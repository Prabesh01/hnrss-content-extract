<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sun, 28 Dec 2025 22:10:27 +0000</lastBuildDate><item><title>Fathers‚Äô choices may be packaged and passed down in sperm RNA</title><link>https://www.quantamagazine.org/how-dads-fitness-may-be-packaged-and-passed-down-in-sperm-rna-20251222/</link><description>&lt;doc fingerprint="f66c934f689e0b5b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How Dad‚Äôs Fitness May Be Packaged and Passed Down in Sperm RNA&lt;/head&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;The standard sperm-meets-egg story posits that sperm cells are hardly more than bundles of shrink-wrapped DNA with tails. Their mission is simple: Deliver a father‚Äôs genes into a mother‚Äôs egg for sexual reproduction. Just about all other aspects of a developing embryo, including its cellular and environmental components, have nothing to do with dad. Those all come from mom.&lt;/p&gt;
    &lt;p&gt;But nearly two decades of studies from multiple independent labs threaten to rewrite that story. They suggest that dad‚Äôs gametes shuttle more than DNA: Within a sperm‚Äôs minuscule head are stowaway molecules, which enter the egg and convey information about the father‚Äôs fitness, such as diet, exercise habits and stress levels, to his offspring. These non-DNA transfers may influence genomic activity that boots up during and after fertilization, exerting some control over the embryo‚Äôs development and influencing the adult they will become.&lt;/p&gt;
    &lt;p&gt;The findings, so far largely described in mouse models, could end up changing the way we think about heredity. They suggest ‚Äúthat what we do in this life affects the next generation,‚Äù said Qi Chen, a reproductive and developmental biologist at the University of Utah Medical School who is among the pioneers of this research. In other words: What a father eats, drinks, inhales, is stressed by or otherwise experiences in the weeks and months before he conceives a child might be encoded in molecules, packaged into his sperm cells and transmitted to his future kid. The researchers have largely zeroed in on RNA molecules, those short-lived copies of DNA that reflect genetic activity at a given time.&lt;/p&gt;
    &lt;p&gt;It‚Äôs a tantalizing notion. But the mechanistic details ‚Äî how experience is encoded, how it‚Äôs transferred from sperm to egg, and whether and how it affects a developing embryo ‚Äî are not easy to unpack, especially given the challenges of conducting research in human subjects. For this reason, and because of the potentially textbook-rewriting implications of the findings, researchers, including those spearheading the work, are cautious about overselling their results.&lt;/p&gt;
    &lt;p&gt;‚ÄúIt‚Äôs still very hand-wavy,‚Äù said the epigeneticist Colin Conine of the University of Pennsylvania Perelman School of Medicine and Children‚Äôs Hospital of Philadelphia, who has been trying to uncover the mechanics of how sperm RNA can contribute nongenetic information to progeny. Some elements of the story are clear, he said: Researchers have significant evidence that the environment can regulate sperm RNAs, that these molecules transmit traits to offspring and that they can regulate embryonic development after fertilization. ‚ÄúWe just don‚Äôt have really any understanding of how RNAs can do this, and that‚Äôs the hand-wavy part,‚Äù Conine said.&lt;/p&gt;
    &lt;p&gt;But evidence keeps piling up. Most recently, in November 2025, a comprehensive paper published in Cell Metabolism traced the downstream molecular effects of a father mouse‚Äôs exercise regimen on sperm microRNAs that target genes ‚Äúcritical for mitochondrial function and metabolic control‚Äù in a developing embryo. The researchers found many of those same RNAs overexpressed in the sperm of well-exercised human men.&lt;/p&gt;
    &lt;p&gt;‚ÄúThis study shows that paternal exercise can confer benefits ‚Äî enhanced endurance and metabolic health ‚Äî to offspring,‚Äù said Chen, who was not involved in the study. ‚ÄúIt‚Äôs a powerful reminder that many sperm-mediated epigenetic effects are deeply adaptive in nature.‚Äù&lt;/p&gt;
    &lt;p&gt;The possibility that a previously undocumented avenue of inheritance is at play is too important to ignore. That‚Äôs why the researchers are now hunkering down in their labs to trace out the molecular processes that would have to operate for a father‚Äôs here-and-now experience to be transferred as developmental instructions to his partner‚Äôs egg.&lt;/p&gt;
    &lt;head rend="h2"&gt;Epigenetic Avenues&lt;/head&gt;
    &lt;p&gt;In most animals, a sperm cell is tiny compared to an egg cell. In humans, an egg contains 10 million times the volume of a sperm and contributes most cellular components ‚Äî nutrition, cytoplasm, mitochondria and other organelles, the molecular machinery to make proteins, and more ‚Äî to a zygote (a newly fertilized egg that hasn‚Äôt started dividing). Plus, a mother provides the environment within which an embryo and then fetus develops and grows. As a result, the effect of a mother‚Äôs health on her children has long been scrutinized, including at the molecular level. But over the past 15 years or so, the evidence for some kind of non-DNA inheritance of paternal experience has also been strengthening.&lt;/p&gt;
    &lt;p&gt;‚ÄúThere are many different labs that have done diet and stress studies, and typically the readouts of those in the next generation are either metabolism or behavioral changes,‚Äù Conine said. Feed a male mouse a high-fat or low-protein diet, or take him away from his mom when he is young, and his offspring will inherit traits, such as changes in mitochondrial function, related to those environmental conditions. These traits aren‚Äôt necessarily detrimental. For instance, mouse fathers exposed to nicotine sire male pups with livers that are good at disarming not just nicotine but cocaine and other toxins as well.&lt;/p&gt;
    &lt;p&gt;There is a survival logic here, said Oliver Rando, an epigeneticist at the University of Massachusetts Chan Medical School who led the nicotine study. It‚Äôs reasonable to expect that offspring will experience an environmental context similar to that of their parents. Biologically priming them for those conditions could therefore help them survive.&lt;/p&gt;
    &lt;p&gt;‚ÄúYou might think of this as a way to tell your kids something useful for them so that they can be better at dealing with the world they inherit,‚Äù said Rando, a father of two boys.&lt;/p&gt;
    &lt;p&gt;But logic does not make the story true. That‚Äôs why Chen, Rando, Conine and other researchers have been working to uncover the mechanistic components of dad-based epigenetic heredity to add to what is already known about these processes in mothers. ‚ÄúEpigenetics‚Äù refers to heredity processes that do not change the DNA sequences of genes, but rather involve when and to what degree genes are expressed and made into functional proteins. Epigeneticists focus on the molecular biology that unfolds around genomic and chromosomal frameworks that can switch genes on and off in response to internal and external cues.&lt;/p&gt;
    &lt;p&gt;This kind of differential gene expression is central to some of biology‚Äôs greatest wonders ‚Äî for example, the fact that all cells in the human body have the same DNA, and yet brain cells differ dramatically from liver, skin and blood cells. Some cues that trigger changes in gene expression are programmed into DNA, while others come from the environment ‚Äî for example, a dearth of calories or nutrients due to food deprivation, or rising cortisol levels due to stressors such as the absence of parental care. These conditions affect the kinds of metabolites and other molecules circulating in our bodies, which influences what kinds of reactions and genomic processes cells can carry out.&lt;/p&gt;
    &lt;p&gt;Some molecules involved in epigenetic processes, such as methyl or acetyl groups, interface directly with DNA or bind to proteins attached to DNA. These actions loosen up or batten down portions of the genome and are akin to opening or closing doors to specific genes.&lt;/p&gt;
    &lt;p&gt;RNA molecules ‚Äî flexible, ephemeral versions of DNA sequences ‚Äî can also intervene in gene expression. But because they are relatively short-lived, sometimes surviving mere minutes or hours before degrading, they have been overlooked as epigenetic regulators. Since the 1990s, their roles have been clarified, as has their longevity: Certain RNAs can survive for weeks or longer. Some RNAs (such as long noncoding RNAs, or lncRNAs) regulate gene expression by modifying DNA or its proteins. Others, known as microRNAs, alter or repress other RNAs, including those that would otherwise be translated into proteins; this discovery was awarded the 2024 Nobel Prize in Physiology or Medicine.&lt;/p&gt;
    &lt;p&gt;Could sperm carry RNA or other molecules that then participate in epigenetic processes in the embryo? It seemed plausible to some researchers, but it would take a whole lot of experimental work to put the pieces together.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Package of RNA&lt;/head&gt;
    &lt;p&gt;There are three core questions that biologists need to resolve to confirm that sperm cells transmit epigenetic inheritance. The first is how a father‚Äôs body physically encodes lived experience, such as stress, diet, exercise or nicotine use, in the form of molecules ‚Äî for example, as RNAs circulating in blood that reflect gene expression in tissues. The next centers on how molecularly encoded experience could make its way into sperm cells. The third traces how those signals in sperm could become epigenetic vectors during and after fertilization to specify observable traits, known as phenotypes, in offspring.&lt;/p&gt;
    &lt;p&gt;In a series of studies beginning in 2012, Qi Chen started answering all three questions. In what he describes as one of the most serendipitous discoveries of his career, his team at the Chinese Academy of Sciences in Beijing used sequencing techniques to inventory the short RNA molecules present in mice sperm cells.&lt;/p&gt;
    &lt;p&gt;They were shocked to see a subset of the RNAs drastically increasing in concentration as sperm cells matured, and then crowding into the sperm heads with DNA. This same class of RNAs was abundant in the blood serum of various vertebrates, ranging from fish to humans, they found. All of this pointed to the possibility that information-carrying molecules were being transferred into the reproductive cells.&lt;/p&gt;
    &lt;p&gt;It got even more interesting when Chen, who moved to the U.S. academic circuit in 2015, and his team collected sperm RNAs from male mice fed different diets. The RNA assemblages in mice reared on high-fat foods differed dramatically from those in mice that were fed normal diets. And when the researchers injected the RNAs from the sperm of the fat-eating mice into a zygote, some of the male offspring showed metabolic issues associated with a high-fat diet.&lt;/p&gt;
    &lt;p&gt;The experiments hinted at a seemingly heretical possibility, Chen said: that ‚Äúcertain acquired traits during paternal exposure can be ‚Äòmemorized‚Äô in the sperm and inherited by the offspring.‚Äù After characterizing a pathway that regulates sperm RNAs, in 2019 Chen dubbed this channel of heredity the ‚Äúsperm RNA code,‚Äù which he suggested ‚Äúprograms the metabolic health of offspring.‚Äù&lt;/p&gt;
    &lt;p&gt;He wasn‚Äôt the only one to become fixated on this idea. Around the same time, in an article published in Developmental Cell in 2018, Rando‚Äôs team reported the use of biochemical techniques to characterize where and when RNAs are packaged into sperm cells and how those RNAs might change during this process. They were trying to answer the question: ‚ÄúWhat tissue could be responsible for choosing what to tell sperm to tell kids?‚Äù he said. One logical place to start looking was the epididymis. Within this tubular organ attached to the back of the testicle, sperm cells undergo a maturation process, taking about one to two weeks in most mammalian species, before they become ready for fertilization.&lt;/p&gt;
    &lt;p&gt;Rando‚Äôs data showed that sperm cells gain almost all their small RNAs when they are in the epididymis. Using techniques for tracking specific RNA molecules, the scientists observed RNAs getting packaged into virus-size capsules, called epididymosomes, which shuttled the molecules into sperm.&lt;/p&gt;
    &lt;p&gt;‚ÄúThis shows how small RNAs can get trafficked between the body‚Äôs nonreproductive cells, like those in the epididymis, and germline cells,‚Äù such as sperm, Rando said. ‚ÄúThe epididymis has been emerging as a key location for paternal effects. Certainly the epididymis has to be taken seriously as a potential sensor of the world.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;A Molecular Snapshot&lt;/head&gt;
    &lt;p&gt;By ‚Äúsensor of the world,‚Äù Rando is referring to the first stage of a presumed paternal-effects mechanism ‚Äî when a male‚Äôs body translates a lived condition, such as a high-fat diet, rigorous exercise or toxin exposure, into molecular signals. The epididymis then provides a route for the second step, packaging those signals for the next generation.&lt;/p&gt;
    &lt;p&gt;This is also where investigations by Isabelle Mansuy come in. At the University of Zurich and the Swiss Federal Institute of Technology Zurich, she studies the molecular and cellular mechanisms of epigenetic inheritance in mammals.&lt;/p&gt;
    &lt;p&gt;¬© Philippe Rossier / Ringier Media Switzerland&lt;/p&gt;
    &lt;p&gt;In one line of her research, she focuses on processes that transmit the molecular effects of traumatic stress to subsequent generations by focusing on extracellular vesicles (EVs) that circulate in blood. Shed by almost every type of cell in the body, including in the epididymis (the epididymosomes are EVs), they carry a diversity of molecular cargo, such as RNAs, proteins, lipids and metabolites. Because EVs circulate in blood just about anywhere in the body and can cross cell membranes, they provide a potential means to transfer molecules and the biological cues they carry between bodily tissues and reproductive cells. Notably, RNAs tend to survive longer when packaged in EVs.&lt;/p&gt;
    &lt;p&gt;Mansuy creates trauma in mice by subjecting the animals to conditions such as restraint or maternal separation when they are young. Then she searches for molecular changes in reproductive cells that could cause similar consequences of trauma to manifest in the children or even grandchildren of the animals who directly endure it.&lt;/p&gt;
    &lt;p&gt;She‚Äôs shown that traumatic stress alters metabolic pathways, especially those that involve lipids, in exposed male mice and their offspring. She has also found a similar metabolic profile in humans who experienced high stress in childhood. In mice, some of the metabolic changes remained discernible through five generations ‚Äî a rare data-backed finding for epigenetic inheritance cascading through generations.&lt;/p&gt;
    &lt;p&gt;Dennis Kunkel Microscopy/Science Source&lt;/p&gt;
    &lt;p&gt;In March 2025, in a preprint uploaded to biorxiv.org, Mansuy and colleagues reported that EVs in mice can transport certain RNAs, metabolites and lipids linked to early-life stress from circulating blood to sperm, with consequences for offspring. The offspring produced by these sperm cells had stress-related metabolic dysfunction as adults and bore the stress signatures in their own sperm RNA. ‚ÄúThese changes imply a mechanistic link between sperm RNA modifications and phenotypic features in the offspring,‚Äù Mansuy‚Äôs team concluded in their paper, which has not yet been peer-reviewed.&lt;/p&gt;
    &lt;head rend="h2"&gt;Phenotypic Translation&lt;/head&gt;
    &lt;p&gt;Perhaps the trickiest step to understand is how sperm-borne molecules could influence an adult‚Äôs observable traits. In one form of experiment, researchers extract all the sperm RNA from mice that have been raised under stressful or health-altering conditions. Those isolated RNAs are then injected into a zygote. Pups that emerge usually ‚Äúget the dad‚Äôs phenotypes,‚Äù Conine said, suggesting that the RNAs alone confer traits from dad to offspring.&lt;/p&gt;
    &lt;p&gt;But how? During early development, epigenetic processes reign. As one fertilized cell divides into two, and those cells divide again, and so on, one set of DNA instructions is dynamically and repeatedly reprogrammed. The growing body specializes into different cell types and is sculpted into a sequence of increasingly complex forms. It‚Äôs possible, then, that early epigenetic alterations to the genome could have significant downstream effects on an adult.&lt;/p&gt;
    &lt;p&gt;Research out of Conine‚Äôs lab, published in 2024, showed that sperm microRNAs alter gene expression in mouse embryos. Experiments like these, he said, support the idea that offspring can inherit paternal traits via the transfer of non-DNA molecular stowaways in sperm.&lt;/p&gt;
    &lt;p&gt;The recent Cell Metabolism paper took this idea a step further by tracing a mechanism by which this can happen. A team of more than two dozen Chinese researchers focused on the epigenetic transmission of exercise benefits, homing in on a set of microRNAs that reprogram gene expression in the early embryo. These changes ultimately result in skeletal muscle adaptations in adult offspring that enhance exercise endurance. The researchers found that well-exercised mice had more of these microRNAs in their sperm than sedentary mice did. When these microRNAs were transferred into zygotes, the adults they grew into were more physically fit, with more mitochondria in skeletal muscle and higher endurance.&lt;/p&gt;
    &lt;p&gt;But how did the molecules generate the exercise-positive phenotype? In experiments, the researchers found that the microRNAs suppressed a particular protein, which had the effect of boosting genes related to mitochondrial activity and metabolism.&lt;/p&gt;
    &lt;p&gt;Intriguingly, the sperm of physically trained male humans also hosted higher levels of many of the same microRNAs than those of untrained cohorts. ‚ÄúThis cross-species conservation suggests a potential role for these sperm mi[cro]RNAs in intergenerational exercise adaptations in humans,‚Äù the researchers wrote.&lt;/p&gt;
    &lt;head rend="h2"&gt;The First Draft&lt;/head&gt;
    &lt;p&gt;The notion that a father‚Äôs lived experience can become recorded by his body, transmitted to his gametes and relayed to his offspring is no longer as outlandish as it once seemed. Many researchers in the field are willing to float speculative visions of what could be going on, even as they acknowledge that gaps remain.&lt;/p&gt;
    &lt;p&gt;‚ÄúOur hypothesis is that the epididymis ‚Äòsees‚Äô the world and alters the small RNAs it produces in response,‚Äù Rando said. ‚ÄúThese RNAs are then delivered to the zygote upon fertilization and control early gene regulation and development to shape offspring health and disease.‚Äù&lt;/p&gt;
    &lt;p&gt;Conine speculates that once certain RNAs make their way into the egg, they trigger ‚Äúa cascade of changes in developmental gene expression that then leads to these phenotypes‚Äù of the father showing up in the next generation. Remarkably, this unfolds even though the sheer volume of the sperm‚Äôs contents is so much less than an egg‚Äôs contents, including the relative amounts of RNA.&lt;/p&gt;
    &lt;p&gt;The full picture of how paternal experience and behavior might epigenetically influence offspring is not nearly in hand. Researchers are currently piecing the story together, one experiment at a time, rather than proving out every step sequentially in the same set of organisms. One of the gaps is in the characterization of what RNA and perhaps other epigenetic factors do in the zygote to modify genomic activity as it unfolds during development, Mansuy said.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe are still blind men describing for the first time different parts of the same elephant,‚Äù Chen said. ‚ÄúThe underlying mechanism is almost certainly an orchestra of a sperm RNA code and factors beyond that.‚Äù&lt;/p&gt;
    &lt;p&gt;Confirming the findings in humans would take enormous effort, but it would be key to turning these findings in mice into ‚Äúinformed medical advice,‚Äù Chen said. This would require well-controlled experiments following multiple generations, tracking diet, exercise, aging and environmental exposures, while also using advanced tools to decode sperm-packaged molecules ‚Äî and then looking for strong correlations between the molecular and phenotypic data.&lt;/p&gt;
    &lt;p&gt;Even amid the uncertainties, researchers are cautiously moving forward as they learn to believe the results of their own experiments. If they‚Äôre right, they will have discovered a new fact of life, Rando said. When he thinks about his two boys, he wonders what he might have done differently when he was younger, before they were born, that might have tweaked his RNA profile in ways that would affect them today.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe don‚Äôt know enough yet to develop guidance like that,‚Äù Rando said. ‚ÄúMaybe we will get there.‚Äù&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46407502</guid><pubDate>Sun, 28 Dec 2025 01:33:10 +0000</pubDate></item><item><title>Calendar</title><link>https://neatnik.net/calendar/?year=2026</link><description>&lt;doc fingerprint="5ff9519dbc2b8b32"&gt;
  &lt;main&gt;
    &lt;p&gt;üëã Hello! If you print this page, you‚Äôll get a nifty calendar that displays all of the year‚Äôs dates on a single page. It will automatically fit on a single sheet of paper of any size. For best results, adjust your print settings to landscape orientation and disable the header and footer.&lt;/p&gt;
    &lt;p&gt;Take in the year all at once. Fold it up and carry it with you. Jot down your notes on it. Plan things out and observe the passage of time. Above all else, be kind to others.&lt;/p&gt;
    &lt;p&gt;Looking for 2026? Here you go!&lt;/p&gt;
    &lt;p&gt;2026&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="12"&gt;
        &lt;cell role="head"&gt;Jan&lt;/cell&gt;
        &lt;cell role="head"&gt;Feb&lt;/cell&gt;
        &lt;cell role="head"&gt;Mar&lt;/cell&gt;
        &lt;cell role="head"&gt;Apr&lt;/cell&gt;
        &lt;cell role="head"&gt;May&lt;/cell&gt;
        &lt;cell role="head"&gt;Jun&lt;/cell&gt;
        &lt;cell role="head"&gt;Jul&lt;/cell&gt;
        &lt;cell role="head"&gt;Aug&lt;/cell&gt;
        &lt;cell role="head"&gt;Sep&lt;/cell&gt;
        &lt;cell role="head"&gt;Oct&lt;/cell&gt;
        &lt;cell role="head"&gt;Nov&lt;/cell&gt;
        &lt;cell role="head"&gt;Dec&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;1 T&lt;/cell&gt;
        &lt;cell&gt;1 S&lt;/cell&gt;
        &lt;cell&gt;1 S&lt;/cell&gt;
        &lt;cell&gt;1 W&lt;/cell&gt;
        &lt;cell&gt;1 F&lt;/cell&gt;
        &lt;cell&gt;1 M&lt;/cell&gt;
        &lt;cell&gt;1 W&lt;/cell&gt;
        &lt;cell&gt;1 S&lt;/cell&gt;
        &lt;cell&gt;1 T&lt;/cell&gt;
        &lt;cell&gt;1 T&lt;/cell&gt;
        &lt;cell&gt;1 S&lt;/cell&gt;
        &lt;cell&gt;1 T&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;2 F&lt;/cell&gt;
        &lt;cell&gt;2 M&lt;/cell&gt;
        &lt;cell&gt;2 M&lt;/cell&gt;
        &lt;cell&gt;2 T&lt;/cell&gt;
        &lt;cell&gt;2 S&lt;/cell&gt;
        &lt;cell&gt;2 T&lt;/cell&gt;
        &lt;cell&gt;2 T&lt;/cell&gt;
        &lt;cell&gt;2 S&lt;/cell&gt;
        &lt;cell&gt;2 W&lt;/cell&gt;
        &lt;cell&gt;2 F&lt;/cell&gt;
        &lt;cell&gt;2 M&lt;/cell&gt;
        &lt;cell&gt;2 W&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;3 S&lt;/cell&gt;
        &lt;cell&gt;3 T&lt;/cell&gt;
        &lt;cell&gt;3 T&lt;/cell&gt;
        &lt;cell&gt;3 F&lt;/cell&gt;
        &lt;cell&gt;3 S&lt;/cell&gt;
        &lt;cell&gt;3 W&lt;/cell&gt;
        &lt;cell&gt;3 F&lt;/cell&gt;
        &lt;cell&gt;3 M&lt;/cell&gt;
        &lt;cell&gt;3 T&lt;/cell&gt;
        &lt;cell&gt;3 S&lt;/cell&gt;
        &lt;cell&gt;3 T&lt;/cell&gt;
        &lt;cell&gt;3 T&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;4 S&lt;/cell&gt;
        &lt;cell&gt;4 W&lt;/cell&gt;
        &lt;cell&gt;4 W&lt;/cell&gt;
        &lt;cell&gt;4 S&lt;/cell&gt;
        &lt;cell&gt;4 M&lt;/cell&gt;
        &lt;cell&gt;4 T&lt;/cell&gt;
        &lt;cell&gt;4 S&lt;/cell&gt;
        &lt;cell&gt;4 T&lt;/cell&gt;
        &lt;cell&gt;4 F&lt;/cell&gt;
        &lt;cell&gt;4 S&lt;/cell&gt;
        &lt;cell&gt;4 W&lt;/cell&gt;
        &lt;cell&gt;4 F&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;5 M&lt;/cell&gt;
        &lt;cell&gt;5 T&lt;/cell&gt;
        &lt;cell&gt;5 T&lt;/cell&gt;
        &lt;cell&gt;5 S&lt;/cell&gt;
        &lt;cell&gt;5 T&lt;/cell&gt;
        &lt;cell&gt;5 F&lt;/cell&gt;
        &lt;cell&gt;5 S&lt;/cell&gt;
        &lt;cell&gt;5 W&lt;/cell&gt;
        &lt;cell&gt;5 S&lt;/cell&gt;
        &lt;cell&gt;5 M&lt;/cell&gt;
        &lt;cell&gt;5 T&lt;/cell&gt;
        &lt;cell&gt;5 S&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;6 T&lt;/cell&gt;
        &lt;cell&gt;6 F&lt;/cell&gt;
        &lt;cell&gt;6 F&lt;/cell&gt;
        &lt;cell&gt;6 M&lt;/cell&gt;
        &lt;cell&gt;6 W&lt;/cell&gt;
        &lt;cell&gt;6 S&lt;/cell&gt;
        &lt;cell&gt;6 M&lt;/cell&gt;
        &lt;cell&gt;6 T&lt;/cell&gt;
        &lt;cell&gt;6 S&lt;/cell&gt;
        &lt;cell&gt;6 T&lt;/cell&gt;
        &lt;cell&gt;6 F&lt;/cell&gt;
        &lt;cell&gt;6 S&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;7 W&lt;/cell&gt;
        &lt;cell&gt;7 S&lt;/cell&gt;
        &lt;cell&gt;7 S&lt;/cell&gt;
        &lt;cell&gt;7 T&lt;/cell&gt;
        &lt;cell&gt;7 T&lt;/cell&gt;
        &lt;cell&gt;7 S&lt;/cell&gt;
        &lt;cell&gt;7 T&lt;/cell&gt;
        &lt;cell&gt;7 F&lt;/cell&gt;
        &lt;cell&gt;7 M&lt;/cell&gt;
        &lt;cell&gt;7 W&lt;/cell&gt;
        &lt;cell&gt;7 S&lt;/cell&gt;
        &lt;cell&gt;7 M&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;8 T&lt;/cell&gt;
        &lt;cell&gt;8 S&lt;/cell&gt;
        &lt;cell&gt;8 S&lt;/cell&gt;
        &lt;cell&gt;8 W&lt;/cell&gt;
        &lt;cell&gt;8 F&lt;/cell&gt;
        &lt;cell&gt;8 M&lt;/cell&gt;
        &lt;cell&gt;8 W&lt;/cell&gt;
        &lt;cell&gt;8 S&lt;/cell&gt;
        &lt;cell&gt;8 T&lt;/cell&gt;
        &lt;cell&gt;8 T&lt;/cell&gt;
        &lt;cell&gt;8 S&lt;/cell&gt;
        &lt;cell&gt;8 T&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;9 F&lt;/cell&gt;
        &lt;cell&gt;9 M&lt;/cell&gt;
        &lt;cell&gt;9 M&lt;/cell&gt;
        &lt;cell&gt;9 T&lt;/cell&gt;
        &lt;cell&gt;9 S&lt;/cell&gt;
        &lt;cell&gt;9 T&lt;/cell&gt;
        &lt;cell&gt;9 T&lt;/cell&gt;
        &lt;cell&gt;9 S&lt;/cell&gt;
        &lt;cell&gt;9 W&lt;/cell&gt;
        &lt;cell&gt;9 F&lt;/cell&gt;
        &lt;cell&gt;9 M&lt;/cell&gt;
        &lt;cell&gt;9 W&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;10 S&lt;/cell&gt;
        &lt;cell&gt;10 T&lt;/cell&gt;
        &lt;cell&gt;10 T&lt;/cell&gt;
        &lt;cell&gt;10 F&lt;/cell&gt;
        &lt;cell&gt;10 S&lt;/cell&gt;
        &lt;cell&gt;10 W&lt;/cell&gt;
        &lt;cell&gt;10 F&lt;/cell&gt;
        &lt;cell&gt;10 M&lt;/cell&gt;
        &lt;cell&gt;10 T&lt;/cell&gt;
        &lt;cell&gt;10 S&lt;/cell&gt;
        &lt;cell&gt;10 T&lt;/cell&gt;
        &lt;cell&gt;10 T&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;11 S&lt;/cell&gt;
        &lt;cell&gt;11 W&lt;/cell&gt;
        &lt;cell&gt;11 W&lt;/cell&gt;
        &lt;cell&gt;11 S&lt;/cell&gt;
        &lt;cell&gt;11 M&lt;/cell&gt;
        &lt;cell&gt;11 T&lt;/cell&gt;
        &lt;cell&gt;11 S&lt;/cell&gt;
        &lt;cell&gt;11 T&lt;/cell&gt;
        &lt;cell&gt;11 F&lt;/cell&gt;
        &lt;cell&gt;11 S&lt;/cell&gt;
        &lt;cell&gt;11 W&lt;/cell&gt;
        &lt;cell&gt;11 F&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;12 M&lt;/cell&gt;
        &lt;cell&gt;12 T&lt;/cell&gt;
        &lt;cell&gt;12 T&lt;/cell&gt;
        &lt;cell&gt;12 S&lt;/cell&gt;
        &lt;cell&gt;12 T&lt;/cell&gt;
        &lt;cell&gt;12 F&lt;/cell&gt;
        &lt;cell&gt;12 S&lt;/cell&gt;
        &lt;cell&gt;12 W&lt;/cell&gt;
        &lt;cell&gt;12 S&lt;/cell&gt;
        &lt;cell&gt;12 M&lt;/cell&gt;
        &lt;cell&gt;12 T&lt;/cell&gt;
        &lt;cell&gt;12 S&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;13 T&lt;/cell&gt;
        &lt;cell&gt;13 F&lt;/cell&gt;
        &lt;cell&gt;13 F&lt;/cell&gt;
        &lt;cell&gt;13 M&lt;/cell&gt;
        &lt;cell&gt;13 W&lt;/cell&gt;
        &lt;cell&gt;13 S&lt;/cell&gt;
        &lt;cell&gt;13 M&lt;/cell&gt;
        &lt;cell&gt;13 T&lt;/cell&gt;
        &lt;cell&gt;13 S&lt;/cell&gt;
        &lt;cell&gt;13 T&lt;/cell&gt;
        &lt;cell&gt;13 F&lt;/cell&gt;
        &lt;cell&gt;13 S&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;14 W&lt;/cell&gt;
        &lt;cell&gt;14 S&lt;/cell&gt;
        &lt;cell&gt;14 S&lt;/cell&gt;
        &lt;cell&gt;14 T&lt;/cell&gt;
        &lt;cell&gt;14 T&lt;/cell&gt;
        &lt;cell&gt;14 S&lt;/cell&gt;
        &lt;cell&gt;14 T&lt;/cell&gt;
        &lt;cell&gt;14 F&lt;/cell&gt;
        &lt;cell&gt;14 M&lt;/cell&gt;
        &lt;cell&gt;14 W&lt;/cell&gt;
        &lt;cell&gt;14 S&lt;/cell&gt;
        &lt;cell&gt;14 M&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;15 T&lt;/cell&gt;
        &lt;cell&gt;15 S&lt;/cell&gt;
        &lt;cell&gt;15 S&lt;/cell&gt;
        &lt;cell&gt;15 W&lt;/cell&gt;
        &lt;cell&gt;15 F&lt;/cell&gt;
        &lt;cell&gt;15 M&lt;/cell&gt;
        &lt;cell&gt;15 W&lt;/cell&gt;
        &lt;cell&gt;15 S&lt;/cell&gt;
        &lt;cell&gt;15 T&lt;/cell&gt;
        &lt;cell&gt;15 T&lt;/cell&gt;
        &lt;cell&gt;15 S&lt;/cell&gt;
        &lt;cell&gt;15 T&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;16 F&lt;/cell&gt;
        &lt;cell&gt;16 M&lt;/cell&gt;
        &lt;cell&gt;16 M&lt;/cell&gt;
        &lt;cell&gt;16 T&lt;/cell&gt;
        &lt;cell&gt;16 S&lt;/cell&gt;
        &lt;cell&gt;16 T&lt;/cell&gt;
        &lt;cell&gt;16 T&lt;/cell&gt;
        &lt;cell&gt;16 S&lt;/cell&gt;
        &lt;cell&gt;16 W&lt;/cell&gt;
        &lt;cell&gt;16 F&lt;/cell&gt;
        &lt;cell&gt;16 M&lt;/cell&gt;
        &lt;cell&gt;16 W&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;17 S&lt;/cell&gt;
        &lt;cell&gt;17 T&lt;/cell&gt;
        &lt;cell&gt;17 T&lt;/cell&gt;
        &lt;cell&gt;17 F&lt;/cell&gt;
        &lt;cell&gt;17 S&lt;/cell&gt;
        &lt;cell&gt;17 W&lt;/cell&gt;
        &lt;cell&gt;17 F&lt;/cell&gt;
        &lt;cell&gt;17 M&lt;/cell&gt;
        &lt;cell&gt;17 T&lt;/cell&gt;
        &lt;cell&gt;17 S&lt;/cell&gt;
        &lt;cell&gt;17 T&lt;/cell&gt;
        &lt;cell&gt;17 T&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;18 S&lt;/cell&gt;
        &lt;cell&gt;18 W&lt;/cell&gt;
        &lt;cell&gt;18 W&lt;/cell&gt;
        &lt;cell&gt;18 S&lt;/cell&gt;
        &lt;cell&gt;18 M&lt;/cell&gt;
        &lt;cell&gt;18 T&lt;/cell&gt;
        &lt;cell&gt;18 S&lt;/cell&gt;
        &lt;cell&gt;18 T&lt;/cell&gt;
        &lt;cell&gt;18 F&lt;/cell&gt;
        &lt;cell&gt;18 S&lt;/cell&gt;
        &lt;cell&gt;18 W&lt;/cell&gt;
        &lt;cell&gt;18 F&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;19 M&lt;/cell&gt;
        &lt;cell&gt;19 T&lt;/cell&gt;
        &lt;cell&gt;19 T&lt;/cell&gt;
        &lt;cell&gt;19 S&lt;/cell&gt;
        &lt;cell&gt;19 T&lt;/cell&gt;
        &lt;cell&gt;19 F&lt;/cell&gt;
        &lt;cell&gt;19 S&lt;/cell&gt;
        &lt;cell&gt;19 W&lt;/cell&gt;
        &lt;cell&gt;19 S&lt;/cell&gt;
        &lt;cell&gt;19 M&lt;/cell&gt;
        &lt;cell&gt;19 T&lt;/cell&gt;
        &lt;cell&gt;19 S&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;20 T&lt;/cell&gt;
        &lt;cell&gt;20 F&lt;/cell&gt;
        &lt;cell&gt;20 F&lt;/cell&gt;
        &lt;cell&gt;20 M&lt;/cell&gt;
        &lt;cell&gt;20 W&lt;/cell&gt;
        &lt;cell&gt;20 S&lt;/cell&gt;
        &lt;cell&gt;20 M&lt;/cell&gt;
        &lt;cell&gt;20 T&lt;/cell&gt;
        &lt;cell&gt;20 S&lt;/cell&gt;
        &lt;cell&gt;20 T&lt;/cell&gt;
        &lt;cell&gt;20 F&lt;/cell&gt;
        &lt;cell&gt;20 S&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;21 W&lt;/cell&gt;
        &lt;cell&gt;21 S&lt;/cell&gt;
        &lt;cell&gt;21 S&lt;/cell&gt;
        &lt;cell&gt;21 T&lt;/cell&gt;
        &lt;cell&gt;21 T&lt;/cell&gt;
        &lt;cell&gt;21 S&lt;/cell&gt;
        &lt;cell&gt;21 T&lt;/cell&gt;
        &lt;cell&gt;21 F&lt;/cell&gt;
        &lt;cell&gt;21 M&lt;/cell&gt;
        &lt;cell&gt;21 W&lt;/cell&gt;
        &lt;cell&gt;21 S&lt;/cell&gt;
        &lt;cell&gt;21 M&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;22 T&lt;/cell&gt;
        &lt;cell&gt;22 S&lt;/cell&gt;
        &lt;cell&gt;22 S&lt;/cell&gt;
        &lt;cell&gt;22 W&lt;/cell&gt;
        &lt;cell&gt;22 F&lt;/cell&gt;
        &lt;cell&gt;22 M&lt;/cell&gt;
        &lt;cell&gt;22 W&lt;/cell&gt;
        &lt;cell&gt;22 S&lt;/cell&gt;
        &lt;cell&gt;22 T&lt;/cell&gt;
        &lt;cell&gt;22 T&lt;/cell&gt;
        &lt;cell&gt;22 S&lt;/cell&gt;
        &lt;cell&gt;22 T&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;23 F&lt;/cell&gt;
        &lt;cell&gt;23 M&lt;/cell&gt;
        &lt;cell&gt;23 M&lt;/cell&gt;
        &lt;cell&gt;23 T&lt;/cell&gt;
        &lt;cell&gt;23 S&lt;/cell&gt;
        &lt;cell&gt;23 T&lt;/cell&gt;
        &lt;cell&gt;23 T&lt;/cell&gt;
        &lt;cell&gt;23 S&lt;/cell&gt;
        &lt;cell&gt;23 W&lt;/cell&gt;
        &lt;cell&gt;23 F&lt;/cell&gt;
        &lt;cell&gt;23 M&lt;/cell&gt;
        &lt;cell&gt;23 W&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;24 S&lt;/cell&gt;
        &lt;cell&gt;24 T&lt;/cell&gt;
        &lt;cell&gt;24 T&lt;/cell&gt;
        &lt;cell&gt;24 F&lt;/cell&gt;
        &lt;cell&gt;24 S&lt;/cell&gt;
        &lt;cell&gt;24 W&lt;/cell&gt;
        &lt;cell&gt;24 F&lt;/cell&gt;
        &lt;cell&gt;24 M&lt;/cell&gt;
        &lt;cell&gt;24 T&lt;/cell&gt;
        &lt;cell&gt;24 S&lt;/cell&gt;
        &lt;cell&gt;24 T&lt;/cell&gt;
        &lt;cell&gt;24 T&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;25 S&lt;/cell&gt;
        &lt;cell&gt;25 W&lt;/cell&gt;
        &lt;cell&gt;25 W&lt;/cell&gt;
        &lt;cell&gt;25 S&lt;/cell&gt;
        &lt;cell&gt;25 M&lt;/cell&gt;
        &lt;cell&gt;25 T&lt;/cell&gt;
        &lt;cell&gt;25 S&lt;/cell&gt;
        &lt;cell&gt;25 T&lt;/cell&gt;
        &lt;cell&gt;25 F&lt;/cell&gt;
        &lt;cell&gt;25 S&lt;/cell&gt;
        &lt;cell&gt;25 W&lt;/cell&gt;
        &lt;cell&gt;25 F&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;26 M&lt;/cell&gt;
        &lt;cell&gt;26 T&lt;/cell&gt;
        &lt;cell&gt;26 T&lt;/cell&gt;
        &lt;cell&gt;26 S&lt;/cell&gt;
        &lt;cell&gt;26 T&lt;/cell&gt;
        &lt;cell&gt;26 F&lt;/cell&gt;
        &lt;cell&gt;26 S&lt;/cell&gt;
        &lt;cell&gt;26 W&lt;/cell&gt;
        &lt;cell&gt;26 S&lt;/cell&gt;
        &lt;cell&gt;26 M&lt;/cell&gt;
        &lt;cell&gt;26 T&lt;/cell&gt;
        &lt;cell&gt;26 S&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;27 T&lt;/cell&gt;
        &lt;cell&gt;27 F&lt;/cell&gt;
        &lt;cell&gt;27 F&lt;/cell&gt;
        &lt;cell&gt;27 M&lt;/cell&gt;
        &lt;cell&gt;27 W&lt;/cell&gt;
        &lt;cell&gt;27 S&lt;/cell&gt;
        &lt;cell&gt;27 M&lt;/cell&gt;
        &lt;cell&gt;27 T&lt;/cell&gt;
        &lt;cell&gt;27 S&lt;/cell&gt;
        &lt;cell&gt;27 T&lt;/cell&gt;
        &lt;cell&gt;27 F&lt;/cell&gt;
        &lt;cell&gt;27 S&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;28 W&lt;/cell&gt;
        &lt;cell&gt;28 S&lt;/cell&gt;
        &lt;cell&gt;28 S&lt;/cell&gt;
        &lt;cell&gt;28 T&lt;/cell&gt;
        &lt;cell&gt;28 T&lt;/cell&gt;
        &lt;cell&gt;28 S&lt;/cell&gt;
        &lt;cell&gt;28 T&lt;/cell&gt;
        &lt;cell&gt;28 F&lt;/cell&gt;
        &lt;cell&gt;28 M&lt;/cell&gt;
        &lt;cell&gt;28 W&lt;/cell&gt;
        &lt;cell&gt;28 S&lt;/cell&gt;
        &lt;cell&gt;28 M&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;29 T&lt;/cell&gt;
        &lt;cell&gt;29 S&lt;/cell&gt;
        &lt;cell&gt;29 W&lt;/cell&gt;
        &lt;cell&gt;29 F&lt;/cell&gt;
        &lt;cell&gt;29 M&lt;/cell&gt;
        &lt;cell&gt;29 W&lt;/cell&gt;
        &lt;cell&gt;29 S&lt;/cell&gt;
        &lt;cell&gt;29 T&lt;/cell&gt;
        &lt;cell&gt;29 T&lt;/cell&gt;
        &lt;cell&gt;29 S&lt;/cell&gt;
        &lt;cell&gt;29 T&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;30 F&lt;/cell&gt;
        &lt;cell&gt;30 M&lt;/cell&gt;
        &lt;cell&gt;30 T&lt;/cell&gt;
        &lt;cell&gt;30 S&lt;/cell&gt;
        &lt;cell&gt;30 T&lt;/cell&gt;
        &lt;cell&gt;30 T&lt;/cell&gt;
        &lt;cell&gt;30 S&lt;/cell&gt;
        &lt;cell&gt;30 W&lt;/cell&gt;
        &lt;cell&gt;30 F&lt;/cell&gt;
        &lt;cell&gt;30 M&lt;/cell&gt;
        &lt;cell&gt;30 W&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;31 S&lt;/cell&gt;
        &lt;cell&gt;31 T&lt;/cell&gt;
        &lt;cell&gt;31 S&lt;/cell&gt;
        &lt;cell&gt;31 F&lt;/cell&gt;
        &lt;cell&gt;31 M&lt;/cell&gt;
        &lt;cell&gt;31 S&lt;/cell&gt;
        &lt;cell&gt;31 T&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46408613</guid><pubDate>Sun, 28 Dec 2025 05:02:39 +0000</pubDate></item><item><title>Growing up in ‚Äú404 Not Found‚Äù: China's nuclear city in the Gobi Desert</title><link>https://substack.com/inbox/post/182743659</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46408988</guid><pubDate>Sun, 28 Dec 2025 06:43:25 +0000</pubDate></item><item><title>Hungry Fat Cells Could Someday Starve Cancer</title><link>https://www.ucsf.edu/news/2025/01/429411/how-hungry-fat-cells-could-someday-starve-cancer-death</link><description>&lt;doc fingerprint="3348413b9eaeeb1b"&gt;
  &lt;main&gt;
    &lt;p&gt;Liposuction and plastic surgery aren‚Äôt often mentioned in the same breath as cancer.&lt;/p&gt;
    &lt;p&gt;But they are the inspiration for a new approach to treating cancer that uses engineered fat cells to deprive tumors of nutrition.&lt;/p&gt;
    &lt;p&gt;Researchers at UC San Francisco used the gene editing technology CRISPR to turn ordinary white fat cells into ‚Äúbeige‚Äù fat cells, which voraciously consume calories to make heat. The work is funded by the National Institute of Health (NIH).&lt;/p&gt;
    &lt;p&gt;Then, they implanted them near tumors the way plastic surgeons inject fat from one part of the body to plump up another. The fat cells scarfed up all the nutrients, starving most of the tumor cells to death. The approach even worked when the fat cells were implanted in mice far from the sites of their tumors.&lt;/p&gt;
    &lt;p&gt;The approach's reliance on a common procedure could speed its use as a new form of cellular therapy.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe already routinely remove fat cells with liposuction and put them back via plastic surgery,‚Äù said Nadav Ahituv, PhD, director of the UCSF Institute for Human Genetics and professor in the Department of Bioengineering and Therapeutic Sciences. He is the senior author of the paper, which appears Feb. 4 in Nature Biotechnology. ‚ÄúThese fat cells can be easily manipulated in the lab and safely placed back into the body, making them an attractive platform for cellular therapy, including for cancer.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;&lt;lb/&gt; Cold therapy sparks a new idea&lt;/head&gt;
    &lt;p&gt;Ahituv and his post-doc at the time, Hai Nguyen, PhD, were aware of studies that showed exposure to cold could suppress cancer in mice. One experiment even showed it could help a patient with non-Hodgkin lymphoma. Scientists concluded that the cancer cells were starving because the cold was activating brown fat cells.&lt;/p&gt;
    &lt;p&gt;But cold therapy isn‚Äôt a viable option for cancer patients with fragile health. So, Ahituv and Nguyen turned to the idea of using beige fat, wagering that they could engineer it to burn enough calories, even in the absence of cold, to deprive tumors of the fuel they needed to grow.&lt;/p&gt;
    &lt;p&gt;Nguyen, who is the first author of the paper, used CRISPR to activate genes that are dormant in white fat cells but are active in brown fat cells, in the hopes of finding the ones that would transform the white fat cells into the hungriest of beige fat cells.&lt;/p&gt;
    &lt;p&gt;A gene called UCP1 rose to the top. Nguyen grew UCP1 beige fat cells and cancer cells in a ‚Äútrans-well‚Äù petri dish. The cancer cells were on the bottom and the fat cells were above them in separate compartments that kept the cells apart but forced them to share nutrients. The results were shocking.&lt;/p&gt;
    &lt;p&gt;‚ÄúIn our very first trans-well experiment, very few cancer cells survived. We thought we had messed something up ‚Äì we were sure it was a mistake,‚Äù Ahituv recalled. ‚ÄúSo, we repeated it multiple times, and we kept seeing the same effect.‚Äù&lt;/p&gt;
    &lt;p&gt;The beige fat cells held sway over two different types of breast cancer cells, as well as colon, pancreatic and prostate cancer cells.&lt;/p&gt;
    &lt;p&gt;No fat cells: Actively-multiplying cancer cells (pink) are seen in a mouse predisposed to develop breast cancer.&lt;/p&gt;
    &lt;p&gt;Fat cells are added: When fat cells were implanted in the breast, far fewer cancer cells were able to multiply.&lt;/p&gt;
    &lt;head rend="h2"&gt;Cancer is no match for hungry fat&lt;/head&gt;
    &lt;p&gt;But the researchers still didn‚Äôt know if the beige fat cells would work in a more realistic context. So, they turned to fat organoids, which are coherent clumps of cells grown in a dish, to see if they could beat tumor cells when they were implanted next to tumors in mice. The approach worked against breast cancer, as well as pancreatic and prostate cancer cells. The cancer cells starved as the fat cells gobbled up all the available nutrients.&lt;/p&gt;
    &lt;p&gt;Once implanted into mice that were genetically predisposed to develop cancer, the beige fat cells were so powerful that they suppressed pancreatic and breast tumors. Beige fat even worked when it was implanted far away from the breast cancer cells.&lt;/p&gt;
    &lt;p&gt;To see how the fat cells would work in human tissue, Ahituv and Nguyen teamed up with Jennifer Rosenbluth, MD, PhD, a breast cancer specialist at UCSF. Rosenbluth had amassed a library of breast cancer tissue from mastectomies containing both fat cells and cancer cells.&lt;/p&gt;
    &lt;p&gt;‚ÄúBecause the breast has a lot of fat, we could get fat from the same patient, modify the fat and grow it in a single trans-well experiment with that patient‚Äôs own breast cancer cells,‚Äù Ahituv said.&lt;/p&gt;
    &lt;p&gt;These same-patient beige fat cells outcompeted breast cancer cells in petri dishes ‚Äì and when they were implanted together in mouse models.&lt;/p&gt;
    &lt;p&gt;Knowing that cancers have preferred diets, the researchers engineered fat just to eat certain nutrients. Certain forms of pancreatic cancer, for example, rely on uridine when glucose is scarce. So, they programmed the fat cells to eat just uridine, and they easily outcompeted the pancreatic cancer cells. This suggested that fat could be adapted to any cancer‚Äôs dietary preferences.&lt;/p&gt;
    &lt;head rend="h2"&gt;A new approach to living cell therapy&lt;/head&gt;
    &lt;p&gt;Fat cells have many advantages when it comes to living cell therapies, according to Ahituv. They are easy to obtain from patients. They grow well in the laboratory and can be engineered to express different genes and take on different biological roles. And they behave well once they are put back into the body, not straying from the location where they‚Äôre implanted and playing nice with the immune system.&lt;/p&gt;
    &lt;p&gt;It‚Äôs a conclusion supported by decades of plastic surgery.&lt;/p&gt;
    &lt;p&gt;‚ÄúWith fat cells, there‚Äôs less interaction with the environment, so there‚Äôs very little worry of the cells leaking out into the body, where they might cause problems,‚Äù Ahituv said.&lt;/p&gt;
    &lt;p&gt;Fat cells can also be programmed to emit signals or carry out more complicated tasks.&lt;/p&gt;
    &lt;p&gt;And their ability to defeat cancer even when they are not right next to tumors could prove invaluable for treating hard-to-reach cancers like glioblastoma, which affects the brain, as well as many other diseases.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe think these cells could also be designed to sense glucose in the bloodstream and release insulin, for diabetes, or suck up iron in diseases where there‚Äôs excessive iron like hemochromatosis,‚Äù Ahituv said. ‚ÄúThe sky‚Äôs the limit for these fat cells.‚Äù&lt;/p&gt;
    &lt;head rend="h3"&gt;A pioneering scientist is lost too soon&lt;/head&gt;
    &lt;p&gt;The discovery of how hungry fat cells could suppress cancer began in 2021, when Hai Nguyen, PhD, joined Ahituv‚Äôs lab. Nguyen had years of experience working with fat cells in the laboratory. But he wasn‚Äôt aware of their cancer-fighting potential until an experiment pitting engineered beige fat cells against cancer cells tipped them off.&lt;/p&gt;
    &lt;p&gt;Amazed at how the beige fat was able to starve the tumors, they tested the engineered cells against all sorts of cancers in the lab. The project grew to include other scientists and cancer specialists at UCSF and across the country, offering a proof of principle that the approach could work against a wide range of cancers.&lt;/p&gt;
    &lt;p&gt;Nguyen moved to UT Austin to start his own lab in January 2024 but passed away suddenly in November before he could finish the final experiments. The paper, of which he is the first author, is dedicated to him.&lt;/p&gt;
    &lt;p&gt;‚ÄúHai was one of the most amazing post-docs I‚Äôll ever have and a great friend,‚Äù Ahituv said. ‚ÄúWe are heartbroken. He has left us with this incredible gift of a technology that could truly change lives.‚Äù&lt;/p&gt;
    &lt;head rend="h3"&gt;A pioneering scientist is lost&lt;lb/&gt; too soon&lt;/head&gt;
    &lt;p&gt;The discovery of how hungry fat cells could suppress cancer began in 2021, when Hai Nguyen, PhD, joined Ahituv‚Äôs lab. Nguyen had years of experience working with fat cells in the laboratory. But he wasn‚Äôt aware of their cancer-fighting potential until an experiment pitting engineered beige fat cells against cancer cells tipped them off.&lt;/p&gt;
    &lt;p&gt;Amazed at how the beige fat was able to starve the tumors, they tested the engineered cells against all sorts of cancers in the lab. The project grew to include other scientists and cancer specialists at UCSF and across the country, offering a proof of principle that the approach could work against a wide range of cancers.&lt;/p&gt;
    &lt;p&gt;Nguyen moved to UT Austin to start his own lab in January 2024 but passed away suddenly in November before he could finish the final experiments. The paper, of which he is the first author, is dedicated to him.&lt;/p&gt;
    &lt;p&gt;‚ÄúHai was one of the most amazing post-docs I‚Äôll ever have and a great friend,‚Äù Ahituv said. ‚ÄúWe are heartbroken. He has left us with this incredible gift of a technology that could truly change lives.‚Äù&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; Authors: In addition to Ahituv, Nguyen, and Rosenbluth, other UCSF authors include Kelly An, Yusuke Ito, Bhushan N. Kharbikar, PhD, Rory Sheng, Breanna Paredes, MS, Elizabeth Murray, Kimberly Pham, Michael Bruck, Xujia Zhou, MS, PhD, Cassidy Biellak, Aki Ushiki, PhD, Mai Nobuhara, MS, Daniel A. Bernards, PhD, Mark Jesus M. Magbanua, PhD, Laura A. Huppert, MD, Heinz Hammerlindl, PhD, Laura Esserman, MD, MBA, Tejal A. Desai, PhD, and Sook Wah Yee, MPharm. For all authors see the paper.&lt;/p&gt;
    &lt;p&gt;Funding: The work was funded in part by the UCSF Sandler Program for Breakthrough Biomedical Research, the UCSF Living Therapeutics Initiative, the National Institutes of Health (1R01DK124769, 1R01CA283826) and the California Institute for Regenerative Medicine. Ahituv is a cofounder and on the scientific advisory board of Regel Therapeutics.&lt;/p&gt;
    &lt;p&gt;Disclosures: Ahituv receives funding from BioMarin Pharmaceutical Incorporate. Ahituv has filed a patent application covering embodiments and concepts disclosed in the manuscript. For all funding and disclosures see the paper.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46409928</guid><pubDate>Sun, 28 Dec 2025 10:04:42 +0000</pubDate></item><item><title>Last Year on My Mac: Look Back in Disbelief</title><link>https://eclecticlight.co/2025/12/28/last-year-on-my-mac-look-back-in-disbelief/</link><description>&lt;doc fingerprint="26bce657dc5791ff"&gt;
  &lt;main&gt;
    &lt;p&gt;If someone had told me 12 months ago what was going to happen this past year, I wouldn‚Äôt have believed them. Skipping swiftly past all the political, economic and social turmoil, I come to the interface changes brought in macOS Tahoe with Liquid Glass. After three months of strong feedback during beta-testing, I was disappointed when Tahoe was released on 15 September to see how little had been addressed. When 26.1 followed on 3 November it had only regressed, and 26.2 has done nothing. Here I summarise my opinions on where Tahoe‚Äôs overhaul has gone wrong.&lt;/p&gt;
    &lt;head rend="h4"&gt;What goes round&lt;/head&gt;
    &lt;p&gt;Almost all the content displayed in windows is best suited to rectangular views. Images, video, webpages and other text crave areas bounded by right angles. Gentle rounding on the corners, as in Sequoia, is fine, but the significantly increased radius enforced in Tahoe is a misfit. This either leads to cropping of contents, or reduction in size of the view and wasted space.&lt;/p&gt;
    &lt;p&gt;Cropping is misleading, as seen in this enlarged view of a thumbnail image in the Finder‚Äôs Gallery view, compared to the larger version shown below. The thumbnail misrepresents what‚Äôs in the original.&lt;/p&gt;
    &lt;p&gt;Among Apple‚Äôs claims for this new look is greater consistency. But two windows in the same app, both created using SwiftUI, can‚Äôt even share a common radius, as shown below in Providable running in macOS 26.2.&lt;/p&gt;
    &lt;head rend="h4"&gt;Out of control&lt;/head&gt;
    &lt;p&gt;Tahoe has also increased the size of its controls, without using that to improve their clarity. The best way to see that is in my Mallyshag demo app.&lt;/p&gt;
    &lt;p&gt;This looks good in Sequoia above, but becomes a mess in Tahoe (below) because of its changed control dimensions.&lt;/p&gt;
    &lt;p&gt;Those three buttons are significantly wider, so now overlap one another and are wider than the text box below. The user sees no benefit to this, though, as the text within the controls is identical.&lt;/p&gt;
    &lt;head rend="h4"&gt;Iconoclasm&lt;/head&gt;
    &lt;p&gt;App icons need to be both distinguishable and readily recalled. The first ensures that we can tell one from another, and relies on all the visual cues we can muster, including colours, form and content. Tahoe enforces a rule that everything in the icon must be fitted inside its uniform square with rounded corners, so restricting cues to colours and contents. As a result, the icons of many bundled and other Apple apps have become harder to distinguish in a crowded Dock. Some, including Apple‚Äôs Developer app and the App Store, are indistinguishable, while others have degenerated into vague blotches.&lt;/p&gt;
    &lt;p&gt;Above are most of the apps bundled in Sequoia, and below are those in Tahoe.&lt;/p&gt;
    &lt;head rend="h4"&gt;Whiteout&lt;/head&gt;
    &lt;p&gt;In real life, whiteouts are dangerous because they‚Äôre so disorienting. There‚Äôs no horizon, no features in the landscape, and no clues to navigation. We see and work best in visual environments that are rich in colour and tonal contrasts. Tahoe has continued a trend for Light Mode to be bleached-out white, and Dark Mode to be a moonless night. Seeing where controls, views and contents start and end is difficult, and leaves them suspended in the whiteout.&lt;/p&gt;
    &lt;p&gt;In light mode, with default transparency, tool icons and text are clearly distinguished tonally, as are some controls including buttons and checkboxes. However, text entry fields are indistinguishable from the background, and there‚Äôs a general lack of demarcation, particularly between controls and the list view below.&lt;/p&gt;
    &lt;head rend="h4"&gt;Wet-on-wet&lt;/head&gt;
    &lt;p&gt;This technique is used in watercolours to merge layers of colour diffusely, and the best description of some of the results of transparency in Liquid Glass. My examples speak for themselves, and are drawn first from Apple‚Äôs own design for System Settings.&lt;/p&gt;
    &lt;p&gt;Transparency of the Search box at the top of the sidebar on the left renders it incomprehensible when it‚Äôs underlaid by scrolled navigational content.&lt;/p&gt;
    &lt;p&gt;Although the view title Keyboard remains readable, bleed-through of underlying colours is confusing, distracting and aesthetically upsetting.&lt;/p&gt;
    &lt;p&gt;My next examples show the same window in Providable with a selected list row being scrolled up behind what used to be a window title bar.&lt;/p&gt;
    &lt;p&gt;With the window in focus, the selection colour overwhelms the traffic light controls and window title, which should read Drop Files. This also draws attention to the limited width necessary to accommodate rectangular content in a window with excessively rounded corners.&lt;/p&gt;
    &lt;p&gt;Out of focus the selected row is less overwhelming, but traffic lights and title have dissipated in grey blur.&lt;/p&gt;
    &lt;p&gt;I‚Äôm sure that, in the right place and time, transparency effects of Liquid Glass can be visually pleasing. Not only is this the wrong time and place, but those with visual impairment can no longer remove or even reduce these effects, as the Reduce Transparency control in Accessibility settings no longer reduces transparency in any useful way. That was one of the regressions in 26.1 that hasn‚Äôt been addressed in 26.2.&lt;/p&gt;
    &lt;head rend="h4"&gt;Summary&lt;/head&gt;
    &lt;p&gt;macOS Tahoe‚Äôs visual interface:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fits largely rectangular contents into windows with excessively rounded corners.&lt;/item&gt;
      &lt;item&gt;Enlarges controls without any functional benefit.&lt;/item&gt;
      &lt;item&gt;Results in app icons being more uniform, thus less distinguishable and memorable.&lt;/item&gt;
      &lt;item&gt;Fails to distinguish tools, controls and other interface elements using differences in tone, so making them harder to use.&lt;/item&gt;
      &lt;item&gt;Makes a mess where transparent layers are superimposed, and won‚Äôt reduce transparency when that‚Äôs needed to render its interface more accessible.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Maybe this is because I‚Äôm getting older, but that gives me the benefit of having experienced Apple‚Äôs older interfaces, with their exceptional quality and functionality.&lt;/p&gt;
    &lt;p&gt;That was little more than a decade ago, in 2014. Not that I want to turn the clock back, but it would be really helpful if I could read clearly what‚Äôs on my display once again.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46409969</guid><pubDate>Sun, 28 Dec 2025 10:12:08 +0000</pubDate></item><item><title>Learn computer graphics from scratch and for free</title><link>https://www.scratchapixel.com</link><description>&lt;doc fingerprint="94021bf895f5cbe4"&gt;
  &lt;main&gt;
    &lt;p&gt;These lessons are structured to introduce 3D rendering concepts in a beginner-friendly order. Unlike most resources, we start with hands-on results before diving into theory.&lt;/p&gt;
    &lt;p&gt;This section is dedicated to explaining the mathematical theories and tools used in creating images and simulations with a computer. It's not intended as a starting point, but rather as a reference to be consulted when these topics are mentioned in lessons from other sections.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46410210</guid><pubDate>Sun, 28 Dec 2025 11:08:22 +0000</pubDate></item><item><title>Building a macOS app to know when my Mac is thermal throttling</title><link>https://stanislas.blog/2025/12/macos-thermal-throttling-app/</link><description>&lt;doc fingerprint="25dc742d3b2ac9ec"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Building a macOS app to know when my Mac is thermal throttling&lt;/head&gt;
    &lt;head class="block cursor-pointer bg-neutral-100 py-1 ps-5 text-lg font-semibold text-neutral-800 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden"&gt;Table of Contents&lt;/head&gt;
    &lt;p&gt;This is the story about how I built MacThrottle.&lt;/p&gt;
    &lt;p&gt;I‚Äôve been very happy with my M2 MacBook Air for the past few years. However, when using an external display, especially a very demanding one like a 4K 120Hz display, I‚Äôve noticed it started struggling more. Since it lacks fans, you can‚Äôt hear it struggling, but you can feel it as everything becomes very slow or unresponsive: that‚Äôs when thermal throttling kicks in.&lt;/p&gt;
    &lt;p&gt;I know it‚Äôs thermal throttling because I can see in iStat Menus that my CPU usage is 100% while the power usage in watts goes down.&lt;/p&gt;
    &lt;p&gt;It‚Äôs even more obvious with MX Power Gadget: You can see the power usage and frequency of the performance core dropping, as usage keeps being 100%:&lt;/p&gt;
    &lt;p&gt;I‚Äôve also hit thermal throttling with my work MacBook Pro. It‚Äôs the 14" M4 Max variant, which is the worst variant because the thermal envelope of the 14" is too small for the max output for the M4 Max. On my previous 14" M1 Pro MacBook Pro, I‚Äôve never even heard the fans in 3 years‚Ä¶&lt;/p&gt;
    &lt;p&gt;That being said, I still love Apple Silicon for the performance and power usage, it‚Äôs still a dramatic improvement over the Intel days. ü´∂&lt;/p&gt;
    &lt;p&gt;Anyway, I wanted to know: is there a way to tell if the Apple Silicon SoC is thermal throttling, that is not based on heuristics like in my screenshot?&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting the thermal state programmatically #&lt;/head&gt;
    &lt;p&gt;This was a wilder ride than I expected. It‚Äôs possible to know programmatically if the Mac is throttled, because macOS exposes this in various but inconsistent ways.&lt;/p&gt;
    &lt;p&gt;The approach that Apple recommends is to use &lt;code&gt;ProcessInfo.thermalState&lt;/code&gt; from &lt;code&gt;Foundation&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;‚ûú  ~ swift -e 'import Foundation; print(["nominal", "fair", "serious", "critical"][ProcessInfo.processInfo.thermalState.rawValue])'
nominal
&lt;/code&gt;
    &lt;p&gt;Sounds good, right? However, I knew that another tool could provide this information, though it needed root: &lt;code&gt;powermetrics&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;‚ûú  ~ sudo powermetrics -s thermal

Password:
Machine model: Mac14,2
OS version: 25B78
Boot arguments:
Boot time: Sun Nov 23 10:19:29 2025



*** Sampled system activity (Wed Dec 17 09:48:34 2025 +0100) (5001.07ms elapsed) ***



**** Thermal pressure ****

Current pressure level: Nominal


*** Sampled system activity (Wed Dec 17 09:48:39 2025 +0100) (5001.25ms elapsed) ***



**** Thermal pressure ****

Current pressure level: Nominal
&lt;/code&gt;
    &lt;p&gt;(yes the output has that many newlines)&lt;/p&gt;
    &lt;p&gt;Both report the pressure level to be ‚Äúnominal‚Äù, they must be the same‚Ä¶right?&lt;/p&gt;
    &lt;p&gt;After running a few stress tests &lt;code&gt;stress-ng --cpu 0 -t 600&lt;/code&gt;, I started to see the two values diverge!&lt;/p&gt;
    &lt;p&gt;For some reason, the granularity is different between &lt;code&gt;ProcessInfo.thermalState&lt;/code&gt; and &lt;code&gt;powermetrics&lt;/code&gt;. They have a different amount of possible states and they don‚Äôt line up.&lt;/p&gt;
    &lt;p&gt;Here is my empirical experience:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;
          &lt;code&gt;ProcessInfo.thermalState&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;code&gt;powermetrics&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;nominal&lt;/cell&gt;
        &lt;cell&gt;nominal&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;fair&lt;/cell&gt;
        &lt;cell&gt;moderate&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;fair&lt;/cell&gt;
        &lt;cell&gt;heavy&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;I never managed to hit these states, so I don‚Äôt know if they match, but they‚Äôre technically defined:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;
          &lt;code&gt;ProcessInfo.thermalState&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;code&gt;powermetrics&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;serious&lt;/cell&gt;
        &lt;cell&gt;trapping&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;critical&lt;/cell&gt;
        &lt;cell&gt;sleeping&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;In practice, when my Mac starts getting hot, from the &lt;code&gt;powermetrics&lt;/code&gt; perspective it goes into &lt;code&gt;moderate&lt;/code&gt;, and when it starts throttling, it goes into &lt;code&gt;heavy&lt;/code&gt;. The problem is that with &lt;code&gt;ProcessInfo&lt;/code&gt;, both are covered by the &lt;code&gt;fair&lt;/code&gt; state, so it‚Äôs not really useful to know when the Mac is actually throttling. ‚òπÔ∏è&lt;/p&gt;
    &lt;p&gt;I thought maybe this was an iOS vs macOS thing? But Apple references it in the macOS docs as well. Maybe it was more consistent on Intel Macs?&lt;/p&gt;
    &lt;p&gt;I stumbled upon this article from Dave MacLachlan, a Googler working on Apple stuff, from 2020. I learned that there are other CLI tools to get thermal data, but they don‚Äôt seem to work on my Apple Silicon MacBook:&lt;/p&gt;
    &lt;code&gt;‚ûú sudo thermal levels
Thermal levels are unsupported on this machine.
&lt;/code&gt;
    &lt;code&gt;‚ûú sudo pmset -g thermlog
Note: No thermal warning level has been recorded
Note: No performance warning level has been recorded
Note: No CPU power status has been recorded
^C
&lt;/code&gt;
    &lt;p&gt;But the most interesting thing I learned is that the data &lt;code&gt;powermetrics&lt;/code&gt; shows is actually coming from &lt;code&gt;thermald&lt;/code&gt;. And &lt;code&gt;thermald&lt;/code&gt; writes the current thermal pressure to the Darwin notification system (&lt;code&gt;notifyd&lt;/code&gt;)!&lt;/p&gt;
    &lt;code&gt;‚ûú notifyutil -g com.apple.system.thermalpressurelevel

com.apple.system.thermalpressurelevel 0
&lt;/code&gt;
    &lt;p&gt;The various levels are defined in &lt;code&gt;OSThermalNotification.h&lt;/code&gt; according to the article. Indeed:&lt;/p&gt;
    &lt;code&gt;‚ûú  ~ xcrun --sdk macosx --show-sdk-path
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX26.2.sdk
‚ûú  ~ SDK="$(xcrun --sdk macosx --show-sdk-path)"
‚ûú  ~ find "$SDK/usr/include" -name 'OSThermalNotification.h'
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX26.2.sdk/usr/include/libkern/OSThermalNotification.h
&lt;/code&gt;
    &lt;code&gt;‚ûú  ~ head -n 52 "/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX26.2.sdk/usr/include/libkern/OSThermalNotification.h"
/*
 * Copyright (c) 2007 Apple Inc. All rights reserved.
 *
 * @APPLE_LICENSE_HEADER_START@
 *
 * This file contains Original Code and/or Modifications of Original Code
 * as defined in and that are subject to the Apple Public Source License
 * Version 2.0 (the 'License'). You may not use this file except in
 * compliance with the License. Please obtain a copy of the License at
 * http://www.opensource.apple.com/apsl/ and read it before using this
 * file.
 *
 * The Original Code and all software distributed under the License are
 * distributed on an 'AS IS' basis, WITHOUT WARRANTY OF ANY KIND, EITHER
 * EXPRESS OR IMPLIED, AND APPLE HEREBY DISCLAIMS ALL SUCH WARRANTIES,
 * INCLUDING WITHOUT LIMITATION, ANY WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE, QUIET ENJOYMENT OR NON-INFRINGEMENT.
 * Please see the License for the specific language governing rights and
 * limitations under the License.
 *
 * @APPLE_LICENSE_HEADER_END@
 */

#ifndef _OSTHERMALNOTIFICATION_H_
#define _OSTHERMALNOTIFICATION_H_

#include &amp;lt;_bounds.h&amp;gt;
#include &amp;lt;sys/cdefs.h&amp;gt;
#include &amp;lt;Availability.h&amp;gt;
#include &amp;lt;TargetConditionals.h&amp;gt;

_LIBC_SINGLE_BY_DEFAULT()

/*
**  OSThermalNotification.h
**
**  Notification mechanism to alert registered tasks when device thermal conditions
**  reach certain thresholds. Notifications are triggered in both directions
**  so clients can manage their memory usage more and less aggressively.
**
*/

__BEGIN_DECLS

/* Define pressure levels usable by OSThermalPressureLevel */
typedef enum {
#if TARGET_OS_OSX || TARGET_OS_MACCATALYST
        kOSThermalPressureLevelNominal = 0,
        kOSThermalPressureLevelModerate,
        kOSThermalPressureLevelHeavy,
        kOSThermalPressureLevelTrapping,
        kOSThermalPressureLevelSleeping
&lt;/code&gt;
    &lt;p&gt;The funny thing is that &lt;code&gt;OSThermalNotification.h&lt;/code&gt; is barely referenced anywhere, there are only three pages of Google results. It seems to be used in Bazel for example. That post was a big help.&lt;/p&gt;
    &lt;p&gt;What‚Äôs great about this approach is that it doesn‚Äôt require root! I can subscribe to the notification system for the &lt;code&gt;com.apple.system.thermalpressurelevel&lt;/code&gt; event to get the (good) thermal state!&lt;/p&gt;
    &lt;p&gt;Here is a snippet to get it in Swift:&lt;/p&gt;
    &lt;code&gt;import Foundation

@_silgen_name("notify_register_check")
private func notify_register_check(
  _ name: UnsafePointer&amp;lt;CChar&amp;gt;, _ token: UnsafeMutablePointer&amp;lt;Int32&amp;gt;
) -&amp;gt; UInt32
@_silgen_name("notify_get_state")
private func notify_get_state(_ token: Int32, _ state: UnsafeMutablePointer&amp;lt;UInt64&amp;gt;) -&amp;gt; UInt32
@_silgen_name("notify_cancel")
private func notify_cancel(_ token: Int32) -&amp;gt; UInt32

let notifyOK: UInt32 = 0
let name = "com.apple.system.thermalpressurelevel"

var token: Int32 = 0
let reg = name.withCString { notify_register_check($0, &amp;amp;token) }
guard reg == notifyOK else { fatalError("notify_register_check failed: \(reg)") }
defer { _ = notify_cancel(token) }

var state: UInt64 = 0
let got = notify_get_state(token, &amp;amp;state)
guard got == notifyOK else { fatalError("notify_get_state failed: \(got)") }

let label =
  switch state {
  case 0: "nominal"
  case 1: "moderate"
  case 2: "heavy"
  case 3: "trapping"
  case 4: "sleeping"
  default: "unknown(\(state))"
  }

print("\(state) \(label)")
&lt;/code&gt;
    &lt;p&gt;Prints:&lt;/p&gt;
    &lt;code&gt;‚ûú  ~ swift thermal.swift
0 nominal
&lt;/code&gt;
    &lt;p&gt;Now that I had a useful value to work with, it was time to build the app.&lt;/p&gt;
    &lt;head rend="h2"&gt;Building MacThrottle #&lt;/head&gt;
    &lt;p&gt;Armed with Opus 4.5, I set out to build a little menu bar app where I could see, at a glance, if my Apple Silicon die was trying to save itself from crossing 110¬∞C. I called it MacThrottle.&lt;/p&gt;
    &lt;p&gt;I built a simple SwiftUI app for the menu bar that shows me the status in a superbly original thermometer icon. The thermometer is filled depending on the thermal state, and its color changes from green to red. I have like 20 menu bar icons and they‚Äôre all monochromatic, so the color in the thermometer is very subtle to keep things consistent.&lt;/p&gt;
    &lt;p&gt;The app is a simple SwiftUI app. Apple provides a scene called MenuBarExtra to render a menu bar control. It was simpler than I expected! To make it a pure menu bar app with no dock icon, you just need to set &lt;code&gt;LSUIElement&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt; in &lt;code&gt;Info.plist&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;First approach: root helper for &lt;code&gt;powermetrics&lt;/code&gt; #&lt;/head&gt;
    &lt;p&gt;I explained the various approaches to get the thermal pressure level in the previous section. But when I was building the app, I discovered later on that &lt;code&gt;thermald&lt;/code&gt; was publishing the thermal state to &lt;code&gt;notifyd&lt;/code&gt;. So at first, I thought I had to use &lt;code&gt;powermetrics&lt;/code&gt; to get useful thermal state changes. Since that unfortunately requires root access, the app needed root access too.&lt;/p&gt;
    &lt;p&gt;To reduce the scope of what runs as root, I did not run the app itself as root. Instead, the app does not work by default, but it gives you the option to install a helper. It does this through an AppleScript &lt;code&gt;with administrator privileges&lt;/code&gt; to prompt for access.&lt;/p&gt;
    &lt;p&gt;The helper is just a bash script run as a launchd daemon:&lt;/p&gt;
    &lt;code&gt;‚ûú  ~ cat /Library/LaunchDaemons/com.macthrottle.thermal-monitor.plist
&amp;lt;?xml version="1.0" encoding="UTF-8"?&amp;gt;
&amp;lt;!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"&amp;gt;
&amp;lt;plist version="1.0"&amp;gt;
&amp;lt;dict&amp;gt;
    &amp;lt;key&amp;gt;Label&amp;lt;/key&amp;gt;
    &amp;lt;string&amp;gt;com.macthrottle.thermal-monitor&amp;lt;/string&amp;gt;
    &amp;lt;key&amp;gt;ProgramArguments&amp;lt;/key&amp;gt;
    &amp;lt;array&amp;gt;
        &amp;lt;string&amp;gt;/usr/local/bin/mac-throttle-thermal-monitor&amp;lt;/string&amp;gt;
    &amp;lt;/array&amp;gt;
    &amp;lt;key&amp;gt;RunAtLoad&amp;lt;/key&amp;gt;
    &amp;lt;true/&amp;gt;
    &amp;lt;key&amp;gt;KeepAlive&amp;lt;/key&amp;gt;
    &amp;lt;true/&amp;gt;
&amp;lt;/dict&amp;gt;
&amp;lt;/plist&amp;gt;
&lt;/code&gt;
    &lt;code&gt;‚ûú  ~ cat /usr/local/bin/mac-throttle-thermal-monitor
#!/bin/bash
OUTPUT_FILE="/tmp/mac-throttle-thermal-state"

while true; do
    THERMAL_OUTPUT=$(powermetrics -s thermal -n 1 -i 1 2&amp;gt;/dev/null | grep -i "Current pressure level")

    if echo "$THERMAL_OUTPUT" | grep -qi "sleeping"; then
        PRESSURE="sleeping"
    elif echo "$THERMAL_OUTPUT" | grep -qi "trapping"; then
        PRESSURE="trapping"
    elif echo "$THERMAL_OUTPUT" | grep -qi "heavy"; then
        PRESSURE="heavy"
    elif echo "$THERMAL_OUTPUT" | grep -qi "moderate"; then
        PRESSURE="moderate"
    elif echo "$THERMAL_OUTPUT" | grep -qi "nominal"; then
        PRESSURE="nominal"
    else
        PRESSURE="unknown"
    fi

    echo "{\"pressure\":\"$PRESSURE\",\"timestamp\":$(date +%s)}" &amp;gt; "$OUTPUT_FILE"
    chmod 644 "$OUTPUT_FILE"
    sleep 10
done
&lt;/code&gt;
    &lt;p&gt;The bash script writes the thermal state to a file every few seconds and the app reads it every few seconds!&lt;/p&gt;
    &lt;head rend="h3"&gt;Using the &lt;code&gt;thermald&lt;/code&gt; IPC notifications #&lt;/head&gt;
    &lt;p&gt;Once I discovered I could use the notification system without elevated privileges, I replaced the helper by code in the app to read the value from the notification system directly. Much simpler üéâ&lt;/p&gt;
    &lt;head rend="h3"&gt;Temperature and fans #&lt;/head&gt;
    &lt;p&gt;I wanted to show the temperature and fan speed (when supported) in a little graph in the menu bar app. This would allow me to correlate the thermal state with increased temperature, for example.&lt;/p&gt;
    &lt;p&gt;Again, there are multiple APIs to read the temperature. First, I started using an undocumented API from IOKit, but I realised I was getting ~80¬∫C max, while iStat Menus or MX Power Gadget would show &amp;gt;100¬∫C.&lt;/p&gt;
    &lt;p&gt;Stats, the open source alternative to iStat Menus, helped me use the SMC instead and get the correct values. But the SMC is a much more unstable API because each SoC has different keys to access the temperature data:&lt;/p&gt;
    &lt;code&gt;private let m1Keys = ["Tp01", "Tp05", "Tp09", "Tp0D", "Tp0H", "Tp0L", "Tp0P", "Tp0X", "Tp0b"]
private let m2Keys = ["Tp01", "Tp05", "Tp09", "Tp0D", "Tp0X", "Tp0b", "Tp0f", "Tp0j"]
private let m3Keys = ["Tf04", "Tf09", "Tf0A", "Tf0B", "Tf0D", "Tf0E", "Tf44", "Tf49", "Tf4A", "Tf4B"]
&lt;/code&gt;
    &lt;p&gt;Though the M3 keys seem to work on my M4 Max work MacBook Pro‚Ä¶&lt;/p&gt;
    &lt;p&gt;I ended up using SMC first to get the accurate temperature and fall back to IOKit if SMC doesn‚Äôt work.&lt;/p&gt;
    &lt;head rend="h3"&gt;Graph in the menu bar #&lt;/head&gt;
    &lt;p&gt;For the graph, I wanted a compact visualization that would show me the thermal history at a glance.&lt;/p&gt;
    &lt;p&gt;The graph packs three layers of information:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Colored background segments for each thermal state (green for nominal, yellow for moderate, orange for heavy, red for critical)&lt;/item&gt;
      &lt;item&gt;A solid line for CPU temperature with a dynamic Y-axis that adjusts to actual values&lt;/item&gt;
      &lt;item&gt;A dashed cyan line for fan speed percentage (on Macs that have fans)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I didn‚Äôt want to spend too much time making a super fancy graph system. Since it polls every two seconds, the graph gets very busy after a while. So I decided to keep it down to 10 minutes, since the thermal state history is mostly interesting short-term.&lt;/p&gt;
    &lt;p&gt;I also added hover tooltips using &lt;code&gt;onContinuousHover&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;When the system was under load, I noticed the graph hovering was not very smooth on my 120Hz display. I found out I can add &lt;code&gt;.drawingGroup&lt;/code&gt; to my SwiftUI canvas to use GPU rendering!. Indeed, I added it, and it was smooth again.&lt;/p&gt;
    &lt;head rend="h3"&gt;Adding macOS notifications #&lt;/head&gt;
    &lt;p&gt;I also added notifications so I get alerted when the state changes, in case I miss the menu bar icon. It can alert on specific state transitions, and optionally on recovery. This is useful to know when it‚Äôs time to kill a VS Code instance or a Docker container!&lt;/p&gt;
    &lt;p&gt;It‚Äôs true that I usually already notice when the Mac is getting slow, but sometimes the Mac gets slow when it‚Äôs swapping heavily. At least now I know when it‚Äôs just too hot.&lt;/p&gt;
    &lt;head rend="h3"&gt;Launching the app at Login #&lt;/head&gt;
    &lt;p&gt;Of course, I want the app to start automatically now, since it works so well!&lt;/p&gt;
    &lt;p&gt;I expected that I would need to write &lt;code&gt;.plist&lt;/code&gt; again, but no, it‚Äôs extremely easy to prompt the user to add a ‚Äúlogin item‚Äù as macOS calls it, using &lt;code&gt;SMAppService&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;SMAppService.mainApp.register()    // enable auto-start
SMAppService.mainApp.unregister()  // disable auto-start
SMAppService.mainApp.status == .enabled  // check current state
&lt;/code&gt;
    &lt;head rend="h2"&gt;How to use it #&lt;/head&gt;
    &lt;p&gt;Since I don‚Äôt have an Apple Developer account, I can‚Äôt notarize the app, so installing it from the releases is going to require a few extra clicks in &lt;code&gt;Privacy and Security&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;And for Macs that disallow it entirely, building from source with Xcode is the only way. I added instructions in the README.&lt;/p&gt;
    &lt;p&gt;Hope this is useful to someone else!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46410402</guid><pubDate>Sun, 28 Dec 2025 11:51:42 +0000</pubDate></item><item><title>Langfuse (YC W23) Is Hiring in Berlin, Germany</title><link>https://langfuse.com/careers</link><description>&lt;doc fingerprint="a8cdb519cd720a6d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Building Langfuse&lt;/head&gt;
    &lt;p&gt;Join the team building the leading open-source LLM engineering platform&lt;/p&gt;
    &lt;p&gt;View Open Positions ‚Üí&lt;/p&gt;
    &lt;p&gt;While LLMs improve a lot, we don‚Äôt see enough applications in production. Building these applications requires a new workflow of continuous monitoring and evaluation that we enable with Langfuse (learn more about our mission).&lt;/p&gt;
    &lt;p&gt;We are seeing strong traction (see metrics below), thus it is the right time to grow the team to build out our backend systems, product, and how we communicate with developers.&lt;/p&gt;
    &lt;p&gt;We are backed by Lightspeed, General Catalyst, Y Combinator, and angels. We are growing fast (see metrics below) and work with some of the best AI teams such as Samsara, Twilio, Khan Academy, and Rocket Money.&lt;/p&gt;
    &lt;p&gt;If complex technical problems &amp;amp; great developer experiences excite you, we‚Äôd love to hear from you.&lt;/p&gt;
    &lt;p&gt;‚Äì Marc, Clemens, Max and the Langfuse team&lt;/p&gt;
    &lt;head rend="h2"&gt;Team&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Marc Klingen, @marcklingen, GitHub, Linkedin&lt;/item&gt;
      &lt;item&gt;Max Deichmann, @maxdeichmann, GitHub, Linkedin&lt;/item&gt;
      &lt;item&gt;Clemens Rawert, @rawert, GitHub, Linkedin&lt;/item&gt;
      &lt;item&gt;Marlies Mayerhofer, @marliessophie, GitHub, LinkedIn&lt;/item&gt;
      &lt;item&gt;Hassieb Pakzad, @hassiebpakzad, GitHub, LinkedIn&lt;/item&gt;
      &lt;item&gt;Steffen Schmitz, GitHub, LinkedIn&lt;/item&gt;
      &lt;item&gt;Jannik Maierh√∂fer, @jmaierhoefer, GitHub, LinkedIn&lt;/item&gt;
      &lt;item&gt;Felix Krauth, @felixkrrr, GitHub, LinkedIn&lt;/item&gt;
      &lt;item&gt;Akio Nuernberger, @AkioNuernberger, LinkedIn&lt;/item&gt;
      &lt;item&gt;Nimar Blume, @nimarblu, GitHub, LinkedIn&lt;/item&gt;
      &lt;item&gt;Michael Froehlich, GitHub, LinkedIn&lt;/item&gt;
      &lt;item&gt;Valeriy Meleshkin, GitHub, LinkedIn&lt;/item&gt;
      &lt;item&gt;Lotte Verheyden, GitHub, LinkedIn&lt;/item&gt;
      &lt;item&gt;Leonard Wolters, GitHub, LinkedIn&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Curious to build with us?&lt;/head&gt;
    &lt;p&gt;If you are excited about delivering exceptional open-source developer experiences alongside an insanely motivated team that ships, reach out!&lt;/p&gt;
    &lt;head rend="h2"&gt;Read our Handbook&lt;/head&gt;
    &lt;p&gt;We publicly document our core principles and processes at Langfuse to align as a team, maintain transparency with our community, and help you determine if you‚Äôd enjoy working here.&lt;/p&gt;
    &lt;head rend="h3"&gt;Main Chapters&lt;/head&gt;
    &lt;head rend="h3"&gt;More Links&lt;/head&gt;
    &lt;p&gt;The handbook contains many more resources that define how we do things. These might be interesting to you:&lt;/p&gt;
    &lt;head rend="h2"&gt;Open Source&lt;/head&gt;
    &lt;p&gt;Almost everything we do is public. Get a glimpse of our work here:&lt;/p&gt;
    &lt;head rend="h2"&gt;Videos/Podcasts&lt;/head&gt;
    &lt;p&gt;If you prefer watching videos or listening to podcasts to get an impression, here are some suggestions:&lt;/p&gt;
    &lt;head rend="h2"&gt;Public Metrics&lt;/head&gt;
    &lt;p&gt;Langfuse is the most widely adopted LLM Engineering platform with 19,719 GitHub stars, 23.1M+ SDK installs per month, and 6M+ Docker pulls. Trusted by 19 of the Fortune 50 and 63 of the Fortune 500 companies.&lt;/p&gt;
    &lt;head rend="h2"&gt;Work with us&lt;/head&gt;
    &lt;head rend="h3"&gt;Curious to build with us?&lt;/head&gt;
    &lt;p&gt;If you are excited about delivering exceptional open-source developer experiences alongside an insanely motivated team that ships, reach out!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46410449</guid><pubDate>Sun, 28 Dec 2025 12:00:06 +0000</pubDate></item><item><title>Designing Predictable LLM-Verifier Systems for Formal Method Guarantee</title><link>https://arxiv.org/abs/2512.02080</link><description>&lt;doc fingerprint="e89c2c0b05c79c88"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Artificial Intelligence&lt;/head&gt;&lt;p&gt; [Submitted on 30 Nov 2025 (v1), last revised 16 Dec 2025 (this version, v2)]&lt;/p&gt;&lt;head rend="h1"&gt;Title:The 4/$Œ¥$ Bound: Designing Predictable LLM-Verifier Systems for Formal Method Guarantee&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:The integration of Formal Verification tools with Large Language Models (LLMs) offers a path to scale software verification beyond manual workflows. However, current methods remain unreliable: without a solid theoretical footing, the refinement process acts as a black box that may oscillate, loop, or diverge. This work bridges this critical gap by developing an LLM-Verifier Convergence Theorem, providing the first formal framework with provable guarantees for termination in multi-stage verification pipelines. We model the interaction not as a generic loop, but as a sequential absorbing Markov Chain comprising four essential engineering stages: \texttt{CodeGen}, \texttt{Compilation}, \texttt{InvariantSynth}, and \texttt{SMTSolving}. We prove that for any non-zero stage success probability ($\delta &amp;gt; 0$), the system reaches the \texttt{Verified} state almost surely. Furthermore, because of the sequential nature of the pipeline, we derive a precise latency bound of $\mathbb{E}[n] \leq 4/\delta$. We stress-tested this prediction in an extensive empirical campaign comprising over 90,000 trials. The results match the theory with striking consistency: every run reached verification, and the empirical convergence factor clustered tightly around $C_f\approx 1.0$, confirming that the $4/\delta$ bound accurately mirrors system behavior rather than serving as a loose buffer. Based on this data, we identify three distinct operating zones -- marginal, practical, and high-performance -- and propose a dynamic calibration strategy to handle parameter drift in real-world environments. Together, these contributions replace heuristic guesswork with a rigorous architectural foundation, enabling predictable resource planning and performance budgeting for safety-critical software.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Pierre Dantas [view email]&lt;p&gt;[v1] Sun, 30 Nov 2025 22:19:09 UTC (459 KB)&lt;/p&gt;&lt;p&gt;[v2] Tue, 16 Dec 2025 22:28:30 UTC (491 KB)&lt;/p&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;cs.AI&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46411539</guid><pubDate>Sun, 28 Dec 2025 15:02:07 +0000</pubDate></item><item><title>Global Memory Shortage Crisis: Market Analysis</title><link>https://www.idc.com/resource-center/blog/global-memory-shortage-crisis-market-analysis-and-the-potential-impact-on-the-smartphone-and-pc-markets-in-2026/</link><description>&lt;doc fingerprint="bb723c998ebaa7c8"&gt;
  &lt;main&gt;
    &lt;p&gt;In late 2025, the global semiconductor ecosystem is experiencing an unprecedented memory chip shortage with knock-on effects for the device manufacturers and end users that could persist well into 2027. DRAM prices have surged significantly as demand from AI data centers continues to outstrip supply, creating a supply/demand imbalance.&lt;/p&gt;
    &lt;p&gt;IDC was monitoring the memory situation as we prepared our November device forecasts, and we factored them into the update. The situation, however, has become more acute since publishing, and we feel it‚Äôs important we address the situation. Although we are maintaining our official forecasts as the situation is still evolving, we will offer here two downside risk scenarios that may play out in two critical markets: Smartphones and Personal Computers.&lt;/p&gt;
    &lt;p&gt;What‚Äôs causing the shortage? The memory market is at an unprecedented inflexion point, with demand materially outpacing supply. For an industry that has long been characterized by boom-and-bust cycles, this time is different. The rapid expansion of AI infrastructure and workloads is exerting significant pressure on the memory ecosystem. These AI workloads require large amounts of memory, and the shortage, in part, is driven by a reallocation of manufacturing capacity away from consumer electronics toward high-margin memory solutions to support AI. Instead of expanding conventional DRAM and NAND used in smartphones, PCs, and other consumer electronics, major memory makers have shifted production toward memory used in AI data centers, such as high-bandwidth (HBM) and high-capacity DDR5. This has restricted the supply of general-purpose memory modules and driven up prices across the board.&lt;/p&gt;
    &lt;p&gt;AI servers and enterprise environments require far more memory per system than consumer devices, so the AI build-out is pulling a disproportionate share of global capacity and creating shortages, as suppliers prioritize orders from hyperscalers and OEMs building AI servers. That dynamic has left less DRAM available for consumer devices, exacerbating price pressure in a tight market.&lt;/p&gt;
    &lt;p&gt;However, this is not just a cyclical shortage driven by a mismatch in supply and demand, but a potentially permanent, strategic reallocation of the world‚Äôs silicon wafer capacity. For decades, the production of DRAM and NAND Flash for smartphones and PCs was the primary driver for production. Today, that dynamic has inverted. The voracious demand for HBM by hyperscalers, such as Microsoft, Google, Meta and Amazon, has forced the three biggest memory manufacturers (Samsung Electronics, SK Hynix, and Micron Technology) to pivot their limited cleanroom space and capital expenditure towards higher margin enterprise-grade components. This is a zero-sum game: every wafer allocated to an HBM stack for an Nvidia GPU is a wafer denied to the LPDDR5X module of a mid-range smartphone or the SSD of a consumer laptop.&lt;/p&gt;
    &lt;p&gt;As a result, IDC expects 2026 DRAM and NAND supply growth be below historical norms at 16% year-on-year and 17% year-on-year, respectively.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Crisis in the Devices Market&lt;/head&gt;
    &lt;p&gt;The result of this supply/demand imbalance is twofold: DRAM and NAND/SSD prices have risen sharply in recent months, and the availability of these components is limited, forcing device manufacturers to navigate a fluid situation.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Potential Smartphone Market Impact&lt;/head&gt;
    &lt;p&gt;The global smartphone market, particularly Android manufacturers, is facing a threat in 2026. The industry‚Äôs decade-long trend of democratizing specs by bringing flagship features to affordable smartphones is reversing.&lt;/p&gt;
    &lt;p&gt;The cost structure of a smartphone is heavily dependent on the memory used. For a mid-range device, memory can represent 15-20% of the total bill of materials (BOM), while for a high-end flagship device, it is around 10-15%. As memory prices continue to surge, OEMs will likely have to raise prices significantly, cut specifications or both.&lt;/p&gt;
    &lt;head rend="h3"&gt;Different Vendors, Different Impacts&lt;/head&gt;
    &lt;p&gt;The impact of the shortage is highly asymmetric, creating winners and losers on supply chain resilience and vertical integration.&lt;/p&gt;
    &lt;p&gt;Manufacturers, whose business is mainly in the low end of the market, are likely to suffer significantly. The business models of vendors such as TCL, Transsion, Realme, Xiaomi, Lenovo, Oppo, Vivo, Honor or Huawei are based on thin margins. This increase in cost will hit their margins substantially, and they will have no other option but to pass the cost (or part) to end users.&lt;/p&gt;
    &lt;p&gt;In the high end of the market, Apple and Samsung face pressure but are structurally hedged. Its cash reserves and long-term supply agreements allow it to secure memory supply 12-24 months in advance. On the other hand, new flagship models in 2026 will likely have no RAM upgrades, sticking to 12GB for Pro models rather than increasing to 16GB. It is also unlikely that current models will see the same price erosion seen after the introduction of the latest model.&lt;/p&gt;
    &lt;p&gt;The cumulative effect of these pressures is a potential contraction in the global smartphone market alongside an increase in average selling prices (ASP). In 2026, in our moderate downside scenario, we could see the market contract by 2.9%. In our pessimistic downside scenario, it could be as bad as 5.2%. The severity of each scenario depends on how long this situation lasts.&lt;/p&gt;
    &lt;p&gt;At the same time, smartphone ASPs could rise by 3% to 5% in the moderate scenario, or by 6% to 8% in the pessimistic scenario. These price rises will be significantly higher in the low end of the market, where margins are extremely tight, and OEMs will have to pass the cost to end users.&lt;/p&gt;
    &lt;p&gt;But regardless of the severity of the scenario, longer replacement cycles are likely to occur in markets with rising costs causing lower purchasing power. By contrast, in more mature markets, consumers are likely to rely on financing and instalment plans to absorb higher prices.&lt;/p&gt;
    &lt;p&gt;While there could be significant downside risk to volumes in 2026, we expect 4Q25 to outperform our earlier projections as vendors stocked channels ahead of price increases.&lt;/p&gt;
    &lt;head rend="h3"&gt;Impact to the PC Market&lt;/head&gt;
    &lt;p&gt;If the smartphone market is facing pressure, the PC market is bracing for disruption. The timing of the memory shortage creates a perfect storm for the PC industry, colliding with the Microsoft Windows 10 end-of-life refresh cycle and the AI PC marketing push.&lt;/p&gt;
    &lt;p&gt;PC vendors are signalling broad price increases as cost pressures intensify into H2 2026. Lenovo, Dell, HP, Acer and ASUS have warned clients of tougher conditions ahead, confirming 15-20% hikes and contract resets as an industry-wide response.&lt;/p&gt;
    &lt;p&gt;PC vendors with larger shipment volumes should be better positioned to navigate current supply constraints, enabling them to capture market share from smaller and regional brands. Regardless of how much the total market size may be impacted, we expect vendor market shares to shift in favor of the largest vendors armed with inventory and greater leverage with suppliers.&lt;/p&gt;
    &lt;p&gt;White box as well as lower tier (often local) vendors, on the other hand, will bear the greatest burden of the shortage, and that would include DIY systems, oftentimes built by gamers. That in turn represents an opportunity for large OEMs to gain share from smaller assemblers in the gaming space by positioning pre-built systems as offering higher value.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Impact on AI PC&lt;/head&gt;
    &lt;p&gt;The shortage threatens to derail the industry‚Äôs growth narrative around AI PC. IDC defines the AI PC as any PC with an NPU. Crucially, these devices tend to have more RAM (Microsoft‚Äôs Copilot+ PCs require a minimum of 16GB). As more small language models and large language models move on device, memory becomes even more important, with many higher-end systems shifting toward 32GB or higher. Just as the industry is seeing a need to add more RAM, it has become prohibitively expensive to do so, even if they can get supply. This will result in higher prices, lower margins, or a potential downmix in the amount of RAM in new systems at the worst possible time for this to occur.&lt;/p&gt;
    &lt;p&gt;As with smartphones, IDC is not changing its official PC forecast. Here again, we offer two potential scenarios for 2026.&lt;/p&gt;
    &lt;p&gt;In the more moderate downside scenario, we could see the PC market contract by 4.9% compared with a 2.4% year-on-year decline in the November forecast. Under a more pessimistic scenario, the decline could deepen to 8.9%. The severity of each scenario will largely depend on how long the current supply constraints persist through 2026.&lt;/p&gt;
    &lt;p&gt;Under these downside scenarios, PC average selling prices would likely rise, increasing by 4% to 6% in a moderate scenario, and by 6% to 8% in a pessimistic scenario.&lt;/p&gt;
    &lt;p&gt;As with smartphones, channels are building inventory in advance to mitigate the impact of further price increases in the months ahead, which is expected to support stronger-than-expected forecast performance in Q4 2025, relative to the November outlook.&lt;/p&gt;
    &lt;head rend="h3"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;What began as an AI infrastructure boom has now rippled outward, with tightening memory supply, inflating prices, and reshaping product and pricing strategies across both consumer and enterprise devices. As the industry adjusts to this new reality, the smartphone and PC markets are bracing for a period of higher costs, altered product roadmaps, and slower volume growth. The severity and duration of the shortage will be determined by how quickly production capacity can expand and how effectively demand rebalances across segments.&lt;/p&gt;
    &lt;p&gt;For consumers and enterprises alike, this signals the end of an era of cheap, abundant memory and storage, at least in the medium term. The year 2026 is shaping up to be one in which technology becomes more expensive, driven by supply constraints rather than demand growth.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46411902</guid><pubDate>Sun, 28 Dec 2025 15:51:08 +0000</pubDate></item><item><title>tc-ematch(8) extended matches for use with "basic", "cgroup" or "flow" filters</title><link>https://man7.org/linux/man-pages/man8/tc-ematch.8.html</link><description>&lt;doc fingerprint="a601e349e52939e4"&gt;
  &lt;main&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;NAME | SYNOPSIS | MATCHES | CAVEATS | EXAMPLE &amp;amp; USAGE | AUTHOR | COLOPHON&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;code&gt;
ematch(8)                         Linux                         ematch(8)
&lt;/code&gt;
    &lt;quote&gt;ematch - extended matches for use with "basic", "cgroup" or "flow" filters&lt;/quote&gt;
    &lt;quote&gt;tc filter add .. basic match EXPR .. flowid .. EXPR := TERM [ { and | or } EXPR ] TERM := [ not ] { MATCH | '(' EXPR ')' } MATCH := module '(' ARGS ')' ARGS := ARG1 ARG2 ..&lt;/quote&gt;
    &lt;quote&gt;cmp Simple comparison ematch: arithmetic compare of packet data to a given value. cmp( ALIGN at OFFSET [ ATTRS ] { eq | lt | gt } VALUE ) ALIGN := { u8 | u16 | u32 } ATTRS := [ layer LAYER ] [ mask MASK ] [ trans ] LAYER := { link | network | transport | 0..2 } meta Metadata ematch meta( OBJECT { eq | lt |gt } OBJECT ) OBJECT := { META_ID | VALUE } META_ID := id [ shift SHIFT ] [ mask MASK ] meta attributes: random 32 bit random value loadavg_1 Load average in last 5 minutes nf_mark Netfilter mark vlan Vlan tag sk_rcvbuf Receive buffer size sk_snd_queue Send queue length A full list of meta attributes can be obtained via # tc filter add dev eth1 basic match 'meta(list)' nbyte match packet data byte sequence nbyte( NEEDLE at OFFSET [ layer LAYER ] ) NEEDLE := { string | c-escape-sequence } OFFSET := int LAYER := { link | network | transport | 0..2 } u32 u32 ematch u32( ALIGN VALUE MASK at [ nexthdr+ ] OFFSET ) ALIGN := { u8 | u16 | u32 } ipset test packet against ipset membership ipset( SETNAME FLAGS ) SETNAME := string FLAGS := { FLAG [, FLAGS] } The flag options are the same as those used by the iptables "set" match. When using the ipset ematch with the "ip_set_hash:net,iface" set type, the interface can be queried using "src,dst (source ip address, outgoing interface) or "src,src" (source ip address, incoming interface) syntax. ipt test packet against xtables matches ipt( [-6] -m MATCH_NAME FLAGS ) MATCH_NAME := string FLAGS := { FLAG [, FLAGS] } The flag options are the same as those used by the xtable match used. canid ematch rule to match CAN frames canid( IDLIST ) IDLIST := IDSPEC[IDLIST] IDSPEC := { √¢sff√¢ CANID | √¢eff√¢ CANID } CANID := ID[:MASK] ID, MASK := hexadecimal number (i.e. 0x123)&lt;/quote&gt;
    &lt;quote&gt;The ematch syntax uses '(' and ')' to group expressions. All braces need to be escaped properly to prevent shell commandline from interpreting these directly. When using the ipset ematch with the "ifb" device, the outgoing device will be the ifb device itself, e.g. "ifb0". The original interface (i.e. the device the packet arrived on) is treated as the incoming interface.&lt;/quote&gt;
    &lt;quote&gt;# tc filter add .. basic match ... # 'cmp(u16 at 3 layer 2 mask 0xff00 gt 20)' # 'meta(nfmark gt 24)' and 'meta(tcindex mask 0xf0 eq 0xf0)' # 'nbyte("ababa" at 12 layer 1)' # 'u32(u16 0x1122 0xffff at nexthdr+4)' Check if packet source ip address is member of set named bulk: # 'ipset(bulk src)' Check if packet source ip and the interface the packet arrived on is member of "hash:net,iface" set named interactive: # 'ipset(interactive src,src)' Check if packet matches an IPSec state with reqid 1: # 'ipt(-m policy --dir in --pol ipsec --reqid 1)'&lt;/quote&gt;
    &lt;quote&gt;The extended match infrastructure was added by Thomas Graf.&lt;/quote&gt;
    &lt;code&gt;
       This page is part of the iproute2 (utilities for controlling
       TCP/IP networking and traffic) project.  Information about the
       project can be found at 
       √¢¬®http://www.linuxfoundation.org/collaborate/workgroups/networking/iproute2√¢¬©.
       If you have a bug report for this manual page, send it to
       netdev@vger.kernel.org, shemminger@osdl.org.  This page was
       obtained from the project's upstream Git repository
       √¢¬®https://git.kernel.org/pub/scm/network/iproute2/iproute2.git√¢¬© on
       2025-08-11.  (At that time, the date of the most recent commit
       that was found in the repository was 2025-08-08.)  If you discover
       any rendering problems in this HTML version of the page, or you
       believe there is a better or more up-to-date source for the page,
       or you have corrections or improvements to the information in this
       COLOPHON (which is not part of the original manual page), send a
       mail to man-pages@man7.org

iproute2                      6 August 2012                     ematch(8)
&lt;/code&gt;
    &lt;p&gt;Pages that refer to this page: tc(8), tc-basic(8), tc-bpf(8), tc-cgroup(8), tc-flow(8)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46412327</guid><pubDate>Sun, 28 Dec 2025 16:43:14 +0000</pubDate></item><item><title>Show HN: Pion SCTP with RACK is 70% faster with 30% less latency</title><link>https://pion.ly/blog/sctp-and-rack/</link><description>&lt;doc fingerprint="21e41095e1799bd5"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;What is SCTP?&lt;/head&gt;
    &lt;p&gt;SCTP stands for Stream Control Transmission Protocol. At a basic level, SCTP is designed to be reliable, handle de-duplication of packets, and support packets that may be delivered in order or out of order. Beyond transporting messages, SCTP can also set up a connection between users. On a deeper level, SCTP includes native support for multiplexing: multiple applications can take advantage of a single transport connection. SCTP also supports multi-homing, which enables automatic failover from a primary connection to a secondary one.&lt;/p&gt;
    &lt;p&gt;At the most basic level, it lets you reliably send information from one computer to another without any complications.&lt;/p&gt;
    &lt;head rend="h3"&gt;What is SCTP used for?&lt;/head&gt;
    &lt;p&gt;SCTP‚Äôs uses can generally fit into two cases:&lt;/p&gt;
    &lt;head rend="h4"&gt;1. Sending some amount of data.&lt;/head&gt;
    &lt;p&gt;Imagine a scenario where two people are texting when one person remembers a picture that they want to send. As they text back and forth, an image gets uploaded, which takes some time to get sent. SCTP can handle multiple things going on at the same time and doesn‚Äôt delay any messages from being sent just because an image is being uploaded! Thanks to SCTP, text messages can be safely delivered to each person and nothing in their conversation is lost in transit or delayed just because something else is being transferred at the same time as their messages.&lt;/p&gt;
    &lt;p&gt;Building on this idea, users can share larger files with each other. This includes anything: birthday videos, audio recordings, even boring paperwork; anything that‚Äôs a file can be sent!&lt;/p&gt;
    &lt;head rend="h4"&gt;2. Sending small amounts of data with a purpose.&lt;/head&gt;
    &lt;p&gt;In a new scenario, imagine two people who are texting back and forth when one person gets hungry. They send a message saying, ‚ÄúI want a pizza!‚Äù When the other person receives the text, they think, ‚ÄúMaybe I should do something about that!‚Äù The recipient can choose to do something useful for the sender with that information.&lt;/p&gt;
    &lt;p&gt;This is the blueprint for many awesome technologies today, as it opens up the possibility of controlling one computer from a different computer. Consider a surgeon who performs an operation involving a remote-controlled device that needs to respond with as little latency as possible. Similarly, real-time navigation systems also need to respond to changes in traffic conditions quickly in order to avoid congested or unsafe areas due to accidents or weather conditions.&lt;/p&gt;
    &lt;head rend="h4"&gt;Other uses:&lt;/head&gt;
    &lt;p&gt;SCTP can be used for online multiplayer games where every frame counts, including first-person shooters and fighting games. Taking the remote surgery example in this direction leads to the idea of cloud gaming, as players can have their inputs sent to a different device than the one that they‚Äôre using while still being able to play the game!&lt;/p&gt;
    &lt;p&gt;SCTP is also used inside web browsers via WebRTC and has found use in AI applications and cryptocurrency-related technologies. Additionally, payment verification can similarly benefit from secure and fast communication.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why SCTP for WebRTC?&lt;/head&gt;
    &lt;p&gt;SCTP is used for WebRTC because of its ability to send information via reliable and unreliable datachannels. For example, you can send messages or files in a chat with SCTP. Other uses include being able to know when users toggle their microphone or video in a video call. In some special cases, SCTP can even be used to transmit video between users, but that‚Äôs significantly less common.&lt;/p&gt;
    &lt;p&gt;In WebRTC, the ICE protocol connects users and the DTLS protocol establishes a secure connection, at which point SCTP is then used to securely transfer data. In an ideal setup, data that‚Äôs sent should ‚Äújust work‚Äù. Unfortunately, that isn‚Äôt how things tend to pan out, as issues eventually crop up. Packets get dropped, the network jitters, the computer stutters, or the coffee machine doesn‚Äôt start when you thought it had. That‚Äôs why it‚Äôs important to have a backup plan for when things go wrong.&lt;/p&gt;
    &lt;head rend="h2"&gt;How SCTP Deals With Loss&lt;/head&gt;
    &lt;p&gt;SCTP was designed with this in mind and has two built-in recovery strategies for when networking goes wrong.&lt;/p&gt;
    &lt;p&gt;The first is called ‚Äúfast retransmission.‚Äù The receiver detects if a chunk of data is missing in the transmission. If so, the receiver notifies the sender that a specific chunk ID is missing. If the sender receives three reports of a missing chunk where all three reports are referring to the same chunk ID, then the sender will assume that the chunk has been lost and resend it.&lt;/p&gt;
    &lt;p&gt;The second is a timer-based retransmission. This happens if the receiver doesn‚Äôt acknowledge that it has received all the packets within a specific window of time. If the receiver doesn‚Äôt acknowledge that all the packets have been received, then the sender is prompted to retransmit the unacknowledged data.&lt;/p&gt;
    &lt;p&gt;Both of these loss recovery strategies are used by SCTP to try to ensure that any lost data is detected and retransmitted as quickly as possible. At the time of writing, Pion‚Äôs implementation of Pion‚Äôs implementation of SCTP uses these two mechanisms for loss recovery.&lt;/p&gt;
    &lt;p&gt;These strategies are also used by TCP, which has prompted engineers to see if there‚Äôs an even better strategy to detect and mitigate lost data.&lt;/p&gt;
    &lt;head rend="h2"&gt;Introducing RACK&lt;/head&gt;
    &lt;p&gt;In February 2021, RFC 8985: The RACK-TLP Loss Detection Algorithm for TCP was published. This was a completely new loss detection algorithm that focused on actively keeping track of network statistics and using timer-based signals in order to remain adaptive to ever-changing network conditions. RACK‚Äôs improvements over SACK and fast retransmission in TCP were enticing enough for Linux, Windows, and FreeBSD to all implement it in TCP.&lt;/p&gt;
    &lt;p&gt;While RACK was originally intended to be implemented for TCP, it is noted in the RFC that it can be implemented in other transport protocols, including SCTP.&lt;/p&gt;
    &lt;p&gt;The implementation for SCTP was formally analyzed in Felix Weinrank‚Äôs Dissertation and other publications. Weinrank‚Äôs deep dive provides an extremely comprehensive review of SCTP and improvements regarding usage in various scenarios, including WebRTC. At the moment, we‚Äôre more concerned with Weinrank‚Äôs analysis and implementation notes regarding RACK in SCTP. In Chapter 7 of the dissertation, Weinrank goes over how SCTP handles loss and how RACK can be implemented for SCTP, including extra details regarding how the implementation interacts with various SCTP extensions.&lt;/p&gt;
    &lt;head rend="h2"&gt;RACK‚Äôs motivations:&lt;/head&gt;
    &lt;p&gt;The authors of RACK in RFC 8985 provides examples of situations where RACK improves SCTP and TCP during loss recovery.&lt;/p&gt;
    &lt;head rend="h3"&gt;How RACK‚Äôs Tail Loss Probing (TLP) Works&lt;/head&gt;
    &lt;quote&gt;sequenceDiagram participant S as Sender participant R as Receiver Note over S,R: The two sends are normally&amp;lt;br&amp;gt;combined but are separated&amp;lt;br&amp;gt;here for visual clarity. S-&amp;gt;&amp;gt;R: Send üçé S--&amp;gt;&amp;gt;R: Send üçå, ü•ï, ü•î Note right of R: Only üçé arrived, so it's ACK'd. R-&amp;gt;&amp;gt;S: ACK üçé Note over S,R: 2 RTTs later, TLP fires S-&amp;gt;&amp;gt;R: TLP triggers a retransmit ü•î Note right of R: ü•î arrived, so it's SACK'd. R-&amp;gt;&amp;gt;S: SACK ü•î Note left of S: Mark üçå and ü•ï as lost Note over S,R: The two sends are normally&amp;lt;br&amp;gt;combined but are separated&amp;lt;br&amp;gt;here for visual clarity. S--&amp;gt;&amp;gt;R: Retransmit üçå S-&amp;gt;&amp;gt;R: Retransmit ü•ï Note right of R: Only ü•ï arrived, so it's SACK'd&amp;lt;br&amp;gt;alongside ü•î. R--&amp;gt;&amp;gt;S: SACK ü•ï and ü•î Note left of S: üçå retransmission marked as lost.&amp;lt;br&amp;gt;Note that this is the second time&amp;lt;br/&amp;gt;that üçå has been marked as lost. S-&amp;gt;&amp;gt;R: Retransmit üçå again Note right of R: üçå finally arrived! R--&amp;gt;&amp;gt;S: ACK ü•î Note over S,R: The ACK ü•î is a cumulative ACK&amp;lt;br&amp;gt;for the üçéüçåü•ïü•î sequence&lt;/quote&gt;
    &lt;p&gt;In the above scenario, Tail Loss Probing enables the sender to quickly know if üçéüçåü•ïü•î were successfully received. Since the sender only receives an acknowledgment (ACK) for üçé from the receiver, the TLP timer eventually triggers because it didn‚Äôt receive an ACK for üçå, ü•ï, and ü•î. The TLP can then resend the last packet in the segment as an efficient way to:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Retransmit data that the receiver would have to receive down the line anyway. The alternative would be to send an empty packet, receive an ACK, then send a missing packet. This handles both at once and can potentially save an RTT if only the last packet is missing in a segment.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Allow the receiver to ACK any earlier missing packets in the sequence if there were other issues due to networking, temporary stutters or freezes, etc.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Check receiver responsiveness and detect if there‚Äôs a network issue. Note that this is different from (2), as the receiver could potentially never respond with an ACK.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The receiver then confirms that it has ü•î by sending a selective acknowledgment (SACK) to the sender, which tells the sender that it‚Äôs received one of the packets from the segment but not all of them. At this point, the sender has an ACK for üçé and a SACK for ü•î, which means that it can determine that üçå and ü•ï must be missing. The sender then notes that üçå and ü•ï have been lost once. It then retransmits üçå and ü•ï. In the example, üçå happens to get dropped by the network whereas ü•ï is sent and received successfully. The receiver then replies with a SACK for ü•ï and ü•î, at which point the sender can determine that üçå was lost a second time. Finally, the sender retransmits üçå, which fortunately doesn‚Äôt get dropped, and the receiver sends an ACK for ü•î (note the ACK is for the last packet in the segment, which implies that all previous packets have been received).&lt;/p&gt;
    &lt;p&gt;Side note: keeping track of the number of times that a packet has been lost is important as the cubic congestion control algorithm described in RFC 9438 (which is mentioned in RFC 8985) relies on this information.&lt;/p&gt;
    &lt;head rend="h3"&gt;SCTP RTO vs RACK RTO&lt;/head&gt;
    &lt;p&gt;In this example, the authors of RFC 8985 show how, without RACK, SCTP and TCP can suffer from spurious retransmissions when there are retransmission timeouts (RTOs). In this case, each food icon represents an entire segment instead of a packet.&lt;/p&gt;
    &lt;quote&gt;sequenceDiagram participant S as Sender participant R as Receiver S-&amp;gt;&amp;gt;R: Send ü•ê Note over S,R: Then right before&amp;lt;br&amp;gt;the end of the RTO... Note right of R: The receiver has a network hiccup! S-&amp;gt;&amp;gt;R: Send üç≥ü•≠ Note right of R: Received ü•ê Note over S,R: End of the RTO R-&amp;gt;&amp;gt;S: ACK ü•ê&lt;/quote&gt;
    &lt;p&gt;In this scenario, ü•ê is sent, and right before the end of the RTO, üç≥ and ü•≠ are sent. The receiver gets ü•ê, üç≥, and ü•≠, but only manages to send an ACK for ü•ê right after the RTO. Let‚Äôs see how SCTP handles this without RACK versus with RACK.&lt;/p&gt;
    &lt;quote&gt;sequenceDiagram participant S as Sender participant R as Receiver S-&amp;gt;&amp;gt;R: Send ü•ê Note over S,R: Then right before&amp;lt;br&amp;gt;the end of the RTO... Note right of R: The receiver has a network hiccup! S-&amp;gt;&amp;gt;R: Send üç≥ü•≠ Note right of R: Received ü•ê Note over S,R: End of the RTO R-&amp;gt;&amp;gt;S: ACK ü•ê Note over S,R: Without RACK... %% without rack Note left of S: Mark ü•êüç≥ü•≠ as lost&amp;lt;br&amp;gt;since RTO expired Note right of R: Received üç≥ü•≠ Note over S,R: The Sender incorrectly&amp;lt;br&amp;gt;ignores the ack for üç≥ü•≠! Note left of S: Prepare to retransmit ü•êüç≥ü•≠ S-&amp;gt;&amp;gt;R: Retransmit ü•êüç≥ü•≠&lt;/quote&gt;
    &lt;p&gt;We can see here that the receiver eventually sends an ACK for üç≥ and ü•≠, but the sender ignores it and believes that ü•ê, üç≥, and ü•≠ are all missing instead of just ü•ê. While it‚Äôs reasonable to assume that ü•ê is missing, it‚Äôs a little overzealous in retransmitting packets, which can increase network traffic during recovery, especially when it‚Äôs completely possible for the sender to wait for the acknowledgments of üç≥ and ü•≠ from the receiver.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs see what RACK does!&lt;/p&gt;
    &lt;quote&gt;sequenceDiagram participant S as Sender participant R as Receiver S-&amp;gt;&amp;gt;R: Send ü•ê Note over S,R: Then right before&amp;lt;br&amp;gt;the end of the RTO... Note right of R: The receiver has a network hiccup! S-&amp;gt;&amp;gt;R: Send üç≥ü•≠ Note right of R: Received ü•ê Note over S,R: End of the RTO R-&amp;gt;&amp;gt;S: ACK ü•ê Note over S,R: With RACK... %% with rack Note left of S: Mark ü•ê as lost&amp;lt;br&amp;gt;since RTO expired Note right of R: Received üç≥ü•≠ Note left of S: Prepare to retransmit ü•ê S-&amp;gt;&amp;gt;R: Retransmit ü•ê&lt;/quote&gt;
    &lt;p&gt;Here, RACK makes it so only ü•ê is marked as lost when the RTO expires. üç≥ and ü•≠ aren‚Äôt marked as lost because their own RTOs have not yet expired by the time their ACKs are received. Therefore, only ü•ê is retransmitted, as the timers for üç≥ and ü•≠ would be re-armed if an ACK is received for the retransmitted ü•ê.&lt;/p&gt;
    &lt;p&gt;In this example, even though both non-RACK and RACK end up retransmitting ü•ê despite the receiver already having it, the focus is on minimizing spurious retransmissions. This can save on the amount of data sent over the network, which naturally speeds up any retransmissions that might occur.&lt;/p&gt;
    &lt;head rend="h3"&gt;RACK‚Äôs strategy&lt;/head&gt;
    &lt;p&gt;In summary, RACK‚Äôs strategy generally has two main parts:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Detect packet losses as quickly as possible by utilizing time-based acknowledgments of segmented data and inferences from network statistics.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Use Tail Loss Probing (TLP), which sends sample data to gather more network statistics.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The combination of these two strategies allows it to quickly determine issues and properly rectify them once identified. It also provides better resilience for some tricky edge cases! If you‚Äôre interested in seeing how RACK could perform in SCTP and other SCTP-specific improvements, check out chapter 7 of Felix Weinrank‚Äôs thesis.&lt;/p&gt;
    &lt;head rend="h2"&gt;A quick look at the results (why this matters if you don‚Äôt live in SCTP land)&lt;/head&gt;
    &lt;p&gt;SCP is a Go test harness that runs two Pion SCTP stacks against each other inside a deterministic, in-process ‚Äúvirtual network‚Äù (from Pion/transport). It pins exact commits on each side, replays scenarios with a fixed seed, validates packet on the wire (CRC32c + basic SCTP parsing), and writes artifacts (&lt;code&gt;results.json&lt;/code&gt;, packet logs, and pprof) so you can reproduce the numbers.&lt;/p&gt;
    &lt;head rend="h3"&gt;The headline (max-burst): more throughput, less CPU, lower latency&lt;/head&gt;
    &lt;p&gt;This is the cleanest microbench in the suite: no loss, no delay, no jitter. Just a burst of messages in both directions. Comparing non-rack&amp;lt;-&amp;gt;non-rack vs rack&amp;lt;-&amp;gt;rack (There are similar improvements even when comparing rack&amp;lt;-&amp;gt;non-rack):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;metric&lt;/cell&gt;
        &lt;cell role="head"&gt;main (baseline)&lt;/cell&gt;
        &lt;cell role="head"&gt;RACK&lt;/cell&gt;
        &lt;cell role="head"&gt;delta&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;goodput&lt;/cell&gt;
        &lt;cell&gt;234.55 Mbps&lt;/cell&gt;
        &lt;cell&gt;316.42 Mbps&lt;/cell&gt;
        &lt;cell&gt;+34.9%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;CPU time (&lt;code&gt;cpu_seconds&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;0.0560 s&lt;/cell&gt;
        &lt;cell&gt;0.0441 s&lt;/cell&gt;
        &lt;cell&gt;‚àí21.3%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;goodput / CPU-second&lt;/cell&gt;
        &lt;cell&gt;4,189&lt;/cell&gt;
        &lt;cell&gt;7,177&lt;/cell&gt;
        &lt;cell&gt;+71.3%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;latency p50&lt;/cell&gt;
        &lt;cell&gt;16.37 ms&lt;/cell&gt;
        &lt;cell&gt;11.86 ms&lt;/cell&gt;
        &lt;cell&gt;‚àí27.5%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;latency p99&lt;/cell&gt;
        &lt;cell&gt;36.95 ms&lt;/cell&gt;
        &lt;cell&gt;27.84 ms&lt;/cell&gt;
        &lt;cell&gt;‚àí24.6%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;That +71% throughput-per-CPU is simply the goodput measured (Mbps) divided by the run‚Äôs &lt;code&gt;cpu_seconds&lt;/code&gt;. Non-rack cruised at ~234 Mbps using ~0.056 CPU seconds (~4,189 Mbps/CPU-s), while RACK sustained 316 Mbps with ~0.044 CPU seconds (~7,177 Mbps/CPU-s). That gap is the proof that rack delivers ~71% more work per unit of CPU.&lt;/p&gt;
    &lt;head rend="h3"&gt;Test setup&lt;/head&gt;
    &lt;p&gt;To test RACK, we ran these test profiles to compare how RACK performs against main (baseline):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;max-burst - ‚Äúhow fast can we go‚Äù with no delay, loss, or reordering; it targets the raw transport path:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Goodput jumps +34.9% (234 -&amp;gt;316 Mbps) while CPU seconds drop by 21% (0.056 -&amp;gt;0.044 s) and p50/p99 both fall by ~25%. RACK now delivers ~71% more Mbps per CPU-second.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;handshake - same burst pattern, this time including the COOKIE/SHUTDOWN handshake, so we exercise setup timers:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Goodput climbs +15% (237 -&amp;gt;272 Mbps) while latency stays basically flat (15.65 -&amp;gt;15.99 ms for p50, 35.27 -&amp;gt;33.25 ms for p99), which confirms that the faster throughput comes without slower ACK paths.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;unordered-late-low-rtt - minor delay/jitter (10 ms) but unordered delivery to simulate packet trains with mild disorder:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Minor latency and throughput noise. Both branches still pass but RACK keeps the delivery steady despite small unordered bursts.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;unordered-late-high-rtt - large RTT/jitter (180 ms / 60 ms) with unordered delivery, so we can watch how the stack copes with latency spikes:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Very high latency due to the profile, but RACK keeps throughput comparable while completely avoiding any regressions.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;unordered-late-dynamic-rtt - fluctuating RTT (40 ms base ¬±180 ms jitter) with unordered delivery to mimic burst-y network dynamics:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Both branches pass with no noticeable regressions from RACK, which shows that each branch handles jitter swings fine.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;congestion - ordered delivery with 2% loss and modest delay/jitter to stress-tests congestion control and SACK-driven recovery:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The loss-handling path stays green and RACK doesn‚Äôt use extra CPU compared to master which shows the +35% clean-case gain doesn‚Äôt cost the loss profile.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;retransmission - ordered with 5% loss and 20 ms jitter to force fast-retransmit/TLP scenario:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The fault case still hits retries and RACK‚Äôs CPU profile actually shows more JSON/packet-logging work but that‚Äôs what we expect during retransmit storms.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;reorder-low - unordered with 1.5% loss plus deliberate reordering to exercise scheduler/queue behavior under lossÔºãreorder:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Goodput improves +44% (1.79 Mbps -&amp;gt; 2.58 Mbps) and the run finishes faster (~3.70 s vs 5.34 s), so RACK dominates the low-rate reordering scenario.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;burst-loss - unordered with 4% loss and 50 ms jitter to push retransmit/recovery under heavy loss bursts.&lt;/item&gt;
      &lt;item&gt;fragmentation - oversized payloads require chunk fragmentation/reassembly to verify large-message handling:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Nothing improved or got worse.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;media-hevc - A real-world use case with video: one-way stream, paced HEVC frames (~25 fps), 3% loss, ~1200-byte max payload, across a ~13-14 Mbps link (taken from a real-world use case of sending DRM media over WebRTC datachannels) to ensure sustained media delivery works.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;RACK hits 12.90 Mbps goodput in 2.14 s (100% delivery) while the main branch streaming to the RACK branch sits at 11.34 Mbps in 4.66 s. That‚Äôs a 2x faster finish!&lt;/p&gt;
    &lt;p&gt;We also have 3 negative tests to ensure that any corruptions or errors are still being caught:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;fault-checksum - corrupts every 7th DATA chunk‚Äôs checksum so receivers must drop it and log the error.&lt;/item&gt;
      &lt;item&gt;fault-bad-chunk-len - mangles the chunk length field every 7th chunk to validate length checks/parsing.&lt;/item&gt;
      &lt;item&gt;fault-nonzero-padding - corrupts padding bytes every 7th chunk so padding validation and chunk isolation logic are exercised.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In both branches, these cases fail (as desired), which confirms that both branches detect the corruption and that there is no regression in behavior.&lt;/p&gt;
    &lt;head rend="h3"&gt;CPU flamegraphs&lt;/head&gt;
    &lt;p&gt;The flamegraphs below show the CPU profiles for max-burst runs. You can see in the metadata that the RACK profile captured 20ms of samples (9.95% of 201.08ms duration) versus the master profile‚Äôs 40ms of samples (19.86% of 201.45ms duration) ‚Äì exactly half the sample count for a similar duration, which directly supports the efficiency claims.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why RACK behaves better (not just ‚Äúgoes faster‚Äù)&lt;/head&gt;
    &lt;p&gt;RACK changes how SCTP decides that something is lost and when it sends probes, so it wastes less work fixing problems that never really happened:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Instead of keying almost everything off ‚Äúthree missing reports or an RTO fired‚Äù, RACK uses time-based loss detection: it looks at when chunks were last SACKed/ACKed and infers loss from elapsed time and the pattern of tail acknowledgments.&lt;/item&gt;
      &lt;item&gt;Tail Loss Probes (TLP) send a cheap ‚Äúsample‚Äù chunk at the end of a burst to flush out late ACKs. If the receiver really did get the data, it answers and the sender avoids a full retransmission storm, otherwise, the probe doubles as the retransmission you needed anyway.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In practical terms that‚Äôs what the profiles and metrics are showing:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We still see the same hot stack (&lt;code&gt;vnet.(*chunkUDP).UserData&lt;/code&gt;,&lt;code&gt;runtime.memmove&lt;/code&gt;, a thin layer of runtime/type helpers) in both master and RACK. It‚Äôs the normal packet I/O path.&lt;/item&gt;
      &lt;item&gt;With RACK, that stack is exercised fewer times per unit of useful data because there are fewer spurious retransmits and fewer ‚Äújust in case‚Äù timer expirations.&lt;/item&gt;
      &lt;item&gt;That‚Äôs exactly how we get more goodput, lower latency, and smaller CPU profiles at the same time: RACK spends less CPU ‚Äúarguing with the network‚Äù and more CPU pushing real user data through SCTP.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Spec-aligned ACK behavior and testing&lt;/head&gt;
    &lt;p&gt;Using SCP testing tool we were able to find some issues includes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;In the initial RACK implementation, handling of transitions from high to low RTT was suboptimal due to the implementation using a global minimum for recent RTT measurements instead of a windowed minimum (the latter approach is only a ‚ÄúSHOULD‚Äù in RFC 8985 section 6.2.1). Atsushi Watanabe quickly identified it and we resolved the issue.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The earlier version of RACK implementation also handled packet reordering poorly and consumed more CPU than non-RACK. This was corrected by implementing improved active RTT measurement, following the approach described in Weinrank‚Äôs work, see p. 120.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;A minor bug was discovered (and fixed) in the initial RACK implementation where the latest RTT was not measured for every packet.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;We also found that Pion SCTP did not send a SACK immediately after a TSN gap, causing RACK to perform worse under moderate reordering. After fixing this behavior to align with RFC 4960 section 6.7 (surprisingly only a ‚ÄúSHOULD‚Äù), reordering test cases showed a ~30% improvement.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Looking forward&lt;/head&gt;
    &lt;p&gt;Keep an eye out for even more improvements and benchmarks from our improved SCTP implementation using real-world data, as well as how we‚Äôre doing it in an upcoming blog post!&lt;/p&gt;
    &lt;p&gt;Thanks for reading!&lt;/p&gt;
    &lt;head rend="h2"&gt;Credits&lt;/head&gt;
    &lt;p&gt;Huge thanks to the following for making this possible:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Joe Turki for introducing me to Pion, making SCP, answering countless questions, and so much more.&lt;/item&gt;
      &lt;item&gt;Sean DuBois for making Pion, finding Felix Weinrank‚Äôs thesis, and endless encouragement.&lt;/item&gt;
      &lt;item&gt;Srayan Jana for helping to bounce around many ideas.&lt;/item&gt;
      &lt;item&gt;Atsushi Watanabe for reviewing and catching the global minimum vs windowed minimum issue in the RACK PR.&lt;/item&gt;
      &lt;item&gt;And many more people along the way!&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46413053</guid><pubDate>Sun, 28 Dec 2025 18:05:13 +0000</pubDate></item><item><title>Remembering Lou Gerstner</title><link>https://newsroom.ibm.com/2025-12-28-Remembering-Lou-Gerstner</link><description>&lt;doc fingerprint="3f8dd935902cb38d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;All press releases&lt;/head&gt;
    &lt;head rend="h1"&gt;Remembering Lou Gerstner&lt;/head&gt;
    &lt;p&gt;The following is the text of an email sent today to all IBM employees by Chairman and CEO Arvind Krishna:&lt;/p&gt;
    &lt;p&gt;IBMers,&lt;/p&gt;
    &lt;p&gt;I am saddened to share that Lou Gerstner, IBM‚Äôs Chairman and CEO from 1993 to 2002, passed away yesterday.&lt;/p&gt;
    &lt;p&gt;Lou arrived at IBM at a moment when the company‚Äôs future was genuinely uncertain. The industry was changing rapidly, our business was under pressure, and there was serious debate about whether IBM should even remain whole. His leadership during that period reshaped the company. Not by looking backward, but by focusing relentlessly on what our clients would need next.&lt;/p&gt;
    &lt;p&gt;One of Lou‚Äôs earliest signals as CEO has become part of IBM lore. Early on, he stopped a long internal presentation and said, simply, ‚ÄúLet‚Äôs just talk.‚Äù The message was clear: less inward focus, more real discussion, and much closer attention to customers. That mindset would define his tenure.&lt;/p&gt;
    &lt;p&gt;Lou believed one of IBM‚Äôs central problems was that we had become optimized around our own processes, debates, and structures rather than around client outcomes. As he later put it, the company had lost sight of a basic truth of business: understanding the customer and delivering what the customer actually values.&lt;/p&gt;
    &lt;p&gt;That insight drove real change. Meetings became more direct. Decisions were grounded more in facts and client impact than in hierarchy or tradition. Innovation mattered if it could translate into something clients would come to rely on. Execution in the quarter and the year mattered, but always in service of longer-term relevance.&lt;/p&gt;
    &lt;p&gt;Lou made what may have been the most consequential decision in IBM‚Äôs modern history: to keep IBM together. At the time, the company was organized into many separate businesses, each pursuing its own path. Lou understood that clients didn‚Äôt want fragmented technology‚Äîthey wanted integrated solutions. That conviction shaped IBM‚Äôs evolution and reestablished our relevance for many of the world‚Äôs largest enterprises.&lt;/p&gt;
    &lt;p&gt;Lou also understood that strategy alone would not be enough. He believed lasting change required a shift in culture‚Äîin how people behave when no one is watching. What mattered was what IBMers valued, how honestly they confronted reality, and how willing they were to challenge themselves and each other. Rather than discard IBM‚Äôs long-standing values, he pushed the company to renew them to meet the demands of a very different era.&lt;/p&gt;
    &lt;p&gt;I have my own memory of Lou from the mid-1990s, at a small town hall with a few hundred people. What stood out was his intensity and focus. He had an ability to hold the short term and the long term in his head at the same time. He pushed hard on delivery, but he was equally focused on innovation: doing work that clients would remember, not just consume.&lt;/p&gt;
    &lt;p&gt;Lou stayed engaged with IBM long after his tenure ended. From my first days as CEO, he was generous with advice‚Äîbut always careful in how he gave it. He would offer perspective, then say, ‚ÄúI‚Äôve been gone a long time‚ÄîI‚Äôm here if you need me.‚Äù He listened closely to what others were saying about IBM and reflected it back candidly.&lt;/p&gt;
    &lt;p&gt;That neutral, experienced voice mattered to me, and I was fortunate to learn from Lou on a regular basis.&lt;/p&gt;
    &lt;p&gt;Lou was direct. He expected preparation. He challenged assumptions. But he was deeply committed to building a company that could adapt‚Äîculturally as much as strategically‚Äîwithout losing its core values.&lt;/p&gt;
    &lt;p&gt;Lou‚Äôs impact extended well beyond IBM. Before joining the company, he had already built an extraordinary career‚Äîbecoming one of the youngest partners at McKinsey &amp;amp; Company, later serving as president of American Express and CEO of RJR Nabisco. After IBM, he went on to chair The Carlyle Group and devoted significant time and resources to philanthropy, particularly in education and biomedical research. A native of Long Island, NY, Lou earned his undergraduate degree from Dartmouth and an MBA from Harvard, and he remained deeply devoted to his family throughout his life. Lou was preceded in death by his son Louis Gerstner III.&lt;/p&gt;
    &lt;p&gt;We will hold a celebration in the new year to reflect on Lou‚Äôs legacy and what his leadership enabled at IBM.&lt;/p&gt;
    &lt;p&gt;My thoughts are with Lou‚Äôs wife Robin, his daughter Elizabeth, his grandchildren and extended family, as well as his many friends, colleagues, and people around the world who were shaped by his leadership and his work.&lt;lb/&gt; Media contact:&lt;lb/&gt; IBM Press Room&lt;lb/&gt; ibmpress@us.ibm.com &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46413365</guid><pubDate>Sun, 28 Dec 2025 18:43:54 +0000</pubDate></item><item><title>PySDR: A Guide to SDR and DSP Using Python</title><link>https://pysdr.org/content/intro.html</link><description>&lt;doc fingerprint="7c6211f0c4f3e3a0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;1. Introduction¬∂&lt;/head&gt;
    &lt;head rend="h2"&gt;Purpose and Target Audience¬∂&lt;/head&gt;
    &lt;p&gt;First and foremost, a couple important terms:&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Software-Defined Radio (SDR):&lt;/item&gt;
      &lt;item rend="dd-1"&gt;
        &lt;p&gt;As a concept it refers to using software to perform signal processing tasks that were traditionally performed by hardware, specific to radio/RF applications. This software can be run on a general-purpose computer (CPU), FPGA, or even GPU, and it can be used for real-time applications or offline processing of recorded signals. Analogous terms include ‚Äúsoftware radio‚Äù and ‚ÄúRF digital signal processing‚Äù.&lt;/p&gt;
        &lt;p&gt;As a thing (e.g., ‚Äúan SDR‚Äù) it typically refers to a device that you can plug an antenna into and receive RF signals, with the digitized RF samples being sent to a computer for processing or recording (e.g., over USB, Ethernet, PCI). Many SDRs also have transmit capabilities, allowing the computer to send samples to the SDR which then transmits the signal at a specified RF frequency. Some embedded-style SDRs include an onboard computer.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-2"&gt;Digital Signal Processing (DSP):&lt;/item&gt;
      &lt;item rend="dd-2"&gt;The digital processing of signals; in our case, RF signals.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This textbook acts as a hands-on introduction to the areas of DSP, SDR, and wireless communications. It is designed for someone who is:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Interested in using SDRs to do cool stuff&lt;/item&gt;
      &lt;item&gt;Good with Python&lt;/item&gt;
      &lt;item&gt;Relatively new to DSP, wireless communications, and SDR&lt;/item&gt;
      &lt;item&gt;A visual learner, preferring animations over equations&lt;/item&gt;
      &lt;item&gt;Better at understanding equations after learning the concepts&lt;/item&gt;
      &lt;item&gt;Looking for concise explanations, not a 1,000 page textbook&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;An example is a Computer Science student interested in a job involving wireless communications after graduation, although it can be used by anyone itching to learn about SDR who has programming experience. As such, it covers the necessary theory to understand DSP techniques without the intense math that is usually included in DSP courses. Instead of burying ourselves in equations, an abundance of images and animations are used to help convey the concepts, such as the Fourier series complex plane animation below. I believe that equations are best understood after learning the concepts through visuals and practical exercises. The heavy use of animations is why PySDR will never have a hard copy version being sold on Amazon.&lt;/p&gt;
    &lt;p&gt;This textbook is meant to introduce concepts quickly and smoothly, enabling the reader to perform DSP and use SDRs intelligently. It‚Äôs not meant to be a reference textbook for all DSP/SDR topics; there are plenty of great textbooks already out there, such as Analog Device‚Äôs SDR textbook and dspguide.com. You can always use Google to recall trig identities or the Shannon limit. Think of this textbook like a gateway into the world of DSP and SDR: it‚Äôs lighter and less of a time and monetary commitment, when compared to more traditional courses and textbooks.&lt;/p&gt;
    &lt;p&gt;To cover foundational DSP theory, an entire semester of ‚ÄúSignals and Systems‚Äù, a typical course within electrical engineering, is condensed into a few chapters. Once the DSP fundamentals are covered, we launch into SDRs, although DSP and wireless communications concepts continue to come up throughout the textbook.&lt;/p&gt;
    &lt;p&gt;Code examples are provided in Python. They utilize NumPy, which is Python‚Äôs standard library for arrays and high-level math. The examples also rely upon Matplotlib, which is a Python plotting library that provides an easy way to visualize signals, arrays, and complex numbers. Note that while Python is ‚Äúslower‚Äù than C++ in general, most math functions within Python/NumPy are implemented in C/C++ and heavily optimized. Likewise, the SDR API we use is simply a set of Python bindings for C/C++ functions/classes. Those who have little Python experience yet a solid foundation in MATLAB, Ruby, or Perl will likely be fine after familiarizing themselves with Python‚Äôs syntax.&lt;/p&gt;
    &lt;head rend="h2"&gt;Contributing¬∂&lt;/head&gt;
    &lt;p&gt;If you got value from PySDR, please share it with colleagues, students, and other lifelong learners who may be interested in the material. You can also donate through the PySDR Patreon as a way to say thanks and get your name on the left of every page below the chapter list.&lt;/p&gt;
    &lt;p&gt;If you get through any amount of this textbook and email me at marc@pysdr.org with questions/comments/suggestions, then congratulations, you will have contributed to this textbook! You can also edit the source material directly on the textbook‚Äôs GitHub page (your change will start a new pull request). Feel free to submit an issue or even a Pull Request (PR) with fixes or improvements. Those who submit valuable feedback/fixes will be permanently added to the acknowledgments section below. Not good at Git but have changes to suggest? Feel free to email me at marc@pysdr.org.&lt;/p&gt;
    &lt;head rend="h2"&gt;Acknowledgements¬∂&lt;/head&gt;
    &lt;p&gt;Thank you to anyone who has read any portion of this textbook and provided feedback, and especially to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Barry Duggan&lt;/item&gt;
      &lt;item&gt;Matthew Hannon&lt;/item&gt;
      &lt;item&gt;James Hayek&lt;/item&gt;
      &lt;item&gt;Deidre Stuffer&lt;/item&gt;
      &lt;item&gt;Tarik Benaddi for translating PySDR to French&lt;/item&gt;
      &lt;item&gt;Daniel Versluis for translating PySDR to Dutch&lt;/item&gt;
      &lt;item&gt;mrbloom for translating PySDR to Ukrainian&lt;/item&gt;
      &lt;item&gt;Yimin Zhao for translating PySDR to Simplified Chinese&lt;/item&gt;
      &lt;item&gt;Eduardo Chancay for translating PySDR to Spanish&lt;/item&gt;
      &lt;item&gt;John Marcovici&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As well as all PySDR Patreon supporters!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46413975</guid><pubDate>Sun, 28 Dec 2025 20:02:50 +0000</pubDate></item><item><title>Stepping down as Mockito maintainer after 10 years</title><link>https://github.com/mockito/mockito/issues/3777</link><description>&lt;doc fingerprint="6702905447ee068a"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Notifications &lt;tool-tip&gt;You must be signed in to change notification settings&lt;/tool-tip&gt;&lt;/item&gt;
      &lt;item&gt;Fork 2.6k&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Description&lt;/head&gt;
    &lt;p&gt;In March 2026, I will be Mockito maintainer for 10 years (nearly a third of my whole life). Looking ahead, I decided that a decade milestone is a good moment to pass on maintainership to other folks. In the coming months until March, I will spend time ensuring a smooth transition in maintainership.&lt;/p&gt;
    &lt;p&gt;In this issue I list several considerations why I made the decision. Communication and discussion of plans for future maintainership will be somewhere else, most likely in a separate GitHub issue. Stay tuned for that.&lt;/p&gt;
    &lt;head rend="h2"&gt;Energy drain because of JVM agent change&lt;/head&gt;
    &lt;p&gt;As you might know, Mockito 5 shipped a breaking change where its main artifact is now an agent. That's because starting JVM 22, the previous so-called "dynamic attachment of agents" is put behind a flag. This change makes sense from a security point-of-view and I support it.&lt;/p&gt;
    &lt;p&gt;However, the way this was put forward to Mockito maintainers was energy draining to say the least. Mockito is probably the biggest user of such an agent and is often looked at for inspiration by other projects. As such, Mockito often pioneers on supporting JVM features, built on a solid foundation with ByteBuddy. Modules was such a feature that took months of hard work by Rafael to figure out, including providing feedback to JVM maintainers.&lt;/p&gt;
    &lt;p&gt;Unfortunately such a collaborative way of working was not the case when discussing agents. To me, it felt like the feature was presented as a done deal because of security. While dynamic attachment is problematic in many ways, no alternative solutions were proposed. That's okay, as Mockito pioneers on these solutions, yet in this case I felt we were left alone.&lt;/p&gt;
    &lt;p&gt;My personal take is that folks involved with the change severely underestimated the societal impact that it had. The fact that proper build support is non-existent to this day shows that agents are not a priority. That's okay if it isn't a priority, but when it was communicated with Mockito I perceived it as "Mockito is holding the JVM ecosystem back by using dynamic attachment, please switch immediately and figure it out on your own".&lt;/p&gt;
    &lt;p&gt;Here, the fact that I (and others) are volunteers doing their best for the project, is important to understand the societal impact. When you put individuals under pressure, who do this work in their own time out of goodwill, things crumble. It's commonly joked about with XKCD's on the fact that the whole open source world relies on a couple of individuals. That couldn't be more true in this situation, where the collaborative system collapses when too much pressure is put on individual folks.&lt;/p&gt;
    &lt;p&gt;This saga planted the seed to reconsider my position as maintainer.&lt;/p&gt;
    &lt;head rend="h2"&gt;Kotlin as the future and odd one out&lt;/head&gt;
    &lt;p&gt;It's undeniable that Kotlin as a language has grown in popularity in recent years. While Mockito maintains several flavors for JVM languages, these packages typically include sugar that makes integration nicer. In all cases, mockito-core remains the place where functionality is implemented.&lt;/p&gt;
    &lt;p&gt;Unfortunately, this model doesn't nicely apply to Kotlin. Where almost all JVM languages work similarly under the hood, Kotlin often does things differently. This means that in several places in mockito-core, there are separate flows dedicated to Kotlin. Most often that's a direct result of Kotlin doing (in my opinion) shenanigans on the JVM that the JVM never intended to support, yet was able to.&lt;/p&gt;
    &lt;p&gt;Even within Kotlin itself, features don't work consistently. Suspend functions are the most well-known example. As such, Mockito code becomes more spaghetti, it's API sometimes fully duplicated just to support a core Kotlin language feature and overall less maintainable.&lt;/p&gt;
    &lt;p&gt;While I fully understand the reasons that developers enjoy the feature richness of Kotlin as a programming language, its underlying implementation has significant downsides for projects like Mockito. Quite frankly, it's not fun to deal with.&lt;/p&gt;
    &lt;p&gt;To me, a future where Kotlin becomes more predominant is not a future that makes me hopeful I can keep on dedicating energy to Mockito.&lt;/p&gt;
    &lt;head rend="h2"&gt;Alternative open source activities&lt;/head&gt;
    &lt;p&gt;I have always been a fan of open source work and have contributed to hundreds of projects in all these years. Mockito is my most important project, but I have also consistently worked on others. In recent months, I have rediscovered the joy of programming by working on Servo. It's a web engine written in Rust.&lt;/p&gt;
    &lt;p&gt;When I need to choose how I want to spend my 2 hours of evening time in a given week, I rarely preferred Mockito in the last year. In the past, Mockito was my go-to and I enjoyed it a lot. Nowadays, Servo and related projects provide significantly more enjoyment.&lt;/p&gt;
    &lt;p&gt;Justifying why I needed to work on Mockito becomes difficult when (because of the above reasons) it feels like a chore. Volunteering work shouldn't feel like a chore, at least not for a long time.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summing it up&lt;/head&gt;
    &lt;p&gt;As you have read, these three factors combined led me to the decision. The first point explains why I started to doubt my position, the second point why I am not hopeful for things to change in a good way and the third point how I found enjoyment in a different way.&lt;/p&gt;
    &lt;p&gt;While these points had impact on me as maintainer, my hypothesis is that it doesn't apply to others in the same way. I know others are eager to work on Kotlin support for example. That's why I concluded that a decade is enough time to have helped Mockito forward. Now it's time for somebody else to take over, as I believe that's in the best interest of Mockito as a project. Because ultimately that's why I chose to become maintainer in the first place: I believed that with my work, I could improve Mockito for millions of software engineers.&lt;/p&gt;
    &lt;p&gt;For those wondering: yes I wholeheartedly advise everyone to take on a volunteering task such as maintaining an open source project. It was an honour and privilege to do so and I thank those that I enjoyed working with.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46414078</guid><pubDate>Sun, 28 Dec 2025 20:14:58 +0000</pubDate></item><item><title>Show HN: Phantas ‚Äì A browser-based binaural strobe engine (Web Audio API)</title><link>https://phantas.io</link><description>&lt;doc fingerprint="c7bc1d2388b9f1ff"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Operating Protocol&lt;/head&gt;
    &lt;p&gt;STEREO AUDIO: Headphones essential. Frequencies split left/right to create the binaural beat.&lt;/p&gt;
    &lt;p&gt;OPTICAL DRIVING: Set brightness to 100%. Close eyes. Position screen to fill your entire visual field with light.&lt;/p&gt;
    &lt;p&gt;FEEDBACK LOOP: Log duration and pre/post state below to track efficiency.&lt;/p&gt;
    &lt;p&gt;STANDBY&lt;/p&gt;
    &lt;p&gt;Screen Lock&lt;/p&gt;
    &lt;head rend="h4"&gt;ALPHA (10HZ) - PASSIVE OBSERVATION&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Best For: Routine Coding, "Autopilot" Work.&lt;/item&gt;
      &lt;item&gt;How To Use: Don't force thoughts. Let your mind wander. Good for stability.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;10.0&lt;/p&gt;
    &lt;p&gt;15&lt;/p&gt;
    &lt;p&gt;30&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46414258</guid><pubDate>Sun, 28 Dec 2025 20:38:09 +0000</pubDate></item><item><title>Loss of moist broadleaf forest in Africa has turned a carbon sink into source</title><link>https://www.nature.com/articles/s41598-025-27462-3</link><description>&lt;doc fingerprint="177840d35d162283"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Abstract&lt;/head&gt;
    &lt;p&gt;Africa‚Äôs forests and woody savannas have historically acted as a carbon sink, removing atmospheric carbon and storing it as biomass. However, our novel analysis reveals a critical transition from a carbon sink to a carbon source between 2010 and 2017. Using new high-resolution satellite-derived biomass maps, validated with field plots and machine learning techniques, we quantified the aboveground biomass stocks across African biomes over a decade. Between 2007 and 2010, the continent gained 439 ¬± 66 Tg yr‚Åª1 of aboveground biomass, but from 2010 to 2015 biomass declined by ‚àí 132 ¬± 20 Tg yr-1 and from 2015 to 2017 this decline continued with a loss of ‚àí 41 ¬± 6 Tg yr-1, primarily driven by deforestation in tropical moist broadleaf forests. Gains in savanna biomass partially offset these losses, likely due to shrub encroachment. Our findings underline the urgent need for implementing policies to halt global deforestation as required by the Glasgow Leaders Declaration to close the global emissions gap. The current ongoing revisions of Nationally Determined Contributions to the Paris Agreement need to be even more ambitious to compensate for the ongoing loss of natural carbon sinks.&lt;/p&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Africa‚Äôs ecosystems play a pivotal role in the global carbon cycle, contributing approximately 20% of global carbon removals through terrestrial net primary production, 40% of the world‚Äôs carbon emissions from biomass burning and 20% of emissions from deforestation and forest degradation1. Carbon removals occur in forests and woody savannas through photosynthesis, while carbon emissions are largely driven by fire during forest cover loss, shifting cultivation, agricultural burning and fuelwood burning (~0.4 Pg C y-1 for Africa)2. Biomass burning in savannas mainly burns perennial herbaceous plant matter, which does not add significantly to net carbon emissions but is thought to accelerate the carbon cycle by reducing carbon turnover times3.&lt;/p&gt;
    &lt;p&gt;Despite their critical importance, Africa‚Äôs forests and savannas face increasing pressures from anthropogenic and natural disturbances, leading to a decline in their carbon sequestration potential. Understanding these dynamics is essential for addressing the goals of the Paris Agreement and devising effective climate mitigation strategies.&lt;/p&gt;
    &lt;p&gt;While previous studies have mapped African biomass and carbon stocks, they are limited by coarse spatial resolutions, temporal gaps, or methodological inconsistencies. Notably, the sparse availability of field-based data has hampered precise assessments of biomass changes at fine spatial scales. Recent advancements in satellite remote sensing, such as the GEDI LiDAR and ALOS PALSAR radar systems, combined with more powerful machine learning models, offer an unprecedented opportunity to bridge these knowledge gaps.&lt;/p&gt;
    &lt;p&gt;Previous studies have estimated the extent of African forests, including mosaics of forests and woodlands, as between 638.2 and 836.8 million ha4. These forests contain large carbon stocks in the form of aboveground woody biomass, in the range from 85 to 129 Pg5,6,7,8,9. African tropical forests have an average aboveground biomass density over 396 Mg ha-1, but this can be as high as 429 Mg ha-1 in some areas of the Congo Basin10. This far exceeds the carbon stock density in savannas with an average aboveground biomass density of 45 Mg ha-111, although savannas cover a much larger total area4, making forests and savannas the most relevant biomes for understanding the total carbon stocks stored in aboveground woody biomass (Fig. 1).&lt;/p&gt;
    &lt;p&gt;The quantitative nature of carbon dynamics of African ecosystems remains subject to scientific debate due to the sparse observation network1,3. Bombelli et al.3 estimated that sub-Saharan Africa is a net carbon sink of between 0.16 - 1 Pg C yr-1, depending on the data source used. Bombelli et al.3 also concluded that biogeochemical process models give an ‚Äúunrealistically large sink‚Äù between 1.3 and 3.9 Pg C yr-1 (average of 3.23 Pg C yr-1). Even the direction of the carbon fluxes in Africa is controversial. Some recent studies indicate that the African carbon sink is declining16, while other studies conclude that it is in a near-zero steady-state2, or even that it has already transitioned to a carbon source17,18. A more recent assessment of the African greenhouse gas budget in REgional Carbon Cycle Assessment and Processes 1 (RECCAP1)19 concluded that Africa‚Äôs carbon sink capacity is decreasing and net ecosystem exchange switched from a small sink of -0.61 ¬± 0.58 PgC yr-1 to a small source in RECCAP2 at +0.16 (CI=[-0.52;1.36]) PgC yr-1. In this context, the role of forest degradation20, i.e. the partial loss of aboveground tree biomass from a forest, and total forest cover loss, as well as their interannual variability are major uncertainties in the African carbon cycle1.&lt;/p&gt;
    &lt;p&gt;The rationale of this study was to analyse new satellite-based maps of aboveground biomass stocks at unprecedented high spatial resolution and to use the biomass dynamics inferred from these maps to test whether forest biomass stocks in Africa have switched from a net sink into a net source.&lt;/p&gt;
    &lt;p&gt;Earth observation from satellites combined with field-plot-based national forest inventories provides spatially explicit estimates of key terrestrial carbon pools and their changes over time. In Africa, field plots are scarce. Because of the correlation between forest canopy height, aboveground woody biomass and aboveground carbon stock, satellite-derived forest canopy height maps are the best option for large-scale mapping. Spaceborne Light Detection and Ranging (LiDAR) transmits polarised light from a pulsed laser to measure the distance to the Earth‚Äôs surface. Spaceborne LiDAR missions such as ICESAT21 and GEDI22 allow the estimation of canopy height from the vertical profile of returned laser light to the sensor. These datasets can be used to train empirical and machine learning models, in combination with other datasets such as optical multispectral imagery, digital elevation models, or maps of radar backscatter, in order to map aboveground biomass density across the tropics, including tropical Africa, e.g. for a single year5,6 and for different years to estimate biomass (and carbon) gains and losses using coarse spatial resolution images9,17,23,24,25. However, the resolution of these aboveground biomass density maps is too coarse to relate them to drivers of disturbances, such as forest cover loss and forest degradation26.&lt;/p&gt;
    &lt;p&gt;Because deforestation and forest degradation occur on relatively fine spatial scales, more reliable estimates of aboveground biomass density across Africa and its annual gains and losses can only be quantified at high spatial resolution. This is the route to improving our quantitative knowledge of the African terrestrial carbon cycle and estimating carbon emissions and removals more reliably.&lt;/p&gt;
    &lt;head rend="h2"&gt;Results&lt;/head&gt;
    &lt;p&gt;Our analysis of aboveground woody biomass density derived from Earth observation over a time period of 11 years reveals the spatial distribution and temporal trends of biomass gains and losses for all forests and woody savannas in Africa. Fig. 1a shows a map of aboveground woody biomass density for the year 2017. Tropical Grasslands, Savannas and Shrublands are by far the largest biome by area with an average aboveground biomass density of 32 Mg ha-1, while Tropical Moist Broadleaf Forests cover a much smaller area with much higher biomass density (Fig. 1b,c). An accuracy assessment against an extensive set of field plot measurements gave a coefficient of determination (R2) of 0.70, a Root Mean Square Difference (RMSD) of 74.2 Mg ha-1, a Relative Root Mean Square Difference (Rel. RMSD) of 33%, and a Mean Bias Difference (MBD) of 8 Mg ha-1, but the higher aboveground biomass densities tended to be overestimated (Fig. 1d). A further comparison with airborne LiDAR-based biomass estimates for 2015 and 2016 (Fig. 1e) showed that the aboveground woody biomass map is unbiased even at higher biomass levels (R2 = 0.85, RMSD = 47.7 Mg ha-1, Rel. RMSD = 48%, MBD = 0 Mg ha-1), though these results may be overoptimistic, due to the spatial proximity to the training data. While both validation approaches suggest there may be potential underestimations beyond 350 Mg/ha (Table S4a), this is a common issue in remote sensing derived AGBD maps. Quantifying AGBD in dense forests is still challenging and AGBD remote sensing retrieval algorithms suffer from large uncertainties at high AGBD27.&lt;/p&gt;
    &lt;head rend="h3"&gt;Aboveground woody biomass gains and losses across Africa&lt;/head&gt;
    &lt;p&gt;From 2007 to 2010, Africa gained 439 ¬± 66 Tg yr-1 (0.37% yr-1) net aboveground woody biomass. However, between 2010 and 2015 the continent lost -132 ¬± 20 Tg yr-1 or -0.11% yr-1 biomass. Between 2015 and 2017 the average net aboveground biomass change decreased to a loss rate of -41 ¬± 6 Tg yr-1 or -0.03% yr-1 (Fig. 2a). These results indicate that Africa‚Äôs forests have transitioned from a net sink of aboveground biomass to a net source over that time period. We now investigate where that switch has taken place.&lt;/p&gt;
    &lt;p&gt;The recent aboveground biomass losses in Africa are mostly driven by losses in the Tropical Moist Broadleaf Forests biome over this period. This is partly offset by biomass gains in the savanna biome from 2015 to 2017 (Fig. 2b). These gains are plausibly explained by enhanced shrub encroachment due to the carbon fertilisation effect of increasing atmospheric carbon dioxide, which has been shown to alter the competition between trees and grasses in savannas in favour of trees28. The Tropical Moist Broadleaf Forests biome gained +192 Tg yr-1 aboveground biomass in the period 2007 to 2010. This changed to a biomass loss of -70 Tg yr-1 between 2010‚Äì2015, and an even greater biomass loss of ‚àí 154 Tg yr-1 between 2015 and 2017. The observed biomass losses for 2007 to 2017 can be explained by a significant increase in forest cover loss rates during the last decade in Democratic Republic of Congo, Madagascar and some West African countries29.&lt;/p&gt;
    &lt;p&gt;The largest cumulative aboveground biomass gains took place in the Tropical Moist Broadleaf Forests biome of the Congo basin in areas within Equatorial Guinea, Gabon and the Republic of Congo (Fig. 2). The majority of the Tropical Grasslands, Savannas and Shrublands biome shows cumulative aboveground biomass gains across Africa, although between 2010 and 2015, it exhibited a cumulative loss.&lt;/p&gt;
    &lt;p&gt;These results provide fresh evidence from the new aboveground biomass dataset presented here that Africa‚Äôs forests have switched from a net sink of carbon to a net source after 2010.&lt;/p&gt;
    &lt;head rend="h2"&gt;Discussion&lt;/head&gt;
    &lt;p&gt;Previous studies have led to contradictory insights into whether Africa‚Äôs ecosystems are a net sink or a net source of carbon. This study provides the first continent-wide, high-resolution assessment of aboveground woody biomass changes in Africa over a decade, revealing a significant transition from a carbon sink to a source between 2010 and 2017. Our analysis, based on satellite-derived aboveground biomass maps validated with field data, highlights the escalating impact of deforestation in tropical moist broadleaf forests as a primary driver of biomass loss. We acknowledge that satellite-derived AGBD has some limitations due to the saturation at high AGBD ranges. However, there are two facts that give us confidence in our conclusions. First, we have adopted a rigorous uncertainty analysis approach and the 95% confidence intervals of the net changes in AGBD shown in Fig. 2 indicate that we can claim with high confidence that the transition from a carbon sink to a source is real. The confidence intervals do not overlap. Second, Table 1 and Figure S7 show that the AGBD values in our study are reasonably similar to independent country-level statistics reported by FAO. For example, for the Democratic Republic of Congo (DRC), which contains by far the most of the African AGB, the deviation of our estimate from the FAO estimate is only 11%. Furthermore, as most deforestation occurs in the dense moist broadleaf forests where biomass is high, the underestimations we detect beyond 350 Mg/ha suggest that our analysis may not reflect the full impacts of forest loss on carbon emissions and that the reversal from sink to source we suggest may be even more pronounced than what we report here. While gains in savanna regions, potentially due to shrub encroachment, partially mitigated these losses, they are insufficient to reverse the overall trend.&lt;/p&gt;
    &lt;p&gt;Our study focuses on aboveground woody biomass stock and its changes, as this is the only pool that is persistent over long time periods and that we can realistically quantify using remote sensing techniques. Although also persistent, soil carbon stocks cannot be estimated with any confidence from remote sensing. At continental and biome scale, we consider carbon fluxes from woody debris and litter as short-term (annual turnover time), with no substantial dampening or enhancing effects on ecosystem-level carbon fluxes.&lt;/p&gt;
    &lt;p&gt;The implications of this shift are profound. Africa‚Äôs forests and woodlands have historically served as a carbon sink. Now, they are contributing to widening the global greenhouse gas emissions gap that needs to be filled to stay within the goals of the Paris Agreement. The significance of this finding to global climate policies and the current revision of the Nationally Determined Contributions to the Paris Agreement is that even more greenhouse gas emission reductions are needed than was the case before this natural carbon sink shut down. Our findings underline the urgent need for strengthened conservation policies, improved forest governance, and targeted restoration initiatives, such as REDD+. The fine-scale spatial and temporal insights provided in this study can support policymakers and scientists in prioritizing interventions to halt biomass loss and enhance carbon sequestration.&lt;/p&gt;
    &lt;p&gt;New insights into the geographical regions where significant biomass changes have occurred are also presented. The biomass maps at continental and biome scales were validated with a large independent dataset of field plot data and LiDAR-based estimates of aboveground biomass density (Supplementary Material). The fine spatial resolution allowed us to account for the trends in biomass loss associated with forest disturbances as small as one hectare, which was not possible until recently9,17,31,32.&lt;/p&gt;
    &lt;p&gt;Total aboveground biomass stocks of African forests and woodlands are estimated at of 118 Pg biomass, which equates to approximately 59 Pg carbon. These overall values are consistent with previous estimates using independent datasets, e.g. 113 Pg5, 111 Pg9, 116 Pg8, and 129 Pg6 biomass stocks, but it is higher than the estimates provided by Santoro et al.31 and Avitabile et al.7 (85 Pg and 96 Pg, respectively). The latter two studies excluded some areas with woody aboveground biomass by applying a spatial forest mask to exclude several woody vegetated areas, such as savannas, that did not fit their specific forest definitions, while our estimates include all woody vegetation in the tropical forest and savanna biomes with a percentage tree cover above 1%.&lt;/p&gt;
    &lt;p&gt;The aboveground biomass estimates presented here, and other Earth observation-based studies disagree with official biomass statistics for some countries at national level as reported by the United Nations Food and Agriculture Organisation (FAO) (Table 1). These differences are most likely also the consequence of using different national forest definitions33,34 leading to substantial differences in the reported total national forest area.&lt;/p&gt;
    &lt;p&gt;The pantropical and continental AGBD maps products derived by Saatchi et al.5, Baccini et al.6, Avitabile et al.7, Bouvet et al.35 present spatial resolutions from 25 m to 1 km, and reported Rel. RMSD = 33%, RMSD = 39 Mg/ha, RMSD = 87‚Äì90 Mg/ha, and RMSD = 17‚Äì19 Mg/ha for Africa, respectively. However, the later African AGBD 25m pixel map is constrained to AGBD levels below 100 Mg ha-1. Only the global map from Santoro et al.31 presents the same spatial resolution as the current study (i.e. 100m pixel size) but reports larger errors with Rel. RMSD = 57‚Äì73% for tropical and subtropical regions compared to this study‚Äôs Rel. RMSD = 33‚Äì40%.&lt;/p&gt;
    &lt;p&gt;The mean annual net aboveground biomass change shows gains of +57 ¬± 9 Tg yr-1 for the period 2007 to 2017. However, analysing the gains and losses for different time periods, an annual net gain of +439 ¬± 66 Tg yr-1 is found in the earlier time period from 2007 to 2010, followed by a net loss of -106 ¬± 16 Tg yr-1 from 2011 to 2017. This indicates a rapid acceleration of aboveground biomass losses in Africa, which is driven by increasing biomass loss rates in the Tropical Moist Broadleaf Forests.&lt;/p&gt;
    &lt;p&gt;The evidence presented here suggests that Africa‚Äôs forests and woodlands have switched from a net carbon sink into a net source because of increased biomass losses due to human activities and natural disturbances. This finding is consistent with growing forest loss rates in Africa from 2010 onwards as reported by FAO36, and the increasing forest cover loss rates based on satellite observations from 2012 to 2013 onwards by Hansen et al.29. FAO36 statistics on increasing annual harvested roundwood from 277 million m3 in 1961 up to 768 million m3 by 2017 also confirm these forest losses. The observed trends may be further exacerbated in the future by population growth in Africa37, the increasing export demand particularly from Asia38, and the resulting pressure on natural resources (agricultural expansion for commodity crop, timber and fuelwood). The long-term persistence of these trends will depend on local governance and whether resources are used sustainably.&lt;/p&gt;
    &lt;p&gt;The results provide further independent evidence of a shift in forest functioning from a carbon sink to a source around this time period, which is consistent with recent studies of all pantropical regions19,35,39,40.&lt;/p&gt;
    &lt;p&gt;A comprehensive assessment of the terrestrial greenhouse gas budget of Africa found that most studies agree that Africa is a small sink of carbon on an annual scale, with an average value of ‚àí 0.61 ¬± 0.58 Pg C yr‚àí14. The net loss of aboveground woody biomass from 2011 to 2017 of ‚àí 106 ¬± 16 Tg yr-1 observed here (weighted mean) may well tip the overall carbon budget into a net source overall when considering all carbon pools and fluxes.&lt;/p&gt;
    &lt;p&gt;The world needs to step up efforts to protect the substantial carbon stocks in Africa‚Äôs aboveground woody biomass and restore lost forest areas to counter the climate crisis, as agreed in the Glasgow Leaders Declaration on Forests and Land Use41 at the 26th Conference of the Parties (COP26) to halt net deforestation by 2030. The world otherwise risks losing an important carbon sink needed to achieve the goals of the Paris Agreement. Reversing biomass losses in Africa requires actions in the political, economic and societal spheres, to promote capacity building42, improve forest governance43, implement financial incentives through the REDD+ initiative44, and facilitate technological infrastructure, such as satellite-enabled forest alert systems to halt illegal logging such as those deployed in Kenya45. Restoration initiatives such as AFR10046 and Restor47 will also be needed.&lt;/p&gt;
    &lt;p&gt;Future research should explore the underlying drivers of regional variability in biomass dynamics and assess the potential of emerging technologies for near-real-time monitoring of forest disturbances and strengthening forest governance.&lt;/p&gt;
    &lt;head rend="h2"&gt;Methods&lt;/head&gt;
    &lt;p&gt;Assessing forest aboveground biomass dynamics over long time periods and at continental to global scale requires reference observations such as forest inventory field plots in combination with satellite Earth observation. To overcome the low availability and quality of reference data, we used the spaceborne Geoscience Laser Altimeter System (GLAS) onboard the Ice, Cloud, and land Elevation Satellite (ICESat)48, which operated from 2003 to 2010 and acquired millions of Light Detection and Ranging (LiDAR) footprints, providing measurements of canopy height and other biophysical metrics relating to canopy structure that are highly correlated with aboveground biomass49. The Global Ecosystem Dynamics Investigation (GEDI) LiDAR instrument22 onboard the International Space Station that commenced operation in 2019 uses similar technology to the GLAS/ICESat instrument but with smaller footprints and much denser coverage (narrower spacing between footprint locations along the orbit), providing a dense network of training and validation data on forest canopy height.&lt;/p&gt;
    &lt;p&gt;Based on a machine learning algorithm, L-band Synthetic Aperture Radar (SAR) backscatter image mosaics acquired by ALOS PALSAR-1/PALSAR-248 and optical multispectral Landsat-derived percent tree cover maps29 were used as joint predictors to extend the canopy height obtained from GEDI to canopy height maps across the whole of Africa. Regional maps of aboveground biomass density derived from airborne LiDAR over a range of biomes in Africa were then used to derive an empirical model that estimates aboveground biomass density as a function of canopy height. The LiDAR-based aboveground biomass footprint estimates from LiDAR were used to train the machine learning model. The model was then used to produce annual Africa-wide maps of aboveground biomass density and its standard deviation (SD) at 100 m pixel spacing for the period 2007 to 2017. The maps were validated using a large independent dataset of field plot measurements across the continent. The aboveground biomass density maps and associated standard deviations were used to estimate the African aboveground woody biomass stock and its annual changes (with confidence intervals based on the uncertainty characterization described in Supplementary Materials) with the aim of contributing to improvement of carbon inventories, understanding trends, and testing whether the aboveground biomass change rate has increased, reduced or changed sign over the period 2007-2017.&lt;/p&gt;
    &lt;head rend="h3"&gt;Datasets&lt;/head&gt;
    &lt;p&gt;Spaceborne LiDAR from GEDI. The GEDI L2B Canopy Cover and Vertical Profile Metrics product (version 1), available from the NASA/USGS Land Processes Distributed Active Archive Center50, was collected from April 2019 to June 2019 (Fig. 3a). The LiDAR metrics estimated by this product are representative of a 25 m diameter footprint on the ground. Version 1 of the product has a geolocation error of approximately 15-20 m, so can be difficult to use with moderate spatial resolution imagery such as Sentinel-1/-2 or Landsat (i.e. 10-30 m spatial resolution pixels).&lt;/p&gt;
    &lt;p&gt;Airborne laser scanning (ALS). This study uses gridded LiDAR-derived aboveground biomass density maps based on airborne LiDAR acquired in 2016 at 4 different sites in Gabon (Lope, Mabounie, Mondah, and Rabi)51,52, and in 2015-16 at 2 sites in Kenya (Taita Hills and Maktau)53,54. The canopy height to AGBD model was developed using 50% of the pixels from these datasets, while the remaining 50% were used to validate the aboveground biomass product.&lt;/p&gt;
    &lt;p&gt;Field plot data of aboveground biomass density. We collated a dataset consisting of 10,837 aboveground biomass density reference field plots across Africa (see Table S2 in supplementary material) to be used as an independent validation dataset for the 2017 map (Fig. 3). The assessment was limited to 2017 due to the lack of re-measured plot data. Field plots were measured in different years, mainly between 2000 and 2017, with the vast majority before 2010. The plot data are from different national forest inventories and research projects, so have various plot designs, sizes and shapes. Since most of the plots do not have accurate spatial coordinates due to licensing restrictions, we cannot use them directly to validate the 100 m resolution pixel maps. Instead, we followed the approach described by Santoro et al.31 and Araza et al.15 in which the plot values were first adjusted to minimize the temporal and areal mismatches between the plot and map estimates of aboveground biomass density. The adjustment was necessary because of the uneven spatial distribution of the reference samples, the variety of plot sizes used, variations in field survey methods, and used allometric equations to estimate biomass of the plots55. The plots were mostly smaller than 1 ha and often represented only a small fraction of the area covered by a 1 ha biomass map pixel. To reduce the effect of random errors caused by different resolutions of the reference dataset and the biomass map, we aggregated the map and the plot data to 0.1¬∞ grid cells15. This procedure yielded 463 grid cells with reference aboveground biomass density values for validation (Fig. 3b). The standard deviation associated with each of these values was estimated by accounting for the principal plot measurement error sources (as described in Araza et al.15).&lt;/p&gt;
    &lt;p&gt;ALOS PALSAR/ALOS-2 PALSAR-2 radar image mosaics. JAXA‚Äôs annual mosaics of L-band SAR HH and HV polarised backscatter (Œ≥0) were based on ALOS PALSAR from 2007 to 2010 and ALOS-2 PALSAR-2 from 2015 to 201756,57. No mosaics are available for 2011 to 2014. The PALSAR-2 mosaics for 2018 to 2020 are available, but the pre-processing and geolocation approaches are different from the previous mosaics, so they were excluded from this analysis. The mosaics are a calibrated, 16-look, re-projected, orthorectified and slope-corrected product with 25 m pixel spacing, to which a de-striping process has been applied22,31,33. The PALSAR and PALSAR-2 mosaics were normalised to reduce artefacts and to ensure temporal consistency of the radar backscatter signal, allowing the same trained model to be used for the whole time series. Artefacts in the mosaics usually result from changes in moisture conditions between image acquisitions, which affects the backscatter, or appear in the pre-processing due to inadequate calibration and/or topographic corrections. We followed a similar approach to that described in58, but instead of superpixels used a circular moving window 100 pixels in diameter (~2,000 ha). This normalises the PALSAR/PALSAR-2 imagery to a common baseline based on the mean and standard deviation of backscatter of the PALSAR mosaics (2007-2010). Implicit in this procedure is the assumption that continuous changes with scale larger than 2,000 hectares did not occur from year to year. Normalizing the images at this large scale also tends to ensure that local changes due to disturbances and vegetation growth are preserved. The analysis used both HH and HV polarisations and two additional metrics, the Cross-polarisation Ratio (CpR = HH‚ÅÑHV) and the Radar Forest Degradation Index (RFDI = (HH‚ÄìHV)‚ÅÑ(HH+HV))59.&lt;/p&gt;
    &lt;p&gt;Percent tree cover data. A 30 m Landsat-based map product of percent tree canopy cover for the year 2000 and annual tree cover loss estimates for the period from 2000 to 201729 was used to generate annual percent tree cover maps for each year. For the year 2007, all pixels detected as forest cover loss were set as 0% percent tree cover, while pixels detected as having forest cover loss in previous years (i.e. from 2000 to 2006) were set to ‚Äúno data‚Äù, as we have no information on regrowth after the disturbance. The canopy height and aboveground biomass predictions for these ‚Äúno data‚Äù pixels were performed using only PALSAR as a predictor variable (see Modelling Framework). We repeated this process for all the years within our study period (2007-2010 and 2015-2017). PALSAR data and Landsat percent tree cover datasets were mosaicked and co-registered to generate two stacks of predictor datasets, with 50 m and 100 m pixel spacing, respectively. Woody vegetated areas were defined as pixels with equal or above 1% tree cover.&lt;/p&gt;
    &lt;head rend="h3"&gt;Modelling framework&lt;/head&gt;
    &lt;p&gt;GEDI footprint selection and clustering. We used the maximum footprint height in a footprint, provided by the GEDI L2B footprint product, as reference canopy height metric, but performed a filtering process to select only the highest quality footprints for training and validation purposes. Coverage footprints were excluded due to their lack of laser light penetration in dense forests and only footprints acquired by the full power beams were used. Only night acquisitions (solar elevation &amp;lt; 0¬∞) with a beam sensitivity greater than 95% were retained. Low quality footprints, as indicated by the L2B quality assurance layers, were discarded, as were footprints with canopy height above the 99.9th percentile of the initial set. The Copernicus Global Land Cover dataset60 was used to exclude footprints in non-vegetated classes. We used the 11 forest classes and the shrubland class for this purpose60. After the filtering, approximately 1.8 million footprints were available, distributed across the African continent (Fig. 3). The GEDI footprints were grouped into 4-footprint clusters along the track direction, in each of which the top canopy height values (RH100) were averaged to correct for sampling and geolocation errors. This provided the main reference data for training and validating our canopy height model. The average by cluster increases the sampled area of our reference unit from 0.05 ha (1 footprint) to 0.2 ha (4 footprints) and has been demonstrated to increase accuracy when training models with spaceborne LiDAR footprints6. The larger sampled area helps to average out various errors typical of small sampling units (e.g. small inventory plots), such as sampling error and geolocation error. Only clusters with 4 consecutive footprints were used.&lt;/p&gt;
    &lt;p&gt;Canopy height modelling. We used a non-parametric machine learning Random Forests (RF) regression algorithm61, following the same framework as in62 and 63, to generate a canopy height model (CHM) and its associated error at pixel level using PALSAR/PALSAR-2 radar backscatter and Landsat Percent Tree Cover for the same years as predictors. We used 100 trees for each RF model run. Generation of the canopy height model uses two different resolutions (Fig. 4): (i) Remote sensing signatures were extracted from the four 50 m pixels that overlap the 0.2 ha area corresponding to each cluster of four GEDI footprints and averaged; these four pixels are equivalent to the area of 1 ha. (ii) The model training and the prediction output are at 1 ha pixel size, i.e. 100 m by 100 m.&lt;/p&gt;
    &lt;p&gt;The conversion from 50 m to 100 m was needed because geolocation errors in the GEDI footprint products (15‚Äì20 m for version 1 and around 10 m for version 2) prevent small (&amp;lt; 50 m) pixels being adequately matched to single GEDI footprints. Additionally, as with small forest inventory plots, a large tree within the footprint biases the canopy height and makes the value unrepresentative of the canopy height within 1 ha. This two-scale scheme follows Saatchi et al.5 and Baccini et al.6, and aims to average out these errors by combining several footprints. We assume that 4 footprints located within 1 ha (four 50m x 50m pixels) are more representative of the actual canopy height than 1 or 2 footprints located within a 100 m pixel.&lt;/p&gt;
    &lt;p&gt;The GEDI canopy height dataset was randomly partitioned into 2 datasets: 10% for training the CHM model (36,944 GEDI clusters) and the remaining 90% (328,243 clusters) for independent validation. Training was performed within a jack-knife/k-fold framework in which the training reference data (10% of the original dataset) were spatially partitioned into k subsamples with k = 10. The jack-knife / k-fold allocation was applied spatially to avoid over-optimistic accuracy metrics due to the possible spatial autocorrelation of the training data64. We used a very large dataset for independent validation (i.e., 90% of the original dataset) to avoid a large proportion of the validation dataset being autocorrelated with the training data. Hence, we divided our training dataset (36,944 GEDI clusters) over the whole of Africa into 10 regions with approximately the same number of footprint clusters. A single spatial subsample was kept aside as the validation data for testing the RF model, while the remaining k-1 spatial subsamples were used as training data. The cross-validation process was then repeated k times. Thus, 10 canopy height maps were generated. The mean value of all 10 predictions for each pixel was then used as the final canopy height estimate, and their standard deviation as the prediction error. We also propagated the GEDI footprint height measurement error, the sampling error and the error arising from the temporal difference between GEDI footprints and the satellite imagery to estimate the total error of our canopy height maps (see Supplementary Material).&lt;/p&gt;
    &lt;p&gt;We trained 2 different random forest (RF) models to predict canopy height. The first one (main model) used annual percent tree cover and SAR backscatter data, while the second one only used SAR backscatter data. Our main canopy height model uses L-band PALSAR/PALSAR-2 radar imagery together with the Landsat percent tree cover product. This model was applied for all pixels from the year 2000 to the given year that were undisturbed according to Hansen et al.29. However, for the pixels detected as disturbed (i.e., forest cover loss), a second canopy height model based only on PALSAR/PALSAR-2 was fitted and used for the years after the disturbance, as this is better suited to detecting any recovery (the Landsat Percent Tree Cover product assumes no regrowth after a forest loss event).&lt;/p&gt;
    &lt;p&gt;Conversion of canopy height to aboveground woody biomass density. We developed a single empirical linear model to estimate the square root of aboveground biomass density as a function of canopy height. The model was based on six airborne LiDAR aboveground biomass density maps covering closed-canopy moist tropical forest, mangrove, montane forest, drylands and open savannas (see supplementary material).&lt;/p&gt;
    &lt;p&gt;The square root of AGBD is derived to reduce heteroscedasticity65. Conversion to AGBD requires correction of the inherent negative bias in the square root transformation66 using the ratio estimator proposed by Snowdon et al.67:&lt;/p&gt;
    &lt;p&gt;Boveground biomass density change analysis. For a given pixel, we identified a significant biomass loss between times t1 and t2 if AGBDt1‚ÄìSDt1 &amp;gt; AGBDt2 + SDt2, while there is a significant biomass gain if AGBDt1 + SDt1 &amp;lt; AGBDt2‚ÄìSDt2, where the AGBD values at t1 and t2 are AGBDt1 and AGBDt2 respectively, and their corresponding SD values are SDt1 and SDt2. Changes between consecutive years were considered significant when the error bounds on the estimates of AGBD at the two times did not overlap, otherwise the measured change was considered insignificant. For pixels showing a significant annual gain or loss, we calculated the cumulative significant change over the time series. If this was negative at the end of the period (i.e. 2017), we accepted it as significant biomass loss, and assign this loss value to the year with the highest loss (when significant loss is detected in two or more consecutive pairs of images). Biomass losses usually result from forest cover loss events, but could also arise from other causes, such as natural or anthropogenic fires. A similar approach was taken to biomass gains. However, small gains and losses are hard to detect using this method, and biomass gains were very scarce in forest areas with high aboveground biomass density (i.e. mature forest). Either change is negligible in such areas due to a balance between mortality and growth, or it simply cannot be detected due to insufficient sensitivity of the Earth observation signal when biomass is high.&lt;/p&gt;
    &lt;p&gt;For pixels that were undisturbed (i.e. with positive cumulative significant biomass change or non-significant biomass change), the slope of the temporal linear regression for the given time period was used to represent the average rate of vegetation growth or progressive loss. We calculated the long-term Sen‚Äôs slope68 and only accepted significant slopes (p &amp;lt; 0.05). Additionally, we followed Xu et al.24 in assuming that biomass gain cannot be properly measured once aboveground biomass density exceeds a certain level, as evidenced by the steep increase in the standard deviation of our estimates for high aboveground biomass density (Fig. S5). Thus, for undisturbed pixels with aboveground biomass density above 50 Mg ha-1 we used the IPCC aboveground biomass density growth factors for mature forest69.&lt;/p&gt;
    &lt;p&gt;Once all the significant changes across the time-series were identified, we generated a new aboveground biomass density dataset using the aboveground biomass density map from 2017 as reference (the year used to train the model, equation1), and then rolled only the significant changes back to 2007 to generate a consistent temporal dataset.&lt;/p&gt;
    &lt;p&gt;Biome-level AGB quantification: We used terrestrial biomes as spatial units to calculate regional AGB statistics. Biomes are not strictly defined by the physical land cover types (e.g. forests, shrublands etc.), but rather a complex combination of climate and vegetation conditions70. While biome extents may be dynamic, due to gains and losses in woody vegetation across landscapes, alongside changes in regional climatic conditions, to our knowledge, there is no data product that accounts for land cover dynamics to delineate biomes on an annual basis. We therefore used the most up-to-date static product available, the Ecoregions2017 Resolve biome map14 and assumed that biome extents have not significantly changed over the study period. Quantifying woody aboveground biomass losses / gains is itself an indicator of biomass changes in forests and shrublands.&lt;/p&gt;
    &lt;head rend="h2"&gt;Data availability&lt;/head&gt;
    &lt;p&gt;The datasets used and/or analysed during the current study will be available from the corresponding author on reasonable request.&lt;/p&gt;
    &lt;head rend="h2"&gt;References&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Ciais, P. et al. The carbon balance of Africa: Synthesis of recent research studies. Philos. Trans. R. Soc. A Math. Phys. Eng. Sci. 369, 2038‚Äì2057 (2011).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Williams, C. A. et al. Africa and the global carbon cycle. Carbon Balance Manage. 2, 1‚Äì13 (2007).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Bombelli, A. et al. An outlook on the Sub-Saharan Africa carbon balance. Biogeosciences 6, 2193‚Äì2205 (2009).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Valentini, R. et al. A full greenhouse gases budget of Africa: Synthesis, uncertainties, and vulnerabilities. Biogeosciences 11, 381‚Äì407 (2014).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Saatchi, S. S. et al. Benchmark map of forest carbon stocks in tropical regions across three continents. Proc. Natl. Acad. Sci. 108, 9899‚Äì9904. https://doi.org/10.1073/pnas.1019576108 (2011).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Baccini, A. et al. Estimated carbon dioxide emissions from tropical deforestation improved by carbon-density maps. Nat. Clim. Change 2, 182‚Äì185. https://doi.org/10.1038/nclimate1354 (2012).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Avitabile, V. et al. An integrated pan-tropical biomass map using multiple reference datasets. Glob. Change Biol. 22, 1406‚Äì1420 (2016).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;FAO. Global forest resources assessment 2010. (Food and Agriculture Organization of the United Nations, 2010).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Liu, Y. Y. et al. Recent reversal in loss of global terrestrial biomass. Nat. Clim. Change 5(5), 470‚Äì474. https://doi.org/10.1038/nclimate2581 (2015).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lewis, S. L. et al. Above-ground biomass and structure of 260 African tropical forests. Philos. Trans. R. Soc. B Biol. Sci. 368, 20120295 (2013).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ryan, C. M., Williams, M. &amp;amp; Grace, J. Above- and belowground carbon stocks in a miombo woodland landscape of mozambique. Biotropica 43, 423‚Äì432. https://doi.org/10.1111/j.1744-7429.2010.00713.x (2011).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Runfola, D. et al. GeoBoundaries: A global database of political administrative boundaries. PLoS ONE 15(4), e0231866. https://doi.org/10.1371/journal.pone.0231866 (2020).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Environmental Systems Research Institute (ESRI). ArcGIS Desktop, version 10.8.2. https://desktop.arcgis.com/ (2023)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Dinerstein, E. et al. An Ecoregion-based approach to protecting half the terrestrial realm. Bioscience 67, 534‚Äì545. https://doi.org/10.1093/biosci/bix014 (2017).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Araza, A. et al. A comprehensive framework for assessing the accuracy and uncertainty of global above-ground biomass maps. Remote Sens. Environ. 272, 112917 (2022).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Hubau, W. et al. Asynchronous carbon sink saturation in African and Amazonian tropical forests. Nature 579, 80‚Äì87 (2020).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Baccini, A. et al. Tropical forests are a net carbon source based on aboveground measurements of gain and loss. Science 358(6360), 230‚Äì234. https://doi.org/10.1126/science.aam5962 (2017).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Palmer, P. I. et al. Net carbon emissions from African biosphere dominate pan-tropical atmospheric CO2 signal. Nat. Commun. 10, 3344. https://doi.org/10.1038/s41467-019-11097-w (2019).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ernst, Y. et al. The African Regional Greenhouse Gases Budget (2010‚Äì2019). Global Biogeochem. Cycles 38, e2023GB008016. https://doi.org/10.1029/2023GB008016 (2024).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Neeff, T. et al. Slowly getting there: A review of country experience on estimating emissions and removals from forest degradation. Carbon Balance Manage. 19, 38. https://doi.org/10.1186/s13021-024-00281-1 (2024).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Abdalati, W. et al. The ICESat-2 laser altimetry mission. Proc. IEEE 98, 735‚Äì751 (2010).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Dubayah, R. et al. The global ecosystem dynamics investigation: High-resolution laser ranging of the Earth‚Äôs forests and topography. Sci. Remote Sens. 1, 100002 (2020).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Fan, L. et al. Satellite-observed pantropical carbon dynamics. Nat. Plants 5, 944‚Äì951 (2019).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Xu, L. et al. Changes in global terrestrial live biomass over the 21st century. Sci. Adv. 7, eabe9829. https://doi.org/10.1126/sciadv.abe9829 (2021).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Harris, N. L. et al. Global maps of twenty-first century forest carbon fluxes. Nat. Clim. Chang. 11, 234‚Äì240 (2021).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;McNicol, I. M., Ryan, C. M. &amp;amp; Mitchard, E. T. A. Carbon losses from deforestation and widespread degradation offset by extensive growth in African woodlands. Nat. Commun. 9, 3045. https://doi.org/10.1038/s41467-018-05386-z (2018).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Rodr√≠guez-Veiga, P. et al. Forest biomass retrieval approaches from earth observation in different biomes. Int. J. Appl. Earth Obs. Geoinf. 77, 53‚Äì68 (2019).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Bond, W. J. &amp;amp; Midgley, G. F. Carbon dioxide and the uneasy interactions of trees and savannah grasses. Philos. Trans. R. Soc. B Biol. Sci. 367, 601‚Äì612 (2012).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Hansen, M. C. et al. High-resolution global maps of 21st-century forest cover change. Science 342, 850‚Äì853. https://doi.org/10.1126/science.1244693 (2013).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Bouvet, A. et al. An above-ground biomass map of African savannahs and woodlands at 25 m resolution derived from ALOS PALSAR. Remote Sens. Environ. 206, 156‚Äì173. https://doi.org/10.1016/j.rse.2017.12.030 (2018).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Santoro, M. et al. The global forest above-ground biomass pool for 2010 estimated from high-resolution satellite observations. Earth Syst. Sci. Data 13, 3927‚Äì3950. https://doi.org/10.5194/essd-13-3927-2021 (2010).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Santoro, M. &amp;amp; Cartus, O. ESA Biomass climate change initiative (Biomass_cci): Global datasets of forest above-ground biomass for the years 2010, 2017, 2018, 2019 and 2020, v4. V4 ed. (NERC EDS Centre for Environmental Data Analysis; 2023).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lund, H. G. Rev* Definitions of Forest, Deforestation, Afforestation, and Reforestation [Online]. Forest Information Services 2012 [cited 2012, 15‚Äì05‚Äì2012] Misc. pagination. Note, this paper has been continuously updated since 1998. Available from: http://home.comcast.net/~gyde/DEFpaper.htm&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lund, H. G. When is a forest not a forest?. J. Forest. 100, 21‚Äì28 (2002).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Knoke, T. et al. Trends in tropical forest loss and the social value of emission reductions. Nat. Sustain. 6, 1373‚Äì1384. https://doi.org/10.1038/s41893-023-01175-9 (2023).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;FAO. Global forest resources assessment 2020‚Äìkey findings, Policy research paper. (FAO, Rome, 2020).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Tyukavina, A. et al. Congo Basin forest loss dominated by increasing smallholder clearing. Sci. Adv. 4(11), eaat2993. https://doi.org/10.1126/sciadv.aat2993 (2018).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CIFOR-ICRAF, Eba‚Äôa Atyi, R., Hiol Hiol, F., Lescuyer, G., Mayaux, P., Defourny, P., Bayol, N., Saracco, F., Pokem, D., Sufo Kankeu, R. &amp;amp; Nasi, R. (2022). The forests of the Congo basin: State of the forests 2021. Bogor, Indonesia: CIFOR-ICRAF. https://doi.org/10.17528/cifor/008700&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Gatti, L. V. et al. Amazonia as a carbon source linked to deforestation and climate change. Nature 595, 388‚Äì393. https://doi.org/10.1038/s41586-021-03629-6 (2021).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Feng, Y. et al. Doubling of annual forest carbon loss over the tropics during the early twenty-first century. Nat. Sustain. 5, 444‚Äì451. https://doi.org/10.1038/s41893-022-00854-3 (2022).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Gasser, T., Ciais, P. &amp;amp; Lewis, S. L. How the Glasgow Declaration on Forests can help keep alive the 1.5 C target. Proc. Nat. Acad. Sci. 119, e2200519119 (2022).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Bamwesigye, D., Doli, A. &amp;amp; Hlavackova, P. REDD+: An analysis of initiatives in East Africa amidst increasing deforestation. Eur. J. Sustain. Dev. 9, 224‚Äì224 (2020).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Fischer, R., Giessen, L. &amp;amp; G√ºnter, S. Governance effects on deforestation in the tropics: A review of the evidence. Environ. Sci. Policy 105, 84‚Äì101 (2020).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Henry, M., Maniatis, D., Gitz, V., Huberman, D. &amp;amp; Valentini, R. Implementation of REDD+ in sub-Saharan Africa: State of knowledge, challenges and opportunities. Environ. Dev. Econ. 16, 381‚Äì404 (2011).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Roberts, J. et al. Pyeo: A python package for near-real-time forest cover change detection from Earth observation using machine learning. Comput. Geosci. 167, 105192 (2022).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;AUDA-NEPAD. AFR100‚ÄîThe African Forest Landscape Restoration Initiative. African Union Development Agency, https://afr100.org/ (2023).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Restor. Restor global network movement. https://restor.eco/ (2024).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Schutz, B. E., Zwally, H. J., Shuman, C. A., Hancock, D. &amp;amp; DiMarzio, J. P. Overview of the ICESat mission. Geophys. Res. Lett. 32, L21S01. https://doi.org/10.1029/2005gl024009 (2005).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lefsky, M. A. et al. Estimates of forest canopy height and aboveground biomass using ICESat. Geophys. Res. Lett. 32, L22S02 (2005).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Dubayah, R., Tang, H., Armston, J., Luthcke, S., Hofton, M. &amp;amp; Blair, J. GEDI L2B canopy cover and vertical profile metrics data global footprint level V001. NASA EOSDIS land processes DAAC. Accessed 2020-04-11 from https://lpdaac.usgs.gov/products/gedi02_bv001/. (2020).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Labriere, N. et al. In situ reference datasets from the TropiSAR and AfriSAR campaigns in support of upcoming spaceborne biomass missions. IEEE J. Select. Top. Appl. Earth Observ. Remote Sens. 11, 3617‚Äì3627 (2018).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Saatchi, S. S., Chave, J., Labriere, N., Barbier, N., R√âJou-M√âChain, M., Ferraz, A. &amp;amp; Tao, S. AfriSAR: Aboveground Biomass for Lope, Mabounie, Mondah, and Rabi Sites, Gabon. ORNL DAAC. (ORNL Distributed Active Archive Center, 2019).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Adhikari, H. et al. Determinants of aboveground biomass across an Afromontane landscape mosaic in Kenya. Remote Sens. 9, 827 (2017).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Amara, E. et al. Aboveground biomass distribution in a multi-use savannah landscape in Southeastern Kenya: Impact of land use and fences. Land 9, 381 (2020).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Rodriguez-Veiga, P. et al. Forest biomass retrieval approaches from earth observation in different biomes. Int. J. Appl. Earth Obs. Geoinf. 77, 53‚Äì68 (2019).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Shimada, M. &amp;amp; Ohtaki, T. Generating large-scale high-quality SAR mosaic datasets: Application to PALSAR data for global monitoring. IEEE J. Select. Top. Appl. Earth Observ. Remote Sens. 3, 637‚Äì656 (2010).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Shimada, M. et al. New global forest/non-forest maps from ALOS PALSAR data (2007‚Äì2010). Remote Sens. Environ. 155, 13‚Äì31. https://doi.org/10.1016/j.rse.2014.04.014 (2014).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Marshak, C., Simard, M. &amp;amp; Denbina, M. Monitoring forest loss in ALOS/PALSAR time-series with superpixels. Remote Sens. 11, 556 (2019).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mitchard, E. T. A. et al. Mapping tropical forest biomass with radar and spaceborne LiDAR in Lop√© National Park, Gabon: Overcoming problems of high biomass and persistent cloud. Biogeosciences 9, 179‚Äì191. https://doi.org/10.5194/bg-9-179-2012 (2012).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Buchhorn, M., Bertels, L., Smets, B., De Roo, B., Lesiv, M., Tsendbazar, N., Masiliunas, D. &amp;amp; Li, L. Copernicus global land service: Land cover 100 m: Version 3 globe 2015-2019: Product user manual. (Zenodo, Geneve, Switzerland, 2020).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Breiman, L. Random forests. Mach. Learn. 45, 5‚Äì32 (2001).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Rodr√≠guez-Veiga, P. et al. Carbon stocks and fluxes in Kenyan forests and wooded grasslands derived from earth observation and model-data fusion. Remote Sens. 12, 2380 (2020).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Bispo, P. D. C. et al. Woody aboveground biomass mapping of the Brazilian Savanna with a multi-sensor and machine learning approach. Remote Sens. 12, 2685 (2020).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ploton, P. et al. Spatial validation reveals poor predictive performance of large-scale ecological mapping models. Nat. Commun. 11, 1‚Äì11 (2020).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Nilsson, M. et al. A nationwide forest attribute map of Sweden predicted using airborne laser scanning data and field data from the National Forest Inventory. Remote Sens. Environ. 194, 447‚Äì454. https://doi.org/10.1016/j.rse.2016.10.022 (2017).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Baskerville, G. Use of logarithmic regression in the estimation of plant biomass. Can. J. For. Res. 2, 49‚Äì53 (1972).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Snowdon, P. A ratio estimator for bias correction in logarithmic regressions. Can. J. For. Res. 21, 720‚Äì724. https://doi.org/10.1139/x91-101 (1991).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sen, P. K. Estimates of the regression coefficient based on Kendall‚Äôs tau. J. Am. Stat. Assoc. 63, 1379‚Äì1389 (1968).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;IPCC. 2019 Refinement to the 2006 IPCC Guidelines for National Greenhouse Gas Inventories. (IPCC, Switzerland, 2019).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Olson, D. M. et al. Terrestrial ecoregions of the world: A New Map of Life on Earth A new global map of terrestrial ecoregions provides an innovative tool for conserving biodiversity. Bioscience 51(11), 933‚Äì938. https://doi.org/10.1641/0006-3568(2001)051[0933:TEOTWA]2.0.CO;2 (2001).&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;This research was supported by the Natural Environment Research Council (NERC) through the National Centre for Earth Observation and the European Space Agency‚Äôs Climate Change Initiative Plus on Biomass (Biomass CCI+ contract ESA-EOP-SC-AMT-2021-26). The research was also supported by the Short-term International Fellowship awarded by the Japan Society for Promotion of Science (JSPS) to P.R.V and N.T (PE18044). H.B and N.A. were financially supported by the Natural Environment Research Council (NERC, NE/Y006216/1). The authors would like to thank the following organizations for making the data freely available: JAXA, NASA, USGS, GEDI mission, ORNL DAAC, Google, and University of Maryland. P.P., J.H. and H.A. acknowledge Ministry for Foreign AÔ¨Äairs of Finland, Academy of Finland (Decision number 318645) and Faculty of Science, University of Helsinki for funding of Lidar data acquisitions in Kenya. C.M.R, J.C, S.Q, and M.W were supported by the NERC-funded SECO project (NE/T01279X/1); plot data collection by T.B, C.M.R and data analysis by C.J.N was supported by SEOSAW, the Socio-ecological observatory for studying African woodlands (NE/P008755/1; NE/T004258/1).&lt;/p&gt;
    &lt;head rend="h2"&gt;Author information&lt;/head&gt;
    &lt;head rend="h3"&gt;Authors and Affiliations&lt;/head&gt;
    &lt;head rend="h3"&gt;Contributions&lt;/head&gt;
    &lt;p&gt;P.R.V. and H.B. conceived the experiments, P.R.V. and A.A. conducted the experiments and data analyses, P.R.V., J.C., S.Q., A.A. and N.T. contributed to the methodological design. J.C., J.H., P.P., H.A., C.N., and A.A contributed with datasets used in the analysis. All authors contributed to the interpretation of the analysis results and reviewed the manuscript.&lt;/p&gt;
    &lt;head rend="h3"&gt;Corresponding authors&lt;/head&gt;
    &lt;head rend="h2"&gt;Ethics declarations&lt;/head&gt;
    &lt;head rend="h3"&gt;Competing interests&lt;/head&gt;
    &lt;p&gt;The authors declare no competing interests.&lt;/p&gt;
    &lt;head rend="h2"&gt;Additional information&lt;/head&gt;
    &lt;head rend="h3"&gt;Publisher‚Äôs note&lt;/head&gt;
    &lt;p&gt;Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Supplementary Information&lt;/head&gt;
    &lt;p&gt;Below is the link to the electronic supplementary material.&lt;/p&gt;
    &lt;head rend="h2"&gt;Rights and permissions&lt;/head&gt;
    &lt;p&gt;Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article‚Äôs Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article‚Äôs Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.&lt;/p&gt;
    &lt;head rend="h2"&gt;About this article&lt;/head&gt;
    &lt;head rend="h3"&gt;Cite this article&lt;/head&gt;
    &lt;p&gt;Rodr√≠guez-Veiga, P., Carreiras, J.M.B., Quegan, S. et al. Loss of tropical moist broadleaf forest has turned Africa‚Äôs forests from a carbon sink into a source. Sci Rep 15, 41744 (2025). https://doi.org/10.1038/s41598-025-27462-3&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Received:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Accepted:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Published:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Version of record:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;DOI: https://doi.org/10.1038/s41598-025-27462-3&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46414443</guid><pubDate>Sun, 28 Dec 2025 20:59:21 +0000</pubDate></item><item><title>MongoBleed Explained Simply</title><link>https://bigdata.2minutestreaming.com/p/mongobleed-explained-simply</link><description>&lt;doc fingerprint="b899ddd9ce0a239a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;MongoBleed explained simply&lt;/head&gt;
    &lt;head rend="h3"&gt;CVE-2025-14847 allows attackers to read any arbitrary data from the database's heap memory. It affects all MongoDB versions since 2017, here's how it works:&lt;/head&gt;
    &lt;p&gt;MongoBleed, officially CVE-2025-14847, is a recently-uncovered extremely sensitive vulnerability affecting basically all versions of MongoDB since ~2017.&lt;/p&gt;
    &lt;p&gt;It is a bug in the zlib1 message compression path in MongoDB.&lt;/p&gt;
    &lt;p&gt;It allows an attacker to read off any uninitialized heap memory, meaning anything that was allocated to memory from a previous database operation could be read.&lt;/p&gt;
    &lt;p&gt;The bug was introduced in 20172. It is dead-easy to exploit - it only requires connectivity to the database (no auth needed). It is fixed as of writing, but some EOL versions (3.6, 4.0, 4.2) will not get it.&lt;/p&gt;
    &lt;head rend="h1"&gt;MongoDB Basics&lt;/head&gt;
    &lt;p&gt;Let‚Äôs get a few basics out of the way before we explain the bug:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;MongoDB uses its own TCP wire protocol instead of e.g HTTP. This is standard for databases, especially ones chasing high performance.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mongo uses the BSON format for messages3. It‚Äôs basically binary json but with some key optimizations. We will talk about one later because it is essential to the exploit.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mongo doesn‚Äôt have endpoints or RPCs. It only uses a single op code called OP_MSG.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The OP_MSG command contains a BSON message. The contents of the message denote what type of request it is. Concretely, it‚Äôs the first field of the message that marks the request type. 4&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The request can be compressed. In that case, an OP_COMPRESSED message is sent which wraps the now-compressed OP_MSG BSON.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The request then looks like this:&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;     OP_COMPRESSED message
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ standard header (16 bytes) ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ originalOpcode (int32)     ‚îÇ
‚îÇ uncompressedSize (int32)   ‚îÇ
‚îÇ compressorId (int8)        ‚îÇ
‚îÇ compressed OP payload      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Critically, the&lt;/p&gt;&lt;code&gt;uncompressedSize&lt;/code&gt;field denotes how large the payload is once it‚Äôs uncompressed.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Exploit Part 1&lt;/head&gt;
    &lt;p&gt;The first part of the exploit is to get the server to wrongfully think that an overly-large OP_MSG is coming.&lt;/p&gt;
    &lt;p&gt;An attacker can send a falsefully large &lt;code&gt;`uncompressedSize`&lt;/code&gt; field, say 1MB5, when in reality the underlying message is 1KB uncompressed. &lt;/p&gt;
    &lt;p&gt;This will make the server allocate a 1MB buffer in memory to decompress the message into. This is fine.&lt;/p&gt;
    &lt;p&gt;The critical bug here is that, once finished decompressing, the server does NOT check the actual resulting size of the newly-uncompressed payload.&lt;/p&gt;
    &lt;p&gt;Instead, it trusts the user‚Äôs input and uses that as the canonical size of the payload, even if it got a different number.6&lt;/p&gt;
    &lt;p&gt;The result is an in-memory representation of the BSON message which looks something like this:&lt;/p&gt;
    &lt;code&gt;[ 1KB of REAL DATA |      999KB of UNREFERENCED HEAP GARBAGE       ]
                   ‚Üë                                               ‚Üë
        actual length (1KB)                     user input length (1MB)&lt;/code&gt;
    &lt;head rend="h3"&gt;Unreferenced Heap Garbage&lt;/head&gt;
    &lt;p&gt;Like in every programming language, when a variables in the code goes out of scope, the runtime marks the memory it previously took up as available.&lt;/p&gt;
    &lt;p&gt;In most modern languages, the memory gets zeroed out. In other words, the old bytes that used to take up the space get deleted.&lt;/p&gt;
    &lt;p&gt;In C/C++, this doesn‚Äôt happen. When you allocate memory via &lt;code&gt;`malloc()`&lt;/code&gt;, you get whatever was previously there.&lt;/p&gt;
    &lt;p&gt;Since Mongo is writen in C++, that unreferenced heap garbage part can represent anything that was in memory from previous operations, including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Cleartext passwords and credentials&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Session tokens / API keys&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Customer data and PII&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Database configs and system info&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Docker paths and client IP addresses&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;[ REAL BSON DATA | password: 123 | apiKey: jA2sa | ip: 219.117.127.202 ]&lt;/code&gt;
    &lt;head rend="h1"&gt;Exploit Part 2&lt;/head&gt;
    &lt;p&gt;Now that the server has wrongfully allocated some potentially-sensitive data to the input message, the only thing left for the attacker is to somehow get the server return the data.&lt;/p&gt;
    &lt;head rend="h3"&gt;BSON&lt;/head&gt;
    &lt;p&gt;As mentioned, BSON is Mongo‚Äôs way of serializing JSON. As mentioned on its site, it was designed with efficiency in mind:&lt;/p&gt;
    &lt;quote&gt;
      &lt;head&gt;3. Efficient&lt;/head&gt;
      &lt;p&gt;Encoding data to BSON and decoding from BSON can be performed very quickly in most languages due to the use of C data types.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;C Strings&lt;/head&gt;
    &lt;p&gt;C famously uses null-terminated strings7. A null-terminated string means that a null byte is used to mark the end of the string:&lt;/p&gt;
    &lt;code&gt;char* s = "hello"
// in memory, this is represented as an array of characters with the last element being the null terminator: h e l l o \0&lt;/code&gt;
    &lt;p&gt;The way such strings get parsed is very simple - the deserializer reads every character until it finds a null terminator.&lt;/p&gt;
    &lt;head rend="h3"&gt;Malicious BSON Input&lt;/head&gt;
    &lt;p&gt;If you recall, I said earlier that the first field of the BSON message denotes what type of ‚ÄúRPC‚Äù the command is.&lt;/p&gt;
    &lt;p&gt;As such, the first thing a server does when handling an incoming message over the wire is‚Ä¶ parse the first field!&lt;/p&gt;
    &lt;p&gt;Because fields are strings, and strings are null-terminated CStrings, the deserializing logic in the MongoDB server parses the field until the first null terminator found.&lt;/p&gt;
    &lt;p&gt;An attacker can send a compressed, invalid BSON object that does NOT contain a null terminator. This forces the server to continue scanning through foreign data in the wrongly-allocated memory buffer until it finds the first null terminator (\0)&lt;/p&gt;
    &lt;code&gt;# Conceptual
[ REAL DATA |             UNREFERENCED HEAP GARBAGE                 ]
# Practical Example
[ { "a      | password: 123\0 | apiKey: jA2sa | ip: 219.117.127.202 ]&lt;/code&gt;
    &lt;p&gt;As the first null terminator is right after the password, the server would now think that the first field of the BSON is:&lt;/p&gt;
    &lt;code&gt;"a      | password: 123"&lt;/code&gt;
    &lt;p&gt;Obviously that is an invalid BSON field, so the server responds with an error to the client. In order to be helpful, the response contains an error message that shows which field was invalid:&lt;/p&gt;
    &lt;code&gt;{
  "ok": 0,
  "errmsg": "invalid BSON field name 'a      | password: 123'",
  "code": 2,
  "codeName": "BadValue"
}&lt;/code&gt;
    &lt;p&gt;Boom. The attacker successfully got the server to leak data to it.&lt;/p&gt;
    &lt;p&gt;Any serious attacker would then run this over and over again, thousands of time a second, until they believe they‚Äôve scanned the majority of the database‚Äôs heap. They can then repeat this ad infinitum.&lt;/p&gt;
    &lt;head rend="h1"&gt;üí• Impact&lt;/head&gt;
    &lt;head rend="h3"&gt;1. Ease of Exploitation - ‚ÄúPre-Auth‚Äù&lt;/head&gt;
    &lt;p&gt;The impact of this is particularly nasty, because the request-response parsing cycle happens before any authentication can be made. This makes sense, since you cannot begin to authenticate a request you still haven‚Äôt deserialized.&lt;/p&gt;
    &lt;p&gt;This allows any attacker to gain access to any piece of potentially-sensitive data. The only thing they need is internet access to the database.&lt;/p&gt;
    &lt;p&gt;Exposing your database to the internet is a practice that‚Äôs heavily frowned upon8. At the same time, Shodan shows that there are over 213,000 publicly-accessible Mongo databases.&lt;/p&gt;
    &lt;head rend="h3"&gt;2. Eight Years of Vulnerability (handled badly)&lt;/head&gt;
    &lt;p&gt;The PR that introduced the bug was from May 2017. This means that, roughly from version 3.6.0, any publicly-accessible MongoDB instance has been vulnerable to this.&lt;/p&gt;
    &lt;p&gt;It is unknown whether the exploit was known and exploited by actors prior to its disclosure. Given the simplicity of it, I bet it was.&lt;/p&gt;
    &lt;p&gt;As of the exploit‚Äôs disclosure, which happened on 19th of December, it has been a race to patch the database.&lt;/p&gt;
    &lt;p&gt;Sifting through Git history, it seems like the fix was initially committed on the 17th of December. Interestingly enough, it was only merged a full 5 days after - on the 22nd of December (1-line fix btw).&lt;/p&gt;
    &lt;p&gt;That beig said, MongoDB 8.0.17 containing the fix was released on Dec 19, consistent with the CVE publish data. But JIRA activity shows that patches went out on the 22nd of December.&lt;/p&gt;
    &lt;p&gt;Because there‚Äôs no official timeline posted, members of the community like me have to guess. As of writing, 10 days later in Dec 28, 2025, Mongo have still NOT properly addressed the issue publicly.&lt;/p&gt;
    &lt;p&gt;They only issued a community disclosure of the CVE a full five days after the publication of it. It is then, on the 24th of December, that they announced that all of their database instances in their cloud service Atlas were fully patched.&lt;/p&gt;
    &lt;p&gt;I believe this implies that all Atlas databases exposed to the internet were vulnerable to this issue for almost a week. By default, Atlas databases use an IP allowlist for connectivity. But users could configure it to allow connections from anywhere.&lt;/p&gt;
    &lt;p&gt;Mongo says that they haven‚Äôt verified exploitation so far:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚Äúat this time, we have no evidence that this issue has been exploited or that any customer data has been compromised‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;3. Ease of Mitigation&lt;/head&gt;
    &lt;p&gt;Mitigation is admittedly very easy, you have one of two choices:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Update to the newest patch&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Disable zlib network compression&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I found the latter wasn‚Äôt circulated a lot in online talk, but I understand is just as good as a short-term mitigation.&lt;/p&gt;
    &lt;head rend="h1"&gt;A bit of Drama?&lt;/head&gt;
    &lt;p&gt;The tech lead for Security at Elastic coined the name MongoBleed by posting a Python script that acts as a proof of concept to exploiting the vulnerability: https://github.com/joe-desimone/mongobleed&lt;/p&gt;
    &lt;p&gt;This is particularly interesting, because despite being different systems, Mongo competes with Elastic on Vector Search, Text Search and Analytical use cases.&lt;/p&gt;
    &lt;head rend="h1"&gt;Summary&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The exploit allows attackers to read arbitrary heap data, including user data, plaintext passwords, api keys/secrets, and more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;It is performed by leveraging a simple, malformed zlib-compressed request.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;MongoDB versions from 2017-2025 are vulnerable to this exploit.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Rough timeline:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;June 1, 2017: Commit introducing the bug gets merged.&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Dec 17, 2025: Code for the fix is written (original commit date).&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Dec 19, 2025: CVE officially published.&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Dec 22, 2025: Code with the fix is merged.&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Dec 24, 2025: MongoDB announce the patch, say all Atlas databases are patched.&lt;/p&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;On Dec 24th, MongoDB reported they have no evidence of anybody exploiting the CVE. Given the fact this exploit lived on for ~8 years, and their honey-pot cloud service Atlas took a full 5 days to patch since the official CVE publish date‚Ä¶ I find that hard to believe.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;MongoDB have not apologized yet.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;There are over 213k+ potentially vulnerable internet-exposed MongoDB instances, ensuring that this exploit is web scale:&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Interesting Links&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Official CVE: https://nvd.nist.gov/vuln/detail/CVE-2025-14847 (Dec 19, 2025)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;PR introducing the bug: https://github.com/mongodb/mongo/pull/1152 (May 2017)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Commit fixing the issue: https://github.com/mongodb/mongo/commit/505b660a14698bd2b5233bd94da3917b585c5728#diff-e5f6e2daef81ce1c3c4e9f7d992bd6ff9946b3b4d98a601e4d9573e5ef0cb07dR77&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Security Report on the incident, including fix versions: https://www.ox.security/blog/attackers-could-exploit-zlib-to-exfiltrate-data-cve-2025-14847/&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Write-up on how to detect exploitation attempts via log analysis: https://blog.ecapuano.com/p/hunting-mongobleed-cve-2025-14847&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Somebody also vibe-coded a detector: https://github.com/Neo23x0/mongobleed-detector&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Other Reads You May Like:&lt;/head&gt;
    &lt;p&gt;zlib is a library for compression. It uses the DEFLATE algorithm under the hood, but produces results in a specific wire format to ease sending such data over the wire. (e.g includes metadata like flags, checksums, etc)&lt;/p&gt;
    &lt;p&gt;Here is the PR that introduced it. I‚Äôm not aware of Mongo‚Äôs public review practices, but it appears as if nobody explicitly reviewed the change.&lt;/p&gt;
    &lt;p&gt;They actually created it. There‚Äôs a very good site for it - https://bsonspec.org/&lt;/p&gt;
    &lt;p&gt;Weird, I know. Here are examples of different commands, just so you get a sense:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Insert a document into the users table&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;{
  "insert": "users",
  "documents": [{ "name": "alice", "age": 30 }]
}&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Delete users with&lt;/p&gt;
        &lt;code&gt;inactive=true&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;{
  "delete": "users",
  "deletes": [ { "q": { "inactive": true }, "limit": 0 }]
}&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Check the server‚Äôs status&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;{ "serverStatus": 1 }&lt;/code&gt;
    &lt;p&gt;I‚Äôm making this number up. There is probably some limit on the server side as to how large a request can be - perhaps 1MB is too large.&lt;/p&gt;
    &lt;p&gt;Here is the line (pre-fix): https://github.com/mongodb/mongo/blame/b2f3ca9c996ba409e7d48601fca16c28fd58b774/src/mongo/transport/message_compressor_zlib.cpp#L83&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;`output` &lt;/code&gt;is the large memory buffer that was allocated earlier&lt;/p&gt;
    &lt;p&gt;The code, instead, ought to return the referenced &lt;code&gt;`length`&lt;/code&gt; field, as that gets updated with the actual length that was seen post-compression.&lt;/p&gt;
    &lt;p&gt;This has been the cause of many security issues in the past.&lt;/p&gt;
    &lt;p&gt;The most common comment I saw online is that you ‚Äúdeserved it‚Äù if you exposed your DB to the wild. üòÅ&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46414475</guid><pubDate>Sun, 28 Dec 2025 21:03:03 +0000</pubDate></item><item><title>The Prison of Financial Mediocrity</title><link>https://twitter.com/systematicls/status/2004900241745883205</link><description>&lt;doc fingerprint="d635f48b34542867"&gt;
  &lt;main&gt;
    &lt;p&gt;We‚Äôve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.&lt;/p&gt;
    &lt;p&gt;Help Center&lt;/p&gt;
    &lt;p&gt;Terms of Service Privacy Policy Cookie Policy Imprint Ads info ¬© 2025 X Corp.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46414611</guid><pubDate>Sun, 28 Dec 2025 21:17:12 +0000</pubDate></item><item><title>Software engineers should be a little bit cynical</title><link>https://www.seangoedecke.com/a-little-bit-cynical/</link><description>&lt;doc fingerprint="2c3f995c3e160190"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Software engineers should be a little bit cynical&lt;/head&gt;
    &lt;p&gt;A lot of my readers call me a cynic when I say things like ‚Äúyou should do things that make your manager happy‚Äù or ‚Äúbig tech companies get to decide what projects you work on‚Äù. Alex Wennerberg put the ‚ÄúSean Goedecke is a cynic‚Äù case well in his post Software Engineers Are Not Politicians. Here are some excerpts:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I have no doubt that [Sean‚Äôs] advice is quite effective for navigating the upper levels of an organization dedicated to producing a large, mature software product. But what is lost is any sort of conception of value. Is it too naive to say that engineers are more than ‚Äútools in a political game‚Äù, they are specialized professionals whose role is to apply their expertise towards solving meaningful problems?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;The irony is that this kind of thinking destroys a company‚Äôs ability to actually make money ‚Ä¶ the idea that engineers should begin with a self-conception of doing what their manager tells them to is, to me, very bleak. It may be a good way to operate smoothly within a bureaucratic organization, and of course, one must often make compromises and take direction, but it is a bad way to do good work.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I can see why people would think this way. But I love working in big tech companies! I do see myself as a professional solving meaningful problems. And I think navigating the organization to put real features or improvements in the hands of users is an excellent way - maybe the best way - to do good work.&lt;/p&gt;
    &lt;p&gt;Why do I write such cynical posts, then? Well, I think that a small amount of cynicism is necessary in order to think clearly about how organizations work, and to avoid falling into the trap of being overly cynical. In general, I think good engineers ought to be a little bit cynical.&lt;/p&gt;
    &lt;head rend="h3"&gt;The idealist view is more cynical than idealists think&lt;/head&gt;
    &lt;p&gt;One doctrinaire ‚Äúidealist‚Äù view of software engineering goes something like this. I‚Äôm obviously expressing it in its most lurid form, but I do think many people believe this more or less literally:1&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We live in a late-stage-capitalist hellscape, where large companies are run by aspiring robber barons who have no serious convictions beyond desiring power. All those companies want is for obedient engineering drones to churn out bad code fast, so they can goose the (largely fictional) stock price. Meanwhile, end-users are left holding the bag: paying more for worse software, being hassled by advertisements, and dealing with bugs that are unprofitable to fix. The only thing an ethical software engineer can do is to try and find some temporary niche where they can defy their bosses and do real, good engineering work, or to retire to a hobby farm and write elegant open-source software in their free time.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;When you write it all out, I think it‚Äôs clear to see that this is incredibly cynical. At the very least, it‚Äôs a cynical way to view your coworkers and bosses, who are largely people like you: doing a job, balancing a desire to do good work with the need to please their own bosses. It‚Äôs a cynical way to view the C-staff of a company. I think it‚Äôs also inaccurate: from my limited experience, the people who run large tech companies really do want to deliver good software to users.&lt;/p&gt;
    &lt;p&gt;It‚Äôs idealistic only in the sense that it does not accept the need for individual software engineers to compromise. According to this view, you never need to write bad software. No matter how hard the company tells you to compromise and just get something out, you‚Äôre morally required to plant your feet and tell them to go to hell. In fact, by doing so, you‚Äôre taking a stand against the general degeneration of the modern software world. You‚Äôre protecting - unsung, like Batman - the needs of the end-user who will never know you exist.&lt;/p&gt;
    &lt;p&gt;I can certainly see the appeal of this view! But I don‚Äôt think it‚Äôs an idealistic appeal. It comes from seeing the world as fundamentally corrupted and selfish, and believing that real positive change is impossible. In other words, I think it‚Äôs a cynical appeal.&lt;/p&gt;
    &lt;head rend="h3"&gt;The cynical view is more idealistic than idealists think&lt;/head&gt;
    &lt;p&gt;I don‚Äôt see a hard distinction between engineers being ‚Äútools in a political game‚Äù and professionals who solve meaningful problems. In fact, I think that in practice almost all meaningful problems are solved by playing political games.&lt;/p&gt;
    &lt;p&gt;There are very few problems that you can solve entirely on your own. Software engineers encounter more of these problems than average, because the nature of software means that a single engineer can have huge leverage by sitting down and making a single code change. But in order to make changes to large products - for instance, to make it possible for GitHub‚Äôs 150M users to use LaTeX in markdown - you need to coordinate with many other people at the company, which means you need to be involved in politics.&lt;/p&gt;
    &lt;p&gt;It is just a plain fact that software engineers are not the movers and shakers in large tech organizations. They do not set the direction of the company. To the extent that they have political influence, it‚Äôs in how they translate the direction of the company into specific technical changes. But that is actually quite a lot of influence!&lt;/p&gt;
    &lt;p&gt;Large tech companies serve hundreds of millions (or billions) of users. Small changes to these products can have a massive positive or negative effect in the aggregate. As I see it, choosing to engage in the messy, political process of making these changes - instead of washing your hands of it as somehow impure - is an act of idealism.&lt;/p&gt;
    &lt;p&gt;I think the position of a software engineer in a large tech company is similar to people who go into public service: idealistically hoping that they can do some good, despite knowing that they themselves will never set the broad strokes of government policy.&lt;/p&gt;
    &lt;p&gt;Of course, big-tech software engineers are paid far better, so many people who go into this kind of work in fact are purely financially-motivated cynics. But I‚Äôm not one of them! I think it‚Äôs possible, by doing good work, to help steer the giant edifice of a large tech company for the better.&lt;/p&gt;
    &lt;head rend="h3"&gt;Cynicism as inoculation&lt;/head&gt;
    &lt;p&gt;Cynical writing is like most medicines: the dose makes the poison. A healthy amount of cynicism can serve as an inoculation from being overly cynical.&lt;/p&gt;
    &lt;p&gt;If you don‚Äôt have an slightly cynical explanation for why engineers write bad code in large tech companies - such as the one I write about here - you risk adopting an overly cynical one. For instance, you might think that big tech engineers are being deliberately demoralized as part of an anti-labor strategy to prevent them from unionizing, which is nuts. Tech companies are simply not set up to engage in these kind of conspiracies.&lt;/p&gt;
    &lt;p&gt;If you don‚Äôt have a slightly cynical explanation for why large tech companies sometimes make inefficient decisions - such as this one - you risk adopting an overly cynical one. For instance, you might think that tech companies are full of incompetent losers, which is simply not true. Tech companies have a normal mix of strong and weak engineers.&lt;/p&gt;
    &lt;head rend="h3"&gt;Final thoughts&lt;/head&gt;
    &lt;p&gt;Idealist writing is massively over-represented in writing about software engineering. There is no shortage of books or blog posts (correctly) explaining that we ought to value good code, that we ought to be kind to our colleagues, that we ought to work on projects with positive real-world impact, and so on. There is a shortage of writing that accurately describes how big tech companies operate.&lt;/p&gt;
    &lt;p&gt;Of course, cynical writing can harm people: by making them sad, or turning them into bitter cynics. But idealist writing can harm people too. There‚Äôs a whole generation of software engineers who came out of the 2010s with a factually incorrect model of how big tech companies work, and who are effectively being fed into the woodchipper in the 2020s. They would be better off if they internalized a correct model of how these companies work: not just less likely to get into trouble, but better at achieving their own idealist goals2.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;I don‚Äôt think I‚Äôm strawmanning here - I‚Äôve seen many people make all of these points in the past, and I suspect at least some readers will be genuinely nodding along to the following paragraph. If you‚Äôre one of those readers (or if you only agree with about 50%), consider doing me a favor and emailing me to let me know! If I don‚Äôt get any emails I will probably rewrite this.&lt;/p&gt;‚Ü©&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;For some concrete details on this, see my post How I influence tech company politics as a staff software engineer. Also, if you‚Äôre interested, I wrote a much less well-developed version of this post right at the start of 2024, called Is it cynical to do what your manager wants?.&lt;/p&gt;‚Ü©&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you liked this post, consider subscribing to email updates about my new posts, or sharing it on Hacker News. Here's a preview of a related post that shares tags with this one.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;You can't design software you don't work on&lt;/p&gt;&lt;p&gt;Only the engineers who work on a large software system can meaningfully participate in the design process. That‚Äôs because you cannot do good software design without an intimate understanding of the concrete details of the system. In other words, generic software design advice is typically useless for most practical software design problems.&lt;/p&gt;&lt;p&gt;What is generic software design? It‚Äôs ‚Äúdesigning to the problem‚Äù: the kind of advice you give when you have a reasonable understanding of the domain, but very little knowledge of the existing codebase. Unfortunately, this is the only kind of advice you‚Äôll read in software books and blog posts. Engineers love giving generic software design advice for the same reason that all technical professionals love ‚Äútalking shop‚Äù. However, you should be very careful about applying generic advice to your concrete day-to-day work problems.&lt;/p&gt;&lt;lb/&gt;Continue reading...&lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46414723</guid><pubDate>Sun, 28 Dec 2025 21:29:32 +0000</pubDate></item></channel></rss>