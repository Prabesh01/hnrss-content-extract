<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 24 Oct 2025 21:09:01 +0000</lastBuildDate><item><title>When is it better to think without words?</title><link>https://www.henrikkarlsson.xyz/p/wordless-thought</link><description>&lt;doc fingerprint="7519513caab092d0"&gt;
  &lt;main&gt;
    &lt;head rend="h6"&gt;Portrait of a Man with Glasses I, Francis Bacon, 1963&lt;/head&gt;
    &lt;p&gt;This essay can be read as a complement to last year’s “How to think in writing.”&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Thoughts die the moment they are embodied in words.&lt;/p&gt;&lt;lb/&gt;—Schopenhauer&lt;/quote&gt;
    &lt;head rend="h4"&gt;1.&lt;/head&gt;
    &lt;p&gt;In the 1940s, when the French mathematician Jacques Hadamard asked good mathematicians how they came up with solutions to hard problems, they nearly universally answered that they didn’t think in words; neither did they think in images or equations. Rather, what passed through the mathematicians as they struggled with problems were such things as vibrations in their hands, nonsense words in their ears, or blurry shapes in their heads.1&lt;/p&gt;
    &lt;p&gt;Hadamard, who had the same types of experiences, wrote in The Psychology of Invention in the Mathematical Field that this mode of thinking was distinct from daydreaming, and that most people, though they often think wordlessly, have never experienced the kind of processing that the mathematicians did.&lt;/p&gt;
    &lt;p&gt;When I read this, in December 2024, all sorts of questions arose in me. First of all, what does it even mean? Do they not think in words and equations at all? And secondly, how do I square this with my personal experience, which is that whenever I write what I think about a subject, it always turns out that my thoughts do not hold up on paper? No matter how confident I am in my thoughts, they reveal themselves on the page as little but logical holes, contradictions, and non sequiturs.&lt;/p&gt;
    &lt;p&gt;I recognize myself when Paul Graham writes:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The reason I’ve spent so long establishing [that writing helps you refine your thinking] is that it leads to another [point] that many people will find shocking. If writing down your ideas always makes them more precise and more complete, then no one who hasn’t written about a topic has fully formed ideas about it. And someone who never writes has no fully formed ideas about anything nontrivial.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;How come Hadamard’s colleagues are able to have productive thoughts, working in their heads, without words, sometimes, for days on end?&lt;/p&gt;
    &lt;head rend="h2"&gt;Tense subconscious processing&lt;/head&gt;
    &lt;p&gt;Hadamard’s book is most famous for its detailed discussion of what Henri Poincaré called the “sudden illumination”—the moment when the solution to a problem emerges “in the shower” unexpectedly after a long period of unconscious incubation.&lt;/p&gt;
    &lt;p&gt;The hypothesis here is that if you work hard on a problem, you soak your subconscious with it. Wrestling with a problem helps you build a mental model of what you know and what you don’t—providing the subconscious with building blocks to work with. (You can’t have genuine intuition and inspiration in areas where you lack knowledge.) Then, once you drop the problem from conscious thought and go take care of the dishes or something, the subconscious begins a silent and parallelized search, trying many, many alternatives (in a somewhat random fashion), until something snaps in place. When this happens, the solution bubbles back up to the conscious mind, as if out of nowhere, making you freeze mid-motion with a stack of dirty plates in your hands.&lt;/p&gt;
    &lt;p&gt;This is a very useful thing to know about the mind, because it means you can steer your subconscious towards the particular problems you want it to work on. By priming yourself with important problems before doing the dishes or going for walks or sleeping, you make sure your mental resources are used on what matters for you, instead of, for example, the open loops in a Netflix series you watched before bed. It is free labor.&lt;/p&gt;
    &lt;p&gt;But—this is not what Hadamard is talking about when he describes the wordless thought of the mathematicians and researchers he has surveyed. Instead, what they seem to be doing is something similar to this subconscious, parallelized search, except they do it in a “tensely” focused way.&lt;/p&gt;
    &lt;p&gt;The impression I get is that Hadamard loads a question into his mind (either in a non-verbal way, or by reading a mathematical problem that has been written by himself or someone else), and then he holds the problem effortfully centered in his mind. Effortfully, but wordlessly, and without clear visualizations. Describing the mental image that filled his mind while working on a problem concerning infinite series for his thesis, Hadamard writes that his mind was occupied by an image of a ribbon which was thicker in certain places (corresponding to possibly important terms). He also saw something that looked like equations, but as if seen from a distance, without glasses on: he was unable to make out what they said.&lt;/p&gt;
    &lt;p&gt;I’m not sure what is going on here. But here’s a speculation. As I understand it, when one part of our brain is working, it often inhibits another—if you put words to distressing feelings, for example, the language-oriented parts of your brain inhibit the amygdala, which reduces the emotional distress. Similarly, when you are focused on a task at hand, the executive control network of your brain will tend to inhibit the default mode network which is responsible for mind wandering. (This might explain why illuminations tend to occur mainly in the shower, when the executive control networks downregulate and the mind is allowed to wander.)&lt;/p&gt;
    &lt;p&gt;Here’s my speculation: perhaps Hadamard and the other great mathematicians are able to enter into a modality of thought where they are able to keep both the default mode network and the executive control network on at the same time. Perhaps this allows them to do a sort of subconscious, in-the-shower-type processing, while still maintaining enough conscious focus to ensure the thoughts don’t drift away from the problem and its constraints.&lt;/p&gt;
    &lt;p&gt;When I look into this, I notice that there is research indicating that when doing certain types of creative work, the default mode network and the executive control network are, indeed, active at the same time, which they usually aren’t. Individuals who are experienced in a creative field seem to have the capacity to keep the default mode network turned on, allowing them to generate many permutations of ideas, while steering it with the executive control network, ensuring their parallelized mindwandering is constrained by the facts of the problem. I suspect we are all capable of this to some extent, but doing it to the extent Hadamard’s subjects did is akin to a ballerina spinning on her toes: a mental posture that requires serious practice to develop the necessary muscles and coordination.&lt;/p&gt;
    &lt;p&gt;I’m not well-versed in neuroscience enough to know if I’m interpreting this right; I’m just speculating.&lt;/p&gt;
    &lt;p&gt;But what we do know is that Hadamard, as he worked, would pace up and down his room with what “witnesses to [his] daily life and work” called his “inside” look. (Others, like Poincaré and Helmholtz, seem to have sat at their desks, staring into nowhere.) And this type of deep, consciously-blurry concentration could go on for a long time: Hadamard mentions that he only stopped walking if he needed to write down a proof (reluctantly). An acquaintance writes that a friend of his shared an office with one of the best now living physicists; this physicist’s work habit was to come into the office in the morning and then stare into the wall for 8 hours before going home. Imagine holding a productive thought for that long without writing any steps down and, presumably, without even compressing things into words inside your head!&lt;/p&gt;
    &lt;head rend="h2"&gt;The interplay between writing and non-linguistic thinking&lt;/head&gt;
    &lt;p&gt;Hadamard writes that he sometimes used algebraic signs when dealing with easy calculations, but adds that, “whenever the matter looks more difficult, they become too heavy a baggage for me.”&lt;/p&gt;
    &lt;p&gt;Why are words too heavy?&lt;/p&gt;
    &lt;p&gt;Reasoning from my experience, I suspect it is because words are laborious. When we put words to a thought, we have to compress something that is like a web in our mind, filled with connections and associations going in all directions, turning that web into a sequential string of words; we have to compress what is high-dimensional into something low-dimensional. This has all sorts of advantages, which I will return to, but the point I want to emphasize here is that compression is effortful. It takes intense concentration to find the right words (rather than the sloppy ones that first come to mind), and then to put them in the proper order. As James Joyce said to his friend when he was asked why he looked so gloomy, “I’ve only written seven words today…” “But why then are you in despair—seven words is a lot for you!” “I don’t know in which order to put them…”&lt;/p&gt;
    &lt;p&gt;If we can avoid the compression step, and do the manipulations directly in the high-dimensional, non-linguistic, conceptual space, we can move much faster.2&lt;/p&gt;
    &lt;p&gt;But this is a big if. Most people, myself included, have too weak mental models to do this kind of processing for complex problems, and so, our thoughts are riddled with contradictions and holes that we often don’t notice unless we try to write them down. We can move faster in wordless thought, but we’re moving at random. If, however, you have deep expertise in an area, like the mathematicians, it is possible to let go of the language compression and do a much faster search. M, who started his career as a physicist, tells me that when he was 13 and read that Einstein thought without words, he felt disappointed since his mind didn’t work like that; then, “a decade and many thousands of hours of mathematics and physics later,” he reread the passage and recognized himself almost completely. I guess this was because the labor of learning mathematics, done largely through reading and writing his way through complex ideas and problems, had given him deep enough mental models to make words somewhat superfluous.&lt;/p&gt;
    &lt;p&gt;But even then, as Hadamard notes, writing is a necessary step of the process. The insights arrived at wordlessly need to be submitted to the rigor of mathematical notation and logic, to test their validity. It is a sort of feedback mechanism: unless the intuition holds up on the page, it is a false intuition.&lt;/p&gt;
    &lt;p&gt;The written results also work as relay results. By writing something down and making sure it is solid, we can offload that thought from working memory and instead use it as a building block for the next step of the thought. Or, to use a metaphor by the mathematician William Hamilton, deep thinking is like building a tunnel through a sandbank:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In this operation, it is impossible to succeed unless every foot, nay, almost every inch in our progress be secured by an arch of masonry before we attempt the excavation of another. Now, language is to the mind precisely what the arch is to the tunnel. The power of thinking and the power of excavation are not dependent on the words in the one case, on the mason-work in the other; but without these subsidiaries, neither process could be carried on beyond its rudimentary commencement.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;So writing—and reading, seriously, the writings of others—is a way to collect stepping stones: ideas that have been stabilized enough that they can carry us as we walk deeper into the thought space.&lt;/p&gt;
    &lt;p&gt;But this stabilization of meaning can go wrong, too, if we stabilize ideas that aren’t ready to be stabilized yet. When writing, there are all sorts of details that need to be specified for our paragraphs to make sense, and if we don’t know what should go into a sentence, it is all too easy to fill in the uncertain parts with guesses. At least my brain has the most miraculous autocomplete function and supplies me with credible endings to any sentence I start—often credible nonsense. But when the nonsense is there on the page, next to thoughts I’ve settled through hard work, it looks respectable! It often takes considerable work to realize I’ve fooled myself.&lt;/p&gt;
    &lt;p&gt;This was another reason Hadamard’s subjects gave for why they were reluctant to use words: they were afraid of the false precision writing forces onto thinking. They were afraid of premature precision and the confusion it breeds. By thinking in blurry images, or tensions of the hands, or sounds, they could keep their thoughts accurately vague in the areas where there was still uncertainty. They wrote down on paper, as settled, only mostly what was actually known. If you are disciplined, you can write in such a way that you avoid false precision.&lt;/p&gt;
    &lt;p&gt;To sum up: the relationship between verbal thinking and deep wordless concentration is complex.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Non-verbal, blurry thinking is faster and can search in a broader way, but it is more error-prone than verbal thought.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Good writing tends to come from an attempt to capture in words something you understand wordlessly, rather than moving ideas around on the page; but, paradoxically, a generative subconscious is usually one that has been trained by writing and deep reading, which provides the subconscious with relay results and other mental structures necessary for deep thought.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Writing forces precision, which can fool us into locking in details we have no reason to lock in, but written notes (or drawings) are a necessary aid when thinking long chains of thoughts.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Over the last nine months, as I’ve been thinking about this topic, I’ve become more mindful about when words hinder and when they help. I notice that I spend more time in wordless thoughts than I used to. But I’m also more deliberate about using writing to structure my brain so it feeds me better thoughts.&lt;/p&gt;
    &lt;p&gt;As always, a big thank you to the paying subscribers who fund the work on the public essays. I couldn’t do this without you! I also want to thank Johanna Karlsson and Michael Nielsen for discussion about the topic. Esha Rana helped me with the final edit.&lt;/p&gt;
    &lt;p&gt;I can think of examples of mathematicians and physicist for whom this is not true. The first one who comes to mind is Richard Feynman, who said in an interview:&lt;/p&gt;
    &lt;head rend="h5"&gt;Feynman:&lt;/head&gt;
    &lt;p&gt;I actually did the work on the paper.&lt;/p&gt;
    &lt;head rend="h5"&gt;Weiner:&lt;/head&gt;
    &lt;p&gt;That s right. It wasn’t a record of what you had done but it is the work.&lt;/p&gt;
    &lt;head rend="h5"&gt;Feynman:&lt;/head&gt;
    &lt;p&gt;It’s the doing it — it’s the scrap paper.&lt;/p&gt;
    &lt;head rend="h5"&gt;Weiner:&lt;/head&gt;
    &lt;p&gt;Well, the work was done in your head but the record of it is still here.&lt;/p&gt;
    &lt;head rend="h5"&gt;Feynman:&lt;/head&gt;
    &lt;p&gt;No, it’s not a record, not really, it’s working. You have to work on paper and this is the paper. OK?&lt;/p&gt;
    &lt;p&gt;A more technical way of saying this is that our (non-verbal) thoughts seem to behave as vectors; when a cluster of neurons fire together, that pattern is like an address pointing toward a point in a high dimensional space. But when we convert our thoughts to words, we convert that vector into a scalar. I’m not sure if this is true, but here is a paper laying out the argument for why it might be.&lt;/p&gt;
    &lt;p&gt;The discussion of vectors and dimension reduction also has an interesting parallel to an ongoing discussion in AI research. When a large language model calculates what to output, the “thinking” happens in high dimensional space where vectors are passed from layer to layer. At the final layer, that high dimensional representation is collapsed into a token—the written output. When this happens, enormous amounts of information is lost: the residual stream contains over a thousand times more information than gets encoded into the token! That lends some support to the idea that non-verbal (partly unconscious) thinking might be more information rich in humans, too.&lt;/p&gt;
    &lt;p&gt;In reasoning models, where the LLM is encouraged to think for longer, what happens is that this written output—this collapsed thought—is fed back into the model as input, so it can keep thinking about it. It is as if a person were to lose all of their memories and thoughts every few seconds and could only rely on whatever conclusions they had written on a slip of paper; this seems, potentially, like a limited way of thinking. To come around this problem—if it is a problem—one idea that is being explored is to feed the entire vector back into the model as a chain of thought, instead of the tokens on the scratch pad. This would be something like letting the models think in a non-verbal mental space, akin to what Hadamard described—thinking in the latent space, rather than on the scratch pad.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45687441</guid><pubDate>Thu, 23 Oct 2025 21:26:57 +0000</pubDate></item><item><title>/dev/null is an ACID compliant database</title><link>https://jyu.dev/blog/why-dev-null-is-an-acid-compliant-database/</link><description>&lt;doc fingerprint="8812dd1940f64a11"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Atomicity&lt;/head&gt;
    &lt;p&gt;Operations are "all or nothing."&lt;/p&gt;
    &lt;p&gt;Anything you write to &lt;code&gt;/dev/null&lt;/code&gt; disappears entirely. There's no partial write problem: it’s either written (and discarded) or not written at all. ✅&lt;/p&gt;
    &lt;head rend="h2"&gt;Consistency&lt;/head&gt;
    &lt;p&gt;The system transitions from one valid state to another.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;/dev/null&lt;/code&gt; always stays in a consistent state (empty). No matter what you write, the invariant "file contains nothing" always holds. ✅&lt;/p&gt;
    &lt;head rend="h2"&gt;Isolation&lt;/head&gt;
    &lt;p&gt;Concurrent transactions don’t interfere with each other.&lt;/p&gt;
    &lt;p&gt;Multiple processes can write to &lt;code&gt;/dev/null&lt;/code&gt; at the same time, and their outputs never conflict, because nothing is ever stored. ✅&lt;/p&gt;
    &lt;head rend="h2"&gt;Durability&lt;/head&gt;
    &lt;p&gt;Once a transaction is committed, it remains so, even after crashes.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;/dev/null&lt;/code&gt; "durably" commits your data into nothingness. After a crash or reboot, it still contains exactly what it always has: nothing. ✅&lt;/p&gt;
    &lt;p&gt;There is only 1 small problem though, it only comes with 0b of free storage. For more space, you will have to contact entreprise sales, which is actually just me!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45687458</guid><pubDate>Thu, 23 Oct 2025 21:28:02 +0000</pubDate></item><item><title>Counter-Strike's player economy is in a freefall</title><link>https://www.polygon.com/counter-strike-cs-player-economy-multi-billion-dollar-freefall/</link><description>&lt;doc fingerprint="b660f151878bcf98"&gt;
  &lt;main&gt;
    &lt;p&gt;Counter-Strike has long been known for two things: tight tactical FPS gameplay and a thriving player marketplace effectively valued at literal billions of dollars. Now, thanks to a recent update from Valve, the latter is in a downward spiral, having lost 25% of its value — or $1.75 billion — overnight.&lt;/p&gt;
    &lt;p&gt;First, some context. Counter-Strike is a free-to-play multiplayer shooter. As with most other F2P games, it generates revenue from selling cosmetics. They arrive in lootbox-like Cases, which are opened by Keys purchased with real-world currency. They can also be obtained through trading with other players and purchasing from Steam Community Market. Beyond Steam, unofficial third-party marketplaces for CS cosmetics have also popped up as channels for buying and selling items.&lt;/p&gt;
    &lt;p&gt;Because items are obtained at random through opening Cases, rarer items fetch the highest value on the open marketplaces. Items of lower-rarity tiers can also be traded in at volume for an item of a higher tier via trade up contracts. Previously, Knives and Gloves could not be obtained through trade up contracts, exponentially increasing their value as highly sought-after items. Prior to the most recent update, some Knives, like a Doppler Ruby Butterfly Knife, could fetch around $20,000 on third-party storefronts like CSFloat.&lt;/p&gt;
    &lt;p&gt;Following Valve's Oct. 22 update to Counter-Strike, the second-highest-tier, Covert (Red), can now be traded up and turned into Knives and Gloves. Essentially, this means that a previously extremely rare and highly sought-after cosmetic is going to be much more obtainable for those who increasingly want it, reducing the value of Knives and Gloves on the open marketplace.&lt;/p&gt;
    &lt;p&gt;And this is where the market descends into a freefall. Now, that Butterfly Knife mentioned above? It's going for around $12,000, as people are essentially dumping their stock, with 15 sold over the past 16 hours at the time of this writing.&lt;/p&gt;
    &lt;p&gt;Bloomberg reported the market for Counter-Strike cosmetic items dropped 25% overnight from Wednesday evening into Thursday morning. It's lost about $1.84 billion in value, according to Pricempire, which tracks and analyses the market for CS items. "This completely changes the supply of Counter-Strike’s most sought-after and expensive tier of items," Pricempire marketing manager Ethan MacDonald told Bloomberg.&lt;/p&gt;
    &lt;p&gt;As sellers attempt to recoup their investments, similar fire sales like the one happening at CSFloat are occurring at other sites. One such site, Skin Port, even put us in a waiting room to access it; traffic was overwhelming its servers.&lt;/p&gt;
    &lt;p&gt;Just like how NFT or cryptocurrency values can drastically shift, Counter-Strike item traders are seeing their stock rapidly change in value, and not for the best. While some items of lower-rarity tiers have gone up in value, and Reds might see a bump now that they can be traded up into Knives and Gloves, that can't make up for the sudden drop at the top of the cosmetics market.&lt;/p&gt;
    &lt;p&gt;We'll have to wait and see if the market levels out or if it continues to crash. Plenty of players and CS traders must be eagerly awaiting more news: As of this writing, Pricempire's servers had crashed.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45689241</guid><pubDate>Fri, 24 Oct 2025 00:24:11 +0000</pubDate></item><item><title>Modern Perfect Hashing</title><link>https://blog.sesse.net/blog/tech/2025-10-23-21-23_modern_perfect_hashing.html</link><description>&lt;doc fingerprint="a7b01034cd082b9d"&gt;
  &lt;main&gt;
    &lt;p&gt;Wojciech Muła posted about modern perfect hashing for strings and I wanted to make some comments about my own implementation (that sadly never got productionized because doubling the speed compared to gperf wasn't really that impactful in the end).&lt;/p&gt;
    &lt;p&gt;First, let's define the problem, just so we're all on the same page; the goal is to create code that maps a known, fixed set of strings to a predefined integer (per string), and rejects everything else. This is essentially the same as a hash table, except that since the set of strings is known ahead of time, we can do better than a normal hash table. (So no “but I heard SwissTables uses SIMD and thus cannot be beat”, please. :-) ) My use case is around a thousand strings or so, and we'll assume that a couple of minutes of build time is OK (shorter would be better, but we can probably cache somehow). If you've got millions of strings, and you don't know them compile-time (for instance because you want to use your hash table in the join phase of a database), see this survey; it's a different problem with largely different solutions.&lt;/p&gt;
    &lt;p&gt;Like Wojciech, I started splitting by length. This means that we can drop all bounds checking after this, memcmp will be optimized by the compiler to use SIMD if relevant, and so on.&lt;/p&gt;
    &lt;p&gt;But after that, he recommends using PEXT (bit extraction, from BMI2), which has two problems: First, the resulting table can get quite big if your input set isn't well-behaved. (You can do better than the greedy algorithm he suggests, but not infinitely so, and finding the optimal mask quickly is sort of annoying if you don't want to embed a SAT solver or something.) Second, I needed the code to work on Arm, where you simply don't have this instruction or anything like it available. (Also, not all x86 has it, and on older Zen, it's slow.)&lt;/p&gt;
    &lt;p&gt;So, we need some other way, short of software emulation of PEXT (which exists, but we'd like to do better), to convert a sparse set of bits into a table without any collisions. It turns out the computer chess community has needed to grapple with this for a long time (they want to convert from “I have a \&lt;code&gt;((value &amp;amp; mask) * magic)&lt;/code&gt;, it is very
likely that the upper bits will be collision-free between your different
&lt;code&gt;value&lt;/code&gt;s if you try enough different numbers for &lt;code&gt;magic&lt;/code&gt;. We can use this
too; for instance, here is code for all length-4 CSS keywords:&lt;/p&gt;
    &lt;quote&gt;static const uint8_t table[] = { 6, 0, 0, 3, 2, 5, 9, 0, 0, 1, 0, 8, 7, 0, 0, }; static const uint8_t strings[] = { 1, 0, 'z', 'o', 'o', 'm', 2, 0, 'c', 'l', 'i', 'p', 3, 0, 'f', 'i', 'l', 'l', 4, 0, 'l', 'e', 'f', 't', 5, 0, 'p', 'a', 'g', 'e', 6, 0, 's', 'i', 'z', 'e', 7, 0, 'f', 'l', 'e', 'x', 8, 0, 'f', 'o', 'n', 't', 9, 0, 'g', 'r', 'i', 'd', 10, 0, 'm', 'a', 's', 'k', }; uint16_t block; memcpy(&amp;amp;block, str + 0, sizeof(block)); uint32_t pos = uint32_t(block * 0x28400000U) &amp;gt;&amp;gt; 28; const uint8_t *candidate = strings + 6 * table[pos]; if (memcmp(candidate + 2, str, 4) == 0) { return candidate[0] + (candidate[1] &amp;lt;&amp;lt; 8); } return 0;&lt;/quote&gt;
    &lt;p&gt;There's a bit to unpack here; we read the first 16 bits from our value with memcpy (big-endian users beware!), multiply it with the magic value &lt;code&gt;0x28400000U&lt;/code&gt; found by trial
and error, shift the top bits down, and now all of our ten candidate
values (“zoom”, “clip”, etc.) have different top four bits. We use that to index
into a small table, check that we got the right one instead of a random collision
(e.g. “abcd”, 0x6261, would get a value of 12, and &lt;code&gt;table[12]&lt;/code&gt; is 7,
so we need to disambiguate that from “flex”, which is what we are actually looking
for in that spot), and then return the 16-bit identifier related to the match (or zero,
if we didn't find it).&lt;/p&gt;
    &lt;p&gt;We don't need to use the first 16 bits; we could have used any other consecutive 16 bits, or any 32 bits, or any 64 bits, or possibly any of those masked off, or even XOR of two different 32-bit sets if need be. My code prefers smaller types because a) they tend to give smaller code size (easier to load into registers, or can even be used as immediates), and b) you can bruteforce them instead of doing random searches (which, not the least, has the advantage that you can give up much quicker).&lt;/p&gt;
    &lt;p&gt;You also don't really need the intermediate table; if the fit is particularly good, you can just index directly into the final result without wasting any space. Here's the case for length-24 CSS keywords, where we happened to have exactly 16 candidates and we found a magic giving a perfect (4-bit) value, making it a no-brainer:&lt;/p&gt;
    &lt;quote&gt;static const uint8_t strings[] = { 95, 0, 'b', 'o', 'r', 'd', 'e', 'r', '-', 'b', 'l', 'o', 'c', 'k', '-', 's', 't', 'a', 'r', 't', '-', 'w', 'i', 'd', 't', 'h', 40, 0, '-', 'w', 'e', 'b', 'k', 'i', 't', '-', 't', 'e', 'x', 't', '-', 'o', 'r', 'i', 'e', 'n', 't', 'a', 't', 'i', 'o', 'n', 115, 1, 's', 'c', 'r', 'o', 'l', 'l', '-', 'p', 'a', 'd', 'd', 'i', 'n', 'g', '-', 'b', 'l', 'o', 'c', 'k', '-', 'e', 'n', 'd', 198, 2, '-', 'w', 'e', 'b', 'k', 'i', 't', '-', 't', 'r', 'a', 'n', 's', 'f', 'o', 'r', 'm', '-', 'o', 'r', 'i', 'g', 'i', 'n', 225, 0, '-', 'i', 'n', 't', 'e', 'r', 'n', 'a', 'l', '-', 'o', 'v', 'e', 'r', 'f', 'l', 'o', 'w', '-', 'b', 'l', 'o', 'c', 'k', 101, 2, '-', 'w', 'e', 'b', 'k', 'i', 't', '-', 'b', 'o', 'r', 'd', 'e', 'r', '-', 'e', 'n', 'd', '-', 's', 't', 'y', 'l', 'e', 93, 0, 'b', 'o', 'r', 'd', 'e', 'r', '-', 'b', 'l', 'o', 'c', 'k', '-', 's', 't', 'a', 'r', 't', '-', 'c', 'o', 'l', 'o', 'r', 102, 2, '-', 'w', 'e', 'b', 'k', 'i', 't', '-', 'b', 'o', 'r', 'd', 'e', 'r', '-', 'e', 'n', 'd', '-', 'w', 'i', 'd', 't', 'h', 169, 1, 't', 'e', 'x', 't', '-', 'd', 'e', 'c', 'o', 'r', 'a', 't', 'i', 'o', 'n', '-', 's', 'k', 'i', 'p', '-', 'i', 'n', 'k', 156, 0, 'c', 'o', 'n', 't', 'a', 'i', 'n', '-', 'i', 'n', 't', 'r', 'i', 'n', 's', 'i', 'c', '-', 'h', 'e', 'i', 'g', 'h', 't', 201, 2, '-', 'w', 'e', 'b', 'k', 'i', 't', '-', 't', 'r', 'a', 'n', 's', 'i', 't', 'i', 'o', 'n', '-', 'd', 'e', 'l', 'a', 'y', 109, 1, 's', 'c', 'r', 'o', 'l', 'l', '-', 'm', 'a', 'r', 'g', 'i', 'n', '-', 'i', 'n', 'l', 'i', 'n', 'e', '-', 'e', 'n', 'd', 240, 0, '-', 'i', 'n', 't', 'e', 'r', 'n', 'a', 'l', '-', 'v', 'i', 's', 'i', 't', 'e', 'd', '-', 's', 't', 'r', 'o', 'k', 'e', 100, 2, '-', 'w', 'e', 'b', 'k', 'i', 't', '-', 'b', 'o', 'r', 'd', 'e', 'r', '-', 'e', 'n', 'd', '-', 'c', 'o', 'l', 'o', 'r', 94, 0, 'b', 'o', 'r', 'd', 'e', 'r', '-', 'b', 'l', 'o', 'c', 'k', '-', 's', 't', 'a', 'r', 't', '-', 's', 't', 'y', 'l', 'e', 196, 2, '-', 'w', 'e', 'b', 'k', 'i', 't', '-', 't', 'e', 'x', 't', '-', 's', 'i', 'z', 'e', '-', 'a', 'd', 'j', 'u', 's', 't', }; uint32_t block; memcpy(&amp;amp;block, str + 16, sizeof(block)); uint32_t pos = uint32_t(block * 0xe330a008U) &amp;gt;&amp;gt; 28; const uint8_t *candidate = strings + 26 * pos; if (memcmp(candidate + 2, str, 24) == 0) { return candidate[0] + (candidate[1] &amp;lt;&amp;lt; 8); } return 0;&lt;/quote&gt;
    &lt;p&gt;You can see that we used a 32-bit value here (bytes 16 through 19 of the input), and a corresponding 32-bit magic (though still not with an AND mask). So we got fairly lucky, but sometimes you do that. Of course, we need to validate the entire 24-byte value even though we only discriminated on four of the bytes! (Unless you know for sure that you never have any out-of-distribution inputs, that is. There are use cases where this is true.)&lt;/p&gt;
    &lt;p&gt;(If you wonder what &lt;code&gt;95, 0&lt;/code&gt; or similar is above; that's just
“the answer the user wanted for that input”. It corresponds to
a 16-bit enum in the parser.)&lt;/p&gt;
    &lt;p&gt;If there are only a few values, we don't need any of this; just like Wojciech, we do with a simple compare. Here's the generated code for all length-37 CSS keywords, plain and simple:&lt;/p&gt;
    &lt;quote&gt;if (memcmp(str, "-internal-inactive-list-box-selection", 37) == 0) { return 171; } return 0;&lt;/quote&gt;
    &lt;p&gt;(Again 171 is “the desired output for that input”, not a value the code generator decides in any way.)&lt;/p&gt;
    &lt;p&gt;So how do we find these magic values? There's really only one way: Try lots of different ones and see if they work. But there's a trick to accelerate “see if they work”, which I also borrowed from computer chess: The killer heuristic.&lt;/p&gt;
    &lt;p&gt;See, to try if a magic is good, you generally try to hash all the different values and see if any two go into the same bucket. (If they do, it's not a perfect hash and the entire point of the exercise is gone.) But it turns out that most of the time, it's the same two values that collide. So every couple hundred candidates, we check which two values disproved the magic, and put those in a slot. Whenever we check magics, we can now try those first, and more likely than not, discard the candidate right away and move on to the next one (whether it is by exhaustive search or randomness). It's actually a significant speedup.&lt;/p&gt;
    &lt;p&gt;But occasionally, we simply cannot find a magic for a given group; either there is none, or we didn't have enough time to scan through enough of the 64-bit space. At this point, Wojciech suggests we switch on one of the characters (heuristically) to get smaller subgroups and try again. I didn't actually find this to perform all that well; indirect branch predictors are better than 20 years ago, but the pattern is typically not that predictable. What I tried instead was to have more of a yes/no on some character (i.e., a non-indirect branch), which makes for a coarser split.&lt;/p&gt;
    &lt;p&gt;It's not at all obvious where the best split would be. You'd intuitively think that 50/50 would be a good idea, but if you have e.g. 40 elements, you'd much rather split them 32/8… if you can find perfect hashes for both subgroups (5-bit and 3-bit, respectively). If not, a 20–20 split is most likely better, since you very easily can find magics that put 20 elements into 32 buckets without collisions. I ended up basically trying all the different splits and scoring them, but this makes the searcher rather slow, and it means you basically must have some sort of cache if you want to run it as part of your build system. This is the part I'm by far the least happy about; gperf isn't great by modern standards, but it never feels slow to run.&lt;/p&gt;
    &lt;p&gt;The end result for me was: Runtime about twice as fast as gperf, compiled code about half as big. That's with everything hard-coded; if you're pushed for space (or are icache-bound), you could make more generic code at the expense of some speed.&lt;/p&gt;
    &lt;p&gt;So, if anyone wants to make a more modern gperf, I guess this space is up for grabs? It's not exactly technology that will make your stock go to AI levels, though.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45689905</guid><pubDate>Fri, 24 Oct 2025 01:59:56 +0000</pubDate></item><item><title>Roc Camera</title><link>https://roc.camera/</link><description>&lt;doc fingerprint="d8c40a7031a4502f"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Photos used to be magic&lt;/head&gt;
    &lt;head rend="h2"&gt;Photosusedtobemagic&lt;/head&gt;
    &lt;p&gt;There was a time when cameras captured magic. Photos told stories of a certain moment in time, a reflection of reality, a physical artifact of lives.&lt;/p&gt;
    &lt;head rend="h2"&gt;AI has blurred the line&lt;/head&gt;
    &lt;head rend="h2"&gt;AIhasblurredtheline&lt;/head&gt;
    &lt;p&gt;Now, how we take, share, and create images has changed. Social media has made sharing images easy. Generative AI now creates any image we can imagine.&lt;/p&gt;
    &lt;head rend="h2"&gt;Lost sight of what is real&lt;/head&gt;
    &lt;head rend="h2"&gt;Lostsightofwhatisreal&lt;/head&gt;
    &lt;p&gt;We've started to lose sight of what is real. We've lost our ability to find our bearings in an endless sea of copies and AI-generated noise.&lt;/p&gt;
    &lt;head rend="h2"&gt;It's time for Roc Camera&lt;/head&gt;
    &lt;head rend="h2"&gt;It'stimeforRocCamera&lt;/head&gt;
    &lt;p&gt;By combining attested sensor data, zero-knowledge proofs, and a tamper-proof environment, we've built Roc Camera to capture verifiably real photos.&lt;/p&gt;
    &lt;head rend="h3"&gt;Camera Components:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;â¢ 4-inch IPS LCD Screen 720x720 with Capacitive Touch&lt;/item&gt;
      &lt;item&gt;â¢ 16MP Sony IMX519 CMOS with 122Â° FOV lens&lt;/item&gt;
      &lt;item&gt;â¢ Raspberry Pi 4 4GB RAM ARM Cortex-A72 1.5 Ghz&lt;/item&gt;
      &lt;item&gt;â¢ LiPo 4000mAh Battery&lt;/item&gt;
      &lt;item&gt;â¢ Uninterruptible Power Supply Board&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Capture&lt;/head&gt;
    &lt;p&gt;Capture a photo that only this Camera can uniquely take&lt;/p&gt;
    &lt;head rend="h3"&gt;Prove&lt;/head&gt;
    &lt;p&gt;Creates a Zero Knowledge (ZK) Proof of the camera sensor data and other metadatas&lt;/p&gt;
    &lt;head rend="h3"&gt;Verify&lt;/head&gt;
    &lt;p&gt;Verify that the photo is real by checking the ZK proof via the Roc Photo SDK&lt;/p&gt;
    &lt;head rend="h2"&gt;Capture verifiably real moments&lt;/head&gt;
    &lt;p&gt;Accepting orders now â (Batch 2)&lt;/p&gt;
    &lt;p&gt;Ships in 2~3 weeks&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45690251</guid><pubDate>Fri, 24 Oct 2025 02:54:29 +0000</pubDate></item><item><title>'Attention is all you need' coauthor says he's 'sick' of transformers</title><link>https://venturebeat.com/ai/sakana-ais-cto-says-hes-absolutely-sick-of-transformers-the-tech-that-powers</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45690840</guid><pubDate>Fri, 24 Oct 2025 04:40:31 +0000</pubDate></item><item><title>Interstellar Mission to a Black Hole</title><link>https://www.centauri-dreams.org/2025/10/23/interstellar-mission-to-a-black-hole/</link><description>&lt;doc fingerprint="b6467ad31861cbdb"&gt;
  &lt;main&gt;
    &lt;p&gt;We normally think of interstellar flight in terms of reaching a single target. The usual destination is one of the Alpha Centauri stars, and because we know of a terrestrial-mass planet there, Proxima Centauri emerges as the best candidate. I don’t recall Proxima ever being named as the destination Breakthrough Starshot officially had in mind, but there is such a distance between it (4.2 light years) and the next target, Barnard’s Star at some 5.96 light years, that it seems evident we will give the nod to Proxima. If, that is, we decide to go interstellar.&lt;/p&gt;
    &lt;p&gt;Let’s not forget, though, that if we build a beaming infrastructure either on Earth or in space that can accelerate a sail to a significant percentage of lightspeed, we can use it again and again. That means many possible targets. I like the idea of exploring other possibilities, which is why Cosimo Bambi’s ideas on black holes interest me. Associated with Fudan University in Shanghai as well as New Uzbekistan University in Tashkent, Bambi has been thinking about the proliferation of black holes in the galaxy, and the nearest one to us. I’ve been pondering his notions ever since reading about them last August.&lt;/p&gt;
    &lt;p&gt;Black holes are obviously hard to find as we scale down to solar mass objects, and right now the closest one to us is GAIA-BH1, some 1560 light years out. But reading Bambi’s most recent paper, I see that one estimate of the number of stellar mass black holes in our galaxy is 1.4 X 109. Bambi uses this number, but as we might expect, estimates vary widely, from 10 million to 1 billion. These numbers are extrapolated from the population of massive stars and to a very limited extent on clues from observational astronomy.&lt;/p&gt;
    &lt;p&gt;Image: The first image of Sagittarius A*, or Sgr A*, the supermassive black hole at the center of our galaxy. Given how hard it was to achieve this image, can we find ways to locate far smaller solar-mass black holes, and possibly send a mission to one? Credit: Event Horizon Telescope Collaboration.&lt;/p&gt;
    &lt;p&gt;Bambi calculates a population of 1 black hole and 10 white dwarfs for every 100 stars in the general population. If he’s anywhere close to right, a black hole might well exist within 20 to 25 light years, conceivably detected in future observations by its effects upon the orbital motion of a companion star, assuming we are so lucky as to find a black hole in a binary system. The aforementioned GAIA-BH1 is in such a system, orbiting a companion star.&lt;/p&gt;
    &lt;p&gt;Most black holes, though, are thought to be isolated. One black hole (OGLE-2011-BLG-0462) has been detected through microlensing, and perhaps LIGO A+, the upgrade to the two LIGO facilities in Hanford, Washington, and Livingston, Louisiana, can help us find more as we increase our skills at detecting gravitational waves. There are other options as well, as Bambi notes:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Murchikova &amp;amp; Sahu (2025) proposed to use observational facilities like the Square Kilometer Array (SKA), the Atacama Large Millimiter/Submillimiter Array (ALMA), and James Webb Space Telescope (JWST). Isolated black holes moving through the interstellar medium can accrete from the interstellar medium itself and such an accretion process produces electromagnetic radiation. Murchikova &amp;amp; Sahu (2025) showed that current observational facilities can already detect the radiation from isolated black holes in the warm medium of the Local Interstellar Cloud within 50 pc of Earth, but their identification as accreting black holes is challenging and requires multi-telescope observations.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;If we do find a black hole out there at, say, 10 light years, we now have a target for future beamed sailcraft that offers an entirely different mission concept. We’re now probing not simply an unknown planet, but an astrophysical object so bizarre that observing its effects on spacetime will be a primary task. Sending two nanocraft, one could observe the other as it approaches the black hole. A signal sent from one to the other will be affected by the spacetime metric – the ‘geometry’ of spacetime – which would give us information about the Kerr solution to the phenomenon. The latter assumes a rotating black hole, whereas other solutions, like that of Schwarzschild, describe a non-rotating black hole.&lt;/p&gt;
    &lt;p&gt;Also intriguing is Bambi’s notion of testing fundamental constants. Does atomic physics change in gravitational fields this strong? There have been some papers exploring possible variations in fundamental constants over time, but little by way of observation studying gravitational fields much stronger than white dwarf surfaces. Two nanocraft in the vicinity of a black hole may offer a way to emit photons whose energies can probe the nature of the fine structure constant. The latter sets the interactions between elementary charged particles.&lt;/p&gt;
    &lt;p&gt;For that matter, is a black hole inevitably possessed of an event horizon, or is it best described as an ‘horizonless compact object’ (Bambi’s term)?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In the presence of an event horizon, the signal from nanocraft B should be more and more redshifted (formally without disappearing, as an observer should never see a test-particle crossing the event horizon in a finite time, but, in practice, at some point the signal leaves the sensitivity band of the receiver on nanocraft A). If the compact object is a Kerr black hole, we can make clear predictions on the temporal evolution of the signal emitted by nanocraft B. If the compact object is a fuzzball [a bound state without event horizon], the temporal evolution of the signal should be different and presumably stop instantly when nanocraft B is converted into fuzzball degrees of freedom.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;There are so many things to learn about black holes that it is difficult to know where to begin, and I suspect that if many of our space probes have returned surprising results (think of the remarkable ‘heart’ on Pluto), a mission to a black hole would uncover mysteries and pose questions we have yet to ask. What an intriguing idea, and to my knowledge, no one else has made the point that if we ever reach the level of launching a mission to Proxima Centauri, we should be capable of engineering the same sort of flyby of a nearby black hole.&lt;/p&gt;
    &lt;p&gt;And on the matter of small black holes, be aware of a just released paper examining the role of dark matter in their formation. This one considers black holes on a much smaller scale, possibly making the chances of finding a nearby one that much greater. Let me quote the abstract (the italics are mine). The citation is below:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Exoplanets, with their large volumes and low temperatures, are ideal celestial detectors for probing dark matter (DM) interactions. DM particles can lose energy through scattering with the planetary interior and become gravitationally captured if their interaction with the visible sector is sufficiently strong. In the absence of annihilation, the captured DM thermalizes and accumulates at the planet’s center, eventually collapsing into black holes (BHs). Using gaseous exoplanets as an example, we demonstrate that BH formation can occur within an observable timescale for superheavy DM with masses greater than 106 GeV and nuclear scattering cross sections. The BHs may either accrete the planetary medium or evaporate via Hawking radiation, depending on the mass of the DM that formed them. We explore the possibility of periodic BH formation within the unconstrained DM parameter space and discuss potential detection methods, including observations of planetary-mass objects, pulsed high-energy cosmic rays, and variations in exoplanet temperatures. Our findings suggest that future extensive exoplanet observations could provide complementary opportunities to terrestrial and cosmological searches for superheavy DM.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The paper is Bambi, “An interstellar mission to test astrophysical black holes,” iScience Volume 28, Issue 8113142 (August 15, 2025). Full text. The paper on black holes and dark matter is Phoroutan-Mehr &amp;amp; Fetherolf, “Probing superheavy dark matter with exoplanets,” Physical Review D Vol. 112 (20 August 2025), 036012 (full text).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45692585</guid><pubDate>Fri, 24 Oct 2025 09:17:24 +0000</pubDate></item><item><title>Debian Technical Committee overrides systemd change</title><link>https://lwn.net/Articles/1041316/</link><description>&lt;doc fingerprint="cecb083ff8077df8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Debian Technical Committee overrides systemd change&lt;/head&gt;
    &lt;quote&gt;LWN.net needs you!&lt;p&gt;Without subscribers, LWN would simply not exist. Please consider signing up for a subscription and helping to keep LWN publishing.&lt;/p&gt;&lt;/quote&gt;
    &lt;p&gt;Debian packagers have a great deal of latitude when it comes to the configuration of the software they package; they may opt, for example, to disable default features in software that they feel are a security hazard. However, packagers are expected to ensure that their packages comply with Debian Policy, regardless of the upstream's preferences. If a packager fails to comply with the policy, the Debian Technical Committee (TC) can step in to override them, which it has done in the case of a recent systemd change that broke several programs that depend on a world-writable /run/lock directory.&lt;/p&gt;
    &lt;p&gt;The Filesystem Hierarchy Standard (FHS) specifies that the /var/lock directory should be used to store lock files for devices and other resources shared by multiple applications. On Debian, /var/lock is a symbolic link to /run/lock. The /run directory is created as a tmpfs filesystem specifically for run-time files by systemd-tmpfiles during system startup.&lt;/p&gt;
    &lt;p&gt;Debian Policy still cites the FHS, even though the FHS has gone unmaintained for more than a decade. The specification was not so much finished as abandoned after FHS 3.0 was released—though there is a slow-moving effort to revive and revise the standard as FHS 4.0, it has not yet produced any results. Meanwhile, in the absence of a current standard, systemd has spun off its file-hierarchy documentation to the Linux Userspace API (UAPI) Group as a specification. LWN covered that development in August, related to Fedora's search for an FHS successor.&lt;/p&gt;
    &lt;head rend="h4"&gt;Locking up /run/lock&lt;/head&gt;
    &lt;p&gt;The /run/lock directory was deprecated in Systemd v258; rather than dropping the directory entirely, though, the project has changed the default to making /run/lock writable only by root, which is stricter than the permissions Debian had shipped with previously &lt;del&gt;rather than making it world-writable as in the past&lt;/del&gt;. The plan is to get rid of /run/lock entirely in the v259 release, though users (or distributions) can still retain the legacy behavior by adding a configuration file in /etc/tmpfiles.d to override systemd's defaults and create the directory with the desired permissions.&lt;/p&gt;
    &lt;p&gt;The Debian project just released a new stable version, Debian 13 ("trixie"), in August, and work has begun on Debian 14 ("forky"). The current stable version of Debian shipped with systemd v257, so users on stable will not be affected by these changes. But v258 has entered Debian unstable where the change to /run/lock broke other software, such as the Unix-to-Unix Copy program (UUCP) and the cu utility. Use of the directory is not limited to vintage utilities; Zbigniew Jędrzejewski-Szmek objected to removing /var/lock in v259 as it would break alsa-utils and create additional work for distributions:&lt;/p&gt;
    &lt;quote&gt;Doing this would this way just creat a foottrap for distributions: if they notice the change, they'll just create a local override, so we get a more complicated system in total with zero benefit to anyone. If they miss it, things will be broken for a while until users report it. And then they'll add the override.&lt;/quote&gt;
    &lt;p&gt;On August 13, Marco d'Itri—who is listed as a maintainer of the systemd package—filed a bug against the uucp package reporting that systemd v258-rc1-1 had broken uucico, along with filing a bug against the systemd package, which cited the FHS entry for /var/lock. He said that a compromise might be to make the directory writable by the dialout group rather than world-writable. He also mentioned that there was a previous effort in 2014 to modernize software that uses UUCP-style locks to use flock() instead, but it stalled out.&lt;/p&gt;
    &lt;head rend="h4"&gt;"Dead and severely outdated"&lt;/head&gt;
    &lt;p&gt;Rather than temporarily reverting the behavior, systemd maintainer Luca Boccassi argued that a world-writable directory in /run is a security risk. Any process could write as much as it wanted to /run, which could effectively DoS the system by exhausting space or inodes; filling up /run would then cause critical services, such as udev, to stop working. The FHS, he said, is "&lt;quote&gt;dead and severely outdated&lt;/quote&gt;".&lt;/p&gt;
    &lt;p&gt;The issue had already been discussed by the systemd project; Lennart Poettering had responded that he did not see the point of /var/lock "&lt;quote&gt;in the modern world&lt;/quote&gt;", but distributions were free to do as they see fit:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Consider this more a passing of the baton from upstream systemd to downstreams: if your distro wants this kind of legacy interface, then just add this via a distro-specific tmpfiles drop-in. But there's no point really in forcing anyone who has a more forward-looking view of the world to still carry that dir.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Poettering argued that distributions could make their own choices, though it made him shudder to think of allowing unprivileged programs to fill up a directory. Boccassi echoed that sentiment in his response to the Debian systemd bug. Any package could ship a configuration for tmpfiles.d to create the directory and assume responsibility for it as well:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I certainly won't try to stop anyone wishing to do it, but also I do not wish for these old workarounds to ship in this package either.&lt;/p&gt;
      &lt;p&gt;There's ~2 years time until Forky ships, and that should be plenty of time to either add this workaround elsewhere, or fix remaining programs to use BSD locks, or both, so I'm not going to hold back the new version from testing for this niche case, sorry.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Boccassi closed the bug with the "WONTFIX" tag.&lt;/p&gt;
    &lt;head rend="h4"&gt;Debian Policy&lt;/head&gt;
    &lt;p&gt;On September 1, d'Itri responded that upstream systemd's opinion was not relevant in this case. Debian policy requires the directory for lock files of serial devices, though he had also opened a bug to revisit that, since the practice of using /var/lock for serial-device locks dates back to the 1980s. However, /var/lock is provided by systemd, so he reasoned that it is a systemd bug unless another package was identified to take ownership of creating the directory. "&lt;quote&gt;But you cannot just decide that the policy violation does not exist.&lt;/quote&gt;"&lt;/p&gt;
    &lt;p&gt;Thorsten Alteholz opened a bug with Debian's Technical Committee on September 15. He asked for advice on how to proceed since the systemd bug had been marked WONTFIX.&lt;/p&gt;
    &lt;quote&gt;So what do you recommend how to go on from here? Change Debian policy (as asked in #1111839), revert the change in systemd, find a Debian wide solution or let every package maintainer implement their own solution?&lt;/quote&gt;
    &lt;p&gt;Bdale Garbee weighed in on the bug as well. He said that he uses cu "&lt;quote&gt;almost constantly for interacting with embedded serial consoles on devices a USB connection away from my laptop&lt;/quote&gt;". He was frustrated with the change imposed by systemd "&lt;quote&gt;with no warning&lt;/quote&gt;", and looked forward to the TC's response.&lt;/p&gt;
    &lt;p&gt;On September 24, Matthew Vernon responded to the bug, with a CC to the systemd maintainer alias. He said that it seemed that Debian Policy required FHS compliance, "&lt;quote&gt;at least until we come up with a transition plan&lt;/quote&gt;", and asked if systemd would please revert the change. There was no response from any of the systemd maintainers.&lt;/p&gt;
    &lt;head rend="h4"&gt;Override&lt;/head&gt;
    &lt;p&gt;Vernon updated the bug on September 29, and said that the TC had discussed the situation at its last meeting. The conclusion was that systemd should comply with policy, and thus FHS. He included a draft ballot text that the TC would vote on, which noted that the committee was "&lt;quote&gt;sympathetic&lt;/quote&gt;" to the argument that flock() would be a better solution, but that "&lt;quote&gt;an important part of the role of a Debian Developer is ensuring that software in Debian complies with Debian Policy&lt;/quote&gt;". A final ballot for the committee to consider was posted on October 2.&lt;/p&gt;
    &lt;p&gt;The ballot contained three options; all three required that the systemd package provide /var/lock "&lt;quote&gt;with relaxed enough permissions that existing Debian software that uses /var/lock for system-wide locks of serial devices (and similar purposes) works again&lt;/quote&gt;". The committee would exercise its power under the Debian Constitution to override the systemd maintainers. The options were:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;1) This change to systemd must persist until a satisfactory migration of impacted software has occurred and Policy updated accordingly.&lt;/p&gt;
      &lt;p&gt;2) This change to systemd must persist until Policy has been updated to allow otherwise.&lt;/p&gt;
      &lt;p&gt;3) This change to systemd must persist until the TC allows otherwise, which the TC expects to do once a suitable transition plan has been agreed.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Vernon replied on October 6 to say that a decision had been reached and that option one had won.&lt;/p&gt;
    &lt;head rend="h4"&gt;Unlocking&lt;/head&gt;
    &lt;p&gt;Debian's continued use of UUCP-style locking does seem to be more than a little bit dated. The FHS 3.0 is clearly reaching the end of its useful life, if not actually expired.&lt;/p&gt;
    &lt;p&gt;As a comparison, Fedora's uucp package has a patch to use lockdev instead. The upcoming Fedora 43 release includes systemd v258, and /run/lock is not world-writable. It seems like Debian could borrow Fedora's approach for the uucp package, though that would not solve the problem for any other Debian packages affected by the /run/lock change. There is also third-party software to consider, of course.&lt;/p&gt;
    &lt;p&gt;To date, Boccassi has not responded to the conversation; I emailed d'Itri to ask why he did not make the change himself, since he was aware of the bug. He replied on October 13 and said that "&lt;quote&gt;a maintainer cannot force a decision on another maintainer&lt;/quote&gt;." Since he and Boccassi disagreed about the change it was left to the TC to decide. He said that he planned to prepare a merge request to implement the TC's decision, "&lt;quote&gt;as I have already agreed with Luca&lt;/quote&gt;", within the week.&lt;/p&gt;
    &lt;p&gt; Posted Oct 13, 2025 19:34 UTC (Mon) by honschu (subscriber, #61008) [Link] (12 responses) Posted Oct 13, 2025 20:49 UTC (Mon) by mb (subscriber, #50428) [Link] (10 responses) That is not possible for users without source code. Posted Oct 13, 2025 21:49 UTC (Mon) by edgewood (subscriber, #1123) [Link] (7 responses) There's a difference between slowing down a reasonable change to give open source programs a chance to get updates and never making it because closed source programs can't update. Posted Oct 14, 2025 0:41 UTC (Tue) by smurf (subscriber, #17840) [Link] Posted Oct 14, 2025 1:25 UTC (Tue) by mjg59 (subscriber, #23239) [Link] (4 responses) Posted Oct 14, 2025 1:32 UTC (Tue) by josh (subscriber, #17465) [Link] (3 responses) Posted Oct 15, 2025 2:38 UTC (Wed) by Hello71 (subscriber, #103412) [Link] (2 responses) Posted Oct 15, 2025 3:12 UTC (Wed) by josh (subscriber, #17465) [Link] (1 responses) 1) Modern flock, modern traditional lock, legacy traditional lock: The modern program has the lock, the legacy program waits until the modern program is done. 2) Modern flock, legacy traditional lock, modern traditional lock: the legacy program has the lock, the modern program is waiting on the traditional lock before it can run. 3) Legacy traditional lock, modern flock, modern traditional lock: The legacy program has the lock, the modern program is waiting on the traditional lock before it can run. Posted Oct 16, 2025 13:17 UTC (Thu) by edeloget (subscriber, #88392) [Link] Posted Oct 19, 2025 7:20 UTC (Sun) by thoeme (subscriber, #2871) [Link] &amp;gt;add "a configuration file in /etc/tmpfiles.d to override systemd's defaults Posted Oct 13, 2025 21:58 UTC (Mon) by tux3 (subscriber, #101245) [Link] (1 responses) There are also historical artifacts that don't receive updates, don't have a source to patch, and don't have a community fixing the binary directly. The kernel doesn't break those too often, so for containers have worked nicely, as a little time capsule. But third-party binaries aren't really participating in this whole free software distribution project. You can't really plan around people who are doing their own thing and throwing opaque blobs over the wall every so often. Posted Oct 14, 2025 5:02 UTC (Tue) by notriddle (subscriber, #130608) [Link] You can, but you end up heavily limiting the amount of shared data that different subsystems/services/apps can see. Mere blocking isn't enough, because (1) this tends to result in systems that don't work when the permission is turned off, because that code path isn't tested (2) the existence of the file might be sensitive information in and of itself (3) what happens if two systems both think they should be able to use the same name for their things? This also means any change of behavior that's visible to the blob has to be opt-in. That's not how UNIX was designed. That's not even how Windows was designed, though MS has haphazardly added application-level namespacing features to patch around specific, widespread breakages. Hardened web browsers like Tor actually go in the right direction, but they only try to protect sites from each other: new APIs provided by the browser itself are dumped directly into the global namespace, and though they avoid adding anything that will cause widespread breakage, it's still possible for new browser-provided APIs to break a site by existing. Other than hardware virtualization systems like MAME, does anything actually do better on backwards compat than web browsers? Posted Oct 13, 2025 21:38 UTC (Mon) by dmv (subscriber, #168800) [Link] Posted Oct 13, 2025 22:22 UTC (Mon) by skissane (subscriber, #38675) [Link] (1 responses) Maybe I'm reading it wrong, but I came away from this article unclear what the final decision was. Posted Oct 13, 2025 22:38 UTC (Mon) by mjg59 (subscriber, #23239) [Link] Posted Oct 14, 2025 6:59 UTC (Tue) by stephanlachnit (subscriber, #151361) [Link] Posted Oct 14, 2025 7:36 UTC (Tue) by rgb (subscriber, #57129) [Link] (4 responses) Posted Oct 14, 2025 7:59 UTC (Tue) by MaZe (subscriber, #53908) [Link] (3 responses) Posted Oct 14, 2025 9:27 UTC (Tue) by rgb (subscriber, #57129) [Link] Posted Oct 14, 2025 11:14 UTC (Tue) by aragilar (subscriber, #122569) [Link] Posted Oct 14, 2025 12:38 UTC (Tue) by Jonno (subscriber, #49613) [Link] And if there is any problematic tmpfs mount in your typical Linux system it would be /dev/shm, as it has the same fs permissions, but mounted without noexec or any significant size restriction... Posted Oct 14, 2025 12:16 UTC (Tue) by eru (subscriber, #2753) [Link] Wouldn't setting a quota for /run/lock be a solution to this concern? Same for other shared directories for temporaries. Posted Oct 14, 2025 12:27 UTC (Tue) by gray_-_wolf (subscriber, #131074) [Link] (2 responses) Posted Oct 14, 2025 20:46 UTC (Tue) by fw (subscriber, #26023) [Link] (1 responses) The revert did not bring back the separate mount point, though: https://salsa.debian.org/systemd-team/systemd/-/commit/92... I don't know why things are done this way. Posted Oct 15, 2025 3:19 UTC (Wed) by lutchann (subscriber, #8872) [Link] Posted Oct 15, 2025 3:49 UTC (Wed) by raven667 (subscriber, #5198) [Link] (1 responses) Posted Oct 15, 2025 4:01 UTC (Wed) by mjg59 (subscriber, #23239) [Link] Posted Oct 16, 2025 7:44 UTC (Thu) by gdt (subscriber, #6284) [Link] (3 responses) The device /dev/ttyS0 is open()ed and flock(, LOCK_EX) applied. The terminal program now has exclusive use of the modem and proceeds to use it. Later a line condition causes Data Carrier Detect to drop. The way to reinitiate the modem link is to close() and re-open() the device file: this will drop and then re-assert the Data Terminal Ready line, which makes the modem re-attempt a connection. So with flock() there is a race condition which does not exist with a lock file: can the terminal program re-open() and re-flock() the device faster than the competition? The semantics of the lock file is "This program desires to use the serial device". That desire can remain even if the serial port is close()ed. The semantics of flock()ing the device cannot survive a close(). Posted Oct 16, 2025 12:31 UTC (Thu) by chris_se (subscriber, #99706) [Link] (2 responses) You can set the status of the DTR line via TIOCM_DTR on an open device, see also &amp;lt;https://man7.org/linux/man-pages/man2/TIOCMSET.2const.html&amp;gt;. There is no need to close the serial device. This is completely race-free. I don't think lockfiles are a good idea in any way, shape or form, because especially with modern containerization solutions, the only guarantee you have as a program is that if you can open() and flock() the device, you are allowed access to it. With containers you might not even see the same lock directory as the rest of the system (or another container), whereas you might have access to the same serial device. Hence I completely agree that getting rid of /var/lock and /run/lock is the right thing to do, it's just that in the current state of affairs this change should be coordinated with other software before the lock directory is phased out, so I do agree with Debian's TC's decision here. Side note: Actually, flock(, LOCK_EX) by itself is not sufficient to properly lock a serial port: every time a port is opened on Linux, at least some of the port's settings are reset to their defaults, even if it's already open. So the proper thing to do in my opinion is: 1) First flock(fd, LOCK_EX) it to avoid races You need both LOCK_EX and TIOCEXCL: TIOCEXCL prevents the open() command from other processes from working, so that other programs can't open the same device while your program is handling it, preventing some settings to be reset. flock() is still needed regardless, because otherwise you might have a race condition where process A calls open(), then process B calls open(), then process A calls ioctl(), and then process B calls ioctl(), and they both succeed (they would only prevent a process C from calling open() thereafter, the ioctls will both succeed), so use the flock() to avoid that specific race as well. (Caveat: TIOCEXCL doesn't help against root, but ideally you should run as little stuff as possible as root anyway.) Posted Oct 20, 2025 2:45 UTC (Mon) by gdt (subscriber, #6284) [Link] (1 responses) That changes the semantics of the end of a login session from a dial-in modem. The user terminates the shell, and that file close brings down DTR, clearing down the call. To adjust to this behaviour every shell will need to be updated. Whereas currently the system boot can create a lock file for every dial-in line to prevent its use by programs looking for a dial-out line. Posted Oct 20, 2025 16:11 UTC (Mon) by hmh (subscriber, #3838) [Link] It is worth considering that using /var/lock to ensure dial-in and dial-out separation, or any other "reservation" can, in the end, be decently implemented by naming the serial devices you want for dial-out differently from the ones for dial-in, etc (udev/mdev/etc are perfectly capable of being configured to do so). Giving it a good UX might not be that easy, though, and going distro-specific here is a major loss. The point about how classical tty-like devices behave ties in with the way other components (like the shells) work when plugged to a tty is very valuable. &lt;head&gt;Progress with a Plan&lt;/head&gt;&lt;head&gt;Progress with a Plan&lt;/head&gt;&lt;lb/&gt; What is your plan for those?&lt;head&gt;Progress with a Plan&lt;/head&gt;&lt;head&gt;Progress with a Plan&lt;/head&gt;&lt;head&gt;Progress with a Plan&lt;/head&gt;&lt;head&gt;Progress with a Plan&lt;/head&gt;&lt;head&gt;Progress with a Plan&lt;/head&gt;&lt;head&gt;Progress with a Plan&lt;/head&gt;&lt;head&gt;Progress with a Plan&lt;/head&gt;&lt;head&gt;Progress with a Plan&lt;/head&gt;&lt;lb/&gt; I wasn't aware of that possibility, something to check next monday at work.&lt;head&gt;Progress with a Plan&lt;/head&gt;&lt;lb/&gt; If you get updates from your third-party vendor, I suppose you'd talk to them to learn what the plan is.&lt;lb/&gt; More times than I'd like I've been held back from updating the distribution for the sake of enterprise-quality vendor tools.&lt;head&gt;Re: Progress with a Plan&lt;/head&gt;&lt;head&gt;Progress with a Plan&lt;/head&gt;&lt;head&gt;What is the actual technical solution here?&lt;/head&gt;&lt;head&gt;What is the actual technical solution here?&lt;/head&gt;&lt;head&gt;New Package&lt;/head&gt;&lt;head&gt;Single partition setups&lt;/head&gt;&lt;head&gt;Single partition setups&lt;/head&gt;&lt;lb/&gt; At least on my Fedora, /var/lock is -&amp;gt; /run/lock, and /run is tmpfs.&lt;head&gt;Single partition setups&lt;/head&gt;&lt;head&gt;Single partition setups&lt;/head&gt;&lt;head&gt;Single partition setups&lt;/head&gt;&lt;head&gt;Quota?&lt;/head&gt;&lt;quote&gt; shudder to think of allowing unprivileged programs to fill up a directory &lt;/quote&gt;&lt;head&gt;Why not a separate tmpfs?&lt;/head&gt;&lt;head&gt;Why not a separate tmpfs?&lt;/head&gt;&lt;head&gt;Why not a separate tmpfs?&lt;/head&gt;&lt;head&gt;Why was this a policy debate at all?&lt;/head&gt;&lt;head&gt;Why was this a policy debate at all?&lt;/head&gt;&lt;head&gt;flock() versus lock file semantics&lt;/head&gt;&lt;head&gt;flock() versus lock file semantics&lt;/head&gt;&lt;lb/&gt; 2) second ioctl(fd, TIOCEXCL) to prevent further opens&lt;head&gt;flock() versus lock file semantics&lt;/head&gt;&lt;head&gt;flock() versus lock file semantics&lt;/head&gt;&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45692915</guid><pubDate>Fri, 24 Oct 2025 10:07:34 +0000</pubDate></item><item><title>Twake Drive – An open-source alternative to Google Drive</title><link>https://github.com/linagora/twake-drive</link><description>&lt;doc fingerprint="cb16d4485c6376c3"&gt;
  &lt;main&gt;
    &lt;p&gt; The open-source alternative to Google Drive. &lt;lb/&gt; Learn more » &lt;lb/&gt; Telegram | Website | Issues | Roadmap &lt;/p&gt;
    &lt;p&gt;To get a local copy up and running, please follow these simple steps.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Clone the repo &lt;quote&gt;git clone https://github.com/linagora/twake-drive&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Run it with Docker &lt;code&gt;cd tdrive docker compose -f docker-compose.minimal.yml up&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Open http://localhost/ in a browser&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Node.js (Version: &amp;gt;=18.x)&lt;/item&gt;
      &lt;item&gt;MongoDB&lt;/item&gt;
      &lt;item&gt;Yarn (recommended)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Launch MongoDB using&lt;/p&gt;
        &lt;quote&gt;docker run -p 27017:27017 -d mongo&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Launch frontend with&lt;/p&gt;
        &lt;quote&gt;cd tdrive/frontend/; yarn dev:start&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Launch backend with&lt;/p&gt;&lt;quote&gt;cd tdrive/backend/node/; SEARCH_DRIVER=mongodb DB_DRIVER=mongodb PUBSUB_TYPE=local \ DB_MONGO_URI=mongodb://localhost:27017 STORAGE_LOCAL_PATH=/[full-path-to-store-documents]/documents \ NODE_ENV=development yarn dev&lt;/quote&gt;&lt;p&gt;If you need more parameters, create/edit&lt;/p&gt;&lt;code&gt;tdrive/backend/node/config/development.json&lt;/code&gt;file&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The app will be running on port 3000&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Twake Drive is licensed under Affero GPL v3&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45692984</guid><pubDate>Fri, 24 Oct 2025 10:16:25 +0000</pubDate></item><item><title>Mesh2Motion – Open-source web application to animate 3D models</title><link>https://mesh2motion.org/</link><description>&lt;doc fingerprint="a9753601cfb2d489"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;ð¥³ Human &amp;amp; Animal rigs&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Supports importing GLB, GLTF, and FBX models&lt;/item&gt;
      &lt;item&gt;Human and animal skeleton options&lt;/item&gt;
      &lt;item&gt;Intuitive skeleton positioning&lt;/item&gt;
      &lt;item&gt;Undo/Redo system when you make mistakes&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;âï¸ Export Animations&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Export multiple animations at once&lt;/item&gt;
      &lt;item&gt;Uses widely-supported GLB format&lt;/item&gt;
      &lt;item&gt;Human animation library from Quaternius&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Video Walkthrough&lt;/head&gt;
    &lt;head rend="h2"&gt;FREE &amp;amp; Open-Source&lt;/head&gt;
    &lt;p&gt;Mesh2Motion is an open-source project. With the way 3d animations and modeling tools are progressing, there just needs to be some tool like this that is open-source that can evolve. The goal of this project is to provide a free and easy way to animate 3D models for web and game engines. Everything should be freely available for both personal and commercial projects. Check out the GitHub repository for all the code.&lt;/p&gt;
    &lt;head rend="h2"&gt;Contact&lt;/head&gt;
    &lt;p&gt;The best place for bug reports and feedback is on the GitHub page. If you don't have GitHub, you could also try my socials:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;github.com/scottpetrovic/mesh2motion-app&lt;/item&gt;
      &lt;item&gt;@scottpetrovic&lt;/item&gt;
      &lt;item&gt;@scottpetrovic.bsky.social&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45693325</guid><pubDate>Fri, 24 Oct 2025 11:01:23 +0000</pubDate></item><item><title>ChunkLLM: A Lightweight Pluggable Framework for Accelerating LLMs Inference</title><link>https://arxiv.org/abs/2510.02361</link><description>&lt;doc fingerprint="8d9c1c23d1f186ae"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Computation and Language&lt;/head&gt;&lt;p&gt; [Submitted on 28 Sep 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:ChunkLLM: A Lightweight Pluggable Framework for Accelerating LLMs Inference&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:Transformer-based large models excel in natural language processing and computer vision, but face severe computational inefficiencies due to the self-attention's quadratic complexity with input tokens. Recently, researchers have proposed a series of methods based on block selection and compression to alleviate this problem, but they either have issues with semantic incompleteness or poor training-inference efficiency. To comprehensively address these challenges, we propose ChunkLLM, a lightweight and pluggable training framework. Specifically, we introduce two components: QK Adapter (Q-Adapter and K-Adapter) and Chunk Adapter. The former is attached to each Transformer layer, serving dual purposes of feature compression and chunk attention acquisition. The latter operates at the bottommost layer of the model, functioning to detect chunk boundaries by leveraging contextual semantic information. During the training phase, the parameters of the backbone remain frozen, with only the QK Adapter and Chunk Adapter undergoing training. Notably, we design an attention distillation method for training the QK Adapter, which enhances the recall rate of key chunks. During the inference phase, chunk selection is triggered exclusively when the current token is detected as a chunk boundary, thereby accelerating model inference. Experimental evaluations are conducted on a diverse set of long-text and short-text benchmark datasets spanning multiple tasks. ChunkLLM not only attains comparable performance on short-text benchmarks but also maintains 98.64% of the performance on long-context benchmarks while preserving a 48.58% key-value cache retention rate. Particularly, ChunkLLM attains a maximum speedup of 4.48x in comparison to the vanilla Transformer in the processing of 120K long texts.&lt;/quote&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45693591</guid><pubDate>Fri, 24 Oct 2025 11:41:26 +0000</pubDate></item><item><title>Padlet (YC W13) Is Hiring in San Francisco and Singapore</title><link>https://padlet.jobs</link><description>&lt;doc fingerprint="28684c070fcc5eec"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;LET'S GET TO WORK&lt;/head&gt;
    &lt;p&gt;Your morning cup of coffee.&lt;lb/&gt;The song you'll play at your wedding.&lt;lb/&gt;Football, either one.&lt;lb/&gt;The camera that recorded your first steps.&lt;lb/&gt;Air conditioning in the living room, hot water in the bathroom.&lt;lb/&gt;Your every comfort, every joy, every memory.&lt;lb/&gt;You have them because of someone's work,&lt;lb/&gt;because of a world at work,&lt;lb/&gt;because of generations that worked before us.&lt;lb/&gt;Making.&lt;lb/&gt;Saving.&lt;lb/&gt;Breaking.&lt;lb/&gt;Moving.&lt;lb/&gt;Wrestling inboxes that never tap out.&lt;lb/&gt;Five minutes to finish a ziplocked ham sandwich.&lt;lb/&gt;Trying to find parking. Always trying to find parking.&lt;lb/&gt;Knots in the gut before the lights turn on.&lt;lb/&gt;Blisters on fingers where the pencil meets the skin.&lt;lb/&gt;Snowfall or heatwave.&lt;lb/&gt;Stardust to sunrise.&lt;lb/&gt;They showed up for us.&lt;lb/&gt;Let's show up for them.&lt;lb/&gt;Let's move.&lt;lb/&gt;Let's break.&lt;lb/&gt;Let's save.&lt;lb/&gt;Let's make.&lt;lb/&gt;Let's get to work.&lt;/p&gt;
    &lt;p&gt;The song you'll play at your wedding.&lt;/p&gt;
    &lt;p&gt;Football, either one.&lt;/p&gt;
    &lt;p&gt;The camera that recorded your first steps.&lt;/p&gt;
    &lt;p&gt;Air conditioning in the living room, hot water in the bathroom.&lt;/p&gt;
    &lt;p&gt;Your every comfort, every joy, every memory.&lt;/p&gt;
    &lt;p&gt;You have them because of someone's work,&lt;/p&gt;
    &lt;p&gt;because of a world at work,&lt;/p&gt;
    &lt;p&gt;because of generations that worked before us.&lt;/p&gt;
    &lt;p&gt;Making.&lt;/p&gt;
    &lt;p&gt;Saving.&lt;/p&gt;
    &lt;p&gt;Breaking.&lt;/p&gt;
    &lt;p&gt;Moving.&lt;/p&gt;
    &lt;p&gt;Wrestling inboxes that never tap out.&lt;/p&gt;
    &lt;p&gt;Five minutes to finish a ziplocked ham sandwich.&lt;/p&gt;
    &lt;p&gt;Trying to find parking. Always trying to find parking.&lt;/p&gt;
    &lt;p&gt;Knots in the gut before the lights turn on.&lt;/p&gt;
    &lt;p&gt;Blisters on fingers where the pencil meets the skin.&lt;/p&gt;
    &lt;p&gt;Snowfall or heatwave.&lt;/p&gt;
    &lt;p&gt;Stardust to sunrise.&lt;/p&gt;
    &lt;p&gt;They showed up for us.&lt;/p&gt;
    &lt;p&gt;Let's show up for them.&lt;/p&gt;
    &lt;p&gt;Let's move.&lt;/p&gt;
    &lt;p&gt;Let's break.&lt;/p&gt;
    &lt;p&gt;Let's save.&lt;/p&gt;
    &lt;p&gt;Let's make.&lt;/p&gt;
    &lt;p&gt;Let's get to work.&lt;/p&gt;
    &lt;p&gt;Nitesh&lt;/p&gt;
    &lt;p&gt;Founder and CEO&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45693743</guid><pubDate>Fri, 24 Oct 2025 12:01:08 +0000</pubDate></item><item><title>Typst 0.14</title><link>https://typst.app/blog/2025/typst-0.14/</link><description>&lt;doc fingerprint="7e9e51106fe534cc"&gt;
  &lt;main&gt;
    &lt;p&gt;Typst 0.14 is out now. With accessibility by default, PDFs as images, character-level justification, and more, it has everything you need to move from draft to production.&lt;/p&gt;
    &lt;p&gt;Typst's origins lie in academia, but over the past year, we've seen it expand to so much more. It's increasingly being used in the industry: For manually written documents, partially automated reports, and in fully automated batch PDF generation pipelines. Across these use cases, it's being used in production for critical documents.&lt;/p&gt;
    &lt;p&gt;In August, we launched a new website to reflect Typst's expanding scope, and now, with Typst 0.14, we're shipping crucial features that make Typst even more widely applicable.&lt;/p&gt;
    &lt;p&gt;If you need to comply with accessibility-related regulations, Typst 0.14 has your back. Typst now generates accessible documents by default, with opt-in support for stricter checks. For those working with complex illustrations, PDFs are now supported as a native image format. In case you're typesetting a book, the new character-level justification will give your layout the final touch. And if you're building a website or blog, many improvements to Typst's HTML export are waiting for you.&lt;/p&gt;
    &lt;head rend="h2"&gt;Contents&lt;/head&gt;
    &lt;p&gt;In this blog post, we'll take a closer look at the highlights of this release:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Accessibility&lt;/item&gt;
      &lt;item&gt;PDF standards&lt;/item&gt;
      &lt;item&gt;PDFs as images&lt;/item&gt;
      &lt;item&gt;Character-level justification&lt;/item&gt;
      &lt;item&gt;Richer HTML export&lt;/item&gt;
      &lt;item&gt;Migrating to Typst 0.14&lt;/item&gt;
      &lt;item&gt;Community Call&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To get started with Typst 0.14…&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;…in the web app: Just open any of your projects! You'll get a prompt offering you to upgrade to the latest version.&lt;/item&gt;
      &lt;item&gt;…on the command line: Run &lt;code&gt;typst update&lt;/code&gt;in your terminal or, if you haven't installed Typst previously, download the latest version of the CLI.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For a comprehensive overview of all changes in the release, visit the changelog. If you're looking to upgrade your document to Typst 0.14, you can also skip ahead to the Migration section.&lt;/p&gt;
    &lt;head rend="h2"&gt;Accessibility&lt;/head&gt;
    &lt;p&gt;Not everyone reads PDF documents the same. Some people read on large screens or print; others use small phones or screen readers to have documents read aloud. To cater to all these uses, a file must contain tags that allow Assistive Technology (AT) like screen readers to learn about the reading order and semantic meaning of each piece of text. Tags allow AT users to learn which text is &lt;code&gt;*strongly emphasized*&lt;/code&gt;, enable navigation of the document by skipping between headings, and more.&lt;/p&gt;
    &lt;p&gt;Tagging requires no additional work from you: If you are using the built-in markup and elements, Typst will automatically select the right tags! Unlike many other tools, PDF files created with Typst 0.14 are tagged by default, raising the bar for accessibility.&lt;/p&gt;
    &lt;p&gt;But tags are not enough to make a file accessible: To reach everyone, you need to design for universal accessibility from the start. The new features in Typst 0.14 can help you with that. Consider diagrams created with shapes or packages like cetz—their visual meaning is invisible to assistive technology. The new &lt;code&gt;alt&lt;/code&gt; parameter on figures solves this:&lt;/p&gt;
    &lt;code&gt;#figure(
  stack(
    dir: ltr,
    spacing: 0.5em,
    rect[Tagged PDF],
    text(2em, sym.arrow.long),
    rect[Accessibility],
  ),
  alt: "Diagram with two rectangles. The first is labelled 'Tagged PDF'. An arrow points to the second, labelled 'Accessibility'",
  caption: [
    Tags enable PDF accessibility
  ],
)
&lt;/code&gt;
    &lt;p&gt;With this change, AT users hear the alternative description and can grasp the figure's purpose just like sighted users—no information is lost. We have put together a new Accessibility Guide that contains more tips on how to create accessible documents, including how to write good alternative descriptions, when to use the figure's vs. the image's &lt;code&gt;alt&lt;/code&gt; parameter, and more.&lt;/p&gt;
    &lt;p&gt;To make sure you got everything right, you can enable the new PDF/UA-1 export. PDF/UA is an international standard that helps to create universally accessible PDF files. When it is enabled, Typst will run additional checks against your document to find accessibility issues and optimize for accessibility rather than compatibility. It will find issues such as missing document titles, wrong heading hierarchies, and missing alternative descriptions.&lt;/p&gt;
    &lt;p&gt;PDF/UA-1 helps you comply with existing and upcoming international accessibility regulation like the European Accessibility Act (EAA) in the EU and the new Americans with Disabilities Act's (ADA) Title II guidance by the DOJ. The former applies to many businesses active in the European Union since 28 June 2025 while the deadline for the latter is set for April 24, 2026. If you are using Typst in your business for customer- or government-facing documents, you should adopt Typst 0.14 as soon as possible.&lt;/p&gt;
    &lt;head rend="h2"&gt;PDF standards&lt;/head&gt;
    &lt;p&gt;Alongside PDF/UA-1 support, we've also generally expanded Typst's support for PDF standards. Instead of just PDF 1.7, you can now choose between the PDF versions 1.4, 1.5, 1.6, 1.7, and 2.0. And for PDF/A, we've expanded support from just two specific substandards to all four parts with all their conformance levels. While Typst's defaults are perfectly fine for most use cases, choosing a standard can optimize your document specifically for your use case. Consult the expanded PDF documentation in the reference for guidance on which standards you should pick under which circumstances.&lt;/p&gt;
    &lt;head rend="h2"&gt;PDFs as images&lt;/head&gt;
    &lt;p&gt;Staying with the PDF theme, there are exciting news for authors that have a lot of complex illustrations. Typst now supports PDF as a native image format. What I personally find most exciting about it, is that PDF images are supported across all export targets, and for each export target in the most suitable format. In PDF export, PDFs are naturally directly embedded. Meanwhile, in HTML and SVG export, PDFs are converted to an embedded SVG on-the-fly. And, finally, in PNG export and the web app preview, PDFs are rasterized. All of this PDF processing functionality lives right in the Typst compiler, with no system dependencies. This is only possible thanks to the amazing work of community member @LaurenzV, who created a new PDF processing library called &lt;code&gt;hayro&lt;/code&gt; from scratch. The library is 100% written in the programming language Rust (which is also the language we use for the Typst compiler) and is thus highly portable.&lt;/p&gt;
    &lt;code&gt;#figure(
  image(
    "throwing-success.pdf",
    alt: "A diagram titled 'Throwing Success' that .."
  ),
  caption: [
    Effect of normalized thrust
    on X and Y position of
    thrown emojis
  ],
)
&lt;/code&gt;
    &lt;head rend="h2"&gt;Character-level justification&lt;/head&gt;
    &lt;p&gt;Producing a visually balanced paragraph was once a fine art, when professional typesetters still carefully set paragraphs with movable type. Nowadays, you could hope that optimal paragraph typesetting is a solved problem across all our software. But, alas, it is not!&lt;/p&gt;
    &lt;p&gt;There are different strategies we can employ to produce a well-justified paragraph. Of course, to justify the paragraph, we need to stretch each line to the width of the measure. There are different ways to do this: Most obviously, we can adjust the spacing between words. This is what most software does. But we can also adjust the spacing between characters. This is now implemented in Typst.&lt;/p&gt;
    &lt;p&gt;Other methods to do this (which we want to explore in the future) include stretching the width of characters (this is best done with variable fonts) or, for some scripts, inserting special textual elements. For example, in Arabic, there are Kashida, which allow spacing out glyphs in words by extending the connectors between individual glyphs.&lt;/p&gt;
    &lt;p&gt;But that's just part of the recipe. Arguably, the even more crucial part is how this interplays with which linebreaks we chose to insert. Naively, we can choose our break points based on how much text fits and then perform the stretching. But we can do much better by taking into account each line's potential for stretching with the various mechanisms discussed above! We can then choose the break points that minimize the amount of bad-looking stretching.&lt;/p&gt;
    &lt;p&gt;I was initially skeptical about supporting character-level justification because I've seen it done poorly in some books. But that's actually not the fault of character-level justification per se; it's just excessive use of it. Tastefully chosen maxima—together with an algorithm that minimizes displeasing typography—make it bring out the best in justification.&lt;/p&gt;
    &lt;p&gt;We hear a lot about microtypography when people compare Typst with LaTeX. And even though Typst uses the same fundamental algorithm as LaTeX does to optimize paragraphs, it's true that LaTeX has some extra tricks up its sleeve. Now we do too though, as character-level justification is a feature that LaTeX does not support.&lt;/p&gt;
    &lt;head rend="h2"&gt;Richer HTML Export&lt;/head&gt;
    &lt;p&gt;In Typst 0.13, we shipped a first, highly experimental version of HTML export. This very minimal version already introduced the primitives for flexible HTML generation. With these primitives, the mapping of Typst elements to HTML can be expressed through show rules, just like the mapping to visual elements is performed in paged export.&lt;/p&gt;
    &lt;p&gt;What was lacking though were show rules for many built-in elements, including elements like footnotes, outlines, and citations. Typst 0.14 makes good progress in this regard. Most semantic elements (those from the Model category) are now properly mapped to semantic HTML. We've also improved handling of textual content in HTML export. The more visualization- and styling-focused parts of Typst's standard library remain largely unsupported, but we plan to add support for those (to the extent possible) in the future.&lt;/p&gt;
    &lt;p&gt;Below, you can see an example of a small, but non-trivial Typst document exported to HTML with Typst 0.14.&lt;/p&gt;
    &lt;code&gt;#set heading(numbering: "1.")

= Introduction &amp;lt;intro&amp;gt;
In @intro, let's cite @netwok.

#bibliography("works.bib")
&lt;/code&gt;
    &lt;quote&gt;&amp;lt;!-- html, head, and body omitted for brevity --&amp;gt; &amp;lt;h2 id="intro"&amp;gt;1. Introduction&amp;lt;/h2&amp;gt; &amp;lt;p&amp;gt; In &amp;lt;a href="#intro"&amp;gt;Section 1&amp;lt;/a&amp;gt;, let’s cite &amp;lt;a id="loc-1" href="#loc-2" role="doc-biblioref"&amp;gt;[1]&amp;lt;/a&amp;gt;. &amp;lt;/p&amp;gt; &amp;lt;section role="doc-bibliography"&amp;gt; &amp;lt;h2&amp;gt;Bibliography&amp;lt;/h2&amp;gt; &amp;lt;ul style="list-style-type: none"&amp;gt; &amp;lt;li id="loc-2"&amp;gt; &amp;lt;span class="prefix"&amp;gt;&amp;lt;a href="#loc-1" role="doc-backlink"&amp;gt;[1]&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt; R. Astley and L. Morris, “At-scale impact of the Net Wok: A culinarically holistic investigation of distributed dumplings,” &amp;lt;em&amp;gt;Armenian Journal of Proceedings&amp;lt;/em&amp;gt;, vol. 61, pp. 192–219, 2020. &amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt; &amp;lt;/section&amp;gt;&lt;/quote&gt;
    &lt;p&gt;Another exciting addition to HTML export is the new typed HTML interface. Typst's &lt;code&gt;html&lt;/code&gt; module now includes functions for constructing HTML elements with strongly-typed attributes. This means you can now write&lt;/p&gt;
    &lt;code&gt;#html.video(
  autoplay: true,
  width: 1280,
  height: 720,
  src: "sunrise.mp4",
)
&lt;/code&gt;
    &lt;p&gt;instead of&lt;/p&gt;
    &lt;code&gt;#html.elem("video", attrs: (
  autoplay: "",
  width: "1280",
  height: "720",
  src: "sunrise.mp4",
))
&lt;/code&gt;
    &lt;p&gt;As you can see, attributes are mapped to idiomatic Typst-native types.&lt;/p&gt;
    &lt;p&gt;Last but not least, we're happy to announce that HTML export will soon come to the Typst web app. We're still polishing up the implementation, but plan to ship it in the coming weeks.&lt;/p&gt;
    &lt;p&gt;Please note that HTML export remains experimental. To enable it in the CLI, pass &lt;code&gt;--features html&lt;/code&gt; or set &lt;code&gt;TYPST_FEATURES=html&lt;/code&gt;. In the web app, support for HTML export will also need to be enabled on a per-project basis.&lt;/p&gt;
    &lt;head rend="h2"&gt;Migrating to Typst 0.14&lt;/head&gt;
    &lt;p&gt;As far as breaking changes and deprecations go, this is a pretty calm release. Most documents should continue to work as before. There are a few minor breaking changes that make certain validations more strict. For instance, labels, link URLs, and font lists may not be empty anymore. To learn about all breaking changes, consult the changelog and search for "breaking change".&lt;/p&gt;
    &lt;p&gt;The release also contains a few deprecations. In particular, you'll need to replace any use of &lt;code&gt;pdf.embed&lt;/code&gt; with &lt;code&gt;pdf.attach&lt;/code&gt;. Moreover, two bibliography styles were renamed and the &lt;code&gt;--make-deps&lt;/code&gt; CLI flag was deprecated in favor of the new, more flexible &lt;code&gt;--deps&lt;/code&gt; flag with &lt;code&gt;--deps-format make&lt;/code&gt;. There are also a few deprecated symbols. The compiler will warn you about all use of deprecated functionality.&lt;/p&gt;
    &lt;head rend="h3"&gt;In the web app&lt;/head&gt;
    &lt;p&gt;With this release, we're also bringing a better version upgrade experience to the web app. Previously, projects would always use the latest compiler version unless explicitly pinned to a specific version in the settings side panel.&lt;/p&gt;
    &lt;p&gt;We are now phasing out the "Latest" option. Instead, the web app detects when a new version is available since you've last edited a project, and offers you to upgrade. The upgrade assistant includes an automatic compatibility check that compiles your document with both versions, makes a verdict, and lists new errors and warnings.&lt;/p&gt;
    &lt;head rend="h2"&gt;Community Call&lt;/head&gt;
    &lt;p&gt;Typst 0.14 is the result of 8 months of hard work by us and the community. We hope you are as excited about it as we are!&lt;/p&gt;
    &lt;p&gt;Speaking of the community—We're hosting a community call on Discord on Friday, November 7th. Join us to share your experiences with the new version and to chat with the community!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45693978</guid><pubDate>Fri, 24 Oct 2025 12:33:10 +0000</pubDate></item><item><title>Asahi Linux Still Working on Apple M3 Support, M1n1 Bootloader Going Rust</title><link>https://www.phoronix.com/news/Asahi-Linux-M3-m1n1-Update</link><description>&lt;doc fingerprint="8f41bb17d99430ec"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Asahi Linux Still Working On Apple M3 Support, m1n1 Bootloader Going Rust&lt;/head&gt;
    &lt;p&gt; The Asahi Linux developers involved with working on Linux support for Apple Silicon M-Series devices have put out a new progress report on their development efforts. &lt;lb/&gt;Asahi Linux developers have kept working on new kernel patches and some being upstreamed for Linux 6.17 and 6.18 cycles, as previously covered on Phoronix. Notably with Linux 6.18 is the Device Trees for the Apple M2 Pro / Max / Ultra devices albeit more driver code is still working its way upstream.&lt;lb/&gt;Asahi Linux developers are also working on moving toward the Rust programming language with their important m1n1 bootloader for Apple Silicon. They feel going to Rust is important for such a critical piece of software for better maintainability, safety, and ensuring the correct logic.&lt;lb/&gt;Asahi Linux developers have also made progress on getting more games working on Apple Silicon devices. Wine is also now working outside of muvm and their graphics driver support continues maturing:&lt;lb/&gt;With the upstream Linux kernel work around Apple Silicon so far being focused on Apple M1 and M2, you may be wondering about M3 and M4 or the recently announced M5... They still are battling Apple M3 bring-up. Today's progress report comments:&lt;lb/&gt;See the progress report in full over on AsahiLinux.org.&lt;/p&gt;
    &lt;p&gt;Asahi Linux developers have kept working on new kernel patches and some being upstreamed for Linux 6.17 and 6.18 cycles, as previously covered on Phoronix. Notably with Linux 6.18 is the Device Trees for the Apple M2 Pro / Max / Ultra devices albeit more driver code is still working its way upstream.&lt;/p&gt;
    &lt;p&gt;Asahi Linux developers are also working on moving toward the Rust programming language with their important m1n1 bootloader for Apple Silicon. They feel going to Rust is important for such a critical piece of software for better maintainability, safety, and ensuring the correct logic.&lt;/p&gt;
    &lt;p&gt;Asahi Linux developers have also made progress on getting more games working on Apple Silicon devices. Wine is also now working outside of muvm and their graphics driver support continues maturing:&lt;/p&gt;
    &lt;p&gt;With the upstream Linux kernel work around Apple Silicon so far being focused on Apple M1 and M2, you may be wondering about M3 and M4 or the recently announced M5... They still are battling Apple M3 bring-up. Today's progress report comments:&lt;/p&gt;
    &lt;quote&gt;"It may be surprising to learn that very basic, low-level support for M3 has existed for quite some time now. m1n1 is capable of initialising the CPU cores, turning on some critical peripheral devices, and booting the Asahi kernel. However, the level of support right now begins and ends with being able to boot to a blinking cursor. Naturally, this level of support is not at all useful for anything but low-level reverse engineering, but we of course plan on rectifying this in due time..."&lt;/quote&gt;
    &lt;p&gt;See the progress report in full over on AsahiLinux.org.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45694767</guid><pubDate>Fri, 24 Oct 2025 14:03:22 +0000</pubDate></item><item><title>First shape found that can't pass through itself</title><link>https://www.quantamagazine.org/first-shape-found-that-cant-pass-through-itself-20251024/</link><description>&lt;doc fingerprint="a390899286a00301"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;First Shape Found That Can’t Pass Through Itself&lt;/head&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Imagine you’re holding two equal-size dice. Is it possible to bore a tunnel through one die that’s big enough for the other to slide through?&lt;/p&gt;
    &lt;p&gt;Perhaps your instinct is to say “Surely not!” If so, you’re not alone. In the late 1600s, an unidentified person placed a bet to that effect with Prince Rupert of the Rhine. Rupert — a nephew of Charles I of England who commanded the Royalist forces in the English Civil War — spent his sunset years studying metallurgy and glassmaking in his laboratory at Windsor Castle.&lt;/p&gt;
    &lt;p&gt;Rupert won the bet. The mathematician John Wallis, recounting the story in 1693, didn’t say whether Rupert wrote a proof or bored a hole through an actual cube. But Wallis himself proved mathematically that, if you drill a straight tunnel in the direction of one of the cube’s inner diagonals, it can be made wide enough to allow another cube through. It’s a tight squeeze: If you make the second cube just 4% larger, it will no longer fit.&lt;/p&gt;
    &lt;p&gt;It’s natural to wonder which other shapes have this property. “I think of this problem as being quite canonical,” said Tom Murphy, a software engineer at Google who has explored the question extensively in his free time. It “would have gotten rediscovered and rediscovered — aliens would have come to this one.”&lt;/p&gt;
    &lt;p&gt;Mark Belan/Quanta Magazine&lt;/p&gt;
    &lt;p&gt;The full menagerie of shapes is too diverse to get a handle on, so mathematicians tend to focus on convex polyhedra: shapes, like the cube, that have flat sides and no protrusions or indentations. When such a shape is much wider in some directions than others, it’s usually easy to find a straight tunnel that will allow another copy of the shape to pass through. But many famous convex polyhedra — for instance the dodecahedron, or the truncated icosahedron, the shape that forms a soccer ball — are highly symmetric and difficult to analyze. Among these, “for hundreds of years we only knew of the cube,” said Jakob Steininger, a mathematician at Statistics Austria, Austria’s federal statistics organization.&lt;/p&gt;
    &lt;p&gt;Then, in 1968, Christoph Scriba proved that the tetrahedron and octahedron also have the “Rupert property,” as mathematicians now call it. And in a burst of activity over the past decade, professional mathematicians and hobbyists have found Rupert tunnels through many of the most widely studied convex polyhedra, including the dodecahedron, icosahedron and soccer ball.&lt;/p&gt;
    &lt;p&gt;The Rupert property appeared to be so widespread that mathematicians conjectured a general rule: Every convex polyhedron will have the Rupert property. No one could find one that didn’t — until now.&lt;/p&gt;
    &lt;p&gt;In a paper posted online in August, Steininger and Sergey Yurkevich — a researcher at A&amp;amp;R Tech, an Austrian transportation systems company — describe a shape with 90 vertices and 152 faces that they’ve named the Noperthedron (after “Nopert,” a coinage by Murphy that combines “Rupert” and “nope”). Steininger and Yurkevich proved that no matter how you bore a straight tunnel through a Noperthedron, a second Noperthedron cannot fit through.&lt;/p&gt;
    &lt;p&gt;The proof required a mix of theoretical advances and massive computer calculations, and relies on a delicate property of the Noperthedron’s vertices. “It’s a miracle that it works,” Steininger said.&lt;/p&gt;
    &lt;head rend="h2"&gt;Passing Through the Shadows&lt;/head&gt;
    &lt;p&gt;To see how one cube can pass through another, imagine holding a cube over a table and examining its shadow (assuming it’s illuminated from above). If you hold the cube in the standard position, the shadow is a square. But if you point one of the corners directly upward, the shadow is a regular hexagon.&lt;/p&gt;
    &lt;p&gt;In 1693, Wallis showed that the square shadow fits inside the hexagon, leaving a thin margin. That means that if you point a cube’s corner upward, you can bore a vertical tunnel that’s big enough for a second cube to pass through. About a century later, Pieter Nieuwland showed that a different orientation casts an even better shadow — one that can accommodate a cube more than 6% larger than the cube with the tunnel.&lt;/p&gt;
    &lt;p&gt;Mark Belan/Quanta Magazine&lt;/p&gt;
    &lt;p&gt;Every subsequent analysis of more complicated shapes has relied on this process of turning the shape in different directions and looking for one shadow that fits inside another. With the aid of computers, mathematicians have found Rupert passages through a wide variety of shapes. Some are incredibly tight fits — for instance, the passage in a “triakis tetrahedron” has a margin that’s only about 0.000002 times the length of the shape’s radius. “The world of mixing computation and discrete geometry has flowered to make these kinds of calculations possible,” said Joseph O’Rourke, an emeritus professor at Smith College.&lt;/p&gt;
    &lt;p&gt;Researchers who have written algorithms to find Rupert passages have noticed a curious dichotomy: For any given convex polyhedron, the algorithm seems to either find a passage almost immediately, or not find one at all. In the past five years, mathematicians have accumulated a small collection of holdout shapes for which no passage has been found.&lt;/p&gt;
    &lt;p&gt;“I’ve had my desktop churn for two weeks on trying the rhombicosidodecahedron,” said Benjamin Grimmer, an applied mathematician at Johns Hopkins University, referring to a solid made of 62 regular triangles, squares and pentagons. “That one just seems to resist any attempt.”&lt;/p&gt;
    &lt;p&gt;But such resistance doesn’t prove that a shape is a Nopert. There are infinitely many ways to orient a shape, and a computer can only check finitely many. Researchers don’t know whether the holdouts are true Noperts or just shapes whose Rupert passages are hard to find.&lt;/p&gt;
    &lt;p&gt;What they do know is that candidate Noperts are incredibly rare. Starting last year, Murphy began to construct hundreds of millions of shapes. These include random polyhedra, polyhedra whose vertices lie on a sphere, polyhedra with special symmetries, and polyhedra in which he moved one vertex to intentionally mess up a previous Rupert passage. His algorithm easily found Rupert tunnels for nearly every one.&lt;/p&gt;
    &lt;p&gt;The contrast between these quick results and the stubbornness of the Nopert holdouts made some mathematicians suspect that true Noperts do exist. But until August, all they had were suspicions.&lt;/p&gt;
    &lt;head rend="h2"&gt;No Passage&lt;/head&gt;
    &lt;p&gt;Steininger, now 30, and Yurkevich, 29, have been friends since they participated together as teenagers in mathematics Olympiad competitions. Even though both eventually left academia (after a doctorate for Yurkevich and a master’s for Steininger), they have continued to explore unsolved problems together.&lt;/p&gt;
    &lt;p&gt;“We just had pizza three hours ago, and we talked about math almost the whole time,” Steininger told Quanta. “That’s what we do.”&lt;/p&gt;
    &lt;p&gt;Five years ago, the pair happened upon a YouTube video of one cube passing through another, and they were instantly smitten. They developed an algorithm to search for Rupert tunnels and soon became convinced that some shapes were Noperts. In a 2021 paper, they conjectured that the rhombicosidodecahedron is not Rupert. Their work, which preceded Murphy’s and Grimmer’s recent explorations, was, “I think, the first to conjecture that there might be solids that don’t have this property,” Steininger said.&lt;/p&gt;
    &lt;p&gt;If you want to prove that a shape is a Nopert, you must rule out Rupert tunnels for every possible orientation of the two shapes. Each orientation can be written down as a collection of rotation angles. This collection of angles can then be represented as a point in a higher-dimensional “parameter space.”&lt;/p&gt;
    &lt;p&gt;Florentina Stadlbauer; Courtesy of Jakob Steininger&lt;/p&gt;
    &lt;p&gt;Suppose you choose an orientation for your two shapes, and the computer tells you that the second shadow sticks out past the border of the first shadow. This rules out one point in the parameter space.&lt;/p&gt;
    &lt;p&gt;But you may be able to rule out much more than a single point. If the second shadow sticks out significantly, it would require a big change to move it inside the first shadow. In other words, you can rule out not just your initial orientation but also “nearby” orientations — an entire block of points in the parameter space. Steininger and Yurkevich came up with a result they called their global theorem, which quantifies precisely how large a block you can rule out in these cases. By testing many different points, you can potentially rule out block after block in the parameter space.&lt;/p&gt;
    &lt;p&gt;If these blocks cover the entire parameter space, you’ll have proved that your shape is a Nopert. But the size of each block depends on how far the second shadow sticks out beyond the first, and sometimes it doesn’t stick out very far. For instance, suppose you start with the two shapes in exactly the same position, and then you slightly rotate the second shape. Its shadow will at most stick out just a tiny bit past the first shadow, so the global theorem will only rule out a tiny box. These boxes are too small to cover the whole parameter space, leaving the possibility that some point you’ve missed might correspond to a Rupert tunnel.&lt;/p&gt;
    &lt;p&gt;To deal with these small reorientations, the pair came up with a complement to their global theorem that they called the local theorem. This result deals with cases where you can find three vertices (or corner points) on the boundary of the original shadow that satisfy some special requirements. For instance, if you connect those three vertices to form a triangle, it must contain the shadow’s center point. The researchers showed that if these requirements are met, then any small reorientation of the shape will create a shadow that pushes at least one of the three vertices further outward. So the new shadow can’t lie inside the original shadow, meaning it doesn’t create a Rupert tunnel.&lt;/p&gt;
    &lt;p&gt;If your shape casts a shadow that lacks three appropriate vertices, the local theorem won’t apply. And all the previously identified Nopert candidates have at least one shadow with this problem. Steininger and Yurkevich sifted through a database of hundreds of the most symmetric and beautiful convex polyhedra, but they couldn’t find any shape whose shadows all worked. So they decided to generate a suitable shape themselves.&lt;/p&gt;
    &lt;p&gt;They developed an algorithm to construct shapes and test them for the three-vertices property. Eventually, the algorithm produced the Noperthedron, which is made of 150 triangles and two regular 15-sided polygons. It looks like a rotund crystal vase with a wide base and top; one fan of the work has already 3D-printed a copy to use as a pencil holder.&lt;/p&gt;
    &lt;p&gt;Peter Lely&lt;/p&gt;
    &lt;p&gt;Steininger and Yurkevich then divided the parameter space of orientations into approximately 18 million tiny blocks, and tested the center point of each block to see if its corresponding orientation produced a Rupert passage. None of them did. Next, the researchers showed that each block satisfied either the local or global theorem, allowing them to rule out the entire block. Since these blocks fill out the entire parameter space, this meant that there is no Rupert passage through the Noperthedron.&lt;/p&gt;
    &lt;p&gt;The “natural conjecture has been proved false,” O’Rourke said.&lt;/p&gt;
    &lt;p&gt;It remains to be seen whether mathematicians can use the new method to generate other Noperts, or if they can find a different local theorem that can handle candidates like the rhombicosidodecahedron. But now that mathematicians know that Noperts do exist, “we’re on sound footing to study other shapes,” Murphy said.&lt;/p&gt;
    &lt;p&gt;Murphy, who like Steininger and Yurkevich has been exploring the question for its own sake, independent of his day job, feels a kinship across the centuries with Prince Rupert. “I like that he chose to use his retirement to do math and science in his castle,” he said.&lt;/p&gt;
    &lt;p&gt;Meanwhile, Steininger and Yurkevich are on the lookout for new questions to tackle. “We’re just humble mathematicians — we love working on such problems,” Steininger said. “We’ll keep doing that.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45694856</guid><pubDate>Fri, 24 Oct 2025 14:12:00 +0000</pubDate></item><item><title>Code Like a Surgeon</title><link>https://www.geoffreylitt.com/2025/10/24/code-like-a-surgeon</link><description>&lt;doc fingerprint="355491dd119110ed"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;October 2025&lt;/head&gt;
    &lt;head rend="h1"&gt;Code like a surgeon&lt;/head&gt;
    &lt;p&gt;A lot of people say AI will make us all “managers” or “editors”…but I think this is a dangerously incomplete view!&lt;/p&gt;
    &lt;p&gt;Personally, I’m trying to code like a surgeon.&lt;/p&gt;
    &lt;p&gt;A surgeon isn’t a manager, they do the actual work! But their skills and time are highly leveraged with a support team that handles prep, secondary tasks, admin. The surgeon focuses on the important stuff they are uniquely good at.&lt;/p&gt;
    &lt;p&gt;My current goal with AI coding tools is to spend 100% of my time doing stuff that matters. (As a UI prototyper, that mostly means tinkering with design concepts.)&lt;/p&gt;
    &lt;p&gt;It turns out there are a LOT of secondary tasks which AI agents are now good enough to help out with. Some things I’m finding useful to hand off these days:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Before attempting a big task, write a guide to relevant areas of the codebase&lt;/item&gt;
      &lt;item&gt;Spike out an attempt at a big change. Often I won’t use the result but I’ll review it as a sketch of where to go&lt;/item&gt;
      &lt;item&gt;Fix typescript errors or bugs which have a clear specification&lt;/item&gt;
      &lt;item&gt;Write documentation about what I’m building&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I often find it useful to run these secondary tasks async in the background – while I’m eating lunch, or even literally overnight!&lt;/p&gt;
    &lt;p&gt;When I sit down for a work session, I want to feel like a surgeon walking into a prepped operating room. Everything is ready for me to do what I’m good at.&lt;/p&gt;
    &lt;head rend="h2"&gt;Mind the autonomy slider&lt;/head&gt;
    &lt;p&gt;Notably, there is a huge difference between how I use AI for primary vs secondary tasks.&lt;/p&gt;
    &lt;p&gt;For the core design prototyping work, I still do a lot of coding by hand, and when I do use AI, I’m more careful and in the details. I need fast feedback loops and good visibility. (eg, I like Cursor tab-complete here)&lt;/p&gt;
    &lt;p&gt;Whereas for secondary tasks, I’m much much looser with it, happy to let an agent churn for hours in the background. The ability to get the job done eventually is the most important thing; speed and visibility matter less. Claude Code has been my go-to for long unsupervised sessions but Codex CLI is becoming a strong contender there too, possibly my new favorite.&lt;/p&gt;
    &lt;p&gt;These are very different work patterns! Reminds me of Andrej Karpathy’s “autonomy slider” concept. It’s dangerous to conflate different parts of the autonomy spectrum – the tools and mindset that are needed vary quite a lot.&lt;/p&gt;
    &lt;head rend="h2"&gt;Your agent doesn’t need a career trajectory&lt;/head&gt;
    &lt;p&gt;The “software surgeon” concept is a very old idea – Fred Brooks attributes it to Harlan Mills in his 1975 classic “The Mythical Man-Month”. He talks about a “chief programmer” who is supported by various staff including a “copilot” and various administrators. Of course, at the time, the idea was to have humans be in these support roles.&lt;/p&gt;
    &lt;p&gt;OK, so there is a super obvious angle here, that “AI has now made this approach economically viable where it wasn’t before”, yes yes… but I am also noticing a more subtle thing at play, something to do with status hierarchies.&lt;/p&gt;
    &lt;p&gt;A lot of the “secondary” tasks are “grunt work”, not the most intellectually fulfilling or creative part of the work. I have a strong preference for teams where everyone shares the grunt work; I hate the idea of giving all the grunt work to some lower-status members of the team. Yes, junior members will often have more grunt work, but they should also be given many interesting tasks to help them grow.&lt;/p&gt;
    &lt;p&gt;With AI this concern completely disappears! Now I can happily delegate pure grunt work. And the 24/7 availability is a big deal. I would never call a human intern at 11pm and tell them to have a research report on some code ready by 7am… but here I am, commanding my agent to do just that!&lt;/p&gt;
    &lt;head rend="h2"&gt;Notion is for surgeons?&lt;/head&gt;
    &lt;p&gt;Finally I’ll mention a couple thoughts on how this approach to work intersects with my employer, Notion.&lt;/p&gt;
    &lt;p&gt;First, as an employee, I find it incredibly valuable right now to work at a place that is bullish on AI coding tools. Having support for heavy use of AI coding tools, and a codebase that’s well setup for it, is enabling serious productivity gains for me – especially as a newcomer to a big codebase.&lt;/p&gt;
    &lt;p&gt;Secondly, as a product – in a sense I would say we are trying to bring this way of working to a broader group of knowledge workers beyond programmers. When I think about how that will play out, I like the mental model of enabling everyone to “work like a surgeon”.&lt;/p&gt;
    &lt;p&gt;The goal isn’t to delegate your core work, it’s to identify and delegate the secondary grunt work tasks, so you can focus on the main thing that matters.&lt;/p&gt;
    &lt;head rend="h2"&gt;Related reads&lt;/head&gt;
    &lt;p&gt;If you liked this perspective, you might enjoy reading these other posts I’ve written about the nature of human-AI collaboration:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Enough AI copilots! We need AI HUDs: “anyone serious about designing for AI should consider non-copilot form factors that more directly extend the human mind…”&lt;/item&gt;
      &lt;item&gt;AI-generated tools can make programming more fun: “Instead, I used AI to build a custom debugger UI… which made it more fun for me to do the coding myself…”&lt;/item&gt;
      &lt;item&gt;ChatGPT as muse, not oracle: “What if we were to think of LLMs not as tools for answering questions, but as tools for asking us questions and inspiring our creativity?&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45695621</guid><pubDate>Fri, 24 Oct 2025 15:25:17 +0000</pubDate></item><item><title>How to make a Smith chart</title><link>https://www.johndcook.com/blog/2025/10/23/smith-chart/</link><description>&lt;doc fingerprint="1d0b6d028f79c1a2"&gt;
  &lt;main&gt;
    &lt;p&gt;The Smith chart from electrical engineering is the image of a Cartesian grid under the function&lt;/p&gt;
    &lt;p&gt;f(z) = (z − 1)/(z + 1).&lt;/p&gt;
    &lt;p&gt;More specifically, it’s the image of a grid in the right half-plane.&lt;/p&gt;
    &lt;p&gt;This post will derive the basic mathematical properties of this graph but will not go into the applications. Said another way, I’ll explain how to make a Smith chart, not how to use one.&lt;/p&gt;
    &lt;p&gt;We will use z to denote points in the right half-plane and w to denote the image of these points under f. We will speak of lines in the z plane and the circles they correspond to in the w plane.&lt;/p&gt;
    &lt;head rend="h2"&gt;Möbius transformations&lt;/head&gt;
    &lt;p&gt;Our function f is a special case of a Möbius transformation. There is a theorem that says Möbius transformation map generalized circles to generalized circles. Here a generalized circle means a circle or a line; you can think of a line as a circle with infinite radius. We’re going to get a lot of mileage out of that theorem.&lt;/p&gt;
    &lt;head rend="h2"&gt;Image of the imaginary axis&lt;/head&gt;
    &lt;p&gt;The function f maps the imaginary axis in the z plane to the unit circle in the w plane. We can prove this using the theorem above. The imaginary axis is a line, so it’s image is either a line or a circle. We can take three points on the imaginary axis in the z plane and see where they go.&lt;/p&gt;
    &lt;p&gt;When we pick z equal to 0, i, and −i from the imaginary axis we get w values of −1, i, and −i. These three w values do not line on a line, so the image of the imaginary axis must be a circle. Furthermore, three points uniquely determine a circle, so the image of the imaginary axis is the circle containing −1, i, and −i, i.e. the unit circle.&lt;/p&gt;
    &lt;head rend="h2"&gt;Image of the right half-plane&lt;/head&gt;
    &lt;p&gt;The imaginary axis is the boundary of the right half-plane. Since it is mapped to the unit circle, the right half-plane is either mapped to the interior of the unit circle or the exterior of the unit circle. The point z = 1 goes to w = 0, and so the right half-plane is mapped inside the unit circle.&lt;/p&gt;
    &lt;head rend="h2"&gt;Images of vertical lines&lt;/head&gt;
    &lt;p&gt;Let’s think about what happens to vertical lines in the z plane, lines with constant positive real part. The images of these lines in the w plane must be either lines or circles. And since the right-half plane gets mapped inside the unit circle, these lines must get mapped to circles.&lt;/p&gt;
    &lt;p&gt;We can say a little more. All lines contain the point ∞, and f(∞) = 1, so the image of every vertical line in the z plane is a circle in the w plane, inside the unit circle and tangent to the unit circle at w = 1. (Tossing around ∞ is a bit informal, but it’s easy to make rigorous.)&lt;/p&gt;
    &lt;p&gt;The vertical lines in the z plane&lt;/p&gt;
    &lt;p&gt;map to tangent circles in the w plane.&lt;/p&gt;
    &lt;head rend="h2"&gt;Images of horizontal lines&lt;/head&gt;
    &lt;p&gt;Next, let’s think about horizontal lines in the z plane, lines with constant imaginary part. The image of these lines is either a line or a circle. Which is it? The image of a line is a line if it contains ∞, otherwise it’s a circle. Now f(z) = ∞ if and only if z = −1, and so the image of the real axis is a line, but the image of every other horizontal line is a circle.&lt;/p&gt;
    &lt;p&gt;Since f(∞) = 1, the image of every horizontal line passes through 1, just as the images of all the vertical lines passes through 1.&lt;/p&gt;
    &lt;p&gt;Since horizontal lines extend past the right half-plane, the image circles extend past the unit circle. The part of the line with positive real part gets mapped inside the unit circle, and the part of the line with negative real part gets mapped outside the unit circle. In particular, the image of the positive real axis is the interval [−1, 1].&lt;/p&gt;
    &lt;p&gt;Möbius transformations are conformal maps, and so they preserve angles of intersection. Since horizontal lines are perpendicular to vertical lines, the circles that are the images of the horizontal lines meet the circles that are the images of vertical lines at right angles.&lt;/p&gt;
    &lt;p&gt;The horizontal rays in the z plane&lt;/p&gt;
    &lt;p&gt;become partial circles in the w plane.&lt;/p&gt;
    &lt;p&gt;If we were to look at horizontal lines rather than rays, i.e. if we extended the lines into the left half-plane, the images in the w plane would be full circles.&lt;/p&gt;
    &lt;p&gt;Now let’s put our images together. The grid&lt;/p&gt;
    &lt;p&gt;in the z plane becomes the following in the w plane.&lt;/p&gt;
    &lt;p&gt;An evenly spaced grid in the z plane becomes a very unevenly spaced graph in the w plane. Things are crowded on the right hand side and sparse on the left. A useable Smith chart needs to be roughly evenly filled in, which means it has to be the image of an unevenly filled in grid in the z plane. For example, you’d need more vertical lines in the z plane with small real values than with large real values.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45696838</guid><pubDate>Fri, 24 Oct 2025 17:18:17 +0000</pubDate></item><item><title>Harnessing America's Heat Pump Moment</title><link>https://www.heatpumped.org/p/harnessing-america-s-heat-pump-moment</link><description>&lt;doc fingerprint="676f107f6a85b4ba"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Heat Pumped&lt;/item&gt;
      &lt;item&gt;Posts&lt;/item&gt;
      &lt;item&gt;Harnessing America’s Heat Pump Moment&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Harnessing America’s Heat Pump Moment&lt;/head&gt;
    &lt;head rend="h2"&gt;The tech works. The policy’s in place. So why are heat pumps still a hard sell?&lt;/head&gt;
    &lt;p&gt;Editor’s note: This is a guest post by Joseph DeNatale, an entrepreneur and project coordinator at Jetson Home. It originally appeared in Climate Drift earlier this year, and is republished on Heat Pumped with permission.&lt;/p&gt;
    &lt;p&gt;Joseph interviewed me when he was researching the piece, and I was excited to see that the final product touched many topics that I've been wanting to write about.&lt;/p&gt;
    &lt;p&gt;A big thank you to Joseph and Climate Drift for sharing with the Heat Pumped community - it's incredibly in-depth. Since there’s so much to digest, we’re splitting it up into 5 parts that we'll be sharing over the next few weeks.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Execution Is Everything: A Personal Perspective&lt;/head&gt;
    &lt;p&gt;As a small business owner, I’ve built a career not around inventing new things, but around making things happen: making sure systems run smoothly, projects get completed on time, and clients feel taken care of.&lt;/p&gt;
    &lt;p&gt;My work has been rooted in the real-world, hands-on, often chaotic rhythm of operations, logistics, and direct client service. Whether it’s organizing teams to execute live events, refining workflows to scale a growing business, or managing the delicate art of closing a sale, I’ve learned one simple truth: the hardest part is never the idea. It’s the execution.&lt;/p&gt;
    &lt;p&gt;So when I began diving into the world of home electrification—particularly heat pumps—that same truth surfaced again, just with higher stakes.&lt;/p&gt;
    &lt;p&gt;The technology isn’t the issue. In fact, the technology is there. It’s been there for decades, and it is continuing to improve. We’re not waiting on some magical breakthrough or futuristic device.&lt;/p&gt;
    &lt;p&gt;We’re waiting on people—mostly homeowners and home contractors, but also manufacturers and policy makers—to embrace, understand, and implement what already works.&lt;/p&gt;
    &lt;p&gt;This piece isn’t about reinventing the wheel. It’s about understanding why we’re not using the wheel we already have—and what it’s going to take, from the human side of the equation, to make heat pumps the obvious, accessible, and default choice for millions of American homes.&lt;/p&gt;
    &lt;head rend="h3"&gt;Heat Pumps Aren’t New—But This Moment Is&lt;/head&gt;
    &lt;p&gt;In the world of climate solutions, it’s easy to get distracted by what’s shiny and new—sleek devices, breakthrough technologies, futuristic models of sustainability.&lt;/p&gt;
    &lt;p&gt;But not every climate solution is some new-fangled wonder gadget. Some of them already exist. Some of them are sitting in basements and behind houses, quietly doing the work.&lt;/p&gt;
    &lt;p&gt;The heat pump is one of them.&lt;/p&gt;
    &lt;p&gt;Heat pumps are not new. In fact, the idea has been around for well over a century, and the technology has been used widely for decades—mostly in Europe and Asia, but also in pockets of the U.S.—for everything from water heating to whole-home climate control.&lt;/p&gt;
    &lt;p&gt;Modern heat pumps are highly efficient—anywhere from 2-4x more efficient than a furnace—and capable of replacing both a furnace and an air conditioner with a single system in virtually every climate. For millions of homes across the country, they offer a cleaner, quieter, and more precise way to stay comfortable year-round.&lt;/p&gt;
    &lt;p&gt;Importantly, heat pumps have also been shown to match or beat the operating costs of even the cheapest heating option—natural gas—in many cases. This has been demonstrated through both local and national studies. One study showed that over 90% of American households would save on energy bills by replacing worn-out heating equipment with the right-sized heat pump.&lt;/p&gt;
    &lt;p&gt;Installation costs vary wildly depending on many factors in a home, but with the introduction of generous incentives via the Inflation Reduction Act (IRA) and additional state programs, even these costs can be on-par with fossil fuel alternatives.&lt;/p&gt;
    &lt;p&gt;So why aren’t they everywhere?&lt;/p&gt;
    &lt;p&gt;The answer isn’t technical. It’s cultural, economic, and human.&lt;/p&gt;
    &lt;head rend="h3"&gt;TL;DR&lt;/head&gt;
    &lt;p&gt;Heat pumps are proven, efficient, and climate-friendly—but adoption is still slow.&lt;/p&gt;
    &lt;p&gt;The barrier isn’t the tech. It’s people:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Contractors who default to what they know&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Homeowners who need education and guidance&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;A fragmented market full of noise and misinformation&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This piece discusses these challenges, and then explores five keys to accelerating adoption:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Educate homeowners so heat pumps feel familiar and trustworthy.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Train the next-gen workforce and upskill legacy HVAC pros.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Leverage better tools and data to size and install systems right.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Prioritize quality and trust to build social proof and demand.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Align policy to phase out one-way ACs and normalize heat pumps.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Execution—not invention—is what will move the needle.&lt;/p&gt;
    &lt;head rend="h2"&gt;Hold On.. What’s A Heat Pump Again?&lt;/head&gt;
    &lt;p&gt;If you’re reading this piece, you probably know what a heat pump is (and you can feel free to skip this section).&lt;/p&gt;
    &lt;p&gt;But if you’re among the uninitiated – like, believe it or not, most people – here’s a (very) quick primer. (Editor’s note: check out Heat Pumps 101 if you want to dive deeper)&lt;/p&gt;
    &lt;p&gt;A heat pump works by drawing thermal energy (heat) out of the atmosphere and “pumping” it into the home. This process works in reverse for cooling. (Source)&lt;/p&gt;
    &lt;head rend="h3"&gt;The 2-Way AC&lt;/head&gt;
    &lt;p&gt;The term “heat pump”, it turns out, is a fairly unhelpful name for most people. In fact, there are some leaders in the home electrification industry who believe the name itself is one of the barriers to adoption. It’s one of many ways that the heat pump is misunderstood.&lt;/p&gt;
    &lt;p&gt;Think of a heat pump as a “2-way AC.” An air conditioner cools your home by pulling heat from inside an enclosed space and transferring it outside. Your refrigerator works the same way.&lt;/p&gt;
    &lt;p&gt;A heat pump does the same thing, but can also reverse the process to bring heat into the home. It uses a few key components to make this happen:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The fan pulls air across the system’s coils to help move heat in or out of the space.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The evaporator coil absorbs heat from the air inside your home (in cooling mode) or from the outside air (in heating mode).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The compressor pressurizes and moves a fluid called refrigerant through the system, enabling the heat transfer process.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The refrigerant is the working fluid that captures and carries heat from one place to another—either out of your home or into it.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What’s important to understand is that a heat pump does not create heat. It also doesn’t create cold (cold is the absence of heat, just like darkness is the absence of light). A heat pump simply transfers – pumps! – heat from one place to another.&lt;/p&gt;
    &lt;p&gt;“The difference between a heat pump and a one-way AC is just one valve. It still works perfectly fine as an air conditioner—there’s no difference. That’s why we’ve started calling them “two-way ACs” as an education tool. It helps people compare a two-way AC, which has a reverse gear, with a one-way AC—which, in my mind, is basically broken.”&lt;/p&gt;
    &lt;p&gt;But what about in the winter when it’s below freezing? In any environment where the temperature is above absolute zero (remember the Kelvin scale?) there is still a significant amount of heat in the air in the form of thermal energy.&lt;/p&gt;
    &lt;p&gt;That’s why a heat pump can still heat your home even on the coldest day of the year.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Heat Pumps Matter&lt;/head&gt;
    &lt;p&gt;The fact that heat pumps simply transfer heat—and do not create it—gives them the potential to heat homes without doing the thing that humans have done since time immemorial to keep warm: burn stuff.&lt;/p&gt;
    &lt;p&gt;In the U.S., over half of all homes still rely on burning fossil fuels for heat. Replacing those systems with electric, air source heat pumps (ASHPs) can significantly reduce household emissions, especially as the grid gets cleaner and moves towards a higher percentage of renewable energy (i.e. not burning stuff).&lt;/p&gt;
    &lt;p&gt;And, because they’re so efficient, heat pumps can lower operating costs over time—although this is highly dependent on where you live, as the cost of fuel and electricity varies widely. They’re also safer (no burning stuff), can improve indoor air quality (again, no burning), and create healthier, more comfortable homes.&lt;/p&gt;
    &lt;p&gt;Finally, heat pumps are a crucial component of an energy-independent home. Paired with solar panels and battery storage, a homeowner can heat and cool their home entirely with energy they generate on their own. Try that with a furnace!&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Metric&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Gas Furnace&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Air-Source Heat Pump (ASHP)&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Fuel Source&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Natural gas, propane, or oil&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Electricity&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Heating/Cooling&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Heating only&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Heats and cools (dual function)&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Air Quality&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Can introduce combustion byproducts; potential for CO&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;No combustion; generally better indoor air quality&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Health/Safety&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Risk of gas leaks, carbon monoxide&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;No combustion risk; safer for indoor environments&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Comfort&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Delivers blasts of hot air; on/off “short cycles”&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;More consistent, even heating/cooling with variable-speed options&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Initial Cost&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Typically lower (although the cost of a furnace + AC if replaced at the same time is often higher)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Often higher upfront, especially for cold-climate models. Costs can be lowered via incentive programs.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Operating Cost&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Depends on gas prices; cheaper where gas is low&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Can be lower, especially with efficient models + incentives and/or when paired with solar + battery storage&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Emissions&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Emits CO₂ and other GHGs&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Zero onsite emissions; cleaner with a green grid&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Climate Suitability&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Performs well in all climates&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Cold-climate models now perform down to -15 to -20°F&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Incentives/Rebates&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Limited (varies by region)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Significant federal/state incentives available&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;This is not a marginal climate solution. According to the IEA, global heat pump adoption could reduce carbon emissions by half a billion tons annually—roughly equivalent to the annual emissions of all cars in Europe.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Heat Pump Moment Has Arrived&lt;/head&gt;
    &lt;p&gt;For years, heat pumps were a niche topic, something discussed by green building enthusiasts, early adopters, or homeowners with unusually high energy awareness.&lt;/p&gt;
    &lt;p&gt;But that’s no longer the case. Here are four reasons why:&lt;/p&gt;
    &lt;head rend="h3"&gt;Cultural Momentum Is Building&lt;/head&gt;
    &lt;p&gt;The electrification movement is no longer a fringe concept. The push to “electrify everything” has gained traction among policymakers, climate advocates, startups, utilities, and even popular media.&lt;/p&gt;
    &lt;p&gt;From Substack newsletters to YouTube explainers, there’s growing awareness that building decarbonization—and especially heating and cooling—is one of the most practical, scalable ways for regular people to cut their emissions. Campaigns like Rewiring America’s “Go Electric” initiative frame heat pumps not just as energy-efficient appliances, but as a gateway to modern, climate-aligned homes.&lt;/p&gt;
    &lt;p&gt;This momentum is turning into real action. Heat pumps have now outsold gas furnaces in the U.S. every year since 2022.&lt;/p&gt;
    &lt;head rend="h3"&gt;Federal and State Policy Is Aligned (For Now)&lt;/head&gt;
    &lt;p&gt;For the time being (Republicans’ “One Big, Beautiful Bill” notwithstanding), both federal and state governments are backing this transition with significant financial and structural support. Editor’s note: Ouch. Since this piece was originally written, OBBB passed, and most tax credits at the federal level phase out at the end of this year. If you’ve been on the fence about getting a heat pump, now might be a good time to act!&lt;/p&gt;
    &lt;p&gt;The Inflation Reduction Act (IRA) has introduced a suite of rebates, tax credits, and grant programs designed to make heat pumps more affordable and accessible. Single-family households can receive up to $8,000 in upfront rebates for heat pump installations and up to $2,000 in federal tax credits, not to mention additional support for electrical panel upgrades and home energy audits. Editor’s note: the IRA rebates are federally funded, but implemented at the state level. Not all states are participating, and some that are haven’t rolled out their programs yet. In other states like California, the funds are already exhausted.&lt;/p&gt;
    &lt;p&gt;State and local governments are also leading the way in the transition away from fossil fuels on both the demand and supply sides. Programs like Efficiency Maine, TECH Clean California, and Mass Save offer generous incentives and no-interest financing to homeowners that drive the cost of electrification upgrades down even further. Meanwhile, New York City has banned gas in new construction, and Massachusetts has ordered public utilities to begin phasing out natural gas, a move which is being studied in at least 11 other states.&lt;/p&gt;
    &lt;head rend="h3"&gt;Private Capital Is Following&lt;/head&gt;
    &lt;p&gt;The heat pump space is no longer just a niche for contractors and utilities—it’s attracting serious private investment. VC-backed companies like Quilt are reimagining the user experience with sleek, design-forward equipment and app-based controls. Others, like Elephant Energy and Forge, are building “heat pump concierge” platforms that manage the customer journey end-to-end—from sales to install to rebate navigation.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Cold-Climate Performance Myth Has Been Fully Debunked&lt;/head&gt;
    &lt;p&gt;One of the biggest myths about heat pumps—that they can’t handle cold weather—is now being debunked at scale. While older, single-speed models may have struggled in colder temperatures, especially when size and installed incorrectly, modern cold-climate, variable-speed air-source heat pumps can provide reliable heating even at outdoor temperatures of -20°F.&lt;/p&gt;
    &lt;p&gt;These systems are already in use in northern New England, the upper Midwest, and Canada. In Nordic countries—some of the coldest climates in the word—the technology has been viable for decades.&lt;/p&gt;
    &lt;p&gt;And yet, despite all this momentum, heat pump adoption is still slow.&lt;/p&gt;
    &lt;p&gt;Why? Because the hardest part isn’t scaling the technology. It’s aligning the people—contractors, homeowners, policymakers, and market actors—who need to make it happen.&lt;/p&gt;
    &lt;p&gt;“We’ve had the technology dialed for 20, 30, 40 years, depending on how you’re arguing it—but it’s not being applied. It’s a human problem. It’s not a technical one. The technical one has been solved.”&lt;/p&gt;
    &lt;p&gt;That’s where we go next.&lt;/p&gt;
    &lt;p&gt;This is part 1 in a 5 part series about challenges and solutions in accelerating heat pump adoption across the US. Stay tuned for the next issue!&lt;/p&gt;
    &lt;head rend="h2"&gt;Want a heat pump in your own home?&lt;/head&gt;
    &lt;p&gt;The first Heat Pumped group buy generated lots of enthusiasm! There are still a handful of slots left, but you’ll have to act fast if you’re interested. Sign-ups close later this month (or when all the slots fill, whichever comes first).&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;head&gt;Do you want to participate in this group buy?&lt;/head&gt;
          &lt;p&gt;Fair &amp;amp; transparent heat pump pricing in the SF Bay Area and LA&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45698554</guid><pubDate>Fri, 24 Oct 2025 20:05:07 +0000</pubDate></item><item><title>The Swift SDK for Android</title><link>https://www.swift.org/blog/nightly-swift-sdk-for-android/</link><description>&lt;doc fingerprint="360e51139294ee0b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Announcing the Swift SDK for Android&lt;/head&gt;
    &lt;p&gt;Swift has matured significantly over the past decade — extending from cloud services to Windows applications, browser apps, and microcontrollers. Swift powers apps and services of all kinds, and thanks to its great interoperability, you can share code across platforms.&lt;/p&gt;
    &lt;p&gt;The Android workgroup is an open group, free for anyone to join, that aims to expand Swift to Android. Today, we are pleased to announce nightly preview releases of the Swift SDK for Android.&lt;/p&gt;
    &lt;p&gt;This milestone reflects months of effort by the Android workgroup, building on many years of grassroots community effort. With the SDK, developers can begin developing Android applications in Swift, opening new avenues for cross-platform development and accelerating innovation across the mobile ecosystem.&lt;/p&gt;
    &lt;p&gt;The Swift SDK for Android is available today, bundled with the Windows installer or downloadable separately for use on Linux or macOS.&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting Started&lt;/head&gt;
    &lt;p&gt;We’ve published a Getting Started guide to help you set up your first native Swift code on an Android device. The Swift for Android Examples help demonstrate end‑to‑end application workflows on Android.&lt;/p&gt;
    &lt;p&gt;With the Swift SDK for Android, you can now start porting your Swift packages to Android. Over 25% of packages in the Swift Package Index already build for Android, and the Community Showcase now indicates Android compatibility.&lt;/p&gt;
    &lt;p&gt;The swift-java project enables you to interoperate between Java and Swift. It is both a library and a code generator, enabling you to integrate Swift and Java in both directions by automatically generating safe and performant bindings. To learn about generating bindings to bring your business logic to Android, check out the recent Swift Server Side meetup talk by Mads Odgaard.&lt;/p&gt;
    &lt;head rend="h2"&gt;Next Steps&lt;/head&gt;
    &lt;p&gt;This preview release opens many new opportunities to continue improving these tools. We encourage you to share your experiences, ideas, tools and apps on the Swift forums. This post has been published on an associated thread for discussion, and new posts can be shared in the Android category.&lt;/p&gt;
    &lt;p&gt;The Android workgroup is drafting a vision document, currently under review, for directing future work regarding Swift on Android. This vision will outline priority areas and guide community efforts to maximize impact across the ecosystem. In addition, we maintain a project board that tracks the status of major efforts, as well as official CI for the Swift SDK for Android.&lt;/p&gt;
    &lt;p&gt;If you’re as excited as we are, join us and help make this ecosystem even better!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45698570</guid><pubDate>Fri, 24 Oct 2025 20:06:52 +0000</pubDate></item><item><title>TextEdit and the relief of simple software</title><link>https://www.newyorker.com/culture/infinite-scroll/textedit-and-the-relief-of-simple-software</link><description>&lt;doc fingerprint="b5c3191809c781c0"&gt;
  &lt;main&gt;
    &lt;p&gt;The so-called desktop first appeared on a home computer in 1981, with the release of the Xerox 8010 Star Information System. That device pioneered the graphical-user interface, or G.U.I., a convenient series of visual metaphors that allows us to interact more easily with our machines. The most basic computing interface is the command-line prompt, the empty box in which users write instructions in code directly to the machine; the Xerox Star replaced that forbidding vacuum with a friendly illustration of a tabletop surface, textured in patterned pixels, scattered with icons for folders, spreadsheets, and filing trays. A 1982 paper on the device described the then novel system: “Users are encouraged to think of the objects on the Desktop in physical terms. You can move the icons around to arrange your Desktop as you wish. (Messy Desktops are certainly possible, just as in real life.)” That mess derives from the files that we scatter on our desktops, agglomerations of data in formats that read as increasingly arcane and anachronistic: PDFs, JPGs, ZIPs, M4As. Similar to a physical desk drawer, the desktop is now something that we tend to stuff full and then forget about.&lt;/p&gt;
    &lt;p&gt;Over the past decade of computing, the desktop has receded. Digital-file systems have gone the way of the IRL inbox tray. Instead, we use the search bar to call up any file that we might want to find or tap apps that provide self-contained, streamlined experiences for consuming or producing content. Our phone home screens are even less customizable and less idiosyncratic than our computer desktops; we rarely think of individual files existing on our phones. Apple recently launched an iPhone operating-system interface redesign called Liquid Glass that turns its icons translucent, further homogenizing their appearance. Even such icons may soon be a thing of the past. The promise of artificial intelligence is that the desktop will disappear entirely and users will only interact with a chatbot or a voice that will carry out their bidding through plain language alone, morphing the entire computer into an anthropomorphized character. No mess there, just A.I. efficiency.&lt;/p&gt;
    &lt;p&gt;Amid the accelerating automation of our computers—and the proliferation of assistants and companions and agents designed to execute tasks for us—I’ve been thinking more about the desktop that’s hidden in the background of the laptop I use every day. Mine is strewn with screenshots and Word documents and e-books. What I’ve accrued the most of by far, though, are TextEdit files, from the bare-bones Mac app that just lets you type stuff into a blank window. Apple computers have come with text-editing software since the original Mac was released, in 1984; the current iteration of the program launched in the mid-nineties and has survived relatively unchanged. Over the past few years, I’ve found myself relying on TextEdit more as every other app has grown more complicated, adding cloud uploads, collaborative editing, and now generative A.I. TextEdit is not connected to the internet, like Google Docs. It is not part of a larger suite of workplace software, like Microsoft Word. You can write in TextEdit, and you can format your writing with a bare minimum of fonts and styling. Those files are stored as RTFs (short for rich-text format), one step up from the most basic TXT file. TextEdit now functions as my to-do-list app, my e-mail drafting window, my personal calendar, and my stash of notes to self, which act like digital Post-its.&lt;/p&gt;
    &lt;p&gt;I trust in TextEdit. It doesn’t redesign its interface without warning, the way Spotify does; it doesn’t hawk new features, and it doesn’t demand I update the app every other week, as Google Chrome does. I’ve tried out other software for keeping track of my random thoughts and ideas in progress—the personal note-storage app Evernote; the task-management board Trello; the collaborative digital workspace Notion, which can store and share company information. Each encourages you to adapt to a certain philosophy of organization, with its own formats and filing systems. But nothing has served me better than the brute simplicity of TextEdit, which doesn’t try to help you at all with the process of thinking. Using the app is the closest you can get to writing longhand on a screen. I could make lists on actual paper, of course, but I’ve also found that my brain has been so irredeemably warped by keyboards that I can only really get my thoughts down by typing. (Apparently my internal monologue takes place in Arial typeface, fourteen-point font.)&lt;/p&gt;
    &lt;p&gt;TextEdit is software that does what it says on the box. Its app icon features a sheet of lined paper. The writing window has an anachronistic measuring rule in the header with customizable margins, though I’ve never printed a TextEdit file. That kind of skeuomorphism—the design of a digital interface to resemble a physical one, by, for example, adding a faux-metal texture to a calculator app—has been out of fashion for more than a decade, ever since Apple moved away from it in the early twenty-tens. But the literalist sensibility is coming back into vogue as A.I. destabilizes our technological interactions once more and causes us to search for new metaphors to govern our digital lives. Earlier this year, Airbnb launched a heavily skeuomorphic redesign, swapping its buttons for tiny animated renderings of real-life objects: a slant-roofed home, for rentals; a hot-air balloon, for “experiences”; and a concierge bell, for services. The message of the interface is, Trust our software; it will deliver exactly what it promises. In practice, though, Airbnb’s offerings remain quite opaque, and driven by algorithmic recommendations that try to anticipate the user’s desires.&lt;/p&gt;
    &lt;p&gt;We users have learned that cloud-based apps and digital platforms are more likely to surveil us, mine our data, and manipulate our attention than to provide us the precise content and services we seek. Companies are trying to combat that accumulated sense of distrust in various other ways. This month, the A.I. company Anthropic tried to give itself a friendlier, more physical face by hosting a pop-up at a West Village storefront which it reportedly dubbed a “zero slop zone.” Attendees received free baseball caps embroidered with the word “thinking”—never mind that the product the company puts forward is supposed to do the thinking for you. Pinterest, the source of many complaints about A.I. images, has allowed users to minimize A.I. content in search results, and iPhones include a setting that disables Apple Intelligence features. The best way to reclaim our digital experiences, though, might be to stick with the likes of TextEdit, software that is unable to do anything except follow our commands. ♦&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45698716</guid><pubDate>Fri, 24 Oct 2025 20:25:58 +0000</pubDate></item></channel></rss>