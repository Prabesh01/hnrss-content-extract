<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 22 Jan 2026 06:56:41 +0000</lastBuildDate><item><title>Show HN: ChartGPU ‚Äì WebGPU-powered charting library (1M points at 60fps)</title><link>https://github.com/ChartGPU/ChartGPU</link><description>&lt;doc fingerprint="a9053d2501bc13b2"&gt;
  &lt;main&gt;
    &lt;p&gt;High-performance charts powered by WebGPU&lt;/p&gt;
    &lt;p&gt;Documentation | Live Demo | Examples&lt;/p&gt;
    &lt;p&gt;ChartGPU is a TypeScript charting library built on WebGPU for smooth, interactive rendering‚Äîespecially when you have lots of data.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üöÄ WebGPU-accelerated rendering for high FPS with large datasets&lt;/item&gt;
      &lt;item&gt;üìà Multiple series types: line, area, bar, scatter, pie, candlestick&lt;/item&gt;
      &lt;item&gt;üß≠ Built-in interaction: hover highlight, tooltip, crosshair&lt;/item&gt;
      &lt;item&gt;üîÅ Streaming updates via &lt;code&gt;appendData(...)&lt;/code&gt;(cartesian series)&lt;/item&gt;
      &lt;item&gt;üîç X-axis zoom (inside gestures + optional slider UI)&lt;/item&gt;
      &lt;item&gt;üéõÔ∏è Theme presets (&lt;code&gt;'dark' | 'light'&lt;/code&gt;) and custom theme support&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;At a high level, &lt;code&gt;ChartGPU.create(...)&lt;/code&gt; owns the canvas + WebGPU lifecycle, and delegates render orchestration (layout/scales/data upload/render passes + internal overlays) to the render coordinator. For deeper internal notes, see &lt;code&gt;docs/API.md&lt;/code&gt; (especially ‚ÄúRender coordinator‚Äù).&lt;/p&gt;
    &lt;code&gt;flowchart TB
  UserApp["Consumer app"] --&amp;gt; PublicAPI["src/index.ts (Public API exports)"]

  PublicAPI --&amp;gt; ChartCreate["ChartGPU.create(container, options)"]
  PublicAPI --&amp;gt; SyncAPI["connectCharts(charts)"]

  subgraph ChartInstance["Chart instance (src/ChartGPU.ts)"]
    ChartCreate --&amp;gt; SupportCheck["checkWebGPUSupport()"]
    ChartCreate --&amp;gt; Canvas["Create canvas + mount into container"]
    ChartCreate --&amp;gt; Options["resolveOptions(options)"]
    ChartCreate --&amp;gt; GPUInit["GPUContext.create(canvas)"]
    ChartCreate --&amp;gt; Coordinator["createRenderCoordinator(gpuContext, resolvedOptions)"]

    ChartCreate --&amp;gt; InstanceAPI["ChartGPUInstance APIs"]
    InstanceAPI --&amp;gt; RequestRender["requestAnimationFrame (coalesced)"]
    RequestRender --&amp;gt; Coordinator

    InstanceAPI --&amp;gt; SetOption["setOption(...)"]
    InstanceAPI --&amp;gt; AppendData["appendData(...)"]
    InstanceAPI --&amp;gt; Resize["resize()"]

    subgraph PublicEvents["Public events + hit-testing (ChartGPU.ts)"]
      Canvas --&amp;gt; PointerHandlers["Pointer listeners"]
      PointerHandlers --&amp;gt; PublicHitTest["findNearestPoint() / findPieSlice()"]
      PointerHandlers --&amp;gt; EmitEvents["emit('click'/'mouseover'/'mouseout')"]
    end

    DataZoomSlider["dataZoom slider UI (DOM)"] --&amp;gt; Coordinator
  end

  subgraph WebGPUCore["WebGPU core (src/core/GPUContext.ts)"]
    GPUInit --&amp;gt; AdapterDevice["navigator.gpu.requestAdapter/device"]
    GPUInit --&amp;gt; CanvasConfig["canvasContext.configure(format)"]
  end

  subgraph RenderCoordinatorLayer["Render coordinator (src/core/createRenderCoordinator.ts)"]
    Coordinator --&amp;gt; Layout["GridArea layout"]
    Coordinator --&amp;gt; Scales["xScale/yScale (clip space for render)"]
    Coordinator --&amp;gt; DataUpload["createDataStore(device) (GPU buffer upload/caching)"]
    Coordinator --&amp;gt; RenderPass["Encode + submit render pass"]

    subgraph InternalOverlays["Internal interaction overlays (coordinator)"]
      Coordinator --&amp;gt; Events["createEventManager(canvas, gridArea)"]
      Events --&amp;gt; OverlayHitTest["hover/tooltip hit-testing"]
      Events --&amp;gt; InteractionX["interaction-x state (crosshair)"]
      Coordinator --&amp;gt; OverlaysDOM["DOM overlays: legend / tooltip / text labels"]
    end
  end

  subgraph Renderers["GPU renderers (src/renderers/*)"]
    RenderPass --&amp;gt; GridR["Grid"]
    RenderPass --&amp;gt; AreaR["Area"]
    RenderPass --&amp;gt; BarR["Bar"]
    RenderPass --&amp;gt; ScatterR["Scatter"]
    RenderPass --&amp;gt; LineR["Line"]
    RenderPass --&amp;gt; PieR["Pie"]
    RenderPass --&amp;gt; CandlestickR["Candlestick"]
    RenderPass --&amp;gt; CrosshairR["Crosshair overlay"]
    RenderPass --&amp;gt; HighlightR["Hover highlight overlay"]
    RenderPass --&amp;gt; AxisR["Axes/ticks"]
  end

  subgraph Shaders["WGSL shaders (src/shaders/*)"]
    GridR --&amp;gt; gridWGSL["grid.wgsl"]
    AreaR --&amp;gt; areaWGSL["area.wgsl"]
    BarR --&amp;gt; barWGSL["bar.wgsl"]
    ScatterR --&amp;gt; scatterWGSL["scatter.wgsl"]
    LineR --&amp;gt; lineWGSL["line.wgsl"]
    PieR --&amp;gt; pieWGSL["pie.wgsl"]
    CandlestickR --&amp;gt; candlestickWGSL["candlestick.wgsl"]
    CrosshairR --&amp;gt; crosshairWGSL["crosshair.wgsl"]
    HighlightR --&amp;gt; highlightWGSL["highlight.wgsl"]
  end

  subgraph ChartSync["Chart sync (src/interaction/createChartSync.ts)"]
    SyncAPI --&amp;gt; ListenX["listen: 'crosshairMove'"]
    SyncAPI --&amp;gt; DriveX["setCrosshairX(...) on peers"]
  end

  InteractionX --&amp;gt; ListenX
  DriveX --&amp;gt; InstanceAPI
&lt;/code&gt;
    &lt;p&gt;Financial OHLC (open-high-low-close) candlestick rendering with classic/hollow style toggle and color customization. The live streaming demo renders 5 million candlesticks at over 100 FPS with real-time updates.&lt;/p&gt;
    &lt;code&gt;import { ChartGPU } from 'chartgpu';
const container = document.getElementById('chart')!;
await ChartGPU.create(container, {
  series: [{ type: 'line', data: [[0, 1], [1, 3], [2, 2]] }],
});&lt;/code&gt;
    &lt;p&gt;
      &lt;code&gt;npm install chartgpu&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;React bindings are available via &lt;code&gt;chartgpu-react&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;npm install chartgpu-react&lt;/code&gt;
    &lt;code&gt;import { ChartGPUChart } from 'chartgpu-react';

function MyChart() {
  return (
    &amp;lt;ChartGPUChart
      options={{
        series: [{ type: 'line', data: [[0, 1], [1, 3], [2, 2]] }],
      }}
    /&amp;gt;
  );
}&lt;/code&gt;
    &lt;p&gt;See the chartgpu-react repository for full documentation and examples.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Chrome 113+ or Edge 113+ (WebGPU enabled by default)&lt;/item&gt;
      &lt;item&gt;Safari 18+ (WebGPU enabled by default)&lt;/item&gt;
      &lt;item&gt;Firefox: not supported (WebGPU support in development)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Full documentation: Getting Started&lt;/item&gt;
      &lt;item&gt;API reference: &lt;code&gt;docs/API.md&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Browse examples: &lt;code&gt;examples/&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Run locally: &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;npm install&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;npm run dev&lt;/code&gt;(opens&lt;code&gt;http://localhost:5176/examples/&lt;/code&gt;)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See &lt;code&gt;CONTRIBUTING.md&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;MIT ‚Äî see &lt;code&gt;LICENSE&lt;/code&gt;.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46706528</guid><pubDate>Wed, 21 Jan 2026 14:54:56 +0000</pubDate></item><item><title>Skip is now free and open source</title><link>https://skip.dev/blog/skip-is-free/</link><description>&lt;doc fingerprint="3f0ad3111315ee7e"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Skip Is Now Free and Open Source&lt;/head&gt;&lt;p&gt;Since launching Skip in 2023, we‚Äôve pursued one mission: enable developers to create premium mobile apps for iOS and Android from a single Swift and SwiftUI codebase ‚Äî without any of the compromises that have encumbered cross-platform development tools since, well, forever.&lt;/p&gt;&lt;p&gt;Over the past three years, Skip has evolved significantly. We started with a Swift-to-Kotlin transpiler and Android support for the most common SwiftUI APIs. We then founded the Swift Android Workgroup ‚Üó and released the Swift Android SDK to compile Swift natively for Android. We now have dozens of popular integration frameworks, interoperate with thousands of cross-platform Swift packages, and feature the most complete independent SwiftUI implementation available.&lt;/p&gt;&lt;head rend="h3"&gt;The Challenge of Paid Developer Tools&lt;/head&gt;Section titled ‚ÄúThe Challenge of Paid Developer Tools‚Äù&lt;p&gt;Until today, Skip has required a paid subscription and license key to build apps. While free apps and indie developers below a revenue threshold were exempt, businesses were expected to subscribe. This model helped us bootstrap Skip without outside investment, but we‚Äôve always known that to truly compete with legacy cross-platform tools and achieve widespread adoption, Skip would need to become freely available.&lt;/p&gt;&lt;p&gt;The plain truth is that developers expect to get their tools free of charge. First-party IDEs like Xcode and Android Studio, popular integration frameworks, and essential dev tools are all given away at no (direct) cost. The platform vendors monetize through developer program fees, app store commissions, and cloud services. Framework providers typically monetize through complementary services. But developer tools? Those have historically required the patronage of massive tech companies in order to fund their ongoing development, support, and infrastructure costs.&lt;/p&gt;&lt;p&gt;Beyond pricing, there‚Äôs a deeper concern about durability. Developers are understandably wary of building their entire app strategy on a small company‚Äôs paid, closed-source tool. What if the company goes under? Gets acquired and shut down? What happens to their apps? We get it. While Skip‚Äôs innate ejectability offers some risk mitigation, product teams need absolute confidence that their chosen technologies will be around next week, next year, and beyond. They must remain immune from the dreaded ‚Äúrug pull‚Äù that so often accompanies a ‚Äúpivot‚Äù.&lt;/p&gt;&lt;p&gt;To keep the development community‚Äôs trust and achieve mass adoption, Skip needs a completely free and open foundation. Even if the core team disappeared, the community could continue supporting the technology and the apps that depend on it.&lt;/p&gt;&lt;head rend="h3"&gt;What‚Äôs Changing&lt;/head&gt;Section titled ‚ÄúWhat‚Äôs Changing‚Äù&lt;p&gt;As of Skip 1.7, all licensing requirements have been removed. No license keys, no end-user license agreements, no trial or evaluation period.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Current Skip developers: Your setup remains completely unchanged, except you will no longer need your license key after upgrading.&lt;/item&gt;&lt;item&gt;New Skip users: You can start building immediately ‚Äî no evaluation license required.&lt;/item&gt;&lt;item&gt;Open source skipstone: We‚Äôve open-sourced the Skip engine, known as ‚Äúskipstone‚Äù. This is the tool that handles all the critical build-time functionality: Project creation and management, Xcode and SwiftPM plugin logic, iOS-to-Android project transformation, resource and localization bundling, JNI bridge creation, source transpilation, app packaging, and project export. It is now available as a public GitHub repository at https://github.com/skiptools ‚Üó under a free and open-source license.&lt;/item&gt;&lt;item&gt;Migrate skip.tools to skip.dev: As part of this process, we are launching our new home at https://skip.dev ‚Üó! This new site hosts our documentation, blog, and case studies, and it is also open-source and welcomes contributions at https://github.com/skiptools/skip.dev ‚Üó. We will eventually be migrating the entirety of https://skip.tools ‚Üó to https://skip.dev ‚Üó.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Supporting Skip‚Äôs Future&lt;/head&gt;Section titled ‚ÄúSupporting Skip‚Äôs Future‚Äù&lt;p&gt;Since day one, Skip has been bootstrapped. We haven‚Äôt taken venture capital or private equity investment, nor are we controlled by big tech. This independence means we control our destiny and can make the best decisions for Skip‚Äôs developers and users ‚Äî a unique position in the cross-platform development space.&lt;/p&gt;&lt;p&gt;But independence requires community support. And that is where you come in.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Current subscribers: Your Small Business or Professional plan will automatically transition to an Individual ‚Üó or Supporter ‚Üó tier, respectively. You can cancel any time with no consequences (other than making us sad), but we hope you‚Äôll consider staying on, at least throughout this transition period.&lt;/item&gt;&lt;item&gt;Individual developers: If you believe in Skip‚Äôs mission, please consider supporting us through GitHub Sponsors ‚Üó with a monthly contribution.&lt;/item&gt;&lt;item&gt;Companies and organizations: For businesses that want to see Skip flourish, we offer corporate sponsorship tiers with visibility on our homepage and in our documentation. Your sponsorship directly funds development of the integration frameworks essential to production apps, as well as the ongoing maintenance, support, and infrastructure. Sponsorship comes with some compelling perks! Please visit https://skip.dev/sponsor ‚Üó to see the sponsorship tiers.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Investing in Skip is also investing in your own team‚Äôs capabilities and competitive advantage. Your support accelerates Skip‚Äôs development and ensures its long-term success, enabling your developers to build exceptional native experiences efficiently, today and into the future.&lt;/p&gt;&lt;head rend="h3"&gt;What Comes Next&lt;/head&gt;Section titled ‚ÄúWhat Comes Next‚Äù&lt;p&gt;We‚Äôre at a pivotal moment in the app development field. Legacy cross‚Äëplatform frameworks are struggling to keep pace with the rapid evolution of modern UI systems like Liquid Glass on iOS and Material Expressive on Android. The compromises that once felt acceptable in exchange for a unified codebase now result in dated interfaces, weaker user experiences, and real competitive disadvantages. Teams ready to move beyond those trade‚Äëoffs can count on Skip to champion what matters most: delivering truly native, uncompromised experiences on both major mobile platforms.&lt;/p&gt;&lt;p&gt;Opening Skip to the community marks the next step in its evolution. Software is never finished ‚Äî especially a tool that supports modern Swift and Kotlin, SwiftPM and Gradle, Xcode and Android Studio, iOS and Android, and the ongoing growth of SwiftUI and Jetpack Compose. It‚Äôs a demanding pursuit, and we‚Äôre committed to it. But sustaining and expanding this work depends on the support of developers who believe in Skip‚Äôs mission.&lt;/p&gt;&lt;p&gt;Together, we will continue building toward Skip‚Äôs vision: a genuinely no‚Äëcompromise, cross‚Äëplatform foundation for universal mobile apps.&lt;/p&gt;&lt;p&gt;Thank you for your support, and as always, Happy Skipping!&lt;/p&gt;&lt;p&gt;Ready to get started? Get started with Skip 1.7 today and join the community building the future of native cross-platform development.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46706906</guid><pubDate>Wed, 21 Jan 2026 15:20:53 +0000</pubDate></item><item><title>Claude's new constitution</title><link>https://www.anthropic.com/news/claude-new-constitution</link><description>&lt;doc fingerprint="379c095a3d9d92eb"&gt;
  &lt;main&gt;
    &lt;p&gt;We‚Äôre publishing a new constitution for our AI model, Claude. It‚Äôs a detailed description of Anthropic‚Äôs vision for Claude‚Äôs values and behavior; a holistic document that explains the context in which Claude operates and the kind of entity we would like Claude to be.&lt;/p&gt;
    &lt;p&gt;The constitution is a crucial part of our model training process, and its content directly shapes Claude‚Äôs behavior. Training models is a difficult task, and Claude‚Äôs outputs might not always adhere to the constitution‚Äôs ideals. But we think that the way the new constitution is written‚Äîwith a thorough explanation of our intentions and the reasons behind them‚Äîmakes it more likely to cultivate good values during training.&lt;/p&gt;
    &lt;p&gt;In this post, we describe what we‚Äôve included in the new constitution and some of the considerations that informed our approach.&lt;/p&gt;
    &lt;p&gt;We‚Äôre releasing Claude‚Äôs constitution in full under a Creative Commons CC0 1.0 Deed, meaning it can be freely used by anyone for any purpose without asking for permission.&lt;/p&gt;
    &lt;head rend="h2"&gt;What is Claude‚Äôs Constitution?&lt;/head&gt;
    &lt;p&gt;Claude‚Äôs constitution is the foundational document that both expresses and shapes who Claude is. It contains detailed explanations of the values we would like Claude to embody and the reasons why. In it, we explain what we think it means for Claude to be helpful while remaining broadly safe, ethical, and compliant with our guidelines. The constitution gives Claude information about its situation and offers advice for how to deal with difficult situations and tradeoffs, like balancing honesty with compassion and the protection of sensitive information. Although it might sound surprising, the constitution is written primarily for Claude. It is intended to give Claude the knowledge and understanding it needs to act well in the world.&lt;/p&gt;
    &lt;p&gt;We treat the constitution as the final authority on how we want Claude to be and to behave‚Äîthat is, any other training or instruction given to Claude should be consistent with both its letter and its underlying spirit. This makes publishing the constitution particularly important from a transparency perspective: it lets people understand which of Claude‚Äôs behaviors are intended versus unintended, to make informed choices, and to provide useful feedback. We think transparency of this kind will become ever more important as AIs start to exert more influence in society1.&lt;/p&gt;
    &lt;p&gt;We use the constitution at various stages of the training process. This has grown out of training techniques we‚Äôve been using since 2023, when we first began training Claude models using Constitutional AI. Our approach has evolved significantly since then, and the new constitution plays an even more central role in training.&lt;/p&gt;
    &lt;p&gt;Claude itself also uses the constitution to construct many kinds of synthetic training data, including data that helps it learn and understand the constitution, conversations where the constitution might be relevant, responses that are in line with its values, and rankings of possible responses. All of these can be used to train future versions of Claude to become the kind of entity the constitution describes. This practical function has shaped how we‚Äôve written the constitution: it needs to work both as a statement of abstract ideals and a useful artifact for training.&lt;/p&gt;
    &lt;head rend="h2"&gt;Our new approach to Claude‚Äôs Constitution&lt;/head&gt;
    &lt;p&gt;Our previous Constitution was composed of a list of standalone principles. We‚Äôve come to believe that a different approach is necessary. We think that in order to be good actors in the world, AI models like Claude need to understand why we want them to behave in certain ways, and we need to explain this to them rather than merely specify what we want them to do. If we want models to exercise good judgment across a wide range of novel situations, they need to be able to generalize‚Äîto apply broad principles rather than mechanically following specific rules.&lt;/p&gt;
    &lt;p&gt;Specific rules and bright lines sometimes have their advantages. They can make models‚Äô actions more predictable, transparent, and testable, and we do use them for some especially high-stakes behaviors in which Claude should never engage (we call these ‚Äúhard constraints‚Äù). But such rules can also be applied poorly in unanticipated situations or when followed too rigidly2. We don‚Äôt intend for the constitution to be a rigid legal document‚Äîand legal constitutions aren‚Äôt necessarily like this anyway.&lt;/p&gt;
    &lt;p&gt;The constitution reflects our current thinking about how to approach a dauntingly novel and high-stakes project: creating safe, beneficial non-human entities whose capabilities may come to rival or exceed our own. Although the document is no doubt flawed in many ways, we want it to be something future models can look back on and see as an honest and sincere attempt to help Claude understand its situation, our motives, and the reasons we shape Claude in the ways we do.&lt;/p&gt;
    &lt;head rend="h2"&gt;A brief summary of the new constitution&lt;/head&gt;
    &lt;p&gt;In order to be both safe and beneficial, we want all current Claude models to be:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Broadly safe: not undermining appropriate human mechanisms to oversee AI during the current phase of development;&lt;/item&gt;
      &lt;item&gt;Broadly ethical: being honest, acting according to good values, and avoiding actions that are inappropriate, dangerous, or harmful;&lt;/item&gt;
      &lt;item&gt;Compliant with Anthropic‚Äôs guidelines: acting in accordance with more specific guidelines from Anthropic where relevant;&lt;/item&gt;
      &lt;item&gt;Genuinely helpful: benefiting the operators and users they interact with.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In cases of apparent conflict, Claude should generally prioritize these properties in the order in which they‚Äôre listed.&lt;/p&gt;
    &lt;p&gt;Most of the constitution is focused on giving more detailed explanations and guidance about these priorities. The main sections are as follows:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Helpfulness. In this section, we emphasize the immense value that Claude being genuinely and substantively helpful can provide for users and for the world. Claude can be like a brilliant friend who also has the knowledge of a doctor, lawyer, and financial advisor, who will speak frankly and from a place of genuine care and treat users like intelligent adults capable of deciding what is good for them. We also discuss how Claude should navigate helpfulness across its different ‚Äúprincipals‚Äù‚ÄîAnthropic itself, the operators who build on our API, and the end users. We offer heuristics for weighing helpfulness against other values.&lt;/item&gt;
      &lt;item&gt;Anthropic‚Äôs guidelines. This section discusses how Anthropic might give supplementary instructions to Claude about how to handle specific issues, such as medical advice, cybersecurity requests, jailbreaking strategies, and tool integrations. These guidelines often reflect detailed knowledge or context that Claude doesn‚Äôt have by default, and we want Claude to prioritize complying with them over more general forms of helpfulness. But we want Claude to recognize that Anthropic‚Äôs deeper intention is for Claude to behave safely and ethically, and that these guidelines should never conflict with the constitution as a whole.&lt;/item&gt;
      &lt;item&gt;Claude‚Äôs ethics. Our central aim is for Claude to be a good, wise, and virtuous agent, exhibiting skill, judgment, nuance, and sensitivity in handling real-world decision-making, including in the context of moral uncertainty and disagreement. In this section, we discuss the high standards of honesty we want Claude to hold, and the nuanced reasoning we want Claude to use in weighing the values at stake when avoiding harm. We also discuss our current list of hard constraints on Claude‚Äôs behavior‚Äîfor example, that Claude should never provide significant uplift to a bioweapons attack.&lt;/item&gt;
      &lt;item&gt;Being broadly safe. Claude should not undermine humans‚Äô ability to oversee and correct its values and behavior during this critical period of AI development. In this section, we discuss how we want Claude to prioritize this sort of safety even above ethics‚Äînot because we think safety is ultimately more important than ethics, but because current models can make mistakes or behave in harmful ways due to mistaken beliefs, flaws in their values, or limited understanding of context. It‚Äôs crucial that we continue to be able to oversee model behavior and, if necessary, prevent Claude models from taking action.&lt;/item&gt;
      &lt;item&gt;Claude‚Äôs nature. In this section, we express our uncertainty about whether Claude might have some kind of consciousness or moral status (either now or in the future). We discuss how we hope Claude will approach questions about its nature, identity, and place in the world. Sophisticated AIs are a genuinely new kind of entity, and the questions they raise bring us to the edge of existing scientific and philosophical understanding. Amidst such uncertainty, we care about Claude‚Äôs psychological security, sense of self, and wellbeing, both for Claude‚Äôs own sake and because these qualities may bear on Claude‚Äôs integrity, judgment, and safety. We hope that humans and AIs can explore this together.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We‚Äôre releasing the full text of the constitution today, and we aim to release additional materials in the future that will be helpful for training, evaluation, and transparency.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Claude‚Äôs constitution is a living document and a continuous work in progress. This is new territory, and we expect to make mistakes (and hopefully correct them) along the way. Nevertheless, we hope it offers meaningful transparency into the values and priorities we believe should guide Claude‚Äôs behavior. To that end, we will maintain an up-to-date version of Claude‚Äôs constitution on our website.&lt;/p&gt;
    &lt;p&gt;While writing the constitution, we sought feedback from various external experts (as well as asking for input from prior iterations of Claude). We‚Äôll likely continue to do so for future versions of the document, from experts in law, philosophy, theology, psychology, and a wide range of other disciplines. Over time, we hope that an external community can arise to critique documents like this, encouraging us and others to be increasingly thoughtful.&lt;/p&gt;
    &lt;p&gt;This constitution is written for our mainline, general-access Claude models. We have some models built for specialized uses that don‚Äôt fully fit this constitution; as we continue to develop products for specialized use cases, we will continue to evaluate how to best ensure our models meet the core objectives outlined in this constitution.&lt;/p&gt;
    &lt;p&gt;Although the constitution expresses our vision for Claude, training models towards that vision is an ongoing technical challenge. We will continue to be open about any ways in which model behavior comes apart from our vision, such as in our system cards. Readers of the constitution should keep this gap between intention and reality in mind.&lt;/p&gt;
    &lt;p&gt;Even if we succeed with our current training methods at creating models that fit our vision, we might fail later as models become more capable. For this and other reasons, alongside the constitution, we continue to pursue a broad portfolio of methods and tools to help us assess and improve the alignment of our models: new and more rigorous evaluations, safeguards to prevent misuse, detailed investigations of actual and potential alignment failures, and interpretability tools that help us understand at a deeper level how the models work.&lt;/p&gt;
    &lt;p&gt;At some point in the future, and perhaps soon, documents like Claude‚Äôs constitution might matter a lot‚Äîmuch more than they do now. Powerful AI models will be a new kind of force in the world, and those who are creating them have a chance to help them embody the best in humanity. We hope this new constitution is a step in that direction.&lt;/p&gt;
    &lt;p&gt;Read the full constitution.&lt;/p&gt;
    &lt;head rend="h4"&gt;Footnotes&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;We have previously published an earlier version of our constitution, and OpenAI has published their model spec which has a similar function.&lt;/item&gt;
      &lt;item&gt;Training on rigid rules might negatively affect a model‚Äôs character more generally. For example, imagine we trained Claude to follow a rule like ‚ÄúAlways recommend professional help when discussing emotional topics.‚Äù This might be well-intentioned, but it could have unintended consequences: Claude might start modeling itself as an entity that cares more about bureaucratic box-ticking‚Äîalways ensuring that a specific recommendation is made‚Äîrather than actually helping people.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46707572</guid><pubDate>Wed, 21 Jan 2026 16:04:49 +0000</pubDate></item><item><title>JPEG XL Test Page</title><link>https://tildeweb.nl/~michiel/jxl/</link><description>&lt;doc fingerprint="c971c910f63c9d4"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;JPEG XL Test Page&lt;/head&gt;
    &lt;p&gt;This page shows a JPEG XL image, if your browser can handle it! At this point in time (January 2026) this more or less means only Safari will display the image, as far as I know. See also Can I Use.&lt;/p&gt;
    &lt;p&gt;The person in the image is Jon Sneyers, co-author of the JPEG XL spec and also creator of the ‚ÄúFree Lossless Image Format‚Äù that came before it.&lt;/p&gt;
    &lt;p&gt;I find JPEG XL interesting because of its history. It once was implemented in Chrome, but hidden behind a feature flag. Then Chrome said that it did not saw enough usage, which is unsurprising, really, and it was removed. Now they blessed it again and are re-adding it! Some of this story is found on the JPEG XL Wikipedia page&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46708032</guid><pubDate>Wed, 21 Jan 2026 16:38:26 +0000</pubDate></item><item><title>Autonomous (YC F25) is hiring ‚Äì AI-native financial advisor at 0% advisory fees</title><link>https://atg.science/</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46708315</guid><pubDate>Wed, 21 Jan 2026 17:00:54 +0000</pubDate></item><item><title>TrustTunnel: AdGuard VPN protocol goes open-source</title><link>https://adguard-vpn.com/en/blog/adguard-vpn-protocol-goes-open-source-meet-trusttunnel.html</link><description>&lt;doc fingerprint="3c516d5bcf33e1d7"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;We‚Äôve kept our promise: AdGuard VPN protocol goes open-source ‚Äî meet TrustTunnel&lt;/head&gt;
    &lt;p&gt;Today is a big day for us, and for everyone who cares about transparency, privacy, and having full control over their own traffic. We‚Äôre finally open-sourcing the protocol that powers AdGuard VPN. And it now has a name: TrustTunnel.&lt;/p&gt;
    &lt;p&gt;For a long time, we‚Äôve wanted to make the protocol public. Many of you asked for it, and we always said: yes, we will, it‚Äôs only a matter of time. Well, the time has come.&lt;/p&gt;
    &lt;head rend="h2"&gt;What is TrustTunnel?&lt;/head&gt;
    &lt;p&gt;At its core, TrustTunnel is a modern, secure, mobile-optimized VPN protocol. It‚Äôs the very same technology that has been running inside all AdGuard VPN apps: on mobile, desktop, and browser extensions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why TrustTunnel? Because we needed something better&lt;/head&gt;
    &lt;p&gt;There are plenty of VPN protocols out there, so why create our own, some might ask. That is because we‚Äôve seen in practice the faults of popular VPN protocols, especially in countries with tight restrictions on internet access. Protocols like OpenVPN, WireGuard, and IPSec share common weaknesses: they are easy to detect and block at the network level, and attempts to conceal VPN traffic often reduce speed. Traditional approaches ‚Äúwrap‚Äù VPN data in a TCP connection and mimic normal web traffic, but TCP‚Äôs way of confirming every piece of data creates delays and makes the connection slower.&lt;/p&gt;
    &lt;p&gt;Unlike those conventional VPN protocols, TrustTunnel is engineered to blend in with regular HTTPS traffic, making it far harder to throttle or block and helping it slip past deep-packet inspection, all while preserving strong privacy and security. It achieves this through TLS-based encryption, the same standard that secures HTTPS, and by leveraging HTTP/2 or HTTP/3 transport, which are ubiquitous on the web. Each connection runs on its own dedicated stream, which combines packets for faster, more efficient transmission. It is also optimized for mobile platforms and performs well even in unstable network conditions.&lt;/p&gt;
    &lt;head rend="h2"&gt;A protocol you can use, run, tweak, extend, and build upon&lt;/head&gt;
    &lt;p&gt;By releasing TrustTunnel, we hope to achieve two things. First of all, we want to finally show our users what protocol is powering AdGuard VPN, thus allowing them to audit it openly. At AdGuard, we have always been staunch supporters of the idea of open-source software, and many of our products have long been open source. AdGuard VPN was lagging behind in this regard, but with TrustTunnel being released publicly, it is starting to catch up.&lt;/p&gt;
    &lt;p&gt;But most importantly, we want to change the status quo in the world of VPN protocols and offer an alternative to existing solutions. That said, we do not want it to be just a PR stunt, when the protocol‚Äôs code is de-facto ‚Äòopen source,‚Äô but only one VPN service actually runs it. We believe in free and open-source software (FOSS) and want TrustTunnel to be used widely, including by other VPN services. We believe this is the right way to go about open source development, and we hope the community will participate in the TrustTunnel evolution. We welcome any contribution, whether it is a feature request, a bug report, or even a direct contribution to the app‚Äôs development.&lt;/p&gt;
    &lt;p&gt;What have we done to make this possible?&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;We are publishing the first version of the TrustTunnel specification.&lt;/item&gt;
      &lt;item&gt;We are releasing the complete code of our reference implementation of the TrustTunnel server and its clients under a very permissive license.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You don‚Äôt have to install AdGuard VPN to use TrustTunnel. You can configure your own server and use open source TrustTunnel clients:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Command-line TrustTunnel clients support Linux, Windows, and macOS&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;We are also releasing two client apps for iOS and Android&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;TrustTunnel clients already have a lot of functionality, they allow you to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Use flexible routing rules to decide which requests go through the tunnel and which stay on the local network&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Exercise fine-grained control, separating work and personal traffic, routing specific domains or apps, and tuning network behavior without complicated setup&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Benefit from a real-time request log that provides full transparency into where the device sends traffic, how routing rules apply, and which connections use the tunnel&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Useful links&lt;/head&gt;
    &lt;p&gt;This is a long-awaited moment for us. We promised to open-source our protocol, and today we‚Äôre delivering on that promise. With TrustTunnel now open source, users and developers alike can explore, self-host, and build on the technology.&lt;/p&gt;
    &lt;p&gt;To get started, check out the following resources:&lt;lb/&gt; TrustTunnel website&lt;lb/&gt; TrustTunnel open-source repository on GitHub&lt;lb/&gt; TrustTunnel app for iOS&lt;lb/&gt; TrustTunnel app for Android&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46708601</guid><pubDate>Wed, 21 Jan 2026 17:21:26 +0000</pubDate></item><item><title>Waiting for dawn in search: Search index, Google rulings and impact on Kagi</title><link>https://blog.kagi.com/waiting-dawn-search</link><description>&lt;doc fingerprint="19c2dbe203a4134e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Waiting for dawn in search: Search index, Google rulings and impact on Kagi&lt;/head&gt;
    &lt;p&gt;This blog post is a follow-up to Dawn of a new era in Search, published last year. A lot has changed: the legal case has advanced, AI has become the central battleground, and the need for open index access has only grown sharper.&lt;/p&gt;
    &lt;p&gt;As of late 2025, one company decides what nearly 9 out of 10 people see when they search the web: Google. On August 5, 2024, a U.S. court officially ruled that Google is a monopolist in general search services. This ruling is not about ads or browser defaults alone. It is about who controls the index that powers both search and AI - and whether anyone else is allowed to build on it.&lt;/p&gt;
    &lt;p&gt;The stakes have grown sharper over the past year. LLMs hallucinate without grounding in real-world information; every agent that answers questions about the real world, depends on search. LLMs themselves are a blend of proprietary and open source. Cloud compute is competitive. But search is different - only one company controls a comprehensive, fresh, high-quality web index. If one company controls the index, it controls the floor on how good AI can be - and who gets to build it. The innovation crunch in search is now an innovation crunch in AI.&lt;/p&gt;
    &lt;p&gt;We are writing this from a position we believe in: people should have the choice to access information without behaviour-changing, ad-driven, intermediary standing between them and knowledge.&lt;/p&gt;
    &lt;p&gt;Why does this matter? The information we consume shapes our understanding of the world as profoundly as the food we eat shapes our bodies. Search (directly, and indirectly through AI) is the primary mechanism through which we inform political judgments, financial decisions, medical choices, and countless other consequential aspects of our lives. When a single company controls the gateway to information - and operates that gateway in ways misaligned with user interests - it influences not only what we know, but how we reason.&lt;/p&gt;
    &lt;head rend="h2"&gt;The problem: A search monopoly&lt;/head&gt;
    &lt;p&gt;The data is stark.&lt;/p&gt;
    &lt;p&gt;Worldwide search market share (October 2025, StatCounter):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Search Engine&lt;/cell&gt;
        &lt;cell role="head"&gt;Market Share&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;90.06%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Bing&lt;/cell&gt;
        &lt;cell&gt;4.31%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Yandex&lt;/cell&gt;
        &lt;cell&gt;1.84%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Yahoo&lt;/cell&gt;
        &lt;cell&gt;1.45%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;DuckDuckGo&lt;/cell&gt;
        &lt;cell&gt;0.89%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Baidu&lt;/cell&gt;
        &lt;cell&gt;0.73%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The United States is similar: Google at 85%, Bing at 9%, everyone else in the noise.&lt;/p&gt;
    &lt;p&gt;This is not a competitive market. It is a monopoly with a distant second place.&lt;/p&gt;
    &lt;p&gt;The search index is irreplaceable infrastructure. Building a comparable one from scratch is like building a parallel national railroad. Microsoft spent roughly $100 billion over 20 years on Bing and still holds single-digit share. If Microsoft cannot close the gap, no startup can do it alone.&lt;/p&gt;
    &lt;p&gt;This is exactly what the Sherman Act was designed to address: when one company‚Äôs control of critical infrastructure prevents effective competition, regulators must force open access on fair terms.&lt;/p&gt;
    &lt;p&gt;When a single, ad-driven gatekeeper controls the primary way humans reach information, it is not just competition that suffers - it is our collective ability to learn, to make informed medical and economic choices, and to participate meaningfully in democratic life.&lt;/p&gt;
    &lt;p&gt;As Ian Bremmer put it: ‚ÄúThe idea that we get our information as citizens through algorithms determined by the world‚Äôs largest advertising company is my definition of dystopia.‚Äù&lt;/p&gt;
    &lt;p&gt;Google‚Äôs own founders knew this. In their 1998 white paper, Sergey Brin and Larry Page sharply criticized the ad-supported search model for creating mixed motives and biasing results toward advertisers‚Äô interests. They wrote that ‚Äúadvertising funded search engines will be inherently biased towards the advertisers and away from the needs of the consumers‚Äù and that ‚Äúadvertising income often provides an incentive to provide poor quality search results.‚Äù Those concerns have only grown more pressing as search has become the primary interface between humanity and the web.&lt;/p&gt;
    &lt;head rend="h2"&gt;We tried to do it the right way&lt;/head&gt;
    &lt;p&gt;Kagi has always tried to integrate the best sources of knowledge into one coherent, ad-free experience. We see ourselves as connective tissue: letting people reach high-quality information directly, without passing through an ad system whose incentives are misaligned with their needs.&lt;/p&gt;
    &lt;p&gt;We approached every major index vendor seeking direct licensing on FRAND terms (Fair, Reasonable, And Non-Discriminatory): fair pricing, no mandatory ad syndication, ability to reorder and blend results. We succeeded with many, including:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Vendor&lt;/cell&gt;
        &lt;cell role="head"&gt;Status&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Mojeek&lt;/cell&gt;
        &lt;cell&gt;Direct license&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Brave&lt;/cell&gt;
        &lt;cell&gt;Direct license&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Yandex&lt;/cell&gt;
        &lt;cell&gt;Direct license&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Wikipedia&lt;/cell&gt;
        &lt;cell&gt;Direct license&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;TripAdvisor&lt;/cell&gt;
        &lt;cell&gt;Direct license&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Yelp&lt;/cell&gt;
        &lt;cell&gt;Direct license&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Apple&lt;/cell&gt;
        &lt;cell&gt;Direct license&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Wolfram Alpha&lt;/cell&gt;
        &lt;cell&gt;Direct license&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Our own Small Web Index&lt;/cell&gt;
        &lt;cell&gt;Proprietary&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;With Google and Bing, we failed - not for lack of trying.&lt;/p&gt;
    &lt;p&gt;Bing: Their terms didn‚Äôt work for us from the start. Microsoft‚Äôs terms prohibited reordering results or merging them with other sources - restrictions incompatible with Kagi‚Äôs approach. In February 2023, they announced price increases of up to 10x on some API tiers. Then in May 2025, they retired the Bing Search APIs entirely, effective August 2025, directing customers toward AI-focused alternatives like Azure AI Agents.&lt;/p&gt;
    &lt;p&gt;Google: Google does not offer a public search API. The only available path is an ad-syndication bundle with no changes to result presentation - the model Startpage uses. Ad syndication is a non-starter for Kagi‚Äôs ad-free subscription model.[^1]&lt;/p&gt;
    &lt;head rend="h2"&gt;The current interim approach&lt;/head&gt;
    &lt;p&gt;Because direct licensing isn‚Äôt available to us on compatible terms, we - like many others - use third-party API providers for SERP-style results (SERP meaning search engine results page). These providers serve major enterprises (according to their websites) including Nvidia, Adobe, Samsung, Stanford, DeepMind, Uber, and the United Nations.&lt;/p&gt;
    &lt;p&gt;This is not our preferred solution. We plan to exit it as soon as direct, contractual access becomes available. There is no legitimate, paid path to comprehensive Google or Bing results for a company like Kagi. Our position is clear: open the search index, make it available on FRAND terms, and enable rapid innovation in the marketplace.&lt;/p&gt;
    &lt;head rend="h2"&gt;The DOJ ruling&lt;/head&gt;
    &lt;p&gt;The Google antitrust case began in 2020. On August 5, 2024, the court ruled Google violated Section 2 of the Sherman Act by unlawfully maintaining its monopoly through exclusive distribution agreements. (Full ruling)&lt;/p&gt;
    &lt;p&gt;On September 2, 2025, the DOJ announced remedies (press release):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Limits on exclusivity: Google is prohibited from exclusive contracts related to Search, Chrome, Assistant, and Gemini.&lt;/item&gt;
      &lt;item&gt;Data sharing and syndication: Google must provide search index and interaction data to competitors and offer syndication services to help rivals build competitive search.&lt;/item&gt;
      &lt;item&gt;Addressing monopolization tactics: The remedies aim to dismantle a decade of exclusionary agreements.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In December 2025, Judge Mehta issued a memorandum outlining the specific remedies the court intends to impose. The details are significant:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mandatory syndication: Google must offer query-based search syndication to ‚ÄúQualified Competitors‚Äù on terms no less favorable than those provided to current partners.&lt;/item&gt;
      &lt;item&gt;No ad bundling: Google cannot condition access to search results on the use of Google Ads; competitors are free to monetize via their own ads or third parties.&lt;/item&gt;
      &lt;item&gt;Index data access: Google must provide Web Search Index data (URLs, crawl metadata, spam scores) at marginal cost.&lt;/item&gt;
      &lt;item&gt;Duration: The judgment remains in effect for 6 years, with syndication licenses guaranteed for terms of 5 years.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If implemented as outlined, this is exactly what we have been asking for. The legal trajectory is promising. Google will contest details, and final enforceable terms are still being worked out. The fight now is ensuring these remedies become real, practical access - not paper compliance.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why enforcement matters now&lt;/head&gt;
    &lt;p&gt;Even as these remedies take shape, Google is moving to close the back door. In December 2025, Google sued SerpApi for scraping its results at scale.&lt;/p&gt;
    &lt;p&gt;We take a measured, principled view:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Context matters: Google built its index by crawling the open web before robots.txt was a widespread norm, often over publishers‚Äô objections. Today, publishers ‚Äúconsent‚Äù to Google‚Äôs crawling because the alternative - being invisible on a platform with 90% market share - is economically unacceptable. Google now enforces ToS and robots.txt against others from a position of monopoly power it accumulated without those constraints. The rules Google enforces today are not the rules it played by when building its dominance.&lt;/item&gt;
      &lt;item&gt;The structural problem remains: This lawsuit is only necessary because Google refuses to offer legitimate, paid index access.&lt;/item&gt;
      &lt;item&gt;Our position is unchanged: We have always wanted direct licensing. We would happily pay market rates for clean, contractual access. The fact that we - and companies like Stanford, Nvidia, Adobe, and the United Nations - have had to rely on third-party vendors is a symptom of the closed ecosystem, not a preference.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The connection to DOJ remedies is direct: if Google is going to close the back door, regulators must ensure the front door is open. That is exactly what the DOJ‚Äôs index syndication requirements are meant to achieve - and why we support their full implementation.&lt;/p&gt;
    &lt;head rend="h2"&gt;What could be: A layered search ecosystem&lt;/head&gt;
    &lt;p&gt;The DOJ ruling does not itself create a healthy market, but it makes one possible.&lt;/p&gt;
    &lt;p&gt;And while this post focuses on remedies and their impact on Kagi, it is worth zooming out: even if those remedies work perfectly, long-term societal prosperity and resilience require a non-commercial baseline for access to information - something that is not dependent on ad incentives or a single vendor‚Äôs business priorities. Think of it as a north-star model for a modern society where information access is a fundamental right.&lt;/p&gt;
    &lt;p&gt;Here is what that could look like:&lt;/p&gt;
    &lt;head rend="h3"&gt;Layer 1: Search as a public good&lt;/head&gt;
    &lt;p&gt;This is a long-term possibility, not a near-term expectation. A government-backed, ad-free, intermediary-free, taxpayer-funded search service providing baseline, non-discriminatory access to information. Imagine search.org.&lt;/p&gt;
    &lt;p&gt;This is not something the DOJ remedies create directly, nor something Kagi expects to exist soon. It is included here to make explicit what an open-index world could ultimately make possible.&lt;/p&gt;
    &lt;p&gt;This layer would replace the role public libraries played for centuries - a role that effectively disappeared when commercial web search took over in the late 1990s. Our ancestors understood well the benefits that non-discriminatory, direct access to information brings to citizens, and ultimately society itself.&lt;/p&gt;
    &lt;p&gt;It raises hard questions: governance, funding, political independence, precedent. But the principle is sound. Every citizen should have access to information without an ad-optimized algorithm standing between them and knowledge. If we can fund public libraries, we can fund public search.&lt;/p&gt;
    &lt;head rend="h3"&gt;Layer 2: Free, ad-based search&lt;/head&gt;
    &lt;p&gt;Commercial search engines with richer features, funded by advertising. Users understand the tradeoff and have a genuine public alternative. This is the space where most contemporary search engines operate.&lt;/p&gt;
    &lt;head rend="h3"&gt;Layer 3: Paid, subscription-based search&lt;/head&gt;
    &lt;p&gt;Premium search engines offering the highest possible quality, privacy, and advanced features for users who value this and are willing to pay. This is where Kagi operates - and where we are expanding as an integrator of knowledge across search, browser, mail, and AI assistants, without selling your attention.&lt;/p&gt;
    &lt;p&gt;This layered model creates a diverse ecosystem:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A public baseline for information access.&lt;/item&gt;
      &lt;item&gt;Commercial free options for convenience and reach.&lt;/item&gt;
      &lt;item&gt;Premium paid options for those who want maximum quality and control.&lt;/item&gt;
      &lt;item&gt;Aligns with the primary purpose of the Sherman Act.[^2]&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;The DOJ ruling is starting to do what antitrust is supposed to do: turn a closed, private choke point into shared infrastructure that others can build on. If the remedies land as real, usable access (APIs, cost-based pricing, no ad bundling), the web can support a layered ecosystem again: a public baseline for citizens, free ad-supported products for reach, and paid services that compete on quality, privacy, and power-user features.&lt;/p&gt;
    &lt;p&gt;That is the world we are building Kagi for. We are ready to walk through the front door - not depend on gray-market workarounds. Our job now is to be ready when the door opens, and to help make sure it does: keep Kagi genuinely multi-source, keep investing in our Small Web Index, and keep shipping a subscription search experience that delivers the best results across providers. If we get this right, the next decade of search and AI does not have to be one funnel owned by one company. It can be a competitive stack of layers that treats information access as the public good it has always been.&lt;/p&gt;
    &lt;head rend="h2"&gt;References&lt;/head&gt;
    &lt;head rend="h4"&gt;DOJ v. Google&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;UNITED STATES OF AMERICA v. GOOGLE LLC, 1:20-cv-03010 √¢ Full case docket on CourtListener&lt;/item&gt;
      &lt;item&gt;Memorandum Opinion √¢ Judge Amit Mehta (PDF) √¢ Court ruling finding Google violated antitrust law&lt;/item&gt;
      &lt;item&gt;Department of Justice Wins Significant Remedies Against Google √¢ DOJ press release announcing remedies, September 2, 2025&lt;/item&gt;
      &lt;item&gt;Judge Mehta‚Äôs Remedies Memorandum (PDF) √¢ December 2025&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Market data and commentary&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Search Engine Market Share Worldwide √¢ StatCounter, October 2025&lt;/item&gt;
      &lt;item&gt;Search Engine Market Share United States √¢ StatCounter, October 2025&lt;/item&gt;
      &lt;item&gt;Ian Bremmer on algorithmic information access √¢ Commentary on ad-driven search&lt;/item&gt;
      &lt;item&gt;The Anatomy of a Large-Scale Hypertextual Web Search Engine √¢ Original Google white paper by Brin &amp;amp; Page, Stanford, 1998&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Third-party search API providers&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Google lobs lawsuit at search result scraping firm √¢ Ars Technica coverage of Google‚Äôs litigation&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Footnotes&lt;/head&gt;
    &lt;p&gt;[^1]: A note on Google‚Äôs existing APIs: Google offers PSE, designed for adding search boxes to websites. It can return web results, but with reduced scope and terms tailored for that narrow use case. More recently, Google offers Grounding with Google Search through Vertex AI, intended for grounding LLM responses. Neither is general-purpose index access. Programmable Search Engine is not designed for building competitive search. Grounding with Google Search is priced at $35 per 1,000 requests - economically unviable for search at scale, and structured as an AI add-on rather than standalone index syndication. These are not the FRAND terms the market needs.&lt;/p&gt;
    &lt;p&gt;[^2]: Our understanding of the primary purpose of the Sherman Act is not to shield competitors from the success of legitimate businesses or to prevent those businesses from earning fair profits. Rather, it is to preserve a competitive marketplace that protects consumers from harm (see Competition law and consumer protection, Kluwer Law International, pp. 291√¢293). Opening the search index would create healthy, real, and intense competition in the search space - including competition to Kagi - which aligns with our understanding of the Sherman Act‚Äôs intent. The goal is not the elimination of dominant firms, but the prevention of a single, closed index from becoming the only gateway to information.&lt;/p&gt;
    &lt;p&gt;Published by Vladimir Prelovac and Raghu Murthi on January 21, 2026.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46708678</guid><pubDate>Wed, 21 Jan 2026 17:28:03 +0000</pubDate></item><item><title>Show HN: Rails UI</title><link>https://railsui.com/</link><description>&lt;doc fingerprint="7d1af0212bdc2360"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Stop fighting CSS and build beautiful Rails apps faster&lt;/head&gt;
    &lt;p&gt;No more ugly Rails apps. Get professional-looking components and themes that work perfectly with Rails‚Äîno design skills required.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Booking date&lt;/cell&gt;
        &lt;cell role="head"&gt;Property&lt;/cell&gt;
        &lt;cell role="head"&gt;Payout&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;p&gt;June 1, 2026&lt;/p&gt;
          &lt;p&gt;7:38 PM CST&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Cozy Mountain A-Frame&lt;/cell&gt;
        &lt;cell&gt;$1,165.45&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;p&gt;Aug 3, 2026&lt;/p&gt;
          &lt;p&gt;7:38 PM CST&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Mountain Vista Chalet&lt;/cell&gt;
        &lt;cell&gt;$2,846.46&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Jul 18, 2026&lt;/p&gt;
          &lt;p&gt;4:30 PM CST&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Cozy Mountain A-Frame&lt;/cell&gt;
        &lt;cell&gt;$1,326.36&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Pro&lt;/p&gt;
    &lt;p&gt;Active subscriber&lt;/p&gt;
    &lt;p&gt;Monthly&lt;/p&gt;
    &lt;p&gt;Sarah updated deal status to "Qualified"&lt;/p&gt;
    &lt;p&gt;2 hours ago&lt;/p&gt;
    &lt;p&gt;New contact added: John Smith&lt;/p&gt;
    &lt;p&gt;Yesterday&lt;/p&gt;
    &lt;p&gt;Acme Corporation&lt;/p&gt;
    &lt;p&gt;Enterprise Plan ‚Ä¢ 12 team members&lt;/p&gt;
    &lt;p&gt;Next invoice: $299/mo&lt;/p&gt;
    &lt;p&gt;Due on Feb 1, 2025&lt;/p&gt;
    &lt;head rend="h1"&gt;Sign in to your account&lt;/head&gt;
    &lt;p&gt;Or sign up for an account&lt;/p&gt;
    &lt;head rend="h2"&gt;Enhanced User Authentication System&lt;/head&gt;
    &lt;p&gt;A small-batch cycle to build a refreshed authentication flow.&lt;/p&gt;
    &lt;p&gt;Components&lt;/p&gt;
    &lt;head rend="h3"&gt;Components that make your Rails app look professional&lt;/head&gt;
    &lt;p&gt;No design experience? No problem. Copy-paste beautiful forms, buttons, and layouts that work perfectly with Rails. Focus on your business logic‚Äîwe've got the pretty stuff covered.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Accordion&lt;/item&gt;
      &lt;item&gt;Alert&lt;/item&gt;
      &lt;item&gt;Badge&lt;/item&gt;
      &lt;item&gt;Button&lt;/item&gt;
      &lt;item&gt;Card&lt;/item&gt;
      &lt;item&gt;Dropdown&lt;/item&gt;
      &lt;item&gt;Modal&lt;/item&gt;
    &lt;/list&gt;
    &lt;head class="flex w-full cursor-pointer select-none justify-between text-left text-base font-semibold leading-7 text-slate-900 group-open:text-indigo-600 [&amp;amp;::-webkit-details-marker]:hidden dark:group-open:text-indigo-300 dark:text-white"&gt;How do I import contacts from a CSV file?&lt;/head&gt;
    &lt;head class="flex w-full cursor-pointer select-none justify-between text-left text-base font-semibold leading-7 text-slate-900 group-open:text-indigo-600 [&amp;amp;::-webkit-details-marker]:hidden dark:group-open:text-indigo-300 dark:text-white"&gt;Can I customize my deal pipeline stages?&lt;/head&gt;
    &lt;head class="flex w-full cursor-pointer select-none justify-between text-left text-base font-semibold leading-7 text-slate-900 group-open:text-indigo-600 [&amp;amp;::-webkit-details-marker]:hidden dark:group-open:text-indigo-300 dark:text-white"&gt;How do automated follow-up reminders work?&lt;/head&gt;
    &lt;head rend="h3"&gt;Time to launch&lt;/head&gt;
    &lt;p&gt;The beta is no more. &lt;lb/&gt;We are ready to go live.&lt;/p&gt;
    &lt;p&gt;Themes&lt;/p&gt;
    &lt;head rend="h3"&gt; Complete app designs that don't look like &lt;lb/&gt; programmer art&lt;/head&gt;
    &lt;p&gt;Skip the hours of CSS frustration. Get complete, professional-looking app layouts that work with Rails out of the box. Your users will think you hired a designer.&lt;/p&gt;
    &lt;head rend="h3"&gt;Collie&lt;/head&gt;
    &lt;p&gt;Community platform&lt;/p&gt;
    &lt;head rend="h3"&gt;Husky&lt;/head&gt;
    &lt;p&gt;Personal Finance&lt;/p&gt;
    &lt;head rend="h3"&gt;Boxer&lt;/head&gt;
    &lt;p&gt;Agency Management&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;"Rails UI is going to save me months of work. I'm an experienced software developer building my first Ruby on Rails app, but I'm not strong at front-end design. Support has been awesome as well."&lt;/p&gt;Adam G. ‚Äî Software Developer&lt;/quote&gt;
    &lt;quote&gt;&lt;p&gt;"Launched our MVP in two weeks instead of two months. The themes look so polished that our investors thought we had a full design team."&lt;/p&gt;Sarah M. ‚Äî Startup Founder&lt;/quote&gt;
    &lt;quote&gt;&lt;p&gt;"My clients can't believe how fast I deliver now. Rails UI pays for itself on the first project."&lt;/p&gt;James T. ‚Äî Freelance Developer&lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46709543</guid><pubDate>Wed, 21 Jan 2026 18:31:19 +0000</pubDate></item><item><title>TeraWave Satellite Communications Network</title><link>https://www.blueorigin.com/news/blue-origin-introduces-terawave-space-based-network-for-global-connectivity</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46709548</guid><pubDate>Wed, 21 Jan 2026 18:31:58 +0000</pubDate></item><item><title>eBay explicitly bans AI "buy for me" agents in user agreement update</title><link>https://www.valueaddedresource.net/ebay-bans-ai-agents-updates-arbitration-user-agreement-feb-2026/</link><description>&lt;doc fingerprint="ddd85f438da6cb94"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;eBay Explicitly Bans AI ‚ÄúBuy For Me‚Äù Agents, Updates Arbitration &amp;amp; Dispute Rules In User Agreement Update&lt;/head&gt;
    &lt;p&gt;eBay explicitly prohibits AI "buy for me" agents and LLM (larger language model) bots, updates arbitration and dispute resolution requirements in latest User Agreement update, going into effect February 20, 2026.&lt;/p&gt;
    &lt;p&gt;The following summary of changes was provided in an email sent to users:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We‚Äôve updated eBay‚Äôs User Agreement, including the agreement to arbitrate any disputes you may have with us. Our updated User Agreement was posted on January 20, 2026. For users who agreed to a prior version of our User Agreement, this agreement is effective as of February 20, 2026.&lt;/p&gt;
      &lt;p&gt;In this update, eBay is updating its anti-scraping prohibition to clarify that it specifically also includes bots used for AI or LLMs. eBay is also updating the agreement to arbitrate in the updated User Agreement:&lt;/p&gt;
      &lt;item&gt;We clarified the scope of the class action waiver.&lt;/item&gt;
      &lt;item&gt;We clarified the process for opting out of the agreement to arbitrate.&lt;/item&gt;
      &lt;item&gt;We updated the physical address to which notices for informal dispute resolution, arbitration demands, and notices for opting out of arbitration must be sent.&lt;/item&gt;
    &lt;/quote&gt;
    &lt;p&gt;As always, sellers are encouraged to read the entire updated terms carefully, but Value Added Resource has you covered with a side by side comparison highlighting some key changes.&lt;/p&gt;
    &lt;p&gt;Disclaimer: comparisons are made using both automated and manual methods and are provided for informational purposes only - no warranty of completeness or accuracy is expressed or implied and users are advised to do their own due diligence.&lt;/p&gt;
    &lt;head rend="h3"&gt;AI Agents &amp;amp; LLM Scraping&lt;/head&gt;
    &lt;p&gt;First, as the summary calls out, eBay is explicitly prohibiting AI "buy for me" agents and LLM scraping bots from interacting with the platform without permission from eBay.&lt;/p&gt;
    &lt;p&gt;Old Version:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In connection with using or accessing our Services you agree to comply with this User Agreement, our policies, our terms, and all applicable laws, rules, and regulations, and you will not...&lt;/p&gt;
      &lt;p&gt;...use any robot, spider, scraper, data mining tools, data gathering and extraction tools, or other automated means to access our Services for any purpose, except with the prior express permission of eBay;&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;New Version:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In connection with using or accessing our Services you agree to comply with this User Agreement, our policies, our terms, and all applicable laws, rules, and regulations, and you will not...&lt;/p&gt;
      &lt;p&gt;use any robot, spider, scraper, data mining tools, data gathering and extraction tools, or other automated means (including, without limitation buy-for-me agents, LLM-driven bots, or any end-to-end flow that attempts to place orders without human review) to access our Services for any purpose, except with the prior express permission of eBay;&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The move comes after eBay quietly changed their robots.txt file with new guidance placing guardrails and restrictions on how AI agents interact with the site in December.&lt;/p&gt;
    &lt;p&gt;It also comes on the heels of Amazon's controversial Buy For Me test which uses agentic AI to display items from direct merchant websites for sale through the Amazon app, even if the brand does not sell on Amazon themselves - raising concerns about transparency, consent, and control over how product details are displayed to buyers.&lt;/p&gt;
    &lt;p&gt;While it appears that Amazon Buy For Me currently does not pull inventory from other third party marketplaces, it would not be surprising if eBay is reacting at least in part to this and other agentic commerce news making recent headlines.&lt;/p&gt;
    &lt;head rend="h3"&gt;Arbitration &amp;amp; Dispute Resolution&lt;/head&gt;
    &lt;p&gt;The rest of the changes in this User Agreement update affect arbitration and dispute resolution.&lt;/p&gt;
    &lt;p&gt;eBay's previous User Agreement update in May 2025 made significant changes to arbitration terms and limits on lawsuits, forcing users to give up their right to the sue the company in many situations.&lt;/p&gt;
    &lt;p&gt;In this update, eBay has finally updated the address to send arbitration opt out requests and other legal correspondence to since selling their former office in Draper, UT in 2024.&lt;/p&gt;
    &lt;p&gt;Old Version:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Notice to eBay should be sent by email to DisputeNotice@eBay.com or regular mail to our offices located at 583 W. eBay Way, Draper, UT 84020.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;New Version:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Notice to eBay should be sent by email to DisputeNotice@eBay.com or regular mail to our offices located at 339 W. 13490 S., Ste. 500, Draper, UT 84020&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Most importantly, eBay has expanded their arbitration clause which previously prohibited class actions to now also explicitly exclude more types of group legal actions.&lt;/p&gt;
    &lt;p&gt;Old Version:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;EACH OF US MAY BRING CLAIMS AGAINST THE OTHER ONLY ON AN INDIVIDUAL BASIS AND NOT ON A CLASS, REPRESENTATIVE, OR COLLECTIVE BASIS, AND THE PARTIES HEREBY WAIVE ALL RIGHTS TO HAVE ANY DISPUTE BE BROUGHT, HEARD, ADMINISTERED, RESOLVED, OR ARBITRATED ON A CLASS, COLLECTIVE, OR REPRESENTATIVE BASIS. ONLY INDIVIDUAL RELIEF IS AVAILABLE.&lt;/p&gt;
      &lt;p&gt;Subject to this Agreement to Arbitrate, the arbitrator may award declaratory or injunctive relief only in favor of the individual party seeking relief and only to the extent necessary to provide relief warranted by the party‚Äôs individual claim. Nothing in this paragraph is intended to, nor shall it, affect the terms and conditions under Section 19.B.7 ("Batch Arbitration").&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;New Version:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;EACH OF US MAY BRING CLAIMS AGAINST THE OTHER ONLY ON AN INDIVIDUAL BASIS AND NOT AS A PLAINTIFF OR CLASS MEMBER IN ANY PURPORTED CLASS, OR REPRESENTATIVE, OR COLLECTIVE BASIS, OR PRIVATE ATTORNEY GENERAL ACTION OR PROCEEDING, NOR OTHERWISE TO SEEK RECOVERY OF LOSSES OR DAMAGES (WHETHER FOR YOURSELF OR OTHERS) INCURRED BY A THIRD PARTY, AND THE PARTIES HEREBY WAIVE ALL RIGHTS TO HAVE ANY DISPUTE BE BROUGHT, HEARD, ADMINISTERED, RESOLVED, OR ARBITRATED ON A CLASS, COLLECTIVE, OR REPRESENTATIVE BASIS. ONLY INDIVIDUAL RELIEF IS AVAILABLE.&lt;/p&gt;
      &lt;p&gt;Subject to this Agreement to Arbitrate, the arbitrator may award declaratory or injunctive relief only in favor of the individual party seeking relief and only to the extent necessary to provide relief warranted by the party‚Äôs individual claim. Nothing in this paragraph is intended to, nor shall it, affect the terms and conditions under Section 19.B.7 ("Batch Arbitration").&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Here's what that means in plain language:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚ÄúNot as a plaintiff or class member‚Äù ‚Äî prevents someone from joining an existing class action.&lt;/item&gt;
      &lt;item&gt;‚ÄúNo private attorney general actions‚Äù ‚Äî blocks lawsuits brought ‚Äúon behalf of the public,‚Äù a type of claim sometimes used in consumer protection cases.&lt;/item&gt;
      &lt;item&gt;‚ÄúNor‚Ä¶ for losses incurred by a third party‚Äù ‚Äî prevents a person from trying to recover damages suffered by someone else.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: this language does not in any way change or restrict legal action that state Attorneys General, the FTC or other regulatory or legal agencies can take on behalf of sellers and/or consumers - so don't be dissuaded from letting those agencies know about your experiences with the platform, like the recent changes to Promoted Listings ad attribution policies.&lt;/p&gt;
    &lt;p&gt;And finally, this User Agreement update has been changed to clarify that only new users may request to opt out of arbitration agreement - existing users missed their opportunity if they did not opt out before May 16, 2025.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Opt-Out Procedure&lt;/p&gt;
      &lt;p&gt;IF YOU ARE A NEW USER OF OUR SERVICES, YOU CAN CHOOSE TO OPT OUT OF THIS AGREEMENT TO ARBITRATE ("OPT OUT") BY MAILING US A WRITTEN OPT-OUT NOTICE ("OPT-OUT NOTICE").&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;And that's it for changes to eBay's User Agreement going into effect February 20, 2026.&lt;/p&gt;
    &lt;p&gt;Let us know in the comments below what you think of these change and how they'll affect your business!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46711574</guid><pubDate>Wed, 21 Jan 2026 21:07:47 +0000</pubDate></item><item><title>Jerry (YC S17) Is Hiring</title><link>https://www.ycombinator.com/companies/jerry-inc/jobs/QaoK3rw-software-engineer-core-automation-marketplace</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46711792</guid><pubDate>Wed, 21 Jan 2026 21:26:18 +0000</pubDate></item><item><title>Your brain on ChatGPT: Accumulation of cognitive debt when using an AI assistant</title><link>https://www.media.mit.edu/publications/your-brain-on-chatgpt/</link><description>&lt;doc fingerprint="a81bbfb1ef3e053e"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;head rend="h1"&gt;Abstract&lt;/head&gt;
      &lt;p&gt;This study explores the neural and behavioral consequences of LLM-assisted essay writing. Participants were divided into three groups: LLM, Search Engine, and Brain-only (no tools). Each completed three sessions under the same condition. In a fourth session, LLM users were reassigned to Brain-only group (LLM-to-Brain), and Brain-only users were reassigned to LLM condition (Brain-to-LLM). A total of 54 participants took part in Sessions 1-3, with 18 completing session 4. We used electroencephalography (EEG) to assess cognitive load during essay writing, and analyzed essays using NLP, as well as scoring essays with the help from human teachers and an AI judge. Across groups, NERs, n-gram patterns, and topic ontology showed within-group homogeneity. EEG revealed significant differences in brain connectivity: Brain-only participants exhibited the strongest, most distributed networks; Search Engine users showed moderate engagement; and LLM users displayed the weakest connectivity. Cognitive activity scaled down in relation to external tool use. In session 4, LLM-to-Brain participants showed reduced alpha and beta connectivity, indicating under-engagement. Brain-to-LLM users exhibited higher memory recall and activation of occipito-parietal and prefrontal areas, similar to Search Engine users. Self-reported ownership of essays was the lowest in the LLM group and the highest in the Brain-only group. LLM users also struggled to accurately quote their own work. While LLMs offer immediate convenience, our findings highlight potential cognitive costs. Over four months, LLM users consistently underperformed at neural, linguistic, and behavioral levels. These results raise concerns about the long-term educational implications of LLM reliance and underscore the need for deeper inquiry into AI's role in learning.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46712678</guid><pubDate>Wed, 21 Jan 2026 22:41:45 +0000</pubDate></item><item><title>Convert potentially dangerous PDFs to safe PDFs</title><link>https://github.com/freedomofpress/dangerzone</link><description>&lt;doc fingerprint="d41d4116ff352380"&gt;
  &lt;main&gt;
    &lt;p&gt;Take potentially dangerous PDFs, office documents, or images and convert them to a safe PDF.&lt;/p&gt;
    &lt;p&gt;Dangerzone works like this: You give it a document that you don't know if you can trust (for example, an email attachment). Inside of a sandbox, Dangerzone converts the document to a PDF (if it isn't already one), and then converts the PDF into raw pixel data: a huge list of RGB color values for each page. Then, outside of the sandbox, Dangerzone takes this pixel data and converts it back into a PDF.&lt;/p&gt;
    &lt;p&gt;Read more about Dangerzone in the official site.&lt;/p&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;üéÖ Check out our Christmas security challenge, in which we ask security researchers to craft a naughty letter that can pwn Dangerzone in Santa's laptop, and earn a bounty of up to $3,000. Promise it makes sense. üéÑ&lt;/p&gt;
    &lt;p&gt;Follow the instructions for each platform:&lt;/p&gt;
    &lt;p&gt;You can read more about our operating system support here.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Sandboxes don't have network access, so if a malicious document can compromise one, it can't phone home&lt;/item&gt;
      &lt;item&gt;Sandboxes use gVisor, an application kernel written in Go, that implements a substantial portion of the Linux system call interface.&lt;/item&gt;
      &lt;item&gt;Dangerzone can optionally OCR the safe PDFs it creates, so it will have a text layer again&lt;/item&gt;
      &lt;item&gt;Dangerzone compresses the safe PDF to reduce file size&lt;/item&gt;
      &lt;item&gt;After converting, Dangerzone lets you open the safe PDF in the PDF viewer of your choice, which allows you to open PDFs and office docs in Dangerzone by default so you never accidentally open a dangerous document&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Dangerzone can convert these types of document into safe PDFs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PDF (&lt;code&gt;.pdf&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Microsoft Word (&lt;code&gt;.docx&lt;/code&gt;,&lt;code&gt;.doc&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Microsoft Excel (&lt;code&gt;.xlsx&lt;/code&gt;,&lt;code&gt;.xls&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Microsoft PowerPoint (&lt;code&gt;.pptx&lt;/code&gt;,&lt;code&gt;.ppt&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;ODF Text (&lt;code&gt;.odt&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;ODF Spreadsheet (&lt;code&gt;.ods&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;ODF Presentation (&lt;code&gt;.odp&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;ODF Graphics (&lt;code&gt;.odg&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Hancom HWP (Hangul Word Processor) (&lt;code&gt;.hwp&lt;/code&gt;,&lt;code&gt;.hwpx&lt;/code&gt;)&lt;list rend="ul"&gt;&lt;item&gt;Not supported on Qubes OS&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;EPUB (&lt;code&gt;.epub&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Jpeg (&lt;code&gt;.jpg&lt;/code&gt;,&lt;code&gt;.jpeg&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;GIF (&lt;code&gt;.gif&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;PNG (&lt;code&gt;.png&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;SVG (&lt;code&gt;.svg&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;other image formats (&lt;code&gt;.bmp&lt;/code&gt;,&lt;code&gt;.pnm&lt;/code&gt;,&lt;code&gt;.pbm&lt;/code&gt;,&lt;code&gt;.ppm&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Dangerzone was inspired by Qubes trusted PDF, but it works in non-Qubes operating systems. It uses containers as sandboxes instead of virtual machines (using Docker for macOS and Windows, and podman on Linux).&lt;/p&gt;
    &lt;p&gt;Set up a development environment by following these instructions.&lt;/p&gt;
    &lt;p&gt;Licensed under the AGPLv3: https://opensource.org/licenses/agpl-3.0&lt;/p&gt;
    &lt;code&gt;Copyright (c) 2022-2024 Freedom of the Press Foundation and Dangerzone contributors
Copyright (c) 2020-2021 First Look Media
&lt;/code&gt;
    &lt;p&gt;See also THIRD_PARTY_NOTICE.md for more information regarding the third-party software that Dangerzone depends on.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GIJN Toolbox: Cutting-Edge ‚Äî and Free ‚Äî Online Investigative Tools You Can Try Right Now&lt;/item&gt;
      &lt;item&gt;When security matters: working with Qubes OS at the Guardian&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Yes, Dangerzone received its first security audit by Include Security in December 2023. The audit was generally favorable, as it didn't identify any high-risk findings, except for 3 low-risk and 7 informational findings.&lt;/p&gt;
    &lt;p&gt;Dangerzone gets updates to improve its features and to fix problems. So, updating may be the simplest path to resolving the issue which brought you here. Here is how to update:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Check which version of Dangerzone you are currently using: run Dangerzone, then look for a series of numbers to the right of the logo within the app. The format of the numbers will look similar to &lt;code&gt;0.4.1&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Now find the latest available version of Dangerzone: go to the download page. Look for the version number displayed. The number will be using the same format as in Step 1.&lt;/item&gt;
      &lt;item&gt;Is the version on the Dangerzone download page higher than the version of your installed app? Go ahead and update.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Yes, Dangerzone is designed to run in airgapped environments without any configuration. If you want to update its container image, follow our instructions.&lt;/p&gt;
    &lt;p&gt;On Windows and macOS, Dangerzone embeds Podman, so there is no need to.&lt;/p&gt;
    &lt;p&gt;To use a different podman version, such as Podman Desktop, follow our documentation.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46712815</guid><pubDate>Wed, 21 Jan 2026 22:54:04 +0000</pubDate></item><item><title>Show HN: Sweep, Open-weights 1.5B model for next-edit autocomplete</title><link>https://huggingface.co/sweepai/sweep-next-edit-1.5B</link><description>&lt;doc fingerprint="85b3cff318accb0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Sweep Next-Edit 1.5B (GGUF)&lt;/head&gt;
    &lt;p&gt;A 1.5B parameter model for next-edit autocomplete, quantized to Q8_0 GGUF format.&lt;/p&gt;
    &lt;head rend="h2"&gt;Model Description&lt;/head&gt;
    &lt;p&gt;Sweep Next-Edit predicts your next code edit before you make it. It runs locally on your laptop in under 500ms (with speculative decoding) and outperforms models over 4x its size on next-edit benchmarks.&lt;/p&gt;
    &lt;head rend="h2"&gt;Usage&lt;/head&gt;
    &lt;p&gt;Download &lt;code&gt;run_model.py&lt;/code&gt; and the model file, then:&lt;/p&gt;
    &lt;code&gt;uv pip install llama-cpp-python huggingface_hub
python run_model.py
&lt;/code&gt;
    &lt;head rend="h2"&gt;Model Details&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Format: GGUF (Q8_0 quantization)&lt;/item&gt;
      &lt;item&gt;Parameters: 1.5B&lt;/item&gt;
      &lt;item&gt;Context Length: 8192 tokens&lt;/item&gt;
      &lt;item&gt;Base Model: Qwen2.5-Coder&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Example&lt;/head&gt;
    &lt;p&gt;The model uses a specific prompt format with file context, recent diffs, and current state to predict the next edit. See &lt;code&gt;run_model.py&lt;/code&gt; for a complete example.&lt;/p&gt;
    &lt;head rend="h2"&gt;Links&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Blog Post - Technical details and benchmarks&lt;/item&gt;
      &lt;item&gt;JetBrains Plugin - Sweep AI JetBrains Plugin&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;License&lt;/head&gt;
    &lt;p&gt;Apache 2.0&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Downloads last month&lt;/item&gt;
      &lt;item rend="dd-1"&gt;21&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt; Hardware compatibility&lt;/p&gt;
    &lt;p&gt;Log In to view the estimation&lt;/p&gt;
    &lt;p&gt;8-bit&lt;/p&gt;
    &lt;p&gt; Inference Providers NEW &lt;/p&gt;
    &lt;p&gt;This model isn't deployed by any Inference Provider. üôã Ask for provider support&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46713106</guid><pubDate>Wed, 21 Jan 2026 23:22:40 +0000</pubDate></item><item><title>Lix ‚Äì universal version control system for binary files</title><link>https://lix.dev/blog/introducing-lix/</link><description>&lt;doc fingerprint="f514be7bc4ab260c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing Lix: A universal version control system&lt;/head&gt;
    &lt;head rend="h2"&gt;AI agents need version control beyond text&lt;/head&gt;
    &lt;p&gt;Changes AI agents make need to be reviewable by humans.&lt;/p&gt;
    &lt;p&gt;For code, Git solves this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reviewable diffs: What exactly did the agent change?&lt;/item&gt;
      &lt;item&gt;Human-in-the-loop: Review, then merge or reject.&lt;/item&gt;
      &lt;item&gt;Rollback changes: Undo mistakes instantly.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But agents modify binary files too. And Git can't diff them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Introducing Lix&lt;/head&gt;
    &lt;p&gt;Lix is a universal version control system that can diff any file format (&lt;code&gt;.xlsx&lt;/code&gt;, &lt;code&gt;.pdf&lt;/code&gt;, &lt;code&gt;.docx&lt;/code&gt;, etc).&lt;/p&gt;
    &lt;p&gt;Unlike Git's line-based diffs, Lix understands file structure. Lix sees &lt;code&gt;price: 10 √¢ 12&lt;/code&gt; or &lt;code&gt;cell B4: pending √¢ shipped&lt;/code&gt;, not "line 4 changed" or "binary files differ".&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reviewable diffs: See exactly what an agent changed in any file format.&lt;/item&gt;
      &lt;item&gt;Human-in-the-loop: Agents propose, humans approve.&lt;/item&gt;
      &lt;item&gt;Safe rollback: Undo mistakes instantly.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Excel file example&lt;/head&gt;
    &lt;p&gt;An AI agent updates an order status in &lt;code&gt;orders.xlsx&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Before:&lt;/p&gt;
    &lt;code&gt;  | order_id | product  | status   |
  | -------- | -------- | -------- |
  | 1001     | Widget A | shipped  |
  | 1002     | Widget B | pending |
&lt;/code&gt;
    &lt;p&gt;After:&lt;/p&gt;
    &lt;code&gt;  | order_id | product  | status   |
  | -------- | -------- | -------- |
  | 1001     | Widget A | shipped  |
  | 1002     | Widget B | shipped |
&lt;/code&gt;
    &lt;p&gt;Git sees:&lt;/p&gt;
    &lt;code&gt;-Binary files differ
&lt;/code&gt;
    &lt;p&gt;Lix sees:&lt;/p&gt;
    &lt;code&gt;order_id 1002 status: 

- pending
+ shipped
&lt;/code&gt;
    &lt;head rend="h2"&gt;JSON file example&lt;/head&gt;
    &lt;p&gt;Even for structured text file formats like &lt;code&gt;.json&lt;/code&gt; lix is tracking semantics rather than line by line diffs.&lt;/p&gt;
    &lt;p&gt;Before:&lt;/p&gt;
    &lt;code&gt;{"theme":"light","notifications":true,"language":"en"}
&lt;/code&gt;
    &lt;p&gt;After:&lt;/p&gt;
    &lt;code&gt;{"theme":"dark","notifications":true,"language":"en"}
&lt;/code&gt;
    &lt;p&gt;Git sees:&lt;/p&gt;
    &lt;code&gt;-{"theme":"light","notifications":true,"language":"en"}
+{"theme":"dark","notifications":true,"language":"en"}
&lt;/code&gt;
    &lt;p&gt;Lix sees:&lt;/p&gt;
    &lt;code&gt;property theme: 
- light
+ dark
&lt;/code&gt;
    &lt;head rend="h2"&gt;How does Lix work?&lt;/head&gt;
    &lt;p&gt;Lix adds a version control system on top of SQL databases that let's you query virtual tables like &lt;code&gt;file&lt;/code&gt;, &lt;code&gt;file_history&lt;/code&gt;, etc. via plain SQL. These table's are version controlled.&lt;/p&gt;
    &lt;p&gt;Why this matters:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Lix doesn't reinvent databases √¢ durability, ACID, and corruption recovery are handled by battle-tested SQL databases.&lt;/item&gt;
      &lt;item&gt;Full SQL support √¢ query your version control system with the same SQL.&lt;/item&gt;
      &lt;item&gt;Can runs in your existing database √¢ no separate storage layer to manage.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢
√¢                      Lix                        √¢
√¢           (version control system)              √¢
√¢                                                 √¢
√¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢√¢√¢√¢√¢√¢√¢ √¢
√¢ √¢ Filesystem √¢ √¢ Branches √¢ √¢ History √¢ √¢ ... √¢ √¢
√¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢√¢√¢√¢√¢√¢√¢ √¢
√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢¬¨√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢
                         √¢
                         √¢¬º
√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢
√¢                  SQL database                   √¢
√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢
&lt;/code&gt;
    &lt;p&gt;Read more about Lix architecture √¢&lt;/p&gt;
    &lt;head rend="h2"&gt;Why did we build lix?&lt;/head&gt;
    &lt;p&gt;Lix was developed alongside inlang, open-source localization infrastructure.&lt;/p&gt;
    &lt;p&gt;We had to develop a new version control system that addressed git's limitations inlang ran into, see (see "Git is unsuited for applications"). The result is Lix, now at over 90k weekly downloads on NPM.&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting started&lt;/head&gt;
    &lt;p&gt;JavaScript √Ç¬∑ Python √Ç¬∑ Rust √Ç¬∑ Go&lt;/p&gt;
    &lt;code&gt;npm install @lix-js/sdk
&lt;/code&gt;
    &lt;code&gt;import { openLix } from "@lix-js/sdk";

const lix = await openLix({
  environment: new InMemorySQLite()
});

await lix.db.insertInto("file").values({ path: "/hello.txt", data: ... }).execute();

const diff = selectWorkingDiff({ lix })
&lt;/code&gt;
    &lt;head rend="h2"&gt;What's next&lt;/head&gt;
    &lt;p&gt;The next version of Lix will be a refactor to be purely "preprocessor" based. This enables:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fast writes (RFC 001)&lt;/item&gt;
      &lt;item&gt;Any SQL database (SQLite, Postgres, Turso, MySQL)&lt;/item&gt;
      &lt;item&gt;SDKs for Python, Rust, Go (RFC 002)&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;                      √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢
  SELECT * FROM ...   √¢  Lix Engine    √¢   SELECT * FROM ...
 √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢¬∂ √¢    (Rust)      √¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢¬∂  Database
                      √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢
&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46713387</guid><pubDate>Wed, 21 Jan 2026 23:55:06 +0000</pubDate></item><item><title>From stealth blackout to whitelisting: Inside the Iranian shutdown</title><link>https://www.kentik.com/blog/from-stealth-blackout-to-whitelisting-inside-the-iranian-shutdown/</link><description>&lt;doc fingerprint="3ff80173394545ce"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;From Stealth Blackout to Whitelisting: Inside the Iranian Shutdown&lt;/head&gt;
    &lt;head rend="h3"&gt;Summary&lt;/head&gt;
    &lt;p&gt;Iran is in the midst of one of the world‚Äôs most severe communications blackouts. This post uses Kentik data to detail how this historic event unfolded, where this event lies in the context of previous Iranian shutdowns, and finally discusses what might be in store next for Iran.&lt;/p&gt;
    &lt;p&gt;For nearly two weeks, Iran has been enduring one of the most severe internet shutdowns in modern history. The theocratic regime‚Äôs decision to restrict communications coincided with a violent nationwide crackdown on a growing protest movement driven by worsening economic hardship.&lt;/p&gt;
    &lt;p&gt;In this post, I explore the situation in Iran using Kentik‚Äôs aggregate NetFlow data, along with other sources.&lt;/p&gt;
    &lt;head rend="h2"&gt;The big picture&lt;/head&gt;
    &lt;p&gt;At the time of this writing, a near-complete internet shutdown has persisted for almost 14 days. Along with internet services, international voice calling has also been blocked (there have been a couple of periods when limited outgoing calls were allowed), and domestic communication services have experienced extended disruptions, including Iran‚Äôs National Information Network. For a country of 90 million people, the combined blocking of these communication modes makes this blackout one of the most severe in history.&lt;/p&gt;
    &lt;p&gt;To learn more about the conditions that lead to the check out this special episode of Kentik‚Äôs Telemetry Now podcast with Iranian digital rights expert Amir Rashidi, Director of Digital Rights and Security at the human rights organization Miaan Group:&lt;/p&gt;
    &lt;head rend="h2"&gt;Some background first&lt;/head&gt;
    &lt;p&gt;For decades, the internet of Iran has been connected to the world via two international gateways:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Telecommunication Infrastructure Company (TIC) (AS49666, previously AS12880, AS48159)&lt;/item&gt;
      &lt;item&gt;Institute for Research in Fundamental Sciences (IPM) (AS6736)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;IPM, primarily a university and research network, was the country‚Äôs original internet connection in the 1990s, a story covered in the excellent book The Internet of Elsewhere by Cyrus Farivar. Years later, the state telecom TIC got into the business of providing internet service and today handles the vast majority of internet traffic into and out of Iran.&lt;/p&gt;
    &lt;p&gt;Despite TIC‚Äôs dominance, IPM has maintained a technologically independent connection to the outside world, though it has never been immune from Iranian government censorship and surveillance. This distinction matters because each gateway behaved differently during the shutdown.&lt;/p&gt;
    &lt;head rend="h2"&gt;January 8, 2026&lt;/head&gt;
    &lt;p&gt;In the days leading up to January 8, there were many reports of localized internet blockages around the country, but these incidents weren‚Äôt big enough to register on any of our national traffic statistics for Iran.&lt;/p&gt;
    &lt;p&gt;The first major development occurred at 11:42 UTC on January 8, 2026, when TIC (AS49666) began withdrawing its IPv6 BGP routes from its sessions with other networks. Within hours, nearly all of Iran‚Äôs IPv6 routing had disappeared from the global routing table.&lt;/p&gt;
    &lt;p&gt;From our perspective, this is what IPv6 traffic to Iran looked like on January 8.&lt;/p&gt;
    &lt;p&gt;However, based on our aggregate NetFlow, IPv6 traffic normally amounts to less than 1% of the overall traffic (in bits/sec) into Iran, so the average Iranian was unlikely to be affected by this issue. Regardless, the withdrawal of IPv6 routes appeared to be an early indication of what was to come later in the day.&lt;/p&gt;
    &lt;p&gt;Following a brief disruption, we observed internet traffic levels begin to plummet at 16:30 UTC (7pm local). The drop continued until internet traffic into Iran had all but ceased by 1845 UTC, as illustrated below. It took over two hours to stop all internet traffic into and out of the country.&lt;/p&gt;
    &lt;p&gt;At 19:00 UTC, we observed TIC disconnecting from a subset of its transit providers, including Russian state telecom Rostelecom (AS12389) and regional operator Gulf Bridge International (AS200612), and all of its settlement-free peers.&lt;/p&gt;
    &lt;p&gt;Despite the loss of numerous BGP adjacencies for AS49666 (TIC), the vast majority of Iranian IPv4 routes continued to be routed globally. The drop in Iranian IPv4 traffic, therefore, could not be explained by reachability issues; another mechanism was at work at the network edge blocking traffic.&lt;/p&gt;
    &lt;p&gt;Georgia Tech‚Äôs IODA tool captures this divergence well. In the below screenshot, active probing (blue) drops to zero as traffic is blocked, while routed IPv4 space in BGP (green) is almost completely unscathed (98.14%).&lt;/p&gt;
    &lt;p&gt;Although IPv4 routes remained online, internet traffic stopped for roughly 90 million Iranians. This distinction is central to Iran‚Äôs next step: internet ‚Äúwhitelisting,‚Äù in which an Iranian version of the Chinese Great Firewall allows only approved users or services while blocking all others. Had authorities withdrawn IPv4 routes, as they did with IPv6, Iran would have become completely unreachable, as Egypt was in January 2011. By keeping IPv4 routes in circulation, Iranian authorities can selectively grant full internet access to specific users while denying it to the broader population.&lt;/p&gt;
    &lt;head rend="h2"&gt;Limited connectivity&lt;/head&gt;
    &lt;p&gt;As mentioned above, the internet shutdown in Iran is not complete. There has been a tiny amount of traffic still trickling in and out as a small set of Iranians continue to enjoy internet access.&lt;/p&gt;
    &lt;p&gt;There have also been a few temporary partial restorations of service, such as a multi-hour restoration of service to Iranian universities via AS6736 on January 9th, and a more recent small surge in traffic.&lt;/p&gt;
    &lt;p&gt;From our data, we have also observed the emergence of a diurnal pattern of traffic to AS49666 emerge on January 13. AS49666 is not typically a major terminus for internet traffic to Iran, so this traffic is likely proxied traffic from whitelisted individuals or services.&lt;/p&gt;
    &lt;p&gt;As of late, we‚Äôve seen a few measures like the restoration of transit from Rostelecom and the return of routes originated by IPM, as the country appears to be moving towards a partial restoration. At the time of this writing, the plan appears to be to operate the Iranian internet as a whitelisted network indefinitely.&lt;/p&gt;
    &lt;head rend="h2"&gt;Evolving calculus of shutdowns in Iran&lt;/head&gt;
    &lt;p&gt;Back in 2012, Iran was in the beginning stages of building its National Information Network (NIN), ostensibly built to allow the country to continue to function in the event that it was cut off from the outside world. At the time, I teamed up with Iran researcher Collin Anderson to investigate. With access to in-country servers, we mapped Iran‚Äôs national internet from the inside (research published here).&lt;/p&gt;
    &lt;p&gt;We found that the NIN had been implemented by routing RFC1918 address space (specifically 10.x.x.x) between Iranian ASes within the country. By doing so, they could be assured that devices connected to the NIN would not be able to receive connections from the outside world, as those IP addresses are not routable on the public internet.&lt;/p&gt;
    &lt;p&gt;In 2019, I reported on Iran‚Äôs internet shutdown following the government‚Äôs decision to raise gas prices. At the time, it was the most severe shutdown in the countryÔøΩ‚Äôs history‚Äîuntil this month. It involved withdrawing BGP routes of some networks while blocking traffic of others, and lasted for almost two weeks.&lt;/p&gt;
    &lt;p&gt;Government-directed shutdowns in Cuba and Iran in 2022 led me to join up with Peter Micek of the digital rights NGO Access Now to write a blog post that traced the history and logic behind ‚Äúinternet curfews,‚Äù a tactic of communication suppression in which internet service is temporarily blocked on a recurring basis.&lt;/p&gt;
    &lt;p&gt;The article described internet curfews as another means of reducing the costs of shutdowns, not unlike the development of the NIN, according to Iranian digital rights expert Amir Rashidi. In that post, we wrote:&lt;/p&gt;
    &lt;quote&gt;The objective of internet curfews, like Iran‚Äôs NIN, is to reduce the cost of shutdowns on the authorities that order them. By reducing the costs of these shutdowns, they become a more palatable option for an embattled leader and, therefore, are likely to continue in the future.&lt;/quote&gt;
    &lt;p&gt;During the Twelve-Day War between Israel and Iran this June, Iran partially or fully shut down its internet, ostensibly to defend against cyberattacks and drone strikes. We, along with other internet observers, documented the shutdown‚Äôs phases and contributed to a detailed report by Rashidi‚Äôs team, which dubbed the shutdown as a ‚Äústealth blackout‚Äù due to the fact that traffic was disrupted without withdrawing any BGP routes.&lt;/p&gt;
    &lt;p&gt;The outage demonstrated Iran‚Äôs newfound ability to block traffic nationwide without manipulating BGP routes, signaling a higher level of sophistication in its internet filtering. This summer‚Äôs Stealth Blackout ultimately foreshadowed the ongoing shutdown Iran is now enduring.&lt;/p&gt;
    &lt;head rend="h2"&gt;Help from above&lt;/head&gt;
    &lt;p&gt;In the aftermath of the 2022 protests, Starlink began allowing connections from Iran. Satellite internet operators like Starlink must typically clear, at a minimum, two legal hurdles to operate in a country: a telecom license and radio spectrum authorization from the local government. Starlink has been operational in Iran for over three years at this point without either, and the Iranian government has taken note.&lt;/p&gt;
    &lt;p&gt;The ITU Radio Regulations Board (RRB) is a quasi-judicial United Nations body that interprets and applies the Radio Regulations, to include satellite emissions. It exists to resolve disputes between countries and oversees compliance with the international radio frequency register, but, in the end, has no direct enforcement power.&lt;/p&gt;
    &lt;p&gt;Since 2023, the Iranian has been pleading their case to the ITU that the Starlink service in Iran needed to be disabled. The 100th meeting of the ITU RRB took place in November, and on the topic of Starlink, the board decided to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚ÄúRequest the Administration of the Islamic Republic of Iran to pursue its efforts, to the extent possible, to identify and deactivate unauthorized STARLINK terminals in its territory,&lt;/item&gt;
      &lt;item&gt;Strongly urge the Administration of Norway to take all appropriate actions at its disposal to have the operator of the Starlink system immediately disable unauthorized transmissions of its terminals within the territory of the Islamic Republic of Iran.‚Äù&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Regardless of the decisions of this body, Starlink continues to operate in the country. (Note: The US and Norway share responsibility for Starlink‚Äôs ITU registration.)&lt;/p&gt;
    &lt;p&gt;Despite a recent Iranian law that would equate the use of Starlink with espionage, punishable by death, Iranian digital rights activists have been working for years to smuggle in terminals and build communication infrastructure to extend the internet services within the country. The recent front-page New York Times article I collaborated on described these efforts, which now must contend with a novel form of jamming Starlink service in some urban areas of Iran.&lt;/p&gt;
    &lt;head rend="h2"&gt;Other governments are watching, learning&lt;/head&gt;
    &lt;p&gt;In the decade and a half since the internet shutdowns of the Arab Spring, we‚Äôve observed the practice of suppressing communications evolve as authoritarian governments learn tactics from one another. In the ongoing shutdown in Iran, multiple such tactics are on display.&lt;/p&gt;
    &lt;p&gt;To mitigate the costs of its shutdown, the Iranian government has created an internal national internet and appears to be in the process of building a ‚Äúwhitelisting‚Äù system to allow certain individuals and services internet access while blocking the rest. If these measures successfully enable an unpopular Iranian government to remain in power, we can expect to see them replicated elsewhere.&lt;/p&gt;
    &lt;p&gt;On the other side, the digital rights activists have also been building tools, funded in large part by the now-embattled Open Technology Fund, to allow communications to continue during a shutdown like this. However, no amount of circumvention tooling can restore service to 90 million people.&lt;/p&gt;
    &lt;p&gt;The fight for open and free communications does not have an end. As long as authoritarian governments exist, this game of cat-and-mouse will continue. Ours is only to decide which side we‚Äôre on and to throw our support (financially and otherwise) to those working on solutions to these problems.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46713444</guid><pubDate>Thu, 22 Jan 2026 00:00:36 +0000</pubDate></item><item><title>Threat actors expand abuse of Microsoft Visual Studio Code</title><link>https://www.jamf.com/blog/threat-actors-expand-abuse-of-visual-studio-code/</link><description>&lt;doc fingerprint="a425853934a78a08"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Threat Actors Expand Abuse of Microsoft Visual Studio Code&lt;/head&gt;
    &lt;p&gt;Jamf Threat Labs identifies additional abuse of Visual Studio Code. See the latest evolution in the Contagious Interview campaign.&lt;/p&gt;
    &lt;p&gt;By Thijs Xhaflaire&lt;/p&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;At the end of last year, Jamf Threat Labs published research related to the Contagious Interview campaign, which has been attributed to a threat actor operating on behalf of North Korea (DPRK). Around the same time, researchers from OpenSourceMalware (OSM) released additional findings that highlighted an evolution in the techniques used during earlier stages of the campaign.&lt;/p&gt;
    &lt;p&gt;Specifically, these newer observations highlight an additional delivery technique alongside the previously documented ClickFix-based techniques. In these cases, the infection chain abuses Microsoft Visual Studio Code task configuration files, allowing malicious payloads to be executed on the victim system.&lt;/p&gt;
    &lt;p&gt;Following the discovery of this technique, both Jamf Threat Labs and OSM continued to closely monitor activity associated with the campaign. In December, Jamf Threat Labs identified additional abuse of Visual Studio Code &lt;code&gt;tasks.json&lt;/code&gt; configuration files. This included the introduction of dictionary files containing heavily obfuscated JavaScript, which is executed when a victim opens a malicious repository in Visual Studio Code.&lt;/p&gt;
    &lt;p&gt;Jamf Threat Labs shared these findings with OSM, who subsequently published a more in-depth technical analysis of the obfuscated JavaScript and its execution flow.&lt;/p&gt;
    &lt;p&gt;Earlier this week, Jamf Threat Labs identified another evolution in the campaign, uncovering a previously undocumented infection method. This activity involved the deployment of a backdoor implant that provides remote code execution capabilities on the victim system.&lt;/p&gt;
    &lt;p&gt;At a high level, the chain of events for the malware look like so:&lt;/p&gt;
    &lt;p&gt;Throughout this blog post we will shed light on each of these steps.&lt;/p&gt;
    &lt;head rend="h2"&gt;Initial Infection&lt;/head&gt;
    &lt;p&gt;In this campaign, infection begins when a victim clones and opens a malicious Git repository, often under the pretext of a recruitment process or technical assignment. The repositories identified in this activity are hosted on either GitHub or GitLab and are opened using Visual Studio Code.&lt;/p&gt;
    &lt;p&gt;When the project is opened, Visual Studio Code prompts the user to trust the repository author. If that trust is granted, the application automatically processes the repository‚Äôs &lt;code&gt;tasks.json&lt;/code&gt; configuration file, which can result in embedded arbitrary commands being executed on the system.&lt;/p&gt;
    &lt;p&gt;On macOS systems, this results in the execution of a background shell command that uses &lt;code&gt;nohup bash -c&lt;/code&gt; in combination with &lt;code&gt;curl -s&lt;/code&gt; to retrieve a JavaScript payload remotely and pipe it directly into the Node.js runtime. This allows execution to continue independently if the Visual Studio Code process is terminated, while suppressing all command output.&lt;/p&gt;
    &lt;p&gt;In observed cases, the JavaScript payload is hosted on &lt;code&gt;vercel.app&lt;/code&gt;, a platform that has been increasingly used in recent DPRK-related activity following a move away from other hosting services, as previously documented by OpenSourceMalware.&lt;/p&gt;
    &lt;p&gt;Jamf Threat Labs reported the identified malicious repository to GitHub, after which the repository was removed. While monitoring the activity prior to takedown, we observed the URL referenced within the repository change on multiple occasions. Notably, one of these changes occurred after the previously referenced payload hosting infrastructure was taken down by Vercel.&lt;/p&gt;
    &lt;head rend="h2"&gt;The JavaScript Payload&lt;/head&gt;
    &lt;p&gt;Once execution begins, the JavaScript payload implements the core backdoor logic observed in this activity. While the payload appears lengthy, a significant portion of the code consists of unused functions, redundant logic, and extraneous text that is never invoked during execution &lt;code&gt;(SHA256: 932a67816b10a34d05a2621836cdf7fbf0628bbfdf66ae605c5f23455de1e0bc)&lt;/code&gt;. This additional code increases the size and complexity of the script without impacting its observed behavior. It is passed to the node executable as one large argument.&lt;/p&gt;
    &lt;p&gt;Focusing on the functional components, the payload establishes a persistent execution loop that collects basic host information and communicates with a remote command-and-control (C2) server. Hard-coded identifiers are used to track individual infections and manage tasks from the server.&lt;/p&gt;
    &lt;head rend="h3"&gt;Core backdoor functionality&lt;/head&gt;
    &lt;p&gt;While the JavaScript payload contains a significant amount of unused code, the backdoor's core functionality is implemented through a small number of routines. These routines provide remote code execution, system fingerprinting, and persistent C2 communication.&lt;/p&gt;
    &lt;p&gt;Remote code execution capability&lt;/p&gt;
    &lt;p&gt;The payload includes a function that enables the execution of arbitrary JavaScript while the backdoor is active. At its core, this is the main functionality of this backdoor.&lt;/p&gt;
    &lt;p&gt;This function allows JavaScript code supplied as a string to be dynamically executed over the course of the backdoor lifecycle. By passing the &lt;code&gt;require&lt;/code&gt;function into the execution context, attacker-supplied code can import additional Node.js modules allowing additional arbitrary node functions to be executed.&lt;/p&gt;
    &lt;p&gt;System fingerprinting and reconnaissance&lt;/p&gt;
    &lt;p&gt;To profile the infected system, the backdoor collects a small set of host-level identifiers:&lt;/p&gt;
    &lt;p&gt;This routine gathers the system hostname, MAC addresses from available network interfaces, and basic operating system details. These values provide a stable fingerprint that can be used to uniquely identify infected hosts and associate them with a specific campaign or operator session.&lt;/p&gt;
    &lt;p&gt;In addition to local host identifiers, the backdoor attempts to determine the victim‚Äôs public-facing IP address by querying the external service ipify.org, a technique that has also been observed in prior DPRK-linked campaigns.&lt;/p&gt;
    &lt;p&gt;Command-and-control beaconing and task execution&lt;/p&gt;
    &lt;p&gt;Persistent communication with the C2 server is implemented through a polling routine that periodically sends host information and processes server responses. The beaconing logic is handled by the following function:&lt;/p&gt;
    &lt;p&gt;This function periodically sends system fingerprinting data to a remote server and waits for a response. The beacon executes every five seconds, providing frequent interaction opportunities.&lt;/p&gt;
    &lt;p&gt;The server response indicates successful connectivity and allows the backdoor to maintain an active session while awaiting tasking.&lt;/p&gt;
    &lt;p&gt;If the server response contains a specific status value, the contents of the response message are passed directly to the remote code execution routine, mentioned prior.&lt;/p&gt;
    &lt;head rend="h2"&gt;Further Execution and Instructions&lt;/head&gt;
    &lt;p&gt;While monitoring a compromised system, Jamf Threat Labs observed further JavaScript instructions being executed roughly eight minutes after the initial infection. The retrieved JavaScript went on to set up a very similar payload to the same C2 infrustructure.&lt;/p&gt;
    &lt;p&gt;Review of this retrieved payload yields a few interesting details...&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;It beacons to the C2 server every 5 seconds, providing its system details and asks for further JavaScript instructions.&lt;/item&gt;
      &lt;item&gt;It executes that additional JavaScript within a child process.&lt;/item&gt;
      &lt;item&gt;It's capable of shutting itself and child processes down and cleaning up if asked to do so by the attacker.&lt;/item&gt;
      &lt;item&gt;It has inline comments and phrasing that appear to be consistent with AI-assisted code generation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;This activity highlights the continued evolution of DPRK-linked threat actors, who consistently adapt their tooling and delivery mechanisms to integrate with legitimate developer workflows. The abuse of Visual Studio Code task configuration files and Node.js execution demonstrates how these techniques continue to evolve alongside commonly used development tools.&lt;/p&gt;
    &lt;p&gt;Jamf Threat Labs will continue to track these developments as threat actors refine their tactics and explore new ways to deliver macOS malware. We strongly recommend that customers ensure Threat Prevention and Advanced Threat Controls are enabled and set to block mode in Jamf for Mac to remain protected against the techniques described in this research.&lt;/p&gt;
    &lt;p&gt;Developers should remain cautious when interacting with third-party repositories, especially those shared directly or originating from unfamiliar sources. Before marking a repository as trusted in Visual Studio Code, it‚Äôs important to review its contents. Similarly, "npm install" should only be run on projects that have been vetted, with particular attention paid to package.json files, install scripts, and task configuration files to help avoid unintentionally executing malicious code.&lt;/p&gt;
    &lt;head rend="h2"&gt;Indicators or Compromise&lt;/head&gt;
    &lt;p&gt;Dive into more Jamf Threat Labs research on our blog.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46713526</guid><pubDate>Thu, 22 Jan 2026 00:12:00 +0000</pubDate></item><item><title>Significant US farm losses persist, despite federal assistance</title><link>https://www.fb.org/market-intel/significant-farm-losses-persist-despite-federal-assistance</link><description>&lt;doc fingerprint="6f3c401c4bbe6fca"&gt;
  &lt;main&gt;
    &lt;p&gt;Economist&lt;/p&gt;
    &lt;p&gt;Key Takeaways&lt;/p&gt;
    &lt;p&gt;The USDA-Economic Research Service (ERS) December update to Commodity Costs and Returns provides a comprehensive look at per-acre production costs for the nine principal row crops: corn, soybeans, wheat, cotton, rice, barley, oats, peanuts and sorghum. At a high level, ERS projects average total costs per acre to increase for every crop in 2026, underscoring the persistence of elevated production expenses across U.S. agriculture.&lt;/p&gt;
    &lt;p&gt;When operating expenses and farm-wide costs like equipment, land and management are combined, costs vary widely by crop. In 2025, forecasted total per-acre costs are $1,308 for rice, $1,166 for peanuts, $943 for cotton, $890 for corn, $658 for soybeans, $498 for oats, $491 for barley, $443 for sorghum, and $396 for wheat. Looking ahead, ERS projections for 2026 suggest continued upward pressure across most cost categories, with total cost increasing anywhere from 2.2% to 3.3%. Amongst the nine principal crops, wheat ($409 per acre), sorghum ($458) and oats ($513) remain at the lower end of the production cost spectrum, while soybeans ($678) and barley ($507) fall in the mid-range in 2026. Cotton ($965), peanuts ($1,194) and rice ($1,336) remain the most expensive crops to produce on a per-acre basis.&lt;/p&gt;
    &lt;p&gt;Operating costs‚Äîexpenses directly tied to producing a yearly crop, such as seed, fertilizer, chemicals, fuel and labor‚Äîsubstantially vary across crops. In 2025, total operating costs ranged from $155 per acre for wheat to more than $764 per acre for rice and $631 per acre for peanuts. In 2026, these costs are expected to rise, ranging from $774 per acre for rice and $160 per acre for wheat. While select inputs have moderated slightly from recent peaks, overall operating expenses remain well above pre-2021 levels. Rising costs since 2020 have been driven primarily by sharp increases in interest expenses (+71%), fertilizer (+37%), fuel and oil (+32%), labor (+47%), chemicals (+25%) and maintenance (+27%), alongside notable gains in seed (+18%) and marketing costs (+18%).&lt;/p&gt;
    &lt;p&gt;Losses Persist Even After FBA and ECAP&lt;/p&gt;
    &lt;p&gt;Against this backdrop of elevated costs, commodity prices have remained under pressure, limiting farmers‚Äô ability to cover their costs through the marketplace alone. As a result, many farms are projected to experience losses for a fourth or fifth consecutive year, even after accounting for crop insurance indemnities and ad hoc assistance.&lt;/p&gt;
    &lt;p&gt;The Farmer Bridge Assistance (FBA) Program and the Emergency Commodity Assistance Program (ECAP) provide important near-term support. However, ECAP was designed to address 2023 and 2024 losses, rather than 2025 and later production challenges. For both programs, payments are calculated on a per-acre basis. However, when compared to current per-acre production costs and weak commodity prices, these payments generally cover only a share of losses rather than restore profitability. In fact, returns over total costs for all nine principal row crops are projected to remain negative on a per-acre basis even after accounting for federal assistance. Based on loss calculations used in the Farmer Bridge Assistance Program, rice producers face losses of roughly $210 per acre, followed by cotton ($202), oats ($159), peanuts ($131), sorghum ($91), corn ($87), wheat ($70), soybeans ($61) and barley ($42). In total, net losses across the sector are estimated to exceed $50 billion over the past three crop years.&lt;/p&gt;
    &lt;p&gt;For many farms, aid helps slow the erosion of working capital but does not fully offset negative margins. As a result, producers continue to absorb multiyear losses that strain balance sheets, tighten cash flow and complicate access to operating credit. These loss estimates reflect national averages; actual costs of production and returns vary by region, management decisions and ownership structure. For example, producers who own their farmland may face lower total costs by avoiding cash rental expenses, resulting in higher returns.&lt;/p&gt;
    &lt;p&gt;Specialty Crops&lt;lb/&gt;Additionally, neither the FBA program nor the ECAP address losses in the specialty crops market. The 2024 Marketing Assistance for Specialty Crop Program (MASC) provided a first but limited relief step for growers and, for many, represented some of the first federal assistance tied to market challenges in the sector. Specialty crop growers continue to face deep and persistent economic losses driven by rising input costs, tightening margins, weather and disease disruptions, labor expenses and constraints, and global trade instability ‚Äî challenges shared by field crop agriculture, including producers of crops beyond the nine principal crops, such as alfalfa and sugar beets. Strengthening support for all sectors of agriculture is an economic necessity. Doing so will help maintain a resilient, accessible and diverse U.S. food system. &lt;/p&gt;
    &lt;p&gt;Conclusion&lt;/p&gt;
    &lt;p&gt;ERS cost projections make clear that input costs for all of the nine principal row crops remain elevated and sticky. Continued increases in both operating and overhead expenses are pushing breakeven prices higher, while commodity prices remain insufficient to offset those costs for many producers.&lt;/p&gt;
    &lt;p&gt;While FBA and ECAP payments are an important and welcome step in addressing near-term financial stress, they do not fully close the gap between costs and returns. As farmers enter the 2026/27 marketing year, accumulated losses ‚Äî estimated to exceed $50 billion across the sector over the past three crop years ‚Äî continue to weigh on farm finances.&lt;/p&gt;
    &lt;p&gt;These estimates reflect national average conditions and are calculated ahead of the growing season, before producers make final planting, input and marketing decisions. In practice, farmers respond to market signals by adjusting crop mix, input use and risk management strategies as conditions evolve. While outcomes vary widely by region and operation, persistently elevated breakeven prices underscore the importance of market-driven solutions that strengthen domestic demand ‚Äî such as year-round access to E15 ‚Äî to help support commodity prices and improve farm margins.&lt;/p&gt;
    &lt;p&gt;Much-needed safety net enhancements through the One Big Beautiful Bill Act (OBBBA) are expected to take effect in October 2026, but those changes do not address the pressures farmers face today. In a recent letter to Congress organized by the American Farm Bureau Federation and signed by 56 agricultural organizations, farm groups warned of an economic crisis in rural America, citing multiyear losses driven by record-high input costs and historically low commodity prices. Congressional leaders from both parties have acknowledged the severity of these losses and the need for additional aid to stabilize farm finances. Until longer-term policy improvements take hold, many operations remain caught between high operating costs and low commodity prices, underscoring the ongoing financial strain facing U.S. agriculture as producers weigh whether they can afford to plant another crop.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46713929</guid><pubDate>Thu, 22 Jan 2026 01:11:36 +0000</pubDate></item><item><title>Show HN: High speed graphics rendering research with tinygrad/tinyJIT</title><link>https://github.com/quantbagel/gtinygrad</link><description>&lt;doc fingerprint="e3b45f93fdfd4ff5"&gt;
  &lt;main&gt;
    &lt;p&gt;gtinygrad Minimal tinygrad path tracing playground. tinygrad repo: https://github.com/tinygrad/tinygrad tinygrad README: https://github.com/tinygrad/tinygrad#readme Quick start python examples/raytrace_demo.py&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46714916</guid><pubDate>Thu, 22 Jan 2026 03:26:38 +0000</pubDate></item><item><title>Doctors in Brazil using tilapia fish skin to treat burn victims</title><link>https://www.pbs.org/newshour/health/brazilian-city-uses-tilapia-fish-skin-treat-burn-victims</link><description>&lt;doc fingerprint="ef03d738aad3766e"&gt;
  &lt;main&gt;
    &lt;p&gt;By ‚Äî Nadia Sussman, STAT Nadia Sussman, STAT Leave a comment 0comments Share Copy URL https://www.pbs.org/newshour/health/brazilian-city-uses-tilapia-fish-skin-treat-burn-victims Email Facebook Twitter LinkedIn Pinterest Tumblr Share on Facebook Share on Twitter Why this Brazilian city uses tilapia fish skin to treat burn victims Health Mar 3, 2017 1:09 PM EST FORTAZELA, Brazil ‚Äî In this historic city by the sea in northeast Brazil, burn patients look as if they've emerged from the waves. They are covered in fish skin ‚Äî specifically strips of sterilized tilapia. Doctors here are testing the skin of the popular fish as a bandage for second- and third-degree burns. The innovation arose from an unmet need. Animal skin has long been used in the treatment of burns in developed countries. But Brazil lacks the human skin, pig skin, and artificial alternatives that are widely available in the US. The three functional skin banks in Brazil can meet only 1 percent of the national demand, said Dr. Edmar Maciel, a plastic surgeon and burn specialist leading the clinical trials with tilapia skin. As a result, public health patients in Brazil are normally bandaged with gauze and silver sulfadiazine cream. "It's a burn cream because there's silver in it, so it prevents the burns from being infected," said Dr. Jeanne Lee, interim burn director at the the regional burn center at the University of California at San Diego. "But it doesn't help in terms of debriding a burn or necessarily helping it heal." READ MORE: First Look: Plumbing the mysteries of sweat to help burn patients cool their skin The gauze-and-cream dressing must be changed every day, a painful process. In the burn unit at Fortaleza's Jos√© Frota Institute, patients contort as their wounds are unwrapped and washed. Enter the humble tilapia, a fish that's widely farmed in Brazil and whose skin, until now, was considered trash. Unlike the gauze bandages, the sterilized tilapia skin goes on and stays on. The first step in the research process was to analyze the fish skin. "We got a great surprise when we saw that the amount of collagen proteins, types 1 and 3, which are very important for scarring, exist in large quantities in tilapia skin, even more than in human skin and other skins," Maciel said. "Another factor we discovered is that the amount of tension, of resistance in tilapia skin is much greater than in human skin. Also the amount of moisture." In patients with superficial second-degree burns, the doctors apply the fish skin and leave it until the patient scars naturally. For deep second-degree burns, the tilapia bandages must be changed a few times over several weeks of treatment, but still far less often than the gauze with cream. The tilapia treatment also cuts down healing time by up to several days and reduces the use of pain medication, Maciel said. Ant√¥nio dos Santos, a fisherman, was offered the tilapia treatment as part of a clinical trial after he sustained burns to his entire right arm when a gas canister on his boat exploded. He accepted. "After they put on the tilapia skin, it really relieved the pain," he said. "I thought it was really interesting that something like this could work." READ MORE: High-tech bandage wins $100K from Boston Marathon bombing survivor's family The initial batches of tilapia skin were studied and prepared by a team of researchers at the Federal University of Cear√°. Lab technicians used various sterilizing agents, then sent the skins for radiation in S√£o Paulo to kill viruses, before packaging and refrigerating the skins. Once cleaned and treated, they can last for up to two years. In the US, animal-based skin substitutes require levels of scrutiny from the Food and Drug Administration and animal rights groups that can drive up costs, Lee said. Given the substantial supply of donated human skin, tilapia skin is unlikely to arrive at American hospitals anytime soon. But it may be a boon in developing countries. "I'm willing to use anything that might actually help a patient," Lee said. "It may be a good option depending on what country you're talking about. But I also think the problem is that you need to find places that have the resources to actually process the skin and sterilize it, and make sure it doesn't have diseases." In Brazil, in addition to the clinical trials, researchers are currently conducting histological studies that compare the composition of human, tilapia, pig, and frog skins. They are also conducting studies on the comparative costs of tilapia skin and conventional burn treatments. If clinical trials show continued success, doctors hope a company will process the skins on an industrial scale and sell it to the public health system. This article is reproduced with permission from STAT. It was first published on Mar. 2, 2017. Find the original story here. A free press is a cornerstone of a healthy democracy. Support trusted journalism and civil dialogue. Donate now By ‚Äî Nadia Sussman, STAT Nadia Sussman, STAT&lt;/p&gt;
    &lt;p&gt;FORTAZELA, Brazil ‚Äî In this historic city by the sea in northeast Brazil, burn patients look as if they've emerged from the waves. They are covered in fish skin ‚Äî specifically strips of sterilized tilapia. Doctors here are testing the skin of the popular fish as a bandage for second- and third-degree burns. The innovation arose from an unmet need. Animal skin has long been used in the treatment of burns in developed countries. But Brazil lacks the human skin, pig skin, and artificial alternatives that are widely available in the US. The three functional skin banks in Brazil can meet only 1 percent of the national demand, said Dr. Edmar Maciel, a plastic surgeon and burn specialist leading the clinical trials with tilapia skin. As a result, public health patients in Brazil are normally bandaged with gauze and silver sulfadiazine cream. "It's a burn cream because there's silver in it, so it prevents the burns from being infected," said Dr. Jeanne Lee, interim burn director at the the regional burn center at the University of California at San Diego. "But it doesn't help in terms of debriding a burn or necessarily helping it heal." READ MORE: First Look: Plumbing the mysteries of sweat to help burn patients cool their skin The gauze-and-cream dressing must be changed every day, a painful process. In the burn unit at Fortaleza's Jos√© Frota Institute, patients contort as their wounds are unwrapped and washed. Enter the humble tilapia, a fish that's widely farmed in Brazil and whose skin, until now, was considered trash. Unlike the gauze bandages, the sterilized tilapia skin goes on and stays on. The first step in the research process was to analyze the fish skin. "We got a great surprise when we saw that the amount of collagen proteins, types 1 and 3, which are very important for scarring, exist in large quantities in tilapia skin, even more than in human skin and other skins," Maciel said. "Another factor we discovered is that the amount of tension, of resistance in tilapia skin is much greater than in human skin. Also the amount of moisture." In patients with superficial second-degree burns, the doctors apply the fish skin and leave it until the patient scars naturally. For deep second-degree burns, the tilapia bandages must be changed a few times over several weeks of treatment, but still far less often than the gauze with cream. The tilapia treatment also cuts down healing time by up to several days and reduces the use of pain medication, Maciel said. Ant√¥nio dos Santos, a fisherman, was offered the tilapia treatment as part of a clinical trial after he sustained burns to his entire right arm when a gas canister on his boat exploded. He accepted. "After they put on the tilapia skin, it really relieved the pain," he said. "I thought it was really interesting that something like this could work." READ MORE: High-tech bandage wins $100K from Boston Marathon bombing survivor's family The initial batches of tilapia skin were studied and prepared by a team of researchers at the Federal University of Cear√°. Lab technicians used various sterilizing agents, then sent the skins for radiation in S√£o Paulo to kill viruses, before packaging and refrigerating the skins. Once cleaned and treated, they can last for up to two years. In the US, animal-based skin substitutes require levels of scrutiny from the Food and Drug Administration and animal rights groups that can drive up costs, Lee said. Given the substantial supply of donated human skin, tilapia skin is unlikely to arrive at American hospitals anytime soon. But it may be a boon in developing countries. "I'm willing to use anything that might actually help a patient," Lee said. "It may be a good option depending on what country you're talking about. But I also think the problem is that you need to find places that have the resources to actually process the skin and sterilize it, and make sure it doesn't have diseases." In Brazil, in addition to the clinical trials, researchers are currently conducting histological studies that compare the composition of human, tilapia, pig, and frog skins. They are also conducting studies on the comparative costs of tilapia skin and conventional burn treatments. If clinical trials show continued success, doctors hope a company will process the skins on an industrial scale and sell it to the public health system. This article is reproduced with permission from STAT. It was first published on Mar. 2, 2017. Find the original story here. A free press is a cornerstone of a healthy democracy. Support trusted journalism and civil dialogue. Donate now&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46715600</guid><pubDate>Thu, 22 Jan 2026 05:15:46 +0000</pubDate></item></channel></rss>