<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 18 Nov 2025 12:21:00 +0000</lastBuildDate><item><title>Show HN: ESPectre â€“ Motion detection based on Wi-Fi spectre analysis</title><link>https://github.com/francescopace/espectre</link><description>&lt;doc fingerprint="149c507545b3b9c1"&gt;
  &lt;main&gt;
    &lt;p&gt;Motion detection system based on Wi-Fi spectre analysis (CSI), with Home Assistant integration.&lt;/p&gt;
    &lt;p&gt;ğŸ“° Featured Article: Read the complete story behind ESPectre on Medium ğŸ‡®ğŸ‡¹ Italian, ğŸ‡¬ğŸ‡§ English&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;In 3 Points&lt;/item&gt;
      &lt;item&gt;Mathematical Approach&lt;/item&gt;
      &lt;item&gt;What You Need&lt;/item&gt;
      &lt;item&gt;Quick Start&lt;/item&gt;
      &lt;item&gt;How It Works&lt;/item&gt;
      &lt;item&gt;What You Can Do With It&lt;/item&gt;
      &lt;item&gt;Sensor Placement Guide&lt;/item&gt;
      &lt;item&gt;System Architecture&lt;/item&gt;
      &lt;item&gt;FAQ&lt;/item&gt;
      &lt;item&gt;Security and Privacy&lt;/item&gt;
      &lt;item&gt;Technical Deep Dive&lt;/item&gt;
      &lt;item&gt;Future Evolutions&lt;/item&gt;
      &lt;item&gt;References&lt;/item&gt;
      &lt;item&gt;Changelog&lt;/item&gt;
      &lt;item&gt;License&lt;/item&gt;
      &lt;item&gt;Author&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;What it does: Detects movement at home using Wi-Fi (no cameras, no microphones)&lt;/item&gt;
      &lt;item&gt;What you need: A ~â‚¬10 device (ESP32-S3) + Home Assistant or MQTT server + ESP-IDF development tools&lt;/item&gt;
      &lt;item&gt;Setup time: 30-45 minutes (first time, including ESP-IDF setup)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This project currently does NOT use Machine Learning models. Instead, it employs a mathematical approach that extracts 10 features from CSI (Channel State Information) data using statistical and signal processing techniques.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;âœ… No ML training required: Works out-of-the-box with mathematical algorithms&lt;/item&gt;
      &lt;item&gt;âœ… 10 extracted features: Statistical, spatial, and temporal features&lt;/item&gt;
      &lt;item&gt;âœ… Real-time processing: Low latency detection on ESP32-S3 hardware&lt;/item&gt;
      &lt;item&gt;âœ… Foundation for ML: These features can serve as the basis for collecting labeled datasets to train ML models for advanced tasks (people counting, activity recognition, gesture detection)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The mathematical approach provides excellent movement detection without the complexity of ML model training, while the extracted features offer a solid foundation for future ML-based enhancements.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;âœ… 2.4GHz Wi-Fi Router (the one you already have at home works fine)&lt;/item&gt;
      &lt;item&gt;âœ… ESP32-S3 DevKit bundle with external antennas (~â‚¬10) - Available on Amazon, AliExpress, or electronics stores&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;ESP32-S3 DevKit with external antennas (recommended for better reception)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;âœ… MQTT Broker (required for operation): &lt;list rend="ul"&gt;&lt;item&gt;Home Assistant with built-in MQTT broker (on Raspberry Pi, PC, NAS, or cloud)&lt;/item&gt;&lt;item&gt;OR standalone Mosquitto MQTT server (can run on any device, including Raspberry Pi)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;âœ… ESP-IDF v6.1 (development framework for building firmware)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;âœ… Basic command line knowledge required for building and flashing firmware&lt;/item&gt;
      &lt;item&gt;âŒ NO router configuration needed&lt;/item&gt;
      &lt;item&gt;âœ… Follow the setup guide in SETUP.md&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Setup time: ~30-45 minutes (first time)&lt;lb/&gt; Difficulty: Intermediate (requires ESP-IDF setup)&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Setup &amp;amp; Installation: Follow the complete guide in SETUP.md&lt;/item&gt;
      &lt;item&gt;Calibration &amp;amp; Tuning: Optimize for your environment with CALIBRATION.md&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When someone moves in a room, they "disturb" the Wi-Fi waves traveling between the router and the sensor. It's like when you move your hand in front of a flashlight and see the shadow change.&lt;/p&gt;
    &lt;p&gt;The ESP32-S3 device "listens" to these changes and understands if there's movement.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;âœ… No cameras (total privacy)&lt;/item&gt;
      &lt;item&gt;âœ… No wearables needed (no bracelets or sensors to wear)&lt;/item&gt;
      &lt;item&gt;âœ… Works through walls (Wi-Fi passes through walls)&lt;/item&gt;
      &lt;item&gt;âœ… Very cheap (~â‚¬10 total)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;ğŸ“š Technical Explanation (click to expand)&lt;/head&gt;
    &lt;p&gt;Channel State Information (CSI) represents the physical characteristics of the wireless communication channel between transmitter and receiver. Unlike simple RSSI (Received Signal Strength Indicator), CSI provides rich, multi-dimensional data about the radio channel.&lt;/p&gt;
    &lt;p&gt;Per-subcarrier information:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Amplitude: Signal strength for each OFDM subcarrier (up to 64)&lt;/item&gt;
      &lt;item&gt;Phase: Phase shift of each subcarrier&lt;/item&gt;
      &lt;item&gt;Frequency response: How the channel affects different frequencies&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Environmental effects:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Multipath propagation: Reflections from walls, furniture, objects&lt;/item&gt;
      &lt;item&gt;Doppler shifts: Changes caused by movement&lt;/item&gt;
      &lt;item&gt;Temporal variations: How the channel evolves over time&lt;/item&gt;
      &lt;item&gt;Spatial patterns: Signal distribution across antennas/subcarriers&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When a person moves in an environment, they:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Alter multipath reflections (new signal paths)&lt;/item&gt;
      &lt;item&gt;Change signal amplitude and phase&lt;/item&gt;
      &lt;item&gt;Create temporal variations in CSI patterns&lt;/item&gt;
      &lt;item&gt;Modify the electromagnetic field structure&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These changes are detectable even through walls, enabling privacy-preserving presence detection without cameras, microphones, or wearable devices.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ğŸ  Home security: Get an alert if someone enters while you're away&lt;/item&gt;
      &lt;item&gt;ğŸ‘´ Elderly care: Monitor activity to detect falls or prolonged inactivity&lt;/item&gt;
      &lt;item&gt;ğŸ’¡ Smart automation: Turn on lights/heating only when someone is present&lt;/item&gt;
      &lt;item&gt;âš¡ Energy saving: Automatically turn off devices in empty rooms&lt;/item&gt;
      &lt;item&gt;ğŸ‘¶ Child monitoring: Alert if they leave the room during the night&lt;/item&gt;
      &lt;item&gt;ğŸŒ¡ï¸ Climate control: Heat/cool only occupied zones&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Optimal sensor placement is crucial for reliable movement detection.&lt;/p&gt;
    &lt;p&gt;Optimal range: 3-8 meters&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;Distance&lt;/cell&gt;
        &lt;cell role="head"&gt;Signal&lt;/cell&gt;
        &lt;cell role="head"&gt;Multipath&lt;/cell&gt;
        &lt;cell role="head"&gt;Sensitivity&lt;/cell&gt;
        &lt;cell role="head"&gt;Noise&lt;/cell&gt;
        &lt;cell role="head"&gt;Recommendation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;&amp;lt; 2m&lt;/cell&gt;
        &lt;cell&gt;Too strong&lt;/cell&gt;
        &lt;cell&gt;Minimal&lt;/cell&gt;
        &lt;cell&gt;Low&lt;/cell&gt;
        &lt;cell&gt;Low&lt;/cell&gt;
        &lt;cell&gt;âŒ Too close&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;3-8m&lt;/cell&gt;
        &lt;cell&gt;Strong&lt;/cell&gt;
        &lt;cell&gt;Good&lt;/cell&gt;
        &lt;cell&gt;High&lt;/cell&gt;
        &lt;cell&gt;Low&lt;/cell&gt;
        &lt;cell&gt;âœ… Optimal&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;&amp;gt; 10-15m&lt;/cell&gt;
        &lt;cell&gt;Weak&lt;/cell&gt;
        &lt;cell&gt;Variable&lt;/cell&gt;
        &lt;cell&gt;Low&lt;/cell&gt;
        &lt;cell&gt;High&lt;/cell&gt;
        &lt;cell&gt;âŒ Too far&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;âœ… Position sensor in the area to monitor (not necessarily in direct line with router)&lt;lb/&gt; âœ… Height: 1-1.5 meters from ground (desk/table height)&lt;lb/&gt; âœ… External antenna: Use IPEX connector for better reception&lt;lb/&gt; âŒ Avoid metal obstacles between router and sensor (refrigerators, metal cabinets)&lt;lb/&gt; âŒ Avoid corners or enclosed spaces (reduces multipath diversity)&lt;/p&gt;
    &lt;p&gt;ESPectre uses a streamlined processing pipeline:&lt;/p&gt;
    &lt;code&gt;â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CSI Data   â”‚  Raw Wi-Fi Channel State Information
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Segmentation â”‚  Moving Variance Segmentation (MVS)
â”‚  (2-state)  â”‚  IDLE â†” MOTION (operates on RAW CSI)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                     â”‚
       â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    IDLE     â”‚      â”‚    MOTION    â”‚
â”‚  (no feat.) â”‚      â”‚  (optional   â”‚
â”‚             â”‚      â”‚   features)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚   Filters   â”‚  Butterworth, Wavelet,
                     â”‚             â”‚  Hampel, Savitzky-Golay
                     â”‚             â”‚  (applied to features only)
                     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚  Features   â”‚  10 mathematical features
                     â”‚ (if enabled)â”‚  (filtered CSI data)
                     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                                         â”‚
       â–¼                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    MQTT     â”‚  Publish state + metrics â”‚    MQTT     â”‚
â”‚   (IDLE)    â”‚                          â”‚  (MOTION)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
&lt;/code&gt;
    &lt;p&gt;Key Points:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2-state system: IDLE or MOTION (no intermediate states)&lt;/item&gt;
      &lt;item&gt;Segmentation-based: Uses Moving Variance Segmentation (MVS) on raw CSI data&lt;/item&gt;
      &lt;item&gt;Filters applied to features only: Segmentation uses unfiltered data to preserve motion sensitivity&lt;/item&gt;
      &lt;item&gt;Optional features: Feature extraction only during MOTION state (configurable)&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ESP32-S3 â”‚  â”‚ESP32-S3 â”‚  â”‚ESP32-S3 â”‚
â”‚ Room 1  â”‚  â”‚ Room 2  â”‚  â”‚ Room 3  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚            â”‚            â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”‚ MQTT
                  â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    MQTT Broker     â”‚
         â”‚ (Home Assistant    â”‚
         â”‚  built-in or any   â”‚
         â”‚  MQTT Server)      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Home Assistant â”‚
          â”‚   MQTT Sensors â”‚
          â”‚  &amp;amp; Automations â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
&lt;/code&gt;
    &lt;p&gt;Each sensor publishes to its own topic:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;home/espectre/kitchen&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;home/espectre/bedroom&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;home/espectre/living&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Home Assistant can then:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Monitor each room independently&lt;/item&gt;
      &lt;item&gt;Create group sensors for whole-house occupancy&lt;/item&gt;
      &lt;item&gt;Implement zone-based automations&lt;/item&gt;
      &lt;item&gt;Track movement patterns across rooms&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;Click to expand FAQ&lt;/head&gt;
    &lt;p&gt;Q: Do I need programming knowledge to use it?&lt;lb/&gt; A: Basic command line skills are needed to build and flash the firmware using ESP-IDF. Follow the step-by-step guide in SETUP.md.&lt;/p&gt;
    &lt;p&gt;Q: Does it work with my router?&lt;lb/&gt; A: Yes, if your router has 2.4GHz Wi-Fi (virtually all modern routers have it).&lt;/p&gt;
    &lt;p&gt;Q: How much does it cost in total?&lt;lb/&gt; A: Hardware: ~â‚¬10 for the ESP32-S3 device. Software: All free and open source. You'll also need a device to run the MQTT broker (Home Assistant or Mosquitto), which can be a Raspberry Pi (~â‚¬35-50) or any existing PC/NAS you already have (free).&lt;/p&gt;
    &lt;p&gt;Q: Do I need to modify anything on the router?&lt;lb/&gt; A: No! The router works normally. The sensor "listens" to Wi-Fi signals without modifying anything.&lt;/p&gt;
    &lt;p&gt;Q: Can I try it without Home Assistant?&lt;lb/&gt; A: Yes, you can use any MQTT server (e.g., Mosquitto) or even just view data via serial port.&lt;/p&gt;
    &lt;p&gt;Q: Does it work through walls?&lt;lb/&gt; A: Yes, the 2.4GHz Wi-Fi signal penetrates drywall. Reinforced concrete walls reduce sensitivity but detection remains possible at reduced distances.&lt;/p&gt;
    &lt;p&gt;Q: How many sensors are needed for a house?&lt;lb/&gt; A: It depends on size. One sensor can monitor ~50 mÂ². For larger homes, use multiple sensors (1 sensor every 50-70 mÂ² for optimal coverage).&lt;/p&gt;
    &lt;p&gt;Q: Can it distinguish between people and pets?&lt;lb/&gt; A: The system uses a 2-state segmentation model (IDLE/MOTION) that identifies generic movement without distinguishing between people, pets, or other moving objects. For more sophisticated classification (people vs pets, activity recognition, gesture detection), trained AI/ML models would be required (see Future Evolutions section).&lt;/p&gt;
    &lt;p&gt;Q: Does it consume a lot of Wi-Fi bandwidth?&lt;lb/&gt; A: No, MQTT traffic is minimal. With smart publishing disabled (default), the system publishes all detection updates. When smart publishing is enabled, the system only sends data on significant changes or every 5 seconds as a heartbeat, resulting in ~0.2-0.5 KB/s per sensor during idle periods and up to ~1 KB/s during active movement. Network impact is negligible.&lt;/p&gt;
    &lt;p&gt;Q: Does it work with mesh Wi-Fi networks?&lt;lb/&gt; A: Yes, it works normally. Make sure the ESP32 connects to the 2.4 GHz band.&lt;/p&gt;
    &lt;p&gt;Q: Is a dedicated server necessary?&lt;lb/&gt; A: No, Home Assistant can run on Raspberry Pi, NAS, or cloud. Alternatively, just an MQTT broker (Mosquitto) on any device is sufficient.&lt;/p&gt;
    &lt;p&gt;Q: How accurate is the detection?&lt;lb/&gt; A: Detection accuracy is highly environment-dependent and requires proper tuning. Factors affecting performance include: room layout, wall materials, furniture placement, distance from router (optimal: 3-8m), and interference levels. In optimal conditions with proper tuning, the system provides reliable movement detection. Adjust the &lt;code&gt;segmentation_threshold&lt;/code&gt; parameter to tune sensitivity for your specific environment.&lt;/p&gt;
    &lt;p&gt;Q: What's the power consumption?&lt;lb/&gt; A: ~500mW typical during continuous operation. The firmware includes support for power optimization, and deep sleep modes can be implemented for battery-powered deployments, though this would require custom modifications to the code.&lt;/p&gt;
    &lt;p&gt;Q: If it doesn't work, can I get help?&lt;lb/&gt; A: Yes, open an Issue on GitHub or contact me via email.&lt;/p&gt;
    &lt;head&gt;ğŸ” Privacy, Security &amp;amp; Ethical Considerations (click to expand)&lt;/head&gt;
    &lt;p&gt;The system collects anonymous data related to the physical characteristics of the Wi-Fi radio channel:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Amplitudes and phases of OFDM subcarriers&lt;/item&gt;
      &lt;item&gt;Statistical signal variances&lt;/item&gt;
      &lt;item&gt;NOT collected: personal identities, communication contents, images, audio&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;CSI data represents only the properties of the transmission medium and does not contain direct identifying information.&lt;/p&gt;
    &lt;p&gt;âœ… No cameras: Respect for visual privacy&lt;lb/&gt; âœ… No microphones: No audio recording&lt;lb/&gt; âœ… No wearables: Doesn't require wearable devices&lt;lb/&gt; âœ… Aggregated data: Only statistical metrics, not raw identifying data&lt;/p&gt;
    &lt;p&gt;WARNING: Despite the intrinsic anonymity of CSI data, this system can be used for:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Non-consensual monitoring: Detecting presence/movement of people without their explicit consent&lt;/item&gt;
      &lt;item&gt;Behavioral profiling: With advanced AI models, inferring daily life patterns&lt;/item&gt;
      &lt;item&gt;Domestic privacy violation: Tracking activities inside private homes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The user is solely responsible for using this system and must:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;âœ… Obtain explicit consent from all monitored persons&lt;/item&gt;
      &lt;item&gt;âœ… Respect local regulations (GDPR in EU, local privacy laws)&lt;/item&gt;
      &lt;item&gt;âœ… Clearly inform about the presence of the sensing system&lt;/item&gt;
      &lt;item&gt;âœ… Limit use to legitimate purposes (home security, personal home automation)&lt;/item&gt;
      &lt;item&gt;âœ… Protect data with encryption and controlled access&lt;/item&gt;
      &lt;item&gt;âŒ DO NOT use for illegal surveillance, stalking, or violation of others' privacy&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Moving Variance Segmentation (MVS) analysis: baseline graphs (top) show quiet state, while bottom graphs show motion detection with turbulence signal, adaptive threshold, and state transitions&lt;/p&gt;
    &lt;head&gt;ğŸ”¬ Signal Processing Pipeline (click to expand)&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Native ESP32 CSI API captures Wi-Fi Channel State Information via callback&lt;/item&gt;
      &lt;item&gt;Extracts amplitude and phase data from OFDM subcarriers (up to 64 subcarriers)&lt;/item&gt;
      &lt;item&gt;Typical capture rate: ~10-100 packets/second depending on Wi-Fi traffic&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Spatial turbulence calculation: Standard deviation of subcarrier amplitudes (raw CSI data)&lt;/item&gt;
      &lt;item&gt;Moving Variance Segmentation (MVS): Real-time motion segment extraction&lt;/item&gt;
      &lt;item&gt;Adaptive threshold: Based on moving variance of turbulence signal&lt;/item&gt;
      &lt;item&gt;Segment features: Duration, average turbulence, maximum turbulence&lt;/item&gt;
      &lt;item&gt;Circular buffer: Maintains up to 10 recent segments for analysis&lt;/item&gt;
      &lt;item&gt;Foundation for ML: Segments can be labeled and used for activity classification&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: Segmentation operates on raw, unfiltered CSI data to preserve motion sensitivity. Filters are not applied to the turbulence signal used for segmentation.&lt;/p&gt;
    &lt;p&gt;Advanced filters applied to CSI data before feature extraction (configurable via MQTT):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Butterworth Low-Pass: Removes high-frequency noise &amp;gt;8Hz (environmental interference) - Enabled by default&lt;/item&gt;
      &lt;item&gt;Wavelet db4: Removes low-frequency persistent noise using Daubechies wavelet transform&lt;/item&gt;
      &lt;item&gt;Hampel Filter: Outlier removal using MAD (Median Absolute Deviation)&lt;/item&gt;
      &lt;item&gt;Savitzky-Golay Filter: Polynomial smoothing (enabled by default)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Filter Pipeline: Raw CSI â†’ Butterworth (high freq) â†’ Wavelet (low freq) â†’ Hampel â†’ Savitzky-Golay â†’ Features&lt;/p&gt;
    &lt;p&gt;Note: Filters are applied only to feature extraction, not to segmentation. Segmentation uses raw CSI data to preserve motion sensitivity.&lt;/p&gt;
    &lt;p&gt;When enabled (default: on), extracts 10 mathematical features from filtered CSI data during MOTION state:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Statistical (5): Variance, Skewness, Kurtosis, Entropy, IQR&lt;/item&gt;
      &lt;item&gt;Spatial (3): Spatial variance, correlation, gradient across subcarriers&lt;/item&gt;
      &lt;item&gt;Temporal (2): Delta mean, delta variance (changes between consecutive packets)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: Feature extraction can be disabled to reduce CPU usage if only basic motion detection is needed.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Publishes JSON payload every 1 second (configurable)&lt;/item&gt;
      &lt;item&gt;QoS level 0 (fire-and-forget) for low latency&lt;/item&gt;
      &lt;item&gt;Retained message option for last known state&lt;/item&gt;
      &lt;item&gt;Automatic reconnection on connection loss&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;MQTT Sensor subscribes to topic and creates entity&lt;/item&gt;
      &lt;item&gt;State: Primary &lt;code&gt;movement&lt;/code&gt;value (0.0-1.0)&lt;/item&gt;
      &lt;item&gt;Attributes: All other metrics available for conditions&lt;/item&gt;
      &lt;item&gt;History: Automatic logging to database for graphs&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;ğŸ“Š Optional Feature Extraction (click to expand)&lt;/head&gt;
    &lt;p&gt;ESPectre can optionally extract 10 mathematical features from CSI data during MOTION state:&lt;/p&gt;
    &lt;p&gt;Statistical properties of the CSI signal distribution:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Variance - Signal variability, increases significantly with movement&lt;/item&gt;
      &lt;item&gt;Skewness - Distribution asymmetry, detects irregular movement patterns&lt;/item&gt;
      &lt;item&gt;Kurtosis - Distribution "tailedness", identifies outliers and sudden changes&lt;/item&gt;
      &lt;item&gt;Entropy - Signal randomness/disorder, increases when environment changes&lt;/item&gt;
      &lt;item&gt;IQR (Interquartile Range) - Robust spread measure (Q3-Q1), resistant to outliers&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Characteristics across OFDM subcarriers (frequency domain):&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Spatial Variance - Variability across subcarriers, indicates multipath diversity&lt;/item&gt;
      &lt;item&gt;Spatial Correlation - Correlation between adjacent subcarriers, affected by movement&lt;/item&gt;
      &lt;item&gt;Spatial Gradient - Rate of change across subcarriers, highly sensitive to movement&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Changes between consecutive CSI packets:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Temporal Delta Mean - Average absolute difference from previous packet&lt;/item&gt;
      &lt;item&gt;Temporal Delta Variance - Variance of differences from previous packet&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Feature extraction is enabled by default but can be disabled to reduce CPU usage. Note: Features are only extracted during MOTION state, not during IDLE, to optimize performance.&lt;/p&gt;
    &lt;head&gt;ğŸ“‹ Technical Specifications (click to expand)&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Board: ESP32-S3-DevKitC-1 N16R8&lt;/item&gt;
      &lt;item&gt;Flash: 16MB&lt;/item&gt;
      &lt;item&gt;PSRAM: 8MB&lt;/item&gt;
      &lt;item&gt;Wi-Fi: 802.11 a/g/n (2.4 GHz only)&lt;/item&gt;
      &lt;item&gt;Antenna: Built-in PCB antenna + IPEX connector for external&lt;/item&gt;
      &lt;item&gt;Power: USB-C 5V or 3.3V via pins&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Framework: ESP-IDF v6.1&lt;/item&gt;
      &lt;item&gt;Language: C&lt;/item&gt;
      &lt;item&gt;Build System: CMake&lt;/item&gt;
      &lt;item&gt;Flash Tool: esptool.py&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CSI Capture Rate: 10-100 packets/second&lt;/item&gt;
      &lt;item&gt;Processing Latency: &amp;lt;50ms per packet&lt;/item&gt;
      &lt;item&gt;MQTT Publish Rate: Smart publishing (only on significant changes + 5s heartbeat)&lt;/item&gt;
      &lt;item&gt;MQTT Bandwidth: ~0.2-1 KB/s depending on activity&lt;/item&gt;
      &lt;item&gt;Power Consumption: ~500mW typical&lt;/item&gt;
      &lt;item&gt;Detection Range: 3-8 meters optimal&lt;/item&gt;
      &lt;item&gt;Detection Accuracy: Environment-dependent, requires tuning&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Works only on 2.4 GHz band (ESP32-S3 hardware limitation)&lt;/item&gt;
      &lt;item&gt;Sensitivity dependent on: wall materials, antenna placement, distances, interference&lt;/item&gt;
      &lt;item&gt;Not suitable for environments with very high Wi-Fi traffic&lt;/item&gt;
      &lt;item&gt;Cannot distinguish between people, pets, or objects (generic motion detection)&lt;/item&gt;
      &lt;item&gt;Cannot count people or recognize specific activities (without ML models)&lt;/item&gt;
      &lt;item&gt;Reduced performance through metal obstacles or thick concrete walls&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;ğŸ“š Machine Learning and Deep Learning (click to expand)&lt;/head&gt;
    &lt;p&gt;The current implementation uses an advanced mathematical approach with 10 features and multi-criteria detection to identify movement patterns. While this provides excellent results without requiring ML training, scientific research has shown that Machine Learning and Deep Learning techniques can extract even richer information from CSI data for complex tasks like people counting, activity recognition, and gesture detection.&lt;/p&gt;
    &lt;p&gt;Classification or regression models can estimate the number of people present in an environment by analyzing complex patterns in CSI.&lt;/p&gt;
    &lt;p&gt;References:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Wang et al. (2017) - "Device-Free Crowd Counting Using WiFi Channel State Information" - IEEE INFOCOM&lt;/item&gt;
      &lt;item&gt;Xi et al. (2016) - "Electronic Frog Eye: Counting Crowd Using WiFi" - IEEE INFOCOM&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Neural networks (CNN, LSTM, Transformer) can classify human activities like walking, falling, sitting, sleeping.&lt;/p&gt;
    &lt;p&gt;References:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Wang et al. (2015) - "Understanding and Modeling of WiFi Signal Based Human Activity Recognition" - ACM MobiCom&lt;/item&gt;
      &lt;item&gt;Yousefi et al. (2017) - "A Survey on Behavior Recognition Using WiFi Channel State Information" - IEEE Communications Magazine&lt;/item&gt;
      &lt;item&gt;Zhang et al. (2019) - "WiFi-Based Indoor Robot Positioning Using Deep Neural Networks" - IEEE Access&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Deep learning algorithms can estimate position and trajectory of moving people.&lt;/p&gt;
    &lt;p&gt;References:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Wang et al. (2016) - "CSI-Based Fingerprinting for Indoor Localization: A Deep Learning Approach" - IEEE Transactions on Vehicular Technology&lt;/item&gt;
      &lt;item&gt;Chen et al. (2018) - "WiFi CSI Based Passive Human Activity Recognition Using Attention Based BLSTM" - IEEE Transactions on Mobile Computing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Models trained on CSI temporal sequences can recognize hand gestures for touchless control.&lt;/p&gt;
    &lt;p&gt;References:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Abdelnasser et al. (2015) - "WiGest: A Ubiquitous WiFi-based Gesture Recognition System" - IEEE INFOCOM&lt;/item&gt;
      &lt;item&gt;Jiang et al. (2020) - "Towards Environment Independent Device Free Human Activity Recognition" - ACM MobiCom&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;UT-HAR: Human Activity Recognition dataset (University of Texas)&lt;/item&gt;
      &lt;item&gt;Widar 3.0: Gesture recognition dataset with CSI&lt;/item&gt;
      &lt;item&gt;SignFi: Sign language recognition dataset&lt;/item&gt;
      &lt;item&gt;FallDeFi: Fall detection dataset&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;ğŸ›œ Standardized Wi-Fi Sensing (IEEE 802.11bf) (click to expand)&lt;/head&gt;
    &lt;p&gt;Currently, only a limited number of Wi-Fi chipsets support CSI extraction, which restricts hardware options for Wi-Fi sensing applications. However, the IEEE 802.11bf (Wi-Fi Sensing) standard should significantly improve this situation by making CSI extraction a standardized feature.&lt;/p&gt;
    &lt;p&gt;The 802.11bf standard was officially published on September 26, 2025, introducing Wi-Fi Sensing as a native feature of the Wi-Fi protocol. Main characteristics:&lt;/p&gt;
    &lt;p&gt;ğŸ”¹ Native sensing: Detection of movements, gestures, presence, and vital signs&lt;lb/&gt; ğŸ”¹ Interoperability: Standardized support across different vendors&lt;lb/&gt; ğŸ”¹ Optimizations: Specific protocols to reduce overhead and power consumption&lt;lb/&gt; ğŸ”¹ Privacy by design: Privacy protection mechanisms integrated into the standard&lt;lb/&gt; ğŸ”¹ Greater precision: Improvements in temporal and spatial granularity&lt;lb/&gt; ğŸ”¹ Existing infrastructure: Works with already present Wi-Fi infrastructure&lt;/p&gt;
    &lt;p&gt;Market: The Wi-Fi Sensing market is in its early stages and is expected to experience significant growth in the coming years as the 802.11bf standard enables native sensing capabilities in consumer devices.&lt;/p&gt;
    &lt;p&gt;Hardware availability:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;g-emoji&gt;âš ï¸&lt;/g-emoji&gt;Consumer routers: Currently there are no widely available consumer routers with native 802.11bf support&lt;/item&gt;
      &lt;item&gt;ğŸ¢ Commercial/industrial: Experimental devices and integrated solutions already in use&lt;/item&gt;
      &lt;item&gt;ğŸ”§ Hardware requirements: Requires multiple antennas, Wi-Fi 6/6E/7 support, and AI algorithms for signal processing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Expected timeline:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2025-2026: First implementations in enterprise and premium smart home devices&lt;/item&gt;
      &lt;item&gt;2027-2028: Diffusion in high-end consumer routers&lt;/item&gt;
      &lt;item&gt;2029+: Mainstream adoption in consumer devices&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When 802.11bf is widely adopted, applications like this project will become:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;More accessible: No need for specialized hardware or modified firmware&lt;/item&gt;
      &lt;item&gt;More reliable: Standardization ensures predictable behavior&lt;/item&gt;
      &lt;item&gt;More efficient: Protocols optimized for continuous sensing&lt;/item&gt;
      &lt;item&gt;More secure: Privacy mechanisms integrated at the standard level&lt;/item&gt;
      &lt;item&gt;More powerful: Ability to detect even vital signs (breathing, heartbeat)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Perspective: In the next 3-5 years, routers and consumer devices will natively support Wi-Fi Sensing, making projects like this implementable without specialized hardware or firmware modifications. This will open new possibilities for smart home, elderly care, home security, health monitoring, and advanced IoT applications.&lt;/p&gt;
    &lt;p&gt;For now: Solutions like this project based on ESP32 CSI API remain the most accessible and economical way to experiment with Wi-Fi Sensing.&lt;/p&gt;
    &lt;p&gt;This project builds upon extensive research in Wi-Fi sensing and CSI-based movement detection. The following academic works and theses provide valuable insights into mathematical signal processing approaches for human activity recognition using Wi-Fi Channel State Information:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Wi-Fi Sensing per Human Identification attraverso CSI&lt;/p&gt;&lt;lb/&gt;University thesis (in Italian) covering CSI data collection for human recognition through Wi-Fi signal analysis, with in-depth exploration of mathematical signal processing methods.&lt;lb/&gt;ğŸ“„ Read thesis&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Channel State Information (CSI) Features Collection in Wi-Fi&lt;/p&gt;&lt;lb/&gt;Detailed analysis of CSI feature collection and processing in Wi-Fi environments, with methods for extraction and analysis suitable for mathematical processing.&lt;lb/&gt;ğŸ“„ Read thesis&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Indoor Motion Detection Using Wi-Fi Channel State Information (2018)&lt;/p&gt;&lt;lb/&gt;Scientific article describing indoor movement detection using CSI with approaches based on signal mathematics and physics, minimizing the use of machine learning models.&lt;lb/&gt;ğŸ“„ Read paper&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;WiFi Motion Detection: A Study into Efficacy and Performance (2019)&lt;/p&gt;&lt;lb/&gt;Study using CSI data collected from standard devices to detect movements, with analysis of signal processing methods to extract movement events without relying on ML.&lt;lb/&gt;ğŸ“„ Read paper&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;CSI-HC: A WiFi-Based Indoor Complex Human Motion Recognition Using Channel State Information (2020)&lt;/p&gt;&lt;lb/&gt;Recognition of complex indoor movements through CSI with methods based on mathematical signal features, ideal for projects with signal-based analysis without advanced ML.&lt;lb/&gt;ğŸ“„ Read paper&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Location Intelligence System for People Estimation in Indoor Environment During Emergency Operation (2022)&lt;/p&gt;&lt;lb/&gt;Demonstrates the use of ESP32 with wavelet filtering (Daubechies db4) for people detection in emergency scenarios. This paper directly influenced ESPectre's wavelet filter implementation, showing that wavelet denoising outperforms traditional filters on ESP32 hardware.&lt;lb/&gt;ğŸ“„ Read paper&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These references demonstrate that effective Wi-Fi sensing can be achieved through mathematical and statistical approaches, which is the foundation of ESPectre's design philosophy.&lt;/p&gt;
    &lt;p&gt;For a detailed history of changes, new features, and improvements, see the CHANGELOG.md.&lt;/p&gt;
    &lt;p&gt;This project is released under the GNU General Public License v3.0 (GPLv3).&lt;/p&gt;
    &lt;p&gt;GPLv3 ensures that:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;âœ… The software remains free and open source&lt;/item&gt;
      &lt;item&gt;âœ… Anyone can use, study, modify, and distribute it&lt;/item&gt;
      &lt;item&gt;âœ… Modifications must be shared under the same license&lt;/item&gt;
      &lt;item&gt;âœ… Protects end-user rights and software freedom&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See LICENSE for the full license text.&lt;/p&gt;
    &lt;p&gt;Francesco Pace&lt;lb/&gt; ğŸ“§ Email: francesco.pace@gmail.com&lt;lb/&gt; ğŸ’¼ LinkedIn: linkedin.com/in/francescopace&lt;lb/&gt; ğŸ›œ Project: ESPectre&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45953977</guid><pubDate>Mon, 17 Nov 2025 14:40:54 +0000</pubDate></item><item><title>Aldous Huxley predicts Adderall and champions alternative therapies</title><link>https://angadh.com/inkhaven-7</link><description>&lt;doc fingerprint="d71d2a7e38330707"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Aldous Huxley Predicts Adderall and Champions Alternative Therapies&lt;/head&gt;
    &lt;p&gt;If delivered today, the last of Huxleyâ€™s 7-part lecture series at MIT would probably be categorised under motivational talks or self-help strategies. It surveys the various under-explored non-pharmacological means to realise the best versions of ourselves. Or, as he calls it, actualising our desirable potentialities.&lt;/p&gt;
    &lt;p&gt;Some fairly well known means for self-actualisation that Huxley discusses are Alexander technique and Gestalt therapy. While the former is considered a pseudoscientific therapyI am not using this as a pejorative, for a change., Huxley tells us of the influential educator John Deweyâ€™s admiration of F.M. Alexanderâ€™s work. He paraphrases Deweyâ€™s foreword in one of Alexanderâ€™s books:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Alexanderâ€™s technique is to education what education is to life, in general. It proposes an ideal and provides means whereby that ideal can be realised.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;While this is mentioned much later in his lecture, a Huxley-like figure today might need to lead their lecture with this part to convey the import and validity of such approaches. Huxley doesnâ€™t really go into the details of why or how this is true but admittedly admires Alexanderâ€™s contribution. I have a friend who swears by it for enhancing their dance practice though I have not been able to grok what it does so farâ€”it sounds a lot like what meditation does in terms of raising awareness.&lt;/p&gt;
    &lt;p&gt;Huxley believes that such practices are effective at psychologically breeding in desirable qualities in a person instead of: genetically breeding out undesirable ones; or pharmacologically enhancing our intellectual abilitiesâ€”i.e., improved attention spans or reduced sleepâ€”to increase our mental efficiency. Here, Huxley predicts the emergence of Adderall though I was less impressed by his forecasting euphoric pharmaceuticals. After all, this lecture was delivered several years after the publication of The Doors of Perception.&lt;/p&gt;
    &lt;p&gt;The underlying efficiency gains from these psychological approaches happen, he claims, because they train humans into being fundamentally happier; something he felt pharma-euphorics might also achieve one day. The reason such therapies are effective is that they do not provide a homogeneous training; instead, they can be adapted to individual personalities and their intrinsic differences, allowing each individual to actualise their latent potentialities via different means. This recognition that there is no single ideal version of a human is quite old; Huxley finds the most realistic (or complete) ideals in the Bhagavad Gitaâ€™s Three Yogas. The ways of devotion (Bhakti), selfless action (Karma), and contemplation (Jnana) can all lead to enlightenment, i.e., the actualisation of desirable qualities. He sees a correspondence between these yogas and the more recent Western categorisation of human beings by William Sheldonâ€™s somatotypesâ€”quite a problematic take when I read the traits listed in this table. While I do admire his capacity to form connections through historyWhether I see them or not is less important., I donâ€™t see the relationship between these two beyond the fact that these are categories. Theyâ€™re by no means comparable so maybe I missed the point of this comparison.&lt;/p&gt;
    &lt;p&gt;He highlights parallels between the positive outcomes of training oneâ€™s imagination via Gestalt therapy and those seen in Richard DeMilleâ€™s strategies in Childrenâ€™s Imagination Games: children get more fun out of life by, for example, visualising adversarial or intimidating situations with adults in a more playful manner so that things feel less serious than they need to beThat is how I understood this section.. The examples Huxley gives here reminded me of those given to nervous interviewees and public speakers, like â€œImagine your audience is nakedâ€, to take the edge off.&lt;/p&gt;
    &lt;p&gt;As an educator I am very sympathetic to Huxleyâ€™s grand idea in this lecture that we must develop new methods of education that adapt to personality variations; the current strategy of pigeonholing students into the identical training-and-testing modalities remains inappropriate, especially as technological advancementsâ€”which academia struggles to keep up withâ€”could enable more personalised and expressive learning. He doesnâ€™t imagine one-to-one therapy as the scalable solution to actualisation; instead, he suggests building upon the pre-existing categories of humans into three or more groups to test out other means and potentially develop new ones based on past practices.&lt;/p&gt;
    &lt;p&gt;While I think the whole lecture is delivered eloquently, I am unsure if it has more of a thesis than that; itâ€™s more a survey of techniques that rely on anecdotal evidence or name-dropping to convey their effectiveness.&lt;/p&gt;
    &lt;p&gt;Tomorrowâ€™s post will unpack how he sees the role of the humanities in helping us actualise our desirable potentialities, which Huxley discussed in his lecture. It will also include my own concluding thoughts on his lecture. Maybe I will have some semblance of a thesis from it as I contemplate his words overnight.&lt;/p&gt;
    &lt;p&gt;Thanks to taylor.town for linking to a transcript of Huxleyâ€™s speech on Hacker News!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45954140</guid><pubDate>Mon, 17 Nov 2025 14:57:33 +0000</pubDate></item><item><title>WeatherNext 2: Our most advanced weather forecasting model</title><link>https://blog.google/technology/google-deepmind/weathernext-2/</link><description>&lt;doc fingerprint="3ff8f453711c2ba8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;WeatherNext 2: Our most advanced weather forecasting model&lt;/head&gt;
    &lt;p&gt;The weather affects important decisions we make everyday â€” from global supply chains and flight paths to your daily commute. In recent years, artificial intelligence (AI) has dramatically enhanced whatâ€™s possible in weather forecasting and the ways in which we can use it.&lt;/p&gt;
    &lt;p&gt;Today, Google DeepMind and Google Research are introducing WeatherNext 2, our most advanced and efficient forecasting model. WeatherNext 2 can generate forecasts 8x faster and with resolution up to 1-hour. This breakthrough is enabled by a new model that can provide hundreds of possible scenarios. Using this technology, weâ€™ve supported weather agencies in making decisions based on a range of scenarios through our experimental cyclone predictions.&lt;/p&gt;
    &lt;p&gt;We're now taking our research out of the lab and putting it into the hands of users. WeatherNext 2's forecast data is now available in Earth Engine and BigQuery. Weâ€™re also launching an early access program on Google Cloudâ€™s Vertex AI platform for custom model inference.&lt;/p&gt;
    &lt;p&gt;By incorporating WeatherNext technology, weâ€™ve now upgraded weather forecasts in Search, Gemini, Pixel Weather and Google Maps Platformâ€™s Weather API. In the coming weeks, it will also help power weather information in Google Maps.&lt;/p&gt;
    &lt;head rend="h2"&gt;Predicting more possible scenarios&lt;/head&gt;
    &lt;p&gt;From a single input, we use independently trained neural networks and inject noise in function space to create coherent variability in weather forecast predictions.&lt;/p&gt;
    &lt;p&gt;Weather predictions need to capture the full range of possibilities â€” including worst case scenarios, which are the most important to plan for.&lt;/p&gt;
    &lt;p&gt;WeatherNext 2 can predict hundreds of possible weather outcomes from a single starting point. Each prediction takes less than a minute on a single TPU; it would take hours on a supercomputer using physics-based models.&lt;/p&gt;
    &lt;p&gt;Our model is also highly skillful and capable of higher-resolution predictions, down to the hour. Overall, WeatherNext 2 surpasses our previous state-of-the-art WeatherNext model on 99.9% of variables (e.g. temperature, wind, humidity) and lead times (0-15 days), enabling more useful and accurate forecasts.&lt;/p&gt;
    &lt;p&gt;This improved performance is enabled by a new AI modelling approach called a Functional Generative Network (FGN), which injects â€˜noiseâ€™ directly into the model architecture so the forecasts it generates remain physically realistic and interconnected.&lt;/p&gt;
    &lt;p&gt;This approach is particularly useful for predicting what meteorologists refer to as â€œmarginalsâ€ and â€œjoints.â€ Marginals are individual, standalone weather elements: the precise temperature at a specific location, the wind speed at a certain altitude or the humidity. What's novel about our approach is that the model is only trained on these marginals. Yet, from that training, it learns to skillfully forecast 'joints' â€” large, complex, interconnected systems that depend on how all those individual pieces fit together. This 'joint' forecasting is required for our most useful predictions, such as identifying entire regions affected by high heat, or expected power output across a wind farm.&lt;/p&gt;
    &lt;p&gt;Continuous Ranked Probability Score (CRPS) comparing WeatherNext 2 to WeatherNext Gen&lt;/p&gt;
    &lt;head rend="h2"&gt;From research to reality&lt;/head&gt;
    &lt;p&gt;With WeatherNext 2, we're translating cutting edge research into high-impact applications. Weâ€™re committed to advancing the state of the art of this technology and making our latest tools available to the global community.&lt;/p&gt;
    &lt;p&gt;Looking ahead, weâ€™re actively researching capabilities to improve our models, including integrating new data sources, and expanding access even further. By providing powerful tools and open data, we hope to accelerate scientific discovery and empower a global ecosystem of researchers, developers and businesses to make decisions on todayâ€™s most complex problems and build for the future.&lt;/p&gt;
    &lt;p&gt;To learn more about geospatial platforms and AI work at Google, check out Google Earth, Earth Engine, AlphaEarth Foundations, and Earth AI.&lt;/p&gt;
    &lt;head rend="h2"&gt;Learn more about WeatherNext 2&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Read our paper&lt;/item&gt;
      &lt;item&gt;WeatherNext developer documentation&lt;/item&gt;
      &lt;item&gt;Explore the Earth Engine Data Catalog&lt;/item&gt;
      &lt;item&gt;Query forecast data in BigQuery&lt;/item&gt;
      &lt;item&gt;Sign up to the early access program for Cloud Vertex AI&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45954210</guid><pubDate>Mon, 17 Nov 2025 15:04:26 +0000</pubDate></item><item><title>Project Gemini</title><link>https://geminiprotocol.net/</link><description>&lt;doc fingerprint="7b91a15fbb3f9295"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Project Gemini&lt;/head&gt;
    &lt;head rend="h2"&gt;Gemini in 100 words&lt;/head&gt;
    &lt;p&gt;Gemini is a new internet technology supporting an electronic library of interconnected text documents. That's not a new idea, but it's not old fashioned either. It's timeless, and deserves tools which treat it as a first class concept, not a vestigial corner case. Gemini isn't about innovation or disruption, it's about providing some respite for those who feel the internet has been disrupted enough already. We're not out to change the world or destroy other technologies. We are out to build a lightweight online space where documents are just documents, in the interests of every reader's privacy, attention and bandwidth. &lt;/p&gt;
    &lt;p&gt; If you'd like to know more, read our FAQ&lt;/p&gt;
    &lt;p&gt; Or, if you'd prefer, here's a video overview &lt;/p&gt;
    &lt;head rend="h2"&gt;Official resources&lt;/head&gt;
    &lt;p&gt; Project Gemini news&lt;/p&gt;
    &lt;p&gt; Project Gemini documentation&lt;/p&gt;
    &lt;p&gt; Project Gemini history&lt;/p&gt;
    &lt;p&gt; Known Gemini software &lt;/p&gt;
    &lt;p&gt;All content at geminiprotocol.net is CC BY-NC-ND 4.0 licensed unless stated otherwise:&lt;/p&gt;
    &lt;p&gt; CC Attribution-NonCommercial-NoDerivs 4.0 International &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45954640</guid><pubDate>Mon, 17 Nov 2025 15:50:04 +0000</pubDate></item><item><title>How when AWS was down, we were not</title><link>https://authress.io/knowledge-base/articles/2025/11/01/how-we-prevent-aws-downtime-impacts</link><description>&lt;doc fingerprint="765090565d2694dd"&gt;
  &lt;main&gt;
    &lt;p&gt;For help understanding this article or how you can implement auth and similar security architectures in your services, feel free to reach out to me via the community server.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ã°Â¨ AWS us-east-1 is down!Ã¢&lt;/head&gt;
    &lt;p&gt;One of the most massive AWS incidents transpired on October 20th. The long story short is that the DNS for DynamoDB was impacted for &lt;code&gt;us-east-1&lt;/code&gt;, which created a health event for the entire region. It's the worst incident we've seen in a decade. Disney+, Lyft, McDonald'ss, New York Times, Reddit, and the list goes on were lining up to claim their share too of the spotlight. And we've been watching because our product is part of our customers critical infrastructure. This one graph of the event says it all:&lt;/p&gt;
    &lt;p&gt;The AWS post-incident report indicates that at 7:48 PM UTC DynamoDB had "increased error rates". But this article isn't about AWS, and instead I want to share how exactly we were still up when when AWS was down.&lt;/p&gt;
    &lt;p&gt;Now you might be thinking: why are you running infra in us-east-1?&lt;/p&gt;
    &lt;p&gt;And it's true, almost no one should be using us-east-1, unless, well, of course, you are us. And that's because we end up running our infrastructure where our customers are. In theory, practice and theory are the same, but in practice they differ. And if our (or your) customers chose &lt;code&gt;us-east-1&lt;/code&gt; in AWS, then realistically, that means you are also choosing us-east-1 Ã°Â….&lt;/p&gt;
    &lt;p&gt;During this time, us-east-1 was offline, and while we only run a limited amount of infrastructure in the region, we have to run it there because we have customers who want it there. And even without a direct dependency on &lt;code&gt;us-east-1&lt;/code&gt;, there are critical services in AWS Ã¢ CloudFront, Certificate Manager, Lambda@Edge, and IAM Ã¢ that all have their control planes in that region. Attempting to create distributions or roles at that time were also met with significant issues.&lt;/p&gt;
    &lt;p&gt;Since there are plenty of articles in the wild talking about what actually happened, why it happened, and why it will continue to happen, I don't need to go into it here. Instead, I'm going to share a dive about exactly what we've built to avoid these exact issues, and what you can do for your applications and platforms as well. In this article, I'll review how we maintain a high SLI to match our SLA reliability commitment even when the infrastructure and services we use don't.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ã° What is reliability?Ã¢&lt;/head&gt;
    &lt;p&gt;Before I get to the part where I share how we built one of the most reliable auth solutions available. I want to define reliability. And for us, that's an SLA of five nines. I think that's so extraordinary that the question I want you to keep in mind through this article is: is that actually possible? Is it really achievable to have a service with a five nines SLA? When I say five nines, I mean that 99.999% of the time, our service is up and running as expected by our customers. And to put this into perspective, the red, in the sea of blue, represents just how much time we can be down.&lt;/p&gt;
    &lt;p&gt;And if you can't see it, it's hiding inside this black dot. It amounts to just five minutes and 15 seconds per year. This pretty much means we have to be up all the time, providing responses and functionality exactly as our customers expect.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ã°Â¤ But why?Ã¢&lt;/head&gt;
    &lt;p&gt;To put it into perspective, it's important to share for a moment, the specific challenges that we face, why we built what we built, and of course why that's relevant. To do that, I need to include some details about what we're building Ã¢ what Authress actually does. Authress provides login and access control for the software applications that you write Ã¢ It generates JWTs for your applications. This means:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;User authentication and authorization&lt;/item&gt;
      &lt;item&gt;User identities&lt;/item&gt;
      &lt;item&gt;Granular role and resource-based authorization (ReBAC, ABAC, TBAC, RBAC, etc...)&lt;/item&gt;
      &lt;item&gt;API keys for your technical customers to interact with your own APIs&lt;/item&gt;
      &lt;item&gt;Machine to machine authentication, or services Ã¢ if you have a microservice architecture.&lt;/item&gt;
      &lt;item&gt;Audit trails to track the permission changes within your services or expose this to your customers.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And there are of course many more components, that help complete full auth-platform, but they aren't totally relevant to this article, so I'm going to skip over them.&lt;/p&gt;
    &lt;p&gt;With that, you may already start to be able to see why uptime is so critical for us. We're on the critical path for our customers. It's not inherently true for every single platform, but it is for us. So if our solution is down, then our customer applications are down as well.&lt;/p&gt;
    &lt;p&gt;If we put the reliability part in the back corner for one second and just think about the features, we can theorize about a potential initial architecture. That is, an architecture that just focuses on the features, how might you build this out as simple as possible? I want to do this, so I can help explain all the issues that we would face with the simple solution.&lt;/p&gt;
    &lt;p&gt;Maybe you've got a single region, and in that region you have some sort of HTTP router that handles requests and they forward to some compute, serverless, container, or virtual machine, or, and I'm very sorry for the scenario Ã¢ if you have to use bare metal. Lastly, you're interacting with some database, NoSQL, SQL, or something else, file storage, and maybe there's some async components.&lt;/p&gt;
    &lt;p&gt;If you take a look at this, it's probably obvious to you (and everyone else) that there is no way it is going to meet our reliability needs. But we have to ask, just exactly how often will there actually be a problem with this architecture? Just building out complexity doesn't directly increase reliability, we need to focus on why this architecture would fail. For us, we use AWS, so I look to the Amazon CTO for guidance, and he's famously quoted as saying, Everything fails all the time.&lt;/p&gt;
    &lt;p&gt;And AWS's own services are no exception to this. Over the last decade, we've seen numerous incidents:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2014 - Ireland (Partial) - Hardware - Transformer failed - EC2, EBS, and RDS&lt;/item&gt;
      &lt;item&gt;2016 - Sydney (Partial) - Severe Weather - Power Loss - All Services&lt;/item&gt;
      &lt;item&gt;2017 - All Regions - Human error - S3 critical servers deleted - S3&lt;/item&gt;
      &lt;item&gt;2018 - Seoul Region - Human error - DNS resolvers impacted - EC2&lt;/item&gt;
      &lt;item&gt;2021 - Virginia - Traffic Scaling - Network Control Plane outage - All Services&lt;/item&gt;
      &lt;item&gt;2021 - California - Traffic Scaling - Network Control Plane outage - All Services&lt;/item&gt;
      &lt;item&gt;2021 - Frankfurt (Partial) - Fire - Fire Suppression System issues - All Services&lt;/item&gt;
      &lt;item&gt;2023 - Virginia - Kinesis issues - Scheduling Lambda Invocations impact - Lambda&lt;/item&gt;
      &lt;item&gt;2023 - Virginia - Networking issues - Operational issue - Lambda, Fargate, API GatewayÃ¢Â¦&lt;/item&gt;
      &lt;item&gt;2023 - Oregon (Partial) - Error rates - Dynamodb + 48 services&lt;/item&gt;
      &lt;item&gt;2024 - Singapore (Partial) - EC2 Autoscaling - EC2&lt;/item&gt;
      &lt;item&gt;2024 - Virginia (Partial) - Describe API Failures ECS - ECS + 4 services&lt;/item&gt;
      &lt;item&gt;2024 - Brazil - ISP issues - CloudFront connectivity - CloudFront&lt;/item&gt;
      &lt;item&gt;2024 - Global - Network connectivity - STS Service&lt;/item&gt;
      &lt;item&gt;2024 - Virginia - Message size overflow - Kinesis down - Lambda, S3, ECS, CloudWatch, Redshift&lt;/item&gt;
      &lt;item&gt;2025 - Virginia - Dynamo DB DNS - DynamoDB down - All Services&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And any one of these would have caused major problems for us and therefore our customers. And the frequency of incident is actually increasing in time. This shouldn't be a surprise, right? Cloud adoption is increasing over time. The number of services AWS is offering is also increasing. But how impactful are these events? Would single one of them have been a problem for us to actually reach our SLA promise? What would happen if we just trusted AWS and used that to pass through our commitments? Would it be sufficient to achieve 99.999% SLA uptime? Well, let's take a look.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ã°Â°Ã¯Â¸ AWS SLA CommitmentsÃ¢&lt;/head&gt;
    &lt;head rend="h4"&gt;The AWS Lambda SLA is below 5 ninesÃ¢&lt;/head&gt;
    &lt;head rend="h4"&gt;The API Gateway SLA is below 5 ninesÃ¢&lt;/head&gt;
    &lt;head rend="h4"&gt;The AWS SQS SLA is below 5 ninesÃ¢&lt;/head&gt;
    &lt;p&gt;Okay, so when it comes to trusting AWS SLAs, it isn't sufficient. At. All.&lt;/p&gt;
    &lt;p&gt;We can't just use the components that are offered by AWS, and go from there. We fundamentally need to do something more than that. So the question becomes, what exactly must a dependency's reliability be in order for us to utilize it? To answer that question, it's time for a math lesson. Or more specifically, everyone's favorite topic, probabilities.&lt;/p&gt;
    &lt;p&gt;Let's quickly get through this &lt;del&gt;torture&lt;/del&gt; exercise. Fundamentally, you have endpoints in your service, and you get in an HTTP request, and it interacts with some third-party component or API, and then you write the result to a database. For us, this could be an integration such as logging in with Google or with Okta for our customers' enterprise customers.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ã°Â» Calculating the allowed failure rateÃ¢&lt;/head&gt;
    &lt;p&gt;So if we want to meet a 5-nines reliability promise, how unreliable could this third-party component actually be? What happens if this component out of the box is only 90% reliable? We'll design a strategy for getting around that.&lt;/p&gt;
    &lt;p&gt;Uptime is a product of all of the individual probabilities:&lt;/p&gt;
    &lt;p&gt;For the sake of this example, we'll just assume that every other component in our architecture is 100% reliable Ã¢ That's every line of code, no bugs ever written in our library dependencies, or transitive library dependencies, or the dependencies' dependencies' dependencies, and everything always works exactly as we expect.&lt;/p&gt;
    &lt;p&gt;So we can actually rewrite our uptime promise as a result of the failure rate of that third-party component.&lt;/p&gt;
    &lt;p&gt;And the only way that we can actually increase the success rate of the uptime based off of failures is to retry. And so we can multiply out the third-party failure rate and retry multiple times.&lt;/p&gt;
    &lt;p&gt;Logically that makes a lot of sense. When a component fails, if you retry again, and again, the likelihood it will be down every single time approaches zero. And we can generate a really nasty equation from this to actually determine how many exact times do we need to retry.&lt;/p&gt;
    &lt;p&gt;How many exactly can it? Rather than guessing whether or not we should retry four times or five times, or put it in a &lt;code&gt;while(true)&lt;/code&gt; loop, we can figure it out exactly. So we take this equation and extend it out a little bit. Plugging in our 90% reliable third-party component:&lt;/p&gt;
    &lt;p&gt;We find that our retry count actually must be greater than or equal to five. We can see that this adds up to our uptime expectation:&lt;/p&gt;
    &lt;p&gt;Is this the end of the story? Just retry a bunch of times and you're good? Well, not exactly. Remember this equation?&lt;/p&gt;
    &lt;p&gt;We do really need to consider every single component that we utilize. And specifically when it comes to the third-party component, we had to execute it by utilizing a retry handler. So we need to consider the addition of the retry handler into our equation. Going back to the initial architecture, instead of what we had before, when there's a failure in that third-party component, now we will automatically execute some sort of asynchronous retries or in-process retries. And every time that third-party component fails, we execute the retry handler and retry again.&lt;/p&gt;
    &lt;p&gt;This means we need to consider the reliability of that retry handler.&lt;/p&gt;
    &lt;p&gt;Let's assume we have a really reliable retry handler and that it's even more reliable than our service. I think that's reasonable, and actually required. A retry handler that is less reliable than our stated SLA by default is just as faulty as the third-party component.&lt;/p&gt;
    &lt;p&gt;Let's consider one with five and a half nines Ã¢ that's half a nine more reliable than our own SLA.&lt;/p&gt;
    &lt;p&gt;But how reliable does it really need to be? Well, we can pull in our original equation and realize that our total uptime is the unreliability or the reliability of the third-party component multiplied by the reliability of our retry handler.&lt;/p&gt;
    &lt;p&gt;From here, we add in the retries to figure out what the result should be:&lt;/p&gt;
    &lt;p&gt;We have a reliable retry handler, but it's not perfect. And with a retry handler that has reliability of five and a half nines, we can retry a maximum two times. Because remember, it has to be reliable every single time we utilize it, as it is a component which can also fail. Which means left with this equation:&lt;/p&gt;
    &lt;p&gt;I don't think comes as a surprise to anyone that in fact five is greater than two. What is the implication here?&lt;/p&gt;
    &lt;p&gt;The number of retries required for that unreliable third-party component to be utilized by us exceeds the number of retries actually allowed by our retry handler.&lt;/p&gt;
    &lt;p&gt;That's a failure, the retry handler can only retry twice before itself violates our SLA, but we need to retry five times in order to raise the third-party component reliably up. We can actually figure out what the minimum reliability of a third-party component is allowed to be, when using our retry handler:&lt;/p&gt;
    &lt;p&gt;Which in turn validates that it's actually impossible for us to utilize that component. &lt;code&gt;99.7%&lt;/code&gt;. &lt;code&gt;99.7%&lt;/code&gt; is the minimum allowed reliability for any third-party component in order for us to meet our required 5-nines SLA. This third-party component is so unreliable (&lt;code&gt;~90%&lt;/code&gt;), that even using a highly reliable retry handler, we still can't make it reliable enough without the retry handler itself compromising our SLA. We fundamentally need to consider this constraint, when we're building out our architecture. &lt;/p&gt;
    &lt;p&gt;That means we drop this third-party component. Done.&lt;/p&gt;
    &lt;p&gt;And then, let's assume we get rid of every flaky component, everything that don't have a high enough reliability for us. At this point, it's good to think, is this sufficient to achieve our 5-nines SLA? Well, it isn't just third-party components we have to be concerned about. We also have to be worried about those AWs infrastructure failures.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ã°Â©Ã¯Â¸ Infrastructure FailuresÃ¢&lt;/head&gt;
    &lt;p&gt;So let's flashback to our initial architecture again:&lt;/p&gt;
    &lt;p&gt;We can have issues at the database layer, right? There could be any number of problems here. Maybe it's returning 500s, there are some slow queries, maybe things are timing out. Or there could be a problem with our compute. Maybe it's not scaling up fast enough. We're not getting new infrastructure resources. Sometimes, even AWS is out of bare metal machines when you don't reserve them, request them get them on demand, and the list go on.&lt;/p&gt;
    &lt;p&gt;Additionally, there could also be some sort of network issue, where requests aren't making it through to us or even throw a DNS resolution error on a request from our users.&lt;/p&gt;
    &lt;p&gt;In many of these cases, I think the answer is obvious. We just have to declare the whole region as down. And you are probably thinking, well, this is where we failover to somewhere else. No surprise, yeah, this is exactly what we do:&lt;/p&gt;
    &lt;p&gt;However, this means we have to have all the data and all the infrastructure components duplicated to another region in order to do this. And since Authress has six primary regions around the world, that also means we need multiple backup regions to be able to support the strategy. But this comes with significant wasted resources and wasted compute that we're not even getting to use. Costly! But I'll get to that later.&lt;/p&gt;
    &lt;p&gt;Knowing a redundant architecture is required is a great first step, but that leaves us having to solve for: how do we actually make the failover happen in practice?&lt;/p&gt;
    &lt;head rend="h2"&gt;Ã°Â§ The Failover Routing StrategyÃ¢&lt;/head&gt;
    &lt;p&gt;Simply put Ã¢ our strategy is to utilize DNS dynamic routing. This means requests come into our DNS and it automatically selects between one of two target regions, the primary region that we're utilizing or the failover region in case there's an issue. The critical component of the infrastructure is to switch regions during an incident:&lt;/p&gt;
    &lt;p&gt;In our case, when using AWS, this means using the Route 53 health checks and the Route 53 failover routing policy.&lt;/p&gt;
    &lt;p&gt;We know how we're gonna do it, but the long pole in the tent is actually knowing that there is even a problem in the first place. A partial answer is to say Have a health check, so of course there is health check here. But the full answer is: have a health check that validates both of the regions, checking if the region is up, or is there an incident? And if it is, reports the results to the DNS router.&lt;/p&gt;
    &lt;p&gt;We could be utilizing the default provided handler from AWS Route 53 or a third-party component which pings our website, but that's not accurate enough from a standpoint of correctly and knowing for certain that our services are in fact down.&lt;/p&gt;
    &lt;p&gt;It would be devastating for us to fail over when a secondary region is having worse problems than our primary region. Or what if there's an issue with with network traffic. We wouldn't know if that's an issue of communication between AWS's infrastructure services, or an issue with the default Route 53 health check endpoint, or some entangled problem with how those specifically interact with our code that we're actually utilizing. So it became a requirement to built something ourselves, custom, to actually execute exactly what we need to check.&lt;/p&gt;
    &lt;p&gt;Here is a representation of what we're doing. It's not exactly what we are doing, but it's close enough to be useful. Health check request come in from the Route 53 Health Check. They call into our APIGW or Load Balancer as a router. The requests are passed to our compute which can interact and validate logic, code, access, and data in the database:&lt;/p&gt;
    &lt;p&gt;The health check executes this code on request that allows us to validate if the region is in fact healthy:&lt;/p&gt;
    &lt;code&gt;import Authorizer from './authorizer.js';&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;We start a profiler to know how long our requests are taking.&lt;/item&gt;
      &lt;item&gt;Then we interact with our databases, as well as validate some secondary components, such as SQS. While issues with secondary components may not always be a reason to failover, they can cause impacts to response time, and those indicators can be used to predict incoming incidents.&lt;/item&gt;
      &lt;item&gt;From there, we check whether or not the most critical business logic is working correctly. In our case, that's interactions with DynamoDB as well as core authorizer logic. Compared to a simple unit test, this accounts for corruption in a deployment package, as well instances where some subtle differences between regions interact with our code base. We can catch those sorts of problems here, and know that the primary region that we're utilizing, one of the six, is having a problem and automatically update the DNS based on this.&lt;/item&gt;
      &lt;item&gt;When we're done, we return success or failure so the health check can track changes.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Ã°Â¿ Improving the Failover StrategyÃ¢&lt;/head&gt;
    &lt;p&gt;And we don't stop here with our infrastructure failover however. With the current strategy, it's good, in some cases, even sufficient. But it isn't that great. For starters, we have to completely failover. If there's just one component that's problematic, we can't just swap that one out easily, it's all or nothing with the Route 53 health check. So when possible, we push for an edge-optimized architecture. In AWS, this means utilizing AWS CloudFront with AWS Lambda@Edge for compute. This not only helps reduce latency for our customers and their end users depending where they are around the world, as a secondary benefit, fundamentally, it is an improved failover strategy.&lt;/p&gt;
    &lt;p&gt;And that looks like this:&lt;/p&gt;
    &lt;p&gt;Using CloudFront gives us a highly reliable CDN, which routes requests to the locally available compute region. From there, we can interact with the local database. When our database in that region experiences a health incident, we automatically failover, and check the database in a second adjacent region. And when there's a problem there as well, we do it again to a third region. We can do that because when utilizing DynamoDB we have Global Tables configured for authorization configuration. In places where we don't need the data duplicated, we just interact with the table in a different region without replication.&lt;/p&gt;
    &lt;p&gt;After a third region with an issue, we stop.&lt;/p&gt;
    &lt;p&gt;And maybe you're asking why three and not four or five or six? Aren't you glad we did the probabilities exercise earlier? Now you can actually figure out why it's three here. But, I'll leave that math as an exercise for you.&lt;/p&gt;
    &lt;p&gt;As a quick recap, this handles the problems with at the infrastructure level and with third-party components. And if we solve those, is that sufficient for us to achieve our goal the 5-nines SLA?&lt;/p&gt;
    &lt;p&gt;For us the answer is No, and you might have guessed, if you peaked at the scrollbar or table contents that there are still quite some additional components integrated into our solution. One of them is knowing that at some point, there's going to be a bug in our code, unfortunately.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ã°Â» Application level failuresÃ¢&lt;/head&gt;
    &lt;p&gt;And that bug will get committed to production, which means we're going to end up with an application failure. It should be obvious that it isn't achievable to write completely bug-free code. Maybe there is someone out there that thinks that, and maybe even that's you, and I believe you that you believe that. However, I know it's not me, and realistically, I don't want to sit around and pray that it's also my fellow team members. The risk is too high, because in the case something does get into production, that means it can impact some of our customers. So instead, let's assume that will happen and design a strategy around it.&lt;/p&gt;
    &lt;p&gt;So when it does happen, we of course have to trigger our incident response. For us, we send out an email, we post a message on our community and internal communication workspaces, and start an on-call alert. The technology here isn't so relevant, but tools like AWS SES, SQS, SNS, Discord, and emails are involved.&lt;/p&gt;
    &lt;p&gt;Incidents wake an engineer up, so someone can start to take look at the incident, and most likely the code.&lt;/p&gt;
    &lt;p&gt;But by the time they even respond to the alert, let alone actually investigate and fix the cause of the incident, we would long violated our SLA. So an alert is not sufficient for us. We need to also implement automation to automatically remediate any of these problems. Now, I'm sure you're thinking, yeah, okay, test automation. You might even be thinking about an LLM agent that can automatically create PRs. (Side note: LLM code generation, doesn't actually work for us, and I'll get to that a little further down) Instead, we have to rely on having sufficient testing in place. And yes, of course we do. We test before deployment. There is no better time to test.&lt;/p&gt;
    &lt;p&gt;This seems simple and an obvious answer, and I hope that for anyone reading this article it is. Untested code never goes to production. Every line of code is completely tested before it is merged to production, even if it is enabled on some flag. Untested code is never released, it is far too dangerous. Untested code never makes it to production behind some magic flag. Abusing feature flags to make that happen could not be a worse decision for us. And that's because we can need to be as confident as possible before those changes actually get out in front of our customers. The result is Ã¢ we don't focus on test coverage percentage, but rather test value. That is, which areas provide most value, that are most risky, that we care about being the most reliable for our customers. Those are the ones we focus on testing.&lt;/p&gt;
    &lt;head rend="h3"&gt;Root Cause Analysis (RCA)Ã¢&lt;/head&gt;
    &lt;p&gt;Every incident could have been prevented if we just had one more test. The trick though is actually having that right test, before the incident.&lt;/p&gt;
    &lt;p&gt;And in reality, that's not actually possible. Having every right test for a service that is constantly changing, while new features are being added, is just unmaintainable. Every additional test we write increases the maintenance burden of our service. Attempting to achieve 100% complete test coverage would require an infinite amount of time. This is known as the Pareto Principle, more commonly the 80-20 rule. If it takes 20% of the time to deliver 80% of the tests, it takes an infinite amount of time to achieve all the tests, and that assumes that the source code isn't changing.&lt;/p&gt;
    &lt;p&gt;The result is we'll never be able to catch everything. So we can't just optimize for prevention. We also need to optimize for recovery. This conclusion for us means also implementing tests against our deployed production code. One example of this are validation tests.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ã° Validation TestsÃ¢&lt;/head&gt;
    &lt;p&gt;A validation test is where you have some data in one format and data in another format and you use those two different formats to ensure referential consistency. (Side note: There are many different kinds of tests, and I do a deep dive in the different types of tests and how they're relevant in building secure and reliable systems). One concrete example could be you have a request that comes in, you end up logging the request data and the response, then you can compare that logged data to what's actually saved in your database.&lt;/p&gt;
    &lt;p&gt;In our scenario, which focuses on the authorization and permissions enforcement checks, we have multiple databases with similar data. In one case, there's the storage of permissions as well as the storage of the expected checks and the audit trail tracking the creation of those permissions. So we actually have multiple opportunities to compare the data between our databases asynchronously outside of customer critical path usage.&lt;/p&gt;
    &lt;head rend="h3"&gt;Running the ValidationÃ¢&lt;/head&gt;
    &lt;p&gt;On a schedule, via an AWS CloudWatch Scheduled Rule, we load the data from our different databases and we compare them against each other to make sure it is consistent. If there is a problem, then if this fires off an incident before any of our customers notice, so that we can actually go in and check what's going on.&lt;/p&gt;
    &lt;p&gt;This sounds bad on the surface that it could ever happen. But the reality of the situation is that a discrepancy can show up as a result of any number of mechanisms. For instance, the infrastructure from AWS could have corrupted one of the database shards and what is written to the databases is inconsistent. We know that this can happen as there is no 100% guarantee on database durability, even from AWS. AWS does not guarantee Database Durability, are you assuming they do, because we don't! So actually reading the data back and verifying its internal consistency is something that we must do.&lt;/p&gt;
    &lt;p&gt;While it might not seem that this could reduce the probability of there being an incident. Consider that a requested user permission check whose result doesn't match our customer's expectation is an incident. It might not always be one that anyone identifies or even becomes aware of, but it nonetheless a problem, just like a publicly exposed S3 is technically an issue, even if no one has exfiltrated the data yet, it doesn't mean the bucket isn'is sufficiently secured.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ã°Â¯ Incident ImpactÃ¢&lt;/head&gt;
    &lt;p&gt;There are two parts to the actual risk of an incident. The probability and the impact. Everything in this article I've discuss until now talks about reducing the probability of an incident, that is Ã¢ the likelihood of it happening. But since we know that we can't avoid ever having an incident, we also have to reduce the impact when it happens.&lt;/p&gt;
    &lt;p&gt;One way we do that is by utilizing an incremental rollout. Hopefully everyone knows what incremental rollout is, so I'll instead jump straight into how we accomplish it utilizing AWS. And for that we focus again on our solution integrating with CloudFront and our edge architecture.&lt;/p&gt;
    &lt;p&gt;The solution for us is what I call Customer Deployment Buckets. We bucket individual customers into separate buckets and then deploy to each of the buckets sequentially. If the deployment rolls out without a problem, and it's all green, that is everything works correctly, then we go on to the second bucket and then deploy our code to there, and then the third bucket, and so on and so forth until every single customer has the new version.&lt;/p&gt;
    &lt;p&gt;If there is an issue, we stop the rollout and we go and investigate what's actually going on. While we can't prevent the issue from happening to the earlier buckets, we are able to stop that issue from propagating to more customers, having an impact on everyone, and thus reduce the impact of the incident.&lt;/p&gt;
    &lt;p&gt;As I mentioned before the biggest recurring issue isn't executing an operations process during an incident, it's identifying there is a real incident in the first place. So, How do we actually know that there's an issue?&lt;/p&gt;
    &lt;p&gt;If it was an easy problem to solve, you would have written a unit task or integration test or service level test and thus already discovered it, right? So adding tests can't, by design, help us. Maybe there's an issue with the deployment itself or during infrastructure creation, but likely that's not what's happening.&lt;/p&gt;
    &lt;p&gt;Now, I know you're thinking, When is he going to get to AI?&lt;/p&gt;
    &lt;p&gt;Whether or not we'll ever truly have AI is a separate &lt;code&gt;&amp;lt;rant /&amp;gt;&lt;/code&gt; that I won't get into here, so this is the only section on it, I promise. What we actually do is better called anomaly detection. Historically anomaly detection, was what AI always meant, true AI, rather than an LLM or agent in any way.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ã° AI: Anomaly DetectionÃ¢&lt;/head&gt;
    &lt;p&gt;This is a graph of our detection analysis:&lt;/p&gt;
    &lt;p&gt;You might notice that it's not tracking 400s or 500s, which are in reality relatively easy to detect. But in fact don't actually tell us meaningfully what's wrong with our service or whether or not there really is a problem. Impact is measured by business value, not technical protocol level analytics, so we need to have a business-focused metric.&lt;/p&gt;
    &lt;p&gt;And for us, at Authress, the business-focussed metric we use to identify meaningful incidents we call: The Authorization Ratio. That is the ratio of successful logins and authorizations to ones that are blocked, rejected, timeout or are never completed for some reason.&lt;/p&gt;
    &lt;p&gt;The above CloudWatch metric display contains this exact ratio, and here in this timeframe represents an instance not too long ago where we got really close to firing off our alert.&lt;/p&gt;
    &lt;p&gt;Here, there was a slight elevation of errors soon after a deployment. The expected ratio was outside of our allowance span for a short period of time. However not long enough to trigger an incident. We still investigated, but it wasn't something that required immediate remediation. And it's a good reminder that identifying problems in any production software isn't so straightforward. To achieve high reliability, we've needed an AI or in this case anomaly detection to actually identify additional problems. And realistically, even with this level of sophistication in place, we still can never know with 100% certainty that there is actually an incident at any moment. And that's because "what is an incident", is actually a philosophical question...&lt;/p&gt;
    &lt;head rend="h2"&gt;Ã°Â¹ Does it smell like an incident?Ã¢&lt;/head&gt;
    &lt;p&gt;Our anomaly detection said Ã¢ almost an incident, and we determined the result Ã¢ no incident. But does that mean there wasn't an incident? What makes an incident, how do I define an incident? And is that exact definition ubiquitous, for every system, every engineer, every customer?&lt;/p&gt;
    &lt;p&gt;Obviously not, and one look at the AWS Health Status Dashboard is all you need to determine that the identification of incidents is based on subjective perspective, rather than objective criteria. What's actually more important is the synthesis of our perspective on the situation and what our customers believe. To see what I mean, let's do a comparison:&lt;/p&gt;
    &lt;p&gt;I'm going to use Authress as an example. So I've got the product services perspective on one side and our customer's perspective on the other.&lt;/p&gt;
    &lt;head rend="h3"&gt;Incident AlignmentÃ¢&lt;/head&gt;
    &lt;p&gt;In the top left corner we have alignment. If we believe that our system is up and working and our customers do, too, then success, all good. Everything's working as expected.&lt;/p&gt;
    &lt;p&gt;Inversely in the opposite corner, maybe there is a problem. We believe that one of our services is having an issue, and successfully, we're able to identify it. Most importantly, our customers sayÃ¢yes, there is an issue for us.&lt;/p&gt;
    &lt;p&gt;It's not great that there's an incident, but as I've identified incidents will absolutely happen, and the fact we've correctly aligned with our customers on the problem's existence independently allows us to deploy automation to automatically remediate the issue. That's a success! If it's a new problem that we haven't seen before, we can even design new automation to fix this. Correctly identifying incidents is challenging, so doing that step correctly, leads itself very well to automation for remediation.&lt;/p&gt;
    &lt;head rend="h3"&gt;Perspective MismatchÃ¢&lt;/head&gt;
    &lt;p&gt;One interesting corner is when our customers believe that there's nothing wrong, there have been no incidents reported, but all our alerts are saying Ã¢ RED ALERT Ã¢ someone has to go look at this!&lt;/p&gt;
    &lt;p&gt;In this case, our alerts have identified a problem that no one cares about. This often happens in scenarios where our customers are in one region, Switzerland for example, with local region users, a health care, manufacturing, or e-commerce app, is a good example, rather than global, who are likely asleep at 2:00 AM. And that means an incident at the moment, could be an issue affecting some customers. But if they aren't around to experience it, is it actually happening?&lt;/p&gt;
    &lt;p&gt;You are probably wincing at that idea. There's a bug, it must be fixed! And sure that's a problem, it's happening and we should take note of what's going on. But we don't need to respond in real time. That's a waste of our resources where we could be investing in other things. Why wake up our engineers based on functionality that no one is using?&lt;/p&gt;
    &lt;p&gt;I think one of the most interesting categories is in the top right-hand corner where:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;our customers say, "hey, your service is down"&lt;/item&gt;
      &lt;item&gt;But we say, "Wait, really, is it?"_&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is known as a gray failure.&lt;/p&gt;
    &lt;head rend="h3"&gt;Gray FailuresÃ¢&lt;/head&gt;
    &lt;p&gt;And it can happen for any number of reasons. Maybe there is something in our knowledge base that tells our customers to do something one way and it's confusing and they've interpreted it in a different way. So there's a different expectation here. That expectation can get codified into customer processes and product services.&lt;/p&gt;
    &lt;p&gt;Or maybe our customer is running different tests from us, ones that are of course, valuable for their business, but not ones that we consider. Or more likely they are just using a less resilient cloud provider.&lt;/p&gt;
    &lt;p&gt;Most fundamentally, there could really be an incident, something that we haven't detected yet, but they have. And if we don't respond to that, it could grow, and left unchecked, escalate, and eventually impact all our customers. This means we need to give our customers an easy way to report incidents to us, which we can immediately follow up with.&lt;/p&gt;
    &lt;p&gt;For us, every single incident, every single customer support ticket that comes into our platform, we immediately and directly send it to our engineering team. Now, I often get pushback on this from other leaders. I'm sure, even you might be thinking something like Ã¢ I don't want to be on call for customer support incidents. But if you throw additional tiers in your organization between your engineering teams and your customers, that means you're increasing the time to actually start investigating and resolving those problems. If you have two tiers before your engineering team and each tier has its own SLA of 10 minutes to triage the issue, that means you've already gone through 20 minutes before an engineer even knows about it and can go and look at it. That violates our SLA by fourfold before investigation and remediation can even begin.&lt;/p&gt;
    &lt;p&gt;Instead, in those scenarios, what I actually recommend thinking about is how might you reduce the number of support tickets you receive in aggregate? This is the much more appropriate way to look at the problem. If you are getting support tickets that don't make sense, then you've got to investigate, why did we get this ticket? Do the root cause analysis on the ticket, not just the issue mentioned in it Ã¢ why the ticket was even created in the first place.&lt;/p&gt;
    &lt;p&gt;A ticket means: Something is broken. From there, we can figure out, OK, maybe we need to improve our documentation. Or we need to change what we're doing on one of our endpoints. Or we need to change the response error message we're sending. But you can always go deeper.&lt;/p&gt;
    &lt;head rend="h3"&gt;The customer support advantageÃ¢&lt;/head&gt;
    &lt;p&gt;And going deeper, means customer support is critical for us. We consider customer support to be the lifeline of our service level agreement (SLA). If we didn't have that advantage, then we might not have been able to deliver our commitment at all. So much so that we report some of our own CloudWatch custom metrics to our customers so they can have an aggregate view of both what they know internally and what we believe. We do this through our own internal dashboard in our application management UIs.&lt;/p&gt;
    &lt;p&gt;Helping our users identify incidents benefits us; because we can't catch everything. It's just not possible.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ã° Negligence and MaliceÃ¢&lt;/head&gt;
    &lt;p&gt;To this point, we've done the math on reliability of third-party components. We've implemented an automatic region failover and added incremental rollout. And we have a core customer support focus. Is that sufficient to achieve 5-nines of reliability?&lt;/p&gt;
    &lt;p&gt;If you think yes, then you'd expect the meme pictures now. And, I wish I could say it was enough, but it's not. That's because we also have to deal with negligence and malice.&lt;/p&gt;
    &lt;p&gt;We're in a privileged position to have numerous security researchers out there on the internet constantly trying to find vulnerabilities within our service. For transparency, I have some of those reports I want to share:&lt;/p&gt;
    &lt;head rend="h3"&gt;Ã¢RealÃ¢ Vulnerability ReportsÃ¢&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;I am a web security researcher enthusiast. Do you give a monetary reward?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Okay, this isn't starting out that great. What else have we received?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I found some vulnerabilities in your website. Do you offer rewards for ethical hackers?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Well, maybe, but I think you would actually need to answer for us, what the problem actually is. And you also might notice this went to our spam. It didn't even get to our inbox. So a lot of help they might be providing. Actually we ignore any Ã¢securityÃ¢ email sent from a non-custom domain.&lt;/p&gt;
    &lt;p&gt;This one was really interesting. We had someone attempting to phish our engineering team by creating a support ticket and putting in some configuration trying to get us to provide them our own credentials to one of our third-party dependencies. Interestingly enough, our teams don't even have access to those credentials directly.&lt;/p&gt;
    &lt;p&gt;And, we know this was malicious because the credentials that they are referencing in the support request are from our honey pot, stuck in our UI to explicitly catch these sorts of things. The only way to get these credentials is if they hacked around our UI application and pulled out of the HTML. They aren't readily available any other way. So it was very easy for us to detect that this Ã¢reportÃ¢ was actually a social engineering attack.&lt;/p&gt;
    &lt;p&gt;And this is one of my favorites, and I can't make this up:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I have found many security loophole. How much will you pay if you want to working with me like project?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That's the exact quote, I don't even know what that means. Unfortunately, LLMs will actually start to make all of these future "vulnerability reports" sound more appealing to read in the future, for better or worse. However, at the end of the day, the truth is that these are harmless. And we actually do have a security disclosure program that anyone can go and submit problems for. I hope the message to white-hat hackers is please use that process, and the legitimate reports usually do go through it. Do not send us emails. Those are going to go into the abyss. Alternatively, you can follow our security.txt public page or go to the disclosure form, but with email, the wrong people are going to get that and we can't triage effectively.&lt;/p&gt;
    &lt;p&gt;Vulnerabilities in our services can result in production incidents for our customers. That means security is part of our SLA. Don't believe me, I'll show you how:&lt;/p&gt;
    &lt;head rend="h3"&gt;Multitenant considerationsÃ¢&lt;/head&gt;
    &lt;p&gt;It's relevant for us, that Authress is a multitenant solution. So some of the resources within our service are in fact shared between customers.&lt;/p&gt;
    &lt;p&gt;Additionally, customers could have multiple services in a microservice architecture or multiple components. And one of these services could theoretically consume all of the resources that we've allocated for that customer. In that scenario, that would cause an incident for that customer. So we need to protect against resource exhaustion Intra-Tenant. Likewise, we have multiple customers. One of those customers could be consuming more resources than we've allocated to the entire tenant. And that could cause an incident across Inter-Tenant and cause an incident across our platform and impact other customers.&lt;/p&gt;
    &lt;p&gt;Lastly, we have to be worried about our customers, our customers' customers, and our customers' customers' customers, because any one of those could be malicious and consume their resources and so on and so forth, thus causing a cascading failure. A failure due to lack of resources is an incident. The only solution that makes sense for this is, surprise, rate limiting.&lt;/p&gt;
    &lt;head rend="h3"&gt;Helpful Rate LimitingÃ¢&lt;/head&gt;
    &lt;p&gt;So we need to rate-limit these requests at different levels for different kinds of clients, different kinds of users, and we do that within our architecture, at different fundamental levels within our infrastructure.&lt;/p&gt;
    &lt;p&gt;Primarily there are protections at our compute level, as well at the region level, and also place protections at a global level. In AWS, this of course means using a web application firewall or WAF. I think our WAF configuration is interesting and in some ways novel.&lt;/p&gt;
    &lt;p&gt;Fundamentally, one of the things that we love to use is the AWS managed IP reputation list.&lt;/p&gt;
    &lt;p&gt;The reputation list is list of IP addresses that have been associated with malicious activity outside of our service throughout other customers at AWS and other providers out there in the world where a problem has been detected. That means before those attacks even get to our service or to our customers' instances of Authress, we can already know to block them, and the WAF does that. This is great, and most importantly, has a very low false positive rate.&lt;/p&gt;
    &lt;p&gt;However, the false positive rate is an important metric for consideration of counter measures against malicious attacks or negligent accidental abuse of resources, and something that prevents us from using any other managed rules from AWS or external providers. There's two problems with managed rules, fundamentally:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Number one is the false positive rate. If that is even a little bit more than, it couldn't be sustainable, and would result in us blocking legitimate requests coming for a customer. This means it is a problem, and it's an incident for them if some of their users can't utilize their software because of something we did. False positives are customer incidents.&lt;/item&gt;
      &lt;item&gt;The second one is that managed rules are gratuitously expensive. Lots of companies are building these just to charge you lots of money, and the ROI just doesn't seem to be there. We don't see useful blocks from them.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But the truth is, we need to do something more than just the reputation list rule.&lt;/p&gt;
    &lt;head rend="h3"&gt;Handling Requests at ScaleÃ¢&lt;/head&gt;
    &lt;p&gt;And the thing that we've decided to do is Ã¢ add blocking for sufficiently high requests. By default, any Authress account's service client that goes above 2,000 requests per second (RPS), we just immediately terminate. Now, this isn't every customer, as there are some out there for us that do require such a high load or even higher (as 2k isn't that high). But for the majority of them, if you get to this number and they haven't talked to us about their volume, then it is probably malicious in some way. You don't magically go from zero to 2,000 one day, unless it is an import job.&lt;/p&gt;
    &lt;p&gt;Likewise, we can actually learn about a problem long before it gets to that scale. We have milestones, and we start reporting loads from clients at 100, 200, 500, 1,000, et cetera. If we see clients hitting these load milestones, we can already start to respond and create an incident for us to investigate before they reach a point where they're consuming all of the resources in our services for that customer. And we do this by adding alerts on the COUNT of requests for WAF metrics.&lt;/p&gt;
    &lt;p&gt;However, we also get attacks at a smaller scale. Just because we aren't being DDoS-ed doesn't mean there isn't attack. And those requests will still get through because they don't meet our blocking limits. They could be malicious in nature, but only identifiable in aggregate. So while single request might seem fine, if you see the same request 10 times a second, 100 times a second, something is probably wrong. Or if you have request urls that end in &lt;code&gt;.php?admin&lt;/code&gt;, when no one has run WordPress in decades, you also know that there's a problem. We catch these by logging all of the blocked requests.&lt;/p&gt;
    &lt;p&gt;We have automation in place to query those results and update our rules, but a picture is worth a thousand words:&lt;/p&gt;
    &lt;p&gt;Here you can see a query based off of the IP addresses from the client that are being utilized and sorted by frequency. When we get these requests that look non-malicious individually, we execute a query such as this one and we check to see if the results match a pattern. You can use ip address matching or more intelligently, something called the JA3 or JA4 fingerprints of those requests There are actually lots of options available, I'm not going to get into exactly what they are, there are some great articles on the topic. And there are more mechanisms to actually track these used throughout the security industry, and utilizing them let's you instantly identify: Hey, you know what? This request violates one of our patterns, maybe we should block all the requests from that client.&lt;/p&gt;
    &lt;p&gt;And so, rather than waiting for them to get to the point where an attacker is consuming 2,000 requests per second worth of resources, you can stop there right away. In the cases where we can't make a conclusive decision, this technology gives us another tool that we can utilize to improve our patterns for the future. Maybe it goes without saying, but of course because we've running our technology to many regions around the world, we have to work on deploying this infrastructure in all these places and push it out to the edge where possible.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ã° The ConclusionÃ¢&lt;/head&gt;
    &lt;p&gt;I said a lot of things, so I to quickly want to quickly summarize our architecture that we have in place:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Third-party component reliability reviews. I can't stress this enough. Don't just assume that you can utilize something. And sometimes in order to achieve 5-nines, you actually have to remove components from your infrastructure. Some things are just not able to be utilized no matter what. Now maybe you can put it in some sort of async background, but it can't be on the critical path for your endpoints.&lt;/item&gt;
      &lt;item&gt;DNS failover and health checks. For places where you have an individual region or availability zone or cluster, having a full backup with a way to conclusively determine what's up and automatically failover is critical.&lt;/item&gt;
      &lt;item&gt;Edge compute where possible. There's a whole network out there of services that are running on top of the cloud providers, which help guarantee your capability to run as close to as possible to where your users are and reduce latency.&lt;/item&gt;
      &lt;item&gt;Incremental rollout for when you want to reduce the impact as much as possible.&lt;/item&gt;
      &lt;item&gt;The Web Application Firewall for handling those malicious requests.&lt;/item&gt;
      &lt;item&gt;Having a Customer Support Focus to enable escalating issues that outside your area of detection.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And through seven years or so that we've been doing this and building up this architecture, there's a couple of things that we've learned:&lt;/p&gt;
    &lt;head rend="h3"&gt;Murphy's LawÃ¢&lt;/head&gt;
    &lt;p&gt;Everything fails all the time. There absolutely will be failures everywhere. Every line of code, every component you pull in, every library, there's guaranteed to be a problem in each and everyone of those. And you will for sure have to deal with it, at some point. So being prepared to handle that situation, is something you have to be thinking through in your design.&lt;/p&gt;
    &lt;head rend="h3"&gt;DNSÃ¢&lt;/head&gt;
    &lt;p&gt;DNS, yeah, AWS will say it, everyone out there will say, and now we get to say it. The global DNS architecture is pretty good and reliable for a lot of scenarios, but I worry that it's still a single point of failure in a lot of ways.&lt;/p&gt;
    &lt;head rend="h3"&gt;Infrastructure as Code (IAC)Ã¢&lt;/head&gt;
    &lt;p&gt;The last thing is infrastructure as code challenges. We deploy primary regions, but then there's also the backup regions, which are slightly different from the primary regions, and then there are edge compute, which are, again, even more slightly different. And then sometimes, we do this ridiculous thing, where we deploy infrastructure dedicated to one customers. And in doing so, we're running some sort of IaC to deploy those resources.&lt;/p&gt;
    &lt;p&gt;It is almost exactly the same architecture. Almost! Because it isn't exactly the same there are quite the opportunities for challenges to sneak it. That's problematic with even Open Tofu or CloudFormation, and often these tools make it more difficult, not less. And good luck to you, if you're still using some else that hasn't been modernized. With those, it's even easier to run into problems and not get it exactly correct.&lt;/p&gt;
    &lt;p&gt;The last thing I want to leave you with is, well, With all of these, is that actually sufficient to achieve five nines?&lt;/p&gt;
    &lt;p&gt;No. Our commitment is 5-nines, what we do is in defense of that, just because you do all these things doesn't automatically mean your promise of 5-nines in guaranteed. And you know what, you too can promise a 5-nines SLA without doing anything. You'll likely break your promise, but for us our promise is important, and so this is our defense.&lt;/p&gt;
    &lt;p&gt;For help understanding this article or how you can implement auth and similar security architectures in your services, feel free to reach out to me via the community server.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45955565</guid><pubDate>Mon, 17 Nov 2025 17:07:17 +0000</pubDate></item><item><title>Azure hit by 15 Tbps DDoS attack using 500k IP addresses</title><link>https://www.bleepingcomputer.com/news/microsoft/microsoft-aisuru-botnet-used-500-000-ips-in-15-tbps-azure-ddos-attack/</link><description>&lt;doc fingerprint="a111bbc93816209a"&gt;
  &lt;main&gt;
    &lt;p&gt;Microsoft said today that the Aisuru botnet hit its Azure network with a 15.72 terabits per second (Tbps) DDoS attack, launched from over 500,000 IP addresses.&lt;/p&gt;
    &lt;p&gt;The attack used extremely high-rate UDP floods that targeted a specific public IP address in Australia, reaching nearly 3.64 billion packets per second (bpps).&lt;/p&gt;
    &lt;p&gt;"The attack originated from Aisuru botnet. Aisuru is a Turbo Mirai-class IoT botnet that frequently causes record-breaking DDoS attacks by exploiting compromised home routers and cameras, mainly in residential ISPs in the United States and other countries," said Azure Security senior product marketing manager Sean Whalen.&lt;/p&gt;
    &lt;p&gt;"These sudden UDP bursts had minimal source spoofing and used random source ports, which helped simplify traceback and facilitated provider enforcement."&lt;/p&gt;
    &lt;p&gt;Cloudflare linked the same botnet to a record-breaking 22.2 terabits per second (Tbps) DDoS attack that reached 10.6 billion packets per second (Bpps) and was mitigated in September 2025. This attack lasted only 40 seconds but was roughly equivalent to streaming one million 4K videos simultaneously.&lt;/p&gt;
    &lt;p&gt;One week earlier, the XLab research division of Chinese cybersecurity company Qi'anxin attributed another 11.5 Tbps DDoS attack to the Aisuru botnet, saying that it was controlling around 300,000 bots at the time.&lt;/p&gt;
    &lt;p&gt;The botnet targets security vulnerabilities in IP cameras, DVRs/NVRs, Realtek chips, and routers from T-Mobile, Zyxel, D-Link, and Linksys. As XLab researchers said, it suddenly ballooned in size in April 2025 after its operators breached a TotoLink router firmware update server and infected approximately 100,000 devices.&lt;/p&gt;
    &lt;p&gt;Infosec journalist Brian Krebs reported earlier this month that Cloudflare removed multiple domains linked to the Aisuru botnet from its public "Top Domains" rankings of the most frequently requested websites (based on DNS query volume) after they began overtaking legitimate sites, such as Amazon, Microsoft, and Google.&lt;/p&gt;
    &lt;p&gt;The company stated that Aisuru's operators were deliberately flooding Cloudflare's DNS service (1.1.1.1) with malicious query traffic to boost their domain's popularity while undermining trust in the rankings. Cloudflare CEO Matthew Prince also confirmed that the botnet's behavior was severely distorting the ranking system and added that Cloudflare now redacts or completely hides suspected malicious domains to avoid similar incidents in the future.&lt;/p&gt;
    &lt;p&gt;As Cloudflare revealed in its 2025 Q1 DDoS Report in April, it mitigated a record number of DDoS attacks last year, with a 198% quarter-over-quarter jump and a massive 358% year-over-year increase.&lt;/p&gt;
    &lt;p&gt;In total, it blocked 21.3 million DDoS attacks targeting its customers throughout 2024, as well as another 6.6 million attacks targeting its own infrastructure during an 18-day multi-vector campaign.&lt;/p&gt;
    &lt;head rend="h2"&gt;The 2026 CISO Budget Benchmark&lt;/head&gt;
    &lt;p&gt;It's budget season! Over 300 CISOs and security leaders have shared how they're planning, spending, and prioritizing for the year ahead. This report compiles their insights, allowing readers to benchmark strategies, identify emerging trends, and compare their priorities as they head into 2026.&lt;/p&gt;
    &lt;p&gt;Learn how top leaders are turning investment into measurable impact.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45955900</guid><pubDate>Mon, 17 Nov 2025 17:39:15 +0000</pubDate></item><item><title>Compiling Ruby to machine language</title><link>https://patshaughnessy.net/2025/11/17/compiling-ruby-to-machine-language</link><description>&lt;doc fingerprint="c606289e40bbfb0a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Compiling Ruby To Machine Language&lt;/head&gt;
    &lt;p&gt;I've started working on a new edition of Ruby Under a Microscope that covers Ruby 3.x. I'm working on this in my spare time, so it will take a while. Leave a comment or drop me a line and I'll email you when it's finished.&lt;/p&gt;
    &lt;p&gt;Hereâ€™s an excerpt from the completely new content for Chapter 4, about YJIT and ZJIT. Iâ€™m still finishing this upâ€¦ so this content is fresh off the page! Itâ€™s been a lot of fun for me to learn about how JIT compilers work and to brush up on my Rust skills as well. And itâ€™s very exciting to see all the impressive work the Ruby team at Shopify and other contributors have done to improve Rubyâ€™s runtime performance.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 4: Compiling Ruby To Machine Language&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Interpreting vs. Compiling Ruby Code&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Yet Another JIT (YJIT)&lt;/cell&gt;
        &lt;cell&gt;6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Virtual Machines and Actual Machines&lt;/cell&gt;
        &lt;cell&gt;6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Counting Method and Block Calls&lt;/cell&gt;
        &lt;cell&gt;8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;YJIT Blocks&lt;/cell&gt;
        &lt;cell&gt;8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;YJIT Branch Stubs&lt;/cell&gt;
        &lt;cell&gt;10&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Executing YJIT Blocks and Branches&lt;/cell&gt;
        &lt;cell&gt;11&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Deferred Compilation&lt;/cell&gt;
        &lt;cell&gt;12&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Regenerating a YJIT Branch&lt;/cell&gt;
        &lt;cell&gt;12&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;YJIT Guards&lt;/cell&gt;
        &lt;cell&gt;14&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Adding Two Integers Using Machine Language&lt;/cell&gt;
        &lt;cell&gt;15&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Experiment 4-1: Which Code Does YJIT Optimize?&lt;/cell&gt;
        &lt;cell&gt;18&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;How YJIT Recompiles Code&lt;/cell&gt;
        &lt;cell&gt;22&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Finding a Block Version&lt;/cell&gt;
        &lt;cell&gt;22&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Saving Multiple Block Versions&lt;/cell&gt;
        &lt;cell&gt;24&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ZJIT, Rubyâ€™s Next Generation JIT&lt;/cell&gt;
        &lt;cell&gt;26&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Counting Method and Block Calls&lt;/cell&gt;
        &lt;cell&gt;27&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ZJIT Blocks&lt;/cell&gt;
        &lt;cell&gt;29&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Method Based JIT&lt;/cell&gt;
        &lt;cell&gt;31&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Rust Inside of Ruby&lt;/cell&gt;
        &lt;cell&gt;33&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Experiment 4-2: Reading ZJIT HIR and LIR&lt;/cell&gt;
        &lt;cell&gt;35&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Summary&lt;/cell&gt;
        &lt;cell&gt;37&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Counting Method and Block Calls&lt;/head&gt;
    &lt;p&gt;To find hot spots, YJIT counts how many times your program calls each function or block. When this count reaches a certain threshold, YJIT stops your program and converts that section of code into machine language. Later Ruby will execute the machine language version instead of the original YARV instructions.&lt;/p&gt;
    &lt;p&gt;To keep track of these counts, YJIT saves an internal counter nearby the YARV instruction sequence for each function or block.&lt;/p&gt;
    &lt;p&gt;Figure 4-5: YJIT saves information adjacent to each set of YARV instructions&lt;/p&gt;
    &lt;p&gt;Figure 4-5 shows the YARV instruction sequence the main Ruby compiler created for the sum += i block at (3) in Listing 4-1. At the top, above the YARV instructions, Figure 4-5 shows two YJIT related values: jit_entry and jit_entry_calls. As weâ€™ll see in a moment, jit_entry starts as a null value but will later hold a pointer to the machine language instructions YJIT produces for this Ruby block. Below jit_entry, Figure 4-5 also shows jit_entry_calls, YJITâ€™s internal counter.&lt;/p&gt;
    &lt;p&gt;Each time the program in Listing 4-1 calls this block, YJIT increments the value of jit_entry_calls. Since the range at (1) in Listing 4-1 spans from 1 through 40, this counter will start at zero and increase by 1 each time Range#each calls the block at (3).&lt;/p&gt;
    &lt;p&gt;When the jit_entry_calls reaches a particular threshold, YJIT will compile the YARV instructions into machine language. By default for small Ruby programs YJIT in Ruby 3.5 uses a threshold of 30. Larger programs, like Ruby on Rails web applications, will use a larger threshold value of 120. (You can also change the threshold by passing â€”yjit-call-threshold when you run your Ruby program.)&lt;/p&gt;
    &lt;head rend="h2"&gt;YJIT Blocks&lt;/head&gt;
    &lt;p&gt;While compiling your Ruby program, YJIT saves the machine language instructions it creates into YJIT blocks. YJIT blocks, which are distinct from Ruby blocks, each contain a sequence of machine language instructions for a range of corresponding YARV instructions. By grouping YARV instructions and compiling each group into a YJIT block, YJIT can produce more optimized code that is tailored to your programâ€™s behavior and avoid compiling code that your program doesnâ€™t need.&lt;/p&gt;
    &lt;p&gt;As weâ€™ll see next, a single YJIT block doesnâ€™t correspond to a Ruby function or block. YJIT blocks instead represent smaller sections of code: individual YARV instructions or a small range of YARV instructions. Each Ruby function or block typically consists of several YJIT blocks.&lt;/p&gt;
    &lt;p&gt;Letâ€™s see how this works for our example. After the program in Listing 4-1 executes the Ruby block at (3) 29 times, YJIT will increment the jit_entry_calls counter again, just before Ruby runs the block for the 30th time. Since jit_entry_calls reaches the threshold value of 30, YJIT triggers the compilation process.&lt;/p&gt;
    &lt;p&gt;YJIT compiles the first YARV instruction getlocal_WC_1 and saves machine language instructions that perform the same work as getlocal_WC_1 into a new YJIT block:&lt;/p&gt;
    &lt;p&gt;Figure 4-6: Creating a YJIT block&lt;/p&gt;
    &lt;p&gt;On the left side, Figure 4-6 shows the YARV instructions for the sum += i Ruby block. On the right, Figure 4-6 shows the new YJIT block corresponding to getlocal_WC_1.&lt;/p&gt;
    &lt;p&gt;Next, the YJIT compiler continues and compiles the second YARV instruction from the left side of Figure 4-7: getlocal_WC_0 at index 2.&lt;/p&gt;
    &lt;p&gt;Figure 4-7: Appending to a YJIT block&lt;/p&gt;
    &lt;p&gt;On the left side, Figure 4-7 shows the same YARV instructions for the sum += i Ruby block that we saw above in Figure 4-6. But now the two dotted arrows indicate that the YJIT block on the right contains the machine language instructions equivalent to both getlocal_WC_1 and getlocal_WC_0.&lt;/p&gt;
    &lt;p&gt;Letâ€™s take a look inside this new block. YJIT compiles or translates the Ruby YARV instructions into machine language instructions. In this example, running on my Mac laptop, YJIT writes the following machine language instructions into this new block:&lt;/p&gt;
    &lt;p&gt;Figure 4-8: The contents of one YJIT block&lt;/p&gt;
    &lt;p&gt;Figure 4-8 shows a closer view of the new YJIT block that appeared on the right side of Figures 4-6 and 4-7. Inside the block, Figure 4-8 shows the assembly language acronyms corresponding to the ARM64 machine language instructions that YJIT generated for the two YARV instructions shown on the left. The YARV instructions on the left are: getlocal_WC_1, which loads a value from a local variable located in the previous stack frame and saves it on the YARV stack, and getlocal_WC_0, which loads a local variable from the current stack from and also saves it on the YARV stack. The machine language instructions on the right side of Figure 4-8 perform the same task, loading these values into registers on my M1 microprocessor: x1 and x9. If youâ€™re curious and would like to learn more about what the machine language instructions mean and how they work, the section â€œAdding Two Integers Using Machine Languageâ€ discusses the instructions for this example in more detail.&lt;/p&gt;
    &lt;head rend="h2"&gt;YJIT Branch Stubs&lt;/head&gt;
    &lt;p&gt;Next, YJIT continues down the sequence of YARV instructions and compiles the opt_plus YARV instruction at index 4 in Figures 4-6 and 4-7. But this time, YJIT runs into a problem: It doesnâ€™t know the type of the addition arguments. That is, will opt_plus add two integers? Or two strings, floating point numbers, or some other types?&lt;/p&gt;
    &lt;p&gt;Machine language is very specific. To add two 64-bit integers on an M1 microprocessor, YJIT could use the adds assembly language instruction. But adding two floating pointer numbers would require different instructions. And, of course, adding or concatenating two strings is an entirely different operation altogether.&lt;/p&gt;
    &lt;p&gt;In order for YJIT to know which machine language instructions to save into the YJIT block for opt_plus, YJIT needs to know exactly what type of values the Ruby program might ever add at (3) in Listing 4-1. You and I can tell by reading Listing 4-1 that the Ruby code is adding integers. We know right away that the sum += 1 block at (3) is always adding one integer to another. But YJIT doesnâ€™t know this.&lt;/p&gt;
    &lt;p&gt;YJIT uses a clever trick to solve this problem. Instead of analyzing the entire program ahead of time to determine all of the possible types of values the opt_plus YARV instruction might ever need to add, YJIT simply waits until the block runs and observes which types the program actually passes in.&lt;/p&gt;
    &lt;p&gt;YJIT uses branch stubs to achieve this wait-and-see compile behavior, as shown in Figure 4-9.&lt;/p&gt;
    &lt;p&gt;Figure 4-9: A YJIT block, branch and stub&lt;/p&gt;
    &lt;p&gt;Figure 4-9 shows the YARV instructions on the left, and the YJIT block for indexes 0000-0002 on the right. But note the bottom right corner of Figure 4-7, which shows an arrow pointing down from the block to a box labeled stub. This arrow represents a YJIT branch. Since this new branch doesnâ€™t point to a block yet, YJIT sets up the branch to point to a branch stub instead.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45957629</guid><pubDate>Mon, 17 Nov 2025 20:04:49 +0000</pubDate></item><item><title>Run ancient UNIX on modern hardware</title><link>https://github.com/felipenlunkes/run-ancient-unix</link><description>&lt;doc fingerprint="b085fe091cbba1c6"&gt;
  &lt;main&gt;
    &lt;p&gt;The contents of this repository allow older versions of UNIX (ancient UNIX) to run easily on modern Unix-like systems (Linux, FreeBSD, macOS, among others).&lt;/p&gt;
    &lt;p&gt;At this time, you can run the following versions of UNIX:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;UNIX versions for PDP-11 (run on a PDP-11 simulator):&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;UNIX versions for x86:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Version 7 UNIX ported to x86 architecture by Robert Nordier (original port in 1999 and patches in 2006-2007).&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;First of all, credits and acknowledgment for material available in this repository that is not my own (or has been modified by me based on previous work).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The UNIX versions available in this repository have been released as open source under the Caldera license available in this repository. Please read the document carefully for concrete information about your rights and obligations when using the software. &lt;list rend="ul"&gt;&lt;item&gt;Note that various components within the system images may have been made available under other license conditions. Pay attention to these components. A clear example is version 2.11BSD UNIX, which features code covered by the Caldera license made available, in addition to code released under the BSD license. Source files available in the images show the license and due copyright. Check this data before reuse.&lt;/item&gt;&lt;item&gt;The UNIX images available in this repository were obtained from the w11 project (which uses these images for other purposes). You can get them directly here, as well as more information about the project, images, licenses and other data.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;The scripts used to simulate the systems using SIMH for v5 and v7 UNIX were obtained from a w11 project repository, which can be accessed here. The original scripts are available under license GLP v3 or later. Modifications in these files were made by me, to fit the purpose of this repository. These modifications are restricted to the same license as the original script. &lt;list rend="ul"&gt;&lt;item&gt;In addition, the general script for configuring the execution environment of versions v5 and v7 was obtained from the project, authored by Walter F.J. Mueller. You can get the original script here. The original script are available under license GLP v3 or later. Modifications in these files were made by me, to fit the purpose of this repository. These modifications are restricted to the same license as the original script.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;The port of Version 7 UNIX to the x86 architecture was performed by Robert Nordier. These modifications are released under the simplified BSD license. For more information on all aspects of the distribution, read this file.&lt;/item&gt;
      &lt;item&gt;All my contributions and modifications (except for material that requires redistribution under the same license, such as the running scripts) are available in this repository under the BSD-3-Clause license.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You will need the following tools and utilities to run the available UNIX versions:&lt;/p&gt;
    &lt;p&gt;First of all, you must have the &lt;code&gt;PDP-11 Simulator&lt;/code&gt; (SIMH), &lt;code&gt;qemu&lt;/code&gt;, &lt;code&gt;GNU bash&lt;/code&gt;, &lt;code&gt;Python&lt;/code&gt;, &lt;code&gt;wget&lt;/code&gt; and &lt;code&gt;git&lt;/code&gt; installed on your device. If you already have them installed, skip to section 2.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;To install on Debian, Ubuntu, Pop!_OS and derivatives, use:&lt;/p&gt;
    &lt;/quote&gt;
    &lt;code&gt;sudo apt install simh qemu qemu-system-i386 git wget python3 python3-pip python3-tk
&lt;/code&gt;
    &lt;quote&gt;
      &lt;p&gt;To install on Fedora and derivatives, use:&lt;/p&gt;
    &lt;/quote&gt;
    &lt;code&gt;sudo dnf install simh qemu qemu-system-i386 git wget python3 python3-pip python3-tkinter
&lt;/code&gt;
    &lt;quote&gt;
      &lt;p&gt;To install on FreeBSD, use (for FreeBSD, installing GNU bash is also required. This shell is not normally installed in a default installation. Installation of GNU bash is not required on Linux systems, where bash is already installed by default):&lt;/p&gt;
    &lt;/quote&gt;
    &lt;code&gt;su root # &amp;lt;= Enter your password to login as root user
pkg install -q -y simh bash qemu git wget python3 py39-pip
ln -s /usr/local/bin/pip-3.9 /usr/local/bin/pip
pip install --upgrade pip
&lt;/code&gt;
    &lt;quote&gt;
      &lt;p&gt;To install on NetBSD, use (for NetBSD, installing GNU bash is also required. This shell is not normally installed in a default installation. Installation of GNU bash is not required on Linux systems, where bash is already installed by default):&lt;/p&gt;
    &lt;/quote&gt;
    &lt;code&gt;su root # &amp;lt;= Enter your password to login as root user
pkgin install simh bash qemu git wget python3 py39-pip
ln -s /usr/local/bin/pip-3.9 /usr/local/bin/pip
pip install --upgrade pip
&lt;/code&gt;
    &lt;quote&gt;
      &lt;p&gt;To install on OpenBSD, use (for OpenBSD, installing GNU bash is also required. This shell is not normally installed in a default installation. Installation of GNU bash is not required on Linux systems, where bash is already installed by default):&lt;/p&gt;
    &lt;/quote&gt;
    &lt;code&gt;su root # &amp;lt;= Enter your password to login as root user
pkg_add simh bash qemu git wget python3 py39-pip
ln -s /usr/local/bin/pip-3.9 /usr/local/bin/pip
pip install --upgrade pip
&lt;/code&gt;
    &lt;p&gt;After installation, proceed to section 2.&lt;/p&gt;
    &lt;p&gt;You must clone this repository to your computer. For that, use:&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/felipenlunkes/run-ancient-unix
cd run-ancient-unix
&lt;/code&gt;
    &lt;p&gt;After cloning the repository with the configuration files, you must populate the directories of each UNIX version with their respective image files. For that, go to the next section.&lt;/p&gt;
    &lt;p&gt;Now, you have to run the available &lt;code&gt;run.sh&lt;/code&gt; script. For that, use:&lt;/p&gt;
    &lt;code&gt;chmod +x run.sh
./run.sh
&lt;/code&gt;
    &lt;p&gt;First, you have to run the script and select the option to install system images. You can also use the Python frontend to run the script. This is the easiest and simplest way to run script functions. To run this frontend and not rely on the command line, go to section 5. To continue the steps using the terminal, go to section 4.&lt;/p&gt;
    &lt;p&gt;You will see the following screen:&lt;/p&gt;
    &lt;code&gt;You must select, from the list below, which edition/version of
UNIX you want to start. The available options are:

1) v1 UNIX
2) v5 UNIX
3) v7 UNIX
4) 2.11BSD UNIX
5) v7 UNIX for x86
6) Clear temporary files
7) Install the disk images for UNIX

Select a number and press &amp;lt;ENTER&amp;gt;: 
&lt;/code&gt;
    &lt;p&gt;In this case, you should select option &lt;code&gt;7&lt;/code&gt;, which will install the system images. After pressing 7, press ENTER to make your choice effective. Wait for the process of obtaining, extracting, configuring and installing the images.&lt;/p&gt;
    &lt;p&gt;After the installation is complete, you must run &lt;code&gt;run.sh&lt;/code&gt; again to start a UNIX version.&lt;/p&gt;
    &lt;p&gt;When running the script, you will be asked to choose one of the available UNIX versions. After typing only the number relative to the choice, press ENTER to make your decision effective. Then wait for the desired version to run.&lt;/p&gt;
    &lt;p&gt;Now, you need to know peculiarities in the execution of each version of the system. For this, go to section 6.&lt;/p&gt;
    &lt;p&gt;You need to start running the Python frontend that will manage the configuration and running of UNIX on your computer. First, you must install the TKinter Python package on your computer. For that, use:&lt;/p&gt;
    &lt;code&gt;pip install tk
&lt;/code&gt;
    &lt;p&gt;After that, you can press the &lt;code&gt;RAU.py&lt;/code&gt; script with the right button of your mouse and select the option of &lt;code&gt;Run as program&lt;/code&gt; or start the script from the terminal, using:&lt;/p&gt;
    &lt;code&gt;python3 RAU.py
&lt;/code&gt;
    &lt;quote&gt;&lt;p&gt;WARNING! The frontend is currently only compatible with the GNOME graphical environment (Linux and BSD systems). You can manually replace the&lt;/p&gt;&lt;code&gt;gnome-terminal&lt;/code&gt;calls with&lt;code&gt;konsole&lt;/code&gt;or another desired terminal emulator. Feel free to submit a pull request with any improvements or changes to the frontend.&lt;/quote&gt;
    &lt;p&gt;After running the program, you will see the following screen:&lt;/p&gt;
    &lt;p&gt;On first run, you must install the UNIX disk images locally on your computer. Prior to this operation, you will NOT be able to run UNIX. To do so, click on the &lt;code&gt;Install UNIX system images&lt;/code&gt; button.&lt;/p&gt;
    &lt;p&gt;After downloading and installing the disk images, you are able to run UNIX. To do so, select the desired UNIX version in the &lt;code&gt;Running options&lt;/code&gt; section of the frontend screen.&lt;/p&gt;
    &lt;p&gt;Go to the next section for more information about the specifics of running each version of UNIX available. Remember that when using the Python frontend, the command line selection screen, as shown in the next section, will not be displayed. However, the manual options and settings presented in the next section (after the selection screen, which will not appear) are still required to run each version of UNIX.&lt;/p&gt;
    &lt;p&gt;Select the desired UNIX version option below for details on how to start and operate the system. Each version of UNIX has different boot procedures. Pay attention to each particularity.&lt;/p&gt;
    &lt;head align="left"&gt;Particularities for Version 1 UNIX&lt;/head&gt;
    &lt;p&gt;After the start of execution after selecting v1 version, you will see a screen like below:&lt;/p&gt;
    &lt;code&gt;You must select, from the list below, which edition/version of
UNIX you want to start. The available options are:

1) v1 UNIX
2) v5 UNIX
3) v7 UNIX
4) 2.11BSD UNIX
5) v7 UNIX for x86
6) Clear temporary files
7) Install the disk images for UNIX

Select a number and press &amp;lt;ENTER&amp;gt;: 1

PDP-11 simulator V3.8-1
Disabling CR
Disabling XQ
RF: buffering file in memory
TC0: 16b format, buffering file in memory

:login: 
&lt;/code&gt;
    &lt;p&gt;Just type &lt;code&gt;root&lt;/code&gt;, in lower case, and press ENTER. You will immediately be taken to the UNIX v1 shell.&lt;/p&gt;
    &lt;code&gt;You must select, from the list below, which edition/version of
UNIX you want to start. The available options are:

1) v1 UNIX
2) v5 UNIX
3) v7 UNIX
4) 2.11BSD UNIX
5) v7 UNIX for x86
6) Clear temporary files
7) Install the disk images for UNIX

Select a number and press &amp;lt;ENTER&amp;gt;: 1

PDP-11 simulator V3.8-1
Disabling CR
Disabling XQ
RF: buffering file in memory
TC0: 16b format, buffering file in memory

:login: root
root
# ls
bin
dev
etc
tmp
usr
# 
&lt;/code&gt;
    &lt;p&gt;To end the simulation, press CTRL-E followed by CTRL-C or by typing quit when the &lt;code&gt;simh&amp;gt;&lt;/code&gt; prompt appears on the screen.&lt;/p&gt;
    &lt;head align="left"&gt;Particularities for Version 5 UNIX&lt;/head&gt;
    &lt;p&gt;After the start of execution after selecting v5 version, you will see a screen like below:&lt;/p&gt;
    &lt;code&gt;You must select, from the list below, which edition/version of
UNIX you want to start. The available options are:

1) v1 UNIX
2) v5 UNIX
3) v7 UNIX
4) 2.11BSD UNIX
5) v7 UNIX for x86
6) Clear temporary files
7) Install the disk images for UNIX

Select a number and press &amp;lt;ENTER&amp;gt;: 2

PDP-11 simulator V3.8-1
Disabling XQ
Logging to file "simh_dl0.log"
Listening on port 5671 (socket 5)
Listening on port 5672 (socket 7)
Modem control activated
@
&lt;/code&gt;
    &lt;p&gt;To start UNIX, you must type &lt;code&gt;unix&lt;/code&gt; and press ENTER after the @ character, without spaces and in lower case. After pressing ENTER, UNIX will load and you will be taken to a login screen as below:&lt;/p&gt;
    &lt;code&gt;You must select, from the list below, which edition/version of
UNIX you want to start. The available options are:

1) v1 UNIX
2) v5 UNIX
3) v7 UNIX
4) 2.11BSD UNIX
5) v7 UNIX for x86
6) Clear temporary files
7) Install the disk images for UNIX

Select a number and press &amp;lt;ENTER&amp;gt;: 2

PDP-11 simulator V3.8-1
Disabling XQ
Logging to file "simh_dl0.log"
Listening on port 5671 (socket 5)
Listening on port 5672 (socket 7)
Modem control activated
@unix

login:
&lt;/code&gt;
    &lt;p&gt;You must then type &lt;code&gt;root&lt;/code&gt; and press ENTER. You will then be taken to the shell and be able to use the system. See below:&lt;/p&gt;
    &lt;code&gt;You must select, from the list below, which edition/version of
UNIX you want to start. The available options are:

1) v1 UNIX
2) v5 UNIX
3) v7 UNIX
4) 2.11BSD UNIX
5) v7 UNIX for x86
6) Clear temporary files
7) Install the disk images for UNIX

Select a number and press &amp;lt;ENTER&amp;gt;: 2

PDP-11 simulator V3.8-1
Disabling XQ
Logging to file "simh_dl0.log"
Listening on port 5671 (socket 5)
Listening on port 5672 (socket 7)
Modem control activated
@unix

login: root
# 
&lt;/code&gt;
    &lt;p&gt;To end the simulation, press CTRL-E followed by CTRL-C or by typing quit when the &lt;code&gt;simh&amp;gt;&lt;/code&gt; prompt appears on the screen.&lt;/p&gt;
    &lt;head align="left"&gt;Particularities for Version 7 UNIX&lt;/head&gt;
    &lt;p&gt;After the start of execution after selecting v7 version, you will see a screen like below:&lt;/p&gt;
    &lt;code&gt;You must select, from the list below, which edition/version of
UNIX you want to start. The available options are:

1) v1 UNIX
2) v5 UNIX
3) v7 UNIX
4) 2.11BSD UNIX
5) v7 UNIX for x86
6) Clear temporary files
7) Install the disk images for UNIX

Select a number and press &amp;lt;ENTER&amp;gt;: 3

PDP-11 simulator V3.8-1
Disabling XQ
Logging to file "simh_dl0.log"
Listening on port 5671 (socket 5)
Listening on port 5672 (socket 7)
Modem control activated
&lt;/code&gt;
    &lt;p&gt;After seeing the screen above, you must type &lt;code&gt;boot&lt;/code&gt; in lower case and press ENTER. You will see the screen below after that:&lt;/p&gt;
    &lt;code&gt;You must select, from the list below, which edition/version of
UNIX you want to start. The available options are:

1) v1 UNIX
2) v5 UNIX
3) v7 UNIX
4) 2.11BSD UNIX
5) v7 UNIX for x86
6) Clear temporary files
7) Install the disk images for UNIX

Select a number and press &amp;lt;ENTER&amp;gt;: 3

PDP-11 simulator V3.8-1
Disabling XQ
Logging to file "simh_dl0.log"
Listening on port 5671 (socket 5)
Listening on port 5672 (socket 7)
Modem control activated
boot
Boot
:
&lt;/code&gt;
    &lt;p&gt;After the appearance of &lt;code&gt;:&lt;/code&gt;, you must type, without spaces and in lower case, the command &lt;code&gt;hp(0,0)unix&lt;/code&gt; and press ENTER, as below:&lt;/p&gt;
    &lt;code&gt;You must select, from the list below, which edition/version of
UNIX you want to start. The available options are:

1) v1 UNIX
2) v5 UNIX
3) v7 UNIX
4) 2.11BSD UNIX
5) v7 UNIX for x86
6) Clear temporary files
7) Install the disk images for UNIX

Select a number and press &amp;lt;ENTER&amp;gt;: 3

PDP-11 simulator V3.8-1
Disabling XQ
Logging to file "simh_dl0.log"
Listening on port 5671 (socket 5)
Listening on port 5672 (socket 7)
Modem control activated
boot
Boot
: hp(0,0)unix
mem = 2020544
# 
&lt;/code&gt;
    &lt;p&gt;Pressing ENTER will immediately take you to the UNIX v7 shell.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; To enter multiuser mode and access all system functions, press CTRL-D. Afterwards, provide &lt;code&gt;root&lt;/code&gt;as username and password. You will again be taken to the UNIX v7 shell, as below:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;You must select, from the list below, which edition/version of
UNIX you want to start. The available options are:

1) v1 UNIX
2) v5 UNIX
3) v7 UNIX
4) 2.11BSD UNIX
5) v7 UNIX for x86
6) Clear temporary files
7) Install the disk images for UNIX

Select a number and press &amp;lt;ENTER&amp;gt;: 3

PDP-11 simulator V3.8-1
Disabling XQ
Logging to file "simh_dl0.log"
Listening on port 5671 (socket 5)
Listening on port 5672 (socket 7)
Modem control activated
boot
Boot
: hp(0,0)unix
mem = 2020544
# RESTRICTED RIGHTS: USE, DUPLICATION, OR DISCLOSURE
IS SUBJECT TO RESTRICTIONS STATED IN YOUR CONTRACT WITH
WESTERN ELECTRIC COMPANY, INC.
WED DEC 31 19:05:14 EST 1969

login: root
Password:
You have mail.
# 
&lt;/code&gt;
    &lt;p&gt;To end the simulation, press CTRL-E followed by CTRL-C or by typing quit when the &lt;code&gt;simh&amp;gt;&lt;/code&gt; prompt appears on the screen.&lt;/p&gt;
    &lt;head align="left"&gt;Particularities for 2.11BSD UNIX&lt;/head&gt;
    &lt;p&gt;After the start of execution after selecting 2.11BSD UNIX version, you will see a screen like below:&lt;/p&gt;
    &lt;code&gt;You must select, from the list below, which edition/version of
UNIX you want to start. The available options are:

1) v1 UNIX
2) v5 UNIX
3) v7 UNIX
4) 2.11BSD UNIX
5) v7 UNIX for x86
6) Clear temporary files
7) Install the disk images for UNIX

Select a number and press &amp;lt;ENTER&amp;gt;: 4

PDP-11 simulator V3.8-1
Listening on port 4000 (socket 4)
Modem control activated
Auto disconnect activated
211bsd.simh&amp;gt; attach xq eth0
File open error
Disabling CR

73Boot from ra(0,0,0) at 0172150
: 
&lt;/code&gt;
    &lt;p&gt;You can just press ENTER when you see the screen to start UNIX. Afterwards, you will see the following screen:&lt;/p&gt;
    &lt;code&gt;You must select, from the list below, which edition/version of
UNIX you want to start. The available options are:

1) v1 UNIX
2) v5 UNIX
3) v7 UNIX
4) 2.11BSD UNIX
5) v7 UNIX for x86
6) Clear temporary files
7) Install the disk images for UNIX

Select a number and press &amp;lt;ENTER&amp;gt;: 4

PDP-11 simulator V3.8-1
Listening on port 4000 (socket 4)
Modem control activated
Auto disconnect activated
211bsd.simh&amp;gt; attach xq eth0
File open error
Disabling CR

73Boot from ra(0,0,0) at 0172150
: 
: ra(0,0,0)unix
Boot: bootdev=02400 bootcsr=0172150

2.11 BSD UNIX #1: Fri Jun 9 08:42:54 PDT 1995
    root@SSU-64EN137:/usr/src/sys/SYSTEM

ra0: Ver 3 mod 3
ra0: RD54  size=311200
attaching qe0 csr 174440
qe0: DEC DELQA addr 00:50:56:01:01:01
attaching lo0

phys mem  = 3145728
avail mem = 1737664
user mem  = 307200

June  9 12:21:04 init: configure system

dz 0 csr 160100 vector 300 attached
ra 0 csr 172150 vector 154 vectorset attached
ts 0 csr 172520 vector 224 attached
erase, kill ^U, intr ^C
# 
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;#&lt;/code&gt; symbol indicates that the shell is ready to receive commands. Try using &lt;code&gt;uname -a&lt;/code&gt; or &lt;code&gt;ls&lt;/code&gt; to get started.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; To enter multiuser mode and access all system functions, press CTRL-D. Afterwards, provide &lt;code&gt;root&lt;/code&gt;as username and password. You will again be taken to the 2.11BSD shell.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To end the simulation, press CTRL-E followed by CTRL-C or by typing quit when the &lt;code&gt;simh&amp;gt;&lt;/code&gt; prompt appears on the screen.&lt;/p&gt;
    &lt;head align="left"&gt;Particularities for Version 7 UNIX for x86&lt;/head&gt;
    &lt;p&gt;After the start of execution after selecting v7 UNIX for x86, you will see a screen like below:&lt;/p&gt;
    &lt;code&gt;You must select, from the list below, which edition/version of
UNIX you want to start. The available options are:

1) v1 UNIX
2) v5 UNIX
3) v7 UNIX
4) 2.11BSD UNIX
5) v7 UNIX for x86
6) Clear temporary files
7) Install the disk images for UNIX

Select a number and press &amp;lt;ENTER&amp;gt;: 5
&lt;/code&gt;
    &lt;p&gt;Upon selection, &lt;code&gt;qemu&lt;/code&gt; will automatically start with the Version 7 UNIX for x86 disk image. After the initial boot, you will see the following screen:&lt;/p&gt;
    &lt;p&gt;Then press ENTER to load and start UNIX. After pressing ENTER, you will see the following screen, and you will be able to interact with the Version 7 UNIX shell:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; To enter multiuser mode and access all system functions, press CTRL-D. Afterwards, provide &lt;code&gt;root&lt;/code&gt;as username and&lt;code&gt;password&lt;/code&gt;as password. You will again be taken to the Version 7 UNIX shell.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When you are finished running the system on the PDP-11 simulator, you can clean up temporary and log files that may have been created by SIMH. To do so, go to section 7.&lt;/p&gt;
    &lt;p&gt;The simulator can create temporary and log files to simulate peripheral devices that would be connected to a PDP-11 minicomputer. These files typically have &lt;code&gt;.log&lt;/code&gt; and &lt;code&gt;.dat&lt;/code&gt; extensions. You can remove these files using the &lt;code&gt;run.sh&lt;/code&gt; script and selecting the cleanup temporary files option, as well as manually going into each system directory and entering, in your system shell:&lt;/p&gt;
    &lt;code&gt;cd UNIX_VERSION_DIRECTORY
rm *.log *.dat
cd ..
&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45958717</guid><pubDate>Mon, 17 Nov 2025 21:46:06 +0000</pubDate></item><item><title>Show HN: Parqeye â€“ A CLI tool to visualize and inspect Parquet files</title><link>https://github.com/kaushiksrini/parqeye</link><description>&lt;doc fingerprint="35fc99af4d856b82"&gt;
  &lt;main&gt;
    &lt;p&gt;&lt;code&gt;parqeye&lt;/code&gt; lets you peek inside your Parquet files. Instantly inspect their contents, schema, and metadata â€” right from your terminal.&lt;/p&gt;
    &lt;p&gt;Features&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Interactive Data Visualization - Browse through your Parquet data in a table view with keyboard navigation.&lt;/item&gt;
      &lt;item&gt;Schema Explorer - Inspect column types, nested structures, and field definitions.&lt;/item&gt;
      &lt;item&gt;File Metadata - View Parquet file-level metadata including version, created by, encoding stats and more.&lt;/item&gt;
      &lt;item&gt;Row Group Statistics - Examine row group-level metadata, statistics, and data distribution across groups.&lt;/item&gt;
      &lt;item&gt;Tab-based Interface - Quickly switch between Visualize, Schema, Metadata, and Row Groups views.&lt;/item&gt;
      &lt;item&gt;Terminal-native - Works directly in your terminal.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Run &lt;code&gt;parqeye&lt;/code&gt; by providing the path to the &lt;code&gt;.parquet&lt;/code&gt; file.&lt;/p&gt;
    &lt;code&gt;parqeye &amp;lt;path-to-parquet-file&amp;gt;
&lt;/code&gt;
    &lt;p&gt;You can download the latest release from the Releases page.&lt;/p&gt;
    &lt;p&gt;You can build from source by downloading the repository and running the following command:&lt;/p&gt;
    &lt;code&gt;cargo build --release
&lt;/code&gt;
    &lt;p&gt;If you use Rust, build directly from crates.io&lt;/p&gt;
    &lt;code&gt;cargo install parqeye
&lt;/code&gt;
    &lt;p&gt;This package is released under the MIT License.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;csvlens for the inspiration&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Lazy/streaming loading of parquet files.&lt;/item&gt;
      &lt;item&gt;Filter columns by value in the visualize tab.&lt;/item&gt;
      &lt;item&gt; Read parquet files on the cloud (&lt;code&gt;s3://...&lt;/code&gt;).&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45959780</guid><pubDate>Mon, 17 Nov 2025 23:45:42 +0000</pubDate></item><item><title>Windows 11 adds AI agent that runs in background with access to personal folders</title><link>https://www.windowslatest.com/2025/11/18/windows-11-to-add-an-ai-agent-that-runs-in-background-with-access-to-personal-folders-warns-of-security-risk/</link><description>&lt;doc fingerprint="3492a95ffb26f2e6"&gt;
  &lt;main&gt;
    &lt;p&gt;Microsoft is moving forward with its plans to turn Windows 11 into a full-fledged â€œAIâ€ operating system amidst Copilot backlash.&lt;/p&gt;
    &lt;p&gt;The first big move in that direction is an experimental feature called â€œAgent Workspace,â€ which gives AI agents access to the most-used folders in your directory, such as Desktop, Music, Pictures, and Videos. It will also allow AI agents to have their own runtime, desktop, user account, and ability to always run in the background if you turn on the feature.&lt;/p&gt;
    &lt;head rend="h2"&gt;New agentic features in Windows 11&lt;/head&gt;
    &lt;p&gt;As soon as I installed Windows 11 Build 26220.7262, Windows Latest noticed a new toggle â€œExperimental agentic featuresâ€ inside the â€œAI Componentsâ€ page in the Settings app &amp;gt; System.&lt;/p&gt;
    &lt;p&gt;This turns on â€œAgent Workspace,â€ but it doesnâ€™t work right now, and if youâ€™re wondering, itâ€™s only available to Windows Insiders in the Dev or Beta Channel.&lt;/p&gt;
    &lt;head rend="h3"&gt;What are AI Agents and how do they work?&lt;/head&gt;
    &lt;p&gt;If youâ€™ve ever used ChatGPT, you might have come across â€˜Agents.â€™ AI Agents have their own interface, and they navigate just like a human.&lt;/p&gt;
    &lt;p&gt;For example, if you ask ChatGPTâ€™s Agent to book a trip, itâ€™ll open Chromium on Linux in an Azure container, search for the query, visit different websites, navigate each page, and book a flight ticket using your saved credentials. An AI Agent tries to behave like a human, and it can perform tasks on your behalf while you sit back and relax (spoiler: you donâ€™t).&lt;/p&gt;
    &lt;p&gt;Thatâ€™s the core idea Silicon Valley is trying to sell. However, it doesnâ€™t work as well as companies like OpenAI and Perplexity claim.&lt;/p&gt;
    &lt;p&gt;Up until now, these Agents have been limited to cloud containers with Chromium and Linux terminal access, but as Microsoft wants Windows 11 to become an â€œAI-nativeâ€ OS, itâ€™s adding Agent Workspace.&lt;/p&gt;
    &lt;head rend="h2"&gt;What the hell is Agent Workspace on Windows 11?&lt;/head&gt;
    &lt;p&gt;Agent workspace is a separate, contained Windows session made just for AI agents, where they get their own account, desktop, and permissions so they can click, type, open apps, and work on your files in the background while you keep using your normal desktop.&lt;/p&gt;
    &lt;p&gt;This feature is completely optional and is never turned on by default. To test it, I turned on the feature, and Microsoft created an extra â€œworkspace.â€ Itâ€™s very similar to how Windows Sandbox or Workspaces in Microsoft Edge work, but it could be a potential security disaster, as even Microsoft is warning about risks.&lt;/p&gt;
    &lt;p&gt;When Windows spins up this extra workspace, it gives it limited access (like specific folders such as Documents or Desktop) and keeps its actions isolated and auditable.&lt;/p&gt;
    &lt;p&gt;Each agent can have its own workspace and access rules, so what one agent can see or do doesnâ€™t automatically apply to others, and you stay in control of what theyâ€™re allowed to touch.&lt;/p&gt;
    &lt;p&gt;â€œThe creation of the agent workspace where agents can work in parallel with a human user, enabling runtime isolation and scoped authorization,â€ Microsoft noted in a support document. â€œThis provides the agent with capabilities like its own desktop while limiting the visibility and accessing the agent has to the userâ€™s desktop activity.â€&lt;/p&gt;
    &lt;head rend="h4"&gt;A bit similar to Sandbox? Not technically&lt;/head&gt;
    &lt;p&gt;You might find the idea of Agent Workspace a bit similar to Windows Sandbox. Microsoft argues that Windows Agent Workspace is more â€œefficientâ€ than a virtual machine, such as Windows Sandbox, because:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The agent still has security isolation&lt;/item&gt;
      &lt;item&gt;Supports parallel execution&lt;/item&gt;
      &lt;item&gt;and gives you controlâ€¦ as you can allow the Agent to access your personal folders even when itâ€™s running in a separate isolated instance. Or you can see the logs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;â€œThe overall experience and security model are actively being refined to support key principles of transparency, safety, and user control,â€ Microsoft says.&lt;/p&gt;
    &lt;p&gt;While Agent and Sandbox have similarities like isolation, Sandbox does not have access to your personal files or folders. In Windows Sandbox, Microsoft creates an isolated and hardware-based virtualization, and even a separate kernel to keep the sandbox completely separate.&lt;/p&gt;
    &lt;p&gt;When you turn off Sandbox, all of its activities are deleted. We canâ€™t say the same for AI agents.&lt;/p&gt;
    &lt;head rend="h2"&gt;Windows 11 lets AI agents into your Documents and Desktop folders by default, with read and write access&lt;/head&gt;
    &lt;p&gt;When you turn on the feature, youâ€™re giving agents access to apps and even local folders, such as Desktop, Music, Pictures, and Videos.&lt;/p&gt;
    &lt;p&gt;I dug a bit into the implementation, and it looks like Agent Workspace has limited access to your local folder inside (C:\Users\&amp;lt;username&amp;gt;\). When the toggle â€œExperimental Agent featuresâ€ is enabled, Windows gets read and write access to the following folders: Downloads, Desktop, Videos, Pictures, and Music.&lt;/p&gt;
    &lt;p&gt;These folders are called â€œKnown folders,â€ a feature that Microsoft added with Windows Vista.&lt;/p&gt;
    &lt;p&gt;Since Agent workspace is using known folders, it can always locate these folders (Documents, Downloads, Desktop, Videos, Pictures, Music) even if youâ€™ve redirected the location elsewhere in the filesystem.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why do Agents need access to my personal folders?&lt;/head&gt;
    &lt;p&gt;To run things for you. Simple. Agent Workspace requires access to apps or private folders to perform actions on your behalf. Microsoft insists that itâ€™s taking care of security implications by giving Agent Workspace its own authorisation (a separate account, similar to your user account), runtime isolation.&lt;/p&gt;
    &lt;p&gt;Each agent will have its own defined set of dos and donâ€™ts.&lt;/p&gt;
    &lt;p&gt;The idea is to give Agents their own backyard on your PC, and let them run in the background all the time. Youâ€™ll be able to monitor the logs and keep an eye on agent activity.&lt;/p&gt;
    &lt;head rend="h3"&gt;Agents also need your apps, not just files or folders&lt;/head&gt;
    &lt;p&gt;While each agent gets its own account, independent of your personal account, an agent would still need access to your apps.&lt;/p&gt;
    &lt;p&gt;Now, when you turn on the feature, Microsoft is giving access to all your installed apps that you can use. But you can specifically install apps for your agents. Or you can maintain different user accounts on Windows, and then install apps for those specific users. If this isnâ€™t an unnecessary solution to a problem no one had, then what isâ€¦?&lt;/p&gt;
    &lt;head rend="h3"&gt;AI Agents may have performance issues&lt;/head&gt;
    &lt;p&gt;In our tests, Windows Latest observed that the experimental toggle warns of potential performance issues, and it makes sense.&lt;/p&gt;
    &lt;p&gt;AI agents are going to run in the background all the time and use RAM or CPU, depending agentâ€™s activity. However, Microsoftâ€™s early benchmarks suggest they wonâ€™t really drain PCs of their power. Microsoft wonâ€™t give us the numbers for obvious reasons.&lt;/p&gt;
    &lt;p&gt;Microsoft only says AI Agents will use a limited amount of RAM and CPU.&lt;/p&gt;
    &lt;p&gt;By default, these agents are lightweight, but the catch is that some Agents could be resource-intensive. Weâ€™re going to find out later.&lt;/p&gt;
    &lt;head rend="h2"&gt;Despite the AI push, Microsoft still insists it deeply cares about power users&lt;/head&gt;
    &lt;p&gt;Ironically, this new agentic experience has been announced after Microsoftâ€™s Windows boss promised to improve Windows for everyone, including developers.&lt;/p&gt;
    &lt;p&gt;As Windows Latest reported recently, when Microsoftâ€™s Windows boss teased an â€œAgenticâ€ future for Windows, hundreds and thousands of users criticised the leadership. Microsoftâ€™s executive closed the replies/comments on his post to calm the public, but the move backfired as more users started shaming Windowsâ€™ Agentic shift.&lt;/p&gt;
    &lt;p&gt;Later, Microsoftâ€™s Windows boss promised that it would make Windows better for everyone, and it deeply cares about developers.&lt;/p&gt;
    &lt;p&gt;â€œWe know we have work to do on the experience, both on the everyday usability, from inconsistent dialogs to power user experiences. When we meet as a team, we discuss these paint points and others in detail, because we want developers to choose Windows,â€ says Pavan Davuluri, who is the boss of Windows and devices at Microsoft.â€&lt;/p&gt;
    &lt;p&gt;â€œâ€¦.Iâ€™ll boil it down, we care deeply about developers,â€ he added.&lt;/p&gt;
    &lt;p&gt;While the Experimental Agents Feature is optional, it makes it quite obvious Microsoft will not stop investing in AI for Windows 11, and Agentic OS is the future, whether you like it or not.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45959795</guid><pubDate>Mon, 17 Nov 2025 23:47:27 +0000</pubDate></item><item><title>Rebecca Heineman has died</title><link>https://www.pcgamer.com/gaming-industry/legendary-game-designer-programmer-space-invaders-champion-and-lgbtq-trailblazer-rebecca-heineman-has-died/</link><description>&lt;doc fingerprint="b06153b0a9e4610"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Legendary game designer, programmer, Space Invaders champion, and LGBTQ trailblazer Rebecca Heineman has died&lt;/head&gt;
    &lt;p&gt;Heineman's cancer fundraiser is now collecting for her funeral.&lt;/p&gt;
    &lt;p&gt;Game developer Rebecca Heineman has died after being diagnosed with cancer last month. The news was shared to Bluesky by Heineman's friend, Heidi McDonald, while the most recent post on Heineman's GoFundMe is a goodbye message stating that her health was rapidly deteriorating, and she was entering palliative care. Heineman was 62, and the GoFundMe will remain live to help her family make final arrangements.&lt;/p&gt;
    &lt;p&gt;Born in 1963, Heineman initially made a mark on the industry by winning a national Space Invaders tournament in 1980 in New York, becoming the first formally recognized US champion of any videogame. She went on to have a far-reaching career, being credited on 67 games according to MobyGames.&lt;/p&gt;
    &lt;p&gt;Heineman co-founded Interplay in 1983 alongside Brian Fargo, Jay Patel, and Troy Worrell. The developer and publisher was the source of many foundational PC games, including Wasteland, Fallout, and Baldur's Gate. Heineman designed and programmed a number of games at Interplay, with her most prominent design credit being The Bard's Tale 3: Thief of Fate.&lt;/p&gt;
    &lt;p&gt;Heineman's friend and colleague from Interplay, Brian Fargo, shared a remembrance of the developer on X. "Rebecca Heineman sadly passed away," Fargo wrote. "Known her since the 80s when I'd drive her to work, one of the most brilliant programmers around. A real gut punch earlier today when she messaged me: 'We have gone on so many adventures together! But, into the great unknown! I go first!!!'"&lt;/p&gt;
    &lt;p&gt;Later, in the '90s and 2000s, Heineman made a name primarily as a programmer, particularly on ports like the Macintosh versions of Wolfenstein 3D, Baldur's Gate, and Icewind Dale. The saga of Heineman overcoming a deranged businessman to solo program the ill-fated 3DO port of Doom in mere weeks has become a bit of an internet legend: Here's Digital Foundry and Heineman herself recounting the tale.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Rebecca Heineman sadly passed away. Known her since the 80s when I'd drive her to work, one of the most brilliant programmers around. A real gut punch earlier today when she messaged me: "We have gone on so many adventures together! But, into the great unknown! I go first!!!" :( pic.twitter.com/lu3i0fyt5CNovember 17, 2025&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Heineman publicly came out as transgender in the 2000s, and was married to fellow games industry legend Jennell Jaquays. Heineman was the recipient of Gayming's 2025 Gayming Icon award, with the site writing that "her advocacy for LGBTQ+ inclusion, accessibility, and diversity in tech has inspired countless developers and players."&lt;/p&gt;
    &lt;p&gt;Jaquays died of complications from Guillainâ€“BarrÃ© syndrome in January 2024, and Heineman was blindsided last month by an aggressive cancer diagnosis. She turned to GoFundMe to help with the costs of treatment, where fans, friends, and industry peers showed up to support the developer.&lt;/p&gt;
    &lt;p&gt;Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team.&lt;/p&gt;
    &lt;p&gt;Heineman shared the message last night that her health was rapidly declining.&lt;/p&gt;
    &lt;p&gt;"It's time. According to my doctors. All further treatments are pointless," Heineman wrote. "So, please donate so my kids can create a funeral worthy of my keyboard, Pixelbreaker! So I can make a worthy entrance for reuniting with my one true love, Jennell Jaquays."&lt;/p&gt;
    &lt;p&gt;Game developers have begun sharing their own condolences and remembrances in the wake of Heineman's death.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Rebecca was one of the founders of Interplay and programmed &amp;amp; designed for some of the most influential games of my youth, notably Bard's Tale I &amp;amp; III and Wasteland. She will be missed.&lt;/p&gt;â€” @jesawyer.bsky.social (@jesawyer.bsky.social.bsky.social) 2025-11-18T00:17:03.191Z&lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;A game industry legend died a few mins ago, Rebecca Heineman (@burgerbecky), taken away by aggressive lung cancer. She oversaw the porting of Wizordum to the Mac OS most recently for Apogee. My local friends would often have dinner with her and I loved her industry stories andâ€¦November 17, 2025&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;&lt;p&gt;What a remarkable human, and what a remarkable thing to know that she passed bemused at reading her own eulogies. Rest in peace, Rebecca. Thank you for everything.&lt;/p&gt;â€” @ramiismail.com (@ramiismail.com.bsky.social) 2025-11-18T00:15:53.662Z&lt;/quote&gt;
    &lt;quote&gt;&lt;p&gt;Rebecca was in my life because she reached out to me, a stranger, because she'd caught wind of a layoff I was impacted by. Her achievements were great, and so too was her kindness.&lt;/p&gt;â€” @jyoungman.bsky.social (@jyoungman.bsky.social.bsky.social) 2025-11-18T00:15:53.699Z&lt;/quote&gt;
    &lt;quote&gt;&lt;p&gt;Rest well, you legend, you pioneer, you wonderful soul. I'm lucky to have known you, though briefly. Please share her legacy by reposting Heidi's message. ğŸ’–&lt;/p&gt;â€” @caseymongillo.bsky.social (@caseymongillo.bsky.social.bsky.social) 2025-11-18T00:15:53.712Z&lt;/quote&gt;
    &lt;quote&gt;&lt;p&gt;in the early 2000s Rebecca took the time to chat over IRC with a teenaged and gender-confused Me on the practicalities of transition - in a time where being out as trans online was something that could get you socially ostracized. I owe her a lot for that and only hope I can pay it forward.&lt;/p&gt;â€” @moomanibe.bsky.social (@moomanibe.bsky.social.bsky.social) 2025-11-18T00:15:53.675Z&lt;/quote&gt;
    &lt;p&gt;2025 games: This year's upcoming releases&lt;lb/&gt;Best PC games: Our all-time favorites&lt;lb/&gt;Free PC games: Freebie fest&lt;lb/&gt;Best FPS games: Finest gunplay&lt;lb/&gt;Best RPGs: Grand adventures&lt;lb/&gt;Best co-op games: Better together&lt;/p&gt;
    &lt;p&gt;Ted has been thinking about PC games and bothering anyone who would listen with his thoughts on them ever since he booted up his sister's copy of Neverwinter Nights on the family computer. He is obsessed with all things CRPG and CRPG-adjacent, but has also covered esports, modding, and rare game collecting. When he's not playing or writing about games, you can find Ted lifting weights on his back porch. You can follow Ted on Bluesky.&lt;/p&gt;
    &lt;p&gt;You must confirm your public display name before commenting&lt;/p&gt;
    &lt;p&gt;Please logout and then login again, you will then be prompted to enter your display name.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45960368</guid><pubDate>Tue, 18 Nov 2025 01:25:54 +0000</pubDate></item><item><title>Unofficial "Tier 4" Rust Target for older Windows versions</title><link>https://github.com/rust9x/rust</link><description>&lt;doc fingerprint="ac60d61a319bb854"&gt;
  &lt;main&gt;
    &lt;p&gt;This is the main source code repository for Rust. It contains the compiler, standard library, and documentation.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Performance: Fast and memory-efficient, suitable for critical services, embedded devices, and easily integrated with other languages.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Reliability: Our rich type system and ownership model ensure memory and thread safety, reducing bugs at compile-time.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Productivity: Comprehensive documentation, a compiler committed to providing great diagnostics, and advanced tooling including package manager and build tool (Cargo), auto-formatter (rustfmt), linter (Clippy) and editor support (rust-analyzer).&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Read "Installation" from The Book.&lt;/p&gt;
    &lt;p&gt;If you really want to install from source (though this is not recommended), see INSTALL.md.&lt;/p&gt;
    &lt;p&gt;See https://www.rust-lang.org/community for a list of chat platforms and forums.&lt;/p&gt;
    &lt;p&gt;See CONTRIBUTING.md.&lt;/p&gt;
    &lt;p&gt;Rust is primarily distributed under the terms of both the MIT license and the Apache License (Version 2.0), with portions covered by various BSD-like licenses.&lt;/p&gt;
    &lt;p&gt;See LICENSE-APACHE, LICENSE-MIT, and COPYRIGHT for details.&lt;/p&gt;
    &lt;p&gt;The Rust Foundation owns and protects the Rust and Cargo trademarks and logos (the "Rust Trademarks").&lt;/p&gt;
    &lt;p&gt;If you want to use these names or brands, please read the media guide.&lt;/p&gt;
    &lt;p&gt;Third-party logos may be subject to third-party copyrights and trademarks. See Licenses for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45960852</guid><pubDate>Tue, 18 Nov 2025 02:46:50 +0000</pubDate></item><item><title>LeJEPA</title><link>https://arxiv.org/abs/2511.08544</link><description>&lt;doc fingerprint="acdc242ad4ffc2ae"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Machine Learning&lt;/head&gt;&lt;p&gt; [Submitted on 11 Nov 2025 (v1), last revised 14 Nov 2025 (this version, v3)]&lt;/p&gt;&lt;head rend="h1"&gt;Title:LeJEPA: Provable and Scalable Self-Supervised Learning Without the Heuristics&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:Learning manipulable representations of the world and its dynamics is central to AI. Joint-Embedding Predictive Architectures (JEPAs) offer a promising blueprint, but lack of practical guidance and theory has led to ad-hoc R&amp;amp;D. We present a comprehensive theory of JEPAs and instantiate it in {\bf LeJEPA}, a lean, scalable, and theoretically grounded training objective. First, we identify the isotropic Gaussian as the optimal distribution that JEPAs' embeddings should follow to minimize downstream prediction risk. Second, we introduce a novel objective--{\bf Sketched Isotropic Gaussian Regularization} (SIGReg)--to constrain embeddings to reach that ideal distribution. Combining the JEPA predictive loss with SIGReg yields LeJEPA with numerous theoretical and practical benefits: (i) single trade-off hyperparameter, (ii) linear time and memory complexity, (iii) stability across hyper-parameters, architectures (ResNets, ViTs, ConvNets) and domains, (iv) heuristics-free, e.g., no stop-gradient, no teacher-student, no hyper-parameter schedulers, and (v) distributed training-friendly implementation requiring only $\approx$50 lines of code. Our empirical validation covers 10+ datasets, 60+ architectures, all with varying scales and domains. As an example, using imagenet-1k for pretraining and linear evaluation with frozen backbone, LeJEPA reaches 79\% with a ViT-H/14. We hope that the simplicity and theory-friendly ecosystem offered by LeJEPA will reestablish self-supervised pre-training as a core pillar of AI research (\href{this https URL}{GitHub repo}).&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Randall Balestriero [view email]&lt;p&gt;[v1] Tue, 11 Nov 2025 18:21:55 UTC (12,072 KB)&lt;/p&gt;&lt;p&gt;[v2] Wed, 12 Nov 2025 14:26:39 UTC (12,072 KB)&lt;/p&gt;&lt;p&gt;[v3] Fri, 14 Nov 2025 08:38:32 UTC (12,072 KB)&lt;/p&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;cs.LG&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;p&gt; IArxiv Recommender (What is IArxiv?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45960922</guid><pubDate>Tue, 18 Nov 2025 02:58:31 +0000</pubDate></item><item><title>The surprising benefits of giving up</title><link>https://nautil.us/the-surprising-benefits-of-giving-up-1248362/</link><description>&lt;doc fingerprint="37f482b945538782"&gt;
  &lt;main&gt;
    &lt;p&gt;You mightâ€™ve been told to â€œhang in thereâ€ throughout your childhood, as illustrated by a kitten dangling from a rope. But it turns out that quitting might often be your healthiest option.&lt;/p&gt;
    &lt;p&gt;Researchers have long sought to understand how persistence is linked to personal well-being and human evolution more broadly. One poorly supported theory posited that our ancestors were so determined to catch prey that they ran for long stretches in hot, dry environments.&lt;/p&gt;
    &lt;p&gt;Newer evidence suggests that ditching tough-to-attain goals can actually be good for us. According to a review of more than 230 studies recently published in the journal Nature Human Behaviour, adjusting our goals in response to stress or challenges, rather than grinding on, is often â€œa more appropriate and beneficial response.â€&lt;/p&gt;
    &lt;p&gt;The authors of the sweeping meta-analysis examined 235 studies spanning various fields, including psychology, health, and social sciences, that detailed how people shift their goals after encountering obstacles to success. The researchers wanted to consolidate this â€œfragmentedâ€ information and observe how adjusting goals relates not only to psychological well-being but also physical health, social functioning, and future ambitions. This allowed them to chart a goal â€œroadmap.â€&lt;/p&gt;
    &lt;p&gt;Read more: â€œWe Can Be Heroesâ€&lt;/p&gt;
    &lt;p&gt;â€œSticking with impossible goals can take a real toll, with previous research suggesting it can lead to higher stress, poorer well-being, and even physical health costs such as illness,â€ said study author Hugh Riddell, a professor at the School of Population Health at Curtin University in Australia, in a statement. â€œBut letting go andâ€”cruciallyâ€”reengaging with new goals, was found to restore purpose and well-being.â€&lt;/p&gt;
    &lt;p&gt;The team employed statistical analysis to illuminate what causes people to ditch, adjust, or re-engage with goals. Disengagement from goals, for example, was most strongly linked to negative feedback on these ideas and an â€œaction crisisâ€ stemming from oneâ€™s failure to overcome related obstacles. Our personalities might also play a major role in these types of decisions: Optimism tended to be strongly linked to oneâ€™s openness to revise a goal to better fit their skills and resources. â€œThese findings indicate that goal-striving flexibility is more likely to emerge when individuals feel secure, exhibit stable regulation, and possess emotional resilience,â€ the paper notes.&lt;/p&gt;
    &lt;p&gt;The scientists also analyzed the impacts of these decisions. Giving up on goals was significantly linked to reduced stress, anxiety, and depression, for instance. And adopting new ones was strongly associated with high social and physical functioning. Finding new goals also came with moderate to large benefits to psychological functioning, feeling a sense of purpose in life, satisfaction, and personal growth.&lt;/p&gt;
    &lt;p&gt;This analysis comes with limitations, the authors acknowledge, due to observational data collected at specific points in time and risks of bias in individual papers. The next step, they write, is to pinpoint the specific moment that people should rethink their dreams or keep on chugging. â€œFinding out when exactly people should stick with their goals or change course, without giving up too early, is really the next piece of the puzzle,â€ Riddell said in the statement.&lt;/p&gt;
    &lt;p&gt;So whether youâ€™re the type to stick with it to the bitter end or change course when you sense trouble up ahead, there may be an optimal method to help you achieveâ€”or alterâ€”your goals.&lt;/p&gt;
    &lt;p&gt;Enjoying Nautilus? Subscribe to our free newsletter.&lt;/p&gt;
    &lt;p&gt;Lead image: eamesBot / Shutterstock&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45961481</guid><pubDate>Tue, 18 Nov 2025 04:44:21 +0000</pubDate></item><item><title>Langfuse (YC W23) Hiring OSS Support Engineers in Berlin and SF</title><link>https://jobs.ashbyhq.com/langfuse/5ff18d4d-9066-4c67-8ecc-ffc0e295fee6</link><description>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45962178</guid><pubDate>Tue, 18 Nov 2025 07:00:50 +0000</pubDate></item><item><title>How Quake.exe got its TCP/IP stack</title><link>https://fabiensanglard.net/quake_chunnel/index.html</link><description>&lt;doc fingerprint="2eea993caa203e87"&gt;
  &lt;main&gt;
    &lt;p&gt;Released in June 1996, Quake had to ride three technological shock-waves during its lifetime. Besides the emergence of 3D hardware accelerator cards and the growth of the Internet, an operating system shift put game developers in a tough position.&lt;/p&gt;
    &lt;p&gt;With its push for Windows 95 and Windows NT, Microsoft was replacing its legacy PC operating system, MS-DOS. From 1996 to 1997, the market share of DOS dropped by 50%. Some developers, like Blizzard North, took the leap of faith and wrote Windows 95â€“exclusive titles such as Diablo. id Software on the other hand went through the effort of producing a single binary, &lt;code&gt;quake.exe&lt;/code&gt;, able to run on both DOS and Windows.&lt;/p&gt;
    &lt;p&gt;What is even more impressive is that id managed to make Quake better when Windows 95 TCP/IP stack was available. Here is how they did it.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;quake.exe&lt;/code&gt; is a DOS executable. id Software had used &lt;code&gt;Watcom&lt;/code&gt; compiler for DOOM but they switched to a GCC port named &lt;code&gt;djgpp&lt;/code&gt;[1] to cross-compile Quake on Alpha servers.&lt;/p&gt;
    &lt;quote&gt;$ file quake.exe quake.exe: MS-DOS executable, COFF for MS-DOS, DJGPP go32 DOS extender&lt;/quote&gt;
    &lt;p&gt;Alike &lt;code&gt;watcom&lt;/code&gt;'s &lt;code&gt;DOS/4GW&lt;/code&gt;, &lt;code&gt;djgpp&lt;/code&gt; offered to developers an extender allowing to write programs with flat 32-bit addressing instead of the dreaded 16-bit near/far hellish real-mode otherwise mandated by DOS. An extender works with a client and a server. In the case of Quake the extender client is embedded in &lt;code&gt;quake.exe&lt;/code&gt; while the server is in &lt;code&gt;cwsdpmi.exe&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;From the beginning of the development, id had requested from &lt;code&gt;djgpp&lt;/code&gt; engineers that their DPMI client would be able to run on &lt;code&gt;djgpp&lt;/code&gt;'s DPMI server but also Windows 95 DPMI server.&lt;/p&gt;
    &lt;p&gt;It may not be apparent how much of a tour-de-force it was for &lt;code&gt;djgpp&lt;/code&gt; to make their DPMI client work with another DPMI server but knowing a little about how it works, it blows me away. Raymond Chen, Microsoft kernel engineer at the time, had the best description of how to perceive this situation.&lt;/p&gt;
    &lt;quote&gt;The client application was written with the assumption that it is using the MS-DOS extender that is included with the application, but in reality it is talking to the DPMI host that comes with Windows.&lt;lb/&gt;The fact that programs seem to run mostly okay in spite of running under a foreign extender is either completely astonishing or totally obvious, depending on your point of view.&lt;lb/&gt;Itâ€™s completely astonishing because, well, youâ€™re taking a program written to be run in one environment, and running it in a different environment. Or itâ€™s totally obvious because they are using the same DPMI interface, and as long as the interface has the same behavior, then naturally the program will continue to work, because thatâ€™s why we have interfaces!&lt;lb/&gt;- Raymond Chen[2]&lt;/quote&gt;
    &lt;p&gt;Being able to run with Windows 95 DPMI server was how &lt;code&gt;quake.exe&lt;/code&gt; pulled off the ability to run under both DOS and Windows 95.&lt;/p&gt;
    &lt;p&gt;DOOM only needed two files to run, &lt;code&gt;doom.exe&lt;/code&gt; and &lt;code&gt;doom.wad&lt;/code&gt; but there are many files that came with Quake.&lt;/p&gt;
    &lt;quote&gt;$ find quake ./mgenvxd.vxd ./genvxd.dll ./qlaunch.exe ./id1/pak0.pak ./pdipx.com ./cwsdpmi.exe ./q95.bat ./id1/config.cfg ./quake.exe ./quakeudp.dll&lt;/quote&gt;
    &lt;p&gt;It looks like a mess at first sight but running Quake under DOS only requires four files. Namely, the game engine &lt;code&gt;quake.exe&lt;/code&gt;, the config file &lt;code&gt;config.cfg&lt;/code&gt;, the asset file &lt;code&gt;pak0.pak&lt;/code&gt;, and the DOS extender server &lt;code&gt;cwsdpmi.exe&lt;/code&gt;.&lt;/p&gt;
    &lt;quote&gt;./mgenvxd.vxd ./genvxd.dll ./qlaunch.exe ./id1/pak0.pak ./pdipx.com ./cwsdpmi.exe ./q95.bat ./id1/config.cfg ./quake.exe ./quakeudp.dll&lt;/quote&gt;
    &lt;p&gt;Quake supported four types of multiplayer protocols.&lt;/p&gt;
    &lt;p&gt;Two modes allowed gamers to enter a duel (1v1). Both modes expected a device plugged into the COM port of the PC. A modem allowed to call an opponent's phone number (hello $$$) while a NullModem cable (called here "Direct Connect") required both computers to be a few feet apart.&lt;/p&gt;
    &lt;p&gt;Both IPX and TCP/IP allowed a much more interesting deathmatch featuring up to 16 players. IPX technology was intended for LAN where all machines were a few feet apart, while TCP/IP allowed to reach anybody worldwide.&lt;/p&gt;
    &lt;p&gt;Notice how, under DOS, by default, both IPX and TCP modes were disabled (greyed out).&lt;/p&gt;
    &lt;p&gt;Quake came with PDIPX.EXE which loaded an IPX DOS TSR. That TSR communicated with a packet driver which in turn hit the network card. Quake was able to probe for that DOS TSR and upon detection allowed players to select IPX.&lt;/p&gt;
    &lt;p&gt;Using TCP/IP was nearly impossible. DOS did not come with a TCP/IP stack and it was something complex enough that only a single vendor provided a TSR for it on DOS.&lt;/p&gt;
    &lt;p&gt;The TSR name was BWNFS. Made by Beame &amp;amp; Whiteside, its cost $395 in 1996 ($830 in 2025!)[3]. It is reasonable to say that few gamers ever used TCP/IP on DOS to play QUAKE.&lt;/p&gt;
    &lt;p&gt;Starting &lt;code&gt;quake.exe&lt;/code&gt; from Windows 95 works like a charm. The executable is loaded into a Windows 95 "dos-box"[4] that virtualizes memory, interrupts, and signals[5]. The game ran exactly like under DOS with the same multiplayer choices available. It was convenient since users did not have to load any mouse driver or set up the &lt;code&gt;BLASTER&lt;/code&gt; environment variable to make the sound card work.&lt;/p&gt;
    &lt;p&gt; Much less convenient however, this way to run Quake requires 16 MiB RAM. Quake only needs 8 MiB but Windows 95 adds quite a bit of overhead! The same files used when running from DOS are used here as well, except for &lt;code&gt;cwsdpmi.exe&lt;/code&gt;, since the DJGPP client detects and uses Windowsâ€™ built-in DPMI server.&lt;/p&gt;
    &lt;quote&gt;./mgenvxd.vxd ./genvxd.dll ./qlaunch.exe ./id1/pak0.pak ./pdipx.com ./cwsdpmi.exe ./q95.bat ./id1/config.cfg ./quake.exe ./quakeudp.dll&lt;/quote&gt;
    &lt;p&gt;It is impressive to see Quake run at full speed knowing that Windows 95 runs DOS executable in a virtual machine. My guess is that, in full screen, memory writes and reads to the VGA are given direct access to the hardware to preserve performances.&lt;/p&gt;
    &lt;p&gt;Starting &lt;code&gt;quake.exe&lt;/code&gt; from DOS or Windows are not the only two options to run Quake. There is a third one which is to launch &lt;code&gt;q95.bat&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;In this case, a window "Launching Quake" briefly pops up on Windows 95 desktop.&lt;lb/&gt; The text gives a clue about what is happening. Quake is loaded with a tunnel to Winsock, Microsoft's TCP/IP stack. There is further indication of what is doing that, "Powered by Mpath". But not much more to explain how this all works.&lt;/p&gt;
    &lt;p&gt;Mpath Interactive was a company dedicated to online gaming. They provided subscription services to help gamers find each other but also operated as an ISP reseller.[6]. It was in their interest to help gaming companies to release titles allowing Internet play as Larry Hastings, an Mpath employee at the time, recalls.&lt;/p&gt;
    &lt;quote&gt;Back then in the primordial ooze that was the mid-90s internet, online multiplayer was still in its infancy. If you wanted to play a multiplayer game on the internet, either you needed to have explicit host &amp;amp; port information, or you needed to use an online multiplayer gaming service. And in 1995 there were only two: us, and Total Entertainment Network. You might think game creators would come to us and say "please put my game on your service!", but... nope! Not only did we have a licensing team that went out and got contracts to license games for our service, but we had to pay the vendor for the right to license their game, which was often an exclusive. So, we had Quake and Unreal; TEN got Duke Nukem 3D and NASCAR.&lt;lb/&gt;The user experience for Mplayer was like this. First, you'd run the "Gizmo", which was a Windows program that acted as a sort of game browser. It knew which compatible games you had installed, and it'd let you browse the multiplayer games on offer for each game; the metaphor we used for this was a "room". Quake was drop-in, so you could simply find a game in progress and hop right in--not a feature of very many games back then. Alternatively, you could find a "room" where someone was proposing to launch a game soon. Or you could create your own. You'd set the name of the room, and the Mplayer Gizmo had some per-game UI that let you set the settings for the game (what map, what features, etc). The room featured text and audio chat, and even a shared "whiteboard", a simple paint program. Once the owner of the "room" "launched" the game, everyone's Gizmos would automatically start the game for them, and the game would automatically join that online game and start playing.&lt;lb/&gt;In order for a game to run on Mplayer, it had to integrate with the Mplayer software stack. Mostly this integration work was done by Mpath engineers; we'd get source code from the game developer and "porting engineers" would get it to run on Mplayer. This often included modifying both the client and the server, so that both could talk via Mplayer's servers.&lt;lb/&gt;The early version of Quake was DOS only, and used the Chunnel to talk to the Windows 95 TCP/IP stack. (Which in retrospect makes the "Chunnel" a type of "thunk", like Microsoft's "Win32s".) I think the deal was, we licensed the Chunnel to id, and in return for that we got to have Quake on Mplayer. So, DOS Quake supported running on Mplayer via the Chunnel, in addition to connecting to open game servers on the Internet via host and port.&lt;lb/&gt;- Larry Hastings (Email conversation)&lt;/quote&gt;
    &lt;p&gt;Larry was kind enough to share some Quake anecdotes.&lt;/p&gt;
    &lt;quote&gt;One afternoon shortly after we got our first build of the game, we played a round of deathmatch with the id team over the internet. We were in Cupertino, CA, in a building on Bandley Drive (now a "Fitness Center" for Apple employees). They of course were in Mesquite TX. Yup, it was deathmatch over the internet--very exciting!&lt;lb/&gt;The only id employee I remember for sure being in the game was Tim Willits. He owned us, both because he was way more used to Quake, but also because he knew where all the secrets were. At one point I spotted him coming out of a secret doorway with a rocket launcher. And either he didn't see me, or I died shortly thereafter.&lt;lb/&gt;- Larry Hastings (Email conversation)&lt;/quote&gt;
    &lt;p&gt;As for explaining how the Chunnel worked, I was out of luck.&lt;/p&gt;
    &lt;quote&gt;I didn't work on the Chunnel. That was mainly a British guy named Henry but I don't remember his last name, it was thirty years ago. All I remember about him is what he looked like, and the fact that he drove a cool car, a white Merkur XR4Ti.&lt;lb/&gt;- Larry Hastings (Email conversation)&lt;/quote&gt;
    &lt;p&gt;When everything else fails, we still have Ghidra and doomworld's amazing community (thanks xttl[7]). After much decompiling and talking, it turned out all files previously ignored were part of Mpath's "Chunnel".&lt;/p&gt;
    &lt;quote&gt;./mgenvxd.vxd ./genvxd.dll ./qlaunch.exe ./id1/pak0.pak ./pdipx.com ./cwsdpmi.exe ./q95.bat ./id1/config.cfg ./quake.exe ./quakeudp.dll&lt;/quote&gt;
    &lt;p&gt;&lt;code&gt;q95.bat&lt;/code&gt; is just a small script to launch mpath's main program. &lt;code&gt;qlauncher.exe&lt;/code&gt; contains all the MPlayer functions. However the role of this executable is limited.&lt;/p&gt;
    &lt;p&gt;It merely loads &lt;code&gt;quakeudp.dll&lt;/code&gt;. Despite its confusing name, this DLL is the heart of Quake Chunnel. It is the bridge to Microsoft TCP/UDP/IP stack (&lt;code&gt;wsock32.dll&lt;/code&gt;). It also starts Quake with &lt;code&gt;-path&lt;/code&gt; parameter to make it load a BSD network socket API &lt;code&gt;sys/socket.h&lt;/code&gt;. Finally, it also loads the virtual device driver manager &lt;code&gt;genvxd.dll&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The virtual device is the trick that allows a DOS executable running inside a Windows 95 dos box to communicate with win32. The &lt;code&gt;genvxd.dll&lt;/code&gt; dynamic library loads a virtual device driver[8] named &lt;code&gt;GENVXD.VXD&lt;/code&gt; which installs itself to respond on interrupt &lt;code&gt;0x48&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The last piece of the puzzle is on Quake side. The implementation of BSD &lt;code&gt;sys/socket.h&lt;/code&gt;, &lt;code&gt;mpplc.c&lt;/code&gt;, is code provided by Mpath. It takes care of marshaling every BSD socket function call, then use the DPMI client to trigger a software interrupt that is received in win32 land. Data is passed up the pipeline we previously described until it is unmarshalled by &lt;code&gt;genvxd.dll&lt;/code&gt; and routed towards &lt;code&gt;wsock32.dll&lt;/code&gt;. Notice the symmetry of functions found in &lt;code&gt;mplib.c&lt;/code&gt; marshalling and the symbols found in &lt;code&gt;genvxd.dll&lt;/code&gt; unmarshalling.&lt;/p&gt;
    &lt;p&gt;It seems John Cash was involved in compiling Mpath's stuff. We can find his name in the symbols of &lt;code&gt;mgenvxd.vxd&lt;/code&gt;.&lt;/p&gt;
    &lt;quote&gt;F:\cashcode\GENVXD\bin\Mgenvxd.pdb&lt;/quote&gt;
    &lt;p&gt;The source code of mgenvxd.vxd, genvxd.dll, qlaunch.exe and quakeudp.dll was never released. It was a proprietary, patented technology from Mpath. It is likely id only got permission to release the client side of it.&lt;/p&gt;
    &lt;p&gt;As far as I understood it, that is how Quake was able to send TCP and UDP packets over IP. This convoluted construct became obsolete when id stopped shipping DOS executable (the last one being &lt;code&gt;vquake.exe&lt;/code&gt;). After Dec 1996, &lt;code&gt;winquake.exe&lt;/code&gt;, &lt;code&gt;glquake.exe&lt;/code&gt;, and all QuakeWorld binaries were win32 exclusive with direct access to &lt;code&gt;wsock32.dll&lt;/code&gt;.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45962654</guid><pubDate>Tue, 18 Nov 2025 08:18:35 +0000</pubDate></item><item><title>Comparing Android Alternatives: Lineage OS, âˆ•Eâˆ•OS, and Graphene OS</title><link>https://kevinboone.me/lineage-eos-graphene.html</link><description>&lt;doc fingerprint="261cf9b790612a05"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Comparing Android alternatives: Lineage OS, âˆ•eâˆ•OS, and Graphene OS&lt;/head&gt;
    &lt;p&gt;A significant part of the de-Googling experience is finding ways to replace a smartphone vendorâ€™s bloated, data-siphoning firmware with something more acceptable. While at one time the main focus of Android â€˜custom ROMsâ€™ was hacking and customization, the projects that have survived to the present day seem to focus more on improvements to privacy and security. Consequently, interest in this area may actually be increasing a little, with new and updated firmwares becoming available on a regular basis.&lt;/p&gt;
    &lt;p&gt;In this article I compare three open-source Android-derived firmwares: Lineage OS, âˆ•eâˆ•OS, and Graphene OS. There are others; Iâ€™m focusing on these three because I have most experience with them.&lt;/p&gt;
    &lt;p&gt;Despite what their proponents sometimes claim, these firmwares have more commonalities than differences. All are derived from the Android Open-Source Project (AOSP), so they look similar, and offer similar features. Youâ€™ll need the same tools and skills to install them all. However, the differences are significant, and may not be obvious on casual inspection.&lt;/p&gt;
    &lt;p&gt;Iâ€™m trying to be unbiased here, because I recognize that we all have different views on what makes for the best compromise between privacy, security, and convenience. However, I do have an opinion on which is best, at least for me, and I canâ€™t help my preference being somewhat visible.&lt;/p&gt;
    &lt;p&gt;Iâ€™ll start with Lineage because itâ€™s the oldest of the three and, in some sense, the ancestor. Then Iâ€™ll review âˆ•eâˆ•OS and Graphene, largely in comparison with Lineage.&lt;/p&gt;
    &lt;head rend="h2"&gt;Lineage OS&lt;/head&gt;
    &lt;p&gt;Lineage OS is one of the best-established alternative Android firmwares, dating back to Cyanogen, the first really popular â€˜custom ROMâ€™. A standard installation is quite minimal, and doesnâ€™t include Google Play Services, or even a substitute for it like MicroG. You can install these things later if you wish. In its basic form, Lineage is snappy in use, and allows pretty good battery life, because thereâ€™s little going on to drain the battery.&lt;/p&gt;
    &lt;p&gt;The set-up process for Lineage starts with installing a custom recovery application (which means first unlocking the bootloader, which in turn means erasing all data), and then using the custom recovery to install the rest of the system. In general, getting the custom recovery loaded is the tricky part of the process, and the method differs between devices. An increasing number of handsets doesnâ€™t allow the bootloader to be unlocked at all, which is showstopper for the installation of any firmware, not just Lineage.&lt;/p&gt;
    &lt;p&gt;Nevertheless, Lineage still supports a good range of handsets â€“ even more if youâ€™re willing to use out-of-date builds. Of course, this isnâ€™t encouraged, but an out-of-date Lineage might still be more up-to-date than anything provided by the handset vendor. Iâ€™ve used Lineage successfully on Samsung, Sony, Google Pixel, and NVidia devices, both phones and tablets.&lt;/p&gt;
    &lt;p&gt;Although it has little that can be called â€˜bloatâ€™, Lineage is not a bare-bones installation. It includes a camera app, gallery, music player, contact manager, and calendar. Itâ€™s probably fair to say that better, open-source replacements exist for all these built-in apps, although thereâ€™s nothing in particular wrong with any of them.&lt;/p&gt;
    &lt;p&gt;Lineageâ€™s basic user interface will look more familiar to some handset users than others. Itâ€™s much like the stock interface on the Google Pixel range, and very different from Samsungâ€™s â€œOne UIâ€. You get some control over styling and themes, but not as much as in some earlier firmwares.&lt;/p&gt;
    &lt;p&gt;The Lineage maintainers are not, so far as I know, associated with any providers of on-line services, like email and calendar. Youâ€™ll need to find those services for yourself, if you need them, and install whatever apps you need to use them. Thereâ€™s no Google Play store, of course, but you can install F-Droid or another alternative store from its APK, and then use that to install other apps.&lt;/p&gt;
    &lt;p&gt;With no Google services, or any way to fake them, commercial apps often struggle on Lineage. Lineage might be a bad choice if you need to use subscription apps, or those that are funded by Googleâ€™s advertising infrastructure. Of course, you might struggle even to install such apps, without access to the Google Play store.&lt;/p&gt;
    &lt;p&gt;If you want to root your Lineage installation, itâ€™s not difficult: just boot into the Lineage custom recovery, and then use &lt;code&gt;adb sideload&lt;/code&gt; to push the Magisk installer from a computer.
The Magisk app can then do the rest of the work. This process takes less
than ten minutes. Of course, rooting reduces the compatibility with
commercial apps even further, so the benefits need to outweigh the
costs. Although Lineage is popular with tinkerers and enthusiasts, its
maintainers are increasingly trying to present their platform as a
mainstream one, and are no longer very supportive of users modifying
it.&lt;/p&gt;
    &lt;p&gt;Lineage has a few, well-documented privacy weaknesses. Most obviously, it uses the Chromium WebView implementation, which is slightly leaky. I donâ€™t regard these minor leaks as highly troublesome, but âˆ•eâˆ•OS and Graphene plug them anyway.&lt;/p&gt;
    &lt;p&gt;Apart from these minor issues, Lineage is reasonably good at avoiding leaks of personal data, so long as you donâ€™t install apps that do this anyway. Itâ€™s not so good at low-level security. It does little to sandbox or virtualize apps at the kernel level, for example. Thereâ€™s no â€˜attestationâ€™ mechanism, to verify that firmware hasnâ€™t been tampered with. If youâ€™re worried about â€˜evil maidâ€™ intrusions, or even about apps that try to interfere with one another, Graphene might be a better bet.&lt;/p&gt;
    &lt;p&gt;The fact that it isnâ€™t usually possibly to relock the bootloader after installation is seen as a weakness by some authorities, but Iâ€™m not overly concerned about this. If I were a vulnerable person, or likely to be a target, I might feel differently.&lt;/p&gt;
    &lt;p&gt;Lineageâ€™s main venue for support and discussion is on Reddit, unfortunately. Thereâ€™s an IRC channel on Libera.Chat which is reasonably responsive, but not particularly helpful, and not at all polite.&lt;/p&gt;
    &lt;p&gt;All in all, Lineage is a good choice for a technically-sophisticated person who wants a privacy-sparing, bloat-free smartphone that isnâ€™t too hampered by the side-effects of low-level security hardening. Itâ€™s particularly appropriate if, like me, you use only apps that do not require any Google services.&lt;/p&gt;
    &lt;head rend="h2"&gt;âˆ•eâˆ•OS&lt;/head&gt;
    &lt;p&gt;âˆ•eâˆ•OS is a derivative of Lineage that aims for simplicity, and also plugs some of the minor privacy holes. âˆ•eâˆ•OS is closely associated with Murena, a commercial provider of PDA and email services. In fact, when you install âˆ•eâˆ•OS youâ€™re encouraged to create an account with Murena (more on that later). Because of the Murena association, âˆ•eâˆ•OS is less minimal than Lineage, providing some apps that not everybody will want. Some of these are associated with Murenaâ€™s services while some, like the email client, are more general. However, the general apps are unimpressive compared to other, open-source alternatives, and youâ€™ll have to root the device if you want to expunge them completely.&lt;/p&gt;
    &lt;p&gt;In addition, âˆ•eâˆ•OS includes MicroG, which is a privacy-sparing stub for Googleâ€™s services. The tight integration with MicroG wonâ€™t suit everybody, but thereâ€™s no denying it makes it easier to install commercial apps.&lt;/p&gt;
    &lt;p&gt;Installing âˆ•eâˆ•OS is exactly the same as installing Lineage, for better or worse. In fact, the custom recoveries of Lineage and âˆ•eâˆ•OS can install one anotherâ€™s systems.&lt;/p&gt;
    &lt;p&gt;Because âˆ•eâˆ•OS is derived from Lineage, itâ€™s a bit less up-to-date, and is slower to get security patches. On the other hand, specific handsets remain supported for a bit longer with âˆ•eâˆ•OS than with Lineage. Apart from fixing the small privacy leaks in Lineage, âˆ•eâˆ•OS doesnâ€™t seem to offer much extra in the way of security hardening.&lt;/p&gt;
    &lt;p&gt;In use, âˆ•eâˆ•OS looks just like Lineage, except for the extra app icons in the launcher. Itâ€™s just as fast and, in my tests, offers similar battery life.&lt;/p&gt;
    &lt;p&gt;The connection between âˆ•eâˆ•OS and Murena is an interesting one and, in fact, Murena sells smartphones with âˆ•eâˆ•OS pre-installed. Many people will find it helpful that a de-Googled handset has easy access to the kinds of services that Google would otherwise provide, but others worry about the potential conflict of interests. Murena professes a strong commitment to privacy, and does not sell its customersâ€™ data to advertisers. So Iâ€™d certainly trust it more than Google.&lt;/p&gt;
    &lt;p&gt;Of course, because Murena canâ€™t monetize your personal data, it charges for its services, but a subscription is not particularly expensive. A bigger concern I have is that Murena is a small company, and may not have the resources to support an expanding user base.&lt;/p&gt;
    &lt;p&gt;âˆ•eâˆ•OS looks like a good bet for somebody who wants a modest improvement in privacy and substantial reduction in bloatware over the vendorâ€™s firmware, and is likely to buy supporting services from Murena. I can see how, if youâ€™re not a geek, âˆ•eâˆ•OS with Murena might be a relatively painless entry into the de-Googled lifestyle.&lt;/p&gt;
    &lt;p&gt;So far as I can see, on-line support for âˆ•eâˆ•OS is intertwined with Murena. Their forum is easy to use and, unlike the Lineage folks, Murenaâ€™s staff are both polite and helpful. I presume theyâ€™re being paid. However, it takes a long time (perhaps days) to get a response to a technical question. So, for very different reasons, support for Murena seems to me little better than support for Lineage.&lt;/p&gt;
    &lt;head rend="h2"&gt;Graphene OS&lt;/head&gt;
    &lt;p&gt;While Lineage and âˆ•eâˆ•OS have a good deal in common, Graphene is rather different. The differences start with the installation process. Grapheneâ€™s installation is similar to the one Google provides for (re-)installing stock Android images: thereâ€™s a script or batch file that runs a bunch of &lt;code&gt;fastboot&lt;/code&gt; commands to install the
entire software set â€“ thereâ€™s no specific custom recovery. Provided you
have the necessary tools, and youâ€™ve unlocked the bootloader on the
device, the actual installation of Graphene is trivial â€“ just run a
script and wait.&lt;/p&gt;
    &lt;p&gt;Graphene also offers a web-based installation process, but it doesnâ€™t work with any web browser I use, so I didnâ€™t test it.&lt;/p&gt;
    &lt;p&gt;Unlike Lineage and âˆ•eâˆ•OS, Graphene supports only a small number of handsets, currently Google Pixel 6-9. The maintainers say that only these handsets have the hardware-level security features they require, and I have no reason to doubt this, although I donâ€™t understand the technical issue.&lt;/p&gt;
    &lt;p&gt;Graphene supports relocking the bootloader on the few supported devices and, in fact, this is advised.&lt;/p&gt;
    &lt;p&gt;A basic installation of Graphene doesnâ€™t look much different to âˆ•eâˆ•OS or Lineage, except that itâ€™s even more bare-bones. There are few built-in apps, not even a calendar. It does have an app store, however, with access to a small number of apps. Of course, you can still use alternative stores like F-Droid.&lt;/p&gt;
    &lt;p&gt;Graphene provides a high degree of security hardening, and has auditing and attestation services. I would expect it to be pretty resistant to â€˜evil maidâ€™ attacks, and offer fewer opportunities for rogue apps to grub around in your data.&lt;/p&gt;
    &lt;p&gt;Grapheneâ€™s approach to Google Play Services is completely different to that taken by âˆ•eâˆ•OS.&lt;lb/&gt; Rather than replacing Google services with an alternative like MicroG, Graphene allows a user to run the real Google Play Services (and the Google Play store) in a privacy sandbox. This means that the permissions allowed to Googleâ€™s services can be turned on and off, just as they can for a regular app. Google services canâ€™t leak private data without network permission, for example.&lt;/p&gt;
    &lt;p&gt;As I only use apps that have no dependence on Googleâ€™s services, I canâ€™t comment on whether the Graphene approach, or the use of MicroG, is better. I seem to be alone in my reticence, however: disagreements between supporters of Graphene and MicroG are often loud and acrimonious, with each side hurling abuse at the other on social media. Not very edifying, since we should really be on the same side.&lt;/p&gt;
    &lt;p&gt;I have mixed feelings about Grapheneâ€™s security hardening. On the one hand, thereâ€™s no doubt that a smartphone is a potential target, particular when itâ€™s effectively connected to the public Internet. We hear stories all the time of rogue apps inserting malware into handsets, some of which is disturbingly hard to remove. The security hardening, regular patch schedule, attestation features, and bootloader relocking does mean that Graphene has some chance of being recognized as trustworthy by paranoid apps, particularly those involved with banking and payments. Thatâ€™s unlikely to be the case with Lineage or âˆ•eâˆ•OS.&lt;/p&gt;
    &lt;p&gt;On the other hand, Grapheneâ€™s hardening does have side-effects, which may be minor irritations or show-stoppers, depending on your needs. For example, on my Pixel handset, the push-buttons on my USB-C headset have no effect under Graphene, regardless how much I fiddle with the settings. These controls work fine with Lineage and âˆ•eâˆ•OS, but Graphene has additional hardening associated with external ports. For many people, of course, this will just be a minor irritation, but itâ€™s one of many niggles I had with Graphene, that I didnâ€™t have with other firmware, that can be attributed to the increased hardware security.&lt;/p&gt;
    &lt;p&gt;If youâ€™re an undercover journalist reporting on an oppressive regime, youâ€™ll likely find these irritations worth living with. Similarly, you might find that fussy banking and payment apps work better with Graphene than with the other platforms, although comments Iâ€™ve read suggest that the theoretical improvements in this area are often not realized.&lt;/p&gt;
    &lt;p&gt;Unlike Lineage, Graphene was never a tinkererâ€™s platform. The maintainers discourage any kind of modification, and rooting in particular. You pretty much have to swallow it whole, whether you like the taste or not. Thatâ€™s inevitable, I guess, if you want to provide an operating system that is tolerated by banks.&lt;/p&gt;
    &lt;p&gt;Graphene has a lively and accessible discussion forum of its own, and another on Reddit. Unfortunately itâ€™s managed, and somewhat populated, by a community whose rudeness and arrogance is notable even in the weird world of niche open-source projects. Itâ€™s not unheard of for the moderators to delete posts that are critical of Graphene, or ban users who post such things.&lt;/p&gt;
    &lt;p&gt;Graphene would suit somebody who really has a good reason to think his smartphone will come under sustained, expert attack, or who really wants to run commercial apps, and has the expertise to use Grapheneâ€™s framework to do that safely.&lt;/p&gt;
    &lt;head rend="h2"&gt;Closing remarks&lt;/head&gt;
    &lt;p&gt;If you care about personal privacy, any replacement firmware will be an improvement over what a smartphone vendor provides. The trick, for most people, will be balancing the competing needs of privacy, compatibility, and convenience. Graphene ought to score highly in both privacy and compatibility, but it only supports a few devices, and its security hardening can make it quirky. âˆ•eâˆ•OS scores for convenience and support if youâ€™re a Murena customer, but has little to recommend it over Lineage otherwise, in my view. Lineage probably remains the geekâ€™s choice, despite the maintainersâ€™ increasing disdain for tinkering with it.&lt;/p&gt;
    &lt;p&gt;Using any replacement firmware will be inconvenient if youâ€™re tied to Googleâ€™s services, as many of us are. You can try to continue to use those services, but in a less privacy-crushing way, and Graphene and âˆ•eâˆ•OS purport to offer some help with that. However, I think youâ€™d need to be both knowledgeable and careful to use Google Services, even in these restrictive environments, without inadvertently sacrificing privacy. To my mind, if you want to de-Google, you have to find replacements for Google, not ways to appease Google.&lt;/p&gt;
    &lt;p&gt;One final point: none of the firmwares Iâ€™ve mentioned will maintain your privacy if you run a bunch of data-harvesting apps. You may be able to keep your data out of Googleâ€™s hands, but is it worth doing that, if youâ€™re giving it to everyone else?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45963001</guid><pubDate>Tue, 18 Nov 2025 09:13:13 +0000</pubDate></item><item><title>The Miracle of WÃ¶rgl</title><link>https://scf.green/story-of-worgl-and-others/</link><description>&lt;doc fingerprint="2681901966d72d90"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Story of WÃ¶rgl and others&lt;/head&gt;
    &lt;head rend="h2"&gt;The Miracle of WÃ¶rgl&lt;/head&gt;
    &lt;p&gt;WÃ¶rgl was the first in town in Austria that effectively managed to eliminate the extreme unemployment caused by the Great Depression. Its local currency experiment was such a success that it gained worldwide attention. That effort became known as the â€œMiracle of WÃ¶rgl .â€ For the full details, go here. Here is the summary of that story.&lt;/p&gt;
    &lt;p&gt;On July 5th 1932, in the middle of the Great Depression, the Austrian town of WÃ¶rgl made economic history by introducing a remarkable complimentary currency. WÃ¶rgl was in trouble, and was prepared to try anything. Of its population of 4,500, a total of 1,500 people were without a job, and 200 families were penniless. The mayor, Michael Unterguggenberger, had a long list of projects he wanted to accomplish, but there was hardly any money with which to carry them out. These included repaving the roads, streetlights, extending water distribution across the whole town, and planting trees along the streets.&lt;/p&gt;
    &lt;p&gt;Rather than spending the 40,000 Austrian schillings in the townâ€™s coffers to start these projects off, he deposited them in a local savings bank as a guarantee to back the issue of a type of complimentary currency known as â€˜stamp scripâ€™. The Mayor then proceeded to hire people to do infrastructure projects for the town and the community quickly went from an unemployment rate of over 30% to near zero, as that money began to circulate very rapidly.&lt;/p&gt;
    &lt;p&gt;Of all the business in town, only the railway station and the post office refused to accept the local money. When people ran out of spending ideas, they would pay their taxes early using scrip, resulting in a huge increase in town revenues. Over the 13-month period the project ran, the council not only carried out all the intended works projects, but also built new houses, a reservoir, a ski jump, and a bridge. The people also used scrip to replant forests, in anticipation of the future cash flow they would receive from the trees.&lt;/p&gt;
    &lt;p&gt;Six neighbouring villages copied the system successfully. The French Prime Minister, Eduoard Dalladier, made a special visit to see the â€˜miracle of WÃ¶rglâ€™. In January 1933, the project was replicated in the neighbouring city of Kirchbuhl, and in June 1933, Unterguggenburger addressed a meeting with representatives from 170 different towns and villages. Two hundred Austrian townships were interested in adopting the idea.&lt;/p&gt;
    &lt;p&gt;At this point, the central bank panicked, and decided to assert its monopoly rights by banning complimentary currencies. The people unsuccessfully sued the bank, and later lost in the Austrian Supreme Court. It then became a criminal offence to issue â€™emergency currencyâ€™. The town went back to 30% unemployment. In 1934, social unrest exploded across Austria. In 1938, when Hitler annexed Austria, he was welcomed by many people as their economic and political saviour.&lt;/p&gt;
    &lt;p&gt;Nonetheless, the success of WÃ¶rgl attracted the attention of one of the leading economists in the U.S. at the time, Professor Irving Fisher, who informed the FDR administration he thought that idea could be used to end the Great Depression. That story is next.&lt;/p&gt;
    &lt;head rend="h2"&gt;Irving Fisher, the Great Depression and FDR&lt;/head&gt;
    &lt;p&gt;When Professor Irving Fisher learned of the success of WÃ¶rgl and other European experiments, he determined that â€œThe correct application of stamp scrip would solve the Depression crisis in the U.S. in three weeks.â€ He presented his findings to Dean Acheson, then under-secretary of the Treasury under FDR. Acheson sought input from Harvard economics professor Russell Sprague, who told him that this approach could indeed succeed in bringing America out of the Depression, but cautioned him to check with the President.&lt;/p&gt;
    &lt;p&gt;He did so. Unfortunately, fearing decentralization, President Roosevelt denounced complementary currencies soon afterwards and they were prohibited. He did so in probably his most famous address, the one including the phrase â€œThe only thing we need to fear is fear itself.â€&lt;/p&gt;
    &lt;p&gt;In that speech he also announced that by â€œexecutive decreeâ€ he would henceforth prohibit â€˜emergency currenciesâ€™. This was the code name for all the complementary currencies already in existence, and all those in preparation around the country. That prohibition lasted for decades.&lt;/p&gt;
    &lt;p&gt;Imagine if Fisherâ€™s recommendation had held the day. The Great Depression would have ended well before World War II and a great deal of suffering would have been avoided. Fortunately, complementary currencies are now legal in just about every country, as evidenced by the popularity of cryptocurrencies, one form of a complementary currency.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Central Middle Ages and Cathedrals&lt;/head&gt;
    &lt;p&gt;We now come to one of the most prolonged and significant times where the use of complementary currencies had a profound and widespread positive impact on the communities that adopted them. Here we find a sustained period of 250 years (1040-1290) of financial success based on local currencies spread throughout Western Europe.&lt;/p&gt;
    &lt;p&gt;Chapter 6 from the book, New Money for a New World by Bernard Lietaer (co-architect of the Euro) and Stephen Belgin details that period of widespread abundance throughout Western Europe that can be directly attributed to the extensive use of local currencies.&lt;/p&gt;
    &lt;p&gt;The authors note that, â€œThere was work for all, with favorable working conditions and abundant time for family, community, and personal pursuits. This epoch was also characterized by significant advancements in science, technology, education, literature, music, arts, craftsmanship, and more.â€&lt;/p&gt;
    &lt;p&gt;It all commenced when communities like Paris decided they wanted to build a local cathedral like Notre Dame, each a massive infrastructure project that lasted on average between 50 and 100 years. Those communities printed their own money and hired architects, stone masons, carpenters, lead workers, glass workers and more to build those magnificent edifices and more.&lt;/p&gt;
    &lt;p&gt;What most people donâ€™t know is that those citizens were directly responsible for building more than 1,000 cathedrals in Western Europe, alongside 350,000 churches and several thousand large abbeys. That means over 1,000 European communities adopted their own complementary currency program, yielding a building phase rarely matched throughout history.&lt;/p&gt;
    &lt;p&gt;Month after month those communities paid those workers â€œnew moneyâ€ they printed up which in turn was injected into the local economy. That money was spent on food, clothing, shelter and all the necessities of life, which stimulated all manner of new local merchants and the jobs they produced.&lt;/p&gt;
    &lt;p&gt;â€œThis medieval building phenomenon is more remarkable still,â€ say the authors, â€œgiven that there was no central authority, church or otherwise, in charge of initiating or funding the construction of these cathedrals. Contrary to popular belief today, these structures were neither built by nor belonged to the church or nobility.&lt;/p&gt;
    &lt;p&gt;Local nobility and royalty customarily did make contributions, but these monuments were typically owned and financed by the citizens of the municipalities where they were built.â€&lt;/p&gt;
    &lt;p&gt;Those efforts initiated over 800 years ago are still providing financial returns today. Tourists flock to those cathedrals bringing with them money that they leave in the communities they visit. Almost nothing in history has provided a greater return on investment.&lt;/p&gt;
    &lt;head rend="h2"&gt;More examples&lt;/head&gt;
    &lt;p&gt;See this document, Complementary Currencies in Use for more examples of complementary currencies and the positive impact they had on the communities that adopted them.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45963583</guid><pubDate>Tue, 18 Nov 2025 10:59:54 +0000</pubDate></item><item><title>Cloudflare, X, More are down</title><link>https://www.cloudflarestatus.com/?t=1</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45963780</guid><pubDate>Tue, 18 Nov 2025 11:35:10 +0000</pubDate></item><item><title>Cloudflare Global Network experiencing issues</title><link>https://www.cloudflarestatus.com/incidents/8gmgl950y3h7</link><description>&lt;doc fingerprint="d4a618d2935028af"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt; Subscribe to updates for &lt;strong&gt;Cloudflare Global Network experiencing issues&lt;/strong&gt; via email and/or text message. You'll receive email notifications when incidents are updated, and text message notifications whenever Cloudflare &lt;strong&gt;creates&lt;/strong&gt; or &lt;strong&gt;resolves&lt;/strong&gt; an incident. &lt;/p&gt;
      &lt;div&gt;
        &lt;label&gt;VIA SMS:&lt;/label&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;
              &lt;select&gt;
                &lt;option&gt;Afghanistan (+93)&lt;/option&gt;
                &lt;option&gt;Albania (+355)&lt;/option&gt;
                &lt;option&gt;Algeria (+213)&lt;/option&gt;
                &lt;option&gt;American Samoa (+1)&lt;/option&gt;
                &lt;option&gt;Andorra (+376)&lt;/option&gt;
                &lt;option&gt;Angola (+244)&lt;/option&gt;
                &lt;option&gt;Anguilla (+1)&lt;/option&gt;
                &lt;option&gt;Antigua and Barbuda (+1)&lt;/option&gt;
                &lt;option&gt;Argentina (+54)&lt;/option&gt;
                &lt;option&gt;Armenia (+374)&lt;/option&gt;
                &lt;option&gt;Aruba (+297)&lt;/option&gt;
                &lt;option&gt;Australia/Cocos/Christmas Island (+61)&lt;/option&gt;
                &lt;option&gt;Austria (+43)&lt;/option&gt;
                &lt;option&gt;Azerbaijan (+994)&lt;/option&gt;
                &lt;option&gt;Bahamas (+1)&lt;/option&gt;
                &lt;option&gt;Bahrain (+973)&lt;/option&gt;
                &lt;option&gt;Bangladesh (+880)&lt;/option&gt;
                &lt;option&gt;Barbados (+1)&lt;/option&gt;
                &lt;option&gt;Belarus (+375)&lt;/option&gt;
                &lt;option&gt;Belgium (+32)&lt;/option&gt;
                &lt;option&gt;Belize (+501)&lt;/option&gt;
                &lt;option&gt;Benin (+229)&lt;/option&gt;
                &lt;option&gt;Bermuda (+1)&lt;/option&gt;
                &lt;option&gt;Bolivia (+591)&lt;/option&gt;
                &lt;option&gt;Bosnia and Herzegovina (+387)&lt;/option&gt;
                &lt;option&gt;Botswana (+267)&lt;/option&gt;
                &lt;option&gt;Brazil (+55)&lt;/option&gt;
                &lt;option&gt;Brunei (+673)&lt;/option&gt;
                &lt;option&gt;Bulgaria (+359)&lt;/option&gt;
                &lt;option&gt;Burkina Faso (+226)&lt;/option&gt;
                &lt;option&gt;Burundi (+257)&lt;/option&gt;
                &lt;option&gt;Cambodia (+855)&lt;/option&gt;
                &lt;option&gt;Cameroon (+237)&lt;/option&gt;
                &lt;option&gt;Canada (+1)&lt;/option&gt;
                &lt;option&gt;Cape Verde (+238)&lt;/option&gt;
                &lt;option&gt;Cayman Islands (+1)&lt;/option&gt;
                &lt;option&gt;Central Africa (+236)&lt;/option&gt;
                &lt;option&gt;Chad (+235)&lt;/option&gt;
                &lt;option&gt;Chile (+56)&lt;/option&gt;
                &lt;option&gt;China (+86)&lt;/option&gt;
                &lt;option&gt;Colombia (+57)&lt;/option&gt;
                &lt;option&gt;Comoros (+269)&lt;/option&gt;
                &lt;option&gt;Congo (+242)&lt;/option&gt;
                &lt;option&gt;Congo, Dem Rep (+243)&lt;/option&gt;
                &lt;option&gt;Costa Rica (+506)&lt;/option&gt;
                &lt;option&gt;Croatia (+385)&lt;/option&gt;
                &lt;option&gt;Cyprus (+357)&lt;/option&gt;
                &lt;option&gt;Czech Republic (+420)&lt;/option&gt;
                &lt;option&gt;Denmark (+45)&lt;/option&gt;
                &lt;option&gt;Djibouti (+253)&lt;/option&gt;
                &lt;option&gt;Dominica (+1)&lt;/option&gt;
                &lt;option&gt;Dominican Republic (+1)&lt;/option&gt;
                &lt;option&gt;Egypt (+20)&lt;/option&gt;
                &lt;option&gt;El Salvador (+503)&lt;/option&gt;
                &lt;option&gt;Equatorial Guinea (+240)&lt;/option&gt;
                &lt;option&gt;Estonia (+372)&lt;/option&gt;
                &lt;option&gt;Ethiopia (+251)&lt;/option&gt;
                &lt;option&gt;Faroe Islands (+298)&lt;/option&gt;
                &lt;option&gt;Fiji (+679)&lt;/option&gt;
                &lt;option&gt;Finland/Aland Islands (+358)&lt;/option&gt;
                &lt;option&gt;France (+33)&lt;/option&gt;
                &lt;option&gt;French Guiana (+594)&lt;/option&gt;
                &lt;option&gt;French Polynesia (+689)&lt;/option&gt;
                &lt;option&gt;Gabon (+241)&lt;/option&gt;
                &lt;option&gt;Gambia (+220)&lt;/option&gt;
                &lt;option&gt;Georgia (+995)&lt;/option&gt;
                &lt;option&gt;Germany (+49)&lt;/option&gt;
                &lt;option&gt;Ghana (+233)&lt;/option&gt;
                &lt;option&gt;Gibraltar (+350)&lt;/option&gt;
                &lt;option&gt;Greece (+30)&lt;/option&gt;
                &lt;option&gt;Greenland (+299)&lt;/option&gt;
                &lt;option&gt;Grenada (+1)&lt;/option&gt;
                &lt;option&gt;Guadeloupe (+590)&lt;/option&gt;
                &lt;option&gt;Guam (+1)&lt;/option&gt;
                &lt;option&gt;Guatemala (+502)&lt;/option&gt;
                &lt;option&gt;Guinea (+224)&lt;/option&gt;
                &lt;option&gt;Guyana (+592)&lt;/option&gt;
                &lt;option&gt;Haiti (+509)&lt;/option&gt;
                &lt;option&gt;Honduras (+504)&lt;/option&gt;
                &lt;option&gt;Hong Kong (+852)&lt;/option&gt;
                &lt;option&gt;Hungary (+36)&lt;/option&gt;
                &lt;option&gt;Iceland (+354)&lt;/option&gt;
                &lt;option&gt;India (+91)&lt;/option&gt;
                &lt;option&gt;Indonesia (+62)&lt;/option&gt;
                &lt;option&gt;Iraq (+964)&lt;/option&gt;
                &lt;option&gt;Ireland (+353)&lt;/option&gt;
                &lt;option&gt;Israel (+972)&lt;/option&gt;
                &lt;option&gt;Italy (+39)&lt;/option&gt;
                &lt;option&gt;Jamaica (+1)&lt;/option&gt;
                &lt;option&gt;Japan (+81)&lt;/option&gt;
                &lt;option&gt;Jordan (+962)&lt;/option&gt;
                &lt;option&gt;Kenya (+254)&lt;/option&gt;
                &lt;option&gt;Korea, Republic of (+82)&lt;/option&gt;
                &lt;option&gt;Kosovo (+383)&lt;/option&gt;
                &lt;option&gt;Kuwait (+965)&lt;/option&gt;
                &lt;option&gt;Kyrgyzstan (+996)&lt;/option&gt;
                &lt;option&gt;Laos (+856)&lt;/option&gt;
                &lt;option&gt;Latvia (+371)&lt;/option&gt;
                &lt;option&gt;Lebanon (+961)&lt;/option&gt;
                &lt;option&gt;Lesotho (+266)&lt;/option&gt;
                &lt;option&gt;Liberia (+231)&lt;/option&gt;
                &lt;option&gt;Libya (+218)&lt;/option&gt;
                &lt;option&gt;Liechtenstein (+423)&lt;/option&gt;
                &lt;option&gt;Lithuania (+370)&lt;/option&gt;
                &lt;option&gt;Luxembourg (+352)&lt;/option&gt;
                &lt;option&gt;Macao (+853)&lt;/option&gt;
                &lt;option&gt;Macedonia (+389)&lt;/option&gt;
                &lt;option&gt;Madagascar (+261)&lt;/option&gt;
                &lt;option&gt;Malawi (+265)&lt;/option&gt;
                &lt;option&gt;Malaysia (+60)&lt;/option&gt;
                &lt;option&gt;Maldives (+960)&lt;/option&gt;
                &lt;option&gt;Mali (+223)&lt;/option&gt;
                &lt;option&gt;Malta (+356)&lt;/option&gt;
                &lt;option&gt;Martinique (+596)&lt;/option&gt;
                &lt;option&gt;Mauritania (+222)&lt;/option&gt;
                &lt;option&gt;Mauritius (+230)&lt;/option&gt;
                &lt;option&gt;Mexico (+52)&lt;/option&gt;
                &lt;option&gt;Monaco (+377)&lt;/option&gt;
                &lt;option&gt;Mongolia (+976)&lt;/option&gt;
                &lt;option&gt;Montenegro (+382)&lt;/option&gt;
                &lt;option&gt;Montserrat (+1)&lt;/option&gt;
                &lt;option&gt;Morocco/Western Sahara (+212)&lt;/option&gt;
                &lt;option&gt;Mozambique (+258)&lt;/option&gt;
                &lt;option&gt;Namibia (+264)&lt;/option&gt;
                &lt;option&gt;Nepal (+977)&lt;/option&gt;
                &lt;option&gt;Netherlands (+31)&lt;/option&gt;
                &lt;option&gt;New Zealand (+64)&lt;/option&gt;
                &lt;option&gt;Nicaragua (+505)&lt;/option&gt;
                &lt;option&gt;Niger (+227)&lt;/option&gt;
                &lt;option&gt;Nigeria (+234)&lt;/option&gt;
                &lt;option&gt;Norway (+47)&lt;/option&gt;
                &lt;option&gt;Oman (+968)&lt;/option&gt;
                &lt;option&gt;Pakistan (+92)&lt;/option&gt;
                &lt;option&gt;Palestinian Territory (+970)&lt;/option&gt;
                &lt;option&gt;Panama (+507)&lt;/option&gt;
                &lt;option&gt;Paraguay (+595)&lt;/option&gt;
                &lt;option&gt;Peru (+51)&lt;/option&gt;
                &lt;option&gt;Philippines (+63)&lt;/option&gt;
                &lt;option&gt;Poland (+48)&lt;/option&gt;
                &lt;option&gt;Portugal (+351)&lt;/option&gt;
                &lt;option&gt;Puerto Rico (+1)&lt;/option&gt;
                &lt;option&gt;Qatar (+974)&lt;/option&gt;
                &lt;option&gt;Reunion/Mayotte (+262)&lt;/option&gt;
                &lt;option&gt;Romania (+40)&lt;/option&gt;
                &lt;option&gt;Russia/Kazakhstan (+7)&lt;/option&gt;
                &lt;option&gt;Rwanda (+250)&lt;/option&gt;
                &lt;option&gt;Samoa (+685)&lt;/option&gt;
                &lt;option&gt;San Marino (+378)&lt;/option&gt;
                &lt;option&gt;Saudi Arabia (+966)&lt;/option&gt;
                &lt;option&gt;Senegal (+221)&lt;/option&gt;
                &lt;option&gt;Serbia (+381)&lt;/option&gt;
                &lt;option&gt;Seychelles (+248)&lt;/option&gt;
                &lt;option&gt;Sierra Leone (+232)&lt;/option&gt;
                &lt;option&gt;Singapore (+65)&lt;/option&gt;
                &lt;option&gt;Slovakia (+421)&lt;/option&gt;
                &lt;option&gt;Slovenia (+386)&lt;/option&gt;
                &lt;option&gt;South Africa (+27)&lt;/option&gt;
                &lt;option&gt;Spain (+34)&lt;/option&gt;
                &lt;option&gt;Sri Lanka (+94)&lt;/option&gt;
                &lt;option&gt;St Kitts and Nevis (+1)&lt;/option&gt;
                &lt;option&gt;St Lucia (+1)&lt;/option&gt;
                &lt;option&gt;St Vincent Grenadines (+1)&lt;/option&gt;
                &lt;option&gt;Sudan (+249)&lt;/option&gt;
                &lt;option&gt;Suriname (+597)&lt;/option&gt;
                &lt;option&gt;Swaziland (+268)&lt;/option&gt;
                &lt;option&gt;Sweden (+46)&lt;/option&gt;
                &lt;option&gt;Switzerland (+41)&lt;/option&gt;
                &lt;option&gt;Taiwan (+886)&lt;/option&gt;
                &lt;option&gt;Tajikistan (+992)&lt;/option&gt;
                &lt;option&gt;Tanzania (+255)&lt;/option&gt;
                &lt;option&gt;Thailand (+66)&lt;/option&gt;
                &lt;option&gt;Togo (+228)&lt;/option&gt;
                &lt;option&gt;Tonga (+676)&lt;/option&gt;
                &lt;option&gt;Trinidad and Tobago (+1)&lt;/option&gt;
                &lt;option&gt;Tunisia (+216)&lt;/option&gt;
                &lt;option&gt;Turkey (+90)&lt;/option&gt;
                &lt;option&gt;Turks and Caicos Islands (+1)&lt;/option&gt;
                &lt;option&gt;Uganda (+256)&lt;/option&gt;
                &lt;option&gt;Ukraine (+380)&lt;/option&gt;
                &lt;option&gt;United Arab Emirates (+971)&lt;/option&gt;
                &lt;option&gt;United Kingdom (+44)&lt;/option&gt;
                &lt;option&gt;United States (+1)&lt;/option&gt;
                &lt;option&gt;Uruguay (+598)&lt;/option&gt;
                &lt;option&gt;Uzbekistan (+998)&lt;/option&gt;
                &lt;option&gt;Venezuela (+58)&lt;/option&gt;
                &lt;option&gt;Vietnam (+84)&lt;/option&gt;
                &lt;option&gt;Virgin Islands, British (+1)&lt;/option&gt;
                &lt;option&gt;Virgin Islands, U.S. (+1)&lt;/option&gt;
                &lt;option&gt;Yemen (+967)&lt;/option&gt;
                &lt;option&gt;Zambia (+260)&lt;/option&gt;
                &lt;option&gt;Zimbabwe (+263)&lt;/option&gt;
              &lt;/select&gt;
            &lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
        &lt;label&gt;Enter mobile number&lt;/label&gt;
        &lt;div&gt;
          &lt;label&gt;Enter the OTP sent&lt;/label&gt;
          &lt;div&gt;
            &lt;p&gt;To receive SMS updates, please verify your number. To proceed with just email click â€˜Subscribeâ€™ &lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45963949</guid><pubDate>Tue, 18 Nov 2025 11:48:56 +0000</pubDate></item></channel></rss>