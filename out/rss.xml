<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 27 Dec 2025 22:40:01 +0000</lastBuildDate><item><title>OrangePi 6 Plus Review</title><link>https://boilingsteam.com/orange-pi-6-plus-review/</link><description>&lt;doc fingerprint="3753087659829594"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;OrangePi 6 Plus Review: The New Frontier for ARM64 SBC Performance&lt;/head&gt;
    &lt;p&gt;So after our previous reviews (that started mainly around RISC-V since we are really interested in this new architecture) of SBC, we continue to review what’s available these days in the world of small, versatile computers. Today this is going to be about the OrangePi 6 Plus, following our previous review of the OrangePi 5 ultra board.&lt;/p&gt;
    &lt;p&gt;This is NOT a super small, credit card format SBC. We are talking about something that’s definitely larger, and that comes directly with an integrated heatsink.&lt;/p&gt;
    &lt;p&gt;At the bottom there’s a wealth of ports, and it’s where you will install the necessary wireless module if you want Wifi and Bluetooth.&lt;/p&gt;
    &lt;p&gt;Now let’s dive into what you can do with this.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ports&lt;/head&gt;
    &lt;p&gt;Here is what you can get from the top of the device. Note that most of it will be hidden from view as the board comes pre-installed with the heatsink that covers the SOC and the memory chips.&lt;/p&gt;
    &lt;p&gt;And the bottom view.&lt;/p&gt;
    &lt;p&gt;You can tell just from the format that you should have higher expectations from the hardware.&lt;/p&gt;
    &lt;head rend="h2"&gt;Specs of the OrangePi 6 Plus&lt;/head&gt;
    &lt;p&gt;In a table format:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;Specification&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;SoC&lt;/cell&gt;
        &lt;cell&gt;CIX CD8180 / CD8160 (12-core 64-bit)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CPU Architecture&lt;/cell&gt;
        &lt;cell&gt;4× Cortex-A720 (High-perf) + 4× Cortex-A720 (Main) + 4× Cortex-A520 (Efficiency)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;GPU&lt;/cell&gt;
        &lt;cell&gt;Arm Immortalis-G720 MC10 (Ray Tracing &amp;amp; 8K Decoding support)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;NPU (AI)&lt;/cell&gt;
        &lt;cell&gt;Up to 45 TOPS (System-wide); ~30 TOPS Dedicated NPU&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;RAM&lt;/cell&gt;
        &lt;cell&gt;16GB / 32GB / 64GB LPDDR5 (128-bit)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Storage&lt;/cell&gt;
        &lt;cell&gt;2× M.2 2280 slots (PCIe 4.0 x4 NVMe), 1× MicroSD (TF) slot&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Networking&lt;/cell&gt;
        &lt;cell&gt;Dual 5GbE (5000Mbps) Ethernet ports&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Wireless&lt;/cell&gt;
        &lt;cell&gt;M.2 Key-E (2230) slot for Wi-Fi 6E/7 &amp;amp; Bluetooth 5.4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Video Output&lt;/cell&gt;
        &lt;cell&gt;1× HDMI 2.1 (8K@60Hz), 1× DP 1.4, 2× USB-C (DP Alt Mode), 1× eDP&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;USB Ports&lt;/cell&gt;
        &lt;cell&gt;2× USB 3.0 Type-A, 2× USB 2.0 Type-A, 2× Full-function USB Type-C&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Camera (MIPI)&lt;/cell&gt;
        &lt;cell&gt;2× 4-lane MIPI CSI interfaces&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Expansion&lt;/cell&gt;
        &lt;cell&gt;40-pin GPIO header (UART, I2C, SPI, PWM, etc.)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Audio&lt;/cell&gt;
        &lt;cell&gt;3.5mm Headphone/Mic jack, 2× Speaker headers, 1× Analog MIC header&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Power Supply&lt;/cell&gt;
        &lt;cell&gt;100W Dual USB Type-C PD (20V/5A)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Dimensions&lt;/cell&gt;
        &lt;cell&gt;115mm × 100mm&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;As you can see from the specs, this is no joke. 16GB RAM by default, 12-cores processor, with a powerful GPU (Immortalis G720), and a NPU that has a claimed performance up to 30 TOPS. Not just that, but there’s numerous ports on this SBC, with 2 full sized M2 2280 slots! You can tell that the IO is not going to be a joke here.&lt;/p&gt;
    &lt;p&gt;If you are wondering about the SOC itself, we have more info about what to expect from CIX.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Feature&lt;/cell&gt;
        &lt;cell role="head"&gt;Specification&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;SoC Model&lt;/cell&gt;
        &lt;cell&gt;CIX CD8180 / CD8160 (Codename: CIX P1)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Architecture&lt;/cell&gt;
        &lt;cell&gt;Armv9.2-A (64-bit)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Total CPU Cores&lt;/cell&gt;
        &lt;cell&gt;12 Cores (Tri-cluster configuration)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Big Cores&lt;/cell&gt;
        &lt;cell&gt;4× Cortex-A720 @ Up to 2.8 GHz (Performance)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Medium Cores&lt;/cell&gt;
        &lt;cell&gt;4× Cortex-A720 @ Up to 2.4 GHz (Mainstream)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Little Cores&lt;/cell&gt;
        &lt;cell&gt;4× Cortex-A520 @ 1.8 GHz (Efficiency)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;L3 Cache&lt;/cell&gt;
        &lt;cell&gt;12MB Shared L3 Cache&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;GPU&lt;/cell&gt;
        &lt;cell&gt;Arm Immortalis-G720 MC10&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Graphics Features&lt;/cell&gt;
        &lt;cell&gt;Hardware Ray Tracing, Vulkan 1.3, OpenGL ES 3.2, OpenCL 3.0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;NPU (AI Engine)&lt;/cell&gt;
        &lt;cell&gt;Arm-China Zhouyi: 30 TOPS (Dedicated); ~45 TOPS (Total System AI)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;AI Precision&lt;/cell&gt;
        &lt;cell&gt;INT4, INT8, INT16, FP16, TF32&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;VPU (Video)&lt;/cell&gt;
        &lt;cell&gt;Linlon V8: 8K@60fps Decode (AV1/H.265/VP9), 8K@30fps Encode (H.265)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Memory Interface&lt;/cell&gt;
        &lt;cell&gt;128-bit LPDDR5 / LPDDR5X (Up to 5500 MT/s)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Memory Bandwidth&lt;/cell&gt;
        &lt;cell&gt;Up to 96 GB/s (Theoretical peak)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;PCIe Support&lt;/cell&gt;
        &lt;cell&gt;PCIe Gen4 (Supports x8, x4, and x2 configurations)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;System Security&lt;/cell&gt;
        &lt;cell&gt;Integrated Security Engine (Standard Arm SystemReady / ACPI support)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;2.8Ghz ARM Big Cores processors! That’s no joke, this is way beyond the typical frequency we see for small boards where things are usually below 2 Ghz. The memory interface also has a huge bandwidth, and we get full PCI4 with 8 lanes! This means that this board could probably be attached to an external GPU (eGPU) and be able to drive it (provided adequate software support).&lt;/p&gt;
    &lt;p&gt;About the NPU, the usual problem on Linux is that there is poor software support, and it’s certainly not in the mainline either. To leverage the 30 TOPS of dedicated AI power, you cannot simply use standard versions of PyTorch or TensorFlow out of the box. You must use the NeuralONE AI SDK. This also means that the NPU cannot use regular weights, and need to compile them into a different format to make them work. On paper, the NPU is highly versatile and supports the following data types: INT4, INT8, INT16, FP16, BF16, and TF32. The board has extensive documentation on a bunch of embedded models for vision detection, automation, such as YOLOv8 (Vision), ResNet50, OpenPose, and DeepLabv3.&lt;/p&gt;
    &lt;p&gt;Now let’s jump into the actual user experience.&lt;/p&gt;
    &lt;head rend="h2"&gt;Software Support&lt;/head&gt;
    &lt;head rend="h3"&gt;Desktop Experience&lt;/head&gt;
    &lt;head rend="h4"&gt;Debian Bookworm&lt;/head&gt;
    &lt;p&gt;There is a Debian Bookworm (12) image available at the time of writing. I was actually waiting for a 24.04 Ubuntu image to be made available, and that was the plan at some point according to my OrangePi contact, but they had to shift priorities apparently and now there is no ETA for the Ubuntu image. So instead of waiting, I decided to go ahead and review what’s possible with this Debian image. As you know, Debian Bookworm is not that new anymore (the base is from Mid-2023), and is now superseded by Debian Trixie (released in 2025). This Debian image comes with two kernels available, 6.1 and 6.6. The 6.6 kernel is also from 2023, and it’s not surprising you don’t get a more recent kernel, since the Linux support for various parts of the boards, not being upstreamed and mainlined, is very likely to be stuck on an older version. This is usually what causes headaches down the road: maybe some general functionality can be upstreamed, but will the NPU have working drivers for a more recent kernel? Your guess is as good as mine.&lt;/p&gt;
    &lt;p&gt;You can burn the image directly on the NVME drive - no need to boot on a MicroSD card this time around. Note that at the beginning, my OrangePi did not boot, but I could see from the BIOS (yes, this board comes with a BIOS-like interface!) that everything was supposed to be seen by the SBC. Turns out that the firmware required an update to be able to boot on this Linux kernel, and after imaging the latest firmware on a USB stick and booting on it, a few minutes later, things worked as expected.&lt;/p&gt;
    &lt;p&gt;In any case, we get a GNOME desktop after boot. And everything works pretty much as you’d expect. Once thing that is immediately apparent when you start with the desktop is how snappy everything is. SBC boards like the Raspberry Pi 4 provide a good desktop experience but have some general sluggishness to them. On this board, this is pretty much like having a X86_64 experience. It recognized immediately my Ultra Wide Display and supported the 3440 x 1440 resolution without a hitch. Everything from navigating the desktop and settings is very fast. You get Chromium by default (and Firefox ESR in the repos) and the browser experience is very clean and fast, too. This board has absolutely no problem to play Youtube streams, even at 4k. This thing is FAST!&lt;/p&gt;
    &lt;p&gt;A quick look at vulkaninfo shows that we have working Vulkan drivers on this board! This is something that was initially very exciting, but it turns out that there are some limitations. More on that later.&lt;/p&gt;
    &lt;p&gt;Turns out the Vulkan driver is limited to some early 1.3 version. You have options to upgrade Mesa, by using Debian backports - it gets you to a 25.07 Mesa version, where you don’t rely anymore on the proprietary driver - no, this time you get Panfrost, which means a more robust driver potentially… except that you are stuck on the 6.6 Linux Kernel, and Panfrost requires a more recent kernel to work properly (6.10+ apparently). So the solution would be to move to a more recent kernel, right? Do the Debian backports have it? Yes. Problem is, moving away from 6.6 will break a lot of patches that are necessary for the hardware of this board to work. Such as HDMI out at resolutions higher than 1080p, and NPU support! So, it’s a major trade-off.&lt;/p&gt;
    &lt;head rend="h4"&gt;Getting Bluetooth to work&lt;/head&gt;
    &lt;p&gt;Even though bluetooth shows in the GNOME desktop controls, and that it could see some of my peripherals, it could not connect to any of my external audio devices. But I don’t give up so fast. Turns out there’s an issue with a missing pipewire dependency to allow for bluetooth audio to work. Here’s how you can get it done:&lt;/p&gt;
    &lt;code&gt;sudo apt install libspa-0.2-bluetooth pipewire-audio-client-libraries
&lt;/code&gt;
    &lt;p&gt;Afterwards you can launch bluetoothctl from the command line, and you can execute the following commands one by one&lt;/p&gt;
    &lt;code&gt;power on
agent on
default-agent
scan on
&lt;/code&gt;
    &lt;p&gt;After the scan is activated you should see bluetooth device popping up in the terminal. Note the ID of the bluetooth device you want to connect, and then:&lt;/p&gt;
    &lt;code&gt;pair &amp;lt;device id&amp;gt;
trust &amp;lt;device id&amp;gt;
connect &amp;lt;devic_id&amp;gt;
&lt;/code&gt;
    &lt;p&gt;Once this is fixed, things work as expected. And now I get audio!&lt;/p&gt;
    &lt;head rend="h4"&gt;Compiling OBS&lt;/head&gt;
    &lt;p&gt;OBS is not available as flatpak for arm64, and not in the repos either. This means, that you are in for a compilation from sources. This is not the thing that scares me. But in our situation, it’s a little more convoluted that I expected. First, turns out that OBS did not like the fact that the Cmake was relatively old. So I had to get one of the recent Cmake binaries. Thanksfully they have arm64 binaries already available on their website, so that was easy.&lt;/p&gt;
    &lt;p&gt;Next, OBS would complain of a too old FFmpeg version. Not too surprising for something that depends so heavily on it. So I had to go for a full FFmpeg compilation. Here’s what I did to save you time:&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/FFmpeg/FFmpeg.git
cd ffmpeg
git checkout release/7.1 # in order to have a stable release, not the master branch in itself

./configure --prefix=/usr/local --enable-shared --disable-static --enable-gpl --enable-libx264 --enable-libx265
make -j$(nproc)

sudo make install
&lt;/code&gt;
    &lt;p&gt;Finally, compiling OBS is a game of cat and mouse, you need to basically give up one extension after the other as new errors arise. Most of the things you need to remove are not critical (NVENC, not relevant on non-nvidia hardware, browser support, not really our thing either) and at the end you get a fairly long series of command.&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/obsproject/obs-studio.git
cd obs-studio

# remove the obs-browser plugin from the obs folder root directlroy
mv plugins/obs-browser plugins/obs-browser.bak

# from the obs root folder
git submodule update --init --recursive

# a couple of exports to avoid the compilation to fail because of FFmpeg warnings
export CFLAGS="-Wno-error=deprecated-declarations"
export CXXFLAGS="-Wno-error=deprecated-declarations"

# since the flags can be ignored, we also edit the following file from the root directory
echo 'target_compile_options(obs-ffmpeg PRIVATE "-Wno-error=deprecated-declarations")' &amp;gt;&amp;gt; plugins/obs-ffmpeg/CMakeLists.txt

# use the path to the cmake version you just downloaded
&amp;lt;path_to_newer_cmake_binary&amp;gt;/cmake -DCMAKE_PREFIX_PATH=/usr/local -DFFMPEG_INCLUDE_DIR=/usr/local/include  -DPKG_CONFIG_PATH=/usr/local/lib/pkgconfig -DENABLE_AJA=OFF -DUNIX_STRUCTURE=1 -DENABLE_GIO=OFF -DENABLE_VPL=OFF  -DENABLE_QSV11=OFF -DENABLE_BROWSER=OFF  -DENABLE_WEBRTC=OFF -DENABLE_NATIVE_NVENC=OFF -DCMAKE_COMPILE_WARNING_AS_ERROR=OFF ..

make -j$(nproc)

sudo make install

&lt;/code&gt;
    &lt;p&gt;It took a little while, but it worked!&lt;/p&gt;
    &lt;p&gt;I must admit, I did not expect that it would go so well in the end. Now, thanks to this, you will get a lot of videos from the board in action that no other site reviewing that board has been able to offer.&lt;/p&gt;
    &lt;head rend="h4"&gt;Noise and Temperature&lt;/head&gt;
    &lt;p&gt;The board is very quiet by default. Even when the fan is activated, you barely hear it, at least under fairly typical conditions. Things change when you push the board to its full power, for example a long compilation time. In such conditions, the fan becomes louder with a woosh kind of sound. You will definitely hear it when doing benchmarks, and in my case, when running LLMs, for example.&lt;/p&gt;
    &lt;p&gt;In terms of temperature, the control is very good. At 100% usage even for long durations, while the fan becomes clearly noticeable, it maintains the temperature under 60 C (this is winter right now, and the temperature remained at 58 C). Kudos for the good engineering there. It’s as good as the custom cooling solution for my RTX3090.&lt;/p&gt;
    &lt;head rend="h4"&gt;Power Draw&lt;/head&gt;
    &lt;p&gt;I don’t have a way to measure the power draw currently, but based on reports from other publications it looks like we are looking at:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;15W at idle, which is fairly high&lt;/item&gt;
      &lt;item&gt;30+W during usage - this is why they recommend to use the provided PSU with USB-C. Note that any charger that can provide 45W should do the trick as well.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So, if you are looking for something that has almost no footprint at idle, this is not it. At idle the OrangePi 5 Ultra consumes more than 3 times less, so that sound more like something you’d use for a server.&lt;/p&gt;
    &lt;head rend="h4"&gt;Benchmarks&lt;/head&gt;
    &lt;p&gt;A quick run at Geekbench 6 shows a very strong single core score, and an exceptional multi-core score.&lt;/p&gt;
    &lt;p&gt;Now the details in single score:&lt;/p&gt;
    &lt;p&gt;And in multi-core where we can see that the OrangePi 6 absolutely crushes what you can find on a Raspberry Pi 5.&lt;/p&gt;
    &lt;p&gt;Of course, this is a relatively cheap system that is not going to win the benchmark charts. But look at the results. On single core, we get a score equivalent to a i5-10500 running at a similar frequency (2.3 Ghz).&lt;/p&gt;
    &lt;p&gt;On multicore this is much more impressive, thanks to its twelve cores. And it gets very close, according to the bench, to what an AMD Ryzen 7 4800H (8 cores) can deliver.&lt;/p&gt;
    &lt;p&gt;This is clearly a powerhouse, CPU-wise. For a starting price at 199 USD for the 16GB version, this is a fantastic value proposition. We reviewed the OrangePi 5 Ultra a few months back and the price point is very close (around 160 USD), and unless you need something very small and fanless, the OrangePi 6 Plus is (very clearly) a better deal.&lt;/p&gt;
    &lt;head rend="h4"&gt;Gaming&lt;/head&gt;
    &lt;p&gt;Since we have both a fairly powerful SOC, and a working Vulkan driver, this means that we can expect Box64 to do some magic for us there. I compiled Box64 to make it possible to launch Steam, and for some reason there is some Vulkan related error that prevents Steam from launching. Too bad. I still have a GOG account with a few games that have Linux clients. I tried the following:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Beholder 2&lt;/item&gt;
      &lt;item&gt;Shadow Warrior 2013&lt;/item&gt;
      &lt;item&gt;Oxenfree&lt;/item&gt;
      &lt;item&gt;Day of the Tentacle Remastered&lt;/item&gt;
      &lt;item&gt;Torchlight 2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And with some degree of success! Beholder 2 worked just fine, and are definitely playable on this board, while the framerate remains between the 20s and 30s FPS (here a little slower on this video because of software OBS capture).&lt;/p&gt;
    &lt;p&gt;Here’s Oxenfree’s Linux x86_64 client running in Full HD on the OrangePi 6 Plus, using Box64:&lt;/p&gt;
    &lt;p&gt;Torchlight 2 runs nicely too, at something like 20 to 30 FPS in Full HD.&lt;/p&gt;
    &lt;p&gt;Shadow Warrior refused to launch, complaining about the graphics drivers not being recent enough (turns out that Zink provides OpenGL support, and there is some issue to detect that the OpenGL version is properly supported… my guess). Day of the Tentacle crashes at start too, not sure why. When games work, the performance is not staggering but convincing for a somewhat small SoC at the end of the day. AMD and Intel are certainly ahead in terms of graphics performance on integrated chips, but they have much larger processors and much more expensive ones, too.&lt;/p&gt;
    &lt;p&gt;I also tried FOSS games or engines:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GZDoom (compiled from source, the flatpak version sucks in performance!)&lt;/item&gt;
      &lt;item&gt;Luanti (ex-Minetest)&lt;/item&gt;
      &lt;item&gt;IOQuake3 (compiled from source)&lt;/item&gt;
      &lt;item&gt;OAD (from Debian repos)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;GZDoom works exceptionally well with the OpenGLES renderer at Full HD. It’s fast, responsive. Stable at 60 FPS on Full HD. And Doom is still as fun as it was in the days, or more so if you run Brutal Doom.&lt;/p&gt;
    &lt;p&gt;While I don’t have a sample video here, Quake 3 Arena with the IOQuake3 engine works perfectly, and runs at 60 fps on Full HD without a sweat.&lt;/p&gt;
    &lt;p&gt;Luanti (ex Minetest) works extremely well - I turned most of the details to the max at 1080p and it kept at a solid 60 FPS. Sure, that’s no AAA game, but it’s a good alternative to Minecraft.&lt;/p&gt;
    &lt;p&gt;0Ad works extremely well, even in full screen at my Ultra Wide screen resolution. I took a video at FUll HD, and while OBS does slow the framerate a little, you can still see it’s very smooth.&lt;/p&gt;
    &lt;p&gt;0ad has come a long way, I really need to revisit a recent version of the game to see how much it has changed!&lt;/p&gt;
    &lt;head rend="h3"&gt;Server use&lt;/head&gt;
    &lt;p&gt;This is a very capable board that would make a very powerful server. The Debian image comes with Docker, and as we have seen before during the OrangePi 5 Ultra review, the landscape of ready-to-use Docker Hub images is huge and can get you started with numerous server-side applications in no time. Since we have at least 16Gb of memory, very fast I/O (PCIe4!), and a very fast CPU, this SBC will be able to wonders with a wide variety of applications. The only problem is the power draw. It looks like we are stuck with 15W as an idle baseline, and that seems a bit too much for some light server use.&lt;/p&gt;
    &lt;head rend="h3"&gt;AI applications&lt;/head&gt;
    &lt;p&gt;This board comes with a very large repository (60 GB!) that you can install and sync automatically, with tons of applications and demos you can try out. There is a large part of their documentation dedicated to that part in their manual. And for what I could try, it seems to work as long as you follow their instructions.&lt;/p&gt;
    &lt;p&gt;In my case I like to work with LLMs for a range of applications, so I was interested to see how fast this board could run some small-ish models. One of the major limitations is that we don’t have working NPU support for llama.cpp (oh no!). I was thinking, “no worries, we have a vulkan driver so let’s use Vulkan instead”. I like to be optimistic sometimes. Turns out that the Vulkan driver is below the minimum Vulkan drivers specs required by llama.cpp recently, and I would need to go back to a end 2024 build to be able to compile for Vulkan support. Going back one year on llama.cpp… not an option, sorry (too many models would not be supported going back so far in time). So, we are left with using the raw power of the CPU. Which means it won’t be quiet - expect some good old noise fan in such use cases.&lt;/p&gt;
    &lt;p&gt;Anyway, I went for Qwen3 1.7b - downloaded the safetensors weights, then converted them to gguf, followed by a quantization step to make them IQ4_S. Running the model at this kind of quantization gives us about 14 tokens per second when doing inference. Definitely usable, very usable even, while this is a small model.&lt;/p&gt;
    &lt;p&gt;Ideally, you’d want to have a board that can run a 7b model with proper hardware acceleration and no fan usage. Not sure if having actual NPU support in the future would help for that or not. In other words, we are not there yet.&lt;/p&gt;
    &lt;head rend="h2"&gt;Existing Alternatives&lt;/head&gt;
    &lt;p&gt;As usual there is not a single vendor who can provide you with a CIX experience. This time the main competitor is Radxa, and they have two boards called Orion 6 that feature the same chip - one that is much bigger in footprint (mini-ITX size), and another one that is more similar to the OrangePi 6 Plus size (the Orion 6N). While I don’t have access to the Radxa ones, I can’t comment on how good their support is, but they are very likely to suffer from the same limitations, software wise.&lt;/p&gt;
    &lt;p&gt;As expected, they also only provide a Debian Bookworm image under the Radxa OS nickname so this is no different from what you can get on the OrangePi 6 Plus. Price-wise, they are both available at around similar price points, so you could make you decision based on the best deal you can get.&lt;/p&gt;
    &lt;head rend="h2"&gt;Verdict&lt;/head&gt;
    &lt;p&gt;This is a very impressive SBC, with an exceptional value proposition. Its performance profile puts if far away from the toy category from what we have seen before in the SBC category, and puts it right into the desktop performance realm. It’s still relatively small so you could easily attach it behind a monitor and power a personal computer this way. As a Linux user, things are so fast that you’d be very surprised this is an ARM board running under the hood. For server use, you’d probably want to avoid this one, because of the fairly heavily baseline power consumption.&lt;/p&gt;
    &lt;p&gt;As usual, the pitfalls are always going to be the same. This time around you get an older Debian image (bookworm), with an older kernel (6.6), and some proprietary drivers that you have to live with. Ultimately if you want to upgrade the software running on your SBC that will mean breaking things, and there’s often a fairly long time (if ever) for some hardware components to be supported in newer distros. It’s not necessarily a deal breaker these days. This board is fast enough to compile software fairly quickly if needed. You have Flatpak as well providing some good coverage for a lot of application (even if performance may be sub-par). There are ongoing efforts to mainline the GPU found in the chip, so it could be that a year from now we are in a better place when it comes to proper hardware support beyond kernel 6.6.&lt;/p&gt;
    &lt;p&gt;In any case, this is a surprising new entry in terms of performance / price point. This puts the bar very high for future SBCs ARM64 SBCs. On a personal note, I’d like to see some serious hardware dedicated to running AI models (instead of large desktops chaining multiple GPUs), and maybe highly customized ARM64 SBCs are going to become one option at some point.&lt;/p&gt;
    &lt;p&gt;If you are interested in getting one, there are many resellers, but one of the most direct ones are on Aliexpress:&lt;/p&gt;
    &lt;p&gt;Since the difference of price between 16 GB and 32GB is so small currently, it would make total sense to go for the 32GB.&lt;/p&gt;
    &lt;p&gt;Note: we were provided with a review unit from OrangePi (more specifically the OrangePi 6 Plus 16GB version).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46401499</guid><pubDate>Sat, 27 Dec 2025 12:51:15 +0000</pubDate></item><item><title>Floor796</title><link>https://floor796.com/</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46401612</guid><pubDate>Sat, 27 Dec 2025 13:13:00 +0000</pubDate></item><item><title>NMH BASIC</title><link>https://t3x.org/nmhbasic/index.html</link><description>&lt;doc fingerprint="b738281b4ea5b2d8"&gt;
  &lt;main&gt;
    &lt;p&gt;Download: nmhbas23c.zip (version 1.2, 74KB) | nmhbas25c.zip (version 2.1, 90KB) | man page&lt;/p&gt;
    &lt;p&gt;This is a small BASIC interpreter that I wrote in the early 1990s. For some reason I think it is one of the coolest programs I have ever written. Maybe because it is just a bit under 5K bytes large and still does something useful. Maybe it is just nostalgia.&lt;/p&gt;
    &lt;p&gt;One of the more interesting programs I have written in NMH BASIC is a variant of the well-known mine sweeper game that runs in text mode. Not just text mode, actually, but (tele)typewriter mode, as it reprints the playing field after every move.&lt;/p&gt;
    &lt;p&gt;The screenshots use Viacheslav Slavinsky's excellent GlassTTY font, a TrueType font that perfectly resembles the one used in the DEC VT-220 terminal. The same font, at bigger magnification, is used in the NMH BASIC logo.&lt;/p&gt;
    &lt;p&gt;What is maybe interesting about the mine sweeper clone is that it uses a stackless floodfill algorithm that stores its state in the playing field itself and needs no dynamic memory at all. I have recently described it in the paper A Stackless Floodfill Automaton (PDF, 34KB). A demo showing an animation of the algorithm is included in the NMH BASIC package.&lt;/p&gt;
    &lt;p&gt;There are other programs in the package, most of them rather simple, like an implementation of the Hangman game, the (rather pointless) Nim game, a banner printer, a random number generator, etc. NMH BASIC does not have a RNG, so a 15-bit linear feedback shift register is implemented in BASIC to generate pseudo-random numbers.&lt;/p&gt;
    &lt;p&gt;The first program I have ever written in NMH BASIC was the inevitable prime number sieve. I have no idea how often I have loaded and run it in the past decades - until the Floodfill demo became my new favorite. Here is the code of my first NMH BASIC program (the backslash is the division remainder operator):&lt;/p&gt;
    &lt;quote&gt;10 REM 'PRINT PRIME NUMBERS' 20 REM 'M = NUMBER OF PRIMES TO PRINT' 100 LET M = 1000 105 DIM Z(M) 110 LET Z(0) = 2 : LET T = 1 : LET P = 1 115 PRINT 2, 120 IF T &amp;gt;= M GOTO 200 130 LET P = P+2 : LET O = 1 140 FOR I = 0 TO T-1 150 IF P\Z(I) = 0 LET O = 0 : LET I = T 160 NEXT 170 IF O = 0 GOTO 120 180 LET Z(T) = P : LET T = T+1 185 PRINT P, 190 GOTO 120 200 END&lt;/quote&gt;
    &lt;p&gt;I wrote the first version of NMH BASIC in 1994, recycling some parts that I had written in the years 1991..1993. The first version that I wrote in 1994 was a prototype in BASYL-II which I then translated, function by function, to 8086 assembly language. The resulting executable had a size of about 4700bytes and because the token representation that the interpreter uses internally is quite efficient, you could do interesting things with NMH BASIC in as little as 12Kbytes of memory. I had named the interpreter 12K-BASIC initially, but soon learned that others had had that idea before me.&lt;/p&gt;
    &lt;p&gt;Of course in 1994 memory was already measured in megabytes, so you might say that writing a tiny BASIC interpreter was kind of pointless at that time. It depends I would say; it is better than getting drunk in a bar, and now, almost 30 years later, I still enjoy playing with this little program. So much, in fact, that I decided to translate the original code to T3X/0, so that I can play with it on Unix without having to use an emulator.&lt;/p&gt;
    &lt;p&gt;All the above versions are included in the package: the original BASYL-II version, the assembly language version, and the new T3X version. You can recompile the T3X version with T3X/0 and the 8086 assembly language version with TASM or MASM. You need to create a COM file or it will not run. A precompiled COM file and Tcode machine executable (as well as a Tcode machine for Unix) are also included in the package.&lt;/p&gt;
    &lt;p&gt;There is also a simplified version of the interpreter that runs under CP/M. A COM file for CP/M (BASICS.COM) is also included in the archive. The CP/M version currently needs 32K bytes of TPA to run.&lt;/p&gt;
    &lt;p&gt;The NMH BASIC language contains some interesting (IMHO) hacks to make its implementation simpler.&lt;/p&gt;
    &lt;p&gt;All variables have either single-character names or names consisting of a character and a digit, like A0, B2, Z9, etc. The expressions A and A0 and A(0) all refer to the same variable. If you do not use A0..A9, you can use A as a 10-slot array A(0) .. A(9). Or you can use A5 in the place of A(5) if you are refering to a fixed slot.&lt;/p&gt;
    &lt;p&gt;It is getting even weirder. A(10) is the same as B or B0 or B(0). A(22) is equal to C2 or C(2) and, finally, A(259) would be equal to Z(9). So, for instance, if you do not use any Z's, you can use Y as a 20-slot array. In this case the command &lt;code&gt;DIM Y(20)&lt;/code&gt; is really
a null-operation. It merely serves as a reminder that Y is a 20-slot
array (and Z should not be used).
&lt;/p&gt;
    &lt;p&gt;You could also use Y as a 50-alot array by dimensioning it with &lt;code&gt;DIM Y(50)&lt;/code&gt;. In this case the elements of Z will still be used, but
40 additional slots will be allocated to integer variable storage,
so Z becomes a 40-slot array and Y a 50-slot array. It probably
goes without saying that most programs either use single-character
variables as 10-slot arrays or dimension Z, if a larger array is
needed.
&lt;/p&gt;
    &lt;p&gt;This also means that &lt;code&gt;DIM Y(50)&lt;/code&gt; and &lt;code&gt;DIM Z(50)&lt;/code&gt; in the same program
would just allocate 50 integer slots to Z and the last 40 slots of Y would
overlap with the slots of Z. Having multiple large arrays in the
same NMH BASIC program requires some hacking, like using Z(0)..Z(99)
for one array and Z(100)..Z(199) for the other.
&lt;/p&gt;
    &lt;p&gt;Note the definition of "large" above. NMH BASIC uses 12Kbytes of memory in total: for integer variables, string variables, program memory, stacks, and the machine code of the interpreter itself! You could probably write a version of this interpreter that would run on a CP/M machine with as little as 16K bytes of transient program area (but I have never done so).&lt;/p&gt;
    &lt;p&gt;The interpreter performs I/O on "units", where each unit is assigned a file or device when the interpreter is started. NMH BASIC programs cannot open or close any files. They can only redirect input and output to the assigned units. I/O is sequential, i.e. each unit is like a tape drive. The following program prints the data stored on unit #5:&lt;/p&gt;
    &lt;quote&gt;100 LET X = IOCTL(5, 100) : INPUT #5 110 INPUT A$ : IF ASC(A$) = 255 INPUT #0 : END 120 PRINT A$ : GOTO 110&lt;/quote&gt;
    &lt;p&gt;The statement &lt;code&gt;INPUT #5&lt;/code&gt; redirects input to unit #5, so from that point
on all INPUT statements will read from that unit. (Analogously,
&lt;code&gt;PRINT #5&lt;/code&gt; would redirect output to unit #5.) When a string read from
a unit contains the value 255 in its first slot, there is no more
input available from the current input unit. &lt;code&gt;INPUT #0&lt;/code&gt; connects input
back to the keyboard. Note that &lt;code&gt;PRINT #1&lt;/code&gt; would connect output back
to the screen.
&lt;/p&gt;
    &lt;p&gt;There is an IOCTL function that can perform several "services" on a unit, like rewinding it, appending to it (moving the read/write pointer to the end of the unit), or truncating it (or writing an EOF marker on a tape). The IOCTL call in the above example rewinds the unit.&lt;/p&gt;
    &lt;p&gt;The maximum length of a line or string is 64 bytes. Reading anything longer, either via INPUT or by entering it at the interpreter prompt, will result in an error. The CR,LF characters that separate lines are not counted.&lt;/p&gt;
    &lt;p&gt;I have forgotten how other BASIC dialects handle this, but I suspect that NMH BASIC is the odd one out here: in an IF statement the entire rest of the line is executed conditionally. For example&lt;/p&gt;
    &lt;quote&gt;IF 1 = 1 PRINT 'FOO' : PRINT 'BAR'&lt;/quote&gt;
    &lt;p&gt;would print both FOO and BAR. There is no THEN or ELSE keyword. The first keyword after the condition of IF starts the conditional part of the IF statement. When the condition in IF is false, the interpreter advances to the next line. An alternative branch is implemented with jump around jumps using GOTO:&lt;/p&gt;
    &lt;quote&gt;100 IF condition GOTO 130 110 alternative statements 120 GOTO 140 130 consequent statements 140 REM&lt;/quote&gt;
    &lt;p&gt;Or, if the condition and statements are short:&lt;/p&gt;
    &lt;quote&gt;100 IF condition statements 110 IF # condition statements&lt;/quote&gt;
    &lt;p&gt;The # operator implements the logical NOT. It had high precedence in NMH BASIC up to version 1.2, but has very low precedence in NMH BASIC II. Interestingly, this change did not affect any programs in the archive. There is a logical AND, but not a logical OR in IF. If there are multiple conditions separated by commas then the conditional statements will only execute, if all conditions are true. For example, the statement&lt;/p&gt;
    &lt;quote&gt;IF 0 &amp;lt; C, C &amp;lt; 11 STOP&lt;/quote&gt;
    &lt;p&gt;will stop program execution, if C is in the range 1..10. To implement a logical OR, multiple IF statemements with the same conditional part (or jumps around jumps) have to be used.&lt;/p&gt;
    &lt;p&gt;NMH BASIC 1.x listed programs with blanks between all adjacent tokens. NMH BASIC II uses a more compact representation. Either way is merely a characteristic of the LIST routine, though. You can enter a program as&lt;/p&gt;
    &lt;quote&gt;FOR I=1TO10:PRINT A(I):NEXT&lt;/quote&gt;
    &lt;p&gt;but the LIST command will print it as&lt;/p&gt;
    &lt;quote&gt;FOR I = 1 TO 10 : PRINT A ( I ) : NEXT&lt;/quote&gt;
    &lt;p&gt;in NMH BASIC and as&lt;/p&gt;
    &lt;quote&gt;FOR I = 1 TO 10 : PRINT A(I) : NEXT&lt;/quote&gt;
    &lt;p&gt;in NMH BASIC II.&lt;/p&gt;
    &lt;p&gt;This has the weird side effect that sometimes you can SAVE a program but cannot LOAD it later, because some lines will be shorter than 64 characters when you enter them, but LIST (and hence SAVE) will blow them up to a bigger size.&lt;/p&gt;
    &lt;p&gt;This is mostly a problem in NMH BASIC 1.x, which inserts blanks between all tokens. For example:&lt;/p&gt;
    &lt;quote&gt;100 IF ASC(MID$(A$, I, 1)) = ASC('X') LET X = X+1 : GOTO 120 ----+----1----+----2----+----3----+----4----+----5----+----6---| 100 IF ASC( MID$( A$ , I , 1 ) ) = ASC( 'X' ) LET X = X + 1 : GOTO 120&lt;/quote&gt;
    &lt;p&gt;There is no workaround. When a program cannot be loaded, the only remedy is to edit it with a text editor and fix it, either by removing unnecessary blanks or, even better, by splitting the offending line. E.g.:&lt;/p&gt;
    &lt;quote&gt;100 LET C = ASC( MID$( A$ , I , 1 ) ) 105 IF C = ASC( 'X' ) LET X = X + 1 : GOTO 120&lt;/quote&gt;
    &lt;p&gt;Finally, it is a good idea to keep NMH BASIC programs in DOS text format with CR/LF line separators, even on Unix systems, because otherwise the DOS version of the interpreter will refuse to load them.&lt;/p&gt;
    &lt;p&gt;In December 2024 I changed a few things and pubished a new version of NMH BASIC, which I called, for lack of imagination, NMH BASIC II. The new version changes the precedence of the # (logical NOT) operator from highest to lowest (this was a mistake in the original version!) and uses a more compact and more comprehensible LIST format, which is also used for saving programs. Because some code was simplified in the interpreter at the same time, the new version is one byte smaller than the original version.&lt;/p&gt;
    &lt;p&gt;Download: nmhbas3_30.zip (version 3.0, 105KB) | man page&lt;/p&gt;
    &lt;p&gt;Version 3.x of NMH BASIC is an in-progress version that differs from the previous versions in a few points that are described in detail in the manual. Most prominently, the CMPS ("compare strings") function has been replaced with string comparison operators, so, for example,&lt;/p&gt;
    &lt;quote&gt;IF CMPS(A$, 'FOO') = 0 PRINT 'YEP'&lt;/quote&gt;
    &lt;p&gt;would now be written as&lt;/p&gt;
    &lt;quote&gt;IF A$ = 'FOO' PRINT 'YEP'&lt;/quote&gt;
    &lt;p&gt;Then, NMH BASIC III supports baudot-encoded units. This means that any unit connected to the interpreter can be written to and read from using five-channel baudot-encoding (CCITT-2, US-TTY). So the interpreter can, in theory, save and load programs to/from five-hole paper tape.&lt;/p&gt;
    &lt;p&gt;The T3X/0 version of the interpreter is currently fully working. There also is a more efficient Z80 version written in assembly language, which is work in slow progress. It currently runs all the example programs, but lacks baudot-encoded units and may still have a few bugs. An 8086 version written in assembly language may appear later.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46401938</guid><pubDate>Sat, 27 Dec 2025 14:05:44 +0000</pubDate></item><item><title>Gpg.fail</title><link>https://gpg.fail</link><description>&lt;doc fingerprint="902c8e970565f1c4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Slides, pocs and patches soon!&lt;/head&gt;
    &lt;p&gt;"in the hurry of leaving i forgot the sites src at home, sorry, had to rewrite the whole thing. expect a nicer site by tomorrow. im patching as we speak." &lt;lb/&gt; - crackticker (&amp;lt;- to blame)&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Multiple Plaintext Attack on Detached PGP Signatures in GnuPG&lt;/item&gt;
      &lt;item&gt;GnuPG Accepts Path Separators and Path Traversals in Literal Data "Filename" Field&lt;/item&gt;
      &lt;item&gt;Cleartext Signature Plaintext Truncated for Hash Calculation&lt;/item&gt;
      &lt;item&gt;Encrypted message malleability checks are incorrectly enforced causing plaintext recovery attacks&lt;/item&gt;
      &lt;item&gt;Memory Corruption in ASCII-Armor Parsing&lt;/item&gt;
      &lt;item&gt;Trusted comment injection (minisign)&lt;/item&gt;
      &lt;item&gt;Cleartext Signature Forgery in the NotDashEscaped header implementation in GnuPG&lt;/item&gt;
      &lt;item&gt;OpenPGP Cleartext Signature Framework Susceptible to Format Confusion&lt;/item&gt;
      &lt;item&gt;GnuPG Output Fails To Distinguish Signature Verification Success From Message Content&lt;/item&gt;
      &lt;item&gt;Cleartext Signature Forgery in GnuPG&lt;/item&gt;
      &lt;item&gt;Radix64 Line-Truncation Enabling Polyglot Attacks&lt;/item&gt;
      &lt;item&gt;GnuPG may downgrade digest algorithm to SHA1 during key signature checking&lt;/item&gt;
      &lt;item&gt;GnuPG Trust Packet Parsing Enables Adding Arbitrary Subkeys&lt;/item&gt;
      &lt;item&gt;Trusted comment Injection (minisign)&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46403200</guid><pubDate>Sat, 27 Dec 2025 17:05:50 +0000</pubDate></item><item><title>USD share as global reserve currency drops to lowest since 1994</title><link>https://wolfstreet.com/2025/12/26/status-of-the-us-dollar-as-global-reserve-currency-usd-share-drops-to-lowest-since-1994/</link><description>&lt;doc fingerprint="625000f5d0a1cb05"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Central Banks diversify their holdings into dozens of smaller “non-traditional reserve currencies.”&lt;/head&gt;
    &lt;head rend="h4"&gt;By Wolf Richter for WOLF STREET.&lt;/head&gt;
    &lt;p&gt;The share of USD-denominated assets held by other central banks dropped to 56.9% of total foreign exchange reserves in Q3, the lowest since 1994, from 57.1% in Q2 and 58.5% in Q1, according to the IMF’s new data on Currency Composition of Official Foreign Exchange Reserves.&lt;/p&gt;
    &lt;p&gt;USD-denominated foreign exchange reserves include US Treasury securities, US mortgage-backed securities (MBS), US agency securities, US corporate bonds, and other USD-denominated assets held by central banks other than the Fed.&lt;/p&gt;
    &lt;p&gt;Excluded are any central bank’s assets denominated in its own currency, such as the Fed’s Treasury securities or the ECB’s euro-denominated securities.&lt;/p&gt;
    &lt;p&gt;It’s not that foreign central banks dumped US-dollar-denominated assets, such as Treasury securities. They did not. They added a little to their holdings. But they added more assets denominated in other currencies, particularly a gaggle of smaller currencies whose combined share has surged, while central banks’ holdings of USD-denominated assets haven’t changed much for a decade, and so the percentage share of those USD assets continued to decline.&lt;/p&gt;
    &lt;p&gt;As the dollar’s share declines toward the 50% line, the dollar would still be by far the largest reserve currency, as all other currencies combined would weigh as much as the dollar. But it does have consequences.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why is having the top reserve currency important for the US?&lt;/head&gt;
    &lt;p&gt;Foreign central banks buying USD-denominated assets, such as Treasury securities, helps push up prices and push down yields of those assets. Being the dominant reserve currency had the effect of helping the US borrow more cheaply to fund its huge twin deficits – the trade deficit and the budget deficit – and thereby has enabled the US to run those huge twin deficits for decades. At some point, this continued decline as a reserve currency, as it reduces demand for USD debt, would make the trade deficit and the budget deficit more difficult to sustain.&lt;/p&gt;
    &lt;p&gt;The dollar’s share had already been below 50% before, in 1990 and 1991, after a long plunge from the peak in 1977 (share of 85.5%). This plunge accompanied a deep crisis in the US with sky-high inflation and interest rates, and four recessions over those years, including the nasty double-dip recession. Central banks lost confidence in the Fed’s willingness or ability to do what it takes to get this inflation under control that had washed over the US in three ever larger waves.&lt;/p&gt;
    &lt;p&gt;The dotted line in the chart below indicates the 50%-share. The dollar’s share bottomed out at 46% in 1991, by which time the Fed had brought inflation under control, and soon, central banks began loading up on dollar-assets.&lt;/p&gt;
    &lt;p&gt;Then came the euro, which turned into the next set-back for the dollar, but not nearly as much as European politicians had promised when pushing the euro through the system; they were talking about parity with the dollar. That talk ended with the Euro Debt Crisis that began in 2009.&lt;/p&gt;
    &lt;p&gt;Then, over the past 10 years, came dozens of smaller “non-traditional reserve currencies,” as the IMF calls them.&lt;/p&gt;
    &lt;p&gt;The chart shows the dollar’s share at the end of each year, except 2025 where it shows the share in Q3:&lt;/p&gt;
    &lt;head rend="h3"&gt;But they didn’t actually dump USD-denominated securities.&lt;/head&gt;
    &lt;p&gt;Foreign central banks increased their holdings of USD-denominated assets by a hair in Q3 to $7.4 trillion, the third increase in a row.&lt;/p&gt;
    &lt;p&gt;Since mid-2014, despite some sharp ups and downs, their holdings of USD-assets have remained essentially flat.&lt;/p&gt;
    &lt;p&gt;So, what has caused the percentage share of USD assets to decline over the years is the growth of foreign exchange reserves denominated in other currencies, particularly many smaller currencies, as central banks have been diversifying their growing pile of foreign exchange assets.&lt;/p&gt;
    &lt;p&gt;The chart below shows foreign central banks’ holdings of USD-denominated assets – US Treasury securities, US MBS, US agency securities, US corporate bonds, etc. – in trillions of dollars:&lt;/p&gt;
    &lt;head rend="h3"&gt;The top foreign exchange reserves by currency.&lt;/head&gt;
    &lt;p&gt;Central banks’ holdings of foreign exchange reserves in all currencies, and expressed in USD, rose to $13.0 trillion in Q3.&lt;/p&gt;
    &lt;p&gt;Top holdings, expressed in USD:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;USD assets: $7.41 trillion&lt;/item&gt;
      &lt;item&gt;Euro assets (EUR): $2.65 trillion&lt;/item&gt;
      &lt;item&gt;Yen assets (YEN): $0.76 trillion&lt;/item&gt;
      &lt;item&gt;British pound assets (GBP): $0.58 trillion&lt;/item&gt;
      &lt;item&gt;Canadian dollar assets (CAD): $0.35 trillion&lt;/item&gt;
      &lt;item&gt;Australian dollar assets (AUD): $0.27 trillion&lt;/item&gt;
      &lt;item&gt;Chinese renminbi (RMB) assets: $0.25 trillion&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The euro’s share, #2, has been around 20% since 2015. Before the Euro Debt Crisis, it was on an upward trajectory and had already risen to nearly 25%.&lt;/p&gt;
    &lt;p&gt;The rest of the reserve currencies are the colorful spaghetti at the bottom of the chart (more in a moment). Combined, they have gained share over the years, at the expense of the dollar, while the euro’s share has remained roughly stable since 2015.&lt;/p&gt;
    &lt;head rend="h3"&gt;The rise of the “non-traditional” reserve currencies.&lt;/head&gt;
    &lt;p&gt;The chart below takes a magnifying glass to the colorful spaghetti at the bottom of the chart above.&lt;/p&gt;
    &lt;p&gt;The soaring red line shows the combined surge of assets denominated in dozens of smaller “nontraditional reserve currencies,” as the IMF calls them. Combined, they reached a share of 5.6%, just below the yen-denominated assets (5.8%).&lt;/p&gt;
    &lt;p&gt;But the share of the RMB (yellow) has been declining since Q1 2022, and its share is now back where it had been in 2019, amid ongoing capital controls, convertibility issues, and a slew of other issues.&lt;/p&gt;
    &lt;p&gt;In other words, the USD and the RMB both have given up share to the “non-traditional reserve currencies” as other central banks have been diversifying away from assets denominated in USD and RMB.&lt;/p&gt;
    &lt;p&gt;In case you missed my update on a slightly less ugly situation: US Government Interest Payments to Tax Receipts, Average Interest Rate on the Debt, and Debt-to-GDP Ratio in Q3 2025&lt;/p&gt;
    &lt;p&gt;Enjoy reading WOLF STREET and want to support it? You can donate. I appreciate it immensely. Click on the mug to find out how:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46403276</guid><pubDate>Sat, 27 Dec 2025 17:14:06 +0000</pubDate></item><item><title>Janet Jackson had the power to crash laptop computers (2022)</title><link>https://devblogs.microsoft.com/oldnewthing/20220816-00/?p=106994</link><description>&lt;doc fingerprint="5455cd69a968ea9f"&gt;
  &lt;main&gt;
    &lt;p&gt;A colleague of mine shared a story from Windows XP product support. A major computer manufacturer discovered that playing the music video for Janet Jackson’s “Rhythm Nation” would crash certain models of laptops. I would not have wanted to be in the laboratory that they must have set up to investigate this problem. Not an artistic judgement.&lt;/p&gt;
    &lt;p&gt;One discovery during the investigation is that playing the music video also crashed some of their competitors’ laptops.&lt;/p&gt;
    &lt;p&gt;And then they discovered something extremely weird: Playing the music video on one laptop caused a laptop sitting nearby to crash, even though that other laptop wasn’t playing the video!&lt;/p&gt;
    &lt;p&gt;What’s going on?&lt;/p&gt;
    &lt;p&gt;It turns out that the song contained one of the natural resonant frequencies for the model of 5400 rpm laptop hard drives that they and other manufacturers used.&lt;/p&gt;
    &lt;p&gt;The manufacturer worked around the problem by adding a custom filter in the audio pipeline that detected and removed the offending frequencies during audio playback.&lt;/p&gt;
    &lt;p&gt;And I’m sure they put a digital version of a “Do not remove” sticker on that audio filter. (Though I’m worried that in the many years since the workaround was added, nobody remembers why it’s there. Hopefully, their laptops are not still carrying this audio filter to protect against damage to a model of hard drive they are no longer using.)&lt;/p&gt;
    &lt;p&gt;And of course, no story about natural resonant frequencies can pass without a reference to the collapse of the Tacoma Narrows Bridge in 1940.¹&lt;/p&gt;
    &lt;p&gt;Related: Shouting in the Datacenter.&lt;/p&gt;
    &lt;p&gt;Bonus chatter: Video version of this story and a Twitter poll.&lt;/p&gt;
    &lt;p&gt;Also, Larry Osterman had a similar experience with a specific game that crashed a prototype PC.&lt;/p&gt;
    &lt;p&gt;Follow-up: Janet Jackson had the power to crash laptop computers, follow-up.&lt;/p&gt;
    &lt;p&gt;¹ Follow-up 2: Yes, I know that the Tacoma Narrows Bridge collapse was not the result of resonance, but I felt I had to drop the reference to forestall the “You forgot to mention the Tacoma Narrows Bridge!” comments.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46403291</guid><pubDate>Sat, 27 Dec 2025 17:16:08 +0000</pubDate></item><item><title>Nvidia's $20B antitrust loophole</title><link>https://ossa-ma.github.io/blog/groq</link><description>&lt;doc fingerprint="3f50c7784766c0bf"&gt;
  &lt;main&gt;
    &lt;p&gt;"You're taking on a giant. What gives you the audacity?"&lt;/p&gt;
    &lt;p&gt;On November 5th, 2025, Groq CEO Jonathan Ross was asked why he was even bothering to challenge Nvidia. He didn't blink:&lt;/p&gt;
    &lt;p&gt;"I think that was a polite way to ask why in the world are we competing with Nvidia, so we're not. Competition is a waste of money; competition fundamentally means you are taking something someone else is doing and trying to copy it. You're wasting R&amp;amp;D dollars trying to do the exact same thing they've done instead of using them to differentiate."&lt;/p&gt;
    &lt;p&gt;49 days later, Nvidia paid $20 billion for Groq's assets and hired Ross along with his entire executive team.&lt;/p&gt;
    &lt;p&gt;Except this wasn't actually an acquisition, at least not in the traditional sense. Nvidia paid $20 billion for Groq's IP and people, but explicitly did NOT buy the company. Jensen Huang's statement was surgical: "While we are adding talented employees to our ranks and licensing Groq's IP, we are not acquiring Groq as a company."&lt;/p&gt;
    &lt;p&gt;That phrasing is the entire story. Because what Nvidia carved out of the deal tells you everything about why this happened.&lt;/p&gt;
    &lt;p&gt;Forget the AI doomer takes about a bubble forming, lets look into the actual reasons.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Nvidia Actually Bought (And What It Didn't)&lt;/head&gt;
    &lt;p&gt;Nvidia acquired:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;All of Groq's intellectual property and patents&lt;/item&gt;
      &lt;item&gt;Non-exclusive licensing rights to Groq's inference technology&lt;/item&gt;
      &lt;item&gt;Jonathan Ross (CEO), Sunny Madra (President), and the entire senior leadership team&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Nvidia explicitly did NOT buy:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GroqCloud (the cloud infrastructure business)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;GroqCloud continues as an independent company under CFO Simon Edwards. This is Nvidia's largest acquisition ever (previous record was Mellanox at $7B in 2019), and they structured it to leave the actual operating business behind. That doesn't happen by accident.&lt;/p&gt;
    &lt;head rend="h2"&gt;LPU vs TPU vs CPU: Why SRAM Matters&lt;/head&gt;
    &lt;p&gt;To understand why Nvidia paid anything for Groq, you need to understand the architectural bet Ross made when he left Google.&lt;/p&gt;
    &lt;p&gt;CPUs and GPUs are built around external DRAM/HBM (High Bandwidth Memory). Every compute operation requires shuttling data between the processor and off-chip memory. This works fine for general-purpose computing, but for inference workloads, that constant round-trip creates latency and energy overhead. GPUs evolved from graphics rendering, so they're optimized for parallel training workloads, not sequential inference.&lt;/p&gt;
    &lt;p&gt;TPUs (Google's Tensor Processing Units) reduce some of this overhead with larger on-chip buffers and a systolic array architecture, but they still rely on HBM for model weights and activations. They're deterministic in execution but non-deterministic in memory access patterns.&lt;/p&gt;
    &lt;p&gt;LPUs (Groq's Language Processing Units) take a different approach: massive on-chip SRAM instead of external DRAM/HBM. The entire model (for models that fit) lives in SRAM with 80 TB/s of bandwidth and 230 MB capacity per chip. No off-chip memory bottleneck. No dynamic scheduling. The architecture is entirely deterministic from compilation to execution. You know exactly what happens at each cycle on each chip at each moment.&lt;/p&gt;
    &lt;p&gt;This creates massive advantages for inference:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Llama 2 7B: 750 tokens/sec (2048 token context)&lt;/item&gt;
      &lt;item&gt;Llama 2 70B: 300 tokens/sec (4096 token context)&lt;/item&gt;
      &lt;item&gt;Mixtral 8x7B: 480 tokens/sec (4096 token context)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And 10x better energy efficiency because you're not constantly moving data across a memory bus.&lt;/p&gt;
    &lt;p&gt;Compare this to SOTA model tokens/sec throughput on GPU inference&lt;/p&gt;
    &lt;p&gt;Serious trade off though, only 14GB of SRAM per rack means you can't run Llama 3.1 405B. And LPUs can't train models at all. This is an inference-only architecture with limited model size support.&lt;/p&gt;
    &lt;p&gt;But here's what makes this interesting: if DRAM/HBM prices continue climbing (DRAM has tripled in a year I should've gone all in DRAM in Jan I'm done with indexes), and if inference becomes the dominant AI workload (which it is), SRAM-based architectures become economically compelling despite the size limitations. Most production AI applications aren't running 405B models. They're running 7B-70B models that need low latency and high throughput.&lt;/p&gt;
    &lt;head rend="h2"&gt;The $13.1B Premium and the Non-Traditional Structure&lt;/head&gt;
    &lt;p&gt;Groq raised $750 million in September 2025 at a post-money valuation of $6.9 billion. Three months later on Xmas Eve, Nvidia paid $20 billion through a "non-exclusive licensing agreement" that acquired all IP and talent while explicitly NOT buying the company.&lt;/p&gt;
    &lt;p&gt;That's a $13.1 billion premium (3x the September valuation) for a company valued at 40x target revenue (double Anthropic's recent 20x multiple) with slashed projections (The Information reported Groq cut over $1B from 2025 revenue forecasts).&lt;/p&gt;
    &lt;p&gt;The structure is the story. Traditional M&amp;amp;A would trigger:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CFIUS review (given Saudi contracts)&lt;/item&gt;
      &lt;item&gt;Antitrust scrutiny (Nvidia's dominant position)&lt;/item&gt;
      &lt;item&gt;Shareholder votes and disclosure requirements&lt;/item&gt;
      &lt;item&gt;Multi-year regulatory review&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Non-exclusive licensing bypasses all of it. No acquisition means no CFIUS review. "Non-exclusive" means no monopoly concerns (anyone can license Groq's tech). No shareholder votes, minimal disclosure.&lt;/p&gt;
    &lt;p&gt;But in practice: Nvidia gets the IP (can integrate before anyone else), the talent (Ross + team can't work for competitors now), and the elimination of GroqCloud (will likely die without IP or leadership). The "non-exclusive" label is legal fiction. When you acquire all the IP and hire everyone who knows how to use it, exclusivity doesn't matter.&lt;/p&gt;
    &lt;p&gt;The question isn't just why Nvidia paid $13.1B more than market rate for technology they could build themselves (they have the PDK, volume, talent, infrastructure, and cash). The question is why they structured it this way.&lt;/p&gt;
    &lt;p&gt;The $13.1B premium bought five things a traditional acquisition couldn't:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Regulatory arbitrage: Non-exclusive licensing avoids years of antitrust review. Structure the deal as IP licensing + talent acquisition, and regulators have no grounds to block it. This alone is worth billions in time and certainty.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Neutralizing Meta/Llama: The April 2025 partnership gave Groq distribution to millions of developers. If Llama + Groq became the default open-source inference stack, Nvidia's ecosystem gets commoditized. Kill the partnership before it scales.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Eliminating GroqCloud without inheriting Saudi contracts: Nvidia has invested in other cloud providers. GroqCloud was a competitor. Traditional acquisition would mean inheriting $1.5B worth of contracts to build AI infrastructure for Saudi Arabia, triggering CFIUS scrutiny. The carve-out kills GroqCloud while avoiding geopolitical entanglement.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Political access: Chamath makes ~$2B (Social Capital's ~10% stake). Sacks looks good (major AI deal under his watch as AI Czar). Nvidia gets favorable regulatory treatment from the Trump administration. Timing it for Christmas Eve ensures minimal media scrutiny of these connections.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Preempting other acquirers: Ross invented Google's TPU. If Google had acquired Groq and brought Ross back, they'd have the original TPU creator plus LPU IP. Amazon and Microsoft were also exploring alternatives to Nvidia GPUs. Better to pay $20B now than compete with Ross at Google/Amazon/Microsoft later.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Two speculative reasons worth considering:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Blocking Google/Amazon/Microsoft from partnering with Groq: Both are developing custom AI chips (Trainium, Maia). If either had hired Ross + team or licensed Groq's tech, Nvidia's inference dominance faces a real challenger. If Google had acquired Groq and brought Ross back, they'd have the original TPU inventor plus LPU IP.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Chiplet integration for future products: Nvidia might integrate LPU as a chiplet alongside GPUs in Blackwell or future architectures. Having Ross's team makes that possible. You can't integrate IP you don't own, and you can't build it without the people who invented it.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;That's how business works when regulation hasn't caught up to structural innovation. Nvidia paid $6.9B for technology and $13.1B to solve everything else using a deal structure that traditional antitrust can't touch.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Saudi Arabia Problem&lt;/head&gt;
    &lt;p&gt;In February 2025, Saudi Arabia committed $1.5 billion to expand Groq's Dammam data center. The publicly stated goal was supporting SDAIA's ALLaM, Saudi Arabia's Arabic large language model. The actual goal was Vision 2030: positioning the Kingdom as an AI superpower.&lt;/p&gt;
    &lt;p&gt;Groq built the region's largest inference cluster in eight days in December 2024. From that Dammam facility, GroqCloud serves "nearly four billion people regionally adjacent to the KSA." This isn't API access. This is critical AI infrastructure for a nation-state, funded by the Public Investment Fund, processing inference workloads at national scale.&lt;/p&gt;
    &lt;p&gt;According to Ross in the Series E announcement, Groq powers Humain's services including the Humain chat product and supported OpenAI's GPT-OSS model release in Saudi Arabia. Groq operates 13 facilities across the US, Canada, Europe, and the Middle East. Ross noted that capacity expanded more than 10% in the month before the funding announcement and all of that capacity was already in use. Customers were asking for more capacity than Groq could satisfy.&lt;/p&gt;
    &lt;p&gt;That creates a CFIUS (Committee on Foreign Investment in the United States) problem. A U.S. chip company, venture-backed by American investors, building sovereign AI capability for Saudi Arabia. If Nvidia had acquired GroqCloud outright, they would inherit those contracts and the regulatory scrutiny that comes with them. Foreign investment reviews, export control questions, congressional inquiries about why an American company is providing cutting-edge AI to a Middle Eastern monarchy.&lt;/p&gt;
    &lt;p&gt;By carving out GroqCloud, Nvidia gets the technology and the talent without the geopolitical mess. The Saudi contracts stay with Edwards and the independent GroqCloud entity. Clean separation. No CFIUS entanglement.&lt;/p&gt;
    &lt;head rend="h2"&gt;Who Actually Gets Paid (And Who Gets Left Behind)&lt;/head&gt;
    &lt;p&gt;The Financial Times reported that "despite the loss of much of its leadership team, Groq said it will continue to operate as an independent company." That's corporate speak for: executives and VCs are cashing out while regular employees watch the company they built get hollowed out.&lt;/p&gt;
    &lt;p&gt;Here's how the $20B probably breaks down (we'll never know the exact numbers since Groq is private and this isn't a traditional acquisition):&lt;/p&gt;
    &lt;p&gt;Who definitely wins:&lt;/p&gt;
    &lt;p&gt;VCs (Chamath, BlackRock, Neuberger Berman, Deutsche Telekom, etc.): They own equity in Groq Inc. Depending on how the deal is structured, they get paid based on their ownership percentage. Social Capital's ~10% stake (after dilution) is worth $1.6-2.4B. BlackRock, Neuberger Berman, and other Series E investors get their cut. They're protected regardless of structure.&lt;/p&gt;
    &lt;p&gt;Executives joining Nvidia (Ross, Madra, senior leadership): They get:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Retention packages from Nvidia (likely massive given the $20B deal size)&lt;/item&gt;
      &lt;item&gt;Sign-on bonuses&lt;/item&gt;
      &lt;item&gt;Accelerated vesting of any unvested Groq equity&lt;/item&gt;
      &lt;item&gt;New Nvidia equity compensation packages&lt;/item&gt;
      &lt;item&gt;Their existing Groq equity gets paid out at the $20B valuation&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Jensen Huang's email to Nvidia staff (obtained by the FT) said they're "adding talented employees to our ranks." When you're talent important enough to be mentioned in a $20B deal, you're getting paid.&lt;/p&gt;
    &lt;p&gt;Who might get paid (depending on deal structure):&lt;/p&gt;
    &lt;p&gt;Regular Groq employees with vested equity: This is where it gets murky. There are three possible scenarios:&lt;/p&gt;
    &lt;p&gt;Scenario 1: The IP licensing fee goes to Groq Inc. If the $20B (or a significant portion) is structured as a licensing fee paid to Groq Inc. for the IP rights, that money gets distributed to all shareholders based on ownership percentage. Employees with vested stock options or RSUs get their pro-rata share. This is the best case for employees.&lt;/p&gt;
    &lt;p&gt;Example: Engineer with 0.01% fully vested equity gets $2M ($20B × 0.01%). Not bad for an engineer who's been there since 2018-2020.&lt;/p&gt;
    &lt;p&gt;Scenario 2: Most of the $20B goes to retention packages If the deal is structured so that the bulk of the money goes to retention/hiring packages for Ross, Madra, and the senior team joining Nvidia, with a smaller licensing fee to Groq Inc., employees get less. Maybe the split is $15B retention, $5B licensing fee. Now that same engineer with 0.01% gets $500K instead of $2M.&lt;/p&gt;
    &lt;p&gt;Scenario 3: The IP licensing is separate from talent acquisition Nvidia pays Groq Inc. for the IP (say $5-7B, roughly the Sept 2024 valuation), and separately pays Ross + team retention packages directly. Regular employees get their share of the IP licensing fee only. That same engineer might get $500-700K.&lt;/p&gt;
    &lt;p&gt;The critical question: Is the $20B figure the total cost to Nvidia (including retention packages), or is it just the IP licensing fee? If it's total cost and most goes to retention, regular employees get scammed.&lt;/p&gt;
    &lt;p&gt;Who definitely gets done over:&lt;/p&gt;
    &lt;p&gt;Employees staying at GroqCloud: These are the people who:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Weren't important enough to be hired by Nvidia&lt;/item&gt;
      &lt;item&gt;Have equity tied to GroqCloud's future value&lt;/item&gt;
      &lt;item&gt;Just watched their CEO, President, and entire engineering leadership leave&lt;/item&gt;
      &lt;item&gt;Are now working for a company with no IP rights, no technical leadership, and no future&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Their equity is worthless. GroqCloud will wind down over 12-18 months. They'll either get laid off or jump ship to wherever they can land. They built the LPU architecture, contributed to the compiler stack, supported the infrastructure, and got nothing while Chamath made $2B.&lt;/p&gt;
    &lt;head rend="h2"&gt;The All-In Connection&lt;/head&gt;
    &lt;p&gt;This gets messier when you look at who was involved. Chamath Palihapitiya, through Social Capital, led Groq's initial $10 million investment in 2017 at a $25 million pre-money valuation. Social Capital secured 28.57% of the company and a board seat for Chamath.&lt;/p&gt;
    &lt;p&gt;David Sacks, Chamath's co-host on the All-In podcast, became Trump's AI and Crypto Czar in late 2024. In July 2025, Sacks co-authored "America's AI Action Plan," a White House strategy document positioning AI as a matter of national security. The plan called for exporting "the full AI technology stack to all countries willing to join America's AI alliance" while preventing adversarial nations from building independent AI capabilities.&lt;/p&gt;
    &lt;p&gt;Two months later at the All-In Summit in September 2025, Tareq Amin (CEO of HUMAIN, Saudi Arabia's state-backed AI company) presented Groq as "the American AI stack in action." This was seven months after the $1.5B Saudi deal.&lt;/p&gt;
    &lt;p&gt;Sunny Madra, Groq's President and COO, was actively promoting the All-In narrative during this period. He appeared on the All-In podcast in March 2024 to provide a "Groq update" and joined Sacks on "This Week in Startups" in November 2023. When Anthropic raised AI safety regulation concerns in October 2025, Madra publicly sided with Sacks, suggesting "one company is causing chaos for the entire industry" and echoing Sacks's accusation that Anthropic was engaged in "regulatory capture."&lt;/p&gt;
    &lt;p&gt;So you have Sacks pushing an "America First" AI policy from the White House while Chamath's portfolio company (where Madra is President) is building AI infrastructure for Saudi Arabia. Then Groq gets presented at the All-In Summit as an example of American AI leadership. Three months later, announced on Christmas Eve when media coverage is minimal, Nvidia pays $20 billion to clean up the geopolitical contradiction.&lt;/p&gt;
    &lt;p&gt;Chamath walks away with $1.6B to $2.4B. Sacks gets a major AI deal under his watch. Nvidia gets favorable regulatory treatment and eliminates multiple problems. The timing ensures minimal scrutiny of these connections.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chamath's $2 Billion Win vs. His SPAC Graveyard&lt;/head&gt;
    &lt;p&gt;After dilution from raising $1.7 billion across Series C, D, and E rounds, Social Capital's stake in Groq was probably 8-12% by the time of the Nvidia deal. At a $20 billion exit, that's $1.6 billion to $2.4 billion.&lt;/p&gt;
    &lt;p&gt;Chamath after using you as exit liquidity and bankrolling it into a 200x win for himself&lt;/p&gt;
    &lt;p&gt;Why do I hate Chamath?&lt;/p&gt;
    &lt;p&gt;Let's look at the sh he dumped on retail with his abysmal SPAC track record:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;IPOA (Virgin Galactic): -98.5% since inception&lt;/item&gt;
      &lt;item&gt;IPOB (Opendoor): -62.9% (was -95% before a brief spike)&lt;/item&gt;
      &lt;item&gt;IPOC (Clover Health): -74.4%&lt;/item&gt;
      &lt;item&gt;IPOE (SoFi): +46% (still underperformed S&amp;amp;P 500's +86%)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Chamath personally dumped $213 million of Virgin Galactic stock before it crashed, using PIPE structures that let him exit while retail investors stayed locked up. In October 2025, when launching a new SPAC, he posted a warning telling retail investors not to buy it: "these vehicles are not ideal for most retail investors."&lt;/p&gt;
    &lt;p&gt;The Groq bet was classic venture capital: concentrated bet on an exceptional founder (Jonathan Ross, the engineer who invented Google's TPU) building non-obvious technology. Social Capital's 2017 internal memo projected a "High" exit scenario of $3.2 billion. They landed within range despite dilution.&lt;/p&gt;
    &lt;p&gt;But retail investors never got access to deals like Groq. They got Virgin Galactic. LOL.&lt;/p&gt;
    &lt;head rend="h2"&gt;To Conclude&lt;/head&gt;
    &lt;p&gt;Nvidia paid $20 billion for a company valued at $6.9 billion three months earlier, structured the deal to avoid traditional M&amp;amp;A oversight, killed the cloud business without inheriting Saudi contracts, and enriched the exact people (Chamath, Sacks) who spent the last year promoting "American AI leadership" while cutting deals with foreign governments. The employees who built the technology either got hired by Nvidia or have been utterly shafted.&lt;/p&gt;
    &lt;p&gt;This was fun to look into. If you have any questions or comments, shout me.&lt;/p&gt;
    &lt;head rend="h2"&gt;Sources&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Nvidia Acquiring Groq for $20B&lt;/item&gt;
      &lt;item&gt;Nvidia-Groq Deal Structure&lt;/item&gt;
      &lt;item&gt;Groq Series E: $750M at $6.9B Valuation&lt;/item&gt;
      &lt;item&gt;Groq LPU Architecture&lt;/item&gt;
      &lt;item&gt;Groq Deterministic Inference&lt;/item&gt;
      &lt;item&gt;Saudi Arabia $1.5B Groq Investment&lt;/item&gt;
      &lt;item&gt;Groq Dammam Data Center&lt;/item&gt;
      &lt;item&gt;America's AI Action Plan&lt;/item&gt;
      &lt;item&gt;White House AI Action Plan&lt;/item&gt;
      &lt;item&gt;Chamath SPAC Performance&lt;/item&gt;
      &lt;item&gt;Chamath Virgin Galactic Stock Dump&lt;/item&gt;
      &lt;item&gt;Chamath SPAC Warning&lt;/item&gt;
      &lt;item&gt;Meta-Groq Partnership&lt;/item&gt;
      &lt;item&gt;HUMAIN Groq Partnership&lt;/item&gt;
      &lt;item&gt;Sunny Madra All-In Appearance&lt;/item&gt;
      &lt;item&gt;David Sacks Anthropic Criticism&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46403559</guid><pubDate>Sat, 27 Dec 2025 17:42:46 +0000</pubDate></item><item><title>Windows 2 for the Apricot PC/Xi</title><link>https://www.ninakalinina.com/notes/win2apri/</link><description>&lt;doc fingerprint="159ee95f3da634d7"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Windows 2 for the Apricot PC/Xi&lt;/head&gt;
    &lt;p&gt;(and Word, and Excel, and so much more) by Nina Kalinina, December 27th, 2025 (rev. 1.01 2025-12-27)&lt;/p&gt;
    &lt;p&gt;I bought my first Apricot PC about three years ago, when I realised I wanted an 8086-based computer. At the time, I knew nothing about it and simply bought it because it looked rad and the price was low. I had no idea that it was not IBM PC-compatible, and that there were very few programs available for it.&lt;/p&gt;
    &lt;p&gt;I have been on a quest to get a modern-ish word processor and spreadsheet program for it ever since. Which eventually made me "port" Windows 2 on it. In this post, I will tell you the story of this port.&lt;/p&gt;
    &lt;p&gt;As a side-quest, I also wrote an article explaining why Windows 2 is kind of awesome. Make sure to check it out, too, if you need more Windows 2 screenshots in your life.&lt;/p&gt;
    &lt;p&gt;A photograph of a dark grey computer with a CRT monitor - an Apricot PC - running Windows 2&lt;/p&gt;
    &lt;p&gt;Please note that most of the images in this post were taken from a real green CRT, and thus their quality might vary. You can click the image to load it in full size.&lt;/p&gt;
    &lt;p&gt;If you own an Apricot PC, or want to try the port in an emulator, check out the project on sr.ht. You need an Apricot PC, PC/Xi or Xen with at least 512 kB of RAM.&lt;/p&gt;
    &lt;head rend="h2"&gt;A few words about the Apricot PC/Xi&lt;/head&gt;
    &lt;p&gt;If you want a personal computer today, your general choice is between a "PC" and a "Mac". Back in the 1980s, you would have to choose between dozens or even hundreds of computer architectures, and "PC" was not necessarily the most popular choice for a computer. One of the most promising market contenders, Victor 9000, also known as Sirius 1, was released in 1981. It gained popularity in Europe, creating a niche market for "Sirius-compatible" computers. Two years later, the British company ACT released its Sirius-compatible Apricot PC.&lt;/p&gt;
    &lt;p&gt;A photograph of the main board of Apricot PC/Xi, in the process of being washed.&lt;/p&gt;
    &lt;p&gt;Apricot PC is a delightful computer with a great design. Its heart is Intel 8086, the older sibling of the 8088 used in the IBM PC. It uses lovely 3.5" floppy disks; and it is the first Western computer to have a 3.5" drive - before Apple Macintosh. The screen is 9 inches, 800x400 pixels, with great image fidelity. The PC/Xi model comes with a 10 megabyte Winchester hard drive, British-made Rodime RO352, the first-ever 3.5" hard drive.&lt;/p&gt;
    &lt;p&gt;A photograph of the computer's display showing multiple images at once: photographs of computer chips, schematics, and oscilloscope charts.&lt;/p&gt;
    &lt;p&gt;The computer is simple enough to be understood by one person in its entirety (over the course of many months of studying). There are schematics, technical manuals, BIOS reference manuals, and example code available for it, too. Its CPU is supported by Microsoft C, Turbo Pascal, and Open Watcom. It even runs MS-DOS (2.0 to 3.20), though, of course, it cannot run any IBM PC programs.&lt;/p&gt;
    &lt;p&gt;The lack of IBM PC-compatibility proved to be fatal for the Apricot. The entirety of its software catalogue is less than 300 megabytes. There is only one graphical game with a soundtrack for it, and it was made in 2025.&lt;/p&gt;
    &lt;p&gt;There were, of course, productivity applications for the Apricot, including Microsoft Word for DOS. But among those, only two word processors had a graphical interface: GEM Write and Microsoft Write for Windows 1. Neither were popular; GEM drivers were lost and re-created by John Elliot in 2012 or so. Windows 1 was thought to be lost.&lt;/p&gt;
    &lt;p&gt;Hypothetically, it should be possible to port a 16-bit Windows to this computer. It would require creating &lt;code&gt;SYSTEM.DRV&lt;/code&gt;, &lt;code&gt;DISPLAY.DRV&lt;/code&gt;, &lt;code&gt;KEYBOARD.DRV&lt;/code&gt;, &lt;code&gt;MOUSE.DRV&lt;/code&gt;, and ideally &lt;code&gt;COMM.DRV&lt;/code&gt; drivers. But that would be a lot of work.&lt;/p&gt;
    &lt;p&gt;A screenshot of Windows 1 Notepad. I didn't have a Windows 1 Write screenshot at hand, but trust me, it looks almost the same.&lt;/p&gt;
    &lt;p&gt;This is where things get interesting. A port of Windows 1 for the Apricot PC (released by ACT in 1987, a year before Windows 2) was miraculously preserved and surfaced online not that long ago. By itself, Windows 1 is unremarkable, as it does not have much useful software. But its driver architecture is not too different from Windows 2, so I thought it might be just about possible to make Windows 2 for the Apricot. And if I could somehow boot Windows 2, I'd be able to run Word, Excel, and Adobe Illustrator on my Apricot.&lt;/p&gt;
    &lt;p&gt;Well, it only took two and a half years to pull it off!&lt;/p&gt;
    &lt;head rend="h2"&gt;Porting Windows 2 on the Apricot&lt;/head&gt;
    &lt;head rend="h3"&gt;Booting, fast and slow&lt;/head&gt;
    &lt;p&gt;Even today, software historians are still arguing whether Windows 2.0 deserves to be called a major Windows update. It added dozens of new kernel features, but it barely changed the driver architecture of the system. The mouse and the keyboard drivers for Windows 2 would work fine on Windows 1, and vice versa. The CGA and EGA video drivers from Windows 1 would allow Windows 2 to boot, but could not render the fonts correctly.&lt;/p&gt;
    &lt;p&gt;A screenshot of Windows 2 for IBM PC with a broken video driver; all text on the screen is garbled.&lt;/p&gt;
    &lt;p&gt;A natural thing to try would be installing Windows 2 with the Apricot drivers for Windows 1. Except that there are no driver files.&lt;/p&gt;
    &lt;p&gt;When you install Windows 1 or 2 on your computer, the SETUP utility combines (links) the driver files with the kernel. It is called "fast boot" and is supposed to improve the boot times of the system. The result of the SETUP is two files, WIN100.BIN and WIN100.OVL. The BIN file is an EXE file in disguise, consisting of the Windows kernel and the system drivers. The OVL file has resources and code that the system uses only from time to time.&lt;/p&gt;
    &lt;p&gt;The Windows 1 port of Apricot was only ever distributed with the "fast boot". The individual driver files were not distributed, so we cannot use them.&lt;/p&gt;
    &lt;head rend="h3"&gt;The stub drivers&lt;/head&gt;
    &lt;p&gt;If there are no drivers, we can make some! Microsoft has a Driver Development Kit for Windows, also known as Windows DDK. The DDK comes with the drivers for the IBM PC, meant to be used as a reference for other platforms. With the help of the DDK, I implemented a stub video driver, and somehow got a stub mouse and system drivers. This was enough to confirm that Windows 2, indeed, can start on the Apricot PC without any patches to the kernel. I had my doubts about that, because Windows 2 comes with EMS memory support, and it might have been using something IBM PC-specific to test for it. Thankfully not.&lt;/p&gt;
    &lt;p&gt;A screenshot of Windows 2 booting in the text mode. The file manager application simply dumps the list of files on the screen, without drawing any windows.&lt;/p&gt;
    &lt;head rend="h3"&gt;Trying to write a video driver&lt;/head&gt;
    &lt;p&gt;Now I could expand the drivers to support the Apricot PC. Keyboard, mouse, and even system drivers are small and simple. The real beast of a driver is DISPLAY.DRV, as it has to implement a large subset of the Windows graphical subsystem. With the reference display drivers, this should not be a problem, as long as the video card supports a graphical mode.&lt;/p&gt;
    &lt;p&gt;But the Apricot PC doesn't have a real graphical mode. It has a 50x25 "graphics screen" with a fake 16x16 font. This is a big problem.&lt;/p&gt;
    &lt;p&gt;A page of the Apricot technical reference explaining the organisation of the Video RAM.&lt;/p&gt;
    &lt;p&gt;The reference video driver from Microsoft makes many bold assumptions about the way video RAM is organised. With the display initialisation routines corrected, the image produced by the reference driver is still undecipherable.&lt;/p&gt;
    &lt;p&gt;A screenshot of the MAME emulator, running Windows 2 on the Apricot. There are no windows, only stripes of black.&lt;/p&gt;
    &lt;p&gt;Writing a driver for such a video card is significantly more painful than designing a VGA-compatible video card for the Apricot. Maybe I return to the Apricot display driver project one day (for the Windows 3.0 port), but for now, I have given up on it.&lt;/p&gt;
    &lt;head rend="h3"&gt;Lose the battle, win the war: re-linking&lt;/head&gt;
    &lt;p&gt;I decided to abandon the video driver writing when I discovered that video drivers from Windows 1 work correctly in Windows 2 if the system has a font from Windows 1, too. This means if I could somehow extract a video driver from the WIN100.BIN/OVL, I would not need to reverse-engineer it to patch in the font support; it could work out of the box. But how?&lt;/p&gt;
    &lt;p&gt;The driver files in WIN100 are not "simply concatenated together": some parts from DISPLAY.DRV ends up in WIN100.BIN, and some in WIN100.OVL. Looking closely at those parts, I realised that the part in WIN100.OVL is identical to the Hercules driver. This gave me an idea: I can get a Hercules video driver; then I could extract CODE and DATA segments along with the Entry Table from the WIN100.BIN, and patch them into the Hercules driver. Unfortunately, not a single NE file format tool supported this use-case. I ended up writing my own tool NExus-relink to assist in this process; the tool is still incomplete, but it gave me enough leverage to finish the job manually.&lt;/p&gt;
    &lt;p&gt;For the video driver, I used a "combine" tool I made for NExus, and then manually patched in the offsets and lengths in the NE header (one for the entry table, two for the segments). Incredibly, this was enough to make Windows 2 happy about the display:&lt;/p&gt;
    &lt;p&gt;A screenshot of Windows 2 running in the MAME emulator.&lt;/p&gt;
    &lt;p&gt;The same trick worked for the keyboard driver, but the mouse driver gave me a headache. I knew that when the mouse is not found, Windows doesn't display it on the screen, so I kept iterating on the driver, going deeper and deeper. The mouse driver has a relocation table of the OS Fixup type, and there are very few things written about it, so I wasn't sure if the driver was loading correctly.&lt;/p&gt;
    &lt;p&gt;I confirmed that the interrupt handler of the driver works, and was about to check the kernel source of the corresponding event handler when I discovered that, in fact, the mouse was working fine. It's just that the cursor wasn't displayed on the screen.&lt;/p&gt;
    &lt;p&gt;In Windows 1/2, the cursor is handled by the video driver to allow hardware acceleration and "hide cursor before taking a screenshot or drawing a bitmap". So, why is the video driver not drawing the cursor?&lt;/p&gt;
    &lt;p&gt;Windows DDK documentation has an answer: the mouse cursor drawing routines in the video driver are called by a timer routine, from the SYSTEM.DRV. I told about this to my fiancée, Atsuko, and she said: "Oh, you didn't notice the cursor wasn't blinking?"&lt;/p&gt;
    &lt;p&gt;Turns out, the timer routines in the SYSTEM.DRV were broken. The SYSTEM.DRV from Windows 1.0 cannot be used with Windows 2, so I implemented the Apricot PC &lt;code&gt;SYSTEM.DRV&lt;/code&gt; using Windows DDK as a reference.&lt;/p&gt;
    &lt;p&gt;With this driver complete, I had Windows 2 working on my Apricot PC/Xi.&lt;/p&gt;
    &lt;head rend="h1"&gt;Windows 2 for the Apricot PC: a tour&lt;/head&gt;
    &lt;p&gt;Welcome, welcome, let me show you around!&lt;/p&gt;
    &lt;p&gt;I am greeted with the AUG logo when I power up my Apricot. I use the AUG BIOS because it supports the upgraded CPU, NEC V30, much better than the original one. Note that my machine has 896 kB of RAM.&lt;/p&gt;
    &lt;p&gt;The PC/Xi comes with a single 720 kB floppy drive and a 10 MB hard drive. I have MS-DOS 3.20 installed on the hard drive.&lt;/p&gt;
    &lt;p&gt;I have created a file called `win.bat` that simply starts the kernel.&lt;/p&gt;
    &lt;p&gt;Welcome to Windows 2. I have GW Basic, Turbo Pascal, Windows 1, Windows 2, Word and Excel installed on the hard drive, and I still have almost 2 megabytes free.&lt;/p&gt;
    &lt;p&gt;PC Paintbrush is one of the few programs that work on both Windows 1 and Windows 2. But it is more stable when running on top of Windows 2. Note that this is not Microsoft Paint (yet).&lt;/p&gt;
    &lt;p&gt;I have to remind you that the screen is monochrome. Pixel dithering works really well on a 100 PPI 800x400 display, creating shades of grey from pixel patterns.&lt;/p&gt;
    &lt;p&gt;The screen is 4:3, so the pixels are not square. I have to pre-process raster images so they would look right on the Apricot's screen. Vector images are fine, though.&lt;/p&gt;
    &lt;p&gt;The default shell for Windows 2 is a bit too minimalistic to my taste. WANG's ClearView for Windows 2 brings a familiar to Windows 3 users PROGMAN-like experience to the Apricot.&lt;/p&gt;
    &lt;p&gt;Windows 1 came with tiling windows; Windows 2 uses overlapping windows that quickly become a disorganised mess. ClearView's window manager can arrange the windows for you.&lt;/p&gt;
    &lt;p&gt;Windows 2 control panel looks a bit funny in monochrome, but it is a powerful reminder that Windows supports 24-bit colour, which is important for printing and publishing.&lt;/p&gt;
    &lt;p&gt;A side note: Apricot's keyboard had an LED in the logo before ThinkPad did.&lt;/p&gt;
    &lt;p&gt;The MicroScreen and re-programmable keys are fully supported by the Windows keyboard driver. There is no ALT key, so "Close" is as close as we can get to pressing ALT+f4. Note that there is a hotkey for starting the XENTEL telephone accessory. The XENTEL button is somewhat similar to a Copilot button, except it can actually be useful in some situations.&lt;/p&gt;
    &lt;p&gt;Microsoft Word for Windows. Word for DOS, a completely different program, was first released back in 1983. Word for Windows had its first release in late 1989 due to a non-competition agreement with Apple. The success of Word for Windows made Microsoft abandon Word for DOS and Word for Mac; all the new versions of Word were based on this Word.&lt;/p&gt;
    &lt;p&gt;Word for Windows is surprisingly powerful for a brand-new product. There is a spellchecker, a page layout editor, and even support for macros. I have deleted the macros to save space on the hard drive, so the README file shows "Error!" where the macros were. The files created by Word for Windows 1.0 can be opened by modern office suites if you save as RTF.&lt;/p&gt;
    &lt;p&gt;Microsoft Excel is a real deal-breaker. There is no other spreadsheet as powerful as Excel on the Apricot.&lt;/p&gt;
    &lt;p&gt;Excel for Windows from 1988 looks almost exactly like Excel for Windows from 2018.&lt;/p&gt;
    &lt;p&gt;My previous trip to Japan was planned between Google Docs and Excel for Windows 2 (I had to convert the file back and forth). I needed a few GB of RAM for Google Docs, and only a few hundred kilobytes for Excel.&lt;/p&gt;
    &lt;p&gt;Excel Help is a hidden gem. It is a hypertext application that feels a lot like a web browser.&lt;/p&gt;
    &lt;p&gt;I used the Help application to see how to create a stonks chart.&lt;/p&gt;
    &lt;p&gt;Creating a stonks chart is surprisingly easy. There are 44 chart types, more than many modern programs offer.&lt;/p&gt;
    &lt;p&gt;Until yesterday, Apricot PC had five graphical games: Chess, Where Is The Owl, Windows 1 Reversi, Windows 1 Minesweeper, and Windows 1 Risk. Now there are many more, including a solitaire and a Taipei mahjongg.&lt;/p&gt;
    &lt;p&gt;That's it! There are many Windows 2 programs I have yet to try on the Apricot, but my quest for running modern-ish Word and Excel for Windows is finally over.&lt;/p&gt;
    &lt;head rend="h2"&gt;Acknowledgments&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Thank you for reading! If you have any questions or comments, please let me know. You can leave a comment in the Mastodon thread about this article.&lt;/item&gt;
      &lt;item&gt;My fiancée not only helped with beta-testing, she even designed a RAM expansion board for the Apricot PC/Xi that was necessary to run Windows on it. Love~&lt;/item&gt;
      &lt;item&gt;This project could not exist without advice from Michal Necasek of os2museum and David Simunič of krnl386 regarding drivers for ancient Windows version.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46403915</guid><pubDate>Sat, 27 Dec 2025 18:22:05 +0000</pubDate></item><item><title>Scientists edited genes in a living person and saved his life</title><link>https://www.popularmechanics.com/science/health/a64815804/crispr-therapy/</link><description>&lt;doc fingerprint="2691111d18b59590"&gt;
  &lt;main&gt;
    &lt;p&gt;Here’s what you’ll learn in this story.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The world’s first bespoke gene therapy saved the life of a newborn with a rare genetic disorder that cause the build-up of life-threatening ammonia in the body.&lt;/item&gt;
      &lt;item&gt;In a race against time, scientists and doctors across the U.S. developed the first in vivo gene therapy, thanks to decades of medical research.&lt;/item&gt;
      &lt;item&gt;After three doses, the newborn patient showed drastic improvement, and this new era of in vivo gene therapies could save the lives of millions more in the future.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Life’s ability to successfully copy three billion distinct letters in the human genome is an absolute biological wonder—but sometimes, mistakes are made. Whether inherited or formed in utero, genetic disorders and other birth defects are common, and occur in one in every 33 babies in the U.S., according to the Centers of Disease Control and Prevention (CDC). For all of human history, a person born with such a disorder likely had to live with the condition, and depending on the defect, those lives could be brutally short.&lt;/p&gt;
    &lt;p&gt;But in 2025, human history changed forever.&lt;/p&gt;
    &lt;p&gt;In a groundbreaking announcement, detailed in a study published in the New England Journal of Medicine, scientists, doctors, and specialists from institutions around the U.S.—including the Children’s Hospital of Philadelphia, University of California-Berkeley, and Penn Medicine—successfully saved the life of a newborn patient named KJ, who had been born with a rare genetic disorder. To pull off this incredible medical feat, doctors employed the world’s first custom in vivo (i.e. inside a living organism, rather than in a petri dish) CRISPR gene therapy. This technique, developed over decades thanks to U.S.-funded medical research, could help alleviate painful lives for millions of people born every year with now-fixable genetic disorders.&lt;/p&gt;
    &lt;p&gt;“Years and years of progress in gene editing and collaboration between researchers and clinicians made this moment possible, and while KJ is just one patient, we hope he is the first of many to benefit from a methodology that can be scaled to fit an individual patient’s needs,” Children’s Hospital of Philadelphia’s Rebecca Ahrens-Nicklas, a co-author of the study, said in a press statement.&lt;/p&gt;
    &lt;p&gt;The details of this incredible medical intervention play out like a made-for-tv medical drama, but the stakes were incredibly real and deadly serious. A week after his birth, doctors noticed something wasn’t quite right with KJ. After ruling out a few possibilities, they stumbled across the unfortunate answer—a rare genetic disorder called severe carbamoyl phosphate synthetase 1 (CPS1) deficiency that affects only one in every 1.3 million babies. This disorder inhibits the body’s ability to get rid of ammonia, a product of protein metabolism. This can have deadly consequences, impact brain development, and wreak havoc on the liver. Usually, the treatment for a disorder like this is a liver transplant, but that was not an option for the infant boy, who was still too young to be considered for the surgery.&lt;/p&gt;
    &lt;p&gt;So, once arriving at a diagnosis, Ahrens-Nicklas contacted a gene-editing specialist at the University of Pennsylvania named Kiran Musunuru and “the clock start[ed]in my mind,” he later told The New York Times. Working with a team of specialists across the country for six months, Ahrens-Nicklas and Musunuru developed a targeted gene therapy to fix KJ’s specific variant of CPS1. Meanwhile, KJ was kept under medical surveillance at the hospital and subsisted on a diet completely devoid of protein to avoid making his condition worse. By the time the CRISPR treatment was ready, KJ was in the 7th percentile for his weight.&lt;/p&gt;
    &lt;p&gt;On February 25, the team began administering the treatment, with Ahrens-Nicklas and Musunuru describing the process as both exciting and terrifying.&lt;/p&gt;
    &lt;p&gt;“One of the most terrifying moments was when I walked into the room and said, ‘I don’t know if it will work but I promise I will do everything I can to make sure it is safe,’” Ahrens-Nicklas told The New York Times.&lt;/p&gt;
    &lt;p&gt;The first infusion took two hours, and within two weeks, KJ began eating protein like a healthy baby. A second dose arrived 22 days later, and about two weeks ago, KJ received a third. Although it’s unknown if he will eventually still need a liver transplant, doctors can now safely say that a human life has been saved thanks to the world’s first bespoke in vivo gene therapy—a huge testament to decades of a research and experimentation. KJ is now at home with his family.&lt;/p&gt;
    &lt;p&gt;“We want each and every patient to have the potential to experience the same results we saw in this first patient, and we hope that other academic investigators will replicate this method for many rare diseases and give many patients a fair shot at living a healthy life,” Musunuru said in a press statement. “The promise of gene therapy that we’ve heard about for decades is coming to fruition, and it’s going to utterly transform the way we approach medicine.”&lt;/p&gt;
    &lt;p&gt;Darren lives in Portland, has a cat, and writes/edits about sci-fi and how our world works. You can find his previous stuff at Gizmodo and Paste if you look hard enough.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46403955</guid><pubDate>Sat, 27 Dec 2025 18:26:46 +0000</pubDate></item><item><title>Toll roads are spreading in America</title><link>https://www.economist.com/united-states/2025/12/18/toll-roads-are-spreading-in-america</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46403992</guid><pubDate>Sat, 27 Dec 2025 18:31:27 +0000</pubDate></item><item><title>Rainbow Six Siege hacked as players get billions of credits and random bans</title><link>https://www.shanethegamer.com/esports-news/rainbow-six-siege-hacked-global-server-outage/</link><description>&lt;doc fingerprint="e5ff45575e6e7597"&gt;
  &lt;main&gt;
    &lt;p&gt;Rainbow Six Siege is currently facing a major crisis, with mounting evidence pointing to a large scale hack or exploit, even as Ubisoft continues to describe the situation as a server incident. The disruption has now escalated into full service outages across all platforms, according to Ubisoft’s own service status page.&lt;/p&gt;
    &lt;p&gt;Players across PC and console are being urged by the community to stay offline, as reports continue to surface of accounts receiving billions of in game credits, rare and developer only skins, and experiencing random bans.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;BREAKING: Ubisoft Rainbow Six Siege servers have been breached.&lt;/p&gt;
      &lt;p&gt;Players are reporting massive amounts of R6 Credits, Renown, Alpha Packs, and exclusive items unexpectedly.&lt;/p&gt;
      &lt;p&gt;Numerous accounts even Ubisoft, including streamers’ and possibly official ones, have received random or… pic.twitter.com/9hGNbBCMAm&lt;/p&gt;
      &lt;p&gt;— Pirat_Nation 🔴 (@Pirat_Nation) December 27, 2025&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;Ubisoft Confirms Widespread Outages Across All Platforms&lt;/head&gt;
    &lt;p&gt;The official service status page for Rainbow Six Siege now shows critical issues across every major platform.&lt;/p&gt;
    &lt;p&gt;On PC, PS4, PS5, Xbox One, and Xbox Series X|S, core services including authentication, in game store access, and matchmaking are all listed as being in outage, while overall connectivity is marked as degraded. Ubisoft states that issues are being investigated, but has not provided a timeline for recovery.&lt;/p&gt;
    &lt;p&gt;The scale of the outages has further fuelled claims that this is far more serious than routine server instability.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ubisoft’s Statement Draws Heavy Criticism&lt;/head&gt;
    &lt;p&gt;Earlier, the official Rainbow Six account acknowledged that it was aware of an incident affecting the game and said teams were working on a resolution. No mention was made of a security breach, hack, or exploit.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We’re aware of an incident currently affecting Rainbow Six Siege. Our teams are working on a resolution.&lt;/p&gt;
      &lt;p&gt;We will share further updates once available.&lt;/p&gt;
      &lt;p&gt;— Rainbow Six Siege X (@Rainbow6Game) December 27, 2025&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That wording has been met with heavy backlash from players, many of whom believe Ubisoft is attempting to downplay the severity of the situation. Community responses have accused the publisher of calling it a server issue while core systems appear compromised.&lt;/p&gt;
    &lt;p&gt;Some players also questioned why the game remained online for hours while accounts were being altered in real time.&lt;/p&gt;
    &lt;head rend="h2"&gt;Players Report Billions of Credits, Dev Skins, and Ban Chaos&lt;/head&gt;
    &lt;p&gt;As the incident unfolded, players reported logging in to find their accounts flooded with billions of R6 Credits and Renown, thousands of Alpha Packs, and access to exclusive cosmetics such as developer skins and Glaciers.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Why is nobody talking about what is happening on Siege right now? Everyone that logs in gets 2 Billion R6 credits, Renown, Developer Skins and Glaciers 😭 pic.twitter.com/9SBiLdrirm&lt;/p&gt;
      &lt;p&gt;— Terd (@Terdsta) December 27, 2025&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;There were also widespread claims that the in game ban feed had been taken over, displaying arbitrary messages. Thousands of accounts were reportedly banned and unbanned at random, including those belonging to streamers and high profile players.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Rainbow Six is fucked pic.twitter.com/OZpDXzttOZ&lt;/p&gt;
      &lt;p&gt;— Pirat_Nation 🔴 (@Pirat_Nation) December 27, 2025&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Prominent Siege creator KingGeorge described the situation as completely broken, warning players not to log in and strongly advising against spending any currency, as it could lead to bans or rollbacks once Ubisoft regains control.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Btw as a side note I would not login right now, definitely don’t spend any credits or renown could lead to a ban.&lt;/p&gt;
      &lt;p&gt;— KingGeorge (@KingGeorge) December 27, 2025&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;Community Expects Rollbacks, Fears Punishment&lt;/head&gt;
    &lt;p&gt;With authentication and account systems affected, many players now expect Ubisoft to roll accounts back to a previous state. However, fears remain that innocent players could still face penalties, especially those who unknowingly spent credits thinking the issue was a visual glitch.&lt;/p&gt;
    &lt;p&gt;Others argue that banning a significant portion of the active player base would be disastrous, adding further pressure on Ubisoft to handle the aftermath carefully.&lt;/p&gt;
    &lt;p&gt;The lack of clear communication has only intensified frustration, with players demanding transparency about what actually happened.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Players Should Do Right Now&lt;/head&gt;
    &lt;p&gt;Until Ubisoft confirms the issue is fully resolved and explains the cause, players are strongly advised to stay offline, avoid logging in, and do not spend any credits or Renown if access is restored.&lt;/p&gt;
    &lt;p&gt;With Rainbow Six Siege’s core services offline worldwide and player accounts potentially compromised, this incident could have lasting implications for the game if not handled properly. Ubisoft is expected to provide further updates as its investigation continues.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46404597</guid><pubDate>Sat, 27 Dec 2025 19:45:28 +0000</pubDate></item><item><title>How we lost communication to entertainment</title><link>https://ploum.net/2025-12-15-communication-entertainment.html</link><description>&lt;doc fingerprint="6d901f930c208a99"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How We Lost Communication to Entertainment&lt;/head&gt;
    &lt;p&gt;by Ploum on 2025-12-15&lt;/p&gt;
    &lt;quote&gt;All our communication channels are morphed into content distribution networks. We are more and more entertained but less and less connected.&lt;/quote&gt;
    &lt;p&gt;A few days ago, I did a controversial blog post about Pixelfed hurting the Fediverse. I defended the theory that, in a communication network, you hurt the trust in the whole network if you create clients that arbitrarily drop messages, something that Pixelfed is doing deliberately. It gathered a lot of reactions.&lt;/p&gt;
    &lt;p&gt;When I originally wrote this post, nearly one year ago, I thought that either I was missing something or Dansup, Pixelfed’s creator, was missing it. We could not both be right. But as the reactions piled in on the Fediverse, I realised that such irreconcilable opinions do not arise only from ignorance or oversight. It usually means that both parties have vastly different assumptions about the world. They don’t live in the same world.&lt;/p&gt;
    &lt;head rend="h2"&gt;Two incompatible universes&lt;/head&gt;
    &lt;p&gt;I started to see a pattern in the two kinds of reactions to my blog post.&lt;/p&gt;
    &lt;p&gt;There were people like me, often above 40, who like sending emails and browsing old-fashioned websites. We think of ActivityPub as a "communication protocol" between humans. As such, anything that implies losing messages without feedback is the worst thing that could happen. Not losing messages is the top priority of a communication protocol.&lt;/p&gt;
    &lt;p&gt;And then there are people like Dansup, who believe that ActivityPub is a content consumption protocol. It’s there for entertainment. You create as many accounts as the kinds of media you want to consume. Dansup himself is communicating through a Mastodon account, not a Pixelfed one. Many Pixelfed users also have a Mastodon account, and they never questioned that. They actually want multiple accounts for different use cases.&lt;/p&gt;
    &lt;p&gt;On the Fediverse threads, nearly all the people defending the Pixelfed philosophy posted from Mastodon accounts. They usually boasted about having both a Mastodon and a Pixelfed account.&lt;/p&gt;
    &lt;head rend="h2"&gt;A multiplicity of accounts&lt;/head&gt;
    &lt;p&gt;To me, the very goal of interoperability is not to force you into creating multiple accounts. Big Monopolies have managed to convince people that they need one account on each platform. This was done, on purpose, for purely unethical reasons in order to keep users captive.&lt;/p&gt;
    &lt;p&gt;That brainwash/marketing is so deeply entrenched that most people cannot see an alternative anymore. It looks like a natural law: you need an account on a platform to communicate with someone on that platform. That also explains why most politicians want to "regulate" Facebook or X. They think it is impossible not to be on those platforms. They believe those platforms are "public spaces" while they truly are "private spaces trying to destroy all other public spaces in order to get a monopoly."&lt;/p&gt;
    &lt;p&gt;People flock to the Fediverse with this philosophy of "one platform, one account", which makes no sense if you truly want to create a federated communication protocol like email or XMPP.&lt;/p&gt;
    &lt;p&gt;But Manuel Moreale cracked it for me: the Fediverse is not a communication network. ActivityPub is not a communication protocol. The spec says it: ActivityPub is a protocol to build a "social platform" whose goal is "to deliver content."&lt;/p&gt;
    &lt;quote&gt;The ActivityPub protocol is a decentralised social networking protocol based upon the ActivityStreams 2.0 data format. It provides a client to server API for creating, updating and deleting content, as well as a federated server-to-server API for delivering notifications and content. (official W3C definition of ActivityPub)&lt;/quote&gt;
    &lt;head rend="h2"&gt;No more communication&lt;/head&gt;
    &lt;p&gt;But aren’t social networks also communication networks? That’s what I thought. That’s how they historically were marketed. That’s what we all believed during the "Arab Spring."&lt;/p&gt;
    &lt;p&gt;But that was a lie. Communication networks are not profitable. Social networks are entertainment platforms, media consumption protocols. Historically, they disguised themselves as communication platforms to attract users and keep them captive.&lt;/p&gt;
    &lt;p&gt;The point was never to avoid missing a message sent from a fellow human being. The point was always to fill your time with "content."&lt;/p&gt;
    &lt;p&gt;We dreamed of decentralised social networks as "email 2.0." They truly are "television 2.0."&lt;/p&gt;
    &lt;p&gt;They are entertainment platforms that delegate media creation to the users themselves the same way Uber replaced taxis by having people drive others in their own car.&lt;/p&gt;
    &lt;p&gt;But what was created as "ride-sharing" was in fact a way to 1) destroy competition and 2) make a shittier service while people producing the work were paid less and lost labour rights. It was never about the social!&lt;/p&gt;
    &lt;head rend="h2"&gt;The lost messages&lt;/head&gt;
    &lt;p&gt;My own interpretation is that social media users don’t mind losing messages because they were raised on algorithmic platforms that did that all the time. They don’t see the point in trusting a platform because they never experienced a trusted means of communication.&lt;/p&gt;
    &lt;p&gt;Now that I write it, it may also explain why instant messaging became the dominant communication medium: because if you don’t receive an immediate answer, you don’t even trust the recipient to have received your messages. In fact, even if the message was received, you don’t even trust the recipient's attention span to remember the message.&lt;/p&gt;
    &lt;p&gt;Multiple studies have confirmed that we don’t remember the vast majority of what we see while doomscrolling. While the "view" was registered to increase statistics, we don’t have the slightest memory of most of that content, even after only a few seconds. It thus makes sense not to consider social media as a means of communication at all.&lt;/p&gt;
    &lt;p&gt;There’s no need for a reliable communication protocol if we assume that human brains are not reliable enough to handle asynchronous messages.&lt;/p&gt;
    &lt;p&gt;It’s not Dansup who is missing something. It is me who is unadapted to the current society. I understand now that Pixelfed was only following some design decisions and protocol abuses fathered by Mastodon. Pixelfed was my own "gotcha" moment because I never understood Instagram in the first place, and, in my eyes, Pixelfed was no better. But if you take that route, Mastodon is no better than Twitter.&lt;/p&gt;
    &lt;p&gt;Many reactions pointed, justly, that other Fediverse tools such as PeerTube, WriteFreely, or Mobilizon were just not displaying messages at all.&lt;/p&gt;
    &lt;p&gt;I didn’t consider it a big problem because they never pretended to do it in the first place. Nobody uses those tools to follow others. There’s no expectation. Those platforms are "publish only." But this is still a big flaw in the Fediverse! Someone could, using autocompletion, send a message pinging your PeerTube address and you will never see it. Try autocomplete "@ploum" from your Mastodon account and guess which suggestion is the only one that will send me a valid notification!&lt;/p&gt;
    &lt;p&gt;On a more positive note, I should give credit to Dansup for announcing that Pixelfed will soon allow people to optionally "not drop" text messages.&lt;/p&gt;
    &lt;head rend="h2"&gt;How we lost email&lt;/head&gt;
    &lt;p&gt;I cling to asynchronous reliable communications, but those are disappearing. I use email a lot because I see it as a true means of communication: reliable, asynchronous, decentralised, standardised, manageable offline with my own tools. But many people, even barely younger than me, tell me that email is "too formal" or "for old people" or "even worse than social network feeds."&lt;/p&gt;
    &lt;p&gt;And they are probably right. I like it because I’ve learned to use it. I apply a strong inbox 0 methodology. If I don’t reply or act on your email, it is because I decided not to. I’m actively keeping my inbox clean by sharing only disposable email addresses that I disable once they start to be spammed.&lt;/p&gt;
    &lt;p&gt;But for most people, their email inbox is simply one more feed full of bad advertising. They have 4 or 5 digit unread count. They scroll through their inbox like they do through their social media feeds.&lt;/p&gt;
    &lt;head rend="h2"&gt;Boringness of communications&lt;/head&gt;
    &lt;p&gt;The main problem with reliable communication protocols? It is a mostly solved problem. Build simple websites, read RSS feeds, write emails. Use IRC and XMPP if you truly want real-time communication. Those are working and working great.&lt;/p&gt;
    &lt;p&gt;And because of that, they are boring.&lt;/p&gt;
    &lt;p&gt;Communications protocols are boring. They don’t give you that well-studied random hit of dopamine. They don’t make you addicted.&lt;/p&gt;
    &lt;p&gt;They don’t make you addicted which means they are not hugely profitable and thus are not advertised. They are not new. They are not as shiny as a new app or a new random chatbot.&lt;/p&gt;
    &lt;p&gt;The problem with communication protocols was never the protocol part. It’s the communication part. A few sad humans never wanted to communicate in the first place and managed to become billionaires by convincing the rest of mankind that being entertained is better than communicating with other humans.&lt;/p&gt;
    &lt;head rend="h2"&gt;As long as I’m not alone&lt;/head&gt;
    &lt;p&gt;We believe that a communication network must reach a critical mass to be really useful. People stay on Facebook to "stay in touch with the majority." I don’t believe that lie anymore. I’m falling back to good old mailing lists. I’m reading the Web and Gemini while offline through Offpunk. I also handle my emails asynchronously while offline.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Offpunk, an offline-first command-line browser (offpunk.net)&lt;/item&gt;
      &lt;item&gt;There Is No Content on Gemini (ploum.net)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I may be part of an endangered species.&lt;/p&gt;
    &lt;p&gt;It doesn’t matter. I made peace with the fact that I will never get in touch with everyone. As long as there are people posting on their gemlogs or blogs with RSS feeds, as long as there are people willing to read my emails without automatically summarising them, there will be a place for those who want to simply communicate. A protected reserve.&lt;/p&gt;
    &lt;p&gt;You are welcome to join!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Illustration of a message board piled with messages by David Revoy (CC By 4.0)&lt;/item&gt;
      &lt;item&gt;Illustration of animal meeting at an intersection with messages by David Revoy (CC By 4.0)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I’m Ploum, a writer and an engineer. I like to explore how technology impacts society. You can subscribe by email or by rss. I value privacy and never share your adress.&lt;/p&gt;
    &lt;p&gt;I write science-fiction novels in French. For Bikepunk, my new post-apocalyptic-cyclist book, my publisher is looking for contacts in other countries to distribute it in languages other than French. If you can help, contact me!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46404848</guid><pubDate>Sat, 27 Dec 2025 20:15:01 +0000</pubDate></item><item><title>'Off switch' discovery could help clear our brains of a common parasite</title><link>https://www.sciencealert.com/off-switch-discovery-could-help-clear-our-brains-of-a-common-parasite</link><description>&lt;doc fingerprint="ba2289379cf997d1"&gt;
  &lt;main&gt;
    &lt;p&gt;There's a parasite living in the brains of 40 million Americans, and most of these human hosts are completely unaware.&lt;/p&gt;
    &lt;p&gt;Doctors don't usually treat this bug unless it begins wreaking havoc on the bodies of patients with weakened immune systems, but a new discovery may make short work of the invader without the typical risks.&lt;/p&gt;
    &lt;p&gt;Parasitologist Rajshekhar Gaji runs a lab at the Virginia-Maryland College of Veterinary Medicine, investigating what makes the parasite, Toxoplasma gondii, tick.&lt;/p&gt;
    &lt;p&gt;Related: Cat Parasite Can Seriously Disrupt Brain Function, Study Suggests&lt;/p&gt;
    &lt;p&gt;"The parasite that's sitting in the brain gets reactivated, starts multiplying, and then it's fatal," Gaji explains. "Because of that, the parasite is a dreaded pathogen."&lt;/p&gt;
    &lt;p&gt;T. gondii is closely associated with cats, which are the only known hosts within which the parasite can reproduce sexually. But once its offspring are shed in the cat's poop, there are very few warm-blooded species T. gondii won't make a home in.&lt;/p&gt;
    &lt;p&gt;For most of us, an infection with T. gondii will fall completely under the radar. For those with cancer, HIV, or who are on immunosuppressants, the parasite presents significant risks.&lt;/p&gt;
    &lt;p&gt;Without a healthy immune system to keep T. gondii at bay, these patients can quickly develop a disease known as toxoplasmosis, which can bring flu-like symptoms, swollen lymph nodes, and brain inflammation.&lt;/p&gt;
    &lt;p&gt;The parasite can also be transmitted to the placenta of a developing fetus during pregnancy. This form of the disease, congenital toxoplasmosis, can cause developmental problems, and even miscarriages.&lt;/p&gt;
    &lt;p&gt;Treatments for acute toxoplasmosis involve medications that target mechanisms in the parasite that are biologically similar to processes in our own bodies. This often puts patients at risk of severe side effects, restricting treatments to situations where infections are considered to be dire.&lt;/p&gt;
    &lt;p&gt;Gaji and his team might have found a lead, though: in a new study, they have shown that switching off just a single protein inside the microscopic parasite can kill it.&lt;/p&gt;
    &lt;p&gt;The protein, TgAP2X-7, appears to be essential to the parasite's ability to invade a host, form plaques, and self-replicate. To prove this, the team genetically modified some parasites so that their TgAP2X-7 proteins function normally unless auxin (a plant hormone that regulates growth) is added, in which case the proteins would quickly degrade.&lt;/p&gt;
    &lt;p&gt;Auxin, they established prior, had no impact on T. gondii growth or plaque formation on its own, so any effect it had on the genetically modified parasites could be attributed to the fact that the TgAP2X-7 proteins had been destroyed.&lt;/p&gt;
    &lt;p&gt;Deprived of TgAP2X-7, the parasites couldn't form plaques, and their ability to invade hosts (which, in this lab study, were human foreskin cells) was severely impaired.&lt;/p&gt;
    &lt;p&gt;Usually, they have a near-100 percent success rate invading these kinds of cells, but without that key protein, success dropped to below 50 percent. They also struggled to replicate.&lt;/p&gt;
    &lt;p&gt;"These parasites completely stop growing, and they cannot survive," Gaji says. "That shows this particular transcription factor is essential for the parasite to survive within the host."&lt;/p&gt;
    &lt;p&gt;Best of all, this protein bears no similarities to anything in the human body, which means there's potential to target it without harming patients.&lt;/p&gt;
    &lt;p&gt;"There is a critical need for the identification and development of novel therapeutic options to treat Toxoplasma infections," first author parasitologist Padmaja Mandadi and team write.&lt;/p&gt;
    &lt;p&gt;"Unique transcription factors that regulate the expression of proteins involved in these lytic cycle events could open new opportunities for therapeutic interventions."&lt;/p&gt;
    &lt;p&gt;Given that much of the damage wrought by T. gondii comes from repeated cycles of cell invasion, replication, and destruction, knowing how to interrupt these cycles could lead to new ways of treating the disease.&lt;/p&gt;
    &lt;p&gt;This research was published in mSphere.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46404952</guid><pubDate>Sat, 27 Dec 2025 20:28:07 +0000</pubDate></item><item><title>White House pushes to dismantle leading climate and weather research center</title><link>https://www.pbs.org/newshour/show/white-house-pushes-to-dismantle-leading-climate-and-weather-research-center</link><description>&lt;doc fingerprint="3a901153a7fcad99"&gt;
  &lt;main&gt;
    &lt;p&gt;By — William Brangham William Brangham By — Jackson Hudgins Jackson Hudgins Leave your feedback Share Copy URL https://www.pbs.org/newshour/show/white-house-pushes-to-dismantle-leading-climate-and-weather-research-center Email Facebook Twitter LinkedIn Pinterest Tumblr Share on Facebook Share on Twitter Transcript Audio The Trump administration says it plans to dismantle the National Center for Atmospheric Research in Colorado, which is the nation’s premier atmospheric science center. The center was founded in 1960 and has facilitated generations of breakthroughs in climate and weather science. William Brangham discussed the move with climate scientist Kim Cobb and meteorologist Matthew Cappucci. Read the Full Transcript Notice: Transcripts are machine and human generated and lightly edited for accuracy. They may contain errors. William Brangham: The Trump administration says it plans to dismantle the National Center for Atmospheric Research in Colorado, which is the nation's premier atmospheric science center.In announcing the closing, Budget Director Russell Vought called the center -- quote -- "one of the largest sources of climate alarmism in the country."NCAR, as the center is known, was founded in 1960 and has facilitated generations of breakthroughs in climate and weather science. The announcement has drawn outcry from meteorologists and climate scientists across the country.Earlier this week, I spoke with two of them who are very familiar with the center's work. Brown University's Kim Cobb is a climate scientist and director of the Institute at Brown for Environment and Society, and Matthew Cappucci is senior meteorologist at MyRadar.Thank you both so much for being here.Kim Cobb, to you first. What is NCAR and why, as a climate scientist, is it so important and seemingly precious to this community? Kim Cobb, Brown University: Thanks for having me, William.NCAR is a really historic institution in our field. It, of course, dates back decades now. And, over that time, it has really woven itself into the fabric of both weather and climate science across the country and around the world.We're talking about unique, one-of-a-kind facilities like supercomputers, ticked-out airplanes, and most importantly, a staff of over 800 people who are at the top of their game in innovating in weather and climate science for public good, putting out data that is on every single climate scientist's computer around the country, if not around the world, and a nexus of collaboration as well that is important training grounds for the next generation of leaders. William Brangham: And, Matthew Cappucci, as a meteorologist, how important is NCAR to your profession? Matthew Cappucci, Senior Meteorologist, MyRadar: I mean, NCAR is really the birthplace of all the tools we use, both technologically.And, really, the discoveries that are made at NCAR are crucial to our understanding of how the atmosphere works. That's where we first learned about the MJO, the Madden-Julian Oscillation, one of the biggest overturning circulations in the atmosphere that governs how so many things, for example, hurricanes behave.It's where we first created a special product used by airplanes when they're landing to avoid wind shear, disruptive changing winds with height that could cause plane crashes. They invented a system there to prevent that. That's where dropsondes were invented, those little probes that are dropped out of the belly of airplanes in the middle of hurricanes to figure out how strong the hurricanes are.So, so many different tools and discoveries have come from NCAR. In addition, the modeling is incredibly important. And if we're sort of putting the brakes on that, I worry about the implications for weather forecasting. William Brangham: Kim Cobb, well, what more on that? Well, let's say NCAR is broken up. What are the impacts, both for the scientific community and for Americans who benefit from its research? Kim Cobb: I think what's really important to remember is that NCAR focuses on the entire continuum from weather that ranges over hours and days that's designed to aid the forecasts that keep people safe and protect infrastructure and our economy.But they also go all the way out to looking decades into the future and really understanding that most important intersection right now, how weather is responding to ongoing climate change. It's these kinds of questions at the very forefront of our field that they're focused on right now.And these are innovations that are going to reap absolutely untold dividends through time. So, by breaking this -- these up and its component parts, if you will, first of all, the administration has made clear that it's the climate portion of the portfolio which they are taking squarely in aim.And, of course, that is the portion that is right now so important to invest in as we seek to understand more about the coming threats and impacts of ongoing climate change, 2025, of course, wrapping up to be tied for the second warmest year ever. William Brangham: And, Matthew, the White House has argued that NCAR and its undertakings and its work is somehow contaminated with woke ideology or climate alarmism.Is there research or data that is coming out of NCAR that is politicized or ideological in any way? Matthew Cappucci: Truth be told, no. The atmosphere does not possess a voter registration card. I think it's important to remember that scientists do science. And, really, the only people doing the politicization are, for the most part, politicians and the general public and the media.It worries me, though, that this fits into an overall pattern of the demonization of both science and academia. The idea that we're trying to shut down science that produces results we don't like, it's a very worrisome trend. And we have seen this other times in history, and it never really ended well.And I'm just very concerned about the tone that's being taken that simply because one political party or even one political person doesn't like the fact that we're learning about the atmosphere. William Brangham: I mean, Kim, as Matthew is saying, we know that President Trump has called climate change a hoax. He believes it's nothing that we need to focus on. He has directed so much of the administration to move away from climate research, from renewable energy, doubling down on fossil fuels.I'm just curious as to what -- are you worried similarly about the future of climate research if we continue to chip away at these foundational projects? Kim Cobb: Well, obviously, as Matthew said, we turn our backs on science to great risk and peril.And I think most Americans get it right now. In the headlines every year are these horrific climate-fueled disasters that have taken such a toll on communities and our national economy, to the tune of billions of dollars per year. So this is not a controversial subject in that regard. People do want the best available science information to protect themselves.And that's exactly what NCAR and its scientists are focused on. And I think the Trump administration is just not understanding how long an investment has been made to get us to this point and the many dividends that we have already reached and that, once you break something like this, it's really going to be hard to put it back together again. That's my concern. William Brangham: Matthew, the OMB director in his announcement said they will do a systematic review of the work that NCAR does, and critical weather information and research will just get sent somewhere else or done in another location.How confident are you that a breakup of NCAR could still keep some of the critical elements intact? Matthew Cappucci: I think so many times this administration has historically put the cart before the horse. And what I mean by that is, it seems like just a year ago, they were cutting a huge chunk of National Weather Service forecasters.And then, after they were laid off, the government realized, oh, wait, we kind of need them, and brought them back. This seems like another really shortsighted decision made by the administration without realizing or fully researching the potential implications of what could happen.And I also just sort of think this strikes the wrong tone for just about everybody. Weather and climate affect everybody. And, realistically, you're much more likely to be hit by a tornado or hurricane in a red state. And so I'm surprised by sort of Trump and his administration doing something that could potentially have negative impacts on his own core audience and following. William Brangham: All right, that is Matthew Cappucci and Kim Cobb.Thank you both so much for being here. We really appreciate it. Listen to this Segment Watch Watch the Full Episode PBS NewsHour from Dec 26, 2025 By — William Brangham William Brangham William Brangham is an award-winning correspondent, producer, and substitute anchor for the PBS News Hour. @WmBrangham By — Jackson Hudgins Jackson Hudgins&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46405183</guid><pubDate>Sat, 27 Dec 2025 21:01:09 +0000</pubDate></item><item><title>An Ounce of Silver Is Now Worth More Than a Barrel of Oil</title><link>https://www.wsj.com/finance/commodities-futures/an-ounce-of-silver-is-now-worth-more-than-a-barrel-of-oil-196e149e</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46405235</guid><pubDate>Sat, 27 Dec 2025 21:06:47 +0000</pubDate></item><item><title>Richard Stallman at the First Hackers Conference in 1984 [video]</title><link>https://www.youtube.com/watch?v=Hf2pfzzWPYE</link><description>&lt;doc fingerprint="7055905545553646"&gt;
  &lt;main&gt;
    &lt;p&gt;About Press Copyright Contact us Creators Advertise Developers Terms Privacy Policy &amp;amp; Safety How YouTube works Test new features NFL Sunday Ticket © 2025 Google LLC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46405306</guid><pubDate>Sat, 27 Dec 2025 21:15:14 +0000</pubDate></item><item><title>In 1995, a Netscape employee wrote a hack in 10 days that now runs the Internet</title><link>https://arstechnica.com/gadgets/2025/12/in-1995-a-netscape-employee-wrote-a-hack-in-10-days-that-now-runs-the-internet/</link><description>&lt;doc fingerprint="ed27d92981a3b276"&gt;
  &lt;main&gt;
    &lt;p&gt;Thirty years ago today, Netscape Communications and Sun Microsystems issued a joint press release announcing JavaScript, an object scripting language designed for creating interactive web applications. The language emerged from a frantic 10-day sprint at pioneering browser company Netscape, where engineer Brendan Eich hacked together a working internal prototype during May 1995.&lt;/p&gt;
    &lt;p&gt;While the JavaScript language didn’t ship publicly until that September and didn’t reach a 1.0 release until March 1996, the descendants of Eich’s initial 10-day hack now run on approximately 98.9 percent of all websites with client-side code, making JavaScript the dominant programming language of the web. It’s wildly popular; beyond the browser, JavaScript powers server backends, mobile apps, desktop software, and even some embedded systems. According to several surveys, JavaScript consistently ranks among the most widely used programming languages in the world.&lt;/p&gt;
    &lt;p&gt;In crafting JavaScript, Netscape wanted a scripting language that could make webpages interactive, something lightweight that would appeal to web designers and non-professional programmers. Eich drew from several influences: The syntax looked like a trendy new programming language called Java to satisfy Netscape management, but its guts borrowed concepts from Scheme, a language Eich admired, and Self, which contributed JavaScript’s prototype-based object model.&lt;/p&gt;
    &lt;p&gt;The JavaScript partnership secured endorsements from 28 major tech companies, but amusingly, the December 1995 announcement now reads like a tech industry epitaph. The endorsing companies included Digital Equipment Corporation (absorbed by Compaq, then HP), Silicon Graphics (bankrupt), and Netscape itself (bought by AOL, dismantled). Sun Microsystems, co-creator of JavaScript and owner of Java, was acquired by Oracle in 2010. JavaScript outlived them all.&lt;/p&gt;
    &lt;head rend="h2"&gt;What’s in a name?&lt;/head&gt;
    &lt;p&gt;The 10-day creation story has become programming folklore, but even with that kernel of truth we mentioned, it tends to oversimplify the timeline. Eich’s sprint produced a working demo, not a finished language, and over the next year, Netscape continued tweaking the design. The rushed development left JavaScript with quirks and inconsistencies that developers still complain about today. So many changes were coming down the pipeline, in fact, that it began to annoy one of the industry’s most prominent figures at the time.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46405375</guid><pubDate>Sat, 27 Dec 2025 21:22:44 +0000</pubDate></item><item><title>How Pfizer ended up passing on my GLP-1 work back in the early '90s</title><link>https://www.statnews.com/2024/09/09/glp-1-history-pfizer-john-baxter-jeffrey-flier-calbio-metabio/</link><description>&lt;doc fingerprint="185c5a958bdf0196"&gt;
  &lt;main&gt;
    &lt;p&gt;One of the biopharma industry’s marvels of the 2020s has been the enormous medical and financial success of the GLP-1 class of drugs. But the path to commercialization of these therapies was far more complex than most understand, and some of the earliest history has never been presented.&lt;/p&gt;
    &lt;p&gt;Beginning in 1988, I was part of what I believe was the earliest commercial effort to develop GLP-1 as a metabolic therapy. Despite extremely promising results, Pfizer, the major funder of the work in alliance with California Biotechnology, abandoned the effort around 1991 after mistakenly concluding that the GLP-1 therapeutic approach was not worth continuing. To be clear, I’m not writing this to claim credit for discovery or development of GLP-1s or anything like that. Rather, I think the story offers valuable lessons on drug development for pharmaceutical companies, researchers, and the general public alike.&lt;/p&gt;
    &lt;p&gt;In 1987, John Baxter — a professor of medicine at UCSF, leader in molecular endocrinology, and founder of a biotech firm named California Biotechnology — asked me to work with him to create a start-up focused on metabolic disease, and I enthusiastically agreed. I enlisted two Harvard colleagues, Ron Kahn and Bruce Spiegelman, and together we outlined an approach that included a search for novel insulin analogues and insulin sensitizing agents, identifying the protein responsible for obesity in genetically obese mice (six years before identification of the ob gene), and exploration of gut factors regulating metabolism, such as the “incretins” that enhanced insulin secretion.&lt;/p&gt;
    &lt;head rend="h2"&gt;This article is exclusive to STAT+ subscribers&lt;/head&gt;
    &lt;head rend="h3"&gt;Unlock this article — plus in-depth analysis, newsletters, premium events, and news alerts.&lt;/head&gt;
    &lt;p&gt;Already have an account? Log in&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46405480</guid><pubDate>Sat, 27 Dec 2025 21:36:22 +0000</pubDate></item><item><title>How We Found Out About COINTELPRO (2014)</title><link>https://monthlyreview.org/articles/how-we-found-out-about-cointelpro/</link><description>&lt;doc fingerprint="31efabff6d1a84b1"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Also in this issue&lt;/head&gt;
    &lt;head rend="h3"&gt;Books by Martin Oppenheimer&lt;/head&gt;
    &lt;p&gt; White Collar Politics &lt;/p&gt;
    &lt;p&gt;by Martin Oppenheimer&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46405481</guid><pubDate>Sat, 27 Dec 2025 21:36:27 +0000</pubDate></item><item><title>Bankruptcies are exploding across the economy</title><link>https://www.businessinsider.com/bankruptcies-across-economy-small-business-households-corporate-2025-12</link><description>&lt;doc fingerprint="5f8c0345c6bfa6c0"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;From corporate giants to mom-and-pop shops, bankruptcies are piling up across the US this year.&lt;/item&gt;
      &lt;item&gt;Large corporate bankruptcies have hit their highest level in 15 years.&lt;/item&gt;
      &lt;item&gt;"Bankruptcies seem to be kind of all over the place," one veteran bankruptcy attorney said.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Bankruptcies aren't just rising — they're suddenly everywhere.&lt;/p&gt;
    &lt;p&gt;From billion-dollar giants to mom-and-pop shops to everyday individuals, bankruptcies are piling up across the US this year, with large corporate bankruptcies already hitting their highest level in 15 years.&lt;/p&gt;
    &lt;p&gt;The surge in bankruptcies highlights the growing financial pressures facing consumers and companies as costs climb amid a tougher borrowing environment.&lt;/p&gt;
    &lt;p&gt;"Rising costs, tighter credit conditions, and ongoing geopolitical volatility continue to exert pressure on households and businesses already facing financial strain," Amy Quackenboss, the executive director at the American Bankruptcy Institute, said earlier this month.&lt;/p&gt;
    &lt;p&gt;Unlike past downturns, this wave of bankruptcies appears to be hitting nearly every corner of the economy. It's sweeping across a range of sectors in what one veteran bankruptcy attorney described as a strikingly "unusual" pattern.&lt;/p&gt;
    &lt;head rend="h2"&gt;A wide cross-section of industries&lt;/head&gt;
    &lt;p&gt;Typically, corporate failures tend to be "industry sticky," meaning they cluster within the same sectors, Robert Stark, a partner at the law firm Brown Rudnick and chair of its bankruptcy and corporate restructuring practice group, recently told Business Insider.&lt;/p&gt;
    &lt;p&gt;In 2022, for example, he said there was the "big crypto winter" culminating in a string of cryptocurrency firm bankruptcies, including Sam Bankman-Fried's FTX.&lt;/p&gt;
    &lt;p&gt;"That was a sticky event — a lot in the industry kind of went through bankruptcy at the same time," Stark said. "What we have now, which is the thing that I find kind of interesting, is I don't see as much stickiness as I'm used to seeing."&lt;/p&gt;
    &lt;p&gt;"Bankruptcies seem to be kind of all over the place," added Stark, who represents creditor groups in the 2025 bankruptcies of auto parts company First Brands and fintech startup Linqto, as well as the equity committee in the Chapter 11 case of genetic testing company 23andMe.&lt;/p&gt;
    &lt;p&gt;Stark said that he can't pinpoint a clear cause for the "broad smattering of industries" now in bankruptcy, but he called it "unusual" in his 30 years of experience and "shockingly so."&lt;/p&gt;
    &lt;head rend="h2"&gt;High-profile bankruptcies&lt;/head&gt;
    &lt;p&gt;Major corporate bankruptcies this year have included hospitality company Sonder, Spirit Airlines, Del Monte Foods, retailer Claire's, and CVS Health subsidiary Omnicare. Each, in court filings, listed more than $1 billion in liabilities, placing them among the largest bankruptcies of 2025.&lt;/p&gt;
    &lt;p&gt;According to data from S&amp;amp;P Global Market Intelligence, which tracks public and private companies of a certain size, bankruptcy filings climbed to 717 through November, topping last year's tally of 687.&lt;/p&gt;
    &lt;p&gt;Even without December figures, 2025 has already logged the highest annual count for large corporate bankruptcies since 2010, when filings totaled 828, according to S&amp;amp;P Global.&lt;/p&gt;
    &lt;p&gt;Data from the intelligence firm shows that the industrials sector was the most distressed through November, with 110 companies filing for bankruptcy. The consumer discretionary sector followed with 85 bankruptcy filings, and healthcare was next up with 46 firms filing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Small business bankruptcies&lt;/head&gt;
    &lt;p&gt;The spike in bankruptcies extends well beyond the corporate sphere, with an increasing number of small businesses also filing for bankruptcy, data shows.&lt;/p&gt;
    &lt;p&gt;Small businesses carrying $3,024,725 or less in secured and unsecured debt have the option to file for bankruptcy under Subchapter V of Chapter 11, which offers a more streamlined reorganization process.&lt;/p&gt;
    &lt;p&gt;Data from Epiq Bankruptcy Analytics shows Subchapter V filings, made by small firms and individuals, at more than 2,300 year-to-date through mid-December — a nearly 10% increase from the same period last year.&lt;/p&gt;
    &lt;p&gt;In November alone, Subchapter V bankruptcy filings totaled 223 — a 23% bump from the previous year, according to the American Bankruptcy Institute, which cited data from Epiq.&lt;/p&gt;
    &lt;head rend="h2"&gt;Personal bankruptcies&lt;/head&gt;
    &lt;p&gt;In addition to big and small businesses, individual bankruptcies have also increased amid rising costs.&lt;/p&gt;
    &lt;p&gt;Individual bankruptcy filings saw an 8% jump to 40,973 in November 2025, up from the 37,814 filings in November 2024, the data cited by ABI shows.&lt;/p&gt;
    &lt;p&gt;Last month, there were 25,329 individual filings for Chapter 7, known as "clean slate" or liquidation bankruptcy, up 11% from the 22,871 filings recorded in November 2024.&lt;/p&gt;
    &lt;p&gt;Individual filings for Chapter 13, also called a "wage earner's plan" to repay all or part of someone's debts, accounted for 15,558 in November 2025, a 5% jump over the 14,865 filings in November last year, according to the data cited by ABI.&lt;/p&gt;
    &lt;p&gt;"For debt-burdened families and companies, bankruptcy remains a critical pathway to restore stability and rebuild toward a stronger financial future," Quackenboss, the ABI executive director, said.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46405898</guid><pubDate>Sat, 27 Dec 2025 22:18:24 +0000</pubDate></item></channel></rss>