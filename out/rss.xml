<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 10 Dec 2025 05:13:13 +0000</lastBuildDate><item><title>Pebble Index 01 – External memory for your brain</title><link>https://repebble.com/blog/meet-pebble-index-01-external-memory-for-your-brain</link><description>&lt;doc fingerprint="5c6b48dfd9872b65"&gt;
  &lt;main&gt;
    &lt;p&gt;Catch your best ideas before they slip through your fingers&lt;/p&gt;
    &lt;p&gt;Do you ever have flashes of insight or an idea worth remembering? This happens to me 5-10 times every day. If I don’t write down the thought immediately, it slips out of my mind. Worst of all, I remember that I’ve forgotten something and spend the next 10 minutes trying to remember what it is. So I invented external memory for my brain.&lt;/p&gt;
    &lt;p&gt;Introducing Pebble Index 01 - a small ring with a button and microphone. Hold the button, whisper your thought, and it’s sent to your phone. It’s added to your notes, set as a reminder, or saved for later review.&lt;/p&gt;
    &lt;p&gt;Index 01 is designed to become muscle memory, since it’s always with you. It’s private by design (no recording until you press the button) and requires no internet connection or paid subscription. It’s as small as a wedding band and comes in 3 colours. It’s made from durable stainless steel and is water-resistant. Like all Pebble products, it’s extremely customizable and built with open source software.&lt;/p&gt;
    &lt;p&gt;Here’s the best part: the battery lasts for years. You never need to charge it.&lt;/p&gt;
    &lt;p&gt;Pre-order today for $75. After worldwide shipping begins in March 2026, the price will go up to $99.&lt;/p&gt;
    &lt;head rend="h3"&gt;#Design&lt;/head&gt;
    &lt;p&gt;Now that I’ve worn my Index 01 for several months, I can safely say that it has changed my life - just like with Pebble, I couldn’t go back to a world without this. There are so many situations each day where my hands are full (while biking or driving, washing dishes, wrangling my kids, etc) and I need to remember something. A random sampling of my recent recordings:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Set a timer for 3pm to go pick up the kids&lt;/item&gt;
      &lt;item&gt;Remind me to phone the pharmacy at 11am&lt;/item&gt;
      &lt;item&gt;Peter is coming by tomorrow at 11:30am, add that to my calendar&lt;/item&gt;
      &lt;item&gt;Jerry recommends reading Breakneck&lt;/item&gt;
      &lt;item&gt;Mark wants a Black/Red PT2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Before, I would take my phone out of my pocket to jot these down, but I couldn’t always do that (eg, while bicycling). I also wanted to start using my phone less, especially in front of my kids.&lt;/p&gt;
    &lt;p&gt;Initially, we experimented by building this as an app on Pebble, since it has a mic and I’m always wearing one. But, I realized quickly that this was suboptimal - it required me to use my other hand to press the button to start recording (lift-to-wake gestures and wake-words are too unreliable). This was tough to use while bicycling or carrying stuff.&lt;/p&gt;
    &lt;p&gt;Then a genius electrical engineer friend of mine came up with an idea to fit everything into a tiny ring. It is the perfect form factor! Honestly, I’m still amazed that it all fits.&lt;/p&gt;
    &lt;p&gt;The design needed to satisfy several critical conditions:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Must work reliably 100% of the time. If it didn’t work or failed to record a thought, I knew I would take it off and revert back to my old habit of just forgetting things.&lt;/item&gt;
      &lt;item&gt;It had to have a physical press-button, with a satisfying click-feel. I want to know for sure if the button is pressed and my thought is captured.&lt;/item&gt;
      &lt;item&gt;Long battery life - every time you take something off to charge, there’s a chance you’ll forget to put it back on.&lt;/item&gt;
      &lt;item&gt;Must be privacy-preserving. These are your inner thoughts. All recordings must be processed and stored on your phone. Only record when the button is pressed.&lt;/item&gt;
      &lt;item&gt;It had to be as small as a wedding band. Since it’s worn on the index finger, if it were too large or bulky, it would hit your phone while you held it in your hand.&lt;/item&gt;
      &lt;item&gt;Water resistance - must be able to wash hands, shower, and get wet.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We’ve been working on this for a while, testing new versions and making tweaks. We’re really excited to get this out into the world.&lt;/p&gt;
    &lt;p&gt;Here are a few of my favourite things about Index 01:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It does one thing really well - it helps me remember things.&lt;/item&gt;
      &lt;item&gt;It’s discreet. It's not distracting. It doesn't take you out of the moment.&lt;/item&gt;
      &lt;item&gt;There’s no AI friend persona and it’s not always recording.&lt;/item&gt;
      &lt;item&gt;It’s inexpensive. We hope you try it and see if you like it as well!&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;#Key Details&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Available in 3 colours and 8 sizes &lt;list rend="ul"&gt;&lt;item&gt;Colours: polished silver, polished gold, and matte black&lt;/item&gt;&lt;item&gt;US ring sizes: 6, 7, 8, 9, 10, 11, 12, 13&lt;/item&gt;&lt;item&gt;You can pre-order now and pick your size/colour later before your ring ships.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Cost and availability: Pre-order price is $75, rises to $99 later. Ships worldwide, beginning in March.&lt;/item&gt;
      &lt;item&gt;Works with iPhone and Android: We overcame Apple’s best efforts to make life terrible for 3rd party accessory makers and have Index 01 working well on iOS and Android.&lt;/item&gt;
      &lt;item&gt;Extremely private and secure: Your thoughts are processed by open source speech-to-text (STT) and AI models locally on your phone. You can read the code and see exactly how it works - our Pebble mobile app is open source. Higher-quality STT is available through an optional cloud service.&lt;/item&gt;
      &lt;item&gt;No charging: The battery lasts for up to years of average use. After the end of its life, send your ring back to us for recycling.&lt;/item&gt;
      &lt;item&gt;On-ring storage: Recording works even if your phone is out of range. Up to 5 minutes of audio can be stored on-ring, then synced later.&lt;/item&gt;
      &lt;item&gt;No speaker or vibrating motor: This is an input device only. There is an RGB LED, but it’s rarely used (to save battery life and to reduce distraction).&lt;/item&gt;
      &lt;item&gt;Works great with Pebble or other smartwatches: After recording, the thought will appear on your watch, and you can check that it’s correct. You can ask questions like ‘What’s the weather today?’ and see the answer on your watch.&lt;/item&gt;
      &lt;item&gt;Raw audio playback: Very helpful if STT doesn’t work perfectly due to wind or loud background noises.&lt;/item&gt;
      &lt;item&gt;Actions: While the primary task is remembering things for you, you can also ask it to do things like ’Send a Beeper message to my wife - running late’ or answer simple questions that could be answered by searching the web. You can configure button clicks to control your music - I love using this to play/pause or skip tracks. You can also configure where to save your notes and reminders (I have it set to add to Notion).&lt;/item&gt;
      &lt;item&gt;Customizable and hackable: Configure single/double button clicks to control whatever you want (take a photo, turn on lights, Tasker, etc). Add your own voice actions via MCP. Or route the audio recordings directly to your own app or server!&lt;/item&gt;
      &lt;item&gt;99+ languages: Speech to text and local LLM support over 99 languages! Naturally, the quality of each may vary.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;#Future Plans&lt;/head&gt;
    &lt;p&gt;Let me be very clear - Index 01 is designed at its core to be a device that helps you remember things. We want it to be 100% reliable at its primary task. But we’re leaving the side door open for folks to customize, build new interactions and actions.&lt;/p&gt;
    &lt;p&gt;Here’s how I’m thinking about it - a single click-hold + voice input will be routed to the primary memory processing path. Double-click-hold + voice input would be routed to a more general purpose voice agent (think ChatGPT with web search). Responses from the agent would be presented on Pebble (eg ‘What’s the weather tomorrow?’, ‘When’s the next northbound Caltrain?’) or other smartwatches (as a notification). Maybe this could even be an input for something like ChatGPT Voice Mode, enabling you to hear the AI response from your earbuds.&lt;/p&gt;
    &lt;p&gt;The built in actions, set reminder, create note, alarms, etc, are actually MCPs - basically mini apps that AI agents know how to operate. They run locally in WASM within the Pebble mobile app (no cloud MCP server required). Basically any MCP server can be used with the system, so intrepid folks may have fun adding various actions like Beeper, Google Calendar, weather, etc that already offer MCPs.&lt;/p&gt;
    &lt;p&gt;Not everything will be available at launch, but this is the direction we are working towards. There will be 3 ways to customize your Index 01:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Trigger actions via button clicks - configure a single or double click to do things like take a photo, control your Home Assistant smart home, Tasker function, unlock your car. This will work better on Android since iOS Shortcuts doesn’t have an open API.&lt;/item&gt;
      &lt;item&gt;Trigger actions via voice input - write an MCP to do….basically anything? This is pretty open ended.&lt;/item&gt;
      &lt;item&gt;Route your voice recordings and/or transcriptions to your own webhook - or skip our AI processing entirely and send every recording to your own app or webapp.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;How does it work?&lt;/p&gt;
    &lt;p&gt;People usually wear it on the index finger. Inside the ring is a button, a microphone, a Bluetooth chip, memory, and a battery that lasts for years. Click the button with your thumb, talk into the mic, and it records to internal memory. When your phone is in range, the recording is streamed to the Pebble app. It’s converted to text on-device, then processed by an on-device large language model (LLM) which selects an action to take (create note, add to reminders, etc).&lt;/p&gt;
    &lt;p&gt;When do I pick my size?&lt;/p&gt;
    &lt;p&gt;You’ll be able to pick your ring size and color after placing a pre-order. If you have a 3D printer, you can print our CAD designs to try on. We’re also planning a sizing kit. You can view the measurements of the inner diameter of each ring size.&lt;/p&gt;
    &lt;p&gt;How long does the battery last?&lt;/p&gt;
    &lt;p&gt;Roughly 12 to 15 hours of recording. On average, I use it 10-20 times per day to record 3-6 second thoughts. That’s up to 2 years of usage.&lt;/p&gt;
    &lt;p&gt;Is it secure and private?&lt;/p&gt;
    &lt;p&gt;Yes, extremely. The connection between ring and phone is encrypted. Recordings are processed locally on your phone in the open-source Pebble app. The app works offline (no internet connection) and does not require a cloud service. An optional cloud storage system for backing up recordings is available. Our plan is for this to be optionally encrypted, but we haven’t built it yet.&lt;/p&gt;
    &lt;p&gt;Is a paid subscription required?&lt;/p&gt;
    &lt;p&gt;No.&lt;/p&gt;
    &lt;p&gt;What kind of battery is inside?&lt;/p&gt;
    &lt;p&gt;Index 01 uses silver-oxide batteries.&lt;/p&gt;
    &lt;p&gt;Why can’t it be recharged?&lt;/p&gt;
    &lt;p&gt;We considered this but decided not to for several reasons:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;You’d probably lose the charger before the battery runs out!&lt;/item&gt;
      &lt;item&gt;Adding charge circuitry and including a charger would make the product larger and more expensive.&lt;/item&gt;
      &lt;item&gt;You send it back to us to recycle.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Wait, it’s single use?&lt;/p&gt;
    &lt;p&gt;Yes. We know this sounds a bit odd, but in this particular circumstance we believe it’s the best solution to the given set of constraints. Other smart rings like Oura cost $250+ and need to be charged every few days. We didn’t want to build a device like that. Before the battery runs out, the Pebble app notifies and asks if you’d like to order another ring.&lt;/p&gt;
    &lt;p&gt;Is it always listening?&lt;/p&gt;
    &lt;p&gt;No. It only records while the button is pressed. It’s not designed to record your whole life, or meetings.&lt;/p&gt;
    &lt;p&gt;What if the speech-to-text processing misses a word or something?&lt;/p&gt;
    &lt;p&gt;You can always listen to the each recording in the app.&lt;/p&gt;
    &lt;p&gt;Why no touchpad?&lt;/p&gt;
    &lt;p&gt;We experimented with a touchpad, but found it too easy to accidentally swipe and press. Also, nothing beats the feedback of a real gosh darn pressable button.&lt;/p&gt;
    &lt;p&gt;Is there a speaker or vibrating motor?&lt;/p&gt;
    &lt;p&gt;No. The button has a great click-feel to indicate when you are pressing.&lt;/p&gt;
    &lt;p&gt;Does it do health tracking like Oura?&lt;/p&gt;
    &lt;p&gt;Nope&lt;/p&gt;
    &lt;p&gt;How durable and water-resistant is it?&lt;/p&gt;
    &lt;p&gt;It’s primarily made from stainless steel 316, with a liquid silicone rubber (LSR) button. It’s water-resistant to 1 meter. You can wash your hands, do dishes, and shower with it on, but we don’t recommend swimming with it.&lt;/p&gt;
    &lt;p&gt;Does it work with iPhone and Android?&lt;/p&gt;
    &lt;p&gt;Yes&lt;/p&gt;
    &lt;p&gt;I love customizing and hacking on my devices. What could I do with Index 01?&lt;/p&gt;
    &lt;p&gt;Lots of stuff! Control things with the buttons. Route raw audio or transcribed text directly to your own app via webhook. Use MCPs (also run locally on-device! No cloud server required) to add more actions.&lt;/p&gt;
    &lt;p&gt;Is this an AI friend thingy or always-recording device?&lt;/p&gt;
    &lt;p&gt;No.&lt;/p&gt;
    &lt;p&gt;How far along is development?&lt;/p&gt;
    &lt;p&gt;We’ve been working on this in the background to watch development. It helps that our Pebble Time 2 partner factory is also building Index 01! We’re currently in the DVT stage, testing pre-production samples. We’ll start a wider alpha test in January with a lot more people. Here’s some shots from the pre-production assembly line:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46205661</guid><pubDate>Tue, 09 Dec 2025 15:03:09 +0000</pubDate></item><item><title>Apple's slow AI pace becomes a strength as market grows weary of spending</title><link>https://finance.yahoo.com/news/apple-slow-ai-pace-becomes-104658095.html</link><description>&lt;doc fingerprint="5f1d1981b3685bf"&gt;
  &lt;main&gt;
    &lt;p&gt;(Bloomberg) -- Shares of Apple Inc. were battered earlier this year as the iPhone maker faced repeated complaints about its lack of an artificial intelligence strategy. But as the AI trade faces increasing scrutiny, that hesitance has gone from a weakness to a strength — and it’s showing up in the stock market.&lt;/p&gt;
    &lt;p&gt;Through the first six months of 2025, Apple was the second-worst performer among the Magnificent Seven tech giants, as its shares tumbled 18% through the end of June. That has reversed since then, with the stock soaring 35%, while AI darlings like Meta Platforms Inc. and Microsoft Corp. slid into the red and even Nvidia Corp. underperformed. The S&amp;amp;P 500 Index rose 10% in that time, and the tech-heavy Nasdaq 100 Index gained 13%.&lt;/p&gt;
    &lt;p&gt;Most Read from Bloomberg&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;NJ’s Montclair Cuts School Staff and Mulls March Tax-Hike Vote&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Trump Replaces Architect to Lead $300 Million Ballroom Design&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Owner of NYC’s Fordham Landing Housing Project Files Bankruptcy&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Democrats Want Probe of Trump Officials and Immigration Deals&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;“It is remarkable how they have kept their heads and are in control of spending, when all of their peers have gone the other direction,” said John Barr, portfolio manager of the Needham Aggressive Growth Fund, which owns Apple shares.&lt;/p&gt;
    &lt;p&gt;As a result, Apple now has a $4.1 trillion market capitalization and the second biggest weight in the S&amp;amp;P 500, leaping over Microsoft and closing in on Nvidia. The shift reflects the market’s questioning of the hundreds of billions of dollars Big Tech firms are throwing at AI development, as well as Apple’s positioning to eventually benefit when the technology is ready for mass use.&lt;/p&gt;
    &lt;p&gt;“While they most certainly will incorporate more AI into the phones over time, Apple has avoided the AI arms race and the massive capex that accompanies it,” said Bill Stone, chief investment officer at Glenview Trust Company, who owns the stock and views it as “a bit of an anti-AI holding.”&lt;/p&gt;
    &lt;p&gt;Of course, the rally has made Apple’s stock pricier than it has been in a long time. The shares are trading for around 33 times expected earnings over the next 12 months, a level they’ve only hit a few times in the past 15 years, with a high of 35 in September 2020. The stock’s average multiple over that time is less than 19 times. Apple is now the second most expensive stock in the Bloomberg Magnificent Seven Index, trailing only Tesla Inc.’s whopping valuation of 203 times forward earnings. Apple’s shares climbed about 0.5% in early Tuesday trading.&lt;/p&gt;
    &lt;p&gt;“It’s really hard to see how the stock can continue to compound value at a level that makes this a compelling entry point,” said Craig Moffett, co-founder of research firm MoffettNathanson. “The obvious question is, are investors overpaying for Apple’s defensiveness? We think so.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46205724</guid><pubDate>Tue, 09 Dec 2025 15:08:24 +0000</pubDate></item><item><title>A supersonic engine core makes the perfect power turbine</title><link>https://boomsupersonic.com/flyby/ai-needs-more-power-than-the-grid-can-deliver-supersonic-tech-can-fix-that</link><description>&lt;doc fingerprint="16d2b440c19c9c2a"&gt;
  &lt;main&gt;
    &lt;p&gt;By: Blake Scholl, Founder &amp;amp; CEO, Boom Supersonic&lt;/p&gt;
    &lt;p&gt;It started, as many things do these days, by scrolling on X.&lt;/p&gt;
    &lt;p&gt;I was reading post after post about the power crisis hitting AI data centers—GPU racks sitting idle, waiting not on chips, but on electricity. I texted with Sam Altman—who confirmed power was indeed a major constraint. I pinged our engineering team—and found that they already had the outline of a plan to build a power turbine based on our Symphony supersonic engine.&lt;/p&gt;
    &lt;p&gt;After a few conversations, it became clear: AI didn’t just need more turbines—it needed a new and fundamentally better turbine. Symphony was the perfect new engine to accelerate AI in America. About three months later, we had a signed deal for 1.21 gigawatts and had started manufacturing the first turbine.&lt;/p&gt;
    &lt;p&gt;Today, we’re announcing Superpower, our new 42‑megawatt natural gas turbine, along with a $300M funding round and Crusoe as our launch customer. And most importantly: this marks a turning point. Boom is now on a self-funded path to both Superpower and the Overture supersonic airliner.&lt;/p&gt;
    &lt;p&gt;I want to share the real story of how this happened—and why supersonic technology is exactly what America’s energy crisis demands.&lt;/p&gt;
    &lt;head rend="h4"&gt;America Doesn’t Have 10–15 Years to Solve Its Power Problem the Old Way&lt;/head&gt;
    &lt;p&gt;If you’ve been paying attention, you know the U.S. is in a genuine energy crunch. GPU racks are idling because they can’t get power. Data centers are fighting over substations and interconnection queues. Meanwhile China is adding power capacity at a wartime pace—coal, gas, nuclear, everything—while America struggles to get a single transmission line permitted.&lt;/p&gt;
    &lt;p&gt;AI won’t wait for us to fix the grid. And the United States simply doesn’t have 10–15 years to build out power infrastructure the old way.&lt;/p&gt;
    &lt;p&gt;Hyperscalers have already moved to their own Plan B: behind‑the‑meter power plants. You’ve seen XAI’s Colossus I and II in Memphis. OpenAI’s Stargate I in Abilene. These projects are powered by arrays of aeroderivative natural-gas turbines—which are, fundamentally, modified jet engines from the 1970s. There’s something brilliant in this approach: the transition from gigantic “frame” turbines to arrays of mid-size “aeroderivative” turbines mirrors the computing industry’s shift from mainframes to blade servers.&lt;/p&gt;
    &lt;p&gt;The problem? The “blade servers” of the energy world are old tech and they’re sold out. Because the most popular “aeroderivative” turbines are based on subsonic jet engines, they’re happiest when the outside air temperature is -50°F—like it is when going Mach 0.8 at 30,000 feet. As outside temperatures rise, there is no option but to throttle back the engines—or else the turbine blades literally melt down. These turbines begin losing power at about 50°F and by the time it’s 110°—as often happens in popular data center locations like Texas—30% of generation capacity is lost. Nonetheless, major manufacturers all have backlogs through the rest of the decade and none is building a new-generation advanced-technology turbine.&lt;/p&gt;
    &lt;head rend="h4"&gt;A Supersonic Engine Core Makes the Perfect Power Turbine&lt;/head&gt;
    &lt;p&gt;When we designed the Symphony engine for Overture, we built something no one else has built this century: a brand-new large engine core optimized for continuous, high‑temperature operation.&lt;/p&gt;
    &lt;p&gt;A subsonic engine is built for short bursts of power at takeoff. A supersonic engine is built to run hard, continuously, at extreme thermal loads. Symphony was designed for Mach 1.7 at 60,000 feet, where effective temperatures reach 160°F—not the frigid -50°F conditions where legacy subsonic engines operate.&lt;/p&gt;
    &lt;p&gt;This gives Superpower several critical advantages:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Full power even with high ambient heat – Where legacy turbines lose 20–30% at 110°F, Superpower maintains its full 42MW output without derate.&lt;/item&gt;
      &lt;item&gt;Waterless operation – Legacy turbines need huge quantities of water for cooling to avoid thermal derate in hot environments. Superpower doesn’t. It stays at full output, water‑free.&lt;/item&gt;
      &lt;item&gt;Cloud‑native control and monitoring. Superpower inherits the telemetry and operations stack we built for XB‑1. Every turbine streams real‑time performance data, supports remote control, and flags anomalies before customers ever notice.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Superpower and Symphony are based on virtually identical turbine engines. Both share the identical core (HPC and HPT) and a slightly tuned low spool. In the place of Symphony’s hollow-core titanium fan, Superpower adds two additional compressor stages plus a three-stage free power turbine connected to a high-efficiency generator on its own shaft. Additionally, the engines use slightly different fuel nozzles, Symphony’s optimized for Jet A vs. Superpower’s for natural gas.&lt;/p&gt;
    &lt;head rend="h4"&gt;Scaling Production the Supersonic Way: Vertical Integration&lt;/head&gt;
    &lt;p&gt;The legacy aerospace supply chain is congested. When the mission is urgent and the supply chain congested, you build the supply chain. The new Superpower Superfactory starts with a simple vision: raw materials in one side of the building, gigawatts of completed power turbine packages out the other side. We’ve already started making the first parts—and much of the production equipment to support 2GW/yr is on order. With this new financing we’re ready to accelerate further.&lt;/p&gt;
    &lt;p&gt;If America wants to build at the speed AI requires, vertical integration isn’t optional. We’re standing up our own foundry and our own large scale CNC machining capability. We’ll have more to share on the Superpower Superfactory in early 2026.&lt;/p&gt;
    &lt;head rend="h4"&gt;Scaling Production the Supersonic Way: Vertical Integration&lt;/head&gt;
    &lt;p&gt;Superpower is sort of like our Starlink moment, the strongest accelerant we’ve ever had toward our core mission of making Earth dramatically more accessible.&lt;/p&gt;
    &lt;p&gt;The fastest way to a certified, passenger-carrying Symphony engine is to run its core for hundreds of thousands of hours in the real world, powering Earth’s most demanding AI data centers. Every hour a Superpower turbine spins is an hour of validation for Symphony. Every gigawatt we deliver strengthens our vertical integration and manufacturing capability. And with Superpower profitability funding the remainder of the aircraft program, we’ve done something rare in aerospace: created a self-sustaining path to a new airliner.&lt;/p&gt;
    &lt;p&gt;Superpower also reminds me of what Boom is at our core: a team willing to take on what others say is impossible, to do with a small team what big companies might not even attempt.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46206277</guid><pubDate>Tue, 09 Dec 2025 15:51:32 +0000</pubDate></item><item><title>Handsdown one of the coolest 3D websites</title><link>https://bruno-simon.com/</link><description>&lt;doc fingerprint="e43305f6f9f2bf3"&gt;
  &lt;main&gt;
    &lt;p&gt;00:00:000&lt;/p&gt;
    &lt;p&gt;Server currently offline. Scores can't be saved.&lt;/p&gt;
    &lt;p&gt;Welcome!&lt;/p&gt;
    &lt;p&gt;My name is Bruno Simon, and I'm a creative developer (mostly for the web).&lt;/p&gt;
    &lt;p&gt;This is my portfolio. Please drive around to learn more about me and discover the many secrets of this world.&lt;/p&gt;
    &lt;p&gt;And don't break anything!&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Audio&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Quality&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;I'm stuck!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Reset&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Renderer&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Server&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;WASD or ARROWS&lt;/cell&gt;
        &lt;cell&gt;Move around&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;SHIFT&lt;/cell&gt;
        &lt;cell&gt;Boost&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CTRL LEFT or B&lt;/cell&gt;
        &lt;cell&gt;Brake&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;SPACE&lt;/cell&gt;
        &lt;cell&gt;Jump&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ENTER&lt;/cell&gt;
        &lt;cell&gt;Interact&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;M&lt;/cell&gt;
        &lt;cell&gt;Map&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;L&lt;/cell&gt;
        &lt;cell&gt;Mute&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;T&lt;/cell&gt;
        &lt;cell&gt;Post a whisper&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;R&lt;/cell&gt;
        &lt;cell&gt;Respawn&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;NUM KEYS/NUM PAD&lt;/cell&gt;
        &lt;cell&gt;Activate hydraulics&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;LEFT CLICK (DRAG)&lt;/cell&gt;
        &lt;cell&gt;Move camera&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;H&lt;/cell&gt;
        &lt;cell&gt;Honk&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;One finger&lt;/cell&gt;
        &lt;cell&gt;Move the car&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Two fingers&lt;/cell&gt;
        &lt;cell&gt;Move camera / zoom&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Tap (on the car)&lt;/cell&gt;
        &lt;cell&gt;Jump&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;B&lt;/cell&gt;
        &lt;cell&gt;Boost&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;Jump&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;X&lt;/cell&gt;
        &lt;cell&gt;Brake&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;A&lt;/cell&gt;
        &lt;cell&gt;Interact / Exit&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;LT L2&lt;/cell&gt;
        &lt;cell&gt;Accelerate&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;RT R2&lt;/cell&gt;
        &lt;cell&gt;Backward accelerate&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;LB / RB L1 / R1&lt;/cell&gt;
        &lt;cell&gt;Hydraulics&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Joystick Left&lt;/cell&gt;
        &lt;cell&gt;Turn wheels&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Joystick Left (press)&lt;/cell&gt;
        &lt;cell&gt;Honk&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Joystick Right&lt;/cell&gt;
        &lt;cell&gt;Move camera&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Joystick Right (press)&lt;/cell&gt;
        &lt;cell&gt;Zoom in/out&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Select&lt;/cell&gt;
        &lt;cell&gt;Reset&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Start&lt;/cell&gt;
        &lt;cell&gt;Pause&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Server currently offline. Scores can't be saved.&lt;/p&gt;
    &lt;p&gt;Resets in&lt;/p&gt;
    &lt;p&gt;Whispers are messages left by visitors.&lt;/p&gt;
    &lt;p&gt; - Everyone can see them&lt;lb/&gt; - New whispers remove old ones (max 30)&lt;lb/&gt; - One whisper per user&lt;lb/&gt; - Choose a flag&lt;lb/&gt; - No slur!&lt;lb/&gt; - Max 30 characters &lt;/p&gt;
    &lt;p&gt;Server currently offline&lt;/p&gt;
    &lt;p&gt; Thank you for visiting my portfolio! &lt;lb/&gt;If you are curious about the stack and how I built it, hereâs everything you need to know. &lt;/p&gt;
    &lt;p&gt; Three.js is the library Iâm using to render this 3D world. &lt;lb/&gt;It was created by mr.doob (X, GitHub), followed by hundreds of awesome developers, one of which being Sunag (X, GitHub) who added TSL, enabling the use of both WebGL and WebGPU, making this portfolio possible. &lt;/p&gt;
    &lt;p&gt; If you want to learn Three.js, I got you covered with this huge course. &lt;lb/&gt;It contains everything you need to start building awesome stuff with Three.js (and much more). &lt;/p&gt;
    &lt;p&gt; Iâve been making devlogs since the very start of this portfolio and you can find them on my Youtube channel. &lt;lb/&gt;Even though the portfolio is out, Iâm still working on the last videos so that the series is complete. &lt;/p&gt;
    &lt;p&gt; The code is available on GitHub under MIT license. Even the Blender files are there, so have fun! &lt;lb/&gt;For security reasons, Iâm not sharing the server code, but the portfolio works without it. &lt;/p&gt;
    &lt;p&gt; The music you hear was made especially for this portfolio by the awesome Kounine (Linktree). &lt;lb/&gt;They are now under CC0 license, meaning you can do whatever you want with them! &lt;lb/&gt;Download them here. &lt;/p&gt;
    &lt;p&gt;â Bruno&lt;/p&gt;
    &lt;p&gt;Server currently offline. Scores can't be saved.&lt;/p&gt;
    &lt;p&gt;Come hang out with the community, show us your projects and ask us anything.&lt;/p&gt;
    &lt;p&gt;Contact me directly.&lt;lb/&gt;I have to warn you, I try to answer everyone, but it might take a while.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46206531</guid><pubDate>Tue, 09 Dec 2025 16:06:58 +0000</pubDate></item><item><title>Clearspace (YC W23) Is Hiring a Founding Designer</title><link>https://www.ycombinator.com/companies/clearspace/jobs/yamWTLr-founding-designer-at-clearspace</link><description>&lt;doc fingerprint="b782896e8d09edc5"&gt;
  &lt;main&gt;
    &lt;p&gt;Eliminate compulsive phone usage&lt;/p&gt;
    &lt;p&gt;About Clearspace&lt;/p&gt;
    &lt;p&gt;Clearspace is building the intentionality layer of the internet. Our mission is to build technology as effective at protecting human attention as social media is at exploiting it (infinite scrolling, short-form feeds, manipulative notifications, etc). Our category defining mobile app has been featured on Huberman Lab, New York Times Wirecutter, NPR Marketplace, Forbes, TBPN.&lt;/p&gt;
    &lt;p&gt;People that want a better relationship with their devices have nowhere to turn except for willpower. We are building an agent that achieves this on all devices by processing and filtering network traffic based on natural language rules.&lt;/p&gt;
    &lt;p&gt;About The Role&lt;/p&gt;
    &lt;p&gt;We are looking for a lead designer with strong aesthetic intuition and an obsession with designing through every inch of the user journey. You will be asked to bring pixel perfect designs to life across several different platforms, if you don’t love the process of designing this is not the role for you. You will be talking to users often and asked to speak to the overall brand direction at Clearspace.&lt;/p&gt;
    &lt;p&gt;Responsibilities&lt;/p&gt;
    &lt;p&gt;Qualifications&lt;/p&gt;
    &lt;p&gt;Nice to Have&lt;/p&gt;
    &lt;p&gt;At Clearspace we help people reduce compulsive phone usage.&lt;/p&gt;
    &lt;p&gt;We exist to protect people's attention from the exploits of modern technology platforms and make space for the things that matter to them most.&lt;/p&gt;
    &lt;p&gt;We believe the technology to protect someones attention should be just as sophisticated and effective as the tech that is exploiting it and are building a world-class engineering team to arm the world with a comprehensive attention protection stack.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46207360</guid><pubDate>Tue, 09 Dec 2025 17:01:11 +0000</pubDate></item><item><title>Donating the Model Context Protocol and establishing the Agentic AI Foundation</title><link>https://www.anthropic.com/news/donating-the-model-context-protocol-and-establishing-of-the-agentic-ai-foundation</link><description>&lt;doc fingerprint="fd5e72507a8d8692"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Donating the Model Context Protocol and establishing the Agentic AI Foundation&lt;/head&gt;
    &lt;p&gt;Today, we’re donating the Model Context Protocol (MCP) to the Agentic AI Foundation (AAIF), a directed fund under the Linux Foundation, co-founded by Anthropic, Block and OpenAI, with support from Google, Microsoft, Amazon Web Services (AWS), Cloudflare, and Bloomberg.&lt;/p&gt;
    &lt;head rend="h2"&gt;Model Context Protocol&lt;/head&gt;
    &lt;p&gt;One year ago, we introduced MCP as a universal, open standard for connecting AI applications to external systems. Since then, MCP has achieved incredible adoption:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Across the ecosystem: There are now more than 10,000 active public MCP servers, covering everything from developer tools to Fortune 500 deployments;&lt;/item&gt;
      &lt;item&gt;Across platforms: MCP has been adopted by ChatGPT, Cursor, Gemini, Microsoft Copilot, Visual Studio Code, and other popular AI products;&lt;/item&gt;
      &lt;item&gt;Across infrastructure: Enterprise-grade infrastructure now exists with deployment support for MCP from providers including AWS, Cloudflare, Google Cloud, and Microsoft Azure.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;&lt;lb/&gt;We’re continuing to invest in MCP’s growth. Claude now has a directory with over 75 connectors (powered by MCP), and we recently launched Tool Search and Programmatic Tool Calling capabilities in our API to help optimize production-scale MCP deployments, handling thousands of tools efficiently and reducing latency in complex agent workflows.&lt;lb/&gt;MCP now has an official, community-driven Registry for discovering available MCP servers, and the November 25th spec release introduced many new features, including asynchronous operations, statelessness, server identity, and official extensions. There are also official SDKs (Software Development Kits) for MCP in all major programming languages with 97M+ monthly SDK downloads across Python and TypeScript. &lt;lb/&gt;Since its inception, we’ve been committed to ensuring MCP remains open-source, community-driven and vendor-neutral. Today, we further that commitment by donating MCP to the Linux Foundation.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Linux Foundation and the Agentic AI Foundation&lt;/head&gt;
    &lt;p&gt;The Linux Foundation is a non-profit organization dedicated to fostering the growth of sustainable, open-source ecosystems through neutral stewardship, community building, and shared infrastructure. It has decades of experience stewarding the most critical and globally-significant open-source projects, including The Linux Kernel, Kubernetes, Node.js, and PyTorch. Importantly, the Linux Foundation has a proven track record in facilitating open collaboration and maintaining vendor neutrality.&lt;/p&gt;
    &lt;p&gt;The Agentic AI Foundation (AAIF) is a directed fund under the Linux Foundation co-founded by Anthropic, Block and OpenAI, with support from Google, Microsoft, AWS, Cloudflare and Bloomberg. The AAIF aims to ensure agentic AI evolves transparently, collaboratively, and in the public interest through strategic investment, community building, and shared development of open standards.&lt;/p&gt;
    &lt;head rend="h2"&gt;Donating the Model Context Protocol&lt;/head&gt;
    &lt;p&gt;Anthropic is donating the Model Context Protocol to the Linux Foundation's new Agentic AI Foundation, where it will join goose by Block and AGENTS.md by OpenAI as founding projects. Bringing these and future projects under the AAIF will foster innovation across the agentic AI ecosystem and ensure these foundational technologies remain neutral, open, and community-driven. &lt;lb/&gt;The Model Context Protocol’s governance model will remain unchanged: the project’s maintainers will continue to prioritize community input and transparent decision-making.&lt;/p&gt;
    &lt;head rend="h2"&gt;The future of MCP&lt;/head&gt;
    &lt;p&gt;Open-source software is essential for building a secure and innovative ecosystem for agentic AI. Today’s donation to the Linux Foundation demonstrates our commitment to ensuring MCP remains a neutral, open standard. We’re excited to continue contributing to MCP and other agentic AI projects through the AAIF.&lt;lb/&gt;Learn more about MCP at modelcontextprotocol.io and get involved with the AAIF here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46207425</guid><pubDate>Tue, 09 Dec 2025 17:05:42 +0000</pubDate></item><item><title>PeerTube is recognized as a digital public good by Digital Public Goods Alliance</title><link>https://www.digitalpublicgoods.net/r/peertube</link><description>&lt;doc fingerprint="95773f811edde224"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;PeerTube&lt;/head&gt;
    &lt;p&gt;Verified DPG&lt;/p&gt;
    &lt;head rend="h3"&gt;Owner&lt;/head&gt;
    &lt;p&gt;Framasoft&lt;/p&gt;
    &lt;head rend="h3"&gt;Type&lt;/head&gt;
    &lt;p&gt;backend, mobile, web&lt;/p&gt;
    &lt;head rend="h3"&gt;Licence&lt;/head&gt;
    &lt;p&gt;AGPL-3.0&lt;/p&gt;
    &lt;head rend="h3"&gt;Last evaluated&lt;/head&gt;
    &lt;p&gt;07.10.2025&lt;/p&gt;
    &lt;head rend="h3"&gt;Origin country&lt;/head&gt;
    &lt;p&gt;France&lt;/p&gt;
    &lt;head rend="h3"&gt;Release date&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;head rend="h3"&gt;DPG since&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;head rend="h3"&gt;Description&lt;/head&gt;
    &lt;p&gt;PeerTube is a tool for hosting, managing, and sharing videos or live streams.&lt;/p&gt;
    &lt;head rend="h3"&gt;Core Components Assessed/Included Repositories&lt;/head&gt;
    &lt;p&gt;The following repositories were submitted by the solution and included in our evaluation. Any repositories, add-ons, features not included in here were not reviewed by us.&lt;/p&gt;
    &lt;head rend="h3"&gt;Feature&lt;/head&gt;
    &lt;head rend="h3"&gt;Scale of the Solution*&lt;/head&gt;
    &lt;head rend="h3"&gt;Connected members&lt;/head&gt;
    &lt;p&gt;N/A&lt;/p&gt;
    &lt;head rend="h3"&gt;Participated Programs&lt;/head&gt;
    &lt;p&gt;N/A&lt;/p&gt;
    &lt;head rend="h3"&gt;Available Languages&lt;/head&gt;
    &lt;p&gt;Esperanto, English, Slovenčina, Gàidhlig, العربية, Norsk, Magyar, Deutsch, Toki Pona, Euskara, Polski, Português (Portugal), Suomi, Tiếng Việt, Italiano, فارسی, Español, Taqbaylit, 简体中文（中国）, Hrvatski, ελληνικά, Occitan, украї́нська мо́ва, Français, ไทย, Türkçe, 繁體中文（台灣）, 日本語, Galego, Íslenska, Svenska, Nederlands, Pусский, bokmål, Čeština, Shqip, Català, Português (Brasil), Norsk nynorsk&lt;/p&gt;
    &lt;head rend="h3"&gt;Organisations using it&lt;/head&gt;
    &lt;p&gt;French Ministry of National Education (~100K videos), Italy’s National Research Council, a few French alternative media, the Weißensee Kunsthochschule in Berlin, as well as the Universität der Künste in the same city, a few universities worldwide, the Blender and Debian projects, and various activist groups&lt;/p&gt;
    &lt;p&gt;* This information is self-reported and updated annually&lt;/p&gt;
    &lt;head rend="h3"&gt;Github insights&lt;/head&gt;
    &lt;p&gt;Learn how this product has met the requirements of the DPG Standard by exploring the indicators below.&lt;/p&gt;
    &lt;head rend="h3"&gt;Application Details&lt;/head&gt;
    &lt;head rend="h4"&gt;DPG ID&lt;/head&gt;
    &lt;head rend="h4"&gt;GID0092472&lt;/head&gt;
    &lt;head rend="h4"&gt;Status&lt;/head&gt;
    &lt;head rend="h4"&gt;DPG&lt;/head&gt;
    &lt;head rend="h4"&gt;Date Created&lt;/head&gt;
    &lt;head rend="h4"&gt;2025-08-11&lt;/head&gt;
    &lt;head rend="h4"&gt;Date Submitted&lt;/head&gt;
    &lt;head rend="h4"&gt;2025-08-25&lt;/head&gt;
    &lt;head rend="h4"&gt;Date Reviewed&lt;/head&gt;
    &lt;head rend="h4"&gt;2025-10-07&lt;/head&gt;
    &lt;head rend="h4"&gt;Date of Expiry&lt;/head&gt;
    &lt;head rend="h4"&gt;2026-10-07&lt;/head&gt;
    &lt;head rend="h3"&gt;Application Log Details&lt;/head&gt;
    &lt;head rend="h4"&gt;Timestamp&lt;/head&gt;
    &lt;head rend="h4"&gt;Activity&lt;/head&gt;
    &lt;p&gt;2025-10-07 08:40:13&lt;/p&gt;
    &lt;p&gt;Ricardo Torres (L2 Reviewer) submitted their review of PeerTube (152) and found it to be a DPG&lt;/p&gt;
    &lt;p&gt;2025-10-07 08:40:12&lt;/p&gt;
    &lt;p&gt;System unmarked PeerTube (12958) as a nominee&lt;/p&gt;
    &lt;p&gt;2025-10-07 08:40:07&lt;/p&gt;
    &lt;p&gt;Ricardo Torres (L2 Reviewer) passed 4. Platform Independence for PeerTube (12958)&lt;/p&gt;
    &lt;p&gt;2025-10-07 08:40:02&lt;/p&gt;
    &lt;p&gt;Ricardo Torres (L2 Reviewer) moved PeerTube (12958) to under review&lt;/p&gt;
    &lt;p&gt;2025-10-07 08:38:21&lt;/p&gt;
    &lt;p&gt;Ricardo Torres (L2 Reviewer) finished consultation on 4. Platform Independence for PeerTube (12958)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46207464</guid><pubDate>Tue, 09 Dec 2025 17:08:37 +0000</pubDate></item><item><title>If you're going to vibe code, why not do it in C?</title><link>https://stephenramsay.net/posts/vibe-coding.html</link><description>&lt;doc fingerprint="af2319bf33f607dd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;If You’re Going to Vibe Code, Why Not Do It in C?&lt;/head&gt;
    &lt;p&gt;Stephen Ramsay&lt;/p&gt;
    &lt;p&gt;Or hell, why not do it in x86 assembly?&lt;/p&gt;
    &lt;p&gt;Let’s get a few things out of the way before I go any further with this seemingly impertinent thought, because it’s nowhere near as snarky as it sounds.&lt;/p&gt;
    &lt;p&gt;First, I don’t particularly like vibe coding. I love programming, and I have loved it since I made my first tentative steps with it sometime back in the mid-to-late 90s. I love programming so much, it always feels like I’m having too much fun for it to count as real work. I’ve done it professionally, but I also do it as a hobby. Someone apparently once said, “Do what you love and you’ll never work a day in your life.” That’s how I feel about writing code. I’ve also been teaching the subject for twenty-five years, and I can honestly say I am as excited about the first day of the semester now as I was when I first started. I realize it’s a bit precious to say so, but I’ll say it anyway: Turning non-programmers into programmers is my life’s work. It is the thing of which I am most proud as a college professor.&lt;/p&gt;
    &lt;p&gt;Vibe coding makes me feel dirty in ways that I struggle to articulate precisely. It’s not just that it feels like “cheating” (though it does). I also think it takes a lot of the fun out of the whole thing. I sometimes tell people (like the aforementioned students) that programming is like doing the best crossword puzzle in the world, except that when you solve it, it actually dances and sings. Vibe coding robs me of that moment, because I don’t feel like I really did it at all. And even though to be a programmer is to live with a more-or-less permanent set of aporias (you don’t really understand what the compiler is doing, really—and even if you do, you probably don’t really understand how the virtual memory subsystem works, really), it’s satisfying to understand every inch of my code and frustrating—all the way to the borderlands of active anxiety—not quite understanding what Claude just wrote.&lt;/p&gt;
    &lt;p&gt;But this leads me to my second point, which I must make as clearly and forcefully as I can. Vibe coding actually works. It creates robust, complex systems that work. You can tell yourself (as I did) that it can’t possibly do that, but you are wrong. You can then tell yourself (as I did) that it’s good as a kind of alternative search engine for coding problems, but not much else. You are also wrong about that. Because when you start giving it little programming problems that you can’t be arsed to work out yourself (as I did), you discover (as I did) that it’s awfully good at those. And then one day you muse out loud (as I did) to an AI model something like, “I have an idea for a program…” And you are astounded. If you aren’t astounded, you either haven’t actually done it or you are at some stage of grief prior to acceptance. Perfect? Hardly. But then neither are human coders. The future? I think the questions answers itself.&lt;/p&gt;
    &lt;p&gt;But to get to my impertinent question…&lt;/p&gt;
    &lt;p&gt;Early on in my love affair with programming, I read Structure and Interpretation of Computer Programs, which I now consider one of the great pedagogical masterpieces of the twentieth century. I learned a great deal about programming from that book, but among the most memorable lessons was one that appears in the second paragraph of the original preface. There, Hal Abelson and Gerald Sussman make a point that hits with the force of the obvious, and yet is very often forgotten:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;[W]e want to establish the idea that a computer language is not just a way of getting a computer to perform operations but rather that it is a novel formal medium for expressing ideas about methodology. Thus, programs must be written for people to read, and only incidentally for machines to execute.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I’ve been repeating some version of this to my students ever since. Computers, I remind them, do not need the code to be “readable” or “ergonomic” for humans; they only need it to be readable and ergonomic for a computer, which is a considerably lower bar.&lt;/p&gt;
    &lt;p&gt;Every programming language—including assembly language—was and is intended for the convenience of humans who need to read it and write it. If a language is innovative, it is usually not because it has allowed for automatic memory management, or concurrency, or safety, or robust error checking, but because it has made it easier for humans to express and reason about these matters. When we extol the virtues of this or that language—Rust’s safety guarantees, C++’s “no-cost abstractions,” or Go’s approach to concurrency—we are not talking about an affordance that the computer has gained, but about an affordance that we have gained as programmers of said computer. From our standpoint as programmers, object-oriented languages offer certain ways to organize our code—and, I think Abelson and Sussman would say, our thinking—that are potentially conducive to the noble treasures of maintainability, extensibility, error checking, and any number of other condign matters. From the standpoint of the computer, this little OO kink of ours seems mostly to indicate a strange affinity for heap memory. “Whatevs!” (says the computer). And pick your poison here, folks: functional programming, algebraic data types, dependent types, homoiconicity, immutable data structures, brace styles… We can debate the utility of these things, but we must understand that we are primarily talking about human problems. The set of “machine problems” to which these matters correspond is considerably smaller.&lt;/p&gt;
    &lt;p&gt;So my question is this: Why vibe code with a language that has human convenience and ergonomics in view? Or to put that another way: Wouldn’t a language designed for vibe coding naturally dispense with much of what is convenient and ergonomic for humans in favor of what is convenient and ergonomic for machines? Why not have it just write C? Or hell, why not x86 assembly?&lt;/p&gt;
    &lt;p&gt;Now, at this point, you will want to say that the need for human understanding isn’t erased entirely thereby. Some version of this argument has merit, but I would remind you that if you are really vibe coding for real you already don’t understand a great deal of what it is producing. But if you look carefully, you will notice that it doesn’t struggle with undefined behavior in C. Or with making sure that all memory is properly freed. Or with off-by-one errors. It sometimes struggles to understand what it is that you actually want, but it rarely struggles with the actual execution of the code. It’s better than you are at keeping track of those things in the same way that a compiler is better at optimizing code than you are. Perfect? No. But as I said before…&lt;/p&gt;
    &lt;p&gt;Is C the ideal language for vibe coding? I think I could mount an argument for why it is not, but surely Rust is even less ideal. To say nothing of Haskell, or OCaml, or even Python. All of these languages, after all, are for people to read, and only incidentally for machines to execute. They are practically adorable in their concern for problems that AI models do not have.&lt;/p&gt;
    &lt;p&gt;I suppose what I’m getting at, here, is that if vibe coding is the future of software development (and it is), then why bother with languages that were designed for people who are not vibe coding? Shouldn’t there be such a thing as a “vibe-oriented programming language?” VOP. You read it here first.&lt;/p&gt;
    &lt;p&gt;One possibility is that such a language truly would be executable pseudocode beyond even the most extravagant fever dreams of the most earnest Pythonistas; it shows you what it’s doing in truly pseudo code, but all the while it’s writing assembly. Or perhaps it’s something like the apotheosis of literate programming. You write a literary document “expressing ideas about methodology,” and the AI produces machine code (and a kind of literary critical practice evolves around this activity, eventually ordering itself into structuralist and post-structuralist camps. But I’m getting ahead of myself). Perhaps your job as a programmer is mostly running tests that verify this machine code (tests which have also been produced by AI). Or maybe a VOPL is really a certain kind of language that comes closer to natural language than any existing programming language, but which has a certain (easily learned) set of idioms and expressions that guide the AI more reliably and more quickly toward particular solutions. It doesn’t have goroutines. It has a “concurrency slang.”&lt;/p&gt;
    &lt;p&gt;Now obviously, the reason a large language model focused on coding is good at Javascript and C++ is precisely because it has been trained on billions of lines of code in those languages along with countless forum posts, StackOverflow debates, and so on. Bootstrapping a VOPL presents a certain kind of difficulty, but then one also suspects that LLMs are already being trained in some future version of this language, because so many programmers are already groping their way toward a system like this by virtue of the fact that so many of them are already vibe coding production-level systems.&lt;/p&gt;
    &lt;p&gt;I don’t know how I feel about all of this (see my first and second points above). It saddens me to think of “coding by hand” becoming a kind of quaint Montessori-school stage in the education of a vibe coder—something like the contour drawings we demand from future photoshopers or the balanced equations we insist serve as a rite of passage for people who will never be without a calculator to the end of their days.&lt;/p&gt;
    &lt;p&gt;At the same time, there is something exciting about the birth of a computational paradigm. It wasn’t that long ago, in the grand scheme of things, that someone realized that rewiring the entire machine every time you wanted to do a calculation (think ENIAC, circa 1945) was a rather suboptimal way to do things. And it is worth recalling that people complained when the stored-program computer rolled around (think EDVAC, circa 1951). Why? Well, the answer should be obvious. It was less reliable. It was slower. It removed the operator from the loop. It threatened specialized labor. It was conceptually impure. I’m not kidding about any of this. No less an authority than Grace Hopper had to argue against the quite popular idea that there was no way anyone could ever trust a machine to write instructions for another machine.&lt;/p&gt;
    &lt;p&gt;Same vibe, as the kids say.&lt;/p&gt;
    &lt;p&gt;Keywords: programming, AI&lt;/p&gt;
    &lt;p&gt;Last Modified: 2025-12-07T16:29:42:-0600&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46207505</guid><pubDate>Tue, 09 Dec 2025 17:11:09 +0000</pubDate></item><item><title>The stack circuitry of the Intel 8087 floating point chip, reverse-engineered</title><link>https://www.righto.com/2025/12/8087-stack-circuitry.html</link><description>&lt;doc fingerprint="2b5a4030cd17f258"&gt;
  &lt;main&gt;
    &lt;p&gt;Early microprocessors were very slow when operating with floating-point numbers. But in 1980, Intel introduced the 8087 floating-point coprocessor, performing floating-point operations up to 100 times faster. This was a huge benefit for IBM PC applications such as AutoCAD, spreadsheets, and flight simulators. The 8087 was so effective that today's computers still use a floating-point system based on the 8087.1&lt;/p&gt;
    &lt;p&gt;The 8087 was an extremely complex chip for its time, containing somewhere between 40,000 and 75,000 transistors, depending on the source.2 To explore how the 8087 works, I opened up a chip and took numerous photos of the silicon die with a microscope. Around the edges of the die, you can see the hair-thin bond wires that connect the chip to its 40 external pins. The complex patterns on the die are formed by its metal wiring, as well as the polysilicon and silicon underneath. The bottom half of the chip is the "datapath", the circuitry that performs calculations on 80-bit floating point values. At the left of the datapath, a constant ROM holds important constants such as π. At the right are the eight registers that form the stack, along with the stack control circuitry.&lt;/p&gt;
    &lt;p&gt;The chip's instructions are defined by the large microcode ROM in the middle. This ROM is very unusual; it is semi-analog, storing two bits per transistor by using four transistor sizes. To execute a floating-point instruction, the 8087 decodes the instruction and the microcode engine starts executing the appropriate micro-instructions from the microcode ROM. The decode circuitry to the right of the ROM generates the appropriate control signals from each micro-instruction. The bus registers and control circuitry handle interactions with the main 8086 processor and the rest of the system. Finally, the bias generator uses a charge pump to create a negative voltage to bias the chip's substrate, the underlying silicon.&lt;/p&gt;
    &lt;p&gt;The stack registers and control circuitry (in red above) are the subject of this blog post. Unlike most processors, the 8087 organizes its registers in a stack, with instructions operating on the top of the stack. For instance, the square root instruction replaces the value on the top of the stack with its square root. You can also access a register relative to the top of the stack, for instance, adding the top value to the value two positions down from the top. The stack-based architecture was intended to improve the instruction set, simplify compiler design, and make function calls more efficient, although it didn't work as well as hoped.&lt;/p&gt;
    &lt;p&gt;The diagram above shows how the stack operates. The stack consists of eight registers, with the Stack Top (ST) indicating the current top of the stack. To push a floating-point value onto the stack, the Stack Top is decremented and then the value is stored in the new top register. A pop is performed by copying the value from the stack top and then incrementing the Stack Top. In comparison, most processors specify registers directly, so register 2 is always the same register.&lt;/p&gt;
    &lt;head rend="h2"&gt;The registers&lt;/head&gt;
    &lt;p&gt;The stack registers occupy a substantial area on the die of the 8087 because floating-point numbers take many bits. A floating-point number consists of a fractional part (sometimes called the mantissa or significand), along with the exponent part; the exponent allows floating-point numbers to cover a range from extremely small to extremely large. In the 8087, floating-point numbers are 80 bits: 64 bits of significand, 15 bits of exponent, and a sign bit. An 80-bit register was very large in the era of 8-bit or 16-bit computers; the eight registers in the 8087 would be equivalent to 40 registers in the 8086 processor.&lt;/p&gt;
    &lt;p&gt;The registers store each bit in a static RAM cell. Each cell has two inverters connected in a loop. This circuit forms a stable feedback loop, with one inverter on and one inverter off. Depending on which inverter is on, the circuit stores a 0 or a 1. To write a new value into the circuit, one of the lines is pulled low, flipping the loop into the desired state. The trick is that each inverter uses a very weak transistor to pull the output high, so its output is easily overpowered to change the state.&lt;/p&gt;
    &lt;p&gt;These inverter pairs are arranged in an 8 × 80 grid that implements eight words of 80 bits. Each of the 80 rows has two bitlines that provide access to a bit. The bitlines provide both read and write access to a bit; the pair of bitlines allows either inverter to be pulled low to store the desired bit value. Eight vertical wordlines enable access to one word, one column of 80 bits. Each wordline turns on 160 pass transistors, connecting the bitlines to the inverters in the selected column. Thus, when a wordline is enabled, the bitlines can be used to read or write that word.&lt;/p&gt;
    &lt;p&gt;Although the chip looks two-dimensional, it actually consists of multiple layers. The bottom layer is silicon. The pinkish regions below are where the silicon has been "doped" to change its electrical properties, making it an active part of the circuit. The doped silicon forms a grid of horizontal and vertical wiring, with larger doped regions in the middle. On top of the silicon, polysilicon wiring provides two functions. First, it provides a layer of wiring to connect the circuit. But more importantly, when polysilicon crosses doped silicon, it forms a transistor. The polysilicon provides the gate, turning the transistor on and off. In this photo, the polysilicon is barely visible, so I've highlighted part of it in red. Finally, horizontal metal wires provide a third layer of interconnecting wiring. Normally, the metal hides the underlying circuitry, so I removed the metal with acid for this photo. I've drawn blue lines to represent the metal layer. Contacts provide connections between the various layers.&lt;/p&gt;
    &lt;p&gt;The layers combine to form the inverters and selection transistors of a memory cell, indicated with the dotted line below. There are six transistors (yellow), where polysilicon crosses doped silicon. Each inverter has a transistor that pulls the output low and a weak transistor to pull the output high. When the word line (vertical polysilicon) is active, it connects the selected inverters to the bit lines (horizontal metal) through the two selection transistors. This allows the bit to be read or written.&lt;/p&gt;
    &lt;p&gt;Each register has two tag bits associated with it, an unusual form of metadata to indicate if the register is empty, contains zero, contains a valid value, or contains a special value such as infinity. The tag bits are used to optimize performance internally and are mostly irrelevant to the programmer. As well as being accessed with a register, the tag bits can be accessed in parallel as a 16-bit "Tag Word". This allows the tags to be saved or loaded as part of the 8087's state, for instance, during interrupt handling.&lt;/p&gt;
    &lt;head rend="h2"&gt;The decoder&lt;/head&gt;
    &lt;p&gt;The decoder circuit, wedged into the middle of the register file, selects one of the registers. A register is specified internally with a 3-bit value. The decoder circuit energizes one of the eight register select lines based on this value.&lt;/p&gt;
    &lt;p&gt;The decoder circuitry is straightforward: it has eight 3-input NOR gates to match one of the eight bit patterns. The select line is then powered through a high-current driver that uses large transistors. (In the photo below, you can compare the large serpentine driver transistors to the small transistors in a bit cell.)&lt;/p&gt;
    &lt;p&gt;The decoder has an interesting electrical optimization. As shown earlier, the register select lines are eight polysilicon lines running vertically, the length of the register file. Unfortunately, polysilicon has fairly high resistance, better than silicon but much worse than metal. The problem is that the resistance of a long polysilicon line will slow down the system. That is, the capacitance of transistor gates in combination with high resistance causes an RC (resistive-capacitive) delay in the signal.&lt;/p&gt;
    &lt;p&gt;The solution is that the register select lines also run in the metal layer, a second set of lines immediately to the right of the register file. These lines branch off from the register file about 1/3 of the way down, run to the bottom, and then connect back to the polysilicon select lines at the bottom. This reduces the maximum resistance through a select line, increasing the speed.&lt;/p&gt;
    &lt;head rend="h2"&gt;The stack control circuitry&lt;/head&gt;
    &lt;p&gt;A stack needs more control circuitry than a regular register file, since the circuitry must keep track of the position of the top of the stack.3 The control circuitry increments and decrements the top of stack (TOS) pointer as values are pushed or popped (purple).4 Moreover, an 8087 instruction can access a register based on its offset, for instance the third register from the top. To support this, the control circuitry can temporarily add an offset to the top of stack position (green). A multiplexer (red) selects either the top of stack or the adder output, and feeds it to the decoder (blue), which selects one of the eight stack registers in the register file (yellow), as described earlier.&lt;/p&gt;
    &lt;p&gt;The physical implementation of the stack circuitry is shown below. The logic at the top selects the stack operation based on the 16-bit micro-instruction.5 Below that are the three latches that hold the top of stack value. (The large white squares look important, but they are simply "jumpers" from the ground line to the circuitry, passing under metal wires.)&lt;/p&gt;
    &lt;p&gt;The three-bit adder is at the bottom, along with the multiplexer. You might expect the adder to use a simple "full adder" circuit. Instead, it is a faster carry-lookahead adder. I won't go into details here, but the summary is that at each bit position, an AND gate produces a Carry Generate signal while an XOR gate produces a Carry Propagate signal. Logic gates combine these signals to produce the output bits in parallel, avoiding the slowdown of the carry rippling through the bits.&lt;/p&gt;
    &lt;p&gt;The incrementer/decrementer uses a completely different approach. Each of the three bits uses a toggle flip-flop. A few logic gates determine if each bit should be toggled or should keep its previous value. For instance, when incrementing, the top bit is toggled if the lower bits are 11 (e.g. incrementing from 011 to 100). For decrementing, the top bit is toggled if the lower bits are 00 (e.g. 100 to 011). Simpler logic determines if the middle bit should be toggled. The bottom bit is easier, toggling every time whether incrementing or decrementing.&lt;/p&gt;
    &lt;p&gt;The schematic below shows the circuitry for one bit of the stack. Each bit is implemented with a moderately complicated flip-flop that can be cleared, loaded with a value, or toggled, based on control signals from the microcode. The flip-flop is constructed from two set-reset (SR) latches. Note that the flip-flop outputs are crossed when fed back to the input, providing the inversion for the toggle action. At the right, the multiplexer selects either the register value or the sum from the adder (not shown), generating the signals to the decoder.&lt;/p&gt;
    &lt;head rend="h2"&gt;Drawbacks of the stack approach&lt;/head&gt;
    &lt;p&gt;According to the designers of the 8087,7 the main motivation for using a stack rather than a flat register set was that instructions didn't have enough bits to address multiple register operands. In addition, a stack has "advantages over general registers for expression parsing and nested function calls." That is, a stack works well for a mathematical expression since sub-expressions can be evaluated on the top of the stack. And for function calls, you avoid the cost of saving registers to memory, since the subroutine can use the stack without disturbing the values underneath. At least that was the idea.&lt;/p&gt;
    &lt;p&gt;The main problem is "stack overflow". The 8087's stack has eight entries, so if you push a ninth value onto the stack, the stack will overflow. Specifically, the top-of-stack pointer will wrap around, obliterating the bottom value on the stack. The 8087 is designed to detect a stack overflow using the register tags: pushing a value to a non-empty register triggers an invalid operation exception.6&lt;/p&gt;
    &lt;p&gt;The designers expected that stack overflow would be rare and could be handled by the operating system (or library code). After detecting a stack overflow, the software should dump the existing stack to memory to provide the illusion of an infinite stack. Unfortunately, bad design decisions made it difficult "both technically and commercially" to handle stack overflow.&lt;/p&gt;
    &lt;p&gt;One of the 8087's designers (Kahan) attributes the 8087's stack problems to the time difference between California, where the designers lived, and Israel, where the 8087 was implemented. Due to a lack of communication, each team thought the other was implementing the overflow software. It wasn't until the 8087 was in production that they realized that "it might not be possible to handle 8087 stack underflow/overflow in a reasonable way. It's not impossible, just impossible to do it in a reasonable way."&lt;/p&gt;
    &lt;p&gt;As a result, the stack was largely a problem rather than a solution. Most 8087 software saved the full stack to memory before performing a function call, creating more memory traffic. Moreover, compilers turned out to work better with regular registers than a stack, so compiler writers awkwardly used the stack to emulate regular registers. The &lt;code&gt;GCC&lt;/code&gt; compiler reportedly needs 3000 lines of extra code to support the x87 stack.&lt;/p&gt;
    &lt;p&gt;In the 1990s, Intel introduced a new floating-point system called SSE, followed by AVX in 2011. These systems use regular (non-stack) registers and provide parallel operations for higher performance, making the 8087's stack instructions largely obsolete.&lt;/p&gt;
    &lt;head rend="h2"&gt;The success of the 8087&lt;/head&gt;
    &lt;p&gt;At the start, Intel was unenthusiastic about producing the 8087, viewing it as unlikely to be a success. John Palmar, a principal architect of the chip, had little success convincing skeptical Intel management that the market for the 8087 was enormous. Eventually, he said, "I'll tell you what. I'll relinquish my salary, provided you'll write down your number of how many you expect to sell, then give me a dollar for every one you sell beyond that."7 Intel didn't agree to the deal—which would have made a fortune for Palmer—but they reluctantly agreed to produce the chip.&lt;/p&gt;
    &lt;p&gt;Intel's Santa Clara engineers shunned the 8087, considering it unlikely to work: the 8087 would be two to three times more complex than the 8086, with a die so large that a wafer might not have a single working die. Instead, Rafi Nave, at Intel's Israel site, took on the risky project: “Listen, everybody knows it's not going to work, so if it won't work, I would just fulfill their expectations or their assessment. If, by chance, it works, okay, then we'll gain tremendous respect and tremendous breakthrough on our abilities.”&lt;/p&gt;
    &lt;p&gt;A small team of seven engineers developed the 8087 in Israel. They designed the chip on Mylar sheets: a millimeter on Mylar represented a micron on the physical chip. The drawings were then digitized on a Calma system by clicking on each polygon to create the layout. When the chip was moved into production, the yield was very low but better than feared: two working dies per four-inch wafer.&lt;/p&gt;
    &lt;p&gt;The 8087 ended up being a large success, said to have been Intel's most profitable product line at times. The success of the 8087 (along with the 8088) cemented the reputation of Intel Israel, which eventually became Israel's largest tech employer. The benefits of floating-point hardware proved to be so great that Intel integrated the floating-point unit into later processors starting with the 80486 (1989). Nowadays, most modern computers, from cellphones to mainframes, provide floating point based on the 8087, so I consider the 8087 one of the most influential chips ever created.&lt;/p&gt;
    &lt;p&gt;For more, follow me on Bluesky (@righto.com), Mastodon (@[email protected]), or RSS. I wrote some articles about the 8087 a few years ago, including the die, the ROM, the bit shifter, and the constants, so you may have seen some of this material before.&lt;/p&gt;
    &lt;head rend="h2"&gt;Notes and references&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Most computers now use the IEEE 754 floating-point standard, which is based on the 8087. This standard has been awarded a milestone in computation. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Curiously, reliable sources differ on the number of transistors in the 8087 by almost a factor of 2. Intel says 40,000, as does designer William Kahan (link). But in A Numeric Data Processor, designers Rafi Nave and John Palmer wrote that the chip contains "the equivalent of over 65,000 devices" (whatever "equivalent" means). This number is echoed by a contemporary article in Electronics (1980) that says "over 65,000 H-MOS transistors on a 78,000-mil2 die." Many other sources, such as Upgrading &amp;amp; Repairing PCs, specify 45,000 transistors. Designer Rafi Nave stated that the 8087 has 63,000 or 64,000 transistors if you count the ROM transistors directly, but if you count ROM transistors as equivalent to two transistors, then you get about 75,000 transistors. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The 8087 has a 16-bit Status Word that contains the stack top pointer, exception flags, the four-bit condition code, and other values. Although the Status Word appears to be a 16-bit register, it is not implemented as a register. Instead, parts of the Status Word are stored in various places around the chip: the stack top pointer is in the stack circuitry, the exception flags are part of the interrupt circuitry, the condition code bits are next to the datapath, and so on. When the Status Word is read or written, these various circuits are connected to the 8087's internal data bus, making the Status Word appear to be a monolithic entity. Thus, the stack circuitry includes support for reading and writing it. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Intel filed several patents on the 8087, including Numeric data processor, another Numeric data processor, Programmable bidirectional shifter, Fraction bus for use in a numeric data processor, and System bus arbitration, circuitry and methodology. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I started looking at the stack in detail to reverse engineer the micro-instruction format and determine how the 8087's microcode works. I'm working with the "Opcode Collective" on Discord on this project, but progress is slow due to the complexity of the micro-instructions. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The 8087 detects stack underflow in a similar manner. If you pop more values from the stack than are present, the tag will indicate that the register is empty and shouldn't be accessed. This triggers an invalid operation exception. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The 8087 is described in detail in The 8086 Family User's Manual, Numerics Supplement. An overview of the stack is on page 60 of The 8087 Primer by Palmer and Morse. More details are in Kahan's On the Advantages of the 8087's Stack, an unpublished course note (maybe for CS 279?) with a date of Nov 2, 1990 or perhaps August 23, 1994. Kahan discusses why the 8087's design makes it hard to handle stack overflow in How important is numerical accuracy, Dr. Dobbs, Nov. 1997. Another information source is the Oral History of Rafi Nave ↩↩&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46208409</guid><pubDate>Tue, 09 Dec 2025 18:16:44 +0000</pubDate></item><item><title>So you want to speak at software conferences?</title><link>https://dylanbeattie.net/2025/12/08/so-you-want-to-speak-at-software-conferences.html</link><description>&lt;doc fingerprint="6278511b9fc389bd"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;So You Want To Speak At Software Conferences?&lt;/head&gt;Posted by Dylan Beattie on 08 December 2025 • permalink&lt;p&gt;I run a .NET user group here in London, and we host a lot of talks from people who are relatively inexperienced presenters. Sometimes they’ve done presentations internally but never spoken before a public audience. Sometimes they’re developers who have been in theatre or played in bands; people with plenty of stage experience but who haven’t presented on technical topics before - and sometimes they’ve never done any kind of public presentations or performance at all. We aim to be a friendly, supportive crowd; public speaking can be daunting, and the first public outing of somebody’s first talk can be… let’s just say that the presenter sometimes learns a lot more than the audience, and leave it at that.&lt;/p&gt;&lt;p&gt;But it can also be a hugely rewarding experience, and as a seasoned tech presenter who’s been doing this for a while, aspiring speakers often ask me for advice on how to take it to the next level.&lt;/p&gt;&lt;p&gt;Before we get into the specifics, there are two things to bear in mind.&lt;/p&gt;&lt;p&gt;One: ask yourself why you want to do this. What does “the next level” mean for you? Are you looking to promote your consultancy, or your training courses, or your software products? Do you want to become a professional speaker and actually get paid to give talks? Are you doing it ‘cos you want to go places and meet people? Figure out what “success” looks like for you.&lt;/p&gt;&lt;p&gt;Two: be realistic about how much work is involved. It took me seven years to go from my first user group lightning talk, back 2008, to my first international conference. If you think you can hack together some code, write a talk about it, stick it on Sessionize and three months later you’re on your way to a major international event like NDC or Yow! or Devoxx… well, no. That’s not how this works. Strap in; it’s a long ride.&lt;/p&gt;&lt;head rend="h3"&gt;Year 1: Get Good&lt;/head&gt;&lt;p&gt;Write the talk. Write a talk nobody else could do; tell a story nobody else can tell. Figure out what your audience is going to learn, and why you’re the best person to teach them that. Then give it at local user group. It might go great. It might be a train wreck. Don’t worry. That’s one of the reasons user groups exist. Learn from the experience. Fix the demos. Fix the slides. If it was too short? Write some more. If it was too long? Cut something. Give it at another user group. Do it again. Do it again. Maybe write a second talk, shop that one around a couple of user groups too.&lt;/p&gt;&lt;p&gt;If you can’t find user groups, look on Meetup.com. Yes, it’s a horrible platform, but it works; search by topic, search by region, find groups that look like a good match for your content, and ask if they’re looking for speakers. They probably are.&lt;/p&gt;&lt;head rend="h3"&gt;Year 2: Get Seen&lt;/head&gt;&lt;p&gt;After user groups and meetups come the community conferences. Typically small, one-day events, with a few tracks, and usually free (or very cheap) to attend. For me, these were the DDD events _(that’s DDD as in Developers! Developers! Developers!, not to be confused with DDD as in Domain Driven Design), _a series of one-day free developer events around the UK, organised by volunteers, usually on a Saturday so people don’t have to take time off work. They bring in a good crowd, they’re a great way to get to know other presenters and people who are involved in tech events, and you’ll almost certainly meet a few people who are on the programme committees for the bigger conferences.&lt;/p&gt;&lt;p&gt;Events like this are your chance to get noticed. Turn up the day before, join the pre-conference dinner and drinks, introduce yourself. Yeah, it’s awkward when you don’t know anybody. There will be other people there who don’t know anybody and will appreciate you making the effort. Enjoy yourself, but don’t end up doing tequila shots in a karaoke bar at 3am. Not now. You’re there to give a talk, remember?&lt;/p&gt;&lt;p&gt;Go to the event. Spend the whole day there, do your talk, watch the other sessions. Communicate with the organisers. You don’t want their memorable impression of you to be a half-hour of panic and missed calls because one of their speakers has gone AWOL and nobody knows where they are.&lt;/p&gt;&lt;p&gt;Figure out how to keep in touch with the people you met. Join the Signal or WhatsApp group chat; if there isn’t one, create one. Follow them on LinkedIn, or Bluesky - be prepared to go where people are; don’t expect folks to join Mastodon just because that’s where you want to talk to them. That’s not how this works. If you really don’t want to play the social media game - and I can’t blame you - there’s always good old-fashioned email. A short email a week later saying “hey, thanks for having me” or “hey, I loved your session at DDD, let’s keep in touch” can pay off in a big way.&lt;/p&gt;&lt;p&gt;Finally, watch out for events that put video of their sessions online. Having a couple of YouTube links of you doing your thing in front of a live, appreciate audience can make all the difference when a programme committee is looking at a handful of talks and can only accept one of them.&lt;/p&gt;&lt;head rend="h3"&gt;Year 3: Get Accepted&lt;/head&gt;&lt;p&gt;You’ve got a couple of talks. You’ve delivered then enough times that you know they’re good *(and if they’re not good, make them good - or scrap them and write new ones)*. You know people. People know you. If somebody asks “hey, do we know anybody who could do a good session about $topic”, your name comes up. You’ve got a decent network of connections - group chats, LinkedIn, email addresses.&lt;/p&gt;&lt;p&gt;Now, find all the conferences in your field with an open Call for Papers (CfP), and get submitting. Dave Aronson over at codeasaur.us maintains a really useful list of CfPs which are closing soon. Check that regularly. Many events will cover your travel &amp;amp; hotel costs, although with sponsorship budgets drying up right across the industry that’s not as prevalent as it was a few years ago. If not, maybe you can persuade your employer to pay your travel - “hey, boss, if I can get a free ticket to this amazing conference with all these industry experts, do you think the company will pay my air fare &amp;amp; hotel?”&lt;/p&gt;&lt;p&gt;Lean on your network. What are people submitting to? Which events should you look out for? Which topics are getting a lot of traction (and which topics are not?)&lt;/p&gt;&lt;p&gt;Keep your content fresh. Write new talks. Keep giving them at user groups and community events.&lt;/p&gt;&lt;p&gt;Keep your submissions focused. 2-3 talks per event; don’t submit ten wildly different abstracts to the same conference in the hope one of them will get accepted. Every selection committee I’ve been on, if we see that, we assume the presenter hasn’t actually written *any* of them yet and is throwing everything they can think of into the mix and hoping one of them gets chosen. Not a great way to stand out. An open CFP at a big tech conference typically gets 20+ submissions for every available slot, which means if you reduce it to a numbers game, you’re submitting 20 talks for every one that gets accepted. Keep track of the numbers, and be objective about it.&lt;/p&gt;&lt;head rend="h3"&gt;Year 4: Get Bored.&lt;/head&gt;&lt;p&gt;It’s great fun doing this for a while… but it’s also exhausting. Some people hit it hard for a few years, do all the things, go to all the places, make a lot of great friends and happy memories, and then wake up one day and decide that’s enough. Some people do a few talks, tick it off their bucket list and decide that’s enough for them. Some settle into a gentle routine of 3-4 events they’ll do every year. And yes, some of us end up treating our calendars like a game of Tetris, juggling flights and trains and hotels and meetups and conferences and spending half the year on the road and the other half writing talks and workshops and all the other things it’s hard to do when you’re at the airport.&lt;/p&gt;&lt;p&gt;That’s why you gotta figure out ahead of time what “success” looks like. If you’re doing it for fun, remember to have fun - and if you find you’re not enjoying it any more? Stop. If you’re doing it as promotion or marketing? Track your leads. Make sure it’s actually generating the attention and the revenue it’s supposed to. If you’re doing it for money, be mercenary: no pay, no play. Not every event is the same, of course. In a given year I’ll have some events that are fun, some that are lucrative, some that are running alongside workshops or training engagements. Just make sure you know which is which.&lt;/p&gt;&lt;p&gt;Finally: respect your audience. Whether you’re talking to five people at a meetup, fifty at a community event, or five thousand at a huge international conference: those people are the reason you get to do this. They have given up their time - and often a substantial amount of money - to hear what you have to say. They deserve your best shot, every time. If you find you’re bored, fed up, tired, running talks on autopilot or making mistakes because you just don’t care? It’s time to try something else - and remember, there’s a thousand aspiring speakers out there who would dearly love to take that spot instead of you.&lt;/p&gt;&lt;p&gt;Now get out there. Work hard, have fun, teach us awesome things, and if you ever want me to look over an abstract or a slide deck, drop me a line - [email protected]. I’d be happy to help.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46208773</guid><pubDate>Tue, 09 Dec 2025 18:42:27 +0000</pubDate></item><item><title>10 Years of Let's Encrypt</title><link>https://letsencrypt.org/2025/12/09/10-years</link><description>&lt;doc fingerprint="6d5da1590926b3fa"&gt;
  &lt;main&gt;
    &lt;p&gt;On September 14, 2015, our first publicly-trusted certificate went live. We were proud that we had issued a certificate that a significant majority of clients could accept, and had done it using automated software. Of course, in retrospect this was just the first of billions of certificates. Today, Let’s Encrypt is the largest certificate authority in the world in terms of certificates issued, the ACME protocol we helped create and standardize is integrated throughout the server ecosystem, and we’ve become a household name among system administrators. We’re closing in on protecting one billion web sites.&lt;/p&gt;
    &lt;p&gt;In 2023, we marked the tenth anniversary of the creation of our nonprofit, Internet Security Research Group, which continues to host Let’s Encrypt and other public benefit infrastructure projects. Now, in honor of the tenth anniversary of Let’s Encrypt’s public certificate issuance and the start of the general availability of our services, we’re looking back at a few milestones and factors that contributed to our success.&lt;/p&gt;
    &lt;p&gt;A conspicuous part of Let’s Encrypt’s history is how thoroughly our vision of scalability through automation has succeeded.&lt;/p&gt;
    &lt;p&gt;In March 2016, we issued our one millionth certificate. Just two years later, in September 2018, we were issuing a million certificates every day. In 2020 we reached a billion total certificates issued and as of late 2025 we’re frequently issuing ten million certificates per day. We’re now on track to reach a billion active sites, probably sometime in the coming year. (The “certificates issued” and “certificates active” metrics are quite different because our certificates regularly expire and get replaced.)&lt;/p&gt;
    &lt;p&gt;The steady growth of our issuance volume shows the strength of our architecture, the validity of our vision, and the great efforts of our engineering team to scale up our own infrastructure. It also reminds us of the confidence that the Internet community is placing in us, making the use of a Let’s Encrypt certificate a normal and, dare we say, boring choice. But I often point out that our ever-growing issuance volumes are only an indirect measure of value. What ultimately matters is improving the security of people’s use of the web, which, as far as Let’s Encrypt’s contribution goes, is not measured by issuance volumes so much as by the prevalence of HTTPS encryption. For that reason, we’ve always emphasized the graph of the percentage of encrypted connections that web users make (here represented by statistics from Firefox).&lt;/p&gt;
    &lt;p&gt;(These graphs are snapshots as of the date of this post; a dynamically updated version is found on our stats page.) Our biggest goal was to make a concrete, measurable security impact on the web by getting HTTPS connection prevalence to increase—and it’s worked. It took five years or so to get the global percentage from below 30% to around 80%, where it’s remained ever since. In the U.S. it has been close to 95% for a while now.&lt;/p&gt;
    &lt;p&gt;A good amount of the remaining unencrypted traffic probably comes from internal or private organizational sites (intranets), but other than that we don’t know much about it; this would be a great topic for Internet security researchers to look into.&lt;/p&gt;
    &lt;p&gt;We believe our present growth in certificate issuance volume is essentially coming from growth in the web as a whole. In other words, if we protect 20% more sites over some time period, it’s because the web itself grew by 20%.&lt;/p&gt;
    &lt;p&gt;We’ve blogged about most of Let’s Encrypt’s most significant milestones as they’ve happened, and I invite everyone in our community to look over those blog posts to see how far we’ve come. We’ve also published annual reports for the past seven years, which offer elegant and concise summaries of our work.&lt;/p&gt;
    &lt;p&gt;As I personally think back on the past decade, just a few of the many events that come to mind include:&lt;/p&gt;
    &lt;p&gt;Telling the world about the project in November 2014&lt;/p&gt;
    &lt;p&gt;Our first certificate issuance in September 2015&lt;/p&gt;
    &lt;p&gt;Our one millionth certificate in March 2016, then our 100 millionth certificate in June 2017, and then our billionth certificate in 2020&lt;/p&gt;
    &lt;p&gt;Along the way, first issuing one million certificates in a single day (in September 2018), significantly contributed to by the SquareSpace and Shopify Let’s Encrypt integrations&lt;/p&gt;
    &lt;p&gt;Just at the end of September 2025, we issued more than ten million certificates in a day for the first time.&lt;/p&gt;
    &lt;p&gt;We’ve also periodically rolled out new features such as internationalized domain name support (2016), wildcard support (2018), and short-lived and IP address (2025) certificates. We’re always working on more new features for the future.&lt;/p&gt;
    &lt;p&gt;There are many technical milestones like our database server upgrades in 2021, where we found we needed a serious server infrastructure boost because of the tremendous volumes of data we were dealing with. Similarly, our original infrastructure was using Gigabit Ethernet internally, and, with the growth of our issuance volume and logging, we found that our Gigabit Ethernet network eventually became too slow to synchronize database instances! (Today we’re using 25-gig Ethernet.) More recently, we’ve experimented with architectural upgrades to our ever-growing Certificate Transparency logs, and decided to go ahead with deploying those upgrades—to help us not just keep up with, but get ahead of, our continuing growth.&lt;/p&gt;
    &lt;p&gt;These kinds of growing pains and successful responses to them are nice to remember because they point to the inexorable increase in demands on our infrastructure as we’ve become a more and more essential part of the Internet. I’m proud of our technical teams which have handled those increased demands capably and professionally.&lt;/p&gt;
    &lt;p&gt;I also recall the ongoing work involved in making sure our certificates would be as widely accepted as possible, which has meant managing the original cross-signature from IdenTrust, and subsequently creating and propagating our own root CA certificates. This process has required PKI engineering, key ceremonies, root program interactions, documentation, and community support associated with certificate migrations. Most users never have reason to look behind the scenes at our chains of trust, but our engineers update it as root and intermediate certificates have been replaced. We’ve engaged at the CA/B Forum, IETF, and in other venues with the browser root programs to help shape the web PKI as a technical leader.&lt;/p&gt;
    &lt;p&gt;As I wrote in 2020, our ideal of complete automation of the web PKI aims at a world where most site owners wouldn’t even need to think about certificates at all. We continue to get closer and closer to that world, which creates a risk that people will take us and our services for granted, as the details of certificate renewal occupy less of site operators’ mental energy. As I said at the time,&lt;/p&gt;
    &lt;p&gt;When your strategy as a nonprofit is to get out of the way, to offer services that people don’t need to think about, you’re running a real risk that you’ll eventually be taken for granted. There is a tension between wanting your work to be invisible and the need for recognition of its value. If people aren’t aware of how valuable our services are then we may not get the support we need to continue providing them.&lt;/p&gt;
    &lt;p&gt;I’m also grateful to our communications and fundraising staff who help make clear what we’re doing every day and how we’re making the Internet safer.&lt;/p&gt;
    &lt;p&gt;Our community continually recognizes our work in tangible ways by using our certificates—now by the tens of millions per day—and by sponsoring us.&lt;/p&gt;
    &lt;p&gt;We were honored to be recognized with awards including the 2022 Levchin Prize for Real-World Cryptography and the 2019 O’Reilly Open Source Award. In October of this year some of the individuals who got Let’s Encrypt started were honored to receive the IEEE Cybersecurity Award for Practice.&lt;/p&gt;
    &lt;p&gt;We documented the history, design, and goals of the project in an academic paper at the ACM CCS ‘19 conference, which has subsequently been cited hundreds of times in academic research.&lt;/p&gt;
    &lt;p&gt;Ten years later, I’m still deeply grateful to the five initial sponsors that got Let’s Encrypt off the ground - Mozilla, EFF, Cisco, Akamai, and IdenTrust. When they committed significant resources to the project, it was just an ambitious idea. They saw the potential and believed in our team, and because of that we were able to build the service we operate today.&lt;/p&gt;
    &lt;p&gt;I’d like to particularly recognize IdenTrust, a PKI company that worked as a partner from the outset and enabled us to issue publicly-trusted certificates via a cross-signature from one of their roots. We would simply not have been able to launch our publicly-trusted certificate service without them. Back when I first told them that we were starting a new nonprofit certificate authority that would give away millions of certificates for free, there wasn’t any precedent for this arrangement, and there wasn’t necessarily much reason for IdenTrust to pay attention to our proposal. But the company really understood what we were trying to do and was willing to engage from the beginning. Ultimately, IdenTrust’s support made our original issuance model a reality.&lt;/p&gt;
    &lt;p&gt;I’m proud of what we have achieved with our staff, partners, and donors over the past ten years. I hope to be even more proud of the next ten years, as we use our strong footing to continue to pursue our mission to protect Internet users by lowering monetary, technological, and informational barriers to a more secure and privacy-respecting Internet.&lt;/p&gt;
    &lt;p&gt;Let’s Encrypt is a project of the nonprofit Internet Security Research Group, a 501(c)(3) nonprofit. You can help us make the next ten years great as well by donating or becoming a sponsor.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46208962</guid><pubDate>Tue, 09 Dec 2025 18:54:55 +0000</pubDate></item><item><title>Agentic AI Foundation</title><link>https://block.xyz/inside/block-anthropic-and-openai-launch-the-agentic-ai-foundation</link><description>&lt;doc fingerprint="2f02334316bba1b9"&gt;
  &lt;main&gt;
    &lt;p&gt;An initiative to advance open source agentic AI under the Linux Foundation umbrella&lt;/p&gt;
    &lt;p&gt;Today, the industry is making a pivotal choice. Block, Anthropic, OpenAI, and other leaders in AI are launching the Agentic AI Foundation (AAIF) to ensure agentic AI develops as an open, collaborative ecosystem. Agentic AI refers to artificial intelligence systems that can take initiative, make decisions, and act independently to achieve goals with minimal human direction.&lt;/p&gt;
    &lt;p&gt;The AAIF is a vendor-neutral home for open source agentic AI projects where no single company dominates, providing funding for critical community programs and research, and building open protocols that let systems from different builders work together seamlessly. Block is contributing its open source agent goose to the AAIF, along with Anthropicâs Model Context Protocol (MCP) and OpenAIâs AGENTS.md.&lt;/p&gt;
    &lt;p&gt;In addition to the three founding members, the AAIFâs platinum members include Amazon Web Services, Bloomberg, Cloudflare, Google, and MicrosoftI. Gold members of the AAIF include Adyen, Arcade.dev, Cisco, Datadog, Docker, Ericsson, IBM, JetBrains, Okta, Oracle, Runlayer, Salesforce, SAP, Shopify, Snowflake, Temporal, Tetrate, and Twilio Inc. Silver members of the AAIF include Apify, Chronosphere, Cosmonic, Elasticsearch, Eve Security, Hugging Face, Kubermatic, KYXStart, LanceDB, Mirantis, NinjaTech AI, Obot.ai, Prefect.io, Pydantic, Shinkai.com, Solo.io, Spectro Cloud, Stacklok, SUSE, Uber, WorkOS, Zapier and ZED.&lt;/p&gt;
    &lt;p&gt;AI systems represent one of the most significant technological shifts in decades. These systems are fundamentally reshaping how developers build software, how businesses operate, and how people solve complex problems. Use of autonomous agents promises to accelerate this even further.&lt;/p&gt;
    &lt;p&gt;But we're at a critical juncture. We have an unprecedented opportunity to shape how this technology develops. Will we build open, interoperable infrastructure that serves everyone? Or will we see fragmentation that limits this powerful technology's potential? Without collaborative open development, we risk missing the full potential of agentic AI where everyone benefits thanks to open standards, open protocols, and open systems on which other tools are built. We also risk concentrating the power in the hands of a few, which dampers competition and restricts accessibility. In a proprietary, siloed ecosystem, breakthrough ideas can't easily build on each other, integration challenges slow enterprise adoption and limit use cases, accessibility barriers prevent smaller organizations from benefiting, and research limitations slow academic and independent innovation.&lt;/p&gt;
    &lt;p&gt;History proves thereâs a better path. The Internet, Linux, and the Web succeeded precisely because they were open. They empowered anyone with talent and determination to build, innovate, and create value on top of open infrastructure. Agentic AI deserves the same opportunity. We hope that the AAIF can become what the W3C is for the Web: a set of standards and protocols that guarantee interoperability, open access, and freedom of choice with open source reference implementations.&lt;/p&gt;
    &lt;p&gt;The Agentic AI Foundation provides a neutral home where companies, researchers, and independent developers can collaborate on open source agentic AI.&lt;/p&gt;
    &lt;p&gt;Following the Linux Foundation's trusted governance model, AAIF will operate on several core principles:&lt;/p&gt;
    &lt;p&gt;Open Governance: AAIF operates under a transparent and inclusive governance model where contributors from all backgrounds are empowered to shape the direction of the foundation and its projects. Decisions, policies, and criteria are open and accessible to members.&lt;/p&gt;
    &lt;p&gt;AI Innovation: AAIF encourages agentic AI innovation and exploration from a diverse and collaborative ecosystem of open source developers, researchers, and practitioners. We move at the speed of AI, keeping governance small and responsive.&lt;/p&gt;
    &lt;p&gt;Sustainability and Neutrality: AAIF provides neutral infrastructure and funding mechanisms to ensure long-term sustainability of projects. Project inclusion is based on demonstrated adoption, quality, and community health - not how well funded it may be.&lt;/p&gt;
    &lt;p&gt;Focused, not broad: The AAIF exists to further open source agentic AI - not to cover all of open source AI, machine learning, or data science.&lt;/p&gt;
    &lt;p&gt;AAIF launches with contributions from Block, Anthropic, and OpenAI:&lt;/p&gt;
    &lt;p&gt;goose, Block's open source agentic AI framework, will transition to community governance under AAIF. Since its release earlier this year, goose has become a reference implementation for Anthropic's Model Context Protocol (MCP) and has attracted thousands of developers worldwide. Under AAIF, goose will maintain its open source license and commercial-friendly terms while gaining the benefits of neutral governance and broader community input.&lt;/p&gt;
    &lt;p&gt;Model Context Protocol (MCP), developed by Anthropic, is an open protocol that enables seamless integration between AI systems and external data sources, providing a standardized way for AI agents to access context. MCP demonstrates AAIF's potential as the neutral hub for cross-industry agentic AI standards. From MCPâs very first release, Block engineers have been active contributors, and several continue to participate as members of the MCP steering committee.&lt;/p&gt;
    &lt;p&gt;AGENTS.md, developed by OpenAI, is an open format for guiding coding agents. It is used by more than 20,000 open source projects and serves as a README for agents: a dedicated, predictable place to provide the context and instructions to help AI coding agents work on projects.&lt;/p&gt;
    &lt;p&gt;Additional projects from other member organizations have been proposed and are being evaluated to join, and will be selected based on demonstrated adoption, strong governance, and alignment with AAIF's mission to advance open source agentic AI.&lt;/p&gt;
    &lt;p&gt;AAIF succeeds only if it truly represents the community. Whether you're a developer, researcher, company, or simply someone who believes AI should be open, there are multiple ways to participate:&lt;/p&gt;
    &lt;p&gt;Contribute to projects: All AAIF projects welcome community contributions. Check project repositories for contribution guidelines and good first issues.&lt;/p&gt;
    &lt;p&gt;Join the conversation &amp;amp; propose new projects: Have an agentic AI project that could benefit from neutral governance, foundation support, collaboration with leaders in agentic AI, and more visibility? Projects that promote the agentic AI ecosystem, operate under OSI-approved open source licenses, demonstrate open governance, and foster community growth are welcome to apply. For more information about the AAIF and how to become a member, please visit AAIF.io.&lt;/p&gt;
    &lt;p&gt;Attend events: Participate in AAIF-sponsored conferences, hackathons, and meetups to connect with the community and learn about the latest developments.&lt;/p&gt;
    &lt;p&gt;The foundation's governance structure ensures that community voices matter, not just corporate interests. Technical decisions will be made by project maintainers and steering committees, with AAIF providing resources and neutral oversight.&lt;/p&gt;
    &lt;p&gt;The next decade of AI development will be defined by choices we make today. By establishing the AAIF, the industry is making a clear statement: agentic AI will be open, accessible, and community-driven. The world has repeatedly proven that open collaboration produces better outcomes than competition in isolation. The AAIF provides the structure for that open collaboration to flourish in agentic AI.&lt;/p&gt;
    &lt;p&gt;This isn't just about technology: it's about values. It's about ensuring that powerful tools serve everyone. It's about creating an ecosystem where the best ideas win, regardless of where they come from.&lt;/p&gt;
    &lt;p&gt;The future is being written in the open. Join us.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46209846</guid><pubDate>Tue, 09 Dec 2025 20:00:39 +0000</pubDate></item><item><title>Django: what’s new in 6.0</title><link>https://adamj.eu/tech/2025/12/03/django-whats-new-6.0/</link><description>&lt;doc fingerprint="babb1d3d4db5baca"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Django: whatâs new in 6.0&lt;/head&gt;
    &lt;p&gt;Django 6.0 was released today, starting another release cycle for the loved and long-lived Python web framework (now 20 years old!). It comes with a mosaic of new features, contributed to by many, some of which I am happy to have helped with. Below is my pick of highlights from the release notes.&lt;/p&gt;
    &lt;head rend="h2"&gt;Upgrade with help from django-upgrade&lt;/head&gt;
    &lt;p&gt;If youâre upgrading a project from Django 5.2 or earlier, please try my tool django-upgrade. It will automatically update old Django code to use new features, fixing some deprecation warnings for you, including five fixers for Django 6.0. (One day, Iâll propose django-upgrade to become an official Django project, when energy and time permitâ¦)&lt;/p&gt;
    &lt;head rend="h2"&gt;Template partials&lt;/head&gt;
    &lt;p&gt;There are four headline features in Django 6.0, which weâll cover before other notable changes, starting with this one:&lt;/p&gt;
    &lt;quote&gt;The Django Template Language now supports template partials, making it easier to encapsulate and reuse small named fragments within a template file.&lt;/quote&gt;
    &lt;p&gt;Partials are sections of a template marked by the new &lt;code&gt;{% partialdef %}&lt;/code&gt; and &lt;code&gt;{% endpartialdef %}&lt;/code&gt; tags. They can be reused within the same template or rendered in isolation. Letâs look at examples for each use case in turn.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reuse partials within the same template&lt;/head&gt;
    &lt;p&gt;The below template reuses a partial called &lt;code&gt;filter_controls&lt;/code&gt; within the same template. Itâs defined once at the top of the template, then used twice later on. Using a partial allows the template avoid repetition without pushing the content into a separate include file.&lt;/p&gt;
    &lt;code&gt;&amp;lt;section id=videos&amp;gt;
  {% partialdef filter_controls %}
    &amp;lt;form&amp;gt;
      {{ filter_form }}
    &amp;lt;/form&amp;gt;
  {% endpartialdef %}

  {% partial filter_controls %}

  &amp;lt;ul&amp;gt;
    {% for video in videos %}
      &amp;lt;li&amp;gt;
        &amp;lt;h2&amp;gt;{{ video.title }}&amp;lt;/h2&amp;gt;
        ...
      &amp;lt;/li&amp;gt;
    {% endfor %}
  &amp;lt;/ul&amp;gt;

  {% partial filter_controls %}
&amp;lt;/section&amp;gt;
&lt;/code&gt;
    &lt;p&gt;Actually, we can simplify this pattern further, by using the &lt;code&gt;inline&lt;/code&gt; option on the &lt;code&gt;partialdef&lt;/code&gt; tag, which causes the definition to also render in place:&lt;/p&gt;
    &lt;code&gt;&amp;lt;section id=videos&amp;gt;
  {% partialdef filter_controls inline %}
    &amp;lt;form&amp;gt;
      {{ filter_form }}
    &amp;lt;/form&amp;gt;
  {% endpartialdef %}

  &amp;lt;ul&amp;gt;
    {% for video in videos %}
      &amp;lt;li&amp;gt;
        &amp;lt;h2&amp;gt;{{ video.title }}&amp;lt;/h2&amp;gt;
        ...
      &amp;lt;/li&amp;gt;
    {% endfor %}
  &amp;lt;/ul&amp;gt;

  {% partial filter_controls %}
&amp;lt;/section&amp;gt;
&lt;/code&gt;
    &lt;p&gt;Reach for this pattern any time you find yourself repeating template code within the same template. Because partials can use variables, you can also use them to de-duplicate when rendering similar controls with different data.&lt;/p&gt;
    &lt;head rend="h3"&gt;Render partials in isolation&lt;/head&gt;
    &lt;p&gt;The below template defines a &lt;code&gt;view_count&lt;/code&gt; partial thatâs intended to be re-rendered in isolation. It uses the &lt;code&gt;inline&lt;/code&gt; option, so when the whole template is rendered, the partial is included.&lt;/p&gt;
    &lt;p&gt;The page uses htmx, via my django-htmx package, to periodically refresh the view count, through the &lt;code&gt;hx-*&lt;/code&gt; attributes. The request from htmx goes to a dedicated view that re-renders the &lt;code&gt;view_count&lt;/code&gt; partial.&lt;/p&gt;
    &lt;code&gt;{% load django_htmx %}
&amp;lt;!doctype html&amp;gt;
&amp;lt;html&amp;gt;
  &amp;lt;body&amp;gt;
    &amp;lt;h1&amp;gt;{{ video.title }}&amp;lt;/h1&amp;gt;
    &amp;lt;video width=1280 height=720 controls&amp;gt;
      &amp;lt;source src="{{ video.file.url }}" type="video/mp4"&amp;gt;
      Your browser does not support the video tag.
    &amp;lt;/video&amp;gt;

    {% partialdef view_count inline %}
    &amp;lt;section
      class=view-count
      hx-trigger="every 1s"
      hx-swap=outerHTML
      hx-get="{% url 'video-view-count' video.id %}"
    &amp;gt;
      {{ video.view_count }} views
    &amp;lt;/section&amp;gt;
    {% endpartialdef %}

    {% htmx_script %}
  &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;
    &lt;p&gt;The relevant code for the two views could look like this:&lt;/p&gt;
    &lt;code&gt;from django.shortcuts import render


def video(request, video_id):
    ...
    return render(request, "video.html", {"video": video})


def video_view_count(request, video_id):
    ...
    return render(request, "video.html#view_count", {"video": video})
&lt;/code&gt;
    &lt;p&gt;The initial &lt;code&gt;video&lt;/code&gt; view renders the full template &lt;code&gt;video.html&lt;/code&gt;. The &lt;code&gt;video_view_count&lt;/code&gt; view renders just the &lt;code&gt;view_count&lt;/code&gt; partial, by appending &lt;code&gt;#view_count&lt;/code&gt; to the template name. This syntax is similar to how youâd reference an HTML fragment by its ID in a URL.&lt;/p&gt;
    &lt;head rend="h3"&gt;History&lt;/head&gt;
    &lt;p&gt;htmx was the main motivation for this feature, as promoted by htmx creator Carson Gross in a cross-framework review post. Using partials definitely helps maintain âLocality of behaviourâ within your templates, easing authoring, debugging, and maintenance by avoiding template file sprawl.&lt;/p&gt;
    &lt;p&gt;Djangoâs support for template partials was initially developed by Carlton Gibson in the django-template-partials package, which remains available for older Django versions. The integration into Django itself was done in a Google Summer of Code project this year, worked on by student Farhan Ali and mentored by Carlton, in Ticket #36410. You can read more about the development process in Farhanâs retrospective blog post. Many thanks to Farhan for authoring, Carlton for mentoring, and Natalia Bidart, Nick Pope, and Sarah Boyce for reviewing!&lt;/p&gt;
    &lt;head rend="h2"&gt;Tasks framework&lt;/head&gt;
    &lt;p&gt;The next headline feature weâre covering:&lt;/p&gt;
    &lt;quote&gt;Django now includes a built-in Tasks framework for running code outside the HTTP requestâresponse cycle. This enables offloading work, such as sending emails or processing data, to background workers.&lt;/quote&gt;
    &lt;p&gt;Basically, thereâs a new API for defining and enqueuing background tasksâvery cool!&lt;/p&gt;
    &lt;p&gt;Background tasks are a way of running code outside of the request-response cycle. Theyâre a common requirement in web applications, used for sending emails, processing images, generating reports, and more.&lt;/p&gt;
    &lt;p&gt;Historically, Django has not provided any system for background tasks, and kind of ignored the problem space altogether. Developers have instead relied on third-party packages like Celery or Django Q2. While these systems are fine, they can be complex to set up and maintain, and often donât âgo with the grainâ of Django.&lt;/p&gt;
    &lt;p&gt;The new Tasks framework fills this gap by providing an interface to define background tasks, which task runner packages can then integrate with. This common ground allows third-party Django packages to define tasks in a standard way, assuming youâll be using a compatible task runner to execute them.&lt;/p&gt;
    &lt;p&gt;Define tasks with the new &lt;code&gt;@task&lt;/code&gt; decorator:&lt;/p&gt;
    &lt;code&gt;from django.tasks import task


@task
def resize_video(video_id): ...
&lt;/code&gt;
    &lt;p&gt;â¦and enqueue them for background execution with the &lt;code&gt;Task.enqueue()&lt;/code&gt; method:&lt;/p&gt;
    &lt;code&gt;from example.tasks import resize_video


def upload_video(request):
    ...
    resize_video.enqueue(video.id)
    ...
&lt;/code&gt;
    &lt;head rend="h3"&gt;Execute tasks&lt;/head&gt;
    &lt;p&gt;At this time, Django does not include a production-ready task backend, only two that are suitable for development and testing:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;ImmediateBackend&lt;/code&gt;- runs tasks synchronously, blocking until they complete.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;DummyBackend&lt;/code&gt;- does nothing when tasks are enqueued, but allows them to be inspected later. Useful for tests, where you can assert that tasks were enqueued without actually running them.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For production use, youâll need to use a third-party package that implements one, for which django-tasks, the reference implementation, is the primary option. It provides &lt;code&gt;DatabaseBackend&lt;/code&gt; for storing tasks in your SQL database, a fine solution for many projects, avoiding extra infrastructure and allowing atomic task enqueuing within database transactions. We may see this backend merged into Django in due course, or at least become an official package, to help make Django âbatteries includedâ for background tasks.&lt;/p&gt;
    &lt;p&gt;To use django-tasksâ &lt;code&gt;DatabaseBackend&lt;/code&gt; today, first install the package:&lt;/p&gt;
    &lt;code&gt;uv add django-tasks
&lt;/code&gt;
    &lt;p&gt;Second, add these two apps to your &lt;code&gt;INSTALLED_APPS&lt;/code&gt; setting:&lt;/p&gt;
    &lt;code&gt;INSTALLED_APPS = [
    # ...
    "django_tasks",
    "django_tasks.backends.database",
    # ...
]
&lt;/code&gt;
    &lt;p&gt;Third, configure &lt;code&gt;DatabaseBackend&lt;/code&gt; as your tasks backend in the new &lt;code&gt;TASKS&lt;/code&gt; setting:&lt;/p&gt;
    &lt;code&gt;TASKS = {
    "default": {
        "BACKEND": "django_tasks.backends.database.DatabaseBackend",
    },
}
&lt;/code&gt;
    &lt;p&gt;Fourth, run migrations to create the necessary database tables:&lt;/p&gt;
    &lt;code&gt;$ ./manage.py migrate
&lt;/code&gt;
    &lt;p&gt;Finally, to run the task worker process, use the packageâs &lt;code&gt;db_worker&lt;/code&gt; management command:&lt;/p&gt;
    &lt;code&gt;$ ./manage.py db_worker
Starting worker worker_id=jWLMLrms3C2NcUODYeatsqCFvd5rK6DM queues=default
&lt;/code&gt;
    &lt;p&gt;This process runs indefinitely, polling for tasks and executing them, logging events as it goes:&lt;/p&gt;
    &lt;code&gt;Task id=10b794ed-9b64-4eed-950c-fcc92cd6784b path=example.tasks.echo state=RUNNING
Hello from test task!
Task id=10b794ed-9b64-4eed-950c-fcc92cd6784b path=example.tasks.echo state=SUCCEEDED
&lt;/code&gt;
    &lt;p&gt;Youâll want to run &lt;code&gt;db_worker&lt;/code&gt; in production, and also in development if you want to test background task execution.&lt;/p&gt;
    &lt;head rend="h3"&gt;History&lt;/head&gt;
    &lt;p&gt;Itâs been a long path to get the Tasks framework into Django, and Iâm super excited to see it finally available in Django 6.0. Jake Howard started on the idea for Wagtail, a Django-powered CMS, back in 2021, as they have a need for common task definitions across their package ecosystem. He upgraded the idea to target Django itself in 2024, when he proposed DEP 0014. As a member of the Steering Council at the time, I had the pleasure of helping review and accept the DEP.&lt;/p&gt;
    &lt;p&gt;Since then, Jake has been leading the implementation effort, building pieces first in the separate django-tasks package before preparing them for inclusion in Django itself. This step was done under Ticket #35859, with a pull request that took nearly a year to review and land. Thanks to Jake for his perseverance here, and to all reviewers: Andreas NÃ¼Ãlein, Dave Gaeddert, Eric Holscher, Jacob Walls, Jake Howard, Kamal Mustafa, @rtr1, @tcely, Oliver Haas, Ran Benita, Raphael Gaschignard, and Sarah Boyce.&lt;/p&gt;
    &lt;p&gt;Read more about this feature and story in Jakeâs post celebrating when it was merged.&lt;/p&gt;
    &lt;head rend="h2"&gt;Content Security Policy support&lt;/head&gt;
    &lt;p&gt;Our third headline feature:&lt;/p&gt;
    &lt;quote&gt;Built-in support for the Content Security Policy (CSP) standard is now available, making it easier to protect web applications against content injection attacks such as cross-site scripting (XSS). CSP allows declaring trusted sources of content by giving browsers strict rules about which scripts, styles, images, or other resources can be loaded.&lt;/quote&gt;
    &lt;p&gt;Iâm really excited about this, because Iâm a bit of a security nerd whoâs been deploying CSP for client projects for years.&lt;/p&gt;
    &lt;p&gt;CSP is a security standard that can protect your site from cross-site scripting (XSS) and other code injection attacks. You set a &lt;code&gt;content-security-policy&lt;/code&gt; header to declare which content sources are trusted for your site, and then browsers will block content from other sources. For example, you might declare that only scripts your domain are allowed, so an attacker who manages to inject a &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; tag pointing to evil.com would be thwarted, as the browser would refuse to load it.&lt;/p&gt;
    &lt;p&gt;Previously, Django had no built-in support for CSP, and developers had to rely on building their own, or using a third-party package like the very popular django-csp. But this was a little bit inconvenient, as it meant that other third-party packages couldnât reliably integrate with CSP, as there was no common API to do so.&lt;/p&gt;
    &lt;p&gt;The new CSP support provides all the core features that django-csp did, with a slightly tidier and more Djangoey API. To get started, first add &lt;code&gt;ContentSecurityPolicyMiddleware&lt;/code&gt; to your &lt;code&gt;MIDDLEWARE&lt;/code&gt; setting:&lt;/p&gt;
    &lt;code&gt;MIDDLEWARE = [
    # ...
    "django.middleware.csp.ContentSecurityPolicyMiddleware",
    # ...
]
&lt;/code&gt;
    &lt;p&gt;Place it next to &lt;code&gt;SecurityMiddleware&lt;/code&gt;, as it similarly adds security-related headers to all responses. (You do have &lt;code&gt;SecurityMiddleware&lt;/code&gt; enabled, right?)&lt;/p&gt;
    &lt;p&gt;Second, configure your CSP policy using the new settings:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;SECURE_CSP&lt;/code&gt;to configure the&lt;code&gt;content-security-policy&lt;/code&gt;header, which is your actively enforced policy.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;SECURE_CSP_REPORT_ONLY&lt;/code&gt;to configure the&lt;code&gt;content-security-policy-report-only&lt;/code&gt;header, which sets a non-enforced policy for which browsers report violations to a specified endpoint. This option is useful for testing and monitoring a policy before enforcing it.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For example, to adopt the nonce-based strict CSP recommended by web.dev, you could start with the following setting:&lt;/p&gt;
    &lt;code&gt;from django.utils.csp import CSP

SECURE_CSP_REPORT_ONLY = {
    "script-src": [CSP.NONCE, CSP.STRICT_DYNAMIC],
    "object-src": [CSP.NONE],
    "base-uri": [CSP.NONE],
}
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;CSP&lt;/code&gt; enum used above provides constants for CSP directives, to help avoid typos.&lt;/p&gt;
    &lt;p&gt;This policy is quite restrictive and will break most existing sites if deployed as-is, because it requires nonces, as covered next. Thatâs why the example shows starting with the report-only mode header, to help track down places that need fixing before enforcing the policy. Youâd later change to setting the &lt;code&gt;SECURE_CSP&lt;/code&gt; setting to enforce the policy.&lt;/p&gt;
    &lt;p&gt;Anyway, those are the two basic steps to set up the new CSP support!&lt;/p&gt;
    &lt;head rend="h3"&gt;Nonce generation&lt;/head&gt;
    &lt;p&gt;A key part of the new feature is that nonce generation is now built-in to Django, when using the CSP middleware. Nonces are a security feature in CSP that allow you to mark specific &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; and &lt;code&gt;&amp;lt;style&amp;gt;&lt;/code&gt; tags as trusted with a &lt;code&gt;nonce&lt;/code&gt; attribute:&lt;/p&gt;
    &lt;code&gt;&amp;lt;script src=/static/app.js type=module nonce=55vsH4w7ATHB85C3MbPr_g&amp;gt;&amp;lt;/script&amp;gt;
&lt;/code&gt;
    &lt;p&gt;The nonce value is randomly generated per-request, and included in the CSP header. An attacker performing content injection couldnât guess the nonce, so browsers can trust only those tags that include the correct nonce. Because nonce generation is now part of Django, third-party packages can depend on it for their &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; and &lt;code&gt;&amp;lt;style&amp;gt;&lt;/code&gt; tags and theyâll continue to work if you adopt CSP with nonces.&lt;/p&gt;
    &lt;p&gt;Nonces are the recommended way to use CSP today, avoiding problems with previous allow-list based approaches. Thatâs why the above recommended policy enables them. To adopt a nonce-based policy, youâll need to annotate your &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; and &lt;code&gt;&amp;lt;style&amp;gt;&lt;/code&gt; tags with the nonce value through the following steps.&lt;/p&gt;
    &lt;p&gt;First, add the new &lt;code&gt;csp&lt;/code&gt; template context processor to your &lt;code&gt;TEMPLATES&lt;/code&gt; setting:&lt;/p&gt;
    &lt;code&gt;TEMPLATES = [
    {
        "BACKEND": "django.template.backends.django.DjangoTemplates",
        "OPTIONS": {
            "context_processors": [
                # ...
                "django.template.context_processors.csp",
            ],
        },
    },
]
&lt;/code&gt;
    &lt;p&gt;Second, annotate your &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; and &lt;code&gt;&amp;lt;style&amp;gt;&lt;/code&gt; tags with &lt;code&gt;nonce="{{ csp_nonce }}"&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;-   &amp;lt;script src="{% static 'app.js' %}" type="module"&amp;gt;&amp;lt;/script&amp;gt;
+   &amp;lt;script src="{% static 'app.js' %}" type="module" nonce="{{ csp_nonce }}"&amp;gt;&amp;lt;/script&amp;gt;
&lt;/code&gt;
    &lt;p&gt;This can be tedious and error-prone, hence using the report-only mode first to monitor violations might be useful, especially on larger projects.&lt;/p&gt;
    &lt;p&gt;Anyway, deploying CSP right would be another post in itself, or even a book chapter, so weâll stop here for now. For more info, check out that web.dev article and the MDN CSP guide.&lt;/p&gt;
    &lt;head rend="h3"&gt;History&lt;/head&gt;
    &lt;p&gt;CSP itself was proposed for browsers way back in 2004, and was first implemented in Mozilla Firefox version 4, released 2011. That same year, Django Ticket #15727 was opened, proposing adding CSP support to Django. Mozilla created django-csp from 2010, before the first public availability of CSP, using it on their own Django-powered sites. The first comment on Ticket #15727 pointed to django-csp, and the community basically rolled with it as the de facto solution.&lt;/p&gt;
    &lt;p&gt;Over the years, CSP itself evolved, as did django-csp, with Rob Hudson ending up as its maintainer. Focusing on the package motivated to finally get CSP into Django itself. He made a draft PR and posted on Ticket #15727 in 2024, which I enjoyed helping review. He iterated on the PR over the next 13 months until it was finally merged for Django 6.0. Thanks to Rob for his heroic dedication here, and to all reviewers: Benjamin Balder Bach, Carlton Gibson, Collin Anderson, David Sanders, David Smith, Florian Apolloner, Harro van der Klauw, Jake Howard, Natalia Bidart, Paolo Melchiorre, Sarah Boyce, and SÃ©bastien Corbin.&lt;/p&gt;
    &lt;head rend="h2"&gt;Email API updates&lt;/head&gt;
    &lt;p&gt;The fourth and final headline feature:&lt;/p&gt;
    &lt;code&gt;Email handling in Django now uses Pythonâs modern email API, introduced in Python 3.6. This API, centered around the  email.message.EmailMessage class, offers a cleaner and Unicode-friendly interface for composing and sending emails.&lt;/code&gt;
    &lt;p&gt;This is a major change, but itâs unlikely to affect projects using basic email features. You can still use Djangoâs &lt;code&gt;send_mail()&lt;/code&gt; function and &lt;code&gt;EmailMessage&lt;/code&gt; class as before, like:&lt;/p&gt;
    &lt;code&gt;from django.core.mail import EmailMessage

email = EmailMessage(
    subject="ð¼ Need more bamboo",
    body="We are desperately low, please restock before the pandas find out!",
    from_email="zookeeper@example.com",
    to=["supplies@example.com"],
)
email.attach_file("/media/bamboo_cupboard.jpg")
email.send()
&lt;/code&gt;
    &lt;p&gt;The key change is that, under-the-hood, when you call &lt;code&gt;send()&lt;/code&gt; on a Django &lt;code&gt;EmailMessage&lt;/code&gt; object, it now translates itself into a Pythonâs newer &lt;code&gt;email.message.EmailMessage&lt;/code&gt; type before sending.&lt;/p&gt;
    &lt;p&gt;Modernizing provides these benefits:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Fewer bugs - many edge case bugs in Pythonâs old email API have been fixed in the new one.&lt;/item&gt;
      &lt;item&gt;Django is less hacky - a bunch of workarounds and security fixes in Djangoâs email code have been removed.&lt;/item&gt;
      &lt;item&gt;More convenient API - the new API supports some niceties, like the below inline attachment example.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Easier inline attachments with &lt;code&gt;MIMEPart&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;Djangoâs &lt;code&gt;EmailMessage.attach()&lt;/code&gt; method allows you to attach a file as an attachment. Emails support images as inline attachments, which can be displayed within the HTML email body.&lt;/p&gt;
    &lt;p&gt;While you could previously use &lt;code&gt;EmailMessage.attach()&lt;/code&gt; to add inline attachments, it was a bit fiddly, using a legacy class. Now, you can call the method with a Python &lt;code&gt;email.message.MIMEPart&lt;/code&gt; object to add an inline attachment in a few steps:&lt;/p&gt;
    &lt;code&gt;import email.utils
from email.message import MIMEPart
from django.core.mail import EmailMultiAlternatives

message = EmailMultiAlternatives(
    subject="Cute Panda Alert",
    body="Here's a cute panda picture for you!",
    from_email="cute@example.com",
    to=["fans@example.com"],
)
with open("panda.jpg", "rb") as f:
    panda_jpeg = f.read()

cid = email.utils.make_msgid()
inline_image = MIMEPart()
inline_image.set_content(
    panda_jpeg,
    maintype="image",
    subtype="jpeg",
    disposition="inline",
    cid=cid,
)
message.attach(inline_image)
message.attach_alternative(
    f'&amp;lt;h1&amp;gt;Cute panda baby alert!&amp;lt;/h1&amp;gt;&amp;lt;img src="cid:{cid[1:-1]}"&amp;gt;',
    "text/html",
)
&lt;/code&gt;
    &lt;p&gt;Itâs not the simplest API, but it does expose all the power of the underlying email system, and itâs better than the past situation.&lt;/p&gt;
    &lt;head rend="h3"&gt;History&lt;/head&gt;
    &lt;p&gt;The new email API was added to Python as provisional in version 3.4 (2014), and made stable in version 3.6 (2016). The legacy API, however, was never planned for deprecation, so there was never any deadline to upgrade Djangoâs email handling.&lt;/p&gt;
    &lt;p&gt;In 2024, Mike Edmunds posted on the (old) django-developers mailing list, proposing the upgrade with strong reasoning and planning. This conversation led to Ticket #35581, which he worked on for eight months until it was merged. Many thanks to Mike for leading this effort, and to Sarah Boyce for reviewing! Email is not a glamorous feature, but itâs a critical communication channel for nearly every Django project, so props for this.&lt;/p&gt;
    &lt;head rend="h2"&gt;Positional arguments in &lt;code&gt;django.core.mail&lt;/code&gt; APIs&lt;/head&gt;
    &lt;p&gt;Weâre now out of the headline features and onto the âminorâ changes, starting with this deprecation related to the above email changes:&lt;/p&gt;
    &lt;quote&gt;&lt;code&gt;django.core.mail&lt;/code&gt;APIs now require keyword arguments for less commonly used parameters. Using positional arguments for these now emits a deprecation warning and will raise a&lt;code&gt;TypeError&lt;/code&gt;when the deprecation period ends:&lt;item&gt;All optional parameters (&lt;/item&gt;&lt;code&gt;fail_silently&lt;/code&gt;and later) must be passed as keyword arguments to&lt;code&gt;get_connection()&lt;/code&gt;,&lt;code&gt;mail_admins()&lt;/code&gt;,&lt;code&gt;mail_managers()&lt;/code&gt;,&lt;code&gt;send_mail()&lt;/code&gt;, and&lt;code&gt;send_mass_mail()&lt;/code&gt;.&lt;item&gt;All parameters must be passed as keyword arguments when creating an&lt;/item&gt;&lt;code&gt;EmailMessage&lt;/code&gt;or&lt;code&gt;EmailMultiAlternatives&lt;/code&gt;instance, except for the first four (&lt;code&gt;subject&lt;/code&gt;,&lt;code&gt;body&lt;/code&gt;,&lt;code&gt;from_email&lt;/code&gt;, and&lt;code&gt;to&lt;/code&gt;), which may still be passed either as positional or keyword arguments.&lt;/quote&gt;
    &lt;p&gt;Previously, Django would let you pass all parameters positionally, which gets a bit silly and hard to read with long parameter lists, like:&lt;/p&gt;
    &lt;code&gt;from django.core.mail import send_mail

send_mail(
    "ð¼ Panda of the week",
    "This weekâs panda is Po Ping, sha-sha booey!",
    "updates@example.com",
    ["adam@example.com"],
    True,
)
&lt;/code&gt;
    &lt;p&gt;The final &lt;code&gt;True&lt;/code&gt; doesnât provide any clue what it means without looking up the function signature. Now, using positional arguments for those less-commonly-used parameters raises a deprecation warning, nudging you to write:&lt;/p&gt;
    &lt;code&gt;from django.core.mail import send_mail

send_mail(
    subject="ð¼ Panda of the week",
    body="This weekâs panda is Po Ping, sha-sha booey!",
    from_email="updates@example.com",
    ["adam@example.com"],
    fail_silently=True,
)
&lt;/code&gt;
    &lt;p&gt;This change is appreciated for API clarity, and Django is generally moving towards using keyword-only arguments more often. django-upgrade can automatically fix this one for you, via its &lt;code&gt;mail_api_kwargs&lt;/code&gt; fixer.&lt;/p&gt;
    &lt;p&gt;Thanks to Mike Edmunds, again, for making this improvement in Ticket #36163.&lt;/p&gt;
    &lt;head rend="h2"&gt;Extended automatic &lt;code&gt;shell&lt;/code&gt; imports&lt;/head&gt;
    &lt;p&gt;Next up:&lt;/p&gt;
    &lt;quote&gt;Common utilities, such as django.conf.settings, are now automatically imported to the shell by default.&lt;/quote&gt;
    &lt;p&gt;One of the headline features back in Django 5.2 was automatic model imports in the shell, making &lt;code&gt;./manage.py shell&lt;/code&gt; import all of your models automatically. Building on that DX boost, Django 6.0 now also imports other common utilities, for which we can find the full list by running &lt;code&gt;./manage.py shell&lt;/code&gt; with &lt;code&gt;-v 2&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;$ ./manage.py shell -v 2
6 objects imported automatically:

  from django.conf import settings
  from django.db import connection, models, reset_queries
  from django.db.models import functions
  from django.utils import timezone

...
&lt;/code&gt;
    &lt;p&gt;(This is from a project without any models, so only the utilities are listed.)&lt;/p&gt;
    &lt;p&gt;So thatâs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;settings&lt;/code&gt;, useful for checking your runtime configuration:&lt;quote&gt;In [1]: settings.DEBUG Out[1]: False&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;connection&lt;/code&gt;and&lt;code&gt;reset_queries()&lt;/code&gt;, great for checking the executed queries:&lt;quote&gt;In [1]: Book.objects.select_related('author') Out[1]: &amp;lt;QuerySet []&amp;gt; In [2]: connection.queries Out[2]: [{'sql': 'SELECT "example_book"."id", "example_book"."title", "example_book"."author_id", "example_author"."id", "example_author"."name" FROM "example_book" INNER JOIN "example_author" ON ("example_book"."author_id" = "example_author"."id") LIMIT 21', 'time': '0.000'}]&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;models&lt;/code&gt;and&lt;code&gt;functions&lt;/code&gt;, useful for advanced ORM work:&lt;quote&gt;In [1]: Book.objects.annotate( ...: title_lower=functions.Lower("title") ...: ).filter( ...: title_lower__startswith="a" ...: ).count() Out[1]: 71&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;timezone&lt;/code&gt;, useful for using Djangoâs timezone-aware date and time utilities:&lt;quote&gt;In [1]: timezone.now() Out[1]: datetime.datetime(2025, 12, 1, 23, 42, 22, 558418, tzinfo=datetime.timezone.utc)&lt;/quote&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It remains possible to extend the automatic imports with whatever youâd like, as documented in How to customize the &lt;code&gt;shell&lt;/code&gt; command documentation page.&lt;/p&gt;
    &lt;p&gt;Salvo Polizzi contributed the original automatic shell imports feature in Django 5.2. Heâs then returned to offer these extra imports for Django 6.0, in Ticket #35680. Thanks to everyone that contributed to the forum discussion agreeing on which imports to add, and to Natalia Bidart and Sarah Boyce for reviewing!&lt;/p&gt;
    &lt;head rend="h2"&gt;Dynamic field refresh on &lt;code&gt;save()&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;Now letâs discuss a series of ORM improvements, starting with this big one:&lt;/p&gt;
    &lt;quote&gt;&lt;code&gt;GeneratedField&lt;/code&gt;s and fields assigned expressions are now refreshed from the database after&lt;code&gt;save()&lt;/code&gt;on backends that support the&lt;code&gt;RETURNING&lt;/code&gt;clause (SQLite, PostgreSQL, and Oracle). On backends that donât support it (MySQL and MariaDB), the fields are marked as deferred to trigger a refresh on subsequent accesses.&lt;/quote&gt;
    &lt;p&gt;Django models support having the database generate field values for you in three cases:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;db_default&lt;/code&gt;field option, which lets the database generate the default value when creating an instance:&lt;quote&gt;from django.db import models from django.db.models.functions import Now class Video(models.Model): ... created = models.DateTimeField(db_default=Now())&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;GeneratedField&lt;/code&gt;field type, which is always computed by the database based on other fields in the same instance:&lt;quote&gt;from django.db import models from django.db.models.functions import Concat class Video(models.Model): ... full_title = models.GeneratedField( models.TextField(), expression=Concat( "title", models.Value(" - "), "subtitle", ), )&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Assigning expression values to fields before saving:&lt;/p&gt;
        &lt;quote&gt;from django.db import models from django.db.models.functions import Now class Video(models.Model): ... last_updated = models.DateTimeField() video = Video.objects.get(id=1) ... video.last_updated = Now() video.save()&lt;/quote&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Previously, only the first method, using &lt;code&gt;db_default&lt;/code&gt;, would refresh the field value from the database after saving. The other two methods would leave you with only the old value or the expression object, meaning youâd need to call &lt;code&gt;Model.refresh_from_db()&lt;/code&gt; to get any updated value if necessary. This was hard to remember and it costs an extra database query.&lt;/p&gt;
    &lt;p&gt;Now Django takes advantage of the &lt;code&gt;RETURNING&lt;/code&gt; SQL clause to save the model instance and fetch updated dynamic field values in a single query, on backends that support it (SQLite, PostgreSQL, and Oracle). A &lt;code&gt;save()&lt;/code&gt; call may now issue a query like:&lt;/p&gt;
    &lt;code&gt;UPDATE "example_video"
SET "last_updated" = NOW()
WHERE "example_video"."id" = 1
RETURNING "example_video"."last_updated"
&lt;/code&gt;
    &lt;p&gt;Django puts the return value into the model field, so you can read it immediately after saving:&lt;/p&gt;
    &lt;code&gt;video = Video.objects.get(id=1)
...
video.last_updated = Now()
video.save()
print(video.last_updated)  # Updated value from the database
&lt;/code&gt;
    &lt;p&gt;On backends that donât support &lt;code&gt;RETURNING&lt;/code&gt; (MySQL and MariaDB), Django now marks the dynamic fields as deferred after saving. That way, the later access, as in the above example, will automatically call &lt;code&gt;Model.refresh_from_db()&lt;/code&gt;. This ensures that you always read the updated value, even if it costs an extra query.&lt;/p&gt;
    &lt;head rend="h3"&gt;History&lt;/head&gt;
    &lt;p&gt;This feature was proposed in Ticket #27222 way back in 2016, by Anssi KÃ¤Ã¤riÃ¤inen. It sat dormant for most of the nine years since, but ORM boss Simon Charette picked it up earlier this year, found an implementation, and pushed it through to completion. Thanks to Simon for continuing to push the ORM forward, and to all reviewers: David Sanders, Jacob Walls, Mariusz Felisiak, nessita, Paolo Melchiorre, Simon Charette, and Tim Graham.&lt;/p&gt;
    &lt;head rend="h2"&gt;Universal &lt;code&gt;StringAgg&lt;/code&gt; aggregate&lt;/head&gt;
    &lt;p&gt;The next ORM change:&lt;/p&gt;
    &lt;quote&gt;The new&lt;code&gt;StringAgg&lt;/code&gt;aggregate returns the input values concatenated into a string, separated by the&lt;code&gt;delimiter&lt;/code&gt;string. This aggregate was previously supported only for PostgreSQL.&lt;/quote&gt;
    &lt;p&gt;This aggregate is often used for making comma-separated lists of related items, among other things. Previously, it was only supported on PostgreSQL, as part of &lt;code&gt;django.contrib.postgres&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;from django.contrib.postgres.aggregates import StringAgg
from example.models import Video

videos = Video.objects.annotate(
    chapter_ids=StringAgg("chapter", delimiter=","),
)

for video in videos:
    print(f"Video {video.id} has chapters: {video.chapter_ids}")
&lt;/code&gt;
    &lt;p&gt;â¦which might give you output like:&lt;/p&gt;
    &lt;code&gt;Video 104 has chapters: 71,72,74
Video 107 has chapters: 88,89,138,90,91,93
&lt;/code&gt;
    &lt;p&gt;Now this aggregate is available on all database backends supported by Django, imported from &lt;code&gt;django.db.models&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;from django.db.models import StringAgg, Value
from example.models import Video

videos = Video.objects.annotate(
    chapter_ids=StringAgg("chapter", delimiter=Value(",")),
)

for video in videos:
    print(f"Video {video.id} has chapters: {video.chapter_ids}")
&lt;/code&gt;
    &lt;p&gt;Note the &lt;code&gt;delimiter&lt;/code&gt; argument now requires a &lt;code&gt;Value()&lt;/code&gt; expression wrapper for literal strings, as above. This change allows you to use database functions or fields as the delimiter if desired.&lt;/p&gt;
    &lt;p&gt;While most Django projects stick to PostgreSQL, having this aggregate available on all backends is a nice improvement for cross-database compatibility, and it means third-party packages can use it without affecting their database support.&lt;/p&gt;
    &lt;head rend="h3"&gt;History&lt;/head&gt;
    &lt;p&gt;The PostgreSQL-specific &lt;code&gt;StringAgg&lt;/code&gt; was added way back in Django 1.9 (2015) by Andriy Sokolovskiy, in Ticket #24301. In Ticket #35444, Chris Muthig proposed adding the &lt;code&gt;Aggregate.order_by&lt;/code&gt; option, something used by &lt;code&gt;StringAgg&lt;/code&gt; to specify the ordering of concatenated elements, and as a side effect this made it possible to generalize &lt;code&gt;StringAgg&lt;/code&gt; to all backends.&lt;/p&gt;
    &lt;p&gt;Thanks to Chris for proposing and implementing this change, and to all reviewers: Paolo Melchiorre, Sarah Boyce, and Simon Charette.&lt;/p&gt;
    &lt;head rend="h2"&gt;&lt;code&gt;BigAutoField&lt;/code&gt; as the default primary key type&lt;/head&gt;
    &lt;p&gt;Next up:&lt;/p&gt;
    &lt;quote&gt;&lt;code&gt;DEFAULT_AUTO_FIELD&lt;/code&gt;setting now defaults to&lt;code&gt;BigAutoField&lt;/code&gt;&lt;/quote&gt;
    &lt;p&gt;This important change helps lock in scalable larger primary keys.&lt;/p&gt;
    &lt;p&gt;Django 3.2 (2021) introduced the &lt;code&gt;DEFAULT_AUTO_FIELD&lt;/code&gt; setting for changing the default primary key type used in models. Django uses this setting to add a primary key field called &lt;code&gt;id&lt;/code&gt; to models that donât explicitly define a primary key field. For example, if you define a model like this:&lt;/p&gt;
    &lt;code&gt;from django.db import models


class Video(models.Model):
    title = models.TextField()
&lt;/code&gt;
    &lt;p&gt;â¦then it will have two fields: &lt;code&gt;id&lt;/code&gt; and &lt;code&gt;title&lt;/code&gt;, where &lt;code&gt;id&lt;/code&gt; uses the type defined by &lt;code&gt;DEFAULT_AUTO_FIELD&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The setting can also be overridden on a per-app basis by defining &lt;code&gt;AppConfig.default_auto_field&lt;/code&gt; in the appâs &lt;code&gt;apps.py&lt;/code&gt; file:&lt;/p&gt;
    &lt;code&gt;from django.apps import AppConfig


class ChannelConfig(AppConfig):
    name = "channel"
    default_auto_field = "django.db.models.BigAutoField"
&lt;/code&gt;
    &lt;p&gt;A key motivation for adding the setting was to allow projects to switch from &lt;code&gt;AutoField&lt;/code&gt; (a 32-bit integer) to &lt;code&gt;BigAutoField&lt;/code&gt; (a 64-bit integer) for primary keys, without needing changes to every model. &lt;code&gt;AutoField&lt;/code&gt; can store values up to about 2.1 billion, which sounds large but it becomes easy to hit at scale. &lt;code&gt;BigAutoField&lt;/code&gt; can store values up to about 9.2 quintillion, which is âmore than enoughâ for every practical purpose.&lt;/p&gt;
    &lt;p&gt;If a model using &lt;code&gt;AutoField&lt;/code&gt; hits its maximum value, it can no longer accept new rows, a problem known as primary key exhaustion. The table is effectively blocked, requiring an urgent fix to switch the model from &lt;code&gt;AutoField&lt;/code&gt; to &lt;code&gt;BigAutoField&lt;/code&gt; via a locking database migration on a large table. For a great watch on how Kraken is fixing this problem, see Tim Bellâs DjangoCon Europe 2025 talk, detailing some clever techniques to proactively migrate large tables with minimal downtime.&lt;/p&gt;
    &lt;p&gt;To stop this problem arising for new projects, Django 3.2 made new projects created with &lt;code&gt;startproject&lt;/code&gt; set &lt;code&gt;DEFAULT_AUTO_FIELD&lt;/code&gt; to &lt;code&gt;BigAutoField&lt;/code&gt;, and new apps created with &lt;code&gt;startapp&lt;/code&gt; set their &lt;code&gt;AppConfig.default_auto_field&lt;/code&gt; to &lt;code&gt;BigAutoField&lt;/code&gt;. It also added a system check to ensure that projects set &lt;code&gt;DEFAULT_AUTO_FIELD&lt;/code&gt; explicitly, to ensure users were aware of the feature and could make an informed choice.&lt;/p&gt;
    &lt;p&gt;Now Django 6.0 changes the actual default values of the setting and app config attribute to &lt;code&gt;BigAutoField&lt;/code&gt;. Projects using &lt;code&gt;BigAutoField&lt;/code&gt; can remove the setting:&lt;/p&gt;
    &lt;code&gt;-DEFAULT_AUTO_FIELD = "django.db.models.BigAutoField"
&lt;/code&gt;
    &lt;p&gt;â¦and app config attribute:&lt;/p&gt;
    &lt;code&gt;from django.apps import AppConfig

 class ChannelConfig(AppConfig):
     name = "channel"
-    default_auto_field = "django.db.models.BigAutoField"
&lt;/code&gt;
    &lt;p&gt;The default &lt;code&gt;startproject&lt;/code&gt; and &lt;code&gt;startapp&lt;/code&gt; templates also no longer set these values. This change reduces the amount of boilerplate in new projects, and the problem of primary key exhaustion can fade into history, becoming something that most Django users no longer need to think about.&lt;/p&gt;
    &lt;head rend="h3"&gt;History&lt;/head&gt;
    &lt;p&gt;The addition of &lt;code&gt;DEFAULT_AUTO_FIELD&lt;/code&gt; in Django 3.2 was proposed by Caio Ariede and implemented by Tom Forbes, in Ticket #31007. This new change in Django 6.0 was proposed and implemented by ex-Fellow Tim Graham, in Ticket #36564. Thanks to Tim for spotting that this cleanup was now possible, and to Jacob Walls and Clifford Gama for reviewing!&lt;/p&gt;
    &lt;head rend="h2"&gt;Template variable &lt;code&gt;forloop.length&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;Moving on to templates, letâs start with this nice little addition:&lt;/p&gt;
    &lt;quote&gt;The new variable forloop.length is now available within a for loop.&lt;/quote&gt;
    &lt;p&gt;This small extension makes it possible to write a template loop like this:&lt;/p&gt;
    &lt;code&gt;&amp;lt;ul&amp;gt;
  {% for goose in geese %}
    &amp;lt;li&amp;gt;
      &amp;lt;strong&amp;gt;{{ forloop.counter }}/{{ forloop.length }}&amp;lt;/strong&amp;gt;: {{ goose.name }}
    &amp;lt;/li&amp;gt;
  {% endfor %}
&amp;lt;/ul&amp;gt;
&lt;/code&gt;
    &lt;p&gt;Previously, youâd need to refer to the length in an another way, like &lt;code&gt;{{ geese|length }}&lt;/code&gt;, which is a bit less flexible.&lt;/p&gt;
    &lt;p&gt;Thanks to Jonathan StrÃ¶bele for contributing this idea and implementation in Ticket #36186, and to David Smith, Paolo Melchiorre, and Sarah Boyce for reviewing.&lt;/p&gt;
    &lt;head rend="h2"&gt;&lt;code&gt;querystring&lt;/code&gt; template tag enhancements&lt;/head&gt;
    &lt;p&gt;There are two extensions to the &lt;code&gt;querystring&lt;/code&gt; template tag, which was added in Django 5.1 to help with building links that modify the current requestâs query parameters.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Release note:&lt;/p&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;querystring&lt;/code&gt;template tag now consistently prefixes the returned query string with a&lt;code&gt;?&lt;/code&gt;, ensuring reliable link generation behavior.&lt;p&gt;This small change improves how the tag behaves when an empty mapping of query parameters are provided. Say you had a template like this:&lt;/p&gt;&lt;quote&gt;&amp;lt;a href="{% querystring params %}"&amp;gt;Reset search&amp;lt;/a&amp;gt;&lt;/quote&gt;&lt;p&gt;â¦where&lt;/p&gt;&lt;code&gt;params&lt;/code&gt;is a dictionary that may sometimes be empty. Previously, if&lt;code&gt;params&lt;/code&gt;was empty, the output would be:&lt;quote&gt;&amp;lt;a href=""&amp;gt;Reset search&amp;lt;/a&amp;gt;&lt;/quote&gt;&lt;p&gt;Browsers treat this as a link to the same URL including the query parameters, so it would not clear the query parameters as intended. Now, with this change, the output will be:&lt;/p&gt;&lt;quote&gt;&amp;lt;a href="?"&amp;gt;Reset search&amp;lt;/a&amp;gt;&lt;/quote&gt;&lt;p&gt;Browsers treat&lt;/p&gt;&lt;code&gt;?&lt;/code&gt;as a link to the same URL without any query parameters, clearing them as the user would expect.&lt;p&gt;Thanks to Django Fellow Sarah Boyce for spotting this improvement and implementing the fix in Ticket #36268, and for Django Fellow Natalia Bidart for reviewing!&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Release note:&lt;/p&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;querystring&lt;/code&gt;template tag now accepts multiple positional arguments, which must be mappings, such as&lt;code&gt;QueryDict&lt;/code&gt;or&lt;code&gt;dict&lt;/code&gt;.&lt;p&gt;This enhancement allows the tag to merge multiple sources of query parameters when building the output. For example, you might have a template like this:&lt;/p&gt;&lt;quote&gt;&amp;lt;a href="{% querystring request.GET super_search_params %}"&amp;gt;Super search&amp;lt;/a&amp;gt;&lt;/quote&gt;&lt;p&gt;â¦where&lt;/p&gt;&lt;code&gt;super_search_params&lt;/code&gt;is a dictionary of extra parameters to add to make the current search âsuperâ. The tag merges the two mappings, with later mappings taking precedence for duplicate keys.&lt;p&gt;Thanks again to Sarah Boyce for proposing this improvement in Ticket #35529, to Giannis Terzopoulos for implementing it, and to Natalia Bidart, Sarah Boyce, and Tom Carrick for reviewing!&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Fin&lt;/head&gt;
    &lt;p&gt;Thatâs a wrap! Thank you for reading my highlights. There are plenty more changes to read about in the release notes.&lt;/p&gt;
    &lt;p&gt;Also, there are always many more behind-the-scenes improvements and bug fixes that donât make it into the release notes. Optimizations and micro-improvements get merged all the time, so donât delay, upgrade today!&lt;/p&gt;
    &lt;p&gt;Thank you to all 174 people who contributed to Django 6.0, as counted in this list by Mariusz Felisiak.&lt;/p&gt;
    &lt;p&gt;May your upgrade be swift, smooth, safe, and secure,&lt;/p&gt;
    &lt;p&gt;âAdam&lt;/p&gt;
    &lt;p&gt;ð¸ð¸ð¸ Check out my new book on using GitHub effectively, Boost Your GitHub DX! ð¸ð¸ð¸&lt;/p&gt;
    &lt;p&gt;One summary email a week, no spam, I pinky promise.&lt;/p&gt;
    &lt;p&gt;Related posts:&lt;/p&gt;
    &lt;p&gt;Tags: django&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46210240</guid><pubDate>Tue, 09 Dec 2025 20:33:14 +0000</pubDate></item><item><title>Qt, Linux and everything: Debugging Qt WebAssembly</title><link>http://qtandeverything.blogspot.com/2025/12/debugging-qt-webassembly-dwarf.html</link><description>&lt;doc fingerprint="ef121c580b3130e5"&gt;
  &lt;main&gt;
    &lt;p&gt;One of the most tedious tasks a developer will do is debugging a nagging bug. It's worse when it's a web app, and even worse when its a webassembly web app.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;The easiest way to debug Qt Webassembly is by configuring using the -g argument, or CMAKE_BUILD_TYPE=Debug . Emscripten embeds DWARF symbols in the wasm binaries. &lt;/p&gt;
    &lt;p&gt;NOTE: Debugging wasm files with DWARF works only in the Chrome browser with the help of a browser extension.&lt;/p&gt;
    &lt;p&gt;C/C++ DevTools Support (DWARF) browser extension. If you are using Safari or Firefox, or do not want to or cannot install a browser extension, you will need to generate source maps, which I will look at in my next blog post.&lt;/p&gt;
    &lt;head rend="h3"&gt;DWARF debugging&lt;/head&gt;
    &lt;p&gt;You need to also enable DWARF in the browser developer tools settings, but you do not need symlinks to the source directories, as you would need to using source maps, as the binaries are embedded with the full directory path. Like magic!&lt;/p&gt;
    &lt;p&gt;Emscripten embeds DWARF symbols into the binaries built with -g by default, so re-building Qt or your application in debug mode is all you need to do.&lt;/p&gt;
    &lt;p&gt;Qt builds debug libraries by default using the optimized argument -g2, which produces less debugging info, but results in faster link times. To preserve debug symbols you need to build Qt debug using the -g or -g3 argument. Both of these do the same thing.&lt;/p&gt;
    &lt;head rend="h3"&gt;Using DWARF debugger&lt;/head&gt;
    &lt;p&gt;You can then step though your code as you would debugging a desktop application.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46210806</guid><pubDate>Tue, 09 Dec 2025 21:19:37 +0000</pubDate></item><item><title>Linux CVEs, more than you ever wanted to know</title><link>http://www.kroah.com/log/blog/2025/12/08/linux-cves-more-than-you-ever-wanted-to-know/</link><description>&lt;doc fingerprint="d713115f51c1b7bb"&gt;
  &lt;main&gt;
    &lt;p&gt;It’s been almost 2 full years since Linux became a CNA (Certificate Numbering Authority) which meant that we (i.e. the kernel.org community) are now responsible for issuing all CVEs for the Linux kernel. During this time, we’ve become one of the largest creators of CVEs by quantity, going from nothing to number 3 in 2024 to number 1 in 2025. Naturally, this has caused some questions about how we are both doing all of this work, and how people can keep track of it.&lt;/p&gt;
    &lt;p&gt;I’ve given a number of talks over the past years about this, starting with the Open Source security podcast right after we became a CNA and then the Kernel Recipes 2024 talk, “CVEs are alive, but do not panic” and then a talk at OSS Hong Kong 2024 about the same topic with updated numbers and later a talk at OSS Japan 2024 with more info about the same topic and finally for 2024 a talk with more detail that I can’t find the online version.&lt;/p&gt;
    &lt;p&gt;In 2025 I did lots of work on the CRA so most of my speaking over this year has been about that topic , but the CVE assignment work continued on, evolving to meet many of the issues we had in our first year of being a CNA. As that work is not part of the Linux kernel source directly, it’s not all that visable to the normal development process, except for the constant feed on the linux-cve-announce mailing list I figured it was time to write down how this is all now working, as well a bunch of background information about how Linux is developed that is relevant for how we do CVE reporting (i.e. almost all non-open-source-groups don’t seem to know how to grasp our versioning scheme.)&lt;/p&gt;
    &lt;p&gt;There is a in-kernel document that describes how CVEs can be asked for from the kernel community, as well as a basic summary of how CVEs are automatically asigned. But as we are an open community, it’s good to go into more detail as to how all of us do this work, explaining how our tools have evolved over time and how they work, why some things are the way they are for our releases, as well as document a way that people can track CVE assignments on their own in a format that is, in my opinion, much simpler than attempting to rely on the CVE json format (and don’t get me started on NVD…)&lt;/p&gt;
    &lt;p&gt;So here’s a series of posts going into all of this, hopefully providing more information than you ever wanted to know, which might be useful for other open source projects as they start to run into many of the same issues we have already dealt with (i.e. how to handle reports at scale):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Linux kernel versions, how the Linux kernel releases are numbered.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46211802</guid><pubDate>Tue, 09 Dec 2025 22:47:36 +0000</pubDate></item><item><title>OpenEvolve: Teaching LLMs to Discover Algorithms Through Evolution</title><link>https://algorithmicsuperintelligence.ai/blog/openevolve-overview/index.html</link><description>&lt;doc fingerprint="dd8ca0ba8fb27bdb"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;OpenEvolve: Teaching LLMs to Discover Algorithms Through Evolution&lt;/head&gt;
    &lt;p&gt;How do we teach machines to discover algorithms? Traditional approaches rely on hand-crafted heuristics, exhaustive search, or gradient-based optimization. But what if we could harness the creative potential of large language models (LLMs) within an evolutionary framework?&lt;/p&gt;
    &lt;p&gt;OpenEvolve is an open-source evolutionary coding agent that integrates large language models into a quality-diversity search framework for algorithm discovery. Candidate programs are produced via LLM-guided edits (diff-based by default), evaluated with user-defined metrics, and organized using MAP-Elites while an island model with migration supports parallel, diversified exploration. The evaluation pipeline supports cascade staging and an artifact side-channel that feeds execution traces and errors back into subsequent prompts; optional LLM-based feedback can be incorporated into scoring.&lt;/p&gt;
    &lt;p&gt;OpenEvolve has been applied across many domains—here are a few examples: systems optimization, scientific discovery, geospatial algorithms, scaling law discovery, GPU kernel optimization, prompt optimization, and more.&lt;/p&gt;
    &lt;head rend="h2"&gt;Architecture Overview&lt;/head&gt;
    &lt;head rend="h3"&gt;The Evolution Loop&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Prompt Sampler: Constructs context-rich prompts by selecting a parent program from the current island and curating evidence sets (top performers by fitness, lineage ancestors, diverse extremes across feature bins, and random samples). Prompts include the parent's code, evaluation metrics, feature coordinates for MAP-Elites, evolution history, and (optionally) execution artifacts. Template selection supports diff-based editing by default or full rewrites, with controlled stochasticity.&lt;/item&gt;
      &lt;item&gt;LLM Ensemble: Generates candidate code using a weighted ensemble of OpenAI-compatible models (deterministic under seeds). In standard mode, a model is sampled by weight; in model-based islands, each island uses a fixed model. Responses drive either diff-based edits (SEARCH/REPLACE blocks) or full rewrites (JSON/code-block extraction), with generation parameters drawn from configuration.&lt;/item&gt;
      &lt;item&gt;Evaluator: Executes the user-provided &lt;code&gt;evaluate(program_path)&lt;/code&gt;with timeouts and retries; optionally applies cascade evaluation (&lt;code&gt;evaluate_stage1/2/3&lt;/code&gt;) with thresholds to filter weak candidates early. It can incorporate LLM-based feedback into metrics and captures artifacts (e.g., stderr, tracebacks) for subsequent prompt context. Parallel evaluations are supported via an internal task pool.&lt;/item&gt;
      &lt;item&gt;Program Database: Implements MAP-Elites per island, binning programs along configurable feature dimensions (defaults include complexity and diversity; custom dimensions are taken from evaluator metrics). New candidates replace cell occupants when fitness improves (preferring &lt;code&gt;combined_score&lt;/code&gt;, otherwise a safe numeric aggregate excluding feature dimensions). The database enforces population limits, tracks the global best, logs prompts, supports migration, and persists checkpoints.&lt;/item&gt;
      &lt;item&gt;Controller: Orchestrates the loop, including seeding, logging, prompt/evaluator initialization, and process-based parallel execution. It schedules iterations across islands, manages checkpointing and resume, enforces early stopping/target score criteria, stores artifacts, and writes the best discovered program and its metadata to the output directory.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Key Algorithmic Innovations&lt;/head&gt;
    &lt;head rend="h3"&gt;Island-Based Evolution with Lazy Migration&lt;/head&gt;
    &lt;p&gt;OpenEvolve maintains multiple isolated populations (islands) that evolve independently to reduce premature convergence and enable parallel exploration. Migration is event-driven: each island migrates when its per-island program additions since the last migration reach a configured interval, rather than on wall-clock time. Migration follows a ring topology by default (optional random migration), transferring a fraction of top programs while avoiding duplicate code in the destination island.&lt;/p&gt;
    &lt;code&gt;# Configuration example
database:
  num_islands: 5
  migration_interval: 20   # generations, not iterations
  migration_rate: 0.1      # 10% of top programs migrate&lt;/code&gt;
    &lt;head rend="h3"&gt;MAP-Elites for Diversity Preservation&lt;/head&gt;
    &lt;p&gt;Each island maintains a MAP-Elites grid over configurable feature dimensions (defaults include complexity and diversity; additional dimensions can be supplied by the evaluator). A candidate occupies or replaces the cell if it improves fitness (preferring &lt;code&gt;combined_score&lt;/code&gt;, otherwise a safe aggregate over numeric metrics excluding feature dimensions). This enforces one elite per cell and preserves quality-diversity. The system also avoids exact duplicates (e.g., during migration) and computes diversity using structural measures (e.g., edit distance), rather than relying on code embeddings.&lt;/p&gt;
    &lt;head rend="h3"&gt;Cascade Evaluation&lt;/head&gt;
    &lt;p&gt;Evaluation proceeds in stages with configurable thresholds. If cascade functions are provided, Stage 1 performs fast checks (e.g., import/execute), Stage 2 runs lightweight tests, and Stage 3 executes comprehensive benchmarks. Candidates must meet stage thresholds to advance. Timeouts and exceptions are captured as artifacts and can be fed back into subsequent prompts. When cascade functions are not defined, evaluation falls back to a single-stage &lt;code&gt;evaluate(program_path)&lt;/code&gt; with timeouts and retries.&lt;/p&gt;
    &lt;head rend="h3"&gt;Double-Selection Strategy&lt;/head&gt;
    &lt;p&gt;Parent selection is biased toward high-fitness programs, while inspiration material shown to the LLM is drawn from complementary sources (top programs, lineage ancestors, diverse extremes across feature bins, and random samples). This separation encourages improvements guided by the current best while maintaining exploration pressure via diverse exemplars, implemented through prompt construction rather than direct recombination.&lt;/p&gt;
    &lt;head rend="h2"&gt;Sample Use Cases&lt;/head&gt;
    &lt;head rend="h3"&gt;Example 1: Algorithmic Discovery&lt;/head&gt;
    &lt;p&gt;On the AlgoTune benchmark, OpenEvolve discovered algorithms achieving dramatic speedups through automatic optimization:&lt;/p&gt;
    &lt;p&gt;Key breakthroughs include automatic discovery of JAX JIT compilation (321x), FFT-based convolution (256x), and optimized graph algorithms (95.78x). The system evolved from simple iterative implementations to sophisticated numerical computing patterns without human intervention. For more detailed analysis, see Towards Open Evolutionary Agents.&lt;/p&gt;
    &lt;head rend="h3"&gt;Example 2: Circle Packing&lt;/head&gt;
    &lt;p&gt;OpenEvolve matched state-of-the-art results (2.634 sum of radii for n=26), evolving from naive geometric constructions to discovering scipy.optimize with SLSQP—a completely different algorithmic approach than the initial solution.&lt;/p&gt;
    &lt;head rend="h3"&gt;Example 3: GPU Kernel Optimization&lt;/head&gt;
    &lt;p&gt;Evolution of Metal GPU kernels for transformer attention on Apple Silicon:&lt;/p&gt;
    &lt;p&gt;OpenEvolve discovered several non-obvious optimizations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;8-element SIMD vectorization matching Apple Silicon's hardware width&lt;/item&gt;
      &lt;item&gt;Two-pass online softmax reducing memory bandwidth&lt;/item&gt;
      &lt;item&gt;GQA-specific memory layouts exploiting head structure&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These optimizations maintain 100% numerical accuracy while achieving measurable performance improvements across diverse inference scenarios. For more details, see GPU Kernel Discovery.&lt;/p&gt;
    &lt;head rend="h3"&gt;Example 4: LLM Prompt Optimization&lt;/head&gt;
    &lt;p&gt;Beyond code, OpenEvolve can evolve prompts themselves:&lt;/p&gt;
    &lt;p&gt;On GEPA benchmarks, evolved prompts achieved +10.69% accuracy on HotpotQA (multi-hop reasoning) and +6.42% overall across multiple benchmarks. This demonstrates OpenEvolve's versatility—the same evolutionary framework optimizes both code and natural language.&lt;/p&gt;
    &lt;p&gt;Evolution Progress: As shown below on the AlgoTune benchmark, we see that the performance consistently improves over generations. Extended evolution (200 iterations) achieved 24% better results than shorter runs (100 iterations), suggesting that patient exploration of the solution space yields compounding benefits.&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting Started&lt;/head&gt;
    &lt;p&gt;OpenEvolve provides both library and command-line interfaces:&lt;/p&gt;
    &lt;code&gt;from openevolve import run_evolution

result = run_evolution(
    initial_program="def solve(x): return x * 2",
    evaluator=lambda path: {"score": benchmark(path)},
    iterations=100
)&lt;/code&gt;
    &lt;p&gt;For complex configurations, use YAML files specifying LLM models, evolution strategies, and evaluation parameters. OpenEvolve supports checkpoint/resume for long-running experiments and parallel evaluation across multiple cores. OpenEvolve is open-source and available on GitHub.&lt;/p&gt;
    &lt;p&gt;Update: This blog post was updated on November 1, 2025&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46211861</guid><pubDate>Tue, 09 Dec 2025 22:54:33 +0000</pubDate></item><item><title>Post-transformer inference: 224× compression of Llama-70B with improved accuracy</title><link>https://zenodo.org/records/17873275</link><description>&lt;doc fingerprint="3ffa92dd34900792"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Post-Transformer Inference: 224× Compression of Llama-70B with Improved Accuracy&lt;/head&gt;
    &lt;head rend="h2"&gt;Description&lt;/head&gt;
    &lt;p&gt;This paper introduces the first verified method to eliminate transformers from inference while preserving, and in many cases improving, downstream accuracy.&lt;/p&gt;
    &lt;p&gt;We show that a frozen 70-billion-parameter Llama-3.3-70B model can be replaced by a 256-dimensional meaning field extracted from seven internal activation layers. A lightweight compressor (AN1) reduces these fields by 224× with an average +1.81 percentage point gain across classification tasks, including +3.25 pp on low-resource RTE (R² = 0.98 inverse-scaling fit, p &amp;lt; 0.01). A 30M-parameter student then learns to regenerate these fields directly from raw text, enabling full transformer-free inference at 60× higher throughput with only 0.35 pp average accuracy loss.&lt;/p&gt;
    &lt;p&gt;The core insight is that task-aligned semantics in modern transformers occupy a remarkably low-rank manifold. Across layers we observe 72–99 percent of variance in the top one to three dimensions. Once this structure is extracted and learned, the transformer becomes unnecessary. It serves as a one-time sculptor of meaning rather than the permanent home of inference.&lt;/p&gt;
    &lt;p&gt;This work establishes Field Processing Units (FPUs) as a post-transformer compute primitive that replaces deep matrix multiplication with shallow field operations.&lt;/p&gt;
    &lt;p&gt;All results are averaged over five seeds with statistical significance reported. Ablations isolate the causal contributions of field supervision, geometric regularization, and anchor-layer selection.&lt;/p&gt;
    &lt;p&gt;This Zenodo release provides the complete scientific manuscript and the baseline reference implementation for the AN1 Core system. Proprietary optimizations (AN1-Turbo) have been removed to support independent verification and further research into post-transformer inference.&lt;/p&gt;
    &lt;head rend="h2"&gt;Files&lt;/head&gt;
    &lt;head rend="h3"&gt; Post-Transformer_Inference.pdf &lt;/head&gt;
    &lt;head rend="h3"&gt; Files (1.6 MB) &lt;/head&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Name&lt;/cell&gt;
        &lt;cell role="head"&gt;Size&lt;/cell&gt;
        &lt;cell role="head"&gt;Download all&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt; md5:66c0299f4b076dce030e70b7cf65efea &lt;/cell&gt;
        &lt;cell&gt;1.6 MB&lt;/cell&gt;
        &lt;cell&gt;Preview Download&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Additional details&lt;/head&gt;
    &lt;head rend="h3"&gt; Software &lt;/head&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Repository URL&lt;/item&gt;
      &lt;item rend="dd-1"&gt;https://github.com/Anima-Core/an1-core&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46212969</guid><pubDate>Wed, 10 Dec 2025 01:25:00 +0000</pubDate></item><item><title>Show all your application error using Cloudflare Error Page</title><link>https://github.com/donlon/cloudflare-error-page</link><description>&lt;doc fingerprint="f82eaa0a8486a8cc"&gt;
  &lt;main&gt;
    &lt;p&gt;📢 Update (2025/12/09): All icons used in the error page have been fully redrawn as vector assets. These icons along with the stylesheet are also inlined into a single file of the error page, eliminating any need of hosting additional resources and ensuring better experience for you and your end users.&lt;/p&gt;
    &lt;p&gt;This project creates customized error pages that mimics the well-known Cloudflare error page. You can also embed it into your website.&lt;/p&gt;
    &lt;p&gt;Here's an online editor to create customized error pages. Try it out here.&lt;/p&gt;
    &lt;p&gt;Install &lt;code&gt;cloudflare-error-page&lt;/code&gt; with pip.&lt;/p&gt;
    &lt;code&gt;pip install git+https://github.com/donlon/cloudflare-error-page.git&lt;/code&gt;
    &lt;p&gt;Then you can generate an error page with the &lt;code&gt;render&lt;/code&gt; function. (example.py)&lt;/p&gt;
    &lt;code&gt;import webbrowser
from cloudflare_error_page import render as render_cf_error_page

# This function renders an error page based on the input parameters
error_page = render_cf_error_page({
    # Browser status is ok
    'browser_status': {
        "status": 'ok',
    },
    # Cloudflare status is error
    'cloudflare_status': {
        "status": 'error',
        "status_text": 'Error',
    },
    # Host status is also ok
    'host_status': {
        "status": 'ok',
        "location": 'example.com',
    },
    # can be 'browser', 'cloudflare', or 'host'
    'error_source': 'cloudflare',

    # Texts shown in the bottom of the page
    'what_happened': '&amp;lt;p&amp;gt;There is an internal server error on Cloudflare\'s network.&amp;lt;/p&amp;gt;',
    'what_can_i_do': '&amp;lt;p&amp;gt;Please try again in a few minutes.&amp;lt;/p&amp;gt;',
})

with open('error.html', 'w') as f:
    f.write(error_page)

webbrowser.open('error.html')&lt;/code&gt;
    &lt;p&gt;You can also see live demo here.&lt;/p&gt;
    &lt;p&gt;A demo server using Flask is also available in flask_demo.py.&lt;/p&gt;
    &lt;code&gt;// Coming soon!&lt;/code&gt;
    &lt;code&gt;/* Coming soon! */&lt;/code&gt;
    &lt;code&gt;params = {
    "title": "Catastrophic infrastructure failure",
    "more_information": {
        "for": "no information",
    },
    "browser_status": {
        "status": "error",
        "status_text": "Out of Memory",
    },
    "cloudflare_status": {
        "status": "error",
        "location": "Everywhere",
        "status_text": "Error",
    },
    "host_status": {
        "status": "error",
        "location": "example.com",
        "status_text": "On Fire",
    },
    "error_source": "cloudflare",
    "what_happened": "&amp;lt;p&amp;gt;There is a catastrophic failure.&amp;lt;/p&amp;gt;",
    "what_can_i_do": "&amp;lt;p&amp;gt;Please try again in a few years.&amp;lt;/p&amp;gt;",
}&lt;/code&gt;
    &lt;code&gt;params = {
    "title": "Web server is working",
    "error_code": 200,
    "more_information": {
        "hidden": True,
    },
    "browser_status": {
        "status": "ok",
        "status_text": "Seems Working",
    },
    "cloudflare_status": {
        "status": "ok",
        "status_text": "Often Working",
    },
    "host_status": {
        "status": "ok",
        "location": "example.com",
        "status_text": "Almost Working",
    },
    "error_source": "host",
    "what_happened": "&amp;lt;p&amp;gt;This site is still working. And it looks great.&amp;lt;/p&amp;gt;",
    "what_can_i_do": "&amp;lt;p&amp;gt;Visit the site before it crashes someday.&amp;lt;/p&amp;gt;",
}&lt;/code&gt;
    &lt;head rend="h3"&gt;How to show real user IP / Cloudflare Ray ID / data center location in the error page so that it looks more realistic?&lt;/head&gt;
    &lt;p&gt;Ray ID and user IP field in the error page can be set by &lt;code&gt;ray_id&lt;/code&gt; and &lt;code&gt;client_ip&lt;/code&gt; properties in the &lt;code&gt;params&lt;/code&gt; argument passed to the render function. The real Cloudflare Ray ID and the data center location of current request can be extracted from the &lt;code&gt;Cf-Ray&lt;/code&gt; request header (e.g. &lt;code&gt;Cf-Ray: 230b030023ae2822-SJC&lt;/code&gt;). Detailed description of this header can be found in Cloudflare documentation.&lt;/p&gt;
    &lt;p&gt;To lookup the city name of the data center corresponding to the three letter code in the header, you can use a location list from here&lt;/p&gt;
    &lt;p&gt;The demo server runs in our website did handle these. Take a look at this file for reference.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;cloudflare-error-page-3th.pages.dev:&lt;/p&gt;
        &lt;p&gt;Error page of every HTTP status code (reload to show random page).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;React reimplementation of the original page, and can be deployed directly to Cloudflare Pages.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;{
    "html_title": "cloudflare.com | 500: Internal server error",
    "title": "Internal server error",
    "error_code": 500,
    "time": "2025-11-18 12:34:56 UTC",  // if not set, current UTC time is shown

    // Configuration for "Visit ... for more information" line
    "more_information": {
        "hidden": false,
        "text": "cloudflare.com", 
        "link": "https://www.cloudflare.com/",
        "for": "more information",
    },

    // Configuration for the Browser/Cloudflare/Host status
    "browser_status": {
        "status": "ok", // "ok" or "error"
        "location": "You",
        "name": "Browser",
        "status_text": "Working",
        "status_text_color": "#9bca3e",
    },
    "cloudflare_status": {
        "status": "error",
        "location": "Cloud",
        "name": "Cloudflare",
        "status_text": "Error",
        "status_text_color": "#bd2426",
    },
    "host_status": {
        "status": "ok",
        "location": "The Site",
        "name": "Host",
        "status_text": "Working",
        "status_text_color": "#9bca3e",
    },
    "error_source": "host", // Position of the error indicator, can be "browser", "cloudflare", or "host"

    "what_happened": "&amp;lt;p&amp;gt;There is an internal server error on Cloudflare's network.&amp;lt;/p&amp;gt;",
    "what_can_i_do": "&amp;lt;p&amp;gt;Please try again in a few minutes.&amp;lt;/p&amp;gt;",

    "ray_id": '0123456789abcdef',  // if not set, random hex string is shown
    "client_ip": '1.1.1.1',

    // Configuration for 'Performance &amp;amp; security by ...' in the footer
    "perf_sec_by": {
        "text": "Cloudflare",
        "link": "https://www.cloudflare.com/",
    },
}&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46213273</guid><pubDate>Wed, 10 Dec 2025 02:18:07 +0000</pubDate></item><item><title>The end of the kernel Rust experiment</title><link>https://lwn.net/Articles/1049831/</link><description>&lt;doc fingerprint="d47182f9dc7c0f0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The end of the kernel Rust experiment&lt;/head&gt;
    &lt;p&gt; (Stay tuned for details in our Maintainers Summit coverage.)&lt;/p&gt;
    &lt;p&gt; Posted Dec 10, 2025 4:25 UTC (Wed) by ktkaffee (subscriber, #112877) [Link] (2 responses) Posted Dec 10, 2025 4:45 UTC (Wed) by josh (subscriber, #17465) [Link] (1 responses) Posted Dec 10, 2025 4:48 UTC (Wed) by corbet (editor, #1) [Link] &lt;head&gt;Nice&lt;/head&gt;&lt;head&gt;Nice&lt;/head&gt;&lt;head/&gt; Ouch. That is what I get for pushing something out during a meeting, I guess. That was not my point; the experiment is done, and it was a success. I meant no more than that. &lt;head&gt;Nice&lt;/head&gt;&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46213585</guid><pubDate>Wed, 10 Dec 2025 03:15:24 +0000</pubDate></item><item><title>'Source available' is not open source (and that's okay)</title><link>https://dri.es/source-available-is-not-open-source-and-that-is-okay</link><description>&lt;doc fingerprint="a5471b19deb3153e"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;'Source available' is not open source (and that's okay)&lt;/head&gt;
    &lt;p&gt;I have spent twenty years working on open source sustainability, so watching a fight ignite between Ruby on Rails creator David Heinemeier Hansson and WordPress founding developer Matt Mullenweg this week felt uncomfortably familiar in a way I wish it didn't.&lt;/p&gt;
    &lt;p&gt;David Heinemeier Hansson (also known as DHH) released a new kanban tool, Fizzy, this week and called it open source.&lt;/p&gt;
    &lt;p&gt;People quickly pointed out that the O'Saasy license that Fizzy is released under blocks others from offering a competing SaaS version, which violates the Open Source Initiative's definition. When challenged, he brushed it off on X and said, "You know this is just some shit people made up, right?". He followed with "Open source is when the source is open. Simple as that".&lt;/p&gt;
    &lt;p&gt;This morning, Matt Mullenweg rightly pushed back. He argued that you can't ignore the Open Source Initiative definition. He compared it to North Korea calling itself a democracy. A clumsy analogy, but the point stands.&lt;/p&gt;
    &lt;p&gt;Look, the term "open source" has a specific, shared meaning. It is not a loose idea and not something you can repurpose for marketing. Thousands of people shaped that definition over decades. Ignoring that work means benefiting from the community while setting aside its rules.&lt;/p&gt;
    &lt;p&gt;This whole debate becomes spicier knowing that DHH was on Lex Fridman's podcast only a few months ago, appealing to the spirit and ethics of open source to criticize Matt's handling of the WP Engine dispute. If the definition is just "shit people made up", what spirit was Matt violating?&lt;/p&gt;
    &lt;p&gt;The definition debate matters, but the bigger issue here is sustainability. DHH's choice of license reacts to a real pressure in open source: many companies make real money from open source software while leaving the hard work of building and maintaining it to others.&lt;/p&gt;
    &lt;p&gt;This tension also played a role in Matt's fight with WP Engine, so he and DHH share some common ground, even if they handle it differently. We see the same thing in Drupal, where the biggest companies do not always contribute at the same level.&lt;/p&gt;
    &lt;p&gt;DHH can experiment because Fizzy is new. He can choose a different license and see how it works. Matt can't as WordPress has been under the GPL for more than twenty years. Changing that now is virtually impossible.&lt;/p&gt;
    &lt;p&gt;Both conversations are important, but watching two of the most influential people in open source argue about definitions while we all wrestle with free riders feels a bit like firefighters arguing about hose lengths during a fire.&lt;/p&gt;
    &lt;p&gt;The definition debate matters because open source only works when we agree on what the term means. But sustainability decides whether projects like Drupal, WordPress, and Ruby on Rails keep thriving for decades to come. That is the conversation we need to have.&lt;/p&gt;
    &lt;p&gt;In Drupal, we are experimenting with contribution credits and with guiding work toward companies that support the project. These ideas have helped, but also have not solved the imbalance.&lt;/p&gt;
    &lt;p&gt;Six years ago I wrote in my Makers and Takers blog post that I would love to see new licenses that "encourage software free riding", but "discourage customer free riding". O'Saasy is exactly that kind of experiment.&lt;/p&gt;
    &lt;p&gt;A more accurate framing would be that Fizzy is source available. You can read it, run it, and modify it. But DHH's company is keeping the SaaS rights because they want to be able to build a sustainable business. That is defensible and generous, but it is not open source.&lt;/p&gt;
    &lt;p&gt;I still do not have the full answer to the open source sustainability problem. I have been wrestling with it for more than twenty years. But I do know the solution is not renaming the problem.&lt;/p&gt;
    &lt;p&gt;Some questions are worth asking, and answering:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;How do we distinguish between companies that can't contribute and those that won't?&lt;/item&gt;
      &lt;item&gt;What actually changes corporate behavior: shame, self-interest, punitive action, exclusive benefits, or regulation?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If this latest fight nudges us away from word games and toward these questions, some good may come from it.&lt;/p&gt;
    &lt;p&gt;— Dries Buytaert&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46213709</guid><pubDate>Wed, 10 Dec 2025 03:33:14 +0000</pubDate></item></channel></rss>