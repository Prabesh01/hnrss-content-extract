<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 17 Sep 2025 00:44:33 +0000</lastBuildDate><item><title>When the job search becomes impossible</title><link>https://www.jeffwofford.com/wp/?p=2240</link><description>&lt;doc fingerprint="7748915723d08eaf"&gt;
  &lt;main&gt;
    &lt;p&gt;I have the good fortune to have a job right now, but many of my friends are out of work. Most have been searching for a while. Some are encountering a problem that has my full sympathy, something I’ve experienced myself at various times. I’m not sure I can solve it, but maybe I can help put words to what some are going through.&lt;/p&gt;
    &lt;p&gt;The problem unfolds in three distinct phases as the job search drags on.&lt;/p&gt;
    &lt;head rend="h2"&gt;Phase I: The Obvious but Impossible Search&lt;/head&gt;
    &lt;p&gt;You’ve spent several months sending out scores of carefully tailored resumes and cover letters for jobs you know you are fully qualified for and would excel at. Usually you get no response. Occasionally you get a polite “position filled.” That’s it.&lt;/p&gt;
    &lt;p&gt;You’re knocking on all the obvious doors—all the jobs closest to what you’ve been doing—and nothing is opening up. It’s exhausting and frustrating. The very act of telling your friends you’re “discouraged” feels like swallowing a horse pill; “discouraged” does not reach the depths of your fear and despair.&lt;/p&gt;
    &lt;p&gt;The obvious path forward—finding a job in line with your resume—no longer looks like a path. It looks like The Cliffs of Insanity. What used to feel like the Obvious Way Forward now feels like the Impossible Way Forward. Somewhere in your brain there is a tank of gasoline that gets burned each time you force yourself to do something irksome. That tank has burned down to vapors.&lt;/p&gt;
    &lt;p&gt;You are burned out. You are burned out on search. You are burned out on an impossible search.&lt;/p&gt;
    &lt;p&gt;But you can’t stay still. So your mind looks for new paths.&lt;/p&gt;
    &lt;head rend="h2"&gt;Phase II: The Adjacent-to-Impossible Search&lt;/head&gt;
    &lt;p&gt;You consider job openings that aren’t quite aligned with what you were doing but might offer better chances. Maybe it’s in an adjacent industry, a slightly different role, or somewhere you never really wanted to live. Maybe you could take a small pay cut. Maybe an hour’s commute wouldn’t be so bad. You expand your search away from the impossible to a broader horizon, to things that are adjacent to impossible.&lt;/p&gt;
    &lt;p&gt;This often works! The compromises can turn out better than expected. A pay cut can lead to a quick raise that puts you ahead of your prior pay. Sometimes they turn out worse than expected, but the next job search goes better—new connections, new head space, more time for the market to improve.&lt;/p&gt;
    &lt;p&gt;Sometimes it doesn’t work. The employers don’t bite. The required compromises are just too dire. The adjacent-to-impossible jobs turn out to be impossible too.&lt;/p&gt;
    &lt;p&gt;You are burned out. You are very burned out. The creativity and spunk it took to expand your horizons has gone nowhere. That extra spark has died. The brain’s reserve gas tank is now showing “E.” You are suffering from a disease we call Adjacent-to-Impossible Search Burnout (AISB, for the medical professionals in the room).&lt;/p&gt;
    &lt;p&gt;But you can’t stay still. So your mind looks for new paths.&lt;/p&gt;
    &lt;head rend="h2"&gt;Phase III: Weird Search&lt;/head&gt;
    &lt;p&gt;Well, if none of the obvious or even next-to-obvious stuff is working, why hang around? Throw the gates wide open, go ronin, walk the whole horizon, drag the whole ocean. You could learn to make jewelry and open an Etsy shop. You could band together with friends and make that little app you’ve always talked about. You could open up that little coffee shop, that bakery, that catering business. You could go back to college and learn a new career.&lt;/p&gt;
    &lt;p&gt;It feels like giving up, though, doesn’t it? Wait, no! It feels like taking charge of your own destiny, plotting your own course, becoming master of your fate, all that sort of thing! Except, geez, at maybe one-half, one-fourth the pay, if you’re lucky? Maybe less, if you’re paying for college before you even start this new career.&lt;/p&gt;
    &lt;p&gt;And yet… what’s the alternative? Getting paid zero for the foreseeable future? Continuing to churn out groveling resumes and “I can’t wait to work at your wonderful company that doesn’t have the internal culture of decency or self-discipline to bother responding to this application that you invited, from someone you know really needs answers right now” cover letters?&lt;/p&gt;
    &lt;p&gt;So yes, you go weird, at least mentally, and you entertain ideas about what else in tarnation might possibly pay you a living wage while using your talents and filling up your joy-meter.&lt;/p&gt;
    &lt;p&gt;And sometimes this goes great. Almost every company or product we love started more or less like this. The next one might be yours. I like the weird path, and if you take it and it blossoms, I salute you and I bless you.&lt;/p&gt;
    &lt;p&gt;But we’re here for the ones that are still stuck in this place, this third phase.&lt;/p&gt;
    &lt;p&gt;You have been thwarted by the Cliffs of Insanity. You have become nauseated by the Wide World of Compromise. But nowhere else on your broad horizon has yet called you forward.&lt;/p&gt;
    &lt;p&gt;And here’s the deal: here’s how you know you are really at the end of the rope: you are sick of freaking thinking about it.&lt;/p&gt;
    &lt;p&gt;You are sicking of trying to find jobs you should have. You are sick of trying to find jobs you could have. You are sick of trying to find jobs you shouldn’t have—jobs that could be fun but would make your grandmother shake her head a little. You are burned out on search. All possible gas tanks are empty. All the creative-hopeful-bright-idea-one-more-try sauce is gone, dried up, kaput.&lt;/p&gt;
    &lt;p&gt;You are Burned Out On Search (BOOS for the professionals). That’s the problem. That’s the disease. You’re welcome.&lt;/p&gt;
    &lt;head rend="h2"&gt;Solutions&lt;/head&gt;
    &lt;p&gt;I don’t know. I can’t solve your problem. If your problem wasn’t genuinely hard you would have solved it already. Some stranger who doesn’t know your situation ain’t gonna solve it. But here are some notes I’ve picked up along similar roads.&lt;/p&gt;
    &lt;p&gt;You’re not alone. A lot, a lot of people are in this boat right now, and frankly, in any given year somebody, probably somebody you know, is in this boat. As I write, 40% of unemployed people have been out of work for at least 15 weeks. That’s almost four months. Fully a fourth have been unemployed at least 27 weeks: over six months. Unemployment is not strange or rare. Happens to everybody: good, capable people who did miracles at prior organizations and will do them again, they just can’t do them right now.&lt;/p&gt;
    &lt;p&gt;It sucks real bad. Let’s not understate the horror of unemployment in a modern economy. Talk about a Cliff of Insanity: there is an unbelievable drop in wellbeing from the employed to unemployed. I don’t need to spell it all out—the money stuff, the healthcare stuff, the embarrassment, the boredom, the fear. It’s bad.&lt;/p&gt;
    &lt;p&gt;And yet somehow in the grand scheme of social sympathy and compassion, unemployment doesn’t get a lot of loving. Tell folks you’ve got knee problems, house foundation problems, college debt, divorce, death in the family, hair stylist went rogue this morning and messed up your cowlick, and here comes all kinds of sympathy. Tell them you’re unemployed, what do you get? “Oh yeah I was unemployed one month ten years ago boy that sucked.” Yes, friend, yes it does suck right now six months in, and unlike your little story there I don’t know when or if it will ever stop.&lt;/p&gt;
    &lt;p&gt;But I do feel you. High five. I feel you.&lt;/p&gt;
    &lt;p&gt;It won’t turn out as bad as you fear. How often have you known somebody whose life was really, finally wrecked by unemployment? I mean, they truly never got back on their feet. Maybe previously they had a decent home, but then they became homeless, and now they’re still homeless? I’m not just talking about stories and imagination and movies right now, I’m talking about who do you personally know who’s had it go that badly?&lt;/p&gt;
    &lt;p&gt;And look, it does happen. I’m not saying that 100% of people spring back from unemployment. But in your experience what percentage of people get back to a decent place? 90%? It’s got to be more than that. 95%? 99%? Most of the time, your friends and family members go through a period of unemployment and then they find a new, good life on the other side. It might be in the obvious place, it might not be. It might be on one of those “weird paths” we talked about, but very often the new path, no matter how weird, becomes stable and sufficient and even joyful.&lt;/p&gt;
    &lt;p&gt;People—you—are more resilient and resourceful than you think. You are skillful at imagining bad outcomes. You are also skillful at avoiding them. Do yourself a favor, set aside the imagining bad outcomes skill for a year or two and focus for now on the avoiding skill—and the finding skill that runs along with it.&lt;/p&gt;
    &lt;p&gt;It’s okay to rest. This is the best lesson I’ve learned from these kinds of seasons. When you’ve searched and you’ve searched without success until you’re sick of searches, usually the lesson is: now it’s time to rest.&lt;/p&gt;
    &lt;p&gt;There is a time for hard work, very hard work. There’s a time to push yourself, even to push beyond the limits of what you think you can endure. But a time comes when you are at the limit, at least for now. In those times, the word is “rest.”&lt;/p&gt;
    &lt;p&gt;Rest is much more than mere idleness. When you rest you give your mind the space to explore possibilities it never had time to consider. Often this exploration happens without your knowing it. Suddenly you see a new way to tackle that challenge. Or you realize it was the wrong challenge to begin with, that what you needed was a different quest. Rest refuels the mind. It refills the gas tanks. It untwists wounded joints. It builds up sore muscles.&lt;/p&gt;
    &lt;p&gt;We’re not talking about watching eight hours of YouTube every day or playing video games till 4 AM. Rest is all about space. It engages purposefully with serious boredom. You’re going to need to get in there and stare at some ceilings—or better yet, from a hammock, at some skies. Give the mind space to think.&lt;/p&gt;
    &lt;p&gt;Rest should involve time with friends but also plenty of solitude. It ought to involve some deep reading—books, not just the short pieces—especially those that are full of new ideas, not on the usual menu, surprising perspectives that get your thoughts percolating.&lt;/p&gt;
    &lt;p&gt;Rest needs to be done well. Set your alarm. Make appointments and keep them. Get outside. Use your hands.&lt;/p&gt;
    &lt;p&gt;When you’re Burned Out On Search, what do you do next? When we ask it that way the answer becomes obvious. You rest. It’s the only antidote to burn out. Give your mind time to rebuild and it will find ways forward that you never expected. Sometimes the best way to search is… not to search.&lt;/p&gt;
    &lt;head rend="h3"&gt;Discover more from Holy Ghost Stories&lt;/head&gt;
    &lt;p&gt;Subscribe to get the latest posts sent to your email.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45261848</guid><pubDate>Tue, 16 Sep 2025 13:18:00 +0000</pubDate></item><item><title>Implicit ODE solvers are not universally more robust than explicit ODE solvers</title><link>https://www.stochasticlifestyle.com/implicit-ode-solvers-are-not-universally-more-robust-than-explicit-ode-solvers-or-why-no-ode-solver-is-best/</link><description>&lt;doc fingerprint="3f09c854abe7bb95"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Implicit ODE Solvers Are Not Universally More Robust than Explicit ODE Solvers, Or Why No ODE Solver is Best&lt;/head&gt;
    &lt;head rend="h4"&gt;September 4 2025 in Differential Equations, Julia, Mathematics, Programming | Tags: bdf, euler, explicit, implicit, numerical analysis, ode, runge-kutta, solver | Author: Christopher Rackauckas&lt;/head&gt;
    &lt;p&gt;A very common adage in ODE solvers is that if you run into trouble with an explicit method, usually some explicit Runge-Kutta method like RK4, then you should try an implicit method. Implicit methods, because they are doing more work, solving an implicit system via a Newton method having “better” stability, should be the thing you go to on the “hard” problems.&lt;/p&gt;
    &lt;p&gt;This is at least what I heard at first, and then I learned about edge cases. Specifically, you hear people say “but for hyperbolic PDEs you need to use explicit methods”. You might even intuit from this “PDEs can have special properties, so sometimes special things can happen with PDEs… but ODEs, that should use implicit methods if you need more robustness”. This turns out to not be true, and really understanding the ODEs will help us understand better why there are some PDE semidiscretizations that have this “special cutout”.&lt;/p&gt;
    &lt;p&gt;What I want to do in this blog post is more clearly define what “better stability” actually means, and show that it has certain consequences that can sometimes make explicit ODE solvers actually more robust on some problems. And not just some made-up problems, lots of real problems that show up in the real world.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Quick Primer on Linear ODEs&lt;/head&gt;
    &lt;p&gt;First, let’s go through the logic of why implicit ODE solvers are considered to be more robust, which we want to define in some semi-rigorous way as “having a better chance to give an answer closer to the real answer”. In order to go from semi-rigorous into a rigorous definition, we can choose a test function, and what better test function to use than a linear ODE. So let’s define a linear ODE:&lt;/p&gt;
    &lt;p&gt;$$u’ = \lambda u$$&lt;/p&gt;
    &lt;p&gt;is the simplest ODE. We can even solve it analytically, $u(t) = \exp(\lambda t)u(0)$. For completeness, we can generalize this to a linear system of ODEs, where instead of having a scalar $u$ we can let $u$ be a vector, in which case the linear ODE has a matrix of parameters $A$, i.e.&lt;/p&gt;
    &lt;p&gt;$$u’ = Au$$&lt;/p&gt;
    &lt;p&gt;In this case, if $A$ is diagonalizable, $A = P^{-1}DP$, then we can replace $A$:&lt;/p&gt;
    &lt;p&gt;$$u’ = P^{-1}DP u$$&lt;/p&gt;
    &lt;p&gt;$$Pu’ = DPu$$&lt;/p&gt;
    &lt;p&gt;or if we let $w = Pu$, then&lt;/p&gt;
    &lt;p&gt;$$w’ = Dw$$&lt;/p&gt;
    &lt;p&gt;where $D$ is a diagonal matrix. This means that for every element of $w$ we have the equation:&lt;/p&gt;
    &lt;p&gt;$$w_i’ = \lambda_i w_i$$&lt;/p&gt;
    &lt;p&gt;where $w_i$ is the vector in the direction of the $i$th eigenvector of $A$, and $\lambda_i$ is the $i$th eigenvalue of $A$. Thus our simple linear ODE $u’ = \lambda u$ tells us about general linear systems along the eigenvectors. Importantly, since even for real $A$ we can have $\lambda$ be a complex number, i.e. real-valued matrices can have complex eigenvalues, it’s important to allow for $\lambda$ to be complex to understand all possible systems.&lt;/p&gt;
    &lt;p&gt;But why is this important for any other ODE? Well by the Hartman-Grobman theorem, for any sufficiently nice ODE:&lt;/p&gt;
    &lt;p&gt;$$u’ = f(u)$$&lt;/p&gt;
    &lt;p&gt;We can locally approximate the ODE by:&lt;/p&gt;
    &lt;p&gt;$$u’ = Au$$&lt;/p&gt;
    &lt;p&gt;where $A = f'(u)$, i.e. $A$ is the linear system defined by the Jacobian local to the point. This is effectively saying any “sufficiently nice” system (i.e. if $f$ isn’t some crazy absurd function and has properties like being differentiable), you can understand how things locally move by looking at the system approximated by a linear system, where the right linear approximation is given by the Jacobian. And we know that linear systems then boil down generally to just the scalar linear system, and so understanding the behavior of a solver on the scalar linear system tells us a lot about how it will do “for small enough h”.&lt;/p&gt;
    &lt;p&gt;Okay, there are lots of unanswered questions, such as what if $A$ is not diagonalizable? What if $f$ is not differentiable? What if the system is very nonlinear so the Jacobian changes very rapidly? But under assumptions that things are nice enough, we can say that if a solver does well on $u’ = \lambda u$ then it is probably some idea of good.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why implicit ODE solvers are “better”, i.e. more robust&lt;/head&gt;
    &lt;p&gt;So now we have a metric by which we can analyze ODEs: if they have good behavior on $u’ = \lambda u$, then they are likely to be good in general. So what does it mean to have good behavior on $u’ = \lambda u$? One nice property would be to at least be asymptotically correct for the most basic statement, i.e. does it go to zero when it should? If you have $u’ = \lambda u$ and $\lambda$ is negative, then the analytical solution $u(t) = \exp(\lambda t)u(0)$ goes to zero as $t$ goes to infinity. So a good question to ask is, for a given numerical method, for what values of $h$ (the time step size) does the numerical method give a solution that goes to zero, and for which $h$ does it get an infinitely incorrect answer?&lt;/p&gt;
    &lt;p&gt;To understand this, we just take a numerical method and plug in the test equation. So the first thing to look at is Euler’s method. For Euler’s method, we step forward by $h$ by assuming the derivative is constant along the interval, or:&lt;/p&gt;
    &lt;p&gt;$$u_{n+1} = u_n + hf(u_n)$$&lt;/p&gt;
    &lt;p&gt;When does this method give a solution that is asymptotically consistent? With a little bit of algebra:&lt;/p&gt;
    &lt;p&gt;$$u_{n+1} = u_n + h\lambda u_n$$&lt;/p&gt;
    &lt;p&gt;$$u_{n+1} = (1 + h\lambda) u_n$$&lt;/p&gt;
    &lt;p&gt;Let $z = h\lambda$, which means&lt;/p&gt;
    &lt;p&gt;$$u_{n+1} = (1 + z) u_n$$&lt;/p&gt;
    &lt;p&gt;This is a discrete dynamical system which has the analytical solution:&lt;/p&gt;
    &lt;p&gt;$$u_n = u_0 (1+z)^{n}$$&lt;/p&gt;
    &lt;p&gt;Note that if $1 + z &amp;gt; 1$, then $(1+z)^n$ keeps growing as $n$ increases, so this goes to infinity, while if $1 + z &amp;lt; 1$ it goes to zero. But since $\lambda$ can actually be a complex number, the analysis is a little bit more complex (pun intended), but it effectively means that if $z$ is in the unit circle shifted to the left in the complex plane by 1, then $u_n \rightarrow 0$. This gives us the definition of the stability region, $G(z)$ is the region for which $u_n \rightarrow 0$, and this is the shifted unit circle in the complex plane for explicit Euler.&lt;/p&gt;
    &lt;p&gt;This shows a pretty bad property for this method. For any given $\lambda$ with negative real part, there is a maximum $h$, actually $h = 1/\lambda$, such that for any larger step size we don’t just get a bad answer, we can get an infinitely bad answer, i.e. the analytical solution goes to zero but the numerical solution goes to infinity!&lt;/p&gt;
    &lt;p&gt;So, is there a method that doesn’t have this bad property? In comes the implicit methods. If you run the same analysis with implicit Euler,&lt;/p&gt;
    &lt;p&gt;$$u_{n+1} = u_n + hf(u_{n+1})$$&lt;/p&gt;
    &lt;p&gt;$$u_{n+1} = u_n + h\lambda u_{n+1}$$&lt;/p&gt;
    &lt;p&gt;$$(1-z) u_{n+1} = u_n$$&lt;/p&gt;
    &lt;p&gt;$$u_{n+1} = \frac{1}{1-z} u_n$$&lt;/p&gt;
    &lt;p&gt;Then we have almost an “inverse” answer, i.e. $G(z)$ is everything except the unit circle in the complex plane shifted to the right. This means that for any $\lambda$ with negative real part, for any $h$ the implicit Euler method has $u_n \rightarrow 0$, therefore it’s never infinitely wrong.&lt;/p&gt;
    &lt;p&gt;Therefore it’s just better, QED.&lt;/p&gt;
    &lt;p&gt;This then generalizes to more advanced methods. For example, the stability region of RK4&lt;/p&gt;
    &lt;p&gt;an explicit method has a maximum $h$, while the stability region of BDF2&lt;/p&gt;
    &lt;p&gt;an implicit method does not. You can even prove it’s impossible for any explicit method to have this “good” property, so “implicit methods are better”. QED times 2, done deal.&lt;/p&gt;
    &lt;head rend="h2"&gt;Wait a second, what about that other “wrongness”?&lt;/head&gt;
    &lt;p&gt;Any attentive student should immediately throw their hand up. “Teacher, given the $G(z)$ you said, you also have that for any $\lambda$ where $\text{Re}(\lambda)&amp;gt;1$, you also have that $u_n \rightarrow 0$, but in reality the analytical solution has $u(t) \rightarrow \infty$, so implicit Euler is infinitely wrong! And explicit Euler has the correct asymptotic behavior since it goes to infinity!”&lt;/p&gt;
    &lt;p&gt;That is completely correct! But it can be easy to brush this off with “practical concerns”. If you have a real model which has positive real eigenvalues like that, then it’s just going to explode to infinity. Those kinds of models aren’t really realistic? Energy goes to infinity, angular momentum goes to infinity, the chemical concentration goes to infinity: whatever you’re modeling just goes crazy! If you’re in this scenario, then your model is probably wrong. Or if the model isn’t wrong, the numerical methods aren’t very good anyways. If you analyze the error propagation properties, you’ll see the error of the numerical method also increases exponentially! So this is a case you shouldn’t be modeling anyways.&lt;/p&gt;
    &lt;head rend="h2"&gt;Seeing this robustness in practice&lt;/head&gt;
    &lt;p&gt;Therefore if you need a more accurate result, use an implicit method. And you don’t need to go to very difficult models to see this manifest in practice. Take the linear ODE:&lt;/p&gt;
    &lt;p&gt;$$T’ = 5(300-T)$$&lt;/p&gt;
    &lt;p&gt;with $T(0) = 320$. This is a simple model of cooling an object with a constant temperature influx. It’s easy to analytically solve, you just have an exponential fall in the temperature towards $T = 300$ the steady state. But when we solve it with an explicit method at default tolerances, that’s not what we see:&lt;/p&gt;
    &lt;quote&gt;using OrdinaryDiffEq function cooling(du,u,p,t) du[1] = 5.0*(300-u[1]) end u0 = [310.0] tspan = (0.0,10.0) prob = ODEProblem(cooling, u0, tspan) sol = solve(prob, Tsit5()) using Plots plot(sol, title="RK Method, Cooling Problem") savefig("rk_cooling.png")&lt;/quote&gt;
    &lt;p&gt;We see that the explicit method gives oscillations in the solution! Meanwhile, if we take a “robust” implicit method like the BDF method from the classic C++ library SUNDIALS, we can solve this:&lt;/p&gt;
    &lt;quote&gt;using Sundials sol = solve(prob, CVODE_BDF()) plot(sol, title="BDF Method, Cooling Problem") savefig("bdf_cooling.png")&lt;/quote&gt;
    &lt;p&gt;Sure it’s not perfectly accurate, but at least it doesn’t give extremely wrong behavior. We can decrease tolerances to make this all go away,&lt;/p&gt;
    &lt;p&gt;But the main point is that the explicit method is just generally “less robust”, you have to be more careful, it can give things that are just qualitatively wrong.&lt;/p&gt;
    &lt;p&gt;This means that “good tools”, tools that have a reputation for robustness, they should default to just using implicit solvers because that’s going to be better. And you see that in tools like Modelica. For example, the Modelica University’s playground and other tools in the space like OpenModelica and Dymola, default to implicit solvers like DASSL. And you can see they do great on this problem by default!&lt;/p&gt;
    &lt;p&gt;Modelica tools gives a good answer out of the box.&lt;/p&gt;
    &lt;p&gt;So QED, that’s the “right thing to do”: if you want to be robust, stick to implicit methods.&lt;/p&gt;
    &lt;head rend="h2"&gt;But why oscillations?&lt;/head&gt;
    &lt;p&gt;Hold up a bit… why does the explicit method give oscillations? While we know that’s wrong, it would be good to understand why it gives the qualitatively wrong behavior that it does. It turns out that this falls right out of the definition of the method. If you go back to the definition of explicit Euler on the test problem, i.e.&lt;/p&gt;
    &lt;p&gt;$$u_{n+1} = u_n + hf(u_n)$$&lt;/p&gt;
    &lt;p&gt;then substitute in:&lt;/p&gt;
    &lt;p&gt;$$u_{n+1} = (1 + h\lambda) u_{n}$$&lt;/p&gt;
    &lt;p&gt;If we think about our stability criteria $G(z)$ another way, its boundaries are exactly the value by which the next $u_{n+1}$ would have a negative real part. So the analytical solution is supposed to go to zero, but the “bad” behavior is when we choose a step size $h$ such that if we extrapolate out with a straight line for $h$ long in time, then we will “jump” over this zero, something that doesn’t happen in the analytical solution. But now let’s think about what happens in that case. If you jump over zero, then $u_n &amp;lt; 0$ (think real right now), so therefore the derivative of the next update points in the other direction, i.e. we're still going towards zero, but now from the negative side we go up to zero. But since $\|1 + h\lambda\| &amp;gt; 1$, we have that $\|u_{n+1}\| &amp;gt; \|u_n\|$, i.e. the norm of the solution keeps growing. So you jump from positive to negative, then negative to positive, then positive to negative, where the jumps are growing each time. This is the phantom oscillations of the explicit ODE solver!&lt;/p&gt;
    &lt;p&gt;So what’s happening is the default tolerances of the explicit ODE solver were large enough that the chosen $h$s were in the range of the phantom oscillation behavior, and so you just need to cap $h$ below that value, which is dependent on the real part of the eigenvalue of $h$ (you can do the same analysis with complex numbers, but that just gives rotations in the complex plane along with the real part oscillation).&lt;/p&gt;
    &lt;p&gt;But if explicit methods give oscillations, what’s going on with implicit ODE solvers with large $h$? Let’s look at the update equation again:&lt;/p&gt;
    &lt;p&gt;$$u_{n+1} = \frac{1}{1-z} u_n$$&lt;/p&gt;
    &lt;p&gt;now instead of multiplying each time by $(1-z)$, we divide by it. This means that when $\lambda &amp;lt; 0$ (or $\text{Re}(\lambda) &amp;lt; 0$ to be more exact), then for any $h$ we have that $\|u_{n+1}\| &amp;lt; \|u_{n}\|$. Therefore, we might jump over the zero with a big enough $h$, but we are guaranteed that our "jump size" is always shrinking. Thus for any $h$, we will get to zero because we're always shrinking in absolute value. This means that implicit methods are working because they have a natural dampening effect. So:&lt;/p&gt;
    &lt;head rend="h4"&gt;Explicit methods introduce spurious oscillations, but implicit methods naturally damp oscillations&lt;/head&gt;
    &lt;p&gt;This explains in more detail why we saw what we saw: the explicit method when the error tolerance is sufficiently high will introduce oscillations that don’t exist, while the implicit method will not have this behavior. This is a more refined version of the “energy doesn’t go to infinity!”, now it’s “energy doesn’t come from nowhere in real systems”, and because of this implicit solvers give a better qualitative answer. This is why they are more robust, which is why robust software for real engineers just always default to them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Wait a second… do we always want that?&lt;/head&gt;
    &lt;p&gt;You should now be the student in the front row raising your hand, “implicit methods are always dampening… is that actually a good idea? Are you sure that’s always correct?” And the answer is… well it’s not. And that then gives us exactly the failure case for which implicit methods are less robust. If you have a system that is supposed to actually oscillate, then this “hey let’s always dampen everything to make solving more robust” actually leads to very wrong answers!&lt;/p&gt;
    &lt;p&gt;To highlight this, let’s just take a simple oscillator. You can think of this as a harmonic oscillator, or you can think about it as a simple model of a planet going around a star. However you want to envision it, you can write it out as a system of ODEs:&lt;/p&gt;
    &lt;p&gt;$$u_1′ = 500u_2$$&lt;lb/&gt; $$u_2′ = -500u_1$$&lt;/p&gt;
    &lt;p&gt;This is the linear ODE $u’ = Au$ where $A = [0\ 500; -500\ 0]$, which has complex eigenvalues with zero real part. In other words, the analytical solution is $\sin(500t)$ and $\cos(500t)$, just a pure oscillation that just keeps going around and around in circles. If we solve this with an explicit ODE solver:&lt;/p&gt;
    &lt;quote&gt;function f(du,u,p,t) du[1] = 500u[2] du[2] = -500u[1] end u0 = [1.0,1.0] tspan = (0.0,1.0) prob = ODEProblem(f, u0, tspan) sol = solve(prob, Tsit5()) plot(sol, title="RK Method", idxs=(1,2)) savefig("rk_oscillate.png")&lt;/quote&gt;
    &lt;p&gt;we can see that it generally gets the right answer. Over time you get some drift where the energy is slowly increasing due to numerical error in each step, but it’s going around in circles relatively well. However, our “robust implicit method”…&lt;/p&gt;
    &lt;quote&gt;sol = solve(prob, CVODE_BDF()) plot(sol, title="BDF Method", idxs=(1,2)) savefig("bdf_oscillate.png")&lt;/quote&gt;
    &lt;p&gt;is just not even close. And you can see that even our “robust Modelica tools” completely fall apart:&lt;/p&gt;
    &lt;p&gt;It says the answer goes to zero! Even when the analytical solution is just a circle! But we can understand why this is the case: the software developers made the implicit assumption that “dampening oscillations is always good, because generally that’s what happens in models, so let’s always do this by default so people get better answers”, and the result of this choice is that if someone puts in a model of the Earth going around the sun, then oops the Earth hits the sun pretty quickly.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion: ODE solvers make trade-offs, you need to make the right ones for your domain&lt;/head&gt;
    &lt;p&gt;This gives us the conclusion: there is no “better” or “more robust” ODE solver method, it’s domain-specific. This is why the Julia ODE solver package has hundreds of methods, because each domain can be asking for different properties that they want out of the method. Explicit methods are not generally faster, they are also something that tends to preserve (or generate) oscillations. Implicit methods are not generally more robust, they are methods which work by dampening transients, which is a good idea for some models but not for others. But then there’s a ton of nuance. For example, can you construct an explicit ODE solver so that on such oscillations you don’t get energy growth? You can! Anas5(w) is documented as “4th order Runge-Kutta method designed for periodic problems. Requires a periodicity estimate w which when accurate the method becomes 5th order (and is otherwise 4th order with less error for better estimates)”, i.e. if you give it a canonical frequency 500 it will be able to do extremely well on this problem (and being a bit off in that estimate still works, it just has energy growth that is small).&lt;/p&gt;
    &lt;p&gt;What about what was mentioned at the beginning of the article, “for hyperbolic PDEs you need to use explicit methods”? This isn’t a “special behavior” of PDEs, this is simply because for this domain, for example advective models of fluids, you want to conserve fluid as it moves. If you choose an implicit method, it “dampens” the solver, which means you get that as you integrate you get less and less fluid, breaking the conservation laws and giving qualitatively very incorrect solutions. If you use explicit methods, you don’t have this extraneous dampening, and this gives a better looking solution. But you can go even further and develop methods for which, if $h$ is sufficiently small, then you get little to no dampening. These are SSP methods, which we say are “for Hyperbolic PDEs (Conservation Laws)” but in reality what we mean is “when you don’t want things to dampen”.&lt;/p&gt;
    &lt;p&gt;But the point is, you can’t just say “if you want a better solution, use an implicit solver”. Maybe in some domains and for some problems that is true, but in other domains and problems that’s not true. And many numerical issues can stem from the implicit assumptions that follow from the choice being made for the integrator. Given all of this, it should be no surprise that much of the Modelica community has had many problems handling fluid models, the general flow of “everything is a DAE” → “always use an implicit solver” → “fluid models always dampen” → “we need to fix the dampening” could be fixed by making different assumptions at the solver level.&lt;/p&gt;
    &lt;p&gt;So, the next time someone tells you should just use ode15s or scipy.integrate.radau in order to make things robust without knowing anything about your problem, say “umm actually”.&lt;/p&gt;
    &lt;head rend="h2"&gt;Little Extra Details&lt;/head&gt;
    &lt;p&gt;The article is concluded. But here’s a few points I couldn’t fit into the narrative I want to mention:&lt;/p&gt;
    &lt;head rend="h3"&gt;Trapezoidal is cool&lt;/head&gt;
    &lt;p&gt;One piece I didn’t fit in here is that the Trapezoidal method is cool. The dampening property comes from L-stability, i.e. $G(z) \rightarrow 0$ as $\text{Re}(z) \rightarrow -\infty$. This is a stricter form of stability, since instead of just being stable for any finite $\lambda$, this also enforces that you are stable at the limit of bigger lambdas. “Most” implicit solvers that are used in practice, like Implicit Euler, have this property, and you can show the dampening is directly related to this property. But you can have an implicit method that isn’t L-stable. Some of these methods include Adams-Bashforth-Moulton methods, which are not even A-stable so they tend to have stability properties and act more like explicit methods. But the Trapezoidal method is A-stable without being L-stable, so it doesn’t tend to dampen while it tends to be also pretty stable. Though it’s not as stable, and the difference between “is stable for any linear ODE” versus “actually stable for nonlinear ODEs” (i.e. B-stability) is pronounced on real-world stiff problems. What this means in human terms is that the Trapezoidal method tends to not be stable enough for hard stiff problems, but it also doesn’t artificially dampen, so it can be a good default in cases where you know you have “some stiffness” but also want to keep some oscillations. One particular case of this is in some electrical circuit models with natural oscillators.&lt;/p&gt;
    &lt;head rend="h3"&gt;Lower order methods have purposes too&lt;/head&gt;
    &lt;p&gt;“All ODE solvers have a purpose”, I give some talks that give the justification for many high order methods, so in general “higher order is good if you solve with stricter tolerances and need more precision”. But lower order methods can be better because the higher order methods require that more derivatives of $f$ are defined, and if that’s not the case (like derivative discontinuities), then lower order methods will be more efficient. So even implicit Euler has cases where it’s better than higher order BDF methods, and it has to do with “how nice” $f$ is.&lt;/p&gt;
    &lt;head rend="h3"&gt;BDF methods like DASSL are actually α-stable&lt;/head&gt;
    &lt;p&gt;I said that generally implicit methods that you use are A-stable. That’s also a small lie to make the narrative simpler. The BDF methods which Sundials, DASSL, LSODE, FBDF, etc. use are actually α-stable, which means that they are actually missing some angle α of the complex plane for stability. The stability regions look like this:&lt;/p&gt;
    &lt;p&gt;So these BDF methods are actually pretty bad for other reasons on very oscillatory problems! Meanwhile, things like Rosenbrock methods can also solve DAEs while actually being L-stable, which can make them more stable in many situations where there’s oscillations towards a steady state. So there’s a trade-off there… again every method has a purpose. But this is another “ode15s is more stable than ode23s”… “well actually…”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45262151</guid><pubDate>Tue, 16 Sep 2025 13:41:51 +0000</pubDate></item><item><title>Things you can do with a Software Defined Radio (2024)</title><link>https://blinry.org/50-things-with-sdr/</link><description>&lt;doc fingerprint="b604197b7163def1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Fifty Things you can do with a Software Defined Radio ð»&lt;/head&gt;
    &lt;p&gt;Last week, I went on an adventure through the electromagnetic spectrum!&lt;/p&gt;
    &lt;p&gt;Itâs like an invisible world that always surrounds us, and allows us to do many amazing things: Itâs how radio and TV are transmitted, itâs how we communicate using Wi-Fi or our phones. And there are many more things to discover there, from all over the world.&lt;/p&gt;
    &lt;p&gt;In this post, Iâll show you fifty things you can find there â all you need is this simple USB dongle and an antenna kit!&lt;/p&gt;
    &lt;head rend="h2"&gt;The âMake 50 of Somethingâ technique&lt;/head&gt;
    &lt;p&gt;A couple of years ago, I heard about the âMake 50 of Somethingâ technique in Vi Hartâs Fifty Fizzbuzzes. Since then, Iâve already made fifty programs for the fantasy console TIC-80 in one weekend in 2021.&lt;/p&gt;
    &lt;p&gt;I found that a very exciting experience â trying to make so many new things really pushed me to leave my comfort zone, to be creative, and not to get sucked into rabbit holes too deep.&lt;/p&gt;
    &lt;p&gt;I knew I definitely wanted to try the technique again. So, when I took a week of vacation, I decided to try to find 50 things to do with a Software Defined Radio!&lt;/p&gt;
    &lt;head rend="h2"&gt;What is an SDR?&lt;/head&gt;
    &lt;p&gt;A Software Defined Radio is essentially a radio that relies on a computer to do most of its data processing. It doesnât rely on analog hardware too much â instead, most of what is does is âdefined in softwareâ, hence the name.&lt;/p&gt;
    &lt;p&gt;Usually, SDRs can detect electromagnetic waves in a much wider range than a common FM radio, which makes it especially exciting! I got interested in SDRs after reading about Albertâs project to build one as a module for the Framework laptop!&lt;/p&gt;
    &lt;head rend="h2"&gt;What youâll need&lt;/head&gt;
    &lt;p&gt;I went into this week without much knowledge of the things Iâd find. Iâd read through a introductory course for aspiring amateur radio operators (more on that later), but I barely knew which way to point my antenna.&lt;/p&gt;
    &lt;p&gt;If you want to follow along, this section is intended to help you get started!&lt;/p&gt;
    &lt;p&gt;Most of the 50 things also have a little infobox at the beginning, explaining the frequencies, and some special knowledge needed to receive them.&lt;/p&gt;
    &lt;head rend="h3"&gt;Hardware&lt;/head&gt;
    &lt;p&gt;I looked into the topic a bit, and a popular, cheap SDR right now is the RTL-SDR Blog V4, which has the form factor of a simple SUB dongle. You can get it for around $30, or as a kit with telescopic antennas for $50.&lt;/p&gt;
    &lt;p&gt;Everything I tried during this week was done using this USB dongle, the antenna kit, and a long piece of wire!&lt;/p&gt;
    &lt;p&gt;(By the way, thereâs another great option if you donât want to buy anything â lots of people make their SDR accessible through the Internet! You can find a map here.)&lt;/p&gt;
    &lt;head rend="h3"&gt;Using the antennas&lt;/head&gt;
    &lt;p&gt;I tried to adjust my antenna to the desired frequencies as best as I could. I think for receiving, itâs not super important that your antenna is perfectly configured, though.&lt;/p&gt;
    &lt;p&gt;For most applications, I used the dipole antennas that came with the kit I purchased. Dipole antennas have two sides that stick out the same length. You generally wanna make the whole antenna half as long as the wave length you want to receive, and orient it vertically.&lt;/p&gt;
    &lt;p&gt;My rule of thumb was to divide 72 by the frequency in MHz, and take that as the length of each side of the dipole in meters. Thatâd make the whole antenna a bit shorter than half of the wavelength.&lt;/p&gt;
    &lt;p&gt;For example, this is what the configuration looked like for frequencies around 100 MHz:&lt;/p&gt;
    &lt;p&gt;And for higher frequencies, I used the tiny screw-on antennas from the kit:&lt;/p&gt;
    &lt;p&gt;For specific applications like receiving satellites, or receiving locators for airplanes, I used special configurations, but Iâll discuss these as we go!&lt;/p&gt;
    &lt;head rend="h3"&gt;Software&lt;/head&gt;
    &lt;p&gt;The software I liked best, and which I used for many things, was SDR++. It allows you to explore the frequency spectrum very smoothly, and has a modern user interface!&lt;/p&gt;
    &lt;p&gt;But I also used plenty of other software, on Linux in my case. Iâll link to the software as needed below.&lt;/p&gt;
    &lt;head rend="h2"&gt;Monday&lt;/head&gt;
    &lt;p&gt;On Monday morning, I was excited to start this project! I sat down at my desk, and got to work!&lt;/p&gt;
    &lt;head rend="h3"&gt;1: Listen to FM radio&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 87.5-108 MHz&lt;/item&gt;
      &lt;item&gt;Modulation: FM (âfrequency modulationâ)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This as an obvious first thing to do, as the signals are very strong! I was using the SDR++ software, and it felt very nice browsing around and discovering the stations around me! It reminded me of exploring the radio as a child.&lt;/p&gt;
    &lt;p&gt;I found a local station that gives 1-hour slots to civic groups, for example!&lt;/p&gt;
    &lt;head rend="h3"&gt;2: Listen to Freenet&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 149.01-149.11 MHz&lt;/item&gt;
      &lt;item&gt;Modulation: FM&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is a special frequency range in Germany: Anyone is allowed to send there, using licensed devices. There are 6 channels.&lt;/p&gt;
    &lt;p&gt;I think someone was testing their device there when I listened in. :D I heard a âHellooo?â, then a âTest, testâ, and then a âGeneral call to all stationsâ. Oh, and shortly after a short transmission on channel 3 in a Slavic-sounding language!&lt;/p&gt;
    &lt;p&gt;Freenet devices have a range of only a couple of kilometers, so these people must have been pretty close! :O&lt;/p&gt;
    &lt;head rend="h3"&gt;3: Receive weather conditions from airports&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: Differs by airport, search term is âATISâ&lt;/item&gt;
      &lt;item&gt;Modulation: AM&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;While browsing the aviation frequencies, I found this station that reports weather conditions in an endless loop. It seems to be the âAutomatic Terminal Information Serviceâ of Hamburg airport!&lt;/p&gt;
    &lt;p&gt;Thanks to that, I found out that the current air pressure was 1011 hPa! :D&lt;/p&gt;
    &lt;head rend="h3"&gt;4: Listen to airplane communication&lt;/head&gt;
    &lt;p&gt;Listening to âmessages not meant for the general publicâ is not allowed in Germany, so of course I didnât do that. And if I had accidentally done that, I wouldnât be allowed to tell you about it. ð&lt;/p&gt;
    &lt;head rend="h3"&gt;5: Track aircraft via ADS-B&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 1090 MHz&lt;/item&gt;
      &lt;item&gt;Protocol: ADS-B&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Thatâs short for âAutomatic Dependent Surveillance â Broadcastâ. Aircraft send it automatically to be tracked.&lt;/p&gt;
    &lt;p&gt;For this, I built my first antenna! From wire and and an antenna connector called âSMAâ.&lt;/p&gt;
    &lt;p&gt;And it worked! \o/ I decoded the signal using the software SDRangel. Fascinating! I saw some big &amp;amp; small airplanes, and even a helicopter!&lt;/p&gt;
    &lt;head rend="h3"&gt;6: Listen to stereo FM radio&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 87.5-108 MHz&lt;/item&gt;
      &lt;item&gt;Modulation: FM&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;How stereo audio is transmitted is really interesting, because itâs backwards-compatible to receivers that donât support it:&lt;/p&gt;
    &lt;p&gt;Here, you see the demodulated audio frequency spectrum, as shown in SDRangel. Below 19k Hz, itâs just mono audio. Then, to mark a stereo station, thereâs a constant âpilot toneâ at 19k Hz! (Outside of what most humans can hear.)&lt;/p&gt;
    &lt;p&gt;Then, if you double the frequency of the pilot tone, you can derive the sections where the difference of the left &amp;amp; right channel to the mono channel is transmitted!&lt;/p&gt;
    &lt;p&gt;Correction: Iâve been told that instead of what I call âleftâ and ârightâ in this diagram, the upper frequencies transmit the difference of the left and right channels! That way, the receiver can calculate the left and right channels from the mono signal (which is, esseutially, the sum of left and right).&lt;/p&gt;
    &lt;head rend="h3"&gt;7: Receive road traffic information&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 87.5-108 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you triple the frequency of the pilot tone, you get to a range where FM stations transmit small amounts of digital metadata, like the name and genre of the station, and the current song! Thatâs a protocol called Radio Data System.&lt;/p&gt;
    &lt;p&gt;This system can also transmit road traffic information! There seemed to be a road closure at â0x64BEâ, as decoded by SDRangel.&lt;/p&gt;
    &lt;p&gt;The Federal Highway Research Institute publishes an Excel table, where I could look up that this is a town in Lower Saxony!&lt;/p&gt;
    &lt;head rend="h3"&gt;8: Listen to conversations on the 2-meter amateur radio band&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 144-146 MHz&lt;/item&gt;
      &lt;item&gt;Modulation: FM&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is a frequency range reserved for amateur radio operators â for non-commercial use only. You may send on this band after getting a license.&lt;/p&gt;
    &lt;p&gt;What I found here is seemingly a conversation circle facilitated by a relay around 15 km away from here â it takes input on a certain frequency, and outputs an amplified copy of it on another frequency! Klaus, Bernd, JÃ¼rgen and Horst were talking about antennas, relays, and Windows XP! ð&lt;/p&gt;
    &lt;head rend="h3"&gt;9: Listen to digital radio&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 174-240 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The SDRangel software also has a demodulator for Digital Audio Broadcast! :O I continue to be amazed by it!&lt;/p&gt;
    &lt;p&gt;I think this was the first time Iâve received digital radio via air! I saw so many stations, and Iâve only checked a couple of channels.&lt;/p&gt;
    &lt;p&gt;The advantage of this digital channel is that thereâs no noise. And I even saw a âcover imageâ in one of the programs!&lt;/p&gt;
    &lt;head rend="h3"&gt;10: Listen to PMR446&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 446.0-446.2 MHz&lt;/item&gt;
      &lt;item&gt;Modulation: FM&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is a frequency range for âPrivate Mobile Radioâ. Itâs another of these bands where anyone can transmit using a licensed device!&lt;/p&gt;
    &lt;p&gt;Not a lot of activity here. I heard âHello, hellooo!â, âCan you hear me?â and some short transmissions that sounded like a child! :D&lt;/p&gt;
    &lt;p&gt;There also seemed to be digital transmissions, but I didnât know how to decode them yet.&lt;/p&gt;
    &lt;p&gt;The range of PMR446 devices is pretty low (a couple of hundred metres in cities), so again, the people mustâve been close!&lt;/p&gt;
    &lt;head rend="h2"&gt;Tuesday&lt;/head&gt;
    &lt;p&gt;After the first day of SDR experiments, I was amazed how much invisible communication is going on around us in the electromagnetic spectrum at the same time!&lt;/p&gt;
    &lt;p&gt;I posted each of these things on Mastodon as I went, and asked people for suggestions for more things I could receive.&lt;/p&gt;
    &lt;head rend="h3"&gt;11: Read your neighborsâ sensors&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 433.05-434.79 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;At 433 MHz, thereâs a frequency band for âindustrial, scientific and medicalâ applications. And wow, there was quite a lot of activity nearby!&lt;/p&gt;
    &lt;p&gt;Using the decoder rtl_433, I saw two sensors that output the current temperature, humidity, and air pressure!&lt;/p&gt;
    &lt;p&gt;There were also some âIBIS beaconsâ flying by, which are used in public transportation, so maybe itâs buses driving by?&lt;/p&gt;
    &lt;p&gt;Later, an âInterlogix Securityâ device also appeared, reporting âclosed switch statesâ :O&lt;/p&gt;
    &lt;head rend="h3"&gt;12: Track ships!&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 162.025 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Ships send out their status using AIS (Automatic Identification System). And again, I received a lot of them here in Hamburg! :O&lt;/p&gt;
    &lt;p&gt;I was especially excited to receive data from the MS Stubnitz (a fisher boat that was turned into a culture center/techno club)! It reports its status as âmooredâ, and its speed as 0.1 knots! :D&lt;/p&gt;
    &lt;p&gt;Again, I used the software SDRangel. Apparently, it can also display a 3D map, but I havenât figured out how to add 3D modelsâ¦&lt;/p&gt;
    &lt;head rend="h3"&gt;13: Detect GSM activity&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 876-959 MHz, I looked up the specific ranges for Germany on Wikipedia&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I was curious whether you could tell if someone used their phone! So I borrowed a GSM phone, tuned to the correct frequencies, and made some test calls.&lt;/p&gt;
    &lt;p&gt;What surprised me most: You can kind of âseeâ the volume at which I was talking!?&lt;/p&gt;
    &lt;p&gt;In the recording, the three dense bands at the end were when I was humming into the phone at the other end. This only worked in the âreceivingâ direction.&lt;/p&gt;
    &lt;head rend="h2"&gt;Wednesday&lt;/head&gt;
    &lt;head rend="h3"&gt;14: Receive signals from a satellite!&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 136-138 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I spent all Tuesday afternoon and evening learning about satellites. The program gpredict is really nice to find out when satellites will pass overhead! I learned a lot, including that one satellite I was trying to receive burned up last week! :D&lt;/p&gt;
    &lt;p&gt;I was super excited when I first received a signal from a NOAA satellite! ð°ï¸&lt;/p&gt;
    &lt;p&gt;But I didnât manage to decode it properly yet. Maybe my reception was too noisy? I wanted to keep trying, but I had to move on.&lt;/p&gt;
    &lt;head rend="h3"&gt;15: Admire TETRA signals&lt;/head&gt;
    &lt;p&gt;In Germany, the police has switched to an encrypted digital protocol called TETRA.&lt;/p&gt;
    &lt;p&gt;Even though Iâve seen some interesting talks at CCC events about weaknesses in the decryption, all I wanted to do for now is looking at the pretty signals in SDR++. :3&lt;/p&gt;
    &lt;head rend="h3"&gt;16: Listen to taxi dispatchers&lt;/head&gt;
    &lt;p&gt;Again, this is communication not meant for the general public.&lt;/p&gt;
    &lt;p&gt;I didnât listen to someone dispatching taxis to specific addresses, and you also shouldnât do that either. ð&lt;/p&gt;
    &lt;p&gt;Stay away from a site called âfrequenzdatenbankâ!&lt;/p&gt;
    &lt;head rend="h3"&gt;17: Ponder mysterious signals&lt;/head&gt;
    &lt;p&gt;Some of the most fun I had was just browsing frequencies and seeing what I can find! Sometimes, I encountered signals I canât identify.&lt;/p&gt;
    &lt;p&gt;For example, at 865-868 MHz, there was a family of slow, continuous, digital signals that made a nice melody when listened to in single-sideband demodulation!&lt;/p&gt;
    &lt;p&gt;And at 177-180 MHz, there were two very broadband transmissions. Might be TV? But I couldnât find out what type. (It later turned out that Iâd already listened to these signals â it was digital radio, DAB+.)&lt;/p&gt;
    &lt;head rend="h3"&gt;18: Track weather balloons&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 400-405.9 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As I was browsing around for things to receive, I saw on this tracking website that a radiosonde was just launched in Hamburg! SDRangel could decode its transmission! It had climbed to a height of 7 km, and itâs -17 Â°C there!&lt;/p&gt;
    &lt;p&gt;I knew that it would eventually burst and fall back to Earth, and that I could try to get to it and find it!&lt;/p&gt;
    &lt;head rend="h3"&gt;19: Hunt weather balloons!&lt;/head&gt;
    &lt;p&gt;I decided to go on a field trip, using trains and my bike.&lt;/p&gt;
    &lt;p&gt;I was following the tracker. The balloon popped earlier than predicted, and I frantically changed travel plans!&lt;/p&gt;
    &lt;p&gt;Eventually, it landed in a forest. I hoped I could get to it! What made this adventure more tricky was that my mobile Internet contract ran out while I was on the go, and my battery was also almost empty.&lt;/p&gt;
    &lt;p&gt;But I made it to the forest, and entered it.&lt;/p&gt;
    &lt;p&gt;As I circled the site, I encountered a person in their 60s, with a stubbly beard and a blue wool hat. He was looking in the direction of the crash site, and was holding a smartphone, so I asked him whether he also was looking for the radiosonde.&lt;/p&gt;
    &lt;p&gt;He was! We looked for it together for half an hour, jumping over small rivers and crawling through the woods, while he gave me a lot of tips related to hunting sondes.&lt;/p&gt;
    &lt;p&gt;He told me that he had found around 40 of them so far!&lt;/p&gt;
    &lt;p&gt;Usually, the sondes keep broadcasting after landing, but this one wasnât. So he quickly guessed that someone else couldâve taken it. Or maybe it landed in the water and died?&lt;/p&gt;
    &lt;p&gt;Some pictures of the area we searched:&lt;/p&gt;
    &lt;p&gt;Eventually, we gave up, and walked back to our vehicles. He also is an amateur radio operator, and could answer a couple of questions related to building antennas!&lt;/p&gt;
    &lt;p&gt;And he was right: Someone had been faster than us! The status was changed. So in the end, I didnât find the sonde. But something that might be even better â a friend!&lt;/p&gt;
    &lt;head rend="h3"&gt;20: Receive amateur packet radio&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 144.8 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In the 2-meter amateur band, there are certain frequencies for the âAutomatic Packet Reporting Systemâ. Itâs a bit like IP â packets have a âfromâ and a âtoâ. They can also broadcast their position, or weather data.&lt;/p&gt;
    &lt;p&gt;Some stations seem to announce themselves as repeaters, which probably help forward the packets to increase the range.&lt;/p&gt;
    &lt;p&gt;And two people seemed to be on a âfielddayâ, and broadcasted their location. :D&lt;/p&gt;
    &lt;p&gt;SDRangel can create a map automatically:&lt;/p&gt;
    &lt;head rend="h2"&gt;Thursday&lt;/head&gt;
    &lt;p&gt;I started the day by building an antenna!&lt;/p&gt;
    &lt;p&gt;This was going to be a simple ârandom wireâ antenna, to allow me to get better reception in the lower frequencies, which Iâve omitted so far (because I knew it would be much more fun with a better antenna)!&lt;/p&gt;
    &lt;p&gt;I measured out 21.6 m of wire (which for â¨magicâ¨ reasons seem to be a good universal antenna length)â¦&lt;/p&gt;
    &lt;p&gt;â¦directly attached it to the center of another SMA connectorâ¦&lt;/p&gt;
    &lt;p&gt;â¦and draped it all around my room!&lt;/p&gt;
    &lt;p&gt;People on the Internet say that there are many problems with this â that it would be better to have it outside, and that thereâs an impedance mismatch between the receiver and the wire.&lt;/p&gt;
    &lt;p&gt;I could address those problems, but I wanna try how well this works first :)&lt;/p&gt;
    &lt;head rend="h3"&gt;21: Receive Morse code from other countries&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 10.10-10.13 MHz&lt;/item&gt;
      &lt;item&gt;Modulation: CW (âcontinuous waveâ)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;On the 30-meter amateur band, I found people sending Morse code! :O&lt;/p&gt;
    &lt;p&gt;Iâd been learning it a little bit, so if I recorded it and slowed it down, I could understand it: Theyâre sending their callsigns. These are from Belgium, France, and Italy! \o/&lt;/p&gt;
    &lt;p&gt;I compared to my 2-meter dipole antenna, and the reception was definitely better â I can pick up more transmissions, and with much less noise!&lt;/p&gt;
    &lt;head rend="h3"&gt;22: Receive maritime weather reports&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 11.039 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The German Weather Service broadcasts maritime information throughout the day on various shortwave frequencies.&lt;/p&gt;
    &lt;p&gt;They use a protocol called RTTY (radioteletype), and it took me a while to decode it. But I found a neat little program called âfldigiâ: You can pipe audio to it (single side band modulation), and then if you pick the correct settings (see screenshot), it happily transcribes the messages!&lt;/p&gt;
    &lt;p&gt;Hereâs the station weather reports for the Baltic Sea and Northern Sea!&lt;/p&gt;
    &lt;head rend="h3"&gt;23: Receive digimodes from other countries&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 10.130-10.15 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I found some other strange signals on the 30-meter band. The Signal Identification Wiki was really helpful for figuring out what they were: FT8!&lt;/p&gt;
    &lt;p&gt;FT8 is quite a new protocol, invented in 2017, and it seems to be super popular right now! It allows you to transmit short messages, and again, people are looking for people to talk to (CQ), saying how well they receive each other, or saying goodbye (73).&lt;/p&gt;
    &lt;p&gt;This is the WSJT-X software.&lt;/p&gt;
    &lt;head rend="h3"&gt;24: Detect whether your notebook is charging&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: Below 1 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As I was browsing the very low-frequency bands, I had a strange problem: Sometimes, that would work okayish, sometimes I could even make out voices!&lt;/p&gt;
    &lt;p&gt;But other times, it wouldnât work at all, and everything would be loud, angry noise. Even in regions where I had better reception before!&lt;/p&gt;
    &lt;p&gt;Eventually, I found out how to solve that issue â by unplugging my notebook charger. Dâoh! :D&lt;/p&gt;
    &lt;head rend="h3"&gt;25 &amp;amp; 26: See ionosondes and radar signals&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 6-30 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In the low frequencies, occasionally, you can hear a short chirp! :D These are caused by ionosondes, scientific instruments which measure the properties of the ionosphere by sweeping a wide frequency spectrum.&lt;/p&gt;
    &lt;p&gt;Another signal (which I accidentally got in the same screenshot) is a radar system â in this case, according to the Signal Identification Wiki, itâs a âCODARâ system, used to measure the motion of water waves and currents along coasts! :O&lt;/p&gt;
    &lt;head rend="h3"&gt;27: Listen to âsingle side bandâ conversations&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: In all amateur bands, especially the ones below 30 MHz&lt;/item&gt;
      &lt;item&gt;Modulation: SSB (âsingle side bandâ)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;How do you transmit speech over long distances? You can use âamplitude modulationâ, where you change the volume of the carrier frequency to model your audio.&lt;/p&gt;
    &lt;p&gt;As a side effect, the bands to the sides of the carrier will contain a signal, as well.&lt;/p&gt;
    &lt;p&gt;One trick is to transmit just those sidebands, which saves power! But you have to âguessâ the base frequency when listening. Depending on which part you transmit, this is called âlower side bandâ or âupper side bandâ.&lt;/p&gt;
    &lt;p&gt;SDR++ makes it very easy to play with this! :) Hereâs someone from Serbia!&lt;/p&gt;
    &lt;head rend="h3"&gt;28: Listen to AM radio from the other side of the world&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: Shortwave bands below 26 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;At night, low-frequency radio waves can travel further around the world, because theyâre reflected by the layers of the ionosphere! Thereâs something magical about this.&lt;/p&gt;
    &lt;p&gt;I put my antenna outside, and I could hear a lot of broadcasting stations! On short-wave.info, you can look up where they are located.&lt;/p&gt;
    &lt;p&gt;Some stations in China are broadcasting with very high power! Some I could hear were over 7500 km away.&lt;/p&gt;
    &lt;p&gt;Wow. Itâs full of stars! ð&lt;/p&gt;
    &lt;head rend="h2"&gt;Friday&lt;/head&gt;
    &lt;p&gt;Originally, I had planned the project to run from Monday to Friday. When I still had 32 things to do in Friday morning, I knew Iâd need to extend it. But I hadnât run out of ideas yet:&lt;/p&gt;
    &lt;head rend="h3"&gt;29: Listen to CB radio&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 26.965-27.405 MHz&lt;/item&gt;
      &lt;item&gt;Modulation: FM or AM&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;After Iâd looked into the low frequencies on Thursday, I went to a higher band again: The Citizens Band!&lt;/p&gt;
    &lt;p&gt;This is the third frequency band Iâm aware of where anyone is allowed to transmit â provided that you use a licensed device!&lt;/p&gt;
    &lt;p&gt;This is a band where my random wire antenna really came in handy. Without it, I would have had a hard time understanding anything. And even with it, transmissions are extremely noisy.&lt;/p&gt;
    &lt;p&gt;CB radio is used internationally, especially by truck drivers, it seems.&lt;/p&gt;
    &lt;head rend="h3"&gt;30: Assess the propagation of radio waves using beacons&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 14.100, 18.110, 21.150, 24.930, and 28.200 MHz&lt;/item&gt;
      &lt;item&gt;Modulation: CW&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The International Beacon Project runs a network of 18 stations, which take turns transmitting their callsigns at certain frequencies.&lt;/p&gt;
    &lt;p&gt;Using this system, you can quickly get a sense of how well radio waves are currently propagating to your location. Clever!&lt;/p&gt;
    &lt;p&gt;I picked up the beacon from southern Finland! You can see its callsign scrolling away in the video. Itâs followed by four dashes send with decreasing power. I only heard the first oneâ¦&lt;/p&gt;
    &lt;head rend="h3"&gt;31: Receive a time signal&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 9996 kHz&lt;/item&gt;
      &lt;item&gt;Modulation: CW&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I wouldâve loved to receive DCF77, which powers the radio clocks in Germany! But no matter how hard I listened to 77.5 kHz, there was nothing there. I donât think my dongle can do that.&lt;/p&gt;
    &lt;p&gt;So I used higher frequencies! Russia transmits its âRWMâ time signal at 9996 kHz, which beeps every second, with a long beep for the full minute.&lt;/p&gt;
    &lt;p&gt;Not enough to tell the time, but enough to adjust your wrist watch, I guess!&lt;/p&gt;
    &lt;head rend="h3"&gt;32: Receive a weather fax&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 3855, 7880, and 13882.5 kHz (see weatherfax.com for more)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The German Weather Service broadcasts weather maps throughout the day! You can decode them using fldigiâs âWEFAX-576â setting.&lt;/p&gt;
    &lt;p&gt;I caught this one only halfway through. According to the schedule, itâs the âSurface weather chart North Atlantic, Europeâ!&lt;/p&gt;
    &lt;p&gt;If you squint really hard, you can make out the coast of Spain and the Mediterranean Sea on the right side!&lt;/p&gt;
    &lt;head rend="h3"&gt;33: Decode images from a weather satellite!&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 137.62, 137.9125, and 137.1 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I couldnât stop trying to capture a weather satellite, itâs just too cool to receive an image from space!&lt;/p&gt;
    &lt;p&gt;That evening, an American satellite called NOAA-15 passed right over us, so I thought Iâd try again. And this time, I got parts of an image! \o/&lt;/p&gt;
    &lt;p&gt;This is real-time data! At night, both transmitted images are infrared recordings.&lt;/p&gt;
    &lt;p&gt;I recorded the FM signal using SDR++, and then decoded the image using noaa-apt, which also added country outlines.&lt;/p&gt;
    &lt;head rend="h3"&gt;34: Estimate the speed of satellites&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 136-138 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Hereâs what the NOAA-15 weather satellite sounds like, by the way! tick-tock&lt;/p&gt;
    &lt;p&gt;While recording, I noticed something strange: The transmission didnât happen at the frequency I had expected it to! And also, the frequency changed.&lt;/p&gt;
    &lt;p&gt;Then it hit me: Doppler effect! At the time of the recording, the frequency was around 4250 Hz higher than expected.&lt;/p&gt;
    &lt;p&gt;After looking up the formula, I calculated a relative speed of 9 km/s! (Which got close to its real speed, 7.5 km/s.)&lt;/p&gt;
    &lt;head rend="h3"&gt;35: Listen to number stations&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 5-30 MHz?&lt;/item&gt;
      &lt;item&gt;Modulation: Differs by station&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These stations send encrypted messages using number sequences, possibly for espionage purposes!&lt;/p&gt;
    &lt;p&gt;So why not listen to one? Thereâs a surprisingly well-maintained database of them on a site call Priyom.&lt;/p&gt;
    &lt;p&gt;So I tuned into the next frequency that was listed, and: Bingo!&lt;/p&gt;
    &lt;p&gt;Allegedly, this was a station in Moscow. That day, it sent â218, 218, 218â in a loop, followed by three long beeps, which is the format of a ânull messageâ.&lt;/p&gt;
    &lt;p&gt;So no news for the Russian spies.&lt;/p&gt;
    &lt;head rend="h2"&gt;Saturday&lt;/head&gt;
    &lt;p&gt;The week was really intense for me. Initially, I thought Iâd do 10 things per day, but it turned out that that was too much. I had to learn so many new things.&lt;/p&gt;
    &lt;p&gt;Many things I tried donât work on my first attempt. Finding LoRaWAN signals, decoding packet radio, finding something on PMR446, decoding the satellite â those were all things that required a second (or third) attempt.&lt;/p&gt;
    &lt;p&gt;This project was exhausting, but also joyful â having committed to it, I got in a nice flow state, where I could focus on it for hours.&lt;/p&gt;
    &lt;p&gt;Often, I thought: âOkay, this is it. I canât possibly find more things.â But this is the power of the 50 Things technique: I have to keep looking, leave my comfort zone, be creative, try things I otherwise wouldnât have tried!&lt;/p&gt;
    &lt;p&gt;So, 15 more things, huh?&lt;/p&gt;
    &lt;head rend="h3"&gt;36: Receive images from amateur radio operators&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 14.230, 14.233, 21.340, 28.680, 145.625 MHz seem to be popular&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Using a protocol called âSSTVâ (slow-scan television), amateur radio operators send each other postcards! :D&lt;/p&gt;
    &lt;p&gt;Iâve been browsing the usual frequencies, and tried to decode images using the software QSSTV on Linux. And I accidentally caught a piece of what seems to be a test image!&lt;/p&gt;
    &lt;p&gt;SSTV has the prettiest noise! :3&lt;/p&gt;
    &lt;head rend="h3"&gt;37: Listen to The Buzzer&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 4625 kHz&lt;/item&gt;
      &lt;item&gt;Modulation: Upper side band&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Thereâs a mysterious Russian station broadcasting at 4625 kHz. Sometimes, it sends encrypted voice messages.&lt;/p&gt;
    &lt;p&gt;But usually, all it does is send a honking sound every two seconds, to deter other stations from using the same frequency.&lt;/p&gt;
    &lt;p&gt;The purpose of the station is unclear, but most theories think itâs military communication.&lt;/p&gt;
    &lt;head rend="h3"&gt;38: Catch a LoRaWAN chirp&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 868.1-868.5 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This was a bit like trying to catch a rare insect! ð&lt;/p&gt;
    &lt;p&gt;LoRaWAN is a low-power, wide-area networking protocol, intended for âInternet of Thingsâ applications.&lt;/p&gt;
    &lt;p&gt;You can see transmission in the lower half of the screenshot! It has a very cute structure: You can see eight âdown-chirpsâ, followed by two âup-chirpsâ. Thatâs the header, followed by the payload.&lt;/p&gt;
    &lt;p&gt;To look for the signal, I made a âbaseband captureâ in SDR++, and opened the recording in Sonic Visualizer.&lt;/p&gt;
    &lt;head rend="h3"&gt;39: Read data from utility meters&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 868.95 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Devices like smoke detectors or meters for water or heat are sending their readings via a protocol called Wireless M-Bus.&lt;/p&gt;
    &lt;p&gt;Again, I was surprised by how many devices seem to be around! Thanks for the tip, @envy :)&lt;/p&gt;
    &lt;p&gt;wmbusmeters is a really nice tool for decoding the messages.&lt;/p&gt;
    &lt;head rend="h3"&gt;40: âWatchâ TV&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 174-786 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The chips in my SDR stick are also being used in DVB-T dongles! So, can we watch TV? Unfortunately, no.&lt;/p&gt;
    &lt;p&gt;From what I pieced together, thereâs a difference between using the stick in SDR mode (where it sends the full spectrum), and in TV mode (where it sends the decoded video).&lt;/p&gt;
    &lt;p&gt;In Germany, thereâs now DVB-T2, which my hardware doesnât support in TV mode. And in SDR mode, the bandwidth is too narrow for DVB-T2. But we can scroll over a channel and look at it! :3&lt;/p&gt;
    &lt;head rend="h3"&gt;41: Track cars and buses&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 433.05-434.79 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Did a little walk to a big intersection, to see what âdevice signalsâ Iâd find there at 433 MHz.&lt;/p&gt;
    &lt;p&gt;I could confirm that the IBIS beacons are in fact being sent by buses! The included âvehicle IDâ even matches the white number thatâs printed on it.&lt;/p&gt;
    &lt;p&gt;I also saw some messages from tire pressure monitoring systems in cars! They also include an ID, and usually, the brand of the car! The owners probably arenât aware how easy it would be to track themâ¦ (Thanks, @scy!)&lt;/p&gt;
    &lt;p&gt;Side note: I wonder why some signals in that band are warped like the one at 433.96 MHz here!&lt;/p&gt;
    &lt;p&gt;At first, I thought âAh, Doppler effect again, itâs coming from a moving car!â But if thatâd be the case, that car would be moving at over 700 m/sâ¦&lt;/p&gt;
    &lt;p&gt;Friends later suspected that this effect is due to weak batteries affecting the crystal in the sending devices, or temperature changes.&lt;/p&gt;
    &lt;head rend="h3"&gt;42: Receive Morse code from a satellite!&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 145.860 (status information) and 145.960 (beacon)&lt;/item&gt;
      &lt;item&gt;Modulation: CW&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So I caught a satellite again! :D This time, it was school project, the Italian satellite âMax Valierâ. It continuously sends Morse code on a beacon frequency.&lt;/p&gt;
    &lt;p&gt;Pretty weak signal, but hereâs what I could hear:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;
3MV MAX VALIER SAT ... MANFRED ES CHRISTA FUKSE 73 ... II3MV ...
&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;Super happy about this! I got both the name of the satellite, as well as its callsign at the end, and what seems to be some kind of greeting? I later learned that &lt;code&gt;ES&lt;/code&gt; is Morse code shorthand for âandâ, and that Manfred and Christa Fuchs were the founders of a company that helped launch the satellite!&lt;/p&gt;
    &lt;p&gt;(Thanks for the tip, @manawyrm!)&lt;/p&gt;
    &lt;head rend="h3"&gt;43: Receive emergency service pagers&lt;/head&gt;
    &lt;p&gt;This is another thing thatâs not allowed in Germany, so you shouldnât do it.&lt;/p&gt;
    &lt;p&gt;Pagers use a format called âPOCSAGâ (Post Office Code Standardisation Advisory Groupâ¦), which you should not decode using multimon-ng.&lt;/p&gt;
    &lt;p&gt;Because you would find that the content is short and cryptic anyway. It would probably be repeated by several stations all around you, to make sure the whole region is covered.&lt;/p&gt;
    &lt;p&gt;Do not read the English Wikipedia page! It contains frequencies!&lt;/p&gt;
    &lt;head rend="h2"&gt;Sunday&lt;/head&gt;
    &lt;p&gt;At this point, I was pretty tired. Focusing on this project for 6 days straight took a lot of energy, and I was always uncertain if I could actually complete all 50 things in that week! But I woke up with a fun idea:&lt;/p&gt;
    &lt;head rend="h3"&gt;44: Detect when a smartphone is turned on&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 13.56 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I was curious whether I could see the NFC transceiver in my smartphone! And yeah, especially using my random wire antenna, this works really well!&lt;/p&gt;
    &lt;p&gt;My smartphone seems to emit at the NFC frequency a couple of times per second. And when unlocking the screen, it emits five very strong beeps on that frequency! I can see those from the other side of our apartment.&lt;/p&gt;
    &lt;p&gt;Surely, these signals are the same for every device, right? ð¶&lt;/p&gt;
    &lt;p&gt;Observe the five beeps here:&lt;/p&gt;
    &lt;head rend="h3"&gt;45: Communicate wirelessly usingâ¦ a book&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 13.56 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Piko and I played around with NFC a bit more, and we found out that when getting close to an NFC tag, a smartphone emits at 13.56 MHz continuously!&lt;/p&gt;
    &lt;p&gt;So, we started sending Morse code to each other between rooms, using a smartphone and a library book! :âD&lt;/p&gt;
    &lt;p&gt;Take that, Bundesnetzagentur!&lt;/p&gt;
    &lt;p&gt;Seems that the shortest signal you can create is 0.7 s long, resulting in a meager communication speed of 3-4 words per minuteâ¦&lt;/p&gt;
    &lt;head rend="h3"&gt;46: Receive navigational aids for airplanes&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frequency: 108.00-117.95 MHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are ground stations that emit a signal that allow calculating your angle relative to it! If you receive two, you can determine your position. (Thanks, @fly_it!)&lt;/p&gt;
    &lt;p&gt;I heard the one close to Hamburg! And SDRangel has a decoder, of course! It calculated angles between 210Â° and 230Â°, which is pretty close to the actual value of 224Â°! I donât think they are meant to be used from the ground.&lt;/p&gt;
    &lt;p&gt;The neat navigational map is from https://skyvector.com!&lt;/p&gt;
    &lt;p&gt;I spent ages trying to build my own decoder in GNU Radio. But I wasnât familiar with it at all, and I eventually gave up. Still, that seems to be the software you wanna learn for tasks like these!&lt;/p&gt;
    &lt;p&gt;By the way, how the ground stations work is fascinating: In my case, itâs a âDoppler VORâ: It transmits a static frequency via amplitude modulation, and adds another signal that moves around in circles, so you get a Doppler frequency shift.&lt;/p&gt;
    &lt;p&gt;If you compare the two, you can calculate the angle!&lt;/p&gt;
    &lt;head rend="h3"&gt;47: See how low you can go in the frequency spectrum&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Modulation: mostly AM&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This was a fun exploration: Whatâs the lowest-frequency broadcast I can receive?&lt;/p&gt;
    &lt;p&gt;The RTL-SDR Blog V4 stick Iâm using has a neat feature â a built-in âupconverterâ, which is enabled automatically when you try to listen to frequencies below what the chipset supports. This allows it to receive down to ~500 kHz!&lt;/p&gt;
    &lt;p&gt;The first stations that are comprehensible started at 1 MHz for me.&lt;/p&gt;
    &lt;head rend="h3"&gt;48: See how high you can go in the frequency spectrum&lt;/head&gt;
    &lt;p&gt;The chipset in my SDR stick go up to maximum frequency of 1766 MHz. It seems pretty quiet up there, probably because I lack proper antennas. I found these three lines in an amateur band, but they probably originate from the stick itself, or another device.&lt;/p&gt;
    &lt;p&gt;So the highest-frequency thing Iâve received is ADS-B at 1090 MHz (see entry #5)! ð&lt;/p&gt;
    &lt;head rend="h3"&gt;49: Listen to marine radio&lt;/head&gt;
    &lt;p&gt;Weâve been over this. Not allowed in Germany. Donât do it. â&lt;/p&gt;
    &lt;p&gt;But if youâre in the US, anyone can purchase a marine radio, and even use it to transmit! :D&lt;/p&gt;
    &lt;head rend="h3"&gt;50: Go mobile!&lt;/head&gt;
    &lt;p&gt;Just now, I was wondering whether there are any Android apps for controlling SDRs.&lt;/p&gt;
    &lt;p&gt;And it turned out, the software I liked best that week, SDR++, had an Android version since a couple of weeks! \o/&lt;/p&gt;
    &lt;p&gt;So now I could go track down the source of some of these strange signals! :3&lt;/p&gt;
    &lt;head rend="h2"&gt;Looking back&lt;/head&gt;
    &lt;p&gt;And with that, â¦ ð¥ â¦ I was officially done with my â50 things to do with a software defined radioâ! ð&lt;/p&gt;
    &lt;p&gt;This were seven very intense days, where I learned a lot of new things about radio waves and the many things they can be used for!&lt;/p&gt;
    &lt;p&gt;I was proud! I was tired! I was amazed that all those things I received are all around us, everywhere, all at once â if you know where to look. :O&lt;/p&gt;
    &lt;head rend="h2"&gt;More things to explore&lt;/head&gt;
    &lt;p&gt;Hereâs some things that I havenât tried or that havenât worked:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Receiving digital voice modes (SDRangel should be able to do it, but I couldnât figure it out)&lt;/item&gt;
      &lt;item&gt;Receive something from the ISS&lt;/item&gt;
      &lt;item&gt;Use the GRAVES radar to detect meteors (couldnât detect it)&lt;/item&gt;
      &lt;item&gt;Receive videos on ham bands&lt;/item&gt;
      &lt;item&gt;Receive Iridium satellites&lt;/item&gt;
      &lt;item&gt;Listen to pirate stations&lt;/item&gt;
      &lt;item&gt;Receive Cubesat&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Also, doing things with Wi-Fi/Bluetooth/Zigbee could be fun, but Iâd need a more expensive receiver for those frequencies.&lt;/p&gt;
    &lt;head rend="h2"&gt;Future thoughts&lt;/head&gt;
    &lt;p&gt;So, was this project in fact a gateway drug to getting an amateur radio license?&lt;/p&gt;
    &lt;p&gt;Yeah, probably. Iâd love to transmit something and experiment more! :D&lt;/p&gt;
    &lt;p&gt;In Germany, a new license class will be introduced in summer 2024, thatâll allow you to send on the 10-meter, 2-meter and 70-cm bands (the âN classâ).&lt;/p&gt;
    &lt;p&gt;In fact, thereâs a really good German online course that teaches you everything you need to know: 50ohm.de&lt;/p&gt;
    &lt;p&gt;Highly recommended, even if youâre not planning on getting a license.&lt;/p&gt;
    &lt;p&gt;Finally, thanks to Piko, Chris, and Cqoicebordel for proof-reading this blog post! &amp;lt;3&lt;/p&gt;
    &lt;head rend="h2"&gt;Join the discussion!&lt;/head&gt;
    &lt;p&gt;You can add your comment in the Fediverse! Alternatively, drop me a mail at mail@blinry.org. Also, you can support me on Patreon or subscribe to my newsletter&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45262835</guid><pubDate>Tue, 16 Sep 2025 14:35:19 +0000</pubDate></item><item><title>A new experimental Google app for Windows</title><link>https://blog.google/products/search/google-app-windows-labs/</link><description>&lt;doc fingerprint="59ea9b23e3b72fc2"&gt;
  &lt;main&gt;
    &lt;p&gt;Today, we’re launching a new experimental Google app for Windows in Labs to help you find what you need, faster.&lt;/p&gt;
    &lt;p&gt;Now you can search without switching windows or interrupting your flow. Whether you're writing in a doc or in the middle of a game, just press Alt + Space to instantly search for information from your computer files, installed apps, Google Drive files — and of course, the web.&lt;/p&gt;
    &lt;p&gt;With Google Lens built in, you can select and search anything on your screen, making it easy to translate images or text, get help with homework problems and more. You can also get deeper AI-powered responses in AI Mode and keep exploring with follow-up questions and helpful links.&lt;/p&gt;
    &lt;p&gt;Try it for yourself by opting into the experiment in Labs.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45263317</guid><pubDate>Tue, 16 Sep 2025 15:05:46 +0000</pubDate></item><item><title>Plugin System</title><link>https://iina.io/plugins/</link><description>&lt;doc fingerprint="f0ec3c5b09ddb6d2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Plugin System&lt;/head&gt;
    &lt;p&gt;The plugin system allows you to extend IINA's functionality with JavaScript. You can control the playback, call the mpv API, access the network and file system, adding custom UI elements, and more. The plugin system is available in IINA 1.4.0.&lt;/p&gt;
    &lt;head rend="h4"&gt;Concise API, powerful features&lt;/head&gt;
    &lt;p&gt;With several lines of code, you can implement the exact feature tailored to your needs. Furthermore, with the Official User Scripts plugin, you can just copy-and-paste code snippets into IINA without writing plugin packages.&lt;/p&gt;
    &lt;quote&gt;const { core, event, overlay } = iina;&lt;lb/&gt;event.on("iina.file-loaded", () =&amp;gt; {&lt;lb/&gt;overlay.simpleMode();&lt;lb/&gt;overlay.setContent(`&amp;lt;p&amp;gt;${core.status.title}&amp;lt;/p&amp;gt;`);&lt;lb/&gt;overlay.setStyle(`p { font-size: 48px; }`);&lt;lb/&gt;overlay.show();&lt;lb/&gt;})&lt;/quote&gt;
    &lt;p&gt;Display the video title in a large font on the top of the video&lt;/p&gt;
    &lt;quote&gt;const { core, event } = iina;&lt;lb/&gt;event.on("mpv.pause.changed", () =&amp;gt; {&lt;lb/&gt;core.window.miniaturized = core.status.paused;&lt;lb/&gt;});&lt;lb/&gt;event.on("iina.window-deminiaturized", () =&amp;gt; {&lt;lb/&gt;core.resume();&lt;lb/&gt;});&lt;/quote&gt;
    &lt;p&gt;Minimize the window when the video is paused, and resume when restored&lt;/p&gt;
    &lt;head rend="h4"&gt;What you can do with the plugin system&lt;/head&gt;
    &lt;p&gt;Core&lt;/p&gt;
    &lt;p&gt;Control the playback and get/set various status from the window frame to subtitle tracks.&lt;/p&gt;
    &lt;p&gt;MPV&lt;/p&gt;
    &lt;p&gt;Access the mpv API with properties and hooks for advanced playback control.&lt;/p&gt;
    &lt;p&gt;Event&lt;/p&gt;
    &lt;p&gt;Register and remove listeners for IINA and mpv events.&lt;/p&gt;
    &lt;p&gt;HTTP&lt;/p&gt;
    &lt;p&gt;Make HTTP and XMLRPC requests.&lt;/p&gt;
    &lt;p&gt;Playlist&lt;/p&gt;
    &lt;p&gt;Control the playlist and add custom playlist context menu items.&lt;/p&gt;
    &lt;p&gt;Subtitle&lt;/p&gt;
    &lt;p&gt;Register custom subtitle downloaders that integrates with IINA's user interface.&lt;/p&gt;
    &lt;p&gt;Menu&lt;/p&gt;
    &lt;p&gt;Add menu items with keyboard shortcuts under the Plugin menu.&lt;/p&gt;
    &lt;p&gt;Overlay&lt;/p&gt;
    &lt;p&gt;Render custom webview-based content on the top of videos.&lt;/p&gt;
    &lt;p&gt;Sidebar View&lt;/p&gt;
    &lt;p&gt;Add a tab in the sidebar with custom webview-based contents.&lt;/p&gt;
    &lt;p&gt;Standalone Window&lt;/p&gt;
    &lt;p&gt;Display a webview-based standalone window for complicated user interface.&lt;/p&gt;
    &lt;p&gt;Global Controller&lt;/p&gt;
    &lt;p&gt;Spawn and control multiple player instances.&lt;/p&gt;
    &lt;p&gt;File&lt;/p&gt;
    &lt;p&gt;Access the user file system or read/write sandboxed temporary files and data files.&lt;/p&gt;
    &lt;p&gt;Preferences&lt;/p&gt;
    &lt;p&gt;Store preferences and display a settings page in IINA's preferences panel.&lt;/p&gt;
    &lt;p&gt;Utils&lt;/p&gt;
    &lt;p&gt;Display system dialogs and run custom executables.&lt;/p&gt;
    &lt;p&gt;Console&lt;/p&gt;
    &lt;p&gt;Print logs for debugging, viewable from IINA's log viewer.&lt;/p&gt;
    &lt;head rend="h4"&gt;Start building your plugin&lt;/head&gt;
    &lt;p&gt;An &lt;code&gt;iina-plugin&lt;/code&gt; command line tool is included with the IINA installation to help you create, build, and run plugins.
We have also prepared a complete documentation with tutorials and API references.&lt;/p&gt;
    &lt;p&gt;at docs.iina.io&lt;/p&gt;
    &lt;p&gt;You may also find these resources helpful:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Official User Scripts plugin: simply enter &lt;code&gt;iina/iina-plugin-userscript&lt;/code&gt;when installing.&lt;/item&gt;
      &lt;item&gt;TypeScript definitions: TypeScript definitions for the plugin API. It is included automatically when you create a new plugin with the &lt;code&gt;iina-plugin&lt;/code&gt;command line tool.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45264190</guid><pubDate>Tue, 16 Sep 2025 16:10:44 +0000</pubDate></item><item><title>Waymo has received our pilot permit allowing for commercial operations at SFO</title><link>https://waymo.com/blog/#short-all-systems-go-at-sfo-waymo-has-received-our-pilot-permit</link><description>&lt;doc fingerprint="db87b0168e9549f1"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;All systems go at SFO! Waymo has received our pilot permit allowing for commercial operations at San Francisco International Airport.&lt;/p&gt;
      &lt;p&gt;We’ll partner with SFO to prepare our operations at the airport in phases, beginning with employee testing soon ahead of welcoming Bay Area riders. Pickups and dropoffs will initially start at SFO’s Kiss &amp;amp; Fly area – a short AirTrain ride from the terminals – with the intention to explore other locations at the airport in the future.&lt;/p&gt;
      &lt;p&gt;This is a major milestone that strengthens Waymo’s impact on the region and offers residents and visitors an innovative way to travel. With years of experience serving riders at Phoenix Sky Harbor (PHX) and operations beginning soon at San Jose Mineta International Airport (SJC), we’re accelerating our efforts to serve more airports in more cities as we scale.&lt;/p&gt;
      &lt;p&gt;“Across San Francisco, we are expanding safe, reliable, and modern transportation options—supporting our city’s economic comeback, boosting our tourism industry, and connecting residents and visitors to everything our city has to offer,” said Mayor Lurie. “We announced in March that we wanted visitors to be able to ride in a Waymo as soon as they arrived in San Francisco, and today, we are taking another important step to get there.”&lt;/p&gt;
      &lt;p&gt;“Bringing the Waymo experience to San Francisco International Airport is about more than just a ride—it’s about providing a safe, reliable, magical way for Bay Area residents and global visitors to connect with the places and people that matter most,” said Tekedra Mawakana, co-CEO, Waymo. “We’re grateful for the partnership with SFO and the vision of Mayor Lurie in making this a reality.”&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45264562</guid><pubDate>Tue, 16 Sep 2025 16:38:08 +0000</pubDate></item><item><title>Scammed out of $130K via fake Google call, spoofed Google email and auth sync</title><link>https://bewildered.substack.com/p/i-was-scammed-out-of-130000-and-google</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45264726</guid><pubDate>Tue, 16 Sep 2025 16:50:42 +0000</pubDate></item><item><title>Launch HN: Rowboat (YC S24) – Open-source IDE for multi-agent systems</title><link>https://github.com/rowboatlabs/rowboat</link><description>&lt;doc fingerprint="9cd53c59514fa0b8"&gt;
  &lt;main&gt;
    &lt;p&gt; ⚡ Build AI agents instantly with natural language | 🔌 Connect tools with one-click integrations | 📂 Power with knowledge by adding documents for RAG | 🔄 Automate workflows by setting up triggers and actions | 🚀 Deploy anywhere via API or SDK&lt;lb/&gt; ☁️ Prefer a hosted version? Use our cloud to starting building agents right away! &lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Set your OpenAI key&lt;/p&gt;
        &lt;code&gt;export OPENAI_API_KEY=your-openai-api-key&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Clone the repository and start Rowboat (requires Docker)&lt;/p&gt;
        &lt;code&gt;git clone git@github.com:rowboatlabs/rowboat.git cd rowboat ./start.sh&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Access the app at http://localhost:3000.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To add tools, RAG, more LLMs, and triggers checkout the Advanced section below.&lt;/p&gt;
    &lt;p&gt;Chat with the copilot to build a meeting-prep workflow, then add a calendar invite as a trigger. Watch the full demo here.&lt;/p&gt;
    &lt;p&gt;Chat with the copilot to build a customer support assistant, then connect your MCP server, and data for RAG. Watch the full demo here.&lt;/p&gt;
    &lt;p&gt;Chat with the copilot to build a personal assistant. Watch the full demo here.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Native RAG Support: Enable file uploads and URL scraping with Rowboat's built-in RAG capabilities – see RAG Guide.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Custom LLM Providers: Use any LLM provider, including aggregators like OpenRouter and LiteLLM - see Using more LLM providers.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Tools &amp;amp; Triggers: Add tools and event triggers (e.g., Gmail, Slack) for automation – see Tools &amp;amp; Triggers.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;API &amp;amp; SDK: Integrate Rowboat agents directly into your app – see API &amp;amp; SDK docs.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Refer to Docs to learn how to start building agents with Rowboat.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45264867</guid><pubDate>Tue, 16 Sep 2025 17:01:16 +0000</pubDate></item><item><title>The Linux Process Journey (2023) [pdf]</title><link>https://thelearningjourneyebooks.com/wp-content/uploads/2023/09/TheLinuxProcessJourney_v6_Sep2023.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45265610</guid><pubDate>Tue, 16 Sep 2025 18:01:42 +0000</pubDate></item><item><title>Denmark close to wiping out cancer-causing HPV strains after vaccine roll-out</title><link>https://www.gavi.org/vaccineswork/denmark-close-wiping-out-leading-cancer-causing-hpv-strains-after-vaccine-roll-out</link><description>&lt;doc fingerprint="2714216008bd02a0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Denmark close to wiping out leading cancer-causing HPV strains after vaccine roll-out&lt;/head&gt;
    &lt;p&gt;A nationwide study suggests infections with human papillomavirus (HPV) types 16 and 18 have been virtually eliminated since vaccination began in 2008 – protecting even unvaccinated women.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2 September 2025&lt;/item&gt;
      &lt;item&gt;3 min read&lt;/item&gt;
      &lt;item&gt;by Linda Geddes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Denmark has effectively eliminated infections with the two biggest cancer-causing strains of human papillomavirus (HPV) since the vaccine was introduced in 2008, data suggests.&lt;/p&gt;
    &lt;p&gt;The research, published in Eurosurveillance, could have implications for how vaccinated populations are screened in the coming years – particularly as people increasingly receive vaccines that protect against multiple high-risk types of HPV virus.&lt;/p&gt;
    &lt;head rend="h3"&gt;Deadly cancer&lt;/head&gt;
    &lt;p&gt;After breast cancer, cervical cancer is the most common type of cancer among women aged 15 to 44 years in Europe, and human papillomavirus (HPV) is the leading cause.&lt;/p&gt;
    &lt;p&gt;At least 14 high-risk types of the virus have been identified, and before Denmark introduced the HPV vaccine in 2008, HPV types 16 and 18 accounted for around three quarters (74%) of cervical cancers in the country.&lt;/p&gt;
    &lt;p&gt;Initially, girls were offered a vaccine that protected against four types of HPV: 16, 18, plus the lower risk types 6 and 11. However, since 2017, Danish girls have been offered a vaccine that protects against nine types of HPV – including those accounting for approximately 90% of cervical cancers.&lt;/p&gt;
    &lt;head rend="h4"&gt;Have you read?&lt;/head&gt;
    &lt;p&gt;To better understand the impact that these vaccination programmes have had on HPV prevalence as vaccinated girls reach cervical screening age (23 to 64 years in Denmark), Dr Mette Hartmann Nonboe at Zealand University Hospital in Nykøbing Falster and colleagues analysed up to three consecutive cervical cell samples collected from Danish women between 2017 and 2024, when they were 22 to 30 years of age.&lt;/p&gt;
    &lt;p&gt;“In 2017, one of the first birth cohorts of women in Denmark who were HPV-vaccinated as teenage girls in 2008 reached the screening age of 23 years,” Nonboe explained.&lt;/p&gt;
    &lt;p&gt;“Compared with previous generations, these women are expected to have a considerably lower risk of cervical cancer, and it is pertinent to assess [their] future need for screening.”&lt;/p&gt;
    &lt;head rend="h3"&gt;High-risk HPV elimination&lt;/head&gt;
    &lt;p&gt;The research found that infection with the high-risk HPV types (HPV16/18) covered by the vaccine has been almost eliminated.&lt;/p&gt;
    &lt;p&gt;“Before vaccination, the prevalence of HPV16/18 was between 15 and 17%, which has decreased in vaccinated women to less than one percent by 2021,” the researchers said.&lt;/p&gt;
    &lt;p&gt;In addition, prevalence of HPV types 16 and 18 in women who had not been vaccinated against HPV was five percent. This strongly suggests that the vaccine has reduced the circulation of these HPV types in general population, to the extent that even unvaccinated women are now less likely to be infected with them – so called “population immunity” – the researchers said.&lt;/p&gt;
    &lt;p&gt;Despite this good news, roughly one third of women screened during the study period still had infection with high-risk HPV types not covered by the original vaccines – and new infections with these types were more frequent among vaccinated women, compared to unvaccinated ones.&lt;/p&gt;
    &lt;p&gt;This is expected to fall once girls who received the more recent ‘nine-valent’ vaccine reach screening age. At this point, the screening guidelines should potentially be reconsidered, Nonboe and colleagues said.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45265745</guid><pubDate>Tue, 16 Sep 2025 18:12:29 +0000</pubDate></item><item><title>How to make the Framework Desktop run even quieter</title><link>https://noctua.at/en/how-to-make-the-framework-desktop-run-even-quieter</link><description>&lt;doc fingerprint="1dfb18b60853d5bb"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How to make the Framework Desktop run even quieter&lt;/head&gt;
    &lt;head rend="h2"&gt;How to make the Framework Desktop run even quieter&lt;/head&gt;
    &lt;p&gt;Not so long ago, the compact, small form factor PC segment witnessed a significant refreshment with the launch of the Framework desktop PC. If you've missed it and are wondering why this mini-PC is considered so special, it's because it was the first desktop PC to utilise the AMD Ryzen AI Max APU, a processor previously exclusive to laptops.&lt;/p&gt;
    &lt;p&gt;The AMD Ryzen AI Max processor stands out for its exceptional speed and integrated graphics performance, frequently surprising users with its gaming capabilities, even on demanding titles. Users often highlight its powerful integrated GPU, which can leverage a massive memory pool (up to 96GB for AI tasks), allowing it to efficiently handle complex AI and deep learning workloads. The raw performance delivered by this chip makes it a worthwhile choice for intensive tasks and creative workflows.&lt;/p&gt;
    &lt;p&gt;As a collaborator and partner on the Framework Desktop mini-PC project, our first steps involved integrating our NF-A12x25 fan and a fan duct. This way, we could significantly reduce system noise levels while ensuring safe operating temperatures – you can read more about this here. But can the Framework Desktop be made even quieter? We wanted to leave no stone unturned to find out, so we took it a step further by trying to integrate our signature Noctua fan grill design that debuted on the Seasonic Prime TX-1600 Noctua Edition power supply.&lt;/p&gt;
    &lt;p&gt;It must be noted that customer safety and EMC requirements for the mini PC, a standalone electrical item, differ from those for hardware components (such as the PSU) designed to be inside a PC case. The safety standard suggests that ventilation openings on case side panels need to be less than 5mm in diameter. To comply with safety regulations, we created an updated version of the original fan grille as implemented on the Seasonic Prime TX 1600 Noctua Edition power supply featuring more struts and a smaller opening size, ensuring full adherence to these standards. To complement the new grille design, we have also designed a custom, funnel shaped fan duct that makes maximum use of the outermost openings of the custom side panel.&lt;/p&gt;
    &lt;p&gt;In combination, the custom side panel and duct design provided a massive noise reduction compared to the stock configuration, particularly in lower fan speed ranges. We have measured around 7 dB(A) lower noise levels at around 50% fan speed, and up to 5 dB(A) lower at higher fan speeds, when compared at the same APU operating temperature.&lt;/p&gt;
    &lt;p&gt;While the custom side panel with our signature Noctua grill as well as the custom fan duct are not slated for mass production at this point, we are more than happy to share the 3D CAD files for everyone who is looking to make their Framework Desktop run even quieter.&lt;/p&gt;
    &lt;p&gt;Both the custom side panel and the customised fan ductare available to download at Printables.com for you to 3D-print at home:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Custom side panel with Noctua-style fan grill&lt;/item&gt;
      &lt;item&gt;Custom fan duct to make best use of the custom side panel&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Fortunately, the quality of 3D printing technologies has advanced so much that you can end up with a nice, clean side panel, which will additionally optimise the sound profile, or bring your APU temperatures down significantly.&lt;/p&gt;
    &lt;p&gt;In addition to redesigning and testing the Noctua fan grill, we also evaluated various other scenarios. These included replacing the NF-A12x25 with its G2 variant and incorporating an additional 8cm fan for exhaust purposes. The findings of these tests may prove surprising. The additional NF-A8 PWM fan, which was added as an exhaust fan at the front of the case, yielded slightly lower temperatures, but at the expense of extra noise emission, so it’s not a setup that we would recommend from a performance-to-noise efficiency point of view.&lt;/p&gt;
    &lt;p&gt;While upgrading to an NF-A12x25 G2 does provide some acoustical benefits compared to the stock setup (around 1 to 1.5 dB(A) lower noise levels at the same temperatures), its maximum speed is limited to 1800 RPM, so it cannot match the performance headroom of the 2400 RPM HS-PWM version of the NF-A12x25 that is supplied with the Framework Desktop PC. This high-speed version of the „G1“ fan is a safeguard that ensures the system can maintain full performance in worst-case conditions with high ambient temperatures. In other words, we would only recommend upgrading to the NF-A12x25 G2 if you seek to lower noise levels as much as possible and if you are willing to sacrifice the maximum performance headroom in worst-case scenarios that the G1 HS-PWM fan provides.&lt;/p&gt;
    &lt;p&gt;In summary, after a lot of simulation, experimenting and testing, we can conclude that not all tweaks to the Framework Desktop’s cooling setup make sense. However, if you have access to a 3D printer, swapping the stock side panel and fan duct for the custom designed ones can help to make your unit run significantly quieter.&lt;/p&gt;
    &lt;p&gt;Related products:&lt;/p&gt;
    &lt;p&gt;Your opinion matters!&lt;/p&gt;
    &lt;p&gt;We are excited to invite you to participate in our short website survey. It will only take 5 minutes of your time!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45266039</guid><pubDate>Tue, 16 Sep 2025 18:33:21 +0000</pubDate></item><item><title>Should We Drain the Everglades?</title><link>https://rabbitcavern.substack.com/p/should-we-drain-the-everglades</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45266854</guid><pubDate>Tue, 16 Sep 2025 19:33:35 +0000</pubDate></item><item><title>The "Most Hated" CSS Feature: Cos() and Sin()</title><link>https://css-tricks.com/the-most-hated-css-feature-cos-and-sin/</link><description>&lt;doc fingerprint="3f01bb27012dfba9"&gt;
  &lt;main&gt;&lt;p&gt;No feature is truly “the worst” in CSS, right? After all, it’s all based on opinion and personal experience, but if we had to reach a consensus, checking the State of CSS 2025 results would be a good starting point. I did exactly that, jumped into the awards section, and there I found it: the “Most Hated Feature,” a title no CSS should have bear…&lt;/p&gt;&lt;p&gt;This shocks me, if I’m being honest. Are really trigonometric functions really that hated? I know “hated” is not the same as saying something is “worst”, but it still has an awful ring to it. And I know I’m being a little dramatic here, since only “9.1% of respondents truly hate trigonometry.” But that’s still too much shade being thrown for my taste.&lt;/p&gt;&lt;p&gt;I want to eliminate that 9.1%. So, in this series, I want to look at practical uses for CSS trigonometric functions. We’ll tackle them in pieces because there’s a lot to take in and I find it easiest to learn and retain information when it’s chunked into focused, digestible pieces. And we’ll start with what may be the most popular functions of the “worst” feature: &lt;code&gt;sin()&lt;/code&gt; and &lt;code&gt;cos()&lt;/code&gt;.&lt;/p&gt;&lt;head rend="h4"&gt;CSS Trigonometric Functions: The “Most Hated” CSS Feature&lt;/head&gt;&lt;list rend="ol"&gt;&lt;item&gt;&lt;code&gt;sin()&lt;/code&gt;and&lt;code&gt;cos()&lt;/code&gt;(You are here!)&lt;/item&gt;&lt;item&gt;Tackling the CSS &lt;code&gt;tan()&lt;/code&gt;Function (coming soon)&lt;/item&gt;&lt;item&gt;Inverse functions: &lt;code&gt;asin()&lt;/code&gt;,&lt;code&gt;acos()&lt;/code&gt;,&lt;code&gt;atan()&lt;/code&gt;and&lt;code&gt;atan2()&lt;/code&gt;(coming soon)&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;&lt;code&gt;cos()&lt;/code&gt; and &lt;code&gt;sin()&lt;/code&gt; anyway?&lt;/head&gt; What the heck are &lt;p&gt;This section is for those who &lt;code&gt;cos()&lt;/code&gt; and &lt;code&gt;sin()&lt;/code&gt; don’t quite click yet, or simply want a refresher. If you aced trigonometry quizzes in high school, feel free to skip ahead to the next section!&lt;/p&gt;&lt;p&gt;What I find funny about &lt;code&gt;cos()&lt;/code&gt; and &lt;code&gt;sin()&lt;/code&gt;— and also why I think there is confusion around them — is the many ways we can describe them. We don’t have to look too hard. A quick glance at this Wikipedia page has an eye-watering number of super nuanced definitions.&lt;/p&gt;&lt;p&gt;This is a learning problem in the web development field. I feel like some of those definitions are far too general and lack detail about the essence of what trigonometric functions like &lt;code&gt;sin()&lt;/code&gt; and &lt;code&gt;cos()&lt;/code&gt; can do. Conversely, other definitions are overly complex and academic, making them tough to grok without an advanced degree.&lt;/p&gt;&lt;p&gt;Let’s stick to the sweet middle spot: the unit circle.&lt;/p&gt;&lt;p&gt;Meet the unit circle. It is a circle with a radius of one unit:&lt;/p&gt;&lt;p&gt;Right now it’s alone… in space. Let’s place it on the Cartesian coordinate system (the classic chart with X and Y axes). We describe each point in space in Cartesian coordinates:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;The X coordinate: The horizontal axis, plotting the point towards the left or right.&lt;/item&gt;&lt;item&gt;The Y coordinate: The vertical axis, plotting the point towards the top or bottom.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;We can move through the unit circle by an angle, which is measured from the positive X-axis going counter-clockwise.&lt;/p&gt;&lt;p&gt;We can go in a clockwise direction by using negative angles. As my physics teacher used to say, “Time is negative!”&lt;/p&gt;&lt;p&gt;Notice how each angle lands on a unique point in the unit circle. How else can we describe that point using Cartesian coordinates?&lt;/p&gt;&lt;p&gt;When the angle is &lt;code&gt;0°&lt;/code&gt; the X and Y coordinates are 1 and 0 (&lt;code&gt;1&lt;/code&gt;, &lt;code&gt;0&lt;/code&gt;), respectively. We can deduce the Cartesian coordinates for other angles just as easily, like &lt;code&gt;90°&lt;/code&gt;, &lt;code&gt;180°&lt;/code&gt; and &lt;code&gt;270°&lt;/code&gt;. But for any other angle, we don’t know where the point is initially located on the unit circle.&lt;/p&gt;&lt;p&gt;If only there were a pair of functions that take an angle and give us our desired coordinates…&lt;/p&gt;&lt;p&gt;You guessed it, the CSS &lt;code&gt;cos()&lt;/code&gt; and &lt;code&gt;sin()&lt;/code&gt; functions do exactly that. And they’re very closely related, where &lt;code&gt;cos()&lt;/code&gt; is designed to handle the X coordinate and &lt;code&gt;sin()&lt;/code&gt; returns the Y coordinate.&lt;/p&gt;&lt;p&gt;Play with the toggle slider in the following demo to see the relationship between the two functions, and notice how they form a right triangle with the initial point on the unit circle:&lt;/p&gt;&lt;p&gt;I think that’s all you really need to know about &lt;code&gt;cos()&lt;/code&gt; and &lt;code&gt;sin()&lt;/code&gt; for the moment. They’re mapped to Cartesian coordinates, which allows us to track a point along the unit circle with an angle, no matter what size that circle happens to be.&lt;/p&gt;&lt;p&gt;Let’s dive into what we can actually use &lt;code&gt;cos()&lt;/code&gt; and &lt;code&gt;sin()&lt;/code&gt; for our everyday CSS work. It’s always good to put a little real-world context to theoretical concepts like math.&lt;/p&gt;&lt;head rend="h3"&gt;Circular layouts&lt;/head&gt;&lt;p&gt;If we go by the unit circle definition of &lt;code&gt;cos()&lt;/code&gt; and &lt;code&gt;sin()&lt;/code&gt;, then it’s easy to see how they might be used to create circular layouts in CSS.  The initial setup is a single row of circular elements:&lt;/p&gt;&lt;p&gt;Say we want to place each circular item around the outline of a larger circle instead. First, we would let CSS know the total number of elements and also each element’s index (the order it’s in), something we can do with an inline CSS variable that holds each order in the position:&lt;/p&gt;&lt;code&gt;&amp;lt;ul style="--total: 9"&amp;gt;
  &amp;lt;li style="--i: 0"&amp;gt;0&amp;lt;/li&amp;gt;
  &amp;lt;li style="--i: 1"&amp;gt;1&amp;lt;/li&amp;gt;
  &amp;lt;li style="--i: 2"&amp;gt;2&amp;lt;/li&amp;gt;
  &amp;lt;li style="--i: 3"&amp;gt;3&amp;lt;/li&amp;gt;
  &amp;lt;li style="--i: 4"&amp;gt;4&amp;lt;/li&amp;gt;
  &amp;lt;li style="--i: 5"&amp;gt;5&amp;lt;/li&amp;gt;
  &amp;lt;li style="--i: 6"&amp;gt;6&amp;lt;/li&amp;gt;
  &amp;lt;li style="--i: 7"&amp;gt;7&amp;lt;/li&amp;gt;
  &amp;lt;li style="--i: 8"&amp;gt;8&amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;&lt;/code&gt;



&lt;p&gt;Note: This step will become much easier and concise when the &lt;code&gt;sibling-index()&lt;/code&gt; and &lt;code&gt;sibling-count()&lt;/code&gt; functions gain support (and they’re really neat). I’m hardcoding the indexes with inline CSS variables in the meantime.&lt;/p&gt;&lt;p&gt;To place the items around the outline of a larger circle, we have to space them evenly by a certain angle. And to get that angle, we can divide &lt;code&gt;360deg&lt;/code&gt; (a full turn around the circle) by the total number of items, which is 8 in this specific example. Then, to get each element’s specific angle, we can multiply the angle spacing by the element’s index (i.e., position):&lt;/p&gt;&lt;code&gt;li {
  --rotation: calc(360deg / var(--total) * var(--i));
}&lt;/code&gt;



&lt;p&gt;We also need to push the items away from the center, so we’ll assign a &lt;code&gt;--radius&lt;/code&gt; value for the circle using another variable.&lt;/p&gt;&lt;code&gt;ul {
  --radius: 10rem;
}&lt;/code&gt;



&lt;p&gt;We have the element’s angle and radius. What’s left is to calculate the X and Y coordinates for each item.&lt;/p&gt;&lt;p&gt;That’s where &lt;code&gt;cos()&lt;/code&gt; and &lt;code&gt;sin()&lt;/code&gt; come into the picture. We use them to get the X and Y coordinates that place each item around the unit circle, then multiply each coordinate by the &lt;code&gt;--radius&lt;/code&gt; value to get an item’s final position on the bigger circle:&lt;/p&gt;&lt;code&gt;li {
  /* ... */
  position: absolute;

  transform: translateX(calc(cos(var(--rotation)) * var(--radius))) 
             translateY(calc(sin(var(--rotation)) * var(--radius)));
}&lt;/code&gt;



&lt;p&gt;That’s it! We have a series of eight circular items placed evenly around the outline of a larger circle:&lt;/p&gt;&lt;p&gt;And we didn’t need to use a bunch of magic numbers to do it! All we provide CSS with is the unit circle’s radius, and then CSS does all the trigonometric gobbledygook that makes so many of us call this the “worst” CSS feature. Hopefully, I’ve convinced you to soften your opinions on them if that’s what was holding you back!&lt;/p&gt;&lt;p&gt;We aren’t limited to full circles, though! We can also have a semicircular arrangement by choosing &lt;code&gt;180deg&lt;/code&gt; instead of &lt;code&gt;360deg&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;This opens up lots of layout possibilities. Like, what if we want a circular menu that expands from a center point by transitioning the radius of the circle? We can totally do that:&lt;/p&gt;&lt;p&gt;Click or hover the heading and the menu items form around the circle!&lt;/p&gt;&lt;head rend="h3"&gt;Wavy layouts&lt;/head&gt;&lt;p&gt;There’s still more we can do with layouts! If, say, we plot the &lt;code&gt;cos()&lt;/code&gt; and &lt;code&gt;sin()&lt;/code&gt; coordinates on a two-axis graph, notice how they give us a pair of waves that periodically go up and down. And notice they are offset from each other along the horizontal (X) axis:&lt;/p&gt;&lt;p&gt;Where do these waves come from? If we think back to the unit circle we talked about earlier, the value of &lt;code&gt;cos()&lt;/code&gt; and &lt;code&gt;sin()&lt;/code&gt; oscillate between &lt;code&gt;-1&lt;/code&gt; and &lt;code&gt;1&lt;/code&gt;. In other words, the lengths match when the angle around the unit circle varies. If we graph that oscillation, then we’ll get our wave and see that they’re sorta like reflections of each other.&lt;/p&gt;&lt;head&gt;⚠️ Auto-playing media&lt;/head&gt;&lt;p&gt;Can we place an element following one of these waves? Absolutely. Let’s start with the same single row layout of circular items we made earlier. This time, though, the length of that row spans beyond the viewport, causing overflow.&lt;/p&gt;&lt;p&gt;We’ll assign an index position for each item like we did before, but this time we don’t need to know the total number of items. We had eight items last time, so let’s bump that up to 10 and pretend like we don’t know that:&lt;/p&gt;&lt;code&gt;&amp;lt;ul&amp;gt;
  &amp;lt;li style="--i: 0"&amp;gt;&amp;lt;/li&amp;gt;
  &amp;lt;li style="--i: 1"&amp;gt;&amp;lt;/li&amp;gt;
  &amp;lt;li style="--i: 2"&amp;gt;&amp;lt;/li&amp;gt;
  &amp;lt;li style="--i: 3"&amp;gt;&amp;lt;/li&amp;gt;
  &amp;lt;li style="--i: 4"&amp;gt;&amp;lt;/li&amp;gt;
  &amp;lt;li style="--i: 5"&amp;gt;&amp;lt;/li&amp;gt;
  &amp;lt;li style="--i: 6"&amp;gt;&amp;lt;/li&amp;gt;
  &amp;lt;li style="--i: 7"&amp;gt;&amp;lt;/li&amp;gt;
  &amp;lt;li style="--i: 8"&amp;gt;&amp;lt;/li&amp;gt;
  &amp;lt;li style="--i: 9"&amp;gt;&amp;lt;/li&amp;gt;
  &amp;lt;li style="--i: 10"&amp;gt;&amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;&lt;/code&gt;



&lt;p&gt;We want to vary the element’s vertical position along either a &lt;code&gt;sin()&lt;/code&gt; or &lt;code&gt;cos()&lt;/code&gt; wave, meaning translating each item’s position based on its order in the index. We’ll multiply an item’s index by a certain angle that is passed into the &lt;code&gt;sin()&lt;/code&gt; function, and that will return a ratio that describes how high or low the element should be on the wave. The final thing is to multiply that result by a length value, which I calculated as half  an item’s total size.&lt;/p&gt;&lt;p&gt;Here’s the math in CSS-y terms:&lt;/p&gt;&lt;code&gt;li {
  transform: translateY(calc(sin(60deg * var(--i)) * var(--shape-size) / 2));
}&lt;/code&gt;



&lt;p&gt;I’m using a &lt;code&gt;60deg&lt;/code&gt; value because the waves it produces are smoother than some other values, but we can vary it as much as we want to get cooler waves. Play around with the toggle in the next demo and watch how the wave’s intensity changes with the angle:&lt;/p&gt;&lt;p&gt;This is a great example to see what we’re working with, but how would you use it in your work? Imagine we have two of these wavy chains of circles, and we want to intertwine them together, kinda like a DNA strand.&lt;/p&gt;&lt;p&gt;Let’s say we’re starting with the HTML structure for two unordered lists nested inside another unordered list. The two nested unordered lists represent the two waves that form the chain pattern:&lt;/p&gt;&lt;code&gt;&amp;lt;ul class="waves"&amp;gt;
  &amp;lt;!-- First wave --&amp;gt;
  &amp;lt;li&amp;gt;
    &amp;lt;ul class="principal"&amp;gt;
      &amp;lt;!-- Circles --&amp;gt;
      &amp;lt;li style="--i: 0"&amp;gt;&amp;lt;/li&amp;gt;
      &amp;lt;li style="--i: 1"&amp;gt;&amp;lt;/li&amp;gt;
      &amp;lt;li style="--i: 2"&amp;gt;&amp;lt;/li&amp;gt;
      &amp;lt;li style="--i: 3"&amp;gt;&amp;lt;/li&amp;gt;
      &amp;lt;!-- etc.  --&amp;gt;
    &amp;lt;/ul&amp;gt;
  &amp;lt;/li&amp;gt;

  &amp;lt;!-- Second wave --&amp;gt;
  &amp;lt;li&amp;gt;
    &amp;lt;ul class="secondary"&amp;gt;
      &amp;lt;!-- Circles --&amp;gt;
      &amp;lt;li style="--i: 0"&amp;gt;&amp;lt;/li&amp;gt;
      &amp;lt;li style="--i: 1"&amp;gt;&amp;lt;/li&amp;gt;
      &amp;lt;li style="--i: 2"&amp;gt;&amp;lt;/li&amp;gt;
      &amp;lt;li style="--i: 3"&amp;gt;&amp;lt;/li&amp;gt;
      &amp;lt;!-- etc.  --&amp;gt;
    &amp;lt;/ul&amp;gt;
  &amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;&lt;/code&gt;



&lt;p&gt;Pretty similar to the examples we’ve seen so far, right? We’re still working with an unordered list where the items are indexed with a CSS variable, but now we’re working with two of those lists… and they’re contained inside a third unordered list. We don’t have to structure this as lists, but I decided to leave them so I can use them as hooks for additional styling later.&lt;/p&gt;&lt;p&gt;To avoid any problems, we’ll ignore the two direct &lt;code&gt;&amp;lt;li&amp;gt;&lt;/code&gt; elements in the outer unordered list that contain the other lists using &lt;code&gt;display: contents&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;.waves &amp;gt; li { display: contents; }&lt;/code&gt;



&lt;p&gt;Notice how one of the chains is the “principal” while the other is the “secondary.” The difference is that the “secondary” chain is positioned behind the “principal” chain. I’m using slightly different background colors for the items in each chain, so it’s easier to distinguish one from the other as you scroll through the block-level overflow.&lt;/p&gt;&lt;p&gt;We can reorder the chains using a stacking context:&lt;/p&gt;&lt;code&gt;.principal {
  position: relative;
  z-index: 2;
}

.secondary { position: absolute; }&lt;/code&gt;



&lt;p&gt;This positions one chain on top of the other. Next, we will adjust each item’s vertical position with the “hated” &lt;code&gt;sin()&lt;/code&gt; and &lt;code&gt;cos()&lt;/code&gt; functions. Remember, they’re sorta like reflections of one another, so the variance between the two is what offsets the waves to form two intersecting chains of items:&lt;/p&gt;&lt;code&gt;.principal {
  /* ... */
  li {
    transform: translateY(calc(sin(60deg * var(--i)) * var(--shape-size) / 2));
  }
}

.secondary {
  /* ... */
  li {
    transform: translateY(calc(cos(60deg * var(--i)) * var(--shape-size) / 2));
  }
}&lt;/code&gt;



&lt;p&gt;We can accentuate the offset even more by shifting the &lt;code&gt;.secondary&lt;/code&gt; wave another &lt;code&gt;60deg&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;.secondary {
  /* ... */
  li {
    transform: translateY(calc(cos(60deg * var(--i) + 60deg) * var(--shape-size) / 2));
  }
}&lt;/code&gt;



&lt;p&gt;The next demo shows how the waves intersect at an offset angle of &lt;code&gt;60deg&lt;/code&gt;. Adjust the slider toggle to see how the waves intersect at different angles:&lt;/p&gt;&lt;p&gt;Oh, I told you this could be used in a practical, real-world way. How about adding a little whimsy and flair to a hero banner:&lt;/p&gt;&lt;head rend="h3"&gt;Damped oscillatory animations&lt;/head&gt;&lt;p&gt;The last example got me thinking: is there a way to use &lt;code&gt;sin()&lt;/code&gt; and &lt;code&gt;cos()&lt;/code&gt;‘s back and forth movement for animations? The first example that came to mind was an animation that also went back and forth, something like a pendulum or a bouncing ball.&lt;/p&gt;&lt;p&gt;This is, of course, trivial since we can do it in a single &lt;code&gt;animation&lt;/code&gt; declaration:&lt;/p&gt;&lt;code&gt;.element {
  animation: someAnimation 1s infinite alternate;
}&lt;/code&gt;



&lt;p&gt;This “back and forth” animation is called oscillatory movement. And while &lt;code&gt;cos()&lt;/code&gt; or &lt;code&gt;sin()&lt;/code&gt; are used to model oscillations in CSS, it would be like reinventing the wheel (albeit a clunkier one).&lt;/p&gt;&lt;p&gt;I’ve learned that perfect oscillatory movement — like a pendulum that swings back and forth in perpetuity, or a ball that never stops bouncing — doesn’t really exist. Movement tends to decay over time, like a bouncing spring:&lt;/p&gt;&lt;head&gt;⚠️ Auto-playing media&lt;/head&gt;&lt;p&gt;There’s a specific term that describes this: damped oscillatory movement. And guess what? We can model it in CSS with the &lt;code&gt;cos()&lt;/code&gt; function! If we graph it over time, then we will see it goes back and forth while getting closer to the resting position1.&lt;/p&gt;&lt;p&gt;Wikipedia has another animated example that nicely demonstrates what damped oscillation looks like.&lt;/p&gt;&lt;p&gt;In general, we can describe damped oscillation over time as a mathematical function:&lt;/p&gt;&lt;p&gt;It’s composed of three parts:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;e−γt: Due to the negative exponent, it becomes exponentially smaller as time passes, bringing the movement to a gradual stop. It is multiplied by a damping constant (γ) that specifies how quickly the movement should decay.&lt;/item&gt;&lt;item&gt;a: This is the initial amplitude of the oscillation, i.e., the element’s initial position.&lt;/item&gt;&lt;item&gt;cos(ωt−α): This gives the movement its oscillation as time passes. Time is multiplied by frequency (ω), which determines an element’s oscillation speed2. We can also subtract from time α, which we can use to offset the initial oscillation of the system.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Okay, enough with all the theory! How do we do it in CSS? We’ll set the stage with a single circle sitting all by itself.&lt;/p&gt;&lt;p&gt;We have a few CSS variables we can define that will come in handy since we already know the formula we’re working with:&lt;/p&gt;&lt;code&gt;:root {
  --circle-size: 60px;

  --amplitude: 200px; /* The amplitude is the distance, so let's write it in pixels*/
  --damping: 0.3;
  --frequency: 0.8;
  --offset: calc(pi/2); /* This is the same as 90deg! (But in radians) */
}&lt;/code&gt;



&lt;p&gt;Given these variables, we can peek at what the animation would look like on a graph using a tool like GeoGebra:&lt;/p&gt;&lt;p&gt;From the graph, we can see that the animation starts at &lt;code&gt;0px&lt;/code&gt; (thanks to our offset), then peaks around &lt;code&gt;140px&lt;/code&gt; and dies out around &lt;code&gt;25s&lt;/code&gt; in. I, for one, won’t be waiting 25 seconds for the animation to end, so let’s create a &lt;code&gt;--progress&lt;/code&gt; property that will animate between &lt;code&gt;0&lt;/code&gt; to &lt;code&gt;25&lt;/code&gt;, and will act as our “time” in the function.&lt;/p&gt;&lt;p&gt;Remember that to animate or transition a custom property, we’ve gotta register it with the &lt;code&gt;@property&lt;/code&gt; at-rule.&lt;/p&gt;&lt;code&gt;@property --progress {
  syntax: "&amp;lt;number&amp;gt;";
  initial-value: 0;
  inherits: true;
}

@keyframes movement {
  from { --progress: 0; }
  to { --progress: 25; }
}&lt;/code&gt;



&lt;p&gt;What’s left is to implement the prior formula for the element’s movement, which, written in CSS terms, looks like this:&lt;/p&gt;&lt;code&gt;.circle {
  --oscillation: calc(
    (exp(-1 * var(--damping) * var(--progress))) * 
    var(--amplitude) * 
    cos(var(--frequency) * (var(--progress)) - var(--offset))
  );

  transform: translateX(var(--oscillation));
  animation: movement 1s linear infinite;
}&lt;/code&gt;







&lt;p&gt;This gives a pretty satisfying animation by itself, but the damped motion is only on the x-axis. What would it look like if, instead, we applied the damped motion on both axes? To do this, we can copy the same oscillation formula for x, but replace the &lt;code&gt;cos()&lt;/code&gt; with &lt;code&gt;sin()&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;.circle {
  --oscillation-x: calc(
    (exp(-1 * var(--damping) * var(--progress))) * 
    var(--amplitude) * 
    cos(var(--frequency) * (var(--progress)) - var(--offset))
  );
  --oscillation-y: calc(
    (exp(-1 * var(--damping) * var(--progress))) * 
    var(--amplitude) * 
    sin(var(--frequency) * (var(--progress)) - var(--offset))
  );

  transform: translateX(var(--oscillation-x)) translateY(var(--oscillation-y));
  animation: movement 1s linear infinite;
}&lt;/code&gt;







&lt;p&gt;This is even more satisfying! A circular and damped motion, all thanks to &lt;code&gt;cos()&lt;/code&gt; and &lt;code&gt;sin()&lt;/code&gt;. Besides looking great, how could this be used in a real layout?&lt;/p&gt;&lt;p&gt;We don’t have to look too hard. Take, for example, this sidebar I recently made where the menu items pop in the viewport with a damped motion:&lt;/p&gt;&lt;p&gt;Pretty neat, right?!&lt;/p&gt;&lt;head rend="h3"&gt;More trigonometry to come!&lt;/head&gt;&lt;p&gt;Well, finding uses for the “most hated CSS feature” wasn’t that hard; maybe we should start showing some love to trigonometric functions. But wait. There are still several trigonometric functions in CSS we haven’t talked about. In the following posts, we’ll keep exploring what trig functions (like &lt;code&gt;tan()&lt;/code&gt; and inverse functions) can do in CSS.&lt;/p&gt;&lt;head rend="h4"&gt;CSS Trigonometric Functions: The “Most Hated” CSS Feature&lt;/head&gt;&lt;list rend="ol"&gt;&lt;item&gt;&lt;code&gt;sin()&lt;/code&gt;and&lt;code&gt;cos()&lt;/code&gt;(You are here!)&lt;/item&gt;&lt;item&gt;Tackling the CSS &lt;code&gt;tan()&lt;/code&gt;Function (coming soon)&lt;/item&gt;&lt;item&gt;Inverse functions: &lt;code&gt;asin()&lt;/code&gt;,&lt;code&gt;acos()&lt;/code&gt;,&lt;code&gt;atan()&lt;/code&gt;and&lt;code&gt;atan2()&lt;/code&gt;(coming soon)&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Also, before I forget, here is another demo I made using cos() and sin() that didn’t make the cut in this article, but it is still worth checking out because it dials up the swirly-ness from the last example to show how wacky we can get.&lt;/p&gt;&lt;head rend="h4"&gt;Footnotes&lt;/head&gt;&lt;list rend="ol"&gt;&lt;item&gt;This kind of damped oscillatory movement, where the back and forth is more visible, is called underdamped oscillation. There are also overdamped and critically damped oscillations, but we won’t focus on them here. ↪️&lt;/item&gt;&lt;item&gt;In reality, the damped constant and the frequency are closely related. You can read more about damped oscillation in this paper. ↪️&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45267336</guid><pubDate>Tue, 16 Sep 2025 20:10:59 +0000</pubDate></item><item><title>SQL performance improvements: finding the right queries to fix</title><link>https://ohdear.app/news-and-updates/sql-performance-improvements-finding-the-right-queries-to-fix-part-1</link><description>&lt;doc fingerprint="f3399dd54fb31822"&gt;
  &lt;main&gt;
    &lt;p&gt;SQL performance improvements: finding the right queries to fix (part 1) Published on September 17, 2025 by Mattias Geniar @mattiasgeniar Mattias Geniar September 17, 2025 A few weeks ago, we massively improved the performance of the dashboard &amp;amp; website by optimizing some of our SQL queries. In this post, we'll share how we identified the queries that needed work. In the next post, we'll explore how we fixed each of them. We'll cover the basics and gradually work our way up to the more advanced/complex ways of identifying slow queries. In this post, you'll see: Using a local debug-bar to identify queries Using MySQL slow query log Logging queries that don't use indexes Evaluating currently running queries live Analysing the global query log 2 MySQL bonusses: better CLI output &amp;amp; redirecting output to files Enforce eager loading in local Laravel environment Let's go! What these results look like # As a reminder, this is the resulting performance gain for the dashboard &amp;amp; some of our internal APIs: These graphs come from the Oh Dear uptime &amp;amp; performance monitoring we perform. Now let's get started identifying which queries need optimising. Enable the debug-bar in your local environment # The easiest place to start investigating queries is locally, in your development environment. Most frameworks have the concept of a "debug bar" - in the case of Laravel applications, the most widely used is the barryvdh/laravel-debugbar package that offers excellent insights. Once enabled, you can see output similar to this: It contains, at a glance: The total time spent executing SQL queries (top-right) The total amount of queries executed (top-left) How many of those were duplicates (indicating potential N+1 loop issues) Before optimising any query, it makes sense to ask the question: can the query be avoided in the first place? Duplicate queries are worth investigating, as well as queries that don't add meaning to the page you're seeing (ie a Class being lazy-loaded whose data isn't needed on this page). In our case, if we're looking at the data being loaded on an uptime monitor, we wouldn't expect a SQL query to load data for a broken link monitor. For this, you need application-awareness to know what data makes sense to load on that page. Let MySQL tell you which queries are slow # MySQL has the ability to enable a "slow query log", where you get to decide what qualifies as a slow query. This is the easiest step to get started, as MySQL will log to disk the SQL queries that exceeded your threshold. First, create the file to be used as the log (as the root user): $ touch /var/log/mysql-slow-query.log $ chown mysql:mysql /var/log/mysql-slow-query.log This creates an empty file and allows MySQL to read &amp;amp; write to it. If the file doesn't exist, MySQL won't create it for you, it just won't log anything. Next, hop in your MySQL command-line and activate the Slow Query Log. $ mysql mysql&amp;gt; SET GLOBAL slow_query_log_file = '/var/log/mysql-slow-query.log'; mysql&amp;gt; SET GLOBAL long_query_time = 1; mysql&amp;gt; SET GLOBAL slow_query_log = 'ON'; From this point, MySQL will log every query that exceeded the 1s threshold in your log file. Tweak the "long query time" as you see fit. $ tail -f /var/log/mysql-slow-query.log # Query_time: 2.547717 Lock_time: 0.000003 Rows_sent: 0 Rows_examined: 0 SET timestamp=1757095277; select * from `runs` where `runs`.`check_id` = ...; This will give you a list of your slow queries, ready to be optimized. The example above will modify your currently running MySQL instance to log queries, but if you restart your MySQL server, the settings won't be persisted. If you want to have this enabled all the time, it needs to be added to your my.cnf config file: [mysqld] slow_query_log = ON slow_query_log_file = /var/log/mysql-slow-query.log long_query_time = 1 You can gradually increase the slow query threshold, MySQL allows decimal values to log queries that are faster than 500ms, 300ms, etc. mysql&amp;gt; SET GLOBAL long_query_time = 0.3; This would let MySQL log all queries that are slower than 300ms. If the results become too verbose, you can tweak how many queries get logged a bit more by setting a minimal amount of rows that a query should return, before it's logged. mysql&amp;gt; SET GLOBAL min_examined_row_limit = 1000; Queries that examine fewer than this number of rows will not be logged to the slow query log. Let MySQL tell you which queries lack indexes # Spoiler alert: a fast query usually has indexes on them that make retrieving the data blazing fast. We'll explore how to set those &amp;amp; decide which ones to set in future posts. MySQL can log all queries that are being executed that don't use an index for lookups. This can get a little noisy, especially if you haven't added indexes before, so this is a setting to enable once you've done the 2 tips shared above first, to trim down on the log-noise this might generate. mysql&amp;gt; SET GLOBAL log_queries_not_using_indexes = ON; This will log all sorts of queries, including queries like: SELECT * FROM users: a full table scan (without a WHERE clause) SELECT * FROM users WHERE email = '[email protected]': a WHERE clause on a non-index column SELECT * FROM users WHERE UPPER(email) = '[email protected]: a function call on an indexed column (this prevents index usage) SELECT * FROM users WHERE name LIKE '%mattias%': using a leading wildcard in a LIKE statement I wouldn't recommend running log_queries_not_using_indexes all the time, just for debugging &amp;amp; analysis purposes. The log_queries_not_using_indexes is also compatible with the same min_examined_row_limit option we shared in the previous tip, so you can limit the logging of non-indexed queries by adding: mysql&amp;gt; SET GLOBAL min_examined_row_limit = 1000; If you have a high amount of queries without indexes and a busy MySQL server, the log activity can also become a bottleneck. Keep this in mind and disable it again once you're done with your analysis. mysql&amp;gt; SET GLOBAL log_queries_not_using_indexes = OFF; Ps; feels weird writing queries that set a value to what seems to be a string, right? The values for OFF and ON are reserved keywords, similar to TRUE or FALSE, so they don't need quotes. Let MySQL tell you which queries are executed right now # As a rule of thumb, I like to use: whenever I can see a query being executed right now, it probably can use some optimisations. Think about that logic for a second: ideally, queries are finished under 10ms or faster. What are the odds that when I request the current processlist, a query will show up? It becomes such a narrow window that when you look at the current processlist a few times, and you see the same queries showing up over and over again, they're worth investigating. Let's start with the basics: mysql&amp;gt; SHOW FULL PROCESSLIST; If this returns a lot of results, you can use the raw SQL query to be able to filter the results based on your own criteria. The SHOW FULL PROCESSLIST is essentially a shortcut for the following SQL query: mysql&amp;gt; SELECT ID, USER, HOST, DB, COMMAND, TIME, STATE, INFO FROM performance_schema.processlist ORDER BY ID; So you're able to trim down the output a little by avoiding Sleeping connections or from databases or users you don't need (if you're hosting multiple databases on this system); mysql&amp;gt; SELECT ID, USER, HOST, DB, COMMAND, TIME, STATE, INFO FROM performance_schema.processlist WHERE DB = 'ohdear' AND COMMAND != 'Sleep'; If you run this command a few times in a row and you see the same types of queries showing up, even if they have indexes, they're worth noting for followup. The output of PROCESSLIST and the content of the performance_schema.processlist have a limitation that the TIME only has seconds granularity, so it's hard to sort on. As a workaround, once you need more insights into &amp;lt; 1 second queries, you can run the following query: mysql&amp;gt; SELECT t.processlist_id, t.processlist_user, t.processlist_host, t.processlist_db, t.processlist_command, t.processlist_state, t.processlist_info, ROUND(s.timer_wait/1000000, 2) as execution_time_ms FROM performance_schema.threads t JOIN performance_schema.events_statements_current s ON t.thread_id = s.thread_id WHERE t.processlist_command != 'Sleep' AND s.timer_wait IS NOT NULL ORDER BY s.timer_wait DESC; This will show the time spent in miliseconds in the execution_time_ms column. Let MySQL tell you which queries get executed the most # Caution: on high-traffic MySQL servers, this will become a major bottleneck! Be careful. This one is best to enable locally, in your development environment. Sure, you can try to enable this on staging or production, but there's a very big chance your disk I/O won't survive that setting. Be careful when doing this on anything but your local development environment. I know some will #YOLO this in production, don't @ me when your system breaks. :-) MySQL can log all queries that are being executed, with the ability to then fire off some CLI tools on that big query log to identify the most recurring queries. First, similar to the Slow Query Log, create the file MySQL can write to: $ touch /var/log/mysql-general-query.log $ chown mysql:mysql /var/log/mysql-general-query.log Next, instruct MySQL to log all queries to that file: mysql&amp;gt; SET GLOBAL general_log_file = '/var/log/mysql-general-query.log'; mysql&amp;gt; SET GLOBAL general_log = ON; To disable the general log again: mysql&amp;gt; SET GLOBAL general_log = OFF; Now you can - again, locally - open your application, run your jobs &amp;amp; scheduled tasks, run your CI tests, ... and every query will be logged to the /var/log/mysql-general-query.log file. The output will be something like this: $ tail -f /var/log/mysql-general-query.log 2025-09-16T11:40:04.736814Z 94 Prepare select * from `plan_prices` where `archived` = ? and `is_yearly` = ? and `currency` = ? order by `amount` asc limit 1 2025-09-16T11:40:04.736987Z 94 Execute select * from `plan_prices` where `archived` = 0 and `is_yearly` = 0 and `currency` = 'eur' order by `amount` asc limit 1 2025-09-16T11:40:04.737575Z 94 Close stmt 2025-09-16T11:40:04.745635Z 94 Prepare select * from `transformation_results` where `url` = ? and `type` = ? limit 1 2025-09-16T11:40:04.745773Z 94 Execute select * from `transformation_results` where `url` = 'https://ohdear.app.test/pricing' and `type` = 'ldJson' limit 1 2025-09-16T11:40:04.746173Z 94 Close stmt 2025-09-16T11:40:04.768509Z 94 Prepare select * from `users` where `id` = ? limit 1 2025-09-16T11:40:04.768763Z 94 Execute select * from `users` where `id` = 27765 limit 1 2025-09-16T11:40:04.769149Z 94 Close stmt This quickly becomes overwhelming &amp;amp; you won't be able to parse this manually anymore. That's where the CLI comes in. Percona offers some amazing scripts for us to use, let's install those first: $ apt install percona-toolkit # for debian/ubuntu $ brew install percona-toolkit # for Mac The pt-query-digest tool allows us to analyse this general log and sort the queries by either count or time-spent in the database. We just need a quick fix in our log, because pt-query-digest only looks at the keyword Query in the log, and we're using Prepared Statements so we have a lot of entries with Prepare and Execute that the tool will happily ignore. Since each Execute is just a Query that was executed, we can simply rename them in our logfile. $ sed 's/Execute\t/Query\t/' /var/log/mysql-general-query.log &amp;gt; /var/log/mysql-general-query-editted.log Then, let's fire off the analysis: $ pt-query-digest \ --type=genlog \ --group-by fingerprint \ --order-by Query_time:cnt,Query_time:sum \ --filter '$event-&amp;gt;{cmd} =~ /^(Query|Execute)$/' \ --limit 25 \ /var/log/mysql-general-query-editted.log The output is a bit noisy, but tells you which queries were executed most (Count attribute) and which spent most time (Exec time attribute). Any performance gain that can be made to the most-occuring queries will yield better results. Improving a query from 25ms to 20ms may sound negligible, but if it's performed millions of times a day, it adds up. MySQL bonus 1: sort output vertically, not horizontally # If you're working via the CLI, some of the queries I shared above can have quite lengthy output that's not always easy to see on small screens. You can change some of the outputs with modifiers in MySQL. One very useful modifier is the \G control character - that's backslash + G. This is a normal query output via the CLI: mysql&amp;gt; SELECT id, name FROM teams LIMIT 2; +----+--------------+ | id | name | +----+--------------+ | 1 | Team Mattias | | 2 | Spatie | +----+--------------+ 2 rows in set (0.00 sec) If you add in the \G suffix to a query, the results are shown vertically instead: mysql&amp;gt; SELECT id, name FROM teams LIMIT 2 \G; ************************* * 1. row *************************** id: 1 name: Team Mattias ************************* * 2. row *************************** id: 2 name: Spatie 2 rows in set (0.00 sec) That's a litteral \G (backslash + G) at the end of the query. MySQL bonus 2: write query output to a file # If you miss using grep, awk, sort, ... in a MySQL shell, you're probably a greybeard Linux sysadmin and we should have some beers together. But good news, MySQLs' output can be redirected to a file for easier parsing! mysql&amp;gt; \T /tmp/query-output.log Logging to file '/tmp/query-output.log' mysql&amp;gt; SELECT * FROM teams; mysql&amp;gt; \t Outfile disabled. With \T you can specify which file this MySQL session should write all its output to. And with \t you can stop writing to that file. Afterwards, your file contains all the output of the queries you ran in between. You can also use INTO OUTFILE but I find it a little cumbersome to tweak queries to achieve that, I'd rather mark a terminal session as "log to file", do the queries I want, and then stop that logging. Let Laravel warn you for N+1 queries # The Laravel framework can warn you when you're (potentially) causing excessive queries by throwing an exception when you're lazy loading relationships. You can enable this warning in your non-production environment by adding the following into your boot() method in your AppServiceProvider: public function boot(): void { Model::preventLazyLoading(! $this-&amp;gt;app-&amp;gt;isProduction()); } Now, every time you run a piece of code like this: $posts = Post::all(); foreach ($posts as $post) { echo $post-&amp;gt;comments-&amp;gt;count(); } It'll throw an exception, because for every iteration through the loop, Laravel would perform an extra query to count the comments of that specific $post instead of loading them at once. The fix, in this example, would be to eager load the counts only - not all the comments. // Eager load the comment counts $posts = Post::withCount('comments')-&amp;gt;get(); foreach ($posts as $post) { echo $post-&amp;gt;comments_count; // Note the _count suffix } This is an example that will optimise your query count with just minimal code changes. Next up: fixing the queries # In this post, we shared several ways of identifying which queries either get executed the most or which are the slowest. There's many ways to get this data, and you're able to pick whichever method you're most comfortable with or have access to. In our next post, we'll deep-dive into the different ways of identifying what the bottleneck of a query is and how to resolve it.&lt;/p&gt;
    &lt;p&gt;A few weeks ago, we massively improved the performance of the dashboard &amp;amp; website by optimizing some of our SQL queries. In this post, we'll share how we identified the queries that needed work. In the next post, we'll explore how we fixed each of them. We'll cover the basics and gradually work our way up to the more advanced/complex ways of identifying slow queries. In this post, you'll see: Using a local debug-bar to identify queries Using MySQL slow query log Logging queries that don't use indexes Evaluating currently running queries live Analysing the global query log 2 MySQL bonusses: better CLI output &amp;amp; redirecting output to files Enforce eager loading in local Laravel environment Let's go! What these results look like # As a reminder, this is the resulting performance gain for the dashboard &amp;amp; some of our internal APIs: These graphs come from the Oh Dear uptime &amp;amp; performance monitoring we perform. Now let's get started identifying which queries need optimising. Enable the debug-bar in your local environment # The easiest place to start investigating queries is locally, in your development environment. Most frameworks have the concept of a "debug bar" - in the case of Laravel applications, the most widely used is the barryvdh/laravel-debugbar package that offers excellent insights. Once enabled, you can see output similar to this: It contains, at a glance: The total time spent executing SQL queries (top-right) The total amount of queries executed (top-left) How many of those were duplicates (indicating potential N+1 loop issues) Before optimising any query, it makes sense to ask the question: can the query be avoided in the first place? Duplicate queries are worth investigating, as well as queries that don't add meaning to the page you're seeing (ie a Class being lazy-loaded whose data isn't needed on this page). In our case, if we're looking at the data being loaded on an uptime monitor, we wouldn't expect a SQL query to load data for a broken link monitor. For this, you need application-awareness to know what data makes sense to load on that page. Let MySQL tell you which queries are slow # MySQL has the ability to enable a "slow query log", where you get to decide what qualifies as a slow query. This is the easiest step to get started, as MySQL will log to disk the SQL queries that exceeded your threshold. First, create the file to be used as the log (as the root user): $ touch /var/log/mysql-slow-query.log $ chown mysql:mysql /var/log/mysql-slow-query.log This creates an empty file and allows MySQL to read &amp;amp; write to it. If the file doesn't exist, MySQL won't create it for you, it just won't log anything. Next, hop in your MySQL command-line and activate the Slow Query Log. $ mysql mysql&amp;gt; SET GLOBAL slow_query_log_file = '/var/log/mysql-slow-query.log'; mysql&amp;gt; SET GLOBAL long_query_time = 1; mysql&amp;gt; SET GLOBAL slow_query_log = 'ON'; From this point, MySQL will log every query that exceeded the 1s threshold in your log file. Tweak the "long query time" as you see fit. $ tail -f /var/log/mysql-slow-query.log # Query_time: 2.547717 Lock_time: 0.000003 Rows_sent: 0 Rows_examined: 0 SET timestamp=1757095277; select * from `runs` where `runs`.`check_id` = ...; This will give you a list of your slow queries, ready to be optimized. The example above will modify your currently running MySQL instance to log queries, but if you restart your MySQL server, the settings won't be persisted. If you want to have this enabled all the time, it needs to be added to your my.cnf config file: [mysqld] slow_query_log = ON slow_query_log_file = /var/log/mysql-slow-query.log long_query_time = 1 You can gradually increase the slow query threshold, MySQL allows decimal values to log queries that are faster than 500ms, 300ms, etc. mysql&amp;gt; SET GLOBAL long_query_time = 0.3; This would let MySQL log all queries that are slower than 300ms. If the results become too verbose, you can tweak how many queries get logged a bit more by setting a minimal amount of rows that a query should return, before it's logged. mysql&amp;gt; SET GLOBAL min_examined_row_limit = 1000; Queries that examine fewer than this number of rows will not be logged to the slow query log. Let MySQL tell you which queries lack indexes # Spoiler alert: a fast query usually has indexes on them that make retrieving the data blazing fast. We'll explore how to set those &amp;amp; decide which ones to set in future posts. MySQL can log all queries that are being executed that don't use an index for lookups. This can get a little noisy, especially if you haven't added indexes before, so this is a setting to enable once you've done the 2 tips shared above first, to trim down on the log-noise this might generate. mysql&amp;gt; SET GLOBAL log_queries_not_using_indexes = ON; This will log all sorts of queries, including queries like: SELECT * FROM users: a full table scan (without a WHERE clause) SELECT * FROM users WHERE email = '[email protected]': a WHERE clause on a non-index column SELECT * FROM users WHERE UPPER(email) = '[email protected]: a function call on an indexed column (this prevents index usage) SELECT * FROM users WHERE name LIKE '%mattias%': using a leading wildcard in a LIKE statement I wouldn't recommend running log_queries_not_using_indexes all the time, just for debugging &amp;amp; analysis purposes. The log_queries_not_using_indexes is also compatible with the same min_examined_row_limit option we shared in the previous tip, so you can limit the logging of non-indexed queries by adding: mysql&amp;gt; SET GLOBAL min_examined_row_limit = 1000; If you have a high amount of queries without indexes and a busy MySQL server, the log activity can also become a bottleneck. Keep this in mind and disable it again once you're done with your analysis. mysql&amp;gt; SET GLOBAL log_queries_not_using_indexes = OFF; Ps; feels weird writing queries that set a value to what seems to be a string, right? The values for OFF and ON are reserved keywords, similar to TRUE or FALSE, so they don't need quotes. Let MySQL tell you which queries are executed right now # As a rule of thumb, I like to use: whenever I can see a query being executed right now, it probably can use some optimisations. Think about that logic for a second: ideally, queries are finished under 10ms or faster. What are the odds that when I request the current processlist, a query will show up? It becomes such a narrow window that when you look at the current processlist a few times, and you see the same queries showing up over and over again, they're worth investigating. Let's start with the basics: mysql&amp;gt; SHOW FULL PROCESSLIST; If this returns a lot of results, you can use the raw SQL query to be able to filter the results based on your own criteria. The SHOW FULL PROCESSLIST is essentially a shortcut for the following SQL query: mysql&amp;gt; SELECT ID, USER, HOST, DB, COMMAND, TIME, STATE, INFO FROM performance_schema.processlist ORDER BY ID; So you're able to trim down the output a little by avoiding Sleeping connections or from databases or users you don't need (if you're hosting multiple databases on this system); mysql&amp;gt; SELECT ID, USER, HOST, DB, COMMAND, TIME, STATE, INFO FROM performance_schema.processlist WHERE DB = 'ohdear' AND COMMAND != 'Sleep'; If you run this command a few times in a row and you see the same types of queries showing up, even if they have indexes, they're worth noting for followup. The output of PROCESSLIST and the content of the performance_schema.processlist have a limitation that the TIME only has seconds granularity, so it's hard to sort on. As a workaround, once you need more insights into &amp;lt; 1 second queries, you can run the following query: mysql&amp;gt; SELECT t.processlist_id, t.processlist_user, t.processlist_host, t.processlist_db, t.processlist_command, t.processlist_state, t.processlist_info, ROUND(s.timer_wait/1000000, 2) as execution_time_ms FROM performance_schema.threads t JOIN performance_schema.events_statements_current s ON t.thread_id = s.thread_id WHERE t.processlist_command != 'Sleep' AND s.timer_wait IS NOT NULL ORDER BY s.timer_wait DESC; This will show the time spent in miliseconds in the execution_time_ms column. Let MySQL tell you which queries get executed the most # Caution: on high-traffic MySQL servers, this will become a major bottleneck! Be careful. This one is best to enable locally, in your development environment. Sure, you can try to enable this on staging or production, but there's a very big chance your disk I/O won't survive that setting. Be careful when doing this on anything but your local development environment. I know some will #YOLO this in production, don't @ me when your system breaks. :-) MySQL can log all queries that are being executed, with the ability to then fire off some CLI tools on that big query log to identify the most recurring queries. First, similar to the Slow Query Log, create the file MySQL can write to: $ touch /var/log/mysql-general-query.log $ chown mysql:mysql /var/log/mysql-general-query.log Next, instruct MySQL to log all queries to that file: mysql&amp;gt; SET GLOBAL general_log_file = '/var/log/mysql-general-query.log'; mysql&amp;gt; SET GLOBAL general_log = ON; To disable the general log again: mysql&amp;gt; SET GLOBAL general_log = OFF; Now you can - again, locally - open your application, run your jobs &amp;amp; scheduled tasks, run your CI tests, ... and every query will be logged to the /var/log/mysql-general-query.log file. The output will be something like this: $ tail -f /var/log/mysql-general-query.log 2025-09-16T11:40:04.736814Z 94 Prepare select * from `plan_prices` where `archived` = ? and `is_yearly` = ? and `currency` = ? order by `amount` asc limit 1 2025-09-16T11:40:04.736987Z 94 Execute select * from `plan_prices` where `archived` = 0 and `is_yearly` = 0 and `currency` = 'eur' order by `amount` asc limit 1 2025-09-16T11:40:04.737575Z 94 Close stmt 2025-09-16T11:40:04.745635Z 94 Prepare select * from `transformation_results` where `url` = ? and `type` = ? limit 1 2025-09-16T11:40:04.745773Z 94 Execute select * from `transformation_results` where `url` = 'https://ohdear.app.test/pricing' and `type` = 'ldJson' limit 1 2025-09-16T11:40:04.746173Z 94 Close stmt 2025-09-16T11:40:04.768509Z 94 Prepare select * from `users` where `id` = ? limit 1 2025-09-16T11:40:04.768763Z 94 Execute select * from `users` where `id` = 27765 limit 1 2025-09-16T11:40:04.769149Z 94 Close stmt This quickly becomes overwhelming &amp;amp; you won't be able to parse this manually anymore. That's where the CLI comes in. Percona offers some amazing scripts for us to use, let's install those first: $ apt install percona-toolkit # for debian/ubuntu $ brew install percona-toolkit # for Mac The pt-query-digest tool allows us to analyse this general log and sort the queries by either count or time-spent in the database. We just need a quick fix in our log, because pt-query-digest only looks at the keyword Query in the log, and we're using Prepared Statements so we have a lot of entries with Prepare and Execute that the tool will happily ignore. Since each Execute is just a Query that was executed, we can simply rename them in our logfile. $ sed 's/Execute\t/Query\t/' /var/log/mysql-general-query.log &amp;gt; /var/log/mysql-general-query-editted.log Then, let's fire off the analysis: $ pt-query-digest \ --type=genlog \ --group-by fingerprint \ --order-by Query_time:cnt,Query_time:sum \ --filter '$event-&amp;gt;{cmd} =~ /^(Query|Execute)$/' \ --limit 25 \ /var/log/mysql-general-query-editted.log The output is a bit noisy, but tells you which queries were executed most (Count attribute) and which spent most time (Exec time attribute). Any performance gain that can be made to the most-occuring queries will yield better results. Improving a query from 25ms to 20ms may sound negligible, but if it's performed millions of times a day, it adds up. MySQL bonus 1: sort output vertically, not horizontally # If you're working via the CLI, some of the queries I shared above can have quite lengthy output that's not always easy to see on small screens. You can change some of the outputs with modifiers in MySQL. One very useful modifier is the \G control character - that's backslash + G. This is a normal query output via the CLI: mysql&amp;gt; SELECT id, name FROM teams LIMIT 2; +----+--------------+ | id | name | +----+--------------+ | 1 | Team Mattias | | 2 | Spatie | +----+--------------+ 2 rows in set (0.00 sec) If you add in the \G suffix to a query, the results are shown vertically instead: mysql&amp;gt; SELECT id, name FROM teams LIMIT 2 \G; ************************* * 1. row *************************** id: 1 name: Team Mattias ************************* * 2. row *************************** id: 2 name: Spatie 2 rows in set (0.00 sec) That's a litteral \G (backslash + G) at the end of the query. MySQL bonus 2: write query output to a file # If you miss using grep, awk, sort, ... in a MySQL shell, you're probably a greybeard Linux sysadmin and we should have some beers together. But good news, MySQLs' output can be redirected to a file for easier parsing! mysql&amp;gt; \T /tmp/query-output.log Logging to file '/tmp/query-output.log' mysql&amp;gt; SELECT * FROM teams; mysql&amp;gt; \t Outfile disabled. With \T you can specify which file this MySQL session should write all its output to. And with \t you can stop writing to that file. Afterwards, your file contains all the output of the queries you ran in between. You can also use INTO OUTFILE but I find it a little cumbersome to tweak queries to achieve that, I'd rather mark a terminal session as "log to file", do the queries I want, and then stop that logging. Let Laravel warn you for N+1 queries # The Laravel framework can warn you when you're (potentially) causing excessive queries by throwing an exception when you're lazy loading relationships. You can enable this warning in your non-production environment by adding the following into your boot() method in your AppServiceProvider: public function boot(): void { Model::preventLazyLoading(! $this-&amp;gt;app-&amp;gt;isProduction()); } Now, every time you run a piece of code like this: $posts = Post::all(); foreach ($posts as $post) { echo $post-&amp;gt;comments-&amp;gt;count(); } It'll throw an exception, because for every iteration through the loop, Laravel would perform an extra query to count the comments of that specific $post instead of loading them at once. The fix, in this example, would be to eager load the counts only - not all the comments. // Eager load the comment counts $posts = Post::withCount('comments')-&amp;gt;get(); foreach ($posts as $post) { echo $post-&amp;gt;comments_count; // Note the _count suffix } This is an example that will optimise your query count with just minimal code changes. Next up: fixing the queries # In this post, we shared several ways of identifying which queries either get executed the most or which are the slowest. There's many ways to get this data, and you're able to pick whichever method you're most comfortable with or have access to. In our next post, we'll deep-dive into the different ways of identifying what the bottleneck of a query is and how to resolve it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45267762</guid><pubDate>Tue, 16 Sep 2025 20:43:43 +0000</pubDate></item><item><title>Doom crash after 2.5 years of real-world runtime confirmed on real hardware</title><link>https://lenowo.org/viewtopic.php?t=31</link><description>&lt;doc fingerprint="dc4f80d558235299"&gt;
  &lt;main&gt;
    &lt;p&gt;Two and a half years ago, I started my now longest real-world software experiment. I had read an article about how DOOMs engine works and noticed how a variable for tracking the demo kept being incremented even after the next demo started. This variable was compared with a second one storing its previous value. The issue here being, each incrementation would cause the variable to slowly get closer to an overflow, realistically this would never happen in a normal scenario, although it got me curious on just how long it would take until the game would crash due to this.&lt;lb/&gt; I did a few calculations, I don't remember the specifics of it sadly as it has been over two years since that point and I sadly did not document it back then (or I did, but on a partition I no longer have access to) but I remember having gotten roughly 2 1/2 years of possible runtime before an overflow. Obviously, I wanted to know if this would actually happen in the real game on real hardware.&lt;lb/&gt; So I set up DOOM on a small PDA, powered through a DIY 18650 based UPS which itself was connected to the USB port of my router for a constant 5V supply. I left the system running and mostly forgot about it.&lt;lb/&gt; ... Until today when I noticed a pop-up appearing on the device, not long ago from posting this to the board. The game had crashed, only hours after the two and a half year mark, proving that the variable did indeed overflow and cause the expected hard crash of the game: &lt;/p&gt;
    &lt;head rend="h2"&gt;DOOM crash after 2.5 years of real-world runtime confirmed on real hardware&lt;/head&gt;
    &lt;head rend="h3"&gt;DOOM crash after 2.5 years of real-world runtime confirmed on real hardware&lt;/head&gt;
    &lt;p&gt;~-~-~ MSD - Making your old devices useful again since 2022! ~-~-~&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45268269</guid><pubDate>Tue, 16 Sep 2025 21:24:23 +0000</pubDate></item><item><title>Micro-LEDs boost random number generation</title><link>https://discovery.kaust.edu.sa/en/article/25936/micro-leds-boost-random-number-generation/</link><description>&lt;doc fingerprint="83dc030560c5394e"&gt;
  &lt;main&gt;
    &lt;p&gt;Electrical Engineering&lt;/p&gt;
    &lt;head rend="h1"&gt;Micro-LEDs boost random number generation&lt;/head&gt;
    &lt;p&gt;Intensity fluctuations from miniature LEDs provide ultrafast generation rates.&lt;/p&gt;
    &lt;p&gt;Miniature LEDs called micro-LEDs have been shown to generate random numbers at gigabit-per-second speeds by a team of researchers from Saudi Arabia and the United States[1].&lt;/p&gt;
    &lt;p&gt;The generation of random numbers is vital for many tasks, including data security — where it is used to create encryption keys and passwords — and computer simulations of complex systems such as the weather and financial markets.&lt;/p&gt;
    &lt;p&gt;There is, therefore, a strong demand to develop cost-effective random number generators that are small enough for chip-scale integration while also offering a fast generation rate.&lt;/p&gt;
    &lt;p&gt;The most robust and reliable way to generate true random numbers is to sample and digitize a physical process underpinned by the intrinsic randomness of quantum mechanics. For example, the thermal noise, chaos, and jitter from electronic and optoelectronic devices have all been investigated in the past.&lt;/p&gt;
    &lt;p&gt;Now, Heming Lin, Boon Ooi, and coworkers from KAUST, King Abdulaziz City for Science and Technology (KACST), and the University of California at Santa Barbara report that intensity fluctuations in the spontaneous emission from blue GaN micro-LEDs, ranging in size from 5-100 μm, can serve as a quantum random number generator (QRNG) with an ultra-high generation rate of 9.375 Gbit/s.&lt;/p&gt;
    &lt;p&gt;“Micro-LEDs are compact, reliable, and cost-effective,” say Lin and Ooi. “They consume less power and require simpler electronic and photonic system architectures than other competing technologies.”&lt;/p&gt;
    &lt;p&gt;The idea of using LEDs to generate numbers is not new. Over the past decade, research teams have explored measuring photon number and arrival time. However, a major limitation of these previous schemes is that they have provided much slower generation rates, typically on the scale of no more than a few hundred megabits per second.&lt;/p&gt;
    &lt;p&gt;“Systems relying on single-photon detection typically extract only two bits per sampling cycle, whereas our system achieves six bits by leveraging intensity fluctuations,” explain Lin and Ooi.&lt;/p&gt;
    &lt;p&gt;Importantly, for any QRNG to be trusted, its output must be stringently tested to ensure it is sufficiently random. The tests developed by the U.S. National Institute of Standards and Technology (NIST) are the gold standard. The KAUST team tested a variety of micro-LEDs with different sizes — spanning from 5 × 5 μm² to 100 × 100 μm² — and drive currents ranging from 0.5 to 100 mA. All passed the NIST tests.&lt;/p&gt;
    &lt;p&gt;The team’s future work will focus on boosting generation rates by creating 2D arrays of micro-LEDs that enable parallel random number generation.&lt;/p&gt;
    &lt;p&gt;The researchers are also planning to create a fully integrated system, rather than using discrete components. At present, the KAUST system comprises a GaN micro-LED, which is temperature stabilized using a thermoelectric cooler and has its light emission fed to an avalanche photodetector. This, in turn, is connected to a sampling oscilloscope via an electronic amplifier.&lt;/p&gt;
    &lt;p&gt;Lin and Ooi add:“Our next step is to integrate an on-chip photodetector with the micro-LED and subsequently incorporate all the required electronic components to realize a fully integrated QRNG chip.”&lt;/p&gt;
    &lt;head rend="h5"&gt;Reference&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Lin, H., Lu, H., Wong, W.S., Almogbel, A., Alyamani, A., Ng., T.K., Bakr, O., Nakamura, S., Denbaars, S. &amp;amp; Ooi, B. Micro-LED based quantum random number generators. Optics Express 33, 22154-22164 (2025).| article.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h6"&gt;You might also like&lt;/head&gt;
    &lt;p&gt;Bioengineering&lt;/p&gt;
    &lt;head rend="h3"&gt;Sensing stress to keep plants safe&lt;/head&gt;
    &lt;p&gt;Computer Science&lt;/p&gt;
    &lt;head rend="h3"&gt;Sweat-sniffing sensor could make workouts smarter&lt;/head&gt;
    &lt;p&gt;Electrical Engineering&lt;/p&gt;
    &lt;head rend="h3"&gt;New tech detects dehydration by touching a screen&lt;/head&gt;
    &lt;p&gt;Electrical Engineering&lt;/p&gt;
    &lt;head rend="h3"&gt;A new interface for efficient electronics&lt;/head&gt;
    &lt;p&gt;Electrical Engineering&lt;/p&gt;
    &lt;head rend="h3"&gt;Artificial neurons enable neuromorphic computing with light&lt;/head&gt;
    &lt;p&gt;Electrical Engineering&lt;/p&gt;
    &lt;head rend="h3"&gt;Narrow-linewidth lasers bring low-noise answer&lt;/head&gt;
    &lt;p&gt;Electrical Engineering&lt;/p&gt;
    &lt;head rend="h3"&gt;Octopus suckers inspire sticky medical patch&lt;/head&gt;
    &lt;p&gt;Electrical Engineering&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45268575</guid><pubDate>Tue, 16 Sep 2025 21:48:06 +0000</pubDate></item><item><title>Chronon: A data platform for serving for AI/ML applications</title><link>https://github.com/airbnb/chronon</link><description>&lt;doc fingerprint="38c13850f5ae088b"&gt;
  &lt;main&gt;
    &lt;p&gt;Chronon is a platform that abstracts away the complexity of data computation and serving for AI/ML applications. Users define features as transformation of raw data, then Chronon can perform batch and streaming computation, scalable backfills, low-latency serving, guaranteed correctness and consistency, as well as a host of observability and monitoring tools.&lt;/p&gt;
    &lt;p&gt;It allows you to utilize all of the data within your organization, from batch tables, event streams or services to power your AI/ML projects, without needing to worry about all the complex orchestration that this would usually entail.&lt;/p&gt;
    &lt;p&gt;More information about Chronon can be found at chronon.ai.&lt;/p&gt;
    &lt;p&gt;Chronon offers an API for realtime fetching which returns up-to-date values for your features. It supports:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Managed pipelines for batch and realtime feature computation and updates to the serving backend&lt;/item&gt;
      &lt;item&gt;Low latency serving of computed features&lt;/item&gt;
      &lt;item&gt;Scalable for high fanout feature sets&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;ML practitioners often need historical views of feature values for model training and evaluation. Chronon's backfills are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Scalable for large time windows&lt;/item&gt;
      &lt;item&gt;Resilient to highly skewed data&lt;/item&gt;
      &lt;item&gt;Point-in-time accurate such that consistency with online serving is guaranteed&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Chronon offers visibility into:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Data freshness - ensure that online values are being updated in realtime&lt;/item&gt;
      &lt;item&gt;Online/Offline consistency - ensure that backfill data for model training and evaluation is consistent with what is being observed in online serving&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Chronon supports a range of aggregation types. For a full list see the documentation here.&lt;/p&gt;
    &lt;p&gt;These aggregations can all be configured to be computed over arbitrary window sizes.&lt;/p&gt;
    &lt;p&gt;This section walks you through the steps to create a training dataset with Chronon, using a fabricated underlying raw dataset.&lt;/p&gt;
    &lt;p&gt;Includes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Example implementation of the main API components for defining features - &lt;code&gt;GroupBy&lt;/code&gt;and&lt;code&gt;Join&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;The workflow for authoring these entities.&lt;/item&gt;
      &lt;item&gt;The workflow for backfilling training data.&lt;/item&gt;
      &lt;item&gt;The workflows for uploading and serving this data.&lt;/item&gt;
      &lt;item&gt;The workflow for measuring consistency between backfilled training data and online inference data.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Does not include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A deep dive on the various concepts and terminologies in Chronon. For that, please see the Introductory documentation.&lt;/item&gt;
      &lt;item&gt;Running streaming jobs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Docker&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To get started with the Chronon, all you need to do is download the docker-compose.yml file and run it locally:&lt;/p&gt;
    &lt;code&gt;curl -o docker-compose.yml https://chronon.ai/docker-compose.yml
docker-compose up&lt;/code&gt;
    &lt;p&gt;Once you see some data printed with a &lt;code&gt;only showing top 20 rows&lt;/code&gt; notice, you're ready to proceed with the tutorial.&lt;/p&gt;
    &lt;p&gt;In this example, let's assume that we're a large online retailer, and we've detected a fraud vector based on users making purchases and later returning items. We want to train a model that will be called when the checkout flow commences and predicts whether this transaction is likely to result in a fraudulent return.&lt;/p&gt;
    &lt;p&gt;Fabricated raw data is included in the data directory. It includes four tables:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Users - includes basic information about users such as account created date; modeled as a batch data source that updates daily&lt;/item&gt;
      &lt;item&gt;Purchases - a log of all purchases by users; modeled as a log table with a streaming (i.e. Kafka) event-bus counterpart&lt;/item&gt;
      &lt;item&gt;Returns - a log of all returns made by users; modeled as a log table with a streaming (i.e. Kafka) event-bus counterpart&lt;/item&gt;
      &lt;item&gt;Checkouts - a log of all checkout events; this is the event that drives our model predictions&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In a new terminal window, run:&lt;/p&gt;
    &lt;code&gt;docker-compose exec main bash&lt;/code&gt;
    &lt;p&gt;This will open a shell within the chronon docker container.&lt;/p&gt;
    &lt;p&gt;Now that the setup steps are complete, we can start creating and testing various Chronon objects to define transformation and aggregations, and generate data.&lt;/p&gt;
    &lt;p&gt;Let's start with three feature sets, built on top of our raw input sources.&lt;/p&gt;
    &lt;p&gt;Note: These python definitions are already in your &lt;code&gt;chronon&lt;/code&gt; image. There's nothing for you to run until Step 3 - Backfilling Data when you'll run computation for these definitions.&lt;/p&gt;
    &lt;p&gt;Feature set 1: Purchases data features&lt;/p&gt;
    &lt;p&gt;We can aggregate the purchases log data to the user level, to give us a view into this user's previous activity on our platform. Specifically, we can compute &lt;code&gt;SUM&lt;/code&gt;s &lt;code&gt;COUNT&lt;/code&gt;s and &lt;code&gt;AVERAGE&lt;/code&gt;s of their previous purchase amounts over various windows.&lt;/p&gt;
    &lt;p&gt;Because this feature is built upon a source that includes both a table and a topic, its features can be computed in both batch and streaming.&lt;/p&gt;
    &lt;code&gt;source = Source(
    events=EventSource(
        table="data.purchases", # This points to the log table with historical purchase events
        topic=None, # Streaming is not currently part of quickstart, but this would be where you define the topic for realtime events
        query=Query(
            selects=select("user_id","purchase_price"), # Select the fields we care about
            time_column="ts") # The event time
    ))

window_sizes = [Window(length=day, timeUnit=TimeUnit.DAYS) for day in [3, 14, 30]] # Define some window sizes to use below

v1 = GroupBy(
    sources=[source],
    keys=["user_id"], # We are aggregating by user
    aggregations=[Aggregation(
            input_column="purchase_price",
            operation=Operation.SUM,
            windows=window_sizes
        ), # The sum of purchases prices in various windows
        Aggregation(
            input_column="purchase_price",
            operation=Operation.COUNT,
            windows=window_sizes
        ), # The count of purchases in various windows
        Aggregation(
            input_column="purchase_price",
            operation=Operation.AVERAGE,
            windows=window_sizes
        ) # The average purchases by user in various windows
    ],
)&lt;/code&gt;
    &lt;p&gt;See the whole code file here: purchases GroupBy. This is also in your docker image. We'll be running computation for it and the other GroupBys in Step 3 - Backfilling Data.&lt;/p&gt;
    &lt;p&gt;Feature set 2: Returns data features&lt;/p&gt;
    &lt;p&gt;We perform a similar set of aggregations on returns data in the returns GroupBy. The code is not included here because it looks similar to the above example.&lt;/p&gt;
    &lt;p&gt;Feature set 3: User data features&lt;/p&gt;
    &lt;p&gt;Turning User data into features is a littler simpler, primarily because there are no aggregations to include. In this case, the primary key of the source data is the same as the primary key of the feature, so we're simply extracting column values rather than performing aggregations over rows:&lt;/p&gt;
    &lt;code&gt;source = Source(
    entities=EntitySource(
        snapshotTable="data.users", # This points to a table that contains daily snapshots of the entire product catalog
        query=Query(
            selects=select("user_id","account_created_ds","email_verified"), # Select the fields we care about
        )
    ))

v1 = GroupBy(
    sources=[source],
    keys=["user_id"], # Primary key is the same as the primary key for the source table
    aggregations=None # In this case, there are no aggregations or windows to define
) &lt;/code&gt;
    &lt;p&gt;Taken from the users GroupBy.&lt;/p&gt;
    &lt;p&gt;Next, we need the features that we previously defined backfilled in a single table for model training. This can be achieved using the &lt;code&gt;Join&lt;/code&gt; API.&lt;/p&gt;
    &lt;p&gt;For our use case, it's very important that features are computed as of the correct timestamp. Because our model runs when the checkout flow begins, we'll want to be sure to use the corresponding timestamp in our backfill, such that features values for model training logically match what the model will see in online inference.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Join&lt;/code&gt; is the API that drives feature backfills for training data. It primarilly performs the following functions:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Combines many features together into a wide view (hence the name &lt;code&gt;Join&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Defines the primary keys and timestamps for which feature backfills should be performed. Chronon can then guarantee that feature values are correct as of this timestamp.&lt;/item&gt;
      &lt;item&gt;Performs scalable backfills.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here is what our join looks like:&lt;/p&gt;
    &lt;code&gt;source = Source(
    events=EventSource(
        table="data.checkouts", 
        query=Query(
            selects=select("user_id"), # The primary key used to join various GroupBys together
            time_column="ts",
            ) # The event time used to compute feature values as-of
    ))

v1 = Join(  
    left=source,
    right_parts=[JoinPart(group_by=group_by) for group_by in [purchases_v1, refunds_v1, users]] # Include the three GroupBys
)&lt;/code&gt;
    &lt;p&gt;Taken from the training_set Join.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;left&lt;/code&gt; side of the join is what defines the timestamps and primary keys for the backfill (notice that it is built on top of the &lt;code&gt;checkout&lt;/code&gt; event, as dictated by our use case).&lt;/p&gt;
    &lt;p&gt;Note that this &lt;code&gt;Join&lt;/code&gt; combines the above three &lt;code&gt;GroupBy&lt;/code&gt;s into one data definition. In the next step, we'll run the command to execute computation for this whole pipeline.&lt;/p&gt;
    &lt;p&gt;Once the join is defined, we compile it using this command:&lt;/p&gt;
    &lt;code&gt;compile.py --conf=joins/quickstart/training_set.py&lt;/code&gt;
    &lt;p&gt;This converts it into a thrift definition that we can submit to spark with the following command:&lt;/p&gt;
    &lt;code&gt;run.py --conf production/joins/quickstart/training_set.v1&lt;/code&gt;
    &lt;p&gt;The output of the backfill would contain the user_id and ts columns from the left source, as well as the 11 feature columns from the three GroupBys that we created.&lt;/p&gt;
    &lt;p&gt;Feature values would be computed for each user_id and ts on the left side, with guaranteed temporal accuracy. So, for example, if one of the rows on the left was for &lt;code&gt;user_id = 123&lt;/code&gt; and &lt;code&gt;ts = 2023-10-01 10:11:23.195&lt;/code&gt;, then the &lt;code&gt;purchase_price_avg_30d&lt;/code&gt; feature would be computed for that user with a precise 30 day window ending on that timestamp.&lt;/p&gt;
    &lt;p&gt;You can now query the backfilled data using the spark sql shell:&lt;/p&gt;
    &lt;code&gt;spark-sql&lt;/code&gt;
    &lt;p&gt;And then:&lt;/p&gt;
    &lt;code&gt;spark-sql&amp;gt; SELECT user_id, quickstart_returns_v1_refund_amt_sum_30d, quickstart_purchases_v1_purchase_price_sum_14d, quickstart_users_v1_email_verified from default.quickstart_training_set_v1 limit 100;&lt;/code&gt;
    &lt;p&gt;Note that this only selects a few columns. You can also run a &lt;code&gt;select * from default.quickstart_training_set_v1 limit 100&lt;/code&gt; to see all columns, however, note that the table is quite wide and the results might not be very readable on your screen.&lt;/p&gt;
    &lt;p&gt;To exit the sql shell you can run:&lt;/p&gt;
    &lt;code&gt;spark-sql&amp;gt; quit;&lt;/code&gt;
    &lt;p&gt;Now that we've created a join and backfilled data, the next step would be to train a model. That is not part of this tutorial, but assuming it was complete, the next step after that would be to productionize the model online. To do this, we need to be able to fetch feature vectors for model inference. That's what this next section covers.&lt;/p&gt;
    &lt;p&gt;In order to serve online flows, we first need the data uploaded to the online KV store. This is different than the backfill that we ran in the previous step in two ways:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The data is not a historic backfill, but rather the most up-to-date feature values for each primary key.&lt;/item&gt;
      &lt;item&gt;The datastore is a transactional KV store suitable for point lookups. We use MongoDB in the docker image, however you are free to integrate with a database of your choice.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Upload the purchases GroupBy:&lt;/p&gt;
    &lt;code&gt;run.py --mode upload --conf production/group_bys/quickstart/purchases.v1 --ds  2023-12-01

spark-submit --class ai.chronon.quickstart.online.Spark2MongoLoader --master local[*] /srv/onlineImpl/target/scala-2.12/mongo-online-impl-assembly-0.1.0-SNAPSHOT.jar default.quickstart_purchases_v1_upload mongodb://admin:admin@mongodb:27017/?authSource=admin&lt;/code&gt;
    &lt;p&gt;Upload the returns GroupBy:&lt;/p&gt;
    &lt;code&gt;run.py --mode upload --conf production/group_bys/quickstart/returns.v1 --ds  2023-12-01

spark-submit --class ai.chronon.quickstart.online.Spark2MongoLoader --master local[*] /srv/onlineImpl/target/scala-2.12/mongo-online-impl-assembly-0.1.0-SNAPSHOT.jar default.quickstart_returns_v1_upload mongodb://admin:admin@mongodb:27017/?authSource=admin&lt;/code&gt;
    &lt;p&gt;If we want to use the &lt;code&gt;FetchJoin&lt;/code&gt; api rather than &lt;code&gt;FetchGroupby&lt;/code&gt;, then we also need to upload the join metadata:&lt;/p&gt;
    &lt;code&gt;run.py --mode metadata-upload --conf production/joins/quickstart/training_set.v2&lt;/code&gt;
    &lt;p&gt;This makes it so that the online fetcher knows how to take a request for this join and break it up into individual GroupBy requests, returning the unified vector, similar to how the Join backfill produces the wide view table with all features.&lt;/p&gt;
    &lt;p&gt;With the above entities defined, you can now easily fetch feature vectors with a simple API call.&lt;/p&gt;
    &lt;p&gt;Fetching a join:&lt;/p&gt;
    &lt;code&gt;run.py --mode fetch --type join --name quickstart/training_set.v2 -k '{"user_id":"5"}'&lt;/code&gt;
    &lt;p&gt;You can also fetch a single GroupBy (this would not require the Join metadata upload step performed earlier):&lt;/p&gt;
    &lt;code&gt;run.py --mode fetch --type group-by --name quickstart/purchases.v1 -k '{"user_id":"5"}'&lt;/code&gt;
    &lt;p&gt;For production, the Java client is usually embedded directly into services.&lt;/p&gt;
    &lt;code&gt;Map&amp;lt;String, String&amp;gt; keyMap = new HashMap&amp;lt;&amp;gt;();
keyMap.put("user_id", "123");
Fetcher.fetch_join(new Request("quickstart/training_set_v1", keyMap))&lt;/code&gt;
    &lt;p&gt;sample response&lt;/p&gt;
    &lt;code&gt;&amp;gt; '{"purchase_price_avg_3d":14.3241, "purchase_price_avg_14d":11.89352, ...}'
&lt;/code&gt;
    &lt;p&gt;Note: This java code is not runnable in the docker env, it is just an illustrative example.&lt;/p&gt;
    &lt;p&gt;As discussed in the introductory sections of this README, one of Chronon's core guarantees is online/offline consistency. This means that the data that you use to train your model (offline) matches the data that the model sees for production inference (online).&lt;/p&gt;
    &lt;p&gt;A key element of this is temporal accuracy. This can be phrased as: when backfilling features, the value that is produced for any given &lt;code&gt;timestamp&lt;/code&gt; provided by the left side of the join should be the same as what would have been returned online if that feature was fetched at that particular &lt;code&gt;timestamp&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Chronon not only guarantees this temporal accuracy, but also offers a way to measure it.&lt;/p&gt;
    &lt;p&gt;The measurement pipeline starts with the logs of the online fetch requests. These logs include the primary keys and timestamp of the request, along with the fetched feature values. Chronon then passes the keys and timestamps to a Join backfill as the left side, asking the compute engine to backfill the feature values. It then compares the backfilled values to actual fetched values to measure consistency.&lt;/p&gt;
    &lt;p&gt;Step 1: log fetches&lt;/p&gt;
    &lt;p&gt;First, make sure you've ran a few fetch requests. Run:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;run.py --mode fetch --type join --name quickstart/training_set.v2 -k '{"user_id":"5"}'&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;A few times to generate some fetches.&lt;/p&gt;
    &lt;p&gt;With that complete, you can run this to create a usable log table (these commands produce a logging hive table with the correct schema):&lt;/p&gt;
    &lt;code&gt;spark-submit --class ai.chronon.quickstart.online.MongoLoggingDumper --master local[*] /srv/onlineImpl/target/scala-2.12/mongo-online-impl-assembly-0.1.0-SNAPSHOT.jar default.chronon_log_table mongodb://admin:admin@mongodb:27017/?authSource=admin
compile.py --conf group_bys/quickstart/schema.py
run.py --mode backfill --conf production/group_bys/quickstart/schema.v1
run.py --mode log-flattener --conf production/joins/quickstart/training_set.v2 --log-table default.chronon_log_table --schema-table default.quickstart_schema_v1&lt;/code&gt;
    &lt;p&gt;This creates a &lt;code&gt;default.quickstart_training_set_v2_logged&lt;/code&gt; table that contains the results of each of the fetch requests that you previously made, along with the timestamp at which you made them and the &lt;code&gt;user&lt;/code&gt; that you requested.&lt;/p&gt;
    &lt;p&gt;Note: Once you run the above command, it will create and "close" the log partitions, meaning that if you make additional fetches on the same day (UTC time) it will not append. If you want to go back and generate more requests for online/offline consistency, you can drop the table (run &lt;code&gt;DROP TABLE default.quickstart_training_set_v2_logged&lt;/code&gt; in a &lt;code&gt;spark-sql&lt;/code&gt; shell) before rerunning the above command.&lt;/p&gt;
    &lt;p&gt;Now you can compute consistency metrics with this command:&lt;/p&gt;
    &lt;code&gt;run.py --mode consistency-metrics-compute --conf production/joins/quickstart/training_set.v2&lt;/code&gt;
    &lt;p&gt;This job will take the primary key(s) and timestamps from the log table (&lt;code&gt;default.quickstart_training_set_v2_logged&lt;/code&gt; in this case), and uses those to create and run a join backfill. It then compares the backfilled results to the actual logged values that were fetched online&lt;/p&gt;
    &lt;p&gt;It produces two output tables:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;default.quickstart_training_set_v2_consistency&lt;/code&gt;: A human readable table that you can query to see the results of the consistency checks.&lt;list rend="ol"&gt;&lt;item&gt;You can enter a sql shell by running &lt;code&gt;spark-sql&lt;/code&gt;from your docker bash sesion, then query the table.&lt;/item&gt;&lt;item&gt;Note that it has many columns (multiple metrics per feature), so you might want to run a &lt;code&gt;DESC default.quickstart_training_set_v2_consistency&lt;/code&gt;first, then select a few columns that you care about to query.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;You can enter a sql shell by running &lt;/item&gt;
      &lt;item&gt;&lt;code&gt;default.quickstart_training_set_v2_consistency_upload&lt;/code&gt;: A list of KV bytes that is uploaded to the online KV store, that can be used to power online data quality monitoring flows. Not meant to be human readable.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Using chronon for your feature engineering work simplifies and improves your ML Workflow in a number of ways:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;You can define features in one place, and use those definitions both for training data backfills and for online serving.&lt;/item&gt;
      &lt;item&gt;Backfills are automatically point-in-time correct, which avoids label leakage and inconsistencies between training data and online inference.&lt;/item&gt;
      &lt;item&gt;Orchestration for batch and streaming pipelines to keep features up to date is made simple.&lt;/item&gt;
      &lt;item&gt;Chronon exposes easy endpoints for feature fetching.&lt;/item&gt;
      &lt;item&gt;Consistency is guaranteed and measurable.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For a more detailed view into the benefits of using Chronon, see Benefits of Chronon documentation.&lt;/p&gt;
    &lt;p&gt;Chronon offers the most value to AI/ML practitioners who are trying to build "online" models that are serving requests in real-time as opposed to batch workflows.&lt;/p&gt;
    &lt;p&gt;Without Chronon, engineers working on these projects need to figure out how to get data to their models for training/eval as well as production inference. As the complexity of data going into these models increases (multiple sources, complex transformation such as windowed aggregations, etc), so does the infrastructure challenge of supporting this data plumbing.&lt;/p&gt;
    &lt;p&gt;Generally, we observed ML practitioners taking one of two approaches:&lt;/p&gt;
    &lt;p&gt;With this approach, users start with the data that is available in the online serving environment from which the model inference will run. Log relevant features to the data warehouse. Once enough data has accumulated, train the model on the logs, and serve with the same data.&lt;/p&gt;
    &lt;p&gt;Pros:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Features used to train the model are guaranteed to be available at serving time&lt;/item&gt;
      &lt;item&gt;The model can access service call features&lt;/item&gt;
      &lt;item&gt;The model can access data from the the request context&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Cons:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It might take a long to accumulate enough data to train the model&lt;/item&gt;
      &lt;item&gt;Performing windowed aggregations is not always possible (running large range queries against production databases doesn't scale, same for event streams)&lt;/item&gt;
      &lt;item&gt;Cannot utilize the wealth of data already in the data warehouse&lt;/item&gt;
      &lt;item&gt;Maintaining data transformation logic in the application layer is messy&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With this approach, users train the model with data from the data warehouse, then figure out ways to replicate those features in the online environment.&lt;/p&gt;
    &lt;p&gt;Pros:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You can use a broad set of data for training&lt;/item&gt;
      &lt;item&gt;The data warehouse is well suited for large aggregations and other computationally intensive transformation&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Cons:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Often very error prone, resulting in inconsistent data between training and serving&lt;/item&gt;
      &lt;item&gt;Requires maintaining a lot of complicated infrastructure to even get started with this approach,&lt;/item&gt;
      &lt;item&gt;Serving features with realtime updates gets even more complicated, especially with large windowed aggregations&lt;/item&gt;
      &lt;item&gt;Unlikely to scale well to many models&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Chronon approach&lt;/p&gt;
    &lt;p&gt;With Chronon you can use any data available in your organization, including everything in the data warehouse, any streaming source, service calls, etc, with guaranteed consistency between online and offline environments. It abstracts away the infrastructure complexity of orchestrating and maintining this data plumbing, so that users can simply define features in a simple API, and trust Chronon to handle the rest.&lt;/p&gt;
    &lt;p&gt;We welcome contributions to the Chronon project! Please read CONTRIBUTING for details.&lt;/p&gt;
    &lt;p&gt;Use the GitHub issue tracker for reporting bugs or feature requests. Join our community Slack workspace for discussions, tips, and support.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45269661</guid><pubDate>Tue, 16 Sep 2025 23:30:29 +0000</pubDate></item><item><title>Fairchild PPS-25: 4-bit CPU for 25-digit precision</title><link>https://www.cpushack.com/2025/02/01/fairchild-pps-25-4-bit-cpu-for-25-digit-precision/</link><description>&lt;doc fingerprint="3f5122766d957768"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Fairchild PPS-25: 4-bit CPU for 25-digit precision&lt;/head&gt;
    &lt;p&gt;It’s been a long while since I have been able to post/write, having a new baby apparently does that (I missed that in the datasheet). Since I have neglected posting, or forgotten, lets continues with ‘The Forgotten Ones”&lt;/p&gt;
    &lt;p&gt;This brings us to 1971, Fairchild, after losing many employees in 1968-69 who went on to start world famous semiconductor companies (Intel and AMD amongst others) has decided to make their own processor system. This was very early in the era of CPUs, you had the Intel 4004, the TI TMS1000, and various calculator type circuits. The PPS-25 is a 400KHz (62.5uS Word cycle time, 2.5uS bitrate) PMOS processor, organized into several different chips. It is a 4-bit parallel, with 25 digit serial data, thus the name, Programmable Processor System 25. Each of those 62.5uS cycles is also divided into 25 micro instructions of 2.5uS, Now what would a 4-bit processor need 25 bit data? Precision, the PPS-25 was designed to fill the void (at the time) between high end calculator chips and actual mini-computers.&lt;/p&gt;
    &lt;p&gt;The PPS-25 systems core is the 3805 ALU and the 3806 Function/Timing chips. The 3805 (DIP18) includes the adder/subtractor as well as a 25 bit register (The accumulator). This accumulator was maskable as well, allowing different parts of it to be operated on with a 6-bit mask. This allowed a great amount of flexibility in programming. The 3806 chip (the largest of the chipset a DIP24) contains the timing and control logic, two 25-bit status registers, branch logic, the instruction address register, and various other logic functions. To support this core, is a pair of register chips, the 3808 and 3809 registers. These are basic shift registers and each contain three 4-bit BCD parallel, 25-digit serial register memories. Instructions are stored in up to 25 256×12 bit serial ROMs, the 3810. The address bus is 8-bits, and the instruction word is 12-bits so with 25 chips, you get 6400 instruction words of available instructions (or constants). 95 instructions were provided.&lt;/p&gt;
    &lt;p&gt;The PPS-25 also supports the 3811 for handling output, as well as the 3807/3803 input devices which support up to a 32 key keyboard (3807) or larger, 3803. Both these chips came in 40DIP packages, larger then the CPU itself.&lt;/p&gt;
    &lt;p&gt;This design was a bit complicated, and took several chips, so it did not see wide adoption, Fairchild ‘de-emphasized’ it by 1974 as they were working then on the F8 processor. The PPS-25 did however find its uses, and inspired other designs as well. HP considered using the PPS-25 in its calculator designs, before deciding to make their own CPU’s in house (Saturn, Nut etc). The design and programming of which bare a strong resemblance to the PPS-25.&lt;/p&gt;
    &lt;p&gt;One of the more known uses of the PPS-25 was in the Cybernetic Mathiputer, an early learning toy for children but its use was not limited to such trivial devices. It was also used where precise math work was needed. a Walsh Spectrum Analyser design chose it above the what would normally be considered much more powerful Intel 8080 largely due to its math capabilities.&lt;/p&gt;
    &lt;p&gt;Its turns out making a CPU function more like an advanced calculator allowed it to do advanced math fairly well. It was also chosen for calculating SINC/COSC values for an engineering system.&lt;/p&gt;
    &lt;p&gt;Another field where precise math is needed is in navigation, and the PPS-25 found a home here as well. King Radio Corp (now Honeywell) designed a Radio Navigation computer for airplanes in the 1970s based on the PPS-25. Around 500 of these were made and were found in such planes as the Piper PA-31T Cheyenne, Cessna 441 Conquest II, and Beech King Air, high end twin turbo props of the era. Interestingly King had difficulties sourcing replacements for these, so a common upgrade to these nav computers was replacing the PPS-25 with a custom ASIC and a Motorola 6802 CPU.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45269673</guid><pubDate>Tue, 16 Sep 2025 23:32:05 +0000</pubDate></item><item><title>I launched a Mac utility; now there are 5 clones on the App Store using my story</title><link>https://news.ycombinator.com/item?id=45269827</link><description>&lt;doc fingerprint="70d016933597199f"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;I'm a solo dev, and I wanted to share a recent experience as a case study on the current state of the App Store and indie development.&lt;/p&gt;
      &lt;p&gt;A few months ago, I built a simple macOS utility to solve a personal frustration: verifying the actual speed of USB-C cables and devices in the Mac menu bar. It is call USB Connection Information and it supports macOS 13 and up. Before launch, there were no other apps in this specific niche on the Mac App Store. The app became unexpectedly successful, hitting the top 100 paid utilities and getting a good amount of organic press.&lt;/p&gt;
      &lt;p&gt;In the last two weeks, at least five near-identical apps have appeared on the App Store. The concerning part is that some of these clones have copied my App Store description, including my personal origin story about why I built the app.&lt;/p&gt;
      &lt;p&gt;A few open-source clones have also appeared on GitHub, which I see as a positive community contribution. My concern is with the commercial clones on the App Store that are engaging in plagiarism.&lt;/p&gt;
      &lt;p&gt;This raises a few questions I'd be interested to hear HN's thoughts on:&lt;/p&gt;
      &lt;p&gt;I've been transparent about my success on Reddit. How much are LLMs lowering the barrier to entry, allowing others to take a validated idea and marketing copy and generate a functional clone in a matter of days?&lt;/p&gt;
      &lt;p&gt;It seems that derivative apps with plagiarized descriptions and app elements are being approved without issue. Does this signal a shift in App curation?&lt;/p&gt;
      &lt;p&gt;My app's value is its simplicity. In an environment where simple, successful ideas can be replicated this quickly, what is the moat? Is it brand, speed of innovation, marketing, or something else?&lt;/p&gt;
      &lt;p&gt;Curious to hear your perspectives.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45269827</guid><pubDate>Tue, 16 Sep 2025 23:51:39 +0000</pubDate></item><item><title>Apple releases iOS 15.8.5 security update for 10-year old iPhone 6s</title><link>https://support.apple.com/en-us/125142</link><description>&lt;doc fingerprint="b546dd2c1066535e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;About the security content of iOS 15.8.5 and iPadOS 15.8.5&lt;/head&gt;
    &lt;p&gt;This document describes the security content of iOS 15.8.5 and iPadOS 15.8.5.&lt;/p&gt;
    &lt;head rend="h2"&gt;About Apple security updates&lt;/head&gt;
    &lt;p&gt;For our customers' protection, Apple doesn't disclose, discuss, or confirm security issues until an investigation has occurred and patches or releases are available. Recent releases are listed on the Apple security releases page.&lt;/p&gt;
    &lt;p&gt;Apple security documents reference vulnerabilities by CVE-ID when possible.&lt;/p&gt;
    &lt;p&gt;For more information about security, see the Apple Product Security page.&lt;/p&gt;
    &lt;head rend="h2"&gt;iOS 15.8.5 and iPadOS 15.8.5&lt;/head&gt;
    &lt;p&gt;Released September 15, 2025&lt;/p&gt;
    &lt;head rend="h3"&gt;ImageIO&lt;/head&gt;
    &lt;p&gt;Available for: iPhone 6s (all models), iPhone 7 (all models), iPhone SE (1st generation), iPad Air 2, iPad mini (4th generation), and iPod touch (7th generation)&lt;/p&gt;
    &lt;p&gt;Impact: Processing a malicious image file may result in memory corruption. Apple is aware of a report that this issue may have been exploited in an extremely sophisticated attack against specific targeted individuals.&lt;/p&gt;
    &lt;p&gt;Description: An out-of-bounds write issue was addressed with improved bounds checking.&lt;/p&gt;
    &lt;p&gt;CVE-2025-43300: Apple&lt;/p&gt;
    &lt;p&gt;Information about products not manufactured by Apple, or independent websites not controlled or tested by Apple, is provided without recommendation or endorsement. Apple assumes no responsibility with regard to the selection, performance, or use of third-party websites or products. Apple makes no representations regarding third-party website accuracy or reliability. Contact the vendor for additional information.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45270108</guid><pubDate>Wed, 17 Sep 2025 00:34:02 +0000</pubDate></item></channel></rss>