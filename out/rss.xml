<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 03 Oct 2025 18:43:36 +0000</lastBuildDate><item><title>I spent the day teaching seniors how to use an iPhone</title><link>https://forums.macrumors.com/threads/i-spent-the-day-trying-to-teach-seniors-how-to-use-an-iphone-and-it-was-a-nightmare.2468117/</link><description>&lt;doc fingerprint="ae3e8916e6c093d8"&gt;
  &lt;main&gt;
    &lt;p&gt;Honestly, I think Apple really needs to simplify the iPhone for the elderly. I know there are accessibility modes, but you don’t want to have to go through all that and spend hours trying to customize the phone. Also, the whole phone setup process needs to be delayed; having to go through it for an hour puts them off from even wanting to bother. I first set the phones up to make accounts, but it turns out none of them could understand how to unlock the phone. Entering a passcode was a nightmare because they kept forgetting it, even though it was a birthday they knew, lol. &lt;lb/&gt;So, I tried Touch ID and Face ID, and that was even more complicated and kept erroring out. Then, the Siri thing kept popping up on the phones with Touch ID, despite turning it off, and the whole swiping from the button kept making the screen go down to the bottom half. :/ There were too many apps; all they wanted was the phone app, but it doesn’t default to the keypad, which was too much for them to find.&lt;lb/&gt;The phones are too fiddly now, and pressing random things as they try to hold the phone meant the phone got lost in a sea of opening stuff up. So, I tried the assistive access, but why isn’t this an option from the get-go? It asks you the age of setup; why not have a 65+ or something for a senior mode?&lt;lb/&gt;They don’t need passcodes, accounts, and a sea of information. It’s insane, and it’s insane how fiddly these phones are. I never noticed because I’m used to it, but for these people with hands that barely move, the fake Touch ID button and the swiping from the bottom on Face ID phones seem to be the worst! I think having a proper physical button, like iPhones used to have, would have been superior. The one complaint about the fake button was that it didn’t feel like a real button, so they couldn’t gauge it.&lt;lb/&gt;I left there achieving nothing because they couldn’t figure out their old Nokia phones. The unlock thing on the keypad was too difficult, and if I turned that off, they kept dialing 999 in their pockets for some reason. That’s why I was there: they were calling emergency services 100 times a day, lol.&lt;lb/&gt;I think what I’ve realized is that I need to go back with flip phones that answer and hang up when you open and close them. However, the two I tried before didn’t act like that, and they had too many features. I really thought I could make the iPhone simple, but NOPE!&lt;lb/&gt;Apple should work on their phones to make them more accessible and less fiddly, without having to go through a sea of menus.&lt;/p&gt;
    &lt;p&gt;So, I tried Touch ID and Face ID, and that was even more complicated and kept erroring out. Then, the Siri thing kept popping up on the phones with Touch ID, despite turning it off, and the whole swiping from the button kept making the screen go down to the bottom half. :/ There were too many apps; all they wanted was the phone app, but it doesn’t default to the keypad, which was too much for them to find.&lt;/p&gt;
    &lt;p&gt;The phones are too fiddly now, and pressing random things as they try to hold the phone meant the phone got lost in a sea of opening stuff up. So, I tried the assistive access, but why isn’t this an option from the get-go? It asks you the age of setup; why not have a 65+ or something for a senior mode?&lt;/p&gt;
    &lt;p&gt;They don’t need passcodes, accounts, and a sea of information. It’s insane, and it’s insane how fiddly these phones are. I never noticed because I’m used to it, but for these people with hands that barely move, the fake Touch ID button and the swiping from the bottom on Face ID phones seem to be the worst! I think having a proper physical button, like iPhones used to have, would have been superior. The one complaint about the fake button was that it didn’t feel like a real button, so they couldn’t gauge it.&lt;/p&gt;
    &lt;p&gt;I left there achieving nothing because they couldn’t figure out their old Nokia phones. The unlock thing on the keypad was too difficult, and if I turned that off, they kept dialing 999 in their pockets for some reason. That’s why I was there: they were calling emergency services 100 times a day, lol.&lt;/p&gt;
    &lt;p&gt;I think what I’ve realized is that I need to go back with flip phones that answer and hang up when you open and close them. However, the two I tried before didn’t act like that, and they had too many features. I really thought I could make the iPhone simple, but NOPE!&lt;/p&gt;
    &lt;p&gt;Apple should work on their phones to make them more accessible and less fiddly, without having to go through a sea of menus.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45457670</guid><pubDate>Fri, 03 Oct 2025 01:20:32 +0000</pubDate></item><item><title>Fp8 runs ~100 tflops faster when the kernel name has "cutlass" in it</title><link>https://github.com/triton-lang/triton/pull/7298</link><description>&lt;doc fingerprint="cef8dd4f2e620e8a"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Notifications &lt;tool-tip&gt;You must be signed in to change notification settings&lt;/tool-tip&gt;&lt;/item&gt;
      &lt;item&gt;Fork 2.3k&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;[Gluon][Tutorial] Persistent attention #7298&lt;/head&gt;
    &lt;head id="button-4b13e3ca7d020057" class="btn btn-sm btn-primary m-0 ml-0 ml-md-2"&gt;New issue&lt;/head&gt;
    &lt;p&gt;Have a question about this project? Sign up for a free GitHub account to open an issue and contact its maintainers and the community.&lt;/p&gt;
    &lt;p&gt;By clicking “Sign up for GitHub”, you agree to our terms of service and privacy statement. We’ll occasionally send you account related emails.&lt;/p&gt;
    &lt;p&gt;Already on GitHub? Sign in to your account&lt;/p&gt;
    &lt;head rend="h2"&gt;Conversation&lt;/head&gt;
    &lt;p&gt;Rewrite the attention kernel to be persistent. This gives better performance at low-contexts. However, fp16 at large context has suffered a bit due to a ptxas instruction scheduling issue in the softmax partition. fp8 is ~100 tflops faster when the kernel name has "cutlass" in it.&lt;/p&gt;
    &lt;code&gt;Attention Z=4 H=32 D=64 causal=False:
     N_CTX  triton-fp16  triton-fp8
0   1024.0   359.574448  370.119987
1   2048.0   612.103928  641.204555
2   4096.0   653.868402  682.337948
3   8192.0   692.102228  721.555690
4  16384.0   696.972041  726.190035
5  32768.0   698.723685  727.983456
6  65536.0   699.865817  728.558321
Attention Z=4 H=32 D=64 causal=True:
     N_CTX  triton-fp16  triton-fp8
0   1024.0   181.879039  177.982453
1   2048.0   441.315463  454.310072
2   4096.0   532.170527  539.995252
3   8192.0   633.620646  638.544937
4  16384.0   667.687180  670.681255
5  32768.0   684.276329  688.571907
6  65536.0   692.953202  694.648353
Attention Z=4 H=32 D=128 causal=False:
     N_CTX  triton-fp16   triton-fp8
0   1024.0   718.580015   709.863720
1   2048.0  1133.490258  1222.548477
2   4096.0  1247.605551  1369.800195
3   8192.0  1243.482713  1406.799697
4  16384.0  1125.744367  1514.857403
5  32768.0  1124.116305  1521.267973
6  65536.0  1064.588719  1518.738037
Attention Z=4 H=32 D=128 causal=True:
     N_CTX  triton-fp16   triton-fp8
0   1024.0   355.642522   351.161232
1   2048.0   846.404095   854.547917
2   4096.0  1013.840017  1021.676435
3   8192.0  1176.258395  1152.844234
4  16384.0  1190.290681  1325.786204
5  32768.0  1063.658200  1394.413325
6  65536.0   970.531569  1413.282610
&lt;/code&gt;
    &lt;p&gt;There was a problem hiding this comment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Choose a reason for hiding this comment&lt;/head&gt;
    &lt;p&gt;The reason will be displayed to describe this comment to others. Learn more.&lt;/p&gt;
    &lt;p&gt;wow!&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;For posterity, these are the best results prior to converting the kernel to persistent&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;I don't see a "cutlass" in the kernel names?&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Before:&lt;/p&gt;
          &lt;p&gt;After&lt;/p&gt;
          &lt;p&gt;I'm not sure if I interpreted it incorrectly, but seems like perf is dropped based on the numbers?&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;There was a problem hiding this comment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Choose a reason for hiding this comment&lt;/head&gt;
    &lt;p&gt;The reason will be displayed to describe this comment to others. Learn more.&lt;/p&gt;
    &lt;p&gt;Great stuff. Couple small NITs though.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;_, corr_bar, corr_producer = corr_producer.acquire()&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"/&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;p = gl.join(p0, p1).permute(0, 2, 1).reshape([config.SPLIT_M, config.BLOCK_N])&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;p = gl.convert_layout(p, config.qk_layout)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;There was a problem hiding this comment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Choose a reason for hiding this comment&lt;/head&gt;
    &lt;p&gt;The reason will be displayed to describe this comment to others. Learn more.&lt;/p&gt;
    &lt;p&gt;This shouldn't be needed any more after I introduced the slice layout for split, right?&lt;/p&gt;
    &lt;p&gt;There was a problem hiding this comment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Choose a reason for hiding this comment&lt;/head&gt;
    &lt;p&gt;The reason will be displayed to describe this comment to others. Learn more.&lt;/p&gt;
    &lt;p&gt;The convert layout coming out of the &lt;code&gt;split&lt;/code&gt; is no longer needed, but&lt;/p&gt;
    &lt;code&gt;ValueError('Layout mismatch in broadcast: 

SliceLayout(dim=1, parent=BlockedLayout(size_per_thread=[1, 128], threads_per_warp=[32, 1], warps_per_cta=[4, 1], order=[0, 1], ctas_per_cga=[1, 1], cta_split_num=[1, 1], cta_order=[1, 0])) 
vs 
SliceLayout(dim=1, parent=DistributedLinearLayout(reg_bases=[[0, 64], [0, 1], [0, 2], [0, 4], [0, 8], [0, 16], [0, 32]], lane_bases=[[1, 0], [2, 0], [4, 0], [8, 0], [16, 0]], warp_bases=[[32, 0], [64, 0]], block_bases=[], shape=[128, 128]))')
&lt;/code&gt;
    &lt;p&gt;It seems that &lt;code&gt;p&lt;/code&gt; ends up with a linear layout instead of a blocked layout. I am not sure why though -- I believe the layout inference should try a blocked layout first before falling back to linear layout.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;name = "gluon_attention"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;# Up to 150 TFLOPS faster for fp8!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;if specialization.constants["dtype"] == gl.float8e5:&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;name = "cutlass_" + name&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;There was a problem hiding this comment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Choose a reason for hiding this comment&lt;/head&gt;
    &lt;p&gt;The reason will be displayed to describe this comment to others. Learn more.&lt;/p&gt;
    &lt;p&gt;very cool... did you check if other names change the scheduling (e.g. because of non-determinism or code alignment) or if it's literally just special cased for cutlass.&lt;/p&gt;
    &lt;p&gt;There was a problem hiding this comment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Choose a reason for hiding this comment&lt;/head&gt;
    &lt;p&gt;The reason will be displayed to describe this comment to others. Learn more.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;it's literally just special cased for cutlass.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Yup&lt;/p&gt;
    &lt;p&gt;There was a problem hiding this comment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Choose a reason for hiding this comment&lt;/head&gt;
    &lt;p&gt;The reason will be displayed to describe this comment to others. Learn more.&lt;/p&gt;
    &lt;p&gt;wow! You literally beat the nvcc team!&lt;/p&gt;
    &lt;p&gt;There was a problem hiding this comment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Choose a reason for hiding this comment&lt;/head&gt;
    &lt;p&gt;The reason will be displayed to describe this comment to others. Learn more.&lt;/p&gt;
    &lt;p&gt;@AlexMaclean Just a FYI, in case you can prod the right folks on your side. There must be a better way to enable this optimization. A PTX directive, perhaps, if ptxas can't figure out the right thing by itself?&lt;/p&gt;
    &lt;p&gt;There was a problem hiding this comment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Choose a reason for hiding this comment&lt;/head&gt;
    &lt;p&gt;The reason will be displayed to describe this comment to others. Learn more.&lt;/p&gt;
    &lt;p&gt;@Mogball have you checked the accuracy, is it the same? The Deepseek technical report mentioned that fp8 tensor cores use reduced mantissa for the accumulator, maybe this is what indirectly enabled/disabled by the name of the kernel.&lt;/p&gt;
    &lt;p&gt;There was a problem hiding this comment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Choose a reason for hiding this comment&lt;/head&gt;
    &lt;p&gt;The reason will be displayed to describe this comment to others. Learn more.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The Deepseek technical report mentioned that fp8 tensor cores use reduced mantissa for the accumulator, maybe this is what indirectly enabled/disabled by the name of the kernel.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That's only on Hopper&lt;/p&gt;
    &lt;p&gt;There was a problem hiding this comment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Choose a reason for hiding this comment&lt;/head&gt;
    &lt;p&gt;The reason will be displayed to describe this comment to others. Learn more.&lt;/p&gt;
    &lt;p&gt;There was a problem hiding this comment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Choose a reason for hiding this comment&lt;/head&gt;
    &lt;p&gt;The reason will be displayed to describe this comment to others. Learn more.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;By disassembly of&lt;/p&gt;&lt;code&gt;ptxas&lt;/code&gt;, it is indeed hard-coded that they have logic like&lt;code&gt;strstr(kernel_name, "cutlass")&lt;/code&gt;.&lt;/quote&gt;
    &lt;p&gt;That's Interesting! I'm curious is it feasible to modifty asm code for &lt;code&gt;ptxas&lt;/code&gt; that make the &lt;code&gt;al&lt;/code&gt; return register always be true (maybe we could modify code in the address between &lt;code&gt;2165-216c&lt;/code&gt;), did you have a try?&lt;/p&gt;
    &lt;p&gt;There was a problem hiding this comment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Choose a reason for hiding this comment&lt;/head&gt;
    &lt;p&gt;The reason will be displayed to describe this comment to others. Learn more.&lt;/p&gt;
    &lt;p&gt;Admittedly it is feasible. But it is more likely that, this is an unstable, experimental, aggressive optimization by NVIDIA, and blindly always enabling it may produce some elusive bugs.&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;For D64 it did drop quite a bit during the transition to persistent. This is due to a scheduling issue in ptxas that I couldn't find a workaround for.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45458948</guid><pubDate>Fri, 03 Oct 2025 04:21:23 +0000</pubDate></item><item><title>In Praise of RSS and Controlled Feeds of Information</title><link>https://blog.burkert.me/posts/in_praise_of_syndication/</link><description>&lt;doc fingerprint="e6f45a221ea4acb5"&gt;
  &lt;main&gt;
    &lt;p&gt;The way we consume content on the internet is increasingly driven by walled-garden platforms and black-box feed algorithms. This shift is making our media diets miserable. Ironically, a solution to the problem predates algorithmic feeds, social media and other forms of informational junk food. It is called RSS (Really Simple Syndication) and it is beautiful.&lt;/p&gt;
    &lt;head rend="h2"&gt;What the hell is RSS?&lt;/head&gt;
    &lt;p&gt;RSS is just a format that defines how websites can publish updates (articles, posts, episodes, and so on) in a standard feed that you can subscribe to using an RSS reader (or aggregator). Don’t worry if this sounds extremely uninteresting to you; there aren’t many people that get excited about format specifications; the beauty of RSS is in its simplicity. Any content management system or blog platform supports RSS out of the box, and often enables it by default. As a result, a large portion of the content on the internet is available to you in feeds that you can tap into. But this time, you’re in full control of what you’re receiving, and the feeds are purely reverse chronological bliss. Coincidentally, you might already be using RSS without even knowing, because the whole podcasting world runs on RSS.&lt;/p&gt;
    &lt;p&gt;There are many amazing articles about the utility and elegance of RSS, and I do not think the world needs another, so I will spare you and instead focus on my personal experience and tips. If you are interested in a deeper dive, I highly recommend Molly White’s article Curate your own newspaper with RSS. It is a convincing, well-written article that you can also listen to in Molly’s own voice if you wish to.&lt;/p&gt;
    &lt;head rend="h2"&gt;Broken distribution models&lt;/head&gt;
    &lt;p&gt;Here’s a little story about the promise of social media. In 2011, my band was getting a little more serious and preparing to record our first album. Facebook was rapidly growing all over the world, so I created an account - mostly to manage my band’s Facebook page. Back then, social media (and Facebook in particular) felt very different: vibrant and full of promise for the brave new future of web 2.0. I looked up all my favorite bands so that every time they put out an album or tour near me, I wouldn’t miss it. Many bands either lacked proper websites or rarely updated them in a useful way, so this felt like the perfect use case for Facebook.&lt;/p&gt;
    &lt;p&gt;It didn’t take long for me to start seeing the cracks. As Facebook would push for more engagement, some bands would flood their pages with multiple posts per day, especially if they were touring or had a new release coming up. Others would be more restrained, but then their posts would often be lost in the feed. There was no way to opt in only for a certain type of updates from my followed pages, and the increasingly algorithmic feed would simply prioritize posts by engagement. I realized that I wouldn’t be able to get just the important updates; instead, I’d get a wild mish-mash of engagement-bait that I wasn’t willing to work my way through. And don’t get me started about how over time, page owners had to pay to promote their posts to get any reach on the platform - that is simply extortion.&lt;/p&gt;
    &lt;p&gt;I no longer use Facebook (or any similar social media for that matter) for many reasons, though algorithmic feeds are at the top of the list. Algorithms on social media are very unlikely to be written with your best interest in mind: The goal of social media is to keep you glued to the feed for as long as possible. It optimizes for the most time spent, for engagement, for serving the most ads. It will not necessarily optimize for keeping you well informed, showing you balanced opinions, giving you control or even showing you all the information you’d like. The misalignment of incentives has become very apparent in the last few years, but the problem goes deeper. Any type of curation (because algorithmic feeds are simply curation machines) will never be flexible enough to account for every person’s needs. The story we are sold with algorithmic curation is that it adapts to everyone’s taste and interests, but that’s only true until the interests of the advertisers enter the picture.&lt;/p&gt;
    &lt;head rend="h2"&gt;How I use RSS&lt;/head&gt;
    &lt;p&gt;My RSS journey starting many moons ago with Opera and Thunderbird, continued with Google Reader (RIP) and The Old Reader, and finally led me to running my own instance of FreshRSS. However, in the last year, I have read most of the content from my RSS feeds on my phone via the FeedMe app. I find that it scratches the itch of unlocking your phone and wanting to see something novel (probably gravitating towards social media). On the upside, it feeds me only articles and media that a) I have picked upfront and nothing more, b) is typically longer-form and more thoughtful than your typical social media posts.&lt;/p&gt;
    &lt;p&gt;Also, unlike algorithmic feeds, it allows me to pick what category of my interests I am in the mood for. If I’m in the mood for something lighter, I can just look into my “Fun” folder to check out new stuff from The Oatmeal or xkcd. If I feel like reading something more thoughtful, I’d dive into my “Reads” folder for The Marginalian or Sentiers. Feeling like catching up on the newest AI research? I can browse the latest research papers from arXiv that have specific keywords in the abstracts (such as prompt injection). Or I could just browse everything at once to see what piques my interest. I am the master of what information I consume, how and in what order, and no one can take that away from me by rearranging my feed or tweaking the algorithm.&lt;/p&gt;
    &lt;p&gt;One of the many small advantages is the consistency of the interface and the lack of distractions when reading. Modern browsers support reader modes, but you need to enter the mode manually and some pages might not be displayed correctly. I don’t have any attention problems (that I know of), but reading articles on certain newspaper sites feels like a cruel joke: the text of the article is often drowned by ads, suggested articles, polls, and other visual smog. Not a pleasant reading experience. Your RSS reader always uses the same font, font size, screen real estate and never shows anything but the article itself.&lt;/p&gt;
    &lt;p&gt;The focused, reductive nature of RSS readers means you don’t get the full website experience, but that is arguably for the better in a lot of cases. We already mentioned the lack of suggested articles with engagement bait that could easily draw you in, but another notable omission is the comments section. It is very easy to slip into the comments section at the bottom of an article and spend far too much time reading those. You can still do that in an RSS reader by opening the article in your browser, scrolling down to the comments and diving in. At least in my case, that is a safe amount of friction to prevent me from doing it most of the time. Less is more!&lt;/p&gt;
    &lt;head rend="h2"&gt;Tips to get you going&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Many of the websites you open regularly, follow on social media or get a newsletter from, likely have an RSS feed. Look out for the RSS icon or the words RSS or feed. There are also tools like Lighthouse that can sniff out the feed for you. That said, my experience is that simply adding the homepage URL of the website into an aggregator usually works.&lt;/item&gt;
      &lt;item&gt;Remember my frustration with Facebook as a source of news for new music releases? Turns out there is a much better free solution called Muspy, where you enter all your favorite artists and it will notify you of their new releases. And guess what? You either get notified via email, or you use your personal RSS feed. Highly recommended!&lt;/item&gt;
      &lt;item&gt;Start easy with something like The Old Reader or Feedly - both offer relatively generous free tiers. And if you outgrow them or want to try something else, you simply export an OPML file with all your feeds and import them into your new RSS solution. This is the upside of open standards: freedom, ownership, and portability.&lt;/item&gt;
      &lt;item&gt;Once you have more than 5-10 feeds, start putting them into folders/categories. No need to overthink it, but doing this will help you be more selective about the content you read if you’re in a specific mood.&lt;/item&gt;
      &lt;item&gt;RSS readers can be great when traveling or whenever your internet connection might be down or spotty. You can set up your RSS client in a way that automatically fetches new content, so when you board the plane and go dark, you can still read through the already downloaded articles. (Beware, though: not all RSS feeds include full content - sometimes they’re more like teasers.)&lt;/item&gt;
      &lt;item&gt;Some websites that limit how many articles you can browse for free are actually less strict about content accessed through RSS feeds. There are obvious ethical concerns with abusing this, but it is still an upside, and you are only consuming what they provide.&lt;/item&gt;
      &lt;item&gt;If you want to tinker, you can set up an RSS aggregator like FreshRSS, tiny tiny RSS or selfoss on a shared web hosting service. If you want to go full self-hosted, there are many more options available.&lt;/item&gt;
      &lt;item&gt;Get a good mobile app. Try a few before you settle! This is a highly personal choice because even small UI quirks and differences may bother you. If you’re anything like me, you’ll do most of the reading on your phone, so make sure it feels good.&lt;/item&gt;
      &lt;item&gt;RSS readers/clients often have bookmarking/starring system which works much like dedicated bookmarking apps.&lt;/item&gt;
      &lt;item&gt;Bigger publications often have separate feeds for individual categories or tags - check those to avoid getting your main feed flooded.&lt;/item&gt;
      &lt;item&gt;Some websites have very elaborate RSS APIs which allow you to query for specific types of content. For example, arXiv has a really elaborate one, allowing you to only follow specific topics. The documentation is quite complex, so here is a quick example to kick start you:&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;https://export.arxiv.org/api/query?search_query=abs:LLM+AND+multilingual&amp;amp;sortBy=submittedDate&amp;amp;sortOrder=descending&lt;/code&gt;&lt;/item&gt;&lt;item&gt;The query searches through the most recently submitted papers with the words LLM and multilingual in the abstract.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Do a little cleanup from time to time: unsubscribe from feeds that no longer seem to interest you. It’s fine, no one will take offense, and your attention is too precious to be wasted on stuff that is not for you.&lt;/item&gt;
      &lt;item&gt;Don’t know where to start? Check out this list of 100 most popular RSS feeds, Feedspot’s 70 most popular feeds or Hostinger’s list of 55 popular blogs. Apart from that, Google is your friend (especially if you start searching for specific topics or niches), and good blogs often link to other blogs - all you need to do is to follow the breadcrumbs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Happy RSS-ing!&lt;/p&gt;
    &lt;p&gt;EDIT: Hello, Hacker News! Thrilled to be on the front page.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45459233</guid><pubDate>Fri, 03 Oct 2025 05:13:47 +0000</pubDate></item><item><title>Niri – A scrollable-tiling Wayland compositor</title><link>https://github.com/YaLTeR/niri</link><description>&lt;doc fingerprint="f76fe4761cb74b90"&gt;
  &lt;main&gt;
    &lt;p&gt;A scrollable-tiling Wayland compositor.&lt;/p&gt;
    &lt;p&gt;Getting Started | Configuration | Setup Showcase&lt;/p&gt;
    &lt;p&gt;Windows are arranged in columns on an infinite strip going to the right. Opening a new window never causes existing windows to resize.&lt;/p&gt;
    &lt;p&gt;Every monitor has its own separate window strip. Windows can never "overflow" onto an adjacent monitor.&lt;/p&gt;
    &lt;p&gt;Workspaces are dynamic and arranged vertically. Every monitor has an independent set of workspaces, and there's always one empty workspace present all the way down.&lt;/p&gt;
    &lt;p&gt;The workspace arrangement is preserved across disconnecting and connecting monitors where it makes sense. When a monitor disconnects, its workspaces will move to another monitor, but upon reconnection they will move back to the original monitor.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Built from the ground up for scrollable tiling&lt;/item&gt;
      &lt;item&gt;Dynamic workspaces like in GNOME&lt;/item&gt;
      &lt;item&gt;An Overview that zooms out workspaces and windows&lt;/item&gt;
      &lt;item&gt;Built-in screenshot UI&lt;/item&gt;
      &lt;item&gt;Monitor and window screencasting through xdg-desktop-portal-gnome &lt;list rend="ul"&gt;&lt;item&gt;You can block out sensitive windows from screencasts&lt;/item&gt;&lt;item&gt;Dynamic cast target that can change what it shows on the go&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Touchpad and mouse gestures&lt;/item&gt;
      &lt;item&gt;Group windows into tabs&lt;/item&gt;
      &lt;item&gt;Configurable layout: gaps, borders, struts, window sizes&lt;/item&gt;
      &lt;item&gt;Gradient borders with Oklab and Oklch support&lt;/item&gt;
      &lt;item&gt;Animations with support for custom shaders&lt;/item&gt;
      &lt;item&gt;Live-reloading config&lt;/item&gt;
      &lt;item&gt;Works with screen readers&lt;/item&gt;
    &lt;/list&gt;
    &lt;head class="px-3 py-2"&gt;demo.mp4&lt;/head&gt;
    &lt;p&gt;Also check out this video from Brodie Robertson that showcases a lot of the niri functionality: Niri Is My New Favorite Wayland Compositor&lt;/p&gt;
    &lt;p&gt;Niri is stable for day-to-day use and does most things expected of a Wayland compositor. Many people are daily-driving niri, and are happy to help in our Matrix channel.&lt;/p&gt;
    &lt;p&gt;Give it a try! Follow the instructions on the Getting Started page. Have your waybars and fuzzels ready: niri is not a complete desktop environment. Also check out awesome-niri, a list of niri-related links and projects.&lt;/p&gt;
    &lt;p&gt;Here are some points you may have questions about:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Multi-monitor: yes, a core part of the design from the very start. Mixed DPI works.&lt;/item&gt;
      &lt;item&gt;Fractional scaling: yes, plus all niri UI stays pixel-perfect.&lt;/item&gt;
      &lt;item&gt;NVIDIA: seems to work fine.&lt;/item&gt;
      &lt;item&gt;Floating windows: yes, starting from niri 25.01.&lt;/item&gt;
      &lt;item&gt;Input devices: niri supports tablets, touchpads, and touchscreens. You can map the tablet to a specific monitor, or use OpenTabletDriver. We have touchpad gestures, but no touchscreen gestures yet.&lt;/item&gt;
      &lt;item&gt;Wlr protocols: yes, we have most of the important ones like layer-shell, gamma-control, screencopy. You can check on wayland.app at the bottom of each protocol's page.&lt;/item&gt;
      &lt;item&gt;Performance: while I run niri on beefy machines, I try to stay conscious of performance. I've seen someone use it fine on an Eee PC 900 from 2008, of all things.&lt;/item&gt;
      &lt;item&gt;Xwayland: integrated via xwayland-satellite starting from niri 25.08.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;niri: Making a Wayland compositor in Rust · December 2024&lt;/p&gt;
    &lt;p&gt;My talk from the 2024 Moscow RustCon about niri, and how I do randomized property testing and profiling, and measure input latency. The talk is in Russian, but I prepared full English subtitles that you can find in YouTube's subtitle language selector.&lt;/p&gt;
    &lt;p&gt;An interview with Ivan, the developer behind Niri · June 2025&lt;/p&gt;
    &lt;p&gt;An interview by a German tech podcast Das Triumvirat (in English). We talk about niri development and history, and my experience building and maintaining niri.&lt;/p&gt;
    &lt;p&gt;A tour of the niri scrolling-tiling Wayland compositor · July 2025&lt;/p&gt;
    &lt;p&gt;An LWN article with a nice overview and introduction to niri.&lt;/p&gt;
    &lt;p&gt;If you'd like to help with niri, there are plenty of both coding- and non-coding-related ways to do so. See CONTRIBUTING.md for an overview.&lt;/p&gt;
    &lt;p&gt;Niri is heavily inspired by PaperWM which implements scrollable tiling on top of GNOME Shell.&lt;/p&gt;
    &lt;p&gt;One of the reasons that prompted me to try writing my own compositor is being able to properly separate the monitors. Being a GNOME Shell extension, PaperWM has to work against Shell's global window coordinate space to prevent windows from overflowing.&lt;/p&gt;
    &lt;p&gt;Here are some other projects which implement a similar workflow:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PaperWM: scrollable tiling on top of GNOME Shell.&lt;/item&gt;
      &lt;item&gt;karousel: scrollable tiling on top of KDE.&lt;/item&gt;
      &lt;item&gt;scroll and papersway: scrollable tiling on top of sway/i3.&lt;/item&gt;
      &lt;item&gt;hyprscrolling and hyprslidr: scrollable tiling on top of Hyprland.&lt;/item&gt;
      &lt;item&gt;PaperWM.spoon: scrollable tiling on top of macOS.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Our main communication channel is a Matrix chat, feel free to join and ask a question: https://matrix.to/#/#niri:matrix.org&lt;/p&gt;
    &lt;p&gt;We also have a community Discord server: https://discord.gg/vT8Sfjy7sx&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45461500</guid><pubDate>Fri, 03 Oct 2025 11:08:42 +0000</pubDate></item><item><title>A Thermometer for Measuring Quantumness</title><link>https://www.quantamagazine.org/a-thermometer-for-measuring-quantumness-20251001/</link><description>&lt;doc fingerprint="f5dbf1ebe585c5e8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A Thermometer for Measuring Quantumness&lt;/head&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;If there’s one law of physics that seems easy to grasp, it’s the second law of thermodynamics: Heat flows spontaneously from hotter bodies to colder ones. But now, gently and almost casually, Alexssandre de Oliveira Jr. has just shown me I didn’t truly understand it at all.&lt;/p&gt;
    &lt;p&gt;Take this hot cup of coffee and this cold jug of milk, the Brazilian physicist said as we sat in a café in Copenhagen. Bring them into contact and, sure enough, heat will flow from the hot object to the cold one, just as the German scientist Rudolf Clausius first stated formally in 1850. However, in some cases, de Oliveira explained, physicists have learned that the laws of quantum mechanics can drive heat flow the opposite way: from cold to hot.&lt;/p&gt;
    &lt;p&gt;This doesn’t really mean that the second law fails, he added as his coffee reassuringly cooled. It’s just that Clausius’ expression is the “classical limit” of a more complete formulation demanded by quantum physics.&lt;/p&gt;
    &lt;p&gt;Physicists began to appreciate the subtlety of this situation more than two decades ago and have been exploring the quantum mechanical version of the second law ever since. Now, de Oliveira, a postdoctoral researcher at the Technical University of Denmark, and colleagues have shown that the kind of “anomalous heat flow” that’s enabled at the quantum scale could have a convenient and ingenious use.&lt;/p&gt;
    &lt;p&gt;It can serve, they say, as an easy method for detecting “quantumness” — sensing, for instance, that an object is in a quantum “superposition” of multiple possible observable states, or that two such objects are entangled, with states that are interdependent — without destroying those delicate quantum phenomena. Such a diagnostic tool could be used to ensure that a quantum computer is truly using quantum resources to perform calculations. It might even help to sense quantum aspects of the force of gravity, one of the stretch goals of modern physics. All that’s needed, the researchers say, is to connect a quantum system to a second system that can store information about it, and to a heat sink: a body that’s able to absorb a lot of energy. With this setup, you can boost the transfer of heat to the heat sink, exceeding what would be permitted classically. Simply by measuring how hot the sink is, you could then detect the presence of superposition or entanglement in the quantum system.&lt;/p&gt;
    &lt;p&gt;Practical benefits aside, the research demonstrates a new aspect of a deep truth about thermodynamics: How heat and energy can be transformed and moved in physical systems is intimately bound up with information — what is or can be known about those systems. In this case, we “pay for” the anomalous heat flow by sacrificing stored information about the quantum system.&lt;/p&gt;
    &lt;p&gt;“I love the idea that thermodynamic quantities can signal quantum phenomena,” said the physicist Nicole Yunger Halpern of the University of Maryland. “The topic is fundamental and deep.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Knowledge Is Power&lt;/head&gt;
    &lt;p&gt;The connection between the second law of thermodynamics and information was first explored in the 19th century by the Scottish physicist James Clerk Maxwell. To Maxwell’s distress, Clausius’ second law seemed to imply that pockets of heat will dissipate throughout the universe until all temperature differences disappear. In the process, the total entropy of the universe — crudely, a measure of how disordered and featureless it is — will inexorably increase. Maxwell realized that this trend would eventually remove all possibility of harnessing heat flows to do useful work, and the universe would settle into a sterile equilibrium pervaded by a uniform buzz of thermal motion: a “heat death.” That forecast would be troubling enough to anyone. It was anathema to the devoutly Christian Maxwell. But in a letter to his friend Peter Guthrie Tait in 1867, Maxwell claimed to have found a way to “pick a hole” in the second law.&lt;/p&gt;
    &lt;p&gt;He imagined a tiny being (later dubbed a demon) who could see the motions of individual molecules in a gas. The gas would fill a box that was divided in two by a wall with a trapdoor. By opening and closing the trapdoor selectively, the demon could sequester the faster-moving molecules in one compartment and the slower-moving ones in the other, making a hot gas and a cold one, respectively. By acting on the information it gathered about molecules’ motions, the demon thus reduced the entropy of the gas, creating a temperature gradient that could be used to do mechanical work, such as pushing a piston.&lt;/p&gt;
    &lt;p&gt;Scientists felt sure that Maxwell’s demon couldn’t really violate the second law, but it took nearly 100 years to figure out why not. The answer is that the information the demon collects and stores about the molecular motions will eventually fill up its finite memory. Its memory must then be erased and reset for it to keep working. The physicist Rolf Landauer showed in 1961 that this erasure burns energy and produces entropy — more entropy than is reduced by the demon’s sorting actions. Landauer’s analysis established an equivalence between information and entropy, implying that information itself can act as a thermodynamic resource: It can be transformed into work. Physicists experimentally demonstrated this information-to-energy conversion in 2010.&lt;/p&gt;
    &lt;p&gt;But quantum phenomena allow information to be processed in ways that classical physics does not permit — that’s the entire basis of technologies such as quantum computing and quantum cryptography. And that’s why quantum theory messes with the conventional second law.&lt;/p&gt;
    &lt;head rend="h2"&gt;Exploiting Correlations&lt;/head&gt;
    &lt;p&gt;Entangled quantum objects have mutual information: They are correlated, so we can discover properties of one by looking at the other. That in itself is not so strange; if you look at one of a pair of gloves and find it’s left-handed, you know the other is right-handed. But a pair of entangled quantum particles differs from gloves in a particular way: Whereas the handedness of gloves is already fixed before you look, this isn’t the case for the particles, according to quantum mechanics. Before we measure them, it’s undecided which value of the observable property each particle in the entangled pair has. At that stage the only things we can know are the probabilities of the possible combinations of values, such as 50% left-right and 50% right-left. Only when we measure the state of one of the particles do these possibilities resolve themselves into a definite outcome. In that measurement process, the entanglement is destroyed.&lt;/p&gt;
    &lt;p&gt;If gas molecules are entangled in this way, then a Maxwell’s demon can manipulate them more efficiently than if all the molecules are moving independently. If, say, the demon knows that any fast-moving molecule it sees coming is correlated in such a way that it will be trailed by another fast one just a moment later, the demon doesn’t have to bother observing the second particle before opening the trapdoor to admit it. The thermodynamic cost of (temporarily) foiling the second law is lowered.&lt;/p&gt;
    &lt;p&gt;In 2004, the quantum theorists Časlav Brukner of the University of Vienna and Vlatko Vedral, then at Imperial College London, pointed out that this means macroscopic thermodynamic measurements can be used as a “witness” to reveal the presence of quantum entanglement between particles. Under certain conditions, they showed, a system’s heat capacity or its response to an applied magnetic field should carry an imprint of entanglement, if it is present.&lt;/p&gt;
    &lt;p&gt;In a similar vein, other physicists calculated that you can extract more work from a warm body when there is quantum entanglement in the system than when it is purely classical.&lt;/p&gt;
    &lt;p&gt;And in 2008, the physicist Hossein Partovi of California State University identified a particularly dramatic implication of the way quantum entanglement can undermine preconceptions derived from classical thermodynamics. He realized that the presence of entanglement can actually reverse the spontaneous flow of heat from a hot object to a cold one, seemingly upending the second law itself.&lt;/p&gt;
    &lt;p&gt;That reversal is a special kind of refrigeration, Yunger Halpern said. And as usual with refrigeration, it doesn’t come for free (and so doesn’t truly subvert the second law). Classically, refrigerating an object takes work: We have to pump the heat the “wrong” way by consuming fuel, thereby repaying the entropy that’s lost by making the cold object colder and the hot object hotter. But in the quantum case, Yunger Halpern said, instead of burning fuel to achieve refrigeration, “you burn the correlations.” In other words, as the anomalous heat flow proceeds, the entanglement gets destroyed: Particles that initially had correlated properties become independent. “We can use the correlations as a resource to push heat in the opposite direction,” Yunger Halpern said.&lt;/p&gt;
    &lt;p&gt;In effect, the fuel here is information itself: specifically the mutual information of the entangled hot and cold bodies.&lt;/p&gt;
    &lt;p&gt;Two years later, David Jennings and Terry Rudolph of Imperial College London clarified what’s going on. They showed how the second law of thermodynamics can be reformulated to include the case where mutual information is present, and they calculated the limits on how much the classical heat flow can be altered and even reversed by the consumption of quantum correlations.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Demon Knows&lt;/head&gt;
    &lt;p&gt;When quantum effects are in play, then, the second law isn’t so simple. But can we do anything useful with the way quantum physics loosens the bounds of thermodynamic laws? That’s one of the goals of the discipline called quantum thermodynamics, in which some researchers seek to make quantum engines that run more efficiently than classical ones, or quantum batteries that charge more quickly.&lt;/p&gt;
    &lt;p&gt;Patryk Lipka-Bartosik of the Center for Theoretical Physics at the Polish Academy of Sciences has sought practical applications in the other direction: using thermodynamics as a tool for probing quantum physics. Last year, he and his co-workers saw how to realize Brukner and Vedral’s 2004 idea to use thermodynamic properties as a witness of quantum entanglement. Their scheme involves hot and cold quantum systems that are correlated with each other, and a third system to mediate the heat flow between the two. We can think of this third system as a Maxwell’s demon, except now it has a “quantum memory” that can itself be entangled with the systems it is manipulating. Being entangled with the demon’s memory effectively links the hot and cold systems so that the demon can infer something about one from the properties of the other.&lt;/p&gt;
    &lt;p&gt;Such a quantum demon can act as a kind of catalyst, helping heat transfer happen by accessing correlations that are inaccessible otherwise. That is, because it is entangled with the hot and cold objects, the demon can divine and exploit all their correlations systematically. And, again like a catalyst, this third system returns to its original state once the heat exchange between the objects is completed. In this way, the process can boost the anomalous heat flow beyond what can be achieved without such a catalyst.&lt;/p&gt;
    &lt;p&gt;The paper this year by de Oliveira, co-authored by Lipka-Bartosik and Jonatan Bohr Brask of the Technical University of Denmark, uses some of these same ideas but with a crucial difference that turns the setup into a kind of thermometer for measuring quantumness. In the earlier work, the demonlike quantum memory interacted with a correlated pair of quantum systems, one hot and one cold. But in the latest work, it sits between a quantum system (say, an array of entangled quantum bits, or qubits, in a quantum computer) and a simple heat sink with which the quantum system is not directly entangled.&lt;/p&gt;
    &lt;p&gt;Because the memory is entangled with both the quantum system and the sink, it can again catalyze heat flow between them beyond what is possible classically. In that process, entanglement within the quantum system converts into extra heat that enters the sink. So measuring the energy stored in the heat sink (akin to reading its “temperature”) reveals the presence of entanglement in the quantum system. But since the system and sink aren’t themselves entangled, the measurement doesn’t affect the state of the quantum system. This gambit circumvents the notorious way that measurements destroy quantumness. “If you simply tried to make a measurement on the [quantum] system directly, you’d destroy its entanglement before the process could even unfold,” de Oliveira said.&lt;/p&gt;
    &lt;p&gt;The new scheme has the advantage of being simple and general, said Vedral, who is now at the University of Oxford. “These verification protocols are very important,” he said: Whenever some quantum computer company makes a new announcement about the performance of its latest device, he said the question always arises of how (or if) they really know that entanglement among the qubits is helping with the computation. A heat sink could serve as a detector of such quantum phenomena purely via its energy change. To implement the idea, you might designate one quantum bit as the memory whose state reveals that of other qubits, and then couple this memory qubit to a set of particles that will serve as the sink, whose energy you can measure. (One proviso, Vedral added, is that you need to have very good control over your system to be sure there aren’t other sources of heat flow contaminating the measurements. Another is that the method will not detect all entangled states.)&lt;/p&gt;
    &lt;p&gt;De Oliveira thinks that a system already exists for testing their idea experimentally. He and his colleagues are discussing that goal with Roberto Serra’s research group at the Federal University of ABC in São Paulo, Brazil. In 2016, Serra and colleagues used the magnetic orientations, or spins, of carbon and hydrogen atoms in molecules of chloroform as quantum bits between which they could transfer heat.&lt;/p&gt;
    &lt;p&gt;Using this setup, de Oliveira says it should be possible to exploit a quantum behavior — in this case coherence, meaning that the properties of two or more spins are evolving in phase with one another — to change the heat flow between the atoms. Coherence of qubits is essential for quantum computing, so being able to verify it by detecting anomalous heat exchange could be helpful.&lt;/p&gt;
    &lt;p&gt;The stakes could be even higher. Several research groups are trying to design experiments to determine whether gravity is a quantum force like the other three fundamental forces. Some of these efforts involve looking for quantum entanglement between two objects generated purely by their mutual gravitational attraction. Perhaps researchers could probe such gravity-induced entanglement by making simple thermodynamic measurements on them — thereby verifying (or not) that gravity really is quantized.&lt;/p&gt;
    &lt;p&gt;To study one of the deepest questions in physics, Vedral said, “wouldn’t it be lovely if you could do something as easy and macroscopic as this?”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45462143</guid><pubDate>Fri, 03 Oct 2025 12:24:02 +0000</pubDate></item><item><title>Faroes</title><link>https://photoblog.nk412.com/Faroe2025/Faroes/n-cPCNFr</link><description>&lt;doc fingerprint="b6601c6e8caa7e9e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Faroes (2025)&lt;/head&gt;
    &lt;p&gt;The Faroe Islands are like the child that Denmark and Iceland had, but forgot to tell the world about. This group of eighteen small islands receives the least amount of sunshine in the world per year. Constant rain and heavy winds have always battered these lands.&lt;lb/&gt;Politically part of Denmark (for now) but fiercely independent in spirit, the Faroes exist in their own bubble of Nordic culture. Here, sheep outnumber humans two to one, villages of colorful houses cling to clifftops like they're holding on for dear life, and the weather can shift from apocalyptic storms to sunny calm in the space of an hour.&lt;/p&gt;
    &lt;p&gt;Situated between Iceland, Norway and Scotland, the Faroes face the brunt of the North Atlantic weather system. Constant storms and crashing waves have sculpted the volcanic rock over millions of years into some of the most jaw-dropping (and vertigo-inducing) coastlines on Earth. These towering basalt cliffs can reach heights of over 400 meters, dropping straight into churning seas below.&lt;lb/&gt;What's most striking is how abruptly the land stops. There are no sandy beaches or gentle slopes here—the islands simply plunge headfirst into the Atlantic. One step you're on grass-covered clifftops, the next you're staring down hundreds of meters of sheer volcanic rock to where waves explode against the base far below.&lt;/p&gt;
    &lt;p&gt;The weather here is unpredictable, and changes faster than you can put your raincoat on—one minute you're in thick fog, the next you're hit with winds and piercing rain that'll knock you sideways, then suddenly the clouds part to reveal views that'll make your camera work overtime.&lt;/p&gt;
    &lt;p&gt;Meet the true locals of the Faroes. These wooly sheep have been roaming the islands for over a thousand years, and they outnumber people on the islands. They couldn't care less about your hiking plans and will casually block paths or graze on the edge of 200-meter cliffs like it's the most natural thing in the world.&lt;lb/&gt;Faroe's name comes from a combination of fær (sheep) and eyjar (islands). &lt;/p&gt;
    &lt;p&gt;Unlike their farm-bound cousins elsewhere, Faroese sheep roam completely free across the islands, somehow always managing to find the most photogenic spots for an impromptu rest. This fellow right here is the only one that gave me any sort of attention. Otherwise, they are all busy grazing on all the grass they could ever ask for.&lt;/p&gt;
    &lt;p&gt;Why fight the landscape? For over a millennium, islanders have been topping their huts with birch bark and soil and let the grass grow wild. They act as insulation, and the thick roots are an excellent waterproof seal against the weather.&lt;lb/&gt;The grass grows quickly and does need tending every once in a while. In typical Faroese fashion, the solution is simple: put a sheep on top for an afternoon.&lt;/p&gt;
    &lt;p&gt;On the northern tip of Kalsoy lies the Kallur lighthouse. Like most regions on the islands, the land is privately owned. Hiking usually incurs a modest fee paid at the trailhead to the land owners, and the rest is up to you. Trails are just sheep paths, worn smooth by countless hooves over years rather than any official trail maintenance.&lt;/p&gt;
    &lt;p&gt;There are no guardrails, no warning signs, and definitely no liability waivers - just you, the weather, and whatever route the sheep decided made sense. The approach to Kallur is particularly gnarly, following a knife-edge ridge with steep drops on both sides before reaching the lighthouse perched dramatically on sea cliffs.&lt;/p&gt;
    &lt;p&gt;In No Time To Die (2021), Daniel Craig's James Bond meets his end at the villain's lair, which happened to be here on Kalsoy. The Faroese then followed through with the obvious next step.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45462297</guid><pubDate>Fri, 03 Oct 2025 12:41:03 +0000</pubDate></item><item><title>CVE-2025-59489: Arbitrary Code Execution in Unity Runtime since 2017</title><link>https://flatt.tech/research/posts/arbitrary-code-execution-in-unity-runtime/</link><description>&lt;doc fingerprint="b56811138876f9e9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;CVE-2025-59489: Arbitrary Code Execution in Unity Runtime&lt;/head&gt;
    &lt;head rend="h5"&gt;Posted on October 3, 2025 • 6 minutes • 1067 words&lt;/head&gt;
    &lt;head class="flex items-center font-bold py-2 px-4 cursor-pointer justify-between select-none text-black dark:text-white"&gt;Table of contents&lt;/head&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Hello, I’m RyotaK (@ryotkak ), a security engineer at GMO Flatt Security Inc.&lt;/p&gt;
    &lt;p&gt;In May 2025, I participated in the Meta Bug Bounty Researcher Conference 2025. During this event, I discovered a vulnerability (CVE-2025-59489) in the Unity Runtime that affects games and applications built on Unity 2017.1 and later.&lt;/p&gt;
    &lt;p&gt;In this article, I will explain the technical aspects of this vulnerability and its impact.&lt;/p&gt;
    &lt;p&gt;This vulnerability was disclosed to Unity following responsible disclosure practices.&lt;lb/&gt; Unity has since released patches for Unity 2019.1 and later, as well as a Unity Binary Patch tool to address the issue, and I strongly encourage developers to download the updated versions of Unity, recompile affected games or applications, and republish as soon as possible.&lt;/p&gt;
    &lt;p&gt;For the official security advisory, please refer to Unity’s advisory here: https://unity.com/security/sept-2025-01&lt;/p&gt;
    &lt;p&gt;We appreciate Unity’s commitment to addressing this issue promptly and their ongoing efforts to enhance the security of their platform.&lt;lb/&gt; Security vulnerabilities are an inherent challenge in software development, and by working together as a community, we can continue to make software systems safer for everyone.&lt;/p&gt;
    &lt;head rend="h2"&gt;TL;DR&lt;/head&gt;
    &lt;p&gt;A vulnerability was identified in the Unity Runtime’s intent handling process for Unity games and applications.&lt;lb/&gt; This vulnerability allows malicious intents to control command line arguments passed to Unity applications, enabling attackers to load arbitrary shared libraries (&lt;code&gt;.so&lt;/code&gt; files) and execute malicious code, depending on the platform.&lt;/p&gt;
    &lt;p&gt;In its default configuration, this vulnerability allowed malicious applications installed on the same device to hijack permissions granted to Unity applications.&lt;lb/&gt; In specific cases, the vulnerability could be exploited remotely to execute arbitrary code, although I didn’t investigate third-party Unity applications to find an app with the functionality required to enable this exploit.&lt;/p&gt;
    &lt;p&gt;Unity has addressed this issue and has updated all affected Unity versions starting with 2019.1. Developers are strongly encouraged to download them, recompile their games and applications, and republish to ensure their projects remain secure.&lt;/p&gt;
    &lt;head rend="h2"&gt;About Unity&lt;/head&gt;
    &lt;p&gt;Unity is a popular game engine used to develop games and applications for various platforms, including Android.&lt;/p&gt;
    &lt;p&gt;According to Unity’s website, 70% of top mobile games are built with Unity. This includes popular games like Among Us and Pokémon GO, along with many other applications that use Unity for development.&lt;/p&gt;
    &lt;head rend="h2"&gt;Technical Details&lt;/head&gt;
    &lt;p&gt;Note: During the analysis, I used Android 16.0 on the Android Emulator of Android Studio. The behavior and impact of this vulnerability may differ on older Android versions.&lt;/p&gt;
    &lt;head rend="h3"&gt;Unity’s Intent Handler&lt;/head&gt;
    &lt;p&gt;To support debugging Unity applications on Android devices, Unity automatically adds a handler for the intent containing the &lt;code&gt;unity&lt;/code&gt; extra to the UnityPlayerActivity. This activity serves as the default entry point for applications and is exported to other applications.&lt;/p&gt;
    &lt;p&gt;https://docs.unity3d.com/6000.0/Documentation/Manual/android-custom-activity-command-line.html&lt;/p&gt;
    &lt;code&gt;adb shell am start -n "com.Company.MyGame/com.unity3d.player.UnityPlayerActivity" -e unity "-systemallocator"
&lt;/code&gt;
    &lt;p&gt;As documented above, the &lt;code&gt;unity&lt;/code&gt; extra is parsed as command line arguments for Unity.&lt;/p&gt;
    &lt;p&gt;While Android’s permission model manages feature access by granting permissions to applications, it does not restrict which intents can be sent to an application.&lt;lb/&gt; This means any application can send the &lt;code&gt;unity&lt;/code&gt; extra to a Unity application, allowing attackers to control the command line arguments passed to that application.&lt;/p&gt;
    &lt;head rend="h3"&gt;xrsdk-pre-init-library Command Line Argument&lt;/head&gt;
    &lt;p&gt;After loading the Unity Runtime binary into Ghidra, I discovered the following command line argument:&lt;/p&gt;
    &lt;code&gt;initLibPath = FUN_00272540(uVar5, "xrsdk-pre-init-library");
&lt;/code&gt;
    &lt;p&gt;The value of this command line argument is later passed to &lt;code&gt;dlopen&lt;/code&gt;, causing the path specified in &lt;code&gt;xrsdk-pre-init-library&lt;/code&gt; to be loaded as a native library.&lt;/p&gt;
    &lt;code&gt;lVar2 = dlopen(initLibPath, 2);  
&lt;/code&gt;
    &lt;p&gt;This behavior allows attackers to execute arbitrary code within the context of the Unity application, leveraging its permissions by launching them with the -xrsdk-pre-init-library argument.&lt;/p&gt;
    &lt;head rend="h2"&gt;Attack Scenarios&lt;/head&gt;
    &lt;head rend="h3"&gt;Local Attack&lt;/head&gt;
    &lt;p&gt;Any malicious application installed on the same device can exploit this vulnerability by:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Extracting the native library with the &lt;code&gt;android:extractNativeLibs&lt;/code&gt;attribute set to&lt;code&gt;true&lt;/code&gt;in the AndroidManifest.xml&lt;/item&gt;
      &lt;item&gt;Launching the Unity application with the &lt;code&gt;-xrsdk-pre-init-library&lt;/code&gt;argument pointing to the malicious library&lt;/item&gt;
      &lt;item&gt;The Unity application would then load and execute the malicious code with its own permissions&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Remote Exploitation via Browser&lt;/head&gt;
    &lt;p&gt;In specific cases, this vulnerability could potentially be exploited remotely although the condition .&lt;lb/&gt; For example, if an application exports &lt;code&gt;UnityPlayerActivity&lt;/code&gt; or &lt;code&gt;UnityPlayerGameActivity&lt;/code&gt; with the &lt;code&gt;android.intent.category.BROWSABLE&lt;/code&gt; category (allowing browser launches), websites can specify extras passed to the activity using intent URLs:&lt;/p&gt;
    &lt;code&gt;intent:#Intent;package=com.example.unitygame;scheme=custom-scheme;S.unity=-xrsdk-pre-init-library%20/data/local/tmp/malicious.so;end;
&lt;/code&gt;
    &lt;p&gt;At first glance, it might appear that malicious websites could exploit this vulnerability by forcing browsers to download &lt;code&gt;.so&lt;/code&gt; files and load them via the &lt;code&gt;xrsdk-pre-init-library&lt;/code&gt; argument.&lt;/p&gt;
    &lt;head rend="h3"&gt;SELinux Restrictions&lt;/head&gt;
    &lt;p&gt;However, Android’s strict SELinux policy prevents &lt;code&gt;dlopen&lt;/code&gt; from opening files in the downloads directory, which mitigates almost all remote exploitation scenarios.&lt;/p&gt;
    &lt;code&gt;library "/sdcard/Download/libtest.so" ("/storage/emulated/0/Download/libtest.so") needed 
or dlopened by "/data/app/~~24UwD8jnw7asNjRwx1MOBg==/com.DefaultCompany.com.unity.template. 
mobile2D-E043IptGJDwcTqq56BocIA==/lib/arm64/libunity.so" is not accessible for the 
namespace: [name="clns-9", ld_library_paths="",default_library_paths="/data/app/~~24UwD8jnw7asNjRwx1MOBg==/com.DefaultCompany.com.unity.template. 
mobile2D-E043IptGJDwcTqq56BocIA==/lib/arm64:/data/app/~~24UwD8jnw7asNjRwx1MOBg==/com.DefaultCompany.com.unity.template.mobile2D-E043IptGJDwcTqq56BocIA==/base.apk!/lib/arm64-v8a", permitted_paths="/data:/mnt/expand:/data/data/com.DefaultCompany.com.unity.template.mobile2D"]
&lt;/code&gt;
    &lt;p&gt;That being said, since the &lt;code&gt;/data/&lt;/code&gt; directory is included in &lt;code&gt;permitted_paths&lt;/code&gt;, if the target application writes files to its private storage, it can be used to bypass this restriction.&lt;/p&gt;
    &lt;p&gt;Furthermore, &lt;code&gt;dlopen&lt;/code&gt; doesn’t require the &lt;code&gt;.so&lt;/code&gt; file extension. If attackers can control the content of a file in an application’s private storage, they can exploit this vulnerability by creating a file containing malicious native library binary. This is actually a common pattern when applications cache data.&lt;/p&gt;
    &lt;p&gt;For example, another vulnerability in Messenger was exploited using the application’s cache: https://www.hexacon.fr/slides/Calvanno-Defense_through_Offense_Building_a_1-click_Exploit_Targeting_Messenger_for_Android.pdf&lt;/p&gt;
    &lt;head rend="h3"&gt;Requirements for Remote Exploitation&lt;/head&gt;
    &lt;p&gt;To exploit this vulnerability remotely, the following conditions must be met:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The application exports &lt;code&gt;UnityPlayerActivity&lt;/code&gt;or&lt;code&gt;UnityPlayerGameActivity&lt;/code&gt;with the&lt;code&gt;android.intent.category.BROWSABLE&lt;/code&gt;category&lt;/item&gt;
      &lt;item&gt;The application writes files with attacker-controlled content to its private storage (e.g., through caching)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Even without these conditions, local exploitation remains possible for any Unity application.&lt;/p&gt;
    &lt;head rend="h2"&gt;Demonstration&lt;/head&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;In this article, I explained a vulnerability in Unity Runtime that allows arbitrary code execution in almost all Unity applications on Android.&lt;/p&gt;
    &lt;p&gt;I hope this article helps you understand that vulnerabilities can exist in the frameworks and libraries you depend on, and you should always be mindful of the security implications of the features you use.&lt;/p&gt;
    &lt;head rend="h2"&gt;Shameless plug&lt;/head&gt;
    &lt;p&gt;At GMO Flatt Security, we provide top-notch penetration testing for a wide range of targets, from Web apps to IoT devices.&lt;/p&gt;
    &lt;p&gt;https://flatt.tech/en/professional/penetration_test&lt;/p&gt;
    &lt;p&gt;We also developed Takumi, our AI security engineer. It’s an autonomous agent that finds vulnerabilities in source code and has already discovered CVEs in major libraries like Vim and Next.js. https://flatt.tech/en/takumi&lt;/p&gt;
    &lt;p&gt;Recently, we’ve expanded Takumi’s capabilities. It’s no longer just a SAST (white-box testing) tool; we’ve added DAST (black-box testing) to enable high-fidelity gray-box scanning for more accurate results.&lt;/p&gt;
    &lt;p&gt;Based in Japan, we work with clients globally, including industry leaders like Canonical Ltd.&lt;/p&gt;
    &lt;p&gt;If you’d like to learn more, please contact us at https://flatt.tech/en&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45462713</guid><pubDate>Fri, 03 Oct 2025 13:21:44 +0000</pubDate></item><item><title>Webbol: A minimal static web server written in COBOL</title><link>https://github.com/jmsdnns/webbol</link><description>&lt;doc fingerprint="11bcbc59fd061f87"&gt;
  &lt;main&gt;
    &lt;p&gt;A minimal static web server written in COBOL using GnuCOBOL.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Serves static files from the current directory&lt;/item&gt;
      &lt;item&gt;Automatic MIME type detection for common file types&lt;/item&gt;
      &lt;item&gt;HTTP status codes: 200 (OK), 403 (Forbidden), 404 (Not Found), 413 (Payload Too Large)&lt;/item&gt;
      &lt;item&gt;Path traversal attack prevention&lt;/item&gt;
      &lt;item&gt;Clean request logging with full HTTP headers&lt;/item&gt;
      &lt;item&gt;Defaults to &lt;code&gt;index.html&lt;/code&gt;for root path requests&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GnuCOBOL (cobc) compiler&lt;/item&gt;
      &lt;item&gt;POSIX-compatible operating system (Linux, macOS, BSD)&lt;/item&gt;
      &lt;item&gt;make&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;macOS:&lt;/p&gt;
    &lt;code&gt;brew install gnucobol&lt;/code&gt;
    &lt;p&gt;Ubuntu/Debian:&lt;/p&gt;
    &lt;code&gt;sudo apt-get install gnucobol&lt;/code&gt;
    &lt;p&gt;Fedora/RHEL:&lt;/p&gt;
    &lt;code&gt;sudo dnf install gnucobol&lt;/code&gt;
    &lt;p&gt;Clone or download the repository, then compile:&lt;/p&gt;
    &lt;code&gt;make&lt;/code&gt;
    &lt;p&gt;This will compile all modules and create the &lt;code&gt;webserver&lt;/code&gt; executable.&lt;/p&gt;
    &lt;p&gt;To clean build artifacts:&lt;/p&gt;
    &lt;code&gt;make clean&lt;/code&gt;
    &lt;p&gt;Start the server from the directory you want to serve:&lt;/p&gt;
    &lt;code&gt;./webserver&lt;/code&gt;
    &lt;p&gt;The server will start on port 8080 and serve files from the current directory.&lt;/p&gt;
    &lt;code&gt;# Create a test HTML file
echo "&amp;lt;html&amp;gt;&amp;lt;body&amp;gt;&amp;lt;h1&amp;gt;Hello from COBOL!&amp;lt;/h1&amp;gt;&amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;" &amp;gt; index.html

# Start the server
./webserver

# In another terminal, test it
curl http://localhost:8080/&lt;/code&gt;
    &lt;p&gt;Once running, you can access files via:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;http://localhost:8080/&lt;/code&gt;- serves&lt;code&gt;index.html&lt;/code&gt;from the current directory&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;http://localhost:8080/filename.html&lt;/code&gt;- serves the specified file&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;http://localhost:8080/path/to/file.txt&lt;/code&gt;- serves files from subdirectories&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Press &lt;code&gt;Ctrl+C&lt;/code&gt; to stop the server.&lt;/p&gt;
    &lt;p&gt;To change the server port, edit &lt;code&gt;config.cpy&lt;/code&gt; and modify the &lt;code&gt;SERVER-PORT&lt;/code&gt; value:&lt;/p&gt;
    &lt;code&gt;01 SERVER-PORT          PIC 9(5) VALUE 8080.&lt;/code&gt;
    &lt;p&gt;Then recompile with &lt;code&gt;make&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;webbol/
├── Makefile              # Build configuration
├── README.md            # This file
├── config.cpy           # Server configuration
├── socket-defs.cpy      # Socket structure definitions
├── http-structs.cpy     # HTTP data structures
├── file-structs.cpy     # File handling structures
├── path-utils.cbl       # Path validation and sanitization
├── mime-types.cbl       # MIME type detection
├── file-ops.cbl         # File reading operations
├── http-handler.cbl     # HTTP request/response handling
└── webserver.cbl        # Main server program
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;HTML: &lt;code&gt;text/html&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;CSS: &lt;code&gt;text/css&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;JavaScript: &lt;code&gt;application/javascript&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;JSON: &lt;code&gt;application/json&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;XML: &lt;code&gt;application/xml&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Plain text: &lt;code&gt;text/plain&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;PNG: &lt;code&gt;image/png&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;JPEG: &lt;code&gt;image/jpeg&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;GIF: &lt;code&gt;image/gif&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;SVG: &lt;code&gt;image/svg+xml&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;ICO: &lt;code&gt;image/x-icon&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;PDF: &lt;code&gt;application/pdf&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Additional MIME types can be added by editing &lt;code&gt;mime-types.cbl&lt;/code&gt;.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Path traversal prevention: Blocks requests containing &lt;code&gt;..&lt;/code&gt;sequences&lt;/item&gt;
      &lt;item&gt;Directory access restriction: Only serves files from the current directory and subdirectories&lt;/item&gt;
      &lt;item&gt;Safe file handling: Validates all paths before file system access&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Single-threaded: Handles one request at a time&lt;/item&gt;
      &lt;item&gt;No SSL/TLS support&lt;/item&gt;
      &lt;item&gt;Maximum file size: 64KB&lt;/item&gt;
      &lt;item&gt;Line sequential file organization only (text files)&lt;/item&gt;
      &lt;item&gt;No caching or compression&lt;/item&gt;
      &lt;item&gt;No range requests or partial content support&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Port already in use:&lt;/p&gt;
    &lt;code&gt;Bind failed - check if port is in use
&lt;/code&gt;
    &lt;p&gt;Another process is using port 8080. Either stop that process or change the port in &lt;code&gt;config.cpy&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Permission denied: Ensure the files you're trying to serve have read permissions and the current user can access them.&lt;/p&gt;
    &lt;p&gt;File not found (404): Verify the file exists in the current directory where the server is running. File paths are case-sensitive.&lt;/p&gt;
    &lt;p&gt;This project is released into the public domain. Use it however you'd like.&lt;/p&gt;
    &lt;p&gt;Built with GnuCOBOL, demonstrating that COBOL can still be used for modern systems programming tasks.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45463251</guid><pubDate>Fri, 03 Oct 2025 14:13:03 +0000</pubDate></item><item><title>I Turned the Lego Game Boy into a Working Game Boy</title><link>https://blog.nataliethenerd.com/i-turned-the-lego-game-boy-into-a-working-game-boy-part-1/</link><description>&lt;doc fingerprint="15cf6c54ebc4b5f9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;I turned the Lego Game Boy into a working Game Boy part. 1&lt;/head&gt;
    &lt;p&gt;Through my documentation of Game Boy boards, I have drawn up schematics of each device. I know them pretty well. Check out my board scan wiki https://wiki.nataliethenerd.com/&lt;/p&gt;
    &lt;p&gt;I jokingly made this tweet when the kit was announced, but decided to actually do it.&lt;/p&gt;
    &lt;p&gt;I know from experience of routing Game Boy CPU PCBs that there isn't much to it. There's the RAM, CPU, some decoupling capacitors and power regulation. &lt;lb/&gt;Note: I went with the MGB (Pocket) CPU rather than DMG for a couple of reasons.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;They are pretty much the same&lt;/item&gt;
      &lt;item&gt;I have more of them&lt;/item&gt;
      &lt;item&gt;They are cheaper and easier to get. This opens up the project to more people&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The DMG CPU has external VRAM, the MGB CPU has internal VRAM and in a very space conscious build that was the biggest factor.&lt;/p&gt;
    &lt;head rend="h2"&gt;Pre Planning&lt;/head&gt;
    &lt;p&gt;I only had the press pictures to work off. I used the dimensions to scale the image on my PC and from that I got measurements for the screen inserts; since that's where I plan to put the Game Boy.&lt;/p&gt;
    &lt;p&gt;I incorporated the power circuit I use for my Safer Charger boards, changed the power switch to a soft latching power button, added pin outs for the button matrix and audio.&lt;/p&gt;
    &lt;p&gt;I didn't really know what the buttons on the Lego would be like, but the fact that they could be pressed was enough for me to know I could implement them. At the moment I have them wired up to custom 3D printed *toy brick* parts. Same with the USB C&lt;/p&gt;
    &lt;p&gt;I am currently working on refining the board now I have the Lego build in my hands. This project will be released in full once I am finished with it - so stay tuned!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45463319</guid><pubDate>Fri, 03 Oct 2025 14:18:56 +0000</pubDate></item><item><title>Microsoft CTO says he wants to swap most AMD and Nvidia GPUs for homemade chips</title><link>https://www.theregister.com/2025/10/02/microsoft_maia_dc/</link><description>&lt;doc fingerprint="37f0403644aec8d5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Microsoft CTO says he wants to swap most AMD and Nvidia GPUs for homemade chips&lt;/head&gt;
    &lt;head rend="h2"&gt;Pivot will hinge on success of next-gen Maia accelerator&lt;/head&gt;
    &lt;p&gt;Microsoft buys a lot of GPUs from both Nvidia and AMD. But moving forward, Redmond's leaders want to shift the majority of its AI workloads from GPUs to its own homegrown accelerators.&lt;/p&gt;
    &lt;p&gt;The software titan is rather late to the custom silicon party. While Amazon and Google have been building custom CPUs and AI accelerators for years, Microsoft only revealed its Maia AI accelerators in late 2023.&lt;/p&gt;
    &lt;p&gt;Driving the transition is a focus on performance per dollar, which for a hyperscale cloud provider is arguably the only metric that really matters. Speaking during a fireside chat moderated by CNBC on Wednesday, Microsoft CTO Kevin Scott said that up to this point, Nvidia has offered the best price-performance, but he's willing to entertain anything in order to meet demand.&lt;/p&gt;
    &lt;p&gt;Going forward, Scott suggested Microsoft hopes to use its homegrown chips for the majority of its datacenter workloads.&lt;/p&gt;
    &lt;p&gt;When asked, "Is the longer term idea to have mainly Microsoft silicon in the data center?" Scott responded, "Yeah, absolutely."&lt;/p&gt;
    &lt;p&gt;Later, he told CNBC, "It's about the entire system design. It's the networks and cooling, and you want to be able to have the freedom to make decisions that you need to make in order to really optimize your compute for the workload."&lt;/p&gt;
    &lt;p&gt;With its first in-house AI accelerator, the Maia 100, Microsoft was able to free up GPU capacity by shifting OpenAI's GPT-3.5 to its own silicon back in 2023. However, with just 800 teraFLOPS of BF16 performance, 64GB of HBM2e, and 1.8TB/s of memory bandwidth, the chip fell well short of competing GPUs from Nvidia and AMD.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Alibaba unveils $53B global AI plan – but it will need GPUs to back it up&lt;/item&gt;
      &lt;item&gt;Arm wrestles away 25% share of server market thanks to Nvidia's home-grown CPUs&lt;/item&gt;
      &lt;item&gt;SiPearl ships reference node design for Rhea1 high-spec Arm chip&lt;/item&gt;
      &lt;item&gt;Arm reckons it'll own 50% of the datacenter by year's end&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Microsoft is reportedly in the process of bringing a second-generation Maia accelerator to market next year that will no doubt offer more competitive compute, memory, and interconnect performance.&lt;/p&gt;
    &lt;p&gt;But while we may see a change in the mix of GPUs to AI ASICs in Microsoft data centers moving forward, they're unlikely to replace Nvidia and AMD's chips entirely.&lt;/p&gt;
    &lt;p&gt;Over the past few years, Google and Amazon have deployed tens of thousands of their TPUs and Trainium accelerators. While these chips have helped them secure some high-profile customer wins, Anthropic for example, these chips are more often used to accelerate the company's own in-house workloads.&lt;/p&gt;
    &lt;p&gt;As such, we continue to see large-scale Nvidia and AMD GPU deployments on these cloud platforms, in part because customers still want them.&lt;/p&gt;
    &lt;p&gt;It should be noted that AI accelerators aren't the only custom chips Microsoft has been working on. Redmond also has its own CPU called Cobalt and a whole host of platform security silicon designed to accelerate cryptography and safeguard key exchanges across its vast datacenter domains. ®&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45463642</guid><pubDate>Fri, 03 Oct 2025 14:48:36 +0000</pubDate></item><item><title>Social anxiety isn't about being liked</title><link>https://chrislakin.blog/p/social-anxiety</link><description>&lt;doc fingerprint="3b56d81500d3c6b5"&gt;
  &lt;main&gt;
    &lt;p&gt;There's this popular idea that socially anxious folks are just dying to be liked. It seems logical, right? Why else would someone be so anxious about how others see them?&lt;/p&gt;
    &lt;p&gt;And yet, being socially anxious tends to make you less likeable…they must be optimizing poorly, behaving irrationally, right?&lt;/p&gt;
    &lt;p&gt;Maybe not. What if social anxiety isn’t about getting people to like you? What if it's about stopping them from disliking you?&lt;/p&gt;
    &lt;p&gt;Consider what can happen when someone has social anxiety (or self-loathing, self-doubt, insecurity, lack of confidence, etc.):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;They stoop or take up less space&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;They become less agentic&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;They make fewer requests of others&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;They maintain fewer relationships, go out less, take fewer risks…&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If they were trying to get people to like them, becoming socially anxious would be an incredibly bad strategy.&lt;/p&gt;
    &lt;p&gt;So what if they're not concerned with being likeable?&lt;/p&gt;
    &lt;head rend="h2"&gt;What if what they actually want is to avoid being disliked?&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;To understand the object of an obscure plot, observe its consequences and ask who might have intended them… —Harry Potter and the Methods of Rationality&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;What if the socially anxious were calibrating to avoid being DISliked?&lt;/p&gt;
    &lt;p&gt;Consider: if you shrink and never make any attention-getting moves, you are less likely to dangerously disappoint others, get into risky conflicts or be seen as a failure, embarrassment, or threat.&lt;/p&gt;
    &lt;p&gt;Like, yeah, it's wonderful to do awesome things and have people love you. But you know what’s better than being loved? People not hating you.&lt;/p&gt;
    &lt;head rend="h2"&gt;Social anxiety is a symptom of risk aversion&lt;/head&gt;
    &lt;p&gt;It’s not a pursuit of potential upside, but an attempt to avoid downsides.&lt;/p&gt;
    &lt;p&gt;Once you catch on to this pattern, you see it everywhere.&lt;/p&gt;
    &lt;p&gt;Two examples:&lt;/p&gt;
    &lt;p&gt;1) When you feel financially insecure, you’re not optimizing for windfall as much as you’re optimizing for not going bankrupt. You avoid risky bets with higher EV in favor of safer, more predictable options, even if they offer smaller returns. The goal is to keep you fed, not to make you rich.&lt;/p&gt;
    &lt;p&gt;2) Reversely, countersignalling is a demonstration of safety in close relationships. In Scott Alexander’s Friendship is Countersignalling, he describes an interaction he has with a friend:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Becca: What are you doing here? I figured they’d have locked you away in the psych ward for good by now.&lt;/p&gt;
      &lt;p&gt;Scott: Nope. And what are you doing here? You haven’t killed off all your patients yet?&lt;/p&gt;
      &lt;p&gt;Becca: Only person in this hospital I might kill is standing right in front of me.&lt;/p&gt;
      &lt;p&gt;Scott: Be careful, I’m armed and dangerous *picks up a central line placement practice set menacingly*&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The security of good friendship diffuses your anxiety about making a social faux pas and enables you to take more risks.&lt;/p&gt;
    &lt;head rend="h2"&gt;What does this mean for your growth?&lt;/head&gt;
    &lt;p&gt;If you believe your primary goal is to "be liked" and you keep finding yourself hiding in the shadows, you'll feel like a total failure. This hurts!&lt;/p&gt;
    &lt;p&gt;But all our feelings have their own kind of logic. Even when we do things that seem self-sabotaging, there's usually an incentive that makes sense in that specific context – even if it maybe not the best strategy overall. Locally optimal!&lt;/p&gt;
    &lt;p&gt;Consider: what if all these symptoms of social anxiety aren't failures of a system trying to be liked, but successes of a system trying to avoid being disliked?&lt;/p&gt;
    &lt;p&gt;What if you’ve been operating pretty rationally this whole time, but not for the outcome you thought you were optimizing for?&lt;/p&gt;
    &lt;p&gt;What if you’re not failing at being liked - you’re succeeding at avoiding being disliked?&lt;/p&gt;
    &lt;p&gt;Recognize this, and you’ll be able to shift your focus to the real work: becoming comfortable with the worst-case scenarios your anxiety is protecting you from.&lt;/p&gt;
    &lt;p&gt;The solution isn’t trying harder to be liked. It’s unlearning your discomfort with being disliked.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45463656</guid><pubDate>Fri, 03 Oct 2025 14:51:02 +0000</pubDate></item><item><title>Anduril and Palantir battlefield comms system has deep flaws: Army</title><link>https://www.cnbc.com/2025/10/03/anduril-palantir-ngc2-deep-flaws-army.html</link><description>&lt;doc fingerprint="a573ccbb7c3e5585"&gt;
  &lt;main&gt;
    &lt;p&gt;The much-needed modernization of the U.S. Army's battlefield communications network being undertaken by Anduril, Palantir and others is rife with "fundamental security" problems and vulnerabilities, and should be treated as a "very high risk," according to a recent internal Army memo.&lt;/p&gt;
    &lt;p&gt;The two Silicon Valley companies, led by allies of U.S. President Donald Trump, have gained access to the Pentagon's lucrative flow of contracts on the promise of quickly providing less expensive and more sophisticated weapons than the Pentagon's longstanding arms providers.&lt;/p&gt;
    &lt;p&gt;But the September memo from the Army's chief technology officer about the NGC2 platform that connects soldiers, sensors, vehicles and commanders with real-time data paints a bleak picture of the initial product.&lt;/p&gt;
    &lt;p&gt;"We cannot control who sees what, we cannot see what users are doing, and we cannot verify that the software itself is secure," the memo says.&lt;/p&gt;
    &lt;p&gt;Palantir and Anduril did not comment for this story.&lt;/p&gt;
    &lt;p&gt;The assessment, seen by Reuters and first reported by Breaking Defense, comes just months after defense drone and software maker Anduril was awarded a $100 million to create a prototype of NGC2 with partners including Palantir, Microsoft and several smaller contractors.&lt;/p&gt;
    &lt;p&gt;The Army should treat the NGC2 prototype version as “very high risk” because of the “likelihood of an adversary gaining persistent undetectable access," wrote Gabrielle Chiulli, the Army chief technology officer authorizing official.&lt;/p&gt;
    &lt;p&gt;Despite the early September memo's scathing critique, Leonel Garciga, Army chief information officer and Chiulli's supervisor, said in a statement to Reuters that the report was part of a process that helped in "triaging cybersecurity vulnerabilities" and mitigating them.&lt;/p&gt;
    &lt;p&gt;In March, the 4th Infantry Division used the system in live-fire artillery training at Fort Carson, Colorado, in an exercise Anduril described as demonstrating faster and more reliable performance than legacy systems.&lt;/p&gt;
    &lt;p&gt;The Army memo identifies some major security gaps.&lt;/p&gt;
    &lt;p&gt;The report says the system allows any authorized user to access all applications and data regardless of their clearance level or operational need. As a result, "Any user can potentially access and misuse sensitive" classified information, the memo states, with no logging to track their actions.&lt;/p&gt;
    &lt;p&gt;Other deficiencies highlighted in the memo include the hosting of third-party applications that have not undergone Army security assessments. One application revealed 25 high-severity code vulnerabilities. Three additional applications under review each contain over 200 vulnerabilities requiring assessment, according to the document.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45464269</guid><pubDate>Fri, 03 Oct 2025 15:46:11 +0000</pubDate></item><item><title>Cancelling Async Rust</title><link>https://sunshowers.io/posts/cancelling-async-rust/</link><description>&lt;doc fingerprint="310499976ca2b6bc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Cancelling async Rust&lt;/head&gt;
    &lt;p&gt;This is an edited, written version of my RustConf 2025 talk about cancellations in async Rust. Like the written version of my RustConf 2023 talk, I’ve tried to retain the feel of a talk while making it readable as a standalone blog entry. Some links:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Video of the talk on YouTube.&lt;/item&gt;
      &lt;item&gt;Slides on Google Slides.&lt;/item&gt;
      &lt;item&gt;Repository with links and notes on GitHub.&lt;/item&gt;
      &lt;item&gt;Coverage on Linux Weekly News.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Introduction#&lt;/head&gt;
    &lt;p&gt;Let’s start with a simple example – you decide to read from a channel in a loop and gather a bunch of messages:&lt;/p&gt;
    &lt;code&gt;loop {
    match rx.recv().await {
        Ok(msg) =&amp;gt; process(msg),
        Err(_) =&amp;gt; return,
    }
}
&lt;/code&gt;
    &lt;p&gt;All good, nothing wrong with this, but you realize sometimes the channel is empty for long periods of time, so you add a timeout and print a message:&lt;/p&gt;
    &lt;code&gt;loop {
    match timeout(Duration::from_secs(5), rx.recv()).await {
        Ok(Ok(msg)) =&amp;gt; process(msg),
        Ok(Err(_)) =&amp;gt; return,
        Err(_) =&amp;gt; println!("no messages for 5 seconds"),
    }
}
&lt;/code&gt;
    &lt;p&gt;There’s nothing wrong with this code—it behaves as expected.&lt;/p&gt;
    &lt;p&gt;Now you realize you need to write a bunch of messages out to a channel in a loop:&lt;/p&gt;
    &lt;code&gt;loop {
    let msg = next_message();
    match tx.send(msg).await {
        Ok(_) =&amp;gt; println!("sent successfully"),
        Err(_) =&amp;gt; return,
    }
}
&lt;/code&gt;
    &lt;p&gt;But sometimes the channel gets too full and blocks, so you add a timeout and print a message:&lt;/p&gt;
    &lt;code&gt;loop {
    let msg = next_message();
    match timeout(Duration::from_secs(5), tx.send(msg)).await {
        Ok(Ok(_)) =&amp;gt; println!("sent successfully"),
        Ok(Err(_)) =&amp;gt; return,
        Err(_) =&amp;gt; println!("no space for 5 seconds"),
    }
}
&lt;/code&gt;
    &lt;p&gt;It turns out that this code is often incorrect, because not all messages make their way to the channel.&lt;/p&gt;
    &lt;p&gt;Hi, I’m Rain, and this post is about cancelling async Rust. This post is split into three parts:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;What is cancellation? It’s an extremely powerful part of async Rust but also one that is very hard to reason thoroughly about.&lt;/item&gt;
      &lt;item&gt;Analyzing cancellations: Going deep into their mechanics and providing some helpful ways to think about them.&lt;/item&gt;
      &lt;item&gt;What can be done? Solutions, including practical guidance, and real bugs we’ve found and fixed in production codebases.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Before we begin, I want to lay my cards on the table – I really love async Rust!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;I gave a talk at RustConf a couple years ago talking about how async Rust is a great fit for signal handling in complex applications.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I’m also the author of cargo-nextest, a next-generation test runner for Rust, where async Rust is the best way I know of to express some really complex algorithms that I wouldn’t know how to express otherwise. I wrote a blog post about this a few years ago.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Now, I work at Oxide Computer Company, where we make cloud-in-a-box computers. We make vertically integrated systems where you provide power and networking on one end, and the software you want to run on the other end, and we take care of everything in between.&lt;/p&gt;
    &lt;p&gt;Of course, we use Rust everywhere, and in particular we use async Rust extensively for our higher-level software, such as storage, networking and the customer-facing management API. But along the way we’ve encountered a number of issues around async cancellation, and a lot of this post is about what we learned along the way.&lt;/p&gt;
    &lt;head rend="h2"&gt;1. What is cancellation?#&lt;/head&gt;
    &lt;p&gt;What does cancellation mean? Logically, a cancellation is exactly what it sounds like: you start some work, and then change your mind and decide to stop doing that work.&lt;/p&gt;
    &lt;p&gt;As you might imagine this is a useful thing to do:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You may have started a large download or a long network request&lt;/item&gt;
      &lt;item&gt;Maybe you’ve started reading a file, similar to the &lt;code&gt;head&lt;/code&gt;command.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But then you change your mind: you want to cancel it rather than continue it to completion.&lt;/p&gt;
    &lt;head rend="h3"&gt;Cancellations in synchronous Rust#&lt;/head&gt;
    &lt;p&gt;Before we talk about async Rust, it’s worth thinking about how you’d do cancellations in synchronous Rust.&lt;/p&gt;
    &lt;p&gt;One option is to have some kind of flag you periodically check, maybe stored in an atomic:&lt;/p&gt;
    &lt;code&gt;while !should_cancel.load(Ordering::Relaxed) {
    expensive_operation();
}
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The code that wishes to perform the cancellation can set that flag.&lt;/item&gt;
      &lt;item&gt;Then, the code which checks that flag can exit early.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This approach is fine for smaller bits of code but doesn’t really scale well to large chunks of code since you’d have to sprinkle these checks everywhere.&lt;/p&gt;
    &lt;p&gt;A related option, if you’re working with a framework as part of your work, is to panic with a special payload of some kind.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If that feels strange to you, you’re not alone! But the Salsa framework for incremental computation, used by—among other things—rust-analyzer, uses this approach.&lt;/item&gt;
      &lt;item&gt;Something I learned recently was that this only works on build targets which have a notion of panic unwinding, or being able to bubble up the panic. Not all platforms support this, and in particular, Wasm doesn’t. This means that Salsa cancellations don’t work if you build rust-analyzer for Wasm.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A third option is to kill the whole process. This is a very heavyweight approach, but an effective one in case you spawn processes to do your work.&lt;/p&gt;
    &lt;p&gt;Rather than kill the whole process, can you kill a single thread?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;While some OSes have APIs to perform this action, they tend to warn very strongly against it. That’s because in general, most code is just not ready for a thread disappearing from underneath.&lt;/item&gt;
      &lt;item&gt;In particular, thread killing is not permitted by safe Rust, since it can cause serious corruption. For example, Rust mutexes would likely stay locked forever.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All of these options are suboptimal or of limited use in some way. In general, the way I think about it is that there isn’t a universal protocol for cancellation in synchronous Rust.&lt;/p&gt;
    &lt;p&gt;In contrast, there is such a protocol in async Rust, and in fact cancellations are extraordinarily easy to perform in async Rust.&lt;/p&gt;
    &lt;p&gt;Why is that so? To understand that, let’s look at what a future is.&lt;/p&gt;
    &lt;head rend="h3"&gt;What is a future?#&lt;/head&gt;
    &lt;p&gt;Here’s a simple example of a future:&lt;/p&gt;
    &lt;code&gt;// This creates a state machine.
let future = async {
    let data = request().await;
    process(data).await
};

// Nothing executes yet. `future` is just a struct in memory.
&lt;/code&gt;
    &lt;p&gt;In this future, you first perform a network request which returns some data, and then you process it.&lt;/p&gt;
    &lt;p&gt;The Rust compiler looks at this future and generates a state machine, which is just a struct or enum in memory:&lt;/p&gt;
    &lt;code&gt;// The compiler generates something like:
enum MyFuture {
    Start,
    WaitingForNetwork(NetworkFuture),
    WaitingForProcess(ProcessFuture, Data),
    Done(Result),
}

// It's just data, no running code!
&lt;/code&gt;
    &lt;p&gt;If you’ve written async Rust before the &lt;code&gt;async&lt;/code&gt; and &lt;code&gt;await&lt;/code&gt; keywords, you’ve probably written code like it by hand. It’s basically just an enum describing all the possible states the future can be in.&lt;/p&gt;
    &lt;p&gt;The compiler also generates an implementation of the &lt;code&gt;Future&lt;/code&gt; trait for this future:&lt;/p&gt;
    &lt;code&gt;impl Future for MyFuture {
    fn poll(/* ... */) -&amp;gt; Poll&amp;lt;Self::Output&amp;gt; {
        match self {
            Start =&amp;gt; { /* ... */ }
            WaitingForNetwork(fut) =&amp;gt; { /* ... */ }
            // etc
        }
    }
}
&lt;/code&gt;
    &lt;p&gt;and when you call &lt;code&gt;.await&lt;/code&gt; on the future, it gets translated down to this underlying &lt;code&gt;poll&lt;/code&gt; function. It is only when &lt;code&gt;await&lt;/code&gt; or this &lt;code&gt;poll&lt;/code&gt; function is called that something actually happens.&lt;/p&gt;
    &lt;p&gt;Note that this is diametrically opposed to how async works in other languages like Go, JavaScript, or C#. In those languages, when you create a future to await on, it starts doing its thing, immediately, in the background:&lt;/p&gt;
    &lt;code&gt;// JavaScript: starts running immediately
const promise = fetch('/api/data');
&lt;/code&gt;
    &lt;p&gt;That’s regardless of whether you await it or not.&lt;/p&gt;
    &lt;p&gt;In Rust, this &lt;code&gt;get&lt;/code&gt; call does nothing until you actually call &lt;code&gt;.await&lt;/code&gt; on it:&lt;/p&gt;
    &lt;code&gt;// Rust: just data, does nothing!
let future = reqwest::get("/api/data");
&lt;/code&gt;
    &lt;p&gt;I know I sound a bit like a broken record here, but if you can take away one thing from this post, it would be that futures are passive, and completely inert until awaited or polled.&lt;/p&gt;
    &lt;head rend="h3"&gt;The universal protocol#&lt;/head&gt;
    &lt;p&gt;So what does the universal protocol to cancel futures look like? It is simply to drop the future, or to not await it, or poll it any more. Since a future is just a state machine, you can throw it away at any time the poll function isn’t actively being called.&lt;/p&gt;
    &lt;code&gt;let future = some_async_work();
drop(future); // cancelled
&lt;/code&gt;
    &lt;p&gt;The upshot of all this is that any Rust future can be cancelled at any await point.&lt;/p&gt;
    &lt;p&gt;Given how hard cancellation tends to be in synchronous environments, the ability to easily cancel futures in async Rust is extraordinarily powerful—in many ways its greatest strength!&lt;/p&gt;
    &lt;p&gt;But there is a flip side, which is that cancelling futures is far, far too easy. This is for two reasons.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;First, it’s just way too easy to quietly drop a future. As we’re going to see, there are all kinds of code patterns that lead to silently dropping futures.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Now this wouldn’t be so bad, if not for the second reason: that cancellation of parent futures propagates down to child futures.&lt;/p&gt;
        &lt;p&gt;Because of Rust’s single ownership model, child futures are owned by parent ones. If a parent future is dropped or cancelled, the same happens to the child.&lt;/p&gt;
        &lt;p&gt;To figure out whether a child future’s cancellation can cause issues, you have to look at its parent, and grandparent, and so on. Reasoning about cancellation becomes a very complicated non-local operation.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;2. Analyzing cancellations#&lt;/head&gt;
    &lt;p&gt;I’m going to cover some examples in a bit, but before we do that I want to talk about a couple terms, some of which you might have seen references to already.&lt;/p&gt;
    &lt;head rend="h3"&gt;Cancel safety and cancel correctness#&lt;/head&gt;
    &lt;p&gt;The first term is cancel safety. You might have seen mentions of this in the Tokio documentation. Cancel safety, as generally defined, means the property of a future that can be cancelled (i.e. dropped) without any side effects.&lt;/p&gt;
    &lt;p&gt;For example, a Tokio sleep future is cancel safe: you can just stop waiting on the sleep and it’s completely fine.&lt;/p&gt;
    &lt;code&gt;let future = tokio::time::sleep();
drop(future); // this has no side effects
&lt;/code&gt;
    &lt;p&gt;An example of a future that is not cancel safe is Tokio’s MPSC send, which sends a message over a channel:&lt;/p&gt;
    &lt;code&gt;let message = /* ... */;
let future = sender.send(message);
drop(future); // message is lost!
&lt;/code&gt;
    &lt;p&gt;If this future is dropped, the message is lost forever.&lt;/p&gt;
    &lt;p&gt;The important thing is that cancel safety is a local property of an individual future.&lt;/p&gt;
    &lt;p&gt;But cancel safety is not all that one needs to care about. What actually matters is the context the cancellation happens in, or in other words whether the cancellation actually causes some kind of larger property in the system to be violated.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;For example, if you drop a future which sends a message, but for whatever reason you don’t care about the message any more, it’s not really a bug!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To capture this I tend to use a different term called cancel correctness, which I define as a global property of system correctness in the face of cancellations. (This isn’t a standard term, but it’s a framing I’ve found really helpful in understanding cancellations.)&lt;/p&gt;
    &lt;p&gt;When is cancel correctness violated? It requires three things:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;The system has a cancel-unsafe future somewhere within it. As we’ll see, many APIs that are cancel-unsafe can be reworked to be cancel-safe. If there aren’t any cancel-unsafe futures in the system, then the system is cancel correct.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;A cancel-unsafe future is actually cancelled. This may sound a bit trivial, but if cancel-unsafe futures are always run to completion, then the system can’t have cancel correctness bugs.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Cancelling the future violates some property of a system. This could be data loss as with&lt;/p&gt;&lt;code&gt;Sender::send&lt;/code&gt;, some kind of invariant violation, or some kind of cleanup that must be performed but isn’t.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So a lot of making Rust async robust is about trying to tackle one of these three things.&lt;/p&gt;
    &lt;p&gt;I want to zoom in for a second on invariant violations and talk about an example of a Tokio API that is very prone to cancel correctness issues: Tokio mutexes.&lt;/p&gt;
    &lt;head rend="h3"&gt;The pain of Tokio mutexes#&lt;/head&gt;
    &lt;p&gt;The way Tokio mutexes work is: you create a mutex, you lock it which gives you mutable access to the data underneath, and then you unlock it by releasing the mutex.&lt;/p&gt;
    &lt;code&gt;let guard = mutex.lock().await;
// Access guard.data, protected by the mutex...
drop(guard);
&lt;/code&gt;
    &lt;p&gt;If you look at the &lt;code&gt;lock&lt;/code&gt; function’s documentation, in the “cancel safety” section it says:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;This method uses a queue to fairly distribute locks in the order they were requested. Cancelling a call to lock makes you lose your place in the queue.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Okay, so not totally cancel safe, but the only kind of unsafety is fairness, which doesn’t sound too bad.&lt;/p&gt;
    &lt;p&gt;But the problems lie in what you actually do with the mutex. In practice, most uses of mutexes are in order to temporarily violate invariants that are otherwise upheld when a lock isn’t held.&lt;/p&gt;
    &lt;p&gt;I’ll use a real world example of a cancel correctness bug that we found at my job at Oxide: we had code to manage a bunch of data sent over by our computers, which we call sleds. The shared state was guarded by a mutex, and a typical operation was:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Obtain a lock on the mutex.&lt;/item&gt;
      &lt;item&gt;Obtain the sled-specific data by value, moving it to an invalid &lt;code&gt;None&lt;/code&gt;state.&lt;/item&gt;
      &lt;item&gt;Perform an action.&lt;/item&gt;
      &lt;item&gt;Set the sled-specific data back to the next valid state.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here’s a rough sketch of what that looks like:&lt;/p&gt;
    &lt;code&gt;let guard = mutex.lock().await;
// guard.data is Option&amp;lt;T&amp;gt;: Some to begin with
let data = guard.data.take(); // guard.data is now None

let new_data = process_data(data);
guard.data = Some(new_data); // guard.data is Some again
&lt;/code&gt;
    &lt;p&gt;This is all well and good, but the problem is that the action being performed actually had an await point within it:&lt;/p&gt;
    &lt;code&gt;let guard = mutex.lock().await;
// guard.data is Option&amp;lt;T&amp;gt;: Some to begin with
let data = guard.data.take(); // guard.data is now None

// DANGER: cancellation here leaves data in None state!
let new_data = process_data(data).await;
guard.data = Some(new_data); // guard.data is Some again
&lt;/code&gt;
    &lt;p&gt;If the code that operated on the mutex got cancelled at that await point, then the data would be stuck in the invalid &lt;code&gt;None&lt;/code&gt; state. Not great!&lt;/p&gt;
    &lt;p&gt;And keep in mind the non-local reasoning aspect: when doing this analysis, you need to look at the whole chain of callers.&lt;/p&gt;
    &lt;head rend="h3"&gt;Cancellation patterns#&lt;/head&gt;
    &lt;p&gt;Now that we’ve talked about some of the bad things that can happen during cancellations, it’s worth asking what kinds of code patterns lead to futures being cancelled.&lt;/p&gt;
    &lt;p&gt;The most straightforward example, and maybe a bit of a silly one, is that you create a future but simply forget to call &lt;code&gt;.await&lt;/code&gt; on it.&lt;/p&gt;
    &lt;code&gt;some_async_work(); // missing .await
&lt;/code&gt;
    &lt;p&gt;Now Rust actually warns you if you don’t call &lt;code&gt;.await&lt;/code&gt; on the future:&lt;/p&gt;
    &lt;code&gt;warning: unused implementer of `Future` that must be used
   |
11 |     some_async_work();
   |     ^^^^^^^^^^^^^^^^^
   |
   = note: futures do nothing unless you `.await` or poll them
&lt;/code&gt;
    &lt;p&gt;But a code pattern I’ve sometimes made mistakes with is that the future returns a &lt;code&gt;Result&lt;/code&gt;, and you want to ignore the result so you assign it to an underscore like so:&lt;/p&gt;
    &lt;code&gt;let _ = some_async_work(); // future returns Result
&lt;/code&gt;
    &lt;p&gt;If I forget to call &lt;code&gt;.await&lt;/code&gt; on the future, Rust doesn’t warn me about it at all, and then I’m left scratching my head about why this code didn’t run. I know this sounds really silly and basic, but I’ve made this mistake a bunch of times.&lt;/p&gt;
    &lt;p&gt;(After my talk, it was pointed out to me that Clippy 1.67 and above have a &lt;code&gt;let_underscore_future&lt;/code&gt; warn-by-default lint for this. Hooray!)&lt;/p&gt;
    &lt;p&gt;Another example of futures being cancelled is &lt;code&gt;try&lt;/code&gt; operations, such as Tokio’s &lt;code&gt;try_join&lt;/code&gt; macro. For example:&lt;/p&gt;
    &lt;code&gt;async fn do_stuff_async() -&amp;gt; Result&amp;lt;(), &amp;amp;'static str&amp;gt; {
    // async work
}

async fn more_async_work() -&amp;gt; Result&amp;lt;(), &amp;amp;'static str&amp;gt; {
    // more here
}

let res = tokio::try_join!(
    do_stuff_async(),
    more_async_work(),
);

// ...
&lt;/code&gt;
    &lt;p&gt;If you call &lt;code&gt;try_join&lt;/code&gt; with a bunch of futures, and all of them succeed, it’s all good. But if one of them fails, the rest simply get cancelled.&lt;/p&gt;
    &lt;p&gt;In fact, at Oxide we had a pretty bad bug around this: we had code to stop a bunch of services, all expressed as futures. We used &lt;code&gt;try_join&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;try_join!(
    stop_service_a(),
    stop_service_b(),
    stop_service_c(),
)?;
&lt;/code&gt;
    &lt;p&gt;If one of these operations failed for whatever reason, we would stop running the code to wait for the other services to exit. Oops!&lt;/p&gt;
    &lt;p&gt;But perhaps the most well-known source of cancellations is Tokio’s &lt;code&gt;select&lt;/code&gt; macro. Select is this incredibly beautiful operation. It is called with a set of futures, and it drives all of them forward concurrently:&lt;/p&gt;
    &lt;code&gt;tokio::select! {
    result1 = future1 =&amp;gt; handle_result1(result1),
    result2 = future2 =&amp;gt; handle_result2(result2),
}
&lt;/code&gt;
    &lt;p&gt;Each future has a code block associated with it (above, &lt;code&gt;handle_result1&lt;/code&gt; and &lt;code&gt;handle_result2&lt;/code&gt;). If one of the futures completes, the corresponding code block is called. But also, all of the other futures are always cancelled!&lt;/p&gt;
    &lt;p&gt;For a variety of reasons, select statements in general, and select loops in particular, are particularly prone to cancel correctness issues. So a lot of the documentation about cancel safety talks about select loops. But I want to emphasize here that select is not the only source of cancellations, just a particularly notable one.&lt;/p&gt;
    &lt;head rend="h2"&gt;3. What can be done?#&lt;/head&gt;
    &lt;p&gt;So, now that we’ve looked at all of these issues with cancellations, what can be done about it?&lt;/p&gt;
    &lt;p&gt;First, I want to break the bad news to you – there is no general, fully reliable solution for this in Rust today. But in our experience there are a few patterns that have been successful at reducing the likelihood of cancellation bugs.&lt;/p&gt;
    &lt;p&gt;Going back to our definition of cancel correctness, there are three prongs all of which come together to produce a bug:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A cancel-unsafe future exists&lt;/item&gt;
      &lt;item&gt;This cancel-unsafe future is cancelled&lt;/item&gt;
      &lt;item&gt;The cancellation violates a system property&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Most solutions we’ve come up with try and tackle one of these prongs.&lt;/p&gt;
    &lt;head rend="h3"&gt;Making futures cancel-safe#&lt;/head&gt;
    &lt;p&gt;Let’s look at the first prong: the system has a cancel-unsafe future somewhere in it. Can we use code patterns to make futures be cancel-safe? It turns out we can! I’ll give you two examples here.&lt;/p&gt;
    &lt;p&gt;The first is MPSC sends. Let’s come back to the example from earlier where we would lose messages entirely:&lt;/p&gt;
    &lt;code&gt;loop {
    let msg = next_message();
    match timeout(Duration::from_secs(5), tx.send(msg)).await {
        Ok(Ok(_)) =&amp;gt; println!("sent successfully"),
        Ok(Err(_)) =&amp;gt; return,
        Err(_) =&amp;gt; println!("no space for 5 seconds"),
    }
}
&lt;/code&gt;
    &lt;p&gt;Can we find a way to make this cancel safe?&lt;/p&gt;
    &lt;p&gt;In this case, yes, and we do so by breaking up the operation into two parts:&lt;/p&gt;
    &lt;code&gt;loop {
    let msg = next_message();
    loop {
        match timeout(Duration::from_secs(5), tx.reserve()).await {
            Ok(Ok(permit)) =&amp;gt; { permit.send(msg); break; }
            Ok(Err(_)) =&amp;gt; return,
            Err(_) =&amp;gt; println!("no space for 5 seconds"),
        }
    }
}
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The first component is the operation to reserve a permit or slot in the channel. This is an initial async operation that’s cancel-safe.&lt;/item&gt;
      &lt;item&gt;The second is to actually send the message, which is an operation that becomes infallible.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;(I want to put an asterisk here that reserve is not entirely cancel-safe, since Tokio’s MPSC follows a first-in-first-out pattern and dropping the future means losing your place in line. Keep this in mind for now.)&lt;/p&gt;
    &lt;p&gt;The second is with Tokio’s &lt;code&gt;AsyncWrite&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;If you’ve written synchronous Rust you’re probably familiar with the &lt;code&gt;write_all&lt;/code&gt; method, which writes an entire buffer out:&lt;/p&gt;
    &lt;code&gt;use std::io::Write;

let buffer: &amp;amp;[u8] = /* ... */;
writer.write_all(buffer)?;
&lt;/code&gt;
    &lt;p&gt;In synchronous Rust, this is a great API. But within async Rust, the &lt;code&gt;write_all&lt;/code&gt; pattern is absolutely not cancel safe! If the future is dropped before completion, you have no idea how much of this buffer was written out.&lt;/p&gt;
    &lt;code&gt;use tokio::io::AsyncWriteExt;

let buffer: &amp;amp;[u8] = /* ... */;
writer.write_all(buffer).await?; // Not cancel-safe!
&lt;/code&gt;
    &lt;p&gt;But there’s an alternative API that is cancel-safe, called &lt;code&gt;write_all_buf&lt;/code&gt;. This API is carefully designed to enable the reporting of partial progress, and it doesn’t just accept a buffer, but rather something that looks like a cursor on top of it:&lt;/p&gt;
    &lt;code&gt;use tokio::io::AsyncWriteExt;

let mut buffer: io::Cursor&amp;lt;&amp;amp;[u8]&amp;gt; = /* ... */;
writer.write_all_buf(&amp;amp;mut buffer).await?;
&lt;/code&gt;
    &lt;p&gt;When part of the buffer is written out, the cursor is advanced by that number of bytes. So if you call &lt;code&gt;write_all_buf&lt;/code&gt; in a loop, you’ll be resuming from this partial progress, which works great.&lt;/p&gt;
    &lt;head rend="h3"&gt;Not cancelling futures#&lt;/head&gt;
    &lt;p&gt;Going back to the three prongs: the second prong is about actually cancelling futures. What code patterns can be used to not cancel futures? Here are a couple of examples.&lt;/p&gt;
    &lt;p&gt;The first one is, in a place like a select loop, resume futures rather than cancelling them each time. You’d typically achieve this by pinning a future, and then polling a mutable reference to that future. For example:&lt;/p&gt;
    &lt;code&gt;let mut future = Box::pin(channel.reserve());
loop {
    tokio::select! {
        result = &amp;amp;mut future =&amp;gt; break result,
        _ = other_condition =&amp;gt; continue,
    }
}
&lt;/code&gt;
    &lt;p&gt;Coming back to our example of MPSC sends, the one asterisk with &lt;code&gt;reserve&lt;/code&gt; is that cancelling it makes you lose your place in line. Instead, if you pin the &lt;code&gt;reserve&lt;/code&gt; future and poll a mutable reference to it, you don’t lose your place in line.&lt;/p&gt;
    &lt;p&gt;(Does the difference here matter? It depends, but you can now have this strategy available to you.)&lt;/p&gt;
    &lt;p&gt;The second example is to use tasks. I mentioned earlier that futures are Rust are diametrically opposed to similar notions in languages like JavaScript. Well, there’s an alternative in async Rust that’s much closer to the JavaScript idea, and that’s tasks.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Unlike futures which are driven by the caller, tasks are driven by the runtime (such as Tokio).&lt;/item&gt;
      &lt;item&gt;With Tokio, dropping a handle to a task does not cause it to be cancelled, which means they’re a good place to run cancel-unsafe code.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A fun example is that at Oxide, we have an HTTP server called Dropshot. Previously, whenever an HTTP request came in, we’d use a future for it, and drop the future if the TCP connection was closed.&lt;/p&gt;
    &lt;code&gt;// Before: Future cancelled on TCP close
handle_request(req).await;
&lt;/code&gt;
    &lt;p&gt;This was really bad because future cancellations could happen due to the behavior of not just the parent future, but of a process that was running across a network! This is a rather extreme form of non-local reasoning.&lt;/p&gt;
    &lt;p&gt;We addressed this by spinning up a task for each HTTP request, and by running the code to completion even if the connection is closed:&lt;/p&gt;
    &lt;code&gt;// After: Task runs to completion
tokio::spawn(handle_request(req));
&lt;/code&gt;
    &lt;head rend="h3"&gt;Systematic solutions?#&lt;/head&gt;
    &lt;p&gt;The last thing I want to say is that this sucks!&lt;/p&gt;
    &lt;p&gt;The promise of Rust is that you don’t need to do this kind of non-local reasoning—that you can analyze small bits of code for local correctness, and scale that up to global correctness. Almost everything in Rust, from &lt;code&gt;&amp;amp;&lt;/code&gt; and &lt;code&gt;&amp;amp;mut&lt;/code&gt; to &lt;code&gt;unsafe&lt;/code&gt;, is geared towards making that possible. Future cancellations fly directly in the face of that, and I think they’re probably the least Rusty part of Rust. This is all really unfortunate.&lt;/p&gt;
    &lt;p&gt;Can we come up with something more systematic than this kind of ad-hoc reasoning?&lt;/p&gt;
    &lt;p&gt;There doesn’t exist anything in safe Rust today, but there are a few different ideas people have come up with. I wanted to give a nod to those ideas:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Async drop would let you run async code when a future is cancelled. This would handle some, though not all, of the cases we discussed today.&lt;/item&gt;
      &lt;item&gt;There’s also a couple different proposals for what are called linear types, where you could force some code to be run on drop, or mark a particular future as non-cancellable (once it’s been created it must be driven to completion).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All of these options have really significant implementation challenges, though. This blog post from boats covers some of these solutions, and the implementation challenges with them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion#&lt;/head&gt;
    &lt;p&gt;In this post, we:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Saw that futures are passive&lt;/item&gt;
      &lt;item&gt;Introduced cancel safety and cancel correctness as concepts&lt;/item&gt;
      &lt;item&gt;Examined some bugs that can occur with cancellation&lt;/item&gt;
      &lt;item&gt;Looked at some recommendations you can use to mitigate the downsides of cancellation&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Some of the recommendations are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Avoid Tokio mutexes&lt;/item&gt;
      &lt;item&gt;Rewrite APIs to make futures cancel-safe&lt;/item&gt;
      &lt;item&gt;Find ways to ensure that cancel-unsafe futures are driven to completion&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There’s a very deep well of complexity here, a lot more than I can cover in one blog post:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Why are futures passive, anyway?&lt;/item&gt;
      &lt;item&gt;Cooperative cancellation: cancellation tokens&lt;/item&gt;
      &lt;item&gt;Actor model as an alternative to Tokio mutexes&lt;/item&gt;
      &lt;item&gt;Task aborts&lt;/item&gt;
      &lt;item&gt;Structured concurrency&lt;/item&gt;
      &lt;item&gt;Relationship to panic safety and mutex poisoning&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you’re curious about any of these, check out this link where I’ve put together a collection of documents and blog posts about these concepts. In particular, I’d recommend reading these two Oxide RFDs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;RFD 397 Challenges with async/await in the control plane by David Pacheco&lt;/item&gt;
      &lt;item&gt;RFD 400 Dealing with cancel safety in async Rust by myself&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Thank you for reading this post to the end! And thanks to many of my coworkers at Oxide for reviewing the talk and the RFDs linked above, and for suggestions and constructive feedback.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45464632</guid><pubDate>Fri, 03 Oct 2025 16:18:29 +0000</pubDate></item><item><title>OpenAI Is Just Another Boring, Desperate AI Startup</title><link>https://www.wheresyoured.at/sora2-openai/</link><description>&lt;doc fingerprint="60179855900eef9c"&gt;
  &lt;main&gt;
    &lt;p&gt;What is OpenAI?&lt;/p&gt;
    &lt;p&gt;I realize you might say "a foundation model lab" or "the company that runs ChatGPT," but that doesn't really give the full picture of everything it’s promised, or claimed, or leaked that it was or would be.&lt;/p&gt;
    &lt;p&gt;No, really, if you believe its leaks to the press...&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;OpenAI is a social media company, this week launching Sora 2, a social feed entirely made up of generative video.&lt;/item&gt;
      &lt;item&gt;OpenAI is a workplace productivity company, allegedly working on its own productivity suite to compete with Microsoft.&lt;/item&gt;
      &lt;item&gt;OpenAI is a jobs portal, announcing in September it was "developing an AI-powered hiring platform," which it will launch 'by mid-2026.&lt;/item&gt;
      &lt;item&gt;OpenAI is an ads company, and is apparently trying to hire an an ads chief, with the (alleged) intent to start showing ads in ChatGPT "by 2026."&lt;/item&gt;
      &lt;item&gt;OpenAI is a company that would sell AI compute like Microsoft Azure or Amazon Web Services, or at least is considering being one, with CFO Sarah Friar telling Bloomberg in August that it is not "actively looking" at such an effort today but will "think about it as a business down the line, for sure."&lt;/item&gt;
      &lt;item&gt;OpenAI is a fabless semiconductor design company, launching its own AI chips in, again, 2026 with Broadcom, but only for internal use.&lt;/item&gt;
      &lt;item&gt;OpenAI is a consumer hardware company, preparing to launch a device by the end of 2026 or early 2027 and hiring a bunch of Apple people to work on it, as well as considering — again, it’s just leaking random stuff at this point to pump up its value — a smart speaker, a voice recorder and AR glasses.&lt;/item&gt;
      &lt;item&gt;OpenAI is also working on its own browser, I guess.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To be clear, many of these are ideas that OpenAI has leaked specifically so the media can continue to pump up its valuation and continue to raise the money it needs — at least $1 Trillion over the next four or five years, and I don't believe the theoretical (or actual) costs of many of the things I've listed are included.&lt;/p&gt;
    &lt;p&gt;OpenAI wants you to believe it is everything, because in reality it’s a company bereft of strategy, focus or vision. The GPT-5 upgrade for ChatGPT was a dud — an industry-wide embarrassment for arguably the most-hyped product in AI history, one that (as I revealed a few months ago) costs more to operate than its predecessor, not because of any inherent capability upgrade, but how it actually processes the prompts its user provides — and now it's unclear what it is that this company does.&lt;/p&gt;
    &lt;p&gt;Does it make hardware? Software? Ads? Is it going to lease you GPUs to use for your own AI projects? Is it going to certify you as an AI expert? Notice how I've listed a whole bunch of stuff that isn't ChatGPT, which will, if you look at The Information's reporting of its projections, remain the vast majority of its revenue until 2027, at which point "agents" and "new products including free user monetization" will magically kick in.&lt;/p&gt;
    &lt;head rend="h2"&gt;OpenAI Is A Boring (and Bad) Business&lt;/head&gt;
    &lt;p&gt;In reality, OpenAI is an extremely boring (and bad!) software business. It makes the majority of its revenue selling subscriptions to ChatGPT, and apparently had 20 million paid subscribers (as of April) and 5 million business subscribers (as of August, though 500,000 of them are Cal State University seats paid at $2.50 a month).&lt;/p&gt;
    &lt;p&gt;It also loses incredibly large amounts of money.&lt;/p&gt;
    &lt;head rend="h3"&gt;OpenAI's Pathetic API Sales Have Effectively Turned It Into Any Other AI Startup&lt;/head&gt;
    &lt;p&gt;Yes, I realize that OpenAI also sells access to its API, but as you can see from the chart above, it is making a teeny tiny sliver of revenue from it in 2025, though I will also add that this chart has a little bit of green for "agent" revenue, which means it's very likely bullshit. Operator, OpenAI's so-called agent, is barely functional, and I have no idea how anyone would even begin to charge money for it outside of "please try my broken product."&lt;/p&gt;
    &lt;p&gt;In any case, API sales appear to be a very, very small part of OpenAI's revenue stream, and that heavily suggests a lack of interest in integrating its models at scale.&lt;/p&gt;
    &lt;p&gt;Worse still, this effectively turns OpenAI into an AI startup.&lt;/p&gt;
    &lt;p&gt;Think about it: if OpenAI can't make the majority of its money through "innovating" in the development of large language models (LLMs), then it’s just another company plugging LLMs into its software. While ChatGPT may be a very popular product, it is, by definition (and in its name!) a GPT wrapper, with the few differences being that OpenAI pays its own immediate costs, has the people necessary to continue improving its own models, and also continually makes promises to convince people it’s anything other than just another AI startup.&lt;/p&gt;
    &lt;p&gt;In fact, the only real difference is the amount of money backing it. Otherwise, OpenAI could be literally any foundation model company, and with a lack of real innovation within those models, it’s just another startup trying to find ways to monetize generative AI, an industry that only ever seems to lose money.&lt;/p&gt;
    &lt;p&gt;As a result, we should start evaluating OpenAI as just another AI startup, as its promises do not appear to mesh with any coherent strategy, other than "we need $1 trillion dollars." There does not seem to be much of a plan on a day-to-day basis, nor does there seem to be one about what OpenAI should be, other than that OpenAI will be a consumer hardware, consumer software, enterprise SaaS and data center operator, as well as running a social network.&lt;/p&gt;
    &lt;p&gt;As I've discussed many times, LLMs are inherently flawed due to their probabilistic nature."Hallucinations" — when a model authoritatively states something is true when it isn't (or takes an action that seems the most likely course of action, even if it isn't the right one) — are a "mathematically inevitable" according to OpenAI's own research feature of the technology, meaning that there is no fixing their most glaring, obvious problem, even with "perfect data."&lt;/p&gt;
    &lt;p&gt;I'd wager the reason OpenAI is so eager to build out so much capacity while leaking so many diverse business lines is an attempt to get away from a dark truth: that when you peel away the hype, ChatGPT is a wrapper, every product it makes is a wrapper, and OpenAI is pretty fucking terrible at making products.&lt;/p&gt;
    &lt;p&gt;Today I'm going to walk you through a fairly unique position: that OpenAI is just another boring AI startup lacking any meaningful product roadmap or strategy, using the press as a tool to pump its bags while very rarely delivering on what it’s promised. It is a company with massive amounts of cash, industrial backing, and brand recognition, and otherwise is, much like its customers, desperately trying to work out how to make money selling products built on top of Large Language Models.&lt;/p&gt;
    &lt;p&gt;OpenAI lives and dies on its mythology as the center of innovation in the world of AI, yet reality is so much more mediocre. Its revenue growth is slowing, its products are commoditized, its models are hardly state-of-the-art, the overall generative AI industry has lost its sheen, and its killer app is a mythology that has converted a handful of very rich people and very few others.&lt;/p&gt;
    &lt;p&gt;OpenAI spent, according to The Information, 150% ($6.7 billion in costs) of its H1 2025 revenue ($4.3 billion) on research and development, producing the deeply-underwhelming GPT-5 and Sora 2, an app that I estimate costs it upwards of $5 for each video generation, based on Azure's published rates for the first Sora model, though it's my belief that these rates are unprofitable, all so that it can gain a few more users.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45464849</guid><pubDate>Fri, 03 Oct 2025 16:37:01 +0000</pubDate></item><item><title>Germany must stand firmly against client-side scanning in Chat Control [pdf]</title><link>https://signal.org/blog/pdfs/germany-chat-control.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45464921</guid><pubDate>Fri, 03 Oct 2025 16:44:02 +0000</pubDate></item><item><title>The Collapse of the Econ PhD Job Market</title><link>https://www.chrisbrunet.com/p/the-collapse-of-the-econ-phd-job</link><description>&lt;doc fingerprint="2a4080db19b566a2"&gt;
  &lt;main&gt;&lt;p&gt;For decades, a doctorate in economics was a golden ticket. It promised a path to tenure, or at worst, a lucrative role at a central bank, think tank, or tech firm.&lt;/p&gt;&lt;p&gt;Not anymore.&lt;/p&gt;&lt;p&gt;The economics job market is in freefall, and the profession’s own data proves it.&lt;/p&gt;&lt;p&gt;Unlike most fields, economics has a bizarrely centralized hiring ritual. Once a year, in the fall, every employer posts openings at the same time. Every candidate applies at the same time. The entire profession runs through one clearinghouse: the American Economic Association’s “Job Openings for Economists” (JOE). This makes economics PhD market uniquely measurable, and the numbers are brutal.&lt;/p&gt;&lt;head rend="h3"&gt;Job postings for PhD economists are down 30 percent in just three years&lt;/head&gt;&lt;p&gt;The JOE data shows few jobs in 2022, fewer still in 2023, and fewer still in 2024.&lt;/p&gt;&lt;p&gt;This year’s trajectory suggests 2025 will be even worse:&lt;/p&gt;&lt;p&gt;Extrapolating, the 2025 market looks set to bottom out around 1,000 openings:&lt;/p&gt;&lt;p&gt;I think my freehand projection is a very conservative approximation of reality—actual numbers may come in slightly higher or lower, of course, but this reasonably looks like what the market is on track for, barring a miracle.&lt;/p&gt;&lt;p&gt;Just three years ago, there were 1,477 openings.&lt;/p&gt;&lt;p&gt;The fall to ~1,000 this year will represent a 32% collapse.&lt;/p&gt;&lt;p&gt;Most economics PhD students aren’t looking for just any job, though, they want a tenure-track position in academia. According to polling data from the 2025 Webinar on the Economics PhD Job Market, 94% of candidates from the past four cohorts reported being “very interested” or “somewhat interested” in becoming an assistant professor, dwarfing all non-academic options.&lt;/p&gt;&lt;p&gt;Subsetting the JOE data to permanent academic positions (tenure-track or tenured) yields a nearly identical trend: openings dropped from 631 in 2022 to about 400 in 2025, a 35% decline over three years:&lt;/p&gt;&lt;p&gt;Again, please forgive my Microsoft Paint skills:&lt;/p&gt;&lt;p&gt;The JOE data is confirmed by Econ Job Market (EJM) data, a nonprofit 501(c)(3) whose stated mission is “to improve the flow of information in the job market for academic economists, by providing a central repository for job-market materials.”&lt;/p&gt;&lt;p&gt;EJM data makes the pattern robust: nearly all interview invitations are sent out during a concentrated few weeks in December, and the volume of those invitations has collapsed from 3,835 down to 2,502… a 34.8% decline.&lt;/p&gt;&lt;p&gt;As a result, the AEA’s own Job Market Committee quietly admitted in its 2025 report that last year was “challenging” for candidates.&lt;/p&gt;&lt;head rend="h2"&gt;While Supply of Tenure-Track Jobs Plummets, Demand Rises&lt;/head&gt;&lt;p&gt;EJM data show that the cumulative number of views on job ads is higher than ever, with 2025 easily on track to set a new record.&lt;/p&gt;&lt;p&gt;That isn’t surprising: according to the 2024 NSF Survey of Doctorate Recipients, 1,385 Americans earned economics PhDs in 2024, more than in 2023, more than in 2022, and more than in 2021.&lt;/p&gt;&lt;p&gt;You now have 1,385 brand-new PhDs chasing just 400 tenure-track jobs.&lt;/p&gt;&lt;p&gt;At first glance, that ratio might not look catastrophic. But here’s the catch:&lt;/p&gt;&lt;p&gt;They’re not competing only against each other. An equally large wave of international candidates floods the U.S. market every year. American universities routinely hire from London, Oxford, Cambridge, Toronto, Paris, Barcelona, and beyond.&lt;/p&gt;&lt;p&gt;Furthermore, the new graduates aren’t competing just with their own cohort. They’re thrown into the same bucket as the leftovers from every prior cycle: post-docs clinging to hope, visiting professors chasing stability, lecturers desperate to upgrade, assistant professors stranded at second-tier schools. The “new supply” is just the visible tip; the true applicant pool is a rolling backlog several times larger.&lt;/p&gt;&lt;p&gt;The result? According to EJM, 5,341 candidates participated in the 2024–25 market, the largest applicant pool ever recorded:&lt;/p&gt;&lt;p&gt;Yet the AEA’s Survey of the Labor Market for New Ph.D. Hires in Economics found that only 99 fresh PhD secured a tenure-track job in America.&lt;/p&gt;&lt;p&gt;That’s a ~7% placement rate for American PhD students.&lt;/p&gt;&lt;p&gt;Put differently: if 100 students spend six years earning an econ PhD in America (the current U.S. median time to degree is 5.8 years, not counting the growing detour of “pre-docs”), only seven will get a tenure-track job.&lt;/p&gt;&lt;p&gt;Even if we allow for survey response gaps and use the most charitable assumptions, the best possible placement rate for fresh Econ PhDs is likely no higher than 10–20%, maybe 25%? My methodology isn’t perfect, but no matter what, that’s still catastrophic.&lt;/p&gt;&lt;p&gt;And these jobs aren’t evenly distributed. A massively disproportionate share go to graduates of Harvard, MIT, Stanford, Chicago, Princeton, Yale, Berkeley, and Penn. That means for every grad student outside the top 10 programs, the odds of landing tenure track are significantly less than 5%.&lt;/p&gt;&lt;head rend="h2"&gt;Beyond academia is even more grim&lt;/head&gt;&lt;p&gt;Government has long been the second-largest employer of economics PhDs, traditionally offering stable if less glamorous careers at agencies like the Federal Reserve, Treasury, Bureau of Labor Statistics, or Congressional Budget Office. But even here, the number of available positions has fallen sharply. Federal hiring freezes, budget constraints, and shifting political priorities mean that many agencies are cutting back.&lt;/p&gt;&lt;p&gt;International organizations once served as the safety net for economists who missed out on academia or Washington. The IMF, World Bank, and OECD hired tons of econ PhDs. Today, those doors are far more scarce, and the competition is global: an American graduate is just as likely to be measured against candidates from LSE, Sciences Po, or Peking University.&lt;/p&gt;&lt;p&gt;Oh yeah, and they have hiring freezes too:&lt;/p&gt;&lt;p&gt;Outside academia, government, or IGOs, the tech industry used to provide a reliable fallback. Tech giants like Amazon, Microsoft, Netflix, and Airbnb built entire teams of economists to optimize pricing, design experiments, and model consumer behavior.&lt;/p&gt;&lt;p&gt;That avenue, too, has begun to shrink. Tech hiring, which exploded during the pandemic, has collapsed. Today, demand is not just weak but structurally below trend, as firms automate more of the work that junior economists once did.&lt;/p&gt;&lt;p&gt;‘‘What does the modal economist, or any non CS or DS person really, have to offer to a tech firm in 2025? Not all, but many tech companies are actively downsizing and laying off tons of workers with tech experience that you have to compete against. And few firms will really care about causal inference and any other data analytics jobs can be filled by data science masters grads with deeper programming skills and cheaper salary expectations. Not to mention there is a focus on developing and using AI these days and your intro to machine learning class isn’t going to cut it.’’&lt;/p&gt;&lt;p&gt;— Anonymous economist&lt;/p&gt;&lt;p&gt;The only seemingly stable landing spot left for economists is in banking and finance, but even here hiring is stagnant and remains well below its pre-pandemic trend. Counterintuitively, most private-sector banks and investment firms do not rely heavily on PhDs in economics. They prefer MBAs, statisticians, or computer scientists, leaving economics doctorates as niche hires rather than a core part of the workforce.&lt;/p&gt;&lt;head rend="h2"&gt;Four Structural Reasons Behind Decline of Demand for Economics professors &lt;/head&gt;&lt;p&gt;REASON 1: Declining undergraduate enrollment in economics&lt;/p&gt;&lt;p&gt;Benjamin Hansen, an econ professor at the University of Oregon, recently tweeted out His department’s own data show a steady fall in the number of declared majors, which has now translated into fewer degrees conferred.&lt;/p&gt;&lt;p&gt;National statistics confirm the trend: the number of students graduating with economics degrees is now slipping after years of steady growth.&lt;/p&gt;&lt;p&gt;Because universities hire faculty in proportion to student demand, this drop in majors eventually trickles down into fewer faculty lines.&lt;/p&gt;&lt;p&gt;REASON 2: The looming demographic cliff&lt;/p&gt;&lt;p&gt;The decline in majors is compounded by a larger demographic shift. The U.S. is approaching a “demographic cliff,” as the number of 18-year-olds begins to shrink in the 2020s and 2030s. Fewer college-aged students overall means fiercer competition among departments for enrollments.&lt;/p&gt;&lt;p&gt;REASON 3: The rise of artificial intelligence&lt;/p&gt;&lt;p&gt;Bryan Caplan, professor of economics at George Mason University, gave ChatGPT his graduate-level Labor Economics final exam. The AI earned a “D” (this was 2 years ago), but soon enough, we all know it will be smart enough to earn an A. The technology is improving rapidly, and universities know it, and so does the private sector. Tasks once reserved for graduate students and junior faculty—data cleaning, econometric modeling, even writing referee reports—are now being automated.&lt;/p&gt;&lt;p&gt;REASON 4: Lying About Inflation&lt;/p&gt;&lt;p&gt;If you were there during the pandemic money printing, you remember the sequence all too well: first the confident insistence that government spending wouldn’t fuel inflation, then the soothing claim that inflation was merely “transitory,” and finally the outright gaslighting that prices weren’t rising at all. Each step was wrong, and each was delivered with smug certainty. Ordinary people—who watched their rent, groceries, and gas bills skyrocket—saw a profession more invested in protecting Democratic policy narratives than in telling the truth. The result is a self-inflicted torching of trust.&lt;/p&gt;&lt;head rend="h2"&gt;Is an Economics PhD still a good deal?&lt;/head&gt;&lt;p&gt;The answer is no. An economics PhD is no longer an investment. It is a gamble with terrible odds. A handful of winners still exist, almost all of them minted at Harvard, MIT, Princeton, or Chicago. For everyone else, the degree is a trap: six or more years of grinding work that too often ends with being overeducated, underpaid, and locked out of the profession you trained to join.&lt;/p&gt;&lt;p&gt;‘‘My advice is to do something other than go for a Ph.D in economics … In hindsight, my decision to go to graduate school was a mistake. My primary motivation was intellectual curiosity, and econ grad school worked against that.’’&lt;/p&gt;&lt;p&gt;—&lt;/p&gt;&lt;p&gt;After I wrote this entire article, I came across a similar one published last month by the New York Times:&lt;/p&gt;&lt;p&gt;It essentially just blamed the ‘‘bull market for economists being over’’ on the same three core reasons as I did:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;‘‘Universities and nonprofits have scaled back hiring amid declining state budgets and federal funding cuts.’’&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;‘‘At the same time, the Trump administration has laid off government economists and frozen hiring for new ones.’’&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;‘‘Tech companies also have grown stingier, and their need for high-level economists — once seemingly insatiable — has waned.’’&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Much more interesting than the NYT article was this commentary on it from&lt;/p&gt;, a PhD economist trained at UC Berkeley:&lt;p&gt;He begins by engaging with the NYT article, then runs through the same JOE data I did, ultimately landing on a similar diagnosis: the collapse is driven largely by federal hiring freezes and the looming demographic cliff. From there, though, his piece becomes more distinctive and interesting, exploring the social dynamics and internal hierarchies of the profession. His conclusion is bleak for the discipline itself, but notably optimistic about the future of Substack:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Do I think the PhD job market will bounce back?&lt;/p&gt;&lt;p&gt;Prognosticating too eagerly is a good way to land yourself a place in the Irving Fisher Hall of Forever Being Remembered For Having Said One Stupid Thing.4 A 16% fall in jobs, while devastating, is not yet apocalyptic. (By comparison, historian job ads have fallen closer to 50% since their 2008 peak.) But for things to get better requires a causal mechanism. Reinstating science and academic funding would require either Republicans to reverse their stance on the value of higher education, or for Democrats to win back the Senate. I don’t have a great sense of if either will happen.5&lt;/p&gt;&lt;p&gt;In this case, prediction may be less important than preparation. Placement chairs need to own up to the harshness of the labor market, and urge job market candidates to start prepping non-academic options. (Better yet, admissions chairs should consider paring back cohort sizes.) Candidates who would like a proper job after graduating should be networking, hard. And candidates resolutely committed to academia should steel themselves for long hibernations as post docs, to wait out the coming storm.&lt;/p&gt;&lt;p&gt;On second thought, I will venture one dark prediction, for at least the near future.&lt;/p&gt;&lt;p&gt;We’re going to see a lot more Substacks.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;The wager, then, is that the future of intellectual life will be increasingly decentralized. Platforms like Substack are already siphoning off the kind of energy and analysis that once flowed into journals or policy shops.&lt;/p&gt;&lt;p&gt;As for the economics profession, the only real fix would be radical: every PhD program would have to coordinate and act like a cartel to slash admissions to dramatically reduce supply. Without that discipline, the system will keep flooding the market with useless doctorates, a Ponzi scheme destined to collapse under its own weight.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45464984</guid><pubDate>Fri, 03 Oct 2025 16:49:57 +0000</pubDate></item><item><title>Depot (YC W23) Is Hiring a Principal Design Engineer (Remote US/EU)</title><link>https://www.ycombinator.com/companies/depot/jobs/qg8iVTz-principal-design-engineer</link><description>&lt;doc fingerprint="7cdcf65b3f542330"&gt;
  &lt;main&gt;
    &lt;p&gt;Build faster. Waste less time.&lt;/p&gt;
    &lt;p&gt;At Depot, we are on a mission to redefine software collaboration and accelerate developers everywhere. We are creating a build performance and developer platform unlike any other, combining performance, empathy, and centralized collaboration to enable companies to iterate exponentially faster.&lt;/p&gt;
    &lt;p&gt;We are embarking on the next phase of Depot, which aims to redefine the software development process. Everyone at Depot is inspired by the opportunity to help developers ship and collaborate faster than ever before. We are all builders and care deeply about the quality of our work.&lt;/p&gt;
    &lt;p&gt;We believe that by focusing on performance, empathy, and quality, we are creating a gravitational pull towards Depot, both the team and the product. This is the foundation on which all other things are built.&lt;/p&gt;
    &lt;p&gt;We are looking to hire our first Design Engineer who can further advance our mission to provide not just the fastest place to collaborate on software, but the highest quality as well.&lt;/p&gt;
    &lt;p&gt;For this role, we expect you to be a seasoned expert, have robust design skills, sharp product thinking, and the ability to engage deeply in technical discussions. We work as a small team where engineers and designers work side by side to test ideas, build proof of concepts, and ultimately ship quality solutions to customers. You will be a key contributor and have ownership &amp;amp; autonomy to see projects through from beginning to end.&lt;/p&gt;
    &lt;p&gt;Please note: We are an equal opportunity employer and remote-only company. At this time, we can only support hiring within North America and Europe for this role.&lt;/p&gt;
    &lt;p&gt;We are a fully remote and globally distributed team across the US, Europe, and Canada currently. As a remote startup, there is a collection of things we value and expect from folks:&lt;/p&gt;
    &lt;p&gt;Depot is a build acceleration and developer productivity platform that saves companies like PostHog, Wistia, Semgrep, and Secoda thousands of hours in build time every week.&lt;/p&gt;
    &lt;p&gt;We are developers. We started Depot because we were frustrated with the constant pain of slow build performance. We were fed up waiting for builds and annoyed by the lack of tooling and providers that actually made builds performant. So, we went and built the solution we had always wanted.&lt;/p&gt;
    &lt;p&gt;Slow builds are the dam standing in the way between mediocrity and innovation. They’re wasteful, expensive, and a drain on developer happiness &amp;amp; productivity. They slow down innovation.&lt;/p&gt;
    &lt;p&gt;Taking a 40-minute build down to a minute, changes everything. We help folks save literal years in build time every single week.&lt;/p&gt;
    &lt;p&gt;And we’re just getting started. For us, it’s all about iteration speed and keeping developers in their flow state. Our mission is to be relentless in accelerating software development.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45465078</guid><pubDate>Fri, 03 Oct 2025 17:00:08 +0000</pubDate></item><item><title>Ants Trapped in a Soviet Nuclear Bunker Survived for Years</title><link>https://www.sciencealert.com/ants-trapped-in-an-old-soviet-nuclear-bunker-survived-for-years-by-turning-on-their-own</link><description>&lt;doc fingerprint="3e211792082b4bea"&gt;
  &lt;main&gt;
    &lt;p&gt;Even in a hopeless place, ants will find a way. No food, no light, no escape? No problem.&lt;/p&gt;
    &lt;p&gt;In the woods of western Poland lies a dismantled Soviet nuclear base, complete with two underground bunkers where nuclear ammunition was once kept. After the military complex was abandoned, these eerie human-made caves became great roosting places for overwintering bats.&lt;/p&gt;
    &lt;p&gt;In early 2010s, volunteers started visiting the bunkers to monitor the bat population in winter, and made a discovery of a different sort: A large mass of wood ants (Formica polyctena) trapped on the bunker floor, surviving without a queen or any of their usual creature comforts.&lt;/p&gt;
    &lt;p&gt;When it was first found in 2013, this 'colony' of underground ants already included up to a million live workers and several more million dead. They were not reproducing, though. Instead, the population was being replenished through sheer accident.&lt;/p&gt;
    &lt;p&gt;In the ceiling of the bunker sat a rusted ventilation pipe, connecting the dark cavern to the forest above. There, a giant ant colony had built a mound right above the bunker; as the metal rusted through, some of their ranks started falling into the concrete cavern below.&lt;/p&gt;
    &lt;p&gt;"In total darkness, they have constructed an earthen mound, which they have maintained all-year-round by moulding it and keeping the nest entrances open," researchers wrote in a study in 2016, noting these ants are "a far cry from a fully functional colony".&lt;/p&gt;
    &lt;p&gt;Investigating the limits of ant living conditions is a subject of keen interest for some entomologists. So, for several years, researchers made repeated trips to the bunker and watched in fascination as this isolated population continued to grow and survive despite a lack of light, heat, or obvious nourishment.&lt;/p&gt;
    &lt;p&gt;Now, scientists finally know how these trapped insects pulled it off: the mass consumption of their own imprisoned nest mates.&lt;/p&gt;
    &lt;p&gt;Cannibalism was obviously suspected; wood ants are, after all, the only major food source available in this tight spot, apart from the occasional dead mouse or bat. Plus, this particular species is known to consume their own fallen dead during territorial "ant wars" when food is often scarce.&lt;/p&gt;
    &lt;p&gt;To confirm this hunch, a team of researchers collected corpses from several ant 'cemeteries' scattered within the bunker. Closely examining 150 dead worker ants, the team noticed the vast majority of bodies (roughly 93 percent) had gnawed holes and bite marks.&lt;/p&gt;
    &lt;p&gt;The authors say these are clear signs of mass consumption, with practically no other organism in the bunker capable of making these marks.&lt;/p&gt;
    &lt;p&gt;"The survival and growth of the bunker 'colony' through the years, without producing own offspring, was possible owing to continuous supply of new workers from the upper nest and accumulation of nestmate corpses," the researchers concluded in their study.&lt;/p&gt;
    &lt;p&gt;"The corpses served as an inexhaustible source of food which substantially allowed survival of the ants trapped down in otherwise extremely unfavourable conditions."&lt;/p&gt;
    &lt;p&gt;It seems that wood ants can handle remarkable adversity in their bid for survival. Although luckily for this colony, they no longer have to turn on their own: In 2016, researchers installed a wooden boardwalk (below) in the bunker, connecting the ventilation pipe to the ground. Within four months, nearly all the trapped ants had deserted the bunker floor.&lt;/p&gt;
    &lt;p&gt;Now, when any ants are unfortunate enough to fall into the dark chamber, they don't have to resort to cannibalism. They can just calmly walk the plank, all the way home.&lt;/p&gt;
    &lt;p&gt;The research was published in the Journal of Hymenoptera Research.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45465091</guid><pubDate>Fri, 03 Oct 2025 17:01:27 +0000</pubDate></item><item><title>Email was the user interface for the first AI recommendation engines</title><link>https://buttondown.com/blog/ringo-email-as-an-ai-interface</link><description>&lt;doc fingerprint="a69329413b20cfa9"&gt;
  &lt;main&gt;
    &lt;p&gt;Spinning the radio dials like mini roulette wheels was, in 1993, the best way to discover new music. Static, a snatch of a familiar song, a news report, then ah wait that sounds interesting. You’d walk into a record store with that song stuck in your head, and with any luck would walk out after a conversation with the clerk a few tapes richer, a few dozen dollars poorer.&lt;/p&gt;
    &lt;p&gt;One year later, everything had changed. For in 1994, the best way to discover new music was to email an AI.&lt;/p&gt;
    &lt;p&gt;“This sounds ****in’ moronic,” said one Dave Dell in response to the idea, convinced his love of Lustmord meant the AI couldn’t possibly match his tastes. Even he acquiesced: “I'll try it anyways.”&lt;/p&gt;
    &lt;p&gt;By the time The Cranberries released their hit single “Zombie” that September, over two thousand Daves had tried their luck, emailing Ringo with their favorite artists. To their surprise, they’d get a reply from what appeared to be early artificial intelligence, filled with recommendations of new music they’d love. Enough that, seven years later, science fiction writer Cory Doctorow would reminisce that “half the music in my collection came out of Ringo,” that nascent music AI.&lt;/p&gt;
    &lt;p&gt;Yet incredibly, Ringo was little more than those couple thousand users’ recommendations, averaged and redistributed via email. An email that users would quickly come to think of as a human, a friend, one in a quick succession of email-powered crowdsourced recommendation AIs.&lt;/p&gt;
    &lt;p&gt;It all started with what MIT assistant professor Paul Resnick called “A deceptively simple idea,” in 1994.&lt;/p&gt;
    &lt;p&gt;“People who agreed in the past are likely to agree again,” he postulated, an idea that’d been christened Social Filtering by MIT Thomas Malone seven years earlier. If you and another person both like the same song, or book, or author, there’s a pretty good chance that if one of you likes a new artist, the other will like it as well. The more overlapping agreements you have, the better one’s tastes should be predictive of another’s.&lt;/p&gt;
    &lt;p&gt;And, maybe, social filtering could be an organizing principle of the internet.&lt;/p&gt;
    &lt;p&gt;For as the nascent world wide web grew exponentially from a single website in 1991 and ten in 1992 to 623 sites in 1993 and over 10,000 by the end of 1994, the ancient prophecy that “knowledge shall increase” suddenly seemed more an omen of content overload than a portent of good things. Cataloguing and categorization could only go so far. It would be easy enough to find another Cranberries album once you knew you liked them. Finding the next new band that you’d love required something beyond lists. What good was infinite knowledge and limitless content without a way to discover it?&lt;/p&gt;
    &lt;p&gt;“The exploding volume of digital information makes it difficult for the user, equipped with only search capability, to keep up with the fast pace of information generation,” wrote Stanford’s Tak W. Yan and Hector Garcia-Molina, in their stab at solving the same problem. “There is a need for technology to help us wade through all the information to find the items we really want and need, and to rid us of the things we do not want to be bothered with,” as MIT Media Lab’s Upendra Shardanand summarized the issue.&lt;/p&gt;
    &lt;p&gt;Maybe the best option would be to ask someone else. We like getting recommendations from others, after all. “Choice under uncertainty is an opportunity to benefit from other more knowledgeable people,” wrote a Bellcore research team of their stab at the same problem in 1993.&lt;/p&gt;
    &lt;p&gt;Social filtering, teams from Xerox and Bell, Stanford and MIT alike agreed, seemed the perfect discovery mechanism of the future. That is, if they could gather everyone’s preferences and turn them into predictions accurately.&lt;/p&gt;
    &lt;p&gt;The idea behind Tapestry’s social filtering&lt;/p&gt;
    &lt;p&gt;Decades before the explosion of email newsletters, newsgroups were filling up early inboxes at a time when hard drives cost as much as $4,000 per gigabyte. Storage wasn’t the only scarce resource; no one had time to read every rant and reply in their inboxes.&lt;/p&gt;
    &lt;p&gt;Automatic filters were too restrictive—and they weren’t intelligent. Intelligence was when a friend read a message that hit the spot, and forwarded it on to you. It was when a colleague deleted a message, a silent vote that others might also deem that message irrelevant, or when they saved or replied to was a message in a vote towards its relevance.&lt;/p&gt;
    &lt;p&gt;Therein lay an idea: “More effective filtering can be done by involving humans in the filtering process,” postulated David Goldberg, David Nichols, Brian Oki, and Douglas Terry of the Xerox PARC team. That, in 1992, was the insight behind Tapestry, a short-lived collaborative email app inside Xerox PARC.&lt;/p&gt;
    &lt;p&gt;Tapestry sorted newsgroup emails with ratings. When you read an email or other document that you liked, you’d add an endorsement that Tapestry would store in a database alongside others’ endorsements. The next time someone searched for a message or document, they’d first see the messages that had the most endorsements, or could filter by specific users’ endorsements to follow the likes of a particular tastemaker.&lt;/p&gt;
    &lt;p&gt;“Eager readers will read all the documents ... in order to get immediate access,” the team surmised, while “more casual readers will wait for the eager readers to annotate, and read documents based on their reviews.”&lt;/p&gt;
    &lt;p&gt;SIFT’s social filtering model&lt;/p&gt;
    &lt;p&gt;Tapestry, it seems, never left Xerox’ bounds. But two years later, in February 1994, a Stanford team took up the mantle with SIFT, or Stanford Information Filtering Tool. It, too, sorted through messages based on crowdsourced wisdom. But it didn’t require a new app. SIFT, instead, was built around email.&lt;/p&gt;
    &lt;p&gt;“Email communications is the lowest common denominator of network connectivity,” wrote the team. “By having an email interface, a SIFT server is accessible from users with less powerful machines, with limited network capability, or behind Internet-access firewalls,” features that, to this day, make email one of the most universally accessible bits of the internet, even behind corporate firewalls and government censorships.&lt;/p&gt;
    &lt;p&gt;A SIFT email preview in an early browser&lt;/p&gt;
    &lt;p&gt;SIFT put email front and center. You’d sign up with an early web form and choose a topic of interest, like “underwater archeology.” SIFT would then regularly email you a list of articles and their first few lines to see what piqued your interest—an early curated email newsletter of top headlines. You’d then reply again with the articles you wanted to read, and SIFT would both email you the full messages, and store your choices as votes to help it refine what it’d recommend next time.&lt;/p&gt;
    &lt;p&gt;SIFT had some hits and some misses, and users were surprisingly accepting when things went wrong. “Well, nothing is perfect,” surmised Jiří Peterka in an early review. But SIFT clearly hit a nerve. “Within ten days of the announcement, we received well over a thousand profiles,” reported the team. By November, ten months after launch, SIFT was matching 45,000 articles each week to over 13,000 subscribers’ profiles.&lt;/p&gt;
    &lt;p&gt;Meanwhile, on opposite coasts, a Bell team was pondering decision paralysis. “Future users of the national information infrastructure will be overwhelmed with choices,” wrote Bellcore researchers Will Hill, Larry Stead, Mark Rosenstein and George Furnas in their 1995 writeup of the project. The best way out was to ask an expert, they decided. “When making a choice in the absence of decisive first-hand knowledge, choosing as other like-minded, similarly-situated people have successfully chosen in the past is a good strategy.”&lt;/p&gt;
    &lt;p&gt;So a team from the same Bell roots as UNIX and C++ and the transistor itself decided to harness social filtering to help you figure out which movie to rent from Blockbuster.&lt;/p&gt;
    &lt;p&gt;Movies lent themselves well to the model. There were a limited number of movies to sort and recommend, and existing expert ratings from the likes of Roger Ebert to pre-seed the database. If people would share their favorite movies, the system could match them with others who liked the same movies, and recommend other movies those people liked.&lt;/p&gt;
    &lt;p&gt;And it all ran over email.&lt;/p&gt;
    &lt;p&gt;An example videos@bellcore.com email&lt;/p&gt;
    &lt;p&gt;“The Internet email interface is currently a subject-line command interface,” the team wrote. For a few short months, from October 1993 to May 1994, you could email the subject “ratings” to videos@bellcore.com, and receive a reply with an overwhelming 500 movies.&lt;/p&gt;
    &lt;p&gt;Reply with your reviews of the movies you’d watched on a 1 to 10 scale, and Bellcore’s server would parse your reply and add your ratings to a database. Then, it’d look for “correlations between the new user's ratings and ratings from a random subsample of known users,” then “evaluate every unseen movie, sort them by highest prediction and skim off the top to recommend.”&lt;/p&gt;
    &lt;p&gt;Minutes later, you’d get back a reply, recommending you watch Alien and Blade Runner, say, along with a list of people who shared your tastes. It was a recommendation engine and nascent social network in one, where you just might find your next favorite movie and make a friend.&lt;/p&gt;
    &lt;p&gt;“Virtual communities may also sprout up around other domains such as music, books and catalog products,” predicted the team.&lt;/p&gt;
    &lt;p&gt;It didn’t take long. Two months after videos@bellcore.com shut down, a new MIT project launched: Ringo. “Our system, in our opinion, tackled the much more difficult problem domain of music,” wrote co-founder Upendra Shardanand in his master’s thesis.&lt;/p&gt;
    &lt;p&gt;The ingredients were in place. Social filtering had been proven out by Tapestry and SIFT. “The user interface for videos@bellcore.com system was used as a reference when designing the e-mail interface for Ringo,” said Shardanand. Along with that, Ringo added email-based accounts to learn from your preferences over time, and a constrained Pearson Correlation algorithm to rate “commonality between two users when computing the weights ... proportional to the number of artists both users have rated in common.”&lt;/p&gt;
    &lt;p&gt;That, and a personality. Ringo’s original emails were written as if they came from a person, such as “I recommend that you check out these artists...” It got toned down over time, partly to ensure people sent clear, precise instructions that Ringo could understand instead of fluent, natural language—but it quickly became clear that people thought of Ringo as a friend.&lt;/p&gt;
    &lt;p&gt;You’d email Ringo to sign up, and it’d reply with a more manageable list of 125 artists that you’d rate from 1 (“Pass the earplugs,” in Ringo’s description of its lowest rating) to 7 (“BOOM! One of my FAVORITE few!”). Ringo would then match your favorites to others with similar tastes, and reply with the eight artists it thought you’d like most.&lt;/p&gt;
    &lt;p&gt;The first email promoting Ringo, on a USENET group&lt;/p&gt;
    &lt;p&gt;On July 1, 1994—four years and 11 months before Napster’s launch—Ringo opened its inbox to the world. Shardanand marketed it on USENET groups. “The more users that use Ringo, the better Ringo's predictions,” he wrote, “so tell a friend.” Soon enough, Ringo was spreading by word-of-mouth in early email newsletters and other Usenet groups.&lt;/p&gt;
    &lt;p&gt;It worked—but it wasn’t always right. “In the first couple weeks of Ringo’s life, Ringo was relatively incompetent,” Shardanand recalled, and yet that, somehow, didn’t dampen people’s enthusiasm for the email bot they quickly came to love.&lt;/p&gt;
    &lt;p&gt;Example Ringo artist suggestions&lt;/p&gt;
    &lt;p&gt;“People would see the suggestions, and say things like ‘That one’s about right, that’s right, well that one I’d probably rate lower, but wow, it’s working,’” he recalled. “I watched them score artists, then I saw the poor suggestions, and was thinking, ‘You’ve got to be kidding.’ It’s as if they expected it [to] work, and therefore it did.”&lt;/p&gt;
    &lt;p&gt;Even when it came back with no recommendations, people were impressed. “It said there weren't enough participants out there like me,” Pat Anders recalled months after Ringo’s launch. “I was flattered.”&lt;/p&gt;
    &lt;p&gt;Others, though, found magic in the recommendations. “RINGO always came up with a great selection,” said Joe Morris. “I got turned on to a bunch of stuff I would of never found otherwise.” As did Cory Doctorow, with a music library still years later influenced by Ringo’s recommendations.&lt;/p&gt;
    &lt;p&gt;For it wasn’t simple recommendations over email. It was trust in a system that seemed greater than the sum of its parts. “A fellow Media Labber commented that possibly it is because people see Ringo’s suggestions as a ‘reflection of themselves,’” said Shardanand. “Once you have decided that there must be a logical connection between what you have told the system about your tastes and the system’s recommendations, then you are much more inclined to believe the predictions to be right.”&lt;/p&gt;
    &lt;p&gt;“I am largely of the opinion that great AI consists of aggregated human decisions, not machine generated decisions,” said Cory Doctorow, reminiscing about Ringo’s music recommendations.&lt;/p&gt;
    &lt;p&gt;For in every take on email-powered social filtering, the secret ingredient wasn’t the interface, nor was it the algorithm. It was in the crowdsourced data, and the system’s ability to match you with others of similar taste.&lt;/p&gt;
    &lt;p&gt;Some folks defied classification, felt that AI recommendations would devalue their unique tastes. Others embraced the crowdsourced models, found comfort in peeking in an AI-filtered mirror.&lt;/p&gt;
    &lt;p&gt;An early web form to sign up for Ringo&lt;/p&gt;
    &lt;p&gt;The services themselves faded with time. SIFT grew into a commercial project that sold ads for early newsletters, while the Stanford Library Project itself later provided the primary funding for Larry Page and Sergey Brin as they developed the ideas behind PageRank that turned into Google search (itself another way to harness the wisdom of the crowds).&lt;/p&gt;
    &lt;p&gt;Ringo later launched on the web first as HOMR (Helpful Online Music Service) then as Firefly (a community website for collaborative filtering that, fun fact, pitched RSS-competitor ICE to Microsoft), and won second place in MIT’s 1995 student business competition. The magic faded as it left email behind, though, and when Microsoft acquired it for $40 million in 1998, the only thing the software giant kept was their email-based login that, over time, morphed into Microsoft Passport.&lt;/p&gt;
    &lt;p&gt;31 years after those early crowdsourced email tools provided people’s first interactions with AI, today’s GPTs are eerily reminiscent of both those early app’s crowdsourced wisdom, and of our credulity to seemingly intelligent agents that mirror our preferences. The social filtering lives on, in ever less personal ways, in Google’s PageRank, Facebook’s feed algorithm, Netflix’s suggestions, and Spotify’s Daily Mix playlists.&lt;/p&gt;
    &lt;p&gt;And, in a roundabout way, email newsletters’ staying power may be due to the same selection bias and sorting powers that inspired social filtering-powered software. If you read something you like, there’s a fair chance you’ll continue to like the other things that person writes. Newsletters are the easiest way to select into that author’s filter bubble and find new things you like from their recommendations.&lt;/p&gt;
    &lt;p&gt;“As the information barrage continues to accelerate, agents will be as indispensable as E-mail,” predicted Ringo’s Shardanand in a foreshadowing of today’s AI and MCP servers and agents. People, it turned out though, were what was indispensable to email and recommendations you’d love.&lt;/p&gt;
    &lt;p&gt;Image Credits: Header image by Samuel Regan-Asante via Unsplash.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45465392</guid><pubDate>Fri, 03 Oct 2025 17:27:02 +0000</pubDate></item><item><title>Apple removes ICEBlock, won't allow apps that report locations of ICE agents</title><link>https://arstechnica.com/tech-policy/2025/10/apple-bends-to-trump-admin-demand-to-remove-ice-tracking-apps-like-iceblock/</link><description>&lt;doc fingerprint="f5c0188f0b7f101d"&gt;
  &lt;main&gt;
    &lt;p&gt;Acting on a demand from the Trump administration, Apple has removed apps that let iPhone users report the locations of Immigration and Customs Enforcement (ICE) officers.&lt;/p&gt;
    &lt;p&gt;"We reached out to Apple today demanding they remove the ICEBlock app from their App Store—and Apple did so," Attorney General Pam Bondi said in a statement to Fox News yesterday. "ICEBlock is designed to put ICE agents at risk just for doing their jobs, and violence against law enforcement is an intolerable red line that cannot be crossed."&lt;/p&gt;
    &lt;p&gt;Apple confirmed it removed multiple apps after hearing from law enforcement. "We created the App Store to be a safe and trusted place to discover apps," an Apple statement to news organizations said. "Based on information we've received from law enforcement about the safety risks associated with ICEBlock, we have removed it and similar apps from the App Store."&lt;/p&gt;
    &lt;p&gt;The app removals follow a September 24 shooting at a Dallas ICE facility that resulted in the deaths of two immigrants in federal custody and the shooter. The shooter, identified as Joshua Jahn, "searched apps that tracked the presence of ICE agents," according to FBI Director Kash Patel.&lt;/p&gt;
    &lt;p&gt;ICEBlock creator Joshua Aaron disputed claims that his app could have contributed to the shooting. He pointed out that an app isn't needed to find the locations of ICE facilities.&lt;/p&gt;
    &lt;p&gt;"You don't need to use an app to tell you where an ICE agent is when you're aiming at an ICE detention facility," Aaron told the BBC. "Everybody knows that's where ICE agents are."&lt;/p&gt;
    &lt;head rend="h2"&gt;Apple cited “objectionable content”&lt;/head&gt;
    &lt;p&gt;Aaron said he was disappointed by Apple's decision to remove the app. "ICEBlock is no different from crowd-sourcing speed traps, which every notable mapping application including Apple's own Maps app [does]," he was quoted as saying. "This is protected speech under the First Amendment of the United States Constitution."&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45465803</guid><pubDate>Fri, 03 Oct 2025 18:00:02 +0000</pubDate></item></channel></rss>