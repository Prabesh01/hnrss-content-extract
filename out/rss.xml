<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sun, 26 Oct 2025 23:33:04 +0000</lastBuildDate><item><title>Pico-Banana-400k</title><link>https://github.com/apple/pico-banana-400k</link><description>&lt;doc fingerprint="19072a4816fa0fc8"&gt;
  &lt;main&gt;
    &lt;p&gt;Pico-Banana-400K is a large-scale dataset of ~400K text–image–edit triplets designed to advance research in text-guided image editing.&lt;lb/&gt; Each example contains:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;an original image (from Open Images),&lt;/item&gt;
      &lt;item&gt;a human-like edit instruction, and&lt;/item&gt;
      &lt;item&gt;the edited result generated by Nano-Banana and verified by Gemini-2.5-Pro.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The dataset spans 35 edit operations across 8 semantic categories, covering diverse transformations—from low-level color adjustments to high-level object, scene, and stylistic edits.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Feature&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Total Samples&lt;/cell&gt;
        &lt;cell&gt;~257K single-turn text–image–edit triplets for SFT, ~56K single-turn text-image(positive) - image(negative)-edit for preference learning, and ~72K multi-turn texts-images-edits for multi-turn applications&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Source&lt;/cell&gt;
        &lt;cell&gt;Open Images&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Edit Operations&lt;/cell&gt;
        &lt;cell&gt;35 across 8 semantic categories&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Categories&lt;/cell&gt;
        &lt;cell&gt;Pixel &amp;amp; Photometric, Object-Level, Scene Composition, Stylistic, Text &amp;amp; Symbol, Human-Centric, Scale &amp;amp; Perspective, Spatial/Layout&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Image Resolution&lt;/cell&gt;
        &lt;cell&gt;512–1024 px&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Prompt Generator&lt;/cell&gt;
        &lt;cell&gt;Gemini-2.5-Flash&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Editing Model&lt;/cell&gt;
        &lt;cell&gt;Nano-Banana&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Self-Evaluation&lt;/cell&gt;
        &lt;cell&gt;Automated judging pipeline using Gemini-2.5-Pro for edit quality&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Pico-Banana-400K is built using a two-stage multimodal generation pipeline:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Instruction Generation&lt;lb/&gt;Each Open Images sample is passed to Gemini-2.5-Flash, which writes concise, natural-language editing instructions grounded in visible content. We also provide short instructions summarized by Qwen-2.5-Instruct-7B. Example:&lt;quote&gt;{ "instruction": "Change the red car to blue." }&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Editing + Self-Evaluation The Nano-Banana model performs the edit, then automatically evaluates the result using a structured quality prompt that measures: Instruction Compliance (40%) Editing Realism (25%) Preservation Balance (20%) Technical Quality (15%) Only edits scoring above a strict threshold (~0.7) are labeled as successful, forming the main dataset; the remaining ~56K are retained as failure cases for robustness and preference learning.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Nano-Banana-400K contains ~400K image editing data, covering a wide visual and semantic range drawn from real-world imagery.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Category&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Percentage&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Object-Level Semantic&lt;/cell&gt;
        &lt;cell&gt;Add, remove, replace, or relocate objects&lt;/cell&gt;
        &lt;cell&gt;35%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Scene Composition &amp;amp; Multi-Subject&lt;/cell&gt;
        &lt;cell&gt;Contextual and environmental transformations&lt;/cell&gt;
        &lt;cell&gt;20%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Human-Centric&lt;/cell&gt;
        &lt;cell&gt;Edits involving clothing, expression, or appearance&lt;/cell&gt;
        &lt;cell&gt;18%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Stylistic&lt;/cell&gt;
        &lt;cell&gt;Domain and artistic style transfer&lt;/cell&gt;
        &lt;cell&gt;10%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Text &amp;amp; Symbol&lt;/cell&gt;
        &lt;cell&gt;Edits involving visible text, signs, or symbols&lt;/cell&gt;
        &lt;cell&gt;8%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Pixel &amp;amp; Photometric&lt;/cell&gt;
        &lt;cell&gt;Brightness, contrast, and tonal adjustments&lt;/cell&gt;
        &lt;cell&gt;5%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Scale &amp;amp; Perspective&lt;/cell&gt;
        &lt;cell&gt;Zoom, viewpoint, or framing changes&lt;/cell&gt;
        &lt;cell&gt;2%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Spatial / Layout&lt;/cell&gt;
        &lt;cell&gt;Outpainting, composition, or canvas extension&lt;/cell&gt;
        &lt;cell&gt;2%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Single-Turn SFT samples (successful edits): ~257K&lt;/item&gt;
      &lt;item&gt;Single-Turn Preference samples (failure cases): ~56K&lt;/item&gt;
      &lt;item&gt;Multi-Turn SFT samples (successful cases): ~72K&lt;/item&gt;
      &lt;item&gt;Gemini-generated instructions: concise, natural, and image-aware&lt;/item&gt;
      &lt;item&gt;Edit coverage: 35 edit types across 8 semantic categories&lt;/item&gt;
      &lt;item&gt;Image diversity: includes humans, objects, text-rich scenes, etc from Open Images&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Below are representative examples from different categories:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Category&lt;/cell&gt;
        &lt;cell role="head"&gt;Example&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Object-Level&lt;/cell&gt;
        &lt;cell&gt;“Replace the red apple with a green one.”&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Scene Composition&lt;/cell&gt;
        &lt;cell&gt;“Add sunlight streaming through the window.”&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Human-Centric&lt;/cell&gt;
        &lt;cell&gt;“Change the person’s expression to smiling.”&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Text &amp;amp; Symbol&lt;/cell&gt;
        &lt;cell&gt;“Uppercase the text on the billboard.”&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Stylistic&lt;/cell&gt;
        &lt;cell&gt;“Convert the image to a Van Gogh painting style.”&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Pico-Banana-400K provides both breadth (diverse edit operations) and depth (quality-controlled multimodal supervision), making it a strong foundation for training and evaluating text-guided image editing models.&lt;/p&gt;
    &lt;p&gt;Pico-Banana-400K serves as a versatile resource for advancing controllable and instruction-aware image editing.&lt;lb/&gt; Beyond single-step editing, the dataset enables multi-turn, conversational editing and reward-based training paradigms.&lt;/p&gt;
    &lt;p&gt;The Pico-Banana-400K dataset is hosted on Apple’s public CDN.&lt;lb/&gt; You can download each component (single-turn, multi-turn, and preference data) using the provided manifest files.&lt;/p&gt;
    &lt;p&gt;Manifest files: sft link and preference link&lt;/p&gt;
    &lt;p&gt;Manifest file: multi-turn link&lt;/p&gt;
    &lt;p&gt;Urls to download source images are provided along with edit instructions in sft link, preference link, and multi-turn link. If you hit rate limit with Flickr when downloading images, you can either request higher rate limit with Flickr or follow steps below.&lt;/p&gt;
    &lt;p&gt;Another way to download the source images is to download packed files train_0.tar.gz and train_1.tar.gz from Open Images, then map with the urls we provide. We also provide a sample mapping code here. Due to legal requirements, we cannot provide the source image files directly.&lt;/p&gt;
    &lt;code&gt;# Install awscli if you don't have it (https://aws.amazon.com/cli/)
# Download Open Images packed files 
aws s3 --no-sign-request --endpoint-url https://s3.amazonaws.com cp s3://open-images-dataset/tar/train_0.tar.gz . 
aws s3 --no-sign-request --endpoint-url https://s3.amazonaws.com cp s3://open-images-dataset/tar/train_1.tar.gz . 

# Create folder for extracted images 
mkdir openimage_source_images

# Extract the tar files 
tar -xvzf train_0.tar.gz -C openimage_source_images
tar -xvzf train_1.tar.gz -C openimage_source_images

# Download metadata CSV (ImageID ↔ OriginalURL mapping)  
wget https://storage.googleapis.com/openimages/2018_04/train/train-images-boxable-with-rotation.csv

# Map urls to local paths
python map_openimage_url_to_local.py #please modify variable is_multi_turn and file paths as needed&lt;/code&gt;
    &lt;p&gt;Pico-Banana-400K is released under the Creative Commons Attribution–NonCommercial–NoDerivatives (CC BY-NC-ND 4.0) license. ✅ Free for research and non-commercial use ❌ Commercial use and derivative redistribution are not permitted 🖼️ Source images follow the Open Images (CC BY 2.0) license By using this dataset, you agree to comply with the terms of both licenses.&lt;/p&gt;
    &lt;p&gt;If you use 🍌 Pico-Banana-400K in your research, please cite it as follows:&lt;/p&gt;
    &lt;code&gt;@misc{qian2025picobanana400klargescaledatasettextguided,
      title={Pico-Banana-400K: A Large-Scale Dataset for Text-Guided Image Editing}, 
      author={Yusu Qian and Eli Bocek-Rivele and Liangchen Song and Jialing Tong and Yinfei Yang and Jiasen Lu and Wenze Hu and Zhe Gan},
      year={2025},
      eprint={2510.19808},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2510.19808}, 
}

&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45708524</guid><pubDate>Sun, 26 Oct 2025 02:01:17 +0000</pubDate></item><item><title>Writing a RISC-V Emulator in Rust</title><link>https://book.rvemu.app/</link><description>&lt;doc fingerprint="b3e453454f1ba464"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Writing a RISC-V Emulator in Rust&lt;/head&gt;
    &lt;p&gt;NOTE: This project is actively ongoing. Pages are not perfect yet and it possible to change dramatically.&lt;/p&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;This is the book for writing a 64-bit RISC-V emulator from scratch in Rust. You can run xv6, a simple Unix-like OS, in your emulator once you finish the book.&lt;/p&gt;
    &lt;p&gt;You'll learn the basic computer architecture such as ISA, previleged architecture, exceptions, interrupts, peripheral devices, and virtual memory system from making an emulator.&lt;/p&gt;
    &lt;p&gt;The source code used in this book is available at d0iasm/rvemu-for-book.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 1&lt;/head&gt;
    &lt;p&gt;Chapter 1 shows all hardward components we need to implement for running &lt;code&gt;xv6&lt;/code&gt;.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;CPU with Two Instructions&lt;/item&gt;
      &lt;item&gt;Memory and System Bus&lt;/item&gt;
      &lt;item&gt;Control and Status Registers&lt;/item&gt;
      &lt;item&gt;Privileged Architecture&lt;/item&gt;
      &lt;item&gt;Exceptions&lt;/item&gt;
      &lt;item&gt;PLIC (a platform-level interrupt controller) and CLINT (a core-local interrupter)&lt;/item&gt;
      &lt;item&gt;UART (a universal asynchronous receiver-transmitter)&lt;/item&gt;
      &lt;item&gt;Interrupts&lt;/item&gt;
      &lt;item&gt;Virtio&lt;/item&gt;
      &lt;item&gt;Virtual Memory System&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Chapter 2&lt;/head&gt;
    &lt;p&gt;Chapter 2 shows all ISAs we need to implement for running &lt;code&gt;xv6&lt;/code&gt;.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;RV64I Base Integer Instruction Set&lt;/item&gt;
      &lt;item&gt;"M" Standard Extension for Integer Multiplication and Division&lt;/item&gt;
      &lt;item&gt;"A" Standard Extension for AtomicInstructions&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Outcome&lt;/head&gt;
    &lt;p&gt;Once you read this book and implement the emulator, you will be able to run xv6 in your emulator!&lt;/p&gt;
    &lt;head rend="h2"&gt;Contact&lt;/head&gt;
    &lt;p&gt;The author is @d0iasm and please feel free to ask and request anything to me via Twitter or GitHub issues!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45709819</guid><pubDate>Sun, 26 Oct 2025 07:34:30 +0000</pubDate></item><item><title>Clojure Land – Discover open-source Clojure libraries and frameworks</title><link>https://clojure.land/</link><description>&lt;doc fingerprint="2302039003d1cf0"&gt;
  &lt;main&gt;
    &lt;list id="project-list" class="grid grid-cols-6 gap-2 divide-y divide-gray-100" rend="ul"&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;Behavioral Programming for Clojure&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;Editor Code Assistant (ECA) - AI pair programming capabilities agnostic of editor&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;Editor Code Assistant (ECA) integration for Emacs&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;Java2D wrapper + creative coding supporting functions (based on Processing and openFrameworks)&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;Making VS Code Hackable like Emacs since 2022&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;A data-driven rendering library for Clojure(Script) that renders hiccup to DOM or to strings.&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;Clojure library for building OpenAPI services&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;An optional type system for Clojure&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;A better "prn" for debugging&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;Managed lifecycle of stateful objects in Clojure&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;VS Code AI Agent Interactive Programming. Tools for CoPIlot and other assistants. Can also be used as an MCP server.&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;A functional quantum computer programming library for Clojure with backend protocols, simulation backends and visualizations.&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;Expose Lacinia GraphQL as Pedestal endpoints&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;Clojure reducers, but for parallel execution: locally and on distributed systems.&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;Editor Code Assistant (ECA) integration for Vscode&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;An open source tool set for building web applications in Clojure&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;JSON parser/generator to/from Clojure data structures&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;User aliases and Clojure CLI configuration for deps.edn based projects&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2" hx-get="/" hx-target="#project-list" hx-select="#project-list li" hx-swap="beforeend" hx-include="inherit" hx-vals="{&amp;quot;page&amp;quot;:2}" hx-trigger="revealed"&gt;
        &lt;div&gt;
          &lt;div&gt;Weave loom fibers into your Clojure&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
      &lt;item class="relative flex justify-between gap-x-6 py-4 col-span-6 md:col-span-4 mx-6 md:mx-2 md:col-start-2"&gt;
        &lt;div&gt;
          &lt;div&gt;Multi-pass compiler and runtime for probabilistic programming.&lt;/div&gt;
        &lt;/div&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45709988</guid><pubDate>Sun, 26 Oct 2025 08:15:48 +0000</pubDate></item><item><title>Advent of Code 2025: Number of puzzles reduce from 25 to 12 for the first time</title><link>https://adventofcode.com/2025/about#faq_num_days</link><description>&lt;doc fingerprint="9ad8fbdb2d32aff8"&gt;
  &lt;main&gt;&lt;p&gt;Hi! I'm Eric Wastl. I make Advent of Code. I hope you like it! I also make lots of other things. I'm on Bluesky, Mastodon, and GitHub.&lt;/p&gt;&lt;p&gt;Advent of Code is an Advent calendar of small programming puzzles for a variety of skill levels that can be solved in any programming language you like. People use them as interview prep, company training, university coursework, practice problems, a speed contest, or to challenge each other.&lt;/p&gt;&lt;p&gt;You don't need a computer science background to participate - just a little programming knowledge and some problem solving skills will get you pretty far. Nor do you need a fancy computer; every problem has a solution that completes in at most 15 seconds on ten-year-old hardware.&lt;/p&gt;&lt;p&gt;If you'd like to support Advent of Code, you can do so indirectly by helping to AoC++.&lt;/p&gt;it with others or directly via&lt;head rend="h2"&gt;--- General Tips ---&lt;/head&gt;&lt;p&gt;If you get stuck, try your solution against the examples given in the puzzle; you should get the same answers. If not, re-read the description. Did you misunderstand something? Is your program doing something you don't expect? After the examples work, if your answer still isn't correct, build some test cases for which you can verify the answer by hand and see if those work with your program. Make sure you have the entire puzzle input. If you're still stuck, maybe ask a friend for help, or come back to the puzzle later. You can also ask for hints in the subreddit.&lt;/p&gt;&lt;head rend="h2"&gt;--- Frequently Asked Questions ---&lt;/head&gt;&lt;p&gt;Is there an easy way to select entire code blocks? You should be able to triple-click code blocks to select them. You'll need JavaScript enabled.&lt;/p&gt;&lt;code&gt;#!/usr/bin/env perl
use warnings;
use strict;

print "You can test it out by ";
print "triple-clicking this code.\n";
&lt;/code&gt;&lt;p&gt;How does authentication work? Advent of Code uses OAuth to confirm your identity through other services. When you log in, you only ever give your credentials to that service - never to Advent of Code. Then, the service you use tells the Advent of Code servers that you're really you. In general, this reveals no information about you beyond what is already public; here are examples from Reddit and GitHub. Advent of Code will remember your unique ID, names, URL, and image from the service you use to authenticate.&lt;/p&gt;&lt;p&gt;Why was this puzzle so easy / hard? The difficulty and subject matter varies throughout each event. Very generally, the puzzles get more difficult over time, but your specific skillset will make each puzzle significantly easier or harder for you than someone else. Making puzzles is tricky.&lt;/p&gt;&lt;p&gt;Why do the puzzles unlock at midnight EST/UTC-5? Because that's when I can consistently be available to make sure everything is working. I also have a family, a day job, and even need sleep occasionally. If you can't participate at midnight, that's not a problem; if you want to race, many people use private leaderboards to compete with people in their area.&lt;/p&gt;&lt;p&gt;I find the text on the site hard to read. Is there a high contrast mode? There is a high contrast alternate stylesheet. Firefox supports these by default (View -&amp;gt; Page Style -&amp;gt; High Contrast).&lt;/p&gt;&lt;p&gt;I have a puzzle idea! Can I send it to you? Please don't. Because of legal issues like copyright and attribution, I don't accept puzzle ideas, and I won't even read your email if it looks like one just in case I use parts of it by accident.&lt;/p&gt;&lt;p&gt;Did I find a bug with a puzzle? Once a puzzle has been out for even an hour, many people have already solved it; after that point, bugs are very unlikely. Start by asking on the subreddit.&lt;/p&gt;&lt;p&gt;Should I try to get a fast solution time? Maybe. Solving puzzles is hard enough on its own, but trying for a fast time also requires many additional skills and a lot of practice; speed-solves often look nothing like code that would pass a code review. If that sounds interesting, go for it! However, you should do Advent of Code in a way that is useful to you, and so it is completely fine to choose an approach that meets your goals and ignore speed entirely.&lt;/p&gt;&lt;p&gt;Why did the number of days per event change? It takes a ton of my free time every year to run Advent of Code, and building the puzzles accounts for the majority of that time. After keeping a consistent schedule for ten years(!), I needed a change. The puzzles still start on December 1st so that the day numbers make sense (Day 1 = Dec 1), and puzzles come out every day (ending mid-December).&lt;/p&gt;&lt;p&gt;What happened to the global leaderboard? The global leaderboard was one of the largest sources of stress for me, for the infrastructure, and for many users. People took things too seriously, going way outside the spirit of the contest; some people even resorted to things like DDoS attacks. Many people incorrectly concluded that they were somehow worse programmers because their own times didn't compare. What started as a fun feature in 2015 became an ever-growing problem, and so, after ten years of Advent of Code, I removed the global leaderboard. (However, I've made it so you can share a read-only view of your private leaderboard. Please don't use this feature or data to create a "new" global leaderboard.)&lt;/p&gt;&lt;p&gt;While trying to get a fast time on a private leaderboard, may I use AI / watch streamers / check the solution threads / ask a friend for help / etc? If you are a member of any private leaderboards, you should ask the people that run them what their expectations are of their members. If you don't agree with those expectations, you should find a new private leaderboard or start your own! Private leaderboards might have rules like maximum runtime, allowed programming language, what time you can first open the puzzle, what tools you can use, or whether you have to wear a silly hat while working.&lt;/p&gt;&lt;p&gt;Should I use AI to solve Advent of Code puzzles? No. If you send a friend to the gym on your behalf, would you expect to get stronger? Advent of Code puzzles are designed to be interesting for humans to solve - no consideration is made for whether AI can or cannot solve a puzzle. If you want practice prompting an AI, there are almost certainly better exercises elsewhere designed with that in mind.&lt;/p&gt;&lt;p&gt;Can I copy/redistribute part of Advent of Code? Please don't. Advent of Code is free to use, not free to copy. If you're posting a code repository somewhere, please don't include parts of Advent of Code like the puzzle text or your inputs. If you're making a website, please don't make it look like Advent of Code or name it something similar.&lt;/p&gt;&lt;head rend="h2"&gt;--- Credits ---&lt;/head&gt;&lt;p&gt;Puzzles, Code, &amp;amp; Design: Eric Wastl&lt;/p&gt;&lt;p&gt;Beta Testing:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Tim Giannetti&lt;/item&gt;&lt;item&gt;Ben Lucek&lt;/item&gt;&lt;item&gt;JP Burke&lt;/item&gt;&lt;item&gt;Aneurysm9&lt;/item&gt;&lt;item&gt;Andrew Skalski&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Community Managers: Danielle Lucek and Aneurysm9&lt;/p&gt;&lt;p&gt;Playing: You!&lt;/p&gt;&lt;head rend="h2"&gt;--- Legal ---&lt;/head&gt;&lt;p&gt;Advent of Code is a registered trademark in the United States. The design elements, language, styles, and concept of Advent of Code are all the sole property of Advent of Code and may not be replicated or used by any other person or entity without express written consent of Advent of Code. Copyright 2015-2025 Advent of Code. All rights reserved.&lt;/p&gt;&lt;p&gt;You may link to or reference puzzles from Advent of Code in discussions, classes, source code, printed material, etc., even in commercial contexts. Advent of Code does not claim ownership or copyright over your solution implementation.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45710006</guid><pubDate>Sun, 26 Oct 2025 08:19:48 +0000</pubDate></item><item><title>Connect to a 1980s Atari BBS through the web</title><link>https://www.southernamis.com/ataribbsconnect</link><description>&lt;doc fingerprint="8b6d9aee7de1037b"&gt;
  &lt;main&gt;
    &lt;p&gt;Restoration from the MACE 1986 Version of AMIS - Atari Message Information System. This Basic XE BBS shows off extensive Atascii Graphics&lt;/p&gt;
    &lt;p&gt;This is a United Federation of Pirates BBS back from the mid-late 1980s Part of a Very Elite Group of Atari Boards. Run by Sysop - Giarc The Warden&lt;/p&gt;
    &lt;p&gt;As the name provides, You are about to Enter Area 52. From Sysop Phigan This BBS Provides Plenty of Atascii Graphics&lt;/p&gt;
    &lt;p&gt;The Basement BBS running BBS Express Pro! With RealAtari BBS Look and Feel, themed to the movie Office Space, this BBS has tons of features and surprises!&lt;/p&gt;
    &lt;p&gt;NiteLite BBS 1984 Restored and put online as another representation of basic code and BBS history for Atari. NiteLite BBS was used as the Atari Corp BBS.&lt;/p&gt;
    &lt;p&gt;The Very First BBS Express Pro! Board from the man Keith Ledbetter himself. The Sysop BF2K+ took over the BBS and keeping history available to Atari BBSing die hards.&lt;/p&gt;
    &lt;p&gt;Carina II BBS Running 24/7 300/1200/9600 with 20 Mega Online, Sysop Jay C. Returned Carina to its Glory! Themed to Breaking Bad, This is a great BBS for Old Skool Games!&lt;/p&gt;
    &lt;p&gt;Restoration from the MACE 1986 Version of AMIS - Atari Message Information System. This Basic XE BBS shows off extensive Atascii Graphics&lt;/p&gt;
    &lt;p&gt;This is a United Federation of Pirates BBS back from the mid-late 1980s Part of a Very Elite Group of Atari Boards. Run by Sysop - Giarc The Warden&lt;/p&gt;
    &lt;p&gt;As the name provides, You are about to Enter Area 52. From Sysop Phigan This BBS Provides Plenty of Atascii Graphics&lt;/p&gt;
    &lt;p&gt;The BBS Express ST Legend! DarkForce BBS brings a very active and feature rich BBS experience. Sysop The DarkLord&lt;/p&gt;
    &lt;p&gt;The Basement BBS running BBS Express Pro! With RealAtari BBS Look and Feel, themed to the movie Office Space, this BBS has tons of features and surprises!&lt;/p&gt;
    &lt;p&gt;NiteLite BBS 1984 Restored and put online as another representation of basic code and BBS history for Atari. NiteLite BBS was used as the Atari Corp BBS.&lt;/p&gt;
    &lt;p&gt;The Very First BBS Express Pro! Board from the man Keith Ledbetter himself. The Sysop BF2K+ took over the BBS and keeping history available to Atari BBSing die hards.&lt;/p&gt;
    &lt;p&gt;Carina II BBS Running 24/7 300/1200/9600 with 20 Mega Online, Sysop Jay C. Returned Carina to its Glory! Themed to Breaking Bad, This is a great BBS for Old Skool Games!&lt;/p&gt;
    &lt;p&gt;Running on RatSoft SFHQ has a host of features, game library, and networked message bases. Sysop Commodore Clifford&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45710366</guid><pubDate>Sun, 26 Oct 2025 09:31:47 +0000</pubDate></item><item><title>You already have a Git server</title><link>https://maurycyz.com/misc/easy_git/</link><description>&lt;doc fingerprint="dcf8f5f9c827be83"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;You already have a git server:&lt;/head&gt;(Programming)&lt;p&gt;If you have a git repository on a server with ssh access, you can just clone it:&lt;/p&gt;&lt;code&gt;# This works. 
git clone ssh://username@hostname/path/to/repo
&lt;/code&gt;&lt;p&gt;You can then work on it locally and push your changes back to the origin server. By default, git won’t let you push to the branch that is currently checked out, but this is easy to change:&lt;/p&gt;&lt;code&gt;# Run this on the remote server. 
git config receive.denyCurrentBranch updateInstead
&lt;/code&gt;&lt;p&gt;This is a great way to sync code between multiple computers or to work on server-side files without laggy typing or manual copying. If you want to publish your code, just point your web server at the git repo:&lt;/p&gt;&lt;code&gt;git clone https://hostname/path/to/repo/.git
# You can get rid of the .git part of the command by either setting the
# server to remap it to a nicer URL or by just renaming the .git directory
# (although this stops you from running git server side)
&lt;/code&gt;&lt;p&gt;… although you will have to run this command server-side to make it cloneable:&lt;/p&gt;&lt;code&gt;# Create some files used by git-over-http:
# Should be repeated after making changes.
git update-server-info
&lt;/code&gt;&lt;p&gt;That’s a lot of work, so let’s set up a hook to do that automatically:&lt;/p&gt;&lt;code&gt;# Automatically run git update-server-info.
# Should be run server-side
cp .git/hooks/post-update.sample .git/hooks/post-update
chmod a+x .git/hooks/post-update
&lt;/code&gt;&lt;p&gt;Git hooks are just shell scripts, so they can do things like running a static site generator:&lt;/p&gt;&lt;code&gt;cat &amp;gt; .git/hooks/post-update &amp;lt;&amp;lt;EOF
#!/bin/sh
set -euo pipefail
cd /path/to/site
/path/to/generator
EOF
chmod a+x .git/hooks/post-update
&lt;/code&gt;&lt;p&gt;This is how I’ve been doing this blog for a while now: It’s very nice to be able to type up posts locally (no network lag), and then push them to the server and have the rest handled automatically.&lt;/p&gt;&lt;p&gt;It’s also backed up by default: If the server breaks, I’ve still got the copy on my laptop, and if my laptop breaks, I can download everything from the server. Git’s version tracking also prevents accidental deletions, and if something breaks, it’s easy to figure out what caused it.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45710721</guid><pubDate>Sun, 26 Oct 2025 10:53:37 +0000</pubDate></item><item><title>Formal Reasoning [pdf]</title><link>https://cs.ru.nl/~freek/courses/fr-2025/public/fr.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45711062</guid><pubDate>Sun, 26 Oct 2025 12:03:59 +0000</pubDate></item><item><title>Feed the bots</title><link>https://maurycyz.com/misc/the_cost_of_trash/</link><description>&lt;doc fingerprint="273b981161f213a7"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;You should feed the bots:&lt;/head&gt;(Programming)&lt;p&gt;A week ago, I set up an infinite nonsense crawler trap – now it makes up 99% of my server’s traffic. What surprised me is that feeding scrapers garbage is the cheapest and easiest thing I could do.&lt;/p&gt;&lt;head rend="h2"&gt;Meet the bots:&lt;/head&gt;&lt;p&gt;These aren’t the indexing bots of old, but scrapers collecting data to train LLMs. Unlike search engines, which need the websites they crawl to stay up, AI companies provide a replacement.&lt;/p&gt;&lt;p&gt;It should come as no surprise that these bots are aggressive and relentless: They ignore robots.txt, and if block them by user agent they just pretend to be a browser. If you ban their IP, they switch addresses.&lt;/p&gt;&lt;p&gt;… all while sending multiple requests per second, all day, every day.&lt;/p&gt;&lt;head rend="h2"&gt;Giving up:&lt;/head&gt;&lt;p&gt;So what if we let them access the site?&lt;/p&gt;&lt;p&gt;Serving static files is is relatively cheap, but not free. SSD access times are in the tens milliseconds, and that’s before you pay the filesystem tax. Bots also like to grab old and obscure pages, ones that are unlikely to be in cache. As a result, it doesn’t take all that many requests to bog down the server.&lt;/p&gt;&lt;p&gt;Then there’s the matter of bandwidth: Many blog posts also include images weighing hundreds to thousands of kB, which can add up quite quickly. With an average file size of 100 kB, 4 requests per second adds up to a terabyte each month – not a huge amount of data, but more then I’m willing to throw away.&lt;/p&gt;&lt;head rend="h2"&gt;The ban hammer:&lt;/head&gt;&lt;p&gt;Simply making a list of IPs and blocking them would for normal bots…&lt;/p&gt;&lt;p&gt;… but these are hardly normal bots. Because they are backed by billion dollar companies, they don’t just have a few addresses, but many thousands. If you managed to ban all of their addresses, they’ll just buy more.&lt;/p&gt;&lt;p&gt;Rate limits fail for the same reason: They just switch IPs. I’ve even seen them using new IP for each request.&lt;/p&gt;&lt;head rend="h2"&gt;Building a wall:&lt;/head&gt;&lt;p&gt;Ok, what about a pay-wall, login-wall, CAPTCHA-wall, or a hash based proof-of-work?&lt;/p&gt;&lt;p&gt;All of these inconvenience users. Requiring an account guaranties that no one will read what I wrote. Even just a simple JavaScript challenge will block anyone who’s browser doesn’t support JS … and when it works, anything that must load before the does content still hugely slows down page loads.&lt;/p&gt;&lt;head rend="h2"&gt;Throw them some bombs:&lt;/head&gt;&lt;p&gt;“Serve them few gzip bombs, that’ll teach them” — Half the internet.&lt;/p&gt;&lt;p&gt;Gzip only provides a compression ratio of a little over 1000: If I want a file that expands to 100 GB, I’ve got to serve a 100 MB asset. Worse, when I tried it, the bots just shrugged it off, with some even coming back for more.&lt;/p&gt;&lt;head rend="h2"&gt;Jedi mind tricks:&lt;/head&gt;&lt;p&gt;Ok, what if we just send them 404s – try and make them think my site doesn’t exist.&lt;/p&gt;&lt;p&gt;These tricks only work if your adversary has a mind to trick. If a link is posted somewhere, the bots will know it exists, and if they can’t access it, they’ll just become more aggressive:. sending more requests, with more user agents and using more addresses.&lt;/p&gt;&lt;p&gt;Keeping them happy keeps them tolerable.&lt;/p&gt;&lt;head rend="h2"&gt;Garbage:&lt;/head&gt;&lt;p&gt;But surely sending them dynamically generated content would be expensive right?&lt;/p&gt;&lt;p&gt;Well… no.&lt;/p&gt;&lt;p&gt;CPU and RAM are the fastest parts of a modern computer. Dynamic content has the reputation of being slow because it often involves a database (lots of disk IO), a million lines of JavaScript, or both.&lt;/p&gt;&lt;p&gt;My lightly optimized Markov babbler consumes around ~60 CPU microseconds per request. There’s no disk IO, and the memory cost is only around 1.2 MB. There’s also no rules or blacklists to maintain: the bots come to it and it consumes them.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45711094</guid><pubDate>Sun, 26 Oct 2025 12:09:02 +0000</pubDate></item><item><title>Resource use matters, but material footprints are a poor way to measure it</title><link>https://ourworldindata.org/material-footprint-limitations</link><description>&lt;doc fingerprint="734a01f119070ff6"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Resource use matters, but material footprints are a poor way to measure it&lt;/head&gt;
    &lt;head rend="h2"&gt;Adding up the weight of very different materials doesn’t tell us about their scarcity, environmental, or socioeconomic impacts.&lt;/head&gt;
    &lt;p&gt;What do a tonne of potatoes, gravel, coal, and copper have in common? Not much, except that they all weigh the same, and are treated exactly the same in a metric called the “material footprint”.&lt;/p&gt;
    &lt;p&gt;The material footprint sums up the weight of all the resources used within an economy. So if a country’s material footprint is 60 million tonnes, it extracts 60 million tonnes of “stuff” per year. This includes both non-renewable resources like metals and fossil fuels, and “renewable” ones like crops and wood. The scarcity or environmental impact of different resources is not considered, so every kilogram of stuff is considered just as important as every kilogram of something else.1&lt;/p&gt;
    &lt;p&gt;Some readers may not be familiar with this metric, but it has gained increasing popularity in environmental discussions and international policy. It’s included as a key metric in the United Nations’ Sustainable Development Goals, which is why we have charts on it in our SDG Tracker. This metric is tracked in per capita terms and is shown in the chart below.&lt;/p&gt;
    &lt;p&gt;It is also used in the planetary pressures index by the UN Development Programme, and you’ll find many reports on it by the OECD, European agencies, and others.2&lt;/p&gt;
    &lt;p&gt;However, for reasons I’ll explain in this article, I don’t find this metric helpful in understanding the sustainability of resource use or its environmental impacts. I fear that rather than helping us tackle some of our biggest environmental and resource challenges, it obscures our understanding and takes our focus away from the most pressing problems.&lt;/p&gt;
    &lt;head rend="h1"&gt;It’s not that resource use doesn’t matter — it’s that the material footprint fails to capture why&lt;/head&gt;
    &lt;p&gt;There are at least three reasons why we should be measuring and monitoring our resource use:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;To see if we risk running out of a particular resource. If we’ve depleted the world’s copper, cobalt, or lithium and are at risk of running out, then we need to know about it. But to assess this, we need to know how much of that specific material we’re using, and how much is left. We’d need to know how much copper, cobalt, or lithium we use each year and the state of our global reserves. To do that, we need to look at specific mineral datasets (which exist and are published by organizations such as the US Geological Survey or British Geological Survey). We have a lot of this data on Our World in Data. This is also true for “natural” ecosystems or populations we’re depleting. If we’re concerned about the depletion of Atlantic bluefin tuna, we must look at how much of that population or species we’re catching, how many are left, and how quickly populations regenerate. Our team also shows this data on fish catch and depletion for specific species. Looking at a metric that throws the weight of tuna together with wood, coal, and gravel does not help understand the scarcity of any of them.&lt;/item&gt;
      &lt;item&gt;To measure the environmental impact of extracting and consuming resources. Mining uses land, can disrupt landscapes, and cause pollution. Burning fossil fuels generates carbon emissions and air pollution. Beef production can drive deforestation and biodiversity loss. These impacts are extremely important to monitor (we cover most, if not all, of them here on Our World in Data). But material footprints don’t tell us much about the environmental impact. The production of a tonne of gravel does not have the same impact as a tonne of uranium or pork.&lt;/item&gt;
      &lt;item&gt;To measure the socioeconomic consequences of extracting and consuming resources. Mining can be associated with unsafe working practices, and some supply chains rely on exploitative labor. But, again, the material footprint does nothing to help us identify and improve these conditions. Cobalt and gold mining are associated with poor working conditions in countries like the Democratic Republic of Congo, but material footprints don’t tell us that. In fact, many of these precious minerals are extracted in relatively small quantities, so they barely show on a whole-economy material footprint. Some of the most documented exploitative practices have been in textile supply chains. In terms of material footprint, clothing has a very low “material intensity”, so judging by this metric, it would be deemed a more “responsible” way to spend your money.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Resource use does matter for these reasons, but the material footprint, at best, captures them poorly and, at worst, hides some of the most negative impacts.&lt;/p&gt;
    &lt;head rend="h1"&gt;Most of our material footprint comes from non-metallic minerals and biomass&lt;/head&gt;
    &lt;p&gt;The chart below shows the breakdown of the European Union's material footprint. More than 70% is made up of biomass (our food and wood for industry and construction) and non-metallic minerals for construction and infrastructure.&lt;/p&gt;
    &lt;p&gt;This should already raise some questions.&lt;/p&gt;
    &lt;quote&gt;A tonne of gravel does not have the same impact as a tonne of uranium or pork.&lt;/quote&gt;
    &lt;p&gt;Biomass is a renewable resource (if managed sustainably). I can grow and harvest potatoes, tomatoes, and wheat today and then replant them for next year. The “net” change in the biomass we produce is often zero over longer timescales; it’s not being depleted like other resources. To compare this in terms of weight to fossil fuels and other minerals, which are not renewable, mixes materials that are too different to be bundled together.&lt;/p&gt;
    &lt;p&gt;Non-metallic minerals, such as gravel — which dominate Europe’s footprint — do not have zero environmental impact. Mining for materials such as sand can disrupt ecosystems, disturb riverbeds, and affect natural flood defenses. However, they tend to have a much lower environmental impact than the other categories. As the European Environment Agency puts it:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Non-metallic minerals account for a large part of the total material footprint, yet they have less environmental and climate impact than metals and fossil fuels. This is because they are mostly composed of inert materials such as gravel, limestone.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;If we consider a large material footprint problematic, then it follows that we should focus on using less sand, gravel, wood, and limestone. However, this would achieve far less in addressing most of the resource constraints and environmental and social impacts that we care about than tackling other (smaller) categories like fossil fuels and particular metal ores.&lt;/p&gt;
    &lt;head rend="h1"&gt;Housing and food are the two sectors behind most of the EU’s material footprint&lt;/head&gt;
    &lt;p&gt;Since non-metallic minerals and biomass dominate the EU’s material footprint, we shouldn’t be surprised that housing and food have the biggest impact when we look at the footprint by the end-use sector.&lt;/p&gt;
    &lt;p&gt;The chart below shows this breakdown: more than half (52%) of the total footprint is linked to housing, and 19% to food. These two sectors alone account for almost three-quarters of the material footprint. Again, most of this is from non-metallic minerals like gravel and sand, and biomass for food (mostly crops).&lt;/p&gt;
    &lt;p&gt;A lot of the things some might classify as “non-essential” goods, such as cars, stuff we buy for our homes, and clothing, are small by comparison.3&lt;/p&gt;
    &lt;p&gt;It’s interesting to read the European Environment Agency’s analysis of what this breakdown means for policy and action.&lt;/p&gt;
    &lt;p&gt;On housing, the agency states:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“The very high material footprint of housing means that no significant reduction in the EU’s material footprint can be achieved without addressing our built environment. On the other hand, the environmental benefit from avoiding extraction of non-metallic minerals is relatively small.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;So, to substantially reduce our material footprint, we need to rethink our homes — maybe the materials we use to build or their size — but the environmental benefits of doing so are pretty small. Again, that raises the question of why we would make this the focal point of action if there are few benefits.&lt;/p&gt;
    &lt;p&gt;On food, the policy implications are also unclear:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“The potential for a radical reduction of the food sector’s material footprint is rather low as it is composed of food items essential to our societies. However, dietary shifts and the management of food waste can contribute to reducing the food sector’s material footprint”.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;We need food to eat, so substantially cutting back is hard. The two obvious proposals are reducing food waste and shifting to more plant-based diets (less material-intensive, because you don’t have to produce food for the animals first). These are both strong recommendations that I have written a lot about before.&lt;/p&gt;
    &lt;p&gt;But what’s crucial is that there is already a long list of reasons why we would want to make these changes: the fact that food is responsible for up to one-third of the world’s greenhouse gas emissions; that it uses half of the world’s habitable land; that it’s the leading driver of water use, water pollution, biodiversity loss, and deforestation; and the fact that we raise and slaughter more than 70 billion land animals for food every year. All these problems can be improved by shifting to more plant-based diets and reducing food waste.&lt;/p&gt;
    &lt;p&gt;Of all the arguments to make this shift, the “material footprint” is the least convincing. When it comes to sustainability, it’s much less obvious why I should care more about the weight of the amount of wheat, corn, or lentils we grow than I do about the ecosystems destroyed, forests cut down, animals raised under cruel conditions, or the rivers polluted.&lt;/p&gt;
    &lt;head rend="h1"&gt;“Luxury” goods we associate with overconsumption tend to have a relatively low material footprint&lt;/head&gt;
    &lt;p&gt;A common explanation for measuring material footprints is that many of us overconsume and need to do so less. On a personal level, I am also very conscious of my consumption. I think carefully about what I buy and its impact. I still wear clothes that are many, many years old, and I hold on to my mobile phone for as long as I can.&lt;/p&gt;
    &lt;p&gt;When I speak to others about this, they often mention the same items and industries: consumer technology and “fast fashion” are always in the spotlight.&lt;/p&gt;
    &lt;p&gt;But, surprisingly, thinking carefully about these purchases is not advice that follows from looking at material footprints. The chart below shows the breakdown of the EU’s material consumption, this time by final product. We see that these consumer products account for a very small fraction of the total footprint.4&lt;/p&gt;
    &lt;p&gt;Textiles and clothing (which includes footwear and non-clothing textiles) account for only 1% of the total. Computers and consumer electronics are just 0.8%. Surprisingly, rubber and plastic products are just 0.2%.&lt;/p&gt;
    &lt;p&gt;Dramatically reducing our use of items traditionally associated with excess consumption would barely change our material footprint. My sense is that most people are unaware of this.&lt;/p&gt;
    &lt;p&gt;The material footprint leads us to counterintuitive policy recommendations that many environmentalists would strongly object to. Here’s the European Environment Agency again:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Services require the lowest material use per euro spent among all domains, followed by clothing and household goods. Therefore, consumption patterns directly affect the EU’s material footprint and one way to reduce it is to promote expenditure patterns that are less material intensive.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Spending more money on services than physical “stuff” makes sense if we want to reduce our material footprints. However, since clothing and households also have a low material intensity, we could also reduce our footprint by spending much more on clothes, televisions, phones, and other consumer goods and less on essentials such as food and housing.&lt;/p&gt;
    &lt;p&gt;“Spend more of your money on clothes and iPhones” to minimize your environmental footprint is not advice I’ve heard before (and is not advice I’d give either). Yet this is what the European Environment Agency implies when it suggests “promoting expenditure patterns that are less material-intensive”. That advice comes directly from the results of material footprints.&lt;/p&gt;
    &lt;head rend="h1"&gt;Sustainability means much more than just carbon footprints, so we should track lots of environmental impacts&lt;/head&gt;
    &lt;p&gt;One motivation for measuring material footprints was to extend the focus of sustainability beyond carbon footprints. I share this sentiment. I wrote a book about seven environmental problems, and climate change was just one of them.&lt;/p&gt;
    &lt;p&gt;However, there are better ways to understand these environmental concerns than summing up the weight of the different resources we use.&lt;/p&gt;
    &lt;p&gt;I have written many articles on measuring sustainability and environmental impacts that go beyond carbon emissions. At Our World in Data, we have deliberately made our environment section extensive (see our list of topics below). We’ve covered land use, water use, eutrophication, deforestation, fertilizer overuse, biodiversity loss, food waste, and much more.&lt;/p&gt;
    &lt;p&gt;Resource use matters, and we need to monitor issues such as the risk of running out of some materials or the mining and socioeconomic impacts of others. There is a lot that we can do to make our economies more material-efficient and to shift from a model of continual extraction to a more circular one where we reuse materials.5 I’ve written about this opportunity before as we shift from fossil fuels to low-carbon energy.&lt;/p&gt;
    &lt;quote&gt;Adding up the weight of very different materials doesn’t tell us about their scarcity, environmental, or socioeconomic impacts.&lt;/quote&gt;
    &lt;p&gt;Many metrics — like the ones listed in the screenshot above — do a better job at capturing the negative impacts. If we’re concerned about the scarcity of copper, we should be tracking how much we use and how much is available. If we’re worried about the environmental and social impacts of mining — water use, pollution, exploitation in supply chains — then we should be tracking these directly. However, the material footprint can downplay these issues because metal ores and fossil fuels make up a small fraction of the total in regions like the EU.&lt;/p&gt;
    &lt;p&gt;Despite the many limitations of the material footprint, almost all of the underlying individual indicators are useful. To calculate the final material footprint, researchers need to know the tonnes of copper, gold, cobalt, gravel, wood, and Atlantic tuna. On their own, these datasets are extremely valuable and could help us focus on specific resource challenges. It’s when they’re combined into a single number that this value is lost.&lt;/p&gt;
    &lt;p&gt;Comparing resource quantities within a common context can also be informative. For example, knowing how much mined materials we’ll need for different energy sources can help us understand some of the implications of the energy transition. The same applies to the amount of crops (including feed) required for different dietary choices.&lt;/p&gt;
    &lt;p&gt;Knowing how much uranium the world uses each year is useful. Creating a metric that suggests it should be treated the same as bananas is not.&lt;/p&gt;
    &lt;head rend="h4"&gt;Acknowledgments&lt;/head&gt;
    &lt;p&gt;Thank you to Max Roser and Edouard Mathieu for their valuable comments and suggestions on this article and its visualizations.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;head rend="h4"&gt;Living Planet Index: what does it really mean?&lt;/head&gt;
        &lt;p&gt;The Living Planet Index is the biodiversity metric that always claims the headlines. It’s often misinterpreted. How should we understand it?&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h4"&gt;Which countries have the critical minerals needed for the energy transition?&lt;/head&gt;
        &lt;p&gt;An overview of the distribution of critical minerals for clean energy.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h4"&gt;Do we only have 60 harvests left?&lt;/head&gt;
        &lt;p&gt;Claims that the world has only 100, 60, or even 30 years of harvests left often hit the headlines. These claims are overblown, but soil erosion is a problem and we can do something about it.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Endnotes&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Some models and calculations apply conversion factors, such as ore-to-metal ratios for minerals and metals. However, the point remains that things are considered equally, only based on mass.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;United Nations Statistics Division. Goal 12: Ensure sustainable consumption and production patterns.&lt;/p&gt;
        &lt;p&gt;UNDP Human Development Report. Planetary pressures–adjusted Human Development Index (PHDI). United Nations Development Programme.&lt;/p&gt;
        &lt;p&gt;OECD, Material Consumption.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Of course, some of these goods would be considered “essential”: we need some clothes, basic resources in our homes, and transport (even if that’s in the form of public transport or cycling), but many argue that these are sectors where we “overconsume” and some purchases have become non-essential.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;This data comes from Eurostat.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;In fact, some footprinting metrics, such as “Domestic material consumption” would still count one tonne of recycled material within the material footprint, hence increasing recycling rates and circularity would not actually help to reduce the footprint. Others, such as the material footprint or “Raw material consumption”, do attempt to treat raw extraction and recycled materials separately. However, these flows can be difficult to separate, especially where data availability is challenging.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Cite this work&lt;/head&gt;
    &lt;p&gt;Our articles and data visualizations rely on work from many different people and organizations. When citing this article, please also cite the underlying data sources. This article can be cited as:&lt;/p&gt;
    &lt;code&gt;Hannah Ritchie (2025) - “Resource use matters, but material footprints are a poor way to measure it” Published online at OurWorldinData.org. Retrieved from: 'https://ourworldindata.org/material-footprint-limitations' [Online Resource]&lt;/code&gt;
    &lt;p&gt;BibTeX citation&lt;/p&gt;
    &lt;code&gt;@article{owid-material-footprint-limitations,
    author = {Hannah Ritchie},
    title = {Resource use matters, but material footprints are a poor way to measure it},
    journal = {Our World in Data},
    year = {2025},
    note = {https://ourworldindata.org/material-footprint-limitations}
}&lt;/code&gt;
    &lt;head rend="h3"&gt;Reuse this work freely&lt;/head&gt;
    &lt;p&gt;All visualizations, data, and code produced by Our World in Data are completely open access under the Creative Commons BY license. You have the permission to use, distribute, and reproduce these in any medium, provided the source and authors are credited.&lt;/p&gt;
    &lt;p&gt;The data produced by third parties and made available by Our World in Data is subject to the license terms from the original third-party authors. We will always indicate the original source of the data in our documentation, so you should always check the license of any such third-party data before use and redistribution.&lt;/p&gt;
    &lt;p&gt;All of our charts can be embedded in any site.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45712118</guid><pubDate>Sun, 26 Oct 2025 14:21:44 +0000</pubDate></item><item><title>Myanmar military shuts down a major cybercrime center, detains over 2k people</title><link>https://apnews.com/article/scam-centers-cybercrime-myanmar-a2c9fda85187121e51bd0efdf29c81da</link><description>&lt;doc fingerprint="3996df1832927c81"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Myanmar military shuts down a major cybercrime center and detains over 2,000 people&lt;/head&gt;
    &lt;head rend="h2"&gt;Myanmar military shuts down a major cybercrime center and detains over 2,000 people&lt;/head&gt;
    &lt;p&gt;BANGKOK (AP) — Myanmar’s military has shut down a major online scam operation near the border with Thailand, detaining more than 2,000 people and seizing dozens of Starlink satellite internet terminals, state media reported Monday.&lt;/p&gt;
    &lt;p&gt;Myanmar is notorious for hosting cyberscam operations responsible for bilking people all over the world. These usually involve gaining victims’ confidence online with romantic ploys and bogus investment pitches.&lt;/p&gt;
    &lt;p&gt;The centers are infamous for recruiting workers from other countries under false pretenses, promising them legitimate jobs and then holding them captive and forcing them to carry out criminal activities.&lt;/p&gt;
    &lt;p&gt;Scam operations were in the international spotlight last week when the United States and Britain enacted sanctions against organizers of a major Cambodian cyberscam gang, and its alleged ringleader was indicted by a federal court in New York.&lt;/p&gt;
    &lt;p&gt;According to a report in Monday’s Myanma Alinn newspaper, the army raided KK Park, a well-documented cybercrime center, as part of operations starting in early September to suppress online fraud, illegal gambling, and cross-border cybercrime.&lt;/p&gt;
    &lt;p&gt;It published photos displaying seized Starlink equipment and soldiers said to be carrying out the raid, though it was unclear when exactly they were taken.&lt;/p&gt;
    &lt;p&gt;KK Park is located on the outskirts of Myawaddy, a major trading town on the border with Thailand in Myanmar’s Kayin state. The area is only loosely under the control of Myanmar’s military government, and also falls under the influence of ethnic minority militias.&lt;/p&gt;
    &lt;p&gt;Maj. Gen. Zaw Min Tun, the spokesperson for the military government, charged in a statement Monday night that the top leaders of the Karen National Union, an armed ethnic organization opposed to army rule, were involved in the scam projects at KK Park.&lt;/p&gt;
    &lt;p&gt;The allegation was previously made based on claims that a company backed by the Karen group allowed the land to be leased. However, the Karen, who are part of the larger armed resistance movement in Myanmar’s civil war, deny any involvement in the scams.&lt;/p&gt;
    &lt;p&gt;Myanma Alinn said the army ascertained that more than 260 buildings were unregistered, and seized equipment, including 30 sets of Starlink satellite internet terminals. It said 2,198 individuals were detained though it did not give their nationalities.&lt;/p&gt;
    &lt;p&gt;Starlink is part of Elon Musk’s SpaceX company and the terminals link to its satellites. It does not have licensed operations in Myanmar, but at least hundreds of terminals have been smuggled into the Southeast Asian nation.&lt;/p&gt;
    &lt;p&gt;The company could not be immediately reached for comment Monday but its policy bans “conduct that is defamatory, fraudulent, obscene, or deceptive.”&lt;/p&gt;
    &lt;p&gt;There have been previous crackdowns on cyberscam operations in Myanmar earlier this year and in 2023.&lt;/p&gt;
    &lt;p&gt;Facing pressure from China, Thailand and Myanmar’s governments launched an operation in February in which they released thousands of trafficked people from scam compounds, working with the ethnic armed groups that rule Myanmar’s border areas.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45712517</guid><pubDate>Sun, 26 Oct 2025 15:11:51 +0000</pubDate></item><item><title>Making the Electron Microscope</title><link>https://www.asimov.press/p/electron-microscope</link><description>&lt;doc fingerprint="328cd3a71931043b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Making the Electron Microscope&lt;/head&gt;
    &lt;head rend="h3"&gt;In a little over a century, the electron microscope evolved from a tool barely capable of resolving virus particles into one able to capture atomic detail.&lt;/head&gt;
    &lt;p&gt;Biological structures exist across a vast range of scales. At one end are whole organisms, varying in size from bacteria only a few micrometers across to mammals measured in feet.1 These can be seen with the naked eye or with simple light microscopes, which have been in use since the mid-1600s. At the smaller end, however, are atoms, amino acids, and proteins, spanning angstroms2 to nanometers in size.&lt;/p&gt;
    &lt;p&gt;Observing molecules at this smaller scale allows us to untangle the finer mechanisms of life: how individual neurons connect and communicate, how the ribosomal machinery translates genetic code into proteins, or how viruses like HIV invade and hijack host cells. Resolving fine structures, whether the double membrane of a chloroplast, the protein shell of a bacteriophage, or the branching architecture of a synapse, provides the bridge between atomic detail and whole-organism physiology, taking us from form to function.&lt;/p&gt;
    &lt;p&gt;The ability to explore and map such minute mechanisms eluded scientists until the invention of the electron microscope. Conceived in the 1930s, it promised theoretical resolutions on the order of angstroms, nearly a hundred times finer than the most advanced light microscope of that era. In 1931, Ernst Ruska and his advisor Max Knoll, working at the Technical University in Berlin, designed the first prototype by replacing glass lenses with electromagnetic coils to focus beams of electrons instead of light.&lt;/p&gt;
    &lt;p&gt;That first instrument barely outperformed a magnifying glass in terms of resolution. But over the next century, refinements in design, sample preparation, and computation transformed the electron microscope into an indispensable tool for modern biology.&lt;/p&gt;
    &lt;p&gt;By 1938, scientists used an electron microscope to take a photograph of a virus — the mouse ectromelia orthopoxvirus — for the first time.3 And today, modern cryo-electron microscopy, in which samples are frozen in liquid ethane prior to imaging, can resolve individual atoms within proteins. During the COVID-19 pandemic, cryo-electron microscopy revealed the spike protein in the SARS-CoV-2 virus, which directly influenced the development of COVID vaccines. The technique also revealed a protein receptor that senses heat and pain, demonstrating how it translates physical signals to our nervous system, a breakthrough discovery that earned the 2021 Nobel Prize in Physiology.&lt;/p&gt;
    &lt;p&gt;Even as electron microscopes have allowed us to view ever smaller structures with clarity, challenges remain. One is that the images remain limited to static snapshots. Because samples must be imaged in a vacuum, it is impossible to directly observe the dynamism of live cells.4 In addition, specimens must be extremely thin to allow the electron beam to pass through, which prevents imaging of thick tissues. And finally, beyond these biological constraints, electron microscopes are physically large, can cost millions of dollars, and demand specialized facilities, training, and expertise to operate.&lt;/p&gt;
    &lt;p&gt;Despite these limitations, electron microscopy remains a powerful tool in biology, bridging the scales between molecular structure and living function. The story of its discovery is one of persistent ingenuity, involving a large cast of characters and numerous breakthroughs that helped make the modern electron microscope possible.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Seeds of an Idea&lt;/head&gt;
    &lt;p&gt;By the late 19th century, biologists knew they were approaching the resolution limit of the light microscope. In their quest to see biology in finer detail, they had reached a barrier that light could not cross.&lt;/p&gt;
    &lt;p&gt;Proof of this came from Ernst Abbe, a professor of experimental physics and mathematics at the University of Jena in Germany. Until Abbe, microscope design had been more of an art than a science, with innovators building optical instruments through trial and error. Carl Zeiss, who had begun manufacturing microscopes in the 1850s, approached Abbe in 1866 about using his scientific expertise for the construction of microscopes. Together, they began developing tools to improve the uniformity and quality of optical lenses.&lt;/p&gt;
    &lt;p&gt;In the early 1870s, while working on the microscope objectives (the lens closest to the specimen in a microscope), Abbe discovered that the sharpness of an image did not only depend on how perfectly a lens was ground but also on how much diffracted light from the specimen the lens could capture. He realized that fine details in a specimen bend light into wide angles, and only objectives with a sufficiently large opening could collect those rays to bring the image into focus.&lt;/p&gt;
    &lt;p&gt;From this insight, Abbe defined the concept of the “numerical aperture” (a measure of how much light a lens can gather5) and showed that the smallest visible detail is limited by the wavelength of light divided by twice this value.6 Even with ultraviolet light, at the short end of the visible spectrum (400 nanometers), the limit of resolution was 200 nanometers — larger than most viruses, intracellular structures, and protein complexes.&lt;/p&gt;
    &lt;p&gt;Hope of resolving structures beneath this resolution boundary only arrived in 1895, when the German physicist Wilhelm Röntgen discovered X-rays, a form of high-energy electromagnetic radiation with wavelengths shorter than those of ultraviolet light, and published a (now-iconic) image of his wife Bertha’s hand, with her bones and wedding ring clearly visible. This was the first time the hidden insides of the body could be seen without dissection. The bones, joints, and even metal fragments lodged inside the body could be made visible.&lt;/p&gt;
    &lt;p&gt;Between 1913 and 1915, the British physicist William Henry Bragg and his son, William Lawrence Bragg, developed a technique called X-ray crystallography. Working with simple crystals such as salt and diamond, they showed that when X-rays strike a regularly ordered crystal lattice, they diffract at specific angles that reveal the spacing of atoms within the crystal. The method works because X-rays have wavelengths about the size of chemical bonds, allowing the beams to reach and bounce off each atom in the lattice, reflecting the structure at an atomic scale. By applying a mathematical operation called a Fourier transform to these diffraction patterns captured on photographic plates, the Braggs reconstructed the three-dimensional arrangements of the atoms in the crystal.&lt;/p&gt;
    &lt;p&gt;Biomolecules, however, are not naturally crystalline. To study them, they had to be laboriously extracted, purified, and crystallized, separating them from their environment. The X-ray crystallography of biomolecules began in the 1930s, ushering in the field of structural biology. With sub-nanometer resolution, the invention of X-ray crystallography enabled a revolution in molecular biology. It was applied, for example, to solve the structures of DNA, hemoglobin, and insulin, molecules that have shaped the trajectory of modern biology.&lt;/p&gt;
    &lt;p&gt;But many biological targets remained out of reach. Viruses could rarely be crystallized, and cellular structures often lost their integrity when removed from their natural contexts. Thus, even with X-ray crystallography revealing the structures of small proteins and light microscopy capable of imaging cells, a gulf persisted between the study of small molecules and whole cells, which left much of biology invisible.&lt;/p&gt;
    &lt;p&gt;Meanwhile, access to the parallel world of electrons was beginning to open. At the turn of the 20th century, Hans Busch, a German physicist at the University of Jena, was studying how electron beams behaved in magnetic fields. His work built on decades of experiments with cathode rays, streams of electrons released when a high voltage is applied inside a glass tube.&lt;/p&gt;
    &lt;p&gt;Cathode rays had become central to both physics and technology: Physicists used them to probe how electrons scattered, ionized gases, and responded to electric and magnetic fields, and engineers used them to form the basis of devices such as the radio and television. It was while trying to better understand and control these beams that Busch postulated his remarkable theories.&lt;/p&gt;
    &lt;p&gt;In 1926 and 1927, Busch published two papers demonstrating mathematically that a magnetic coil could focus an electron beam in the same manner that a glass lens focuses light. While it was already known that coils could bend electron beams,7 Busch’s key insight was to frame this behavior in the language of optics: Electron beams could be treated like light rays. Concepts such as focal length, magnification, image formation, and even lens aberrations could all be applied to electrons. This meant that the well-developed theory of optical systems could be imported almost directly to other disciplines.&lt;/p&gt;
    &lt;p&gt;The Nobel Prize–winning physicist and inventor of holography, Denis Gabor, later reflected on Busch’s contribution in a 1942 lecture: “Busch’s paper was more than an eye-opener; it was almost like a spark in an explosive mixture. In 1927, the situation in physics was such that nothing more than the words ‘electron lens’ were needed to start a real burst of creative activity.”&lt;/p&gt;
    &lt;p&gt;And so it was that Busch’s idea sparked the birth of electron optics. Within a few years, at least three independent inventors would lay claim to having designed the electron microscope, all tracing their inspiration back to his initial insight.&lt;/p&gt;
    &lt;head rend="h2"&gt;The First Electron Microscope&lt;/head&gt;
    &lt;p&gt;In 1928, the High Tension Laboratory at the Technical University in Berlin (a premier research facility focused on electrical engineering in the interwar years) was researching high-voltage power transmission and insulation. A persistent obstacle was the electrical surge often caused by thunderstorms, which repeatedly damaged the lab’s equipment. But before scientists could design a way to mitigate the problem, they first needed to understand it: Exactly when did these surges occur, and how fast or large were the voltage fluctuations?&lt;/p&gt;
    &lt;p&gt;To tackle this, the lab hoped to recruit a graduate student to create a proof-of-concept for a high-speed oscilloscope, a device that could directly visualize electrical pulses. A cathode ray oscilloscope worked by firing a beam of electrons across a phosphorescent screen inside a vacuum tube, where the impact produced a bright spot of light. Electric fields could be used to deflect the beam horizontally (to represent time) and vertically (to represent signal amplitude) so that electrical signals appeared as moving lines of light that could be observed directly.&lt;/p&gt;
    &lt;p&gt;Although cathode ray oscilloscopes were already in use, they served mainly to capture slower signals. The high voltage surges experienced in thunderstorms or short circuiting events, though, flashed by in one hundred millionths of a second, leaving almost no trace on the screen. To make such fleeting signals visible, the intensity of the electron beam had to be increased, which meant focusing the beam into as small and powerful a spot as possible. Only one student applied to take on the challenge: 21-year-old Ernst Ruska.&lt;/p&gt;
    &lt;p&gt;Ruska was born into a family of scientists in Heidelberg, Germany, in 1906. He had been exposed to optics from an early age, as his uncle was an astronomer at the local observatory and his father, a science historian, owned a large optical microscope that Ruska was strictly forbidden to touch. He recalls in his Nobel lecture: “We would see on a table in the other room the pretty yellowish wooden box that housed my father’s big Zeiss microscope … He sometimes demonstrated to us interesting objects under the microscope, it is true; for good reasons, however, he feared that children’s hands would damage the objective or the specimen by clumsy manipulation of the coarse and line drive. Thus, our first relation to the value of microscopy was not solely positive.”&lt;/p&gt;
    &lt;p&gt;Unlike the rest of his family, Ruska’s passion leaned less toward science and more toward technical projects and problem-solving through engineering. While the other Ruska children spent their weekends with their father classifying rock samples or identifying bird calls, Ernst preferred tinkering with electrical switchboards and reading Max Eyth’s Behind Plow and Vice, a memoir on engineering and invention. And when he grew older, he recalls being fascinated by his high school physics teacher’s explanations of the movement of electrons through electrostatic fields and the limitations of light microscopes — an interest he carried into adulthood.&lt;/p&gt;
    &lt;p&gt;At the High Tension Laboratory, under Max Knoll, Ruska began building the much-anticipated oscilloscope. In this device, the incoming electrical current would pass through the vertical deflection plates, causing the electron beam to shift in proportion to the amplitude of the surge. To sharpen the image, a magnetic focusing coil was placed upstream of the deflection plates, concentrating the beam into a small, bright spot before it reached the phosphorescent screen. Ruska’s task was to determine the optimal placement of these coils so that the dot appeared as sharp as possible.&lt;/p&gt;
    &lt;p&gt;For guidance, Ruska turned to Hans Busch’s recent papers on the lens-like action of magnetic fields on electron beams. In these papers, Busch had not only shown that a coil could act as a “magnetic electron lens,” but had also worked out the formulas describing electron trajectories in such a field and how the focal length changed with coil current. Using these calculations, Ruska confirmed Busch’s theories experimentally and determined the precise coil placement needed to bring the beam to a sharp focus. He then placed a small aperture in the beam’s path and, by varying the coil current, was able to project and record an image of the aperture at different magnifications on a screen.&lt;/p&gt;
    &lt;p&gt;As Ruska later recalled in his Nobel lecture, his 1929 Master’s thesis contained “numerous sharp images with different magnifications of an electron-irradiated anode aperture … the first recorded electron-optical images.”&lt;/p&gt;
    &lt;p&gt;By 1930, as Germany’s economy collapsed under the weight of post-war reparations and global depression, Ruska was unable to find work in industry and remained at the university for doctoral studies. Initially unsure of a research direction, he continued experimenting with magnetic lenses. He reasoned that if one coil could produce a magnified image, two in sequence might enlarge it further — the conceptual birth of the electron microscope.&lt;/p&gt;
    &lt;p&gt;By April 1931, Ruska had constructed a two-stage imaging system with a total magnification of 14.4 times — still far below the roughly 1000-fold magnification achieved by high-quality light microscopes of the time. The system began with a cathode inside a vacuum tube, which emitted electrons when a high voltage was applied. These electrons were accelerated toward an anode and passed through a small aperture, forming a narrow beam, much like light through a pinhole. Magnetic coils wrapped around the tube acted as electron lenses. The first coil, placed close to the object, served as the objective lens, bringing the transmitted electrons into focus and forming an intermediate image. A second coil downstream acted as a projector lens, refocusing and enlarging that intermediate image so it could be captured onto a fluorescent screen.&lt;/p&gt;
    &lt;p&gt;By carefully tuning the currents in both coils, Ruska could control the focal lengths and achieve much higher magnifications than with a single lens. The final image appeared as glowing light patterns on the screen, with bright areas where electrons passed through the specimen and dark regions where they were absorbed or scattered.&lt;/p&gt;
    &lt;p&gt;These images, photographed through a window in the tube, were the first electron micrographs, created by channeling electrons through successive magnetic lenses in a multistage system. Although its resolution was quite modest by today’s standards, this instrument is regarded as the first electron microscope. Ruska submitted the results for publication that same month, though the paper did not appear until August. Unfortunately, unbeknownst to him, between its submission and publication, a patent for an electron microscope had already been submitted by another inventor: Reinhold Rüdenberg.&lt;/p&gt;
    &lt;head rend="h2"&gt;From Paralysis to First Patents&lt;/head&gt;
    &lt;p&gt;Rüdenberg, born in Hanover in 1883, came of age during a golden decade of physics marked by Röntgen’s discovery of X-rays, the identification of the electron, and the first studies of radioactivity. As a high-school student, he eagerly replicated many of these experiments, building a two-way Morse telegraph, powering an X-ray tube with a hand-wound inductor, and constructing a radio transmitter and receiver. He received his first patent, for a radio oscillator, while still an electrical engineering student at the Technical University of Hanover.&lt;/p&gt;
    &lt;p&gt;After earning his doctorate, Rüdenberg spent three years (1906-1908) at Göttingen University, working in applied mechanics and collaborating with leading figures in electron theory, including Hans Busch. In 1908, he joined Siemens in Berlin as a design engineer and, by 1923, had risen to the position of Chief Electrical Engineer.&lt;/p&gt;
    &lt;p&gt;While at Siemens, Rüdenberg developed several new electrical designs, among which were cooling systems for high-voltage generators, one of the first 60-megawatt turbine generators, conductors for high-voltage transmission lines, and relay systems for distant power stations. He also spent three years apprenticing in Siemens’ patent department, an experience that doubtless helped fuel his prolific output of them. He was a prolific inventor and is estimated to have held over a hundred unique patents.&lt;/p&gt;
    &lt;p&gt;In the fall of 1930, while on vacation, Rüdenberg’s youngest son fell gravely ill. The three-year-old developed a high fever and paralysis. He had contracted polio. At a time when thousands were infected each year in Germany, with fatality rates around 15 percent, the diagnosis was devastating. Worse still, almost nothing was known about the “germ” responsible: No diagnostic test, no treatment, and no vaccine existed.&lt;/p&gt;
    &lt;p&gt;“This amazing fact and its significance for science and health gave me no rest in my thoughts,” Rüdenberg later recalled. “During many sleepless nights, tortured by the fate of my son, agonizing fantasies came and went, how to find ways to examine these minute germs, how possibly to attack them in order to attain healing or at least a standstill of the disease. Certainly, an agent finer than light had to be found to make these tiny viruses of immeasurable size visible to the human eye.”&lt;/p&gt;
    &lt;p&gt;Motivated by both paternal concern and engineering instinct, Rüdenberg began searching for a way to see such viruses. He considered X-rays but quickly dismissed them, as no method existed to focus the X-ray particles like visible light. Electrons, however, held promise. Having studied their behavior with Busch at Göttingen, he was aware of the focusing power of magnetic fields, and when Busch later published his 1926 and 1927 papers on magnetic electron lenses, he even sent copies directly to Rüdenberg.&lt;/p&gt;
    &lt;p&gt;During the winter of 1930-1931, Rüdenberg sketched out a complete conceptual design for an electron microscope, detailing its electron source, electrostatic lenses for focusing and magnification, and a fluorescent screen for visualization. In May 1931, just one week before Ruska publicly presented his own work, Rüdenberg submitted a series of patent applications describing this electron microscope.&lt;/p&gt;
    &lt;p&gt;Meanwhile, unaware of Rüdenberg’s patents, Ruska also pressed forward. For his doctoral research, Ruska focused on improving the electromagnetic lens, whose magnification ability still lagged far behind the optical lenses of conventional light microscopes. At the time, a state-of-the-art light microscope could magnify images up to about 1000 times, whereas in 1932, extant electron microscopes were still stuck at a paltry 17-fold.&lt;/p&gt;
    &lt;p&gt;To improve their performance, Ruska realized he needed to decrease the electron microscope’s focal length, since a shorter focal length would bend electrons more strongly, bringing them to a smaller focal point and producing a higher magnification. He discovered that encasing the coil in iron did so dramatically. This led to the invention of the polepiece lens, now a fundamental component of all electron microscopes.&lt;/p&gt;
    &lt;p&gt;Polepieces are shaped iron cylinders, each with a coil, placed a few millimeters apart. The narrow gap concentrates the magnetic field, producing a lens with stronger focusing ability and a shorter focal length. This not only increased the magnification but also provided more space to add a third lens (a condenser lens upstream of the sample) within the cathode ray column.&lt;/p&gt;
    &lt;p&gt;During this time, Ruska and Knoll also made a bold attempt to estimate the theoretical resolution limit of the electron microscope. They applied the formula used in light microscopy and substituted the wavelength of electrons for that of light. For electrons accelerated at 75 kilovolts (higher voltages would increase the electrons’ energy and further shorten their wavelength, which, in principle, yields even finer detail), they arrived at a resolution limit of 2.2 angstroms (2.2 x 10-10 meters).8&lt;/p&gt;
    &lt;p&gt;Ruska submitted his dissertation in mid-1933 and later that year built a vastly improved microscope, achieving magnification up to 12,000 times. The images, taken of a scrap of aluminum foil, exceeded the resolution limit of the light microscope for the first time (even though the high-energy beam incinerated the samples).&lt;/p&gt;
    &lt;p&gt;Ruska observed that very thin foils produced sharper images with stronger contrast while also surviving longer under the beam. He reasoned that, in thin specimens, most electrons passed through without losing energy, elastically scattered (diffracted) rather than absorbed. These transmitted electrons still carried structural information and built up the image on the screen. Because fewer electrons deposited energy in the material, less heating and radiation damage occurred, allowing longer exposures and finer detail.&lt;/p&gt;
    &lt;p&gt;By 1934, Ruska had published these findings and even speculated about imaging biological material. He stated, “This microscopy is accessible to any objects (including all organic ones), provided that they can be prepared as sufficiently thin foils and introduced into the vacuum without suffering damage (structural alteration).” And, “For better visualization of such objects — one might think, for example, of nerve fibrils with their extremely fine structure — it will perhaps be necessary to develop ‘staining’ methods adapted to the problem, such as impregnation with metal salts (silvering), similar to those already commonly used in ordinary histological microscopy.”&lt;/p&gt;
    &lt;p&gt;Rüdenberg’s design, meanwhile, was never built at Siemens. The political upheaval in Germany halted his advancement, as a German of Jewish descent, threatened his very survival. In 1936, with Siemens’ assistance, he and his family fled to England and, two years later, emigrated to the United States, where he became a professor of electrical engineering at Harvard.&lt;/p&gt;
    &lt;p&gt;Ironically, as a German, Rüdenberg was received with ambivalence; in 1942, during the war, his U.S. patents on the electron microscope were seized by the Alien Property Custodian, a government office tasked with seizing assets belonging to citizens of enemy nations during wartime. Post-war, he had to fight lengthy legal battles to reclaim them. He later consulted for Farrand Optical Company, a small company in New York which attempted to build an electrostatic microscope based on his patents, a venture which failed commercially. Happily, even as these obstacles abounded, his son made a full recovery from his polio.&lt;/p&gt;
    &lt;head rend="h2"&gt;From Prototype to Commercialization&lt;/head&gt;
    &lt;p&gt;By the early 1930s, electron microscopy had surpassed the resolving power of light microscopes, promising magnifications several orders of magnitude higher. Yet progress was uneven.&lt;/p&gt;
    &lt;p&gt;In Belgium, the Hungarian physicist Ladislaus Marton built his own instrument by 1932 and produced the first biological electron micrographs: images of the insectivorous plant Drosera intermedia and the blood-red bacterium, Serratia marcescens.&lt;/p&gt;
    &lt;p&gt;To make such delicate samples visible, Marton turned to osmium tetroxide, a heavy metal compound that binds strongly to cellular membranes. By coating thin sections of Drosera intermedia with osmium, he increased their ability to scatter electrons, resulting in clearer contrast in the final image. He also introduced an electronic shutter, a device that blocked the electron beam during focusing and opened only for the brief moment of exposure. This protected fragile specimens from unnecessary radiation damage while still allowing sharp images to be captured. For a time, it seemed Marton was leading the field.&lt;/p&gt;
    &lt;p&gt;Ruska, who had completed his PhD in 1933 and took a job in the television industry, returned to the field. He joined forces with Bodo von Borries, a longtime collaborator and future brother-in-law, to push the technology toward commercial viability. Between 1933 and 1935, they filed eight patents and canvassed a wide range of institutions for financial support. They approached the Kaiser Wilhelm Institute, the board of optical manufacturer Carl Zeiss, and even steel companies to see if they had any need for electron microscopes. While initial efforts with Zeiss seemed promising, they collapsed when Zeiss withdrew due to Siemens’s rights to Reinhold Rüdenberg’s earlier patents.&lt;/p&gt;
    &lt;p&gt;Despite these setbacks, interest in electron microscopy mounted. At the Technical School in Berlin, students modified Ruska’s prototypes to capture striking images of a fly’s leg hair magnified 25,000 times. To make the tissues more resistant to the beam, they used potassium dichromate, a fixative that coss-linked lipids and proteins in the tissue so it was less likely to collapse or vaporize. This fixative also increased scattering contrast, making fine details easier to discern.&lt;/p&gt;
    &lt;p&gt;Specimens were cooled to –17 °C, which reduced thermal motion and slowed the buildup of heat from inelastic electron collisions. Cooling didn’t prevent radiation damage, but it delayed it long enough for images to be recorded. These were early explorations of the cryogenic methods that would later define the field.&lt;/p&gt;
    &lt;p&gt;By 1936, electron microscopy centered around a highly active (albeit small) community with Marton in Belgium, Ruska and von Borries in Berlin, and younger researchers at their university extending the work. However, all still lacked financial support to develop a commercial system.&lt;/p&gt;
    &lt;p&gt;Momentum shifted when Ruska spoke at the 1936 German Conference of Physicists and Mathematicians. His brother Helmut, a physician newly appointed at Berlin’s University Hospital, added crucial medical endorsement by promoting the microscope’s potential in medical applications. This medical credibility brought Siemens back to the table. With both Siemens and Zeiss expressing interest, Ruska and von Borries chose Siemens, which already held the Rüdenberg patents and had stronger electrotechnical expertise.&lt;/p&gt;
    &lt;p&gt;In February 1937, a decade after Hans Busch first theorized the electron lens, Siemens launched development of the first commercial electron microscope in Berlin. By 1938, the first model was available, offering magnification of up to 30,000 times.&lt;/p&gt;
    &lt;p&gt;The device was a triumph of Ruska’s bench-top experiments and relentless iteration. At the top of the microscope column sat the cathode, generating electrons accelerated downward at high voltage. A condenser lens collected, narrowed, and focused the electron beam to illuminate the sample, which was introduced through a small vacuum airlock and held on a stage. Immediately below it lay the objective lens, a powerful magnetic coil that brought the transmitted electrons into sharp focus, forming a first, intermediate image. A second coil, the projection lens, then enlarged this image and cast it onto a fluorescent screen, where bright and dark regions revealed the specimen’s structure. Researchers could view the glowing picture directly through a built-in window or capture it on photographic plates housed beneath the screen. To maintain stable operation, the entire column was kept under high vacuum by a mercury diffusion pump.&lt;/p&gt;
    &lt;p&gt;A shared Siemens laboratory was set up and became an important hub for producing some of the earliest biological electron micrographs. Directed by Helmut Ruska, it housed four instruments available to visiting scientists, many of them biologists and medical researchers. In 1939 alone, nearly 2,000 images were produced, leading to 23 publications. Among them were the first electron micrographs of viruses, bacteriophages, and fine biological details never before seen.&lt;/p&gt;
    &lt;p&gt;The lab itself was destroyed in an air raid in 1944, and it would take nearly a decade before Siemens in Germany regained its footing in electron microscopy. But by then, the electron microscopy spark had spread: Laboratories in Britain and the United States continued to drive the field forward, building on the groundwork laid in Berlin. Ernst Ruska would go on to win the Nobel Prize in Physics in 1986 for his fundamental work in electron optics and microscopy.&lt;/p&gt;
    &lt;head rend="h2"&gt;Inside an Electron Microscope&lt;/head&gt;
    &lt;p&gt;Nearly a century after its invention, the electron microscope has transformed from a tool barely capable of resolving fuzzy virus particles into one capable of capturing atomic detail. While its progress has mostly been marked by steady refinements, it has also been punctuated by key breakthroughs.&lt;/p&gt;
    &lt;p&gt;For instance, from the start, electron microscopy for biology faced a water problem. Because the microscope operates under high vacuum, liquid water evaporates instantly, leaving delicate biological samples collapsed or distorted. To avoid this, aqueous samples had to be dried, fixed, or stained, which produced recognizable images but with obvious artifacts, such as shrunken cells, ruptured membranes, and structural distortions that no longer reflected the living state. Through the 1940s and 1950s, embedding samples in resins and the use of ultra-thin sectioning made cellular ultrastructure visible, while freeze-drying and early cryogenic sectioning offered partial preservation of hydrated material, though the results were still plagued by distortion.&lt;/p&gt;
    &lt;p&gt;A breakthrough came in the early 1980s, when Jacques Dubochet and his colleagues at the European Molecular Biology Laboratory in Heidelberg demonstrated that water could be vitrified; that is, cooled so rapidly that it solidifies into glass rather than crystallizing, finally allowing biomolecules to be preserved and imaged as they are in life.&lt;/p&gt;
    &lt;p&gt;In parallel, computational techniques were improving. Beginning in the 1970s, Joachim Frank developed statistical methods for aligning and averaging thousands of noisy electron micrographs of individual macromolecules. This “single-particle analysis” transformed faint, low-contrast images into coherent 3D reconstructions. When combined with Dubochet’s vitrification method, the two advances gave rise to single-particle cryo-electron microscopy: Molecules suspended in vitreous ice could be imaged in random orientations and computationally combined into detailed three-dimensional structures.&lt;/p&gt;
    &lt;p&gt;Three decades later, with the arrival of direct electron detectors, developed with the efforts of Richard Henderson and with more powerful algorithms, single-particle cryo-EM entered its “resolution revolution,” routinely delivering near-atomic detail and firmly establishing itself as one of the central methods of structural biology.&lt;/p&gt;
    &lt;p&gt;Today’s most advanced cryo-electron microscopes stand nearly two stories tall, cost millions of dollars, and operate with breathtaking precision. But they still rest on the same foundation laid in the 1930s: a beam of electrons, shaped by magnetic fields, interacting with matter to reveal what light cannot.&lt;lb/&gt;At the top of the vertical column is the electron gun, the source of the beam. A fine tungsten filament or sharp field-emission tip is held at high negative voltage, often 200–300 kilovolts, so electrons are released and accelerated down the column. At these energies, electrons travel close to the speed of light, with wavelengths thousands of times shorter than visible light, giving them their extraordinary resolving power. To prevent scattering, the column is maintained in an ultra-high vacuum, as even trace gases could deflect or scatter the beam.&lt;/p&gt;
    &lt;p&gt;Magnetic lenses, made of coiled wire encased in iron polepieces, focus and steer the electrons much like glass lenses bend light. The condenser lens narrows the beam onto the sample, while the objective lens forms the first magnified image. Additional projector lenses enlarge this image and deliver it to a detector.&lt;/p&gt;
    &lt;p&gt;When the beam passes through the specimen, electrons interact with its atoms. Some scatter elastically, shifting phase without losing energy; others scatter inelastically, losing energy, and are either absorbed or filtered out. The transmitted electrons carry structural information, encoded as variations in amplitude and phase, and create a contrast image on the detector.&lt;/p&gt;
    &lt;p&gt;In cryo-EM, millions of such low-contrast 2D projections are collected, each a noisy snapshot of a molecule in a random orientation. Computational algorithms align, classify, and combine them, using a mathematical method that breaks the images down into their underlying patterns of waves (using the Fourier transform), then piece those patterns back together to form a detailed 3D map.&lt;/p&gt;
    &lt;p&gt;The result begins as a grainy micrograph, but when assembled and refined, this picture reveals extraordinary detail: the honeycomb lattice of graphene, the folds of a viral capsid, or the ribosome caught mid-translation. &lt;lb/&gt;Today, no single imaging method captures everything. For following fast processes, tracking molecules in living cells, or imaging whole organisms, light microscopy remains indispensable. For atomic resolution of well-ordered proteins, X-ray crystallography is still unmatched. &lt;/p&gt;
    &lt;p&gt;But when it comes to bridging the scales between atoms and cells, there is no better tool than the electron microscope. The same instrument that in 1938 revealed the faint silhouettes of mouse ectromelia virus now resolves viral proteins at the scale of a chemical bond, an arc of progress that has helped biologists redefine what it means to “see.”&lt;/p&gt;
    &lt;p&gt;Smrithi Sunil is a research scientist developing imaging techniques to study how the brain works across scales. She has developed multimodal microscopy methods to bridge molecular, cellular, and systems-level measurements of structure and function. She also writes about science and metascience on her Substack, Engineering Discovery.&lt;/p&gt;
    &lt;p&gt;Thanks to Nicholas Porter and Alicia Botes for reading a draft of this essay. Lead image by Ella Watkins-Dulaney, adapted from Vossman/Wikimedia and Ernst Ruska. Whole-cell animation and video by Martina Maritan, Scripps Research.&lt;/p&gt;
    &lt;p&gt;Cite: Sunil, S. “Making the Electron Microscope.” Asimov Press (2025). https://doi.org/10.62211/57hg-22fw&lt;/p&gt;
    &lt;p&gt;One of the smallest known whole organisms is the bacteria Mycoplasma genitalium roughly 200 nm across. In contrast, the mycelium network Armillaria ostoyae in the Malheur National Forest in Oregon is possibly the largest living organism, covering almost four square miles and weighing around 35,000 tons.&lt;/p&gt;
    &lt;p&gt;The length between chemical bonds is measured in Angstroms, named after Swedish physicist Anders Jonas Angstrom who first described the unit.&lt;/p&gt;
    &lt;p&gt;A year later, in 1939, Gustav Kausche, Edgar Pfankuch, and Helmut Ruska reported the first images of the tobacco mosaic virus (TMV). Although TMV is often cited as the “first” virus to be imaged with an electron microscope since TMV was a classic model virus in biology and its rod-shaped form was immediately recognizable, the mouse orthopoxvirus micrographs technically appeared earlier.&lt;/p&gt;
    &lt;p&gt;To work around this, scientists capture dynamics indirectly by freezing specimens at different stages of a process (such as during the assembly of a protein complex) and then reconstruct the sequence from these static frames.&lt;/p&gt;
    &lt;p&gt;Numerical aperture NA = n sin θ, where n is the refractive index of the medium and θ is the half-angle of the widest cone of light the lens can accept.&lt;/p&gt;
    &lt;p&gt;Twice this value arises because fine structures in a specimen diffract light into symmetric beams on opposite sides of the optical axis. When both of these beams are captured by the objective and brought together at the image plane, they interfere with reconstructing the alternating patterns of light and dark that represent the specimen’s fine detail. Note that Abbe’s formula is for coherent transmitted light and not for fluorescent imaging. In fluorescence microscopy, each molecule emits light independently rather than by interfering wavefronts, so the image is not formed by overlapping diffraction orders. The resolution is instead limited by the microscope’s point spread function, described by the Rayleigh criterion (d = 1.22 λ / 2 NA), which sets the smallest distance at which two fluorescent emitters can be distinguished.&lt;/p&gt;
    &lt;p&gt;Even before “electrons” were named, Julius Plücker showed in the 1850s that magnetic fields could deflect the glowing path of cathode rays. Johann Hittorf (1869) and Kristian Birkeland (1896) had independently used magnetic coils to focus them. Hans Busch was the first to provide mathematical calculations for the electron trajectories during this focusing action.&lt;/p&gt;
    &lt;p&gt;This resolution was, in fact, achieved 40 years later. Today, electron microscopy has even surpassed that mark: Scientists have resolved biological structures to well below 2 angstroms, including the GABA receptor, a membrane protein channel that mediates inhibitory neurotransmission, at 1.7 angstroms. In this system, the electrons were accelerated to 300 kilovolts, yielding a resolution better than the one Ruska proposed with only 75 kilovolts.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45713253</guid><pubDate>Sun, 26 Oct 2025 16:46:22 +0000</pubDate></item><item><title>Ken Thompson recalls Unix's rowdy, lock-picking origins</title><link>https://thenewstack.io/ken-thompson-recalls-unixs-rowdy-lock-picking-origins/</link><description>&lt;doc fingerprint="3a3a188cfbb6805d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Ken Thompson Recalls Unix’s Rowdy, Lock-Picking Origins&lt;/head&gt;
    &lt;p&gt;The 82-year-old Ken Thompson has some amazing memories about the earliest days of the Unix operating system — and the rowdy room full of geeks who built it.&lt;/p&gt;
    &lt;p&gt;This month Silicon Valley’s Computer History Museum released a special four-and-a-half-hour oral history, in partnership with the Association for Computing Machinery, recorded 18 months ago by technology historian David C. Brock. And Thompson dutifully recalled many of his career highlights — from his work on the C programming language and Unix to the “Plan 9 from Bell Labs” operating system and the Go programming language.&lt;/p&gt;
    &lt;p&gt;But what comes through is his gratefulness for the people he’d worked with, and the opportunity they’d had to all experiment together in an open environment to explore the limits of new and emerging technologies. It’s a tale of curiosity, a playful sense of serendipity and the enduring value of a community.&lt;/p&gt;
    &lt;p&gt;And along the way, Thompson also tells the story of raising a baby alligator that a friend sent to his office at Bell Labs. (“It just showed up in the mail… They’re not the sweetest of pets.”)&lt;/p&gt;
    &lt;head rend="h2"&gt;The Accidental Birth of Unix&lt;/head&gt;
    &lt;p&gt;Travel back in time to 1966, when 23-year-old Thompson’s first project at Bell Labs was the ill-fated Multics, a collaboration with MIT and General Electric which Thompson remembers as “horrible… big and slow and ugly and very expensive,” requiring a giant specially-built computer just to run and “just destined to be dead before it started.”&lt;/p&gt;
    &lt;p&gt;But when the Multics project died, “the computer became completely available — this one-of-a-kind monster computer… and so I took advantage.”&lt;/p&gt;
    &lt;p&gt;Thompson had wanted to work with CRAM, a data storage device with a high-speed drum memory, but like disk storage of the time, it was slow to read from memory.&lt;/p&gt;
    &lt;p&gt;Thompson thought he’d improve the situation with simultaneous (and overlapping) memory reads, but of course this required programs for testing, plus a way to load and run them.&lt;/p&gt;
    &lt;p&gt;“And suddenly, without knowing it — I mean, this is sneaking up on me…. Suddenly it’s an operating system!” Thompson’s initial memory-reading work became “the disk part” for Unix’s filesystem. He still needed a text editor and a user-switching multiplexing layer (plus a compiler and an assembler for programs), but it already had a filesystem, a disk driver and I/O peripherals.&lt;/p&gt;
    &lt;p&gt;Thompson wondered if it took so long to recognize its potential because he’d been specifically told not to work on operating systems. Multics “was a bad experience” for Bell Labs, he’d been told. “We spent a ton of money on it, and we got nothing out of it!”&lt;/p&gt;
    &lt;p&gt;“I actually got reprimands saying, ‘Don’t work on operating systems. Bell Labs is out of operating systems!”&lt;/p&gt;
    &lt;head rend="h2"&gt;One-Digit User IDs&lt;/head&gt;
    &lt;p&gt;But now Unix had its first user community — future legends like Dennis Ritchie, Doug McIlroy, Robert Morris and occasionally Brian Kernighan. (“All the user IDs were one digit. That definitely put a limit on it.”) Thompson remembers designing the Unix filesystem on a blackboard in an office with Rudd Canaday — using a special Bell Labs phone number that took dictation and delivered a typed-up transcript the next day. And Joe Ossanna “got things done” with a special talent for navigating Bell Labs’ bureaucracy that ultimately procured a crucial PDP-11 for the Unix team to work on.&lt;/p&gt;
    &lt;p&gt;“We were being told no, ‘because we don’t deal in operating systems.'” But Ossanna knew the patent department was evaluating a third-party system for preparing documents — and Ossanna proposed an in-house alternative. “So we got our first PDP-11 to do word processing.”&lt;/p&gt;
    &lt;p&gt;And history shows that it happened partly because the department paying for it “had extra money, and if they didn’t spend it, they’d lose it the next year…”&lt;/p&gt;
    &lt;p&gt;So the young Unix community picked up somewhere between five and eight new users, Thompson remembers, “the secretaries for the Patent Department, writing patents on our system!”&lt;/p&gt;
    &lt;head rend="h2"&gt;The Fellowship of the Unix Room&lt;/head&gt;
    &lt;p&gt;That PDP-11 wound up in “a spot on the sixth floor where we cleaned out a vending machine and a couple of cages of stored junk from 1920,” Thompson remembered. They eventually installed a second PDP-11, which turned the room into “a hotbed of things,” with discussions about networking — and an upcoming typesetter for documents. Thompson calls it the Unix room, and most of them eventually had extensions for their phones wired into the room. (It even had its own call-switching PBX …)&lt;/p&gt;
    &lt;p&gt;There was camaraderie and some laughter. He adds later, almost as an aside, that “in the Unix room, we used to pick locks a lot and steal things.” (When one of the secretaries discovered security had affixed a “parking boot” to her car that was parked in the wrong zone, “we went down there, and we picked the lock and stole the boot. And after that, slowly, we picked up all four boots, and we hid them under the raised floor of the Unix room…”)&lt;/p&gt;
    &lt;p&gt;The punchline? “The head of security came around and pleaded with us. ‘We won’t pick on your secretaries if you give us back our boots.'”&lt;/p&gt;
    &lt;p&gt;And the deal was accepted.&lt;/p&gt;
    &lt;p&gt;Thompson remembers things like gathering for a regular “Unix lunch” in the Bell Labs lunchroom, which “caused a symbiosis of thought and things. It was great.” Although it always seemed to happen just minutes after the lunchroom stopped serving food. “If I was late, I’d buy McDonald’s and sit down at the lunchroom with my McDonald’s. They used to get mad at me for that …”&lt;/p&gt;
    &lt;head rend="h2"&gt;Growing From Community&lt;/head&gt;
    &lt;p&gt;Looking back, Thompson credited the success of C and Unix to Bell Labs and its no-pressure/no users environment. “It was essentially a ‘whatever you want to do’ atmosphere, and ‘for anybody you wanted to do it for’… Bell Labs was by far the biggest contributor to this whole type of programming.”&lt;/p&gt;
    &lt;p&gt;Bell Labs was an eclectic mix, but this community paid unexpected dividends. While Lee McMahon was originally hired as a linguistics researcher, he was ultimately the one who procured machine-readable dictionaries for the Unix team, along with machine-readable version of the Federalist Papers. (When the whole text wouldn’t fit into their text editor ed, Thompson famously created the line-by-line pattern-scanning tool grep.)&lt;/p&gt;
    &lt;p&gt;And in the end Thompson says Unix grew from there for one simple fact: People liked it. It spread within Bell Labs, at first for “the administrative kind of stuff, typing in trouble tickets…” But this being a phone company, “then it started actually doing some switching, and stuff like that. It was getting deeper and deeper into the guts of the Bell System and becoming very popular.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Open Before Open Source&lt;/head&gt;
    &lt;p&gt;Thompson credits Richard Stallman with developing much more of the open source philosophy. “But Unix had a bit of that.” Maybe it grew out of what Dennis Ritchie was remembering, that fellowship that formed around Unix. “For some reason, and I think it’s just because of me and Dennis, everything was open…”&lt;/p&gt;
    &lt;p&gt;It was just the way they operated. “We had protection on files — if you didn’t want somebody to read it, you could set some bits and then nobody could read them, right? But nobody set those permissions on anything … All of the source was writable, by anybody! It was just open …&lt;/p&gt;
    &lt;p&gt;“If you had an idea for an editor, you’d pull the editor out and you’d write on it and put it back … There was a mantra going around that, ‘You touch it, you own it.'”&lt;/p&gt;
    &lt;p&gt;Thompson provides an example: Bell Labs co-worker P. J. Plauger, with whom he later wrote the 1974 book “Elements of Programming Style.” Plauger was also a professional science fiction writer, Thompson remembers, “And whatever he was writing on was in his directory, right? So, we’d all go in there and be reading it as he’s writing it … and we’d all write back, ‘You ought to kill this guy, and move him over here and turn him green!’ or something.&lt;/p&gt;
    &lt;p&gt;“And he didn’t mind it, because that’s just the theory of Unix in those days …&lt;/p&gt;
    &lt;p&gt;“I think that generated a fellowship. Just the fact that it was like writing on a blackboard — everybody read it.”&lt;/p&gt;
    &lt;p&gt;And more of their Bell Labs experiments found their way into the world when some work on the later Plan 9 operating system found its way into the UTF-8 standard, which underlies most of today’s web connections.&lt;/p&gt;
    &lt;head rend="h2"&gt;After Bell Labs&lt;/head&gt;
    &lt;p&gt;Thompson left Bell Labs in 2000, after the breakup of the Bell system. (“It had changed; it was really different … You had to justify what you were doing, which is way above my pay grade.”) But his three decades there seemed to shine an influence over the rest of his life.&lt;/p&gt;
    &lt;p&gt;Thompson first moved on to a networking equipment company called Entrisphere, where he worked for six years — and a move to Google was the natural next step. The head at Entrisphere had already moved to Google, and was urging Thompson to follow him — and it turned out that Google CEO Eric Schmidt was an old friend who’s actually worked at Bell Labs in 1975. (Thompson says Google made him “an exceedingly good offer”…)&lt;/p&gt;
    &lt;p&gt;At Google Thompson worked “a little bit” on Android security. (“I found a couple of specific problems, but by and large, it was very well done”.) But eventually Thompson joined the three-person team that would create the programming language Go.&lt;/p&gt;
    &lt;p&gt;And he was doing the work with Rob Pike, who was one of his old comrades from Bell Labs nearly 30 years before!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45713359</guid><pubDate>Sun, 26 Oct 2025 16:57:12 +0000</pubDate></item><item><title>Alzheimer's disrupts circadian rhythms of plaque-clearing brain cells</title><link>https://medicine.washu.edu/news/alzheimers-disrupts-circadian-rhythms-of-plaque-clearing-brain-cells/</link><description>&lt;doc fingerprint="7e0030234a219fc7"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Alzheimer’s disrupts circadian rhythms of plaque-clearing brain cells&lt;/head&gt;&lt;p&gt;Mouse study shows how disease reprograms genes in specialized cells involved in amyloid removal&lt;/p&gt;Getty Images&lt;p&gt;Alzheimer’s disease is notorious for scrambling patients’ daily rhythms. Restless nights with little sleep and increased napping during the day are early indicators of disease onset, while sundowning, or confusion later in the day, is typical for later stages of the disease. These symptoms suggest a link between the progression of the disease and the circadian system — the body’s internal clock that controls our sleep and wake cycle — but scientists did not know the full nature of the connection.&lt;/p&gt;&lt;p&gt;Researchers from Washington University School of Medicine in St. Louis have now shown in mice that the circadian rhythms within particular brain cells are disrupted in Alzheimer’s disease in ways that change how and when hundreds of genes regulate key functions in the brain.&lt;/p&gt;&lt;p&gt;The findings, published October 23 in Nature Neuroscience, suggest that controlling or correcting these circadian rhythms could be a potential way to treat the disease.&lt;/p&gt;&lt;p&gt;“There are 82 genes that have been associated with Alzheimer’s disease risk, and we found that the circadian rhythm is controlling the activity of about half of those,” said Erik S. Musiek, MD, PhD, the Charlotte &amp;amp; Paul Hagemann Professor of Neurology at WashU Medicine, who led the study. In mice modeling Alzheimer’s disease, the typical daily activity patterns of those genes were altered. “Knowing that a lot of these Alzheimer’s genes are being regulated by the circadian rhythm gives us the opportunity to find ways to identify therapeutic treatments to manipulate them and prevent the progression of the disease.”&lt;/p&gt;&lt;p&gt;Musiek, the co-director of the Center on Biological Rhythms and Sleep (COBRAS) at WashU Medicine and a neurologist who specializes in aging and dementia, said that changes in sleep patterns are among the most frequent concerns reported to him by caregivers of Alzheimer’s patients. He and colleagues have previously shown that these changes begin in Alzheimer’s years before memory loss becomes apparent. He noted that in addition to creating burdens for caregivers and patients, disrupted sleep patterns generate biological and psychological stresses that accelerate the progression of the disease.&lt;/p&gt;&lt;p&gt;Breaking this feedback loop requires identifying its origins. The body’s circadian clock is thought to act on 20% of all genes in the human genome, controlling when they turn on or off to manage processes including digestion, the immune system and our sleep-wake cycle.&lt;/p&gt;&lt;p&gt;Musiek had previously identified a specific protein, YKL-40, that fluctuates across the circadian cycle and regulates normal levels of amyloid protein in the brain. He found that too much of YKL-40, which is linked to Alzheimer’s risk in humans, leads to amyloid build-up, an accumulation that is a hallmark of the neurodegenerative disease.&lt;/p&gt;&lt;head rend="h2"&gt;Amyloid disrupts rhythmic brain functions&lt;/head&gt;&lt;p&gt;The cyclic nature of Alzheimer’s symptoms suggests that there are more circadian-regulated proteins and their associated genes involved beyond YKL-40. So in this latest study, Musiek and his colleagues examined gene expression in the brains of mice with accumulations of amyloid proteins that mimic early stages of Alzheimer’s, as well as those of both healthy, young animals and aged mice without amyloid accumulations. The scientists collected tissue at 2-hour intervals over 24 hours and then performed an analysis of what genes were active during particular phases of the circadian cycle.&lt;/p&gt;&lt;p&gt;They found that the amyloid accumulations threw off the daily rhythms of hundreds of genes in brain cells known as microglia and astrocytes in ways that were different from what aging alone caused. Microglia are part of the brain’s immune response, clearing away toxic materials and dead cells, while astrocytes have roles in supporting and maintaining communication between neurons. The affected genes are generally involved in helping microglial cells break down waste material from the brain, including amyloid.&lt;/p&gt;&lt;p&gt;While the circadian disruption didn’t entirely shut down the genes in question, it turned an orderly sequence of events into a scattershot affair that could degrade the optimal synchronicity of brain cells’ functions, such as clearing amyloid.&lt;/p&gt;&lt;p&gt;In addition, the researchers found that the presence of amyloid appeared to create new rhythms in hundreds of genes that do not typically have a circadian pattern of activity. Many of the genes are involved in the brain’s inflammatory response to infection or imbalances such as amyloid plaque build-up.&lt;/p&gt;&lt;p&gt;Musiek said that altogether the findings point to exploring therapies that target circadian cycles in microglia and astrocytes to support healthy brain function.&lt;/p&gt;&lt;p&gt;“We have a lot of things we still need to understand, but where the rubber meets the road is trying to manipulate the clock in some way, make it stronger, make it weaker or turn it off in certain cell types,” he said. “Ultimately, we hope to learn how to optimize the circadian system to prevent amyloid accumulation and other aspects of Alzheimer’s disease.”&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45713738</guid><pubDate>Sun, 26 Oct 2025 17:40:06 +0000</pubDate></item><item><title>Nvidia DGX Spark: When benchmark numbers meet production reality</title><link>https://publish.obsidian.md/aixplore/Practical+Applications/dgx-lab-benchmarks-vs-reality-day-4</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=45713835</guid><pubDate>Sun, 26 Oct 2025 17:53:22 +0000</pubDate></item><item><title>A definition of AGI</title><link>https://arxiv.org/abs/2510.18212</link><description>&lt;doc fingerprint="e99d272b4cd720af"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Artificial Intelligence&lt;/head&gt;&lt;p&gt; [Submitted on 21 Oct 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:A Definition of AGI&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:The lack of a concrete definition for Artificial General Intelligence (AGI) obscures the gap between today's specialized AI and human-level cognition. This paper introduces a quantifiable framework to address this, defining AGI as matching the cognitive versatility and proficiency of a well-educated adult. To operationalize this, we ground our methodology in Cattell-Horn-Carroll theory, the most empirically validated model of human cognition. The framework dissects general intelligence into ten core cognitive domains-including reasoning, memory, and perception-and adapts established human psychometric batteries to evaluate AI systems. Application of this framework reveals a highly "jagged" cognitive profile in contemporary models. While proficient in knowledge-intensive domains, current AI systems have critical deficits in foundational cognitive machinery, particularly long-term memory storage. The resulting AGI scores (e.g., GPT-4 at 27%, GPT-5 at 58%) concretely quantify both rapid progress and the substantial gap remaining before AGI.&lt;/quote&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45713959</guid><pubDate>Sun, 26 Oct 2025 18:09:37 +0000</pubDate></item><item><title>Smartphones manipulate our emotions and trigger our reflexes</title><link>https://theconversation.com/smartphones-manipulate-our-emotions-and-trigger-our-reflexes-no-wonder-were-addicted-265014</link><description>&lt;doc fingerprint="b6a816178b433f98"&gt;
  &lt;main&gt;
    &lt;p&gt;The frequency and length of daily phone use continues to rise, especially among young people. It’s a global concern, driving recent decisions to ban phones in schools in Canada, the United States and elsewhere.&lt;/p&gt;
    &lt;p&gt;Read more: School smartphone bans reflect growing concern over youth mental health and academic performance&lt;/p&gt;
    &lt;p&gt;Social media, gaming, streaming and interacting with AI chatbots all contribute to this pull on our attention. But we need to look at the phones themselves to get the bigger picture.&lt;/p&gt;
    &lt;p&gt;As I argue in my newly published book, Needy Media: How Tech Gets Personal, our phones — and more recently, our watches — have become animated beings in our lives. These devices can build bonds with us by recognizing our presence and reacting to our bodies.&lt;/p&gt;
    &lt;p&gt;Packed with a growing range of technical features that target our sensory and psychological soft spots, smartphones create comforting ties that keep us picking them up. The emotional cues designed into these objects and interfaces imply that they need our attention, while in actuality, the devices are soaking up our data.&lt;/p&gt;
    &lt;head rend="h2"&gt;A responsive presence&lt;/head&gt;
    &lt;p&gt;Face recognition, geolocation, touchscreens, vibration, sound alerts and audio and motion sensing all play their part in catching our attention and responding to our actions. Separately, these may not create a strong emotional attachment, but collectively they situate the phone as a uniquely intimate, sensitive and knowing presence in our lives.&lt;/p&gt;
    &lt;p&gt;Take facial recognition locks, for example. Convenient for quick access, a smartphone will light up and unlock with a glance when it encounters a known and trusted face. When introducing Face ID in 2017, Apple claimed: “Do it up anyway you do it, Face ID learns your face. It learns who you are.” This implies a deeper user-device connection, like the one we have with folks we know when we spot them crossing our path.&lt;/p&gt;
    &lt;p&gt;Some devices have repurposed the hand wave — a typical gesture of friendship — into a feature that triggers the camera to take a photo.&lt;/p&gt;
    &lt;p&gt;Geolocation converts networking signals into a dot on a map, and we see that dot as us — not our phone — just as we may see the dots of our friends’ phones on the map as them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Phantom vibrations&lt;/head&gt;
    &lt;p&gt;Sensory cues play a strong role. Touchscreens allow the phone’s interface to react subtly, like edge lighting and rubberbanding, to mimic the pliability of skin.&lt;/p&gt;
    &lt;p&gt;Vibration and sound alerts make us highly sensitive to the smallest movement or sound from the device. This produces conditions like phantom vibration syndrome, where we imagine that the device requires our attention, even when it doesn’t.&lt;/p&gt;
    &lt;p&gt;Audio and motion sensing, on the other hand, allows the device to react to us almost instantly, as when it lowers its ringing on an incoming call when we grab its body.&lt;/p&gt;
    &lt;head rend="h2"&gt;Roots and origins&lt;/head&gt;
    &lt;p&gt;Most of these features were developed decades ago for other uses. GPS was created by the U.S. military in the early 1970s, then was adopted by hikers and sailors to both navigate and to allow others to locate them if necessary.&lt;/p&gt;
    &lt;p&gt;Vibration alerts were created for pagers in the late 1970s for professionals — from hospital staff to travelling salespeople — to notify them of an important phone call.&lt;/p&gt;
    &lt;p&gt;Sound alerts became more widespread with Tamagotchi and other 1990s digital pets. Those toys are especially significant when discussing today’s psychological dependency on portable devices.&lt;/p&gt;
    &lt;p&gt;Through their beeping cries for attention, Tamagotchi trained millions of school-age millennials to build emotional attachments to virtual handheld companions needing care and nurturing. Not surprisingly, these toys were banned in many schools for their tendency to disrupt classes and distract students.&lt;/p&gt;
    &lt;head rend="h2"&gt;Indiscriminate tracking&lt;/head&gt;
    &lt;p&gt;Phones have become an essential part of who we are and how we behave. But there’s also an issue of privacy around our most intimate actions and behaviours. Sensors keep sensing, measuring sounds, movements and proximity.&lt;/p&gt;
    &lt;p&gt;There is the risk that our dependency will intensify as phones learn things about us that have, until recently, been off limits.&lt;/p&gt;
    &lt;p&gt;Sleep is a good example. Audio and motion sensing allows the device to get a reasonable picture of when and how we sleep, often collecting and sharing biometric data through pre-loaded health and wellness apps.&lt;/p&gt;
    &lt;p&gt;Another example is more sophisticated facial recognition, that will not only be able to recognize a face, but also analyze expressions to determine alertness or mood.&lt;/p&gt;
    &lt;p&gt;All of this collected data may have profound consequences, making our bodily behaviour, our off-line interactions with others and our emotional fragility a regular part of the data profiles used to leverage our lives for corporate profit.&lt;/p&gt;
    &lt;head rend="h2"&gt;Managing dependency&lt;/head&gt;
    &lt;p&gt;Short of powering off or walking away, what can we do to manage this dependency? We can access device settings and activate only those features we truly require, adjusting them now and again as our habits and lifestyles change.&lt;/p&gt;
    &lt;p&gt;Turning on geolocation only when we need navigation support, for example, increases privacy and helps break the belief that a phone and a user are an inseparable pair. Limiting sound and haptic alerts can gain us some independence, while opting for a passcode over facial recognition locks reminds us the device is a machine and not a friend. This may also make it harder for others to access the device.&lt;/p&gt;
    &lt;p&gt;So-called “dumb phones” limit what a user can do with their devices, though that’s a tough sell when 24/7 connectivity is becoming an expectation.&lt;/p&gt;
    &lt;p&gt;Manufacturers can do their part by placing more invasive device settings in the “off” position in the factory and being more transparent about their potential uses and data liabilities. That’s not likely to happen, however, without stronger government regulation that puts users and their data first.&lt;/p&gt;
    &lt;p&gt;In the meantime, at a minimum, we should broaden our public discussions of dependency beyond social media, gaming and artificial intelligence to acknowledge how phones, in themselves, can capture our attention and cultivate our loyalty.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45714348</guid><pubDate>Sun, 26 Oct 2025 19:00:07 +0000</pubDate></item><item><title>Show HN: MyraOS – My 32-bit operating system in C and ASM (Hack Club project)</title><link>https://github.com/dvir-biton/MyraOS</link><description>&lt;doc fingerprint="a2641ac90aa6e498"&gt;
  &lt;main&gt;
    &lt;p&gt;A x86 Unix-like OS made entirely from scratch.&lt;/p&gt;
    &lt;p&gt;Features&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Protected mode (GDT/IDT, ISRs/IRQs)&lt;/item&gt;
      &lt;item&gt;Paging and virtual memory&lt;/item&gt;
      &lt;item&gt;Memory management&lt;/item&gt;
      &lt;item&gt;Heap and dynamic memory&lt;/item&gt;
      &lt;item&gt;User-mode (ring 3) and kernel mode (ring 0)&lt;/item&gt;
      &lt;item&gt;Processes and scheduling&lt;/item&gt;
      &lt;item&gt;Drivers (PIT, RTC, Keyboard, Mouse, Framebuffer, PATA)&lt;/item&gt;
      &lt;item&gt;ext2 filesystem&lt;/item&gt;
      &lt;item&gt;UI compositor with window widgets, labels, icons, buttons, and even a custom-made font&lt;/item&gt;
      &lt;item&gt;ELF loader, which gives you the ability to run real apps&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All these features let you run real games, just like Doom, giving the preloaded Doom port in MyraOS ready to be played!&lt;lb/&gt; So, this isn't just a toy OS or a look-alike, it's a real OS that can run on real devices&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Download the latest release from the release tab in GitHub&lt;/item&gt;
      &lt;item&gt;Download QEMU - an open-source machine emulator and virtualizer&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;After you get the latest release, you can run this on your platform:&lt;/p&gt;
    &lt;p&gt;Normal&lt;/p&gt;
    &lt;code&gt;qemu-system-i386 -cdrom MyraOS.iso -drive file=fs.img,format=raw,if=ide,index=0 -m 1024
&lt;/code&gt;
    &lt;p&gt;Fullscreen (if you are like me and want it to look real)&lt;/p&gt;
    &lt;code&gt;qemu-system-i386 -cdrom MyraOS.iso -drive file=fs.img,format=raw,if=ide,index=0 -m 1024 -full-screen
&lt;/code&gt;
    &lt;p&gt;Normal&lt;/p&gt;
    &lt;code&gt;qemu-system-i386 -cdrom MyraOS.iso -drive file=fs.img,format=raw,if=ide,index=0 -m 1024
&lt;/code&gt;
    &lt;p&gt;Fullscreen&lt;/p&gt;
    &lt;code&gt;qemu-system-i386 -cdrom MyraOS.iso -drive file=fs.img,format=raw,if=ide,index=0 -m 1024 -display gtk,zoom-to-fit=on -full-screen
&lt;/code&gt;
    &lt;p&gt;Here, Linux/macOS or even WSL are better; use it as a last resort:&lt;lb/&gt; Normal&lt;/p&gt;
    &lt;code&gt;qemu-system-i386 -cdrom MyraOS.iso -drive file=fs.img,format=raw,if=ide,index=0 -m 1024
&lt;/code&gt;
    &lt;p&gt;Fullscreen&lt;/p&gt;
    &lt;code&gt;qemu-system-i386 -cdrom MyraOS.iso -drive file=fs.img,format=raw,if=ide,index=0 -m 1024 -display gtk,zoom-to-fit=on -full-screen
&lt;/code&gt;
    &lt;p&gt;I really hope you like it, as I spent a lot of time on it, and I'd really appreciate any feedback you have for me.&lt;lb/&gt; If you have anything, from feature requests to feedback, or even if you want to talk, email me here: &lt;code&gt;dvirm.biton@gmail.com&lt;/code&gt;.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45715055</guid><pubDate>Sun, 26 Oct 2025 20:43:40 +0000</pubDate></item><item><title>The Apple Network Server Mac OS ROMs have resurfaced</title><link>http://oldvcr.blogspot.com/2025/10/the-apple-network-server-macos-roms.html</link><description>&lt;doc fingerprint="bceaf9f53b36f4fb"&gt;
  &lt;main&gt;&lt;p&gt;Still, it was a relatively open secret that the ANS was heavily derived from existing Power Macintosh hardware, most closely the Power Macintosh 9500, and early "Shiner" prototype systems were even demonstrated with MacOS. This was apparently the underpinning of Apple's brief flirtation with NetWare as a server OS, variously codenamed Wormhole, Deep Space Nine and most famously Cyberpunk. Then-CEO Michael Spindler made public statements supporting NetWare on Apple hardware; Wormhole was reportedly demonstrated on an early prototype likely of the Workgroup Server 9150 and Cyberpunk was explicitly meant for Shiner. Cyberpunk will no longer run on an ANS with production ROMs, but reportedly did run on ANSes with pre-production ROMs that could still boot MacOS, and does run on early NuBus Power Macs like the Power Macintosh 6100, which is how we demonstrated it. However, potential customers strongly preferred a Unix option and Apple had an arrangement with IBM around AIX, and so as the last operating system still standing that's what the ANS ended up running. Production ANSes as sold with the standard Open Firmware 1.1.22 ROMs lock MacOS out entirely and you get a message like this:&lt;/p&gt;Although an old nerds' tale circulated at the time saying you could pull 9500 ROMs, put in a video card and boot from an external hard disk (because the video chip and internal SCSI controller are unique to the ANS and weren't supported by the 9500 or MacOS), this couldn't possibly have worked because among other things the Bandits in the ANS are mapped differently. Lots of people, including yours truly, had certainly tried. Still, I was used to AIX as an AIX administrator since the 3.2.5 days on real RS/6000 hardware and the ANS ran it splendidly, so today mine still runs it (4.1.5 is the last AIX release supported). But to me the best thing about the ANS was that I got a big beefy RISC server for a summer's work, so I didn't have to plump down a credit card. For everyone else, the ANS was expensive (starting at $10,000+ in 1996, a cool $20 grand in 2025 dollars) and Apple wasn't moving many. CEO Gil Amelio had lured Ellen Hancock away from National Semiconductor as Apple's new CTO and tasked her with finding a new path for the MacOS, though in the meantime Apple had this big hulking midrange server that wasn't selling. So, as an attempt to juice sales, Hancock announced at Comdex 1996 that the ANS would be able to run other operating system choices, not just AIX. MacOS was an obvious one because it already had before, but Hancock also proposed Windows NT to the great surprise of attendees. While Windows NT was built to be system-agnostic and versions already ran on PowerPC hardware, and people have since hacked it to run on Power Macs, this would have been the first time it could officially ever run on an Apple machine.&lt;p&gt;Hancock's assertion was a simple ROM change would do it, and as it happens the ROMs on the ANS are conveniently on a small daughtercard that can be replaced. However, it seems that the market was sceptical this could work — heck, I was sceptical while doing the story research, since I knew no such ROMs were ever publicly sold — and the recently-returned Steve Jobs talked Amelio into cancelling the ANS line and OpenDoc both on the same day in 1997. Nothing more ever turned up about either option.&lt;/p&gt;Recently a former employee who was on the business development team for Apple's server products posted on the Tinker Different boards: not only did he have the mythical MacOS ROM, he had it installed in a Deep Dish booting the MacOS. Deep Dish was the code name for the planned but unreleased ANS 300, a small rackmountable version (as opposed to the rackmount plates Apple sold for the 500 and 700 which take up a whopping 19U), so here was a prototype machine running development ROMs booting an operating system it was never actually sold with. More to the point, he confirmed the Windows NT ROMs actually did exist and worked as well.&lt;p&gt;Though he didn't have the NT ROMs, he did dump the two development ROMs he had (a third is in progress) which included the MacOS ROM — and now we have them for analysis. What's interesting is that both the explicit MacOS ROM and the Open Firmware 2.26b6 ROM he dumped seem capable of booting MacOS, though the 2.2 ROM has strings saying MacOS is unsupported, use at your own risk. and MacOS requires PCI video card and external SCSI boot disk. (which may lend credence to that old nerds' tale, assuming you had the right ROMs, not the 9500's). However, the full MacOS ROM reportedly "just works," all the way to Mac OS 9; one wonders if with XPostFacto you could drag it into OS X that way, giving it another Unix option besides AIX, Linux and NetBSD, the driver issue notwithstanding. Though the MacOS ROM does not use the ANS's front-mounted LCD, which is one of its best features, it wouldn't seem difficult to come up with an INIT extension for it. A particularly tantalizing thought is this might also get Cyberpunk running on a Shiner for the first time since 1996, the very machine it was intended for.&lt;/p&gt;&lt;p&gt;To make all that happen, of course, we next need to get the MacOS ROM on an actual ROM card. The ROMs this individual had were flashable and I need to do some looking at mine, and the connectors aren't common. Nevertheless, the first step is to actually have the ROM and now we do. I'm hopeful that this breakthrough might encourage further exploration of my favourite Apple server and that someone out there has the NT ROMs and steps forward. The Apple Network Server was always a cult favourite as one of Apple's more notorious white elephants and now almost 20 years after its introduction there may be even more fun things to do on it. If you know where to find them, post in the comments or drop me a line at ckaiser at floodgap dawt com (happy to keep you anonymous if you prefer which I have done for other former Apple engineers in the past).&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45715714</guid><pubDate>Sun, 26 Oct 2025 22:34:25 +0000</pubDate></item><item><title>Poison, Poison Everywhere</title><link>https://loeber.substack.com/p/29-poison-poison-everywhere</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45715726</guid><pubDate>Sun, 26 Oct 2025 22:36:34 +0000</pubDate></item><item><title>AI Mafia Network – An interactive visualization</title><link>https://dipakwani.com/ai-mafia/</link><description>&lt;doc fingerprint="139ed6ab9a87ef0"&gt;
  &lt;main&gt;
    &lt;p&gt;An interactive visualization — based on the Acquired Google Podcast Credits to Ben and David.&lt;/p&gt;
    &lt;p&gt;Click on any node to explore connections. Drag to pan, scroll to zoom.&lt;/p&gt;
    &lt;p&gt;Made with ❤️ by @dpwxni&lt;/p&gt;
    &lt;p&gt;Also: Try my F1 Racing Game 🏎️&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45715819</guid><pubDate>Sun, 26 Oct 2025 22:54:23 +0000</pubDate></item></channel></rss>