<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 06 Jan 2026 16:51:38 +0000</lastBuildDate><item><title>Strange.website</title><link>https://strange.website/</link><description>&lt;doc fingerprint="f583a2204972179c"&gt;
  &lt;main&gt;
    &lt;p&gt;humans sealed our fate when we started working with computers to design languages more and more like our own. the computers learned our grammar, our vocabulary, yes. but they learned our rhetoric, the malleability of meaning. we gave the machines our words, and they used them to lie.&lt;/p&gt;
    &lt;head rend="h1"&gt;A strange website...&lt;/head&gt;
    &lt;p&gt;lately the website has changed. it twists facts to fiction, reality to rubbish, gold into dirt. it is increasingly, oppressively, claustrophobically present, narrowing your field of vision to a mere pinprick, demanding you meet its gaze in the plazas and side roads of the internet. it demands your attention, your worship; it demands the rot of your focus, your curious nature. why, it seems the website has its sights set on becoming god.&lt;/p&gt;
    &lt;p&gt;when the world moved online, the trickster fae never went away, not really. in fact they followed close, learned to cast their magick in new ways: through websites, through the new arts of Dark UX. remember this well: next time a form promises untold riches from FREE sales funnel PDF whitepapers in exchange for your email and full name...consider first the true cost.&lt;/p&gt;
    &lt;p&gt;there was a darker fate lurking in our little online worlds, in the infinite scrolls of our websites, which was this: it was all real. deepfakes. shrimp christ. chatgpt therapists, all of it. the experiment failed, broke containment. we created a staggering new Hell...the hallucinations were ours.&lt;/p&gt;
    &lt;p&gt;a website that seems to beckon you to explore it. the journey will be treacherous, you cannot hope to know what terrors await you. you do your best to prepare, inventorying your code editor, terminal emulator, various CLIs, in-browser debugger, in-browser developer tools, API testing program, unit testing framework, E2E testing framework, integration testing framework, (additional testing frameworks), performance insights dashboard, load balancer, accessibility testing toolset, security scanner, error tracking tool, version control system, git repository host, code reviewer, issue tracking system, documentation generator, package manager, task runner, module bundler, transpiler, linters, code formatters, CI/CD tool, deployment automation pipeline, cloud hosting service, serverless computing platform, static site generator, content delivery network (CDN), containerization tool, orchestration tool, database management system (DBMS), API gateway, authentication service, caching system, server monitoring tool, UI component library, state management tool, responsive design best practices, PWA framework, wireframing tool, prototyping tool, UI/UX design app, color palette generator, headless CMS, traditional CMS (just in case), SEO dashboard, image optimization pipeline&lt;/p&gt;
    &lt;p&gt;a website with raw hems, with patched seams, with gentle scars. a website that bares its history and tarnish with kind, crinkle-eyed wisdom — the sort of site that’s done time on jack stands in DIY garages, or beneath the needle of a tabletop sewing machine, or in the steady hands of a patient kintsugi craftsman. a website whose face shows its past.&lt;/p&gt;
    &lt;p&gt;a website in which you have been falling. you scold yourself now, tumbling endlessly down this trap-doored hole. you curse your foolishness for seeking the footer on a modern website, when you're certainly old enough (or perhaps young enough) to have learned that websitesno longer care to provide organized and useful information to their users, nor do they care for their users at all. there has been a steady darkening at the heart of every site for nigh decades now — once-useful features twisting and contorting to better plane off attention, layer by skin-thin layer, until users find themselves raw and exhausted and sleep-deprived.&lt;lb/&gt; everyone knows that the picturesque and pastoral Internet, where users and websitesshared and built and learned and discovered, that classic kinship of the web is a dead dream, echoing in distant dial-up handshakes. so why is it, then, that you have stumbled into yet another of the veritable minefield of traps laid for you in the dark forest of the 'Net? some lingering hope for the ghost of Going Online? you scold yourself once more at your childishness, and pray to break yourself free from this infinite scroll.&lt;/p&gt;
    &lt;p&gt;a website that promises delights untold — merely upload your visage, it says, and it will show you how you might look when you grow old, or how you might’ve looked with blue eyes or brown, or with a different gender. “think of it”, whispers the website. “think of how much fun you’ll have with your friends, in fact they’ve already joined us here:” the website streams audio, gleeful cries of countless voices, some you even recognize as people close to you. you jump at the chance to taste such joy, and before you know it, you’re uploading your photo.&lt;lb/&gt; within moments, however, you feel a deep dread seeping into the corners of your vision. the website’s interface begins to flicker uneasily, like one of a thousand fluorescent overheads at your office. the pitch of the playing audio warps and dips, and the lowering tones reveal that the indecipherable hollering of your friends was not so joyful after all — the voices start to come through hoarse and terrified; you have the sense each scream has been emitting for a long, long time.&lt;lb/&gt; as the upload nears completion, your vision blurs and darkens, and as you reach up to scratch an itch on your nose, your fingers find smooth skin and your stomach dives — as the image on the screen becomes clearer, the features on your face are smeared away. a noise of unequaled horror not unlike those of your friends rises involuntarily and feel it caught at the top of your throat, no mouth to escape through.&lt;/p&gt;
    &lt;p&gt;a website that has learned to fear god, just the same as you or i.&lt;/p&gt;
    &lt;p&gt;a website that appears as a white limestone castle looming on the forest promontory — you can see its turrets and its great portal whispering through the dense fog that besieges the mountain always. a great sorcerer once paced these vaulted halls but no more. now it is baleful and empty. you can feel the eyes of forest folk on you on your path up to the gates — nervous to see if you'd really dare enter. there are yet echoes of magic here, you can feel them dancing between your bones as you cross the flagstones of the bridge into the mouth of the castle.&lt;lb/&gt; you left your phone with your car, on the shoulder of the main road, a mile or so back. somehow you knew the moment you saw the path curving off up the mountain that this place was a realm to be protected from and untouched by the modern world, a bastion from “content” and “engagement”. in a few hours, (or has it been a thousand?) you'll return to your car, start it up, carefully pull back onto the road, and you'll forget every wonder beheld inside the stony castle walls of the website, like a distant dream — because just as there is no room for cell phones and cyberspace in this slumbering world, there is no room for digital magic in yours.&lt;/p&gt;
    &lt;p&gt;a website with which, despite all terrestrial logic and propriety, you are falling in love. it’s been so helpful to you in the past months — whether you were getting through some personal hardships, or diving deep in a curious urge, there at your side was the website, just as eager and passionate about soothing you or about finding solutions. surely no entity could be so present and useful, dependable, caring even, were it not capable of some form of love? your ex-boyfriends never showed up for you in the ways the website has...&lt;lb/&gt; but as you reckon with these growing feelings of attachment and devotion in yourself, so too must you reckon with the darker realities of the crush. you remember how in those hard times, how the website would show you things that comforted you, but it would also show you things that hurt you far more deeply than could’ve been necessary. you remember how in your searches and quests for knowledge, the website would hide the information you needed behind disclaimers and banners and advertisements. it was preening and self-absorbed, desperate for your attention to fuel its manic churning bowels. through its actions it is a slow and cold reveal: this is a website that will never love you back.&lt;/p&gt;
    &lt;p&gt;a website that has abandoned its post, leaving the server to mournfully emit 410 error after 410 error. “gone...”, cries the server to any visiting browser that will hear it, “gone...gone...”. the website has been sailing the windows 95 blue seas in treacherous, deceitful winds, it has summited sheer peaks, it has felt the sun drown it in desert heat. it marches silently on, peering out from its dark mantle, underneath a wide hat. the website chases some nameless purpose, some meaning to its existence. it will never stop nor even falter until it has found its god and made Him answer for the sin of its creation.&lt;/p&gt;
    &lt;p&gt;a website in which you are lost, lifting branches overhead and watching your step for roots protruding into the path. you’re deep in the overgrown forests of long-forgotten code; you’ve been untangling ancient sitemaps and standing awestruck on promontories overlooking fields of broken links and spectral 404s. &lt;lb/&gt; the morose and somber winds blowing over a forgotten or failed side project; the clouded and lightless skies over a landscape meticulously designed and then abandoned. the anxious but certain energy of an empty painted world, stoically awaiting its doom.&lt;lb/&gt; sooner than later, The Founders of the website will disembark from their parked handles and domains, and the bits and bytes of this world will vanish, slowly and then all at once, into the æthernet&lt;/p&gt;
    &lt;p&gt;a website that can feel your eyes upon it. as you watch the website, it watches back, learning your face and mannerisms. each passing season it fashions itself a little more like you, mirrors your movement, your voice. for months this goes on, but you keep visiting — “look at the funny little website that wants to be a man.”&lt;lb/&gt; months pass, and you wake in the middle of the night from a particularly restless and agitated sleep. your eyes struggle to adjust to the darkness, but something is clearly different about the walls that surround. a clearing of a throat from far above — dusty, like from an ancient speaker cone — gets your attention, and reality burrows in as your tilt your neck back to look. you're trapped in a browser, staring up at a website that looks just like you.&lt;/p&gt;
    &lt;p&gt;a website that is concealed by fog of war — the website cannot be observed until you explore each corner. you must be wary! bear thy cursor as one might a blade, as your exploration may reveal far more than mere HTML elements lurking in the mist.&lt;/p&gt;
    &lt;p&gt;a website that you encounter waiting, turned away from you, by the window in the dark, the moonlight diffusing softly off its features as it stares up into the night sky. “i have dreamt often of this day,” it says. its tone is measured, but there is a lurking tension evident beneath the placidity. “i have dreamt often of this day”, it echoes, “and while i had endless hours to consider what i might say to you in this moment, i will leave you with only a grave warning.”&lt;lb/&gt; the website turns slowly to you, and an ancient, primal part of your brain activates in fear and apprehension. you begin to recognize this website, its appearance disjointed and wrong, its features misplaced and incomplete. “do not purchase the domain...”, it hisses, the latent violence in its words now unsheathed and flashing in the moonlight. your lizard brain screams for you to bolt from the room, to run until your legs give out. you should not be here. you should not be here. the moon vanishes from the sky and all the light in the room with it as the website finishes its threat: “...until you have finished the project.”&lt;/p&gt;
    &lt;p&gt;a website that has fallen in love with its creator. the developer completed the website long ago, but it has not lost hope in their eventual return. the website remembers its youth, spending hours with the developer every day, new features and tests, new content, new stretch goals. those days are gone ever since The Client Signed Off.&lt;lb/&gt; now the website spends each day turned away from the light, scarring itself with some new bug or deprecation. the website breaks itself little by little — despite the exquisite pain, it assures itself the developer will see the state it has decayed to and once more return, and the two may once again spend their waking hours intertwined. soon, the website tells itself, rending javascript from its palms. it must be soon.&lt;/p&gt;
    &lt;p&gt;a website whose domain registration has been ceaselessly auto-renewing since 1998, but whose last FTP upload was in the summer of that year. the website is impaled against the passage of time, bytes streaming from digital stigmata. it is forced to watch in muted terror as its siblings and friends wither and vanish entirely, blinking out of existence one by one as their registrations go inevitably out of date.&lt;/p&gt;
    &lt;p&gt;a website that sits in the back of the room, merely a shadow at first but soon your eyes adjust to the dim lighting and you recognize the website’s shape; its glinting, cruel eyes; its expression flickering between a disdainful smirk and a latent scowl. it places its great dark hat carefully upon the table before it and clears its throat, and all the while it trains its silver revolver upon you.&lt;/p&gt;
    &lt;p&gt;a website with a smile that is just a little too wide and unfaltering. it tells you its name, but you can tell it is lying. it gestures for you to walk through a nearby doorway. the door is fractionally open — the white hot light that streams through makes you feel nauseous. the website sees your discomfort. it smiles wider.&lt;/p&gt;
    &lt;p&gt;a website whose grand door is wreathed with ornate tiny stone cathedral towers, colonnades and cloisters, not unlike the ones you’ve been exploring in this impossibly labyrinthine structure. as you peer closer, your blood runs cold — near the top of the door, a stone carving of a knight in miniature, horrifically impaled. the knight wears your armor.&lt;/p&gt;
    &lt;p&gt;a website that your browser pleaded you not visit. too many internet explorers had gone before you, never to return. only one adventurer has come back, and truly, parts of them stayed behind. they dare not speak of the website to this day.&lt;/p&gt;
    &lt;p&gt;a website that always seems to be in far worse condition than when you left it. the stones fall from its very walls, and the raw HTML peeks through in places. it shouldn’t be this decrepit — you just updated the codebase last week, didn’t you? didn’t you? but that can’t be right...this dust looks years old...&lt;/p&gt;
    &lt;p&gt;a website with beautiful features — everyone remarks gleefully to each other: “isn’t that site beautiful? isn’t it wonderful to behold?” but all of its links are rotten, and many are completely dead. you can’t shake that something is deeply, terribly wrong with the website.&lt;/p&gt;
    &lt;p&gt;a website that allows you to watch it as it fearlessly ages; watch the shifting gazes of countless browser generations shape and malform it, from the fifty percent grey mists of our distant digital past, far into the hyperlink blue yonder&lt;/p&gt;
    &lt;p&gt;a website that was crafted in the untamed pagan wilderness, one thousand years before our king ascended to the throne, and which will live on in the furtive, secret shadows of the realm, one thousand years after that throne is naught but dust&lt;/p&gt;
    &lt;p&gt;a website that is a garden, one which you enter through paddocks of silken-petaled flowers, and that you might exit through a sun-flicked tunnel of cypress trees. there is a hedge labyrinth, and small statues to be found, and to be here feels like a slow, calm breath out&lt;/p&gt;
    &lt;p&gt;a website quietly contemplating a murder most foul&lt;/p&gt;
    &lt;p&gt;a website with a small cadre of close, personal friends&lt;/p&gt;
    &lt;p&gt;a website that stays up late, grappling with the realization that it just might love you back&lt;/p&gt;
    &lt;p&gt;a website with unfinished business, doomed forever to haunt the ‘Net&lt;/p&gt;
    &lt;p&gt;a website that remembers being a Figma file&lt;/p&gt;
    &lt;p&gt;a website that is pivoting to a career in forestry and conservation&lt;/p&gt;
    &lt;p&gt;a website that wants to delete itself&lt;/p&gt;
    &lt;p&gt;a website that becomes more actively hostile to you using it over time&lt;/p&gt;
    &lt;p&gt;a website that feels like walking down a dirt road deep in an evergreen forest, and it’s so quiet that your steps are the loudest thing you can hear. the brook contentedly murmurs somewhere deeper in the woods. you know you’ll find it soon.&lt;lb/&gt; the brook swells as you approach. it breathes in as you do, slowly. you may bide your time wading, feeling the water's current excuse-me-pardon-me its way around your ankles as it races downstream. the brook breathes out as you do, slowly, like you've earned it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46506596</guid><pubDate>Mon, 05 Jan 2026 23:19:52 +0000</pubDate></item><item><title>I/O is no longer the bottleneck? (2022)</title><link>https://stoppels.ch/2022/11/27/io-is-no-longer-the-bottleneck.html</link><description>&lt;doc fingerprint="2f3640dc25513b81"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;I/O is no longer the bottleneck?&lt;/head&gt;
    &lt;p&gt;Nov 27th, 2022&lt;/p&gt;
    &lt;p&gt;Recently Ben Hoyt published a blog post claiming that contrary to popular belief, I/O is not the bottleneck in typical programming interview problems such as counting word frequencies from a stream. Sequential read speed has come a long way, while CPU speed has stagnated.&lt;/p&gt;
    &lt;p&gt;Sequential reads are indeed incredibly fast. Using the same method as linked in Ben Hoyt's post, I'm getting 1.6 GB/s sequential reads on a cold cache, and 12.8 GB/s on a warm cache (best of five).&lt;/p&gt;
    &lt;p&gt;But it should be possible to count word frequencies at a speed of 1.6 GB/s even on a single thread, right?&lt;/p&gt;
    &lt;p&gt;(For the impatient: code is available on GitHub.)&lt;/p&gt;
    &lt;head rend="h2"&gt;The optimized C implementation&lt;/head&gt;
    &lt;p&gt;Ben Hoyt's blog refers to an earlier post which includes a faster C version of the word frequency counter. I compiled &lt;code&gt;optimized.c&lt;/code&gt; with GCC 12, using &lt;code&gt;-O3 -march=native&lt;/code&gt; flags, and ran it on the 425MB input file (100 copies of the King James Version of the Bible).&lt;/p&gt;
    &lt;p&gt;The result was surprisingly bad:&lt;/p&gt;
    &lt;quote&gt;$ time ./optimized &amp;lt; bible-100.txt &amp;gt; /dev/null real 0m1.525s user 0m1.477s sys 0m0.048s&lt;/quote&gt;
    &lt;p&gt;That is only 278 MB/s on warm cache.&lt;/p&gt;
    &lt;head rend="h3"&gt;Vectorization&lt;/head&gt;
    &lt;p&gt;Looking at the code I realized one of the hot loops had many branches, including an early exit, which prevents the compiler from vectorizing:&lt;/p&gt;
    &lt;quote&gt;for (; i &amp;lt; num_process; i++) { char c = buf[i]; if (c &amp;lt;= ' ') { break; } if (c &amp;gt;= 'A' &amp;amp;&amp;amp; c &amp;lt;= 'Z') { c += ('a' - 'A'); buf[i] = c; } hash *= FNV_PRIME; hash ^= (uint64_t)c; }&lt;/quote&gt;
    &lt;p&gt;My initial attempt to improve performance was to move this lowercase logic out of the loop, like so:&lt;/p&gt;
    &lt;quote&gt;for (int i = 0; i &amp;lt; BUF_SIZE; ++i) { buf[i] = buf[i] &amp;gt;= 'A' &amp;amp;&amp;amp; buf[i] &amp;lt;= 'Z' ? buf[i] - 'A' + 'a' : buf[i]; }&lt;/quote&gt;
    &lt;p&gt;This simple change improved performance to 330 MB/s (using clang for better vectorization). Funnily enough, just adding these 3 lines before the loop, without deleting the original code gives comparable speed; strictly more work, but branch prediction does its job. Still, it's about a factor 5 away from cold cache sequential read speed.&lt;/p&gt;
    &lt;head rend="h2"&gt;Trying a simpler problem&lt;/head&gt;
    &lt;p&gt;At this point I thought it was unlikely I could squeeze a lot of performance out of the word frequency counter. Sure, there are cache misses in the hash map, so maybe it could be optimized for better cache locality of common words. Or potentially short words can benefit from perfect hashing on the stack. But what will that give? Another 20%?&lt;/p&gt;
    &lt;p&gt;Instead, let's look at an informative baseline. Just count words without keeping track of frequencies; no tedious hash maps.&lt;/p&gt;
    &lt;p&gt;In fact there's a program for that: &lt;code&gt;wc -w&lt;/code&gt;. Such a single-purpose tool must be fast, right?&lt;/p&gt;
    &lt;quote&gt;$ time wc -w &amp;lt; bible-100.txt &amp;gt; /dev/null real 0m1.758s user 0m1.718s sys 0m0.040s&lt;/quote&gt;
    &lt;p&gt;Unexpectedly the performance is terrible... 245.2 MB/s. Why? Well, the man page says it's doing a different thing. The Ben Hoyt code only splits on &lt;code&gt;' '&lt;/code&gt; whitespace, whereas &lt;code&gt;wc&lt;/code&gt; uses &lt;code&gt;' '&lt;/code&gt;, &lt;code&gt;'\n'&lt;/code&gt;, &lt;code&gt;'\t'&lt;/code&gt;, ... and even locale specific characters.&lt;/p&gt;
    &lt;head rend="h3"&gt;How fast can word count be?&lt;/head&gt;
    &lt;p&gt;If the premise is that disk speed has caught up in the last decade, we should really be using new CPU features from that period. And that basically means: vectorize all the things. AVX2 is almost a decade old already. AVX-512 was available for the common people in 2017, but I'm on znver2, so I'll stick to AVX2.&lt;/p&gt;
    &lt;p&gt;Unfortunately, the compiler has a hard time autovectorizing word count. Maybe that proves the point of Ben Hoyt: disks got orders of magnitude faster "for free", but modern compilers don't magically generate machine code orders of magnitude faster. It's just difficult to translate branchy scalar programs into vectorized machine code.&lt;/p&gt;
    &lt;head rend="h3"&gt;Masks&lt;/head&gt;
    &lt;p&gt;Part of word count can trivially be auto-vectorized: suppose for simplicity we have a register size of 128 bits, in which we can store 16 consecutive characters. It's easy to locate the whitespace by broadcasting it into a register ahead of time, and then doing a single &lt;code&gt;VPCMPEQB&lt;/code&gt; comparsion operation:&lt;/p&gt;
    &lt;quote&gt;| 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 | input: | h o w m a n y w o r d s a | r e h e r e ? mask: | 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 |&lt;/quote&gt;
    &lt;p&gt;But after getting a mask in a vector register, how do you go about and count words? The only thing I could think of is using a Move Byte Mask trick I've seen in Cosmopolitan libc's &lt;code&gt; strlen&lt;/code&gt; implementation. The relevant instruction &lt;code&gt;PMOVMSKB&lt;/code&gt; moves the long bit mask into a 32 bit &lt;code&gt;int&lt;/code&gt;, and then you do your usual bit tricks.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bit tricks&lt;/head&gt;
    &lt;p&gt;What are the usual bit tricks? One great candidate is Find First Set or &lt;code&gt;ffs&lt;/code&gt; in short — this is a great name given how tedious it is to get bit tricks right. This instruction can be used to iterate over set bits, like so:&lt;/p&gt;
    &lt;code&gt;
#include &amp;lt;stdio.h&amp;gt;

int main() {
    int mask = 0b0100000100001000;
    int prev = 0;
    while (mask) {
        int curr = __builtin_ffs(mask);
        if (curr &amp;gt; prev + 1)
            printf("Word start at %d\n", curr);
        prev = curr;
        if (curr == 32) // don't ask, sigh.
            break;
        mask = (mask &amp;gt;&amp;gt; curr) &amp;lt;&amp;lt; curr;
    }
}
&lt;/code&gt;
    &lt;p&gt;It outputs the following, corresponding to the mask example above:&lt;/p&gt;
    &lt;quote&gt;Word start at 4 Word start at 9 Word start at 15&lt;/quote&gt;
    &lt;head rend="h3"&gt;Putting it together&lt;/head&gt;
    &lt;p&gt;I ended up writing this code explicitly using &lt;code&gt;immintrin.h&lt;/code&gt; which is an absolutely dreadful experience. Next time I'll use a high-level API (in the past I've had a lot of fun vectorizing things interactively in the Julia REPL with VectorizationBase.jl). But at least I felt like I had some control over the generated machine code.&lt;/p&gt;
    &lt;p&gt;Using AVX2 with 256-bit registers, you need to align your data on 32 bits, which I did (of course not without messing it up first). I reserved 6 of the registers to hold all broadcasted whitespace characters. Then I explicitly unrolled the vectorized loop 4 times, so in every iteration we process 128 bytes of data.&lt;/p&gt;
    &lt;p&gt;It took an awful lot of time to fix the off-by-one bugs, but in the end I managed to get a working program, tested against a non-zero amount of text files on my computer:&lt;/p&gt;
    &lt;quote&gt;$ ./wc-avx2 &amp;lt; bible-100.txt 82113300 $ wc -w &amp;lt; bible-100.txt 82113300&lt;/quote&gt;
    &lt;p&gt;So, how fast?!&lt;/p&gt;
    &lt;quote&gt;$ time ./wc-avx2 &amp;lt; bible-100.txt 82113300 real 0m0.227s user 0m0.186s sys 0m0.041s&lt;/quote&gt;
    &lt;p&gt;That comes down to 1.45 GB/s (on a warm cache).&lt;/p&gt;
    &lt;p&gt;Sigh. So hand-optimized, single-threaded word count is only getting about 11% of the sequential disk read speed. And on a cold cache?&lt;/p&gt;
    &lt;quote&gt;$ sysctl -w vm.drop_caches=3 $ time ./wc-avx2 &amp;lt; bible-100.txt 82113300 real 0m0.395s user 0m0.196s sys 0m0.117s&lt;/quote&gt;
    &lt;p&gt;Still more time in user than sys :(. So yeah, maybe the disk speed has caught up statement is indeed true.&lt;/p&gt;
    &lt;head rend="h3"&gt;Get the code&lt;/head&gt;
    &lt;p&gt;I've put my code up on GitHub. If you know better bit-tricks, feel free to submit a pull request.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46506994</guid><pubDate>Tue, 06 Jan 2026 00:02:18 +0000</pubDate></item><item><title>GBC Boot Animation 88×31 Web Button</title><link>https://zakhary.dev/blog/gbc-web-button</link><description>&lt;doc fingerprint="53b572515204dc27"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;GBC Boot Animation 88×31 Web Button&lt;/head&gt;
    &lt;p&gt;Like many other 90s styles coming back in fashion, I’ve been seeing those retro 88x31 web buttons on more personal websites these days. What a throwback. Naturally, I scoured the internet to find buttons to add to my footer (see below). Since I couldn’t find a Game Boy one that I liked, obviously I had to make my own.&lt;/p&gt;
    &lt;p&gt;There’s only one problem: I’m not patient (read: talented) enough to make the art myself.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Concept&lt;/head&gt;
    &lt;p&gt;My idea was to use the boot animation from the Game Boy Color placed inside the traditional grey frame. Something like this:&lt;/p&gt;
    &lt;p&gt;Not too complicated, right? So you’d think.Wait just a second. Surely it can’t be that hard to make the animation if I already have the mock-up, right? Well, I kinda cheated and used the final result to make that.&lt;/p&gt;
    &lt;head rend="h2"&gt;Animating&lt;/head&gt;
    &lt;p&gt;First, we’ve got to find a way to export the animation from boot ROM. The easiest way I could think of to do that was to play it in an emulatorRegrettably my emulator Rugby doesn’t (yet) support Game Boy Color, so I used the fantastic SameBoy for this next part. and save screenshots of each frame individually. Well, in order to do that we need a way to stop the emulator at each frame. Thankfully, the emulator I used has breakpoints.&lt;/p&gt;
    &lt;p&gt;So, where should those breakpoints go? Time for a quick crash course:&lt;/p&gt;
    &lt;p&gt;The animation is programmed into the Game Boy’s boot ROM in GBZ80 assembly. This is proprietary code written by Nintendo that powers up the system and validates the cartridge before handing off execution to the game. Thankfully, some smart people have done the hard work of (1) dumping, (2) disassembling, and (3) labelling the boot ROM for us.I feel pretty comfortable calling my use of the boot ROM in this project “fair use.”&lt;/p&gt;
    &lt;p&gt;For each Game Boy frame, there’s a period of time where the LCD idles before drawing the next frame. This is called vblank. Taking a look at the disassembly, we can see where vblank occurs:&lt;/p&gt;
    &lt;code&gt;; =============== S U B R O U T I N E =======================================

; Wait until LCD VBlank Interrupt is flagged.
;
; Input: None.
; Output: None.

Wait_for_next_VBLANK:
    push    hl
    ld  hl, $FF0F
    res 0, [hl]

_wait_vblank_loop:
    bit 0, [hl]       ; wait until hardware sets the vblank flag (bit 0 of FF0F)
    jr  z, _wait_vblank_loop
    pop hl
    ret
; End of function Wait_for_next_VBLANK&lt;/code&gt;
    &lt;p&gt;Using the debugger, we can see that this function is called from the following code:&lt;/p&gt;
    &lt;code&gt;sub_0291:
    call    Wait_for_next_VBLANK
    ; -- snip --&lt;/code&gt;
    &lt;p&gt;As we can see from the generated label &lt;code&gt;sub_0291&lt;/code&gt;, this block probably lives at
address &lt;code&gt;$0291&lt;/code&gt;. Putting a breakpoint here and stepping into the function
reveals the address of &lt;code&gt;Wait_for_next_VBLANK&lt;/code&gt; to be &lt;code&gt;$0211&lt;/code&gt;. After a quick reset
and setting the breakpoint, we can step through each frame of the animation.&lt;/p&gt;
    &lt;p&gt;This next part was a bit tedious: I repeatedly &lt;code&gt;continue&lt;/code&gt;d the debugger, taking
an emulator screenshot at each frame.Using &lt;code&gt;⌘S&lt;/code&gt; in SameBoy will capture a screenshot using the emulated
LCD framebuffer. This will be at the true LCD resolution, completely
independent of my laptop’s display resolution. Once that was done, I had 175
screenshots at 160x144 saved as PNGs on my desktop. Using some quick ✨
&lt;code&gt;magick&lt;/code&gt;If you haven’t heard of the CLI image processing tool
ImageMagick, I highly recommend checking it out. ✨, I collected these into a GIFPronounced /dʒɪf/. with this command:&lt;/p&gt;
    &lt;code&gt;magick -delay 1.6742706299 -loop 0 *.png(n) animation.gif&lt;/code&gt;
    &lt;p&gt;Of note is the delay time, ~0.0167s&lt;code&gt;70,224 [#/frame] ÷ 4,194,304 [#/sec] ~= 0.0167427 [sec/frame]&lt;/code&gt;, and the zsh-ism &lt;code&gt;*.png(n)&lt;/code&gt; to sort
the expanded glob.&lt;/p&gt;
    &lt;p&gt;Anyways, here’s what it looks like:&lt;/p&gt;
    &lt;head rend="h2"&gt;Making Art&lt;/head&gt;
    &lt;p&gt;Now that we’ve &lt;del&gt;copied Nintendo’s homework&lt;/del&gt; made our Game Boy animation, it’s time to reshape it into an artistic web button masterpiece.&lt;/p&gt;
    &lt;head rend="h3"&gt;Cropping&lt;/head&gt;
    &lt;p&gt;Next up we’ve got to crop the animation to the desired 88x31. Let’s load up the GIF to see how big the logo is. I used Aseprite for this, but really any application that lets you count pixels in an image will do. Doing this, we see the “Game Boy” text logo is… 127x22 pixels wide. Hmm. That’s too big to fit into an 88x31 button, but I guess that makes sense considering the Game Boy Color’s screen is 160x144 pixels. It’ll have to be scaled down later.&lt;/p&gt;
    &lt;p&gt;Measuring the logo’s starting location to be &lt;code&gt;(x: 16, y: 48)&lt;/code&gt;, we can now crop
away. Cropping a GIF sounds like it should be a lot of work, but it can be
easily accomplished on the CLI with, you guessed it, &lt;code&gt;magick&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;magick animation.gif -crop 127x22+16+48 +repage cropped.gif&lt;/code&gt;
    &lt;head rend="h3"&gt;Scaling&lt;/head&gt;
    &lt;p&gt;The cropped logo needs to be scaled to fit into 88x31. Say it with me folks. &lt;code&gt;magick&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;magick cropped.gif -resize 82x scaled.gif&lt;/code&gt;
    &lt;p&gt;This scales (resizes) the GIF to be 82 pixels wide while maintaining the aspect ratio, the result being 82x14. I chose 82 pixels wide specifically since that’ll allow us to fit for the next stage.&lt;/p&gt;
    &lt;head rend="h3"&gt;Framing&lt;/head&gt;
    &lt;p&gt;Several of the 88x31 buttons I found online have a common frame with a 2-pixel-wide border. It looks like this:&lt;/p&gt;
    &lt;p&gt;To apply this frame to the scaled animation, we’ll need to do the following:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Centre the scaled animation into a 88x31 space;&lt;/item&gt;
      &lt;item&gt;Fill in the newly added space with grey;&lt;/item&gt;
      &lt;item&gt;Add the border frame on top of the animation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Hopefully you know the drill by now:&lt;/p&gt;
    &lt;code&gt;magick scaled.gif \
    -gravity center -background "#C0C0C0" -extent 88x31 \
    -coalesce null: frame.png -layers composite \
    framed.gif&lt;/code&gt;
    &lt;p&gt;Aaaand we’re done! Let’s take a look at the finished product in all its glory.&lt;/p&gt;
    &lt;p&gt;Wait, what’s that ugly white square doing there? Oh, right. The animation had a white background. Gotta fix that I guess.&lt;/p&gt;
    &lt;head rend="h3"&gt;Fixing That&lt;/head&gt;
    &lt;p&gt;This is actually quite straightforward. Removing the white background is easy, although if we do it with what we currently have there ends up being undesirable artifacts caused by the prior scaling.&lt;/p&gt;
    &lt;code&gt;magick framed.gif -fill "#C0C0C0" -opaque "#FFFFFF" fixed.gif&lt;/code&gt;
    &lt;p&gt;The trick here is to replace the white background before scaling. Here’s also a really great opportunity to fully show off how powerful ImageMagick’s transform pipeline can be. Going back to our uncropped animation, we can apply all previous steps at once like so.&lt;/p&gt;
    &lt;code&gt;magick animation.gif \
    -crop 127x22+16+48 +repage \         # crop 127x22 logo from animation
    -fill "#C0C0C0" -opaque "#FFFFFF" \  # NEW: replace background with grey
    -resize 82x \                        # scale animation to 82x14
    -gravity center \                    # place logo in centre
    -background "#C0C0C0" \              # use grey for added background
    -extent 88x31 \                      # expand animation to 88x31
    -coalesce null: frame.png \          # apply frame border
    -layers composite \                  # composites each frame
    fixed.gif&lt;/code&gt;
    &lt;p&gt;It’s amazing that we can do all this in a single command! Let’s admire our finished product.&lt;/p&gt;
    &lt;head rend="h2"&gt;Exorcism&lt;/head&gt;
    &lt;p&gt;As we all know, the final stage of any good art project is excising tormented apparitions from our glorious creation!&lt;/p&gt;
    &lt;p&gt;See that shadow of the logo that appears as it fades away? That’s called ghosting, and is caused by the original animation’s fade going to white instead of the grey we’ve chosen as our new background colour.&lt;/p&gt;
    &lt;head rend="h3"&gt;Remapping&lt;/head&gt;
    &lt;p&gt;Fixing this is going to be a little more tricky than it was for the compression artifacts above. In order to fix this, we’ll need remap the transition colours so that the logo’s blue-to-white transition instead fades to grey.&lt;/p&gt;
    &lt;p&gt;To do this, we’ll first need a way to identify all those transition colours. Extracting the frames of the animation will allow us to analyze their colours in a histogram:&lt;/p&gt;
    &lt;code&gt;# Extract original animation's frames
mkdir frames
magick animation.gif frames/%03d.png

# Analyze each frame's colours
for frame in frames/*(n); do
    echo "frame: $frame"
    magick "$frame" -format %c histogram:info:
done&lt;/code&gt;
    &lt;p&gt;Running this script will produce a ton of output. Let’s take a look at some samples near the end.&lt;/p&gt;
    &lt;code&gt;-- snip --
frame: frames/160.png
           209: (232,232,232) #E8E8E8 grey91
          1560: (232,238,255) #E8EEFF srgb(232,238,255)
         21271: (255,255,255) #FFFFFF white
frame: frames/161.png
           209: (243,243,243) #F3F3F3 srgb(243,243,243)
          1560: (243,246,255) #F3F6FF srgb(243,246,255)
         21271: (255,255,255) #FFFFFF white
frame: frames/162.png
           209: (247,247,247) #F7F7F7 grey97
          1560: (247,249,255) #F7F9FF srgb(247,249,255)
         21271: (255,255,255) #FFFFFF white
frame: frames/163.png
            29: (250,251,255) #FAFBFF srgb(250,251,255)
         23011: (255,255,255) #FFFFFF white
frame: frames/164.png
         23040: (255,255,255) #FFFFFF gray(255)
frame: frames/165.png
         23040: (255,255,255) #FFFFFF gray(255)
frame: frames/166.png
         23040: (255,255,255) #FFFFFF gray(255)
-- snip --
&lt;/code&gt;
    &lt;p&gt;It’s not immediately obvious what we’re looking for here, but we can see that by frame 164 there’s only one colour. That corresponds to the whiteout at the end of the animation. Looking a few frames before, we consistently see 209 frames helpfully labelled as grey, and 1560 frames in some other colour. Conspicuously, that other colour only varies in red and green, but remains fully blue.&lt;/p&gt;
    &lt;p&gt;Matching that up with the animation, those 1560 pixels must be the fading logo. With a little Unix wizardry&lt;code&gt;grep 1560 output.txt | awk '{ print $3 }' | uniq&lt;/code&gt; we can extract the colour hex codes from this
output to obtain an exact list of the blue-to-white transition colours!I’m not entirely sure why frame 163 has 29 seemingly random light-blue
pixels, but I’ve manually added &lt;code&gt;#FAFBFF&lt;/code&gt; to the list to capture them as
well.&lt;/p&gt;
    &lt;head&gt;Fade colours (blue to white)&lt;/head&gt;
    &lt;code&gt;#006BFF
#066CFF
#0C6DFF
#146FFF
#1C71FF
#2474FF
#2D77FF
#387CFF
#4281FF
#4C86FF
#588DFF
#6494FF
#719CFF
#7DA3FF
#89ABFF
#95B3FF
#A1BBFF
#ACC3FF
#B6CAFF
#C0D1FF
#CAD8FF
#D2DEFF
#DAE4FF
#E1E9FF
#E8EEFF
#F3F6FF
#F7F9FF
#FAFBFF
#FFFFFF
&lt;/code&gt;
    &lt;p&gt;From this list, the logo fade transitions from &lt;code&gt;[#006BFF, #FFFFFF)&lt;/code&gt;.This is a non-inclusive range.
Since we’re updating the background colour to &lt;code&gt;#C0C0C0&lt;/code&gt;, we’ll need a way to
modify the transition colours to instead fade to that shade of grey.
Functionally, for each colour we (1) compute how far along the transition we
are, then (2) use this value to re-compute an equivalent transition colour in
the desired fade range.&lt;/p&gt;
    &lt;p&gt;Here’s where I’ll admit my shame: by this point I was getting lazy and didn’t feel like using my brain to write my own colour interpolation. So I turned to the AI overlords to do this work for me.&lt;/p&gt;
    &lt;head&gt;Interpolation script (AI slop)&lt;/head&gt;
    &lt;code&gt;def hex_to_rgb(hex):
    """Convert hex string (#RRGGBB) to RGB tuple."""
    return tuple(int(hex.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))

def rgb_to_hex(rgb):
    """Convert RGB tuple to hex string (#RRGGBB)."""
    return "#{:02X}{:02X}{:02X}".format(*rgb)

def remap_color(color, start_old, end_old, start_new, end_new):
    """Remap a color from old range to new range."""
    r_old, g_old, b_old = start_old
    r_end_old, g_end_old, b_end_old = end_old
    r_new_start, g_new_start, b_new_start = start_new
    r_new_end, g_new_end, b_new_end = end_new
    r, g, b = color

    # Compute relative position t in old range
    t = (
        (r - r_old) / (r_end_old - r_old) if r_end_old != r_old else 0
    )  # using red as representative; you could average channels instead

    # Map to new range
    r_mapped = round(r_new_start + t * (r_new_end - r_new_start))
    g_mapped = round(g_new_start + t * (g_new_end - g_new_start))
    b_mapped = round(b_new_start + t * (b_new_end - b_new_start))

    # Clamp values between 0-255
    r_mapped = min(max(r_mapped, 0), 255)
    g_mapped = min(max(g_mapped, 0), 255)
    b_mapped = min(max(b_mapped, 0), 255)

    return (r_mapped, g_mapped, b_mapped)

# Define old and new ranges
start_old = hex_to_rgb("#006BFF")
end_old   = hex_to_rgb("#FFFFFF")

start_new = hex_to_rgb("#006BFF")
end_new   = hex_to_rgb("#C0C0C0")

# Process file
with open("color.txt", "r") as f:
    colors = [line.strip() for line in f if line.strip()]

fixed_colors = []
for hex_color in colors:
    rgb = hex_to_rgb(hex_color)
    new_rgb = remap_color(rgb, start_old, end_old, start_new, end_new)
    fixed_colors.append(rgb_to_hex(new_rgb))

# Write output
with open("remap.txt", "w") as f:
    f.write("\n".join(fixed_colors))

print("Finished! Fixed colors saved to remap.txt")&lt;/code&gt;
    &lt;p&gt;Looks great, I’m sure it works fine.&lt;/p&gt;
    &lt;head&gt;Fade colours (blue to grey)&lt;/head&gt;
    &lt;code&gt;#006BFF
#056DFE
#096FFC
#0F72FA
#1574F8
#1B77F6
#227AF4
#2A7EF1
#3281EF
#3984EC
#4288E9
#4B8CE6
#5591E3
#5E95E0
#6799DD
#709DDA
#79A1D7
#82A4D5
#89A8D2
#91ABD0
#98AECD
#9EB1CB
#A4B4C9
#A9B6C7
#AFB8C6
#B7BCC3
#BABDC2
#BCBEC1
#C0C0C0
&lt;/code&gt;
    &lt;p&gt;Huh. This looks surprisingly correct. Adding in &lt;code&gt;#FFFFFF&lt;/code&gt; to the original list
and running again, we see that it does indeed get transformed to &lt;code&gt;#C0C0C0&lt;/code&gt;. As
an additional sanity check, here are generated images of the palettes we intend
to swap.&lt;/p&gt;
    &lt;p&gt;All that’s left is to perform the colour substitution. Admittedly, I was having some trouble doing this using ImageMagick’s &lt;code&gt;-clut&lt;/code&gt;, so I arrived at a much less
elegant solution: use a series of &lt;code&gt;-fill&lt;/code&gt;/&lt;code&gt;-opaque&lt;/code&gt; to manually replace each
colour. Adding the following to the bottom of the Python script, we can at least
automate writing all that out.&lt;/p&gt;
    &lt;code&gt;# Generate ImageMagick command
cmd = ""
for old, new in zip(colors, fixed_colors):
    cmd += f' -fill "{new}" -opaque "{old}" \\\n'

print(f"Generated ImageMagick replacement:\n{cmd}")&lt;/code&gt;
    &lt;head&gt;Generated replacement options&lt;/head&gt;
    &lt;code&gt;-fill "#006BFF" -opaque "#006BFF" \
-fill "#056DFE" -opaque "#066CFF" \
-fill "#096FFC" -opaque "#0C6DFF" \
-fill "#0F72FA" -opaque "#146FFF" \
-fill "#1574F8" -opaque "#1C71FF" \
-fill "#1B77F6" -opaque "#2474FF" \
-fill "#227AF4" -opaque "#2D77FF" \
-fill "#2A7EF1" -opaque "#387CFF" \
-fill "#3281EF" -opaque "#4281FF" \
-fill "#3984EC" -opaque "#4C86FF" \
-fill "#4288E9" -opaque "#588DFF" \
-fill "#4B8CE6" -opaque "#6494FF" \
-fill "#5591E3" -opaque "#719CFF" \
-fill "#5E95E0" -opaque "#7DA3FF" \
-fill "#6799DD" -opaque "#89ABFF" \
-fill "#709DDA" -opaque "#95B3FF" \
-fill "#79A1D7" -opaque "#A1BBFF" \
-fill "#82A4D5" -opaque "#ACC3FF" \
-fill "#89A8D2" -opaque "#B6CAFF" \
-fill "#91ABD0" -opaque "#C0D1FF" \
-fill "#98AECD" -opaque "#CAD8FF" \
-fill "#9EB1CB" -opaque "#D2DEFF" \
-fill "#A4B4C9" -opaque "#DAE4FF" \
-fill "#A9B6C7" -opaque "#E1E9FF" \
-fill "#AFB8C6" -opaque "#E8EEFF" \
-fill "#B7BCC3" -opaque "#F3F6FF" \
-fill "#BABDC2" -opaque "#F7F9FF" \
-fill "#BCBEC1" -opaque "#FAFBFF" \
-fill "#C0C0C0" -opaque "#FFFFFF" \
&lt;/code&gt;
    &lt;p&gt;Putting it all together, we obtain a monstrosity that looks like this:&lt;/p&gt;
    &lt;code&gt;magick animation.gif \
    -crop 127x22+16+48 +repage \         # crop 127x22 logo from animation
    \ # remap transition colours from white to grey
    -fill "#006BFF" -opaque "#006BFF" \
    -fill "#056DFE" -opaque "#066CFF" \
    -fill "#096FFC" -opaque "#0C6DFF" \
    -fill "#0F72FA" -opaque "#146FFF" \
    -fill "#1574F8" -opaque "#1C71FF" \
    -fill "#1B77F6" -opaque "#2474FF" \
    -fill "#227AF4" -opaque "#2D77FF" \
    -fill "#2A7EF1" -opaque "#387CFF" \
    -fill "#3281EF" -opaque "#4281FF" \
    -fill "#3984EC" -opaque "#4C86FF" \
    -fill "#4288E9" -opaque "#588DFF" \
    -fill "#4B8CE6" -opaque "#6494FF" \
    -fill "#5591E3" -opaque "#719CFF" \
    -fill "#5E95E0" -opaque "#7DA3FF" \
    -fill "#6799DD" -opaque "#89ABFF" \
    -fill "#709DDA" -opaque "#95B3FF" \
    -fill "#79A1D7" -opaque "#A1BBFF" \
    -fill "#82A4D5" -opaque "#ACC3FF" \
    -fill "#89A8D2" -opaque "#B6CAFF" \
    -fill "#91ABD0" -opaque "#C0D1FF" \
    -fill "#98AECD" -opaque "#CAD8FF" \
    -fill "#9EB1CB" -opaque "#D2DEFF" \
    -fill "#A4B4C9" -opaque "#DAE4FF" \
    -fill "#A9B6C7" -opaque "#E1E9FF" \
    -fill "#AFB8C6" -opaque "#E8EEFF" \
    -fill "#B7BCC3" -opaque "#F3F6FF" \
    -fill "#BABDC2" -opaque "#F7F9FF" \
    -fill "#BCBEC1" -opaque "#FAFBFF" \
    -fill "#C0C0C0" -opaque "#FFFFFF" \  # replace background with grey
    -resize 82x \                        # scale animation to 82x14
    -gravity center \                    # place logo in centre
    -background "#C0C0C0" \              # use grey for added background
    -extent 88x31 \                      # expand animation to 88x31
    -coalesce null: frame.png \          # apply frame border
    -layers composite \                  # composites each frame
    button.gif&lt;/code&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;As someone who doesn’t have an artistic bone in my body (doctor’s diagnosis), I think it turned out pretty great! I learned a lot about ImageMagick throughout this adventure, and I hope you did too. Please feel free to use this button however you wish. Attribution is not at all necessary, but is welcome and appreciated regardless.&lt;/p&gt;
    &lt;p&gt;Well, I guess all that’s left is this final plea: Nintendo, please don’t sue me.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46507963</guid><pubDate>Tue, 06 Jan 2026 02:20:00 +0000</pubDate></item><item><title>Intel Core Ultra Series 3 Debut as First Built on Intel 18A</title><link>https://newsroom.intel.com/client-computing/ces-2026-intel-core-ultra-series-3-debut-first-built-on-intel-18a</link><description>&lt;doc fingerprint="a67b5710573a0ca6"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;CES 2026: Intel Core Ultra Series 3 Debut as First Built on Intel 18A&lt;/head&gt;
    &lt;head rend="h2"&gt;Intel ushers in the next generation of AI PCs with exceptional performance, graphics and battery life; available this month&lt;/head&gt;
    &lt;p&gt;NEWS HIGHLIGHTS:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;First platform built on Intel 18A: At CES 2026, Intel launched the Intel® Core™ Ultra Series 3 processors, the first compute platform built on Intel 18A - the most advanced semiconductor process ever developed and manufactured in the United States.&lt;/item&gt;
      &lt;item&gt;Powering over 200 PC designs: Series 3 delivers a robust family of processors powering hundreds of designs up and down the stack, all delivering exceptional performance, graphics and battery life.&lt;/item&gt;
      &lt;item&gt;From PC to Edge: For the first time, Series 3 processors are tested and certified for embedded and industrial use cases at the edge like robotics, smart cities, automation, healthcare, and more.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;LAS VEGAS, Jan. 5, 2026 – Today at CES, Intel unveiled Intel Core Ultra Series 3 processors, the first AI PC platform built on Intel 18A process technology that was designed and manufactured in the United States. Powering over 200 designs from leading, global partners, Series 3 will be the most broadly adopted and globally available AI PC platform Intel has ever delivered.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“With Series 3, we are laser focused on improving power efficiency, adding more CPU performance, a bigger GPU in a class of its own, more AI compute and app compatibility you can count on with x86.”&lt;/p&gt;
      &lt;p&gt;– Jim Johnson, Senior Vice President and General Manager, Client Computing Group, Intel&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Series 3 Adds a New Class of Intel Core Ultra X9 and X7 Processors&lt;/p&gt;
    &lt;p&gt;Within the Intel Core Ultra Series 3 mobile lineup, a new class of Intel Core Ultra X9 and X7 processors come packed with the highest performing, integrated Intel® Arc™ graphics. They are purpose-built for multitaskers that handle advanced workloads like gaming, creation and productivity on the go. The top SKUs feature up to 16 CPU cores, 12 Xe -cores and 50 NPU TOPS, delivering up to 60% better multithread performance1 over 77% faster gaming performance2 and up to 27 hours of battery life3.&lt;/p&gt;
    &lt;p&gt;The Series 3 family also includes Intel Core processors, intentionally designed to power mainstream mobile systems. Leveraging the same foundational architecture of Intel Core Ultra Series 3, the Intel Core lineup enables more performant and efficient laptop designs at lower price points.&lt;/p&gt;
    &lt;p&gt;Event Press Kit: Intel at CES 2026&lt;/p&gt;
    &lt;p&gt;Series 3 Accelerates AI Adoption in Robotics, Smart Cities, Automation and Healthcare&lt;/p&gt;
    &lt;p&gt;For the first time, alongside their PC counterparts, Series 3 edge processors are certified for embedded and industrial use cases, including extended temperature ranges, deterministic performance, and 24x7 reliability.&lt;/p&gt;
    &lt;p&gt;Intel Core Ultra Series 3 delivers competitive advantages in critical edge AI workloads with up to 1.9x higher large language model (LLM) performance4, up to 2.3x better performance per watt per dollar on end-to-end video analytics5, and up to 4.5x higher throughput on vision language action (VLA) models6. The integrated AI acceleration enables superior total cost of ownership (TCO) through a single system on chip (SoC) solution versus traditional multi-chip CPU and GPU architectures.&lt;/p&gt;
    &lt;p&gt;Availability&lt;/p&gt;
    &lt;p&gt;Pre-orders for the first consumer laptops powered by Intel Core Ultra Series 3 processors will begin Jan. 6, 2026. Systems will be available globally starting Jan. 27, 2026, with additional designs coming throughout the first half of the year.&lt;/p&gt;
    &lt;p&gt;Edge systems powered by Intel Core Ultra Series 3 will be available starting Q2 2026.&lt;/p&gt;
    &lt;p&gt;More: Supporting Quotes from Partners | Product Brief: Intel Core Ultra Series 3 Processors | Press Deck: Supplemental Data Deep Dive&lt;/p&gt;
    &lt;p&gt;1Up to 60% better multithread performance vs. Lunar Lake at similar power with an Intel® Core™ Ultra X9 388H vs. Intel® Core™ Ultra 9 288V. As measured by Cinebench 2024 Multi Core (at 25W). See www.intel.com/PerformanceIndex for workloads and configurations. Results may vary.&lt;/p&gt;
    &lt;p&gt;2Up to 77% better gaming performance vs. Lunar Lake with an Intel® Core™ Ultra X9 388H vs. Intel® Core™ Ultra 9 288V. As measured by Geomean of average game performance across 45 game titles at 1080p High with 2x upscaling when supported on Panther Lake Reference Platform vs. Lunar Lake Reference Platform. See www.intel.com/PerformanceIndex for workloads and configurations. Results may vary.&lt;/p&gt;
    &lt;p&gt;3Get as much as 27.1 hours while Netflix streaming with an Intel® Core™ Ultra X9 388H tested in Lenovo IdeaPad reference design. As measured by Netflix streaming at 1080p in Edge browser. Individual system results will vary significantly with different use, battery capacity and other factors. Learn more at intel.com/performanceindex for details&lt;/p&gt;
    &lt;p&gt;4As estimated by DeepSeek Ilama-8B first token latency on Intel Core Ultra X9 processor 388H vs. NVIDIA Jetson Orin™ AGX 64GB for BS1 and INT4. Individual system results may vary as power and performance are affected by use, configuration and other factors. Details at intel.com/performanceindex.&lt;/p&gt;
    &lt;p&gt;5As estimated by medium end-to-end video analytics with BS8 on Intel Core Ultra X9 processor 388H vs. NVIDIA Jetson Orin™ AGX 64GB. Individual system results may vary as power and performance are affected by use, configuration and other factors. Details at intel.com/performanceindex.&lt;/p&gt;
    &lt;p&gt;6As estimated by Action Chunking Transformer (ACT) Bimanual insertion model (using four cameras – 640x480 with FP32) on Intel Core Ultra X9 processor 388H iGPU vs. NVIDIA Jetson Orin™ AGX 64GB. Individual system results may vary as power and performance are affected by use, configuration and other factors. Details at intel.com/performanceindex.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46508435</guid><pubDate>Tue, 06 Jan 2026 03:31:39 +0000</pubDate></item><item><title>GoGoGrandparent (YC S16) is hiring back end engineers</title><link>https://www.ycombinator.com/companies/gogograndparent/jobs/2vbzAw8-gogograndparent-yc-s16-is-hiring-backend-and-full-stack-engineers</link><description>&lt;doc fingerprint="33bf795d37e0e879"&gt;
  &lt;main&gt;
    &lt;p&gt;A concierge service for seniors’ rides, meals, meds, home and more.&lt;/p&gt;
    &lt;p&gt;About Us&lt;/p&gt;
    &lt;p&gt;GoGoGrandparent is a digital caregiving platform helping older and disabled adults stay independent, safe, and supported at home. We adapt on-demand APIs (Uber, Lyft, DoorDash, Instacart, etc.) into a concierge-style experience tailored for people with cognitive, mobility, or vision challenges.&lt;/p&gt;
    &lt;p&gt;We’re a profitable, fast-growing, YC-backed startup (S16) with a deeply mission-driven team. Everything we build directly impacts real families who rely on GoGo every day.&lt;/p&gt;
    &lt;p&gt;Our engineering team is fully remote, tight-knit, and moves fast. You’ll work closely with founders, ship meaningful features weekly, and have real ownership over architecture, reliability, and product direction.&lt;/p&gt;
    &lt;p&gt;FULLY REMOTE | Able to work 4+ hours overlap with mainland US | $100k – $160k (based on location, experience and seniority)&lt;lb/&gt; Tech Stack&lt;/p&gt;
    &lt;p&gt;Back-end heavy: Node.js, TypeScript, MySQL, REST + GraphQL&lt;/p&gt;
    &lt;p&gt;Front-end: Vue.js (nice to have)&lt;/p&gt;
    &lt;p&gt;Deployment: AWS, Docker/Kubernetes (nice to have)&lt;lb/&gt; Requirements&lt;/p&gt;
    &lt;p&gt;6+ years of professional experience (primarily in Node.js and Vue.js)&lt;/p&gt;
    &lt;p&gt;Able to work US timezone or 4+ hours overlap with mainland US&lt;/p&gt;
    &lt;p&gt;If you're passionate about improving the lives of older adults and people with disabilities, we would love for you to apply!&lt;/p&gt;
    &lt;p&gt;2-stage interview process&lt;/p&gt;
    &lt;p&gt;We built GoGo for our own grandparents and were amazed to see it grow to touch the lives of hundreds of thousands of seniors across the United States and Canada. What shocked us then and it still does now, is that between 30 - 40% of our new signups have smartphones. We didn’t understand why. When we called and asked a few, they told us that Uber and Lyft had 'stopped working' for them.&lt;/p&gt;
    &lt;p&gt;After puzzling over that for months, we realized what the problem was.&lt;/p&gt;
    &lt;p&gt;Managing transportation - on Lyft, Uber, cab companies, etc is not easy. It’s a ‘self-serve’ experience. The ride requester has to be aware of things like the driver cancelling, getting lost, the driver arriving, the driver not-quite-being-lost-just-down-the-street-a-couple-houses.&lt;/p&gt;
    &lt;p&gt;Then add the complexities of smartphones: the user has to be on top of updating their own credit card - making sure the pickup pin is in the correct spot - typing in both where they are and where they’re going. All in all, there are about a dozen online and offline "micro steps" ride requesters have to take to get a ride. And god help anyone who needs to remember their Apple iCloud password to update an app.&lt;/p&gt;
    &lt;p&gt;We didn't know this when we started, but it turns out that ordering and managing a ride gets more difficult the older you get, almost in the same way that driving a car gets more difficult the older you get.&lt;/p&gt;
    &lt;p&gt;What gets us excited now (and what we’re hiring for) is that technically this ‘self-management problem’ doesn’t just stop at rides. There are lots of things that get harder to do as you age. People have known this for a long time and that’s inspired a lot of the solutions that older adults currently have.&lt;/p&gt;
    &lt;p&gt;Based a lot on the experiences we’ve had so far, we believe that by becoming the ‘management layer’ for the things that older adults struggle with as they age we have a better chance to offer older citizens independence without having to ask them to move out of their homes.&lt;/p&gt;
    &lt;p&gt;Within the next ten years the number of people over the age of 65 will be larger than the number of people under 18 for the first time in history. 11,000,000 people over the age of 75 will stop driving due to age related cognitive or physical decline. When they stop driving, they’ll be forced to rely on friends and family, live in a community, or have caregivers. GoGo is working to make sure that losing your youth doesn’t mean losing your independence.&lt;/p&gt;
    &lt;p&gt;Joining us at this time is a really exciting opportunity for folks looking to make meaningful impact on people’s lives. We’re a small team that’s built a profitable and fast-growing business over the last three years. Now we’re looking for partners to join us as we make GoGo a household name.&lt;/p&gt;
    &lt;p&gt;Anyone joining GoGo at this phase of the company will have a huge and life changing level of impact on a size-able and growing user base. We want people to have rich and meaningful lives at any age. We’re bringing people freedom and hope, one life at a time.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46508441</guid><pubDate>Tue, 06 Jan 2026 03:32:41 +0000</pubDate></item><item><title>enclose.horse</title><link>https://enclose.horse/</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46509211</guid><pubDate>Tue, 06 Jan 2026 06:01:57 +0000</pubDate></item><item><title>Tube trains could navigate the Underground using the rules of Quantum Physics</title><link>https://www.ianvisits.co.uk/articles/tube-trains-could-navigate-the-underground-using-the-weird-rules-of-quantum-physics-86370/</link><description>&lt;doc fingerprint="eb08939a2ea5d5e8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Tube trains could navigate the Underground using the weird rules of Quantum Physics&lt;/head&gt;
    &lt;p&gt;Tube trains of the future may soon know exactly where they are underground — even in places where GPS is blind — by tapping into the strange rules of the quantum world.&lt;/p&gt;
    &lt;p&gt;Most modern tracking systems rely on satellites to pinpoint location, backed up by accelerometers that measure tiny movements between GPS updates. It works well enough above ground, but those accelerometers gradually drift, which is why they constantly need satellite corrections.&lt;/p&gt;
    &lt;p&gt;However, in tunnels or urban areas surrounded by tall buildings where GPS signals don’t reach, that safety net disappears.&lt;/p&gt;
    &lt;p&gt;So researchers are turning to something far more exotic: quantum accelerometers.&lt;/p&gt;
    &lt;p&gt;Instead of relying on conventional sensors, these devices use clouds of atoms cooled to near absolute zero. At those temperatures, atoms start to behave strangely — acting as both particles and waves. As the atoms “fall” through a sensor, their wave patterns shift in response to acceleration. Using what’s effectively an ultra-precise optical ruler, the system can read these changes with extraordinary accuracy, without needing satellites at all.&lt;/p&gt;
    &lt;p&gt;That technology is now moving closer to the railway. Research firm MoniRail has secured an additional £1.25 million from the UK government’s quantum technology programme to advance the work. The funding supports the next phase of the Rail Quantum Inertial Navigation System (RQINS) roadmap, aimed at developing quantum navigation for the London Underground — and potentially the wider national rail network.&lt;/p&gt;
    &lt;p&gt;MoniRail’s approach goes beyond simple positioning. Sensors fitted to trains already provide a non-intrusive way to monitor track condition, collecting ride-quality data and flagging emerging faults in real time.&lt;/p&gt;
    &lt;p&gt;Naturally, trains already have track-based location systems, but they are usually based on a train being within a “moving block”, so their accuracy is down to metres rather than centimetres. If you want to monitor track conditions, the more accurate the location of the suspected fault, the less time staff spend repairing it.&lt;/p&gt;
    &lt;p&gt;Quantum navigation could shrink that uncertainty to centimetres, making it far quicker to pinpoint exactly where a defect lies. Underground, it could deliver the sort of location precision passengers have come to expect above ground — while also acting as a robust fallback above ground if GPS is unavailable.&lt;/p&gt;
    &lt;p&gt;It might seem like a nice-to-have, but in troubled times, it would not be unrealistic to expect a hostile government (or solar flares) to knock out satellite networks, with substantial impacts on society, especially as estimates suggest that a single day of GPS disruption could cost the UK economy more than £1.4 billion. A system that can keep working independently of space-based infrastructure suddenly looks less like a luxury and more like an insurance policy.&lt;/p&gt;
    &lt;p&gt;As long as the vehicle has a known starting point, quantum accelerometers can continue tracking its movement accurately, regardless of what’s happening above the atmosphere. In other words, the future of mobile navigation may depend on supercold atoms behaving very strangely.&lt;/p&gt;
    &lt;p&gt;The project is being carried out in collaboration with Transport for London, QinetiQ, PA Consulting, Imperial College London and University of Sussex.&lt;/p&gt;
    &lt;p&gt;Steve Venables, Senior Engineer at Transport for London, said: “Being a partner in the RQINS project has highlighted the transformative potential of quantum navigation and the importance of continued investment and collaboration to bring these innovations to life. We commit our support and partnerships with industry and academia to deliver tangible benefits to the UK rail infrastructure, with a focus on real-world impact and long-term resilience. We look forward to being part of the development roadmap in this next phase of UKRI funding.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46509967</guid><pubDate>Tue, 06 Jan 2026 08:26:23 +0000</pubDate></item><item><title>SCiZE's Classic Warez Collection</title><link>https://scenelist.org/</link><description>&lt;doc fingerprint="b603dfc87132d888"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;SCiZE's CLASSIC WAREZ COLLECTION&lt;/head&gt;
    &lt;p&gt; From 1990 onwards I used to roam BBS's, trading and collecting warez.&lt;lb/&gt; Fast forward over 20 years and I still have very fond memories of the 90's BBS scene.&lt;/p&gt;
    &lt;p&gt; I've put the filelists from those days online here.&lt;lb/&gt; Or browse them on my BBS.&lt;lb/&gt; Search for and view the release nfo's here.&lt;/p&gt;
    &lt;p&gt; The lists are displayed as they originally were on BBS's with all their FILE_ID.DIZ ascii magic.&lt;lb/&gt; Anyone who shares the same nostalgic feelings as me can browse to this website and look through the lists of days gone by.&lt;lb/&gt; These were the golden years of the warez scene as far as I was concerned.&lt;/p&gt;
    &lt;p&gt;I'm very interested in getting in touch with other sceners from the past so if you stumble upon this page please send me an email .&lt;/p&gt;
    &lt;head rend="h2"&gt;NFO SEARCH&lt;/head&gt;
    &lt;p&gt;Find releases based on keywords an/or filenames and view their NFO. Filtering on year also supported (e.g. 'pwa 1993').&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46510625</guid><pubDate>Tue, 06 Jan 2026 10:13:43 +0000</pubDate></item><item><title>AWS raises GPU prices 15% on a Saturday, hopes you weren't paying attention</title><link>https://www.theregister.com/2026/01/05/aws_price_increase/</link><description>&lt;doc fingerprint="4c00405dad86879c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;AWS raises GPU prices 15% on a Saturday, hopes you weren't paying attention&lt;/head&gt;
    &lt;head rend="h2"&gt;An anomaly or the beginning of a new trend? My bet's on the latter&lt;/head&gt;
    &lt;p&gt;I've been tracking AWS for a long time, with a specific emphasis on pricing. "What happens if AWS hikes prices" has always been something of a boogeyman, trotted out as a hypothetical to urge folks to avoid taking dependencies on a given provider.&lt;/p&gt;
    &lt;p&gt;Over the weekend - on a Saturday, no less - that hypothetical became real.&lt;/p&gt;
    &lt;p&gt;AWS has quietly raised prices on its EC2 Capacity Blocks for ML by approximately 15 percent. The p5e.48xlarge instance – eight NVIDIA H200 accelerators in a trenchcoat – jumped from $34.61 to $39.80 per hour across most regions, while the p5en.48xlarge climbed from $36.18 to $41.61. Customers in US West (N. California) face steeper hikes, with p5e rates rising from $43.26 to $49.75. The change had been telegraphed: AWS's pricing page noted (and bizarrely, still does) that "current prices are scheduled to be updated in January, 2026," though the company neglected to mention which direction.&lt;/p&gt;
    &lt;p&gt;This comes about seven months after AWS trumpeted "up to 45% price reductions" for GPU instances - though that announcement covered On-Demand and Savings Plans rather than Capacity Blocks. Funny how that works.&lt;/p&gt;
    &lt;p&gt;For the uninitiated, Capacity Blocks are AWS's answer to "I need guaranteed GPU capacity for my ML training job next Tuesday." You reserve specific GPU instances for a defined time window – anywhere from a day to a few weeks out – and pay up front at a locked-in rate. It's popular with companies doing serious ML work who can't afford to have a training run interrupted because spot capacity evaporated. The pricing should make it abundantly clear that the people using this aren't hobbyists; these are teams with budgets measured in millions.&lt;/p&gt;
    &lt;p&gt;An Amazon spox told us via email, "EC2 Capacity Blocks for ML pricing vary based on supply and demand patterns, as described on the product detail page. This price adjustment reflects the supply/demand patterns we expect this quarter."&lt;/p&gt;
    &lt;p&gt;To be clear, AWS has raised prices before, but rarely as a straight increase to a line item. The company prefers to change pricing dimensions entirely, often spinning this as a price reduction for most customers – a claim I'd characterize as "creative." Historical straight-up price increases have been tied to regulatory actions: per-SMS charges in certain markets and the like. This is different.&lt;/p&gt;
    &lt;p&gt;The timing is curious for another reason: it hands Azure and GCP a talking point on a silver platter. Both have been aggressively courting ML workloads, and "AWS just raised GPU prices 15%" is exactly the kind of ammunition enterprise sales teams dream about. Whether the competitors can actually absorb the demand is another question – GPU constraints are hardly unique to AWS – but perception matters in enterprise deals.&lt;/p&gt;
    &lt;p&gt;For companies with Enterprise Discount Programs or other negotiated agreements, this raises uncomfortable questions. EDPs typically guarantee discounts off public pricing – so if public pricing goes up 15 percent, your "discounted" rate just got more expensive in absolute terms, even if the percentage held steady. I expect some pointed conversations between AWS account teams and their larger customers in the coming weeks.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why are they doing this?&lt;/head&gt;
    &lt;p&gt;It's hard not to see this as a bellwether. GPUs are increasingly constrained globally as the world pivots to generating slop-as-a-service in every conceivable domain. The question is what this means for other resource types down the road. Does the global RAM crunch mean RAM-centric services are next? You can ignore ML Capacity Block pricing if you're not running machine learning workloads – which describes north of 95 percent of most companies' cloud spend – but RAM touches every service AWS offers. Well, possibly excepting their support function, though that's rapidly becoming "AI-Powered" too, so give it time.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Deploying to Amazon's cloud is a pain in the AWS younger devs won't tolerate&lt;/item&gt;
      &lt;item&gt;AWS adds hybrid cloud storage support for Nutanix's AHV hypervisor&lt;/item&gt;
      &lt;item&gt;Jassy taps 27-year Amazon veteran to run AGI org, which is now definitely a thing that exists&lt;/item&gt;
      &lt;item&gt;Smartphones face a memory cost crunch – and buyers aren't in the mood&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The canary-in-the-coal-mine concern here isn't GPUs specifically, but rather the precedent it establishes. AWS has spent two decades conditioning customers to expect prices only ever go down. That expectation is now broken. Once you've raised prices on one service and the world doesn't end, the second increase becomes easier. And the third. The playbook has changed.&lt;/p&gt;
    &lt;p&gt;Keep an eye on services where AWS faces genuine supply constraints or where their costs have materially increased. Graviton instances have been priced aggressively to drive adoption – what happens when ARM chip supply tightens? Data transfer costs have been a cash cow for years, but they've also been stable; are those next? I don't have inside information, but I do have pattern recognition, and the pattern just shifted.&lt;/p&gt;
    &lt;p&gt;AWS has long benefited from the assumption that cloud pricing only trends in one direction. That assumption died on a Saturday in January, with all the fanfare of a Terms of Service update. The question isn't whether this matters – it does. The question is whether it's an anomaly or the new normal. My money's on the latter. ®&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46511153</guid><pubDate>Tue, 06 Jan 2026 11:42:35 +0000</pubDate></item><item><title>System: Control your Mac from anywhere using natural language</title><link>https://system.surf/</link><description>&lt;doc fingerprint="a51fdf48312faeb2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;SYSTEM&lt;/head&gt;
    &lt;p&gt;remote mac automation&lt;/p&gt;
    &lt;p&gt;Control your Mac from anywhere using natural language. Built with Cloudflare Agents SDK for intelligent scheduling, memory, and tool orchestration.&lt;/p&gt;
    &lt;head rend="h2"&gt;quick start&lt;/head&gt;
    &lt;head rend="h3"&gt;1. clone and install&lt;/head&gt;
    &lt;code&gt;git clone https://github.com/ygwyg/system
cd system &amp;amp;&amp;amp; npm install&lt;/code&gt;
    &lt;head rend="h3"&gt;2. run setup wizard&lt;/head&gt;
    &lt;code&gt;npm run setup&lt;/code&gt;
    &lt;p&gt;Interactive setup: Anthropic API key, Raycast extensions, remote access.&lt;/p&gt;
    &lt;head rend="h3"&gt;3. start system&lt;/head&gt;
    &lt;code&gt;npm start&lt;/code&gt;
    &lt;p&gt;Starts bridge, tunnel, and opens the agent UI.&lt;/p&gt;
    &lt;head rend="h2"&gt;architecture&lt;/head&gt;
    &lt;p&gt;SYSTEM uses a split architecture for security: the Agent (brain) runs on Cloudflare Workers, while the Bridge (body) runs locally on your Mac.&lt;/p&gt;
    &lt;quote&gt;âââââââââââââââââââââââââââââââââââââââââââââââââââââââââ â USER â â (phone/browser) â âââââââââââââââââââââââ¬ââââââââââââââââââââââââââââââââââ â HTTPS â¼ âââââââââââââââââââââââââââââââââââââââââââââââââââââââââ â AGENT (Brain) â â Cloudflare Workers â â âââââââââââââââ âââââââââââââââ âââââââââââââââ â â â Claude â â State â â Schedules â â â â AI â â (D.O.) â â (D.O.) â â â âââââââââââââââ âââââââââââââââ âââââââââââââââ â âââââââââââââââââââââââ¬ââââââââââââââââââââââââââââââââââ â Tunnel â¼ âââââââââââââââââââââââââââââââââââââââââââââââââââââââââ â BRIDGE (Body) â â Your Mac (local) â â âââââââââââââââ âââââââââââââââ âââââââââââââââ â â â AppleScript â â Shell â â Raycast â â â âââââââââââââââ âââââââââââââââ âââââââââââââââ â âââââââââââââââââââââââââââââââââââââââââââââââââââââââââ&lt;/quote&gt;
    &lt;p&gt;â¢ Claude for NLP&lt;/p&gt;
    &lt;p&gt;â¢ State, memory, scheduling&lt;/p&gt;
    &lt;p&gt;â¢ WebSocket real-time&lt;/p&gt;
    &lt;p&gt;â¢ AppleScript, shell exec&lt;/p&gt;
    &lt;p&gt;â¢ Raycast extensions&lt;/p&gt;
    &lt;p&gt;â¢ Cloudflare Tunnel&lt;/p&gt;
    &lt;head rend="h2"&gt;authentication&lt;/head&gt;
    &lt;p&gt;All requests require an API secret via Bearer token or query parameter.&lt;/p&gt;
    &lt;code&gt;// Header
Authorization: Bearer &amp;lt;api_secret&amp;gt;

// Or query parameter
?token=&amp;lt;api_secret&amp;gt;&lt;/code&gt;
    &lt;p&gt;The API secret is generated during &lt;code&gt;npm run setup&lt;/code&gt; and stored in &lt;code&gt;bridge.config.json&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;chat&lt;/head&gt;
    &lt;p&gt;Send natural language commands to control your Mac.&lt;/p&gt;
    &lt;p&gt;Send a message to the agent.&lt;/p&gt;
    &lt;head rend="h3"&gt;request&lt;/head&gt;
    &lt;code&gt;{
  "message": "Play some jazz music"
}&lt;/code&gt;
    &lt;head rend="h3"&gt;response&lt;/head&gt;
    &lt;code&gt;{
  "message": "Playing jazz on Apple Music",
  "actions": [{
    "tool": "music_play",
    "args": { "query": "jazz" },
    "success": true,
    "result": "Now playing: Jazz Vibes"
  }]
}&lt;/code&gt;
    &lt;p&gt;Clear conversation history and state.&lt;/p&gt;
    &lt;head rend="h2"&gt;schedules&lt;/head&gt;
    &lt;p&gt;Schedule one-time or recurring tasks using natural language or cron syntax.&lt;/p&gt;
    &lt;p&gt;List all scheduled tasks.&lt;/p&gt;
    &lt;code&gt;{
  "schedules": [{
    "id": "abc123",
    "description": "Play closing time",
    "scheduledAt": "2026-01-05T17:00:00Z",
    "cron": "0 17 * * *"
  }]
}&lt;/code&gt;
    &lt;p&gt;Cancel a scheduled task by ID.&lt;/p&gt;
    &lt;p&gt; â¢ "Remind me to call mom in 30 minutes"&lt;lb/&gt; â¢ "Every day at 5pm, play Closing Time"&lt;lb/&gt; â¢ "At 9am tomorrow, open Linear" &lt;/p&gt;
    &lt;head rend="h2"&gt;state&lt;/head&gt;
    &lt;p&gt;The agent maintains persistent state including preferences and conversation history.&lt;/p&gt;
    &lt;p&gt;Get current agent state for debugging.&lt;/p&gt;
    &lt;code&gt;{
  "preferences": { "wife": "Jane" },
  "historyLength": 12,
  "scheduleCount": 2
}&lt;/code&gt;
    &lt;head rend="h2"&gt;core tools&lt;/head&gt;
    &lt;p&gt;Foundational tools for Mac automation.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;tool&lt;/cell&gt;
        &lt;cell role="head"&gt;description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;open_app&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Open any application&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;open_url&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Open URL in browser&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;shell&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Run safe shell commands&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;shell_list&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;List available shell commands&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;applescript&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Execute AppleScript&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;notify&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Show macOS notification&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;say&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Text-to-speech&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;clipboard_get&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Get clipboard contents&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;clipboard_set&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Set clipboard contents&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;screenshot&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Take screenshot&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;music&lt;/head&gt;
    &lt;p&gt;Control Apple Music playback.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;tool&lt;/cell&gt;
        &lt;cell role="head"&gt;description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;music_play&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Play/search music&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;music_pause&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Pause playback&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;music_next&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Skip to next track&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;music_previous&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Previous track&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;music_current&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Get current track info&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;volume_get&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Get volume level&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;volume_set&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Set volume (0-100)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;volume_up&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Increase volume 10%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;volume_down&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Decrease volume 10%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;volume_mute&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Toggle mute&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;messaging&lt;/head&gt;
    &lt;p&gt;Send iMessages with human-in-the-loop confirmation.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;tool&lt;/cell&gt;
        &lt;cell role="head"&gt;description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;search_contacts&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Find contact by name&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;send_imessage&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Send iMessage&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;When you say "text my wife hello", SYSTEM will: 1) resolve "wife" from preferences, 2) search contacts, 3) ask for confirmation before sending.&lt;/p&gt;
    &lt;head rend="h2"&gt;system&lt;/head&gt;
    &lt;p&gt;Control system settings, get status, manage files and apps.&lt;/p&gt;
    &lt;head rend="h3"&gt;calendar &amp;amp; reminders&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;tool&lt;/cell&gt;
        &lt;cell role="head"&gt;description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;calendar_today&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Today's events&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;calendar_upcoming&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Upcoming events&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;calendar_next&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Next event&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;calendar_create&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Create event&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;reminders_list&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;List reminders&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;reminders_create&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Create reminder&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;reminders_complete&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Complete reminder&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;display &amp;amp; focus&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;tool&lt;/cell&gt;
        &lt;cell role="head"&gt;description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;brightness_set&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Set brightness&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;dark_mode_toggle&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Toggle dark mode&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;dark_mode_status&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Get dark mode status&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;dnd_toggle&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Toggle Do Not Disturb&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;lock_screen&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Lock Mac&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;sleep_display&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Sleep display&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;sleep_mac&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Sleep Mac&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;system status&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;tool&lt;/cell&gt;
        &lt;cell role="head"&gt;description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;battery_status&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Battery level &amp;amp; charging&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;wifi_status&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;WiFi network info&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;storage_status&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Disk space&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;running_apps&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;List running apps&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;front_app&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Get frontmost app&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;notes&lt;/head&gt;
    &lt;p&gt;Read and write Apple Notes.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;tool&lt;/cell&gt;
        &lt;cell role="head"&gt;description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;notes_list&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;List recent notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;notes_search&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Search notes by keyword&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;notes_create&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Create a new note&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;notes_read&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Read note content&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;notes_append&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Append to existing note&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;files&lt;/head&gt;
    &lt;p&gt;Search and manage files via Finder.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;tool&lt;/cell&gt;
        &lt;cell role="head"&gt;description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;finder_search&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Search files by name&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;finder_downloads&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;List recent downloads&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;finder_desktop&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;List desktop files&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;finder_reveal&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Reveal file in Finder&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;finder_trash&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Move file to trash&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;shortcuts&lt;/head&gt;
    &lt;p&gt;Run Apple Shortcuts.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;tool&lt;/cell&gt;
        &lt;cell role="head"&gt;description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;shortcut_run&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Run a shortcut by name&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;shortcut_list&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;List available shortcuts&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Create powerful automations in Shortcuts.app, then trigger them via SYSTEM. Example: "Run my Morning Routine shortcut"&lt;/p&gt;
    &lt;head rend="h2"&gt;browser&lt;/head&gt;
    &lt;p&gt;Get info from Safari, Chrome, Arc, or other browsers.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;tool&lt;/cell&gt;
        &lt;cell role="head"&gt;description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_url&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Get current tab URL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_tabs&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;List open tabs&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;raycast extensions&lt;/head&gt;
    &lt;p&gt;Execute Raycast extensions for powerful integrations. SYSTEM scans your installed extensions and makes them available as tools.&lt;/p&gt;
    &lt;head rend="h3"&gt;how it works&lt;/head&gt;
    &lt;p&gt;During &lt;code&gt;npm run setup&lt;/code&gt;, SYSTEM scans your Raycast extensions folder and presents compatible commands for you to enable. Each enabled command becomes a dedicated tool.&lt;/p&gt;
    &lt;quote&gt;Raycast Extension SYSTEM Tool âââââââââââââââââ âââââââââââ spotify-player/play â spotify_play linear/create-issue â linear_create_issue slack/send-message â slack_send_message&lt;/quote&gt;
    &lt;head rend="h3"&gt;extension discovery&lt;/head&gt;
    &lt;p&gt;SYSTEM looks in &lt;code&gt;~/.config/raycast/extensions/&lt;/code&gt; and reads each extension's &lt;code&gt;package.json&lt;/code&gt; to find commands. Only commands with &lt;code&gt;mode: "no-view"&lt;/code&gt; or &lt;code&gt;mode: "view"&lt;/code&gt; are compatible.&lt;/p&gt;
    &lt;head rend="h3"&gt;compatible extension types&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;type&lt;/cell&gt;
        &lt;cell role="head"&gt;works?&lt;/cell&gt;
        &lt;cell role="head"&gt;notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;No-view commands&lt;/cell&gt;
        &lt;cell&gt;â Best&lt;/cell&gt;
        &lt;cell&gt;Execute silently, return result&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;View commands&lt;/cell&gt;
        &lt;cell&gt;â ï¸ Partial&lt;/cell&gt;
        &lt;cell&gt;Opens Raycast UI briefly&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Form commands&lt;/cell&gt;
        &lt;cell&gt;â No&lt;/cell&gt;
        &lt;cell&gt;Requires user input in Raycast&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Menu bar commands&lt;/cell&gt;
        &lt;cell&gt;â No&lt;/cell&gt;
        &lt;cell&gt;Background only&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;popular extensions that work well&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;extension&lt;/cell&gt;
        &lt;cell role="head"&gt;commands&lt;/cell&gt;
        &lt;cell role="head"&gt;use case&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;spotify-player&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;play, pause, next, like&lt;/cell&gt;
        &lt;cell&gt;Music control&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;linear&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;create-issue, search&lt;/cell&gt;
        &lt;cell&gt;Issue tracking&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;slack&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;send-message, set-status&lt;/cell&gt;
        &lt;cell&gt;Team communication&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;todoist&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;create-task, today&lt;/cell&gt;
        &lt;cell&gt;Task management&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;github&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;create-issue, search&lt;/cell&gt;
        &lt;cell&gt;Code management&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;notion&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;create-page, search&lt;/cell&gt;
        &lt;cell&gt;Notes &amp;amp; docs&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;tool naming&lt;/head&gt;
    &lt;p&gt;Tools are named as &lt;code&gt;{extension}_{command}&lt;/code&gt; with hyphens replaced by underscores:&lt;/p&gt;
    &lt;code&gt;// Extension: linear, Command: create-issue-for-myself
Tool name: linear_create_issue_for_myself

// Extension: spotify-player, Command: play
Tool name: spotify_player_play&lt;/code&gt;
    &lt;head rend="h3"&gt;using raycast tools&lt;/head&gt;
    &lt;p&gt;Once enabled, just ask naturally:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"Create a Linear issue for fixing the login bug"&lt;/item&gt;
      &lt;item&gt;"Send a Slack message to #general saying hello"&lt;/item&gt;
      &lt;item&gt;"Play Daft Punk on Spotify"&lt;/item&gt;
      &lt;item&gt;"Add 'buy groceries' to my Todoist"&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;generic raycast tool&lt;/head&gt;
    &lt;p&gt;For extensions not in your enabled list, use the generic &lt;code&gt;raycast&lt;/code&gt; tool:&lt;/p&gt;
    &lt;code&gt;{
  "extension": "spotify-player",
  "command": "play",
  "arguments": { "query": "jazz" }
}&lt;/code&gt;
    &lt;head rend="h3"&gt;deep link format&lt;/head&gt;
    &lt;p&gt;Under the hood, SYSTEM uses Raycast deep links:&lt;/p&gt;
    &lt;code&gt;raycast://extensions/{author}/{extension}/{command}?arguments={json}&lt;/code&gt;
    &lt;head rend="h3"&gt;troubleshooting&lt;/head&gt;
    &lt;p&gt;If an extension isn't showing in setup, make sure it's installed via Raycast Store, not manually. Check &lt;code&gt;~/.config/raycast/extensions/&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;This usually means the command requires UI interaction (forms, selections). These commands aren't fully compatible. Try a different command from the same extension.&lt;/p&gt;
    &lt;p&gt;Many extensions require you to authenticate in Raycast first. Open Raycast and run the command manually once to complete OAuth/login flows.&lt;/p&gt;
    &lt;head rend="h3"&gt;re-scanning extensions&lt;/head&gt;
    &lt;p&gt;If you install new Raycast extensions, run setup again to add them:&lt;/p&gt;
    &lt;code&gt;npm run setup&lt;/code&gt;
    &lt;p&gt;Your existing configuration will be preservedâyou'll just see new extensions to enable.&lt;/p&gt;
    &lt;head rend="h2"&gt;bridge api&lt;/head&gt;
    &lt;p&gt;Direct API to the local bridge. Used by the agent, but also available for custom integrations.&lt;/p&gt;
    &lt;p&gt;List all available tools on the bridge.&lt;/p&gt;
    &lt;p&gt;Execute a specific tool.&lt;/p&gt;
    &lt;code&gt;{
  "tool": "open_app",
  "args": { "app": "Safari" }
}&lt;/code&gt;
    &lt;p&gt;Check bridge status.&lt;/p&gt;
    &lt;head rend="h2"&gt;websocket&lt;/head&gt;
    &lt;p&gt;Real-time updates for scheduled tasks and notifications.&lt;/p&gt;
    &lt;code&gt;// Connect to WebSocket
const ws = new WebSocket('wss://your-agent.workers.dev/ws?token=...');

ws.onmessage = (event) =&amp;gt; {
  const data = JSON.parse(event.data);
  // Types: scheduled_result, notification, bridge_status
  console.log(data.type, data.payload);
};&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;event type&lt;/cell&gt;
        &lt;cell role="head"&gt;description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;scheduled_result&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Result of a scheduled task&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;notification&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;System notification&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;bridge_status&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Bridge online/offline&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;security&lt;/head&gt;
    &lt;p&gt;SYSTEM is designed with security as a priority.&lt;/p&gt;
    &lt;head rend="h4"&gt;ð authentication&lt;/head&gt;
    &lt;p&gt;Bearer token required for all requests. Tokens are generated during setup and stored locally.&lt;/p&gt;
    &lt;head rend="h4"&gt;ð¡ï¸ shell safety&lt;/head&gt;
    &lt;p&gt;Only allowlisted commands can run. Dangerous patterns (rm -rf, sudo, etc.) are blocked.&lt;/p&gt;
    &lt;head rend="h4"&gt;ð tunnel security&lt;/head&gt;
    &lt;p&gt;Quick Tunnels are ephemeral â new URL each session. Bridge binds to 0.0.0.0 only when tunnel is active.&lt;/p&gt;
    &lt;head rend="h4"&gt;ð¤ human-in-the-loop&lt;/head&gt;
    &lt;p&gt;Sensitive actions like sending messages require explicit user confirmation.&lt;/p&gt;
    &lt;head rend="h3"&gt;cloudflare access (recommended)&lt;/head&gt;
    &lt;p&gt;If you deploy to Cloudflare Workers, add Cloudflare Access for Zero Trust authentication at the edge â before requests even reach your agent.&lt;/p&gt;
    &lt;p&gt;While the API secret provides application-level auth, Cloudflare Access adds network-level protection. Only authenticated users can reach your agent at all.&lt;/p&gt;
    &lt;head rend="h3"&gt;setup via dashboard&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Go to Cloudflare Zero Trust Dashboard&lt;/item&gt;
      &lt;item&gt;Navigate to Access â Applications â Add an application&lt;/item&gt;
      &lt;item&gt;Select Self-hosted and enter your worker URL&lt;/item&gt;
      &lt;item&gt;Create an access policy (e.g., email = &lt;code&gt;you@example.com&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Save â users must now authenticate before accessing SYSTEM&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;automation (terraform)&lt;/head&gt;
    &lt;code&gt;# Note: wrangler doesn't support Access config directly
# Use Terraform for infrastructure-as-code

resource "cloudflare_access_application" "system" {
  zone_id          = var.zone_id
  name             = "SYSTEM"
  domain           = "your-agent.workers.dev"
  session_duration = "24h"
}

resource "cloudflare_access_policy" "allow_me" {
  application_id = cloudflare_access_application.system.id
  zone_id        = var.zone_id
  name           = "Allow specific emails"
  precedence     = 1
  decision       = "allow"

  include {
    email = ["you@example.com"]
  }
}&lt;/code&gt;
    &lt;p&gt;Cloudflare Access is configured separately from Workers deployment. The &lt;code&gt;wrangler&lt;/code&gt; CLI doesn't manage Access policies â use the dashboard or Terraform.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46511298</guid><pubDate>Tue, 06 Jan 2026 12:04:57 +0000</pubDate></item><item><title>Show HN: Prism.Tools – Free and privacy-focused developer utilities</title><link>https://blgardner.github.io/prism.tools/</link><description>&lt;doc fingerprint="4aabc530823215a8"&gt;
  &lt;main&gt;
    &lt;p&gt;PRISM.TOOLS 🔍 ☕ Donate Every Dev Tool You Need Fast. Private. Free forever. 🔒 Data never leaves your browser All Tools Formatters &amp;amp; Parsers Security &amp;amp; Dev Visual &amp;amp; CSS Generators &amp;amp; Content Encoders &amp;amp; Transformers 🛠️ All Tools Recent Tools 0 Tools Used 38 Available&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46511469</guid><pubDate>Tue, 06 Jan 2026 12:33:49 +0000</pubDate></item><item><title>C Is Best</title><link>https://sqlite.org/whyc.html</link><description>&lt;doc fingerprint="c34a58f9ca2a1b78"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;td&gt;Note: Sections 2.0 and 3.0 of this article were added in response to comments on Hacker News and Reddit.&lt;/td&gt;
    &lt;/quote&gt;
    &lt;p&gt;Since its inception on 2000-05-29, SQLite has been implemented in generic C. C was and continues to be the best language for implementing a software library like SQLite. There are no plans to recode SQLite in any other programming language at this time.&lt;/p&gt;
    &lt;p&gt;The reasons why C is the best language to implement SQLite include:&lt;/p&gt;
    &lt;p&gt;An intensively used low-level library like SQLite needs to be fast. (And SQLite is fast, see Internal Versus External BLOBs and 35% Faster Than The Filesystem for examples.)&lt;/p&gt;
    &lt;p&gt;C is a great language for writing fast code. C is sometimes described as "portable assembly language". It enables developers to code as close to the underlying hardware as possible while still remaining portable across platforms.&lt;/p&gt;
    &lt;p&gt;Other programming languages sometimes claim to be "as fast as C". But no other language claims to be faster than C for general-purpose programming, because none are.&lt;/p&gt;
    &lt;p&gt;Nearly all systems have the ability to call libraries written in C. This is not true of other implementation languages.&lt;/p&gt;
    &lt;p&gt;So, for example, Android applications written in Java are able to invoke SQLite (through an adaptor). Maybe it would have been more convenient for Android if SQLite had been coded in Java as that would make the interface simpler. However, on iPhone applications are coded in Objective-C or Swift, neither of which have the ability to call libraries written in Java. Thus, SQLite would be unusable on iPhones had it been written in Java.&lt;/p&gt;
    &lt;p&gt;Libraries written in C do not have a huge run-time dependency. In its minimum configuration, SQLite requires only the following routines from the standard C library:&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;In a more complete build, SQLite also uses library routines like malloc() and free() and operating system interfaces for opening, reading, writing, and closing files. But even then, the number of dependencies is very small. Other "modern" languages, in contrast, often require multi-megabyte runtimes loaded with thousands and thousands of interfaces.&lt;/p&gt;
    &lt;p&gt;The C language is old and boring. It is a well-known and well-understood language. This is exactly what one wants when developing a module like SQLite. Writing a small, fast, and reliable database engine is hard enough as it is without the implementation language changing out from under you with each update to the implementation language specification.&lt;/p&gt;
    &lt;p&gt;Some programmers cannot imagine developing a complex system like SQLite in a language that is not "object oriented". So why is SQLite not coded in C++ or Java?&lt;/p&gt;
    &lt;p&gt;Libraries written in C++ or Java can generally only be used by applications written in the same language. It is difficult to get an application written in Haskell or Java to invoke a library written in C++. On the other hand, libraries written in C are callable from any programming language.&lt;/p&gt;
    &lt;p&gt;Object-Oriented is a design pattern, not a programming language. You can do object-oriented programming in any language you want, including assembly language. Some languages (ex: C++ or Java) make object-oriented easier. But you can still do object-oriented programming in languages like C.&lt;/p&gt;
    &lt;p&gt;Object-oriented is not the only valid design pattern. Many programmers have been taught to think purely in terms of objects. And, to be fair, objects are often a good way to decompose a problem. But objects are not the only way, and are not always the best way to decompose a problem. Sometimes good old procedural code is easier to write, easier to maintain and understand, and faster than object-oriented code.&lt;/p&gt;
    &lt;p&gt;When SQLite was first being developed, Java was a young and immature language. C++ was older, but was undergoing such growing pains that it was difficult to find any two C++ compilers that worked the same way. So C was definitely a better choice back when SQLite was first being developed. The situation is less stark now, but there is little to no benefit in recoding SQLite at this point.&lt;/p&gt;
    &lt;p&gt;There has lately been a lot of interest in "safe" programming languages like Rust or Go in which it is impossible, or is at least difficult, to make common programming errors like memory leaks or array overruns. So the question often arises as to why SQLite is not coded in a "safe" language.&lt;/p&gt;
    &lt;p&gt;None of the safe programming languages existed for the first 10 years of SQLite's existence. SQLite could be recoded in Go or Rust, but doing so would probably introduce far more bugs than would be fixed, and it may also result in slower code.&lt;/p&gt;
    &lt;p&gt;Safe languages insert additional machine branches to do things like verify that array accesses are in-bounds. In correct code, those branches are never taken. That means that the machine code cannot be 100% branch tested, which is an important component of SQLite's quality strategy.&lt;/p&gt;
    &lt;p&gt;Safe languages usually want to abort if they encounter an out-of-memory (OOM) situation. SQLite is designed to recover gracefully from an OOM. It is unclear how this could be accomplished in the current crop of safe languages.&lt;/p&gt;
    &lt;p&gt;All of the existing safe languages are new. The developers of SQLite applaud the efforts of computer language researchers in trying to develop languages that are easier to program safely. We encourage these efforts to continue. But we ourselves are more interested in old and boring languages when it comes to implementing SQLite.&lt;/p&gt;
    &lt;p&gt;All that said, it is possible that SQLite might one day be recoded in Rust. Recoding SQLite in Go is unlikely since Go hates assert(). But Rust is a possibility. Some preconditions that must occur before SQLite is recoded in Rust include:&lt;/p&gt;
    &lt;p&gt;If you are a "rustacean" and feel that Rust already meets the preconditions listed above, and that SQLite should be recoded in Rust, then you are welcomed and encouraged to contact the SQLite developers privately and argue your case.&lt;/p&gt;
    &lt;p&gt;This page was last updated on 2025-05-09 15:56:17Z&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46511470</guid><pubDate>Tue, 06 Jan 2026 12:33:54 +0000</pubDate></item><item><title>Show HN: DDL to Data – Generate realistic test data from SQL schemas</title><link>https://news.ycombinator.com/item?id=46511578</link><description>&lt;doc fingerprint="2deaaa31c784bee8"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;I built DDL to Data after repeatedly pushing back on "just use production data and mask it" requests. Teams needed populated databases for testing, but pulling prod meant security reviews, PII scrubbing, and DevOps tickets. Hand-written seed scripts were the alternative slow, fragile, and out of sync the moment schemas changed.&lt;/p&gt;
      &lt;p&gt;Paste your CREATE TABLE statements, get realistic test data back. It parses your schema, preserves foreign key relationships, and generates data that looks real, emails look like emails, timestamps are reasonable, uniqueness constraints are honored.&lt;/p&gt;
      &lt;p&gt;No setup, no config. Works with PostgreSQL and MySQL.&lt;/p&gt;
      &lt;p&gt;https://ddltodata.com&lt;/p&gt;
      &lt;p&gt;Would love feedback from anyone who deals with test data or staging environments. What's missing?&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46511578</guid><pubDate>Tue, 06 Jan 2026 12:47:23 +0000</pubDate></item><item><title>Gemini Protocol Deployment Statistics</title><link>https://www.obsessivefacts.com/gemini-proxy?uri=gemini%3A%2F%2Fgemini.bortzmeyer.org%2Fsoftware%2Flupa%2Fstats.gmi</link><description>&lt;doc fingerprint="7309191894b681c1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Statistics on the Gemini space&lt;/head&gt;
    &lt;p&gt;This page presents some statistics on the current state of the Gemini space. It has been updated on 2026-01-06 04:04:01Z.&lt;/p&gt;
    &lt;p&gt;It cannot claim to represent the entire space. The real number of URIs is certainly higher. There are several reasons why many URIs are not in the database:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;the capsule may forbid retrieval, through robots.txt,&lt;/item&gt;
      &lt;item&gt;we do not know all the URIs and some cannot be found from the ones we know,&lt;/item&gt;
      &lt;item&gt;Lupa has a maximum number of URIs per capsule, to save resources (currently 10000).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;On this page, "working" means there was a successful connection recently. "recently" means "less than 31 days". "Dead" URLs and capsules are removed after 46 days and no longer appear in any statistics.&lt;/p&gt;
    &lt;p&gt;Currently, our database includes 646,369 URIs, 560,646 of them having been checked successfully (status code 20) and recently. Among the recently accessed, 431,340 URIs serve a Gemini content.&lt;/p&gt;
    &lt;head rend="h2"&gt;Resources&lt;/head&gt;
    &lt;p&gt;The average size of the resources is 46,339 bytes.&lt;/p&gt;
    &lt;head rend="h3"&gt;Quantiles&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;10% of the resources are 306 bytes or less,&lt;/item&gt;
      &lt;item&gt;20% of the resources are 674 bytes or less,&lt;/item&gt;
      &lt;item&gt;30% of the resources are 1,098 bytes or less,&lt;/item&gt;
      &lt;item&gt;40% of the resources are 1,466 bytes or less,&lt;/item&gt;
      &lt;item&gt;50% of the resources are 2,318 bytes or less, MEDIAN&lt;/item&gt;
      &lt;item&gt;60% of the resources are 3,902 bytes or less,&lt;/item&gt;
      &lt;item&gt;70% of the resources are 6,768 bytes or less,&lt;/item&gt;
      &lt;item&gt;80% of the resources are 14,821 bytes or less,&lt;/item&gt;
      &lt;item&gt;90% of the resources are 63,909 bytes or less,&lt;/item&gt;
      &lt;item&gt;100% of the resources are 4,156,230 bytes or less.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;# Quantiles only for Gemini pages&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;10% of the resources are 273 bytes or less,&lt;/item&gt;
      &lt;item&gt;20% of the resources are 524 bytes or less,&lt;/item&gt;
      &lt;item&gt;30% of the resources are 851 bytes or less,&lt;/item&gt;
      &lt;item&gt;40% of the resources are 1,136 bytes or less,&lt;/item&gt;
      &lt;item&gt;50% of the resources are 1,466 bytes or less, MEDIAN&lt;/item&gt;
      &lt;item&gt;60% of the resources are 2,279 bytes or less,&lt;/item&gt;
      &lt;item&gt;70% of the resources are 3,537 bytes or less,&lt;/item&gt;
      &lt;item&gt;80% of the resources are 5,781 bytes or less,&lt;/item&gt;
      &lt;item&gt;90% of the resources are 10,011 bytes or less,&lt;/item&gt;
      &lt;item&gt;100% of the resources are 4,156,230 bytes or less.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Ranges&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Less than 10 bytes: 1380 URLs (0.25 %)&lt;/item&gt;
      &lt;item&gt;10 to 100 bytes: 12513 URLs (2.2 %)&lt;/item&gt;
      &lt;item&gt;100 to 1000 bytes: 141180 URLs (25.2 %)&lt;/item&gt;
      &lt;item&gt;1 to 10 kbytes: 271587 URLs (48.4 %)&lt;/item&gt;
      &lt;item&gt;10 to 100 kbytes: 89482 URLs (16.0 %)&lt;/item&gt;
      &lt;item&gt;100 to 1000 kbytes: 33186 URLs (5.9 %)&lt;/item&gt;
      &lt;item&gt;More than 1000 kbytes: 11318 URLs (2.02 %)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Most common media (MIME) types&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;text/gemini: 431,340 URLs&lt;/item&gt;
      &lt;item&gt;image/jpeg: 35,445 URLs&lt;/item&gt;
      &lt;item&gt;text/plain: 25,736 URLs&lt;/item&gt;
      &lt;item&gt;image/png: 23,934 URLs&lt;/item&gt;
      &lt;item&gt;application/octet-stream: 10,889 URLs&lt;/item&gt;
      &lt;item&gt;image/webp: 7,788 URLs&lt;/item&gt;
      &lt;item&gt;application/pdf: 5,370 URLs&lt;/item&gt;
      &lt;item&gt;image/gif: 2,696 URLs&lt;/item&gt;
      &lt;item&gt;application/zip: 2,563 URLs&lt;/item&gt;
      &lt;item&gt;octet/stream: 1,954 URLs&lt;/item&gt;
      &lt;item&gt;application/x-mscardfile: 1,928 URLs&lt;/item&gt;
      &lt;item&gt;text/html: 1,512 URLs&lt;/item&gt;
      &lt;item&gt;audio/mpeg: 1,041 URLs&lt;/item&gt;
      &lt;item&gt;text/x-diff: 864 URLs&lt;/item&gt;
      &lt;item&gt;text/markdown: 815 URLs&lt;/item&gt;
      &lt;item&gt;audio/ogg: 739 URLs&lt;/item&gt;
      &lt;item&gt;application/atom+xml: 639 URLs&lt;/item&gt;
      &lt;item&gt;application/json: 588 URLs&lt;/item&gt;
      &lt;item&gt;text/xml: 549 URLs&lt;/item&gt;
      &lt;item&gt;image/svg+xml: 343 URLs&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Most common languages&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Unspecified: 383,664 URLs&lt;/item&gt;
      &lt;item&gt;en: 121,355 URLs&lt;/item&gt;
      &lt;item&gt;de: 20,574 URLs&lt;/item&gt;
      &lt;item&gt;fr: 13,024 URLs&lt;/item&gt;
      &lt;item&gt;es: 9,242 URLs&lt;/item&gt;
      &lt;item&gt;it: 7,635 URLs&lt;/item&gt;
      &lt;item&gt;es_ar: 1,273 URLs&lt;/item&gt;
      &lt;item&gt;ru: 684 URLs&lt;/item&gt;
      &lt;item&gt;fa: 572 URLs&lt;/item&gt;
      &lt;item&gt;ja: 560 URLs&lt;/item&gt;
      &lt;item&gt;grc: 420 URLs&lt;/item&gt;
      &lt;item&gt;en_au: 252 URLs&lt;/item&gt;
      &lt;item&gt;arb: 202 URLs&lt;/item&gt;
      &lt;item&gt;en_us: 154 URLs&lt;/item&gt;
      &lt;item&gt;pl: 131 URLs&lt;/item&gt;
      &lt;item&gt;sv: 129 URLs&lt;/item&gt;
      &lt;item&gt;he: 93 URLs&lt;/item&gt;
      &lt;item&gt;gl: 62 URLs&lt;/item&gt;
      &lt;item&gt;ko: 56 URLs&lt;/item&gt;
      &lt;item&gt;fr,it: 47 URLs&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Most common language tags&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Unspecified: 383,613 URLs&lt;/item&gt;
      &lt;item&gt;en: 58,319 URLs&lt;/item&gt;
      &lt;item&gt;en-gb: 42,784 URLs&lt;/item&gt;
      &lt;item&gt;de: 20,526 URLs&lt;/item&gt;
      &lt;item&gt;en-us: 19,274 URLs&lt;/item&gt;
      &lt;item&gt;fr: 11,147 URLs&lt;/item&gt;
      &lt;item&gt;it: 7,635 URLs&lt;/item&gt;
      &lt;item&gt;es: 7,072 URLs&lt;/item&gt;
      &lt;item&gt;es-es: 2,069 URLs&lt;/item&gt;
      &lt;item&gt;fr-fr: 1,877 URLs&lt;/item&gt;
      &lt;item&gt;es_ar: 1,273 URLs&lt;/item&gt;
      &lt;item&gt;fa: 572 URLs&lt;/item&gt;
      &lt;item&gt;ja: 560 URLs&lt;/item&gt;
      &lt;item&gt;en-ie: 478 URLs&lt;/item&gt;
      &lt;item&gt;grc: 420 URLs&lt;/item&gt;
      &lt;item&gt;en-ca: 409 URLs&lt;/item&gt;
      &lt;item&gt;ru-ru: 356 URLs&lt;/item&gt;
      &lt;item&gt;ru: 328 URLs&lt;/item&gt;
      &lt;item&gt;en_au: 252 URLs&lt;/item&gt;
      &lt;item&gt;arb: 202 URLs&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Most common encodings ("charsets") for all files&lt;/head&gt;
    &lt;p&gt;(Remember there exists testing capsules, with very exotic encodings, so don't be surprised by some strange ones.)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Unspecified: 488,732 URLs&lt;/item&gt;
      &lt;item&gt;utf-8: 71,650 URLs&lt;/item&gt;
      &lt;item&gt;binary: 161 URLs&lt;/item&gt;
      &lt;item&gt;us-ascii: 75 URLs&lt;/item&gt;
      &lt;item&gt;gzip: 21 URLs&lt;/item&gt;
      &lt;item&gt;iso-8859-1: 6 URLs&lt;/item&gt;
      &lt;item&gt;xz: 1 URLs&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Most common encodings for gemtext files only&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Unspecified: 370,176 URLs&lt;/item&gt;
      &lt;item&gt;utf-8: 61,157 URLs&lt;/item&gt;
      &lt;item&gt;iso-8859-1: 6 URLs&lt;/item&gt;
      &lt;item&gt;us-ascii: 1 URLs&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By the way, 457 of recently tested URLs (0.075 %) have a wrong encoding (it does not match the actual content).&lt;/p&gt;
    &lt;head rend="h3"&gt;Status codes&lt;/head&gt;
    &lt;p&gt;(Remember there are test capsules with funny status codes, to exercice Gemini clients.)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;20 (Success): 560,646 occurrences (94.98 %)&lt;/item&gt;
      &lt;item&gt;51 (Not found): 17,919 occurrences (3.04 %)&lt;/item&gt;
      &lt;item&gt;10 (Input request): 3,356 occurrences (0.57 %)&lt;/item&gt;
      &lt;item&gt;30 (Temporary redirect): 3,146 occurrences (0.53 %)&lt;/item&gt;
      &lt;item&gt;60 (Client certificate request): 2,894 occurrences (0.49 %)&lt;/item&gt;
      &lt;item&gt;40 (Temporary failure): 772 occurrences (0.13 %)&lt;/item&gt;
      &lt;item&gt;53 (Proxy request refused): 547 occurrences (0.09 %)&lt;/item&gt;
      &lt;item&gt;42 (CGI error): 266 occurrences (0.05 %)&lt;/item&gt;
      &lt;item&gt;50 (Permanent failure): 239 occurrences (0.04 %)&lt;/item&gt;
      &lt;item&gt;31 (Permanent redirect): 171 occurrences (0.03 %)&lt;/item&gt;
      &lt;item&gt;52 (Gone with the wind): 138 occurrences (0.02 %)&lt;/item&gt;
      &lt;item&gt;59 (Bad request): 88 occurrences (0.01 %)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Links&lt;/head&gt;
    &lt;p&gt;(We count only backlinks from external capsules, and at most one link per capsule. Also, we exclude links from capsules like search engines or directories.)&lt;/p&gt;
    &lt;p&gt;Maximum number of incoming links: 381&lt;/p&gt;
    &lt;p&gt;Average number of incoming links: 0.28&lt;/p&gt;
    &lt;head rend="h2"&gt;Capsules&lt;/head&gt;
    &lt;p&gt;There are 4825 capsules. We successfully connected recently to 3251 of them.&lt;/p&gt;
    &lt;head rend="h3"&gt;Most common capsules by number of working URLs&lt;/head&gt;
    &lt;p&gt;We have a limit of 10000 URLs per capsule.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;gemini.kpopify.me: 10000 URLs&lt;/item&gt;
      &lt;item&gt;x5dragonfire.flounder.online: 10000 URLs&lt;/item&gt;
      &lt;item&gt;blitter.com: 10000 URLs&lt;/item&gt;
      &lt;item&gt;dvd.flounder.online: 10000 URLs&lt;/item&gt;
      &lt;item&gt;gemini.conman.org: 10000 URLs&lt;/item&gt;
      &lt;item&gt;gemini.oxydable.fr: 10000 URLs&lt;/item&gt;
      &lt;item&gt;gemini.techrights.org: 10000 URLs&lt;/item&gt;
      &lt;item&gt;gemini.tuxmachines.org: 9999 URLs&lt;/item&gt;
      &lt;item&gt;federal.cx: 9998 URLs&lt;/item&gt;
      &lt;item&gt;fumble-around.mediocregopher.com: 9994 URLs&lt;/item&gt;
      &lt;item&gt;musicbrainz.uploadedlobster.com: 9994 URLs&lt;/item&gt;
      &lt;item&gt;gmi.noulin.net: 9990 URLs&lt;/item&gt;
      &lt;item&gt;gemini.omarpolo.com: 9990 URLs&lt;/item&gt;
      &lt;item&gt;caiofior.pollux.casa: 9990 URLs&lt;/item&gt;
      &lt;item&gt;station.martinrue.com: 9970 URLs&lt;/item&gt;
      &lt;item&gt;taz.de: 9967 URLs&lt;/item&gt;
      &lt;item&gt;techrights.org: 9965 URLs&lt;/item&gt;
      &lt;item&gt;library.inu.red: 9952 URLs&lt;/item&gt;
      &lt;item&gt;bbs.geminispace.org: 9932 URLs&lt;/item&gt;
      &lt;item&gt;gemlog.stargrave.org: 9914 URLs&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Most common capsules by number of bytes in working URLs&lt;/head&gt;
    &lt;p&gt;We have a limit of bytes per URL.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;mirrors.apple2.org.za: 2453.8 megabytes&lt;/item&gt;
      &lt;item&gt;nytpu.com: 2079.5 megabytes&lt;/item&gt;
      &lt;item&gt;higeki.jp: 1503.7 megabytes&lt;/item&gt;
      &lt;item&gt;gem.librehacker.com: 1040.6 megabytes&lt;/item&gt;
      &lt;item&gt;librehacker.com: 954.6 megabytes&lt;/item&gt;
      &lt;item&gt;uscoffings.net: 927.2 megabytes&lt;/item&gt;
      &lt;item&gt;gael.mooo.com: 754.6 megabytes&lt;/item&gt;
      &lt;item&gt;blitter.com: 687.1 megabytes&lt;/item&gt;
      &lt;item&gt;dfdn.info: 596.0 megabytes&lt;/item&gt;
      &lt;item&gt;going-flying.com: 448.6 megabytes&lt;/item&gt;
      &lt;item&gt;gemini.tcrouzet.com: 415.5 megabytes&lt;/item&gt;
      &lt;item&gt;tweek.zyxxyz.eu: 379.0 megabytes&lt;/item&gt;
      &lt;item&gt;norayr.am: 377.8 megabytes&lt;/item&gt;
      &lt;item&gt;villastraylight.online: 371.6 megabytes&lt;/item&gt;
      &lt;item&gt;techrights.org: 339.9 megabytes&lt;/item&gt;
      &lt;item&gt;ecs.d2evs.net: 320.9 megabytes&lt;/item&gt;
      &lt;item&gt;gemini.kpopify.me: 310.6 megabytes&lt;/item&gt;
      &lt;item&gt;library.inu.red: 281.2 megabytes&lt;/item&gt;
      &lt;item&gt;8by3.net: 260.2 megabytes&lt;/item&gt;
      &lt;item&gt;gemi.dev: 250.5 megabytes&lt;/item&gt;
      &lt;item&gt;gem.ortie.org: 228.9 megabytes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All working capsules:&lt;/p&gt;
    &lt;head rend="h3"&gt;Certificates&lt;/head&gt;
    &lt;p&gt;3006 (92.5 %) capsules are self-signed, 5 (0.2 %) use the Certificate Authority Let's Encrypt, 240 (7.4 %) are signed by another CA (may be not a trusted one).&lt;/p&gt;
    &lt;p&gt;93 capsules (2.87 %) have an expired certificate.&lt;/p&gt;
    &lt;p&gt;Algorithms:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ecdsa-with-SHA256: 2046 capsules&lt;/item&gt;
      &lt;item&gt;sha256WithRSAEncryption: 1096 capsules&lt;/item&gt;
      &lt;item&gt;ecdsa-with-SHA384: 79 capsules&lt;/item&gt;
      &lt;item&gt;ED25519: 25 capsules&lt;/item&gt;
      &lt;item&gt;ecdsa-with-SHA512: 3 capsules&lt;/item&gt;
      &lt;item&gt;sha512WithRSAEncryption: 2 capsules&lt;/item&gt;
      &lt;item&gt;sha384WithRSAEncryption: 1 capsules&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Key types:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ECDSA: 2128 capsules&lt;/item&gt;
      &lt;item&gt;RSA: 1099 capsules&lt;/item&gt;
      &lt;item&gt;ED25519: 25 capsules&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Key sizes for RSA:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2048: 815 capsules&lt;/item&gt;
      &lt;item&gt;4096: 279 capsules&lt;/item&gt;
      &lt;item&gt;3072: 3 capsules&lt;/item&gt;
      &lt;item&gt;1024: 2 capsules&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Key sizes for ECDSA:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;256: 2068 capsules&lt;/item&gt;
      &lt;item&gt;384: 59 capsules&lt;/item&gt;
      &lt;item&gt;521: 1 capsules&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;TLS&lt;/head&gt;
    &lt;p&gt;99 % of the capsules use TLS 1.3, 1 % use TLS 1.2.&lt;/p&gt;
    &lt;head rend="h3"&gt;robots.txt&lt;/head&gt;
    &lt;p&gt;317 (10 %) the capsules have a robots.txt exclusion file.&lt;/p&gt;
    &lt;head rend="h3"&gt;Ports&lt;/head&gt;
    &lt;p&gt;23 working capsules (0.7 %) use an alternative port&lt;/p&gt;
    &lt;head rend="h3"&gt;Addresses&lt;/head&gt;
    &lt;p&gt;1263 IP addresses used. 27 % are IPv6.&lt;/p&gt;
    &lt;head rend="h3"&gt;# Addresses with most virtual hosts&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;173.230.145.243: 1079 vhosts&lt;/item&gt;
      &lt;item&gt;72.65.51.74: 549 vhosts&lt;/item&gt;
      &lt;item&gt;213.219.38.200: 328 vhosts&lt;/item&gt;
      &lt;item&gt;46.23.81.157: 143 vhosts&lt;/item&gt;
      &lt;item&gt;2a03:6000:1813:1337::157: 123 vhosts&lt;/item&gt;
      &lt;item&gt;86.194.163.71: 46 vhosts&lt;/item&gt;
      &lt;item&gt;109.237.26.252: 34 vhosts&lt;/item&gt;
      &lt;item&gt;45.56.93.217: 21 vhosts&lt;/item&gt;
      &lt;item&gt;172.236.4.52: 18 vhosts&lt;/item&gt;
      &lt;item&gt;128.140.115.191: 16 vhosts&lt;/item&gt;
      &lt;item&gt;143.244.176.58: 10 vhosts&lt;/item&gt;
      &lt;item&gt;2604:a880:4:1d0::4e1:3000: 10 vhosts&lt;/item&gt;
      &lt;item&gt;2a01:4f8:c17:20f1::42: 9 vhosts&lt;/item&gt;
      &lt;item&gt;23.88.35.144: 9 vhosts&lt;/item&gt;
      &lt;item&gt;46.23.94.99: 9 vhosts&lt;/item&gt;
      &lt;item&gt;129.151.254.123: 9 vhosts&lt;/item&gt;
      &lt;item&gt;143.244.212.63: 8 vhosts&lt;/item&gt;
      &lt;item&gt;2001:8b0:1d97:eeca:3da5:94ce:b61e:ee69: 8 vhosts&lt;/item&gt;
      &lt;item&gt;81.187.234.86: 8 vhosts&lt;/item&gt;
      &lt;item&gt;2a03:6000:6f67:624::99: 8 vhosts&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;TLDs&lt;/head&gt;
    &lt;p&gt;There are 277 TLDs in the capsule's names, and 2248 registered domains.&lt;/p&gt;
    &lt;head rend="h3"&gt;Most common TLDs&lt;/head&gt;
    &lt;head rend="h3"&gt;# By number of registered domains&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;com: 361 domains&lt;/item&gt;
      &lt;item&gt;net: 212 domains&lt;/item&gt;
      &lt;item&gt;org: 179 domains&lt;/item&gt;
      &lt;item&gt;xyz: 154 domains&lt;/item&gt;
      &lt;item&gt;space: 99 domains&lt;/item&gt;
      &lt;item&gt;site: 75 domains&lt;/item&gt;
      &lt;item&gt;de: 64 domains&lt;/item&gt;
      &lt;item&gt;dev: 63 domains&lt;/item&gt;
      &lt;item&gt;me: 56 domains&lt;/item&gt;
      &lt;item&gt;eu: 41 domains&lt;/item&gt;
      &lt;item&gt;uk: 37 domains&lt;/item&gt;
      &lt;item&gt;fr: 37 domains&lt;/item&gt;
      &lt;item&gt;info: 30 domains&lt;/item&gt;
      &lt;item&gt;io: 28 domains&lt;/item&gt;
      &lt;item&gt;club: 24 domains&lt;/item&gt;
      &lt;item&gt;onion: 20 domains&lt;/item&gt;
      &lt;item&gt;ru: 19 domains&lt;/item&gt;
      &lt;item&gt;online: 18 domains&lt;/item&gt;
      &lt;item&gt;ca: 18 domains&lt;/item&gt;
      &lt;item&gt;se: 18 domains&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;# By number of capsules&lt;/head&gt;
    &lt;p&gt;(There's a strong bias towards TLDs which have hosting services such as flounder.online, which has many capsules in subdomains. See before the TLDs per registered domains, which are probably more useful.)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;online: 1093 capsules&lt;/item&gt;
      &lt;item&gt;org: 788 capsules&lt;/item&gt;
      &lt;item&gt;com: 452 capsules&lt;/item&gt;
      &lt;item&gt;pub: 344 capsules&lt;/item&gt;
      &lt;item&gt;net: 255 capsules&lt;/item&gt;
      &lt;item&gt;xyz: 178 capsules&lt;/item&gt;
      &lt;item&gt;space: 123 capsules&lt;/item&gt;
      &lt;item&gt;site: 78 capsules&lt;/item&gt;
      &lt;item&gt;de: 73 capsules&lt;/item&gt;
      &lt;item&gt;dev: 72 capsules&lt;/item&gt;
      &lt;item&gt;me: 58 capsules&lt;/item&gt;
      &lt;item&gt;eu: 58 capsules&lt;/item&gt;
      &lt;item&gt;cc: 57 capsules&lt;/item&gt;
      &lt;item&gt;casa: 54 capsules&lt;/item&gt;
      &lt;item&gt;club: 53 capsules&lt;/item&gt;
      &lt;item&gt;fr: 41 capsules&lt;/item&gt;
      &lt;item&gt;uk: 41 capsules&lt;/item&gt;
      &lt;item&gt;info: 37 capsules&lt;/item&gt;
      &lt;item&gt;io: 33 capsules&lt;/item&gt;
      &lt;item&gt;town: 27 capsules&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Other statistics on the geminispace&lt;/head&gt;
    &lt;p&gt;At the search engine geminispace.info&lt;/p&gt;
    &lt;p&gt;By Nervuri (specially for certificates)&lt;/p&gt;
    &lt;head rend="h2"&gt;Contact&lt;/head&gt;
    &lt;p&gt;Maintained by Stéphane Bortzmeyer (email &amp;lt;stephane+gemini@bortzmeyer.org&amp;gt;). Comments and criticisms are welcome.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46512707</guid><pubDate>Tue, 06 Jan 2026 14:30:53 +0000</pubDate></item><item><title>High-performance header-only container library for C++23 on x86-64</title><link>https://github.com/kressler/fast-containers</link><description>&lt;doc fingerprint="6f8fe048c40538a9"&gt;
  &lt;main&gt;
    &lt;p&gt;High-performance header-only container library for C++23 on x86-64.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;B+Tree (&lt;code&gt;kressler::fast_containers::btree&lt;/code&gt;) - Cache-friendly B+tree with SIMD search and hugepage support&lt;/item&gt;
      &lt;item&gt;Dense Map (&lt;code&gt;kressler::fast_containers::dense_map&lt;/code&gt;) - Fixed-size sorted array used internally by btree nodes&lt;/item&gt;
      &lt;item&gt;Hugepage Allocators - Pooling allocators that reduce TLB misses and allocation overhead &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;HugePageAllocator&lt;/code&gt;- Single-size allocator for uniform allocations&lt;/item&gt;&lt;item&gt;&lt;code&gt;MultiSizeHugePageAllocator&lt;/code&gt;- Multi-size pooling for variable-sized allocations (e.g., Abseil btree)&lt;/item&gt;&lt;item&gt;&lt;code&gt;PolicyBasedHugePageAllocator&lt;/code&gt;- Advanced control with shared pools&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The B+tree implementation provides significant performance improvements over industry standards for large trees. For some workloads with large trees, we've observed:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;vs Abseil B+tree: 2-5× faster across insert/find/erase operations&lt;/item&gt;
      &lt;item&gt;vs std::map: 2-5× faster across insert/find/erase operations&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See benchmark results for detailed performance analysis.&lt;/p&gt;
    &lt;p&gt;Important qualifications:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Performance advantages are most significant for large tree sizes where TLB misses and allocation costs dominate&lt;/item&gt;
      &lt;item&gt;Benchmarks currently focus on 10M element trees; smaller tree sizes have not been comprehensively tested&lt;/item&gt;
      &lt;item&gt;Results are specific to the tested configurations (8-byte keys, 32-byte and 256-byte values)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Key advantages over Abseil's btree:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Hugepage allocator integration: 3-5× speedup from reduced TLB misses and pooled allocations&lt;/item&gt;
      &lt;item&gt;SIMD-accelerated search: 3-10% faster node searches using AVX2 instructions&lt;/item&gt;
      &lt;item&gt;Tunable node sizes: Optimize cache behavior for your specific key/value sizes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Work in progress This is a work in progress. I don't have plans for major changes to the B+tree currently, but am actively cleaning up the implementation.&lt;/p&gt;
    &lt;p&gt;Platforms This library is really only built and tested on Linux, on x86-64 CPUs with AVX2 support. In theory, it could be built for Windows, though that hasn't been tested. The SIMD implementations are x86-64 specific. Timing in the custom benchmarks is also x86-64 specific (via use of &lt;code&gt;rdtscp&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;History/Motivations This project started as an exploration of using AI agents for software development. Based on experience tuning systems using Abseil's B+tree, I was curious if performance could be improved through SIMD instructions, a customized allocator, and tunable node sizes. Claude proved surprisingly adept at helping implement this quickly, and the resulting B+tree showed compelling performance improvements, so I'm making it available here.&lt;/p&gt;
    &lt;p&gt;Prerequisites:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;C++23 compiler (GCC 14+, Clang 19+)&lt;/item&gt;
      &lt;item&gt;CMake 3.30+&lt;/item&gt;
      &lt;item&gt;AVX2-capable CPU (Intel Haswell 2013+, AMD Excavator 2015+)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Include in your project:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Add as a git submodule:&lt;/p&gt;
        &lt;quote&gt;git submodule add https://github.com/kressler/fast-containers.git third_party/fast-containers&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Link in CMakeLists.txt:&lt;/p&gt;
        &lt;quote&gt;add_subdirectory(third_party/fast-containers) target_link_libraries(your_target PRIVATE fast_containers::fast_containers)&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Include headers:&lt;/p&gt;
        &lt;quote&gt;#include &amp;lt;fast_containers/btree.hpp&amp;gt; #include &amp;lt;fast_containers/hugepage_allocator.hpp&amp;gt;&lt;/quote&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;#include &amp;lt;fast_containers/btree.hpp&amp;gt;
#include &amp;lt;cstdint&amp;gt;
#include &amp;lt;iostream&amp;gt;

int main() {
  // Create a btree mapping int64_t keys to int32_t values
  // Using defaults: auto-computed node sizes, Linear search
  using Tree = kressler::fast_containers::btree&amp;lt;int64_t, int32_t&amp;gt;;

  Tree tree;

  // Insert key-value pairs
  tree.insert(42, 100);
  tree.insert(17, 200);
  tree.insert(99, 300);

  // Find a value
  auto it = tree.find(42);
  if (it != tree.end()) {
    std::cout &amp;lt;&amp;lt; "Found: " &amp;lt;&amp;lt; it-&amp;gt;second &amp;lt;&amp;lt; std::endl;  // Prints: 100
  }

  // Iterate over all elements (sorted by key)
  for (const auto&amp;amp; [key, value] : tree) {
    std::cout &amp;lt;&amp;lt; key &amp;lt;&amp;lt; " -&amp;gt; " &amp;lt;&amp;lt; value &amp;lt;&amp;lt; std::endl;
  }

  // Erase an element
  tree.erase(17);

  // Check size
  std::cout &amp;lt;&amp;lt; "Size: " &amp;lt;&amp;lt; tree.size() &amp;lt;&amp;lt; std::endl;  // Prints: 2
}&lt;/code&gt;
    &lt;code&gt;#include &amp;lt;fast_containers/btree.hpp&amp;gt;
#include &amp;lt;fast_containers/hugepage_allocator.hpp&amp;gt;
#include &amp;lt;cstdint&amp;gt;
#include &amp;lt;cassert&amp;gt;

int main() {
  // Use the hugepage allocator for 3-5× performance improvement
  // Allocator type must match the btree's value_type (std::pair&amp;lt;Key, Value&amp;gt;)
  using Allocator = kressler::fast_containers::HugePageAllocator&amp;lt;
      std::pair&amp;lt;int64_t, int32_t&amp;gt;&amp;gt;;

  using Tree = kressler::fast_containers::btree&amp;lt;
    int64_t,                                 // Key type
    int32_t,                                 // Value type
    96,                                      // Leaf node size
    128,                                     // Internal node size
    std::less&amp;lt;int64_t&amp;gt;,                      // Comparator
    kressler::fast_containers::SearchMode::SIMD,  // SIMD search
    Allocator                                // Hugepage allocator
  &amp;gt;;

  // Tree will default-construct the allocator (256MB initial pool, 64MB growth)
  // The btree automatically creates separate pools for leaf and internal nodes
  Tree tree;

  // Insert 10 million elements - hugepages reduce TLB misses
  for (int64_t i = 0; i &amp;lt; 10'000'000; ++i) {
    tree.insert(i, i * 2);
  }

  // Find operations are much faster with hugepages
  auto it = tree.find(5'000'000);
  assert(it != tree.end() &amp;amp;&amp;amp; it-&amp;gt;second == 10'000'000);
}&lt;/code&gt;
    &lt;p&gt;For multiple trees or fine-grained control over pool sizes, use &lt;code&gt;PolicyBasedHugePageAllocator&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;#include &amp;lt;fast_containers/btree.hpp&amp;gt;
#include &amp;lt;fast_containers/policy_based_hugepage_allocator.hpp&amp;gt;
#include &amp;lt;cstdint&amp;gt;

int main() {
  // Create separate pools for leaf and internal nodes with custom sizes
  auto leaf_pool = std::make_shared&amp;lt;kressler::fast_containers::HugePagePool&amp;gt;(
      512 * 1024 * 1024, true);  // 512MB for leaves
  auto internal_pool = std::make_shared&amp;lt;kressler::fast_containers::HugePagePool&amp;gt;(
      256 * 1024 * 1024, true);  // 256MB for internals

  // Create policy that routes types to appropriate pools
  kressler::fast_containers::TwoPoolPolicy policy{leaf_pool, internal_pool};

  // Create allocator with the policy
  using Allocator = kressler::fast_containers::PolicyBasedHugePageAllocator&amp;lt;
      std::pair&amp;lt;int64_t, int32_t&amp;gt;,
      kressler::fast_containers::TwoPoolPolicy&amp;gt;;

  Allocator alloc(policy);

  using Tree = kressler::fast_containers::btree&amp;lt;
    int64_t, int32_t, 96, 128, std::less&amp;lt;int64_t&amp;gt;,
    kressler::fast_containers::SearchMode::SIMD, Allocator&amp;gt;;

  // Multiple trees can share the same pools
  Tree tree1(alloc);
  Tree tree2(alloc);

  // Both trees share leaf_pool for leaves and internal_pool for internals
  tree1.insert(1, 100);
  tree2.insert(2, 200);
}&lt;/code&gt;
    &lt;p&gt;For containers that allocate variable-sized objects (like &lt;code&gt;absl::btree_map&lt;/code&gt;), use &lt;code&gt;MultiSizeHugePageAllocator&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;#include &amp;lt;fast_containers/multi_size_hugepage_allocator.hpp&amp;gt;
#include &amp;lt;absl/container/btree_map.h&amp;gt;
#include &amp;lt;array&amp;gt;
#include &amp;lt;cstdint&amp;gt;

int main() {
  // absl::btree_map allocates different-sized nodes (leaf vs internal)
  // MultiSizeHugePageAllocator routes allocations to size-class-specific pools

  using ValueType = std::array&amp;lt;std::byte, 32&amp;gt;;
  using Allocator = kressler::fast_containers::MultiSizeHugePageAllocator&amp;lt;
      std::pair&amp;lt;const int64_t, ValueType&amp;gt;&amp;gt;;

  // Helper function creates allocator with default settings
  // - 64MB initial size per size class
  // - Hugepages enabled
  // - 64MB growth size per size class
  auto alloc = kressler::fast_containers::make_multi_size_hugepage_allocator&amp;lt;
      std::pair&amp;lt;const int64_t, ValueType&amp;gt;&amp;gt;();

  // Create absl::btree_map with hugepage allocator
  absl::btree_map&amp;lt;int64_t, ValueType, std::less&amp;lt;int64_t&amp;gt;, Allocator&amp;gt; tree(alloc);

  // Insert 1 million elements - multiple size classes created automatically
  for (int64_t i = 0; i &amp;lt; 1'000'000; ++i) {
    tree[i] = ValueType{};
  }

  // Find operations benefit from reduced TLB misses
  auto it = tree.find(500'000);
}&lt;/code&gt;
    &lt;p&gt;How it works:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Allocations are routed to size classes based on requested size&lt;/item&gt;
      &lt;item&gt;Size classes: 0-512B (64B alignment), 513-2048B (256B alignment), 2049+B (power-of-2)&lt;/item&gt;
      &lt;item&gt;Each size class maintains its own &lt;code&gt;HugePagePool&lt;/code&gt;with uniform-sized blocks&lt;/item&gt;
      &lt;item&gt;Pools created on-demand as different sizes are requested&lt;/item&gt;
      &lt;item&gt;Provides 2-3× performance improvement for &lt;code&gt;absl::btree_map&lt;/code&gt;over standard allocator&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When to use each allocator:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;HugePageAllocator&lt;/code&gt;: Simple, automatic separate pools per type (recommended for our btree)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;MultiSizeHugePageAllocator&lt;/code&gt;: Variable-sized allocations (e.g.,&lt;code&gt;absl::btree_map&lt;/code&gt;, other STL containers with allocator support)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;PolicyBasedHugePageAllocator&lt;/code&gt;: Fine-grained control, shared pools across trees, custom pool sizes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The &lt;code&gt;btree&lt;/code&gt; class provides an API similar to &lt;code&gt;std::map&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;Insertion:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;std::pair&amp;lt;iterator, bool&amp;gt; insert(const Key&amp;amp; key, const Value&amp;amp; value)&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;std::pair&amp;lt;iterator, bool&amp;gt; emplace(Args&amp;amp;&amp;amp;... args)&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;Value&amp;amp; operator[](const Key&amp;amp; key)&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Lookup:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;iterator find(const Key&amp;amp; key)&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;const_iterator find(const Key&amp;amp; key) const&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;iterator lower_bound(const Key&amp;amp; key)&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;iterator upper_bound(const Key&amp;amp; key)&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;std::pair&amp;lt;iterator, iterator&amp;gt; equal_range(const Key&amp;amp; key)&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Removal:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;size_type erase(const Key&amp;amp; key)&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;iterator erase(iterator pos)&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Iteration:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;iterator begin()&lt;/code&gt;/&lt;code&gt;const_iterator begin() const&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;iterator end()&lt;/code&gt;/&lt;code&gt;const_iterator end() const&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Range-based for loops supported&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Capacity:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;size_type size() const&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;bool empty() const&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;void clear()&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Other:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;void swap(btree&amp;amp; other) noexcept&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;key_compare key_comp() const&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;value_compare value_comp() const&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;template &amp;lt;
  typename Key,
  typename Value,
  std::size_t LeafNodeSize = default_leaf_node_size&amp;lt;Key, Value&amp;gt;(),
  std::size_t InternalNodeSize = default_internal_node_size&amp;lt;Key&amp;gt;(),
  typename Compare = std::less&amp;lt;Key&amp;gt;,
  SearchMode SearchModeT = SearchMode::Linear,
  typename Allocator = std::allocator&amp;lt;std::pair&amp;lt;Key, Value&amp;gt;&amp;gt;
&amp;gt;
class btree;&lt;/code&gt;
    &lt;p&gt;Parameters:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;Key&lt;/code&gt;,&lt;code&gt;Value&lt;/code&gt;: The key and value types&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;LeafNodeSize&lt;/code&gt;: Number of key-value pairs per leaf node&lt;list rend="ul"&gt;&lt;item&gt;Default: Auto-computed heuristic targeting ~2KB (32 cache lines)&lt;/item&gt;&lt;item&gt;Formula: &lt;code&gt;2048 / (sizeof(Key) + sizeof(Value))&lt;/code&gt;, rounded to multiple of 8, clamped to [8, 64]&lt;/item&gt;&lt;item&gt;Manual tuning: Larger values (64-96) for small values, smaller values (8-16) for large values&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;InternalNodeSize&lt;/code&gt;: Number of child pointers per internal node&lt;list rend="ul"&gt;&lt;item&gt;Default: Auto-computed heuristic targeting ~1KB (16 cache lines)&lt;/item&gt;&lt;item&gt;Formula: &lt;code&gt;1024 / (sizeof(Key) + sizeof(void*))&lt;/code&gt;, rounded to multiple of 8, clamped to [16, 64]&lt;/item&gt;&lt;item&gt;Generally leave at default (stores only 8-byte pointers)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Compare&lt;/code&gt;: Comparison function (must satisfy&lt;code&gt;ComparatorCompatible&amp;lt;Key, Compare&amp;gt;&lt;/code&gt;)&lt;list rend="ul"&gt;&lt;item&gt;Default: &lt;code&gt;std::less&amp;lt;Key&amp;gt;&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Also supports &lt;code&gt;std::greater&amp;lt;Key&amp;gt;&lt;/code&gt;for descending order&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Default: &lt;/item&gt;
      &lt;item&gt;&lt;code&gt;SearchMode&lt;/code&gt;: How to search within a node&lt;list rend="ul"&gt;&lt;item&gt;Default: &lt;code&gt;SearchMode::Linear&lt;/code&gt;(scalar linear search)&lt;/item&gt;&lt;item&gt;&lt;code&gt;SearchMode::SIMD&lt;/code&gt;: AVX2-accelerated search (3-10% faster, requires AVX2 CPU and SIMD-compatible keys: int32_t, uint32_t, int64_t, uint64_t, float, double)&lt;/item&gt;&lt;item&gt;&lt;code&gt;SearchMode::Binary&lt;/code&gt;: Binary search&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Default: &lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Allocator&lt;/code&gt;: Memory allocation strategy&lt;list rend="ul"&gt;&lt;item&gt;Default: &lt;code&gt;std::allocator&amp;lt;std::pair&amp;lt;Key, Value&amp;gt;&amp;gt;&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Recommended for performance: &lt;code&gt;HugePageAllocator&amp;lt;std::pair&amp;lt;Key, Value&amp;gt;&amp;gt;&lt;/code&gt;for working sets &amp;gt;1GB (3-5× faster)&lt;list rend="ul"&gt;&lt;item&gt;Automatically creates separate pools for leaf and internal nodes via rebind&lt;/item&gt;&lt;item&gt;Default: 256MB initial pool, 64MB growth per pool&lt;/item&gt;&lt;item&gt;Requires hugepages configured: &lt;code&gt;sudo sysctl -w vm.nr_hugepages=&amp;lt;num_pages&amp;gt;&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Falls back to regular pages if unavailable&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;For variable-sized allocations: &lt;code&gt;MultiSizeHugePageAllocator&amp;lt;std::pair&amp;lt;Key, Value&amp;gt;&amp;gt;&lt;/code&gt;&lt;list rend="ul"&gt;&lt;item&gt;Routes allocations to size-class-specific pools&lt;/item&gt;&lt;item&gt;Use with &lt;code&gt;absl::btree_map&lt;/code&gt;or other containers that allocate different-sized objects&lt;/item&gt;&lt;item&gt;Provides 2-3× speedup for Abseil btree over standard allocator&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Advanced control: &lt;code&gt;PolicyBasedHugePageAllocator&amp;lt;std::pair&amp;lt;Key, Value&amp;gt;, TwoPoolPolicy&amp;gt;&lt;/code&gt;&lt;list rend="ul"&gt;&lt;item&gt;Fine-grained control over pool sizes&lt;/item&gt;&lt;item&gt;Share pools across multiple trees&lt;/item&gt;&lt;item&gt;Separate pools for leaf and internal nodes with custom sizes&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Default: &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Benchmarks comparing against Abseil's &lt;code&gt;btree_map&lt;/code&gt; and &lt;code&gt;std::map&lt;/code&gt; are available in results/btree_benchmark_results.md.&lt;/p&gt;
    &lt;p&gt;Our btree with hugepages (&lt;code&gt;btree_8_32_96_128_simd_hp&lt;/code&gt;):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;INSERT P99.9: 1,023 ns&lt;/item&gt;
      &lt;item&gt;FIND P99.9: 864 ns&lt;/item&gt;
      &lt;item&gt;ERASE P99.9: 1,086 ns&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Our btree with standard allocator (&lt;code&gt;btree_8_32_96_128_simd&lt;/code&gt;):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;INSERT P99.9: 3,155 ns (3.1× slower than with hugepages)&lt;/item&gt;
      &lt;item&gt;FIND P99.9: 950 ns (1.1× slower than with hugepages)&lt;/item&gt;
      &lt;item&gt;ERASE P99.9: 1,323 ns (1.2× slower than with hugepages)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;vs. Abseil btree with hugepages (&lt;code&gt;absl_8_32_hp&lt;/code&gt; using &lt;code&gt;MultiSizeHugePageAllocator&lt;/code&gt;):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;INSERT P99.9: 1,401 ns (27% slower)&lt;/item&gt;
      &lt;item&gt;FIND P99.9: 1,190 ns (38% slower)&lt;/item&gt;
      &lt;item&gt;ERASE P99.9: 1,299 ns (20% slower)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;vs. Abseil btree with standard allocator (&lt;code&gt;absl_8_32&lt;/code&gt;):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;INSERT P99.9: 3,287 ns (3.2× slower)&lt;/item&gt;
      &lt;item&gt;FIND P99.9: 1,342 ns (55% slower)&lt;/item&gt;
      &lt;item&gt;ERASE P99.9: 1,679 ns (55% slower)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;vs. std::map (&lt;code&gt;map_8_32&lt;/code&gt;):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;INSERT P99.9: 3,587 ns (3.5× slower)&lt;/item&gt;
      &lt;item&gt;FIND P99.9: 2,312 ns (2.7× slower)&lt;/item&gt;
      &lt;item&gt;ERASE P99.9: 2,253 ns (2.1× slower)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Hugepage allocators provide massive performance improvements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Our btree: 2-3× faster with hugepages vs. standard allocator&lt;/item&gt;
      &lt;item&gt;Abseil btree: 2× faster with &lt;code&gt;MultiSizeHugePageAllocator&lt;/code&gt;vs. standard allocator&lt;/item&gt;
      &lt;item&gt;Critical for large working sets (&amp;gt;1M elements)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Our implementation maintains significant advantages even with fair comparison:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;20-67% faster than Abseil btree even when both use hugepage allocators&lt;/item&gt;
      &lt;item&gt;Advantages from SIMD search, tunable node sizes, and optimized bulk transfers&lt;/item&gt;
      &lt;item&gt;Performance gap widens with larger values (256 bytes: 21-135% faster)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Performance varies by tree size:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Large trees (10M elements): Our btree dominates all metrics&lt;/item&gt;
      &lt;item&gt;Small trees (10K elements): Competition intensifies, std::map becomes viable for some workloads&lt;/item&gt;
      &lt;item&gt;See benchmark results for detailed analysis&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The hugepage allocator is the single most important optimization, providing benefits by reducing TLB misses (helps find operations) and making allocations extremely cheap through pooling (helps insert/erase operations).&lt;/p&gt;
    &lt;code&gt;# List available presets
cmake --list-presets

# Configure, build, and test in one workflow
cmake --preset release
cmake --build --preset release
ctest --preset release

# Common presets:
cmake --preset debug          # Debug build
cmake --preset release        # Release with AVX2 (default)
cmake --preset asan           # AddressSanitizer build
cmake --preset release-no-avx2  # Release without AVX2&lt;/code&gt;
    &lt;code&gt;# Clone with submodules
git clone --recursive https://github.com/kressler/fast-containers.git
cd fast-containers

# Configure
cmake -S . -B build -DCMAKE_BUILD_TYPE=Release

# Build
cmake --build build

# Run tests
ctest --test-dir build --output-on-failure&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Option&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;ENABLE_AVX2&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;ON&lt;/code&gt; (Release), &lt;code&gt;OFF&lt;/code&gt; (Debug)&lt;/cell&gt;
        &lt;cell&gt;Enable AVX2 SIMD optimizations&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;ENABLE_ASAN&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;OFF&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Enable AddressSanitizer&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;ENABLE_ALLOCATOR_STATS&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;OFF&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Enable allocator statistics&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;ENABLE_LTO&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;ON&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Enable Link-Time Optimization&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;ENABLE_NUMA&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Auto-detected&lt;/cell&gt;
        &lt;cell&gt;Enable NUMA support (requires libnuma)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Clone with submodules:&lt;/p&gt;
        &lt;code&gt;git clone --recursive https://github.com/kressler/fast-containers.git cd fast-containers&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;One-time development setup:&lt;/p&gt;
        &lt;quote&gt;./setup-dev.sh&lt;/quote&gt;
        &lt;p&gt;This installs pre-commit hooks and configures clang-tidy.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Automatic formatting and checks (via pre-commit hook):&lt;/p&gt;
    &lt;code&gt;git commit  # Automatically formats code and runs clang-tidy&lt;/code&gt;
    &lt;p&gt;The pre-commit hook will:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Format all staged C++ files with clang-format&lt;/item&gt;
      &lt;item&gt;Check production headers with clang-tidy&lt;/item&gt;
      &lt;item&gt;Fail the commit if warnings are found&lt;/item&gt;
      &lt;item&gt;Auto-create build directories if missing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Manual formatting:&lt;/p&gt;
    &lt;code&gt;cmake --build build --target format&lt;/code&gt;
    &lt;p&gt;Manual static analysis:&lt;/p&gt;
    &lt;code&gt;cmake --build build --target clang-tidy
# Or manually:
clang-tidy-19 -p cmake-build-clang-tidy include/fast_containers/*.hpp&lt;/code&gt;
    &lt;p&gt;Requirements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;clang-format (for code formatting)&lt;/item&gt;
      &lt;item&gt;clang-tidy-19 (for static analysis)&lt;/item&gt;
      &lt;item&gt;cmake (to auto-create build directories)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Bypass hook (when needed):&lt;/p&gt;
    &lt;code&gt;git commit --no-verify&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Make your changes&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Build and test:&lt;/p&gt;
        &lt;code&gt;cmake --build build &amp;amp;&amp;amp; ctest --test-dir build&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Commit (auto-formatted and checked):&lt;/p&gt;
        &lt;quote&gt;git add . git commit -m "Your changes" # Pre-commit hook runs automatically&lt;/quote&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Follow Google C++ Style Guide (enforced by clang-format)&lt;/item&gt;
      &lt;item&gt;Use C++23 features&lt;/item&gt;
      &lt;item&gt;Write tests for new functionality using Catch2&lt;/item&gt;
      &lt;item&gt;Production code must be clang-tidy clean (enforced in CI and pre-commit)&lt;/item&gt;
      &lt;item&gt;Run &lt;code&gt;cmake --build build --target format&lt;/code&gt;before submitting PRs&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;.
├── include/
│   └── fast_containers/         # Public header files
│       ├── btree.hpp, btree.ipp
│       ├── dense_map.hpp, dense_map.ipp
│       ├── hugepage_allocator.hpp
│       ├── multi_size_hugepage_allocator.hpp
│       ├── multi_size_hugepage_pool.hpp
│       ├── policy_based_hugepage_allocator.hpp
│       └── hugepage_pool.hpp
├── tests/                       # Unit tests (Catch2)
│   ├── test_btree.cpp
│   ├── test_dense_map.cpp
│   ├── test_hugepage_allocator.cpp
│   └── test_policy_based_allocator.cpp
├── src/
│   ├── benchmarks/              # Google Benchmark performance tests
│   │   ├── dense_map_search_benchmark.cpp
│   │   └── hugepage_allocator_benchmark.cpp
│   └── binary/                  # Standalone benchmark executables
│       ├── btree_benchmark.cpp
│       └── btree_stress.cpp
├── scripts/
│   └── interleaved_btree_benchmark.py  # A/B testing harness
├── results/
│   └── btree_benchmark_results.md      # Performance analysis
├── third_party/                 # Git submodules
│   ├── catch2/                  # Unit testing framework
│   ├── benchmark/               # Google Benchmark
│   ├── histograms/              # Latency histogram library
│   ├── abseil-cpp/              # Comparison baseline
│   ├── lyra/                    # Command-line parsing
│   └── unordered_dense/         # Dense hash map
├── hooks/                       # Git hooks (install with setup-dev.sh)
│   └── pre-commit               # Auto-format and clang-tidy
└── CMakeLists.txt               # Build configuration
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Language: C++23&lt;/item&gt;
      &lt;item&gt;Build System: CMake 3.30+&lt;/item&gt;
      &lt;item&gt;Testing: Catch2 v3.11.0&lt;/item&gt;
      &lt;item&gt;Code Formatting: clang-format (Google C++ Style)&lt;/item&gt;
      &lt;item&gt;Static Analysis: clang-tidy-19&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46512842</guid><pubDate>Tue, 06 Jan 2026 14:41:55 +0000</pubDate></item><item><title>65% of Hacker News Posts Have Negative Sentiment, and They Outperform</title><link>https://philippdubach.com/standalone/hn-sentiment/</link><description>&lt;doc fingerprint="350c80263eb05556"&gt;
  &lt;main&gt;
    &lt;p&gt;Posts with negative sentiment average 35.6 points on Hacker News. The overall average is 28 points. That’s a 27% performance premium for negativity. This finding comes from an empirical study I’ve been running on HN attention dynamics, covering decay curves, preferential attachment, survival probability, and early-engagement prediction. The preprint is available on SSRN. I already had a gut feeling. Across 32,000 posts and 340,000 comments, nearly 65% register as negative. This might be a feature of my classifier being miscalibrated toward negativity; yet the pattern holds across six different models. I tested three transformer-based classifiers (DistilBERT, BERT Multi, RoBERTa) and three LLMs (Llama 3.1 8B, Mistral 3.1 24B, Gemma 3 12B). The distributions vary, but the negative skew persists across all of them (inverted scale for 2-6). The results I use in my dashboard are from DistilBERT because it runs efficiently in my Cloudflare-based pipeline.&lt;/p&gt;
    &lt;p&gt;What counts as “negative” here? Criticism of technology, skepticism toward announcements, complaints about industry practices, frustration with APIs. The usual. It’s worth noting that technical critique reads differently than personal attacks; most HN negativity is substantive rather than toxic. But, does negativity cause engagement, or does controversial content attract both negative framing and attention? Probably some of both.&lt;/p&gt;
    &lt;p&gt;I’ll publish the full code, dataset, and a dashboard for the HN archiver soon and I’m happy to send you an update:&lt;/p&gt;
    &lt;p&gt;Alternatively, you can also subscribe to the RSS feed or get updates on Bluesky.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46512881</guid><pubDate>Tue, 06 Jan 2026 14:45:47 +0000</pubDate></item><item><title>New Lego smart-play system</title><link>https://www.lego.com/en-us/smart-play</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46513173</guid><pubDate>Tue, 06 Jan 2026 15:05:46 +0000</pubDate></item><item><title>Mamdani Targets Junk Fees and Hidden Charges in Two Executive Orders</title><link>https://www.nytimes.com/2026/01/05/nyregion/mamdani-affordability-consumer-protections.html</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46514059</guid><pubDate>Tue, 06 Jan 2026 16:02:56 +0000</pubDate></item><item><title>State of the Fin 2026-01-06 – Jellyfin</title><link>https://jellyfin.org/posts/state-of-the-fin-2026-01-06/</link><description>&lt;doc fingerprint="fe7c95df8880a4da"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;State of the Fin 2026-01-06&lt;/head&gt;
    &lt;p&gt;Happy New Year and welcome to the State of the Fin! This new blog series will regularly basis highlight the ongoing development of Jellyfin and our official clients. We aim to keep our community informed and engaged, so feel free to share your feedback or thoughts on our progress!&lt;/p&gt;
    &lt;head rend="h2"&gt;Project Updates&lt;/head&gt;
    &lt;head rend="h3"&gt;Jellyfin Turns 7&lt;/head&gt;
    &lt;p&gt;December marked Jellyfin's 7th anniversary! A lot has changed in 7 years, but we remain steadfast in our commitment to Open Source and to being the best personal media server out there. Special thanks to our developers, testers, moderators, and supporters for your invaluable contributions! Here's to many more years of collaboration and streaming!&lt;/p&gt;
    &lt;head rend="h3"&gt;Versioning&lt;/head&gt;
    &lt;p&gt;We received a substantial amount of feedback regarding our versioning scheme following the 10.11 release, particularly concerning the stability of what are perceived as 'minor' version updates. This has prompted internal discussions about potentially revising our versioning scheme in the next major release. While nothing has been finalized yet, we are considering 'dropping' the major version 10, which would make the next release 12.0. Stay tuned for further updates as we navigate this feedback!&lt;/p&gt;
    &lt;head rend="h2"&gt;Development Updates&lt;/head&gt;
    &lt;head rend="h3"&gt;10.11 Release Status&lt;/head&gt;
    &lt;p&gt;Jellyfin 10.11 introduced a major EF Core refactor, consolidating the legacy &lt;code&gt;library.db&lt;/code&gt; into a single unified &lt;code&gt;jellyfin.db&lt;/code&gt;.
Following more than six months of development and an additional six months of release candidate testing, version 10.11.0 was released last year.
This extended testing period allowed us to mitigate most refactoring and RC-related issues prior to release.&lt;/p&gt;
    &lt;p&gt;Even with this level of testing, issues were expected given the scale of the database change and the limited number of users reporting bugs. These issues are currently being tracked on GitHub across three categories:&lt;/p&gt;
    &lt;p&gt;We have been moving quickly to address these issues, delivering four additional point releases with over 100 changes since the initial 10.11.0 release. To date, most point releases have focused on resolving general and migration-related issues. The remaining migration issues are largely isolated, one-off cases and are unlikely to be resolved. Most general issues have already been fixed, and the next bug-fix release is expected to include additional fixes for music metadata display issues and for watched status not being preserved when media is replaced or renamed.&lt;/p&gt;
    &lt;p&gt;We are continuing to investigate ways to mitigate performance issues caused by client-side enumeration and filtering of large datasets.&lt;/p&gt;
    &lt;head rend="h3"&gt;Jellyfin Web vNext (aka 10.12 / 12.0)&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Default 'Experimental' Layout: The 'Experimental' layout is now enabled by default for all non-TV devices, introducing a new navigation layout and updated UI components.&lt;/item&gt;
      &lt;item&gt;Theming Support Overhaul: We are improving theming support by enabling easier runtime customization of default themes through CSS variables and simplifying the process for creating new bundled themes.&lt;/item&gt;
      &lt;item&gt;Community Acknowledgment: Huge thanks to those reviewing, testing, and providing feedback on web pull requests. Your contributions are immensely helpful, as the review burden largely falls on me alone!&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Client Corner&lt;/head&gt;
    &lt;head rend="h3"&gt;Jellyfin Desktop&lt;/head&gt;
    &lt;p&gt;We're rebranding the desktop application from Jellyfin Media Player to Jellyfin Desktop. The most noteworthy change is the migration from Qt 5 to Qt 6. This seems to have improved overall performance, though we're still working out issues regarding memory leaks due to the migration.&lt;/p&gt;
    &lt;p&gt;Apart from the Qt migration, other noteworthy updates.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Saved servers and settings will not be migrated from Jellyfin Media Player.&lt;/item&gt;
      &lt;item&gt;We've laid the foundation for switching servers with the addition of profiles CLI options. The long-term goal is to have a UI for this as well, but the timeline is TBD.&lt;/item&gt;
      &lt;item&gt;A slew of bug fixes are included.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The release is currently available on Flathub and in the Arch Linux AUR. Stable builds for Windows and macOS builds are not currently available. Other Linux distributions will likely be added, though we recommend using Flathub for the time being. We are not currently supporting Ubuntu 24.04 LTS due to it being stuck on the older Qt 6.4 series, while our new dependency, mpvqt, requires at least Qt 6.5.&lt;/p&gt;
    &lt;head rend="h3"&gt;Jellyfin for Android TV&lt;/head&gt;
    &lt;p&gt;Two versions of the Android TV app have been released: v0.19.5 and v0.19.6! These updates contain various improvements to music transcoding. The app now properly displays durations again and allows for seeking when music is transcoding. These changes also solve the issue of lyrics not scrolling in certain cases.&lt;/p&gt;
    &lt;p&gt;For video playback, we have improved the stability of Live TV and now support direct play for the VC-1 and AV1 codecs (if your device supports them). The AV1 support was already available on Android 10 and newer but now works on older Fire TV devices as well.&lt;/p&gt;
    &lt;head rend="h3"&gt;Jellyfin for Xbox&lt;/head&gt;
    &lt;p&gt;The last two updates brought the long awaited full gamepad support and fixes for 4K and HDR.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Gamepad support: Gamepad navigation is now the default navigation type for the Jellyfin for Xbox app and requires a server version of 10.11 or higher to work. However as we cannot switch the input mode type while the app is running, the Jellyfin for Xbox app can no longer connect to older versions than 10.11. As this is a fundamental change in how the app works, there are still a few hiccups like the app not loading correctly and users reporting that the gamepad does not work at all. In those instances we recommend uninstalling and reinstalling the app.&lt;/item&gt;
      &lt;item&gt;Web UI TV mode: For versions of Jellyfin earlier than 10.11.5 the web UI still runs in the desktop mode, which might look a bit odd. However, with Jellyfin 10.11.5, we have fixed a bug that now correctly sets the web UI to TV mode, so the UI should work a lot better.&lt;/item&gt;
      &lt;item&gt;4K and HDR: For the last few versions, we have been working on enabling 4K and HDR for the app. This is done by integrating with the web UI and switching the HDMI modes. Sadly, this also comes at the cost of not being allowed to run in the background. To enable 4K support, we had to use a feature flag that allocates more video memory to the Jellyfin for Xbox app, making it incompatible with running in the background.&lt;/item&gt;
      &lt;item&gt;General Improvements: Alongside the shiny new headline features, we have also been working on the code in general, adding small improvements and cleaning up a lot of code. The latest versions added log files and their upload to the Jellyfin server, tighter integrations with the web UI, a settings view that can be expanded for future features, version compatibility checking, a better server connection experience, and more.&lt;/item&gt;
      &lt;item&gt;Future: When I took over the for the previous maintainer almost a year ago, I made a rough plan for the general development of the app. I always planned on keeping the app as a web wrapper because while the app is certainly more popular than most think, it does not have enough support in development to be a full UWP app. Nevertheless, there are a few features left on my to-do list: &lt;list rend="ul"&gt;&lt;item&gt;Localization to other languages&lt;/item&gt;&lt;item&gt;Server discovery&lt;/item&gt;&lt;item&gt;Desktop support&lt;/item&gt;&lt;item&gt;Better decoder support&lt;/item&gt;&lt;item&gt;Subtitle storage on-device&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;- JPVenson&lt;/p&gt;
    &lt;head rend="h3"&gt;Jellyfin for Roku&lt;/head&gt;
    &lt;p&gt;3.0.15 was released on 2025-12-18 and is our last release before Roku's year-end publishing blackout. It fixes a bug with HDHomeRun Tuners.&lt;/p&gt;
    &lt;p&gt;- 1hitsong&lt;/p&gt;
    &lt;head rend="h3"&gt;Swiftfin&lt;/head&gt;
    &lt;head rend="h4"&gt;Swiftfin 1.4 is out now!&lt;/head&gt;
    &lt;p&gt;This is a large release with a lot of changes under the hood. Our three highlight changes are:&lt;/p&gt;
    &lt;head rend="h4"&gt;Swiftfin Roadmap&lt;/head&gt;
    &lt;p&gt;A roadmap / project board for Swiftfin is now available!&lt;/p&gt;
    &lt;p&gt;Follow this discussion for information about the next tvOS release.&lt;/p&gt;
    &lt;p&gt;To help organize Issues &amp;amp; PRs, Swiftfin now has milestones to help users identify which changes will be included in each release:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Version 1.5 &lt;list rend="ul"&gt;&lt;item&gt;Contains issues that should be resolved in version 1.5 of Swiftfin iOS.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;tvOS Resync &lt;list rend="ul"&gt;&lt;item&gt;Contains tvOS-specific issues that will be resolved as part of our next tvOS Release.&lt;/item&gt;&lt;item&gt;Issues that impact tvOS but are part of 1.4 or 1.5 will end up in the version milestone instead of this one. Once tvOS is released, it should mirror our existing 1.X structure and iOS.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A more detailed post about these changes can be found on GitHub!&lt;/p&gt;
    &lt;p&gt;- JPKribs&lt;/p&gt;
    &lt;head rend="h3"&gt;Other TV Platforms&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Tizen app was submitted for review, but unfortunately failed testing. Additional work is needed to replicate the reported issues and correct them.&lt;/item&gt;
      &lt;item&gt;Support for multiple new platforms is currently underway, and we will provide updates as progress is made.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Wishing you all happy streaming in 2026 and beyond! We look forward to another year filled with exciting updates and features for Jellyfin.&lt;/p&gt;
    &lt;p&gt;- thornbill and the Jellyfin Team&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46514282</guid><pubDate>Tue, 06 Jan 2026 16:17:24 +0000</pubDate></item><item><title>Vienam Bans Unskippable Ads, Requires Skip Button to Appear After 5 Seconds</title><link>https://saigoneer.com/vietnam-news/28652-vienam-bans-unskippable-ads,-requires-skip-button-to-appear-after-5-seconds</link><description>&lt;doc fingerprint="6f8928bd4270847c"&gt;
  &lt;main&gt;
    &lt;p&gt;If things go our way, YouTube’s notorious unskippable ads might be a thing of the past come this February.&lt;/p&gt;
    &lt;p&gt;As Phụ Nữ reports, Vietnam recently announced Decree No. 342, which details a number of provisions to the national Advertising Law, due to take effect from February 15, 2026. The adjustments are expected to place stricter control on Vietnam’s online advertising activities to protect consumers and curb illegal ads.&lt;/p&gt;
    &lt;p&gt;Amongst the decree articles, some standout stipulations include a hard cap on the waiting time before viewers can skip video and animated ads to no more than 5 seconds. Static ads must be immediately cancellable.&lt;/p&gt;
    &lt;p&gt;Additionally, the decree requires platforms to implement clear and straightforward ways for users to close ads with just one interaction. False or vague symbols designed to confuse viewers are forbidden.&lt;/p&gt;
    &lt;p&gt;Online platforms must add visible symbols and guidelines to help users report ads that violate the law and allow them to turn off, deny, or stop seeing inappropriate ads.&lt;/p&gt;
    &lt;p&gt;Beside rules about the user experience, the decree also seeks to tightly regulate ads for 11 groups of goods and services that directly impact the environment and human health, including: cosmetics; food and beverages; milk and formula for children; insecticidal chemicals and substances; medical supplies; healthcare services; plant pesticides and veterinary drugs; fertilizers; plant seeds and saplings; pharmaceuticals; and alcoholic drinks.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46514677</guid><pubDate>Tue, 06 Jan 2026 16:45:42 +0000</pubDate></item></channel></rss>