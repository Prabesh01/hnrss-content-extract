<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 11 Oct 2025 11:32:23 +0000</lastBuildDate><item><title>A Molecular Motor Minimizes Energy Waste</title><link>https://physics.aps.org/articles/v18/167</link><description>&lt;doc fingerprint="f54dd18e6121ca5a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How a Molecular Motor Minimizes Energy Waste&lt;/head&gt;
    &lt;p&gt;Within every biological cell is an enzyme, called adenosine triphosphate (ATP) synthase, that churns out energy-rich molecules for fueling the cell’s activity. New experiments investigate the functioning of this “energy factory” by artificially cranking one of the enzyme’s molecular motors [1]. The results suggest that maintaining a fixed rotation rate minimizes energy waste caused by microscopic fluctuations. Future work could confirm the role of efficiency in the evolutionary design of biological motors.&lt;/p&gt;
    &lt;p&gt;ATP synthase consists of two rotating molecular motors, Fo and F1, that are oriented along a common rotation axis and locked together so that the rotation of Fo exerts a torque on the shaft in the middle of F1. The resulting motion within F1 helps bring together the chemical ingredients of the molecule ATP, which stores energy that can later be used in cellular processes.&lt;/p&gt;
    &lt;p&gt;Researchers have determined the motors’ atomic structures, but the details of the coupling between Fo and F1 are unclear. Fo is embedded in a membrane. Protons flow across this membrane and drive Fo’s rotation, but directly measuring Fo’s torque is challenging because it would require reproducing the membrane and its chemical environment in a controllable laboratory setting, says Shoichi Toyabe of Tohoku University in Japan.&lt;/p&gt;
    &lt;p&gt;Toyabe and his colleagues devised an approach for overcoming this challenge. They reasoned that Fo could exert torque on F1 in different ways, but evolution would favor a more energetically efficient driving mechanism. To explore the role of efficiency, the team replaced Fo with an artificial motor and used it to drive F1’s rotation in one of two ways: either by applying constant torque or by fixing the rotation rate with a variable torque. Artificially rotating the F1 motor is not new, but no one has previously been able to drive the motor in two distinct modes and measure their efficiencies.&lt;/p&gt;
    &lt;p&gt;The researchers started by isolating the F1 motor from Bacillus bacteria. They fixed the motor’s outer frame to a glass slide and attached a pair of polystyrene beads to the F1 shaft, using a kind of chemical glue. The researchers then brought in a set of electrodes and applied a time-varying voltage, which caused the beads to turn the shaft around its axis, just as Fo would do. The system was bathed in a solution containing the ATP ingredients so that the F1 motor performed the same chemical assembly that it does in a cell.&lt;/p&gt;
    &lt;p&gt;To find the efficiency in each mode, the team divided the output energy—determined from the F1 shaft’s total rotation—by the input energy supplied by the electrodes. The results showed that the constant-turning mode was more efficient than the constant-torque mode.&lt;/p&gt;
    &lt;p&gt;To explain these observations, team member David Sivak and his colleagues at Simon Fraser University in Canada modeled the effects of fluctuations on the experimental system. These fluctuations come from random thermal motions of the atoms, and they can, for example, nudge the rotation along, or they can push against it. “Some fluctuations hurt and some fluctuations help, but the resisting ones hurt more than the assisting ones help,” Sivak says. He explains that the constant-turning mode better balances the positive and negative effects and is thus more efficient than the constant-torque mode.&lt;/p&gt;
    &lt;p&gt;The researchers argue that their work implies a general guiding principle for molecular machines: Running at a constant speed can suppress the effect of random fluctuations and minimize energy waste. Toyabe says that a similar principle applies to macroscopic motors: “It is often said that driving at a steady speed is the most efficient way to drive a car, as sudden breaking or acceleration typically costs additional energy.”&lt;/p&gt;
    &lt;p&gt;Although a constant-turning mode has advantages, it’s not clear that Fo adopts this strategy. The motor has complicated interactions with its cellular environment that might favor a more complex driving mode. The researchers say that future experiments may uncover new clues about this mechanical behavior by combining Fo with F1 in a controlled, laboratory setting.&lt;/p&gt;
    &lt;p&gt;“The team’s approach to isolate and manipulate the mechanical motion of F1 is elegant, clever, and highly efficient,” says biophysicist Édgar Roldán from the International Centre for Theoretical Physics in Italy. He notes that the researchers performed a control experiment, in which the artificial motor turned freely without attachment to F1. In this case, with “biology” removed, the mechanical system showed no difference in efficiency between the two driving modes. Thus, a sensitivity to driving modes may be an important footprint of biological activity, Roldán says.&lt;/p&gt;
    &lt;p&gt;–Michael Schirber&lt;/p&gt;
    &lt;p&gt;Michael Schirber is a Corresponding Editor for Physics Magazine based in Lyon, France.&lt;/p&gt;
    &lt;head rend="h2"&gt;References&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;T. Mishima et al., “Efficiently driving F1 molecular motor in experiment by suppressing nonequilibrium variation,” Phys. Rev. Lett. 135, 148402 (2025).&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45517717</guid><pubDate>Wed, 08 Oct 2025 16:09:08 +0000</pubDate></item><item><title>Love C, hate C: Web framework memory problems</title><link>https://alew.is/lava.html</link><description>&lt;doc fingerprint="2e3a99cdbcef0edd"&gt;
  &lt;main&gt;
    &lt;p&gt;I love C. I could give you rational reasons for that. Like the fact that it works everywhere and how it goes fast. But mostly I love C because when I write C I feel an intimate connection with my computer. To me, C has soul. In fact all my personal project are written in C, like the graphics rendering engines that I'm currently writing. The problem is that C is dangerous and sharing new C projects to wider audiences is borderline malicious.&lt;/p&gt;
    &lt;p&gt;Today on hacker news a cool little web framework written in C was posted. As a security researcher I'm always trying to sharpen my skills so I thought I'd given the app a look. And yup sure enough, there's memory safety issues.&lt;/p&gt;
    &lt;code&gt;HttpParser parseRequest(char *request) {
    HttpParser parser = {
        .isValid = true,
        .requestBuffer = strdup(request), // [0]
        .requestLength = strlen(request),
        .position = 0,
    };

    // ... irrelevant stuff

    for (int i = 0; i &amp;lt; parser.request.headerCount; i++) {
        if (strcasecmp(parser.request.headers[i].name, "Content-Length") == 0) {
            parser.request.bodyLength = atoi(parser.request.headers[i].value); // [1]
            break;
        }
    }
    
    parser.request.body = malloc(parser.request.bodyLength + 1); // [2]
    for (int i = parser.position; i &amp;lt; parser.position + parser.request.bodyLength; i++) {
        parser.request.body[i - parser.position] = parser.requestBuffer[i]; // [3]
    }&lt;/code&gt;
    &lt;p&gt;line [1] takes Content-Length off the http packet. This is a non validated value basically straight from the socket. line [2] allocates based on that size. Line [3] copies data into that buffer based on that size. But it's copying out of a buffer of any size. So passing a &lt;code&gt;Content-Length&lt;/code&gt; Larger than the &lt;code&gt;request&lt;/code&gt; sent in will start copying heap data into the &lt;code&gt;parser.request.body&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Another interesting choice in this project is to make lengths signed:&lt;/p&gt;
    &lt;code&gt;typedef struct {
    //...

    int        headerCount;
    int        headerCapacity;

    //...
    int        bodyLength;
} HttpRequest;

typedef struct {
    // ...
    
    int         position;
    //...
    int         requestLength;
} HttpParser;&lt;/code&gt;
    &lt;p&gt;What does it mean to have a negative &lt;code&gt;headerCount&lt;/code&gt; or negative of anything here? Maybe there is a valid meaning, but we need to ask ourselves that question. Going back to the original code sample. A malicious user can pass &lt;code&gt;Content-Length&lt;/code&gt; of &lt;code&gt;4294967295&lt;/code&gt;. &lt;code&gt;malloc(parser.request.bodyLength + 1)&lt;/code&gt; which becomes &lt;code&gt;malloc(0)&lt;/code&gt; actually returns a  valid pointer in glibc. Now you won't immediately buffer overflow here because &lt;code&gt;i &amp;lt; parser.position + parser.request.bodyLength&lt;/code&gt; where i is initialized to &lt;code&gt;parser.position&lt;/code&gt; and it's basically &lt;code&gt;parser.position-1&lt;/code&gt; so &lt;code&gt;i&lt;/code&gt; will always be greater. But these mangled request body and length values get routed to the webdevs App. You'd better hope they catch the issue.&lt;/p&gt;
    &lt;p&gt;I love C it's simple, elegant but also so dang annoying.&lt;/p&gt;
    &lt;p&gt;Comments to be found on this hackernews thread. Ping me there to talk security, C, or graphics and rendering haha :)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45535183</guid><pubDate>Fri, 10 Oct 2025 03:39:57 +0000</pubDate></item><item><title>Show HN: Lights Out: my 2D Rubik's Cube-like Game</title><link>https://raymondtana.github.io/projects/pages/Lights_Out.html</link><description>&lt;doc fingerprint="77d1a1abf29021f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Lights Out&lt;/head&gt;
    &lt;p&gt;Lights Out is a mathematical puzzle that lives on an $n \times n$ grid where each cell of the grid is one of two colors: either red or white. The goal is to eventually get all the cells in the grid to be red. You can play the game below:&lt;/p&gt;
    &lt;head rend="h2"&gt;Background&lt;/head&gt;
    &lt;p&gt;The original setup involves a $5 \times 5$ board, on whose cells a user may “click.” Clicking a cell will not only flip the color of that cell, but also flip the color of all the neigbors to its north, east, south, and west (call this rule &lt;code&gt;Adjacent&lt;/code&gt;). But the original variant of the game introduced to me followed a different rule &lt;code&gt;Same Row &amp;amp; Col&lt;/code&gt;: any click flips the color of all cells sharing the same row or column as the clicked cell. Another variant involves all cells sharing the same diagonal (without any wrapping), called &lt;code&gt;Diagonals&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;There is a general strategy for solving an $n \times n$ board following the &lt;code&gt;Same Row &amp;amp; Col&lt;/code&gt; rule whenever $n$ is odd. There’s a different strategy that works under the same rule but for $n$ being even. I’m not aware of general strategies otherwise… let me know if you find one!&lt;/p&gt;
    &lt;head rend="h2"&gt;Implementation&lt;/head&gt;
    &lt;p&gt;Implemented in TypeScript with strict mode enabled. The project utilizes static type-checking, union types, and interfaces.&lt;/p&gt;
    &lt;head rend="h2"&gt;Video&lt;/head&gt;
    &lt;p&gt;Watch the teaser video I made for Lights Out in Manim.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45535424</guid><pubDate>Fri, 10 Oct 2025 04:40:19 +0000</pubDate></item><item><title>Show HN: I invented a new generative model and got accepted to ICLR</title><link>https://discrete-distribution-networks.github.io/</link><description>&lt;doc fingerprint="345c0b1f68b2c5a6"&gt;
  &lt;main&gt;&lt;p&gt;🥳 Accepted by ICLR 2025&lt;lb/&gt;📝 Released a blog with added insights&lt;/p&gt;&lt;p&gt;Discrete Distribution Networks&lt;/p&gt;&lt;p&gt;A novel generative model with simple principles and unique properties&lt;/p&gt;&lt;p&gt;This GIF demonstrates the optimization process of DDN for 2D probability density estimation:&lt;/p&gt;&lt;code&gt;blur_circles&lt;/code&gt; -&amp;gt; &lt;code&gt;QR_code&lt;/code&gt; -&amp;gt; &lt;code&gt;spiral&lt;/code&gt; -&amp;gt; &lt;code&gt;words&lt;/code&gt; -&amp;gt; &lt;code&gt;gaussian&lt;/code&gt; -&amp;gt; &lt;code&gt;blur_circles&lt;/code&gt; (same at beginning and end, completing a cycle)&lt;p&gt;Contributions of this paper:&lt;/p&gt;&lt;p&gt; Left: Illustrates the process of image reconstruction and latent acquisition in DDN. Each layer of DDN outputs &lt;lb/&gt; Right: Shows the tree-structured representation space of DDN's latent variables. Each sample can be mapped to a leaf node on this tree.&lt;/p&gt;&lt;p&gt;Reviews from ICLR:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;I find the method novel and elegant. The novelty is very strong, and this should not be overlooked. This is a whole new method, very different from any of the existing generative models.&lt;/p&gt;&lt;/quote&gt;&lt;quote&gt;&lt;p&gt;This is a very good paper that can open a door to new directions in generative modeling.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;We introduce a novel generative model, the Discrete Distribution Networks (DDN), that approximates data distribution using hierarchical discrete distributions. We posit that since the features within a network inherently capture distributional information, enabling the network to generate multiple samples simultaneously, rather than a single output, may offer an effective way to represent distributions. Therefore, DDN fits the target distribution, including continuous ones, by generating multiple discrete sample points. To capture finer details of the target data, DDN selects the output that is closest to the Ground Truth (GT) from the coarse results generated in the first layer. This selected output is then fed back into the network as a condition for the second layer, thereby generating new outputs more similar to the GT. As the number of DDN layers increases, the representational space of the outputs expands exponentially, and the generated samples become increasingly similar to the GT. This hierarchical output pattern of discrete distributions endows DDN with unique properties: more general zero-shot conditional generation and 1D latent representation. We demonstrate the efficacy of DDN and its intriguing properties through experiments on CIFAR-10 and FFHQ.&lt;/p&gt;&lt;p&gt;DDN enables more general zero-shot conditional generation. DDN supports zero-shot conditional generation across non-pixel domains, and notably, without relying on gradient, such as text-to-image generation using a black-box CLIP model. Images enclosed in yellow borders serve as the ground truth. The abbreviations in the table header correspond to their respective tasks as follows: “SR” stands for Super-Resolution, with the following digit indicating the resolution of the condition. “ST” denotes Style Transfer, which computes Perceptual Losses with the condition.&lt;/p&gt;&lt;p&gt; (a) The data flow during the training phase of DDN is shown at the top. As the network depth increases, the generated images become increasingly similar to the training images. Within each Discrete Distribution Layer (DDL), &lt;/p&gt;&lt;p&gt;Here, &lt;/p&gt;&lt;p&gt;The numerical values at the bottom of each figure represent the Kullback-Leibler (KL) divergence. Due to phenomena such as “dead nodes” and “density shift”, the application of Gradient Descent alone fails to properly fit the Ground Truth (GT) density. However, by employing the Split-and-Prune strategy, the KL divergence is reduced to even lower than that of the Real Samples. For a clearer and more comprehensive view of the optimization process, see the 2D Density Estimation with 10,000 Nodes DDN page.&lt;/p&gt;&lt;p&gt;The text at the top is the guide text for that column.&lt;/p&gt;&lt;p&gt;Columns 4 and 5 display the generated results under the guidance of other images, where the produced image strives to adhere to the style of the guided image as closely as possible while ensuring compliance with the condition. The resolution of the generated images is 256x256.&lt;/p&gt;&lt;p&gt;To demonstrate the features of DDN conditional generation and Zero-Shot Conditional Generation.&lt;/p&gt;&lt;p&gt;We trained a DDN with output level &lt;/p&gt;&lt;p&gt;Uncompressed raw backup of this video is here: DDN_latent_video&lt;/p&gt;&lt;p&gt;The following content contains personal opinions and is not included in the original paper&lt;/p&gt;&lt;p&gt;Based on the current state of DDN, we speculate on several possible future research directions. These include improvements to DDN itself and tasks suitable for the current version of DDN. Due to my limited perspective, some of these speculations might not be accurate:&lt;/p&gt;&lt;p&gt;Improving DDN through hyperparameter tuning, exploratory experiments, and theoretical analysis:&lt;lb/&gt;The total time spent developing DDN was less than three months, mostly by a single person. Therefore, experiments were preliminary, and there was limited time for detailed analysis and tuning. There is significant room for improvement.&lt;/p&gt;&lt;p&gt;Scaling up to ImageNet-level complexity:&lt;lb/&gt;Building a practical generative model with Zero-Shot Conditional Generation as a key feature.&lt;/p&gt;&lt;p&gt;Applying DDN to domains with relatively small generation spaces.&lt;/p&gt;&lt;p&gt;Applying DDN to non-generative tasks:&lt;/p&gt;&lt;p&gt;Using DDN's design ideas to improve existing generative models:&lt;/p&gt;&lt;p&gt;Applying DDN to language modeling tasks:&lt;/p&gt;&lt;p&gt;Q1: Will DDN require a lot of GPU memory?&lt;/p&gt;&lt;quote&gt;&lt;p&gt;DDN's GPU memory requirements are slightly higher than conventional GAN generator using the same backbone architecture, but the difference is negligible.&lt;/p&gt;&lt;p&gt;During training, generating&lt;/p&gt;&lt;mjx-container&gt;samples is only to identify the one closest to the ground truth, and the&lt;/mjx-container&gt;&lt;mjx-container&gt;unselected samples do not retain gradients, so they are immediately discarded after sampling at the current layer, freeing up memory.&lt;/mjx-container&gt;&lt;p&gt;In the generation phase, we randomly sample an index from&lt;/p&gt;&lt;mjx-container&gt;and only generate the sample at the chosen index, avoiding the need to generate the other&lt;/mjx-container&gt;&lt;mjx-container&gt;samples, thus not occupying additional memory or computation.&lt;/mjx-container&gt;&lt;/quote&gt;&lt;p&gt;Q2: Will there be a mode collapse issue?&lt;/p&gt;&lt;quote&gt;&lt;p&gt;No. DDN selects the output most similar to the current GT and then uses the&lt;/p&gt;&lt;mjx-container&gt;loss to make it even more similar to the GT. This operation naturally has a diverse tendency, which can "expand" the entire generation space.&lt;/mjx-container&gt;&lt;p&gt;Additionally, DDN supports reconstruction. Figure 14 in the original paper shows that DDN has good reconstruction performance on the test set, meaning that DDN can fully cover the target distribution.&lt;/p&gt;&lt;p&gt;The real issue with DDN is not mode collapse but attempting to cover a high-dimensional target distribution that exceeds its own complexity, leading to the generation of blurry samples.&lt;/p&gt;&lt;/quote&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45536694</guid><pubDate>Fri, 10 Oct 2025 09:01:54 +0000</pubDate></item><item><title>OpenGL: Mesh shaders in the current year</title><link>https://www.supergoodcode.com/mesh-shaders-in-the-current-year/</link><description>&lt;doc fingerprint="bec39254fca1fee5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Mesh Shaders In The Current Year&lt;/head&gt;
    &lt;head rend="h1"&gt;It Happened.&lt;/head&gt;
    &lt;p&gt;Just a quick post to confirm that the OpenGL/ES Working Group has signed off on the release of GL_EXT_mesh_shader.&lt;/p&gt;
    &lt;head rend="h1"&gt;Credits&lt;/head&gt;
    &lt;p&gt;This is a monumental release, the largest extension shipped for GL this decade, and the culmination of many, many months of work by AMD. In particular we all need to thank Qiang Yu (AMD), who spearheaded this initiative and did the vast majority of the work both in writing the specification and doing the core mesa implementation. Shihao Wang (AMD) took on the difficult task of writing actual CTS cases (not mandatory for EXT extensions in GL, so this is a huge benefit to the ecosystem).&lt;/p&gt;
    &lt;p&gt;Big thanks to both of you, and everyone else behind the scenes at AMD, for making this happen.&lt;/p&gt;
    &lt;p&gt;Also we have to thank the nvidium project and its author, Cortex, for single-handedly pushing the industry forward through the power of Minecraft modding. Stay sane out there.&lt;/p&gt;
    &lt;head rend="h1"&gt;Support&lt;/head&gt;
    &lt;p&gt;Minecraft mod support is already underway, so expect that to happen “soon”.&lt;/p&gt;
    &lt;p&gt;The bones of this extension have already been merged into mesa over the past couple months. I opened a MR to enable zink support this morning since I have already merged the implementation.&lt;/p&gt;
    &lt;p&gt;Currently, I’m planning to wait until either just before the branch point next week or until RadeonSI merges its support to merge the zink MR. This is out of respect: Qiang Yu did a huge lift for everyone here, and ideally AMD’s driver should be the first to be able to advertise that extension to reflect that. But the branchpoint is coming up in a week, and SGC will be going into hibernation at the end of the month until 2026, so this offer does have an expiration date.&lt;/p&gt;
    &lt;p&gt;In any case, we’re done here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45537890</guid><pubDate>Fri, 10 Oct 2025 11:56:05 +0000</pubDate></item><item><title>Ryanair flight landed at Manchester airport with six minutes of fuel left</title><link>https://www.theguardian.com/business/2025/oct/10/ryanair-flight-landed-at-manchester-airport-with-six-minutes-of-fuel-left-flight-log-suggests</link><description>&lt;doc fingerprint="32049a1c222d59d2"&gt;
  &lt;main&gt;
    &lt;p&gt;An investigation is under way after a Ryanair flight battling with high wind speeds during storm Amy last week landed at Manchester airport with just six minutes of fuel left in its tanks.&lt;/p&gt;
    &lt;p&gt;The pilots had been taking passengers from Pisa in Italy to Prestwick in Scotland on Friday evening, but wind speeds of up to 100mph meant they were unable to land.&lt;/p&gt;
    &lt;p&gt;After three failed attempts to touch down, the pilots of Ryanair flight FR3418 issued a mayday emergency call and raced to Manchester, where the weather was calmer.&lt;/p&gt;
    &lt;p&gt;The Boeing 737-800 had just 220kg of fuel left in its tanks when it finally landed, according to a picture of what appears to be a handwritten technical log. Pilots who examined the picture said this would be enough for just five or six minutes of flying.&lt;/p&gt;
    &lt;p&gt;Analysis of the log suggests the plane left Pisa with reserve fuel, as commercial flights are required to do.&lt;/p&gt;
    &lt;p&gt;A spokesperson for the airline said: “Ryanair reported this to the relevant authorities on Friday [3 October]. As this is now subject of an ongoing investigation, which we are co-operating fully with, we are unable to comment.”&lt;/p&gt;
    &lt;p&gt;The Air Accidents Investigation Branch confirmed on Thursday it had opened an investigation after being notified by Ryanair.&lt;/p&gt;
    &lt;p&gt;A spokesperson said: “The AAIB has commenced an investigation into a serious incident involving an aircraft which was diverted from Prestwick to Manchester Airport on Friday 3 October. AAIB inspectors have begun making inquiries and gathering evidence.”&lt;/p&gt;
    &lt;p&gt;The Boeing 737-800 can carry up to 189 passengers. One person on board recounted what is thought to have been a two-hour attempt to make a safe landing, saying the plane made two attempts to land at Prestwick, before heading for Edinburgh and finally Manchester.&lt;/p&gt;
    &lt;p&gt;“Everyone was calm until the descent; we were being buffeted around a lot and jumping. There were a few worried people on the second descent as we could feel the plane was struggling,” Alexander Marchi told the Ayr Advertiser.&lt;/p&gt;
    &lt;p&gt;“Then the pilot surprised us by saying he was going to attempt Edinburgh. This was just as bad, though, as the second time at Prestwick.&lt;/p&gt;
    &lt;p&gt;“There was turbulence over the Firth of Forth and then as we approached the airport, as we were very close to landing, again we had to pull up sharply.”&lt;/p&gt;
    &lt;p&gt;The passengers were taken from Manchester to Prestwick, arriving 10 hours later than the scheduled arrival time of 6pm on Friday.&lt;/p&gt;
    &lt;p&gt;One pilot who reviewed the log said: “Just imagine that whenever you land with less than 2T (2,000kg) of fuel left you start paying close attention to the situation. Less than 1.5T you are sweating. But this is as close to a fatal accident as possible.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45539943</guid><pubDate>Fri, 10 Oct 2025 15:11:04 +0000</pubDate></item><item><title>Does our “need for speed” make our wi-fi suck?</title><link>https://orb.net/blog/does-speed-make-wifi-suck</link><description>&lt;doc fingerprint="f578975e3811dbed"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Does our “need for speed” make our Wi-Fi suck?&lt;/head&gt;
    &lt;head rend="h3"&gt;Yep.&lt;/head&gt;
    &lt;p&gt;It is common knowledge among Wi-Fi professionals that using 20 MHz or 40 MHz channel widths when planning 5 GHz networks offers the best overall experience for enterprise networks. This is because enterprise networks can often cover large footprints and need higher density for many connected devices. Using narrower channel widths provides many more available channels for building out networks with appropriate channel reuse and allows flexibility to avoid co-channel interference from noisy neighbors.&lt;/p&gt;
    &lt;p&gt;Residential and small business Wi-Fi challenges are not so different. The average US household has 21 Wi-Fi devices1. Many homes require multiple mesh nodes or access points to cover effectively. Users in dense urban areas face many nearby access points using wide channels. Although Wi-Fi networks built by seasoned professionals typically use narrower channels, consumer Wi-Fi devices from popular manufacturers and ISPs utilize 80 MHz or wider channel widths by default. Popular routers and mesh systems from large manufacturers can even default to 40 MHz channels for 2.4 GHz networks (some not even allowing you to change to 20 MHz), utilizing two-thirds of the available spectrum!&lt;/p&gt;
    &lt;p&gt;Why? Because consumers have been conditioned to understand only raw speed as a metric of Wi-Fi quality and not more important indicators of internet experience such as responsiveness and reliability. If manufacturers shipped Wi-Fi routers and mesh systems that utilized more reasonable 40 MHz-wide 5 GHz channels out of the box, consumers would return the products when their favorite speed testing tool showed no improvement in speed over their previous system. Similarly, ISPs are reluctant to configure consumer premise equipment (CPE) to use narrower channels by default to reduce adjacent-channel and co-channel interference, as this will decrease the maximum achieved speed and hurt their standings in network performance benchmarks that emphasize raw speed over a rock solid and consistent Wi-Fi experience.&lt;/p&gt;
    &lt;head rend="h1"&gt;But wait. It gets worse.&lt;/head&gt;
    &lt;p&gt;Not only does consumer and telecoms marketing’s heavy focus on speed hamstring ISPs and device manufacturers when it comes to delivering excellent in-home Wi-Fi, but the very act of performing speed tests negatively impacts experience.&lt;/p&gt;
    &lt;p&gt;For example, here is a 1-minute summary of an iPhone’s responsiveness connected to a Wi-Fi 6 router connected directly to a symmetrical 1 Gbps fiber connection.&lt;/p&gt;
    &lt;p&gt;Now, an important concept in Wi-Fi is that of airtime contention: basically, only a single device can “talk” at a time on a given channel2. So if one device is generating a considerable amount of unnecessary traffic, say from taking an internet speed test, substantial airtime contention occurs. Let’s connect a laptop to the same Wi-Fi router, take an internet speed test, and observe the impact on responsiveness from the same iPhone:&lt;/p&gt;
    &lt;p&gt;We can see material increases in latency, jitter, and packet loss, resulting in a doubling of the effective Lag. Of course, this does not prove that airtime contention is the cause, as there may be other factors such as buffer bloat. So let’s have the laptop perform the speed test via a wired connection instead of Wi-Fi:&lt;/p&gt;
    &lt;p&gt;This resulted in no material impact compared to the idle state, demonstrating that the speed testing activity was in fact the cause of the degraded experience from airtime contention and other Wi-Fi factors. In fact, the router is running FQ_Codel to mitigate non-Wi-Fi variables. With FQ_Codel disabled, the combined airtime contention and buffer bloat results in even greater degradation of experience when running a speed test: 1.5% packet loss, 13 ms jitter, and 113 ms peak lag. Considering the majority of consumer-grade equipment does not ship with buffer bloat mitigations enabled, this more accurately represents the general consumer Wi-Fi experience when an internet speed test is active.&lt;/p&gt;
    &lt;p&gt;Many ISPs, device manufacturers, and consumers automate periodic, high-intensity speed tests that negatively impact the consumer internet experience as demonstrated. Further, static probes that connect to Wi-Fi networks to measure maximum throughput are contributing to both buffer bloat and airtime contention.&lt;/p&gt;
    &lt;head rend="h1"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;18% of US households experienced Wi-Fi issues on a daily basis, 20% on a weekly basis, and 68% reported issues in the past year3. But until consumers, the press, and industry understand that responsiveness and reliability are the largest drivers of their Wi-Fi experience, not speed, there will be little appetite from device manufacturers and ISPs to focus on solutions that result in truly great home Wi-Fi.&lt;/p&gt;
    &lt;p&gt;The IEEE 802.11bn (Wi-Fi 8) working group has acknowledged the need for a shift in focus, framing the standard’s goals differently from past generations: not chasing ever-higher peak speeds, but improving reliability, lower latency (especially at the 95th percentile), reduced packet loss, and robustness under challenging conditions (interference, mobility).&lt;/p&gt;
    &lt;p&gt;That said, the standard is not projected to be finalized until 2028. Near-term, the availability of Wi-Fi bands in the 6 GHz range will also help provide an even better balance of speed, responsiveness, and reliability with the ability to use wider bands while minimizing co-channel interference. However, this only offers another “lane” and does not eliminate the inherent problem of data-hungry devices cannibalizing precious air time. And, as analysis from Opensignal in conjunction with Hamina Founder &amp;amp; CEO Jussi Kiviniemi demonstrates, 6 GHz penetration remains low due to network and user equipment lagging behind on Wi-Fi 6E and 7 adoption.&lt;/p&gt;
    &lt;p&gt;We don’t have to wait until there is material Wi-Fi 6E and 7 penetration (or the unrealized promises of Wi-Fi 8) in the market to make progress—we can do so much better with the hardware already deployed with configuration changes if we can simply stop chasing the maximum possible throughputs and instead focus on Wi-Fi responsiveness and reliability.&lt;/p&gt;
    &lt;p&gt;So, are standard internet speed tests bad? Of course not! They are a tool, and when used for an appropriate task, such as validating provisioned speeds are achievable by a network or client, they are incredibly useful. But we tend to over-use speed testing tools for all connectivity-related troubleshooting activities due to a historical lack of available user-friendly utilities and industry focus on "megabits per second".&lt;/p&gt;
    &lt;p&gt;This isn’t a matter of education: consumers know they want responsive and reliable Wi-Fi networks for the use cases of today. Instead, we need tooling and data to show consumers the metrics they care about most in an easily digestible form and make them readily available. Modern monitoring tools that measure continuous network experience—not just point-in-time speed—give manufacturers and ISPs the opportunity to compete on metrics that actually improve Wi-Fi rather than degrade it.&lt;/p&gt;
    &lt;p&gt;Footnotes&lt;lb/&gt;1Journal of Consumer Affairs, April 2024&lt;lb/&gt;2This is an oversimplification given newer features such as OFDMA, but due to the nature of speed testing, the activity will demand large RUs or the entire channel. The scheduler also introduces overhead. And, as we will show, adoption of newer standards is low.&lt;lb/&gt;3TechSee data via Telecompetitor, September 2025&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45542444</guid><pubDate>Fri, 10 Oct 2025 18:55:30 +0000</pubDate></item><item><title>Show HN: Semantic search over the National Gallery of Art</title><link>https://nga.demo.mixedbread.com/</link><description>&lt;doc fingerprint="d347f7e0daff0674"&gt;
  &lt;main&gt;
    &lt;p&gt;National Gallery of Art Nation Gallery of Art Mixedbread Github Discover art with natural language Still life paintings Paintings of flowers Woodcuts of landscapes Portraits of women Sculptures of animals Paintings of the sea Ancient coins Search through over 50,000 images from the National Gallery of Art public collection.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45543471</guid><pubDate>Fri, 10 Oct 2025 20:33:25 +0000</pubDate></item><item><title>I built physical album cards with NFC tags to teach my son music discovery</title><link>https://fulghum.io/album-cards</link><description>&lt;doc fingerprint="ea7b844cb976b30"&gt;
  &lt;main&gt;
    &lt;p&gt;by Jordan Fulghum, October 2025&lt;/p&gt;
    &lt;p&gt;Albums you can hold again.&lt;/p&gt;
    &lt;p&gt;When I was 10, I blew every dollar I had on CDs. I remember sitting cross-legged on my floor, flipping through jewel cases, memorizing liner notes and lyrics, and most importantly developing my own taste for music.&lt;/p&gt;
    &lt;p&gt;My 10-year-old doesn't have that. Music just sort of... happens. It's like it's infinite and invisible at the same time, playing from smart speakers, car stereos, my phone. Endless perfectly curated playlists, designed to fade into the background. The default listening experience has become both literally and figuratively formless.&lt;/p&gt;
    &lt;p&gt;So I thought: what's the modern equivalent of that CD browsing experience? Maybe what's missing is something tangible that he can flip through, or even collect.&lt;/p&gt;
    &lt;p&gt;I could combine my old CD-collector brain with today's tech: take something fun and collectable (trading cards), dress them up with album art, and add NFC tags so they can be tapped to play the album on our home speaker system, all without a screen.&lt;/p&gt;
    &lt;p&gt;Away I went.&lt;/p&gt;
    &lt;p&gt;I needed to get the music into a format that could be played. I've long since surrendered to streaming, but I still have my MP3s organized via Plex on my home server. Funny to think that these files are the same MP3s that I've been collecting since the late 90s. I wanted the NFC tag to be deep-linked to those same files instead of a streaming service.&lt;/p&gt;
    &lt;p&gt;But which albums do I pick? I had the idea to create themed "packs" of albums. The first pack is obviously "Albums That Dad Wants You to Listen To", and it's just a bunch of dad rock. But the idea is that each pack can be a different theme or genre, and he can build his own collection (and develop his own taste) over time.&lt;/p&gt;
    &lt;p&gt;I found a PDF template that matched the dimensions of trading cards, hopped into Canva and got to work. It was easy enough to find high-quality album cover images from Google, but....&lt;/p&gt;
    &lt;p&gt;I was quite far into this project when I remembered the obvious fact that album art is square but trading cards are rectangular. Trading cards use a 2.5:3.5 aspect ratio, which is...not a square! Oops.&lt;/p&gt;
    &lt;p&gt;I looked at what they did for cassette tapes (also rectangular) back in the day, but their solutions were all over the place, from just cropping the square into a rectangle (gross) to having a giant white space next to the square art. That wasn't gonna cut it.&lt;/p&gt;
    &lt;p&gt;So, I used an AI diffusion model to extend each album's art into a trading card aspect ratio. The AI was (mostly) able to extend the artwork while maintaining the original style and composition. Not perfect, but a pretty fun solution not possible just a couple years ago.&lt;/p&gt;
    &lt;p&gt;After ordering a bundle of blank NFC tags from Amazon, I learned that PlexAmp oddly has first-class support for zapping NFC tags to specific albums in auto play mode. A strange feature, but perfect for this project. Easy.&lt;/p&gt;
    &lt;p&gt;The process was simple: open PlexAmp, navigate to an album, tap the three dots menu, and there's a "Program NFC Tag" option. Hold your phone over the blank NFC tag and it writes the deep link. That's it. The tag just contains a URL that opens PlexAmp and starts playing that specific album when tapped.&lt;/p&gt;
    &lt;p&gt;I printed the cards on our crappy HP inkjet printer at home. I used label paper that exactly matched the dimensions of trading cards, but after the fact, I realized it was kind of unnecessary. You can just print on cardstock if you have a digital template file. I cut them out and glued them to blank playing cards, but not before wedging the NFC tags between.&lt;/p&gt;
    &lt;p&gt;For placement, I found a trading card display model from Makerworld and 3D printed it on my A1. It turned out alright!&lt;/p&gt;
    &lt;p&gt;Once it was all working and in decent shape, I presented them in a nice neat arrangement to my son. He flipped through them like Pokémon cards, examined the cards that were the most visually interesting. Daft Punk's Discovery was his first pick. He grabbed it, flipped it around, tapped it, and that One More Time loop dropped throughout our entire house. Boom.&lt;/p&gt;
    &lt;p&gt;I was happy to see that the physical cards encouraged active listening and ownership. Instead of music being background noise, it became something he could choose, hold, explore, maybe even trade with his sister!&lt;/p&gt;
    &lt;p&gt;I think we're unintentionally teaching our children to consume music passively. My goal with this project was to teach them to discover it actively, to own it, to care about it at the album level. I think it kinda worked!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45543475</guid><pubDate>Fri, 10 Oct 2025 20:34:19 +0000</pubDate></item><item><title>Tangled, a Git collaboration platform built on atproto</title><link>https://blog.tangled.org/intro</link><description>&lt;doc fingerprint="bb129eda18bc2f5a"&gt;
  &lt;main&gt;
    &lt;p&gt;Tangled is a new social-enabled Git collaboration platform, built on top of the AT Protocol. We envision a place where developers have complete ownership of their code, open source communities can freely self-govern and most importantly, coding can be social and fun again.&lt;/p&gt;
    &lt;p&gt;There are several models for decentralized code collaboration platforms, ranging from ActivityPub’s (Forgejo) federated model, to Radicle’s entirely P2P model. Our approach attempts to be the best of both worlds by adopting atproto—a protocol for building decentralized social applications with a central identity.&lt;/p&gt;
    &lt;p&gt;Our approach to this is the idea of “knots”. Knots are lightweight, headless servers that enable users to host Git repositories with ease. Knots are designed for either single or multi-tenant use which is perfect for self-hosting on a Raspberry Pi at home, or larger “community” servers. By default, Tangled provides managed knots where you can host your repositories for free.&lt;/p&gt;
    &lt;p&gt;The App View at tangled.sh acts as a consolidated “view” into the whole network, allowing users to access, clone and contribute to repositories hosted across different knots—completely seamlessly.&lt;/p&gt;
    &lt;p&gt;Tangled is still in its infancy, and we’re building out several of its core features as we dogfood it ourselves. We developed these three tenets to guide our decisions:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Ownership of data&lt;/item&gt;
      &lt;item&gt;Low barrier to entry&lt;/item&gt;
      &lt;item&gt;No compromise on user-experience&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Collaborating on code isn’t easy, and the tools and workflows we use should feel natural and stay out of the way. Tangled’s architecture enables common workflows to work as you’d expect, all while remaining decentralized.&lt;/p&gt;
    &lt;p&gt;We believe that atproto has greatly simplfied one of the hardest parts of social media: having your friends on it. Today, we’re rolling out invite-only access to Tangled—join us on IRC at &lt;code&gt;#tangled&lt;/code&gt; on
libera.chat and we’ll get you set up.&lt;/p&gt;
    &lt;p&gt;Update: Tangled is open to public, simply login at tangled.sh/login! Have fun!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45543899</guid><pubDate>Fri, 10 Oct 2025 21:18:55 +0000</pubDate></item><item><title>(Re)Introducing the Pebble Appstore</title><link>https://ericmigi.com/blog/re-introducing-the-pebble-appstore/</link><description>&lt;doc fingerprint="dcea42331bd429f1"&gt;
  &lt;main&gt;
    &lt;p&gt;For those who didn’t catch my blog post last week (pls read), we manufactured 2,960 white Pebble 2 Duos in September! Pretty good for the first month of production. These watches are being transferred to our fulfillment center and will be shipped out soon.&lt;/p&gt;
    &lt;p&gt;Black Pebble 2 Duo production did not start until the end of September, and then got interrupted by a China/Hong Kong holiday. Extremely sorry for the delay on black!&lt;/p&gt;
    &lt;p&gt;Pebble Time 2&lt;/p&gt;
    &lt;p&gt;One fun piece of Pebble Time 2 software development news - we added a feature to make existing Pebble watchfaces/apps now (optionally) scale up to fill larger and higher resolution Pebble Time 2 display! Previous generation Pebble rectangular displays measured 144x168 pixels in 1.26" diagonal, but Pebble Time 2 is 200x228 pixels in 1.5", existing faces/apps would have had a black border on PT2. Many thanks to Alina for posting this idea on Discord.&lt;/p&gt;
    &lt;p&gt;This is fantastic because it will allow all older apps/faces to fill up the whole screen. Even better though, many Pebble developers are already upgrading their apps/faces to support the bigger screen natively, like Lignite’s beautiful face Mosaic.&lt;/p&gt;
    &lt;p&gt;Pebble Time 2 hardware development is going pretty well. We finished EVT (engineering verification test) and we’re now heading into the DVT (design verification test) stage. We’re still working on a number of tasks like tuning the stainless steel PVD hard coating, testing water resistance, integrating our firmware test suite into the factory ERP and more fun stuff.&lt;/p&gt;
    &lt;p&gt;Schedule-wise, we’re behind where I would have liked to be in October. We’re now aiming to start mass production just around the end of the year (12/26 to be precise). That means December pre-orders will not ship out until January at the earliest. We’ll try our best to catch up, but the other looming date is the start of the lunar new year (factory shuts down Feb 1 through 17). We’ve got our work cut out for us! We’ll get it done.&lt;/p&gt;
    &lt;p&gt;For those of you who forgot or weren’t around 10 years ago, one of the most awesome parts of Pebble is the huge selection of fun/quirky/beautiful/clever/useful apps and watchfaces (from here I’ll just call them both ‘apps’). These were made by an extraordinarily talented community of casual developers, who primarily built apps for themselves and shared them with the broader public. This was facilitated by a damn good SDK, APIs, devtools and documentation created by the friendly and talented software and devrel teams at Pebble.&lt;/p&gt;
    &lt;p&gt;I think the ease of development and hackability of Pebble truly made the world a better place, one little app at a time. I love hearing stories from people who first learned how to program on a free Pebble they got from a hackathon (we gave away thousands this way). Books were written. Toolswere created. My then-girlfriend now-wife (a biochemistry professor) even learned Pebble.JS to create an amino acid flash card app for her students! Yes, we are nerds.&lt;/p&gt;
    &lt;p&gt;Over 2,000 apps and 10,000 watchfaces were created and hosted on the Pebble Appstore. It’s time to get (re)acquainted with them - browse away on apps.rePebble.com!&lt;/p&gt;
    &lt;p&gt;All existing Pebble apps are compatible with the new watches, though some apps may not work anymore due to broken settings pages, obsolete APIs, etc. Hopefully as we ship out more new watches, some developers will re-emerge to rescue some of these apps. I’m sure new apps will also rise to fill any voids!&lt;/p&gt;
    &lt;p&gt;What are your favourite Pebble apps and watchfaces? Share links to your favs in the comment section below!&lt;/p&gt;
    &lt;p&gt;For the last 9 years, the Rebble Alliance has been keeping the Pebble dream alive. Many of you have used their web services, Discord, helpful instructions or dev portal. I’m a huge fan - I’ve been a daily active user since 2017. Without Rebble, it’s unlikely that the Pebble community would be as in-tact as it is today. On top of that, several members of the Rebble (and ex-Pebble colleagues) were absolutely critical in helping Google open-source PebbleOS. Without the community or the OS, there is zero chance that these new watches would be possible! Thank you Rebble!&lt;/p&gt;
    &lt;p&gt;One other great thing that Rebble did was in 2017 - they archived and started hosting a copy of the Pebble Appstore, before the servers were shut down. New apps uploaded by developers since 2017 have also been popping up!&lt;/p&gt;
    &lt;p&gt;We have partnered with Rebble to re-introduce the appstore. Their web services now power the Pebble appstore backend. New apps submitted via dev-portal.rebble.io will show up on Pebble Appstore as well.&lt;/p&gt;
    &lt;p&gt;You won’t need a subscription with Rebble in order to access the Appstore. Core Devices is funding Rebble, a non-profit, directly to provide this service. You can still donate or subscribe to Rebble and support their community efforts!&lt;/p&gt;
    &lt;p&gt;The Pebble Appstore now lives on apps.rePebble.com. The web view looks, feels and generally is the same as in 2016, with a few new tweaks and improvements:&lt;/p&gt;
    &lt;p&gt;Social link previews - share your favourite watchfaces on WhatsApp, Twitter, Bluesky, Discord, etc! Like PebbleEye 007&lt;/p&gt;
    &lt;p&gt;Similar Apps/Recommendations - while building this feature, I was reminded about the true depth of the Pebble app catalog. It’s easy to get caught up in the ‘most hearted’ section…use this new feature at the bottom of each app page to discover hidden gems! It’s not perfect, but it’s helped me discover some awesome apps.&lt;/p&gt;
    &lt;p&gt;Additionally, we’re thinking about adding new features like:&lt;/p&gt;
    &lt;p&gt;Click to try out the app in an emulator&lt;/p&gt;
    &lt;p&gt;Detecting and warning users about broken APIs and settings pages&lt;/p&gt;
    &lt;p&gt;More and better categories&lt;/p&gt;
    &lt;p&gt;Better discovery and recommendations&lt;/p&gt;
    &lt;p&gt;Highlighting less-hearted apps (give new apps a chance vs old ones with a lot of hearts)&lt;/p&gt;
    &lt;p&gt;What new features should we add next? Add a comment below!&lt;/p&gt;
    &lt;p&gt;One of our goals with this next phase of Pebble is to nurture and facilitate an awesome, easy and dare-we-say fun developer experience for the Pebble developer community. Part of what made the experience so awesome before was the developer relations team! We unfortunately do not have the resources to recruit the whole team back (though I wish we could!). Luckily many of the great decisions they made continue to pay off.&lt;/p&gt;
    &lt;p&gt;The great news is that over the summer, we had an insanely productive intern on our team. He dusted off the SDK, updated it from Python2 → 3 and even built a CloudPebble-like way to build Pebble apps entirely in the browser.&lt;/p&gt;
    &lt;p&gt;What’s working now&lt;/p&gt;
    &lt;p&gt;Try the Pebble SDK! Tested on Mac, Windows (WSL) and Linux&lt;/p&gt;
    &lt;p&gt;Or use the Cloud IDE → build hello-world and see it on an emulator, all in your browser, in under 2 minutes!&lt;/p&gt;
    &lt;p&gt;Build an app with AI → run pebble new-project --ai then open dir in Claude Code or Cursor (etc) and prompt your way to your own custom app or watchface&lt;/p&gt;
    &lt;p&gt;Upgrade your apps to support the larger 200x228 px display on Pebble Time 2, run it on the emulator using pebble install --emulator emery (just like Obsidian!)&lt;/p&gt;
    &lt;p&gt;What’s on the SDK roadmap:&lt;/p&gt;
    &lt;p&gt;Pebble packages support in SDK&lt;/p&gt;
    &lt;p&gt;Adding Timeline support into the Pebble mobile app&lt;/p&gt;
    &lt;p&gt;New APIs for barometer, touchscreen, speaker&lt;/p&gt;
    &lt;p&gt;JS SDK - brand new, powered by Moddable. This will replace Rocky.js&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45544228</guid><pubDate>Fri, 10 Oct 2025 21:53:48 +0000</pubDate></item><item><title>Verge Genomics (YC S15) Is Hiring for Multiple Engineering and Product Roles</title><link>https://news.ycombinator.com/item?id=45544636</link><description>&lt;doc fingerprint="244fc49b6d1a231c"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Verge is using AI to develop better drugs faster. We are one of the few AI drug discovery companies to advance from data to clinic – delivering two new AI-derived drugs in the last three years, discovered using our industry-leading proprietary datasets and tooling. Along the way, we've signed commercial partnerships with Eli Lilly and AstraZeneca totaling $1.6B in contract value and $67M in near-term cash.&lt;/p&gt;
      &lt;p&gt;We're hiring for the following roles on our platform team:&lt;/p&gt;
      &lt;p&gt;* Head of Product &amp;amp; Engineering&lt;/p&gt;
      &lt;p&gt;* Principal Full-Stack Engineer (Django)&lt;/p&gt;
      &lt;p&gt;* Senior Computational Biologist (AI/ML)&lt;/p&gt;
      &lt;p&gt;* Senior Data Engineer&lt;/p&gt;
      &lt;p&gt;Please apply through our careers page, and mention Hacker News in your application:&lt;/p&gt;
      &lt;p&gt;https://www.vergegenomics.com/openings&lt;/p&gt;
      &lt;p&gt;Our platform team is developing Verge's CONVERGE drug discovery engine into a transformative tool for partners and customers across pharma and AI. We are a small, nimble group of scientists and software engineers.&lt;/p&gt;
      &lt;p&gt;Successful applicants will have a significant role in steering, scoping, and prioritizing the work we do.&lt;/p&gt;
      &lt;p&gt;All of our roles are remote within the US, and require a willingness to travel to San Francisco a few times per year. We do not currently offer visa sponsorship.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45544636</guid><pubDate>Fri, 10 Oct 2025 22:37:16 +0000</pubDate></item><item><title>In a post-truth world truth-seeking is more important</title><link>https://iai.tv/articles/in-a-post-truth-world-truth-seeking-is-more-important-than-ever-auid-3382</link><description>&lt;doc fingerprint="e5905bdf5557871b"&gt;
  &lt;main&gt;
    &lt;p&gt;The age of 'post-truth' has jumped off the philosophical page and come to life. With almost every news story today, there are competing perspectives, with competing truths. Many have simply given up in their quest for knowledge. In such a world, philosopher Jason Baehr argues, knowledge is a survival skill. One that societies must cultivate to sustain trust and democracy in the digital age. While technology has expanded access to information, it has also eroded our ability to think well. The antidote, he suggests, lies not in more data or smarter algorithms, but in cultivating the intellectual virtues that make genuine understanding possible: persistence, rigor, and humility.&lt;/p&gt;
    &lt;p&gt;As humans, we care about forming true beliefs and avoiding false beliefs. We want to know, understand, get things right. We want to avoid cognitive error and ignorance. These are our twin epistemic aims.&lt;/p&gt;
    &lt;p&gt;Our success in achieving these aims depends on many factors. Some are systemic and technological. But others are personal. When gathering information, what questions do we ask? How hard do we work to get to the truth? Do we consider alternative perspectives and explanations? Scrutinize the quality of our sources? Attend to the limits of our evidence? These are things we do as individual thinkers. They express our agency, values, attitudes, and commitments. Whether we do them, and do them well, can significantly contribute to the success or failure of our inquiries.&lt;/p&gt;
    &lt;p&gt;___&lt;/p&gt;
    &lt;p&gt;What our sophisticated information technologies give with one hand they take away with the other.&lt;/p&gt;
    &lt;p&gt;___&lt;/p&gt;
    &lt;p&gt;One might expect that revolutionary information technologies like the internet or AI would make our lives as epistemic agents much easier. Alas, things are not that simple. While we have unprecedented access to information about innumerable topics, the sheer quantity of information can be overwhelming, which can short-circuit our motivation to inquire. Moreover, the quality of this information is uneven and can be very difficult to evaluate. Making matters worse, the architecture of our information landscape is designed to show us what we want to see and tell us what we already believe. We find ourselves, often without knowing it, in echo chambers and epistemic bubbles. What our sophisticated information technologies give with one hand they take away with the other.&lt;/p&gt;
    &lt;p&gt;This leaves many of us wrestling with questions like: What sources of information can I trust? Am I capable of distinguishing between credible information and misinformation? Are objectivity and impartiality hopeless ideals? What is the best—or least problematic—way to navigate the minefield that is our epistemic landscape?&lt;/p&gt;
    &lt;p&gt;SUGGESTED VIEWING After Post-Truth With Rana Mitter, Hilary Lawson, Rebecca Goldstein, Homi Bhabha&lt;/p&gt;
    &lt;p&gt;One optimistic thought is that we can outsource the relevant epistemic labor by simply “trusting the experts.” While occasionally helpful, this suggestion is not as straightforward as it seems. For one thing, it demands distinguishing between actual and purported experts, which can be just as difficult as gauging the credibility of a particular information source or claim. For another, it is not uncommon even for genuine experts to disagree. Accordingly, to achieve our twin epistemic aims, some demanding intellectual work is required. In what follows, I’ll briefly describe two familiar and tempting ways of dealing with this predicament, each of which leaves something to be desired.&lt;/p&gt;
    &lt;p&gt;___&lt;/p&gt;
    &lt;p&gt;But responsible action is informed action.&lt;/p&gt;
    &lt;p&gt;___&lt;/p&gt;
    &lt;p&gt;The first is to surrender and withdraw. Overwhelmed by the sheer quantity of information, and uncertain about how to approach it, I might elect simply to give up, stick my head in the sand, and suspend judgment about any number of important topics in politics, science, health, technology, economics, and ethics.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45544890</guid><pubDate>Fri, 10 Oct 2025 23:14:02 +0000</pubDate></item><item><title>Programming in the Sun: A Year with the Daylight Computer</title><link>https://wickstrom.tech/2025-10-10-programming-in-the-sun-a-year-with-the-daylight-computer.html</link><description>&lt;doc fingerprint="a694403731e3b5d5"&gt;
  &lt;main&gt;
    &lt;p&gt;October 10, 2025&lt;/p&gt;
    &lt;p&gt;Iâve been hinting on X/Twitter about my use of the Daylight DC-1 as a programming environment, and after about a year of use, itâs time to write about it in longer form. This isnât a full product review, but rather an experience report on coding in sunlight. Itâs also about the Boox Tab Ultra â which has a different type of display â and how it compares to the DC-1 for my use cases.&lt;/p&gt;
    &lt;p&gt;This is not a sponsored post.&lt;/p&gt;
    &lt;p&gt;Why do I even bother, you might ask? Sunlight makes me energetic and alert, which I need when I work. Living in the Nordics, 50% of the year is primarily dark, so any direct daylight I can get becomes really important. I usually run light mode on my Framework laptop during the day, but working in actual daylight with these displays, or plain old paper, is even better.&lt;/p&gt;
    &lt;p&gt;Here are the main components of this coding environment:&lt;/p&gt;
    &lt;code&gt;apt&lt;/code&gt;
    &lt;p&gt;I use a slimmed-down version of my regular dotfiles, because this setup doesnât use Nix. Iâve manually installed Neovim, tmux, and a few other essentials, using the package manager that comes with Termux. Iâve configured Termux to not show its virtual keyboard when a physical keyboard is connected (the Bluetooth keyboard). The Termux theme is âE-Inkâ and the font is JetBrains Mono, all built into Termux. Neovim uses the built-in &lt;code&gt;quiet&lt;/code&gt; colorscheme for
maximum contrast.&lt;/p&gt;
    &lt;p&gt;Certain work requires a more capable environment, and in those cases I connect to my workstation using SSH and run tmux in there. For writing or simpler programming projects (Iâve even done Rust work with Cargo, for instance), the local Termux environment is fine.&lt;/p&gt;
    &lt;p&gt;Sometimes I want to go really minimalist, so I hide the tmux status bar and run &lt;code&gt;Goyo&lt;/code&gt; in
Neovim. Deep breaths. Feel the fresh air in your lungs. This is
especially nice for writing blog posts like this one.&lt;/p&gt;
    &lt;p&gt;My blog editing works locally in Termux, with a live reloading Chrome in a split window, here during an evening writing session with the warm backlight enabled:&lt;/p&gt;
    &lt;p&gt;Thereâs the occasional Bluetooth connection problem with the 8BitDo keyboard. I also donât love the layout, and Iâm considering getting the Kinesis Freestyle2 Blue instead. I already have the wired version for my workstation, and the ergonomics are great.&lt;/p&gt;
    &lt;p&gt;What about the Boox? Iâve had this device for longer and I really like it too, but not for the same tasks. The E-Ink display is, quite frankly, a lot nicer to read on; EPUB books, research PDFs, web articles, etc. The 227 PPI instead of the Daylightâs 190 PPI makes a difference, and I like the look of E-Ink better overall.&lt;/p&gt;
    &lt;p&gt;However, the refresh rate and ghosting make it a bit frustrating for typing. Same goes for drawing, which Iâve used the Daylight for a lot. Most of my home renovation blueprints are sketched on the Daylight. The refresh rate makes it possible.&lt;/p&gt;
    &lt;p&gt;When reading at night with a more direct bedside lamp, often in combination with a subtle backlight, the Boox is much better. The Daylight screen can glare quite a bit, so the only option is backlight only. And at that point, a lot of the paperlike quality goes away.&lt;/p&gt;
    &lt;p&gt;You can also get some glare when thereâs direct sunlight at a particular angle:&lt;/p&gt;
    &lt;p&gt;Even if I donât write or program directly on the Boox, Iâve experimented with using it as a secondary display, like for the live reload blog preview:&lt;/p&gt;
    &lt;p&gt;To sum up, these devices are good for different things, in my experience. Iâve probably spent more time on the Boox, because Iâve had it for longer and Iâve read a lot on it, but the Daylight has been much better for typing and drawing.&lt;/p&gt;
    &lt;p&gt;Another thing Iâd like to try is a larger E-Ink monitor for my workstation, like the one Zack is hacking on. Iâm hoping this technology continues to improve on refresh rate, because I love E-Ink. Until then, the Daylight is a good compromise.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45545098</guid><pubDate>Fri, 10 Oct 2025 23:51:13 +0000</pubDate></item><item><title>How hard do you have to hit a chicken to cook it? (2020)</title><link>https://james-simon.github.io/blog/chicken-cooking/</link><description>&lt;doc fingerprint="110a311b6246df50"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How hard do you have to hit a chicken to cook it?&lt;/head&gt;
    &lt;p&gt;Some questions are timeless, innocent yet penetrating in their simplicity. Why is the sky blue? Why do things fall? How hard must one hit a chicken to cook it? It is this last mystery of the universe that we discuss today.&lt;/p&gt;
    &lt;p&gt;There’s a classic solution in which someone calculated that, if you slap a chicken at 3726 mph, it will be cooked. However, this analysis just calculates how hard you’d have to hit a chicken to get it to cooking temperature; you need to keep it at that temperature for it to cook. One slap won’t work unless you get it so hot that it cooks while it’s cooling.&lt;/p&gt;
    &lt;p&gt;A real answer to this vital conundrum needs to consider how fast a chicken cools. A body at a nonzero temperature is constantly radiating energy as blackbody radiation; this is what you see in incandescent lightbulbs or when glass glows during glassblowing. To keep an object at a given temperature, you have to continuously give it the same energy it’s radiating away. A typical-sized chicken at 165 F is radiating away roughly 2000 watts of power, around 300 times the power used in a fluorescent lightbulb. To avoid losing any heat to contact with the air, let’s assume we dangle the chicken from a string in a large vacuum chamber. Let’s also assume you and a few friends are hitting the chicken with baseball bats like a pinata. In order to keep the chicken at 165 F for the minutes needed to cook it, it would be enough to have four people each hitting it once a second with a bat swung at 75 mph, about the speed with which a pro swings. Four major-league baseball players wearing pressure suits in a vacuum chamber each hitting a dangling chicken with a baseball bat once a second could cook it in a few minutes.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45545965</guid><pubDate>Sat, 11 Oct 2025 02:06:02 +0000</pubDate></item><item><title>AMD and Sony's PS6 chipset aims to rethink the current graphics pipeline</title><link>https://arstechnica.com/gaming/2025/10/amd-and-sony-tease-new-chip-architecture-ahead-of-playstation-6/</link><description>&lt;doc fingerprint="3b2f1556bbd612d"&gt;
  &lt;main&gt;
    &lt;p&gt;It feels like it was just yesterday that Sony hardware architect Mark Cerny was first teasing Sony's "PS4 successor" and its "enhanced ray-tracing capabilities" powered by new AMD chips. Now that we're nearly five full years into the PS5 era, it's time for Sony and AMD to start teasing the new chips that will power what Cerny calls "a future console in a few years' time."&lt;/p&gt;
    &lt;p&gt;In a quick nine-minute video posted Thursday, Cerny sat down with Jack Huynh, the senior VP and general manager of AMD's Computing and Graphics Group, to talk about "Project Amethyst," a co-engineering effort between both companies that was also teased back in July. And while that Project Amethyst hardware currently only exists in the form of a simulation, Cerny said that the "results are quite promising" for a project that's still in the "early days."&lt;/p&gt;
    &lt;head rend="h2"&gt;Mo’ ML, fewer problems?&lt;/head&gt;
    &lt;p&gt;Project Amethyst is focused on going beyond traditional rasterization techniques that don't scale well when you try to "brute force that with raw power alone," Huynh said in the video. Instead, the new architecture is focused on more efficient running of the kinds of machine-learning-based neural networks behind AMD's FSR upscaling technology and Sony's similar PSSR system.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;From the same source. Two branches. One vision.&lt;/p&gt;
      &lt;p&gt;My good friend and fellow gamer @cerny and I recently reflected on our shared journey — symbolized by these two pieces of amethyst, split from the same stone.&lt;/p&gt;
      &lt;p&gt;Project Amethyst is a co-engineering effort between @PlayStation and… pic.twitter.com/De9HWV3Ub2&lt;/p&gt;
      &lt;p&gt;— Jack Huynh (@JackMHuynh) July 1, 2025&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;While that kind of upscaling currently helps let GPUs pump out 4K graphics in real time, Cerny said that the "nature of the GPU fights us here," requiring calculations to be broken up into subproblems to be handled in a somewhat inefficient parallel process by the GPU's individual compute units.&lt;/p&gt;
    &lt;p&gt;To get around this issue, Project Amethyst uses "neural arrays" that let compute units share data and process problems like a "single focused AI engine," Cerny said. While the entire GPU won't be connected in this manner, connecting small sets of compute units like this allows for more scalable shader engines that can "process a large chunk of the screen in one go," Cerny said. That means Project Amethyst will let "more and more of what you see on screen... be touched or enhanced by ML," Huynh added.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45546593</guid><pubDate>Sat, 11 Oct 2025 04:36:16 +0000</pubDate></item><item><title>Daniel Kahneman opted for assisted suicide in Switzerland</title><link>https://www.bluewin.ch/en/entertainment/nobel-prize-winner-opts-for-suicide-in-switzerland-2619460.html</link><description>&lt;doc fingerprint="2ed71a13137502a8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;"It's time to go" Nobel Prize winner opts for suicide in Switzerland&lt;/head&gt;
    &lt;p&gt;Sven Ziegler&lt;/p&gt;
    &lt;p&gt;24.3.2025&lt;/p&gt;
    &lt;p&gt;At the age of 90, Nobel Prize winner Daniel Kahneman chose to die a self-determined death in Switzerland. He spent his last days in Paris - conscious, fulfilled and quiet.&lt;/p&gt;
    &lt;head rend="h2"&gt;No time? blue News summarizes for you&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Israeli-American psychologist Daniel Kahneman chose assisted suicide in Switzerland on March 27, 2024.&lt;/item&gt;
      &lt;item&gt;The Nobel Prize winner wanted to forestall a phase of mental and physical decline.&lt;/item&gt;
      &lt;item&gt;His final step was well-considered - and yet difficult for many to understand.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In March 2024, Daniel Kahneman celebrated his 90th birthday - surrounded by his partner Barbara Tversky, his daughter and her family in Paris.&lt;/p&gt;
    &lt;p&gt;The Israeli-American psychologist strolled through the city, visited museums and the ballet, enjoyed soufflés and chocolate mousse. They were days full of life.&lt;/p&gt;
    &lt;p&gt;But towards the end of his stay, Kahneman began to send a personal message to close friends: a farewell email. On March 26, he left his family and flew to Zurich. One day later, he died by assisted suicide.&lt;/p&gt;
    &lt;p&gt;In the email, he wrote openly about his decision, as theWall Street Journalhas now revealed: He was convinced that the suffering and humiliations of old age were superfluous - and that it was now time to go.&lt;/p&gt;
    &lt;p&gt;He wanted to "forestall natural decline, not slip helplessly into a state" that he himself had experienced with his mother, his wife Anne Treisman and other loved ones.&lt;/p&gt;
    &lt;p&gt;His partner died in 2018 as a result of vascular dementia. The loss affected him deeply.&lt;/p&gt;
    &lt;head rend="h2"&gt;Kahneman wanted to preserve his autonomy until the end&lt;/head&gt;
    &lt;p&gt;Although Daniel Kahneman neither suffered from dementia nor required dialysis, he said he noticed an "increase in mental lapses and a decline in his kidney function".&lt;/p&gt;
    &lt;p&gt;His decision seems to have been based less on his famous scientific thinking and more on a very personal feeling. He wanted to retain his autonomy until the end and to shape his own end.&lt;/p&gt;
    &lt;p&gt;Kahneman knew that many would see his decision as premature. But that was exactly what he intended, he wrote: If you wait until a life is "obviously no longer worth living", it is already too late.&lt;/p&gt;
    &lt;p&gt;Therefore, his move was inevitably premature. He had spoken about it with some people close to him, and even though they initially resisted, they had finally accepted his decision.&lt;/p&gt;
    &lt;head rend="h2"&gt;Kahneman: "Thank you all for helping me"&lt;/head&gt;
    &lt;p&gt;Daniel Kahneman did not want to make a statement or start a debate. "I am not ashamed of my decision," he wrote, "but I don't want it to be discussed publicly either."&lt;/p&gt;
    &lt;p&gt;Even in death, the Nobel laureate remained modest - his wish was that his passing should not dominate the obituaries.&lt;/p&gt;
    &lt;p&gt;He spent his last days in Paris - remembering, enjoying, writing. And even at the end, when asked what he would like to do, he said: "I would like to learn something."&lt;/p&gt;
    &lt;p&gt;Kahneman lived to the end as a curious researcher. He closed his email with the words: "Thank you all for helping me to make this life a good one."&lt;/p&gt;
    &lt;head rend="h2"&gt;Suicidal thoughts? You can find help here:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;These services are available around the clock for people in suicidal crises and for those around them.&lt;/item&gt;
      &lt;item&gt;Dargebotene Hand counseling hotline: Telephone number 143 or www.143.ch&lt;/item&gt;
      &lt;item&gt;Pro Juventute counseling hotline (for children and young people): Telephone number 147 or www.147.ch&lt;/item&gt;
      &lt;item&gt;Further addresses and information: www.reden-kann-retten.ch&lt;/item&gt;
      &lt;item&gt;Addresses for people who have lost someone to suicide:&lt;lb/&gt;Refugium: Association for bereaved people after suicide&lt;lb/&gt;Sea of fog: Perspectives after the suicide of a parent&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45547492</guid><pubDate>Sat, 11 Oct 2025 08:09:15 +0000</pubDate></item><item><title>AV2 video codec delivers 30% lower bitrate than AV1, final spec due in late 2025</title><link>https://videocardz.com/newz/av2-video-codec-delivers-30-lower-bitrate-than-av1-final-spec-due-in-late-2025</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45547537</guid><pubDate>Sat, 11 Oct 2025 08:19:31 +0000</pubDate></item><item><title>HTML's Best Kept Secret: The Output Tag</title><link>https://denodell.com/blog/html-best-kept-secret-output-tag</link><description>&lt;doc fingerprint="365a9b111ba6d282"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;HTML’s Best Kept Secret: The &amp;lt;output&amp;gt; Tag&lt;/head&gt;
    &lt;p&gt;Den Odell 1 October 2025 · ⏱️ 5 min read&lt;/p&gt;
    &lt;p&gt;Den Odell 1 October 2025 · ⏱️ 5 min read&lt;/p&gt;
    &lt;p&gt;Every developer knows &lt;code&gt;&amp;lt;input&amp;gt;&lt;/code&gt;. It’s the workhorse of the web.&lt;/p&gt;
    &lt;p&gt;But &lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt;? Most have never touched it. Some don’t even know it exists.&lt;/p&gt;
    &lt;p&gt;That’s a shame, because it solves something we’ve been cobbling together with &lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt;s and ARIA for years: dynamic results that are announced to screen readers by default.&lt;/p&gt;
    &lt;p&gt;It’s been in the spec for years. Yet it’s hiding in plain sight.&lt;/p&gt;
    &lt;p&gt;Here’s what the HTML5 spec says:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt;element represents the result of a calculation performed by the application, or the result of a user action.&lt;/quote&gt;
    &lt;p&gt;It’s mapped to &lt;code&gt;role="status"&lt;/code&gt; in the accessibility tree. In plain terms, it announces its value when it changes, as if it already had &lt;code&gt;aria-live="polite" aria-atomic="true"&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;In practice, that means updates do not interrupt the user. They are read shortly after, and the entire content is spoken rather than just the part that changed. You can override this behavior by setting your own ARIA properties if needed.&lt;/p&gt;
    &lt;p&gt;Usage is straightforward:&lt;/p&gt;
    &lt;code&gt;&amp;lt;output&amp;gt;Your dynamic value goes here&amp;lt;/output&amp;gt;&lt;/code&gt;
    &lt;p&gt;That’s it. Built-in assistive technology support. No attributes to memorize. Just HTML doing what it was always meant to do.&lt;/p&gt;
    &lt;p&gt;I discovered &lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt; on an accessibility project with a multi-step form. The form updated a risk score as fields changed. It looked perfect in the browser, but screen reader users had no idea the score was updating.&lt;/p&gt;
    &lt;p&gt;Adding an ARIA live region fixed it. But I’ve always believed in reaching for semantic HTML first, and live regions often feel like a patch.&lt;/p&gt;
    &lt;p&gt;That’s when I scoured the spec and &lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt; jumped out. It understands forms without requiring one, and it announces its changes natively. Turns out the simplest fix had been in the spec all along.&lt;/p&gt;
    &lt;p&gt;Because we forgot. It’s not covered in most tutorials. It doesn’t look flashy. When I searched GitHub public repos, it barely showed up at all.&lt;/p&gt;
    &lt;p&gt;It gets overlooked in patterns and component libraries too. That absence creates a feedback loop: if no one teaches it, no one uses it.&lt;/p&gt;
    &lt;p&gt;Like &lt;code&gt;&amp;lt;label&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt; has a &lt;code&gt;for=""&lt;/code&gt; attribute. Here you list the &lt;code&gt;id&lt;/code&gt;s of any &lt;code&gt;&amp;lt;input&amp;gt;&lt;/code&gt; elements the result depends on, separated by spaces:&lt;/p&gt;
    &lt;code&gt;&amp;lt;input id="a" type="number"&amp;gt; +
&amp;lt;input id="b" type="number"&amp;gt; =
&amp;lt;output for="a b"&amp;gt;&amp;lt;/output&amp;gt;&lt;/code&gt;
    &lt;p&gt;For most users, nothing changes visually. But in the accessibility tree it creates a semantic link, letting assistive technology users connect the inputs with their calculated result.&lt;/p&gt;
    &lt;p&gt;Update 7 Oct 2025: Some screen readers have been found not to announce updates to the tag, so explicitly emphasising the &lt;code&gt;role&lt;/code&gt; attribute might be worthwhile for now until support improves: &lt;code&gt;&amp;lt;output role="status"&amp;gt;&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;It doesn’t require a &lt;code&gt;&amp;lt;form&amp;gt;&lt;/code&gt; either. You can use it anywhere you are updating dynamic text on the page based on the user’s input.&lt;/p&gt;
    &lt;p&gt;By default &lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt; is inline, so you’ll usually want to style it for your layout, just as you would a &lt;code&gt;&amp;lt;span&amp;gt;&lt;/code&gt; or &lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;And because it has been part of the spec since 2008, support is excellent across browsers and screen readers. It also plays nicely with any JavaScript framework you might be using, like React or Vue.&lt;/p&gt;
    &lt;p&gt;One thing to note: &lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt; is for results tied to user inputs and actions, not global notifications like toast messages. Those are better handled with &lt;code&gt;role="status"&lt;/code&gt; or &lt;code&gt;role="alert"&lt;/code&gt; on a generic element, since they represent system feedback rather than calculated output.&lt;/p&gt;
    &lt;p&gt;So what does this look like in practice?&lt;/p&gt;
    &lt;p&gt;I’ve personally reached for &lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt; in multiple real-world projects since discovering it:&lt;/p&gt;
    &lt;p&gt;During a recent 20-minute coding challenge, I used &lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt; to display calculation results. Without adding a single ARIA role, the screen reader announced each result as it updated. No hacks required.&lt;/p&gt;
    &lt;p&gt;At Volvo Cars, we displayed user-friendly versions of slider values. Internally the slider might hold &lt;code&gt;10000&lt;/code&gt;, but the output showed &lt;code&gt;10,000 miles/year&lt;/code&gt;. We wrapped the slider and &lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt; in a container with &lt;code&gt;role="group"&lt;/code&gt; and a shared label, creating a cohesive React component:&lt;/p&gt;
    &lt;code&gt;&amp;lt;div role="group" aria-labelledby="mileage-label"&amp;gt;
  &amp;lt;label id="mileage-label" htmlFor="mileage"&amp;gt;
    Annual mileage
  &amp;lt;/label&amp;gt;
  &amp;lt;input
    id="mileage"
    name="mileage"
    type="range"
    value={mileage}
    onChange={(e) =&amp;gt; setMileage(Number(e.target.value))}
  /&amp;gt;
  &amp;lt;output name="formattedMileage" htmlFor="mileage"&amp;gt;
    {mileage.toLocaleString()} miles/year
  &amp;lt;/output&amp;gt;
&amp;lt;/div&amp;gt;&lt;/code&gt;
    &lt;p&gt;I found that password strength indicators and real-time validation messages work beautifully with &lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;&amp;lt;label for="password"&amp;gt;Password&amp;lt;/label&amp;gt;
&amp;lt;input type="password" id="password" name="password"&amp;gt;
&amp;lt;output for="password"&amp;gt;
  Password strength: Strong
&amp;lt;/output&amp;gt;&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt; tag even fits modern patterns where you might fetch prices from APIs, show tax calculations, or display server-generated recommendations.&lt;/p&gt;
    &lt;p&gt;Here, a shipping cost calculator updates an &lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt; tag, informing users once the cost has been calculated:&lt;/p&gt;
    &lt;code&gt;export function ShippingCalculator() {
  const [weight, setWeight] = useState("");
  const [price, setPrice] = useState("");

  useEffect(() =&amp;gt; {
    if (weight) {
      // Fetch shipping price from server based on package weight
      fetch(`/api/shipping?weight=${weight}`)
        .then((res) =&amp;gt; res.json())
        .then((data) =&amp;gt; setPrice(data.price));
    }
  }, [weight]);

  return (
    &amp;lt;form&amp;gt;
      &amp;lt;label&amp;gt;
        Package weight (kg):
        &amp;lt;input
          type="number"
          name="weight"
          value={weight}
          onChange={(e) =&amp;gt; setWeight(e.target.value)}
        /&amp;gt;
      &amp;lt;/label&amp;gt;
      
      &amp;lt;output name="price" htmlFor="weight"&amp;gt;
        {price ? `Estimated shipping: $${price}` : "Calculating..."}
      &amp;lt;/output&amp;gt;
    &amp;lt;/form&amp;gt;
  );
}&lt;/code&gt;
    &lt;p&gt;There’s something satisfying about using a native HTML element for what it was designed for, especially when it makes your UI more accessible with less code.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt; might be HTML’s best kept secret, and discovering gems like this shows how much value is still hiding in the spec.&lt;/p&gt;
    &lt;p&gt;Sometimes the best tool for the job is the one you didn’t even know you had.&lt;/p&gt;
    &lt;p&gt;💬 Comments? Join the discussion on Dev.to →&lt;/p&gt;
    &lt;p&gt;🔗 Share: Twitter/X · LinkedIn ·&lt;/p&gt;
    &lt;p&gt;What happens when accessibility stops being a best practice and starts being the law? We’re about to find out.&lt;/p&gt;
    &lt;p&gt;We keep changing how we style the web, but the real problem isn’t CSS. It’s how we build around it.&lt;/p&gt;
    &lt;p&gt;No spam. Just occasional deep dives on frontend engineering and developer experience.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45547566</guid><pubDate>Sat, 11 Oct 2025 08:27:26 +0000</pubDate></item><item><title>Vietnam Airlines Data Breach</title><link>https://haveibeenpwned.com/Breach/VietnamAirlines</link><description>&lt;doc fingerprint="9f77c81e4ff274c5"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Vietnam Airlines Data Breach&lt;/head&gt;&lt;head rend="h2"&gt;What Happened&lt;/head&gt;&lt;p&gt;In October 2025, data stolen from the Salesforce instances of multiple companies by a hacking group calling itself "Scattered LAPSUS$ Hunters" was publicly released. Among the affected organisations was Vietnam Airlines, which had 7.5M unique customer email addresses exposed following a breach of its Salesforce environment in June of that year. The compromised data also included names, phone numbers, dates of birth, and loyalty program membership numbers.&lt;/p&gt;&lt;head rend="h2"&gt;Compromised Data&lt;/head&gt;&lt;head rend="h2"&gt;Recommended Actions&lt;/head&gt;&lt;p&gt;Use a password manager to generate and store strong, unique passwords for all your accounts. 1Password helps protect your data with industry-leading security.&lt;/p&gt;Try 1Password&lt;p&gt;Get Aura for identity theft and credit protection. Keep your assets safe with fast fraud alerts, instant credit lock, and $1,000,000 identity theft insurance. Speak to a U.S. based fraud specialist 24/7.&lt;/p&gt;Try Aura&lt;p&gt;After a breach every click matters. Guardio’s AI-powered protection is the only solution that shields you from phishing, scams, and fake logins before they cause damage.&lt;/p&gt;Try Guardio&lt;head rend="h3"&gt;Breach Overview&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;Affected Accounts:&lt;/p&gt;&lt;p&gt;7.3 million&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Breach Occurred:&lt;/p&gt;&lt;p&gt;June 2025&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Added to HIBP:&lt;/p&gt;&lt;p&gt;11 Oct 2025&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Recommended Actions&lt;/head&gt;&lt;head rend="h5"&gt;Change Your Password&lt;/head&gt;&lt;p&gt;If you haven't changed your Vietnam Airlines password since 2025, do so immediately.&lt;/p&gt;&lt;head rend="h5"&gt;Enable Two-Factor Authentication&lt;/head&gt;&lt;p&gt;Add an extra layer of security to your account.&lt;/p&gt;&lt;p&gt;Use a password manager to generate and store strong, unique passwords for all your accounts. 1Password helps protect your data with industry-leading security.&lt;/p&gt;Try 1Password&lt;p&gt;Get Aura for identity theft and credit protection. Keep your assets safe with fast fraud alerts, instant credit lock, and $1,000,000 identity theft insurance. Speak to a U.S. based fraud specialist 24/7.&lt;/p&gt;Try Aura&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45547807</guid><pubDate>Sat, 11 Oct 2025 09:40:10 +0000</pubDate></item></channel></rss>