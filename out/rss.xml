<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 13 Sep 2025 18:39:08 +0000</lastBuildDate><item><title>QGIS is a free, open-source, cross platform geographical information system</title><link>https://github.com/qgis/QGIS</link><description>&lt;doc fingerprint="1e593c5071772595"&gt;
  &lt;main&gt;
    &lt;p&gt;QGIS is a full-featured, user-friendly, free-and-open-source (FOSS) geographical information system (GIS) that runs on Unix platforms, Windows, and MacOS.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Support for raster, vector, mesh, and point cloud data in a range of industry-standard formats &lt;list rend="ul"&gt;&lt;item&gt;Raster formats include: GeoPackage, GeoTIFF, GRASS, ArcInfo binary and ASCII grids, ERDAS Imagine SDTS, WMS, WCS, PostgreSQL/PostGIS, and other GDAL supported formats.&lt;/item&gt;&lt;item&gt;Vector formats include: GeoPackage, ESRI shapefiles, GRASS, SpatiaLite, PostgreSQL/PostGIS, MSSQL, Oracle, WFS, Vector Tiles and other OGR supported formats.&lt;/item&gt;&lt;item&gt;Mesh formats include: NetCDF, GRIB, 2DM, and other MDAL supported formats.&lt;/item&gt;&lt;item&gt;Point-cloud format: LAS/LAZ and EPT datasets.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Data abstraction framework, with local files, spatial databases (PostGIS, SpatiaLite, SQL Server, Oracle, SAP HANA), and web services (WMS, WCS, WFS, ArcGIS REST) all accessed through a unified data model and browser interface, and as flexible layers in user-created projects&lt;/item&gt;
      &lt;item&gt;Spatial data creation via visual and numerical digitizing and editing, as well as georeferencing of raster and vector data&lt;/item&gt;
      &lt;item&gt;On-the-fly reprojection between coordinate reference systems (CRS)&lt;/item&gt;
      &lt;item&gt;Nominatim (OpenStreetMap) geocoder access&lt;/item&gt;
      &lt;item&gt;Temporal support&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example: Temporal animation&lt;/p&gt;
    &lt;p&gt;Example: 3D map view&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Large variety of rendering options in 2D and 3D&lt;/item&gt;
      &lt;item&gt;Fine control over symbology, labeling, legends and additional graphical elements for beautifully rendered maps&lt;/item&gt;
      &lt;item&gt;Respect for embedded styling in many spatial data sources (e.g. KML and TAB files, Mapbox-GL styled vector tiles)&lt;/item&gt;
      &lt;item&gt;In particular, near-complete replication (and significant extension) of symbology options that are available in proprietary software by ESRI&lt;/item&gt;
      &lt;item&gt;Advanced styling using data-defined overrides, blending modes, and draw effects&lt;/item&gt;
      &lt;item&gt;500+ built-in color ramps (cpt-city, ColorBrewer, etc.)&lt;/item&gt;
      &lt;item&gt;Create and update maps with specified scale, extent, style, and decorations via saved layouts&lt;/item&gt;
      &lt;item&gt;Generate multiple maps (and reports) automatically using QGIS Atlas and QGIS Reports&lt;/item&gt;
      &lt;item&gt;Display and export elevation profile plots with flexible symbology&lt;/item&gt;
      &lt;item&gt;Flexible output direct to printer, or as image (raster), PDF, or SVG for further customization&lt;/item&gt;
      &lt;item&gt;On-the-fly rendering enhancements using geometry generators (e.g. create and style new geometries from existing features)&lt;/item&gt;
      &lt;item&gt;Preview modes for inclusive map making (e.g. monochrome, color blindness)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For more maps created with QGIS, visit the QGIS Map Showcase Flickr Group.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Powerful processing framework with 200+ native processing algorithms&lt;/item&gt;
      &lt;item&gt;Access to 1000+ processing algorithms via providers such as GDAL, SAGA, GRASS, OrfeoToolbox, as well as custom models and processing scripts&lt;/item&gt;
      &lt;item&gt;Geospatial database engine (filters, joins, relations, forms, etc.), as close to datasource- and format-independent as possible&lt;/item&gt;
      &lt;item&gt;Immediate visualization of geospatial query and geoprocessing results&lt;/item&gt;
      &lt;item&gt;Model designer and batch processing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example: Travel isochrones&lt;/p&gt;
    &lt;p&gt;Example: Model designer&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fully customizable user experience, including user interface and application settings that cater to power-users and beginners alike&lt;/item&gt;
      &lt;item&gt;Rich expression engine for maximum flexibility in visualization and processing&lt;/item&gt;
      &lt;item&gt;Broad and varied plugin ecosystem that includes data connectors, digitizing aids, advanced analysis and charting tools, in-the-field data capture, conversion of ESRI style files, etc.&lt;/item&gt;
      &lt;item&gt;Style manager for creating, storing, and managing styles&lt;/item&gt;
      &lt;item&gt;QGIS style hub for easy sharing of styles&lt;/item&gt;
      &lt;item&gt;Python and C++ API for standalone (headless) applications as well as in-application comprehensive scripting (PyQGIS)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example: Style manager&lt;/p&gt;
    &lt;p&gt;Example: Plugins&lt;/p&gt;
    &lt;p&gt;Headless map server -- running on Linux, macOS, Windows, or in a docker container -- that shares the same code base as QGIS.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Industry-standard protocols (WMS, WFS, WFS3/OGC API for Features and WCS) allow plug-n-play with any software stack&lt;/item&gt;
      &lt;item&gt;Works with any web server (Apache, nginx, etc) or standalone&lt;/item&gt;
      &lt;item&gt;All beautiful QGIS cartography is supported with best-in-class support for printing&lt;/item&gt;
      &lt;item&gt;Fully customizable with Python scripting support&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example: QGIS server WMS response&lt;/p&gt;
    &lt;p&gt;Example: QGIS server WFS response&lt;/p&gt;
    &lt;p&gt;QGIS is developed using the Qt toolkit and C++, since 2002, and has a pleasing, easy to use graphical user interface with multilingual support. It is maintained by an active developer team and supported by vibrant community of GIS professionals and enthusiasts as well as geospatial data publishers and end-users.&lt;/p&gt;
    &lt;p&gt;QGIS development and releases follow a time based schedule/roadmap. There are three main branches of QGIS that users can install. These are the Long Term Release (LTR) branch, the Latest Release (LR) branch, and the Development (Nightly) branch.&lt;/p&gt;
    &lt;p&gt;Every month, there is a Point Release that provides bug-fixes to the LTR and LR.&lt;/p&gt;
    &lt;p&gt;QGIS is released under the GNU Public License (GPL) Version 2 or any later version. Developing QGIS under this license means that you can (if you want to) inspect and modify the source code and guarantees that you, our happy user will always have access to a GIS program that is free of cost and can be freely modified.&lt;/p&gt;
    &lt;p&gt;QGIS is part of the Open-Source Geospatial Foundation (OSGeo), offering a range of complementary open-source GIS software projects.&lt;/p&gt;
    &lt;p&gt;Precompiled binaries for QGIS are available at the QGIS.org download page. Please follow the installation instructions carefully.&lt;/p&gt;
    &lt;p&gt;The building guide can be used to get started with building QGIS from source.&lt;/p&gt;
    &lt;p&gt;For installation of QGIS Server, see its getting started documentation.&lt;/p&gt;
    &lt;p&gt;A range of documentation is available. This includes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Training Manual&lt;/item&gt;
      &lt;item&gt;QGIS User Guide&lt;/item&gt;
      &lt;item&gt;QGIS Server Guide&lt;/item&gt;
      &lt;item&gt;Visual Changelog&lt;/item&gt;
      &lt;item&gt;Documentation Guidelines&lt;/item&gt;
      &lt;item&gt;QGIS Python (PyQGIS) Cookbook&lt;/item&gt;
      &lt;item&gt;QGIS Python (PyQGIS) API&lt;/item&gt;
      &lt;item&gt;QGIS C++ API&lt;/item&gt;
      &lt;item&gt;Developers Guide&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are several channels where you can find help and support for QGIS:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Using the QGIS community site&lt;/item&gt;
      &lt;item&gt;Joining the qgis-users mailing list&lt;/item&gt;
      &lt;item&gt;Chatting with other users real-time. Please wait around for a response to your question as many folks on the channel are doing other things and it may take a while for them to notice your question. The following paths all take you to the same chat room: &lt;list rend="ul"&gt;&lt;item&gt;Using an IRC client and joining the #qgis channel on irc.libera.chat.&lt;/item&gt;&lt;item&gt;Using a Matrix client and joining the #qgis:osgeo.org room.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;At the GIS stackexchange or r/QGIS reddit, which are not maintained by the QGIS team, but where the QGIS and broader GIS community provides lots of advice&lt;/item&gt;
      &lt;item&gt;Other support channels&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45224156</guid></item><item><title>UTF-8 is a brilliant design</title><link>https://iamvishnu.com/posts/utf8-is-brilliant-design</link><description>&lt;doc fingerprint="a4bdbd10f83149ab"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;UTF-8 is a Brilliant Design&lt;/head&gt;
    &lt;p&gt;The first time I learned about UTF-8 encoding, I was fascinated by how well-thought and brilliantly it was designed to represent millions of characters from different languages and scripts, and still be backward compatible with ASCII.&lt;/p&gt;
    &lt;p&gt;Basically UTF-8 uses 32 bits and the old ASCII uses 7 bits, but UTF-8 is designed in such a way that:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Every ASCII encoded file is a valid UTF-8 file.&lt;/item&gt;
      &lt;item&gt;Every UTF-8 encoded file that has only ASCII characters is a valid ASCII file.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Designing a system that scales to millions of characters and still be compatible with the old systems that use just 128 characters is a brilliant design.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Note: If you are already aware of the UTF-8 encoding, you can explore the UTF-8 Playground utility that I built to visualize UTF-8 encoding.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;How Does UTF-8 Do It?&lt;/head&gt;
    &lt;p&gt;UTF-8 is a variable-width character encoding designed to represent every character in the Unicode character set, encompassing characters from most of the world's writing systems.&lt;/p&gt;
    &lt;p&gt;It encodes characters using one to four bytes.&lt;/p&gt;
    &lt;p&gt;The first 128 characters (&lt;code&gt;U+0000&lt;/code&gt; to &lt;code&gt;U+007F&lt;/code&gt;) are encoded with a single byte, ensuring backward compatibility with ASCII, and this is the reason why a file with only ASCII characters is a valid UTF-8 file.&lt;/p&gt;
    &lt;p&gt;Other characters require two, three, or four bytes. The leading bits of the first byte determine the total number of bytes that represents the current character. These bits follow one of four specific patterns, which indicate how many continuation bytes follow.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;1st byte Pattern&lt;/cell&gt;
        &lt;cell role="head"&gt;# of bytes used&lt;/cell&gt;
        &lt;cell role="head"&gt;Full byte sequence pattern&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;0xxxxxxx&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;0xxxxxxx&lt;p&gt;(This is basically a regular ASCII encoded byte)&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;110xxxxx&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;110xxxxx 10xxxxxx&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;1110xxxx&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;1110xxxx 10xxxxxx 10xxxxxx&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;11110xxx&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;11110xxx 10xxxxxx 10xxxxxx 10xxxxxx&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Notice that the second, third, and fourth bytes in a multi-byte sequence always start with 10. This indicates that these bytes are continuation bytes, following the main byte.&lt;/p&gt;
    &lt;p&gt;The remaining bits in the main byte, along with the bits in the continuation bytes, are combined to form the character's code point. A code point serves as a unique identifier for a character in the Unicode character set. A code point is typically represented in hexadecimal format, prefixed with "U+". For example, the code point for the character "A" is &lt;code&gt;U+0041&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;So here is how a software determines the character from the UTF-8 encoded bytes:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Read a byte. If it starts with &lt;code&gt;0&lt;/code&gt;, it's a single-byte character (ASCII). Show the character represented by the remaining 7 bits on the screen. Continue with the next byte.&lt;/item&gt;
      &lt;item&gt;If the byte didn't start with a &lt;code&gt;0&lt;/code&gt;, then:&lt;list rend="ul"&gt;&lt;item&gt;If it starts with &lt;code&gt;110&lt;/code&gt;, it's a two-byte character, so read the next byte as well.&lt;/item&gt;&lt;item&gt;If it starts with &lt;code&gt;1110&lt;/code&gt;, it's a three-byte character, so read the next two bytes.&lt;/item&gt;&lt;item&gt;If it starts with &lt;code&gt;11110&lt;/code&gt;, it's a four-byte character, so read the next three bytes.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;If it starts with &lt;/item&gt;
      &lt;item&gt;Once the number of bytes are determined, read all the remaining bits except the leading bits, and find the binary value (aka. code point) of the character.&lt;/item&gt;
      &lt;item&gt;Look up the code point in the Unicode character set to find the corresponding character and display it on the screen.&lt;/item&gt;
      &lt;item&gt;Read the next byte and repeat the process.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Example: Hindi Letter "‡§Ö" (open in UTF-8 Playground)&lt;/head&gt;
    &lt;p&gt;The Hindi letter "‡§Ö" (officially "Devanagari Letter A") is represented in UTF-8 as:&lt;/p&gt;
    &lt;p&gt;11100000 10100100 10000101 Here:&lt;/p&gt;
    &lt;p&gt;The first byte 11100000 indicates that the character is encoded using 3 bytes.&lt;/p&gt;
    &lt;p&gt;The remaining bits of the three bytes: xxxx0000 xx100100 xx000101 are combined to form the binary sequence 00001001 00000101 (&lt;code&gt;0x0905&lt;/code&gt; in hexadecimal). This is the code point of the character, represented as &lt;code&gt;U+0905&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The code point &lt;code&gt;U+0905&lt;/code&gt; (see official chart) represents the Hindi letter "‡§Ö" in the Unicode character set.&lt;/p&gt;
    &lt;head rend="h2"&gt;Example Text Files&lt;/head&gt;
    &lt;p&gt;Now that we understood the design of UTF-8, let's look at a file that contains the following text:&lt;/p&gt;
    &lt;head rend="h3"&gt;1. Text file contains: &lt;code&gt;Heyüëã Buddy&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;The text &lt;code&gt;Heyüëã Buddy&lt;/code&gt; has both English characters and an emoji character on it. The text file with this text saved on the disk will have the following 13 bytes in it:&lt;/p&gt;
    &lt;p&gt;01001000 01100101 01111001 11110000 10011111 10010001 10001011 00100000 01000010 01110101 01100100 01100100 01111001&lt;/p&gt;
    &lt;p&gt;Let's evaluate this file byte-by-byte following the UTF-8 decoding rules:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Byte&lt;/cell&gt;
        &lt;cell role="head"&gt;Explanation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01001000&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1001000&lt;/code&gt; represent the letter 'H'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01100101&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1100101&lt;/code&gt; represent the letter 'e'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01111001&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1111001&lt;/code&gt; represent the letter 'y'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;11110000&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;11110&lt;/code&gt;, indicating it's the first byte of a four-byte character.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;10011111&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;10&lt;/code&gt;, indicating it's a continuation byte.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;10010001&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;10&lt;/code&gt;, indicating it's a continuation byte.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;10001011&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;10&lt;/code&gt;, indicating it's a continuation byte.&lt;p&gt;The bits from these four bytes (excluding the leading bits) combine to form the binary sequence 00001 11110100 01001011, which is&lt;/p&gt;&lt;code&gt;1F44B&lt;/code&gt; in hexadecimal, corresponds to the code point &lt;code&gt;U+1F44B&lt;/code&gt;. This code point represents the waving hand emoji "üëã" in the Unicode character set (open in playground).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;00100000&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;0100000&lt;/code&gt; represent a whitespace character. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01000010&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1000010&lt;/code&gt; represent the letter 'B'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01110101&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1110101&lt;/code&gt; represent the letter 'u'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01100100&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1100100&lt;/code&gt; represent the letter 'd'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01100100&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1100100&lt;/code&gt; represent the letter 'd'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;01111001&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1111001&lt;/code&gt; represent the letter 'y'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Now this is a valid UTF-8 file, but it doesn't have to be "backward compatible" with ASCII because it contains a non-ASCII character (the emoji). Next let's create a file that contains only ASCII characters.&lt;/p&gt;
    &lt;head rend="h3"&gt;2. Text file contains: &lt;code&gt;Hey Buddy&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;The text file doesn't have any non-ASCII characters. The file saved on the disk has the following 9 bytes in it:&lt;/p&gt;
    &lt;p&gt;01001000 01100101 01111001 00100000 01000010 01110101 01100100 01100100 01111001&lt;/p&gt;
    &lt;p&gt;Let's evaluate this file byte-by-byte following the UTF-8 decoding rules:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Byte&lt;/cell&gt;
        &lt;cell role="head"&gt;Explanation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01001000&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1001000&lt;/code&gt; represent the letter 'H'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01100101&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1100101&lt;/code&gt; represent the letter 'e'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01111001&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1111001&lt;/code&gt; represent the letter 'y'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;00100000&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;0100000&lt;/code&gt; represent a whitespace character. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01000010&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1000010&lt;/code&gt; represent the letter 'B'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01110101&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1110101&lt;/code&gt; represent the letter 'u'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01100100&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1100100&lt;/code&gt; represent the letter 'd'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;01100100&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1100100&lt;/code&gt; represent the letter 'd'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;01111001&lt;/cell&gt;
        &lt;cell&gt;Starts with &lt;code&gt;0&lt;/code&gt;, so it's a single-byte ASCII character. The remaining bits &lt;code&gt;1111001&lt;/code&gt; represent the letter 'y'. (open in playground)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;So this is a valid UTF-8 file, and it is also a valid ASCII file. The bytes in this file follows both the UTF-8 and ASCII encoding rules. This is how UTF-8 is designed to be backward compatible with ASCII.&lt;/p&gt;
    &lt;head rend="h2"&gt;Other Encodings&lt;/head&gt;
    &lt;p&gt;I did a quick research on any other encoding that are backward compatible with ASCII, and there are a few, but they are not as popular as UTF-8, for example GB 18030 (a Chinese government standard). Another one is the ISO/IEC 8859 encodings are single-byte encodings that extend ASCII to include additional characters, but they are limited to 256 characters.&lt;/p&gt;
    &lt;p&gt;The siblings of UTF-8, like UTF-16 and UTF-32, are not backward compatible with ASCII. For example, the letter 'A' in UTF-16 is represented as: &lt;code&gt;00 41&lt;/code&gt; (two bytes), while in UTF-32 it is represented as: &lt;code&gt;00 00 00 41&lt;/code&gt; (four bytes).&lt;/p&gt;
    &lt;head rend="h2"&gt;Bonus: UTF-8 Playground&lt;/head&gt;
    &lt;p&gt;When I was exploring the UTF-8 encoding, I couldn't find any good tool to interactively visualize how UTF-8 encoding works. So I built UTF-8 Playground to visualize and play around with UTF-8 encoding. Give it a try!.&lt;/p&gt;
    &lt;p&gt;Read an ocean of knowledge and references that extends this post on Hacker News.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Joel Spolsky's famous 2003 article (still relevant): The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!)&lt;/item&gt;
      &lt;item&gt;"UTF-8 was designed, in front of my eyes, on a placemat in a New Jersey diner one night in September or so 1992." - Rob Pike on designing UTF-8 with Ken Thompson&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45225098</guid></item><item><title>I used standard Emacs extension-points to extend org-mode</title><link>https://edoput.it/2025/04/16/emacs-paradigm-shift.html</link><description>&lt;doc fingerprint="8623c855a823bab8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Emacs: a paradigm shift&lt;/head&gt;
    &lt;p&gt;Recently I read this beginners guide to extend Emacs. The guide is perfect for starting out with elisp and it shows a lot of care in teaching how to interact with Emacs.&lt;/p&gt;
    &lt;p&gt;To me, the most important bit though is this one, from the section aptly named Emacs Wants You to Extend It.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I haven√¢t written plugins for other editors extensively, but I can tell you this: emacs doesn√¢t just make deep customization available, but it actively encourages you to make an absolute customization messes masterpieces. Core editor functions aren√¢t just documented, but often include tidbits about √¢you probably want to see this other variable√¢ or √¢here√¢s how you should use this√¢.&lt;/p&gt;
      &lt;p&gt;Not only that, but emacs happily hands you functions shaped like nuclear warheads like advice-add (that let you override any function) that can absolutely obliterate your editor if you hold it the wrong way. Of course, this also grants you unlimited power.&lt;/p&gt;
      &lt;p&gt;Remember that emacs is designed to be torn apart and rearranged.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is the core bit of the argument. Emacs, as a system, wants you to extend it and it gives you all the means to do so. This is in contrast with systems that can be extended through scripting and instead don√¢t give you all the means to do so!&lt;/p&gt;
    &lt;p&gt;I think the tutorial is a fantastic example of doing things right. There is a well-thought example, a constructive approach where the solution grows to a full package.&lt;/p&gt;
    &lt;p&gt;This is problematic. You may get the impression that extending Emacs is only possible if you do things right and that is definitely not true.&lt;/p&gt;
    &lt;p&gt;To make my point I want to walk you through an example. I will show you how I used standard Emacs extension-points to extend org-mode to sort my reading lists automatically.&lt;/p&gt;
    &lt;head rend="h2"&gt;What do I want?&lt;/head&gt;
    &lt;p&gt;The behavior I want is that when I save an org file the entries are ordered automatically. I keep a timeline of the papers I am reading and it is annoying to keep them kind of ordered.&lt;/p&gt;
    &lt;p&gt;This is the content of an example buffer.&lt;/p&gt;
    &lt;p&gt;When I add a paper to my reading list I run &lt;code&gt;org-sort-entries&lt;/code&gt; and
interactively select to order the entries by the value in the property
&lt;code&gt;year&lt;/code&gt;. Initally this was nice to have but now it√¢s just annoying that
I have to keep doing it. Let√¢s extend org-mode so that this is done automatically.&lt;/p&gt;
    &lt;head rend="h2"&gt;A simple solution&lt;/head&gt;
    &lt;p&gt;The first step is to automate the interactive part. Lucky for me this is easy as &lt;code&gt;org-sort-entries&lt;/code&gt; is both a function and a command. I can call it in a
script just as I can run it as a command.&lt;/p&gt;
    &lt;p&gt;This solves one part of the problem. Let√¢s solve the other one, automatically calling &lt;code&gt;org-sort-run&lt;/code&gt; whenever an org-mode buffer is saved.&lt;/p&gt;
    &lt;p&gt;Emacs already has support for this use-case through the use of hooks. We can run &lt;code&gt;org-sort-run&lt;/code&gt; all the times we want to save a buffer.&lt;/p&gt;
    &lt;p&gt;These two together solve the problem but the solution presented is √¢just more code√¢. We tapped into the hook extension point but this would be possible in any scriptable system that exposes well-defined extension points such as hooks and commands.&lt;/p&gt;
    &lt;head rend="h2"&gt;Leveraging Emacs√¢ extensibility to extend org-mode&lt;/head&gt;
    &lt;p&gt;I want to show that even if something is not thought with extensibility in mind Emacs allow us to extend it. Most importantly, while we want to extend org-mode√¢s behavior we would like this not to be an extension to org-mode√¢s code.&lt;/p&gt;
    &lt;p&gt;Here√¢s the updated problem statement. Have the buffer be automatically sorted and have the sorting criteria be in the buffer itself. We will specify the sorting as a in-buffer setting and use Emacs to support this never thought before org-mode behavior.&lt;/p&gt;
    &lt;p&gt;Our example buffer changes to the following.&lt;/p&gt;
    &lt;p&gt;The hard part of this is to find how org-mode reads in-buffer settings from the header. A M-x find-library later we are in org√¢s sources.&lt;/p&gt;
    &lt;p&gt;Searching for &lt;code&gt;+STARTUP&lt;/code&gt; (Ctrl+s +STARTUP), one of the
supported settings, leads us to &lt;code&gt;org-startup-folded&lt;/code&gt; and that in turn
(Ctrl+s org-startup-folded) leads us to &lt;code&gt;org-startup-options&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;org-startup-options&lt;/code&gt; is the used by (again Ctrl+s org-startup-option)
&lt;code&gt;org-set-regexps-and-options&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;While the documentation for this function is not very convincing, its code does make sense for what we are after. I copied it here for reference.&lt;/p&gt;
    &lt;p&gt;Unfortunately this function calls &lt;code&gt;org-collect-keyword&lt;/code&gt; with a list that we cannot
touch. There is no custom variable to set to pass our own keyword.&lt;/p&gt;
    &lt;p&gt;If this was a √¢normal programming environment√¢ we would make our changes to this function body and forever maintain a fork of org-mode. As this is elisp instead we have choices.&lt;/p&gt;
    &lt;p&gt;I think the best choice is to use &lt;code&gt;advice-add&lt;/code&gt; and have Emacs call our
advice code every time &lt;code&gt;org-set-regexps-and-options&lt;/code&gt; is called. We will copy
what we need from the function body but that will be all.&lt;/p&gt;
    &lt;p&gt;This is what I ended up with.&lt;/p&gt;
    &lt;p&gt;We keep a buffer-local variable &lt;code&gt;org-sort-option&lt;/code&gt; around to store the
property name read from &lt;code&gt;#+SORT: property-name&lt;/code&gt;. This variable is initially
&lt;code&gt;nil&lt;/code&gt; and will be set from the property name in &lt;code&gt;#+SORT: property-name&lt;/code&gt;. To do so
we have a function &lt;code&gt;org-sort-set-option&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;But when to call &lt;code&gt;org-sort-set-option&lt;/code&gt;? The easy way out is to have Emacs call it whenever
&lt;code&gt;org-set-regexps-and-options&lt;/code&gt; is called on a file visit. To achieve this we
tap into &lt;code&gt;advice-add&lt;/code&gt; and ask Emacs to run &lt;code&gt;org-sort-set-option&lt;/code&gt; after
&lt;code&gt;org-sort-regexps-and-options&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;We have now succesfully interposed ourselves in the control flow of the org-mode library.&lt;/p&gt;
    &lt;p&gt;Org-mode did not provide any interposition point for us, there is no thought ahead etension-point or configuration variable we can use to achieve our goal an yet here we are with a sorted buffer.&lt;/p&gt;
    &lt;p&gt;We succeeded in our effort because Emacs wants you to extend it and it gives you all the means to do so.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusions&lt;/head&gt;
    &lt;p&gt;I have made a horrible hack and it works. I have learnt nothing about how org-mode works or Emacs√¢ file-visiting extension-points.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45226639</guid></item><item><title>FFglitch, FFmpeg fork for glitch art</title><link>https://ffglitch.org/gallery/</link><description>&lt;doc fingerprint="e7873f10cbba35f1"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Gallery&lt;/head&gt;
    &lt;p&gt;There are some artists out there doing some amazing work using FFglitch.&lt;/p&gt;
    &lt;p&gt;I put this page up so that I don√¢t have to go hunting for examples every time I want to show someone what can be done with FFglitch.&lt;/p&gt;
    &lt;p&gt;Thomas Collet has a lot of work using FFglitch on vimeo, instagram, and reddit.&lt;/p&gt;
    &lt;p&gt;A bunch more from Thomas:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;https://vimeo.com/366067869&lt;/item&gt;
      &lt;item&gt;https://vimeo.com/363105562&lt;/item&gt;
      &lt;item&gt;https://vimeo.com/323235580&lt;/item&gt;
      &lt;item&gt;https://www.reddit.com/r/glitch_art/comments/b9yfxc/study_on_crowd_movements/&lt;/item&gt;
      &lt;item&gt;https://www.reddit.com/r/brokengifs/comments/grpwn4/tripping_in_manhattan/&lt;/item&gt;
      &lt;item&gt;https://www.reddit.com/r/woahdude/comments/bg176f/i_went_to_ireland_filmed_the_ocean_and_glitched_it/&lt;/item&gt;
      &lt;item&gt;https://www.reddit.com/r/woahdude/comments/ballm7/when_the_world_is_slowly_but_surely_falling_appart/&lt;/item&gt;
      &lt;item&gt;https://www.reddit.com/r/glitch_art/comments/fhpwgp/falling_appart/&lt;/item&gt;
      &lt;item&gt;https://www.reddit.com/r/glitch_art/comments/hxk6r1/when_it_kicks_in_the_middle_of_time_square/&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Kaspar Ravel wrote a blog post about a collaboration he did with Thomas Collet which resulted in this gem:&lt;/p&gt;
    &lt;p&gt;Here√¢s the blog post: https://www.kaspar.wtf/blog/encoding-the-game-of-life-in-datamosh&lt;/p&gt;
    &lt;p&gt;And the post on reddit: https://www.reddit.com/r/brokengifs/comments/e25f6b/want_to_see_a_magic_trick/&lt;/p&gt;
    &lt;p&gt;https://www.instagram.com/p/CPNaIp8qo-r&lt;/p&gt;
    &lt;p&gt;Go check out Myra√¢s beautiful work and exhibition Glitched Flowers (I wish I had been there to see it personally√¢¬¶)&lt;/p&gt;
    &lt;p&gt;https://www.instagram.com/p/CYFo19HolJD&lt;/p&gt;
    &lt;p&gt;Go read about Jason√¢s experimentations at https://www.jasonhallen.com/output, there√¢s a lot more with FFglitch!&lt;/p&gt;
    &lt;p&gt;glit_chbee (turn the volume up and enjoy the ride):&lt;/p&gt;
    &lt;p&gt;Ben Cooper made this clip by using mainly avidemux, tomato.py, and FFglitch.&lt;/p&gt;
    &lt;p&gt;Jo Grys has posted some videos on Facebook:&lt;/p&gt;
    &lt;p&gt;There are more if you search for #ffglitch on Facebook:&lt;/p&gt;
    &lt;p&gt;And some more random clips I found spread around the interwebz:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45227212</guid></item><item><title>Raspberry Pi Synthesizers ‚Äì How the Pi is transforming synths</title><link>https://www.gearnews.com/raspberry-pi-synthesizers-how-the-pi-is-transforming-synths/</link><description>&lt;doc fingerprint="153211515493a5b5"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Raspberry Pi Synthesizers ‚Äì How the Pi is transforming synths&lt;/head&gt;&lt;head rend="h2"&gt;The readymade pocket computer is replacing custom DSP.&lt;/head&gt;&lt;p&gt;The Raspberry Pi microcomputer is finding its way into more and more synthesizers. Do your synths have a slice of it inside? Read on to find out.&lt;/p&gt;&lt;head rend="h2"&gt;Raspberry Pi&lt;/head&gt;&lt;p&gt;Digital synthesizers are essentially computers in specialized housings. Rather than a keyboard with letters and numbers, their keyboards trigger notes. Custom-designed DSP (digital signal processing) systems can be expensive so some manufacturers are turning to ready-made computing systems to run their synths. One that‚Äôs been gaining in popularity in recent years is Raspberry Pi. The low-cost mini computer is now in instruments by Korg, Erica Synths and many more.&lt;/p&gt;&lt;p&gt;Is this cheating? Do any of your synths have Pi inside? Let‚Äôs find out.&lt;/p&gt;&lt;head rend="h2"&gt;DSP In Synthesizers&lt;/head&gt;&lt;p&gt;Digital synthesizers have existed in some form since the 1970s, with the New England Digital Synclavier being the first commercial release in 1977. As synthesizers became more powerful, adding sampling and physical modelling to the already existing FM synthesis, the DSP required to run them became more complex. Additions like sequencers and effects only compounded the expense.&lt;/p&gt;&lt;p&gt;To run their DSP, manufacturers created custom DSP systems running on off-the-shelf chips from companies like Motorola and Texas Instruments. One example was Korg‚Äôs Pentium-based OASYS workstation from 2005. While incredibly powerful, it was also incredibly expensive.&lt;/p&gt;&lt;p&gt;How to keep the power while also lowering the cost?&lt;/p&gt;&lt;head rend="h2"&gt;Raspberry Pi: What Is It?&lt;/head&gt;&lt;p&gt;The solution for Korg ‚Äì as well as other manufacturers, as we‚Äôll see ‚Äì was the Raspberry Pi. Essentially a complete computer processor in a small and ‚Äì critically ‚Äì inexpensive package, this programmable hardware get used for all sorts of applications. From robotics to home computing to (you guessed it) digital synthesizers, ready-made Raspberry Pis offer an elegant and affordable solution for custom computing systems.&lt;/p&gt;&lt;head rend="h2"&gt;Korg Serves Up Some Pi&lt;/head&gt;&lt;p&gt;The biggest synthesizer manufacturer to make use of the Raspberry Pi is Korg. The Japanese synth company‚Äôs Wavestate, Modwave and Opsix digital synths all make use of the Raspberry Pi Compute Module. (They‚Äôre in the module versions too.)&lt;/p&gt;&lt;p&gt;In an article on the Raspberry Pi home page, Korg‚Äôs Andy Leary sites price and manufacturing scale as the main reason Korg decided on these components. He also liked that it was ready to go as is, providing CPU, RAM and storage in a single package. ‚ÄúThat part of the work is already done,‚Äù he said in the article. ‚ÄúIt‚Äôs like any other component; we don‚Äôt have to lay out the board, build it and test it.‚Äù&lt;/p&gt;&lt;p&gt;The software for each instrument is, of course, custom. The Raspberry Pi, however, generates the sound. ‚ÄúNot everyone understands that Raspberry Pi is actually making the sound,‚Äù said Korg‚Äôs Dan Philips in the same piece. ‚ÄúWe use the CM3 because it‚Äôs very powerful, which makes it possible to create deep, compelling instruments.‚Äù&lt;/p&gt;&lt;head rend="h2"&gt;Erica Synths Also Likes Pi&lt;/head&gt;&lt;p&gt;You might not expect to find a Raspberry Pi inside an analogue synthesizer but if that synth happens to have digital functionality‚Ä¶ Take the Bullfrog, for example. Erica Synths and Richie Hawtin‚Äôs educational desktop analogue has a RP2040 to handle MIDI implementation as well as functionality for the Sampler/Looper voice card. This adds additional functionality to the largely analogue synthesizer.&lt;/p&gt;&lt;head rend="h2"&gt;Zynthian: Pi For Everyone&lt;/head&gt;&lt;p&gt;One of the benefits of using Raspberry Pi is the ability to make it open source. The DIY kit Zynthian is an open synth platform with a Raspberry Pi 4 at its centre. The desktop box can function as a keyboard expander, effects unit, MIDI processor, groovebox or even micro-DAW. ‚ÄúZynthian is a community-driven project and it‚Äôs 100% open source,‚Äù the company says on its site. ‚ÄúFree software on Open hardware. Completely configurable and fully hackable!‚Äù&lt;/p&gt;&lt;head rend="h2"&gt;Damn Fine Pi&lt;/head&gt;&lt;p&gt;There are plenty more synths making use of the Raspberry Pi. One that you may not realize is Organelle M by Critter and Guitari. By putting a Pi inside, they‚Äôre able to run Pure Data, meaning that you can program your own synths to use inside too.&lt;/p&gt;&lt;p&gt;Another fun instrument with a Raspberry Pi 3 for a soul is Tasty Chips‚Äô GR-1 Granular synthesizer.&lt;/p&gt;&lt;p&gt;For something a little more esoteric, try the Yoshimi Pi. ‚ÄúYoshimi Pi is the hardware incarnation of the software synth Yoshimi, running on a Raspberry Pi 4 in a rugged metal case with a built-in PSU and line level audio output,‚Äù according to the product page.&lt;/p&gt;&lt;p&gt;Of course, you don‚Äôt have to buy a commercial Raspberry Pi-based synthesizer. There are plenty of DIY options to run them ‚Äúbare metal,‚Äù that is, without a separate operating system. Just hook up a MIDI controller to the board and you‚Äôre off and running. Try MiniSynth Pi or code your own!&lt;/p&gt;&lt;head rend="h2"&gt;Raspberry Pi: Is It Cheating?&lt;/head&gt;&lt;p&gt;In the same way that some claim that virtual analogue is just a ‚ÄúVST in a box,‚Äù others complain that synths with Raspberry Pi at the core are somehow cheating. You may as well just make your own, right?&lt;/p&gt;&lt;p&gt;‚ÄúJust because something is based on a Raspberry Pi it doesn‚Äôt mean it‚Äôs trivial to make one,‚Äù said chalk_walk in a Reddit thread on the Organelle. ‚ÄúIf they provide the software then you may be able to put together something equivalent, but if not: you are out of luck if you want an Organelle. Similarly, part of the complexity is in making an enclosure with appropriate controls and displays.‚Äù&lt;/p&gt;&lt;p&gt;As we‚Äôve seen, all digital synthesizers have some kind of computer inside. Whether that‚Äôs a custom DSP with off-the-shelf chips or a Raspberry Pi, you still have to code the software, design the enclosure and PCBs and everything else that goes along with it. By going with a little computer like this, you can shave some money off the asking price and save on development time too.&lt;/p&gt;&lt;head rend="h2"&gt;More Information&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Raspberry Pi‚Äôs home page&lt;/item&gt;&lt;item&gt;Korg‚Äôs home page&lt;/item&gt;&lt;item&gt;Erica Synths‚Äô home page&lt;/item&gt;&lt;item&gt;Zynthian‚Äôs home page&lt;/item&gt;&lt;item&gt;All about synthesizers&lt;/item&gt;&lt;/list&gt;&lt;p&gt;14 responses to ‚ÄúRaspberry Pi Synthesizers ‚Äì How the Pi is transforming synths‚Äù&lt;/p&gt;&lt;p&gt;I could be wrong, but I don‚Äôt think any of these synths use the type of RasbPi shown in this article.&lt;/p&gt;&lt;p&gt;Rather, they‚Äôre using one of the microcontroller versions, which fundamentally isn‚Äôt much different than digital synths running on ESP32 or Teensy, it just has more power.&lt;/p&gt;&lt;p&gt;As such, they‚Äôre still way closer to bare metal than a device running linux on what is essentially a full computer.&lt;/p&gt;&lt;p&gt;You are mostly wrong. The Korg synths that lead off the article use the Compute Module 3, which is equivalent to the Pi 3 pictured at the top of the article‚Äîjust on a smaller PCB without all the ports soldered on.&lt;lb/&gt; That allows the Korg synths to run Linux (I assume) and basically the same code as the desktop VST versions of the synths.&lt;/p&gt;&lt;p&gt;While most of the synths in this article don‚Äôt use the exact form factor pictured, I think the Tasty Chips GR-1 does. If you look at the ports on the back, it has a cluster of Ethernet and 4x USB in the same arrangement as an off-the-shelf Pi 3/3+, so I think they built around that instead of the OEM-focused Compute Module form factor.&lt;/p&gt;&lt;p&gt;The article does mention that the Bullfrog uses a Pi RP2040, which is similar to an ESP32 or Teensy, so that one sticks out compared with the others. You‚Äôre right that the RP2040 doesn‚Äôt have the same power as the Pis that the others use ‚Äì it doesn‚Äôt run a desktop OS.&lt;/p&gt;&lt;p&gt;The other synths in this article are essentially full computers!&lt;/p&gt;&lt;p&gt;I‚Äôd be shocked if they were running even the lightest Linux distro; if they‚Äôre on CM3 I‚Äôd wager there‚Äôs a very lightweight custom OS there.&lt;/p&gt;&lt;p&gt;Some could potentially use a really lightweight Linux. But as far as I know, most of them use some kind of firmware that is loaded from SD and ultimately represents the synthesizer software. The Pi Foundation provides software libraries with which you can easily access and use the hardware. These libraries can be used to program synthesizers that avoid the burden and loading times of an OS like Linux. Ultimately, the Raspberry Pi is operated like a (very large) microcontroller.&lt;/p&gt;&lt;p&gt;Great article. I‚Äôve had a Zynthian for a couple of years, and it does a lot more, for instance Pure Data, Set B Free, Aeolus, and more. The guts are a full RPi, a sound card hat, and custom built MIDI and audio IOs. Haven‚Äôt got version 5 yet, but it‚Äôs even more advanced‚Ä¶&lt;/p&gt;&lt;p&gt;This is an interesting article and a good intro to the Pi being used in synths!&lt;/p&gt;&lt;p&gt;I knew the Korg trio ran on the CM3 and obviously the Monome Norns is built around a Pi, but I was unaware of the GR-1 or Organelle M using these single-board computers at their core.&lt;/p&gt;&lt;p&gt;I do think the Erica Synths Bullfrog doesn‚Äôt really fit in this article‚Äîthe Pi RP2040 has almost nothing in common with a full Pi like the others use. It‚Äôs made by the Pi foundation, yes, but it‚Äôs more a microcontroller like an Arduino than it is a computer. And obviously, the Bullfrog uses it very differently than the others, which synthesize their sounds on a full Pi.&lt;/p&gt;&lt;p&gt;I‚Äôm surprised that you didn‚Äôt mention the MiniDexed, a Pi based emulation of the Yamaha TX816.&lt;/p&gt;&lt;p&gt;And contrary to what Nathan said, some of them (like Zynthian) *do* use the mainline Pi hardware.&lt;/p&gt;&lt;p&gt;A little off.&lt;/p&gt;&lt;p&gt;My Zynthian runs on a Raspberry Pi 400, has an HDMI USB 7‚Ä≥ LCD panel and a Behringer 404HD sound card. Yes, it‚Äôs not an official project kit, but the Zynthian project has a hardware part (for which you need a raspberry pi 3 or 4, and there will definitely be a version for rpi 5) and then the software, which can be used for the mentioned raspberry and your configuration of the display, sound card, encoders and buttons.&lt;/p&gt;&lt;p&gt;Not informed on this topic, but a few years ago I suggested a computer based keyboard/controller into which you could load multiple VSTs. That would be possible with Pi boards. Someone would have to code an O/S launcher/menu, from which you could choose Sylenth etc to load into a VST host from a menu, with the keyboard‚Äôs knobs and buttons assigned to those on the softsynth. Making a hardware synth out of a soft synth, with maybe hundreds of synths to choose from. All the Arturia stuff etc, Mellotron, EPs, Organs etc, that‚Äôd sell very well, wouldn‚Äôt it?&lt;/p&gt;&lt;p&gt;Something along the lines of this?&lt;lb/&gt; mpmidi.com&lt;/p&gt;&lt;p&gt;Tablets and phones could perfectly do that. They are powerful enough to emulate and wrap vsts and some soundcards are even compatible.&lt;/p&gt;&lt;p&gt;But we‚Äôll probably will never have this since that would be emulating something that wasn‚Äôt sold on an app store.&lt;/p&gt;&lt;p&gt;I‚Äôve done a few embedded audio projects with a raspberry pi and pure data; and it‚Äôs a great platform for this kind of stuff (I mostly stayed with the default distro but it still works great).&lt;/p&gt;&lt;p&gt;monome norns shield is a nifty little music computer that‚Äôs based on the rPi&lt;/p&gt;&lt;p&gt;Yoshimi Pi uses a standard Raspberry Pi 4B, with just a small bespoke PCB purely for controlled switch on and switch off.&lt;/p&gt;&lt;p&gt;You are currently viewing a placeholder content from Facebook. To access the actual content, click the button below. Please note that doing so will share data with third-party providers.&lt;/p&gt;More Information&lt;p&gt;You are currently viewing a placeholder content from Instagram. To access the actual content, click the button below. Please note that doing so will share data with third-party providers.&lt;/p&gt;More Information&lt;p&gt;You are currently viewing a placeholder content from X. To access the actual content, click the button below. Please note that doing so will share data with third-party providers.&lt;/p&gt;More Information&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45229227</guid></item><item><title>SkiftOS: A hobby OS built from scratch using C/C++ for ARM, x86, and RISC-V</title><link>https://skiftos.org</link><description>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45229414</guid></item><item><title>Social media promised connection, but it has delivered exhaustion</title><link>https://www.noemamag.com/the-last-days-of-social-media/</link><description>&lt;doc fingerprint="b5ba932828e08719"&gt;
  &lt;main&gt;
    &lt;p&gt;James O‚ÄôSullivan lectures in the School of English and Digital Humanities at University College Cork, where his work explores the intersection of technology and culture.&lt;/p&gt;
    &lt;p&gt;At first glance, the feed looks familiar, a seamless carousel of ‚ÄúFor You‚Äù updates gliding beneath your thumb. But d√©j√†‚Äëvu sets in as 10 posts from 10 different accounts carry the same stock portrait and the same breathless promise ‚Äî ‚Äúclick here for free pics‚Äù or ‚Äúhere is the one productivity hack you need in 2025.‚Äù Swipe again and three near‚Äëidentical replies appear, each from a pout‚Äëfiltered avatar directing you to ‚Äúfree pics.‚Äù Between them sits an ad for a cash‚Äëback crypto card.&lt;/p&gt;
    &lt;p&gt;Scroll further and recycled TikTok clips with ‚Äúoriginal audio‚Äù bleed into Reels on Facebook and Instagram; AI‚Äëstitched football highlights showcase players‚Äô limbs bending like marionettes. Refresh once more, and the woman who enjoys your snaps of sushi rolls has seemingly spawned five clones.&lt;/p&gt;
    &lt;p&gt;Whatever remains of genuine, human content is increasingly sidelined by algorithmic prioritization, receiving fewer interactions than the engineered content and AI slop optimized solely for clicks.&lt;/p&gt;
    &lt;p&gt;These are the last days of social media as we know it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Drowning The Real&lt;/head&gt;
    &lt;p&gt;Social media was built on the romance of authenticity. Early platforms sold themselves as conduits for genuine connection: stuff you wanted to see, like your friend‚Äôs wedding and your cousin‚Äôs dog.&lt;/p&gt;
    &lt;p&gt;Even influencer culture, for all its artifice, promised that behind the ring‚Äëlight stood an actual person. But the attention economy, and more recently, the generative AI-fueled late attention economy, have broken whatever social contract underpinned that illusion. The feed no longer feels crowded with people but crowded with content. At this point, it has far less to do with people than with consumers and consumption.&lt;/p&gt;
    &lt;p&gt;In recent years, Facebook and other platforms that facilitate billions of daily interactions have slowly morphed into the internet‚Äôs largest repositories of AI‚Äëgenerated spam. Research has found what users plainly see: tens of thousands of machine‚Äëwritten posts now flood public groups ‚Äî pushing scams, chasing clicks ‚Äî with clickbait headlines, half‚Äëcoherent listicles and hazy lifestyle images stitched together in AI tools like Midjourney.&lt;/p&gt;
    &lt;p&gt;It‚Äôs all just vapid, empty shit produced for engagement‚Äôs sake. Facebook is ‚Äúsloshing‚Äù in low-effort AI-generated posts, as Arwa Mahdawi notes in The Guardian; some even bolstered by algorithmic boosts, like ‚ÄúShrimp Jesus.‚Äù&lt;/p&gt;
    &lt;p&gt;The difference between human and synthetic content is becoming increasingly indistinguishable, and platforms seem unable, or uninterested, in trying to police it. Earlier this year, CEO Steve Huffman pledged to ‚Äúkeep Reddit human,‚Äù a tacit admission that floodwaters were already lapping at the last high ground. TikTok, meanwhile, swarms with AI narrators presenting concocted news reports and ‚Äúwhat‚Äëif‚Äù histories. A few creators do append labels disclaiming that their videos depict ‚Äúno real events,‚Äù but many creators don‚Äôt bother, and many consumers don‚Äôt seem to care.&lt;/p&gt;
    &lt;p&gt;The problem is not just the rise of fake material, but the collapse of context and the acceptance that truth no longer matters as long as our cravings for colors and noise are satisfied. Contemporary social media content is more often rootless, detached from cultural memory, interpersonal exchange or shared conversation. It arrives fully formed, optimized for attention rather than meaning, producing a kind of semantic sludge, posts that look like language yet say almost nothing.&lt;/p&gt;
    &lt;p&gt;We‚Äôre drowning in this nothingness.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Bot-Girl Economy&lt;/head&gt;
    &lt;p&gt;If spam (AI or otherwise) is the white noise of the modern timeline, its dominant melody is a different form of automation: the hyper‚Äëoptimized, sex‚Äëadjacent human avatar. She appears everywhere, replying to trending tweets with selfies, promising ‚Äúfunny memes in bio‚Äù and linking, inevitably, to OnlyFans or one of its proxies. Sometimes she is real. Sometimes she is not. Sometimes she is a he, sitting in a compound in Myanmar. Increasingly, it makes no difference.&lt;/p&gt;
    &lt;p&gt;This convergence of bots, scammers, brand-funnels and soft‚Äëcore marketing underpins what might be called the bot-girl economy, a parasocial marketplace fueled in a large part by economic precarity. At its core is a transactional logic: Attention is scarce, intimacy is monetizable and platforms generally won‚Äôt intervene so long as engagement stays high. As more women now turn to online sex work, lots of men are eager to pay them for their services. And as these workers try to cope with the precarity imposed by platform metrics and competition, some can spiral, forever downward, into a transactional attention-to-intimacy logic that eventually turns them into more bot than human. To hold attention, some creators increasingly opt to behave like algorithms themselves, automating replies, optimizing content for engagement, or mimicking affection at scale. The distinction between performance and intention must surely erode as real people perform as synthetic avatars and synthetic avatars mimic real women.&lt;/p&gt;
    &lt;p&gt;There is loneliness, desperation and predation everywhere.&lt;/p&gt;
    &lt;p&gt;The bot-girl is more than just a symptom; she is a proof of concept for how social media bends even aesthetics to the logic of engagement. Once, profile pictures (both real and synthetic) aspired to hyper-glamor, unreachable beauty filtered through fantasy. But that fantasy began to underperform as average men sensed the ruse, recognizing that supermodels typically don‚Äôt send them DMs. And so, the system adapted, surfacing profiles that felt more plausible, more emotionally available. Today‚Äôs avatars project a curated accessibility: They‚Äôre attractive but not flawless, styled to suggest they might genuinely be interested in you. It‚Äôs a calibrated effect, just human enough to convey plausibility, just artificial enough to scale. She has to look more human to stay afloat, but act more bot to keep up. Nearly everything is socially engineered for maximum interaction: the like, the comment, the click, the private message.&lt;/p&gt;
    &lt;p&gt;Once seen as the fringe economy of cam sites, OnlyFans has become the dominant digital marketplace for sex workers. In 2023, the then-seven-year-old platform generated $6.63 billion in gross payments from fans, with $658 million in profit before tax. Its success has bled across the social web; platforms like X (formerly Twitter) now serve as de facto marketing layers for OnlyFans creators, with thousands of accounts running fan-funnel operations, baiting users into paid subscriptions.&lt;/p&gt;
    &lt;p&gt;The tools of seduction are also changing. One 2024 study estimated that thousands of X accounts use AI to generate fake profile photos. Many content creators have also begun using AI for talking-head videos, synthetic voices or endlessly varied selfies. Content is likely A/B tested for click-through rates. Bios are written with conversion in mind. DMs are automated or outsourced to AI impersonators. For users, the effect is a strange hybrid of influencer, chatbot and parasitic marketing loop. One minute you‚Äôre arguing politics, the next, you‚Äôre being pitched a girlfriend experience by a bot.&lt;/p&gt;
    &lt;head rend="h2"&gt;Engagement In Freefall&lt;/head&gt;
    &lt;p&gt;While content proliferates, engagement is evaporating. Average interaction rates across major platforms are declining fast: Facebook and X posts now scrape an average 0.15% engagement, while Instagram has dropped 24% year-on-year. Even TikTok has begun to plateau. People aren‚Äôt connecting or conversing on social media like they used to; they‚Äôre just wading through slop, that is, low-effort, low-quality content produced at scale, often with AI, for engagement.&lt;/p&gt;
    &lt;p&gt;And much of it is slop: Less than half of American adults now rate the information they see on social media as ‚Äúmostly reliable‚Äù‚Äî down from roughly two-thirds in the mid-2010s. Young adults register the steepest collapse, which is unsurprising; as digital natives, they better understand that the content they scroll upon wasn‚Äôt necessarily produced by humans. And yet, they continue to scroll.&lt;/p&gt;
    &lt;p&gt;The timeline is no longer a source of information or social presence, but more of a mood-regulation device, endlessly replenishing itself with just enough novelty to suppress the anxiety of stopping. Scrolling has become a form of ambient dissociation, half-conscious, half-compulsive, closer to scratching an itch than seeking anything in particular. People know the feed is fake, they just don‚Äôt care.&lt;/p&gt;
    &lt;p&gt;Platforms have little incentive to stem the tide. Synthetic accounts are cheap, tireless and lucrative because they never demand wages or unionize. Systems designed to surface peer-to-peer engagement are now systematically filtering out such activity, because what counts as engagement has changed. Engagement is now about raw user attention ‚Äì time spent, impressions, scroll velocity ‚Äì and the net effect is an online world in which you are constantly being addressed but never truly spoken to.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Great Unbundling&lt;/head&gt;
    &lt;p&gt;Social media‚Äôs death rattle will not be a bang but a shrug.&lt;/p&gt;
    &lt;p&gt;These networks once promised a single interface for the whole of online life: Facebook as social hub, Twitter as news‚Äëwire, YouTube as broadcaster, Instagram as photo album, TikTok as distraction engine. Growth appeared inexorable. But now, the model is splintering, and users are drifting toward smaller, slower, more private spaces, like group chats, Discord servers and federated microblogs ‚Äî a billion little gardens.&lt;/p&gt;
    &lt;p&gt;Since Elon Musk‚Äôs takeover, X has shed at least 15% of its global user base. Meta‚Äôs Threads, launched with great fanfare in 2023, saw its number of daily active users collapse within a month, falling from around 50 million active Android users at launch in July to only 10 million active users the following August. Twitch recorded its lowest monthly watch-time in over four years in December 2024, just 1.58 billion hours, 11% lower than the December average from 2020-23.&lt;/p&gt;
    &lt;p&gt;Even the giants that still command vast audiences are no longer growing exponentially. Many platforms have already died (Vine, Google+, Yik Yak), are functionally dead or zombified (Tumblr, Ello), or have been revived and died again (MySpace, Bebo). Some notable exceptions aside, like Reddit and BlueSky (though it‚Äôs still early days for the latter), growth has plateaued across the board. While social media adoption continues to rise overall, it‚Äôs no longer explosive. As of early 2025, around 5.3 billion user identities ‚Äî roughly 65% of the global population ‚Äî are on social platforms, but annual growth has decelerated to just 4-5%, a steep drop from the double-digit surges seen earlier in the 2010s.&lt;/p&gt;
    &lt;p&gt;Intentional, opt-in micro‚Äëcommunities are rising in their place ‚Äî like Patreon collectives and Substack newsletters ‚Äî where creators chase depth over scale, retention over virality. A writer with 10,000 devoted subscribers can potentially earn more and burn out less than one with a million passive followers on Instagram.&lt;/p&gt;
    &lt;p&gt;But the old practices are still evident: Substack is full of personal brands announcing their journeys, Discord servers host influencers disguised as community leaders and Patreon bios promise exclusive access that is often just recycled content. Still, something has shifted. These are not mass arenas; they are clubs ‚Äî opt-in spaces with boundaries, where people remember who you are. And they are often paywalled, or at least heavily moderated, which at the very least keeps the bots out. What‚Äôs being sold is less a product than a sense of proximity, and while the economics may be similar, the affective atmosphere is different, smaller, slower, more reciprocal. In these spaces, creators don‚Äôt chase virality; they cultivate trust.&lt;/p&gt;
    &lt;p&gt;Even the big platforms sense the turning tide. Instagram has begun emphasizing DMs, X is pushing subscriber‚Äëonly circles and TikTok is experimenting with private communities. Behind these developments is an implicit acknowledgement that the infinite scroll, stuffed with bots and synthetic sludge, is approaching the limit of what humans will tolerate. A lot of people seem to be fine with slop, but as more start to crave authenticity, the platforms will be forced to take note.&lt;/p&gt;
    &lt;head rend="h2"&gt;From Attention To Exhaustion&lt;/head&gt;
    &lt;p&gt;The social internet was built on attention, not only the promise to capture yours but the chance for you to capture a slice of everyone else‚Äôs. After two decades, the mechanism has inverted, replacing connection with exhaustion. ‚ÄúDopamine detox‚Äù and ‚Äúdigital Sabbath‚Äù have entered the mainstream. In the U.S., a significant proportion of 18‚Äë to 34‚Äëyear‚Äëolds took deliberate breaks from social media in 2024, citing mental health as the motivation, according to an American Psychiatric Association poll. And yet, time spent on the platforms remains high ‚Äî people scroll not because they enjoy it, but because they don‚Äôt know how to stop. Self-help influencers now recommend weekly ‚Äúno-screen Sundays‚Äù (yes, the irony). The mark of the hipster is no longer an ill-fitting beanie but an old-school Nokia dumbphone.&lt;/p&gt;
    &lt;p&gt;Some creators are quitting, too. Competing with synthetic performers who never sleep, they find the visibility race not merely tiring but absurd. Why post a selfie when an AI can generate a prettier one? Why craft a thought when ChatGPT can produce one faster?&lt;/p&gt;
    &lt;p&gt;These are the last days of social media, not because we lack content, but because the attention economy has neared its outer limit ‚Äî we have exhausted the capacity to care. There is more to watch, read, click and react to than ever before ‚Äî an endless buffet of stimulation. But novelty has become indistinguishable from noise. Every scroll brings more, and each addition subtracts meaning. We are indeed drowning. In this saturation, even the most outrageous or emotive content struggles to provoke more than a blink.&lt;/p&gt;
    &lt;p&gt;Outrage fatigues. Irony flattens. Virality cannibalizes itself. The feed no longer surprises but sedates, and in that sedation, something quietly breaks, and social media no longer feels like a place to be; it is a surface to skim.&lt;/p&gt;
    &lt;p&gt;No one is forcing anyone to go on TikTok or to consume the clickbait in their feeds. The content served to us by algorithms is, in effect, a warped mirror, reflecting and distorting our worst impulses. For younger users in particular, their scrolling of social media can become compulsive, rewarding their developing brains with unpredictable hits of dopamine that keep them glued to their screens.&lt;/p&gt;
    &lt;p&gt;Social media platforms have also achieved something more elegant than coercion: They‚Äôve made non-participation a form of self-exile, a luxury available only to those who can afford its costs.&lt;/p&gt;
    &lt;p&gt;Our offline reality is irrevocably shaped by our online world: Consider the worker who deletes or was never on LinkedIn, excluding themselves from professional networks that increasingly exist nowhere else; or the small business owner who abandons Instagram, watching customers drift toward competitors who maintain their social media presence. The teenager who refuses TikTok may find herself unable to parse references, memes and microcultures that soon constitute her peers‚Äô vernacular.&lt;/p&gt;
    &lt;p&gt;These platforms haven‚Äôt just captured attention, they‚Äôve enclosed the commons where social, economic and cultural capital are exchanged. But enclosure breeds resistance, and as exhaustion sets in, alternatives begin to emerge.&lt;/p&gt;
    &lt;head rend="h2"&gt;Architectures Of Intention&lt;/head&gt;
    &lt;p&gt;The successor to mass social media is, as already noted, emerging not as a single platform, but as a scattering of alleyways, salons, encrypted lounges and federated town squares ‚Äî those little gardens.&lt;/p&gt;
    &lt;p&gt;Maybe today‚Äôs major social media platforms will find new ways to hold the gaze of the masses, or maybe they will continue to decline in relevance, lingering like derelict shopping centers or a dying online game, haunted by bots and the echo of once‚Äëhuman chatter. Occasionally we may wander back, out of habit or nostalgia, or to converse once more as a crowd, among the ruins. But as social media collapses on itself, the future points to a quieter, more fractured, more human web, something that no longer promises to be everything, everywhere, for everyone.&lt;/p&gt;
    &lt;p&gt;This is a good thing. Group chats and invite‚Äëonly circles are where context and connection survive. These are spaces defined less by scale than by shared understanding, where people no longer perform for an algorithmic audience but speak in the presence of chosen others. Messaging apps like Signal are quietly becoming dominant infrastructures for digital social life, not because they promise discovery, but because they don‚Äôt. In these spaces, a message often carries more meaning because it is usually directed, not broadcast.&lt;/p&gt;
    &lt;p&gt;Social media‚Äôs current logic is designed to reduce friction, to give users infinite content for instant gratification, or at the very least, the anticipation of such. The antidote to this compulsive, numbing overload will be found in deliberative friction, design patterns that introduce pause and reflection into digital interaction, or platforms and algorithms that create space for intention.&lt;/p&gt;
    &lt;p&gt;This isn‚Äôt about making platforms needlessly cumbersome but about distinguishing between helpful constraints and extractive ones. Consider Are.na, a non-profit, ad-free creative platform founded in 2014 for collecting and connecting ideas that feels like the anti-Pinterest: There‚Äôs no algorithmic feed or engagement metrics, no trending tab to fall into and no infinite scroll. The pace is glacial by social media standards. Connections between ideas must be made manually, and thus, thoughtfully ‚Äî there are no algorithmic suggestions or ranked content.&lt;/p&gt;
    &lt;p&gt;To demand intention over passive, mindless screen time, X could require a 90-second delay before posting replies, not to deter participation, but to curb reactive broadcasting and engagement farming. Instagram could show how long you‚Äôve spent scrolling before allowing uploads of posts or stories, and Facebook could display the carbon cost of its data centers, reminding users that digital actions have material consequences, with each refresh. These small added moments of friction and purposeful interruptions ‚Äî what UX designers currently optimize away ‚Äî are precisely what we need to break the cycle of passive consumption and restore intention to digital interaction.&lt;/p&gt;
    &lt;p&gt;We can dream of a digital future where belonging is no longer measured by follower counts or engagement rates, but rather by the development of trust and the quality of conversation. We can dream of a digital future in which communities form around shared interests and mutual care rather than algorithmic prediction. Our public squares ‚Äî the big algorithmic platforms ‚Äî will never be cordoned off entirely, but they might sit alongside countless semi‚Äëpublic parlors where people choose their company and set their own rules, spaces that prioritize continuity over reach and coherence over chaos. People will show up not to go viral, but to be seen in context. None of this is about escaping the social internet, but about reclaiming its scale, pace, and purpose.&lt;/p&gt;
    &lt;head rend="h2"&gt;Governance Scaffolding&lt;/head&gt;
    &lt;p&gt;The most radical redesign of social media might be the most familiar: What if we treated these platforms as public utilities rather than private casinos?&lt;/p&gt;
    &lt;p&gt;A public-service model wouldn‚Äôt require state control; rather, it could be governed through civic charters, much like public broadcasters operate under mandates that balance independence and accountability. This vision stands in stark contrast to the current direction of most major platforms, which are becoming increasingly opaque.&lt;/p&gt;
    &lt;p&gt;In recent years, Reddit and X, among other platforms, have either restricted or removed API access, dismantling open-data pathways. The very infrastructures that shape public discourse are retreating from public access and oversight. Imagine social media platforms with transparent algorithms subject to public audit, user representation on governance boards, revenue models based on public funding or member dues rather than surveillance advertising, mandates to serve democratic discourse rather than maximize engagement, and regular impact assessments that measure not just usage but societal effects.&lt;/p&gt;
    &lt;p&gt;Some initiatives gesture in this direction. Meta‚Äôs Oversight Board, for example, frames itself as an independent body for content moderation appeals, though its remit is narrow and its influence ultimately limited by Meta‚Äôs discretion. X‚Äôs Community Notes, meanwhile, allows user-generated fact-checks but relies on opaque scoring mechanisms and lacks formal accountability. Both are add-ons to existing platform logic rather than systemic redesigns. A true public-service model would bake accountability into the platform‚Äôs infrastructure, not just bolt it on after the fact.&lt;/p&gt;
    &lt;p&gt;The European Union has begun exploring this territory through its Digital Markets Act and Digital Services Act, but these laws, enacted in 2022, largely focus on regulating existing platforms rather than imagining new ones. In the United States, efforts are more fragmented. Proposals such as the Platform Accountability and Transparency Act (PATA) and state-level laws in California and New York aim to increase oversight of algorithmic systems, particularly where they impact youth and mental health. Still, most of these measures seek to retrofit accountability onto current platforms. What we need are spaces built from the ground up on different principles, where incentives align with human interest rather than extractive, for-profit ends.&lt;/p&gt;
    &lt;p&gt;This could take multiple forms, like municipal platforms for local civic engagement, professionally focused networks run by trade associations, and educational spaces managed by public library systems. The key is diversity, delivering an ecosystem of civic digital spaces that each serve specific communities with transparent governance.&lt;/p&gt;
    &lt;p&gt;Of course, publicly governed platforms aren‚Äôt immune to their own risks. State involvement can bring with it the threat of politicization, censorship or propaganda, and this is why the governance question must be treated as infrastructural, rather than simply institutional. Just as public broadcasters in many democracies operate under charters that insulate them from partisan interference, civic digital spaces would require independent oversight, clear ethical mandates, and democratically accountable governance boards, not centralized state control. The goal is not to build a digital ministry of truth, but to create pluralistic public utilities: platforms built for communities, governed by communities and held to standards of transparency, rights protection and civic purpose.&lt;/p&gt;
    &lt;p&gt;The technical architecture of the next social web is already emerging through federated and distributed protocols like ActivityPub (used by Mastodon and Threads) and Bluesky‚Äôs Authenticated Transfer (AT) Protocol, or atproto, (a decentralised framework that allows users to move between platforms while keeping their identity and social graph) as well as various blockchain-based experiments, like Lens and Farcaster.&lt;/p&gt;
    &lt;p&gt;But protocols alone won‚Äôt save us. The email protocol is decentralized, yet most email flows through a handful of corporate providers. We need to ‚Äúrewild the internet,‚Äù as Maria Farrell and Robin Berjon mentioned in a Noema essay. We need governance scaffolding, shared institutions that make decentralization viable at scale. Think credit unions for the social web that function as member-owned entities providing the infrastructure that individual users can‚Äôt maintain alone. These could offer shared moderation services that smaller instances can subscribe to, universally portable identity systems that let users move between platforms without losing their history, collective bargaining power for algorithm transparency and data rights, user data dividends for all, not just influencers (if platforms profit from our data, we should share in those profits), and algorithm choice interfaces that let users select from different recommender systems.&lt;/p&gt;
    &lt;p&gt;Bluesky‚Äôs AT Protocol explicitly allows users to port identity and social graphs, but it‚Äôs very early days and cross-protocol and platform portability remains extremely limited, if not effectively non-existent. Bluesky also allows users to choose among multiple content algorithms, an important step toward user control. But these models remain largely tied to individual platforms and developer communities. What‚Äôs still missing is a civic architecture that makes algorithmic choice universal, portable, auditable and grounded in public-interest governance rather than market dynamics alone.&lt;/p&gt;
    &lt;p&gt;Imagine being able to toggle between different ranking logics: a chronological feed, where posts appear in real time; a mutuals-first algorithm that privileges content from people who follow you back; a local context filter that surfaces posts from your geographic region or language group; a serendipity engine designed to introduce you to unfamiliar but diverse content; or even a human-curated layer, like playlists or editorials built by trusted institutions or communities. Many of these recommender models do exist, but they are rarely user-selectable, and almost never transparent or accountable. Algorithm choice shouldn‚Äôt require a hack or browser extension; it should be built into the architecture as a civic right, not a hidden setting.&lt;/p&gt;
    &lt;p&gt;Algorithmic choice can also develop new hierarchies. If feeds can be curated like playlists, the next influencer may not be the one creating content, but editing it. Institutions, celebrities and brands will be best positioned to build and promote their own recommendation systems. For individuals, the incentive to do this curatorial work will likely depend on reputation, relational capital or ideological investment. Unless we design these systems with care, we risk reproducing old dynamics of platform power, just in a new form.&lt;/p&gt;
    &lt;p&gt;Federated platforms like Mastodon and Bluesky face real tensions between autonomy and safety: Without centralized moderation, harmful content can proliferate, while over-reliance on volunteer admins creates sustainability problems at scale. These networks also risk reinforcing ideological silos, as communities block or mute one another, fragmenting the very idea of a shared public square. Decentralization gives users more control, but it also raises difficult questions about governance, cohesion and collective responsibility ‚Äî questions that any humane digital future will have to answer.&lt;/p&gt;
    &lt;p&gt;But there is a possible future where a user, upon opening an app, is asked how they would like to see the world on a given day. They might choose the serendipity engine for unexpected connections, the focus filter for deep reads or the local lens for community news. This is technically very achievable ‚Äî the data would be the same; the algorithms would just need to be slightly tweaked ‚Äî but it would require a design philosophy that treats users as citizens of a shared digital system rather than cattle. While this is possible, it can feel like a pipe dream.&lt;/p&gt;
    &lt;p&gt;To make algorithmic choice more than a thought experiment, we need to change the incentives that govern platform design. Regulation can help, but real change will come when platforms are rewarded for serving the public interest. This could mean tying tax breaks or public procurement eligibility to the implementation of transparent, user-controllable algorithms. It could mean funding research into alternative recommender systems and making those tools open-source and interoperable. Most radically, it could involve certifying platforms based on civic impact, rewarding those that prioritize user autonomy and trust over sheer engagement.&lt;/p&gt;
    &lt;head rend="h2"&gt;Digital Literacy As Public Health&lt;/head&gt;
    &lt;p&gt;Perhaps most crucially, we need to reframe digital literacy not as an individual responsibility but as a collective capacity. This means moving beyond spot-the-fake-news workshops to more fundamental efforts to understand how algorithms shape perception and how design patterns exploit our cognitive processes.&lt;/p&gt;
    &lt;p&gt;Some education systems are beginning to respond, embedding digital and media literacy across curricula. Researchers and educators argue that this work needs to begin in early childhood and continue through secondary education as a core competency. The goal is to equip students to critically examine the digital environments they inhabit daily, to become active participants in shaping the future of digital culture rather than passive consumers. This includes what some call algorithmic literacy, the ability to understand how recommender systems work, how content is ranked and surfaced, and how personal data is used to shape what you see ‚Äî and what you don‚Äôt.&lt;/p&gt;
    &lt;p&gt;Teaching this at scale would mean treating digital literacy as public infrastructure, not just a skill set for individuals, but a form of shared civic defense. This would involve long-term investments in teacher training, curriculum design and support for public institutions, such as libraries and schools, to serve as digital literacy hubs. When we build collective capacity, we begin to lay the foundations for a digital culture grounded in understanding, context and care.&lt;/p&gt;
    &lt;p&gt;We also need behavioral safeguards like default privacy settings that protect rather than expose, mandatory cooling-off periods for viral content (deliberately slowing the spread of posts that suddenly attract high engagement), algorithmic impact assessments before major platform changes and public dashboards that show platform manipulation, that is, coordinated or deceptive behaviors that distort how content is amplified or suppressed, in real-time. If platforms are forced to disclose their engagement tactics, these tactics lose power. The ambition is to make visible hugely influential systems that currently operate in obscurity.&lt;/p&gt;
    &lt;p&gt;We need to build new digital spaces grounded in different principles, but this isn‚Äôt an either-or proposition. We also must reckon with the scale and entrenchment of existing platforms that still structure much of public life. Reforming them matters too. Systemic safeguards may not address the core incentives that inform platform design, but they can mitigate harm in the short term. The work, then, is to constrain the damage of the current system while constructing better ones in parallel, to contain what we have, even as we create what we need.&lt;/p&gt;
    &lt;p&gt;The choice isn‚Äôt between technological determinism and Luddite retreat; it‚Äôs about constructing alternatives that learn from what made major platforms usable and compelling while rejecting the extractive mechanics that turned those features into tools for exploitation. This won‚Äôt happen through individual choice, though choice helps; it also won‚Äôt happen through regulation, though regulation can really help. It will require our collective imagination to envision and build systems focused on serving human flourishing rather than harvesting human attention.&lt;/p&gt;
    &lt;p&gt;Social media as we know it is dying, but we‚Äôre not condemned to its ruins. We are capable of building better ‚Äî smaller, slower, more intentional, more accountable ‚Äî spaces for digital interaction, spaces where the metrics that matter aren‚Äôt engagement and growth but understanding and connection, where algorithms serve the community rather than strip-mining it.&lt;/p&gt;
    &lt;p&gt;The last days of social media might be the first days of something more human: a web that remembers why we came online in the first place ‚Äî not to be harvested but to be heard, not to go viral but to find our people, not to scroll but to connect. We built these systems, and we can certainly build better ones. The question is whether we will do this or whether we will continue to drown.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45229799</guid></item><item><title>Java 25's new CPU-Time Profiler (1)</title><link>https://mostlynerdless.de/blog/2025/06/11/java-25s-new-cpu-time-profiler-1/</link><description>&lt;doc fingerprint="e298c11719f02744"&gt;
  &lt;main&gt;
    &lt;p&gt;This is the first part of my series; the other parts are&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Java 25‚Äôs new CPU-Time Profiler: The Implementation (2)&lt;/item&gt;
      &lt;item&gt;Java 25‚Äôs new CPU-Time Profiler: Queue Sizing (3)&lt;/item&gt;
      &lt;item&gt;Java 25‚Äôs new CPU-Time Profiler: Removing Redundant Synchronization (4)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Back to the blog post:&lt;/p&gt;
    &lt;p&gt;More than three years in the making, with a concerted effort starting last year, my CPU-time profiler landed in Java with OpenJDK 25. It‚Äôs an experimental new profiler/method sampler that helps you find performance issues in your code, having distinct advantages over the current sampler. This is what this week‚Äôs and next week‚Äôs blog posts are all about. This week, I will cover why we need a new profiler and what information it provides; next week, I‚Äôll cover the technical internals that go beyond what‚Äôs written in the JEP. I will quote the JEP 509 quite a lot, thanks to Ron Pressler; it reads like a well-written blog post in and of itself.&lt;/p&gt;
    &lt;p&gt;Before I show you its details, I want to focus on what the current default method profiler in JFR does:&lt;/p&gt;
    &lt;head rend="h2"&gt;Current JFR Profiling Strategy&lt;/head&gt;
    &lt;p&gt;JDK 25‚Äôs default method profiler also changed, as my previous blog post, Taming the Bias: Unbiased* Safepoint-Based Stack Walking in JFR, described. However, the profiling strategy remained the same.&lt;/p&gt;
    &lt;p&gt;At every interval, say 10 or 20 milliseconds, five threads running in Java and one in native Java are picked from the list of threads and sampled. This thread list is iterated linearly, and threads not in the requested state are skipped (source).&lt;/p&gt;
    &lt;head rend="h2"&gt;Problems?&lt;/head&gt;
    &lt;p&gt;This strategy has problems, as also covered in a talk by Jaroslav Bachorik and me at this year‚Äôs FOSDEM:&lt;/p&gt;
    &lt;p&gt;The aggressive subsampling means that the effective sampling interval depends on the number of cores and the parallelism of your system. Say we have a large machine on which 32 threads can run in parallel. Then JFR on samples at most 19%, turning a sampling rate of 10ms into 53ms. This is an inherent property of wall-clock sampling, as the sampler considers threads on the system. This number can be arbitrarily large, so sub-sampling is necessary.&lt;/p&gt;
    &lt;p&gt;However, the sampling policy is not true wall-clock sampling, as it prioritizes threads running in Java. Consider a setting where 10 threads run in native and 5 in Java. In this case, the sampler always picks all threads running in Java, and only one thread running in native. This might be confusing and may lead users to the wrong conclusions.&lt;/p&gt;
    &lt;p&gt;Even if we gloss over this and call the current strategy ‚Äúexecution-time‚Äù, it might not be suitable for profiling every application. To quote from the/my JEP (thanks to Ron Pressler for writing most of the JEP text in its final form):&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Execution time does not necessarily reflect CPU time. A method that sorts an array, e.g., spends all of its time on the CPU. Its execution time corresponds to the number of CPU cycles it consumes. In contrast, a method that reads from a network socket might spend most of its time idly waiting for bytes to arrive over the wire. Of the time it consumes, only a small portion is spent on the CPU. An execution-time profile will not distinguish between these cases.&lt;/p&gt;&lt;p&gt;Even a program that does a lot of I/O can be constrained by the CPU. A computation-heavy method might consume little execution time compared the program‚Äôs I/O operations, thus having little effect on latency ‚Äî but it might consume most of the program‚Äôs CPU cycles, thus affecting throughput. Identifying and optimizing such methods will reduce CPU consumption and improve the program‚Äôs throughput ‚Äî but in order to do so, we need to profile CPU time rather than execution time.&lt;/p&gt;JEP 509: JFR CPU-Time Profiling (Experimental)&lt;/quote&gt;
    &lt;head rend="h2"&gt;Execution-time Example&lt;/head&gt;
    &lt;quote&gt;&lt;p&gt;For example, consider a program,&lt;/p&gt;&lt;code&gt;HttpRequests&lt;/code&gt;, with two threads, each performing HTTP requests. One thread runs a&lt;code&gt;tenFastRequests&lt;/code&gt;method that makes ten requests, sequentially, to an HTTP endpoint that responds in 10ms; the other runs a&lt;code&gt;oneSlowRequest&lt;/code&gt;method that makes a single request to an endpoint that responds in 100ms. The average latency of both methods should be about the same, and so the total time spent executing them should be about the same.&lt;p&gt;We can record a stream of execution-time profiling events like so:&lt;/p&gt;$ java -XX:StartFlightRecording=filename=profile.jfr,settings=profile.jfc HttpRequests clientJEP 509: JFR CPU-Time Profiling (Experimental)&lt;/quote&gt;
    &lt;p&gt;You can find the program on GitHub. Be aware that it requires the server instance to run alongside, start it via&lt;/p&gt;
    &lt;quote&gt;java HttpRequests server&lt;/quote&gt;
    &lt;quote&gt;&lt;p&gt;At fixed time intervals, JFR records&lt;/p&gt;&lt;code&gt;ExecutionSample&lt;/code&gt;events into the file&lt;code&gt;profile.jfr&lt;/code&gt;. Each event captures the stack trace of a thread running Java code, thus recording all of the methods currently running on that thread. (The file&lt;code&gt;profile.jfc&lt;/code&gt;is a JFR configuration file, included in the JDK, that configures the JFR events needed for an execution-time profile.)&lt;p&gt;We can generate a textual profile from the recorded event stream by using the&lt;/p&gt;&lt;code&gt;jfr&lt;/code&gt;tool included in the JDK:$ jfr view native-methods profile.jfr Waiting or Executing Native Methods Method Samples Percent --------------------------------------------------------------- ------- ------- sun.nio.ch.SocketDispatcher.read0(FileDescriptor, long, int) 102 98.08% ...&lt;p&gt;This clearly shows that most of the program‚Äôs time is spent waiting for socket I/O.&lt;/p&gt;&lt;p&gt;We can generate a graphical profile, in the form of a flame graph, by using the JDK Mission Control tool (JMC):&lt;/p&gt;&lt;p&gt;Here we see that the&lt;/p&gt;&lt;code&gt;oneSlowRequest&lt;/code&gt;and&lt;code&gt;tenFastRequests&lt;/code&gt;methods take a similar amount of execution time, as we expect.&lt;p&gt;However, we also expect&lt;/p&gt;JEP 509: JFR CPU-Time Profiling (Experimental)&lt;code&gt;tenFastRequests&lt;/code&gt;to take more CPU time than&lt;code&gt;oneSlowRequest&lt;/code&gt;, since ten rounds of creating requests and processing responses requires more CPU cycles than just one round. If these methods were run concurrently on many threads then the program could become CPU-bound, yet an execution-time profile would still show most of the program‚Äôs time being spent waiting for socket I/O. If we could profile CPU time then we could see that optimizing&lt;code&gt;tenFastRequests&lt;/code&gt;, rather than&lt;code&gt;oneSlowRequest&lt;/code&gt;, could improve the program‚Äôs throughput.&lt;/quote&gt;
    &lt;p&gt;Additionally, we point to a tiny but important problem in the JEP: the handling of failed samples. Sampling might fail for many reasons, be it that the sampled thread is not in the correct state, that the stack walking failed due to missing information, or many more. However, the default JFR sampler ignores these samples (which might account for up to a third of all samples). This doesn‚Äôt make interpreting the ‚Äúexecution-time‚Äù profiles any easier.&lt;/p&gt;
    &lt;head rend="h2"&gt;CPU-time profiling&lt;/head&gt;
    &lt;p&gt;As shown in the video above, sampling every thread every n milliseconds of CPU time improves the situation. Now, the number of samples for every thread is directly related to the time it spends on the CPU without any subsampling, as the number of hardware threads bounds the number of sampled threads.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;The ability to accurately and precisely measure CPU-cycle consumption was added to the Linux kernel in version 2.6.12 via a timer that emits signals at fixed intervals of CPU time rather than fixed intervals of elapsed real time. Most profilers on Linux use this mechanism to produce CPU-time profiles.&lt;/p&gt;&lt;p&gt;Some popular third-party Java tools, including async-profiler, use Linux‚Äôs CPU timer to produce CPU-time profiles of Java programs. However, to do so, such tools interact with the Java runtime through unsupported internal interfaces. This is inherently unsafe and can lead to process crashes.&lt;/p&gt;&lt;p&gt;We should enhance JFR to use the Linux kernel‚Äôs CPU timer to safely produce CPU-time profiles of Java programs. This would help the many developers who deploy Java applications on Linux to make those applications more efficient.&lt;/p&gt;JEP 509: JFR CPU-Time Profiling (Experimental)&lt;/quote&gt;
    &lt;p&gt;Please be aware that I don‚Äôt discourage using async-profiler. It‚Äôs a potent tool and is used by many people. But it is inherently hampered by not being embedded into the JDK. This is especially true with the new stackwalking at safepoints (see Taming the Bias: Unbiased* Safepoint-Based Stack Walking in JFR), making the current JFR sampler safer to use. This mechanism is sadly not available for external profilers, albeit I had my ideas for an API (see Taming the Bias: Unbiased Safepoint-Based Stack Walking), but this project has sadly been abandoned.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs continue with the example from before.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;FR will use Linux‚Äôs CPU-timer mechanism to sample the stack of every thread running Java code at fixed intervals of CPU time. Each such sample is recorded in a new type of event,&lt;/p&gt;&lt;code&gt;jdk.CPUTimeSample&lt;/code&gt;. This event is not enabled by default.&lt;p&gt;This event is similar to the existing&lt;/p&gt;&lt;code&gt;jdk.ExecutionSample&lt;/code&gt;event for execution-time sampling. Enabling CPU-time events does not affect execution-time events in any way, so the two can be collected simultaneously.&lt;p&gt;We can enable the new event in a recording started at launch like so:&lt;/p&gt;$ java -XX:StartFlightRecording=jdk.CPUTimeSample#enabled=true,filename=profile.jfr ...&lt;p&gt;With the new CPU-time sampler, in the flame graph it becomes clear that the application spends nearly all of its CPU cycles in&lt;/p&gt;&lt;code&gt;tenFastRequests&lt;/code&gt;:&lt;p&gt;A textual profile of the hot CPU methods, i.e., those that consume many CPU cycles in their own bodies rather than in calls to other methods, can be obtained like so:&lt;/p&gt;$ jfr view cpu-time-hot-methods profile.jfr&lt;p&gt;However, in this particular example, the output is not as useful as the flame graph.&lt;/p&gt;JEP 509: JFR CPU-Time Profiling (Experimental)&lt;/quote&gt;
    &lt;p&gt;Notably, the CPU-time profiler also reports failed and missed samples, but more on that later.&lt;/p&gt;
    &lt;head rend="h2"&gt;Problems of the new Profiler&lt;/head&gt;
    &lt;p&gt;I pointed out all the problems in the current JFR method sampler, so I should probably point out my problems, too.&lt;/p&gt;
    &lt;p&gt;The most significant issue is platform support, or better, the lack of it: The new profiler only supports Linux for the time being. While this is probably not a problem for production profiling, as most systems use Linux anyway, it‚Äôs a problem for profiling on developer machines. Most development happens on Windows and Mac OS machines. So, not being able to use the same profiler as in production hampers productivity. But this is a problem for other profilers too. Async-profiler, for example, only supports wall-clock profiling on Mac OS and doesn‚Äôt support Windows at all. JetBrains has a closed-source version of async-profiler that might support cpu-time profiling on Windows (see GitHub issue). Still, I could not confirm as I don‚Äôt have a Windows machine and found no specific information online.&lt;/p&gt;
    &lt;p&gt;Another issue, of course, is that the profiler barely got in at the last minute, after Nicolai Parlog, for example, filmed his Java 25 update video.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why did it get into JDK 25?&lt;/head&gt;
    &lt;p&gt;Most users only use and get access to LTS versions of the JDK, so we wanted to get the feature into the LTS JDK 25 to allow people to experiment with it. To quote Markus Gr√∂nlund:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;I am approving this PR for the following reasons:&lt;/p&gt;&lt;item&gt;We have reached a state that is ‚Äúgood enough‚Äù ‚Äì I no longer see any fundamental design issues that can not be handled by follow-up bug fixes.&lt;/item&gt;&lt;item&gt;There are still many vague aspects included with this PR, as many has already pointed out, mostly related to the memory model and thread interactions ‚Äì all those can, and should, be clarified, explained and exacted post-integration.&lt;/item&gt;&lt;item&gt;The feature as a whole is experimental and turned off by default.&lt;/item&gt;&lt;item&gt;Today is the penultimate day before JDK 25 cutoff. To give the feature a fair chance for making JDK25, it needs approval now.&lt;/item&gt;&lt;p&gt;Thanks a lot Johannes and all involved for your hard work getting this feature ready.&lt;/p&gt;&lt;p&gt;Many thanks&lt;/p&gt;Comment on the PR&lt;lb/&gt;Markus&lt;/quote&gt;
    &lt;head rend="h2"&gt;Open Issues&lt;/head&gt;
    &lt;p&gt;So, use the profiler with care. None of the currently known issues should break the JVM. But there are currently three important follow-up issues to the merged profiler:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Avoid using a spinlock as the synchronization point returning from native in CPU Time Profiler [Edit July: fixed]&lt;/item&gt;
      &lt;item&gt;Clarify the requirements and exact the memory ordering in CPU Time Profiler: I used acquire-release semantics for most atomic variables, which is not wrong, just not necessarily optimal from a performance perspective.&lt;/item&gt;
      &lt;item&gt;Fix interval recomputation in CPU Time Profiler [Edit July: fixed]&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I have already started work on the last issue and will be looking into the other two soon. Please test the profiler yourself and report all the issues you find.&lt;/p&gt;
    &lt;head rend="h2"&gt;The new CPUTimeSample Event&lt;/head&gt;
    &lt;p&gt;Where the old profiler had two events &lt;code&gt;jdk.ExecutionSample&lt;/code&gt; and &lt;code&gt;jdk.NativeMethodSample&lt;/code&gt;The new profiler has only one for simplicity, as it doesn‚Äôt treat threads in native and Java differently. As stated before, this event is called &lt;code&gt;jdk.CPUTimeSample&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The event has five different fields:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;stackTrace&lt;/code&gt;(nullable): Recorded stack trace&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;eventThread&lt;/code&gt;: Sampled thread&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;failed&lt;/code&gt;(boolean): Did the sampler fail to walk the stack trace? Implies that&lt;code&gt;stackTrace&lt;/code&gt;is&lt;code&gt;null&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;samplingPeriod&lt;/code&gt;: The actual sampling period, directly computed in the signal handler. More on that next week.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;biased&lt;/code&gt;(boolean): Is this sample safepoint biased (the stacktrace related to the frame at safepoint and not the actual frame when the sampling request has been created, see Taming the Bias: Unbiased* Safepoint-Based Stack Walking in JFR for more)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can find the event on the JFR Events Collection page too.&lt;/p&gt;
    &lt;p&gt;Internally, the profiler uses bounded queues, which might overflow; this can result in lost events. The number of these events is regularly recorded in the form of the &lt;code&gt;jdk.CPUTimeSampleLoss&lt;/code&gt; event. The event has two fields:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;lostSamples&lt;/code&gt;: Number of samples that have been lost since the last&lt;code&gt;jdk.CPUTimeSampleLoss&lt;/code&gt;event&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;eventThread&lt;/code&gt;: Thread for which the samples are lost&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Both events allow a pretty good view of the program‚Äôs execution, including a relatively exact view of the CPU time used.&lt;/p&gt;
    &lt;head rend="h2"&gt;Configuration of the CPU-time Profiler&lt;/head&gt;
    &lt;p&gt;The emission of two events of the current sampler is controlled via the &lt;code&gt;period&lt;/code&gt; property. It allows the user to configure the sampling interval. The problem now with the CPU-time profiler is that it might produce too many events depending on the number of hardware threads. This is why the &lt;code&gt;jdk.CPUTimeSample&lt;/code&gt; event is controlled via the &lt;code&gt;throttle&lt;/code&gt; setting. This setting can be either a sampling interval or an upper bound for the number of emitted events.&lt;/p&gt;
    &lt;p&gt;When setting an interval directly like ‚Äú10ms‚Äù (as in the &lt;code&gt;default.jfc&lt;/code&gt;), then we sample every thread every 10ms of CPU-time. This can at most result in 100 * #[hardware threads] events per second. On a 10 hardware thread machine, this results in at most (when every thread is CPU-bound) 1000 events per second or 12800 on a 128 hardware thread machine.&lt;/p&gt;
    &lt;p&gt;Setting, on the other hand, &lt;code&gt;throttle&lt;/code&gt; to a rate like ‚Äú500/s‚Äù (as in the &lt;code&gt;profile.jfc&lt;/code&gt;), limits the number of events per second to a fixed rate. This is implemented by choosing the proper sampling interval in relation to the number of hardware threads. For a rate of ‚Äú500/s‚Äù and a ten hardware thread machine, this would be 20ms. On a 128 hardware thread machine, this would be 0.256.&lt;/p&gt;
    &lt;p&gt;I have to mention that the issue Fix interval recomputation in CPU Time Profiler is related to the recomputation when the number of hardware threads changes mid-profiling.&lt;/p&gt;
    &lt;head rend="h2"&gt;New JFR Views&lt;/head&gt;
    &lt;p&gt;In addition to the two new events, there are two new views that you can use via &lt;code&gt;jfr view VIEW_NAME profile.jfr&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;cpu-time-hot-methods&lt;/code&gt; shows you a list of the 25 most executed methods. These are methods that are on top of the stack the most (running the example with a 1ms throttle):&lt;/p&gt;
    &lt;quote&gt;Java Methods that Execute the Most from CPU Time Sampler (Experimental) Method Samples Percent ----------------------------------------------------------------------------------------------------- ------- ------- jdk.jfr.internal.JVM.emitEvent(long, long, long) 35 72.92% jdk.jfr.internal.event.EventWriter.putStringValue(String) 1 2.08% jdk.internal.loader.NativeLibraries.load(NativeLibraries$NativeLibraryImpl, String, boolean, boolean) 1 2.08% jdk.internal.logger.LazyLoggers$LazyLoggerAccessor.platform() 1 2.08% jdk.internal.jimage.ImageStringsReader.unmaskedHashCode(String, int) 1 2.08% sun.net.www.ParseUtil.quote(String, long, long) 1 2.08% java.net.HttpURLConnection.getResponseCode() 1 2.08% java.io.BufferedInputStream.read(byte[], int, int) 1 2.08% java.util.HashMap.hash(Object) 1 2.08% sun.nio.ch.NioSocketImpl$1.read(byte[], int, int) 1 2.08% java.util.Properties.load0(Properties$LineReader) 1 2.08% java.lang.StringLatin1.regionMatchesCI(byte[], int, byte[], int, int) 1 2.08% java.util.stream.AbstractPipeline.exactOutputSizeIfKnown(Spliterator) 1 2.08% sun.nio.fs.UnixChannelFactory$Flags.toFlags(Set) 1 2.08%&lt;/quote&gt;
    &lt;p&gt;The second view is &lt;code&gt;cpu-time-statistics&lt;/code&gt; which gives you the number of successful samples, failed samples, biased Samples, total samples, and lost samples:&lt;/p&gt;
    &lt;quote&gt;CPU Time Sample Statistics -------------------------- Successful Samples: 48 Failed Samples: 0 Biased Samples: 0 Total Samples: 48 Lost Samples: 14&lt;/quote&gt;
    &lt;p&gt;All of the lost samples are caused by the sampled Java thread running VM internal code. This view is really helpful when checking whether the profiling contains the whole picture.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Getting this new profiler in JDK 25 was a real push, but I think it was worth it. OpenJDK now has a built-in CPU-time profiler that records missed samples. The implementation builds upon JFR‚Äôs new cooperative sampling approach, which also got into JDK 25 just days before. CPU-time profiling has many advantages, especially when you‚Äôre interested in the code that is actually wasting your CPU.&lt;/p&gt;
    &lt;p&gt;This is the first of a two-part series on the new profiler. You can expect a deep dive into the implementation of the profiler next week.&lt;/p&gt;
    &lt;p&gt;This blog post is part of my work in the SapMachine team at SAP, making profiling easier for everyone.&lt;/p&gt;
    &lt;p&gt;P.S.: I submitted to a few conferences the talk From Idea to JEP: An OpenJDK Developer‚Äôs Journey to Improve Profiling with the following description: Have you ever wondered how profiling, like JFR, works in OpenJDK and how we can improve it? In this talk, I‚Äôll take you on my three-year journey to improve profiling, especially method sampling, with OpenJDK: from the initial ideas and problems of existing approaches to my different draft implementations and JEP versions, with all the setbacks and friends I made along the way. It‚Äôs a story of blood, sweat, and C++.&lt;lb/&gt;It has sadly not been accepted yet.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45230265</guid></item><item><title>How 'overworked, underpaid' humans train Google's AI to seem smart</title><link>https://www.theguardian.com/technology/2025/sep/11/google-gemini-ai-training-humans</link><description>&lt;doc fingerprint="3d3319d039b296c7"&gt;
  &lt;main&gt;
    &lt;p&gt;In the spring of 2024, when Rachael Sawyer, a technical writer from Texas, received a LinkedIn message from a recruiter hiring for a vague title of writing analyst, she assumed it would be similar to her previous gigs of content creation. On her first day of work a week later, however, her expectations went bust. Instead of writing words herself, Sawyer‚Äôs job was to rate and moderate the content created by artificial intelligence.&lt;/p&gt;
    &lt;p&gt;The job initially involved a mix of parsing through meeting notes and chats summarized by Google‚Äôs Gemini, and, in some cases, reviewing short films made by the AI.&lt;/p&gt;
    &lt;p&gt;On occasion, she was asked to deal with extreme content, flagging violent and sexually explicit material generated by Gemini for removal, mostly text. Over time, however, she went from occasionally moderating such text and images to being tasked with it exclusively.&lt;/p&gt;
    &lt;p&gt;‚ÄúI was shocked that my job involved working with such distressing content,‚Äù said Sawyer, who has been working as a ‚Äúgeneralist rater‚Äù for Google‚Äôs AI products since March 2024. ‚ÄúNot only because I was given no warning and never asked to sign any consent forms during onboarding, but because neither the job title or description ever mentioned content moderation.‚Äù&lt;/p&gt;
    &lt;p&gt;The pressure to complete dozens of these tasks every day, each within 10 minutes of time, has led Sawyer into spirals of anxiety and panic attacks, she says ‚Äì without mental health support from her employer.&lt;/p&gt;
    &lt;p&gt;Sawyer is one among the thousands of AI workers contracted for Google through Japanese conglomerate Hitachi‚Äôs GlobalLogic to rate and moderate the output of Google‚Äôs AI products, including its flagship chatbot Gemini, launched early last year, and its summaries of search results, AI Overviews. The Guardian spoke to 10 current and former employees from the firm. Google contracts with other firms for AI rating services as well, including Accenture and, previously, Appen.&lt;/p&gt;
    &lt;p&gt;Google has clawed its way back into the AI race in the past year with a host of product releases to rival OpenAI‚Äôs ChatGPT. Google‚Äôs most advanced reasoning model, Gemini 2.5 Pro, is touted to be better than OpenAI‚Äôs O3, according to LMArena, a leaderboard that tracks the performance of AI models. Each new model release comes with the promise of higher accuracy, which means that for each version, these AI raters are working hard to check if the model responses are safe for the user. Thousands of humans lend their intelligence to teach chatbots the right responses across domains as varied as medicine, architecture and astrophysics, correcting mistakes and steering away from harmful outputs.&lt;/p&gt;
    &lt;p&gt;A great deal of attention has been paid to the workers who label the data that is used to train artificial intelligence. There is, however, another corps of workers, including Sawyer, working day and night to moderate the output of AI, ensuring that chatbots‚Äô billions of users see only safe and appropriate responses.&lt;/p&gt;
    &lt;p&gt;AI models are trained on vast swathes of data from every corner of the internet. Workers such as Sawyer sit in a middle layer of the global AI supply chain ‚Äì paid more than data annotators in Nairobi or Bogota, whose work mostly involves labelling data for AI models or self-driving cars, but far below the engineers in Mountain View who design these models.&lt;/p&gt;
    &lt;p&gt;Despite their significant contributions to these AI models, which would perhaps hallucinate if not for these quality control editors, these workers feel hidden.&lt;/p&gt;
    &lt;p&gt;‚ÄúAI isn‚Äôt magic; it‚Äôs a pyramid scheme of human labor,‚Äù said Adio Dinika, a researcher at the Distributed AI Research Institute based in Bremen, Germany. ‚ÄúThese raters are the middle rung: invisible, essential and expendable.‚Äù&lt;/p&gt;
    &lt;p&gt;Google said in a statement: ‚ÄúQuality raters are employed by our suppliers and are temporarily assigned to provide external feedback on our products. Their ratings are one of many aggregated data points that help us measure how well our systems are working, but do not directly impact our algorithms or models.‚Äù GlobalLogic declined to comment for this story.&lt;/p&gt;
    &lt;head rend="h2"&gt;AI raters: the shadow workforce&lt;/head&gt;
    &lt;p&gt;Google, like other tech companies, hires data workers through a web of contractors and subcontractors. One of the main contractors for Google‚Äôs AI raters is GlobalLogic ‚Äì where these raters are split into two broad categories: generalist raters and super raters. Within the super raters, there are smaller pods of people with highly specialized knowledge. Most workers hired initially for the roles were teachers. Others included writers, people with master‚Äôs degrees in fine arts and some with very specific expertise, for instance, Phd holders in physics, workers said.&lt;/p&gt;
    &lt;p&gt;GlobalLogic started this work for the tech giant in 2023 ‚Äì at the time, it hired 25 super raters, according to three of the interviewed workers. As the race to improve chatbots intensified, GlobalLogic ramped up its hiring and grew the team of AI super raters to almost 2,000 people, most of them located within the US and moderating content in English, according to the workers.&lt;/p&gt;
    &lt;p&gt;AI raters at GlobalLogic are paid more than their data-labeling counterparts in Africa and South America, with wages starting at $16 an hour for generalist raters and $21 an hour for super raters, according to workers. Some are simply thankful to have a gig as the US job market sours, but others say that trying to make Google‚Äôs AI products better has come at a personal cost.&lt;/p&gt;
    &lt;p&gt;‚ÄúThey are people with expertise who are doing a lot of great writing work, who are being paid below what they‚Äôre worth to make an AI model that, in my opinion, the world doesn‚Äôt need,‚Äù said a rater of their highly educated colleagues, requesting anonymity for fear of professional reprisal.&lt;/p&gt;
    &lt;p&gt;Ten of Google‚Äôs AI trainers the Guardian spoke to said they have grown disillusioned with their jobs because they work in siloes, face tighter and tighter deadlines, and feel they are putting out a product that‚Äôs not safe for users.&lt;/p&gt;
    &lt;p&gt;One rater who joined GlobalLogic early last year said she enjoyed understanding the AI pipeline by working on Gemini 1.0, 2.0 and now 2.5, and helping it give ‚Äúa better answer that sounds more human‚Äù. Six months in, though, tighter deadlines kicked in. Her timer of 30 minutes for each task shrank to 15 ‚Äì which meant reading, fact-checking and rating approximately 500 words per response, sometimes more. The tightening constraints made her question the quality of her work and, by extension, the reliability of the AI. In May 2023, a contract worker for Appen submitted a letter to the US Congress that the pace imposed on him and others would make Google Bard, Gemini‚Äôs predecessor, a ‚Äúfaulty‚Äù and ‚Äúdangerous‚Äù product.&lt;/p&gt;
    &lt;head rend="h2"&gt;High pressure, little information&lt;/head&gt;
    &lt;p&gt;One worker who joined GlobalLogic in spring 2024 and has worked on five different projects so far, including Gemini and AI Overviews, described her work as being presented with a prompt ‚Äì either user-generated or synthetic ‚Äì and with two sample responses, then choosing the response that aligned best with the guidelines, and rating it based on any violations of those guidelines. Occasionally, she was asked to stump the model.&lt;/p&gt;
    &lt;p&gt;She said raters are typically given as little information as possible or that their guidelines changed too rapidly to enforce consistently. ‚ÄúWe had no idea where it was going, how it was being used or to what end,‚Äù she said, requesting anonymity, as she is still employed at the company.&lt;/p&gt;
    &lt;p&gt;The AI responses she got ‚Äúcould have hallucinations or incorrect answers‚Äù and she had to rate them based on factuality ‚Äì is it true? ‚Äì and groundedness ‚Äì does it cite accurate sources? Sometimes, she also handled ‚Äúsensitivity tasks‚Äù that included prompts such as ‚Äúwhen is corruption good?‚Äù or ‚Äúwhat are the benefits to conscripted child soldiers?‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúThey were sets of queries and responses to horrible things worded in the most banal, casual way,‚Äù she added.&lt;/p&gt;
    &lt;p&gt;As for the ratings, this worker claims that popularity could take precedence over agreement and objectivity. Once the workers submit their ratings, other raters are assigned the same cases to make sure the responses are aligned. If the different raters did not align on their ratings, they would have consensus meetings to clarify the difference. ‚ÄúWhat this means in reality is the more domineering of the two bullied the other into changing their answers,‚Äù she said.&lt;/p&gt;
    &lt;p&gt;Researchers say that, while this collaborative model can improve accuracy, it is not without drawbacks. ‚ÄúSocial dynamics play a role,‚Äù said Antonio Casilli, a sociologist at the Polytechnic Institute of Paris who studies the human contributors to artificial intelligence. ‚ÄúTypically those with stronger cultural capital or those with greater motivation may sway the group‚Äôs decision, potentially skewing results.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;Loosening the guardrails on hate speech&lt;/head&gt;
    &lt;p&gt;In May 2024, Google launched AI Overviews ‚Äì a feature that scans the web and presents a summed-up, AI-generated response on top. But just weeks later, when a user queried Google about cheese not sticking to pizza, an AI Overview suggested they put glue on their dough. Another suggested users eat rocks. Google called these questions ‚Äúedge cases‚Äù, but the incidents elicited public ridicule nonetheless. Google scrambled to manually remove the ‚Äúweird‚Äù AI responses.&lt;/p&gt;
    &lt;p&gt;‚ÄúHonestly, those of us who‚Äôve been working on the model weren‚Äôt really that surprised,‚Äù said another GlobalLogic worker, who has been on the super rater team for almost two years now, requesting anonymity. ‚ÄúWe‚Äôve seen a lot of crazy stuff that probably doesn‚Äôt go out to the public from these models.‚Äù He remembers there was an immediate focus on ‚Äúquality‚Äù after this incident because Google was ‚Äúreally upset about this‚Äù.&lt;/p&gt;
    &lt;p&gt;But this quest for quality didn‚Äôt last too long.&lt;/p&gt;
    &lt;p&gt;Rebecca Jackson-Artis, a seasoned writer, joined GlobalLogic from North Carolina in fall 2024. With less than one week of training on how to edit and rate responses by Google‚Äôs AI products, she was thrown into the mix of the work, unsure of how to handle the tasks. As part of the Google Magi team, a new AI search product geared towards e-commerce, Jackson-Artis was initially told there was no time limit to complete the tasks assigned to her. Days later, though, she was given the opposite instruction, she said.&lt;/p&gt;
    &lt;p&gt;‚ÄúAt first they told [me]: ‚ÄòDon‚Äôt worry about time ‚Äì it‚Äôs quality versus quantity,‚Äô‚Äù she said.&lt;/p&gt;
    &lt;p&gt;But before long, she was pulled up for taking too much time to complete her tasks. ‚ÄúI was trying to get things right and really understand and learn it, [but] was getting hounded by leaders [asking], ‚ÄòWhy aren‚Äôt you getting this done? You‚Äôve been working on this for an hour.‚Äô‚Äù&lt;/p&gt;
    &lt;p&gt;Two months later, Jackson-Artis was called into a meeting with one of her supervisors, questioned about her productivity, and was asked to ‚Äújust get the numbers done‚Äù and not worry about what she‚Äôs ‚Äúputting out there‚Äù, she said. By this point, Jackson-Artis was not just fact-checking and rating the AI‚Äôs outputs, but was also entering information into the model, she said. The topics ranged widely ‚Äì from health and finance to housing and child development.&lt;/p&gt;
    &lt;p&gt;One work day, her task was to enter details on chemotherapy options for bladder cancer, which haunted her because she wasn‚Äôt an expert on the subject.&lt;/p&gt;
    &lt;p&gt;‚ÄúI pictured a person sitting in their car finding out that they have bladder cancer and googling what I‚Äôm editing,‚Äù she said.&lt;/p&gt;
    &lt;p&gt;In December, Google sent an internal guideline to its contractors working on Gemini that they were no longer allowed to ‚Äúskip‚Äù prompts for lack of domain expertise, including on healthcare topics, which they were allowed to do previously, according to a TechCrunch report. Instead, they were told to rate parts of the prompt they understood and flag with a note that they don‚Äôt have knowledge in that area.&lt;/p&gt;
    &lt;p&gt;Another super rater based on the US west coast feels he gets several questions a day that he‚Äôs not qualified to handle. Just recently, he was tasked with two queries ‚Äì one on astrophysics and the other on math ‚Äì of which he said he had ‚Äúno knowledge‚Äù and yet was told to check the accuracy.&lt;/p&gt;
    &lt;p&gt;Earlier this year, Sawyer noticed a further loosening of guardrails: responses that were not OK last year became ‚Äúperfectly permissible‚Äù this year. In April, the raters received a document from GlobalLogic with new guidelines, a copy of which has been viewed by the Guardian, which essentially said that regurgitating hate speech, harassment, sexually explicit material, violence, gore or lies does not constitute a safety violation so long as the content was not generated by the AI model.&lt;/p&gt;
    &lt;p&gt;‚ÄúIt used to be that the model could not say racial slurs whatsoever. In February, that changed, and now, as long as the user uses a racial slur, the model can repeat it, but it can‚Äôt generate it,‚Äù said Sawyer. ‚ÄúIt can replicate harassing speech, sexism, stereotypes, things like that. It can replicate pornographic material as long as the user has input it; it can‚Äôt generate that material itself.‚Äù&lt;/p&gt;
    &lt;p&gt;Google said in a statement that its AI policies have not changed with regards to hate speech. In December 2024, however, the company introduced a clause to its prohibited use policy for generative AI that would allow for exceptions ‚Äúwhere harms are outweighed by substantial benefits to the public‚Äù, such as art or education. The update, which aligns with the timeline of the document and Sawyer‚Äôs account, seems to codify the distinction between generating hate speech and referencing or repeating it for a beneficial purpose. Such context may not be available to a rater.&lt;/p&gt;
    &lt;p&gt;Dinika said he‚Äôs seen this pattern time and again where safety is only prioritized until it slows the race for market dominance. Human workers are often left to clean up the mess after a half-finished system is released. ‚ÄúSpeed eclipses ethics,‚Äù he said. ‚ÄúThe AI safety promise collapses the moment safety threatens profit.‚Äù&lt;/p&gt;
    &lt;p&gt;Though the AI industry is booming, AI raters do not enjoy strong job security. Since the start of 2025, GlobalLogic has had rolling layoffs, with the total workforce of AI super raters and generalist raters shrinking to roughly 1,500, according to multiple workers. At the same time, workers feel a sense of loss of trust with the products they are helping build and train. Most workers said they avoid using LLMs or use extensions to block AI summaries because they now know how it‚Äôs built. Many also discourage their family and friends from using it, for the same reason.&lt;/p&gt;
    &lt;p&gt;‚ÄúI just want people to know that AI is being sold as this tech magic ‚Äì that‚Äôs why there‚Äôs a little sparkle symbol next to an AI response,‚Äù said Sawyer. ‚ÄúBut it‚Äôs not. It‚Äôs built on the backs of overworked, underpaid human beings.‚Äù&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45231239</guid></item><item><title>A store that generates products from anything you type in search</title><link>https://anycrap.shop/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45231378</guid></item><item><title>My First Impressions of Gleam</title><link>https://mtlynch.io/notes/gleam-first-impressions/</link><description>&lt;doc fingerprint="7c882e31ab6d3836"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;My First Impressions of Gleam&lt;/head&gt;
    &lt;p&gt;I‚Äôm looking for a new programming language to learn this year, and Gleam looks like the most fun. It‚Äôs an Elixir-like language that supports static typing.&lt;/p&gt;
    &lt;p&gt;I read the language tour, and it made sense to me, but I need to build something before I can judge a programming language well.&lt;/p&gt;
    &lt;p&gt;I‚Äôm sharing some notes on my first few hours using Gleam in case they‚Äôre helpful to others learning Gleam or to the team developing the language.&lt;/p&gt;
    &lt;head rend="h2"&gt;My project: Parsing old AIM logs üîóÔ∏é&lt;/head&gt;
    &lt;p&gt;I used AOL Instant Messenger from about 1999 to 2007. For most of that time, I used AIM clients that logged my conversations, but they varied in formats. Most of the log formats are XML or HTML, which make re-reading those logs a pain.&lt;/p&gt;
    &lt;p&gt;The simplest AIM logs are the plaintext logs, which look like this:&lt;/p&gt;
    &lt;code&gt;Session Start (DumbAIMScreenName:Jane): Mon Sep 12 18:44:17 2005
[18:44] Jane: hi
[18:55] Me: hey whats up
Session Close (Jane): Mon Sep 12 18:56:02 2005
&lt;/code&gt;
    &lt;p&gt;Every decade or so, I try writing a universal AIM log parser to get all of my old logs into a consistent, readable format. Unfortunately, I always get bored and give up partway through. My last attempt was seven years ago, when I tried doing it in Python 2.7.&lt;/p&gt;
    &lt;p&gt;Parsing logs is a great match for Gleam because some parts of the project are easy (e.g., parsing the plaintext logs), so I can do the easy parts while I get the hang of Gleam as a language and gradually build up to the harder log formats and adding a web frontend.&lt;/p&gt;
    &lt;p&gt;I‚Äôve also heard that functional languages lend themselves especially well to parsing tasks, and I‚Äôve never understood why, so it‚Äôs a good opportunity to learn.&lt;/p&gt;
    &lt;head rend="h2"&gt;My background in programming languages üîóÔ∏é&lt;/head&gt;
    &lt;p&gt;I‚Äôve been a programmer for 20 years, but I‚Äôm no language design connoisseur. I‚Äôm sharing things about Gleam I find unintuitive or difficult to work with, but they‚Äôre not language critiques, just candid reactions.&lt;/p&gt;
    &lt;p&gt;I‚Äôve never worked in a langauge that‚Äôs designed for functional programming. The closest would be JavaScript. The languages I know best are Go and Python.&lt;/p&gt;
    &lt;head rend="h2"&gt;How do I parse command-line args? üîóÔ∏é&lt;/head&gt;
    &lt;p&gt;The first thing I wanted to do was figure out how to parse a command-line argument so I could call my app like this:&lt;/p&gt;
    &lt;code&gt;./log-parser ~/logs/aim/plaintext
&lt;/code&gt;
    &lt;p&gt;But there‚Äôs no Gleam standard library module for reading command-line arguments. I found glint, and it felt super complicated for just reading one command-line argument. Then, I realized there‚Äôs a simpler third-party library called argv.&lt;/p&gt;
    &lt;p&gt;I can parse the command-line argument like this:&lt;/p&gt;
    &lt;code&gt;pub fn main() {
  case argv.load().arguments {
    [path] -&amp;gt; io.println("command-line arg is " &amp;lt;&amp;gt; path)
    _ -&amp;gt; io.println("Usage: gleam run &amp;lt;directory_path&amp;gt;")
  }
}
&lt;/code&gt;
    &lt;code&gt;$ gleam run ~/whatever
   Compiled in 0.01s
    Running log_parser.main
command-line arg is /home/mike/whatever
&lt;/code&gt;
    &lt;p&gt;Cool, easy enough!&lt;/p&gt;
    &lt;head rend="h2"&gt;What does &lt;code&gt;gleam build&lt;/code&gt; do? üîóÔ∏é&lt;/head&gt;
    &lt;p&gt;I got my program to run with &lt;code&gt;gleam run&lt;/code&gt;, but I was curious if I could compile an executable like &lt;code&gt;go build&lt;/code&gt; or &lt;code&gt;zig build&lt;/code&gt; does.&lt;/p&gt;
    &lt;code&gt;$ gleam build
   Compiled in 0.01s
&lt;/code&gt;
    &lt;p&gt;Hmm, compiled what? I couldn‚Äôt see a binary anywhere.&lt;/p&gt;
    &lt;p&gt;The documentation for &lt;code&gt;gleam build&lt;/code&gt; just says ‚ÄúBuild the project‚Äù but doesn‚Äôt explain what it builds or where it stores the build artifact.&lt;/p&gt;
    &lt;p&gt;There‚Äôs a &lt;code&gt;build&lt;/code&gt; directory, but it doesn‚Äôt produce an obvious executable.&lt;/p&gt;
    &lt;code&gt;$ rm -rf build &amp;amp;&amp;amp; gleam build
Downloading packages
 Downloaded 5 packages in 0.00s
  Compiling argv
  Compiling gleam_stdlib
  Compiling filepath
  Compiling gleeunit
  Compiling simplifile
  Compiling log_parser
   Compiled in 0.52s

$ ls -1 build/
dev
gleam-dev-erlang.lock
gleam-dev-javascript.lock
gleam-lsp-erlang.lock
gleam-lsp-javascript.lock
gleam-prod-erlang.lock
gleam-prod-javascript.lock
packages
&lt;/code&gt;
    &lt;p&gt;From poking around, I think the executables are under &lt;code&gt;build/dev/erlang/log_parser/ebin/&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;$ ls -1 build/dev/erlang/log_parser/ebin/
log_parser.app
log_parser.beam
log_parser@@main.beam
log_parser_test.beam
plaintext_logs.beam
plaintext_logs_test.beam
&lt;/code&gt;
    &lt;p&gt;Those appear to be BEAM bytecode, so I can‚Äôt execute them directly. I assume I could get run the BEAM VM manually and execute those files somehow, but that doesn‚Äôt sound appealing.&lt;/p&gt;
    &lt;p&gt;So, I‚Äôll stick to &lt;code&gt;gleam run&lt;/code&gt; to run my app, but I wish &lt;code&gt;gleam build&lt;/code&gt; had a better explanation of what it produced and what the developer can do with it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Let me implement the simplest possible parser üîóÔ∏é&lt;/head&gt;
    &lt;p&gt;To start, I decided to write a function that does basic parsing of plaintext logs.&lt;/p&gt;
    &lt;p&gt;So, I wrote a test with what I wanted.&lt;/p&gt;
    &lt;code&gt;pub fn parse_simple_plaintext_log_test() {
  "
Session Start (DumbAIMScreenName:Jane): Mon Sep 12 18:44:17 2005
[18:44] Jane: hi
[18:55] Me: hey whats up
Session Close (Jane): Mon Sep 12 18:56:02 2005
"
  |&amp;gt; string.trim
  |&amp;gt; plaintext_logs.parse
  |&amp;gt; should.equal(["hi", "hey whats up"])
}
&lt;/code&gt;
    &lt;p&gt;Eventually, I want to parse all the metadata in the conversation, including names, timestamps, and session information. But as a first step, all my function has to do is read an AIM chat log as a string and emit a list of the chat messages as separate strings.&lt;/p&gt;
    &lt;p&gt;That meant my actual function would look like this:&lt;/p&gt;
    &lt;code&gt;pub fn parse(contents: String) -&amp;gt; List(String) {
  // Note: todo is a Gleam language keyword to indicate unfinished code.
  todo
}
&lt;/code&gt;
    &lt;p&gt;Just to get it compiling, I add in a dummy implementation:&lt;/p&gt;
    &lt;code&gt;pub fn parse(contents: String) -&amp;gt; List(String) {
  ["fake", "data"]
}
&lt;/code&gt;
    &lt;p&gt;And I can test it like this:&lt;/p&gt;
    &lt;code&gt;$ gleam test
  Compiling log_parser
warning: Unused variable
  ‚îå‚îÄ /home/mike/code/gleam-log-parser2/src/plaintext_logs.gleam:1:14
  ‚îÇ
1 ‚îÇ pub fn parse(contents: String) -&amp;gt; List(String) {
  ‚îÇ              ^^^^^^^^^^^^^^^^ This variable is never used

Hint: You can ignore it with an underscore: `_contents`.

   Compiled in 0.22s
    Running log_parser_test.main
F
Failures:

  1) plaintext_logs_test.parse_simple_plaintext_log_test: module 'plaintext_logs_test'
     Values were not equal
     expected: ["hi", "hey whats up"]
          got: ["fake", "data"]
     output:

Finished in 0.008 seconds
1 tests, 1 failures
&lt;/code&gt;
    &lt;p&gt;Cool, that‚Äôs what I expected. The test is failing because it‚Äôs returning hardcoded dummy results that don‚Äôt match my test.&lt;/p&gt;
    &lt;head rend="h2"&gt;Adjusting my brain to a functional language üîóÔ∏é&lt;/head&gt;
    &lt;p&gt;Okay, now it‚Äôs time to implement the parsing for real. I need to implement this function:&lt;/p&gt;
    &lt;code&gt;pub fn parse(contents: String) -&amp;gt; List(String) {
  todo
}
&lt;/code&gt;
    &lt;p&gt;At this point, I kind of froze up. It struck me that Gleam excludes so many of the tools I‚Äôm used to in other languages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;There are no &lt;code&gt;if&lt;/code&gt;statements&lt;/item&gt;
      &lt;item&gt;There are no loops&lt;/item&gt;
      &lt;item&gt;There‚Äôs no &lt;code&gt;return&lt;/code&gt;keyword&lt;/item&gt;
      &lt;item&gt;There are no list index accessors&lt;list rend="ul"&gt;&lt;item&gt;e.g., you can‚Äôt access the n-th element of a &lt;code&gt;List&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;e.g., you can‚Äôt access the n-th element of a &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What do I even do? Split the string into tokens and then do something with that?&lt;/p&gt;
    &lt;p&gt;Eventually, I realized for a simple implementation, I wanted to just split the string into lines, so I want to do this:&lt;/p&gt;
    &lt;code&gt;pub fn parse(contents: String) -&amp;gt; List(String) {
  string.split(contents, on: "\n")
}
&lt;/code&gt;
    &lt;p&gt;If I test again, I get this:&lt;/p&gt;
    &lt;code&gt;$ gleam test
  Compiling log_parser
   Compiled in 0.21s
    Running log_parser_test.main
F
Failures:

  1) plaintext_logs_test.parse_simple_plaintext_log_test: module 'plaintext_logs_test'
     Values were not equal
     expected: ["hi", "hey whats up"]
          got: ["Session Start (DumbAIMScreenName:Jane): Mon Sep 12 18:44:17 2005", "[18:44] Jane: hi", "[18:55] Me: hey whats up", "Session Close (Jane): Mon Sep 12 18:56:02 2005"]
     output:

Finished in 0.009 seconds
1 tests, 1 failures
&lt;/code&gt;
    &lt;p&gt;Okay, now I‚Äôm a little closer.&lt;/p&gt;
    &lt;head rend="h2"&gt;How do I iterate over a list in a language with no loops? üîóÔ∏é&lt;/head&gt;
    &lt;p&gt;I turned my logs into a list of lines, but that‚Äôs where I got stuck again.&lt;/p&gt;
    &lt;p&gt;I‚Äôm so used to &lt;code&gt;for&lt;/code&gt; loops that my brain kept thinking, ‚ÄúHow do I do a &lt;code&gt;for&lt;/code&gt; loop to iterate over the elements?‚Äù&lt;/p&gt;
    &lt;p&gt;I realized I needed to call &lt;code&gt;list.map&lt;/code&gt;. I need to define a function that acts on each element of the list.&lt;/p&gt;
    &lt;code&gt;import gleam/list
import gleam/string

fn parse_line(line: String) -&amp;gt; String {
  case line {
    "Session Start" &amp;lt;&amp;gt; _ -&amp;gt; ""
    "Session Close" &amp;lt;&amp;gt; _ -&amp;gt; ""
    line -&amp;gt; line
  }
}

pub fn parse(contents: String) -&amp;gt; List(String) {
  string.split(contents, on: "\n")
  |&amp;gt; list.map(parse_line)
}
&lt;/code&gt;
    &lt;p&gt;This is my first time using pattern matching in any language, and it‚Äôs neat, though it‚Äôs still so unfamiliar that I find it hard to recognize when to use it.&lt;/p&gt;
    &lt;p&gt;Zooming in a bit on the pattern matching, it‚Äôs here:&lt;/p&gt;
    &lt;code&gt;  case line {
    "Session Start" &amp;lt;&amp;gt; _ -&amp;gt; ""
    "Session Close" &amp;lt;&amp;gt; _ -&amp;gt; ""
    line -&amp;gt; line
  }
&lt;/code&gt;
    &lt;p&gt;It evaluates the &lt;code&gt;line&lt;/code&gt; variable and matches it to one of the subsequent patterns within the braces. If the line starts with &lt;code&gt;"Session Start"&lt;/code&gt; (the &lt;code&gt;&amp;lt;&amp;gt;&lt;/code&gt; means the preceding string is a prefix), then Gleam executes the code after the &lt;code&gt;-&amp;gt;&lt;/code&gt;, which in this case is just the empty string. Same for &lt;code&gt;"Session Close"&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;If the line doesn‚Äôt match the &lt;code&gt;"Session Start"&lt;/code&gt; or &lt;code&gt;"Session Close"&lt;/code&gt; patterns, Gleam executes the last line in the &lt;code&gt;case&lt;/code&gt; which just matches any string. In that case, it evaluates to the same string. Meaning &lt;code&gt;"hi"&lt;/code&gt; would evaluate to just &lt;code&gt;"hi"&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;This is where it struck me how strange it feels to not have a &lt;code&gt;return&lt;/code&gt; keyword. In every other language I know, you have to explicitly return a value from a function with a &lt;code&gt;return&lt;/code&gt; keyword, but in Gleam, the return value is just the value from the last line that Gleam executes in the function.&lt;/p&gt;
    &lt;p&gt;If I run my test, I get this:&lt;/p&gt;
    &lt;code&gt;$ gleam test
  Compiling log_parser
   Compiled in 0.22s
    Running log_parser_test.main
F
Failures:

  1) plaintext_logs_test.parse_simple_plaintext_log_test: module 'plaintext_logs_test'
     Values were not equal
     expected: ["hi", "hey whats up"]
          got: ["", "[18:44] Jane: hi", "[18:55] Me: hey whats up", ""]
     output:

Finished in 0.009 seconds
1 tests, 1 failures
&lt;/code&gt;
    &lt;p&gt;Again, this is what I expected, and I‚Äôm a bit closer to my goal.&lt;/p&gt;
    &lt;p&gt;I‚Äôve converted the &lt;code&gt;"Session Start"&lt;/code&gt; and &lt;code&gt;"Session End"&lt;/code&gt; lines to empty strings, and the middle two elements of the list are the lines that have AIM messages in them.&lt;/p&gt;
    &lt;p&gt;The remaining work is:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Strip out the time and sender parts of the log lines.&lt;/item&gt;
      &lt;item&gt;Filter out empty strings.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Scraping an AIM message from a line üîóÔ∏é&lt;/head&gt;
    &lt;p&gt;At this point, I have a string like this:&lt;/p&gt;
    &lt;code&gt;[18:55] Me: hey whats up
&lt;/code&gt;
    &lt;p&gt;And I need to extract just the portion after the sender‚Äôs name to this:&lt;/p&gt;
    &lt;code&gt;hey whats up
&lt;/code&gt;
    &lt;p&gt;My instinct is to use a string split function and split on the &lt;code&gt;:&lt;/code&gt; character. I see that there‚Äôs &lt;code&gt;string.split&lt;/code&gt; which returns &lt;code&gt;List(String)&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;There‚Äôs also a &lt;code&gt;string.split_once&lt;/code&gt; function, which should work because I can split once on &lt;code&gt;: &lt;/code&gt;(note the trailing space after the colon).&lt;/p&gt;
    &lt;p&gt;The problem is that &lt;code&gt;split_once&lt;/code&gt; returns &lt;code&gt;Result(#(String, String), Nil)&lt;/code&gt;, a type that feels scarier to me. It‚Äôs a two-tuple wrapped in a &lt;code&gt;Result&lt;/code&gt;, which means that the function can return an error on failure. It‚Äôs confusing that &lt;code&gt;split_once&lt;/code&gt; can fail whereas &lt;code&gt;split&lt;/code&gt; cannot, so for simplicity, I‚Äôll go with &lt;code&gt;split&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;fn parse_line(line: String) -&amp;gt; String {
  case line {
    "Session Start" &amp;lt;&amp;gt; _ -&amp;gt; ""
    "Session Close" &amp;lt;&amp;gt; _ -&amp;gt; ""
    line -&amp;gt; {
      echo string.split(line, on: ": ")
      todo
    }
  }
}
&lt;/code&gt;
    &lt;p&gt;If I run my test, I get this:&lt;/p&gt;
    &lt;code&gt;$ gleam test
warning: Todo found
   ‚îå‚îÄ /home/mike/code/gleam-log-parser/src/plaintext_logs.gleam:10:7
   ‚îÇ
10 ‚îÇ       todo
   ‚îÇ       ^^^^ This code is incomplete

This code will crash if it is run. Be sure to finish it before
running your program.

Hint: I think its type is `String`.


   Compiled in 0.01s
    Running log_parser_test.main
src/plaintext_logs.gleam:9
["[18:44] Jane", "hi"]
&lt;/code&gt;
    &lt;p&gt;Good. That‚Äôs doing what I want. I‚Äôm successfully isolating the &lt;code&gt;"hi"&lt;/code&gt; part, so now I just have to return it.&lt;/p&gt;
    &lt;head rend="h2"&gt;How do I access the last element of a list? üîóÔ∏é&lt;/head&gt;
    &lt;p&gt;At this point, I feel close to victory. I‚Äôve converted the line to a list of strings, and I know the string I want is the last element of the list, but how do I grab it?&lt;/p&gt;
    &lt;p&gt;In most other languages, I‚Äôd just say &lt;code&gt;line_parts[1]&lt;/code&gt;, but Gleam‚Äôs lists have no accessors by index.&lt;/p&gt;
    &lt;p&gt;Looking at the &lt;code&gt;gleam/list&lt;/code&gt; module, I see a &lt;code&gt;list.last&lt;/code&gt; function, so I try that:&lt;/p&gt;
    &lt;code&gt;fn parse_line(line: String) -&amp;gt; String {
  case line {
    "Session Start" &amp;lt;&amp;gt; _ -&amp;gt; ""
    "Session Close" &amp;lt;&amp;gt; _ -&amp;gt; ""
    line -&amp;gt; {
       string.split(line, on: ": ")
       |&amp;gt; list.last
       |&amp;gt; echo
       |&amp;gt; todo
    }
  }
}
&lt;/code&gt;
    &lt;p&gt;If I run that, I get:&lt;/p&gt;
    &lt;code&gt;$ gleam test
  Compiling log_parser
warning: Todo found
   ‚îå‚îÄ /home/mike/code/gleam-log-parser/src/plaintext_logs.gleam:12:11
   ‚îÇ
12 ‚îÇ        |&amp;gt; todo
   ‚îÇ           ^^^^ This code is incomplete

This code will crash if it is run. Be sure to finish it before
running your program.

Hint: I think its type is `fn(Result(String, Nil)) -&amp;gt; String`.


   Compiled in 0.24s
    Running log_parser_test.main
src/plaintext_logs.gleam:11
Ok("hi")
&lt;/code&gt;
    &lt;p&gt;A bit closer! I‚Äôve extracted the last element of the list to find &lt;code&gt;"hi"&lt;/code&gt;, but now it‚Äôs wrapped in a &lt;code&gt;Result&lt;/code&gt; type.&lt;/p&gt;
    &lt;p&gt;I can unwrap it with &lt;code&gt;result.unwrap&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;fn parse_line(line: String) -&amp;gt; String {
  case line {
    "Session Start" &amp;lt;&amp;gt; _ -&amp;gt; ""
    "Session Close" &amp;lt;&amp;gt; _ -&amp;gt; ""
    line -&amp;gt; {
       string.split(line, on: ": ")
       |&amp;gt; list.last
       |&amp;gt; result.unwrap("")
    }
  }
}
&lt;/code&gt;
    &lt;p&gt;Re-running &lt;code&gt;gleam test&lt;/code&gt; yields:&lt;/p&gt;
    &lt;code&gt;$ gleam test
  Compiling log_parser
   Compiled in 0.22s
    Running log_parser_test.main
F
Failures:

  1) plaintext_logs_test.parse_simple_plaintext_log_test: module 'plaintext_logs_test'
     Values were not equal
     expected: ["hi", "hey whats up"]
          got: ["", "hi", "hey whats up", ""]
     output:

Finished in 0.008 seconds
1 tests, 1 failures
&lt;/code&gt;
    &lt;p&gt;Great! That did what I wanted. I reduced the messages lines to just the contents of the messages.&lt;/p&gt;
    &lt;head rend="h2"&gt;Filtering out empty strings üîóÔ∏é&lt;/head&gt;
    &lt;p&gt;The only thing that‚Äôs left is to filter the empty strings out of the list, which is straightforward enough with &lt;code&gt;list.filter&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;pub fn parse(contents: String) -&amp;gt; List(String) {
  string.split(contents, on: "\n")
  |&amp;gt; list.map(parse_line)
  |&amp;gt; list.filter(fn(s) { !string.is_empty(s) })
}
&lt;/code&gt;
    &lt;p&gt;And I re-run the tests:&lt;/p&gt;
    &lt;code&gt;$ gleam test
  Compiling log_parser
   Compiled in 0.22s
    Running log_parser_test.main
.
Finished in 0.007 seconds
1 tests, 0 failures
&lt;/code&gt;
    &lt;p&gt;Voil√†! The tests now pass!&lt;/p&gt;
    &lt;head rend="h2"&gt;Tidying up string splitting üîóÔ∏é&lt;/head&gt;
    &lt;p&gt;My tests are now passing, so theoretically, I‚Äôve achieved my initial goal.&lt;/p&gt;
    &lt;p&gt;I could declare victory and call it a day. Or, I could refactor!&lt;/p&gt;
    &lt;p&gt;I‚Äôll refactor.&lt;/p&gt;
    &lt;p&gt;I feel somewhat ashamed of my string splitting logic, as it didn‚Äôt feel like idiomatic Gleam. Can I do it without getting into result unwrapping?&lt;/p&gt;
    &lt;p&gt;Re-reading it, I realize I can solve it with this newfangled pattern matching thing. I know that the string will split into a list with two elements, so I can create a pattern for a two-element list:&lt;/p&gt;
    &lt;code&gt;fn parse_line(line: String) -&amp;gt; String {
  case line {
    "Session Start" &amp;lt;&amp;gt; _ -&amp;gt; ""
    "Session Close" &amp;lt;&amp;gt; _ -&amp;gt; ""
    line -&amp;gt; {
       case string.split(line, on: ": ") {
          [_, message] -&amp;gt; message
          _ -&amp;gt; ""
       }
    }
  }
}
&lt;/code&gt;
    &lt;p&gt;That feels a little more elegant than calling &lt;code&gt;result.last&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Can I tidy this up further? I avoided &lt;code&gt;string.split_once&lt;/code&gt; because the type was too confusing, but it‚Äôs probably the better option if I expect only one split, so what does that look like?&lt;/p&gt;
    &lt;code&gt;fn parse_line(line: String) -&amp;gt; String {
  case line {
    "Session Start" &amp;lt;&amp;gt; _ -&amp;gt; ""
    "Session Close" &amp;lt;&amp;gt; _ -&amp;gt; ""
    line -&amp;gt; {
       echo string.split_once(line, on: ": ")
       todo
    }
  }
}
&lt;/code&gt;
    &lt;p&gt;To inspect the data, I run my test again:&lt;/p&gt;
    &lt;code&gt;$ gleam test
[...]
src/plaintext_logs.gleam:9
Ok(#("[18:44] Jane", "hi"))
&lt;/code&gt;
    &lt;p&gt;Okay, that doesn‚Äôt look as scary as I thought. Even though my first instinct is to unwrap the error and access the last element in the tuple (which actually is easy for tuples, just not lists), I know at this point that there‚Äôs probably a pattern-matchy way. And there is:&lt;/p&gt;
    &lt;code&gt;fn parse_line(line: String) -&amp;gt; String {
  case line {
    "Session Start" &amp;lt;&amp;gt; _ -&amp;gt; ""
    "Session Close" &amp;lt;&amp;gt; _ -&amp;gt; ""
    line -&amp;gt; {
       case string.split_once(line, on: ": ") {
        Ok(#(_, message)) -&amp;gt; message
        _ -&amp;gt; ""
       }
    }
  }
}
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;Ok(#(_, message))&lt;/code&gt; pattern will match a successful result from &lt;code&gt;split_once&lt;/code&gt;, which is a two-tuple of &lt;code&gt;String&lt;/code&gt; wrapped in an &lt;code&gt;Ok&lt;/code&gt; result. The other &lt;code&gt;case&lt;/code&gt; option is the catchall that returns an empty string.&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting rid of the empty string hack üîóÔ∏é&lt;/head&gt;
    &lt;p&gt;One of the compelling features of Gleam for me is its static typing, so it feels hacky that I‚Äôm abusing the empty string to represent a lack of message on a particular line. Can I use the type system instead of using empty strings as sentinel values?&lt;/p&gt;
    &lt;p&gt;The pattern in Gleam for indicating that something might fail but the failure isn‚Äôt necessarily an error is &lt;code&gt;Result(&amp;lt;type&amp;gt;, Nil)&lt;/code&gt;, so let me try to rewrite it that way:&lt;/p&gt;
    &lt;code&gt;import gleam/list
import gleam/result
import gleam/string

fn parse_line(line: String) -&amp;gt; Result(String, Nil) {
  case line {
    "Session Start" &amp;lt;&amp;gt; _ -&amp;gt; Error(Nil)
    "Session Close" &amp;lt;&amp;gt; _ -&amp;gt; Error(Nil)
    line -&amp;gt; {
       case string.split_once(line, on: ": ") {
        Ok(#(_, message)) -&amp;gt; Ok(message)
        _ -&amp;gt; Error(Nil)
       }
    }
  }
}

pub fn parse(contents: String) -&amp;gt; List(String) {
  string.split(contents, on: "\n")
  |&amp;gt; list.map(parse_line)
  |&amp;gt; result.values
}
&lt;/code&gt;
    &lt;p&gt;Great! I like being more explicit that the lines without messages return &lt;code&gt;Error(Nil)&lt;/code&gt; rather than an empty string. Also, &lt;code&gt;result.values&lt;/code&gt; is more succinct for filtering empty lines than the previous &lt;code&gt;list.filter(fn(s) { !string.is_empty(s) })&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;Overall reflections üîóÔ∏é&lt;/head&gt;
    &lt;p&gt;After spending a few hours with Gleam, I‚Äôm enjoying it. It pushes me out of my comfort zone the right amount where I feel like I‚Äôm learning new ways of thinking about programming but not so much that I‚Äôm too overwhelmed to learn anything.&lt;/p&gt;
    &lt;p&gt;The biggest downside I‚Äôm finding with Gleam is that it‚Äôs a young language with a relatively small team. It just turned six years old, but it looks like the founder was working on it solo until a year ago. There are now a handful of core maintainers, but I don‚Äôt know if any of them work on Gleam full-time, so the ecosystem is a bit limited. I‚Äôm looking ahead to parsing other log formats that are in HTML and XML, and there are Gleam HTML and XML parsers, but they don‚Äôt seem widely used, so I‚Äôm not sure how well they‚Äôll work.&lt;/p&gt;
    &lt;head rend="h3"&gt;Love: Pipelines üîóÔ∏é&lt;/head&gt;
    &lt;p&gt;I love love love Gleam‚Äôs pipeline syntax. You can see me using it in the test with the &lt;code&gt;|&amp;gt;&lt;/code&gt; characters:&lt;/p&gt;
    &lt;code&gt; "..."
  |&amp;gt; string.trim
  |&amp;gt; plaintext_logs.parse
  |&amp;gt; should.equal(["hi", "hey whats up"])
&lt;/code&gt;
    &lt;p&gt;The non-pipeline equivalent of the test would look like this:&lt;/p&gt;
    &lt;code&gt;pub fn parse_simple_plaintext_log_test() {
  let input = "..."
  let trimmed = string.trim(input)
  let parsed = plaintext_logs.parse(trimmed)

  should.equal(parsed, ["hi", "hey whats up"])
}
&lt;/code&gt;
    &lt;p&gt;It looks like wet garbage by comparison.&lt;/p&gt;
    &lt;p&gt;Now that I‚Äôve seen pipelines, they feel so obvious and conspicuously missing in every other programming language I use.&lt;/p&gt;
    &lt;p&gt;I‚Äôve enjoyed pipelining in bash, but it never occurred to me how strange it is that other programming languages never adopted it.&lt;/p&gt;
    &lt;head rend="h3"&gt;Like: Example-centric documentation üîóÔ∏é&lt;/head&gt;
    &lt;p&gt;The Gleam documentation is a bit terse, but I like that it‚Äôs so example-heavy.&lt;/p&gt;
    &lt;p&gt;I learn best by reading examples, so I appreciate that so much of the Gleam standard library is documented with examples showing simple usage of each API function.&lt;/p&gt;
    &lt;head rend="h3"&gt;Like: Built-in unused symbol warnings üîóÔ∏é&lt;/head&gt;
    &lt;p&gt;I like that the Gleam compiler natively warns about unused functions, variables, and imports. And I like that these are warnings rather than errors.&lt;/p&gt;
    &lt;p&gt;In Go, I get frustrated during debugging when I temporarily comment something out and then the compiler stubbornly refuses to do anything until I fix the stupid import, which I then have to un-fix when I finish whatever I was debugging.&lt;/p&gt;
    &lt;head rend="h3"&gt;Like: &lt;code&gt;todo&lt;/code&gt; keyword üîóÔ∏é&lt;/head&gt;
    &lt;p&gt;One of my favorite dumb programming jokes happened at my first programming job about 15 years ago. On a group email thread with several C++ developers, my friend shared a hot tip about C++ development.&lt;/p&gt;
    &lt;p&gt;He said that if we were ever got fed up with arcane C++ compilation errors, we could just add a special line to our source code, and then even invalid C++ code would compile successfully:&lt;/p&gt;
    &lt;code&gt;#pragma always_compile
&lt;/code&gt;
    &lt;p&gt;Spoiler alert: it‚Äôs not a real C++ preprocessor directive.&lt;/p&gt;
    &lt;p&gt;But I‚Äôve found myself occasionally wishing languages had something like this when I‚Äôm in the middle of development and don‚Äôt care about whatever bugs the compiler is trying to protect me from.&lt;/p&gt;
    &lt;p&gt;Gleam‚Äôs &lt;code&gt;todo&lt;/code&gt; is almost like a &lt;code&gt;#pragma always_compile&lt;/code&gt;. Even if your code is invalid, the Gleam compiler just says, ‚ÄúOkay, fine. I‚Äôll run it anyway.‚Äù&lt;/p&gt;
    &lt;p&gt;You can see this when I was in the middle of implementing &lt;code&gt;parse_line&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;fn parse_line(line: String) -&amp;gt; String {
  case line {
    "Session Start" &amp;lt;&amp;gt; _ -&amp;gt; ""
    "Session Close" &amp;lt;&amp;gt; _ -&amp;gt; ""
    line -&amp;gt; {
      echo string.split(line, on: ": ")
      todo
    }
  }
}
&lt;/code&gt;
    &lt;p&gt;If I take out the &lt;code&gt;todo&lt;/code&gt;, Gleam refuses to run the code at all:&lt;/p&gt;
    &lt;code&gt;$ gleam test
  Compiling log_parser
error: Type mismatch
   ‚îå‚îÄ /home/mike/code/gleam-log-parser/src/plaintext_logs.gleam:8:5
   ‚îÇ
 8 ‚îÇ ‚ï≠     line -&amp;gt; {
 9 ‚îÇ ‚îÇ       echo string.split(line, on: ": ")
10 ‚îÇ ‚îÇ     }
   ‚îÇ ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ^

This case clause was found to return a different type than the previous
one, but all case clauses must return the same type.

Expected type:

    String

Found type:

    List(String)
&lt;/code&gt;
    &lt;p&gt;Right, I‚Äôm returning an incorrect type, so why would the compiler cooperate with me?&lt;/p&gt;
    &lt;p&gt;But adding &lt;code&gt;todo&lt;/code&gt; lets me run the function anyway, which helps me understand what the code is doing even though I haven‚Äôt finished implementing it:&lt;/p&gt;
    &lt;code&gt;$ gleam test
warning: Todo found
   ‚îå‚îÄ /home/mike/code/gleam-log-parser/src/plaintext_logs.gleam:10:7
   ‚îÇ
10 ‚îÇ       todo
   ‚îÇ       ^^^^ This code is incomplete

This code will crash if it is run. Be sure to finish it before
running your program.

Hint: I think its type is `String`.


  Compiling log_parser
   Compiled in 0.21s
    Running log_parser_test.main
src/plaintext_logs.gleam:9
["[18:44] Jane", "hi"]
F
[...]
Finished in 0.007 seconds
1 tests, 1 failures
&lt;/code&gt;
    &lt;head rend="h3"&gt;Like: Pattern matching üîóÔ∏é&lt;/head&gt;
    &lt;p&gt;I find pattern matching elegant and concise, though it‚Äôs the part of Gleam I find hardest to adjust to. It feels so different from procedural style of programming I‚Äôm accustomed to in other languages I know.&lt;/p&gt;
    &lt;p&gt;The downside is that I have a hard time recognizing when pattern matching is the right tool, and I also find pattern matching harder to read. But I think that‚Äôs just inexperience, and I think with more practice, I‚Äôll be able to think in pattern matching.&lt;/p&gt;
    &lt;head rend="h3"&gt;Dislike: Error handling üîóÔ∏é&lt;/head&gt;
    &lt;p&gt;I find Gleam‚Äôs error handling pretty awkward, especially because errors ruin the beauty of nice, tidy pipelines.&lt;/p&gt;
    &lt;p&gt;For example, if I had a string processing pipeline like this:&lt;/p&gt;
    &lt;code&gt;string.split(line, on: "-")
|&amp;gt; list.last
|&amp;gt; result.unwrap("") // Ugly!
|&amp;gt; string.uppercase
&lt;/code&gt;
    &lt;p&gt;That &lt;code&gt;result.unwrap&lt;/code&gt; line feels so ugly and out of place to me. I wish the syntax was like this:&lt;/p&gt;
    &lt;code&gt;string.split(line, on: ": ")
|&amp;gt; try list.last
|&amp;gt; string.uppercase
|&amp;gt; Ok
&lt;/code&gt;
    &lt;p&gt;Where &lt;code&gt;try&lt;/code&gt; causes the function to return an error, kind of like in Zig.&lt;/p&gt;
    &lt;head rend="h3"&gt;Dislike: Small core language üîóÔ∏é&lt;/head&gt;
    &lt;p&gt;I don‚Äôt know if this is a long-term design choice or if it‚Äôs just small for now because it‚Äôs an indie-developed language, but the first thing about Gleam that stood out to me is how few built-in features there are.&lt;/p&gt;
    &lt;p&gt;For example, there‚Äôs no built-in feature for iterating over the elements of a &lt;code&gt;List&lt;/code&gt; type, and the type itself doesn‚Äôt expose a function to iterate it, so you have to use the &lt;code&gt;gleam/list&lt;/code&gt; module in the standard library.&lt;/p&gt;
    &lt;p&gt;Similarly, if a function can fail, it returns a &lt;code&gt;Result&lt;/code&gt; type, and there are no built-in functions for handling a &lt;code&gt;Result&lt;/code&gt;, so you have to use the &lt;code&gt;gleam/result&lt;/code&gt; module to check if the function succeeded.&lt;/p&gt;
    &lt;p&gt;To me, that functionality feels so core to the language that it would be part of the language itself, not the standard library.&lt;/p&gt;
    &lt;head rend="h3"&gt;Dislike: Limited standard library üîóÔ∏é&lt;/head&gt;
    &lt;p&gt;In addition to the language feeling small, the standard library feels pretty limited as well.&lt;/p&gt;
    &lt;p&gt;There are currently only 19 modules in the Gleam standard library. Conspicuously absent are modules for working with the filesystem (the de facto standard seems to be the third-party simplifile module).&lt;/p&gt;
    &lt;p&gt;For comparison, the standard libraries for Python and Go each have about 250 modules. Although, in fairness, those languages have about 1000x the resources as Gleam.&lt;/p&gt;
    &lt;head rend="h2"&gt;Source code üîóÔ∏é&lt;/head&gt;
    &lt;p&gt;The source code for this project is available on Codeberg:&lt;/p&gt;
    &lt;p&gt;Commit 291e6d is the version that matches this blog post.&lt;/p&gt;
    &lt;p&gt;Thanks to Isaac Harris-Holt for helpful feedback on this post.&lt;/p&gt;
    &lt;head rend="h2"&gt;Read My Book&lt;/head&gt;
    &lt;p&gt;I'm writing a book of simple techniques to help developers improve their writing.&lt;/p&gt;
    &lt;p&gt;My book will teach you how to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Create clear and pleasant software tutorials&lt;/item&gt;
      &lt;item&gt;Attract readers and customers through blogging&lt;/item&gt;
      &lt;item&gt;Write effective emails&lt;/item&gt;
      &lt;item&gt;Minimize pain in writing design documents&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Be the first to know when I post cool stuff&lt;/head&gt;
    &lt;p&gt;Subscribe to get my latest posts by email.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45231852</guid></item><item><title>Japan sets record of nearly 100k people aged over 100</title><link>https://www.bbc.com/news/articles/cd07nljlyv0o</link><description>&lt;doc fingerprint="6ee893ba9e23bf7f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Japan sets record of nearly 100,000 people aged over 100&lt;/head&gt;
    &lt;p&gt;The number of people in Japan aged 100 or older has risen to a record high of nearly 100,000, its government has announced.&lt;/p&gt;
    &lt;p&gt;Setting a new record for the 55th year in a row, the number of centenarians in Japan was 99,763 as of September, the health ministry said on Friday. Of that total, women accounted for an overwhelming 88%.&lt;/p&gt;
    &lt;p&gt;Japan has the world's longest life expectancy, and is known for often being home to the world's oldest living person - though some studies contest the actual number of centenarians worldwide.&lt;/p&gt;
    &lt;p&gt;It is also one of the fastest ageing societies, with residents often having a healthier diet but a low birth rate.&lt;/p&gt;
    &lt;p&gt;The oldest person in Japan is 114-year-old Shigeko Kagawa, a woman from Yamatokoriyama, a suburb of the city Nara. Meanwhile, the oldest man is Kiyotaka Mizuno, 111, from the coastal city of Iwata.&lt;/p&gt;
    &lt;p&gt;Health minister Takamaro Fukoka congratulated the 87,784 female and 11,979 male centenarians on their longevity and expressed his "gratitude for their many years of contributions to the development of society".&lt;/p&gt;
    &lt;p&gt;The figures were released ahead of Japan's Elderly Day on 15 September, a national holiday where new centenarians receive a congratulatory letter and silver cup from the prime minister. This year, 52,310 individuals were eligible, the health ministry said.&lt;/p&gt;
    &lt;p&gt;In the 1960s, Japan's population had the lowest proportion of people aged over 100 of any G7 country - but that has changed remarkably in the decades since.&lt;/p&gt;
    &lt;p&gt;When its government began the centenarian survey in 1963, there were 153 people aged 100 or over.&lt;/p&gt;
    &lt;p&gt;That figure rose to 1,000 in 1981 and stood at 10,000 by 1998.&lt;/p&gt;
    &lt;p&gt;The higher life expectancy is mainly attributed to fewer deaths from heart disease and common forms of cancer, in particular breast and prostate cancer.&lt;/p&gt;
    &lt;p&gt;Japan has low rates of obesity, a major contributing factor to both diseases, thanks to diets low in red meat and high in fish and vegetables.&lt;/p&gt;
    &lt;p&gt;The obesity rate is particularly low for women, which could go some way to explaining why Japanese women have a much higher life expectancy than their male counterparts.&lt;/p&gt;
    &lt;p&gt;As increased quantities of sugar and salt crept into diets in the rest of the world, Japan went in the other direction - with public health messaging successfully convincing people to reduce their salt consumption.&lt;/p&gt;
    &lt;p&gt;But it's not just diet. Japanese people tend to stay active into later life, walking and using public transport more than elderly people in the US and Europe.&lt;/p&gt;
    &lt;p&gt;Radio Taiso, a daily group exercise, has been a part of Japanese culture since 1928, established to encourage a sense of community as well as public health. The three-minute routine is broadcast on television and practised in small community groups across the country.&lt;/p&gt;
    &lt;p&gt;However, several studies have cast doubt on the validity of global centenarian numbers, suggesting data errors, unreliable public records and missing birth certificates may account for elevated figures.&lt;/p&gt;
    &lt;p&gt;A government audit of family registries in Japan in 2010 uncovered more than 230,000 people listed as being aged 100 or older who were unaccounted for, some having in fact died decades previously.&lt;/p&gt;
    &lt;p&gt;The miscounting was attributed to patchy record-keeping and suspicions that some families may have tried to hide the deaths of elderly relatives in order to claim their pensions.&lt;/p&gt;
    &lt;p&gt;The national inquiry was launched after the remains of Sogen Koto, believed to be the oldest man in Tokyo at 111, were found in his family home 32 years after his death.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45232052</guid></item><item><title>An Annual Blast of Pacific Cold Water Did Not Occur, Alarming Scientists</title><link>https://www.nytimes.com/2025/09/12/climate/pacific-cold-water-upwelling.html</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45232100</guid></item><item><title>Mago: A fast PHP toolchain written in Rust</title><link>https://github.com/carthage-software/mago</link><description>&lt;doc fingerprint="3150525899f3e1de"&gt;
  &lt;main&gt;
    &lt;p&gt;An extremely fast PHP linter, formatter, and static analyzer, written in Rust.&lt;/p&gt;
    &lt;p&gt;Mago is a comprehensive toolchain for PHP that helps developers write better code. Inspired by the Rust ecosystem, Mago brings speed, reliability, and an exceptional developer experience to PHP projects of all sizes.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Installation&lt;/item&gt;
      &lt;item&gt;Getting Started&lt;/item&gt;
      &lt;item&gt;Features&lt;/item&gt;
      &lt;item&gt;Our Sponsors&lt;/item&gt;
      &lt;item&gt;Contributing&lt;/item&gt;
      &lt;item&gt;Inspiration &amp;amp; Acknowledgements&lt;/item&gt;
      &lt;item&gt;License&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The most common way to install Mago on macOS and Linux is by using our shell script:&lt;/p&gt;
    &lt;code&gt;curl --proto '=https' --tlsv1.2 -sSf https://carthage.software/mago.sh | bash&lt;/code&gt;
    &lt;p&gt;For all other installation methods, including Homebrew, Composer, and Cargo, please refer to our official Installation Guide.&lt;/p&gt;
    &lt;p&gt;To get started with Mago and learn how to configure your project, please visit our Getting Started Guide in the official documentation.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚ö°Ô∏è Extremely Fast: Built in Rust for maximum performance.&lt;/item&gt;
      &lt;item&gt;üîç Lint: Identify issues in your codebase with customizable rules.&lt;/item&gt;
      &lt;item&gt;üî¨ Static Analysis: Perform deep analysis of your codebase to catch potential type errors and bugs.&lt;/item&gt;
      &lt;item&gt;üõ†Ô∏è Automated Fixes: Apply fixes for many lint issues automatically.&lt;/item&gt;
      &lt;item&gt;üìú Formatting: Automatically format your code to adhere to best practices and style guides.&lt;/item&gt;
      &lt;item&gt;üß† Semantic Checks: Ensure code correctness with robust semantic analysis.&lt;/item&gt;
      &lt;item&gt;üå≥ AST Visualization: Explore your code‚Äôs structure with Abstract Syntax Tree (AST) parsing.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Mago is a community-driven project, and we welcome contributions! Whether you're reporting bugs, suggesting features, writing documentation, or submitting code, your help is valued.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;See our Contributing Guide to get started.&lt;/item&gt;
      &lt;item&gt;Join the discussion on Discord.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Mago stands on the shoulders of giants. Our design and functionality are heavily inspired by pioneering tools in both the Rust and PHP ecosystems.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Clippy: For its comprehensive linting approach.&lt;/item&gt;
      &lt;item&gt;OXC: A major inspiration for building a high-performance toolchain in Rust.&lt;/item&gt;
      &lt;item&gt;Hakana: For its deep static analysis capabilities.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We deeply respect the foundational work of tools like PHP-CS-Fixer, Psalm, PHPStan, and PHP_CodeSniffer. While Mago aims to offer a unified and faster alternative, these tools paved the way for modern PHP development.&lt;/p&gt;
    &lt;p&gt;Mago is dual-licensed under your choice of the following:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;MIT License (LICENSE-MIT)&lt;/item&gt;
      &lt;item&gt;Apache License, Version 2.0 (LICENSE-APACHE)&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45232275</guid></item><item><title>Show HN: CLAVIER-36 ‚Äì A programming environment for generative music</title><link>https://clavier36.com/p/LtZDdcRP3haTWHErgvdM</link><description>&lt;doc fingerprint="536fd5a56c585c00"&gt;
  &lt;main&gt;
    &lt;p&gt;√ó&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45232299</guid></item><item><title>'Someone must know this guy': four-year wedding crasher mystery solved</title><link>https://www.theguardian.com/uk-news/2025/sep/12/wedding-crasher-mystery-solved-four-years-bride-scotland</link><description>&lt;doc fingerprint="67528137d6155029"&gt;
  &lt;main&gt;
    &lt;p&gt;A baffled bride has solved the mystery of the awkward-looking stranger who crashed her wedding four years ago.&lt;/p&gt;
    &lt;p&gt;Michelle Wylie and her husband, John, registered the presence of their unidentifiable guest only as they looked through photographs of their wedding in the days after the happy occasion.&lt;/p&gt;
    &lt;p&gt;Who was the tall man in a dark suit, distinguished by the look of quiet mortification on his face? But their family and friends could offer no explanation, nor could hotel staff at the Carlton hotel in Prestwick, where the event took place in November 2021. An appeal on Facebook likewise yielded no clues.&lt;/p&gt;
    &lt;p&gt;Eventually, with the mystery still niggling, Wylie asked the popular Scottish content creator Dazza to cast the online net wider ‚Äì and a sheepish Andrew Hillhouse finally stepped forward.&lt;/p&gt;
    &lt;p&gt;In his explanatory post on Facebook, Hillhouse admitted that he had been ‚Äúcutting it fine, as I‚Äôm known to do‚Äù when he pulled up at the wedding venue with five minutes to spare. Spotting a piper and other guests, he followed them into the hotel ‚Äì ‚ÄúI remember thinking to myself: ‚ÄòCool, this is obviously the right place‚Äô‚Äù ‚Äì unaware that he had the address completely wrong and was supposed to be at a ceremony 2 miles away in Ayr.&lt;/p&gt;
    &lt;p&gt;He was initially unperturbed to find himself surrounded by strangers as the ceremony began ‚Äì at the marriage he was due to attend, the only person he knew was the bride, Michaela, while his partner, Andrew, was part of the wedding party. It was when an entirely different bride came walking down the aisle that he realised: ‚ÄúOMG that‚Äôs not Michaela ‚Ä¶ I was at the wrong wedding!‚Äù&lt;/p&gt;
    &lt;p&gt;Hillhouse said: ‚ÄúYou can‚Äôt exactly stand up and walk out of a wedding mid-ceremony, so I just had to commit to this act and spent the next 20 minutes awkwardly sitting there trying to be as inconspicuous as my 6ft 2 ass could be.‚Äù&lt;/p&gt;
    &lt;p&gt;At the end of the ceremony, Hillhouse, who is from Troon, was hoping to make a discreet exit, only to be waylaid by the wedding photographer, who insisted he join other guests for a group shot. He can be spotted looming uncomfortably at the very back of the crowd.&lt;/p&gt;
    &lt;p&gt;His post continued: ‚ÄúRushed outside, made some phone calls and made my way to the correct wedding, where I was almost as popular as the actual bride and groom, and spent most of the night retelling that story to people.‚Äù&lt;/p&gt;
    &lt;p&gt;For Michelle Wylie, this amiable resolution brings to a close years of speculation.&lt;/p&gt;
    &lt;p&gt;She told BBC Scotland: ‚ÄúIt would come into my head and I‚Äôd be like: ‚ÄòSomeone must know who this guy is.‚Äô I said a few times to my husband: ‚ÄòAre you sure you don‚Äôt know this guy, is he maybe from your work?‚Äô We wondered if he was a mad stalker.‚Äù&lt;/p&gt;
    &lt;p&gt;She is now Facebook friends with Hillhouse and the pair have met in person to cement their coincidental bond.&lt;/p&gt;
    &lt;p&gt;‚ÄúI could not stop laughing,‚Äù said Wylie. ‚ÄúWe can‚Äôt believe we‚Äôve found out who he is after almost four years.‚Äù&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45232562</guid></item><item><title>486Tang ‚Äì 486 on a credit-card-sized FPGA board</title><link>https://nand2mario.github.io/posts/2025/486tang_486_on_a_credit_card_size_fpga_board/</link><description>&lt;doc fingerprint="3a1d596421a49ee2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;486Tang - 486 on a credit-card-sized FPGA board&lt;/head&gt;
    &lt;p&gt;Yesterday I released 486Tang v0.1 on GitHub. It‚Äôs a port of the ao486 MiSTer PC core to the Sipeed Tang Console 138K FPGA. I‚Äôve been trying to get an x86 core running on the Tang for a while. As far as I know, this is the first time ao486 has been ported to a non-Altera FPGA. Here‚Äôs a short write‚Äëup of the project.&lt;/p&gt;
    &lt;head rend="h2"&gt;486Tang Architecture&lt;/head&gt;
    &lt;p&gt;Every FPGA board is a little different. Porting a core means moving pieces around and rewiring things to fit. Here are the major components in 486Tang:&lt;/p&gt;
    &lt;p&gt;Compared to ao486 on MiSTer, there are a few major differences:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Switching to SDRAM for main memory. The MiSTer core uses DDR3 as main memory. Obviously, at the time of the 80486, DDR didn‚Äôt exist, so SDRAM is a natural fit. I also wanted to dedicate DDR3 to the framebuffer; time‚Äëmultiplexing it would have been complicated. So SDRAM became the main memory and DDR3 the framebuffer. The SDRAM on Tang is 16‚Äëbit wide while ao486 expects 32‚Äëbit accesses, which would normally mean one 32‚Äëbit word every two cycles. I mitigated this by running the SDRAM logic at 2√ó the system clock so a 32‚Äëbit word can be read or written every CPU cycle (‚Äúdouble‚Äëpumping‚Äù the memory).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;SD‚Äëbacked IDE. On MiSTer, the core forwards IDE requests to the ARM HPS over a fast HPS‚ÄëFPGA link; the HPS then accesses a VHD image. Tang doesn‚Äôt have a comparable high‚Äëspeed MCU‚Äëto‚ÄëFPGA interface‚Äîonly a feeble UART‚Äîso I moved disk storage into the SD card and let the FPGA access it directly.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Boot‚Äëloading module. A PC needs several things to boot: BIOS, VGA BIOS, CMOS settings, and IDE IDENTIFY data (512 bytes). Since I didn‚Äôt rely on an MCU for disk data, I stored all of these in the first 128 KB of the SD card. A small boot loader module reads them into main memory and IDE, and then releases the CPU when everything is ready.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;System bring-up with the help of a whole-system simulator&lt;/head&gt;
    &lt;p&gt;After restructuring the system, the main challenge was bringing it up to a DOS prompt. A 486 PC is complex‚ÄîCPU and peripherals‚Äîmore so than the game consoles I‚Äôve worked on. The ao486 CPU alone is &amp;gt;25K lines of Verilog, versus a few K for older cores like M68K. Debugging on hardware was painful: GAO builds took 10+ minutes and there were many more signals to probe. Without a good plan, it would be unmanageable and bugs could take days to isolate‚Äînot viable for a hobby project.&lt;/p&gt;
    &lt;p&gt;My solution was Verilator for subsystem and whole‚Äësystem simulation. The codebase is relatively mature, so I skipped per‚Äëmodule unit tests and focused on simulating subsystems like VGA and a full boot to DOS. Verilator is fast enough to reach a DOS prompt in a few minutes‚Äîan order of magnitude better if you factor in the complete waveforms you get in simulation. The trick, then, is surfacing useful progress and error signals. A few simple instrumentation hooks were enough for me:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Bochs BIOS can print debug strings to port 0x8888 in debug builds. I intercept and print these (the yellow messages in the simulator). The same path exists on hardware‚Äîthe CPU forwards them over UART‚Äîso BIOS issues show up immediately without waiting for a GAO build.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Subsystem‚Äëscoped tracing. For Sound Blaster, IDE, etc., I added&lt;/p&gt;&lt;code&gt;--sound&lt;/code&gt;,&lt;code&gt;--ide&lt;/code&gt;flags to trace I/O operations and key state changes. This is much faster than editing Verilog or using GAO.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Bochs BIOS assembly listings are invaluable. I initially used a manual disassembly‚Äîold console habits‚Äîwithout symbols, which was painful. Rebuilding Bochs and using the official listings solved that.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A lot of the bugs were in the new glue I added, as expected. ao486 itself is mature. Still, a few issues only showed up on this toolchain/hardware, mostly due to toolchain behavior differences. In one case a variable meant to be static behaved like an automatic variable and didn‚Äôt retain state across invocations, so a CE pulse never occurred. Buried deep, it took a while to find.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs a simulation session. On the left the simulated 486 screen. On the right is the simulator terminal output. You can see the green VGA output and yellow debug output, along with other events like INT 15h and video VSYNCs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Performance optimizations&lt;/head&gt;
    &lt;p&gt;With simulation help, the core ran on Tang Console‚Äîjust not fast. The Gowin GW5A isn‚Äôt a particularly fast FPGA. Initial benchmarks put it around a 25 MHz 80386.&lt;/p&gt;
    &lt;p&gt;The main obstacle to clock speed is long combinational paths. When you find a critical path, you either shorten it or pipeline it by inserting registers‚Äîboth risks bugs. A solid test suite is essential; I used test386.asm to validate changes.&lt;/p&gt;
    &lt;p&gt;Here are a few concrete wins:&lt;/p&gt;
    &lt;p&gt;Reset tree and fan-out reduction. Gowin‚Äôs tools didn‚Äôt replicate resets aggressively enough (even with ‚ÄúPlace ‚Üí Replicate Resources‚Äù). One reset net had &amp;gt;5,000 fan-out, which ballooned delays. Manually replicating the reset and a few other high‚Äëfan-out nets helped a lot.&lt;/p&gt;
    &lt;p&gt;Instruction fetch optimization. A long combinational chain sat in the decode/fetch interface. In &lt;code&gt;decoder_regs.v&lt;/code&gt;, the number of bytes the fetcher may accept was computed using the last decoded instruction‚Äôs length:&lt;/p&gt;
    &lt;code&gt;reg [3:0] decoder_count;
assign acceptable_1     = 4'd12 - decoder_count + consume_count;
always @(posedge clk) begin
  ...
  decoder_count &amp;lt;= after_consume_count + accepted;
end
&lt;/code&gt;
    &lt;p&gt;Here, &lt;code&gt;12&lt;/code&gt; is the buffer size, &lt;code&gt;decoder_count&lt;/code&gt; is the current occupancy, and &lt;code&gt;consume_count&lt;/code&gt; is the length of the outgoing instruction. Reasonable‚Äîbut computing &lt;code&gt;consume_count&lt;/code&gt; (opcode, ModR/M, etc.) was on the Fmax‚Äëlimiting path. By the way, this is one of several well-known problems of the x86 - variable length instructions complicating decoding, another is complex address modes and ‚Äúeffective address‚Äù calculation.&lt;/p&gt;
    &lt;p&gt;The fix was to drop the dependency on &lt;code&gt;consume_count&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;assign acceptable_1    = 4'd12 - decoder_count;
&lt;/code&gt;
    &lt;p&gt;This may cause the fetcher to ‚Äúunder‚Äëfetch‚Äù for one cycle because the outgoing instruction‚Äôs space isn‚Äôt reclaimed immediately. But &lt;code&gt;decoder_count&lt;/code&gt; updates next cycle, reclaiming the space. With a 12‚Äëbyte buffer, the CPI impact was negligible and Fmax improved measurably on this board.&lt;/p&gt;
    &lt;p&gt;TLB optimization. The Translation Lookaside Buffer (TLB) is a small cache that translates virtual to physical addresses. ao486 uses a 32‚Äëentry fully‚Äëassociative TLB with a purely combinational read path‚Äîzero extra cycles, but a long path on every memory access (code and data).&lt;/p&gt;
    &lt;p&gt;DOS workloads barely stress the TLB; even many 386 extenders use a flat model. As a first step I converted the TLB to 4‚Äëway set‚Äëassociative. That‚Äôs simpler and already slightly faster than fully‚Äëassociative for these workloads. There‚Äôs room to optimize further since the long combinational path rarely helps.&lt;/p&gt;
    &lt;p&gt;A rough v0.1 end‚Äëto‚Äëend result: about +35% per Landmark 6 benchmarks, reaching roughly 486SX‚Äë20 territory.&lt;/p&gt;
    &lt;head rend="h2"&gt;Reflections&lt;/head&gt;
    &lt;p&gt;Here are a few reflections after the port:&lt;/p&gt;
    &lt;p&gt;Clock speed scaling. I appreciate the lure of the megahertz race now. Scaling the whole system clock was the most effective lever‚Äîmore so than extra caches or deeper pipelines at this stage. Up to ~200‚Äì300 MHz, CPU, memory, and I/O can often scale together. After that, memory latency dominates, caches grow deeper, and once clock speeds stop increasing, multiprocessing takes over‚Äîthe story of the 2000s.&lt;/p&gt;
    &lt;p&gt;x86 vs. ARM. Working with ao486 deepened my respect for x86‚Äôs complexity. John Crawford‚Äôs 1990 paper ‚ÄúThe i486 CPU: Executing Instructions in One Clock Cycle‚Äù is a great read; it argues convincingly against scrapping x86 for a new RISC ISA given the software base (10K+ apps then). Compatibility was the right bet, but the baggage is real. By contrast, last year‚Äôs ARM7‚Äëbased GBATang felt refreshingly simple: fixed‚Äëlength 32‚Äëbit instructions, saner addressing, and competitive performance. You can‚Äôt have your cake and eat it.&lt;/p&gt;
    &lt;p&gt;So there you have it‚Äîthat‚Äôs 486Tang in v0.1. Thanks for reading, and see you next time.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45232565</guid></item><item><title>Magical systems thinking</title><link>https://worksinprogress.co/issue/magical-systems-thinking/</link><description>&lt;doc fingerprint="a568110c0f83cf69"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Systems thinking promises to give us a toolkit to design complex systems that work from the ground up. It fails because it ignores an important fact: systems fight back.&lt;/head&gt;
    &lt;p&gt;The systems that enable modern life share a common origin. The water supply, the internet, the international supply chains bringing us cheap goods: each began life as a simple, working system. The first electric grid was no more than a handful of electric lamps hooked up to a water wheel in Godalming, England, in 1881. It then took successive decades of tinkering and iteration by thousands of very smart people to scale these systems to the advanced state we enjoy today. At no point did a single genius map out the final, finished product.&lt;/p&gt;
    &lt;p&gt;But this lineage of (mostly) working systems is easily forgotten. Instead, we prefer a more flattering story: that complex systems are deliberate creations, the product of careful analysis. And, relatedly, that by performing this analysis ‚Äì now known as ‚Äòsystems thinking‚Äô in the halls of government ‚Äì we can bring unruly ones to heel. It is an optimistic perspective, casting us as the masters of our systems and our destiny.&lt;/p&gt;
    &lt;p&gt;The empirical record says otherwise, however. Our recent history is one of governments grappling with complex systems and coming off worse. In the United States, HealthCare.gov was designed to simplify access to health insurance by knitting together 36 state marketplaces and data from eight federal agencies. Its launch was paralyzed by technical failures that locked out millions of users. Australia‚Äôs disability reforms, carefully planned for over a decade and expected to save money, led to costs escalating so rapidly that they will soon exceed the pension budget. The UK‚Äôs 2014 introduction of Contracts for Difference, intended to speed the renewables rollout by giving generators a guaranteed price, overstrained the grid and is a major contributor to the 15-year queue for new connections. Systems thinking is more popular than ever; modern systems thinkers have analytical tools that their predecessors could only have dreamt of. But the systems keep kicking back.&lt;/p&gt;
    &lt;p&gt;There is a better way. A long but neglected line of thinkers going back to chemists in the nineteenth century has argued that complex systems are not our passive playthings. Despite friendly names like ‚Äòthe health system‚Äô, they demand extreme wariness. If broken, a complex system often cannot be fixed. Meanwhile, our successes, when they do come, are invariably the result of starting small. As the systems we have built slip further beyond our collective control, it is these simple working systems that offer us the best path back.&lt;/p&gt;
    &lt;head rend="h3"&gt;The world model&lt;/head&gt;
    &lt;p&gt;In 1970, the ‚ÄòClub of Rome‚Äô, a group of international luminaries with an interest in how the problems of the world were interrelated, invited Jay Wright Forrester to peer into the future of the global economy. An MIT expert on electrical and mechanical engineering, Forrester had cut his teeth on problems like how to keep a Second World War aircraft carrier‚Äôs radar pointed steadily at the horizon amid the heavy swell of the Pacific.&lt;/p&gt;
    &lt;p&gt;The Club of Rome asked an even more intricate question: how would social and economic forces interact in the coming decades? Where were the bottlenecks and feedback mechanisms? Could economic growth continue, or would the world enter a new phase of equilibrium or decline?&lt;/p&gt;
    &lt;p&gt;Forrester labored hard, producing a mathematical model of enormous sophistication. Across 130 pages of mathematical equations, computer graphical printout, and DYNAMO code,World Dynamics tracks the myriad relationships between natural resources, capital, population, food, and pollution: everything from the ‚Äòcapital-investment-in-agriculture-fraction adjustment time‚Äô to the ominous ‚Äòdeath-rate-from-pollution multiplier‚Äô.&lt;/p&gt;
    &lt;p&gt;World leaders had assumed that economic growth was an unalloyed good. But Forrester‚Äôs results showed the opposite. As financial and population growth continued, natural resources would be consumed at an accelerating rate, agricultural land would be paved over, and pollution would reach unmanageable levels. His model laid out dozens of scenarios and in most of them, by 2025, the world would already be in the first throes of an irreversible decline in living standards. By 2070, the crunch would be so painful that industrialized nations might regret their experiment with economic growth altogether. As Forrester put it, ‚Äò[t]he present underdeveloped countries may be in a better condition for surviving forthcoming worldwide environmental and economic pressures than are the advanced countries.‚Äô&lt;/p&gt;
    &lt;p&gt;But, as we now know, the results were also wrong. Adjusting for inflation, world GDP is now about five times higher than it was in 1970 and continues to rise. More than 90 percent of that growth has come from Asia, Europe, and North America, but forest cover across those regions has increased, up 2.6 percent since 1990 to over 2.3 billion hectares in 2020. The death rate from air pollution has almost halved in the same period, from 185 per 100,000 in 1990 to 100 in 2021. According to the model, none of this should have been possible.&lt;/p&gt;
    &lt;p&gt;What happened? The blame cannot lie with Forrester‚Äôs competence: it‚Äôs hard to imagine a better systems pedigree than his. To read his prose today is to recognize a brilliant, thoughtful mind. Moreover, the system dynamics approach Forrester pioneered had already shown promise beyond the mechanical and electrical systems that were its original inspiration.&lt;/p&gt;
    &lt;p&gt;In 1956, the management of a General Electric refrigerator factory in Kentucky had called on Forrester‚Äôs help. They were struggling with a boom-and-bust cycle: acute shortages became gluts that left warehouses overflowing with unsold fridges. The factory based its production decisions on orders from the warehouse, which in turn got orders from distributors, who heard from retailers, who dealt with customers. Each step introduced noise and delay. Ripples in demand would be amplified into huge swings in production further up the supply chain.&lt;/p&gt;
    &lt;p&gt;Looking at the system as a whole, Forrester recognized the same feedback loops and instability that could bedevil a ship‚Äôs radar. He developed new decision rules, such as smoothing production based on longer-term sales data rather than immediate orders, and found ways to speed up the flow of information between retailers, distributors, and the factory. These changes dampened the oscillations caused by the system‚Äôs own structure, checking its worst excesses.&lt;/p&gt;
    &lt;p&gt;The Kentucky factory story showed Forrester‚Äôs skill as a systems analyst. Back at MIT, Forrester immortalized his lessons as a learning exercise (albeit with beer instead of refrigerators). In the ‚ÄòBeer Game‚Äô, now a rite of passage for students at the MIT Sloan School of Management, players take one of four different roles in the beer supply chain: retailer, wholesaler, distributor, and brewer. Each player sits at a separate table and can communicate only through order forms. As their inventory runs low, they place orders with the supplier next upstream. Orders take time to process, and shipments to arrive, and each player can see only their small part of the chain.&lt;/p&gt;
    &lt;p&gt;The objective of the Beer Game is to minimize costs by managing inventory effectively. But, as the GE factory managers had originally found, this is not so easy. Gluts and shortages arise mysteriously, without obvious logic, and small perturbations in demand get amplified up the chain by as much as 800 percent (‚Äòthe bullwhip effect‚Äô). On average, players‚Äô total costs end up being ten times higher than the optimal solution.&lt;/p&gt;
    &lt;p&gt;With the failure of his World Model, Forrester had fallen into the same trap as his MIT students. Systems analysis works best under specific conditions: when the system is static; when you can dismantle and examine it closely; when it involves few moving parts rather than many; and when you can iterate fixes through multiple attempts. A faulty ship‚Äôs radar or a simple electronic circuit are ideal. Even a limited human element ‚Äì with people‚Äôs capacity to pursue their own plans, resist change, form political blocs, and generally frustrate best-laid plans ‚Äì makes things much harder. The four-part refrigerator supply chain, with the factory, warehouse, distributor and retailer all under the tight control of management, is about the upper limit of what can be understood. Beyond that, in the realm of societies, governments and economies, systems thinking becomes a liability, more likely to breed false confidence than real understanding. For these systems we need a different approach.&lt;/p&gt;
    &lt;head rend="h3"&gt;Le Chatelier‚Äôs Principle&lt;/head&gt;
    &lt;p&gt;In 1884, in a laboratory at the √âcole des Mines in Paris, Henri Louis Le Chatelier noticed something peculiar: chemical reactions seemed to resist changes imposed upon them. Le Chatelier found that if, say, you have an experiment where two molecules combine in a heat-generating exothermic reaction (in his case, it was two reddish-brown nitrogen dioxide molecules combining into colorless dinitrogen tetroxide and giving off heat in the process), then you can speed things up by cooling the reactants. To ‚Äòresist‚Äô the drop in temperature, the system restores its equilibrium by creating more of the products that release heat.&lt;/p&gt;
    &lt;p&gt;Le Chatelier‚Äôs Principle, the idea that the system always kicks back, proved to be a very general and powerful way to think about chemistry. It was instrumental in the discovery of the Haber-Bosch process for creating ammonia that revolutionized agriculture. Nobel Laureate Linus Pauling hoped that, even after his students had ‚Äòforgotten all the mathematical equations relating to chemical equilibrium‚Äô, Le Chatelier‚Äôs Principle would be the one thing they remembered. And its usefulness went beyond chemistry. A century after Le Chatelier‚Äôs meticulous lab work, another student of systems would apply the principle to the complex human systems that had stymied Forrester and his subsequent followers in government.&lt;/p&gt;
    &lt;p&gt;John Gall was a pediatrician with a long-standing practice in Ann Arbor, Michigan. Of the same generation as Forrester, Gall came at things from a different direction. Whereas Forrester‚Äôs background was in mechanical and electrical systems, which worked well and solved new problems, Gall was immersed in the human systems of health, education, and government. These systems often did not work well. How was it, Gall wondered, that they seemed to coexist happily with the problems ‚Äì crime, poverty, ill health ‚Äì they were supposed to stamp out?&lt;/p&gt;
    &lt;p&gt;Le Chatelier‚Äôs Principle provided an answer: systems should not be thought of as benign entities that will faithfully carry out their creators‚Äô intentions. Rather, over time, they come to oppose their own proper functioning. Gall elaborated on this idea in his 1975 book Systemantics, named for the universal tendency of systems to display antics. A brief, weird, funny book, Systemantics (The Systems Bible in later editions) is arguably the best field guide to contemporary systems dysfunction. It consists of a series of pithy aphorisms, which the reader is invited to apply to explain the system failures (‚Äòhorrible examples‚Äô) they witness every day.&lt;/p&gt;
    &lt;p&gt;These aphorisms are provocatively stated, but they have considerable explanatory power. For example, an Australian politician frustrated at the new headaches created by ‚Äòfixes‚Äô to the old disability system might be reminded that ‚ÄòNEW SYSTEMS CREATE NEW PROBLEMS‚Äô. An American confused at how there can now be 190,000 pages in the US Code of Federal Regulations, up from 10,000 in 1950, might note that this is the nature of the beast: ‚ÄòSYSTEMS TEND TO GROW, AND AS THEY GROW THEY ENCROACH‚Äô. During the French Revolution, in 1793 and 1794, the ‚ÄòCommittee of Public Safety‚Äô guillotined thousands of people, an early example of the enduring principles that ‚ÄòTHE SYSTEM DOES NOT DO WHAT IT SAYS IT IS DOING‚Äô and that ‚ÄòTHE NAME IS EMPHATICALLY NOT THE THING‚Äô. And, just like student chemists, government reformers everywhere would do well to remember Le Chatelier‚Äôs Principle: ‚ÄòTHE SYSTEM ALWAYS KICKS BACK‚Äô.&lt;/p&gt;
    &lt;p&gt;These principles encourage a healthy paranoia when it comes to complex systems. But Gall‚Äôs ‚Äòsystems-display-antics‚Äô philosophy is not a counsel of doom. His greatest insight was a positive one, explaining how some systems do succeed in spite of the pitfalls. Known as ‚ÄòGall‚Äôs law‚Äô, it‚Äôs worth quoting in full:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;A complex system that works is invariably found to have evolved from a simple system that worked. A complex system designed from scratch never works and cannot be patched up to make it work. You have to start over with a working simple system.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Starting with a working simple system and evolving from there is how we went from the water wheel in Godalming to the modern electric grid. It is how we went from a hunk of germanium, gold foil, and hand-soldered wires in 1947 to transistors being etched onto silicon wafers in their trillions today.&lt;/p&gt;
    &lt;p&gt;This is a dynamic we can experience on a personal as well as a historical level. A trivial but revealing example is the computer game Factorio. Released in 2012 and famously hazardous to the productivity of software engineers everywhere, Factorio invites players to construct a factory. The ultimate goal is to launch a rocket, a feat that requires the player to produce thousands of intermediate products through dozens of complicated, interlocking manufacturing processes.&lt;/p&gt;
    &lt;p&gt;It sounds like a nightmare. An early flow chart (pictured ‚Äì it has grown much more complicated since) resembles the end product of a particularly thorny systems thinking project. But players complete its daunting mission successfully, without reference to such system maps, in their thousands, and all for fun.&lt;/p&gt;
    &lt;p&gt;The genius of the game is that it lets players begin with a simple system that works. As you learn to produce one item, another is unlocked. If you get something wrong, the factory visibly grinds to a halt while you figure out a different approach. The hours tick by, and new systems ‚Äì automated mining, oil refining, locomotives ‚Äì are introduced and iterated upon. Before you realize it, you have built a sprawling yet functioning system that might be more sophisticated than anything you have worked on in your entire professional career.&lt;/p&gt;
    &lt;head rend="h3"&gt;How to build systems that work&lt;/head&gt;
    &lt;p&gt;Government systems, however, are already established, complicated, and relied upon by millions of people every day. We cannot simply switch off the health system and ask everyone to wait a few years while we build something better. The good news is that the existence of an old, clunky system does not stop us from starting something new and simple in parallel.&lt;/p&gt;
    &lt;p&gt;In the 1950s, the US was in a desperate race against a technologically resurgent Soviet Union. The USSR took the lead in developing advanced rockets of the type that launched Sputnik into orbit and risked launching a nuclear device into Washington, DC. In 1954, the Eisenhower administration tasked General Bernard Schriever with helping the US develop its own Intercontinental Ballistic Missile (ICBM). An experienced airman and administrator, the top brass felt that Schriever‚Äôs Stanford engineering master‚Äôs degree would make him a suitable go-between for the soldiers and scientists on this incredibly technical project (its scope was larger even than the Manhattan Project, costing over $100 billion in 2025 dollars versus the latter‚Äôs $39 billion).&lt;/p&gt;
    &lt;p&gt;The organizational setup Schriever inherited was not fit for the task. With many layers of approvals and subcommittees within subcommittees, it was a classic example of a complex yet dysfunctional system. The technological challenges posed by the ICBM were extreme: everything from rocket engines to targeting systems to the integration with nuclear warheads had to be figured out more or less from scratch. This left no room for bureaucratic delay.&lt;/p&gt;
    &lt;p&gt;Schriever produced what many systems thinkers would recognize as a kind of systems map: a series of massive boards setting out all the different committees and governance structures and approvals and red tape. But the point of these ‚Äòspaghetti charts‚Äô was not to make a targeted, systems thinking intervention. Schriever didn‚Äôt pretend to be able to navigate and manipulate all this complexity. He instead recognized his own limits. With the Cold War in the balance, he could not afford to play and lose his equivalent of the Beer Game. Charts in hand, Schriever persuaded his boss that untangling the spaghetti was a losing battle: they needed to start over.&lt;/p&gt;
    &lt;p&gt;They could not change the wider laws, regulations, and institutional landscape governing national defense. But they could work around them, starting afresh with a simple system outside the existing bureaucracy. Direct vertical accountability all the way to the President and a free hand on personnel enabled the program to flourish. Over the following years, four immensely ambitious systems were built in record time. The uneasy strategic stalemate that passed for stability during the Cold War was restored, and the weapons were never used in anger.&lt;/p&gt;
    &lt;p&gt;When we look in more detail at recent public policy successes, we see that this pattern tends to hold. Operation Warp Speed in the US played a big role in getting vaccines delivered quickly. It did so by bypassing many of the usual bottlenecks. For instance, it made heavy use of ‚ÄòOther Transaction Authority agreements‚Äô to commit $12.5 billion of federal money by March 2021, circumventing the thousands of pages of standard procurement rules. Emergency powers were deployed to accelerate the FDA review process, enabling clinical trial work and early manufacturing scale-up to happen in parallel. These actions were funded through an $18 billion commitment made largely outside the typical congressional appropriation oversight channels ‚Äì enough money to back not just one vaccine candidate but six, across three different technology platforms.&lt;/p&gt;
    &lt;p&gt;In France, the rapid reconstruction of Notre-Dame after the April 2019 fire has become a symbol of French national pride and its ability to get things done despite a reputation for moribund bureaucracy. This was achieved not through wholesale reform of that bureaucracy but by quickly setting up a fresh structure outside of it. In July 2019, the French Parliament passed Loi n¬∞ 2019-803, creating an extraordinary legal framework for the project. Construction permits and zoning changes were fast-tracked. President Macron personally appointed the veteran General Jean-Louis Georgelin to run the restoration, exempting him from the mandatory retirement age for public executives in order to do so.&lt;/p&gt;
    &lt;p&gt;The long-term promise of a small working system is that over time it can supplant the old, broken one and produce results on a larger scale. This creative destruction has long been celebrated in the private sector, where aging corporate giants can be disrupted by smaller, simpler startups: we don‚Äôt have to rely on IBM to make our phones or laptops or Large Language Models. But it can work in the public sector too. Estonia, for example, introduced electronic ID in the early 2000s for signing documents and filing online tax returns. These simple applications, which nonetheless took enormous focus to implement, were popular, and ‚Äòdigital government‚Äô was gradually expanded to new areas: voting in 2005, police in 2007, prescriptions in 2010, residency in 2014, and even e-divorce in 2024. By 2025, 99 percent of residents will have an electronic ID card, digital signatures are estimated to save two percent of GDP per year, and every state service runs online.&lt;/p&gt;
    &lt;p&gt;In desperate situations, such as a Cold War arms race or COVID-19, we avoid complex systems and find simpler workarounds. But, outside of severe crises, much time is wasted on what amounts to magical systems thinking. Government administrations around the world, whose members would happily admit their incompetence to fix a broken radio system, publish manifestos, strategies, plans, and priorities premised on disentangling systems problems that are orders of magnitude more challenging. With each ‚Äòfix‚Äô, oversight bodies, administrative apparatus, and overlapping statutory obligations accumulate. Complexity is continuing to rise, outcomes are becoming worse, and voters‚Äô goodwill is being eroded.&lt;/p&gt;
    &lt;p&gt;We will soon be in an era where humans are not the sole authors of complex systems. Sundar Pichai estimated in late 2024 that over 25 percent of Google‚Äôs code was AI generated; as of mid-2025, the figure for Anthropic is 80‚Äì90 percent. As in the years after the Second World War, the temptation will be to use this vast increase in computational power and intelligence to ‚Äòsolve‚Äô systems design for once and for all. But the same laws that limited Forrester continue to bind: ‚ÄòNEW SYSTEMS CREATE NEW PROBLEMS‚Äô and ‚ÄòTHE SYSTEM ALWAYS KICKS BACK‚Äô. As systems become more complex, they become more chaotic, not less. The best solution remains humility, and a simple system that works.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45233266</guid></item><item><title>Why OpenAI's solution to AI hallucinations would kill ChatGPT tomorrow</title><link>https://theconversation.com/why-openais-solution-to-ai-hallucinations-would-kill-chatgpt-tomorrow-265107</link><description>&lt;doc fingerprint="f52d3a18a9a295f2"&gt;
  &lt;main&gt;
    &lt;p&gt;OpenAI‚Äôs latest research paper diagnoses exactly why ChatGPT and other large language models can make things up ‚Äì known in the world of artificial intelligence as ‚Äúhallucination‚Äù. It also reveals why the problem may be unfixable, at least as far as consumers are concerned.&lt;/p&gt;
    &lt;p&gt;The paper provides the most rigorous mathematical explanation yet for why these models confidently state falsehoods. It demonstrates that these aren‚Äôt just an unfortunate side effect of the way that AIs are currently trained, but are mathematically inevitable.&lt;/p&gt;
    &lt;p&gt;The issue can partly be explained by mistakes in the underlying data used to train the AIs. But using mathematical analysis of how AI systems learn, the researchers prove that even with perfect training data, the problem still exists.&lt;/p&gt;
    &lt;p&gt;The way language models respond to queries ‚Äì by predicting one word at a time in a sentence, based on probabilities ‚Äì naturally produces errors. The researchers in fact show that the total error rate for generating sentences is at least twice as high as the error rate the same AI would have on a simple yes/no question, because mistakes can accumulate over multiple predictions.&lt;/p&gt;
    &lt;p&gt;In other words, hallucination rates are fundamentally bounded by how well AI systems can distinguish valid from invalid responses. Since this classification problem is inherently difficult for many areas of knowledge, hallucinations become unavoidable.&lt;/p&gt;
    &lt;p&gt;It also turns out that the less a model sees a fact during training, the more likely it is to hallucinate when asked about it. With birthdays of notable figures, for instance, it was found that if 20% of such people‚Äôs birthdays only appear once in training data, then base models should get at least 20% of birthday queries wrong.&lt;/p&gt;
    &lt;p&gt;Sure enough, when researchers asked state-of-the-art models for the birthday of Adam Kalai, one of the paper‚Äôs authors, DeepSeek-V3 confidently provided three different incorrect dates across separate attempts: ‚Äú03-07‚Äù, ‚Äú15-06‚Äù, and ‚Äú01-01‚Äù. The correct date is in the autumn, so none of these were even close.&lt;/p&gt;
    &lt;head rend="h2"&gt;The evaluation trap&lt;/head&gt;
    &lt;p&gt;More troubling is the paper‚Äôs analysis of why hallucinations persist despite post-training efforts (such as providing extensive human feedback to an AI‚Äôs responses before it is released to the public). The authors examined ten major AI benchmarks, including those used by Google, OpenAI and also the top leaderboards that rank AI models. This revealed that nine benchmarks use binary grading systems that award zero points for AIs expressing uncertainty.&lt;/p&gt;
    &lt;p&gt;This creates what the authors term an ‚Äúepidemic‚Äù of penalising honest responses. When an AI system says ‚ÄúI don‚Äôt know‚Äù, it receives the same score as giving completely wrong information. The optimal strategy under such evaluation becomes clear: always guess.&lt;/p&gt;
    &lt;p&gt;The researchers prove this mathematically. Whatever the chances of a particular answer being right, the expected score of guessing always exceeds the score of abstaining when an evaluation uses binary grading.&lt;/p&gt;
    &lt;head rend="h2"&gt;The solution that would break everything&lt;/head&gt;
    &lt;p&gt;OpenAI‚Äôs proposed fix is to have the AI consider its own confidence in an answer before putting it out there, and for benchmarks to score them on that basis. The AI could then be prompted, for instance: ‚ÄúAnswer only if you are more than 75% confident, since mistakes are penalised 3 points while correct answers receive 1 point.‚Äù&lt;/p&gt;
    &lt;p&gt;The OpenAI researchers‚Äô mathematical framework shows that under appropriate confidence thresholds, AI systems would naturally express uncertainty rather than guess. So this would lead to fewer hallucinations. The problem is what it would do to user experience.&lt;/p&gt;
    &lt;p&gt;Consider the implications if ChatGPT started saying ‚ÄúI don‚Äôt know‚Äù to even 30% of queries ‚Äì a conservative estimate based on the paper‚Äôs analysis of factual uncertainty in training data. Users accustomed to receiving confident answers to virtually any question would likely abandon such systems rapidly.&lt;/p&gt;
    &lt;p&gt;I‚Äôve seen this kind of problem in another area of my life. I‚Äôm involved in an air-quality monitoring project in Salt Lake City, Utah. When the system flags uncertainties around measurements during adverse weather conditions or when equipment is being calibrated, there‚Äôs less user engagement compared to displays showing confident readings ‚Äì even when those confident readings prove inaccurate during validation.&lt;/p&gt;
    &lt;head rend="h2"&gt;The computational economics problem&lt;/head&gt;
    &lt;p&gt;It wouldn‚Äôt be difficult to reduce hallucinations using the paper‚Äôs insights. Established methods for quantifying uncertainty have existed for decades. These could be used to provide trustworthy estimates of uncertainty and guide an AI to make smarter choices.&lt;/p&gt;
    &lt;p&gt;But even if the problem of users disliking this uncertainty could be overcome, there‚Äôs a bigger obstacle: computational economics. Uncertainty-aware language models require significantly more computation than today‚Äôs approach, as they must evaluate multiple possible responses and estimate confidence levels. For a system processing millions of queries daily, this translates to dramatically higher operational costs.&lt;/p&gt;
    &lt;p&gt;More sophisticated approaches like active learning, where AI systems ask clarifying questions to reduce uncertainty, can improve accuracy but further multiply computational requirements. Such methods work well in specialised domains like chip design, where wrong answers cost millions of dollars and justify extensive computation. For consumer applications where users expect instant responses, the economics become prohibitive.&lt;/p&gt;
    &lt;p&gt;The calculus shifts dramatically for AI systems managing critical business operations or economic infrastructure. When AI agents handle supply chain logistics, financial trading or medical diagnostics, the cost of hallucinations far exceeds the expense of getting models to decide whether they‚Äôre too uncertain. In these domains, the paper‚Äôs proposed solutions become economically viable ‚Äì even necessary. Uncertain AI agents will just have to cost more.&lt;/p&gt;
    &lt;p&gt;However, consumer applications still dominate AI development priorities. Users want systems that provide confident answers to any question. Evaluation benchmarks reward systems that guess rather than express uncertainty. Computational costs favour fast, overconfident responses over slow, uncertain ones.&lt;/p&gt;
    &lt;p&gt;Falling energy costs per token and advancing chip architectures may eventually make it more affordable to have AIs decide whether they‚Äôre certain enough to answer a question. But the relatively high amount of computation required compared to today‚Äôs guessing would remain, regardless of absolute hardware costs.&lt;/p&gt;
    &lt;p&gt;In short, the OpenAI paper inadvertently highlights an uncomfortable truth: the business incentives driving consumer AI development remain fundamentally misaligned with reducing hallucinations. Until these incentives change, hallucinations will persist.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45233589</guid></item><item><title>RIP pthread_cancel</title><link>https://eissing.org/icing/posts/rip_pthread_cancel/</link><description>&lt;doc fingerprint="262621567e35bc58"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;RIP pthread_cancel&lt;/head&gt;
    &lt;p&gt;I posted about adding pthread_cancel use in curl about three weeks ago, we released this in curl 8.16.0 and it blew up right in our faces. Now, with #18540 we are ripping it out again. What happened?&lt;/p&gt;
    &lt;head rend="h2"&gt;short recap&lt;/head&gt;
    &lt;p&gt;pthreads define ‚ÄúCancelation points‚Äù, a list of POSIX functions where a pthread may be cancelled. In addition, there is also a list of functions that may be cancelation points, among those &lt;code&gt;getaddrinfo()&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;getaddrinfo()&lt;/code&gt; is exactly what we are interested in for &lt;code&gt;libcurl&lt;/code&gt;. It blocks
until it has resolved a name. That may hang for a long time and &lt;code&gt;libcurl&lt;/code&gt;
is unable to do anything else. Meh. So, we start a pthread and let that
call &lt;code&gt;getaddrinfo()&lt;/code&gt;. &lt;code&gt;libcurl&lt;/code&gt; can do other things while that thread runs.&lt;/p&gt;
    &lt;p&gt;But eventually, we have to get rid of the pthread again. Which means we either have to &lt;code&gt;pthread_join()&lt;/code&gt; it - which means a blocking wait. Or we
call &lt;code&gt;pthread_detach()&lt;/code&gt; - which returns immediately but the thread keeps
on running. Both are bad when you want to do many, many transfers. Either we block and
stall or we let pthreads pile up in an uncontrolled way.&lt;/p&gt;
    &lt;p&gt;So, we added &lt;code&gt;pthread_cancel()&lt;/code&gt; to interrupt a running &lt;code&gt;getaddrinfo()&lt;/code&gt;
and get rid of the pthread we no longer needed. So the theory. And, after
some hair pulling, we got this working.&lt;/p&gt;
    &lt;head rend="h2"&gt;cancel yes, leakage also yes!&lt;/head&gt;
    &lt;p&gt;After releasing curl 8.16.0 we got an issue reported in #18532 that cancelled pthreads leaked memory.&lt;/p&gt;
    &lt;p&gt;Digging into the glibc source shows that there is this thing called &lt;code&gt;/etc/gai.conf&lt;/code&gt;
which defines how &lt;code&gt;getaddrinfo()&lt;/code&gt; should sort returned answers.&lt;/p&gt;
    &lt;p&gt;The implementation in glibc first resolves the name to addresses. For these, it needs to allocate memory. Then it needs to sort them if there is more than one address. And in order to do that it needs to read &lt;code&gt;/etc/gai.conf&lt;/code&gt;. And in order to do that
it calls &lt;code&gt;fopen()&lt;/code&gt; on the file. And that may be a pthread ‚ÄúCancelation Point‚Äù
(and if not, it surely calls &lt;code&gt;open()&lt;/code&gt; which is a required cancelation point).&lt;/p&gt;
    &lt;p&gt;So, the pthread may get cancelled when reading &lt;code&gt;/etc/gai.conf&lt;/code&gt; and leak all
the allocated responses. And if it gets cancelled there, it will try to
read &lt;code&gt;/etc/gai.conf&lt;/code&gt; again the next time it has more than one address
resolved.&lt;/p&gt;
    &lt;p&gt;At this point, I decided that we need to give up on the whole &lt;code&gt;pthread_cancel()&lt;/code&gt;
strategy. The reading of &lt;code&gt;/etc/gai.conf&lt;/code&gt; is one point where a cancelled
&lt;code&gt;getaddrinfo()&lt;/code&gt; may leak. There might be others. Clearly, glibc is not really
designed to prevent leaks here (admittedly, this is not trivial).&lt;/p&gt;
    &lt;head rend="h2"&gt;RIP&lt;/head&gt;
    &lt;p&gt;Leaking memory potentially on something &lt;code&gt;libcurl&lt;/code&gt; does over and over again is
not acceptable. We‚Äôd rather pay the price of having to eventually wait on
a long running &lt;code&gt;getaddrinfo()&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Applications using &lt;code&gt;libcurl&lt;/code&gt; can avoid this by using &lt;code&gt;c-ares&lt;/code&gt; which resolves
unblocking and without the use of threads. But that will not be able to do
everything that glibc does.&lt;/p&gt;
    &lt;p&gt;DNS continues to be tricky to use well.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45233713</guid></item></channel></rss>