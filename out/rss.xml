<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 05 Nov 2025 10:12:32 +0000</lastBuildDate><item><title>By the Power of Grayscale</title><link>https://zserge.com/posts/grayskull/</link><description>&lt;doc fingerprint="362f87793ff11b93"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;By the power of grayscale!&lt;/head&gt;
    &lt;p&gt;When people talk about computer vision, they usually think of OpenCV or deep neural networks like YOLO. But in most cases, doing computer vision implies understanding of the core algorithms, so you can use or adapt them for your own needs.&lt;/p&gt;
    &lt;p&gt;I wanted to see how far I could go by stripping computer vision down to the bare minimum: only grayscale 8-bit images, no fancy data structures, plain old C, some byte arrays and a single header file. After all, an image is just a rectangle of numbers, right?&lt;/p&gt;
    &lt;p&gt;This post is a guided tour through the algorithms behind Grayskull – a minimal computer vision library designed for resource-constrained devices.&lt;/p&gt;
    &lt;head rend="h2"&gt;Pixels&lt;/head&gt;
    &lt;p&gt;A grayscale pixel is normally represented as a single byte, where &lt;code&gt;0&lt;/code&gt; means black, &lt;code&gt;255&lt;/code&gt; means white, and values in between represent various shades of gray.&lt;/p&gt;
    &lt;p&gt;A grayscale image is essentially a 2D array of these pixels, defined by its width and height, but for a simpler memory layout languages such as C often represent it as a 1D array of size &lt;code&gt;width * height&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;// An image of WxH pixels, stored as a flat array of bytes
struct gs_image { unsigned w, h; uint8_t *data; };

// Helpers to get/set pixel values respecting the bounds
uint8_t gs_get(struct gs_image img, unsigned x, unsigned y) {
  return (x &amp;lt; img.w &amp;amp;&amp;amp; y &amp;lt; img.h) ? img.data[y * img.w + x] : 0;
}
void gs_set(struct gs_image img, unsigned x, unsigned y, uint8_t value) {
  if (x &amp;lt; img.w &amp;amp;&amp;amp; y &amp;lt; img.h) img.data[y * img.w + x] = value;
}

// A somewhat convenient macro to iterate over all pixels
#define gs_for(img, x, y)                \
  for (unsigned y = 0; y &amp;lt; (img).h; y++) \
    for (unsigned x = 0; x &amp;lt; (img).w; x++)
&lt;/code&gt;
    &lt;p&gt;This humble start already allows us to do some tricks like inverting or mirroring images:&lt;/p&gt;
    &lt;code&gt;// invert image (negative): px[x,y] = 255 - px[x,y]
gs_for(img, x, y) gs_set(img, x, y, 255 - gs_get(img, x, y));

// mirror the image: swap px[x,y] with px[w-x-1,y]
gs_for(img, x, y) {
for (unsigned y = 0; y &amp;lt; img.h; y++) {
  for (unsigned x = 0; x &amp;lt; img.w/2; x++) { // iterate only through the first half
    uint8_t tmp = gs_get(img, x, y);
    gs_set(img, x, y, gs_get(img, img.w - x - 1, y));
    gs_set(img, img.w - x - 1, y, tmp);
  }
}
&lt;/code&gt;
    &lt;p&gt;We can just as well copy images, crop images, resize or rotate them. It’s not computer vision yet, but still some basic image processing:&lt;/p&gt;
    &lt;code&gt;struct gs_rect { unsigned x, y, w, h; }; // for regions of interest (ROI)

// crop image src into dst using region of interest (roi)
gs_for(roi, x, y) gs_set(dst, x, y, gs_get(src, roi.x + x, roi.y + y));

// downscale 2x: set pixel to average from 4 neighbouring pixels (2x2)
gs_for(dst, x, y) {
    unsigned sum = 0;
    for (unsigned j = 0; j &amp;lt; 2; j++)
      for (unsigned i = 0; i &amp;lt; 2; i++)
        sum += gs_get(src, x * 2 + i, y * 2 + j);
    gs_set(dst, x, y, sum / 4);
}
&lt;/code&gt;
    &lt;p&gt;One can do naïve nearest-neighbour resizing, which is fast but looks blocky, or do bilinear interpolation, which is slower and requires floating point operations, but often looks better:&lt;/p&gt;
    &lt;code&gt;// Nearest-neighbour resize
void gs_resize_nn(struct gs_image dst, struct gs_image src) {
    gs_for(dst, x, y) {
        unsigned sx = x * src.w / dst.w, sy = y * src.h / dst.h;
        gs_set(dst, x, y, gs_get(src, sx, sy));
    }
}

// Bilinear resize
GS_API void gs_resize(struct gs_image dst, struct gs_image src) {
  gs_for(dst, x, y) {
    float sx = ((float)x + 0.5f) * src.w / dst.w, sy = ((float)y + 0.5f) * src.h / dst.h;
    sx = GS_MAX(0.0f, GS_MIN(sx, src.w - 1.0f)), sy = GS_MAX(0.0f, GS_MIN(sy, src.h - 1.0f));
    unsigned sx_int = (unsigned)sx, sy_int = (unsigned)sy;
    unsigned sx1 = GS_MIN(sx_int + 1, src.w - 1), sy1 = GS_MIN(sy_int + 1, src.h - 1);
    float dx = sx - sx_int, dy = sy - sy_int;
    uint8_t c00 = gs_get(src, sx_int, sy_int), c01 = gs_get(src, sx1, sy_int),
            c10 = gs_get(src, sx_int, sy1), c11 = gs_get(src, sx1, sy1);
    uint8_t p = (c00 * (1 - dx) * (1 - dy)) + (c01 * dx * (1 - dy)) + (c10 * (1 - dx) * dy) + (c11 * dx * dy);
    gs_set(dst, x, y, p);
  }
}
&lt;/code&gt;
    &lt;p&gt;Here’s how the original image (left) looks after bilinear resizing (middle) compared to nearest-neighbour resizing (right).&lt;/p&gt;
    &lt;head rend="h2"&gt;Image processing&lt;/head&gt;
    &lt;p&gt;Now that we can manipulate individual pixels, we can start doing more serious image processing.&lt;/p&gt;
    &lt;p&gt;One useful tool is convolutional filters. A filter is a small 2D array (kernel) that is applied to each pixel in the image. The new pixel value is computed as a weighted sum of the neighbouring pixels, where weights are defined by the kernel.&lt;/p&gt;
    &lt;code&gt;void gs_filter(struct gs_image dst, struct gs_image src, struct gs_image kernel, unsigned norm) {
    gs_for(dst, x, y) {
        int sum = 0;
        gs_for(kernel, i, j) {
            sum += gs_get(src, x + i - kernel.w / 2, y + j - kernel.h / 2) * (int8_t)gs_get(kernel, i, j);
        }
        gs_set(dst, x, y, sum / norm);
    }
}
&lt;/code&gt;
    &lt;p&gt;This technique can be used for blurring, sharpening, edge detection and many other effects. Here are some common kernels. Note that they are defined as signed 8-bit integers:&lt;/p&gt;
    &lt;code&gt;// box blur 3x3, all pixels have equal weight
struct gs_image gs_blur_box = {3, 3, (uint8_t *)(int8_t[]){1, 1, 1, 1, 1, 1, 1, 1, 1}};
// gaussian blur 3x3, central pixels have more weight
struct gs_image gs_blur_gaussian = {3, 3, (uint8_t *)(int8_t[]){1, 2, 1, 2, 4, 2, 1, 2, 1}};
// sharpen, enhance edges
struct gs_image gs_sharpen = {3, 3, (uint8_t *)(int8_t[]){0, -1, 0, -1, 5, -1, 0, -1, 0}};
// emboss, make image look "3D"
struct gs_image gs_emboss = {3, 3, (uint8_t *)(int8_t[]){-2, -1, 0, -1, 1, 1, 0, 1, 2}};
&lt;/code&gt;
    &lt;p&gt;Similarly, we can apply Sobel filters, that are useful if we want to detect edges in the image:&lt;/p&gt;
    &lt;code&gt;struct gs_image gs_sobel_x = {3, 3, (uint8_t *)(int8_t[]){-1, 0, 1, -2, 0, 2, -1, 0, 1}};
struct gs_image gs_sobel_y = {3, 3, (uint8_t *)(int8_t[]){1, 2, 1, 0, 0, 0, -1, -2, -1}};

void gs_sobel(struct gs_image dst, struct gs_image src) {
    struct gs_image gx = {src.w, src.h, malloc(src.w * src.h)};
    struct gs_image gy = {src.w, src.h, malloc(src.w * src.h)};
    gs_filter(gx, src, gs_sobel_x, 1);
    gs_filter(gy, src, gs_sobel_y, 1);
    gs_for(dst, x, y) {
        int mag = sqrt(gs_get(gx, x, y) * gs_get(gx, x, y) + gs_get(gy, x, y) * gs_get(gy, x, y));
        gs_set(dst, x, y, GS_MIN(mag, 255));
    }
    free(gx.data);
    free(gy.data);
}
&lt;/code&gt;
    &lt;p&gt;Here are some examples of these filters, notice how some of them remove the noise or enhance the edges:&lt;/p&gt;
    &lt;p&gt;The first image is the original, followed by box filter and Gaussian blur filter. Next is the sharpen filter, then emboss filter and finally Sobel filter that highlights edges.&lt;/p&gt;
    &lt;head rend="h2"&gt;Thresholding&lt;/head&gt;
    &lt;p&gt;To actually “see” objects in an image, we need to segment it into foreground and background, and then operate on the foreground segments, trying to locate objects of interest.&lt;/p&gt;
    &lt;p&gt;This is much easier done when an image is binary, so that each pixel is either fully black or fully white. This conversion from grayscale to black-and-white is called thresholding.&lt;/p&gt;
    &lt;p&gt;In the simplest case we may consider any pixel above 127 white, and below – black. This is fixed-level thresholding. Of course, in darker environments this thresholding value could be too high and many meaningful details would be lost. So how to pick a threshold value more accurately?&lt;/p&gt;
    &lt;code&gt;// apply fixed threshold value and binarise the image
GS_API void gs_threshold(struct gs_image img, uint8_t thresh) {
  for (unsigned i = 0; i &amp;lt; img.w * img.h; i++) img.data[i] = (img.data[i] &amp;gt; thresh) ? 255 : 0;
}
&lt;/code&gt;
    &lt;p&gt;One approach would be to calculate the brightness distribution as a histogram. We know that there are 255 unique values of pixels in a grayscale image, so we iterate through all pixels and count how many of them have this or that value. Analysing the resulting histogram could give us some clue about which pixel value would work best as a threshold for the particular image.&lt;/p&gt;
    &lt;p&gt;A clever way to do this is with Otsu’s method. It automatically determines the optimal threshold by testing every possible value (from 0 to 255). For each value, it splits the image’s pixels into two classes—background and foreground—and calculates their “inter-class variance.” The threshold that maximizes this variance is the one that creates the best separation between the two classes, making it the ideal choice. It works fiarly well on images with good contrast:&lt;/p&gt;
    &lt;code&gt;// try to find the best threshold to separate "foreground" from "background"
uint8_t gs_otsu_threshold(struct gs_image img) {
  unsigned hist[256] = {0}, wb = 0, wf = 0, threshold = 0;
  // calculate how many pixels of each brightness value we have
  for (unsigned i = 0; i &amp;lt; img.w * img.h; i++) hist[img.data[i]]++;
  float sum = 0, sumB = 0, varMax = -1.0;
  for (unsigned i = 0; i &amp;lt; 256; i++) sum += (float)i * hist[i];
  // try to find the threshold that maximises inter-class variance
  for (unsigned t = 0; t &amp;lt; 256; t++) {
    wb += hist[t];
    if (wb == 0) continue;
    wf = (img.w * img.h) - wb;
    if (wf == 0) break;
    sumB += (float)t * hist[t];
    float mB = (float)sumB / wb;
    float mF = (float)(sum - sumB) / wf;
    float varBetween = (float)wb * (float)wf * (mB - mF) * (mB - mF);
    if (varBetween &amp;gt; varMax) varMax = varBetween, threshold = t;
  }
  return threshold;
}
&lt;/code&gt;
    &lt;p&gt;In real life, however, the lighting conditions are often uneven. In such cases a single global threshold may not work well, and neither of the possible 255 threshold values would give a good result.&lt;/p&gt;
    &lt;p&gt;To address this, we can use adaptive thresholding. Instead of using a single threshold for the entire image, we compute a local threshold for each pixel based on the average brightness of its neighbouring pixels. This way, we can better handle varying lighting conditions across the image:&lt;/p&gt;
    &lt;code&gt;gs_for(src, x, y) {
  unsigned sum = 0, count = 0;
  for (int dy = -radius; dy &amp;lt;= (int)radius; dy++) {
    for (int dx = -radius; dx &amp;lt;= (int)radius; dx++) {
      int sy = (int)y + dy, sx = (int)x + dx;
      if (sy &amp;gt;= 0 &amp;amp;&amp;amp; sy &amp;lt; (int)src.h &amp;amp;&amp;amp; sx &amp;gt;= 0 &amp;amp;&amp;amp; sx &amp;lt; (int)src.w) {
        sum += gs_get(src, sx, sy);
        count++;
      }
    }
  }
  int threshold = sum / count - c;
  gs_set(dst, x, y, (gs_get(src, x, y) &amp;gt; threshold) ? 255 : 0);
}
&lt;/code&gt;
    &lt;p&gt;Compare how various thresholding approaches work on the same image:&lt;/p&gt;
    &lt;p&gt;The first image is the original, followed by fixed-level thresholding (80), then Otsu’s method and adaptive thresholding. Notice how adaptive thresholding preserves more details in both bright and dark areas of the image, while Otsu’s method struggles with uneven lighting.&lt;/p&gt;
    &lt;head rend="h2"&gt;Morphological operations&lt;/head&gt;
    &lt;p&gt;Due to the way how image sensors work in cameras, images often contain noise.&lt;/p&gt;
    &lt;p&gt;This means that after thresholding there would be random individual pixels that do not belong to any object, or small holes in objects, or small gaps between object parts. All of this will confuse the object detection algorithms, but morphological operations can help to clean up the binary image.&lt;/p&gt;
    &lt;p&gt;Two most common operations are erosion and dilation. Erosion removes pixels on object boundaries (shrinking the objects), while dilation adds pixels to their boundaries (expanding the objects).&lt;/p&gt;
    &lt;p&gt;There is also opening (erosion followed by dilation) and closing (dilation followed by erosion). Opening is useful for removing small objects or noise, while closing is useful for filling small holes in objects.&lt;/p&gt;
    &lt;code&gt;void gs_erode(struct gs_image dst, struct gs_image src, unsigned radius) {
  gs_for(dst, x, y) {
    uint8_t min_val = 255;
    for (int dy = -radius; dy &amp;lt;= (int)radius; dy++) {
      for (int dx = -radius; dx &amp;lt;= (int)radius; dx++) {
        int sy = (int)y + dy, sx = (int)x + dx;
        if (sy &amp;gt;= 0 &amp;amp;&amp;amp; sy &amp;lt; (int)src.h &amp;amp;&amp;amp; sx &amp;gt;= 0 &amp;amp;&amp;amp; sx &amp;lt; (int)src.w) {
          uint8_t val = gs_get(src, sx, sy);
          if (val &amp;lt; min_val) min_val = val;
        }
      }
    }
    gs_set(dst, x, y, min_val);
  }
}
void gs_dilate(struct gs_image dst, struct gs_image src, unsigned radius) {
  gs_for(dst, x, y) {
    uint8_t max_val = 0;
    for (int dy = -radius; dy &amp;lt;= (int)radius; dy++) {
      for (int dx = -radius; dx &amp;lt;= (int)radius; dx++) {
        int sy = (int)y + dy, sx = (int)x + dx;
        if (sy &amp;gt;= 0 &amp;amp;&amp;amp; sy &amp;lt; (int)src.h &amp;amp;&amp;amp; sx &amp;gt;= 0 &amp;amp;&amp;amp; sx &amp;lt; (int)src.w) {
          uint8_t val = gs_get(src, sx, sy);
          if (val &amp;gt; max_val) max_val = val;
        }
      }
    }
    gs_set(dst, x, y, max_val);
  }
}
&lt;/code&gt;
    &lt;p&gt;Here’s how morphological operations can clean up a rather confusing image with ArUco markers:&lt;/p&gt;
    &lt;p&gt;The first image is the original, followed by thresholded image (Otsu). Next we do erosion followed by dilation. Since the markers are black it might sound odd, but since morpological operations work on white pixels we essentially perform closing, but for black pixels. We could also invert the image first, then do opening and invert back.&lt;/p&gt;
    &lt;p&gt;At the end all markers are shrinked to their original dimensions and all of them are easily detectable by shape and size.&lt;/p&gt;
    &lt;head rend="h2"&gt;Blobs and contours&lt;/head&gt;
    &lt;p&gt;Once we have a clean binary image, we can start detecting objects in it. A classic way to do this is by finding connected components (blobs).&lt;/p&gt;
    &lt;p&gt;A “blob” is a group of connected white pixels (255) that form an object. The simplest way to find blobs is by using a flood-fill algorithm or depth-first search (DFS) to label connected pixels:&lt;/p&gt;
    &lt;code&gt;void gs_flood_fill(struct gs_image img, unsigned x, unsigned y, uint8_t target, uint8_t replacement) {
  if (x &amp;gt;= img.w || y &amp;gt;= img.h) return;
  if (gs_get(img, x, y) != target || gs_get(img, x, y) == replacement) return;
  gs_set(img, x, y, replacement);
  gs_flood_fill(img, x + 1, y, target, replacement);
  gs_flood_fill(img, x - 1, y, target, replacement);
  gs_flood_fill(img, x, y + 1, target, replacement);
  gs_flood_fill(img, x, y - 1, target, replacement);
}
&lt;/code&gt;
    &lt;p&gt;Of course this would immediately blow up your stack on most real-life images. So an iterative approach using a queue or stack is preferred.&lt;/p&gt;
    &lt;p&gt;However, it’s still a fairly suboptimal way to find blobs. A more efficient approach is a two-pass algorithm, which scans the image twice: first to assign “provisional” labels and record equivalences between them, followed by the second scan to resolve these equivalences and assign final unique labels to every blob.&lt;/p&gt;
    &lt;p&gt;It would be nice if we could use the same &lt;code&gt;gs_image&lt;/code&gt; type for labels, but in most cases it would require more than 256 labels (especially for temporary provisional labels). So we need a separate array of larger integers to store labels:&lt;/p&gt;
    &lt;code&gt;typedef uint16_t gs_label; // 64K should be enough, right?

struct gs_blob {
  gs_label label; // what label the blob has?
  unsigned area; // how many white pixels are in a blob?
  struct gs_rect box; // bounding box
  struct gs_point centroid; // center of "mass"
};
unsigned gs_blobs(struct gs_image img, gs_label *labels, struct gs_blob *blobs, unsigned nblobs) { ... }
&lt;/code&gt;
    &lt;p&gt;Before we go futher, let’s talk about connectivity. There are two common types of pixel connectivity: 4-connectivity and 8-connectivity. In 4-connectivity, a pixel is connected to its four direct neighbours (up, down, left, right). In 8-connectivity, a pixel is connected to all eight surrounding pixels (including diagonals). So, in case of 8-connectivity this would be one blob and in case of 4-connectivity - two separate blobs:&lt;/p&gt;
    &lt;code&gt;......
.#..#.
.##.#.
.###..
......
&lt;/code&gt;
    &lt;p&gt;We will be using 4-connectivity in our implementation, for simplicity. Let’s consider the following image:&lt;/p&gt;
    &lt;code&gt;.........
.###..#..
.###.##..
.#####..#
.......##
&lt;/code&gt;
    &lt;p&gt;We start scanning it row after row, if a white pixel is found, we check its left and top neighbours:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If both are black (0), we assign a new label to the pixel, assuming that it could be a new blob.&lt;/item&gt;
      &lt;item&gt;If one of them is white, we assign its label to the current pixel, as it is a continuation of the existing known blob.&lt;/item&gt;
      &lt;item&gt;If both are white but have different labels, we assign the smallest of the labels to the current pixel and record the equivalence between the two labels in a special data structure (like a union-find).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;After this first pass the labels array would look like this:&lt;/p&gt;
    &lt;code&gt;.........
.111..2..
.111.32..
.11111..4
.......55
&lt;/code&gt;
    &lt;p&gt;Our equivalence table would look like this: &lt;code&gt;1 &amp;lt;-&amp;gt; 3, 3 &amp;lt;-&amp;gt; 2, 4 &amp;lt;-&amp;gt; 5&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;During the second pass we resolve the equivalences and assign final labels to each pixel. The final labels array would look like this:&lt;/p&gt;
    &lt;code&gt;.........
.111..1..
.111.11..
.11111..4
.......44
&lt;/code&gt;
    &lt;p&gt;During the second pass we can also calculate blob properties, such as area, bounding box and centroid. Largest blob’s area is 14 pixels, bounding box is from (1,1) to (6,3). Centroid is calculated as the average of all pixel coordinates in the blob, in our case for X it would be &lt;code&gt;(3*1+3*2+3*3+4+2*5+2*6)/14&lt;/code&gt;, or rounded to 4. Y coordinate would be &lt;code&gt;(4*1+5*2+5*3)/14&lt;/code&gt;, or rounded to 2. So the centroid is (4,2), which is not part of the blob “body”, but still is the center of mass.&lt;/p&gt;
    &lt;p&gt;Such geometric properties already give us plenty of information about blobs. For example, we can filter blobs by area to remove small noise blobs. We can also calculate aspect ratio (width/height) of the bounding box to filter out very tall or very wide blobs. Ratio between blob actual area and bounding box area helps to filter out blobs that are not compact enough. Rectangles tend to have a ratio of &lt;code&gt;1.0&lt;/code&gt;, circles are &lt;code&gt;pi/4 = 0.785&lt;/code&gt;, while lines approach to zero.&lt;/p&gt;
    &lt;p&gt;Another clues could be centroid position, orientation using moments or contour shape. There is a fairly simple method to trace a contour of a blob using the Moore-Neighbor tracing algorithm. It starts from a known border pixel and follows the contour clockwise by checking neighbouring pixels, until it returns to the starting pixel:&lt;/p&gt;
    &lt;code&gt;struct gs_contour { struct gs_rect box; struct gs_point start; unsigned length; };
void gs_trace_contour(struct gs_image img, struct gs_image visited, struct gs_contour *c) {
  static const int dx[] = {1, 1, 0, -1, -1, -1, 0, 1};
  static const int dy[] = {0, 1, 1, 1, 0, -1, -1, -1};
  c-&amp;gt;length = 0;
  c-&amp;gt;box = (struct gs_rect){c-&amp;gt;start.x, c-&amp;gt;start.y, 1, 1};
  struct gs_point p = c-&amp;gt;start;
  unsigned dir = 7, seenstart = 0;
  for (;;) {
    if (!visited.data[p.y * visited.w + p.x]) c-&amp;gt;length++;
    visited.data[p.y * visited.w + p.x] = 255;
    int ndir = (dir + 1) % 8, found = 0;
    for (int i = 0; i &amp;lt; 8; i++) {
      int d = (ndir + i) % 8, nx = p.x + dx[d], ny = p.y + dy[d];
      if (nx &amp;gt;= 0 &amp;amp;&amp;amp; nx &amp;lt; (int)img.w &amp;amp;&amp;amp; ny &amp;gt;= 0 &amp;amp;&amp;amp; ny &amp;lt; (int)img.h &amp;amp;&amp;amp;
          img.data[ny * img.w + nx] &amp;gt; 128) {
        p = (struct gs_point){nx, ny};
        dir = (d + 6) % 8;
        found = 1;
        break;
      }
    }
    if (!found) break;  // open contour
    c-&amp;gt;box.x = GS_MIN(c-&amp;gt;box.x, p.x);
    c-&amp;gt;box.y = GS_MIN(c-&amp;gt;box.y, p.y);
    c-&amp;gt;box.w = GS_MAX(c-&amp;gt;box.w, p.x - c-&amp;gt;box.x + 1);
    c-&amp;gt;box.h = GS_MAX(c-&amp;gt;box.h, p.y - c-&amp;gt;box.y + 1);
    if (p.x == c-&amp;gt;start.x &amp;amp;&amp;amp; p.y == c-&amp;gt;start.y) {
      if (seenstart) break;
      seenstart = 1;
    }
  }
}
&lt;/code&gt;
    &lt;p&gt;This way we can extract contours for each blob and analyse their shapes or compare contour length (perimeter) to the blob area. It is also possible to approximate contours with straight lines using Douglas-Peucker algirithm, which replaces a curve with a series of straight line segments, while preserving the overall shape.&lt;/p&gt;
    &lt;p&gt;All of this is good if we want to detect simple objects in a static image. But what if we want to detect or track more complex objects, like faces, cars or pedestrians?&lt;/p&gt;
    &lt;head rend="h2"&gt;Keypoints and descriptors&lt;/head&gt;
    &lt;p&gt;A keypoint is a specific location in an image that is distinctive and can be reliably detected no matter what scale, rotation or lighting of the object are.&lt;/p&gt;
    &lt;p&gt;In practice, keypoints are often corners (also known as “features”). One of the most intuitive algorithms to detect features is FAST (Features from Accelerated Segment Test). It works by examining a circle of 16 pixels around a candidate pixel (4 pixels away from it). If at least 9 of contiguous pixels in this &lt;code&gt;r=4px&lt;/code&gt; circle around pixel &lt;code&gt;P&lt;/code&gt; are all brighter or all darker - then the candidate pixel is considered a corner:&lt;/p&gt;
    &lt;code&gt;..............
......012.....
.....F...3....
....E.....4...
....D..P..5...
....C.....6...
.....B...7....
......A98.....
..............
&lt;/code&gt;
    &lt;p&gt;As simple as it gets, this approach finds too many features in real-life images. A solution is to keep “score” of each feature and only keep the points with the highest score. The score can be calculated as the sum of absolute differences between the candidate pixel and the contiguous pixels in the circle, or by the minimum difference between central pixel and the pixels on the circle.&lt;/p&gt;
    &lt;code&gt;  gs_assert(gs_valid(img) &amp;amp;&amp;amp; kps &amp;amp;&amp;amp; nkps &amp;gt; 0);
  static const int dx[16] = {0, 1, 2, 3, 3, 3, 2, 1, 0, -1, -2, -3, -3, -3, -2, -1};
  static const int dy[16] = {-3, -3, -2, -1, 0, 1, 2, 3, 3, 3, 2, 1, 0, -1, -2, -3};
  unsigned n = 0;
  // first pass: compute score map
  for (unsigned y = 3; y &amp;lt; img.h - 3; y++) {
    for (unsigned x = 3; x &amp;lt; img.w - 3; x++) {
      uint8_t p = img.data[y * img.w + x];
      int run = 0, score = 0;
      for (int i = 0; i &amp;lt; 16 + 9; i++) {
        int idx = (i % 16);
        uint8_t v = img.data[(y + dy[idx]) * img.w + (x + dx[idx])];
        if (v &amp;gt; p + threshold) {
          run = (run &amp;gt; 0) ? run + 1 : 1;
        } else if (v &amp;lt; p - threshold) {
          run = (run &amp;lt; 0) ? run - 1 : -1;
        } else {
          run = 0;
        }
        if (run &amp;gt;= 9 || run &amp;lt;= -9) {
          score = 255;
          for (int j = 0; j &amp;lt; 16; j++) {
            int d = gs_get(img, x + dx[j], y + dy[j]) - p;
            if (d &amp;lt; 0) d = -d;
            if (d &amp;lt; score) score = d;
          }
          break;
        }
      }
      scoremap.data[y * img.w + x] = score;
    }
  }
  // second pass: non-maximum suppression
  for (unsigned y = 3; y &amp;lt; img.h - 3; y++) {
    for (unsigned x = 3; x &amp;lt; img.w - 3; x++) {
      int s = scoremap.data[y * img.w + x], is_max = 1;
      if (s == 0) continue;
      for (int yy = -1; yy &amp;lt;= 1 &amp;amp;&amp;amp; is_max; yy++) {
        for (int xx = -1; xx &amp;lt;= 1; xx++) {
          if (xx == 0 &amp;amp;&amp;amp; yy == 0) continue;
          if (scoremap.data[(y + yy) * img.w + (x + xx)] &amp;gt; s) {
            is_max = 0;
            break;
          }
        }
      }
      if (is_max &amp;amp;&amp;amp; n &amp;lt; nkps) kps[n++] = (struct gs_keypoint){{x, y}, (unsigned)s, 0, {0}};
    }
  }
  return n;
}
&lt;/code&gt;
    &lt;p&gt;Notice how keypoints are detected on corners and distinctive features of the cat image, such as eyes, nose, whiskers and other “meaningful” corners. But how to use keypoints to detect objects?&lt;/p&gt;
    &lt;p&gt;This is where ORB enters the stage. ORB builds on top of the same FAST corner detector, it tries to find sharp intensity changes, but also adds two more components: orientation and descriptor.&lt;/p&gt;
    &lt;p&gt;Once the corners are found, ORB estimates their orientation by calculating image moments in a small patch around each keypoint. This way, each keypoint gets an angle, basically saying which way is “up” for this keypoint.&lt;/p&gt;
    &lt;p&gt;Then comes the descriptor. A descriptor is a compact representation of the local image patch around the keypoint, designed to be invariant to scale and rotation. ORB uses a modified version of BRIEF (Binary Robust Independent Elementary Features) descriptor, which is a clever way to encode image patch as a small bit string.&lt;/p&gt;
    &lt;p&gt;It simply compares bit intensities, if one pixel is lighter than another, it sets the corresponding bit to &lt;code&gt;1&lt;/code&gt;, otherwise to &lt;code&gt;0&lt;/code&gt;. By performing multiple such comparisons, we can create a binary string that represents the local image patch.&lt;/p&gt;
    &lt;p&gt;The descriptor is 256 bit long, and for each of the 256 “samples” we pick two sampling points within the patch area using some pseudo-random lookup table and encode the following bit as 0 or 1 depending on the pixel relative values.&lt;/p&gt;
    &lt;p&gt;Comparing keypoints becomes trivial, we simply XOR two bitstrings and count the bits.&lt;/p&gt;
    &lt;p&gt;Since keypoints are agnostic to rotation and lighting conditions, we can use them to detect objects in various scenarios.&lt;/p&gt;
    &lt;p&gt;One last addition to this algorithm is to resize/scale the image multiple times and detect keypoints at different scales. This way we can detect objects that are closer or further away from the camera, rotated at any angle, or partially occluded.&lt;/p&gt;
    &lt;head rend="h2"&gt;LBP Cascades&lt;/head&gt;
    &lt;p&gt;While keypoints and descriptors are great for detecting arbitrary objects, sometimes we need a more specialised approach for specific object types, like faces, vehicles, or hand gestures. This is where cascade classifiers, famously used in the Viola-Jones object detection framework, come into play.&lt;/p&gt;
    &lt;p&gt;Instead of complex Haar-like features used by Viola and Jones, we can use something simpler: Local Binary Patterns (LBP). LBP is a powerful texture descriptor. For each pixel, it looks at its 8 neighbours. If a neighbour is brighter than the central pixel, we write a ‘1’, otherwise a ‘0’. This gives us an 8-bit number that describes the local texture.&lt;/p&gt;
    &lt;p&gt;The “cascade” is a series of simple classifiers, or “stages”. Each stage looks at a sub-window of the image and uses a few LBP features to decide if that window could possibly contain the object of interest (e.g., a face).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If the sub-window fails the test at any stage, it’s immediately rejected. This is very fast.&lt;/item&gt;
      &lt;item&gt;Only if a sub-window passes all stages is it classified as a positive detection.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This structure allows the classifier to quickly discard the vast majority of the image, focusing computational power only on promising regions. By sliding this detection window across the entire image (and across multiple scales), we can find objects of a specific, pre-trained class. Grayskull provides a pre-trained frontal face detector that uses this exact technique.&lt;/p&gt;
    &lt;p&gt;Here you can see the LBP cascade classifier in action, successfully detecting Sir Gary Oldman in all variety of his faces. The picture on the left uses minimum number of neighbours set to 4, while the right one uses 14. This means the left image detects more faces, but also has more false positives, while the right one is more conservative and only detect camera-facing images with no visual obstructions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;We’ve taken a journey from the humble pixel to sophisticated object detection, all using simple C structures and fundamental algorithms. We tried to manipulate pixels, apply filters to enhance images, segment objects using thresholding, and clean them up. We then learned to find and analyze blobs, detect robust keypoints with FAST and ORB, and finally, use LBP cascades for specialized object detection.&lt;/p&gt;
    &lt;p&gt;This is the core philosophy of Grayskull: to demystify computer vision by providing a minimal, dependency-free, and understandable toolkit. It proves that you don’t always need massive libraries or deep learning frameworks to achieve decent results, especially on resource-constrained systems.&lt;/p&gt;
    &lt;p&gt;An image is indeed just a rectangle of numbers, and with a bit of algorithmic knowledge, you have the power to make it see. As always, I encourage you to check out the repository, experiment with the code, and maybe even try building your own simple CV project!&lt;/p&gt;
    &lt;p&gt;I hope you’ve enjoyed this article. You can follow – and contribute to – on Github, Mastodon, Twitter or subscribe via rss.&lt;/p&gt;
    &lt;p&gt;Oct 26, 2025&lt;/p&gt;
    &lt;p&gt;See also: Étude in C minor and more.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45771151</guid><pubDate>Fri, 31 Oct 2025 12:11:03 +0000</pubDate></item><item><title>Intervaltree with Rust Back End</title><link>https://github.com/Athe-kunal/intervaltree_rs</link><description>&lt;doc fingerprint="1a5b32fdd0e4e110"&gt;
  &lt;main&gt;
    &lt;p&gt;This crate exposes an interval tree implementation written in Rust to Python via PyO3. The Python wrapper provides the ability to build a tree from tuples, insert additional intervals, search for overlaps, and delete intervals by their &lt;code&gt;(left, right)&lt;/code&gt; key.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Rust toolchain (for compiling the extension module)&lt;/item&gt;
      &lt;item&gt;Python 3.8+&lt;/item&gt;
      &lt;item&gt;maturin for building/installing the package&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;python -m venv .venv
source .venv/bin/activate
pip install maturin
maturin develop&lt;/code&gt;
    &lt;p&gt;You can install the package with (also with uv)&lt;/p&gt;
    &lt;code&gt;pip install intervaltree_rs
&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;maturin develop&lt;/code&gt; builds the extension module in-place and installs it into the active virtual environment, making it importable as &lt;code&gt;intervaltree_rs&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Once installed, you can use the interval tree directly from Python:&lt;/p&gt;
    &lt;code&gt;from intervaltree_rs import IntervalTree

# Build a tree from tuples: (left, right, payload)
intervals = [
    (5, 10, "a"),
    (12, 18, "b"),
    (1, 4, "c"),
]
tree = IntervalTree.from_tuples(intervals)

# Insert another interval
tree.insert((8, 11, "d"))

# Search for overlaps. Inclusive bounds are enabled by default.
hits = tree.search(9, 10)
for left, right, value in hits:
    print(left, right, value)

# Delete by the interval key
removed = tree.delete((12, 18))
print("Removed:", removed)&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;IntervalTree.search(ql, qr, inclusive=True)&lt;/code&gt; accepts an &lt;code&gt;inclusive&lt;/code&gt; flag. Set it to &lt;code&gt;False&lt;/code&gt; to perform exclusive range queries.&lt;/p&gt;
    &lt;p&gt;To build a wheel that you can distribute or upload to PyPI, run:&lt;/p&gt;
    &lt;code&gt;maturin build --release&lt;/code&gt;
    &lt;p&gt;The built wheels will be placed under &lt;code&gt;target/wheels/&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The Python bindings are covered by Rust unit tests. Run them with:&lt;/p&gt;
    &lt;code&gt;cargo test&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45788385</guid><pubDate>Sun, 02 Nov 2025 07:04:59 +0000</pubDate></item><item><title>Building blobd: single-machine object store with sub-ms reads and 15 GB/s upload</title><link>https://blog.wilsonl.in/blobd/</link><description>&lt;doc fingerprint="a6da511d29868b81"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Building blobd: single-machine object store with sub-millisecond reads and 15 GB/s uploads&lt;/head&gt;
    &lt;p&gt;For a past content platform, I used S3 for serving user content videos and documents, where there were lots of small range requests for streaming and seeking. Despite serving from same-region datacenters 2 ms from the user, S3 would take 30-200 ms to respond to each request. Even slight delays when jumping around quickly felt grating, and in UX every millisecond counts.&lt;/p&gt;
    &lt;p&gt;S3 also felt suboptimal for small objects, like thumbnails. They have the same high TTFB as large objects, and the overhead of requests begins to dominate in terms of throughput, pricing, and rate limits. For example, a dynamic webpage may have hundreds of thumbnails that need to be shown quickly. That might mean 100 billed &lt;code&gt;GetObject&lt;/code&gt; calls, saturating S3 rate limits and internal connections 100x faster for a single page, and still feel unresponsive since users will decide and scroll past most in a few milliseconds. At small sizes, the time handling requests dominates the actual transfer time.&lt;/p&gt;
    &lt;p&gt;To improve on this, I set out to build a new object store from scratch optimized for a lot of low-latency random reads and small objects. It would be interesting to experiment with newer ideas:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Leverage newer things like io_uring, async Rust, and atomic writes.&lt;/item&gt;
      &lt;item&gt;I did not need to enumerate keys, so could I avoid tree-based data structures to gain constant time lookups?&lt;/item&gt;
      &lt;item&gt;Given bare metal hardware, could we use block devices and direct I/O, bypassing filesystems and kernel caches?&lt;/item&gt;
      &lt;item&gt;As any critical low-level system, keep it as simple as possible to set up, operate, and understand.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In terms of design trade offs, the object store would prioritize reads over writes. For writes, I prioritized creates over updates, and updates over deletes. Read performance should focus on latency, ensuring low constant latency regardless of object size or read offset/length. These fit the typical user content platform, where reads are more frequent and performance-sensitive than writes, and content typically grows over time — updates and deletes are rarer compared to creation.&lt;/p&gt;
    &lt;p&gt;From the physical limits perspective, modern NVMe SSDs can do hundreds of thousands of random I/O reads per second, and local DCs are just 1-5 ms from the user. How close can the object store get to these raw numbers?&lt;/p&gt;
    &lt;p&gt;In this blog post, I'll go over the design decisions and process of blobd with explanations for concepts, an open source object store built from scratch around these principles. I'll also go over the benchmarks, which show strong performance: on a system with eight 1.8 GB/s write NVMe SSDs, it saturates underlying disks when uploading, exceeding 15 GB/s:&lt;/p&gt;
    &lt;p&gt;Then, when doing random 4K reads across these objects, it achieves sub-millisecond time-to-first-byte, regardless of object size:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="8"&gt;
        &lt;cell role="head"&gt;Store&lt;/cell&gt;
        &lt;cell role="head"&gt;12.0 KB object size&lt;/cell&gt;
        &lt;cell role="head"&gt;77.0 KB&lt;/cell&gt;
        &lt;cell role="head"&gt;338 KB&lt;/cell&gt;
        &lt;cell role="head"&gt;1.4 MB&lt;/cell&gt;
        &lt;cell role="head"&gt;3.8 MB&lt;/cell&gt;
        &lt;cell role="head"&gt;9.7 MB&lt;/cell&gt;
        &lt;cell role="head"&gt;30.5 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;blobd&lt;/cell&gt;
        &lt;cell&gt;0.330 ms&lt;/cell&gt;
        &lt;cell&gt;0.339&lt;/cell&gt;
        &lt;cell&gt;0.380&lt;/cell&gt;
        &lt;cell&gt;0.360&lt;/cell&gt;
        &lt;cell&gt;0.413&lt;/cell&gt;
        &lt;cell&gt;0.553&lt;/cell&gt;
        &lt;cell&gt;0.767&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;minio&lt;/cell&gt;
        &lt;cell&gt;66.404 ms&lt;/cell&gt;
        &lt;cell&gt;69.126&lt;/cell&gt;
        &lt;cell&gt;85.882&lt;/cell&gt;
        &lt;cell&gt;105.755&lt;/cell&gt;
        &lt;cell&gt;104.941&lt;/cell&gt;
        &lt;cell&gt;195.205&lt;/cell&gt;
        &lt;cell&gt;100.248&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Turbostore&lt;/head&gt;
    &lt;p&gt;For the month of March 2022, I experimented with implementing a new object store called Turbostore written in C.&lt;/p&gt;
    &lt;p&gt;I only required point lookups and did not need to list objects. Listing typically requires tree-like data structures that have logarithmic time lookups, and some complexity from rebalancing. Without needing this, would it be possible to design an alternate simple object store and achieve constant low latency?&lt;/p&gt;
    &lt;p&gt;I decided to start with a basic design:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reserve a block device as the raw "canvas" to design this object store on top of, bypassing any filesystem design and overhead.&lt;/item&gt;
      &lt;item&gt;Incorporate three core components: a "heap" to allocate space for objects, an index to look up objects and map to their heap address, and a journal to safely write critical state.&lt;/item&gt;
      &lt;item&gt;Pick or design an algorithm to allocate and deallocate space from the heap.&lt;/item&gt;
      &lt;item&gt;Use memory mapping to read and write using direct pointer arithmetic with automatic kernel paging and caching, simplifying operating over structured metadata on disk.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The disk layout would be simple: reserve space at the start for the journal, allocator state, and index, and use the remaining space for the heap. Each object would have metadata ("inode") and data: the data would be the actual value, while its inode would contain its key, size, version, heap address, etc. Since such metadata would itself be variable-length, it will use the same heap and allocation system to dynamically allocate space on disk for them to reside at.&lt;/p&gt;
    &lt;head rend="h3"&gt;Index&lt;/head&gt;
    &lt;p&gt;The index maps keys to where their allocated object inode resides on disk. All operations involving objects interact with the index, so its design largely determines performance characteristics of the system. Specifically for reads, after looking up an object's location in the index, reading it from disk typically becomes I/O-bound, so focusing on the index is key to increasing reads per second and TTFB, our goals.&lt;/p&gt;
    &lt;p&gt;Most databases use a tree as their index, as opposed to a hash map. The primary benefit is the ability to iterate by keys in order. However, I typically access objects via some key derived from an ID that exists elsewhere. For example, if a user requests a video, its ID is in the DB and its object key is statically mapped to &lt;code&gt;videos/$ID/1080p.mp4&lt;/code&gt;. To list, I &lt;code&gt;SELECT&lt;/code&gt; from the DB, not ListObjectsV2 from S3. So the set of objects that exist is known and enumerating is not needed.&lt;/p&gt;
    &lt;p&gt;A second reason systems often prefer trees is their ability to grow without needing a full rewrite. Expanding a hash map requires rehashing everything, expensive for I/O. Hash maps also have O(n) worst case performance, whereas trees guarantee O(log n).&lt;/p&gt;
    &lt;p&gt;However, I tried to think how a hash-based index could work well.&lt;/p&gt;
    &lt;p&gt;A fixed hash map with chaining is very easy to use: each bucket is a pointer, and inserting and removing elements involves simple pointer updates; the performance is guaranteed by the bucket size and hash function. With a tree, each node has a more complex structure, and the logic for rebalancing can get complicated, but it is necessary to ensure logarithmic performance.&lt;/p&gt;
    &lt;p&gt;The argument that resizing hash indices is expensive makes sense in theory. However, what are the numbers here? The size of hash indices is proportional to how many elements (in this case, objects) you want it to be able to store. The amount of objects you can have is inversely proportional to object size. For example, given a large 64 TB disk:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Content&lt;/cell&gt;
        &lt;cell role="head"&gt;Typical size&lt;/cell&gt;
        &lt;cell role="head"&gt;Capacity&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Image&lt;/cell&gt;
        &lt;cell&gt;128 KB&lt;/cell&gt;
        &lt;cell&gt;537 million&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;2 MB&lt;/cell&gt;
        &lt;cell&gt;34 million&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Audio&lt;/cell&gt;
        &lt;cell&gt;10 MB&lt;/cell&gt;
        &lt;cell&gt;7 million&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Video&lt;/cell&gt;
        &lt;cell&gt;200 MB&lt;/cell&gt;
        &lt;cell&gt;336 thousand&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Given that most object stores store large blobs, as opposed to small records seen in KV stores and relational databases, it's possible that the absolute numbers aren't so high such that you could simply preallocate a very large fixed hash index, and avoid the issues around O(n) degradation and expensive resizes. Continuing the example, if we assume a mixed workload (e.g. user content), an upper bound might be 30 million objects. If each bucket pointer occupies 6 bytes, and we overprovision by 4x and use 120 million buckets, that's 687 MB, or 0.001% of the disk space. This makes sense — if objects are 2 MB, then 6×4 bytes per object is insignificant. Even at 500×3 million buckets, that's 8.4 GB, or 0.01% of disk space.&lt;/p&gt;
    &lt;p&gt;I did a quick empirical test by hashing all 4 million paths from &lt;code&gt;find /&lt;/code&gt; into 12 million buckets (3x) using xxhash3_64 and found that 4% required more than 1 hop, 0.5% more than 2, and 72% of buckets were empty, close to the optimal 67%. The total size of the buckets was only 69 MB.&lt;/p&gt;
    &lt;p&gt;The O(1) lookups is likely more beneficial here than for in-memory data structures, because disk latency is much higher than memory, and each node traversal in a tree requires another roundtrip to disk. &lt;code&gt;log(30e6)&lt;/code&gt; is about 17; assuming EBS latency of 1 ms, that could mean 17 ms and 17 read operations just to find the object on disk. This saturates IOPS quicker, and 17 ms can be significant if you're fetching multiple objects, doing things like media streaming or edge cache serving, or working as part of a larger system. For the hash index, it's so small that it can fit entirely in memory, and jumps directly to the location on disk almost all the time (tunable via hash index size).&lt;/p&gt;
    &lt;p&gt;So in Turbostore, a hash index with a configurable amount of buckets is used. On disk, it is stored as an array of bucket pointers. In memory, one read-write lock exists per bucket, which covers both the bucket state (linked list) as well as any objects (inode + data) in it. How it interacts with each operation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Create: the object is not added to the index initially, and doesn't lock or update any bucket. Instead, an inode is constructed on disk but unattached.&lt;/item&gt;
      &lt;item&gt;Write: the client passes the unique handle identifying the dangling inode's location directly, so no locking is necessary. The allocated space is guaranteed exclusive use for the creation, and won't be freed or overwritten by anyone else.&lt;/item&gt;
      &lt;item&gt;Commit/Delete: a write lock is acquired on the bucket in order to modify the linked list as well as potentially objects in it.&lt;/item&gt;
      &lt;item&gt;Read: a read lock is acquired on the bucket, to ensure that the linked list or inode metadata won't be changed when reading them, and that allocated space for the object won't get released and then overwritten while being read. To avoid long-held locks or starving deletes, the lock is released as soon as the &lt;code&gt;send&lt;/code&gt;buffer is full and not the entire requested range, which means the process starts from the beginning for every&lt;code&gt;send&lt;/code&gt;chunk for correctness.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;While locking a bucket could theoretically lock more than one object, we expect one utilized bucket to equal one object almost all the time.&lt;/p&gt;
    &lt;head rend="h3"&gt;Allocation algorithm&lt;/head&gt;
    &lt;p&gt;With the index in place, we need a subsystem to allocate space for objects on the device to point index entries (object keys) to.&lt;/p&gt;
    &lt;p&gt;The simplest way to allocate is to give the exact bytes requested. The problem is external fragmentation: future allocations rarely match existing "holes". Over time, this degrades to a lot of free space in total but no large enough contiguous region, so you have to compact (lots of I/O) or fail the request. And even with efficient tracking data structures like trees, many distinct values can cause excessive overhead.&lt;/p&gt;
    &lt;p&gt;This is why allocator algorithms typically use a small set of fixed sizes, reducing external fragmentation while accepting some internal fragmentation (overallocating). I initially used a very simple allocation algorithm: split the heap into "tiles", hard coded to be 16 MB. To support small allocations, free tiles can convert to "microtiles" that are bump allocated. For example, an allocation of 65 MB would allocate 4 tiles + 1 MB from a microtile.&lt;/p&gt;
    &lt;p&gt;At the time, I was working with objects on a scale of 200 MB to 4 GB (and hence why I picked 16 MB), so this fixed the primary external fragmentation issue — the larger the file, the less likely that amount of contiguous space is available. However, this has similar "exact allocation" issues for small allocations (microtiles), meaning that many such allocations over time would likely result in more compactions than ideal. As I was dealing with mostly large objects, which meant fewer metadata and that their data (and not metadata) would dominate I/O and space, I accepted the trade-offs at the time.&lt;/p&gt;
    &lt;p&gt;This approach required background processes to coalesce microtiles to make freed space usable, which was complex and led to spikes in I/O. However, this was not a major problem, as the object store was used to store user content, where most users upload files and rarely delete them, so most objects were immutable, and deletions often happened in bulk which allowed for coalescing I/O work at the same time.&lt;/p&gt;
    &lt;head rend="h3"&gt;Allocation state tracking&lt;/head&gt;
    &lt;p&gt;I thought about whether it was possible to allocate and deallocate in bounded time. Given 16 MB tiles, and a reasonable max disk size of 256 TB, there would be 16,777,216 tiles. That's too many to have any sort of brute force linear algorithm in a hot path, but it is possible to leverage a hierarchy to efficiently divide-and-conquer a large but bounded search space in guaranteed fixed time.&lt;/p&gt;
    &lt;p&gt;In this case, there are only two states for a tile: free or used. Therefore, I used a hierarchical bitmap, where each bit represents whether there is any free tile in the level below for the range it represents. At the lowest level, each bit represents one tile; the next level up has one bit for its 64 tiles, the next level has one for its 64×64 tiles, and so on. Here's a conceptual demo, with two bits per element for simplicity:&lt;/p&gt;
    &lt;p&gt;On top of having fixed latency, CPUs have very efficient bitwise manipulation instructions. We need an instruction to find any set bit in an integer, and one does exist: tzcnt_u64 — get position of lowest set bit. Just four of these instructions can be used to find a free tile across 16 million tiles. Similarly, marking as used or new is simply four bit flips:&lt;/p&gt;
    &lt;code&gt;uint32_t fast_allocate_one_tile(freelist_t* fl) {
  uint64_t i1 = _tzcnt_u64(fl-&amp;gt;tile_bitmap_1);
  uint64_t i2 = _tzcnt_u64(fl-&amp;gt;tile_bitmap_2[i1]);
  uint64_t i3 = _tzcnt_u64(fl-&amp;gt;tile_bitmap_3[i1][i2]);
  uint64_t i4 = _tzcnt_u64(fl-&amp;gt;tile_bitmap_4[i1][i2][i3]);

  propagate_tile_bitmap_change(fl, fl-&amp;gt;tile_bitmap_4[i1][i2][i3] &amp;amp; ~(1llu &amp;lt;&amp;lt; i4), i1, i2, i3);
  uint32_t tile = (((((i1 * 64) + i2) * 64) + i3) * 64) + i4;

  return tile;
}

static inline void propagate_tile_bitmap_change(freelist_t* fl, uint64_t new_bitmap, uint64_t i1, uint64_t i2, uint64_t i3) {
  if (!(fl-&amp;gt;tile_bitmap_4[i1][i2][i3] = new_bitmap)) {
    if (!(fl-&amp;gt;tile_bitmap_3[i1][i2] &amp;amp;= ~(1llu &amp;lt;&amp;lt; i3))) {
      if (!(fl-&amp;gt;tile_bitmap_2[i1] &amp;amp;= ~(1llu &amp;lt;&amp;lt; i2))) {
        fl-&amp;gt;tile_bitmap_1 &amp;amp;= ~(1llu &amp;lt;&amp;lt; i1);
      }
    }
  }
}
&lt;/code&gt;
    &lt;p&gt;Allocating more than one tile would require enumerating each set bit in an element, which gets inefficient with large allocation requests. I searched for another CPU intrinsic to do this quickly, and found mm512_mask_compressstoreu_epi8, which uses a bitmap to pick up to 64 elements from a source vector and packs them contiguously in a destination. A visualization, reduced to 16 bits for compactness, to illustrate:&lt;/p&gt;
    &lt;p&gt;An out-of-range value is used as the "padding" to indicate the end of the elements. This can transform a bitmap element in the hierarchy into an array of indices in one instruction, which can then be iterated over:&lt;/p&gt;
    &lt;code&gt;array_u8_64_t vec_find_indices_of_nonzero_bits_64(uint64_t bits) {
  uint8_t indices_raw[64] = {0, 1, 2, ..., 62, 63};
  __m512i indices = _mm512_loadu_epi8(indices_raw);

  array_u8_64_t result;
  memset(result.elems, 64, 64);
  _mm512_mask_compressstoreu_epi8(result.elems, bits, indices);
  return result;
}

void freelist_consume_tiles(freelist_t* fl, uint64_t tiles_needed, cursor_t* out) {
  array_u8_64_t i1_candidates = vec_find_indices_of_nonzero_bits_64(fl-&amp;gt;tile_bitmap_1);
  for (uint64_t i = 0, i1; i &amp;lt; 64 &amp;amp;&amp;amp; (i1 = i1_candidates.elems[i]) != 64; i++) {
    // ...
  }
}
&lt;/code&gt;
    &lt;p&gt;For a bitmap at the last level, as I didn't want all free tiles but only up to n, mm512_mask_blend_epi8 was used to mask off elements after n with the out-of-range value:&lt;/p&gt;
    &lt;code&gt;static inline vec_512i_u8_t find_free_tiles_in_region(uint64_t region_tile_bitmap, uint8_t tile_count_wanted) {
  uint8_t indices_raw[64] = {0, 1, 2, ..., 62, 63};
  __m512i indices = _mm512_loadu_epi8(indices_raw);
  __m512i fill = _mm512_set1_epi8(64);

  // Find tiles that are available.
  vec_512i_u8_t available;
  available.vec = _mm512_mask_compress_epi8(fill, region_tile_bitmap, indices);
  // Limit tile count to tile_count_wanted.
  available.vec = _mm512_mask_blend_epi8((1llu &amp;lt;&amp;lt; tile_count_wanted) - 1, fill, available.vec);
  return available;
}
&lt;/code&gt;
    &lt;p&gt;I took a similar approach for finding a microtile with enough space for any given allocation request. Instead of representing &lt;code&gt;any(is_free for tile in next level)&lt;/code&gt;, it's &lt;code&gt;max(free_space for microtile in next level)&lt;/code&gt;, since that's the objective we want to divide and navigate through the search space:&lt;/p&gt;
    &lt;code&gt;struct freelist_s {
  // For each element, bits [31:8] represent the maximum free amount 
  // of all elements it represents in the next layer, [7:7] if the 
  // tile is not a microtile, and [6:0] the self-index (although 
  // only 4 bits are used as there are only 16 elements per vector).
  vec_512i_u32_t microtile_free_map_1;
  vec_512i_u32_t microtile_free_map_2[16];
  vec_512i_u32_t microtile_free_map_3[16][16];
  vec_512i_u32_t microtile_free_map_4[16][16][16];
  vec_512i_u32_t microtile_free_map_5[16][16][16][16];
  vec_512i_u32_t microtile_free_map_6[16][16][16][16][16];
}
&lt;/code&gt;
    &lt;p&gt;We're tracking more information so it's less dense: 32 bits per "region" rather than 1 bit. We use wide 512-bit (32x16) values and AVX-512, which is not as dense as the previous 64-bit (1x64) but still achieves 16x vectorization. 24 bits are used to represent the actual free space value, and 4 bits are used to represent the self-index as AVX-512 currently has no instruction for getting argmax, only max.&lt;/p&gt;
    &lt;p&gt;A query starts off by broadcasting the value to compare to (i.e. requested allocation size), to vectorize the comparison against all 16 elements at once:&lt;/p&gt;
    &lt;code&gt;uint64_t freelist_consume_microtile_space(freelist_t* fl, uint32_t bytes_needed) {
  __m512i y512 = _mm512_set1_epi32(bytes_needed &amp;lt;&amp;lt; 8);
&lt;/code&gt;
    &lt;p&gt;To find the element with enough capacity, mm512_cmpge_epu32_mask is used, which returns a mask, with a bit set for each element that is greater than or equal to the value. Then tzcnt_32 gets any element:&lt;/p&gt;
    &lt;code&gt;  uint32_t m1 = _mm512_cmpge_epu32_mask(fl-&amp;gt;microtile_free_map_1.vec, y512);
  uint32_t p1 = _tzcnt_u32(m1);
&lt;/code&gt;
    &lt;p&gt;Now we know the element at &lt;code&gt;p1&lt;/code&gt; in &lt;code&gt;fl-&amp;gt;microtile_free_map_1&lt;/code&gt; contains enough space for our request. This is then repeated, traversing down the hierarchy:&lt;/p&gt;
    &lt;code&gt;  uint32_t i1, i2, i3, i4, i5, i6;
  i1 = fl-&amp;gt;microtile_free_map_1.elems[p1] &amp;amp; 127;
  uint16_t m2 = _mm512_cmpge_epu32_mask(fl-&amp;gt;microtile_free_map_2[i1].vec, y512);
  uint32_t p2 = _tzcnt_u32(m2);

  i2 = fl-&amp;gt;microtile_free_map_2[i1].elems[p2] &amp;amp; 127;
  uint16_t m3 = _mm512_cmpge_epu32_mask(fl-&amp;gt;microtile_free_map_3[i1][i2].vec, y512);
  uint32_t p3 = _tzcnt_u32(m3);

  i3 = fl-&amp;gt;microtile_free_map_3[i1][i2].elems[p3] &amp;amp; 127;
  uint16_t m4 = _mm512_cmpge_epu32_mask(fl-&amp;gt;microtile_free_map_4[i1][i2][i3].vec, y512);
  uint32_t p4 = _tzcnt_u32(m4);

  // ... and so on
&lt;/code&gt;
    &lt;p&gt;Once the leaf element is reached, the offset can be calculated and the updated value can be propagated back up using mm512_reduce_max_epu32, which calculates the maximum value:&lt;/p&gt;
    &lt;code&gt;  uint32_t meta = fl-&amp;gt;microtile_free_map_6[i1][i2][i3][i4][i5].elems[p6];
  cur_free = meta &amp;gt;&amp;gt; 8;
  i6 = meta &amp;amp; 127;
  microtile_addr = (((((((((i1 * 16) + i2) * 16) + i3) * 16) + i4) * 16) + i5) * 16) + i6;

  uint32_t new_free = cur_free - bytes_needed;
  fl-&amp;gt;microtile_free_map_6[i1][i2][i3][i4][i5].elems[i6] = (new_free &amp;lt;&amp;lt; 8) | i6;
  fl-&amp;gt;microtile_free_map_5[i1][i2][i3][i4].elems[i5] = (_mm512_reduce_max_epu32(fl-&amp;gt;microtile_free_map_6[i1][i2][i3][i4][i5].vec) &amp;amp; ~15) | i5;
  fl-&amp;gt;microtile_free_map_4[i1][i2][i3].elems[i4] = (_mm512_reduce_max_epu32(fl-&amp;gt;microtile_free_map_5[i1][i2][i3][i4].vec) &amp;amp; ~15) | i4;
  fl-&amp;gt;microtile_free_map_3[i1][i2].elems[i3] = (_mm512_reduce_max_epu32(fl-&amp;gt;microtile_free_map_4[i1][i2][i3].vec) &amp;amp; ~15) | i3;
  fl-&amp;gt;microtile_free_map_2[i1].elems[i2] = (_mm512_reduce_max_epu32(fl-&amp;gt;microtile_free_map_3[i1][i2].vec) &amp;amp; ~15) | i2;
  fl-&amp;gt;microtile_free_map_1.elems[i1] = (_mm512_reduce_max_epu32(fl-&amp;gt;microtile_free_map_2[i1].vec) &amp;amp; ~15) | i1;

  return ((uint64_t) microtile_addr) * TILE_SIZE + (TILE_SIZE - cur_free);
}
&lt;/code&gt;
    &lt;p&gt;This approach uses a fixed six comparison + bit count operations in order to find a microtile with at least n bytes across up to 16 million microtiles. It may seem like storing the next-level maximum's index, rather than self-index, would be more efficient, as it would mean directly following indices down the tree at query time, rather than doing comparisons. But as mentioned, there is no argmax, so that would mean doing a max + equals comparison + find set bit for each level when bubbling up, rather than a single max instruction, and it approximately evens out.&lt;/p&gt;
    &lt;p&gt;This is essentially a max-heap-like tree with very wide branching to leverage SIMD. Having a fixed size means branchless execution, fixed latency, and no rebalancing. It also allows for updating any arbitrary microtile free space, since there's a computable fixed element index. This approach does require AVX-512F, which can cause CPU throttling and have higher latency than expected, so it may not be so clear cut.&lt;/p&gt;
    &lt;head rend="h3"&gt;Journal&lt;/head&gt;
    &lt;p&gt;To atomically write critical metadata to disk and handle interruptions that could cause corruption, a journal is used. Any metadata writes to disk are recorded as events in the journal first. Each event entry contains enough data to reapply them to get to a consistent state that was guaranteed to clients, in case of a crash or power loss. Client requests are responded with success only when they have been written to the journal on disk (and synced), since that guarantees persistence, even if not yet applied.&lt;/p&gt;
    &lt;p&gt;A subtlety arises when ordering events. Take, for example, a DB with three subsystems, each with their own internal state: index (A), allocator (B), and log (C). From the user's perspective, each request is atomic, advancing the state of the entire object store in lockstep as one, even if internally there are three separate subsystems. For example, it's not correct to insert an entry into the index but point it to space that's not actually allocated for it. A simple correct approach is to lock the entire system and perform each request one at a time:&lt;/p&gt;
    &lt;code&gt;void handle_request() {
  lock();
  a();
  b();
  c();
  commit();
  unlock();
}
&lt;/code&gt;
    &lt;p&gt;This has the downside of serializing requests; it'd be nice to do some pipelining here with more granular locking:&lt;/p&gt;
    &lt;code&gt;void handle_request() {
  lock_a(); a(); unlock_a();
  lock_b(); b(); unlock_b();
  lock_c(); c(); unlock_c();
  lock_journal(); commit(); unlock_journal();
}
&lt;/code&gt;
    &lt;p&gt;The issue is that there's no guarantee of execution ordering between locked subsystem calls. For example, it's possible for thread 1 handling request 1 to mutate A, then yield to thread 2, which handles request 2 but reaches and mutates both A and B before yielding back — perhaps it was faster at A and the OS decided to give it more CPU time. Now request 1 will mutate B after B was affected by request 2. This becomes a problem if request 1 is in the journal but the system crashes before request 2 makes it. Now, reapplying request 1 causes an incorrect system state, due to the partial changes in B for a non-existent request 2. If B was the allocator, this might mean lost space, double free, or worse. This applies all the way down: even if all subsystems executed in the same order across all requests, it would cause issues if request 3 came before request 2 in the journal.&lt;/p&gt;
    &lt;p&gt;One fix is to acquire the next lock before releasing the current one. This should guarantee sequential processing of requests across systems while still pipelining, and never deadlock if the execution path is always the same:&lt;/p&gt;
    &lt;code&gt;void handle_request() {
    lock_a(); a(); lock_b();
  unlock_a(); b(); lock_c();
  unlock_b(); c(); lock_journal();
  unlock_c(); commit(); unlock_journal();
}
&lt;/code&gt;
    &lt;p&gt;Another approach would be to issue sequence numbers for requests. Each subsystem, including the journal, only processes in order, deferring out-of-order requests in a queue. You could also try batch processing requests serially.&lt;/p&gt;
    &lt;p&gt;The journal is checksummed using xxHash as it itself could get interrupted while being written. Similarly, applying the journal is idempotent: we can reapply as many times as we want safely, so as to handle crashing during journal recovery. If the journal hash mismatches, we can safely assume it was not built or erased completely, which by our semantics is OK.&lt;/p&gt;
    &lt;head rend="h3"&gt;Background flush&lt;/head&gt;
    &lt;p&gt;These metadata writes are quite small, typically less than 100 bytes. Writing each individually to disk immediately would be wasteful:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Disks have a minimum write size, typically 512 bytes. Writing less than this causes write amplification.&lt;/item&gt;
      &lt;item&gt;Disks, including NVMe SSDs, have optimizations for larger sequential writes, transferring more data at once.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;fsync&lt;/code&gt;is expensive.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Therefore, these journal events first go into an in-memory buffer. After it becomes full, or around every 100 ms, a background thread applies the in-memory data to disk. By waiting a few milliseconds, the hope is that more events get collected and coalesced, reducing write amplification and exploiting larger sequential writes. It also reduces the amount of &lt;code&gt;fsync&lt;/code&gt; calls. A condvar with a timed wait is used to wake up the thread based on timer or capacity.&lt;/p&gt;
    &lt;head rend="h3"&gt;Server&lt;/head&gt;
    &lt;p&gt;For efficiency, epoll was used, to avoid blocking threads when reading from and writing to network sockets during request processing. A simple binary protocol was adopted: a 255-byte leading metadata packet, containing the request type and arguments, followed by a request or response payload. Multiplexing is not supported but connections are reused across requests.&lt;/p&gt;
    &lt;p&gt;A standard C server approach is to accept clients, then make blocking &lt;code&gt;read&lt;/code&gt; and &lt;code&gt;write&lt;/code&gt; calls to process requests; threads are used to scale this approach, usually some multiple beyond CPU count since many threads may actually be blocked-idle at any time. With epoll, the approach is slightly different:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;An epoll instance is created.&lt;/item&gt;
      &lt;item&gt;accept4 is provided with the &lt;code&gt;SOCK_NONBLOCK&lt;/code&gt;flag and sockets are registered with the epoll instance.&lt;/item&gt;
      &lt;item&gt;A server loop will wait for events, like "ready to read/write", on registered epoll sockets, then pass them off to request handlers.&lt;/item&gt;
      &lt;item&gt;A non-blocking socket means &lt;code&gt;read&lt;/code&gt;and&lt;code&gt;write&lt;/code&gt;will return if not possible to fulfill immediately.&lt;/item&gt;
      &lt;item&gt;At this point, we can "rearm" the socket, re-registering with epoll until we have sent or received more data and can continue processing the request.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is efficient because our threads are either busy doing work or efficiently sleeping while I/O is done in the background, never blocked. The downside is that blocking code is simpler to write because it looks like normal sequentially-executed code. With epoll, one has to track function (the request handler) state and handle "re-entering" at a higher level, since at any point you do a read/write, you could return from the function, and then later be called again from that logical position and state.&lt;/p&gt;
    &lt;head&gt;Async in other languages&lt;/head&gt;
    &lt;p&gt;This is why syntactic sugar like async is used in other languages: write regular-looking functions and let the language handle state across yielding and resuming behind the scenes. You'll see something similar if you downlevel JS to a browser pre-async, where it goes from:&lt;/p&gt;
    &lt;code&gt;async function f() {
  let a = 1;
  await x(a);
  a += 1;
  await y(a);
  a += 2;
  return a;
}
&lt;/code&gt;
    &lt;p&gt;to something like:&lt;/p&gt;
    &lt;code&gt;// To be used in combination with and driven by some generator runtime.
function f(state) {
  switch (state._entrypoint) {
  case 0:
    state.a = 1;
    return x(state.a);
  case 1:
    state.a += 1;
    return y(state.a);
  case 2:
    state.a += 2;
    return state.a;
  }
}
&lt;/code&gt;
    &lt;p&gt;Asynchronous Programming in Rust has a good primer and detailed explanation on async programming here.&lt;/p&gt;
    &lt;head rend="h2"&gt;blobd&lt;/head&gt;
    &lt;p&gt;About a year later, when I was running into scaling issues with the object storage for my search engine, I decided to revisit Turbostore. There were some pain points that I wanted to resolve:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Being written in C made it difficult to develop correctly and quickly: raw pointers, undefined behavior, and barebones syntax, types and libraries.&lt;/item&gt;
      &lt;item&gt;mmap and page cache hid a lot of I/O impacts on performance and correctness. Reading a few bytes actually meant loading an entire 4 KB page from disk. Reads and writes implicitly block. Dirty pages could be flushed at any time, so writes were not fully controllable.&lt;/item&gt;
      &lt;item&gt;The earlier allocation algorithm lacked efficient deallocation.&lt;/item&gt;
      &lt;item&gt;Incomplete object uploads did not get auto-deleted over time; without an external system tracking these, they essentially made space irrecoverable.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Turbostore already achieves the goal of constant low latency random reads, and I was satisified with its feature set. However, I wanted to experiment with further speed gains, seeking better mechanical sympathy with the underlying NVMe SSDs.&lt;/p&gt;
    &lt;p&gt;I renamed it to blobd: single binary, simple design, does one thing and does it well. New design changes went to blobd while the existing Turbostore was kept as blobd-lite, useful for systems with older Linux kernels or low memory.&lt;/p&gt;
    &lt;head rend="h3"&gt;Direct I/O&lt;/head&gt;
    &lt;p&gt;In Turbostore, the underlying storage was treated as a very large addressable region of bytes. But storage devices actually operate on aligned blocks, typically 512 bytes, not individual bytes. The kernel abstracts this away via in-memory buffers: when you &lt;code&gt;write&lt;/code&gt; 6 bytes to offset 510, the kernel actually fetches blocks 0 and 1 (since it touches both), applies your changes to those memory buffers, then writes them back. A single 6-byte write, which seemed efficient, turned into a 1024-byte read-then-write.&lt;/p&gt;
    &lt;p&gt;While hiding this complexity works great for most applications, it's not so good for a low level storage system:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Not designing around blocks means not optimizing for how the physical device actually operates, causing unintentional inefficiencies: write amplification, misalignment, hidden latencies.&lt;/item&gt;
      &lt;item&gt;Tight control of how I/O works is important for performance and correctness for blobd. The kernel can reorder writes, issue more or less than desired and at arbitrary times, and won't guarantee actual physical writes except via coarse and slow APIs like &lt;code&gt;fsync&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Being a low level storage system, there's no need to also design around the intermediate kernel abstraction.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;Examples of inefficiencies due to leaky abstraction&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Two subsystems are placed at locations [0, 1000] and [1001, 2000]. In theory, they have independent authority over their regions. In reality, their boundary lies on the same disk block, so they get entangled: a short write issued by subsystem A actually has to wait for a longer write by subsystem B to the same block. What seems like a one-way (and therefore immediate) write by subsystem B actually requires first reading the underlying block, including data from A, before the write can be issued. A write by A can somehow damage B because the write to the underlying shared block was interrupted.&lt;/item&gt;
      &lt;item&gt;Write 1 writes across two blocks. The second block is already in memory, but the first block still needs to be read. Or maybe the first block is still being changed by an earlier write 0. Should block 2 be sent now for efficiency, causing only part of write 1 to be written and jump ahead of write 0, or should it wait for block 1 and send both together? What if write 5 touches block 4, 5, 6, but block 4 is not yet in memory, write 4 (earlier) touches block 5, and write 6 (later) touches block 5 and 6? There's a lot of complexity here to implement both correctly and optimally, and it also interferes with modeling I/O at the program layer. Synchronization points like &lt;code&gt;fsync&lt;/code&gt;, necessary for correctness, become entangled and inefficient as per the previous point.&lt;/item&gt;
      &lt;item&gt;While you need similar synchronization points even with blocks (for example, write to 1000, write to 100 to update metadata like allocator state that references 1000, write 1000 again — sync/barrier after metadata to prevent later 1000 overwrite from making no sense), it's a bit easier and faster because you can just issue a write and await it, whereas with Linux buffer abstraction, you must then wait for a global &lt;code&gt;fsync&lt;/code&gt;, which we've seen requires a lot more global pause-the-world timing. Each subsystem is truly has full independent control over its own blocks, can sync anytime without waiting/joining others (implicitly or explicitly), can know exactly order of writes (e.g. write 1 to block will always come before write 2 to same block), etc.&lt;/item&gt;
      &lt;item&gt;A subsystem might choose to use very small on-disk structures and values, or use in-memory state that allows for granular reading and writing of disk data, not realizing that every non-direct I/O reads and writes 4 KB of data, negating any optimization, and not leveraging this "bulk read/write" for free.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In blobd, direct I/O is used to enforce operating on disk realities. This is a Linux flag that makes every &lt;code&gt;read&lt;/code&gt;/&lt;code&gt;write&lt;/code&gt; correspond to I/Os issued directly to the physical storage device, bypassing the kernel abstraction layer. Because disks operate on blocks, this means all such reads and writes must be block aligned and multiples.&lt;/p&gt;
    &lt;p&gt;Direct I/O means no more &lt;code&gt;fsync&lt;/code&gt;: no more complexity via background flushes and optimal scheduling of syncs. There's no kernel overhead from copying and coalescing. It essentially provides the performance, control, and simplicity of issuing raw 1:1 I/O requests.&lt;/p&gt;
    &lt;head rend="h3"&gt;Atomic writes&lt;/head&gt;
    &lt;p&gt;Another interesting hardware feature is atomic writes. When set on a write request, the physical device ensures that it either succeeds or leaves existing data untouched — no torn writes. Currently, our journal provides the equivalent via transactions for disk mutations, to prevent corruption in the case of interruptions. But it writes everything twice, inefficiently. It's another indirection layer to model and manage. And as mentioned previously, it has complexities that can cause subtle correctness issues.&lt;/p&gt;
    &lt;p&gt;My understanding of the history of atomic writes is that it was mostly an implicit guarantee by hardware manufactures for some devices. Then NVMe added it as an explicit part of their spec, so devices can expose what sized atomic writes they support. However, only recently did the Linux kernel add support for this via standard APIs: a flag to signal that a write must be atomic, and fail if it can't be (e.g. hardware doesn't support it). It seems that before this, one just assumed all writes below some size were atomic, as suggested by AWS. There's a great Stack Overflow answer for further deep diving.&lt;/p&gt;
    &lt;p&gt;As I proceeded with the redesign, I tried to incorporate atomic writes as well as direct I/O.&lt;/p&gt;
    &lt;head rend="h3"&gt;Tuple blocks&lt;/head&gt;
    &lt;p&gt;The original design revolved around disk-resident data structures to represent state. For example, the hash index was stored as a long array of bucket pointers, such that the location on disk of bucket &lt;code&gt;i&lt;/code&gt;'s pointer was at &lt;code&gt;index_start + i * 6&lt;/code&gt;. For the allocator state, the amount of free space for a tile &lt;code&gt;i&lt;/code&gt; was located at the 24-bit integer at &lt;code&gt;state_start + i * 3&lt;/code&gt;. One reason was the simplicity of correctly reading and writing such data structures compared to others. Another benefit was allowing these data structures to be used without needing to load into memory first, since they are already structured on disk.&lt;/p&gt;
    &lt;p&gt;But there are downsides. As mentioned, reading or writing 6 bytes actually reads/writes 512 bytes, an 85x amplification; hashes are intentionally random so write coalescing is an anti-goal. In reality, all the data is initially read into memory anyway, as one issue is that state, represented on disk, needs to be visibly modified after processing each operation, but not actually modified on disk until flushed via journal — so it's easier to mirror state in memory. Then keeping memory and disk in sync is a simpler one-way (write from memory to disk) and there's no need to couple them.&lt;/p&gt;
    &lt;p&gt;In blobd, state on disk is instead represented by blocks of serialized tuples, where a block is the physical device I/O unit. When a tuple is created, it gets placed in any block with enough space. To coalesce writes, existing dirty blocks are prioritized, only allocating if none are suitable. When the server starts, all tuple blocks are read and processed from disk.&lt;/p&gt;
    &lt;p&gt;In this case, tuples represent index entries of &lt;code&gt;(object_id, object_address)&lt;/code&gt;. However, this approach generalizes to any state that can be represented as a flat bag or set of entries; I believe heap files are conceptually similar. The block is the set size as it's the smallest writable unit, so it minimizes write amplification.&lt;/p&gt;
    &lt;p&gt;It also ties into atomic writes. Previously object creations and deletions would require multiple writes at disparate locations: bucket pointer, allocator state, and possibly linked list node pointers. This meant it was not possible to leverage atomic writes, and so journaling was necessary. Now, it's just one atomic block write, so the journal can be dropped.&lt;/p&gt;
    &lt;head rend="h3"&gt;In-memory index&lt;/head&gt;
    &lt;p&gt;With no more disk-resident index, the initial approach was to simply build an index in-memory at startup. There are two main trade offs. One is slower startup times, which I think is fine for a production system that has far more uptime than restarts. The other is memory usage. What are the actual numbers here?&lt;/p&gt;
    &lt;p&gt;Using the previous example of 30 million objects, assuming every key was a very long 256 bytes, it would require 7 GB of memory to load the entire key set into memory. At a more reasonable 80 bytes on average, it would be 2 GB. If you hash every key using BLAKE3, it would only occupy 0.9 GB of RAM, which is fine for point lookups. So it seems reasonable to hold the entire index in memory.&lt;/p&gt;
    &lt;p&gt;I did a quick empirical test over a real world upper-scale dataset: indexing 282 million URLs (15.1 GB) from my search engine crawl on an AMD EPYC 7502P server:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Data structure&lt;/cell&gt;
        &lt;cell role="head"&gt;Insert time (sec.)&lt;/cell&gt;
        &lt;cell role="head"&gt;Inserts per second&lt;/cell&gt;
        &lt;cell role="head"&gt;Memory usage (GB)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;ahash::HashMap&lt;/cell&gt;
        &lt;cell&gt;102.3&lt;/cell&gt;
        &lt;cell&gt;2,755,047&lt;/cell&gt;
        &lt;cell&gt;31.4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;ahash::HashMap + BLAKE3&lt;/cell&gt;
        &lt;cell&gt;171.8&lt;/cell&gt;
        &lt;cell&gt;1,641,377&lt;/cell&gt;
        &lt;cell&gt;16.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;ahash::HashMap + MD5&lt;/cell&gt;
        &lt;cell&gt;183.2&lt;/cell&gt;
        &lt;cell&gt;1,539,116&lt;/cell&gt;
        &lt;cell&gt;8.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;blart::TreeMap + CString&lt;/cell&gt;
        &lt;cell&gt;72.3&lt;/cell&gt;
        &lt;cell&gt;3,897,173&lt;/cell&gt;
        &lt;cell&gt;43.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;fst::Set&lt;/cell&gt;
        &lt;cell&gt;644.7&lt;/cell&gt;
        &lt;cell&gt;437,264&lt;/cell&gt;
        &lt;cell&gt;5.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;std::collections::BTreeMap&lt;/cell&gt;
        &lt;cell&gt;121.3&lt;/cell&gt;
        &lt;cell&gt;2,323,753&lt;/cell&gt;
        &lt;cell&gt;32.5&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The standard data structures took up about 2x the raw bytes in memory. Interestingly, there isn't much difference between the BTreeMap and HashMap, meaning range functionality could be added without much cost. blart is an implementation of the adaptive radix tree, which promises tree functionality with both faster performance and lower memory usage, but only resulted in one. If only point lookups are needed and memory is constrained, hashing keys is a viable approach.&lt;/p&gt;
    &lt;p&gt;I believe there is much more room for optimization here, as the fst crate demonstrates. FSTs are very compact but static string-key maps. One approach is to build them repeatedly as the index grows, and use an overlay for intermediate keys between snapshots. Another hybrid technique could be LSMTs.&lt;/p&gt;
    &lt;p&gt;For my use case, where I have plenty of memory and want the fastest performance possible, I prefer this trade off. Writes are much simpler to correctly implement, while being faster. Reads are even faster: looking up a key is instant, and the data location on disk can be jumped to immediately. It's possible to switch out indices depending on use case (e.g. hash map for point lookups, tree map for range queries), and optimize them over time, without any rewriting or migration.&lt;/p&gt;
    &lt;head rend="h3"&gt;Buddy allocation&lt;/head&gt;
    &lt;p&gt;The buddy memory allocation algorithm was picked as the replacement. It's quite easy to understand and implement, and minimizes fragmentation, while remaining very fast to allocate and deallocate state with only bitwise operations and simple arrays.&lt;/p&gt;
    &lt;p&gt;It works by defining a set of allocation sizes, increasing by power-of-2. In blobd, the possible allocation sizes are 4 KB (212), 8 KB (213), 16 KB (214), all the way up to 16 MB (224). Then, the heap is divided into pieces and a bitmap represents whether each piece is free or not, with one bitmap for each size. Initially, all 16 MB pieces are free, while all pieces of all other sizes are not.&lt;/p&gt;
    &lt;p&gt;To allocate, find a free piece of the nearest allocation size. If none is available, allocate a piece from the next higher allocation size and "break" it into two, such that there's now two free pieces of the intended size. This can recurse all the way to the largest allocation size. To deallocate, mark that piece as free. If it's "buddy" piece, which is the previous even-address piece if it's odd and vice versa, is also free, then both coalesce back into the larger next-sized piece, recursing all the way to the largest allocation size.&lt;/p&gt;
    &lt;p&gt;It's greedy and simple, with minimal overhead and complexity, yet handles large disks, many objects, varying sizes, and reclaiming of space over long periods. The Wikipedia article has a good example with a visualization.&lt;/p&gt;
    &lt;p&gt;Unlike &lt;code&gt;malloc&lt;/code&gt;, we don't need to store all of an object's data contiguously, so we can further reduce internal fragmentation by dividing the final &amp;lt;16 MB chunk into smaller-and-smaller fragments.&lt;/p&gt;
    &lt;head rend="h3"&gt;io_uring&lt;/head&gt;
    &lt;p&gt;I went with io_uring to get fast async I/O, which works by using two queues: one to send requests, one to get responses. Instead of frequently making expensive syscalls (e.g. &lt;code&gt;read&lt;/code&gt;), you issue a lot of request messages (e.g. &lt;code&gt;IORING_OP_READ&lt;/code&gt;) and then submit them to io_uring, which will execute them on your behalf in their kernel threads. This also provides asynchronicity, since your userland threads aren't blocked on these syscalls. Then you have some thread that repeatedly polls the other queue for responses. If you're busy enough, you can even have the kernel threads poll in a loop, rather than you submitting — reducing syscalls even further.&lt;/p&gt;
    &lt;p&gt;io_uring has generalized beyond its initial I/O focus, and you can make many other syscalls with it, not just &lt;code&gt;open&lt;/code&gt;/&lt;code&gt;read&lt;/code&gt;/&lt;code&gt;write&lt;/code&gt;/&lt;code&gt;close&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;This worked nicely with Rust, which has its own primitives: async, queues, and oneshots. These made it straightforward to tie into io_uring seamlessly. The file interface can remain very familar and easy to use:&lt;/p&gt;
    &lt;code&gt;impl UringFile {
  async fn read_at(&amp;amp;self, offset: u64, len: u64) -&amp;gt; Vec&amp;lt;u8&amp;gt; {
    // Notifier to wake us up when io_uring has done our thing.
    let (tx, rx) = oneshot::channel();
    // Send the request to our submission thread, which submits it to io_uring.
    self.userspace_requests_queue.send(Request::Read {
      req: ReadRequest { out_buf: vec![0u8; len], offset, len: u32!(len) },
      res: tx,
    });
    // Wait on our notifier, sleeping until then.
    rx.await
  }
}

// Using it looks like a normal async File:
let res = file.read_at(offset, len).await;
&lt;/code&gt;
    &lt;p&gt;Under the hood, we spawn two userspace threads to submit requests and consume responses. Standard queues make it easy to do this in Rust:&lt;/p&gt;
    &lt;code&gt;// Spawn our userspace submission thread.
thread::spawn(|| {
  let mut uring_submission_queue = unsafe { ring.submission_shared() };
  // We use IDs to track requests on our end, match up responses from io_uring.
  let mut next_id = 0;
  while let Ok(msg) = userspace_requests_queue.recv() {
    let id = next_id; next_id += 1;
    // Build io_uring specific request entry.
    let entry = match &amp;amp;msg {
      Request::Read { req, .. } =&amp;gt; {
        let ptr = req.out_buf.as_ptr() as *mut u8;
        // `Fixed(0)` means use the file descriptor we registered during setup.
        opcode::Read::new(Fixed(0), ptr, req.len).offset(req.offset).build().user_data(id)
      }
      Request::Write { req, .. } =&amp;gt; {
        let ptr = req.data.as_ptr() as *mut u8;
        let len = req.data.len() as u32;
        opcode::Write::new(Fixed(0), ptr, len).offset(req.offset).build().user_data(id)
      }
    };
    // Store the request in userspace so we know how to handle when we get its response.
    // This also ensures buffers we passed to io_uring remain alive.
    pending.insert(id, msg);
    if uring_submission_queue.is_full() {
      uring_submission_queue.sync();
      ring.submit_and_wait(1).unwrap();
    }
    unsafe { uring_submission_queue.push(&amp;amp;entry).unwrap(); };
    uring_submission_queue.sync();
    ring.submit().unwrap();
  }
});
&lt;/code&gt;
    &lt;p&gt;These code snippets has been simplified for brevity and skips many checks and optimizations; for example, you can wait for more requests before submitting.&lt;/p&gt;
    &lt;p&gt;On the responses end:&lt;/p&gt;
    &lt;code&gt;// Spawn our userspace completion thread.
thread::spawn(|| {
  let mut uring_completion_queue = unsafe { ring.completion_shared() };
  loop {
    // Wake when io_uring has new response ready.
    let Some(e) = uring_completion_queue.next() else {
      ring.submit_and_wait(1).unwrap();
      uring_completion_queue.sync();
      continue;
    };
    // Get corresponding userspace request.
    let id = e.user_data();
    let req = pending.remove(&amp;amp;id).unwrap().1;
    match req {
      // Signal caller that it's done.
      Request::Read { req, res } =&amp;gt; res.send(req.out_buf),
      Request::Write { req, res } =&amp;gt; res.send(req.data),
    }
  }
});
&lt;/code&gt;
    &lt;p&gt;The use of oneshot is what allows the interface to remain a simple async method, where the Rust async caller automatically efficiently sleeps and wakes, rather than having callers deal with queuing and synchronization.&lt;/p&gt;
    &lt;head rend="h2"&gt;Performance&lt;/head&gt;
    &lt;p&gt;Let’s see how these design decisions perform in practice. I wrote a Rust benchmark to hit object stores concurrently in phases, one for each operation type, and then tested against:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Store&lt;/cell&gt;
        &lt;cell role="head"&gt;Configuration&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;blobd&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;blobd-lite&lt;/cell&gt;
        &lt;cell&gt;mdadm RAID 0, 16777216 buckets&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;RocksDB with BlobDB&lt;/cell&gt;
        &lt;cell&gt;mdadm RAID 0, xfs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;MinIO&lt;/cell&gt;
        &lt;cell&gt;xfs&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;RocksDB lacks the ability to read ranges and upload in parts; it was included as an interesting but not equivalent comparison point. MinIO used the Rust AWS SDK and S3-compatible REST API over 127.0.0.1, which adds around 20–100 µs round trip, essentially zero given the resulting numbers.&lt;/p&gt;
    &lt;p&gt;For each phase, at most 1024 operations are requested over all object keys. Object keys are &lt;code&gt;range(object_count)&lt;/code&gt;, serialized as big-endian 64-byte integers, shuffled in each phase to randomize request order. Object data is generated using random bytes of &lt;code&gt;object_size&lt;/code&gt;. The kernel page cache is evicted before each read phase, and &lt;code&gt;malloc_trim(0)&lt;/code&gt; is called between stores, to accurately measure memory usage and avoid any existing cache from skewing results. The phases are:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Begin multipart upload (no-op for RocksDB)&lt;/item&gt;
      &lt;item&gt;Upload parts (one part for RocksDB)&lt;/item&gt;
      &lt;item&gt;Commit object (no-op for RocksDB)&lt;/item&gt;
      &lt;item&gt;Inspect object&lt;/item&gt;
      &lt;item&gt;Read small range of object from random offset&lt;/item&gt;
      &lt;item&gt;Read entire object&lt;/item&gt;
      &lt;item&gt;Delete object&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To balance time and thoroughness, different object sizes and counts were tested. A consistent object count would result in excessive time for large objects or not enough for small objects. Numbers were unaligned to avoid hitting special code pathways.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Object count&lt;/cell&gt;
        &lt;cell role="head"&gt;Object size&lt;/cell&gt;
        &lt;cell role="head"&gt;Total bytes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;567,890&lt;/cell&gt;
        &lt;cell&gt;12,345&lt;/cell&gt;
        &lt;cell&gt;6.5 GB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;400,890&lt;/cell&gt;
        &lt;cell&gt;78,901&lt;/cell&gt;
        &lt;cell&gt;29.5 GB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;300,890&lt;/cell&gt;
        &lt;cell&gt;345,678&lt;/cell&gt;
        &lt;cell&gt;96.9 GB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;123,456&lt;/cell&gt;
        &lt;cell&gt;1,512,345&lt;/cell&gt;
        &lt;cell&gt;173.9 GB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;45,678&lt;/cell&gt;
        &lt;cell&gt;4,012,345&lt;/cell&gt;
        &lt;cell&gt;170.7 GB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;17,890&lt;/cell&gt;
        &lt;cell&gt;10,123,123&lt;/cell&gt;
        &lt;cell&gt;168.7 GB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;7,004&lt;/cell&gt;
        &lt;cell&gt;31,987,654&lt;/cell&gt;
        &lt;cell&gt;208.7 GB&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Testing was done on a machine with:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AMD EPYC 7502P 32-core/64-thread CPU&lt;/item&gt;
      &lt;item&gt;16x32 (512) GB DDR4 ECC RAM&lt;/item&gt;
      &lt;item&gt;Debian 12, Linux 6.12.19&lt;/item&gt;
      &lt;item&gt;8x3.84 TB Micron 7300 PRO MTFDHBE3T8TDF NVMe SSDs &lt;list rend="ul"&gt;&lt;item&gt;3 GB/s seq. read, 1.8 GB/s seq. write&lt;/item&gt;&lt;item&gt;520K random read IOPS, 70K random write IOPS&lt;/item&gt;&lt;item&gt;90 μs random read, 25 μs random write&lt;/item&gt;&lt;item&gt;Micron 3D TLC NAND&lt;/item&gt;&lt;item&gt;PCIe Gen3 1x4, 2x2 NVMe&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The system was tuned with the following commands:&lt;/p&gt;
    &lt;head&gt;System tuning script&lt;/head&gt;
    &lt;code&gt;# File descriptor limits
sysctl -w fs.file-max=2097152
sysctl -w fs.nr_open=2097152
ulimit -n 1048576

# Virtual memory settings
sysctl -w vm.swappiness=10
sysctl -w vm.dirty_ratio=15
sysctl -w vm.dirty_background_ratio=5
sysctl -w vm.vfs_cache_pressure=50

# AIO limits
sysctl -w fs.aio-max-nr=1048576

# Network buffer sizes (256MB max)
sysctl -w net.core.rmem_max=268435456
sysctl -w net.core.wmem_max=268435456
sysctl -w net.core.rmem_default=16777216
sysctl -w net.core.wmem_default=16777216

# TCP buffer auto-tuning
sysctl -w net.ipv4.tcp_rmem="4096 87380 268435456"
sysctl -w net.ipv4.tcp_wmem="4096 65536 268435456"
sysctl -w net.ipv4.tcp_mem="786432 1048576 26777216"

# Connection handling
sysctl -w net.core.somaxconn=65535
sysctl -w net.core.netdev_max_backlog=250000
sysctl -w net.ipv4.tcp_max_syn_backlog=8192
sysctl -w net.ipv4.tcp_syncookies=1

# TCP optimization
sysctl -w net.ipv4.tcp_fin_timeout=15
sysctl -w net.ipv4.tcp_tw_reuse=1
sysctl -w net.ipv4.tcp_max_tw_buckets=2000000
sysctl -w net.ipv4.tcp_slow_start_after_idle=0
sysctl -w net.ipv4.tcp_mtu_probing=1

# Local port range for more connections
sysctl -w net.ipv4.ip_local_port_range="10000 65535"
&lt;/code&gt;
    &lt;p&gt;Starting with uploading objects, blobd and blobd-lite have much faster rates of creating and committing objects than MinIO. RocksDB isn't present as it doesn't have these methods.&lt;/p&gt;
    &lt;p&gt;The drop in commits per second for blobd at higher object sizes is likely due to not enough requests to fully utilize the performance — at the expected 300K op/s, 7K operations would take 0.02 seconds, where measurement variance and overhead may have an effect. Even at 50K op/s, at 32 MB object sizes you would need to be writing 1.5 TB/s before this became a bottleneck.&lt;/p&gt;
    &lt;p&gt;When uploading the parts, blobd is significantly faster than all other solutions, at times exceeding raw theoretical disk write speeds of 8×1.8 (14.4) GB/s:&lt;/p&gt;
    &lt;p&gt;A key focus was optimizing for random reads. In this test, 4000-byte reads are done from random offsets. (Note that RocksDB does not support range reads.) Both blobd and blobd-lite deliver that here, with blobd having much higher performance:&lt;/p&gt;
    &lt;p&gt;Part of this was a goal for consistent low latency random reads, regardless of object size. Both blobd and blobd-lite achieve this:&lt;/p&gt;
    &lt;p&gt;blobd has sub-millisecond latencies, 130x faster than blobd-lite and at times close to raw NVMe disk latency. Here are the exact numbers:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="9"&gt;
        &lt;cell role="head"&gt;Store&lt;/cell&gt;
        &lt;cell role="head"&gt;Metric&lt;/cell&gt;
        &lt;cell role="head"&gt;12.0 KB&lt;/cell&gt;
        &lt;cell role="head"&gt;77.0 KB&lt;/cell&gt;
        &lt;cell role="head"&gt;338 KB&lt;/cell&gt;
        &lt;cell role="head"&gt;1.4 MB&lt;/cell&gt;
        &lt;cell role="head"&gt;3.8 MB&lt;/cell&gt;
        &lt;cell role="head"&gt;9.7 MB&lt;/cell&gt;
        &lt;cell role="head"&gt;30.5 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;direct&lt;/cell&gt;
        &lt;cell&gt;Avg&lt;/cell&gt;
        &lt;cell&gt;0.330&lt;/cell&gt;
        &lt;cell&gt;0.339&lt;/cell&gt;
        &lt;cell&gt;0.380&lt;/cell&gt;
        &lt;cell&gt;0.360&lt;/cell&gt;
        &lt;cell&gt;0.413&lt;/cell&gt;
        &lt;cell&gt;0.553&lt;/cell&gt;
        &lt;cell&gt;0.767&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;lite&lt;/cell&gt;
        &lt;cell&gt;Avg&lt;/cell&gt;
        &lt;cell&gt;43.256&lt;/cell&gt;
        &lt;cell&gt;42.995&lt;/cell&gt;
        &lt;cell&gt;42.291&lt;/cell&gt;
        &lt;cell&gt;41.141&lt;/cell&gt;
        &lt;cell&gt;41.754&lt;/cell&gt;
        &lt;cell&gt;41.979&lt;/cell&gt;
        &lt;cell&gt;40.500&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;minio&lt;/cell&gt;
        &lt;cell&gt;Avg&lt;/cell&gt;
        &lt;cell&gt;66.404&lt;/cell&gt;
        &lt;cell&gt;69.126&lt;/cell&gt;
        &lt;cell&gt;85.882&lt;/cell&gt;
        &lt;cell&gt;105.755&lt;/cell&gt;
        &lt;cell&gt;104.941&lt;/cell&gt;
        &lt;cell&gt;195.205&lt;/cell&gt;
        &lt;cell&gt;100.248&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;rocksdb&lt;/cell&gt;
        &lt;cell&gt;Avg&lt;/cell&gt;
        &lt;cell&gt;4.122&lt;/cell&gt;
        &lt;cell&gt;5.235&lt;/cell&gt;
        &lt;cell&gt;13.169&lt;/cell&gt;
        &lt;cell&gt;55.003&lt;/cell&gt;
        &lt;cell&gt;163.355&lt;/cell&gt;
        &lt;cell&gt;391.346&lt;/cell&gt;
        &lt;cell&gt;1123.244&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;direct&lt;/cell&gt;
        &lt;cell&gt;P99&lt;/cell&gt;
        &lt;cell&gt;0.996&lt;/cell&gt;
        &lt;cell&gt;0.998&lt;/cell&gt;
        &lt;cell&gt;1.314&lt;/cell&gt;
        &lt;cell&gt;1.385&lt;/cell&gt;
        &lt;cell&gt;3.500&lt;/cell&gt;
        &lt;cell&gt;3.994&lt;/cell&gt;
        &lt;cell&gt;5.319&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;lite&lt;/cell&gt;
        &lt;cell&gt;P99&lt;/cell&gt;
        &lt;cell&gt;69.547&lt;/cell&gt;
        &lt;cell&gt;68.484&lt;/cell&gt;
        &lt;cell&gt;67.511&lt;/cell&gt;
        &lt;cell&gt;65.665&lt;/cell&gt;
        &lt;cell&gt;68.627&lt;/cell&gt;
        &lt;cell&gt;73.304&lt;/cell&gt;
        &lt;cell&gt;82.044&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;minio&lt;/cell&gt;
        &lt;cell&gt;P99&lt;/cell&gt;
        &lt;cell&gt;227.921&lt;/cell&gt;
        &lt;cell&gt;374.208&lt;/cell&gt;
        &lt;cell&gt;980.492&lt;/cell&gt;
        &lt;cell&gt;1258.599&lt;/cell&gt;
        &lt;cell&gt;1294.902&lt;/cell&gt;
        &lt;cell&gt;1380.968&lt;/cell&gt;
        &lt;cell&gt;153.009&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;rocksdb&lt;/cell&gt;
        &lt;cell&gt;P99&lt;/cell&gt;
        &lt;cell&gt;11.260&lt;/cell&gt;
        &lt;cell&gt;14.015&lt;/cell&gt;
        &lt;cell&gt;39.980&lt;/cell&gt;
        &lt;cell&gt;193.706&lt;/cell&gt;
        &lt;cell&gt;602.324&lt;/cell&gt;
        &lt;cell&gt;1374.650&lt;/cell&gt;
        &lt;cell&gt;3789.236&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The improved and simplified design of blobd also means it uses less system resources:&lt;/p&gt;
    &lt;p&gt;The increase in memory usage as object sizes go up is likely due to to the benchmarking harness itself. 1024 32 MB requests in flight is 32 GB just for the combined payload data. We'd expect memory usage from database state (e.g. index) to go down as size increases as there are fewer objects.&lt;/p&gt;
    &lt;p&gt;blobd also has lower disk write amplification and overhead, writing fewer bytes and issuing fewer requests:&lt;/p&gt;
    &lt;head rend="h2"&gt;Stochastic stresser&lt;/head&gt;
    &lt;p&gt;Correctness and reliability is important for a system holding critical data and in critical performance paths. One way I sought to achieve this was through simplicity, getting as close to transparently and self-evidently correct design as possible.&lt;/p&gt;
    &lt;p&gt;However, I did also want to stress test blobd, and explored a harness to hit it with a lot of varying concurrent operations, to try and put it in an unexpected state and elicit bad behavior, called the stochastic stresser. It works by using a queue of valid tasks that could be performed. But instead of predictable FIFO polling, it dequeues random entries — legal tasks, but executed unpredictably.&lt;/p&gt;
    &lt;p&gt;For example, we can create an object with a random key and size at any time. The next legal action is to upload the parts, so those tasks get enqueued. Any of them could therefore happen immediately, at the end, or any time in between. Combined with many other random tasks, objects, and concurrent executors, there should be enough "chaotic mixing" to hit blobd in unseen and unpredictable ways. The hope is that this triggers rare code paths, unforeseen configurations, and race conditions. The stresser will assert that each task completes correctly and panic if otherwise.&lt;/p&gt;
    &lt;p&gt;This "stochastic" queue is backed by a vector of entries. When pushing, it is appended to the end. Popping picks a random index, then does an O(1) swap_remove; this is how the queue is made random. It's wrapped in a condvar, woken on pushes and sender/receiver changes, for efficient waiting on messages.&lt;/p&gt;
    &lt;p&gt;It's quite simple, but was able to catch subtle correctness bugs and race conditions. It's similar conceptually to fuzzing and I think is worth checking out for stateful systems generally. The next improvement would be to simulate crashes, hardware failures, and system errors.&lt;/p&gt;
    &lt;head rend="h2"&gt;What's next&lt;/head&gt;
    &lt;p&gt;There are some low hanging improvements that can be had around performance, such as caching metadata to avoid repeated disk reads when repeatedly hitting the same object in a short time period. Improving the developer experience is also a near-term goal — polishing documentation, creating more language bindings, and simplifying the configuration.&lt;/p&gt;
    &lt;p&gt;I am experimenting with a distributed blobd with replication and sharding, for cases where a single node is not enough.&lt;/p&gt;
    &lt;p&gt;It would be interesting to investigate using these primitives — atomic writes, io_uring, tuple blocks — for a KV store, optimized for small values. Could there be similar gains in performance and simplicity?&lt;/p&gt;
    &lt;p&gt;You can check out the open source code and usage instructions on the GitHub repo. Feel free to raise issues, ask questions and start discussions about blobd there! I'm especially interested in ideas or considerations to use blobd in projects, how the performance can benefit, and any limitations around using it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45809644</guid><pubDate>Tue, 04 Nov 2025 11:09:24 +0000</pubDate></item><item><title>This week in 1988, Robert Morris unleashed his eponymous worm</title><link>https://www.tomshardware.com/tech-industry/cyber-security/on-this-day-in-1988-the-morris-worm-slithered-out-and-sparked-a-new-era-in-cybersecurity-10-percent-of-the-internet-was-infected-within-24-hours</link><description>&lt;doc fingerprint="ff40223f0be08a6f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;37 years ago this week, the Morris worm infected 10% of the Internet within 24 hours — worm slithered out and sparked a new era in cybersecurity&lt;/head&gt;
    &lt;p&gt;The Internet contracted worms a year before the World Wide Web was even a thing.&lt;/p&gt;
    &lt;p&gt;This week in 1988, Cornell graduate student Robert Tappan Morris unleashed his eponymous worm upon the Internet. The wave of infections grew to 10% of the entire Internet within 24 hours, causing astronomically expensive damage for the time. However, the pioneering Morris worm malware wasn’t made with malice, says an FBI retrospective on the “programming error.” It was designed to gauge the size of the Internet, resulting in a classic case of unintended consequences.&lt;/p&gt;
    &lt;head rend="h2"&gt;Morris worm dissection&lt;/head&gt;
    &lt;p&gt;Known to be something of a prankster, Morris must have felt some foreboding about releasing his ‘innocent’ program into the wild. Evidence of this comes from his release method. “He released it by hacking into an MIT computer from his Cornell terminal in Ithaca, New York,” according to the FBI.&lt;/p&gt;
    &lt;p&gt;The Morris worm was written in C and targeted BSD UNIX systems, like VAX and Sun-3 machines. Specifically, the FBI writes, it “exploited a backdoor in the Internet’s electronic mail system and a bug in the ‘finger’ program that identified network users.” In contrast to computer viruses, the worm Morris had devised had no need of a host program, but could self-replicate and spread autonomously.&lt;/p&gt;
    &lt;p&gt;Thankfully, the Morris worm wasn’t written to cause damage to files. Due to those unintended consequences, though, it precipitated massive slowdowns, and messaging delays and system crashes were common symptoms. It became a computer news sensation in the worst possible way. Just to get rid of the worm in a timely fashion, some institutions ended up wiping complete systems and unplugging networks for as long as a week.&lt;/p&gt;
    &lt;p&gt;Among the Morris worm's casualties were prestigious institutions such as Berkeley, Harvard, Princeton, Stanford, Johns Hopkins, NASA, and the Lawrence Livermore National Laboratory.&lt;/p&gt;
    &lt;head rend="h2"&gt;Whodunit?&lt;/head&gt;
    &lt;p&gt;Experts worked hard to find a fix, and while they did so, the question of who was behind the worm came to the fore. Understandably, whoever created and unleashed this worm needed to feel some consequences, and thus, the FBI was brought in.&lt;/p&gt;
    &lt;p&gt;Apparently, Morris sought to anonymously explain and apologize for the worm, but an inadvertent slip of his initials by a friend landed Morris in it.&lt;/p&gt;
    &lt;p&gt;Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.&lt;/p&gt;
    &lt;p&gt;FBI interviews and computer file analysis would subsequently confirm Morris was the culprit. He was indicted under the rather freshly inked Computer Fraud and Abuse Act of 1986. After a court appearance for his misdemeanors in 1989, Morris ended up not with jail time, but with a fine, probation, and 400 hours of community service to complete.&lt;/p&gt;
    &lt;head rend="h2"&gt;Computer worms have been around longer than the World Wide Web&lt;/head&gt;
    &lt;p&gt;Back in November 1988, the Internet bore little resemblance to what it is today. For example, the World Wide Web (WWW) wasn’t even a thing. Though the WWW would soon form the core experience for the first tide of surfers in the 90s.&lt;/p&gt;
    &lt;p&gt;At the time, the Internet’s backbone was the NSFNET, the recent successor to ARPANET. Its purpose was mostly to expand the prior backbone’s reach beyond military and defense institutions, and it more broadly embraced academia. While we are here, it is worth mentioning that NSFNET was decommissioned in 1995, and succeeded by the commercial Internet, which emerged in the 1990s off the back of private ISPs and commercial backbones.&lt;/p&gt;
    &lt;p&gt;So, when we talk about 10% of the Internet being paralyzed by the Morris Worm, contemporary estimates are that about 6,000 of the approximately 60,000 connected systems were infected and impacted. Moreover, when we highlighted the potentially massive costs of this first worm propagating, estimates range from $100,000 to millions of dollars.&lt;/p&gt;
    &lt;p&gt;Computer worms have remained a scary phenomenon in recent times. For example, we reported on the first-generation AI worm, the Morris II generative AI worm, last year.&lt;/p&gt;
    &lt;p&gt;Follow Tom's Hardware on Google News, or add us as a preferred source, to get our latest news, analysis, &amp;amp; reviews in your feeds.&lt;/p&gt;
    &lt;p&gt;Mark Tyson is a news editor at Tom's Hardware. He enjoys covering the full breadth of PC tech; from business and semiconductor design to products approaching the edge of reason.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;header&gt;sb5k&lt;/header&gt;I was working at DEC when the worm slithered its way across the Internet, as part of an engineering team. I also helped manage our Ultrix systems; our IT department knew VMS only.Reply&lt;lb/&gt;I don't remember which CPU was in our systems, but the worm was not able to run on our systems, but I did find it dropped in them.&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;Gaston404&lt;/header&gt;I completely disagree with the tone of the article. Depicting this as an accident without consequences and limited effect is simply incorrect.Reply&lt;lb/&gt;Back then as a part time job I managed some of the traffic routing through Washington DC. Mail relays were shutdown and backed up queues were spooked off to tape. By today’s standards the volume of traffic may seem trivial but when many of these links ran at 56kbps or less. It was a mess. The main way administrators communicated with each other was email. This also affected collaboration between University researchers and access to the NSF super computer centers.&lt;lb/&gt;At the time rumors maintained that Morris used exploits that he learned from his father who had a consulting agreement with the NSA. So if this is true there is a certain level of non-originality.&lt;lb/&gt;On one hand stronger persecution may have reduced follow on internet crime. On the other hand the fragility demonstrated by this crime, resulted in the creation of procedures to deal with outages. If anything the naive sense of trusted collaboration that pervaded the Internet started to fade.&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;derekullo&lt;/header&gt;In 9 years, Tiktok has infected over 90% of the internet!Reply&lt;lb/&gt;Much slower but also much more insidious!&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;DS426&lt;/header&gt;Reply&lt;quote/&gt;The next big social media craze is probably just around the corner. I shutter to think how ludicrous it will be.derekullo said:In 9 years, Tiktok has infected over 90% of the internet!&lt;lb/&gt;Much slower but also much more insidious!&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45812024</guid><pubDate>Tue, 04 Nov 2025 15:23:14 +0000</pubDate></item><item><title>Pg_lake: Postgres with Iceberg and data lake access</title><link>https://github.com/Snowflake-Labs/pg_lake</link><description>&lt;doc fingerprint="fb9ba072642955e8"&gt;
  &lt;main&gt;
    &lt;p&gt;&lt;code&gt;pg_lake&lt;/code&gt; integrates Iceberg and data lake files into Postgres. With the &lt;code&gt;pg_lake&lt;/code&gt; extensions, you can use Postgres as a stand-alone lakehouse system that supports transactions and fast queries on Iceberg tables, and can directly work with raw data files in object stores like S3.&lt;/p&gt;
    &lt;p&gt;At a high level, &lt;code&gt;pg_lake&lt;/code&gt; lets you:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Create and modify Iceberg tables directly from PostgreSQL, with full transactional guarantees and query them from other engines&lt;/item&gt;
      &lt;item&gt;Query and import data files in object storage in Parquet, CSV, JSON, and Iceberg format&lt;/item&gt;
      &lt;item&gt;Export query results back to object storage in Parquet, CSV, or JSON formats using COPY commands&lt;/item&gt;
      &lt;item&gt;Read geospatial formats supported by GDAL, such as GeoJSON and Shapefiles&lt;/item&gt;
      &lt;item&gt;Use the built-in map type for semi-structured or key–value data&lt;/item&gt;
      &lt;item&gt;Combine heap, Iceberg, and external Parquet/CSV/JSON files in the same SQL queries and modifications — all with full transactional guarantees and no SQL limitations&lt;/item&gt;
      &lt;item&gt;Infer table columns and types from external data sources such as Iceberg, Parquet, JSON, and CSV files&lt;/item&gt;
      &lt;item&gt;Leverage DuckDB’s query engine underneath for fast execution without leaving Postgres&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are two ways to set up &lt;code&gt;pg_lake&lt;/code&gt;:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Using Docker, for an easy, ready-to-run test environment.&lt;/item&gt;
      &lt;item&gt;Building from source, for a manual setup or development use.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Both approaches include the PostgreSQL extensions, the &lt;code&gt;pgduck_server&lt;/code&gt; application and setting up S3-compatible storage.&lt;/p&gt;
    &lt;p&gt;Follow the Docker README to set up and run &lt;code&gt;pg_lake&lt;/code&gt; with Docker.&lt;/p&gt;
    &lt;p&gt;Once you’ve built and installed the required components, you can initialize &lt;code&gt;pg_lake&lt;/code&gt; inside Postgres.&lt;/p&gt;
    &lt;p&gt;Create all required extensions at once using &lt;code&gt;CASCADE&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;CREATE EXTENSION pg_lake CASCADE;
NOTICE:  installing required extension "pg_lake_table"
NOTICE:  installing required extension "pg_lake_engine"
NOTICE:  installing required extension "pg_extension_base"
NOTICE:  installing required extension "pg_lake_iceberg"
NOTICE:  installing required extension "pg_lake_copy"
CREATE EXTENSION&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;pgduck_server&lt;/code&gt; is a standalone process that implements the Postgres wire-protocol (locally), and underneath uses &lt;code&gt;DuckDB&lt;/code&gt; to execute queries.&lt;/p&gt;
    &lt;p&gt;When you run &lt;code&gt;pgduck_server&lt;/code&gt; it starts listening to port &lt;code&gt;5332&lt;/code&gt; on unix domain socket:&lt;/p&gt;
    &lt;code&gt;pgduck_server
LOG pgduck_server is listening on unix_socket_directory: /tmp with port 5332, max_clients allowed 10000
&lt;/code&gt;
    &lt;p&gt;As &lt;code&gt;pgduck_server&lt;/code&gt; implements Postgres wire protocol, you can access it via &lt;code&gt;psql&lt;/code&gt; on port &lt;code&gt;5332&lt;/code&gt; and host &lt;code&gt;/tmp&lt;/code&gt; and run commands via DuckDB.&lt;/p&gt;
    &lt;p&gt;For example, you can get the DuckDB version:&lt;/p&gt;
    &lt;code&gt;psql -p 5332 -h /tmp

select version() as duckdb_version; 
duckdb_version 
---------------- 
v1.3.2 (1 row)&lt;/code&gt;
    &lt;p&gt;You can also provide some additional settings while starting the server, to see all:&lt;/p&gt;
    &lt;code&gt;pgduck_server --help
&lt;/code&gt;
    &lt;p&gt;There are some important settings that should be adjusted, especially on production systems:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;--memory_limit&lt;/code&gt;: Optionally specify the maximum memory of pgduck_server similar to DuckDB's memory_limit, the default is 80 percent of the system memory&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--init_file_path &amp;lt;path&amp;gt;&lt;/code&gt;: Execute all statements in this file on start-up&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--cache_dir&lt;/code&gt;: Specify the directory to use to cache remote files (from S3)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;&lt;code&gt;pgduck_server&lt;/code&gt; relies on the DuckDB secrets manager for credentials and it follows the credentials chain by default for AWS and GCP. Make sure your cloud credentials are configured properly — for example, by setting them in ~/.aws/credentials.&lt;/p&gt;
    &lt;p&gt;Once you set up the credential chain, you should set the &lt;code&gt;pg_lake_iceberg.default_location_prefix&lt;/code&gt;. This is the location where Iceberg tables are stored:&lt;/p&gt;
    &lt;code&gt;SET pg_lake_iceberg.default_location_prefix TO 's3://testbucketpglake';&lt;/code&gt;
    &lt;p&gt;You can also set the credentials on &lt;code&gt;pgduck_server&lt;/code&gt; for local development with &lt;code&gt;minio&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;You can create Iceberg tables by adding &lt;code&gt;USING iceberg&lt;/code&gt; to your &lt;code&gt;CREATE TABLE&lt;/code&gt; statements.&lt;/p&gt;
    &lt;code&gt;CREATE TABLE iceberg_test USING iceberg 
      AS SELECT 
            i as key, 'val_'|| i  as val
         FROM 
            generate_series(0,99)i;&lt;/code&gt;
    &lt;p&gt;Then, query it:&lt;/p&gt;
    &lt;code&gt;SELECT count(*) FROM iceberg_test;
 count 
-------
   100
(1 row)&lt;/code&gt;
    &lt;p&gt;You can then see the Iceberg metadata location:&lt;/p&gt;
    &lt;code&gt;SELECT table_name, metadata_location FROM iceberg_tables;


    table_name     |                                                metadata_location
-------------------+--------------------------------------------------------------------------------------------------------------------
 iceberg_test      | s3://testbucketpglake/postgres/public/test/435029/metadata/00001-f0c6e20a-fd1c-4645-87c9-c0c64b92992b.metadata.json&lt;/code&gt;
    &lt;p&gt;You can import or export data directly using &lt;code&gt;COPY&lt;/code&gt; in Parquet, CSV, or newline-delimited JSON formats.  The format is automatically inferred from the file extension, or you can specify it explicitly with &lt;code&gt;COPY&lt;/code&gt; options like &lt;code&gt;WITH (format 'csv', compression 'gzip')&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;-- Copy data from Postgres to S3 with format parquet
-- Read from any data source, including iceberg tables, heap tables or any query results
COPY (SELECT * FROM iceberg_test) TO 's3://testbucketpglake/parquet_data/iceberg_test.parquet';

-- Copy back from S3 to any table in Postgres
-- This example copies into an iceberg table, but could be heap table as well
COPY iceberg_test FROM 's3://testbucketpglake/parquet_data/iceberg_test.parquet';&lt;/code&gt;
    &lt;p&gt;You can create a foreign table directly from a file or set of files without having to specify column names or types.&lt;/p&gt;
    &lt;code&gt;-- use the files under the path, can use * for all files
CREATE FOREIGN TABLE parquet_table() 
SERVER pg_lake 
OPTIONS (path 's3://testbucketpglake/parquet_data/*.parquet');

-- note that we infer the columns from the file
\d parquet_table
              Foreign table "public.parquet_table"
 Column |  Type   | Collation | Nullable | Default | FDW options 
--------+---------+-----------+----------+---------+-------------
 key    | integer |           |          |         | 
 val    | text    |           |          |         | 
Server: pg_lake
FDW options: (path 's3://testbucketpglake/parquet_data/*.parquet')

-- and, query it
select count(*) from parquet_table;
 count 
-------
   100
(1 row)
&lt;/code&gt;
    &lt;p&gt;A &lt;code&gt;pg_lake&lt;/code&gt; instance consists of two main components: PostgreSQL with the pg_lake extensions and pgduck_server.&lt;/p&gt;
    &lt;p&gt;Users connect to PostgreSQL to run SQL queries, and the &lt;code&gt;pg_lake&lt;/code&gt; extensions integrate with Postgres’s hooks to handle query planning, transaction boundaries, and overall orchestration of execution.&lt;/p&gt;
    &lt;p&gt;Behind the scenes, parts of query execution are delegated to DuckDB through pgduck_server, a separate multi-threaded process that implements the PostgreSQL wire protocol (locally). This process runs DuckDB together with our duckdb_pglake extension, which adds PostgreSQL-compatible functions and behavior.&lt;/p&gt;
    &lt;p&gt;Users typically don’t need to be aware of &lt;code&gt;pgduck_server&lt;/code&gt;; it operates transparently to improve performance. When appropriate, &lt;code&gt;pg_lake&lt;/code&gt; delegates scanning of the data and the computation to DuckDB’s highly parallel, column-oriented execution engine.&lt;/p&gt;
    &lt;p&gt;This separation also avoids the threading and memory-safety limitations that would arise from embedding DuckDB directly inside the Postgres process, which is designed around process isolation rather than multi-threaded execution. Moreover, it lets us interact with the query engine directly by connecting to it using standard Postgres clients.&lt;/p&gt;
    &lt;p&gt;The team behind pg_lake has a lot of experience building Postgres extensions (e.g. Citus, pg_cron, pg_documentdb). Over time, we’ve learned that large, monolithic PostgreSQL extensions are harder to evolve and maintain.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;pg_lake&lt;/code&gt; follows a modular design built around a set of interoperating components — mostly implemented as PostgreSQL extensions, others as supporting services or libraries.&lt;lb/&gt; Each part focuses on a well-defined layer, such as table and metadata management, catalog and object store integration, query execution, or data format handling. This approach makes it easier to extend, test, and evolve the system, while keeping it familiar to anyone with a PostgreSQL background.&lt;/p&gt;
    &lt;p&gt;The current set of components are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;pg_lake_iceberg: a PostgreSQL extension that implements the Iceberg specification&lt;/item&gt;
      &lt;item&gt;pg_lake_table: a PostgreSQL extension that implements a foreign data wrapper to query files in object storage&lt;/item&gt;
      &lt;item&gt;pg_lake_copy: a PostgreSQL extension that implements COPY to/from your data lake&lt;/item&gt;
      &lt;item&gt;pg_lake_engine: a common module for different pg_lake extensions&lt;/item&gt;
      &lt;item&gt;pg_extension_base: A foundational building block for other extensions&lt;/item&gt;
      &lt;item&gt;pg_extension_updater: An extension for updating all extensions on start-up. See README.md.&lt;/item&gt;
      &lt;item&gt;pg_lake_benchmark: a PostgreSQL extension that performs various benchmarks on lake tables. See README.md.&lt;/item&gt;
      &lt;item&gt;pg_map: A generic map type generator&lt;/item&gt;
      &lt;item&gt;pgduck_server: a stand-alone server that loads DuckDB into the same server machine and exposes DuckDB via the PostgreSQL protocol&lt;/item&gt;
      &lt;item&gt;duckdb_pglake: a DuckDB extension that adds missing PostgreSQL functions to DuckDB&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;&lt;code&gt;pg_lake&lt;/code&gt; development started in early 2024 at Crunchy Data with the goal of bringing Iceberg to PostgreSQL. The first few months were focused on building a robust integration of an external query engine (DuckDB). To get to market early, we made the query/import/export features available to Crunchy Bridge customers as Crunchy Bridge for Analytics.&lt;/p&gt;
    &lt;p&gt;Next, we started building a comprehensive implementation of the Iceberg (v2) protocol with support for transactions and almost all PostgreSQL features. In November 2024, we relaunched Crunchy Bridge for Analytics as Crunchy Data Warehouse available on Crunchy Bridge and on-premises.&lt;/p&gt;
    &lt;p&gt;In June 2025, Crunchy Data was acquired by Snowflake. Following the acquisition, Snowflake decided to open source the project as &lt;code&gt;pg_lake&lt;/code&gt; in November 2025. The initial version is 3.0 because of the two prior generations. If you’re currently a Crunchy Data Warehouse user there will be an automatic upgrade path, though some names will change.&lt;/p&gt;
    &lt;p&gt;Full project documentation can be found in the docs directory.&lt;/p&gt;
    &lt;p&gt;Copyright (c) Snowflake Inc. All rights reserved. Licensed under the Apache 2.0 license.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;pg_lake&lt;/code&gt; is dependent on third-party projects Apache Avro and DuckDB. During build, &lt;code&gt;pg_lake&lt;/code&gt; applies patches to Avro and certain DuckDB extensions in order to provide the &lt;code&gt;pg_lake&lt;/code&gt; functionality. The source code associated with the Avro and DuckDB extensions is downloaded from the applicable upstream repos and the source code associated with those projects remains under the original licenses. If you are packaging or redistributing packages that include &lt;code&gt;pg_lake&lt;/code&gt;, please note that you should review those upstream license terms.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45812606</guid><pubDate>Tue, 04 Nov 2025 16:12:27 +0000</pubDate></item><item><title>Launch HN: Plexe (YC X25) – Build production-grade ML models from prompts</title><link>https://www.plexe.ai/</link><description>&lt;doc fingerprint="d1d50ecbdfaae78"&gt;
  &lt;main&gt;
    &lt;p&gt;AI Data Scientist&lt;/p&gt;
    &lt;p&gt;AI Data Scientist&lt;/p&gt;
    &lt;p&gt;AI Data Scientist&lt;/p&gt;
    &lt;p&gt;Your Agentic ML Engineering&lt;/p&gt;
    &lt;p&gt;Team&lt;/p&gt;
    &lt;p&gt;Turn your data into engineered AI solutions.&lt;/p&gt;
    &lt;p&gt;Turn your data into engineered AI solutions.&lt;/p&gt;
    &lt;p&gt;Turn your data into engineered AI solutions.&lt;/p&gt;
    &lt;p&gt;Turn your raw data into engineered AI solutions.&lt;/p&gt;
    &lt;p&gt;Custom ML Models&lt;/p&gt;
    &lt;p&gt;Data Dashboards&lt;/p&gt;
    &lt;p&gt;API Endpoints&lt;/p&gt;
    &lt;p&gt;Batch Jobs&lt;/p&gt;
    &lt;p&gt;File Upload&lt;/p&gt;
    &lt;p&gt;Database Connectors&lt;/p&gt;
    &lt;p&gt;Custom ML Models&lt;/p&gt;
    &lt;p&gt;Data Dashboards&lt;/p&gt;
    &lt;p&gt;API Endpoints&lt;/p&gt;
    &lt;p&gt;Batch Jobs&lt;/p&gt;
    &lt;p&gt;File Upload&lt;/p&gt;
    &lt;p&gt;Database Connectors&lt;/p&gt;
    &lt;p&gt;Custom ML Models&lt;/p&gt;
    &lt;p&gt;Data Dashboards&lt;/p&gt;
    &lt;p&gt;API Endpoints&lt;/p&gt;
    &lt;p&gt;Batch Jobs&lt;/p&gt;
    &lt;p&gt;File Upload&lt;/p&gt;
    &lt;p&gt;Database Connectors&lt;/p&gt;
    &lt;p&gt;Custom ML Models&lt;/p&gt;
    &lt;p&gt;Data Dashboards&lt;/p&gt;
    &lt;p&gt;API Endpoints&lt;/p&gt;
    &lt;p&gt;Batch Jobs&lt;/p&gt;
    &lt;p&gt;File Upload&lt;/p&gt;
    &lt;p&gt;Database Connectors&lt;/p&gt;
    &lt;p&gt;How It Works&lt;/p&gt;
    &lt;p&gt;From Prompt to Production: The Plexe Workflow&lt;/p&gt;
    &lt;p&gt;Get Instant, Actionable Data Insights&lt;/p&gt;
    &lt;p&gt;Simply connect your data, Plexe checks quality, and spots the patterns that matter most.&lt;/p&gt;
    &lt;p&gt;Create Model&lt;/p&gt;
    &lt;p&gt;Build a custom AI model for your specific needs in a few simple steps&lt;/p&gt;
    &lt;p&gt;Give me quick insights on ecommerce fraud dataset&lt;/p&gt;
    &lt;p&gt;Quick Insights on E-commerce Fraud Dataset&lt;/p&gt;
    &lt;p&gt;ð Key Findings:&lt;/p&gt;
    &lt;p&gt;Data Quality: â Excellent - No missing values across all fields&lt;/p&gt;
    &lt;p&gt;Fraud Rate: ð Very low at -1% (mean of 0.01025), which is typical for fraud datasets&lt;/p&gt;
    &lt;p&gt;ð Notable Patterns&lt;/p&gt;
    &lt;p&gt;Transaction Amounts:&lt;/p&gt;
    &lt;p&gt;Average: $90.59 but with high variation (std: $116.23)&lt;/p&gt;
    &lt;p&gt;Ask anything about models or datasets...&lt;/p&gt;
    &lt;p&gt;Turn Ideas into Deployable ML Models&lt;/p&gt;
    &lt;p&gt;Tell Plexe what you want to achieve, in plain language and it will build a production-ready model thatâs engineered for your exact business challenge.&lt;/p&gt;
    &lt;p&gt;Create Model&lt;/p&gt;
    &lt;p&gt;Build a custom AI model for your specific needs in a few simple steps&lt;/p&gt;
    &lt;p&gt;Describe your modelâs purpose&lt;/p&gt;
    &lt;p&gt;Explain what you want your model to do in detail. Be specific about what you want to predict and what data it should use.&lt;/p&gt;
    &lt;p&gt;Model Intent&lt;/p&gt;
    &lt;p&gt;Build me a product recommendations model for my ecommerce website&lt;/p&gt;
    &lt;p&gt;Model Name&lt;/p&gt;
    &lt;p&gt;build-product-recommendations&lt;/p&gt;
    &lt;p&gt;Generate&lt;/p&gt;
    &lt;p&gt;A unique identifier for your model. Use lowercase letters, numbers, and hyphens only.&lt;/p&gt;
    &lt;p&gt;Full Transparency, Built In&lt;/p&gt;
    &lt;p&gt;We believe you should always know what your AI is doing and why. Plexe gives you clear performance metrics, training details, and easy-to-read explanations so you can trust every prediction your model makes.&lt;/p&gt;
    &lt;p&gt;Funding Prediction Model&lt;/p&gt;
    &lt;p&gt;completed&lt;/p&gt;
    &lt;p&gt;Retrain Model&lt;/p&gt;
    &lt;p&gt;Download Model&lt;/p&gt;
    &lt;p&gt;Performance&lt;/p&gt;
    &lt;p&gt;Overview&lt;/p&gt;
    &lt;p&gt;Technical Details&lt;/p&gt;
    &lt;p&gt;API Usage&lt;/p&gt;
    &lt;p&gt;Model Performance&lt;/p&gt;
    &lt;p&gt;Training performance, metrics and behavior insights.&lt;/p&gt;
    &lt;p&gt;Training Performance&lt;/p&gt;
    &lt;p&gt;Mean Absolute Error&lt;/p&gt;
    &lt;p&gt;0.2083&lt;/p&gt;
    &lt;p&gt;Training Details&lt;/p&gt;
    &lt;p&gt;Preprocessing&lt;/p&gt;
    &lt;p&gt;One-hot encoding for categorical variables proj_a, proj_b, funder and quarter.&lt;/p&gt;
    &lt;p&gt;Spotlight&lt;/p&gt;
    &lt;p&gt;Spotlight&lt;/p&gt;
    &lt;p&gt;As Seen On&lt;/p&gt;
    &lt;p&gt;As Seen On&lt;/p&gt;
    &lt;p&gt;As Seen On&lt;/p&gt;
    &lt;p&gt;Read what the media is saying about us&lt;/p&gt;
    &lt;p&gt;Read what the media is saying about us&lt;/p&gt;
    &lt;p&gt;Read what the media is saying about us&lt;/p&gt;
    &lt;p&gt;Featured in BIâs 10 Most Exciting AI Startups from YC Spring 2025&lt;/p&gt;
    &lt;p&gt;Featured in BIâs 10 Most Exciting AI Startups from YC Spring 2025&lt;/p&gt;
    &lt;p&gt;Plexe AI Redefines Credit Underwriting With Real-Time ML Models&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Plexe Launches to Bring Custom AI Models to Every Business&lt;/p&gt;
    &lt;p&gt;Plexe Launches to Bring Custom AI Models to Every Business&lt;/p&gt;
    &lt;p&gt;Plexe Launches to Bring Custom AI Models to Every Business&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Plexe featured in European Startups at Y Combinator&lt;/p&gt;
    &lt;p&gt;Plexe featured in European Startups at Y Combinator&lt;/p&gt;
    &lt;p&gt;Plexe featured in European Startups at Y Combinator&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Read More&lt;/p&gt;
    &lt;p&gt;Solutions&lt;/p&gt;
    &lt;p&gt;Solutions&lt;/p&gt;
    &lt;p&gt;What Plexe Can Build For You&lt;/p&gt;
    &lt;p&gt;What Plexe Can Build For You&lt;/p&gt;
    &lt;p&gt;What Plexe Can Build For You&lt;/p&gt;
    &lt;p&gt;Tailored ML solutions for your industry, deployed instantly.&lt;/p&gt;
    &lt;p&gt;Tailored ML solutions for your industry, deployed instantly.&lt;/p&gt;
    &lt;p&gt;Tailored ML solutions for your industry, deployed instantly.&lt;/p&gt;
    &lt;p&gt;Select your industry:&lt;/p&gt;
    &lt;p&gt;Finance &amp;amp; Banking&lt;/p&gt;
    &lt;p&gt;E-commerce&lt;/p&gt;
    &lt;p&gt;Logistics&lt;/p&gt;
    &lt;p&gt;Cybersecurity&lt;/p&gt;
    &lt;p&gt;Stop fraud before it drains your revenue.&lt;/p&gt;
    &lt;p&gt;Protect your customers and your bottom line with AI that spots suspicious activity before it becomes a problem. &lt;/p&gt;
    &lt;p&gt;Lend with confidence.&lt;/p&gt;
    &lt;p&gt;Make smarter credit decisions by accurately understanding whoâs truly creditworthy.&lt;/p&gt;
    &lt;p&gt;Keep your best customers from leaving.&lt;/p&gt;
    &lt;p&gt;Identify early signs of churn so you can act before valuable relationships are lost.&lt;/p&gt;
    &lt;p&gt;Select your industry:&lt;/p&gt;
    &lt;p&gt;Finance &amp;amp; Banking&lt;/p&gt;
    &lt;p&gt;E-commerce&lt;/p&gt;
    &lt;p&gt;Logistics&lt;/p&gt;
    &lt;p&gt;Cybersecurity&lt;/p&gt;
    &lt;p&gt;Stop fraud before it drains your revenue.&lt;/p&gt;
    &lt;p&gt;Protect your customers and your bottom line with AI that spots suspicious activity before it becomes a problem. &lt;/p&gt;
    &lt;p&gt;Lend with confidence.&lt;/p&gt;
    &lt;p&gt;Make smarter credit decisions by accurately understanding whoâs truly creditworthy.&lt;/p&gt;
    &lt;p&gt;Keep your best customers from leaving.&lt;/p&gt;
    &lt;p&gt;Identify early signs of churn so you can act before valuable relationships are lost.&lt;/p&gt;
    &lt;p&gt;Select your industry:&lt;/p&gt;
    &lt;p&gt;Finance &amp;amp; Banking&lt;/p&gt;
    &lt;p&gt;E-commerce&lt;/p&gt;
    &lt;p&gt;Logistics&lt;/p&gt;
    &lt;p&gt;Cybersecurity&lt;/p&gt;
    &lt;p&gt;Stop fraud before it drains your revenue.&lt;/p&gt;
    &lt;p&gt;Protect your customers and your bottom line with AI that spots suspicious activity before it becomes a problem. &lt;/p&gt;
    &lt;p&gt;Lend with confidence.&lt;/p&gt;
    &lt;p&gt;Make smarter credit decisions by accurately understanding whoâs truly creditworthy.&lt;/p&gt;
    &lt;p&gt;Keep your best customers from leaving.&lt;/p&gt;
    &lt;p&gt;Identify early signs of churn so you can act before valuable relationships are lost.&lt;/p&gt;
    &lt;p&gt;Select your industry:&lt;/p&gt;
    &lt;p&gt;Finance &amp;amp; Banking&lt;/p&gt;
    &lt;p&gt;E-commerce&lt;/p&gt;
    &lt;p&gt;Logistics&lt;/p&gt;
    &lt;p&gt;Cybersecurity&lt;/p&gt;
    &lt;p&gt;Stop fraud before it drains your revenue.&lt;/p&gt;
    &lt;p&gt;Protect your customers and your bottom line with AI that spots suspicious activity before it becomes a problem. &lt;/p&gt;
    &lt;p&gt;Lend with confidence.&lt;/p&gt;
    &lt;p&gt;Make smarter credit decisions by accurately understanding whoâs truly creditworthy.&lt;/p&gt;
    &lt;p&gt;Keep your best customers from leaving.&lt;/p&gt;
    &lt;p&gt;Identify early signs of churn so you can act before valuable relationships are lost.&lt;/p&gt;
    &lt;p&gt;FAQ&lt;/p&gt;
    &lt;p&gt;FAQ&lt;/p&gt;
    &lt;p&gt;Questions? Weâve Got Answers.&lt;/p&gt;
    &lt;p&gt;Questions? Weâve Got Answers.&lt;/p&gt;
    &lt;p&gt;Questions? Weâve Got Answers.&lt;/p&gt;
    &lt;p&gt;Everything you need to know about using Plexe, from building your first model to deploying at scale.&lt;/p&gt;
    &lt;p&gt;Everything you need to know about using Plexe, from building your first model to deploying at scale.&lt;/p&gt;
    &lt;p&gt;Everything you need to know about using Plexe, from building your first model to deploying at scale.&lt;/p&gt;
    &lt;p&gt;Who owns the models?&lt;/p&gt;
    &lt;p&gt;Where can I use Plexe?&lt;/p&gt;
    &lt;p&gt;Do you have a free version?&lt;/p&gt;
    &lt;p&gt;Can I use Plexe without my own data?&lt;/p&gt;
    &lt;p&gt;How secure is my data?&lt;/p&gt;
    &lt;p&gt;Can Plexe integrate with my existing tools?&lt;/p&gt;
    &lt;p&gt;Do you offer annual or enterprise pricing?&lt;/p&gt;
    &lt;p&gt;Who owns the models?&lt;/p&gt;
    &lt;p&gt;Where can I use Plexe?&lt;/p&gt;
    &lt;p&gt;Do you have a free version?&lt;/p&gt;
    &lt;p&gt;Can I use Plexe without my own data?&lt;/p&gt;
    &lt;p&gt;How secure is my data?&lt;/p&gt;
    &lt;p&gt;Can Plexe integrate with my existing tools?&lt;/p&gt;
    &lt;p&gt;Do you offer annual or enterprise pricing?&lt;/p&gt;
    &lt;p&gt;Who owns the models?&lt;/p&gt;
    &lt;p&gt;Where can I use Plexe?&lt;/p&gt;
    &lt;p&gt;Do you have a free version?&lt;/p&gt;
    &lt;p&gt;Can I use Plexe without my own data?&lt;/p&gt;
    &lt;p&gt;How secure is my data?&lt;/p&gt;
    &lt;p&gt;Can Plexe integrate with my existing tools?&lt;/p&gt;
    &lt;p&gt;Do you offer annual or enterprise pricing?&lt;/p&gt;
    &lt;p&gt;Who owns the models?&lt;/p&gt;
    &lt;p&gt;Where can I use Plexe?&lt;/p&gt;
    &lt;p&gt;Do you have a free version?&lt;/p&gt;
    &lt;p&gt;Can I use Plexe without my own data?&lt;/p&gt;
    &lt;p&gt;How secure is my data?&lt;/p&gt;
    &lt;p&gt;Can Plexe integrate with my existing tools?&lt;/p&gt;
    &lt;p&gt;Do you offer annual or enterprise pricing?&lt;/p&gt;
    &lt;p&gt;Letâs Build Something Incredible Together.&lt;/p&gt;
    &lt;p&gt;Whether youâre starting from scratch or scaling to millions of users, Plexe is your AI engineering team, ready to turn your ideas into real solutions.&lt;/p&gt;
    &lt;p&gt;Whether youâre starting from scratch or scaling to millions of users, Plexe is your AI engineering team, ready to turn your data into your competitive advantage.&lt;/p&gt;
    &lt;p&gt;Letâs Build Something Incredible Together.&lt;/p&gt;
    &lt;p&gt;Whether youâre starting from scratch or scaling to millions of users, Plexe is your AI engineering team, ready to turn your ideas into real solutions.&lt;/p&gt;
    &lt;p&gt;Letâs Build Something Incredible Together.&lt;/p&gt;
    &lt;p&gt;Whether youâre starting from scratch or scaling to millions of users, Plexe is your AI engineering team, ready to turn your ideas into real solutions.&lt;/p&gt;
    &lt;p&gt;Â© 2025 Plexe Ltd. All rights reserved.&lt;/p&gt;
    &lt;p&gt;Â© 2025 Plexe Ltd. All rights reserved.&lt;/p&gt;
    &lt;p&gt;Â© 2025 Plexe Ltd. All rights reserved.&lt;/p&gt;
    &lt;p&gt;Â© 2025 Plexe Ltd. All rights reserved.&lt;/p&gt;
    &lt;p&gt;How It Works&lt;/p&gt;
    &lt;p&gt;From Prompt to Production: The Plexe Workflow&lt;/p&gt;
    &lt;p&gt;From Prompt to Production: The Plexe Workflow&lt;/p&gt;
    &lt;p&gt;Get Instant, Actionable Data Insights&lt;/p&gt;
    &lt;p&gt;Simply connect your data, Plexe checks quality, and spots the patterns that matter most. Youâll see whatâs working, whatâs not, and where the real opportunities are hiding. No code, no setup, no fuss.&lt;/p&gt;
    &lt;p&gt;Create Model&lt;/p&gt;
    &lt;p&gt;Build a custom AI model for your specific needs in a few simple steps&lt;/p&gt;
    &lt;p&gt;Give me quick insights on ecommerce fraud dataset&lt;/p&gt;
    &lt;p&gt;Quick Insights on E-commerce Fraud Dataset&lt;/p&gt;
    &lt;p&gt;ð Key Findings:&lt;/p&gt;
    &lt;p&gt;Data Quality: â Excellent - No missing values across all fields&lt;/p&gt;
    &lt;p&gt;Fraud Rate: ð Very low at -1% (mean of 0.01025), which is typical for fraud datasets&lt;/p&gt;
    &lt;p&gt;ð Notable Patterns&lt;/p&gt;
    &lt;p&gt;Transaction Amounts:&lt;/p&gt;
    &lt;p&gt;Average: $90.59 but with high variation (std: $116.23)&lt;/p&gt;
    &lt;p&gt;Ask anything about models or datasets...&lt;/p&gt;
    &lt;p&gt;Turn Ideas into Deployable ML Models&lt;/p&gt;
    &lt;p&gt;Tell Plexe what you want to achieve, in plain language and weâll build a production-ready model thatâs engineered for your exact business challenge. Whether itâs predicting churn or fraud detection, youâll go from idea to working AI in hours, not months.&lt;/p&gt;
    &lt;p&gt;Create Model&lt;/p&gt;
    &lt;p&gt;Build a custom AI model for your specific needs in a few simple steps&lt;/p&gt;
    &lt;p&gt;Describe your modelâs purpose&lt;/p&gt;
    &lt;p&gt;Explain what you want your model to do in detail. Be specific about what you want to predict and what data it should use.&lt;/p&gt;
    &lt;p&gt;Model Intent&lt;/p&gt;
    &lt;p&gt;Build me a product recommendations model for my ecommerce website&lt;/p&gt;
    &lt;p&gt;Model Name&lt;/p&gt;
    &lt;p&gt;build-product-recommendations&lt;/p&gt;
    &lt;p&gt;Generate&lt;/p&gt;
    &lt;p&gt;A unique identifier for your model. Use lowercase letters, numbers, and hyphens only.&lt;/p&gt;
    &lt;p&gt;Full Transparency, Built In&lt;/p&gt;
    &lt;p&gt;We believe you should always know what your AI is doing and why. Plexe gives you clear performance metrics, training details, and easy-to-read explanations so you can trust every prediction your model makes.&lt;/p&gt;
    &lt;p&gt;Funding Prediction Model&lt;/p&gt;
    &lt;p&gt;completed&lt;/p&gt;
    &lt;p&gt;Retrain Model&lt;/p&gt;
    &lt;p&gt;Download Model&lt;/p&gt;
    &lt;p&gt;Performance&lt;/p&gt;
    &lt;p&gt;Overview&lt;/p&gt;
    &lt;p&gt;Technical Details&lt;/p&gt;
    &lt;p&gt;API Usage&lt;/p&gt;
    &lt;p&gt;Model Performance&lt;/p&gt;
    &lt;p&gt;Training performance, metrics and behavior insights.&lt;/p&gt;
    &lt;p&gt;Training Performance&lt;/p&gt;
    &lt;p&gt;Mean Absolute Error&lt;/p&gt;
    &lt;p&gt;0.2083&lt;/p&gt;
    &lt;p&gt;Training Details&lt;/p&gt;
    &lt;p&gt;Preprocessing&lt;/p&gt;
    &lt;p&gt;One-hot encoding for categorical variables proj_a, proj_b, funder and quarter.&lt;/p&gt;
    &lt;p&gt;How It Works&lt;/p&gt;
    &lt;p&gt;From Prompt to Production: The Plexe Workflow&lt;/p&gt;
    &lt;p&gt;How It Works&lt;/p&gt;
    &lt;p&gt;From Prompt to Production: The Plexe Workflow&lt;/p&gt;
    &lt;p&gt;Get Instant, Actionable Data Insights&lt;/p&gt;
    &lt;p&gt;Simply connect your data, Plexe checks quality, and spots the patterns that matter most. Youâll see whatâs working, whatâs not, and where the real opportunities are hiding. No code, no setup, no fuss.&lt;/p&gt;
    &lt;p&gt;Create Model&lt;/p&gt;
    &lt;p&gt;Build a custom AI model for your specific needs in a few simple steps&lt;/p&gt;
    &lt;p&gt;Give me quick insights on ecommerce fraud dataset&lt;/p&gt;
    &lt;p&gt;Quick Insights on E-commerce Fraud Dataset&lt;/p&gt;
    &lt;p&gt;ð Key Findings:&lt;/p&gt;
    &lt;p&gt;Data Quality: â Excellent - No missing values across all fields&lt;/p&gt;
    &lt;p&gt;Fraud Rate: ð Very low at -1% (mean of 0.01025), which is typical for fraud datasets&lt;/p&gt;
    &lt;p&gt;ð Notable Patterns&lt;/p&gt;
    &lt;p&gt;Transaction Amounts:&lt;/p&gt;
    &lt;p&gt;Average: $90.59 but with high variation (std: $116.23)&lt;/p&gt;
    &lt;p&gt;Ask anything about models or datasets...&lt;/p&gt;
    &lt;p&gt;Turn Ideas into Deployable ML Models&lt;/p&gt;
    &lt;p&gt;Tell Plexe what you want to achieve, in plain language and weâll build a production-ready model thatâs engineered for your exact business challenge. Whether itâs predicting churn or fraud detection, youâll go from idea to working AI in hours, not months.&lt;/p&gt;
    &lt;p&gt;Create Model&lt;/p&gt;
    &lt;p&gt;Build a custom AI model for your specific needs in a few simple steps&lt;/p&gt;
    &lt;p&gt;Describe your modelâs purpose&lt;/p&gt;
    &lt;p&gt;Explain what you want your model to do in detail. Be specific about what you want to predict and what data it should use.&lt;/p&gt;
    &lt;p&gt;Model Intent&lt;/p&gt;
    &lt;p&gt;Build me a product recommendations model for my ecommerce website&lt;/p&gt;
    &lt;p&gt;Model Name&lt;/p&gt;
    &lt;p&gt;build-product-recommendations&lt;/p&gt;
    &lt;p&gt;Generate&lt;/p&gt;
    &lt;p&gt;A unique identifier for your model. Use lowercase letters, numbers, and hyphens only.&lt;/p&gt;
    &lt;p&gt;Full Transparency, Built In&lt;/p&gt;
    &lt;p&gt;We believe you should always know what your AI is doing and why. Plexe gives you clear performance metrics, training details, and easy-to-read explanations so you can trust every prediction your model makes.&lt;/p&gt;
    &lt;p&gt;Funding Prediction Model&lt;/p&gt;
    &lt;p&gt;completed&lt;/p&gt;
    &lt;p&gt;Retrain Model&lt;/p&gt;
    &lt;p&gt;Download Model&lt;/p&gt;
    &lt;p&gt;Performance&lt;/p&gt;
    &lt;p&gt;Overview&lt;/p&gt;
    &lt;p&gt;Technical Details&lt;/p&gt;
    &lt;p&gt;API Usage&lt;/p&gt;
    &lt;p&gt;Model Performance&lt;/p&gt;
    &lt;p&gt;Training performance, metrics and behavior insights.&lt;/p&gt;
    &lt;p&gt;Training Performance&lt;/p&gt;
    &lt;p&gt;Mean Absolute Error&lt;/p&gt;
    &lt;p&gt;0.2083&lt;/p&gt;
    &lt;p&gt;Training Details&lt;/p&gt;
    &lt;p&gt;Preprocessing&lt;/p&gt;
    &lt;p&gt;One-hot encoding for categorical variables proj_a, proj_b, funder and quarter.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45813310</guid><pubDate>Tue, 04 Nov 2025 17:07:47 +0000</pubDate></item><item><title>Codemaps: Understand Code, Before You Vibe It</title><link>https://cognition.ai/blog/codemaps</link><description>&lt;doc fingerprint="3fc296052cb3ae5f"&gt;
  &lt;main&gt;
    &lt;quote&gt;“Your code is your understanding of the problem you’re exploring. So it’s only when you have your code in your head that you really understand the problem.” — Paul Graham&lt;/quote&gt;
    &lt;p&gt;Software development only becomes engineering with understanding. Your ability to reason through your most challenging coding tasks is constrained by your mental model of how things work — in other words, how quickly and how well you onboard to any codebase for solving any problem. However most AI vibe coding tools are aimed at relieving you of that burden by reading → thinking → writing the code for you, increasing the separation from you and your code. This is fine for low value, commodity tasks, but absolutely unacceptable for the hard, sensitive, and high value work that defines real engineering.&lt;/p&gt;
    &lt;p&gt;We all need more AI that turns your brain ON, not OFF.&lt;/p&gt;
    &lt;p&gt;Today we are announcing Windsurf Codemaps, which are first-of-its-kind AI-annotated structured maps of your code, powered by SWE-1.5 and Claude Sonnet 4.5. Building on our popular work from DeepWiki and Ask Devin, Codemaps is the next step in hyper-contextualized codebase understanding, grounded in precise code navigation.&lt;/p&gt;
    &lt;p&gt;Every engineering task — debugging, refactors, new features — starts with understanding. Great engineers aren’t just good at writing code; they’re good at reading it, building mental models that span files, layers, and systems.&lt;/p&gt;
    &lt;p&gt;But modern codebases are sprawling: hundreds of files, multiple services, dense abstractions. Based on own experience and deep conversations with our customers across the Fortune 500, even top engineers spend much of their deep-work time finding and remembering what matters.&lt;/p&gt;
    &lt;p&gt;It’s a huge tax on productivity:&lt;/p&gt;
    &lt;p&gt;This is the frontier that AI coding tools haven’t yet solved. Onboarding isn’t even a onetime cost, you pay it every time you switch context and codebases. The faster and better you understand your codebase, the faster and better you’ll be able to fix it yourself, or prompt agents to do it.&lt;/p&gt;
    &lt;p&gt;Until today, the standard approach by Copilot, Claude Code, Codex, and even Windsurf Cascade, was to have you ask questions of a generalist agent with access to your code in a typical chat experience. But those solutions don’t solve focused onboarding and strongly grounded navigation to onboard, debug, and better context engineer for your codebase.&lt;/p&gt;
    &lt;p&gt;At Cognition, we’ve been investing far more deeply in understanding:&lt;/p&gt;
    &lt;p&gt;Codemaps is our next investment in tooling that makes engineers the best versions of themselves.&lt;/p&gt;
    &lt;p&gt;When you first open Codemaps (click the new maps icon or Cmd+Shift+C in Windsurf) with a codebase opened in Windsurf, you can enter in a prompt for the task you are trying to do, or take one of the automatic suggestions. You can choose a Fast (SWE-1.5) or Smart (Sonnet 4.5) model to generate your Codemap. Every Codemap is a snapshot of your code and respects ZDR.&lt;/p&gt;
    &lt;p&gt;Based on our demos to customers, you will experience Codemaps best on your own codebase and asking a question about how or where some functionality works. In our dogfooding, we find particular effectiveness tracing through client-server problems or a data pipeline or debugging auth/security issues:&lt;/p&gt;
    &lt;p&gt;If all you wanted was to quickly jump through grouped and nested parts of your code that related to your question, this is already an improvement compared to asking the same question in Cascade, where answers are not as densely linked to the exact lines of code.&lt;/p&gt;
    &lt;p&gt;You can also toggle over to a visually drawn Codemap, which performs the same functions when you click on individual nodes: they send you to the exact part of the codebase you clicked on.&lt;/p&gt;
    &lt;p&gt;However, if you want a little more context, then you can hit “See more” in any section to expand our “trace guide” that gives a more descriptive explanation of what groups the discovered lines together.&lt;/p&gt;
    &lt;p&gt;Finally, inside Cascade you can also reference a codemap for the agent with &lt;code&gt;@{codemap}&lt;/code&gt; (all of it, or a particular subsection) in your prompt to provide more specific context and dramatically improve the performance of your agent for your task.&lt;/p&gt;
    &lt;p&gt;We feel that the popular usage of “vibe coding” has strayed far from the original intent, into a blanket endorsement of plowing through any and all AI generated code slop. If you look at the difference between the most productive vs the problematic AI-assisted coders, the productive ones can surf the vibes of code that they understand well, whereas people get into trouble when the code they generate and maintain starts to outstrip their ability to understand it.&lt;/p&gt;
    &lt;p&gt;To understand is to be accountable. As AI takes on more of the easy work, the hard problems left to humans are the ones that demand real comprehension: debugging complex systems, refactoring legacy code, making architecture decisions. In this new era, the engineer’s role shifts from authoring to accountability — you might not write every line, but you’re still responsible for what ships. That accountability depends on understanding what the AI produced, why it changed, and whether it’s safe. Codemaps closes that gap by giving both the human and the AI a shared picture of the system: how it’s structured, how data flows, where dependencies live. Codemaps is our latest Fast Agent, but as we discussed in the Semi-Async Valley of Death, our goal isn't just about speed, it is to help your human engineers stay in flow, stay on top of their code, and to move faster and more confidently on the hardest problems, never shipping slop that they don't understand.&lt;/p&gt;
    &lt;p&gt;Augment engineers for high value work, relieve them of low value work. The other local minima that the coding agent industry has gotten stuck in is in the general messaging of replacing engineers for low value work and not having any solutions for the hardest tasks apart from “pls ultrathink high, no mistakes”, which only gives autonomy to the agent, at the expense of the engineer. The long history of human-machine collaboration teaches us that we can always do more with the synergy rather than humans-alone or AI-alone. Our view is that the AI product that engineers will love most is the one that makes them better at their job, not the one that tries to replace them with a sloppy facsimile of themselves.&lt;/p&gt;
    &lt;p&gt;With Codemaps, we are now exposing to humans some of the indexing and analysis we do inside of our coding agents. These artifacts are sharable today across teams for learning and discussion, but we have yet to benchmark how much better they can make our coding agents like Devin and Cascade in solving challenging tasks on their own. We also see opportunities for connecting and annotating codemaps, as well as defining an open &lt;code&gt;.codemap&lt;/code&gt; protocol that can be used by other code agents and custom tooling built by you. Complementing our Fast Context feature, this is an advancement in human-readable automatic context engineering.&lt;/p&gt;
    &lt;p&gt;You can try Codemaps on the latest versions of Windsurf, or DeepWiki!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45813767</guid><pubDate>Tue, 04 Nov 2025 17:47:09 +0000</pubDate></item><item><title>I took all my projects off the cloud, saving thousands of dollars</title><link>https://rameerez.com/send-this-article-to-your-friend-who-still-thinks-the-cloud-is-a-good-idea/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45816041</guid><pubDate>Tue, 04 Nov 2025 21:22:15 +0000</pubDate></item><item><title>Grayskull: A tiny computer vision library in C for embedded systems, etc.</title><link>https://github.com/zserge/grayskull</link><description>&lt;doc fingerprint="6e340ed9bad71609"&gt;
  &lt;main&gt;
    &lt;p&gt;Grayskull is a minimalist, dependency-free computer vision library designed for microcontrollers and other resource-constrained devices. It focuses on grayscale images and provides modern, practical algorithms that fit in a few kilobytes of code. Single-header design, integer-based operations, pure C99.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Image operations: copy, crop, resize (bilinear), downsample&lt;/item&gt;
      &lt;item&gt;Filtering: blur, Sobel edges, thresholding (global, Otsu, adaptive)&lt;/item&gt;
      &lt;item&gt;Morphology: erosion, dilation&lt;/item&gt;
      &lt;item&gt;Geometry: connected components, perspective warp&lt;/item&gt;
      &lt;item&gt;Features: FAST/ORB keypoints and descriptors (object tracking)&lt;/item&gt;
      &lt;item&gt;Local binary patterns: LBP cascades to detect faces, vehicles etc&lt;/item&gt;
      &lt;item&gt;Utilities: PGM read/write&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As usual, no dependencies, no dynamic memory allocation, no C++, no surprises. Just a single header file under 1KLOC.&lt;/p&gt;
    &lt;p&gt;Check out the examples folder for more!&lt;/p&gt;
    &lt;p&gt;Online demo: try Grayskull in your browser.&lt;/p&gt;
    &lt;code&gt;#include "grayskull.h"

struct gs_image img = gs_read_pgm("input.pgm");
struct gs_image blurred = gs_alloc(img.w, img.h);
struct gs_image binary = gs_alloc(img.w, img.h);

gs_blur(blurred, img, 2);
gs_threshold(binary, blurred, gs_otsu_theshold(blurred));

gs_write_pgm(binary, "output.pgm");
gs_free(img);
gs_free(blurred);
gs_free(binary);&lt;/code&gt;
    &lt;p&gt;Note that &lt;code&gt;gs_alloc&lt;/code&gt;/&lt;code&gt;gs_free&lt;/code&gt; are optional helpers; you can allocate image pixel buffers any way you like.&lt;/p&gt;
    &lt;code&gt;struct gs_image { unsigned w, h; uint8_t *data; };
struct gs_rect { unsigned x, y, w, h; }; // ROI
struct gs_point { unsigned x, y; }; // corners

uint8_t gs_get(struct gs_image img, unsigned x, unsigned y);
void gs_set(struct gs_image img, unsigned x, unsigned y, uint8_t value);
void gs_crop(struct gs_image dst, struct gs_image src, struct gs_rect roi);
void gs_copy(struct gs_image dst, struct gs_image src);
void gs_resize(struct gs_image dst, struct gs_image src);
void gs_downsample(struct gs_image dst, struct gs_image src);

// Thresholding
void gs_histogram(struct gs_image img, unsigned hist[256]);
void gs_threshold(struct gs_image img, uint8_t threshold);
uint8_t gs_otsu_threshold(struct gs_image img);
void gs_adaptive_threshold(struct gs_image dst, struct gs_image src, unsigned radius, int c);

// Filters
void gs_blur(struct gs_image dst, struct gs_image src, unsigned radius);
void gs_erode(struct gs_image dst, struct gs_image src);
void gs_dilate(struct gs_image dst, struct gs_image src);
void gs_sobel(struct gs_image dst, struct gs_image src);

// Blobs (connected components) and contours
typedef uint16_t gs_label;
struct gs_blob { gs_label label; unsigned area; struct gs_rect box; struct gs_point centroid; };
struct gs_contour { struct gs_rect box; struct gs_point start; unsigned length; };
unsigned gs_blobs(struct gs_image img, gs_label *labels, struct gs_blob *blobs, unsigned nblobs);
void gs_blob_corners(struct gs_image img, gs_label *labels, struct gs_blob *b, struct gs_point c[4]);
void gs_perspective_correct(struct gs_image dst, struct gs_image src, struct gs_point c[4]);
void gs_trace_contour(struct gs_image img, struct gs_image visited, struct gs_contour *c);

// FAST/ORB
struct gs_keypoint { struct gs_point pt; unsigned response; float angle; uint32_t descriptor[8]; };
struct gs_match { unsigned idx1, idx2; unsigned distance; };
unsigned gs_fast(struct gs_image img, struct gs_image scoremap, struct gs_keypoint *kps, unsigned nkps, unsigned threshold);
float gs_compute_orientation(struct gs_image img, unsigned x, unsigned y, unsigned r);
void gs_brief_descriptor(struct gs_image img, struct gs_keypoint *kp);
unsigned gs_orb_extract(struct gs_image img, struct gs_keypoint *kps, unsigned nkps, unsigned threshold, uint8_t *scoremap_buffer);
unsigned gs_match_orb(const struct gs_keypoint *kps1, unsigned n1, const struct gs_keypoint *kps2, unsigned n2, struct gs_match *matches, unsigned max_matches, float max_distance);

// LBP cascades
struct gs_lbp_cascade { uint16_t window_w, window_h; uint16_t nfeatures, nweaks, nstages; const int8_t *features; /* [nfeatures * 4] */ const uint16_t *weak_feature_idx; const float *weak_left_val, *weak_right_val; const uint16_t *weak_subset_offset, *weak_num_subsets; const int32_t *subsets; const uint16_t *stage_weak_start, *stage_nweaks; const float *stage_threshold; };
void gs_integral(struct gs_image src, unsigned *ii);
unsigned gs_lbp_window(const struct gs_lbp_cascade *c, const unsigned *ii, unsigned iw, unsigned ih, int x, int y, float scale);
unsigned gs_lbp_detect(const struct gs_lbp_cascade *c, const unsigned *ii, unsigned iw, unsigned ih, struct gs_rect *rects, unsigned max_rects, float scale_factor, float min_scale, float max_scale, int step);

// Optional:
struct gs_image gs_alloc(unsigned w, unsigned h);
void gs_free(struct gs_image img);
struct gs_image gs_read_pgm(const char *path);
int gs_write_pgm(struct gs_image img, const char *path);&lt;/code&gt;
    &lt;p&gt;This project is licensed under the MIT License. Feel free to use in research, products, and your next embedded vision project!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45816673</guid><pubDate>Tue, 04 Nov 2025 22:35:58 +0000</pubDate></item><item><title>Mr TIFF</title><link>https://inventingthefuture.ghost.io/mr-tiff/</link><description>&lt;doc fingerprint="6498b18bb326a2bd"&gt;
  &lt;main&gt;
    &lt;p&gt;For as long as I have published my books, one of my overarching goals was to give credit to those who actually invented the hardware and software that we use.&lt;/p&gt;
    &lt;p&gt;I have spent 10,000+ hours to create an accurate record of their work but I'm not complaining. The 'as-close-to-possible' truth of invention by individuals or teams meant identifying the work, educating myself, writing questions, and sending emails. And after that process, I set up a chat because it all gets down to talking to someone on the other side of the world, about something that happened 30 or 40 years ago.&lt;/p&gt;
    &lt;p&gt;If the invention involves a team, I try to interview more than one person, so I can cross-check the facts. Not to call anyone out, it’s just that, given time, we all forget the facts. And everyone adds their personal take. It’s because of that, for example, that I know the English musician Peter Gabriel really did visit Apple's research labs as they tested the Apple Sound Chip, and gave the team his personal approval to use the song 'Red Rain' for the Macintosh II launch. Wil Oxford, Steve Perlman, Mike Potel, Mark Lentczner and Steve Milne told me so.&lt;/p&gt;
    &lt;p&gt;As I was wrapping up Version 2.3 of Inventing the Future, I spoke with Steve M and Mark about the AIFF (Audio Interchange File Format) audio standard that they built around the same time as their VIP visit. They did so as professional programmers, amateur musicians and electronic music experts. Milne and Lentczner knew users needed a standard file format to make their work lives easier and to fend off confusion in the nascent MIDI marketplace. But it didn't exist. So Steve and Mark consulted with users and manufacturers in the Apple cafeteria after hours. This work is interesting on its own but it also underpinned other research. The AIFF, Apple Sound Chip, and MIDI Manager work scaffolded QuickTime and its extensible video formats and programs in 1991. Senior engineer Toby Farrand told me:&lt;/p&gt;
    &lt;p&gt;Audio drove the development of QuickTime more than anything.&lt;/p&gt;
    &lt;p&gt;So who or what drove the development of AIFF?&lt;/p&gt;
    &lt;p&gt;Steve and Mark referred me to the IFF (Interchange File Format (IFF) and the TIFF (Tag Image File Format) that were built before AIFF, in 1985 and 1986 respectively. These file formats were the benchmark for open media standards. My search pivoted, as it always does, to understand those inventions. I expected to be able to find the engineer or engineers names, track them down and interview them. It has worked around 100 times before.&lt;/p&gt;
    &lt;p&gt;Jerry Morrison created IFF while working at Electronic Arts and then went to Apple, where he liaised with the AIFF team. I could easily background his work.&lt;/p&gt;
    &lt;p&gt;So I turned my attention to TIFF, built initially as an image standard for desktop publishing. TIFF was able to store monochrome, grayscale, and color images, alongside metadata such as size, compression algorithms, and color space information. In many ways, it was a lot like AIFF so I was keen to know more. But I couldn't find a TIFF creator. No matter how I enquired, Aldus created TIFF.&lt;/p&gt;
    &lt;p&gt;To be clear, while a search for AIFF will offer up a company (Apple) not a person, I was able to find Milne and Lentczner in part because of their unique names and because Apple publicised the AIFF work and those publications are archived.&lt;/p&gt;
    &lt;p&gt;All I had was Aldus, an American company that created desktop publishing with the help of Apple and Adobe. In fact, Paul Brainerd, the cofounder of Aldus coined the term 'desktop publishing' to quickly explain the technicality of what they were doing to potential investors. But Aldus and their seminal product, PageMaker, are long gone, and there were no breadcrumbs for TIFF's creation.&lt;/p&gt;
    &lt;p&gt;Finally, after a day-long trawl through MacWeek back issues, I found Steve Carlson. (below)&lt;/p&gt;
    &lt;p&gt;Then I ran a similar length search through the Computer History Museum’s amazing Oral Histories transcriptions. Brainerd mentioned Carlson's name in an interview. (below)&lt;/p&gt;
    &lt;p&gt;But it was too brief an explanation so I kept looking. Then the trail went cold.&lt;/p&gt;
    &lt;p&gt;And that was because, folks had misspelt his name when quoting him and then that was copied into magazines, and reviews and so forth. Brainerd's CHM interview transcript was wrong. But I didn’t know that.&lt;/p&gt;
    &lt;p&gt;I just kept looking for Steve Carlson.&lt;/p&gt;
    &lt;p&gt;I found other inventors because they had unique middle or last names or by random methods such as searching glider pilot licences in the Napa Valley after a tip from a former colleague that 'so and so' was a pilot in retirement. I had no tips, no links, nothing.&lt;/p&gt;
    &lt;p&gt;Why couldn’t I find Steve Carlson?&lt;/p&gt;
    &lt;p&gt;All the while, the answer was right under my nose. I had downloaded the final Aldus TIFF specifications document, hoping to find the author’s name. However, the name is seemingly written in white text on white paper - making it invisible. What?&lt;/p&gt;
    &lt;p&gt;See below where I have highlighted the region with a blue block over the text.&lt;/p&gt;
    &lt;p&gt;For a reason I can’t recall, I downloaded a plain text version and typed in Carlson to see if he was mentioned, but I must have paused at ‘Carls...' and the search functionality automatically filled in the rest. Suddenly I was staring at:&lt;/p&gt;
    &lt;p&gt;Author/Editor/Arbitrator: Steve Carlsen.&lt;/p&gt;
    &lt;p&gt;‘Carls-EN’&lt;/p&gt;
    &lt;p&gt;A quick trip to Google patents, and a search for Steve Carlsen, Stephen Carlsen. Bingo! Stephen E. Carlsen’s patents at Aldus (and Adobe) in Issaquah, WA.&lt;/p&gt;
    &lt;p&gt;I checked the geography, as most folks of a certain age do not stray far from the addresses filed in their patents, and typed Stephen’s correctly spelled surname into the online US White Pages for Washington State. There was ‘a’ Stephen Carlsen listed in a retirement village in WA. His age matched, but there were no public facing email addresses.&lt;/p&gt;
    &lt;p&gt;I searched bulletin boards on the topic of TIFF, as I had found a former Apple engineer that way. Don had picked an abbreviation of his initials and numbers to post on BBS in his college days and then carried that same combination into adulthood. Many of us did. I took a punt pasting his unique prefix into hotmail, gmail etc. and found Don and interviewed him, but - Stephen Carlsen did not show up in a BBS. So, no email to try.&lt;/p&gt;
    &lt;p&gt;My ‘last straw' method for finding someone is a stamped envelope. I wrote, printed and mailed a one-page letter to Stephen's listed address, and crossed my fingers. Four months later he popped up in my email.&lt;/p&gt;
    &lt;p&gt;It was a surprise and a relief. We swapped a few emails, and he confirmed the TIFF catalyst story. For Stephen it was 'no big deal'. Once he had built the initial TIFF, Aldus needed to convince 3rd party developers and scanner manufacturers to agree to TIFF as a standard.&lt;/p&gt;
    &lt;p&gt;“We had to define and promote an industry standard for storing and processing scanned images, so that we wouldn't have to write import filters for every model of every scanner that would soon be entering the budding desktop scanner market."&lt;/p&gt;
    &lt;p&gt;Stephen himself did much of the evangelizing as Paul Brainerd later pointed out:&lt;/p&gt;
    &lt;p&gt;“(Steve) developed the standard, and then we went out and promoted it in a series of meetings with specific companies - as well as some workshops we ran in Seattle and the Bay Area during the Seybold shows and the MacWorld shows.”&lt;/p&gt;
    &lt;p&gt;I sent Stephen a draft of what I had written and he sent a prompt reply saying - ‘Looks good’.&lt;/p&gt;
    &lt;p&gt;I followed up asking him how he ended up at a tiny startup in Seattle called Aldus.&lt;/p&gt;
    &lt;p&gt;At that time, I was interviewing for a graphics position at Boeing Computer Services in Seattle, and noticed a small wanted ad that sounded really interesting, and seemed to be an excellent match for my background and interests. I interviewed with Paul and the 5-person mostly-ex-Atex engineering team, and I was hired.&lt;/p&gt;
    &lt;p&gt;Out of curiosity I put Stephen's email address, now that I knew it, into a Duck Duck search and found him helping people online with TIFF queries long after Aldus had been acquired by Adobe. He also contributed to a Google Group called tiffcentral.&lt;/p&gt;
    &lt;p&gt;Having interviewed so many people across more than a decade, I’ve got pretty good at judging those who would like to talk or type, those who are verbose and those that are not. I knew Stephen had said what he was going to say. I added his pioneering work on TIFF to the AIFF story and moved on.&lt;/p&gt;
    &lt;p&gt;Two years had flown by when I received an email yesterday. His ex-wife Peggy found my paper letter and wrote to me. Stephen passed away earlier this year.&lt;/p&gt;
    &lt;p&gt;Thank you for your interest in and support of Stephen’s brilliant work creating TIFF. I’m not surprised Stephen didn’t finish corresponding with you, as he had begun to struggle with using his computer and phone. Some days were better than others for him, but he began to lose touch with people during those months you were reaching out to him. He was a humble man, and I guess never pushed to be recognized, although I believe those who worked with him knew the truth. His last week was in my home, where he was never left alone.&lt;/p&gt;
    &lt;p&gt;Peggy finished the email with, ‘I called him Mr TIFF up to his last moment.'&lt;/p&gt;
    &lt;p&gt;The 10,000+ hours of book research disappeared in an instant. As sad as it was, I could see clearly that all of my work was worth it. Every single second. Because of this email.&lt;/p&gt;
    &lt;p&gt;Mr TIFF.&lt;/p&gt;
    &lt;p&gt;Last night, as everyone in my house went to sleep, I took a deep breath and edited the Wikipedia page for TIFF, the Tag Image File Format.&lt;/p&gt;
    &lt;p&gt;It no longer reads ‘created by Aldus’, it reads ‘…created by Stephen Carlsen, an engineer at Aldus'&lt;/p&gt;
    &lt;p&gt;My book "Inventing the Future: Bit by Bit" is here -&amp;gt;&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45816853</guid><pubDate>Tue, 04 Nov 2025 22:57:12 +0000</pubDate></item><item><title>Patching 68K Software – SimpleText</title><link>https://tinkerdifferent.com/threads/patching-68k-software-simpletext.4793/</link><description>&lt;doc fingerprint="b2497ef403174708"&gt;
  &lt;main&gt;
    &lt;p&gt;Someone asked to have SimpleText open a smaller text window at startup. Initially, I assumed this would be a fairly easy fix by just overwriting a few constant values in SimpleText code. It turned out to be a pain -- but I learned a lot along the way.&lt;lb/&gt;You need to have the code editor (from one of the Apple developer CDs) in your ResEdit preference file in order to disassemble code resources within ResEdit. Then, open each 'CODE' resource of SimpleText and search for _SizeWindow (A91D). Or, just skim the code until you see system calls that look like they have something to do with windows. Here is a nice chunk in routine Anon48. A new window is created, then it looks at the main device, looks at the size of the menu bar (MBarHeight), sets the port, and moves and sizes the window.&lt;lb/&gt;But, uh oh, earlier in the code it checks what type of window it is opening. A patch is going to need to avoid resizing code for pictures, video, and the about box.&lt;lb/&gt;I could not locate any obvious constants to adjust. Instead, I would need to inject a more complicated routine that detects whether it was a text window and substitute a new rectangle for the size. But, you cannot simply insert code, as it would move all subsequent code down, and the jumps (subroutine calls) that cross over that location would now jump to the wrong spots. So, I need to jump out of their code to my own (appended at the end of the code resource) and return.&lt;lb/&gt;For example, SimpleText's code to get the size of MBarHeight can easily be performed elsewhere. My routine need only return the MBarHeight in register D0 before returning. That gives me 8 bytes to overwrite with my jump.&lt;lb/&gt;Here is my replacement code. It still is only 8 bytes. But, I now jump to my subroutine, check the result, and jump over their resizing code if my routine says it is changing the window size.&lt;lb/&gt;In my subroutine, I make sure all the needed information is in registers (which I checked that SimpleText was not using), I call my various functions and then perform any work that was lost from overwriting or jumping over the original code. Specifically, I get the MBarHeight into D0 and set the current port to the window.&lt;lb/&gt;Easy! But, later in the code, SimpleText reads the content of whatever document is being opened and once again resizes the window. So, I needed to patch later code as well. How could I determine at that point that a replacement window size was being used? I simply store the result of the first subroutine (see SetRecentResult above) and then check it on later calls.&lt;lb/&gt;Where could I store this information? it is not possible to add global variables and the registers are all reused by SimpleText between the first and second routines. Well, you can store a variable (or an entire structure with many variables) within the code itself. Here is my little workaround for CodeWarrior.&lt;lb/&gt;A couple of other tricks.&lt;lb/&gt;1. The system routine GetHandleSize has some glue code (they intercept the call in a local library before calling the system). I needed this call, but didn't want to add the weight of CodeWarrior's libary. So, I defined the direct call to GetHandleSize (I didn't need the glue fix).&lt;lb/&gt;2. You can pass any of the scratch registers (D0-D2, A0-A1, FP0-FP3) to a C function. The way of defining that in CodeWarrior is noted below. You cannot use any other registers. To make debugging easier, I wrote the original subroutine as a true C function, and the register-&amp;gt;C function as a wrapper.&lt;lb/&gt;3. CodeWarrior does not support BSR for some reason. Use JSR instead. Also, a called routine must be placed before the caller routine in order to generate a short relative JSR rather than absolute address. See my 'RecentResult' example above, where the routines that call RecentResult are placed after it in code.&lt;lb/&gt;4. SimpleText stores literals (strings, constants) at the end of the 'CODE' resource. After that is where I placed my code. Unfortunately, this breaks disassembly in ResEdit. Below, do you see 'A9FF'? That's the '_Debugger' trap call. It is follow by the rest of the code, and the MacsBug symbols for "SimpleTextWindowChoicePrep'&lt;lb/&gt;I then needed to hand compute the JSR patched in the original SimpleText code to this location at the end of the code resource.&lt;lb/&gt;5. To make it easy to redefine window sizes in the future, I added a resource.&lt;lb/&gt;The ResEdit definition of this resource is the TMPL. By the way, I have experienced corruption twice with ResEdit 2.1.3. Perhaps it has a bug with templates?&lt;lb/&gt;I doubt this information will be useful to most people. However, it may help avoid some frustrating issues for those few people that attempt patching old software.&lt;lb/&gt;Attached is the hacked version of SimpleText.&lt;lb/&gt;- David&lt;/p&gt;
    &lt;p&gt;You need to have the code editor (from one of the Apple developer CDs) in your ResEdit preference file in order to disassemble code resources within ResEdit. Then, open each 'CODE' resource of SimpleText and search for _SizeWindow (A91D). Or, just skim the code until you see system calls that look like they have something to do with windows. Here is a nice chunk in routine Anon48. A new window is created, then it looks at the main device, looks at the size of the menu bar (MBarHeight), sets the port, and moves and sizes the window.&lt;/p&gt;
    &lt;p&gt;But, uh oh, earlier in the code it checks what type of window it is opening. A patch is going to need to avoid resizing code for pictures, video, and the about box.&lt;/p&gt;
    &lt;p&gt;I could not locate any obvious constants to adjust. Instead, I would need to inject a more complicated routine that detects whether it was a text window and substitute a new rectangle for the size. But, you cannot simply insert code, as it would move all subsequent code down, and the jumps (subroutine calls) that cross over that location would now jump to the wrong spots. So, I need to jump out of their code to my own (appended at the end of the code resource) and return.&lt;/p&gt;
    &lt;p&gt;For example, SimpleText's code to get the size of MBarHeight can easily be performed elsewhere. My routine need only return the MBarHeight in register D0 before returning. That gives me 8 bytes to overwrite with my jump.&lt;/p&gt;
    &lt;p&gt;Here is my replacement code. It still is only 8 bytes. But, I now jump to my subroutine, check the result, and jump over their resizing code if my routine says it is changing the window size.&lt;/p&gt;
    &lt;p&gt;In my subroutine, I make sure all the needed information is in registers (which I checked that SimpleText was not using), I call my various functions and then perform any work that was lost from overwriting or jumping over the original code. Specifically, I get the MBarHeight into D0 and set the current port to the window.&lt;/p&gt;
    &lt;p&gt;Easy! But, later in the code, SimpleText reads the content of whatever document is being opened and once again resizes the window. So, I needed to patch later code as well. How could I determine at that point that a replacement window size was being used? I simply store the result of the first subroutine (see SetRecentResult above) and then check it on later calls.&lt;/p&gt;
    &lt;p&gt;Where could I store this information? it is not possible to add global variables and the registers are all reused by SimpleText between the first and second routines. Well, you can store a variable (or an entire structure with many variables) within the code itself. Here is my little workaround for CodeWarrior.&lt;/p&gt;
    &lt;p&gt;A couple of other tricks.&lt;/p&gt;
    &lt;p&gt;1. The system routine GetHandleSize has some glue code (they intercept the call in a local library before calling the system). I needed this call, but didn't want to add the weight of CodeWarrior's libary. So, I defined the direct call to GetHandleSize (I didn't need the glue fix).&lt;/p&gt;
    &lt;p&gt;2. You can pass any of the scratch registers (D0-D2, A0-A1, FP0-FP3) to a C function. The way of defining that in CodeWarrior is noted below. You cannot use any other registers. To make debugging easier, I wrote the original subroutine as a true C function, and the register-&amp;gt;C function as a wrapper.&lt;/p&gt;
    &lt;p&gt;3. CodeWarrior does not support BSR for some reason. Use JSR instead. Also, a called routine must be placed before the caller routine in order to generate a short relative JSR rather than absolute address. See my 'RecentResult' example above, where the routines that call RecentResult are placed after it in code.&lt;/p&gt;
    &lt;p&gt;4. SimpleText stores literals (strings, constants) at the end of the 'CODE' resource. After that is where I placed my code. Unfortunately, this breaks disassembly in ResEdit. Below, do you see 'A9FF'? That's the '_Debugger' trap call. It is follow by the rest of the code, and the MacsBug symbols for "SimpleTextWindowChoicePrep'&lt;/p&gt;
    &lt;p&gt;I then needed to hand compute the JSR patched in the original SimpleText code to this location at the end of the code resource.&lt;/p&gt;
    &lt;p&gt;5. To make it easy to redefine window sizes in the future, I added a resource.&lt;/p&gt;
    &lt;p&gt;The ResEdit definition of this resource is the TMPL. By the way, I have experienced corruption twice with ResEdit 2.1.3. Perhaps it has a bug with templates?&lt;/p&gt;
    &lt;p&gt;I doubt this information will be useful to most people. However, it may help avoid some frustrating issues for those few people that attempt patching old software.&lt;/p&gt;
    &lt;p&gt;Attached is the hacked version of SimpleText.&lt;/p&gt;
    &lt;p&gt;- David&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45816879</guid><pubDate>Tue, 04 Nov 2025 22:59:22 +0000</pubDate></item><item><title>UPS plane crashes near Louisville airport</title><link>https://www.cbsnews.com/news/ups-plane-crash-louisville-kentucky/</link><description>&lt;doc fingerprint="771c0157a07387ef"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;UPS plane crashes near Louisville airport, at least 7 killed, officials say&lt;/head&gt;
    &lt;p&gt;At least seven people were killed and several others injured after a UPS plane crashed shortly after takeoff near the Louisville International Airport on Tuesday, officials said.&lt;/p&gt;
    &lt;p&gt;The number of fatalities is expected to increase, Kentucky Gov. Andy Beshear wrote on social media Tuesday night. At least 11 people were injured, officials said earlier.&lt;/p&gt;
    &lt;p&gt;Louisville Mayor Craig Greenberg confirmed at a news conference Tuesday night that at least four people had been killed on the ground.&lt;/p&gt;
    &lt;p&gt;UPS Flight 2976 crashed around 5:15 p.m. local time after it departed from the Louisville airport, according to the Federal Aviation Administration. The aircraft was headed to Daniel K. Inouye International Airport in Honolulu, Hawaii, when it went down three miles south of the airfield, Louisville airport public safety officer Jonathan Biven said at a news conference.&lt;/p&gt;
    &lt;p&gt;Beshear said there was no hazardous cargo onboard the plane that would create environmental issues around the crash site, but urged residents to follow any shelter-in-place orders.&lt;/p&gt;
    &lt;p&gt;The Louisville Metro Police Department described the scene as active with "fire and debris," warning residents to stay away from Fern Valley and Grade Lane, an intersection located on the south side of the airport, which serves as the hub of UPS. More than 100 firefighters responded to the crash and were still battling hot spots as of Tuesday night, Greenberg said. Louisville Fire Chief Brian O'Neill noted the fire was "almost entirely contained."&lt;/p&gt;
    &lt;p&gt;O'Neill said the fire had been extinguished enough to allow a formal grid search for any possible victims in the area.&lt;/p&gt;
    &lt;p&gt;Videos of the crash showed the aircraft partially on fire as it sped down the runway before it burst into flames.&lt;/p&gt;
    &lt;p&gt;A shelter-in-place order has been reduced to a one-mile radius of the crash site, authorities said. The police department also urged those in the area to turn off any air intake systems as soon as possible due to the smoke in the area.&lt;/p&gt;
    &lt;p&gt;"Anybody who has seen the images and the video knows how violent this crash is, and there are a lot of families that are gonna be waiting and wondering for a period of time. We're going to try to get them that information as fast as we can," Beshear said.&lt;/p&gt;
    &lt;p&gt;UPS said in a statement that it was notified of an incident involving one of its aircraft. Three UPS crewmembers were on board, the company said. It didn't immediately provide more details.&lt;/p&gt;
    &lt;p&gt;"We do not at the moment have the status of the crew," Beshear said. "Watching that video, I think we're all very, very worried about them."&lt;/p&gt;
    &lt;p&gt;Businesses in the area were heavily impacted by the crash, including Kentucky Petroleum Recycling and Grade A Auto Parts, the governor said.&lt;/p&gt;
    &lt;p&gt;All arriving and departing flights at the Louisville airport were temporarily suspended. The airport will remain closed Tuesday night, but is expected to reopen Wednesday morning, Greenberg said.&lt;/p&gt;
    &lt;p&gt;According to preliminary flight data from FlightRadar24, the plane appeared to hit 175 feet in altitude briefly after takeoff. It would have been full of fuel for the flight to Hawaii, which likely led to the significant fire as seen from CBS affiliate WLKY-TV's chopper.&lt;/p&gt;
    &lt;p&gt;The three-engine McDonnell Douglas MD-11 was manufactured in 1991, according to FAA data.&lt;/p&gt;
    &lt;p&gt;It was carrying approximately 38,000 gallons of fuel, which weighs about 233,000 pounds, Louisville Fire Chief Brian O'Neill said. The area affected by the crash is about a city block wide, he said, but it has been difficult to contain the fire due to surrounding hazardous materials.&lt;/p&gt;
    &lt;p&gt;Greenberg urged any residents who find debris on their property not to touch it, and instead report it through a website that should be live by Wednesday.&lt;/p&gt;
    &lt;p&gt;The crash is where UPS Worldport, an international air hub for the parcel service, is located. UPS said it was halting package sorting operations at Worldport on Tuesday night.&lt;/p&gt;
    &lt;p&gt;"This is a UPS town," Louisville Metro Councilwoman Betsy Ruhe, whose district is part of the crash site, said during the news conference Tuesday night. "We all know somebody who works at UPS, and they're all texting their friends, their family, trying to make sure everyone is safe. Sadly, some of those texts are probably going to go unanswered."&lt;/p&gt;
    &lt;p&gt;The 5.2 million-square-foot facility processes more than 400,000 packages an hour and is home to 20,000 UPS workers and 300 daily flights, according to the company.&lt;/p&gt;
    &lt;p&gt;"My team and I are closely monitoring the plane crash near Louisville Muhammad Ali International Airport," Kentucky Sen. Rand Paul said. "We continue to pray for the safety of the aircrew, everyone in the area, and for the first-responders on the scene."&lt;/p&gt;
    &lt;p&gt;The National Transportation Safety Board will lead the investigation into the crash. A team of 28 investigators is expected to arrive Wednesday, Greenberg said.&lt;/p&gt;
    &lt;p&gt;All public schools in the Jefferson County School District, the largest school district in Kentucky with a little under 100,000 students, will be closed Wednesday, Greenberg said.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45816963</guid><pubDate>Tue, 04 Nov 2025 23:10:53 +0000</pubDate></item><item><title>Google Removed 749M Anna's Archive URLs from Its Search Results</title><link>https://torrentfreak.com/google-removed-749-million-annas-archive-urls-from-its-search-results/</link><description>&lt;doc fingerprint="3b2013d053b71323"&gt;
  &lt;main&gt;
    &lt;p&gt;Anna’s Archive is a meta-search engine for shadow libraries that allows users to find pirated books and other related sources.&lt;/p&gt;
    &lt;p&gt;The site launched in the fall of 2022, just days after Z-Library was targeted in a U.S. criminal crackdown, to ensure continued availability of ‘free’ books and articles to the broader public.&lt;/p&gt;
    &lt;p&gt;In the three years since then, Anna’s Archive has built up quite the track record. The site has been blocked in various countries, was sued in the U.S. after it scraped WorldCat, and actively provides assistance to AI researchers who want to use its library for model training.&lt;/p&gt;
    &lt;p&gt;Despite legal pressure, Annas-archive.org and the related .li and .se domains remain operational. This is a thorn in the side of publishers who are actively trying to take the site down. In the absence of options to target the site directly, they ask third-party intermediaries such as Google to lend a hand.&lt;/p&gt;
    &lt;head rend="h2"&gt;749 Million URLs&lt;/head&gt;
    &lt;p&gt;Google and other major search engines allow rightsholders to request removal of allegedly infringing URLs. The aim is to ensure that pirate sites no longer show up in search results when people search for books, movies, music, or other copyrighted content.&lt;/p&gt;
    &lt;p&gt;The Pirate Bay, for example, has been a popular target; Google has removed more than 4.2 million thepiratebay.org URLs over the years in response to copyright holder complaints. While this sounds like a sizable number, it pales in comparison to the volume of takedowns targeting Anna’s Archive.&lt;/p&gt;
    &lt;p&gt;Google’s transparency report reveals that rightsholders asked Google to remove 784 million URLs, divided over the three main Anna’s Archive domains. A small number were rejected, mainly because Google didn’t index the reported links, resulting in 749 million confirmed removals.&lt;/p&gt;
    &lt;p&gt;The comparison to sites such as The Pirate Bay isn’t fair, as Anna’s Archive has many more pages in its archive and uses multiple country-specific subdomains. This means that there’s simply more content to take down. That said, in terms of takedown activity, the site’s three domain names clearly dwarf all pirate competition.&lt;/p&gt;
    &lt;head rend="h2"&gt;5% of All Google Takedowns, Ever&lt;/head&gt;
    &lt;p&gt;Since Google published its first transparency report in May 2012, rightsholders have flagged 15.1 billion allegedly infringing URLs. That’s a staggering number, but the fact that 5% of the total targeted Anna’s Archive URLs is remarkable.&lt;/p&gt;
    &lt;p&gt;Penguin Random House and John Wiley &amp;amp; Sons are the most active publishers targeting the site, but they are certainly not alone. According to Google data, more than 1,000 authors or publishers have sent DMCA notices targeting Anna’s Archive domains.&lt;/p&gt;
    &lt;p&gt;Yet, there appears to be no end in sight. Rightsholders are reporting roughly 10 million new URLs per week for the popular piracy library, so there is no shortage of content to report.&lt;/p&gt;
    &lt;p&gt;With these DMCA takedown notices, publishers are aiming to make it as difficult as possible for people to find books on the site using Google. This works, as many URLs are now delisted while others are actively being demoted by the search engine for book-related queries.&lt;/p&gt;
    &lt;p&gt;That said, the Anna’s Archive website is certainly not unfindable. Searching for the site’s name in Google still shows the main domain as the top search result.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45816968</guid><pubDate>Tue, 04 Nov 2025 23:11:20 +0000</pubDate></item><item><title>Bluetui – A TUI for managing Bluetooth on Linux</title><link>https://github.com/pythops/bluetui</link><description>&lt;doc fingerprint="e4d181ddbeaa2ea"&gt;
  &lt;main&gt;
    &lt;p&gt;A Linux based OS with bluez installed.&lt;/p&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;You might need to install nerdfonts for the icons to be displayed correctly.&lt;/p&gt;
    &lt;p&gt;You can download the pre-built binaries from the release page release page&lt;/p&gt;
    &lt;p&gt;You can install &lt;code&gt;bluetui&lt;/code&gt; from crates.io&lt;/p&gt;
    &lt;code&gt;cargo install bluetui&lt;/code&gt;
    &lt;p&gt;You can install &lt;code&gt;bluetui&lt;/code&gt; from the extra repository:&lt;/p&gt;
    &lt;code&gt;pacman -S bluetui&lt;/code&gt;
    &lt;p&gt;You can install &lt;code&gt;bluetui&lt;/code&gt; from the lamdness Gentoo Overlay:&lt;/p&gt;
    &lt;code&gt;sudo eselect repository enable lamdness
sudo emaint -r lamdness sync
sudo emerge -av net-wireless/bluetui&lt;/code&gt;
    &lt;p&gt;If you are a user of x-cmd, you can run:&lt;/p&gt;
    &lt;code&gt;x install bluetui&lt;/code&gt;
    &lt;p&gt;Run the following command:&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/pythops/bluetui
cd bluetui
cargo build --release&lt;/code&gt;
    &lt;p&gt;This will produce an executable file at &lt;code&gt;target/release/bluetui&lt;/code&gt; that you can copy to a directory in your &lt;code&gt;$PATH&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Tab&lt;/code&gt;: Switch between different sections.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;j&lt;/code&gt; or &lt;code&gt;Down&lt;/code&gt; : Scroll down.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;k&lt;/code&gt; or &lt;code&gt;Up&lt;/code&gt;: Scroll up.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;s&lt;/code&gt;: Start/Stop scanning.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;?&lt;/code&gt;: Show help.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;esc&lt;/code&gt;: Dismiss the help pop-up.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;ctrl+c&lt;/code&gt; or &lt;code&gt;q&lt;/code&gt;: Quit the app.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;p&lt;/code&gt;: Enable/Disable the pairing.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;o&lt;/code&gt;: Power on/off the adapter.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;d&lt;/code&gt;: Enable/Disable the discovery.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;u&lt;/code&gt;: Unpair the device.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Space or Enter&lt;/code&gt;: Connect/Disconnect the device.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;t&lt;/code&gt;: Trust/Untrust the device.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;e&lt;/code&gt;: Rename the device.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Space or Enter&lt;/code&gt;: Pair the device.&lt;/p&gt;
    &lt;p&gt;Keybindings can be customized in the default config file location &lt;code&gt;$HOME/.config/bluetui/config.toml&lt;/code&gt; or from a custom path with &lt;code&gt;-c&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;# Possible values: "Legacy", "Start", "End", "Center", "SpaceAround", "SpaceBetween"
layout = "SpaceAround"

# Window width
# Possible values: "auto" or a positive integer
width = "auto"

toggle_scanning = "s"

[adapter]
toggle_pairing = "p"
toggle_power = "o"
toggle_discovery = "d"

[paired_device]
unpair = "u"
toggle_trust = "t"
rename = "e"&lt;/code&gt;
    &lt;p&gt;GPLv3&lt;/p&gt;
    &lt;p&gt;Bluetui logo: Marco Bulgarelli&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45817114</guid><pubDate>Tue, 04 Nov 2025 23:29:31 +0000</pubDate></item><item><title>Uncle Sam wants to scan your iris and collect your DNA, citizen or not</title><link>https://www.theregister.com/2025/11/04/dhs_wants_to_collect_biometric_data/</link><description>&lt;doc fingerprint="fbca09582881b604"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Uncle Sam wants to scan your iris and collect your DNA, citizen or not&lt;/head&gt;
    &lt;head rend="h2"&gt;DHS rule would expand biometric collection to immigrants and some citizens linked to them&lt;/head&gt;
    &lt;p&gt;If you're filing an immigration form - or helping someone who is - the Feds may soon want to look in your eyes, swab your cheek, and scan your face. The US Department of Homeland Security wants to greatly expand biometric data collection for immigration applications, covering immigrants and even some US citizens tied to those cases.&lt;/p&gt;
    &lt;p&gt;DHS, through its component agency US Citizenship and Immigration Services, on Monday proposed a sweeping expansion of the agency's collection of biometric data. While ostensibly about verifying identities and preventing fraud in immigration benefit applications, the proposed rule goes much further than simply ensuring applicants are who they claim to be.&lt;/p&gt;
    &lt;p&gt;First off, the rule proposes expanding when DHS can collect biometric data from immigration benefit applicants, as "submission of biometrics is currently only mandatory for certain benefit requests and enforcement actions." DHS wants to change that, including by requiring practically everyone an immigrant is associated with to submit their biometric data.&lt;/p&gt;
    &lt;p&gt;"DHS proposes in this rule that any applicant, petitioner, sponsor, supporter, derivative, dependent, beneficiary, or individual filing or associated with a benefit request or other request or collection of information, including U.S. citizens, U.S. nationals and lawful permanent residents, and without regard to age, must submit biometrics unless DHS otherwise exempts the requirement," the rule proposal said.&lt;/p&gt;
    &lt;p&gt;DHS also wants to require the collection of biometric data from "any alien apprehended, arrested or encountered by DHS."&lt;/p&gt;
    &lt;p&gt;It's not explicitly stated in the rule proposal why US citizens associated with immigrants who are applying for benefits would have to have their biometric data collected. DHS didn't answer questions to that end, though the rule stated that US citizens would also be required to submit biometric data "when they submit a family-based visa petition."&lt;/p&gt;
    &lt;head rend="h3"&gt;Give me your voice, your eye print, your DNA samples&lt;/head&gt;
    &lt;p&gt;In addition to expanded collection, the proposed rule also changes the definition of what DHS considers to be valid biometric data.&lt;/p&gt;
    &lt;p&gt;"Government agencies have grouped together identifying features and actions, such as fingerprints, photographs, and signatures under the broad term, biometrics," the proposal states. "DHS proposes to define the term 'biometrics' to mean 'measurable biological (anatomical, physiological or molecular structure) or behavioral characteristics of an individual,'" thus giving DHS broad leeway to begin collecting new types of biometric data as new technologies are developed.&lt;/p&gt;
    &lt;p&gt;The proposal mentions several new biometric technologies DHS wants the option to use, including ocular imagery, voice prints and DNA, all on the table per the new rule.&lt;/p&gt;
    &lt;p&gt;"The rule proposes to grant DHS express authority to require, request, or accept raw DNA or DNA test results," DHS said, including "to prove or disprove … biological sex" in situations where that can affect benefit eligibility.&lt;/p&gt;
    &lt;p&gt;DHS wants to use all that data for identity enrollment, verification and management of the immigration lifecycle, national security and criminal history checks, "the production of secure identity documents," to prove familial relationships, and to perform other administrative functions, the rule states.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Facial recognition works better in the lab than on the street, researchers show&lt;/item&gt;
      &lt;item&gt;EU biometric border system launch hits inevitable teething problems&lt;/item&gt;
      &lt;item&gt;Vietnam to collect biometrics - even DNA - for new ID cards&lt;/item&gt;
      &lt;item&gt;Altman's eyeball-scanning biometric blockchain orbs officially come to America&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As we noted in our story last week about DHS' new rule expanding biometric data collection on entry into and exit from the US, biometric technology - especially the often-used facial recognition scan - is ripe for misuse and prone to errors.&lt;/p&gt;
    &lt;p&gt;This new proposed rule goes far beyond subjecting immigrants to algorithmic identification tech prone to misidentifying non-white individuals, however, and reaches a new level of surveillance, with DHS seeking to collect and keep DNA test results - including partial profiles - from immigrants and some US citizens to verify family ties or biological sex when relevant. It's not much more assuring that DHS also wants to collect new forms of biometric data like voice records, which are increasingly easy to spoof with AI.&lt;/p&gt;
    &lt;p&gt;When we asked DHS questions about its biometric expansion proposal, it only sent us a statement identical to the one it sent last week when we inquired about the new entry/exit biometric requirements. The agency didn't respond when we asked for a statement pertaining to this latest proposed rule.&lt;/p&gt;
    &lt;p&gt;DHS is taking comments on the proposal until January 2; so far the submissions are nearly entirely negative, with posters decrying the plan as government overreach, comparing the proposal to communist China, and calling it a violation of Constitutional guarantees against unreasonable search and seizure. ®&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45817167</guid><pubDate>Tue, 04 Nov 2025 23:35:27 +0000</pubDate></item><item><title>Direct File won't happen in 2026, IRS tells states</title><link>https://www.nextgov.com/digital-government/2025/11/direct-file-wont-happen-2026-irs-tells-states/409309/</link><description>&lt;doc fingerprint="b8a1c09cd9635069"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Direct File won’t happen in 2026, IRS tells states&lt;/head&gt;
    &lt;head rend="h2"&gt;The free service that allowed taxpayers to file online directly with the IRS was used by hundreds of thousands of taxpayers in 2024 and 2025, who gave it high marks — although tax prep companies and Republicans have sought its end.&lt;/head&gt;
    &lt;p&gt;The IRS has notified states that offered the free, government tax filing service known as Direct File in 2025 that the program won’t be available next filing season.&lt;/p&gt;
    &lt;p&gt;In an email sent from the IRS to 25 states, the tax agency thanked them for collaborating and noted that “no launch date has been set for the future.”&lt;/p&gt;
    &lt;p&gt;“IRS Direct File will not be available in Filing Season 2026,” says the Monday email, obtained by Nextgov/FCW and confirmed by multiple sources. It follows reports that the program was ending and Trump’s former tax chief, Billy Long, remarking over the summer that the service was “gone.”&lt;/p&gt;
    &lt;p&gt;The program, which debuted in 2024, was a big shift from the decades-long IRS policy of not competing with the tax prep industry in offering its own free, online tax filing service for Americans. Many Republicans had opposed Direct File, and tax prep companies also lobbied against it.&lt;/p&gt;
    &lt;p&gt;Still, most of the taxpayers that used Direct File earlier this year — over 296,500 — gave it high marks.&lt;/p&gt;
    &lt;p&gt;Those users won’t be able to log on to the Direct File website to get their returns anymore, according to the new email, which directs anyone needing a transcript to their IRS online accounts.&lt;/p&gt;
    &lt;p&gt;The Trump administration’s massive tax and spending policy bill signed into law over the summer directed the IRS to set up a task force to examine how the tax agency can use public-private partnerships to replace Direct File.&lt;/p&gt;
    &lt;p&gt;The IRS has relied on a public-private partnership called Free File for decades to give most Americans a free way to file their taxes, although it's been extremely underutilized. Only 3% of eligible taxpayers used it in recent years. Some of the member companies were found to have pushed people toward products they’d have to pay for, even when they could’ve used free options.&lt;/p&gt;
    &lt;p&gt;"It's not surprising since the Trump administration sabotaged Direct File all through this year's filing season, at the urging of tax prep monopolies like TurboTax," Adam Ruben, the vice president of the Economic Security Project, told Nextgov/FCW. "Trump's billionaire friends get favors while honest hardworking Americans will pay more to file their taxes."&lt;/p&gt;
    &lt;p&gt;Sen. Elizabeth Warren, D-Mass., told Nextgov/FCW that "the fight isn't over," saying that "giant tax prep companies are popping champagne, while Americans are forced to spend more time and more money to file their taxes."&lt;/p&gt;
    &lt;p&gt;The IRS did not respond to a request for comment.&lt;/p&gt;
    &lt;p&gt;Editor's note: This article has been updated to include comment from Sen. Elizabeth Warren.&lt;/p&gt;
    &lt;p&gt;If you have a tip you'd like to share, Natalie Alms can be securely contacted at nalms.41 on Signal.&lt;/p&gt;
    &lt;p&gt;NEXT STORY: CBP expands facial recognition for non-citizens at borders&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45818319</guid><pubDate>Wed, 05 Nov 2025 02:30:38 +0000</pubDate></item><item><title>The Microsoft SoftCard for the Apple II: Getting two processors to share memory</title><link>https://devblogs.microsoft.com/oldnewthing/20251104-00/?p=111758</link><description>&lt;doc fingerprint="a2dfd9092d34a089"&gt;
  &lt;main&gt;
    &lt;p&gt;The Microsoft Z-80 SoftCard was a plug-in expansion card for the Apple II that added the ability to run CP/M software. According to Wikipedia, it was Microsoft’s first hardware product and in 1980 was the single largest revenue source for the company.&lt;/p&gt;
    &lt;p&gt;CP/M runs on an 8080 processor, but the Apple II has a 6502 processor. So how can you run CP/M on an Apple II? Answer: The card comes with its own 8080-compatible processor, the Zilog Z80, which was arguable better than the 8080 for a bunch of reasons given on its Wikipedia page.¹&lt;/p&gt;
    &lt;p&gt;Great, you now have a processor. But what happens to the old 6502 processor? Ideally, you would just shut it off, but you can’t go cold turkey because some things still had to be handled by the 6502.² Nicole Branagan digs deeper into the story of how the two processors coexist. The idea is that the SoftCard tells the 6502 that it’s doing DMA, so the 6502 pauses and waits for the DMA to complete. However, you can’t leave the 6502 paused for too long or its internal registers degrade and lose their values.&lt;/p&gt;
    &lt;p&gt;The solution is to take advantage of the Z80’s REFRESH line, which the processor uses to signal that it’s not accessing memory right now (because it’s decoding an instruction). This tells external memory refresh circuitry that it can run and keep the RAM values refreshed so that they don’t degrade and lose their values.&lt;/p&gt;
    &lt;p&gt;On the Apple II, memory refreshing is done by the video circuitry, so there is need for a dedicated REFRESH signal. The SoftCard uses this signal to allow the 6502 to execute a tiny little bit. (Presumably it is sitting in a spin loop waiting to be woken.) This keeps the 6502’s registers refreshed.&lt;/p&gt;
    &lt;p&gt;When the SoftCard needs the 6502 to do actual work, it can update some memory to tell the 6502, “Break out of your spin loop and do something for me, then let me know the answer and go back to the spin loop.” The Z80 then goes to sleep until it gets an answer from the 6502.&lt;/p&gt;
    &lt;p&gt;Another wrinkle in the way that the 6502 and Z80 shared memory is in the memory map. Both the Z80 and 6502 consider the first 256 bytes of memory to be special and want to use it for different things. Furthermore, CP/M programs expect to be loaded at $0100, but the 6502 hard-codes its CPU stack to live in the range $0100–$01FF. There are other obstacles in the low part of the Apple II memory map: The Apple II system monitor uses $0200–$02FF as its keyboard input buffer, the bytes in the range $03F0–$03FF are used to hold interrupt vectors, and the text video frame buffer goes from $0400–$07FF. (There is a second text video frame buffer from $0800–$0BFF, but almost nobody uses it.) Other big obstacles are the memory range from $C000–$CFFF, which is used by peripheral devices, and the memory range from $D000–$FFFF, which holds the Apple II monitor ROM, but can be replaced by RAM if you have the Language Card (a 16KB memory expansion card), except that the last few bytes $FFFA–$FFFF are used by the CPU as interrupt vectors.&lt;/p&gt;
    &lt;p&gt;The solution is to remap the memory by putting address translation circuitry on the SoftCard, so that when the Z80 asks for memory address $0000, say, it actually gets physical memory $1000. The remapping is carefully arranged so that all of the Apple II’s special reserved addresses get shuffled to the end of the Z80 memory map, and all of the Apple II’s normal RAM occupies contiguous address space in the Z80 memory map starting at $0000.³&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;6502&lt;/cell&gt;
        &lt;cell&gt;Physical&lt;/cell&gt;
        &lt;cell&gt;Z80&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Special use&lt;/cell&gt;
        &lt;cell&gt;$0000–$0FFF&lt;/cell&gt;
        &lt;cell&gt;↘&lt;/cell&gt;
        &lt;cell&gt;$1000–$1FFF&lt;/cell&gt;
        &lt;cell&gt;$0000–$0FFF&lt;/cell&gt;
        &lt;cell&gt;normal RAM&lt;p&gt;(contiguous,&lt;/p&gt;&lt;p&gt;up to&lt;/p&gt;&lt;p&gt;installed RAM)&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;normal RAM&lt;p&gt;(contiguous,&lt;/p&gt;&lt;p&gt;up to&lt;/p&gt;&lt;p&gt;installed RAM)&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;$1000–$1FFF&lt;/cell&gt;
        &lt;cell&gt;↗&lt;/cell&gt;
        &lt;cell&gt;$2000–$2FFF&lt;/cell&gt;
        &lt;cell&gt;$1000–$1FFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;$2000–$2FFF&lt;/cell&gt;
        &lt;cell&gt;$3000–$3FFF&lt;/cell&gt;
        &lt;cell&gt;$2000–$2FFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;$3000–$3FFF&lt;/cell&gt;
        &lt;cell&gt;$4000–$4FFF&lt;/cell&gt;
        &lt;cell&gt;$3000–$3FFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;$4000–$4FFF&lt;/cell&gt;
        &lt;cell&gt;$5000–$5FFF&lt;/cell&gt;
        &lt;cell&gt;$4000–$4FFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;$5000–$5FFF&lt;/cell&gt;
        &lt;cell&gt;$6000–$6FFF&lt;/cell&gt;
        &lt;cell&gt;$5000–$5FFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;$6000–$6FFF&lt;/cell&gt;
        &lt;cell&gt;$7000–$7FFF&lt;/cell&gt;
        &lt;cell&gt;$6000–$6FFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;$7000–$7FFF&lt;/cell&gt;
        &lt;cell&gt;$8000–$8FFF&lt;/cell&gt;
        &lt;cell&gt;$7000–$7FFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;$8000–$8FFF&lt;/cell&gt;
        &lt;cell&gt;$9000–$9FFF&lt;/cell&gt;
        &lt;cell&gt;$8000–$8FFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;$9000–$9FFF&lt;/cell&gt;
        &lt;cell&gt;$A000–$AFFF&lt;/cell&gt;
        &lt;cell&gt;$9000–$9FFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;$A000–$AFFF&lt;/cell&gt;
        &lt;cell&gt;$B000–$BFFF&lt;/cell&gt;
        &lt;cell&gt;$A000–$AFFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;$B000–$BFFF&lt;/cell&gt;
        &lt;cell&gt;$D000–$DFFF&lt;/cell&gt;
        &lt;cell&gt;$B000–$BFFF&lt;/cell&gt;
        &lt;cell&gt;expansion RAM&lt;p&gt;(except for&lt;/p&gt;&lt;p&gt;last 6 bytes)&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;I/O space&lt;/cell&gt;
        &lt;cell&gt;$C000–$CFFF&lt;/cell&gt;
        &lt;cell&gt;↘&lt;/cell&gt;
        &lt;cell&gt;$E000–$EFFF&lt;/cell&gt;
        &lt;cell&gt;$C000–$CFFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;expansion RAM&lt;p&gt;(except for&lt;/p&gt;&lt;p&gt;last 6 bytes)&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;$D000–$DFFF&lt;/cell&gt;
        &lt;cell&gt;↗&lt;/cell&gt;
        &lt;cell&gt;$F000–$FFFF&lt;/cell&gt;
        &lt;cell&gt;$D000–$DFFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;$E000–$EFFF&lt;/cell&gt;
        &lt;cell&gt;$C000–$CFFF&lt;/cell&gt;
        &lt;cell&gt;$E000–$EFFF&lt;/cell&gt;
        &lt;cell&gt;I/O space&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;$F000–$FFFF&lt;/cell&gt;
        &lt;cell&gt;$0000–$0FFF&lt;/cell&gt;
        &lt;cell&gt;$F000–$FFFF&lt;/cell&gt;
        &lt;cell&gt;Special use&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The SoftCard manual contained lots of details on how to write code for it. For example, it included instructions on how to call into a 6502 subroutine from Z80 and had a chart showing how the memory was remapped for the Z80. It even included the Z80 processor reference manual, listing all the instructions. This will come in handy in a future story.&lt;/p&gt;
    &lt;p&gt;¹ I don’t know where the hyphen in Z-80 came from.&lt;/p&gt;
    &lt;p&gt;² In many places, I/O was handled by timing loops, so if you wanted to access, say, the game paddles, you had to let the 6502 do the I/O with its precise software timing loops.&lt;/p&gt;
    &lt;p&gt;³ There were also two high resolution graphics frame buffers, one at $2000–$3FFF, and another at $4000–$5FFF. These were right in the middle of the Z80 memory map, but in practice it wasn’t a problem because CP/M was a text-mode operating system, so the programs you were running didn’t try to do graphics anyway.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45818471</guid><pubDate>Wed, 05 Nov 2025 02:58:25 +0000</pubDate></item><item><title>Preventing Kubernetes from Pulling the Pause Image from the Internet</title><link>https://kyle.cascade.family/posts/preventing-kubernetes-from-pulling-the-pause-image-from-the-internet/</link><description>&lt;doc fingerprint="3510c03015708d17"&gt;
  &lt;main&gt;
    &lt;p&gt;I don’t normally write blog posts that regurgitate information from normal documentation, but this particular subject irks me.&lt;/p&gt;
    &lt;p&gt;If you are running an internal Kubernetes (k8s) platform, you owe it to yourself to make sure there is nothing external to your platform determining your reliability.&lt;/p&gt;
    &lt;p&gt;You could ask yourself: How many internet dependencies do you have to start a pod? Should be zero, right???&lt;/p&gt;
    &lt;p&gt;If you use stock k8s, you might be surprised to know that each of your k8s nodes is actually reaching out to &lt;code&gt;registry.k8s.io&lt;/code&gt; on first pod creation to get the &lt;code&gt;pause&lt;/code&gt; image:&lt;/p&gt;
    &lt;code&gt;$ sudo crictl images
IMAGE                                     TAG                 IMAGE ID            SIZE
registry.k8s.io/pause                     3.9                 e6f1816883972
&lt;/code&gt;
    &lt;p&gt;If you want to change that, you can update your containerd (1.x) toml:&lt;/p&gt;
    &lt;code&gt;[plugins."io.containerd.grpc.v1.cri"]
  sandbox_image = "YOUR_REGISTRY/pause:3.10"
&lt;/code&gt;
    &lt;p&gt;And depend on one less thing. The rest of the blog post will go deeper into why this is the case.&lt;/p&gt;
    &lt;head rend="h1"&gt;What Is The Pause Image Anyway?&lt;/head&gt;
    &lt;p&gt;The &lt;code&gt;pause&lt;/code&gt; image is the container image that backs the k8s “sandbox” of a pod.
This &lt;code&gt;pause&lt;/code&gt; container is designed to hold the linux namespaces.
The &lt;code&gt;pause&lt;/code&gt; container used to also reap zombie processes from the other containers in a pod, its duty as PID1, but that isn’t the case by default anymore in k8s 1.8+.&lt;/p&gt;
    &lt;p&gt;The sandbox of a pod is part of the CRI spec. The CRI spec is a generic way for k8s to talk pods (and sandboxes) that is not specific to any particular container runtime (like containerd). Any container runtime that implements the CRI spec can, in theory, run k8s pods.&lt;/p&gt;
    &lt;p&gt;This means that the &lt;code&gt;pause&lt;/code&gt; image has more to do with CRI than it does with k8s.&lt;/p&gt;
    &lt;head rend="h1"&gt;Where The Pause Image Comes From (CRI)&lt;/head&gt;
    &lt;p&gt;When a CRI-enabled container runtime needs to create a sandbox, at least with the case of containerd, it does this by creating a real container.&lt;/p&gt;
    &lt;p&gt;The image containerd is configured to use (by default) to create that sandbox, is the &lt;code&gt;pause&lt;/code&gt; image.
You can see this in code here.&lt;/p&gt;
    &lt;head rend="h1"&gt;How To Point Containerd To Your Local Pause Image&lt;/head&gt;
    &lt;p&gt;Per the current docs, you can overwrite the containerd sandbox image with a containerd configuration like this (assuming you have mirrored to a local registry):&lt;/p&gt;
    &lt;p&gt;(containerd 1.x)&lt;/p&gt;
    &lt;code&gt;[plugins."io.containerd.grpc.v1.cri"]
  sandbox_image = "YOUR_REGISTRY/pause:3.10"
&lt;/code&gt;
    &lt;p&gt;(containerd 2.x)&lt;/p&gt;
    &lt;code&gt;version = 3

[plugins]
  [plugins.'io.containerd.cri.v1.images']
    ...
    [plugins.'io.containerd.cri.v1.images'.pinned_images]
      sandbox = 'YOUR_REGISTRY/pause:3.10'
&lt;/code&gt;
    &lt;p&gt;Don’t take my word for it here, this particular setting has changed over time, check the official docs.&lt;/p&gt;
    &lt;head rend="h1"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;If you go to registry.k8s.io you will see:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Please note that there is NO uptime SLA as this is a free, volunteer managed service. We will however do our best to respond to issues and the system is designed to be reliable and low-maintenance. If you need higher uptime guarantees please consider mirroring images to a location you control.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;So yea, this is your PSA. Please mirror like they recommend and reconfigure as needed to not depend on the internet.&lt;/p&gt;
    &lt;p&gt;Comment via email&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45818499</guid><pubDate>Wed, 05 Nov 2025 03:04:58 +0000</pubDate></item><item><title>Hypothesis: Property-Based Testing for Python</title><link>https://hypothesis.readthedocs.io/en/latest/</link><description>&lt;doc fingerprint="a1031a81e5b71397"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Welcome to Hypothesis!¶&lt;/head&gt;
    &lt;p&gt;Hypothesis is the property-based testing library for Python. With Hypothesis, you write tests which should pass for all inputs in whatever range you describe, and let Hypothesis randomly choose which of those inputs to check - including edge cases you might not have thought about. For example:&lt;/p&gt;
    &lt;p&gt;You should start with the tutorial, or alternatively the more condensed quickstart.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tutorial¶&lt;/head&gt;
    &lt;p&gt;An introduction to Hypothesis.&lt;/p&gt;
    &lt;p&gt;New users should start here, or with the more condensed quickstart.&lt;/p&gt;
    &lt;head rend="h2"&gt;How-to guides¶&lt;/head&gt;
    &lt;p&gt;Practical guides for applying Hypothesis in specific scenarios.&lt;/p&gt;
    &lt;head rend="h2"&gt;Explanations¶&lt;/head&gt;
    &lt;p&gt;Commentary oriented towards deepening your understanding of Hypothesis.&lt;/p&gt;
    &lt;head rend="h2"&gt;API Reference¶&lt;/head&gt;
    &lt;p&gt;Technical API reference.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45818562</guid><pubDate>Wed, 05 Nov 2025 03:15:37 +0000</pubDate></item><item><title>The Hackers Manifesto (The Conscience of a Hacker) (1986)</title><link>https://phrack.org/issues/7/3</link><description>&lt;doc fingerprint="646e8917c32493a6"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Title : Hacker's Manifesto&lt;/p&gt;
      &lt;p&gt; Author : The Mentor&lt;/p&gt;
      &lt;quote&gt; ==Phrack Inc.== Volume One, Issue 7, Phile 3 of 10 =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= The following was written shortly after my arrest... \/\The Conscience of a Hacker/\/ by +++The Mentor+++ Written on January 8, 1986 =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= Another one got caught today, it's all over the papers. "Teenager Arrested in Computer Crime Scandal", "Hacker Arrested after Bank Tampering"... Damn kids. They're all alike. But did you, in your three-piece psychology and 1950's technobrain, ever take a look behind the eyes of the hacker? Did you ever wonder what made him tick, what forces shaped him, what may have molded him? I am a hacker, enter my world... Mine is a world that begins with school... I'm smarter than most of the other kids, this crap they teach us bores me... Damn underachiever. They're all alike. I'm in junior high or high school. I've listened to teachers explain for the fifteenth time how to reduce a fraction. I understand it. "No, Ms. Smith, I didn't show my work. I did it in my head..." Damn kid. Probably copied it. They're all alike. I made a discovery today. I found a computer. Wait a second, this is cool. It does what I want it to. If it makes a mistake, it's because I screwed it up. Not because it doesn't like me... Or feels threatened by me... Or thinks I'm a smart ass... Or doesn't like teaching and shouldn't be here... Damn kid. All he does is play games. They're all alike. And then it happened... a door opened to a world... rushing through the phone line like heroin through an addict's veins, an electronic pulse is sent out, a refuge from the day-to-day incompetencies is sought... a board is found. "This is it... this is where I belong..." I know everyone here... even if I've never met them, never talked to them, may never hear from them again... I know you all... Damn kid. Tying up the phone line again. They're all alike... You bet your ass we're all alike... we've been spoon-fed baby food at school when we hungered for steak... the bits of meat that you did let slip through were pre-chewed and tasteless. We've been dominated by sadists, or ignored by the apathetic. The few that had something to teach found us will- ing pupils, but those few are like drops of water in the desert. This is our world now... the world of the electron and the switch, the beauty of the baud. We make use of a service already existing without paying for what could be dirt-cheap if it wasn't run by profiteering gluttons, and you call us criminals. We explore... and you call us criminals. We seek after knowledge... and you call us criminals. We exist without skin color, without nationality, without religious bias... and you call us criminals. You build atomic bombs, you wage wars, you murder, cheat, and lie to us and try to make us believe it's for our own good, yet we're the criminals. Yes, I am a criminal. My crime is that of curiosity. My crime is that of judging people by what they say and think, not what they look like. My crime is that of outsmarting you, something that you will never forgive me for. I am a hacker, and this is my manifesto. You may stop this individual, but you can't stop us all... after all, we're all alike. +++The Mentor+++ _______________________________________________________________________________ &lt;/quote&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45820715</guid><pubDate>Wed, 05 Nov 2025 08:28:04 +0000</pubDate></item></channel></rss>