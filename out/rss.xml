<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 02 Sep 2025 21:08:03 +0000</lastBuildDate><item><title>'World Models,' an old idea in AI, mount a comeback</title><link>https://www.quantamagazine.org/world-models-an-old-idea-in-ai-mount-a-comeback-20250902/</link><description>&lt;doc fingerprint="3c198b9fef1780ca"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;‘World Models,’ an Old Idea in AI, Mount a Comeback&lt;/head&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;The latest ambition of artificial intelligence research — particularly within the labs seeking “artificial general intelligence,” or AGI — is something called a world model: a representation of the environment that an AI carries around inside itself like a computational snow globe. The AI system can use this simplified representation to evaluate predictions and decisions before applying them to its real-world tasks. The deep learning luminaries Yann LeCun (of Meta), Demis Hassabis (of Google DeepMind) and Yoshua Bengio (of Mila, the Quebec Artificial Intelligence Institute) all believe world models are essential for building AI systems that are truly smart, scientific and safe.&lt;/p&gt;
    &lt;p&gt;The fields of psychology, robotics and machine learning have each been using some version of the concept for decades. You likely have a world model running inside your skull right now — it’s how you know not to step in front of a moving train without needing to run the experiment first.&lt;/p&gt;
    &lt;p&gt;So does this mean that AI researchers have finally found a core concept whose meaning everyone can agree upon? As a famous physicist once wrote: Surely you’re joking. A world model may sound straightforward — but as usual, no one can agree on the details. What gets represented in the model, and to what level of fidelity? Is it innate or learned, or some combination of both? And how do you detect that it’s even there at all?&lt;/p&gt;
    &lt;p&gt;It helps to know where the whole idea started. In 1943, a dozen years before the term “artificial intelligence” was coined, a 29-year-old Scottish psychologist named Kenneth Craik published an influential monograph in which he mused that “if the organism carries a ‘small-scale model’ of external reality … within its head, it is able to try out various alternatives, conclude which is the best of them … and in every way to react in a much fuller, safer, and more competent manner.” Craik’s notion of a mental model or simulation presaged the “cognitive revolution” that transformed psychology in the 1950s and still rules the cognitive sciences today. What’s more, it directly linked cognition with computation: Craik considered the “power to parallel or model external events” to be “the fundamental feature” of both “neural machinery” and “calculating machines.”&lt;/p&gt;
    &lt;p&gt;The nascent field of artificial intelligence eagerly adopted the world-modeling approach. In the late 1960s, an AI system called SHRDLU wowed observers by using a rudimentary “block world” to answer commonsense questions about tabletop objects, like “Can a pyramid support a block?” But these handcrafted models couldn’t scale up to handle the complexity of more realistic settings. By the late 1980s, the AI and robotics pioneer Rodney Brooks had given up on world models completely, famously asserting that “the world is its own best model” and “explicit representations … simply get in the way.”&lt;/p&gt;
    &lt;p&gt;It took the rise of machine learning, especially deep learning based on artificial neural networks, to breathe life back into Craik’s brainchild. Instead of relying on brittle hand-coded rules, deep neural networks could build up internal approximations of their training environments through trial and error and then use them to accomplish narrowly specified tasks, such as driving a virtual race car. In the past few years, as the large language models behind chatbots like ChatGPT began to demonstrate emergent capabilities that they weren’t explicitly trained for — like inferring movie titles from strings of emojis, or playing the board game Othello — world models provided a convenient explanation for the mystery. To prominent AI experts such as Geoffrey Hinton, Ilya Sutskever and Chris Olah, it was obvious: Buried somewhere deep within an LLM’s thicket of virtual neurons must lie “a small-scale model of external reality,” just as Craik imagined.&lt;/p&gt;
    &lt;p&gt;The truth, at least so far as we know, is less impressive. Instead of world models, today’s generative AIs appear to learn “bags of heuristics”: scores of disconnected rules of thumb that can approximate responses to specific scenarios, but don’t cohere into a consistent whole. (Some may actually contradict each other.) It’s a lot like the parable of the blind men and the elephant, where each man only touches one part of the animal at a time and fails to apprehend its full form. One man feels the trunk and assumes the entire elephant is snakelike; another touches a leg and guesses it’s more like a tree; a third grasps the elephant’s tail and says it’s a rope. When researchers attempt to recover evidence of a world model from within an LLM — for example, a coherent computational representation of an Othello game board — they’re looking for the whole elephant. What they find instead is a bit of snake here, a chunk of tree there, and some rope.&lt;/p&gt;
    &lt;p&gt;Of course, such heuristics are hardly worthless. LLMs can encode untold sackfuls of them within their trillions of parameters — and as the old saw goes, quantity has a quality all its own. That’s what makes it possible to train a language model to generate nearly perfect directions between any two points in Manhattan without learning a coherent world model of the entire street network in the process, as researchers from Harvard University and the Massachusetts Institute of Technology recently discovered.&lt;/p&gt;
    &lt;p&gt;So if bits of snake, tree and rope can do the job, why bother with the elephant? In a word, robustness: When the researchers threw their Manhattan-navigating LLM a mild curveball by randomly blocking 1% of the streets, its performance cratered. If the AI had simply encoded a street map whose details were consistent — instead of an immensely complicated, corner-by-corner patchwork of conflicting best guesses — it could have easily rerouted around the obstructions.&lt;/p&gt;
    &lt;p&gt;Given the benefits that even simple world models can confer, it’s easy to understand why every large AI lab is desperate to develop them — and why academic researchers are increasingly interested in scrutinizing them, too. Robust and verifiable world models could uncover, if not the El Dorado of AGI, then at least a scientifically plausible tool for extinguishing AI hallucinations, enabling reliable reasoning, and increasing the interpretability of AI systems.&lt;/p&gt;
    &lt;p&gt;That’s the “what” and “why” of world models. The “how,” though, is still anyone’s guess. Google DeepMind and OpenAI are betting that with enough “multimodal” training data — like video, 3D simulations, and other input beyond mere text — a world model will spontaneously congeal within a neural network’s statistical soup. Meta’s LeCun, meanwhile, thinks that an entirely new (and non-generative) AI architecture will provide the necessary scaffolding. In the quest to build these computational snow globes, no one has a crystal ball — but the prize, for once, may just be worth the hype.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45105710</guid></item><item><title>We already live in social credit, we just don't call it that</title><link>https://www.thenexus.media/your-phone-already-has-social-credit-we-just-lie-about-it/</link><description>&lt;doc fingerprint="b51eea140ec083e1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Your Phone Already Has Social Credit. We Just Lie About It.&lt;/head&gt;
    &lt;p&gt;Your credit score is social credit. Your LinkedIn endorsements are social credit. Your Uber passenger rating, Instagram engagement metrics, Amazon reviews, and Airbnb host status are all social credit systems that track you, score you, and reward you based on your behavior.&lt;/p&gt;
    &lt;p&gt;Social credit, in its original economic definition, means distributing industry profits to consumers to increase purchasing power. But the term has evolved far beyond economics. Today, it describes any kind of metric that tracks individual behavior, assigns scores based on that behavior, and uses those scores to determine access to services, opportunities, or social standing.&lt;/p&gt;
    &lt;p&gt;Sounds dystopian, doesn’t it? But guess what? Every time an algorithm evaluates your trustworthiness, reliability, or social value, whether for a loan, a job, a date, or a ride, you're participating in a social credit system. The scoring happens constantly, invisibly, and across dozens of platforms that weave into your daily life.&lt;/p&gt;
    &lt;p&gt;The only difference between your phone and China's social credit system is that China tells you what they're doing. We pretend our algorithmic reputation scores are just “user experience features.” At least Beijing admits they're gamifying human behavior.&lt;/p&gt;
    &lt;p&gt;When Americans think of the "Chinese social credit system," they likely picture Black Mirror episodes and Orwellian nightmares. Citizens are tracked for every jaywalking incident, points are deducted for buying too much alcohol, and facial recognition cameras are monitoring social gatherings; the image is so powerful that Utah's House passed a law banning social credit systems, despite none existing in America.&lt;/p&gt;
    &lt;p&gt;Here's what's actually happening. As of 2024, there's still no nationwide social credit score in China. Most private scoring systems have been shut down, and local government pilots have largely ended. It’s mainly a fragmented collection of regulatory compliance tools, mostly focused on financial behavior and business oversight. While well over 33 million businesses have been scored under corporate social credit systems, individual scoring remains limited to small pilot cities like Rongcheng. Even there, scoring systems have had "very limited impact" since they've never been elevated to provincial or national levels.&lt;/p&gt;
    &lt;p&gt;What actually gets tracked? Primarily court judgment defaults: people who refuse to pay fines or loans despite having the ability. The Supreme People's Court's blacklist is composed of citizens and companies that refuse to comply with court orders, typically to pay fines or repay loans. Some experimental programs in specific cities track broader social behavior, but these remain isolated experiments.&lt;/p&gt;
    &lt;p&gt;The gap between Western perception and Chinese reality is enormous, and it reveals something important: we're worried about a system that barely exists while ignoring the behavioral scoring systems we actually live with.&lt;/p&gt;
    &lt;p&gt;You already live in social credit.&lt;/p&gt;
    &lt;p&gt;Open your phone right now and count the apps that are scoring your behavior. Uber drivers rate you as a passenger. Instagram tracks your engagement patterns. Your bank is analyzing your Venmo transactions and Afterpay usage. LinkedIn measures your professional networking activity. Amazon evaluates your purchasing behavior. Each platform maintains detailed behavioral profiles that determine your access to services, opportunities, and social connections.&lt;/p&gt;
    &lt;p&gt;We just don't call it social credit.&lt;/p&gt;
    &lt;p&gt;Your credit score doesn't just determine loan eligibility; it affects where you can live, which jobs you can get, and how much you pay for car insurance. But traditional credit scoring is expanding rapidly. Some specialized lenders scan social media profiles as part of alternative credit assessments, particularly for borrowers with limited credit histories. Payment apps and financial services increasingly track spending patterns and transaction behaviors to build comprehensive risk profiles. The European Central Bank has asked some institutions to monitor social media chatter for early warnings of bank runs, though this is more about systemic risk than individual account decisions. Background check companies routinely analyze social media presence for character assessment. LinkedIn algorithmically manages your professional visibility based on engagement patterns, posting frequency, and network connections, rankings that recruiters increasingly rely on to filter candidates. Even dating has become a scoring system: apps use engagement rates and response patterns to determine who rises to the top of the queue and who gets buried.&lt;/p&gt;
    &lt;p&gt;What we have aren't unified social credit systems…yet. They're fragmented behavioral scoring networks that don't directly communicate. Your Uber rating doesn't affect your mortgage rate, and your LinkedIn engagement doesn't determine your insurance premiums. But the infrastructure is being built to connect these systems. We're building the technical and cultural foundations that could eventually create comprehensive social credit systems. The question isn't whether we have Chinese-style social credit now (because we don't). The question is whether we're building toward it without acknowledging what we're creating.&lt;/p&gt;
    &lt;p&gt;Where China's limited experiments have been explicit about scoring criteria, Western systems hide their decision-making processes entirely. Even China's fragmented approach offers more visibility into how behavioral data gets used than our black box algorithms do.&lt;/p&gt;
    &lt;p&gt;You may argue there's a fundamental difference between corporate tracking and government surveillance. Corporations compete; you can switch services. Governments have monopoly power and can restrict fundamental freedoms.&lt;/p&gt;
    &lt;p&gt;This misses three key points: First, switching costs for major platforms are enormous. Try leaving Google's ecosystem or abandoning your LinkedIn network. Second, corporate social credit systems increasingly collaborate. Bad Uber ratings can affect other services; poor credit scores impact everything from insurance to employment. Third, Western governments already access this corporate data through legal channels and data purchases.&lt;/p&gt;
    &lt;p&gt;Social credit systems are spreading globally because they solve coordination problems. They reduce fraud, encourage cooperation, and create behavioral incentives at scale. The question isn't whether Western societies will adopt social credit (because we're building toward it). The question is whether we'll be transparent and accountable about it or continue pretending our algorithmic reputation scores are just neutral technology.&lt;/p&gt;
    &lt;p&gt;Current trends suggest both systems are evolving toward more comprehensive behavioral scoring. European digital identity initiatives are linking multiple service scores. US cities are experimenting with behavioral incentive programs. Corporate platforms increasingly share reputation data. Financial services integrate social media analysis into lending decisions.&lt;/p&gt;
    &lt;p&gt;If both countries evolve toward comprehensive behavioral scoring, and current trends suggest they will, which approach better serves individual agencies? One that admits it's scoring you, or one that pretends algorithmic recommendations are just helpful suggestions?&lt;/p&gt;
    &lt;p&gt;When Uber can destroy your transportation access with a hidden algorithm, and when credit scores determine your housing options through opaque calculations, is that really more free than a system where you know at least some of the behaviors that affect your score?&lt;/p&gt;
    &lt;p&gt;So when China's explicit social credit approach inevitably influences Western platforms, when your apps start showing you the behavioral scores they've always been calculating, when the rules become visible instead of hidden, don't panic.&lt;/p&gt;
    &lt;p&gt;Because for the first time, you'll finally understand the game you've been playing all along. And knowing the rules means you can finally choose whether you want to play.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45106011</guid></item><item><title>&lt;template&gt;: The Content Template element</title><link>https://developer.mozilla.org/en-US/docs/Web/HTML/Reference/Elements/template</link><description>&lt;doc fingerprint="2a029f791cad1b64"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;&amp;lt;template&amp;gt;: The Content Template element&lt;/head&gt;&lt;head&gt; Baseline Widely available * &lt;/head&gt;&lt;p&gt;This feature is well established and works across many devices and browser versions. Itâs been available across browsers since â¨November 2015â©.&lt;/p&gt;&lt;p&gt;* Some parts of this feature may have varying levels of support.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;&amp;lt;template&amp;gt;&lt;/code&gt; HTML element serves as a mechanism for holding HTML fragments, which can either be used later via JavaScript or generated immediately into shadow DOM.&lt;/p&gt;&lt;head rend="h2"&gt;Attributes&lt;/head&gt;&lt;p&gt;This element includes the global attributes.&lt;/p&gt;&lt;list rend="dl"&gt;&lt;item rend="dt-1"&gt;&lt;code&gt;shadowrootmode&lt;/code&gt;&lt;/item&gt;&lt;item rend="dd-1"&gt;&lt;p&gt;Creates a shadow root for the parent element. It is a declarative version of the&lt;/p&gt;&lt;code&gt;Element.attachShadow()&lt;/code&gt;method and accepts the same enumerated values.&lt;list rend="dl"&gt;&lt;item rend="dt-2"&gt;&lt;code&gt;open&lt;/code&gt;&lt;/item&gt;&lt;item rend="dd-2"&gt;&lt;p&gt;Exposes the internal shadow root DOM for JavaScript (recommended for most use cases).&lt;/p&gt;&lt;/item&gt;&lt;item rend="dt-3"&gt;&lt;code&gt;closed&lt;/code&gt;&lt;/item&gt;&lt;item rend="dd-3"&gt;&lt;p&gt;Hides the internal shadow root DOM from JavaScript.&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Note: The HTML parser creates a&lt;/p&gt;&lt;code&gt;ShadowRoot&lt;/code&gt;object in the DOM for the first&lt;code&gt;&amp;lt;template&amp;gt;&lt;/code&gt;in a node with this attribute set to an allowed value. If the attribute is not set, or not set to an allowed value â or if a&lt;code&gt;ShadowRoot&lt;/code&gt;has already been declaratively created in the same parent â then an&lt;code&gt;HTMLTemplateElement&lt;/code&gt;is constructed. A&lt;code&gt;HTMLTemplateElement&lt;/code&gt;cannot subsequently be changed into a shadow root after parsing, for example, by setting&lt;code&gt;HTMLTemplateElement.shadowRootMode&lt;/code&gt;.&lt;p&gt;Note: You may find the non-standard&lt;/p&gt;&lt;code&gt;shadowroot&lt;/code&gt;attribute in older tutorials and examples that used to be supported in Chrome 90-110. This attribute has since been removed and replaced by the standard&lt;code&gt;shadowrootmode&lt;/code&gt;attribute.&lt;/item&gt;&lt;item rend="dt-4"&gt;&lt;code&gt;shadowrootclonable&lt;/code&gt;&lt;/item&gt;&lt;item rend="dd-4"&gt;&lt;p&gt;Sets the value of the&lt;/p&gt;&lt;code&gt;clonable&lt;/code&gt;property of a&lt;code&gt;ShadowRoot&lt;/code&gt;created using this element to&lt;code&gt;true&lt;/code&gt;. If set, a clone of the shadow host (the parent element of this&lt;code&gt;&amp;lt;template&amp;gt;&lt;/code&gt;) created with&lt;code&gt;Node.cloneNode()&lt;/code&gt;or&lt;code&gt;Document.importNode()&lt;/code&gt;will include a shadow root in the copy.&lt;/item&gt;&lt;item rend="dt-5"&gt;&lt;code&gt;shadowrootdelegatesfocus&lt;/code&gt;&lt;/item&gt;&lt;item rend="dd-5"&gt;&lt;p&gt;Sets the value of the&lt;/p&gt;&lt;code&gt;delegatesFocus&lt;/code&gt;property of a&lt;code&gt;ShadowRoot&lt;/code&gt;created using this element to&lt;code&gt;true&lt;/code&gt;. If this is set and a non-focusable element in the shadow tree is selected, then focus is delegated to the first focusable element in the tree. The value defaults to&lt;code&gt;false&lt;/code&gt;.&lt;/item&gt;&lt;item rend="dt-6"&gt;&lt;code&gt;shadowrootserializable&lt;/code&gt;Experimental&lt;/item&gt;&lt;item rend="dd-6"&gt;&lt;p&gt;Sets the value of the&lt;/p&gt;&lt;code&gt;serializable&lt;/code&gt;property of a&lt;code&gt;ShadowRoot&lt;/code&gt;created using this element to&lt;code&gt;true&lt;/code&gt;. If set, the shadow root may be serialized by calling the&lt;code&gt;Element.getHTML()&lt;/code&gt;or&lt;code&gt;ShadowRoot.getHTML()&lt;/code&gt;methods with the&lt;code&gt;options.serializableShadowRoots&lt;/code&gt;parameter set&lt;code&gt;true&lt;/code&gt;. The value defaults to&lt;code&gt;false&lt;/code&gt;.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Usage notes&lt;/head&gt;&lt;p&gt;This element has no permitted content, because everything nested inside it in the HTML source does not actually become the children of the &lt;code&gt;&amp;lt;template&amp;gt;&lt;/code&gt; element. The &lt;code&gt;Node.childNodes&lt;/code&gt; property of the &lt;code&gt;&amp;lt;template&amp;gt;&lt;/code&gt; element is always empty, and you can only access said nested content via the special &lt;code&gt;content&lt;/code&gt; property. However, if you call &lt;code&gt;Node.appendChild()&lt;/code&gt; or similar methods on the &lt;code&gt;&amp;lt;template&amp;gt;&lt;/code&gt; element, then you would be inserting children into the &lt;code&gt;&amp;lt;template&amp;gt;&lt;/code&gt; element itself, which is a violation of its content model and does not actually update the &lt;code&gt;DocumentFragment&lt;/code&gt; returned by the &lt;code&gt;content&lt;/code&gt; property.&lt;/p&gt;&lt;p&gt;Due to the way the &lt;code&gt;&amp;lt;template&amp;gt;&lt;/code&gt; element is parsed, all &lt;code&gt;&amp;lt;html&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;head&amp;gt;&lt;/code&gt;, and &lt;code&gt;&amp;lt;body&amp;gt;&lt;/code&gt; opening and closing tags inside the template are syntax errors and are ignored by the parser, so &lt;code&gt;&amp;lt;template&amp;gt;&amp;lt;head&amp;gt;&amp;lt;title&amp;gt;Test&amp;lt;/title&amp;gt;&amp;lt;/head&amp;gt;&amp;lt;/template&amp;gt;&lt;/code&gt; is the same as &lt;code&gt;&amp;lt;template&amp;gt;&amp;lt;title&amp;gt;Test&amp;lt;/title&amp;gt;&amp;lt;/template&amp;gt;&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;There are two main ways to use the &lt;code&gt;&amp;lt;template&amp;gt;&lt;/code&gt; element.&lt;/p&gt;&lt;head rend="h3"&gt;Template document fragment&lt;/head&gt;&lt;p&gt;By default, the element's content is not rendered. The corresponding &lt;code&gt;HTMLTemplateElement&lt;/code&gt; interface includes a standard &lt;code&gt;content&lt;/code&gt; property (without an equivalent content/markup attribute). This &lt;code&gt;content&lt;/code&gt; property is read-only and holds a &lt;code&gt;DocumentFragment&lt;/code&gt; that contains the DOM subtree represented by the template.
This fragment can be cloned via the &lt;code&gt;cloneNode&lt;/code&gt; method and inserted into the DOM.&lt;/p&gt;&lt;p&gt;Be careful when using the &lt;code&gt;content&lt;/code&gt; property because the returned &lt;code&gt;DocumentFragment&lt;/code&gt; can exhibit unexpected behavior.
For more details, see the Avoiding DocumentFragment pitfalls section below.&lt;/p&gt;&lt;head rend="h3"&gt;Declarative Shadow DOM&lt;/head&gt;&lt;p&gt;If the &lt;code&gt;&amp;lt;template&amp;gt;&lt;/code&gt; element contains the &lt;code&gt;shadowrootmode&lt;/code&gt; attribute with a value of either &lt;code&gt;open&lt;/code&gt; or &lt;code&gt;closed&lt;/code&gt;, the HTML parser will immediately generate a shadow DOM. The element is replaced in the DOM by its content wrapped in a &lt;code&gt;ShadowRoot&lt;/code&gt;, which is attached to the parent element.
This is the declarative equivalent of calling &lt;code&gt;Element.attachShadow()&lt;/code&gt; to attach a shadow root to an element.&lt;/p&gt;&lt;p&gt;If the element has any other value for &lt;code&gt;shadowrootmode&lt;/code&gt;, or does not have the &lt;code&gt;shadowrootmode&lt;/code&gt; attribute, the parser generates a &lt;code&gt;HTMLTemplateElement&lt;/code&gt;.
Similarly, if there are multiple declarative shadow roots, only the first one is replaced by a &lt;code&gt;ShadowRoot&lt;/code&gt; â subsequent instances are parsed as &lt;code&gt;HTMLTemplateElement&lt;/code&gt; objects.&lt;/p&gt;&lt;head rend="h2"&gt;Examples&lt;/head&gt;&amp;gt;&lt;head rend="h3"&gt;Generating table rows&lt;/head&gt;&lt;p&gt;First we start with the HTML portion of the example.&lt;/p&gt;&lt;code&gt;&amp;lt;table id="producttable"&amp;gt;
  &amp;lt;thead&amp;gt;
    &amp;lt;tr&amp;gt;
      &amp;lt;td&amp;gt;UPC_Code&amp;lt;/td&amp;gt;
      &amp;lt;td&amp;gt;Product_Name&amp;lt;/td&amp;gt;
    &amp;lt;/tr&amp;gt;
  &amp;lt;/thead&amp;gt;
  &amp;lt;tbody&amp;gt;
    &amp;lt;!-- existing data could optionally be included here --&amp;gt;
  &amp;lt;/tbody&amp;gt;
&amp;lt;/table&amp;gt;

&amp;lt;template id="productrow"&amp;gt;
  &amp;lt;tr&amp;gt;
    &amp;lt;td class="record"&amp;gt;&amp;lt;/td&amp;gt;
    &amp;lt;td&amp;gt;&amp;lt;/td&amp;gt;
  &amp;lt;/tr&amp;gt;
&amp;lt;/template&amp;gt;
&lt;/code&gt;&lt;p&gt;First, we have a table into which we will later insert content using JavaScript code. Then comes the template, which describes the structure of an HTML fragment representing a single table row.&lt;/p&gt;&lt;p&gt;Now that the table has been created and the template defined, we use JavaScript to insert rows into the table, with each row being constructed using the template as its basis.&lt;/p&gt;&lt;code&gt;// Test to see if the browser supports the HTML template element by checking
// for the presence of the template element's content attribute.
if ("content" in document.createElement("template")) {
  // Instantiate the table with the existing HTML tbody
  // and the row with the template
  const tbody = document.querySelector("tbody");
  const template = document.querySelector("#productrow");

  // Clone the new row and insert it into the table
  const clone = template.content.cloneNode(true);
  let td = clone.querySelectorAll("td");
  td[0].textContent = "1235646565";
  td[1].textContent = "Stuff";

  tbody.appendChild(clone);

  // Clone the new row and insert it into the table
  const clone2 = template.content.cloneNode(true);
  td = clone2.querySelectorAll("td");
  td[0].textContent = "0384928528";
  td[1].textContent = "Acme Kidney Beans 2";

  tbody.appendChild(clone2);
} else {
  // Find another way to add the rows to the table because
  // the HTML template element is not supported.
}
&lt;/code&gt;&lt;p&gt;The result is the original HTML table, with two new rows appended to it via JavaScript:&lt;/p&gt;&lt;head rend="h3"&gt;Implementing a declarative shadow DOM&lt;/head&gt;&lt;p&gt;In this example, a hidden support warning is included at the beginning of the markup. This warning is later set to be displayed via JavaScript if the browser doesn't support the &lt;code&gt;shadowrootmode&lt;/code&gt; attribute. Next, there are two &lt;code&gt;&amp;lt;article&amp;gt;&lt;/code&gt; elements, each containing nested &lt;code&gt;&amp;lt;style&amp;gt;&lt;/code&gt; elements with different behaviors. The first &lt;code&gt;&amp;lt;style&amp;gt;&lt;/code&gt; element is global to the whole document. The second one is scoped to the shadow root generated in place of the &lt;code&gt;&amp;lt;template&amp;gt;&lt;/code&gt; element because of the presence of the &lt;code&gt;shadowrootmode&lt;/code&gt; attribute.&lt;/p&gt;&lt;code&gt;&amp;lt;p hidden&amp;gt;
  â Your browser doesn't support &amp;lt;code&amp;gt;shadowrootmode&amp;lt;/code&amp;gt; attribute yet.
&amp;lt;/p&amp;gt;
&amp;lt;article&amp;gt;
  &amp;lt;style&amp;gt;
    p {
      padding: 8px;
      background-color: wheat;
    }
  &amp;lt;/style&amp;gt;
  &amp;lt;p&amp;gt;I'm in the DOM.&amp;lt;/p&amp;gt;
&amp;lt;/article&amp;gt;
&amp;lt;article&amp;gt;
  &amp;lt;template shadowrootmode="open"&amp;gt;
    &amp;lt;style&amp;gt;
      p {
        padding: 8px;
        background-color: plum;
      }
    &amp;lt;/style&amp;gt;
    &amp;lt;p&amp;gt;I'm in the shadow DOM.&amp;lt;/p&amp;gt;
  &amp;lt;/template&amp;gt;
&amp;lt;/article&amp;gt;
&lt;/code&gt;&lt;code&gt;const isShadowRootModeSupported = Object.hasOwn(
  HTMLTemplateElement.prototype,
  "shadowRootMode",
);

document
  .querySelector("p[hidden]")
  .toggleAttribute("hidden", isShadowRootModeSupported);
&lt;/code&gt;&lt;head rend="h3"&gt;Declarative Shadow DOM with delegated focus&lt;/head&gt;&lt;p&gt;This example demonstrates how &lt;code&gt;shadowrootdelegatesfocus&lt;/code&gt; is applied to a shadow root that is created declaratively, and the effect this has on focus.&lt;/p&gt;&lt;p&gt;The code first declares a shadow root inside a &lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt; element, using the &lt;code&gt;&amp;lt;template&amp;gt;&lt;/code&gt; element with the &lt;code&gt;shadowrootmode&lt;/code&gt; attribute.
This displays both a non-focusable &lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt; containing text and a focusable &lt;code&gt;&amp;lt;input&amp;gt;&lt;/code&gt; element.
It also uses CSS to style elements with &lt;code&gt;:focus&lt;/code&gt; to blue, and to set the normal styling of the host element.&lt;/p&gt;&lt;code&gt;&amp;lt;div&amp;gt;
  &amp;lt;template shadowrootmode="open"&amp;gt;
    &amp;lt;style&amp;gt;
      :host {
        display: block;
        border: 1px dotted black;
        padding: 10px;
        margin: 10px;
      }
      :focus {
        outline: 2px solid blue;
      }
    &amp;lt;/style&amp;gt;
    &amp;lt;div&amp;gt;Clickable Shadow DOM text&amp;lt;/div&amp;gt;
    &amp;lt;input type="text" placeholder="Input inside Shadow DOM" /&amp;gt;
  &amp;lt;/template&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;p&gt;The second code block is identical except that it sets the &lt;code&gt;shadowrootdelegatesfocus&lt;/code&gt; attribute, which delegates focus to the first focusable element in the tree if a non-focusable element in the tree is selected.&lt;/p&gt;&lt;code&gt;&amp;lt;div&amp;gt;
  &amp;lt;template shadowrootmode="open" shadowrootdelegatesfocus&amp;gt;
    &amp;lt;style&amp;gt;
      :host {
        display: block;
        border: 1px dotted black;
        padding: 10px;
        margin: 10px;
      }
      :focus {
        outline: 2px solid blue;
      }
    &amp;lt;/style&amp;gt;
    &amp;lt;div&amp;gt;Clickable Shadow DOM text&amp;lt;/div&amp;gt;
    &amp;lt;input type="text" placeholder="Input inside Shadow DOM" /&amp;gt;
  &amp;lt;/template&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;p&gt;Last of all we use the following CSS to apply a red border to the parent &lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt; element when it has focus.&lt;/p&gt;&lt;code&gt;div:focus {
  border: 2px solid red;
}
&lt;/code&gt;&lt;p&gt;The results are shown below. When the HTML is first rendered, the elements have no styling, as shown in the first image. For the shadow root that does not have &lt;code&gt;shadowrootdelegatesfocus&lt;/code&gt; set you can click anywhere except the &lt;code&gt;&amp;lt;input&amp;gt;&lt;/code&gt; and the focus does not change (if you select the &lt;code&gt;&amp;lt;input&amp;gt;&lt;/code&gt; element it will look like the second image).&lt;/p&gt;&lt;p&gt;For the shadow root with &lt;code&gt;shadowrootdelegatesfocus&lt;/code&gt; set, clicking on the text (which is non-focusable) selects the &lt;code&gt;&amp;lt;input&amp;gt;&lt;/code&gt; element, as this is the first focusable element in the tree.
This also focuses the parent element as shown below.&lt;/p&gt;&lt;head rend="h2"&gt;Avoiding DocumentFragment pitfalls&lt;/head&gt;&lt;p&gt;When a &lt;code&gt;DocumentFragment&lt;/code&gt; value is passed, &lt;code&gt;Node.appendChild&lt;/code&gt; and similar methods move only the child nodes of that value into the target node. Therefore, it is usually preferable to attach event handlers to the children of a &lt;code&gt;DocumentFragment&lt;/code&gt;, rather than to the &lt;code&gt;DocumentFragment&lt;/code&gt; itself.&lt;/p&gt;&lt;p&gt;Consider the following HTML and JavaScript:&lt;/p&gt;&lt;head rend="h3"&gt;HTML&lt;/head&gt;&lt;code&gt;&amp;lt;div id="container"&amp;gt;&amp;lt;/div&amp;gt;

&amp;lt;template id="template"&amp;gt;
  &amp;lt;div&amp;gt;Click me&amp;lt;/div&amp;gt;
&amp;lt;/template&amp;gt;
&lt;/code&gt;&lt;head rend="h3"&gt;JavaScript&lt;/head&gt;&lt;code&gt;const container = document.getElementById("container");
const template = document.getElementById("template");

function clickHandler(event) {
  event.target.append(" â Clicked this div");
}

const firstClone = template.content.cloneNode(true);
firstClone.addEventListener("click", clickHandler);
container.appendChild(firstClone);

const secondClone = template.content.cloneNode(true);
secondClone.children[0].addEventListener("click", clickHandler);
container.appendChild(secondClone);
&lt;/code&gt;&lt;head rend="h3"&gt;Result&lt;/head&gt;&lt;p&gt;Since &lt;code&gt;firstClone&lt;/code&gt; is a &lt;code&gt;DocumentFragment&lt;/code&gt;, only its children are added to &lt;code&gt;container&lt;/code&gt; when &lt;code&gt;appendChild&lt;/code&gt; is called; the event handlers of &lt;code&gt;firstClone&lt;/code&gt; are not copied. In contrast, because an event handler is added to the first child node of &lt;code&gt;secondClone&lt;/code&gt;, the event handler is copied when &lt;code&gt;appendChild&lt;/code&gt; is called, and clicking on it works as one would expect.&lt;/p&gt;&lt;head rend="h2"&gt;Technical summary&lt;/head&gt;&lt;table&gt;&lt;row span="2"&gt;&lt;cell role="head"&gt;Content categories&lt;/cell&gt;&lt;cell&gt;Metadata content, flow content, phrasing content, script-supporting element&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Permitted content&lt;/cell&gt;&lt;cell&gt;Nothing (see Usage notes)&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Tag omission&lt;/cell&gt;&lt;cell&gt;None, both the starting and ending tag are mandatory.&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Permitted parents&lt;/cell&gt;&lt;cell&gt; Any element that accepts metadata content, phrasing content, or script-supporting elements. Also allowed as a child of a &lt;code&gt;&amp;lt;colgroup&amp;gt;&lt;/code&gt;
        element that does not have a
        &lt;code&gt;span&lt;/code&gt; attribute.
      &lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Implicit ARIA role&lt;/cell&gt;&lt;cell&gt;No corresponding role&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Permitted ARIA roles&lt;/cell&gt;&lt;cell&gt;No &lt;code&gt;role&lt;/code&gt; permitted&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;DOM interface&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;HTMLTemplateElement&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;head rend="h2"&gt;Specifications&lt;/head&gt;&lt;table&gt;&lt;row&gt;&lt;cell role="head"&gt;Specification&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;HTML&amp;gt;&lt;p&gt;# the-template-element&amp;gt;&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;head rend="h2"&gt;Browser compatibility&lt;/head&gt;&lt;p&gt;Loadingâ¦&lt;/p&gt;&lt;head rend="h2"&gt;See also&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;part&lt;/code&gt;and&lt;code&gt;exportparts&lt;/code&gt;HTML attributes&lt;/item&gt;&lt;item&gt;&lt;code&gt;&amp;lt;slot&amp;gt;&lt;/code&gt;HTML element&lt;/item&gt;&lt;item&gt;&lt;code&gt;:has-slotted&lt;/code&gt;,&lt;code&gt;:host&lt;/code&gt;,&lt;code&gt;:host()&lt;/code&gt;, and&lt;code&gt;:host-context()&lt;/code&gt;CSS pseudo-classes&lt;/item&gt;&lt;item&gt;&lt;code&gt;::part&lt;/code&gt;and&lt;code&gt;::slotted&lt;/code&gt;CSS pseudo-elements&lt;/item&gt;&lt;item&gt;&lt;code&gt;ShadowRoot&lt;/code&gt;interface&lt;/item&gt;&lt;item&gt;Using templates and slots&lt;/item&gt;&lt;item&gt;CSS scoping module&lt;/item&gt;&lt;item&gt;Declarative Shadow DOM (with html) in Using Shadow DOM&lt;/item&gt;&lt;item&gt;Declarative shadow DOM on web.dev (2023)&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45106049</guid></item><item><title>Python has had async for 10 years – why isn't it more popular?</title><link>https://tonybaloney.github.io/posts/why-isnt-python-async-more-popular.html</link><description>&lt;doc fingerprint="363096d5e4a0b040"&gt;
  &lt;main&gt;&lt;p&gt;The Python Documentary dropped this morning. In the middle of the documentary, there’s a dramatic segment about how the transition from Python 2 to 3 divided the community (spoiler alert: it didn’t in the end).&lt;/p&gt;&lt;p&gt;The early versions of Python 3 (3.0-3.4) were mostly focused on stability and offering pathways for users moving from 2.7. Along came 3.5 in 2015 with a new feature: &lt;code&gt;async&lt;/code&gt; and &lt;code&gt;await&lt;/code&gt; keywords for executing coroutines.&lt;/p&gt;&lt;p&gt;Ten years and nine releases later, Python 3.14 is weeks away.&lt;/p&gt;&lt;p&gt;Whilst everyone will be distracted by the shiny, colorful REPL features in 3.14, there are some big announcements nestled in the release notes — both related to concurrency and parallelism&lt;/p&gt;&lt;p&gt;Both of these features are huge advancements in how Python can be used to execute concurrent code. But if &lt;code&gt;async&lt;/code&gt; has been here for 10 years, why do we need them?&lt;/p&gt;&lt;p&gt;The killer use-case for async is web development. Coroutines lend well to out-of-process network calls, like HTTP requests and database queries. Why block the entire Python interpreter waiting for a SQL query to run on another server?&lt;/p&gt;&lt;p&gt;Yet, among the three most popular Python web frameworks, async support is still not universal. FastAPI is async from the ground-up, Django has some support, but is “still working on async support” in key areas like the ORM (database). Then Flask is and probably always will be synchronous (Quart is an async alternative with similar APIs). The most popular ORM for Python, SQLAlchemy, only added asyncio support in 2023 (changelog).&lt;/p&gt;&lt;p&gt;I posed the question “Why isn’t async more popular” to a couple of other developers to get their thoughts.&lt;/p&gt;&lt;p&gt;Christopher Trudeau, co-host of the Real Python Podcast, shared his perspective:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Certain kinds of errors get caught by the compiler, others just disappear. Why didn’t that function run? Oops, forgot to await it. Error in the coroutine? Did you remember to launch with the right params, if not, it doesn’t percolate up. I still find threads easier to wrap my head around.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Michael Kennedy offered some additional insight:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;The [GIL] is so omnipresent that most Python people never developed multithreaded/async thinking. Because async/await only works for I/O bound work, not CPU as well, it’s of much less use. E.g. You can use in on the web, but most servers fork out to 4-8 web workers anyway&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;So what’s going on here and can we apply the lessons to Free-Threading and Multiple Interpreters in 3.14 so that in another ten years we’re looking back and wondering why they aren’t more popular?&lt;/p&gt;&lt;p&gt;Coroutines are most valuable with IO-related tasks. In Python, you can start hundreds of coroutines to make network requests, then wait for them all to finish without running them one at a time. The concepts behind coroutines are quite straightforward. You have a loop (the event loop) and you pass it coroutines to evaluate.&lt;/p&gt;&lt;p&gt;Let’s go back to the classic use-case, HTTP requests:&lt;/p&gt;&lt;code&gt;def get_thing_sync():
    return http_client.get('/thing/which_takes?ages=1')
&lt;/code&gt;&lt;p&gt;The equivalent async function is clean and readable:&lt;/p&gt;&lt;code&gt;async def get_thing_async():
    return await http_client.get('/thing/which_takes?ages=1')
&lt;/code&gt;&lt;p&gt;If you call function &lt;code&gt;get_thing_sync()&lt;/code&gt; versus &lt;code&gt;await get_thing_async()&lt;/code&gt;, they take the same amount of time. Calling it “✨ asynchronously ✨” does not somehow make it faster. The gains are when you have more than one coroutine running at once. &lt;/p&gt;&lt;p&gt;When fetching multiple HTTP resources you can start all the requests at once via the OS network stack, then handle each response as it arrives. The important point is that the actual work — sending packets and waiting for remote servers — happens outside your Python process while your code waits. Async is most effective here: you start operations, receive awaitable handles (tasks/futures), and the event loop efficiently notifies the coroutine when each operation completes without wasting CPU on busy‑polling.&lt;/p&gt;&lt;p&gt;This scenario works well because:&lt;/p&gt;&lt;p&gt;That’s all fine, but I started with the statement Coroutines are most valuable with IO-related tasks. I then picked the one task that asyncio can handle really well, HTTP requests.&lt;/p&gt;&lt;p&gt;What about disk IO? I have far more applications in Python which read and write from files on disks or memory than I do making HTTP requests. I also have Python programs which run other programs using &lt;code&gt;subprocess&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Can I make all of those &lt;code&gt;async&lt;/code&gt;?  &lt;/p&gt;&lt;p&gt;No, not really. From the asyncio Wiki:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;asyncio does not support asynchronous operations on the filesystem. Even if files are opened with O_NONBLOCK, read and write will block.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;The solution is to use a third-party package, &lt;code&gt;aiofiles&lt;/code&gt;, which gives you async file I/O capabilities:&lt;/p&gt;&lt;code&gt;async with aiofiles.open('filename', mode='r') as f:
    contents = await f.read()
&lt;/code&gt;&lt;p&gt;So, mission accomplished? No because &lt;code&gt;aiofiles&lt;/code&gt; uses a thread pool to offload the blocking file I/O operations. &lt;/p&gt;&lt;p&gt;Windows has an async file IO API called IoRing. Linux has this availability in newer Kernels via &lt;code&gt;io_uring&lt;/code&gt;. All I could find for a Python implementation of &lt;code&gt;io_uring&lt;/code&gt; is this synchronous API written in Cython.&lt;/p&gt;&lt;p&gt;There were io_uring APIs for other platforms, Rust has implementations with tokio, C++ has Asio and Node.JS has libuv.&lt;/p&gt;&lt;p&gt;So, the asyncio Wiki is a little out of date, but&lt;/p&gt;&lt;code&gt;io_uring&lt;/code&gt;&lt;code&gt;io_uring&lt;/code&gt; has been plagued by security issues so bad that RedHat, Google and others have restricted or removed its availability. After paying out $1 million in bug bounties related to &lt;code&gt;io_uring&lt;/code&gt;, Google disabled it on some products. The issue was severe; many of the related bug‑bounty reports involved io_uring exploits.&lt;p&gt;So we should hold our horses a little while longer. Operating Systems have long held a file IO API that handles threads for concurrent IO. It does the job just fine for now.&lt;/p&gt;&lt;p&gt;So in summary, Coroutines are most valuable with IO-related tasks is only really true for network I/O and network sockets in Python were never blocking operations in the first place. Socket open in Python is one of the few operations which releases the GIL and works concurrently in a thread pool as a non-blocking operation.&lt;/p&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell role="head"&gt;Operation&lt;/cell&gt;&lt;cell role="head"&gt;Asyncio API&lt;/cell&gt;&lt;cell role="head"&gt;Description&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Sleep&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;asyncio.sleep()&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Asynchronously sleep for a given duration.&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;TCP/UDP Streams&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;asyncio.open_connection()&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Open a TCP/UDP connection.&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;HTTP&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;aiohttp.ClientSession()&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Asynchronous HTTP client.&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Run Subprocesses&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;asyncio.subprocess&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Asynchronously run subprocesses.&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Queues&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;asyncio.Queue&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Asynchronous queue implementation.&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;Will McGugan, the creator of Rich, Textualize, and several other extremely popular Python libraries offered his perspective on async:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;I really enjoy async programming, but it isn’t intuitive for most devs that don’t have a background writing network code. A reoccurring problem I see with Textual is folk testing concurrency by dropping in a&lt;/p&gt;&lt;code&gt;time.sleep(10)&lt;/code&gt;call to simulate the work they are planning. Of course, that blocks the entire loop. But that’s a class of issue which is difficult to explain to devs who haven’t used async much. i.e. what does it mean for code to “block”, and when is it necessary to defer to threads. Without that grounding in the fundamentals, your async code is going to misbehave, but its not going to break per se. So devs don’t get the rapid iteration and feedback that we expect from Python.&lt;/quote&gt;&lt;p&gt;Now that we’ve covered the limited use cases for async, another challenge keeps coming up. The Python GIL.&lt;/p&gt;&lt;p&gt;I’ve been working on this C#/Python bridge project called CSnakes, one of the features that caused the most head-scratching was async.&lt;/p&gt;&lt;p&gt;C#, the language from which the &lt;code&gt;async&lt;/code&gt;/&lt;code&gt;await&lt;/code&gt; syntax was borrowed, has far broader async support in its core I/O libraries because it implements a Task‑based Asynchronous Pattern (TAP), where tasks are dispatched onto a managed thread pool. Disk, network, and memory I/O operations commonly provide both async and sync methods.&lt;/p&gt;&lt;p&gt;In fact, the C# implementation goes all the way up from the disk to the higher-level APIs, such as serialization libraries. JSON deserialization is async, so is XML.&lt;/p&gt;&lt;p&gt;The C# Async model and the Python Async models have some important differences:&lt;/p&gt;&lt;p&gt;The benefit of C#’s model is that a &lt;code&gt;Task&lt;/code&gt; is a higher-level abstraction over a thread or coroutine. This means that you don’t have to worry about the underlying thread management, you can schedule several tasks to be awaited concurrently or you can run them in parallel with Task Parallel Library (TPL).&lt;/p&gt;&lt;p&gt;In Python “An event loop runs in a thread (typically the main thread) and executes all callbacks and Tasks in its thread. While a Task is running in the event loop, no other Tasks can run in the same thread. When a Task executes an await expression, the running Task gets suspended, and the event loop executes the next Task.” 1&lt;/p&gt;&lt;p&gt;Going back to Will’s comment “Of course, that blocks the entire loop”, he’s talking about operations inside async functions which are blocking and therefore block the entire event loop. Since we covered in Problem 1, that’s practically everything except network calls and sleeping.&lt;/p&gt;&lt;p&gt;With Python’s GIL, it doesn’t matter if you’re running 1 thread or 10, the GIL will lock everything so that only 1 is operating at a time.&lt;/p&gt;&lt;p&gt;There are some operations don’t block the GIL (e.g. File IO) and in those cases you can run them in threads. For example, if you used &lt;code&gt;httpx&lt;/code&gt;‘s streaming feature to stream a large network download onto disk:&lt;/p&gt;&lt;code&gt;import httpx
import tempfile

def download_file(url: str):
    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
        with httpx.stream("GET", url) as response:
            for chunk in response.iter_bytes():
                tmp_file.write(chunk)
    return tmp_file.name
&lt;/code&gt;

&lt;p&gt;Neither the &lt;code&gt;httpx&lt;/code&gt; stream iterator nor &lt;code&gt;tmp_file.write&lt;/code&gt; is GIL-blocking, so they benefit from running in separate threads.&lt;/p&gt;&lt;p&gt;We can merge this behavior with an asyncio API, by using the Event Loop &lt;code&gt;run_in_executor()&lt;/code&gt; function and passing it a thread pool:&lt;/p&gt;&lt;code&gt;import asyncio
import concurrent.futures

async def main():
    loop = asyncio.get_running_loop()

    URLS = [
        "https://example.place/big-file-1",
        "https://example.place/big-file-2",
        "https://example.place/big-file-3",
        # etc.
    ]

    tasks = set()
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as pool:
        for url in URLS:
            tasks.add(loop.run_in_executor(pool, download_file, url))
        files = await asyncio.gather(*tasks)
    print(files)
&lt;/code&gt;

&lt;p&gt;It’s not immediately clear to me what the benefit of this is over running a thread-pool and calling &lt;code&gt;pool.submit&lt;/code&gt;. We retain an async API, so if that is important this is an interesting workaround. &lt;/p&gt;&lt;p&gt;I find that memorizing, documenting, and explaining what is and isn’t “blocking” in Python to be confusing and continually changing.&lt;/p&gt;&lt;p&gt;Python 3.13 introduced a very-unstable “free-threaded” build of Python where the GIL is removed and replaced with smaller, more granular locks. See my PyCon US 2024 Talk for a summary of parallelism. The 3.13 build wasn’t stable enough for any production use. 3.14 is looking far improved and I think we can start to introduce free-threading in 2026 in some narrow, well-tested scenarios.&lt;/p&gt;&lt;p&gt;One major benefit to coroutines versus threads is that they have a far smaller memory footprint, a lower context-switching overhead, and faster startup times. async APIs are also easier to reason about and compose.&lt;/p&gt;&lt;p&gt;Because parallelism in Python using threads has always been so limited, the APIs in the standard library are quite rudimentary. I think there is an opportunity to have a task-parallelism API in the standard library once free-threading is stabilized.&lt;/p&gt;&lt;p&gt;Last week I was implementing a registry function that did two discrete tasks. One calls a very slow sync-only API and the other calls several async APIs.&lt;/p&gt;&lt;p&gt;I want the behavior that:&lt;/p&gt;&lt;quote&gt;flowchart LR Start([Start]) --&amp;gt; Invoke["tpl.invoke()"] Invoke --&amp;gt; f1["f1()"] Invoke --&amp;gt; f2["f2()"] f1 --&amp;gt;|f1 -&amp;gt; T1| Join["Tuple[T1, T2]"] f2 --&amp;gt;|f2 -&amp;gt; T2| Join Join --&amp;gt; End([End])&lt;/quote&gt;&lt;p&gt;Since there are only two tasks, I don’t want to have to define a thread-pool or a set number of workers. I also don’t want to have to map or gather the callees. I want to retain my typing information so that the resulting variables are strongly typed from the return types of &lt;code&gt;function_a&lt;/code&gt; and &lt;code&gt;function_a&lt;/code&gt;. Essentially an API like this:&lt;/p&gt;&lt;code&gt;import tpl


def function_a() -&amp;gt; T1:
    ...

def function_b() -&amp;gt; T2:
    ...

result_a: T1, result_b: T2 = tpl.invoke(function_a, function_b)
&lt;/code&gt;

&lt;p&gt;This is all possible today but there are many constraints with the GIL. Free-threading will make parallel programming more popular in Python and we’ll have to revisit some of the APIs.&lt;/p&gt;&lt;p&gt;As a package maintainer, supporting both synchronous and asynchronous APIs is a big challenge. You also have to be selective with where you support async. Much of the stdlib doesn’t support async natively (e.g. logging backends).&lt;/p&gt;&lt;p&gt;Python’s Magic (&lt;code&gt;__dunder__&lt;/code&gt;) methods cannot be async. &lt;code&gt;__init__&lt;/code&gt; cannot be async for example, so none of your code can use network requests in the initializer.&lt;/p&gt;&lt;p&gt;This is an odd-pattern but I’ll keep it simple to illustrate my point. You have a class &lt;code&gt;User&lt;/code&gt; with a property &lt;code&gt;records&lt;/code&gt;. This property gives a list of records for that user. A synchronous API is straightforward:&lt;/p&gt;&lt;code&gt;class User:
    @property
    def records(self) -&amp;gt; list[RecordT]:
        # fetch records from database lazily
        ...
&lt;/code&gt;

&lt;p&gt;We can even use a lazily-initialized instance variable to cache this data.&lt;/p&gt;&lt;p&gt;Porting this API to async is a challenge because whilst &lt;code&gt;@property&lt;/code&gt; methods can be async, standard attributes are not. Having to &lt;code&gt;await&lt;/code&gt; some instance attributes and not others leaves a very odd API:&lt;/p&gt;&lt;code&gt;class AsyncDatabase:
    @staticmethod
    async def fetch_many(id: str, of: Type[RecordT]) -&amp;gt; list[RecordT]:
        ...

class User:
    @property
    async def records(self) -&amp;gt; list[RecordT]:
        # fetch records from database lazily
        return await AsyncDatabase.fetch_many(self.id, RecordT)
&lt;/code&gt;

&lt;p&gt;Anytime you access that property, it needs to be awaited:&lt;/p&gt;&lt;code&gt;user = User(...)
# single access
await user.records
# if
if await user.records:
    ...
# comprehension?
[record async for record in user.records]
&lt;/code&gt;

&lt;p&gt;The further we go into this implementation, the more we wait for the user to accidentally forget to await the property and it fails silently.&lt;/p&gt;&lt;p&gt;The Azure Python SDK, a ginormous Python project supports both sync and async. Maintaining both is achieved via a lot of code-generation infrastructure. This is ok for a project with tens of full-time engineers, but for anything small or voluntary you need to copy + paste a lot of your code base to create an async version. Then you need to patch and backport fixes and changes between the two. The differences (mostly &lt;code&gt;await&lt;/code&gt; calls) are big enough to confuse Git. I was reviewing some langchain implementations last year which had both sync and async implementation. Every method was copied+pasted, with little behavioral differences and their own bugs. People would submit bug fix PR’s to one implementation and not the other so instead of merging directly, maintainers had to port the fix, skip it, or ask the contributors to do both.&lt;/p&gt;&lt;p&gt;Since we’re largely talking about HTTP/Network IO, you also need to pick a backend for sync and async. For synchronous HTTP calls, &lt;code&gt;requests&lt;/code&gt;, &lt;code&gt;httpx&lt;/code&gt; are suitable backends. For &lt;code&gt;async&lt;/code&gt;, its &lt;code&gt;aiohttp&lt;/code&gt; and &lt;code&gt;httpx&lt;/code&gt;. Since neither are part of the Python standard library, the adoption and support for CPython’s main platforms is out of sync. E.g. as of today, &lt;code&gt;aiohttp&lt;/code&gt; has no Python 3.14 wheels, nor free-threaded support. UV Loop, the alternative implementation of the event loop has no Python 3.14 support, nor any Windows support. (Python 3.14 isn’t out yet, so it’s reasonable to not have support in either open-source project).&lt;/p&gt;&lt;p&gt;Further down the copy+paste maintainer overhead is the testing of these APIs. Testing your async code requires different mocks, different calls and in the case of Pytest a whole set of extensions and patterns for fixtures. This situation is so confusing I wrote a post about it and it’s one of the most popular on my blog.&lt;/p&gt;&lt;p&gt;In summary, I think the use cases for asyncio are limited (mostly for reasons beyond the control of &lt;code&gt;asyncio&lt;/code&gt;) and this has constrained it’s popularity. Maintaining duplicate code-bases is a burden.&lt;/p&gt;&lt;p&gt;FastAPI, the web framework that’s async from-the-ground-up grew in popularity again from 29% to 38% share of the web frameworks for Python, taking the #1 spot. It has over 100-million downloads a month. Considering the big use-case for async is HTTP and network IO, having the #1 web framework be an async one is a sign of asyncio’s success.&lt;/p&gt;&lt;p&gt;I think in 3.14 the sub-interpreter executor and free-threading features make more parallel and concurrency use cases practical and useful. For those, we don’t need &lt;code&gt;async&lt;/code&gt; APIs and it alleviates much of the issues I highlighted in this post.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45106189</guid></item><item><title>Microsoft rewarded for security failures with another US Government contract</title><link>https://www.theregister.com/2025/09/02/microsoft_rewarded_for_security_failures/</link><description>&lt;doc fingerprint="3f508f1050884273"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Microsoft rewarded for security failures with another US government contract&lt;/head&gt;
    &lt;head rend="h2"&gt;Free Copilot for any agency who actually wants it&lt;/head&gt;
    &lt;p&gt;Microsoft, the latest tech firm to agree to big software discounts for the US government, is digging even deeper into its bargain bin than the competition by offering a year of free Copilot access to government agencies willing to put up with its other problem products.&lt;/p&gt;
    &lt;p&gt;The General Services Administration (GSA) announced its new deal with Microsoft on Tuesday, describing it as a "strategic partnership" that could save the federal government as much as $3.1 billion over the next year. The GSA didn't mention specific discount terms, but it said that services, including Microsoft 365, Azure cloud services, Dynamics 365, Entra ID Governance, and Microsoft Sentinel, will be cheaper than ever for feds.&lt;/p&gt;
    &lt;p&gt;That, and Microsoft's next-gen Clippy, also known as Copilot, is free to access for any agency with a G5 contract as part of the new deal, too. That free price undercuts Google's previously cheapest-in-show deal to inject Gemini into government agencies for just $0.47 for a year.&lt;/p&gt;
    &lt;p&gt;The GSA made this Microsoft deal as part of its OneGov initiative, which seeks to centralize purchasing of products and services used across the government under a single contract. While the agency intends for OneGov to extend across the federal government, the first phase of the program focuses exclusively on IT contracts.&lt;/p&gt;
    &lt;p&gt;Though it only announced OneGov in April, the GSA has awarded contracts under the plan at a rapid pace, with Oracle the first firm to sign a deal in July. That agreement includes a 75 percent discount on its products to government agencies.&lt;/p&gt;
    &lt;p&gt;The agency wrote many of the other OneGov contracts to get AI products into the hands of government agencies. OpenAI and Anthropic both made deals with the GSA in August to provide a year of their services to agencies for $1 each, which Google undercut later last month.&lt;/p&gt;
    &lt;p&gt;Even Box made an AI discount deal with the federal government, though it didn't disclose pricing. Outside of AI offerings, Amazon Web Services inked its own OneGov deal with the GSA to offer discounted cloud services through 2028.&lt;/p&gt;
    &lt;p&gt;With the exception of AWS, all the other OneGov deals that have been announced so far have a very short shelf life, with most expirations at the end of 2026. Critics of the OneGov program have raised concerns that OneGov deals have set government agencies up for a new era of vendor lock-in not seen since the early cloud days, where one-year discounts leave agencies dependent on services that could suddenly become considerably more expensive by the end of next year.&lt;/p&gt;
    &lt;p&gt;Nicholas Chaillan, former US Air Force and Space Force chief software officer and founder of AI firm Ask Sage, told The Register in a recent conversation that he's protested the OpenAI, Anthropic, and Google deals, accusing the GSA of undermining its own rules on fair and open competition for government-wide contracts.&lt;/p&gt;
    &lt;p&gt;"Pricing this low is not about serving agencies – it's about forcing dependence on a single vendor, hiding future costs, and squeezing out fair competition," Chaillan told us in an email. "What looks cheap today will leave the government with higher costs, fewer options, and greater risk tomorrow."&lt;/p&gt;
    &lt;p&gt;Chillain told us that GSA hasn't made the OneGov contracts public so they could be scrutinized for any unfair elements. We've tried obtaining copies but the GSA hasn't acknowledged those requests. As with the other OneGov contracts, what happens to the discounts after the September 2026 end of the offering isn't clear.&lt;/p&gt;
    &lt;p&gt;The GSA's press release mentioned that discounted pricing will be available for "certain products" for up to 36 months, but the terms of those discounts or the specific products available weren't mentioned. Microsoft's announcement of its new OneGov deal said those extended discounts will save the government as much as $6 billion over three years.&lt;/p&gt;
    &lt;p&gt;The GSA didn't respond to questions for this story.&lt;/p&gt;
    &lt;head rend="h3"&gt;Microsoft gets rewarded for security failures – again&lt;/head&gt;
    &lt;p&gt;Like other tech giants making OneGov deals, Microsoft will likely have to burn some capital to reap the monetary rewards from government agencies who grow dependent on its cheap or free software in the next year. Unlike those other tech giants making OneGov deals, however, Microsoft is yet again being rewarded by the US government with a pathway to profit after making a massive national security mistake.&lt;/p&gt;
    &lt;p&gt;It was mere days ago that we reported on the Pentagon's decision to formally bar Microsoft from using China-based engineers to support sensitive cloud services deployed by the Defense Department, a practice Defense Secretary Pete Hegseth called "mind-blowing" in a statement last week.&lt;/p&gt;
    &lt;p&gt;Then there was last year's episodes that allowed Chinese and Russian cyber spies to break into Exchange accounts used by high-level federal officials and steal a whole bunch of emails and other information. That incident, and plenty more before it, led former senior White House cyber policy director AJ Grotto to conclude that Microsoft was an honest-to-goodness national security threat. None of that has mattered much, as the feds seem content to continue paying Microsoft for its services, despite wagging their finger at Redmond for "avoidable errors."&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Pentagon 'doubling down' on Microsoft despite 'massive hack,' senators complain&lt;/item&gt;
      &lt;item&gt;Microsoft eggheads say AI can never be made secure – after testing Redmond's own products&lt;/item&gt;
      &lt;item&gt;Microsoft answered Congress' questions on security. Now the White House needs to act&lt;/item&gt;
      &lt;item&gt;Google takes shots at Microsoft for shoddy security record with enterprise apps&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When it comes to government customers, using China-based support staff isn't Microsoft's only sin. The company had a Sharepoint zero-day that it only "partially" addressed with July security updates. Suspected state-backed hackers used that vuln to target an unspecified "major western government," per the company.&lt;/p&gt;
    &lt;p&gt;That, senior cybersecurity and counterterrorism advisor for the Clinton and Bush II administrations Roger Cressey told us last month, is among the reasons he considers Microsoft to be a continual gift to America's foreign adversaries, as the Sharepoint issue is just "the latest episode of a decades-long process of Microsoft not taking security seriously."&lt;/p&gt;
    &lt;p&gt;"The Chinese are so well prepared and positioned on Microsoft products that in the event of hostilities, we know for a fact that Chinese actors will target our critical infrastructure through Microsoft," Cressey told us in an interview last month.&lt;/p&gt;
    &lt;p&gt;When asked what it had done to improve its security posture, Microsoft declined to answer any of our questions directly, instead pointing us to its press release about today's GSA deal, specifically its section on security.&lt;/p&gt;
    &lt;p&gt;Agencies are safe to adopt Microsoft software, the company said, because "these services have already achieved key FedRAMP security and compliance authorizations." FedRAMP is the government's security approval process for cloud software.&lt;/p&gt;
    &lt;p&gt;"Microsoft 365, Azure and our key AI services are authorized at FedRAMP High," the company statement says. "Microsoft 365 Copilot received provisional authorization from the US Department of Defense, with FedRAMP High expected soon."&lt;/p&gt;
    &lt;p&gt;That's not exactly reassuring considering Microsoft's products have variously been authorized for government use for years, well before many of its recent security failings that affected federal agencies. ®&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45106295</guid></item><item><title>Introduction to Ada: a project-based exploration with rosettas</title><link>https://blog.adacore.com/introduction-to-ada-a-project-based-exploration-with-rosettas</link><description>&lt;doc fingerprint="a48888018a6d1bd8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introduction to Ada: a project-based exploration with rosettas&lt;/head&gt;
    &lt;head rend="h2"&gt;by Romain Gora –&lt;/head&gt;
    &lt;head rend="h2"&gt;Context&lt;/head&gt;
    &lt;p&gt;This practical walkthrough, designed as a short tutorial, was created upon joining AdaCore as a Field Engineer. In this new role, Iâll be working directly with customers to help them succeed with Ada. Although I was first introduced to the language nearly two decades ago, this new position inspired me to revisit its fundamentals, and I used the excellent https://learn.adacore.com portal as a quick refresher.&lt;/p&gt;
    &lt;p&gt;While that platform takes a concept-based approach, I chose to complement it with a project-based method by developing a small, end-to-end Ada program that generates animated rosettas in the form of SVG files. These are technically hypotrochoid curves, producing patterns that many will recognize from the classic Spirographâ¢ toy.&lt;/p&gt;
    &lt;p&gt;In this walkthrough, weâll show that Ada can be fun and easy to learn. Although the language is famous for safety-critical systems, we will use it as a modern, general-purpose programming language and try out some new features from Ada 2022 along the way.&lt;/p&gt;
    &lt;p&gt;Let's dive in!&lt;/p&gt;
    &lt;head rend="h2"&gt;A brief note on Ada&lt;/head&gt;
    &lt;p&gt;This section leans a bit more into background context, with a slightly encyclopedic flavor that's especially useful for readers new to Ada. If you're already familiar with Adaâs history and principles, feel free to joyfully skip ahead to the next section!&lt;/p&gt;
    &lt;p&gt;Ada was created in the late 1970s after a call from the U.S. Department of Defense to unify its fragmented software landscape. The winning proposal became Ada, a language that's been literally battle-tested (!) and built on a deeply thought-out design that continues to evolve today.&lt;/p&gt;
    &lt;p&gt;While Ada is absolutely a general-purpose programming language, it has carved out a strong niche in fields where software correctness and reliability are mission-critical:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Embedded and real-time systems&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Aerospace and defense&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Rail, automotive, and aviation&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Any system where failure is not just a bug, but a risk&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Its strict compile-time checks, safety features, and clear structure make it particularly appealing when you need your software to be dependable from day one and still maintainable ten years later.&lt;/p&gt;
    &lt;p&gt;Ada's design is grounded in a strong and principled philosophy:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Readability over conciseness: Ada favors clarity. It avoids symbols and abbreviations in favor of full keywords, making the language more accessible and less error-prone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Strong and explicit typing: It is extremely easy to declare new types in Ada, with precise constraints, which makes it much harder to accidentally misuse data. While some functional languages share this strong typing discipline, Ada stands out by requiring the programmer to be very explicit. It uses little to no type inference.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Explicit is better than implicit: Unlike many modern languages that prioritize convenience, Ada leans heavily toward precision. Most types must be explicitly named and matched.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Defined semantics and minimal undefined behavior: Ada offers a level of predictability and safety unmatched in many languages. This makes it a strong choice not only for safety-critical systems, but also for codebases where long-term maintenance, verifiability, and correctness are essential.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Compiler as a partner: Ada compilers are strict by design, not to frustrate, but to help the programmer write clearer, more correct code. This philosophy encourages the developer to communicate intent clearly, both to the compiler and to future readers.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;How the program works&lt;/head&gt;
    &lt;p&gt;Sometimes the best way to figure out how something works is to start at the end. Let's do that!&lt;lb/&gt;In this tutorial, we'll walk through how the program produces its final output â a rosetta SVG file â and use that as a way to explore how Ada's structure, type system, and tooling come together.&lt;lb/&gt;This is a simple command-line program that generates an SVG file. You run it like this:&lt;/p&gt;
    &lt;p&gt;./bin/rosetta&lt;/p&gt;
    &lt;p&gt;The idea was to create something visual: learning is more fun when there's an immediate, satisfying result and generating rosettas fits that goal perfectly.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;Why SVG? Because it's a lightweight and portable vector format that you can view in any modern browser. I wanted to avoid relying on a graphical library, which would have added extra weight and gone beyond the scope of this approach. And while XML isn't the most pleasant format to write by hand, generating it from code is straightforward and gives a surprisingly clean result.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tooling &amp;amp; setup&lt;/head&gt;
    &lt;p&gt;To build and run the project, I used Alire, the Ada package manager. It plays a similar role in the Ada ecosystem as Cargo does for Rust or npm for JavaScript. It's well-documented, and while we won't dive deep into it here, it's a solid and accessible way to manage Ada projects. I encourage anyone curious to get it from https://alire.ada.dev. Interestingly, "Alire" is also the French expression for "Ã lire" â which means "for reading." A fitting name for a tool that supports a language so focused on clarity and readability!&lt;/p&gt;
    &lt;p&gt;Once Alire is set up, the natural next step is choosing where to write the code. You have two excellent options for your development environment. For a dedicated experience, you can download the latest release of GNAT Studio from its GitHub repository. If you prefer a more general-purpose editor, you can install the official Ada &amp;amp; SPARK for Visual Studio Code extension from AdaCore.&lt;/p&gt;
    &lt;p&gt;As a new learner, I also kept https://learn.adacore.com close at hand. Itâs a particularly clear and comprehensive resource â and I especially appreciated being able to download the ebook version and read through it on my phone.&lt;/p&gt;
    &lt;head rend="h2"&gt;Entry point&lt;/head&gt;
    &lt;code&gt;with Rosetta_Renderer;

procedure Main is
begin
   Rosetta_Renderer.Put_SVG_Rosettas;
end Main;&lt;/code&gt;
    &lt;p&gt;There are several interesting things to notice right away:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;with&lt;/code&gt;clause is not a preprocessor directive like in C or C++. Itâs a compiled, checked reference to another package â a reliable and explicit way to express a dependency. This eliminates entire classes of bugs related to fragile&lt;code&gt;#include&lt;/code&gt;chains, macro collisions, or dependency order issues.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;This&lt;/p&gt;&lt;code&gt;procedure&lt;/code&gt;is not a&lt;code&gt;function&lt;/code&gt;: it does not return a value. In Ada, procedures are used to perform actions (like printing or modifying state), and functions are used to compute and query values.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The syntax is designed for readability. Youâll find&lt;/p&gt;&lt;code&gt;begin&lt;/code&gt;and&lt;code&gt;end&lt;/code&gt;here instead of&lt;code&gt;{}&lt;/code&gt;as in C/C++, reinforcing Adaâs philosophy that clarity matters more than brevity.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Put_SVG_Rosettas&lt;/code&gt;uses the idiomatic Pascal_Snake_Case naming style. This reflects a common Ada convention and avoids acronyms or compressed identifiers in favor of more descriptive names.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The entry point is minimal but meaningful: it simply calls a procedure which generates the output we'll explore in the next sections.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Geometry and computation (package Rosetta)&lt;/head&gt;
    &lt;p&gt;In Ada, a package is a modular unit that groups related types, procedures, and functions. Following the convention from GNAT (the Ada compiler, part of the GNU Compiler Collection, fondly known as GCC), each package has a specification file (with the&lt;code&gt; .ads&lt;/code&gt; extension â short for Ada Specification) and an implementation file (with the &lt;code&gt;.adb&lt;/code&gt; extension â short for Ada Body). This clear and enforced split means you always know where to find interface definitions versus their implementation.&lt;/p&gt;
    &lt;p&gt;The following code is the package specification for Rosetta. It defines the data types for the rosetta shapes and declares the public interface of operations available to manipulate them.&lt;/p&gt;
    &lt;code&gt;with Ada.Strings.Text_Buffers;

package Rosetta is

   --  A mathematical description of a rosetta (specifically, a hypotrochoid).
   --  formed by tracing a point attached to a circle rolling inside another circle.
   type Hypotrochoid is record
      Outer_Radius : Float;     --  Radius of the fixed outer circle.
      Inner_Radius : Float;     --  Radius of the rolling inner circle.
      Pen_Offset   : Float;     --  From the center of the inner circle to the drawing point.
      Steps        : Positive;  --  Number of steps (points) used to approximate the curve.
   end record;

   --  A 2D coordinate in Cartesian space.
   type Coordinate is record
      X_Coord, Y_Coord : Float;
   end record
     with Put_Image =&amp;gt; Put_Image_Coordinate;
   
   --  Redefines the 'Image attribute for Coordinate.
   procedure Put_Image_Coordinate 
     (Output : in out Ada.Strings.Text_Buffers.Root_Buffer_Type'Class; 
      Value  : Coordinate);

   --  A type for an unconstrained array of 2D points forming a curve.
   --  The actual bounds are set when an array object of this type is declared.
   type Coordinate_Array is array (Natural range &amp;lt;&amp;gt;) of Coordinate;

   --  Computes the coordinates of the rosetta curve defined by Curve (a hypotrochoid).
   --  Returns a centered array of coordinates.
   function Compute_Points (Curve : Hypotrochoid) return Coordinate_Array;

end Rosetta;&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;Rosetta&lt;/code&gt; package is responsible for all the math and curve computation. It defines:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;Hypotrochoid&lt;/code&gt;, type describing the geometry of the rosetta&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Coordinate&lt;/code&gt;, type representing points in 2D space&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Coordinate_Array&lt;/code&gt;, type holding a series of such points&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Compute_Points&lt;/code&gt;, function which calculates all the points of the curve based on the&lt;code&gt;Hypotrochoid&lt;/code&gt;parameters and recenters them around the origin&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This package is focused solely on computation. It doesnât concern itself with how the result is rendered.&lt;/p&gt;
    &lt;p&gt;Fun fact for the curious: when the rolling circle rolls outside the fixed circle rather than inside, the resulting curve is called an epitrochoid.&lt;/p&gt;
    &lt;p&gt;In Ada, a &lt;code&gt;record&lt;/code&gt; is similar to a &lt;code&gt;struct&lt;/code&gt; in C or a class with only data members in other languages. It's a user-defined type composed of named components, making it ideal for modeling structured data.&lt;/p&gt;
    &lt;p&gt;Using a record for &lt;code&gt;Hypotrochoid&lt;/code&gt; was particularly appropriate: it allows grouping all geometric parameters (outer radius, inner radius, pen offset, and steps) into a single, cohesive unit. This improves readability and maintainability. The compiler enforces correctness by ensuring all required values are present and of the expected type â reinforcing Adaâs philosophy of clarity and safety.&lt;/p&gt;
    &lt;p&gt;The type &lt;code&gt;Coordinate_Array&lt;/code&gt; is an unconstrained array type that holds a range of &lt;code&gt;Coordinate&lt;/code&gt; records. In this context, âunconstrainedâ simply means that we donât define the arrayâs size when we declare the type. Instead, the size is defined when we declare an object of that type. This gives us the flexibility to use this type for a variety of shapes.&lt;/p&gt;
    &lt;p&gt;You may also notice the use of &lt;code&gt;Natural range &amp;lt;&amp;gt;. Natural&lt;/code&gt; is a predefined subtype of Integer that only allows non-negative values. And yes, I mean subtype: Adaâs powerful type system allows you to take an existing type and create a more specific, constrained version of it.&lt;/p&gt;
    &lt;head rend="h3"&gt;Highlights from the .adb file&lt;/head&gt;
    &lt;p&gt;Here are a few notable aspects from the implementation (&lt;code&gt;rosetta.adb&lt;/code&gt;) that illustrate Adaâs strengths for writing safe, clear, and structured code:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Declarative and modular design: Both&lt;/p&gt;&lt;code&gt;Generate_Point&lt;/code&gt;and&lt;code&gt;Compute_Points&lt;/code&gt;are pure functions that operate only on their inputs. Their behavior is fully deterministic and encapsulated.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Safe bounds and array handling: The&lt;/p&gt;&lt;code&gt;Points&lt;/code&gt;array is statically bounded using&lt;code&gt;(0 .. Curve.Steps)&lt;/code&gt;, and its access is strictly safe. The compiler ensures that any index outside this range would raise an error at runtime. This immediate error is a feature, not a bug. It stops silent memory corruption and security flaws by ensuring the program fails predictably and safely at the source of the problem.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Use of constants for robustness: Variables such as&lt;/p&gt;&lt;code&gt;Pi&lt;/code&gt;,&lt;code&gt;R_Diff&lt;/code&gt;, and Ratio are declared as constant, enforcing immutability. This helps ensure clarity of intent and prevents accidental reassignment, a common source of subtle bugs in more permissive languages. Ada encourages this explicit declaration style, promoting safer code.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;with Ada.Numerics;
with Ada.Numerics.Elementary_Functions;

use Ada.Numerics;
use Ada.Numerics.Elementary_Functions;

package body Rosetta is

   --  Computes a single point on the hypotrochoid curve for a given angle Theta.
   --  Uses the standard parametric equation of a hypotrochoid.
   function Generate_Point (Curve : Hypotrochoid; Theta : Float) return Coordinate is
      R_Diff : constant Float := Curve.Outer_Radius - Curve.Inner_Radius;
      Ratio  : constant Float := R_Diff / Curve.Inner_Radius;
   begin
      return (
              X_Coord =&amp;gt; R_Diff * Cos (Theta) + Curve.Pen_Offset * Cos (Ratio * Theta),
              Y_Coord =&amp;gt; R_Diff * Sin (Theta) - Curve.Pen_Offset * Sin (Ratio * Theta)
             );
   end Generate_Point;

   --  Computes all the points of the hypotrochoid curve and recenters them.
   --  The result is an array of coordinates centered around the origin.
   function Compute_Points (Curve : Hypotrochoid) return Coordinate_Array is
      Points : Coordinate_Array (0 .. Curve.Steps);
      Max_X  : Float := Float'First;
      Min_X  : Float := Float'Last;
      Max_Y  : Float := Float'First;
      Min_Y  : Float := Float'Last;
      Offset : Coordinate;
   begin
      --  Computes raw points and updates the bounding box extents.
      for J in 0 .. Curve.Steps loop
         declare
            Theta : constant Float := 2.0 * Pi * Float (J) / Float (Curve.Steps) * 50.0;
            P     : constant Coordinate := Generate_Point (Curve, Theta);
         begin
            Points (J) := P;
            Max_X := Float'Max (Max_X, P.X_Coord);
            Min_X := Float'Min (Min_X, P.X_Coord);
            Max_Y := Float'Max (Max_Y, P.Y_Coord);
            Min_Y := Float'Min (Min_Y, P.Y_Coord);
         end;
      end loop;

      --  Computes the center offset based on the bounding box.
      Offset := (
                 X_Coord =&amp;gt; (Max_X + Min_X) / 2.0,
                 Y_Coord =&amp;gt; (Max_Y + Min_Y) / 2.0
                );

      --  Recenters all points by subtracting the center offset.
      for J in Points'Range loop
         Points (J).X_Coord := @ - Offset.X_Coord;
         Points (J).Y_Coord := @ - Offset.Y_Coord;
      end loop;

      return Points;
   end Compute_Points;
   
   --  Redefines the 'Image attribute for Coordinate.
   procedure Put_Image_Coordinate
     (Output : in out Ada.Strings.Text_Buffers.Root_Buffer_Type'Class;
      Value  : Coordinate)
   is   
      X_Text : constant String := Float'Image (Value.X_Coord);
      Y_Text : constant String := Float'Image (Value.Y_Coord);
   begin
      Output.Put (X_Text &amp;amp; "," &amp;amp; Y_Text);
   end Put_Image_Coordinate;

end Rosetta;&lt;/code&gt;
    &lt;head rend="h2"&gt;On style: strict and predictable (and satisfying!)&lt;/head&gt;
    &lt;p&gt;Ada is one of those rare languages that not only compiles your code but asks you to write it properly. With the compiler switch -gnaty, you can enforce a comprehensive set of style rules, many of which are stricter than what you'd see in most languages.&lt;/p&gt;
    &lt;p&gt;This includes things like:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;No trailing whitespace at the end of lines&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No consecutive blank lines&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Proper indentation and alignment of keywords and parameters&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;A space before â(â when calling a procedure or function&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Consistent casing&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;At first, this can feel surprisingly strict. But once you get used to it, the benefits are clear: it helps enforce a consistent and clean coding style across a codebase. That in turn improves readability, reduces ambiguity, and leads to more maintainable programs.&lt;/p&gt;
    &lt;p&gt;Rather than leaving formatting up to personal taste or optional linter tools, Ada integrates this attention to detail into the compilation process itself. The result is not only more elegant: it's genuinely satisfying. And you can do even more with GNATcheck and GNATformat but itâs outside of the scope of this post.&lt;/p&gt;
    &lt;p&gt;Outputting to SVG (package &lt;code&gt;Rosetta_Renderer&lt;/code&gt;)&lt;/p&gt;
    &lt;p&gt;The Rosetta_Renderer package is responsible for producing the SVG output. It defines a single high-level procedure:&lt;/p&gt;
    &lt;code&gt;package Rosetta_Renderer is

   --  Renders a predefined set of rosettas into an SVG output.
   procedure Put_SVG_Rosettas;

end Rosetta_Renderer;&lt;/code&gt;
    &lt;p&gt;This procedure generates an SVG file directly. It takes care of formatting the SVG structure (header, shapes, animations, and footer) and calls into the math logic defined in the &lt;code&gt;Rosetta &lt;/code&gt;package to generate point data.&lt;/p&gt;
    &lt;p&gt;This separation of concerns is deliberate and beneficial: the math logic doesnât need to know anything about SVG, and the renderer doesnât care how the coordinates were generated.&lt;/p&gt;
    &lt;p&gt;Now let's talk about the body of the package... but not for long. We're keeping it brief because its core is essentially the SVG plumbing required to draw and animate the curves, so we'll skip the fine details. And for those who enjoy seeing how the sausage is made, I've made the fully commented source code available for you right here.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;The procedure &lt;code&gt;Put_Path&lt;/code&gt; handles the creation of the SVG path. Its main job is to take an array of coordinates and write the corresponding command string to the &lt;code&gt;d &lt;/code&gt;attribute of a&lt;code&gt; &amp;lt;path&amp;gt;&lt;/code&gt; element. In SVG, this attribute defines the geometry of the shape. The code iterates over each coordinate, using &lt;code&gt;M &lt;/code&gt;(moveto) for the first point and &lt;code&gt;L&lt;/code&gt; (lineto) for all the others to draw the connecting lines.&lt;/p&gt;
    &lt;code&gt;--  Puts coordinates to a single SVG path string ("d" attribute).
   procedure Put_Path (Stream : File_Type; Points : Coordinate_Array) is
   begin
      Put (Stream, "M "); -- Moves the pen without drawing.
      for J in Points'Range loop
         declare 
            Coord_Text : constant String := Coordinate'Image (Points (J));
         begin   
            Put (Stream, Coord_Text);
            if J &amp;lt; Points'Last then
               Put (Stream, " L "); --  Draws a line.
            end if;
         end;
      end loop;
   end Put_Path;&lt;/code&gt;
    &lt;head rend="h2"&gt;Afterword&lt;/head&gt;
    &lt;p&gt;This small project was an enjoyable and useful way to get back into Ada. It helped me reconnect with the languageâs main strengths and refamiliarize myself with its tools and design. It was a great reminder of how fun, easy to learn, and remarkably modern Ada can be, especially for developers focused on building robust, maintainable, and efficient software.&lt;/p&gt;
    &lt;p&gt;I hope this short walkthrough gives a good idea of that feeling, whether you're already into Ada or just starting to explore it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45106314</guid></item><item><title>Physically based rendering from first principles</title><link>https://imadr.me/pbr/</link><description>&lt;doc fingerprint="4fae1661081d071f"&gt;
  &lt;main&gt;
    &lt;p&gt;In this interactive article, we will explore the physical phenomena that create light and the fundamental laws governing its interaction with matter. We will learn how our human eyes capture light and how our brains interpret it as visual information. We will then model approximations of these physical interactions and learn how to create physically realistic renderings of various materials.&lt;/p&gt;
    &lt;p&gt;We are all familiar with light: it’s the thing that allows us to see the world, distinguish colors and textures, and keeps the universe from being a dark, lifeless void. But precisely defining what light is has proven to be a tricky question.&lt;/p&gt;
    &lt;p&gt;Throughout history, many philosophers (and later, physicists) studied light in an effort to demystify its nature. Some ancient Greeks considered it to be one of the four fundamental elements that composed the universe: beams of fire emanating from our eyes.&lt;/p&gt;
    &lt;p&gt;Descartes proposed that light behaved like waves, while Newton thought that it consisted of tiny particles of matter called corpuscles.&lt;/p&gt;
    &lt;p&gt;Each of these more or less scientific theories explained some aspects of light's behavior, but none could account for all of them in a single, unified framework. That was until the 1920s when physicists came up with quantum electrodynamics. This theory is, as of now, the most accurate way to describe every interaction of light and matter.&lt;/p&gt;
    &lt;p&gt;You can hover the diagram below to see which light's phenomena can be explained using each model:&lt;/p&gt;
    &lt;p&gt;For the purpose of computer graphics, the ray optics model is accurate enough at simulating light interactions. But for the sake of scientific curiosity, we will explore some aspects of the other models, starting with electromagnetism.&lt;/p&gt;
    &lt;p&gt;One of the fundamental properties of matter is the electric charge, and it comes in two types: positive and negative.&lt;lb/&gt;Charges determine how particles interact: charges of the same type repel each other, while opposite charges attract.&lt;/p&gt;
    &lt;p&gt;The amount of force affecting two charged particles is calculated using Coulomb's law:&lt;/p&gt;
    &lt;p&gt;Where is a constant, and are the quantities of each charge, and is the distance between them.&lt;/p&gt;
    &lt;p&gt;You can drag around these charges to see how the electric force affects them:&lt;/p&gt;
    &lt;p&gt;Every charge contributes to the electric field, it represents the force exerted on other charges at each point in space. We can visualize the electric field with a or a :&lt;/p&gt;
    &lt;p&gt;Another way to visualize the electric field is by coloring each point in space with a color gradient representing the force experienced by a small charge at that point:&lt;/p&gt;
    &lt;p&gt;Imagine a moving object carrying a positive electric charge placed under a cable carrying an electrical current.&lt;lb/&gt; From , the object and the negative charges in the wire are moving, and since the positive and negative charges in the cable compensate each other, the object doesn't experience any force.&lt;/p&gt;
    &lt;p&gt;In the , it appears to be static alongside the negative charges, while the positive charges are moving to the left, and the object still doesn't get affected by any force.&lt;/p&gt;
    &lt;p&gt;Now if we take into account , the moving charges in the wire appear "stretched" due to relativistic effects, causing a change in the distribution of charges. This stretching leads to a repulsive force between the object and the wire, which we interpret as magnetism.&lt;/p&gt;
    &lt;p&gt;Maxwell's equations describe how electric and magnetic fields are created and interact with each other. We will focus on the third and fourth equations.&lt;/p&gt;
    &lt;p&gt;Maxwell's third equation, known as Faraday's law of induction, shows how changing magnetic fields can generate electric currents.&lt;lb/&gt;An example of this is moving a magnet inside a coil, which induces an electric current in the wire due to the changing magnetic field.&lt;/p&gt;
    &lt;p&gt;This is the principle behind electric generators: Mechanical energy (like the flow of steam) is used to move magnets inside coils (a turbine), converting it to electrical energy through electromagnetic induction.&lt;/p&gt;
    &lt;p&gt;By moving the magnet left and right, we can see the voltmeter picking up a current and the electric charges in the coil moving back and forth:&lt;/p&gt;
    &lt;p&gt;Maxwell's fourth and final equation, Ampère's Law, illustrates how electric currents (moving charges) produce magnetic fields around them. This is the basis of how electromagnets function:&lt;/p&gt;
    &lt;p&gt;Together, these laws demonstrate how electric and magnetic fields are interdependent. A changing magnetic field generates an electric field, and a changing electric field generates a magnetic field.&lt;/p&gt;
    &lt;p&gt;This continuous cycle enables self-sustaining, self-propagating electromagnetic waves, which can travel through space without requiring a medium.&lt;/p&gt;
    &lt;p&gt;Electromagnetic radiation consists of waves created by synchronized oscillations of electric and magnetic fields. These waves travel at the speed of light in a vacuum.&lt;/p&gt;
    &lt;p&gt;The amplitude of a wave determines the maximum strength of its electric or magnetic field. It represents the wave's intensity or "brightness". In quantum terms, a higher amplitude corresponds to a greater number of photons.&lt;/p&gt;
    &lt;p&gt;The frequency of a wave determines the energy of the individual photons that compose it. Higher frequencies correspond to shorter wavelengths and more energetic photons.&lt;/p&gt;
    &lt;p&gt;When the wavelength falls between approximately 400 nm and 700 nm, the human eye perceives it as visible light.&lt;/p&gt;
    &lt;p&gt;While other wavelengths are invisible to the human eye, many are quite familiar in everyday life. For example, microwaves are used for Wi-Fi and cooking, X-rays are used in medical imaging, and radio waves enable communication.&lt;/p&gt;
    &lt;p&gt;Some insects, like bees, can see ultraviolet light, which helps them locate flowers by revealing hidden patterns and markings created by specialized pigments, such as flavonoids, that reflect UV wavelengths.&lt;/p&gt;
    &lt;p&gt;On the other end of the spectrum, gamma rays are highly energetic and can be dangerous, they are generated by radioactive decay, nuclear bombs, and space phenomena like supernovas.&lt;/p&gt;
    &lt;p&gt;There are many ways for light to be generated, the two most common ones we encounter everyday are incandescence and electroluminescence.&lt;/p&gt;
    &lt;p&gt;Incandescence is the process by which a material emits visible light due to high temperature. It is how incandescent lightbulbs and the sun generates light.&lt;/p&gt;
    &lt;p&gt;An incandescent lightbulb produces light through the heating of a filament until it starts glowing. The filament is made of tungsten, an element with a high melting point, high durability, and a positive temperature coefficient of resistance, which means its resistance increases with temperature.&lt;/p&gt;
    &lt;p&gt;When we increase the current flowing through the filament, it starts heating up (Due to Joule heating), which increases the resistance in turn causing more heat to get dissipated. This feedback loop stabilizes at around 2500°C.&lt;/p&gt;
    &lt;p&gt;This heat makes the electrons in the filament wiggle and collide with each other, releasing photons in the process. This radiation can be approximated as Black-body radiation.&lt;/p&gt;
    &lt;p&gt;The Sun also generates light by incandescence, but unlike the lightbulb's filament glowing via Joule heating, the Sun’s energy is produced by nuclear fusion in the core, where hydrogen nuclei fuse to form helium and release photons as gamma rays.&lt;/p&gt;
    &lt;p&gt;These photons travel from the core through the radiative zone, getting absorbed and remitted countless times while shifting to longer wavelengths. After hundreds of thousands of years of bouncing around, the photons make it to the surface of the Sun, called the photosphere, where they get radiated away.&lt;/p&gt;
    &lt;p&gt;Most (~49%) of the sun's emissions are in infrared, which is responsible for the heat we get on Earth, ~43% is visible light and the ~8% left is ultraviolet.&lt;/p&gt;
    &lt;p&gt;An interesting fact is that illustrations of the Sun's cross-section typically depict the interior with bright orange or yellow colors. However, if we could actually see a cross-section of the Sun, even the hottest regions like the core would appear dark and opaque, because the radiation generated there isn't in the visible spectrum.&lt;/p&gt;
    &lt;p&gt;Another way to generate light is by electroluminescence, this is the phenomenon that powers LEDs&lt;/p&gt;
    &lt;p&gt;The main component of a light-emitting diode is a semiconductor chip. Semiconductors are materials whose electrical conductivity can be modified by mixing them with impurities in a process known as doping.&lt;/p&gt;
    &lt;p&gt;Depending on the type of impurity (called the dopant) used in the mix, the semiconductor can be turned into either an n-type, which has extra electrons freely moving around, or a p-type, which has a lack of electrons and instead carrying an electron "hole", also moving around and acting as a positive charge.&lt;/p&gt;
    &lt;p&gt;When you stick a p-type and an n-type semiconductor side by side, they form a p-n junction. When a current flows through the junction, the electrons and the holes recombine and emit photons in the process.&lt;/p&gt;
    &lt;p&gt;Aside from incandescence and electroluminescence, which are the two most common sources of light we encounter in everyday life, light can come from other places. Some materials glow when exposed to ultraviolet radiation, others absorb that radiation and re-emit it after some time. Some animals like fireflies use special enzymes to produce light. You can read this page to learn more about other sources of luminescence.&lt;/p&gt;
    &lt;p&gt;In the previous chapter, we examined the nature of light and the various methods by which it can be emitted, we will now focus on how it interacts with matter.&lt;/p&gt;
    &lt;p&gt;When a photon hits a material, it interacts with the electrons in the atoms and molecules of that material, then two things can happen, it can either be absorbed or scattered.&lt;/p&gt;
    &lt;p&gt;The electrons occupy atomic orbitals: regions around the nucleus of the atom where an electron is most likely to be found. A higher orbital corresponds to a higher energy level of the electron.&lt;/p&gt;
    &lt;p&gt;If the photon has the energy needed to excite the electron to a higher energy level, the photon can be absorbed. Eventually the electron returns to a lower level and releases the energy as heat.&lt;/p&gt;
    &lt;p&gt;If the photon does not get absorbed, its electric field will make the electrons oscillate in return and generate secondary waves that interfere constructively and destructively with the photon waves in complicated ways.&lt;/p&gt;
    &lt;p&gt;We can simplify these complicated interactions by making a few assumptions about the material:&lt;/p&gt;
    &lt;p&gt;We can use Maxwell's equations to show that such a perfect flat material splits the incoming light waves into two parts: reflected and refracted.&lt;/p&gt;
    &lt;p&gt;The angle of reflection is equal to the angle of incidence relative to the normal of the surface, as per the law of reflection:&lt;/p&gt;
    &lt;p&gt;The angle of refraction is determined by how much slower (or faster) light travels through the material, that speed is defined by the index of refraction, and the angle is calculated using Snell's law:&lt;/p&gt;
    &lt;p&gt;At a and refractive indices light is no longer refracted and seems to disappear.&lt;/p&gt;
    &lt;p&gt;The amount of light that is reflected and refracted is calculated using Fresnel equations.&lt;/p&gt;
    &lt;p&gt;However, computing the full Fresnel equation in real time can be slow, so in 1994 Christophe Schlick came up with an approximation.&lt;/p&gt;
    &lt;p&gt;First we compute the reflectance at zero degrees from the normal:&lt;/p&gt;
    &lt;p&gt;Then we plug in the approximation function for the reflectance:&lt;/p&gt;
    &lt;p&gt;The transmitted (or refracted) light simply becomes:&lt;/p&gt;
    &lt;p&gt;If we try the where the refracted ray disappeared, we can now see it getting reflected back inside the medium, this is called total internal reflection.&lt;/p&gt;
    &lt;p&gt;Total internal reflection gives rise to an interesting phenomenon called Snell's window. If you dive underwater and look up, the light above the surface is refracted through a circular window 96 degrees wide, and everything outside is a reflection of the bottom of the water.&lt;/p&gt;
    &lt;p&gt;This is what it looks underwater:&lt;/p&gt;
    &lt;p&gt;Like we saw earlier, we can explain light reflecting and refracting using different models, depending on the size of the surface irregularities we are considering.&lt;/p&gt;
    &lt;p&gt;For example, wave optics explains light interacting with matter as light waves diffracting on the surface nanogeometry.&lt;/p&gt;
    &lt;p&gt;If we zoom out a bit and use ray optics, we consider light as straight line rays that reflect and refract on the surface microgeometry. With this model we can use the optical laws we described earlier: law of reflection, Snell's law, Fresnel equations.&lt;/p&gt;
    &lt;p&gt;Now for rendering, we can zoom out even further and consider one pixel at a time, each pixel contains many microgeometry surfaces that we call a microfacet. We can use a statistical average of the microfacets in a pixel to simulate the appearance of the surface at that pixel, without considering each individual microfacet which would be unfeasible in real time.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Size&lt;/cell&gt;
        &lt;cell role="head"&gt;Model&lt;/cell&gt;
        &lt;cell role="head"&gt;Phenomenon&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Nanogeometry&lt;/cell&gt;
        &lt;cell&gt;Wave optics&lt;/cell&gt;
        &lt;cell&gt;Light diffraction&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Microgeometry&lt;/cell&gt;
        &lt;cell&gt;Ray optics&lt;/cell&gt;
        &lt;cell&gt;Reflection/refraction, change in local normal&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Macrogeometry&lt;/cell&gt;
        &lt;cell&gt;BRDF&lt;/cell&gt;
        &lt;cell&gt;Statistical average over a pixel, wider cone -&amp;gt; more roughness&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Here we can see a microgeometry surface, changing the roughness makes it more bumpy and the microfacets normals aren't aligned anymore:&lt;/p&gt;
    &lt;p&gt;At the macrogeometry level, a bigger roughness value means light rays have a wider cone where they can spread out. The function that describes this cone is called bidirectional reflectance distribution function, we will discuss it in the next chapter.&lt;/p&gt;
    &lt;p&gt;In our microfacet model, we distinguish two types of materials by the nature of their interaction with light: metals and non-metals.&lt;/p&gt;
    &lt;p&gt;Metals have a sea of free electrons that absorb light very easily when the photons enter a few nanometers deep inside the surface. The light that isn't absorbed is reflected equally across the visible light spectrum, this is why metals have that distinct "silvery" gray color.&lt;/p&gt;
    &lt;p&gt;Notable exceptions are gold, copper, osmium and caesium.&lt;/p&gt;
    &lt;p&gt;Changing the roughness of a metal only changes its specular reflection, making it more or less mirror-like. But there is no diffuse reflection at all.&lt;/p&gt;
    &lt;p&gt;Also called dielectrics, these are materials that do not conduct electricity (insulators). They include plastic, wood, glass, water, diamond, air...&lt;/p&gt;
    &lt;p&gt;When a photon hits a dielectric material, it only gets absorbed if it's energy matches the electron's energy in the material. So light either gets reflected, and the specular reflection depends on the roughness of the surface.&lt;/p&gt;
    &lt;p&gt;The light can also get refracted inside the dielectric material, it bounces around and interacts with the pigments inside the material until it exits the surface, this is called diffuse reflection.&lt;/p&gt;
    &lt;p&gt;If we take the example of a red apple. When we shine a white light (which contains all visible wavelengths) on it, the apple's pigments (anthocyanins) absorb most of the wavelengths like violet, blue and green wavelengths, thus decreasing the intensity of those colors from the light. The remaining wavelengths, mostly red, gets scattered off the apple's surface making us perceive the apple as red.&lt;/p&gt;
    &lt;p&gt;We can characterize the incoming light by describing the amount of energy it carries at each wavelength using a function called the Spectral Power Distribution or SPD for short.&lt;/p&gt;
    &lt;p&gt;For example, below is the SPD for D65, a theoretical source of light standardized by The International Commission on Illumination (CIE). It represents the spectrum of average midday light in Western Europe or North America:&lt;/p&gt;
    &lt;p&gt;We can compare this SPD to AM0, which is the measured solar radiation in outer space before entering Earth's atmosphere. Notice the absence of a dip in the ultraviolet range:&lt;/p&gt;
    &lt;p&gt;And here is the SPD of a typical tungsten incandescent light:&lt;/p&gt;
    &lt;p&gt;The SPD shows us how much of each "color" a light is composed of. Another interesting function we can look at is called the spectral reflectance curve, which shows the fraction of incident light reflected by an object at each wavelength, effectivly representing the color of said object.&lt;/p&gt;
    &lt;p&gt;Going back to our apple example, since it reflects most of its light in the red wavelength, its spectral reflectance curve might look like this:&lt;/p&gt;
    &lt;p&gt;The light we see is the combination of the light spectral power distribution with the object spectral reflectance.&lt;/p&gt;
    &lt;p&gt;If we shine a light on our red apple, depending on the wavelengths of the light, the final color we see changes. A makes the apple appear red, because it's like multiplying the apple's color by one. We get the same result with a , because the apple reflects mostly in the red spectrum.&lt;lb/&gt;However if we shine a , besides the leaf, the rest of the apple doesn't reflect any light, thus appearing black.&lt;/p&gt;
    &lt;p&gt;On the top right you can see the SPD of the flashlight, under it the reflectance curve of the apple, and the resulting reflected light below it:&lt;/p&gt;
    &lt;p&gt;If we now add a banana and shine a , we can obviously tell the apple and the banana apart, one being red while the other is yellow.&lt;lb/&gt;But what happens when the light is ? Both objects appear reddish to our eyes, because the banana doesn't have any green light to reflect, making it lose its yellow color. This phenomenon is called metamerism.&lt;/p&gt;
    &lt;p&gt;You can display the or the :&lt;/p&gt;
    &lt;p&gt;There are different types of metamerism, depending on when it happens during the light transport process. The apple and banana example is called illuminant metamerism, where objects that reflect light differently appear the same under some specific illumination.&lt;/p&gt;
    &lt;p&gt;Observer metamerism is when objects appear different between observers, a good example of this is colorblindness.&lt;/p&gt;
    &lt;p&gt;The rendering equation gives us the light reflected towards a direction at a point by summing all the incoming lights at that point coming from direction in the hemisphere , weighted by the BRDF at that point and the cosine term.&lt;/p&gt;
    &lt;p&gt;Let's peel off this equation step by step, starting with the easiest part:&lt;/p&gt;
    &lt;p&gt;When a beam of light hits a surface, the area it touches is inversly proportional to the cosine of the angle of incidence. When the angle of incidence is , the area is at minimum and the intensity is concentrated, but the more the angle gets, the larger the area and the intensity gets spread out.&lt;/p&gt;
    &lt;p&gt;The BRDF is arguably the most important part of the rendering equation, it characterizes the surface of our material and its appearance. This is where the we can apply the microfacet theory and energy conservation to make our rendering model physically based.&lt;/p&gt;
    &lt;p&gt;It takes as input the incoming and outgoing light direction, and the roughness of the surface . It equals the diffuse and the specular components weighted by their respective coefficients and .&lt;/p&gt;
    &lt;p&gt;There are many different BRDFs, the most common in realtime rendering is the Cook-Torrance specular microfacet model combined with Lambertian diffuse model.&lt;/p&gt;
    &lt;p&gt;The lambertian diffuse component is the diffuse color, called albedo, multiplied by the cosine factor. But since we already have the cosine factor in the rendering equation, the diffuse equation becomes:&lt;/p&gt;
    &lt;p&gt;The Cook-Torrance specular component itself has three components: the normal distribution function , the geometric function and the Fresnel equation .&lt;/p&gt;
    &lt;p&gt;The normal distribution function is an approximation of the number of microfacets oriented in such a way that they will reflect light from the incoming direction to the outgoing direction .&lt;/p&gt;
    &lt;p&gt;The one we will use is the Trowbridge-Reitz GGX function:&lt;/p&gt;
    &lt;p&gt;is the halfway vector between the incoming and outgoing directions, we calculate it like this:&lt;/p&gt;
    &lt;p&gt;Some incoming rays get occluded by some microfacets before they get a chance to bounce off to the outgoing direction, this is called shadowing. Other rays get occluded by microfacets on their way to the outgoing direction, this is called masking. The geometric function approximates this effect.&lt;/p&gt;
    &lt;p&gt;Here we can see the shadowed rays in red and the masked rays in blue. The yellow rays succesfully reflected to the outgoing direction:&lt;/p&gt;
    &lt;p&gt;We will use the Schlick-GGX geometric function:&lt;/p&gt;
    &lt;p&gt;Where:&lt;/p&gt;
    &lt;p&gt;Like we discussed in the previous chapter, we will use the Fresnel-Schlick approximation which is fast for realtime rendering and accurate enough:&lt;/p&gt;
    &lt;p&gt;Now we can combine the diffuse and specular components to get our final PBR render:&lt;/p&gt;
    &lt;p&gt;Here is a grid of spheres with different roughness and metallic values on each axis:&lt;/p&gt;
    &lt;p&gt;Usually the metallic values is either 0 or 1, but it is useful in PBR rendering to consider intermediate values to smoothly interpolate between metals and non-metals. Take this rusted metal material for example:&lt;/p&gt;
    &lt;p&gt;Physically based rendering is a very vast topic and there is a lot more to cover.&lt;/p&gt;
    &lt;p&gt;In the chapter about the physics of light, I omitted the quantum explanation of light's behaviour using probability amplitudes. We didn't talk about the double slit experiment or the wave-particle duality. I may cover this in the future when I learn more about it, for now I'll leave you with this quote from Richard Feynman's QED book:&lt;/p&gt;
    &lt;quote&gt;The theory of quantum electrodynamics describes Nature as absurd from the point of view of common sense. And it agrees fully with experiment. So I hope you accept Nature as She is — absurd.&lt;/quote&gt;
    &lt;p&gt;We didn't talk about polarization and assumed all our light sources are unpolarized, this isn't very important for general rendering but can be useful for research.&lt;/p&gt;
    &lt;p&gt;We focused on surface rendering, in the future I will cover volume rendering, subsurface scattering, effects like optical dispersion, thin-film interference/iridescence...etc&lt;/p&gt;
    &lt;p&gt;There are a lot more implementation specific details. Whether we are implementing PBR in raytracing or rasterization, we need to use optimization techniques to make the rendering faster while still being accurate. Examples that come to mind are prefiltred envmaps and importance sampling (or efficient sampling in general).&lt;/p&gt;
    &lt;p&gt;This article is mainly based on this SIGGRAPH talk by Naty Hoffman and Physically Based Rendering: From Theory To Implementation&lt;/p&gt;
    &lt;p&gt;My main inspiration for writing interactive articles is this fantastic blog by Bartosz Ciechanowski. A lot of interactive demos in this article are similar to the ones in this post.&lt;/p&gt;
    &lt;p&gt;Other resources include LearnOpenGL, the ScienceClic youtube channel, and 3Blue1Brown of course.&lt;/p&gt;
    &lt;p&gt;I can't recommend enough the famous book QED: The Strange Theory of Light and Matter by Richard Feynman.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45106846</guid></item><item><title>ICE obtains access to Israeli-made spyware that hack phones and encrypted apps</title><link>https://www.theguardian.com/us-news/2025/sep/02/trump-immigration-ice-israeli-spyware</link><description>&lt;doc fingerprint="95984d1905a1b19f"&gt;
  &lt;main&gt;
    &lt;p&gt;US immigration agents will have access to one of the world’s most sophisticated hacking tools after a decision by the Trump administration to move ahead with a contract with Paragon Solutions, a company founded in Israel which makes spyware that can be used to hack into any mobile phone – including encrypted applications.&lt;/p&gt;
    &lt;p&gt;The Department of Homeland Security first entered into a contract with Paragon, now owned by a US firm, in late 2024, under the Biden administration. But the $2m contract was put on hold pending a compliance review to make sure it adhered to an executive order that restricts the US government’s use of spyware, Wired reported at the time.&lt;/p&gt;
    &lt;p&gt;That pause has now been lifted, according to public procurement documents, which list US Immigration and Customs Enforcement (Ice) as the contracting agency.&lt;/p&gt;
    &lt;p&gt;It means that one of the most powerful stealth cyberweapons ever created – which was produced outside the US – is now in the hands of an agency that has repeatedly been accused by civil and human rights groups of violating people’s due process rights.&lt;/p&gt;
    &lt;p&gt;The story was first reported by the journalist Jack Poulson on his All-Source Intelligence Substack newsletter.&lt;/p&gt;
    &lt;p&gt;Neither Paragon nor Ice immediately responded to a request for comment.&lt;/p&gt;
    &lt;p&gt;When it is successfully deployed against a target, the hacking software – called Graphite – can hack into any phone. By essentially taking control of the mobile phone, the user – in this case, Ice – can not only track an individual’s whereabouts, read their messages, look at their photographs, but it can also open and read information held on encrypted applications, like WhatsApp or Signal. Spyware like Graphite can also be used as a listening device, through the manipulation of the phone’s recorder.&lt;/p&gt;
    &lt;p&gt;An executive order signed by the Biden administration sought to establish some guardrails around the US government’s use of spyware. It said that the US “shall not make operational use of commercial spyware that poses significant counterintelligence or security risks to the United States government or significant risks of improper use by a foreign government or foreign person”. The Biden administration also took the extraordinary step of placing one of Paragon’s rival spyware makers, NSO Group, on a commerce department blacklist, saying the company had knowingly supplied foreign governments to “maliciously target” the phones of dissidents, human rights activists and journalists.&lt;/p&gt;
    &lt;p&gt;Paragon has sought to differentiate itself from NSO Group. It has said that, unlike NSO – which previously sold its spyware to Saudi Arabia and other regimes – that it only does business with democracies. It has also said it has a no tolerance policy and will cut off government clients who use the spyware to target members of civil society, such as journalists. Paragon refuses to disclose who its clients are and has said it does not have insight into how its clients use the technology against targets.&lt;/p&gt;
    &lt;p&gt;Spyware makers like Paragon and NSO have said their products are intended to be used to prevent crime and terrorist attacks. But both companies’ software has been used in the past to target innocent people, including individuals who have been perceived to be government enemies.&lt;/p&gt;
    &lt;p&gt;John Scott-Railton, a senior research at the Citizen Lab at the University of Toronto, who is one of the world’s leading experts on cases in which spyware like Graphite has been abused by governments, said in a statement that such tools “were designed for dictatorships, not democracies built on liberty and protection of individual rights”.&lt;/p&gt;
    &lt;p&gt;“Invasive, secret hacking power is corrupting. That’s why there’s a growing pile of spyware scandals in democracies, including with Paragon’s Graphite,” he said, referring to a controversy in Italy that erupted late last year.&lt;/p&gt;
    &lt;p&gt;Paragon broke off its ties to Italy after it was revealed that 90 people, including journalists and members of civil society, in two dozen countries, had been targeted with the spyware. The individuals who were targeted by the Italian government included human rights activists who have been critical of Italy’s dealings with Libya. Several journalists were also targeted, though it is still unclear who ordered those hacking attacks.&lt;/p&gt;
    &lt;p&gt;The US government has in the past resisted using spyware technology made outside the US because of concerns that any company that sells technology to multiple government agencies around the world represents a potential security risk.&lt;/p&gt;
    &lt;p&gt;“As long as the same mercenary spyware tech is going to multiple governments, there is a baked-in counterintelligence risk. Since all of them now know what secret surveillance tech the US is using, and would have special insights on how to detect it and track what the US is doing with it,” Scott-Railton said. “Short of Paragon cancelling all foreign contracts, I’m not sure how this goes away.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45106903</guid></item><item><title>Vijaye Raji to become CTO of Applications with acquisition of Statsig</title><link>https://openai.com/index/vijaye-raji-to-become-cto-of-applications-with-acquisition-of-statsig/</link><description>&lt;doc fingerprint="f974305d9fc3edac"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Vijaye Raji to become CTO of Applications with acquisition of Statsig&lt;/head&gt;
    &lt;p&gt;We’re expanding our Applications leadership, the org responsible for how our research reaches and benefits the world.&lt;/p&gt;
    &lt;p&gt;As we scale ChatGPT and build new applications to serve hundreds of millions of people and businesses around the world, our ambition is to push the frontier of AI research and turn it into intuitive, safe, and useful tools that people love. That takes strong engineering systems, fast iteration, and a long-term focus on quality and reliability.&lt;/p&gt;
    &lt;p&gt;Vijaye Raji will step into a new role as CTO of Applications, reporting to Fidji Simo, following the acquisition of Statsig. As a hands-on builder and trusted leader, Vijaye will head product engineering for ChatGPT and Codex, with responsibilities that span core systems and product lines including infrastructure and Integrity. His experience as founder and CEO of Statsig, and a decade leading large-scale consumer engineering at Meta, brings both entrepreneurial vision and operating expertise to scale our next generation of products.&lt;/p&gt;
    &lt;p&gt;“Vijaye has a remarkable record of building new consumer and B2B products and systems at scale. He’s joining at a time when our models are opening entirely new ways to build, and his leadership will help turn that progress into safe applications that empower people with many new tools to improve their lives, help companies increase their impact and allow developers to build faster and better products.”&lt;/p&gt;
    &lt;p&gt;—Fidji Simo, CEO of Applications, OpenAI&lt;/p&gt;
    &lt;p&gt;As part of this transition, we’re acquiring Statsig, one of the most trusted experimentation platforms in the industry—powering A/B testing, feature flagging, and real-time decisioning for some of the world’s most innovative companies, including OpenAI.&lt;/p&gt;
    &lt;p&gt;Vijaye and his team founded Statsig on the belief that the best products come from rapid experimentation, tight feedback loops, and data-informed decision-making.&lt;/p&gt;
    &lt;p&gt;The Statsig platform has already played a central role in how we ship and learn quickly. Bringing it in-house will strengthen our ability to accelerate experimentation across our Applications org and build even better, more responsive experiences for the people and businesses we serve.&lt;/p&gt;
    &lt;p&gt;“Joining OpenAI as CTO of Applications is an extraordinary opportunity to bring my experience scaling consumer and enterprise products to a mission I deeply believe in: advancing AI in ways that are capable of solving hard problems, reliable, and truly beneficial to people everywhere. The journey with Statsig has been deeply gratifying, leading me to this moment and giving me conviction that we will continue helping teams ship better software every day.”&lt;/p&gt;
    &lt;p&gt;—Vijaye Raji, incoming CTO of Applications, OpenAI&lt;/p&gt;
    &lt;p&gt;Once the acquisition is finalized, Statsig employees will become OpenAI employees. It will continue operating independently and serving its customer base out of its Seattle office. We’ll take a measured approach to any future integration, ensuring continuity for current customers and enabling the team to stay focused on what they do best.&lt;/p&gt;
    &lt;p&gt;The closing of the acquisition is subject to customary closing conditions, including receipt of regulatory approval.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45106981</guid></item><item><title>A gentle introduction to CP/M</title><link>https://eerielinux.wordpress.com/2025/08/28/a-gentle-introduction-to-cp-m/</link><description>&lt;doc fingerprint="b6e89fd345878b99"&gt;
  &lt;main&gt;
    &lt;p&gt;[New to Gemini? Have a look at my Gemini FAQ.]&lt;/p&gt;
    &lt;p&gt;This article was bi-posted to Gemini and the Web; Gemini version is here: &lt;code&gt;gemini://gemini.circumlunar.space/users/kraileth/neunix/2025/gentle_introduction_cpm.gmi&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;This article is just what the headline promises: an introduction to the CP/M operating system. No previous knowledge of 1970s and early ’80s operating systems is required. However, some familiarity with Linux or a BSD-style operating system is assumed, as the setup process suggested here involves using a package manager and command-line tools. But why explore CP/M in the 2020s? There are (at least) two good reasons: 1) historical education 2) gaining a better understanding of how computers actually work.&lt;/p&gt;
    &lt;p&gt;Last year I wrote two articles about CP/M after having taken a first look at it:&lt;/p&gt;
    &lt;p&gt;A journey into the 8-Bit microcomputing past: Exploring the CP/M operating system – part 1&lt;lb/&gt; A journey into the 8-Bit microcomputing past: Exploring the CP/M operating system – part 2&lt;/p&gt;
    &lt;p&gt;These were written with a focus on the first reason; I had (partially) read the manuals and tried out a few commands in an emulator (as well as done a little bit of research). I wrote an outsider’s look at CP/M and covered the various versions that were released and some of their notable features.&lt;/p&gt;
    &lt;p&gt;This article is different. It’s for readers who want to get started with CP/M themselves. Expect a practical introduction to get familiar enough with the platform to be able to explore a wealth of historic software, often enough ground-breaking and influential.&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting Ready (Installing an Emulator)&lt;/head&gt;
    &lt;p&gt;Last time I had tried out a couple of Z80 emulators and found Udo Munk’s z80pack to be the one I liked best. It’s not widely packaged; only FreeBSD includes it, but using the package requires some setup. Other options like YAZE exist, but it’s more work to get the original CP/M working on them whereas z80pack comes with disk images of various CP/M versions.&lt;/p&gt;
    &lt;p&gt;Of course you can compile the emulator and tools yourself. But to simplify the setup process, I’ve created a port for Ravenports, a universal package system for POSIX operating systems. Via Ravenports, the emulator and tools I use here will soon be available as binary packages for the following operating systems (in the future additional platforms might get added):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;DragonFly BSD&lt;/item&gt;
      &lt;item&gt;FreeBSD&lt;/item&gt;
      &lt;item&gt;Linux (glibc-based distributions)&lt;/item&gt;
      &lt;item&gt;MidnightBSD&lt;/item&gt;
      &lt;item&gt;NetBSD&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you’re on one of those systems, you can download, inspect and run this script if you want to go that route. It will bootstrap a secondary package manager on your system, which you can use to install additional software on your machine. Those programs live in a separate portion of the filesystem (i. e. below /raven), which means that they won’t interfere with the native package manager of your platform.&lt;/p&gt;
    &lt;p&gt;The package manager is called ‘rvn’. It supports subpackages and so-called variants which is why the package names look a little complicated at first glance. The z80pack port has no variants, hence only the standard (“std”) is available, but the port is split into three subpackages: “docs”, “images” and “primary”. The first contains documentation, the second one provides the CP/M disk images and the last one is the actual emulator. A special subpackage called “set” can always be used to install all available subpackages of a project.&lt;/p&gt;
    &lt;p&gt;Tilde characters separate the fields of the package name. At the time of this writing, the complete package is ‘z80pack~set~std~1.38’ (base name, subpackage, variant, version). Package names can be shortened as long as they are unambiguous. So to install the complete package, you can run this:&lt;/p&gt;
    &lt;quote&gt;# /raven/sbin/rvn install z80pack~s&lt;/quote&gt;
    &lt;p&gt;This will pull in ‘z80pack~docs~std~1.38’, ‘z80pack~images~std~1.38’ and ‘z80pack~primary~std~1.38’ as well as the required dependencies.&lt;/p&gt;
    &lt;p&gt;You will have to add /raven/bin to your PATH environment variable to be able to use it. Depending on your shell of choice use setenv or export. Most people will want to do this:&lt;/p&gt;
    &lt;quote&gt;% export PATH=/raven/bin:$PATH&lt;/quote&gt;
    &lt;p&gt;When you installed the package, the installation message hints at a utility script that I wrote for the port. Just execute ‘runcpm’ and it will display a little help text to let you know what it does and what other command names it’s available under.&lt;/p&gt;
    &lt;p&gt;The help message from the utility script&lt;/p&gt;
    &lt;p&gt;Running any of these requires the /raven/bin to be in the PATH variable, otherwise they won’t find the actual emulator binary. Of course you can also modify /raven/bin/runcpm accordingly if you prefer that.&lt;/p&gt;
    &lt;head rend="h2"&gt;Running CP/M&lt;/head&gt;
    &lt;p&gt;If you’ve installed the emulator and have your PATH configured, you’re ready to go. You just pick a version from the list that ‘runcpm’ told you about and start the emulator. But which one to try? You can of course try out any of them, but I highly recommend to start with version 2.2 for a couple of reasons. Versions 1.x work but are pretty limited in terms of command-line editing and things like that. They are fascinating relics from an age before monitors were common and when output was usually printed on paper. You can explore them later. Version 3 is more complex (by CP/M standards) and might confuse you. CP/M 2.x is basically “classic” CP/M, a solid but simplistic OS that’s straight-forward to get into. That’s also the version used in this article, so if you want to follow along, just go with 2.2 for now.&lt;/p&gt;
    &lt;p&gt;Now that we’ve chosen a version, let’s start the emulator. So, as your user just issue&lt;/p&gt;
    &lt;quote&gt;% cpm22&lt;/quote&gt;
    &lt;p&gt;and that will turn your terminal into an emulated Z80 system with CP/M 2.2!&lt;/p&gt;
    &lt;p&gt;Emulated CP/M 2.2 booted up and ready&lt;/p&gt;
    &lt;p&gt;On modern systems, the boot process is too short to notice and the system is up instantly. CP/M displays ‘A&amp;gt;’ to let you know that it’s ready to take commands from you. The CCP (Console Command Processor) is the core component of CP/M that handles user interaction like prompting you and executing commands. Think of it as your shell.&lt;/p&gt;
    &lt;p&gt;In their simplest form, commands are just simple words or abbreviations which you type after the prompt symbol and then hit ENTER to execute them. Let’s issue our first command. Try this:&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;cls&lt;/quote&gt;
    &lt;p&gt;What did it do? Right, all the previous messages are gone. And that’s no wonder: CLS is short for “CLear Screen”. The CCP is case insensitive; it doesn’t care if you input “cls”, “CLS” or “cLs” – that’s all the same thing.&lt;/p&gt;
    &lt;p&gt;You can always give empty command lines, if you want a bit of screen space between some output and the next. So pressing ENTER without first typing a command is perfectly acceptable. But let’s try a different command:&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;bye&lt;/quote&gt;
    &lt;p&gt;As you might have guessed from the name, this command is used to quit the emulator and returns you to your standard *nix terminal. It’s not the most interesting command but definitely one you will want to know about. It was added to stop z80-sim and is not part of the original CP/M.&lt;/p&gt;
    &lt;head rend="h2"&gt;Filename Basics&lt;/head&gt;
    &lt;p&gt;With these basics done, we can finally take a look at something more useful. Try this command:&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;dir&lt;/quote&gt;
    &lt;p&gt;DIR is short for “DIRectory” and it lists all the files recorded in the – you guessed it – directory (i. e. all the files present on the drive). CP/M’s filesystem is flat, which means that there’s no folders or subdirectories. All the files on one drive are together in one place. Files are referenced by what CP/M calls a file specification. These consist of up to four pieces of information (on 2.x).&lt;/p&gt;
    &lt;p&gt;Okay, let’s take a look at the output. We’ll ignore the “A:” for the moment. File naming follows a schema known as 8.3. This means that a filename can be 8 characters long, then a dot follows and after that it can have a type of up to three characters. Note: Terminology evolved over time. In older CP/M versions, these were known as the primary and secondary names. Later, during DOS times, they were referred to as the filename and the extension.&lt;/p&gt;
    &lt;p&gt;It’s best to think of the whole thing as the actual name of the file, i. e. the up to 8 characters, the dot, and the type. Only the first character is strictly required, though, so “A” is in fact a perfectly valid filename. Internally, CP/M will fill up the remaining characters with blanks, so this file is represented as an A, 7 spaces, a dot and another 3 spaces. Filenames, just like CCP input, are case-insensitive, too.&lt;/p&gt;
    &lt;p&gt;Other than being mindful of the maximum length, try to stick to letters and numbers for names. Many special characters are allowed, but some are reserved and must not be used. But you cannot just memorize these once: different versions of CP/M reserved a different set of special characters! The full list for CP/M 3 is this: . , ; : = ? * [ ] | ( ) / \ ! &amp;amp; $ + –&lt;/p&gt;
    &lt;p&gt;Some of these are not reserved in earlier versions, but again, don’t get fancy and you’ll stay out of trouble. Other than that, you need to be aware that the part before the dot is up to you entirely whereas the type is meant to hint at what kind of file this is.&lt;/p&gt;
    &lt;p&gt;Now that we understand the filename schema, let’s look at the types of files as the list provided by DIR has them. For example there’s “DUMP.COM” (DIR doesn’t display the dot for some reason), “STAT.COM”, and so on. These are both COM files, which is short for “command” files – and it means that these are executable commands (programs).&lt;/p&gt;
    &lt;p&gt;The other types that you can see here are UTL and HLP. The former are two “util” files; these are special programs that cannot run on their own but can be loaded by CP/M’s debugger program. The other is short for “help” and was chosen because this file contains the help text for the WM program. DIR uses colons to delimit one column of files from the others.&lt;/p&gt;
    &lt;p&gt;Now that you know that the COM files are executable commands, DIR basically gave you a list of what programs are available for you to run. But wait a moment! There’s CLS.COM and BYE.COM – but where’s DIR.COM? Good catch. There’s actually two kinds of commands: those like CLS, which exists as COM file on a drive, and the others like DIR. The first kind are called transient commands, the others are built-ins like your Unix shell’s ‘echo’ command. DIR and a few others are part of the CCP and do not exist as separate programs. (Well, in CP/M 3 DIR.COM does exist, even though the command is a built-in, too! That’s because the transient offers additional functionality over the standard command. But like I said before, CP/M 3 is a little different.)&lt;/p&gt;
    &lt;head rend="h2"&gt;File Specification Basics&lt;/head&gt;
    &lt;p&gt;So far we have only executed programs which serve a pretty simple purpose and can thus work on their own. Time to take the next step. Let’s execute another program:&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;dump&lt;/quote&gt;
    &lt;p&gt;The result is this error message:&lt;/p&gt;
    &lt;quote&gt;NO INPUT FILE PRESENT ON DISK&lt;/quote&gt;
    &lt;p&gt;DUMP is a tool to get a hex dump of a binary file and with the error message it is telling us that it needs an input file but couldn’t find it (in this case because we didn’t specify one!). So we need to give this program a file to operate on. Let’s have the program display a hex representation of itself. We can do that like this:&lt;/p&gt;
    &lt;quote&gt;A&amp;gt; dump dump.com&lt;/quote&gt;
    &lt;p&gt;This time the result looks much more interesting (see screenshot).&lt;/p&gt;
    &lt;p&gt;Output of the DUMP command on itself&lt;/p&gt;
    &lt;p&gt;While admittedly the output is not terribly useful for a user without a programming background, this is still an important achievement. We’ve not just executed another program, we’ve executed it on a specific file. In our little command line, DUMP is the program name like always. However after that (delimited by a space character), we’ve given it the so-called file specification (or filespec for short) to let the program know which file we want a hexadecimal representation of.&lt;/p&gt;
    &lt;p&gt;Now we will take a look at another command, TYPE. Don’t look for TYPE.COM, it’s another built-in. This is a simple command for displaying the contents of files (i. e. “typing it out” to the console). If we run it without a filespec, this happens:&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;type ?&lt;/quote&gt;
    &lt;p&gt;Unlike the more verbose DUMP, this program is fairly minimal in letting you know that you screwed up. The question mark tells you “nope, doesn’t work that way!” and it’s on you to figure out what the problem is. That is, you have to know that TYPE requires a filespec to be able to type out the file’s contents, of course.&lt;/p&gt;
    &lt;p&gt;But why is it so minimal? Well, text strings are wasteful. The long error message that DUMP provides could have been used for several program instructions. And remember, that we are in an emulated environment where the machine has 64 kilobytes (!!) of memory, which is not a lot. To make matters worse, CP/M could run on machines with as little as 16k of RAM (versions 1.x at least). Since TYPE is a built-in and the whole CCP has to stay in memory all the time, putting anything in there that’s not strictly required, means stealing from the precious memory which would then no longer be available for other programs. Always keep in mind the extremely constrained environment that people had to make do with back in the day, and you’ll understand most of the design decisions that seem rather weird from today’s perspective.&lt;/p&gt;
    &lt;p&gt;But since we figured out what we did wrong, let’s try again:&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;type dump.com&lt;/quote&gt;
    &lt;p&gt;This results in the following output:&lt;/p&gt;
    &lt;quote&gt;!9"1W&amp;gt;2!QG}DrYQ|͏}͏#&amp;gt; ex͏#r* e&amp;gt; _&amp;gt; e ҉0Ë7e}} :³ʳ7_&amp;lt;2!~ɯ2|\\FILE DUMP VERSION 1.4$ NO INPUT FILE PRESENT ON DISK$&lt;/quote&gt;
    &lt;p&gt;Most of the file is unreadable garbage and some of it even consists of unprintable characters. This is why you normally use TYPE only for plain-text files and view binary files with DUMP. We can see two text strings here, though, one of which is the error message that we’ve already encountered. Given how short the program is, you can see pretty well how wasteful those text strings are!&lt;/p&gt;
    &lt;p&gt;Some commands take more than one filespec. For example REN (“REName”), another built-in. It allows you to change the name of an existing file to another. One CP/M quirk that you have to be aware of, is that it borrowed the notation from a line of DEC operating systems. It doesn’t copy / rename file 1 TO file 2 as you’re probably used to. Source and destination are inverted, so you copy / rename file 1 FROM file 2.&lt;/p&gt;
    &lt;p&gt;Let’s see what REN does when you give it only one filespec:&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;ren wm.hlp FILE EXISTS&lt;/quote&gt;
    &lt;p&gt;The command took the information that it had, tried to rename the file to itself – and couldn’t do that because, of course, that file’s name is already taken. Here’s how to rename the file to RENAME.TST (new name) from the file WM.HLP (old name):&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;ren rename.tst=wm.hlp&lt;/quote&gt;
    &lt;p&gt;The equals character is required as the separator of the two filespecs. This command line doesn’t output any error, which in this case means that it succeeded. Feel free to check it with DIR, before we revert what we just did:&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;ren wm.hlp=rename.tst&lt;/quote&gt;
    &lt;head rend="h2"&gt;More on Filespecs&lt;/head&gt;
    &lt;p&gt;Some commands like DIR can work both with and without a filespec. We’ve only done the latter so far, so it’s time to give the other option a try:&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;dir dump.com A: DUMP COM&lt;/quote&gt;
    &lt;p&gt;This will make DIR only display the file that we asked for instead of the whole list. What is this form of DIR good for? Just to check whether a specific file exists? No, there’s a much better use for it. But to understand that, we need to know a bit more about file specifications.&lt;/p&gt;
    &lt;p&gt;So far we have only used what CP/M calls unambiguous filespecs aka. unambiguous file references aka. unambiguous filenames (ufn), which refer to one particular file only. That means we’ve always used exact names with our commands so far. CP/M supports two kinds of wildcards, though, the question mark and the asterisk. You can use these to construct ambiguous filespecs aka. ambiguous file references aka. ambiguous filenames (afn) which can potentially match several files.&lt;/p&gt;
    &lt;p&gt;A question mark means any character. For example we could modify the previous command line slightly like this:&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;dir dump.?om A: DUMP COM&lt;/quote&gt;
    &lt;p&gt;The output is the same, because DUMP.COM is the only file in our directory that matched the afs. But let’s assume there were also files such as DUMP.BOM, DUMP.LOM and so on – in that case the afs would match them, too, and DIR would display all of them. You can use multiple wildcards in a filespec, so for example DUM?.C?M would still match our DUMP.COM file but also other possible files like DUMB.CIM and so on.&lt;/p&gt;
    &lt;p&gt;The asterisk is even more powerful; it doesn’t match a single character at that position, but translates to anything. For example *.COM means “any filename as long as the file has a type of COM”. You can use this to have DIR list all the available commands only and filter out any other files:&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;dir *.com&lt;/quote&gt;
    &lt;p&gt;This will produce a list where our two UTL files and the HLP file are missing. You can also use something like A*.* to list all the files that begin with the letter A.&lt;/p&gt;
    &lt;p&gt;Combining these wildcards, you can do some pretty advanced but useful name matching. Think for a moment about what this example matches: ??G*.C* – it matches all files which have a filename of three or more characters where the third one is a G and which has a filetype that starts with C.&lt;/p&gt;
    &lt;p&gt;By the way, when you run DIR without any filespec, that’s the same as if you run DIR *.* – for the DIR command the universal filespec is the default.&lt;/p&gt;
    &lt;p&gt;Alright! Now for the last thing that you need to know about filespecs: they can consist of a third component in addition to the filename and type. Run these two commands and compare the output:&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;dir A&amp;gt;dir a:&lt;/quote&gt;
    &lt;p&gt;Hey, there’s the a: finally. And yes, the output is identical. Try another one, before we talk about what this does:&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;dir a:*.*&lt;/quote&gt;
    &lt;p&gt;It’s exactly the same again! Okay, let’s take one step back and take a look at the prompt that we see all the time: A&amp;gt;. With the greater than character, the CCP tells you that it’s ready to let you input a command. But what’s the A all about? It refers to what CP/M calls the logged-on disk. It let’s you know that disk drive A is the one it will assume commands refer to unless told otherwise.&lt;/p&gt;
    &lt;p&gt;And that’s what we did with the A: – we requested DIR to list the files on drive A. Since that’s implicitly assumed when we don’t state it, it didn’t make any difference. And the universal filespec (*.*) is the implicit default for DIR, so in our case all of these were identical.&lt;/p&gt;
    &lt;p&gt;So let’s try out accessing a different disk for the first time, shall we? CP/M 2.2 as it is provided by z80pack consists of two disks, so we have a drive B, too. How about taking a look at which additional programs are on there? We can do that like this:&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;dir b:*.com&lt;/quote&gt;
    &lt;p&gt;Here’s the output:&lt;/p&gt;
    &lt;quote&gt;B: CLS COM : BYE COM : SPEED COM : SURVEY COM B: R COM : RESET COM : W COM&lt;/quote&gt;
    &lt;p&gt;As you can see, for convenience, there’s CLS.COM and BYE.COM on there, too, but also some additional programs that we haven’t seen, yet.&lt;/p&gt;
    &lt;head rend="h2"&gt;Drives&lt;/head&gt;
    &lt;p&gt;Since we’re on the matter, anyways, let’s talk about drives next. A useful command that we haven’t used, yet, is STAT (from STATus). You can use it to find out how much space remains on a certain disk. Let’s check that for both drives:&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;stat a: Bytes Remaining On A: 11k&lt;/quote&gt;
    &lt;quote&gt;A&amp;gt;stat b: Bytes Remaining On B: 168k&lt;/quote&gt;
    &lt;p&gt;Seems like drive A is somewhat short on space while on B there’s still a lot of room for additional files. If we want to examine the programs on drive B, for example R.COM, we can do this:&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;dump b:r.com&lt;/quote&gt;
    &lt;p&gt;However it’s a bit annoying to always have to use the full filespec including the drive, right? And that’s why the logged-on drive can be changed. We want to do some work mostly on drive B next, so let’s do that. It’s as easy as this:&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;B:&lt;/quote&gt;
    &lt;p&gt;This will change the prompt to B&amp;gt; to let you know that now drive B is the default disk. If you for example run DIR without a filespec now, you’ll get a list of files on that drive until you change back. Let’s try to get a hex dump of one of the other programs on this drive:&lt;/p&gt;
    &lt;quote&gt;B&amp;gt;dump w.com DUMP?&lt;/quote&gt;
    &lt;p&gt;Huh? What’s this? Well, the CCP let’s you know that it has no idea what you’re talking about. Remember that unlike DIR the DUMP command is a transient. It’s on drive A and it was readily available so far because that drive was the logged-on default. Now we’re on drive B and there is no DUMP.COM there! So to get the hex dump that we were looking for, we can do this:&lt;/p&gt;
    &lt;quote&gt;B&amp;gt;a:dump w.com&lt;/quote&gt;
    &lt;p&gt;That works! But while we don’t have to include B: for the filespec anymore, now we have to include A: to run the command… So we have merely traded one little headache for another. But there’s a solution to this, of course! Let’s take a look at STAT again. It is not only able to tell you about the remaining space on a disk, it can also give you information about a file. Let’s use it to take a look at DUMP.COM on drive A:&lt;/p&gt;
    &lt;quote&gt;B&amp;gt;a:stat a:dump.com Recs Bytes Ext Acc 3 1k 1 R/W A:DUMP.COM Bytes Remaining On A: 11k&lt;/quote&gt;
    &lt;p&gt;Okay, looks like the file takes up 3 records in the filesystem which is equivalent to a size of 1k. That’s a fairly small program and we have more than enough space to simply copy it over to drive B. That’s what we will use PIP (from “Peripheral Interchange Program”) for. Remember the syntax of REN? For PIP it’s similar and unlike REN it can actually copy files rather than renaming them and supports doing so across different devices as well. Here’s how we copy over DUMP.COM from drive A:&lt;/p&gt;
    &lt;quote&gt;B&amp;gt;a:pip b:dump.com=a:dump.com&lt;/quote&gt;
    &lt;p&gt;Think about this command line for a second. Do you see which part of a filespec is unnecessary? Exactly, since we have drive B logged-on, we could also have used A:PIP DUMP.COM=A:DUMP.COM instead for the same result. Check with DIR whether the file was copied over if you wish. Now we can simply run the program from the current disk which is much more convenient:&lt;/p&gt;
    &lt;quote&gt;B&amp;gt;dump w.com&lt;/quote&gt;
    &lt;p&gt;Great! Now let’s assume we’re done with exploring programs with DUMP and are eventually running out of space. We need to clean up now and then. Removing files is what the ERA (from “ERAse”) command is good at. To get rid of our additional DUMP.COM on the current drive, we can issue the following commands:&lt;/p&gt;
    &lt;quote&gt;B&amp;gt;dir dump.com B: DUMP COM B&amp;gt;era dump.com B&amp;gt;dir dump.com NO FILE&lt;/quote&gt;
    &lt;p&gt;That’s 1k of space reclaimed. It may not sound like much, but as we all know, even small files do add up. Oh, and you cannot only run out of space on a drive. You can also run out directory entries! CP/M 2.2 supports up to 64 files on any drive, which is a lot of files, but at the same time not an exceptionally high limit, either.&lt;/p&gt;
    &lt;head rend="h2"&gt;Control Characters&lt;/head&gt;
    &lt;p&gt;Let’s change the logged-on drive back to A now:&lt;/p&gt;
    &lt;quote&gt;B&amp;gt;a:&lt;/quote&gt;
    &lt;p&gt;Next we’re going to use STAT again but on its own rather than on a drive or a file:&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;stat A: R/W, Space: 11k B: R/W, Space: 168k&lt;/quote&gt;
    &lt;p&gt;This is pretty useful for getting a quick overview. Keep in mind, though, that it will only display information about drives that you have accessed in your current session! If you use STAT the next time after you just started the emulator, it won’t know about drive B, yet. Now let’s do something stupid and try to list files on a non-existing drive:&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;dir c: Bdos Err On C: Bad Sector&lt;/quote&gt;
    &lt;p&gt;BDOS (or Basic Disk Operating System) is the OS component responsible for disks and filesystems. And it rightfully complains that there’s an error on drive C. You cannot simply acknowledge the error or something; if you press ENTER, the error is simply repeated. The system is in a state from which it cannot recover.&lt;/p&gt;
    &lt;p&gt;What you have to do in this case is sending the ^C control character (press CTRL-C to produce it). This will make CP/M perform a warm start and you get the CCP prompt back. Never try to change the logged-on drive to a none-existing one, though! In that case a warm start is not enough and you will have to kill the emulator from your host system. Historically warm starts were also required if you physically changed the diskette in a drive.&lt;/p&gt;
    &lt;p&gt;There’s a couple of other control sequences that are useful to know about. For example if you typed a longer command line and change your mind (or mistyped something right at the beginning), it is useful to press CTRL-U which invalidates the current command line. You can simply press ENTER afterwards and the CCP will ignore what you typed. CP/M 2.x supports a more useful control character, though, CTRL-X, which will simply erase the current command line, allowing you to try again right away.&lt;/p&gt;
    &lt;p&gt;If you are for example using TYPE to display a longer text file, the contents will rush by on the screen. In case you’re interested not in the end of the file but in some section in the middle, you’re supposed to press CTRL-S to suspend further printing until another key is pressed. This may have worked back in the day (and you can probably still use it if you configure the emulator to run at a slower speed), but it’s not a particularly great mechanic for today.&lt;/p&gt;
    &lt;p&gt;CTRL-Z means end-of-input. It’s not used on the command line but some programs like the editor ED make use of it.&lt;/p&gt;
    &lt;p&gt;There’s a few more, but the last one that I want to cover is CTRL-E. Sending this control character causes a carriage return without executing the command line. This is useful if you have to enter a very long command line which won’t fit on a single line. Now this might surprise you since so far all of our command lines have been rather short. But they don’t necessarily have to be! For example, PIP can be used to concatenate multiple files into one. If you’ve got a lot of long filenames, the resulting command line might run over the terminal width.&lt;/p&gt;
    &lt;head rend="h2"&gt;Other Things to be Aware of&lt;/head&gt;
    &lt;p&gt;We’ve already covered a bit of ground here and you should have a good idea of basic CP/M usage that you can build upon. But while the known unknowns can be annoying, it’s usually the unknown unknowns that actually bite you. So let’s at least convert some of the latter to the former, shall we?&lt;/p&gt;
    &lt;p&gt;CP/M 2.x supports 16 so-called user areas, which can be used to organize files, so in a way the previously made statement about the filesystem being flat with all files in one location is not entirely correct. It’s good to know that they exist, but by default only user area 0 is being used and that’s what you may want to stick with.&lt;/p&gt;
    &lt;p&gt;What is typed after a command name is called a command trail in CP/M lingo. We’ve only used filespecs here, but there’s another thing: parameters. These don’t refer to files but modify the behavior of the command. Unfortunately, they are not standardized! For example, STAT uses dollar notation and PIP expects parameters in square brackets. Here’s a few examples:&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;stat b:speed.c $R/O&lt;/quote&gt;
    &lt;p&gt;This instructs STAT to set the read-only flag for the file instead of displaying file information. STAT also accepts a few special keywords, too, like DSK: which will make it display detailed disk information (see screenshot).&lt;/p&gt;
    &lt;p&gt;Output of the STAT command displaying disk information&lt;/p&gt;
    &lt;p&gt;The trouble with PIP is that it can only copy things FROM a different user area and not TO one. This means that when you switch the user area, you need to have PIP available there to copy something else over. But how do you do that without PIP? Well, first you need to load the program into memory. The debugger DDT can do that for us, but then instead of actually debugging it, we’re leaving the application by issuing “G0” at its dash prompt.&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;ddt pip.com DDT VERS 2.2 NEXT PC 1E00 0100 -g0&lt;/quote&gt;
    &lt;p&gt;PIP is now loaded into RAM, and DDT was nice enough to tell us that the next free memory address is 1E00, which in turn means that PIP occupies 1C memory pages. Converted to decimal, that’s 29 pages. Knowing that, we can change to another user area, e. g. number 8 using the USER build-in:&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;user 8 A&amp;gt;dir NO FILE&lt;/quote&gt;
    &lt;p&gt;As you can see, it’s empty. Now we can use the build-in command SAVE to write the contents of the 29 memory pages into a file:&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;save 29 pip.com A&amp;gt;dir A: PIP COM&lt;/quote&gt;
    &lt;p&gt;Here’s the result: we have PIP! Which means we can use it to copy over another file to this user area, using the G parameter for PIP with user area number 0 from where we want to copy it:&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;pip stat.com=stat.com[g0] DISK WRITE ERROR: =STAT.COM[G0]&lt;/quote&gt;
    &lt;p&gt;Oops. Or rather, we can’t. Got any guesses why that is?&lt;/p&gt;
    &lt;quote&gt;A&amp;gt;user 0 A&amp;gt;stat stat.com Recs Bytes Ext Acc 40 5k 1 R/W A:STAT.COM Bytes Remaining On A: 3k&lt;/quote&gt;
    &lt;p&gt;Of course! The STAT program we wanted to copy over is 5k in size, but the drive has only 3k left…&lt;/p&gt;
    &lt;p&gt;Having seen these limitations, you probably understand why I suggest not bothering with user areas as you’re getting started with CP/M. I wanted to at least touch on them, though, so you don’t get the feeling that you’re missing out!&lt;/p&gt;
    &lt;p&gt;Another thing that you should know exists are devices. CP/M reserves some three-letter abbreviations for device names. If you ever wondered, why to this day you cannot create a file called CON in Windows, that’s because it’s CP/M’s reserved device name for the console. PUN is for a paper punch, RDR is a paper tape reader, LST is for a printer and so on. You could use STAT to switch input or output to different devices and PIP supports them, too. This allowed you to read files from the RDR or print a file by copying it to LST.&lt;/p&gt;
    &lt;p&gt;With this information you should be good to generally find your way around in CP/M. You cannot really do much with it, yet, but we’ll take care of that another time. Tune in again if you like.&lt;/p&gt;
    &lt;head rend="h2"&gt;What’s next?&lt;/head&gt;
    &lt;p&gt;I haven’t decided whether I’ll write another CP/M article next (it would make sense, though) or if it will be something else. In autumn, I definitely want to get back to my CBSD series, though!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45107249</guid></item><item><title>The Kafka Replication Protocol with KIP-966</title><link>https://github.com/Vanlightly/kafka-tlaplus/blob/main/kafka_data_replication/kraft/kip-966/description/0_kafka_replication_protocol.md</link><description>&lt;doc fingerprint="3b74d0de090e4684"&gt;
  &lt;main&gt;
    &lt;p&gt;We read every piece of feedback, and take your input very seriously.&lt;/p&gt;
    &lt;p&gt;To see all available qualifiers, see our documentation.&lt;/p&gt;
    &lt;p&gt;There was an error while loading. Please reload this page.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45107353</guid></item><item><title>Show HN: Amber – better Beeper, a modern all-in-one messenger</title><link>https://useamber.app/</link><description>&lt;doc fingerprint="2f512b770b2b50c2"&gt;
  &lt;main&gt;
    &lt;p&gt;Amber&lt;/p&gt;
    &lt;head rend="h1"&gt;The ultimate AI-enabled all-in-one messenger and personal CRM&lt;/head&gt;
    &lt;p&gt;iMessage, Whatsapp, and Telegram seamlessly in one place&lt;/p&gt;
    &lt;head rend="h3"&gt;Operate your relationships at the speed of thought&lt;/head&gt;
    &lt;p&gt;All messages in one place&lt;/p&gt;
    &lt;p&gt;iMessage, Whatsapp, Telegram in one place.&lt;/p&gt;
    &lt;p&gt;ð¨ Split Inboxes&lt;/p&gt;
    &lt;p&gt;Organize conversations by projects, communities, context, and remove all distractions.&lt;/p&gt;
    &lt;p&gt;â¨ AI Assistance (optional)&lt;/p&gt;
    &lt;p&gt;AI suggested replies and search.&lt;/p&gt;
    &lt;p&gt;â° Send Later &amp;amp; Reminders&lt;/p&gt;
    &lt;p&gt;Have perfect timing with scheduling and reminders.&lt;/p&gt;
    &lt;p&gt;â Command Bar &amp;amp; Shortcuts&lt;/p&gt;
    &lt;p&gt;Every action is at your fingertips. Navigate the app like a pro from the first minute.&lt;/p&gt;
    &lt;p&gt;ð Secure Chats&lt;/p&gt;
    &lt;p&gt;All your messages are end-to-end encrypted and stored on device. They go straight from your device to the network following the latest security standards.&lt;/p&gt;
    &lt;p&gt;ð A lightweight CRM&lt;/p&gt;
    &lt;p&gt;Never forget a crucial detail about anyone.&lt;/p&gt;
    &lt;p&gt;â Mark Done &amp;amp; Ninja Mode&lt;/p&gt;
    &lt;p&gt;The messages are read only when you mark them as read. The recipient doesn't know if you've read it until you say so.&lt;/p&gt;
    &lt;head rend="h2"&gt;Become a superconnector&lt;/head&gt;
    &lt;p&gt;We spend hours on messages. Yet we often reply late, sometimes completely forget to reply. We then end up losing deals, opportunities for connection, and missing connections.&lt;/p&gt;
    &lt;p&gt;It's not anybody's fault. Messaging itself has not changed a decade â it has just gotten messier. Our conversations are scattered across different social networks with distinct UI full of distractions. Finding the right thread takes minutes. The context and the small details are forgotten.&lt;lb/&gt;Meanwhile, some people manage thousands of relationships and only grow stronger connections. Whatâs their secret?&lt;/p&gt;
    &lt;p&gt;John D. Rockefeller had a rolodex filled with contact details of 100,000 people. Marlon Brando, Holly Solomon, Akio Morita, David Ogilvy â each relied on personal CRMs and skilled assistants to maintain and deepen their networks. They had systems. They had tools.&lt;/p&gt;
    &lt;p&gt;With the arrival of the latest AI models and well-crafted software, these capabilities are now within everyoneâs reach.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45107364</guid></item><item><title>Civics is boring, so, let's encrypt something (2024)</title><link>https://queue.acm.org/detail.cfm?id=3703126</link><description>&lt;doc fingerprint="86929a1018252219"&gt;
  &lt;main&gt;
    &lt;p&gt;It's a common trope in entertainment for some character to deliver a nonlinear response to something seemingly trivial, only for that to later prove to have been a vitally important clue. So, that room the janitor won't let anybody into? Right, that isn't actually a storage closet, but instead it's the Portal to Hell. Governments have a quirk like that in the sense that you can get away with a lot of crap—in particular, if it looks like it might benefit the economy—But Nobody Messes with Fundamental Human Rights, OK?&lt;/p&gt;
    &lt;p&gt;As I write this, the founder of the encrypted communication service Telegram is under arrest in France. And, depending on where you get your news, he's either a freedom fighter subject to political persecution or a criminal mastermind getting his due. He probably is a bit of both, but he's under arrest now because he messed with the Fundamental Human Rights of people in France.&lt;/p&gt;
    &lt;p&gt;I'll spare you a long civics lesson, but I will provide two important clues to figure out what is going on with politicians and encryption right now. First, when legislators write laws to protect human rights, they decide who has to take responsibility for the problem, and what happens if they fail to lift the burden. So, if you're present when somebody falls off a ladder, the law has made it your problem to try to save that person's life. If you witness a crime, the law has made it your problem to tell the truth about what you saw in court. Similarly, if you publish something that somebody else wrote, the law makes you responsible for ensuring it doesn't endanger national security.&lt;/p&gt;
    &lt;p&gt;Second clue: Judges are superusers. To perform their job, which is to correct wrongs, judges are empowered to write court orders that sanction otherwise illegal violations of human rights. So, a judge who is convinced you're about to kill somebody can unleash the police to follow you everywhere in hopes of preventing that crime. Similarly, a judge who thinks your computer system contains information related to financial crimes can allow the police to hack that system. Likewise, a judge who thinks you're stalking your ex can order you to stay out of a certain part of town. And if there doesn't seem to be any other way to keep you from harming somebody else's human rights, you can be jailed.&lt;/p&gt;
    &lt;p&gt;Then, should you fail to comply with a court order, that's considered contempt of court and can be addressed with punishments far more severe than most people imagine, since court orders are deemed to be crucially important to the maintenance of law and order. What's more, a judge who becomes convinced you are planning a crime or human-rights violation—or have participated in one—can order that the privacy of your communications be violated as part of a search for evidence.&lt;/p&gt;
    &lt;p&gt;The problem for law enforcement in all this is that modern computer-aided encryption is fast, effortless, omnipresent, and unbreakable, thus negating many of these efforts. This is the frustration law-enforcement types are referring to whenever they complain about "criminals going dark." It's also what leads some politicians to say silly things about "banning encryption."&lt;/p&gt;
    &lt;p&gt;It's not as if people didn't communicate in code previously, if only to save on telco expenses. But this used to be slow, bothersome, and error prone, which limited usage and left law enforcement with places to insert the knife—so it was somewhat tolerated.&lt;/p&gt;
    &lt;p&gt;IT libertarians have gone so far as to set up "offshore" services that employ encryption specifically designed to make it impossible for anyone to comply with a court order. So, because the Internet is global, now even petty criminals in Hoople, North Dakota, can effortlessly prevent judges from employing their superuser privileges.&lt;/p&gt;
    &lt;p&gt;This is a direct, in-your-face challenge to any state that considers itself to be a nation built on laws. Predictably, a response delivered with all due force is certain to come. The United Nations' new "cybercrime" treaty, readied for signatures at the time of this writing, is very much focused on how to get court orders to work quickly and efficiently across borders. Bear in mind that international bodies don't fashion treaties like this unless they think an urgent response is vital.&lt;/p&gt;
    &lt;p&gt;Which means we, as IT professionals, now have a choice to make. We can either sit by passively and suffer the consequences of whatever ill-conceived solution the politicians cook up for us, or we can participate in the process in hopes of achieving a less awful solution.&lt;/p&gt;
    &lt;p&gt;In terms of what might be done in that way, here's one straw-man proposal to consider.&lt;/p&gt;
    &lt;p&gt;First, we provide legislators with the essential technical tools.&lt;/p&gt;
    &lt;p&gt;We can make it possible for one side of a TLS protocol negotiation to declare, "I'll deal with court orders related to this communication," in such a way that law enforcement can find out where to send the court order for their wiretap without learning more than they already know.&lt;/p&gt;
    &lt;p&gt;Moreover, parties to a TLS connection should be able to insist that the session key starts with a certain number of zero bits. If the other party thinks that isn't good enough, the TLS handshake fails.&lt;/p&gt;
    &lt;p&gt;Then the legislators can get to work. First, they'll need to make it a crime to force or trick anyone into using stronger encryption than they consent to, no matter how that might be done. (Note that IT liberalists who claim encryption is a human right never realize this should also include the right not to be forced to use encryption against one's will.)&lt;/p&gt;
    &lt;p&gt;Second, they'll need to lay out what it takes for an attestation to handle court orders to be validated—along with the consequences for noncompliance. This will probably be something along the lines of: "The attestation must be signed with Interpol's or XYZ government's certificate."&lt;/p&gt;
    &lt;p&gt;Third, it will need to be legislated that, if the other end attested to handling court orders or if the session key requires fewer than N bits to brute force, you will not be subject to any adverse treatment for using encryption. (N is a political choice since the hardware that law enforcement will need in order to brute-force the N bits will be paid for out of your taxes. Don't argue here; take it up with your politicians.)&lt;/p&gt;
    &lt;p&gt;Then, fourth and finally (drum roll, please!), they'll need to allow courts to jail the accused until: (a) the communication has been decrypted by someone; (b) the maximum penalty for the charged crime has been exceeded; or (c) the court decides to release the accused.&lt;/p&gt;
    &lt;p&gt;Following a bit of implementation work, your browser or mobile phone will then work as follows:&lt;/p&gt;
    &lt;p&gt;You'll configure your jurisdiction—for example, USA, EU, or China—so that the browser will know how to validate attestations from the other end.&lt;/p&gt;
    &lt;p&gt;Whenever you connect to a site that attests, you'll be able to use any kind of encryption with any key size, and since almost all commercial sites, such as your bank, already are legally required to keep records and respond to court orders, they'll have no trouble attesting.&lt;/p&gt;
    &lt;p&gt;Should you contact a site that does not attest—be it Crimes R Us in Elbonia or your Homeowner Association's "50 Rules for Appropriate Lawn Maintenance," your browser will keep you out of jail by refusing to use a session key longer than the N legal bits.&lt;/p&gt;
    &lt;p&gt;If for some reason, however, you think that isn't nearly enough encryption, you'll also be at liberty to go into your browser settings to select whatever session key size you are willing to use—provided, of course, that the other end accepts that as well.&lt;/p&gt;
    &lt;p&gt;The slider should probably be graduated in units of time, days, weeks, months, and years since what you're really setting is the length of time you're willing to rot in jail while refusing to comply with a court order.&lt;/p&gt;
    &lt;p&gt;It goes without saying that you'll suffer no ill consequences even if you set the slider to "eternity," provided you keep a logfile of all your session keys and then hand them over whenever a court order demands it. Just make sure you don't lose that file.&lt;/p&gt;
    &lt;p&gt;Companies can also set up client-side proxies that attest to handling court orders and insist upon proper session key sizes, according to company policy, so their employees won't even have to think about it.&lt;/p&gt;
    &lt;p&gt;Which is to say that this straw-man proposal, in theory, ought to make everybody happy. What's not to like? Law enforcement will have ways to gain access to communications, provided they can convince a judge it's necessary. All important communications will be able to continue using the same strength of encryption they use today. Communications that didn't require encryption in the first place, like that HOA guide to proper lawn maintenance, will be able to employ sufficient encryption to prevent trivial wiretapping, but nothing strong enough to prevent brute-force access should a judge decide that's necessary. And if legislators think that too much or too little encryption is being brute-forced, they can always revise the law to change N.&lt;/p&gt;
    &lt;p&gt;IT libertarians, meanwhile, will have the freedom to encrypt any way they please, and they can even throw away their session keys if they so choose, but they won't be able to force anyone else to do so. If they try, they'll have to stand up in court for it—just like that IT libertarian who's currently in French custody.&lt;/p&gt;
    &lt;p&gt;In reality, I expect that law enforcement will demand more access and that IT libertarians will consider any kind of compromise to be treasonous. So, no, I do not expect my proposed compromise has any chance of adoption whatsoever.&lt;/p&gt;
    &lt;p&gt;But, then, don't tell me 10 or 20 years from now that we didn't have any other options.&lt;/p&gt;
    &lt;p&gt;Poul-Henning Kamp has haunted the Unix world for 40 years and written a lot of widely used open-source software, including bits of FreeBSD and the Varnish HTTP Cache. Living in Denmark with his wife, two cats, and three lawn-mower robots, he remains unconvinced that an older/wiser correlation exists.&lt;/p&gt;
    &lt;p&gt;Copyright © 2024 held by owner/author. Publication rights licensed to ACM.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; Originally published in Queue vol. 22, no. 5— &lt;lb/&gt; Comment on this article in the ACM Digital Library &lt;/p&gt;
    &lt;p&gt; Jinnan Guo, Peter Pietzuch, Andrew Paverd, Kapil Vaswani - Trustworthy AI using Confidential Federated Learning &lt;lb/&gt; The principles of security, privacy, accountability, transparency, and fairness are the cornerstones of modern AI regulations. Classic FL was designed with a strong emphasis on security and privacy, at the cost of transparency and accountability. CFL addresses this gap with a careful combination of FL with TEEs and commitments. In addition, CFL brings other desirable security properties, such as code-based access control, model confidentiality, and protection of models during inference. Recent advances in confidential computing such as confidential containers and confidential GPUs mean that existing FL frameworks can be extended seamlessly to support CFL with low overheads. &lt;/p&gt;
    &lt;p&gt; Raluca Ada Popa - Confidential Computing or Cryptographic Computing? &lt;lb/&gt; Secure computation via MPC/homomorphic encryption versus hardware enclaves presents tradeoffs involving deployment, security, and performance. Regarding performance, it matters a lot which workload you have in mind. For simple workloads such as simple summations, low-degree polynomials, or simple machine-learning tasks, both approaches can be ready to use in practice, but for rich computations such as complex SQL analytics or training large machine-learning models, only the hardware enclave approach is at this moment practical enough for many real-world deployment scenarios. &lt;/p&gt;
    &lt;p&gt; Matthew A. Johnson, Stavros Volos, Ken Gordon, Sean T. Allen, Christoph M. Wintersteiger, Sylvan Clebsch, John Starks, Manuel Costa - Confidential Container Groups &lt;lb/&gt; The experiments presented here demonstrate that Parma, the architecture that drives confidential containers on Azure container instances, adds less than one percent additional performance overhead beyond that added by the underlying TEE. Importantly, Parma ensures a security invariant over all reachable states of the container group rooted in the attestation report. This allows external third parties to communicate securely with containers, enabling a wide range of containerized workflows that require confidential access to secure data. Companies obtain the advantages of running their most confidential workflows in the cloud without having to compromise on their security requirements. &lt;/p&gt;
    &lt;p&gt; Charles Garcia-Tobin, Mark Knight - Elevating Security with Arm CCA &lt;lb/&gt; Confidential computing has great potential to improve the security of general-purpose computing platforms by taking supervisory systems out of the TCB, thereby reducing the size of the TCB, the attack surface, and the attack vectors that security architects must consider. Confidential computing requires innovations in platform hardware and software, but these have the potential to enable greater trust in computing, especially on devices that are owned or controlled by third parties. Early consumers of confidential computing will need to make their own decisions about the platforms they choose to trust. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45107505</guid></item><item><title>Amazon must face US nationwide class action over third-party sales</title><link>https://www.reuters.com/legal/government/amazon-must-face-us-nationwide-class-action-over-third-party-sales-2025-09-02/</link><description>&lt;doc fingerprint="c6a69da3c36098c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Amazon must face US nationwide class action over third-party sales&lt;/head&gt;
    &lt;p&gt;Sept 2 (Reuters) - Amazon.com (AMZN.O) must face a class action on behalf of hundreds of millions of U.S. consumers over claims that the online retail giant overcharged for products sold by third-party sellers, a federal judge in Seattle has ruled.&lt;/p&gt;
    &lt;p&gt;U.S. District Judge John Chun in an order unsealed on Friday certified a nationwide class involving 288 million customers and billions of transactions, marking one of the largest-ever in the United States.&lt;/p&gt;
    &lt;p&gt;Sign up here.&lt;/p&gt;
    &lt;p&gt;The class includes buyers in the United States who purchased five or more new goods from third-party sellers on Amazon since May 26, 2017.&lt;/p&gt;
    &lt;p&gt;The consumers’ 2021 lawsuit said Amazon violated antitrust law by restricting third-party sellers from offering their products for lower prices elsewhere on rival platforms while they are also for sale on Amazon.&lt;/p&gt;
    &lt;p&gt;Amazon’s policies have allowed the company to impose inflated fees on sellers, causing shoppers to pay higher prices for purchases, the lawsuit said.&lt;/p&gt;
    &lt;p&gt;Amazon has denied any wrongdoing. It has already appealed Chun’s class certification order, which was first issued under seal on Aug. 6.&lt;/p&gt;
    &lt;p&gt;Amazon and attorneys for the consumers did not immediately respond to requests for comment.&lt;/p&gt;
    &lt;p&gt;Amazon argued that the class was too large to be manageable and that the plaintiffs failed to show its alleged conduct had a widespread effect. Amazon also said that since 2019 it has not used a pricing program that the plaintiffs challenged.&lt;/p&gt;
    &lt;p&gt;Chun found there was no evidence at this stage that the size of the class was overbroad. Other federal courts had certified class actions with millions or hundreds of millions of class members, the judge said.&lt;/p&gt;
    &lt;p&gt;The case is Elizabeth De Coster et al v. Amazon.com Inc, U.S. District Court, Western District of Washington, No. 2:21-cv-00693-JHC.&lt;/p&gt;
    &lt;p&gt;For plaintiffs: Steve Berman and Barbara Mahoney of Hagens Berman Sobol Shapiro; Zina Bash of Keller Postman; and Steig Olson of Quinn Emanuel Urquhart &amp;amp; Sullivan&lt;/p&gt;
    &lt;p&gt;For defendant: Karen Dunn, William Isaacson and Amy Mauser of Dunn Isaacson Rhee, and John Goldmark of Davis Wright Tremaine&lt;/p&gt;
    &lt;p&gt;Read more:&lt;/p&gt;
    &lt;p&gt;Reporting by Mike Scarcella&lt;/p&gt;
    &lt;p&gt;Our Standards: The Thomson Reuters Trust Principles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45107891</guid></item><item><title>iNaturalist keeps full species classification models private</title><link>https://github.com/inaturalist/inatVisionAPI</link><description>&lt;doc fingerprint="47959d5cd4ea94e0"&gt;
  &lt;main&gt;
    &lt;p&gt;We're doing some computer vision stuff at iNat.&lt;/p&gt;
    &lt;p&gt;iNaturalist makes a subset of its machine learning models publicly available while keeping full species classification models private due to intellectual property considerations and organizational policy. We provide “small” models trained on approximately 500 taxa, including taxonomy files and a geographic model, which are suitable for on-device testing and other applications. Additionally, researchers have independently developed and released open-source models based on iNaturalist data, which can be found in various model distribution venues (for example Hugging Face or Kaggle).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;brew install libmagic&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;python3 -m venv venv&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;source ./venv/bin/activate&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;pip3 install -U pip&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;pip3 install -r requirements.txt&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here's a rough script for OS X assuming you already have homebrew, Python, and virtualenv installed.&lt;/p&gt;
    &lt;code&gt;# Get dependencies
brew install libmagic

# Get the repo
git clone git@github.com:inaturalist/inatVisionAPI.git
cd inatVisionAPI/

# Set up your python environment
python3 -m venv venv
source venv/bin/activate
pip3 install -U pip
pip3 install -r requirements.txt

# Copy your config file (and edit, of course)
cp config.yml.example config.yml

# Run the app
python app.py
&lt;/code&gt;
    &lt;p&gt;Now you should be able to test at http://localhost:6006 via the browser.&lt;/p&gt;
    &lt;p&gt;If the device you're installing on has AVX extensions (check flags in /proc/cpuinfo), try compiling tensorflow for better performance: https://www.tensorflow.org/install/install_sources This is a good idea on AWS or bare metal, but won't make a difference on Rackspace due to them using an old hypervisor. If you're not compiling, install tensorflow from pip: &lt;code&gt;pip install tensorflow&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;If the device you're installing on has AVX2 or SSE4, install pillow-simd for faster image resizing: &lt;code&gt;pip install pillow-simd&lt;/code&gt; if you only have SSE4, or &lt;code&gt;CC="cc -mavx2" pip install pillow-simd&lt;/code&gt; if you have AVX2. I saw a significant increase in performance from pillow to pillow-simd with SSE4, less of an increase for AVX2.
otherwise, install pillow from pip: &lt;code&gt;pip install pillow&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;tensorflow seems to want to compile against your system copy of numpy on OS X regardless of the virtualenv, so if you see stupid errors like &lt;code&gt;ImportError: numpy.core.multiarray failed to import&lt;/code&gt;, try running &lt;code&gt;deactivate&lt;/code&gt; to get out the virtualenv, then &lt;code&gt;pip install -U numpy&lt;/code&gt; or somesuch to update your system copy of numpy. Then &lt;code&gt;source inatvision-venv/bin/activate&lt;/code&gt; to get back in your virtualend and try again.&lt;/p&gt;
    &lt;p&gt;Some performance data from a 15" MBP, 2.5GHz i7:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;task&lt;/cell&gt;
        &lt;cell role="head"&gt;pip tensorflow&lt;/cell&gt;
        &lt;cell role="head"&gt;compiled tensorflow&lt;/cell&gt;
        &lt;cell role="head"&gt;compiled tensorflow + pillow-simd&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;100x medium.jpg&lt;/cell&gt;
        &lt;cell&gt;25 seconds&lt;/cell&gt;
        &lt;cell&gt;17 seconds&lt;/cell&gt;
        &lt;cell&gt;15 seconds&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;100x iphone photos&lt;/cell&gt;
        &lt;cell&gt;81 seconds&lt;/cell&gt;
        &lt;cell&gt;72 seconds&lt;/cell&gt;
        &lt;cell&gt;46 seconds&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The larger the images coming into the pipeline, the more important optimized resize (like pillow-simd) is.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45107939</guid></item><item><title>First attempt will be 95% garbage: 6 weeks with Claude Code</title><link>https://www.sanity.io/blog/first-attempt-will-be-95-garbage</link><description>&lt;doc fingerprint="1e680603ea861e8e"&gt;
  &lt;main&gt;
    &lt;p&gt;This started as an internal Sanity workshop where I demoed how I actually use AI. Spoiler: it's running multiple agents like a small team with daily amnesia.&lt;/p&gt;
    &lt;p&gt;Vincent Quigley&lt;/p&gt;
    &lt;p&gt;Vincent Quigley is a Staff Software Engineer at Sanity&lt;/p&gt;
    &lt;p&gt;Published&lt;/p&gt;
    &lt;p&gt;Until 18 months ago, I wrote every line of code myself. Today, AI writes 80% of my initial implementations while I focus on architecture, review, and steering multiple development threads simultaneously.&lt;/p&gt;
    &lt;p&gt;This isn't another "AI will change everything" post. This is about the messy reality of integrating AI into production development workflows: what actually works, what wastes your time, and why treating AI like a "junior developer who doesn't learn" became my mental model for success.&lt;/p&gt;
    &lt;p&gt;The backstory: We run monthly engineering workshops at Sanity where someone presents what they've been experimenting with. Last time was my turn, and I showed how I'd been using Claude Code.&lt;/p&gt;
    &lt;p&gt;This blog post is from my presentation at our internal workshop (10-min recording below).&lt;/p&gt;
    &lt;p&gt;My approach to solving code problems has pivoted four times in my career:&lt;/p&gt;
    &lt;p&gt;For the first 5 years, I was reading books and SDK documentation.&lt;/p&gt;
    &lt;p&gt;Then 12 years of googling for crowd-sourced answers.&lt;/p&gt;
    &lt;p&gt;It was 18 months of using Cursor for AI-assisted coding&lt;/p&gt;
    &lt;p&gt;And recently, 6 weeks of using Claude Code for full AI delegation&lt;/p&gt;
    &lt;p&gt;Each transition happened faster than the last. The shift to Claude Code? That took just hours of use for me to become productive.&lt;/p&gt;
    &lt;p&gt;Here's what my workflow looks like now, stripped of the hype. I use AI mostly "to think with" as I'm working with it towards the code that ends up in production.&lt;/p&gt;
    &lt;p&gt;Forget the promise of one-shot perfect code generation. Your job as an engineer is to find the best solution for the problem, not just write a bunch of code.&lt;/p&gt;
    &lt;p&gt;Then you take the learnings from this attempt and feed it back.&lt;/p&gt;
    &lt;p&gt;This isn't failure; it's the process! Expecting perfection on attempt one is like expecting a junior developer to nail a complex feature without context.&lt;/p&gt;
    &lt;p&gt;The biggest challenge? AI can't retain learning between sessions (unless you spend the time manually giving it the "memories"). So typically, every conversation starts fresh.&lt;/p&gt;
    &lt;p&gt;My solutions:&lt;/p&gt;
    &lt;p&gt;Create a project-specific context file with:&lt;/p&gt;
    &lt;p&gt;Thanks to MCP integrations, I can now connect my AI to:&lt;/p&gt;
    &lt;p&gt;Without this context, you're explaining the same constraints repeatedly. With it, you start at attempt two instead of attempt one.&lt;/p&gt;
    &lt;p&gt;I run multiple Claude instances in parallel now, it's like managing a small team of developers who reset their memory each morning.&lt;/p&gt;
    &lt;p&gt;Key strategies:&lt;/p&gt;
    &lt;p&gt;Writing code is one part of the job, but so is reviewing code. Adopting AI has evolved my code review process as well.&lt;/p&gt;
    &lt;p&gt;This saves me and my peers time and extra rounds.&lt;/p&gt;
    &lt;p&gt;At Sanity, our policy is that the engineer is responsible for the code they ship, even if it's AI generated. I want to make sure that I ship:&lt;/p&gt;
    &lt;p&gt;The key take away: I'm more critical of "my code" now because I didn't type out a lot of it. No emotional attachment means better reviews.&lt;/p&gt;
    &lt;p&gt;We're testing Slack-triggered agents using Cursor for simple tasks:&lt;/p&gt;
    &lt;p&gt;Current limitations:&lt;/p&gt;
    &lt;p&gt;But the potential? Imagine agents handling your backlog's small tickets while you sleep. We're actively exploring this at Sanity, sharing learnings across teams as we figure out what works.&lt;/p&gt;
    &lt;p&gt;Let's talk money. My Claude Code usage costs my company not an insignificant percent of what they pay me monthly.&lt;/p&gt;
    &lt;p&gt;But for that investment:&lt;/p&gt;
    &lt;p&gt;The ROI is obvious, but budget for $1000-1500/month for a senior engineer going all-in on AI development. It's also reasonable to expect engineers to get more efficient with AI spend as they get good with it, but give them time.&lt;/p&gt;
    &lt;p&gt;Not everything in AI-assisted development is smooth. Here are the persistent challenges I find myself in:&lt;/p&gt;
    &lt;p&gt;The learning problem&lt;lb/&gt;AI doesn't learn from mistakes. You fix the same misunderstandings repeatedly. Your solution: better documentation and more explicit instructions.&lt;/p&gt;
    &lt;p&gt;The confidence problem&lt;lb/&gt;AI confidently writes broken code claiming that it's great. Always verify, especially for:&lt;/p&gt;
    &lt;p&gt;The context limit problem&lt;lb/&gt;Large codebases overwhelm AI context windows. Break problems into smaller chunks and provide focused context.&lt;/p&gt;
    &lt;p&gt;The hardest part? Letting go of code ownership. But now I don't care about "my code" anymore; it's just output to review and refine.&lt;/p&gt;
    &lt;p&gt;This detachment is actually quite liberating!&lt;/p&gt;
    &lt;p&gt;If a better AI tool appears tomorrow, I'll switch immediately. The code isn't precious; the problems we solve are.&lt;/p&gt;
    &lt;p&gt;If I were to give advice from an engineer's perspective, if you're a technical leader considering AI adoption:&lt;/p&gt;
    &lt;p&gt;The engineers who adapt to the new AI workflows will find themselves with a new sharp knife in their toolbox: They're becoming orchestrators, handling multiple AI agents while focusing on architecture, review, and complex problem-solving.&lt;/p&gt;
    &lt;p&gt;Pick one small, well-defined feature. Give AI three attempts at implementing it. Review the output like you're mentoring a junior developer.&lt;/p&gt;
    &lt;p&gt;That's it. No huge transformation needed, no process overhaul required. Just one feature, three attempts, and a honest review.&lt;/p&gt;
    &lt;p&gt;The future isn't about AI replacing developers. It's about developers working faster, creating better solutions, and leveraging the best tools available.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45107962</guid></item><item><title>Linux home server sleep on idle and wake on demand – the simple way</title><link>https://dgross.ca/blog/linux-home-server-auto-sleep</link><description>&lt;doc fingerprint="96f37d91e92280c3"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Making a Linux home server sleep on idle and wake on demand â the simple way&lt;/head&gt;
    &lt;p&gt;It began with what seemed like a final mundane touch to my home server setup for hosting Time Machine backups: I wanted it to automatically sleep when idle and wake up again when needed. You know, sleep on idle â hasnât Windows had that built in since like Windows 98? How hard could it be to configure on a modern Ubuntu install?&lt;/p&gt;
    &lt;p&gt;To be fair, I wanted more than just sleep on idle, I also wanted wake on request â and that second bit turns out to be the hard part. There were a bunch of dead ends, but I stuck out it to find something that âjust worksâ without the need to manually turn on the server for every backup. Join me on the full adventure further down, or cut to the chase with the setup instructions below.&lt;/p&gt;
    &lt;head rend="h1"&gt;tl;dr&lt;/head&gt;
    &lt;head rend="h4"&gt;Outcome:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Server automatically suspends to RAM when idle&lt;/item&gt;
      &lt;item&gt;Server automatically wakes when needed by anything else on the network, including SSH, Time Machine backups, etc.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Youâll need:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;An always-on Linux device on the same network as your server, e.g. a Raspberry Pi&lt;/item&gt;
      &lt;item&gt;A network interface device for your server that supports wake-on-LAN with unicast packets&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;On the server:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Enable wake-on-LAN with unicast packets (not just magic packets), make it persistent&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;sudo ethtool -s eno1 wol ug
sudo tee /etc/networkd-dispatcher/configuring.d/wol &amp;lt;&amp;lt; EOF
#!/usr/bin/env bash

ethtool -s eno1 wol ug || true
EOF
sudo chmod 755 /etc/networkd-dispatcher/configuring.d/wol
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Set up a cron job to sleep on idle (replace &lt;code&gt;/home/ubuntu&lt;/code&gt;with your desired script location)&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;tee /home/ubuntu/auto-sleep.sh &amp;lt;&amp;lt; EOF
#!/bin/bash
logged_in_count=$(who | wc -l)
# We expect 2 lines of output from `lsof -i:548` at idle: one for output headers, another for the 
# server listening for connections. More than 2 lines indicates inbound connection(s).
afp_connection_count=$(lsof -i:548 | wc -l)
if [[ $logged_in_count &amp;lt; 1 &amp;amp;&amp;amp; $afp_connection_count &amp;lt; 3 ]]; then
  systemctl suspend
else
  echo "Not suspending, logged in users: $logged_in_count, connection count: $afp_connection_count"
fi
EOF
chmod +x /home/ubuntu/auto-sleep.sh
sudo crontab -e
# In the editor, add the following line:
*/10 * * * * /home/ubuntu/auto-sleep.sh | logger -t autosuspend
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Disable IPv6: this approach relies on ARP, which IPv6 doesnât use&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;sudo nano /etc/default/grub
# Find GRUB_CMDLINE_LINUX=""
# Change to GRUB_CMDLINE_LINUX="ipv6.disable=1"
sudo update-grub
sudo reboot
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Optional: Configure network services (e.g. Netatalk) to stop before sleep to prevent unwanted wakeups due to network activity&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;sudo tee /etc/systemd/system/netatalk-sleep.service &amp;lt;&amp;lt; EOF
[Unit]
Description=Netatalk sleep hook
Before=sleep.target
StopWhenUnneeded=yes

[Service]
Type=oneshot
RemainAfterExit=yes
ExecStart=-/usr/bin/systemctl stop netatalk
ExecStop=-/usr/bin/systemctl start netatalk

[Install]
WantedBy=sleep.target
EOF
sudo systemctl daemon-reload
sudo systemctl enable netatalk-sleep.service
&lt;/code&gt;
    &lt;head rend="h4"&gt;On the always-on device:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Install ARP Stand-in: a super simple Ruby script that runs as a system service and responds to ARP requests on behalf of another machine. Configure it to respond on behalf of the sleeping server.&lt;/item&gt;
      &lt;item&gt;Optional: Configure Avahi to advertise network services on behalf of the server when itâs sleeping.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;sudo apt install avahi-daemon
sudo tee /etc/systemd/system/avahi-publish.service &amp;lt;&amp;lt; EOF
[Unit]
Description=Publish custom Avahi records
After=network.target avahi-daemon.service
Requires=avahi-daemon.service

[Service]
ExecStart=/usr/bin/avahi-publish -s homeserver _afpovertcp._tcp 548 -H homeserver.local

[Install]
WantedBy=multi-user.target
EOF
sudo systemctl daemon-reload
sudo systemctl enable avahi-publish.service --now
systemctl status avahi-publish.service
&lt;/code&gt;
    &lt;head rend="h4"&gt;Caveats&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The serverâs network device needs to support wake-on-LAN from unicast packets&lt;/item&gt;
      &lt;item&gt;To prevent unwanted wake-ups, youâll need to ensure no device on the network is sending extraneous packets to the server&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;How I got there&lt;/head&gt;
    &lt;p&gt;First, a bit about my hardware, as this solution is somewhat hardware-dependent:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;HP ProDesk 600 G3 SFF&lt;/item&gt;
      &lt;item&gt;CPU: Intel Core i5-7500&lt;/item&gt;
      &lt;item&gt;Network adapter: Intel I219-LM&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Sleeping on idle&lt;/head&gt;
    &lt;p&gt;I started with sleep-on-idle, which boiled down to two questions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;How to determine if the server is idle or busy at any given moment&lt;/item&gt;
      &lt;item&gt;How to automatically suspend to RAM after being idle for some time&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Most of the guides I found for sleep-on-idle, like this one, were for Ubuntu Desktop â sleep-on-idle doesnât seem to be something thatâs commonly done with Ubuntu Server. I came across a few tools that looked promising, the most notable being &lt;code&gt;circadian&lt;/code&gt;. In general, though, there didnât seem to be a standard/best-practice way to do it, so I decided Iâd roll it myself the simplest way I could.&lt;/p&gt;
    &lt;head rend="h3"&gt;Determining idle/busy state&lt;/head&gt;
    &lt;p&gt;I asked myself what server activity would constitute being busy, and landed on two things:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Logged in SSH sessions&lt;/item&gt;
      &lt;item&gt;In-progress Time Machine backups&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Choosing corresponding metrics was pretty straightforward:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Count of logged in users, using &lt;code&gt;who&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Count of connections on the AFP port (548), using &lt;code&gt;lsof&lt;/code&gt;(Iâm using AFP for Time Machine network shares)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For both metrics, I noted the values first at idle, and then again when the server was busy.&lt;/p&gt;
    &lt;head rend="h3"&gt;Automatically suspending to RAM&lt;/head&gt;
    &lt;p&gt;To keep things simple, I opted for a cron job that triggers a bash script â check out the final version shared above. So far itâs worked fine; if I ever need to account for more metrics in detecting idle state, Iâll consider using a more sophisticated option like &lt;code&gt;circadian&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;Waking on request&lt;/head&gt;
    &lt;p&gt;With sleep-on-idle out of the way, I moved on to figuring out how the server would wake on demand.&lt;/p&gt;
    &lt;p&gt;Could the machine be configured to automatically wake upon receiving a network request? I knew Wake-on-LAN supported waking a computer up using a specially crafted âmagic packetâ, and it was straightforward to get this working. The question was if a regular, non-âmagic packetâ could somehow do the same thing.&lt;/p&gt;
    &lt;head rend="h3"&gt;Wake on PHY?&lt;/head&gt;
    &lt;p&gt;Some online searching yielded a superuser discussion that looked particularly promising. It pointed to the man page for ethtool, the Linux utility used to configure network hardware. It shared ethtoolâs complete wake-on-LAN configuration options:&lt;/p&gt;
    &lt;code&gt;wol p|u|m|b|a|g|s|f|d...
      Sets Wake-on-LAN options.  Not all devices support
      this.  The argument to this option is a string of
      characters specifying which options to enable.

      p   Wake on PHY activity
      u   Wake on unicast messages
      m   Wake on multicast messages
      b   Wake on broadcast messages
      a   Wake on ARP
      g   Wake on MagicPacketâ¢
      s   Enable SecureOnâ¢ password for MagicPacketâ¢
      f   Wake on filter(s)
      d   Disable (wake on nothing).  This option
          clears all previous options.
&lt;/code&gt;
    &lt;p&gt;It pointed in particular to the &lt;code&gt;Wake on PHY activity&lt;/code&gt; option, which seemed perfect for this use-case. It seemed to mean that any packet sent to the network interfaceâs MAC address would wake it. I enabled the flag using &lt;code&gt;ethtool&lt;/code&gt;, manually put the machine to sleep, then tried logging back in using SSH and sending pings. No dice: the machine remained asleep despite multiple attempts. So much for that ð&lt;/p&gt;
    &lt;head rend="h3"&gt;Breakthrough: wake on unicast&lt;/head&gt;
    &lt;p&gt;None of &lt;code&gt;ethtool&lt;/code&gt;âs other wake-on-LAN options seemed relevant, but some more searching pointed to the &lt;code&gt;Wake on unicast messages&lt;/code&gt; as another option to try. I enabled the flag using &lt;code&gt;ethtool&lt;/code&gt;, manually put the machine to sleep, then tried logging back in using SSH. Bingo! This time, the machine woke up. ð With that, I figured I was done.&lt;/p&gt;
    &lt;p&gt;Not so fast â there were two problems:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Sometimes, the server would wake up without any network activity that I knew of&lt;/item&gt;
      &lt;item&gt;Some period of time after the server went to sleep, it would become impossible to wake it again using network activity other than a magic packet&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A closer look at the same superuser discussion above revealed exactly the reason for the second problem: shortly after going to sleep, the machine was effectively disappearing from the network because it was no longer responding to ARP requests.&lt;/p&gt;
    &lt;head rend="h3"&gt;ARP&lt;/head&gt;
    &lt;p&gt;So the cached ARP entry for other machines on the network was expiring, meaning that they had no way to resolve the serverâs IP address to its MAC address. In other words, an attempt to ping my server at &lt;code&gt;192.168.1.2&lt;/code&gt; was failing to even send a packet to the server, because the serverâs MAC address wasnât known. Without a packet being sent, there was no way that server was going to wake up.&lt;/p&gt;
    &lt;head rend="h4"&gt;Static ARP?&lt;/head&gt;
    &lt;p&gt;My first reaction: letâs manually create ARP cache entries on each network client. This is indeed possible on macOS using:&lt;/p&gt;
    &lt;code&gt;sudo arp -s [IP address] [MAC address]
&lt;/code&gt;
    &lt;p&gt;But it also didnât meet the goal of having things âjust workâ: I was not interested in creating static ARP cache entries on each machine that would be accessing the server. On to other options.&lt;/p&gt;
    &lt;head rend="h4"&gt;ARP protocol offload?&lt;/head&gt;
    &lt;p&gt;Some more searching revealed something interesting: this problem had already been solved long ago in the Windows world.&lt;/p&gt;
    &lt;p&gt;It was called ARP protocol offload, and it goes like this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The network hardware is capable of responding to ARP requests independently of the CPU&lt;/item&gt;
      &lt;item&gt;Before going to sleep, the OS configures the network hardware to respond to ARP requests&lt;/item&gt;
      &lt;item&gt;While sleeping, the network hardware responds to ARP requests on its own, without waking the rest of the machine to use the CPU&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Voila, this was exactly what I needed. I even looked at the datasheet for my network hardware, which lists ARP Offload as a feature on the front page.&lt;/p&gt;
    &lt;p&gt;The only problem? No Linux support. I searched the far reaches of the internet, then finally dug into the Linux driver source code to find that ARP offload isnât supported by the Linux driver. This was when I briefly pondered trying to patch the driver to add ARP offloadâ¦ before reminding myself that successfully patching Linux driver code is far beyond what I could hope to achieve in a little free-time project like this one. (Though maybe one dayâ¦)&lt;/p&gt;
    &lt;head rend="h4"&gt;Other solutions using magic packets&lt;/head&gt;
    &lt;p&gt;Some more searching led me to some other clever and elaborate solutions involving magic packets. The basic idea was to automate sending magic packets. One solution (wake-on-arp) listens for ARP requests to a specified host to trigger sending a magic packet to that host. Another solution implements a web interface and Home Assistant integration to enable triggering a magic packet from a smartphone web browser. These are impressive, but I wanted something simpler that didnât require manually waking up the server.&lt;/p&gt;
    &lt;p&gt;I considered a few other options, but abandoned them because they felt too complex and prone to breaking:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Writing a script to send a magic packet and then immediately trigger a Time Machine backup using &lt;code&gt;tmutil&lt;/code&gt;. The script would need to be manually installed and scheduled to run periodically on each Mac.&lt;/item&gt;
      &lt;item&gt;Using HAProxy to proxy all relevant network traffic through the Raspberry Pi and using a hook to send a magic packet to the server on activity.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Breakthrough: ARP Stand-in&lt;/head&gt;
    &lt;p&gt;What I was attempting didnât seem much different from the static IP mapping thatâs routinely configured on home routers, except that it was for DHCP instead of ARP. Was there no way to make my router do the same thing for ARP?&lt;/p&gt;
    &lt;p&gt;Some more digging into the ARP protocol revealed that ARP resolution doesnât even require a specific, authoritative host to answer requests â any other network device can respond to ARP requests. In other words, my router didnât need to be the one resolving ARP requests, it could be anything. Now how could I just set up something to respond on behalf of the sleeping server?&lt;/p&gt;
    &lt;p&gt;Hereâs what I was trying to do:&lt;/p&gt;
    &lt;p&gt;I thought it must be possible to implement as a Linux network configuration, but the closest thing I found was Proxy ARP, which accomplished a different goal. So I went one level deeper, to network programming.&lt;/p&gt;
    &lt;p&gt;Now, how to go about listening for ARP request packets? This is apparently possible to do using a raw socket, but I also knew that &lt;code&gt;tcpdump&lt;/code&gt; and Wireshark were capable of using filters to capture only packets of a given type. That led me to look into libpcap, the library that powers both of those tools. I learned that using &lt;code&gt;libpcap&lt;/code&gt; had a clear advantage over a raw socket: &lt;code&gt;libpcap&lt;/code&gt; implements very efficient filtering directly in the kernel, whereas a raw socket would require manual packet filtering in user space, which is less performant.&lt;/p&gt;
    &lt;p&gt;Aiming to keep things simple, I decided to try writing the solution in Ruby, which led me to the pcaprub Ruby bindings for &lt;code&gt;libpcap&lt;/code&gt;. From there, I just needed to figure out what filter to use with &lt;code&gt;libpcap&lt;/code&gt;. Some research and trial/error yielded this filter:&lt;/p&gt;
    &lt;code&gt;arp and arp[6:2] == 1 and arp[24:4] == [IP address converted to hex]
&lt;/code&gt;
    &lt;p&gt;For example, using a target IP address of &lt;code&gt;192.168.1.2&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;arp and arp[6:2] == 1 and arp[24:4] == 0xc0a80102
&lt;/code&gt;
    &lt;p&gt;Letâs break this down, using the ARP packet structure definition for byte offets and lengths:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;arp&lt;/code&gt;â ARP packets&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;arp[6:2] == 1&lt;/code&gt;â ARP request packets.&lt;code&gt;[6:2]&lt;/code&gt;means âthe 2 bytes found at byte offset 6â.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;arp[24:4] == [IP address converted to hex]&lt;/code&gt;â ARP packets with the specified target address.&lt;code&gt;[24:4]&lt;/code&gt;means âthe 4 bytes found at byte offset 24â.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The rest is pretty straightforward and the whole solution comes out to only ~50 lines of Ruby code. In short, &lt;code&gt;arp_standin&lt;/code&gt; is a daemon that does the following:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Starts up, taking these configuration options: &lt;list rend="ul"&gt;&lt;item&gt;IP and MAC address of the machine itâs standing in for (the âtargetâ)&lt;/item&gt;&lt;item&gt;Network interface to operate on&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Listens for ARP requests for the targetâs IP address&lt;/item&gt;
      &lt;item&gt;On detecting an ARP request for the targetâs IP address, responds with the targetâs MAC address&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Since the serverâs IP â MAC address mapping is defined statically through the &lt;code&gt;arp_standin&lt;/code&gt; daemonâs configuration, it doesnât matter if the Raspberry Piâs ARP cache entry for the server is expired.&lt;/p&gt;
    &lt;p&gt;Check out the link below to install it or explore the source code further:&lt;/p&gt;
    &lt;p&gt;danielpgross/arp_standin on GitHub&lt;/p&gt;
    &lt;p&gt;ARP is used in IPv4 and is replaced by Neighbor Discovery Protocol (NDP) in IPv6. I donât have any need for IPv6 right now, so I disabled IPv6 entirely on the server using the steps shown above. It should be possible to add support for Neighbor Discovery to the ARP-Standin service as a future enhancement.&lt;/p&gt;
    &lt;p&gt;With the new service running on my Raspberry Pi, I used Wireshark to confirm that ARP requests being sent to the server were triggering responses from the ARP Stand-in. It worked ð â things were looking promising.&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting it all working&lt;/head&gt;
    &lt;p&gt;The big pieces were in place:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;the server went to sleep after becoming idle&lt;/item&gt;
      &lt;item&gt;the server could wake up from unicast packets&lt;/item&gt;
      &lt;item&gt;other machines could resolve the serverâs MAC address using ARP, long after it went to sleep&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With the ARP Stand-in running, I turned on the server and ran a backup from my computer. When the backup was finished, the server went to sleep automatically. But there was a problem: the server was waking up immediately after going to sleep.&lt;/p&gt;
    &lt;head rend="h3"&gt;Unwanted wake-ups&lt;/head&gt;
    &lt;p&gt;First thing I checked was the Linux system logs, but these didnât prove too helpful, since they didnât show what network packet actually triggered the wakeup. Wireshark/tcpdump were no help here either, because they wouldnât be running when the computer was sleeping. Thatâs when I thought to use port mirroring: capturing packets from an intermediary device between the server and the rest of the network. After a brief, unsuccessful attempt to repurpose an extra router running OpenWRT, a search for the least expensive network switch with port mirroring support yielded the TP-Link TL-SG105E for ~$30.&lt;/p&gt;
    &lt;p&gt;With the switch connected and port mirroring enabled, I started capturing with Wireshark and the culprits immediately became clear:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;My Mac, which was configured to use the server as a Time Machine backup host using AFP, was sending AFP packets to the server after it had gone to sleep&lt;/item&gt;
      &lt;item&gt;My Netgear R7000, acting as a wireless access point, was sending frequent, unsolicited NetBIOS &lt;code&gt;NBTSTAT&lt;/code&gt;queries to the server&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Eliminating AFP packets&lt;/head&gt;
    &lt;p&gt;I had a hunch about why the Mac was sending these packets:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Mac mounted the AFP share to perform a Time Machine backup&lt;/item&gt;
      &lt;item&gt;The Time Machine backup finished, but the share remained mounted&lt;/item&gt;
      &lt;item&gt;The Mac was checking on the status of the share periodically, as would be done normally for a mounted network share&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I also had a corresponding hunch that the solution would be to make sure the share got unmounted before the server went to sleep, so that the Mac would no longer ping the server for its status afterwards. I figured that shutting down the AFP service would trigger unmounting of shares on all its clients, achieving the goal. Now I just needed to ensure the service would shut down when the server was going to sleep, then start again when it woke back up.&lt;/p&gt;
    &lt;p&gt;Fortunately, &lt;code&gt;systemd&lt;/code&gt; supports exactly that, and relatively easily â I defined a dedicated &lt;code&gt;systemd&lt;/code&gt; service to hook into sleep/wake events (check out the configuration shared above). A Wireshark capture confirmed that it did the trick.&lt;/p&gt;
    &lt;head rend="h4"&gt;Eliminating NetBIOS packets&lt;/head&gt;
    &lt;p&gt;This one proved to be harder, because the packets were unsolicited â they seemed random and unrelated to any activity being done by the server. I thought they might be related to Samba services running on the server, but the packets persisted even after I completely removed Samba from the server.&lt;/p&gt;
    &lt;p&gt;Why was my network router sending NetBIOS requests, anyway? Turns out that Netgear routers have a feature called ReadySHARE for sharing USB devices over the network using the SMB protocol. Presumably, the router firmware uses Samba behind the scenes, which uses NetBIOS queries to build and maintain its own representation of NetBIOS hosts on the network. Easy â turn off ReadySHARE, right? Nope, thereâs no way to do that in Netgearâs stock firmware ð.&lt;/p&gt;
    &lt;p&gt;That led me to take the plunge and flash the router with open-source FreshTomato firmware. Iâm glad I did, because the firmware is much better than the stock one anyway, and it immediately stopped the unwanted NetBIOS packets.&lt;/p&gt;
    &lt;head rend="h3"&gt;Time Machine not triggering wake-up&lt;/head&gt;
    &lt;p&gt;I was getting close now: the server remained asleep, and I could reliably wake it up by logging in with SSH, even long after it went to sleep.&lt;/p&gt;
    &lt;p&gt;This was great, but one thing wasnât working: when starting a backup on my Mac, Time Machine would show a loading state indefinitely with &lt;code&gt;Connecting to backup disk...&lt;/code&gt; and eventually give up. Was the server failing to wake up from packets the Mac was sending, or was the Mac not sending packets at all?&lt;/p&gt;
    &lt;p&gt;A port-mirrored Wireshark capture answered that question: the Mac wasnât sending any packets to the server, even long after it started to say &lt;code&gt;Connecting to backup disk...&lt;/code&gt;. Digging into the macOS Time Machine logs with:&lt;/p&gt;
    &lt;code&gt;log show --style syslog --predicate 'senderImagePath contains[cd] "TimeMachine"' --info
&lt;/code&gt;
    &lt;p&gt;A few entries made it clear:&lt;/p&gt;
    &lt;code&gt;(TimeMachine) [com.apple.TimeMachine:Mounting] Attempting to mount 'afp://backup_mbp@homeserver._afpovertcp._tcp.local./tm_mbp'
...
(TimeMachine) [com.apple.TimeMachine:General] Failed to resolve CFNetServiceRef with name = homeserver type = _afpovertcp._tcp. domain = local.
&lt;/code&gt;
    &lt;p&gt;The Mac was using mDNS (a.k.a. Bonjour, Zeroconf) to resolve the backup serverâs IP address using its hostname. The server was asleep and therefore not responding to the requests, so the Mac was failing to resolve its IP address. This explained why the Mac wasnât sending any packets to the server, leaving it asleep.&lt;/p&gt;
    &lt;head rend="h4"&gt;mDNS stand-in&lt;/head&gt;
    &lt;p&gt;I already had an ARP stand-in service, now I needed my Raspberry Pi to also respond to mDNS queries for the server while it slept. I knew that Avahi was one of the main mDNS implementations for Linux. I first tried these instructions using &lt;code&gt;.service&lt;/code&gt; files to configure my Raspberry Pi to respond to mDNS queries on behalf of the server. I used the following on the Mac to check the result:&lt;/p&gt;
    &lt;code&gt;dns-sd -L homeserver _afpovertcp._tcp local
&lt;/code&gt;
    &lt;p&gt;For some reason, that approach just didnât work; Avahi didnât respond on behalf of the server. I experimented instead with &lt;code&gt;avahi-publish&lt;/code&gt; (man page), which (to my pleasant surprise) worked right away using the following:&lt;/p&gt;
    &lt;code&gt;avahi-publish -s homeserver _afpovertcp._tcp 548 -H homeserver.local
&lt;/code&gt;
    &lt;p&gt;With that, I just needed to create a &lt;code&gt;systemd&lt;/code&gt; service definition that would automatically run the &lt;code&gt;avahi-publish&lt;/code&gt; command on boot (check out the configuration shared above).&lt;/p&gt;
    &lt;head rend="h2"&gt;ð Finish&lt;/head&gt;
    &lt;p&gt;With all the wrinkles ironed out, everything has been working well now for over a month. I hope youâve enjoyed following along and that this approach works for you too.&lt;/p&gt;
    &lt;p&gt;This post was discussed on Hacker News and Reddit.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45108066</guid></item><item><title>U.S. Emissions Rise 4.2%, China's Fall 2.7%</title><link>https://www.theenergymix.com/u-s-emissions-rise-chinas-fall-in-massive-shift-between-worlds-biggest-climate-polluters/</link><description>&lt;doc fingerprint="bb7c26ae8f05bebc"&gt;
  &lt;main&gt;
    &lt;p&gt;The United States’ carbon emissions increased while China’s declined in the first half of this year compared to the same period in 2024, pointing to a massive shift in roles between the world’s two biggest climate polluters if the trend continues.&lt;/p&gt;
    &lt;p&gt;Between January 1 and June 30 this year, U.S. emissions rose 4.2% while China’s fell 2.7%, reports Carbon Monitor, a global emissions tracker led by Tsinghua University, France’s Laboratory of Climate and Environmental Sciences, the University of California, Irvine, and China’s Institute of Geographic Sciences and Natural Resources Institute.&lt;/p&gt;
    &lt;p&gt;In China, emissions were down 1.4% across the power sector and industry, and held statistically even across all other economic sectors. The United States was one of just three countries, along with Japan and Brazil, that saw emissions rise across their entire economies—including increases of 2% in ground transport and 1.3% in the power sector.&lt;/p&gt;
    &lt;p&gt;Across all the individual countries in the Carbon Monitor database, Spain recorded the highest emissions increase, at 6%, followed by Brazil at 5.6%, Germany at 5.2%, the European Union plus the United Kingdom at 4.6%, and the U.S. at 4.2%.&lt;/p&gt;
    &lt;p&gt;Between the world’s two leading emitters, the data show “a reversal of the usual trend over the past decade, when global heat-trapping emissions inched higher in large part because U.S. reductions have been offset by higher CO2 output from China,” Politico writes. “It also comes after decades of American politicians of both parties complaining about China failing to clean up its act.”&lt;/p&gt;
    &lt;p&gt;The numbers could still be shifted by factors like weather, short-term economic trends, and natural gas prices, Politico writes. “But there are also signs of structural changes in the global economy.” International Energy Agency (IEA) figures show Chinese coal consumption falling 2.6% in the first half of the year, largely due to a boom in solar that saw the country add 92 gigawatts of capacity—that’s 92 billion watts—in a single month in May, compared to all-time U.S. installations of 134 GW.&lt;/p&gt;
    &lt;p&gt;That reflects a fundamental shift in the way China consumes energy, climate scientist Glen Peters of the Oslo-based Center for International Climate Research (CICERO) told Politico, though it’s still early to declare a permanent change. “Even if Chinese emissions decline this year, I would not start saying they have peaked,” he said. “I would want to see emissions trending down for a few years.”&lt;/p&gt;
    &lt;p&gt;But U.S. per capita emissions are still well above China’s, according to the latest IEA data. And with Donald Trump moving on all fronts to increase fossil fuel production and revoke renewable energy incentives and confirmed contracts, Stanford University earth systems scientist Rob Jackson said the broader trends are clear—even if it’s too soon to say where the 2025 data will land.&lt;/p&gt;
    &lt;p&gt;“It’s fair to say that China and the U.S. are on different trajectories now,” he told Politico, with clean technology adoption likely to drive down emissions over the next five years. The U.S., by contrast, is “heading in the opposite direction.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45108292</guid></item><item><title>Google gets to keep Chrome but is barred from exclusive search deals</title><link>https://www.cnbc.com/2025/09/02/google-antitrust-search-ruling.html</link><description>&lt;doc fingerprint="19c23cf013b73368"&gt;
  &lt;main&gt;
    &lt;p&gt;A federal judge ruled Tuesday that Google can keep its Chrome browser but will be barred from exclusive contracts and must share search data.&lt;/p&gt;
    &lt;p&gt;Alphabet shares popped 6% in extended trading.&lt;/p&gt;
    &lt;p&gt;U.S. District Judge Amit Mehta ruled against the most severe consequences that were proposed by the U.S. Department of Justice, including selling off its Chrome browser, which provides data that helps its advertising business deliver targeted ads.&lt;/p&gt;
    &lt;p&gt;"Google will not be required to divest Chrome; nor will the court include a contingent divestiture of the Android operating system in the final judgment," the decision states. "Plaintiffs overreached in seeking forced divesture of these key assets, which Google did not use to effect any illegal restraints."&lt;/p&gt;
    &lt;p&gt;The company can make payments to preload products, but they cannot have exclusive contracts, the decision showed.&lt;/p&gt;
    &lt;p&gt;The DOJ asked Google to stop the practice of "compelled syndication," which refers to the practice of making certain deals with companies to ensure its search engine remains the default choice in browsers and smartphones.&lt;/p&gt;
    &lt;p&gt;Google pays Apple billions of dollars per year to be the default search engine on iPhones. It's lucrative for Apple and a valuable way for Google to get more search volume and users.&lt;/p&gt;
    &lt;p&gt;Apple shares rose 4% on Tuesday after hours.&lt;/p&gt;
    &lt;p&gt;"Google will not be barred from making payments or offering other consideration to distribution partners for preloading or placement of Google Search, Chrome, or its GenAI products. Cutting off payments from Google almost certainly will impose substantial—in some cases, crippling—downstream harms to distribution partners, related markets, and consumers, which counsels against a broad payment ban."&lt;/p&gt;
    &lt;p&gt;In a landmark case filed in 2020, the U.S. Department of Justice alleged that Google kept its share of the general search market by creating strong barriers to entry and a feedback loop that sustained its dominance.&lt;/p&gt;
    &lt;p&gt;The U.S. District Court for the District of Columbia ruled in August 2024 that Google violated Section 2 of the Sherman Act, which outlaws monopolies, saying the company has held an illegal monopoly in its core market of internet search.&lt;/p&gt;
    &lt;p&gt;Mehta oversaw the remedies trial in May, where the two parties proposed penalties that should be taken against Google as a result of the monopoly ruling. During that trial, the DOJ asked the judge to force Google to share the data it uses for generating search results, such as data about what users click on.&lt;/p&gt;
    &lt;p&gt;Google said it will appeal the ruling, which would delay any potential penalties.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45108548</guid></item><item><title>Judge Orders Google to Share Search Results to Help Resolve Monopoly</title><link>https://www.nytimes.com/2025/09/02/technology/google-search-antitrust-decision.html</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45108727</guid></item></channel></rss>