<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 12 Nov 2025 15:11:54 +0000</lastBuildDate><item><title>.NET 10</title><link>https://devblogs.microsoft.com/dotnet/announcing-dotnet-10/</link><description>&lt;doc fingerprint="fe09fa1b1fb2a0d0"&gt;
  &lt;main&gt;&lt;p&gt;Today, we are excited to announce the launch of .NET 10, the most productive, modern, secure, intelligent, and performant release of .NET yet. It’s the result of another year of effort from thousands of developers around the world. This release includes thousands of performance, security, and functional improvements across the entire .NET stack-from languages and developer tools to workloads-enabling you to build with a unified platform and easily infuse your apps with AI.&lt;/p&gt;&lt;p&gt;Important&lt;/p&gt;.NET 10 is a Long Term Support (LTS) release and will be supported for three years until November 10, 2028. We strongly recommend that production applications upgrade to .NET 10 to take advantage of the extended support window, significant performance improvements, and new capabilities.&lt;p&gt;Downloads of .NET 10 and updates to Visual Studio 2026 and the C# Dev Kit for Visual Studio Code are available now.&lt;/p&gt;&lt;p&gt;The .NET team, our partners, and the .NET community are showcasing what’s new in .NET 10 at .NET Conf 2025. Watch the sessions to see all of the excitement including the keynote.&lt;/p&gt;&lt;head rend="h2"&gt;A Thriving .NET Community&lt;/head&gt;&lt;p&gt;.NET 10 wouldn’t be possible without our amazing community. Thank you to everyone who contributed issues, pull requests, code reviews, and feedback to make this release happen. The .NET ecosystem continues to flourish with over 478,000 packages on NuGet that have been downloaded over 800 billion times. Thousands of companies worldwide including H&amp;amp;R Block, Geocaching, Chipotle, Fidelity, and many more, along with products and services here at Microsoft like Xbox, Bing, Microsoft Graph, Azure Cosmos DB, Microsoft Exchange, Microsoft Teams, and Microsoft Copilot, trust .NET to build their most critical applications.&lt;/p&gt;&lt;head rend="h2"&gt;Unparalleled Performance – Faster Apps, Lower Memory&lt;/head&gt;&lt;p&gt;.NET 10 is the fastest .NET yet with improvements across the runtime, workloads, and languages. Stephen Toub’s performance improvements deep dive highlights the latest optimizations.&lt;/p&gt;&lt;p&gt;Key improvements:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;JIT compiler enhancements: Better inlining, method devirtualization, and improved code generation for struct arguments&lt;/item&gt;&lt;item&gt;Hardware acceleration: AVX10.2 support for cutting-edge Intel silicon, Arm64 SVE for advanced vectorization with Arm64 write-barrier improvements reducing GC pause times by 8-20%&lt;/item&gt;&lt;item&gt;NativeAOT improvements: Smaller, faster ahead-of-time compiled apps&lt;/item&gt;&lt;item&gt;Runtime optimizations: Enhanced loop inversion and stack allocation strategies deliver measurable performance gains&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;C# 14 &amp;amp; F# 10&lt;/head&gt;&lt;p&gt;C# 14 and F# 10 deliver powerful language improvements that make your code more concise and expressive. C# continues to be one of the world’s most popular programming languages, ranking in the top 5 in the 2025 GitHub Octoverse report.&lt;/p&gt;&lt;head rend="h3"&gt;C# 14 highlights&lt;/head&gt;&lt;p&gt;Field-backed properties simplify property declarations by eliminating the need for explicit backing fields. The compiler generates the backing field automatically, making your code cleaner and more maintainable:&lt;/p&gt;&lt;code&gt;// Automatic backing field with custom logic
public string Name
{
    get =&amp;gt; field;
    set =&amp;gt; field = value?.Trim() ?? string.Empty;
}&lt;/code&gt;
&lt;p&gt;Extension properties and methods enable adding members to types you don’t own-including interfaces and static members-making extension types far more powerful. You can now create extension properties that work seamlessly with types throughout your codebase:&lt;/p&gt;&lt;code&gt;// Extension properties for any type
static class ListExtensions
{
    extension(List&amp;lt;int&amp;gt; @this)
    {
        public int Sum =&amp;gt; @this.Aggregate(0, (a, b) =&amp;gt; a + b);
    }
}&lt;/code&gt;
&lt;p&gt;Additional C# 14 features:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;First-class &lt;code&gt;Span&amp;lt;T&amp;gt;&lt;/code&gt;conversions: Implicit conversion support for high-performance span operations&lt;/item&gt;&lt;item&gt;Null-conditional assignment: &lt;code&gt;?.=&lt;/code&gt;operator for cleaner null-safe assignment code&lt;/item&gt;&lt;item&gt;Parameter modifiers in lambdas: Use &lt;code&gt;ref&lt;/code&gt;,&lt;code&gt;in&lt;/code&gt;, or&lt;code&gt;out&lt;/code&gt;parameters without explicit types&lt;/item&gt;&lt;item&gt;Collection expression extensions: &lt;code&gt;.._expression_&lt;/code&gt;to&lt;code&gt;params&lt;/code&gt;and&lt;code&gt;[.._expression_]&lt;/code&gt;spread syntax&lt;/item&gt;&lt;item&gt;Enhanced overload resolution: &lt;code&gt;[OverloadResolutionPriority]&lt;/code&gt;attribute for better method selection&lt;/item&gt;&lt;item&gt;Partial properties and constructors: Complete the partial members story with properties, constructors, and events&lt;/item&gt;&lt;item&gt;&lt;code&gt;ref struct&lt;/code&gt;interface implementations: Better performance with zero-allocation patterns&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;F# 10 highlights&lt;/head&gt;&lt;p&gt;F# 10 is a refinement release focused on clarity, consistency, and performance with meaningful improvements for everyday code.&lt;/p&gt;&lt;p&gt;Language improvements:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Scoped warning suppression: Use &lt;code&gt;#warnon&lt;/code&gt;paired with&lt;code&gt;#nowarn&lt;/code&gt;to enable or disable warnings within specific code sections, giving you precise control over compiler diagnostics&lt;/item&gt;&lt;item&gt;Access modifiers on auto property accessors: Create publicly readable but privately mutable properties without verbose backing fields (&lt;code&gt;member val Balance = 0m with public get, private set&lt;/code&gt;)&lt;/item&gt;&lt;item&gt;&lt;code&gt;ValueOption&lt;/code&gt;optional parameters: Apply&lt;code&gt;[&amp;lt;Struct&amp;gt;]&lt;/code&gt;attribute to optional parameters to use struct-based&lt;code&gt;ValueOption&amp;lt;'T&amp;gt;&lt;/code&gt;instead of heap-allocated&lt;code&gt;option&lt;/code&gt;, eliminating allocations in performance-critical code&lt;/item&gt;&lt;item&gt;Tail-call support in computation expressions: Builders can now opt into tail-call optimizations with &lt;code&gt;ReturnFromFinal&lt;/code&gt;and&lt;code&gt;YieldFromFinal&lt;/code&gt;methods&lt;/item&gt;&lt;item&gt;Typed bindings without parentheses: Write natural type annotations like &lt;code&gt;let! x: int = fetchA()&lt;/code&gt;in computation expressions without parentheses&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Core library &amp;amp; performance:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;and!&lt;/code&gt;in task expressions: Concurrently await multiple tasks with idiomatic syntax:&lt;code&gt;let! a = fetchA() and! b = fetchB()&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Type subsumption cache: Faster compilation and IDE responsiveness through memoized type relationship checks&lt;/item&gt;&lt;item&gt;Parallel compilation preview: Graph-based type checking, parallel IL code generation, and parallel optimization enabled by default with &lt;code&gt;LangVersion=Preview&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Better trimming by default: Auto-generated substitutions remove F# metadata resources for smaller published apps&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Read more about these features, as well as improvements to computation expression bindings, attribute target enforcement, deprecation warnings for omitted &lt;code&gt;seq&lt;/code&gt;, and more in the What’s New in F# 10 documentation.&lt;/p&gt;&lt;head rend="h2"&gt;.NET Libraries – Secure, Modern APIs&lt;/head&gt;&lt;p&gt;.NET 10 libraries deliver important updates across cryptography, networking, serialization, and more-making apps more secure and efficient.&lt;/p&gt;&lt;head rend="h3"&gt;Post-Quantum Cryptography&lt;/head&gt;&lt;p&gt;Note&lt;/p&gt;Quantum computing advances make post-quantum cryptography increasingly important. .NET 10’s expanded PQC support helps future-proof your applications against quantum threats while maintaining compatibility with existing systems.&lt;p&gt;.NET 10 expands post-quantum cryptography (PQC) support:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Windows CNG support: Use ML-DSA and ML-KEM algorithms with Windows cryptography APIs&lt;/item&gt;&lt;item&gt;Enhanced ML-DSA: HashML-DSA variant for improved security characteristics&lt;/item&gt;&lt;item&gt;Composite ML-DSA: Hybrid approaches combining traditional and quantum-resistant algorithms for defense-in-depth&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Enhanced Networking&lt;/head&gt;&lt;p&gt;Networking improvements make apps faster and more capable:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;WebSocketStream&lt;/code&gt;: Simplified WebSocket API that’s easier to use and more efficient&lt;/item&gt;&lt;item&gt;TLS 1.3 on macOS: Modern TLS support across all major platforms&lt;/item&gt;&lt;item&gt;Windows process group support: Better process management on Windows&lt;/item&gt;&lt;item&gt;Performance optimizations: Reduced allocations and improved throughput across HTTP, sockets, and WebSockets&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Additional library improvements&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;JSON enhancements: Disallow duplicate properties for safer deserialization, enhanced serialization settings, &lt;code&gt;PipeReader&lt;/code&gt;support for high-performance scenarios&lt;/item&gt;&lt;item&gt;Cryptography updates: AES KeyWrap with Padding for secure key wrapping in compliance scenarios&lt;/item&gt;&lt;item&gt;System updates: Improved diagnostics, better interop with native code, enhanced collections&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Learn more in What’s new in .NET Libraries.&lt;/p&gt;&lt;head rend="h2"&gt;Aspire – Orchestrate front ends, APIs, containers, and databases effortlessly&lt;/head&gt;&lt;p&gt;Aspire makes building observable, production-ready distributed apps straightforward with built-in telemetry, service discovery, and cloud integrations. Aspire 13 ships with .NET 10 with major improvements for polyglot development, modern workflows, and enterprise deployment.&lt;/p&gt;&lt;p&gt;Key highlights:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Modern development experience: CLI enhancements, single-file AppHost support for streamlined project organization, and quicker onboarding with simplified templates&lt;/item&gt;&lt;item&gt;Seamless build &amp;amp; deployment: Built-in static file site support for frontend apps, robust deployment parallelization for faster releases, and production-ready container workflows&lt;/item&gt;&lt;item&gt;Enterprise-ready infrastructure: Flexible connection strings and certificate trust management that works consistently across your applications&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Additional features:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Simplified AppHost SDK: Set &lt;code&gt;Aspire.AppHost.Sdk&lt;/code&gt;as the sole project SDK&lt;/item&gt;&lt;item&gt;AddCSharpApp support: New &lt;code&gt;CSharpAppResource&lt;/code&gt;and&lt;code&gt;AddCSharpApp&lt;/code&gt;alternatives to&lt;code&gt;AddProject&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Enhanced security: Encoded parameters for sensitive configuration data, customizable resource certificate trust&lt;/item&gt;&lt;item&gt;Dashboard improvements: OpenID Connect claims configuration for flexible authentication&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Working with other platforms:&lt;/p&gt;&lt;p&gt;When your .NET applications need to integrate with services written in Python, JavaScript, or other languages, Aspire 13 makes this seamless. You can orchestrate your entire distributed application from your .NET AppHost with comprehensive debugging support, auto-generated Dockerfiles, and unified environment variable patterns across all platforms. Read the full polyglot announcement.&lt;/p&gt;&lt;p&gt;Ecosystem growth: Check out the Aspire Community Toolkit and earn the Aspire credential.&lt;/p&gt;&lt;p&gt;Learn more in the Aspire documentation.&lt;/p&gt;&lt;head rend="h2"&gt;Artificial Intelligence – From Simple Integrations to Multi-Agent Systems&lt;/head&gt;&lt;p&gt;.NET makes building AI-powered apps straightforward, from simple integrations to complex multi-agent systems. Companies like H&amp;amp;R Block, Blip, and KPMG use .NET for their AI solutions, and the new Microsoft Copilot is built with .NET.&lt;/p&gt;&lt;head rend="h3"&gt;Microsoft Agent Framework – Build Intelligent Multi-Agent Systems&lt;/head&gt;&lt;p&gt;The Microsoft Agent Framework simplifies building intelligent, agentic AI systems by combining the best of Semantic Kernel and AutoGen into a unified experience. Whether you’re building a single AI agent or orchestrating multiple agents working together, the framework provides the patterns and infrastructure you need.&lt;/p&gt;&lt;p&gt;Create sophisticated AI workflows with minimal code:&lt;/p&gt;&lt;code&gt;// Create agents with minimal code
AIAgent writer = new ChatClientAgent(
    chatClient,
    new ChatClientAgentOptions
    {
        Name = "Writer",
        Instructions = "Write engaging, creative stories."
    });

// Orchestrate in workflows
AIAgent editor = new ChatClientAgent(chatClient, /* ... */);
Workflow workflow = AgentWorkflowBuilder.BuildSequential(writer, editor);
AIAgent workflowAgent = await workflow.AsAgentAsync();&lt;/code&gt;
&lt;p&gt;The framework supports multiple workflow patterns to match your application’s needs:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Sequential workflows: Agents execute in a defined order, with each agent’s output feeding into the next&lt;/item&gt;&lt;item&gt;Concurrent workflows: Multiple agents work in parallel for faster processing&lt;/item&gt;&lt;item&gt;Handoff workflows: Agents dynamically pass control based on context and requirements&lt;/item&gt;&lt;item&gt;Group chat: Agents collaborate through conversation to solve complex problems&lt;/item&gt;&lt;item&gt;Magentic: A dedicated manager coordinates a team of specialized agents&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Integrate tools seamlessly, whether they’re simple C# functions or full Model Context Protocol (MCP) servers. The framework is production-ready with built-in support for dependency injection, middleware pipelines, and OpenTelemetry for observability.&lt;/p&gt;&lt;p&gt;You can quickly get started with building server hosted agents with Microsoft Agent Framework and ASP.NET Core using the new AI Agent Web API template (&lt;code&gt;aiagent-webapi&lt;/code&gt;) available in the Microsoft.Agents.AI.ProjectTemplates template package.&lt;/p&gt;&lt;code&gt;dotnet new install Microsoft.Agents.AI.ProjectTemplates
dotnet new aiagent-webapi -o MyAIAgentWebApi
cd MyAIAgentWebApi
dotnet run&lt;/code&gt;
&lt;p&gt;This creates an ASP.NET Core Web API project that hosts your agents and exposes them as standard HTTP endpoints. It includes the Microsoft Agent Framework Dev UI, providing a web-based test harness to validate and visualize agents and workflows through an interactive interface.&lt;/p&gt;&lt;p&gt;Microsoft Agent Framework now supports the AG-UI protocol for building rich agent user interfaces. AG-UI is a light-weight event-based protocol for human-agent interactions that makes it easy to build streaming UIs, frontend tool calling, shared state management, and other agentic UI experiences. Check out various AG-UI enabled scenarios with Microsoft Agent Framework using the AG-UI Dojo sample app.&lt;/p&gt;&lt;p&gt;Use the new Microsoft.Agents.AI.Hosting.AGUI.AspNetCore package to easily map AG-UI endpoints for your agents.&lt;/p&gt;&lt;code&gt;// Map an AG-UI endpoint for the publisher agent at /publisher/ag-ui
app.MapAGUI("publisher/ag-ui", publisherAgent)&lt;/code&gt;
&lt;p&gt;You can then use existing AG-UI client frameworks, like CopilotKit, to quickly build rich user experiences for your agents. Or, use the new .NET AG-UI chat client in the Microsoft.Agents.AI.AGUI package to build your own UI experiences using your favorite .NET UI framework, like .NET MAUI or Blazor.&lt;/p&gt;&lt;code&gt;IChatClient aguiChatClient = new AGUIChatClient(httpClient, "publisher/ag-ui);&lt;/code&gt;
&lt;p&gt;See AG-UI Agents to learn more about getting started with Microsoft Agent Framework and AG-UI.&lt;/p&gt;&lt;head rend="h3"&gt;Microsoft.Extensions.AI – Unified Building Blocks for AI Applications&lt;/head&gt;&lt;p&gt;Microsoft.Extensions.AI and Microsoft.Extensions.VectorData provide unified abstractions for integrating AI services into your applications. The &lt;code&gt;IChatClient&lt;/code&gt; interface works with any provider-OpenAI, Azure OpenAI, GitHub Models, Ollama-through a consistent API, making it easy to switch providers or support multiple backends without rewriting your code.&lt;/p&gt;&lt;code&gt;// Use any AI provider with the same interface
IChatClient chatClient = new AzureOpenAIClient(endpoint, credential)
    .AsChatClient("gpt-4o");

var response = await chatClient.CompleteAsync("Explain quantum computing");
Console.WriteLine(response.Message);&lt;/code&gt;
&lt;p&gt;The unified abstractions support:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Provider flexibility: Switch between AI providers without code changes&lt;/item&gt;&lt;item&gt;Middleware pipeline: Add caching, logging, or custom behavior to any AI call&lt;/item&gt;&lt;item&gt;Dependency injection: Register AI services using familiar .NET patterns&lt;/item&gt;&lt;item&gt;Telemetry: Built-in OpenTelemetry support for monitoring AI usage&lt;/item&gt;&lt;item&gt;Vector data: Unified abstractions for vector databases and semantic search&lt;/item&gt;&lt;/list&gt;&lt;p&gt;These building blocks work seamlessly with the Microsoft Agent Framework, Semantic Kernel, and your own AI implementations.&lt;/p&gt;&lt;head rend="h3"&gt;Model Context Protocol (MCP) – Extend AI Agents with Tools and Services&lt;/head&gt;&lt;p&gt;.NET provides first-class MCP support to extend AI agents with external tools and services. The Model Context Protocol enables AI agents to access data sources, APIs, and tools in a standardized way, making your agents more capable and versatile.&lt;/p&gt;&lt;p&gt;Install the .NET AI templates and use the MCP server template to quickly build and publish MCP servers:&lt;/p&gt;&lt;code&gt;dotnet new install Microsoft.Extensions.AI.Templates
dotnet new mcpserver -n MyMcpServer&lt;/code&gt;
&lt;p&gt;Once built, publish your MCP server to NuGet for easy consumption across your organization or the broader .NET community. The C# MCP SDK has regular releases to implement the latest protocol updates, ensuring compatibility with the growing MCP ecosystem.&lt;/p&gt;&lt;p&gt;MCP enables AI agents to:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Access databases and APIs securely&lt;/item&gt;&lt;item&gt;Execute commands and workflows&lt;/item&gt;&lt;item&gt;Read and modify files&lt;/item&gt;&lt;item&gt;Integrate with business systems&lt;/item&gt;&lt;item&gt;Use specialized tools and services&lt;/item&gt;&lt;/list&gt;&lt;p&gt;By standardizing how AI agents interact with external resources, MCP makes it easier to build, share, and compose AI capabilities across the .NET ecosystem.&lt;/p&gt;&lt;p&gt;Get started with our AI documentation and AI samples.&lt;/p&gt;&lt;head rend="h2"&gt;ASP.NET Core – Secure, High-Performance Web Apps and APIs&lt;/head&gt;&lt;p&gt;ASP.NET Core in .NET 10 includes everything you need to build secure, high-performance web applications and APIs. This release focuses on security, observability &amp;amp; diagnostics, performance, and developer productivity, providing more powerful tools for building modern web experiences.&lt;/p&gt;&lt;p&gt;Key improvements in this release include:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Automatic Memory Pool Eviction: In long-running applications, memory pools can sometimes retain memory that is no longer needed. .NET 10 introduces automatic eviction for memory pools, which helps reduce the memory footprint of your applications by releasing idle memory back to the system.&lt;/item&gt;&lt;item&gt;Web Authentication (Passkey) Support: ASP.NET Core Identity now includes support for passkeys, which are based on the WebAuthn and FIDO2 standards. This allows you to build more secure, passwordless authentication experiences. The Blazor Web App project template includes out-of-the-box support for passkey management and login.&lt;/item&gt;&lt;item&gt;Native AOT Enhancements: The &lt;code&gt;webapiaot&lt;/code&gt;template now includes OpenAPI support by default, and with new AOT-friendly validation, it’s easier to build documented, ahead-of-time compiled APIs. You can opt out with the&lt;code&gt;--no-openapi&lt;/code&gt;flag.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Blazor – Productive Component-Based Web Development&lt;/head&gt;&lt;p&gt;Blazor continues to evolve as a productive framework for building component-based web UIs with C#. .NET 10 brings significant improvements to performance, state management, and the overall developer experience.&lt;/p&gt;&lt;p&gt;Component State Persistence:&lt;/p&gt;&lt;p&gt;.NET 10 introduces significant enhancements to Blazor’s state management, making it more robust and easier to use, especially in server-side scenarios.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Declarative State Persistence: Persisting state during prerendering is now much simpler. Use the &lt;code&gt;[PersistentState]&lt;/code&gt;attribute to declaratively mark state that should be preserved.&lt;/item&gt;&lt;item&gt;Circuit state persistence: Blazor circuits are now more resilient to network interruptions. Component state is automatically persisted before a circuit is evicted after a prolonged disconnection, so users don’t lose their work.&lt;/item&gt;&lt;item&gt;Pause and Resume Circuits: New APIs to “pause” and “resume” circuits enable improved server scalability by freeing up resources for inactive clients&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Performance and Reliability:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Optimized Framework Scripts: The Blazor framework scripts are now delivered as precompressed and fingerprinted static web assets, which improves load performance and ensures proper caching.&lt;/item&gt;&lt;item&gt;WebAssembly Preloading: To improve initial load times, Blazor Web Apps now automatically preload framework assets using &lt;code&gt;Link&lt;/code&gt;headers. Standalone WebAssembly apps also benefit from high-priority asset downloading.&lt;/item&gt;&lt;item&gt;Response Streaming by Default: &lt;code&gt;HttpClient&lt;/code&gt;responses are now streamed by default in Blazor WebAssembly apps, which can improve performance and reduce memory usage when handling large responses.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Forms and Validation:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Improved Form Validation: Blazor’s form validation capabilities have been significantly improved. You can now automatically validate nested objects and collection items using a new source-generator based system that is performant and AOT-compatible.&lt;/item&gt;&lt;item&gt;New &lt;code&gt;InputHidden&lt;/code&gt;Component: A new component for rendering hidden form fields is now available.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Developer Experience:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Automated Browser Testing: &lt;code&gt;WebApplicationFactory&lt;/code&gt;now supports end-to-end testing with browser automation tools like Playwright, making it easier to write automated UI tests for your web apps.&lt;/item&gt;&lt;item&gt;JavaScript Interop Improvements: Interop with JavaScript is now more powerful. You can create instances of JavaScript objects, call their constructors, and directly read or modify their properties using both synchronous and asynchronous APIs.&lt;/item&gt;&lt;item&gt;Improved “Not Found” Handling: Blazor provides a better experience for handling 404s. You can now specify a dedicated “Not Found” page in the &lt;code&gt;Router&lt;/code&gt;component, and the new&lt;code&gt;NavigationManager.NotFound()&lt;/code&gt;method makes it easier to trigger “Not Found” responses from code during server-side rendering or interactive rendering.&lt;/item&gt;&lt;item&gt;QuickGrid enhancements: The &lt;code&gt;QuickGrid&lt;/code&gt;component now includes a&lt;code&gt;RowClass&lt;/code&gt;parameter, allowing you to apply custom CSS classes to rows based on their data. You can also explicitly handle hiding the column options UI.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Build Fast, Modern APIs&lt;/head&gt;&lt;p&gt;ASP.NET Core is an excellent choice for building fast, modern APIs. .NET 10 introduces better standards compliance, more powerful validation, and an improved developer experience.&lt;/p&gt;&lt;p&gt;OpenAPI Improvements:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;OpenAPI 3.1 Support by Default: ASP.NET Core now generates OpenAPI 3.1 documents, which includes support for the latest JSON Schema draft. This improves the representation of types, such as using an array for nullable types instead of a custom property.&lt;/item&gt;&lt;item&gt;XML Comments Integration: The OpenAPI source generator now automatically uses your C# XML comments to populate descriptions, summaries, and other documentation fields in the generated OpenAPI document.&lt;/item&gt;&lt;item&gt;YAML OpenAPI Documents: You can now serve OpenAPI documents in YAML format, providing a more human-readable alternative to JSON.&lt;/item&gt;&lt;item&gt;Enhanced Response Descriptions: The &lt;code&gt;ProducesResponseType&lt;/code&gt;attribute now includes an optional&lt;code&gt;Description&lt;/code&gt;parameter, allowing you to provide more context for your API’s responses.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Minimal APIs Enhancements:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Built-in Validation: You can now enable automatic validation for query, header, and request body parameters by calling &lt;code&gt;AddValidation()&lt;/code&gt;. If validation fails, the framework will automatically return a 400 Bad Request response with the validation details. This works with DataAnnotations and supports nested objects and collections.&lt;/item&gt;&lt;item&gt;Server-Sent Events (SSE): A new &lt;code&gt;TypedResults.ServerSentEvents()&lt;/code&gt;method makes it easy to stream real-time updates to clients over a single HTTP connection.&lt;/item&gt;&lt;item&gt;Customizable Error Responses: You can now integrate your validation logic with &lt;code&gt;IProblemDetailsService&lt;/code&gt;to create consistent, customized error responses.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Enhanced Observability and Diagnostics&lt;/head&gt;&lt;p&gt;.NET 10 introduces significant improvements to observability and diagnostics, making it easier to monitor and troubleshoot your ASP.NET Core applications.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;New Built-in Metrics: ASP.NET Core now includes a rich set of new metrics for monitoring key components, including Blazor, Authentication &amp;amp; Authorization, Identity, and the new memory pool.&lt;/item&gt;&lt;item&gt;Improved Blazor Tracing: Blazor Server tracing has been enhanced to provide more detailed information about circuit activity, making it easier to diagnose issues in real-time.&lt;/item&gt;&lt;item&gt;Blazor WebAssembly Diagnostic Tools: New diagnostic tools are available for Blazor WebAssembly applications, allowing you to collect CPU performance profiles, capture memory dumps, and gather runtime metrics.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;For more details on all the new features, check out the What’s new in ASP.NET Core in .NET 10 documentation.&lt;/p&gt;&lt;head rend="h2"&gt;.NET MAUI – Build Native Cross-Platform Apps&lt;/head&gt;&lt;p&gt;.NET MAUI is the best way to build native cross-platform apps for iOS, Android, macOS, and Windows with .NET and C#.&lt;/p&gt;&lt;p&gt;Platform updates:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Android 16 (API 36 &amp;amp; 36.1) bindings with latest platform features&lt;/item&gt;&lt;item&gt;iOS 26.0 bindings for latest iOS capabilities&lt;/item&gt;&lt;item&gt;Marshal methods enabled: Improved startup performance by default&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Control enhancements:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;HybridWebView: New initialization events (&lt;code&gt;WebViewInitializing&lt;/code&gt;,&lt;code&gt;WebViewInitialized&lt;/code&gt;) for platform-specific customization,&lt;code&gt;InvokeJavaScriptAsync&lt;/code&gt;overload, and JavaScript exception handling&lt;/item&gt;&lt;item&gt;Web request interception: Modify headers, redirect requests, or supply local responses for &lt;code&gt;BlazorWebView&lt;/code&gt;and&lt;code&gt;HybridWebView&lt;/code&gt;&lt;/item&gt;&lt;item&gt;CollectionView/CarouselView: Improved iOS handlers now default&lt;/item&gt;&lt;item&gt;MediaPicker: Automatic EXIF handling, multi-file selection with &lt;code&gt;PickMultipleAsync&lt;/code&gt;, image compression support&lt;/item&gt;&lt;item&gt;SafeArea management: Enhanced to support multiple platforms from the new &lt;code&gt;SafeAreaEdges&lt;/code&gt;API&lt;/item&gt;&lt;item&gt;Secondary toolbar items: Added for iOS and macOS&lt;/item&gt;&lt;/list&gt;&lt;p&gt;XAML improvements:&lt;/p&gt;&lt;p&gt;.NET MAUI in .NET 10 introduces significant XAML enhancements that streamline development and improve performance:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Global and implicit XML namespaces (opt-in): Simplify XAML markup by eliminating repetitive namespace declarations&lt;/item&gt;&lt;item&gt;New XAML source generator: Faster build times and better IntelliSense support with compile-time XAML processing&lt;/item&gt;&lt;/list&gt;&lt;p&gt;With global namespaces, you can declare &lt;code&gt;xmlns&lt;/code&gt; references once in a &lt;code&gt;GlobalXmlns.cs&lt;/code&gt; file and use types without prefixes throughout your XAML files:&lt;/p&gt;&lt;p&gt;Before:&lt;/p&gt;&lt;code&gt;&amp;lt;ContentPage xmlns="http://schemas.microsoft.com/dotnet/2021/maui"
        xmlns:x="http://schemas.microsoft.com/winfx/2009/xaml"
        xmlns:models="clr-namespace:MyApp.Models"
        xmlns:controls="clr-namespace:MyApp.Controls"
        x:Class="MyApp.MainPage"&amp;gt;
    &amp;lt;controls:TagView x:DataType="models:Tag" /&amp;gt;
&amp;lt;/ContentPage&amp;gt;&lt;/code&gt;
&lt;p&gt;After:&lt;/p&gt;&lt;code&gt;&amp;lt;ContentPage x:Class="MyApp.MainPage"&amp;gt;
    &amp;lt;TagView x:DataType="Tag" /&amp;gt;
&amp;lt;/ContentPage&amp;gt;&lt;/code&gt;
&lt;p&gt;No need to declare &lt;code&gt;xmlns:models&lt;/code&gt; or &lt;code&gt;xmlns:controls&lt;/code&gt; because they are declared globally in a &lt;code&gt;GlobalXmlns.cs&lt;/code&gt; file. No prefixes required for &lt;code&gt;TagView&lt;/code&gt; or &lt;code&gt;Tag&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;MediaPicker multi-file selection example:&lt;/p&gt;&lt;code&gt;var result = await MediaPicker.PickMultipleAsync(new MediaPickerOptions
{
    MaximumWidth = 1024,
    MaximumHeight = 768
});&lt;/code&gt;
&lt;p&gt;Additional highlights:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Aspire integration: New project template with telemetry and service discovery&lt;/item&gt;&lt;item&gt;Diagnostics: Comprehensive layout performance monitoring with &lt;code&gt;ActivitySource&lt;/code&gt;and metrics&lt;/item&gt;&lt;item&gt;Quality focus: Continued improvements in reliability and performance&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Read more in What’s new in .NET MAUI 10.&lt;/p&gt;&lt;head rend="h2"&gt;Entity Framework Core 10 – Advanced Data Access&lt;/head&gt;&lt;p&gt;Entity Framework Core 10 brings powerful improvements for data access, including AI-ready vector search, enhanced JSON support, and better complex type handling.&lt;/p&gt;&lt;p&gt;Azure SQL and SQL Server:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Vector search support: Full support for the new &lt;code&gt;vector&lt;/code&gt;data type and&lt;code&gt;VECTOR_DISTANCE()&lt;/code&gt;function, enabling AI workloads like semantic search and RAG with SQL Server 2025 and Azure SQL Database&lt;/item&gt;&lt;item&gt;JSON data type: Automatic use of SQL Server 2025’s native &lt;code&gt;json&lt;/code&gt;type for better performance and safety-query with full LINQ support using&lt;code&gt;JSON_VALUE()&lt;/code&gt;and&lt;code&gt;RETURNING&lt;/code&gt;clauses&lt;/item&gt;&lt;item&gt;Custom default constraint names: Specify names for default constraints or enable automatic naming for all constraints&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Azure Cosmos DB:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Full-text search: Enable efficient text searches with relevance scoring using &lt;code&gt;FullTextContains&lt;/code&gt;,&lt;code&gt;FullTextContainsAll&lt;/code&gt;,&lt;code&gt;FullTextContainsAny&lt;/code&gt;, and&lt;code&gt;FullTextScore&lt;/code&gt;functions&lt;/item&gt;&lt;item&gt;Hybrid search: Combine vector similarity and full-text search with the &lt;code&gt;RRF&lt;/code&gt;(Reciprocal Rank Fusion) function for improved AI search accuracy&lt;/item&gt;&lt;item&gt;Vector search GA: Vector similarity search is now production-ready with improved model building APIs and support for owned reference entities&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Complex Types &amp;amp; JSON:&lt;/p&gt;&lt;p&gt;Complex types bring document-modeling benefits with better performance and simpler schemas:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Optional complex types: Mark complex types as nullable for more flexible data models&lt;/item&gt;&lt;item&gt;JSON mapping: Map complex types to single JSON columns with full LINQ query support and efficient bulk updates via &lt;code&gt;ExecuteUpdate&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Struct support: Use .NET structs instead of classes for complex types with proper value semantics&lt;/item&gt;&lt;item&gt;ExecuteUpdate for JSON: Bulk update JSON column properties efficiently-updates properties in place without loading entire documents&lt;/item&gt;&lt;/list&gt;&lt;code&gt;// Update Views count in JSON column
await context.Blogs.ExecuteUpdateAsync(s =&amp;gt;
    s.SetProperty(b =&amp;gt; b.Details.Views, b =&amp;gt; b.Details.Views + 1));&lt;/code&gt;
&lt;p&gt;LINQ &amp;amp; Query Improvements:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Better parameterized collections: New default translation sends each value as a separate parameter with padding to optimize query plan caching while preserving cardinality information&lt;/item&gt;&lt;item&gt;LeftJoin and RightJoin support: First-class support for .NET 10’s new LINQ join operators for simpler outer join queries&lt;/item&gt;&lt;item&gt;Consistent split query ordering: Fixed data consistency issues in split queries with proper ordering across all SQL statements&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Additional Highlights:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Named query filters: Define multiple query filters per entity type and selectively disable specific filters in queries&lt;/item&gt;&lt;item&gt;ExecuteUpdate with regular lambdas: Build dynamic update operations without complex expression tree code&lt;/item&gt;&lt;item&gt;Security improvements: Inlined constants are now redacted from logs by default, with analyzer warnings for string concatenation in raw SQL APIs&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Learn more in What’s New in EF Core 10.&lt;/p&gt;&lt;head rend="h2"&gt;Windows Development – Modern Desktop Apps&lt;/head&gt;&lt;p&gt;.NET 10 continues to enhance Windows app development across WinUI 3, WPF, and WinForms.&lt;/p&gt;&lt;p&gt;Highlights:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Windows Forms: Improved clipboard handling, ported &lt;code&gt;UITypeEditors&lt;/code&gt;from .NET Framework for better migration support&lt;/item&gt;&lt;item&gt;WPF: Performance improvements, Fluent style updates, quality enhancements&lt;/item&gt;&lt;item&gt;WinUI 3: Latest Windows App SDK features and improvements&lt;/item&gt;&lt;/list&gt;&lt;p&gt;See the docs for WinUI 3, WPF, and WinForms.&lt;/p&gt;&lt;head rend="h2"&gt;Developer Tools – Your Most Productive Environment Yet&lt;/head&gt;&lt;p&gt;.NET 10 and Visual Studio 2026 deliver a world-class, intelligent development platform that makes you more productive across your entire workflow.&lt;/p&gt;&lt;head rend="h3"&gt;Visual Studio 2026 – Enhanced Performance and AI-Powered Development&lt;/head&gt;&lt;p&gt;Visual Studio 2026 brings groundbreaking productivity with AI deeply integrated into your development workflow. The Visual Studio 2026 release notes detail the latest features.&lt;/p&gt;&lt;p&gt;AI-Powered Development:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Adaptive paste: Copilot adapts pasted code to your file’s context-automatically fixing names, formatting, and translating between languages (e.g., C++ to C#)&lt;/item&gt;&lt;item&gt;Profiler Copilot Agent: AI assistant that analyzes CPU usage, memory allocations, suggests optimizations, and generates BenchmarkDotNet benchmarks&lt;/item&gt;&lt;item&gt;Debugger Agent for unit tests: Automatically debugs failing tests, forms hypotheses, applies fixes, and validates solutions iteratively&lt;/item&gt;&lt;item&gt;Code actions at your fingertips: Right-click context menu provides instant Copilot assistance for common tasks (Explain, Optimize, Generate Tests, etc.)&lt;/item&gt;&lt;item&gt;Copilot URL context: Reference web documentation directly in Copilot Chat for more accurate responses&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Productivity Enhancements:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Mermaid chart rendering: Visualize flowcharts and diagrams directly in the Markdown editor and Copilot Chat responses&lt;/item&gt;&lt;item&gt;Enhanced editor controls: Advanced margin capabilities for maximizing your editing experience&lt;/item&gt;&lt;item&gt;File exclusions in search: Better control over which files are included in search results&lt;/item&gt;&lt;item&gt;Code coverage for all editions: Dynamic code coverage now available in Professional edition, with tested lines highlighted directly in the editor&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Debugging &amp;amp; Diagnostics:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Inline if-statement evaluation: Debug conditional logic faster with inline values and Copilot insights&lt;/item&gt;&lt;item&gt;BenchmarkDotNet project template: Jump-start performance benchmarking with built-in CPU profiling and Copilot insights&lt;/item&gt;&lt;item&gt;CodeLens with Optimize Allocations: Right from your editor, ask Copilot to optimize memory-intensive methods&lt;/item&gt;&lt;item&gt;Profiler Agent thread summarization: Smart conversation summaries that maintain context when approaching token limits&lt;/item&gt;&lt;item&gt;CMake diagnostics: Full support for CPU Usage, Events Viewer, memory usage, and File IO tools in CMake projects&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Modern Experience:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;New look and feel: Fluent UI design system with 11 new tinted themes and independent editor appearance settings&lt;/item&gt;&lt;item&gt;Modern settings experience: Streamlined, user-friendly settings interface replacing Tools &amp;gt; Options with better organization and reliability&lt;/item&gt;&lt;item&gt;SLNX support: Work with the new simplified solution format for cleaner version control with SLNX documentation&lt;/item&gt;&lt;item&gt;Performance enhancements: Faster startup, better memory management, and improved overall responsiveness&lt;/item&gt;&lt;item&gt;Aspire integration: Seamless support for Aspire projects with specialized tooling and templates&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;GitHub Copilot – Your AI Pair Programmer&lt;/head&gt;&lt;p&gt;GitHub Copilot is integrated throughout Visual Studio and VS Code, helping with code writing, testing, and debugging:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;AI completions for C#: Better context from relevant files&lt;/item&gt;&lt;item&gt;Fix code issues: AI-assisted problem resolution&lt;/item&gt;&lt;item&gt;Debug tests: Get help with failed test debugging&lt;/item&gt;&lt;item&gt;IEnumerable visualizer: AI-powered LINQ expressions&lt;/item&gt;&lt;item&gt;Modernize to .NET 10: Use GitHub Copilot to help upgrade and modernize your existing .NET applications to .NET 10, getting guidance on breaking changes, new APIs, and best practices&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Tip&lt;/p&gt;Upgrading from an earlier version of .NET? Use GitHub Copilot to help modernize your applications to .NET 10. Copilot can guide you through breaking changes, suggest modern API replacements, and help refactor code to take advantage of new language features and performance improvements.&lt;head rend="h3"&gt;C# Dev Kit for Visual Studio Code&lt;/head&gt;&lt;p&gt;The C# Dev Kit brings a powerful, streamlined C# development experience to Visual Studio Code. Recent updates include:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Solution-less workspace mode: Work without automatic solution file creation for simpler projects&lt;/item&gt;&lt;item&gt;SLNX support: Full support for the new XML-based solution format with improved tooling&lt;/item&gt;&lt;item&gt;Enhanced Razor editing: Improved IntelliSense, formatting, and code navigation in Blazor and Razor Pages&lt;/item&gt;&lt;item&gt;Integrated test coverage: Native support for VS Code’s code coverage UI with visual indicators in the editor&lt;/item&gt;&lt;item&gt;Custom project templates: Create projects from third-party and custom &lt;code&gt;dotnet new&lt;/code&gt;templates directly in VS Code&lt;/item&gt;&lt;item&gt;NuGet package management: Add, update, and remove packages with integrated commands&lt;/item&gt;&lt;item&gt;Drag-and-drop file management: Reorganize projects easily within Solution Explorer&lt;/item&gt;&lt;item&gt;Aspire support: Run and debug Aspire projects with full orchestration support&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Learn more in the C# Dev Kit documentation.&lt;/p&gt;&lt;head rend="h3"&gt;.NET SDK – Powerful CLI Enhancements&lt;/head&gt;&lt;p&gt;The .NET 10 SDK includes powerful CLI enhancements:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Microsoft.Testing.Platform support in &lt;code&gt;dotnet test&lt;/code&gt;for unified test execution&lt;/item&gt;&lt;item&gt;Native tab-completion scripts for popular shells (bash, fish, PowerShell, zsh, nushell)&lt;/item&gt;&lt;item&gt;Container images for console apps without requiring Docker files or &lt;code&gt;EnableSdkContainerSupport&lt;/code&gt;&lt;/item&gt;&lt;item&gt;One-shot tool execution with &lt;code&gt;dotnet tool exec&lt;/code&gt;and the new&lt;code&gt;dnx&lt;/code&gt;script&lt;/item&gt;&lt;item&gt;CLI introspection with &lt;code&gt;--cli-schema&lt;/code&gt;for machine-readable command descriptions&lt;/item&gt;&lt;item&gt;Platform-specific .NET tools supporting multiple RuntimeIdentifiers with self-contained, trimmed, and AOT options&lt;/item&gt;&lt;item&gt;Enhanced file-based apps with publish and native AOT support&lt;/item&gt;&lt;item&gt;SLNX solution format: Simplified, XML-based solution files that are human-readable and easier to manage. Learn more about SLNX&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;NuGet – Enhanced Security and Productivity&lt;/head&gt;&lt;p&gt;NuGet continues to evolve with security and productivity improvements:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Enhanced security: Audit transitive dependencies by default for .NET 10 projects, integration with GitHub Advisory Database, and Dependabot support for automatic security updates&lt;/item&gt;&lt;item&gt;MCP support: Publish and consume MCP servers via NuGet&lt;/item&gt;&lt;item&gt;New NuGet.org: Fresh design with dark mode&lt;/item&gt;&lt;item&gt;Vulnerability remediation: &lt;code&gt;dotnet package update --vulnerable&lt;/code&gt;command updates vulnerable packages to first secure version&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Learn more in the .NET SDK documentation and NuGet package auditing improvements.&lt;/p&gt;&lt;head rend="h2"&gt;.NET 10 Long Term Support&lt;/head&gt;&lt;p&gt;.NET 10 is a Long Term Support (LTS) release and will be supported for three years, until November 10, 2028. LTS releases receive critical updates and security patches, making .NET 10 the recommended version for production applications that require stability and extended support.&lt;/p&gt;&lt;p&gt;.NET follows a predictable annual release cadence with even-numbered LTS releases (3-year support) and odd-numbered Standard Term Support (STS) releases (24-month support). With the recent extension of STS support from 18 to 24 months, both .NET 9 and .NET 8 will reach end of support on November 10, 2026. .NET 10, as an LTS release, will continue to be supported until November 10, 2028.&lt;/p&gt;&lt;p&gt;For complete details on the .NET support policy and release schedule, visit the .NET support policy page.&lt;/p&gt;&lt;head rend="h2"&gt;Get Started with .NET 10&lt;/head&gt;&lt;p&gt;.NET 10 and Visual Studio 2026 are available now. Get started today:&lt;/p&gt;&lt;p&gt;Learn more:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;What’s new in .NET 10: Runtime, Libraries, SDK&lt;/item&gt;&lt;item&gt;What’s new in C# 14&lt;/item&gt;&lt;item&gt;What’s new in F# 10&lt;/item&gt;&lt;item&gt;What’s new in ASP.NET Core&lt;/item&gt;&lt;item&gt;What’s new in Aspire&lt;/item&gt;&lt;item&gt;AI in .NET&lt;/item&gt;&lt;item&gt;What’s new in .NET MAUI&lt;/item&gt;&lt;item&gt;What’s new in EF Core&lt;/item&gt;&lt;item&gt;Windows App SDK release notes&lt;/item&gt;&lt;item&gt;Visual Studio 2026 release notes&lt;/item&gt;&lt;/list&gt;&lt;p&gt;We can’t wait to see what you build with .NET 10!&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45888620</guid><pubDate>Tue, 11 Nov 2025 15:44:35 +0000</pubDate></item><item><title>FFmpeg to Google: Fund us or stop sending bugs</title><link>https://thenewstack.io/ffmpeg-to-google-fund-us-or-stop-sending-bugs/</link><description>&lt;doc fingerprint="3772b5d090a791bc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;FFmpeg to Google: Fund Us or Stop Sending Bugs&lt;/head&gt;
    &lt;p&gt;You may never have heard of FFmpeg, but you’ve used it. This open source program’s robust multimedia framework is used to process video and audio media files and streams across numerous platforms and devices. It provides tools and libraries for format conversion, aka transcoding, playback, editing, streaming, and post-production effects for both audio and video media.&lt;/p&gt;
    &lt;p&gt;FFmpeg’s libraries, such as libavcodec and libavformat, are essential for media players and software, including VLC, Kodi, Plex, Google Chrome, Firefox, and even YouTube’s video processing backend. It is also, like many other vital open source programs, terribly underfunded.&lt;/p&gt;
    &lt;head rend="h2"&gt;Corporate Responsibility vs. Volunteer Labor&lt;/head&gt;
    &lt;p&gt;A lively debate on Twitter began between Dan Lorenc, CEO and co-founder of Chainguard, the software supply chain security company, the FFmpeg project, Google, and security researchers over security disclosures and the responsibilities of large tech companies in open-source software.&lt;/p&gt;
    &lt;p&gt;The core of the discussion revolves around how vulnerabilities should be reported, who is responsible for fixing them, and the challenges that arise when AI is used to uncover a flood of potentially meaningless security issues. But at heart, it’s about money.&lt;/p&gt;
    &lt;head rend="h2"&gt;An Obscure Bug Ignites the Controversy&lt;/head&gt;
    &lt;p&gt;This discussion has been heating up for some time. In mid-October, FFmpeg tweeted that “security issues are taken extremely seriously in FFmpeg, but fixes are written by volunteers.” This point cannot be emphasised enough. As FFmpeg tweeted later, “FFmpeg is written almost exclusively by volunteers.”&lt;/p&gt;
    &lt;p&gt;Thus, as Mark Atwood, an open source policy expert, pointed out on Twitter, he had to keep telling Amazon to not do things that would mess up FFmpeg because, he had to keep explaining to his bosses that “They are not a vendor, there is no NDA, we have no leverage, your VP has refused to help fund them, and they could kill three major product lines tomorrow with an email. So, stop, and listen to me … ”&lt;/p&gt;
    &lt;head rend="h2"&gt;The Growing Burden on Open Source Maintainers&lt;/head&gt;
    &lt;p&gt;The latest episode was sparked after a Google AI agent found an especially obscure bug in FFmpeg. How obscure? This “medium impact issue in ffmpeg,” which the FFmpeg developers did patch, is “an issue with decoding LucasArts Smush codec, specifically the first 10-20 frames of Rebel Assault 2, a game from 1995.”&lt;/p&gt;
    &lt;p&gt;Wow.&lt;/p&gt;
    &lt;p&gt;FFmpeg added, “FFmpeg aims to play every video file ever made.” That’s all well and good, but is that a valuable use of an assembly programmer’s time? Oh, right, you may not know. FFmpeg’s heart is assembly language. As a former assembly language programmer, it is not, in any way, shape, or form, easy to work with.&lt;/p&gt;
    &lt;p&gt;As FFmpeg put it, this is “CVE slop.”&lt;/p&gt;
    &lt;p&gt;Many in the FFmpeg community argue, with reason, that it is unreasonable for a trillion-dollar corporation like Google, which heavily relies on FFmpeg in its products, to shift the workload of fixing vulnerabilities to unpaid volunteers. They believe Google should either provide patches with vulnerability reports or directly support the project’s maintenance.&lt;/p&gt;
    &lt;p&gt;Earlier, FFmpeg pointed out that it’s far from the only open source project to face such issues.&lt;/p&gt;
    &lt;p&gt;Specifically, the project team mentions Nick Wellnhofer, the former maintainer of libxml2, a widely used open source software library for parsing Extensible Markup Language (XML). Wellnhofer recently resigned from maintaining libxml2 because he had to “spend several hours each week dealing with security issues reported by third parties. Most of these issues aren’t critical, but it’s still a lot of work.&lt;/p&gt;
    &lt;p&gt;“In the long term, this is unsustainable for an unpaid volunteer like me. … In the long run, putting such demands on OSS maintainers without compensating them is detrimental. … It’s even more unlikely with Google Project Zero, the best white-hat security researchers money can buy, breathing down the necks of volunteers.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Google’s Controversial Security Disclosure Policy&lt;/head&gt;
    &lt;p&gt;What made this a hot issue was that back in July, Google Project Zero (GPZ) announced a trial of its new Reporting Transparency policy. With this policy change, GPZ announces that it has reported an issue on a specific project within a week of discovery, and the security standard 90-day disclosure clock then starts, regardless of whether a patch is available or not.&lt;/p&gt;
    &lt;p&gt;Many volunteer open source program maintainers and developers feel this is massively unfair to put them under such pressure when Google has billions to address the problem.&lt;/p&gt;
    &lt;p&gt;FFmpeg tweeted, “We take security very seriously, but at the same time, is it really fair that trillion-dollar corporations run AI to find security issues in people’s hobby code? Then expect volunteers to fix.”&lt;/p&gt;
    &lt;p&gt;True, Google does offer a Patch Rewards Program, but as a Twitter user using the handle Ignix The Salamander observed, “FFmpeg already mentioned the program is too limited for them, and they point out the three patches per month limit. Please don’t assume people complain just for the sake of complaining, there is a genuine conflict between corporate security &amp;amp; usage vs open source support IMHO.”&lt;/p&gt;
    &lt;p&gt;Lorenc argues back, in an e-mail to me, that “Creating and publishing software under an open source license is an act of contribution to the digital commons. Finding and publishing information about security issues in that software is also an act of contribution to the same commons.&lt;/p&gt;
    &lt;p&gt;“The position of the FFmpeg X account is that somehow disclosing vulnerabilities is a bad thing. Google provides more assistance to open source software projects than almost any other organization, and these debates are more likely to drive away potential sponsors than to attract them.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Differing Perspectives on Vulnerability Disclosures&lt;/head&gt;
    &lt;p&gt;The fundamental problem remains that the FFmpeg team lacks the financial and developer resources to address a flood of AI-created CVEs.&lt;/p&gt;
    &lt;p&gt;On the other hand, security experts are certainly right in thinking that FFmpeg is a critical part of the Internet’s technology framework and that security issues do need to be made public responsibly and addressed. After all, hackers can use AI to find vulnerabilities in the same way Google does with its AI bug finder, Big Sleep, and Google wants to identify potential security holes ahead of them.&lt;/p&gt;
    &lt;p&gt;The reality is, however, that without more support from the trillion-dollar companies that profit from open source, many woefully underfunded, volunteer-driven critical open-source projects will no longer be maintained at all.&lt;/p&gt;
    &lt;p&gt;For example, Wellnhofer has said he will no longer maintain libxml2 in December. Libxml2 is a critical library in all web browsers, web servers, LibreOffice and numerous Linux packages. We don’t need any more arguments; we need real support for critical open source programs before we have another major security breach.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45891016</guid><pubDate>Tue, 11 Nov 2025 18:32:11 +0000</pubDate></item><item><title>A modern 35mm film scanner for home</title><link>https://www.soke.engineering/</link><description>&lt;doc fingerprint="4d1a5a5e7b33d889"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The New Era of &lt;lb/&gt;Film Scanning&lt;/head&gt;
    &lt;head rend="h2"&gt;The New Era of &lt;lb/&gt;Film Scanning&lt;/head&gt;
    &lt;head rend="h2"&gt;Knokke - a high-resolution 35 mm film scanner built for photographers who demand speed, quality and control.&lt;/head&gt;
    &lt;head rend="h2"&gt;The New Era of &lt;lb/&gt;Film Scanning&lt;/head&gt;
    &lt;head rend="h2"&gt;Knokke - a high-resolution 35 mm film scanner built for photographers who demand speed, quality, and control.&lt;/head&gt;
    &lt;head rend="h2"&gt;Knokke redefines film scanning by bringing modern imaging, optics, and software into a beautifully engineered device.&lt;/head&gt;
    &lt;head rend="h3"&gt;4064&lt;/head&gt;
    &lt;head rend="h3"&gt;4064&lt;/head&gt;
    &lt;head rend="h3"&gt;DPI Resolution&lt;/head&gt;
    &lt;head rend="h3"&gt;DPI Resolution&lt;/head&gt;
    &lt;head rend="h3"&gt;120 dB&lt;/head&gt;
    &lt;head rend="h3"&gt;120 dB&lt;/head&gt;
    &lt;head rend="h3"&gt;Dynamic Range&lt;/head&gt;
    &lt;head rend="h3"&gt;Dynamic Range&lt;/head&gt;
    &lt;head rend="h3"&gt;48-bit&lt;/head&gt;
    &lt;head rend="h3"&gt;48-bit&lt;/head&gt;
    &lt;head rend="h3"&gt;True Color&lt;/head&gt;
    &lt;head rend="h3"&gt;True Color&lt;/head&gt;
    &lt;head rend="h2"&gt;Knokke - State-of-the-Art Hardware&lt;/head&gt;
    &lt;head rend="h3"&gt;Knokke - State-of-the-Art Hardware&lt;/head&gt;
    &lt;head rend="h2"&gt;Knokke - State-of-the-Art Hardware&lt;/head&gt;
    &lt;p&gt;The modern 35 mm film scanner that captures a full roll in under just a few minutes while capturing every frame at 4064 DPI and 48bit colour. Its custom optics and state-of-the-art sensor deliver benchmark setting quality and speed at a price only Knokke can offer.&lt;/p&gt;
    &lt;p&gt;Launch Updates&lt;/p&gt;
    &lt;p&gt;Launch Updates&lt;/p&gt;
    &lt;p&gt;Launch Updates&lt;/p&gt;
    &lt;p&gt;A Modern Workflow&lt;/p&gt;
    &lt;p&gt;A Modern Workflow&lt;/p&gt;
    &lt;p&gt;A Modern Workflow&lt;/p&gt;
    &lt;head rend="h2"&gt;Korova - Custom Software&lt;/head&gt;
    &lt;head rend="h3"&gt;Korova - Custom Software&lt;/head&gt;
    &lt;head rend="h2"&gt;Korova - Custom Software&lt;/head&gt;
    &lt;p&gt;Built for the 21st century, Knokke runs on Korova, a lean C++ application that's native to Linux, macOS, and Windowsâso you can forget vintage PCs and enjoy a plug-and-play workflow that lets you focus on your photos.&lt;/p&gt;
    &lt;p&gt;Each frame can have custom scan settings, repeatable across multiple scans for consistent results and tailored workflows. The scanner can also skip directly to requested frames, massively accelerating scanning time and enabling fast access to key shots without unnecessary delay.&lt;/p&gt;
    &lt;p&gt;Launch Updates&lt;/p&gt;
    &lt;p&gt;Launch Updates&lt;/p&gt;
    &lt;p&gt;Launch Updates&lt;/p&gt;
    &lt;head rend="h3"&gt;Engineered for Individual Users and Lab Professionals&lt;/head&gt;
    &lt;head rend="h6"&gt;01&lt;/head&gt;
    &lt;head rend="h6"&gt;Quality&lt;/head&gt;
    &lt;p&gt;Knokkeâs premium build and precision engineering ensure lasting, reliable performance.&lt;/p&gt;
    &lt;head rend="h6"&gt;02&lt;/head&gt;
    &lt;head rend="h6"&gt;Speed&lt;/head&gt;
    &lt;p&gt;Knokkeâs high scan speed and streamlined workflow keep you moving.&lt;/p&gt;
    &lt;head rend="h6"&gt;03&lt;/head&gt;
    &lt;head rend="h6"&gt;Full Control&lt;/head&gt;
    &lt;p&gt;Knokke lets you fine-tune every detail with flexible settings and precise color control.&lt;/p&gt;
    &lt;head rend="h6"&gt;04&lt;/head&gt;
    &lt;head rend="h6"&gt;Future Proof&lt;/head&gt;
    &lt;p&gt;Knokke comes with ongoing software support, open-source flexibility, and readily available spare parts.&lt;/p&gt;
    &lt;head rend="h2"&gt;Price at Launch&lt;/head&gt;
    &lt;head rend="h2"&gt;999â¬&lt;/head&gt;
    &lt;p&gt;Includes scanner + software&lt;/p&gt;
    &lt;head rend="h2"&gt;4064 dpi resolution&lt;/head&gt;
    &lt;head rend="h2"&gt;5 min per roll&lt;/head&gt;
    &lt;head rend="h2"&gt;48-bit colour depth&lt;/head&gt;
    &lt;head rend="h2"&gt;120 dB Dynamic Range&lt;/head&gt;
    &lt;head rend="h2"&gt;LED Matrix&lt;/head&gt;
    &lt;head rend="h2"&gt;RGB LED backlight&lt;/head&gt;
    &lt;head rend="h2"&gt;USB-C 3.2&lt;/head&gt;
    &lt;head rend="h2"&gt;Custom software&lt;/head&gt;
    &lt;head rend="h2"&gt;A Closer Look at Knokke&lt;/head&gt;
    &lt;head rend="h2"&gt;A Closer Look at Knokke&lt;/head&gt;
    &lt;head rend="h2"&gt;A Closer Look at Knokke&lt;/head&gt;
    &lt;head rend="h2"&gt;Specifications.&lt;/head&gt;
    &lt;head rend="h2"&gt;Specifications.&lt;/head&gt;
    &lt;head rend="h3"&gt;IMAGING SYSTEM&lt;/head&gt;
    &lt;p&gt;SENSOR&lt;/p&gt;
    &lt;p&gt;Backside illumintaed CMOS Sensor&lt;/p&gt;
    &lt;p&gt;DYNAMIC RANGE&lt;/p&gt;
    &lt;p&gt;linear dynamic range of 78 dB, expandable to 120 dB with native 16-bit HDR log profile, up to 14 stops of range&lt;/p&gt;
    &lt;p&gt;RESOLUTION&lt;/p&gt;
    &lt;p&gt;Max. 4064 dpi (~22 MP), 2032 dpi (~5,5MP)&lt;/p&gt;
    &lt;p&gt;LENS&lt;/p&gt;
    &lt;p&gt;Custom 4 element lens with high MTF (modulation transfer function)&lt;/p&gt;
    &lt;p&gt;LIGHT SOURCE&lt;/p&gt;
    &lt;p&gt;RGB LED backlight&lt;/p&gt;
    &lt;head rend="h3"&gt;IMAGING SYSTEM&lt;/head&gt;
    &lt;p&gt;SENSOR&lt;/p&gt;
    &lt;p&gt;Backside illumintaed CMOS Sensor&lt;/p&gt;
    &lt;p&gt;DYNAMIC RANGE&lt;/p&gt;
    &lt;p&gt;linear dynamic range of 78 dB, expandable to 120 dB with native 16-bit HDR log profile, up to 14 stops of range&lt;/p&gt;
    &lt;p&gt;RESOLUTION&lt;/p&gt;
    &lt;p&gt;Max. 4064 dpi (~22 MP), 2032 dpi (~5,5MP)&lt;/p&gt;
    &lt;p&gt;LENS&lt;/p&gt;
    &lt;p&gt;Custom 4 element lens with high MTF (modulation transfer function)&lt;/p&gt;
    &lt;p&gt;LIGHT SOURCE&lt;/p&gt;
    &lt;p&gt;RGB LED backlight&lt;/p&gt;
    &lt;head rend="h3"&gt;PERFORMANCE &amp;amp; WORKFLOW&lt;/head&gt;
    &lt;p&gt;Scan Speed&lt;/p&gt;
    &lt;p&gt;per roll under 5 minutes (4064 dpi), under 2 minutes (2032 dpi)&lt;/p&gt;
    &lt;p&gt;FILM TRANSPORT&lt;/p&gt;
    &lt;p&gt;automated, min. strip length 3 images&lt;/p&gt;
    &lt;p&gt;FRAME CONTROL&lt;/p&gt;
    &lt;p&gt;per-frame scan settings, skip directly to any frame&lt;/p&gt;
    &lt;p&gt;DXN DECODER&lt;/p&gt;
    &lt;p&gt;reads 35 mm DX codes, embeds film type, ISO, roll info into metadata&lt;/p&gt;
    &lt;p&gt;SOFTWARE&lt;/p&gt;
    &lt;p&gt;Korova (native for Windows, macOS, Linux)&lt;/p&gt;
    &lt;p&gt;FILE FORMATS&lt;/p&gt;
    &lt;p&gt;RAW, TIFF, DNG linear, JPEG, PNG, BMP, HDR&lt;/p&gt;
    &lt;p&gt;FILE SIZES&lt;/p&gt;
    &lt;p&gt;RAW/TIFF/DNG linear ~127 MB; JPEG XL (lossless) 42â52 MB; PNG 106â118 MB&lt;/p&gt;
    &lt;head rend="h3"&gt;PERFORMANCE &amp;amp; WORKFLOW&lt;/head&gt;
    &lt;p&gt;Scan Speed&lt;/p&gt;
    &lt;p&gt;per roll under 5 minutes (4064 dpi), under 2 minutes (2032 dpi)&lt;/p&gt;
    &lt;p&gt;FILM TRANSPORT&lt;/p&gt;
    &lt;p&gt;automated, min. strip length 3 images&lt;/p&gt;
    &lt;p&gt;FRAME CONTROL&lt;/p&gt;
    &lt;p&gt;per-frame scan settings, skip directly to any frame&lt;/p&gt;
    &lt;p&gt;DXN DECODER&lt;/p&gt;
    &lt;p&gt;reads 35 mm DX codes, embeds film type, ISO, roll info into metadata&lt;/p&gt;
    &lt;p&gt;SOFTWARE&lt;/p&gt;
    &lt;p&gt;Korova (native for Windows, macOS, Linux)&lt;/p&gt;
    &lt;p&gt;FILE FORMATS&lt;/p&gt;
    &lt;p&gt;RAW, TIFF, DNG linear, JPEG, PNG, BMP, HDR&lt;/p&gt;
    &lt;p&gt;FILE SIZES&lt;/p&gt;
    &lt;p&gt;RAW/TIFF/DNG linear ~127 MB; JPEG XL (lossless) 42â52 MB; PNG 106â118 MB&lt;/p&gt;
    &lt;head rend="h3"&gt;HARDWARE&lt;/head&gt;
    &lt;p&gt;DIMENSIONS&lt;/p&gt;
    &lt;p&gt;250 Ã 150 Ã 63 mm&lt;/p&gt;
    &lt;p&gt;WEIGHT&lt;/p&gt;
    &lt;p&gt;1400 grams&lt;/p&gt;
    &lt;p&gt;INTERFACE&lt;/p&gt;
    &lt;p&gt;USB-C (USB 3.1)&lt;/p&gt;
    &lt;p&gt;POWER SUPPLY&lt;/p&gt;
    &lt;p&gt;18 V DC, 2 A (included)&lt;/p&gt;
    &lt;head rend="h3"&gt;HARDWARE&lt;/head&gt;
    &lt;p&gt;DIMENSIONS&lt;/p&gt;
    &lt;p&gt;250 Ã 150 Ã 63 mm&lt;/p&gt;
    &lt;p&gt;WEIGHT&lt;/p&gt;
    &lt;p&gt;1400 grams&lt;/p&gt;
    &lt;p&gt;INTERFACE&lt;/p&gt;
    &lt;p&gt;USB-C (USB 3.1)&lt;/p&gt;
    &lt;p&gt;POWER SUPPLY&lt;/p&gt;
    &lt;p&gt;18 V DC, 2 A (included)&lt;/p&gt;
    &lt;head rend="h2"&gt;Price at Launch&lt;/head&gt;
    &lt;head rend="h2"&gt;999â¬&lt;/head&gt;
    &lt;p&gt;Includes scanner + software&lt;/p&gt;
    &lt;head rend="h2"&gt;4064 dpi resolution&lt;/head&gt;
    &lt;head rend="h2"&gt;5 min per roll&lt;/head&gt;
    &lt;head rend="h2"&gt;48-bit colour depth&lt;/head&gt;
    &lt;head rend="h2"&gt;120 dB Dynamic Range&lt;/head&gt;
    &lt;head rend="h2"&gt;LED Matrix&lt;/head&gt;
    &lt;head rend="h2"&gt;RGB LED backlight&lt;/head&gt;
    &lt;head rend="h2"&gt;USB-C 3.2&lt;/head&gt;
    &lt;head rend="h2"&gt;Custom software&lt;/head&gt;
    &lt;head rend="h2"&gt;Frequently &lt;lb/&gt;Asked &lt;lb/&gt;Questions.&lt;/head&gt;
    &lt;p&gt;Will Knokke support 120 film, panoramic formats, or border scanning?&lt;/p&gt;
    &lt;p&gt;Knokke fully supports any frame width on 35 mm (135) film, thanks to automatic edge detection. It can also perform partial border scans to preserve maximum resolution and frame content. (120 film support is not part of the first release but is under consideration for the future.)&lt;/p&gt;
    &lt;p&gt;What kind of light source and sensor does Knokke use?&lt;/p&gt;
    &lt;p&gt;Knokke uses an RGB LED backlight, precisely wavelength-matched to a modern backside-illuminated CMOS sensor. The sensor features 2 Î¼m pixels and delivers a 78 dB linear dynamic range in 12-bit mode, expandable to 120 dB (â 14 stops) with the 3-step HDR log mode at native 16-bit output. This combination ensures accurate colour reproduction, tonal smoothness, and detail retention in both highlights and shadows.&lt;/p&gt;
    &lt;p&gt;What makes Knokke different from other scanners like the Fuji Frontier, Nikon Coolscan, or camera-stand setups?&lt;/p&gt;
    &lt;p&gt;Knokke combines speed, scanning quality, and ease of use in a compact form factor. It scans a full 35 mm roll in under 5 minutes, offers per-frame customisation, and requires no legacy computer hardware or drivers.&lt;/p&gt;
    &lt;p&gt;Will example scans be shared before launch?&lt;/p&gt;
    &lt;p&gt;Yes. Weâre collaborating with several film labs in Berlin to benchmark Knokke against Fuji Frontier and Noritsu scanners. Sample results will be published before the Kickstarter campaign, so you can make a fully informed decision.&lt;/p&gt;
    &lt;p&gt;Is the software open source?&lt;/p&gt;
    &lt;p&gt;Yes. Our control application, Korova, will be fully open source and maintained long term. Itâs a native, lightweight application for Windows, macOS, and Linux.&lt;/p&gt;
    &lt;p&gt;How much is Knokke going to cost?&lt;/p&gt;
    &lt;p&gt;Knokke will cost 999â¬ at launch. We are still working on bringing the price down further threw optimising design and sourcing. It's final retail price is set at 1599â¬.&lt;/p&gt;
    &lt;p&gt;Is Knokke open, repairable, and long-term supported?&lt;/p&gt;
    &lt;p&gt;Absolutely. Weâre committed to building a scanner that lasts decades. All schematics and repair manuals will be publicly available, replacement parts can be purchased directly, and the software will remain supported for as long as possible.&lt;/p&gt;
    &lt;p&gt;When will Knokke be available?&lt;/p&gt;
    &lt;p&gt;Knokke will launch on Kickstarter.com in Q1 2026. Follow us on Instagram and subscribe to our newsletter to be among the first notified about updates.&lt;/p&gt;
    &lt;p&gt;Can I become a beta tester?&lt;/p&gt;
    &lt;p&gt;Thank you for your interest! Weâve received an incredible number of requests to join our beta testing program. Weâll be running two separate testing rounds - one in collaboration with selected creators and film labs, and another open to members of our community.&lt;/p&gt;
    &lt;p&gt;Will Knokke support 120 film, panoramic formats, or border scanning?&lt;/p&gt;
    &lt;p&gt;Knokke fully supports any frame width on 35 mm (135) film, thanks to automatic edge detection. It can also perform partial border scans to preserve maximum resolution and frame content. (120 film support is not part of the first release but is under consideration for the future.)&lt;/p&gt;
    &lt;p&gt;What kind of light source and sensor does Knokke use?&lt;/p&gt;
    &lt;p&gt;Knokke uses an RGB LED backlight, precisely wavelength-matched to a modern backside-illuminated CMOS sensor. The sensor features 2 Î¼m pixels and delivers a 78 dB linear dynamic range in 12-bit mode, expandable to 120 dB (â 14 stops) with the 3-step HDR log mode at native 16-bit output. This combination ensures accurate colour reproduction, tonal smoothness, and detail retention in both highlights and shadows.&lt;/p&gt;
    &lt;p&gt;What makes Knokke different from other scanners like the Fuji Frontier, Nikon Coolscan, or camera-stand setups?&lt;/p&gt;
    &lt;p&gt;Knokke combines speed, scanning quality, and ease of use in a compact form factor. It scans a full 35 mm roll in under 5 minutes, offers per-frame customisation, and requires no legacy computer hardware or drivers.&lt;/p&gt;
    &lt;p&gt;Will example scans be shared before launch?&lt;/p&gt;
    &lt;p&gt;Yes. Weâre collaborating with several film labs in Berlin to benchmark Knokke against Fuji Frontier and Noritsu scanners. Sample results will be published before the Kickstarter campaign, so you can make a fully informed decision.&lt;/p&gt;
    &lt;p&gt;Is the software open source?&lt;/p&gt;
    &lt;p&gt;Yes. Our control application, Korova, will be fully open source and maintained long term. Itâs a native, lightweight application for Windows, macOS, and Linux.&lt;/p&gt;
    &lt;p&gt;How much is Knokke going to cost?&lt;/p&gt;
    &lt;p&gt;Knokke will cost 999â¬ at launch. We are still working on bringing the price down further threw optimising design and sourcing. It's final retail price is set at 1599â¬.&lt;/p&gt;
    &lt;p&gt;Is Knokke open, repairable, and long-term supported?&lt;/p&gt;
    &lt;p&gt;Absolutely. Weâre committed to building a scanner that lasts decades. All schematics and repair manuals will be publicly available, replacement parts can be purchased directly, and the software will remain supported for as long as possible.&lt;/p&gt;
    &lt;p&gt;When will Knokke be available?&lt;/p&gt;
    &lt;p&gt;Knokke will launch on Kickstarter.com in Q1 2026. Follow us on Instagram and subscribe to our newsletter to be among the first notified about updates.&lt;/p&gt;
    &lt;p&gt;Can I become a beta tester?&lt;/p&gt;
    &lt;p&gt;Thank you for your interest! Weâve received an incredible number of requests to join our beta testing program. Weâll be running two separate testing rounds - one in collaboration with selected creators and film labs, and another open to members of our community.&lt;/p&gt;
    &lt;head rend="h2"&gt;999â¬&lt;/head&gt;
    &lt;p&gt;Includes scanner + software&lt;/p&gt;
    &lt;head rend="h2"&gt;4064 dpi resolution&lt;/head&gt;
    &lt;head rend="h2"&gt;5 min per roll&lt;/head&gt;
    &lt;head rend="h2"&gt;48-bit colour depth&lt;/head&gt;
    &lt;head rend="h2"&gt;120 dB Dynamic Range&lt;/head&gt;
    &lt;head rend="h2"&gt;LED Matrix&lt;/head&gt;
    &lt;head rend="h2"&gt;RGB LED backlight&lt;/head&gt;
    &lt;head rend="h2"&gt;USB-C 3.2&lt;/head&gt;
    &lt;head rend="h2"&gt;Custom software&lt;/head&gt;
    &lt;head rend="h2"&gt;Frequently Asked Questions.&lt;/head&gt;
    &lt;p&gt;Will Knokke support 120 film, panoramic formats, or border scanning?&lt;/p&gt;
    &lt;p&gt;Knokke fully supports any frame width on 35 mm (135) film, thanks to automatic edge detection. It can also perform partial border scans to preserve maximum resolution and frame content. (120 film support is not part of the first release but is under consideration for the future.)&lt;/p&gt;
    &lt;p&gt;What kind of light source and sensor does Knokke use?&lt;/p&gt;
    &lt;p&gt;Knokke uses an RGB LED backlight, precisely wavelength-matched to a modern backside-illuminated CMOS sensor. The sensor features 2 Î¼m pixels and delivers a 78 dB linear dynamic range in 12-bit mode, expandable to 120 dB (â 14 stops) with the 3-step HDR log mode at native 16-bit output. This combination ensures accurate colour reproduction, tonal smoothness, and detail retention in both highlights and shadows.&lt;/p&gt;
    &lt;p&gt;What makes Knokke different from other scanners like the Fuji Frontier, Nikon Coolscan, or camera-stand setups?&lt;/p&gt;
    &lt;p&gt;Knokke combines speed, scanning quality, and ease of use in a compact form factor. It scans a full 35 mm roll in under 5 minutes, offers per-frame customisation, and requires no legacy computer hardware or drivers.&lt;/p&gt;
    &lt;p&gt;Will example scans be shared before launch?&lt;/p&gt;
    &lt;p&gt;Yes. Weâre collaborating with several film labs in Berlin to benchmark Knokke against Fuji Frontier and Noritsu scanners. Sample results will be published before the Kickstarter campaign, so you can make a fully informed decision.&lt;/p&gt;
    &lt;p&gt;How much is Knokke going to cost?&lt;/p&gt;
    &lt;p&gt;Knokke will cost 999â¬ at launch. We are still working on bringing the price down further threw optimising design and sourcing. It's final retail price is set at 1599â¬.&lt;/p&gt;
    &lt;p&gt;Is the software open source?&lt;/p&gt;
    &lt;p&gt;Yes. Our control application, Korova, will be fully open source and maintained long term. Itâs a native, lightweight application for Windows, macOS, and Linux.&lt;/p&gt;
    &lt;p&gt;Is Knokke open, repairable, and long-term supported?&lt;/p&gt;
    &lt;p&gt;Absolutely. Weâre committed to building a scanner that lasts decades. All schematics and repair manuals will be publicly available, replacement parts can be purchased directly, and the software will remain supported for as long as possible.&lt;/p&gt;
    &lt;p&gt;When will Knokke be available?&lt;/p&gt;
    &lt;p&gt;Knokke will launch on Kickstarter.com in Q1 2026. Follow us on Instagram and subscribe to our newsletter to be among the first notified about updates.&lt;/p&gt;
    &lt;p&gt;Can I become a beta tester?&lt;/p&gt;
    &lt;p&gt;Knokke will launch on Kickstarter in Q1 2026. Follow us on Instagram or subscribe to our newsletter to be among the first notified when pre-orders open.&lt;/p&gt;
    &lt;p&gt;Will Knokke support 120 film, panoramic formats, or border scanning?&lt;/p&gt;
    &lt;p&gt;Knokke fully supports any frame width on 35 mm (135) film, thanks to automatic edge detection. It can also perform partial border scans to preserve maximum resolution and frame content. (120 film support is not part of the first release but is under consideration for the future.)&lt;/p&gt;
    &lt;p&gt;What kind of light source and sensor does Knokke use?&lt;/p&gt;
    &lt;p&gt;Knokke uses an RGB LED backlight, precisely wavelength-matched to a modern backside-illuminated CMOS sensor. The sensor features 2 Î¼m pixels and delivers a 78 dB linear dynamic range in 12-bit mode, expandable to 120 dB (â 14 stops) with the 3-step HDR log mode at native 16-bit output. This combination ensures accurate colour reproduction, tonal smoothness, and detail retention in both highlights and shadows.&lt;/p&gt;
    &lt;p&gt;What makes Knokke different from other scanners like the Fuji Frontier, Nikon Coolscan, or camera-stand setups?&lt;/p&gt;
    &lt;p&gt;Knokke combines speed, scanning quality, and ease of use in a compact form factor. It scans a full 35 mm roll in under 5 minutes, offers per-frame customisation, and requires no legacy computer hardware or drivers.&lt;/p&gt;
    &lt;p&gt;Will example scans be shared before launch?&lt;/p&gt;
    &lt;p&gt;Yes. Weâre collaborating with several film labs in Berlin to benchmark Knokke against Fuji Frontier and Noritsu scanners. Sample results will be published before the Kickstarter campaign, so you can make a fully informed decision.&lt;/p&gt;
    &lt;p&gt;How much is Knokke going to cost?&lt;/p&gt;
    &lt;p&gt;Knokke will cost 999â¬ at launch. We are still working on bringing the price down further threw optimising design and sourcing. It's final retail price is set at 1599â¬.&lt;/p&gt;
    &lt;p&gt;Is the software open source?&lt;/p&gt;
    &lt;p&gt;Yes. Our control application, Korova, will be fully open source and maintained long term. Itâs a native, lightweight application for Windows, macOS, and Linux.&lt;/p&gt;
    &lt;p&gt;Is Knokke open, repairable, and long-term supported?&lt;/p&gt;
    &lt;p&gt;Absolutely. Weâre committed to building a scanner that lasts decades. All schematics and repair manuals will be publicly available, replacement parts can be purchased directly, and the software will remain supported for as long as possible.&lt;/p&gt;
    &lt;p&gt;When will Knokke be available?&lt;/p&gt;
    &lt;p&gt;Knokke will launch on Kickstarter.com in Q1 2026. Follow us on Instagram and subscribe to our newsletter to be among the first notified about updates.&lt;/p&gt;
    &lt;p&gt;Can I become a beta tester?&lt;/p&gt;
    &lt;p&gt;Knokke will launch on Kickstarter in Q1 2026. Follow us on Instagram or subscribe to our newsletter to be among the first notified when pre-orders open.&lt;/p&gt;
    &lt;head rend="h4"&gt;Engineered for individual and lab use&lt;/head&gt;
    &lt;head rend="h6"&gt;01&lt;/head&gt;
    &lt;head rend="h6"&gt;Quality&lt;/head&gt;
    &lt;p&gt;Knokkeâs premium build and precision engineering ensure lasting, reliable performance.&lt;/p&gt;
    &lt;head rend="h6"&gt;01&lt;/head&gt;
    &lt;head rend="h6"&gt;Quality&lt;/head&gt;
    &lt;p&gt;Knokkeâs premium build and precision engineering ensure lasting, reliable performance.&lt;/p&gt;
    &lt;head rend="h6"&gt;02&lt;/head&gt;
    &lt;head rend="h6"&gt;Speed&lt;/head&gt;
    &lt;p&gt;Knokkeâs high scan speed and streamlined workflow keep you moving.&lt;/p&gt;
    &lt;head rend="h6"&gt;02&lt;/head&gt;
    &lt;head rend="h6"&gt;Speed&lt;/head&gt;
    &lt;p&gt;Knokkeâs high scan speed and streamlined workflow keep you moving.&lt;/p&gt;
    &lt;head rend="h6"&gt;03&lt;/head&gt;
    &lt;head rend="h6"&gt;Full Control&lt;/head&gt;
    &lt;p&gt;Knokke lets you fine-tune every detail with flexible settings and precise color control.&lt;/p&gt;
    &lt;head rend="h6"&gt;03&lt;/head&gt;
    &lt;head rend="h6"&gt;Full Control&lt;/head&gt;
    &lt;p&gt;Knokke lets you fine-tune every detail with flexible settings and precise color control.&lt;/p&gt;
    &lt;head rend="h6"&gt;04&lt;/head&gt;
    &lt;head rend="h6"&gt;Future Proof&lt;/head&gt;
    &lt;p&gt;Knokke comes with ongoing software support, open-source flexibility, and readily available spare parts.&lt;/p&gt;
    &lt;head rend="h6"&gt;04&lt;/head&gt;
    &lt;head rend="h6"&gt;Future Proof&lt;/head&gt;
    &lt;p&gt;Knokke comes with ongoing software support, open-source flexibility, and readily available spare parts.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Closer Look at Knokke&lt;/head&gt;
    &lt;head rend="h2"&gt;A Closer Look at Knokke&lt;/head&gt;
    &lt;head rend="h2"&gt;Specifications.&lt;/head&gt;
    &lt;head rend="h2"&gt;Specifications.&lt;/head&gt;
    &lt;head rend="h3"&gt;IMAGING SYSTEM&lt;/head&gt;
    &lt;p&gt;SENSOR&lt;/p&gt;
    &lt;p&gt;Backside illuminated CMOS Sensor&lt;/p&gt;
    &lt;p&gt;DYNAMIC RANGE&lt;/p&gt;
    &lt;p&gt;linear dynamic range of 78 dB, expandable to 120 dB with native 16-bit HDR log profile, up to 14 stops of range&lt;/p&gt;
    &lt;p&gt;RESOLUTION&lt;/p&gt;
    &lt;p&gt;Max. 4064 dpi (~22 MP), 2032 dpi (~5,5MP)&lt;/p&gt;
    &lt;p&gt;LENS&lt;/p&gt;
    &lt;p&gt;Custom 4 element lens with high MTF (modulation transfer function)&lt;/p&gt;
    &lt;p&gt;LIGHT SOURCE&lt;/p&gt;
    &lt;p&gt;RGB LED backlight&lt;/p&gt;
    &lt;head rend="h3"&gt;IMAGING SYSTEM&lt;/head&gt;
    &lt;p&gt;SENSOR&lt;/p&gt;
    &lt;p&gt;Backside illuminated CMOS Sensor&lt;/p&gt;
    &lt;p&gt;DYNAMIC RANGE&lt;/p&gt;
    &lt;p&gt;linear dynamic range of 78 dB, expandable to 120 dB with native 16-bit HDR log profile, up to 14 stops of range&lt;/p&gt;
    &lt;p&gt;RESOLUTION&lt;/p&gt;
    &lt;p&gt;Max. 4064 dpi (~22 MP), 2032 dpi (~5,5MP)&lt;/p&gt;
    &lt;p&gt;LENS&lt;/p&gt;
    &lt;p&gt;Custom 4 element lens with high MTF (modulation transfer function)&lt;/p&gt;
    &lt;p&gt;LIGHT SOURCE&lt;/p&gt;
    &lt;p&gt;RGB LED backlight&lt;/p&gt;
    &lt;head rend="h3"&gt;PERFORMANCE &amp;amp; WORKFLOW&lt;/head&gt;
    &lt;p&gt;Scan Speed&lt;/p&gt;
    &lt;p&gt;per roll under 5 minutes (4064 dpi), under 2 minutes (2032 dpi)&lt;/p&gt;
    &lt;p&gt;FILM TRANSPORT&lt;/p&gt;
    &lt;p&gt;automated, min. strip length 3 images&lt;/p&gt;
    &lt;p&gt;FRAME CONTROL&lt;/p&gt;
    &lt;p&gt;per-frame scan settings, skip directly to any frame&lt;/p&gt;
    &lt;p&gt;DXN DECODER&lt;/p&gt;
    &lt;p&gt;reads 35 mm DX codes, embeds film type, ISO, roll info into metadata&lt;/p&gt;
    &lt;p&gt;SOFTWARE&lt;/p&gt;
    &lt;p&gt;Korova (native for Windows, macOS, Linux)&lt;/p&gt;
    &lt;p&gt;FILE FORMATS&lt;/p&gt;
    &lt;p&gt;RAW, TIFF, DNG linear, JPEG, PNG, BMP, HDR&lt;/p&gt;
    &lt;p&gt;FILE SIZES&lt;/p&gt;
    &lt;p&gt;RAW/TIFF/DNG linear ~127 MB; JPEG XL (lossless) 42â52 MB; PNG 106â118 MB&lt;/p&gt;
    &lt;head rend="h3"&gt;PERFORMANCE &amp;amp; WORKFLOW&lt;/head&gt;
    &lt;p&gt;Scan Speed&lt;/p&gt;
    &lt;p&gt;per roll under 5 minutes (4064 dpi), under 2 minutes (2032 dpi)&lt;/p&gt;
    &lt;p&gt;FILM TRANSPORT&lt;/p&gt;
    &lt;p&gt;automated, min. strip length 3 images&lt;/p&gt;
    &lt;p&gt;FRAME CONTROL&lt;/p&gt;
    &lt;p&gt;per-frame scan settings, skip directly to any frame&lt;/p&gt;
    &lt;p&gt;DXN DECODER&lt;/p&gt;
    &lt;p&gt;reads 35 mm DX codes, embeds film type, ISO, roll info into metadata&lt;/p&gt;
    &lt;p&gt;SOFTWARE&lt;/p&gt;
    &lt;p&gt;Korova (native for Windows, macOS, Linux)&lt;/p&gt;
    &lt;p&gt;FILE FORMATS&lt;/p&gt;
    &lt;p&gt;RAW, TIFF, DNG linear, JPEG, PNG, BMP, HDR&lt;/p&gt;
    &lt;p&gt;FILE SIZES&lt;/p&gt;
    &lt;p&gt;RAW/TIFF/DNG linear ~127 MB; JPEG XL (lossless) 42â52 MB; PNG 106â118 MB&lt;/p&gt;
    &lt;head rend="h3"&gt;HARDWARE&lt;/head&gt;
    &lt;p&gt;DIMENSIONS&lt;/p&gt;
    &lt;p&gt;250 Ã 150 Ã 63 mm&lt;/p&gt;
    &lt;p&gt;WEIGHT&lt;/p&gt;
    &lt;p&gt;1400 grams&lt;/p&gt;
    &lt;p&gt;INTERFACE&lt;/p&gt;
    &lt;p&gt;USB-C (USB 3.1)&lt;/p&gt;
    &lt;p&gt;POWER SUPPLY&lt;/p&gt;
    &lt;p&gt;18 V DC, 2 A (included)&lt;/p&gt;
    &lt;head rend="h3"&gt;HARDWARE&lt;/head&gt;
    &lt;p&gt;DIMENSIONS&lt;/p&gt;
    &lt;p&gt;250 Ã 150 Ã 63 mm&lt;/p&gt;
    &lt;p&gt;WEIGHT&lt;/p&gt;
    &lt;p&gt;1400 grams&lt;/p&gt;
    &lt;p&gt;INTERFACE&lt;/p&gt;
    &lt;p&gt;USB-C (USB 3.1)&lt;/p&gt;
    &lt;p&gt;POWER SUPPLY&lt;/p&gt;
    &lt;p&gt;18 V DC, 2 A (included)&lt;/p&gt;
    &lt;head rend="h3"&gt;Engineered for individual and lab use&lt;/head&gt;
    &lt;head rend="h6"&gt;01&lt;/head&gt;
    &lt;head rend="h6"&gt;Quality&lt;/head&gt;
    &lt;p&gt;Knokkeâs premium build and precision engineering ensure lasting, reliable performance.&lt;/p&gt;
    &lt;head rend="h6"&gt;01&lt;/head&gt;
    &lt;head rend="h6"&gt;Quality&lt;/head&gt;
    &lt;p&gt;Knokkeâs premium build and precision engineering ensure lasting, reliable performance.&lt;/p&gt;
    &lt;head rend="h6"&gt;02&lt;/head&gt;
    &lt;head rend="h6"&gt;Speed&lt;/head&gt;
    &lt;p&gt;Knokkeâs high scan speed and streamlined workflow keep you moving.&lt;/p&gt;
    &lt;head rend="h6"&gt;02&lt;/head&gt;
    &lt;head rend="h6"&gt;Speed&lt;/head&gt;
    &lt;p&gt;Knokkeâs high scan speed and streamlined workflow keep you moving.&lt;/p&gt;
    &lt;head rend="h6"&gt;03&lt;/head&gt;
    &lt;head rend="h6"&gt;Full Control&lt;/head&gt;
    &lt;p&gt;Knokke lets you fine-tune every detail with flexible settings and precise color control.&lt;/p&gt;
    &lt;head rend="h6"&gt;03&lt;/head&gt;
    &lt;head rend="h6"&gt;Full Control&lt;/head&gt;
    &lt;p&gt;Knokke lets you fine-tune every detail with flexible settings and precise color control.&lt;/p&gt;
    &lt;head rend="h6"&gt;04&lt;/head&gt;
    &lt;head rend="h6"&gt;Future Proof&lt;/head&gt;
    &lt;p&gt;Knokke comes with ongoing software support, open-source flexibility, and readily available spare parts.&lt;/p&gt;
    &lt;head rend="h6"&gt;04&lt;/head&gt;
    &lt;head rend="h6"&gt;Future Proof&lt;/head&gt;
    &lt;p&gt;Knokke comes with ongoing software support, open-source flexibility, and readily available spare parts.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45891907</guid><pubDate>Tue, 11 Nov 2025 19:48:19 +0000</pubDate></item><item><title>The terminal of the future</title><link>https://jyn.dev/the-terminal-of-the-future</link><description>&lt;doc fingerprint="37eac95c22846b89"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;the terminal of the future&lt;/head&gt;
    &lt;p&gt;This post is part 6 of a multi-part series called “the computer of the next 200 years”.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Terminal internals are a mess. A lot of it is just the way it is because someone made a decision in the 80s and now it’s impossible to change. —Julia Evans&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;This is what you have to do to redesign infrastructure. Rich [Hickey] didn't just pile some crap on top of Lisp [when building Clojure]. He took the entire Lisp and moved the whole design at once. —Gary Bernhardt&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;a mental model of a terminal&lt;/head&gt;
    &lt;p&gt;At a very very high level, a terminal has four parts:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The "terminal emulator", which is a program that renders a grid-like structure to your graphical display.&lt;/item&gt;
      &lt;item&gt;The "pseudo-terminal" (PTY), which is a connection between the terminal emulator and a "process group" which receives input. This is not a program. This is a piece of state in the kernel.&lt;/item&gt;
      &lt;item&gt;The "shell", which is a program that leads the "process group", reads and parses input, spawns processes, and generally acts as an event loop. Most environments use bash as the default shell.&lt;/item&gt;
      &lt;item&gt;The programs spawned by your shell, which interact with all of the above in order to receive input and send output.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I lied a little bit above. "input" is not just text. It also includes signals that can be sent to the running process. Converting keystrokes to signals is the job of the PTY.&lt;/p&gt;
    &lt;p&gt;Similar, "output" is not just text. It's a stream of ANSI Escape Sequences that can be used by the terminal emulator to display rich formatting.&lt;/p&gt;
    &lt;head rend="h2"&gt;what does a better terminal look like?&lt;/head&gt;
    &lt;p&gt;I do some weird things with terminals. However, the amount of hacks I can get up to are pretty limited, because terminals are pretty limited. I won't go into all the ways they're limited, because it's been rehashed many times before. What I want to do instead is imagine what a better terminal can look like.&lt;/p&gt;
    &lt;head rend="h3"&gt;a first try: Jupyter&lt;/head&gt;
    &lt;p&gt;The closest thing to a terminal analog that most people are familiar with is Jupyter Notebook. This offers a lot of cool features that are not possible in a "traditional" VT100 emulator:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;high fidelity image rendering&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;a "rerun from start" button (or rerun the current command; or rerun only a single past command) that replaces past output instead of appending to it&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;"views" of source code and output that can be rewritten in place (e.g. markdown can be viewed either as source or as rendered HTML)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;a built-in editor with syntax highlighting, tabs, panes, mouse support, etc.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;some problems&lt;/head&gt;
    &lt;p&gt;Jupyter works by having a "kernel" (in this case, a python interpreter) and a "renderer" (in this case, a web application displayed by the browser). You could imagine using a Jupyter Notebook with a shell as the kernel, so that you get all the nice features of Jupyter when running shell commands. However, that quickly runs into some issues:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Your shell gets the commands all at once, not character-by-character, so tab-complete, syntax highlighting, and autosuggestions don't work.&lt;/item&gt;
      &lt;item&gt;What do you do about long-lived processes? By default, Jupyter runs a cell until completion; you can cancel it, but you can't suspend, resume, interact with, nor view a process while it's running. Don't even think about running &lt;code&gt;vi&lt;/code&gt;or&lt;code&gt;top&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;The "rerun cell" buttons do horrible things to the state of your computer (normal Jupyter kernels have this problem too, but "rerun all" works better when the commands don't usually include &lt;code&gt;rm -rf&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Undo/redo do not work. (They don't work in a normal terminal either, but people attempt to use them more when it looks like they should be able to.)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It turns out all these problems are solveable.&lt;/p&gt;
    &lt;head rend="h2"&gt;how does that work?&lt;/head&gt;
    &lt;head rend="h3"&gt;shell integration&lt;/head&gt;
    &lt;p&gt;There exists today a terminal called Warp. Warp has built native integration between the terminal and the shell, where the terminal understands where each command starts and stops, what it outputs, and what is your own input. As a result, it can render things very prettily:&lt;/p&gt;
    &lt;p&gt;It does this using (mostly) standard features built-in to the terminal and shell (a custom DCS): you can read their explanation here. It's possible to do this less invasively using OSC 133 escape codes; I'm not sure why Warp didn't do this, but that's ok.&lt;/p&gt;
    &lt;p&gt;iTerm2 does a similar thing, and this allows it to enable really quite a lot of features: navigating between commands with a single hotkey; notifying you when a command finishes running, showing the current command as an "overlay" if the output goes off the screen.&lt;/p&gt;
    &lt;head rend="h3"&gt;long-lived processes&lt;/head&gt;
    &lt;p&gt;This is really three different things. The first is interacting with a long-lived process. The second is suspending the process without killing it. The third is disconnecting from the process, in such a way that the process state is not disturbed and is still available if you want to reconnect.&lt;/p&gt;
    &lt;head rend="h4"&gt;interacting&lt;/head&gt;
    &lt;p&gt;To interact with a process, you need bidirectional communication, i.e. you need a "cell output" that is also an input. An example would be any TUI, like &lt;code&gt;top&lt;/code&gt;, &lt;code&gt;gdb&lt;/code&gt;, or &lt;code&gt;vim&lt;/code&gt; 1.  Fortunately, Jupyter is really good at this!  The whole design is around having interactive outputs that you can change and update.&lt;/p&gt;
    &lt;p&gt;Additionally, I would expect my terminal to always have a "free input cell", as Matklad describes in A Better Shell, where the interactive process runs in the top half of the window and an input cell is available in the bottom half. Jupyter can do this today, but "add a cell" is manual, not automatic.&lt;/p&gt;
    &lt;head rend="h4"&gt;suspending&lt;/head&gt;
    &lt;p&gt;"Suspending" a process is usually called "job control". There's not too much to talk about here, except that I would expect a "modern" terminal to show me all suspended and background processes as a de-emphasized persistent visual, kinda like how Intellij will show you "indexing ..." in the bottom taskbar.&lt;/p&gt;
    &lt;head rend="h4"&gt;disconnecting&lt;/head&gt;
    &lt;p&gt;There are roughly three existing approaches for disconnecting and reconnecting to a terminal session (Well, four if you count reptyr).&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Tmux / Zellij / Screen&lt;/p&gt;
        &lt;p&gt;These tools inject a whole extra terminal emulator between your terminal emulator and the program. They work by having a "server" which actually owns the PTY and renders the output, and a "client" that displays the output to your "real" terminal emulator. This model lets you detach clients, reattach them later, or even attach multiple clients at once. You can think of this as a "batteries-included" approach. It also has the benefit that you can program both the client and the server (although many modern terminals, like Kitty and Wezterm are programmable now); that you can organize your tabs and windows in the terminal (although many modern desktop environments have tiling and thorough keyboard shortcuts); and that you get street cred for looking like Hackerman.&lt;/p&gt;
        &lt;p&gt;The downside is that, well, now you have an extra terminal emulator running in your terminal, with all the bugs that implies.&lt;/p&gt;
        &lt;p&gt;iTerm actually avoids this by bypassing the tmux client altogether and acting as its own client that talks directly to the server. In this mode, "tmux tabs" are actually iTerm tabs, "tmux panes" are iTerm panes, and so on. This is a good model, and I would adopt it when writing a future terminal for integration with existing tmux setups.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mosh is a really interesting place in the design space. It is not a terminal emulator replacement; instead it is an ssh replacement. Its big draw is that it supports reconnecting to your terminal session after a network interruption. It does that by running a state machine on the server and replaying an incremental diff of the viewport to the client. This is a similar model to tmux, except that it doesn't support the "multiplexing" part (it expects your terminal emulator to handle that), nor scrollback (ditto). Because it has its own renderer, it has a similar class of bugs to tmux. One feature it does have, unlike tmux, is that the "client" is really running on your side of the network, so local line editing is instant.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;alden/shpool/dtach/abduco/diss&lt;/p&gt;
        &lt;p&gt;These all occupy a similar place in the design space: they only handle session detach/resume with a client/server, not networking or scrollback, and do not include their own terminal emulator. Compared to tmux and mosh, they are highly decoupled.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;rerun and undo/redo&lt;/head&gt;
    &lt;p&gt;I'm going to treat these together because the solution is the same: dataflow tracking.&lt;/p&gt;
    &lt;p&gt;Take as an example pluto.jl, which does this today by hooking into the Julia compiler.&lt;/p&gt;
    &lt;p&gt;Note that this updates cells live in response to previous cells that they depend on. Not pictured is that it doesn't update cells if their dependencies haven't changed. You can think of this as a spreadsheet-like Jupyter, where code is only rerun when necessary.&lt;/p&gt;
    &lt;p&gt;You may say this is hard to generalize. The trick here is orthogonal persistence. If you sandbox the processes, track all IO, and prevent things that are "too weird" unless they're talking to other processes in the sandbox (e.g. unix sockets and POST requests), you have really quite a lot of control over the process! This lets you treat it as a pure function of its inputs, where its inputs are "the whole file system, all environment variables, and all process attributes".&lt;/p&gt;
    &lt;head rend="h3"&gt;derived features&lt;/head&gt;
    &lt;p&gt;Once you have these primitives—Jupyter notebook frontends, undo/redo, automatic rerun, persistence, and shell integration—you can build really quite a lot on top. And you can build it incrementally, piece-by-piece:&lt;/p&gt;
    &lt;head rend="h4"&gt;needs a Jupyter notebook frontend&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Runbooks (actually, you can build these just with Jupyter and a PTY primitive).&lt;/item&gt;
      &lt;item&gt;Terminal customization that uses normal CSS, no weird custom languages or ANSI color codes.&lt;/item&gt;
      &lt;item&gt;Search for commands by output/timestamp. Currently, you can search across output in the current session, or you can search across all command input history, but you don't have any kind of smart filters, and the output doesn't persist across sessions.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;needs shell integration&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Timestamps and execution duration for each command.&lt;/item&gt;
      &lt;item&gt;Local line-editing, even across a network boundary.&lt;/item&gt;
      &lt;item&gt;IntelliSense for shell commands, without having to hit tab and with rendering that's integrated into the terminal.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;needs sandboxed tracing&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"All the features from sandboxed tracing": collaborative terminals, querying files modified by a command, "asciinema but you can edit it at runtime", tracing build systems.&lt;/item&gt;
      &lt;item&gt;Extend the smart search above to also search by disk state at the time the command was run.&lt;/item&gt;
      &lt;item&gt;Extending undo/redo to a git-like branching model (something like this is already support by emacs undo-tree), where you have multiple "views" of the process tree.&lt;/item&gt;
      &lt;item&gt;Given the undo-tree model, and since we have sandboxing, we can give an LLM access to your project, and run many of them in parallel at the same time without overwriting each others state, and in such a way that you can see what they're doing, edit it, and save it into a runbook for later use.&lt;/item&gt;
      &lt;item&gt;A terminal in a prod environment that can't affect the state of the machine, only inspect the existing state.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;ok but how do you build this&lt;/head&gt;
    &lt;p&gt;jyn, you may say, you can't build vertical integration in open source. you can't make money off open source projects. the switching costs are too high.&lt;/p&gt;
    &lt;p&gt;All these things are true. To talk about how this is possible, we have to talk about incremental adoption.&lt;/p&gt;
    &lt;p&gt;if I were building this, I would do it in stages, such that at each stage the thing is an improvement over its alternatives. This is how &lt;code&gt;jj&lt;/code&gt; works and it works extremely well: it doesn't require everyone on a team to switch at once because individual people can use &lt;code&gt;jj&lt;/code&gt;, even for single commands, without a large impact on everyone else.&lt;/p&gt;
    &lt;head rend="h3"&gt;stage 1: transactional semantics&lt;/head&gt;
    &lt;p&gt;When people think of redesigning the terminal, they always think of redesigning the terminal emulator. This is exactly the wrong place to start. People are attached to their emulators. They configure them, they make them look nice, they use their keybindings. There is a high switching cost to switching emulators because everything affects everything else. It's not so terribly high, because it's still individual and not shared across a team, but still high.&lt;/p&gt;
    &lt;p&gt;What I would do instead is start at the CLI layer. CLI programs are great because they're easy to install and run and have very low switching costs: you can use them one-off without changing your whole workflow.&lt;/p&gt;
    &lt;p&gt;So, I would write a CLI that implements transactional semantics for the terminal. You can imagine an interface something like &lt;code&gt;transaction [start|rollback|commit]&lt;/code&gt;, where everything run after &lt;code&gt;start&lt;/code&gt; is undoable. There is a lot you can do with this alone, I think you could build a whole business off this.&lt;/p&gt;
    &lt;head rend="h3"&gt;stage 2: persistent sessions&lt;/head&gt;
    &lt;p&gt;Once I had transactional semantics, I would try to decouple persistence from tmux and mosh.&lt;/p&gt;
    &lt;p&gt;To get PTY persistence, you have to introduce a client/server model, because the kernel really really expects both sides of a PTY to always be connected. Using commands like alden, or a library like it (it's not that complicated), lets you do this simply, without affecting the terminal emulator nor the programs running inside the PTY session.&lt;/p&gt;
    &lt;p&gt;To get scrollback, the server could save input and output indefinitely and replay them when the client reconnects. This gets you "native" scrollback—the terminal emulator you're already using handles it exactly like any other output, because it looks exactly like any other output—while still being replayable and resumable from an arbitrary starting point. This requires some amount of parsing ANSI escape codes2, but it's doable with enough work.&lt;/p&gt;
    &lt;p&gt;To get network resumption like mosh, my custom server could use Eternal TCP (possibly built on top of QUIC for efficiency). Notably, the persistence for the PTY is separate from the persistence for the network connection. Eternal TCP here is strictly an optimization: you could build this on top of a bash script that runs &lt;code&gt;ssh host eternal-pty attach&lt;/code&gt; in a loop, it's just not as nice an experience because of network delay and packet loss. Again, composable parts allow for incremental adoption.&lt;/p&gt;
    &lt;p&gt;At this point, you're already able to connect multiple clients to a single terminal session, like tmux, but window management is still done by your terminal emulator, not by the client/server. If you wanted to have window management integrated, the terminal emulator could speak the tmux -CC protocol, like iTerm.&lt;/p&gt;
    &lt;p&gt;All parts of this stage can be done independently and in parallel from the transactional semantics, but I don't think you can build a business off them, it's not enough of an improvement over the existing tools.&lt;/p&gt;
    &lt;head rend="h3"&gt;stage 3: structured RPC&lt;/head&gt;
    &lt;p&gt;This bit depends on the client/server model. Once you have a server interposed between the terminal emulator and the client, you can start doing really funny things like tagging I/O with metadata. This lets all data be timestamped3 and lets you distinguish input from output. xterm.js works something like this. When combined with shell integration, this even lets you distinguish shell prompts from program output, at the data layer.&lt;/p&gt;
    &lt;p&gt;Now you can start doing really funny things, because you have a structured log of your terminal session. You can replay the log as a recording, like asciinema4; you can transform the shell prompt without rerunning all the commands; you can import it into a Jupyter Notebook or Atuin Desktop; you can save the commands and rerun them later as a script. Your terminal is data.&lt;/p&gt;
    &lt;head rend="h3"&gt;stage 4: jupyter-like frontend&lt;/head&gt;
    &lt;p&gt;This is the very first time that we touch the terminal emulator, and it's intentionally the last step because it has the highest switching costs. This makes use of all the nice features we've built to give you a nice UI. You don't need our &lt;code&gt;transaction&lt;/code&gt; CLI anymore unless you want nested transactions, because your whole terminal session starts in a transaction by default. You get all the features I mention above, because we've put all the pieces together.&lt;/p&gt;
    &lt;head rend="h2"&gt;jyn, what the fuck&lt;/head&gt;
    &lt;p&gt;This is bold and ambitious and I think building the whole thing would take about a decade. That's ok. I'm patient.&lt;/p&gt;
    &lt;p&gt;You can help me by spreading the word :) Perhaps this post will inspire someone to start building this themselves.&lt;/p&gt;
    &lt;head rend="h2"&gt;bibliography&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Gary Bernhardt, “A Whole New World”&lt;/item&gt;
      &lt;item&gt;Alex Kladov, “A Better Shell”&lt;/item&gt;
      &lt;item&gt;jyn, “how i use my terminal”&lt;/item&gt;
      &lt;item&gt;jyn, “Complected and Orthogonal Persistence”&lt;/item&gt;
      &lt;item&gt;jyn, “you are in a box”&lt;/item&gt;
      &lt;item&gt;jyn, “there's two costs to making money off an open source project…”&lt;/item&gt;
      &lt;item&gt;Rebecca Turner, “Vertical Integration is the Only Thing That Matters”&lt;/item&gt;
      &lt;item&gt;Julia Evans, “New zine: The Secret Rules of the Terminal”&lt;/item&gt;
      &lt;item&gt;Julia Evans, “meet the terminal emulator”&lt;/item&gt;
      &lt;item&gt;Julia Evans, “What happens when you press a key in your terminal?”&lt;/item&gt;
      &lt;item&gt;Julia Evans, “What's involved in getting a "modern" terminal setup?”&lt;/item&gt;
      &lt;item&gt;Julia Evans, “Bash scripting quirks &amp;amp; safety tips”&lt;/item&gt;
      &lt;item&gt;Julia Evans, “Some terminal frustrations”&lt;/item&gt;
      &lt;item&gt;Julia Evans, “Reasons to use your shell's job control”&lt;/item&gt;
      &lt;item&gt;“signal(7) - Miscellaneous Information Manual”&lt;/item&gt;
      &lt;item&gt;Christian Petersen, “ANSI Escape Codes”&lt;/item&gt;
      &lt;item&gt;saoirse, “withoutboats/notty: A new kind of terminal”&lt;/item&gt;
      &lt;item&gt;Jupyter Team, “Project Jupyter Documentation”&lt;/item&gt;
      &lt;item&gt;“Warp: The Agentic Development Environment”&lt;/item&gt;
      &lt;item&gt;“Warp: How Warp Works”&lt;/item&gt;
      &lt;item&gt;“Warp: Completions”&lt;/item&gt;
      &lt;item&gt;George Nachman, “iTerm2: Proprietary Escape Codes”&lt;/item&gt;
      &lt;item&gt;George Nachman, “iTerm2: Shell Integration”&lt;/item&gt;
      &lt;item&gt;George Nachman, “iTerm2: tmux Integration”&lt;/item&gt;
      &lt;item&gt;Project Jupyter, “Jupyter Widgets”&lt;/item&gt;
      &lt;item&gt;Nelson Elhage, “nelhage/reptyr: Reparent a running program to a new terminal”&lt;/item&gt;
      &lt;item&gt;Kovid Goyal, “kitty”&lt;/item&gt;
      &lt;item&gt;Kovid Goyal, “kitty - Frequently Asked Questions”&lt;/item&gt;
      &lt;item&gt;Wez Furlong, “Wezterm”&lt;/item&gt;
      &lt;item&gt;Keith Winstein, “Mosh: the mobile shell”&lt;/item&gt;
      &lt;item&gt;Keith Winstein, “Display errors with certain characters&lt;/item&gt;
      &lt;item&gt;Matthew Skala, “alden: detachable terminal sessions without breaking scrollback”&lt;/item&gt;
      &lt;item&gt;Ethan Pailes, “shell-pool/shpool: Think tmux, then aim... lower”&lt;/item&gt;
      &lt;item&gt;Ned T. Crigler, “crigler/dtach: A simple program that emulates the detach feature of screen”&lt;/item&gt;
      &lt;item&gt;Marc André Tanner, “martanne/abduco: abduco provides session management”&lt;/item&gt;
      &lt;item&gt;yazgoo, “yazgoo/diss: dtach-like program / crate in rust”&lt;/item&gt;
      &lt;item&gt;Fons van der Plas, “Pluto.jl — interactive Julia programming environment”&lt;/item&gt;
      &lt;item&gt;Ellie Huxtable, “Atuin Desktop: Runbooks that Run”&lt;/item&gt;
      &lt;item&gt;Toby Cubitt, “undo-tree”&lt;/item&gt;
      &lt;item&gt;“SIGHUP - Wikipedia”&lt;/item&gt;
      &lt;item&gt;Jason Gauci, “How Eternal Terminal Works”&lt;/item&gt;
      &lt;item&gt;Marcin Kulik, “Record and share your terminal sessions, the simple way - asciinema.org”&lt;/item&gt;
      &lt;item&gt;“Alternate Screen | Ratatui”&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45892191</guid><pubDate>Tue, 11 Nov 2025 20:11:33 +0000</pubDate></item><item><title>X5.1 solar flare, G4 geomagnetic storm watch</title><link>https://www.spaceweatherlive.com/en/news/view/593/20251111-x5-1-solar-flare-g4-geomagnetic-storm-watch.html</link><description>&lt;doc fingerprint="77527d2b7f75e40e"&gt;
  &lt;main&gt;
    &lt;p&gt;Tuesday, 11 November 2025 19:07 UTC&lt;/p&gt;
    &lt;p&gt;Here she blows! Sunspot region 4274 produced its strongest solar flare thus far since it appeared on the east limb and the sixth strongest solar flare of the current solar cycle. An impressive long duration and highly eruptive X5.1 (R3-strong) solar flare peaked this morning at 10:04 UTC.&lt;/p&gt;
    &lt;p&gt;It became quickly clear that the eruption would be followed by an impressive coronal mass ejection (CME). The resulting coronal wave following the solar explosion as well as the coronal dimming observed as the CME was propelled into space were of a spectacular magnitude as can be seen in the animation below provided by halocme.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Another eruption from AR12474, associated with an X5.1 flare. It has become a full halo CME. I am truly impressed by how fast and global this coronal wave is. The CME will arrive on November 13, but because of earlier CMEs it will be challenging to isolate the ICME from this. pic.twitter.com/H6eNjzQUGz&lt;/p&gt;— Halo CME (@halocme) November 11, 2025&lt;/quote&gt;
    &lt;p&gt;Taking a look at coronagraph imagery provided by GOES-19 CCOR-1 we see the gorgeous fast halo coronal mass ejection as it propagates away from the Sun. It doesn't take a rocket scientist to come to the conclusion that this plasma cloud of course has an earth-directed component and it is pretty clear that this will be a strong impact when it arrives at our planet. This rightfully so prompted the NOAA SWPC to issue a G4 or greater geomagnetic storm watch for tomorrow as the cloud could impact our planet as early as 16 UTC on 12 November. Not only is the CME fast but it will also travel trough an area with high ambient solar wind speed and low density thanks to two other CMEs released earlier by this region. More about that below.&lt;/p&gt;
    &lt;p&gt;If the solar wind and interplanetary magnetic field values at Earth are favorable this could result in a geomagnetic storm which is strong enough for aurora to become visible from locations as far south as northern France, Germany, Ukraine, Switzerland and Austria. In the US it could become visible as far south as Nevada and Arkansas. No guarantees of course, this is space weather we are talking about but be sure to download the SpaceWeatherLive app to your mobile device, turn on the alerts and keep an eye on the solar wind data from ACE and DSCOVR!&lt;/p&gt;
    &lt;p&gt;We also want to remind you that we still have two coronal mass ejections on their way to Earth. These are not as impressive as this X5.1 CME but these two plasma clouds will likely arrive within the next 6 to 18 hours. This is a tricky one as they could arrive as one impact or two impacts close intill each other. More information in yesterday's news.&lt;/p&gt;
    &lt;p&gt;Thank you for reading this article! Did you have any trouble with the technical terms used in this article? Our help section is the place to be where you can find in-depth articles, a FAQ and a list with common abbreviations. Still puzzled? Just post on our forum where we will help you the best we can!&lt;/p&gt;
    &lt;p&gt;A lot of people come to SpaceWeatherLive to follow the Solar activity or if there is a chance to see the aurora, but with more traffic comes higher costs to keep the servers online. If you like SpaceWeatherLive and want to support the project you can choose a subscription for an ad-free site or consider a donation. With your help we can keep SpaceWeatherLive online!&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Last X-flare&lt;/cell&gt;
        &lt;cell&gt;2025/11/11&lt;/cell&gt;
        &lt;cell&gt;X5.1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Last M-flare&lt;/cell&gt;
        &lt;cell&gt;2025/11/11&lt;/cell&gt;
        &lt;cell&gt;M1.4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Last geomagnetic storm&lt;/cell&gt;
        &lt;cell&gt;2025/11/08&lt;/cell&gt;
        &lt;cell&gt;Kp6+ (G2)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Spotless days&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Last spotless day&lt;/cell&gt;
        &lt;cell&gt;2022/06/08&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Monthly mean Sunspot Number&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;October 2025&lt;/cell&gt;
        &lt;cell&gt;114.6 -15.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;November 2025&lt;/cell&gt;
        &lt;cell&gt;95.5 -19.1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Last 30 days&lt;/cell&gt;
        &lt;cell&gt;97.3 -33.5&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45893004</guid><pubDate>Tue, 11 Nov 2025 21:18:26 +0000</pubDate></item><item><title>I didn't reverse-engineer the protocol for my blood pressure monitor in 24 hours</title><link>https://james.belchamber.com/articles/blood-pressure-monitor-reverse-engineering/</link><description>&lt;doc fingerprint="b6398d534b2d77a1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;I didn't reverse-engineer the protocol for my blood pressure monitor in 24 hours&lt;/head&gt;
    &lt;p&gt;Yesterday after receiving my yearly flu vaccine at the pharmacy I was offered a blood pressure test, which reported a reading that made the young pharmacist who had just given me my vaccine a bit worried.&lt;/p&gt;
    &lt;p&gt;Off the back of this she offered me a 24 hour study, and then strapped a cuff to my arm plumbed into a little device which I had to wear in a little caddy - the cuff would inflate every 30 minutes during the day and every 60 minutes during the night, and then tomorrow I would bring it back for analysis.&lt;/p&gt;
    &lt;p&gt;"Can I read the measurements?" I asked, as it was being strapped to me.&lt;/p&gt;
    &lt;p&gt;"Oh, no, that will just stress you out. We turn that off". Fair enough.&lt;/p&gt;
    &lt;p&gt;Thing is, this device had a little micro-USB port on the side.&lt;/p&gt;
    &lt;head rend="h1"&gt;Doing things the proper way&lt;/head&gt;
    &lt;p&gt;I had started researching the device - a Microlife WatchBP O3 - before I got out of the chemist, and once I'd got back to the office I downloaded the software that's freely available to interact with it, setting up a Bottles instance to run the software since I don't (knowingly) have a Windows machine within 100 metres of me.&lt;/p&gt;
    &lt;p&gt;Unfortunately it didn't seem to be able to access the device, and I had no clue why. In Linux it was just presenting as a standard &lt;code&gt;hidraw&lt;/code&gt; device:&lt;/p&gt;
    &lt;code&gt;[33301.736724] hid-generic 0003:04D9:B554.001E: hiddev96,hidraw1: USB HID v1.11 Device [USB HID UART Bridge] on usb-0000:c5:00.0-1/input0
&lt;/code&gt;
    &lt;p&gt;Fine, I'll install windows.&lt;/p&gt;
    &lt;p&gt;After dodging around Microsoft's idea of UX, and then forwarding the USB device to the VM (I used Gnome Boxes for this, works nicely), I finally got to see WatchBP Analyzer with the data downloaded from the device.&lt;/p&gt;
    &lt;p&gt;But I don't want to open a Virtual Machine running Windows to see this data, and anyway - I'm pretty sure that reverse-engineering this will be good for my blood pressure.&lt;/p&gt;
    &lt;head rend="h1"&gt;Sniffing the traffic&lt;/head&gt;
    &lt;p&gt;Since I'm running this in a Virtual Machine I can just rely on Wireshark in Linux to get the traffic between the host and the device. &lt;code&gt;usbmon&lt;/code&gt; is already installed and we know that the device is on Bus 3, so we can select usbmon3 on startup and start capturing.&lt;/p&gt;
    &lt;p&gt;I'm very much out of my depth at this point but, being one of those who could land a plane in an emergency (why would you talk yourself out of it?!) I decided to crack on regardless. I know that the interesting stuff is sent after I press "Download", and I know that something in there is gonna say "my blood pressure is 137/113" - so let's look for that. Just convert to show bytes as decimal and..&lt;/p&gt;
    &lt;p&gt;..that looks like a blood pressure! Let's copy that out as hex:&lt;/p&gt;
    &lt;code&gt;05 0a 89 71 43 9b
&lt;/code&gt;
    &lt;p&gt;I'm not sure if this is "valid" HID Data (Wireshark seems convinced that only the first byte is the Vendor Data, with the rest being padding) but it seems like the data is being sent in 32-byte "chunks", of which the first byte tells you the number of significant (SIG) following bits in the chunk (I deleted the rest - all zeroes - for clarity). The third byte is my Systolic blood Pressure (SYS), the fourth is my Diastolic blood pressure (DIA), and the fifth is my heart rate (HR) - no clue what the second or last byte is, but let's find all other bytes with my blood pressure in them (in decimal this time, because I can't read hex without help):&lt;/p&gt;
    &lt;code&gt;SIG ??? SYS DIA  HR ??? ??? ???
  5  10 137 113  67 155
  5   0 132  86  68 155
  6   0 126  84  82 155  83
  6  10 128  80  61 155  83
  7   0 148  93  65 155  83  64
  7   0 121  92  74 155  83  94
  7   0 123  83  65 155  83  95
  7   0 123  79  78 155  83 129
&lt;/code&gt;
    &lt;p&gt;Hmm. So we're still looking for the Oscillometric signal peak pressure (OPP)as well as some timestamps (we can calculate Mean arterial pressure - MAP - as &lt;code&gt;(2*DIA+SYS)/3&lt;/code&gt;, according to the manual, and Pulse Pressure (PP) is just &lt;code&gt;SYS-DIA&lt;/code&gt;). We can see the OPP in the packets that come after each of those above, but they don't seem to consistently come in on the same line:&lt;/p&gt;
    &lt;code&gt; 10  82  195   80 *121    0    0    0    0    0    0
 10  82  223   80  *95    0    0    0    0    0    0
  9   1   80  *90    0    0    0    0    0    0
  9  35   80  *86    0    0    0    0    0    0
  8  80 *103    0    0    0    0    0    0
  8  80 *106    0    0    0    0    0    0
  8  80  *90    0    0    0    0    0    0
 10  80  *88    0    0    0    0    0    0   29  251
&lt;/code&gt;
    &lt;p&gt;Oh. Maybe if I stick them together?&lt;/p&gt;
    &lt;code&gt;??? SYS DIA  HR ??? ??? ??? ??? OPP ??? ??? ??? ??? ??? ??? ??? ???
 10 137 113  67 155  82 195  80 121   0   0   0   0   0   0
  0 132  86  68 155  82 223  80  95   0   0   0   0   0   0
  0 126  84  82 155  83   1  80  90   0   0   0   0   0   0
 10 128  80  61 155  83  35  80  86   0   0   0   0   0   0
  0 148  93  65 155  83  64  80 103   0   0   0   0   0   0
  0 121  92  74 155  83  94  80 106   0   0   0   0   0   0
  0 123  83  65 155  83  95  80  90   0   0   0   0   0   0
  0 123  79  78 155  83 129  80  88   0   0   0   0   0   0  29 251
&lt;/code&gt;
    &lt;p&gt;Right, timestamps. I first guessed that the four populated contiguous bytes between &lt;code&gt;HR&lt;/code&gt; and &lt;code&gt;OPP&lt;/code&gt; are a 32-bit unix timestamp, but that would make the first one &lt;code&gt;9B52C350&lt;/code&gt;; either &lt;code&gt;Jul 29 2052&lt;/code&gt; or &lt;code&gt;Dec 08 2012&lt;/code&gt; depending on which endianness the protocol is into. The 8 readings we have here are all from &lt;code&gt;November 10th&lt;/code&gt;, at &lt;code&gt;11:03&lt;/code&gt;, &lt;code&gt;11:31&lt;/code&gt;, &lt;code&gt;12:01&lt;/code&gt;, &lt;code&gt;12:35&lt;/code&gt;, &lt;code&gt;13:00&lt;/code&gt;, &lt;code&gt;13:30&lt;/code&gt;, &lt;code&gt;13:31&lt;/code&gt; and &lt;code&gt;14:01&lt;/code&gt;, which isn't.. isn't that.&lt;/p&gt;
    &lt;p&gt;But note that the number in the 6th column flips from &lt;code&gt;82&lt;/code&gt; to &lt;code&gt;83&lt;/code&gt; when we switch from AM to PM - that's something, and when it does the 7th column resets. And hey - &lt;code&gt;1&lt;/code&gt;, &lt;code&gt;35&lt;/code&gt;, &lt;code&gt;64&lt;/code&gt;, &lt;code&gt;94&lt;/code&gt;, &lt;code&gt;95&lt;/code&gt;.. that seems dangerously close to &lt;code&gt;12:01&lt;/code&gt;, &lt;code&gt;12:35&lt;/code&gt;, &lt;code&gt;13:00&lt;/code&gt;, &lt;code&gt;13:30&lt;/code&gt; and &lt;code&gt;13:31&lt;/code&gt; if you were just to count the minutes. What's going on?&lt;/p&gt;
    &lt;head rend="h1"&gt;Deadlines and dead ends&lt;/head&gt;
    &lt;p&gt;I tried feeding a lot of this into various Als (Kagi gives you access to a few with a nice interface) and I found that they mostly were stupid in ways that made me think. A few times I thought they had "cracked the case" but actually they just made me waste time. But they did remind me e.g. of endianness, so I did get a bit out of them.&lt;/p&gt;
    &lt;p&gt;I also spent quite a bit of time trying to write some Python that emulated the initial handshake and download button of the interface so that it could push out the data as a stream instead of me having to wrestle it out of Wireshark - again, Al had a habit of giving me incorrect code (although it did turn me on to pyhidapi).&lt;/p&gt;
    &lt;p&gt;But ultimately I had a deadline, and I had to return the device even though I wanted to spend more time with it. Possibly for the best - while it did give me some reverse engineering practice (which it turns out I really enjoy), I should do some work instead of procrastinating.&lt;/p&gt;
    &lt;p&gt;My final lesson was a new word - Normotension, normal blood pressure - and a new phrase - White Coat Hypertension, the phenomena of high blood pressure in a clinical setting. Turns out that when you check someone's blood pressure after giving them an injection, it's higher than normal.&lt;/p&gt;
    &lt;p&gt;I don't think I'd recommend getting your blood pressure tested after your next flu jab. But then, I'm not a doctor.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45893095</guid><pubDate>Tue, 11 Nov 2025 21:25:19 +0000</pubDate></item><item><title>Heroku Support for .NET 10</title><link>https://www.heroku.com/blog/support-for-dotnet-10-lts-what-developers-need-know/</link><description>&lt;doc fingerprint="df6f5a5e0ea4b3da"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Heroku Support for .NET 10 LTS: What Developers Need to Know&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Last Updated: November 11, 2025&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It’s that time of year for .NET when we get a new major version and a bunch of exciting features. .NET Conf 2025 kicked off earlier today, bringing with it the release of .NET 10, as well as ASP.NET Core 10, C# 14, and F# 10. Congrats (and a big thank you) to the .NET team and everyone who helped get .NET 10 out the door.&lt;/p&gt;
    &lt;p&gt;At Heroku, we believe you should be able to use language and framework releases when they launch, and we prepare accordingly. You can now build and run .NET 10 apps on Heroku, with buildpack support for new SDK features like file-based apps, &lt;code&gt;.slnx&lt;/code&gt; solution files, and more.&lt;/p&gt;
    &lt;head rend="h2"&gt;Migration and support timelines&lt;/head&gt;
    &lt;p&gt;This year’s release is significant because .NET 10 is the new Long Term Support (LTS) release, which will be supported for three years. This extended support, including regular updates and security patches, makes it the best release for businesses and developers to build on and migrate to, offering a stable foundation with access to the latest features.&lt;/p&gt;
    &lt;p&gt;With .NET 10 now available, the clock is ticking on previous versions. Both .NET 8 and .NET 9 will reach End of Support on November 10, 2026. In other words, now is a good time to start planning your migration.&lt;/p&gt;
    &lt;p&gt;We will continue to support .NET 8 and .NET 9 with consistent, timely updates alongside .NET 10. Our .NET support follows the official .NET support policy, and we are fully committed to providing a stable and secure platform for your .NET applications.&lt;/p&gt;
    &lt;p&gt;Let’s dive into using .NET 10 on Heroku today!&lt;/p&gt;
    &lt;head rend="h2"&gt;Zero-config deployment with .NET 10 file-based apps&lt;/head&gt;
    &lt;p&gt;One of the most exciting features in .NET 10 is file-based apps – .NET applications defined in a single C# file without project or solution files, making it easier than ever to deploy .NET apps to Heroku.&lt;/p&gt;
    &lt;p&gt;For example, here’s a complete ASP.NET Core 10 web application, &lt;code&gt;HelloHeroku.cs&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;// Use the new #sdk directive to pull in the ASP.NET Core SDK
#:sdk Microsoft.NET.Sdk.Web

var builder = WebApplication.CreateBuilder(args);
var app = builder.Build();  
  
app.MapGet("/", () =&amp;gt; "Hello from .NET 10 on Heroku!");

app.Run();
&lt;/code&gt;
    &lt;p&gt;When you push this to Heroku, the platform detects the &lt;code&gt;*.cs&lt;/code&gt; file and uses the .NET buildpack. Since there are no solution or project files, the buildpack treats it as a file-based app, installs the latest .NET SDK, builds and publishes the app, detects and configures it as a web application, and deploys it to serve traffic.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; The result is a simple, zero-config experience to get you started quickly, ideal for prototyping and developers new to .NET. And there’s more coming – check out the .NET SDK repository to see what the .NET team is working on!&lt;/p&gt;
    &lt;p&gt;To learn more about what you can do with file-based apps on Heroku today, see our Dev Center documentation.&lt;/p&gt;
    &lt;head rend="h2"&gt;SLNX: A modern solution for a modern .NET&lt;/head&gt;
    &lt;p&gt;For decades, .NET developers have used &lt;code&gt;.sln&lt;/code&gt; solution files, a proprietary format introduced in 2002 for Visual Studio. Unlike .NET itself, they haven’t changed much since. In a step towards modernization, the .NET 10 SDK is making SLNX the default format. Heroku ensures a seamless deployment experience by fully supporting both formats.&lt;/p&gt;
    &lt;code&gt;&amp;lt;solution&amp;gt;
    &amp;lt;project path="MyApp\MyApp.csproj"&amp;gt;&amp;lt;/project&amp;gt;
&amp;lt;/solution&amp;gt;
&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;*.slnx&lt;/code&gt; files are easier to read and edit, less likely to cause merge conflicts, and support a wider range of workflows and environments, from Linux shells to Visual Studio on Windows. To migrate existing &lt;code&gt;.sln&lt;/code&gt; files, run &lt;code&gt;dotnet solution migrate&lt;/code&gt; or see the .NET blog announcement for more details.&lt;/p&gt;
    &lt;head rend="h2"&gt;Heroku CI and the Microsoft Testing Platform&lt;/head&gt;
    &lt;p&gt;The .NET 10 SDK integrates the Microsoft Testing Platform (MTP) directly in the &lt;code&gt;dotnet test&lt;/code&gt; command. Since Heroku CI runs &lt;code&gt;dotnet test&lt;/code&gt; by default, your test suite works out of the box after you migrate your apps.&lt;/p&gt;
    &lt;p&gt;For more control over the test setup and execution, you can specify custom test commands in your &lt;code&gt;app.json&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ready to migrate? We’re here to help&lt;/head&gt;
    &lt;p&gt;To support your .NET 10 migration, we’ve updated all our documentation and resources:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The .NET Getting Started app now runs on .NET 10.&lt;/item&gt;
      &lt;item&gt;The ASP.NET Core configuration article includes new guidance for ASP.NET Core 10, including migration away from the now-obsolete &lt;code&gt;IPNetwork&lt;/code&gt;and&lt;code&gt;ForwardedHeadersOptions.KnownNetworks&lt;/code&gt;APIs (learn more) often used to integrate with Heroku’s router.&lt;/item&gt;
      &lt;item&gt;Apps currently using .NET 10 RC builds on Heroku (with &lt;code&gt;TargetFramework&lt;/code&gt;set to&lt;code&gt;net10.0&lt;/code&gt;) will automatically be built with the stable .NET 10 release on the next&lt;code&gt;git push&lt;/code&gt;. You can pin to specific SDK versions using a&lt;code&gt;global.json&lt;/code&gt;file.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For teams migrating from earlier versions, the .NET 10 breaking changes documentation covers important upgrade considerations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Get started today&lt;/head&gt;
    &lt;p&gt;We can’t wait to see what you build with .NET 10 on Heroku. From new features like file-based apps to the stability of an LTS release, this is a great time to be a .NET developer.&lt;/p&gt;
    &lt;p&gt;Check out our updated Getting Started with .NET on Heroku guide and please feel free to reach out with any questions or feedback.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Originally Published:&lt;/item&gt;
      &lt;item&gt;.NETBuildpacksLanguagesNextgenProduct Features&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45893646</guid><pubDate>Tue, 11 Nov 2025 22:18:17 +0000</pubDate></item><item><title>Four strange places to see London's Roman Wall</title><link>https://diamondgeezer.blogspot.com/2025/11/odd-places-to-see-londons-roman-wall.html</link><description>&lt;doc fingerprint="af4d01017b3c27b4"&gt;
  &lt;main&gt;
    &lt;p&gt;There are manyplaces around the City of London to see its old Roman Wall, notably alongside Noble Street, in Barber Surgeons' Meadow, through the Barbican, in St Alphage Garden and just outside the entrance to Tower Hill station. Here are four of the odder spots.&lt;/p&gt;
    &lt;p&gt;Four strange places to see London's Roman Wall&lt;/p&gt;
    &lt;p&gt;1) From platform 1 at Tower Hill station&lt;/p&gt;
    &lt;p&gt;If you're ever waiting for a westbound train at Tower Hill station, take a walk to the rear of the platform and take a look across the tracks, roughly where the penultimate carriage would stop. High on the far wall is a square recess lined by black tiles, and at the back of that is a dimly-lit surface of chunky irregular blocks. Unlike every single other thing on the Underground, the Romans built that.&lt;/p&gt;
    &lt;p&gt;London's original wall was 2 miles long, 6 metres high and almost 3 metres thick at its base, all the better to keep out uncivilised marauders. It was built around 200 AD, then left to decay and rebuilt in the medieval era, again for defensive purposes. This is one of the original bits, not that you can easily tell by squinting across the tracks. A small metal lamp points inwards but is no longer switched on because heritage illumination is not a TfL priority. There is however a rather nice silver plaque on the pillar opposite, should you step back far enough to notice it.&lt;/p&gt;
    &lt;p&gt;The plaque confirms that the stones here are a continuation of the wall seen (much more clearly) outside. What it doesn't mention is the unavoidable truth that the wall must once have continued across the tracks and platforms but is no longer here. That's because when the Circle line was constructed in 1882 the railway companies had permission to demolish 22 metres of London's wall and duly did, the Victorians never being afraid to destroy ancient heritage. Ian Visits has a photo of navvies standing atop the offending stonework just before they bashed it through. The square hole is no recompense, plus you can't see anything if a train's in the platform, but it is a brilliantly quirky thing to find on the Underground.&lt;/p&gt;
    &lt;p&gt;2) Round the back of the Leonardo Royal Hotel&lt;/p&gt;
    &lt;p&gt;The short walk from Tower Hill station to the rear entrance of Fenchurch Street passes two hotels. The second is the Leonardo Royal, formerly the Grange, whose car port looks like it leads to a cocktail terrace and maybe some parking. Nothing's signed from the street, indeed I'd never thought to duck through before, but at the far end past the umbrellas of Leo's bar is a significant chunk of Roman wall.&lt;/p&gt;
    &lt;p&gt;The upper section has arched windows built for archers and square holes which once supported a timber platform. It's impressive of course merely medieval, part of the rebuild that occurred along much of the wall as the city grew and spread beyond its former border. To see the Roman section stand closer to the rail and look down, this because ground level then was a few metres lower than now. The telltale signs are several distinctive bands of thin red bricks, these added to strengthen and bond the structure, and which look like layers of jam in a particularly lumpy sponge. The entire segment behind the hotel is over 20m long, thus longer than the better-known chunk outside the station.&lt;/p&gt;
    &lt;p&gt;Perhaps the best thing about this bit of wall is that you can walk through it. A couple of steps have been added on each side allowing passage through a low medieval arch, all marked with anachronistic trip hazard markings. If steps aren't your thing you can also pass round the end of the wall on the flat. Round the other side are a glum alley and a staff back-entrance, also an exit into a separate backstreet past a sign that says PRIVATE No Public Right Of Way Beyond This Point Entry At Your Own Risk Absolutely No Liability Is Accepted For Any Reason Whatsoever. Stuff that, there's an actual Roman Wall back here.&lt;/p&gt;
    &lt;p&gt;3) From a cafe terrace&lt;/p&gt;
    &lt;p&gt;I've written about The City Wall at Vine Street before, a free attraction opened in 2023 beneath a block of student flats. Last time I had to battle the Procedural Curmudgeon to gain admittance but I'm pleased to say they've since loosened up and you can now simply gesture at the door, walk in and give your first name to a flunkey with a tablet. He rattled through the key information with all the practised enthusiasm of a call centre employee dictating terms and conditions, then sent me off down the stairs.&lt;/p&gt;
    &lt;p&gt;Two walls are filled with finds from the excavations, including an AD 70s coin and the bones of a 1760s cat. Nobody's quite sure how the ancient Greek tombstone ended up here, given it predates Londinium, but it has pride of place in a central glass case. The 5-minute historical animation is pretty good too, assuming you can read quite fast. But the main draw is the multi-layered towering remnant of wall which here has the benefit of being properly illuminated and protected from the elements. The protruding lower section (which looks much too clean to be so very old) is all that remains of an original postern, and is also unique because all the other towers elsewhere round the City are merely medieval.&lt;/p&gt;
    &lt;p&gt;What's weird is that this large basement space is overlooked by a balcony scattered with small tables at which sit students and businesspeople consuming coffee and all-day brunch. The baristas operate from the cafe upstairs but any food comes from a small kitchen down below, which has the unnerving side effect that while you're wandering around what looks like a museum it smells like an office canteen. If you choose to be tempted by a cappuccino and smashed avocado on your way out you can enjoy extra time with the Roman wall, or indeed skip the walkthrough altogether and focus only on refreshment with an absolutely unique view. I recommend a proper visit though... the visitors book awaits your praise.&lt;/p&gt;
    &lt;p&gt;4) At the rear of a car park&lt;/p&gt;
    &lt;p&gt;This is amazing on many levels, the main level being subterranean. After WW2 so much of the City was in ruins that planners drove a new dual carriageway through the Aldersgate area and called it London Wall. They believed cars were the future and to that end hid a linear car park directly underneath the new road. It's very narrow, very long and pretty grim, indeed precisely the kind of filming location you'd expect a throwback crime thriller to use for a shoot-out or kidnapping. Cars enter down a short spiral ramp and pedestrians through a grubby side door, and the numbered concrete catacombs stretch on and on for almost 400 metres. Keep walking past the white vans, Range Rovers and the attendant's cabin, trying not to attract too much attention, and almost at the far end is... blimey.&lt;/p&gt;
    &lt;p&gt;You can't park in bays 52 and 53 because they're full of Roman remains. A substantial chunk of wall slots in diagonally beneath the joists and pillars, tall enough to incorporate two separate bands of red bricks. It looks quite smooth up front but fairly rubbly round the back, also much thicker at the base than at the top. Obviously it's very risky to have a scheduled ancient monument in a car park so protective concrete blocks have been added to make sure nobody reverses into the stonework by mistake. More recently a glass screen has been added at one end, branded 'City of London' so you know who to thank, but the other end remains accessible for now (not that you should be stepping in or even touching it).&lt;/p&gt;
    &lt;p&gt;It's the contrasts that I found most incongruous. A relic from Roman times penned inbetween a speed hump and a futile pedestrian crossing. A fortification from the 3rd century beside an electric van built last year. A defensive structure that helped see off the Peasants Revolt beside a poster warning what to do in the event of fire. A boundary wall once an intrinsic part of the capital now underground illuminated by strip lights. And all this at the very far end of an oppressive bunker preserved for the benefit of hardly any eyes in a parking facility only a few know to use. Sure you can see chunks of Roman wall all around the City, even from a tube platform, hotel terrace or cafe. But the oddest spot may well be here in the London Wall car park, should you ever have the balls to take a look.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45893795</guid><pubDate>Tue, 11 Nov 2025 22:31:41 +0000</pubDate></item><item><title>.NET MAUI is coming to Linux and the browser</title><link>https://avaloniaui.net/blog/net-maui-is-coming-to-linux-and-the-browser-powered-by-avalonia</link><description>&lt;doc fingerprint="f561401a5d0495ec"&gt;
  &lt;main&gt;
    &lt;p&gt;We are bringing .NET MAUI to Linux and to the browser, powered by Avalonia.&lt;/p&gt;
    &lt;p&gt;For the past few months, we have been working on an Avalonia powered backend for .NET MAUI, with guidance and feedback from engineers in the MAUI ecosystem. What started as an experiment has grown into a project we are committing to, with apps already running on new platforms. It is time to show you what we have been building.&lt;/p&gt;
    &lt;head rend="h2"&gt;Try It Right Now&lt;/head&gt;
    &lt;p&gt;Before we dive into the details, you can experience it yourself:&lt;/p&gt;
    &lt;p&gt;Launch MAUI in your browser â&lt;/p&gt;
    &lt;p&gt;This is a real MAUI application running on WebAssembly, rendered through Avalonia, with no plugins or hidden tricks. It is an early build with rough edges, but it proves the point: MAUI can now run on every major desktop OS and in the browser.&lt;/p&gt;
    &lt;head rend="h2"&gt;What is the Avalonia MAUI Backend?&lt;/head&gt;
    &lt;p&gt;At its core, the Avalonia MAUI Backend enables you to keep your MAUI codebase while replacing the rendering layer with Avalonia. The goal is straightforward: take your existing MAUI applications and extend them to additional platforms, while enhancing desktop performance along the way.&lt;/p&gt;
    &lt;p&gt;In practical terms, that means several big wins.&lt;/p&gt;
    &lt;head rend="h3"&gt;Desktop Linux support&lt;/head&gt;
    &lt;p&gt;.NET MAUI apps running as first class desktop apps on distributions such as Ubuntu, Debian and Fedora, sharing the same Avalonia renderer that already powers demanding desktop apps in production today.&lt;/p&gt;
    &lt;head rend="h3"&gt;Embedded Linux&lt;/head&gt;
    &lt;p&gt;Avalonia already runs on embedded Linux devices, from Raspberry Pi panels to industrial HMIs. Using the same backend, the Avalonia MAUI Backend brings those capabilities to MAUI as well, so the applications you build in MAUI can run on the same embedded Linux targets as Avalonia.&lt;/p&gt;
    &lt;head rend="h3"&gt;WebAssembly support&lt;/head&gt;
    &lt;p&gt;The demo you can open in your browser today is a real MAUI application running on WebAssembly, rendered by Avalonia, with no native dependencies on the client. It is an early build, but it demonstrates what is now possible. MAUI apps will soon be free to deploy to the browser.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bonus: The Avalonia MAUI Backend runs on Windows and macOS too&lt;/head&gt;
    &lt;p&gt;On Windows and macOS, it plugs into the same mature desktop story Avalonia already has. On macOS, early testing indicates significantly improved performance compared to the Mac Catalyst approach. We are seeing more than 2x the performance in representative desktop scenarios, which is a very encouraging sign for the future of MAUI on desktop.&lt;/p&gt;
    &lt;p&gt;All of this is possible because we have built a version of MAUI that sits on top of Avaloniaâs drawn UI model rather than native controls. Not only do you get more platforms and improved performance, your MAUI applications can look and behave consistently whether they are on Windows, macOS, Linux, mobile or running in a browser tab.&lt;/p&gt;
    &lt;head rend="h3"&gt;Simpler, faster development&lt;/head&gt;
    &lt;p&gt;For the Avalonia team, this architecture has a major practical benefit: we only have to target one platform: Avalonia itself. That single target means we can move faster, ship features consistently, and avoid the need to endlessly fix platform-specific edge cases.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;Instead of maintaining separate implementations for iOS, Android, Windows, macOS, Linux, and WebAssembly, we maintain just one. That massively reduces the chances of platform quirks, that can eat up hours of debugging time when something works on Android but not iOS, or renders differently on Mac Catalyst versus WinUI 3. When building on Avalonia, the controls render the same way everywhere because they are using the same rendering engine everywhere.&lt;lb/&gt;That means when we add a feature or fix a bug, it works across all platforms. No more "this works on mobile but breaks on desktop" or "this looks right on Windows but wrong on macOS." The entire development cycle becomes more predictable and significantly faster. &lt;lb/&gt;For us, that is a significant advantage. For MAUI developers, it means the backend evolves faster and more reliably.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Is Avalonia Building a Backend for MAUI?&lt;/head&gt;
    &lt;p&gt;It is a fair question. Avalonia already has its own thriving ecosystem. We see strong, sustained growth in our community, so why invest this much effort into making MAUI run on top of Avalonia?&lt;/p&gt;
    &lt;p&gt;The honest answer is that we care about .NET client developers first, and about which on ramp they use second. Many teams have already chosen MAUI, which they like and want more from. If we can provide them with Linux and browser support, along with improved desktop performance, without requiring a rewrite, that aligns with our mission to delight developers and solve complex problems.&lt;/p&gt;
    &lt;p&gt;This is not entirely selfless. Building a MAUI backend is also a way for us to learn. Running MAUI on Avalonia highlights what is missing for Avalonia to feel completely natural on mobile, which APIs are problematic, which tooling gaps matter, and where we need to raise our game to stay competitive. The work we are doing here directly contributes to strengthening Avalonia.&lt;/p&gt;
    &lt;p&gt;There is also a long term benefit in familiarity. By using Avalonia as the backend for their existing MAUI apps, developers gain insight into our renderer, capabilities and way of thinking. Some of those teams will quite reasonably stay with MAUI. Others, when they start a new project or need something lower level, may build directly on Avalonia instead. If this backend becomes a bridge that brings more people into the Avalonia ecosystem over time, that is a win.&lt;/p&gt;
    &lt;p&gt;So this project is not about âsavingâ MAUI from other frameworks. It is about giving existing MAUI developers more headroom and additional platforms, learning from their needs, and ensuring Avalonia is an obvious, competitive choice for whatever they build next.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why This Matters for MAUI Developers&lt;/head&gt;
    &lt;p&gt;If you have followed MAUI since its launch, you will know the two requests that never went away.&lt;/p&gt;
    &lt;p&gt;Developers want Linux support, both for desktop and for embedded devices. They also want a drawn control model that provides consistent behaviour across platforms, rather than relying on the native toolkit available on each system.&lt;/p&gt;
    &lt;p&gt;The Avalonia backend tackles both of those head on. Avalonia is a mature drawn UI framework.&lt;/p&gt;
    &lt;p&gt;It provides:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Hardware accelerated rendering on every platform&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;A consistent layout and styling system&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Smooth animations at high refresh rates&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Custom rendering and visual effects capabilities&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Broad platform coverage&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;A fully supported platform that is receiving significant investment&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These are not theoretical promises. They are the reasons Avalonia is used in production by companies such as Unity, JetBrains and Schneider Electric.&lt;/p&gt;
    &lt;p&gt;By building MAUI on top of Avalonia, you get a predictable, drawn UI foundation and an expanded set of platforms, without having to throw away your existing codebase. You do not need to abandon MAUI to get Linux and the web. You can bring MAUI with you, while also improving the experience on Windows and macOS.&lt;/p&gt;
    &lt;head rend="h2"&gt;Performance and Next Generation Rendering&lt;/head&gt;
    &lt;p&gt;Performance is an important part of this story.&lt;/p&gt;
    &lt;p&gt;A drawn, GPU friendly UI stack gives you more headroom than wrapping native toolkits.&lt;/p&gt;
    &lt;p&gt;We are collaborating with the Flutter team at Google to bring Impeller, their GPU first renderer, to .NET. That work is already in progress and as it lands, the MAUI backend will inherit those gains.&lt;/p&gt;
    &lt;p&gt;The aim is simple: faster rendering, lower battery usage and smoother animations across desktop, mobile and embedded, using the same underlying technology that is pushing Flutter forward.&lt;/p&gt;
    &lt;p&gt;Read more about our Impeller collaboration with Google â&lt;/p&gt;
    &lt;head rend="h2"&gt;Looking Forward&lt;/head&gt;
    &lt;p&gt;We are particularly grateful to the MAUI engineers who have shared feedback and ideas as we have developed this backend. The .NET client ecosystem is at its best when different teams can cross pollinate and push each other forward.&lt;/p&gt;
    &lt;p&gt;This is just the beginning. As Linux and browser support matures, MAUI can finally live up to its promise as a truly multi platform app UI. We will keep sharing previews, benchmarks and updates as development continues, and once we are happy with the stability of the backend we will release the source code as fully open source under the MIT licence.&lt;/p&gt;
    &lt;p&gt;We are bringing .NET MAUI to Linux and to the browser, powered by Avalonia.&lt;/p&gt;
    &lt;p&gt;For the past few months, we have been working on an Avalonia powered backend for .NET MAUI, with guidance and feedback from engineers in the MAUI ecosystem. What started as an experiment has grown into a project we are committing to, with apps already running on new platforms. It is time to show you what we have been building.&lt;/p&gt;
    &lt;head rend="h2"&gt;Try It Right Now&lt;/head&gt;
    &lt;p&gt;Before we dive into the details, you can experience it yourself:&lt;/p&gt;
    &lt;p&gt;Launch MAUI in your browser â&lt;/p&gt;
    &lt;p&gt;This is a real MAUI application running on WebAssembly, rendered through Avalonia, with no plugins or hidden tricks. It is an early build with rough edges, but it proves the point: MAUI can now run on every major desktop OS and in the browser.&lt;/p&gt;
    &lt;head rend="h2"&gt;What is the Avalonia MAUI Backend?&lt;/head&gt;
    &lt;p&gt;At its core, the Avalonia MAUI Backend enables you to keep your MAUI codebase while replacing the rendering layer with Avalonia. The goal is straightforward: take your existing MAUI applications and extend them to additional platforms, while enhancing desktop performance along the way.&lt;/p&gt;
    &lt;p&gt;In practical terms, that means several big wins.&lt;/p&gt;
    &lt;head rend="h3"&gt;Desktop Linux support&lt;/head&gt;
    &lt;p&gt;.NET MAUI apps running as first class desktop apps on distributions such as Ubuntu, Debian and Fedora, sharing the same Avalonia renderer that already powers demanding desktop apps in production today.&lt;/p&gt;
    &lt;head rend="h3"&gt;Embedded Linux&lt;/head&gt;
    &lt;p&gt;Avalonia already runs on embedded Linux devices, from Raspberry Pi panels to industrial HMIs. Using the same backend, the Avalonia MAUI Backend brings those capabilities to MAUI as well, so the applications you build in MAUI can run on the same embedded Linux targets as Avalonia.&lt;/p&gt;
    &lt;head rend="h3"&gt;WebAssembly support&lt;/head&gt;
    &lt;p&gt;The demo you can open in your browser today is a real MAUI application running on WebAssembly, rendered by Avalonia, with no native dependencies on the client. It is an early build, but it demonstrates what is now possible. MAUI apps will soon be free to deploy to the browser.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bonus: The Avalonia MAUI Backend runs on Windows and macOS too&lt;/head&gt;
    &lt;p&gt;On Windows and macOS, it plugs into the same mature desktop story Avalonia already has. On macOS, early testing indicates significantly improved performance compared to the Mac Catalyst approach. We are seeing more than 2x the performance in representative desktop scenarios, which is a very encouraging sign for the future of MAUI on desktop.&lt;/p&gt;
    &lt;p&gt;All of this is possible because we have built a version of MAUI that sits on top of Avaloniaâs drawn UI model rather than native controls. Not only do you get more platforms and improved performance, your MAUI applications can look and behave consistently whether they are on Windows, macOS, Linux, mobile or running in a browser tab.&lt;/p&gt;
    &lt;head rend="h3"&gt;Simpler, faster development&lt;/head&gt;
    &lt;p&gt;For the Avalonia team, this architecture has a major practical benefit: we only have to target one platform: Avalonia itself. That single target means we can move faster, ship features consistently, and avoid the need to endlessly fix platform-specific edge cases.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;Instead of maintaining separate implementations for iOS, Android, Windows, macOS, Linux, and WebAssembly, we maintain just one. That massively reduces the chances of platform quirks, that can eat up hours of debugging time when something works on Android but not iOS, or renders differently on Mac Catalyst versus WinUI 3. When building on Avalonia, the controls render the same way everywhere because they are using the same rendering engine everywhere.&lt;lb/&gt;That means when we add a feature or fix a bug, it works across all platforms. No more "this works on mobile but breaks on desktop" or "this looks right on Windows but wrong on macOS." The entire development cycle becomes more predictable and significantly faster. &lt;lb/&gt;For us, that is a significant advantage. For MAUI developers, it means the backend evolves faster and more reliably.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Is Avalonia Building a Backend for MAUI?&lt;/head&gt;
    &lt;p&gt;It is a fair question. Avalonia already has its own thriving ecosystem. We see strong, sustained growth in our community, so why invest this much effort into making MAUI run on top of Avalonia?&lt;/p&gt;
    &lt;p&gt;The honest answer is that we care about .NET client developers first, and about which on ramp they use second. Many teams have already chosen MAUI, which they like and want more from. If we can provide them with Linux and browser support, along with improved desktop performance, without requiring a rewrite, that aligns with our mission to delight developers and solve complex problems.&lt;/p&gt;
    &lt;p&gt;This is not entirely selfless. Building a MAUI backend is also a way for us to learn. Running MAUI on Avalonia highlights what is missing for Avalonia to feel completely natural on mobile, which APIs are problematic, which tooling gaps matter, and where we need to raise our game to stay competitive. The work we are doing here directly contributes to strengthening Avalonia.&lt;/p&gt;
    &lt;p&gt;There is also a long term benefit in familiarity. By using Avalonia as the backend for their existing MAUI apps, developers gain insight into our renderer, capabilities and way of thinking. Some of those teams will quite reasonably stay with MAUI. Others, when they start a new project or need something lower level, may build directly on Avalonia instead. If this backend becomes a bridge that brings more people into the Avalonia ecosystem over time, that is a win.&lt;/p&gt;
    &lt;p&gt;So this project is not about âsavingâ MAUI from other frameworks. It is about giving existing MAUI developers more headroom and additional platforms, learning from their needs, and ensuring Avalonia is an obvious, competitive choice for whatever they build next.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why This Matters for MAUI Developers&lt;/head&gt;
    &lt;p&gt;If you have followed MAUI since its launch, you will know the two requests that never went away.&lt;/p&gt;
    &lt;p&gt;Developers want Linux support, both for desktop and for embedded devices. They also want a drawn control model that provides consistent behaviour across platforms, rather than relying on the native toolkit available on each system.&lt;/p&gt;
    &lt;p&gt;The Avalonia backend tackles both of those head on. Avalonia is a mature drawn UI framework.&lt;/p&gt;
    &lt;p&gt;It provides:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Hardware accelerated rendering on every platform&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;A consistent layout and styling system&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Smooth animations at high refresh rates&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Custom rendering and visual effects capabilities&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Broad platform coverage&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;A fully supported platform that is receiving significant investment&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These are not theoretical promises. They are the reasons Avalonia is used in production by companies such as Unity, JetBrains and Schneider Electric.&lt;/p&gt;
    &lt;p&gt;By building MAUI on top of Avalonia, you get a predictable, drawn UI foundation and an expanded set of platforms, without having to throw away your existing codebase. You do not need to abandon MAUI to get Linux and the web. You can bring MAUI with you, while also improving the experience on Windows and macOS.&lt;/p&gt;
    &lt;head rend="h2"&gt;Performance and Next Generation Rendering&lt;/head&gt;
    &lt;p&gt;Performance is an important part of this story.&lt;/p&gt;
    &lt;p&gt;A drawn, GPU friendly UI stack gives you more headroom than wrapping native toolkits.&lt;/p&gt;
    &lt;p&gt;We are collaborating with the Flutter team at Google to bring Impeller, their GPU first renderer, to .NET. That work is already in progress and as it lands, the MAUI backend will inherit those gains.&lt;/p&gt;
    &lt;p&gt;The aim is simple: faster rendering, lower battery usage and smoother animations across desktop, mobile and embedded, using the same underlying technology that is pushing Flutter forward.&lt;/p&gt;
    &lt;p&gt;Read more about our Impeller collaboration with Google â&lt;/p&gt;
    &lt;head rend="h2"&gt;Looking Forward&lt;/head&gt;
    &lt;p&gt;We are particularly grateful to the MAUI engineers who have shared feedback and ideas as we have developed this backend. The .NET client ecosystem is at its best when different teams can cross pollinate and push each other forward.&lt;/p&gt;
    &lt;p&gt;This is just the beginning. As Linux and browser support matures, MAUI can finally live up to its promise as a truly multi platform app UI. We will keep sharing previews, benchmarks and updates as development continues, and once we are happy with the stability of the backend we will release the source code as fully open source under the MIT licence.&lt;/p&gt;
    &lt;p&gt;We are bringing .NET MAUI to Linux and to the browser, powered by Avalonia.&lt;/p&gt;
    &lt;p&gt;For the past few months, we have been working on an Avalonia powered backend for .NET MAUI, with guidance and feedback from engineers in the MAUI ecosystem. What started as an experiment has grown into a project we are committing to, with apps already running on new platforms. It is time to show you what we have been building.&lt;/p&gt;
    &lt;head rend="h2"&gt;Try It Right Now&lt;/head&gt;
    &lt;p&gt;Before we dive into the details, you can experience it yourself:&lt;/p&gt;
    &lt;p&gt;Launch MAUI in your browser â&lt;/p&gt;
    &lt;p&gt;This is a real MAUI application running on WebAssembly, rendered through Avalonia, with no plugins or hidden tricks. It is an early build with rough edges, but it proves the point: MAUI can now run on every major desktop OS and in the browser.&lt;/p&gt;
    &lt;head rend="h2"&gt;What is the Avalonia MAUI Backend?&lt;/head&gt;
    &lt;p&gt;At its core, the Avalonia MAUI Backend enables you to keep your MAUI codebase while replacing the rendering layer with Avalonia. The goal is straightforward: take your existing MAUI applications and extend them to additional platforms, while enhancing desktop performance along the way.&lt;/p&gt;
    &lt;p&gt;In practical terms, that means several big wins.&lt;/p&gt;
    &lt;head rend="h3"&gt;Desktop Linux support&lt;/head&gt;
    &lt;p&gt;.NET MAUI apps running as first class desktop apps on distributions such as Ubuntu, Debian and Fedora, sharing the same Avalonia renderer that already powers demanding desktop apps in production today.&lt;/p&gt;
    &lt;head rend="h3"&gt;Embedded Linux&lt;/head&gt;
    &lt;p&gt;Avalonia already runs on embedded Linux devices, from Raspberry Pi panels to industrial HMIs. Using the same backend, the Avalonia MAUI Backend brings those capabilities to MAUI as well, so the applications you build in MAUI can run on the same embedded Linux targets as Avalonia.&lt;/p&gt;
    &lt;head rend="h3"&gt;WebAssembly support&lt;/head&gt;
    &lt;p&gt;The demo you can open in your browser today is a real MAUI application running on WebAssembly, rendered by Avalonia, with no native dependencies on the client. It is an early build, but it demonstrates what is now possible. MAUI apps will soon be free to deploy to the browser.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bonus: The Avalonia MAUI Backend runs on Windows and macOS too&lt;/head&gt;
    &lt;p&gt;On Windows and macOS, it plugs into the same mature desktop story Avalonia already has. On macOS, early testing indicates significantly improved performance compared to the Mac Catalyst approach. We are seeing more than 2x the performance in representative desktop scenarios, which is a very encouraging sign for the future of MAUI on desktop.&lt;/p&gt;
    &lt;p&gt;All of this is possible because we have built a version of MAUI that sits on top of Avaloniaâs drawn UI model rather than native controls. Not only do you get more platforms and improved performance, your MAUI applications can look and behave consistently whether they are on Windows, macOS, Linux, mobile or running in a browser tab.&lt;/p&gt;
    &lt;head rend="h3"&gt;Simpler, faster development&lt;/head&gt;
    &lt;p&gt;For the Avalonia team, this architecture has a major practical benefit: we only have to target one platform: Avalonia itself. That single target means we can move faster, ship features consistently, and avoid the need to endlessly fix platform-specific edge cases.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;Instead of maintaining separate implementations for iOS, Android, Windows, macOS, Linux, and WebAssembly, we maintain just one. That massively reduces the chances of platform quirks, that can eat up hours of debugging time when something works on Android but not iOS, or renders differently on Mac Catalyst versus WinUI 3. When building on Avalonia, the controls render the same way everywhere because they are using the same rendering engine everywhere.&lt;lb/&gt;That means when we add a feature or fix a bug, it works across all platforms. No more "this works on mobile but breaks on desktop" or "this looks right on Windows but wrong on macOS." The entire development cycle becomes more predictable and significantly faster. &lt;lb/&gt;For us, that is a significant advantage. For MAUI developers, it means the backend evolves faster and more reliably.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Is Avalonia Building a Backend for MAUI?&lt;/head&gt;
    &lt;p&gt;It is a fair question. Avalonia already has its own thriving ecosystem. We see strong, sustained growth in our community, so why invest this much effort into making MAUI run on top of Avalonia?&lt;/p&gt;
    &lt;p&gt;The honest answer is that we care about .NET client developers first, and about which on ramp they use second. Many teams have already chosen MAUI, which they like and want more from. If we can provide them with Linux and browser support, along with improved desktop performance, without requiring a rewrite, that aligns with our mission to delight developers and solve complex problems.&lt;/p&gt;
    &lt;p&gt;This is not entirely selfless. Building a MAUI backend is also a way for us to learn. Running MAUI on Avalonia highlights what is missing for Avalonia to feel completely natural on mobile, which APIs are problematic, which tooling gaps matter, and where we need to raise our game to stay competitive. The work we are doing here directly contributes to strengthening Avalonia.&lt;/p&gt;
    &lt;p&gt;There is also a long term benefit in familiarity. By using Avalonia as the backend for their existing MAUI apps, developers gain insight into our renderer, capabilities and way of thinking. Some of those teams will quite reasonably stay with MAUI. Others, when they start a new project or need something lower level, may build directly on Avalonia instead. If this backend becomes a bridge that brings more people into the Avalonia ecosystem over time, that is a win.&lt;/p&gt;
    &lt;p&gt;So this project is not about âsavingâ MAUI from other frameworks. It is about giving existing MAUI developers more headroom and additional platforms, learning from their needs, and ensuring Avalonia is an obvious, competitive choice for whatever they build next.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why This Matters for MAUI Developers&lt;/head&gt;
    &lt;p&gt;If you have followed MAUI since its launch, you will know the two requests that never went away.&lt;/p&gt;
    &lt;p&gt;Developers want Linux support, both for desktop and for embedded devices. They also want a drawn control model that provides consistent behaviour across platforms, rather than relying on the native toolkit available on each system.&lt;/p&gt;
    &lt;p&gt;The Avalonia backend tackles both of those head on. Avalonia is a mature drawn UI framework.&lt;/p&gt;
    &lt;p&gt;It provides:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Hardware accelerated rendering on every platform&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;A consistent layout and styling system&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Smooth animations at high refresh rates&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Custom rendering and visual effects capabilities&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Broad platform coverage&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;A fully supported platform that is receiving significant investment&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These are not theoretical promises. They are the reasons Avalonia is used in production by companies such as Unity, JetBrains and Schneider Electric.&lt;/p&gt;
    &lt;p&gt;By building MAUI on top of Avalonia, you get a predictable, drawn UI foundation and an expanded set of platforms, without having to throw away your existing codebase. You do not need to abandon MAUI to get Linux and the web. You can bring MAUI with you, while also improving the experience on Windows and macOS.&lt;/p&gt;
    &lt;head rend="h2"&gt;Performance and Next Generation Rendering&lt;/head&gt;
    &lt;p&gt;Performance is an important part of this story.&lt;/p&gt;
    &lt;p&gt;A drawn, GPU friendly UI stack gives you more headroom than wrapping native toolkits.&lt;/p&gt;
    &lt;p&gt;We are collaborating with the Flutter team at Google to bring Impeller, their GPU first renderer, to .NET. That work is already in progress and as it lands, the MAUI backend will inherit those gains.&lt;/p&gt;
    &lt;p&gt;The aim is simple: faster rendering, lower battery usage and smoother animations across desktop, mobile and embedded, using the same underlying technology that is pushing Flutter forward.&lt;/p&gt;
    &lt;p&gt;Read more about our Impeller collaboration with Google â&lt;/p&gt;
    &lt;head rend="h2"&gt;Looking Forward&lt;/head&gt;
    &lt;p&gt;We are particularly grateful to the MAUI engineers who have shared feedback and ideas as we have developed this backend. The .NET client ecosystem is at its best when different teams can cross pollinate and push each other forward.&lt;/p&gt;
    &lt;p&gt;This is just the beginning. As Linux and browser support matures, MAUI can finally live up to its promise as a truly multi platform app UI. We will keep sharing previews, benchmarks and updates as development continues, and once we are happy with the stability of the backend we will release the source code as fully open source under the MIT licence.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45893986</guid><pubDate>Tue, 11 Nov 2025 22:50:32 +0000</pubDate></item><item><title>Why Nietzsche matters in the age of artificial intelligence</title><link>https://cacm.acm.org/blogcacm/why-nietzsche-matters-in-the-age-of-artificial-intelligence/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45894588</guid><pubDate>Tue, 11 Nov 2025 23:59:49 +0000</pubDate></item><item><title>Perkeep – Personal storage system for life</title><link>https://perkeep.org/</link><description>&lt;doc fingerprint="47dd1e4e29b72f56"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Perkeep lets you permanently keep your stuff, for life.&lt;/head&gt;
    &lt;p&gt;Perkeep (née Camlistore) is a set of open source formats, protocols, and software for modeling, storing, searching, sharing and synchronizing data in the post-PC era. Data may be files or objects, tweets or 5TB videos, and you can access it via a phone, browser or FUSE filesystem.&lt;/p&gt;
    &lt;p&gt;Perkeep is under active development. If you're a programmer or fairly technical, you can probably get it up and running and get some utility out of it. Many bits and pieces are actively being developed, so be prepared for bugs and unfinished features.&lt;/p&gt;
    &lt;p&gt;Join the community, consider contributing, or file a bug.&lt;/p&gt;
    &lt;p&gt;Things Perkeep believes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Your data is entirely under your control&lt;/item&gt;
      &lt;item&gt;Open Source&lt;/item&gt;
      &lt;item&gt;Paranoid about privacy, everything private by default&lt;/item&gt;
      &lt;item&gt;No SPOF: don't rely on any single party (including yourself)&lt;/item&gt;
      &lt;item&gt;Your data should be alive in 80 years, especially if you are&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Latest Release&lt;/head&gt;
    &lt;p&gt;The latest release is 0.12 ("Toronto"), released 2025-11-11.&lt;/p&gt;
    &lt;p&gt;Follow the download and getting started instructions to set up Perkeep.&lt;/p&gt;
    &lt;head rend="h2"&gt;Video Demo&lt;/head&gt;
    &lt;p&gt;LinuxFest Northwest 2018 [slides] [video]:&lt;/p&gt;
    &lt;p&gt;Or see the other presentations.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45896130</guid><pubDate>Wed, 12 Nov 2025 03:34:32 +0000</pubDate></item><item><title>Simulating a Planet on the GPU: Part 1 (2022)</title><link>https://www.patrickcelentano.com/blog/planet-sim-part-1</link><description>&lt;doc fingerprint="2545217d4ee8281b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Simulating a Planet on the GPU: Part 1&lt;/head&gt;
    &lt;p&gt;I miss Sim Earth.&lt;/p&gt;
    &lt;p&gt;To be fair, it didn’t go anywhere. You can still boot up a copy, mess around with evolution, atmospheric conditions, and continental drift like it’s 1990… but it’s not 1990. We have 32 years of computing advances at our backs and yet no SimEarth 2. Sure there’s WorldBox and Worlds and a bunch of awesome planet generation projects, (1, 2, 3) but none allow me to play with plate tectonics, currents, or any of the “deep” factors underlying how the Earth really works.&lt;/p&gt;
    &lt;p&gt;Sometime last year, I decided against writing Will Wright a letter, begging him to spend hundreds of hours making a SimEarth 2. Instead, I did what any good programmer would do and decided to devote thousands of my own hours into the same thing. This blog describes my first step toward such a goal: describing well over a year’s worth of work and the many detours taken along the way. While there’s a long way to go from here, I’m very happy to share my progress to this point, and promise to follow up with a “part 2” at some future date.&lt;/p&gt;
    &lt;head rend="h2"&gt;Polygon-Based Approaches&lt;/head&gt;
    &lt;p&gt;My first dozen or so approaches at realistic world generation involved generating polygons on a sphere, using Delaunay Triangulation and Voronoi Tessellation. These fancy-sounding processes allow us to cheaply turn a 2D surface (or indeed, spheres, thanks to this amazing blog) into a number of polygons for representing geographic features. Once I wrapped my head around wrapping Voronoi polygons around the North and South Poles, I managed to get something vaguely passing as a planet generated, and applied a nice water shader.&lt;/p&gt;
    &lt;p&gt;The fundamental issue with a polygon-centric approach is one of tectonic plate realism: plate collisions require an incredible number of polygons to model correctly. Increasing the number of polygons in a Unity &amp;amp; C# environment proved prohibitively expensive, so I turned to an old favorite: C++. After finding Brendan Galea’s excellent YouTube channel and building the first of the three demos above in SDL2 &amp;amp; Vulkan I realized what a titanic task writing a custom engine for this project would be, and went back to the (Unity) drawing board.&lt;/p&gt;
    &lt;head rend="h2"&gt;Cubemap-Overlap-Based Approaches&lt;/head&gt;
    &lt;p&gt;Frustrated with the poor performance of my polygonal approach, I began to research Unity’s performance optimization tools. I chunked up and parallelized the Voronoi tessellation to no avail. I tried rearranging memory to no avail. Clearly, something about doing this amount of math on the CPU was beyond current processing capabilities… but what about the GPU?&lt;/p&gt;
    &lt;p&gt;Like most programmers, I’d heard of the legendary power of GPUs, but had only really harnessed it via graphics programming or CUDA (for my Music ex Machina project). While I had some experience writing conventional shaders, learning how to write compute shaders seemed like a massive undertaking… but what option did I have? I had no room left on the CPU.&lt;/p&gt;
    &lt;p&gt;Put simply, compute shaders are capable of applying a GPU’s heavily-parallelized workflow to arbitrary data, meaning I could simulate a world full of tectonic plates one “pixel” at a time. Once I figured out how to represent potentially world-spanning plates as cubemaps, I managed to create a neat compute shader-based simulation with plates colliding, subducting, and emerging from seafloor spreading… but never deforming.&lt;/p&gt;
    &lt;p&gt;While I liked the direction this adventure in compute shaders had taken me, I needed some new technique which could realistically deform crust at convergent plate boundaries.&lt;/p&gt;
    &lt;head rend="h2"&gt;Smoothed-Particle Hydrodynamics&lt;/head&gt;
    &lt;p&gt;Inspiration can come from anywhere, and as luck would have it, the inspiration for my next step forward came from watching this physical simulation of a plate boundary. The use of sand for crust material makes realistic deformation possible… and reminded me of the falling sand games which were so popular when I was a kid. Could I simulate little bits of “crust” which could bump into one another, forming mountains and valleys? Could I use the same system for air and water?&lt;/p&gt;
    &lt;p&gt;After a little digging, I discovered Smoothed-Particle Hydrodynamics, a technique commonly used in place of cellular fluid simulations. If I could just implement SPH on a sphere using my newfound knowledge of compute shaders, I’d have the fundamentals of a truly-unique planet sim. With a clear implementation strategy in mind, how long could implementing it possibly take?&lt;/p&gt;
    &lt;p&gt;As it turns out, quite a while.&lt;/p&gt;
    &lt;p&gt;Writing compute shaders is difficult, as is debugging and profiling them. I found myself performing true computer “science” on multiple occasions: forming a hypothesis about the performance impact of some new algorithm on the GPU and verifying it through good, old-fashioned experimentation. I learned a great deal in the process, most notably that computation is cheap and memory is expensive! More in depth, I’d highly recommend this incredible talk on compute shader performance optimization. I owe much of this project’s success to that talk.&lt;/p&gt;
    &lt;head rend="h2"&gt;What’s Next?&lt;/head&gt;
    &lt;p&gt;This project has proved one of the most difficult I’ve ever worked on, and yet, one of the most satisfying. I hope to build a great deal on this foundation, slowly approaching a fully-featured planetary simulation. Here are a few thoughts as to what might be next:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Create map modes to display the direction of the currents (at present you can only see the waves moving in the right direction)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Show the air currents in some clever way, perhaps with a moving cloud layer on top of the planet&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Allow the wind to pick up moisture from warm bodies of water and precipitate it back on land… including rain shadows caused by mountain ranges&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Allow currents to warm up the surrounding air, causing phenomenon like the North Atlantic Current's miraculous warming of Europe.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Add hotspots, volcanoes, and a variety of rock types&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Optimize it to run on hardware beyond my Surface Book 2&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here’s to blog #2, with whatever new features that brings! Oh, and looking for a download link? Follow through to this page. Happy simulating : )&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45897122</guid><pubDate>Wed, 12 Nov 2025 06:58:06 +0000</pubDate></item><item><title>Yann LeCun to depart Meta and launch AI startup focused on 'world models'</title><link>https://www.nasdaq.com/articles/metas-chief-ai-scientist-yann-lecun-depart-and-launch-ai-start-focused-world-models</link><description>&lt;doc fingerprint="293f17ef93b2d5d8"&gt;
  &lt;main&gt;
    &lt;p&gt;(RTTNews) - Meta's (META) chief artificial intelligence scientist, Yann LeCun, plans to leave the company to launch his own AI start-up, marking a major shift inside Meta as CEO Mark Zuckerberg doubles down on "superintelligence" initiatives to compete with OpenAI and Google, according to people familiar with the matter.&lt;/p&gt;
    &lt;p&gt;LeCun, a Turing Award-winning pioneer of modern AI, has begun early fundraising discussions for his new venture, which will focus on developing "world models," next-generation systems designed to learn from visual and spatial data rather than text. These models aim to replicate human reasoning and understanding of the physical world, a project LeCun has said could take a decade to mature.&lt;/p&gt;
    &lt;p&gt;LeCun's exit comes amid an internal overhaul of Meta's AI strategy. Zuckerberg has shifted Meta's Fundamental AI Research Lab - FAIR, which LeCun founded in 2013, away from long-term research toward commercial AI products and large language models - LLMs. The move follows the underwhelming release of Meta's Llama 4 model, which lagged behind rival offerings from Anthropic, Google, and OpenAI.&lt;/p&gt;
    &lt;p&gt;To accelerate progress, Zuckerberg recently hired Alexandr Wang, founder of Scale AI, paying $14.3 billion for a 49 percent stake in his company and appointing him to lead Meta's new Superintelligence division, to which LeCun now reports. The CEO also formed an elite team called TBD Lab, offering $100 million pay packages to lure top AI talent from competitors.&lt;/p&gt;
    &lt;p&gt;LeCun has publicly disagreed with Zuckerberg's heavy reliance on LLMs, calling them "useful but fundamentally limited" in their ability to reason and plan like humans. His upcoming start-up will extend his FAIR research into "world models" that could ultimately enable machines to think more like people.&lt;/p&gt;
    &lt;p&gt;LeCun's planned departure adds to a series of AI leadership shake-ups at Meta. In recent months, Joelle Pineau, vice-president of AI research, left for Cohere, and the company laid off 600 employees from its AI division. Meanwhile, Shengjia Zhao, co-creator of ChatGPT, joined Meta as chief scientist of the Superintelligence Lab.&lt;/p&gt;
    &lt;p&gt;The upheaval follows investor pressure after Meta's shares plunged 12.6% in late October, wiping out nearly $240 billion in market value, when Zuckerberg indicated that AI spending could exceed $100 billion next year.&lt;/p&gt;
    &lt;p&gt;LeCun's move signals both a philosophical and structural rift within Meta's AI program, and the emergence of a potential new rival in the race toward true artificial general intelligence.&lt;/p&gt;
    &lt;p&gt;Tuesday META closed at $627.08, down 0.74%, and is trading after hours at $627.00, down 0.01% on the NasdaqGS.&lt;/p&gt;
    &lt;p&gt;The views and opinions expressed herein are the views and opinions of the author and do not necessarily reflect those of Nasdaq, Inc.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45897271</guid><pubDate>Wed, 12 Nov 2025 07:25:30 +0000</pubDate></item><item><title>Please donate to keep Network Time Protocol up – Goal 1k</title><link>https://www.ntp.org/</link><description>&lt;doc fingerprint="55b54b1f4a682295"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;The NTP Project conducts Research and Development in NTP, a protocol designed to synchronize the clocks of computers over a network to a common timebase. NTP is what ensures the reliability of billions of devices around the world, under the sea, and even in space. Accurate timekeeping is vital to the many applications which have revolutionized and are essential to our daily lives: satellites, GPS, 5G, financial services, healthcare, and more.&lt;/p&gt;
      &lt;p&gt;The NTP Project produces an open source Reference Implementation of the NTP standard, maintains the implementation Documentation, and develops the protocol and algorithmic standard that is used to communicate time between systems. Background information about NTP can be found in the Reference Library.&lt;/p&gt;
      &lt;p&gt;Network Time Foundation provides support for the NTP Project. Learn more about the Foundation’s work.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45897457</guid><pubDate>Wed, 12 Nov 2025 07:56:35 +0000</pubDate></item><item><title>What happened to Transmeta, the last big dotcom IPO</title><link>https://dfarq.homeip.net/what-happened-to-transmeta-the-last-big-dotcom-ipo/</link><description>&lt;doc fingerprint="7e934997b964874e"&gt;
  &lt;main&gt;
    &lt;p&gt;Transmeta was the last big IPO of the dotcom era, launching Nov 7, 2000. Some analysts call its $273 million IPO the last successful tech IPO until the Google IPO in 2004. Transmeta didn’t completely fit in to the dotcom era, because they were a hardware company. But they were still a technology company, and if their plans had gone well, they would have sold their product to dotcoms, but it didn’t work out that way for them. In this blog post we explore what happened to Transmeta.&lt;/p&gt;
    &lt;head rend="h2"&gt;Was Transmeta truly the last of the dotcoms?&lt;/head&gt;
    &lt;p&gt;I’ve heard Transmeta called the last successful IPO of the dotcom era, or the last of the big dotcom IPOs. But it’s an oversimplification to say there weren’t any successful technology IPOs between Transmeta and Google. One very notable exception is Paypal, who ran an IPO in February 2002 that raised $70.2 million. The Register even hailed Paypal as the return of the Internet IPO.&lt;/p&gt;
    &lt;p&gt;And it wasn’t just that dotcom IPOs grew scarce after November 2000. On February 7, 2002, Forbes stated that only 34 IPOs in total launched between September 11, 2001 and February 6, 2002, compared to 87 in the same-year-earlier period, and 240 between September 11, 1999 and February 6, 2000. That date is significant. Any bad news can spook investors, and the 9/11 attack did, in fact, spook investors.&lt;/p&gt;
    &lt;p&gt;So where the dotcom-era ended is a fuzzy line, but it makes sense to draw the line at Transmeta. Technology IPOs and particularly Internet IPOs became much more scarce after Transmeta, and the size of the IPOs shrunk too. The distinction of Transmeta being a technology stock, rather than an Internet stock, also suggests investors were already cooling on Internet stocks by November 2000.&lt;/p&gt;
    &lt;head rend="h2"&gt;What was Transmeta?&lt;/head&gt;
    &lt;p&gt;Transmeta was a CPU company. But they may be better known for their most famous employee than for any of their products. When Linus Torvalds completed his degree, there was a great deal of speculation where he would take his day job. Transmeta was not the place most technologists expected him to land. But it allowed him to continue his work on the Linux kernel while staying close to a key part of the hardware, the CPU.&lt;/p&gt;
    &lt;p&gt;In the year 2000, the CPU wars were cooling down. A few years earlier, there had been four companies not named Intel producing Socket 7 CPUs. But only two of them survived to compete in the next generation, and only AMD was able to compete at anything other than the entry level. And even though the Cyrix name survived, it was the competing IDT technology under the hood.&lt;/p&gt;
    &lt;head rend="h2"&gt;How its CPUs worked&lt;/head&gt;
    &lt;p&gt;Transmeta wanted to take a different approach. They were going to produce an x86 compatible CPU, but they were going to use a translation layer to do it. They would design a very efficient CPU, and in theory, they could place any translation layer in front of it that they wanted. Emulating PowerPC or ARM would have been possible if they saw the need to do it. But the popular yet inefficient x86 architecture was a more inviting target.&lt;/p&gt;
    &lt;p&gt;AMD was doing something similar, essentially translating x86 instructions into RISC instructions for efficiency, but they did it in hardware rather than software like Transmeta did. AMD never had any designs on putting any different translation layer in front of it.&lt;/p&gt;
    &lt;p&gt;Transmeta did ship two CPUs, but weren’t able to reach the same levels of performance AMD and Intel were reaching. Its first CPU, Crusoe, could run at Pentium III-like speeds but was about 30% less efficient, so a 700 MHz Crusoe ran like a 500 MHz Pentium III. Transmeta didn’t have fabrication plants of its own, so IBM handled manufacturing of its first-generation CPUs.&lt;/p&gt;
    &lt;p&gt;The Transmeta Efficieon, released in 2004, competed with the Pentium 4 but peaked at 1.7 GHz. With the Pentium 4 reaching 2.4 GHz speeds, the Efficieon had trouble competing. And AMD’s release of the Athlon 64 didn’t help matters. Selling 32-bit CPUs in a 64-bit world was going to be tough. TSMC and Fujitsu handled manufacturing for the Efficieon.&lt;/p&gt;
    &lt;p&gt;Transmeta CPUs saw use in low-power laptops, thin clients, and embedded applications. The Bluecoat web filtering appliance used them for a while. But if you owned a computer at that time, it’s much more likely to have had an AMD or Intel CPU in it. If you used one at work, it was even more likely to have an AMD or Intel CPU in it.&lt;/p&gt;
    &lt;head rend="h2"&gt;What happened to Transmeta&lt;/head&gt;
    &lt;p&gt;Even though Transmeta was the last big dotcom era IPO, they were not among the survivors. Torvalds resigned from Transmeta in June 2003.&lt;/p&gt;
    &lt;p&gt;What happened to Transmeta was that in 2005, Transmeta shifted to licensing intellectual property rather than selling CPUs. And in January 2009, Transmeta sold itself to Novafora, who in turn sold the patent portfolio to Intellectual Ventures, a private equity company. Novafora ceased operations in August 2009, just seven months later. Intellectual Ventures licenses the Transmeta intellectual property to other companies on a non-exclusive basis. Transmeta ended up being more like Netscape or VA Linux than Red Hat.&lt;/p&gt;
    &lt;p&gt;Today, Transmeta hardware is rare enough to be interesting as a collectible. But there aren’t a lot of people nostalgic for it, and that probably keeps prices low.&lt;/p&gt;
    &lt;p&gt;David Farquhar is a computer security professional, entrepreneur, and author. He has written professionally about computers since 1991, so he was writing about retro computers when they were still new. He has been working in IT professionally since 1994 and has specialized in vulnerability management since 2013. He holds Security+ and CISSP certifications. Today he blogs five times a week, mostly about retro computers and retro gaming covering the time period from 1975 to 2000.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45897935</guid><pubDate>Wed, 12 Nov 2025 09:01:41 +0000</pubDate></item><item><title>Yt-dlp: External JavaScript runtime now required for full YouTube support</title><link>https://github.com/yt-dlp/yt-dlp/issues/15012</link><description>&lt;doc fingerprint="bf4f981dcca3bac1"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Notifications &lt;tool-tip&gt;You must be signed in to change notification settings&lt;/tool-tip&gt;&lt;/item&gt;
      &lt;item&gt;Fork 10.8k&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Description&lt;/head&gt;
    &lt;p&gt;This is a follow-up to #14404, which announced that yt-dlp will soon require an external JavaScript runtime (e.g. Deno) in order to fully support downloading from YouTube.&lt;/p&gt;
    &lt;head rend="h3"&gt;With the release of yt-dlp version &lt;code&gt;2025.11.12&lt;/code&gt;, external JavaScript runtime support has arrived.&lt;/head&gt;
    &lt;head rend="h3"&gt;All users who intend to use yt-dlp with YouTube are strongly encouraged to install one of the supported JS runtimes.&lt;/head&gt;
    &lt;p&gt;The following JavaScript runtimes are currently supported (in order of recommendation, from strongest to weakest):&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Deno&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;recommended for most users&lt;/item&gt;
          &lt;item&gt;https://deno.com/&lt;/item&gt;
          &lt;item&gt;https://github.com/denoland/deno &lt;list rend="ul"&gt;&lt;item&gt;note: if downloading from Deno's GitHub releases, get &lt;code&gt;deno&lt;/code&gt;not&lt;code&gt;denort&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;note: if downloading from Deno's GitHub releases, get &lt;/item&gt;
          &lt;item&gt;minimum Deno version supported by yt-dlp: &lt;code&gt;2.0.0&lt;/code&gt;&lt;list rend="ul"&gt;&lt;item&gt;the latest version of Deno is strongly recommended&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Node&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;https://nodejs.org/&lt;/item&gt;
          &lt;item&gt;minimum Node version supported by yt-dlp: &lt;code&gt;20.0.0&lt;/code&gt;&lt;list rend="ul"&gt;&lt;item&gt;if using Node, the latest version (25+) is strongly recommended for security reasons&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;QuickJS&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;https://bellard.org/quickjs/&lt;/item&gt;
          &lt;item&gt;minimum QuickJS version supported by yt-dlp: &lt;code&gt;2023-12-9&lt;/code&gt;&lt;list rend="ul"&gt;&lt;item&gt;if using QuickJS, version &lt;code&gt;2025-4-26&lt;/code&gt;or later is strongly recommended for performance reasons&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;if using QuickJS, version &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;QuickJS-ng&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;https://quickjs-ng.github.io/quickjs/&lt;/item&gt;
          &lt;item&gt;all versions are supported by yt-dlp; however, upstream QuickJS is recommended instead for performance reasons&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Bun&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;https://bun.com/&lt;/item&gt;
          &lt;item&gt;minimum Bun version supported by yt-dlp: &lt;code&gt;1.0.31&lt;/code&gt;&lt;list rend="ul"&gt;&lt;item&gt;if using Bun, the latest version is strongly recommended&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note that only &lt;code&gt;deno&lt;/code&gt; is enabled by default; all others are disabled by default for security reasons. See the EJS wiki page for more details.&lt;/p&gt;
    &lt;p&gt;In addition to the JavaScript runtime, yt-dlp also requires the yt-dlp-ejs component in order to operate the JS runtime.&lt;/p&gt;
    &lt;p&gt;NOTE: This component is already included in all of the official yt-dlp executables.&lt;lb/&gt; Similarly, if you've installed &amp;amp; upgraded the yt-dlp Python package with the &lt;code&gt;default&lt;/code&gt; extra (&lt;code&gt;yt-dlp[default]&lt;/code&gt;), then you already have the yt-dlp-ejs component.&lt;/p&gt;
    &lt;p&gt;If you've installed yt-dlp another way, then please refer to section 2 of the EJS wiki page for more details.&lt;/p&gt;
    &lt;p&gt;Support for YouTube without a JavaScript runtime is now considered "deprecated." It does still work somewhat; however, format availability will be limited, and severely so in some cases (e.g. for logged-in users). Format availability without a JS runtime is expected to worsen as time goes on, and this will not be considered a "bug" but rather an inevitability for which there is no solution. It's also expected that, eventually, support for YouTube will not be possible at all without a JS runtime.&lt;/p&gt;
    &lt;p&gt;If you have questions, please refer to the EJS wiki page, the previous announcement's FAQ, and the README before commenting or opening a new issue:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;https://github.com/yt-dlp/yt-dlp/wiki/EJS&lt;/item&gt;
      &lt;item&gt;[Announcement] Upcoming new requirements for YouTube downloads #14404&lt;/item&gt;
      &lt;item&gt;https://github.com/yt-dlp/yt-dlp#dependencies&lt;/item&gt;
      &lt;item&gt;https://github.com/yt-dlp/yt-dlp#general-options&lt;/item&gt;
      &lt;item&gt;https://github.com/yt-dlp/yt-dlp#youtube-ejs&lt;/item&gt;
      &lt;item&gt;https://github.com/yt-dlp/yt-dlp/wiki/EJS#plugins&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Notes to package maintainers&lt;/head&gt;
    &lt;p&gt;If you are maintaining a downstream package of yt-dlp, we offer the following guidance:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;yt-dlp&lt;/code&gt;repository, source tarball, PyPI source distribution and built distribution (wheel) are still licensed under The Unlicense (public domain); however, when the&lt;code&gt;yt-dlp-ejs&lt;/code&gt;package is built, it bundles code licensed under ISC and MIT. This is the primary reason why&lt;code&gt;yt-dlp-ejs&lt;/code&gt;was split off into a separate repository and PyPI package&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;If&lt;/p&gt;&lt;code&gt;yt-dlp&lt;/code&gt;is packaged as a Python package in your repository,&lt;code&gt;yt-dlp-ejs&lt;/code&gt;would ideally be packaged separately&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;yt-dlp-ejs&lt;/code&gt;is technically an optional Python dependency of yt-dlp, but YouTube support is deprecated without it&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Each version of&lt;/p&gt;&lt;code&gt;yt-dlp&lt;/code&gt;will be pinned to a specific version of&lt;code&gt;yt-dlp-ejs&lt;/code&gt;and yt-dlp will reject any other&lt;code&gt;yt-dlp-ejs&lt;/code&gt;version. Refer to yt-dlp's&lt;code&gt;pyproject.toml&lt;/code&gt;for the pinned version&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;If your repository packages&lt;/p&gt;&lt;code&gt;yt-dlp&lt;/code&gt;as the zipimport binary instead of as a Python package, you can use&lt;code&gt;make yt-dlp-extra&lt;/code&gt;to build the zip executable with&lt;code&gt;yt-dlp-ejs&lt;/code&gt;included. (The Makefile will look for the&lt;code&gt;yt-dlp-ejs&lt;/code&gt;wheel in the&lt;code&gt;build&lt;/code&gt;subdirectory, or the extracted built distribution in the&lt;code&gt;yt_dlp_ejs&lt;/code&gt;subdirectory)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;deno&lt;/code&gt;,&lt;code&gt;nodejs&lt;/code&gt;,&lt;code&gt;quickjs&lt;/code&gt;and/or&lt;code&gt;bun&lt;/code&gt;should be optional dependencies of&lt;code&gt;yt-dlp&lt;/code&gt;. But again, YouTube support is deprecated without one of them&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;While&lt;/p&gt;&lt;code&gt;yt-dlp-ejs&lt;/code&gt;and the external JavaScript runtimes are currently only used with YouTube, yt-dlp's usage of these may be expanded in the future (and necessarily so)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If this guidance is insufficient, or if you are a developer integrating yt-dlp into your software and you have further questions, please open a new GitHub issue.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45898407</guid><pubDate>Wed, 12 Nov 2025 10:12:53 +0000</pubDate></item><item><title>Pakistani newspaper mistakenly prints AI prompt with the article</title><link>https://twitter.com/omar_quraishi/status/1988518627859951986</link><description>&lt;doc fingerprint="d635f48b34542867"&gt;
  &lt;main&gt;
    &lt;p&gt;We’ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.&lt;/p&gt;
    &lt;p&gt;Help Center&lt;/p&gt;
    &lt;p&gt;Terms of Service Privacy Policy Cookie Policy Imprint Ads info © 2025 X Corp.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45898789</guid><pubDate>Wed, 12 Nov 2025 11:17:06 +0000</pubDate></item><item><title>Micro.blog launches new 'Studio' tier with video hosting</title><link>https://heydingus.net/blog/2025/11/micro-blog-offers-an-indie-alternative-to-youtube-with-its-studio-video-hosting-plan</link><description>&lt;doc fingerprint="b4db0e54e8a9e6f9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Micro.blog offers an indie alternative to YouTube with its ‘Studio’ video hosting plan&lt;/head&gt;
    &lt;p&gt;The core of Micro.blog’s mission is to make it easy for people to own their presence on the web. At first, it was a simple blog host that also incorporated a Twitter-like social timeline that put short (title-less) and long (titled) posts on equal footing. In the years since its 2017 launch, Manton Reece — Micro.blog’s founder — has added a plethora of features that expand upon that mission. Here’s a list off the top of my head:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Hosting podcasts&lt;/item&gt;
      &lt;item&gt;Bookmarking/archiving webpages&lt;/item&gt;
      &lt;item&gt;Fediverse compatibility with native replies to Mastodon and novel reply gathering from Bluesky&lt;/item&gt;
      &lt;item&gt;Crossposting to other social networks&lt;/item&gt;
      &lt;item&gt;Photo blogging&lt;/item&gt;
      &lt;item&gt;Custom domain name registration&lt;/item&gt;
      &lt;item&gt;Private notes&lt;/item&gt;
      &lt;item&gt;Book/Movie/TV Show blogging&lt;/item&gt;
      &lt;item&gt;Reading tracking&lt;/item&gt;
      &lt;item&gt;Automatic newsletters&lt;/item&gt;
      &lt;item&gt;Open APIs to manage your content&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All of this is hosted on your own website, (optionally, but strongly encouraged) at your own domain name. I’ve never seen anything else like it.&lt;/p&gt;
    &lt;p&gt;There are plans ranging from $1/month to $15/month that include subsets of these features, depending on how much a blogging “power user” you are.&lt;/p&gt;
    &lt;p&gt;Reece’s next1 big foray with Micro.blog: video hosting, which launched yesterday.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Micro.blog Studio adds longer video hosting for your blog, with uploads up to 20 minutes. You can read some of the technical bits here. It can automatically copy videos to PeerTube and Bluesky too.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That’s a quaint description for what promises to be a significant challenge.2 Because if hosting videos were easy, YouTube wouldn’t be the only3 game in town. And that’s exactly why Reece has pursued it. It’s not good for the open web for so much of its video content to live centralized at one host. John Gruber lamented this following Jimmy Kimmel’s suspension:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The big problem is YouTube. With YouTube, Google has a centralized chokehold on video. We need a way that’s as easy and scalable to host video content, independently, as it is for written content. I don’t know what the answer to that is, technically, but we ought to start working on it with urgency.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Just like Micro.blog encourages people to own their text, reading lists, podcasts, photos, and social network interactions at their own domain, that ethos now extends to videos too.&lt;/p&gt;
    &lt;p&gt;One of the great things about Micro.blog is how it enables the Publish to Own Site, Syndicate Elsewhere (POSSE) framework. That’s manifested in features like its automatic crossposting to Bluesky, Flickr, LinkedIn, Mastodon, Medium, Nostr, Pixelfed, Threads, and Tumblr. And manual crossposting elsewhere. This allows the “source of truth” to be at your own website that you control, but you won’t miss out on conversations and audiences in other places. With expanded video hosting, Reece has added PeerTube as another automatic crossposting destination, and hopes to also enable YouTube if and when Google approves his application. It’s not about only posting to your website, but instead centralizing your website as the first and primary place you post and then getting your text, images, audio, and now video out to other networks from there.&lt;/p&gt;
    &lt;p&gt;As you can probably tell, I’m pretty excited about Micro.blog taking on the challenge of being that ’indie-focused, YouTube alternative” that Reece envisioned. I haven’t upgraded my plan yet, but only because I mainly post shorter videos (covered by my current ‘Premium’ plan), but I’m very glad it now exists as an option.&lt;/p&gt;
    &lt;p&gt;There’s never been a better time to own your spot on the web. If you haven’t checked out Micro.blog before, I think it’s a compelling place to look.&lt;/p&gt;
    &lt;p&gt;Update 2025-11-11: I was in a hurry when I posted this earlier, and it slipped my mind to include some wants and wishes that I have for Micro.blog’s video hosting capabilities. It’s a short list, due to both Reece’s solid offering from the outset, and my lack of imagination. 😆&lt;/p&gt;
    &lt;p&gt;Scale time limits across the tiers. I really think video hosting would be a stronger offering if it were available more consistently across Micro.blog’s tiers. For example, 1-minute videos at $5/month, 5-minute videos at $10/month, 10-minute videos at $15/month, and 20-minute videos at $20/month. All with the same capabilities, but limited by length.&lt;/p&gt;
    &lt;p&gt;This was something that I know Reece considered, but ultimately decided against in the name of simplicity. He didn’t want to muck up the existing plans, and (rightly) considers them a tremendous value with their current features. He obviously hopes that people will upgrade to the higher-priced Studio plan specifically for the new video stuff.&lt;/p&gt;
    &lt;p&gt;But I think tying some video features (multiple resolutions and fast playback on your blog) to the 20-minute time limit and $20 plan creates more confusion, a feature gap, and missed opportunity. Take me for example. I think I could reasonably say that I’m a Micro.blog power user. But even I’m not sure if I’m correct in saying that those unique features are limited to the Studio plan. I know everyone gets video uploads up to 1 minute in length. (Maybe not everyone, though. Does Micro.one users at $1/month get the “new” video features? I’m not sure.&lt;/p&gt;
    &lt;p&gt;Historically, most of the videos I post are around 90 seconds in length. I’m far more likely to shave 30 seconds off my videos to fit a 1-minute time limit than I am to double my monthly cost to show those extra 30 seconds. There’s too big a gap between 1-minute videos and 20-minute videos to make it seem worthwhile. In my mind, I’d be “wasting” the extra $10/month ($120/year) by not posting 20-minute videos. But I’d be more likely to pay a little extra money for a little extra time. And then if I started hitting that new limit, I’d feel incentivized and validated graduating up to the next tier. I worry that Reece will see more infrastructure cost with a bunch of 1-minute videos being uploaded and served, but won’t see an accompanying bump in revenue, since we’re all getting the 1-minute videos for “free, and I don’t see a significant portion of Micro.blog users needing the 20-minutes.&lt;/p&gt;
    &lt;p&gt;Said one more way, I think giving people a little headroom to grow into hosting their videos on Micro.blog will make them more likely to upgrade over time. Once that habit has solidified, and users are comfortable with it, paying $5 more for the next jump in time limit isn’t a big ask. But jumping right into the Studio plan for $10-$15 extra is kind of off-putting. The gap between 1 minute and 20 is just too big.&lt;/p&gt;
    &lt;p&gt;Support 4K resolution. A pie-in-the-sky request, I know. 4K videos are huge. But I can nearly always see the difference, and choose higher quality playback every time. I’d love for my videos to appear at full-quality if they’re uploaded that way.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;To be clear, Micro.blog has had the ability to host videos — or nearly any other kind of file upload — and show them on your blog for years. But it’s been limited by file size, not an optimized part of the offering. The Studio tier makes it a first-rate feature, with smooth playback, automatic conversion to multiple resolutions, and ups the limit to a healthy 20 minutes no matter the file size. And the old file size-limited video uploads should still work for folks who rely on that workflow. 👌↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Sure, Vimeo exists, but it’s expensive and limited, and it’s future is uncertain. Plus, you’re still posting to a&lt;/p&gt;&lt;code&gt;vimeo.com&lt;/code&gt;domain. And, of course, many people post videos to Instagram, Facebook, TikTok, X, and other social networks. But I’d argue that videos there serve the algorithm first and users second. Micro.blog’s Studio tier flips that. It’s meant to serve the user first, and there is no algorithm at all.↩︎&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45900108</guid><pubDate>Wed, 12 Nov 2025 13:46:28 +0000</pubDate></item><item><title>The Geometry Behind Normal Maps</title><link>https://www.shlom.dev/articles/geometry-behind-normal-maps/</link><description>&lt;doc fingerprint="4cb9137b0a295b9d"&gt;
  &lt;main&gt;
    &lt;p&gt;I first ran into tangent space while learning about normal mapping. It was described as this in-between space that connects surfaces and UVs, something you need to make lighting work. Nobody really explained what it was. Tutorials showed math and shader code snippets, but none of them answered the real question: what is tangent space and why does it exist at all?&lt;/p&gt;
    &lt;p&gt;When I first learned about normal mapping I didn’t care as long as the normals looked right. But while working on mesh processing for VGLX that answer stopped being enough. I wanted to understand what those tangent vectors meant, not just how to compute them. What geometry were they pointing to? What was this “space” actually describing?&lt;/p&gt;
    &lt;p&gt;Eventually I realized the answer wasn’t mysterious at all. Tangent space isn’t a rendering trick. It’s a geometric structure that appears any time a surface has a parameterization. I just hadn’t connected the dots before.&lt;/p&gt;
    &lt;p&gt;When we define tangent space using UV coordinates, it becomes the bridge between the flat world of texture coordinates and the curved world of 3D surfaces. Once you see that connection, normal mapping suddenly makes perfect sense.&lt;/p&gt;
    &lt;p&gt;In this article I’ll take tangent space apart piece by piece: what it really is, how it emerges from UVs, how it’s computed, and how it forms the foundation for normal mapping and other techniques that depend on local surface orientation.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Anatomy of Tangent Space&lt;/head&gt;
    &lt;p&gt;Tangent space isn’t a global coordinate system. It’s a local frame built independently at every point on a surface. Each point has its own small world, a tiny patch of geometry defined by the surface itself. The tangent plane is that world’s foundation: a flat approximation that captures how the surface behaves locally and where the space gets its name.&lt;/p&gt;
    &lt;p&gt;Every point on a smooth surface has a tangent plane defined by its normal vector. We can see the same idea in two dimensions: to find the normal at a point on a curve, we first take its tangent line, then rotate it ninety degrees. The tangent plane is the 3D version of that relationship.&lt;/p&gt;
    &lt;p&gt;Tangent plane at a point on the surface with two tangent vectors lying within the plane.&lt;/p&gt;
    &lt;p&gt;Vectors that lie on this plane are called tangent vectors. We can pick two perpendicular directions within the plane that together with the normal form an orthonormal basis: a local coordinate frame on the surface that we call tangent space.&lt;/p&gt;
    &lt;p&gt;Tangent space lets us express directions, derivatives, and transformations relative to the surface itself rather than the world. That's important because most shading computations depend on directions defined locally: light hitting a surface, a normal perturbation from a texture, or the direction of anisotropy.&lt;/p&gt;
    &lt;p&gt;But before we can use it we need to decide how to orient that local frame. For that we typically turn to the surface's UVs.&lt;/p&gt;
    &lt;head rend="h3"&gt;How UVs Define Orientation&lt;/head&gt;
    &lt;p&gt;When people say "tangent space" in the context of computer graphics, they almost always mean a specific orientation of that tangent frame derived from UV parameterization.&lt;/p&gt;
    &lt;p&gt;A UV map gives every point on a surface a pair of 2D coordinates. These coordinates define how textures are applied, but they also do something more subtle: they tell us how movement in 2D texture space translates to movement along the surface.&lt;/p&gt;
    &lt;p&gt;Think of UVs as a coordinate grid draped over the mesh. Moving in the U direction means sliding along one axis of that grid and moving in V means sliding along the other. Those movements correspond to real 3D directions on the surface and those directions are exactly what defines the orientation of tangent space in practice.&lt;/p&gt;
    &lt;p&gt;The tangent directions follow the UV axes matching how texture coordinates move across the surface.&lt;/p&gt;
    &lt;p&gt;This connection between texture coordinates and surface geometry is what makes tangent space so useful: it anchors the surface’s local frame to something a shader can sample. The math for building that frame comes directly from this relationship.&lt;/p&gt;
    &lt;head rend="h3"&gt;Constructing Tangent Space&lt;/head&gt;
    &lt;p&gt;The tangent vectors that define the orientation of the tangent frame are called tangent and bitangent and they describe how texture coordinates move across the surface. Together with the normal vector these directions form the &lt;/p&gt;
    &lt;p&gt;Assuming the normal is known we need to find the tangent vectors &lt;/p&gt;
    &lt;p&gt;Triangle shown in surface space and its corresponding triangle in UV space (texture map).&lt;/p&gt;
    &lt;p&gt;Finding a transformation that maps directions in texture space to their corresponding directions on the surface is what it means to find the tangent vectors. This transformation can be represented as a &lt;/p&gt;
    &lt;p&gt;We can start by defining this relationship for a single edge. Take a triangle defined by three points &lt;/p&gt;
    &lt;p&gt;These two edges describe the same portion of the triangle. We can express how the edge in texture space maps to its surface space counterpart with the following equation:&lt;/p&gt;
    &lt;p&gt;In this equation, &lt;/p&gt;
    &lt;p&gt;We can compute &lt;/p&gt;
    &lt;p&gt;This form captures both edges, giving us enough information to solve for the tangent vectors &lt;/p&gt;
    &lt;p&gt;This gives us the tangent vectors we’re looking for to construct the &lt;/p&gt;
    &lt;p&gt;Tangent vectors aren’t guaranteed to be perpendicular. UV maps are rarely uniform. Unwrapping a curved surface onto a flat plane introduces stretching and compression that can cause the tangent vectors to drift slightly away from the normal.&lt;/p&gt;
    &lt;p&gt;We need an orthonormal basis for stable lighting: all three axes must be perpendicular and of unit length. Assuming the UVs are mostly continuous and locally smooth, these deviations are small and can be corrected by orthogonalizing the tangent frame using the full Gram–Schmidt process. This ensures that the tangent and normal vectors remain perpendicular and normalized:&lt;/p&gt;
    &lt;p&gt;Since the normal is of unit length we can project the tangent vector onto it using the dot product &lt;/p&gt;
    &lt;p&gt;Finally, we normalize both tangent vectors which together with the normal form an orthonormal basis that defines the tangent frame. Packed together they make up the &lt;/p&gt;
    &lt;p&gt;Constructing and storing the full &lt;code&gt;vec4&lt;/code&gt; vertex attribute. The &lt;code&gt;xyz&lt;/code&gt; components hold the tangent direction and &lt;code&gt;w&lt;/code&gt; holds the sign. We then reconstruct the bitangent at render time:&lt;/p&gt;
    &lt;p&gt;The sign is required because flipping the UVs horizontally or vertically inverts one of the tangent-space axes. When that happens the handedness of the tangent frame reverses and the determinant of the &lt;/p&gt;
    &lt;p&gt;With the tangent frame defined per vertex, we can now use it to translate normal directions stored in a texture into directions on the surface.&lt;/p&gt;
    &lt;head rend="h3"&gt;From Tangent Space to Normal Mapping&lt;/head&gt;
    &lt;p&gt;Normal mapping shares more than a storage and retrieval mechanism with texture mapping. It solves the same problem. Real-time meshes are low-resolution because every vertex adds cost and fewer vertices mean less geometric detail.&lt;/p&gt;
    &lt;p&gt;If we could afford a polygon for every pixel we wouldn’t need textures at all. But we can’t so we cheat. Textures give fragments access to data we can’t store per vertex. In normal mapping that data is surface orientation.&lt;/p&gt;
    &lt;p&gt;A normal map stores those orientations as colors. Each texel encodes a normal vector using its RGB channels mapped to XYZ. The blue channel dominates because most normals point roughly outward from the surface. A normal map is tinted blue for that reason.&lt;/p&gt;
    &lt;p&gt;Normal map on the right tinted blue because most normals point outward.&lt;/p&gt;
    &lt;p&gt;These per-pixel normals replace the interpolated vertex normals letting lighting respond to fine details that aren’t present in the mesh.&lt;/p&gt;
    &lt;p&gt;Each texel in a normal map represents a direction in local space. We sometimes say that each texel stores a direction in tangent space in the same way that surface positions in local space are said to be in model space. The name defines the frame these values are expressed in and in the previous section we derived the function that transforms them into this frame: the &lt;/p&gt;
    &lt;p&gt;Assuming the tangent vector and handedness are stored as vertex attributes, we can reconstruct the &lt;/p&gt;
    &lt;p&gt;The tangent vector is transformed by the model-view matrix. Some sources say to use the normal matrix but that’s incorrect. Tangents lie on the surface while normals are perpendicular to it so each must be transformed differently.&lt;/p&gt;
    &lt;p&gt;The transformed tangent works well in most cases but under non-uniform scaling it can introduce slight angular drift. In practice this is often negligible but if precision matters re-orthogonalize the tangent against the normal before computing the bitangent.&lt;/p&gt;
    &lt;p&gt;Once we reconstruct the &lt;/p&gt;
    &lt;p&gt;A normal map stores directions as RGB colors in the range &lt;/p&gt;
    &lt;p&gt;This converts the stored color values into normalized directions. Without this step all normals would point into a single quadrant of tangent space producing incorrect shading.&lt;/p&gt;
    &lt;p&gt;Normal maps are only half the story. They depend on the tangent frame we built earlier. If the tangent basis isn’t generated or interpolated consistently the surface won’t match the texture that defines it. Seams appear, highlights break, and the illusion falls apart. Combining the normal map with accurate tangent frames brings low-polygon models to life revealing fine detail and form that aren’t really there.&lt;/p&gt;
    &lt;p&gt;From Paolo Cignoni: the original high-resolution model (left) is simplified to a low-poly mesh (center). By transferring detail into a normal map, the low-poly version (right) recovers nearly all the visual complexity.&lt;/p&gt;
    &lt;p&gt;The process described here follows the same principles as MikkTSpace, the standard used by most tools and engines to keep bakes and renders in sync. It defines how to build, average, and orthogonalize tangents, how to store the sign, and how to reconstruct the bitangent in the shader so the lighting behaves the same everywhere.&lt;/p&gt;
    &lt;p&gt;By now the picture is complete. Tangent space gives each point on the surface its own coordinate system. UVs define how that system is oriented. The &lt;/p&gt;
    &lt;p&gt;Normal mapping doesn't fake bumps. It describes how the surface would curve if it had more polygons. Shading reacts the same way because light only cares about direction, not depth. At shallow angles the illusion breaks. You can see that surface detail is missing. But viewed head-on the lighting reacts as if every point on the mesh had its own direction capturing every bump and groove.&lt;/p&gt;
    &lt;p&gt;The same idea drives everything that uses a parameterized surface. Anisotropy, triplanar projection, detail normals, even displacement mapping, all build on the same translation between textures and surface space. Once that connection clicks what seemed like a trick becomes geometry. Tangent space isn’t a feature of shading. It’s part of how surfaces exist.&lt;/p&gt;
    &lt;head rend="h2"&gt;Footnotes&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Non-square matrices represent linear transformations between spaces of different dimensions. The number of columns corresponds to the input dimension, and the number of rows corresponds to the output dimension. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The fraction out front is the reciprocal of the UV matrix’s determinant. As long as this value isn’t zero, the matrix can be inverted. The inversion itself follows the usual 2×2 rule: swap the diagonal entries, negate the off-diagonals, and scale by that reciprocal determinant. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;If you’re writing your own mesh preprocessing code it’s also important to average tangent vectors across shared vertices in the same way we smooth normals on indexed meshes. This ensures the tangent field remains continuous across the surface and prevents visible lighting seams. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;An alternate approach is to transform the light direction into tangent space using the inverse&lt;/p&gt;&lt;mjx-container/&gt;matrix instead of transforming the normal into surface space. Both methods are equivalent in theory, but transforming the normal is usually cheaper and integrates more naturally into standard lighting pipelines. ↩&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45900159</guid><pubDate>Wed, 12 Nov 2025 13:50:47 +0000</pubDate></item><item><title>Fighting the New York Times' invasion of user privacy</title><link>https://openai.com/index/fighting-nyt-user-privacy-invasion</link><description>&lt;doc fingerprint="941e81501c87d3a5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Fighting the New York Times’ invasion of user privacy&lt;/head&gt;
    &lt;p&gt;Trust, security, and privacy guide every product and decision we make.&lt;/p&gt;
    &lt;p&gt;Each week, 800 million people use ChatGPT to think, learn, create, and handle some of the most personal parts of their lives. People entrust us with sensitive conversations, files, credentials, memories, searches, payment information, and AI agents that act on their behalf. We treat this data as among the most sensitive information in your digital life—and we’re building our privacy and security protections to match that responsibility.&lt;/p&gt;
    &lt;p&gt;Today, that responsibility is being tested.&lt;/p&gt;
    &lt;p&gt;The New York Times is demanding that we turn over 20 million of your private ChatGPT conversations. They claim they might find examples of you using ChatGPT to try to get around their paywall.&lt;/p&gt;
    &lt;p&gt;This demand disregards long-standing privacy protections, breaks with common-sense security practices, and would force us to turn over tens of millions of highly personal conversations from people who have no connection to the Times’ baseless lawsuit against OpenAI.&lt;/p&gt;
    &lt;p&gt;They have tried this before. Originally, the Times wanted you to lose the ability to delete your private chats. We fought that and restored your right to remove them. Then they demanded we turn over 1.4 billion of your private ChatGPT conversations. We pushed back, and we’re pushing back again now. Your private conversations are yours—and they should not become collateral in a dispute over online content access.&lt;/p&gt;
    &lt;p&gt;We respect strong, independent journalism and partner with many publishers and newsrooms. Journalism has historically played a critical role in defending people’s right to privacy throughout the world. However, this demand from the New York Times does not live up to that legacy, and we’re asking the court to reject it. We will continue to explore every option available to protect our users' privacy.&lt;/p&gt;
    &lt;p&gt;We are accelerating our security and privacy roadmap to protect your data. OpenAI is one of the most targeted organizations in the world. We have invested significant time and resources building systems to prevent unauthorized access to your data by adversaries ranging from organized criminal groups to state-sponsored intelligence services.&lt;/p&gt;
    &lt;p&gt;However, if the Times succeeds in its demand, we will be forced to hand over the very same data we’re protecting—your data—to third parties, including the Times' lawyers and paid consultants.&lt;/p&gt;
    &lt;p&gt;Our long-term roadmap includes advanced security features designed to keep your data private, including client-side encryption for your messages with ChatGPT. We believe these features will help keep your private conversations private and inaccessible to anyone else, even OpenAI. We will build fully automated systems to detect safety issues in our products. Only serious misuse and critical risks—such as threats to someone’s life, plans to harm others, or cybersecurity threats—may ever be escalated to a small, highly vetted team of human reviewers. These security features are in active development and we will share more details about them, and other short-term mitigations, in the very near future.&lt;/p&gt;
    &lt;p&gt;The privacy and security protections must become more powerful as AI becomes more deeply integrated into people’s lives. We are committed to a future where you can trust that your most personal AI conversations are safe, secure, and truly private.&lt;/p&gt;
    &lt;p&gt;—Dane Stuckey, Chief Information Security Officer, OpenAI&lt;/p&gt;
    &lt;head rend="h2"&gt;Answers to your questions&lt;/head&gt;
    &lt;p&gt;Why are The New York Times and other plaintiffs demanding this?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The New York Times is suing OpenAI. As part of their baseless lawsuit, they’ve demanded the court to force us to hand over 20 million user conversations. This would allow them to access millions of user conversations that are unrelated to the case.&lt;/item&gt;
      &lt;item&gt;We strongly believe this is an overreach. It risks your privacy without actually helping resolve the lawsuit. That’s why we’re fighting it.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What led to this stage of the process?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Times’ lawyers argued to the court that their request should be granted, in part because another AI company previously agreed to hand over 5 million private chats of their users in an unrelated court case.&lt;/item&gt;
      &lt;item&gt;We strongly disagree that this is relevant to our case and we’re continuing to appeal.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Did you offer any other solutions to the Times?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We presented several privacy-preserving options to The Times, including targeted searches over the sample (e.g., to search for chats that might include text from a New York Times article so they only receive the conversations relevant to their claims), as well as high-level data classifying how ChatGPT was used in the sample.&lt;/item&gt;
      &lt;item&gt;These were rejected by The Times.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Is the NYT obligated to keep this data private?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Yes. The Times would be legally obligated at this time to not make any data public outside the court process. That said, if the Times continues to push to access it in any way that will make the conversations public, we will fight to protect your privacy at every step.&lt;/item&gt;
      &lt;item&gt;The Times’ original request in this lawsuit was also much broader. It initially demanded 1.4 billion private ChatGPT conversations, which we successfully pushed back on through the legal process. That presented red flags to us that suggested this was not a thoughtful or genuinely necessary request.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;How are these 20 million chats selected?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The 20 million user conversations were randomly sampled from Dec. 2022 to Nov. 2024.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Is my data potentially impacted?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;This data includes a random sampling of consumer ChatGPT conversations from Dec. 2022 to Nov. 2024.&lt;/item&gt;
      &lt;item&gt;Conversations outside of this time window are not potentially impacted.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Are business customers potentially impacted?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;This does not impact ChatGPT Enterprise, ChatGPT Edu, ChatGPT Business (formerly “Team”) customers, or API customers.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What are you doing to protect my personal information and privacy?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We are taking all affected chats and running them through a de-identifying procedure to remove or “scrub” personal identifying information (or “PII”) and other information (e.g., passwords or other sensitive information) from these conversations.&lt;/item&gt;
      &lt;item&gt;We would also push to only allow the Times to view this data in a secure environment maintained under strict legal protocols.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;How will you store this data?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The content covered by the court order is currently stored separately in a secure system. It’s protected under legal hold, meaning it can’t be accessed or used for purposes other than meeting legal obligations.&lt;/item&gt;
      &lt;item&gt;Only a small, audited OpenAI legal and security team would be able to access this data as necessary to comply with our legal obligations.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Who will be able to access this data?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Times’ outside counsel attorneys of record in the case and their hired technical consultants would be able to access the conversations. We will push to only allow The Times to view this data in a secured environment maintained under strict legal protocols.&lt;/item&gt;
      &lt;item&gt;If The Times continues to push to access it in any way that will make the conversations public, we will fight to protect your privacy at every step.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Does this court order violate GDPR or my rights under European or other privacy laws?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We are taking steps to comply at this time because we must follow the law, but The New York Times’ demand does not align with our privacy standards. That is why we’re challenging it.&lt;/item&gt;
      &lt;item&gt;As mentioned, we’ve taken additional steps to protect your privacy, such as de-identifying data and removing personally identifiable information.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Will you keep us updated?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Yes. We’re committed to transparency and will keep you informed. We’ll share meaningful updates, including any changes to the order or how it affects your data.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45900370</guid><pubDate>Wed, 12 Nov 2025 14:08:28 +0000</pubDate></item></channel></rss>