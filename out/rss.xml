<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 06 Nov 2025 16:48:34 +0000</lastBuildDate><item><title>Dillo, a multi-platform graphical web browser</title><link>https://github.com/dillo-browser/dillo</link><description>&lt;doc fingerprint="9650cf58848088e4"&gt;
  &lt;main&gt;
    &lt;p&gt;Dillo is a multi-platform graphical web browser, known for its speed and small footprint, that is developed with a focus on personal security and privacy. It is built with the FLTK 1.3 GUI toolkit.&lt;/p&gt;
    &lt;p&gt;Screenshot of the Dillo Website rendered in Dillo:&lt;/p&gt;
    &lt;p&gt;To install Dillo follow the installation guide.&lt;/p&gt;
    &lt;p&gt;This repository contains mostly the original code of Dillo with some minor patches. Additional patches or pull requests are welcome.&lt;/p&gt;
    &lt;p&gt;See also other related forks: dillo-plus, dilloNG, D+ browser and Mobilized Dillo.&lt;/p&gt;
    &lt;p&gt;Warning&lt;/p&gt;
    &lt;p&gt;As of December 2023, the host &lt;code&gt;dillo.org&lt;/code&gt; is no longer under control
of Dillo developers. A copy of the old website is archived in
GitHub Pages and the Wayback Machine (May 2022).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45826266</guid><pubDate>Wed, 05 Nov 2025 18:40:32 +0000</pubDate></item><item><title>Show HN: See chords as flags ‚Äì Visual harmony of top composers on musescore</title><link>https://rawl.rocks/</link><description>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45826472</guid><pubDate>Wed, 05 Nov 2025 18:57:09 +0000</pubDate></item><item><title>New gel restores dental enamel and could revolutionise tooth repair</title><link>https://www.nottingham.ac.uk/news/new-gel-restores-dental-enamel-and-could-revolutionise-tooth-repair</link><description>&lt;doc fingerprint="29d491bb3e858cc8"&gt;
  &lt;main&gt;Tuesday, 04 November 2025&lt;div&gt;&lt;p&gt;A new material has been used to create a gel that can repair and regenerate tooth enamel, opening up new possibilities for effective and long-lasting preventive and restorative dental treatment.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Scientists from the University of Nottingham‚Äôs School of Pharmacy and Department of Chemical and Environmental Engineering, in collaboration with an international team of researchers, have developed a bioinspired material that has the potential to regenerate demineralized or eroded enamel, strengthen healthy enamel, and prevent future decay. The findings have been published today in Nature Communications.&lt;/p&gt;&lt;p&gt;The gel can be rapidly applied to teeth in the same way dentists currently apply standard fluoride treatments. However, this new protein-based gel is fluoride free and works by mimicking key features of the natural proteins that guide the growth of dental enamel in infancy. When applied, the gel creates a thin and robust layer that impregnates teeth, filling holes and cracks in them. It then functions as a scaffold that takes calcium and phosphate ions from saliva and promotes the controlled growth of new mineral in a process called epitaxial mineralization. This enables the new mineral to be organized and integrated to the underlying natural tissue while recovering both the structure and properties of natural healthy enamel.&lt;/p&gt;&lt;p&gt;The new material can also be applied on top of exposed dentine, growing an enamel-like layer on top of dentine, which has many benefits including treating hypersensitivity or enhancing the bonding of dental restorations.&lt;/p&gt;&lt;p&gt;Enamel degradation is a major contributor to tooth decay and is associated to dental problems affecting almost 50% of the world‚Äôs population. These problems can lead to infections and tooth loss, and can also be associated with conditions such as diabetes and cardiovascular disease. Enamel does not naturally regenerate; once you lose it is gone forever. There is currently no solution available that can effectively regrow enamel. Current treatments such as fluoride varnishes and remineralisation solutions only alleviate the symptoms of lost enamel.&lt;/p&gt;&lt;p&gt;Dr Abshar Hasan, a Postdoctoral Fellow and leading author of the study, said: ‚ÄúDental enamel has a unique structure, which gives enamel its remarkable properties that protect our teeth throughout life against physical, chemical, and thermal insults. When our material is applied to demineralized or eroded enamel, or exposed dentine, the material promotes the growth of crystals in an integrated and organized manner, recovering the architecture of our natural healthy enamel."&lt;/p&gt;&lt;div&gt;&lt;div&gt;&lt;quote&gt; We have tested the mechanical properties of these regenerated tissues under conditions simulating ‚Äòreal-life situations‚Äô such as tooth brushing, chewing, and exposure to acidic foods, and found that the regenerated enamel behaves just like healthy enamel. &lt;/quote&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;quote&gt; We are very excited because the technology has been designed with the clinician and patient in mind. It is safe, can be easily and rapidly applied, and it is scalable. Also, the technology is versatile, which opens the opportunity to be translated into multiple types of products to help patients of all ages suffering from a variety of dental problems associated with loss of enamel and exposed dentine. We have started this process with our start-up company Mintech-Bio and hope to have a first product out next year; this innovation could soon be helping patients worldwide. &lt;/quote&gt;&lt;/div&gt;&lt;/div&gt;&lt;head rend="h2"&gt;Story credits&lt;/head&gt;&lt;p&gt;More information is available from Professor Alvaro Mata on Alvaro.Mata@nottingham.ac.uk&lt;/p&gt;&lt;div&gt;&lt;p&gt;Notes to editors:&lt;/p&gt;&lt;p&gt;About the University of Nottingham&lt;/p&gt;&lt;p&gt;Ranked 97 in the world and 17th in the UK by the QS World University Rankings, the University of Nottingham is a founding member of Russell Group of research-intensive universities. Studying at the University of Nottingham is a life-changing experience, and we pride ourselves on unlocking the potential of our students. We have a pioneering spirit, expressed in the vision of our founder Sir Jesse Boot, which has seen us lead the way in establishing campuses in China and Malaysia - part of a globally connected network of education, research and industrial engagement.&lt;/p&gt;&lt;p&gt;Nottingham was crowned Sports University of the Year by The Times and Sunday Times Good University Guide 2024 ‚Äì the third time it has been given the honour since 2018 ‚Äì and by the Daily Mail University Guide 2024.&lt;/p&gt;&lt;p&gt;The university is among the best universities in the UK for the strength of our research, positioned seventh for research power in the UK according to REF 2021. The birthplace of discoveries such as MRI and ibuprofen, our innovations transform lives and tackle global problems such as sustainable food supplies, ending modern slavery, developing greener transport, and reducing reliance on fossil fuels.&lt;/p&gt;&lt;p&gt;The university is a major employer and industry partner - locally and globally - and our graduates are the third most targeted by the UK's top employers, according to The Graduate Market in 2024 report by High Fliers Research.&lt;/p&gt;&lt;p&gt;We lead the Universities for Nottingham initiative, in partnership with Nottingham Trent University, a pioneering collaboration between the city‚Äôs two world-class institutions to improve levels of prosperity, opportunity, sustainability, health and wellbeing for residents in the city and region we are proud to call home.&lt;/p&gt;&lt;p&gt; More news‚Ä¶ &lt;/p&gt;&lt;/div&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45826995</guid><pubDate>Wed, 05 Nov 2025 19:44:49 +0000</pubDate></item><item><title>Solarpunk is happening in Africa</title><link>https://climatedrift.substack.com/p/why-solarpunk-is-already-happening</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45827190</guid><pubDate>Wed, 05 Nov 2025 20:00:40 +0000</pubDate></item><item><title>The Basic Laws of Human Stupidity (1987) [pdf]</title><link>https://gandalf.fee.urv.cat/professors/AntonioQuesada/Curs1920/Cipolla_laws.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45829210</guid><pubDate>Wed, 05 Nov 2025 22:58:38 +0000</pubDate></item><item><title>Recursive macros in C, demystified (once the ugly crying stops)</title><link>https://h4x0r.org/big-mac-ro-attack/</link><description>&lt;doc fingerprint="2ec9b45278e499bc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Recursive macros in C, demystified (once the ugly crying stops üò≠)&lt;/head&gt;
    &lt;p&gt;In which it becomes clear, the C Preprocessor was designed by &lt;del&gt;a&lt;/del&gt; Kafka &lt;del&gt;fan&lt;/del&gt;&lt;/p&gt;
    &lt;p&gt;So you have heard rumors whispered between peers, that a rare few people somehow manage to make compile-time recursion work in C? And you want to have some insight into how that might be possible??&lt;/p&gt;
    &lt;p&gt;I should warn you, you‚Äôre risking your sanity‚Ä¶ but I‚Äôll indulge you.&lt;/p&gt;
    &lt;p&gt;Wait, did I really just say that? I must be a glutton for punishment, because the macro system is, by far, the thing I like least about C.&lt;/p&gt;
    &lt;p&gt;C has many advantages that have led to its longevity (60 years as perhaps the most important language). It has many quirks due to its age, most of which are easy to look past. But despite 30 years writing C, I still bristle at C‚Äôs macro system.&lt;/p&gt;
    &lt;p&gt;That‚Äôs not just because there are many languages (including C++) with more modern takes on compile-time execution. Macros appear simple, but have subtleties that make them poorly suited for anything other than light wrappers.&lt;/p&gt;
    &lt;p&gt;Still, being C‚Äôs only compile-time execution capability (currently), it is still both critical and important. Critical, in that many venerable critical systems heavily depend on them, and wouldn‚Äôt compile without them. Important, in that it‚Äôs often the only way to abstract out complexity that would lead to safety or security issues if exposed, such as automatically adding sentinels or static type checks.&lt;/p&gt;
    &lt;p&gt;C macros being hard to use does discourage their overuse. It‚Äôs easy for too much abstraction to make it too difficult for other people to maintain the code, so in some ways, as painful as they are, I can find some things to appreciate, and do occasionally find reason to use them for something non-trivial.&lt;/p&gt;
    &lt;p&gt;But it doesn‚Äôt take much for a macro to be non-trivial, because, while C macros can look like functions, they cannot be called recursively (at least, not easily, as we will see).&lt;/p&gt;
    &lt;p&gt;I have never been able to find out why recursion is limited in C macros. It could have started off intentional, but compile time execution wasn‚Äôt really on people‚Äôs minds then; the challenge was abstracting over many platform differences as cheaply as possible.&lt;/p&gt;
    &lt;p&gt;I suspect the system evolved as needed in the early days, without really thinking about it as something that perhaps should support recursion. Certainly at some point, the question would get raised; but it‚Äôs easy to imagine:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The organic evolution of the macro system coupled with early success made it brittle, and hard to evolve.&lt;/item&gt;
      &lt;item&gt;People were worried about build issues like hanging compile times due to infinite loops, or crashing with no diagnostics, due to infinite recursion.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Depending on which of these two was more prominent, I could equally imagine the lack of recursion being an accident, or being an intentional choice.&lt;/p&gt;
    &lt;p&gt;However it happened, that die was cast in a completely different era‚Äîpeople have definitely woken up to the value of pushing as much into compile time as possible.&lt;/p&gt;
    &lt;p&gt;Either way, it all seems archaic and unnecessary now.&lt;/p&gt;
    &lt;p&gt;So, let‚Äôs roll up our sleeves and learn to cope with the issue!&lt;/p&gt;
    &lt;head rend="h2"&gt;Motivation&lt;/head&gt;
    &lt;p&gt;If you have anything interesting you need done with the preprocessor, you probably need to generalize over multiple items.&lt;/p&gt;
    &lt;p&gt;Maybe you want to add automatic sanity checks around parameters, or add automatic type checking. You might want to pre-fill arrays, or generate a list of functions based on some data. Generally, we should be able to do such things at compile time, and in cases like type checking, it is often incredibly challenging to defer the work till runtime. So the lack of a good compile time solution for such things is problematic.&lt;/p&gt;
    &lt;p&gt;I tend to reach for macros when they can remove the potential for human error; for example, calling an API wrong. That can indeed be adding automatic casts, enforcing that null terminators get added on variable argument arrays, etc.&lt;/p&gt;
    &lt;p&gt;In all of those scenarios, we would need something to move macros toward Turing completeness at compile time. But macros do not advertise support for either of the things we‚Äôd be looking for there: iteration, and recursion.&lt;/p&gt;
    &lt;p&gt;Thankfully, we can get there. But it‚Äôs not going to be easy.&lt;/p&gt;
    &lt;p&gt;To frame our discussion, let‚Äôs pick a simple, but highly valuable goal. We‚Äôre going to build a macro that counts the number of variable arguments in a function-like macro that accepts variable arguments.&lt;/p&gt;
    &lt;p&gt;Why that problem? Because from there it‚Äôs a short jump to dealing with some common issues, where we can remove large sources of human error:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Variadic functions (aka varargs) are error prone, because the implementation has to figure out where the arguments stop; the language doesn‚Äôt give you a way to know. The caller has to remember to follow your convention (like adding a null terminator). And that convention can often back fire, for example, when a null value is a valid argument . Being able to count the number of variadic arguments allows us to provide a single, general approach to dealing with this, and to not put the burden on the caller to have to count correctly.&lt;/item&gt;
      &lt;item&gt;There are plenty of cases where we‚Äôd want to apply a transformation to each argument of a variable argument function, like statically checking that parameters are all the same type, or automatically adding a layer of sanity checking to a third party API, so that the people calling your function can remain blissfully unaware. These don‚Äôt directly require counting, but once we can count recursively, it‚Äôs a small change to give ourselves a more general purpose &lt;code&gt;map&lt;/code&gt;construct to make such transformations.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You might be surprised that the language doesn‚Äôt provide a way to count variable arguments in a macro, especially if you noticed the recent addition of a pre-defined macro called &lt;code&gt;__COUNTER__&lt;/code&gt; in the draft C2Y standard. The new &lt;code&gt;__COUNTER__&lt;/code&gt; macro is intended to make it easier to provide uniqueness for situations where macros need to generate identifiers and labels; it definitely isn‚Äôt for counting variadic macro arguments.&lt;/p&gt;
    &lt;head rend="h2"&gt;Apparently math is hard?&lt;/head&gt;
    &lt;p&gt;If there‚Äôs no primitive to count variadic macro arguments, well, we need to create one, right? And if we have to create one, that means it should be pretty easy, one would hope?&lt;/p&gt;
    &lt;head rend="h1"&gt;ü¶óü¶óü¶ó&lt;/head&gt;
    &lt;p&gt;I see you‚Äôre skeptical. But an optimist who wanted to delve into compile-time coding in C for the first time might give it a go. But they will quickly find that the obvious approach below, that feels like it should work, absolutely does not work:&lt;/p&gt;
    &lt;code&gt;// The first macro... counts one argument, then we'd like it to recurse.
#define _COUNT_ONE(x, ...) + 1 _COUNT_TOP(__VA_ARGS__)
#define _COUNT_TOP(...)    __VA_OPT__(_COUNT_ONE(__VA_ARGS__))
#define COUNT(...)        (_COUNT_TOP(__VA_ARGS__) + 0)
&lt;/code&gt;
    &lt;p&gt;Try to call this code, and‚Ä¶&lt;/p&gt;
    &lt;head rend="h1"&gt;ü§Æ&lt;/head&gt;
    &lt;p&gt;Yup, it‚Äôll barf.&lt;/p&gt;
    &lt;p&gt;What this doe-eyed attempt is trying to do, is generate an expression (at compile time) of the form &lt;code&gt;(+ 1 + 1 + ‚Ä¶ + 0)&lt;/code&gt;, by iterating over each argument at a call site (via recursion). It doesn‚Äôt care what the arguments are, it just wants to generate a &lt;code&gt;+ 1&lt;/code&gt; for each valid argument, and a &lt;code&gt;+ 0&lt;/code&gt; at the end, both to make it a valid expression and to handle the case where there are no arguments passed.&lt;/p&gt;
    &lt;p&gt;If we‚Äôre successful, the addition will all happen at compile time, and will be what C calls an integer constant expression. That means, the compiler will, at compile time, fold this into a single static integer. So, even if it feels inefficient, there is no run-time cost involved.&lt;/p&gt;
    &lt;p&gt;Why three macros? That seems a bit excessive, right?&lt;/p&gt;
    &lt;p&gt;Unfortunately, C currently doesn‚Äôt have an easy way to do the equivalent of an &lt;code&gt;if()&lt;/code&gt; statement at compile time. It‚Äôs possible to create something with macros, but that‚Äôs just extra hackery.&lt;/p&gt;
    &lt;p&gt;Instead, we split the primary body into its own macro‚Äî &lt;code&gt;_COUNT_ONE()&lt;/code&gt;, which adds the &lt;code&gt;1 +&lt;/code&gt; and then triggers recursion (we wish, anyway; again, the recursion part won‚Äôt work this easily).&lt;/p&gt;
    &lt;p&gt;The intent the behind &lt;code&gt;_COUNT_TOP()&lt;/code&gt; macro is evaluating an exit condition for our recursion. Specifically, we want to stop when we have no more arguments left in the function. The builtin macro &lt;code&gt;__VA_OPT__()&lt;/code&gt; allows us to do exactly that‚Äî the text inside the parentheses gets expanded only if there are arguments. And when there are no arguments, the text inside the parentheses is discarded.&lt;/p&gt;
    &lt;p&gt;This gives us a lightweight way to separate the one argument case from the two argument case, without need for a kind of &lt;code&gt;if&lt;/code&gt; statement; the 0-case won‚Äôt generate a recursive call. To combine this with &lt;code&gt;_COUNT_ONE()&lt;/code&gt;, we‚Äôd need a primitive that allowed us to specify a replacement that only expands when there are no arguments, which doesn‚Äôt come out of the box.&lt;/p&gt;
    &lt;p&gt;The outer &lt;code&gt;COUNT()&lt;/code&gt; macro could be factored out trivially; I leave it because it keeps what‚Äôs going on a bit clearer. This macro is the actual entry point, adds the ‚Äò0‚Äô a single time the end, and wraps the whole thing in parentheses, which helps avoid running afoul of operator precedence rules.&lt;/p&gt;
    &lt;p&gt;If we directly combine it with &lt;code&gt;_COUNT_TOP()&lt;/code&gt; in the obvious way, it would compute the right thing, but it would do it by adding the &lt;code&gt;+ 0&lt;/code&gt; after EVERY term, and parenthesizing the expression in a way that would come off as odd if you were looking at the resulting C code. For instance, we‚Äôd be aiming for a three argument function to generate:&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;( + 1 ( + 1 ( + 1 ( + 0 ) + 0 ) + 0 ) + 0 )&lt;/code&gt;
If we were to generate this code, it‚Äôd be ugly, but most people would declare success and move on. But unfortunately, the above code does not work, and will never work, no matter how many iterations of the standard are released between now and the heat death of the universe‚Äî changing the behavior would be too likely to impact plenty of real code.&lt;/p&gt;
    &lt;p&gt;For example, let‚Äôs attempt to use the above implementation like so:&lt;/p&gt;
    &lt;code&gt;#include &amp;lt;stdio.h&amp;gt;

int
main()
{
    printf("COUNT() = %d\n", COUNT(1, 2, 3));
    return 0;
}
&lt;/code&gt;
    &lt;p&gt;With &lt;code&gt;clang&lt;/code&gt;, I get:&lt;/p&gt;
    &lt;code&gt;tmp.c:8:30: error: expected ')'
    8 |     printf("COUNT() = %d\n", COUNT(1, 2, 3));
      |                              ^
tmp.c:4:28: note: expanded from macro 'COUNT'
    4 | #define COUNT(...)        (_COUNT_TOP(__VA_ARGS__) + 0)
      |                            ^
tmp.c:3:39: note: expanded from macro '_COUNT_TOP'
    3 | #define _COUNT_TOP(...)    __VA_OPT__(_COUNT_ONE(__VA_ARGS__))
      |                                       ^
tmp.c:2:32: note: expanded from macro '_COUNT_ONE'
    2 | #define _COUNT_ONE(x, ...) + 1 _COUNT_TOP(__VA_ARGS__)
      |                                ^
tmp.c:39:30: note: to match this '('
tmp.c:4:27: note: expanded from macro 'COUNT'
    4 | #define COUNT(...)        (_COUNT_TOP(__VA_ARGS__) + 0)
&lt;/code&gt;
    &lt;p&gt;Wow, that‚Äôs a lot of error messages, saying little that makes sense.&lt;/p&gt;
    &lt;p&gt;I‚Äôm sure you can already get the feeling that, when you have a problem with your macros, it‚Äôs incredibly challenging to translate the resulting errors into what‚Äôs actually wrong. Here, it‚Äôs complaining about balancing parentheses, and with just a bit more complexity in our macros, it‚Äôd be incredibly easy for someone to spend 10 minutes trying to figure out where the parenthesis is missing, when no parenthesis is missing whatsoever.&lt;/p&gt;
    &lt;p&gt;Or, we could have taken advantage of the fact that C is perfectly happy to accept &lt;code&gt;+ + 0&lt;/code&gt;, and write &lt;code&gt;1 +&lt;/code&gt; instead of &lt;code&gt;+ 1&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Making that microscopic change, merely transposing two tokens, completely changes the error &lt;code&gt;clang&lt;/code&gt; produces:&lt;/p&gt;
    &lt;code&gt;tmp.c:8:30: error: call to undeclared function '_COUNT_TOP'; ISO C99 and later do not support implicit function declarations [-Wimplicit-function-declaration]
   8 |     printf("COUNT() = %d\n", COUNT(1, 2, 3));
&lt;/code&gt;
    &lt;p&gt;Hey, at least that message is concise. Never mind that it‚Äôs totally different, and also unrelated to the real issue.&lt;/p&gt;
    &lt;head rend="h2"&gt;Not counting on it&lt;/head&gt;
    &lt;p&gt;The C Preprocessor (which I will usually call CPP) is responsible for macro expansion and processing lines with a leading &lt;code&gt;#&lt;/code&gt;. As we‚Äôve said, it does not fully support recursion. As you might expect, that‚Äôs the core of the actual problem in our first attempt. Yet, the preprocessor happily thinks it did its job. We‚Äôll see in more detail what‚Äôs going on, but the crux of this particular problem is how recursion is disallowed, not that it IS disallowed.&lt;/p&gt;
    &lt;p&gt;The problem here is that C macros are their own programming language, being used to generate C code. The macro language doesn‚Äôt model most of the interesting parts of the language, and it is quite easy to produce code that the preprocessor finds acceptable, that the compiler cannot understand (as we will see).&lt;/p&gt;
    &lt;p&gt;In both these cases, the preprocessor feels like it‚Äôs done its job, and passes off its work to the C compiler. The C compiler gets the generated code, and has no idea that macros were used. It calls the error as it sees it.&lt;/p&gt;
    &lt;p&gt;This disconnect between the preprocessor and the compiler is one of the things that makes macros in C so unfriendly.&lt;/p&gt;
    &lt;p&gt;If a macro expansion (basically the same as an ‚Äòevaluation‚Äô) is recursive, the CPP decides ‚Äúthey can‚Äôt possibly have wanted recursion here, because that might loop forever, so this must be plain old text I have to substitute‚Äù. As a result, the emitted code will still contain the unexpanded macro.&lt;/p&gt;
    &lt;p&gt;How can we confirm this? If we can‚Äôt understand the resulting transformations, we‚Äôre going to end up stumbling around in the dark.&lt;/p&gt;
    &lt;p&gt;Many developers don‚Äôt know how to see what the C preprocessor actually produces. If the preprocessor successfully exits, we can see it‚Äôs output by stopping the compiler after the preprocessing phase, generally with the &lt;code&gt;-E&lt;/code&gt; flag. If we don‚Äôt give a file name (via the &lt;code&gt;-o&lt;/code&gt; flag), we should see the results on the terminal. And at least in the case of &lt;code&gt;clang&lt;/code&gt;, we will even get output up to the point that we did something so wrong that the preprocessor gives us an error.&lt;/p&gt;
    &lt;p&gt;For the code above, running &lt;code&gt;cc -E tmp.c&lt;/code&gt; works without errors, and dumps the output of CPP to my terminal.&lt;/p&gt;
    &lt;p&gt;That consists of a lot of stuff you might not expect to see. The output contains our code after the preprocessor has fully expanded it. But that full expansion includes the results of it preprocessing all of the header files we pulled in, which in our case was &lt;code&gt;stdio.h&lt;/code&gt;, and any cascading dependencies it might have.&lt;/p&gt;
    &lt;p&gt;However, our code is easy to find in that noise. The last thing output will be our fully translated &lt;code&gt;main()&lt;/code&gt; function, ready to be input into the C compiler. For the case where we add &lt;code&gt;+1&lt;/code&gt; at the beginning of the macro, we will see:&lt;/p&gt;
    &lt;code&gt;int
main()
{
    printf("COUNT() = %d\n", (+1 _COUNT_TOP(2, 3) + 0));
    return 0;
}
&lt;/code&gt;
    &lt;p&gt;Here, the compiler doesn‚Äôt have to try to look up the symbol &lt;code&gt;_COUNT_TOP&lt;/code&gt;; it knows that it doesn‚Äôt make sense to have a function call after a number with no operator in between.&lt;/p&gt;
    &lt;p&gt;When we reverse the &lt;code&gt;+&lt;/code&gt; and the &lt;code&gt;1&lt;/code&gt;, the line of code is valid, as long as there‚Äôs a function C can resolve called &lt;code&gt;_COUNT_TOP&lt;/code&gt;. Because there isn‚Äôt, the compiler bails.&lt;/p&gt;
    &lt;p&gt;That explains why we get two different errors, for such a minor change.&lt;/p&gt;
    &lt;p&gt;Because CPP and the compiler itself are oblivious to the execution of the other, and because we have to live with the fact that recursive macros aren‚Äôt errors to the CPP (silently passing them through unexpanded), it‚Äôs quite a bit of work for any compiler to even try to tell you that your problem here is attempting to use recursion in a macro. It could be done, and maybe it should be done, because otherwise, compilers are effectively trying to gaslight you into believing you have a syntax error of some sort.&lt;/p&gt;
    &lt;p&gt;Because the preprocessor is much more permissive than the compiler, without the compiler having any awareness of macros even existing is perhaps the most significant reason why writing non-trivial macros is so hard to do.&lt;/p&gt;
    &lt;p&gt;Again, we can hack our way around the recursion problem. The semantics are arcane and intricate enough that, even knowing the rules (and doing macro work with a copy of the standard at the ready), macro development is incredibly challenging the second you have any problem at all. Decades later, I often feel like I‚Äôm stumbling around in the dark when a macro I write blows up on me.&lt;/p&gt;
    &lt;p&gt;If this is all too intimidating, absolutely we can plagiarize our way to success. Though, personally, I really prefer not to cut-and-paste code from Stack Overflow, especially if it‚Äôs code I don‚Äôt understand. Similarly, while Claude and I are casual acquaintances, I do not trust his code. It‚Äôs my unwillingness to using code I don‚Äôt understand in production that keeps me learning and growing. Instead, I avoid non-trivial macros, unless (as I said above), I make an exception when they will be a huge net positive for helping the developer, usually by removing potential failure modes, or with significant clarity improvements. Meaning, if you can use them to provide an abstraction that makes the code more robust, and is also not going to be hard to maintain if the need arises, then I‚Äôd consider it (even if you have to get Claude to write it). Here, automating size detection statically feels like a good enough use case for my tastes, because macros will not only make variadic functions easier to write, but also make it far easier to call them correctly.&lt;/p&gt;
    &lt;p&gt;So, I‚Äôd like to help those interested understand how to navigate through the pain, and shine a light on it, in the hopes that this is another area of the language that the modern standards committee can make massively better.&lt;/p&gt;
    &lt;head rend="h2"&gt;That doesn‚Äôt count&lt;/head&gt;
    &lt;p&gt;If we want to know how to circumvent the recursion restriction, we probably need to understand the detection mechanism we are attempting to evade.&lt;/p&gt;
    &lt;p&gt;It sure would be nice if we could debug by having our compiler give us intermediate expansions, up until the point that it breaks. This is not directly built into any compiler as far as I know. And my experience with macro debuggers has been that they have a hard time matching compiler semantics. I dusted one of them off when working on this article, and it was easy to get it to expand macros as valid that CPP barfed on, and vice versa. Despite the lack of tooling, I‚Äôll walk through the expansion process in detail so we can all understand.&lt;/p&gt;
    &lt;p&gt;The rules for C macro evaluation are hard to explain in a way that‚Äôs simultaneously precise and clear. But for function-like macros, the main process of evaluating a macro boils down to:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Replace the macro text. Stashing aside the arguments used to call the macro, we replace the full macro with the textual body, within the larger token stream we‚Äôre processing.&lt;/item&gt;
      &lt;item&gt;Add placeholder tokens. Instances of ‚Äòarguments‚Äô in the body get replaced with placeholder tokens, to prevent them from being evaluated as macros in any nested argument expansion we might have. This includes &lt;code&gt;__VA_ARGS__&lt;/code&gt;and&lt;code&gt;__VA_OPT__()&lt;/code&gt;invocations.&lt;/item&gt;
      &lt;item&gt;Evaluate preprocessor operators in the body that take operands , particularly &lt;code&gt;#&lt;/code&gt;and&lt;code&gt;##&lt;/code&gt;. We don‚Äôt make good use of these operators in this article, so we won‚Äôt cover in too much depth. Note, however, that&lt;code&gt;__VA_OPT__()&lt;/code&gt;is also a preprocessor operator that takes arguments. We inhibited expansion within the replacement text, when we were evaluating operators, but at the end of this phase, we put it back; it can get expanded in the next step.&lt;/item&gt;
      &lt;item&gt;Rescanning the body. The body is then scanned for more macros to expand, starting from our cursor in the token stream. The ‚Äúinput‚Äù head moves forward a token at a time, until we mind a macro to expand, or reach the end of the macro we‚Äôre evaluating. When we find a macro to expand, we recursively apply the algorithm.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are some pretty large subtleties here. As long as a macro invocation starts in the scope of a rescan, the scanning head position can move past the end of the original macro. For example, consider this basic scenario:&lt;/p&gt;
    &lt;code&gt;#define CONCAT(X, Y)  X ## Y

int PRINT_INT = 100;

int
main()
{
    printf("%d\n", CONCAT(PRINT_, INT));
}
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;##&lt;/code&gt; operator, seen used in the &lt;code&gt;CONCAT&lt;/code&gt; macro, appends two tokens together, turning them into a single preprocessor token.&lt;/p&gt;
    &lt;p&gt;When the preprocessor evaluates &lt;code&gt;CONCAT()&lt;/code&gt;, it will result in the token &lt;code&gt;PRINT_INT&lt;/code&gt;. If &lt;code&gt;PRINT_INT&lt;/code&gt; were a macro, the preprocessor would do further expansion. But it is not, so the preprocessor outputs &lt;code&gt;PRINT_INT&lt;/code&gt;. The C compiler does not complain, because it sees a variable named &lt;code&gt;PRINT_INT&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;So far, depending on your background, the semantics may or may not being intuitive. But either way, what do you think should happen in this slightly more complex scenario?&lt;/p&gt;
    &lt;code&gt;#define CONCAT(X, Y)  X ## Y

#define PRINT_INT(N)  printf("look an integer %d\n", (N));

int PRINT_INT = 100;

int
main()
{
    printf("%d\n", CONCAT(PRINT_, INT));
    CONCAT(PRINT_,INT)(100);
}
&lt;/code&gt;
    &lt;p&gt;It would be reasonable to think there‚Äôs an error here, but this code will compile and run. Why? In both cases, the preprocessor will generate the token &lt;code&gt;PRINT_INT&lt;/code&gt;. In the first case, everything will happen the same way it did in our first example, and the compiler will see the variable &lt;code&gt;PRINT_INT&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;But, with the second use of &lt;code&gt;CONCAT&lt;/code&gt;, the preprocessor will see that there is a parenthesis immediately following the token &lt;code&gt;PRINT_INT&lt;/code&gt;. Since it has a function-like macro with that name, it will prefer the macro interpretation.&lt;/p&gt;
    &lt;p&gt;That‚Äôs true, even though we didn‚Äôt directly write &lt;code&gt;PRINT_INT&lt;/code&gt; in the code, there. The effective result of the preprocessor‚Äôs expansion would look like this:&lt;/p&gt;
    &lt;code&gt;#define CONCAT(X, Y)  X ## Y

#define PRINT_INT(N)  printf("look an integer %d\n", (N));

int PRINT_INT = 100;

int
main()
{
    printf("%d\n", 100);
    printf("look an integer %d\n", 100);
}
&lt;/code&gt;
    &lt;p&gt;That‚Äôs because C‚Äôs macros come in two flavors, with slightly different semantics:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Function-like macros, which take arguments, and syntactically LOOK like functions. As we see here, if the preprocessor sees a token with the same name as a function like macro, but it‚Äôs not used like a function like macro, it will pass it through, letting the C compiler resolve the token.&lt;/item&gt;
      &lt;item&gt;Object-like macros, the definitions of which look like variables, and do not take arguments. If the C preprocessor sees a left parenthesis after an object-like macro, that token will just be passed through directly to the compiler.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;That is why the following code does NOT error. In fact, it runs quite happily:&lt;/p&gt;
    &lt;code&gt;#define OBJECT_LIKE_MACRO printf
#include &amp;lt;stdio.h&amp;gt;
int main()
{
  OBJECT_LIKE_MACRO("Hello, world!\n");
}
&lt;/code&gt;
    &lt;p&gt;Meaning, if we we have an object-like macro and it looks like we‚Äôre trying to call it, the C preprocessor isn‚Äôt going to call it. It‚Äôs just going to pass the token through, and let the compiler figure it out.&lt;/p&gt;
    &lt;p&gt;As you can see, the preprocessor‚Äôs philosophy is to do its job, and nothing else.&lt;/p&gt;
    &lt;p&gt;Another preprocessor subtlety that‚Äôs easy to miss, yet important to understand is:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;‚ÑπÔ∏èÔ∏è&lt;/cell&gt;
        &lt;cell&gt;Arguments to function-like macros are expanded at the call site. For expansions that trigger inside the body where those arguments are used, the contents of the expanded arguments will not be available to be part of any additional expansion.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The preprocessor‚Äôs approach of substituting arguments with placeholder tokens during evaluation is pretty effective at stopping a bunch of accidental recursion that would be non-intuitive. Although, it‚Äôs not the problem for the recursion we‚Äôre trying to solve. The barrier we‚Äôre hitting is a subtlety that we haven‚Äôt discussed yet, but we‚Äôll get to it soon enough.&lt;/p&gt;
    &lt;p&gt;Before that, let‚Äôs solidify our understanding by walking through the relevant steps with our invocation of &lt;code&gt;COUNT(1)&lt;/code&gt; .&lt;/p&gt;
    &lt;p&gt;We‚Äôve learned that, when &lt;code&gt;COUNT()&lt;/code&gt; has an invocation of &lt;code&gt;_COUNT_TOP()&lt;/code&gt;, the replacement text cannot lead to recursion. The expansion endures the rescan, and nothing attempts to expand it.&lt;/p&gt;
    &lt;p&gt;The rule that‚Äôs preventing the expansion is effectively an explicit anti-recursion rule. Formally, when we replace a macro, that macro is marked as currently being replaced. The mark stays, until that replacement is totally finished, including its rescan.&lt;/p&gt;
    &lt;p&gt;And, unfortunately, marked macros are ineligible for replacement. Note the rescan ineligibility is IN THE CALLING ENVIRONMENT. That‚Äôs going to cause us some grief in a few minutes.&lt;/p&gt;
    &lt;p&gt;For whatever reason, the original C89 standards committee referred to a macro marked as ineligible for expansion as painted blue.&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;‚ùì&lt;/cell&gt;
        &lt;cell&gt;Why the term painted blue? Perhaps the standards committee at the time realized how miserable it was going to make future C developers? It‚Äôs not a term mentioned in the standard, but is often used when people try to explain the whole process.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;I‚Äôm blue, because I can‚Äôt count on you&lt;/head&gt;
    &lt;p&gt;We can work around the problem, despite there being no way in C to opt out of your macro getting painted blue. But the work-around is going to be hard fought.&lt;/p&gt;
    &lt;p&gt;First, let‚Äôs give ourselves a cause to be optimistic: the restriction that‚Äôs preventing &lt;code&gt;_COUNT_TOP()&lt;/code&gt; from recursively expanding is relaxed when the second &lt;code&gt;_COUNT_TOP()&lt;/code&gt; gets replaced. If, instead, the restriction stayed in full force the entire time we‚Äôve evaluating &lt;code&gt;COUNT()&lt;/code&gt;, then you would not be able to do the following:&lt;/p&gt;
    &lt;code&gt;#include &amp;lt;stdio.h&amp;gt;
#define H4X(x) # x // convert to string
#define DUPE(token) H4X(token) H4X(token)

int 
main() {
    printf("%s\n", DUPE(h4x0r));
}
&lt;/code&gt;
    &lt;p&gt;But that will absolutely work. The preprocessor will output exactly what I intended:&lt;/p&gt;
    &lt;code&gt;int
main()
{
    printf("%s\n", "h4x0r" "h4x0r");
}
&lt;/code&gt;
    &lt;p&gt;In C, two string literals next to each other are merged into a single literal at compile time, so this program prints:&lt;/p&gt;
    &lt;code&gt;h4x0rh4x0r
&lt;/code&gt;
    &lt;p&gt;This leads us to believe that the blue paint wears off when the rescan moves past an expanded macro, after we‚Äôve processed its replacement.&lt;/p&gt;
    &lt;p&gt;So our hypothesis right now might be that &lt;code&gt;_COUNT_ONE()&lt;/code&gt; expanding inside &lt;code&gt;COUNT()&lt;/code&gt; is fine, as long as it happens after the processing head moves past the start of where the macro was, after expansion.&lt;/p&gt;
    &lt;p&gt;If that‚Äôs the case, then all we need to do now is add another layer of indirection, right? Let the calling macro evaluate its recursive call on rescan!&lt;/p&gt;
    &lt;p&gt;That would make sense! We‚Äôll rewrite our attempt at recursion to add a proxy layer to call &lt;code&gt;_COUNT_TOP()&lt;/code&gt;, knowing it cannot re-expand.&lt;/p&gt;
    &lt;code&gt;#define _COUNT_ONE(x, ...) + 1 _COUNT_TOP(__VA_ARGS__)
#define _COUNT_TOP(...)    __VA_OPT__(_COUNT_ONE(__VA_ARGS__))
#define _COUNT_PROXY(...)  (_COUNT_TOP(__VA_ARGS__) + 0)
#define COUNT(...)         _COUNT_PROXY(__VA_ARGS__)
&lt;/code&gt;
    &lt;p&gt;We‚Äôd now expect the replacement when our evaluation gets back up to &lt;code&gt;COUNT(1, 2, 3)&lt;/code&gt; to look like:&lt;/p&gt;
    &lt;code&gt;(+1 _COUNT_TOP(2, 3) + 0))
&lt;/code&gt;
    &lt;p&gt;So now, we‚Äôre thinking that escaped the paint, and &lt;code&gt;_COUNT_TOP()&lt;/code&gt; will further expand, right? ü¶óü¶óü¶ó&lt;/p&gt;
    &lt;p&gt;It‚Äôs time to shatter our youthful optimism with the bitter pill of experience. Yes, we‚Äôve added an extra indirection, but here‚Äôs what it expands to:&lt;/p&gt;
    &lt;code&gt;(+1 _COUNT_TOP(2, 3) + 0))
&lt;/code&gt;
    &lt;head rend="h2"&gt;ü§Ø&lt;/head&gt;
    &lt;p&gt;That‚Äôs the same as our intermediate expansion, but nothing further was done to the macro! I thought we made our way past the paint?&lt;/p&gt;
    &lt;p&gt;Clearly, there are subtleties to the rules somewhere. Clearly, the author is a jerk, and must have intentionally failed to mention it above.&lt;/p&gt;
    &lt;p&gt;It‚Äôs true I am a jerk, and it‚Äôs also true that I failed to mention the restriction that‚Äôs biting us right now. That‚Äôs because it‚Äôs a part of the journey‚Äî no tutorial or explanation I‚Äôve ever seen made it clear to me that restrictions on expanded macros can survive past the call site.&lt;/p&gt;
    &lt;p&gt;So maybe I‚Äôm just obtuse, and torturing others because I once suffered long ago. Let‚Äôs go look at the relevant text in the C23 standard, shall we? It‚Äôll either be enlightening‚Ä¶ or further torture.&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;‚ÑπÔ∏èÔ∏è&lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;After all parameters in the replacement list have been substituted and # and ## processing has taken place, all place-marker preprocessing tokens are removed. The resulting preprocessing token sequence is then rescanned, along with all subsequent preprocessing tokens of the source file, for more macro names to replace.&lt;/p&gt;
          &lt;p&gt;If the name of the macro being replaced is found during this scan of the replacement list (not including the rest of the source file‚Äôs preprocessing tokens), it is not replaced. Furthermore, if any nested replacements encounter the name of the macro being replaced, it is not replaced. These non-replaced macro name preprocessing tokens are no longer available for further replacement even if they are later (re)examined in contexts in which that macro name preprocessing token would otherwise have been replaced.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The sentence I bolded, I think we clearly understood; I did explain it above. The two sentences afterward, which I put in italics, is where the restriction that‚Äôs hurting us is specified.&lt;/p&gt;
    &lt;p&gt;For years, I took that to mean, ‚ÄúEven at the top level where the macro was called, no matter how many times subsequent replacement text gets rescanned, the called macro is still ineligible for expansion.‚Äù&lt;/p&gt;
    &lt;p&gt;What am I doing wrong? Why does the blue paint leave and then come back? This makes no sense. Right? Right?&lt;/p&gt;
    &lt;head rend="h2"&gt;üò≠üò≠&lt;/head&gt;
    &lt;p&gt;(I warned you, there‚Äôd be ugly crying. Better me than you though; I clearly deserve it).&lt;/p&gt;
    &lt;head rend="h2"&gt;Close n-counter&lt;/head&gt;
    &lt;p&gt;Perhaps it would be obvious to most readers that I had misinterpreted the standard. Perhaps, but even once I finally realized that my original interpretation couldn‚Äôt possibly be right, I still feel the above text from the standard is bit under-specified.&lt;/p&gt;
    &lt;p&gt;Specifically, what are the boundaries for ‚Äúnested replacement‚Äù? Clearly it‚Äôs not the case that once a macro is called, a parent of the calling macro can never replace it again. So does it mean, ‚Äúthe resulting text can never, in any way be involved in an expansion which produces an expansion ever again?‚Äù requiring full taint tracking of the replacement through all future transformations as long as the text could possibly be rescanned, no matter what?&lt;/p&gt;
    &lt;p&gt;Or, does it only apply to any text with the name of the function we called, and the second that changes, it could change back?&lt;/p&gt;
    &lt;p&gt;Or maybe there are some different semantics?&lt;/p&gt;
    &lt;p&gt;Let‚Äôs roll up our sleeves, with another little experiment, to help us determine how we should interpret the above test. What we‚Äôd like to see, is, can &lt;code&gt;_COUNT_ONE()&lt;/code&gt; produce a macro invocation with a different name, that we don‚Äôt try to expand until after leaving the context in which it and &lt;code&gt;_COUNT_TOP()&lt;/code&gt; are painted, and then somehow replace that macro with &lt;code&gt;_COUNT_TOP()&lt;/code&gt;?&lt;/p&gt;
    &lt;p&gt;If we can make that happen, then we‚Äôll test to see if we can call the resulting function is callable. Let‚Äôs junk our previous experiment, and go back to where we were before:&lt;/p&gt;
    &lt;code&gt;#define _COUNT_ONE(x, ...) + 1 _COUNT_TOP(__VA_ARGS__)
#define _COUNT_TOP(...)    __VA_OPT__(_COUNT_ONE(__VA_ARGS__))
#define COUNT(...)        (_COUNT_TOP(__VA_ARGS__) + 0)
&lt;/code&gt;
    &lt;p&gt;Now, we want to try to change the value of &lt;code&gt;_COUNT_TOP&lt;/code&gt; to something else to escape detection. It‚Äôs got to be a valid macro, but one that we‚Äôre NOT going to end up expanding when rescanning &lt;code&gt;_COUNT_ONE()&lt;/code&gt; or &lt;code&gt;_COUNT_TOP()&lt;/code&gt;. If we call it &lt;code&gt;_COUNT_INDIRECT&lt;/code&gt;, we don‚Äôt want &lt;code&gt;_COUNT_INDIRECT(2,3)&lt;/code&gt; to evaluate until we pop all the way back up into &lt;code&gt;_COUNT()&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Sounds like a tall order, but there‚Äôs are a couple of facts we‚Äôve already learned, that can help us:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;We know that, if we have a function-like macro named &lt;code&gt;X()&lt;/code&gt;, the preprocessor does not consider a bare&lt;code&gt;X&lt;/code&gt;with no parenthesis next to it to be an invocation of&lt;code&gt;X&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Rescans start at the replacement site, they don‚Äôt back up tokens.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So perhaps we can separate the function name and the arguments for a while, and somehow bring them together in a way where we could rescan it inside &lt;code&gt;COUNT()&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Having the function name separate from an argument list will both keep it from running, and will help us avoid a rescan the first time we get the left parenthesis to plop down in the right place.&lt;/p&gt;
    &lt;p&gt;We just need a way to add a spacer of some sort that goes away at rescan, to keep apart the name &lt;code&gt;_COUNT_ONE&lt;/code&gt; from its argument list. That is, we‚Äôd conceptually like to do:&lt;/p&gt;
    &lt;code&gt;#define _COUNT_ONE(x, ...) \
   + 1 __VA_OPT__(_COUNT_ONE &amp;lt;&amp;lt;SPACER&amp;gt;&amp;gt; (__VA_ARGS__))
&lt;/code&gt;
    &lt;p&gt;But we‚Äôre going to change the name of &lt;code&gt;_COUNT_ONE&lt;/code&gt; to &lt;code&gt;_COUNT_INDRECT&lt;/code&gt;. If we just do:&lt;/p&gt;
    &lt;code&gt;#define _COUNT_INDIRECT _COUNT_ONE
&lt;/code&gt;
    &lt;p&gt;Then we‚Äôre going to re-generate &lt;code&gt;_COUNT_ONE&lt;/code&gt; on the rescan, which is painted blue.&lt;/p&gt;
    &lt;p&gt;So it‚Äôs actually &lt;code&gt;_COUNT_INDIRECT&lt;/code&gt; where we currently have the dire need to postpone evaluating it.&lt;/p&gt;
    &lt;p&gt;Therefore, we need to turn &lt;code&gt;_COUNT_INDIRECT&lt;/code&gt; into a function, and keep THAT identifier separated from the parentheses that trigger it, via our to-be-written spacer. So this is the definition we want instead:&lt;/p&gt;
    &lt;code&gt;#define _COUNT_INDIRECT() _COUNT_ONE
&lt;/code&gt;
    &lt;p&gt;We‚Äôll also need to add the empty parameter list to invoke it on the other side of our spacer. So here‚Äôs what we really need &lt;code&gt;_COUNT_ONE&lt;/code&gt; to look like:&lt;/p&gt;
    &lt;code&gt;#define _COUNT_ONE(x, ...) \
   + 1 __VA_OPT__(_COUNT_INDIRECT &amp;lt;&amp;lt;SPACER&amp;gt;&amp;gt; ()(__VA_ARGS__))
&lt;/code&gt;
    &lt;p&gt;As we cascade up with replacements, we want the spacer to disappear, leaving:&lt;/p&gt;
    &lt;code&gt;_COUNT_INDIRECT()(2,3)
&lt;/code&gt;
    &lt;p&gt;Remember, in the contents where we replace the spacer, we will have advanced the input head past &lt;code&gt;_COUNT_INDIRECT&lt;/code&gt;. So if the spacer expands to nothing, the rescan will know that &lt;code&gt;()&lt;/code&gt; isn‚Äôt a replaceable macro, and go on with its day. But it will leave &lt;code&gt;_COUNT_INDIRECT&lt;/code&gt; next to the &lt;code&gt;()&lt;/code&gt; so it can be called above, to generate the correct name.&lt;/p&gt;
    &lt;head rend="h2"&gt;You can count on me being empty inside&lt;/head&gt;
    &lt;p&gt;It‚Äôs not hard to get something to expand to the empty string.&lt;/p&gt;
    &lt;p&gt;And then, once we get back up to &lt;code&gt;COUNT()&lt;/code&gt;, we will evaluate &lt;code&gt;_COUNT_INDIRECT()&lt;/code&gt;, which will leave us with &lt;code&gt;_COUNT_ONE(2,3)&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Once we get that far, will tinker to find if there are any conditions where we can re-invoke &lt;code&gt;_COUNT_ONE()&lt;/code&gt;. Because hey, we already know there are, we just might not know WHAT they are.&lt;/p&gt;
    &lt;p&gt;It‚Äôs not hard to create a spacer. We can define a macro named &lt;code&gt;EMPTY&lt;/code&gt; like this:&lt;/p&gt;
    &lt;code&gt;#define EMPTY
&lt;/code&gt;
    &lt;p&gt;And use that as our spacer. If you‚Äôve ever peeked into someone‚Äôs recursive macros and been dumbfounded with what you saw, there‚Äôs a good chance you saw a macro named &lt;code&gt;EMPTY&lt;/code&gt; and at the time were thinking, ‚Äúwhat the heck could that possibly do?‚Äù&lt;/p&gt;
    &lt;p&gt;Now you know. But when you did see it, it was probably defined as a function-like macro instead:&lt;/p&gt;
    &lt;code&gt;#define EMPTY()
&lt;/code&gt;
    &lt;p&gt;Using it to postpone evaluation is as easy as:&lt;/p&gt;
    &lt;code&gt;_COUNT_INDIRECT EMPTY() () (2, 3)
&lt;/code&gt;
    &lt;p&gt;Why would we use a function-like macro for our spacer? Doing so makes it easy for us to control how long we want to wait before we‚Äôre able to evaluate what we‚Äôre separating.&lt;/p&gt;
    &lt;p&gt;Specifically, let‚Äôs say we nest our recursive call several levels down. Every level, we use the same trick recursively, separating &lt;code&gt;EMPTY()&lt;/code&gt; apart‚Ä¶ using another &lt;code&gt;EMPTY()&lt;/code&gt; invocation.&lt;/p&gt;
    &lt;p&gt;For instance, if we need to postpone a total of three layers, we could write:&lt;/p&gt;
    &lt;code&gt;_COUNT_INDIRECT EMPTY EMPTY EMPTY() () () () (2, 3)
&lt;/code&gt;
    &lt;p&gt;Honestly, &lt;code&gt;EMPTY()&lt;/code&gt; is a confusing name that detracts from what‚Äôs happening. we can encapsulate this into a more readable macro‚Ä¶ or macros, one for each level we might want to postpone evaluation:&lt;/p&gt;
    &lt;code&gt;#define POSTPONE1(macro_name, args) macro_name EMPTY() args
#define POSTPONE2(macro_name, args) macro_name EMPTY EMPTY()() args
#define POSTPONE3(macro_name, args) \
                               macro_name EMPTY EMPTY EMPTY()()() args
&lt;/code&gt;
    &lt;p&gt;We‚Äôll only need the first of these by the way; but now you know, if you never have a use case where you have deeper nesting (though if you do, maybe worry your macros are getting too complex to be readable?)&lt;/p&gt;
    &lt;p&gt;Our &lt;code&gt;POSTPONE1&lt;/code&gt; macro encapsulates the unintuitive &lt;code&gt;EMPTY()&lt;/code&gt; madness for us, allowing us to instead write:&lt;/p&gt;
    &lt;code&gt;#define _COUNT_ONE(x, ...) \
                    + 1 __VA_OPT__(POSTPONE1(_COUNT_INDIRECT, ())(__VA_ARGS__))
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;EMPTY()&lt;/code&gt; invocation is hidden inside &lt;code&gt;POSTPONE1()&lt;/code&gt; That makes the code we use here, it‚Äôs more explicit that we‚Äôre going to postpone expanding &lt;code&gt;_COUNT_INDIRECT&lt;/code&gt;. We‚Äôve even added the args we want to call it with as a second parameter, to make it more clear what we‚Äôre doing, instead of having a bunch of consecutive argument lists detached from their identifier, which many engineers find alien and incomprehensible.&lt;/p&gt;
    &lt;p&gt;So far, the rest of what we have is:&lt;/p&gt;
    &lt;code&gt;#define _COUNT_TOP(...)   __VA_OPT__(_COUNT_ONE(__VA_ARGS__))
#define COUNT(...)        (_COUNT_TOP(__VA_ARGS__) + 0)
#define _COUNT_INDIRECT() _COUNT_ONE
&lt;/code&gt;
    &lt;p&gt;Let‚Äôs now see if it is getting the right text up to the top, even though we won‚Äôt yet try to get it to expand (and thus, we will get a compiler error). If we invoke as &lt;code&gt;COUNT(1, 2)&lt;/code&gt; again, CPP will generate the following expansion:&lt;/p&gt;
    &lt;code&gt;(+1 _COUNT_INDIRECT ()(2) + 0)
&lt;/code&gt;
    &lt;p&gt;That‚Ä¶ looks exactly like what we were hoping to see. As we wanted, the pieces came together, and &lt;code&gt;_COUNT_INDIRECT()&lt;/code&gt; did NOT get evaluated during the rescan process. If we had made a mistake, and the rescan had happened, it would have been replaced with &lt;code&gt;_COUNT_ONE&lt;/code&gt;, which we already know we could not trigger for re-evaluation.&lt;/p&gt;
    &lt;p&gt;Okay, let‚Äôs now see what happens if we try to force the expansion of the above, to finally get an answer to our question as to the true scope of blue paint.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs wrap the body of &lt;code&gt;COUNT()&lt;/code&gt; with a call to a passthrough macro, which we‚Äôll name &lt;code&gt;EVAL()&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;#define EVAL(...)  __VA_ARGS__
#define COUNT(...) EVAL((_COUNT_TOP(__VA_ARGS__) + 0))
&lt;/code&gt;
    &lt;p&gt;Based on our rules above, &lt;code&gt;EVAL()&lt;/code&gt; will substitute, and then rescan. So this passthrough macro forces the rescan we want.&lt;/p&gt;
    &lt;p&gt;The test case for our macro should be:&lt;/p&gt;
    &lt;code&gt;#include &amp;lt;stdio.h&amp;gt;

int
main()
{
    printf("%d\n", COUNT(1, 2));
}
&lt;/code&gt;
    &lt;p&gt;You might notice, this actually compiles. And if you run it, it gives the right answer.&lt;/p&gt;
    &lt;head rend="h1"&gt;ü•π&lt;/head&gt;
    &lt;p&gt;Wow, are we done?&lt;/p&gt;
    &lt;head rend="h3"&gt;ü§£üòÇü§£üòÇü§£üòÇü§£üòÇü§£üòÇü§£üòÇü§£üòÇü§£üòÇü§£üòÇü§£üòÇü§£üòÇü§£üòÇü§£üòÇü§£&lt;/head&gt;
    &lt;p&gt;While we may be farther than expected, we don‚Äôt have something that will fully work. What‚Äôs important is that we‚Äôve shown that blue paint FULLY gets removed from a macro when:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;We have finished all rescans of that macro where it was called; and&lt;/item&gt;
      &lt;item&gt;EITHER the macro does not appear in the replacement text, or we completely exit the recursive expansion.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Unfortunately, we still have a problem. If you change your invocation to &lt;code&gt;COUNT(1, 2, 3)&lt;/code&gt; then your code will no longer compile. Instead, it will expand to:&lt;/p&gt;
    &lt;code&gt;(+1 +1 _COUNT_INDIRECT ()(3) + 0))
&lt;/code&gt;
    &lt;p&gt;What‚Äôs happening should be clear at this point: while we are iterating over arguments, we are stopping after the second iteration.&lt;/p&gt;
    &lt;p&gt;Great, that‚Äôs easy to fix. We can do so by‚Ä¶&lt;/p&gt;
    &lt;p&gt;Passing the output of &lt;code&gt;EVAL()&lt;/code&gt; to another call of &lt;code&gt;EVAL()&lt;/code&gt;, like so:&lt;/p&gt;
    &lt;code&gt;#define COUNT(...) EVAL(EVAL((_COUNT_TOP(__VA_ARGS__) + 0)))
&lt;/code&gt;
    &lt;p&gt;Before we address the obvious complaint, I‚Äôd like to point out that the extra &lt;code&gt;EVAL()&lt;/code&gt; doesn‚Äôt mess up the results if we change our test invocation to &lt;code&gt;COUNT()&lt;/code&gt; or &lt;code&gt;COUNT(1)&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;EVAL()&lt;/code&gt; will expand, but it doesn‚Äôt break anything when there are no macros in the text passed to it that are eligible for expansion. Once the last possible expansion happens, it will just keep copying its arguments to the replacement text, per the algorithm above; the associated rescans have nothing to do.&lt;/p&gt;
    &lt;p&gt;Given that, it‚Äôs common to say, ‚ÄúNobody needs more than 10 arguments!‚Äù and do something like:&lt;/p&gt;
    &lt;code&gt;#define _E(...) __VA_ARGS__
#define EVAL(...) _E(_E(_E(_E(_E(_E(_E(_E(_E(_E(__VA_ARGS__))))))))))
&lt;/code&gt;
    &lt;p&gt;Although, more commonly, you‚Äôd probably see people do more expansions, perhaps enough to accommodate 20 or 50 arguments. Even there, I‚Äôve seen some Microsoft APIs that convince me, that‚Äôs too low a limit, so I‚Äôd suggest at least 100 iterations.&lt;/p&gt;
    &lt;p&gt;We can use a much smarter approach that can still fairly compactly get us as many expansions as we think we might ever need.&lt;/p&gt;
    &lt;p&gt;I‚Äôd guess that, if we saw a function with 1024 arguments, it would be explicitly TRYING to break our macro. So let‚Äôs do the base 2 version of the Spinal Tap ‚Äúone more‚Äù, and get to 1025 expansions:&lt;/p&gt;
    &lt;code&gt;#define _E1(...)    __VA_ARGS__
#define _E8(...)    _E1(_E1(_E1(_E1(_E1(_E1(_E1(_E1(__VA_ARGS__))))))))
#define _E64(...)   _E8(_E8(_E8(_E8(_E8(_E8(_E8(_E8(__VA_ARGS__))))))))
#define _E256(...)  _E64(_E64(_E64(_E64(__VA_ARGS__))))
#define _E1024(...) _E256(_E256(_E256(_E256(__VA_ARGS__))))
#define EVAL(...)   _E1024(__VA_ARGS__)
&lt;/code&gt;
    &lt;p&gt;The last expansion really is gratuitous; we could name &lt;code&gt;_E1024()&lt;/code&gt; to&lt;code&gt;EVAL()&lt;/code&gt; and stop on the power of two, but what fun is that?&lt;/p&gt;
    &lt;p&gt;Before writing this article, I generally stopped at 256 iterations, but I was curious as to whether the compiler‚Äôs CPP was smart enough to skip unnecessary evaluations, given it‚Äôs a common idiom. I ramped the number of iterations up to 65,636, and built a minimal program that would trigger 100 different calls to eval. On a Macbook Pro using &lt;code&gt;clang&lt;/code&gt;, that many expansions took .13 seconds; when setting EVAL to 256 expansions, compiling took .06 seconds. When using &lt;code&gt;gcc&lt;/code&gt;, both times were a bit more than twice as expensive.&lt;/p&gt;
    &lt;p&gt;So no, we definitely shouldn‚Äôt keep going until we get to 2^64; it‚Äôs unlikely to work. But, I‚Äôve never noticed compile time impact due to 256 iterations, even in programs using recursive macros extensively, and can recommend it, but it also seems 2^16 expansions is totally acceptable for cases where you might need it (probably when you‚Äôre iterating over something other than call arguments).&lt;/p&gt;
    &lt;p&gt;NOW we can declare victory.&lt;/p&gt;
    &lt;p&gt;Hang on, I‚Äôm going to go cry again, but this time tears of joy. üò≠üò≠&lt;/p&gt;
    &lt;head rend="h3"&gt;You can count me out&lt;/head&gt;
    &lt;p&gt;While the &lt;code&gt;EVAL&lt;/code&gt;approach works, you may find it feels kludgy. Why ask the preprocessor to do all that additional work? maybe it can recognize the idiom and short-circuit a bunch of work with an &lt;code&gt;EVAL()&lt;/code&gt;? Is there really no better way?
There is a technique that facilitates the kind of compile-time recursion we‚Äôre trying to do here, without unnecessary layers of expansion.
The basic idea is related to the concept of continuations; every macro passes a bag of state to the ‚Äònext‚Äô function-like macro that should get called, doing it in a way that allows us to BOTH dodge blue paint, AND terminate without oblivious expansions.
However:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The approach is MUCH more complicated than what we‚Äôve done so far (and I hope anyone reading should agree what we‚Äôve done today is already much too complicated).&lt;/item&gt;
      &lt;item&gt;Having used the continuation approach, I find it too brittle (as implementable in CPP), and significantly harder to debug than more traditional recursion work-arounds.&lt;/item&gt;
      &lt;item&gt;The extra evals in the approach we‚Äôre using tend to be cheap enough, that the massive amount of extra complexity buys you virtually nothing.&lt;/item&gt;
      &lt;item&gt;I suspect the continuation technique cannot be done without relying on undefined behavior (specifically, how the compiler chooses to resolve cases where there are multiple possible ambiguous valid expansions). But, it‚Äôs still really cool, and if you‚Äôre interested (and really want to risk your head going ü§Ø), check out this brainf‚Äî interpreter written entirely in C macros.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I should note, there are still other ways we could avoid such deep compile-time recursion, or even all recursion if we aren‚Äôt trying to get close to an arbitrary number of arguments. It‚Äôs all far uglier (and way more challenging to understand), and what we‚Äôre doing is performant, enough so that added ugliness isn‚Äôt merited, IMHO.&lt;/p&gt;
    &lt;p&gt;Though, one thing I do recommend you do differently from what we‚Äôve done today, is that you should add a common prefix to all your names, to remove the risk of name collisions ‚Äî many libraries already define things like &lt;code&gt;EVAL()&lt;/code&gt; and &lt;code&gt;EMPTY()&lt;/code&gt;for themselves, and you never know what might make its way into your system, and cause chaos.&lt;/p&gt;
    &lt;p&gt;You can‚Äôt be bothered? Okay, I‚Äôm a pushover (and feel strongly about the issue). So I‚Äôve provided a complete version for you at the end of this article.&lt;/p&gt;
    &lt;head rend="h2"&gt;Count your blessings&lt;/head&gt;
    &lt;p&gt;This journey has taken us further down the macro rabbit hole than anyone should ever have to go, yet we didn‚Äôt have to sacrifice ALL of our remaining sanity (it helps that I was already tapped out). As much as C actively worked to thwart us from our goal, we got there; now we have a good tool for better compile-time checking of C code in a number of cases, such as when we want to support variable argument functions. And, with incredibly minor changes, we can re-use the code to operate on each argument, to support other things we might want to automate to make our code more robust. For instance, we could add automatic casts or calls to runtime type checkers, or so on. All you really need to do is, take the text we insert (generating the addition that the compiler can easily fold into a count), and replace it with an invocation of a macro that the caller passes in, passing that macro the current argument. Yes, the C standard committee has good reason to disallow recursion‚Äî removing the restriction would undoubtedly break existing code. Yet, the difficulty of the whole exercise hopefully demonstrates the need for some quality-of-life improvements in C2Y, all of which can be done without significant backward compatibility risk.&lt;/p&gt;
    &lt;p&gt;Most of all, I‚Äôd love to be able to do far more meaningful work at compile time much more sanely, minimizing my use of macros (as I know many others would too). For that, the language should extend &lt;code&gt;constexpr&lt;/code&gt; capabilities, giving us good, full-fledged &lt;code&gt;constexpr&lt;/code&gt; functions, with as few limitations as possible. That may be a tall order for C2Y, given the complexity of that change.
But even still, I‚Äôd want to improve the macro system too:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Add a builtin macro, &lt;code&gt;__VA_COUNT__&lt;/code&gt;. We need it to avoid null truncation problems for varargs, and shouldn‚Äôt have to keep reinventing the wheel (or doling out&lt;code&gt;__VA_ARGS__&lt;/code&gt;in our code like it‚Äôs Halloween candy).&lt;/item&gt;
      &lt;item&gt;Add another builtin macro, &lt;code&gt;__VA_EMPTY__(...)&lt;/code&gt;, which would be the inverse of&lt;code&gt;__VA_OPT__(...)&lt;/code&gt;; its arguments would only get expanded only when the are NO variadic arguments. This would make it even easier to ensure people have good tools to easily terminate the kind of recursion we did today. Assuming&lt;code&gt;constexpr&lt;/code&gt;functions take longer to do well, A&lt;code&gt;__VA_EMPTY__&lt;/code&gt;macro can also bridge the gap of not having a good compile-time IF available for complex use cases; it would be much easier to cobble together a reasonably robust one one in macros than it is today by pairing it with&lt;code&gt;__VA_OPT__&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Add a &lt;code&gt;__VA_EVAL__(...)&lt;/code&gt;which simply expands its contents, with two semantic changes to the process that other macro goes through:&lt;list rend="ol"&gt;&lt;item&gt;When an expansion fully finishes, the entire macro gets rescanned again, as many times as necessary, until the full expansion reaches a fix-point (meaning, no more expansions are possible). That would allow us to worry about artificial limits on &lt;code&gt;EVAL()&lt;/code&gt;macros; they‚Äôd just stop when they should stop.&lt;/item&gt;&lt;item&gt;Every top-level rescan should remove all blue paint generated during one expansion, before starting the next expansion (alternately, it could forego further painting macros in the first place).&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;When an expansion fully finishes, the entire macro gets rescanned again, as many times as necessary, until the full expansion reaches a fix-point (meaning, no more expansions are possible). That would allow us to worry about artificial limits on &lt;/item&gt;
      &lt;item&gt;A more general purpose &lt;code&gt;__MAP__(body_macro, state, ...)&lt;/code&gt;would be useful (though, to be fair, much less of a problem to build robustly if the rest of the above were present).&lt;/item&gt;
      &lt;item&gt;While waiting for &lt;code&gt;constexr&lt;/code&gt;functions, it would be valuable to have a preprocessor built-in&lt;code&gt;__SHA256__&lt;/code&gt;that‚Ä¶ replaces the contents passed to it (after expansion) with the SHA256 hash of those contents. I‚Äôve seen more than a few cases where this would be incredibly useful for saving both startup costs, and ongoing costs. No? Why can‚Äôt we have nice things??!! Interestingly, doing a compile-time only implementation of&lt;code&gt;SHA-256&lt;/code&gt;using only C macros may seem possible, but I‚Äôve built it (for strings one block in length), and it completely overwhelms both GCC and Clang, even with significantly reduced rounds.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If the committee were to adopt most of the above, it sure would make one of the ugliest legacies the language has needed to carry forward far more tolerable.&lt;/p&gt;
    &lt;p&gt;We mere mortals would be able to get the gist of expansion rules more easily, if we could tell ourselves, ‚Äúmacro recursion is disallowed unless you use &lt;code&gt;__EVAL__()&lt;/code&gt;‚Äù. That removes a huge source of confusion, but still leaves us with the problem of getting termination conditions right, which are a bit tricky.
Adding &lt;code&gt;__VA_EMPTY__()&lt;/code&gt; makes it pretty easy for someone to get the exit condition right in the common case where our recursion is being used to iterate over the arguments passed to function-like macros. &lt;code&gt;__EVAL__()&lt;/code&gt; would then essentially be able to function as a ‚Äúdo what I mean‚Äù operator, for most of the things people bang their head against when trying to write useful, robust macros to hide C‚Äôs unnecessary complexity. With just these two things, you would be able to implement &lt;code&gt;__VA_COUNT__(‚Ä¶)&lt;/code&gt;fairly simply:&lt;/p&gt;
    &lt;code&gt;#define __REST__(x, ...) __VA_ARGS__
#define __VA_COUNT__(...) \
    __VA_EMPTY__(0) \
    __VA_OPT__(1 + __EVAL__(__VA_COUNT__(__REST__(__VA_ARGS__))))
&lt;/code&gt;
    &lt;p&gt;Sure, it‚Äôs still a little obtuse, but it‚Äôs far more sane than our final product.&lt;/p&gt;
    &lt;head rend="h2"&gt;Does this count?&lt;/head&gt;
    &lt;p&gt;I said there was no price for my full implementation, and there‚Äôs not. But, if you really feel obliged, then spend a minute indulging me.&lt;/p&gt;
    &lt;p&gt;I can count the times I‚Äôve written the word ‚Äúcount‚Äù more than 100 times in a week on one finger. The entire time I‚Äôve been working on this article, I keep thinking about what might be my favorite dad joke ever, but I spent far more time in ‚Äúmacro hell‚Äù than I like. So, before we talk about our final implementation, I‚Äôm going to indulge myself. It will only make sense to people who grew up with US kids programming, and does not in any way contribute to this topic:&lt;/p&gt;
    &lt;p&gt;Person A: ‚ÄúWho‚Äôs your favorite vampire?‚Äù&lt;/p&gt;
    &lt;p&gt;Person B: ‚ÄúWithout a doubt, the one who lives on Sesame Street.‚Äù&lt;/p&gt;
    &lt;p&gt;Person A: ‚ÄúThe puppet? He doesn‚Äôt count!‚Äù&lt;/p&gt;
    &lt;p&gt;Person B: ‚ÄúI assure you, he does.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;‚ö°Ô∏èHa! Ha! Ha! ‚ö°Ô∏è&lt;/head&gt;
    &lt;code&gt;              oooOOOooo
           oOOOOOOOOOOOOOo
         oOO"           "OO
    ____oOO  ====   ====  OOo____ 
    \   OO'      ! !.---. 'OO   /
     \  OO   &amp;lt;0&amp;gt; ! !!&amp;lt;0&amp;gt;!  OO  /
      \ Oo       ! !'---'  oO /
       \o        \_/        o/
        .' _______________ '.
      ,'   :   V     V   :   '.
    ,'      -_         _-      '.
  ,'          "oOOOOOo"          '.
,'              OOOOO              '.
-----------     "OOO"     -----------
                 "O"             
&lt;/code&gt;
    &lt;p&gt;Okay, if you sat through that (or were smart enough to skip it), you‚Äôve earned the full code.&lt;/p&gt;
    &lt;p&gt;As I mentioned above, I added a &lt;code&gt;H4X0R_&lt;/code&gt; prefix to everything to avoid name collisions. Additionally, internal helpers have a leading underscore. The notion of &lt;code&gt;_&lt;/code&gt; indicating an internal variable has a long heritage (it is particularly prominent in Python, for example).&lt;/p&gt;
    &lt;p&gt;Our new top-level count macro is named &lt;code&gt;H4X0R_VA_COUNT()&lt;/code&gt;; I added the &lt;code&gt;VA&lt;/code&gt; to indicate we‚Äôre counting variable arguments (but didn‚Äôt want to make it too verbose, either).&lt;/p&gt;
    &lt;p&gt;But I actually made some other changes from what we did above.&lt;/p&gt;
    &lt;p&gt;Specifically, I first built a macro, &lt;code&gt;H4X0R_MAP(macro, ...)&lt;/code&gt;. The implementation of this new macro is structured in pretty much the same way as our &lt;code&gt;COUNT()&lt;/code&gt; macro above, at least in terms of the recursion. Our major change, besides the names is that, whereas for each argument, &lt;code&gt;COUNT()&lt;/code&gt; ignores the argument and replaces it with &lt;code&gt;+1&lt;/code&gt;, &lt;code&gt;H4X0R_MAP()&lt;/code&gt; takes the argument, and passes it to a macro supplied by the caller. That caller-supplied macro gets passed the value of the parameter currently being visited.&lt;/p&gt;
    &lt;p&gt;That makes it trivial to create &lt;code&gt;H4X0R_VA_COUNT()&lt;/code&gt;; we just have to call our new macro, and pass in a body macro that simply does &lt;code&gt;+1&lt;/code&gt; (ignoring the parameter value).&lt;/p&gt;
    &lt;p&gt;This new macro gives us more flexibility, hopefully lessening the need to write future recursive macros.&lt;/p&gt;
    &lt;code&gt;// To keep this compact width-wise (given the prefix), we only do two 
// expansions per line, and stop at 256 expansions. Extend as desired.

#define H4X0R_EVAL1(...)    __VA_ARGS__
#define H4X0R_EVAL2(...)    H4X0R_EVAL1(H4X0R_EVAL1(__VA_ARGS__))
#define H4X0R_EVAL4(...)    H4X0R_EVAL2(H4X0R_EVAL2(__VA_ARGS__))
#define H4X0R_EVAL8(...)    H4X0R_EVAL4(H4X0R_EVAL4(__VA_ARGS__))
#define H4X0R_EVAL16(...)   H4X0R_EVAL8(H4X0R_EVAL8(__VA_ARGS__))
#define H4X0R_EVAL32(...)   H4X0R_EVAL16(H4X0R_EVAL16(__VA_ARGS__))
#define H4X0R_EVAL64(...)   H4X0R_EVAL32(H4X0R_EVAL32(__VA_ARGS__))
#define H4X0R_EVAL128(...)  H4X0R_EVAL64(H4X0R_EVAL64(__VA_ARGS__))
#define H4X0R_EVAL(...)     H4X0R_EVAL128(H4X0R_EVAL128(__VA_ARGS__))

#define H4X0R_EMPTY()
#define H4X0R_POSTPONE1(macro) macro H4X0R_EMPTY()

// MAP(); If you remove the macro parameter, and replace the call
// `macro(x)` with `+1`, you'll see this is structurally the same
// as COUNT() above.
#define H4X0R_MAP(macro, ...) \
    __VA_OPT__(H4X0R_EVAL(_H4X0R_MAP_ONE(macro, __VA_ARGS__)))
#define _H4X0R_MAP_ONE(macro, x, ...) macro(x) \
    __VA_OPT__(H4X0R_POSTPONE1(_H4X0R_MAP_INDIRECT)()(macro, __VA_ARGS__))
#define _H4X0R_MAP_INDIRECT() _H4X0R_MAP_ONE

// A re-implementation of count on top of H4X0R_MAP()... it's simple now!
#define _H4X0R_COUNT_BODY(x) +1
#define H4X0R_VA_COUNT(...)  \
                           (H4X0R_MAP(_H4X0R_COUNT_BODY, __VA_ARGS__) + 0)
&lt;/code&gt;
    &lt;p&gt;The new &lt;code&gt;H4X0R_MAP()&lt;/code&gt; call gives us a more general purpose way to apply transformations to a list of individual arguments. This can help us automate static type checking per-argument, for instance, when we‚Äôre implementing variable-argument functions and want to statically ensure all items at the call site have the same time (as done in the variadic function arguments implementation I wrote about last week.&lt;/p&gt;
    &lt;p&gt;For a use case like that, we need to add the commas back in from the original call site. But we won‚Äôt want to add the comma at the end of last argument, because the C compiler will complain. There are plenty of different ways to handle this problem, including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If the output is being passed to a C varargs function where the same arguments we‚Äôre iterating over will have a correct &lt;code&gt;count&lt;/code&gt;parameter before the values, we can simply add a dummy value (probably 0 since that‚Äôll pass through easily in most contexts). This one is trivial when appropriate, but I don‚Äôt love it, as it isn‚Äôt always appropriate.&lt;/item&gt;
      &lt;item&gt;We can rework our map implementation to call a different callback for the last parameter, or to call a separate callback in between parameters. This is definitely more workable, but requires more recursive macro work, overcomplicating things. And then, the extra parameter can easily be forgotten by callers, which would lead to confusing errors (any time you make a mistake calling a macro, but the error isn‚Äôt detected until the compilation step, we should expect it to be confusing).&lt;/item&gt;
      &lt;item&gt;We can let the caller handle the first argument separately, and then for any subsequent arguments, add the comma at the beginning, separating it from the previous argument that we know must be present.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I personally think the third option is the best compromise. Let‚Äôs look at a simple little example. While I normally would want to add more static type checking, sometimes the need might arise to convert a bunch of items of different types into &lt;code&gt;void *&lt;/code&gt; .&lt;/p&gt;
    &lt;p&gt;If we only need to do it for integer types and pointers, it‚Äôs not too hard to use a union to statically convert one item at a time to &lt;code&gt;void *&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;We will create a temporary union, with two fields, one being our largest standard unsigned int type (&lt;code&gt;unsigned long long&lt;/code&gt;, guaranteed to be at least 64 bits), and a &lt;code&gt;void *&lt;/code&gt;. We will use a cast to assign to the first field, allowing us to insert any integer or pointer type into the anonymous union:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Shorter integers will happily promote to a larger size.&lt;/item&gt;
      &lt;item&gt;Pointers will convert, since they are never more than 64 bits in size today.&lt;/item&gt;
      &lt;item&gt;The first field being unsigned prevents unwanted sign extension, when we insert signed values that are kept in smaller values.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We then will take the value out of the anonymous union, using the &lt;code&gt;void *&lt;/code&gt; . The compiler is smart enough to not generate a real temporary object for this conversion.&lt;/p&gt;
    &lt;code&gt;#define _H4X0R_CONVERT_ONE(arg)                  \
    ((union { unsigned long long u; void *v; }){ \
         .u = (unsigned long long)arg,           \
     }).v    
&lt;/code&gt;
    &lt;p&gt;Next, let‚Äôs build a macro to return the first parameter item in a variable list:&lt;/p&gt;
    &lt;code&gt;#define H4X0R_FIRST(...)     __VA_OPT__(_H4X0R_FIRST(__VA_ARGS__))
#define _H4X0R_FIRST(x, ...) x
&lt;/code&gt;
    &lt;p&gt;The reason for two macros here, is that we want to be able to tolerate cases where no arguments are provided.&lt;/p&gt;
    &lt;p&gt;We then can do the same thing to get all the rest of the arguments, after carving off the first argument:&lt;/p&gt;
    &lt;code&gt;#define H4X0R_REST(...)     __VA_OPT__(_H4X0R_REST(__VA_ARGS__))
#define _H4X0R_REST(x, ...) __VA_ARGS__
&lt;/code&gt;
    &lt;p&gt;When we process the first argument, we‚Äôll be able to call &lt;code&gt;_H4X0R_CONVERT_ONE()&lt;/code&gt; directly. For the rest of the arguments, we‚Äôre going to want to pass a macro to process the argument, which can reuse &lt;code&gt;_H4X0R_CONVERT_ONE()&lt;/code&gt;, but does need to add a comma before the argument. So it‚Äôs as simple as:&lt;/p&gt;
    &lt;code&gt;#define _H4X0R_CONVERT_LATER_ARG(arg) , _H4X0R_CONVERT_ONE(arg)
&lt;/code&gt;
    &lt;p&gt;We‚Äôll want to pass that macro to our map implementation. Here‚Äôs the call to our map function:&lt;/p&gt;
    &lt;code&gt;#define _H4X0R_CONVERT_LIST(...) H4X0R_MAP(_H4X0R_CONVERT_LATER_ARG, __VA_ARGS__)
&lt;/code&gt;
    &lt;p&gt;To stitch this all together, we just need to peal off the first argument from the rest, and concatenate the two resulting pieces. The only caveat is that we need to be careful to avoid adding a spurious comma or semicolons in between the two bits we need. When in doubt, use &lt;code&gt;cc -E&lt;/code&gt; to review what‚Äôs getting produced.&lt;/p&gt;
    &lt;code&gt;#define H4X0R_VA_VOID_STAR_CONVERT(...)          \
    _H4X0R_CONVERT_ONE(H4X0R_FIRST(__VA_ARGS__)) \
    _H4X0R_CONVERT_LIST(H4X0R_REST(__VA_ARGS__))
&lt;/code&gt;
    &lt;p&gt;A dumb test case to show this working:&lt;/p&gt;
    &lt;code&gt;#include &amp;lt;stdio.h&amp;gt;

int
main()
{
    printf("%d items: (%p, %p, %p)\n",
           H4X0R_VA_COUNT(1, 2, 3),
           H4X0R_VA_VOID_STAR_CONVERT(1, 2, 3));
}
&lt;/code&gt;
    &lt;p&gt;As you may expect, this prints:&lt;/p&gt;
    &lt;code&gt;3 items: (0x1, 0x2, 0x3)
&lt;/code&gt;
    &lt;p&gt;With our knowledge, and our final &lt;code&gt;H4X0R_MAP()&lt;/code&gt; and &lt;code&gt;H4X0R_COUNT()&lt;/code&gt; implementations, we can now do some significant transformations easily most people find mind boggling.&lt;/p&gt;
    &lt;p&gt;I find it astounding, the level of difficulty required to understand enough about C macros to be able to build a primitive as basic as counting arguments statically at a call site.&lt;/p&gt;
    &lt;p&gt;There‚Äôs such a high level of complexity involved, that it‚Äôs even more amazing to me, that once we got the understanding we needed, we could implement both macros in a mere 18 lines of code, exactly half of that being the rote &lt;code&gt;H4X0R_EVAL()&lt;/code&gt;implementation.&lt;/p&gt;
    &lt;p&gt;And in my view, by choosing comprehensible names, despite all the hurdles we‚Äôve had to overcome, the final result looks almost trivial. Yet, the code alone does not hint at the knowledge you need to write it.&lt;/p&gt;
    &lt;p&gt;I‚Äôm confident that nearly anyone who lacks a solid understanding of those basics who tries to gain understanding by trying to rebuild this code, but using it has a guide (perhaps to a slightly different use case), will be inflicting gruesome self-torture on themselves. They might have preferred to code their algorithm in the Brainf‚Äî implementation mentioned above!&lt;/p&gt;
    &lt;p&gt;Why is this stuff so hard after decades of standardization? Is the committee secretly a cabal of Rust zealots, that built time travel and went back to 1989, to maximize their torture of C developers?? Maybe that was the inspiration for the movie 12 Monkeys ü§î Sounds plausible. Or did they just beam that into my head?! Where did I leave my tin foil hat?&lt;/p&gt;
    &lt;p&gt;Happy hacking (but hopefully not on C macros)!&lt;/p&gt;
    &lt;p&gt;‚Äî L33 T. (with a &lt;code&gt;#&lt;/code&gt;-ing headache)&lt;/p&gt;
    &lt;head rend="h2"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;This post started as an out-of-control sidebar in my post on variable argument functions in C.&lt;/p&gt;
    &lt;p&gt;I owe a huge debt of gratitude to Robert Seacord; his early feedback gave me the clarity I needed to (hopefully) help other C programmers over what is probably one of the biggest hurdles in the language‚Ä¶ people who become C developers eventually master pointers, but to many senior developers, macro recursion has remained a dark art, requiring a magic incantation borrowed from Stack Overflow, Claude or the like.&lt;/p&gt;
    &lt;p&gt;Ivan O‚ÄôDay also was critical here, BUT is responsible for me taking several extra weeks to get the article out once it was in decent shape‚Ä¶ because he helped me see that I really needed the step-by-step example of a macro expansion, which I then had to find time to do!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45830223</guid><pubDate>Thu, 06 Nov 2025 01:09:18 +0000</pubDate></item><item><title>End of Japanese community</title><link>https://support.mozilla.org/en-US/forums/contributors/717446</link><description>&lt;doc fingerprint="d673c7910d1bb0ed"&gt;
  &lt;main&gt;
    &lt;p&gt;JavaScript is disabled in your browser. Please enable JavaScript to proceed. A required part of this site couldn‚Äôt load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45830770</guid><pubDate>Thu, 06 Nov 2025 02:38:53 +0000</pubDate></item><item><title>Ratatui ‚Äì App Showcase</title><link>https://ratatui.rs/showcase/apps/</link><description>&lt;doc fingerprint="74cad9da50b51b8f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;App Showcase&lt;/head&gt;
    &lt;p&gt;Atuin replaces your existing shell history with a SQLite database, and records additional context for your commands.&lt;/p&gt;
    &lt;p&gt;This is a CLI utility for displaying current network utilization by process, connection and remote IP/hostname&lt;/p&gt;
    &lt;p&gt;Perform binary analysis in your terminal.&lt;/p&gt;
    &lt;p&gt;A customizable cross-platform graphical process/system monitor for the terminal&lt;/p&gt;
    &lt;p&gt;Play crossword puzzles in your terminal.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;csvlens&lt;/code&gt; is A command line CSV file viewer. It is like less but made for CSV.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;dua&lt;/code&gt; is a disk space analysis tool designed for speed, leveraging parallel processing to quickly
provide detailed disk usage information and allowing for faster deletion of unnecessary data
compared to the standard ‚Äòrm‚Äô command.&lt;/p&gt;
    &lt;p&gt;A command line tool that executes make target using fuzzy finder with preview window&lt;/p&gt;
    &lt;p&gt;TUI for git written in rust&lt;/p&gt;
    &lt;p&gt;gpg-tui is a Terminal User Interface for GnuPG.&lt;/p&gt;
    &lt;p&gt;Ranger-like terminal file manager written in Rust&lt;/p&gt;
    &lt;p&gt;A material design color palette for the terminal.&lt;/p&gt;
    &lt;p&gt;A mine sweeping game written in Rust&lt;/p&gt;
    &lt;p&gt;Oatmeal is a terminal UI chat application that speaks with LLMs, complete with slash commands and fancy chat bubbles. It features agnostic backends to allow switching between the powerhouse of ChatGPT, or keeping things private with Ollama. While Oatmeal works great as a stand alone terminal application, it works even better paired with an editor like Neovim!&lt;/p&gt;
    &lt;p&gt;oha is a tiny program that sends some load to a web application and show realtime tui&lt;/p&gt;
    &lt;p&gt;A simple TUI to view &amp;amp; control docker containers&lt;/p&gt;
    &lt;p&gt;Unlock the power of APIs with simplicity and speed, right from your terminal. View OpenAPI documentations in your terminal.&lt;/p&gt;
    &lt;p&gt;A lightweight and terminal-based tool for interacting with databases.&lt;/p&gt;
    &lt;p&gt;An application to manage markdown notes from your terminal and compile them to HTML&lt;/p&gt;
    &lt;p&gt;A simple oscilloscope/vectorscope/spectroscope for your terminal&lt;/p&gt;
    &lt;p&gt;Terminal HTTP/REST client&lt;/p&gt;
    &lt;p&gt;A CLI-based AI coding agent for local dev, scripts/CI, and automation.&lt;/p&gt;
    &lt;p&gt;A terminal user interface for taskwarrior&lt;/p&gt;
    &lt;p&gt;Television is a fast and versatile fuzzy finder TUI.&lt;/p&gt;
    &lt;p&gt;It lets you quickly search through any kind of data source (files, git repositories, environment variables, docker images, you name it) using a fuzzy matching algorithm and is designed to be easily extensible.&lt;/p&gt;
    &lt;p&gt;A network diagnostic tool that combines the functionality of traceroute and ping and is designed to assist with the analysis of networking issues.&lt;/p&gt;
    &lt;p&gt;A hackable, minimal, fast TUI file explorer&lt;/p&gt;
    &lt;p&gt;Blazing fast terminal file manager written in Rust, based on async I/O&lt;/p&gt;
    &lt;p&gt;Y≈çzefu is an interactive TUI application for exploring data of a Kafka cluster.&lt;/p&gt;
    &lt;p&gt;It is an alternative tool to AKHQ, Redpanda Console, or the Kafka plugin for JetBrains IDEs. It includes a search query language inspired by SQL, providing fine-grained filtering capabilities.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45830829</guid><pubDate>Thu, 06 Nov 2025 02:50:31 +0000</pubDate></item><item><title>Show HN: Flutter_compositions: Vue-inspired reactive building blocks for Flutter</title><link>https://github.com/yoyo930021/flutter_compositions</link><description>&lt;doc fingerprint="b6504001f19ee361"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;Vue-inspired reactive building blocks for Flutter&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Flutter Compositions brings Vue 3's Composition API patterns to Flutter, enabling fine-grained reactivity and composable logic with a clean, declarative API.&lt;/p&gt;
    &lt;p&gt;üìö Read the full documentation ‚Üí&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Getting Started - Quick start guide and installation&lt;/item&gt;
      &lt;item&gt;Guide - Learn core concepts and patterns&lt;/item&gt;
      &lt;item&gt;API Reference - Complete API documentation&lt;/item&gt;
      &lt;item&gt;Internals - Architecture and design decisions&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This repository uses a Melos-managed monorepo layout:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Package&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Version&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;flutter_compositions&lt;/cell&gt;
        &lt;cell&gt;Core reactive composition primitives for Flutter&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;flutter_compositions_lints&lt;/cell&gt;
        &lt;cell&gt;Custom lint rules to enforce best practices&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;import 'package:flutter/material.dart';
import 'package:flutter_compositions/flutter_compositions.dart';

class CounterPage extends CompositionWidget {
  const CounterPage({super.key});

  @override
  Widget Function(BuildContext) setup() {
    // Reactive state
    final count = ref(0);
    final doubled = computed(() =&amp;gt; count.value * 2);

    // Side effects
    watch(() =&amp;gt; count.value, (value, previous) {
      debugPrint('count: $previous ‚Üí $value');
    });

    // Return builder
    return (context) =&amp;gt; Scaffold(
          appBar: AppBar(title: const Text('Counter')),
          body: Center(
            child: Column(
              mainAxisSize: MainAxisSize.min,
              children: [
                Text('Count: ${count.value}'),
                Text('Doubled: ${doubled.value}'),
              ],
            ),
          ),
          floatingActionButton: FloatingActionButton(
            onPressed: () =&amp;gt; count.value++,
            child: const Icon(Icons.add),
          ),
        );
  }
}&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Vue-inspired API - Familiar &lt;code&gt;ref&lt;/code&gt;,&lt;code&gt;computed&lt;/code&gt;,&lt;code&gt;watch&lt;/code&gt;, and&lt;code&gt;watchEffect&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Fine-grained reactivity - Powered by &lt;code&gt;alien_signals&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Composable logic - Extract and reuse stateful logic with custom composables&lt;/item&gt;
      &lt;item&gt;Type-safe DI - &lt;code&gt;provide&lt;/code&gt;/&lt;code&gt;inject&lt;/code&gt;with&lt;code&gt;InjectionKey&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Built-in composables - Controllers, animations, async data, and more&lt;/item&gt;
      &lt;item&gt;Zero boilerplate - Single &lt;code&gt;setup()&lt;/code&gt;function replaces multiple lifecycle methods&lt;/item&gt;
      &lt;item&gt;Lint rules - Custom lints enforce best practices&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is a Melos monorepo. To get started:&lt;/p&gt;
    &lt;code&gt;# Install Melos
flutter pub global activate melos

# Bootstrap the workspace
melos bootstrap

# Run tests across all packages
melos run test

# Run analysis
melos run analyze&lt;/code&gt;
    &lt;code&gt;cd packages/flutter_compositions/example
flutter run&lt;/code&gt;
    &lt;p&gt;Contributions are welcome! Please feel free to submit a Pull Request.&lt;/p&gt;
    &lt;p&gt;Flutter Compositions is built upon excellent work from the open source community:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;alien_signals - Provides the core reactivity system with fine-grained signal-based state management&lt;/item&gt;
      &lt;item&gt;flutter_hooks - Inspired composable patterns and demonstrated the viability of composition APIs in Flutter&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We are grateful to these projects and their maintainers for paving the way.&lt;/p&gt;
    &lt;p&gt;MIT ¬© 2025&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45832198</guid><pubDate>Thu, 06 Nov 2025 06:43:00 +0000</pubDate></item><item><title>How I am deeply integrating Emacs</title><link>https://joshblais.com/blog/how-i-am-deeply-integrating-emacs/</link><description>&lt;doc fingerprint="ae125933290192bc"&gt;
  &lt;main&gt;
    &lt;p&gt;Emacs has holistically become my daily computing environment.&lt;/p&gt;
    &lt;p&gt;My efforts have been focused on building emacs into the workflow of essentially everything I do, as long as it doesn‚Äôt involve heavy video or media, I try my very best to accomplish it in emacs. The idea is to achieve deep integration with everything I do on a computer, to the degree my thoughts are immediately able to be acted upon in the buffer.&lt;/p&gt;
    &lt;p&gt;I use hyprland as my window manager, and while I have heard of other managers/DEs (I was using GNOME for the better part of 6 months), I keep coming back to hyprland just because it works and is easy to configure. Also, for some reason, I seem not to have lagging in emacs on wayland in hyprland, while I had to previously run emacs in X11 mode in GNOME, go figure.&lt;/p&gt;
    &lt;head rend="h2"&gt;My Motivation#&lt;/head&gt;
    &lt;p&gt;I have seen what people are capable of doing when their tools get out of the way, and they are free to just create. This is how world class athletes, musicians, artists, writers, and of course programmers take what is in their mind and translate it into reality. The idea is that if I can learn this ‚Äúeditor of a lifetime‚Äù - then the things that I want to create, the programs I want to write, will be achieved in a near frictionless environment, allowing for velocity that is not possible elsewhere. It is the ultimate sharpening of the axe before chopping the tree.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why not EXWM?#&lt;/head&gt;
    &lt;p&gt;I have considered using EXWM as the window manager (quite literally offloading window management to emacs, and ‚Äúliving in emacs‚Äù - to more of a degree than I do already), the hesitation I have is that:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Emacs is single threaded, therefore if anything in the system hangs, the whole system hangs, and&lt;/item&gt;
      &lt;item&gt;It is only X11 where most of the development and forward movement in the linux space has been in wayland. While I understand this is not a tremendous issue, wayland does seem to be where the puck is going.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So, what I am aiming to do is replicate functionality as best as I can from EXWM to a wayland environment - not wholly possible, but also not wholly impossible, either.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Emacs Launcher program#&lt;/head&gt;
    &lt;p&gt;If you look at my dotfiles, you can see I have a script written in Go that allows me to call each and every one of my emacs controls anywhere is my system. I was previously calling each of these emacs commands in bash and with a sleep command so as to make sure I was targeting the emacs instance. No longer. This Go script has sped up my workflow by 10x.&lt;/p&gt;
    &lt;head rend="h2"&gt;My Current setup#&lt;/head&gt;
    &lt;head rend="h3"&gt;How I Launch Emacs#&lt;/head&gt;
    &lt;p&gt;
      &lt;code&gt;bind = $mainMod SHIFT, E, exec, bash -c "emacs"&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;I almost never press this keybind, as emacs is opened from the get-go in my hyprland sessions. For that rare time I need to re-open it.&lt;/p&gt;
    &lt;head rend="h3"&gt;Opening vterm as my default terminal#&lt;/head&gt;
    &lt;p&gt;
      &lt;code&gt;bind = $mainMod, E, exec, emacsclient -n -e '(my/new-frame-with-vterm)'&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;This permits me to quickly open a vterm window and enter commands etc. If I need anything that is more graphically intense, I fallback to kitty terminal, but this is less and less these days.&lt;/p&gt;
    &lt;head rend="h4"&gt;Opening vterm in my emacs session quickly for in projects is done like so:#&lt;/head&gt;
    &lt;p&gt;
      &lt;code&gt;bind = $mainMod, RETURN, exec, ~/.config/hypr/scripts/emacs-launcher '(my-open-vterm-at-point)'&lt;/code&gt;
    &lt;/p&gt;
    &lt;head rend="h3"&gt;Universal Launcher#&lt;/head&gt;
    &lt;p&gt;
      &lt;code&gt;bind = $mainMod, SPACE, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (universal-launcher-popup))'&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;I wanted to replicate a launcher (similar to wofi/rofi) in which I could easily launch apps and switch to them in the environment.&lt;/p&gt;
    &lt;p&gt;So, my take on this is to replace wofi with this functionality. I was using ssh providers in GNOME, but then brought the functionality into my universal launcher. It has effectively grown to encapsulate:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Passwords&lt;/item&gt;
      &lt;item&gt;SSH&lt;/item&gt;
      &lt;item&gt;Bookmarking&lt;/item&gt;
      &lt;item&gt;Commands and program launching&lt;/item&gt;
      &lt;item&gt;Emojis&lt;/item&gt;
      &lt;item&gt;TODOS (though org-agenda/calendar also handles this)&lt;/item&gt;
      &lt;item&gt;File navigation&lt;/item&gt;
      &lt;item&gt;Web and documentation search&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;While this is a work in progress, I use it every day, hundreds of times a day, and love the flow &amp;amp; speed my launcher allows.&lt;/p&gt;
    &lt;head rend="h3"&gt;Capture to org mode#&lt;/head&gt;
    &lt;p&gt;
      &lt;code&gt;bind = CTRL SHIFT, c, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (org-capture))'&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;When I am not ‚Äúin‚Äù emacs (I am always in emacs by extension) I can still capture direct to emacs with a quick keybind.&lt;/p&gt;
    &lt;p&gt;I capture to my org directory:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;notes&lt;/item&gt;
      &lt;item&gt;bookmarks&lt;/item&gt;
      &lt;item&gt;contacts&lt;/item&gt;
      &lt;item&gt;inbox (todos)&lt;/item&gt;
      &lt;item&gt;events/deadlines&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is very useful when I am wanting to save a thought, idea, bookmark, quote, what have you, and then integrate it with my org-roam file structure.&lt;/p&gt;
    &lt;head rend="h3"&gt;Notes#&lt;/head&gt;
    &lt;p&gt;
      &lt;code&gt;bind = $mainMod CTRL, N, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (find-file "~/org/notes.org"))'&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;I can navigate to my notes file very quickly to write emails, keep notes on stuff, and then translate those into my org-roam directory, too.&lt;/p&gt;
    &lt;head rend="h3"&gt;Calendar/Org Agenda#&lt;/head&gt;
    &lt;p&gt;
      &lt;code&gt;bind = $mainMod, C, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (=calendar))'&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;bind = $mainMod, N, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (my/org-agenda-dashboard))'&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;Quick access to my agenda and calendar from anywhere.&lt;/p&gt;
    &lt;head rend="h3"&gt;Password manager#&lt;/head&gt;
    &lt;p&gt;
      &lt;code&gt;bind = $mainMod, P, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (pass))'&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;Password-store inside emacs to create, update, grab passwords and insert them on page in browsers.&lt;/p&gt;
    &lt;head rend="h3"&gt;File Browsing#&lt;/head&gt;
    &lt;p&gt;
      &lt;code&gt;bind = $mainMod, F, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (dirvish))'&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;I use dirvish/dired for nearly all my file browsing and manipulation. I have some binds that allow me to pull up thunar for graphical drag-drop operations, but other than that files are dealt with inside emacs.&lt;/p&gt;
    &lt;p&gt;The killer feature is that you can edit files as you would edit text, nothing else comes close.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bookmarks#&lt;/head&gt;
    &lt;p&gt;
      &lt;code&gt;bind = $mainMod, B, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (find-file "~/org/bookmarks.org"))'&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;Bookmarking within emacs allows me to keep all sites top of mind.&lt;/p&gt;
    &lt;head rend="h3"&gt;Email#&lt;/head&gt;
    &lt;p&gt;
      &lt;code&gt;bind = $mainMod, M, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (=mu4e))'&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;The greatest email client.&lt;/p&gt;
    &lt;head rend="h3"&gt;Feed reader#&lt;/head&gt;
    &lt;p&gt;
      &lt;code&gt;bind = $mainMod CTRL, Z, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (elfeed))'&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;Reading any feed from around the web, I follow youtube, blogs, news, etc. here - never going out to the web to read anything.&lt;/p&gt;
    &lt;head rend="h3"&gt;Music playing#&lt;/head&gt;
    &lt;p&gt;
      &lt;code&gt;bind = $mainMod CONTROL, M, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (emms-playlist-mode-go))'&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;You thought I wouldn‚Äôt play music in emacs?&lt;/p&gt;
    &lt;head rend="h3"&gt;Emacs everywhere for editing text anywhere#&lt;/head&gt;
    &lt;p&gt;
      &lt;code&gt;bind = $mainMod CONTROL, E, exec, emacsclient --eval '(thanos/type)'&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;When you are in a text box on any site, you can just edit the text in emacs, press &lt;code&gt;C-c C-c&lt;/code&gt; and have it pasted right there for you.&lt;/p&gt;
    &lt;head rend="h2"&gt;Will I use EXWM?#&lt;/head&gt;
    &lt;p&gt;I think that because I spend so much time inside emacs, I don‚Äôt really get the benefits of everything being a buffer. I only use a browser for projects, not as a window I have always open, and I don‚Äôt really need emacs to control buffers or give me the keybinds universally. I will never say never though, perhaps one day it will be my window manager of choice.&lt;/p&gt;
    &lt;p&gt;How are you integrating emacs in your workflow? I would be super interested to see other setups that allow you to use emacs as your one, true, holistic computing environment. Shoot me an email and tell me how it‚Äôs done!&lt;/p&gt;
    &lt;p&gt;Edit: this post has some interesting discussion on HackerNews, I will make a video about the workflow today.&lt;/p&gt;
    &lt;p&gt;As always, God bless, and until next time.&lt;/p&gt;
    &lt;p&gt;If you enjoyed this post, consider supporting my work by Buying me a Coffee, Checking out my book, or sending me an email to tell me what you think.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45832341</guid><pubDate>Thu, 06 Nov 2025 07:09:07 +0000</pubDate></item><item><title>Mathematical exploration and discovery at scale</title><link>https://terrytao.wordpress.com/2025/11/05/mathematical-exploration-and-discovery-at-scale/</link><description>&lt;doc fingerprint="a3799b4924933df3"&gt;
  &lt;main&gt;
    &lt;p&gt;Bogdan Georgiev, Javier G√≥mez-Serrano, Adam Zsolt Wagner, and I have uploaded to the arXiv our paper ‚ÄúMathematical exploration and discovery at scale‚Äú. This is a longer report on the experiments we did in collaboration with Google Deepmind with their AlphaEvolve tool, which is in the process of being made available for broader use. Some of our experiments were already reported on in a previous white paper, but the current paper provides more details, as well as a link to a repository with various relevant data such as the prompts used and the evolution of the tool outputs.&lt;/p&gt;
    &lt;p&gt;AlphaEvolve is a variant of more traditional optimization tools that are designed to extremize some given score function over a high-dimensional space of possible inputs. A traditional optimization algorithm might evolve one or more trial inputs over time by various methods, such as stochastic gradient descent, that are intended to locate increasingly good solutions while trying to avoid getting stuck at local extrema. By contrast, AlphaEvolve does not evolve the score function inputs directly, but uses an LLM to evolve computer code (often written in a standard language such as Python) which will in turn be run to generate the inputs that one tests the score function on. This reflects the belief that in many cases, the extremizing inputs will not simply be an arbitrary-looking string of numbers, but will often have some structure that can be efficiently described, or at least approximated, by a relatively short piece of code. The tool then works with a population of relatively successful such pieces of code, with the code from one generation of the population being modified and combined by the LLM based on their performance to produce the next generation. The stochastic nature of the LLM can actually work in one‚Äôs favor in such an evolutionary environment: many ‚Äúhallucinations‚Äù will simply end up being pruned out of the pool of solutions being evolved due to poor performance, but a small number of such mutations can add enough diversity to the pool that one can break out of local extrema and discover new classes of viable solutions. The LLM can also accept user-supplied ‚Äúhints‚Äù as part of the context of the prompt; in some cases, even just uploading PDFs of relevant literature has led to improved performance by the tool. Since the initial release of AlphaEvolve, similar tools have been developed by others, including OpenEvolve, ShinkaEvolve and DeepEvolve.&lt;/p&gt;
    &lt;p&gt;We tested this tool on a large number (67) of different mathematics problems (both solved and unsolved) in analysis, combinatorics, and geometry that we gathered from the literature, and reported our outcomes (both positive and negative) in this paper. In many cases, AlphaEvolve achieves similar results to what an expert user of a traditional optimization software tool might accomplish, for instance in finding more efficient schemes for packing geometric shapes, or locating better candidate functions for some calculus of variations problem, than what was previously known in the literature. But one advantage this tool seems to offer over such custom tools is that of scale, particularly when when studying variants of a problem that we had already tested this tool on, as many of the prompts and verification tools used for one problem could be adapted to also attack similar problems; several examples of this will be discussed below.&lt;/p&gt;
    &lt;p&gt;Another advantage of AlphaEvolve was robustness: it was relatively easy to set up AlphaEvolve to work on a broad array of problems, without extensive need to call on domain knowledge of the specific task in order to tune hyperparameters. In some cases, we found that making such hyperparameters part of the data that AlphaEvolve was prompted to output was better than trying to work out their value in advance, although a small amount of such initial theoretical analysis was helpful. For instance, in calculus of variation problems, one is often faced with the need to specify various discretization parameters in order to estimate a continuous integral, which cannot be computed exactly, by a discretized sum (such as a Riemann sum), which can be evaluated by computer to some desired precision. We found that simply asking AlphaEvolve to specify its own discretization parameters worked quite well (provided we designed the score function to be conservative with regards to the possible impact of the discretization error); see for instance this experiment in locating the best constant in functional inequalities such as the Hausdorff-Young inequality.&lt;/p&gt;
    &lt;p&gt;A third advantage of AlphaEvolve over traditional optimization methods was the interpretability of many of the solutions provided. For instance, in one of our experiments we sought to find an extremum to a functional inequality such as the Gagliardo‚ÄìNirenberg inequality (a variant of the Sobolev inequality). This is a relatively well-behaved optimization problem, and many standard methods can be deployed to obtain near-optimizers that are presented in some numerical format, such as a vector of values on some discretized mesh of the domain. However, when we applied AlphaEvolve to this problem, the tool was able to discover the exact solution (in this case, a Talenti function), and create code that sampled from that function on a discretized mesh to provide the required input for the scoring function we provided (which only accepted discretized inputs, due to the need to compute the score numerically). This code could be inspected by humans to gain more insight as to the nature of the optimizer. (Though in some cases, AlphaEvolve‚Äôs code would contain some brute force search, or a call to some existing optimization subroutine in one of the libraries it was given access to, instead of any more elegant description of its output.)&lt;/p&gt;
    &lt;p&gt;For problems that were sufficiently well-known to be in the training data of the LLM, the LLM component of AlphaEvolve often came up almost immediately with optimal (or near-optimal) solutions. For instance, for variational problems where the gaussian was known to be the extremizer, AlphaEvolve would frequently guess a gaussian candidate during one of the early evolutions, and we would have to obfuscate the problem significantly to try to conceal the connection to the literature in order for AlphaEvolve to experiment with other candidates. AlphaEvolve would also propose similar guesses for other problems for which the extremizer was not known. For instance, we tested this tool on the sum-difference exponents of relevance to the arithmetic Kakeya conjecture, which can be formulated as a variational entropy inequality concerning certain two-dimensional discrete random variables. AlphaEvolve initially proposed some candidates for such variables based on discrete gaussians, which actually worked rather well even if they were not the exact extremizer, and already generated some slight improvements to previous lower bounds on such exponents in the literature. Inspired by this, I was later able to rigorously obtain some theoretical results on the asymptotic behavior on such exponents in the regime where the number of slopes was fixed, but the ‚Äúrational complexity‚Äù of the slopes went to infinity; this will be reported on in a separate paper.&lt;/p&gt;
    &lt;p&gt;Perhaps unsurprisingly, AlphaEvolve was extremely good at locating ‚Äúexploits‚Äù in the verification code we provided, for instance using degenerate solutions or overly forgiving scoring of approximate solutions to come up with proposed inputs that technically achieved a high score under our provided code, but were not in the spirit of the actual problem. For instance, when we asked it (link under construction) to find configurations to extremal geometry problems such as locating polygons with each vertex having four equidistant other vertices, we initially coded the verifier to accept distances that were equal only up to some high numerical precision, at which point AlphaEvolve promptly placed many of the points in virtually the same location so that the distances they determined were indistinguishable. Because of this, a non-trivial amount of human effort needs to go into designing a non-exploitable verifier, for instance by working with exact arithmetic (or interval arithmetic) instead of floating point arithmetic, and taking conservative worst-case bounds in the presence of uncertanties in measurement to determine the score. For instance, in testing AlphaEvolve against the ‚Äúmoving sofa‚Äù problem and its variants, we designed a conservative scoring function that only counted those portions of the sofa that we could definitively prove to stay inside the corridor at all times (not merely the discrete set of times provided by AlphaEvolve to describe the sofa trajectory) to prevent it from exploiting ‚Äúclipping‚Äù type artefacts. Once we did so, it performed quite well, for instance rediscovering the optimal ‚ÄúGerver sofa‚Äù for the original sofa problem, and also discovering new sofa designs for other problem variants, such as a 3D sofa problem.&lt;/p&gt;
    &lt;p&gt;For well-known open conjectures (e.g., Sidorenko‚Äôs conjecture, Sendov‚Äôs conjecture, Crouzeix‚Äôs conjecture, the ovals problem, etc.), AlphaEvolve generally was able to locate the previously known candidates for optimizers (that are conjectured to be optimal), but did not locate any stronger counterexamples: thus, we did not disprove any major open conjecture. Of course, one obvious possible explanation for this is that these conjectures are in fact true; outside of a few situations where there is a matching ‚Äúdual‚Äù optimization problem, AlphaEvolve can only provide one-sided bounds on such problems and so cannot definitively determine if the conjectural optimizers are in fact the true optimizers. Another potential explanation is that AlphaEvolve essentially tried all the ‚Äúobvious‚Äù constructions that previous researchers working on these problems had also privately experimented with, but did not report due to the negative findings. However, I think there is at least value in using these tools to systematically record negative results (roughly speaking, that a search for ‚Äúobvious‚Äù counterexamples to a conjecture did not disprove the claim), which currently only exist as ‚Äúfolklore‚Äù results at best. This seems analogous to the role LLM Deep Research tools could play by systematically recording the results (both positive and negative) of automated literature searches, as a supplement to human literature review which usually reports positive results only. Furthermore, when we shifted attention to less well studied variants of famous conjectures, we were able to find some modest new observations. For instance, while AlphaEvolve only found the standard conjectural extremizer to Sendov‚Äôs conjecture, as well as for variants such as Borcea‚Äôs conjecture, Schmeisser‚Äôs conjecture, or Smale‚Äôs conjecture it did reveal some potential two-parameter extensions to a conjecture of de Bruin and Sharma that had not previously been stated in the literature. (For this problem, we were not directly optimizing some variational scalar quantity, but rather a two-dimensional range of possible values, which we could adapt the AlphaEvolve framework to treat). In the future, I can imagine such tools being a useful ‚Äúsanity check‚Äù when proposing any new conjecture, in that it will become common practice to run one of these tools against such a conjecture to make sure there are no ‚Äúobvious‚Äù counterexamples (while keeping in mind that this is still far from conclusive evidence in favor of such a conjecture).&lt;/p&gt;
    &lt;p&gt;AlphaEvolve did not perform equally well across different areas of mathematics. When testing the tool on analytic number theory problems, such as that of designing sieve weights for elementary approximations to the prime number theorem, it struggled to take advantage of the number theoretic structure in the problem, even when given suitable expert hints (although such hints have proven useful for other problems). This could potentially be a prompting issue on our end, or perhaps the landscape of number-theoretic optimization problems is less amenable to this sort of LLM-based evolutionary approach. On the other hand, AlphaEvolve does seem to do well when the constructions have some algebraic structure, such as with the finite field Kakeya and Nikodym set problems, which we will turn to shortly.&lt;/p&gt;
    &lt;p&gt;For many of our experiments we worked with fixed-dimensional problems, such as trying to optimally pack shapes in a larger shape for a fixed value of . However, we found in some cases that if we asked AlphaEvolve to give code that took parameters such as as input, and tested the output of that code for a suitably sampled set of values of of various sizes, then it could sometimes generalize the constructions it found for small values of this parameter to larger ones; for instance, in the infamous sixth problem of this year‚Äôs IMO, it could use this technique to discover the optimal arrangement of tiles, which none of the frontier models could do at the time (although AlphaEvolve has no capability to demonstrate that this arrangement was, in fact, optimal). Another productive use case of this technique was for finding finite field Kakeya and Nikodym sets of small size in low-dimensional vector spaces over finite fields of various sizes. For Kakeya sets in , it located the known optimal construction based on quadratic residues in two dimensions, and very slightly beat (by an error term of size ) the best construction in three dimensions; this was an algebraic construction (still involving quadratic residues) discovered empirically that we could then prove to be correct by first using Gemini‚Äôs ‚ÄúDeep Think‚Äù tool to locate an informal proof, which we could then convert into a formalized Lean proof by using Google Deepmind‚Äôs ‚ÄúAlphaProof‚Äù tool. At one point we thought it had found a construction in four dimensions which achieved a more noticeable improvement (of order ) of what we thought was the best known construction, but we subsequently discovered that essentially the same construction had appeared already in a paper of Bukh and Chao, although it still led to a more precise calculation of the error term (to accuracy rather than , where the error term now involves the Lang-Weil inequality and is unlikely to have a closed form). Perhaps AlphaEvolve had somehow absorbed the Bukh-Chao construction within its training data to accomplish this. However, when we tested the tool on Nikodym sets (which are expected to have asymptotic density , although this remains unproven), it did find some genuinely new constructions of such sets in three dimensions, based on removing quadratic varieties from the entire space. After using ‚ÄúDeep Think‚Äù again to analyze these constructions, we found that they were inferior to a purely random construction (which in retrospect was an obvious thing to try); however, they did inspire a hybrid construction in which one removed random quadratic varieties and performed some additional cleanup, which ends up outperforming both the purely algebraic and purely random constructions. This result (with completely human-generated proofs) will appear in a subsequent paper.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45833162</guid><pubDate>Thu, 06 Nov 2025 09:24:42 +0000</pubDate></item><item><title>The trust collapse: Infinite AI content is awful</title><link>https://arnon.dk/the-trust-collapse-infinite-ai-content-is-awful/</link><description>&lt;doc fingerprint="87459213b9636f27"&gt;
  &lt;main&gt;
    &lt;p&gt;We‚Äôre living through the weirdest moment in human history.&lt;/p&gt;
    &lt;p&gt;For the first time since, well, ever, the cost of creating content has dropped to essentially zero. Not ‚Äúcheaper than before‚Äù, but like actually free.&lt;/p&gt;
    &lt;p&gt;It‚Äôs so easy to generate a thousand blog posts or ten thousand ‚Äú‚Äù‚Äùpersonalized‚Äù‚Äù‚Äù emails and it barely costs you anything (for now).&lt;/p&gt;
    &lt;p&gt;In theory this sounds great, infinite content. Giving words to those who struggled before.&lt;/p&gt;
    &lt;p&gt;So many opportunities.&lt;/p&gt;
    &lt;p&gt;But if you‚Äôre trying to sell, trust is collapsing faster than content is proliferating.&lt;/p&gt;
    &lt;p&gt;And I don‚Äôt mean ‚Äútrust‚Äù in some abstract sense, but the real ‚Äì who‚Äôs real, who‚Äôs credible, and what should I be paying attention to?&lt;/p&gt;
    &lt;p&gt;We‚Äôre not moving forward. We‚Äôre definitely moving backwards.&lt;/p&gt;
    &lt;head rend="h3"&gt;A tale of a B2B SaaS company&lt;/head&gt;
    &lt;p&gt;I know someone who runs a B2B SaaS company‚Äôs sales ‚Äì he‚Äôs very smart. He spent many many years building his network and being a ‚Äúrelationship builder‚Äù type of seller ‚Äì earning trust the old-fashioned way.&lt;/p&gt;
    &lt;p&gt;When we spoke last Sunday, he told me ‚ÄúI ignore all email outreach, and I barely even pick up the phone if I don‚Äôt know who it is‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúI can‚Äôt tell if it‚Äôs a real person or someone who‚Äôs scraped my details. I used to be able to tell. Now I can‚Äôt. So I just‚Ä¶ don‚Äôt engage. Not worth my time.‚Äù&lt;/p&gt;
    &lt;p&gt;To dumb it down for you if you‚Äôre doing this outbound ‚Äì he‚Äôs not asking ‚Äúdo I need this product?‚Äù that you‚Äôre selling, but he‚Äôs asking ‚Äúwhy should I trust you specifically to deliver it?‚Äù ‚Äì and you‚Äôre not getting through with that.&lt;/p&gt;
    &lt;head rend="h3"&gt;Marketing funnel? Nah. Meet the trust funnel&lt;/head&gt;
    &lt;p&gt;If being in marketing has taught me something, is that the ‚Äúrules‚Äù and ‚Äúplaybooks‚Äù optimize for the wrong question ‚Äì we craft positioning that explains what we do and why it matters.&lt;/p&gt;
    &lt;p&gt;In many cases, your prospect already knows they need what you‚Äôre selling.&lt;/p&gt;
    &lt;p&gt;They don‚Äôt need another pitch deck explaining why AI coding assistants increase developer productivity or why they can send more e-mails with an AI SDR.&lt;/p&gt;
    &lt;p&gt;They‚Äôve seen forty of those this month (can we talk about how many AI SDRs there are????)&lt;/p&gt;
    &lt;p&gt;Honestly, this hurts saying too, but they don‚Äôt need proof that outcome-based pricing aligns incentives better than seat licenses. They read one of my 40 articles on the topic already.&lt;/p&gt;
    &lt;p&gt;What they actually want to know is ‚Äúwhy the hell would I buy it from you instead of the other hundred companies spamming my inbox with identical claims?‚Äù&lt;/p&gt;
    &lt;p&gt;And because everything is AI slop now, answering that question became harder for them.&lt;/p&gt;
    &lt;p&gt;If you haven‚Äôt heard already, here are the differences between a marketing funnel and a trust funnel:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Aspect&lt;/cell&gt;
        &lt;cell role="head"&gt;Marketing funnel&lt;/cell&gt;
        &lt;cell role="head"&gt;Trust funnel&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Main Focus&lt;/cell&gt;
        &lt;cell&gt;Lead generation and conversions&lt;/cell&gt;
        &lt;cell&gt;Relationship building and customer loyalty&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;End Point&lt;/cell&gt;
        &lt;cell&gt;Purchase or conversion&lt;/cell&gt;
        &lt;cell&gt;Ongoing customer advocacy and retention&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Content Strategy&lt;/cell&gt;
        &lt;cell&gt;Promotional, sales-focused&lt;/cell&gt;
        &lt;cell&gt;Helpful, customer-focused, value-driven&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Success Metrics&lt;/cell&gt;
        &lt;cell&gt;Conversion rates, sales numbers&lt;/cell&gt;
        &lt;cell&gt;Satisfaction, repeat business, advocacy&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Timeline&lt;/cell&gt;
        &lt;cell&gt;Short to medium-term&lt;/cell&gt;
        &lt;cell&gt;Long-term, compounding trust&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;It‚Äôs clear that you need to be on that trust side!&lt;/p&gt;
    &lt;head rend="h3"&gt;With normal marketing funnels, lead generation sucks now&lt;/head&gt;
    &lt;p&gt;It‚Äôs simply too boring.&lt;/p&gt;
    &lt;p&gt;When a Claude license is like, $10 a month ‚Äì content creation costs are effectively zero. Now everyone can afford to look credible. Perfect grammar. Personalized outreach that references your LinkedIn posts (albeit badly).&lt;/p&gt;
    &lt;p&gt;All of it can be generated in minutes, with no human intervention.&lt;/p&gt;
    &lt;p&gt;Which means all of it is now suspect.&lt;/p&gt;
    &lt;p&gt;I now send all e-mail AND LinkedIn messages to the trash.&lt;/p&gt;
    &lt;p&gt;Why? Because I can actually tell they didn‚Äôt come from humans who care about me or my problem.&lt;/p&gt;
    &lt;p&gt;They‚Äôre all ‚Äúvaguely‚Äù personalized, and they‚Äôre all ‚Äúcurious‚Äù about how I do something. Why? Because ‚ÄúI‚Äôm curious about‚Ä¶‚Äù is in a playbook that supposedly gets good responses.&lt;/p&gt;
    &lt;p&gt;This is the trust collapse for me: it‚Äôs not that I don‚Äôt believe your product works. I don‚Äôt believe you‚Äôre a real human who will still care after you sign the contract.&lt;/p&gt;
    &lt;head rend="h3"&gt;Rates are down, I‚Äôll just send more messages&lt;/head&gt;
    &lt;p&gt;God, no. Stop.&lt;/p&gt;
    &lt;p&gt;That‚Äôs not the issue.&lt;/p&gt;
    &lt;p&gt;Old World (‚Ä¶-2024):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cost to produce credible, personalized outreach: $50/hour (human labor)&lt;/item&gt;
      &lt;item&gt;Volume of credible outreach a prospect receives: ~10/week&lt;/item&gt;
      &lt;item&gt;Prospect‚Äôs ability to evaluate authenticity: Pattern recognition works ~80% of time&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;New World (2025-‚Ä¶):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cost to produce credible, personalized outreach: effectively 0&lt;/item&gt;
      &lt;item&gt;Volume of credible outreach a prospect receives: ~200/week&lt;/item&gt;
      &lt;item&gt;Prospect‚Äôs ability to evaluate authenticity: Pattern recognition works ~20% of time&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The signal-to-noise ratio has hit a breaking point where the cost of verification exceeds the expected value of engagement.&lt;/p&gt;
    &lt;p&gt;So prospects don‚Äôt verify. They just assume everything is noise. This is why I (and my friend) ignore all outreach, and I‚Äôm far from alone.&lt;/p&gt;
    &lt;p&gt;The cognitive cost of determining ‚Äúis this real?‚Äù for 200 messages exceeds the expected benefit of the 2-3 that might actually be valuable.&lt;/p&gt;
    &lt;head rend="h3"&gt;Back to trust‚Ä¶&lt;/head&gt;
    &lt;p&gt;You have to understand ‚Äì your prospects aren‚Äôt asking:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚ÄúDoes your AI coding assistant work?‚Äù (They probably assume it does)&lt;/item&gt;
      &lt;item&gt;‚ÄúWill it actually improve {some metric}?‚Äù (They assume it will)&lt;/item&gt;
      &lt;item&gt;‚ÄúIs the pricing competitive?‚Äù (They can compare that in a spreadsheet)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;They‚Äôre asking:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚ÄúWill you still be here in 12 months when I‚Äôve integrated your tool into my workflow?‚Äù&lt;/item&gt;
      &lt;item&gt;‚ÄúWhy are you actually better or different from the 5 others I know of?‚Äù&lt;/item&gt;
      &lt;item&gt;‚ÄúAre you burning VC cash on unsustainable unit economics?‚Äù&lt;/item&gt;
      &lt;item&gt;‚ÄúWhen the music stops, will I be left holding a broken integration?‚Äù&lt;/item&gt;
      &lt;item&gt;‚ÄúHave you actually figured out how to make money, or are you just another vibe-revenue vibe-coded startup hoping to flip before the math catches up to your credit usage?‚Äù&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And here‚Äôs the problem: they can‚Äôt tell if you don‚Äôt tell them.&lt;/p&gt;
    &lt;head rend="h3"&gt;Not to be cynical, but‚Ä¶&lt;/head&gt;
    &lt;p&gt;I‚Äôm not writing this to be cynical, but because I want to make sure you play the right game.&lt;/p&gt;
    &lt;p&gt;Sure, you have to answer ‚Äúwhy should I buy this product category?‚Äù but also ‚Äúwhy should I buy it from you?‚Äù and your content and marketing has to match that.&lt;/p&gt;
    &lt;p&gt;Your opportunity is huge. Here is what we all must do:&lt;/p&gt;
    &lt;p&gt;Trust is still a human job: At least for now ‚Äì AI may help you along the way but at least in 2025 only humans can build genuine emotional connection and credibility. You need that lasting loyalty and advocacy. Don‚Äôt rely on the so-called ‚Äúpersonalized outbound‚Äù alone.&lt;/p&gt;
    &lt;p&gt;Yes, relevance and customization are critical: AI should help you segment prospects meticulously and flag when human follow-up is likely to deepen trust, not just automate at scale. Use the outbound engine to be real.&lt;/p&gt;
    &lt;p&gt;Again, keep a human involved: Too much automation can undermine trust. I expect at least some human engagement, especially in complex or high-value sales contexts.&lt;/p&gt;
    &lt;head rend="h4"&gt;Is this actually different now that we have AI?&lt;/head&gt;
    &lt;p&gt;Yes.&lt;/p&gt;
    &lt;p&gt;You‚Äôre representing a brand. And your brand must continuously earn that trust, even if you blend of AI-powered relevance. We still want that unmistakable human leadership.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45833496</guid><pubDate>Thu, 06 Nov 2025 10:12:04 +0000</pubDate></item><item><title>Eating Stinging Nettles</title><link>https://rachel.blog/2018/04/29/eating-stinging-nettles/</link><description>&lt;doc fingerprint="3730f7cb74e1c58"&gt;
  &lt;main&gt;
    &lt;p&gt;Spring is here and the nettles are growing again so I decided it was time to make a meal out of them. Most people know that stinging nettles are pesky green plants that irritate the skin when you touch them. What you probably don‚Äôt know is that they‚Äôre a nutritious source of iron, calcium, potassium, and silica as well as vitamins A, B, C, and K1. Stinging nettles also have anti-inflammatory properties and can relieve arthritis and rheumatism. They can be turned into soups, curries, and risottos (some recipes here) and you can get them completely free from practically everywhere in Britain over the summer. You‚Äôve likely even got some in your garden.&lt;/p&gt;
    &lt;p&gt;When you collect them you need to wear gloves because they sting. The advantage of this is it allows you to make sure you‚Äôre collecting the right thing. If you‚Äôre unsure, just touch one and see whether it hurts which is exactly what I did. It hurt.&lt;/p&gt;
    &lt;p&gt;The even look a bit scary with their toothy-edged leaves.&lt;/p&gt;
    &lt;p&gt;Once you‚Äôve got them inside, boil them in water for a few minutes and this will stop them stinging.&lt;/p&gt;
    &lt;p&gt;We‚Äôre having stinging nettle risotto.&lt;/p&gt;
    &lt;p&gt;People think that when you become vegan you have to give up lots of food. It‚Äôs true that I stopped eating animals but the number of different species I eat has grown considerably. This is because meat-eaters tend to eat the same few species of animals over and over again ‚Äì pigs, cows, chickens. Whereas there are some 20,000 species of edible plants in the world. Meat also tends to fill you up. Indeed I‚Äôve been to dinner with people where all they have on their plate is a slab of meat and nothing else. Whereas as a vegan (with the exception of a shitty Spanish restaurant that served me a plate of artichokes and nothing else) I eat a huge variety of species. Meat-eaters can eat these too but they often don‚Äôt because meat is so filling.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45834254</guid><pubDate>Thu, 06 Nov 2025 11:57:01 +0000</pubDate></item><item><title>AI Slop vs. OSS Security</title><link>https://devansh.bearblog.dev/ai-slop/</link><description>&lt;doc fingerprint="a60191118e23d432"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;On AI Slop vs OSS Security&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Disclosure: Certain sections of this content were grammatically refined/updated using AI assistance, as English is not my first language. Quite ironic, I know, given the subject being discussed.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Author's Note&lt;/head&gt;
    &lt;p&gt;I have now spent almost a decade in the bug bounty industry, started out as a bug hunter (who initially used to submit reports with minimal impact, low-hanging fruits like RXSS, SQLi, CSRF, etc.), then moved on to complex chains involving OAuth, SAML, parser bugs, supply chain security issues, etc., and then became a vulnerability triager for HackerOne, where I have triaged/reviewed thousands of vulnerability submissions. I have now almost developed an instinct that tells me if a report is BS or a valid security concern just by looking at it. I have been at HackerOne for the last 5 years (Nov 2020 - Present), currently as a team lead, overseeing technical services with a focus on triage operations.&lt;/p&gt;
    &lt;p&gt;One decade of working on both sides, first as a bug hunter, and then on the receiving side reviewing bug submissions, has given me a unique vantage point on how the industry is fracturing under the weight of AI-generated bug reports (sometimes valid submissions, but most of the time, the issues are just plain BS). I have seen cases where it was almost impossible to determine whether a report was a hallucination or a real finding. Even my instincts and a decade of experience failed me, and this is honestly frustrating, not so much for me, because as part of the triage team, it is not my responsibility to fix vulnerabilities, but I do sympathize with maintainers of OSS projects whose inboxes are drowning. Bug bounty platforms have already started taking this problem seriously, as more and more OSS projects are complaining about it.&lt;/p&gt;
    &lt;p&gt;This is my personal writing space, so naturally, these are my personal views and observations. These views might be a byproduct of my professional experience gained at HackerOne, but in no way are they representative of my employer. I am sure HackerOne, as an organization, has its own perspectives, strategies, and positions on these issues. My analysis here just reflects my own thinking about the systemic problems I see and potential solutions(?).&lt;/p&gt;
    &lt;head rend="h3"&gt;What Exactly is the Problem?&lt;/head&gt;
    &lt;p&gt;There are two kinds of AI-generated reports:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AI-generated valid reports&lt;/item&gt;
      &lt;item&gt;AI-generated non-valid reports&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I call the latter ‚ÄúAI slop‚Äù and the first one is still fine, in my opinion. As long as the security report being submitted is technically valid, falls within scope, and demonstrates impact, even if it is written by AI, it is still acceptable. I see both kinds of reports on a daily basis, and I would much rather see researchers use AI to structure their thoughts. But leaving the ‚Äúsecurity research‚Äù and validation of the report to AI is where I draw the line. If you can‚Äôt reproduce what you are reporting, and your finding is based on an assumption spit out by an LLM, that‚Äôs what I call AI slop, and that‚Äôs the problem I‚Äôll be discussing in this piece.&lt;/p&gt;
    &lt;p&gt;AI has infiltrated vulnerability reporting, and they mirror the social dynamics that plague any feedback system (be it mass swiping profiles on Hinge/tinder, or submitting mass job applications, or perhaps doing mass marketing/sales outreach)&lt;/p&gt;
    &lt;p&gt;A "security researcher" who just pastes LLM-generated output into a vulnerability submission form neither knows enough about the actual codebase being examined nor understands the security implications well enough to provide the insight that projects need. Each project has a different threat model. Something might be considered a valid vulnerability in Project A, but the behavior will be deemed acceptable in Project B. The AI doesn't know this difference, and it is very bad at understanding the threat-model context. It merely pattern-matches (like a regex, but not literally). It sees functions that look similar to vulnerable patterns and invents scenarios where they might be exploited, regardless of whether those scenarios are even possible in the actual implementation.&lt;/p&gt;
    &lt;p&gt;Some actors mass-submit AI-generated vulnerability reports, driven by incentives. The incentives are not always monetary, and sometimes take the form of a CVE. Industry has started treating CVEs as trophies. New-age startups are hunting for CVEs, as it looks nice to have them as a trophy, it gives them marketing, and is overall a good look for their startup and it's capabilities. I have no issues with the latter, as long as they are a net positive to the security space. We'll get to the CVE scene in a later section of this article. Coming to actors who mass-submit invalid AI-generated vulnerabilities (they feel productive and entrepreneurial?). Some genuinely believe their AI has found something real; others know it might not even be valid, but they submit it in the hopes maintainers will sort it out. The incentive ( + CVE) is to submit as many reports as possible and see what sticks, because even a 5% hit rate on a hundred submissions is better than the effort of manually verifying five findings.&lt;/p&gt;
    &lt;p&gt;As a result, Daniel Stenberg, who maintains curl, is now seeing about 20% of all security submissions as AI-generated slop. The rate of genuine vulnerabilities has dropped to approximately 5%. This ratio is borderline scary. For every real vulnerability, there are now four fake ones. And every fake one consumes hours of expert time to disprove.&lt;/p&gt;
    &lt;head rend="h3"&gt;Human Capital is Limited&lt;/head&gt;
    &lt;p&gt;HackerOne platform has many OSS projects in scope of various Bug Bounty programs. Imagine yourself as one of the maintainers of one such OSS program. A security report lands in your inbox. It claims there's a buffer overflow in a specific function. Just by looking at the report, its content, and impact statement, it looks like something worth investigating. The report is well-formatted, also includes CVE-style nomenclature, and uses appropriate technical language. As a responsible maintainer, you can't just dismiss it. You alert your security team‚Äîvolunteers, by the way, who have day jobs and families and maybe three hours a week for this work.&lt;/p&gt;
    &lt;p&gt;Three people read the report. One person even tries to reproduce the issue using the steps provided. They can't, because the steps reference test cases that don't exist. Another person examines the source code. The function mentioned in the report doesn't exist in that form. A third person checks whether there's any similar functionality that might be vulnerable in the way described. There isn't.&lt;/p&gt;
    &lt;p&gt;After an hour and a half of combined effort across three people, that's 4.5 person hours you just spent. You've confirmed what you suspected, this report is garbage. Probably AI-generated garbage, based on the telltale signs of hallucinated function names and impossible attack vectors.&lt;/p&gt;
    &lt;p&gt;You close the report. You don't get those hours back. And tomorrow, two more reports just like it will arrive.&lt;/p&gt;
    &lt;p&gt;The curl project has seven people on its security team. They collaborate on every submission, with three to four members typically engaging with each report. In early July 2025, they were receiving approximately two security reports per week. The math is brutal. If you have three hours per week to contribute to an open source project you love, and a single false report consumes all of it, you've contributed nothing that week except proving someone's AI hallucinated a vulnerability.&lt;/p&gt;
    &lt;p&gt;The emotional toll compounds exponentially. Stenberg describes it as "mind-numbing stupidities" that the team must process. It's not just frustration, it's the specific demoralization that comes from having your expertise and goodwill systematically exploited by people who couldn't be bothered to verify their submissions before wasting your time.&lt;/p&gt;
    &lt;head rend="h3"&gt;Burnout Burnout Burnout&lt;/head&gt;
    &lt;p&gt;According to Intel's annual open source community survey, 45% of respondents identified maintainer burnout as their top challenge. The Tidelift State of the Open Source Maintainer Survey is even more stark: 58% of maintainers have either quit their projects entirely (22%) or seriously considered quitting (36%).&lt;/p&gt;
    &lt;p&gt;Why exactly are they quitting? The top reason, cited by 54% of maintainers, is that other things in their life and work took priority over open source contributions. Over half (51%) reported losing interest in the work. And 44% explicitly identified experiencing burnout.&lt;/p&gt;
    &lt;p&gt;The percentage of maintainers who said they weren't getting paid enough to make maintenance work worthwhile rose from 32% to 38% between survey periods. These are people maintaining infrastructure that powers billions of dollars of commercial activity, and they're getting nothing. Or maybe they get $500 a year from GitHub Sponsors while companies make millions off their work.&lt;/p&gt;
    &lt;p&gt;The maintenance work itself is rarely rewarding. You're not building exciting new features. You're just addressing technical debt, responding to user demands, handling security issues, and now you have to sort through AI-generated garbage to find the occasional legitimate report as well.&lt;/p&gt;
    &lt;p&gt;When you're volunteering out of love in a market society, you're setting yourself up to be exploited.&lt;/p&gt;
    &lt;p&gt;And the exploitation is getting worse. Toxic communities, hyper-responsibility for critical infrastructure, and now the weaponization of AI to automate the creation of work for maintainers. This all is adding up to an unsustainable situation.&lt;/p&gt;
    &lt;p&gt;One Kubernetes contributor put it simply, "If your maintainers are burned out, they can't be protecting the code base like they're going to need to be." This shifts maintainer wellbeing from a human resources problem into a security imperative. Burned-out maintainers miss things. They make mistakes. They eventually quit, leaving projects unmaintained or understaffed. Which eventually affects security of these projects.&lt;/p&gt;
    &lt;head rend="h3"&gt;What AI Slop Actually Looks Like&lt;/head&gt;
    &lt;p&gt;A typical AI slop report will reference function names that don't exist in the codebase. The AI has seen similar function names in its training data and invents plausible sounding variations. It will describe memory operations that would indeed be problematic if they existed as described, but which bear no relationship to how the code actually works.&lt;/p&gt;
    &lt;p&gt;One report to curl claimed an HTTP/3 vulnerability and included fake function calls and behaviors that appeared nowhere in the actual codebase. Stenberg has publicly shared a list of AI-generated security submissions received through HackerOne, and they all follow similar patterns, professional formatting, appropriate jargon, and completely fabricated technical details.&lt;/p&gt;
    &lt;p&gt;The sophistication varies. Some reports are obviously generated by someone who just pasted a repository URL into ChatGPT and asked it to find vulnerabilities. Others show more effort‚Äîthe submitter may have fed actual code snippets to the AI and then submitted its analysis without verification. Both are equally useless to maintainers, but the latter takes longer to disprove because the code snippets are real even if the vulnerability analysis is hallucinated.&lt;/p&gt;
    &lt;p&gt;Here's why language models fail so catastrophically at this task: they're designed to be helpful and provide positive responses. When you prompt an LLM to generate a vulnerability report, it will generate one regardless of whether a vulnerability exists. The model has no concept of truth‚Äîonly of plausibility. It assembles technical terminology into patterns that resemble security reports it has seen during training, but it cannot verify whether the specific claims it's making are accurate.&lt;/p&gt;
    &lt;p&gt;This is the fundamental problem: AI can generate the form of security research without the substance.&lt;/p&gt;
    &lt;head rend="h3"&gt;The CVE System is Also Collapsing&lt;/head&gt;
    &lt;p&gt;While AI slop floods individual project inboxes, the broader CVE infrastructure faces its own existential crisis. And these crises compound each other in dangerous ways.&lt;/p&gt;
    &lt;p&gt;In April 2025, MITRE Corporation announced that its contract to maintain the Common Vulnerabilities and Exposures program would expire. The Department of Homeland Security failed to renew the long-term contract, creating a funding lapse that affects everything: national vulnerability databases, advisories, tool vendors, and incident response operations.&lt;/p&gt;
    &lt;p&gt;The National Vulnerability Database experienced catastrophic problems throughout 2024. CVE submissions jumped 32% while creating massive processing delays. By March 2025, NVD had analyzed fewer than 300 CVEs, leaving more than 30,000 vulnerabilities backlogged. Approximately 42% of CVEs lack essential metadata like severity scores and product information.&lt;/p&gt;
    &lt;p&gt;Now layer AI slop onto this already-stressed system. Invalid CVEs are being assigned at scale. A 2023 analysis by former insiders suggested that only around 20% of CVEs were valid, with the remainder being duplicates, invalid, or inflated. The issues include multiple CVEs being assigned for the same bug, CNAs siding with reporters over project developers even when there's no genuine dispute, and reporters receiving CVEs based on test cases rather than actual distinct vulnerabilities.&lt;/p&gt;
    &lt;p&gt;The result is that the vulnerability tracking system everyone relies on is becoming less trustworthy exactly when we need it most. Security teams can't rely on CVE assignments to prioritize their work. Developers don't trust vulnerability scanners because false positive rates are through the roof. The signal-to-noise ratio has deteriorated so badly that the entire system risks becoming useless.&lt;/p&gt;
    &lt;head rend="h3"&gt;What Doesn't Work&lt;/head&gt;
    &lt;p&gt;Banning submitters doesn't work at scale. You can ban an account, but creating new accounts is trivial. HackerOne implements reputation scoring where points are gained or lost based on report validity, but this hasn't stemmed the tide because the cost of creating throwaway accounts is essentially zero.&lt;/p&gt;
    &lt;p&gt;Asking people to "please verify before submitting" doesn't work. The incentive structure rewards volume, and people either genuinely believe their AI-generated reports are valid or don't care enough to verify. Polite requests assume good faith, but much of the slop comes from actors who have no stake in the community norms.&lt;/p&gt;
    &lt;p&gt;Trying to educate submitters about how AI works doesn't scale. For every person you educate, ten new ones appear with fresh GPT accounts. The problem isn't knowledge‚Äîit's incentives.&lt;/p&gt;
    &lt;p&gt;Simply closing inboxes or shutting down bug bounty programs "works" in the sense that it stops the slop, but it also stops legitimate security research. Several projects have done this, and now they're less secure because they've lost a channel for responsible disclosure.&lt;/p&gt;
    &lt;p&gt;None of the easy answers work because this isn't an easy problem.&lt;/p&gt;
    &lt;head rend="h3"&gt;What Might Actually Work&lt;/head&gt;
    &lt;p&gt;Disclosure Requirements represent the first line of defense. Both curl and Django now require submitters to disclose whether AI was used in generating reports. Curl's approach is particularly direct: disclose AI usage upfront and ensure complete accuracy before submission. If AI usage is disclosed, expect extensive follow-up questions demanding proof that the bug is genuine before the team invests time in verification. This works psychologically. It forces submitters to acknowledge they're using AI, which makes them more conscious of their responsibility to verify. It also gives maintainers grounds to reject slop immediately if AI usage was undisclosed but becomes obvious during review. Django goes further with a section titled "Note for AI Tools" that directly addresses language models themselves, reiterating that the project expects no hallucinated content, no fictitious vulnerabilities, and a requirement to independently verify that reports describe reproducible security issues.&lt;/p&gt;
    &lt;p&gt;Proof-of-Concept Requirements raise the bar significantly. Requiring technical evidence such as screencasts showing reproducibility, integration or unit tests demonstrating the fault, or complete reproduction steps with logs and source code makes it much harder to submit slop. AI can generate a description of a vulnerability, but it cannot generate working exploit code for a vulnerability that doesn't exist. Requiring proof forces the submitter to actually verify their claim. If they can't reproduce it, they can't prove it, and you don't waste time investigating. Projects are choosing to make it harder to submit in order to filter out the garbage, betting that real researchers will clear the bar while slop submitters won't.&lt;/p&gt;
    &lt;p&gt;Reputation and Trust Systems offer a social mechanism for filtering. Only users with a history of validated submissions get unrestricted reporting privileges or monetary bounties. New reporters could be required to have established community members vouch for them, creating a web-of-trust model. This mirrors how the world worked before bug bounty platforms commodified security research. You built reputation over time through consistent, high-quality contributions. The downside is that it makes it harder for new researchers to enter the field, and it risks creating an insider club. But the upside is that it filters out low-effort actors who won't invest in building reputation.&lt;/p&gt;
    &lt;p&gt;Economic Friction fundamentally alters the incentive structure. Charge a nominal refundable fee‚Äîsay $50‚Äîfor each submission from new or unproven users. If the report is valid, they get the fee back plus the bounty. If it's invalid, you keep the fee. This immediately makes mass AI submission uneconomical. If someone's submitting 50 AI-generated reports hoping one sticks, that's now $2,500 at risk. But for a legitimate researcher submitting one carefully verified finding, $50 is a trivial barrier that gets refunded anyway. Some projects are considering dropping monetary rewards entirely. The logic is that if there's no money involved, there's no incentive for speculative submissions. But this risks losing legitimate researchers who rely on bounties as income. It's a scorched earth approach that solves the slop problem by eliminating the entire ecosystem.&lt;/p&gt;
    &lt;p&gt;AI-Assisted Triage represents fighting fire with fire. Use AI tools trained specifically to identify AI-generated slop and flag it for immediate rejection. HackerOne's Hai Triage system embodies this approach, using AI agents to cut through noise before human analysts validate findings. The risk is obvious: what if your AI filter rejects legitimate reports? What if it's biased against certain communication styles or methodologies? You've just automated discrimination. But the counterargument is that human maintainers are already overwhelmed, and imperfect filtering is better than drowning. The key is transparency and appeals. If an AI filter rejects a report, there should be a clear mechanism for the submitter to contest the decision and get human review.&lt;/p&gt;
    &lt;p&gt;Transparency and Public Accountability leverage community norms. Curl recently formalized that all submitted security reports will be made public once reviewed and deemed non-sensitive. This means that fabricated or misleading reports won't just be rejected, they'll be exposed to public scrutiny. This works as both deterrent and educational tool. If you know your slop report will be publicly documented with your name attached, you might think twice. And when other researchers see examples of what doesn't constitute a valid report, they learn what standards they need to meet. The downside is that public shaming can be toxic and might discourage good-faith submissions from inexperienced researchers. Projects implementing this approach need to be careful about tone and focus on the technical content rather than attacking submitters personally.&lt;/p&gt;
    &lt;head rend="h3"&gt;Sustainability is Hard&lt;/head&gt;
    &lt;p&gt;Every hour spent evaluating slop reports is an hour not spent on features, documentation, or actual security improvements. And maintainers are already working for free, maintaining infrastructure that generates billions in commercial value. When 38% of maintainers cite not getting paid enough as a reason for quitting, and 97% of open source maintainers are unpaid despite massive commercial exploitation of their work, the system is already broken.&lt;/p&gt;
    &lt;p&gt;AI slop is just the latest exploitation vector. It's the most visible one right now, but it's not the root cause. The root cause is that we've built a global technology infrastructure on the volunteer labor of people who get nothing in return except burnout and harassment.&lt;/p&gt;
    &lt;p&gt;So what does sustainability actually look like?&lt;/p&gt;
    &lt;p&gt;First, it looks like money. Real money. Not GitHub Sponsors donations that average $500 a year. Not swag and conference tickets. Actual salaries commensurate with the value being created. Companies that build products on open source infrastructure need to fund the maintainers of that infrastructure. This could happen through direct employment, foundation grants, or the Open Source Pledge model where companies commit percentages of revenue.&lt;/p&gt;
    &lt;p&gt;Second, it looks like better tooling and automation that genuinely reduces workload rather than creating new forms of work. Automated dependency management, continuous security scanning integrated into development workflows, and sophisticated triage assistance that actually works. The goal is to make maintenance less time-consuming so burnout becomes less likely.&lt;/p&gt;
    &lt;p&gt;Third, it looks like shared workload and team building. No single volunteer should be a single point of failure. Building teams with checks and balances where members keep each other from taking on too much creates sustainability. Finding additional contributors willing to share the burden rather than expecting heroic individual effort acknowledges that most people have limited time available for unpaid work.&lt;/p&gt;
    &lt;p&gt;Fourth, it looks like culture change. Fostering empathy in interactions, starting communications with gratitude even when rejecting contributions, and publicly acknowledging the critical work maintainers perform reduces emotional toll. Demonstrating clear processes for handling security issues gives confidence rather than trying to hide problems.&lt;/p&gt;
    &lt;p&gt;Fifth, it looks like advocacy and policy at organizational and governmental levels. Recognition that maintainer burnout represents existential threat to technology infrastructure. Development of regulations requiring companies benefiting from open source to contribute resources. Establishment of security standards that account for the realities of volunteer-run projects.&lt;/p&gt;
    &lt;p&gt;Without addressing these fundamentals, no amount of technical sophistication will prevent collapse.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Arms Race Ahead&lt;/head&gt;
    &lt;p&gt;The CVE slop crisis is just the beginning. We're entering an arms race between AI-assisted attackers or abusers and AI-assisted defenders, and nobody knows how it ends.&lt;/p&gt;
    &lt;p&gt;HackerOne's research indicates that 70% of security researchers now use AI tools in their workflow. AI-powered testing is becoming the industry standard. The emergence of fully autonomous hackbots‚ÄîAI systems that submitted over 560 valid reports in the first half of 2025‚Äîsignals both opportunity and threat.&lt;/p&gt;
    &lt;p&gt;The divergence will be between researchers who use AI as a tool to enhance genuinely skilled work versus those who use it to automate low-effort spam. The former represents the promise of democratizing security research and scaling our ability to find vulnerabilities. The latter represents the threat of making the signal-to-noise problem completely unmanageable.&lt;/p&gt;
    &lt;p&gt;The challenge is developing mechanisms that encourage the first group while defending against the second.&lt;/p&gt;
    &lt;p&gt;This probably means moving toward more exclusive models. Invite-only programs. Dramatically higher standards for participation. Reputation systems that take years to build. New models for coordinated vulnerability disclosure that assume AI-assisted research as the baseline and require proof beyond "here's what the AI told me."&lt;/p&gt;
    &lt;p&gt;It might mean the end of open bug bounty programs as we know them. Maybe that's necessary. Maybe the experiment of "anyone can submit anything" was only viable when the cost of submitting was high enough to ensure some minimum quality. Now that AI has reduced that cost to near-zero, the experiment might fail soon if things don't improve.&lt;/p&gt;
    &lt;p&gt;So, net-net, here's where we are:&lt;/p&gt;
    &lt;p&gt;When it comes to vulnerability reports, what matters is who submits them and whether they've actually verified their claims. Accepting reports from everyone indiscriminately is backfiring catastrophically because projects are latching onto submissions that sound plausible while ignoring the cumulative evidence that most are noise.&lt;/p&gt;
    &lt;p&gt;You want to receive reports from someone who has actually verified their claims, understands the architecture of what they're reporting on, and isn't trying to game the bounty system or offload verification work onto maintainers.&lt;/p&gt;
    &lt;p&gt;Such people exist, but they're becoming harder to find amidst the deluge of AI-generated content. That's why projects have to be selective about which reports they investigate and which submitters they trust.&lt;/p&gt;
    &lt;p&gt;Remember: not all vulnerability reports are legitimate. Not all feedback is worthwhile. It matters who is doing the reporting and what their incentives are.&lt;/p&gt;
    &lt;p&gt;The CVE slop crisis shows the fragility of open source security. Volunteer maintainers, already operating at burnout levels, face an explosion of AI-generated false reports that consume their limited time and emotional energy. The systems designed to track and manage vulnerabilities struggle under dual burden of structural underfunding and slop inundation.&lt;/p&gt;
    &lt;p&gt;The path forward requires holistic solutions combining technical filtering with fundamental changes to how we support and compensate open source labor. AI can be part of the solution through better triage, but it cannot substitute for adequate resources, reasonable workloads, and human judgment.&lt;/p&gt;
    &lt;p&gt;Ultimately, the sustainability of open source security depends on recognizing that people who maintain critical infrastructure deserve more than exploitation.&lt;/p&gt;
    &lt;p&gt;They deserve compensation, support, reasonable expectations, and protection from abuse. Without addressing these fundamentals, no amount of technical sophistication will prevent the slow collapse of the collaborative model that has produced so much of the digital infrastructure modern life depends on.&lt;/p&gt;
    &lt;p&gt;The CVE slop crisis isn't merely about bad vulnerability reports. It's about whether we'll choose to sustain the human foundation of technological progress, or whether we'll let it burn out under the weight of automated exploitation.&lt;/p&gt;
    &lt;p&gt;That's the choice we're facing. And right now, we're choosing wrong.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45834303</guid><pubDate>Thu, 06 Nov 2025 12:05:12 +0000</pubDate></item><item><title>IKEA launches new smart home range with 21 Matter-compatible products</title><link>https://www.ikea.com/global/en/newsroom/retail/the-new-smart-home-from-ikea-matter-compatible-251106/</link><description>&lt;doc fingerprint="d5745a5ac3b9fbfb"&gt;
  &lt;main&gt;
    &lt;p&gt;Published 6 November 2025 ‚Ä¢ Inter IKEA newsroom&lt;/p&gt;
    &lt;head rend="h1"&gt;IKEA launches new smart home range with 21 Matter-compatible products&lt;/head&gt;
    &lt;p&gt;IKEA is launching 21 new smart home products focusing on lighting, sensors, and control ‚Äî all built to work with Matter, the universal smart home standard. The launch marks a significant step in making smart home technology easier to use, more affordable, and better adapted to real-life needs in the home.&lt;/p&gt;
    &lt;p&gt;With this launch, IKEA is rebuilding its smart home system and product range from the ground up. The new launch reflects years of development and testing in real homes, and a growing understanding of how people want smart products to work in their daily life.&lt;/p&gt;
    &lt;p&gt;The launch includes both new products and updates to existing categories ‚Äì now built to work with Matter. This means IKEA smart products can connect with a wider range of devices and platforms, making it easier for customers to build a smart home across different brands.&lt;/p&gt;
    &lt;p&gt;‚ÄúUntil now, smart home technology hasn‚Äôt been easy enough to use for most people ‚Äî or affordable enough for many to consider. This launch brings us closer to helping everyone feel ready and confident to get started,‚Äù says David Granath, Range Manager at IKEA of Sweden.&lt;/p&gt;
    &lt;p&gt;The updated range focuses on three key segments*, that provide the building blocks of a smart home that‚Äôs flexible, intuitive, and easy to expand over time.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Lighting ‚Äì The new smart bulb range from IKEA. Comes in a variety of shapes, sizes, lumen levels and styles, including colour and white spectrum options, and dimmable features.&lt;/item&gt;
      &lt;item&gt;Sensors ‚Äì motion, air quality, humidity and water leakage sensors designed to support wellbeing and prevent damage&lt;/item&gt;
      &lt;item&gt;Control ‚Äì Remotes that make it easy to control devices from a distance, and a smart plug that can turn any product into a smart product.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;*Full product list further down.&lt;/p&gt;
    &lt;p&gt;‚ÄúThis launch is about making the smart home experience better and broader. We're upgrading our most-appreciated products while also adding new ones to solve even more everyday challenges. Our focus has been on keeping things simple from setup to daily use, so it‚Äôs easy for people to start, use and grow a smart home,‚Äù says Stjepan Begic, Product Developer at IKEA of Sweden.&lt;/p&gt;
    &lt;p&gt;All Matter-enabled products need a smart home hub to work ‚Äî like IKEA‚Äôs DIRIGERA hub, or one from another brand. As a certified Matter controller, DIRIGERA can also manage and control smart products from other manufacturers and brands. As a Matter Bridge, it ensures that existing IKEA non-Matter smart products will also be compatible with platforms using the Matter standard.&lt;/p&gt;
    &lt;p&gt;This launch is the first step in a broader update of the IKEA Home smart range. Looking ahead, IKEA will continue expanding into new product categories. The strategy is to launch products that are easier to use and more affordable than existing ones.&lt;/p&gt;
    &lt;p&gt;‚ÄúOur goal is still the same as when we started exploring the smart home in 2012: to make it easy to use, easy to understand, and within reach for the many. We start with understanding life at home, where we continuously watch, listen and learn what makes a difference in everyday life. We believe technology should serve a purpose, not exist for its own sake. With more than 900 million store visits each year, I think we‚Äôre in a good place to help more people discover the benefits of a smarter home,‚Äù says David Granath.&lt;/p&gt;
    &lt;p&gt;Sales start and local pricing may vary between markets. Please contact your local IKEA market for more information.&lt;/p&gt;
    &lt;head rend="h2"&gt;Discover the new Matter-compatible IKEA Home smart range:&lt;/head&gt;
    &lt;p&gt;The KAJPLATS smart bulb range includes eleven variations, offering a mix of shapes, sizes, lumen levels, and styles ‚Äî with options for both colour and white spectrum, as well as dimmable functionality. Compared to the previous TR√ÖDFRI range, each bulb has more functionality, including more colour options and broader light intensity spans.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;E27/E26 ‚Äì standard globe shape, 60 mm diameter &lt;lb/&gt;Colour and white spectrum, 1 055 lm ‚Äì colour-changing&lt;lb/&gt;White spectrum, 470 lm ‚Äì dimmable&lt;lb/&gt;White spectrum, 1 055 lm ‚Äì dimmable&lt;lb/&gt;White spectrum, 1 521 lm ‚Äì dimmable&lt;/item&gt;
      &lt;item&gt;P45 E14* ‚Äì compact profile, 45 mm diameter&lt;lb/&gt;White spectrum, 470 lm ‚Äì dimmable&lt;lb/&gt;White spectrum, 806 lm ‚Äì dimmable&lt;lb/&gt;Colour and white spectrum, 806 lm ‚Äì colour-changing&lt;/item&gt;
      &lt;item&gt;GU10 ‚Äì directional spotlight &lt;lb/&gt;Colour and white spectrum, 470 lm - colour-changing&lt;lb/&gt;White spectrum, 575 lm ‚Äì dimmable&lt;/item&gt;
      &lt;item&gt;Clear-glass decorative bulbs ‚Äì white spectrum only (dimmable) &lt;lb/&gt;E14* ‚Äì 470 lm clear glass&lt;lb/&gt;E27 standard globe (60 mm diameter) ‚Äì 470 lm clear glass&lt;lb/&gt;E27 large globe (95 mm diameter) ‚Äì 810 lm clear glass&lt;lb/&gt;*E14 also available as E12 and E17 depending on local standardisations.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Smart sensors: Five variations for motion, air quality, humidity and water leakage designed to support wellbeing and prevent damage.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;MYGGSPRAY - Motion sensor for indoor and outdoor use that turns on lighting automatically in areas like entrances, staircases, garages, or anywhere you need hands-free light.&lt;/item&gt;
      &lt;item&gt;MYGGBETT ‚Äì Door/Window sensor. Detects when a door or window is opened or closed, and if connected to a smart system you can get notifications on your phone. Also works for spaces like walk-in closets, where it can trigger a light to turn on or off.&lt;/item&gt;
      &lt;item&gt;TIMMERFLOTTE ‚Äì Temperature and Humidity Sensor. Measures the indoor climate at home. Press the button to view temperature, followed by humidity ‚Äî one after the other.&lt;/item&gt;
      &lt;item&gt;ALPSTUGA ‚Äì Air quality sensor. Measures CO‚ÇÇ, particles (PM2.5), temperature, and humidity to show the air quality in your home. Built to work together with IKEA air purifiers for better indoor air. Can also display the time&lt;/item&gt;
      &lt;item&gt;KLIPPBOK ‚Äì Water leakage sensor. Detects leaks and alerts you with a sound ‚Äì and can also send a notification to your phone when connected to a hub. Small enough to place under sinks, appliances, or other risk areas.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Remote controls and plugs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;BILRESA remote control with dual button ‚Äì A simple way to control smart products from afar. Use it to switch lights on or off, adjust brightness, change colour, or trigger a preset scene.&lt;/item&gt;
      &lt;item&gt;BILRESA remote control with scroll wheel ‚Äì Lets you adjust smart products with a simple turn. Use it to switch lights on or off, dim, change colour, or control a group or preset scene.&lt;/item&gt;
      &lt;item&gt;BILRESA Remote Control Kits (2x) ‚Äì Kits of three colourful versions of the remote controls, in green, red and beige. One kit with three scroll wheels, and the other is with remote control with dual buttons.&lt;/item&gt;
      &lt;item&gt;GRILLPLATS smart plug. This smart plug lets you control ordinary lamps or smaller appliances remotely ‚Äî turning them into smart products. It also tracks energy use and can be paired with a remote or motion sensor. Separate sales start&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45834980</guid><pubDate>Thu, 06 Nov 2025 13:26:37 +0000</pubDate></item><item><title>I analyzed the lineups at the most popular nightclubs</title><link>https://dev.karltryggvason.com/how-i-analyzed-the-lineups-at-the-worlds-most-popular-nightclubs/</link><description>&lt;doc fingerprint="3603417d793229b9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How I analyzed the lineups at the world's most popular nightclubs&lt;/head&gt;
    &lt;p&gt;A few years back I did a bit of dance music related data visualization over at Lazily Evaluated. My favourite was an analysis of clubs and their lineups using Resident Advisor / RA data, I called it Clubster Analysis. I always wanted to dig into the technical aspects of gathering the data, analyzing it and building the charts and graphs to tell a story and give people insight. With this blog I now have the right venue for that kind of tech talk, so here goes.&lt;/p&gt;
    &lt;head rend="h2"&gt;Data gathering #&lt;/head&gt;
    &lt;p&gt;To visualize data, first you have to get some! For this purpose I wrote a little scraper in Python. I used Beautiful Soup to parse the html and grab the bits and pieces I was interested in.&lt;/p&gt;
    &lt;p&gt;My scraping of a few thousand pages didn‚Äôt cause considerable load on the RA servers. But in the age of overzealous AI scrapers it‚Äôs worth being polite, so I throttled according to their robots.txt. I also maintained a local cache of html files I had already downloaded, so that I wouldn‚Äôt have fetch the same data repeatedly (past lineups are unlikely to change after the fact) just because I discovered some bug or error in my parsing.&lt;/p&gt;
    &lt;p&gt;The order I scraped in was:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Get the 20 most popular regions in RA (and then I dropped ‚ÄúStreamland‚Äù which was a pandemic era pseudo-region)&lt;/item&gt;
      &lt;item&gt;Fetch the most popular clubs and some related metadata for all of those regions.&lt;/item&gt;
      &lt;item&gt;For each club, get the lineups for every 2019 event of theirs (the last full year before the pandemic started).&lt;/item&gt;
      &lt;item&gt;Save the results to csv files&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Clean up, verification and Analysis #&lt;/head&gt;
    &lt;p&gt;I did some spot checks to verify that my parsing was working as I expected and added tests to make sure I handled edge cases and normalized artist names. There was a lot of variance in how dates were formatted, how artists were linked, etc.&lt;/p&gt;
    &lt;p&gt;After that I analyzed the data. I built one big table/dataframe in Pandas by joining all the info from the csv files. Then I calculated the similarities between each pair of clubs in the data set using the Jaccard index. Consider all the artists that have played at two given clubs, take the intersection (number of artists that have featured in lineups at both clubs) over the union (all the artists that have performed at one or the other). As an example if Club A had 100 artists booked and Club B had 100 artists, and they had 10 bookings in common, the Jaccard index would be 10/190 = ~5%. This gives you a good way to compare large and small clubs and balances large and small lineups (some of the clubs have multiple rooms with very long events, others have one dj playing in one room all night long once a week).&lt;/p&gt;
    &lt;p&gt;Based on the Jaccard index we can build a graph, using NetworkX from all the clubs. The edges between two nodes are weighted by the similarity of those clubs. On top of the graph we run community detection to create clusters (hence the clubster name). This gives us a rough idea of which clubs are most similar, that is to say, have similar tastes in their bookings.&lt;/p&gt;
    &lt;head rend="h2"&gt;Results #&lt;/head&gt;
    &lt;p&gt;For the year 2019, there were 131 clubs in the data set with 8.502 events. There were 9.405 unique artists making up 30.482 individual bookings. This means that the average artist in the dataset was booked 3.24 times at those clubs in that year and the average event had 3.5 artists on the line up.&lt;/p&gt;
    &lt;p&gt;As a whole, out of 8.515 possible pairs of clubs, 3.716 pairs had some overlap in their bookings and out of those the average overlap was 1%. This was lower than I thought, the bookings at European clubs felt more homogenous to me, but I suppose they book a lot of artists. It would be interesting to get more data, recent and historic, and see how this has evolved through time.&lt;/p&gt;
    &lt;head rend="h2"&gt;Visualization #&lt;/head&gt;
    &lt;p&gt;This was my first time using D3 to draw charts. There was a bit of a learning curve, in earlier projects I had used higher level charting libraries which have simpler apis. But with D3 you get a lot of control over how your charts look and behave which I think I used to good effect in this instance.&lt;/p&gt;
    &lt;p&gt;My main goal was to visualize the clusters and to allow people to interact with the clubs. I coloured the clubs according to their clusters and sized them based on the number of followers they had on RA. I played around with the gravity and placement of the cluster, trying to find a balance that worked on different screen sizes as well as being a fair portrayal of the different communities.&lt;/p&gt;
    &lt;p&gt;I then did some scrollytelling to tell the story of the data, as I saw it, while the reader scrolls down the page. But I also added filters and interactivity for people to explore and see if they agree with my telling of the story or if they can find one of their own.&lt;/p&gt;
    &lt;p&gt;At the time I didn‚Äôt find any great React and D3 bridges, so it was a bit of a hassle getting the React components to play nice with the D3 graph, but in the end I was able to connect the two with &lt;code&gt;createRef&lt;/code&gt; to the D3 svg component.&lt;/p&gt;
    &lt;p&gt;Besides the clustering I looked into the ‚Äúresident factor‚Äù, how many times an artist was booked at a club repeatedly compared to all the one offs. This was lower than expected, most of these clubs were booking a constantly rotating assembly of talent, residents don‚Äôt play as big a part as I would have thought.&lt;/p&gt;
    &lt;p&gt;Transitioning between the different sections of these graphs was one of my favourite parts. Seeing the clusters morph into dots and candlestick charts (and back again) was oddly satisfying. Took a lot of tweaking, but I think it really tied together the scrollytelling experience.&lt;/p&gt;
    &lt;p&gt;I don‚Äôt think these transitions would have been possible with the higher level charting libraries I‚Äôd used previously. So the decision to go with D3 felt justified.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary #&lt;/head&gt;
    &lt;p&gt;This was a great pandemic project that combined web scraping, data analysis, and interactive visualization to explore the global dance music club scene. I learned me some D3 for the visualization, got better at doing cartesian graphing calculations in my head and learned about the underlying svg mechanics that power those graphs.&lt;/p&gt;
    &lt;p&gt;The results surprised me: despite my perceived homogeneity of European club bookings, only 1% average overlap between venues suggested more diverse landscape than I expected. The diminished role of residents compared to one-off bookings also challenged my assumptions about how these clubs operate. For the story telling maintaining the balance between a narrative and letting users explore and decide for themselves was a fun challenge. I think these sort of passion projects can give us deep insights into our world and culture.&lt;/p&gt;
    &lt;p&gt;The technical stack I worked with: Python, Pandas, NetworkX, D3, and React proved powerful despite some integration challenges. The complete project is available on GitHub and you can explore the live interactive visualization yourself.&lt;/p&gt;
    &lt;p&gt;I had a lot of fun building this and am proud of the result. If you‚Äôre working on cultural data analysis, need help with web scraping and visualization, or just want to discuss interesting datasets, feel free to reach out.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45835083</guid><pubDate>Thu, 06 Nov 2025 13:37:07 +0000</pubDate></item><item><title>Cloudflare Tells U.S. Govt That Foreign Site Blocking Efforts Are Trade Barriers</title><link>https://torrentfreak.com/cloudflare-tells-u-s-govt-that-foreign-site-blocking-efforts-are-digital-trade-barriers/</link><description>&lt;doc fingerprint="201a9b555f843940"&gt;
  &lt;main&gt;
    &lt;p&gt;Every year, the office of the United States Trade Representative (USTR) publishes the National Trade Estimate Report on Foreign Trade Barriers.&lt;/p&gt;
    &lt;p&gt;The report is compiled based on input from key industry players. This includes submissions from copyright industry groups that frequently highlight piracy challenges that in their view act as barriers to trade.&lt;/p&gt;
    &lt;p&gt;In previous years, for example, the MPA and others have called for more site-blocking efforts to counter the piracy threat. Interestingly, however, other American companies now inform the USTR that foreign site-blocking measures are becoming a significant trade barrier.&lt;/p&gt;
    &lt;head rend="h2"&gt;Cloudflare Sees Piracy Blockades as Trade Barriers&lt;/head&gt;
    &lt;p&gt;To share its concerns, Cloudflare decided to participate in the annual trade barriers consultation for the first time this year. The company describes itself as a ‚Äúleading connectivity cloud company‚Äù running one of the world‚Äôs largest networks, providing security, performance, and reliability services.&lt;/p&gt;
    &lt;p&gt;According to Cloudflare, several foreign countries disproportionately impact U.S. technology providers, with many concerns relating to site-blocking measures that aim to deter online piracy.&lt;/p&gt;
    &lt;head rend="h3"&gt;Spain&lt;/head&gt;
    &lt;p&gt;Cloudflare writes that Spanish courts allow rightsholders to request ‚Äúoverbroad court orders‚Äù that authorize IP address blocking. Since a single IP address can serve thousands of domains, disrupting pirates often means that many legitimate sites and services are blocked too, causing widespread collateral damage.&lt;/p&gt;
    &lt;p&gt;‚ÄúThis practice results in the widespread and repeated disruption of tens of thousands of unrelated, legitimate websites, as well as the disruption of digital services, with no judicial opportunity for remedy,‚Äù Cloudflare writes.&lt;/p&gt;
    &lt;p&gt;‚ÄúThese actions, designed to protect a narrow set of commercial interests, have caused significant collateral harm to businesses and users who are not the intended targets, without recourse or the possibility for affected parties to challenge the underlying order.‚Äù&lt;/p&gt;
    &lt;p&gt;The Spanish Government is aware of the problems, which Cloudflare says are at odds with international standards, but has chosen not to intervene in the issue. Therefore, it continues to present a significant trade barrier.&lt;/p&gt;
    &lt;head rend="h3"&gt;Italy&lt;/head&gt;
    &lt;p&gt;Cloudflare reports similar concerns in Italy, where the ‚ÄúPiracy Shield‚Äù site-blocking law has a direct effect on American companies. This blocking regulation requires network providers, including CDNs, to comply with blocking notices within 30 minutes.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe failure to include adequate safeguards against collateral damage has led to the inappropriate blocking of shared services of large cloud providers, which are disproportionately American businesses,‚Äù Cloudflare notes.&lt;/p&gt;
    &lt;p&gt;‚ÄúFor instance, the blocking of a Cloudflare IP address resulted in tens of thousands of non-targeted websites being blocked in February 2024. Furthermore, the blocking of the domain ‚Äúdrive.usercontent.google.com‚Äù in October denied Italian users access to Google Drive for over 12 hours.‚Äù&lt;/p&gt;
    &lt;p&gt;Efforts to expand Piracy Shield to public DNS resolvers and VPN services only make the problem worse, Cloudflare says, noting that some U.S. companies have already decided to leave the European country.&lt;/p&gt;
    &lt;p&gt;Automated piracy blocks are not the only reported trade barrier in Italy. Cloudflare also notes that the country allows rightsholders to ‚Äúabuse‚Äù the courts to disrupt U.S. businesses by granting ex parte blocking orders without giving the companies a chance to oppose them.&lt;/p&gt;
    &lt;p&gt;‚ÄúThis coercive, penalty-based approach to removal of content, without adequate judicial review or due process protections, is a significant barrier to doing business in Italy,‚Äù Cloudflare writes.&lt;/p&gt;
    &lt;head rend="h3"&gt;France&lt;/head&gt;
    &lt;p&gt;In France, Cloudflare highlights Article L.333-10 of the Sports Code as a key problem. This has resulted in several pirate site blocking orders that go beyond regular Internet providers, requiring DNS resolvers and VPN services to take action as well.&lt;/p&gt;
    &lt;p&gt;Cloudflare notes that some services lack the technical capabilities to implement these orders and as a result, several U.S. companies have already left the country.&lt;/p&gt;
    &lt;p&gt;Recently, France passed a new anti-piracy bill that opens the door to automated IP-address blocking, similar to Italy‚Äôs Piracy Shield. This is a major concern for Cloudflare, which fears that this will only lead to more collateral damage.&lt;/p&gt;
    &lt;p&gt;‚ÄúIt increases the risk of overblocking legitimate content or mistakenly targeting websites that operate lawfully, potentially disrupting cross-border digital services,‚Äù Cloudflare writes.&lt;/p&gt;
    &lt;head rend="h3"&gt;South Korea&lt;/head&gt;
    &lt;p&gt;South Korea has also created trade barriers due to its site-blocking measures, Cloudflare reports. A revision to the Network Act in 2023 now requires ‚ÄúCDNs to restrict access to illegal content‚Äù.&lt;/p&gt;
    &lt;p&gt;As a result, Cloudflare and other American companies are required to maintain detailed and regularly updated blocklists.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe South Korea Communication Commission (KCC) sends U.S. CDN providers a ‚Äòblock list‚Äô of over 1.5 million URLs (with 30,000 new additions monthly),‚Äù Cloudflare writes, noting that this places an ‚Äúunprecedented compliance burden‚Äù on companies.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conflicting Demands at the U.S. Trade Office&lt;/head&gt;
    &lt;p&gt;Cloudflare urges the USTR to take these concerns into account for its upcoming National Trade Estimate Report. Ideally, it wants these trade barriers to be dismantled.&lt;/p&gt;
    &lt;p&gt;These calls run counter to requests from rightsholders, who urge the USTR to ensure that more foreign countries implement blocking measures. With potential site-blocking legislation being considered in U.S. Congress, that may impact local lobbying efforts as well.&lt;/p&gt;
    &lt;p&gt;If and how the USTR will address these concerns will become clearer early next year, when the 2026 National Trade Estimate Report is expected to be published.&lt;/p&gt;
    &lt;p&gt;‚Äî&lt;/p&gt;
    &lt;p&gt;A copy of Cloudflare‚Äôs submission for the USTR‚Äôs 2025 National Trade Estimate Report on Foreign Trade Barriers is available here (pdf)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45835123</guid><pubDate>Thu, 06 Nov 2025 13:41:14 +0000</pubDate></item><item><title>Kimi release Kimi K2 Thinking, an open-source trillion-parameter reasoning model</title><link>https://moonshotai.github.io/Kimi-K2/thinking.html</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=45836070</guid><pubDate>Thu, 06 Nov 2025 15:06:06 +0000</pubDate></item><item><title>Australia has so much solar that it's offering everyone free electricity</title><link>https://electrek.co/2025/11/04/australia-has-so-much-solar-that-its-offering-everyone-free-electricity-3h-day/</link><description>&lt;doc fingerprint="b2218c5f3ab4e71c"&gt;
  &lt;main&gt;
    &lt;p&gt;The Australian government is floating a scheme that would share the benefits of solar power with everyone on the grid, offering totally free electricity to ratepayers in the middle of the day, when the sun is shining the strongest.&lt;/p&gt;
    &lt;p&gt;Australia is a sunny place. It‚Äôs kind of known for it. It‚Äôs the sunniest continent, and the sunniest country outside of the Middle East/Africa, with extensive photovoltaic power potential across its entire territory.&lt;/p&gt;
    &lt;p&gt;In recognition of that, Australia has been installing lots of solar power. Formerly a coal-heavy nation (for which coal is still its 2nd-largest export), solar and wind have rapidly taken over Australia‚Äôs electricity grid, pushing coal and methane gas out of the equation.&lt;/p&gt;
    &lt;p&gt;This has taken a big chunk out of Australia‚Äôs electricity-related climate emissions, and of course resulted in clean air benefits as dirty coal is pushed out of the grid. And climate emissions matter a lot for Australia, a country that is becoming more unbearably hot and suffering more fires due to climate change. (Though Australia is also a great example of how global cooperation on environmental issues can fix a huge problem, as they are the primary beneficiary of global action on closing the hole in the Ozone layer)&lt;/p&gt;
    &lt;p&gt;So solar power has been a great thing for Australia, especially with rooftop solar on Australian homes.&lt;/p&gt;
    &lt;p&gt;But it can lead to swingy electricity supply, given that solar only generates electricity when the sun is out.&lt;/p&gt;
    &lt;head rend="h2"&gt;How swings in solar supply and electricity pricing work&lt;/head&gt;
    &lt;p&gt;Most areas have certain times of day where more electricity is used than others. These are referred to as ‚Äúpeak hours‚Äù and generally they happen in the early evening, when people get home from work, turn on the HVAC, cook dinner, do laundry and the like.&lt;/p&gt;
    &lt;p&gt;But there are also certain times of day when more electricity is generated, and that‚Äôs particularly the case in places with high solar penetration. Solar obviously generates energy only during the day, and creates a peak of generation in the middle of the day, when most people are at work.&lt;/p&gt;
    &lt;p&gt;There are ways to mitigate this ‚Äì for example, with batteries, which Australia has also used a lot of (and is thinking about extending that to EV batteries too). Wind power also helps, since wind tends to pick up in the hours that solar is dropping off.&lt;/p&gt;
    &lt;p&gt;But another way to mitigate it is through simple economics. Offer people lower prices in the hours that electricity is more abundant, and higher prices in hours where it isn‚Äôt. Then, people will tend to use electricity when they can ‚Äì especially if they have shiftable loads like electric cars, laundry, pool pumps and such, which don‚Äôt need to be on at the same time every day (unlike HVAC, cooking, and lighting, for example).&lt;/p&gt;
    &lt;p&gt;Most electricity providers will offer something like this, called a ‚Äútime of use‚Äù plan. These plans differ in their rates and peak hours depending on your location and how the supply/demand curves work for electricity there (and have seen common use among electric car owners because of the outsized effect an EV has on home electricity use).&lt;/p&gt;
    &lt;p&gt;On the utility side, though, the swings in price can be much more drastic. Wholesale prices for electricity can go up to multiple dollars per kilowatt-hour during times of extreme demand when the grid is stressed, and electricity prices can even go negative when there is little demand and lots of supply, particularly on an islanded grid like Australia (this also happens in Texas, where the grid is largely disconnected from the rest of the US). These swings are ironed out for the consumer, so things aren‚Äôt as spiky for us, but it can be quite a rollercoaster on the grid side.&lt;/p&gt;
    &lt;p&gt;In Australia and other places with high solar penetration, these negative electricity prices often happen during the day. That‚Äôs when generation is the highest for solar panels, and household loads are typically low.&lt;/p&gt;
    &lt;head rend="h2"&gt;Australia proposes letting everyone benefit from negative wholesale rates&lt;/head&gt;
    &lt;p&gt;So, the Australian government has decided on a scheme to bring those electricity savings to the consumer, with what its calling its ‚ÄúSolar Sharer‚Äù program.&lt;/p&gt;
    &lt;p&gt;The program would require electricity retailers to provide free electricity to everyone for at least three hours a day, in recognition of the incredibly low wholesale cost of electricity during daytime due to extensive solar power penetration.&lt;/p&gt;
    &lt;p&gt;These would likely be in the middle of the day, when most people aren‚Äôt home. However, every home has some amount of shiftable electricity load, and the Solar Sharer scheme would encourage people to make use of that. With modern appliances that can be scheduled to start in the middle of the day, people can just plan to do laundry, run the dishwasher, run the pool pump, or charge their car at noon, instead of whenever else they were going to.&lt;/p&gt;
    &lt;p&gt;Additionally, people could fill up a home battery during the day, and then use that electricity during peak hours when rates are higher. And this plan will help to incentivize private installation of batteries, or other shiftable loads.&lt;/p&gt;
    &lt;p&gt;The overall effect of this is that it will help to iron out electricity use, making it track more closely with electricity supply, reducing the need for grid upgrades to manage swings in generation. Just turning on this simple behavioral switch, and then publicizing it so customers know to use electricity in the free hours, will both help the grid and help ratepayers save money.&lt;/p&gt;
    &lt;p&gt;Better yet, this scheme will apply not just to people who have solar or home batteries, but to people who live in places where they can‚Äôt put up solar ‚Äì those who live in apartments and the like. The government says it will require companies to offer this scheme to all customers, not just those with solar.&lt;/p&gt;
    &lt;p&gt;The government did receive some pushback from electricity retailers, who feel they were not properly consulted on the plan. But Australia‚Äôs Climate Change Minister Chris Bowen said he would make ‚Äúno apologies‚Äù if this scheme reduced their margins, and that ‚Äúconsumers are put first‚Äù as reported by the Australian Broadcasting Corporation.&lt;/p&gt;
    &lt;p&gt;The government plans to implement the scheme starting in July next year, first in Queensland, New South Wales and South Australia. If it works well, other regions will get it starting in 2027.&lt;/p&gt;
    &lt;head rend="h2"&gt;Electrek‚Äôs Take&lt;/head&gt;
    &lt;p&gt;Australia is doing a lot of great things with electricity, and acting somewhat like a natural laboratory for a lot of ideas that people have been talking about for a long time. Since the whole country has similar solarization, it can work somewhat as a unit in pushing for solar power, and for reforms to help enable it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Top comment by Spec9&lt;/head&gt;
    &lt;p&gt;It is an interesting idea. There's so much electricity on the grid that the price drops to zero and the electricity is curtailed (wasted). So why not give it out for free and encourage people to do their laundry then, charge EVs, buy residential batteries and charge them then, turn on their water heaters, precool/preheat homes, etc.&lt;/p&gt;
    &lt;p&gt;It‚Äôs already working on V2G, with a huge trial started recently, and the wide adoption of solar and batteries is proving that even a solar-heavy grid can still work. And an idea like this, showing how simple economics can be used to change consumer behavior, could provide a model for the rest of the world on how to usher us into a cleaner energy future.&lt;/p&gt;
    &lt;p&gt;So we‚Äôll be watching with interest how this turns out ‚Äì I think it will likely turn out quite well, if the government goes through with it fully.&lt;/p&gt;
    &lt;p&gt;The 30% federal solar tax credit is ending this year. If you‚Äôve ever considered going solar, now‚Äôs the time to act. To make sure you find a trusted, reliable solar installer near you that offers competitive pricing, check out EnergySage, a free service that makes it easy for you to go solar. It has hundreds of pre-vetted solar installers competing for your business, ensuring you get high-quality solutions and save 20-30% compared to going it alone. Plus, it‚Äôs free to use, and you won‚Äôt get sales calls until you select an installer and share your phone number with them.&lt;/p&gt;
    &lt;p&gt;Your personalized solar quotes are easy to compare online and you‚Äôll get access to unbiased Energy Advisors to help you every step of the way. Get started here.&lt;/p&gt;
    &lt;p&gt;FTC: We use income earning auto affiliate links. More.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45836104</guid><pubDate>Thu, 06 Nov 2025 15:08:56 +0000</pubDate></item><item><title>FBI Tries to Unmask Owner of Infamous Archive.is Site</title><link>https://www.heise.de/en/news/Archive-today-FBI-Demands-Data-from-Provider-Tucows-11066346.html</link><description>&lt;doc fingerprint="3b8a0317679167ef"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Archive.today: FBI Demands Data from Provider Tucows&lt;/head&gt;
    &lt;p&gt;The mysterious website Archive.today is coming under the FBI's crosshairs. A court order is forcing the provider Tucows to hand over user data.&lt;/p&gt;
    &lt;p&gt;It is one of the most mysterious and, at the same time, best-known websites on the internet. Archive.today has built up a user base over a period of more than ten years who use the service to access previous snapshots of a web page. So basically like the Wayback Machine of the Internet Archive, only largely free of rules and presumably therefore also anonymous. To the chagrin of the media industry, the service is also often used to bypass paywalls. This is also possible because the service does not adhere to common rules and laws and offers no opt-out option.&lt;/p&gt;
    &lt;p&gt;And so far, the operators have gotten away with it. Although there have been minor problems in the history of the service occasionally, for example, a top-level domain operator denied them further use of one of the many archive domains. However, the operation of the project, which is allegedly financed by donations and own funds, was not seriously endangered.&lt;/p&gt;
    &lt;head rend="h3"&gt;Court Order in the USA&lt;/head&gt;
    &lt;p&gt;But now the operators of archive.today are apparently fearing bigger trouble. In recent months and years, they had become noticeably quieter. Until two years ago, for example, questions were regularly answered in the blog. In the official X account, which had been silent for over a year, a new post appeared at the end of October new post. ‚ÄúCanary,‚Äù it said there, along with a URL. The mentioned canary bird is likely an allusion to an old custom in mining. A canary brought along warned the miners when it keeled over dead about the threat of invisible gas.&lt;/p&gt;
    &lt;p&gt;Videos by heise&lt;/p&gt;
    &lt;p&gt;The deadly danger that the site operators fear is apparently linked to the PDF linked in the X post linked PDF. It contains a court order that the US investigative authority FBI has obtained. It instructs the Canadian provider Tucows to hand over comprehensive data about the customer behind archive.today. It concerns address and connection data as well as payment information. If Tucows does not provide the data, penalties are threatened. Whether the court order is genuine and how the operators of the site obtained it could not be verified so far.&lt;/p&gt;
    &lt;head rend="h3"&gt;Is the operator based in Russia?&lt;/head&gt;
    &lt;p&gt;Why the FBI is currently interested in archive.today, which is also accessible under the domains archive.is and archive.ph, is not evident from the court order. However, there are several obvious starting points for investigations: in addition to the obvious reason of copyright issues, the investigators could also be pursuing suspicions about unclear financing, the origin of the operators, or the technical approach.&lt;/p&gt;
    &lt;p&gt;In 2023, Finnish blogger Janni Patokallio compiled various clues and research results in a post in a post. According to this, Archive.today uses a botnet with changing IP addresses to circumvent anti-scraping measures. There are also indications that the operator(s) are based in Russia.&lt;/p&gt;
    &lt;p&gt;(mki)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45836826</guid><pubDate>Thu, 06 Nov 2025 16:18:18 +0000</pubDate></item></channel></rss>