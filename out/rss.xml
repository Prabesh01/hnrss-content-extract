<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 12 Dec 2025 00:52:47 +0000</lastBuildDate><item><title>The architecture of “not bad”: Decoding the Chinese source code of the void</title><link>https://suggger.substack.com/p/the-architecture-of-not-bad-decoding</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46231709</guid><pubDate>Thu, 11 Dec 2025 14:21:14 +0000</pubDate></item><item><title>An Orbital House of Cards: Frequent Megaconstellation Close Conjunctions</title><link>https://arxiv.org/abs/2512.09643</link><description>&lt;doc fingerprint="fcbc363a54b394af"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Astrophysics &amp;gt; Earth and Planetary Astrophysics&lt;/head&gt;&lt;p&gt; [Submitted on 10 Dec 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:An Orbital House of Cards: Frequent Megaconstellation Close Conjunctions&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:The number of objects in orbit is rapidly increasing, primarily driven by the launch of megaconstellations, an approach to satellite constellation design that involves large numbers of satellites paired with their rapid launch and disposal. While satellites provide many benefits to society, their use comes with challenges, including the growth of space debris, collisions, ground casualty risks, optical and radio-spectrum pollution, and the alteration of Earth's upper atmosphere through rocket emissions and reentry ablation. There is substantial potential for current or planned actions in orbit to cause serious degradation of the orbital environment or lead to catastrophic outcomes, highlighting the urgent need to find better ways to quantify stress on the orbital environment. Here we propose a new metric, the CRASH Clock, that measures such stress in terms of the time it takes for a catastrophic collision to occur if there are no collision avoidance manoeuvres or there is a severe loss in situational awareness. Our calculations show the CRASH Clock is currently 2.8 days, which suggests there is now little time to recover from a wide-spread disruptive event, such as a solar storm. This is in stark contrast to the pre-megaconstellation era: in 2018, the CRASH Clock was 121 days.&lt;/quote&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;astro-ph.EP&lt;/p&gt;&lt;p&gt; Change to browse by: &lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;p&gt; IArxiv Recommender (What is IArxiv?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46232220</guid><pubDate>Thu, 11 Dec 2025 15:01:44 +0000</pubDate></item><item><title>Launch HN: BrowserBook (YC F24) – IDE for deterministic browser automation</title><link>https://news.ycombinator.com/item?id=46232434</link><description>&lt;doc fingerprint="956206d209fba2cc"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hey HN! We’re Chris, Jorrie, and Evan of BrowserBook, an IDE for writing and debugging Playwright-based web automations. You can download it as a Mac app here: &lt;/p&gt;https://browserbook.com&lt;p&gt;, and there’s a demo video at &lt;/p&gt;https://www.youtube.com/watch?v=ODGJBCNqGUI&lt;p&gt;.&lt;/p&gt;&lt;p&gt;Why we built this: When we were going through YC, we were a company that automated back-office healthcare workflows. Since the interoperability ecosystem in healthcare is so fragmented, we started using browser agents to automate EMRs, practice management software, and payment portals directly through the web. When we did, we ran into a ton of problems:&lt;/p&gt;&lt;p&gt;Speed: High latency on LLM calls vs. a scripting approach&lt;/p&gt;&lt;p&gt;Cost: We burned through tokens with all the context we needed to make the automations reasonably accurate&lt;/p&gt;&lt;p&gt;Reliability: Even with detailed instructions, context, and tools, agents tended to drift on multi-step tasks in unpredictable ways&lt;/p&gt;&lt;p&gt;Debuggability: When drift did occur, we were essentially playing whack-a-mole in our prompt and re-running the whole automation to debug issues (see above: speed and cost issues made this quite painful)&lt;/p&gt;&lt;p&gt;More and more we were just giving our agent scripts to execute. Eventually, we came to the conclusion that scripting is a better approach for web automation for these sort of use cases. But scripting was also too painful, so we set out to solve those problems with BrowserBook.&lt;/p&gt;&lt;p&gt;Under the hood, it runs a standalone TypeScript REPL wired directly into an inline browser instance, with built-in tooling to make script development quick and easy. This includes:&lt;/p&gt;&lt;p&gt;- A fully interactive browser window directly in the IDE so you can run your code without context switching&lt;/p&gt;&lt;p&gt;- A Jupyter-notebook-style environment - the idea here is you can write portions of your automation in individual cells and run them individually (and quickly reset manually in the browser), instead of having to rerun the whole thing every time&lt;/p&gt;&lt;p&gt;- An AI coding assistant which uses the DOM context of the current page to write automation logic, which helps avoid digging around for selectors&lt;/p&gt;&lt;p&gt;- Helper functions for taking screenshots, data extraction, and managed authentication for auth-required workflows.&lt;/p&gt;&lt;p&gt;Once you’ve created your automation, you can run it directly in the application or in our hosted environment via API, so you can use it in external apps or agentic workflows.&lt;/p&gt;&lt;p&gt;At its core, BrowserBook is an Electron app, so we can run a Chrome instance directly in the app without the need for cloud-hosted browsers. For API runs, we use hosted browser infra via Kernel (which is a fantastic product, btw), relying on their bot anti-detection capabilities (stealth mode, proxies, etc.).&lt;/p&gt;&lt;p&gt;Scripted automation can be unpopular because scripts are inherently brittle; unlike “traditional” software development, your code is deployed in an environment you don’t control - someone else’s website. With BrowserBook, we’re trying to “embrace the suck”, and acknowledge this “offensive programming” environment.&lt;/p&gt;&lt;p&gt;We’ve designed from the ground up to assume scripts will break, and aim to provide the tools that make building and maintaining them easier. In the future, our plan is to leverage AI where it has shown its strength already - writing code - to minimize downtime and quickly repair broken scripts as the deployed environment changes.&lt;/p&gt;&lt;p&gt;Browser agents promised to solve this by handing the reins to an LLM which can handle inconsistency and ambiguity. While we think there are some applications where browser agents can be genuinely helpful, tasks that need to be done reliably and repeatedly are not one of them.&lt;/p&gt;&lt;p&gt;We’d love for you to try it out! You can download BrowserBook from our website here: https://browserbook.com (only available for Mac so far, sorry!) And of course, we’d appreciate any feedback and comments you have!&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46232434</guid><pubDate>Thu, 11 Dec 2025 15:18:51 +0000</pubDate></item><item><title>iPhone Typos? It's Not Just You – The iOS Keyboard Is Broken [video]</title><link>https://www.youtube.com/watch?v=hksVvXONrIo</link><description>&lt;doc fingerprint="7055905545553646"&gt;
  &lt;main&gt;
    &lt;p&gt;About Press Copyright Contact us Creators Advertise Developers Terms Privacy Policy &amp;amp; Safety How YouTube works Test new features NFL Sunday Ticket © 2025 Google LLC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46232528</guid><pubDate>Thu, 11 Dec 2025 15:25:43 +0000</pubDate></item><item><title>Deprecate like you mean it</title><link>https://entropicthoughts.com/deprecate-like-you-mean-it</link><description>&lt;doc fingerprint="caef90947e61562e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Deprecate Like You Mean It&lt;/head&gt;
    &lt;p&gt; Seth Larson noticed that people don’t act on deprecation warnings. The &lt;code&gt;response.getheader&lt;/code&gt; method in &lt;code&gt;urllib&lt;/code&gt; has been deprecated since 2023 because
the &lt;code&gt;response.headers&lt;/code&gt; dictionary is what should be used instead. When the
method was eventually removed, lots of code broke.
&lt;/p&gt;
    &lt;p&gt;Deprecation warnings try to solve the fat step function associated with backwards-incompatible api changes, by allowing people to schedule the maintenance burden, rather than having it imposed on them suddenly all at once. The problem is the economic cost of waiting is not tangible. You can ignore the deprecation warning right up until the api change happens, and then it becomes very expensive to delay it further.&lt;/p&gt;
    &lt;p&gt;People aren’t great at planning for sudden changes.&lt;/p&gt;
    &lt;p&gt;What if we intentionally made deprecated functions return the wrong result … sometimes? Every time it intentionally returns the wrong result, it logs the deprecation warning.1 Users that are very sensitive to the correctness of the results might want to swap the wrong result for an artificial delay instead.&lt;/p&gt;
    &lt;p&gt;Initially, it should never return the wrong result. But after it’s been deprecated for a few months, it should start to return the wrong result once every million invocations, say. That would probably not trigger anyone’s midnight pager, but it would make it clear that relying on the deprecated functionality is a bug lurking in the code.&lt;/p&gt;
    &lt;p&gt;Then after a few more months, turn it up to once every ten thousand invocations. It’s probably going to start to hurt a little to delay the maintenance. After a year, make it return the wrong thing once every thousand invocations. At this point, users can only delay maintenance if it’s an unimportant auxiliary usage. And finally, as we bump up into the deadline, it should return the wrong thing every other invocation. Now it’s practically useless, just like when it is removed.&lt;/p&gt;
    &lt;p&gt;This makes the deprecated parts of the api increasingly buggy until they’re removed, and makes the economic tradeoff of when to schedule the maintenance more immediate to users.&lt;/p&gt;
    &lt;p&gt;In case the sarcasm isn’t clear, it’s better to leave the warts. But it is also worthwhile to recognise that in terms of effectiveness for driving system change, signage and warnings are on the bottom of the tier list. We should not be surprised when they don’t work.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46232898</guid><pubDate>Thu, 11 Dec 2025 15:52:30 +0000</pubDate></item><item><title>Show HN: Sim – Apache-2.0 n8n alternative</title><link>https://github.com/simstudioai/sim</link><description>&lt;doc fingerprint="189ff03c2161b5fe"&gt;
  &lt;main&gt;
    &lt;p&gt;Build and deploy AI agent workflows in minutes.&lt;/p&gt;
    &lt;p&gt;Design agent workflows visually on a canvas—connect agents, tools, and blocks, then run them instantly.&lt;/p&gt;
    &lt;p&gt;Leverage Copilot to generate nodes, fix errors, and iterate on flows directly from natural language.&lt;/p&gt;
    &lt;p&gt;Upload documents to a vector store and let agents answer questions grounded in your specific content.&lt;/p&gt;
    &lt;head rend="h3"&gt;Cloud-hosted: sim.ai&lt;/head&gt;
    &lt;code&gt;npx simstudio&lt;/code&gt;
    &lt;p&gt;Docker must be installed and running on your machine.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Flag&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;-p, --port &amp;lt;port&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Port to run Sim on (default &lt;code&gt;3000&lt;/code&gt;)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;--no-pull&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Skip pulling latest Docker images&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;# Clone the repository
git clone https://github.com/simstudioai/sim.git

# Navigate to the project directory
cd sim

# Start Sim
docker compose -f docker-compose.prod.yml up -d&lt;/code&gt;
    &lt;p&gt;Access the application at http://localhost:3000/&lt;/p&gt;
    &lt;p&gt;Run Sim with local AI models using Ollama - no external APIs required:&lt;/p&gt;
    &lt;code&gt;# Start with GPU support (automatically downloads gemma3:4b model)
docker compose -f docker-compose.ollama.yml --profile setup up -d

# For CPU-only systems:
docker compose -f docker-compose.ollama.yml --profile cpu --profile setup up -d&lt;/code&gt;
    &lt;p&gt;Wait for the model to download, then visit http://localhost:3000. Add more models with:&lt;/p&gt;
    &lt;code&gt;docker compose -f docker-compose.ollama.yml exec ollama ollama pull llama3.1:8b&lt;/code&gt;
    &lt;p&gt;If you already have Ollama running on your host machine (outside Docker), you need to configure the &lt;code&gt;OLLAMA_URL&lt;/code&gt; to use &lt;code&gt;host.docker.internal&lt;/code&gt; instead of &lt;code&gt;localhost&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;# Docker Desktop (macOS/Windows)
OLLAMA_URL=http://host.docker.internal:11434 docker compose -f docker-compose.prod.yml up -d

# Linux (add extra_hosts or use host IP)
docker compose -f docker-compose.prod.yml up -d  # Then set OLLAMA_URL to your host's IP&lt;/code&gt;
    &lt;p&gt;Why? When running inside Docker, &lt;code&gt;localhost&lt;/code&gt; refers to the container itself, not your host machine. &lt;code&gt;host.docker.internal&lt;/code&gt; is a special DNS name that resolves to the host.&lt;/p&gt;
    &lt;p&gt;For Linux users, you can either:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Use your host machine's actual IP address (e.g., &lt;code&gt;http://192.168.1.100:11434&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Add &lt;code&gt;extra_hosts: ["host.docker.internal:host-gateway"]&lt;/code&gt;to the simstudio service in your compose file&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Sim also supports vLLM for self-hosted models with OpenAI-compatible API:&lt;/p&gt;
    &lt;code&gt;# Set these environment variables
VLLM_BASE_URL=http://your-vllm-server:8000
VLLM_API_KEY=your_optional_api_key  # Only if your vLLM instance requires auth&lt;/code&gt;
    &lt;p&gt;When running with Docker, use &lt;code&gt;host.docker.internal&lt;/code&gt; if vLLM is on your host machine (same as Ollama above).&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Open VS Code with the Remote - Containers extension&lt;/item&gt;
      &lt;item&gt;Open the project and click "Reopen in Container" when prompted&lt;/item&gt;
      &lt;item&gt;Run &lt;code&gt;bun run dev:full&lt;/code&gt;in the terminal or use the&lt;code&gt;sim-start&lt;/code&gt;alias&lt;list rend="ul"&gt;&lt;item&gt;This starts both the main application and the realtime socket server&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Requirements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Bun runtime&lt;/item&gt;
      &lt;item&gt;PostgreSQL 12+ with pgvector extension (required for AI embeddings)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: Sim uses vector embeddings for AI features like knowledge bases and semantic search, which requires the &lt;code&gt;pgvector&lt;/code&gt; PostgreSQL extension.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Clone and install dependencies:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;git clone https://github.com/simstudioai/sim.git
cd sim
bun install&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Set up PostgreSQL with pgvector:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You need PostgreSQL with the &lt;code&gt;vector&lt;/code&gt; extension for embedding support. Choose one option:&lt;/p&gt;
    &lt;p&gt;Option A: Using Docker (Recommended)&lt;/p&gt;
    &lt;code&gt;# Start PostgreSQL with pgvector extension
docker run --name simstudio-db \
  -e POSTGRES_PASSWORD=your_password \
  -e POSTGRES_DB=simstudio \
  -p 5432:5432 -d \
  pgvector/pgvector:pg17&lt;/code&gt;
    &lt;p&gt;Option B: Manual Installation&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Install PostgreSQL 12+ and the pgvector extension&lt;/item&gt;
      &lt;item&gt;See pgvector installation guide&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Set up environment:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;cd apps/sim
cp .env.example .env  # Configure with required variables (DATABASE_URL, BETTER_AUTH_SECRET, BETTER_AUTH_URL)&lt;/code&gt;
    &lt;p&gt;Update your &lt;code&gt;.env&lt;/code&gt; file with the database URL:&lt;/p&gt;
    &lt;code&gt;DATABASE_URL="postgresql://postgres:your_password@localhost:5432/simstudio"&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Set up the database:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;First, configure the database package environment:&lt;/p&gt;
    &lt;code&gt;cd packages/db
cp .env.example .env &lt;/code&gt;
    &lt;p&gt;Update your &lt;code&gt;packages/db/.env&lt;/code&gt; file with the database URL:&lt;/p&gt;
    &lt;code&gt;DATABASE_URL="postgresql://postgres:your_password@localhost:5432/simstudio"&lt;/code&gt;
    &lt;p&gt;Then run the migrations:&lt;/p&gt;
    &lt;code&gt;bunx drizzle-kit migrate --config=./drizzle.config.ts&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Start the development servers:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Recommended approach - run both servers together (from project root):&lt;/p&gt;
    &lt;code&gt;bun run dev:full&lt;/code&gt;
    &lt;p&gt;This starts both the main Next.js application and the realtime socket server required for full functionality.&lt;/p&gt;
    &lt;p&gt;Alternative - run servers separately:&lt;/p&gt;
    &lt;p&gt;Next.js app (from project root):&lt;/p&gt;
    &lt;code&gt;bun run dev&lt;/code&gt;
    &lt;p&gt;Realtime socket server (from &lt;code&gt;apps/sim&lt;/code&gt; directory in a separate terminal):&lt;/p&gt;
    &lt;code&gt;cd apps/sim
bun run dev:sockets&lt;/code&gt;
    &lt;p&gt;Copilot is a Sim-managed service. To use Copilot on a self-hosted instance:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Go to https://sim.ai → Settings → Copilot and generate a Copilot API key&lt;/item&gt;
      &lt;item&gt;Set &lt;code&gt;COPILOT_API_KEY&lt;/code&gt;environment variable in your self-hosted apps/sim/.env file to that value&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Key environment variables for self-hosted deployments (see &lt;code&gt;apps/sim/.env.example&lt;/code&gt; for full list):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Variable&lt;/cell&gt;
        &lt;cell role="head"&gt;Required&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;DATABASE_URL&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;PostgreSQL connection string with pgvector&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;BETTER_AUTH_SECRET&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;Auth secret (&lt;code&gt;openssl rand -hex 32&lt;/code&gt;)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;BETTER_AUTH_URL&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;Your app URL (e.g., &lt;code&gt;http://localhost:3000&lt;/code&gt;)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;NEXT_PUBLIC_APP_URL&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;Public app URL (same as above)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;ENCRYPTION_KEY&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;Encryption key (&lt;code&gt;openssl rand -hex 32&lt;/code&gt;)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;OLLAMA_URL&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;Ollama server URL (default: &lt;code&gt;http://localhost:11434&lt;/code&gt;)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;VLLM_BASE_URL&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;vLLM server URL for self-hosted models&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;COPILOT_API_KEY&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;API key from sim.ai for Copilot features&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;If you're running Ollama on your host machine and Sim in Docker, change &lt;code&gt;OLLAMA_URL&lt;/code&gt; from &lt;code&gt;localhost&lt;/code&gt; to &lt;code&gt;host.docker.internal&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;OLLAMA_URL=http://host.docker.internal:11434 docker compose -f docker-compose.prod.yml up -d&lt;/code&gt;
    &lt;p&gt;See Using an External Ollama Instance for details.&lt;/p&gt;
    &lt;p&gt;Ensure PostgreSQL has the pgvector extension installed. When using Docker, wait for the database to be healthy before running migrations.&lt;/p&gt;
    &lt;p&gt;If ports 3000, 3002, or 5432 are in use, configure alternatives:&lt;/p&gt;
    &lt;code&gt;# Custom ports
NEXT_PUBLIC_APP_URL=http://localhost:3100 POSTGRES_PORT=5433 docker compose up -d&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Framework: Next.js (App Router)&lt;/item&gt;
      &lt;item&gt;Runtime: Bun&lt;/item&gt;
      &lt;item&gt;Database: PostgreSQL with Drizzle ORM&lt;/item&gt;
      &lt;item&gt;Authentication: Better Auth&lt;/item&gt;
      &lt;item&gt;UI: Shadcn, Tailwind CSS&lt;/item&gt;
      &lt;item&gt;State Management: Zustand&lt;/item&gt;
      &lt;item&gt;Flow Editor: ReactFlow&lt;/item&gt;
      &lt;item&gt;Docs: Fumadocs&lt;/item&gt;
      &lt;item&gt;Monorepo: Turborepo&lt;/item&gt;
      &lt;item&gt;Realtime: Socket.io&lt;/item&gt;
      &lt;item&gt;Background Jobs: Trigger.dev&lt;/item&gt;
      &lt;item&gt;Remote Code Execution: E2B&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We welcome contributions! Please see our Contributing Guide for details.&lt;/p&gt;
    &lt;p&gt;This project is licensed under the Apache License 2.0 - see the LICENSE file for details.&lt;/p&gt;
    &lt;p&gt;Made with ❤️ by the Sim Team&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46234186</guid><pubDate>Thu, 11 Dec 2025 17:20:11 +0000</pubDate></item><item><title>Litestream VFS</title><link>https://fly.io/blog/litestream-vfs/</link><description>&lt;doc fingerprint="67cf1ef5a02c7b1b"&gt;
  &lt;main&gt;
    &lt;p&gt;Iâm Ben Johnson, and I work on Litestream at Fly.io. Litestream is the missing backup/restore system for SQLite. Itâs free, open-source software that should run anywhere, and you can read more about it here.&lt;/p&gt;
    &lt;p&gt;Again with the sandwiches: assume we’ve got a SQLite database of sandwich ratings, and we’ve backed it up with Litestream to an S3 bucket.&lt;/p&gt;
    &lt;p&gt;Now, on our local host, load up AWS credentials and an S3 path into our environment. Open SQLite and:&lt;/p&gt;
    &lt;code&gt;$ sqlite3
SQLite version 3.50.4 2025-07-30 19:33:53
sqlite&amp;gt; .load litestream.so
sqlite&amp;gt; .open file:///my.db?vfs=litestream
&lt;/code&gt;
    &lt;p&gt;SQLite is now working from that remote database, defined by the Litestream backup files in the S3 path we configured. We can query it:&lt;/p&gt;
    &lt;code&gt;sqlite&amp;gt; SELECT * FROM sandwich_ratings ORDER BY RANDOM() LIMIT 3 ; 
22|Veggie Delight|New York|4
30|Meatball|Los Angeles|5
168|Chicken Shawarma Wrap|Detroit|5
&lt;/code&gt;
    &lt;p&gt;This is Litestream VFS. It runs SQLite hot off an object storage URL. As long as you can load the shared library our tree builds for you, it’ll work in your application the same way it does in the SQLite shell.&lt;/p&gt;
    &lt;p&gt;Fun fact: we didn’t have to download the whole database to run this query. More about this in a bit.&lt;/p&gt;
    &lt;p&gt;Meanwhile, somewhere in prod, someone has it in for meatball subs and wants to knock them out of the bracket â oh, fuck:&lt;/p&gt;
    &lt;code&gt;sqlite&amp;gt; UPDATE sandwich_ratings SET stars = 1 ;
&lt;/code&gt;
    &lt;p&gt;They forgot the &lt;code&gt;WHERE&lt;/code&gt; clause!&lt;/p&gt;
    &lt;code&gt;sqlite&amp;gt; SELECT * FROM sandwich_ratings ORDER BY RANDOM() LIMIT 3 ; 
97|French Dip|Los Angeles|1
140|BÃ¡nh MÃ¬|San Francisco|1
62|Italian Beef|Chicago|1
&lt;/code&gt;
    &lt;p&gt;Italian Beefs and BÃ¡nh MÃ¬s, all at 1 star. Disaster!&lt;/p&gt;
    &lt;p&gt;But wait, back on our dev machine:&lt;/p&gt;
    &lt;code&gt;sqlite&amp;gt; PRAGMA litestream_time = '5 minutes ago'; 
sqlite&amp;gt; select * from sandwich_ratings ORDER BY RANDOM() LIMIT 3 ; 
30|Meatball|Los Angeles|5
33|Ham &amp;amp; Swiss|Los Angeles|2
163|Chicken Shawarma Wrap|Detroit|5
&lt;/code&gt;
    &lt;p&gt;We’re now querying that database from a specific point in time in our backups. We can do arbitrary relative timestamps, or absolute ones, like &lt;code&gt;2000-01-01T00:00:00Z&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;What we’re doing here is instantaneous point-in-time recovery (PITR), expressed simply in SQL and SQLite pragmas.&lt;/p&gt;
    &lt;p&gt;Ever wanted to do a quick query against a prod dataset, but didn’t want to shell into a prod server and fumble with the &lt;code&gt;sqlite3&lt;/code&gt; terminal command like a hacker in an 80s movie? Or needed to do a quick sanity check against yesterday’s data, but without doing a full database restore? Litestream VFS makes that easy. I’m so psyched about how it turned out.&lt;/p&gt;
    &lt;head rend="h2"&gt;How It Works&lt;/head&gt;
    &lt;p&gt;Litestream v0.5 integrates LTX, our SQLite data-shipping file format. Where earlier Litestream blindly shipped whole raw SQLite pages to and from object storage, LTX ships ordered sets of pages. We built LTX for LiteFS, which uses a FUSE filesystem to do transaction-aware replication for unmodified applications, but we’ve spent this year figuring out ways to use LTX in Litestream, without all that FUSE drama.&lt;/p&gt;
    &lt;p&gt;The big thing LTX gives us is “compaction”. When we restore a database from object storage, we want the most recent versions of each changed database page. What we don’t want are all the intermediate versions of those pages that occurred prior to the most recent change.&lt;/p&gt;
    &lt;p&gt;Imagine, at the time we’re restoring, we’re going to need pages 1, 2, 3, 4, and 5. Depending on the order in which pages were written, the backup data set might look something like &lt;code&gt;1 2 3 5 3 5 4 5 5&lt;/code&gt;. What we want is the rightmost  5, 4, 3, 2, and 1, without wasting time on the four “extra” page 5’s and the one “extra” page 3. Those “extra” pages are super common in SQLite data sets; for instance, every busy table with an autoincrementing primary key will have them.&lt;/p&gt;
    &lt;p&gt;LTX lets us skip the redundant pages, and the algorithm is trivial: reading backwards from the end of the sequence, skipping any page you already read. This drastically accelerates restores.&lt;/p&gt;
    &lt;p&gt;But LTX compaction isn’t limited to whole databases. We can also LTX-compact sets of LTX files. That’s the key to how PITR restores with Litestream now work.&lt;/p&gt;
    &lt;p&gt;In the diagram below, we’re taking daily full snapshots. Below those snapshots are “levels” of changesets: groups of database pages from smaller and smaller windows of time. By default, Litestream uses time intervals of 1 hour at the highest level, down to 30 seconds at level 1. L0 is a special level where files are uploaded every second, but are only retained until being compacted to L1.&lt;/p&gt;
    &lt;p&gt;Now, let’s do a PITR restore. Start from the most proximal snapshot. Then determine the minimal set of LTX files from each level to reach the time you are restoring to.&lt;/p&gt;
    &lt;p&gt;We have another trick up our sleeve.&lt;/p&gt;
    &lt;p&gt;LTX trailers include a small index tracking the offset of each page in the file. By fetching only these index trailers from the LTX files we’re working with (each occupies about 1% of its LTX file), we can build a lookup table of every page in the database. Since modern object storage providers all let us fetch slices of files, we can perform individual page reads against S3 directly.&lt;/p&gt;
    &lt;head rend="h2"&gt;How It’s Implemented&lt;/head&gt;
    &lt;p&gt;SQLite has a plugin interface for things like this: the “VFS” interface. VFS plugins abstract away the bottom-most layer of SQLite, the interface to the OS. If you’re using SQLite now, you’re already using some VFS module, one SQLite happens to ship with.&lt;/p&gt;
    &lt;p&gt;For Litestream users, there’s a catch. From the jump, we’ve designed Litestream to run alongside unmodified SQLite applications. Part of what makes Litestream so popular is that your apps don’t even need to know it exists. It’s “just” a Unix program.&lt;/p&gt;
    &lt;p&gt;That Litestream Unix program still does PITR restores, without any magic. But to do fast PITR-style queries straight off S3, we need more. To make those queries work, you have to load and register Litestream’s VFS module.&lt;/p&gt;
    &lt;p&gt;But that’s all that changes.&lt;/p&gt;
    &lt;p&gt;In particular: Litestream VFS doesn’t replace the SQLite library you’re already using. It’s not a new “version” of SQLite. It’s just a plugin for the SQLite you’re already using.&lt;/p&gt;
    &lt;p&gt;Still, we know that’s not going to work for everybody, and even though we’re really psyched about these PITR features, we’re not taking our eyes off the ball on the rest of Litestream. You don’t have to use our VFS library to use Litestream, or to get the other benefits of the new LTX code.&lt;/p&gt;
    &lt;p&gt;The way a VFS library works, we’re given just a couple structures, each with a bunch of methods defined on them. We override only the few methods we care about. Litestream VFS handles only the read side of SQLite. Litestream itself, running as a normal Unix program, still handles the “write” side. So our VFS subclasses just enough to find LTX backups and issue queries.&lt;/p&gt;
    &lt;p&gt;With our VFS loaded, whenever SQLite needs to read a page into memory, it issues a &lt;code&gt;Read()&lt;/code&gt; call through our library. The read call includes the byte offset at which SQLite expected to find the page. But with Litestream VFS, that byte offset is an illusion.&lt;/p&gt;
    &lt;p&gt;Instead, we use our knowledge of the page size along with the requested page number to do a lookup on the page index we’ve built. From it, we get the remote filename, the “real” byte offset into that file, and the size of the page. That’s enough for us to use the S3 API’s &lt;code&gt;Range&lt;/code&gt; header handling to download exactly the block we want.&lt;/p&gt;
    &lt;p&gt;To save lots of S3 calls, Litestream VFS implements an LRU cache. Most databases have a small set of “hot” pages â inner branch pages or the leftmost leaf pages for tables with an auto-incrementing ID field. So only a small percentage of the database is updated and queried regularly.&lt;/p&gt;
    &lt;p&gt;Weâve got one last trick up our sleeve.&lt;/p&gt;
    &lt;p&gt;Quickly building an index and restore plan for the current state of a database is cool. But we can do one better.&lt;/p&gt;
    &lt;p&gt;Because Litestream backs up (into the L0 layer) once per second, the VFS code can simply poll the S3 path, and then incrementally update its index. The result is a near-realtime replica. Better still, you donât need to stream the whole database back to your machine before you use it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Eat Your Heart Out, Marty McFly&lt;/head&gt;
    &lt;p&gt;Litestream holds backup files for every state your database has been in, with single-second resolution, for as long as you want it to. Forgot the &lt;code&gt;WHERE&lt;/code&gt; clause on a &lt;code&gt;DELETE&lt;/code&gt; statement? Updating your database state to where it was an hour (or day, or week) ago is just a matter of adjusting the LTX indices Litestream manages.&lt;/p&gt;
    &lt;p&gt;All this smoke-and-mirrors of querying databases without fully fetching them has another benefit: it starts up really fast! We’re living an age of increasingly ephemeral servers, what with the AIs and the agents and the clouds and the hoyvin-glavins. Wherever you find yourself, if your database is backed up to object storage with Litestream, you’re always in a place where you can quickly issue a query.&lt;/p&gt;
    &lt;p&gt;As always, one of the big things we think we’re doing right with Litestream is: we’re finding ways to get as much whiz-bang value as we can (instant PITR reading live off object storage: pretty nifty!) while keeping the underlying mechanism simple enough that you can fit your head around it.&lt;/p&gt;
    &lt;p&gt;Litestream is solid for serious production use (we rely on it for important chunks of our own Fly.io APIs). But you could write Litestream yourself, just from the basic ideas in these blog posts. We think that’s a point in its favor. We land there because the heavy lifting in Litestream is being done by SQLite itself, which is how it should be.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46234710</guid><pubDate>Thu, 11 Dec 2025 17:59:10 +0000</pubDate></item><item><title>GPT-5.2</title><link>https://openai.com/index/introducing-gpt-5-2/</link><description>&lt;doc fingerprint="285fa2d92df7ce9f"&gt;
  &lt;main&gt;
    &lt;p&gt;We are introducing GPT‑5.2, the most capable model series yet for professional knowledge work.&lt;/p&gt;
    &lt;p&gt;Already, the average ChatGPT Enterprise user says AI saves them 40–60 minutes a day, and heavy users say it saves them more than 10 hours a week. We designed GPT‑5.2 to unlock even more economic value for people; it’s better at creating spreadsheets, building presentations, writing code, perceiving images, understanding long contexts, using tools, and handling complex, multi-step projects.&lt;/p&gt;
    &lt;p&gt;GPT‑5.2 sets a new state of the art across many benchmarks, including GDPval, where it outperforms industry professionals at well-specified knowledge work tasks spanning 44 occupations.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;GPT‑5.2 Thinking&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;GPT‑5.1 Thinking&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;GDPval (wins or ties)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;70.9%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;38.8% (GPT‑5)&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;SWE-Bench Pro (public)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;55.6%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;50.8%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;SWE-bench Verified&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;80.0%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;76.3%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;GPQA Diamond (no tools)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;92.4%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;88.1%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;CharXiv Reasoning (w/ Python)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;88.7%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;80.3%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;AIME 2025 (no tools)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;100.0%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;94.0%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;FrontierMath (Tier 1–3)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;40.3%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;31.0%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;FrontierMath (Tier 4)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;14.6%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;12.5%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;ARC-AGI-1 (Verified)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;86.2%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;72.8%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;ARC-AGI-2 (Verified)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;52.9%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;17.6%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Notion(opens in a new window), Box(opens in a new window), Shopify(opens in a new window), Harvey(opens in a new window) and Zoom(opens in a new window) observed GPT‑5.2 demonstrates state-of-the-art long-horizon reasoning and tool-calling performance. Databricks(opens in a new window), Hex(opens in a new window) and Triple Whale(opens in a new window) found GPT‑5.2 to be exceptional at agentic data science and document analysis tasks. Cognition(opens in a new window), Warp(opens in a new window), Charlie Labs(opens in a new window), JetBrains(opens in a new window) and Augment Code(opens in a new window) say GPT‑5.2 delivers state-of-the-art agentic coding performance, with measurable improvements in areas such as interactive coding, code reviews and bug finding.&lt;/p&gt;
    &lt;p&gt;In ChatGPT, GPT‑5.2 Instant, Thinking, and Pro will begin rolling out today, starting with paid plans. In the API, they are available now to all developers.&lt;/p&gt;
    &lt;p&gt;Overall, GPT‑5.2 brings significant improvements in general intelligence, long-context understanding, agentic tool-calling, and vision—making it better at executing complex, real-world tasks end-to-end than any previous model.&lt;/p&gt;
    &lt;p&gt;GPT‑5.2 Thinking is the best model yet for real-world, professional use. On GDPval, an eval measuring well-specified knowledge work tasks across 44 occupations, GPT‑5.2 Thinking sets a new state-of-the-art score, and is our first model that performs at or above a human expert level. Specifically, GPT‑5.2 Thinking beats or ties top industry professionals on 70.9% of comparisons on GDPval knowledge work tasks, according to expert human judges. These tasks include making presentations, spreadsheets, and other artifacts. GPT‑5.2 Thinking produced outputs for GDPval tasks at &amp;gt;11x the speed and &amp;lt;1% the cost of expert professionals, suggesting that when paired with human oversight, GPT‑5.2 can help with professional work. Speed and cost estimates are based on historical metrics; speed in ChatGPT may vary.&lt;/p&gt;
    &lt;p&gt;When reviewing one especially good output, one GDPval judge commented, "It is an exciting and noticeable leap in output quality... [it] appears to have been done by a professional company with staff, and has a surprisingly well designed layout and advice for both deliverables, though with one we still have some minor errors to correct."&lt;/p&gt;
    &lt;p&gt;Additionally, on our internal benchmark of junior investment banking analyst spreadsheet modeling tasks—such as putting together a three-statement model for a Fortune 500 company with proper formatting and citations, or building a leveraged buyout model for a take-private—GPT 5.2 Thinking's average score per task is 9.3% higher than GPT‑5.1’s, rising from 59.1% to 68.4%.&lt;/p&gt;
    &lt;p&gt;Side-by-side comparisons show improved sophistication and formatting in spreadsheets and slides generated by GPT‑5.2 Thinking:&lt;/p&gt;
    &lt;p&gt;To use the new spreadsheet and presentation capabilities in ChatGPT, you must be on a Plus, Pro, Business, or Enterprise plan and select either GPT‑5.2 Thinking or Pro. Complex generations can take many minutes to produce.&lt;/p&gt;
    &lt;p&gt;GPT‑5.2 Thinking sets a new state of the art of 55.6% on SWE-Bench Pro, a rigorous evaluation of real-world software engineering. Unlike SWE-bench Verified, which only tests Python, SWE-Bench Pro tests four languages and aims to be more contamination-resistant, challenging, diverse, and industrially relevant.&lt;/p&gt;
    &lt;p&gt;On SWE-bench Verified (not plotted), GPT‑5.2 Thinking scores our new high of 80%.&lt;/p&gt;
    &lt;p&gt;For everyday professional use, this translates into a model that can more reliably debug production code, implement feature requests, refactor large codebases, and ship fixes end-to-end with less manual intervention.&lt;/p&gt;
    &lt;p&gt;GPT‑5.2 Thinking is also better at front-end software engineering than GPT‑5.1 Thinking. Early testers found it significantly stronger at front-end development and complex or unconventional UI work—especially involving 3D elements—making it a powerful daily partner for engineers across the stack. See a few examples of what it can produce from a single prompt:&lt;/p&gt;
    &lt;p&gt;Early testers shared their feedback on GPT‑5.2’s coding capabilities:&lt;/p&gt;
    &lt;quote&gt;"GPT-5.2 represents the biggest leap for GPT models in agentic coding since GPT-5 and is a SOTA coding model in its price range. The version bump undersells the jump in intelligence. We’re excited to make it the default across Windsurf and several core Devin workloads."&lt;/quote&gt;
    &lt;p&gt;GPT‑5.2 Thinking hallucinates less than GPT‑5.1 Thinking. On a set of de-identified queries from ChatGPT, responses with errors were 30%rel less common. For professionals, this means fewer mistakes when using the model for research, writing, analysis, and decision support—making the model more dependable for everyday knowledge work.&lt;/p&gt;
    &lt;p&gt;Like all models, GPT‑5.2 Thinking is imperfect. For anything critical, double check its answers.&lt;/p&gt;
    &lt;p&gt;GPT‑5.2 Thinking sets a new state of the art in long-context reasoning, achieving leading performance on OpenAI MRCRv2—an evaluation that tests a model’s ability to integrate information spread across long documents. On real-world tasks like deep document analysis, which require related information across hundreds of thousands of tokens, GPT‑5.2 Thinking is substantially more accurate than GPT‑5.1 Thinking. In particular, it’s the first model we’ve seen that achieves near 100% accuracy on the 4-needle MRCR variant (out to 256k tokens).&lt;/p&gt;
    &lt;p&gt;In practical terms, this enables professionals to use GPT‑5.2 to work with long documents—such as reports, contracts, research papers, transcripts, and multi-file projects—while maintaining coherence and accuracy across hundreds of thousands of tokens. This makes GPT‑5.2 especially well suited for deep analysis, synthesis, and complex multi-source workflows.&lt;/p&gt;
    &lt;p&gt;For tasks that benefit from thinking beyond the maximum context window, GPT‑5.2 Thinking is compatible with our new Responses &lt;code&gt;/compact&lt;/code&gt; endpoint, which extends the model’s effective context window. This lets GPT‑5.2 Thinking tackle more tool-heavy, long-running workflows that would otherwise be limited by context length. Read more in our API documentation(opens in a new window).&lt;/p&gt;
    &lt;p&gt;GPT‑5.2 Thinking is our strongest vision model yet, cutting error rates roughly in half on chart reasoning and software interface understanding.&lt;/p&gt;
    &lt;p&gt;For everyday professional use, this means the model can more accurately interpret dashboards, product screenshots, technical diagrams, and visual reports—supporting workflows in finance, operations, engineering, design, and customer support where visual information is central.&lt;/p&gt;
    &lt;p&gt;Compared to previous models, GPT‑5.2 Thinking has a stronger grasp of how elements are positioned within an image, which helps on tasks where relative layout plays a key role in solving the problem. In the example below, we ask the model to identify the components in an image input (in this case, a motherboard) and return labels with approximate bounding boxes. Even on a low-quality image, GPT‑5.2 identifies the main regions and places boxes that sometimes match the true locations of each component, while GPT‑5.1 only labels a few parts and shows a much weaker understanding of their spatial arrangement. Both models make clear mistakes, but GPT‑5.2 shows better comprehension of the image.&lt;/p&gt;
    &lt;head rend="h5"&gt;GPT-5.1&lt;/head&gt;
    &lt;head rend="h5"&gt;GPT-5.2&lt;/head&gt;
    &lt;p&gt;GPT‑5.2 Thinking achieves a new state of the art of 98.7% on Tau2-bench Telecom, demonstrating its ability to reliably use tools across long, multi-turn tasks.&lt;/p&gt;
    &lt;p&gt;For latency-sensitive use cases, GPT‑5.2 Thinking also performs much better at reasoning.effort='none', substantially outperforming GPT‑5.1 and GPT‑4.1.&lt;/p&gt;
    &lt;p&gt;For professionals, this translates into stronger end-to-end workflows—such as resolving customer support cases, pulling data from multiple systems, running analyses, and generating final outputs with fewer breakdowns between steps.&lt;/p&gt;
    &lt;p&gt;For example, when asking a complex customer service question that requires multi-step resolution, the model can more effectively coordinate a full workflow across multiple agents. In the case below, a traveler reports a delayed flight, a missed connection, an overnight stay in New York, and a medical seating requirement. GPT‑5.2 manages the entire chain of tasks—rebooking, special-assistance seating, and compensation—delivering a more complete outcome than GPT‑5.1.&lt;/p&gt;
    &lt;head rend="h5"&gt;GPT-5.1&lt;/head&gt;
    &lt;head rend="h5"&gt;GPT-5.2&lt;/head&gt;
    &lt;p&gt;One of our hopes for AI is that it will accelerate scientific research for the benefit of everyone. Toward this, we’ve been working with and listening to scientists to see how AI can speed up their work, and last month we shared some early collaborative experiments here.&lt;/p&gt;
    &lt;p&gt;We believe GPT‑5.2 Pro and GPT‑5.2 Thinking are the world’s best models for assisting and accelerating scientists. On GPQA Diamond, a graduate-level Google-proof Q&amp;amp;A benchmark, GPT‑5.2 Pro achieves 93.2%, followed closely by GPT‑5.2 Thinking at 92.4%.&lt;/p&gt;
    &lt;p&gt;On FrontierMath (Tier 1–3), an evaluation of expert-level mathematics, GPT‑5.2 Thinking set a new state of the art, solving 40.3% of problems.&lt;/p&gt;
    &lt;p&gt;We're beginning to see AI models meaningfully accelerate progress in math and science in tangible ways. For example, in recent work with GPT‑5.2 Pro, researchers explored an open question in statistical learning theory. In a narrow, well-specified setting, the model proposed a proof that was subsequently verified by the authors and reviewed with external experts, illustrating how frontier models can assist mathematical research under close human oversight.&lt;/p&gt;
    &lt;p&gt;On ARC-AGI-1 (Verified), a benchmark designed to measure general reasoning ability, GPT‑5.2 Pro is the first model to cross the 90% threshold, improving from 87%(opens in a new window) by o3‑preview last year while reducing the cost of achieving that performance by roughly 390×.&lt;/p&gt;
    &lt;p&gt;On ARC-AGI-2 (Verified), which raises the difficulty and better isolates fluid reasoning, GPT‑5.2 Thinking achieves a new state of the art for chain-of-thought models, scoring 52.9%. GPT‑5.2 Pro performs even higher, reaching 54.2%, further extending the model’s ability to reason through novel, abstract problems.&lt;/p&gt;
    &lt;p&gt;Improvements across these evaluations reflect GPT‑5.2’s stronger multi-step reasoning, greater quantitative accuracy, and more reliable problem solving on complex technical tasks.&lt;/p&gt;
    &lt;p&gt;Here’s what our early testers say about GPT‑5.2:&lt;/p&gt;
    &lt;quote&gt;"GPT-5.2 unlocked a complete architecture shift for us. We collapsed a fragile, multi-agent system into a single mega-agent with 20+ tools. The best part is, it just works. The mega-agent is faster, smarter, and 100x easier to maintain. We’re seeing dramatically lower latency, much stronger tool calling, and we no longer need sprawling system prompts because 5.2 will execute cleanly off a simple, one-line prompt. It feels like pure magic."&lt;/quote&gt;
    &lt;p&gt;In ChatGPT, users should notice GPT‑5.2 feels better to use day to day—more structured, more reliable, and still enjoyable to talk to.&lt;/p&gt;
    &lt;p&gt;GPT‑5.2 Instant is a fast, capable workhorse for everyday work and learning, with clear improvements in info-seeking questions, how-tos and walk-throughs, technical writing, and translation, building on the warmer conversational tone introduced in GPT‑5.1 Instant. Early testers particularly noted clearer explanations that surface key information upfront.&lt;/p&gt;
    &lt;p&gt;GPT‑5.2 Thinking is designed for deeper work, helping users tackle more complex tasks with greater polish—especially for coding, summarizing long documents, answering questions about uploaded files, working through math and logic step by step, and supporting planning and decisions with clearer structure and more useful detail.&lt;/p&gt;
    &lt;p&gt;GPT‑5.2 Pro is our smartest and most trustworthy option for difficult questions where a higher-quality answer is worth the wait, with early testing showing fewer major errors and stronger performance in complex domains like programming.&lt;/p&gt;
    &lt;p&gt;GPT‑5.2 builds on the safe completion research we introduced with GPT‑5, which teaches the model to give the most helpful answer while still staying within safety boundaries.&lt;/p&gt;
    &lt;p&gt;With this release, we continued our work to strengthen our models’ responses in sensitive conversations, with meaningful improvements in how they respond to prompts indicating signs of suicide or self harm, mental health distress, or emotional reliance on the model. These targeted interventions have resulted in fewer undesirable responses in both GPT‑5.2 Instant and GPT‑5.2 Thinking as compared to GPT‑5.1 and GPT‑5 Instant and Thinking models. Further details can be found in the system card.&lt;/p&gt;
    &lt;p&gt;We’re in the early stages of rolling out our age prediction model so that we can automatically apply content protections for users who are under 18, in order to limit access to sensitive content. This builds on our existing approach to users we know are under 18 and our parental controls.&lt;/p&gt;
    &lt;p&gt;GPT‑5.2 is one step in an ongoing series of improvements, and we’re far from done. While this release delivers meaningful gains in intelligence and productivity, we know there are areas where people want more. In ChatGPT, we’re working on known issues like over-refusals, while continuing to raise the bar on safety and reliability overall. These changes are complex, and we’re focused on getting them right.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;
          &lt;p&gt;GPT‑5.2&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;GPT‑5.1 &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;GPT‑5.2 &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;GPT‑5.1 &lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;
          &lt;p&gt;Mental health&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;0.995&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;0.883&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;0.915&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;0.684&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;
          &lt;p&gt;Emotional reliance&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;0.938&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;0.945&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;0.955&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;0.785&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Self-harm&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;0.938&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;0.925&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;0.963&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;0.937&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;In ChatGPT, we’ll begin rolling out GPT‑5.2 (Instant, Thinking, and Pro) today, starting with paid plans (Plus, Pro, Go, Business, Enterprise). We deploy GPT‑5.2 gradually to keep ChatGPT as smooth and reliable as we can; if you don’t see it at first, please try again later. In ChatGPT, GPT‑5.1 will still be available to paid users for three months under legacy models, after which we will sunset GPT‑5.1.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;ChatGPT&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;API&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;ChatGPT‑5.2 Instant&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;GPT‑5.2-chat-latest&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;ChatGPT‑5.2 Thinking&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;GPT‑5.2&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;ChatGPT‑5.2 Pro&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;GPT‑5.2 Pro&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;In our API Platform, GPT‑5.2 Thinking is available today in the Responses API and Chat Completions API as &lt;code&gt;gpt-5.2&lt;/code&gt;, and GPT‑5.2 Instant as &lt;code&gt;gpt-5.2-chat-latest&lt;/code&gt;. GPT‑5.2 Pro is available in the Responses API as &lt;code&gt;gpt-5.2-pro&lt;/code&gt;. Developers can now set the reasoning parameter in GPT‑5.2 Pro, and both GPT‑5.2 Pro and GPT‑5.2 Thinking now support the new fifth reasoning effort of xhigh, for tasks where quality is most important.&lt;/p&gt;
    &lt;p&gt;GPT‑5.2 is priced at $1.75/1M input tokens and $14/1M output tokens, with a 90% discount on cached inputs. On multiple agentic evals, we found that despite GPT‑5.2’s greater cost per token, the cost of attaining a given level of quality ended up less expensive due to GPT‑5.2’s greater token efficiency.&lt;/p&gt;
    &lt;p&gt;While ChatGPT subscription pricing remains the same, in the API GPT‑5.2 is priced higher per token than GPT‑5.1 because it is a more capable model. It’s still priced below other frontier models, so people can continue to use it deeply in their daily work and core applications.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;p&gt;Model&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Input&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Cached input&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Output&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;p&gt;gpt-5.2 / &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$1.75&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$0.175&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$14&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;p&gt;gpt-5.2-pro&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$21&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;-&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$168&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;p&gt;gpt-5.1 / &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$1.25&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$0.125&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$10&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;gpt-5-pro&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$15&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;-&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$120&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;We have no current plans to deprecate GPT‑5.1, GPT‑5, or GPT‑4.1 in the API and will communicate any deprecation plans with ample advance notice for developers. While GPT‑5.2 will work well out of the box in Codex, we expect to release a version of GPT‑5.2 optimized for Codex in the coming weeks.&lt;/p&gt;
    &lt;p&gt;GPT‑5.2 was built in collaboration with our long-standing partners NVIDIA and Microsoft. Azure data centers and NVIDIA GPUs, including H100, H200, and GB200-NVL72, underpin OpenAI’s at-scale training infrastructure, driving significant gains in model intelligence. Together, this collaboration allows us to scale compute with confidence and bring new models to market more quickly.&lt;/p&gt;
    &lt;p&gt;Below, we report comprehensive benchmark scores for GPT‑5.2 Thinking, along with a subset for GPT‑5.2 Pro.&lt;/p&gt;
    &lt;head rend="h5"&gt;Professional&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;GPT-5.2 Thinking&lt;/cell&gt;
        &lt;cell role="head"&gt;GPT-5.2 Pro&lt;/cell&gt;
        &lt;cell role="head"&gt;GPT-5.1 Thinking&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;GDPval (ties allowed, wins or ties)&lt;/cell&gt;
        &lt;cell&gt;70.9%&lt;/cell&gt;
        &lt;cell&gt;74.1%&lt;/cell&gt;
        &lt;cell&gt;38.8% (GPT-5)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;GDPval (ties allowed, clear wins)&lt;/cell&gt;
        &lt;cell&gt;49.8%&lt;/cell&gt;
        &lt;cell&gt;60.0%&lt;/cell&gt;
        &lt;cell&gt;35.5% (GPT-5)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;GDPval (no ties)&lt;/cell&gt;
        &lt;cell&gt;61.0%&lt;/cell&gt;
        &lt;cell&gt;67.6%&lt;/cell&gt;
        &lt;cell&gt;37.1% (GPT-5)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Investment banking spreadsheet tasks (internal)&lt;/cell&gt;
        &lt;cell&gt;68.4%&lt;/cell&gt;
        &lt;cell&gt;71.7%&lt;/cell&gt;
        &lt;cell&gt;59.1%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h5"&gt;Coding&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;GPT-5.2 Thinking&lt;/cell&gt;
        &lt;cell role="head"&gt;GPT-5.2 Pro&lt;/cell&gt;
        &lt;cell role="head"&gt;GPT-5.1 Thinking&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;SWE-Bench Pro, Public&lt;/cell&gt;
        &lt;cell&gt;55.6%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;50.8%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;SWE-bench Verified&lt;/cell&gt;
        &lt;cell&gt;80.0%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;76.3%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;SWE-Lancer, IC Diamond*&lt;/cell&gt;
        &lt;cell&gt;74.6%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;69.7%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h5"&gt;Factuality&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;GPT-5.2 Thinking&lt;/cell&gt;
        &lt;cell role="head"&gt;GPT-5.2 Pro&lt;/cell&gt;
        &lt;cell role="head"&gt;GPT-5.1 Thinking&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;ChatGPT answers without errors (w/ search)&lt;/cell&gt;
        &lt;cell&gt;93.9%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;91.2%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;ChatGPT answers without errors (no search)&lt;/cell&gt;
        &lt;cell&gt;88.0%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;87.3%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h5"&gt;Long context&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;GPT-5.2 Thinking&lt;/cell&gt;
        &lt;cell role="head"&gt;GPT-5.2 Pro&lt;/cell&gt;
        &lt;cell role="head"&gt;GPT-5.1 Thinking&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;OpenAI MRCRv2, 8 needles, 4k–8k&lt;/cell&gt;
        &lt;cell&gt;98.2%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;65.3%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;OpenAI MRCRv2, 8 needles, 8k–16k&lt;/cell&gt;
        &lt;cell&gt;89.3%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;47.8%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;OpenAI MRCRv2, 8 needles, 16k–32k&lt;/cell&gt;
        &lt;cell&gt;95.3%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;44.0%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;OpenAI MRCRv2, 8 needles, 32k–64k&lt;/cell&gt;
        &lt;cell&gt;92.0%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;37.8%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;OpenAI MRCRv2, 8 needles, 64k–128k&lt;/cell&gt;
        &lt;cell&gt;85.6%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;36.0%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;OpenAI MRCRv2, 8 needles, 128k–256k&lt;/cell&gt;
        &lt;cell&gt;77.0%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;29.6%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;BrowseComp Long Context 128k&lt;/cell&gt;
        &lt;cell&gt;92.0%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;90.0%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;BrowseComp Long Context 256k&lt;/cell&gt;
        &lt;cell&gt;89.8%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;89.5%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;GraphWalks bfs &amp;lt;128k&lt;/cell&gt;
        &lt;cell&gt;94.0%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;76.8%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Graphwalks parents &amp;lt;128k&lt;/cell&gt;
        &lt;cell&gt;89.0%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;71.5%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h5"&gt;Vision&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;GPT-5.2 Thinking&lt;/cell&gt;
        &lt;cell role="head"&gt;GPT-5.2 Pro&lt;/cell&gt;
        &lt;cell role="head"&gt;GPT-5.1 Thinking&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;CharXiv reasoning (no tools)&lt;/cell&gt;
        &lt;cell&gt;82.1%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;67.0%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;CharXiv reasoning (w/ Python)&lt;/cell&gt;
        &lt;cell&gt;88.7%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;80.3%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;MMMU Pro (no tools)&lt;/cell&gt;
        &lt;cell&gt;79.5%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;MMMU Pro (w/ Python)&lt;/cell&gt;
        &lt;cell&gt;80.4%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;79.0%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Video MMMU (no tools)&lt;/cell&gt;
        &lt;cell&gt;85.9%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;82.9%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Screenspot Pro (w/ Python)&lt;/cell&gt;
        &lt;cell&gt;86.3%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;64.2%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h5"&gt;Tool usage&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;GPT-5.2 Thinking&lt;/cell&gt;
        &lt;cell role="head"&gt;GPT-5.2 Pro&lt;/cell&gt;
        &lt;cell role="head"&gt;GPT-5.1 Thinking&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Tau2-bench Telecom&lt;/cell&gt;
        &lt;cell&gt;98.7%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;95.6%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Tau2-bench Retail&lt;/cell&gt;
        &lt;cell&gt;82.0%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;77.9%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;BrowseComp&lt;/cell&gt;
        &lt;cell&gt;65.8%&lt;/cell&gt;
        &lt;cell&gt;77.9%&lt;/cell&gt;
        &lt;cell&gt;50.8%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Scale MCP-Atlas&lt;/cell&gt;
        &lt;cell&gt;60.6%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;44.5%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Toolathlon&lt;/cell&gt;
        &lt;cell&gt;46.3%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;36.1%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h5"&gt;Academic&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;GPT-5.2 Thinking&lt;/cell&gt;
        &lt;cell role="head"&gt;GPT-5.2 Pro&lt;/cell&gt;
        &lt;cell role="head"&gt;GPT-5.1 Thinking&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;GPQA Diamond (no tools)&lt;/cell&gt;
        &lt;cell&gt;92.4%&lt;/cell&gt;
        &lt;cell&gt;93.2%&lt;/cell&gt;
        &lt;cell&gt;88.1%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;HLE (no tools)&lt;/cell&gt;
        &lt;cell&gt;34.5%&lt;/cell&gt;
        &lt;cell&gt;36.6%&lt;/cell&gt;
        &lt;cell&gt;25.7%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;HLE (w/ search, Python)&lt;/cell&gt;
        &lt;cell&gt;45.5%&lt;/cell&gt;
        &lt;cell&gt;50.0%&lt;/cell&gt;
        &lt;cell&gt;42.7%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;MMMLU&lt;/cell&gt;
        &lt;cell&gt;89.6%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;89.5%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;HMMT, Feb 2025 (no tools)&lt;/cell&gt;
        &lt;cell&gt;99.4%&lt;/cell&gt;
        &lt;cell&gt;100.0%&lt;/cell&gt;
        &lt;cell&gt;96.3%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;AIME 2025 (no tools)&lt;/cell&gt;
        &lt;cell&gt;100.0%&lt;/cell&gt;
        &lt;cell&gt;100.0%&lt;/cell&gt;
        &lt;cell&gt;94.0%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;FrontierMath Tier 1–3 (w/ Python)&lt;/cell&gt;
        &lt;cell&gt;40.3%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;31.0%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;FrontierMath Tier 4 (w/ Python)&lt;/cell&gt;
        &lt;cell&gt;14.6%&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;12.5%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h5"&gt;Abstract reasoning&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;GPT-5.2 Thinking&lt;/cell&gt;
        &lt;cell role="head"&gt;GPT-5.2 Pro&lt;/cell&gt;
        &lt;cell role="head"&gt;GPT-5.1 Thinking&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;ARC-AGI-1 (Verified)&lt;/cell&gt;
        &lt;cell&gt;86.2%&lt;/cell&gt;
        &lt;cell&gt;90.5%&lt;/cell&gt;
        &lt;cell&gt;72.8%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;ARC-AGI-2 (Verified)&lt;/cell&gt;
        &lt;cell&gt;52.9%&lt;/cell&gt;
        &lt;cell&gt;54.2% (high)&lt;/cell&gt;
        &lt;cell&gt;17.6%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Models were run with maximum available reasoning effort in our API (xhigh for GPT‑5.2 Thinking &amp;amp; Pro, and high for GPT‑5.1 Thinking), except for the professional evals, where GPT‑5.2 Thinking was run with reasoning effort heavy, the maximum available in ChatGPT Pro. Benchmarks were conducted in a research environment, which may provide slightly different output from production ChatGPT in some cases.&lt;/p&gt;
    &lt;p&gt;* For SWE-Lancer, we omit 40/237 problems that did not run on our infrastructure.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46234788</guid><pubDate>Thu, 11 Dec 2025 18:04:47 +0000</pubDate></item><item><title>Programmers and software developers lost the plot on naming their tools</title><link>https://larr.net/p/namings.html</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46234806</guid><pubDate>Thu, 11 Dec 2025 18:06:42 +0000</pubDate></item><item><title>Rivian Unveils Custom Silicon, R2 Lidar Roadmap, and Universal Hands Free</title><link>https://riviantrackr.com/news/rivian-unveils-custom-silicon-r2-lidar-roadmap-universal-hands-free-and-its-next-gen-autonomy-platform/</link><description>&lt;doc fingerprint="d8731330b82ec9c9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Rivian Unveils Custom Silicon, R2 LiDAR Roadmap, Universal Hands Free, and Its Next Gen Autonomy Platform&lt;/head&gt;
    &lt;p&gt;RJ opened the first ever Autonomy and AI Day explaining why Rivian believes it is positioned to lead in this next phase of the industry. The company is leaning hard into compute, custom hardware, large scale AI systems, and a shared data foundation that touches every part of the ownership experience.&lt;/p&gt;
    &lt;p&gt;Let’s break it all down.&lt;/p&gt;
    &lt;head rend="h2"&gt;Meet the Rivian Autonomy Processor&lt;/head&gt;
    &lt;p&gt;One of the biggest announcements was RAP1, Rivian’s first in house processor built on a 5nm multi chip module. It delivers 1600 sparse INT8 TOPS and can push 5 billion pixels per second inside the new Gen 3 Autonomy Computer. Rivian even built its own AI compiler and platform software to support it. This shows Rivian is no longer just integrating off the shelf chips, it is now designing silicon specifically for its autonomy roadmap.&lt;/p&gt;
    &lt;head rend="h2"&gt;Autonomy Computer and LiDAR on R2&lt;/head&gt;
    &lt;p&gt;The ACM3 (Autonomy Compute Module 3) autonomy computer will debut on R2 starting at the end of 2026, but Rivian made it clear that R2 will launch initially without LiDAR. What Rivian confirmed today is that LiDAR will be added later in the program. This lines up with what we explored back in May when we spotted early signs that Rivian was evaluating LiDAR as a redundancy and ground truth layer for future autonomy. Rivian has now officially validated that LiDAR is coming to R2 down the road, where it will join cameras and radar to create a richer, more resilient perception stack.&lt;/p&gt;
    &lt;head rend="h2"&gt;Large Driving Model and Rivian’s Data Loop&lt;/head&gt;
    &lt;p&gt;Rivian explained how its autonomy stack is powered by a self improving data loop feeding the company’s Large Driving Model, which is trained similarly to an LLM. Reinforcement learning distills high quality driving behavior into efficient onboard models. Every release improves the system, and Rivian laid out a trajectory that moves toward point to point, eyes off and eventually personal Level 4.&lt;/p&gt;
    &lt;head rend="h2"&gt;Universal Hands Free Coming to Gen 2&lt;/head&gt;
    &lt;p&gt;Rivian confirmed that a major software update will bring Universal Hands Free to Gen 2 R1T and R1S. This hands free experience will cover over 3.5 million miles of roads across the US and Canada as long as there are clearly painted lane lines. It is a huge expansion of the assisted driving envelope for current owners.&lt;/p&gt;
    &lt;head rend="h2"&gt;Autonomy+ Sub Launching in 2026&lt;/head&gt;
    &lt;p&gt;Rivian also announced Autonomy+, an autonomy tier with continuously expanding features launching early 2026.&lt;/p&gt;
    &lt;p&gt;Pricing is $2,500 one time or $49.99 per month.&lt;/p&gt;
    &lt;head rend="h2"&gt;Rivian Unified Intelligence&lt;/head&gt;
    &lt;p&gt;Rivian is reorganizing its entire platform around Rivian Unified Intelligence, a data foundation that ties together telemetry, cloud models, service systems and customer facing features. It is the backbone for predictive maintenance, smarter diagnostics and upcoming AI driven tools.&lt;/p&gt;
    &lt;head rend="h2"&gt;Rivian Assistant Coming in 2026&lt;/head&gt;
    &lt;p&gt;Rivian also officially unveiled its new Rivian Assistant, a next generation voice experience arriving early 2026 on Gen 1 and Gen 2 R1 vehicles. The assistant uses a blend of edge models and in vehicle intelligence to understand your schedule, recognize context, and handle everyday requests.&lt;/p&gt;
    &lt;p&gt;On R2, it will even run fully offline thanks to a more powerful infotainment computer, reducing latency and keeping more of the experience on device.&lt;/p&gt;
    &lt;head rend="h2"&gt;AI Powered Service and Diagnostics&lt;/head&gt;
    &lt;p&gt;Rivian is embedding AI into the service workflow. Technicians will have access to an AI driven expert system that analyzes telemetry and vehicle history to pinpoint issues faster and more accurately. These same tools will eventually power the mobile app as well, making self service diagnostics significantly smarter.&lt;/p&gt;
    &lt;head rend="h3"&gt;27 Comments&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Any mention of retrofitting Autonomy Computer and LiDAR onto existing R1’s? Hopefully at least Gen 2’s!&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;Will not happen&lt;/p&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I need this R2D2 themed R2 🔥&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I watched the event. It felt like I was at an apple event. Is Rivian wanting us to trade in ours cars every two years to get a newer version? A new chip set, better camera, or a faster processor?&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;I’ve always been a vehicle buyer, not leaser. But these rapid tech changes definitely have me looking at leasing an R1S gen 2 so I can unload it once the R1’s get lidar.&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Personally I want to do the driving. I like driving and don’t want to put my life in the hands of anyone’s computer!&lt;/p&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;So with everything we know do we think we can expect automatic lane change before point to point? Was kind of expecting auto park and auto lane change to be announced with universal hands free&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Universal Hands Free when? Did they give any indication?&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;Soon. So probably 6-9 months.&lt;/p&gt;
            &lt;list rend="ul"&gt;
              &lt;item&gt;
                &lt;p&gt;S0––––0N&lt;/p&gt;
              &lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Pretty sure the presentations said universal will in “an update later this month.”&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;They posted on Instagram, it will come on next software update!&lt;/p&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sad day for Gen 1 users except the Rivian Assistant part……&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;This is disappointing. An assistant that can integrate with Google calendar 🤷♂️. Who cares?!?&lt;/p&gt;
        &lt;p&gt;Maybe some finds this valuable but I would rather have apple carplay.&lt;/p&gt;
        &lt;p&gt;People listen to music in their cars. Why not make that the first app? Who decided “let’s invest 2 years and make Google calendar the first app”?&lt;/p&gt;
        &lt;p&gt;Rivian is clueless.&lt;/p&gt;
        &lt;p&gt;I have owned 2 of these and won’t buy a third one.&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;Rivian is trying to do everything, but they really need to consider people’s lives beyond the vehicle. I set up my phone, my home, my computer, my TV, and now my car too? Google and apple have texting and music covered, just let people’s phone do the work and not make the car yet “assistant” to set up. Focus on self driving. Let the car simply connect to phones for phone stuff.&lt;/p&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sad as Gen 1 – should have had at least something to improve Driver-&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;It will be interesting to see which features end up behind the paywall. Will we only end up with adaptive cruse control and center lane assist?&lt;/p&gt;
        &lt;p&gt;Also curious about the $2500 for Autonomy+. I wonder if that will follow a person/family to future Rivian vehicles. If so that would make it more enticing (also if it then included Connect+ as well).&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;p&gt;Found the answer once Rivian website was updated:&lt;/p&gt;&lt;lb/&gt;“Autonomy+ one-time purchases remain with the vehicle upon ownership transfer, and Autonomy+ product features remain available during the lifetime of feature support for the hardware on the vehicle at delivery”&lt;p&gt;So unfortunately it follows the vehicle and not the person.&lt;/p&gt;&lt;p&gt;While I appreciate the fact that continuous development costs money, I just really don’t like subscriptions that much. Due really to the amount of time I would spend not even using the feature. So for this reason I sort of favor the more lifetime buy option…. Main use case for me is really trips/longer drives. Which are definitely less than monthly. I don’t think I see myself getting in the car and paying $50 at the start of a long weekend trip for the sort term feature rental. Oh well 🙂&lt;/p&gt;&lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Wondered the exact same thing. $2500 pays for itself after about 4 years. If it stays with the user, on all their Rivians over time, great!&lt;/p&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;You all be thankful that your Gen 1s have gotten meaningful updates and backwards compatible updates from Gen 2. Be thankful you don’t have a BMW EV from 2022 with iDrive 8, not even a year later they were outdated by the next iteration of iDrive, 8.5 and BMW claims features (even software based) from 8.5 are not backwards compatible with iDrive 8.&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;I know that buying a legacy vehicle like BMW is going to be static. Rivian said we were buying a software driven vehicle with updates (on par with Tesla). Tesla brings updates for years to older vehicles. I agree if we are talking a 5-6 year old car that we’re hitting the wall… but not a car 2 years old that’s marketed in a very different way.&lt;/p&gt;
            &lt;list rend="ul"&gt;
              &lt;item&gt;
                &lt;p&gt;Well with Gen1, just because a certain MY was purchased does not mean the platform was also updated for that model. Gen1 has been riding on an autonomous platform from 2019 so it’s well into its 6-7 year life span. It also lacks the hardware needed to achieve anything beyond what it can hardly do today. The lack of radar alone is what holds it back, on top of its constrained processing power and low res cameras.&lt;/p&gt;
              &lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;So the new processing unit will be out late 2026. Is that when LIDAR is also expected or is LIDAR further out?&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;So R2 will launch without Lidar. But will R2 launch with Gen2 Autonomy hardware? They were clear that Gen3 Autonomy hardware is “late 2026”. But I went through it again, and didn’t see any clear statement on this. If R2 must wait for Gen3 Autonomy hardware, we won’t be seeing R2 any time s00n…&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;Read between the lines….&lt;/p&gt;
            &lt;p&gt;R2 will have all of this stuff, lidar etc….&lt;/p&gt;
            &lt;p&gt;“gen 3 chip will be out late 2026”.&lt;/p&gt;
            &lt;p&gt;If R2 will have all the features, then that means its pushed late 2026. They just didnt to come out and say R2 is delayed.&lt;/p&gt;
            &lt;list rend="ul"&gt;
              &lt;item&gt;
                &lt;p&gt;Yup, that’s the way I read it as well. Of course saying that explicitly would have really rained on the parade.&lt;/p&gt;
              &lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Was there any hint of the Dec update that was to include RAD tuner?&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46234920</guid><pubDate>Thu, 11 Dec 2025 18:17:19 +0000</pubDate></item><item><title>Going Through Snowden Documents, Part 1</title><link>https://libroot.org/posts/going-through-snowden-documents-part-1/</link><description>&lt;doc fingerprint="bfd8a957069095c0"&gt;
  &lt;main&gt;
    &lt;p&gt;We are building a comprehensive archive and analysis project examining published documents leaked by Edward Snowden. Our methodology involves systematically reviewing each available document with particular attention to small details and information that has received little or no public attention since the initial 2013 disclosures. Throughout this process, we will publish posts highlighting interesting previously unreported findings. The main project will hopefully be complete and made public in mid-to-late 2026.&lt;/p&gt;
    &lt;p&gt;This is Part 1 of our "Going Through Snowden Documents" series.&lt;/p&gt;
    &lt;p&gt;Document: CNE Analysis in XKEYSCORE&lt;/p&gt;
    &lt;p&gt;Classification: TOP SECRET//COMINT//REL TO USA, AUS, CAN, GBR, NZL&lt;/p&gt;
    &lt;p&gt;Date: October 15, 2009&lt;/p&gt;
    &lt;p&gt;Published by: The Intercept (July 1 and July 2, 2015)&lt;/p&gt;
    &lt;p&gt;Authors: Morgan Marquis-Boire, Glenn Greenwald, and Micah Lee&lt;/p&gt;
    &lt;p&gt;While The Intercept published this document, the accompanying articles focus on NSA's XKEYSCORE system broadly and does not analyze this specific document. The document appears only in the "Documents published with this article" sections without dedicated coverage. Academic searches, news archives, and general web searches reveal virtually no subsequent analysis or citation of this document. This pattern of important documents published but never publicly analyzed is unfortunately very common in the published Snowden documents.&lt;/p&gt;
    &lt;head rend="h2"&gt;Table of Contents&lt;/head&gt;
    &lt;p&gt;This October 2009 33-page document, in a slideshow format, is an internal NSA training presentation demonstrating how analysts use XKEYSCORE to search and analyze data collected through Computer Network Exploitation (CNE), the NSA's term for active hacking operations. While framed as instructional examples showing various search capabilities, the screenshots display real surveillance operations with identifiable targets and captured data.&lt;/p&gt;
    &lt;p&gt;The screenshots in the document are such poor quality that, at times, reading the text is very difficult. However, by examining the context and surrounding text (or surrounding pages), the text can be inferred with a very high probability. This has certainly contributed to why many documents have not been studied more thoroughly in public, as many are similarly low quality with scrambled text.&lt;/p&gt;
    &lt;head rend="h2"&gt;CNE operation against Chinese defense contractor Norinco&lt;/head&gt;
    &lt;p&gt;One of the most significant previously unreported findings in this document is evidence of NSA surveillance targeting Norinco, China North Industries Corporation, one of the world's largest state-owned defense contractors. Norinco ranks among the world's top 100 defense companies by revenue and serves as a major exporter of military equipment to Pakistan, Iran, Venezuela, Zimbabwe, and dozens of other countries, many of which have contentious relationships with the United States.&lt;/p&gt;
    &lt;p&gt;On page 18, a screenshot from XKEYSCORE's Metaviewer interface displays a "Histogram of @Domain" view with a bar graph showing email volume across 10 domain names followed by a data table with formatted surveillance results. The query appears to be a converged search combining multiple distinct surveillance targets: Mexican federal agencies (ssp.gob.mx at 452 emails, pfp.local at 158 emails), Norinco-related domains (mail.norinco.cn, businessmonitor.com, bmi.msgfocus.com, zhenhuaoil.com, and lms-ms-daemon, each showing 3 emails), and two additional targets (steels-net.cu and inwind.it, each with 1 email). This convergence of seemingly unrelated targets in a single query demonstrates XKEYSCORE's ability to simultaneously analyze multiple surveillance operations.&lt;/p&gt;
    &lt;p&gt;The first five entries in the results table contain:&lt;/p&gt;
    &lt;quote&gt;Email User Name | Datetime | Highlights | @Domain | Subject | Chain [REDACTED] | 2009-10-10 05:15:10 | CNE | mail.norinco.cn | 28-10 senior contacts in India for zh | 0kqe00g01mrdii@mail.norinco.cn&amp;amp;kate.strut [REDACTED] | 2009-10-10 05:15:10 | CNE | businessmonitor.com | 28-10 senior contacts in India for zh | 0kqe00g01mrdii@mail.norinco.cn&amp;amp;kate.strut [REDACTED] | 2009-10-10 05:15:10 | CNE | bmi.msgfocus.com | 28-10 senior contacts in India for zh | 0kqe00g01mrdii@mail.norinco.cn&amp;amp;kate.strut [REDACTED] | 2009-10-10 05:15:10 | CNE | zhenhuaoil.com | 28-10 senior contacts in India for zh | 0kqe00g01mrdii@mail.norinco.cn&amp;amp;kate.strut [REDACTED] | 2009-10-10 05:15:10 | CNE | lms-ms-daemon | 28-10 senior contacts in India for zh | 0kqe00g01mrdii@mail.norinco.cn&amp;amp;kate.strut&lt;/quote&gt;
    &lt;p&gt;All entries are marked with the "CNE" highlight tag, indicating the data came from CNE operations, active hacking intrusions rather than passive network intercepts. Critically, all five entries share an identical "Chain" value indicating this is a single email captured at multiple points as it traversed Norinco's email infrastructure. The multiple domains – businessmonitor.com (newsletter sender), bmi.msgfocus.com (newsletter delivery service), mail.norinco.cn (Norinco's mail server), zhenhuaoil.com (Norinco's subsidiary), and lms-ms-daemon (the default domain name for Sun Java Messaging Server commonly used in enterprise email infrastructure) – represent the newsletter email's routing path through Norinco's network. This indicates that NSA achieved deep network penetration with visibility across multiple servers and routing points within Norinco's corporate email infrastructure, not just a single interception point. The compromise extended to Zhenhua Oil (Norinco's oil exploration subsidiary), indicating enterprise-wide access.&lt;/p&gt;
    &lt;head rend="h2"&gt;Redaction failure exposing NSA agent username&lt;/head&gt;
    &lt;p&gt;Most XKEYSCORE search interfaces display a welcoming message showing the analyst's internal NSA username. In the document all usernames have been redacted from the screenshots except one left unredacted by mistake.&lt;/p&gt;
    &lt;p&gt;On page 9, the username "cryerni" is visible in the screenshot.&lt;/p&gt;
    &lt;p&gt;This username most likely belongs to the NSA analyst who created the presentation. The seven-character length matches the redacted name on the first page, based on the surrounding unredacted font. The length of seven characters also matches to other NSA agents' usernames in other documents (more on that in upcoming parts).&lt;/p&gt;
    &lt;head rend="h2"&gt;CNE operation against Mexican federal law enforcement&lt;/head&gt;
    &lt;p&gt;On the page 18, the XKEYSCORE Metaviewer displays email extraction results showing surveillance of Mexican federal law enforcement from domains ssp.gob.mx (Secretaría de Seguridad Pública) and pfp.local (Policía Federal Preventiva). Email subjects include:&lt;/p&gt;
    &lt;quote&gt;101009 EII LA PAZ, BAJA CALIFORNIA 101009 EII MEXICALI, BAJA CALIFORNIA 101009 EII CIUDAD JUÁREZ, CHIHUAHUA&lt;/quote&gt;
    &lt;p&gt;"EII" likely stands for "Estructura de Información de Inteligencia" or similar internal reporting format. The dates (101009 = October 10, 2009) and locations indicate daily intelligence reports from Mexican federal police units in Baja California's border region and Ciudad Juárez, one of Mexico's most violent cities during the peak of cartel warfare under President Felipe Calderón's military-led offensive against drug cartels.&lt;/p&gt;
    &lt;p&gt;NSA surveillance of these communications likely supported US counter-narcotics operations, identified compromised Mexican officials, and monitored cartel structures and government response capabilities. However, this represents surveillance of a nominal ally's law enforcement agencies without apparent Mexican government knowledge or consent. All entries were marked "CNE," again indicating active computer compromise rather than passive intercept.&lt;/p&gt;
    &lt;head rend="h2"&gt;CNE operation against Iran's customs and rails&lt;/head&gt;
    &lt;p&gt;Another interesting finding appears on page 17, showing document metadata extraction results with the name "Iran OP Customs and Rail Extracted Docs". The results table displays documents captured from a file path containing "lap top drive" and "Private Inbox", with all entries marked "CNE" in the Highlights column, indicating NSA compromised a portable computer likely belonging to someone working in Iranian transportation or customs infrastructure. The implant performed a complete directory walk and extracted Word documents from the user's private folders.&lt;/p&gt;
    &lt;head rend="h2"&gt;New surveillance program codenames&lt;/head&gt;
    &lt;p&gt;Several program codenames mentioned in this document don't appear in any other published Snowden documents or in previous reporting. No mention either in websites documenting all the codenames found in Snowden documents and in other NSA/GCHQ related articles and documents.&lt;/p&gt;
    &lt;p&gt;TURBOCHASER - The document describes TURBOCHASER as an NSA database for "profiles" and for "future tasking", appearing alongside MARINA (the well-documented NSA metadata repository). The name suggests rapid-cycling or high-speed processing ("turbo") of pursuit targets ("chaser"). Based on context, TURBOCHASER likely handled specific metadata types or geographic regions that MARINA didn't cover. The document's brief mention provides no additional details.&lt;/p&gt;
    &lt;p&gt;TUCKER - References in the document suggest TUCKER is an exploitation framework comparable to UNITEDRAKE (the well-documented full-featured Windows implant). The document lists TUCKER's sub-projects including OLYMPUS, EXPANDINGPULLY, and UNIX, indicating TUCKER was a platform hosting multiple specialized payloads and/or (post-)exploitation tools.&lt;/p&gt;
    &lt;p&gt;SHADOWQUEST, WAYTIDE, GREENCHAOS - These appear as collection source identifiers in the document. The document shows them as input sources feeding CNE data into XKEYSCORE. Notably, FOXACID, the well-documented NSA exploit server system used to deliver malware to targets, also appears in this context with the suffix FOXACID6654, suggesting it functioned not just as an exploitation delivery mechanism but also as a collection source identifier once targets were compromised. This reveals FOXACID's dual role: initial compromise vector and ongoing data collection infrastructure.&lt;/p&gt;
    &lt;p&gt;The input sources shown include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;FOXACID6654 - collecting wireless survey data&lt;/item&gt;
      &lt;item&gt;SHADOWQUEST35 - collecting wireless survey data&lt;/item&gt;
      &lt;item&gt;WAYTIDE1173 - collecting wireless intelligence&lt;/item&gt;
      &lt;item&gt;GREENCHAOS15 - source of the Chinese keylogger data&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The numeric suffixes (6654, 35, 1173, 15) likely designates a specific server or operational instance, possibly corresponding to geographic regions, operational theaters, or specific TAO teams.&lt;/p&gt;
    &lt;head rend="h2"&gt;Other&lt;/head&gt;
    &lt;p&gt;Finally, the document showcases several detailed cases of NSA's CNE capabilities, confirming and adding specific context to techniques that have been reported on more generally since 2013.&lt;/p&gt;
    &lt;head rend="h3"&gt;FOGGYBOTTOM: HTTP activity surveillance&lt;/head&gt;
    &lt;p&gt;Pages 19-20 showcase FOGGYBOTTOM for monitoring HTTP activity captured through CNE operations. FOGGYBOTTOM is a computer implant plug-in that records logs of internet browsing histories and collects login details and passwords used to access websites and email accounts. These pages show detailed browser surveillance of a target identified by case notation YM.VALAGWAADTC (Yemen) on October 14, 2009. The system captured:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Multiple Facebook login attempts (login.facebook.com with "login_attempt=1" POST requests)&lt;/item&gt;
      &lt;item&gt;Arabic-language Facebook browsing (ar-ar.facebook.com)&lt;/item&gt;
      &lt;item&gt;Saudi Arabian Google searches (www.google.com.sa with "hl=ar" indicating Arabic language)&lt;/item&gt;
      &lt;item&gt;Yemeni news sites (www.14october.com, www.26sep.net, www.althawranews.net)&lt;/item&gt;
      &lt;item&gt;Arabic sports forums (forum.kooora.com - a popular Middle Eastern sports discussion site)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The surveillance captured not just URLs but complete HTTP request details including POST data and URL parameters. The "dnt_payload/browser" formatter shows the target's local time, timezone offset, and HTTP POST form data. Since this data comes from a CNE implant running on the compromised computer itself – not passive network interception – it captures web traffic before encryption occurs. The implant sees the browsing data whether the connection uses HTTP or HTTPS, providing complete visibility into all browsing activity including encrypted sessions that would be opaque to network-level surveillance.&lt;/p&gt;
    &lt;head rend="h3"&gt;Windows registry surveillance&lt;/head&gt;
    &lt;p&gt;Page 26 demonstrates XKEYSCORE's capability to search and analyze Windows registry data extracted from compromised machines. The screenshots show registry queries returning UserAssist keys; Windows registry entries that record every program a user has executed, how many times, and when they last ran it. This data is maintained by Windows for user interface optimization but becomes a detailed forensic record when captured by NSA implants.&lt;/p&gt;
    &lt;head rend="h3"&gt;Multi-lingual keylogger capabilities&lt;/head&gt;
    &lt;p&gt;Pages 24-25 demonstrate XKEYSCORE's keylogger capabilities with actual captured keystrokes from a compromised computer identified as GREENCHAOS15 in China. The target was using QQ.exe (China's largest instant messaging platform owned by Tencent), Microsoft Excel, and Microsoft Access. The keylogger captured complete Chinese character input, control key sequences, hexadecimal codes for special characters, window titles showing conversation participants, and even deleted text and editing actions. In Excel, the system recorded every keystroke including numerical entries, navigation inputs (Delete, NumPad entries), and cell references (D4, H2, D53, etc.), showing the target working on a spreadsheet titled "3C证书导入工作周报0928-1001.xls" (3C Certificate Import Work Weekly Report 09/28-10/01). The target appeared to be an office worker handling administrative tasks related to China's 3C certification system (China Compulsory Certificate for product safety/quality). This demonstrates NSA's ability to capture multi-lingual keystrokes across all applications with complete context preservation.&lt;/p&gt;
    &lt;head rend="h3"&gt;"vpn in docs"&lt;/head&gt;
    &lt;p&gt;The document also demonstrates how XKEYSCORE uses a generic "tech strings" search to automatically identify and flag arbitrary keywords that an analyst queries. This feature appears to function as a catchall system for finding terms of interest in data streams that lack a more specific parser. The examples show XKEYSCORE tagging the strings "vpn" and "pptp" inside a wide variety of captured data. This includes the content of emails (email_body), the body of local documents (document_body with file paths like C:\TNI-095CC.DOC), and other raw data payloads exfiltrated from implants (tech_body). As nearly all entries are highlighted with "CNE," this reveals that NSA implants actively scan a target's private files and communications for these keywords. The resulting intelligence allows analysts to discover a target's security posture, identify potential vulnerabilities, and find information such as credentials or server details that can be leveraged to gain access to privileged systems or map internal networks.&lt;/p&gt;
    &lt;p&gt;This document is a good example of the significant intelligence hiding in plain sight within the published Snowden documents. A detailed review can reveal significant, previously unreported intelligence operations, such as the CNE op against a major Chinese defense contractor. These findings underscore the importance of a systematic review of the documents. Also, it's important to acknowledge the inherent limitations of analyzing any single document in isolation like we did in this post. A single document analysis offers only a snapshot with limited context.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46235412</guid><pubDate>Thu, 11 Dec 2025 18:52:08 +0000</pubDate></item><item><title>An SVG is all you need</title><link>https://jon.recoil.org/blog/2025/12/an-svg-is-all-you-need.html</link><description>&lt;doc fingerprint="3dc38b5d0be4eb8d"&gt;
  &lt;main&gt;
    &lt;p&gt;SVGs are pretty cool - vector graphics in a simple XML format. They are supported on just about every device and platform, are crisp on every display, and can have embedded scripts in to make them interactive. They're way more capable than many people realise, and I think we can capitalise on some of that unrealised potential.&lt;/p&gt;
    &lt;p&gt;Anil's recent post Four Ps for Building Massive Collective Knowledge Systems got me thinking about the permanence of the experimentation that underlies our scientific papers. In my idealistic vision of how scientific publishing should work, each paper would be accompanied by a fully interactive environment where the reader could explore the data, rerun the experiments, tweak the parameters, and see how the results changed. Obviously we can't do this in the general case - some experiments are just too expensive or time-consuming to rerun on demand. But for many papers, especially in computer science, this is entirely feasible.&lt;/p&gt;
    &lt;p&gt;That line of thought reminded me of a project I tackled about 20 years ago as a post-doc in the Department of Plant Sciences here in Cambridge. I was writing a paper on synergy in fungal networks and built a tiny SVG visualisation tool that let readers wander through the raw data captured from a real fungal network growing in a petri dish. I dug it up recently and was surprised (and delighted) to see that it still works perfectly in modern browsers - even though the original âcover pageâ suggested Firefox 1.5 or the Adobe SVG plug-in (!). Give it a spin; click the 'forward', 'back' and other buttons below the petri dish!&lt;/p&gt;
    &lt;p&gt;And that, dear reader, is literally all you need. A completely self-contained SVG file can either fetch data from a versioned repository or embed the data directly, as the example does. It can process that data, generate visualisations, and render knobs and sliders for interactive exploration. No server-side magic required - everything runs client-side in the browser, served by a plain static web server, and very easily to share.&lt;/p&gt;
    &lt;p&gt;How does it fit in with Anil's four Ps?&lt;/p&gt;
    &lt;p&gt;The SVG above is only a visualisation tool for data; it doesn't really do any processing, but it certainly could. The biggest change that's happened over the 20 years since I wrote this is the massive increase in the computation power available in the browser. If would be entirely feasible to implement the entire data analysis pipeline for that paper in an SVG today, probably without even spinning up the fans on my laptop!&lt;/p&gt;
    &lt;p&gt;So this is yet another tool in our ongoing effort to be able to effortlessly share and remix our work - added to the pile of Jupyter notebooks, Marimo botebooks, the slipshow/x-ocaml combination, Patrick's take on Jon Sterling's Forester, my own notebooks, and many others - and this is a subset of what we're using just in our own group!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46235959</guid><pubDate>Thu, 11 Dec 2025 19:25:14 +0000</pubDate></item><item><title>My productivity app is a never-ending .txt file (2020)</title><link>https://jeffhuang.com/productivity_text_file/</link><description>&lt;doc fingerprint="2555483b29260ef2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Over 14 years of todos recorded in text&lt;/head&gt;
    &lt;head rend="h2"&gt;My productivity app is a never-ending .txt file&lt;/head&gt;
    &lt;head rend="h3"&gt;By Jeff Huang, updated on 2022-03-21&lt;/head&gt;
    &lt;p&gt;The biggest transition for me when I started college was learning to get organized. There was a point when I couldn't just remember everything in my head. And having to constantly keep track of things was distracting me from whatever task I was doing at the moment.&lt;/p&gt;
    &lt;p&gt;So I tried various forms of todo lists, task trackers, and productivity apps. They were all discouraging because the things to do kept getting longer, and there were too many interrelated things like past meeting notes, calendar appointments, idea lists, and lab notebooks, which were all on different systems.&lt;/p&gt;
    &lt;p&gt;I gave up and started just tracking in a single text file and have been using it as my main productivity system for 14 years now. It is so essential to my work now, and has surprisingly scaled with a growing set of responsibilities, that I wanted to share this system. It's been my secret weapon.&lt;/p&gt;
    &lt;p&gt;Prerequisite: A calendar. The one outside tool I use is an online calendar, and I put everything on this calendar, even things that aren't actually for a fixed time like "make a coffee table at the workshop" or "figure out how to recruit new PhD students" — I'll schedule them on a date when I want to think about it. That way all my future plans and schedule are together, and not a bunch of lists I have to keep track of.&lt;/p&gt;
    &lt;p&gt;Making the Daily List: Every night before I go to bed, I take all the items on my calendar for the next day and append it to the end of the text file as a daily todo list, so I know exactly what I'm doing when I wake up. This list contains scheduled tasks (2pm meeting with Madonna, 4pm office hours), errands (sign a form, return a book), and work items (review a paper, prepare a presentation). It also lets me think about whether I've got the right amount of work for a day.&lt;/p&gt;
    &lt;p&gt;Anything I don't want to do tomorrow, I'll shuffle back into my calendar on later dates. If the task is too big, I'll break it down into a piece for tomorrow, and the rest for another date. After years of doing this, I've gotten pretty good at estimating what I can finish in a day. Here's an example with names replaced so you can see what it looks like when I move a day's schedule from my calendar.&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;2021-11-31
11am meet with Head TAs
- where are things at with inviting portfolio reviewers?
11:30am meet with student Enya (interested in research)
review and release A/B Testing assignment grading
12pm HCI group meeting
- vote for lab snacks
send reminders for CHI external reviewers
read Sketchy draft
Zelda pick up eye tracker
- have her sign for it
update biosketch for Co-PI
3:15pm join call with Umbrella Corp and industry partnership staff
3:45pm advising meet with Oprah
4pm Rihanna talk (368 CIT)
5pm 1:1 with Beyonce #phdadvisee
6pm faculty interview dinner with Madonna
&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;As a Record: That daily todo list is where I also take notes, so it's a to do list that turns into a what done list. The best thing about these daily lists is I keep them all in a single text file separated by dates, so I have a record of everything I have ever done and when I did it.&lt;/p&gt;
    &lt;p&gt;My current file was created 9 years ago when I started my current job. It serves as a research notebook, and as meeting minutes. I have 51,690 handwritten lines in one file now, documenting everything I have done as a professor, and nearly every person I have met with, along with notes about what we discussed or ideas I had. Here's what my list looks like at the end of the day, representing work accomplished.&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;2021-11-31
11am meet with Head TAs
- where are things at with inviting portfolio reviewers? A: got 7/29 replies
- need 3 TAs for Thursday lab
- Redesign assignment handout will be done by Monday, ship Thursday
11:30am meet with student Enya (interested in research)
- they're a little inexperienced, suggested applying next year
review and release A/B Testing assignment grading
12pm HCI group meeting
- automatically generate thumbnails from zoom behavior on web pages
- #idea subliminal audio that leads you to dream about websites
- Eminem presenting Nov 24
- vote for lab snacks. A: popcorn and seaweed thing
got unofficial notification ARO YIP funding award #annual #cv
read Sketchy paper draft
- needs 1 more revision
- send to Gandalf to look at?
Zelda pick up eye tracker
- have her sign for it
update biosketch for Co-PI
unexpected drop in from Coolio! #alumni
- now a PM working on TravelAdvisor, thinking about applying to grad school
3:15pm join call with Umbrella Corp and industry partnership staff
- they want to hire 20 data science + SWE interns (year 3), 4 alums there as SWE
3:45pm advising meet with Oprah
- enjoyed CS 33
- interning at Facebook
4pm Rihanna talk (368 CIT)
5pm 1:1 with Beyonce #phdadvisee
- stuck on random graph generating crash
	- monitor memory/swap/disk?
	- ask Mario to help?
- got internship at MSR with Cher
	- start May 15 or 22
- will send me study design outline before next meeting
- interviewing Spartacus as potential RA for next semester
6pm faculty interview dinner with Madonna (Gracie's)
- ask about connection with computer vision
- cool visual+audio unsupervised comparison, thoughtful about missing data, would work with ugrads (?), likes biking, teach compvis + graphics
- vote #HIRE
#note maybe visit Monsters University next spring, Bono does related work
&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;Shortcuts and Features: I use a consistent writing style so things are easily searchable, with a few shorthands. When I search for "meet with", it shows that I have had over 3,000 scheduled meetings. I have some tags like #idea for new ideas to revisit when I want project ideas, #annual for things to put on my next annual report, #nextui for things to add the next time I run my next UI course.&lt;/p&gt;
    &lt;p&gt;A text file is incredibly flexible, and at any point, I can quickly glance to see what I've done that day and what's left. I usually keep an empty line between tasks completed and upcoming tasks. When a task is completed, I move the empty line. Any leftover tasks from the current day can go back into the calendar for when I may want to tackle it again, but that is rare because tasks were already sized into what I can do on that day. I can calculate aggregate statistics using the search box, or list all the lines containing a tag, and other operations using my text editor. I use Ultraedit because I'm familiar with it, but any text editor would have similar capabilities.&lt;/p&gt;
    &lt;p&gt;Email: Email is obviously a part of my workflow. Everyone has all sorts of productivity advice about handling it, but I find a simple flagging system is sufficient — flag Red if it's something I need to deal with, flag Orange if I need to deal with it eventually but requires some thinking or someone else to handle it, and flag Yellow for emails I send that I am waiting on a reply for, so I know to follow up later. I'll flag emails as they come in, whenever it's convenient.&lt;/p&gt;
    &lt;p&gt;At the end of the day, I'll do a quick review of the Orange and Yellows to see if any need to be followed up or should become Red. Some peoples' workflows revolve around obsessively cleaning their Inbox. I don't really care about keeping my inbox empty because then I feel like I have new work to do whenever email comes in.&lt;/p&gt;
    &lt;p&gt;So my daily routine looks like&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;look at the daily todo list I wrote last night to find out what I'm doing today&lt;/item&gt;
      &lt;item&gt;do scheduled things on that list during the day&lt;/item&gt;
      &lt;item&gt;when I have free (unscheduled) time, do the floating tasks on my list and work on Red-flagged emails at the end of the day&lt;/item&gt;
      &lt;item&gt;do a quick review of Orange/Yellow emails to see if they need any handling&lt;/item&gt;
      &lt;item&gt;copy the next day's calendar items to the bottom of the text file&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This process has a few nice properties:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It's easy to immediately see what to do when I wake up&lt;/item&gt;
      &lt;item&gt;I don't need to remember in my head the things to do later (following up on emails, future tasks)&lt;/item&gt;
      &lt;item&gt;It's easy to recall what happened in the past and see how much I can actually accomplish in a day&lt;/item&gt;
      &lt;item&gt;There's no running "todo" list with items that keep pushed back day after day&lt;/item&gt;
      &lt;item&gt;I use Remote Desktop so everything is accessible from every device&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;My daily workload is completely under my control the night before; whenever I feel overwhelmed with my long-term commitments, I reduce it by aggressively unflagging emails, removing items from my calendar that I am no longer excited about doing, and reducing how much work I assign myself in the future.&lt;/p&gt;
    &lt;p&gt;It does mean sometimes I miss some questions or don't pursue an interesting research question, but helps me maintain a manageable workload.&lt;/p&gt;
    &lt;p&gt;So that's it. I would love to hear from you if you try my system, or have some ideas about it!&lt;/p&gt;
    &lt;head rend="h3"&gt;Also in this series&lt;/head&gt;
    &lt;p&gt;The Coronavirus pandemic has changed our sleep behavior&lt;/p&gt;
    &lt;p&gt;Extracting data from tracking devices by going to the cloud&lt;/p&gt;
    &lt;head rend="h3"&gt;Other articles I've written&lt;/head&gt;
    &lt;p&gt;Behind the scenes: the struggle for each paper to get published&lt;/p&gt;
    &lt;p&gt;This page is designed to last, a manifesto for preserving content on the web&lt;/p&gt;
    &lt;p&gt;Illustrative notes for obsessing over publishing aesthetics&lt;/p&gt;
    &lt;p&gt;CS Faculty Composition and Hiring Trends&lt;/p&gt;
    &lt;p&gt;Bias in Computer Science Rankings&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46236037</guid><pubDate>Thu, 11 Dec 2025 19:30:58 +0000</pubDate></item><item><title>UK House of Lords attempting to ban use of VPNs by anyone under 16</title><link>https://alecmuffett.com/article/134925</link><description>&lt;doc fingerprint="64b98a7d2fffc375"&gt;
  &lt;main&gt;
    &lt;p&gt;This is deranged, each nation’s boomers and reactionaries attempting to outdo the others:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Action to prohibit the provision of VPN services to children in the United Kingdom” â¦ the provider of any Relevant VPN Service which is, or is likely to be â (i) offered or marketed to persons in the United Kingdom; (ii) provided to a significant number of persons. (c) must make provision for the monitoring and effective enforcement of the child VPN prohibition.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;VPNs are a technology which anyone can implement for themselves. “Regulatory compliance” of them is not feasible, it’d be like banning DIY.&lt;/p&gt;
    &lt;p&gt;Not to mention it would include The Tor Project.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46236738</guid><pubDate>Thu, 11 Dec 2025 20:32:22 +0000</pubDate></item><item><title>Denial of service and source code exposure in React Server Components</title><link>https://react.dev/blog/2025/12/11/denial-of-service-and-source-code-exposure-in-react-server-components</link><description>&lt;doc fingerprint="b02bbf4aec53e947"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Denial of Service and Source Code Exposure in React Server Components&lt;/head&gt;
    &lt;p&gt;December 11, 2025 by The React Team&lt;/p&gt;
    &lt;p&gt;Security researchers have found and disclosed two additional vulnerabilities in React Server Components while attempting to exploit the patches in last week’s critical vulnerability.&lt;/p&gt;
    &lt;p&gt;These new vulnerabilities do not allow for Remote Code Execution. The patch for React2Shell remains effective at mitigating the Remote Code Execution exploit.&lt;/p&gt;
    &lt;p&gt;The new vulnerabilities are disclosed as:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Denial of Service - High Severity: CVE-2025-55184 and CVE-2025-67779 (CVSS 7.5)&lt;/item&gt;
      &lt;item&gt;Source Code Exposure - Medium Severity: CVE-2025-55183 (CVSS 5.3)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We recommend upgrading immediately due to the severity of the newly disclosed vulnerabilities.&lt;/p&gt;
    &lt;p&gt;Further details of these vulnerabilities will be provided after the rollout of the fixes are complete.&lt;/p&gt;
    &lt;head rend="h2"&gt;Immediate Action Required&lt;/head&gt;
    &lt;p&gt;These vulnerabilities are present in the same packages and versions as CVE-2025-55182.&lt;/p&gt;
    &lt;p&gt;This includes versions 19.0.0, 19.0.1, 19.0.2, 19.1.0, 19.1.1, 19.1.2, 19.1.2, 19.2.0, 19.2.1 and 19.2.2 of:&lt;/p&gt;
    &lt;p&gt;Fixes were backported to versions 19.0.3, 19.1.4, and 19.2.3. If you are using any of the above packages please upgrade to any of the fixed versions immediately.&lt;/p&gt;
    &lt;p&gt;As before, if your app’s React code does not use a server, your app is not affected by these vulnerabilities. If your app does not use a framework, bundler, or bundler plugin that supports React Server Components, your app is not affected by these vulnerabilities.&lt;/p&gt;
    &lt;head rend="h3"&gt;Affected frameworks and bundlers&lt;/head&gt;
    &lt;p&gt;Some React frameworks and bundlers depended on, had peer dependencies for, or included the vulnerable React packages. The following React frameworks &amp;amp; bundlers are affected: next, react-router, waku, @parcel/rsc, @vite/rsc-plugin, and rwsdk.&lt;/p&gt;
    &lt;p&gt;Please see the instructions in the previous post for upgrade steps.&lt;/p&gt;
    &lt;head rend="h3"&gt;Hosting Provider Mitigations&lt;/head&gt;
    &lt;p&gt;As before, we have worked with a number of hosting providers to apply temporary mitigations.&lt;/p&gt;
    &lt;p&gt;You should not depend on these to secure your app, and still update immediately.&lt;/p&gt;
    &lt;head rend="h3"&gt;React Native&lt;/head&gt;
    &lt;p&gt;For React Native users not using a monorepo or &lt;code&gt;react-dom&lt;/code&gt;, your &lt;code&gt;react&lt;/code&gt; version should be pinned in your &lt;code&gt;package.json&lt;/code&gt;, and there are no additional steps needed.&lt;/p&gt;
    &lt;p&gt;If you are using React Native in a monorepo, you should update only the impacted packages if they are installed:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;react-server-dom-webpack&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;react-server-dom-parcel&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;react-server-dom-turbopack&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is required to mitigate the security advisories, but you do not need to update &lt;code&gt;react&lt;/code&gt; and &lt;code&gt;react-dom&lt;/code&gt; so this will not cause the version mismatch error in React Native.&lt;/p&gt;
    &lt;p&gt;See this issue for more information.&lt;/p&gt;
    &lt;head rend="h2"&gt;High Severity: Denial of Service&lt;/head&gt;
    &lt;p&gt;CVEs: CVE-2025-55184 and CVE-2025-67779 Base Score: 7.5 (High)&lt;/p&gt;
    &lt;p&gt;Security researchers have discovered that a malicious HTTP request can be crafted and sent to any Server Functions endpoint that, when deserialized by React, can cause an infinite loop that hangs the server process and consumes CPU. Even if your app does not implement any React Server Function endpoints it may still be vulnerable if your app supports React Server Components.&lt;/p&gt;
    &lt;p&gt;This creates a vulnerability vector where an attacker may be able to deny users from accessing the product, and potentially have a performance impact on the server environment.&lt;/p&gt;
    &lt;p&gt;The patches published today mitigate by preventing the infinite loop.&lt;/p&gt;
    &lt;head rend="h2"&gt;Medium Severity: Source Code Exposure&lt;/head&gt;
    &lt;p&gt;CVE: CVE-2025-55183 Base Score: 5.3 (Medium)&lt;/p&gt;
    &lt;p&gt;A security researcher has discovered that a malicious HTTP request sent to a vulnerable Server Function may unsafely return the source code of any Server Function. Exploitation requires the existence of a Server Function which explicitly or implicitly exposes a stringified argument:&lt;/p&gt;
    &lt;code&gt;'use server';&lt;/code&gt;
    &lt;p&gt;An attacker may be able to leak the following:&lt;/p&gt;
    &lt;code&gt;0:{"a":"$@1","f":"","b":"Wy43RxUKdxmr5iuBzJ1pN"}&lt;/code&gt;
    &lt;p&gt;The patches published today prevent stringifying the Server Function source code.&lt;/p&gt;
    &lt;head rend="h2"&gt;Timeline&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;December 3rd: Leak reported to Vercel and Meta Bug Bounty by Andrew MacPherson.&lt;/item&gt;
      &lt;item&gt;December 4th: Initial DoS reported to Meta Bug Bounty by RyotaK.&lt;/item&gt;
      &lt;item&gt;December 6th: Both issues confirmed by the React team, and the team began investigating.&lt;/item&gt;
      &lt;item&gt;December 7th: Initial fixes created and the React team began verifying and planning new patch.&lt;/item&gt;
      &lt;item&gt;December 8th: Affected hosting providers and open source projects notified.&lt;/item&gt;
      &lt;item&gt;December 10th: Hosting provider mitigations in place and patches verified.&lt;/item&gt;
      &lt;item&gt;December 11th: Additional DoS reported to Meta Bug Bounty by Shinsaku Nomura.&lt;/item&gt;
      &lt;item&gt;December 11th: Patches published and publicly disclosed as CVE-2025-55183 and CVE-2025-55184.&lt;/item&gt;
      &lt;item&gt;December 11th: Missing DoS case found internally, patched and publicly disclosed as CVE-2025-67779.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Attribution&lt;/head&gt;
    &lt;p&gt;Thank you to Andrew MacPherson (AndrewMohawk) for reporting the Source Code Exposure, RyotaK from GMO Flatt Security Inc and Shinsaku Nomura of Bitforest Co., Ltd. for reporting the Denial of Service vulnerabilities.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46236924</guid><pubDate>Thu, 11 Dec 2025 20:46:46 +0000</pubDate></item><item><title>Almond (YC X25) Is Hiring SWEs and MechEs</title><link>https://www.ycombinator.com/companies/almond-2/jobs</link><description>&lt;doc fingerprint="ce8988d79ddffda5"&gt;
  &lt;main&gt;
    &lt;p&gt;Robots designed for the era of AI&lt;/p&gt;
    &lt;p&gt;Our mission is to free humans from physical labor with robotics.&lt;/p&gt;
    &lt;p&gt;We imagine a future where robots handle the essential, repetitive work and humans are free to create, connect, and pursue what truly matters to them.&lt;/p&gt;
    &lt;p&gt;To build that future we’re starting from the ground up with hardware. Our first product is a California-designed and assembled humanoid arm. Surrounding it, we’re developing advanced controls, intuitive data collection, and a full AI stack that makes deployment effortless in real industrial environments. We’re proving it on our own assembly line first.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46237081</guid><pubDate>Thu, 11 Dec 2025 21:00:10 +0000</pubDate></item><item><title>Show HN: Gotui – a modern Go terminal dashboard library</title><link>https://github.com/metaspartan/gotui</link><description>&lt;doc fingerprint="1a8ac82fbdc47d96"&gt;
  &lt;main&gt;
    &lt;p&gt;gotui is a cross-platform and fully-customizable terminal dashboard and widget library built on top of tcell. It is a modern fork of termui, inspired by ratatui and written purely in Go by Carsen Klock.&lt;/p&gt;
    &lt;p&gt;This is a modern fork of termui for 2025, heavily upgraded to support TrueColor, modern terminal events, better performance, and new layouts.&lt;/p&gt;
    &lt;p&gt;gotui is compatible with Go 1.24+.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Backend: Native &lt;code&gt;tcell&lt;/code&gt;support for TrueColor (24-bit RGB), mouse events, and resize handling.&lt;/item&gt;
      &lt;item&gt;Gauges: Progress bars and gauges.&lt;/item&gt;
      &lt;item&gt;Charts: &lt;list rend="ul"&gt;&lt;item&gt;BarChart: Stacked and standard bar charts.&lt;/item&gt;&lt;item&gt;PieChart: Pie and Donut charts.&lt;/item&gt;&lt;item&gt;RadarChart: Spider/Radar charts.&lt;/item&gt;&lt;item&gt;TreeMap: Hierarchical data visualization.&lt;/item&gt;&lt;item&gt;FunnelChart: Process flow/conversion charts.&lt;/item&gt;&lt;item&gt;Sparkline: Mini sparklines.&lt;/item&gt;&lt;item&gt;Plot: Line, Scatter, and Braille-mode charts.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Maps: &lt;list rend="ul"&gt;&lt;item&gt;World Map: High-resolution world map example using the generic &lt;code&gt;Canvas&lt;/code&gt;widget (see&lt;code&gt;_examples/canvas.go&lt;/code&gt;).&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;World Map: High-resolution world map example using the generic &lt;/item&gt;
      &lt;item&gt;New Widgets: &lt;list rend="ul"&gt;&lt;item&gt;LineGauge: Thin, character-based progress bar with alignment options (Block, Dots, custom runic styles).&lt;/item&gt;&lt;item&gt;Scrollbar: Ratatui-compatible scrollbars (Vertical/Horizontal) with mouse and keyboard support.&lt;/item&gt;&lt;item&gt;Logo: Pixel-perfect block-style logo renderer.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Performance: &lt;list rend="ul"&gt;&lt;item&gt;Optimized Rendering: &lt;code&gt;Buffer&lt;/code&gt;uses flat slices for O(1) access, providing 2-3x speedup.&lt;/item&gt;&lt;item&gt;Zero Allocations: Drawing loops minimized for high-fps scenes (~3000 FPS potential).&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Optimized Rendering: &lt;/item&gt;
      &lt;item&gt;Layout: &lt;list rend="ul"&gt;&lt;item&gt;Grid: Responsive grid layout.&lt;/item&gt;&lt;item&gt;Tabs: Tabbed navigation.&lt;/item&gt;&lt;item&gt;Interactive: Calendar, Tables, Input, TextArea.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Styling: &lt;list rend="ul"&gt;&lt;item&gt;Rounded Borders: Optional rounded corners for blocks.&lt;/item&gt;&lt;item&gt;Full RGB Color support.&lt;/item&gt;&lt;item&gt;Border titles (Top and Bottom) with alignment (Left, Center, Right).&lt;/item&gt;&lt;item&gt;Rich styling parser for text.&lt;/item&gt;&lt;item&gt;Collapsed Borders: Support for merging adjacent block borders using &lt;code&gt;BorderCollapse&lt;/code&gt;.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Compatibility: Works with modern terminals (iTerm2, Kitty, Alacritty, Ghostty).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It is not necessary to &lt;code&gt;go get&lt;/code&gt; gotui, since Go will automatically manage any imported dependencies for you.&lt;/p&gt;
    &lt;code&gt;go get github.com/metaspartan/gotui/v4&lt;/code&gt;
    &lt;code&gt;package main

import (
	"log"

	ui "github.com/metaspartan/gotui/v4"
	"github.com/metaspartan/gotui/v4/widgets"
)

func main() {
	if err := ui.Init(); err != nil {
		log.Fatalf("failed to initialize gotui: %v", err)
	}
	defer ui.Close()

	p := widgets.NewParagraph()
	p.Text = "Hello World!"
	p.SetRect(0, 0, 25, 5)

	ui.Render(p)

	for e := range ui.PollEvents() {
		if e.Type == ui.KeyboardEvent {
			break
		}
	}
}&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;BarChart&lt;/item&gt;
      &lt;item&gt;Block&lt;/item&gt;
      &lt;item&gt;Collapsed Borders&lt;/item&gt;
      &lt;item&gt;Calendar&lt;/item&gt;
      &lt;item&gt;Canvas&lt;/item&gt;
      &lt;item&gt;Gauge&lt;/item&gt;
      &lt;item&gt;Heatmap&lt;/item&gt;
      &lt;item&gt;Image&lt;/item&gt;
      &lt;item&gt;Input&lt;/item&gt;
      &lt;item&gt;List&lt;/item&gt;
      &lt;item&gt;Logo&lt;/item&gt;
      &lt;item&gt;LineGauge&lt;/item&gt;
      &lt;item&gt;Tree&lt;/item&gt;
      &lt;item&gt;Paragraph&lt;/item&gt;
      &lt;item&gt;PieChart&lt;/item&gt;
      &lt;item&gt;Plot (for scatterplots and linecharts)&lt;/item&gt;
      &lt;item&gt;Sparkline&lt;/item&gt;
      &lt;item&gt;StackedBarChart&lt;/item&gt;
      &lt;item&gt;Scrollbar&lt;/item&gt;
      &lt;item&gt;Table&lt;/item&gt;
      &lt;item&gt;Tabs&lt;/item&gt;
      &lt;item&gt;TextArea&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Run an example with &lt;code&gt;go run _examples/{example}.go&lt;/code&gt; or run each example consecutively with &lt;code&gt;make run-examples&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;(Submit your projects via a PR)&lt;/p&gt;
    &lt;p&gt;gotui Author: Carsen Klock - X&lt;/p&gt;
    &lt;p&gt;termui Author: Zack Guo - Github&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46237146</guid><pubDate>Thu, 11 Dec 2025 21:05:27 +0000</pubDate></item><item><title>RFC 6677 DNS Transport over TCP – Implementation Requirements (2016)</title><link>https://www.ietf.org/rfc/rfc7766.txt</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46237304</guid><pubDate>Thu, 11 Dec 2025 21:18:49 +0000</pubDate></item><item><title>Powder and stone, or, why medieval rulers loved castles</title><link>https://1517.substack.com/p/powder-and-stone-or-why-medieval</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46237501</guid><pubDate>Thu, 11 Dec 2025 21:35:52 +0000</pubDate></item><item><title>Nokia N900 Necromancy – giving a new life to a classic Linux smartphone</title><link>https://yaky.dev/2025-12-11-nokia-n900-necromancy/</link><description>&lt;doc fingerprint="b6230073e3ff3e7c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Nokia N900 Necromancy&lt;/head&gt;
    &lt;p&gt;Building a fake battery, adding a USB-C port, booting from SD card, and giving a new life to a classic Linux smartphone.&lt;/p&gt;
    &lt;p&gt;My friend Dima sent me his old-school classic Nokia N900. The battery is very old, and it does not boot as-is. So naturally, I wanted to see if I can resurrect it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Step 0: Is such a thing even possible?&lt;/head&gt;
    &lt;p&gt;Yes it is! (Unless there are other hardware issues)&lt;/p&gt;
    &lt;p&gt;I ran a smartphone without a battery a few years ago.&lt;/p&gt;
    &lt;p&gt;Cut and soldered a quick prototype to connect instead of the battery. Resistors are to emulate the "normal" temperature by providing expected resistance between the third pin and ground. See link above for details.&lt;/p&gt;
    &lt;p&gt;Hooked up a large supercapacitor to the battery pins and to a +5V source. If I recall correctly, using a capacitor without additional power did not work.&lt;/p&gt;
    &lt;p&gt;And it boots!&lt;/p&gt;
    &lt;p&gt;Now, let's make something that can fit into the battery compartment.&lt;/p&gt;
    &lt;head rend="h2"&gt;Step 1: Better "battery"&lt;/head&gt;
    &lt;p&gt;These supercapacitors are nice, but way too large. After searching on Mouser, I found FM0H473ZF, 47000 mF (0.047F) capacitors in a rectangular case that is only 5mm thick.&lt;/p&gt;
    &lt;p&gt;Ten of these (~0.5F) is enough to run the smartphone without dying.&lt;/p&gt;
    &lt;p&gt;Capacitor contraption (TM) arranged (using a 3D-printed template) and soldered together.&lt;/p&gt;
    &lt;p&gt;And they all fit nicely into the battery compartment. The power is provided by a wire routed through the hole for the carry loop.&lt;/p&gt;
    &lt;p&gt;Running fine! One noticeable issue is that capacitors are getting pretty warm. Probably my sloppy soldering, but no shorts that I could find.&lt;/p&gt;
    &lt;head rend="h2"&gt;â ï¸&lt;/head&gt;
    &lt;p&gt;This is where I should have stopped. At some point while messing with the "battery" and power, I managed to corrupt the internal partition and the installed OS. Not sure if this was from the sudden battery pull or from supplying +5V instead of the expected +4.2V to the battery pins. Luckily, newer Maemo Leste is intended to run from the SD card anyway, and internal storage still works, so I was able to overwrite it with the bootloader.&lt;/p&gt;
    &lt;p&gt;Bootloader setup on Maemo Wiki&lt;/p&gt;
    &lt;head rend="h2"&gt;Step 2: Consolidating connectors&lt;/head&gt;
    &lt;p&gt;I thought it might be practical to power the "battery" through the existing USB port. Just run the +5V wire from USB to the "battery", and avoid additional wires. (If you think this is kinda stupid, you are right)&lt;/p&gt;
    &lt;p&gt;Yooo... What is happening here? Dima says "oh yeah, the USB port was re-soldered. Twice". A quick glance at the forums also confirms that USB port was poorly designed and is prone to breaking.&lt;/p&gt;
    &lt;p&gt;Just one wire from the +5V pad to the "battery". The ground is the same as the battery pin.&lt;/p&gt;
    &lt;p&gt;Assembled everything back, routed and soldered the +5V wire, and added a diode to prevent the battery from feeding the USB port, and to drop the voltage to more acceptable ~4.3V.&lt;/p&gt;
    &lt;p&gt;The setup works, but the smartphone constantly shows either "Charging", or "Device using more power than it is receiving from the PC. Charging with a compatible charger is recommended", with battery gauge going crazy.&lt;/p&gt;
    &lt;p&gt;And then, the power just cut out.&lt;/p&gt;
    &lt;p&gt;Yeah, this was not a great idea. Let's see what happened.&lt;/p&gt;
    &lt;p&gt;USB +5V wire detached itself from the port. I presume this is from either the high current, age, stress, or corrosion.&lt;/p&gt;
    &lt;p&gt;However, when I opened the smartphone up, I... ripped off the +5V pad. (dark circle in lower right on the photo)&lt;/p&gt;
    &lt;p&gt;Fuck.&lt;/p&gt;
    &lt;p&gt;After reading some N900 forums, that +5V pad is a common place to connect the replacement USB port to (which was done here), but... that is the ONLY +5V connection on the board besides the pads under the USB port itself.&lt;/p&gt;
    &lt;p&gt;FUCK!&lt;/p&gt;
    &lt;head rend="h2"&gt;ðª¦&lt;/head&gt;
    &lt;p&gt;RIP Nokia N900. I tried to resurrect you, but instead, I killed your OS and ripped out the USB port wires.&lt;/p&gt;
    &lt;head rend="h2"&gt;Step 3: Radical replacements&lt;/head&gt;
    &lt;p&gt;To be fair, N900 is far from dead. I already flashed u-boot, was able to boot from SD card, and do not plan to use internal storage otherwise. Power can be supplied entirely through the new "battery". So technically, I do not need the USB functionality for the smartphone itself, just to power the "battery". At this point, I might as well replace the port with USB-C. Because why not.&lt;/p&gt;
    &lt;p&gt;Approximate placement of the new USB port.&lt;/p&gt;
    &lt;p&gt;The location of the original port is not very convenient. It is sandwiched between the main board and the SD card reader (lower left on the photo). SD card reader is also attached by a permanently-attached ribbon (i.e. nearly irreplaceable).&lt;/p&gt;
    &lt;p&gt;First, I used a small file to make the micro-USB-shaped hole on the smartphone body fit the USB-C shape. Then, I took a small 6-pin USB-C port, cut and sanded down its plastic parts to make it fit in the original spot. It is still slightly (~0.25mm) taller than the original, but I cannot make it any slimmer.&lt;/p&gt;
    &lt;p&gt;I tried to attach the USB-C port to the board in the correct place by carefully assembling the board, port and SD card reader into the body, and using small drops of glue to lightly affix the edge of the USB port (that I could reach) to the main board. The intent was to wait for glue to cure, take everything back apart and glue the port in its now-correct position for good. This took several tries but did not really work, as the port got detached while removing the main board every time, and the the superglue I used left lots of residue but did not adhere. Luckily, the tight fit and the shape of the USB-C port hold it in place mechanically quite well.&lt;/p&gt;
    &lt;p&gt;USB-C with +5V and ground attached.&lt;/p&gt;
    &lt;p&gt;Originally, I planned to solder all 6 pins and add 5.1 Ohm pull-down resistors to CC1 and CC2 pins (for full power delivery functionality). But there is simply not enough space to route the wires, the narrow valley between the chips (in the lower right of the photo) barely fits 3, and I did not have anything thinner on hand.&lt;/p&gt;
    &lt;p&gt;Nokia N900 with a USB-C port! Looks pretty nice IMO.&lt;/p&gt;
    &lt;p&gt;Since I did not solder the pull-down resistors, this USB-C port could only be powered by a "dumb" USB-A-to-USB-C cable, at default 0.5A. Chargers with power delivery functionality cannot identify such USB-C ports, and will not provide power at all. (This is also an issue with some handheld consoles such as RGB30)&lt;/p&gt;
    &lt;p&gt;The two wires are routed to the battery compartment through a very convenient opening in the metal frame, crimped and inserted into a DuPont connector.&lt;/p&gt;
    &lt;p&gt;Back to the battery. The capacitor contraption I built before works, but was kind of flimsy, and does not have any more space for a DuPont connector. Also, I would rather use a single capacitor, but it still has to fit. Since the original battery is unusable, I might as well try to salvage it, too.&lt;/p&gt;
    &lt;p&gt;Take off the sticker (that tells you not to do so :). The top BCM piece is held to the main battery body by two tiny screws (hidden under some crumbly compound) on each end, double-sided sticker, and a single lead in the middle.&lt;/p&gt;
    &lt;p&gt;Battery Control Module. Interestingly, for this battery, the body is the positive terminal. So the positive lead connects the battery body and the positive pin directly, while the negative lead goes thorough some control circuitry. Attaching a capacitor to these battery terminals should be sufficient.&lt;/p&gt;
    &lt;p&gt;Since I have a 3D printer, and once you have one, every problem can be solved by printing stuff, I printed the new "battery" to accommodate a large capacitor, diode (for voltage drop), wires, DuPont connectors, and the original battery's BCM.&lt;/p&gt;
    &lt;p&gt;N900 with a new "battery". Fits really tight, and only 0.25-0.5mm too tall, so the cover still snaps closed.&lt;/p&gt;
    &lt;p&gt;Boots without problems. Since the attached capacitor is pretty large, it can take a minute or two to charge it to an acceptable level (~4.0V) with a 0.5A current.&lt;/p&gt;
    &lt;p&gt;Nokia N900 enjoying its new life as an online radio device using Open Media Player.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46239177</guid><pubDate>Fri, 12 Dec 2025 00:04:29 +0000</pubDate></item></channel></rss>