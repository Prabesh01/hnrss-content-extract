<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 26 Jan 2026 16:57:42 +0000</lastBuildDate><item><title>The future of software engineering is SRE</title><link>https://swizec.com/blog/the-future-of-software-engineering-is-sre/</link><description>&lt;doc fingerprint="bd4e911dfc4564fd"&gt;
  &lt;main&gt;
    &lt;p&gt;When code gets cheap operational excellence wins. Anyone can build a greenfield demo, but it takes engineering to run a service.&lt;/p&gt;
    &lt;p&gt;You may be wondering: With all the hype about agentic coding, will we even need software engineers anymore? Yes! We'll need more.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;SRE about to become the most hired job in engineering&lt;/p&gt;‚Äî Swizec Teller (@Swizec) January 13, 2026&lt;lb/&gt;Everybody wants to write a greenfield demo.&lt;lb/&gt;Nobody wants to run a service. https://t.co/THl9rBJ9rk&lt;/quote&gt;
    &lt;p&gt;Writing code was always the easy part of this job. The hard part was keeping your code running for the long time. Software engineering is programming over time. It's about how systems change.&lt;/p&gt;
    &lt;head rend="h2"&gt;Lessons from the no-code and spreadsheets era&lt;/head&gt;
    &lt;p&gt;Let's take no-code and spreadsheets as an example of the kind of software people say is the future ‚Äì custom-built, throwaway, built by non-experts to solve specific problems.&lt;/p&gt;
    &lt;p&gt;Joe Schmoe from accounting takes 10 hours to do a thing. He's does this every week and it feels repetitive, mechanical, and boring. Joe could do the work in his sleep.&lt;/p&gt;
    &lt;p&gt;But he can't get engineering resources to build a tool. The engineers are busy building the product. No worries, Joe is a smart dude. With a little Googling, a few no-code tools, and good old spreadsheet macros he builds a tool.&lt;/p&gt;
    &lt;p&gt;Amazing.&lt;/p&gt;
    &lt;p&gt;Joe's tool is a little janky but his 10 hour weekly task now takes 1 hour! üéâ Sure, he finds a new edge case every every week and there's constant tinkering, but he's having a lot more fun.&lt;/p&gt;
    &lt;p&gt;Time passes, the business changes, accounting rules are in constant flux, and let's never talk about timezones or daylight savings ever again. Joe is sick of this bullshit.&lt;/p&gt;
    &lt;p&gt;All he wanted was to make his job easier and now he's shackled to this stupid system. He can't go on vacation, he can't train anyone else to run this thing successfully, and it never fucking works right.&lt;/p&gt;
    &lt;p&gt;Joe can't remember the last time running his code didn't fill him with dread. He spends hours carefully making sure it all worked.&lt;/p&gt;
    &lt;head rend="h2"&gt;The computer disease&lt;/head&gt;
    &lt;p&gt;Feynman called this the computer disease.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Feynman called this The Computer Disease pic.twitter.com/Zv4Bu4ftv1&lt;/p&gt;‚Äî Swizec Teller (@Swizec) December 26, 2025&lt;/quote&gt;
    &lt;p&gt;The problem with computers is that you tinker. Automating things is fun! You might forget you don't need to üòÜ&lt;/p&gt;
    &lt;p&gt;The part that's not fun is running things. Providing a service. Reliably, at scale, for years on end. A service that people will hire to do their jobs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why operational excellence is the future&lt;/head&gt;
    &lt;p&gt;People don't buy software, they hire a service.&lt;/p&gt;
    &lt;p&gt;You don't care how iCloud works, you just want your photos to magically show up across devices every time. You don't care about Word or Notion or gDocs, you just want to write what's on your mind, share it with others, and see their changes. And you definitely don't care how a payments network point of sale terminal and your bank talk to each other, you just want your $7 matcha latte to get you through the week.&lt;/p&gt;
    &lt;p&gt;Good software is invisible.&lt;/p&gt;
    &lt;p&gt;And that takes work. A lot of work. Because the first 90% to get a working demo is easy. It's the other 190% that matters.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;What's your uptime?&lt;/item&gt;
      &lt;item&gt;Defect rate?&lt;/item&gt;
      &lt;item&gt;How quickly do you recover from defects?&lt;/item&gt;
      &lt;item&gt;Do I have to reach out or will you know before me?&lt;/item&gt;
      &lt;item&gt;Can you own upstream dependencies?&lt;/item&gt;
      &lt;item&gt;When a vendor misbehaves, will you notice or wait until your users complain?&lt;/item&gt;
      &lt;item&gt;When users share ideas, how long does it take?&lt;/item&gt;
      &lt;item&gt;How do you keep engineers from breaking each other's systems?&lt;/item&gt;
      &lt;item&gt;Do you have systems to keep engineers moving without turning your app into a disjointed mess?&lt;/item&gt;
      &lt;item&gt;Can you build software bigger than fits in 1 person's brain?&lt;/item&gt;
      &lt;item&gt;When I'm in a 12 hour different timezone, your engineers are asleep, and there's a big issue ... will it be fixed before I give up?&lt;/item&gt;
      &lt;item&gt;Can you recover from failures, yours and upstream, or does important data get lost?&lt;/item&gt;
      &lt;item&gt;Are you keeping up with security updates?&lt;/item&gt;
      &lt;item&gt;Will you leak all my data?&lt;/item&gt;
      &lt;item&gt;Do I trust you?&lt;/item&gt;
      &lt;item&gt;Can I rely on you?&lt;/item&gt;
      &lt;item&gt;How can you be so sure?&lt;/item&gt;
      &lt;item&gt;Will you sign a legally binding guarantee that your software works when I need it? üòâ&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Those are the ~~fun~~ hard engineering challenges. Writing code is easy.&lt;/p&gt;
    &lt;p&gt;Cheers,&lt;lb/&gt; ~Swizec&lt;/p&gt;
    &lt;head rend="h3"&gt;Scaling Fast book free preview&lt;/head&gt;
    &lt;p&gt;Enter your email to receive a sample chapter of Scaling Fast: Software Engineering Through the Hockeystick and learn how to navigate hypergrowth without burning out your team.&lt;/p&gt;
    &lt;p&gt;Have a burning question that you think I can answer? Hit me up on twitter and I'll do my best.&lt;/p&gt;
    &lt;p&gt;Who am I and who do I help? I'm Swizec Teller and I turn coders into engineers with "Raw and honest from the heart!" writing. No bullshit. Real insights into the career and skills of a modern software engineer.&lt;/p&gt;
    &lt;p&gt;Want to become a true senior engineer? Take ownership, have autonomy, and be a force multiplier on your team. The Senior Engineer Mindset ebook can help üëâ swizec.com/senior-mindset. These are the shifts in mindset that unlocked my career.&lt;/p&gt;
    &lt;p&gt;Curious about Serverless and the modern backend? Check out Serverless Handbook, for frontend engineers üëâ ServerlessHandbook.dev&lt;/p&gt;
    &lt;p&gt;Want to Stop copy pasting D3 examples and create data visualizations of your own? Learn how to build scalable dataviz React components your whole team can understand with React for Data Visualization&lt;/p&gt;
    &lt;p&gt;Want to get my best emails on JavaScript, React, Serverless, Fullstack Web, or Indie Hacking? Check out swizec.com/collections&lt;/p&gt;
    &lt;p&gt;Did someone amazing share this letter with you? Wonderful! You can sign up for my weekly letters for software engineers on their path to greatness, here: swizec.com/blog&lt;/p&gt;
    &lt;p&gt;Want to brush up on your modern JavaScript syntax? Check out my interactive cheatsheet: es6cheatsheet.com&lt;/p&gt;
    &lt;p&gt;By the way, just in case no one has told you it yet today: I love and appreciate you for who you are ‚ù§Ô∏è&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46759063</guid><pubDate>Sun, 25 Jan 2026 22:18:38 +0000</pubDate></item><item><title>Scientists identify brain waves that define the limits of 'you'</title><link>https://www.sciencealert.com/scientists-identify-brain-waves-that-define-the-limits-of-you</link><description>&lt;doc fingerprint="b103d32cb0e38d8a"&gt;
  &lt;main&gt;
    &lt;p&gt;At what point do "you" end and the outside world begins?&lt;/p&gt;
    &lt;p&gt;It might feel like a weird question with an obvious answer, but your brain has to work surprisingly hard to judge that boundary. Now, scientists have linked a specific set of brain waves in a certain part of the brain to a sense of body ownership.&lt;/p&gt;
    &lt;p&gt;In a series of new experiments, researchers from Sweden and France put 106 participants through what's called the rubber hand illusion, monitoring and stimulating their brain activity to see what effect it had.&lt;/p&gt;
    &lt;p&gt;Related: Octopuses Fall For The Classic Fake Arm Trick ‚Äì Just Like We Do&lt;/p&gt;
    &lt;p&gt;This classic illusion involves hiding one of a participant's hands from their view and replacing it with a rubber one instead. When both their real and fake hands are repeatedly touched at the same time, it can evoke the eerie sensation that the rubber hand is part of the person's body.&lt;/p&gt;
    &lt;p&gt;The tests, which in one experiment involved EEG (electroencephalography) readings of brain activity, revealed that a sense of body ownership seems to arise from the frequency of alpha waves in the parietal cortex, a brain region responsible for mapping the body, processing sensory input and building a sense of self.&lt;/p&gt;
    &lt;p&gt;"We have identified a fundamental brain process that shapes our continuous experience of being embodied," says lead author Mariano D'Angelo, a neuroscientist at Karolinska Institute in Sweden.&lt;/p&gt;
    &lt;p&gt;"The findings may provide new insights into psychiatric conditions such as schizophrenia, where the sense of self is disturbed."&lt;/p&gt;
    &lt;p&gt;In the first batch of experiments, participants had a robotic arm tap the index finger of their real and fake hands, either at the exact same time or with a delay of up to 500 milliseconds between each tap.&lt;/p&gt;
    &lt;p&gt;As expected, participants reported feeling that the fake hand was part of their body more strongly if the taps were synchronized, and the feeling steadily weakened as the gap widened between what they felt and what they saw.&lt;/p&gt;
    &lt;p&gt;The EEG readings from the second experiment added more detail to the story. The frequency of alpha waves in the parietal cortex seemed to correlate with how well participants could detect the time delay between taps.&lt;/p&gt;
    &lt;p&gt;Those with faster alpha waves appeared to rule out fake hands even with a tiny gap in taps, while those with slower waves were more likely to feel the fake hand as their own, even if the taps were farther apart.&lt;/p&gt;
    &lt;p&gt;Finally, the researchers investigated whether the frequency of these brain waves actually controls the sensation of body ownership, or if they were perhaps both effects of some other factor.&lt;/p&gt;
    &lt;p&gt;With a third group of participants, they used a non-invasive technique called transcranial alternating current stimulation to speed up or slow down the frequency of a person's alpha waves. And sure enough, this seemed to correlate with how real a fake hand felt.&lt;/p&gt;
    &lt;p&gt;Speeding up someone's alpha waves gave them a tighter sense of body ownership, making them more sensitive to small timing discrepancies. Slowing down the waves had the opposite effect, making it harder for people to tell the difference between their own body and the outside world.&lt;/p&gt;
    &lt;p&gt;"Our findings help explain how the brain solves the challenge of integrating signals from the body to create a coherent sense of self," says Henrik Ehrsson, neuroscientist at Karolinska.&lt;/p&gt;
    &lt;p&gt;The researchers say that the findings could lead to new understanding of or treatments for conditions where the brain's body maps have gone askew, such as schizophrenia or the sensation of 'phantom limbs' experienced by amputees.&lt;/p&gt;
    &lt;p&gt;It could also help make for more realistic prosthetic limbs or even virtual reality tools.&lt;/p&gt;
    &lt;p&gt;The research was published in the journal Nature Communications.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46760099</guid><pubDate>Mon, 26 Jan 2026 00:10:42 +0000</pubDate></item><item><title>Running the Stupid Cricut Software on Linux</title><link>https://arthur.pizza/2025/12/running-stupid-cricut-software-under-linux/</link><description>&lt;doc fingerprint="171f99183bc7b5f9"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Why The Hell Would You do This?&lt;/head&gt;
    &lt;p&gt;I‚Äôm more than happy building vector designs in Inkscape. It‚Äôs the most proficient vector designer app that is free, open source, and runs natively under Linux. However, simply having a quality SVG is only part of the process when it comes to using a plotter like the Cricut.&lt;/p&gt;
    &lt;p&gt;On my own, I would not recommend the Cricut brand, but this is a machine that was bought years ago, and I want to get the most usage out of it.&lt;/p&gt;
    &lt;head rend="h2"&gt;How to Install Cricut Design Space&lt;/head&gt;
    &lt;p&gt;As far as I can tell, almost everything works in the Cricut Design Space application under Linux. The only bug I‚Äôve noticed is the application becomes invisible when going full screen. This could easily be a Wayland bug too. I have no idea. Ideally, Cricut could Easily make a Linux Application with WINE. I could see this as a Flatpak install. I understand why they don‚Äôt, as that comes with the expectation of support, and supporting another operating system costs money.&lt;/p&gt;
    &lt;p&gt;This is a multistep process that you only really have to do once. Because of the complexity, I decided to lay out the instructions, along with the ‚Äòwhy‚Äô of the situation. The more you understand how it works, the more armed you are if anything goes wrong.&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting the Software&lt;/head&gt;
    &lt;p&gt;I HIGHTLY recommend grabbing a fresh build of WINE. I‚Äôm a Debian user, so depending on the build of Linux you‚Äôre using it might vary, but I start on the Wine HQ Git. I know a lot of people might want to run a platform like Wine Bottles, but in my experience a more granular project like this is just easier under regular WINE.&lt;/p&gt;
    &lt;head rend="h3"&gt;OS Detection on the Website&lt;/head&gt;
    &lt;p&gt;When you visit the Design Space Download Page, it seems that the developer chose to use OS detection on the website. If it sees your user agent listed as Linux, for some weird reason it defaults to Mac. Logically, it would make more sense to default to the Windows build, but I think there was some corner cutting on this.&lt;/p&gt;
    &lt;p&gt;I recommend the open source UserAgent Switcher for this, as it has a build for Firefox and Chromium based browsers. (And of course, is free and open source.) After setting to ‚ÄúWindows 10‚Äù mode and refreshing the page:&lt;/p&gt;
    &lt;head rend="h2"&gt;Installing the Software&lt;/head&gt;
    &lt;p&gt;As of this tutorial, the latest build of Design Space is &lt;code&gt;CricutDesignSpace-Install-v9.47.92.exe&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Make sure you‚Äôve setup your install of WINE first. run &lt;code&gt;winecfg&lt;/code&gt; and make sure everything is working.&lt;/p&gt;
    &lt;code&gt;wine CricutDesignSpace-Install-v9.47.92.exe
&lt;/code&gt;
    &lt;p&gt;This will launch the installer. Just install like you normally would under Windows.&lt;/p&gt;
    &lt;head rend="h2"&gt;Logging in, the Stupid Parts‚Ä¶&lt;/head&gt;
    &lt;p&gt;First we need to find the binary with the &lt;code&gt;where&lt;/code&gt; command. Here‚Äôs how it looked on my machine.&lt;/p&gt;
    &lt;code&gt;where cricut
cricut: aliased to wine '/home/art/.wine/drive_c/users/art/AppData/Local/Programs/Cricut Design Space/Cricut Design Space.exe'
&lt;/code&gt;
    &lt;p&gt;Then we need to open two terminals (or two sessions, I use tmux for that).&lt;/p&gt;
    &lt;p&gt;Terminal #1&lt;/p&gt;
    &lt;code&gt;wine Cricut\ Design\ Space.exe
&lt;/code&gt;
    &lt;p&gt;This will show the login panel and will want to launch your default browser. On my machine, that‚Äôs my native Firefox. Login there, and you‚Äôll see a url asking for the Cricut software. Because your native browser and the wine wrapped cricut software can‚Äôt see each other, you gotta extract the part of the URL that features &lt;code&gt;code=&lt;/code&gt;. In the second terminal:&lt;/p&gt;
    &lt;p&gt;Terminal #2&lt;/p&gt;
    &lt;code&gt;wine Cricut\ Design\ Space.exe "cricut://?code=XXXXXXXXXXXXXXXXXXX
&lt;/code&gt;
    &lt;p&gt;You should be logged in!&lt;/p&gt;
    &lt;p&gt;Now you can start uploading your designs and colaborating with other through their locked down, proprietary platform. You can even waste money on stock images.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46761761</guid><pubDate>Mon, 26 Jan 2026 04:05:38 +0000</pubDate></item><item><title>The browser is the sandbox</title><link>https://simonwillison.net/2026/Jan/25/the-browser-is-the-sandbox/</link><description>&lt;doc fingerprint="5daa04924fbda384"&gt;
  &lt;main&gt;
    &lt;p&gt;the browser is the sandbox. Paul Kinlan is a web platform developer advocate at Google and recently turned his attention to coding agents. He quickly identified the importance of a robust sandbox for agents to operate in and put together these detailed notes on how the web browser can help:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;This got me thinking about the browser. Over the last 30 years, we have built a sandbox specifically designed to run incredibly hostile, untrusted code from anywhere on the web, the instant a user taps a URL. [...]&lt;/p&gt;
      &lt;p&gt;Could you build something like Cowork in the browser? Maybe. To find out, I built a demo called Co-do that tests this hypothesis. In this post I want to discuss the research I've done to see how far we can get, and determine if the browser's ability to run untrusted code is useful (and good enough) for enabling software to do more for us directly on our computer.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Paul then describes how the three key aspects of a sandbox - filesystem, network access and safe code execution - can be handled by browser technologies: the File System Access API (still Chrome-only as far as I can tell), CSP headers with &lt;code&gt;&amp;lt;iframe sandbox&amp;gt;&lt;/code&gt; and WebAssembly in Web Workers.&lt;/p&gt;
    &lt;p&gt;Co-do is a very interesting demo that illustrates all of these ideas in a single application:&lt;/p&gt;
    &lt;p&gt;You select a folder full of files and configure an LLM provider and set an API key, Co-do then uses CSP-approved API calls to interact with that provider and provides a chat interface with tools for interacting with those files. It does indeed feel similar to Claude Cowork but without running a multi-GB local container to provide the sandbox.&lt;/p&gt;
    &lt;p&gt;My biggest complaint about &lt;code&gt;&amp;lt;iframe sandbox&amp;gt;&lt;/code&gt; remains how thinly documented it is, especially across different browsers. Paul's post has all sorts of useful details on that which I've not encountered elsewhere, including a complex double-iframe technique to help apply network rules to the inner of the two frames.&lt;/p&gt;
    &lt;p&gt;Thanks to this post I also learned about the &lt;code&gt;&amp;lt;input type="file" webkitdirectory&amp;gt;&lt;/code&gt; tag which turns out to work on Firefox, Safari and Chrome and allows a browser read-only access to a full directory of files at once. I had Claude knock up a webkitdirectory demo to try it out and I'll certainly be using it for projects in the future.&lt;/p&gt;
    &lt;head rend="h2"&gt;Recent articles&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Wilson Lin on FastRender: a browser built by thousands of parallel agents - 23rd January 2026&lt;/item&gt;
      &lt;item&gt;First impressions of Claude Cowork, Anthropic's general agent - 12th January 2026&lt;/item&gt;
      &lt;item&gt;My answers to the questions I posed about porting open source code with LLMs - 11th January 2026&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46762150</guid><pubDate>Mon, 26 Jan 2026 05:23:01 +0000</pubDate></item><item><title>The Holy Grail of Linux Binary Compatibility: Musl and Dlopen</title><link>https://github.com/quaadgras/graphics.gd/discussions/242</link><description>&lt;doc fingerprint="edda3afb1a94b6a8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Holy Grail of Linux Binary Compatibility: musl + dlopen #242&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;I guess using Go + Godot to build native &amp;amp; installable Android &amp;amp; iOS binaries (without any proprietary SDKs) was too easy. So it's time for a real challenge...&lt;/p&gt;
          &lt;head&gt;Linux Binary Compatibility&lt;/head&gt;
          &lt;p&gt;(some background reading: https://jangafx.com/insights/linux-binary-compatibility)&lt;/p&gt;
          &lt;p&gt;For a while now, it's been very easy to reliably ship command line software &amp;amp; servers for Linux, just run &lt;/p&gt;
          &lt;p&gt;The problems begin to creep in when you want access to hardware accelerated graphics. All the GPU drivers on Linux require accessing dynamic libraries via the C ABI. These C libraries are built against a particular libc, which is most commonly &lt;/p&gt;
          &lt;p&gt;In fact, I've directly experienced this, as I recently replaced the OS on my personal computer with the &lt;/p&gt;
          &lt;p&gt;That's a problem, firstly because this is my distro now, I need to be able to build graphics.gd projects! Secondly, in theory, &lt;/p&gt;
          &lt;head&gt;Supporting &lt;/head&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;head rend="h2"&gt;Replies: 2 comments 2 replies&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;I use the dlopen/dlsym technique in Linux and loadlibrary/getprocaddress in my language's VM.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Doesn't work for me:&lt;/p&gt;
          &lt;code&gt;Thread 1 "dodge_the_creep" received signal SIGSEGV, Segmentation fault.
0x0000000002b13d16 in foreign_tramp ()
(gdb) bt
#0  0x0000000002b13d16 in foreign_tramp ()
#1  0x00007fffaa55a5a0 in ?? ()
#2  0x00007ffff75e4558 in ?? ()
#3  0x00007fff5ffec436 in ?? ()
#4  0x00007fffaa2ed710 in ?? ()
#5  0x00007fffffffc0d0 in ?? ()
#6  0x00007fff5ffe5ecc in ?? ()
#7  0x00007fffffffc0d0 in ?? ()
#8  0x00007fff5f9cc488 in ?? ()
#9  0x00007fffaa559a40 in ?? ()
#10 0x0000000000000000 in ?? ()
(gdb)&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46762882</guid><pubDate>Mon, 26 Jan 2026 07:41:52 +0000</pubDate></item><item><title>MapLibre Tile: a modern and efficient vector tile format</title><link>https://maplibre.org/news/2026-01-23-mlt-release/</link><description>&lt;doc fingerprint="4787f953dcbb25f4"&gt;
  &lt;main&gt;
    &lt;p&gt;Jan 23, 2026&lt;/p&gt;
    &lt;p&gt;Today we are happy to announce MapLibre Tile (MLT), a new modern and efficient vector tile format.&lt;/p&gt;
    &lt;p&gt;MapLibre Tile (MLT) is a succesor to Mapbox Vector Tile (MVT). It has been redesigned from the ground up to address the challenges of rapidly growing geospatial data volumes and complex next-generation geospatial source formats, as well as to leverage the capabilities of modern hardware and APIs.&lt;/p&gt;
    &lt;p&gt;MLT is specifically designed for modern and next-generation graphics APIs to enable high-performance processing and rendering of large (planet-scale) 2D and 2.5 basemaps. This current implementation offers feature parity with MVT1 while delivering on the following:&lt;/p&gt;
    &lt;p&gt;In addition, MLT was designed to support the following use cases in the future:&lt;/p&gt;
    &lt;p&gt;As with any MapLibre project, the future of MLT is decided by the needs of the community. There are a lot of exciting ideas for other future extensions and we welcome contributions to the project.&lt;/p&gt;
    &lt;p&gt;For a more in-depth exploration of MLT have a look at the following slides, watch this talk or read this publication by MLT inventor Markus Tremmel.&lt;/p&gt;
    &lt;p&gt;For the adventurous, the answer is: today. Both MapLibre GL JS and MapLibre Native now support MLT sources. You can use the new &lt;code&gt;encoding&lt;/code&gt; property on sources in your style JSON with a value of &lt;code&gt;mlt&lt;/code&gt; for MLT vector tile sources.&lt;/p&gt;
    &lt;p&gt;To try out MLT, you have the following options:&lt;/p&gt;
    &lt;p&gt;Refer to this page for a complete and up-to-date list of integrations and implementations. If you are an integrator working on supporting MLT, feel free to add your own project there.&lt;/p&gt;
    &lt;p&gt;We would love to hear your experience with using MLT! Join the &lt;code&gt;#maplibre-tile-format&lt;/code&gt; channel on our Slack or create an Issue or Discussion on the tile spec repo.&lt;/p&gt;
    &lt;p&gt;MapLibre Tile came to be thanks to a multi-year collaboration between academia, open source and enterprise. Thank you to everyone who was involved! We are very proud that our community can innovate like this.&lt;/p&gt;
    &lt;p&gt;Special thanks go to Markus Tremmel for inventing the format, Yuri Astrakhan for spearheading the project, Tim Sylvester for the C++ implementation, Harel Mazor, Benedikt Vogl and Niklas Greindl for working on the JavaScript implementation.&lt;/p&gt;
    &lt;p&gt;Also thanks to Microsoft and AWS for financing work on MLT.&lt;/p&gt;
    &lt;p&gt;One exception: unlike MVT, MLT does not support layers where a value in a column changes type from feature to feature. ‚Ü©&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46763864</guid><pubDate>Mon, 26 Jan 2026 10:19:51 +0000</pubDate></item><item><title>Show HN: Only 1 LLM can fly a drone</title><link>https://github.com/kxzk/snapbench</link><description>&lt;doc fingerprint="4fd783f63903440d"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;Inspired by Pok√©mon Snap (1999). VLM pilots a drone through 3D world to locate and identify creatures.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;code&gt;%%{init: {'theme': 'base', 'themeVariables': { 'background': '#ffffff', 'primaryColor': '#ffffff'}}}%%
flowchart LR
    subgraph Controller["**Controller** (Rust)"]
        C[Orchestration]
    end

    subgraph VLM["**VLM** (OpenRouter)"]
        V[Vision-Language Model]
    end

    subgraph Simulation["**Simulation** (Zig/raylib)"]
        S[Game State]
    end

    C --&amp;gt;|"screenshot + prompt"| V
    C &amp;lt;--&amp;gt;|"cmds + state&amp;lt;br&amp;gt;**UDP:9999**"| S

    style Controller fill:#8B5A2B,stroke:#5C3A1A,color:#fff
    style VLM fill:#87CEEB,stroke:#5BA3C6,color:#1a1a1a
    style Simulation fill:#4A7C23,stroke:#2D5A10,color:#fff
    style C fill:#B8864A,stroke:#8B5A2B,color:#fff
    style V fill:#B5E0F7,stroke:#87CEEB,color:#1a1a1a
    style S fill:#6BA33A,stroke:#4A7C23,color:#fff
&lt;/code&gt;
    &lt;p&gt;The simulation generates procedural terrain and spawns creatures (cat, dog, pig, sheep) for the drone to discover. It handles drone physics and collision detection, accepting 8 movement commands plus &lt;code&gt;identify&lt;/code&gt; and &lt;code&gt;screenshot&lt;/code&gt;. The Rust controller captures frames from the simulation, constructs prompts enriched with position and state data, then parses VLM responses into executable command sequences. The objective: locate and successfully identify 3 creatures, where &lt;code&gt;identify&lt;/code&gt; succeeds when the drone is within 5 units of a target.&lt;/p&gt;
    &lt;head class="px-3 py-2"&gt;demo_3x.mov&lt;/head&gt;
    &lt;p&gt;I gave 7 frontier LLMs a simple task: pilot a drone through a 3D voxel world and find 3 creatures.&lt;/p&gt;
    &lt;p&gt;Only one could do it.&lt;/p&gt;
    &lt;p&gt;Is this a rigorous benchmark? No. However, it's a reasonably fair comparison - same prompt, same seeds, same iteration limits. I'm sure with enough refinement you could coax better results out of each model. But that's kind of the point: out of the box, with zero hand-holding, only one model figured out how to actually fly.&lt;/p&gt;
    &lt;p&gt;The core differentiator wasn't intelligence - it was altitude control. Creatures sit on the ground. To identify them, you need to descend.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Gemini Flash: Actively adjusts altitude, descends to creature level, identifies&lt;/item&gt;
      &lt;item&gt;GPT-5.2-chat: Gets close horizontally but never lowers&lt;/item&gt;
      &lt;item&gt;Claude Opus: Attempts identification 160+ times, never succeeds - approaching at wrong angles&lt;/item&gt;
      &lt;item&gt;Others: Wander randomly or get stuck&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This left me puzzled. Claude Opus is arguably the most capable model in the lineup. It knows it needs to identify creatures. It tries - aggressively. But it never adjusts its approach angle.&lt;/p&gt;
    &lt;p&gt;Run 13 (seed 72) was the only run where any model found 2 creatures. Why? They happened to spawn near each other. Gemini Flash found one, turned around, and spotted the second.&lt;/p&gt;
    &lt;p&gt;In most other runs, Flash found one creature quickly but ran out of iterations searching for the others. The world is big. 50 iterations isn't a lot of time.&lt;/p&gt;
    &lt;p&gt;This was the most surprising finding. I expected:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Claude Opus 4.5 (most expensive) to dominate&lt;/item&gt;
      &lt;item&gt;Gemini 3 Pro to outperform Gemini 3 Flash (same family, more capability)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Instead, the cheapest model beat models costing 10x more.&lt;/p&gt;
    &lt;p&gt;What's going on here? A few theories:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Spatial reasoning doesn't scale with model size - at least not yet&lt;/item&gt;
      &lt;item&gt;Flash was trained differently - maybe more robotics data, more embodied scenarios?&lt;/item&gt;
      &lt;item&gt;Smaller models follow instructions more literally - "go down" means go down, not "consider the optimal trajectory"&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I genuinely don't know. But if you're building an LLM-powered agent that needs to navigate physical or virtual space, the most expensive model might not be your best choice.&lt;/p&gt;
    &lt;p&gt;Anecdotally, creatures with higher contrast (gray sheep, pink pigs) seemed easier to spot than brown-ish creatures that blended into the terrain. A future version might normalize creature visibility. Or maybe that's the point - real-world object detection isn't normalized either.&lt;/p&gt;
    &lt;p&gt;Before this, I tried having LLMs pilot a real DJI Tello drone.&lt;/p&gt;
    &lt;p&gt;Results: it flew straight up, hit the ceiling, and did donuts until I caught it. (I was using Haiku 4.5, which in hindsight explains a lot.)&lt;/p&gt;
    &lt;p&gt;The Tello is now broken. I've ordered a BetaFPV and might get another Tello since they're so easy to program. Now that I know Gemini Flash can actually navigate, a real-world follow-up might be worth revisiting.&lt;/p&gt;
    &lt;p&gt;This is half-serious research, half "let's see what happens."&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The simulation has rough edges (it's a side project, not a polished benchmark suite)&lt;/item&gt;
      &lt;item&gt;One blanket prompt is used for all models - model-specific tuning would likely improve results&lt;/item&gt;
      &lt;item&gt;The feedback loop is basic (position, screenshot, recent commands) - there's room to get creative with what information gets passed back&lt;/item&gt;
      &lt;item&gt;Iteration limits (50) may artificially cap models that are slower but would eventually succeed&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Tool&lt;/cell&gt;
        &lt;cell role="head"&gt;Version&lt;/cell&gt;
        &lt;cell role="head"&gt;Install&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Zig&lt;/cell&gt;
        &lt;cell&gt;‚â•0.15.2&lt;/cell&gt;
        &lt;cell&gt;ziglang.org/download&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Rust&lt;/cell&gt;
        &lt;cell&gt;stable (2024 edition)&lt;/cell&gt;
        &lt;cell&gt;rust-lang.org/tools/install&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Python&lt;/cell&gt;
        &lt;cell&gt;‚â•3.11&lt;/cell&gt;
        &lt;cell&gt;python.org&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;uv&lt;/cell&gt;
        &lt;cell&gt;latest&lt;/cell&gt;
        &lt;cell&gt;docs.astral.sh/uv&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;You'll also need an OpenRouter API key.&lt;/p&gt;
    &lt;code&gt;gh repo clone kxzk/snapbench
cd snapbench

# set your API key
export OPENROUTER_API_KEY="sk-or-..."&lt;/code&gt;
    &lt;code&gt;# terminal 1: start the simulation (with optional seed)
zig build run -Doptimize=ReleaseFast -- 42
# or
make sim

# terminal 2: start the drone controller
cargo run --release --manifest-path llm_drone/Cargo.toml -- --model google/gemini-3-flash-preview
# or
make drone&lt;/code&gt;
    &lt;code&gt;# runs all models defined in bench/models.toml
uv run bench/bench_runner.py
# or
make bench&lt;/code&gt;
    &lt;p&gt;Results get saved to &lt;code&gt;data/run_&amp;lt;id&amp;gt;.csv&lt;/code&gt;.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Model-specific prompts: Tune instructions to each model's strengths&lt;/item&gt;
      &lt;item&gt;Richer feedback: Pass more spatial context (distance readings, compass, minimap?)&lt;/item&gt;
      &lt;item&gt;Multi-agent runs: What if you gave each model a drone and made them compete?&lt;/item&gt;
      &lt;item&gt;Extended iterations: Let slow models run longer to isolate reasoning from speed&lt;/item&gt;
      &lt;item&gt;Real drone benchmark: Gemini Flash vs. the BetaFPV&lt;/item&gt;
      &lt;item&gt;Pok√©mon assets: Found low-poly Pok√©mon models on Poly Pizza‚Äîleaning into the Pok√©mon Snap inspiration&lt;/item&gt;
      &lt;item&gt;World improvements: Larger terrain, better visuals, performance optimizations&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Drone by NateGazzard CC-BY via Poly Pizza&lt;/item&gt;
      &lt;item&gt;Cube World Kit by Quaternius via Poly Pizza&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Donated to Poly Pizza to support the platform.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46764170</guid><pubDate>Mon, 26 Jan 2026 11:00:44 +0000</pubDate></item><item><title>TSMC Risk</title><link>https://stratechery.com/2026/tsmc-risk/</link><description>&lt;doc fingerprint="6380d4514daed7ef"&gt;
  &lt;main&gt;
    &lt;p&gt;Listen to this post:&lt;/p&gt;
    &lt;p&gt;You probably think, given this title, you know what this Article is about. The most advanced semiconductors are made by TSMC in Taiwan,1 and Taiwan is claimed by China, which has not and will not take reunification-by-force off of the table.&lt;/p&gt;
    &lt;p&gt;Relatedly, AI obviously has significant national security implications; at Davos, Anthropic CEO Dario Amodei reiterated his objection to the U.S. allowing the sale of Nvidia chips to China. From Bloomberg:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Anthropic Chief Executive Officer Dario Amodei said selling advanced artificial intelligence chips to China is a blunder with ‚Äúincredible national security implications‚Äù as the US moves to allow Nvidia Corp. to sell its H200 processors to Beijing. ‚ÄúIt would be a big mistake to ship these chips,‚Äù Amodei said in an interview with Bloomberg Editor-in-Chief John Micklethwait at the World Economic Forum in Davos, Switzerland. ‚ÄúI think this is crazy. It‚Äôs a bit like selling nuclear weapons to North Korea.‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The nuclear weapon analogy is an interesting one: a lot of game theory was developed to manage the risk of nuclear weapons, particularly once the U.S.S.R. gained/stole nuclear capability, ending the U.S.‚Äôs brief monopoly on the technology. Before that happened, however, the U.S. had a dominant military position, given we had nuclear weapons and no one else did. Perhaps Amodei believes the U.S. should have advanced AI and China should not, giving us a dominant military position?&lt;/p&gt;
    &lt;p&gt;The problem with that reality, however, is Taiwan, as I explained in AI Promise and Chip Precariousness. AI, in contrast to nuclear weapons, has a physical dependency in Taiwan that can be easily destroyed by Chinese missiles, even without an invasion; if we got to a situation where only the U.S. had the sort of AI that would give us an unassailable advantage militarily, then the optimal strategy for China would change to taking TSMC off of the board.&lt;/p&gt;
    &lt;p&gt;Given this dependency, my recommendations in the Article run counter to Amodei: I want China dependent on not just U.S. chips but also on TSMC directly, which is why I argued in favor of selling Nvidia chips to China, and further believe that Huawei and other Chinese companies ought to be able to source from TSMC (on the flip side, I would ban the sale of semiconductor manufacturing equipment to Chinese fabs). I think it‚Äôs a good thing the Trump administration moved on the first point, at least.&lt;/p&gt;
    &lt;p&gt;However, this risk is not what this Article is about: there is another TSMC risk facing the entire AI industry in particular; moreover, it‚Äôs a risk the downside of which is already being realized.&lt;/p&gt;
    &lt;head rend="h3"&gt;The TSMC Brake&lt;/head&gt;
    &lt;p&gt;There was one refrain that was common across Big Tech earnings last quarter: demand for AI exceeds supply. Here was Amazon CEO Andy Jassy on the company‚Äôs earnings call:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;You‚Äôre going to see us continue to be very aggressive investing in capacity because we see the demand. As fast as we‚Äôre adding capacity right now, we‚Äôre monetizing it.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Here was Microsoft CFO Amy Hood on the company‚Äôs earnings call:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Azure AI services revenue was generally in line with expectations, and this quarter, demand again exceeded supply across workloads, even as we brought more capacity online.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Here was Google CFO Anat Ashkenazi on the company‚Äôs earnings call:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In GCP, we see strong demand for enterprise AI infrastructure, including TPUs and GPUs, enterprise AI solutions driven by demand for Gemini 2.5 and our other AI models, and core GCP infrastructure and other services such as cybersecurity and data analytics. As I‚Äôve mentioned on previous earnings calls, while we have been working hard to increase capacity and have improved the pace of server deployments and data center construction, we still expect to remain in a tight demand-supply environment in Q4 and 2026.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Here was Meta CEO Mark Zuckerberg on the company‚Äôs earnings call:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;To date, we keep on seeing this pattern where we build some amount of infrastructure to what we think is an aggressive assumption. And then we keep on having more demand to be able to use more compute, especially in the core business in ways that we think would be quite profitable than we end up having compute for.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Earlier this month, TSMC CEO C.C. Wei admitted that the shortage was a lack of chips, not power; from the company‚Äôs earnings call:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Talking about to build a lot of AI data center all over the world, I use one of my customers‚Äô customers‚Äô answer. I asked the same question. They told me that they planned this one, 5-6 years ago already. So, as I said, those cloud service providers are smart, very smart. So, they say that they work on the power supply 5-6 years ago. So, today, their message to me is: silicon from TSMC is a bottleneck, and asked me not to pay attention to all others, because they have to solve the silicon bottleneck first. But indeed, we do get the power supply, all over the world, especially in the US. Not only that, but we also look at, who support those kind of a power supply, like a turbine, like, what, nuclear power plant, the plan or those kinds of things. We also look at the supply of the rack. We also look at the supply of the cooling system. Everything, so far, so good. So we have to work hard to narrow the gap between the demand and supply from TSMC.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The cause of that gap is obvious if you look at TSMC‚Äôs financials, specifically the company‚Äôs annual capital expenditures:&lt;/p&gt;
    &lt;p&gt;After a big increase in CapEx in 2021, driven by the COVID shortages and a belief in 5G, TSMC‚Äôs annual CapEx in the following years was basically flat ‚Äî it actually declined on a year-over-year basis in both 2023 and 2024. Note those dates! ChatGPT was released in November 2022; that kicked off a massive increase in CapEx amongst the hyperscalers in particular, but it sure seems like TSMC didn‚Äôt buy the hype.&lt;/p&gt;
    &lt;p&gt;That lack of increased investment earlier this decade is why there is a shortage today, and is why TSMC has been a de facto brake on the AI buildout/bubble; I wrote last quarter:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;To put it another way, if Altman and OpenAI are the ones pushing to accelerate the AI infrastructure buildout, it‚Äôs Wei and TSMC that are the brakes. The extent to which all of Altman‚Äôs deals actually materialize is dependent on how much TSMC invests in capacity now, and while they haven‚Äôt shown their hand yet, the company is saying all of the right things about AI being a huge trend without having yet committed to a commensurate level of investment, at least relative to OpenAI‚Äôs goals.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That Update was about the future, but it‚Äôs important to note that the TSMC brake has ‚Äî if all of those CEO and CFO comments above are to be believed ‚Äî already cost the biggest tech companies a lot of money. That‚Äôs the implication of not having enough supply to satisfy demand: there was revenue to be made that wasn‚Äôt, because TSMC didn‚Äôt buy the AI hype at the same time everyone else did.&lt;/p&gt;
    &lt;head rend="h3"&gt;TSMC‚Äôs CapEx Plans&lt;/head&gt;
    &lt;p&gt;TSMC is, finally, starting to invest more. Last year‚Äôs CapEx increased 37% to $41 billion, and there‚Äôs another increase in store for this year to $52‚Äì$56 billion; if we take the midpoint, that represents an increase of 32%, a bit less than last year:&lt;/p&gt;
    &lt;p&gt;Make no mistake, $54 billion is a big number, one that Wei admitted made him nervous:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;You essentially try to ask whether the AI demand is real or not. I‚Äôm also very nervous about it. Yeah, you bet, because we have to invest about USD52 billion to USD56 billion for the CapEx, right? If we did not do it carefully, that will be a big disaster to TSMC for sure. So, of course, I spent a lot of time in the last three-four months talking to my customers and then customers‚Äô customers. I want to make sure that my customers‚Äô demands are real.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Wei made clear that he was worried about the market several years down the line:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;If you build a new fab, it takes two and three year, two to three years to build a new fab. So even we start to spend $52 billion to $56 billion, the contribution to this year is almost none, and 2027, a little bit. So we actually, we are looking for 2028-2029 supply, and we hope it‚Äôs a time that the gap will be narrow‚Ä¶So 2026-2027 for the short-term, we are looking to improve our productivity. 2028 to 2029, yes, we start to increase our capacity significantly. And it will continue this way if the AI demand megatrend as we expected.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;First off, this delayed impact explains why TSMC‚Äôs lack of CapEx increase a few years ago is resulting in supply-demand imbalance today. Secondly, notice how this year‚Äôs planned increase ‚Äî which again, won‚Äôt really have an impact until 2028 ‚Äî pales in comparison to the CapEx growth of the hyperscalers (2025 numbers are estimates; note that Amazon‚Äôs CapEx includes Amazon.com):&lt;/p&gt;
    &lt;p&gt;Remember, a significant portion of this CapEx growth is for chips that are supported by TSMC‚Äôs stagnant CapEx growth from a few years ago. It‚Äôs notable, then, that TSMC‚Äôs current and projected CapEx growth is still less than the hyperscalers: how much less is it going to be than the hyperscalers‚Äô growth in 2028, when the fabs being built today start actually producing chips?&lt;/p&gt;
    &lt;p&gt;In short, the TSMC brake isn‚Äôt going anywhere ‚Äî if anything, it‚Äôs being pressed harder than ever.&lt;/p&gt;
    &lt;head rend="h3"&gt;TSMC Risk&lt;/head&gt;
    &lt;p&gt;TSMC is, to be clear, being extremely rational. CapEx is inherently risky: you are spending money now in anticipation of demand that may or may not materialize. Moreover, the risk for a foundry is higher than basically any other business model: nearly all of a foundry‚Äôs costs are CapEx, which means that if demand fails to materialize, costs ‚Äî in the form of depreciation ‚Äî don‚Äôt go down as they might with a business model with a higher percentage of marginal costs. This is exacerbated by the huge dollar figures entailed in building fabs: $52‚Äì$56 billion may drive revenues with big margins, but those big margins can easily flip to being huge losses and years of diminished pricing power thanks to excess capacity. Therefore, it‚Äôs understandable that TSMC is trying to manage its risks. Sure, the company may be foregoing some upside in 2028, but what is top of Wei‚Äôs mind is avoiding ‚Äúa big disaster.‚Äù&lt;/p&gt;
    &lt;p&gt;What is important to note, however, is that the risk TSMC is managing doesn‚Äôt simply go away: rather, it‚Äôs being offloaded to the hyperscalers in particular. Specifically, if we get to 2028, and TSMC still isn‚Äôt producing enough chips to satisfy demand, then that means the hyperscalers will be forgoing billions of dollars in revenue ‚Äî even more than they are already forgoing today. Yes, that risk is harder to see than the risk TSMC is avoiding, because the hyperscalers aren‚Äôt going to be bankrupt for a lack of chips to satisfy demand. Still, the potential money not made ‚Äî particularly when the number is potentially in the hundreds of billions of dollars ‚Äî is very much a risk that the hyperscalers are incurring because of TSMC‚Äôs conservatism.&lt;/p&gt;
    &lt;p&gt;What the hyperscalers need to understand is that simply begging TSMC to make more isn‚Äôt going to fix this problem, because begging TSMC to make more is to basically ask TSMC to take back the risk TSMC is offloading to the hyperscalers ‚Äî they already declined! Rather, the only thing that will truly motivate TSMC to take on more risk is competition. If TSMC were worried about not just forgoing its own extra revenue, but actually losing business to a competitor, then the company would invest more. Moreover, that extra investment would be stacked on top of the investment made by said competitor, which means the world would suddenly have dramatically more fab capacity.&lt;/p&gt;
    &lt;head rend="h3"&gt;If You Want a Bubble&lt;/head&gt;
    &lt;p&gt;In short, the only way to truly get an AI bubble, with all of the potential benefits that entails, or, in the optimistic case, to actually meet demand in 2028 and beyond, is to have competition in the foundry space. That, by extension, means Samsung or Intel ‚Äî or both ‚Äî actually being viable options.&lt;/p&gt;
    &lt;p&gt;Remember, however, the number one challenge facing those foundries: a lack of demand from the exact companies whom TSMC has deputized to take on their risk. I wrote in U.S. Intel:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Our mythical startup, however, doesn‚Äôt exist in a vacuum: it exists in the same world as TSMC, the company who has defined the modern pure play foundry. TSMC has put in the years, and they‚Äôve put in the money; TSMC has the unparalleled customer service approach that created the entire fabless chip industry; and, critically, TSMC, just as they did in the mobile era, is aggressively investing to meet the AI moment. If you‚Äôre an Nvidia, or an Apple in smartphones, or an AMD or a Qualcomm, why would you take the chance of fabricating your chips anywhere else? Sure, TSMC is raising prices in the face of massive demand, but the overall cost of a chip in a system is still quite small; is it worth risking your entire business to save a few dollars for worse performance with a worse customer experience that costs you time to market and potentially catastrophic product failures?&lt;/p&gt;
      &lt;p&gt;We know our mythical startup would face these challenges because they are the exact challenges Intel faces. Intel may need ‚Äúa meaningful external customer to drive acceptable returns on [its] deployed capital‚Äù, but Intel‚Äôs needs do not drive the decision-making of those external customers, despite the fact that Intel, while not fully caught up to TSMC, is at least in the ballpark, something no startup could hope to achieve for decades.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Becoming a meaningful customer of Samsung or Intel is very risky: it takes years to get a chip working on a new process, which hardly seems worth it if that process might not be as good, and if the company offering the process definitely isn‚Äôt as customer service-centric as TSMC. I understand why everyone sticks with TSMC.&lt;/p&gt;
    &lt;p&gt;The reality that hyperscalers and fabless chip companies need to wake up to, however, is that avoiding the risk of working with someone other than TSMC incurs new risks that are both harder to see and also much more substantial. Except again, we can see the harms already: foregone revenue today as demand outstrips supply. Today‚Äôs shortages, however, may prove to be peanuts: if AI has the potential these companies claim it does, future foregone revenue at the end of the decade is going to cost exponentially more ‚Äî surely a lot more than whatever expense is necessary to make Samsung and/or Intel into viable competitors for TSMC.&lt;/p&gt;
    &lt;p&gt;This, incidentally, is how the geographic risk issue will be fixed, if it ever is. It‚Äôs hard to get companies to pay for insurance for geopolitical risks that may never materialize. What is much more likely is that TSMC‚Äôs customers realize that their biggest risk isn‚Äôt that TSMC gets blown up by China, but that TSMC‚Äôs monopoly and reasonable reluctance to risk a rate of investment that matches the rest of the industry means that the rest of the industry fails to fully capture the value of AI.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Yes, there are chips made in Arizona, but only a portion, and they need to be sent back to Taiwan for packaging and testing. ‚Ü©&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46764223</guid><pubDate>Mon, 26 Jan 2026 11:07:26 +0000</pubDate></item><item><title>Vibe coding kills open source</title><link>https://arxiv.org/abs/2601.15494</link><description>&lt;doc fingerprint="a49e240a44ff128c"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Economics &amp;gt; General Economics&lt;/head&gt;&lt;p&gt; [Submitted on 21 Jan 2026]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Vibe Coding Kills Open Source&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:Generative AI is changing how software is produced and used. In vibe coding, an AI agent builds software by selecting and assembling open-source software (OSS), often without users directly reading documentation, reporting bugs, or otherwise engaging with maintainers. We study the equilibrium effects of vibe coding on the OSS ecosystem. We develop a model with endogenous entry and heterogeneous project quality in which OSS is a scalable input into producing more software. Users choose whether to use OSS directly or through vibe coding. Vibe coding raises productivity by lowering the cost of using and building on existing code, but it also weakens the user engagement through which many maintainers earn returns. When OSS is monetized only through direct user engagement, greater adoption of vibe coding lowers entry and sharing, reduces the availability and quality of OSS, and reduces welfare despite higher productivity. Sustaining OSS at its current scale under widespread vibe coding requires major changes in how maintainers are paid.&lt;/quote&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;econ.GN&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46765120</guid><pubDate>Mon, 26 Jan 2026 13:01:00 +0000</pubDate></item><item><title>Transfering Files with gRPC</title><link>https://kreya.app/blog/transfering-files-with-grpc/</link><description>&lt;doc fingerprint="a5bbb94665a38ca0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Transfering files with gRPC&lt;/head&gt;
    &lt;p&gt;Is transfering files with gRPC a good idea? Or should that be handled by a separate REST API endpoint? In this post, we will implement a file transfer service in both, use Kreya to test those APIs, and finally compare the performance to see which one is better.&lt;/p&gt;
    &lt;head rend="h2"&gt;Challenges when doing file transfers&lt;/head&gt;
    &lt;p&gt;When handling large files, it is important to stream the file from one place to another. This might sound obvious, but many developers (accidentally) buffer the whole file in memory, potentially leading to out-of-memory errors. For a web server that provides files for download, a correct implementation would stream the files directly from the file system into the HTTP response.&lt;/p&gt;
    &lt;p&gt;Another problem with very large files are network failures. Imagine you are downloading a 10 GB file on a slow connection, but your connection is interrupted for a second after downloading 90% of it. With REST, this could be solved by sending a HTTP &lt;code&gt;Range&lt;/code&gt; header, requesting the rest of the file content without download the first 9 GB again.
For the simplicity of the blogpost and since something similar is possible with gRPC, we are going to ignore this problem.&lt;/p&gt;
    &lt;head rend="h2"&gt;Transfering files with REST&lt;/head&gt;
    &lt;p&gt;Handling file transfers with REST (more correctly plain HTTP) is pretty straight forward in most languages and frameworks. In C# or rather ASP.NET Core, an example endpoint offering a file for downloading could look like this:&lt;/p&gt;
    &lt;code&gt;[HttpGet("api/files/pdf")]&lt;/code&gt;
    &lt;p&gt;We are effectively telling the framework to stream the file &lt;code&gt;/files/test-file.pdf&lt;/code&gt; as the response.
Internally, the framework repeatedly reads a small chunk (usually a few KB) from the file and writes it to the response.&lt;/p&gt;
    &lt;p&gt;The whole response body will consist of the file content and Kreya, our API client, automatically renders it as a PDF. Other information about the file, such as content type or file name, will have to be sent via HTTP headers.&lt;/p&gt;
    &lt;p&gt;This is important. If you have a JSON REST API and try to send additional information in the response body like this:&lt;/p&gt;
    &lt;code&gt;{&lt;/code&gt;
    &lt;p&gt;This is bad! The whole file content will be Base64-encoded and takes up 30% more space than the file size itself. In most languages/frameworks (without additional workarounds), this would also buffer the whole file in memory since the Base64-encoding process is usually not streamed while creating the JSON response. If the file itself is also buffered in memory, you could see memory usage over twice the size of the file. This may be fine if your files are only a few KB in size. But even then, if multiple requests are concurrently hitting this endpoint, you may notice quite a lot of memory usage.&lt;/p&gt;
    &lt;head rend="h2"&gt;Transfering files with gRPC&lt;/head&gt;
    &lt;p&gt;While the REST implementation was straight forward, this is not the case with gRPC. The design of gRPC is based on protobuf messages. There is no concept of "streaming" the content of a message. Instead, gRPC is designed to buffer a message fully in memory. This is the reason why individual gRPC messages should be kept small. The default maximum size is set at 4 MB. So how do we send large files bigger than that?&lt;/p&gt;
    &lt;p&gt;While gRPC cannot stream the content of a message, it allows streaming multiple messages. The solution is to break up the file into small chunks (usually around 32 KB) and then send these chunks until the file is transferred completely. The protobuf definition for a file download service could look like this:&lt;/p&gt;
    &lt;code&gt;edition = "2023";&lt;/code&gt;
    &lt;p&gt;This defines the &lt;code&gt;FileService.DownloadFile&lt;/code&gt; server-streaming method, which means that the method accepts a single (empty) request and returns multiple responses.
While we could send the file metadata via gRPC metadata (=HTTP headers or trailers), I think it's nicer to define it explicitly via a message.
The server should send the metadata first, as it contains important information, such as the file size.&lt;/p&gt;
    &lt;p&gt;A naive server implementation in C# could look like this:&lt;/p&gt;
    &lt;code&gt;private const int ChunkSize = 32 * 1024;&lt;/code&gt;
    &lt;p&gt;This works, but has some issues:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A new byte array buffer is created for each request&lt;/item&gt;
      &lt;item&gt;The buffer is copied each time to create a &lt;code&gt;ByteString&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The first point is easily solved by using a buffer from the shared pool, potentially re-using the same buffer for subsequent requests.&lt;/p&gt;
    &lt;p&gt;The second point happens due to the gRPC implementation in practically all languages. Since the implementation wants to guarantee that the bytes are not modified while sending them, it performs a copy first. This is a design decision which favors stability over performance. Luckily, there is a workaround by using a "unsafe" method, which is perfectly safe in our scenario and improves performance:&lt;/p&gt;
    &lt;code&gt;private const int ChunkSize = 32 * 1024;&lt;/code&gt;
    &lt;p&gt;Let's try this out. After importing the protobuf definition, we call the gRPC method with Kreya:&lt;/p&gt;
    &lt;p&gt;This works, but where is our PDF? Since we are sending individual chunks, we need to put them back together manually.&lt;/p&gt;
    &lt;p&gt;To achieve this, we simply need to append each chunk to a file. In Kreya, this is done via Scripting:&lt;/p&gt;
    &lt;code&gt;import { writeFile, appendFile } from 'fs/promises';&lt;/code&gt;
    &lt;p&gt;This allows us to view the PDF:&lt;/p&gt;
    &lt;head rend="h2"&gt;Comparison&lt;/head&gt;
    &lt;p&gt;Great! So transfering files with gRPC is definitely possible. But how do these two technologies compare against each other? Which one is faster and has less overhead?&lt;/p&gt;
    &lt;head rend="h3"&gt;Total bytes transferred&lt;/head&gt;
    &lt;p&gt;The total amount of bytes transferred on the wire is actually a pretty difficult topic. It depends on a lot of factors, such as the HTTP protocol (HTTP/1.1, HTTP/2 or HTTP/3), the package size of TCP/IP, whether TLS is being used etc. We are going to take a look how this applies to REST and gRPC.&lt;/p&gt;
    &lt;p&gt;Streaming files over a gRPC connection generates overhead, although not much. Since gRPC uses HTTP/2 under the hood, each individual chunk message has a few bytes overhead due to the HTTP/2 DATA frame information needed. Additionally, each chunk needs a few bytes to describe the content of the gRPC message. You are looking at roughly 15 bytes per message chunk if it fits into one HTTP/2 DATA frame. Transfering 4 GB of data with a chunk size of 16 KB would need around 250,000 messages to transfer the file completely, incurring an overhead of ~3.7 MB. This may or may not be negilible depending on the use case.&lt;/p&gt;
    &lt;p&gt;Up- or downloading huge files with REST over HTTP/1.1 has less overhead. Since the bytes of the file are sent as the response/request body, there is not much else that takes up space. In case of uploads to a server, HTTP multipart requests incur a small overhead cost to define the multipart boundary. Additionally, HTTP headers and everything else that is needed to send the request over the wire take up space, but this is the case for all HTTP-based protocols. Downloading files, whether small or large, have roughly the same amount of bytes overhead with HTTP/1.1. Depending on the count and size of HTTP headers, this is around a few hundred bytes.&lt;/p&gt;
    &lt;p&gt;Funnily enough, transfering files with REST over HTTP/2 incurs a bigger overhead. HTTP/2 splits the payload into individual DATA frames, very similar to our custom gRPC solution. Each frame, often with a maximum size of 16 KB, has an overhead of 9 bytes. For a file 4 GB in size, this amounts to ~2.2 MB overhead. While HTTP/2 has many performance advantages, transfering a single, large file over HTTP/1.1 has less overhead.&lt;/p&gt;
    &lt;p&gt;In these examples, we omitted the overhead created by TCP/IP, TLS and the lower network layers, which both HTTP/1.1 and HTTP/2 share. Comparing it with HTTP/3, which uses UDP, would make everything even more complicated, so we leave this as exercise for the reader :)&lt;/p&gt;
    &lt;head rend="h3"&gt;Performance and memory usage&lt;/head&gt;
    &lt;p&gt;I spun up the local server plus client and took a look at the CPU and memory usage. Please note that this is not an accurate benchmark, which would require a more complex setup. Nevertheless, it provides some insight into the differences between the approaches. The example file used was 4 GB in size.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;gRPC (naive)&lt;/cell&gt;
        &lt;cell role="head"&gt;gRPC (optimized)&lt;/cell&gt;
        &lt;cell role="head"&gt;REST (HTTP/1.1)&lt;/cell&gt;
        &lt;cell role="head"&gt;REST (HTTP/2)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Duration&lt;/cell&gt;
        &lt;cell&gt;24s&lt;/cell&gt;
        &lt;cell&gt;22s&lt;/cell&gt;
        &lt;cell&gt;20s&lt;/cell&gt;
        &lt;cell&gt;28s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Max memory usage&lt;/cell&gt;
        &lt;cell&gt;36 MB&lt;/cell&gt;
        &lt;cell&gt;35 MB&lt;/cell&gt;
        &lt;cell&gt;32 MB&lt;/cell&gt;
        &lt;cell&gt;35 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Total memory allocation&lt;/cell&gt;
        &lt;cell&gt;4465 MB&lt;/cell&gt;
        &lt;cell&gt;165 MB&lt;/cell&gt;
        &lt;cell&gt;38 MB&lt;/cell&gt;
        &lt;cell&gt;137 MB&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;If done right, memory usage is no problem for streaming very large files. And as expected, the naive gRPC implementation which copies a lot of &lt;code&gt;ByteString&lt;/code&gt;s around allocates a lot of memory!
It needs constant garbage collections to clean up the mess.
The maximum memory usage however stays low for all approaches.&lt;/p&gt;
    &lt;p&gt;What really surprised me was the bad performance of HTTP/2 in comparison to HTTP/1.1. It was even slower than gRPC, which builds on top of it! I cannot really explain this huge difference, especially since the code is exactly the same, both on the client and the server. I was running these tests on .NET 10 on Windows 11.&lt;/p&gt;
    &lt;p&gt;The optimized gRPC version performs pretty well, but is still slower than REST via HTTP/1.1. Since it has to do more work, it takes longer and uses more memory (and CPU). Optimizing the gRPC code was very important, as the naive implementation allocates so much memory!&lt;/p&gt;
    &lt;p&gt;I also tested HTTP/1.1 with TLS disabled, but it did not really make a difference.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;A REST endpoint for up- and downloading files is still the best option. If you are forced to use gRPC or simply too lazy to add REST endpoints in addition to your gRPC services, transfering files via gRPC is not too bad!&lt;/p&gt;
    &lt;p&gt;If you use some kind of S3 compatible storage backend, the best options is to generate a presigned URL. Then, download your files directly from the S3 storage instead of piping it through your backend.&lt;/p&gt;
    &lt;p&gt;There are lots of points to consider when implementing file transfer APIs. For example, if your users may have slow networks, it may be useful to compress the data before sending it over the wire.&lt;/p&gt;
    &lt;p&gt;Should you need resumable up- or downloads, instead of rolling your own, you could use https://tus.io/. This open-source protocol has implementations in various languages.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46765273</guid><pubDate>Mon, 26 Jan 2026 13:17:19 +0000</pubDate></item><item><title>After two years of vibecoding, I'm back to writing by hand</title><link>https://atmoio.substack.com/p/after-two-years-of-vibecoding-im</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46765460</guid><pubDate>Mon, 26 Jan 2026 13:36:22 +0000</pubDate></item><item><title>Porting 100k lines from TypeScript to Rust using Claude Code in a month</title><link>https://blog.vjeux.com/2026/analysis/porting-100k-lines-from-typescript-to-rust-using-claude-code-in-a-month.html</link><description>&lt;doc fingerprint="23280a7e3da5c6e8"&gt;
  &lt;main&gt;
    &lt;p&gt;I read this post ‚ÄúOur strategy is to combine AI and Algorithms to rewrite Microsoft‚Äôs largest codebases [from C++ to Rust]. Our North Star is ‚Äò1 engineer, 1 month, 1 million lines of code.‚Äù and it got me curious, how difficult is it really?&lt;/p&gt;
    &lt;p&gt;I've long wanted to build a competitive Pokemon battle AI after watching a lot of WolfeyVGC and following the Pok√©Agent challenge at NeurIPS. Thankfully there's an open source project called "Pokemon Showdown" that implements all the rules but it's written in JavaScript which is quite slow to run in a training loop. So my holiday project came to life: let's convert it to Rust using Claude!&lt;/p&gt;
    &lt;head rend="h2"&gt;Escaping the sandbox&lt;/head&gt;
    &lt;p&gt;Having the AI able to run arbitrary code on your machine is dangerous, so there's a lot of safeguards put in place. But... at the same time, this is what I want to do in this case. So let me walk through the ways I escaped the various sandboxes.&lt;/p&gt;
    &lt;head rend="h3"&gt;git push&lt;/head&gt;
    &lt;p&gt;Claude runs in a sandbox that limits some operations like ssh access. You need ssh access in order to publish to GitHub. This is very important as I want to be able to check how the AI is doing from my phone while I do some other activities üòâ&lt;/p&gt;
    &lt;p&gt;What I realized is that I can run the code on my terminal but Claude cannot do it from its own terminal. So what I did was to ask Claude to write a nodejs script that opens an http server on a local port that executes the git commands from the url. Now I just need to keep a tab open on my terminal with this server active and ask Claude to write instructions in Claude.md for it to interact with it.&lt;/p&gt;
    &lt;head rend="h3"&gt;rustc&lt;/head&gt;
    &lt;p&gt;There's an antivirus on my computer that requires a human interaction when an unknown binary is being ran. Since every time we compile it's a new unknown binary, this wasn't going to work.&lt;/p&gt;
    &lt;p&gt;What I found is that I can setup a local docker instance and compile + run the code inside of docker which doesn't trigger the antivirus. Again, I asked Claude to generate the right instructions in Claude.md and problem solved.&lt;/p&gt;
    &lt;p&gt;The next hurdle was to figure out how to let Claude Code for hours without any human intervention.&lt;/p&gt;
    &lt;head rend="h3"&gt;--yes&lt;/head&gt;
    &lt;p&gt;Claude keeps asking for permission to do things. I tried adding a bunch of things to the allowed commands file and &lt;code&gt;--allow-dangerously-skip-permissions --dangerously-skip-permissions&lt;/code&gt;was disabled in my environment (it has now been resolved).&lt;/p&gt;
    &lt;p&gt;I realized that I could run an AppleScript that presses enter every few seconds in another tab. This way it's going to say Yes to everything Claude asks to do. So far it hasn't decided to hack my computer...&lt;/p&gt;
    &lt;code&gt;#!/bin/bash

osascript -e \
'tell application "System Events"
    repeat
        delay 5
        key code 36
    end repeat
end tell'&lt;/code&gt;
    &lt;head rend="h3"&gt;Never give up&lt;/head&gt;
    &lt;p&gt;Claude after working for some time seem to always stop to recap things. I tried prompting it to never do, even threatening it to no avail.&lt;/p&gt;
    &lt;p&gt;I tried using the Ralph Wiggum loop but it couldn't get it to work and apparently I'm not alone.&lt;/p&gt;
    &lt;p&gt;What ended up working is to copy in my clipboard the task I wanted it to do and to tweak the script above to hit the keys "cmd-v" after pressing enter. This way in case it asks a question the "enter" is being used and in case it's not it's queuing the prompt for when Claude is giving back control.&lt;/p&gt;
    &lt;head rend="h3"&gt;Auto-updates&lt;/head&gt;
    &lt;p&gt;There are programs on the computer like software updater that can steal the focus from the terminal window, for example showing a modal. Once that happens, then the cmd-v / enter are no longer sent to the terminal and the execution stops.&lt;/p&gt;
    &lt;p&gt;I used my trusty Auto Clicker by MurGaa from Minecraft days to simulate a left click every few seconds. I place my terminal on the edge of the screen and same for my mouse so that when a modal appears in the middle, it refocuses the terminal correctly.&lt;/p&gt;
    &lt;p&gt;It also prevents the computer from going to sleep so that it can run even when I'm not using the laptop or at night.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bugs üêú&lt;/head&gt;
    &lt;p&gt;Reliability when running things for a long period of time is paramount. Overall it's been a pretty smooth ride but I ran into this specific error during a handful of nights which stopped the process. I hope they get to the bottom of it and solve it as I'm not the only one to report it!&lt;/p&gt;
    &lt;p&gt;This setup is far from optimal but has worked so far. Hopefully this gets streamlined in the future!&lt;/p&gt;
    &lt;head rend="h2"&gt;Porting Pokemon&lt;/head&gt;
    &lt;head rend="h3"&gt;One Shot&lt;/head&gt;
    &lt;p&gt;At the very beginning, I started with a simple prompt asking Claude to port the codebase and make sure that things are done line by line. At first it felt extremely impressive, it generated thousands of lines of Rust that was compiling.&lt;/p&gt;
    &lt;p&gt;Sadly it was only an appearance as it took a lot of shortcuts. For example, it created two different structures for what a move is in two different files so that they would both compile independently but didn't work when integrated together. It ported all the functions very loosely where anything that was remotely complicated would not be ported but instead "simplified".&lt;/p&gt;
    &lt;p&gt;I didn't realize it yet, I got the loop working to have it port more and more code. The issue is that it created wrong abstractions all over the place and kept adding hardcoded code to make whatever it was supposed to fix work. This wasn't going to go anywhere.&lt;/p&gt;
    &lt;head rend="h3"&gt;Giving it structure&lt;/head&gt;
    &lt;p&gt;At this point I knew that I needed to be a lot more prescriptive for what I wanted out of it. Taking a step back, the end result should have every JavaScript file and every method inside to have a Rust equivalent.&lt;/p&gt;
    &lt;p&gt;So I asked Claude to write a script that takes all the files and methods in the JavaScript codebase and put comments in the rust codebase with the JavaScript source, next to the Rust methods.&lt;/p&gt;
    &lt;p&gt;It was really important for it to be a script as even when instructed to copy code over, it would mistranslate JavaScript code. Being deterministic here greatly increased the odds of getting the right results.&lt;/p&gt;
    &lt;head rend="h3"&gt;Litte Islands&lt;/head&gt;
    &lt;p&gt;The next challenge is that the original files were thousands of lines long, double it with source comments we got to files more than 10k lines long. This causes a ton of issues with the context window where Claude straight up refuses to open the file. So it started reading the file in chunks but without a ton of precision. Also the context grew a lot quicker and compaction became way more frequent.&lt;/p&gt;
    &lt;p&gt;So I went ahead and split every method into its own file for the Rust version. This dramatically improved the results. For maximal efficiency I would need to do the same for the JavaScript codebase as well but I was too afraid to do it and accidentally change the behavior so decided not to.&lt;/p&gt;
    &lt;head rend="h3"&gt;Cleanup&lt;/head&gt;
    &lt;p&gt;The process of porting went through two repeating phases. I would give a large task to Claude to do in a loop that would churn on it for a day, and then I would need to spend time cleaning up the places where it went into the wrong direction.&lt;/p&gt;
    &lt;p&gt;For the cleanup, I still used Claude but gave a lot more specific recommendations. For example, I noticed that it would hardcode moves/abilities/items/... behaviors everywhere in the code when left unchecked, even after explicitly telling it not to. So I would manually look for all these and tell it to move them into the right places.&lt;/p&gt;
    &lt;p&gt;This is where engineering skills come into play, all my experience building software let me figure out what went wrong and how to fix it. The good part is that I didn't have to do the cleanup myself, Claude was able to do it just fine when directed to.&lt;/p&gt;
    &lt;head rend="h2"&gt;Integration&lt;/head&gt;
    &lt;head rend="h3"&gt;Build everything before testing&lt;/head&gt;
    &lt;p&gt;So far, I just made sure that the code compiled, but have never actually put all the pieces together to ensure it actually worked. What Claude really wanted was to do a traditional software building strategy where you make "simple" implementations of all of the pieces and then build them up as time goes.&lt;/p&gt;
    &lt;p&gt;But in our case, all this iteration has already happened for 10 years on the pokemon-showdown codebase. It's counter productive to try and re-learn all these lessons and will unlikely converge the same way. What works better is to port everything at once, and then do the integration at the end once.&lt;/p&gt;
    &lt;p&gt;I've learned this strategy from working on Skip, a compiler. For years all the building blocks were built independently and then it all came together with nothing to show for but within a month at the end it all worked. I was so shocked.&lt;/p&gt;
    &lt;head rend="h3"&gt;End-to-end test&lt;/head&gt;
    &lt;p&gt;Once most of the codebase was ported one to one, I started putting it all together. The good thing is that we can run and edit the code in JavaScript and in Rust, and the input/output is very simple and standardized: list of pokemons with their options (moves, items, nature, iv/ev spread...) and then the list of actions at each step (moves and switches). Given the same random sequence, it'll advance the state the same way.&lt;/p&gt;
    &lt;p&gt;Now I can let Claude generate this testing harness and go through all the issues one by one. Impressively, it was able to figure out all issues and fix them.&lt;/p&gt;
    &lt;p&gt;Over the course of 3 weeks it averaged fixing one issue every 20 minutes or so. It fixed hundreds of issues on its own. I never intervened, it was only a matter of time before it fixed every issue that it encountered.&lt;/p&gt;
    &lt;head rend="h3"&gt;Giving it structure&lt;/head&gt;
    &lt;p&gt;At the beginning, this process was extremely slow. Every time a compaction happened, Claude became "dumb" again and reinvented the wheel, writing down tons of markdown files and test scripts along the way. Or Claude decided to take the easy way out and just generate tons of tests but never actually making them match with JavaScript.&lt;/p&gt;
    &lt;p&gt;So, I started looking at what it did well and encoding it. For example, it added a lot of debugging around the PRNG steps and what actions happened at every turn with all the debugging metadata. So I asked it to create a single test script to print down this information for a single step and to print stack traces. Then add instruction to the Claude.md file. This way every investigation started right away.&lt;/p&gt;
    &lt;head rend="h3"&gt;The long slog&lt;/head&gt;
    &lt;p&gt;I built used the existing random number generator to generate battles and could put in a number as a seed. This let me generate consistent battles at an increasing size.&lt;/p&gt;
    &lt;p&gt;I started fixing the first 100 battles, then 1000, 10k, 100k and I'm almost done solving all the issues for the first 2.4 million battles! I'm not sure how many more issues there are but the good thing is that they are getting smaller and smaller as the batch size increases.&lt;/p&gt;
    &lt;head rend="h3"&gt;Types of issues&lt;/head&gt;
    &lt;p&gt;There are two broad classes of issues that were fixed. The first one that I expected is that Rust has different constraints than JavaScript which need to be taken into account and lead to bugs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Rust has the "borrow checker" where a mutable variable cannot be passed in two different contexts at once. The problem is that "Pokemon" and "Battle" have references to each others. So there's a lot of workarounds like doing copies, passing indices instead of the object, providing functions with mutable object as callback...&lt;/item&gt;
      &lt;item&gt;The JavaScript codebase uses dynamism heavily where some function return '', undefined, null, 0, 1, 5.2, Pokemon... which all are handled with different behaviors. At first the rust port started using Option&amp;lt;&amp;gt; to handle many of them but then moved to structs with all these variants.&lt;/item&gt;
      &lt;item&gt;Rust doesn't support optional arguments so every argument has to be spelled out literally.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But the second one are due to itself... Claude Code is like a smart student that is trying to find every opportunity to avoid doing the hard work and take the easy way out if it thinks it can get away with it.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If a fix requires changing more than one or two files, this is a "significant infrastructure" and Claude Code will refuse to do it unless explicitly prompted and will put in whatever hacks it can to make the specific test work.&lt;/item&gt;
      &lt;item&gt;Along the same lines, it is going to implement "simplified" versions of things. For some methods, it was better to delete everything and asking it to port it over from scratch than trying to fix all the existing code it created.&lt;/item&gt;
      &lt;item&gt;The JavaScript comments are supposed to be the source of truth. But Claude is not above changing the original code if it feels like this is the way to solve the problem...&lt;/item&gt;
      &lt;item&gt;If given a list of tasks, it's going to avoid doing the ones that seem difficult until it is absolutely forced to. This is inefficient if not careful as it's going to keep spending time investigating and then skipping all the "hard" ones. Compaction is basically wiping all its memory.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Prompts&lt;/head&gt;
    &lt;p&gt;I didn't write a single line of code myself in this project. I alternated between "co-op" where I work with Claude interactively during the day and creating a job for it to run overnight. I'll focus on the night ones for this section.&lt;/p&gt;
    &lt;head rend="h3"&gt;Conversion&lt;/head&gt;
    &lt;p&gt;For the first phase of the project, I mostly used variations of this one. Asking it to go through all the big files one by one and implement them faithfully (it didn't really follow instructions as we've seen later...)&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Open BATTLE_TODO.md to get the list of all the methods in both battle*.rs.&lt;/p&gt;&lt;lb/&gt;Inspect every single one of them and make sure that they are a direct translation the JavaScript file. If there's a method with the same name, the JavaScript definition will be in the comment.&lt;lb/&gt;If there's no JavaScript definition, question whether this method should be there in the rust version. Our goal is to follow as closely as possible the JavaScript version to avoid any bugs in translation. If you notice that the implementation doesn't match, do all the refactoring needed to match 1 to 1.&lt;lb/&gt;This will be a complex project. You need to go through all the methods one by one, IN ORDER. YOU CANNOT skip a method because it is too hard or would requiring building new infrastructure. We will call this in a loop so spend as much time as you need building the proper infrastructure to make it 1 to 1 with the JavaScript equivalent. Do not give up.&lt;lb/&gt;Update BATTLE_TODO.md and do a git commit after each unit of work.&lt;/quote&gt;
    &lt;head rend="h3"&gt;Todos&lt;/head&gt;
    &lt;p&gt;Claude Code while porting the methods one by one often decided to write a "simplified" version or add a "TODO" for later. I also found it to be useful when generating work to add the instructions in the codebase itself via a TODO comment, so I don't need to wish that it's going to be read from the context.&lt;/p&gt;
    &lt;p&gt;The master md file in practice didn't really work, it quickly became too big to be useful and Claude started creating a bunch more littering the repo with them. Instead I gave it a deterministic way to go through then by calling grep on the codebase, so it knew when to find them.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;We want to fix every TODO in the codebase.&lt;/p&gt;&lt;code&gt;TODO&lt;/code&gt;or&lt;code&gt;simplif&lt;/code&gt;in pokemon-showdown-rs/.&lt;lb/&gt;There are hundreds of them, so go diligently one by one. Do not skip them even if they are difficult. I will call this prompt again and again so you don't need to worry about taking too long on any single one.&lt;lb/&gt;The port must be exactly one to one. If the infrastructure doesn't exist, please implement it. Do not invent anything.&lt;lb/&gt;Make sure it still compiles after each addition and commit and push to git.&lt;/quote&gt;
    &lt;p&gt;At some point the context was poisoned where a TODO was inside of the original js codebase so it changed it to something else which made sense. But then it did the same for all the subsequent TODOs which didn't... Thankfully I could just revert all these commits.&lt;/p&gt;
    &lt;head rend="h3"&gt;Fixing&lt;/head&gt;
    &lt;p&gt;I put in all the instructions to debug in Claude.md and a script to run all the tests which outputs a txt file with progress report. This way Claude was able to just keep going fixing issues after issues.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We want to fix all the divergences in battles. Please look at 500-seeds-results.txt and fix them one by one. The only way you can fix is by making sure that the differences between javascript and rust are explained by language differences and not logic. Every line between the two must match one by one. If you fixed something specific, it's probably a larger issue, spend the time to figure out if other similar things are broken and do the work to do the larger infrastructure fixes. Make sure it still compiles after each addition and commit and push to git. Check if there are other parts of the codebase that make this mistake.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is really useful to have this txt file diff committed to GitHub to get a sense of progress on the go!&lt;/p&gt;
    &lt;head rend="h2"&gt;Epilogue&lt;/head&gt;
    &lt;head rend="h3"&gt;It works ü§Ø&lt;/head&gt;
    &lt;p&gt;I didn't quite know what to expect coming into this project. They usually tend to die due to the sheer amount of work needed to get anywhere close to something complete. But not this time!&lt;/p&gt;
    &lt;p&gt;We have a complete implementation of Pokemon battle system that produces the same results as the existing JavaScript codebase*. This was done through 5000 commits in 4 weeks and the Rust codebase is around 100k lines of code.&lt;/p&gt;
    &lt;p&gt;*I wish we had 0 divergences but right now there are 80 out of the first 2.4 million seeds or 0.003%. I need to run it for longer to solve these.&lt;/p&gt;
    &lt;head rend="h3"&gt;Is it fast?&lt;/head&gt;
    &lt;p&gt;The whole point of the project was for it to be faster than the initial JavaScript implementation. Only towards the end of the project where we had a sizable amount of battles running perfectly I felt like it would be a fair time to do a performance comparison.&lt;/p&gt;
    &lt;p&gt;I asked Claude Code to parallelize both implementations and was relieved by the results, the Rust port is actually significantly faster, I didn't spend all this time for nothing!&lt;/p&gt;
    &lt;p&gt;I've tried asking Claude to optimize it further, it created a plan that looks reasonable (I've never interacted with Rust in my life) and it spent a day building many of these optimizations but at the end of the day, none of them actually improved the runtime and some even made it way worse.&lt;/p&gt;
    &lt;p&gt;This is a good example of how experience and expertise is still very required in order to get the best out of LLMs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;This is pretty wild that I was able to port a ~100k lines codebase from JavaScript to Rust in two weeks on my own with Claude Code running 24 hours a day for a month creating 5k commits! I have never written any line of Rust before in my life.&lt;/p&gt;
    &lt;p&gt;LLM-based coding agents are such a great new tool for engineers, there's no way I would have been able to do that without Claude Code. That said, it still feels like a tool that requires my engineering expertise and constant babysitting to produce these results.&lt;/p&gt;
    &lt;p&gt;Sadly I didn't get to build the Pokemon Battle AI and the winter break is over, so if anybody wants to do it, please have fun with the codebase!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46765694</guid><pubDate>Mon, 26 Jan 2026 13:58:27 +0000</pubDate></item><item><title>Google AI Overviews cite YouTube more than any medical site for health queries</title><link>https://www.theguardian.com/technology/2026/jan/24/google-ai-overviews-youtube-medical-citations-study</link><description>&lt;doc fingerprint="bdca1812fc9b2573"&gt;
  &lt;main&gt;
    &lt;p&gt;Google‚Äôs search feature AI Overviews cites YouTube more than any medical website when answering queries about health conditions, according to research that raises fresh questions about a tool seen by 2 billion people each month.&lt;/p&gt;
    &lt;p&gt;The company has said its AI summaries, which appear at the top of search results and use generative AI to answer questions from users, are ‚Äúreliable‚Äù and cite reputable medical sources such as the Centers for Disease Control and Prevention and the Mayo Clinic.&lt;/p&gt;
    &lt;p&gt;However, a study that analysed responses to more than 50,000 health queries, captured using Google searches from Berlin, found the top cited source was YouTube. The video-sharing platform is the world‚Äôs second most visited website, after Google itself, and is owned by Google.&lt;/p&gt;
    &lt;p&gt;Researchers at SE Ranking, a search engine optimisation platform, found YouTube made up 4.43% of all AI Overview citations. No hospital network, government health portal, medical association or academic institution came close to that number, they said.&lt;/p&gt;
    &lt;p&gt;‚ÄúThis matters because YouTube is not a medical publisher,‚Äù the researchers wrote. ‚ÄúIt is a general-purpose video platform. Anyone can upload content there (eg board-certified physicians, hospital channels, but also wellness influencers, life coaches, and creators with no medical training at all).‚Äù&lt;/p&gt;
    &lt;p&gt;Google told the Guardian that AI Overviews was designed to surface high-quality content from reputable sources, regardless of format, and a variety of credible health authorities and licensed medical professionals created content on YouTube. The study‚Äôs findings could not be extrapolated to other regions as it was conducted using German-language queries in Germany, it said.&lt;/p&gt;
    &lt;p&gt;The research comes after a Guardian investigation found people were being put at risk of harm by false and misleading health information in Google AI Overviews responses.&lt;/p&gt;
    &lt;p&gt;In one case that experts said was ‚Äúdangerous‚Äù and ‚Äúalarming‚Äù, Google provided bogus information about crucial liver function tests that could have left people with serious liver disease wrongly thinking they were healthy. The company later removed AI Overviews for some but not all medical searches.&lt;/p&gt;
    &lt;p&gt;The SE Ranking study analysed 50,807 healthcare-related prompts and keywords to see which sources AI Overviews relied on when generating answers.&lt;/p&gt;
    &lt;p&gt;They chose Germany because its healthcare system is strictly regulated by a mix of German and EU directives, standards and safety regulations. ‚ÄúIf AI systems rely heavily on non-medical or non-authoritative sources even in such an environment, it suggests the issue may extend beyond any single country,‚Äù they wrote.&lt;/p&gt;
    &lt;p&gt;AI Overviews surfaced on more than 82% of health searches, the researchers said. When they looked at which sources AI Overviews relied on most often for health-related answers, one result stood out immediately, they said. The single most cited domain was YouTube with 20,621 citations out of a total of 465,823.&lt;/p&gt;
    &lt;p&gt;The next most cited source was NDR.de, with 14,158 citations (3.04%). The German public broadcaster produces health-related content alongside news, documentaries and entertainment. In third place was a medical reference site, Msdmanuals.com with 9,711 citations (2.08%).&lt;/p&gt;
    &lt;p&gt;The fourth most cited source was Germany‚Äôs largest consumer health portal, Netdoktor.de, with 7,519 citations (1.61%). The fifth most cited source was a career platform for doctors, Praktischarzt.de, with 7,145 citations (1.53%).&lt;/p&gt;
    &lt;p&gt;The researchers acknowledged limitations to their study. It was conducted as a one-time snapshot in December 2025, using German-language queries that reflected how users in Germany typically search for health information.&lt;/p&gt;
    &lt;p&gt;Results could vary over time, by region, and by the phrasing of questions. However, even with those caveats, the findings still prompted alarm.&lt;/p&gt;
    &lt;p&gt;Hannah van Kolfschooten, a researcher specialising in AI, health and law at the University of Basel who was not involved with the research, said: ‚ÄúThis study provides empirical evidence that the risks posed by AI Overviews for health are structural, not anecdotal. It becomes difficult for Google to argue that misleading or harmful health outputs are rare cases.&lt;/p&gt;
    &lt;p&gt;‚ÄúInstead, the findings show that these risks are embedded in the way AI Overviews are designed. In particular, the heavy reliance on YouTube rather than on public health authorities or medical institutions suggests that visibility and popularity, rather than medical reliability, is the central driver for health knowledge.‚Äù&lt;/p&gt;
    &lt;p&gt;A Google spokesperson said: ‚ÄúThe implication that AI Overviews provide unreliable information is refuted by the report‚Äôs own data, which shows that the most cited domains in AI Overviews are reputable websites. And from what we‚Äôve seen in the published findings, AI Overviews cite expert YouTube content from hospitals and clinics.‚Äù&lt;/p&gt;
    &lt;p&gt;Google said the study showed that of the 25 most cited YouTube videos, 96% were from medical channels. However, the researchers cautioned that these videos represented fewer than 1% of all the YouTube links cited by AI Overviews on health.&lt;/p&gt;
    &lt;p&gt;‚ÄúMost of them (24 out of 25) come from medical-related channels like hospitals, clinics and health organisations,‚Äù the researchers wrote. ‚ÄúOn top of that, 21 of the 25 videos clearly note that the content was created by a licensed or trusted source.&lt;/p&gt;
    &lt;p&gt;‚ÄúSo at first glance it looks pretty reassuring. But it‚Äôs important to remember that these 25 videos are just a tiny slice (less than 1% of all YouTube links AI Overviews actually cite). With the rest of the videos, the situation could be very different.‚Äù&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46766031</guid><pubDate>Mon, 26 Jan 2026 14:27:00 +0000</pubDate></item><item><title>Exactitude in Science ‚Äì Borges (1946) [pdf]</title><link>https://kwarc.info/teaching/TDM/Borges.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46766229</guid><pubDate>Mon, 26 Jan 2026 14:44:51 +0000</pubDate></item><item><title>OSS ChatGPT WebUI ‚Äì 530 Models, MCP, Tools, Gemini RAG, Image/Audio Gen</title><link>https://llmspy.org/docs/v3</link><description>&lt;doc fingerprint="b00f92d914e999d8"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;v3 Release Notes&lt;/head&gt;&lt;p&gt;Major release focused on extensibility, expanded provider support, and enhanced user experience.&lt;/p&gt;&lt;head rend="h2"&gt;üöÄ What's New at a Glance&lt;/head&gt;&lt;table&gt;&lt;row span="2"&gt;&lt;cell role="head"&gt;Feature&lt;/cell&gt;&lt;cell role="head"&gt;Description&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;530+ Models&lt;/cell&gt;&lt;cell&gt;Access over 530 models from 24 providers via models.dev integration&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Model Selector&lt;/cell&gt;&lt;cell&gt;Redesigned full-featured dialog with search, filtering, sorting, and favorites&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Extensions&lt;/cell&gt;&lt;cell&gt;Add features, providers, and customize the UI with a flexible plugin architecture&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Gemini RAG&lt;/cell&gt;&lt;cell&gt;Manage Gemini File Search Stores and manage document uploads for RAG workflows&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Tool Support&lt;/cell&gt;&lt;cell&gt;First-class Python function calling for LLM interactions with your local environment&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;MCP Support&lt;/cell&gt;&lt;cell&gt;Connect to Model Context Protocol servers for extended tool capabilities&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Computer Use&lt;/cell&gt;&lt;cell&gt;Desktop automation - control mouse, keyboard, and take screenshots like a human&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;KaTeX Math Typesetting&lt;/cell&gt;&lt;cell&gt;Support for beautiful rendering of LaTeX math expressions&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Calculator UI&lt;/cell&gt;&lt;cell&gt;Beautiful UX Friendly UI to evaluate python math expressions&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Run Code UI&lt;/cell&gt;&lt;cell&gt;Execute Python, JS, TypeScript and C# code scripts in a CodeMirror editor&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Image Generation&lt;/cell&gt;&lt;cell&gt;Built-in support for Google, OpenAI, OpenRouter, Chutes, and Nvidia&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Audio Generation&lt;/cell&gt;&lt;cell&gt;TTS support for Gemini 2.5 Flash/Pro Preview models&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Media Gallery&lt;/cell&gt;&lt;cell&gt;Beautiful UI to browse generated images and audio generations&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;SQLite Storage&lt;/cell&gt;&lt;cell&gt;Migrated IndexedDB to server SQLite for robust persistence and concurrent usage&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Asset Caching&lt;/cell&gt;&lt;cell&gt;Persistent image/file file caching with metadata&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Gemini RAG Extension&lt;/cell&gt;&lt;cell&gt;Manage Gemini File Search Stores for RAG workflows with document uploads and sync&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;head rend="h2"&gt;Table of Contents&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;New Model Selector UI&lt;/item&gt;&lt;item&gt;Rewritten for Extensibility&lt;/item&gt;&lt;item&gt;Extensions System&lt;/item&gt;&lt;item&gt;Gemini RAG Extension&lt;/item&gt;&lt;item&gt;Tool Support&lt;/item&gt;&lt;item&gt;MCP Support&lt;/item&gt;&lt;item&gt;Core Tools&lt;/item&gt;&lt;item&gt;Computer Use&lt;/item&gt;&lt;item&gt;Calculator UI&lt;/item&gt;&lt;item&gt;Run Code UI&lt;/item&gt;&lt;item&gt;KaTeX Math Typesetting&lt;/item&gt;&lt;item&gt;Image Generation Support&lt;/item&gt;&lt;item&gt;Audio Generation Support&lt;/item&gt;&lt;item&gt;Media Gallery&lt;/item&gt;&lt;item&gt;System Prompts Library&lt;/item&gt;&lt;item&gt;Server-Side SQLite Storage&lt;/item&gt;&lt;item&gt;Image Cache &amp;amp; Optimization&lt;/item&gt;&lt;item&gt;CLI - More Powerful Than Ever&lt;/item&gt;&lt;item&gt;Upgrade Instructions&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Install&lt;/head&gt;&lt;p&gt;Get instant access to 530+ models from 24 providers with extensibility at its core:&lt;/p&gt;&lt;code&gt;pip install llms-py&lt;/code&gt;&lt;head rend="h3"&gt;Upgrade&lt;/head&gt;&lt;code&gt;pip install llms-py --upgrade&lt;/code&gt;&lt;p&gt;See Install Docs for running from Docker or source.&lt;/p&gt;&lt;head rend="h2"&gt;Switch to models.dev Provider Model Configuration&lt;/head&gt;&lt;p&gt;A major change to significantly increase the available models is the switch to utilizing the same models.dev open provider and model catalogue as used and maintained by OpenCode.&lt;/p&gt;&lt;p&gt;llms.json provider configuration is now a superset of models.dev/api.json where its definitions are merged, allowing you to enable providers using just &lt;code&gt;"enabled": true&lt;/code&gt; to inherit the configuration from models.dev&lt;/p&gt;&lt;head rend="h3"&gt;üåê Expanded Provider Support&lt;/head&gt;&lt;p&gt;The switch to models.dev greatly expands the model selection to over 530 models from 24 different providers, including new support for:&lt;/p&gt;&lt;table&gt;&lt;row span="4"&gt;&lt;cell role="head"&gt;Provider&lt;/cell&gt;&lt;cell role="head"&gt;Models&lt;/cell&gt;&lt;cell role="head"&gt;Provider&lt;/cell&gt;&lt;cell role="head"&gt;Models&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Alibaba&lt;/cell&gt;&lt;cell&gt;39&lt;/cell&gt;&lt;cell&gt;Hugging Face&lt;/cell&gt;&lt;cell&gt;14&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Chutes&lt;/cell&gt;&lt;cell&gt;56&lt;/cell&gt;&lt;cell&gt;Zai Coding Plan&lt;/cell&gt;&lt;cell&gt;6&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;DeepSeek&lt;/cell&gt;&lt;cell&gt;2&lt;/cell&gt;&lt;cell&gt;MiniMax&lt;/cell&gt;&lt;cell&gt;1&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Fireworks AI&lt;/cell&gt;&lt;cell&gt;12&lt;/cell&gt;&lt;cell&gt;Moonshot AI&lt;/cell&gt;&lt;cell&gt;5&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;GitHub Copilot&lt;/cell&gt;&lt;cell&gt;27&lt;/cell&gt;&lt;cell&gt;Nvidia&lt;/cell&gt;&lt;cell&gt;24&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;GitHub Models&lt;/cell&gt;&lt;cell&gt;55&lt;/cell&gt;&lt;cell&gt;Zai&lt;/cell&gt;&lt;cell&gt;6&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;Cerebras&lt;/cell&gt;&lt;cell&gt;3&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;LMStudio&lt;/cell&gt;&lt;cell&gt;local&lt;/cell&gt;&lt;cell&gt;Ollama&lt;/cell&gt;&lt;cell&gt;local&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;Non OpenAI Compatible LLM and Image generation providers are maintained in the providers extension, registered using the &lt;code&gt;ctx.add_provider()&lt;/code&gt; API. There are several different provider implementations to take advantage of features available in each provider, such as Interleaved Thinking support in Anthropic's Messages API which enables all Claude and MiniMax models to reason between tool calls for improved agentic performance.&lt;/p&gt;&lt;p&gt;TIP&lt;/p&gt;&lt;head rend="h3"&gt;üîÑ Automatic Provider Updates&lt;/head&gt;&lt;p&gt;This actively maintained list of available providers and models are automatically updated into your &lt;code&gt;providers.json&lt;/code&gt; daily that can also be manually updated with:&lt;/p&gt;&lt;p&gt;As an optimization only the providers that are referenced in your &lt;code&gt;llms.json&lt;/code&gt; are saved. Any additional providers you want to use that are not included in models.dev can be added to your &lt;code&gt;~/.llms/providers-extra.json&lt;/code&gt;, which get merged into your &lt;code&gt;providers.json&lt;/code&gt; on every update.&lt;/p&gt;&lt;p&gt;This keeps your local configuration file lightweight by only including the providers that are available for use.&lt;/p&gt;&lt;head rend="h3"&gt;Configuration Examples&lt;/head&gt;&lt;p&gt;Enable providers by ID ‚Äî all configuration is automatically inherited:&lt;/p&gt;&lt;p&gt;See Configuration docs for more info.&lt;/p&gt;&lt;head rend="h3"&gt;New Model Selector UI&lt;/head&gt;&lt;p&gt;With over 530 models from 24 providers now available, discovering and selecting the right model required a complete overhaul. The Model Selector has been completely redesigned as a full-featured dialog offering:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;üîç Smart Search &amp;amp; Discovery - Instantly search across model names, IDs, and providers&lt;/item&gt;&lt;item&gt;üéØ Advanced Filtering - Filter by name, providers &amp;amp; input and output modalities&lt;/item&gt;&lt;item&gt;üìä Flexible Sorting - Sort by Knowledge Cutoff, Release Date, Last Updated &amp;amp; Context&lt;/item&gt;&lt;item&gt;‚≠ê Favorites System - Star model card to add/remove to favorites quick list&lt;/item&gt;&lt;item&gt;üíé Rich Model Cards - In depth model overview at a glance&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Where providers can be quickly enabled or disabled to customize which models are available:&lt;/p&gt;&lt;p&gt;See Model Selector docs for more info.&lt;/p&gt;&lt;head rend="h2"&gt;Rewritten for Extensibility&lt;/head&gt;&lt;p&gt;llms.py has been rewritten from the ground-up with extensibility a core concept where all major UI and Server features now layer on their encapsulated functionality by using the public Client &amp;amp; Server Extensibility APIs.&lt;/p&gt;&lt;p&gt;Extensions are just folders that can add both Server and UI features using the public client and server extensibility APIs. Built-in features are just extensions in the repo's llms/extensions folder which can be disabled or overridden by adding them to your local &lt;code&gt;~/.llms/extensions&lt;/code&gt; folder. Too minimize bloat, only features that are generally useful and don't require additional dependencies are included as built-in extensions.&lt;/p&gt;&lt;p&gt;llms includes support for installing and uninstalling extensions from any GitHub repository. For better discoverability, non built-in extensions are maintained in the github.com/llmspy organization repositories which anyone else is welcome to contribute their repos to for increased discoverability.&lt;/p&gt;&lt;p&gt;UI components are now registered and referenced as Global Vue components, which can be easily replaced by registering Vue components with the same name as done in the xmas extension demo.&lt;/p&gt;&lt;p&gt;This approach allows main.py to retain a lean functional core in a single file whilst still being fully extensible and lays the foundation for rapid development of new features - both from the core team and external 3rd party extensions - enabling the community to extend llms.py in new unanticipated ways.&lt;/p&gt;&lt;p&gt;For deployments requiring minimal footprint, the Custom Build docs shows how to create a tailored distribution with only the specific extensions you need - perfect for CLI-only or lightweight API server deployments.&lt;/p&gt;&lt;head rend="h2"&gt;Extensions System&lt;/head&gt;&lt;p&gt;To keep the core lightweight while enabling limitless enhancements, we've implemented a flexible Extensions system inspired by ComfyUI Custom Nodes. This allows adding new features, pages and toolbar icons, register new provider implementations, extend, replace, and customize the UI with your own custom features, just by adding new extension folders.&lt;/p&gt;&lt;head rend="h3"&gt;Managing Extensions&lt;/head&gt;&lt;p&gt;List available extensions:&lt;/p&gt;&lt;p&gt;Output:&lt;/p&gt;&lt;p&gt;Install an extension:&lt;/p&gt;&lt;p&gt;Install a 3rd-party extension:&lt;/p&gt;&lt;p&gt;INFO&lt;/p&gt;&lt;code&gt;~/.llms/extensions/my_extension&lt;/code&gt; and installs any &lt;code&gt;requirements.txt&lt;/code&gt; dependencies.&lt;p&gt;List installed extensions:&lt;/p&gt;&lt;p&gt;Remove an extension:&lt;/p&gt;&lt;head rend="h3"&gt;Manual Installation&lt;/head&gt;&lt;p&gt;Extensions can be installed from GitHub or by creating a local folder:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Local: Simply create a folder in &lt;code&gt;~/.llms/extensions/my_extension&lt;/code&gt;&lt;/item&gt;&lt;item&gt;GitHub: Clone extensions into &lt;code&gt;~/.llms/extensions&lt;/code&gt;, e.g:&lt;/item&gt;&lt;/list&gt;&lt;p&gt;See Extensions docs for more details.&lt;/p&gt;&lt;head rend="h3"&gt;How it Works (Server)&lt;/head&gt;&lt;p&gt;Extensions are Python modules that plug into the server lifecycle using special hooks defined in their &lt;code&gt;__init__.py&lt;/code&gt;:&lt;/p&gt;&lt;table&gt;&lt;row span="2"&gt;&lt;cell role="head"&gt;Hook&lt;/cell&gt;&lt;cell role="head"&gt;Purpose&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;&lt;code&gt;__parser__(parser)&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Add custom CLI arguments&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;&lt;code&gt;__install__(ctx)&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Enhance the server instance (routes, providers, filters, etc.)&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;&lt;code&gt;__load__(ctx)&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Load data or perform async tasks before server starts&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;&lt;code&gt;__run__(ctx)&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Execute custom logic when running in CLI mode&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;The &lt;code&gt;ctx&lt;/code&gt; parameter provides access to the &lt;code&gt;ExtensionContext&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;See Server Extensions docs for more details.&lt;/p&gt;&lt;head rend="h3"&gt;How it Works (UI)&lt;/head&gt;&lt;p&gt;Extensions can also include frontend components:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Placement: Add a &lt;code&gt;ui&lt;/code&gt;folder within your extension directory&lt;/item&gt;&lt;item&gt;Access: Files in this folder are automatically served at &lt;code&gt;/ext/&amp;lt;extension_name&amp;gt;/*&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Integration: Create a &lt;code&gt;ui/index.mjs&lt;/code&gt;file. This is the entry point and must export an&lt;code&gt;install&lt;/code&gt;function:&lt;/item&gt;&lt;/list&gt;&lt;p&gt;See UI Extensions docs for more details.&lt;/p&gt;&lt;head rend="h3"&gt;Example: xmas extension&lt;/head&gt;&lt;p&gt;The xmas extension demonstrates these capabilities where it utilizes the Extensions APIs to give llms.py a splash of Christmas spirit. It uses &lt;code&gt;__install__&lt;/code&gt; to register an API endpoint and a UI extension for its UI features.&lt;/p&gt;&lt;head rend="h3"&gt;Replacing Core Components&lt;/head&gt;&lt;p&gt;All UI features of xmas is implemented in its ui/index.mjs which overrides default &lt;code&gt;Brand&lt;/code&gt; and &lt;code&gt;Welcome&lt;/code&gt; components by registering components with the same name, e.g:&lt;/p&gt;&lt;p&gt;To change both the home page and brand on the top-left to give every page title a festive touch:&lt;/p&gt;&lt;p&gt;It also demonstrates adding a new icon on the left sidebar to open its custom Xmas page component and a top-panel component to display its "Ask Santa" portal:&lt;/p&gt;&lt;head rend="h3"&gt;xmas page&lt;/head&gt;&lt;p&gt;Click to view full size&lt;/p&gt;&lt;head rend="h3"&gt;Ask Santa panel&lt;/head&gt;&lt;p&gt;Click to view full size&lt;/p&gt;&lt;p&gt;The Xmas page calls a custom API endpoint registered in its &lt;code&gt;__install__&lt;/code&gt; hook to return a custom festive greeting, whilst the top-panel modifies chat requests while its Top Panel is open to add a Santa system prompt which is enough to implement its "Ask Santa" feature.&lt;/p&gt;&lt;p&gt;Smart generation models like Nano Banana's gemini-2.5-flash-image perform exceptionally well here as they're able to answer your kids questions with rich, detailed responses and image outputs.&lt;/p&gt;&lt;head rend="h2"&gt;Gemini RAG Extension&lt;/head&gt;&lt;p&gt;The gemini extension provides a complete solution for managing Google Gemini's File Search Stores, enabling RAG (Retrieval Augmented Generation) workflows with automatic document uploads, category organization, and bidirectional sync between your local database and Gemini's cloud storage.&lt;/p&gt;&lt;p&gt;Build up your own knowledge base in File Stores, optionally organized into categories, that you can query to ground your AI chats with your own data - whether that's searching across a single document, a category of related documents, or your entire filestore.&lt;/p&gt;&lt;head rend="h3"&gt;Install&lt;/head&gt;&lt;p&gt;Install the gemini extension via the CLI:&lt;/p&gt;&lt;p&gt;After which you'll be able to click the Gemini Icon to open the Gemini extension page from the sidebar to manage your filestores.&lt;/p&gt;&lt;head rend="h3"&gt;Key Features&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Filestore Management: Create and manage isolated stores of documents for different projects or knowledge bases&lt;/item&gt;&lt;item&gt;Drag &amp;amp; Drop Uploads: Easily upload documents (PDF, Text, Markdown, etc.) by dragging them into the UI&lt;/item&gt;&lt;item&gt;Smart Categorization: Organize documents into categories (folders) for granular retrieval&lt;/item&gt;&lt;item&gt;Contextual RAG Chat: &lt;list rend="ul"&gt;&lt;item&gt;Ask Filestore: Chat with the entire knowledge base of a filestore&lt;/item&gt;&lt;item&gt;Ask Category: Focus your chat on a specific category within a filestore&lt;/item&gt;&lt;item&gt;Ask Document: Chat with a single specific document&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Bi-Directional Sync: Reconcile your local database with the remote Gemini File API&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Uploading Documents&lt;/head&gt;&lt;p&gt;Documents can be uploaded by dragging and dropping files onto the upload zone or clicking to open the file picker. You can organize uploads into category folders by typing a category name before uploading.&lt;/p&gt;&lt;p&gt;Uploads are processed asynchronously by a Background Worker utilizing a DB Queue, so you can continue working while documents are indexed. The worker automatically starts when new documents are uploaded and efficiently handles batch processing without blocking the UI.&lt;/p&gt;&lt;head rend="h3"&gt;RAG Chat in Action&lt;/head&gt;&lt;p&gt;Once documents are uploaded, you can start contextual RAG chat sessions with your data. Each session is pre-configured with a Gemini Model and the &lt;code&gt;file_search&lt;/code&gt; tool to query your selected filestore, category, or document - as shown in the meta example below querying this very v3 document for its best features:&lt;/p&gt;&lt;p&gt;The grounded sources used to answer your query are displayed at the bottom of each chat response, allowing you to verify and explore the source documents.&lt;/p&gt;&lt;p&gt;See the Gemini Extension docs for complete usage instructions.&lt;/p&gt;&lt;head rend="h2"&gt;Tool Support&lt;/head&gt;&lt;p&gt;This release also includes first-class support for Python function calling (Tools), allowing LLMs to interact with your local environment and custom functionality.&lt;/p&gt;&lt;p&gt;Tools can be defined using standard Python functions where its tool definition can be implicitly defined from its function's signature, type hints, and docstrings:&lt;/p&gt;&lt;head rend="h3"&gt;Register tools for function calling&lt;/head&gt;&lt;head rend="h4"&gt;Implicit Tool Definition&lt;/head&gt;&lt;p&gt;Tools can be registered within an extension's &lt;code&gt;install&lt;/code&gt; hook using &lt;code&gt;ctx.register_tool&lt;/code&gt;:&lt;/p&gt;&lt;p&gt;If no group is specified, tools are registered under the default &lt;code&gt;custom&lt;/code&gt; group, alternatively you can group them under your preferred name:&lt;/p&gt;&lt;head rend="h4"&gt;Explicit Tool Definition&lt;/head&gt;&lt;p&gt;When more fine-grain configuration is needed you can use an explicit tool definition, e.g:&lt;/p&gt;&lt;head rend="h3"&gt;UI Management&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;One-Click Enable/Disable: Use the Tool Selector in the top-right to control which tools to use per request&lt;/item&gt;&lt;item&gt;Granular Control: Select "All", "None", or specific tools for each chat session&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Dedicated Tools Page: View all registered tools and their definitions at &lt;code&gt;/tools&lt;/code&gt; or via the sidebar&lt;/p&gt;&lt;head rend="h2"&gt;MCP Support&lt;/head&gt;&lt;p&gt;The fast_mcp extension brings Model Context Protocol (MCP) support to llms.py, allowing you to extend LLM capabilities with a wide range of external tools and services using the FastMCP Python Framework.&lt;/p&gt;&lt;head rend="h3"&gt;Install&lt;/head&gt;&lt;head rend="h3"&gt;Key Features&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Standardized Tool Access: Connect to any MCP-compliant server (Node.js, Python, etc.) seamlessly&lt;/item&gt;&lt;item&gt;Dynamic Discovery: Automatically discovers and registers all tools exposed by configured servers&lt;/item&gt;&lt;item&gt;Parallel Discovery: All configured MCP servers are discovered concurrently for fast startup times&lt;/item&gt;&lt;item&gt;UI Management: Add, edit, and manage MCP servers directly from the Tools page&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;MCP Servers&lt;/head&gt;&lt;p&gt;Click to view full size&lt;/p&gt;&lt;head rend="h3"&gt;Gemini Image via MCP&lt;/head&gt;&lt;p&gt;Click to view full size&lt;/p&gt;&lt;head rend="h3"&gt;Configuration&lt;/head&gt;&lt;p&gt;MCP servers are configured via a &lt;code&gt;mcp.json&lt;/code&gt; file. By default, Anthropic's Git MCP Server is pre-configured:&lt;/p&gt;&lt;head rend="h3"&gt;Managing Servers&lt;/head&gt;&lt;p&gt;Add, edit, or remove MCP servers directly from the UI:&lt;/p&gt;&lt;head rend="h3"&gt;Add MCP Server&lt;/head&gt;&lt;p&gt;Click to view full size&lt;/p&gt;&lt;head rend="h3"&gt;Edit MCP Server&lt;/head&gt;&lt;p&gt;Click to view full size&lt;/p&gt;&lt;head rend="h3"&gt;Executing Tools&lt;/head&gt;&lt;p&gt;MCP tools can be executed directly from the Tools page or invoked by LLMs during chat sessions:&lt;/p&gt;&lt;head rend="h3"&gt;Execute Tool&lt;/head&gt;&lt;p&gt;Click to view full size&lt;/p&gt;&lt;head rend="h3"&gt;Tool Results&lt;/head&gt;&lt;p&gt;Click to view full size&lt;/p&gt;&lt;head rend="h3"&gt;HTML Results&lt;/head&gt;&lt;p&gt;Tool outputs containing HTML content are rendered within a sandboxed iframe, letting you interact with rich content and even play games:&lt;/p&gt;&lt;p&gt;See the MCP Support docs for complete configuration and usage details.&lt;/p&gt;&lt;head rend="h3"&gt;Omarchy MCP&lt;/head&gt;&lt;p&gt;For Omarchy users, the Omarchy MCP enables AI assistants to manage themes - including listing, switching, previewing, installing, and removing themes from your Omarchy desktop environment.&lt;/p&gt;&lt;head rend="h2"&gt;Core Tools&lt;/head&gt;&lt;p&gt;The built-in core_tools extension provides essential functionality for LLMs to interact with their environment, perform calculations, and manage persistent data.&lt;/p&gt;&lt;head rend="h3"&gt;Memory Tools&lt;/head&gt;&lt;p&gt;Functions for persistent key-value storage.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;memory_read&lt;/code&gt;- Read a value from persistent memory.&lt;/item&gt;&lt;item&gt;&lt;code&gt;memory_write&lt;/code&gt;- Write a value to persistent memory.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;File System Tools&lt;/head&gt;&lt;p&gt;All file system operations are restricted to the current working directory for safety.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;read_file&lt;/code&gt;- Read a text file from disk.&lt;/item&gt;&lt;item&gt;&lt;code&gt;write_file&lt;/code&gt;- Write text to a file (overwrites existing content).&lt;/item&gt;&lt;item&gt;&lt;code&gt;list_directory&lt;/code&gt;- List directory contents including file names, sizes, and modification times.&lt;/item&gt;&lt;item&gt;&lt;code&gt;glob_paths&lt;/code&gt;- Find files and directories matching a glob pattern.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Utilities&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;get_current_time&lt;/code&gt;- Get the current time in ISO-8601 format.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Math &amp;amp; Logic&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;calc&lt;/code&gt;- Evaluate a mathematical expression. Supports arithmetic, comparison, boolean operators, and common math functions.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Code Execution Tools&lt;/head&gt;&lt;p&gt;LLMS includes a suite of tools for executing code in various languages within a sandboxed environment. These tools are designed to allow the agent to run scripts, perform calculations, and verify logic safely.&lt;/p&gt;&lt;head rend="h4"&gt;Supported Languages&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;run_python(code)&lt;/code&gt;- Executes Python code.&lt;/item&gt;&lt;item&gt;&lt;code&gt;run_javascript(code)&lt;/code&gt;- Executes JavaScript code (uses&lt;code&gt;bun&lt;/code&gt;or&lt;code&gt;node&lt;/code&gt;).&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Run Python&lt;/head&gt;&lt;p&gt;Click to view full size&lt;/p&gt;&lt;head rend="h3"&gt;Run JavaScript&lt;/head&gt;&lt;p&gt;Click to view full size&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;run_typescript(code)&lt;/code&gt;- Executes TypeScript code (uses&lt;code&gt;bun&lt;/code&gt;or&lt;code&gt;node&lt;/code&gt;).&lt;/item&gt;&lt;item&gt;&lt;code&gt;run_csharp(code)&lt;/code&gt;- Executes C# code (uses&lt;code&gt;dotnet run&lt;/code&gt;with .NET 10+ single-file support).&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Run TypeScript&lt;/head&gt;&lt;p&gt;Click to view full size&lt;/p&gt;&lt;head rend="h3"&gt;Run C#&lt;/head&gt;&lt;p&gt;Click to view full size&lt;/p&gt;&lt;head rend="h2"&gt;Computer Use&lt;/head&gt;&lt;p&gt;The built-in computer_use extension transforms AI agents into autonomous computer operators. Based on Anthropic's computer use tools, it enables agents to see your screen, control the mouse and keyboard, execute shell commands, and edit files - just like a human sitting at the computer.&lt;/p&gt;&lt;p&gt;This unlocks powerful capabilities that traditional API-based tools cannot achieve:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Visual Verification: Confirm that code actually renders correctly in a browser&lt;/item&gt;&lt;item&gt;Desktop Automation: Control any GUI application - web browsers, IDEs, terminals&lt;/item&gt;&lt;item&gt;End-to-End Workflows: Chain together multiple applications in a single task&lt;/item&gt;&lt;item&gt;Legacy Applications: Automate software that lacks APIs&lt;/item&gt;&lt;/list&gt;&lt;p&gt;For example, an agent can write a web application, open a browser, and capture a screenshot to prove it works:&lt;/p&gt;&lt;p&gt;See the Computer Use docs for complete usage details.&lt;/p&gt;&lt;head rend="h2"&gt;Calculator UI&lt;/head&gt;&lt;p&gt;As some core tools are particularly useful on their own, dedicated UIs has been added for the &lt;code&gt;calc&lt;/code&gt; tool with support for evaluating mathematical python expressions, including arithmetic, comparison, boolean operators, &lt;code&gt;math.*&lt;/code&gt; functions &amp;amp; constants and python list comprehensions&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;üñ•Ô∏è UX Friendly Interface - Clean, modern, responsive UI with dark mode support&lt;/item&gt;&lt;item&gt;üíæ Persistent History - Calculations automatically saved to localStorage and preserved between sessions&lt;/item&gt;&lt;item&gt;‚ö° 1-Click Interaction - Click history items to instantly load expressions and copy to clipboard&lt;/item&gt;&lt;item&gt;‚å®Ô∏è Keyboard-Free Access - Complete UI buttons for numbers, operators, constants, and math functions&lt;/item&gt;&lt;item&gt;üêç Python Math Support - Full access to Python's math library including trig, stats, and more&lt;/item&gt;&lt;item&gt;üõ°Ô∏è Safe Evaluation - AST-based evaluator prevents arbitrary code execution for secure calculations&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Run Code UI&lt;/head&gt;&lt;p&gt;Whilst the &lt;code&gt;run_python&lt;/code&gt; tools provides a scratch pad for running stand-alone Python, JavaScript, TypeScript, and C# code in a sandbox.&lt;/p&gt;&lt;p&gt;The UI uses CodeMirror as the code editor, providing a better user experience with syntax highlighting, code completion, and other IDE-like features for writing code.&lt;/p&gt;&lt;head rend="h2"&gt;Run Python, JavaScript, TypeScript &amp;amp; C# programs&lt;/head&gt;&lt;head rend="h3"&gt;Run Python&lt;/head&gt;&lt;p&gt;Click to view full size&lt;/p&gt;&lt;head rend="h3"&gt;Run JavaScript&lt;/head&gt;&lt;p&gt;Click to view full size&lt;/p&gt;&lt;head rend="h3"&gt;Run TypeScript&lt;/head&gt;&lt;p&gt;Click to view full size&lt;/p&gt;&lt;head rend="h3"&gt;Run C#&lt;/head&gt;&lt;p&gt;Click to view full size&lt;/p&gt;&lt;p&gt;The UI uses CodeMirror as the code editor, providing a better user experience with syntax highlighting, code completion, and other IDE-like features for writing code.&lt;/p&gt;&lt;p&gt;INFO&lt;/p&gt;&lt;p&gt;See the Run Code UI docs for more details.&lt;/p&gt;&lt;head rend="h2"&gt;KaTeX Math Typesetting&lt;/head&gt;&lt;p&gt;The katex extension enables beautiful rendering of LaTeX math expressions in AI responses using KaTeX. It integrates automatically with the markdown parser to render math equations in both inline and block formats.&lt;/p&gt;&lt;head rend="h3"&gt;Features&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Fast Rendering: Uses KaTeX for high-performance rendering of math expressions.&lt;/item&gt;&lt;item&gt;Inline Math: Renders math within text using &lt;code&gt;$&lt;/code&gt;or&lt;code&gt;$$&lt;/code&gt;delimiters.&lt;/item&gt;&lt;item&gt;Block Math: Renders complex equations in their own block using &lt;code&gt;$&lt;/code&gt;or&lt;code&gt;$$&lt;/code&gt;delimiters across multiple lines.&lt;/item&gt;&lt;item&gt;Auto-Integration: Automatically extends the &lt;code&gt;marked&lt;/code&gt;parser used in the application.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Popular math expressions&lt;/head&gt;&lt;p&gt;Click to view full size&lt;/p&gt;&lt;head rend="h3"&gt;Basic math expressions&lt;/head&gt;&lt;p&gt;Click to view full size&lt;/p&gt;&lt;head rend="h2"&gt;Image Generation Support&lt;/head&gt;&lt;p&gt;Unlike text generation, there's no standard API for image generation across providers - each requires its own custom implementation. Despite the additional effort required, there's now seamless image generation support through both the UI and CLI with built-in integrations for:&lt;/p&gt;&lt;table&gt;&lt;row span="2"&gt;&lt;cell role="head"&gt;Provider&lt;/cell&gt;&lt;cell role="head"&gt;Status&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;‚úÖ Supported&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;OpenAI&lt;/cell&gt;&lt;cell&gt;‚úÖ Supported&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;OpenRouter&lt;/cell&gt;&lt;cell&gt;‚úÖ Supported&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Chutes&lt;/cell&gt;&lt;cell&gt;‚úÖ Supported&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Z.ai&lt;/cell&gt;&lt;cell&gt;‚úÖ Supported&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Nvidia&lt;/cell&gt;&lt;cell&gt;‚úÖ Supported&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;To begin select an image generation model from the Model Selector that supports image generation:&lt;/p&gt;&lt;p&gt;When an image generation model is selected, the chat prompt will the option to specify which aspect ratio to use for the generated images:&lt;/p&gt;&lt;head rend="h3"&gt;Command-Line Usage&lt;/head&gt;&lt;p&gt;Generate images using the &lt;code&gt;--out image&lt;/code&gt; modifier:&lt;/p&gt;&lt;p&gt;Which uses the &lt;code&gt;out:image&lt;/code&gt; chat template in &lt;code&gt;llms.json&lt;/code&gt; for its image generation request. Before returning, any assets are saved to cache and their local path and HTTP URL returned, e.g:&lt;/p&gt;&lt;p&gt;Output:&lt;/p&gt;&lt;head rend="h3"&gt;Specify a Model&lt;/head&gt;&lt;p&gt;Use any model that supports image generation by specifying its ID or name:&lt;/p&gt;&lt;p&gt;INFO&lt;/p&gt;&lt;code&gt;~/.llms/cache&lt;/code&gt; using their SHA-256 hash as the filename.&lt;head rend="h2"&gt;Audio Generation Support&lt;/head&gt;&lt;p&gt;Audio generation is an emerging capability with limited provider support where Text-to-Speech generation through both the UI and CLI, currently only supports Google's latest TTS models:&lt;/p&gt;&lt;table&gt;&lt;row span="2"&gt;&lt;cell role="head"&gt;Model&lt;/cell&gt;&lt;cell role="head"&gt;Description&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Gemini 2.5 Flash Preview TTS&lt;/cell&gt;&lt;cell&gt;Fast, lightweight TTS&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Gemini 2.5 Pro Preview TTS&lt;/cell&gt;&lt;cell&gt;High-quality TTS&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;Typically you'd select the audio generation model from the Model Selector to find models that supports audio generation:&lt;/p&gt;&lt;p&gt;But despite models.dev listing them as capable of audio generation, only Gemini's TTS models are currently supported for audio generation through Gemini's API as Alibaba doesn't yet support the audio modality.&lt;/p&gt;&lt;head rend="h3"&gt;UI &amp;amp; Command-Line Usage&lt;/head&gt;&lt;p&gt;Available in both the UI and on the command-line using &lt;code&gt;--out audio&lt;/code&gt;:&lt;/p&gt;&lt;head rend="h3"&gt;Output&lt;/head&gt;&lt;p&gt;Audio files are saved locally and accessible via HTTP URL:&lt;/p&gt;&lt;head rend="h3"&gt;Playback&lt;/head&gt;&lt;p&gt;From the command line:&lt;/p&gt;&lt;p&gt;From the browser: Run server with &lt;code&gt;llms --serve 8000&lt;/code&gt; to play URL in your browser.&lt;/p&gt;&lt;head rend="h2"&gt;Media Gallery&lt;/head&gt;&lt;p&gt;The gallery extension intercepts all generated image, audio &amp;amp; file assets and uploaded files in &lt;code&gt;~/.llms/cache&lt;/code&gt; file storage whose metadata is maintained in a SQLite database at &lt;code&gt;~/.llms/user/default/gallery/gallery.sqlite&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Dedicated UIs are available for quickly browsing and navigating or generated images / audio files including a lightbox previewer for full-size viewing:&lt;/p&gt;&lt;head rend="h4"&gt;Portrait Images&lt;/head&gt;&lt;head rend="h4"&gt;Square Images&lt;/head&gt;&lt;head rend="h4"&gt;Landscape Images&lt;/head&gt;&lt;head rend="h4"&gt;Audio Generations&lt;/head&gt;&lt;head rend="h2"&gt;System Prompts Library&lt;/head&gt;&lt;p&gt;System prompts support was refactored into a replaceable system_prompts extension which configures AI requests with a library of over 200+ awesome curated system prompts that can be selected from the UI.&lt;/p&gt;&lt;head rend="h3"&gt;Custom System Prompts&lt;/head&gt;&lt;p&gt;You can maintain your own library of system prompts for all anonymous users at: &lt;code&gt;~/.llms/user/default/system-prompts.json&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Or for signed in users at: &lt;code&gt;~/.llms/user/&amp;lt;github-user&amp;gt;/system-prompts.json&lt;/code&gt;&lt;/p&gt;&lt;p&gt;With the JSON file simply containing an array of names and their system prompts, e.g:&lt;/p&gt;&lt;p&gt;Browse the complete collection of available system prompts below:&lt;/p&gt;&lt;head rend="h2"&gt;Server SQLite and Cached File Storage persistence&lt;/head&gt;&lt;p&gt;Another major change is the migration from client-side IndexedDB storage to a robust server-side SQLite databases. This architectural shift ensures better data consistency, improved performance that enables parallel executions and multi-device access to your chat history.&lt;/p&gt;&lt;p&gt;To keep the database efficient and portable, binary assets (images, audio, etc.) are not stored directly in the SQLite database, Instead all generated assets are stored in the local file system cache at &lt;code&gt;~/.llms/cache&lt;/code&gt; and only relative URLs referencing these assets are stored in the database.&lt;/p&gt;&lt;head rend="h4"&gt;Concurrency Model&lt;/head&gt;&lt;p&gt;To ensure data integrity and high performance without complex locking mechanisms, the system utilizes a single background thread to write operations to the database. This design improves concurrency handling and eliminates database locking issues during high-load scenarios.&lt;/p&gt;&lt;head rend="h4"&gt;Multi-Tenancy &amp;amp; Security&lt;/head&gt;&lt;p&gt;When authentication is enabled, data isolation is automatically enforced. All core tables, including &lt;code&gt;threads&lt;/code&gt; and &lt;code&gt;requests&lt;/code&gt;, are scoped to the authenticated user, ensuring that users can only access their own data.&lt;/p&gt;&lt;head rend="h2"&gt;Image Cache &amp;amp; Optimization&lt;/head&gt;&lt;p&gt;A new caching system has been implemented for generated assets and uploaded images and files that's now persisted in &lt;code&gt;~/.llms/cache&lt;/code&gt;, preserving them across messages and sessions.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Efficient Storage: Only cache references are stored with chat messages&lt;/item&gt;&lt;item&gt;Persistent Access: Images remain accessible in previews and downloads after page reloads&lt;/item&gt;&lt;item&gt;Automatic Management: System handles file storage and serving transparently&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Now that all persistence is server-side, to transfer or backup your configurations, extensions and Chat History you need only copy your &lt;code&gt;~/.llms&lt;/code&gt; folder.&lt;/p&gt;&lt;head rend="h2"&gt;CLI - more Powerful than Ever&lt;/head&gt;&lt;p&gt;All server extension features including tools, custom providers, database persistence, and image/audio generation are fully accessible via the command line, making llms.py a powerful terminal-based AI assistant.&lt;/p&gt;&lt;head rend="h3"&gt;Core CLI Usage&lt;/head&gt;&lt;head rend="h3"&gt;Tools &amp;amp; Function Calling&lt;/head&gt;&lt;p&gt;All registered tools are automatically available in CLI mode. Enable specific tools with the &lt;code&gt;--tools&lt;/code&gt; flag:&lt;/p&gt;&lt;head rend="h3"&gt;Extensions Management&lt;/head&gt;&lt;head rend="h3"&gt;Provider Management&lt;/head&gt;&lt;head rend="h3"&gt;Image Analysis, Audio Transcribing &amp;amp; Documents Processing&lt;/head&gt;&lt;head rend="h3"&gt;Media Generation&lt;/head&gt;&lt;p&gt;Generate images and audio directly from the command line:&lt;/p&gt;&lt;p&gt;All generated media is automatically saved to &lt;code&gt;~/.llms/cache&lt;/code&gt; with metadata persisted in SQLite.&lt;/p&gt;&lt;head rend="h3"&gt;Database Persistence&lt;/head&gt;&lt;p&gt;All CLI interactions are automatically persisted to &lt;code&gt;~/.llms/user/app/app.sqlite&lt;/code&gt;, including:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Chat threads and messages&lt;/item&gt;&lt;item&gt;Tool calls and results&lt;/item&gt;&lt;item&gt;Generated assets and file references&lt;/item&gt;&lt;item&gt;User preferences and settings&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Ensuring your conversation history is preserved and accessible from both CLI and Web UI.&lt;/p&gt;&lt;head rend="h3"&gt;Server Mode&lt;/head&gt;&lt;p&gt;Launch the web UI while keeping full CLI access:&lt;/p&gt;&lt;p&gt;See CLI Docs for more details.&lt;/p&gt;&lt;head rend="h2"&gt;Upgrade Instructions&lt;/head&gt;&lt;p&gt;Happy holidays from llms.py! üéÑ&lt;/p&gt;&lt;head rend="h2"&gt;Building a Community Extension Ecosystem&lt;/head&gt;&lt;p&gt;With llms .py rebuilt from the ground up as an extensible platform, we hope to foster a thriving community extension ecosystem where developers can share innovative solutions and extend llms.py in ways we haven't yet imagined.&lt;/p&gt;&lt;p&gt;As llms .py is still in active development, we welcome your feedback on any features that would better support 3rd party extensions and help cultivate this growing community.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46766432</guid><pubDate>Mon, 26 Jan 2026 15:01:03 +0000</pubDate></item><item><title>AI will not replace software engineers (hopefully)</title><link>https://medium.com/@sig.segv/ai-will-not-replace-software-engineers-hopefully-84c4f8fc94c0</link><description>&lt;doc fingerprint="691d9551a9ef249d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;AI will not replace software engineers (hopefully)&lt;/head&gt;
    &lt;p&gt;The title is not a statement, it‚Äôs a wish. I‚Äôm writing this blog not because I have some profound knowledge about what the future holds, but to gather my thoughts around the subject, because everywhere I look, people are talking about it. Whatever app I open, people are talking about the same thing, they‚Äôre either worried that AI will replace them, they‚Äôre sharing ‚Äúsuccess‚Äù stories about how they built apps with only AI and no engineering background or that AI is still too dumb to replace anyone.&lt;/p&gt;
    &lt;p&gt;I‚Äôm in the first category, I am afraid that I will end up being replaced, that I‚Äôll find myself without a job and that my only option will be applying to work as a cashier at McDonalds. There‚Äôs one thing that gives me hope though, and that is human drive and a little bit of greed.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs imagine a future where AI is so good at writing software that you can one shot any app. You want to edit photos?&lt;lb/&gt;‚ÄúGenerate a photoshop clone.‚Äù&lt;lb/&gt;You‚Äôre not satisfied with you current browser?&lt;lb/&gt;‚ÄúGenerate a Chrome clone that will allow me to block all ads‚Äù.&lt;lb/&gt;If anyone can write any application they want, what‚Äôs the endgame? Will software companies just cease to exist? All that‚Äôs gonna be left are 3 big companies competing to provide models to everyone?&lt;/p&gt;
    &lt;p&gt;And this is where the drive and the greed makes an appearance. Perhaps it‚Äôs not always money that motivates people, but one thing is for certain, people will always want to build new products, build new companies, disrupt markets and earn a lot of money. But if anyone can do anything with AI, what‚Äôs going to be the competitive advantage? Why should I use someone else's software when I can build my own? And if your product starts to be slightly successful, what‚Äôs stoping me from prompting an AI to build a clone of your product so that I can compete with you? And that, I naively believe will always be people, not because they can write better software than AI, but because people are innovative and unpredictable, and they will come up with a way to be competitive.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46766493</guid><pubDate>Mon, 26 Jan 2026 15:05:04 +0000</pubDate></item><item><title>OracleGPT: Thought Experiment on an AI Powered Executive</title><link>https://senteguard.com/blog/#post-7fYcaQrAcfsldmSb7zVM</link><description>&lt;doc fingerprint="1062d5817a757e2e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;SenTeGuard Blog&lt;/head&gt;
    &lt;p&gt;Longform updates, research notes, and security insights from SenTeGuard. Posts are published by the team and moderated to keep the focus on cognitive security.&lt;/p&gt;
    &lt;head rend="h2"&gt;Browse by Category&lt;/head&gt;
    &lt;head rend="h2"&gt;All Posts&lt;/head&gt;
    &lt;head rend="h3"&gt;No posts yet&lt;/head&gt;
    &lt;p&gt;When the admin publishes a post, it will appear here. Visit /blog/admin to add the first one.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46766507</guid><pubDate>Mon, 26 Jan 2026 15:06:09 +0000</pubDate></item><item><title>Qwen3-Max-Thinking</title><link>https://qwen.ai/blog?id=qwen3-max-thinking</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46766741</guid><pubDate>Mon, 26 Jan 2026 15:23:00 +0000</pubDate></item><item><title>What "The Best" Looks Like</title><link>https://www.kuril.in/blog/what-the-best-looks-like/</link><description>&lt;doc fingerprint="3641d31bb80564ec"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;What "The Best" Looks Like&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Talent hits a target no one else can hit. Genius hits a target no one else can see.&lt;/p&gt;
      &lt;p&gt;‚ÄîArthur Schopenhauer&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The second that the next round of funding hits the bank, every new CTO starts obsessing over the same thing: Who the hell do I hire next? The answer is surprisingly non-obvious. You‚Äôre told that you always want‚Äîscratch that, need‚Äîthe best of the best, your startup‚Äôs future depends on it. You‚Äôre told your company is unique, special, and it requires the most hardcore among researchers, designers, engineers, and product managers. You never skimp on who builds the golden goose. You can‚Äôt succeed with any less than that.&lt;/p&gt;
    &lt;p&gt;But, is that actually true?&lt;/p&gt;
    &lt;p&gt;Every startup-hustle YouTube video, VC podcast and celeb founder interview regurgitates that the key to success is to hire the very best people, no matter what it takes. And yet you live in the real world, with real-world constraints. You have only so much money in the bank. Only so much time and bandwidth to hire. Only so much attention in a given day. And you‚Äôre not alone in your hunt. You‚Äôre competing with hundreds of other players in your geography, industry, and problem space looking for ‚Äúthe best.‚Äù Many of them have a more famous brand, more cash, more promising equity, more charming founders, and maybe even a high production value promo video showcasing happy employees, rare wood office counters and a shoes-off policy.&lt;/p&gt;
    &lt;p&gt;Will you actually hire the best of the best against those odds? Many years ago I found myself in this pickle and I had to learn all the relevant lessons the hard way. I share these lessons here, so that you don‚Äôt have to struggle through that same maze yourself. My pain is your gain.&lt;/p&gt;
    &lt;p&gt;My first time around the startup world in 2012, I hardly knew what I was doing and relied mostly on luck‚Äîand unfortunately, firing‚Äîto end up with a team I could be proud of. I had no real point of reference for greatness, for what ‚Äúthe best‚Äù in our area could look like, and building that model required lots of experimentation, with high highs and many low lows.&lt;/p&gt;
    &lt;p&gt;The story of David, our brilliant infrastructure ops engineer at Freckle, has stayed with me ever since. David applied to the company back when we were only hiring for an ops role. We were growing slowly, so there was zero room for anybody who wasn‚Äôt absolutely essential on the team. We had no open-ended extra seat for a smart person who just happened to be on the market, unlike some companies these days.&lt;/p&gt;
    &lt;p&gt;David was 100% what we were not looking for. He had never done any ops. In fact, he had never done anything related to web dev or product engineering. I‚Äôm not sure he even knew what AWS was at that point. He was a sharp physics guy working with a professor on simulations in an academic context. He didn‚Äôt let that deter him. He wanted to work at Freckle, thanks to our reputation as one of the few software startups in the world using Haskell in production at scale. We were an odd outlier in a sea of buggy and laborious Rails apps, a shelter for people who didn‚Äôt want yet another web slop gig. And Haskell was oh-so-hot in the Hacker News programming language theory space at the time, a technology attracting software nerds obsessed with correctness and new, better ways of developing bug-free apps.&lt;/p&gt;
    &lt;p&gt;I immediately told David that he was not a fit; he had none of what we were looking for. And yet he persisted, emailing me that he would do whatever test project we threw at him, and if he bombed it, no problem, he would go away. But if he nailed it, we would have proof that he was qualified, in spite of what his CV indicated. Fine. I sent him a meaty cloud ops take-home project, expecting to never hear from him again. Importantly, this was in the days before you could have Claude Code slap that together for you in two prompts.&lt;/p&gt;
    &lt;p&gt;A day or two later, he returned the project to us, and it was pretty much flawless, doing even more than we had asked for. That was not expected. I got curious about what else he could do. We weren‚Äôt drowning in applicants anyway, so I figured I didn‚Äôt have much to lose. We took him through the usual interview process. He was humble, optimistic, well-spoken, actively communicating and taking feedback well, eager to get to work. He was pumped about everything he could learn on the job, about the doors that would eventually open if he nailed it. He didn‚Äôt have much experience, as someone who had never written commercial software before, but he was really quick to absorb everything we threw at him.&lt;/p&gt;
    &lt;p&gt;We gave him a chance. As predicted, he was stellar, and we had a really good run with him until he moved on to a much more illustrious employer. A few years later he became a senior principal engineer at Stripe, going from a physics lab, then a starry-eyed K-12 software startup, to being a big deal at one of Silicon Valley‚Äôs finest firms. An unsurprising path for one of ‚Äúthe best.‚Äù&lt;/p&gt;
    &lt;p&gt;While building the different companies I worked at, I‚Äôve run several times into ‚ÄúDavids‚Äù who ended up with meteoric career trajectories, sometimes already pedigreed in all the right ways, sometimes completely invisible to everyone but the trained eye of a CTO looking for gold. What is special about someone like that? And how can you, with your humble hiring budget, identify them before their value is obvious to everybody else in the market?&lt;/p&gt;
    &lt;p&gt;With David, it was obvious that I had lucked my way into finding him. He had to badger me into seeing what he was capable of, at a time when I was only looking for obvious signs of success. Later on at my game studio, thanks to a brutally skewed job market, I had the total pick of the litter during Hiring Summer and could select one or two stellar engineers from hundreds of perfectly reasonable applicants. There was hardly any competition, with money drying up all around the industry. Again, I found a diamond in the rough. But this time I had the right knowledge and strategies in place to end up with the kind of team I wanted with far less reliance on luck. Even as I was drowning in hundreds of resumes that all started to look the same, ‚Äúthe best‚Äù candidate was still in there, like a needle in a haystack. This time, I felt like I was actually skilled enough to find that hidden gem, not simply crossing my fingers and relying on luck alone. That‚Äôs a feeling of empowerment I would like you to experience as well.&lt;/p&gt;
    &lt;head rend="h3"&gt;What do we mean by ‚Äúthe best‚Äù?&lt;/head&gt;
    &lt;p&gt;Of course, when every company says they have the best people, the math doesn‚Äôt work out. And of course, if they regularly have to fire staff, something doesn‚Äôt add up again. One day you end up landing a job at one of these companies and realize that the braggadocio was hardly reflective of reality, but then again, it‚Äôs all part of the startup founder LARP that requires you play the part. ‚ÄúOur team is okay, you will probably like working here, we sometimes know what we‚Äôre doing‚Äù would be a much more accurate depiction, but you‚Äôll never find that quote on the careers page.&lt;/p&gt;
    &lt;p&gt;Regardless, you want to be a good Boy Scout CTO and live up to the lofty expectations set for you by the Silicon Valley elders, and at least try to hire ‚Äúthe best of the best‚Äù as they say in all of the fireside chats.&lt;/p&gt;
    &lt;p&gt;But then, a question naturally emerges: what exactly do we mean by the best? The accolades? Pedigrees? Github stars? Hacker News front pages? Job title? Celebrity employers? Number of former YCombinator companies worked at? Hackathon wins? Typing speed? Clout among other Rust developers wearing fuzzy animal costumes? That all sounds good, I guess, but is that all relevant to your company?&lt;/p&gt;
    &lt;p&gt;It turns out that ‚Äúthe best‚Äù is mostly subjective and specific to your situation. The culture, the vibe, the industry, the processes of your company, and the technical choices will all influence who will be a phenomenal addition to your tribe. That person might not be the same individual bringing in a million or two a year at Meta. In fact, that highly pedigreed, highly connected individual might be a net negative for your company, even though they might, at least on paper, seem the most high-end among candidates. They may blow the mind of a recruiter at Netflix, but they may not want to schlep through all of the messiness and chaos of an early stage company still trying to define itself. They‚Äôre not the best for you, and they‚Äôre likely not the best for startups, but plenty of other people are. Your job is to determine what those traits are and where to find people who have them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Universally Best Startup Hires&lt;/head&gt;
    &lt;p&gt;Your company, timing, industry, problem space and founding team personalities are unique, which is why a generic blog post or a book could never tell you exactly what hires are optimal for you. However, experience shows that there are many universal winning commonalities between great hires that will be applicable regardless of your early stage company‚Äôs unique DNA. I identify 11 of them below.&lt;/p&gt;
    &lt;p&gt;The 11 traits:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Non-obviousness&lt;/item&gt;
      &lt;item&gt;Not-too-junior&lt;/item&gt;
      &lt;item&gt;Not-too-senior&lt;/item&gt;
      &lt;item&gt;Hunger&lt;/item&gt;
      &lt;item&gt;Humility&lt;/item&gt;
      &lt;item&gt;High EQ&lt;/item&gt;
      &lt;item&gt;Team-centricity&lt;/item&gt;
      &lt;item&gt;Competence&lt;/item&gt;
      &lt;item&gt;High-agency problem-solvers&lt;/item&gt;
      &lt;item&gt;Cross-disciplinary empathy&lt;/item&gt;
      &lt;item&gt;Tolerance of uncertainty&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As a side note, I found Patrick Lencioni‚Äôs framework from The Ideal Team Player to survive first contact with both pre-seed and Series A+ realities. It‚Äôs one of those dry-as-dust HBR book club management self-help guides that get an eyeroll by your median 20-year-old founder going through YCombinator, but in my experience it confirmed and put a simple model around something I had personally seen emerge again and again in the field.&lt;/p&gt;
    &lt;p&gt;Lencioni identifies three essential traits: hunger, humility and smarts, the latter of which should have been called EQ all along. You‚Äôll see them referenced below. The three criteria may seem obvious at a glance, but having a simple framework to work with as you‚Äôre making hundreds of decisions makes a big difference. Simple things done right turn out to be pretty darn powerful.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs take a closer look at the 11 commonalities among great startup hires I‚Äôve identified. Some of them are simply statistically likely to occur due to the nature of startup hiring. Others are ones you should straight up filter for when you‚Äôre doing your search.&lt;/p&gt;
    &lt;head rend="h3"&gt;Non-obviousness&lt;/head&gt;
    &lt;p&gt;The best hires in the early stages are usually non-obviously good to the untrained eye. They don‚Äôt look as appealing to employers with infinite resources who otherwise would have already hired them. If they were obviously incredible, it would be unlikely you‚Äîat your startup‚Äîwould ever talk to them.&lt;/p&gt;
    &lt;p&gt;One of the most important skills of a startup CTO trying to hire an amazing team is the ability to uncover awesome talent that others have overlooked. These candidates get skipped often due to being too off-the-beaten-path and under-pedigreed compared to the obvious picks that every other company is making. Often these candidates are bad at marketing themselves, don‚Äôt know where to look, and are off-putting in some way to the naive search. You have an opportunity to take advantage of that oversight.&lt;/p&gt;
    &lt;p&gt;Realistically, someone who looks like the perfect FAANG candidate who has won all of the math olympiads, had all of the stellar internships, and went to the top CS schools will either:&lt;/p&gt;
    &lt;p&gt;a. get a big cash dump from YC and start their own thing, or&lt;lb/&gt; b. go work at one of the career-building brand names in the Valley and make a monstrous amount of money.&lt;/p&gt;
    &lt;p&gt;The karmic wheel is just about cycling between those two until that person either gets into VC or becomes an exec at a prestigious firm years later. If that‚Äôs what the universe has in store for a candidate, taking a chance on a no-name team with 12 months in the bank, poor development practices and sloppy management is a tough proposition.&lt;/p&gt;
    &lt;p&gt;That leaves a pretty large pool of ‚Äúeverybody else‚Äù who didn‚Äôt pattern-match. How you go about sifting through them is a big topic I will leave for another chapter, but the key is to look for signals that are less obvious than a Stanford degree and an OpenAI internship. Often that looks like a large volume of work, expertise in unsexy niche areas of technology, an intense work ethic driven by curiosity, and many others.&lt;/p&gt;
    &lt;p&gt;A Stanford CS degree is no guarantee someone will be a phenomenal contributor at your company, but it‚Äôs a reasonable proxy of future potential for large employers with long time horizons that allow them to invest in coaching and nurturing their junior staff. That‚Äôs not in the cards for a pre-revenue startup that will run out of money next year.&lt;/p&gt;
    &lt;head rend="h3"&gt;Not-too-junior&lt;/head&gt;
    &lt;p&gt;The best people for your startup will most likely be senior, or at least mid-stage contributors with several solid years of experience. Too senior isn‚Äôt great either, you don‚Äôt need the large scale cross-team mature product jousting chops. There‚Äôs likely no staff-level work for them to do, and staff-level engineers aren‚Äôt just faster-typing seniors.&lt;/p&gt;
    &lt;p&gt;As an early stage startup, until you have enough lead developers, senior product managers, senior designers etc. to set the standard, hiring fresh-out-of-school contributors is a gamble. Junior staff are still developing their taste, judgment, ability to work in a team, and understanding of how to follow the process and when to deviate from it. Without an adult in the room you‚Äôre in cat-herding territory. This isn‚Äôt to say that you won‚Äôt get work done this way, but you could have had someone else in that seat who required less supervision. And you‚Äôre at a stage where every seat is mission-critical and the opportunity cost is significant.&lt;/p&gt;
    &lt;p&gt;While it might not matter too much as you throw prototype spaghetti at the wall in the early days, as soon as you have something worth maintaining and complexity rises, you‚Äôre now in a race against time. Someone must actively garden the complexity of the work and be ultimately responsible for it, and that someone will tend to be not fresh-out-of-school. Sure, a green dev can care about complexity. But most haven‚Äôt yet lived through a soul-crushing, multi-week refactor fueled by years of tech debt, the kind of preventable trauma that earns you ‚Äúcharacter-building scars.‚Äù If they‚Äôre learning those lessons on your watch, they‚Äôre doing it at the expense of your delivery timeline and your sanity.&lt;/p&gt;
    &lt;p&gt;I‚Äôm fond of mid-stage software developers who demonstrate terrific chops, hunger to learn and prove themselves. Yes, they require more hand-holding, but usually the volume of work they put out, and their openness to re-do it, if needed, is worth betting on. You should be able to manage a couple of them yourself as the CTO in the early days, and soon enough you‚Äôll have other senior people on the team who will pick up the mentorship torch.&lt;/p&gt;
    &lt;head rend="h3"&gt;Not-too-senior&lt;/head&gt;
    &lt;p&gt;This also means that the ‚Äúbest people‚Äù to hire at this stage will tend to be earlier in their careers. The longer great people are on the market, the more likely they are to be identified by the market as being great. Your job as a startup CTO is to find them before others do. Once the market has found them and has actively started rewarding them, they will be out of your price range.&lt;/p&gt;
    &lt;p&gt;Now, it‚Äôs worth mentioning that in specific well-capitalized niches of the startup market, companies are now able to pay a decent chunk of change thanks to larger VC rounds and quicker time-to-revenue. Thus, the old school notion that BigCo always pays best may not hold true as often. Here‚Äôs a quick sample of many Work at a Startup roles in December 2025. Not quite at FAANG-level, but far from starvation.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;Category&lt;/cell&gt;
        &lt;cell role="head"&gt;Count&lt;/cell&gt;
        &lt;cell role="head"&gt;Mean&lt;/cell&gt;
        &lt;cell role="head"&gt;Median&lt;/cell&gt;
        &lt;cell role="head"&gt;Min (Midpoint)&lt;/cell&gt;
        &lt;cell role="head"&gt;Max (Midpoint)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;Regular SWE&lt;/cell&gt;
        &lt;cell&gt;45&lt;/cell&gt;
        &lt;cell&gt;$157.4K&lt;/cell&gt;
        &lt;cell&gt;$150.0K&lt;/cell&gt;
        &lt;cell&gt;$85.0K&lt;/cell&gt;
        &lt;cell&gt;$275.0K&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;Senior SWE&lt;/cell&gt;
        &lt;cell&gt;32&lt;/cell&gt;
        &lt;cell&gt;$209.8K&lt;/cell&gt;
        &lt;cell&gt;$202.5K&lt;/cell&gt;
        &lt;cell&gt;$140.0K&lt;/cell&gt;
        &lt;cell&gt;$350.0K&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Founding SWE&lt;/cell&gt;
        &lt;cell&gt;33&lt;/cell&gt;
        &lt;cell&gt;$189.3K&lt;/cell&gt;
        &lt;cell&gt;$185.0K&lt;/cell&gt;
        &lt;cell&gt;$125.0K&lt;/cell&gt;
        &lt;cell&gt;$255.0K&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;That also means that, unless your company grows fast or shows tremendous potential for the yet-unvested equity, you won‚Äôt get a ton of time with your great early career hires. They will quickly accumulate valuable experience and prove themselves to be stellar, and move on to a prestigious employer with longer time horizons, a great brand name, and a stupendous paycheck that you will not be able to match. Being an L5-7 at BigCo pays a pretty penny, with none of the unpredictability of startup equity and saner hours, but none of the adventure and camaraderie of a pirate ship. For employees later in their careers, that‚Äôs not a bad tradeoff. Once they have vested with your company, it makes sense for them to diversify their equities, as they already own one lottery ticket.&lt;/p&gt;
    &lt;p&gt;Being on the receiving end of a reference call for one of your star employees, while they‚Äôre still working at your company, is always bittersweet: on one hand you want what‚Äôs best for them, to level up and grow in their career. On the other, they‚Äôre your discovery‚Äîdang it‚Äîand you know you won‚Äôt be able to counter-offer the type of employer they can now attract. Or they decide to start their own company, emboldened and informed by the experience at yours.&lt;/p&gt;
    &lt;p&gt;In the end, that‚Äôs okay. Sometimes a great hire‚Äôs growth trajectory is faster than a startup‚Äôs, and you can be grateful for having given them a chance to prove themselves and to find a new path that they wouldn‚Äôt have otherwise. That kind of hire will have likely made a major difference to your company and having trusted alumni out there in the world doing great things should be a source of pride and good industry karma for any CTO who discovered them.&lt;/p&gt;
    &lt;p&gt;Seniority here also unfortunately often correlates with age. The best startup employee will usually be someone early in their career who doesn‚Äôt have as many responsibilities or as much need for consistency due to having more dependents. They may have fewer immediate cash flow constraints, fewer ‚Äúadult responsibilities.‚Äù Kids need braces and karate classes, and if Mom is doing 996 at a ten-person company paying her peanuts, offering a crappy health care plan, promising an epic payout ten years from now, that‚Äôs a real mismatch. Startups are an extreme sport, and generally inadvisable for anybody who‚Äôs not in a safe position to speculate on their career for several years.&lt;/p&gt;
    &lt;head rend="h3"&gt;Hunger&lt;/head&gt;
    &lt;p&gt;The best hires are self-driven, stoked by the ability to learn, to gain mastery of the craft, and by being able to show off their accomplishments to the rest of the team they want to impress. When you look at their track record, even when it‚Äôs not filled with household-name accolades and pedigrees, you will typically see breadcrumbs of exploration, toy projects and experimentation fueled by curiosity. It‚Äôs that classic desire to hack things and understand them.&lt;/p&gt;
    &lt;p&gt;You don‚Äôt need to ask them to work a little harder, they know this is a big growth spurt for them and they want to take advantage of it. The company is giving them a valuable practice canvas for their skills and they want to make the most of this opportunity, which unfortunately isn‚Äôt that common. They love a challenge, they want to prove themselves, they love the work and they are excited by being around others who will push them to be their best. They would have been hacking on something interesting either way, but now you‚Äôre actually paying them to do it.&lt;/p&gt;
    &lt;p&gt;They‚Äôre curious about how everything works: your company, the startup world, the industry they‚Äôre diving into, other disciplines, the tech they‚Äôre using. They‚Äôre learning, absorbing. Maybe they want to start their own thing one day, or maybe they‚Äôre set on using this gig as a ramp to something else they dream about. Maybe they just want the new optionality granted by having your company on their resume. They‚Äôre sponges and will gladly take on the challenges you send their way.&lt;/p&gt;
    &lt;p&gt;I remember throwing a big Redux experiment at David in what must have been his first month at work. Again, no web dev experience prior to this. Nobody on the team knew the technology and he, hired as an infrastructure engineer with a background in physics and zero product engineering experience, had something up and running for us within days. He was pumped he got to do something so radically new for the team as one of his first assignments. Ultimately we decided the tech wasn‚Äôt a fit for our existing codebase, we scrapped the experiment, and he ran off to the next challenge with no loss of enthusiasm.&lt;/p&gt;
    &lt;p&gt;At Double Dusk we could not figure out why players would regularly de-sync their character positions on the server when using a custom‚Äîand wildly complicated, due to needing to replicate Half Life 2-style movement to the smallest detail inside of Unreal Engine‚Äîcharacter movement component in combination with our own Unreal Engine networking tweaks, making character movement authoritative on client instances of the game. A big deviation from the defaults.&lt;/p&gt;
    &lt;p&gt;Our newly-hired star engineer, us being his first ever employer, had to dive into the pit of madness. He almost gave up several times before finally identifying all of the spots in the physics sub-stepping logic that was causing the drift across the network. I‚Äôm confident I myself would have gone completely bananas trying to debug that one. He was proud of the trust we had put in him, he was eager to learn, he didn‚Äôt want to let the team down, and I knew enough about him to make the bet that the challenge would have been just barely within his abilities.&lt;/p&gt;
    &lt;p&gt;Hunger is a massive force-multiplier, and unlike many other traits, it doesn‚Äôt seem to be teachable. Failures will instill humility. Rejection will hone your EQ. But you‚Äôre either driven to compete, learn and prove yourself, or you‚Äôre not. No manager‚Äôs pep talk will kickstart that drive in you, at least not sustainably. The hubris has to come from somewhere much deeper.&lt;/p&gt;
    &lt;head rend="h3"&gt;Humility&lt;/head&gt;
    &lt;p&gt;Startups are all about rapid experimentation, trying countless ideas that don‚Äôt work, and bootstrapping the skills and processes of the company as it figures out just what exactly people will pay for. Trust-building is critical in any team endeavor, and members who are unable to admit fault, who take up all of the space, and/or who need to be right at all costs will be a real problem as the company matures.&lt;/p&gt;
    &lt;p&gt;The best hires are humble and will happily talk about both their victories and their biggest implosions, about what they learned from their misadventures, about talented past coworkers and how their efforts were part of a team. They rarely claim to have single-handedly carried everything on their backs.&lt;/p&gt;
    &lt;p&gt;As you interview candidates searching for the best, many non-obvious great hires will be bad at behavioral interviews‚Äîor interviews in general, for that matter. They didn‚Äôt get extensive training on answering questions using the STAR method, didn‚Äôt drill stock responses to predictable and tired interview questions. They‚Äôre early-ish stage hands-on technology people, not smooth-talking execs jumping from one boardroom to the next. It is your job to fish for key nuggets of insight buried in the rough presentation. After you interview enough people with a similar set of standard questions, you‚Äôll be able to spot the outliers in the bell curve of responses.&lt;/p&gt;
    &lt;p&gt;An underrated aspect of humility in startups is detachment from one‚Äôs work. Companies in the process of inventing themselves need to actively cycle through many ideas, most of which will ultimately not stand the test of time. Design for the trash can and kill your darlings are important mindsets in creative work, and they extend far beyond music, film and games. Quantity leads to quality, and a great hire will accept regularly needing to apply a flamethrower to their work and try again with the new learnings from the latest experiment. They will not be precious about it, nor will they feel diminished by needing to try again. The Davids do not keep score; they keep trying and do the work knowing that there‚Äôs a good chance it will not go anywhere.&lt;/p&gt;
    &lt;p&gt;That is also highly correlated with their ability to take feedback without taking it personally. They‚Äôre not afraid of criticism and quick feedback loops. In fact, they seek disconfirmation sooner rather than later. They have excellent feedback metabolism.&lt;/p&gt;
    &lt;head rend="h3"&gt;High EQ&lt;/head&gt;
    &lt;p&gt;Building technology companies is a team sport. Everything you do is with the help of other people, for the benefit of other people. As much as the startup world fetishizes the cracked ninja jedi 10x code-poet, if that person makes others never want to talk to them again, cracked they are not. Someone who is able to work with others‚Äô quirks, understand how they operate and what they respond to, and act in a way that brings the best out of their teammates is worth their weight in gold. Brilliant jerks, as great as they are for producing riveting drama in TV shows, quickly become a net negative in the real world.&lt;/p&gt;
    &lt;p&gt;We‚Äôre in the squishy human feeling territory here (aka ‚Äúsoft skills‚Äù) and you can‚Äôt LeetCode your way into knowing if someone will be an ass. There‚Äôs no FizzBuzz for empathy. You have to ask them standard questions, shoot the breeze, interact during the various testing phases of the interview, and outside, and ultimately make a call based on the limited data you have. You will never have all of the evidence, but ultimately you have to make a go or no-go call. Sometimes you get lucky and the candidate discloses a consistent pattern from their past that is obviously disqualifying, but often you don‚Äôt.&lt;/p&gt;
    &lt;p&gt;How they interact with you and your team throughout the interview is usually a good data point, and that, of course, goes both ways. Regardless of how you investigate this side of them, it‚Äôs non-negotiable, and the best hires you‚Äôll make will all have a high EQ.&lt;/p&gt;
    &lt;head rend="h3"&gt;Team-centricity&lt;/head&gt;
    &lt;p&gt;At the same time, someone highly empathetic, but who hides in a cave and is unable to coordinate their work with the rest of the software orchestra, is not the best.&lt;/p&gt;
    &lt;p&gt;Great team players anticipate others‚Äô questions and concerns, and are proactive about reaching out and communicating both their status and the progress of their work to those around them. They make their work visible instead of requiring constant polling for the team to figure out what exactly is going on with them.&lt;/p&gt;
    &lt;p&gt;Remote environments in particular benefit from strong proactive communicators, as you can‚Äôt get away with always knowing what‚Äôs going on with everybody due to sitting in the same room for most of the week. One great Loom is worth a thousand words, but a thousand words is still much better than having to pull status out of people.&lt;/p&gt;
    &lt;p&gt;Early stage startups move at a pace that generates tremendous entropy, and someone who‚Äôs able to coordinate with the rest of a team in a way that feels natural and effortless will allow the small teams to scale without requiring project management and complex processes meant for lower-performing contributors.&lt;/p&gt;
    &lt;head rend="h3"&gt;Competence&lt;/head&gt;
    &lt;p&gt;Perhaps counterintuitively, I don‚Äôt fret too much about competence. To me, that‚Äôs a given. If your interview funnel is set up well, with a great take-home project, an onsite, or even a work trial, determining if the person you‚Äôre interviewing is competent should emerge naturally. After all, you and your team are technical experts, craftspeople who can look at another craftsperson‚Äôs work and quickly judge if it is any good.&lt;/p&gt;
    &lt;p&gt;Yes, AI is getting pretty good these days and it‚Äôs becoming easy for candidates of all disciplines to hide behind prompts, but that‚Äôs only an extra reason to allow them to bring those tools into the interview itself and showcase their use rather than shamefully hide their existence. How they use the agents, the back-and-forth, the planning, the tweaking, the types of searches they do as part of the exercise are all valuable data points for determining competence, and you should allow candidates to surface them.&lt;/p&gt;
    &lt;p&gt;In-person interviews and work trials are for now non-gameable, so if you‚Äôre extra paranoid, they are a great option. Non-obvious candidates will be in the hiring race with fewer other companies, possibly none, depending on your industry. That gives both you and them more flexibility and time to try working together for a few days before making it official. With a sufficiently relevant set of tasks for the work trial, you can rest assured that they‚Äôre competent, and learn a lot more about their other traits in the process.&lt;/p&gt;
    &lt;head rend="h3"&gt;High-agency problem-solvers&lt;/head&gt;
    &lt;p&gt;The best start-up hires are problem-solvers, not ticket resolvers. They want to understand what the business is trying to accomplish, what challenge is standing in the way of it, and how to make that problem go away. They‚Äôre autonomous in the best of ways. They don‚Äôt sit around waiting for someone to tell them what to do; they proactively find challenges and opportunities for improvement, iterate on the feedback, and go out of their way to help their teammates. They figure things out, and they do it without needing their hands held.&lt;/p&gt;
    &lt;p&gt;Someone like David didn‚Äôt take no for an answer; he assumed there had to be a narrow path through the rejections he kept getting from me, that it was only a matter of his resourcefulness before he found a crack through which to get what he wanted.&lt;/p&gt;
    &lt;p&gt;The communication, coordination and cohesion overheads that emerge with the addition of more and more staff to the roster are probably the toughest parts of scaling any business. A leader‚Äôs job is to streamline and remove these emergent dependencies between people and teams as much as possible.&lt;/p&gt;
    &lt;p&gt;Besides keeping the number of hires low, the other powerful lever that a start-up CTO has is to hire people who will be self-sufficient and require little to no support to get their jobs done. They will ask for help when necessary, but they will take pride in figuring things out on their own, checking in with you when the time is right. They will require little supervision overall, and only direction when it comes to their work. If they‚Äôre falling behind, being great communicators, they will let the rest of the team know. If they‚Äôre early, they‚Äôll gladly pick the next interesting opportunity to be useful.&lt;/p&gt;
    &lt;p&gt;If they‚Äôre struggling, their pride in their work will make them double-down and overcome the challenge at all costs. In that case your job is to help them pump the brakes when necessary, or their pace can become unsustainable.&lt;/p&gt;
    &lt;head rend="h3"&gt;Cross-disciplinary empathy&lt;/head&gt;
    &lt;p&gt;A great startup hire doesn‚Äôt only think about their respective lane, but cares about the other disciplines around them that their work is impacting. They understand their angle, their priorities, and their expectations. For example:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A back-end engineer anticipates the needs of the front-end and of the infrastructure developers as they make their changes rather than waiting for their work to be pushed back once it doesn‚Äôt meet the standard.&lt;/item&gt;
      &lt;item&gt;A gameplay engineer doesn‚Äôt wait for the game designer to tell them that the feel of what they implemented won‚Äôt fly with the player. They put themselves in the shoes of the other discipline and think like them.&lt;/item&gt;
      &lt;item&gt;A front-end engineer doesn‚Äôt just roll out the interface they‚Äôre working on, they think through the UX and the UI and the usability and the product management side.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;They think about where and how their work will land and anticipate those objections, addressing them in advance. They proactively reach out to those disciplines to avoid yet another coordination chokepoint that will only gobble up time. As more and more skills are compacting into one single individual, we see AI engineers, product engineers, and product managers becoming more technical and moving downstream into programming. This sort of cross-disciplinary mindset buys companies a ton of leverage and ability to iterate faster.&lt;/p&gt;
    &lt;p&gt;Of course, this becomes progressively easier with experience and seniority. But that‚Äôs also why startups moving fast benefit from more mature contributors as time goes on. The reduced communication costs multiplied across more and more team members really add up over time. Unless you have very specific technical needs, having a generalist bias in the early days is a great idea. In fact we‚Äôre seeing more and more disciplines get compressed into one, with software developers covering UI, UX, PM and engineering, effectively becoming a cross-disciplinary team of one. Even in later stages, half-a-pizza teams powered by AI can move mountains on timelines that felt impossible just a few years ago.&lt;/p&gt;
    &lt;head rend="h3"&gt;Tolerance of uncertainty&lt;/head&gt;
    &lt;p&gt;Early-stage startups are notoriously chaotic and unpredictable. You might be working on one feature one day, it might get cancelled the next day, and maybe now you‚Äôre fielding customer support calls for something you shipped that accidentally blew up. The next day you‚Äôre taking a trip to a customer site to chat with potential users.&lt;/p&gt;
    &lt;p&gt;At no point do you know if any of this will make you money, how long until you kill that feature, and how many more of these iterations you‚Äôll do before you either strike gold or the company runs out of money. There are no guarantees in the startup world, except for the fact that your runway will eventually reach zero if you don‚Äôt find something worth selling.&lt;/p&gt;
    &lt;p&gt;As a CTO, it is your responsibility to shield your team from the messy everyday financial reality of where your company is headed. At the same time, I prefer to keep as much as possible in the open so that the team knows how much longer the music will play and when it‚Äôs time to start refreshing their LinkedIn profiles. I never want anything to be a surprise to the team when I could have been candid about it far in advance. It‚Äôs a fine balance between hiding the daily volatility‚Äîmostly of the founders‚Äô moods and their confidence in the company making it‚Äîand exposing the long-term trends.&lt;/p&gt;
    &lt;p&gt;This type of universe requires people who are okay with fewer guarantees.&lt;/p&gt;
    &lt;p&gt;A startup will never have the time to run comprehensive studies, to build extensive plans, to gain all of the information necessary to make the right decision. Seeking perfection at the cost of an action is generally unacceptable, and you learn much more by failing in a valiant attempt than in delaying a perfect attempt that you might have validated months earlier by just doing the thing.&lt;/p&gt;
    &lt;p&gt;Great hires respect that process and are willing to operate without all of the information, accepting that the team will figure it out as it moves forward, often deviating from the original objective. Deleting existing artifacts or completely pivoting to a new strategy on a dime is the ultimate startup superpower.&lt;/p&gt;
    &lt;p&gt;Anybody who needs well-spelled-out plans and continuity in whatever they‚Äôre doing will ultimately struggle in that kind of environment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Wrap-up&lt;/head&gt;
    &lt;p&gt;Hiring is a gamble, but you can tilt the odds in your favor if you stop playing the same game as everyone else. The ‚Äúbest‚Äù hire isn‚Äôt the person with the most GitHub stars or the flashiest resume; it‚Äôs the person who makes your team better by existing within it. It‚Äôs the David who breaks down doors and ends up shaping the direction of the company through their relentless contributions.&lt;/p&gt;
    &lt;p&gt;Developing an eye for non-obvious talent is the only way to build a high-leverage team on a startup budget. Yes, it takes more work. It requires you to actually pay attention. It‚Äôs one of the hardest feats to pull off in startup team building. It means you must trust your own judgment over a candidate‚Äôs credentials. But if you do it right, you don‚Äôt just get a ‚Äúnice‚Äù team, you get a team capable of doing the impossible. Now stop reading and go find ‚Äúthe best‚Äù.&lt;/p&gt;
    &lt;p&gt;| #cto #startups #leadership #management #hiring #recruiting #talent-acquisition #company-building&lt;/p&gt;
    &lt;p&gt;Subscribe to the newsletter&lt;/p&gt;
    &lt;p&gt;Hard-won lessons on software, startups, and leading teams.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46767323</guid><pubDate>Mon, 26 Jan 2026 16:04:07 +0000</pubDate></item><item><title>France Aiming to Replace Zoom, Google Meet, Microsoft Teams, etc.</title><link>https://twitter.com/lellouchenico/status/2015775970330882319</link><description>&lt;doc fingerprint="d635e49f34142863"&gt;
  &lt;main&gt;
    &lt;p&gt;We‚Äôve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.&lt;/p&gt;
    &lt;p&gt;Help Center&lt;/p&gt;
    &lt;p&gt;Terms of Service Privacy Policy Cookie Policy Imprint Ads info ¬© 2026 X Corp.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46767668</guid><pubDate>Mon, 26 Jan 2026 16:27:46 +0000</pubDate></item></channel></rss>