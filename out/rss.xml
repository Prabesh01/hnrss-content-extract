<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 05 Feb 2026 11:06:02 +0000</lastBuildDate><item><title>Voxtral Transcribe 2</title><link>https://mistral.ai/news/voxtral-transcribe-2</link><description>&lt;doc fingerprint="3c2dcd92a1ee1e85"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Voxtral transcribes &lt;lb/&gt; at the speed of sound.&lt;/head&gt;Try Voxtral Transcribe 2 in Mistral Studio&lt;p&gt; Precision diarization, real-time&lt;lb/&gt; transcription, and a new audio playground.&lt;/p&gt;&lt;p&gt;Today, we're releasing Voxtral Transcribe 2, two next-generation speech-to-text models with state-of-the-art transcription quality, diarization, and ultra-low latency. The family includes Voxtral Mini Transcribe V2 for batch transcription and Voxtral Realtime for live applications. Voxtral Realtime is open-weights under the Apache 2.0 license.&lt;/p&gt;&lt;p&gt;We're also launching an audio playground in Mistral Studio to test transcription instantly, powered by Voxtral Transcribe 2, with diarization and timestamps.&lt;/p&gt;&lt;head rend="h2"&gt;Highlights.&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;Voxtral Mini Transcribe V2: State-of-the-art transcription with speaker diarization, context biasing, and word-level timestamps in 13 languages.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Voxtral Realtime: Purpose-built for live transcription with latency configurable down to sub-200ms, enabling voice agents and real-time applications.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Best-in-class efficiency: Industry-leading accuracy at a fraction of the cost, with Voxtral Mini Transcribe V2 achieving the lowest word error rate, at the lowest price point.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Open weights: Voxtral Realtime ships under Apache 2.0, deployable on edge for privacy-first applications.&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Voxtral Realtime.&lt;/head&gt;&lt;p&gt;Voxtral Realtime is purpose-built for applications where latency matters. Unlike approaches that adapt offline models by processing audio in chunks, Realtime uses a novel streaming architecture that transcribes audio as it arrives. The model delivers transcriptions with delay configurable down to sub-200ms, unlocking a new class of voice-first applications.&lt;/p&gt;&lt;p&gt;Word error rate (lower is better) across languages in the FLEURS transcription benchmark.&lt;/p&gt;&lt;p&gt;At 2.4 seconds delay, ideal for subtitling, Realtime matches Voxtral Mini Transcribe V2, our latest batch model. At 480ms delay, it stays within 1-2% word error rate, enabling voice agents with near-offline accuracy.&lt;/p&gt;&lt;p&gt;The model is natively multilingual, achieving strong transcription performance in 13 languages, including English, Chinese, Hindi, Spanish, Arabic, French, Portuguese, Russian, German, Japanese, Korean, Italian, and Dutch. With a 4B parameter footprint, it runs efficiently on edge devices, ensuring privacy and security for sensitive deployments.&lt;/p&gt;&lt;p&gt;We’re releasing the model weights under Apache 2.0 on the Hugging Face Hub.&lt;/p&gt;&lt;head rend="h2"&gt;Voxtral Mini Transcribe V2.&lt;/head&gt;&lt;p&gt;Average diarization error rate (lower is better) across five English benchmarks (Switchboard, CallHome, AMI-IHM, AMI-SDM, SBCSAE) and the TalkBank multilingual benchmark (German, Spanish, English, Chinese, Japanese).&lt;/p&gt;&lt;p&gt;Average word error rate (lower is better) across the top-10 languages in the FLEURS transcription benchmark.&lt;/p&gt;&lt;p&gt;Voxtral Mini Transcribe V2 delivers significant improvements in transcription and diarization quality across languages and domains. At approximately 4% word error rate on FLEURS and $0.003/min, Voxtral offers the best price-performance of any transcription API. It outperforms GPT-4o mini Transcribe, Gemini 2.5 Flash, Assembly Universal, and Deepgram Nova on accuracy, and processes audio approximately 3x faster than ElevenLabs’ Scribe v2 while matching on quality at one-fifth the cost.&lt;/p&gt;&lt;head rend="h3"&gt;Enterprise-ready features.&lt;/head&gt;&lt;p&gt;Voxtral Mini Transcribe V2 introduces key capabilities for enterprise deployments.&lt;/p&gt;&lt;head rend="h4"&gt;Speaker diarization.&lt;/head&gt;&lt;p&gt;Generate transcriptions with speaker labels and precise start/end times. Ideal for meeting transcription, interview analysis, and multi-party call processing. Note: with overlapping speech, the model typically transcribes one speaker.&lt;/p&gt;&lt;head rend="h4"&gt;Context biasing.&lt;/head&gt;&lt;p&gt;Provide up to 100 words or phrases to guide the model toward correct spellings of names, technical terms, or domain-specific vocabulary. Particularly useful for proper nouns or industry terminology that standard models often miss. Context biasing is optimized for English; support for other languages is experimental.&lt;/p&gt;&lt;head rend="h4"&gt;Word-level timestamps.&lt;/head&gt;&lt;p&gt;Generate precise start and end timestamps for each word, enabling applications like subtitle generation, audio search, and content alignment.&lt;/p&gt;&lt;head rend="h4"&gt;Expanded language support.&lt;/head&gt;&lt;p&gt;Like Realtime, this model now supports 13 languages: English, Chinese, Hindi, Spanish, Arabic, French, Portuguese, Russian, German, Japanese, Korean, Italian, and Dutch. Non-English performance significantly outpaces competitors.&lt;/p&gt;&lt;head rend="h4"&gt;Noise robustness.&lt;/head&gt;&lt;p&gt;Maintains transcription accuracy in challenging acoustic environments, such as factory floors, busy call centers, and field recordings.&lt;/p&gt;&lt;head rend="h4"&gt;Longer audio support.&lt;/head&gt;&lt;p&gt;Process recordings up to 3 hours in a single request.&lt;/p&gt;&lt;p&gt;Word error rate (lower is better) across languages in the FLEURS transcription benchmark.&lt;/p&gt;&lt;head rend="h2"&gt;Audio playground.&lt;/head&gt;&lt;p&gt;Test Voxtral Transcribe 2 directly in Mistral Studio. Upload up to 10 audio files, toggle diarization, choose timestamp granularity, and add context bias terms for domain-specific vocabulary. Supports .mp3, .wav, .m4a, .flac, .ogg up to 1GB each.&lt;/p&gt;&lt;head rend="h2"&gt;Transforming voice applications.&lt;/head&gt;&lt;p&gt;Voxtral powers voice workflows in diverse applications and industries.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;head rend="h3"&gt;Meeting intelligence.&lt;/head&gt;&lt;p&gt;Transcribe multilingual recordings with speaker diarization that clearly attributes who said what and when. At Voxtral's price point, annotate large volumes of meeting content at industry-leading cost efficiency.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;head rend="h3"&gt;Voice agents and virtual assistants.&lt;/head&gt;&lt;p&gt;Build conversational AI with sub-200ms transcription latency. Connect Voxtral Realtime to your LLM and TTS pipeline for responsive voice interfaces that feel natural.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;head rend="h3"&gt;Contact center automation.&lt;/head&gt;&lt;p&gt;Transcribe calls in real time, enabling AI systems to analyze sentiment, suggest responses, and populate CRM fields while conversations are still happening. Speaker diarization ensures clear attribution between agents and customers.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;head rend="h3"&gt;Media and broadcast.&lt;/head&gt;&lt;p&gt;Generate live multilingual subtitles with minimal latency. Context biasing handles proper nouns and technical terminology that trip up generic transcription services.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;head rend="h3"&gt;Compliance and documentation.&lt;/head&gt;&lt;p&gt;Monitor and transcribe interactions for regulatory compliance, with diarization providing clear speaker attribution and timestamps enabling precise audit trails.&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Both models support GDPR and HIPAA-compliant deployments through secure on-premise or private cloud setups.&lt;/p&gt;&lt;head rend="h2"&gt;Get started.&lt;/head&gt;&lt;p&gt;Voxtral Mini Transcribe V2 is available now via API at $0.003 per minute. Try it now in the new Mistral Studio audio playground or in Le Chat.&lt;/p&gt;&lt;p&gt;Voxtral Realtime is available via API at $0.006 per minute and as open weights on Hugging Face.&lt;/p&gt;&lt;p&gt;Explore documentation on Mistral’s audio and transcription capabilities.&lt;/p&gt;&lt;head rend="h2"&gt;We’re hiring.&lt;/head&gt;&lt;p&gt;If you're excited about building world-class speech AI and putting frontier models into the hands of developers everywhere, we'd love to hear from you. Apply to join our team.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46886735</guid><pubDate>Wed, 04 Feb 2026 15:08:17 +0000</pubDate></item><item><title>Microsoft's Copilot chatbot is running into problems</title><link>https://www.wsj.com/tech/ai/microsofts-pivotal-ai-product-is-running-into-big-problems-ce235b28</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46887564</guid><pubDate>Wed, 04 Feb 2026 16:08:55 +0000</pubDate></item><item><title>Postgres Postmaster does not scale</title><link>https://www.recall.ai/blog/postgres-postmaster-does-not-scale</link><description>&lt;doc fingerprint="31daa8e3dcad708b"&gt;
  &lt;main&gt;
    &lt;p&gt;At Recall.ai we run an unusual workload. We record millions of meetings every week. We send meeting bots to calls so our customers can automate everything from meeting notes, to keeping the CRM up-to-date, to handling incidents, to providing live-feedback on the call and more.&lt;/p&gt;
    &lt;p&gt;Processing TB/s of real-time media streams is the thing we get asked most about. However an often-overlooked feature of meetings is their unusual synchronization. Most meetings start on the hour, some on the half, but most on the full. It sounds obvious to say it aloud, but the implication of this has rippled through our entire media processing infrastructure.&lt;/p&gt;
    &lt;p&gt;This is a picture of our load pattern. The y-axis is the number of EC2 instances in our fleet. Those large spikes are the bursts of meetings that we need to capture. And when the meeting starts, the compute capacity must be ready to process the incoming data, or it will be lost forever.&lt;/p&gt;
    &lt;p&gt;The extreme gradient of these spikes has resulted in us running into bottlenecks at almost every layer of the stack, from ARP to AWS. This is the story of a stubbornly mysterious issue, that led us to deeply examine postgres internals (again) and uncover an often overlooked postgres bottleneck that only rears its head at extremely high scale.&lt;/p&gt;
    &lt;head rend="h3"&gt;TL;DR&lt;/head&gt;
    &lt;p&gt;Every postgres server starts and ends with the postmaster process. It is responsible for spawning and reaping children to handle connections and parallel workers, amongst other things. The postmaster runs a single-threaded main loop. With high worker churn, this loop can consume an entire CPU core, slowing down connection establishment, parallel queries, signal handling and more. This caused a rare, hard-to-debug issue where some of our EC2 instances would get delayed by 10-15s, waiting on the postmaster to fork a new backend to handle the connection.&lt;/p&gt;
    &lt;head rend="h3"&gt;Slow connections to postgres&lt;/head&gt;
    &lt;p&gt;Months ago we got alerted to large spike of delayed EC2 instances. We immediately investigated only to find that all of them were actually ready and waiting. We initially suspected a slow query caused the delay but we ruled this out. Eventually we uncovered that the delay originated from additional time connecting to postgres.&lt;/p&gt;
    &lt;p&gt;Postgres has its own binary wire protocol. The client sends a startup message, to which the server responds with an auth request.&lt;/p&gt;
    &lt;p&gt;What we observed was truly bizarre, the client would successfully establish a TCP connection to postgres, however the startup message only receive a response after 10s. Here is a example what we saw:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The initial TCP SYN packet is sent from the client&lt;/item&gt;
      &lt;item&gt;Less than one millisecond later the server responds with a SYN,ACK and the client ACK's to establish the connection&lt;/item&gt;
      &lt;item&gt;The client send the startup message to the postgres server and the server ACK's the message&lt;/item&gt;
      &lt;item&gt;10s later the server responds with an auth request and the connection continue nominally from there&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We ruled out obvious resource bottlenecks such as CPU, memory, disk I/O, network I/O and so forth. With all of these metrics looking nominal we turned to a deeper inspection of postgres internals.&lt;/p&gt;
    &lt;head rend="h3"&gt;A reproduction environment&lt;/head&gt;
    &lt;p&gt;We observed that the delay only occurred during the largest spikes, when many thousands of EC2 instances were booting. Notably, it seemed to occur sporadically, maybe only once or twice a week. We host our database on RDS Postgres, which complicated the matter as low-level telemetry is limited. So we resorted to creating a production-like reproduction environment that we could use to continue our investigation.&lt;/p&gt;
    &lt;p&gt;In this setup we used redis pub/sub to trigger a highly synchronized connection to postgres from a fleet of 3000+ EC2 instances. As we installed postgres on its own EC2 instance, we were able to instrument it while reproducing the delay.&lt;/p&gt;
    &lt;head rend="h3"&gt;A deep dive into the postmaster&lt;/head&gt;
    &lt;p&gt;The next step was to form a hypothesis which we could validate. To do this we inspected the postgres source code.&lt;/p&gt;
    &lt;p&gt;Every postgres has a supervisor process that is responsible for spawing and reaping new backends and workers. This process is called the postmaster (I love this name). The postmaster is designed as a single-threaded server loop that processes its events synchronously.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ServerLoop&lt;list rend="ul"&gt;&lt;item&gt;ChildReaper: Reap exited child processes (workers, backends, etc).&lt;/item&gt;&lt;item&gt;AcceptConnection: Launch a new backend to handle a connection.&lt;/item&gt;&lt;item&gt;LaunchBackgroudWorkers: Launch background workers for a parallel queries.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Our hypothesis was that the burst of new connections would temporarily overwhelm the postmaster loop, causing it to lag behind the queue of incoming connections.&lt;/p&gt;
    &lt;head rend="h3"&gt;Profiling the postmaster&lt;/head&gt;
    &lt;p&gt;To do this we profiled the postmaster process under these periods of connection spikes in our simulated environment. It was surprisingly easy to pin the postmaster process.&lt;/p&gt;
    &lt;p&gt;We ran the postgres on a &lt;code&gt;r8g.8xlarge&lt;/code&gt; instance.
At about ~1400 connections/sec we saturated the postmaster main loop and start to observe noticable delays.&lt;/p&gt;
    &lt;p&gt;Use &lt;code&gt;perf&lt;/code&gt; we took sampling profile of the postmaster while it was under duress.&lt;/p&gt;
    &lt;p&gt;As expected the overwhelming majority of the time is spent spawning and reaping backends. It turns out &lt;code&gt;fork&lt;/code&gt; can be expensive! &lt;/p&gt;
    &lt;head rend="h3"&gt;Huge pages&lt;/head&gt;
    &lt;p&gt;A quick aside on how &lt;code&gt;fork&lt;/code&gt; on linux works. When you call &lt;code&gt;fork&lt;/code&gt;, it spawns a new "child" process, an exact duplicate of the parent continuing from the same instruction as the parent.
However, copying the parent's memory pages would be prohibitively expensive for how &lt;code&gt;fork&lt;/code&gt; is typically used. So linux employs a trick here, the pages are Copy-on-Write. This optimization means the copy only happens when the child process tries to modify a parent's memory page.&lt;/p&gt;
    &lt;p&gt;There is a catch however, linux still needs to copy the parent's page table entries (PTEs). Reducing the number of PTEs decreases the overhead of forking the process. On Linux this is easy to do. You can enable huge pages in the kernel using &lt;code&gt;echo $NUM_PAGES | sudo tee /proc/sys/vm/nr_hugepages&lt;/code&gt; and configuring postgres to use them.&lt;/p&gt;
    &lt;p&gt;Enabling huge pages results in a large reduction in the postmaster PTE size. Empirically we found a 20% throughput increase in connection rate with &lt;code&gt;huge_pages = on&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;Background workers&lt;/head&gt;
    &lt;p&gt;To further complicate the matter, the postmaster is also responsible for launching background workers for parallel queries. A high rate of parallel queries further increases increase the stress on postmaster main loop.&lt;/p&gt;
    &lt;code&gt;CREATE OR REPLACE FUNCTION bg_worker_churn(iterations integer)
RETURNS void
LANGUAGE plpgsql
AS $function$
DECLARE
  i int;
BEGIN
  PERFORM set_config('force_parallel_mode','on', true);
  PERFORM set_config('parallel_setup_cost','0', true);
  PERFORM set_config('parallel_tuple_cost','0', true);
  PERFORM set_config('min_parallel_table_scan_size','0', true);
  PERFORM set_config('min_parallel_index_scan_size','0', true);
  PERFORM set_config('enable_indexscan','off', true);
  PERFORM set_config('enable_bitmapscan','off', true);
  PERFORM set_config('parallel_leader_participation','off', true);
  PERFORM set_config('max_parallel_workers','512', true);
  PERFORM set_config('max_parallel_workers_per_gather','128', true);

  CREATE TABLE data (id BIGINT);
  INSERT INTO data SELECT generate_series(0, 100000);
  ANALYZE data;
  FOR i IN 1..iterations LOOP
    PERFORM sum(id) FROM data;
  END LOOP;
  DROP TABLE data;
END;
$function$;
&lt;/code&gt;
    &lt;p&gt;A high background worker churn rate also puts pressure on the postmaster main loop.&lt;/p&gt;
    &lt;head rend="h3"&gt;Unravelling the mystery&lt;/head&gt;
    &lt;p&gt;In production we only observed the connection delays sporadically. We determinated that was due to a confounding factor of increased background worker churn.&lt;/p&gt;
    &lt;p&gt;The smoking gun was in our database monitoring the whole time, which showed the spike in background worker shutdown load at the time of the delay.&lt;/p&gt;
    &lt;p&gt;We were able to simulate a high background worker churn in parallel with the connection flood and observed a large decrease connection throughput from the postmaster.&lt;/p&gt;
    &lt;p&gt;We correlated this query with one our endpoints using a query that triggered a parllel execution plan, that would occasionally coincide with our hourly peaks, resulting in the delayed connections.&lt;/p&gt;
    &lt;head rend="h3"&gt;Fixing the issue&lt;/head&gt;
    &lt;p&gt;Now that we deeply understand the failure mode we can mechnically reason about a solution.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Implementing jitter in our fleet of EC2 instances reduced the peak connection rate&lt;/item&gt;
      &lt;item&gt;Eliminating bursts of parallel queries from our API servers&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Both of these significantly reduce the pressure on the postmaster.&lt;/p&gt;
    &lt;head rend="h3"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Many pieces of wisdom in the engineering zeitgeist are well preached but poorly understood. Postgres connection pooling falls neatly into this category. In this expedition we found one of the underlying reasons that connection pooling is so widely deployed on postgres systems running at scale.&lt;/p&gt;
    &lt;p&gt;Most online resources chalk this up to connection churn, citing fork rates and the pid-per-backend yada, yada. This is all true but in my opinion misses the forest from the trees. The real bottleneck is the single-threaded main loop in the postmaster. Every operation requiring postmaster involvement is pulling from a fixed pool, the size of a single CPU core. A rudimentary experiment shows that we can linearly increase connection throughput by adding additional postmasters on the same host.&lt;/p&gt;
    &lt;p&gt;This is one of my favourite kinds of discoveries: an artificial constraint that has warped the shape of the developer ecosystem (RDS Proxy, pgbouncer, pgcat, etc) around it. Hopefully to be lifted one day!&lt;/p&gt;
    &lt;p&gt;Aside: it's mildly absurd that none of the DBaaS or monitoring tools provide observability into postmaster contention. What's going on here?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46887893</guid><pubDate>Wed, 04 Feb 2026 16:30:51 +0000</pubDate></item><item><title>Converge (YC S23) Is Hiring Product Engineers (NYC, In-Person)</title><link>https://www.runconverge.com/careers/product-engineer</link><description>&lt;doc fingerprint="a508c173dc07a7a8"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Product Engineer&lt;/head&gt;
    &lt;p&gt;Location: NYC (in-person)&lt;/p&gt;
    &lt;p&gt;Help us build everything a consumer brand needs to grow. Weâre just 4 engineers with serious traction (well beyond $1M ARR). Youâll be shipping end-to-end product and working directly with customers.&lt;/p&gt;
    &lt;head rend="h3"&gt;About Converge&lt;/head&gt;
    &lt;p&gt;We want to profitably grow the world's consumer brands. That begins with helping them understand which marketing efforts are driving profitable growth.&lt;/p&gt;
    &lt;p&gt;200+ consumer brands, including publicly traded companies, rely on Converge to check in on their marketing performance up to a dozen times a day. They drill down to figure out what's working and decide where to shift million-dollar marketing budgets.&lt;/p&gt;
    &lt;p&gt;To ship even more, we've raised $5.7M from some of the best investors, including Y Combinator, General Catalyst, and the founders of Posthog, Algolia, Shipbob, ...&lt;/p&gt;
    &lt;head rend="h3"&gt;What you'll do&lt;/head&gt;
    &lt;p&gt;Ship product fully end-to-end. All the way from designing the system and data models to building out the interface and polishing the experience.&lt;/p&gt;
    &lt;p&gt;We trust you to build the best solution to a customer's problem. We lead with context and give you full autonomy to design the solution. This means you'll need to build a deep understanding of the problem, obsess over the solution, and ship it.&lt;/p&gt;
    &lt;p&gt;Work directly with customers. You'll talk to them, ship, get feedback, and iterate. There are no middlemen. This means you can move incredibly fast: you message a customer, create a PR, and can have it fixed within hours.&lt;/p&gt;
    &lt;p&gt;Some examples of projects you could own:&lt;/p&gt;
    &lt;p&gt;Effortless Slack conversations: Customers screenshot their Converge reports up to a dozen of times a day (!) to share with the rest of the company. Instead, they should be able to directly tag and message a teammate from any number in Converge and have this synced bidirectionally with Slack.&lt;/p&gt;
    &lt;p&gt;Centralizing all growth efforts: Converge already centralizes all growth metrics, but the information explaining them is still scattered. We want overlay the context that actually explains trends like pricing updates, budget changes, and promo calendars.&lt;/p&gt;
    &lt;p&gt;Creative analytics: All growth teams use a separate tool to iterate on ad creatives, but they would want to run this workflow on Converge. We should build a Creative Analytics product on top of our data.&lt;/p&gt;
    &lt;p&gt;AI agents: We never wanted to jump on the AI train for the sake of hype. But now that we have the foundations in place, there's huge leverage in building agents that can help growth teams understand their data and act on it more quickly.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why Converge&lt;/head&gt;
    &lt;p&gt;We're a team of just 4 engineers with serious traction (well beyond $1M ARR). Join us if you want to get rid of office politics and just take ownership to get a lot done.&lt;/p&gt;
    &lt;p&gt;Even though you join early, this job comes with real engineering challenges. We process $4B in online orders annually, 20TB of data flows through Converge each month, and we've collected around 10B customer interactions to date.&lt;/p&gt;
    &lt;p&gt;What you're shipping will actually get used. 50% of our customers use us daily (!), while this is only 13% for the average SaaS company. You will have an immediate impact.&lt;/p&gt;
    &lt;p&gt;We love working in-person. You'll like it here if you do too.&lt;/p&gt;
    &lt;p&gt;If you think you could be a founder, there's no better way to learn than to talk to customers and ship. That's what you'll be spending all of your time on. We obsess over the details and will share honest feedback.&lt;/p&gt;
    &lt;head rend="h3"&gt;What we're looking for&lt;/head&gt;
    &lt;p&gt;Strong experience working across the stack (4+ YOE). We work with React, Python, Postgres, and Clickhouse. Experience building data-intensive products or familiarity with Clickhouse is a plus.&lt;/p&gt;
    &lt;p&gt;You've previously built products or large features fully end-to-end.&lt;/p&gt;
    &lt;p&gt;You obsess over the quality of what you're building, both in UX and code.&lt;/p&gt;
    &lt;head rend="h3"&gt;Compensation&lt;/head&gt;
    &lt;p&gt;Salary: $175K - $240K + equity (0.6% - 0.85%).&lt;/p&gt;
    &lt;p&gt;Private health, dental, and vision insurance.&lt;/p&gt;
    &lt;p&gt;Pension &amp;amp; 401k contributions.&lt;/p&gt;
    &lt;head rend="h3"&gt;Interview process*&lt;/head&gt;
    &lt;p&gt;Intro call (30 min): We want to learn about your motivations to join Converge, determine why youâd be a great fit, and answer any questions you have for us.&lt;/p&gt;
    &lt;p&gt;Technical (1h): We work through a typical engineering problem we face at Converge.&lt;/p&gt;
    &lt;p&gt;Culture (45 min): We dive into your past experiences to learn how you like to work and what motivates you.&lt;/p&gt;
    &lt;p&gt;Superday (1 day): Join us for a day to actually build something! You get to meet the team, we get to meet you, it's great. (fully paid)&lt;/p&gt;
    &lt;p&gt;(*) This can all be done in 2 days. If you want to move quickly, we do too. Our founding engineer was on a plane to meet us just days after our first call.&lt;/p&gt;
    &lt;head rend="h2"&gt;We raised $5.7M from some of the best investors&lt;/head&gt;
    &lt;head rend="h3"&gt;James Hawkins&lt;/head&gt;
    &lt;head rend="h3"&gt;Nicolas Dessaigne&lt;/head&gt;
    &lt;head rend="h2"&gt;Founding team&lt;/head&gt;
    &lt;head rend="h2"&gt;How we started&lt;/head&gt;
    &lt;head rend="h3"&gt;Did you knowâ¦&lt;/head&gt;
    &lt;p&gt;All co-founders have written code that has run in production as part of Converge.&lt;/p&gt;
    &lt;p&gt;We closed our first publicly traded company during our YC batch from our living room in San Francisco.&lt;/p&gt;
    &lt;p&gt;Thomas and Tiago (Founding Engineer) worked together when Thomas was just an intern.&lt;/p&gt;
    &lt;p&gt;Michel (Customer Success) was responsible for most of the incoming Converge Support tickets in his previous job as a freelance tracking consultant.&lt;/p&gt;
    &lt;p&gt;Thomas and Jan were best friends in high school, and Jan and Jerome met in their first year of college.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46888331</guid><pubDate>Wed, 04 Feb 2026 17:01:14 +0000</pubDate></item><item><title>AI is killing B2B SaaS</title><link>https://nmn.gl/blog/ai-killing-b2b-saas</link><description>&lt;doc fingerprint="ede5902a8d97058d"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;AI is Killing B2B SaaS&lt;/head&gt;&lt;p&gt;SaaS is the most profitable business model on Earth.1 It’s easy to understand why: build once, sell the same thing again ad infinitum, and don’t suffer any marginal costs on more sales.&lt;/p&gt;&lt;p&gt;I have been writing software for more than half my life. In the last year itself, I’ve talked to hundreds of founders and operators in SF, from preseed to Series E companies.&lt;/p&gt;&lt;p&gt;AI is bringing an existential threat to a lot of B2B SaaS executives: How to keep asking customers for renewal, when every customer feels they can get something better built with vibe-coded AI products?&lt;/p&gt;&lt;p&gt;And the market is pricing it in. Morgan Stanley’s SaaS basket has lagged the Nasdaq by 40 points since December. HubSpot and Klaviyo are down ~30%. Analysts are writing notes titled “No Reasons to Own” software stocks.&lt;/p&gt;&lt;head rend="h2"&gt;The relation between vibe coding and B2B SaaS sales&lt;/head&gt;&lt;p&gt;The new problem for B2B SaaS is that with AI, customers can get something working with vibe coding. There are tens of vibe coding “internal tool” services that promise to connect to every integration in the world to pump out CRUD and workflow apps.&lt;/p&gt;&lt;p&gt;Whatever they build simply works. It takes some wrangling to get there (one Series C VP listed eleven different vibe coding tools they’ve tried and the pros and cons between each on a phone call once), but productivity gains are immediate.&lt;/p&gt;&lt;p&gt;And vibe coding is fun. You feel like a mad wizard using the right incantation 2 to get this magical new silicon intelligence to do exactly what you want.&lt;/p&gt;&lt;p&gt;What they don’t know, though, is that a poorly architected system will fail, eventually. As every senior programmer (eventually) understands, our job is complex because we have to understand the relationships in the real world, the processes involved, and the workflows needed, and representing it in a robust way to create a stable system. AI can’t do that.&lt;/p&gt;&lt;p&gt;Non-programmers don’t know any of this nuance. One Series E CEO told me that they’re re-evaluating the quarterly renewal of their engineering productivity software because they along with an engineer reimplemented something using Github and Notion APIs. They were paying $30,000 to a popular tool3 and they were not going to renew anymore.&lt;/p&gt;&lt;head rend="h2"&gt;How does it impact B2B sales?&lt;/head&gt;&lt;p&gt;If customers feel like they aren’t being served exactly like they want to, they are more likely to churn. The reason behind all this is that customers are demanding more from their B2B vendors, because they know what’s possible.&lt;/p&gt;&lt;p&gt;Previously, you would change your company to fit what your ERP and pay them hundreds of thousands of dollars. Now, everyone can see that agentic coding makes an unprecedented level of flexibility possible. And customers are demanding that flexibility, and if they don’t get it, they’ll leave.&lt;/p&gt;&lt;p&gt;This week itself I was on a phone call with a Series B AE talking about how they’re potentially losing an $X00,000 account just because the customer can’t use a specific failure reporting workflow in the SaaS. They’re now working with me to build what the customer needs and retain them.&lt;/p&gt;&lt;head rend="h2"&gt;How to survive&lt;/head&gt;&lt;head rend="h3"&gt;1. Be a System of Record&lt;/head&gt;&lt;p&gt;If the entire company’s workflows operates on your platform, i.e. you’re a line-of-business SaaS, you are integrated into their existing team already. They know your UI and rely on you on the day to day.&lt;/p&gt;&lt;p&gt;For example, to create a data visualization I won’t seek any SaaS. I’ll just code one myself using many of the popular vibe coding tools (my team actually did that and it’s vastly more flexible than what we’d get off-the-shelf).&lt;/p&gt;&lt;p&gt;Being a “System of Record” means you’re embedded so deeply that there’s no choice but to win. My prediction is that we’ll see more SaaS companies go from the application layer to offering their robust SoR as their primary selling point.&lt;/p&gt;&lt;head rend="h3"&gt;2. Security, authentication, and robustness&lt;/head&gt;&lt;p&gt;This is where vibe-coded apps silently fail — and where established SaaS platforms earn their keep.&lt;/p&gt;&lt;p&gt;When a non-technical team vibe-codes an internal tool, they’re not thinking about environment keys, XSS vulnerabilities or API keys hardcoded in client-side JavaScript. They’re not implementing rate limiting, audit logs, or proper session management. They’re definitely not thinking about SOC 2 compliance, GDPR data residency requirements, or HIPAA audit trails.&lt;/p&gt;&lt;p&gt;I’ve seen it firsthand: a finance team built a “quick” expense approval tool that stored unencrypted reports in a public S3 bucket. A sales ops team created a commission calculator that anyone with the URL could access — no auth required. These aren’t edge cases. They’re the norm when software is built without security as a foundational concern.&lt;/p&gt;&lt;p&gt;Enterprise SaaS platforms have spent years (and millions) solving these problems: role-based access control, encryption at rest and in transit, penetration testing, compliance certifications, incident response procedures. Your customers may not consciously value this — until something breaks.&lt;/p&gt;&lt;p&gt;The challenge is that security is invisible when it works. You need to communicate this value proactively: remind customers that the “simple” tool they could vibe-code themselves would require them to also handle auth, permissions, backups, uptime, and compliance.&lt;/p&gt;&lt;head rend="h3"&gt;3. Adapt to the customer, not the other way around&lt;/head&gt;&lt;p&gt;The times of asking customers to change how they work are gone. Now, SaaS vendors that differentiate by being ultra customizable win the hearts of customers.&lt;/p&gt;&lt;p&gt;How? It’s the most powerful secret to increase usage. We’ve all heard the classic SaaS problem where the software is sold at the beginning of the year, but no one actually ends up using it because of how inflexible it is and the amount of training needed.&lt;/p&gt;&lt;p&gt;And if a SaaS is underutilized, it gets noticed. And that leads to churn.&lt;/p&gt;&lt;p&gt;This is the case with one of my customers, they have a complex SaaS for maintenance operations. But turns out, this was not being used at the technician level because they found the UI too complex4.&lt;/p&gt;&lt;p&gt;How I’m solving this is essentially a whitelabelled vibe-coding platform with in-built distribution and secure deployments. When they heard of my solution they were immediately onboard. Their customer success teams quickly coded a very specific mobile webapp for the technicians to use and deployed it in a few days.&lt;/p&gt;&lt;p&gt;Now, the IC technician is exposed to just those parts of the SaaS that they care about i.e. creating maintenance work orders. The executives get what they want too, vibe coding custom reports exactly the way they want vs going through complicated BI config. They are able to build exactly what they want and feel like digital gods while doing it.&lt;/p&gt;&lt;p&gt;Usage for that account was under 35%, and is now over 70%. They are now working closely with me to vibe code new “micro-apps” that work according to all of their customer workflows. And the best part? This is all on top of their existing SaaS which works as a system of record and handles security, authentication, and supports lock-in by being a data and a UI moat.&lt;/p&gt;&lt;p&gt;This is exactly what I’m building: a way for SaaS companies to let their end-users vibe code on top of their platform (More on that below). My customers tell me it’s the best thing they’ve done for retention, engagement, and expansion in 2026 – because when your users are building on your platform, they’re not evaluating your competitors.&lt;/p&gt;&lt;head rend="h2"&gt;The Real Shift&lt;/head&gt;&lt;p&gt;Here’s what I’ve realized after hundreds of conversations with founders and operators: AI isn’t killing B2B SaaS. It’s killing B2B SaaS that refuses to evolve.&lt;/p&gt;&lt;p&gt;The SaaS model was built on a simple premise: we build it once, you pay forever. That worked when building software was hard. But now your customers have tasted what’s possible. They’ve seen their finance team whip up a custom dashboard in an afternoon. They’ve watched a non-technical PM build an internal tool that actually fits their workflow.&lt;/p&gt;&lt;p&gt;You can’t unsee that. You can’t go back to paying $X0,000/year for software that almost does what you need.&lt;/p&gt;&lt;p&gt;The survivors won’t be the SaaS companies with the best features. They’ll be the ones who become platforms – who let customers build on top of them instead of instead of them. When I showed a well-known VC what I was building to help SaaS companies do exactly this, he said: “This is the future of marketplaces and software companies.”&lt;/p&gt;&lt;p&gt;Maybe. Or maybe this is just another cycle and traditional SaaS will adapt like it always has. But I know this: the companies I’m talking to aren’t waiting around to find out. They’re already rebuilding their relationship with customers from “use our product” to “build on our platform.”&lt;/p&gt;&lt;p&gt;The question isn’t whether AI will eat your SaaS.&lt;/p&gt;&lt;p&gt;It’s whether you’ll be the one holding the fork.&lt;/p&gt;&lt;p&gt;I’m solving exactly this problem with a whitelabelled AI platform for B2B SaaS companies, so your users can vibe code customized workflows on top of their existing system of record.&lt;/p&gt;&lt;p&gt;My customers tell me this is the best way to support retention, engagement, and expansion in 2026. If this sounds interesting to you or someone you know, I can reach out with a custom demo or you can learn more about Giga Catalyst.&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;&lt;p&gt;Whenever I bring a new friend to the Salesforce Park, they are in absolute awe. And, the meme remains true that no one even knows what Salesforce does. Whatever they’re doing, they’re clearly earning enough revenue to purchase multiple blocks in SF. ↩&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;a.k.a. “prompt engineering” which is not engineering at all but that’s a different blog post. ↩&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;I won’t name any names, but the company’s named after an invertebrate animal. ↩&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;And who can blame them – I still feel a pang of anxiety when I look at my sales CRM. ↩&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Increase engagement and retention&lt;/head&gt;&lt;p&gt;Our whitelabel AI vibe coding platform allows your users to customize and build exactly what they need, on top of your platform.&lt;/p&gt;&lt;p&gt;My customers say that this is the best way to increase engagement and retention in 2026.&lt;/p&gt;Curious? Check out Giga Catalyst to learn more&lt;p&gt;Or, fill out this form and I'll personally reach out to show you how it works:&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46888441</guid><pubDate>Wed, 04 Feb 2026 17:09:28 +0000</pubDate></item><item><title>Building a 24-bit arcade CRT display adapter from scratch</title><link>https://www.scd31.com/posts/building-an-arcade-display-adapter</link><description>&lt;doc fingerprint="671f195658a51bd9"&gt;
  &lt;main&gt;&lt;p&gt;In November, my friend and fellow Recurser, Frank, picked up an arcade machine for the Recurse Center. We call it the RCade. He wanted to leave the original CRT in - which I think is a great choice! - and drove it off of a Raspberry Pi. Eventually we wanted to move to a more powerful computer, but we needed a way to connect it to the display. Off-hand, I mentioned that I could build a CRT display adapter that interfaces with a normal computer over USB. This is that project.&lt;/p&gt;&lt;head rend="h2"&gt;What the display expects&lt;/head&gt;&lt;p&gt;The CRT in the RCade has a JAMMA connector, and Frank bought a converter that goes between VGA and JAMMA.&lt;/p&gt;&lt;p&gt;You might think we could just use an off-the-shelf VGA adapter to drive it at this point, but it's not that simple. The CRT runs at a weird resolution; We started with 320x240 but eventually wanted to target 336x262, which is super non-standard. Even 320x240 is unattainable by most display adapters, which typically can't go below 640x480. A custom solution would allow us to output any arbitrary resolution we wanted.&lt;/p&gt;&lt;p&gt;The other thing is that the Pi, with the VGA board we were using, only supports 18-bit colour, and we wanted to improve this. Even on the RCade's CRT, colour banding was an obvious issue.&lt;/p&gt;&lt;p&gt;We also wanted to use a laptop, not a desktop, which meant not using a PCI-e card. Instead, a USB interface would be preferable.&lt;/p&gt;&lt;head rend="h2"&gt;Wait, but what is VGA?&lt;/head&gt;&lt;p&gt;VGA is a signaling protocol that maps almost exactly 1:1 with what a CRT actually does.&lt;/p&gt;Taken from wikimedia.org&lt;p&gt;Inside of a CRT, there are 3 electron guns, which correspond to red, green, and blue colour values. Two electromagnets in the neck of the tube are responsible for steering the beam - one steers horizontally and one steers vertically. To draw an image, the beam moves across the screen one horizontal line at a time, and the electron guns are rapidly modulated in order to display the correct colour at each pixel.&lt;/p&gt;&lt;p&gt;VGA contains analog signals for these R, G, and B electron guns. It also contains an HSYNC and VSYNC signal, which are used so that the driver and the CRT can agree on what pixel is being drawn at a given time. Between the VGA input and the CRT is a very simple circuit which locks onto these HSYNC and VSYNC pulses and synchronizes the sweeping of the beam.&lt;/p&gt;Taken from pyroelectro.com&lt;p&gt;The HSYNC pulses happen in between horizontal lines, and the VSYNC pulses happen in between frames. There are dead zones around each pulse - referred to as the front and back porch - which give the electron beam time to sweep back across the screen.&lt;/p&gt;&lt;p&gt;So, all we really need are those R, G, B, HSYNC, and VSYNC signals, running at precise timing, and synced properly relative to each other. Conceptually this is actually pretty simple!&lt;/p&gt;&lt;head rend="h2"&gt;Attempt 1: Using the RP2040's PIO&lt;/head&gt;&lt;p&gt;I like the Raspberry Pi RP2040 a lot. It's relatively cheap (around $1 USD) and has tons of on-board RAM - 264 KB in fact! It also has what is called Programmable IO, or PIO.&lt;/p&gt;&lt;p&gt;I've never used the PIO before, but the basic idea is that you can write assembly programs where every instruction takes exactly one cycle, and has useful primitives for interacting with GPIO. It's a fairly limited instruction set, but it allows for bit-banging precise cycle-accurate custom protocols. It's exactly what I need to modulate a VGA signal.&lt;/p&gt;&lt;p&gt;The PIO code ended up looking like this:&lt;/p&gt;&lt;quote&gt;// 1. low for 320+16=336 pixels // 2. high for 30 pixels // 3. low for 34 pixels // 4. repeat // runs on sm0 // 6 instrs -&amp;gt; can save some with sidesetting let hsync = pio::pio_asm!( ".wrap_target", /* begin pixels + front porch */ "irq set 0 [2]", // tell vsync we're doing 1 line "set pins, 1 [31]", // go low for 32 "set X, 8 [15]", // +16 = 48 "a:", "jmp X-- a [31]", // each loop 32, * 9 = 288, total = 336 /* end front porch, being assert hsync */ "set pins, 0 [29]", // assert hsync for 30 /* end assert hsync, begin back porch */ "set pins, 1 [29]", // deassert, wait 32 (note there is extra delay after the wrap) ".wrap" ); // NOTE - we get irq at *end* of line so we have to time things accordingly // 1. low for 242 lines -&amp;gt; but irq 2 every line for the first 240 // 2. high for 3 lines // 3. low for 22 lines // 4. repeat // runs on sm1 // 19 instr let vsync = pio::pio_asm!( ".side_set 1 opt", ".wrap_target", "set Y, 6", "a_outer:", "set X, 31", "a:", "wait 1 irq 0", "irq set 2", "jmp X-- a", // 32 lines per inner loop "jmp Y-- a_outer", // 7 outer loops = 224 "set X, 15", // 16 more lines = 240 "z:" "wait 1 irq 0", "irq set 2", "jmp X-- z", "wait 1 irq 0", // wait for end of last rgb line "wait 1 irq 0", // 2 more lines for front porch "wait 1 irq 0", "set X, 2 side 0", // assert vsync "b:", "wait 1 irq 0", "jmp X-- b", // wait for 3 lines "set X, 20 side 1", // deassert vsync "c:", "wait 1 irq 0", "jmp X-- c" // wait for 21 lines (back porch) ".wrap", ); // 2 cycles per pixel so we run at double speed // 6 instr let rgb = pio::pio_asm!( "out X, 32", // holds 319, which we have to read from the FIFO ".wrap_target", "mov Y, X", "wait 1 irq 2", // wait until start of line "a:", "out pins, 16", // write to rgb from dma "jmp Y-- a", "mov pins, NULL", // output black ".wrap" );&lt;/quote&gt;&lt;p&gt;The full code lives here.&lt;/p&gt;&lt;p&gt;There are 3 separate PIO programs. &lt;code&gt;hsync&lt;/code&gt; is responsible for keeping time and generating HSYNC pulses. At the start of each line, it generates an IRQ event that the other programs use for synchronization. &lt;code&gt;vsync&lt;/code&gt; counts these events and generates the VSYNC pulses. Finally, &lt;code&gt;rgb&lt;/code&gt; reads pixel data from DMA and outputs to the RGB pins in precise time with the other signals. The &lt;code&gt;out pins, 16&lt;/code&gt; signifies that we're only doing 16-bit colour for now.&lt;/p&gt;&lt;p&gt;There's a lot of weirdness in here to get around the constraints of the PIO. For example, between all 3 programs, only a maximum of 31 instructions are allowed. All of the VGA parameters (resolution, porch length, etc.) are hard-coded, and changing these would require at least a small rewrite. It's pretty brittle in that regard, but for our use-case it's sufficient as a proof-of-concept.&lt;/p&gt;&lt;p&gt;Here it is running the actual CRT in the RCade:&lt;/p&gt;&lt;p&gt;I wanted to fill the framebuffer with a repeating pattern, but I messed up my code, hence it looking weird. That's fine - it was enough to verify my VGA program worked!&lt;/p&gt;&lt;p&gt;As an aside, every time I popped off the back of the RCade to work on it was terrifying. Not because of the lethal voltages inside, but because Recursers absolutely love the RCade. I often joke that if I were to break it, I would basically be the anti-Frank!&lt;/p&gt;&lt;p&gt;Now that I had something that could take a framebuffer and throw it onto the CRT, it was time to get the image from my computer to the RP2040.&lt;/p&gt;&lt;head rend="h2"&gt;Let's write a kernel module!&lt;/head&gt;&lt;p&gt;My plan was to write a Linux kernel module that would expose itself as a framebuffer, and then send that framebuffer over USB to the RP2040. On the framebuffer side, this involved interfacing with the DRM layer.&lt;/p&gt;&lt;p&gt;I actually made decent progress here, although I kernel panicked many, many times. I never bothered to set up a proper development environment (oops), so pretty much any bug would require me to reboot my computer. This was super annoying and tedious, although I did learn a lot. I found cursed things in the official documentation, like interrobangs!&lt;/p&gt;Linus pls&lt;p&gt;I got as far as getting a framebuffer to show up at the correct resolution and refresh rate. Along this journey though, I discovered the GUD kernel module, and quickly realized I should use that instead.&lt;/p&gt;&lt;head rend="h2"&gt;GUD is... pretty good&lt;/head&gt;&lt;p&gt;Okay so this GUD thing is sick. It's a USB display adapter protocol - exactly what I need! It was originally designed to send video from a computer to a Pi Zero for use as a secondary display. It consists of an upstreamed (!!!) kernel module that runs on the host, and separate gadget software that runs on the Pi Zero. I decided I would just write my own gadget implementation to run on the RP2040.&lt;/p&gt;&lt;p&gt;As a protocol, GUD seems decent. It supports compression over the wire, and only sends the deltas of what's changed in the host's framebuffer. It's also pretty robust in terms of allowing the gadget to advertise what features it supports - compression is optional, and there's flexibility in colour depth and resolution. And again, it's upstreamed into the kernel, so anyone on modern Linux could use my display adapter with no software tweaks.&lt;/p&gt;&lt;p&gt;Unfortunately, GUD has almost no documentation. I figured out what I needed to do by reverse engineering the kernel module, which involved recompiling it to add some debugging statements. The protocol is simple enough that is wasn't too much of a hassle, and it didn't take long before I had developed a gadget implementation in Rust for the RP2040.&lt;/p&gt;&lt;p&gt;And with that, we saw our first Linux images on the CRT:&lt;/p&gt;&lt;p&gt;I know, I know, it looks terrible. Several years ago, I had built a board that implements the R/G/B DACs out of resistors, and I reused that for this project. It can only do 12 bits of colour maximum, and for this test I only bothered to wire up ~2 bits per channel, which is basically unusable. But it proves the concept works!&lt;/p&gt;The board I built several years ago. It was originally designed to fit an STM32 development board.&lt;p&gt;To be honest, it's pretty lucky that this board came with me to New York. I'm surprised I didn't either throw it out or move it to my parent's place. It was probably in some other box of things I deemed worth keeping around.&lt;/p&gt;The VGA board connected to the RP2040.&lt;p&gt;You can see from the above picture that I really connected the bare minimum for a proof-of-concept. I find perfboard soldering to be a bit tedious!&lt;/p&gt;&lt;p&gt;As an aside, you may notice in the video that the entire screen is shifted to the left. The left side has wrapped around and is now on the right side. On initial boot, it would look fine; over time it would gradually get worse and worse. This is a bug in my implementation - I suspect it's some kind of buffer underflow that's happening, such that each time it occurs, the PIO gets progressively more out of sync. But this is just a guess; I didn't look into it too much.&lt;/p&gt;&lt;p&gt;The colour depth issue is trivial to fix, but this next one isn't. The framerate sucks! You can even see it in the video above, where you can watch the new frame scroll down the screen. The RP2040 can only do USB FS (full-speed), which is capable of 11 Mbps. At the 320x240x16 bpp we were originally targeting, every frame is 153.6 kB. At our maximum USB FS speed, that's less than 10 FPS! Embarrasingly, I had originally done the math with a bandwidth of 11 MBps, not 11 Mbps, so I was off by a factor of 8. I was hoping to get something at least temporarily usable but had to go back to the drawing board.&lt;/p&gt;&lt;head rend="h2"&gt;Going on a GUD gadget side quest&lt;/head&gt;&lt;p&gt;Who even needs microcontrollers anyway? My next idea was to use the normal GUD gadget implementation, running on a Pi Zero, but outputting to VGA over GPIO. Conceptually this is pretty simple, although in practice it was anything but. The canonical GUD gadget software was based on a 2021 version of Buildroot, which was too old to output VGA. I tried, and failed, to update the Buildroot version, as well as to backport the VGA overlay. Neither of those really worked, but I didn't really know what I was doing.&lt;/p&gt;&lt;p&gt;I also played around with generating a custom NixOS image that had a modern kernel and the GUD gadget kernel module. When that didn't work I prepared to run a user space GUD gadget implementation on Raspberry Pi OS. But like, isn't that boring? And then I'll still be stuck at 18 bit colour! And sometimes a girl just wants to tickle her electrons :3&lt;/p&gt;&lt;head rend="h2"&gt;Attempt... 2? 3? 1+i? Returning to MCU land&lt;/head&gt;&lt;p&gt;Okay, so my beloved RP2040 doesn't support USB HS (high-speed). My beloved RP2350 (the newer version of the same chip) doesn't either. But some of my beloved STM32s do!&lt;/p&gt;&lt;p&gt;Initially I was planning to go computer -&amp;gt; USB HS -&amp;gt; STM32 -&amp;gt; SPI bus -&amp;gt; RP2040 -&amp;gt; VGA. But like, that's complicated, and there are 2 microcontrollers to program, and there is so much to go wrong, and the SPI bus protocol is going to need to be robust against lost/extra bits, and AAAAAAAAAA I don't wanna!&lt;/p&gt;&lt;p&gt;But! STM32! I learned through research that some of the nicer ones have an LTDC peripheral, which, among other things, can drive an LCD display. And guess what? Many LCDs take in an R, G, B, HSYNC, and VSYNC signal. That's right - they pretend they're a CRT, and they pretend they have a cute little electron gun inside of them, and the STM32 is like "ok I got u" and can just like, do this natively. And I realize that this is what VGA is, but it's so, so funny to me that the protocol is literally just the manifestation of a physical design that is largely obsolete.&lt;/p&gt;&lt;p&gt;Okay so at this point I'm like, is this even a real project anymore? I'm just connecting the USB peripheral to the LTDC peripheral. What part of this is supposed to take effort? I had already written the GUD gadget implementation. Wasn't I basically already done?&lt;/p&gt;&lt;p&gt;OH BOY.&lt;/p&gt;&lt;p&gt;Anyway, by now it's Christmas time and I fly back to Canada to hang out with my family, as you would expect. I had none of my hardware with me, so now felt like a good time to design the actual board.&lt;/p&gt;&lt;p&gt;By Christmas Eve, this is what I had. Conceptually, it's a pretty basic board - there's the USB HS input, the VGA output, 3 8-bit DACs, some RAM for the framebuffer, and supporting components. At the heart of it is the STM32H723, which is a microcontroller that's advertised as supporting USB HS and LTDC.&lt;/p&gt;&lt;p&gt;It's worth talking about the DACs a bit. They have a few requirements. They need to map the 8-bit binary space uniformly to the analog domain. They also need to act as a resistor divider - my I/O is at 3.3V, but VGA expects a maximum of 0.7 volts for R/G/B. And finally, they need to be impedance-matched to the 75 ohms of the VGA cable, to prevent reflections and ringing that show up in the image. I am... pretty doubtful we need this at our resolution, but it doesn't hurt, and it increases nerd cred (^:&lt;/p&gt;&lt;p&gt;I encoded all of these requirements into a system of equations, threw it into a SAT solver, and computed all of my resistor values. I checked the output manually and it made sense, so I used these values in my DAC.&lt;/p&gt;&lt;p&gt;Also worth noting is the length-matched traces between the STM32 and the HyperRAM. Length-matching ensures that all the signals arrive at the same time; if some arrive too early or late it can cause issues. The traces aren't impedance-matched, but I did a bit of math and determined they were short enough that I didn't have to worry about it.&lt;/p&gt;&lt;p&gt;Also, I want to talk about the USB port. I used Mini-USB. Alright look. I know I know, I should have used USB-C. But I don't like USB-C! It's a dumb standard. We spent decades teaching non-technical users to plug the square wire into the square hole and the round wire into the round hole. And then we made every hole the same shape!! But they don't all support the same things!! Not even every cable supports the same things!! I hate it!! And Mini-USB is so cute. It's not reversible, but who cares? It's more robust than micro USB, while still being small. And it's my board, my rules. So yes, I will keep sending pictures of this board to people, and they will keep complaining it doesn't use USB-C. And I will continue to not care! Mini-USB is CUTE. And by the way, if you read this entire article and this is the section you choose to engage with, then you are boring!!! You will never live up to Mini-USB!!&lt;/p&gt;&lt;p&gt;Okay okay sorry about that. I am calm now. With all of that out of the way, I placed the order for the boards. I bought 5 of them, 2 of which were partially assembled. I would complete the rest of the assembly myself, but I didn't want to worry about the more finicky stuff. Between taxes, tariffs, and shipping, it came to a little over a hundred dollars USD.&lt;/p&gt;&lt;head rend="h2"&gt;Disaster strikes&lt;/head&gt;&lt;p&gt;About a week later, I was back home in NYC. My boards hadn't arrived yet, although I did have access to an STM32H723 development board at this point. To prepare for my boards, I started porting my RP2040 firmware to the STM32H723.&lt;/p&gt;&lt;p&gt;Things were going well until I tried getting USB set up. For some reason, I could only get it working at USB FS speeds. I figured I was just initializing something wrong - maybe a register I was forgetting about, or that wasn't in the HAL? I did a lot of digging, before finding this hidden in the datasheet (emphasis mine):&lt;/p&gt;&lt;quote&gt;&lt;p&gt;The devices embed a USB OTG high-speed (up to 480 Mbit/s) device/host/OTG peripheral that supports both full-speed and high-speed operations. It integrates the transceivers for full-speed operation (12 Mbit/s) and a UTMI low-pin interface (ULPI) for high-speed operation (480 Mbit/s). When using the USB OTG_HS interface in HS mode, an external PHY device connected to the ULPI is required.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;My heart sank. Yes, despite this chip very clearly advertising support for USB HS, it can't actually do that without an external PHY. This is super easy to miss - I actually told other people about the problem, and often they would tell me I was incorrect until I showed it to them in the datasheet. I've also found many posts on the ST Community forums from people running into the same thing. So yeah, I need a new board.&lt;/p&gt;&lt;p&gt;But because boards are expensive, I figure I'll still use the rev 1 board to validate as much as I can.&lt;/p&gt;&lt;head rend="h2"&gt;Disaster strikes, again&lt;/head&gt;&lt;p&gt;Once the boards come, I complete assembly of one, plug it into my computer, and nothing happens. I find out that the 3.3V rail is shorted to ground. This is the same on all of my boards, even the 3 that are disassembled. Some debugging later, it turns out I moved a via in KiCad and didn't do a re-pour. My ground plane was connected to my power plane.&lt;/p&gt;&lt;p&gt;I have a full CI/CD pipeline set up for my PCBs, so I was surprised it didn't catch this. It turns out it has a bit of wiggle-room, and the re-pour was small enough it didn't get picked up. I now know I need to be disciplined and run DRC locally, ensuring there are literally no differences (and if there are, commit them and push them up to my Git forge).&lt;/p&gt;&lt;p&gt;Although annoying, and quite embarrassing, this wasn't a huge deal. I used a drill bit and very carefully drilled out the offending via by hand. It made a bit of a mess - make sure you use breathing protection - but I got a board that worked.&lt;/p&gt;The drilled-out via. You can see it directly under the text, near the center-bottom of the image.&lt;p&gt;At this point I wrote some code that exercised the HyperRAM and VGA. Everything worked great, so I began work on the new board. Here's what my development setup looked like while I was testing:&lt;/p&gt;&lt;p&gt;Even though the rev 1 board didn't work out, Frank pointed out that the difference between it and the previous revision was stark:&lt;/p&gt;&lt;p&gt;Not a bad pace of development!&lt;/p&gt;&lt;head rend="h2"&gt;Attempt 4 - Rev 2&lt;/head&gt;&lt;p&gt;I needed an STM32 that supported ULPI (used for talking to the USB PHY), LTDC, and some kind of external RAM. I looked at dozens of chips and found all sorts of blockers. Chips that actually supported both (but they had overlapping pins), chips that were advertised as supporting both (but in actuality, could only do one or the other, depending on the specific model number), and chips that actually could do both, with unconflicting pins, but only in a BGA package. I did not particularly want to deal with that, mainly because the tiny vias and traces would balloon the board cost even more.&lt;/p&gt;&lt;p&gt;I ended up settling on the STM32H750IBT, a massive, 176 pin, LQFP chip. This thing is larger than some New York apartments, and at over $10 USD, it costs about the same! I have bought entire dev boards for a fraction of this.&lt;/p&gt;&lt;p&gt;Once I picked out the chip, I basically redesigned the entire board from scratch. Sure, I could reuse the DACs, but I needed completely new RAM (the new chip has no HyperBus), as well as the USB PHY and supporting components. Now that my Christmas vacation was over, it took me a solid week to get everything designed. This isn't my most complicated board, but it's certainly my most complex routing:&lt;/p&gt;&lt;p&gt;I mean, look at those traces. I'm using basically all available space just to get them to be the same length. ST famously has bad pinouts, and because one of the memory controller pins is located on the complete opposite side of the chip, literally all of the rest of the RAM traces had to be lengthened. And the RAM has a 16-bit data bus. I had to route 38 length-matched traces for the memory alone!&lt;/p&gt;&lt;p&gt;The USB PHY also had a decent number of traces to route, although far less than the RAM. This is probably the part where I'm supposed to say that like, crosstalk is bad and stuff, but we're just gonna ignore that. I had like no space; leave me alone!&lt;/p&gt;&lt;p&gt;Here's what the board looked like:&lt;/p&gt;&lt;p&gt;And with that, I ordered the board. Waiting for it to arrive just about killed me, but when it finally did, I got to work.&lt;/p&gt;&lt;head rend="h2"&gt;Board bring-up&lt;/head&gt;&lt;p&gt;Board bring-up is a magical thing. One-by-one, you enable each part of the board, and you make sure that everything works the way you expect. Given that USB burned me before, I decided to start there.&lt;/p&gt;&lt;p&gt;Right out of the gate, I was off to a bumpy start. I got the USB technically working, and I even got it to show up on my computer as USB HS (yay!), but it was super, super flaky. Eventually I worked out that its crystal oscillator was unstable. Going back to the datasheet, I realized I missed a 1M ohm resistor, which was meant to be put in parallel with the crystal. I didn't have one handy, but I know the human body is around that resistance. I put one finger on each terminal of the crystal. It immediately stabilized. I was pretty ecstatic!&lt;/p&gt;&lt;p&gt;The next day I went to the Recurse Center and stole a 1M ohm resistor to affix to the board. (Faculty, if you're reading this, I owe you about a tenth of a cent. Sorry!)&lt;/p&gt;&lt;p&gt;With that over, the rest of the bring-up process was pretty smooth. I got the LTDC running and ported over the rest of the code that implemented the GUD protocol. I had written things pretty naively but, to my surprise, it didn't need any optimization for high-speed USB. I guess that's what a microcontroller with a 480 MHz core will get you!&lt;/p&gt;&lt;head rend="h2"&gt;Running it in the RCade cabinet&lt;/head&gt;&lt;p&gt;I was already at the Recurse Center at this point, so I popped the back off the RCade, unplugged the VGA from the Pi, and plugged it into my board. It started up immediately - the colours looked great and I got the full 60 Hz framerate. To be honest, I was shocked at how good it looked, and the crowd that had formed was shocked too. I wasn't really a believer that 24 bit colour would be noticeable, but I was totally wrong. The lack of colour banding was striking.&lt;/p&gt;&lt;p&gt;Next, I plugged the board into the Pi, and Frank reconfigured it to make my display adapter the primary display. We launched the normal RCade software and played some games. They looked truly amazing; nothing like before. Rose, one of the main people who developed the software, joked that it looked so good that some of the graphical shortcuts she took were no longer sufficient.&lt;/p&gt;&lt;p&gt;It's hard to tell in the pictures but the difference in person was striking. Where it's most obvious is in the lack of banding around the mountains.&lt;/p&gt;&lt;p&gt;This felt amazing, but I wasn't quite ready to leave the board installed. It was fragile - especially with the resistor I bodged on - and it was expensive. I took my board back out and Frank reverted the RCade to how it was before.&lt;/p&gt;&lt;head rend="h2"&gt;Designing a case&lt;/head&gt;&lt;p&gt;I'll be honest. I don't get that much joy out of 3D modeling. I find it frustrating, tedious, and generally unfulfilling. To get around this, I decided to use YAPP to design the case. YAPP is a parametric box generator written in OpenSCAD. I wrote a few dozen lines of code and ended up with this beauty:&lt;/p&gt;&lt;p&gt;It took barely any time at all and only took 2 physical revisions before I was happy with it. I added the OpenSCAD code to my board repository and CI/CD pipeline. Now, it builds all the files I need to order the boards, as well as the STL files for the case.&lt;/p&gt;HE'S BEGINNING TO TAKE FORM&lt;p&gt;And now, with the board in the case:&lt;/p&gt;&lt;p&gt;At this point I was starting to prepare myself to install it in the RCade.&lt;/p&gt;&lt;head rend="h2"&gt;Disaster strikes, again??&lt;/head&gt;&lt;p&gt;Everything was done, so I expected I'd just plug it in and be good to go. When I did this, though, nothing happened. After some debugging I realized the USB had completely died on my board. It wasn't showing up on any computer I connected it to, although the STM32 was still chugging along happily (and outputting to VGA).&lt;/p&gt;&lt;p&gt;I still haven't figured out exactly what happened here. I was having a bit of flakiness with the USB already. I vaguely suspect ESD to either the STM32 or the USB PHY, but am not super confident this is the cause. I'm going to keep looking into this. (inb4: wow maybe you shouldn't have touched the crystal without grounding yourself first!)&lt;/p&gt;&lt;p&gt;In the meantime, I assembled a second board and got that installed instead. I'm slightly nervous because I don't have a third board to use if this one also dies, and I don't want to order any more until I can figure out what's killing them. That said, it has been a few days now since I installed it, and despite running 24/7, there's no signs of it dying yet.&lt;/p&gt;&lt;p&gt;Here's the board in its case, installed in the RCade. We're still running it off the Raspberry Pi for now, but soon we'll have that switched out with a laptop. I can't wait!&lt;/p&gt;&lt;head rend="h2"&gt;Future improvements&lt;/head&gt;&lt;p&gt;There are all sorts of things I want to change. I want the board to also support audio, with an integrated amp. Perhaps even a tube amp? I just think it would be funny. And being able to read input from the controls would be cool too.&lt;/p&gt;&lt;p&gt;On the software side, I want double or triple buffering. I actually got them both working, although they didn't play nice with the deltas that GUD sends over the wire. There are workarounds to this that I haven't implemented yet. It would also be nice to give GUD the ability to disable these deltas; perhaps that would be a good feature for me to add to the kernel module. Writing some documentation on the GUD protocol could be good too!&lt;/p&gt;&lt;p&gt;This was a really fun project, and it's not over yet, but I think all the hard stuff is pretty much done (although - I've thought that before!). I really wasn't expecting this to take as long as it did, but I learned so much, and I'm a stronger engineer for it.&lt;/p&gt;&lt;head rend="h2"&gt;Source code&lt;/head&gt;&lt;p&gt;There's a few repositories of interest:&lt;/p&gt;&lt;p&gt;The hardware lives here.&lt;/p&gt;&lt;p&gt;The software lives here.&lt;/p&gt;&lt;p&gt;If you're interested, the original software for the RP2040 lives here.&lt;/p&gt;&lt;p&gt;My very messy DAC equations live here.&lt;/p&gt;&lt;p&gt;My Nix GUD gadget attempt lives here.&lt;/p&gt;&lt;p&gt;I also wrote a fair bit of scratch code while learning (such as for my kernel module), but I don't think any of it was worth putting it in my Git forge.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46888795</guid><pubDate>Wed, 04 Feb 2026 17:35:05 +0000</pubDate></item><item><title>The Great Unwind</title><link>https://occupywallst.com/yen</link><description>&lt;doc fingerprint="7fad91172de75f94"&gt;
  &lt;main&gt;
    &lt;p&gt;Have you wondered why the stock market has been so choppy since October and why crypto and gold keep flash crashing? The western media would have you believe this is due to AI bubble, war in Greenland, and Trump's tweets. We have a better story to tell.&lt;/p&gt;
    &lt;p&gt;Wall Street has lost control of the Japanese Yen carry trade unwind.&lt;/p&gt;
    &lt;p&gt;There's been a fair bit of quiet chaos in financial markets recently. Cryptocurrencies have lost 40% of their value. We saw silver drop 40% which hasn't happened since 1980. Stocks like Microsoft are getting picked off one-by-one with 15% drops when positive earnings reports come out. Meanwhile the broader market chops sideways, so people think things are fine. Trump and Europe were on the brink of war for control of a desolate arctic territory. Truth Social has overtaken FOMC as the most important source of financial news. These things may all appear to the untrained eye as a series of idiosyncratic, disconnected shocks. The prevailing media narrative is that the market is reacting negatively to AI CapEx spending and a hawkish new Fed chair. But our systematic analysis of cross-asset flows, derivatives positioning, central bank policy minutes, and institutional balance sheets suggests a singular, unified causality that binds these disparate anomalies, which is the covert unwinding of the Japanese Yen carry trade.&lt;/p&gt;
    &lt;p&gt;For nearly thirty years, the Bank of Japanâs (BOJ) Zero Interest Rate Policy (ZIRP) and subsequent Negative Interest Rate Policy (NIRP) effectively transformed the Yen into the worldâs funding currency. We would call it the greatest free money printer ever made. By anchoring borrowing costs at or near zero, the BOJ enabled Wall Street to borrow Yen cheaply and invest it with leverage into higher yielding instruments globally, such as U.S. treasuries, equities, and cryptography. For example, you borrow Yen from Japan at 0% interest, you exchange it for USD, and then you buy treasury bonds that pay 4%. It's that simple. This funded government benefits and provided continuous reliable liquidity for financial markets that made stocks keep going up while suppressing volatility.&lt;/p&gt;
    &lt;p&gt;Trillions of dollars of free loans from the Bank of Japan were used by a generation of investors to buy a double digit percentage of the U.S. economy. Now those loans are being recalled. Wall Street traders who levered up on the free Japanese money now have to sell trillions of assets and convert the proceeds back to Yen in order to not be liquidated. These aren't happy times for them. They get liquidated when Japan raises interest rates; they get liquidated when the Federal Reserve lowers interest rates; they get liquidated when the Japanese Yen increases in value; they get liquidated when tech stocks aren't going up enough, and all four of these things have been happening at once.&lt;/p&gt;
    &lt;p&gt;Wall Street may be greedy, but they're very intelligent too. They made many smart choices about where to put the "free" money. Now let's say you're someone who's also smart, but was wise enough to not use Sauron's ring. Chances are you invested in the same things as Wall Street. So by now you've probably seen your whole portfolio move against you; you're wondering why your hedges don't work; and you feel like you're being punished for making all the right choices. It's because other smart people, who got greedy, are being forced to close their positions, and you're the whipping boy for their avarice.&lt;/p&gt;
    &lt;p&gt;The Japanese Yen is sort of like GameStop ($GME). It's the most shorted currency on Earth. When you borrow yen to buy American assets, you're effectively shorting the yen. Currency can be rehypothecated so that yen-denominated debt ends up exceeding the actual yen supply, the same way GME's short interest exceeded 100% of its float. When shorts start covering it compounds tragedy, because they all have to buy yen, which makes its value increase, forcing more shorts to cover, and Japan is a small island.&lt;/p&gt;
    &lt;p&gt;This December 2025 rate hike to 0.75%, followed by the explicitly hawkish signalling from Prime Minister Sanae Takaichiâs administration, has fundamentally altered the risk-reward calculus of these leveraged positions. The market disruptions observed in January 2026 bear the distinct mathematical signature of a forced liquidation event rather than a fundamental repricing of growth prospects. When correlations between historically uncorrelated assets (e.g. Gold, Bitcoin, Microsoft, and Silver) approach 1.0 during a sell-off, it serves as a distinct indicator that traders are not selling what they want to sell, but rather what they must sell in order to meet margin calls in a funding currency that is rapidly appreciating against their liabilities.&lt;/p&gt;
    &lt;p&gt;We shall investigate the mechanics of this unwind in exhaustive detail. We analyze the "Greenland Distraction" not as a root cause but as a volatility trigger that shattered the complacent calm of the "Davos Consensus." We examine the anomalous liquidation in precious metals following the nomination of Kevin Warsh to the Federal Reserve Chairmanship, and we dissect the flow of funds from major Japanese institutional whales like Norinchukin Bank, whose retreat from foreign bond markets has left a liquidity vacuum in the U.S. Treasury complex. The evidence points to a systemic repricing of the global cost of capital, originating in Tokyo and transmitting violently through the plumbing of Wall Street, leaving no asset class untouched.&lt;/p&gt;
    &lt;p&gt;To fully comprehend the market chaos of January 2026, one must look beyond the immediate headlines of the new year and scrutinize the subtle yet seismic shifts that occurred in Tokyo during the closing months of 2025. The conventional market narrative has long regarded the Bank of Japan as a passive, almost paralyzed actor, perpetually trapped in a deflationary mire and unable to normalize policy. This view has always been demonstratably false. The truth is that Wall Street leaders have been planning for the next quarter, while the Japanese have been preparing for the next century. The data confirms a deliberate, aggressive shift toward normalization that caught global carry traders offguard.&lt;/p&gt;
    &lt;p&gt;In a move that many Western analysts critically underestimated, the Policy Board of the Bank of Japan voted unanimously to raise the uncollateralized overnight call rate to 0.75% during its policy session on December 18-19, 2025. While a 25 basis point hike might appear negligible in the context of Federal Reserve or ECB tightening cycles, in the context of the Japanese financial system, which has operated near the zero-bound for decades, it represents a massive tightening of financial conditions.&lt;/p&gt;
    &lt;p&gt;This move was not merely a technical adjustment; it was a fundamental regime change. Coming from a baseline of -0.1% in early 2024 and 0.50% in late 2025, the move to 0.75% signaled that the era of "free money" had definitively ended. The rationale provided by the BOJ was grounded in shifting inflationary dynamics. Core CPI (excluding fresh food), the central bank's preferred metric, was tracking near 3% in late 2025, persistently exceeding the 2% price stability target.Although inflation eased slightly to 2.4% in December, the BOJ minutes reveal a board convinced that "wage gains may be durable," thus justifying higher rates to prevent a wage-price spiral.&lt;/p&gt;
    &lt;p&gt;Crucially, the minutes from the December meeting, which were released in late January 2026, contain explicit language suggesting that the tightening cycle is far from complete. The board noted that "real interest rates are expected to remain negative," implying that a policy rate of 0.75% is still considered accommodative relative to inflation.To a bond trader, this is hawkish code. It suggests that the "neutral rate" is significantly higher, potentially between 1.5% and 2.0%. If the market prices in a terminal rate of 2.0%, the cost of funding for carry trades effectively triples from previous levels, turning profitable arbitrage positions into deep losses.&lt;/p&gt;
    &lt;p&gt;The political dimension in Japan has exacerbated the monetary tightness, creating a "double tightening" effect that algorithms have struggled to price. Prime Minister Sanae Takaichi, preparing for a snap election on February 8, 2026, has adopted a complex economic stance that blends fiscal expansion with monetary discipline, a volatile mix for currency markets.&lt;/p&gt;
    &lt;p&gt;Takaichi advocates for "strategic fiscal spending" and tax cuts to stimulate the domestic economy. In standard macroeconomic theory, an expansionary fiscal policy (increased government spending) combined with a tightening monetary policy (higher rates to combat the resulting inflation) is the perfect recipe for currency appreciation. While Takaichi has publicly softened her rhetoric to avoid accusations of currency manipulation, stating she "did not have a preference for the yen's direction", her policies speak louder than her soundbites.&lt;/p&gt;
    &lt;p&gt;The market fears that Takaichiâs proposed fiscal largesse will force the BOJ to hike rates faster than currently projected to counteract the inflationary effects of government spending. This creates a two-front war on the Yen carry trade:&lt;/p&gt;
    &lt;p&gt;Cost of Funding Rises: Higher BOJ rates make borrowing Yen expensive.&lt;/p&gt;
    &lt;p&gt;Exchange Rate Risk: If the Yen appreciates due to the fiscal-monetary policy mix, the principal value of the USD-denominated assets held by Japanese investors falls in Yen terms, triggering margin calls.&lt;/p&gt;
    &lt;p&gt;The tension between the Prime Minister's office and the Ministry of Finance (MOF) adds another layer of uncertainty. Finance Minister Satsuki Katayama has been far less tolerant of currency volatility, repeatedly intervening or threatening intervention when USD/JPY approaches the 155-160 danger zone.This political friction creates a "floor" for the Yen, making shorting the currency a perilous endeavor for global macro funds.&lt;/p&gt;
    &lt;p&gt;Perhaps the most critical, yet underreported, development is the behavior of Japan's gargantuan institutional investors, specifically Norinchukin Bank (often referred to as the "CLO Whale") and Nippon Life Insurance. These entities have historically been the largest buyers of U.S. debt, recycling Japan's trade surplus into U.S. Treasuries and corporate bonds.&lt;/p&gt;
    &lt;p&gt;The data indicates a massive reversal in these flows. Following significant losses in 2024 and 2025 due to unhedged exposure to U.S. and European sovereign bonds, Norinchukin has been actively liquidating foreign assets. By the end of December 2025, the bank had unloaded nearly Â¥12.8 trillion (approximately $88 billion) in foreign government bonds.The bankâs CEO, Taro Kitabayashi, confirmed the completion of this sell-off, stating the bank would "take its time" before committing capital to fresh investments.&lt;/p&gt;
    &lt;p&gt;The significance of this cannot be overstated. A major, price-insensitive buyer of U.S. debt has left the building. When the U.S. Treasury issues debt to fund its deficit, Norinchukin is no longer the guaranteed bid. This removal of liquidity support weakens the floor for U.S. Treasuries, contributing to the yield spikes seen in January. Similarly, Nippon Life has signaled a rotation back into domestic Japanese Government Bonds (JGBs), acknowledging that "unrealized losses" on foreign bonds had swelled to Â¥4.7 trillion.The logic is simple: why take currency risk for a 4.5% U.S. yield when domestic JGB yields are rising and offer a risk-free return in your home currency?&lt;/p&gt;
    &lt;p&gt;By December 31, 2025, the stage was set. The "free money" era was over. The largest holders of capital in Tokyo were repatriating funds or moving into cash. Global markets, however, were still positioned for "business as usual", long Nvidia, long Bitcoin, short Yen. The dissonance between Japanese reality and Western positioning created the perfect conditions for a crash.&lt;/p&gt;
    &lt;p&gt;To validate the thesis that the Yen unwind is the primary driver of volatility, we must examine the sequence of events. The crash did not happen in a vacuum; it followed a precise timeline where geopolitical shocks acted as triggers for a structural fragility that had been building since the BOJ's December pivot.&lt;/p&gt;
    &lt;p&gt;The pressure began to build in Q4 2025. As the BOJ signaled its intention to hike rates, Japanese traders, often the "canary in the coal mine" for global liquidity, began to reduce risk. This cycle started with Bitcoin. Bitcoin is a pure liquidity asset; it has no yield and is often funded via margin. As the cost of Yen margin rose, Japanese selling pressure on Bitcoin intensified from October through December.This was the first tremor.&lt;/p&gt;
    &lt;p&gt;Was the "Greenland War" theater? While the military dimensions may have been performative, the economic consequences were tangible and acted as the catalyst that exposed the fragility of the Yen carry trade.&lt;/p&gt;
    &lt;p&gt;On January 17, 2026, President Trump escalated his demand to purchase Greenland by threatening a 10% tariff on eight European nations (including the UK, Germany, and France) and escalating to 25% by June if the territory was not ceded.This introduced a "tail risk" that markets had not priced: the fracture of the Atlantic economic alliance.&lt;/p&gt;
    &lt;p&gt;Following the Martin Luther King Jr. holiday, U.S. markets opened on January 20 to a bloodbath. The S&amp;amp;P 500 fell 2.1%, the Nasdaq composite dropped 2.4%, and yields on U.S. Treasuries spiked.The narrative was "Greenland," but the market mechanics told a different story. The threat of tariffs on close allies disrupts the "Atlantic Trade" narrative. For Japanese investors holding U.S. assets, this introduced a new risk premium. It wasn't just about rates anymore; it was about the stability of the U.S.-led global order. This geopolitical volatility forced risk parity funds and algorithmic traders to reduce gross exposure. When a global portfolio deleverages, it buys back its funding currency. In this case, it bought Yen.&lt;/p&gt;
    &lt;p&gt;While Trump walked back the military threat on January 21 at Davos, the economic threat of tariffs remained a live wire. The volatility persisted, suggesting that the "Greenland" narrative was merely the match that lit the fuse of a much larger powder keg.&lt;/p&gt;
    &lt;p&gt;The final and most violent phase of the crash occurred at the end of the month, triggered by the nomination of Kevin Warsh as Federal Reserve Chair.Warsh is widely perceived as a hawk, favoring sound money and skepticism toward quantitative easing. His nomination signaled the potential end of the "Fed Put", the assumption that the central bank would always intervene to support asset prices.&lt;/p&gt;
    &lt;p&gt;This announcement triggered a massive repricing of the "Debasement Trade." Assets that thrive on currency debasement, Gold, Silver, and Bitcoin, collapsed. Gold fell ~11%, and Silver crashed ~36% in a single session.This synchronization of losses across uncorrelated assets (Tech and Gold falling together) is the definitive signature of a liquidity crisis driven by margin calls.&lt;/p&gt;
    &lt;p&gt;The unwinding of a carry trade is not a monolithic event; it is a cascade that ripples outward from the most liquid and speculative assets to the core holdings of institutional portfolios. The sequence of asset price collapses observed from October 2025 to January 2026 follows this classic liquidation hierarchy perfectly.&lt;/p&gt;
    &lt;p&gt;As noted, the unwind began in the crypto markets. Japan is home to a massive retail crypto trading base, and the Yen is a major pair for Bitcoin trading. Snippets indicate that Japanese traders began selling off Bitcoin in October 2025.&lt;/p&gt;
    &lt;p&gt;This timing is crucial. It correlates with the period when the BOJ began signaling the December rate hike. Retail traders, facing higher mortgage rates and loan costs in Japan, likely liquidated their most volatile, liquid asset first to raise cash. The selling was exacerbated by the looming tax reform in Japan. While the proposal to move to a flat 20% tax rate is bullish in the long term, the immediate pressure of rising funding costs forced traders to sell before the tax cut could be realized.By January 31, massive outflows from Bitcoin ETFs ($528 million) coincided with the broader market crash, confirming that crypto was being used as a source of liquidity to cover losses elsewhere.&lt;/p&gt;
    &lt;p&gt;Consider the "painful ~3% dump" in the Nasdaq and Microsoft's staggering 15% drop. On January 29, 2026, Microsoft reported earnings. Despite beating revenue estimates ($81.27 billion vs. $80.28 billion), the stock plummeted ~11-15% intraday.&lt;/p&gt;
    &lt;p&gt;The street blamed concerns over "AI CapEx", the idea that Microsoft was spending billions on data centers with slow return on investment. However, a 15% drop in a $3 trillion company on a "good" earnings beat is rarely fundamental; it is mechanical. Microsoft is a quintessential "momentum" stock, heavily held by foreign institutional investors, including Japanese pension funds. When the Yen strengthens, the value of these USD-denominated assets falls in JPY terms.&lt;/p&gt;
    &lt;p&gt;If a Japanese insurer holds Microsoft unhedged, a falling USD/JPY exchange rate hurts their balance sheet. If they hold it hedged (rolling short USD positions), the rising U.S. rates (driven by the Warsh nomination) make the hedge prohibitively expensive. The January 29 drop was likely exacerbated by a "stop-loss" cascade from Tokyo desks. As the price broke key technical levels, algorithms programmed to protect Yen-denominated returns indiscriminately sold the most liquid blocks. Microsoft, being one of the most liquid stocks in the world, became the ATM for the rest of the portfolio.&lt;/p&gt;
    &lt;p&gt;The most compelling evidence of a forced liquidation event is the behavior of Gold and Silver on January 31, 2026. Gold fell ~11-12% and Silver crashed ~31-36% in a single session. Historically, Gold acts as a safe haven during equity market turmoil. If the Nasdaq is crashing due to "Greenland" fears, Gold should rally. Instead, it crashed.&lt;/p&gt;
    &lt;p&gt;This anomaly can be explained by two factors:&lt;/p&gt;
    &lt;p&gt;The Warsh Effect: As discussed, Warsh's nomination strengthened the USD and undermined the thesis for holding anti-fiat assets.&lt;/p&gt;
    &lt;p&gt;Margin Call Dynamics: Snippets reveal that CME Group and the Shanghai Gold Exchange raised margin requirements on gold and silver futures days before the crash.When Japanese traders faced losses on their Microsoft longs and their Yen shorts, they needed cash immediately. They couldn't sell illiquid bonds quickly enough, so they sold their "winners." Gold had rallied to ~$5,400/oz prior to the crash. Traders liquidated their profitable Gold positions to pay for the margin calls on their losing Tech and Yen positions.&lt;/p&gt;
    &lt;p&gt;Cross-Asset Correlations (Week Ending Jan 31, 2026)&lt;/p&gt;
    &lt;p&gt;This correlation breakdown is visualized in Figure 2, where the correlation between Gold and the Nasdaq 100 spikes to nearly 1.0 during the crash week, a statistical anomaly that only occurs during severe liquidity events.&lt;/p&gt;
    &lt;p&gt;The "Yen Whale" hypothesis is strongly supported by the data on futures volumes and repo market stress. The "central mystery" is not just in the price action, but in the unseen flows of the derivatives market.&lt;/p&gt;
    &lt;p&gt;About a week ago, some whale kicked off an astronomically large market order for a /6J long when it hit recent lows. /6J (CME Yen Futures) hit a low of ~0.00647 (approximately 154.50 USD/JPY) in late January. This level has historically been a "line in the sand" for the Japanese Ministry of Finance (MOF).&lt;/p&gt;
    &lt;p&gt;CME reported record volumes in FX and Interest Rate products for January 2026.The aggressive buying off the lows suggests a massive repatriation flow. Who is the Whale? Two theories emerge:&lt;/p&gt;
    &lt;p&gt;The MOF Thesis: The Ministry of Finance has a history of stealth intervention. Buying /6J (Long Yen) is functionally equivalent to selling USD reserves. Buying futures allows them to support the currency without immediately depleting cash reserves, squeezing speculators who are short.&lt;/p&gt;
    &lt;p&gt;The Carry Unwind: A massive hedge fund or bank (like Norinchukin) realizing that the "game is up" and closing out short-Yen positions. The size of the order suggests an entity that needed to move billions, not millions.&lt;/p&gt;
    &lt;p&gt;The subsequent price action, a sharp rally followed by "hammering back down", represents the battleground. U.S. macro funds are still trying to short the Yen (betting on U.S. economic exceptionalism and Warsh's policies), while Japanese domestic accounts are buying it. The volatility is the result of these tectonic plates grinding against each other.&lt;/p&gt;
    &lt;p&gt;The plumbing of the U.S. financial system showed signs of stress that coincided with the Japanese retreat. The Overnight Reverse Repo facility (ON RRP) saw a year-end spike to $106 billion but has since drained.&lt;/p&gt;
    &lt;p&gt;Japanese banks are typically huge participants in the U.S. repo market to fund their dollar assets. As Norinchukin and others retreat (repatriating funds to Japan), liquidity in the U.S. repo market becomes thinner. The "air pocket" in Microsoft and Gold prices was likely exacerbated by a lack of market maker depth in the repo-funded derivatives market. When market makers cannot access cheap repo funding, they widen spreads and reduce liquidity provision, leading to "gaps" in price action during sell-offs.&lt;/p&gt;
    &lt;p&gt;There have been significant moves in other currency futures as well: /6A increased 87 basis points, /6L rose 19 basis points, and /6S rose 18 basis points.&lt;/p&gt;
    &lt;p&gt;/6A (Australian Dollar): The 87 basis point rise in the Aussie Dollar is notable. AUD is often a proxy for Chinese growth and global risk sentiment. A rise here, amidst a tech crash, suggests a rotation out of U.S. assets and into commodities or Asia-Pacific currencies, further supporting the "Sell America" thesis triggered by the Greenland tariff threats.&lt;/p&gt;
    &lt;p&gt;/6L (Brazilian Real) and /6S (Swiss Franc): The rise in the Swiss Franc (a classic safe haven) aligns with the risk-off sentiment. The move in the Brazilian Real suggests that emerging markets are also seeing volatile flows as the dollar stabilizes.&lt;/p&gt;
    &lt;p&gt;Why was the VIX at 16 despite the chaos? The VIX measures implied volatility of S&amp;amp;P 500 options. Its relatively low level (16) compared to the violence in individual names (MSFT -15%, Gold -11%) indicates that the crash is a de-leveraging event, not a panic event.&lt;/p&gt;
    &lt;p&gt;In a panic, investors buy Puts on the index to protect themselves, spiking the VIX. In a de-leveraging event, investors simply sell the underlying assets (stocks, gold, crypto) to raise cash. They are not hedging; they are exiting. This explains why the VIX remained subdued while prices collapsed, the selling was orderly, algorithmic, and relentless, rather than emotional and panicked.&lt;/p&gt;
    &lt;p&gt;Skepticism about the "Greenland War" is well-founded. While the diplomatic row was real, its utility as a financial narrative was far greater than its geopolitical reality.&lt;/p&gt;
    &lt;p&gt;President Trump's threat of military force was retracted on January 21 at Davos.This "de-escalation" should theoretically have calmed markets. Instead, the volatility worsened into month-end. This confirms that the real problem wasn't Greenland; it was the re-pricing of the Yen.&lt;/p&gt;
    &lt;p&gt;The financial media loves a simple cause-and-effect narrative. "Stocks down because of War" is easy to digest. "Stocks down because the cross-currency basis swap spread widened due to BOJ minutes" is not. The "Greenland" narrative provided the perfect cover for sophisticated actors to liquidate positions in Gold and Tech under the guise of "war jitters." This allowed them to exit without sparking a broader panic about liquidity in the banking system. The focus on the Arctic masked the structural rot in the leverage complex.&lt;/p&gt;
    &lt;p&gt;The evidence suggests a covert, structural unwinding of the Yen carry trade is the primary driver of the January 2026 market chaos.&lt;/p&gt;
    &lt;p&gt;The interconnectedness of these events is undeniable. The BOJ's rate hike in December 2025 and the subsequent hawkish signaling from the Takaichi administration fundamentally altered the cost of capital for the world's largest carry trade. The "Greenland Crisis" acted as the initial volatility trigger, forcing a reduction in gross exposure. The nomination of Kevin Warsh acted as the final catalyst, shattering the "Debasement Trade" and forcing a liquidation of precious metals and crypto to cover margin calls on Yen-funded positions.&lt;/p&gt;
    &lt;p&gt;Here are some key takeaways:&lt;/p&gt;
    &lt;p&gt;The "Free Money" Era is Over: BOJ policies have fundamentally altered the global cost of capital. The flow of liquidity from Tokyo to New York has reversed.&lt;/p&gt;
    &lt;p&gt;Geopolitics as Catalyst: "Greenland" may have been the spark, but the Yen leverage was the powder keg. The tariff threats disrupted the "Atlantic Trade" narrative, forcing a repatriation of capital.&lt;/p&gt;
    &lt;p&gt;Liquidity Event: The synchronized crash of Gold, Crypto, and Tech confirms a systemic de-leveraging. The "Whale" orders in Yen futures and the breakdown of correlations are the smoking guns of a margin-driven event.&lt;/p&gt;
    &lt;p&gt;With the Japanese election on February 8 and U.S. tariffs looming, the "hammering" of the Yen is likely temporary. The structural trend is now toward repatriation. This implies lower U.S. asset prices, higher U.S. yields, and a stronger Yen over the medium term. The "mystery" of the low VIX is explained by the mechanical nature of the unwind, a controlled demolition of leverage rather than a chaotic panic.&lt;/p&gt;
    &lt;p&gt;This won't just be the big one. This could be the last one. If you've been preparing your whole life, knowing that something's coming, then this could be the thing you've been preparing for. One final opportunity to get the guys who did this.&lt;/p&gt;
    &lt;p&gt;Longing the Yen is commonly referred to as "The Widowmaker Trade" on Wall Street, because you have trillions of dollars of monopoly money working against you. The carry traders have compromised every level of our government. Their greatest vulnerability is the Yen rising in value. They will do anything to defend their positions, even if that means bringing America's economy down with them. Since recent events have made it obvious they're going to lose, we might as well fight them. Most of us probably won't make it out of this fight. But if we at least try, then there's a chance we might prosper when it's over.&lt;/p&gt;
    &lt;p&gt;The IV on OTM CME /6J futures calls is 11% which is astonishingly low. The same is true for calls on the FXY ETF. Call options have defined risk. The more Yen we control, the more its value goes up, and the more crooks on Wall Street get liquidated. The worst that can happen is you lose your monopoly money, but that's been happening anyway. Since carry traders own 10% of all U.S. treasuries, when they get liquidated they'll have to sell a lot of treasury bonds, which means that CME /UB futures and the TLT ETF will fall.&lt;/p&gt;
    &lt;p&gt;This blog is brought to you by various radicals, malcontents, and people who think the system is rigged. We're not affiliated with any organization. Nothing here constitutes financial advice. Occupy Wall Street is not your financial advisor or your lawyer. We're retail investors like you. Do your own research. Past performance does not guarantee future results. We are the 99 percent. The only solution is world revolution. Wall Street's time has finally come.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46889008</guid><pubDate>Wed, 04 Feb 2026 17:49:26 +0000</pubDate></item><item><title>Claude Code for Infrastructure</title><link>https://www.fluid.sh/</link><description>&lt;doc fingerprint="8660c4598e99ff8b"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Built for where you already work&lt;/head&gt;
    &lt;head rend="h3"&gt;Sandbox Isolation&lt;/head&gt;
    &lt;p&gt;Clone VMs instantly. Test changes in isolation before touching production.&lt;/p&gt;
    &lt;head rend="h3"&gt;Context-Aware&lt;/head&gt;
    &lt;p&gt;Fluid explores your host first - OS, packages, CLI tools - then adapts.&lt;/p&gt;
    &lt;head rend="h3"&gt;Full Audit Trail&lt;/head&gt;
    &lt;p&gt;Every command logged. Every change tracked. Review before production.&lt;/p&gt;
    &lt;head rend="h3"&gt;Ansible Playbooks&lt;/head&gt;
    &lt;p&gt;Auto-generates playbooks from sandbox work. Reproducible infrastructure.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46889703</guid><pubDate>Wed, 04 Feb 2026 18:34:08 +0000</pubDate></item><item><title>Why more companies are recognizing the benefits of keeping older employees</title><link>https://longevity.stanford.edu/why-more-companies-are-recognizing-the-benefits-of-keeping-older-employees/</link><description>&lt;doc fingerprint="7ea1e07b6bc806ab"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;DEEP DIVE&lt;/head&gt;
    &lt;head rend="h3"&gt;Why More Companies Are Recognizing the Benefits of Keeping Older Employees&lt;/head&gt;
    &lt;p&gt;By Annie Coleman&lt;/p&gt;
    &lt;p&gt;Although age bias is still the norm, the value-add of longtime, experienced workers is beginning to take shape.&lt;/p&gt;
    &lt;p&gt;On the outskirts of Macclesfield, in northwest England, a branch of the UK home-improvement retailer B&amp;amp;Q quietly overturned one of corporate life’s most persistent assumptions. Faced with high staff turnover and uneven customer satisfaction, the company tried a simple experiment: In 1989, it staffed the store largely with older workers.&lt;/p&gt;
    &lt;p&gt;The results were striking, according to one study. Profits rose 18 percent. Staff turnover fell to a fraction of the company average. Absenteeism dropped sharply. An experiment that started more than 30 years ago reshaped how the retailer approached age inclusiveness and led B&amp;amp;Q to open training to all ages and feature older workers in advertising, treating experience as an advantage rather than a cost.&lt;/p&gt;
    &lt;p&gt;In 2007, BMW began implementing 70 ergonomic, low-cost improvements in a specialized assembly line in Dingolfing, Germany, to provide better conditions for its many older and middle-aged workers. Key changes included adjustable-height workstations, improved lighting and specialized stools, resulting in a 7 percent productivity increase.&lt;/p&gt;
    &lt;p&gt;Evidence suggests that similar age-performance dynamics are not limited to the quirks of retail or to the factory floor and are increasingly relevant as declining birth rates and artificial intelligence investments reduce the inflow of entry-level workers. A white paper from Bank of America’s Workplace Benefits group argues that recruiting and retaining older workers is becoming increasingly important as populations age, framing age-inclusive benefits not as accommodation, but as a driver of organizational performance, especially for roles where judgment, experience and decision quality matter most.&lt;/p&gt;
    &lt;p&gt;“The retention of these older workers is an idea that is becoming much more well-received,” says Cynthia Hutchins, Bank of America’s inaugural director of financial gerontology. Hutchins has been involved in implementing a workforce longevity policy that includes hybrid schedules, financial planning benefits, menopause support, grandparents’ leave and sabbaticals. “It’s almost a business imperative to institute those types of benefits” to retain older workers and attract younger ones, adds Hutchins.&lt;/p&gt;
    &lt;p&gt;Yet initiatives such as these are rarely framed as strategy or as signals of a deeper shift. Most corporations continue to design careers as if effectiveness peaks early — as if speed, stamina and innovation belong exclusively to the young. If experience improves outcomes, why are so many organizations structured to push people out just as their value peaks?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;If experience improves outcomes, why are so many organizations structured to push people out just as their value peaks?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;The Albatross or the Wise Man&lt;/head&gt;
    &lt;p&gt;At the heart of corporate resistance lies a fundamental disagreement about value. Moody’s Analytics chief economist Mark Zandi framed the debate in Aging and the Productivity Puzzle, a 2018 analysis delineating two schools of thought. The “albatross theory” holds that workers above the age of 65 drag down productivity due to resistance to change and outdated skills. The “wise man theory” tells a different story: of workers who possess judgment, institutional knowledge, emotional intelligence and expertise that younger employees cannot replicate.&lt;/p&gt;
    &lt;p&gt;Zandi and his colleagues analyzed state-level ADP data in the U.S. and concluded that post-retirement-age workers slowed wage growth and productivity, largely because they tend to be averse to adopting new technologies. Yet several major institutions reject the idea that older workers are a productivity “albatross” — and most look at the effects, not of those above the age of 65, but of the 50-plus age workforce, often the first in line for layoffs.&lt;/p&gt;
    &lt;p&gt;More recent research from AARP and the OECD shows that firms with more 50-plus workers are more productive, not less: a 10-percentage-point increase in older workers is associated with roughly 1.1 percent higher productivity. The 2020 OECD analysis also finds that age-balanced firms benefit from lower turnover and stronger team performance, driven by experience and knowledge sharing rather than technology resistance. Similarly, a 2022 study from Boston Consulting Group found that cross-generational teams outperform homogeneous ones when older workers’ judgment and mentoring are combined with younger workers’ digital skills. A 2022 meta analysis also pushes back against the idea that older workers are less effective, and found that teams perform better when members have a long tenure at the company, irrespective of workers’ ages.&lt;/p&gt;
    &lt;p&gt;Still, Zandi says that the value of older workers may depend on how AI in the workplace unfolds and what impact it has on productivity growth. “If AI turns out to be a bust or doesn’t live up to expectations, and you have other demographic forces that are restraining labor growth, then I think older workers should fare well,” Zandi says. He notes that so far, older workers have “navigated things reasonably gracefully,” while younger workers and mid-level managers are so far taking the brunt of AI-related impacts. &lt;/p&gt;
    &lt;head rend="h3"&gt;People Peak Later Than We Think&lt;/head&gt;
    &lt;p&gt;Population aging is often treated as a future problem, something to be managed later with technology or policy tweaks. In reality, it is already reshaping labor markets in the U.S. and across advanced economies. Birth rates are lower, people are living longer and the share of workers above the age of 50 is rising steadily. This is not a forecast. It is arithmetic.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Across advanced economies, there appears to be a persistent pattern of early exits that are less about individual choice than organizational design.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Yet organizational assumptions about performance have not kept pace. Modern careers are still built around the idea that effectiveness peaks early. Recent research challenges that view. A 2025 study in the journal Intelligence, analyzing age trajectories across 16 cognitive, emotional and personality dimensions, finds that while processing speed does decline after early adulthood, many of the capabilities most relevant to complex work continue to improve well into midlife. When these traits are combined into a composite measure of overall functioning, performance peaks between ages 55 and 60.&lt;/p&gt;
    &lt;p&gt;But if proficiency increasingly peaks in late midlife, then why are so many careers ending before they can be fully realized? Across advanced economies, there appears to be a persistent pattern of early exits that are less about individual choice than organizational design.&lt;/p&gt;
    &lt;p&gt;In the U.S., analysis by the Urban Institute of survey data of older workers from 1992 to 2016 showed that more than half above the age of 50 were pushed out of long-held jobs before they chose to retire, often through layoffs or restructuring rather than performance issues. The 2018 study — along with reporting from ProPublica — found that few ever regained comparable pay or responsibility, and hiring practices reinforced the trend.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The fact that more than half of U.S. workers above the age of 50 leave long-held jobs for reasons unrelated to performance and before they choose to retire is a systemic design failure.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Bill Greene, a longtime business consultant, is an exception to this layoff trend. Hired at 64 as principal of Mind Share Partners, a nonprofit in San Francisco, he advises companies on the importance of creating mentally healthy environments, and cautions that the workplace is a minefield of biases — and that ageism cuts both ways for older workers and younger workers.&lt;/p&gt;
    &lt;p&gt;Greene advises employers to be aware of the blind spots and inconsistencies. In the technology industry, he says, “it’s widely perceived that if you are 45 years old or over, you are a dinosaur,” yet in politics, “you can be 70, 75, 80, 85, and apparently that’s OK.”&lt;/p&gt;
    &lt;p&gt;Experience helps in an emergency. When the Covid-19 pandemic struck in 2020, Greene was consulting for a financial services firm, and he saw firsthand how worried his client was that younger employees were going to panic and quit because they hadn’t been through a crisis of that magnitude before.&lt;/p&gt;
    &lt;p&gt;“They realized that they had to coach their younger employees,” he says, comparing the pandemic to the 2008 financial crash to help the client’s staff understand the risks and path forward. “That kind of wisdom and experience can come with more depth of understanding and perspective from an older employee than from a younger one,” he says.&lt;/p&gt;
    &lt;head rend="h3"&gt;Small-Scale Experiments Miss an Urgent Challenge&lt;/head&gt;
    &lt;p&gt;Although several Fortune 500 companies have advertised their interest in hiring and retaining older workers, corporate commitments remain tentative and small-scale. UK-based Unilever launched its U-Work program in 2019, and now offers employees in nine countries a hybrid between traditional employment and gig work: a monthly retainer, benefits and freedom to choose which projects they work on and when. Workers can scale back hours, pursue other interests or transition gradually toward retirement.&lt;/p&gt;
    &lt;p&gt;The program is innovative and, by all accounts, successful. Half of participants are above the age of 50. But only 140 employees out of Unilever’s 150,000-strong global workforce participate. This raises a question: Are these strategies of genuine transformation or sophisticated public relations?&lt;/p&gt;
    &lt;p&gt;Three converging forces make the case for urgency. First, premature exit creates value leakage. The fact that more than half of U.S. workers above the age of 50 leave long-held jobs for reasons unrelated to performance and before they choose to retire is a systemic design failure.&lt;/p&gt;
    &lt;p&gt;Second, the demand-side blind spot. Globally, spending by people above the age of 55 is projected to approach $15 trillion annually by the end of this decade, making older consumers one of the largest and fastest-growing sources of demand in the world economy. Yet many companies treat older customers as peripheral.&lt;/p&gt;
    &lt;p&gt;There are exceptions. Alan Patricof, now 91 and still investing, launched Primetime Partners at 85 after observing that venture capital remained focused on millennials, despite obvious unmet demand among older adults. His fund has invested in more than 35 companies serving what he calls the “ageless market.” Consumer brands are adapting, too — L’Oréal has repositioned itself around longevity and healthy aging, treating later life as aspiration rather than decline.&lt;/p&gt;
    &lt;p&gt;The silver economy is not a niche. It is one of the largest and least contested growth opportunities of the next decade — and one that many firms still underestimate.&lt;/p&gt;
    &lt;p&gt;Third, longer working lives are inevitable. In Europe and the UK, effective retirement ages have been climbing, driven in part by financial need and policy changes. Meanwhile, in the U.S., the shift from defined-benefit to defined-contribution retirement plans incentivizes workers to remain employed longer. Organizations that fail to retain experienced talent will face labor shortages, while competitors benefit from workers who bring judgment, stability and institutional memory.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Role of Investors, C-Suites and Boards&lt;/head&gt;
    &lt;p&gt;The mismatch between demographic reality and corporate behavior is beginning to register with long-term investors. Large asset managers increasingly frame longevity as a structural economic force with implications for growth, productivity and risk.&lt;/p&gt;
    &lt;p&gt;A Vanguard study, The Economics of a Graying World, highlights aging and slower labor-force growth as a persistent drag on economic expansion, arguing that longer working lives are one of the few viable adjustment mechanisms. From this perspective, workforce age policy becomes financially material, not optional.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;When organizations push experienced workers out early, they forfeit peak judgment, execution capability and mentoring capacity.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Economist Andrew J. Scott of the London Business School argues in his 2024 book The Longevity Imperative that if societies see longevity primarily as an “aging problem” of more pensioners, higher health costs and fewer workers, longer lives risk becoming a fiscal drag. But if they invest in health, skills and age‑inclusive work, longevity can instead raise growth, employment and innovation.&lt;/p&gt;
    &lt;p&gt;One hurdle to this shift in perspective is an ongoing lack of transparency and accountability by employers. Ageism in hiring, promotion and redundancy remains widespread, yet unlike gender or ethnicity, workforce age is rarely disclosed or scrutinized. The result is a growing governance gap. Misalignment with demographic reality creates execution risk — in talent, productivity and growth.&lt;/p&gt;
    &lt;p&gt;The case for a longevity strategy is ultimately an economic one. When organizations push experienced workers out early, they forfeit peak judgment, execution capability and mentoring capacity. When they underinvest in older consumers, they leave vast pools of demand underserved. Value is forfeited on both sides of the business.&lt;/p&gt;
    &lt;p&gt;In meeting their responsibility for long-term risk and growth, companies should begin with clarity. Map the age profile of the workforce by role and seniority. Identify where people in their fifties and early sixties are exiting — and whether those exits reflect performance or design. Treat age as a strategic variable in the same way firms now treat gender, skills or succession risk.&lt;/p&gt;
    &lt;p&gt;From there, redesign follows. Build roles and career paths that assume longer working lives. Invest in mid- and late-career reskilling, not as remediation but as renewal. Structure intergenerational teams deliberately, so experience and speed compound rather than collide. Align product, service and brand strategy with the realities of an aging, wealthier customer base.&lt;/p&gt;
    &lt;p&gt;None of this is about altruism. It is about reclaiming value currently being left on the table. As populations age, companies that learn to retain experience and serve longevity-driven demand will not just adapt — they will outperform.&lt;/p&gt;
    &lt;p&gt;Annie Coleman is Founder of RealiseLongevity, a consulting firm based in the UK, and is a Stanford Center on Longevity Ambassador.&lt;/p&gt;
    &lt;head rend="h3"&gt;KEEP READING&lt;/head&gt;
    &lt;p&gt;FIVE QUESTIONS&lt;lb/&gt; Bruce Feiler on Mastering Life Transitions at Any Age&lt;lb/&gt; ALT/SHIFT&lt;lb/&gt; How Much Health Data is Too Much?&lt;lb/&gt; FINANCING LONGER LIVES&lt;lb/&gt; Retirement Income Gap Sparks Innovation&lt;lb/&gt; DEEP DIVE&lt;lb/&gt; The Longevity Imperative: Why More Companies Are Recognizing the Benefits of Keeping Older Employees&lt;lb/&gt; GRANDPEOPLE&lt;lb/&gt; Soufflé Chef Takes her Final Bow at 90&lt;lb/&gt; FROM THE EDITOR&lt;lb/&gt; LONGEVITY LITERACY&lt;lb/&gt; Multiomics&lt;lb/&gt; GAME CHANGER&lt;lb/&gt; An Ultrasound Helmet to Cleanse the Brain&lt;lb/&gt; @SCL:&lt;lb/&gt; SCL at World Economic Forum&lt;lb/&gt; Call for Case Study Submissions&lt;lb/&gt; Longevity Design Challenge Finals&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46893411</guid><pubDate>Wed, 04 Feb 2026 23:26:23 +0000</pubDate></item><item><title>OpenClaw is what Apple intelligence should have been</title><link>https://www.jakequist.com/thoughts/openclaw-is-what-apple-intelligence-should-have-been</link><description>&lt;doc fingerprint="35ccf94d3962955c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;OpenClaw is What Apple Intelligence Should Have Been&lt;/head&gt;
    &lt;p&gt;Something strange is happening with Mac Minis. They’re selling out everywhere, and it’s not because people suddenly need more coffee table computers.&lt;/p&gt;
    &lt;p&gt;If you browse Reddit or HN, you’ll see the same pattern: people are buying Mac Minis specifically to run AI agents with computer use. They’re setting up headless machines whose sole job is to automate their workflows. OpenClaw—the open-source framework that lets you run Claude, GPT-5, or whatever model you want to actually control your computer—has become the killer app for Mac hardware. Not Final Cut. Not Logic. An AI agent that clicks buttons.&lt;/p&gt;
    &lt;p&gt;This is exactly what Apple Intelligence should have been.&lt;/p&gt;
    &lt;p&gt;Apple had everything: the hardware, the ecosystem, the reputation for “it just works.” They could have shipped an agentic AI that actually automated your computer instead of summarizing your notifications. Imagine if Siri could genuinely file your taxes, respond to emails, or manage your calendar by actually using your apps, not through some brittle API layer that breaks every update.&lt;/p&gt;
    &lt;p&gt;They could have charged $500 more per device and people would have paid it. The margins would have been obscene. And they would have won the AI race not by building the best model, but by being the only company that could ship an AI you’d actually trust with root access to your computer. That trust—built over decades—was their moat.&lt;/p&gt;
    &lt;p&gt;So why didn’t they?&lt;/p&gt;
    &lt;p&gt;Maybe they just didn’t see it. That sounds mundane, but it’s probably the most common reason companies miss opportunities. When you’re Apple, you’re thinking about chip design, manufacturing scale, and retail strategy. An open-source project letting AI agents control computers might not ping your radar until it’s already happening.&lt;/p&gt;
    &lt;p&gt;Or maybe they saw it and decided the risk wasn’t worth it. If you’re Apple, you don’t want your AI agent automatically buying things, posting on social media, or making irreversible decisions. The liability exposure would be enormous. Better to ship something safe and limited than something powerful and unpredictable.&lt;/p&gt;
    &lt;p&gt;But there’s another dynamic at play. Look at who’s about to get angry about OpenClaw-style automation: LinkedIn, Facebook, anyone with a walled garden and a careful API strategy. These services depend on friction. They want you to use their app, see their ads, stay in their ecosystem. An AI that can automate away that friction is an existential threat.&lt;/p&gt;
    &lt;p&gt;If Apple had built this, they’d be fighting Instagram over ToS violations by Tuesday. They’d be testifying in front of Congress about AI agents committing fraud. Every tech platform would be updating their terms to explicitly ban Apple Intelligence.&lt;/p&gt;
    &lt;p&gt;By letting some third party do it, Apple gets plausible deniability. They’re just selling hardware. Not their fault what people run on it. It’s the same strategy that made them billions in the App Store while maintaining they’re “not responsible for what developers do.”&lt;/p&gt;
    &lt;p&gt;But I think this is short-term thinking.&lt;/p&gt;
    &lt;p&gt;Here’s what people miss about moats: they compound. The reason Microsoft dominated PCs wasn’t just that they had the best OS. It’s that everyone built for Windows, which made Windows more valuable, which made more people build for Windows. Network effects.&lt;/p&gt;
    &lt;p&gt;If Apple owned the agent layer, they could have created the most defensible moat in tech. Because an AI agent gets better the more it knows about you. And Apple already has all your data, all your apps, all your devices. They could have built an agent that works across your iPhone, Mac, iPad, and Watch seamlessly—something no one else can do.&lt;/p&gt;
    &lt;p&gt;More importantly, they could have owned the API. Want your service to work with Apple Agent? You play by Apple’s rules. Suddenly Apple isn’t fighting with platforms—they’re the platform that platforms need to integrate with. It’s the App Store playbook all over again, but for the AI era.&lt;/p&gt;
    &lt;p&gt;The Mac Mini rush is a preview of this future. People want agents. They want automation. They want to pay for it. They’re literally buying extra computers just to run someone else’s AI on Apple’s hardware.&lt;/p&gt;
    &lt;p&gt;Apple is getting the hardware revenue but missing the platform revenue. That might look smart this quarter. But platform revenue is what built Apple into a $3 trillion company. And platforms are what create trillion-dollar moats.&lt;/p&gt;
    &lt;p&gt;I suspect ten years from now, people will look back at 2024-2025 as the moment Apple had a clear shot at owning the agent layer and chose not to take it. Not because they couldn’t build it—they obviously could—but because they were optimizing for this year’s legal risk instead of next decade’s platform power.&lt;/p&gt;
    &lt;p&gt;The people buying Mac Minis to run AI agents aren’t just early adopters. They’re showing Apple exactly what product they should have built. Whether Apple is paying attention is another question entirely.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46893970</guid><pubDate>Thu, 05 Feb 2026 00:28:06 +0000</pubDate></item><item><title>Wirth's Revenge</title><link>https://jmoiron.net/blog/wirths-revenge/</link><description>&lt;doc fingerprint="abcad51e692325f9"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Wirth's Revenge&lt;/head&gt;
    &lt;p&gt;In 1995, Turing laureate Niklaus Wirth wrote an essay called A Plea for Lean Software in which he mostly gripes about the state of software at the time. Among these gripes is this claim which Wirth attributes to his colleague Martin Reiser1, though it's become to be known as Wirth's Law:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Software is getting slower more rapidly than hardware becomes faster.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Doing his best grandpa Simpson impersonation, Wirth complains:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;About 25 years ago, an interactive text editor could be designed with as little as 8,000 bytes ofstorage. (Modern program editors request 100 times that much!) An operating system had to manage with 8,000 bytes, and a compiler had to fit into 32 Kbytes, whereas their modern descendants require megabytes. Has all this inflated software become any faster? On the contrary. Were it not for a thousand times faster hardware, modern software would be utterly unusable.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Aside from the numbers involved here, which must sound utterly preposterous to the average modern reader, there's a lot to relate to. My 25 year career in software, all of which happened after 1995, was in many ways a story in two parts about Wirth's Law, an action and a reaction.&lt;/p&gt;
    &lt;p&gt;Personally, I disagree with Wirth's conclusion that nothing of value had been gained for the loss in efficiency. When he laments "the advent of windows, cut-and-paste strategies, and pop-up menus, [..] the replacement of meaningful command words by pretty icons", he is not properly appreciating the value these features had in making computing accessible to more people, and is focusing too much on their runtime cost. Programmers are often too quick to judge software on its technical merits rather than it's social ones.&lt;/p&gt;
    &lt;p&gt;Wirth passed away 2 years ago, but he was a giant in the field of Computer Science and a huge inspiration to me and to many of my other inspirations. In many ways, my focus on simplicity and my own system design sensibilities find their genesis with him.&lt;/p&gt;
    &lt;p&gt;Wirth's law is so self evidently true that it's been a topic of continuous investigation and rediscovery.&lt;/p&gt;
    &lt;p&gt;A notable example of this was Dan Luu's great post on input lag back in 2017. He felt that input latency was getting worse over time, so he got a high speed camera and measured the delay between pressing a key and the letter appearing on screen across a lot of different hardware. The lowest latency computer was the Apple 2e from 1983.&lt;/p&gt;
    &lt;p&gt;Input latency has gone up since 1983 because there is a lot more software involved in the pipeline for handling input. The kind of hardware interrupt based input handling the Apple 2e had is not flexible enough to meet modern requirements, so this additional complexity buys us a lot of value... but it's certainly not free, and if you're not careful, one of the costs is latency.&lt;/p&gt;
    &lt;p&gt;Luu goes on to write a lot about complexity and simplicity, and makes an interesting observation: the modern systems that fix the latency issue mostly do so not through removing complexity but by adding it. There was a lot of talk about complexity and simplicity at the time, because a huge number of software developers were working on another great tradeoff that had been made, this time in the datacenter: the widespread adoption of cloud computing.&lt;/p&gt;
    &lt;p&gt;In 1995, when Wirth wrote his essay, if you wanted to run a new internet company, you could just get a computer and run with it. Amazon didn't launch until July of that year, but it was famously started out of Jeff Bezos' garage.&lt;/p&gt;
    &lt;p&gt;The requirements for an internet company were simpler back then. The web wasn't some ubiquitous technology with total population penetration. There were only about 16 million people using it at the time; more people had an SNES than used the internet. Slashdot didn't exist. There was no real expectation of 5 9's 24/7/365 availability, and no opportunity to "go viral."&lt;/p&gt;
    &lt;p&gt;By 2010, this had changed. Sure, I guess you could still get Slashdotted then, but more relevantly, Twitter and Facebook could drive tons of traffic to you overnight. The number of internet users had ballooned to 2 billion.&lt;/p&gt;
    &lt;p&gt;To run your company's software, you could build your own datacenter, but this is a complicated task requiring a lot of expertise; you need land, permits, contractors, etc. I wouldn't even know where to start.&lt;/p&gt;
    &lt;p&gt;You could buy an existing datacenter, but you'd still need to manage power, backup generators/batteries, air conditioning, fire suppression, racks, maintenance, networking. Again, decades in the software industry, and I can barely build a competent list of requirements. It's a big investment, and there's a lot of opex.&lt;/p&gt;
    &lt;p&gt;You could rent a rack in a colo and focus on your compute needs, but those needs could change in an instant. If you plan out costs for 100,000 users and you never gain traction, you've overspent and are burning cash on pointless hardware you could be using to develop your product. If you get hit with a tidal wave of interest, you could be showing people the fail whale for years or miss your opportunity for success entirely.&lt;/p&gt;
    &lt;p&gt;Cloud computing was the era's answer. By 2010, Amazon was out of Jeff's basement and running its own massive datacenters for their online operations. As Steve Yegge wrote in 2010, Bezos had distributed an influential API mandate in 2002 requiring all internal teams to make their services available via an API. By 2006, they had already built a platform that they felt they could release to paying customers in the form of EC2 and S3. AWS let you rent capacity in Amazon's datacenter through a web interface or via direct API calls, billed on granular timescales.&lt;/p&gt;
    &lt;p&gt;Each step in this pipeline imparts additional cost, but they're all pretty valuable, especially the last step. There are even more steps in that pipeline today, with fully managed services like RDS and IAM which abstract the management of software and Lambda which even further abstract your hardware requirements and allow you to scale (and pay) purely on utilization.&lt;/p&gt;
    &lt;p&gt;Even though the cost to run software had gone up, the improved accessibility of cloud platforms and the reduction of risky capex led to an explosion in web software. All the while, hardware was racing ahead, making the rented capacity more powerful per unit cost and reducing the per-user cost.&lt;/p&gt;
    &lt;p&gt;Unfortunately, not every "Wirth tradeoff" is sound engineering.&lt;/p&gt;
    &lt;p&gt;Early in my career, I was working at a newspaper publisher owned by Condé Nast. I was the lead engineer on one of the company's more forward looking development projects, a Django application that managed local sports results data across dozens of regional newspapers. The application provided a single source of truth for very different users and use cases:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reporters could add box scores and statistics on the go&lt;/item&gt;
      &lt;item&gt;Their websites could display results, league tables, etc.&lt;/item&gt;
      &lt;item&gt;The backend could publish feeds to syndicate into the print editions of each newspaper&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The print syndication system involved writing some pretty gnarly templates in order to generate feeds that could be understood by their newspaper printing systems. After a while, we noticed a problem. These templates were taking minutes to render and setting the database on fire every night.&lt;/p&gt;
    &lt;p&gt;If you've been around the block in software, you might already know the issue. The templates were using an ORM which dynamically loaded foreign key fields on attribute access, so innocent looking loops were doing one database query per iteration. These were complex templates with many nested loops: they were sending hundreds of thousands of database queries per render, many of them just the same query over and over again from a different loop in a different part of the template.&lt;/p&gt;
    &lt;p&gt;We could fix some of the terrible performance by pre-loading those fields with a join, but we had a lot of templates, and they were complex enough and the database large enough that this wasn't a realistic path to success. As Dan Luu concludes in his study on latency, the solution that worked required adding more complexity in the form of a smart caching layer.&lt;/p&gt;
    &lt;p&gt;Although we didn't know we were making it when we started the template project, this was a "bad" Wirth tradeoff. It still had utility: instead of having to manage what data might be needed in what template carefully, we could grab a list of top level objects and let the ORM fetch the rest of the data we needed on the fly.&lt;/p&gt;
    &lt;p&gt;The project started up quickly, but even at a pretty low scale of complexity, it became impossible to execute successfully. Before we realized what the problem was, we were using the convenience of these auto-loaded fields without understanding their true cost, and the software we built was a wasteful monstrosity as a result.&lt;/p&gt;
    &lt;p&gt;I see the same thing happening now but at broader scale with LLMs, and I feel myself sympathizing more and more with Wirth's cane shaking wrath.&lt;/p&gt;
    &lt;p&gt;Programming is the act of getting a computer to do something for you. Many people are discovering that for the first time, thanks to LLMs, they can ask a computer to do something for them, and it will actually go and do it. However, limiting yourself to programming only through this approach poses some problems.&lt;/p&gt;
    &lt;p&gt;While they might not be the unbound ecological disaster that many of their detractors claim they are, LLMs are still intensely computationally expensive. You can ask an AI what &lt;code&gt;2 * 3&lt;/code&gt; is and for the low price of several seconds of waiting, a few milliliters of water and enough power to watch 5% of a TikTok video on a television, it will tell you. But the computer you have in front of you can perform this calculation a billion times per second.&lt;/p&gt;
    &lt;p&gt;If the problem of my accidental database denial of service syndication feed was down to ignorance over the costs of ORM usage, it's pretty obvious that a similar kind of ignorance can lead to enormous unintended costs once we start integrating LLMs into our automation.&lt;/p&gt;
    &lt;p&gt;I've seen a few instances of this out in the wild that lead me to believe that this trap might be particularly tricky to avoid. Despite the capacity for LLMs to educate, or simulate education, or at least point you towards related materials some of which may be real, that's not how laypeople use them.&lt;/p&gt;
    &lt;p&gt;They present the LLM with a problem and ask it solve that problem.&lt;/p&gt;
    &lt;p&gt;One example of this is from myself, as this is how I used LLMs in my first go, too. I had a dump of recipes from a great but sadly unmaintained recipe site that I wanted to import into a self-hosted recipe management app.&lt;/p&gt;
    &lt;p&gt;I thought "Well, this sounds tedious, let me ask an LLM to do this." So I pointed a local LLM to the specification for the destination format, and asked it to convert the files. It converted one file every 10 minutes, inaccurately and without proper formatting. It was slow and it produced trash.&lt;/p&gt;
    &lt;p&gt;When you see engineers heap praise on programming agents, this isn't how they are using them. You don't ask the LLM to perform a repetitive and precise task, you ask it to build a script that performs that task. Except in rare cases, this script does not itself use LLMs.&lt;/p&gt;
    &lt;p&gt;Ironically, if you have the foresight to describe this problem to a major AI model and ask it how you should use an AI to solve it, this is exactly what it will tell you to do.&lt;/p&gt;
    &lt;p&gt;This approach subtly different from the way you might use LLMs for many other tasks, but it's crucial to getting results that reliably get a computer to do something for you. LLMs don't do reliable, they don't do repeatable. Building a program allows you to iterate on a deterministic solution with a stable source of truth, and you come away with an artifact that may or not be useless, but which actually works, and in my case converts 70 files/sec.&lt;/p&gt;
    &lt;p&gt;Another example I came across was this twitter thread by BenjaminDEKR, which I saw being ridiculed on bsky. He asked his personal agent to remind him to get milk, and this led the agent to repeatedly ask Opus if it was daytime yet. Along with the context from his heartbeat file, this resulted in a $0.75 charge for each heartbeat, costing him almost $20 during a single night's sleep.&lt;/p&gt;
    &lt;p&gt;What was the solution?&lt;/p&gt;
    &lt;p&gt;Maybe you decide that for your purposes 00:00 is night and 08:00 is day and use a basic local &lt;code&gt;gettimeofday&lt;/code&gt; call to determine which span you're in. Maybe you're unsatisfied with anything other than astronomical day/night and can generate a sunrise/sunset table for the year using NOAA's unmaintained solar calculator to dynamically produce your day/night spans?&lt;/p&gt;
    &lt;p&gt;You could do these things, but not if asking the LLM to solve problems is your problem solving approach. If asking an LLM is the only way you know how to solve problems, then you optimize the question asking by reducing heartbeat frequency and running on a cheaper model. Problem solved!&lt;/p&gt;
    &lt;p&gt;The overall concern is that having a magic box that gives you the answers ends up being a thought terminating solution to any problem.&lt;/p&gt;
    &lt;p&gt;When I wrote about the ecological impacts of AI, one of the non-ecological impacts I cited was the possibility that "AI erodes human skill." A recent release by research fellows at Anthropic, "How AI Impacts Skill Formation", suggests this fear isn't unfounded:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We find that AI use impairs conceptual understanding, code reading, and debugging abilities, without delivering significant efficiency gains on average.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;A few weeks ago, I was at a family gathering watching some of the kids go through a huge backlog of red envelopes that their grandparents had saved for them over various missed holidays. They were pulling out all of the cash, at which point they were going to tally it all up and split it evenly.&lt;/p&gt;
    &lt;p&gt;When the adults challenged them to come up with better counting strategies, one of them suggested they could throw all of the money on the floor, take a picture, and ask ChatGPT to tally it all.&lt;/p&gt;
    &lt;p&gt;The instincts are for people to get the AI to do work for them, not to learn from the AI how to do the work themselves.&lt;/p&gt;
    &lt;p&gt;Wirth's law posits that software can erase gains faster than hardware can make them, but I'm afraid the reality is much worse than that.&lt;/p&gt;
    &lt;p&gt;If you've studied computer science, you might have heard of a function called Busy Beaver. The name is unfortunately silly, but it's a fairly important thought experiment in computability. &lt;code&gt;BB(N)&lt;/code&gt; is defined as the maximum number of steps a terminating turing machine with N states can run.&lt;/p&gt;
    &lt;p&gt;This function is known to be noncomputable, because any algorithm that could compute it would be able to solve the halting problem, which is known to be undecidable. &lt;code&gt;BB(1..3)&lt;/code&gt; were known in the 1960s to be 1, 6, and 21. In a pleasant bit of symmetry with Dan Luu's experiments, &lt;code&gt;BB(4)&lt;/code&gt; was discovered to be 107 in 1983, the same year his Apple 2e was built. In 2024, &lt;code&gt;BB(5)&lt;/code&gt; was proven to be 47,176,870.&lt;/p&gt;
    &lt;p&gt;As N grows, BB is known to eventually outgrow any computable sequence, including famous fast-growing sequences like TREE(). &lt;code&gt;BB(6)&lt;/code&gt; has a lower bound that is so large that it is impossible to explain how large it is to someone without a significant background in mathematics.&lt;/p&gt;
    &lt;p&gt;Software has an unprecedented capability to produce a correct answer in the most resource consuming way possible. Of course, producing incorrect answers or no answer at all is also an option.&lt;/p&gt;
    &lt;p&gt;Despite the apparent truth of Wirth's law, engineers have been actively battling against it for decades, but I worry that with LLMs we might have lost the war.&lt;/p&gt;
    &lt;p&gt;Am I just the latest in a long line of engineers who can't appreciate the newfound democratization of programming, or have we crossed into a "bad" Wirth tradeoff, where the growth curve of runtime complexity is something that hardware advancements cannot possibly dig us back out of?&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;If you are wincing at the last name Reiser in the context of vaguely old computing, we are both of a very specific place and time, and I want you to know that Martin Reiser is not and has never been Hans Reiser.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46895381</guid><pubDate>Thu, 05 Feb 2026 03:38:26 +0000</pubDate></item><item><title>A few CPU hardware bugs</title><link>https://www.taricorp.net/2026/a-few-cpu-bugs/</link><description>&lt;doc fingerprint="ea86d90907ae236c"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;A few CPU hardware bugs&lt;/head&gt;
    &lt;p&gt;Catherine (Whitequark)’s recent observations on poorly-engineered firmware reminded me of a few mistakes I’ve seen in vendors’ CPUs; some unimportant and others surprisingly bad. Since I’ve never seen these widely discussed, here’s some discussion and links to supporting evidence to make them more widely known, since I think they’re interesting.&lt;/p&gt;
    &lt;head rend="h2"&gt;Intel’s misspelled CPUIDs&lt;/head&gt;
    &lt;p&gt;I’m aware of two situations where Intel have sold CPUs that report misspelled names in some of the strings returned by the &lt;code&gt;CPUID&lt;/code&gt; instruction. This seems embarrassing for an organization of Intel’s size, but probably doesn’t hurt anybody’s ability to use the CPUs in question.&lt;/p&gt;
    &lt;head rend="h3"&gt;GenuineIotel&lt;/head&gt;
    &lt;p&gt;A web search for “GenuineIotel” reveals some discussions regarding this apparent typo, where some processors such as the Xeon E3-1231 v3 return the string “GenuineIotel” (instead of the usual “GenuineIntel”) for the CPU manufacturer ID. This one is well-known enough to be mentioned in the list of manufacturer IDs on Wikipedia.&lt;/p&gt;
    &lt;p&gt;It’s possible this misspelling is actually caused by some kind of random bit error, since the characters ’n’ and ‘o’ differ by only one bit; an unpredictable error that sets that bit could change &lt;code&gt;GenuineIntel&lt;/code&gt; to &lt;code&gt;GenuineIotel&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;ore i5&lt;/head&gt;
    &lt;p&gt;Another error that seems more likely to be human error in the CPU is in the Core i5-1245U CPU, which returns a processor brand string &lt;code&gt;Intel(R) ore(TM) i5-1245U&lt;/code&gt; which is simply missing the ‘C’ in &lt;code&gt;Core(TM) i5&lt;/code&gt;. Web searches for “Intel(R) ore(TM)” show a number of results which could be errors introduced by non-technical users attempting to copy down text from their screen when asking for tech support, but the Ubuntu certified configuration of the Dell Latitude 5430 with this CPU attests to this error actually being present in at least some machines using that CPU.&lt;/p&gt;
    &lt;p&gt;It’s possible this misspelling is not part of the physical CPU design and is instead part of the system firmware because at least on many AMD CPUs the CPU name is normally set by the system firmware. Probably either the CPU design or its microcode encode this misspelling, or Intel’s firmware package that vendors use is the ultimate source. In either case, it seems embarrassing for them that such an error made it out into machines purchased by members of the public because it seems very likely to be the result of human error.&lt;/p&gt;
    &lt;head rend="h2"&gt;ITE’s pipeline bug&lt;/head&gt;
    &lt;p&gt;This one is an actual hardware bug that I discovered at work, but in an embedded processor which most people will never see.&lt;/p&gt;
    &lt;p&gt;ITE Tech is a Taiwanese chip company that sells a variety of specialized ICs, including a selection of PC embedded controllers (which are used for tasks like making the keyboard work and managing battery charging in most laptops). IT81202 is one of those, with on-chip peripherals for communicating with an x86 processor and plenty of memory for private use by its RISC-V CPU.&lt;/p&gt;
    &lt;p&gt;It turns out there’s a pipeline bug in the IT81202 CPU, where instructions modifying some registers immediately following a multiply (&lt;code&gt;mul&lt;/code&gt; instruction) may have no effect. The workaround for this is to cripple the system, telling your compiler that the CPU doesn’t support multiplication or division instructions. Some of the performance can be regained by providing implementations of the library functions that provide integer multiply/divide operations that work in terms of the &lt;code&gt;mul&lt;/code&gt; and &lt;code&gt;div&lt;/code&gt; instructions, which works because inserting no-op instructions after them prevents the issue.&lt;/p&gt;
    &lt;p&gt;To me, this issue doesn’t seem as embarrassing as Intel’s wrong CPUIDs. Pipelined CPUs are hard to build, and at the time they designed the IT81202 CPU RISC-V wasn’t widely used in industry yet so they probably had a pretty immature core implementation. In addition, that’s an embedded processor which very few people will ever need to write software for so an invasive workaround like that isn’t a big deal. This one seems more like a cautionary tale to be aware of than any reason to mock the vendor!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46895388</guid><pubDate>Thu, 05 Feb 2026 03:39:43 +0000</pubDate></item><item><title>When internal hostnames are leaked to the clown</title><link>https://rachelbythebay.com/w/2026/02/03/badnas/</link><description>&lt;doc fingerprint="edd19151c5b24caf"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Owning a $5M data center&lt;/head&gt;
    &lt;p&gt;These days it seems you need a trillion fake dollars, or lunch with politicians to get your own data center. They may help, but they’re not required. At comma we’ve been running our own data center for years. All of our model training, metrics, and data live in our own data center in our own office. Having your own data center is cool, and in this blog post I will describe how ours works, so you can be inspired to have your own data center too.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why no cloud?&lt;/head&gt;
    &lt;p&gt;If your business relies on compute, and you run that compute in the cloud, you are putting a lot of trust in your cloud provider. Cloud companies generally make onboarding very easy, and offboarding very difficult. If you are not vigilant you will sleepwalk into a situation of high cloud costs and no way out. If you want to control your own destiny, you must run your own compute.&lt;/p&gt;
    &lt;p&gt;Self-reliance is great, but there are other benefits to running your own compute. It inspires good engineering. Maintaining a data center is much more about solving real-world challenges. The cloud requires expertise in company-specific APIs and billing systems. A data center requires knowledge of Watts, bits, and FLOPs. I know which one I rather think about.&lt;/p&gt;
    &lt;p&gt;Avoiding the cloud for ML also creates better incentives for engineers. Engineers generally want to improve things. In ML many problems go away by just using more compute. In the cloud that means improvements are just a budget increase away. This locks you into inefficient and expensive solutions. Instead, when all you have available is your current compute, the quickest improvements are usually speeding up your code, or fixing fundamental issues.&lt;/p&gt;
    &lt;p&gt;Finally there’s cost, owning a data center can be far cheaper than renting in the cloud. Especially if your compute or storage needs are fairly consistent, which tends to be true if you are in the business of training or running models. In comma’s case I estimate we’ve spent ~5M on our data center, and we would have spent 25M+ had we done the same things in the cloud.&lt;/p&gt;
    &lt;head rend="h2"&gt;What’s all needed?&lt;/head&gt;
    &lt;p&gt;Our data center is pretty simple. It’s maintained and built by only a couple engineers and technicians. Your needs may be slightly different, our implementation should provide useful context.&lt;/p&gt;
    &lt;head rend="h3"&gt;Power&lt;/head&gt;
    &lt;p&gt;To run servers you need power. We currently use about 450kW at max. Operating a data center exposes you to many fun engineering challenges, but procuring power is not one of them. San Diego power cost is over 40c/kWh, ~3x the global average. It’s a ripoff, and overpriced simply due to political dysfunction. We spent $540,112 on power in 2025, a big part of the data center cost. In a future blog post I hope I can tell you about how we produce our own power and you should too.&lt;/p&gt;
    &lt;head rend="h3"&gt;Cooling&lt;/head&gt;
    &lt;p&gt;Data centers need cool dry air. Typically this is achieved with a CRAC system, but they are power-hungry. San Diego has a mild climate and we opted for pure outside air cooling. This gives us less control of the temperature and humidity, but uses only a couple dozen kW. We have dual 48” intake fans and dual 48” exhaust fans to keep the air cool. To ensure low humidity (&amp;lt;45%) we use recirculating fans to mix hot exhaust air with the intake air. One server is connected to several sensors and runs a PID loop to control the fans to optimize the temperature and humidity.&lt;/p&gt;
    &lt;head rend="h3"&gt;Servers&lt;/head&gt;
    &lt;p&gt;The majority of our current compute is 600 GPUs in 75 TinyBox Pro machines. They were built in-house, which saves us money and ensures they suit our needs. Our self-built machines fail at a similar rate to pre-built machines we’ve bought, but we’re capable of fixing them ourselves quickly. They have 2 CPUs and 8 GPUs each, and work as both training machines and general compute workers.&lt;/p&gt;
    &lt;p&gt;For data storage we have a few racks of Dell machines (R630 and R730). They are filled with SSDs for a total of ~4PB of storage. We use SSDs for reliability and speed. Our main storage arrays have no redundancy and each node needs to be able to saturate the network bandwidth with random access reads. For the storage machines this means reading up to 20Gbps of each 80TB chunk.&lt;/p&gt;
    &lt;p&gt;Other than storage and compute machines we have several one-off machines to run services. This includes a router, climate controller, data ingestion machine, storage master servers, metric servers, redis servers, and a few more.&lt;/p&gt;
    &lt;p&gt;Running the network requires switches, but at this scale we don’t need to bother with complicated switch topologies. We have 3 100Gbps interconnected Z9264F switches, which serve as the main ethernet network. We have two more infiniband switches to interconnect the 2 tinybox pro groups for training all-reduce.&lt;/p&gt;
    &lt;head rend="h3"&gt;The software&lt;/head&gt;
    &lt;p&gt;To effectively use all these compute and storage machines you need some infra. At this scale, services don’t need redundancy to achieve 99% uptime. We use a single master for all services, which makes things pretty simple.&lt;/p&gt;
    &lt;head rend="h5"&gt;Setup&lt;/head&gt;
    &lt;p&gt;All servers get ubuntu installed with pxeboot and are managed by salt.&lt;/p&gt;
    &lt;head rend="h5"&gt;Distributed storage: minikeyvalue&lt;/head&gt;
    &lt;p&gt;All of our storage arrays use mkv. The main array is 3PB of non-redundant storage hosting our driving data we train on. We can read from this array at ~1TB/s, which means we can train directly on the raw data without caching. Redundancy is not needed since no specific data is critical.&lt;/p&gt;
    &lt;p&gt;We have an additional ~300TB non-redundant array to cache intermediate processed results. And lastly, we have a redundant mkv storage array to store all of our trained models and training metrics. Each of these 3 arrays have a separate single master server.&lt;/p&gt;
    &lt;head rend="h5"&gt;Workload management: slurm&lt;/head&gt;
    &lt;p&gt;We use slurm to manage the compute nodes, and compute jobs. We schedule two types of distributed compute. Pytorch training jobs, and miniray workers.&lt;/p&gt;
    &lt;head rend="h5"&gt;Distributed training: pytorch&lt;/head&gt;
    &lt;p&gt;To train models across multiple GPU nodes we use &lt;code&gt;torch.distributed&lt;/code&gt; FSDP. We have 2 separate training partitions, each intra-connected with Infiniband for training across machines. We wrote our own training framework which handles the training loop boilerplate, but it’s mostly just pytorch.&lt;/p&gt;
    &lt;p&gt;We have a custom model experiment tracking service (similar to wandb or tensorboard). It provides a dashboard for tracking experiments, and shows custom metrics and reports. It is also the interface for the mkv storage array that hosts the model weights. The training runs store the model weights there with a uuid, and they are available to download for whoever needs to run them. The metrics and reports for our latest models are also open.&lt;/p&gt;
    &lt;head rend="h5"&gt;Distributed compute: miniray&lt;/head&gt;
    &lt;p&gt;Besides training we have many other compute tasks. This can be anything from running tests, running models, pre-processing data, or even running agent rollouts for on-policy training. We wrote a lightweight open-source task scheduler called miniray that allows you to run arbitrary python code on idle machines. This is a simpler version of dask, with a focus on extreme simplicity. Slurm will schedule any idle machine to be an active miniray worker, and accept pending tasks. All the task information is hosted in a central redis server.&lt;/p&gt;
    &lt;p&gt;Miniray workers with GPUs will spin up a triton inference server to run model inference with dynamic batching. A miniray worker can thus easily and efficiently run any of the models hosted in the model mkv storage array.&lt;/p&gt;
    &lt;p&gt;Miniray makes it extremely easy to scale parallel tasks to hundreds of machines. For example, the controls challenge record was set by just having ~1hr of access to our data center with miniray.&lt;/p&gt;
    &lt;head rend="h5"&gt;Code NFS monorepo&lt;/head&gt;
    &lt;p&gt;All our code is in a monorepo that we have cloned on our workstations. This monorepo is kept small (&amp;lt;3GB), so it can easily be copied around. When a training job or miniray distributed job is started on any workstation, the local monorepo is cached on a shared NFS drive including all the local changes. Training jobs and miniray tasks are pointed towards this cache, such that all distributed work uses the exact codebase you have locally. Even all the python packages are identical, UV on the worker/trainer syncs the packages specified in the monorepo before starting any work. This entire process of copying your entire local codebase and syncing all the packages takes only ~2s, and is well worth it to prevent the issues mismatches can cause.&lt;/p&gt;
    &lt;head rend="h2"&gt;All together now&lt;/head&gt;
    &lt;p&gt;The most complex thing we do at comma is train driving models on-policy, these training runs require training data to be generated during training by running simulated driving rollouts with the most recent model weights. Here’s a real-world command we just used to train such a model. This training run uses all of the infrastructure described above. While only this small command is needed to kick everything off, it orchestrates a lot of moving parts.&lt;/p&gt;
    &lt;code&gt;./training/train.sh N=4 partition=tbox2 trainer=mlsimdriving dataset=/home/batman/xx/datasets/lists/train_500k_20250717.txt vision_model=8d4e28c7-7078-4caf-ac7d-d0e41255c3d4/500 data.shuffle_size=125k optim.scheduler=COSINE bs=4
&lt;/code&gt;
    &lt;head rend="h2"&gt;Like this stuff?&lt;/head&gt;
    &lt;p&gt;Does all this stuff sound exciting? Then build your own datacenter for yourself or your company! You can also come work here.&lt;/p&gt;
    &lt;p&gt;Harald Schäfer&lt;lb/&gt; CTO @ comma.ai&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46895972</guid><pubDate>Thu, 05 Feb 2026 05:22:36 +0000</pubDate></item><item><title>Don't rent the cloud, own instead</title><link>https://blog.comma.ai/datacenter/</link><description>&lt;doc fingerprint="edd19151c5b24caf"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Owning a $5M data center&lt;/head&gt;
    &lt;p&gt;These days it seems you need a trillion fake dollars, or lunch with politicians to get your own data center. They may help, but they’re not required. At comma we’ve been running our own data center for years. All of our model training, metrics, and data live in our own data center in our own office. Having your own data center is cool, and in this blog post I will describe how ours works, so you can be inspired to have your own data center too.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why no cloud?&lt;/head&gt;
    &lt;p&gt;If your business relies on compute, and you run that compute in the cloud, you are putting a lot of trust in your cloud provider. Cloud companies generally make onboarding very easy, and offboarding very difficult. If you are not vigilant you will sleepwalk into a situation of high cloud costs and no way out. If you want to control your own destiny, you must run your own compute.&lt;/p&gt;
    &lt;p&gt;Self-reliance is great, but there are other benefits to running your own compute. It inspires good engineering. Maintaining a data center is much more about solving real-world challenges. The cloud requires expertise in company-specific APIs and billing systems. A data center requires knowledge of Watts, bits, and FLOPs. I know which one I rather think about.&lt;/p&gt;
    &lt;p&gt;Avoiding the cloud for ML also creates better incentives for engineers. Engineers generally want to improve things. In ML many problems go away by just using more compute. In the cloud that means improvements are just a budget increase away. This locks you into inefficient and expensive solutions. Instead, when all you have available is your current compute, the quickest improvements are usually speeding up your code, or fixing fundamental issues.&lt;/p&gt;
    &lt;p&gt;Finally there’s cost, owning a data center can be far cheaper than renting in the cloud. Especially if your compute or storage needs are fairly consistent, which tends to be true if you are in the business of training or running models. In comma’s case I estimate we’ve spent ~5M on our data center, and we would have spent 25M+ had we done the same things in the cloud.&lt;/p&gt;
    &lt;head rend="h2"&gt;What’s all needed?&lt;/head&gt;
    &lt;p&gt;Our data center is pretty simple. It’s maintained and built by only a couple engineers and technicians. Your needs may be slightly different, our implementation should provide useful context.&lt;/p&gt;
    &lt;head rend="h3"&gt;Power&lt;/head&gt;
    &lt;p&gt;To run servers you need power. We currently use about 450kW at max. Operating a data center exposes you to many fun engineering challenges, but procuring power is not one of them. San Diego power cost is over 40c/kWh, ~3x the global average. It’s a ripoff, and overpriced simply due to political dysfunction. We spent $540,112 on power in 2025, a big part of the data center cost. In a future blog post I hope I can tell you about how we produce our own power and you should too.&lt;/p&gt;
    &lt;head rend="h3"&gt;Cooling&lt;/head&gt;
    &lt;p&gt;Data centers need cool dry air. Typically this is achieved with a CRAC system, but they are power-hungry. San Diego has a mild climate and we opted for pure outside air cooling. This gives us less control of the temperature and humidity, but uses only a couple dozen kW. We have dual 48” intake fans and dual 48” exhaust fans to keep the air cool. To ensure low humidity (&amp;lt;45%) we use recirculating fans to mix hot exhaust air with the intake air. One server is connected to several sensors and runs a PID loop to control the fans to optimize the temperature and humidity.&lt;/p&gt;
    &lt;head rend="h3"&gt;Servers&lt;/head&gt;
    &lt;p&gt;The majority of our current compute is 600 GPUs in 75 TinyBox Pro machines. They were built in-house, which saves us money and ensures they suit our needs. Our self-built machines fail at a similar rate to pre-built machines we’ve bought, but we’re capable of fixing them ourselves quickly. They have 2 CPUs and 8 GPUs each, and work as both training machines and general compute workers.&lt;/p&gt;
    &lt;p&gt;For data storage we have a few racks of Dell machines (R630 and R730). They are filled with SSDs for a total of ~4PB of storage. We use SSDs for reliability and speed. Our main storage arrays have no redundancy and each node needs to be able to saturate the network bandwidth with random access reads. For the storage machines this means reading up to 20Gbps of each 80TB chunk.&lt;/p&gt;
    &lt;p&gt;Other than storage and compute machines we have several one-off machines to run services. This includes a router, climate controller, data ingestion machine, storage master servers, metric servers, redis servers, and a few more.&lt;/p&gt;
    &lt;p&gt;Running the network requires switches, but at this scale we don’t need to bother with complicated switch topologies. We have 3 100Gbps interconnected Z9264F switches, which serve as the main ethernet network. We have two more infiniband switches to interconnect the 2 tinybox pro groups for training all-reduce.&lt;/p&gt;
    &lt;head rend="h3"&gt;The software&lt;/head&gt;
    &lt;p&gt;To effectively use all these compute and storage machines you need some infra. At this scale, services don’t need redundancy to achieve 99% uptime. We use a single master for all services, which makes things pretty simple.&lt;/p&gt;
    &lt;head rend="h5"&gt;Setup&lt;/head&gt;
    &lt;p&gt;All servers get ubuntu installed with pxeboot and are managed by salt.&lt;/p&gt;
    &lt;head rend="h5"&gt;Distributed storage: minikeyvalue&lt;/head&gt;
    &lt;p&gt;All of our storage arrays use mkv. The main array is 3PB of non-redundant storage hosting our driving data we train on. We can read from this array at ~1TB/s, which means we can train directly on the raw data without caching. Redundancy is not needed since no specific data is critical.&lt;/p&gt;
    &lt;p&gt;We have an additional ~300TB non-redundant array to cache intermediate processed results. And lastly, we have a redundant mkv storage array to store all of our trained models and training metrics. Each of these 3 arrays have a separate single master server.&lt;/p&gt;
    &lt;head rend="h5"&gt;Workload management: slurm&lt;/head&gt;
    &lt;p&gt;We use slurm to manage the compute nodes, and compute jobs. We schedule two types of distributed compute. Pytorch training jobs, and miniray workers.&lt;/p&gt;
    &lt;head rend="h5"&gt;Distributed training: pytorch&lt;/head&gt;
    &lt;p&gt;To train models across multiple GPU nodes we use &lt;code&gt;torch.distributed&lt;/code&gt; FSDP. We have 2 separate training partitions, each intra-connected with Infiniband for training across machines. We wrote our own training framework which handles the training loop boilerplate, but it’s mostly just pytorch.&lt;/p&gt;
    &lt;p&gt;We have a custom model experiment tracking service (similar to wandb or tensorboard). It provides a dashboard for tracking experiments, and shows custom metrics and reports. It is also the interface for the mkv storage array that hosts the model weights. The training runs store the model weights there with a uuid, and they are available to download for whoever needs to run them. The metrics and reports for our latest models are also open.&lt;/p&gt;
    &lt;head rend="h5"&gt;Distributed compute: miniray&lt;/head&gt;
    &lt;p&gt;Besides training we have many other compute tasks. This can be anything from running tests, running models, pre-processing data, or even running agent rollouts for on-policy training. We wrote a lightweight open-source task scheduler called miniray that allows you to run arbitrary python code on idle machines. This is a simpler version of dask, with a focus on extreme simplicity. Slurm will schedule any idle machine to be an active miniray worker, and accept pending tasks. All the task information is hosted in a central redis server.&lt;/p&gt;
    &lt;p&gt;Miniray workers with GPUs will spin up a triton inference server to run model inference with dynamic batching. A miniray worker can thus easily and efficiently run any of the models hosted in the model mkv storage array.&lt;/p&gt;
    &lt;p&gt;Miniray makes it extremely easy to scale parallel tasks to hundreds of machines. For example, the controls challenge record was set by just having ~1hr of access to our data center with miniray.&lt;/p&gt;
    &lt;head rend="h5"&gt;Code NFS monorepo&lt;/head&gt;
    &lt;p&gt;All our code is in a monorepo that we have cloned on our workstations. This monorepo is kept small (&amp;lt;3GB), so it can easily be copied around. When a training job or miniray distributed job is started on any workstation, the local monorepo is cached on a shared NFS drive including all the local changes. Training jobs and miniray tasks are pointed towards this cache, such that all distributed work uses the exact codebase you have locally. Even all the python packages are identical, UV on the worker/trainer syncs the packages specified in the monorepo before starting any work. This entire process of copying your entire local codebase and syncing all the packages takes only ~2s, and is well worth it to prevent the issues mismatches can cause.&lt;/p&gt;
    &lt;head rend="h2"&gt;All together now&lt;/head&gt;
    &lt;p&gt;The most complex thing we do at comma is train driving models on-policy, these training runs require training data to be generated during training by running simulated driving rollouts with the most recent model weights. Here’s a real-world command we just used to train such a model. This training run uses all of the infrastructure described above. While only this small command is needed to kick everything off, it orchestrates a lot of moving parts.&lt;/p&gt;
    &lt;code&gt;./training/train.sh N=4 partition=tbox2 trainer=mlsimdriving dataset=/home/batman/xx/datasets/lists/train_500k_20250717.txt vision_model=8d4e28c7-7078-4caf-ac7d-d0e41255c3d4/500 data.shuffle_size=125k optim.scheduler=COSINE bs=4
&lt;/code&gt;
    &lt;head rend="h2"&gt;Like this stuff?&lt;/head&gt;
    &lt;p&gt;Does all this stuff sound exciting? Then build your own datacenter for yourself or your company! You can also come work here.&lt;/p&gt;
    &lt;p&gt;Harald Schäfer&lt;lb/&gt; CTO @ comma.ai&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46896146</guid><pubDate>Thu, 05 Feb 2026 05:50:01 +0000</pubDate></item><item><title>BMW's Newest "Innovation" Is a Logo-Shaped Middle Finger to Right to Repair</title><link>https://www.ifixit.com/News/115528/bmws-newest-innovation-is-a-logo-shaped-middle-finger-to-right-to-repair</link><description>&lt;doc fingerprint="d24bc4d1d6233795"&gt;
  &lt;main&gt;
    &lt;p&gt;If you haven’t already heard, BMW’s R&amp;amp;D teams have been busy “innovating.” Unfortunately, they aren’t focusing on the things that actually matter—like stellar engine performance or the legendary driving dynamics that gearheads love. Instead, the C-suite execs decided that the best use of their engineering budget was to design a proprietary security screw specifically intended to prevent BMW drivers from fixing their own cars.&lt;/p&gt;
    &lt;p&gt;At first glance, it’s almost cute: a screw head shaped exactly like the BMW logo. But the novelty wears off the moment you consider the physics. Because this head prioritizes branding over utility, neither the bit nor the screw head can withstand the torque of a standard Torx or Hex fastener. The result? Broken bits, stripped screws, and more time spent on what would otherwise be a simple task.&lt;/p&gt;
    &lt;p&gt;It’s a masterpiece of anti-functional design. To the casual observer, it seems to serve no purpose other than to look “cool”, but when it comes to the nitty gritty of DIY repair, it ensures that a standard toolbox is useless for basic maintenance. In fact, the patent explicitly states this as a function of its design in section [0006]: “…to prevent being loosened or tightened…by unauthorized individuals.”&lt;/p&gt;
    &lt;p&gt;This type of insular protectionism isn’t a one off either, it’s baked into the corporate culture. Our CEO Kyle Wiens observed this firsthand during a visit to BMW’s Recycling and Dismantling Center (RDC) located in Landshut just north of Munich, Germany. It’s a peculiar, one of a kind facility that recovers materials from pre-production and prototype vehicles that will never reach consumer hands. The RDC processes a few thousand vehicles each year which represents only a tiny fraction of the more than one million cars BMW produced in 2025 in Germany alone.&lt;/p&gt;
    &lt;p&gt;BMW doesn’t seem shy about declaring the RDC’s mission either, proclaiming it a “template for the industry” while stating: “In view of new regulations and the BMW Group’s ambitious targets, the RDC will play an even more important role going forward…” (italics for emphasis). New regulations certainly have a way of encouraging ambitious targets, that’s for sure.&lt;/p&gt;
    &lt;p&gt;Their barely-passive hostility towards repair and recycling is even less hidden on the operations floor. As Kyle noted during his visit, BMW’s engineers developed a clever tool to drain oil from shock absorbers so the oil could be reused: “When a member of my tour group asked if BMW sold it to other refurbishers, the man holding the tool looked confused, as though the suggestion was patently absurd. That tool was their intellectual property; it was developed by BMW for BMW. And the patent they filed for the tool ensures that no-one else can invent something similar.” So much for a “template for the industry.”&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;“That tool was their intellectual property; it was developed by BMW for BMW. And the patent they filed for the tool ensures that no-one else can invent something similar.”&lt;/p&gt;Kyle Wiens; “Intellectual property is putting circular economy in jeopardy” for The Guardian&lt;/quote&gt;
    &lt;p&gt;In BMW’s defense—and the defense of an ever-growing list of manufacturers desperate to gatekeep their ecosystems—this isn’t their first dumb idea. Heck, they’re not even the first to use security screws, the first dates back to the one-way screw of the early 1900s. Since then, we’ve seen a parade of “tamperproof” fasteners flood the market, including some very insidious designs like the Pentalobe screws used on iPhones.&lt;/p&gt;
    &lt;p&gt;The justifications are always the same: anti-theft measures or “protecting” the user from dangerous components. While those excuses might hold water for public infrastructure or high-voltage utility boxes, they fall apart when applied to consumer products. In your garage, these aren’t safety features; they are barriers to ownership.&lt;/p&gt;
    &lt;p&gt;To be clear, it’s not like we’re anti-new screws or anything, as evidenced by our resident mechanical engineers waxing poetic about the functional benefits of strip resistant Torx Plus screws when compared to regular old Torx or Hex. Fasteners, like all things, are subject to improvement over time and we’re all for it. That’s not what proprietary security screws are designed to do though.&lt;/p&gt;
    &lt;p&gt;As with any cash-grab engineered to stifle repair, the DIY community isn’t taking it lying down. Our friends over at Adafruit didn’t even need a physical screw to win this round; they used BMW’s own spurious patent filings to map the dimensions and 3D-print a replica bit to defeat the lock.&lt;/p&gt;
    &lt;p&gt;This is where BMW’s plan hits a wall. We’re living in an era where the efforts of industrial giants can be unraveled by a hobbyist with a $200 printer and a bit of ingenuity. The fact that a grassroots effort can dismantle a multi-million dollar “security” initiative in a matter of days speaks volumes.&lt;/p&gt;
    &lt;p&gt;The tide is turning. Across the US, we’re making massive strides in securing the right to repair our stuff, and that includes both commercial and consumer vehicles. In this climate, BMW’s move to lock down hardware with proprietary screws is tone-deaf and will be seen for the desperate cash-grab that it is.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46896427</guid><pubDate>Thu, 05 Feb 2026 06:33:47 +0000</pubDate></item><item><title>Modernizing Linux swapping: introducing the swap table</title><link>https://lwn.net/SubscriberLink/1056405/e728d95dd16f5e1b/</link><description>&lt;doc fingerprint="eef8d25db1b50b80"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Modernizing swapping: introducing the swap table&lt;/head&gt;
    &lt;head rend="h2"&gt;[LWN subscriber-only content]&lt;/head&gt;
    &lt;quote&gt;
      &lt;head&gt;Welcome to LWN.net&lt;/head&gt;
      &lt;p&gt;The following subscription-only content has been made available to you by an LWN subscriber. Thousands of subscribers depend on LWN for the best news from the Linux and free software communities. If you enjoy this article, please consider subscribing to LWN. Thank you for visiting LWN.net!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The kernel's swap subsystem is a complex and often unloved beast. It is also a critical component in the memory-management subsystem and has a significant impact on the performance of the system as a whole. At the 2025 Linux Storage, Filesystem, Memory-Management and BPF Summit, Kairui Song outlined a plan to simplify and optimize the kernel's swap code. A first installment of that work, written with help from Chris Li, was merged for the 6.18 release. This article will catch up with the 6.18 work, setting the stage for a future look at the changes that are yet to be merged.&lt;/p&gt;
    &lt;p&gt;In a virtual-memory system, memory shortages must be addressed by reclaiming RAM and, if necessary, writing its contents to the appropriate persistent backing store. For file-backed memory, the file itself is that backing store. Anonymous memory — the memory that holds the variables and data structures used by a process — lacks that natural backing store, though. That is where the swap subsystem comes in: it provides a place to write anonymous pages when the memory they occupy is needed for other uses. Swapping allows unused (or seldom-used) pages to be pushed out to slower storage, making the system's RAM available for data that is currently in use.&lt;/p&gt;
    &lt;head rend="h4"&gt;A quick swap-subsystem primer&lt;/head&gt;
    &lt;p&gt;A full description of the kernel's swap subsystem would be lengthy indeed; there is a lot of complexity, much of which has built up over time. What follows is a partial, simplified overview of how the swap subsystem looked in the 6.17 kernel, which can then be used as a base for understanding the subsequent changes.&lt;/p&gt;
    &lt;p&gt;The swap subsystem uses one or more swap files, which can be either partitions on a storage device or ordinary files within a filesystem. Inside the kernel, active swap files are described by struct swap_info_struct, but are usually referred to using a simple integer index instead. Each file is divided into page-sized slots; any given slot in the kernel's swap areas can be identified using the swp_entry_t type:&lt;/p&gt;
    &lt;quote&gt;typedef struct { unsigned long val; } swp_entry_t;&lt;/quote&gt;
    &lt;p&gt;This long value is divided into two fields: the upper six bits are the index number of the swap file (which, for extra clarity, is called the "type" in the swap code), and the rest is the slot number within the file. There is a set of simple functions used to create swap entries and get the relevant information back out.&lt;/p&gt;
    &lt;p&gt;Note that the above describes the architecture-independent form of the swap entry; each architecture will also have an architecture-dependent version that is used in page-table entries. Curious readers can look at the x86_64 macros that convert between the two formats. Within the swap subsystem itself, though, the architecture-independent version of the swap entry is used.&lt;/p&gt;
    &lt;p&gt;An overly simplified description of swapping would be something like: when the memory-management subsystem decides to reclaim an anonymous page, it selects a swap slot, writes the page's contents into that slot, then stores the associated swap entry in the page-table entry (using the architecture-dependent format) with the "present" bit cleared. The next attempt to reference that page will result in a page fault; the kernel will see the swap entry, allocate a new page, read the contents from the swap file, then update the page-table entry accordingly.&lt;/p&gt;
    &lt;p&gt;The truth of the matter is that things are rather more complex than that. For example, writing a page to the swap file takes time, and the page itself cannot be reclaimed until the write is complete. So, when the reclaim decision is made, the page is put into the swap cache, which is, in many ways, the analog of the page cache used for file-backed pages. Saying that a page is in the swap cache really only means that a swap entry has been assigned; the page itself may or may not still be resident in RAM. If a fault happens on that page while the writing process is underway, that page can be quickly reactivated, despite being in the swap cache.&lt;/p&gt;
    &lt;p&gt;All of this means that the swap subsystem has to keep track of the status of every page in the swap cache, and that status involves more than just the swap slot that was assigned. To that end, in kernels prior to 6.18, the swap subsystem maintained an array called swapper_spaces that contained pointers to arrays of address_space structures. That structure is used to maintain the mapping between an address space (the bytes of a file, or the slots of a swap file) and the storage that backs up that space. It provides a set of operations that can be used to move pages between RAM and that backing store. Using struct address_space means, among other things, that much of the code that works with the page cache can also operate with the swap cache.&lt;/p&gt;
    &lt;p&gt;Another reason to use struct address_space is the XArray data structure associated with it. For a swap file, that data structure contains the current status of each slot in the file, which can be any of:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The slot is empty.&lt;/item&gt;
      &lt;item&gt;There is a page assigned to the slot, but that page is also resident in RAM; in that case, the XArray entry is a pointer to the page (more precisely, the folio containing the page) itself.&lt;/item&gt;
      &lt;item&gt;There is a page assigned, but it exists only in the swap file. In that case, the entry contains "shadow" information used by the memory-management system to detect pages that are quickly faulted in after being swapped out. (See this 2012 article for an overview of this mechanism).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For extra fun, there is not a single address_space structure and XArray for each swap file. Instead, the file is divided into 64MB chunks, and a separate address_space structure is created for each. This design helps to spread the management of swap entries across multiple XArrays, reducing contention and increasing scalability on larger systems where a lot of swapping is taking place. The swapper_spaces entry for a swap file, thus, points to an array of address_space structures; a 1GB swap file, for example, would be managed with an array of 16 of these structures.&lt;/p&gt;
    &lt;p&gt;There is one more complication (for the purpose of this discussion — there are many others as well) in the management of swap slots. Each swap device is also divided into a set of swap clusters, represented by struct swap_cluster_info; these clusters are usually 2MB in size. Swap clusters make the management of swap files more scalable; each CPU in the system maintains a cache of swap clusters that have been assigned to it. The associated swap entries can then be managed entirely locally to the CPU, with cross-CPU access only needed when clusters must be allocated or freed. Swap clusters reduce the amount of scanning of the global swap map needed to work with swap entries, but the appropriate XArray must still be used to obtain or modify the status of a given slot.&lt;/p&gt;
    &lt;head rend="h4"&gt;The swap table&lt;/head&gt;
    &lt;p&gt;With that background in place, it is possible to look at the changes made for 6.18. They start with the understanding that the swap-subsystem code that deals with swap entries already has access to the swap clusters those entries belong to. Keeping the status information with the clusters would allow the elimination of the XArrays, which can be replaced with simple C arrays of swap entries. The smaller granularity of the swap clusters serves to further localize the management of swap entries, which should improve scalability.&lt;/p&gt;
    &lt;p&gt;So the phase-1 patch set augments the swap_cluster_info structure; the post-6.17 version of that structure contains a new array pointer:&lt;/p&gt;
    &lt;quote&gt;atomic_long_t __rcu *table;&lt;/quote&gt;
    &lt;p&gt;The new table array, which is designed to occupy exactly one page on most architectures, is allocated dynamically, reducing the swap subsystem's memory use when the swap files are not full. Each entry in the table is the same swp_entry_t value seen above, describing the status of one page in the swap cache. The swap code has been reworked to use this new organization, with many of the internal APIs needing minimal or no changes. The arrays of address_space structures covering 64MB each are gone; the XArrays are no longer needed, and the address-space operations can be provided by a single structure, called swap_space.&lt;/p&gt;
    &lt;p&gt; In summary, where the kernel previously divided swap areas using two independent clustering mechanisms (the address_space structures and the swap clusters), now it only has one clustering scheme that increases the locality of many swap operations. The end result, at this stage, is "&lt;quote&gt;up to ~5-20% performance gain in throughput, RPS or build time for benchmark and workload tests&lt;/quote&gt;", according to Song. This speed improvement is entirely due to the removal of the XArray lookups and the reduction in contention that comes from managing swap space in smaller chunks. &lt;/p&gt;
    &lt;p&gt; That is the state of affairs as of 6.18. As significant as this change is, it is only the beginning of the project to simplify and improve the kernel's swap code. The 6.19 kernel did not significantly advance this work, but there are two other installments under consideration, one of which is seemingly poised for the 7.0 release. Those changes will be covered in the second part of this series.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Index entries for this article&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Kernel&lt;/cell&gt;
        &lt;cell&gt;Memory management/Swapping&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46896586</guid><pubDate>Thu, 05 Feb 2026 06:58:43 +0000</pubDate></item><item><title>Show HN: CLI tool to convert Markdown to rich HTML clipboard content</title><link>https://github.com/letientai299/md2cb</link><description>&lt;doc fingerprint="bc0a9c7f3db78aea"&gt;
  &lt;main&gt;
    &lt;p&gt;Converts GitHub Flavored Markdown (GFM) to rich HTML and copies it to the system clipboard for pasting into Word, Google Docs, Pages, Teams, etc.&lt;/p&gt;
    &lt;code&gt;cat file.md | md2cb&lt;/code&gt;
    &lt;p&gt;Then, paste the copied clipboard content to the target app.&lt;/p&gt;
    &lt;p&gt;Add &lt;code&gt;--edit/-e&lt;/code&gt; flag to edit the content in &lt;code&gt;$EDITOR&lt;/code&gt; before converting. &lt;code&gt;-e&lt;/code&gt;
would open an empty markdown file if run without any input (file or stdin).&lt;/p&gt;
    &lt;p&gt;Linux/macOS:&lt;/p&gt;
    &lt;code&gt;curl -fsSL https://raw.githubusercontent.com/letientai299/md2cb/main/scripts/install.sh | bash&lt;/code&gt;
    &lt;p&gt;Windows (PowerShell):&lt;/p&gt;
    &lt;code&gt;irm https://raw.githubusercontent.com/letientai299/md2cb/main/scripts/install.ps1 | iex&lt;/code&gt;
    &lt;p&gt;Installs to &lt;code&gt;/usr/local/bin&lt;/code&gt; (Unix) or &lt;code&gt;%USERPROFILE%\bin&lt;/code&gt; (Windows) by default.
Use &lt;code&gt;-d &amp;lt;path&amp;gt;&lt;/code&gt; to specify a custom directory.&lt;/p&gt;
    &lt;p&gt;Rendered from &lt;code&gt;test/demo.md&lt;/code&gt;.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Microsoft Teams&lt;/cell&gt;
        &lt;cell&gt;Google Docs&lt;/cell&gt;
        &lt;cell&gt;Froala Editor for reference&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;See &lt;code&gt;mise tasks&lt;/code&gt; for list of common tasks. Use &lt;code&gt;mise dev&lt;/code&gt; to start the 2 web
servers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;http://localhost:9091/demo.md: Markdown preview rendered by markserv:&lt;/item&gt;
      &lt;item&gt;http://localhost:9090: Froala editor for pasting the converted content&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;https://mise.jdx.dev for manage dev toosl and tasks runner.&lt;/item&gt;
      &lt;item&gt;Docker for running dev servers&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Most of the code was written by Claude Code, with some code review from Copilot!&lt;/p&gt;
    &lt;p&gt;At work I need to use Teams. It supports a few makdown features, but the editing experience for long message isn't smooth. So, I often write in NVim and use the below shell script to convert them before paste to Teams.&lt;/p&gt;
    &lt;code&gt;pandoc --from gfm --to html |
    textutil -convert rtf -stdin -stdout -format html |
    pbcopy -Prefer&lt;/code&gt;
    &lt;p&gt;The script work well for typical bullet list, but:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Doesn't support image, mermaid.&lt;/item&gt;
      &lt;item&gt;Mac only.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Hence, I build this.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46896623</guid><pubDate>Thu, 05 Feb 2026 07:05:31 +0000</pubDate></item><item><title>Show HN: Micropolis/SimCity Clone in Emacs Lisp</title><link>https://github.com/vkazanov/elcity</link><description>&lt;doc fingerprint="3e873a436311661e"&gt;
  &lt;main&gt;
    &lt;p&gt;ElCity is a small, turn-based city builder that runs entirely inside Emacs. The UI is ASCII-based and optimized for terminal Emacs sessions. The core simulation is deterministic and pure, while the UI handles rendering and input.&lt;/p&gt;
    &lt;p&gt;This is an excercise in implementing the “functional core / imperative shell” architecture in a moderately sized project that with a developed UI. Every tile type is defined through a DSL, with a strong separation between state and effects. Most functions in the core are either pure or pure-ish.&lt;/p&gt;
    &lt;p&gt;Benefits to this approach:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;easy to debug&lt;/item&gt;
      &lt;item&gt;scalable in terms of code: reduced cognitive load on both people and LLMs&lt;/item&gt;
      &lt;item&gt;easy UX/UI as state is always localized&lt;/item&gt;
      &lt;item&gt;easy to extend (with some discipline)&lt;/item&gt;
      &lt;item&gt;easy to autotest&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Emacs 30.1+&lt;/item&gt;
      &lt;item&gt;Optional: Eask for dependency management&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Clone the repository and add it to your Emacs load path. Example with &lt;code&gt;use-package&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;(use-package elcity
  :load-path "/path/to/elcity"
  :commands (elcity-start))&lt;/code&gt;
    &lt;p&gt;If you are not using &lt;code&gt;use-package&lt;/code&gt;, add the directory to &lt;code&gt;load-path&lt;/code&gt;
  and require the entry point:&lt;/p&gt;
    &lt;code&gt;(add-to-list 'load-path "/path/to/elcity")
(require 'elcity)
(elcity-start)&lt;/code&gt;
    &lt;p&gt;From the project root:&lt;/p&gt;
    &lt;code&gt;make run&lt;/code&gt;
    &lt;p&gt;Or from Emacs: &lt;code&gt;M-x elcity-start&lt;/code&gt;&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The game is turn-based. Press &lt;code&gt;n&lt;/code&gt;to advance one turn.&lt;/item&gt;
      &lt;item&gt;Funds increase each turn by: (Population / 2) + (Commercial level + Industrial level).&lt;/item&gt;
      &lt;item&gt;City Hall is the source of road connectivity and is unique and non-demolishable.&lt;/item&gt;
      &lt;item&gt;Roads are only connected if they trace through other roads to City Hall.&lt;/item&gt;
      &lt;item&gt;Power plants provide a Manhattan-radius of 6 tiles.&lt;/item&gt;
      &lt;item&gt;Zones grow by 1 level per turn if powered and road-adjacent.&lt;/item&gt;
      &lt;item&gt;Zones decay by 1 level per turn if they lose power or road adjacency.&lt;/item&gt;
      &lt;item&gt;Maximum zone level is 3.&lt;/item&gt;
      &lt;item&gt;Residential (R) supplies Workers in a radius and dislikes Pollution.&lt;/item&gt;
      &lt;item&gt;Industrial (I) supplies Goods and Pollution and requires Workers.&lt;/item&gt;
      &lt;item&gt;Commercial (C) requires Workers and Goods.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;R&lt;/code&gt;select Residential and place once&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;C&lt;/code&gt;select Commercial and place once&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;I&lt;/code&gt;select Industrial and place once&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;r&lt;/code&gt;select Road and place once&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;p&lt;/code&gt;select Power plant and place once&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;h&lt;/code&gt;select City Hall and place once&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;SPC&lt;/code&gt;or&lt;code&gt;RET&lt;/code&gt;place selected tool at cursor&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;d&lt;/code&gt;demolish at cursor&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;u&lt;/code&gt;undo last action&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;n&lt;/code&gt;advance one turn&lt;/item&gt;
      &lt;item&gt;Arrow keys move the cursor&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;o&lt;/code&gt;cycle overlays (goods, polution, connectivity, etc)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is a simplified snapshot to show the general layout.&lt;/p&gt;
    &lt;code&gt;Funds: 1000 | Pop: 0 | Income: 0 | Turn: 0 | Overlay: none | Tool: none | Unpowered: 0 | Disconnected: 0 | Polluted: 0
Cursor: (0,0) | Tile: HH City Hall | Level: 0 | Build: N | Demo: N | Unique: Y | Cost: 150 | Pop: 0 | Inc: 0
Legend: R res  C com  I ind  == road  Overlay: Pwr Conn Poll Work Goods
Keys: R/C/I zone (select tool) | r road | p power | h city hall | d demolish | n next turn
Place: SPC/RET place selected tool | u undo
Overlay: o cycle (none/power/connectivity/pollution/workers/goods)
Move: arrows
   00 01 02 03 04 05 06 07 08 09
   +--------------------+
00 |HH==R0..PP..........|
01 |....................|
02 |~~~~~~..............|
   +--------------------+
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Start with a custom map by calling &lt;code&gt;elcity-start&lt;/code&gt;with a list of row strings.&lt;/item&gt;
      &lt;item&gt;Example call: &lt;code&gt;(elcity-start '("H=R0" "...."))&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Map tokens are defined in tile definitions.&lt;/item&gt;
      &lt;item&gt;Canonical tokens include &lt;code&gt;..&lt;/code&gt;,&lt;code&gt;~~&lt;/code&gt;,&lt;code&gt;==&lt;/code&gt;,&lt;code&gt;PP&lt;/code&gt;,&lt;code&gt;HH&lt;/code&gt;,&lt;code&gt;R0&lt;/code&gt;-=R3=,&lt;code&gt;C0&lt;/code&gt;-=C3=,&lt;code&gt;I0&lt;/code&gt;-=I3=.&lt;/item&gt;
      &lt;item&gt;Short aliases are also accepted: &lt;code&gt;.&lt;/code&gt;,&lt;code&gt;~&lt;/code&gt;,&lt;code&gt;=&lt;/code&gt;,&lt;code&gt;P&lt;/code&gt;,&lt;code&gt;H&lt;/code&gt;,&lt;code&gt;R&lt;/code&gt;,&lt;code&gt;C&lt;/code&gt;,&lt;code&gt;I&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Default map rows live in &lt;code&gt;elcity-maps.el&lt;/code&gt;(&lt;code&gt;elcity-map-default-rows&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Default map size is set by &lt;code&gt;elcity-core-map-width&lt;/code&gt;and&lt;code&gt;elcity-core-map-height&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;make test&lt;/code&gt;runs ERT tests.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;make lint&lt;/code&gt;runs package lint, checkdoc, and byte compilation.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;make compile&lt;/code&gt;byte-compiles non-test files.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;elcity.el&lt;/code&gt;entry point that wires core and UI&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;elcity-core.el&lt;/code&gt;pure simulation and state transitions&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;elcity-tiles.el&lt;/code&gt;tile definitions and effect metadata&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;elcity-ui.el&lt;/code&gt;UI shell and input handling&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;elcity-maps.el&lt;/code&gt;map presets&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;test/&lt;/code&gt;ERT tests&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46897332</guid><pubDate>Thu, 05 Feb 2026 08:46:13 +0000</pubDate></item><item><title>If you've got Nothing to Hide (2015)</title><link>https://jacquesmattheij.com/if-you-have-nothing-to-hide/</link><description>&lt;doc fingerprint="7e23595264b3175d"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;The Past&lt;/head&gt;
    &lt;p&gt;Since 1851 Amsterdam had a registry that recorded the following innocent pieces of data about the residents: Name, Date of birth, Address, Marital Status, Parents, Profession, Religion, Previous Addresses and Date of Death if deceased. For many years this system served well and was kept meticulously up to date.&lt;/p&gt;
    &lt;p&gt;Which undoubtedly well meaning civil servant long before World War II came up with the brilliant idea of registering religious affiliation during the census is lost in the mists of time. What we do know is that that little field caused untold thousands of people to die once the occupiers decided to use it to locate Jewish people. And there were many of those in Amsterdam, which was home to roughly 80,000 Jews (Dutch) of the total of about 104,000 in all of the Netherlands at the outbreak of the war. 70,000 of them had their data entered into the Amsterdam registry.&lt;/p&gt;
    &lt;p&gt;Once the civil registry was in the hands of the enemy the extermination program for Amsterdam based Jews (those that had not fled) moved into high gear and street after street was raided. Entire neighbourhoods stood empty. The importance of the registry was not lost on the resistance who planned and executed a brave attack (Dutch) to destroy as much of the registry as they could by firebombing it after subduing the guards. The attackers were betrayed to the Nazis and all but two were executed in the dunes near Overveen. Even though the attack was not a complete success a chunk of the registry was destroyed entirely (about 15%), and a large chunk of the remainder suffered substantial water damage thanks to the fire brigades doing their utmost to drown the parts that had not burnt (after dragging their heels as long as possible to let the building burn as much as they could get away with without raising suspicion that they knew what was up).&lt;/p&gt;
    &lt;p&gt;All in all more of a delaying action than a complete success but still, quite the coup and the Nazis were seriously angry they lost access to those records. 80% of the Jews in Amsterdam were killed by the Nazis, without the attack on the registry that percentage probably would have likely approached 100% except for those that had already fled the country at the outbreak of the war. That’s how much of a help the registry was in determining who to look for and where.&lt;/p&gt;
    &lt;p&gt;Because the attack on the civil registry in Amsterdam is widely appreciated as an example of the work the resistance did during the war it is still very much present in the Dutch collective consciousness (though, unfortunately, less so with the passing of time). Apparently innocent database fields suddenly came back to bite a very large group of citizens.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Present&lt;/head&gt;
    &lt;p&gt;In the United States recently something related happened. The Office of Personnel Management (OPM) had an enormous breach leading to the release of 20 million+(!!) files on people employed by the government and those that they associate with. This database apparently existed to aid in determining who could be given what level of clearance and because of that contained all kinds of juicy tidbits as well as complete identity information and a large amount of meta information in terms of who is linked to who by family ties or friendships as well as co-workers (especially abroad) and other such information.&lt;/p&gt;
    &lt;p&gt;It doesn’t require much of an imagination to see how this information could be abused, note that it is closely resembling the situation with the Amsterdam registry in that the original goals of making the database may have been relatively innocent the data suddenly took on a totally different meaning when the ownership of the data changed.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Future&lt;/head&gt;
    &lt;p&gt;One of the mantras that I keep hearing in the wake of the Snowden revelations is that ‘if you’ve got nothing to hide you’ve got nothing to fear’, usually bandied around by upstanding citizens who have done ‘nothing wrong’ and therefore applaud any and all privacy invasions because after all, those privacy invasions on the surface do not seem to affect them.&lt;/p&gt;
    &lt;p&gt;The Amsterdam civil registry take-over and the OPM breach are good illustrations of what can go wrong even if you have done ‘nothing wrong’, after all almost all of those affected have done nothing wrong and yet their privacy has been violated in a pretty drastic manner leading to death, identity theft or embarassement.&lt;/p&gt;
    &lt;p&gt;If they had nothing to hide because they had done nothing wrong then what’s the fuss about?&lt;/p&gt;
    &lt;p&gt;Well, that’s an easy one: The fuss is that even if you have absolutely nothing to hide the ‘privacy is dead’ crowd seems to miss out on the fact that privacy by itself is considered important enough to make it into the Universal Declaration of Human Rights, Article 12, and that ‘privacy’ is not the same as ‘secrecy’, in other words having done something wrong or not does not bear at all on the question of whether or not privacy is a useful thing or merely a luxury we can afford to do without since a lack of privacy only affects those that have done something wrong (which is clearly false!). You don’t have to have any dark secrets in order to to value your privacy.&lt;/p&gt;
    &lt;p&gt;If you really strongly feel that you have nothing that you consider private ask yourself this: Even if you have done nothing wrong, are you willing to publish your pin code, a high resolution scan of your signature, your passport, your SSN, your passwords, your photographs (naked, preferably), your medical records, the conversations with your attorney, the amount of money you currently have, your criminal record (if you have any), your bank statements, your tax returns for the last 10 years, your license plate and a copy of your driving license, your sexual orientation, your infidelities, the names of the people that you love, the names of the people you despise, the contents of your diary, all the emails you ever wrote and received, your report cards, your entire credit history, all the stuff you ever bought, all the movies you’ve ever watched, all the books you ever read, your religion, your home address and so on for all the world to see?&lt;/p&gt;
    &lt;p&gt;If you’re willing to do all of that then congratulations, you really have nothing to hide and the word ‘privacy’ means nothing to you. But if you answer so much as ‘no’ to any one of those or to any bit of information that you yourself come up with that you’d rather not share with the world then you too value privacy.&lt;/p&gt;
    &lt;p&gt;And if you’re not content with living in a world where all of that data is public then you’d better stop repeating that silly mantra ‘if you’ve got nothing to hide then you’ve got nothing to fear’, even if instead of death or identity theft your problems might merely be those of inconvenience or embarassment when your data gets re-purposed in ways that you could not imagine when you sent it out in the world in a careless manner, and when you helped erode the concept of privacy as a great good that needs to be protected rather than sacrificed on the altar of commerce or of national security (especially from some ill defined bogey man, such as the terrorists).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46897620</guid><pubDate>Thu, 05 Feb 2026 09:24:51 +0000</pubDate></item><item><title>Nanobot: Ultra-Lightweight Alternative to OpenClaw</title><link>https://github.com/HKUDS/nanobot</link><description>&lt;doc fingerprint="ae46eed130930a53"&gt;
  &lt;main&gt;
    &lt;p&gt;🐈 nanobot is an ultra-lightweight personal AI assistant inspired by Clawdbot&lt;/p&gt;
    &lt;p&gt;⚡️ Delivers core agent functionality in just ~4,000 lines of code — 99% smaller than Clawdbot's 430k+ lines.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2026-02-04 🚀 v0.1.3.post4 released with multi-provider &amp;amp; Docker support! Check release notes for details.&lt;/item&gt;
      &lt;item&gt;2026-02-01 🎉 nanobot launched! Welcome to try 🐈 nanobot!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;🪶 Ultra-Lightweight: Just ~4,000 lines of code — 99% smaller than Clawdbot - core functionality.&lt;/p&gt;
    &lt;p&gt;🔬 Research-Ready: Clean, readable code that's easy to understand, modify, and extend for research.&lt;/p&gt;
    &lt;p&gt;⚡️ Lightning Fast: Minimal footprint means faster startup, lower resource usage, and quicker iterations.&lt;/p&gt;
    &lt;p&gt;💎 Easy-to-Use: One-click to depoly and you're ready to go.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;📈 24/7 Real-Time Market Analysis&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;🚀 Full-Stack Software Engineer&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;📅 Smart Daily Routine Manager&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;📚 Personal Knowledge Assistant&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Discovery • Insights • Trends&lt;/cell&gt;
        &lt;cell&gt;Develop • Deploy • Scale&lt;/cell&gt;
        &lt;cell&gt;Schedule • Automate • Organize&lt;/cell&gt;
        &lt;cell&gt;Learn • Memory • Reasoning&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Install from source (latest features, recommended for development)&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/HKUDS/nanobot.git
cd nanobot
pip install -e .&lt;/code&gt;
    &lt;p&gt;Install with uv (stable, fast)&lt;/p&gt;
    &lt;code&gt;uv tool install nanobot-ai&lt;/code&gt;
    &lt;p&gt;Install from PyPI (stable)&lt;/p&gt;
    &lt;code&gt;pip install nanobot-ai&lt;/code&gt;
    &lt;p&gt;Tip&lt;/p&gt;
    &lt;p&gt;Set your API key in &lt;code&gt;~/.nanobot/config.json&lt;/code&gt;.
Get API keys: OpenRouter (LLM) · Brave Search (optional, for web search)
You can also change the model to &lt;code&gt;minimax/minimax-m2&lt;/code&gt; for lower cost.&lt;/p&gt;
    &lt;p&gt;1. Initialize&lt;/p&gt;
    &lt;code&gt;nanobot onboard&lt;/code&gt;
    &lt;p&gt;2. Configure (&lt;code&gt;~/.nanobot/config.json&lt;/code&gt;)&lt;/p&gt;
    &lt;code&gt;{
  "providers": {
    "openrouter": {
      "apiKey": "sk-or-v1-xxx"
    }
  },
  "agents": {
    "defaults": {
      "model": "anthropic/claude-opus-4-5"
    }
  },
  "tools": {
    "web": {
      "search": {
        "apiKey": "BSA-xxx"
      }
    }
  }
}&lt;/code&gt;
    &lt;p&gt;3. Chat&lt;/p&gt;
    &lt;code&gt;nanobot agent -m "What is 2+2?"&lt;/code&gt;
    &lt;p&gt;That's it! You have a working AI assistant in 2 minutes.&lt;/p&gt;
    &lt;p&gt;Run nanobot with your own local models using vLLM or any OpenAI-compatible server.&lt;/p&gt;
    &lt;p&gt;1. Start your vLLM server&lt;/p&gt;
    &lt;code&gt;vllm serve meta-llama/Llama-3.1-8B-Instruct --port 8000&lt;/code&gt;
    &lt;p&gt;2. Configure (&lt;code&gt;~/.nanobot/config.json&lt;/code&gt;)&lt;/p&gt;
    &lt;code&gt;{
  "providers": {
    "vllm": {
      "apiKey": "dummy",
      "apiBase": "http://localhost:8000/v1"
    }
  },
  "agents": {
    "defaults": {
      "model": "meta-llama/Llama-3.1-8B-Instruct"
    }
  }
}&lt;/code&gt;
    &lt;p&gt;3. Chat&lt;/p&gt;
    &lt;code&gt;nanobot agent -m "Hello from my local LLM!"&lt;/code&gt;
    &lt;p&gt;Tip&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;apiKey&lt;/code&gt; can be any non-empty string for local servers that don't require authentication.&lt;/p&gt;
    &lt;p&gt;Talk to your nanobot through Telegram, WhatsApp, or Feishu — anytime, anywhere.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Channel&lt;/cell&gt;
        &lt;cell role="head"&gt;Setup&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Telegram&lt;/cell&gt;
        &lt;cell&gt;Easy (just a token)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Medium (scan QR)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Feishu&lt;/cell&gt;
        &lt;cell&gt;Medium (app credentials)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head&gt;Telegram (Recommended)&lt;/head&gt;
    &lt;p&gt;1. Create a bot&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Open Telegram, search &lt;code&gt;@BotFather&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Send &lt;code&gt;/newbot&lt;/code&gt;, follow prompts&lt;/item&gt;
      &lt;item&gt;Copy the token&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;2. Configure&lt;/p&gt;
    &lt;code&gt;{
  "channels": {
    "telegram": {
      "enabled": true,
      "token": "YOUR_BOT_TOKEN",
      "allowFrom": ["YOUR_USER_ID"]
    }
  }
}&lt;/code&gt;
    &lt;quote&gt;&lt;p&gt;Get your user ID from&lt;/p&gt;&lt;code&gt;@userinfobot&lt;/code&gt;on Telegram.&lt;/quote&gt;
    &lt;p&gt;3. Run&lt;/p&gt;
    &lt;code&gt;nanobot gateway&lt;/code&gt;
    &lt;p&gt;Requires Node.js ≥18.&lt;/p&gt;
    &lt;p&gt;1. Link device&lt;/p&gt;
    &lt;code&gt;nanobot channels login
# Scan QR with WhatsApp → Settings → Linked Devices&lt;/code&gt;
    &lt;p&gt;2. Configure&lt;/p&gt;
    &lt;code&gt;{
  "channels": {
    "whatsapp": {
      "enabled": true,
      "allowFrom": ["+1234567890"]
    }
  }
}&lt;/code&gt;
    &lt;p&gt;3. Run (two terminals)&lt;/p&gt;
    &lt;code&gt;# Terminal 1
nanobot channels login

# Terminal 2
nanobot gateway&lt;/code&gt;
    &lt;head&gt;Feishu (飞书)&lt;/head&gt;
    &lt;p&gt;Uses WebSocket long connection — no public IP required.&lt;/p&gt;
    &lt;code&gt;pip install nanobot-ai[feishu]&lt;/code&gt;
    &lt;p&gt;1. Create a Feishu bot&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Visit Feishu Open Platform&lt;/item&gt;
      &lt;item&gt;Create a new app → Enable Bot capability&lt;/item&gt;
      &lt;item&gt;Permissions: Add &lt;code&gt;im:message&lt;/code&gt;(send messages)&lt;/item&gt;
      &lt;item&gt;Events: Add &lt;code&gt;im.message.receive_v1&lt;/code&gt;(receive messages)&lt;list rend="ul"&gt;&lt;item&gt;Select Long Connection mode (requires running nanobot first to establish connection)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Get App ID and App Secret from "Credentials &amp;amp; Basic Info"&lt;/item&gt;
      &lt;item&gt;Publish the app&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;2. Configure&lt;/p&gt;
    &lt;code&gt;{
  "channels": {
    "feishu": {
      "enabled": true,
      "appId": "cli_xxx",
      "appSecret": "xxx",
      "encryptKey": "",
      "verificationToken": "",
      "allowFrom": []
    }
  }
}&lt;/code&gt;
    &lt;quote&gt;&lt;code&gt;encryptKey&lt;/code&gt;and&lt;code&gt;verificationToken&lt;/code&gt;are optional for Long Connection mode.&lt;code&gt;allowFrom&lt;/code&gt;: Leave empty to allow all users, or add&lt;code&gt;["ou_xxx"]&lt;/code&gt;to restrict access.&lt;/quote&gt;
    &lt;p&gt;3. Run&lt;/p&gt;
    &lt;code&gt;nanobot gateway&lt;/code&gt;
    &lt;quote&gt;
      &lt;p&gt;[!TIP] Feishu uses WebSocket to receive messages — no webhook or public IP needed!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Config file: &lt;code&gt;~/.nanobot/config.json&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;Groq provides free voice transcription via Whisper. If configured, Telegram voice messages will be automatically transcribed.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Provider&lt;/cell&gt;
        &lt;cell role="head"&gt;Purpose&lt;/cell&gt;
        &lt;cell role="head"&gt;Get API Key&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;openrouter&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;LLM (recommended, access to all models)&lt;/cell&gt;
        &lt;cell&gt;openrouter.ai&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;anthropic&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;LLM (Claude direct)&lt;/cell&gt;
        &lt;cell&gt;console.anthropic.com&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;openai&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;LLM (GPT direct)&lt;/cell&gt;
        &lt;cell&gt;platform.openai.com&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;deepseek&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;LLM (DeepSeek direct)&lt;/cell&gt;
        &lt;cell&gt;platform.deepseek.com&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;groq&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;LLM + Voice transcription (Whisper)&lt;/cell&gt;
        &lt;cell&gt;console.groq.com&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;gemini&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;LLM (Gemini direct)&lt;/cell&gt;
        &lt;cell&gt;aistudio.google.com&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head&gt;Full config example&lt;/head&gt;
    &lt;code&gt;{
  "agents": {
    "defaults": {
      "model": "anthropic/claude-opus-4-5"
    }
  },
  "providers": {
    "openrouter": {
      "apiKey": "sk-or-v1-xxx"
    },
    "groq": {
      "apiKey": "gsk_xxx"
    }
  },
  "channels": {
    "telegram": {
      "enabled": true,
      "token": "123456:ABC...",
      "allowFrom": ["123456789"]
    },
    "whatsapp": {
      "enabled": false
    },
    "feishu": {
      "enabled": false,
      "appId": "cli_xxx",
      "appSecret": "xxx",
      "encryptKey": "",
      "verificationToken": "",
      "allowFrom": []
    }
  },
  "tools": {
    "web": {
      "search": {
        "apiKey": "BSA..."
      }
    }
  }
}&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Command&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;nanobot onboard&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Initialize config &amp;amp; workspace&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;nanobot agent -m "..."&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Chat with the agent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;nanobot agent&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Interactive chat mode&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;nanobot gateway&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Start the gateway&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;nanobot status&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Show status&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;nanobot channels login&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Link WhatsApp (scan QR)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;nanobot channels status&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Show channel status&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head&gt;Scheduled Tasks (Cron)&lt;/head&gt;
    &lt;code&gt;# Add a job
nanobot cron add --name "daily" --message "Good morning!" --cron "0 9 * * *"
nanobot cron add --name "hourly" --message "Check status" --every 3600

# List jobs
nanobot cron list

# Remove a job
nanobot cron remove &amp;lt;job_id&amp;gt;&lt;/code&gt;
    &lt;p&gt;Tip&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;-v ~/.nanobot:/root/.nanobot&lt;/code&gt; flag mounts your local config directory into the container, so your config and workspace persist across container restarts.&lt;/p&gt;
    &lt;p&gt;Build and run nanobot in a container:&lt;/p&gt;
    &lt;code&gt;# Build the image
docker build -t nanobot .

# Initialize config (first time only)
docker run -v ~/.nanobot:/root/.nanobot --rm nanobot onboard

# Edit config on host to add API keys
vim ~/.nanobot/config.json

# Run gateway (connects to Telegram/WhatsApp)
docker run -v ~/.nanobot:/root/.nanobot -p 18790:18790 nanobot gateway

# Or run a single command
docker run -v ~/.nanobot:/root/.nanobot --rm nanobot agent -m "Hello!"
docker run -v ~/.nanobot:/root/.nanobot --rm nanobot status&lt;/code&gt;
    &lt;code&gt;nanobot/
├── agent/          # 🧠 Core agent logic
│   ├── loop.py     #    Agent loop (LLM ↔ tool execution)
│   ├── context.py  #    Prompt builder
│   ├── memory.py   #    Persistent memory
│   ├── skills.py   #    Skills loader
│   ├── subagent.py #    Background task execution
│   └── tools/      #    Built-in tools (incl. spawn)
├── skills/         # 🎯 Bundled skills (github, weather, tmux...)
├── channels/       # 📱 WhatsApp integration
├── bus/            # 🚌 Message routing
├── cron/           # ⏰ Scheduled tasks
├── heartbeat/      # 💓 Proactive wake-up
├── providers/      # 🤖 LLM providers (OpenRouter, etc.)
├── session/        # 💬 Conversation sessions
├── config/         # ⚙️ Configuration
└── cli/            # 🖥️ Commands
&lt;/code&gt;
    &lt;p&gt;PRs welcome! The codebase is intentionally small and readable. 🤗&lt;/p&gt;
    &lt;p&gt;Roadmap — Pick an item and open a PR!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Voice Transcription — Support for Groq Whisper (Issue #13)&lt;/item&gt;
      &lt;item&gt;Multi-modal — See and hear (images, voice, video)&lt;/item&gt;
      &lt;item&gt;Long-term memory — Never forget important context&lt;/item&gt;
      &lt;item&gt;Better reasoning — Multi-step planning and reflection&lt;/item&gt;
      &lt;item&gt;More integrations — Discord, Slack, email, calendar&lt;/item&gt;
      &lt;item&gt;Self-improvement — Learn from feedback and mistakes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt; Thanks for visiting ✨ nanobot!&lt;/p&gt;
    &lt;p&gt;nanobot is for educational, research, and technical exchange purposes only&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46897737</guid><pubDate>Thu, 05 Feb 2026 09:39:11 +0000</pubDate></item></channel></rss>