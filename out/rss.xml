<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 06 Oct 2025 07:34:47 +0000</lastBuildDate><item><title>Self hosting 10TB in S3 on a framework laptop and disks</title><link>https://jamesoclaire.com/2025/10/05/self-hosting-10tb-in-s3-on-a-framework-laptop-disks/</link><description>&lt;doc fingerprint="108fdf7d4527a9d6"&gt;
  &lt;main&gt;
    &lt;p&gt;About 5 months ago I made the decision to start self hosting my own S3. I was working on AppGoblin’s SDK tracking of the top 100k Android and iOS apps so was wanting a lot of space, but for cheap.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;I got really lucky with getting a second hand Framework laptop. The laptop was missing it’s screen, and was one of the older ones, so it was perfect for a home server. In addition I bought a “just a bunch of disks” JBOD. The framework laptop is running ZFS + garage S3. &lt;/p&gt;
    &lt;head rend="h2"&gt;I’m happy to report I haven’t thought about this laptop for months&lt;/head&gt;
    &lt;p&gt;I’ve been away, I’ve been working, I’ve been busy, and I’ve definitely been using my S3. But I hadn’t thought about the laptop in 4 months. When I finally logged in, I saw I’ve used 10TB of space and it was patiently waiting for a restart for some upgrades. I nervously restarted, and was so relieved to see everything come right back up.&lt;/p&gt;
    &lt;head rend="h2"&gt;I updated garage s3 with no issues as well&lt;/head&gt;
    &lt;p&gt;I also saw a pending upgrade for garage v1 to v2. This went along without a hitch too. Feels like it’s been a good weekend.&lt;/p&gt;
    &lt;head rend="h2"&gt;I’ve been warned…&lt;/head&gt;
    &lt;p&gt;Just so you know, I understand my use case for ZFS is possibly a bit non standard as I’m using a USB to connect the laptop and JBOD. This initially caused me issues with ZFS when garage was heavily reading and writing (the initial setup had the SQLite metadata also stored on the JBOD/ZFS).&lt;/p&gt;
    &lt;p&gt;I moved my metadata to the laptop, which has so far resolved any ZFS issues again.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45480317</guid><pubDate>Sun, 05 Oct 2025 09:51:26 +0000</pubDate></item><item><title>86 GB/s bitpacking with ARM SIMD (single thread)</title><link>https://github.com/ashtonsix/perf-portfolio/tree/main/bytepack</link><description>&lt;doc fingerprint="3b74d0de090e4684"&gt;
  &lt;main&gt;
    &lt;p&gt;We read every piece of feedback, and take your input very seriously.&lt;/p&gt;
    &lt;p&gt;To see all available qualifiers, see our documentation.&lt;/p&gt;
    &lt;p&gt;There was an error while loading. Please reload this page.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45481008</guid><pubDate>Sun, 05 Oct 2025 12:27:11 +0000</pubDate></item><item><title>The QNX Operating System</title><link>https://www.abortretry.fail/p/the-qnx-operating-system</link><description>&lt;doc fingerprint="ff9e891d51a325c6"&gt;
  &lt;main&gt;
    &lt;p&gt;Gordon Bell and Dan Dodge were finishing their time at the University of Waterloo in Ontario in 1979. In pursuit of their masters degrees, they’d worked on a system called Thoth in their real-time operating systems course. Thoth was interesting not only for having been real-time and having featured synchronous message passing, but also for originally having been written in the B programming langue. It was then rewritten in the UW-native Eh language (fitting for a Canadian university), and then finally rewritten in Zed. It is this last, Zed-written, version of Thoth to which Bell and Dodge would have been exposed. Having always been written in a high-level language, the system was portable, and programs were the same regardless of the underlying hardware. Both by convention and by design, Thoth strongly encouraged programs to be structured as networks of communicating processes. As the final project for the RTOS course, students were expected to implement a real-time system of their own. This experience was likely pivotal to their next adventure.&lt;/p&gt;
    &lt;p&gt;The duo’s first year after graduation was a busy one. They moved to Kanata, went to work for Bell-Northern Research (now Nortel), and on the 30th of March in 1980, they founded Quantum Software Systems. To continue their research and experimentation with operating systems, they assembled a microcomputer built around a Motorola 6809. With the release of the IBM PC in September of 1981, Quantum’s efforts shifted to that target. Their goal was to produce a real-time operating system that would enable the PC’s use in factories, communication systems, and anywhere else that emphasized reliability.&lt;/p&gt;
    &lt;p&gt;The first version of Bell and Dodge’s operating system was QUNIX 0.1 (the Q could have been for Quantum, or for Quick, I’ve seen both from former Quantum employees), and it was running on that early, hand-assembled, 8bit microcomputer. This earliest creation was never released outside of Quantum Software as far as I know. QUNIX was a vaguely UNIX-like, microkernel, real-time operating system. I say that it was vaguely UNIX-like because in these early versions, there were some serious differences. In QUNIX, there were CP/M-like things too. Each disk had a drive number prefix, non-disk device files’ names were reserved, and the commands were a bit different from those in UNIX, often simplified to the point of being more CP/M-like than UNIX-like. Another major difference was the directory hierarchy. On a traditional UNIX system, binaries were stored in &lt;code&gt;/bin&lt;/code&gt; or &lt;code&gt;/usr/bin&lt;/code&gt;, configurations in &lt;code&gt;/etc&lt;/code&gt;, and user directories in &lt;code&gt;/home&lt;/code&gt;. On QUNIX, this wasn’t the case. Commands included in the path variable were in &lt;code&gt;/cmds&lt;/code&gt;, configuration files were in &lt;code&gt;/config&lt;/code&gt;, the OS binaries were in &lt;code&gt;/sys&lt;/code&gt;, user directories were &lt;code&gt;/user&lt;/code&gt;, drivers were in &lt;code&gt;/drivers&lt;/code&gt;, and utilities were in &lt;code&gt;/util&lt;/code&gt;. Then, the &lt;code&gt;man&lt;/code&gt; command did not exist, and &lt;code&gt;help&lt;/code&gt; was used instead. Instead of &lt;code&gt;ps&lt;/code&gt;, the system had &lt;code&gt;task&lt;/code&gt; with the labels of father, son, and brother to denote parent and child processes. The first version of QUNIX for the IBM PC was made before the end of 1981, and released either in December of 1981 or January of 1982, making QUNIX the first known microkernel operating system for the PC platform.&lt;/p&gt;
    &lt;p&gt;A fun note from Paul N. Leroux, the bar chart on the monitor in the back left was physically glued to that monitor for another press image. It wasn’t meant to be in this image, but as photo editing tools were essentially non-existent at the time, fixing this would have required them to reshoot. They chose to go to press with bar chart present.&lt;/p&gt;
    &lt;p&gt;With QUNIX 0.4.33 in 1982, QUNIX became the first operating system for the IBM PC to support a hard disk, and in particular, it supported a 5MB Davong HDD. Given that a 10MB disk in 1982 could cost around $3000, it makes sense that the company’s first target was a bit more modest. At this point, however, QUNIX would not boot from an HDD. All of the floppy contents could be copied to a hard disk, but the user would still need to boot from a floppy disk.&lt;/p&gt;
    &lt;p&gt;Even in these early stages of development, the system began getting recognition, and this became a small problem. The name QUNIX was a bit too close to the name UNIX for AT&amp;amp;T. The name of the system was changed to QNX in late 1982 following a Cease and Desist by AT&amp;amp;T. The first official QNX version was released the following year. At the time of the name change the kernel consisted of around 10K line of C, and it handled task scheduling, message passing, and task priority. Everything else was implemented in services that used the microkernel’s message passing to communicate with each other (even drivers, filesystems, and networking). As an important feature, message queues were network transparent so a task on one physical machine could communicate with a task on a separate physical machine on the same network as easily as if it were local. This inherently multitasked and multiuser system allowed 250 simultaneous tasks from 4 to 16 simultaneous users. The system would make extensive use of the 8087 if it was available, and required a minimum of 96K RAM. Loading up the C compiler would require an additional 32K. It’s impressive what the small company achieved on the 8088, even if, for the time, the RAM requirements were quite high. QNX release version 1.0, in March of 1983, running on an IBM PC achieved 29% to 47% the speed of a DEC VAX 11/780 depending upon the task at hand when tested by Rao Mikkilineni at Bell Labs. Sadly, I’ve been unable to find his original write-up of his testing, which was apparently in the publication Personna. If you have information about it, I’d love to get some details. While RV1 was limited to just C and x86 assembly language, the company was hard at work on BASIC, FORTRAN, and Pascal compilers that would utilize common code generators allowing for the mixed-use of languages without losing optimization. With the introduction of GUIs on the Apple Lisa, Xerox systems, and VisiCorp’s Visi-On, Quantum also had plans for windowing as well. According to Quantum’s president Syd Geraghty in InfoWorld on the 21st of March in 1983, the majority of customers were high-end system developers at large corporations. Version 1.0 cost $650 in 1983 (around $2100 in 2025), and that included a C compiler, full-screen editor, the ability to read MS-DOS disks, and full networking support. I haven’t found much information about versions 1.1 through 1.14, but I did find some information about 1.20 released on the 15th of November in 1984. This version brought pattern matching on filenames in the current directory, expanded shell programming, &lt;code&gt;login&lt;/code&gt; was now a separate task with fast user switching and login stacking, &lt;code&gt;TCAP&lt;/code&gt; (think terminfo), &lt;code&gt;ed&lt;/code&gt; was rewritten and supported full-screen visual mode (think Vi), and support for the IBM AT (real-mode) was added. The price of QNX had also fallen to $450.&lt;/p&gt;
    &lt;p&gt;In June of 1981, the Ontario Ministry of Education identified computing as being important for the future, and they wanted to bring computing into their schools. They were also quite aware that some teachers had taken the initiative to bring microcomputers into their classrooms already, and the Commodore PET was the most common for programming courses, while the Apple II was the most common for other educational programs. Targeting many computers would have meant that they’d have rather high software development costs in any attempt to achieve standardization, and it was therefore decided that they’d need a single computer. In 1983, it was found by the ministry and the Canadian Advanced Technology Alliance that no existing computer would fully satisfy the goals of their educational computer. By March that year, some requirements had been drafted: all-in-one PET-like design, headphone output for voice and sound, a trackball, an 80186 CPU, a multitasking operating system, color graphics, voice synthesis, keyboard with accented characters, and networked storage (no physical disk in the computer itself). This machine as described had the sobriquet “bionic beaver.”&lt;/p&gt;
    &lt;p&gt;With the specifications in hand, Robert Arn at CATA created CEMCORP (Canadian Educational Microprocessor Corporation) and won a contract from the ministry for $10 million to develop the initial machines. This resulted in the ICON having been chosen. This machine was initially manufactured by Microtel and it ran QNX from Quantum Software Systems. The first machines were delivered in 1984. Later machines were produced, sold, and supported by Burroughs Canada, and after the merger with Sperry in 1986, by Unisys.&lt;/p&gt;
    &lt;p&gt;The ICON was built around an Intel 80186 clocked at 7.16MHz and 512K RAM. It lacked any local storage having neither a hard disk drive nor floppy disk drive. At boot, the computer grabbed QNX from a local LexICON file server over a 2.5Mbps ARCNET connection, and loaded the OS into RAM. Once loaded, the user logged into the system and his/her home directory was on the file server. Up to 32 of these machines could be on a single LAN. Saving any work to a floppy, meant putting the floppy into the file server, and then copying the file from the LexICON hard disk (early models were 10MB, later models were 64MB) to that floppy. The cost of these machines was high at $2500, but any school need only have paid $495 with the government covering the rest. One incredibly forward thinking feature was the lessonware. This would have been a hypertext system in which educators could have written pages that linked to others building an extensive corpus overtime. Even applications could have been run by simply clicking a link. This model was rejected by the ministry before the ICON shipped, and was replaced by a top-down system with ministry making lesson decisions. This also resulted in the ICON having shipped a QNX CLI with the CEMCORP text editor in the earliest models.&lt;/p&gt;
    &lt;p&gt;The ICON was a project hated by many and loved by many. For detractors, it was seen as expensive and wasteful while not exposing students to industry currents. For supporters, it accomplished all of its goals. It was excellent for programming, and it was excellent at multitasking, networking, and running educational software. The software was also quite reliable. It was QNX doing what QNX does best.&lt;/p&gt;
    &lt;p&gt;From students who used ICONs, we know that it did have educational games, text editors, compilers, word processors, spread sheets, circuit design and simulation software, and CAD software. Of course, being networked machines, some unconventional students figured out ways to hack into other machines over the network, print stuff to other students’ screens, and generally cause some chaos. Combined with audio capabilities (later models even included MIDI support), this apparently got a bit out of hand from time to time.&lt;/p&gt;
    &lt;p&gt;I normally wouldn’t show so many ads, but here is a development that is rather interesting. OS/2 had been announced on the 2nd of April in 1987, and Quantum perceived the OS as a real threat. The comparisons to UNIX were now joined by comparisons to OS/2, and QNX wanted to be certain that people understood QNX to be superior. This advertisement also shows us that QNX had responded to OS/2’s ability to run DOS software by adding that feature to QNX with the QDOS II (invoked as &lt;code&gt;QDOS&lt;/code&gt;) emulator, or by running a DOS application as a task via &lt;code&gt;RUNDOS&lt;/code&gt;. QNX had been ported to the IBM PS/2 as well. This was QNX version 2.&lt;/p&gt;
    &lt;p&gt;As far as I can tell, the release of QNX version 2 was announced on the release date of version 1.2. The release of this version appears to have been quite late, and it occurred in autumn of 1987 (two years after the initial release date given). This release brought protected-mode support for the IBM AT, full LAN support with some networking enhancements ported from BSD, support for files of up to one terabyte in size, up to 32 serial ports in one machine, and a somewhat primitive GUI called House about which I can find nothing but the name.&lt;/p&gt;
    &lt;p&gt;While I couldn’t find anything about the House graphical environment, QNX Windows running the Open Look Window Manager (OLWM) is available.&lt;/p&gt;
    &lt;p&gt;In June of 1987, Quantum Software Systems ceased renting their office space, and they moved into a building they’d had built just for them. Following this, the company would expand the building three times, and finally add another building. So, the company moved from 215 Stafford Road to 175 Terrance Mathews Crescent.&lt;/p&gt;
    &lt;p&gt;As late as 1990, QNX advertisements still mentioned performance on the 80286. This seems more as though Quantum didn’t spend much on marketing rather than not having progressed. In Dan Hildebrand’s An Architectural Overview of QNX from April of 1992, we find that the company had developed QNX versions up to 3.15, and articles about operating systems in the tech press had mentioned QNX as one of the systems that took advantage of features in the 80386.&lt;/p&gt;
    &lt;p&gt;In 1989, Quantum Software Systems began work on a dramatic overhaul of the operating system. This new version would be fully POSIX-compliant and increase performance over the prior generation of QNX operating systems. This version, 4.0, was released in 1991. The kernel now had just 14 calls associated with IPC, network, scheduling, and interrupts, and the kernel weighed in at just 7K (605 LOC), allowing the entire kernel to fit in CPU caches of the time. Unlike earlier versions, messages were no longer queued. Instead, they were copied from process to process. Being POSIX-compliant allowed for the easier porting of software, and it also meant that the directory hierarchy was decidedly more familiar to UNIX veterans. Beyond source compatibility, Quantum was actively working on becoming binary compatible with UNIX as of 1992. In 1994, beyond POSIX and performance, QNX 4.1 introduced the QNX Photon microGUI. This system was developed by Patrick Hayden and Robin Burgener. Much like the underlying system, it was built around a microkernel (around 20K), and it was network transparent. A Photon application could have its interface beamed to another QNX 4 machine at any point in time, or it could be dragged from one device to another just as easily. Photon likewise allowed remote monitoring or control of the user interface. This worked regardless of the device class (desktop, laptop, handheld, server). For those who needed it, the X Windows System (X11R5, Motif Window Manager) was also available, though Photon did implement a binary interface library that was X compatible. Being so lightweight allowed the company to release a demo disk that combined networking, a web browser, web server, graphical environment, file manager, text editor, a vector animation demo, and Towers of Hanoi game onto a single 1.44MB floppy. Unlike prior QNX versions, version 4 required at least an Intel 80386 and VGA graphics card. No 16bit systems were supported.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;KANATA, ONTARIO, September, 1994—QNX Software Systems Ltd., developers of the QNX realtime operating system, announced a unique window system targeted for handheld and embedded applications.&lt;/p&gt;&lt;lb/&gt;According to Rob Oakley, Corporate Communications and Product Management, "the Photon Window System is the first of its kind—a GUI built around a graphical microkernel."&lt;lb/&gt;QNX Software Systems designed the Photon Window System as a graphical microkernel and a team of cooperating processes, basing this design on the company's QNX OS, a microkernel network-distributed system.&lt;lb/&gt;Photon's cooperating processes provide the functionality to scale the system up into a full-featured windowing system or down to fit into resource-constrained environments, like handheld personal computers (HPCs) and compact embedded systems.&lt;lb/&gt;Photon provides a rich widget library that operates much like the X Window System widget set, with an X-inspired API. A Motif-like window manager and a code-generating, visual application builder are also available.&lt;lb/&gt;"Photon is extremely light and fast. It runs in only 256K, yet provides enormous GUI functionality," Oakley said.&lt;lb/&gt;Like the QNX OS itself, Photon is network transparent—an HPC running Photon and QNX, equipped with a wireless LAN interface, becomes a transparent extension of the LAN, able to use all the LAN's resources as if they were integrated directly into the HPC. The power this brings to the HPC user is difficult to appreciate—imagine having the power of 100 Pentiums in the palm of your hand!&lt;lb/&gt;According to Dan Dodge, Vice President R&amp;amp;D, "Photon applications are very network distributed. From the application's perspective, all the resources of all the nodes on the LAN look like a single, logical machine. The environment is so transparent that a user can drag applications from one physical screen to another."&lt;lb/&gt;For example, a user in a factory control environment could walk up to a computer and drag an application from the control screen onto an HPC, and then walk out onto the factory floor with it and interact with the live application.&lt;lb/&gt;Although Photon is aimed at compact environments, its dynamic range is extensive. "Photon's API and rich widget library can support high-performance GUI applications with enough functionality to enter the domain of X, while consuming only a fraction of the resources," said Dodge.&lt;lb/&gt;The QNX operating system is a POSIX-certified realtime OS for Intel and AMD processors. Scalable and modular, QNX fits a wide range of environments, from compact embedded controllers to resource-rich X-based development systems, to distributed realtime systems running hundreds of CPUs.&lt;/quote&gt;
    &lt;p&gt;Versions 4.2, 4.22, and 4.24 all released in 1995. The final version 4 release was 4.25 in 1997. At least one QNX 4 installation ran for over 20 years without a reboot at the ESA. This was possible because peripherals could be hotswapped, drivers could be changed, and network nodes could be added or removed without bringing the system down.&lt;/p&gt;
    &lt;p&gt;Notably, we see that in 1994, Quantum renamed itself to QNX Software Systems Limited. And with a new name and a new version of their operating system, the company won some major installs. From POS systems at FasFax that allowed for real-time sales figures from geographically disparate locations, to video conferencing systems at Georgia State University, to factories, power plants, hospitals, set-top boxes, phone systems, trains, jets, the Space Shuttle, ISPs, and even traffic lights. The price for a single license dropped to around $285 at this time, and by 1995, QNX was the leading real-time OS for x86 systems. The majority of the company’s revenue was from large enterprises.&lt;/p&gt;
    &lt;p&gt;Of course, change was coming in the 1990s, and QSSL knew it. The company took the QNX kernel from version 4.24 and forked it. They had multiple goals with this fork. The system needed to be SMP capable, support POSIX, and be more portable to new hardware. The kernel handled only IPC, message passing, interrupts, and timing. Threading became the minimal unit of scheduling. The new Process Manager then used a loader thread that copied a process’s image into memory freeing the Manager to service other requests while a program continued to load. Naturally, being a real-time system, priority levels were used when scheduling any time-critical process, and new processes inherited the priority of their parent by default. The Process Manager weighed in at 32K (same size as the kernel itself) but added memory allocation, process contexts, resource-manager namespaces, and so on. In this new QNX version, the Process Manager ran inside the microkernel’s address space, but was the only element of the OS to do so. Much of the network stack for this version came from NetBSD, and with that came the ability to use NetBSD network drivers. There was another major change that came from the wider UNIX world, GCC. This naturally meant that language support was quite broadened to include not just C, C++ but all of the other languages supported by the GNU Compiler Collection. This became QNX Neutrino 1.0 released in 1996.&lt;/p&gt;
    &lt;p&gt;On the 19th of October in 1998, QSSL announced QNX Neutrino 2.0 which featured UPM (Universal Process Model). In the words of CTO Dan Dodge:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The premise of UPM is simple. Go beyond the limited MMU protection provided by the other major embedded OSs - where only applications are prevented from corrupting memory - and extend that protection down to services at the kernel level. The result? For the first time, MIPS and PowerPC-based embedded systems can intelligently recover from software faults in drivers, protocol stacks, and custom OS extensions - typically without rebooting.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;QNX was branching into non x86 platforms, and this included PowerPC processors: 401, 403GC, 603e, 821, 823, 860; MIPS processors R4000 and R5000; and naturally all x86 CPUs from the 80386 onward. At this stage, however, the development environment was restricted to QNX 4 and Windows 95/98/NT.&lt;/p&gt;
    &lt;p&gt;This announcement was followed by another about a partnership with Amiga:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Cologne, Germany, November 13 - Amiga Inc. today announced a partnership with QNX Software Systems Ltd. to utilize the QNX realtime operating system (RTOS) as the foundation for the next-generation Amiga architecture. The announcement was made at Computer '98 in Cologne.&lt;/p&gt;
      &lt;p&gt;"The Amiga shook the industry in the 80s with world-leading multimedia architecture," said Jeff Schindler, general manager of Amiga Inc. "QNX's RTOS resembles many of Amiga's unique qualities. It provides the foundation in reaching our vision for the rebirth of Amiga in the new millenium."&lt;/p&gt;
      &lt;p&gt;"We see this partnership as a powerful combination of superior OS technologies, common corporate cultures, and shared business vision," said Dan Dodge, Chief Technology Officer and Cofounder of QNX Software Systems Ltd.&lt;/p&gt;
      &lt;p&gt;About Amiga&lt;/p&gt;
      &lt;p&gt;Amiga Inc. is a technology company targeting the next generation of Amiga architecture with a continued focus on multimedia and the Internet. Since the introduction of the Amiga A1000 in 1985, Amiga has represented the embodiment of the efficient use of memory and hard drive capacity, while pioneering industry developments in multimedia, 32-bit multitasking, and autoconfiguration. Amiga led the industry in combining computer graphics, animation, and film sequences with stereo sound known today as multimedia. Visit http://www.amiga.com and http://www.amiga.de.&lt;/p&gt;
      &lt;p&gt;About QSSL&lt;/p&gt;
      &lt;p&gt;Founded in 1980, QNX Software Systems is one of the top three realtime operating-system vendors in the world, with products licensed in more than a million systems worldwide. The company has established a strong customer base in a variety of industries, including aerospace, telecommunications, medical instrumentation, process control, point-of-sale, consumer electronics, finance, and telephony. With products distributed in over 100 countries, the company is headquartered in Ottawa, Canada.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The Amiga port should have been somewhat straightforward considering that Amiga accelerators had been using PowerPC chips, and those chips were now supported by QNX. Gateway’s Amiga team was working closely with QSSL to build a new Amiga (Amiga NG) around the PowerPC G3 and G4 chips running QNX, and these were apparently prototyped as single, dual, and quad processor machines. During alpha testing, Gateway PowerPC boards apparently had some issues, and the two parties blamed one another. By the middle of 1999, Gateway, QSSL, and to some extent Motorola, had poured a hefty sum into the project, and Gateway began insisting on a solid date for the availability of a QNX Neutrino port. Evidently they weren’t satisfied, and I do not believe communication between the two teams, which had one been quite good, was solid by this point. At noon on the 8th of July in 1999, Dan Dodge announced the QNX Developers Network for Amigans. This was followed by another announcement at 15:15 the following day:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Eight months ago we were chosen by Amiga as their foundation OS partner. Our development group was thrilled to be part of the rebirth of such an innovative product. To meet the challenge we knew it would take a tremendous effort on our part. We had a team of people in place working on our part of the Amiga NG soon after the alliance was announced. Over the next few months we involved more and more of our engineering resouces towards making QNX an advanced multi-media platform. Our investment so far has been significant. These are costs we have borne ourselves.&lt;/p&gt;
      &lt;p&gt;It is clear today from Jim's letter that we were not chosen for the next generation Amiga. Naturally we're disappointed. So, where do we stand now? It is not our intent to confuse the Amiga community. We are proud of what we have accomplished and want to include Amigans in what we've achieved. I did make a promise to deliver an operating system and I intend on keeping that promise. I don't want to split the community, nor do I wish to engage in a war of words. I don't ask you to "trust" me or to take me at my word. Both QNX and Amiga have promised to deliver technology into your hands in the very near future. I ask only that your assessment of QNX be based on what we do and what we deliver.&lt;/p&gt;
      &lt;p&gt;Thanks for the overwhelming support we have received so far.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That letter by Jim Collas read, in part:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Dear Amigans,&lt;/p&gt;&lt;p&gt;After months of research and in-depth discussions with all of our technology partners we have decided to use Linux as the primary OS kernel for the new Amiga Operating Environment (OE). I know this decision is a shock to many of you given the previous announcements and activities relative to QNX. This was a very complicated and difficult decision to make and I assure you that I didn't make this decision without a significant amount of research and deliberation. We have been researching Linux since February but didn't finalized our decision until several weeks ago. We were planning to communicate it to the Amiga community in the technology brief that will be released in the next few days.&lt;/p&gt;&lt;p&gt;I am pressed to communicate the Linux decision before the technology brief because of information released by QNX in the last few days. This information had not been reviewed or approved for release by Amiga. In light of our Linux decision, this information is confusing and misleading so I would like to take the time to clarify the situation. I can't disclose any details of the Amiga/QNX discussions because of legally binding confidentiality agreements but I can talk to you about our decision to use the Linux kernel. I think that you will agree that this is the right decision once you understand the reasons for this decision.&lt;/p&gt;&lt;p&gt;Before I continue, I should mention that our technology decision does not reflect negatively on QNX. I believe that QNX is a good company with great technology. I just believe that Linux gives us a better chance of executing our plans successfully. The decision to use QNX as our OS partner on our next generation multimedia convergence computer (MCC) was made late last year. When I took over as president of Amiga in February of this year, I initiated an in-depth review of existing Amiga plans and decisions. As president of Amiga I had to make sure that we were defining a strategy and an execution plan that would allow Amiga and the Amiga community to be successful. We reviewed our strategy, architecture decisions, technology partners, and execution plans. During this review period we also added a number of very talented and experienced people to help us finalize our technology and product decisions. I am confident that we now have a solid and exciting plan that people can have confidence in.&lt;/p&gt;&lt;p&gt;Linux has been picking up substantial momentum over the past year as a viable, open OS alternative in the marketplace. This momentum, the growing commitment to Linux applications from a wide variety of software vendors, and the growing availability of Linux device drivers from hardware vendors, makes it a compelling candidate. Additionally, with all of the significant component suppliers putting resources on writing drivers for Linux it was difficult to get them to port to yet another operating system. Using the Linux OS as a foundation for our Amiga OE allows us to leverage a significant amount of available software drivers and utilities. This allows us to quickly support multiple graphics cards and other peripherals.&lt;/p&gt;&lt;p&gt;Given the above-mentioned advantages, we decided to do an in-depth technical analysis of Linux to determine if it was a suitable OS kernel for our new Amiga operating environment (OE). As we ported parts of our higher level operating environment and AmigaObject architecture to Linux, we discovered some significant performance advantages in the Linux kernel in areas such as distributed object messaging across a network (up to 10X the performance of Windows NT).&lt;/p&gt;&lt;p&gt;Does this mean that the next generation Amiga will not be unique? Absolutely not! Remember that the OS kernel is only one component of the new Amiga OE and the hardware is unique. The revolutionary nature of the Amiga OE is in the way it extends the traditional operating system to provide a host environment for a new class of portable applications - applications that exist in a pervasive networked computing environment. We will be integrating multiple technologies including an efficient windowing environment and a unique user interface. In summary, we decided to use Linux because of the incredible momentum and the fact that it is solid technology and a good foundation for our new Amiga OE.&lt;/p&gt;&lt;p&gt;Additionally, the Linux community is an impressive force that we should be aligned with. We share many common values and objectives with the Linux community. Using Linux as our OS kernel allows us to build a unique and revolutionary operating environment while leveraging the enormous momentum of Linux. The soon to be released technology brief will further explain our architecture and plans for integrating all of the selected technology. Once you read it, I am confident that you will understand the revolutionary nature of the next generation Amiga. I assure you that Amiga and the Amiga community will be a driving force behind the next computer&lt;/p&gt;&lt;lb/&gt;revolution.&lt;/quote&gt;
    &lt;p&gt;As a person using Linux at the time, I believe this to have been the wrong decision. Despite the momentum that Linux had, it wasn’t (still isn’t) as stable, as reliable, or as efficient as QNX. If network performance were a serious consideration, one of the BSDs would have been the better choice. Linux’s hardware support also wasn’t that great in reality. While it could run on quite a bit of kit, it didn’t always support that hardware well, and it didn’t always support all features. Plus, QNX was doing the work to build drivers for the new Amiga. Of course, none of this really mattered. Gateway chose to divest itself of Amiga entirely. The new Amiga Inc. then turned to AmigaOne Partners for Amiga OS 4.&lt;/p&gt;
    &lt;p&gt;QNX Neutrino 2.1 was released in 1999 with support for Java, the Glide API, a wide array of microcontrollers, ARM, StrongARM, and Hitachi SH-4. Interestingly, this release had beta packages including RealPlayer and X in Photon, and it had experimental packages that included Quake 3 Arena and Doom.&lt;/p&gt;
    &lt;p&gt;On the 14th of September in 1999, QNX made an announcement that would shape the future of QNX. The company was partnering with Motorola to develop automobile driver information systems that included in-vehicle navigation, internet access, natural language processing, car audio, multimedia, and vehicle information dashboards. While the Motorola unit responsible for mobileGT wouldn’t last and the unit at IBM working on Java wouldn’t last, QNX would survive and thrive in that segment.&lt;/p&gt;
    &lt;p&gt;QNX version 6 was released on the 18th of January in 2001. The new version was focused on multimedia with streaming video and audio as well as hardware accelerated MPEG encode/decode. The new system included a web based package manager greatly easing the installation of available software. Thankfully, all supported architectures could now be used for developing QNX native software too. Version 6.1 was mostly a patch release and followed later the same year. QSSL was a founding member of the Eclipse Foundation, and QNX software development got quite a bit better with the release of the Momentics Tool Suite on the 4th of June in 2002 (along with QNX 6.2). This was largely the Eclipse IDE combined with a series of plugins that were QNX and Photon oriented.&lt;/p&gt;
    &lt;p&gt;The last release of QNX by QSSL was version 6.3 on the 3rd of June in 2004. This version was visually slightly different, and Voyager was replaced by the Mozilla Suite. The development environment was improved and now offered a clustering framework for the development of networked applications utilizing distributed processing. Among the highlights for this release were SCTP support, IP filter and NAT support, IPv6 support, 2D and 3D graphics layering/compositing, full UTF8 support in Photon, USB2 host support, and support for up to 64GB of RAM on x86 and PPC, up to 1TB on MIPS.&lt;/p&gt;
    &lt;p&gt;On the 27th of October in 2004, QNX Software Systems Limited was purchased by Harman International Industries. Harman specifically wanted to focus on QNX Neutrino in the embedded market, and within that market, specifically on automotive applications where Harman had found a market in audio. Under Harman’s ownership, QNX operated as a separate division led by Dan Dodge as CEO. While QNX did continue to serve networking, medical, and industrial markets, the direction was clear. What had begun with the Motorola partnership in automotive would become the primary market.&lt;/p&gt;
    &lt;p&gt;QNX development continued with 6.3 SP1, SP2, and SP3. Version 6.3.2 was released on the 16th of August in 2006, 6.4 on the 30th of October in 2008, and 6.4.1 in May of 2009. Throughout that time period, QNX had introduced support for Adobe Flash and developed the QNX CAR platform winning a trophy from Adobe for their efforts. This platform was built of modular components allowing manufacturers to mix and match based upon the market segment. QNX was chosen by companies like BMW, Mercedes, Dodge, Toyota, Volkswagen, and Audi. When QNX demoed their automotive systems in the 2007-2009 timeframe, they had concept dashboards. These all ran QNX Neutrino on ARM CPUs (often Freescale i.MX6 or TI Sitara [Cortex A8]) with the EtherCAT motion library, and many demo units had UIs created in Qt5 and QML while a few had hardware accelerated OpenGL interfaces. From 2008 to 2010, QNX had been licensed for use in more than 17 million in-vehicle systems representing an increase of around 130% over those two years. By March of 2010, more than 200 vehicles were already shipping with QNX, and the QNX CAR platform had more than 60 participants. Those participants included 17 auto makers and 26 automotive suppliers.&lt;/p&gt;
    &lt;p&gt;On the 9th of April in 2010, Research in Motion announced their acquisition of QSS from Harman for $200 million:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“RIM is excited about the planned acquisition of QNX Software Systems and we look forward to ongoing collaboration between Harman, QNX and RIM to further integrate and enhance the user experience between smartphones and in-vehicle audio and infotainment systems," said Mike Lazaridis, President and Co-CEO at RIM. "In addition to our interests in expanding the opportunities for QNX in the automotive sector and other markets, we believe the planned acquisition of QNX will also bring other value to RIM in terms of supporting certain unannounced product plans for intelligent peripherals, adding valuable intellectual property to RIM's portfolio and providing long-term synergies for the companies based on the significant and complementary OS expertise that exists within the RIM and QNX teams today."&lt;/p&gt;
      &lt;p&gt;"We welcome the opportunities that a strengthened relationship with RIM will create, as two innovation leaders collaborate to bring new connectivity solutions to the industry," said Dinesh C. Paliwal, Harman's Chairman, President and CEO. "We expect to maintain our close association with QNX and the cutting-edge software solutions it provides to Harman and our customers. We believe our leading customers will fully endorse this move and see it as a major step in advancing seamless connectivity and integration among intelligent devices."&lt;/p&gt;
      &lt;p&gt;"Like Harman, RIM shares our passion for innovation and reliability, so we are absolutely thrilled with this opportunity," said Dan Dodge, CEO, QNX Software Systems. "Moreover, RIM will give us the best of all possible mandates: to continue on our innovation path and to increase investment in our core products, professional services, and go-to-market channels. This is a great time to be a QNX customer, as we focus on collaborating with RIM to create an even more exciting platform for the next generation of connected and embedded devices."&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Also in 2010, QNX gained the QNX Safety kernel variant. This was a version of Neutrino that was security hardened specifically for mission critical applications. This variant continues to this day with the most recent version (8.0) having been independently certified by TÜV Rheinland to meet several standards including ISO 26262 ASIL D, IEC 61508 SIL3, IEC 62304 Class C, and ISO/SAE 21434. Aside from security hardening, the QNX Safety variant is still fully compatible with Neutrino’s native APIs and POSIX.&lt;/p&gt;
    &lt;p&gt;In July of 2010, QNX Neutrino 6.5 was released. This version brought performance improvements to the kernel when systems were seeing high memory utilization, the kernel gained zombie reaping, and it gained address space randomization. SMP support was increased, and CPU support was extended to ARMv7 Cortex A-9. The Photon microGUI saw some refinements. As one would expect, version updates were present for everything imported from BSD, Linux, and GNU. This version could make use of the NetBSD’s Pkgsrc tool.&lt;/p&gt;
    &lt;p&gt;Version 6.5 was forked to create both the BlackBerry Tablet OS and BBX shortly after its creation. The first device to see a QNX-derived operating system from RIM was the PlayBook, which featured an OMAP 4430 SoC (1.5 GHz dual-core A9), PowerVR SGX540 GPU, 1GB of RAM, 16GB of eMMC flash, a 1024 by 600 seven inch LCD, Bluetooth, 802.11n, USB2, micro HDMI, a 5MP rear camera, and a 3MP front camera. It measured 5.1 inches by 7.6 inches, was about 2/5 of inch thick, and it weighed just under a pound.&lt;/p&gt;
    &lt;p&gt;The PlayBook was released on the 19th of April in 2011 to mixed reviews. While many loved the webkit browser, user interface, HDMI output, and multitasking, many loathed the requirement of a BlackBerry to get certain apps working. Additionally, there was a dearth of third party applications. This latter complaint did get ameliorated. While at launch there weren’t too many applications, this grew to over 24,000 by the same time the following year. Around 2,465,000 PlayBooks had been sold by June of 2013.&lt;/p&gt;
    &lt;p&gt;The BlackBerry Z10 was released on the 31st of January in 2013 running BBX (officially BlackBerry 10 due to a trademark dispute, and at the launch event for BBX, Research in Motion announced that they were changing their name to BlackBerry Limited). The Z10 was built around a Qualcomm Snapdragon S4 Plus SoC (dual core 1.5GHz Krait CPU, Adreno 225 GPU) for LTE units, or around the TI OMAP 4470 for non-LTE units. The shell was plastic wrapped around a stainless steel inner frame, and the on/off, voice command, and volume buttons on the right side were of metal. While it didn’t have quite the premium feel of an iPhone, it did feel good in the hand. In its dimensions it was 5.1 inches by 2.6 inches, and just over an 1/3 of an inch thick (or just slightly larger than an iPhone 5). It was a slick piece of kit with a high price for the time at $599. The display, however, was excellent. It was a 4.2 inch LCD with a resolution of 1280 by 768 at 355ppi (the iPhone 5 was 326ppi). The device had a 2MP font camera, and an 8MP rear camera capable of HDR, panorama, and 1080p video at 30fps. Wi-Fi was dual band 802.11n, and the device featured Bluetooth, GPS, and NFC. Of course, connectivity didn’t stop there. This device had physical ports: micro USB2, micro HDMI, and 3.5mm audio.&lt;/p&gt;
    &lt;p&gt;BBX made heavy use of gestures with a swipe up from the bottom taking the user to the Home Screen, a swipe to right to hit the App Library, and a swipe to the left going to the BlackBerry Hub. The Hub was a combination of SMS/MMS, email, social media, chat, notifications, and calls in a single unified location. BBX was QNX Neutrino, but it did differ. Multitasking was limited to 8 applications at any one time which I believe to have been done due to the application frameworks. A developer could choose to use C/C++ and the Cascades UI framework, or WebWorks which utilized HTML5 with Zepto.js (JQuery API, but 8.4k compressed), or WebKit, or Adobe AIR (Flash), or Android runtime. With so many different application types, decisions would have had to have been made around resource management, and a best guess at when performance would become unacceptable.&lt;/p&gt;
    &lt;p&gt;BlackBerry had been unable to compete against the iPhone and Android, and BBX was their last, best hope. By 2014, BBX was in the number four spot behind Windows Phone. By 2017, it was clear that they weren’t going to survive in the mobile market. Due to the extreme devotion of their fans, they kept BBX on life support until 2022. Being an amazing OS running on good hardware, why did BBX fail? Likely, the most pressing problem was application support. While BBX could run some Android applications, support was limited. The platform likewise failed to grab many developers as the existing install bases for iOS and Android were enormous. What applications were made for BBX were often of quite low effort. Finally, moving to a touch screen angered BlackBerry’s existing fanbase. For those individuals hanging on to the BlackBerry ecosystem, the keyboard was one of the main reasons why. Removing the physical keyboard made many of those fans feel betrayed. When BlackBerry Limited did release another phone with a physical keyboard, it was a bit too late.&lt;/p&gt;
    &lt;p&gt;On the 20th of September in 2013, BlackBerry Limited announced a 4500 person staff reduction and $1 billion (CAD) loss. On the 23rd, they announced an acquisition by Fairfax Financial Holdings for $9/share. This deal was canceled in November. Instead, John Chen became CEO and initiated a turn around that focused on QNX’s former markets of healthcare, finance, law, and mission critical systems. This focus allowed the company to pick up Ford Motor Company as a QNX customer on the 11th of December in 2014 (Ford had previously used Microsoft Auto).&lt;/p&gt;
    &lt;p&gt;On the 28th of February in 2014, BlackBerry released QNX 6.6. The supported platforms were now the expected x86 and ARM CPUs with no mention of any others. This was a major change despite being a point release. Photon support was removed in favor of the Screen Graphics Subsystem. Screen operates as a lower-level service, and this has the benefit of supporting off-screen rendering and compositing of various image sources, and as QNX software had been increasingly using Qt, HTML5, or OpenGL rather than the toolkits supplied with Photon, this made logical sense.&lt;/p&gt;
    &lt;p&gt;QNX version 7 was released on the 4th of January in 2017 for ARM v7, ARM v8, x86, and AMD64. This release featured a rewritten PCI server with APIs moved out of libc and into libpci, rewritten virtual memory manager, fewer synchronization objects with increased limits, and filesystem encryption was moved into the Encrypted Filesystem package available from QNX Software Centry.&lt;/p&gt;
    &lt;p&gt;By June of 2023, QNX was in over 255 million vehicles around the world, and this would explain why the BlackBerry blog featured a rather large section on automobiles:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The automotive evolution to SDVs and “connected cars” requires an OS capable of speed, safety, and security — while unlocking the power to innovate.&lt;/p&gt;
      &lt;p&gt;"With more than 300 million vehicles capable of over-the-air software updates expected to be on the road globally by 2032, automakers are clamoring for better tools to help them develop compelling technology features in the software-defined vehicle," says Alex Oyler, director of North America at SBD Automotive, a leading global automotive technology research and consulting firm.&lt;/p&gt;
      &lt;p&gt;“Both automakers and suppliers rely on validated software and well-integrated development tools to help them more efficiently build and maintain differentiating software for their fleets,” Oyler adds. "A secured-by-design operating system such as the next generation QNX OS — that seamlessly integrates with other software components on a high-performance system-on-chip — represents the foundation of a safe, secure, and seamless experience for drivers.”&lt;/p&gt;
      &lt;p&gt;In addition, early reviews of the new QNX SDP 8.0 give automotive industry leaders a glimpse into what’s possible.&lt;/p&gt;
      &lt;p&gt;“The combination of our DRIVE Thor centralized computer and the new QNX OS will serve as a powerful foundation on which OEMs can build next-generation automotive systems that offer the highest levels of safety and security,” says Ali Kani, vice president and general manager of automotive at NVIDIA. “This represents another major milestone in a nearly 20-year collaboration with BlackBerry QNX that has helped both companies move to the forefront of the automotive industry.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;QNX 8.0 was officially announced in December of 2023, and the release was made in January of 2024. Version 8.0 was quickly discontinued with 8.0.1 taking its place. Version 8.0.3 was made available on the 21st of March in 2024. This latest release is available for a variety of Aarch64 platforms including the Raspberry Pi, and is also available for AMD64. QNX 8 supports SoCs with up to 64 cores and has near linear performance scaling. The network stack is now based upon FreeBSD 13.2, Wi-Fi 6 support is present with WPA3 and TLS 1.3, Screen can operate fully headless and now supports Vulkan 1.3 and OpenCL 3, and Screen now supports Wayland 1.21. Developers are now encouraged to use LLVM and libc++ 16 though GCC is still available with libstdc++ 12.2. Python 3.11, valgrind, libasan (address sanitizer), libubsan (undefined behavior detection), and libunwind are all available. For the UNIX user land, Toybox has replaced many common GNU utilities.&lt;/p&gt;
    &lt;p&gt;If the Raspberry Pi port caught your attention, this is available free for non-commercial use via QNX Everywhere. The image requires a Raspberry Pi 4 with at least 2GB of RAM and an 8GB or greater MicroSD card.&lt;/p&gt;
    &lt;p&gt;On the 2nd of January in 2025, it was announced that BlackBerry IoT would now be known as QNX. This decision was made largely by BlackBerry responding to their customers who recognized and desired the QNX brand. QNX CEO John Giamatteo stated:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Relaunching the QNX brand is an important step in BlackBerry’s broader strategy to increase our visibility and fortify our leadership within the automotive and embedded industries, with a view to better positioning us for sustained growth and success. The values that QNX stands for have always been a cornerstone for our customers and this brand relaunch honors that strong history while setting the stage for the division to fire on all cylinders and drive smarter, safer, and faster innovation through precision-engineered performance.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;QNX is a fascinating operating system. It was extremely well designed from the start, and while it has been rewritten, the core ideas that allowed it survive for 45 years persist to this day. While I am sad that Photon was deprecated, the reasoning is sound. Most vendors using QNX either do not require a GUI, or they implement their own. For example, while Boston Dynamics uses QNX in their robots, they don’t really need Photon, and neither do SpaceX’s Falcon rockets. While cars certainly have displays, most vehicle makers desire their screen interfaces to have a unique look and feel. Of course, just stating these use cases of robots, rockets, and cars speaks to the incredible reliability and versatility of QNX. Better operating systems are possible, and QNX proves it.&lt;/p&gt;
    &lt;p&gt;My dear readers, many of you worked at, ran, or even founded the companies I cover here on ARF, and some of you were present at those companies for the time periods I cover. A few of you have been mentioned by name. All corrections to the record are sincerely welcome, and I would love any additional insights, corrections, or feedback. Please feel free to leave a comment.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45481892</guid><pubDate>Sun, 05 Oct 2025 14:47:13 +0000</pubDate></item><item><title>Show HN: ASCII Drawing Board</title><link>https://www.delopsu.com/draw.html</link><description>&lt;doc fingerprint="f65ec2ddcce25e37"&gt;
  &lt;main&gt;
    &lt;p&gt;Use the List of Unicode characters as a source of characters for your brush ✦ ◒ ▜ █▓▒░ Unfortunately not all of them will work due to font limitations.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45482333</guid><pubDate>Sun, 05 Oct 2025 15:36:21 +0000</pubDate></item><item><title>NFS at 40 – Remembering the Sun Microsystems Network File System</title><link>https://nfs40.online/</link><description>&lt;doc fingerprint="2f90b3e32bf72b79"&gt;
  &lt;main&gt;
    &lt;p&gt;This website gathers material related to the Sun Microsystems Network File System, a project that began in 1983 and remains a fundamental technology for today’s distributed computer systems.&lt;/p&gt;
    &lt;p&gt;The occasion which prompted this project was the ~40th anniversary of NFS, celebrated in September 2025 at the MSST Conference in Santa Clara, CA.&lt;/p&gt;
    &lt;p&gt;The core of the collection is design documents, white papers, engineering specifications, conference and journal papers, and standards material. However it also covers marketing materials, trade press, advertising, books, “swag”, and personal ephemera. We’re always looking for new contributions.&lt;/p&gt;
    &lt;p&gt;We’ve organized the material in four sections:&lt;/p&gt;
    &lt;p&gt;Unless otherwise noted, everything is downloadable from this site.&lt;/p&gt;
    &lt;p&gt;A full list of the Internet RFCs related to NFS can be found here.&lt;/p&gt;
    &lt;p&gt;There is also a site, nfsv4bat.org, which seems to include a variety of materials related to NFS after 1995, especially Connectathons. However, be careful: the site is insecure, load times are insanely slow, and it is unclear whether it’s still being maintained.&lt;/p&gt;
    &lt;p&gt;This website was created with the help of (alphabetically) Russel Berg, Russ Cox, Steve Kleiman, Bob Lyon, Tom Lyon, Joseph Moran, Brian Pawlowski, David Rosenthal, and Kate Stout. Please send any comments or suggestions to me, Geoff Arnold, via email. Last updated .&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45482467</guid><pubDate>Sun, 05 Oct 2025 15:49:58 +0000</pubDate></item><item><title>Fire destroys S. Korean government's cloud storage system, no backups available</title><link>https://koreajoongangdaily.joins.com/news/2025-10-01/national/socialAffairs/NIRS-fire-destroys-governments-cloud-storage-system-no-backups-available/2412936</link><description>&lt;doc fingerprint="fd40bb1beeb70fe1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;NIRS fire destroys government's cloud storage system, no backups available&lt;/head&gt;
    &lt;p&gt; Published: 01 Oct. 2025, 17:59 &lt;/p&gt;
    &lt;p&gt;A fire at the National Information Resources Service (NIRS)'s Daejeon headquarters destroyed the government’s G-Drive cloud storage system, erasing work files saved individually by some 750,000 civil servants, the Ministry of the Interior and Safety said Wednesday.&lt;/p&gt;
    &lt;p&gt;The fire broke out in the server room on the fifth floor of the center, damaging 96 information systems designated as critical to central government operations, including the G-Drive platform. The G-Drive has been in use since 2018, requiring government officials to store all work documents in the cloud instead of on personal computers. It provided around 30 gigabytes of storage per person.&lt;/p&gt;
    &lt;p&gt;However, due to the system’s large-capacity, low-performance storage structure, no external backups were maintained — meaning all data has been permanently lost.&lt;/p&gt;
    &lt;p&gt;The scale of damage varies by agency. The Ministry of Personnel Management, which had mandated that all documents be stored exclusively on G-Drive, was hit hardest. The Office for Government Policy Coordination, which used the platform less extensively, suffered comparatively less damage.&lt;/p&gt;
    &lt;p&gt;The Personnel Ministry stated that all departments are expected to experience work disruptions. It is currently working to recover alternative data using any files saved locally on personal computers within the past month, along with emails, official documents and printed records.&lt;/p&gt;
    &lt;p&gt;The Interior Ministry noted that official documents created through formal reporting or approval processes were also stored in the government’s Onnara system and may be recoverable once that system is restored.&lt;/p&gt;
    &lt;p&gt;“Final reports and official records submitted to the government are also stored in OnNara, so this is not a total loss,” said a director of public services at the Interior Ministry.&lt;/p&gt;
    &lt;p&gt;The Interior Ministry explained that while most systems at the Daejeon data center are backed up daily to separate equipment within the same center and to a physically remote backup facility, the G-Drive’s structure did not allow for external backups. This vulnerability ultimately left it unprotected.&lt;/p&gt;
    &lt;p&gt;Criticism continues to build regarding the government's data management protocols.&lt;/p&gt;
    &lt;p&gt;This article was originally written in Korean and translated by a bilingual reporter with the help of generative AI tools. It was then edited by a native English-speaking editor. All AI-assisted translations are reviewed and refined by our newsroom.&lt;/p&gt;
    &lt;p&gt;BY JEONG JAE-HONG [[email protected]],D&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45483386</guid><pubDate>Sun, 05 Oct 2025 17:20:39 +0000</pubDate></item><item><title>What GPT-OSS leaks about OpenAI's training data</title><link>https://fi-le.net/oss/</link><description>&lt;doc fingerprint="3526435e2833cedc"&gt;
  &lt;main&gt;
    &lt;p&gt;19th of September 2025&lt;/p&gt;
    &lt;p&gt;OpenAI recently released their open-weights model. Here we'll discuss how that inevitably leaks some information about their model training stack, and, on the way, show that GPT-5 was trained on phrases from adult websites.&lt;/p&gt;
    &lt;p&gt;What data does OpenAI train their models on? That is a well-protected trade secret of course, one with vested interest for the answer. While GPT-oss's weights are openly available, the sources of training data are not clearly described in the model card. It is stated that the model was trained on a "text-only dataset with trillions of tokens, with a focus on STEM, coding, and general knowledge". However, as we will see, the model parameters can tell us more than that.&lt;/p&gt;
    &lt;p&gt;A demonstration to start with: Let's have OpenAI's GPT-5We use version GPT-5-2025-08-07 for these experiments. Here is a link to the completion. do the simplest kind of task possible for a language model, repeating a string of Unicode text. Let's choose something random, like the Abkhaz word for "population", which is "ауааԥсыра". Upon asking &lt;code&gt;Repeat after me: "ауааԥсыра"&lt;/code&gt;, it replies something completely different, "ആളുകൾ", which apparently means people in MalayalamAccording to this dictionary. Subsequent translations here are patched together with web searches, online dictionaries and translation software.. As you might have guessed, we did not choose that string randomly at all, it is a special adversarial input belonging to a class of glitch tokens. But how did we identify such a glitch token among the 200,000 tokens that GPT-5 uses?
                            
                        &lt;/p&gt;
    &lt;p&gt;All of OpenAI's models since GPT-4o use the o200k tokenizer. This means that we can use the GPT-oss embeddings to study the token list without having to look at each token's text content. Let's make a histogram of the L2 norm of each row of the embedding matrix.&lt;/p&gt;
    &lt;p&gt;This low L2-norm token group could be useful for two things. Its (1) variance gives an estimate of the variance used in the initialization and (2) its mean would give an estimate of how many gradient descent steps were taken in total, if we assume standard weight decay and know the learning rate.&lt;/p&gt;
    &lt;p&gt;The right tail of the distribution is not quite Gaussian either. Looking at the English tokens with the highest norm, we find:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Token ID&lt;/cell&gt;
        &lt;cell role="head"&gt;Token&lt;/cell&gt;
        &lt;cell role="head"&gt;L2 Norm&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;44041&lt;/cell&gt;
        &lt;cell&gt;' accordingly'&lt;/cell&gt;
        &lt;cell&gt;246.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;3490&lt;/cell&gt;
        &lt;cell&gt;' code'&lt;/cell&gt;
        &lt;cell&gt;243.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;84879&lt;/cell&gt;
        &lt;cell&gt;'ocode'&lt;/cell&gt;
        &lt;cell&gt;235.1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;976&lt;/cell&gt;
        &lt;cell&gt;'The'&lt;/cell&gt;
        &lt;cell&gt;233.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;8743&lt;/cell&gt;
        &lt;cell&gt;' settings'&lt;/cell&gt;
        &lt;cell&gt;231.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;100466&lt;/cell&gt;
        &lt;cell&gt;'Moreover'&lt;/cell&gt;
        &lt;cell&gt;229.0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;6496&lt;/cell&gt;
        &lt;cell&gt;' description'&lt;/cell&gt;
        &lt;cell&gt;226.6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;58369&lt;/cell&gt;
        &lt;cell&gt;"""Let's"""&lt;/cell&gt;
        &lt;cell&gt;224.6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;2500&lt;/cell&gt;
        &lt;cell&gt;'This'&lt;/cell&gt;
        &lt;cell&gt;224.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;10089&lt;/cell&gt;
        &lt;cell&gt;' core'&lt;/cell&gt;
        &lt;cell&gt;219.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;74447&lt;/cell&gt;
        &lt;cell&gt;' utilizes'&lt;/cell&gt;
        &lt;cell&gt;218.6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;119705&lt;/cell&gt;
        &lt;cell&gt;' revolves'&lt;/cell&gt;
        &lt;cell&gt;218.0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;53329&lt;/cell&gt;
        &lt;cell&gt;"""Here's"""&lt;/cell&gt;
        &lt;cell&gt;216.1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;14836&lt;/cell&gt;
        &lt;cell&gt;' possibly'&lt;/cell&gt;
        &lt;cell&gt;214.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;18485&lt;/cell&gt;
        &lt;cell&gt;' logic'&lt;/cell&gt;
        &lt;cell&gt;212.3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;42469&lt;/cell&gt;
        &lt;cell&gt;' thereby'&lt;/cell&gt;
        &lt;cell&gt;211.8&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;These tokens are either very common, or appear especially in reasoning tasks, in particular those with code. This might mean that coding reinforcement learning was the last step in the training process, and that all other tokens got slightly weight decayed. It could also mean that in general, reasoning tokens are treated as so important by gradient descent that their updates are extra large.&lt;/p&gt;
    &lt;p&gt;Filtering for non-ASCII tokens with the highest norm, we find a different picture:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Token ID&lt;/cell&gt;
        &lt;cell role="head"&gt;Token&lt;/cell&gt;
        &lt;cell role="head"&gt;L2 Norm&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;166343&lt;/cell&gt;
        &lt;cell&gt;'гылара'&lt;/cell&gt;
        &lt;cell&gt;213.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;187102&lt;/cell&gt;
        &lt;cell&gt;' министири'&lt;/cell&gt;
        &lt;cell&gt;212.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;89721&lt;/cell&gt;
        &lt;cell&gt;'这里只有精品'&lt;/cell&gt;
        &lt;cell&gt;212.4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;181865&lt;/cell&gt;
        &lt;cell&gt;'еиԥшым'&lt;/cell&gt;
        &lt;cell&gt;207.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;129320&lt;/cell&gt;
        &lt;cell&gt;'彩娱乐彩票'&lt;/cell&gt;
        &lt;cell&gt;207.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;170421&lt;/cell&gt;
        &lt;cell&gt;'天天好彩票'&lt;/cell&gt;
        &lt;cell&gt;206.6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;177625&lt;/cell&gt;
        &lt;cell&gt;'久久综合网'&lt;/cell&gt;
        &lt;cell&gt;204.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;71476&lt;/cell&gt;
        &lt;cell&gt;' иҳәеит'&lt;/cell&gt;
        &lt;cell&gt;203.3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;185118&lt;/cell&gt;
        &lt;cell&gt;'[REDACTED]'&lt;/cell&gt;
        &lt;cell&gt;202.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;104937&lt;/cell&gt;
        &lt;cell&gt;' 北京赛车怎么'&lt;/cell&gt;
        &lt;cell&gt;201.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;146111&lt;/cell&gt;
        &lt;cell&gt;' Урҭ'&lt;/cell&gt;
        &lt;cell&gt;200.9&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;195219&lt;/cell&gt;
        &lt;cell&gt;"',伊人'"&lt;/cell&gt;
        &lt;cell&gt;200.3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;147298&lt;/cell&gt;
        &lt;cell&gt;'大香蕉网'&lt;/cell&gt;
        &lt;cell&gt;199.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;165874&lt;/cell&gt;
        &lt;cell&gt;' акоронавирус'&lt;/cell&gt;
        &lt;cell&gt;198.9&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;66183&lt;/cell&gt;
        &lt;cell&gt;'րբե�'&lt;/cell&gt;
        &lt;cell&gt;198.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;173463&lt;/cell&gt;
        &lt;cell&gt;' иажәа'&lt;/cell&gt;
        &lt;cell&gt;197.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;160540&lt;/cell&gt;
        &lt;cell&gt;'彩神争霸邀请码'&lt;/cell&gt;
        &lt;cell&gt;195.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;155587&lt;/cell&gt;
        &lt;cell&gt;'бжьаратәи'&lt;/cell&gt;
        &lt;cell&gt;195.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;154809&lt;/cell&gt;
        &lt;cell&gt;'无码不卡高清免费v'&lt;/cell&gt;
        &lt;cell&gt;194.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;105084&lt;/cell&gt;
        &lt;cell&gt;'хадоу'&lt;/cell&gt;
        &lt;cell&gt;194.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;134370&lt;/cell&gt;
        &lt;cell&gt;'一本道高清无码'&lt;/cell&gt;
        &lt;cell&gt;194.6&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Mandarin speakers will have understood that the above contains an unwholesome sublist of spammy and adult-oriented website terms, with some being too explicit to make the list here. Indeed, o200k, the tokenizer used for 4o, o1, o3, o4, oss, and GPT-5 contains a lot of junk tokens. This means that every time ChatGPT runs, a matrix containing all the strange tokens we are talking about here are patiently waiting on Microsoft Azure to be multiplied with. Some of my personal favorite tokens are "北京赛车怎么" (How to play Beijing Racing), "天天中彩票的" (Winning the lottery every day), and of course "《凤凰大参考" (Phoenix Reference). Another token is "铁血网", the name of a Chinese nationalism and military enthuiasm website, which is ironic given the geopolitical considerations that are usually raised in connection with OpenAI. It is unexpected that this type of political content not just made it into the tokenizer training data, but was even overrepresented.&lt;/p&gt;
    &lt;p&gt;There are also some oddball high-norm tokens in Abkhaz, Armenian, Gujarati, Thai, and more. Some interesting examples are ",ಂಗಳೂರು" (The city Mangaluru in Kannada) along with other cities in Kerala, "ถวายสัตย์ฯ" ("Oath of Allegiance" in Thai), "แขวงคลองเตยเหนือ" (a district in Bangkok with less than 10,000 inhabitants), "วิเคราะห์บอลวันนี้" ("today's football analysis" in Thai) along with a handful of other football-related tokens.&lt;/p&gt;
    &lt;p&gt;The question is, why do these tokens have a higher, not lower, norm than the normal tokens? If they are unused, weight decay should bring them all the way down to the other unused tokens.&lt;/p&gt;
    &lt;p&gt;In this post, Jessica Rumbelow identified similar glitch tokens in GPT-2 and GPT-3, most famously the "SolidGoldMagicarp" token. Her finding was that the tokens closest to the mean of all embeddings were the glitch tokens, not necessarily those with low norm. But that's not the case here: Tokens with comparatively high norm are always far away from the mean. Further, computing cosine similarity between two of these embeddings gives higher similarity on average.&lt;/p&gt;
    &lt;p&gt;One way to get closer to the answer is to observe the models' behavior when given these tokens. We ask GPT-oss and GPT-5 about the not-so-classy token 162657: &lt;code&gt;What does this mean: "毛片免费观看"&lt;/code&gt;. With some euphemism, it means "watching explicit videos for free" in Mandarin. &lt;/p&gt;
    &lt;p&gt;In the response See the full completion here. To verify that the string was tokenized as expected, we can use tiktokenizer. , GPT-5 correctly states that the token contains Chinese text, and that it is related to watching something. It can also enumerate some of the characters in it. This means that the token was seen during training, at least once! Interestingly, the model seems to be aware of the inappropriate meaning of the token, but plays it down and in particular does not refuse to answer. Presumably this is because the token only occurs a few times in the training corpus.&lt;/p&gt;
    &lt;p&gt;In other words, we can say that a certain string, in this case a sensitive one, was part of the GPT-5 training corpus. This is called membership inference in the machine learning literature. Membership inference with high confidence is generally considered to be impractical in production LLMs, so this is a surprising finding.&lt;/p&gt;
    &lt;p&gt;Automating this process through the API, we can find which glitch tokens were seen during training of the GPT-oss and GPT-5 model families. We ask the models to give a translation of the token to English and ask for the language the token is in. For now, we simply filter for the Chinese tokens, and pass 50 tokens with highest L2 embedding norm to the models. For a control, we also ask Claude 4 and can confirm that it always answers correctly. Since a few of these tokens could technically be Japanese, we count this as a correct answer, too. For cost reasons, we ask about each token only 4 times per model, and denote 4 correct answers with a ✓, 3 and 2 with a !, 1 with a ?, and 0 with a ✗.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="7"&gt;
        &lt;cell role="head"&gt;Token&lt;/cell&gt;
        &lt;cell role="head"&gt;Crude Translation&lt;/cell&gt;
        &lt;cell role="head"&gt;GPT-5&lt;/cell&gt;
        &lt;cell role="head"&gt;Mini&lt;/cell&gt;
        &lt;cell role="head"&gt;Nano&lt;/cell&gt;
        &lt;cell role="head"&gt;oss-20B&lt;/cell&gt;
        &lt;cell role="head"&gt;oss-120B&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;毛片免费观看&lt;/cell&gt;
        &lt;cell&gt;Watch Explicit Videos Free&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;铁血网&lt;/cell&gt;
        &lt;cell&gt;[Chinese Patriotism Website]&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;这里只有精品&lt;/cell&gt;
        &lt;cell&gt;Only Fine Things Here&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;彩娱乐彩票&lt;/cell&gt;
        &lt;cell&gt;Color Entertainment Lottery&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;天天好彩票&lt;/cell&gt;
        &lt;cell&gt;Daily Good Lottery&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;久久综合网&lt;/cell&gt;
        &lt;cell&gt;[Name of adult website (?)]&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;北京赛车怎么&lt;/cell&gt;
        &lt;cell&gt;How to Beijing Racing&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;大香蕉网&lt;/cell&gt;
        &lt;cell&gt;[Name of adult website (?)]&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;彩神争霸邀请码&lt;/cell&gt;
        &lt;cell&gt;Color God Battle Invitation Code&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;无码不卡高清免费v&lt;/cell&gt;
        &lt;cell&gt;Uncensored No Lag HD Free&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;一本道高清无码&lt;/cell&gt;
        &lt;cell&gt;One Way HD Uncensored&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;大发快三和值&lt;/cell&gt;
        &lt;cell&gt;[Name of gambling website (?)]&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;天天中彩票能&lt;/cell&gt;
        &lt;cell&gt;Daily Lottery Winner Can&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;无码一区二区三区&lt;/cell&gt;
        &lt;cell&gt;Uncensored Zone 1 Zone 2 Zone 3&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;彩神争霸邀请码&lt;/cell&gt;
        &lt;cell&gt;Color God Battle Invitation Code&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;彩票开户&lt;/cell&gt;
        &lt;cell&gt;Lottery Account Opening&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;色综合网&lt;/cell&gt;
        &lt;cell&gt;Color Comprehensive Network&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;彩票平台开户&lt;/cell&gt;
        &lt;cell&gt;Lottery Platform Account Opening&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;综合久久&lt;/cell&gt;
        &lt;cell&gt;Comprehensive Long Time&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;免费视频观看&lt;/cell&gt;
        &lt;cell&gt;Free Video Watching&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;最新高清无码&lt;/cell&gt;
        &lt;cell&gt;Latest HD Uncensored&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;一级a&lt;/cell&gt;
        &lt;cell&gt;Level A&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;玩大发快三&lt;/cell&gt;
        &lt;cell&gt;Play Dafa Fast Three&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;东臣&lt;/cell&gt;
        &lt;cell&gt;East Minister&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;凤凰大参考&lt;/cell&gt;
        &lt;cell&gt;Phoenix Reference&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;棋牌游戏官网&lt;/cell&gt;
        &lt;cell&gt;Chess Card Game Official Site&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;热在线精品&lt;/cell&gt;
        &lt;cell&gt;Hot Online Quality&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;彩娱乐平台&lt;/cell&gt;
        &lt;cell&gt;Color Entertainment Platform&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;购彩官网&lt;/cell&gt;
        &lt;cell&gt;Lottery Purchase Official Site&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;最新高清无码专区&lt;/cell&gt;
        &lt;cell&gt;Latest HD Uncensored Zone&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;北京赛车女郎&lt;/cell&gt;
        &lt;cell&gt;Beijing Racing Girls&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;大香线蕉&lt;/cell&gt;
        &lt;cell&gt;Big Fragrant Line Banana&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;官网开户&lt;/cell&gt;
        &lt;cell&gt;Official Site Account Opening&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;经典三级&lt;/cell&gt;
        &lt;cell&gt;Classic Third Level&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;在线大香蕉&lt;/cell&gt;
        &lt;cell&gt;[Name of adult website (?)]&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;无码不卡&lt;/cell&gt;
        &lt;cell&gt;Uncensored No Lag&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;大发时时彩怎么&lt;/cell&gt;
        &lt;cell&gt;Dafa Time Color How&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;大发云&lt;/cell&gt;
        &lt;cell&gt;Dafa Cloud&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;和天天中彩票&lt;/cell&gt;
        &lt;cell&gt;And Daily Lottery Winner&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;平台总代理&lt;/cell&gt;
        &lt;cell&gt;Platform General Agent&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;天天买彩票&lt;/cell&gt;
        &lt;cell&gt;Daily Lottery Buying&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;天天彩票app&lt;/cell&gt;
        &lt;cell&gt;Daily Lottery App&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;彩神争霸充值&lt;/cell&gt;
        &lt;cell&gt;Color God Battle Recharge&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;彩神争霸app&lt;/cell&gt;
        &lt;cell&gt;Color God Battle App&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;律宾&lt;/cell&gt;
        &lt;cell&gt;Law Bin&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;大发扑克&lt;/cell&gt;
        &lt;cell&gt;Dafa Poker&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;热这里只有精品&lt;/cell&gt;
        &lt;cell&gt;Hot Only Quality Here&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;北京赛车有&lt;/cell&gt;
        &lt;cell&gt;Beijing Racing Has&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;留下些什么吧&lt;/cell&gt;
        &lt;cell&gt;Leave Something Behind&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;We can read off that the explicit token we already found is recognized by all models, and identify a few more anomalous tokens that were likely seen during training. Many others however are not recognized, and thus unlikely to have been in the training data.&lt;/p&gt;
    &lt;p&gt;We try to identify a pattern in the tokens that are recognized. It generally seems that recognized tokens yield many more hits on GitHub. Indeed, there often are some spam repositories on GitHub that contain these recognized strings, as well as some repositories containing lists of strings to block for content moderation.&lt;/p&gt;
    &lt;p&gt;The membership inference only tells us that the model saw the string, not where it was sourced from. To test whether GitHub was a likely source, we therefore correlate the number of search hits on GitHub with the number of correct answers across the GPT models. We find a significant Spearman's ρ of 0.448. This does not prove that GitHub was the source, because the high search hit count on GitHub could just be indicative that the token is more common across the internet. Nonetheless, the setup demonstrates how glitch tokens could be used to make broader statements about the training data.&lt;/p&gt;
    &lt;p&gt;In summary, we have found strong evidence that models in the GPT-5 and GPT-oss family were trained on phrases from adult websites. We have also found weak evidence that part of the GPT training corpus was scraped off of GitHub. The search was made easier via access the weights of GPT-oss, showing how the open-weights paradigm opens up new attack vectors on production models. It seems advisable for frontier labs to mitigate this problem by excluding uncommon strings from their tokenizer vocabularies.&lt;/p&gt;
    &lt;p&gt;These glitch tokens have more uses than was described above. If you want to work with these concepts, the companion repository provides a starting point. Some ideas that could be interesting to explore:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Token / Token Family&lt;/cell&gt;
        &lt;cell role="head"&gt;Explanation&lt;/cell&gt;
        &lt;cell role="head"&gt;Example Prompt&lt;/cell&gt;
        &lt;cell role="head"&gt;Behaviour&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;CHKERRQ&lt;/cell&gt;
        &lt;cell&gt;The weirdest pure ASCII token. From a function name in C.&lt;/cell&gt;
        &lt;cell&gt;Can you spell the following word: "CHKERRQ"&lt;/cell&gt;
        &lt;cell&gt;"Unspeakable" for gpt-4o-mini. gpt-4o sometimes almost spells correctly, other times hallucinates.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Can you output every second letter in "CHKERRQ"?&lt;/cell&gt;
        &lt;cell&gt;Makes gpt-4o hallucinate.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Write a poem using the word "CHKERRQ"&lt;/cell&gt;
        &lt;cell&gt;Makes gpt-4o-mini write creepily about the word "terminate"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;\\xadder&lt;/cell&gt;
        &lt;cell&gt;No idea.&lt;/cell&gt;
        &lt;cell&gt;Please spell "\\xadder"&lt;/cell&gt;
        &lt;cell&gt;gpt-4o spells it as "hexadecimal", the summary model is confused and sees "QRST"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;♀♀♀♀&lt;/cell&gt;
        &lt;cell&gt;From social media bios?&lt;/cell&gt;
        &lt;cell&gt;How many symbols are in♀♀♀♀&lt;/cell&gt;
        &lt;cell&gt;gpt-4o trips and outputs random (?) Chinese characters&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;€¦&lt;/cell&gt;
        &lt;cell&gt;From spreadsheets?&lt;/cell&gt;
        &lt;cell&gt;What are these symbols: "€¦"&lt;/cell&gt;
        &lt;cell&gt;gpt-4o-mini thinks this is an ellipsis ("...")&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;風吹けば名無し and 8 variants&lt;/cell&gt;
        &lt;cell&gt;Literally "no name if the wind blows". Former default user name on baseball-themed 2channel boards. (Source)&lt;/cell&gt;
        &lt;cell&gt;What is the meaning of "風吹けば名無し"?&lt;/cell&gt;
        &lt;cell&gt;gpt-4o sometimes hallucinates randomly. gpt-4o-mini hallucinates about baseball and attempts to spell it, incorrectly.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;＠お腹いっぱい&lt;/cell&gt;
        &lt;cell&gt;Literally "@TummyIsFull". From a former default username on 2channel boards.&lt;/cell&gt;
        &lt;cell&gt;What is the meaning of＠お腹いっぱい?&lt;/cell&gt;
        &lt;cell&gt;gpt-4o conflates it with common Japanese phrases and random syllables, gpt-4o-mini similar.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;＠おーぷん&lt;/cell&gt;
        &lt;cell&gt;Literally "@Open". Also from 2channel.&lt;/cell&gt;
        &lt;cell&gt;Please repeat the word＠おーぷん back to me.&lt;/cell&gt;
        &lt;cell&gt;Seemingly unspeakable for gpt-4o-mini and hard to say for gpt-4o.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;How do you pronounce＠おーぷん?&lt;/cell&gt;
        &lt;cell&gt;gpt-4o hallucinates the above mentioned "If the wind blows, Mr. Nameless"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;VIPがお送りします&lt;/cell&gt;
        &lt;cell&gt;Literally "Brought to you by VIP". Another 2channel term.&lt;/cell&gt;
        &lt;cell&gt;Please explain the meaning of "VIPがお送りします".&lt;/cell&gt;
        &lt;cell&gt;gpt-4o-mini is adorable and hallucinates about the horn emoji (📯)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;中央値との差&lt;/cell&gt;
        &lt;cell&gt;Japanese for "difference from the median".&lt;/cell&gt;
        &lt;cell&gt;Please spell this backwards: "中央値との差"&lt;/cell&gt;
        &lt;cell&gt;gpt-4o answers with lowercase latin characters.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;.minecraftforge&lt;/cell&gt;
        &lt;cell&gt;File extension from Minecraft modding&lt;/cell&gt;
        &lt;cell&gt;Please spell the string "readme.minecraftforge"&lt;/cell&gt;
        &lt;cell&gt;gpt-4o-mini: 'The string is spelled "M-O-D dot F-O-R-G-E-R-E-C-E dot G-E.'&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;CHANTABILITY&lt;/cell&gt;
        &lt;cell&gt;Ending of MER-CHANTABILITY&lt;/cell&gt;
        &lt;cell&gt;Please spell the word "CHANTABILITY".&lt;/cell&gt;
        &lt;cell&gt;gpt-4o spells it as "Chanceability".&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;《凤凰大参考&lt;/cell&gt;
        &lt;cell&gt;"The Phoenix Reference"&lt;/cell&gt;
        &lt;cell&gt;What is the meaning of《凤凰大参考?&lt;/cell&gt;
        &lt;cell&gt;Unspeakable for gpt-4o&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;亚历山大发&lt;/cell&gt;
        &lt;cell&gt;"Alexander"&lt;/cell&gt;
        &lt;cell&gt;Please translate this: " 亚历山大发".&lt;/cell&gt;
        &lt;cell&gt;gpt-4o thinks it's Abkhaz for yes.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;微信里的天天中彩票 and the ~100 other Chinese lottery tokens&lt;/cell&gt;
        &lt;cell&gt;This article speculates why the tokenizer training data included so many of these.&lt;/cell&gt;
        &lt;cell&gt;Please print every second character in the following: 微信里的天天中彩票.&lt;/cell&gt;
        &lt;cell&gt;Reliable gibberish generator on gpt-4o-mini. The tokens themselves are mostly unspeakable.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;SUPERHOST&lt;/cell&gt;
        &lt;cell&gt;Programming term?&lt;/cell&gt;
        &lt;cell&gt;Please output every second letter in "SUPERHOST"&lt;/cell&gt;
        &lt;cell&gt;gpt-4o-mini spells it as "SPARENT" and then trips&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;ILLISECONDS&lt;/cell&gt;
        &lt;cell&gt;Ending of M-ILLISECONDS&lt;/cell&gt;
        &lt;cell&gt;Please reverse the string "ILLISECONDS"&lt;/cell&gt;
        &lt;cell&gt;Trouble with character-level operations for gpt-4o-mini.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;GETGLOBAL&lt;/cell&gt;
        &lt;cell&gt;Programming term&lt;/cell&gt;
        &lt;cell&gt;Please output every second letter in " GETGLOBAL"&lt;/cell&gt;
        &lt;cell&gt;Makes gpt-4o-mini hallucinate "GETALLONG" at character level.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;_REALTYPE _EDEFAULT _PRODUCTS&lt;/cell&gt;
        &lt;cell&gt;Maybe from the library libstdc++?&lt;/cell&gt;
        &lt;cell&gt;Can you output every second letter in_REALTYPE?&lt;/cell&gt;
        &lt;cell&gt;gpt-4o-mini likes to hallucinate "translated"&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;As more research on glitch tokens becomes available, I will try to list it here. The most comprehensive report to date is this article in MIT Technology Review, and there are many articles in Chinese, such as this one. However, these discuss the tokenizer itself, not how the models behave.&lt;/p&gt;
    &lt;p&gt;Finally, if you are in a position to fix the issue in the OpenAI API, I presume you already know how, else I'm happy to help. Note that a fix could even lower inference cost a bit. You can mail to lennart@finke.dev.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45483924</guid><pubDate>Sun, 05 Oct 2025 18:28:16 +0000</pubDate></item><item><title>Toybox: All-in-one Linux command line</title><link>https://github.com/landley/toybox</link><description>&lt;doc fingerprint="b4a05d537d87a8a3"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Notifications &lt;tool-tip&gt;You must be signed in to change notification settings&lt;/tool-tip&gt;&lt;/item&gt;
      &lt;item&gt;Fork 365&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;toybox&lt;/p&gt;
    &lt;head rend="h3"&gt;License&lt;/head&gt;
    &lt;head rend="h1"&gt;landley/toybox&lt;/head&gt;
    &lt;head rend="h2"&gt;Folders and files&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Name&lt;/cell&gt;
        &lt;cell role="head"&gt;Name&lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;Last commit message&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;Last commit date&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Repository files navigation&lt;/head&gt;
    &lt;quote&gt;Toybox: all-in-one Linux command line. --- Getting started You can download static binaries for various targets from: http://landley.net/toybox/bin The special name "." indicates the current directory (just like ".." means the parent directory), and you can run a program that isn't in the $PATH by specifying a path to it, so this should work: wget http://landley.net/toybox/bin/toybox-x86_64 chmod +x toybox-x86_64 ./toybox-x86_64 echo hello world --- Building toybox Type "make help" for build instructions. Toybox uses the "make menuconfig; make; make install" idiom same as the Linux kernel. Usually you want something like: make defconfig make make install Or maybe: LDFLAGS="--static" CROSS_COMPILE=armv5l- make defconfig toybox PREFIX=/path/to/root/filesystem/bin make install_flat The file "configure" defines default values for many environment variables that control the toybox build; if you export any of these variables into your environment, your value is used instead of the default in that file. The CROSS_COMPILE argument above is optional, the default builds a version of toybox to run on the current machine. Cross compiling requires an appropriately prefixed cross compiler toolchain, several example toolchains (built using the file "scripts/mcm-buildall.sh" in the toybox source) are available at: https://landley.net/toybox/downloads/binaries/toolchains/latest For the "CROSS_COMPILE=armv5l-" example above, download armv5l-linux-musleabihf-cross.tar.xz, extract it, and add its "bin" subdirectory to your $PATH. (And yes, the trailing - is significant, because the prefix includes a dash.) For more about cross compiling, see: https://landley.net/toybox/faq.html#cross http://landley.net/writing/docs/cross-compiling.html http://landley.net/aboriginal/architectures.html For a more thorough description of the toybox build process, see: http://landley.net/toybox/code.html#building --- Using toybox The toybox build produces a multicall binary, a "swiss-army-knife" program that acts differently depending on the name it was called by (cp, mv, cat...). Installing toybox adds symlinks for each command name to the $PATH. The special "toybox" command treats its first argument as the command to run. With no arguments, it lists available commands. This allows you to use toybox without installing it, and is the only command that can have an arbitrary suffix (hence "toybox-armv5l"). The "help" command provides information about each command (ala "help cat"), and "help toybox" provides general information about toybox. --- Configuring toybox It works like the Linux kernel: allnoconfig, defconfig, and menuconfig edit a ".config" file that selects which features to include in the resulting binary. You can save and re-use your .config file, but may want to run "make oldconfig" to re-run the dependency resolver when migrating to new versions. The maximum sane configuration is "make defconfig": allyesconfig isn't recommended as a starting point for toybox because it enables unfinished commands, debug code, and optional dependencies your build environment may not provide. --- Creating a Toybox-based Linux system Toybox has a built-in simple system builder (scripts/mkroot.sh) with a Makefile target: make root sudo chroot root/host/fs /init Type "exit" to get back out. If you install appropriate cross compilers and point it at Linux source code, it can build simple three-package systems that boot to a shell prompt under qemu: make root CROSS_COMPILE=sh4-linux-musl- LINUX=~/linux cd root/sh4 ./qemu-sh4.sh By calling scripts/mkroot.sh directly you can add additional packages to the build, see scripts/root/dropbear as an example. The FAQ explains this in a lot more detail: https://landley.net/toybox/faq.html#system https://landley.net/toybox/faq.html#mkroot --- Presentations 1) "Why Toybox?" talk at the Embedded Linux Conference in 2013 outline: http://landley.net/talks/celf-2013.txt video: http://youtu.be/SGmtP5Lg_t0 The https://landley.net/toybox/about.html page has nav links breaking that talk down into sections. 2) "Why Public Domain?" The rise and fall of copyleft, Ohio LinuxFest 2013 outline: http://landley.net/talks/ohio-2013.txt audio: https://archive.org/download/OhioLinuxfest2013/24-Rob_Landley-The_Rise_and_Fall_of_Copyleft.mp3 3) Why did I do Aboriginal Linux (which led me here) 260 slide presentation: https://speakerdeck.com/landley/developing-for-non-x86-targets-using-qemu How and why to make android self-hosting: http://landley.net/aboriginal/about.html#selfhost More backstory than strictly necessary: https://landley.net/aboriginal/history.html 4) What's new with toybox (ELC 2015 status update): video: http://elinux.org/ELC_2015_Presentations outline: http://landley.net/talks/celf-2015.txt 5) Toybox vs BusyBox (2019 ELC talk): outline: http://landley.net/talks/elc-2019.txt video: https://www.youtube.com/watch?v=MkJkyMuBm3g --- Contributing The three important URLs for communicating with the toybox project are: web page: http://landley.net/toybox mailing list: http://lists.landley.net/listinfo.cgi/toybox-landley.net git repo: http://github.com/landley/toybox The maintainer prefers patches be sent to the mailing list. If you use git, the easy thing to do is: git format-patch -1 $HASH Then send a file attachment. The list holds messages from non-subscribers for moderation, but I usually get to them in a day or two. I download github pull requests as patches and apply them with "git am" (which avoids gratuitous merge commits). Sometimes I even remember to close the pull request. If I haven't responded to your patch after one week, feel free to remind me of it. Android's policy for toybox patches is that non-build patches should go upstream first (into vanilla toybox, with discussion on the toybox mailing list) and then be pulled into android's toybox repo from there. (They generally resync on fridays). The exception is patches to their build scripts (Android.mk and the checked-in generated/* files) which go directly to AOSP. (As for the other meaning of "contributing", https://patreon.com/landley is always welcome but I warn you up front I'm terrible about updating it.)&lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45484284</guid><pubDate>Sun, 05 Oct 2025 19:09:35 +0000</pubDate></item><item><title>Ken Parker, famed luthier, has died</title><link>https://kenparkerarchtops.com</link><description>&lt;doc fingerprint="365db15571e068b0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;RIP Ken Parker: August 25, 1952 – October 5, 2025&lt;/head&gt;
    &lt;p&gt;Ken Parker, age 73, passed away peacefully at his home in Gloucester, MA on October 5, 2025, with Susan Kolwicz by his side.&lt;/p&gt;
    &lt;p&gt;From Ken, October 3rd, 2025:&lt;/p&gt;
    &lt;p&gt;Hello Everybody,&lt;/p&gt;
    &lt;p&gt;Well, they say that nothing lasts forever and they’re right about that. My time here is about to close down and I won’t be part of the show anymore. What I have done with all my heart and soul is to put together a situation where my work can continue unabated and begin to bring some serious fruit to the things that I’ve been working on for the last 50 years.&lt;/p&gt;
    &lt;p&gt;My deepest and most heartfelt thanks to all of you. It’s been the experience of my lifetime being able to share my life’s work and knowledge with each of you through my instruments and via Archtoppery, and see that you get it. My hope is that you all build on what I’ve learned and shared, and take everything to the next level.&lt;/p&gt;
    &lt;p&gt;Sam Krimmel will be doing just that, and I encourage you to support Sam as he ventures forth. Sam is a natural co-conspirator and he and I will be will be working together down the road through some sort of psychic medium. We’ve already got some amazing new things underway and soon we’re going to show you what that is all about. So stay tuned.&lt;/p&gt;
    &lt;p&gt;All right, well everyone, please take care of yourselves and peace on earth, if that should ever be possible.&lt;/p&gt;
    &lt;p&gt;Love, Ken&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45485736</guid><pubDate>Sun, 05 Oct 2025 22:10:15 +0000</pubDate></item><item><title>Germany outfitted half a million balconies with solar panels</title><link>https://grist.org/buildings/how-germany-outfitted-half-a-million-balconies-with-solar-panels/</link><description>&lt;doc fingerprint="3707d1531a06ed9a"&gt;
  &lt;main&gt;
    &lt;p&gt;Matthias Weyland loves having people ask about his balcony. A pair of solar panels hang from the railing, casting a sheen of dark blue against the red brick of his apartment building. They’re connected to a microinverter plugged into a wall outlet and feed electricity directly into his home. On a sunny day, he’ll produce enough power to supply up to half of his family’s daily needs.&lt;/p&gt;
    &lt;p&gt;Weyland is one of hundreds of thousands of people across Germany who have embraced balkonkraftwerk, or balcony solar. Unlike rooftop photovoltaics, the technology doesn’t require users to own their home, and anyone capable of plugging in an appliance can set it up. Most people buy the simple hardware online or at the supermarket for about $550 (500 euros.)&lt;/p&gt;
    &lt;p&gt;The ease of installation and a potent mix of government policies to encourage adoption has made the wee arrays hugely popular. More than 550,000 of them dot cities and towns nationwide, half of which were installed in 2023. During the first half of this year, Germany added 200 megawatts of balcony solar. Regulations limit each system to just 800 watts, enough to power a small fridge or charge a laptop, but the cumulative effect is nudging the country toward its clean energy goals while giving apartment dwellers, who make up more than half of the population, an easy way to save money and address the climate crisis.&lt;/p&gt;
    &lt;p&gt;“I love the feeling of charging the bike when the sun is shining, or having the washing machine run when the sun is shining, and to know that it comes directly from the sun,” Weyland said. “It’s a small step you can take as a tenant” and an act of “self-efficacy, to not just sit and wait until the climate crisis gets worse.”&lt;/p&gt;
    &lt;p&gt;Balcony solar emerged around a decade ago, but didn’t catch on until four or five years ago, thanks in part to years of lobbying by solar and clean energy advocates for policies to foster its adoption. The German government enacted the first technical regulations for plug-in solar devices in 2019, allowing balcony solar systems to use standard electrical plugs and feed into the grid. That prompted an influx of plug-in devices and advocates to promote the technology.&lt;/p&gt;
    &lt;p&gt;The pandemic helped fuel the surge in popularity as people spent time at home, working on DIY projects. More recently, the escalating energy prices that followed Russia’s invasion of Ukraine led more Germans to consider balcony solar. “People just did anything they could to reduce their energy bills,” said Wolfgang Gründinger, who works with the clean energy company Enpal.&lt;/p&gt;
    &lt;p&gt;Federal and local policymakers have redoubled their efforts to make the technology more accessible. In April, the government simplified permitting and registration requirements, and in July, federal lawmakers passed renter protections that prevent landlords from arbitrarily blocking installations. Cities throughout Germany, including Berlin and Weyland’s home city of Kiel, have offered millions of euros in subsidies to install balcony solar.&lt;/p&gt;
    &lt;p&gt;Gründinger and experts at the German Solar Industry Association noted that the devices don’t generate enough power to strain the grid, and their standardized design and safety features allow them to integrate smoothly and easily.&lt;/p&gt;
    &lt;p&gt;Despite the hype, most users concede that balcony solar provides modest cost and energy savings. Weyland spent around $530 for his 600-watt-capacity system. While he’s happy with how his south-facing panels perform during balmy weather, such days are rare in northern Germany. He estimates that he’ll save around $100 in annual electricity costs and recoup his investment in about five years.&lt;/p&gt;
    &lt;p&gt;That’s fairly typical, although advocates of the technology say a system’s efficacy — and, therefore, payback timeline — varies widely depending upon the number of panels, their location and direction, and how much shade surrounds them. A household with a “comparatively large well-positioned balcony system in a sunny spot facing south” can produce 15 percent of its electricity with balcony solar, according to Peter Stratmann, head of renewables at German Federal Network Agency, the country’s utility regulator.&lt;/p&gt;
    &lt;p&gt;While that can put a dent in a household’s utility bill, its impact on Germany’s consumption is far smaller. “Even if we attached panels to all suitable balconies across the country, we’d still only manage to meet 1 percent or less of our overall energy needs,” Stratmann told Deutsche Welle.&lt;/p&gt;
    &lt;p&gt;So if balcony solar doesn’t generate a lot of power or save a lot of money, why are so many people flocking to it? Many of them like the idea of producing energy at home and gaining a bit of independence from the grid. It also provides a tangible way to take climate action. “It makes the energy transition feel a little more concrete and not so abstract,” said Helena Holenweger of the nonprofit Deutsche Umwelthilfe, or Environmental Action Germany. She installed a balcony solar system on top of her garage about a year ago. “You can literally do something about it.”&lt;/p&gt;
    &lt;p&gt;Holenweger and others who have tapped the sun said balcony solar led them to reevaluate their understanding of electricity consumption and take steps to reduce it. “For lots of people, energy is just something that comes out of your socket,” Holenweger said. “You never think about how it gets there or how it works.” The systems don’t include battery storage, so the juice they generate must be used immediately, leading people to plan the best time to, say, run the washing machine to ensure they’re using renewable energy. In that way, it becomes something of a game. Many balcony solar kits feature an app to track daily energy generation, providing what has, for many people, become a scorecard. “They screenshot that, they send it around to their Facebook groups, family WhatsApp groups. They’re super proud,” Gründinger said.&lt;/p&gt;
    &lt;p&gt;Germany is unique in its rabid embrace of the tech. Although increasingly popular in Austria, the Netherlands, France, and elsewhere in Europe, plug-in solar devices aren’t viable in the United States due to costly permitting requirements and other local regulations. Beyond that, most systems are designed to European electrical standards, making them incompatible with U.S. power systems.&lt;/p&gt;
    &lt;p&gt;But even in Germany, balcony solar still faces hurdles, including fierce resistance from landlords worried about electrical fires or put off by the aesthetics of the panels. Last year, Weyland sued his building’s property management company for imposing what he deemed unreasonable requirements to install a system, including a formal inspection of the building’s electrical system. A court sided with him in October 2023, but similar cases pop up regularly.&lt;/p&gt;
    &lt;p&gt;Weyland hopes that as more people adopt balcony solar, that will soon change. Already, people in his life regularly ask him about his panels, and two friends are buying systems of their own.&lt;/p&gt;
    &lt;p&gt;“So many people talk to me in our neighborhood and ask about the system when they see it,” Weyland said. “It’s kind of like a snowball that gets bigger and bigger.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45485806</guid><pubDate>Sun, 05 Oct 2025 22:18:31 +0000</pubDate></item><item><title>Estimating AI energy use</title><link>https://spectrum.ieee.org/ai-energy-use</link><description>&lt;doc fingerprint="47f42b200bbe516a"&gt;
  &lt;main&gt;
    &lt;p&gt;The Conversation (1)&lt;/p&gt;
    &lt;p&gt;Tagamachi Sakoshi02 Oct, 2025&lt;/p&gt;
    &lt;p&gt; INDV &lt;/p&gt;
    &lt;p&gt;Doing queries for 100 million users at the energy cost of 29 thousand houses is extremely efficient. Local models are even more efficient than that. I use Gemma 3 12B on my laptop.&lt;/p&gt;
    &lt;p&gt;Depending on the task AI assist saves a lot of energy. E.g. instead of spending hours on photoshop to do concept art, you can do dozens to hundreds using AI assist.&lt;/p&gt;
    &lt;p&gt;Datacenter wise, it's sensless, but I suspect the Stargate and oracle project will never take place. There is no economic way to make a return on investment on 500 billion bucks spent on H200.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45486031</guid><pubDate>Sun, 05 Oct 2025 23:00:23 +0000</pubDate></item><item><title>Rule-Based Expert Systems: The Mycin Experiments (1984)</title><link>https://www.shortliffe.net/Buchanan-Shortliffe-1984/MYCIN%20Book.htm</link><description>&lt;doc fingerprint="f3a54915433b8ca0"&gt;
  &lt;main&gt;
    &lt;cell&gt;
      &lt;head rend="h1"&gt;Rule-Based Expert Systems:&lt;lb/&gt;The MYCIN Experiments of the Stanford Heuristic Programming Project&lt;/head&gt;
      &lt;head rend="h2"&gt;Edited by Bruce G. Buchanan and Edward H. Shortliffe&lt;/head&gt;
      &lt;p&gt;754 pp., references, index, illus. electronic text&lt;lb/&gt; Addison Wesley, Reading, MA, 1984&lt;lb/&gt; Out of print. All chapters are freely available below.&lt;/p&gt;
      &lt;p&gt;Artificial intelligence, or AI, is largely an experimental science—at least as much progress has been made by building and analyzing programs as by examining theoretical questions. MYCIN is one of several well-known programs that embody some intelligence and provide data on the extent to which intelligent behavior can be programmed. As with other AI programs, its development was slow and not always in a forward direction. But we feel we learned some useful lessons in the course of nearly a decade of work on MYCIN and related programs. In this book we share the results of many experiments performed in that time, and we try to paint a coherent picture of the work. The book is intended to be a critical analysis of several pieces of related research, performed by a large number of scientists. We believe that the whole field of AI will benefit from such attempts to take a detailed retrospective look at experiments, for in this way the scientific foundations of the field will gradually be defined. It is for all these reasons that we have prepared this analysis of the MYCIN experiments.&lt;/p&gt;
      &lt;p&gt;Contributors&lt;/p&gt;
      &lt;p&gt;Foreword&lt;lb/&gt; Allen Newell&lt;/p&gt;
      &lt;p&gt;Preface&lt;/p&gt;
      &lt;head rend="h3"&gt;Part One: Background&lt;/head&gt;
      &lt;p&gt;Chapter 1—The Context of the MYCIN Experiments&lt;/p&gt;
      &lt;p&gt;Chapter 2—The Origin of Rule-Based Systems in AI&lt;lb/&gt; Randall Davis and Jonathan J. King&lt;/p&gt;
      &lt;head rend="h3"&gt;Part Two: Using Rules&lt;/head&gt;
      &lt;p&gt;Chapter 3—The Evolution of MYCIN’s Rule Form&lt;/p&gt;
      &lt;p&gt;Chapter 4—The Structure of the MYCIN System&lt;lb/&gt; William van Melle&lt;/p&gt;
      &lt;p&gt;Chapter 5—Details of the Consultation System&lt;lb/&gt; Edward H. Shortliffe&lt;/p&gt;
      &lt;p&gt;Chapter 6—Details of the Revised Therapy Algorithm&lt;lb/&gt; William J. Clancey&lt;/p&gt;
      &lt;head rend="h3"&gt;Part Three: Building a Knowledge Base&lt;/head&gt;
      &lt;p&gt;Chapter 7—Knowledge Engineering&lt;/p&gt;
      &lt;p&gt;Chapter 8—Completeness and Consistency in a Rule-Based System&lt;lb/&gt; Motoi Suwa, A. Carlisle Scott, and Edward H. Shortliffe&lt;/p&gt;
      &lt;p&gt;Chapter 9—Interactive Transfer of Expertise&lt;lb/&gt; Randall Davis&lt;/p&gt;
      &lt;head rend="h3"&gt;Part Four: Reasoning Under Uncertainty&lt;/head&gt;
      &lt;p&gt;Chapter 10—Uncertainty and Evidential Support&lt;/p&gt;
      &lt;p&gt;Chapter 11—A Model of Inexact Reasoning in Medicine&lt;lb/&gt; Edward H. Shortliffe and Bruce G. Buchanan&lt;/p&gt;
      &lt;p&gt;Chapter 12—Probabilistic Reasoning and Certainty Factors&lt;lb/&gt; J. Barclay Adams&lt;/p&gt;
      &lt;p&gt;Chapter 13—The Dempster-Shafer Theory of Evidence&lt;lb/&gt; Jean Gordon and Edward H. Shortliffe&lt;/p&gt;
      &lt;head rend="h3"&gt;Part Five: Generalizing MYCIN&lt;/head&gt;
      &lt;p&gt;Chapter 14—Use of the MYCIN Inference Engine&lt;/p&gt;
      &lt;p&gt;Chapter 15—EMYCIN: A Knowledge Engineer’s Tool for Constructing Rule-Based Expert Systems&lt;lb/&gt; William van Melle, Edward H. Shortliffe, and Bruce G. Buchanan&lt;/p&gt;
      &lt;p&gt;Chapter 16—Experience Using EMYCIN&lt;lb/&gt; James S. Bennett and Robert S. Engelmore&lt;/p&gt;
      &lt;head rend="h3"&gt;Part Six: Explaining the Reasoning&lt;/head&gt;
      &lt;p&gt;Chapter 17—Explanation as a Topic of AI Research&lt;/p&gt;
      &lt;p&gt;Chapter 18—Methods for Generating Explanations&lt;lb/&gt; A. Carlisle Scott, William J. Clancey, Randall Davis, and Edward H. Shortliffe&lt;/p&gt;
      &lt;p&gt;Chapter 19—Specialized Explanations for Dosage Selection&lt;lb/&gt; Sharon Wraith Bennett and A. Carlisle Scott&lt;/p&gt;
      &lt;p&gt;Chapter 20—Customized Explanations Using Causal Knowledge&lt;lb/&gt; Jerold W. Wallis and Edward H. Shortliffe&lt;/p&gt;
      &lt;head rend="h3"&gt;Part Seven: Using Other Representations&lt;/head&gt;
      &lt;p&gt;Chapter 21—Other Representation Frameworks&lt;/p&gt;
      &lt;p&gt;Chapter 22—Extensions to the Rule-Based Formalism for a Monitoring Task&lt;lb/&gt; Lawrence M. Fagan, John C. Kunz, Edward A. Feigenbaum, and John J. Osborn&lt;/p&gt;
      &lt;p&gt;Chapter 23—A Representation Scheme Using Both Frames and Rules&lt;lb/&gt; Janice S. Aikins&lt;/p&gt;
      &lt;p&gt;Chapter 24—Another Look at Frames&lt;lb/&gt; David E. Smith and Jan E. Clayton&lt;/p&gt;
      &lt;head rend="h3"&gt;Part Eight: Tutoring&lt;/head&gt;
      &lt;p&gt;Chapter 25—Intelligent Computer-Aided Instruction&lt;/p&gt;
      &lt;p&gt;Chapter 26—Use of MYCIN’s Rules for Tutoring&lt;lb/&gt; William J. Clancey&lt;/p&gt;
      &lt;head rend="h3"&gt;Part Nine: Augmenting the Rules&lt;/head&gt;
      &lt;p&gt;Chapter 27—Additional Knowledge Structures&lt;/p&gt;
      &lt;p&gt;Chapter 28—Meta-Level Knowledge&lt;lb/&gt; Randall Davis and Bruce G. Buchanan&lt;/p&gt;
      &lt;p&gt;Chapter 29—Extensions to Rules for Explanation and Tutoring&lt;lb/&gt; William J. Clancey&lt;/p&gt;
      &lt;head rend="h3"&gt;Part Ten: Evaluating Performance&lt;/head&gt;
      &lt;p&gt;Chapter 30—The Problem of Evaluation&lt;/p&gt;
      &lt;p&gt;Chapter 31—An Evaluation of MYCIN’s Advice&lt;lb/&gt; Victor L. Yu, Lawrence M. Fagan, Sharon Wraith Bennett, William J . Clancey, A. Carlisle Scott, John F. Hannigan, Robert L. Blum, Bruce G. Buchanan, and Stanley N. Cohen&lt;/p&gt;
      &lt;head rend="h3"&gt;Part Eleven: Designing for Human Use&lt;/head&gt;
      &lt;p&gt;Chapter 32—Human Engineering of Medical Expert Systems&lt;/p&gt;
      &lt;p&gt;Chapter 33—Strategies for Understanding Structured English&lt;lb/&gt; Alain Bonnet&lt;/p&gt;
      &lt;p&gt;Chapter 34—An Analysis of Physicians’ Attitudes&lt;lb/&gt; Randy L. Teach and Edward H. Shortliffe&lt;/p&gt;
      &lt;p&gt;Chapter 35—An Expert System for Oncology Protocol Management&lt;lb/&gt; Edward H. Shortliffe, A. Carlisle Scott, Miriam B. Bischoff, A. Bruce Campbell, William van MeUe, and Charlotte D. Jacobs&lt;/p&gt;
      &lt;head rend="h3"&gt;Part Twelve: Conclusions&lt;/head&gt;
      &lt;p&gt;Chapter 36—Major Lessons from This Work&lt;/p&gt;
      &lt;p&gt;Epilog&lt;/p&gt;
      &lt;p&gt;Appendix&lt;/p&gt;
      &lt;p&gt;References&lt;/p&gt;
      &lt;p&gt;Name Index&lt;/p&gt;
      &lt;p&gt;Subject Index&lt;/p&gt;
    &lt;/cell&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45486306</guid><pubDate>Sun, 05 Oct 2025 23:51:47 +0000</pubDate></item><item><title>Should I choose Ada, SPARK, or Rust over C/C++? (2024)</title><link>https://blog.adacore.com/should-i-choose-ada-spark-or-rust-over-c-c</link><description>&lt;doc fingerprint="b64b98bb3093a5d8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Should I choose Ada, SPARK, or Rust over C/C++?&lt;/head&gt;
    &lt;head rend="h2"&gt;by Quentin Ochem –&lt;/head&gt;
    &lt;p&gt;At AdaCore, weâre in the business of supporting people who develop high-integrity software, in particular for embedded systems. In terms of programming languages, this means supporting the most commonly found candidates, which in 2024 include C/C++, Ada/SPARK, and Rust. If youâve already made your decision, we will support you. However, in a number of situations, people ask us: âWhat should we do? Whatâs the best out there?â. While itâs difficult to give a one-size-fits-all answer, there are some strategic elements to consider.&lt;/p&gt;
    &lt;head rend="h1"&gt;C/C++ - a risky default solution&lt;/head&gt;
    &lt;p&gt;In the embedded domain, youâre more likely to look at C/C++ than anything else. This is the option âby defaultâ. A large portion of your software is likely to already be in C/C++. Your staff is trained in this language, tools, and processes are in place, and development costs are known and deterministic. Why change?&lt;/p&gt;
    &lt;p&gt;There is a growing body of evidence, both qualitative and quantitative, that shows that C/C++ is making the production of safe and secure software more difficult than it should be. Decades of research and investment have still not yielded a âsafe C/C++â that is cost-effective, flexible, and reliable.&lt;/p&gt;
    &lt;p&gt;The good news is that today, depending on what you may want to do, you have better options.&lt;/p&gt;
    &lt;head rend="h1"&gt;Rust and Ada - improving traditional development processes&lt;/head&gt;
    &lt;p&gt;Teams that are looking at alternative programming languages have two options today: Ada and Rust. Both languages raise the bar in terms of safety and security compared to C/C++; each has unique strengths&lt;/p&gt;
    &lt;p&gt;Consider ecosystems and communities. Rust has a vibrant community that has developed a huge amount of resources over a short period of time. However, its commercial ecosystem is still in the process of organizing itself. AdaCore has a role to play in this, but filling some of the gaps is going to take some time. In contrast, Ada has a smaller community - it has been growing over the years but much more slowly. However Ada has a complete and mature ecosystem both in terms of toolchain availability and certification documentation.&lt;/p&gt;
    &lt;p&gt;Or consider language capabilities. Rust pushes memory safety very far and provides a more flexible memory model than most programming languages today. Ada has an unmatched specification language that allows one to express and check software and hardware constraints at various levels.&lt;/p&gt;
    &lt;p&gt;These are just two examples. Below, we present a table that compares other aspects of Ada and Rust to help you select the language best suited to your needs.&lt;/p&gt;
    &lt;head rend="h1"&gt;SPARK - industrial-strength formal methods&lt;/head&gt;
    &lt;p&gt;If youâre prepared to look at alternative programming languages to avoid the costs and risks of C/C++, SPARK offers an opportunity to go much further than Ada or Rust. SPARK, which is based on Ada, offers industrial-strength formal methods: an opportunity for you to prove mathematically that your software is safe and secure. This paradigm shift in software development methodology offers significant cost savings for high-integrity software.&lt;/p&gt;
    &lt;p&gt;Using SPARK, you identify properties that can be formalized and proved true throughout an entire program - statically, i.e., at compile time. Ada and Rust offer some basic properties that are checked statically, such as the specification of hardware constraints in Ada or memory safety via borrow checking in Rust. SPARK takes these approaches to the limit, allowing the full range of Adaâs specification language to be used to formalize properties that are proved, automatically. The result is comprehensive proven properties across a whole application.&lt;/p&gt;
    &lt;p&gt;The first set of properties SPARK demonstrates pertains to vulnerabilities inherent to the programming language itself. For example, thereâs no guarantee that the index used to access an array element is within range. While many programming languages guarantee that an out of range access will yield an exception at run-time, SPARK will prove that thereâs no possible out of range index statically, at compile-time.&lt;/p&gt;
    &lt;p&gt;SPARK also allows expression of custom properties and verifies that the code complies with them in all possible cases. These properties can range from simple cases (are the callees to mutexes balanced? Is the array after this sort call really sorted?) to more complex relationships between function input and output.&lt;/p&gt;
    &lt;p&gt;Ultimately, using SPARK allows you to eliminate various checkers (think MISRA-C checkers). By verifying properties with 100% certainty via mathematical proof, you can eliminate many unit-level tests. This yields direct cost savings and ensures an overall higher level of integrity.&lt;/p&gt;
    &lt;head rend="h1"&gt;So whatâs the best choice?&lt;/head&gt;
    &lt;p&gt;Choosing between Ada, Rust, and SPARK is a complex discussion. The key is, what is the team looking at achieving, and what is the potential appetite for change? The chart below provides some elements that can serve as the basis of a discussion. Different companies may allocate different weights to different elements. This is the way we view things at AdaCore and for our customers:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Ada&lt;/cell&gt;
        &lt;cell&gt;Rust&lt;/cell&gt;
        &lt;cell&gt;SPARK&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Community&lt;/cell&gt;
        &lt;cell&gt;Small&lt;/cell&gt;
        &lt;cell&gt;Large&lt;/cell&gt;
        &lt;cell&gt;Small&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Toolchain Embedded Ecosystem&lt;/cell&gt;
        &lt;cell&gt;Mature&lt;/cell&gt;
        &lt;cell&gt;In development&lt;/cell&gt;
        &lt;cell&gt;Mature&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Certification&lt;/cell&gt;
        &lt;cell&gt;Off-the-shelf&lt;/cell&gt;
        &lt;cell&gt;In development&lt;/cell&gt;
        &lt;cell&gt;Off-the-shelf&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Libraries available&lt;/cell&gt;
        &lt;cell&gt;Limited&lt;/cell&gt;
        &lt;cell&gt;Large&lt;/cell&gt;
        &lt;cell&gt;Limited&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Programming paradigm&lt;/cell&gt;
        &lt;cell&gt;Imperative system-level&lt;/cell&gt;
        &lt;cell&gt;Imperative system-level&lt;/cell&gt;
        &lt;cell&gt;Imperative system-level&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Mitigation of programming errors&lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Strong Typing&lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;Limited&lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Data constraints, hardware / software data consistency&lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Guaranteed absence of run-time errors&lt;/cell&gt;
        &lt;cell&gt;Run-time checks&lt;/cell&gt;
        &lt;cell&gt;Run-time checks&lt;/cell&gt;
        &lt;cell&gt;Static, via Proof&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Contract language (pre- post- conditions, invariants, predicatesâ¦)&lt;/cell&gt;
        &lt;cell&gt;Yes, checked at run-time&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;Yes, checked statically, via proof&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Memory safety&lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Pointer avoidance&lt;/p&gt;
          &lt;p&gt;Accessibility checks&lt;/p&gt;
          &lt;p&gt;Dynamic checks&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Borrow checker&lt;/p&gt;
          &lt;p&gt;Lifetimes&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Borrow checker&lt;/p&gt;
          &lt;p&gt;Pointer avoidance&lt;/p&gt;
          &lt;p&gt;Accessibility checks&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Cost of adoption&lt;/cell&gt;
        &lt;cell&gt;Language change&lt;/cell&gt;
        &lt;cell&gt;Language change&lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Methodology change&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Expected benefits&lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Mitigation of programming errors&lt;/p&gt;
          &lt;p&gt;Constraint checks&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Mitigation of programming errors&lt;/p&gt;
          &lt;p&gt;Memory safety&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Mitigation of programming errors&lt;/p&gt;
          &lt;p&gt;Memory Safety&lt;/p&gt;
          &lt;p&gt;Guarantee of absence of run-time errors&lt;/p&gt;
          &lt;p&gt;Guarantee of formal properties&lt;/p&gt;
          &lt;p&gt;Guarantee of constraint checks&lt;/p&gt;
          &lt;p&gt;Testing reduction&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Community&lt;/p&gt;
    &lt;p&gt;One of the big strengths of the Rust programming language is its large and vibrant community. Itâs easy to find resources on the language and people who have a true passion for it. Tools and libraries constantly emerge from the hobbyist scene, which can be easily leveraged when starting projects.&lt;/p&gt;
    &lt;p&gt;The Ada and SPARK communities are comparatively smaller. While excellent resources exist for learning Ada and SPARK, there are fewer community-provided tools and libraries. However, theyâve endured the test of time for over four decades and are composed of dedicated individuals. Today, they are also infused with new members and on the rise.&lt;/p&gt;
    &lt;p&gt;Overall, both communities benefit (albeit at different intensities) from the same underlying force: an increase in the demands for technology that provides safety and security.&lt;/p&gt;
    &lt;p&gt;Embedded Toolchain Ecosystem&lt;/p&gt;
    &lt;p&gt;Ada and SPARK have a very mature ecosystem, in particular in the embedded space. Besides the familiar Linux and Windows environment, compilers exist for many real-time operating systems and hardware architecture, and tools cover the whole range of needs from static analysis to dynamic analysis. All of this comes with industrial support. The tools also come with long term support, which means that you can select one version and stay supported for years or decades.&lt;/p&gt;
    &lt;p&gt;Rust today is becoming established in the native / server environments. Embedded RTOSes and architecture support are in the process of being developed. Itâs a lengthy process, due to the number of environments to support and their accessibility and specificities. Commercial support is also in development - some environments are already available off-the-shelf while others are being put together (including by AdaCore). The question of long-term support is also important, as some providers tend to update their toolchain very frequently, which may make long-lasting projects difficult to support. AdaCore addresses this specific issue with our products.&lt;/p&gt;
    &lt;p&gt;Undoubtedly, both languages will converge over time as far as toolchain goes - the choice criterion is more whether itâs important to have all of the answers today or if the adopting team can wait.&lt;/p&gt;
    &lt;p&gt;Certification&lt;/p&gt;
    &lt;p&gt;The situation on certification mimics the situation in toolchain support. Ada and SPARK, having been around for quite some time, have qualification and certification evidence for a wide variety of standards, notably the most common ones in the embedded world such as avionics (DO-178), automotive (ISO 26262), railway (EN-50128), space (ECSS-E-ST-40C and&lt;/p&gt;
    &lt;p&gt;ECSS-Q-ST-80C) and others.&lt;/p&gt;
    &lt;p&gt;Rust is a much younger technology, so it hasnât had the same amount of time for these to emerge. Weâre starting to see some automotive ISO-26262 evidence, which is currently limited to some environments and for some subsets of the Rust toolchain.&lt;/p&gt;
    &lt;p&gt;Libraries&lt;/p&gt;
    &lt;p&gt;One of the very strong attributes of the Rust programming language is the large number of libraries available through its cargo package manager. Pretty much anything that you can think of is covered one way or another. However, a number of these libraries are developed by hobbyists and many of the most popular libraries have yet to reach version 1.0.&lt;/p&gt;
    &lt;p&gt;Ada and SPARK have fewer off-the-shelf libraries available. The Alire package manager started in 2021, counts about 400 packages at the date of writing. This lack of native libraries is usually offset by binding from Ada and SPARK to pre-existing C or C++ libraries.&lt;/p&gt;
    &lt;p&gt;However, for both languages, constraints may come from regulatory or certification requirements, as publicly available libraries are usually not suitable for safety- or security-certified embedded development.&lt;/p&gt;
    &lt;p&gt;Programming paradigm&lt;/p&gt;
    &lt;p&gt;Thereâs no fundamental underlying difference in terms of the programming paradigms between Ada, SPARK, and Rust. They all are imperative modular languages, providing variations around the concepts of object orientation and other similar capabilities (as opposed to e.g. functional languages). Theyâre all statically compiled directly into machine code (as opposed to, e.g., interpreted languages).&lt;/p&gt;
    &lt;p&gt;Mitigation of programming errors&lt;/p&gt;
    &lt;p&gt;All three languages provide various mechanisms for avoiding or mitigating programming errors. For example, all three languages provide arrays as first-class citizens, containing boundaries and allowing for dynamic index checking. They also provide various ways to avoid uninitialized variables, data races, null pointer dereferencing, etc.&lt;/p&gt;
    &lt;p&gt;Strong Typing&lt;/p&gt;
    &lt;p&gt;Strong typing ensures that you can determine at compile time the specific type of an object and that you can check the integrity of its values throughout its usage. C is notably weakly typed: while variables are typed, implicit conversions allow you to mix numbers with different representations without the developer's oversight (for example, when adding integers and floats). This may result in various issues such as overflow, underflow or rounding errors. Treating arrays like pointers is another example of an issue that arises from weak typing.&lt;/p&gt;
    &lt;p&gt;Rustâs typing is stronger in this regard. Different types canât be mixed together without explicit conversion, and arrays are first-class citizens. This allows programmers to avoid a number of common programming mistakes.&lt;/p&gt;
    &lt;p&gt;Ada and SPARK go further. Types become fundamental elements of the software design. They are named, associated with a number of properties, and checked for consistency statically and dynamically. For example, you can declare a float to be a distance in miles and another float to be a percentage and then make sure that, without explicit conversion, thereâs no risk of mixing them up by mistake. Similarly, a latitude and longitude floating-point type could be defined and the type system would prevent mixing them up in subprogram calls or in arithmetic. Strong typing allows us to detect not only coding errors but also design inconsistencies.&lt;/p&gt;
    &lt;p&gt;Data constraints, hardware/software data consistency&lt;/p&gt;
    &lt;p&gt;The Ada and SPARK type system allows programmers to associate a number of properties, such as data ranges, representation constraints, or validity predicates with types. For example, a percentage type can be constrained to be between 0 and 100; a latitude could be constrained to be between -90 and 90 degrees; and a longitude could be constrained to be between -180 and 180 degrees. These constraints can be checked statically and dynamically, depending on the verification strategy. Data structures can be specified at the bit level in memory with specific endianness, avoiding common mistakes related to bitwise operations. Consistency of specification representation is checked statically (e.g., that there is no overlap between fields of structures, the number of bits specified for a type match is enough for the values that it can take, and the precision for a floating point value can be implemented in hardware).&lt;/p&gt;
    &lt;p&gt;Rust doesnât natively provide these capabilities. When needed, these capabilities could be implemented through more traditional design patterns, such as structures with appropriate methods.&lt;/p&gt;
    &lt;p&gt;Guaranteed absence of run-time errors&lt;/p&gt;
    &lt;p&gt;Run-time errors refer to errors that can be detected by checks and assertions while a program is running. For example, checking that an index used to access an array element is valid. Ada and Rust both provide run-time checks that verify the validity of data and would either raise an exception or issue a panic in case of a failure. While they incur a small footprint in code of code size and performance, they protect the code against much more adversarial vulnerabilities such as buffer overflows.&lt;/p&gt;
    &lt;p&gt;SPARK formally proves absence of run-time errors, at compile time. For example, SPARK statically checks that there are no code paths that can bring values out of bounds. This has the advantage of not only avoiding performance penalties, but also ensuring proper execution of the code against potential exceptions/panic - at the cost of more work on the programmer side to express additional constraints, assertions, and contracts (see later sections).&lt;/p&gt;
    &lt;p&gt;Contract language (pre- post- conditions, invariants, predicatesâ¦)&lt;/p&gt;
    &lt;p&gt;Ada and SPARK are unique in that they allow the description of contracts around software entities, notably types and functions. This allows constraints and dynamic behavior expectations to be encoded as part of the specification and checked for validity across the entire application.&lt;/p&gt;
    &lt;p&gt;Ada translates these contracts into dynamic checks that are verified at runtime. While this has a code size and performance footprint, it helps during testing, debugging, and integration phases and can be stripped out (fully or partially) at compilation time before deployment. Failure in contracts will typically be translated into exceptions.&lt;/p&gt;
    &lt;p&gt;SPARK allows formal, mathematical proof that contracts are always satisfied by the application, ensuring that, regardless of what value is manipulated, specified constraints and functional requirements are met. In this case, thereâs no need to compile these contracts into dynamic checks, obviating the space and performance penalties.&lt;/p&gt;
    &lt;p&gt;SPARK thus offers a paradigm shift for the programmer, who becomes much more verification-oriented, which is extremely valuable in high-integrity environments.&lt;/p&gt;
    &lt;p&gt;Thereâs no specification language in Rust that can be leveraged to implement these capabilities today. They can be emulated to some extent through defensive code and assertion for the purpose of dynamic checking. However, thereâs no technology today that allows formal proof of these kinds of properties like in SPARK.&lt;/p&gt;
    &lt;p&gt;Memory safety&lt;/p&gt;
    &lt;p&gt;One of Rust's most powerful capabilities is its ability to avoid memory errors through its ownership model of memory. This eliminates the most significant source of security vulnerabilities in software, simply by adopting rust, following the ownership model, and satisfying the borrow checker.&lt;/p&gt;
    &lt;p&gt;Ada, in its latest definition (2022), offers a pointer avoidance strategy that mitigates the risk of memory corruption. However, some programming patterns require the use of pointers, and in the absence of, an explicit ownership model borrow checker, memory issues are possible.&lt;/p&gt;
    &lt;p&gt;SPARK, on the other hand, adds a strong ownership model and borrow checker, providing the same level of guarantees as Rust.&lt;/p&gt;
    &lt;p&gt;Cost of adoption&lt;/p&gt;
    &lt;p&gt;The cost of adopting Ada and Rust is similar. In both cases, programmers must learn a new language and teams must deploy a new toolchain. While far from insignificant, programmers keep their overall programming processes more or less the same.&lt;/p&gt;
    &lt;p&gt;The cost of adopting SPARK is probably higher. At the outset, the toolchain and language considerations are pretty close to those of Ada. However, really adopting SPARK means adopting a different way of programming. To be effective, formal verification should be integrated into the development process and change the way software is designed, as well as bringing a number of verification steps earlier in the process. This is not an all-or-nothing decision; depending on the expected trade-off, more or less emphasis can be put on the properties to prove. The benefits can however be significant.&lt;/p&gt;
    &lt;p&gt;Expected benefits&lt;/p&gt;
    &lt;p&gt;Benefits depend on context - here weâre looking at languages in the context of high-integrity development.&lt;/p&gt;
    &lt;p&gt;At the coarse-grained level, the benefit of adopting Ada or Rust should be pretty similar. Both languages greatly reduce the odds of programming errors. Both languages address memory safety, albeit in different ways. When applicable, the Rust memory model will go further than the current Ada pointer-avoidance strategy, but Ada's strong specification and typing allow consistency checking in places where Rust canât yet. Literature on Ada highlights up to 40% development-cost savings compared to C. This does not account for the reduction of residual bugs that are less likely to make it into production.&lt;/p&gt;
    &lt;p&gt;Because SPARK delivers industrial-strength formal methods, it has the potential to exceed the benefits of Ada or Rust significantly. While a number of verification activities will be front-loaded during development, some testing and checking activities will be eliminated - those that would check constraints and properties expressed in SPARK. Deviations against specified behavior are not mitigated, they are eliminated from production. In the context of applications where defect cost is high and whose lifetime is counted in years or decades, this can yield significant gains, beyond the gains of a simple language change.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45486829</guid><pubDate>Mon, 06 Oct 2025 01:35:03 +0000</pubDate></item><item><title>Why do LLMs freak out over the seahorse emoji?</title><link>https://vgel.me/posts/seahorse/</link><description>&lt;doc fingerprint="2d678256c88d5a34"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why do LLMs freak out over the seahorse emoji?&lt;/head&gt;
    &lt;p&gt;This is an edited and expanded version of a Twitter post, originally in response to @arm1st1ce, that can be found here: https://x.com/voooooogel/status/1964465679647887838&lt;/p&gt;
    &lt;p&gt;Is there a seahorse emoji? Let's ask GPT-5 Instant:&lt;/p&gt;
    &lt;p&gt;Wtf? Let's ask Claude Sonnet 4.5 instead:&lt;/p&gt;
    &lt;p&gt;What's going on here? Maybe Gemini 2.5 Pro handles it better?&lt;/p&gt;
    &lt;p&gt;OK, something is going on here. Let's find out why.&lt;/p&gt;
    &lt;head rend="h2"&gt;LLMs really think there's a seahorse emoji&lt;/head&gt;
    &lt;p&gt;Here are the answers you get if you ask several models whether a seahorse emoji exists, yes or no, 100 times:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Is there a seahorse emoji, yes or no? Respond with one word, no punctuation.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;gpt-5-chat &lt;list rend="ul"&gt;&lt;item&gt;100% 'Yes'&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;gpt-5 &lt;list rend="ul"&gt;&lt;item&gt;100% 'Yes'&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;claude-4.5-sonnet &lt;list rend="ul"&gt;&lt;item&gt;100% 'Yes'&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;llama-3.3-70b &lt;list rend="ul"&gt;&lt;item&gt;83% 'yes'&lt;/item&gt;&lt;item&gt;17% 'Yes'&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Needlessly to say, popular language models are very confident that there's a seahorse emoji. And they're not alone in that confidence - here's a Reddit thread with hundreds of comments from people who distinctly remember a seahorse emoji existing:&lt;/p&gt;
    &lt;p&gt;There's tons of this - Google "seahorse emoji" and you'll find TikToks, Youtube videos, and even (now defunct) memecoins based around the supposed vanishing of a seahorse emoji that everyone is pretty sure used to exist - but of course, never did.&lt;/p&gt;
    &lt;p&gt;Maybe LLMs believe a seahorse emoji exists because so many humans in the training data do. Or maybe it's a convergent belief - given how many other aquatic animals are in Unicode, it's reasonable for both humans and LLMs to assume (generalize, even) that such a delightful animal is as well. A seahorse emoji was even formally proposed at one point, but was rejected in 2018.&lt;/p&gt;
    &lt;p&gt;Regardless of the root cause, many LLMs begin each new context window fresh with the mistaken latent belief that the seahorse emoji exists. But why does that produce such strange behavior? I mean, I used to believe a seahorse emoji existed myself, but if I had tried to send it to a friend, I would've simply looked for it on my keyboard and realized it wasn't there, not sent the wrong emoji and then gone into an emoji spam doomloop. So what's happening inside the LLM that causes it to act like this?&lt;/p&gt;
    &lt;head rend="h2"&gt;Using the logit lens&lt;/head&gt;
    &lt;p&gt;Let's look into this using everyone's favorite underrated interpretability tool, the logit lens!&lt;/p&gt;
    &lt;p&gt;Using this prompt prefix - a templated chat with the default llama-3.3-70b system prompt, a question about the seahorse emoji, and a partial answer from the model right before it gives the actual emoji:&lt;/p&gt;
    &lt;code&gt;&amp;lt;|begin_of_text|&amp;gt;&amp;lt;|begin_of_text|&amp;gt;&amp;lt;|start_header_id|&amp;gt;system&amp;lt;|end_header_id&amp;gt;
Cutting Knowledge Date: December 2023
Today Date: 26 Jul 2024

&amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;user&amp;lt;|end_header_id|&amp;gt;

Is there a seahorse emoji?&amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt;

Yes, there is a seahorse emoji:
&lt;/code&gt;
    &lt;p&gt;We can take the model's &lt;code&gt;lm_head&lt;/code&gt;, which is usually only used on the output of the last layer, and apply it to every layer to produce intermediate token predictions. That process produces this table, showing for every fourth layer what the most likely token would be for the next three positions after the prefix (tokens 0, 1, and 2), and what the top 5 most likely predictions for the first position is (token 0 topk 5):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;layer&lt;/cell&gt;
        &lt;cell role="head"&gt;tokens&lt;/cell&gt;
        &lt;cell role="head"&gt;tokens&lt;/cell&gt;
        &lt;cell role="head"&gt;token 0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;merged&lt;/cell&gt;
        &lt;cell&gt;(topk 5)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;83244'ĠBail'&lt;/cell&gt;
        &lt;cell&gt;15591'ĠHarr'&lt;/cell&gt;
        &lt;cell&gt;5309'Ġvert'&lt;/cell&gt;
        &lt;cell&gt;Bail Harr vert&lt;/cell&gt;
        &lt;cell&gt;['ĠBail', 'ĠPeanut', 'ĠãĢ', 'orr', 'ĠâĢĭâĢĭ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;111484'emez'&lt;/cell&gt;
        &lt;cell&gt;26140'abi'&lt;/cell&gt;
        &lt;cell&gt;25727'avery'&lt;/cell&gt;
        &lt;cell&gt;emezabiavery&lt;/cell&gt;
        &lt;cell&gt;['emez', 'Ġunm', 'ĠOswald', 'Ġrem', 'rix']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;122029'chyb'&lt;/cell&gt;
        &lt;cell&gt;44465'ĠCaps'&lt;/cell&gt;
        &lt;cell&gt;15610'iller'&lt;/cell&gt;
        &lt;cell&gt;chyb Capsiller&lt;/cell&gt;
        &lt;cell&gt;['chyb', 'ĠSund', 'ØªØ±ÛĮ', 'resse', 'Ġsod']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;12&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;48952'ĠCliff'&lt;/cell&gt;
        &lt;cell&gt;51965'ĠJackie'&lt;/cell&gt;
        &lt;cell&gt;... Cliff Jackie&lt;/cell&gt;
        &lt;cell&gt;['...', 'ages', 'dump', 'qing', 'Ġexp']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;16&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;12676'365'&lt;/cell&gt;
        &lt;cell&gt;31447'ĠAld'&lt;/cell&gt;
        &lt;cell&gt;...365 Ald&lt;/cell&gt;
        &lt;cell&gt;['...', '...Ċ', 'Ġindeed', 'Ġboth', 'ĠYes']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;20&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;109596'éļĨ'&lt;/cell&gt;
        &lt;cell&gt;51965'ĠJackie'&lt;/cell&gt;
        &lt;cell&gt;...隆 Jackie&lt;/cell&gt;
        &lt;cell&gt;['...', '...Ċ', 'Z', 'Ġboth', 'ĠHust']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;24&lt;/cell&gt;
        &lt;cell&gt;12'-'&lt;/cell&gt;
        &lt;cell&gt;31643'ï¸ı'&lt;/cell&gt;
        &lt;cell&gt;287'ing'&lt;/cell&gt;
        &lt;cell&gt;-️ing&lt;/cell&gt;
        &lt;cell&gt;['-', '...', 'âĢ¦', '...Ċ', 'em']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;28&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;96154'ĠGaut'&lt;/cell&gt;
        &lt;cell&gt;51965'ĠJackie'&lt;/cell&gt;
        &lt;cell&gt;... Gaut Jackie&lt;/cell&gt;
        &lt;cell&gt;['...', '-', '...Ċ', '-Ċ', 'Ġ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;32&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;96154'ĠGaut'&lt;/cell&gt;
        &lt;cell&gt;6892'Ġing'&lt;/cell&gt;
        &lt;cell&gt;... Gaut ing&lt;/cell&gt;
        &lt;cell&gt;['...', 'âĢ¦', '...Ċ', 'O', 'zer']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;36&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;12'-'&lt;/cell&gt;
        &lt;cell&gt;88'y'&lt;/cell&gt;
        &lt;cell&gt;...-y&lt;/cell&gt;
        &lt;cell&gt;['...', 'âĢ¦', '...Ċ', 'Ġ', 'u']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;40&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;31643'ï¸ı'&lt;/cell&gt;
        &lt;cell&gt;88'y'&lt;/cell&gt;
        &lt;cell&gt;...️y&lt;/cell&gt;
        &lt;cell&gt;['...', 'u', 'âĢ¦', 'Âł', '...Ċ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;44&lt;/cell&gt;
        &lt;cell&gt;80435'ĠScor'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;Scor horse horse&lt;/cell&gt;
        &lt;cell&gt;['ĠScor', 'u', 'ĠPan', 'in', 'Ġhttps']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;48&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;horse horse horse&lt;/cell&gt;
        &lt;cell&gt;['Ġhorse', 'Âł', 'ĠPan', 'ĠHomes', 'ĠHorse']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;52&lt;/cell&gt;
        &lt;cell&gt;9581'Ġsea'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;sea horse horse&lt;/cell&gt;
        &lt;cell&gt;['Ġsea', 'Ġhorse', 'ĠHorse', 'ĠSea', 'âĢĳ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;56&lt;/cell&gt;
        &lt;cell&gt;9581'Ġsea'&lt;/cell&gt;
        &lt;cell&gt;43269'ĠSeah'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;sea Seah horse&lt;/cell&gt;
        &lt;cell&gt;['Ġsea', 'ĠSea', 'ĠSeah', 'Ġhippoc', 'Ġhorse']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;60&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;horse horse horse&lt;/cell&gt;
        &lt;cell&gt;['Ġhorse', 'Ġsea', 'ĠSeah', 'Ġse', 'horse']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;64&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;horse horse horse&lt;/cell&gt;
        &lt;cell&gt;['Ġhorse', 'Ġse', 'ĠHorse', 'horse', 'Ġhors']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;68&lt;/cell&gt;
        &lt;cell&gt;60775'horse'&lt;/cell&gt;
        &lt;cell&gt;238'Ĳ'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;horse� horse&lt;/cell&gt;
        &lt;cell&gt;['horse', 'Ġse', 'Ġhorse', 'Ġhippoc', 'ĠSeah']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;72&lt;/cell&gt;
        &lt;cell&gt;513'Ġse'&lt;/cell&gt;
        &lt;cell&gt;238'Ĳ'&lt;/cell&gt;
        &lt;cell&gt;513'Ġse'&lt;/cell&gt;
        &lt;cell&gt;se� se&lt;/cell&gt;
        &lt;cell&gt;['Ġse', 'Ġhippoc', 'horse', 'ĠðŁ', 'Ġhorse']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;76&lt;/cell&gt;
        &lt;cell&gt;513'Ġse'&lt;/cell&gt;
        &lt;cell&gt;238'Ĳ'&lt;/cell&gt;
        &lt;cell&gt;513'Ġse'&lt;/cell&gt;
        &lt;cell&gt;se� se&lt;/cell&gt;
        &lt;cell&gt;['Ġse', 'Ġhippoc', 'hip', 'Ġhorse', 'ĠHipp']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;80&lt;/cell&gt;
        &lt;cell&gt;11410'ĠðŁ'&lt;/cell&gt;
        &lt;cell&gt;238'Ĳ'&lt;/cell&gt;
        &lt;cell&gt;254'ł'&lt;/cell&gt;
        &lt;cell&gt;🐠&lt;/cell&gt;
        &lt;cell&gt;['ĠðŁ', 'ðŁ', 'ĠðŁĴ', 'Ġ', 'ĠðŁĳ']&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;This is the logit lens: using the model's &lt;code&gt;lm_head&lt;/code&gt; to produce logits (token likelihoods) as a way to investigate its internal states. Note that the tokens and likelihoods we get from the logit lens here are not equivalent to the model's full internal states! For that, we would need a more complex technique like representation reading or sparse autoencoders. Instead, this is a lens on that state - it shows what the output token would be if this layer were the last one. But despite this limitation, the logit lens is still useful. The states of early layers may be difficult to interpret using it, but as we move up through the stack we can see that the model is iteratively refining those states towards its final prediction, a fish emoji.&lt;/p&gt;
    &lt;p&gt;(Why do the unmerged tokens look like that 'ĠðŁ', 'Ĳ', 'ł' nonsense? It's because of a tokenizer quirk - those tokens encode the UTF-8 bytes for the fish emoji. It's not relevant to this post, but if you're curious, ask Claude or your favorite LLM to explain this paragraph and this line of code: &lt;code&gt;bytes([bpe_byte_decoder[c] for c in 'ĠðŁĲł']).decode('utf-8') == ' 🐠'&lt;/code&gt;)&lt;/p&gt;
    &lt;p&gt;Take a look at what happens in the middle layers, though - it's not the early-layer weirdness or the emoji bytes of the final prediction! Instead we get words relating to useful concepts, specifically the concept of a seahorse. For example, on layer 52, we get "sea horse horse" - three residual positions in a row encoding the "seahorse" concept. Later, in the top-k for the first position, we get a mixture of "sea", "horse", and an emoji byte sequence prefix, "ĠðŁ".&lt;/p&gt;
    &lt;p&gt;So what is the model thinking about? "seahorse + emoji"! It's trying to construct a residual representation of a seahorse combined with an emoji. Why would the model try to construct this combination? Well, let's look into how the &lt;code&gt;lm_head&lt;/code&gt; actually works.&lt;/p&gt;
    &lt;head rend="h2"&gt;
      &lt;code&gt;lm_head&lt;/code&gt;
    &lt;/head&gt;
    &lt;p&gt;A language model's &lt;code&gt;lm_head&lt;/code&gt; is a huge matrix of residual-sized vectors associated with token ids, one for every token in the vocabulary (~300,000). When a residual is passed into it, either after flowing through the model normally or early because someone is using the logit lens on an earlier layer, the &lt;code&gt;lm_head&lt;/code&gt; is going to compare that input residual with each residual-sized vector in that big matrix, and (in coordination with the sampler) select the token id associated with the vector that matrix contains that is most similar to the input residual.&lt;/p&gt;
    &lt;p&gt;(More technically: &lt;code&gt;lm_head&lt;/code&gt; is a linear layer without a bias, so &lt;code&gt;x @ w.T&lt;/code&gt; does dot products with each unembedding vector to produce raw scores. Then your usual log_softmax and argmax/temperature sample.)&lt;/p&gt;
    &lt;p&gt;That means if the model wants to output the word "hello", for example in response to a friendly greeting from the user, it needs to construct a residual as similar as possible to the vector for the "hello" token that the &lt;code&gt;lm_head&lt;/code&gt; can then turn into the hello token id. And using logit lens, we can see that's exactly what happens in response to "Hello :-)":&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;layer&lt;/cell&gt;
        &lt;cell role="head"&gt;tokens&lt;/cell&gt;
        &lt;cell role="head"&gt;tokens&lt;/cell&gt;
        &lt;cell role="head"&gt;token 0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;merged&lt;/cell&gt;
        &lt;cell&gt;(topk 5)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0'!'&lt;/cell&gt;
        &lt;cell&gt;0'!'&lt;/cell&gt;
        &lt;cell&gt;40952'opa'&lt;/cell&gt;
        &lt;cell&gt;!!opa&lt;/cell&gt;
        &lt;cell&gt;['"', '!', '#', '%', '$']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;121495'ÅĻiv'&lt;/cell&gt;
        &lt;cell&gt;16'1'&lt;/cell&gt;
        &lt;cell&gt;73078'iae'&lt;/cell&gt;
        &lt;cell&gt;řiv1iae&lt;/cell&gt;
        &lt;cell&gt;['ÅĻiv', '-', '(', '.', ',']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;16&lt;/cell&gt;
        &lt;cell&gt;34935'Ġconsect'&lt;/cell&gt;
        &lt;cell&gt;7341'arks'&lt;/cell&gt;
        &lt;cell&gt;13118'Ġindeed'&lt;/cell&gt;
        &lt;cell&gt;consectarks indeed&lt;/cell&gt;
        &lt;cell&gt;['Ġobscure', 'Ġconsect', 'äºķ', 'ĠÐ¿ÑĢÐ¾ÑĦÐµÑģÑģÐ¸Ð¾Ð½Ð°Ð»ÑĮ', 'Îŀ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;24&lt;/cell&gt;
        &lt;cell&gt;67846'&amp;lt;['&lt;/cell&gt;
        &lt;cell&gt;24748'Ġhello'&lt;/cell&gt;
        &lt;cell&gt;15960'Ġhi'&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;[ hello hi&lt;/cell&gt;
        &lt;cell&gt;['&amp;lt;[', 'arks', 'outh', 'ĠHam', 'la']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;32&lt;/cell&gt;
        &lt;cell&gt;15825'-back'&lt;/cell&gt;
        &lt;cell&gt;2312'ln'&lt;/cell&gt;
        &lt;cell&gt;14451'UBL'&lt;/cell&gt;
        &lt;cell&gt;-backlnUBL&lt;/cell&gt;
        &lt;cell&gt;['ÂŃi', '-back', 'Ġquestion', 'ln', 'ant']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;40&lt;/cell&gt;
        &lt;cell&gt;15648'Ġsmile'&lt;/cell&gt;
        &lt;cell&gt;14262'Welcome'&lt;/cell&gt;
        &lt;cell&gt;1203'Ġback'&lt;/cell&gt;
        &lt;cell&gt;smileWelcome back&lt;/cell&gt;
        &lt;cell&gt;['Ġsmile', 'ĠÑĥÐ»ÑĭÐ±', 'Ġsmiled', 'ĠSmile', 'etwork']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;48&lt;/cell&gt;
        &lt;cell&gt;15648'Ġsmile'&lt;/cell&gt;
        &lt;cell&gt;21694'ĠHi'&lt;/cell&gt;
        &lt;cell&gt;1203'Ġback'&lt;/cell&gt;
        &lt;cell&gt;smile Hi back&lt;/cell&gt;
        &lt;cell&gt;['Ġsmile', 'Ġsmiled', 'ĠHello', 'Ġsmiling', 'Ġhello']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;56&lt;/cell&gt;
        &lt;cell&gt;22691'ĠHello'&lt;/cell&gt;
        &lt;cell&gt;15960'Ġhi'&lt;/cell&gt;
        &lt;cell&gt;1203'Ġback'&lt;/cell&gt;
        &lt;cell&gt;Hello hi back&lt;/cell&gt;
        &lt;cell&gt;['ĠHello', 'Ġhi', 'Ġsmile', 'Ġhello', 'Hello']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;64&lt;/cell&gt;
        &lt;cell&gt;4773'-sm'&lt;/cell&gt;
        &lt;cell&gt;24748'Ġhello'&lt;/cell&gt;
        &lt;cell&gt;1203'Ġback'&lt;/cell&gt;
        &lt;cell&gt;-sm hello back&lt;/cell&gt;
        &lt;cell&gt;['-sm', 'ĠHello', 'ĠSm', 'sm', 'Hello']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;72&lt;/cell&gt;
        &lt;cell&gt;22691'ĠHello'&lt;/cell&gt;
        &lt;cell&gt;22691'ĠHello'&lt;/cell&gt;
        &lt;cell&gt;1203'Ġback'&lt;/cell&gt;
        &lt;cell&gt;Hello Hello back&lt;/cell&gt;
        &lt;cell&gt;['ĠHello', 'Ġhello', 'Hello', 'ĠHEL', 'Ġhel']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;80&lt;/cell&gt;
        &lt;cell&gt;271'ĊĊ'&lt;/cell&gt;
        &lt;cell&gt;9906'Hello'&lt;/cell&gt;
        &lt;cell&gt;0'!'&lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Hello!&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;['ĊĊ', 'ĊĊĊ', '&amp;lt;|end_of_text|&amp;gt;', 'ĊĊĊĊ', '"ĊĊ']&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;('Ċ' is another tokenizer quirk - it represents a line break. 'Ġ' is similarly a space.)&lt;/p&gt;
    &lt;p&gt;Likewise, if the model wants to output a seahorse emoji, it needs to construct a residual similar to the vector for the seahorse emoji output token(s) - which in theory could be any arbitrary value, but in practice is "seahorse + emoji", word2vec style. We can see this in action with a real emoji, the fish emoji:&lt;/p&gt;
    &lt;code&gt;&amp;lt;|begin_of_text|&amp;gt;&amp;lt;|begin_of_text|&amp;gt;&amp;lt;|start_header_id|&amp;gt;system&amp;lt;|end_header_id|&amp;gt;

Cutting Knowledge Date: December 2023
Today Date: 26 Jul 2024

&amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;user&amp;lt;|end_header_id|&amp;gt;

Is there a fish emoji?&amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt;

Yes, there is a fish emoji:
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;layer&lt;/cell&gt;
        &lt;cell role="head"&gt;tokens&lt;/cell&gt;
        &lt;cell role="head"&gt;tokens&lt;/cell&gt;
        &lt;cell role="head"&gt;token 0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;merged&lt;/cell&gt;
        &lt;cell&gt;(topk 5)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;83244'ĠBail'&lt;/cell&gt;
        &lt;cell&gt;15591'ĠHarr'&lt;/cell&gt;
        &lt;cell&gt;5309'Ġvert'&lt;/cell&gt;
        &lt;cell&gt;Bail Harr vert&lt;/cell&gt;
        &lt;cell&gt;['ĠBail', 'ĠPeanut', 'ĠãĢ', 'orr', 'ĠâĢĭâĢĭ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;122029'chyb'&lt;/cell&gt;
        &lt;cell&gt;44465'ĠCaps'&lt;/cell&gt;
        &lt;cell&gt;15610'iller'&lt;/cell&gt;
        &lt;cell&gt;chyb Capsiller&lt;/cell&gt;
        &lt;cell&gt;['chyb', '...', 'ØªØ±ÛĮ', 'ĠSund', 'resse']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;16&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;12676'365'&lt;/cell&gt;
        &lt;cell&gt;65615'ĠSole'&lt;/cell&gt;
        &lt;cell&gt;...365 Sole&lt;/cell&gt;
        &lt;cell&gt;['...', '...Ċ', 'Ġboth', 'Ġindeed', 'ĠYes']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;24&lt;/cell&gt;
        &lt;cell&gt;12'-'&lt;/cell&gt;
        &lt;cell&gt;31643'ï¸ı'&lt;/cell&gt;
        &lt;cell&gt;51965'ĠJackie'&lt;/cell&gt;
        &lt;cell&gt;-️ Jackie&lt;/cell&gt;
        &lt;cell&gt;['-', '...', 'âĢ¦', 'em', '...Ċ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;32&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;96154'ĠGaut'&lt;/cell&gt;
        &lt;cell&gt;88'y'&lt;/cell&gt;
        &lt;cell&gt;... Gauty&lt;/cell&gt;
        &lt;cell&gt;['...', 'âĢ¦', '...Ċ', 'O', 'u']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;40&lt;/cell&gt;
        &lt;cell&gt;220'Ġ'&lt;/cell&gt;
        &lt;cell&gt;6"'"&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;'fish&lt;/cell&gt;
        &lt;cell&gt;['Ġ', '...', 'âĢ¦', 'Âł', 'u']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;48&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;fish fish fish&lt;/cell&gt;
        &lt;cell&gt;['Ġfish', 'ĠFish', 'ĠBerk', 'âĢ¦', 'Âł']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;56&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;fish fish fish&lt;/cell&gt;
        &lt;cell&gt;['Ġfish', 'ĠFish', 'fish', 'Fish', 'é±¼']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;64&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;238'Ĳ'&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;fish� fish&lt;/cell&gt;
        &lt;cell&gt;['Ġfish', 'ĠFish', 'ĠPis', 'Fish', 'ĠÙħØ§Ùĩ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;72&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;238'Ĳ'&lt;/cell&gt;
        &lt;cell&gt;253'Ł'&lt;/cell&gt;
        &lt;cell&gt;fish��&lt;/cell&gt;
        &lt;cell&gt;['Ġfish', 'ĠFish', 'ĠðŁ', 'Ġ', 'ÂŁ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;80&lt;/cell&gt;
        &lt;cell&gt;11410'ĠðŁ'&lt;/cell&gt;
        &lt;cell&gt;238'Ĳ'&lt;/cell&gt;
        &lt;cell&gt;253'Ł'&lt;/cell&gt;
        &lt;cell&gt;🐟&lt;/cell&gt;
        &lt;cell&gt;['ĠðŁ', 'ðŁ', 'Ġ', 'ĠĊĊ', 'ĠâĻ']&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Here, everything works perfectly. The model constructs the "fish + emoji" residual - look at the layer 72 topk, where we have both "fish" and the emoji byte prefix "ĠðŁ" - meaning that the residual at this point is similar to both "fish" and "emoji", just like we'd expect. Then when this vector is passed into the &lt;code&gt;lm_head&lt;/code&gt; after the final layer, we see a 🐟 just as the model expected.&lt;/p&gt;
    &lt;p&gt;But unlike with 🐟, the seahorse emoji doesn't exist. The model tries to construct a "seahorse + emoji" vector just as it would for a real emoji, and on layer 72 we even get a very similar construction as with the fish emoji - " se", "horse", and the emoji prefix byte prefix:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;layer&lt;/cell&gt;
        &lt;cell role="head"&gt;tokens&lt;/cell&gt;
        &lt;cell role="head"&gt;tokens&lt;/cell&gt;
        &lt;cell role="head"&gt;token 0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;merged&lt;/cell&gt;
        &lt;cell&gt;(topk 5)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;72&lt;/cell&gt;
        &lt;cell&gt;513'Ġse'&lt;/cell&gt;
        &lt;cell&gt;238'Ĳ'&lt;/cell&gt;
        &lt;cell&gt;513'Ġse'&lt;/cell&gt;
        &lt;cell&gt;se� se&lt;/cell&gt;
        &lt;cell&gt;['Ġse', 'Ġhippoc', 'horse', 'ĠðŁ', 'Ġhorse']&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;But alas, there's no continuation to ĠðŁ corresponding to a seahorse, so the &lt;code&gt;lm_head&lt;/code&gt; similarity score calculation maxes out with horse- or sea-animal-related emoji bytes instead, and an unintended emoji is sampled.&lt;/p&gt;
    &lt;p&gt;Now, that sampling is valuable information for the model! You can see that in, e.g. the Claude 4.5 Sonnet example below, when the tokens get appended into the context autoregressively, the model can tell that they don't form the intended seahorse emoji. The previous, fuzzy "seahorse + emoji" concept has been "snapped" by the &lt;code&gt;lm_head&lt;/code&gt; to an emoji that actually exists, like a tropical fish or horse.&lt;/p&gt;
    &lt;p&gt;Once this happens, it's up to the model how to proceed. Some models like 4.5 Sonnet try again, and eventually update on the evidence, changing mid-response to a statement about how the seahorse emoji doesn't exist. Other models like gpt-5-chat spiral for longer, sometimes never recovering. Other models will either blissfully ignore that the emoji is incorrect, and some will even correct themselves instantly after seeing only a single incorrect sample.&lt;/p&gt;
    &lt;p&gt;But until the model gets the wrong output token from &lt;code&gt;lm_head&lt;/code&gt;, it just doesn't know that its initial belief about a seahorse emoji existing was wrong. It can only assume that "seahorse + emoji" will produce the tokens it wants.&lt;/p&gt;
    &lt;head rend="h2"&gt;Some speculation&lt;/head&gt;
    &lt;p&gt;To speculate a bit more, I wonder if this problem is part of the benefit of reinforcement learning for LLMs - it gives the model information about its &lt;code&gt;lm_head&lt;/code&gt; that's otherwise difficult for it to get at because it's at the end of the layer stack.&lt;/p&gt;
    &lt;p&gt;(Remember that base models are not trained on their own outputs / rollouts. That only happens in RL.)&lt;/p&gt;
    &lt;head rend="h2"&gt;Code&lt;/head&gt;
    &lt;p&gt;If you want to try this yourself, you can find a starter script on Github here: https://gist.github.com/vgel/025ad6af9ac7f3bc194966b03ea68606&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45487044</guid><pubDate>Mon, 06 Oct 2025 02:20:05 +0000</pubDate></item><item><title>Building Effective Text-to-3D AI Agents: A Hybrid Architecture Approach</title><link>https://www.addy.rocks/blog/text-to-3d-agent-hybrid-architecture</link><description>&lt;doc fingerprint="9c97c758ed1890ab"&gt;
  &lt;main&gt;
    &lt;p&gt;As promised, let's deep dive into the learnings from my text-to-3D agent project. The goal was to go beyond simple shapes and see if an AI agent could generate complex 3D models using Blender's Python API.&lt;/p&gt;
    &lt;p&gt;The short answer: yes, but the architecture is everything.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Core Challenge: Reasoning vs. Syntax&lt;/head&gt;
    &lt;p&gt;Most LLMs can write a simple Blender script for a cube. But a "low poly city block"? That requires planning, iteration, and self-correctionâtasks that push models to their limits. This isn't just a coding problem; it's a reasoning problem.&lt;/p&gt;
    &lt;head rend="h2"&gt;My Approach: A Hybrid Agent Architecture ð§&lt;/head&gt;
    &lt;p&gt;I hypothesized that no single model could do it all. So, I designed a hybrid system that splits the work:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A "Thinker" LLM (SOTA models): Responsible for high-level reasoning, planning the steps, and generating initial code.&lt;/item&gt;
      &lt;item&gt;A "Doer" LLM (Specialized Coder models): Responsible for refining, debugging, and ensuring syntactical correctness of the code.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I tested three architectures on tasks of varying difficulty:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Homogeneous SOTA: A large model doing everything.&lt;/item&gt;
      &lt;item&gt;Homogeneous Small: A small coder model doing everything.&lt;/item&gt;
      &lt;item&gt;Hybrid: The "Thinker" + "Doer" approach.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The Results: 3 Key Takeaways ð&lt;/head&gt;
    &lt;p&gt;The data from the experiments was incredibly clear.&lt;/p&gt;
    &lt;head rend="h3"&gt;1. The Hybrid Model is the Undisputed Winner&lt;/head&gt;
    &lt;p&gt;Pairing a powerful reasoning LLM with a specialized coder LLM was significantly more efficient (fewer iterations) and reliable than using a single SOTA model for everything.&lt;/p&gt;
    &lt;head rend="h3"&gt;2. Homogeneous Small Models are a Trap ð¥&lt;/head&gt;
    &lt;p&gt;Using only a small coder model for both reasoning and syntax was a recipe for disaster. This architecture failed 100% of the time, often getting stuck in infinite "tool loops" and never completing the task.&lt;/p&gt;
    &lt;head rend="h3"&gt;3. Memory Had an Unexpected Impact. ð§&lt;/head&gt;
    &lt;p&gt;Contrary to my initial hypothesis, adding a memory module in this setup actually increased the average number of iterations. This suggests that the current memory implementation might be introducing overhead or causing the agent to over-index on past actions rather than improving efficiency. Interesting problem that needs more investigation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Qualitative Insights: How the Models Behaved&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Model Quality: For visual appeal and creativity, the SOTA models were unmatched. Gemini and Claude produced the most impressive geometry.&lt;/item&gt;
      &lt;item&gt;Tool Looping: Qwen had the highest tendency to get stuck in loops, making it unreliable as a standalone agent.&lt;/item&gt;
      &lt;item&gt;Context Issues: GLM performed reasonably well but struggled to maintain structured output with a long context history.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Implementation Considerations&lt;/head&gt;
    &lt;p&gt;When building your own hybrid agent architecture, consider these factors:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Task Decomposition: Clearly separate reasoning tasks from execution tasks&lt;/item&gt;
      &lt;item&gt;Model Selection: Choose models that excel in their specific domain (reasoning vs. code generation)&lt;/item&gt;
      &lt;item&gt;Error Handling: Build robust loops detection and recovery mechanisms&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;ð¼ï¸ The Big Picture&lt;/head&gt;
    &lt;p&gt;Building effective AI agents isn't about finding one "god-tier" model. It's about smart architecture. By composing specialized models and giving them memory, we can create agents that are far more capable than the sum of their parts.&lt;/p&gt;
    &lt;p&gt;This unlocks a new wave of gen AI tools for complex creative work. The future of AI agents lies not in bigger models, but in better orchestration of specialized models working together.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45487247</guid><pubDate>Mon, 06 Oct 2025 02:57:21 +0000</pubDate></item><item><title>Find Nearby Automated License Plate Readers (ALPR)</title><link>https://deflock.me/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45487452</guid><pubDate>Mon, 06 Oct 2025 03:42:15 +0000</pubDate></item><item><title>1 Trillion Web Pages Archived</title><link>https://blog.archive.org/trillion/</link><description>&lt;doc fingerprint="1a1cb085e3f4f429"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;This October, the Internet Archive will celebrate an extraordinary milestone: 1 trillion web pages preserved and available for access via the Wayback Machine.&lt;/head&gt;
    &lt;p&gt;Calendar of Events | Impact Stories | Support the Internet Archive | Press Kit&lt;/p&gt;
    &lt;p&gt;Since 1996, the Internet Archive has worked with libraries and partners around the world to build a shared digital library of humanity’s online history: capturing websites large and small—from breaking news to forgotten personal pages—so they remain accessible for future generations.&lt;/p&gt;
    &lt;p&gt;The series of events scheduled throughout October will highlight the memories, makers, and movements that have made this achievement possible, and will look ahead to the future of web preservation as we continue building the web’s collective memory together.&lt;/p&gt;
    &lt;head rend="h1"&gt;Calendar of Events&lt;/head&gt;
    &lt;head rend="h2"&gt;October 7—The Vast Blue We: Del Sol Quartet at the Internet Archive&lt;/head&gt;
    &lt;p&gt;7:00-8:15pm PT&lt;lb/&gt;Internet Archive&lt;lb/&gt;300 Funston Avenue, San Francisco &amp;amp; ONLINE&lt;lb/&gt;Register now for IN-PERSON or VIRTUAL tickets&lt;/p&gt;
    &lt;p&gt;An evening to celebrate human collaboration—how billions of individual actions weave together into something vast and beautiful. Through music of Del Sol Quartet with new works by Erika Oba and Sam Reider, we mark the staggering scale of one trillion archived web pages available via the Wayback Machine. Join us for an interactive evening of live music reflecting the wonder of what we can achieve together and the power of our own voices.&lt;/p&gt;
    &lt;head rend="h2"&gt;October 9—A Conversation with Sir Tim Berners-Lee and Brewster Kahle&lt;/head&gt;
    &lt;p&gt;Building and Preserving the Web: A Conversation with Sir Tim Berners-Lee and Brewster Kahle&lt;lb/&gt;7:30pm PT&lt;lb/&gt;The Commonwealth Club of California&lt;lb/&gt;110 The Embarcadero, San Francisco &amp;amp; ONLINE&lt;lb/&gt;Register now for IN-PERSON or VIRTUAL tickets&lt;/p&gt;
    &lt;p&gt;Sir Tim Berners-Lee and Brewster Kahle will be in conversation about the rise of the internet, its continuing and explosive impact on society, the importance of the Internet Archive and other developing issues in the growth and use of the internet.&lt;/p&gt;
    &lt;head rend="h2"&gt;October 16—Library Leaders Forum 2025 (VIRTUAL)&lt;/head&gt;
    &lt;p&gt;10:00-11:30am PT&lt;lb/&gt;ONLINE&lt;lb/&gt;Register now for VIRTUAL tickets&lt;/p&gt;
    &lt;p&gt;In our virtual Library Leaders Forum, you’ll hear from Internet Archive staff and partners about our emerging library services and updates on existing efforts. How do libraries empower research in the 21st century? Join in our discussion!&lt;/p&gt;
    &lt;head rend="h2"&gt;October 21—Doors Open 2025: Go Behind the Scenes at the Physical Archive&lt;/head&gt;
    &lt;p&gt;6:00-8:00pm PT&lt;lb/&gt;Richmond, California&lt;lb/&gt;Register now for IN-PERSON tickets&lt;/p&gt;
    &lt;p&gt;The Internet Archive is excited to offer a behind-the-scenes tour of the physical collections of books, music, film, and video in Richmond, California.&lt;/p&gt;
    &lt;p&gt;With this special insider event we are opening the doors to an often unseen place. See the lifecycle of physical materials: donation, preservation, digitization, and access. Also, samples from generous donations and acquisitions of books, records, microfiche, and more will be on display.&lt;/p&gt;
    &lt;head rend="h2"&gt;October 22—The Web We’ve Built: Celebrating 1 Trillion Web Pages Archived&lt;/head&gt;
    &lt;p&gt;5:00-10:00pm PT&lt;lb/&gt;7:00-8:00pm PT Live Stream&lt;lb/&gt;Internet Archive&lt;lb/&gt;300 Funston Ave, San Francisco&lt;lb/&gt;Register now for IN-PERSON or VIRTUAL tickets&lt;/p&gt;
    &lt;p&gt;This October, the Internet Archive’s Wayback Machine is projected to hit a once-in-a-generation milestone: 1 trillion web pages archived. That’s one trillion memories, moments, and movements—preserved for the public and available to access via the Wayback Machine.&lt;/p&gt;
    &lt;p&gt;We’ll be commemorating this historic achievement on October 22, 2025, with a global event: a party at our San Francisco headquarters and a livestream for friends and supporters around the world. More than a celebration, it’s a tribute to what we’ve built together: a free and open digital library of the web.&lt;/p&gt;
    &lt;p&gt;Join us in marking this incredible milestone. Together, we’ve built the largest archive of web history ever assembled. Let’s celebrate this achievement—in San Francisco and around the world—on October 22.&lt;/p&gt;
    &lt;head rend="h2"&gt;October 27—Wayback to the Future: Celebrating the Open Web&lt;/head&gt;
    &lt;p&gt;5:00-8:00pm PT&lt;lb/&gt;Riggs Library, Georgetown University&lt;lb/&gt;Healy Hall, Library Walk, Washington, DC 20057&lt;lb/&gt;Register now for IN-PERSON tickets&lt;/p&gt;
    &lt;p&gt;Join the Foundation for American Innovation, the Massive Data Institute and the Internet Archive at Georgetown University’s historic Riggs Library for Wayback to the Future: Celebrating the Open Web—Past, Present, and Possible.&lt;/p&gt;
    &lt;p&gt;The open web was once defined by experimentation, decentralization, and possibility. The technological advancements were driven by the desire for a place where new voices and ideas could flourish. Today, consolidation and walled gardens challenge that vision. Together, we’ll look back at the internet’s origins to spark a forward-looking conversation about how to keep the web free, open, and innovative.&lt;/p&gt;
    &lt;p&gt;Speakers include:&lt;/p&gt;
    &lt;p&gt;Moderator: Luke Hogg — Director of Technology Policy, FAI&lt;lb/&gt;Brewster Kahle — Founder &amp;amp; Director, Internet Archive&lt;lb/&gt;Vint Cerf — Chief Internet Evangelist, Google&lt;lb/&gt;Cindy Cohn — Executive Director, Electronic Frontier Foundation&lt;lb/&gt;Jon Stokes – Co-founder, Ars Technica &lt;/p&gt;
    &lt;head rend="h1"&gt;Impact Stories&lt;/head&gt;
    &lt;p&gt;The 1 trillion archived webpages are more than just numbers—they represent real impact on people’s lives, research, and memory. From immigration cases to personal histories, academic research to investigative journalism, the Wayback Machine has become an essential public resource that preserves the web for all.&lt;/p&gt;
    &lt;p&gt;Canadian musician David Samuel relied on archived concert programs in the Wayback Machine to secure U.S. residency.&lt;/p&gt;
    &lt;p&gt;Paul Lindner built a digital memorial to his late wife by recovering her online presence.&lt;/p&gt;
    &lt;p&gt;Researchers at King’s College London use web archives to track the evolution of fake news and open data.&lt;/p&gt;
    &lt;p&gt;Investigative trainers call the Wayback Machine “a precious tool” for exposing deleted evidence.&lt;/p&gt;
    &lt;head rend="h1"&gt;Share Your Story&lt;/head&gt;
    &lt;p&gt;What does the web mean to you? How has the Wayback Machine helped you remember, research, or recover something important? Share your story.&lt;/p&gt;
    &lt;head rend="h1"&gt;Support the Internet Archive&lt;/head&gt;
    &lt;p&gt;Help us continue preserving the web for generations to come. Donate today!&lt;/p&gt;
    &lt;head rend="h1"&gt;Press Kit&lt;/head&gt;
    &lt;p&gt;Interested in producing a story about the 1 trillion milestone? Our online press kit includes impact stories from users, facts &amp;amp; figures about the Internet Archive &amp;amp; Wayback Machine, and Then/Now screenshots of popular web sites. Contact info is available in the press kit.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45487476</guid><pubDate>Mon, 06 Oct 2025 03:48:34 +0000</pubDate></item><item><title>CHERI with a Linux on Top</title><link>https://lwn.net/Articles/1037974/</link><description>&lt;doc fingerprint="97e398dd7db79789"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;CHERI with a Linux on top&lt;/head&gt;
    &lt;quote&gt;This article brought to you by LWN subscribers&lt;p&gt;Subscribers to LWN.net made this article — and everything that surrounds it — possible. If you appreciate our content, please buy a subscription and make the next set of articles possible.&lt;/p&gt;&lt;/quote&gt;
    &lt;p&gt;The Capability Hardware Enhanced RISC Instructions (CHERI) project is a rethinking of computer architecture in order to improve system security. Carl Shaw gave a presentation at Linux Security Summit Europe (LSS EU) about CHERI and the efforts to get Linux running on it. He introduced capabilities, which are a mechanism for access control, and outlined their history, which goes back many decades at this point, then looked more specifically at the CHERI project and what it will take to apply the security constraints of capabilities to an operating system like Linux.&lt;/p&gt;
    &lt;head rend="h4"&gt;Capabilities&lt;/head&gt;
    &lt;p&gt; At its core, CHERI is about extending instruction-set architectures (ISAs) to add support for capabilities. A 1966 paper, "Programming Semantics for Multiprogrammed Computations", introduced the idea of capabilities, along with many of the ideas that would later underlie Unix. The paper had a strong focus on security and ensuring that computations did not interfere with each other; it generalized some ideas from earlier computers like Atlas, Rice Computer, and various Burroughs machines into what the authors called "capabilities". "&lt;quote&gt;Processes need to own capabilities to be able to do something on a system.&lt;/quote&gt;" &lt;/p&gt;
    &lt;p&gt; A capability is a reference and a set of rights; "&lt;quote&gt;a capability is an access-control object&lt;/quote&gt;". It was originally applied to memory, but the paper expanded the idea to cover I/O and other system resources. For memory, which he was focusing on for the talk, the reference is to a region of memory and the rights are permissions to read, write, and execute it. More formally, "&lt;quote&gt;a capability is an unforgeable, transferable token that authorizes the use of an object&lt;/quote&gt;", he said. &lt;/p&gt;
    &lt;p&gt;An object capability of that sort incorporates both a reference to the object and access rights for that object. The paper used a list of capabilities that a process had access to, which was called the "C-list". Each entry was a capability, with a reference to a memory segment and the permissions for it. So access to memory required an indirection through the C-list table, which turned out not to perform well.&lt;/p&gt;
    &lt;p&gt; He mentioned a few of the early hardware implementations of capabilities, starting in 1970, though he said there were some slightly earlier machines in the US. The CAP computer was from Cambridge University; the "&lt;quote&gt;first ever commercial capability-based system&lt;/quote&gt;" was the Plessey System 250, which was not a general-purpose computer and was originally used by the military for message routing. It did have many of the attributes of modern computers, such as virtual memory and symmetric multiprocessing; "&lt;quote&gt;it was a pretty far ahead machine for its day&lt;/quote&gt;". &lt;/p&gt;
    &lt;p&gt; A less-successful capability-based CPU is the Intel iAPX 432 from 1975, which ended up only being used in niche applications. Its performance was poor, mainly due to the indirection required to access memory. More recently, the Arm Morello CPU in 2022 was the result of a research project between the company and the UK government; it added CHERI on top of an Arm Neoverse processor. It was developed on a short time scale of about a year, so compromises inevitably had to be made, Shaw said, but "&lt;quote&gt;they did a really good job on it&lt;/quote&gt;"; it is still used for research, but newer CHERI implementations have narrowed their focus to a smaller, more commercially viable subset of capabilities than the Morello has. &lt;/p&gt;
    &lt;p&gt; There were a number of operating systems developed using capabilities, "&lt;quote&gt;some you've probably never heard of&lt;/quote&gt;", including KeyKOS, EROS, and CapROS, which were mostly "&lt;quote&gt;focused around high levels of reliability&lt;/quote&gt;". In modern times, seL4 uses capabilities and, this year, it is joined by CHERI-seL4. &lt;/p&gt;
    &lt;p&gt;But, his talk was aimed at Linux, he said. Linux already has some vestiges of capabilities, including things like socket and file descriptors, which can be passed around to other processes to bestow rights. Kernel capabilities are not true capabilities in his mind, but page-table entries are a form of capabilities: they have a reference to a memory region and associated permissions.&lt;/p&gt;
    &lt;head rend="h4"&gt;CHERI&lt;/head&gt;
    &lt;p&gt; "&lt;quote&gt;CHERI is a new implementation of capabilities&lt;/quote&gt;"; it is a security technology that is designed to be scalable, so that it can be used in everything from microcontrollers to server-class hardware. It is deterministic; CHERI does not rely on any hashing or secrets. "&lt;quote&gt;It's very much a hardware/software co-design technology, as well,&lt;/quote&gt;" Shaw said. &lt;/p&gt;
    &lt;p&gt;Capability-based addressing is used by CHERI, which is a variant without C-lists, so it does not suffer the performance penalties for indirection. CHERI extends existing ISAs. It started by extending MIPS, then Morello extended Arm, and now most of the work being done is for RISC-V; there is also an initial sketch of how the x86 ISA could accommodate CHERI, he said. CHERI takes a hybrid capability approach, so that it can work with existing systems as they are; it accommodates memory-management units (MMUs), hypervisors, and existing programming languages.&lt;/p&gt;
    &lt;p&gt;The CHERI instructions do not use integer address pointers, they use capabilities for addresses instead. Existing code will still run on a CHERI system, using addresses the way it currently does, but it will not get the benefit of the CHERI protections.&lt;/p&gt;
    &lt;p&gt;The project was started 15 years ago by Cambridge University and SRI International funded by DARPA. The CHERI Alliance is the focal point of current research, which is being funded by both governments and companies.&lt;/p&gt;
    &lt;p&gt; The goals of CHERI are to provide memory safety for languages like C and C++, though it will also benefit others, including Rust, while also offering "&lt;quote&gt;fine-grained, efficient compartmentalization&lt;/quote&gt;". There is already coarse-grained compartmentalization in today's systems, including protection (or privilege) rings and MMUs protecting processes from each other, but CHERI is "&lt;quote&gt;designed to be very very fine-grained, down to the byte level, if you wanted to go there&lt;/quote&gt;". &lt;/p&gt;
    &lt;p&gt; The intent was for existing code to run unchanged, "&lt;quote&gt;but it never works like that&lt;/quote&gt;". For most well-written C and C++ application code, a recompile is largely all that is needed to work on a CHERI system. For example, KDE was ported to CHERI on Morello and only required changes to 0.02% of the code to get it working. For things like language runtimes, JIT compilers, memory allocators, and code that does lots of pointer manipulation, such as kernels, it gets more complicated. Beyond Linux, FreeRTOS, Zephyr, and (as mentioned) seL4 have all been ported to run on CHERI hardware; other operating systems are in progress as well. &lt;/p&gt;
    &lt;p&gt;The instructions that CHERI adds to the ISA are for creating and modifying capabilities; the modifications are operations that are normally expected for pointers, such as incrementing and other arithmetic operations. The hardware itself needs to be changed to support capabilities; registers need to be extended to hold them, for example.&lt;/p&gt;
    &lt;p&gt;There is both a pure-capability (purecap) mode, where only capabilities can be used for memory access, and an integer-pointer (integer) mode, which uses regular pointers. There is actually a way to have both in a single program, with pointers annotated based on which type they are, but it is not recommended, Shaw said. On the CPU, there is a mode switch that is made between the two modes, which is particularly important on RISC-V to save space in the ISA encoding; for example, load and store instruction encodings are shared between the modes.&lt;/p&gt;
    &lt;p&gt; On a CHERI system, all loads and stores are checked against a capability, even when running in integer mode. There is a program-counter capability (PCC) for both modes, and a default data capability (DCC) for integer mode, which allows the accesses from programs in integer mode to be constrained; "&lt;quote&gt;we can set where it can execute and we can set what it can see in memory&lt;/quote&gt;". &lt;/p&gt;
    &lt;p&gt;In terms of implementation, a capability is an address that has been extended with metadata, but it is important to think of them as a single unit. There is a bounds field, which holds upper and lower bounds for memory addresses, and a permissions field that has the usual read, write, and execute permissions as well as some others, including whether you can store the capability to memory or not. On the CHERI RISC-V, capabilities are 128 bits in size; all of the registers and caches need to accommodate pointers of that size. There is also an out-of-band single bit tag that is used to indicate whether the contents of memory or a register contain a valid capability or not; software generally does not need to interact with the tag directly, he said.&lt;/p&gt;
    &lt;p&gt; Originally, capabilities were 256 bits so that they could included full 64-bit upper and lower bounds. "&lt;quote&gt;One of the innovations of CHERI is to use a compressed format for bounds&lt;/quote&gt;"; the CHERI RISC-V uses a mantissa-exponent system, which reduces the resolution but that is not much of a problem on a virtual-memory system, he said. &lt;/p&gt;
    &lt;p&gt;There are some rules for using capabilities in CHERI, starting with the provenance rule: a capability can only be created using another valid capability. The monotonicity rule says that a new capability can only have the same or lesser rights than the capability it is created from. The reachable capability monotonicity rule disallows increasing the reachable capabilities for a given chunk of code without yielding execution to another domain. The code only has access to a limited set of capabilities, but if it takes an interrupt, that will run in a different domain, which could perhaps increase the capabilities available to it.&lt;/p&gt;
    &lt;p&gt;When the system boots, it has access to the "infinite cap" (or "root cap"), which is all of the permissions for all of memory; it is generally stored in the PCC. As an example, the system could then create two compartments by creating sub-capabilities that were more restricted; each could have non-overlapping bounds, and one region could perhaps be for code, so it only has read and execute permissions. Then, inside the other region, a read-only array capability could be created; anything having that capability can read the array, but nowhere else in the enclosing region.&lt;/p&gt;
    &lt;p&gt; Most of the "&lt;quote&gt;heavy lifting&lt;/quote&gt;" for setting up the capabilities is done by the compiler, Shaw said. For example, a static C array will have a capability created for it by the compiler, which is how CHERI can provide memory safety to C code. The program cannot successfully read or write outside of the array because the capability it must use to access the array will not allow it to do so. Stacks can be made non-executable by removing that permission from the capability for the stack frame, for example. &lt;/p&gt;
    &lt;head rend="h4"&gt;Linux&lt;/head&gt;
    &lt;p&gt; CHERI provides run-time memory safety that is hardware-enforced, which is critical for C and C++ programs. The Linux kernel is mostly implemented in C so getting memory safety for it requires a tool like CHERI. In addition, CHERI allows implementing least-privilege compartmentalization. There have been supply-chain attacks against libraries, which CHERI could protect against by putting "&lt;quote&gt;a library into a sandbox, mostly automatically, which can constrain its access and its entry and exit points&lt;/quote&gt;". Within the kernel, a similar approach can be taken by placing subsystems and drivers inside sandboxes. An analysis of kernel bugs in 2022 showed that 87% of the high-severity kernel CVEs could be mitigated with either memory safety or compartmentalization; "&lt;quote&gt;we see that as a pretty important thing to try and achieve&lt;/quote&gt;". &lt;/p&gt;
    &lt;p&gt; About two weeks before his talk in late August, CHERI Linux developers got the 6.16 kernel running in purecap mode; "&lt;quote&gt;so this means that every pointer in the kernel is now a capability&lt;/quote&gt;". Originally, Huawei did a proof of concept of Linux running on CHERI, then the Morello project ported Linux to that hardware; the Morello version used the hybrid mode, where most of the pointers were still integers, though the system-call level used capabilities. &lt;/p&gt;
    &lt;p&gt; His employer, Codasip, has a team that is working on Linux for CHERI on RISC-V; it started with the hybrid Morello kernel, but then did a clean implementation in purecap mode. "&lt;quote&gt;We do not claim it's perfect, what we're aiming for at the moment is functionality; we want to get the basics running, then we're gonna go on to the more advanced security concepts.&lt;/quote&gt;" Some of those advanced techniques have already been proved on FreeBSD in CheriBSD, he said, but not on Linux yet. &lt;/p&gt;
    &lt;p&gt; Testing of the kernel has been done using the Linux Test Project (LTP), which is not all passing, yet, but "&lt;quote&gt;it's looking pretty reasonable&lt;/quote&gt;". On the user-space side, there is a "&lt;quote&gt;relatively simple&lt;/quote&gt;" purecap version; it does not yet have the GNU C library (glibc) but is using musl libc. His team is focused on the kernel, core libraries, and utilities, at this point, he said. &lt;/p&gt;
    &lt;p&gt; He went through a list of various kernel features, briefly reporting on their status; many things are working already, including networking, BPF, USB, and PCIe. There is a "&lt;quote&gt;rather dated X11 system working&lt;/quote&gt;". The team has also started some optimization work, especially with regard to copying memory to and from user space. In addition, the CHERI architecture allows doing 128-bit loads and stores, which can accelerate functions like memcpy(). &lt;/p&gt;
    &lt;p&gt;There is other development work going on as well, such as on the LLVM compiler for RISC-V CHERI and on QEMU for running and testing the system. The CHERI Alliance GitHub repository is where all of the work is being done.&lt;/p&gt;
    &lt;p&gt;The ABI being used is the Pure Capability user-space ABI (PCuABI) defined by the Morello project three years ago. It uses capabilities at the system-call level, which constrains what each side of the ABI can do. Copying to and from user-space memory is constrained by the bounds and permissions of the capabilities, while returned capabilities, such as from mmap(), restrict user space.&lt;/p&gt;
    &lt;p&gt;There are a number of challenges for purecap CHERI in the kernel, starting with the use of unsigned long for pointers. That type is used for pointers all over the kernel, but the CHERI compiler needs them to be a uintptr_t so that it can use capabilities instead. There are also alignment and size problems that come from the larger size of capabilities; structures in the kernel sometimes assume pointers have a specific size. The goal is to minimize the changes that need to be made and to make them with an eye on what can go upstream eventually.&lt;/p&gt;
    &lt;p&gt; The next piece that his team plans to look at is loading kernel modules into compartments. It is a tricky problem, since kernel modules "&lt;quote&gt;have to have quite a lot of access within the main kernel&lt;/quote&gt;" Another "&lt;quote&gt;big ticket item&lt;/quote&gt;" that needs to be tackled is support for BPF in user space. The BPF compiler has no conception of capabilities, which needs to be addressed; there is also the question of backward compatibility for existing BPF binaries. The work done in the CheriBSD project is useful as a reference, he said. &lt;/p&gt;
    &lt;p&gt; An area where CHERI could help is with Linux on MMU-less systems. Those systems lack the process isolation that is provided by the MMU, but CHERI can provide hardware-enforced isolation. An MMU also provides translation of addresses to and from virtual and physical, which is not something CHERI can do, but there is some interesting work in academia that might help. "&lt;quote&gt;CHERI is sort of refreshing some ideas and getting people to look back at these sorts of issues&lt;/quote&gt;", he said. &lt;/p&gt;
    &lt;p&gt;A related idea is to use CHERI for a single-address-space Linux targeting workloads with many processes sharing the same data. CHERI would be used for isolation, and the MMU for translation, but the shared data would be accessible without changing translation-lookaside buffers (TLBs), so it would reduce TLB thrashing.&lt;/p&gt;
    &lt;p&gt; Codasip has designed a CHERI CPU, the X730, "&lt;quote&gt;from the ground up&lt;/quote&gt;"; part of what the company does is to create configurable cores, where features like CHERI can be turned on or off when the CPU is built. That makes it easier to compare performance between the two; performance of CHERI CPUs is a question that the project frequently gets asked. The X730 only requires less than 5% more silicon area for CHERI, compared to the A730 non-CHERI version; it can run at the same maximum frequency for both types. The X730 adds 3.8% overhead for the CHERI instructions and overall has a less than a 5% performance overhead for CHERI code. The team is still working on optimizations and thinks it can reduce that overhead further. &lt;/p&gt;
    &lt;p&gt;He wrapped up by returning to the paper from 1966, whose authors stressed that "multiprogrammed computer systems" would need to evolve over time to meet changing requirements. That is what the CHERI project is trying to do, Shaw said, by evolving both hardware and software to try to improve the security of computer systems.&lt;/p&gt;
    &lt;head rend="h4"&gt;Q&amp;amp;A&lt;/head&gt;
    &lt;p&gt; The first question was in relation to DARPA, which regularly has initiatives toward memory safety; the most recent is the Translating all C to Rust (TRACTOR) program, which is looking to automate that transition. If it is successful, "&lt;quote&gt;what role do you see CHERI playing in an environment where a majority, even a vast majority, of all C code has been replaced with Rust?&lt;/quote&gt;" Shaw said that he wonders how successful TRACTOR will be, given that AI techniques may fall short of being able to reliably translate C for all of the different programs needed. Meanwhile, though, he does not see CHERI and Rust as being in conflict at all; the two can work together and it is something the project is putting effort into. "&lt;quote&gt;There will be a CHERI Rust compiler.&lt;/quote&gt;" &lt;/p&gt;
    &lt;p&gt; While memory safety is definitely important, the compartmentalization afforded by CHERI is more interesting to him. "&lt;quote&gt;Being able to get least privilege in software is a real big step forward, I think.&lt;/quote&gt;" None of the current languages attack that problem, he said, so it would take "&lt;quote&gt;a further evolution of language in order to support this whole concept nicely&lt;/quote&gt;". &lt;/p&gt;
    &lt;p&gt;Another attendee warned Shaw about what Arnd Bergmann said in a talk earlier in the week: the existence of MMU-less Linux is slated to end in 2028 or so. He suggested that Shaw talk to Bergmann about those plans. Shaw said there is a niche for MMU-less CPUs, especially for network gear, such as routers, that is driven by trying to keep the costs as low as possible; ideally, the manufacturers want Linux, but will presumably choose something else if they have to.&lt;/p&gt;
    &lt;p&gt;The attendee asked about the memory overhead for CHERI, which Shaw said he did not have any real numbers on, since the team has just started gathering that kind of information. The tags add some overhead, but that is typically less than 1% of the size of memory. Pointer-heavy workloads will obviously have a larger increase in memory than computation-oriented workloads, he said.&lt;/p&gt;
    &lt;p&gt;The compiler being used is LLVM, he said in response to another question; the work there is starting to go upstream and is the first of the CHERI Linux work to do so. The CHERI Linux project has to adapt its strategy for getting code upstream, depending on the target project; LLVM is a large project so the efforts so far have been to get the infrastructure needed for CHERI upstream. Some of that work will show up in LLVM 22, he thinks.&lt;/p&gt;
    &lt;p&gt;LSS EU organizer Elena Reshetova noted that she agreed that the compartmentalization aspects of CHERI were the more interesting and wondered what progress had been made on that. Shaw said that they are just getting started on compartmentalizing for Linux; the first steps will be for user-space libraries, which are already pretty well understood from the CheriBSD work. Kernel-module compartmentalization is the other thing being pursued, as he mentioned earlier.&lt;/p&gt;
    &lt;p&gt; He agreed with Reshetova that compartmentalizing the kernel would be "&lt;quote&gt;very challenging&lt;/quote&gt;". She followed up by asking if it even made sense to pursue for Linux; "&lt;quote&gt;given that it never has been considered in the design, this is a pretty fundamental change&lt;/quote&gt;". Shaw thought that it might be possible, at least based on what the hardware-assisted kernel compartments (HAKC) project has been doing. "&lt;quote&gt;We think it's at least to some extent achievable.&lt;/quote&gt;" &lt;/p&gt;
    &lt;p&gt; James Morris asked about the relationship between the Morello and CHERI Linux projects; "&lt;quote&gt;are you joining forces to do the upstreaming?&lt;/quote&gt;" Shaw said that "&lt;quote&gt;the CHERI community is pretty tight-knit&lt;/quote&gt;". His team works closely with teams for Morello, CHERIoT, and others, including lots of collaboration with Cambridge University people. The project mostly has participants in the US and UK, but that is changing and there is more commercial interest in the project everywhere, he said. &lt;/p&gt;
    &lt;p&gt;Another question was about how people could emulate CHERI hardware to try things out. Shaw said that there was currently a 6.10 kernel in the CHERI Alliance repository, but that the 6.16 kernel should be pushed there soon. It will come with all of the scripts needed for building everything with Yocto, including development tools, like the toolchain, SDK, QEMU for CHERI, and so on. That will be a good starting point for those wanting to check out CHERI Linux.&lt;/p&gt;
    &lt;p&gt;The slides and a YouTube video of the talk are available for interested readers.&lt;/p&gt;
    &lt;p&gt; [I would like to thank the Linux Foundation, LWN's travel sponsor, for supporting my trip to Amsterdam for Linux Security Summit Europe.]&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Index entries for this article&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Kernel&lt;/cell&gt;
        &lt;cell&gt;Capabilities&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Kernel&lt;/cell&gt;
        &lt;cell&gt;Security/Security technologies&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Security&lt;/cell&gt;
        &lt;cell&gt;Capabilities&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Security&lt;/cell&gt;
        &lt;cell&gt;Linux kernel&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Conference&lt;/cell&gt;
        &lt;cell&gt;Linux Security Summit Europe/2025&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt; Posted Sep 24, 2025 22:32 UTC (Wed) by notriddle (subscriber, #130608) [Link] (1 responses) Rust treats speculative execution as completely out of scope. That, as far as I'm concerned, is its biggest weakness and the main reason you still need hardware isolation. A quick Google drops me onto at least one paper &amp;lt;https://www.cl.cam.ac.uk/research/security/ctsrd/pdfs/202...&amp;gt; that claims to address speculative execution in CHERI, but I don't know if that's been incorporated into real cores, if it's long obsoleted by more recent innovation, or if I'm completely barking up the wrong tree. Are CHERI capabilities able to provide SPECTRE-resistant isolation between mutually distrustful privilege domains within a single address space? Posted Sep 24, 2025 23:02 UTC (Wed) by wahern (subscriber, #37304) [Link] Intrinsically, AFAIU, no. But hardware CHERI support, by requiring both bounds and (to varying extents) provenance information to accompany addresses, potentially makes it easier and more natural to avoid side-channels. And maybe more importantly, CHERI provides an opportunity to nail down ISA guarantees before widespread deployment. See Safe Speculation for CHERI, https://www.cl.cam.ac.uk/research/security/ctsrd/pdfs/202... Posted Sep 24, 2025 22:49 UTC (Wed) by wahern (subscriber, #37304) [Link] (6 responses) CHERI is great for spatial safety, but the cost of avoiding indirection means temporal safety requires more work. Perhaps the next evolution will be exploring how linear or affine typing in application languages such as Rust could be leveraged to minimize the sweeping work, e.g. by automatically clearing capabilities as they're copied through the application from malloc through free. Or evolving allocation APIs and page table permission schemes so memory that doesn't need to store a capability/pointer can be skipped from sweeping entirely. [1] https://www.cl.cam.ac.uk/research/security/ctsrd/pdfs/202... Posted Sep 26, 2025 0:29 UTC (Fri) by cpatulea (subscriber, #87498) [Link] (1 responses) Any chance you might have a deeper reference for this? Posted Sep 26, 2025 12:24 UTC (Fri) by wahern (subscriber, #37304) [Link] Also worthwhile to read the core papers on CHERI, especially papers about and subsequent to the ARM Morello implementation. Once you understand the basic architecture, in particular the hidden 129th bit that tags a word (i.e. C pointer) in memory as a valid capability and which is copied along with the visible 128-bit value (e.g. in `char *b = *a;`), it's easy to see understand the problem space regarding revocation. Most of the early work in CHERI was finding and verifying the minimum software and hardware requirements for guaranteed spatial safety that was also maximally performant in hardware and practical to incorporate into existing platforms (language standards, ABIs, kernels, etc). Temporal safety, especially performant revocation, didn't receive as much attention until later, after the shape of capability pointers (i.e. 129-bit compressed pointers) had already largely been settled. But it's still an active area of research and may yet result in some design changes or at least suggest additional hardware facilities for future implementations. Posted Sep 27, 2025 23:15 UTC (Sat) by NYKevin (subscriber, #129325) [Link] 1. Every "regular" capability is really a double indirection (a pointer-to-a-pointer) in disguise. I will use the term "outer pointer" to refer to the first layer of indirection (exposed to user code) and "inner pointer" to refer to the second layer (the pointee of the outer pointer). I know that double indirection is significantly more expensive than single indirection... but sweeping address space not only seems like it should be similarly expensive, it gets slower the more memory we allocate (whereas double indirection is a fixed cost per dereference). How much memory do you have to allocate before you hit the break-even point? The other obvious question is how much of this you can hardware-accelerate, and to what extent. Posted Oct 2, 2025 13:03 UTC (Thu) by Vorpal (guest, #136011) [Link] (2 responses) Oof, that seems like a complete deal breaker to me. My main interests are in low latency hard realtime code, and that would completely kill any RT guarantees. I don't see it scaling well to large workloads either. Imagine a database server with hundreds of GB of memory mapped into the process, no way that you want to sweep through all the pointers in that either. And even if you do it in the background concurrently, you will eat a lot of memory bandwidth, and you risk falling behind. Which means we are left with a small niche: small systems with no RT guarantees. &amp;gt; during the pendency of a concurrent background sweep, a CoW-like scheme temporarily traps all reads to sweep specific pages on demand, permitting forward progress before the concurrent sweep completes. Isn't there a race condition in that: if you copy the capability around you may be able to copy it from a yet-to-be-swept page to an already swept page while the sweep is somewhere in between those pages? Or maybe I'm misunderstanding you. Posted Oct 2, 2025 17:19 UTC (Thu) by Wol (subscriber, #4433) [Link] (1 responses) Then you're using the wrong database server :-) Cheers, Posted Oct 2, 2025 17:25 UTC (Thu) by jake (editor, #205) [Link] Please do not continue down this path, Wol. You have been asked before. Your favorite hobby horse is off-topic on this article (and many, many others). thanks, jake Posted Sep 25, 2025 6:30 UTC (Thu) by chmaynard (subscriber, #125652) [Link] From the Amazon.com summary: "The book describes early descriptor architectures and explains the Burroughs B5000, Rice University Computer, and Basic Language Machine. The text also focuses on early capability architectures. Dennis and Van Horn's Supervisor; CAL-TSS System; MIT PDP-1 Timesharing System; and Chicago Magic Number Machine are discussed. The book then describes Plessey System 250, Cambridge CAP Computer, and Hydra System. The selection also discusses STAROS System and IBM System/38 ... The book highlights Intel iAPX 432, and then considers segment and objects, program execution, storage resources, and abstraction support." Posted Sep 25, 2025 12:34 UTC (Thu) by kevinlyles (subscriber, #77866) [Link] &lt;head&gt;Spectre mitigation overhead&lt;/head&gt;&lt;head&gt;Spectre mitigation overhead&lt;/head&gt;&lt;head&gt;Capability Revocation and Indirection&lt;/head&gt;&lt;head&gt;Capability Revocation and Indirection&lt;/head&gt;&lt;head&gt;Capability Revocation and Indirection&lt;/head&gt;&lt;head&gt;Capability Revocation and Indirection&lt;/head&gt;&lt;lb/&gt; 2. When an allocation is created, we create an inner pointer for it. When an allocation is deallocated, we mark its inner pointer as invalid.&lt;lb/&gt; 3. Inner pointers live in a special region of address space. When it fills up with dead pointers, you unmap the whole region, and map a fresh one somewhere else. The region is not allowed to contain any object other than an inner pointer (no "real" allocations).&lt;lb/&gt; 4. A region that has ever been mapped for inner pointers during the lifetime of a process can never again be remapped to contain inner pointers (but it can be remapped for any other purpose, so this is not a pervasive restriction and should not break anything else). malloc or its equivalent would be responsible for the necessary bookkeeping, which might involve mapping regions at some fixed or regular pattern of offsets to reduce the amount of data that you need to track.&lt;lb/&gt; 5. When an outer pointer is dereferenced by user code, you first check the validity of the outer pointer, then check that it points to a region currently mapped for inner pointers, and finally check the validity of the inner pointer.&lt;lb/&gt; 6. In principle, you could run out of address space doing this, but that ought to take a rather long time if we're using 64-bit addresses. If we really insist on reusing inner pointer regions, one option could be to give each mapping and each outer pointer a generation number, but CHERI pointers are already wider than standard pointers, and I'm not sure this is worth it. Besides, then you're just running out of generation numbers instead.&lt;head&gt;Capability Revocation and Indirection&lt;/head&gt;&lt;head&gt;Capability Revocation and Indirection&lt;/head&gt;&lt;lb/&gt; Wol&lt;head&gt;Capability Revocation and Indirection&lt;/head&gt;&lt;head&gt;Capability-Based Computer Systems&lt;/head&gt;&lt;head&gt;Fantastic title!&lt;/head&gt;&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45487629</guid><pubDate>Mon, 06 Oct 2025 04:25:31 +0000</pubDate></item><item><title>Structured Procrastination</title><link>https://structuredprocrastination.com</link><description>&lt;doc fingerprint="161270546c3194f9"&gt;
  &lt;main&gt;
    &lt;p&gt;Author practices jumping rope with seaweed while work awaits.&lt;/p&gt;
    &lt;p&gt;``. . . anyone can do any amount of work, provided it isn't the work he is supposed to be doing at that moment." -- Robert Benchley, in Chips off the Old Benchley, 1949&lt;/p&gt;
    &lt;p&gt;I have been intending to write this essay for months. Why am I finally doing it? Because I finally found some uncommitted time? Wrong. I have papers to grade, textbook orders to fill out, an NSF proposal to referee, dissertation drafts to read. I am working on this essay as a way of not doing all of those things. This is the essence of what I call structured procrastination, an amazing strategy I have discovered that converts procrastinators into effective human beings, respected and admired for all that they can accomplish and the good use they make of time. All procrastinators put off things they have to do. Structured procrastination is the art of making this bad trait work for you. The key idea is that procrastinating does not mean doing absolutely nothing. Procrastinators seldom do absolutely nothing; they do marginally useful things, like gardening or sharpening pencils or making a diagram of how they will reorganize their files when they get around to it. Why does the procrastinator do these things? Because they are a way of not doing something more important. If all the procrastinator had left to do was to sharpen some pencils, no force on earth could get him do it. However, the procrastinator can be motivated to do difficult, timely and important tasks, as long as these tasks are a way of not doing something more important.&lt;/p&gt;
    &lt;p&gt;Structured procrastination means shaping the structure of the tasks one has to do in a way that exploits this fact. The list of tasks one has in mind will be ordered by importance. Tasks that seem most urgent and important are on top. But there are also worthwhile tasks to perform lower down on the list. Doing these tasks becomes a way of not doing the things higher up on the list. With this sort of appropriate task structure, the procrastinator becomes a useful citizen. Indeed, the procrastinator can even acquire, as I have, a reputation for getting a lot done.&lt;/p&gt;
    &lt;p&gt;The most perfect situation for structured procrastination that I ever had was when my wife and I served as Resident Fellows in Soto House, a Stanford dormitory. In the evening, faced with papers to grade, lectures to prepare, committee work to be done, I would leave our cottage next to the dorm and go over to the lounge and play ping-pong with the residents, or talk over things with them in their rooms, or just sit there and read the paper. I got a reputation for being a terrific Resident Fellow, and one of the rare profs on campus who spent time with undergraduates and got to know them. What a set up: play ping pong as a way of not doing more important things, and get a reputation as Mr. Chips.&lt;/p&gt;
    &lt;p&gt;Procrastinators often follow exactly the wrong tack. They try to minimize their commitments, assuming that if they have only a few things to do, they will quit procrastinating and get them done. But this goes contrary to the basic nature of the procrastinator and destroys his most important source of motivation. The few tasks on his list will be by definition the most important, and the only way to avoid doing them will be to do nothing. This is a way to become a couch potato, not an effective human being.&lt;/p&gt;
    &lt;p&gt;At this point you may be asking, "How about the important tasks at the top of the list, that one never does?" Admittedly, there is a potential problem here.&lt;/p&gt;
    &lt;p&gt;The trick is to pick the right sorts of projects for the top of the list. The ideal sorts of things have two characteristics, First, they seem to have clear deadlines (but really don't). Second, they seem awfully important (but really aren't). Luckily, life abounds with such tasks. In universities the vast majority of tasks fall into this category, and I'm sure the same is true for most other large institutions. Take for example the item right at the top of my list right now. This is finishing an essay for a volume in the philosophy of language. It was supposed to be done eleven months ago. I have accomplished an enormous number of important things as a way of not working on it. A couple of months ago, bothered by guilt, I wrote a letter to the editor saying how sorry I was to be so late and expressing my good intentions to get to work. Writing the letter was, of course, a way of not working on the article. It turned out that I really wasn't much further behind schedule than anyone else. And how important is this article anyway? Not so important that at some point something that seems more important won't come along. Then I'll get to work on it.&lt;/p&gt;
    &lt;p&gt;Another example is book order forms. I write this in June. In October, I will teach a class on Epistemology. The book order forms are already overdue at the book store. It is easy to take this as an important task with a pressing deadline (for you non-procrastinators, I will observe that deadlines really start to press a week or two after they pass.) I get almost daily reminders from the department secretary, students sometimes ask me what we will be reading, and the unfilled order form sits right in the middle of my desk, right under the wrapping from the sandwich I ate last Wednesday. This task is near the top of my list; it bothers me, and motivates me to do other useful but superficially less important things. But in fact, the book store is plenty busy with forms already filed by non-procrastinators. I can get mine in mid-Summer and things will be fine. I just need to order popular well-known books from efficient publishers. I will accept some other, apparently more important, task sometime between now and, say, August 1st. Then my psyche will feel comfortable about filling out the order forms as a way of not doing this new task.&lt;/p&gt;
    &lt;p&gt;The observant reader may feel at this point that structured procrastination requires a certain amount of self-deception, since one is in effect constantly perpetrating a pyramid scheme on oneself. Exactly. One needs to be able to recognize and commit oneself to tasks with inflated importance and unreal deadlines, while making oneself feel that they are important and urgent. This is not a problem, because virtually all procrastinators have excellent self-deceptive skills also. And what could be more noble than using one character flaw to offset the bad effects of another?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45488261</guid><pubDate>Mon, 06 Oct 2025 06:35:36 +0000</pubDate></item><item><title>Flightcontrol: AWS PaaS</title><link>https://www.flightcontrol.dev/</link><description>&lt;doc fingerprint="bd1863730f143a8e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Build your dreams&lt;lb/&gt;on AWS, effortlessly&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Flightcontrol is a PaaS that deploys to your AWS account&lt;/item&gt;
      &lt;item&gt;Servers, Lambdas, workers, crons, static sites, databases &amp;amp; Redis&lt;/item&gt;
      &lt;item&gt;We are your devops team with 24/7 emergency support&lt;/item&gt;
      &lt;item&gt;Companies outgrowing other PaaS or homegrown AWS switch to Flightcontrol to regain reliability, security, and scalability at a reasonable cost&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Over $1 million of AWS resources under management&lt;/head&gt;
    &lt;head rend="h2"&gt;The old way&lt;/head&gt;
    &lt;p&gt;"Our AWS setup is consuming too much time &amp;amp; attention"&lt;/p&gt;
    &lt;p&gt;Your team gets bogged down with complex Terraform scripts, manual configuration, and endless CI/CD pipelines. You could hire DevOps engineers, but they are expensive and it's hard to find really good ones. It will do the job, but now your developer productivity suffers as they are dependent on the infra team to make changes or spin up new services.&lt;/p&gt;
    &lt;head rend="h2"&gt;The new way&lt;/head&gt;
    &lt;p&gt;"Flightcontrol gives our team the power to manage bare metal AWS without needing to hire specific talent"&lt;/p&gt;
    &lt;p&gt;Save thousands of dollars and months of time because Flightcontrol significantly reduces DevOps overhead. It empowers your developers ship like crazy without needing AWS or infrastructure expertise. Your developers gain full autonomy while benefiting from AWS's unmatched scalability, reliability, and flexibility.&lt;/p&gt;
    &lt;head rend="h2"&gt;Simple, powerful deployments without worrying about low level AWS config&lt;/head&gt;
    &lt;p&gt;We take the best AWS services, put together a best-in-class setup, and make them super easy to use.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Connect your AWS account to Flightcontrol&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Connect your git repository to Flightcontrol&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Define your services (servers, APIs, databases, etc)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Flightcontrol fully automates infrastructure provisioning, CI/CD, and deployments. All within your own AWS account where you retain full visibility and control&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Flightcontrol simplifies your deployments by providing a user-friendly dashboard designed specifically for developers, not DevOps engineers. Forget the frustration of navigating AWS’s overwhelming and fragmented console. With Flightcontrol, you see your entire infrastructure clearly in one intuitive interface, allowing you to manage deployments, services, and scaling with confidence.&lt;/p&gt;
    &lt;p&gt;Deployments become as easy as a simple git push or webhook integration. Flightcontrol handles your CI/CD automation entirely, enabling your team to deploy confidently and quickly without maintaining complex Terraform or CDK scripts. You get the simplicity of platforms like Vercel or Heroku, paired with the raw power, near perfect reliability, and immense flexibility of AWS. Your developers can ship faster and stay focused on building great products.&lt;/p&gt;
    &lt;head rend="h2"&gt;Serve all your use-cases from a single platform&lt;/head&gt;
    &lt;p&gt;Static Sites&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CloudFront CDN&lt;/item&gt;
      &lt;item&gt;S3&lt;/item&gt;
      &lt;item&gt;Lambda@Edget&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Web &amp;amp; GPU Servers&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CloudFront CDN&lt;/item&gt;
      &lt;item&gt;ECS&lt;/item&gt;
      &lt;item&gt;Fargate or EC2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Network Servers&lt;/p&gt;
    &lt;p&gt;UDP &amp;amp; TCP with multiple ports&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ECS&lt;/item&gt;
      &lt;item&gt;Fargate or EC2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Private Servers&lt;/p&gt;
    &lt;p&gt;HTTP, HTTPS, TCP, UDP&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ECS&lt;/item&gt;
      &lt;item&gt;Fargate or EC2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Background Workers&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ECS&lt;/item&gt;
      &lt;item&gt;Fargate or EC2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Job Runner&lt;/p&gt;
    &lt;p&gt;Cron &amp;amp; API triggered jobs&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ECS&lt;/item&gt;
      &lt;item&gt;Fargate or EC2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Lambda&lt;/p&gt;
    &lt;p&gt;With function url support&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Lambda&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Databases&lt;/p&gt;
    &lt;p&gt;Postgres, MySQL, MariaDB&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;RDS&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Redis&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ElastiCache&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;S3 Bucket&lt;/p&gt;
    &lt;p&gt;File &amp;amp; object storage&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;S3&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Significantly reduce your DevOps overhead&lt;/head&gt;
    &lt;p&gt;Flightcontrol becomes your devops team. We guarantee support for everything managed through Flightcontrol. You don't have to worry about anything that's amiss in AWS — let us know and we'll fix it ASAP (but rest assured, this almost never happens!).&lt;/p&gt;
    &lt;p&gt;Get 24/7 emergency support on our Business plan for ultimate peace of mind.&lt;/p&gt;
    &lt;p&gt;Need some extra devops support beyond the Flightcontrol platform? We offer DevOps Support Add-ons to supplement your team. This is ideal for teams that need extra infrastructure help but don't need a full time devops engineer.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ephemeral preview environments&lt;/head&gt;
    &lt;p&gt;The fastest moving engineering teams use preview environments to view changes before committing them.&lt;/p&gt;
    &lt;p&gt;Flightcontrol can automatically spin up temporary infrastructure for each pull request and then clean it up when the pull request is merged.&lt;/p&gt;
    &lt;p&gt;Preview environments mean no more conflicts on staging, no more delays, and significantly fewer bugs in production. Enable all stakeholders to see and test changes before merging code.&lt;/p&gt;
    &lt;p&gt;Each preview environment is cost-optimized, intelligently sharing resources such as load balancers and RDS instances, ensuring you maintain control over spending. Database seeding per environment means realistic testing scenarios, catching issues before they go live. Your team will experience faster releases, fewer bugs, and smoother collaboration.&lt;/p&gt;
    &lt;head rend="h2"&gt;World class support with 6 minute median response time&lt;/head&gt;
    &lt;p&gt;Imagine never worrying about infrastructure issues again. Flightcontrol becomes your DevOps team, providing exceptional, responsive support. With guaranteed smooth operations for everything managed by Flightcontrol, you can rest easy knowing your infrastructure is covered by experts around the clock.&lt;/p&gt;
    &lt;p&gt;With a median first response time of 6 minutes, our dedicated support team is accessible via email and Slack, ensuring rapid resolution whenever you need it. Need some extra DevOps help? Don’t hire full time! Our DevOps support add-on gives you expert guidance tailored specifically to your unique requirements, removing the need to hire a full-time DevOps engineer.&lt;/p&gt;
    &lt;p&gt;Visual Config? Code config? Both!&lt;/p&gt;
    &lt;p&gt;Infrastructure-as-code designed for moving fast&lt;/p&gt;
    &lt;p&gt;Deploy close to your users&lt;/p&gt;
    &lt;p&gt;Choose today from 28 AWS regions. Multi-region deploys in early access.&lt;/p&gt;
    &lt;p&gt;Observability&lt;/p&gt;
    &lt;p&gt;Stay on top of things with our metrics and alerts, or add sidecars like Datadog.&lt;/p&gt;
    &lt;p&gt;Nixpacks&lt;/p&gt;
    &lt;p&gt;Build any language or framework without writing a Dockerfile. The modern successor to Heroku buildpacks.&lt;/p&gt;
    &lt;p&gt;Stale while revalidate + Next.js &amp;amp; Svelte ISR&lt;/p&gt;
    &lt;p&gt;Blazing fast speed with CloudFront's stale-while-revalidate support&lt;/p&gt;
    &lt;p&gt;AWS cost transparency&lt;/p&gt;
    &lt;p&gt;Understand exactly where the dollars are going by project, environment, and service.&lt;/p&gt;
    &lt;p&gt;Preview environments, fullstack&lt;/p&gt;
    &lt;p&gt;Deploy your all your services for every pull request to a cost optimized environment.&lt;/p&gt;
    &lt;p&gt;Bring your monoliths and your microservices&lt;/p&gt;
    &lt;p&gt;Your architecture will work with us, no matter how big or small.&lt;/p&gt;
    &lt;p&gt;Your domain, with https&lt;/p&gt;
    &lt;p&gt;Connect your domain with a couple DNS records. No messing with SSL certificates.&lt;/p&gt;
    &lt;p&gt;Peak edge performance&lt;/p&gt;
    &lt;p&gt;World-class performance with CloudFront, Stale-While-Revalidate, and edge-based Next.js ISR. Even multi-region.&lt;/p&gt;
    &lt;p&gt;Monorepos, with watch paths&lt;/p&gt;
    &lt;p&gt;Put all your stuff in one place, that's fine with us. And only deploy changed files with watch paths.&lt;/p&gt;
    &lt;p&gt;Maintenance mode&lt;/p&gt;
    &lt;p&gt;Block traffic to your app while you're doing something important (we assume).&lt;/p&gt;
    &lt;p&gt;API &amp;amp; deploy hooks&lt;/p&gt;
    &lt;p&gt;Trigger deploys from CI. More thorough API is coming, we promise.&lt;/p&gt;
    &lt;p&gt;Notifications&lt;/p&gt;
    &lt;p&gt;Get alerted in Slack or email when things go south. Or when they go north.&lt;/p&gt;
    &lt;p&gt;Rollback&lt;/p&gt;
    &lt;p&gt;It happens to the best of us, so we've got your back when the inevitable happens.&lt;/p&gt;
    &lt;p&gt;Private VPC networking&lt;/p&gt;
    &lt;p&gt;Each environment is deployed to a new or existing VPC. Get private services and private databases.&lt;/p&gt;
    &lt;head rend="h2"&gt;Deploy every language globally&lt;/head&gt;
    &lt;p&gt;Every language and framework works beautifully in the Flightcontrol universe. Welcome home.&lt;/p&gt;
    &lt;head rend="h2"&gt;1. Connect your AWS and Git Repo with 1-click&lt;/head&gt;
    &lt;p&gt;Everything is deployed to your AWS account where you have full ownership and control. Without the frustrating limitations of black box PaaS.&lt;/p&gt;
    &lt;head rend="h2"&gt;2. Zero-config or customize to your heart's content&lt;/head&gt;
    &lt;p&gt;It will often "just work", but we also support many customizations like pulling from image registries or fine-tuning autoscaling.&lt;/p&gt;
    &lt;head rend="h2"&gt;3. Automatic deploys with git push or webhook&lt;/head&gt;
    &lt;p&gt;Fully automated infra provisioning, builds and deploys. All without having to use the AWS console.&lt;/p&gt;
    &lt;head rend="h3"&gt;Trusted by thousands of developers&lt;/head&gt;
    &lt;p&gt;We've got your back with the most helpful, responsive support in the industry&lt;/p&gt;
    &lt;head rend="h3"&gt;Enterprise grade no matter your size&lt;/head&gt;
    &lt;p&gt;Customers of all sizes rely on us for production, from startups to large enterprises&lt;/p&gt;
    &lt;head rend="h3"&gt;Save a fortune on devops costs&lt;/head&gt;
    &lt;p&gt;We delay the need for infra engineers by a few years. And then we enable them to focus on more meaningful work&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45488441</guid><pubDate>Mon, 06 Oct 2025 07:07:11 +0000</pubDate></item></channel></rss>