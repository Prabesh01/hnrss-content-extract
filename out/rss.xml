<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 06 Sep 2025 15:07:47 +0000</lastBuildDate><item><title>I ditched Docker for Podman</title><link>https://codesmash.dev/why-i-ditched-docker-for-podman-and-you-should-too</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45137525</guid></item><item><title>Purposeful animations</title><link>https://emilkowal.ski/ui/you-dont-need-animations</link><description>&lt;doc fingerprint="f7eb51a5ad29df05"&gt;
  &lt;main&gt;&lt;p&gt;When done right, animations make an interface feel predictable, faster, and more enjoyable to use. They help you and your product stand out.&lt;/p&gt;&lt;p&gt;But they can also do the opposite. They can make an interface feel unpredictable, slow, and annoying. They can even make your users lose trust in your product.&lt;/p&gt;&lt;p&gt;So how do you know when and how to animate to improve the experience?&lt;/p&gt;&lt;p&gt;Step one is making sure your animations have a purpose.&lt;/p&gt;&lt;head rend="h2"&gt;Purposeful animations&lt;/head&gt;&lt;p&gt;Before you start animating, ask yourself: what’s the purpose of this animation? &lt;lb/&gt;As an example, what’s the purpose of this marketing animation we built at Linear?&lt;/p&gt;&lt;p&gt;You can view the full animation on linear.app/ai.&lt;/p&gt;&lt;p&gt;This animation explains how Product Intelligence (Linear’s feature) works. We could have used a static asset, but the animated version helps the user understand what this feature does, straight in the initial viewport of the page.&lt;/p&gt;&lt;p&gt;Another purposeful animation is this subtle scale down effect when pressing a button. It’s a small thing, but it helps the interface feel more alive and responsive.&lt;/p&gt;&lt;p&gt;Sonner’s enter animation, on the other hand, has two purposes:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;- Having a toast suddenly appear would feel off, so we animate it in.&lt;/item&gt;&lt;item&gt;- Because it comes from and leaves in the same direction, it creates spatial consistency, making the swipe-down-to-dismiss gesture feel more intuitive.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;But sometimes the purpose of an animation might just be to bring delight.&lt;/p&gt;&lt;p&gt;Morphing of the feedback component below helps make the experience more unique and memorable. This works as long as the user will rarely interact with it. It’ll then become a pleasant surprise, rather than a daily annoyance.&lt;/p&gt;&lt;p&gt;Press on the button to see it morph.&lt;/p&gt;&lt;p&gt;Used multiple times a day, this component would quickly become irritating. The initial delight would fade and the animation would slow users down.&lt;/p&gt;&lt;p&gt;How often users will see an animation is a key factor in deciding whether to animate or not. Let’s dive deeper into it next.&lt;/p&gt;&lt;head rend="h2"&gt;Frequency of use&lt;/head&gt;&lt;p&gt;I use Raycast hundreds of times a day. If it animated every time I opened it, it would be very annoying. But there’s no animation at all. That’s the optimal experience.&lt;/p&gt;&lt;p&gt;To see it for yourself, try to toggle the open state of the menu below by using the buttons belowpressing &lt;code&gt;J&lt;/code&gt; and then &lt;code&gt;K&lt;/code&gt;. Which one feels better if used hundreds of times a day?&lt;/p&gt;&lt;p&gt;When I open Raycast, I have a clear goal in mind. I don’t expect to be “delighted”, I don’t need to be. I just want to do my work with no unnecessary friction.&lt;/p&gt;&lt;p&gt;Think about what the user wants to achieve and how often they will see an animation. A hover effect is nice, but if used multiple times a day, it would likely benefit the most from having no animation at all.&lt;/p&gt;&lt;p&gt;Imagine you interact with this list often during the day.&lt;/p&gt;&lt;p&gt;Imagine you interact with this list often during the day.&lt;/p&gt;&lt;p&gt;The same goes for keyboard-initiated actions. These actions may be repeated hundreds of times a day, an animation would make them feel slow, delayed, and disconnected from the user’s actions. You should never animate them.&lt;/p&gt;&lt;p&gt;Since we can’t really use a keyboard on touch devices, you can press the buttons below to see how it feels with and without animation.&lt;/p&gt;&lt;p&gt;To see it for yourself, focus on the input below and use arrow keys to navigate through the list. Notice how the highlight feels delayed compared to the keys you press. Now press (shift) and see how this interaction feels without animation.&lt;/p&gt;&lt;p&gt;But even if your animation won’t be used too often and it fulfills a clear purpose, you still have to think about its speed…&lt;/p&gt;&lt;head rend="h2"&gt;Perception of speed&lt;/head&gt;&lt;p&gt;Unless you are working on marketing sites, your animations have to be fast. They improve the perceived performance of your app, stay connected to user’s actions, and make the interface feel as if it’s truly listening to the user.&lt;/p&gt;&lt;p&gt;To give you an example, a faster-spinning spinner makes the app seem to load faster, even though the load time is the same. This improves perceived performance.&lt;/p&gt;&lt;p&gt;Which one works harder to load the data?&lt;/p&gt;&lt;p&gt;A &lt;code&gt;180ms&lt;/code&gt; dropdown animation feels more responsive than a &lt;code&gt;400ms&lt;/code&gt; one:&lt;/p&gt;&lt;p&gt;Click on the buttons to compare the speed.&lt;/p&gt;&lt;p&gt;As a rule of thumb, UI animations should generally stay under &lt;code&gt;300ms&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Another example of the importance of speed: tooltips should have a slight delay before appearing to prevent accidental activation. Once a tooltip is open however, hovering over other tooltips should open them with no delay and no animation.&lt;/p&gt;&lt;p&gt;This feels faster without defeating the purpose of the initial delay.&lt;/p&gt;&lt;p&gt;Radix UI and Base UI skip the delay once a tooltip is shown.&lt;/p&gt;&lt;p&gt;Radix UI and Base UI skip the delay once a tooltip is shown.&lt;/p&gt;&lt;head rend="h2"&gt;Building great interfaces&lt;/head&gt;&lt;p&gt;The goal is not to animate for animation’s sake, it’s to build great user interfaces. The ones that users will happily use, even on a daily basis. Sometimes this requires animations, but sometimes the best animation is no animation.&lt;/p&gt;&lt;p&gt;Knowing when to animate is just one of many things you need to know in order to craft great animations. If you’d like to dive deeper into the theory and practice of it, I’ve created a course that covers everything you need to know:&lt;/p&gt;Check out "Animations on the Web"&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45139088</guid></item><item><title>Protobuffers Are Wrong (2018)</title><link>https://reasonablypolymorphic.com/blog/protos-are-wrong/</link><description>&lt;doc fingerprint="1c20d80c0e053ed4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Protobuffers Are Wrong&lt;/head&gt;
    &lt;p&gt;I’ve spent a good deal of my professional life arguing against using protobuffers. They’re clearly written by amateurs, unbelievably ad-hoc, mired in gotchas, tricky to compile, and solve a problem that nobody but Google really has. If these problems of protobuffers remained quarantined in serialization abstractions, my complaints would end there. But unfortunately, the bad design of protobuffers is so persuasive that these problems manage to leak their way into your code as well.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ad-Hoc and Built By Amateurs&lt;/head&gt;
    &lt;p&gt;Stop. Put away your email client that is half-way through writing me about how “Google is filled with the world’s best engineers,” and that “anything they build is, by definition, not built by amateurs.” I don’t want to hear it.&lt;/p&gt;
    &lt;p&gt;Let’s just get this out of the way. Full disclosure: I used to work at Google. It was the first (but unfortunately, not the last) place I ever used protobuffers. All of the problems I want to talk about today exist inside of Google’s codebase; it’s not just a matter of “using protobuffers wrong” or some such nonsense like that.&lt;/p&gt;
    &lt;p&gt;By far, the biggest problem with protobuffers is their terrible type-system. Fans of Java should feel right at home with protobuffers, but unfortunately, literally nobody considers Java to have a well-designed type-system. The dynamic typing guys complain about it being too stifling, while the static typing guys like me complain about it being too stifling without giving you any of the things you actually want in a type-system. Lose lose.&lt;/p&gt;
    &lt;p&gt;The ad-hoc-ness and the built-by-amateurs-itude go hand-in-hand. So much of the protobuffer spec feels bolted on as an afterthought that it clearly was bolted on as an afterthought. Many of its restrictions will make you stop, scratch your head and ask “wat?” But these are just symptoms of the deeper answer, which is this:&lt;/p&gt;
    &lt;p&gt;Protobuffers were obviously built by amateurs because they offer bad solutions to widely-known and already-solved problems.&lt;/p&gt;
    &lt;head rend="h3"&gt;No Compositionality&lt;/head&gt;
    &lt;p&gt;Protobuffers offer several “features”, but none of them see to work with one another. For example, look at the list of orthogonal-yet-constrained typing features that I found by skimming the documentation.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;oneof&lt;/code&gt;fields can’t be&lt;code&gt;repeated&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;map&amp;lt;k,v&amp;gt;&lt;/code&gt;fields have dedicated syntax for their keys and values, but this isn’t used for any other types.&lt;/item&gt;
      &lt;item&gt;Despite &lt;code&gt;map&lt;/code&gt;fields being able to be parameterized, no user-defined types can be. This means you’ll be stuck hand-rolling your own specializations of common data structures.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;map&lt;/code&gt;fields cannot be&lt;code&gt;repeated&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;map&lt;/code&gt;keys can be&lt;code&gt;string&lt;/code&gt;s, but can not be&lt;code&gt;bytes&lt;/code&gt;. They also can’t be&lt;code&gt;enum&lt;/code&gt;s, even though&lt;code&gt;enum&lt;/code&gt;s are considered to be equivalent to integers everywhere else in the protobuffer spec.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;map&lt;/code&gt;values cannot be other&lt;code&gt;map&lt;/code&gt;s.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This insane list of restrictions is the result of unprincipled design choices and bolting on features after the fact. For example, &lt;code&gt;oneof&lt;/code&gt; fields can’t be &lt;code&gt;repeated&lt;/code&gt; because rather than resulting in a coproduct type, instead the code generator will give you a product of mutually-exclusive optional fields. Such a transformation is only valid for a singular field (and, as we’ll see later, not even then.)&lt;/p&gt;
    &lt;p&gt;The restriction behind &lt;code&gt;map&lt;/code&gt; fields being unable to be &lt;code&gt;repeated&lt;/code&gt; is related, but shows off a different limitation of the type-system. Behind the scenes, a &lt;code&gt;map&amp;lt;k,v&amp;gt;&lt;/code&gt; is desugared into something spiritually similar to &lt;code&gt;repeated Pair&amp;lt;k,v&amp;gt;&lt;/code&gt;. And because &lt;code&gt;repeated&lt;/code&gt; is a magical language keyword rather than a type in its own right, it doesn’t compose with itself.&lt;/p&gt;
    &lt;p&gt;Your guess is as good as mine for why an &lt;code&gt;enum&lt;/code&gt; can’t be used as a &lt;code&gt;map&lt;/code&gt; key.&lt;/p&gt;
    &lt;p&gt;What’s so frustrating about all of this is a little understanding of how modern type-systems work would be enough to drastically simplify the protobuffer spec and simultaneously remove all of the arbitrary restrictions.&lt;/p&gt;
    &lt;p&gt;The solution is as follows:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Make all fields in a message &lt;code&gt;required&lt;/code&gt;. This makes messages product types.&lt;/item&gt;
      &lt;item&gt;Promote &lt;code&gt;oneof&lt;/code&gt;fields to instead be standalone data types. These are coproduct types.&lt;/item&gt;
      &lt;item&gt;Give the ability to parameterize product and coproduct types by other types.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;That’s it! These three features are all you need in order to define any possible piece of data. With these simpler pieces, we can re-implement the rest of the protobuffer spec in terms of them.&lt;/p&gt;
    &lt;p&gt;For example, we can rebuild &lt;code&gt;optional&lt;/code&gt; fields:&lt;/p&gt;
    &lt;code&gt;{
 product Unit // no fields
   }

&amp;lt;t&amp;gt; {
 coproduct Optional= 0;
   t    value = 1;
   Unit unset }&lt;/code&gt;
    &lt;p&gt;Building &lt;code&gt;repeated&lt;/code&gt; fields is simple too:&lt;/p&gt;
    &lt;code&gt;&amp;lt;t&amp;gt; {
 coproduct List= 0;
   Unit empty &amp;lt;t, List&amp;lt;t&amp;gt;&amp;gt; cons = 1;
   Pair}&lt;/code&gt;
    &lt;p&gt;Of course, the actual serialization logic is allowed to do something smarter than pushing linked-lists across the network—after all, implementations and semantics don’t need to align one-to-one.&lt;/p&gt;
    &lt;head rend="h3"&gt;Questionable Choices&lt;/head&gt;
    &lt;p&gt;In the vein of Java, protobuffers make the distinction between scalar types and message types. Scalars correspond more-or-less to machine primitives—things like &lt;code&gt;int32&lt;/code&gt;, &lt;code&gt;bool&lt;/code&gt; and &lt;code&gt;string&lt;/code&gt;. Messages, on the other hand, are everything else. All library- and user-defined types are messages.&lt;/p&gt;
    &lt;p&gt;The two varieties of types have completely different semantics, of course.&lt;/p&gt;
    &lt;p&gt;Fields with scalar types are always present. Even if you don’t set them. Did I mention that (at least in proto31) all protobuffers can be zero-initialized with absolutely no data in them? Scalar fields get false-y values—&lt;code&gt;uint32&lt;/code&gt; is initialized to &lt;code&gt;0&lt;/code&gt; for example, and &lt;code&gt;string&lt;/code&gt; is initialized as &lt;code&gt;""&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;It’s impossible to differentiate a field that was missing in a protobuffer from one that was assigned to the default value. Presumably this decision is in place in order to allow for an optimization of not needing to send default scalar values over the wire. Presumably, though the encoding guide makes no mention of this optimization being performed, so your guess is as good as mine.&lt;/p&gt;
    &lt;p&gt;As we’ll see when we discuss protobuffers’ claim to being god’s gift to backwards- and forwards-compatible APIs, this inability to distinguish between unset and default values is a nightmare. Especially if indeed it’s a design decision made in order to save one bit (set or not) per field.&lt;/p&gt;
    &lt;p&gt;Contrast this behavior against message types. While scalar fields are dumb, the behavior for message fields is outright insane. Internally, message fields are either there or they’re not—but their behavior is crazy. Some pseudocode for their accessor is worth a thousand words. Pretend this is Java or something similar:&lt;/p&gt;
    &lt;code&gt;private Foo m_foo;

public Foo foo {
// only if `foo` is used as an expression
   {
   get if (m_foo != null)
     return m_foo;
       else
     return new Foo();
       }
   
// instead if `foo` is used as an lvalue
   {
   mutable get if (m_foo = null)
     = new Foo();
       m_foo return m_foo;
     }
   }&lt;/code&gt;
    &lt;p&gt;The idea is that if the &lt;code&gt;foo&lt;/code&gt; field is unset, you’ll see a default-initialized copy whenever you ask for it, but won’t actually modify its container. But if you modify &lt;code&gt;foo&lt;/code&gt;, it will modify its parent as well! All of this just to avoid using a &lt;code&gt;Maybe Foo&lt;/code&gt; type and the associated “headaches” of the nuance behind needing to figure out what an unset value should mean.&lt;/p&gt;
    &lt;p&gt;This behavior is especially egregious, because it breaks a law! We’d expect the assignment &lt;code&gt;msg.foo = msg.foo;&lt;/code&gt; to be a no-op. Instead the implementation will actually silently change &lt;code&gt;msg&lt;/code&gt; to have a zero-initialized copy of &lt;code&gt;foo&lt;/code&gt; if it previously didn’t have one.&lt;/p&gt;
    &lt;p&gt;Unlike scalar fields, at least it’s possible to detect if a message field is unset. Language bindings for protobuffers offer something along the lines of a generated &lt;code&gt;bool has_foo()&lt;/code&gt; method. In the frequent case of copying a message field from one proto to another, iff it was present, you’ll need to write the following code:&lt;/p&gt;
    &lt;code&gt;if (src.has_foo(src)) {
.set_foo(src.foo());
   dst}&lt;/code&gt;
    &lt;p&gt;Notice that, at least in statically-typed languages, this pattern cannot be abstracted due to the nominal relationship between the methods &lt;code&gt;foo()&lt;/code&gt;, &lt;code&gt;set_foo()&lt;/code&gt; and &lt;code&gt;has_foo()&lt;/code&gt;. Because all of these functions are their own identifiers, we have no means of programmatically generating them, save for a preprocessor macro:&lt;/p&gt;
    &lt;code&gt;#define COPY_IFF_SET(src, dst, field) \
if (src.has_##field(src)) { \
  dst.set_##field(src.field()); \
}&lt;/code&gt;
    &lt;p&gt;(but preprocessor macros are verboten by the Google style guide.)&lt;/p&gt;
    &lt;p&gt;If instead all optional fields were implemented as &lt;code&gt;Maybe&lt;/code&gt;s, you’d get abstract-able, referentially transparent call-sites for free.&lt;/p&gt;
    &lt;p&gt;To change tack, let’s talk about another questionable decision. While you can define &lt;code&gt;oneof&lt;/code&gt; fields in protobuffers, their semantics are not of coproduct types! Rookie mistake my dudes! What you get instead is an optional field for each case of the &lt;code&gt;oneof&lt;/code&gt;, and magic code in the setters that will just unset any other case if this one is set.&lt;/p&gt;
    &lt;p&gt;At first glance, this seems like it should be semantically equivalent to having a proper union type. But instead it is an accursed, unutterable source of bugs! When this behavior teams up with the law-breaking implementation of &lt;code&gt;msg.foo = msg.foo;&lt;/code&gt;, it allows this benign-looking assignment to silently delete arbitrary amounts of data!&lt;/p&gt;
    &lt;p&gt;What this means at the end of the day is that &lt;code&gt;oneof&lt;/code&gt; fields do not form law-abiding &lt;code&gt;Prism&lt;/code&gt;s, nor do messages form law-abiding &lt;code&gt;Lens&lt;/code&gt;es. Which is to say good luck trying to write bug-free, non-trivial manipulations of protobuffers. It is literally impossible to write generic, bug-free, polymorphic code over protobuffers.&lt;/p&gt;
    &lt;p&gt;That’s not the sort of thing anybody likes to hear, let alone those of us who have grown to love parametric polymorphism—which gives us the exact opposite promise.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Lie of Backwards- and Forwards-Compatibility&lt;/head&gt;
    &lt;p&gt;One of the frequently cited killer features of protobuffers is their “hassle-free ability to write backwards- and forwards-compatible APIs.” This is the claim that has been pulled over your eyes to blind you from the truth.&lt;/p&gt;
    &lt;p&gt;What protobuffers are is permissive. They manage to not shit the bed when receiving messages from the past or from the future because they make absolutely no promises about what your data will look like. Everything is optional! But if you need it anyway, protobuffers will happily cook up and serve you something that typechecks, regardless of whether or not it’s meaningful.&lt;/p&gt;
    &lt;p&gt;This means that protobuffers achieve their promised time-traveling compatibility guarantees by silently doing the wrong thing by default. Of course, the cautious programmer can (and should) write code that performs sanity checks on received protobuffers. But if at every use-site you need to write defensive checks ensuring your data is sane, maybe that just means your deserialization step was too permissive. All you’ve managed to do is decentralize sanity-checking logic from a well-defined boundary and push the responsibility of doing it throughout your entire codebase.&lt;/p&gt;
    &lt;p&gt;One possible argument here is that protobuffers will hold onto any information present in a message that they don’t understand. In principle this means that it’s nondestructive to route a message through an intermediary that doesn’t understand this version of its schema. Surely that’s a win, isn’t it?&lt;/p&gt;
    &lt;p&gt;Granted, on paper it’s a cool feature. But I’ve never once seen an application that will actually preserve that property. With the one exception of routing software, nothing wants to inspect only some bits of a message and then forward it on unchanged. The vast majority of programs that operate on protobuffers will decode one, transform it into another, and send it somewhere else. Alas, these transformations are bespoke and coded by hand. And hand-coded transformations from one protobuffer to another don’t preserve unknown fields between the two, because it’s literally meaningless.&lt;/p&gt;
    &lt;p&gt;This pervasive attitude towards protobuffers always being compatible rears its head in other ugly ways. Style guides for protobuffers actively advocate against DRY and suggest inlining definitions whenever possible. The reasoning behind this is that it allows you to evolve messages separately if these definitions diverge in the future. To emphasize that point, the suggestion is to fly in the face of 60 years’ worth of good programming practice just in case maybe one day in the future you need to change something.&lt;/p&gt;
    &lt;p&gt;At the root of the problem is that Google conflates the meaning of data with its physical representation. When you’re at Google scale, this sort of thing probably makes sense. After all, they have an internal tool that allows you to compare the finances behind programmer hours vs network utilization vs the cost to store \(x\) bytes vs all sorts of other things. Unlike most companies in the tech space, paying engineers is one of Google’s smallest expenses. Financially it makes sense for them to waste programmers’ time in order to shave off a few bytes.&lt;/p&gt;
    &lt;p&gt;Outside of the top five tech companies, none of us is within five orders of magnitude of being Google scale. Your startup cannot afford to waste engineer hours on shaving off bytes. But shaving off bytes and wasting programmers’ time in the process is exactly what protobuffers are optimized for.&lt;/p&gt;
    &lt;p&gt;Let’s face it. You are not Google scale and you never will be. Stop cargo-culting technology just because “Google uses it” and therefore “it’s an industry best-practice.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Protobuffers Contaminate Codebases&lt;/head&gt;
    &lt;p&gt;If it were possible to restrict protobuffer usage to network-boundaries I wouldn’t be nearly as hard on it as a technology. Unfortunately, while there are a few solutions in principle, none of them is good enough to actually be used in real software.&lt;/p&gt;
    &lt;p&gt;Protobuffers correspond to the data you want to send over the wire, which is often related but not identical to the actual data the application would like to work with. This puts us in the uncomfortable position of needing to choose between one of three bad alternatives:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Maintain a separate type that describes the data you actually want, and ensure that the two evolve simultaneously.&lt;/item&gt;
      &lt;item&gt;Pack rich data into the wire format for application use.&lt;/item&gt;
      &lt;item&gt;Derive rich information every time you need it from a terse wire format.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Option 1 is clearly the “right” solution, but its untenable with protobuffers. The language isn’t powerful enough to encode types that can perform double-duty as both wire and application formats. Which means you’d need to write a completely separate datatype, evolve it synchronously with the protobuffer, and explicitly write serialization code between the two. Seeing as most people seem to use protobuffers in order to not write serialization code, this is obviously never going to happen.&lt;/p&gt;
    &lt;p&gt;Instead, code that uses protobuffers allows them to proliferate throughout the codebase. True story, my main project at Google was a compiler that took “programs” written in one variety of protobuffer, and spit out an equivalent “program” in another. Both the input and output formats were expressive enough that maintaining proper parallel C++ versions of them could never possibly work. As a result, my code was unable to take advantage of any of the rich techniques we’ve discovered for writing compilers, because protobuffer data (and resulting code-gen) is simply too rigid to do anything interesting.&lt;/p&gt;
    &lt;p&gt;The result is that a thing that could have been 50 lines of recursion schemes was instead 10,000 lines of ad-hoc buffer-shuffling. The code I wanted to write was literally impossible when constrained by having protobuffers in the mix.&lt;/p&gt;
    &lt;p&gt;While this is an anecdote, it’s not in isolation. By virtue of their rigid code-generation, manifestations of protobuffers in languages are never idiomatic, nor can they be made to be—short of rewriting the code-generator.&lt;/p&gt;
    &lt;p&gt;But even then, you still have the problem of needing to embed a shitty type-system into the targeted language. Because most of protobuffers’ features are ill-conceived, these unsavory properties leak into our codebases. It means we’re forced to not only implement, but also use these bad ideas in any project which hopes to interface with protobuffers.&lt;/p&gt;
    &lt;p&gt;While it’s easy to implement inane things out of a solid foundation, going the other direction is challenging at best and the dark path of Eldrich madness at worst.&lt;/p&gt;
    &lt;p&gt;In short, abandon all hope ye who introduce protobuffers into your projects.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;To this day, there’s a raging debate inside Google itself about proto2 and whether fields should ever be marked as&lt;/p&gt;&lt;code&gt;required&lt;/code&gt;. Manifestos with both titles “&lt;code&gt;optional&lt;/code&gt;considered harmful” and “&lt;code&gt;required&lt;/code&gt;considered harmful.” Good luck sorting that out.↩︎&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45139656</guid></item><item><title>MentraOS – open-source Smart glasses OS</title><link>https://github.com/Mentra-Community/MentraOS</link><description>&lt;doc fingerprint="d2f052307bbfb732"&gt;
  &lt;main&gt;
    &lt;p&gt;Works with Even Realities G1, Mentra Mach 1, Mentra Live. See smart glasses compatibility list here.&lt;/p&gt;
    &lt;p&gt;The Mentra Store already has a ton of useful apps that real users are running everyday. Here are some apps already published by developers on the Mentra Store:&lt;/p&gt;
    &lt;p&gt;MentraOS is how developers build smart glasses apps. We handle the pairing, connection, data streaming, and cross-compatibility, so you can focus on creating amazing apps. Every component is 100% open source (MIT license).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cross Compatibility: Your app runs on any pair of smart glasses&lt;/item&gt;
      &lt;item&gt;Speed: TypeScript SDK means you're making apps in minutes, not months&lt;/item&gt;
      &lt;item&gt;Control: Access smart glasses I/O - displays, microphones, cameras, speakers&lt;/item&gt;
      &lt;item&gt;Distribution: Get your app in front of everyone using smart glasses&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The MentraOS Community is a group of developers, companies, and users dedicated to ensuring the next personal computer is open, cross-compatible, and user-controlled. That's why we're building MentraOS.&lt;/p&gt;
    &lt;p&gt;To get involved, join the MentraOS Community Discord server.&lt;/p&gt;
    &lt;p&gt;Have questions or ideas? We'd love to hear from you!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Email: team@mentra.glass&lt;/item&gt;
      &lt;item&gt;Discord: Join our community&lt;/item&gt;
      &lt;item&gt;Twitter: Follow @mentralabs&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;MentraOS is made by a community and we welcome PRs. Here's the Contributors Guide: docs.mentra.glass/contributing&lt;/p&gt;
    &lt;p&gt;MIT License Copyright 2025 MentraOS Community&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45140381</guid></item><item><title>Making a font of my handwriting</title><link>https://chameth.com/making-a-font-of-my-handwriting/</link><description>&lt;doc fingerprint="3714a019faa705f8"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Making a font of my handwriting&lt;/head&gt;
    &lt;p&gt;Published on&lt;/p&gt;
    &lt;p&gt;Recently Iâve been on a small campaign to try to make my personal website moreâ¦ personal. Little ways to make it obvious itâs mine and personal, not just another piece of the boring corporate dystopia that is most of the web these days. I donât quite want to fully regress to the Geocities era and fill the screen with animated under construction GIFs, but I do want to capture some of that vibe.&lt;/p&gt;
    &lt;p&gt;Iâd added some bits and pieces along those lines: floating images in articles now look like theyâre stuck to the page with sellotape, related post links have a wavy border that animates when you hover over them, and so on. Next, I wanted to change the heading fonts from a monospace font to something cursive, to resemble handwriting. Less terminal output, more handwritten letter. I couldnât find one I liked, though. So why not make my own? It canât be that hard, right?&lt;/p&gt;
    &lt;head rend="h3"&gt;Failing to do it myself&lt;/head&gt;
    &lt;p&gt;I set out to try to make the font myself using open source tools. After doing a bit of research, it seemed like the general approach was to create vectors of each character and then import them into a font editor. That seems to mean either Adobe Illustrator and FontLab (if you have too much money) or Inkscape and FontForge (if you like open source). I fall firmly into the latter category, so I grabbed my graphics tablet and opened Inkscape.&lt;/p&gt;
    &lt;p&gt;I wrote out my first three letters: capital A, B and C. Saved them in Inkscape, and attempted to import them into FontForge. Then I remembered one crucial thing that had slipped my mind: I absolutely loathe using FontForge. Itâs a bit like when you open an old version of GIMP and get a bunch of weird looking windows floating all over the place; it feels like youâre fighting against the tool to do even the most basic operations. The difference is I have cause to edit images a lot more than I edit fonts, and GIMP has actually significantly improved their UI over the years.&lt;/p&gt;
    &lt;p&gt;Here are the rough steps I went through with FontForge:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Launch Font Forge. It shows a weird bit of art in one window, and an open file dialog in another.&lt;/item&gt;
      &lt;item&gt;I donât want to open a file, so I close that dialog. The program exits.&lt;/item&gt;
      &lt;item&gt;Relaunch Font Forge, and realise that within the âOpen Fontâ dialog is a âNewâ button. Click it.&lt;/item&gt;
      &lt;item&gt;Get to the standard font-editing UI. Right-click on the âAâ looking for a way to import an SVG. Donât see one.&lt;/item&gt;
      &lt;item&gt;Click around a bit, exploring the menus. Everything feels a bit off. You canât open one menu then hover over the next to see its content, like basically every UI toolkit in existence. I think FontForge has eschewed QT and GTK in favour of doing things itself.&lt;/item&gt;
      &lt;item&gt;Find the âImportâ option in the File menu. Hope itâs for a single glyph not the whole font.&lt;/item&gt;
      &lt;item&gt;A file picker opens. Again itâs all a bit off from normal desktop conventions. Try to resize it, and just get blank gray space at the bottom.&lt;/item&gt;
      &lt;item&gt;Type the absolute path I want to go to in the text field.&lt;/item&gt;
      &lt;item&gt;Get a dialog saying âNot a bdf file /home/chris/etcâ. Press OK.&lt;/item&gt;
      &lt;item&gt;Get a dialog saying âCould not find a bitmap font inâ. Press OK.&lt;/item&gt;
      &lt;item&gt;Press Ctrl+L to see if that lets me enter a path. Click everything in the dialog to try to find a way to enter a path. Get annoyed. Give up. Click through folder-by-folder to get to where I want to be.&lt;/item&gt;
      &lt;item&gt;Get to the folder and donât see any files. Change the format to âSVGâ. Double-click the newly-visible SVG file.&lt;/item&gt;
      &lt;item&gt;Get a dialog saying âYou must select a glyph before you can import an image into itâ. Press OK.&lt;/item&gt;
      &lt;item&gt;The import dialog goes away, having not imported.&lt;/item&gt;
      &lt;item&gt;Select the glyph in the main tool area, then repeat the FileâImport dance.&lt;/item&gt;
      &lt;item&gt;Itâs actually there now! Open the glyph in the editor and see itâs a complete mess of BÃ©zier curves. I canât click what I want without accidentally moving a handle for an adjacent curve.&lt;/item&gt;
      &lt;item&gt;Rage-quit.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Iâm sure FontForge is less anger inducing once youâre used to it. And you definitely could use it to build a font like this if you had much more patience than me. Iâd had enough of death-by-a-thousand-paper-cuts though.&lt;/p&gt;
    &lt;p&gt;I briefly tried Inkscapeâs built-in support for making an SVG font. It annoyed me a lot less, but itâs fiddly: it seemed like each font had to be a single path, so you had to convert the glyphs to paths, then merge them correctly. If you merge them incorrectly then the wrong bits of your letters end up filled (like the inside of the âBâ). Path manipulation is getting towards the limit of my knowledge of vector editing, and it took a bit of trial and error for each letter that had more than a single stroke. I didnât fancy doing that for every letter.&lt;/p&gt;
    &lt;p&gt;Iâm usually a big advocate of open source, but this was one of those painful times where it feels like it just falls short. Clunky, painful UI and processes where commercial tools just let you get on with your work.&lt;/p&gt;
    &lt;head rend="h3"&gt;You can exchange money for goods and services&lt;/head&gt;
    &lt;p&gt;When Iâd been looking for open source tutorials, I found many mentions of a closed source, hosted tool: Calligraphr. It has a free version with limitations (no ligatures, no variations, 75 glyphs per font), and a pro version for Â£8/month. Iâd normally balk at the idea of a subscription for this, but they have the perfect answer: you can make a one-time payment, and your account automatically downgrades back to free after a month. Itâs not a hidden option, either, itâs the most prominent button on the upgrade page. That made me happy to give them Â£8 to play around with the service for a month.&lt;/p&gt;
    &lt;p&gt;Calligraphr works by having you print templates, write out the letters, then scan them in. It does some magical processing to extract the glyphs, provides tools to tidy them up, align them, etc, and then produces a TTF file for you. You can see some of my completed templates here:&lt;/p&gt;
    &lt;p&gt;Calligraphr has a nice UI to generate the templates, allowing you to select which glyphs to include. I added the âminimal Englishâ, âbasic punctuationâ and âLigaturesâ sets. That gave me four pages to fill out, and I did them all twice. That let me filter out versions that didnât work well, and have variants for some letters so the font wasnât too repetitive. Later on, I went back and added some custom ligatures based on blog post titles that didnât look quite right: âReâ, âToâ, âersâ, âeyâ, âhyâ, âraâ, âreâ and âtyâ. Ligatures like this help it look more natural: when we write we donât just stamp out identical letters regardless of their surroundings, instead they will connect to their neighbours, or overlap slightly, or even share a stroke.&lt;/p&gt;
    &lt;p&gt;I filled these templates in with a Sharpie, as I wanted a fairly informal, scrap-booky look, and it would also give good solid shapes that should be easy to pick out of the template. I scanned them with the âScan Documentâ function on my iPhone, and uploaded the PDFs to Calligraphr.&lt;/p&gt;
    &lt;head rend="h3"&gt;Iterating and tweaking&lt;/head&gt;
    &lt;p&gt;The Calligraphr UI allows you to preview the font, but I found it a lot more useful to just download a copy and use it on a local copy of my website. That let me test it with real text, and see how itâd look at the different font sizes I use on the site.&lt;/p&gt;
    &lt;p&gt;The first version was not great. Despite the guidelines on the template, I apparently wasnât good at sticking to them. Some letters were floating way off the baseline, and some were sunken below. When those opposites met it looked terrible. Fortunately Calligraphr has a pretty easy tool to slide each letter up and down, and scale it up or down if needed, and you can see it next to other letters as you do it. It took a little bit of time to go through all the variants of all the letters, but the next version looked a lot better.&lt;/p&gt;
    &lt;p&gt;Another tweak I ended up doing was reducing the spacing between letters. The defaults Calligraphr uses are probably good for a blocky font, but I wanted to put the letters close together to give it more of a joined-up look. Again, this is an easy tool to use, you just drag the sides in or out as desired. While these tweaking steps were probably as fiddly as some of the Inkscape steps I refused to do earlier, theyâre a lot more rewarding as you see things improving with each one. Itâs a lot easier for me to commit time and effort to improving something thatâs already working reasonably, than put that time and energy into an unknown.&lt;/p&gt;
    &lt;p&gt;Later, I noticed that occasionally there would be a huge gap in a title. Not âthe kerning is slightly offâ but âthereâs enough room to park a busâ. It took me a while to figure out what was happening: a couple of glyphs hadnât been isolated perfectly and had picked up a few pixels from the template lines at the edge of their boxes. That meant the glyph had a width that covered the actual written glyph, a big gap, and then the rogue marks. At first, I fixed this by just adjusting the width, but that left the little pixels floating awkwardly down-sentence. The proper fix was to use the editing tool and simply delete them, and then Calligraphr snapped the width back to what it should be.&lt;/p&gt;
    &lt;p&gt;These iterations took a while to do, but I just dipped in and out occasionally over the course of a week, so it didnât actually feel like too much work. I quite enjoy the process of refining things, too.&lt;/p&gt;
    &lt;head rend="h3"&gt;Result and a surprise&lt;/head&gt;
    &lt;p&gt;If youâre viewing this post on my website[1], you can see the font in the headers, captions, and a few other places. Hereâs how it compares to my actual handwriting:&lt;/p&gt;
    &lt;p&gt;Itâs not close enough to forge documents, but I think it definitely gets across my style, and thatâs exactly what I wanted. Itâs surprisingly legible even at smaller font sizes â I think the weight of the Sharpie helps here â and at Â£8 and a bit of manual work was a lot more economical than spending days wresting with open source tools.&lt;/p&gt;
    &lt;p&gt;A few weeks after I put the finishing touches on the font, I got an e-mail from Calligraphr. As my account had lapsed back to the free version, I was no longer eligible for the âserver-side backupâ feature. So what did they do? They e-mailed me an exported copy! Itâs a JSON file with the properties of each glyph and a base64 encoded image. Not only can I re-upload this to Calligraphr if I resubscribe, I can probably hook something up to edit it should I ever need to. Iâm blown away by how pro-user Calligraphrâs business practices are. Theyâre up-front about pricing, donât try and get you stuck on an auto-renewing subscription, and automatically export your data. Itâs like a breath of fresh air compared to the barrage of dark patterns that other websites foist on us. If you want to make this kind of font, Iâd definitely recommend them just because of how nice they are.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;And I havenât changed everything since writing this postâ¦ â©ï¸&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Thanks for reading!&lt;/head&gt;
    &lt;head rend="h3"&gt;Related posts&lt;/head&gt;
    &lt;head rend="h3"&gt;Escaping Spotify the hard way&lt;/head&gt;
    &lt;p&gt;For the longest time I used Spotify for all my music needs. And I listen to a lot of music: sometimes actively, but mostly passively as background noise. I cancelled my premium subscription last December, and stopped using the service entirely. Why? Thereâs a bunch of reasons.&lt;/p&gt;
    &lt;head rend="h3"&gt;How I use Tailscale&lt;/head&gt;
    &lt;p&gt;Iâve been using Tailscale for around four years to connect my disparate devices, servers and apps together. I wanted to talk a bit about how I use it, some cool features you might not know about, and some stumbling blocks I encountered.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Ethics of LLMs&lt;/head&gt;
    &lt;p&gt;Iâve written about LLMs a few times recently, carefully dodging the issue of ethics each time. I didnât want to bog down the other posts with it, and I wanted some time to think over the issues. Now Iâve had time to think, itâs time to remove my head from the sand. There are a lot of different angles to consider, and a lot of it is more nuanced than is often presented. Itâs not all doom and gloom, and itâs also not the most amazing thing since sliced bread. Who would have thought?&lt;/p&gt;
    &lt;head rend="h3"&gt;If all you have is a hammerâ¦&lt;/head&gt;
    &lt;p&gt;I presume everyone is familiar with the idiom âif all you have is a hammer, everything looks like a nailâ. If not, well, there it is. Itâs generally used pejoratively about being single-minded, but I think it also gives a glimpse into something more interesting: mental and perceptual sets.&lt;/p&gt;
    &lt;p&gt;Recently Iâve been on a small campaign to try to make my personal website moreâ¦ personal. Little ways to make it obvious itâs mine and personal, not just another piece of the boring corporate dystopia that is most of the web these days. I donât quite want to fully regress to the Geocities era and fill the screen with animated under construction GIFs, but I do want to capture some of that vibe.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45141636</guid></item><item><title>My Own DNS Server at Home – Part 1: IPv4</title><link>https://jan.wildeboer.net/2025/08/My-DNS-Part-1/</link><description>&lt;doc fingerprint="67234351e5b0b027"&gt;
  &lt;main&gt;
    &lt;p&gt;Posted:&lt;/p&gt;
    &lt;head rend="h1"&gt;My Own DNS Server At Home - Part 1: IPv4&lt;/head&gt;
    &lt;p&gt;âItâs always DNSâ is a famous meme among network people. Name resolution is technically quite simple. Itâs âjustâ translating a hostname like &lt;code&gt;jan.wildeboer.net&lt;/code&gt; to an IP address. What could possibly go wrong? I am a radical optimist and detail-obsessed knowledge collector, so I decided to find out. As part of my goal to make my home network a little island of Digital Sovereignty, meaning that everything at home should JustWorkâ¢, even with no working internet connection, a DNS server is needed.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Based on and extended from my gist Bind on Fedora 42 as DNS server.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I admit, I have a lot of experience with DNS and BIND. But I still consider myself to be merely on the GoodEnoughâ¢ side of things. I know how to get DNS configured for my domains. And I want you to feel fearless too. The best place to fail with DNS is the network at home. It limits the impact :)&lt;/p&gt;
    &lt;p&gt;So read this blog post either as report or as a HOWTO. Both ways can be fun!&lt;/p&gt;
    &lt;p&gt;In my homelab I have a Raspberry Pi 4 that runs infrastructure services. DNS is one of them, my private CA (Certificate Authority) another. The CA runs as a container on Podman. For DNS I use Bind. It thus has to serve 3 networks:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;192.168.1.0/24&lt;/code&gt;My home IPv4 network&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;172.16.0.0/16&lt;/code&gt;IPv4 Network on the second ethernet ports of my homelab servers&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;10.88.0.0/16&lt;/code&gt;The (virtual) podman network&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It uses my Fritz box (7490) as forwarder, so I can resolve all hosts, including the DHCP entries that the Fritz Box hands out under its default local domain name &lt;code&gt;fritz.box&lt;/code&gt;. For my homelab however, I use the &lt;code&gt;homelab.jhw&lt;/code&gt; domain name. Thatâs what the Bind DNS server has to take care of.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;WARNING&lt;/p&gt;&lt;lb/&gt;I really should use the official&lt;code&gt;.internal&lt;/code&gt;TLD (Top Level Domain) for my homelab network, but I decided against it. This introduces the risk of name resolution problems, should someone offer a public&lt;code&gt;.jhw&lt;/code&gt;TLD in future. Itâs a risk I am willing to accept in exchange for using a 3 letter TLD at home. Donât be like me! Use&lt;code&gt;.internal&lt;/code&gt;instead. With that out of the way, letâs continue.&lt;/quote&gt;
    &lt;head rend="h2"&gt;What we (well, I) have&lt;/head&gt;
    &lt;p&gt;Letâs gather what I have in my home network.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;inf01.homelab.jhw&lt;/code&gt;at&lt;code&gt;192.168.1.10&lt;/code&gt;: A Raspberry Pi 4 4GB, running Fedora 42 and podman with my Certificate Authority as a container that should be reachable as&lt;code&gt;ca.homelab.jhw&lt;/code&gt;. See Be the LetsEncrypt in your homelab with step-ca for more details.&lt;/item&gt;
      &lt;item&gt;3 ThinkCentre Tiny PCs in the &lt;code&gt;homelab.jhw&lt;/code&gt;zone, called hl01 (&lt;code&gt;192.168.1.11&lt;/code&gt;), hl02 (&lt;code&gt;192.168.1.12&lt;/code&gt;) and hl03 (&lt;code&gt;192.168.1.13&lt;/code&gt;), running RHEL10 (Red Hat Enterprise Linux)&lt;/item&gt;
      &lt;item&gt;A Fritz Box 7490 at &lt;code&gt;192.168.1.254&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Letâs install BIND on inf01&lt;/head&gt;
    &lt;p&gt;We need to do two things. Install BIND and some utilities on &lt;code&gt;inf01&lt;/code&gt; and open the firewall for DNS traffic.&lt;/p&gt;
    &lt;code&gt;dnf install bind bind-utils
firewall-cmd --add-service=dns --permanent
&lt;/code&gt;
    &lt;p&gt;That was easy enough :)&lt;/p&gt;
    &lt;head rend="h3"&gt;Configure BIND&lt;/head&gt;
    &lt;p&gt;To run BIND in the correct way, we need to work on 4 configuration files.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;/etc/named.conf&lt;/code&gt;The main configuration file where we tell BIND on which networks it should listen and what zones it will serve.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/var/named/forward.homelab.jhw&lt;/code&gt;The forward zone file that maps hostnames in the&lt;code&gt;homelab.jhw&lt;/code&gt;domain to IP addresses on my home network&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/var/named/reverse.homelab.jhw&lt;/code&gt;The reverse zone for the&lt;code&gt;192.168.1.0/24&lt;/code&gt;network range, that looks a bit confusing, that does the opposite. It maps IP addresses to hostnames.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/var/named/reverse2.homelab.jhw&lt;/code&gt;The second reverse zone for the&lt;code&gt;172.16.0.0/16&lt;/code&gt;network range.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Letâs start with &lt;code&gt;/etc/named.conf&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;//
// named.conf
//

options {
  listen-on port 53 { 127.0.0.1; 192.168.1.10; 172.16.1.10; 10.88.0.1; };
  listen-on-v6 port 53 { ::1; fdda:a4da:69a5:0:2783:8c26:b2f1:a6f7; };
  allow-query     { localhost; 192.168.1.0/24; 172.16.0.0/16; 10.88.0.0/16; };

  directory       "/var/named";

  dump-file       "/var/named/data/cache_dump.db";
  statistics-file "/var/named/data/named_stats.txt";
  memstatistics-file "/var/named/data/named_mem_stats.txt";
  secroots-file   "/var/named/data/named.secroots";
  recursing-file  "/var/named/data/named.recursing";

  forwarders { 192.168.1.254; };
  recursion yes;

  dnssec-validation no;

  managed-keys-directory "/var/named/dynamic";
  geoip-directory "/usr/share/GeoIP";

  pid-file "/run/named/named.pid";
  session-keyfile "/run/named/session.key";

  /* https://fedoraproject.org/wiki/Changes/CryptoPolicy */
  include "/etc/crypto-policies/back-ends/bind.config";
};

logging {
        channel default_debug {
                file "data/named.run";
                severity dynamic;
        };
};

zone "." IN {
	type hint;
	file "named.ca";
};

zone "homelab.jhw" IN {
	type master;
	file "forward.homelab.jhw";
	allow-update { none; };
	allow-query { any; };
};

zone "1.168.192.in-addr.arpa" IN {
	type master;
	file "reverse.homelab.jhw";
	allow-update { none; };
	allow-query { any; };
};

zone "16.172.in-addr.arpa" IN {
        type master;
        file "reverse2.homelab.jhw";
        allow-update { none; };
        allow-query { any; };
};

include "/etc/named.rfc1912.zones";
include "/etc/named.root.key";
&lt;/code&gt;
    &lt;p&gt;The first block declare the general options. Yes, it looks complicated and it is, but letâs walk you through every relevant line (the lines not mentioned are default entries that donât need to be changed).&lt;/p&gt;
    &lt;code&gt;listen-on port 53 { 127.0.0.1; 192.168.1.10; 172.16.1.10; 10.88.0.1; };
listen-on-v6 port 53 { ::1; fdda:a4da:69a5:0:2783:8c26:b2f1:a6f7; };
allow-query     { localhost; 192.168.1.0/24; 172.16.0.0/16; 10.88.0.0/16; };
&lt;/code&gt;
    &lt;p&gt;Here we tell BIND that it should listen for queries on port 53 on &lt;code&gt;localhost&lt;/code&gt;, &lt;code&gt;192.168.1.10&lt;/code&gt;, the IPv4 address in my hoem network, &lt;code&gt;172.16.1.10&lt;/code&gt;, the second IPv4 address configured and &lt;code&gt;10.88.0.1&lt;/code&gt;, the virtual IPv4 address the Raspberry uses to bridge to the local podman containers.&lt;/p&gt;
    &lt;p&gt;The second line does the same for IPv6, but that is something we will discuss in Part 2.&lt;/p&gt;
    &lt;p&gt;The third line tells BIND from whom to accept queries. Essentially from everyone on the three IPv4 networks we are listening to.&lt;/p&gt;
    &lt;code&gt;directory       "/var/named";
&lt;/code&gt;
    &lt;p&gt;This is the directory where BIND will look for its zone files, that we will define later.&lt;/p&gt;
    &lt;code&gt;forwarders { 192.168.1.254; };
recursion yes;
&lt;/code&gt;
    &lt;p&gt;Now what if someone asks for a hostname that is outside of &lt;code&gt;homelab.jhw&lt;/code&gt;? In that case we tell BIND to forward that question to &lt;code&gt;192.168.1.254&lt;/code&gt;, our Fritz Box. We will allow recursion and cache results we get from our Fritz box to avoid unneeded traffic.&lt;/p&gt;
    &lt;code&gt;dnssec-validation no;
&lt;/code&gt;
    &lt;p&gt;Our simple setup will not bother with DNSSEC at the moment. Maybe we will have a Part 3 for that.&lt;/p&gt;
    &lt;p&gt;OK. That was the options part. We will ignore the &lt;code&gt;logging&lt;/code&gt; part and the &lt;code&gt;zone "." IN&lt;/code&gt; block.&lt;/p&gt;
    &lt;p&gt;Next (and finally) we define three zone entries (and zone files). A forward zone called &lt;code&gt;homelab.jhw&lt;/code&gt; for our domain and two reverse zones for the IP addresses in the &lt;code&gt;192.168.1.0/24&lt;/code&gt; range called &lt;code&gt;1.168.192.in-addr.arpa&lt;/code&gt;. Yep. Thatâs 192.168.1 reversed. 1.168.192. Thatâs why itâs called the reverse zone ;) We also have &lt;code&gt;16.172.in-addr.arpa&lt;/code&gt; for the &lt;code&gt;172.16.0.0/16&lt;/code&gt; range. Letâs look at them.&lt;/p&gt;
    &lt;code&gt;zone "homelab.jhw" IN {
	type master;
	file "forward.homelab.jhw";
	allow-update { none; };
	allow-query { any; };
};
&lt;/code&gt;
    &lt;p&gt;Itâs a zone, all right. Itâs the &lt;code&gt;master&lt;/code&gt; for this zone, meaning that this DNS server will be the Source of Truth to  answer all queries for the &lt;code&gt;homelab.jhw&lt;/code&gt; hostnames.&lt;/p&gt;
    &lt;p&gt;The exact mapping of all hostnames to IP addresses is in a file called &lt;code&gt;forward.homelab.jhw&lt;/code&gt; in the directory &lt;code&gt;/var/named&lt;/code&gt;. Remember how we defined that path at the beginning in the &lt;code&gt;options&lt;/code&gt; part? Great! We also tell BIND that we do not allow dynamic updates for this zone, meaning that whatâs in the file is all we will look at. Finally we tell BIND that any machine in the network is allowed to ask for a reply.&lt;/p&gt;
    &lt;code&gt;zone "1.168.192.in-addr.arpa" IN {
	type master;
	file "reverse.homelab.jhw";
	allow-update { none; };
	allow-query { any; };
};

zone "16.172.in-addr.arpa" IN {
        type master;
        file "reverse2.homelab.jhw";
        allow-update { none; };
        allow-query { any; };
};
&lt;/code&gt;
    &lt;p&gt;The reverse zones with the weird looking zone names are almost the same, except that we define these in two files called &lt;code&gt;reverse.homelab.jhw&lt;/code&gt; for the reverse lookup of the &lt;code&gt;192.168.1.0/24&lt;/code&gt; range and &lt;code&gt;reverse2.homelab.jhw&lt;/code&gt; for the &lt;code&gt;172.16.0.0/16&lt;/code&gt; range. Why these zones have weird names will be explained later.&lt;/p&gt;
    &lt;p&gt;So now we go to the zone files!&lt;/p&gt;
    &lt;head rend="h3"&gt;Forward zone for homelab.jhw&lt;/head&gt;
    &lt;p&gt;The forward zone resolves names to IP addresses using A records (and other types like TXT, CAA and many more exist, but we wonât cover that in this post). It also contains CNAME entries, if you have services on one machine that should be reachable via more than one hostnames. In my homelab the CA (Certificate Authority) server is a container that runs on &lt;code&gt;inf01.homelab.jhw&lt;/code&gt;, but should be reachable as &lt;code&gt;ca.homelab.jhw&lt;/code&gt; in the home network. The CNAME entry does exactly that. It tells clients that when they want to talk to &lt;code&gt;ca.homelab.jhw&lt;/code&gt; they can. By actually talking to &lt;code&gt;inf01.homelab.jhw&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Now here is the big, important lessen for zone files. They have a serial number. Which MUST be incremented with every change. If you donât, weird things WILL happen. So:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;NEVER FORGET TO INCREASE THE SERIAL WITH EVERY CHANGE TO A ZONE FILE. OR RISK DNS HELL.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;
      &lt;code&gt;/var/named/forward.homelab.jhw&lt;/code&gt;
    &lt;/p&gt;
    &lt;code&gt;$TTL 3600
@   IN  SOA     inf01.homelab.jhw. root.homelab.jhw. (
        2025082706  ;Serial
        3600        ;Refresh
        1800        ;Retry
        604800      ;Expire
        86400       ;Minimum TTL
)
@       IN  NS          inf01.homelab.jhw.
@       IN  A           192.168.1.10

inf01           IN  A     192.168.1.10
hl01            IN  A     192.168.1.11
hl02            IN  A     192.168.1.12
hl03            IN  A     192.168.1.13

ca              IN  CNAME inf01.homelab.jhw.

inf01-m         IN  A     172.16.1.10
hl01-m          IN  A     172.16.1.11
hl02-m          IN  A     172.16.1.12
hl03-m          IN  A     172.16.1.13
&lt;/code&gt;
    &lt;p&gt;Again, letâs go through this.&lt;/p&gt;
    &lt;code&gt;$TTL 3600
&lt;/code&gt;
    &lt;p&gt;The default Time To Live (TTL) for DNS entries is set at 3600 seconds. Thatâs 1 hour. This means that when a machine in the network gets a DNS reply, it will not ask again for the same thing until the TTL has passed.&lt;/p&gt;
    &lt;code&gt;@   IN  SOA     inf01.homelab.jhw. root.homelab.jhw. (
        2025082706  ;Serial
        3600        ;Refresh
        1800        ;Retry
        604800      ;Expire
        86400       ;Minimum TTL
)
&lt;/code&gt;
    &lt;p&gt;The Start Of Authority (SOA) block. Here we say which DNS server is the owner of this domain. Itâs &lt;code&gt;inf01.homelab.jhw.&lt;/code&gt; (yes, that dot at the end is REALLY important). The &lt;code&gt;root.homelab.jhw&lt;/code&gt; actually means &lt;code&gt;root@homelab.jhw&lt;/code&gt; and is the email address responsible for this domain. Donât think to much about why and what :)&lt;/p&gt;
    &lt;code&gt;@       IN  NS          inf01.homelab.jhw.
@       IN  A           192.168.1.10
&lt;/code&gt;
    &lt;p&gt;The first ârealâ DNS entries! They are special, as the &lt;code&gt;@&lt;/code&gt; indicates, which means they represent the domain itself. We first define the nameserver (again? yes, don*ât ask) as NS record. And right after that we define the &lt;code&gt;A&lt;/code&gt; record as the IP address &lt;code&gt;192.168.1.10&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Did you notice that &lt;code&gt;.&lt;/code&gt; at the end of &lt;code&gt;inf01.homelab.jhw.&lt;/code&gt;? Thatâs another VERY important thing. The TL;DR is that this final &lt;code&gt;.&lt;/code&gt; tells DNS to stop doing fancy recursion and lookups. Just look for the hostname `inf01.homelab.jhw. Period. (pun intended). Donât care too much about this. Just remember:&lt;/p&gt;
    &lt;p&gt;EVERY HOSTNAME RECORD ENDS WITH A &lt;code&gt;.&lt;/code&gt; YOU WILL FORGET THIS. YOU WILL FIX THIS.&lt;/p&gt;
    &lt;code&gt;inf01           IN  A     192.168.1.10
hl01            IN  A     192.168.1.11
hl02            IN  A     192.168.1.12
hl03            IN  A     192.168.1.13
&lt;/code&gt;
    &lt;p&gt;Here come the &lt;code&gt;A&lt;/code&gt; records for &lt;code&gt;192.168.1.0/24&lt;/code&gt;! We finally get to map hostnames to IP addresses. For real! It now is quite self-explanatory, isnât it? The hostname gets an A record that is the IP address in my local network. And as these are IP addresses, no &lt;code&gt;.&lt;/code&gt; is needed at the end.&lt;/p&gt;
    &lt;code&gt;ca              IN  CNAME inf01.homelab.jhw.
&lt;/code&gt;
    &lt;p&gt;And here is the CNAME record. Which maps the hostname &lt;code&gt;ca.homelab.jhw&lt;/code&gt; to the Canonical NAME (CNAME) &lt;code&gt;inf01.homelab.jhw.&lt;/code&gt;. This is a hostname at the end! So it needs the &lt;code&gt;.&lt;/code&gt; Period :)&lt;/p&gt;
    &lt;code&gt;inf01-m         IN  A     172.16.1.10
hl01-m          IN  A     172.16.1.11
hl02-m          IN  A     172.16.1.12
hl03-m          IN  A     172.16.1.13
&lt;/code&gt;
    &lt;p&gt;And here we create another set of &lt;code&gt;A&lt;/code&gt; records for the same machines, but this time in the &lt;code&gt;172.16.0.0/16&lt;/code&gt; range. This range is used for management stuff, hence the &lt;code&gt;-m&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;And thatâs the gist of it. If you add a new machine to your network, configure it with an IP address (statically or with DHCP) and add it as an A record to the forward zone. Increment the serial and tell DNS to read the updated zone with &lt;code&gt;systemctl reload named&lt;/code&gt;. Done.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reverse zones for 192.168.1.0/24 and 172.16.0.0/16&lt;/head&gt;
    &lt;p&gt;The reverse zone maps IP addresses to hostnames. Often called the PTR or pointer record. You have to make sure that the entries here are synced to the forward zone.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;NEVER FORGET TO INCREASE THE SERIAL WITH EVERY CHANGE TO A ZONE FILE. Or risk DNS hell.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Here is the reverse zone for the &lt;code&gt;192.168.1.0/24&lt;/code&gt; range.&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;/var/named/reverse.homelab.jhw&lt;/code&gt;
    &lt;/p&gt;
    &lt;code&gt;$TTL 3600
@   IN  SOA     inf01.homelab.jhw. root.homelab.jhw. (
        2025082601  ;Serial
        3600        ;Refresh
        1800        ;Retry
        604800      ;Expire
        86400       ;Minimum TTL
)
@       IN  NS          inf01.homelab.jhw.
@       IN  PTR         homelab.jhw.
10      IN  PTR         inf01.homelab.jhw.
11      IN  PTR         hl01.homelab.jhw.
12      IN  PTR         hl02.homelab.jhw.
13      IN  PTR         hl03.homelab.jhw.
&lt;/code&gt;
    &lt;p&gt;As this is more or less the same but the other way round, I will not go through everything but instead explain the differences. Itâs the reverse zone, so now we have &lt;code&gt;PTR&lt;/code&gt; (pointer) entries that map an IPv4 address in the &lt;code&gt;192.168.1.0/24&lt;/code&gt; range to hostnames. WITH A DOT AT THE END. DO NOT FORGET THE DOT!&lt;/p&gt;
    &lt;p&gt;As this is a /24 block, we only need to set the last digit of the IPv4 address.&lt;/p&gt;
    &lt;p&gt;You might wonder, where is &lt;code&gt;ca&lt;/code&gt; here? Well, itâs CNAME is &lt;code&gt;info1.homelab.jhw&lt;/code&gt; and that already is in this reverse zone. That is good enough. No separate entry needed.&lt;/p&gt;
    &lt;p&gt;We also need the reverse zone for the &lt;code&gt;172.16.0.0/16&lt;/code&gt; range:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;/var/named/reverse2.homelab.jhw&lt;/code&gt;
    &lt;/p&gt;
    &lt;code&gt;$TTL 3600
@   IN  SOA     inf01.homelab.jhw. root.homelab.jhw. (
        2025082901  ;Serial
        3600        ;Refresh
        1800        ;Retry
        604800      ;Expire
        86400       ;Minimum TTL
)
@       IN  NS          inf01.homelab.jhw.
@       IN  PTR         homelab.jhw.
10.1      IN  PTR         inf01-m.homelab.jhw.
11.1      IN  PTR         hl01-m.homelab.jhw.
12.1      IN  PTR         hl02-m.homelab.jhw.
13.1      IN  PTR         hl03-m.homelab.jhw.
&lt;/code&gt;
    &lt;p&gt;Looks deceivingly similar. But there is a big difference. This is a /16 network, so we have to define the last two parts of the IPv4 address. And as it is a reverse zone file, yep, we have to reverse it. So now we need &lt;code&gt;10.1&lt;/code&gt; to define the entry for &lt;code&gt;172.16.1.10&lt;/code&gt;, which is the hostname &lt;code&gt;inf01-m.homelab.jhw&lt;/code&gt;. WITH THE DOT AT THE END. AND DID YOU UPDATE THE SERIAL? :)&lt;/p&gt;
    &lt;p&gt;Phew. Thatâs the config done!&lt;/p&gt;
    &lt;p&gt;A final check with the &lt;code&gt;named-checkconf&lt;/code&gt; command, which should say nothing when all files are OK. If not, it will tell you what is wrong so you get the chance to fix stuff. You did add all the &lt;code&gt;.&lt;/code&gt; at the end of hostnames and you did update the serial of that zone file after you made changes, yes?&lt;/p&gt;
    &lt;head rend="h2"&gt;Start Bind&lt;/head&gt;
    &lt;p&gt;The only thing remaining is to start BIND. And persist it as a service, so it starts after every boot. Itâs DNS. It must always be available.&lt;/p&gt;
    &lt;code&gt;systemctl enable named
systemctl start named
&lt;/code&gt;
    &lt;p&gt;You most likely will make typos in your config. So do check with &lt;code&gt;named-checkconf &lt;/code&gt; and &lt;code&gt;systemctl status named&lt;/code&gt; and &lt;code&gt;journalctl -u named&lt;/code&gt;. If something breaks, read this whole entry again. Find that missing &lt;code&gt;.&lt;/code&gt; in a zone file. Increment the &lt;code&gt;serial&lt;/code&gt; that you forgot to do. You will get there. Donât give up!&lt;/p&gt;
    &lt;head rend="h2"&gt;Result&lt;/head&gt;
    &lt;p&gt;Machines, containers etc can now be resolved in my home network. All with mow own DNS! Yay!&lt;/p&gt;
    &lt;code&gt;% nslookup jhwfritz.fritz.box
Server:		192.168.1.10
Address:	192.168.1.10#53

Non-authoritative answer:
Name:	jhwfritz.fritz.box
Address: 192.168.1.254

% nslookup ca.homelab.jhw    
Server:		192.168.1.10
Address:	192.168.1.10#53

ca.homelab.jhw	canonical name = inf01.homelab.jhw.
Name:	inf01.homelab.jhw
Address: 192.168.1.10
&lt;/code&gt;
    &lt;p&gt;And now you should be able to &lt;code&gt;ping&lt;/code&gt; the machines with their hostname. ssh into them. Get certificates with the CA that runs in the podman container. Life is good!&lt;/p&gt;
    &lt;p&gt;I hope you enjoyed this post and could learn something new! Feel free to comment or send corrections vie the Toot linked below that collects the comments!&lt;/p&gt;
    &lt;head rend="h4"&gt;COMMENTS&lt;/head&gt;
    &lt;p&gt;You can use your Mastodon or other ActivityPub account to comment on this article by replying to the associated post.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45142397</guid></item><item><title>Anthropic agrees to pay $1.5B to settle lawsuit with book authors</title><link>https://www.nytimes.com/2025/09/05/technology/anthropic-settlement-copyright-ai.html?unlocked_article_code=1.jk8.bTTt.Zir9wmtPaTp2&amp;smid=url-share</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45142885</guid></item><item><title>The Universe Within 12.5 Light Years</title><link>http://www.atlasoftheuniverse.com/12lys.html</link><description>&lt;doc fingerprint="b21697bf7e9b7625"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;The Universe within 12.5 Light Years&lt;lb/&gt;The Nearest Stars&lt;/head&gt;&lt;div&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt; Number of stars within 12.5 light years = 33&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;/div&gt;&lt;head rend="h3"&gt;About the Map&lt;/head&gt; This map shows all the star systems that lie within 12.5 light years of our Sun. Most of the stars are red dwarfs - stars with a tenth of the Sun's mass and less than one hundredth the luminosity. Roughly eighty percent of all the stars in the universe are red dwarfs, and the nearest star - Proxima - is a typical example. &lt;div&gt;&lt;table&gt;&lt;row&gt;&lt;cell colspan="2" role="head"&gt;Additional Maps&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt; This is a diagram that zooms out from the Earth's orbit to the nearest star system. It tries to show just how large the distance to the nearest star really is.&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt; Here is a map of all the known stars that lie within 20 light years plotted using the data provided below.&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell colspan="2" role="head"&gt;Data and Catalogs&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt; There are over 100 stars within 20 light years. This is a list of the known stars that lie within this distance.&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt; This is a page showing some simple animations of double, triple and quadruple star systems, to demonstrate how stars orbit each other.&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;/div&gt;&lt;head rend="h3"&gt;Information on the Nearest Stars&lt;/head&gt;&lt;list rend="dl"&gt;&lt;item rend="dt-1"&gt;Sun - Type=G2, Magnitude=-26.8, Distance=0.0000158 ly&lt;/item&gt;&lt;item rend="dd-1"&gt;A typical yellow dwarf star. It has eight planets orbiting it.&lt;/item&gt;&lt;item rend="dt-2"&gt;Proxima Centauri - Type=M5, Magnitude=11.0, Distance=4.22 ly&lt;/item&gt;&lt;item rend="dd-2"&gt;This dim red dwarf is the nearest star to the Sun, and it is a member of the Alpha Centauri system despite lying 0.24 light years from the main pair of stars, requiring over one million years to orbit them. Proxima was discovered in 1915 by Robert Innes and was at that time the least luminous star known. It is also a flare star - capable of brightening a magnitude or more in minutes.&lt;/item&gt;&lt;item rend="dt-3"&gt;Alpha Centauri A,B - Type=G2+K0, Magnitudes=0.0+1.4, Distance=4.39 ly&lt;/item&gt;&lt;item rend="dd-3"&gt;Just slightly further from us than Proxima, lie the orange and yellow dwarf stars that make up Alpha Centauri. Orbiting each other in an 80 year period, together they make up one of the brightest objects in southern hemisphere skies. Seen from Alpha Centauri, the third member of the system, Proxima, is a dim (magnitude 4.8) star.&lt;/item&gt;&lt;item rend="dt-4"&gt;Barnard's Star - Type=M5, Magnitude=9.6, Distance=5.94 ly&lt;/item&gt;&lt;item rend="dd-4"&gt;Famous for having the largest proper motion of any star, this dim red dwarf travels 0.29 degrees against the background sky in a century. Discovered by E Barnard in 1916, it was thought in the 1960's to have a couple of unseen planets orbiting it, but later observations disproved this. In another 8000 years Barnard's Star will become the closest star to us.&lt;/item&gt;&lt;item rend="dt-5"&gt;Wolf 359 - Type=M6, Magnitude=13.5, Distance=7.80 ly&lt;/item&gt;&lt;item rend="dd-5"&gt;An excessively dim red dwarf discovered by Max Wolf in 1918. For 25 years it was the least luminous star known.&lt;/item&gt;&lt;item rend="dt-6"&gt;Lalande 21185 - Type=M2, Magnitude=7.5, Distance=8.31 ly&lt;/item&gt;&lt;item rend="dd-6"&gt;Recorded in JJ Lalande's star catalogue compiled in the 1790's, this is one of the brightest red dwarfs in the sky, but it still needs binoculars to see it. G Gatewood reported in 1996 the possible indications of a couple of Jupiter sized planets orbiting it but this remains unconfirmed.&lt;/item&gt;&lt;item rend="dt-7"&gt;Sirius A,B - Type=A1+DA, Magnitudes=-1.4+8.4, Distance=8.60 ly&lt;/item&gt;&lt;item rend="dd-7"&gt;This brilliant white star is the brightest star in the night sky and the most luminous star within 25 light years. Its white dwarf companion was first seen in 1852, the first white dwarf ever seen. The orbital period is 50 years.&lt;/item&gt;&lt;item rend="dt-8"&gt;Luyten 726-8 A,B - Type=M5+M5, Magnitudes=12.4+13.3, Distance=8.73 ly&lt;/item&gt;&lt;item rend="dd-8"&gt;This is a dim binary system consisting of two red dwarfs. The system is perhaps more famously known as UV Ceti, the variable-star name of the second star in the system. It is a famous flare star and can visibly brighten by several magnitudes as it ejects flares from its surface similar to the ones seen on the surface of the Sun, but far more energetic. Both stars require about 200 years to orbit each other.&lt;/item&gt;&lt;item rend="dt-9"&gt;Ross 154 - Type=M4, Magnitude=10.4, Distance=9.69 ly&lt;/item&gt;&lt;item rend="dd-9"&gt;A dim red dwarf. It is one of a number of nearby stars catalogued by Frank Ross in the 1930's. It is also a known flare star.&lt;/item&gt;&lt;item rend="dt-10"&gt;Ross 248 - Type=M6, Magnitude=12.3, Distance=10.33 ly&lt;/item&gt;&lt;item rend="dd-10"&gt;Another dim red dwarf.&lt;/item&gt;&lt;item rend="dt-11"&gt;Epsilon Eridani - Type=K2, Magnitude=3.7, Distance=10.50 ly&lt;/item&gt;&lt;item rend="dd-11"&gt;An orange dwarf star. This star was searched for signs of intelligent life with the Green Bank radio telescope in 1960. The results, predictably, were negative. The IRAS satellite detected a lot of dust orbiting this star indicating a possible forming solar system, and even more recently, (Aug 2000), a Jupiter sized planet has been detected orbiting this star at a distance of 3.2 AU (480 million km).&lt;/item&gt;&lt;item rend="dt-12"&gt;Lacaille 9352 - Type=M2, Magnitude=7.4, Distance=10.73 ly&lt;/item&gt;&lt;item rend="dd-12"&gt;A fairly bright red dwarf which can easily be seen with binoculars, it was first recorded in Nicolas de Lacaille's catalogue of southern hemisphere stars compiled around 1752.&lt;/item&gt;&lt;item rend="dt-13"&gt;Ross 128 - Type=M4, Magnitude=11.1, Distance=10.89 ly&lt;/item&gt;&lt;item rend="dd-13"&gt;A dim red dwarf, also known as FI Vir - its variable star designation.&lt;/item&gt;&lt;item rend="dt-14"&gt;Luyten 789-6 A,B,C - Type=M5+M5+M7, Magnitudes=13.3+13.3+14.0, Distance=11.1 ly&lt;/item&gt;&lt;item rend="dd-14"&gt;There seems to be three red dwarfs in this system. The main pair orbiting each other in a 2 year period, and a dim third star orbiting the first at a very close range.&lt;/item&gt;&lt;item rend="dt-15"&gt;Procyon A,B - Type=F5+DA, Magnitudes=0.4+10.7, Distance=11.41 ly&lt;/item&gt;&lt;item rend="dd-15"&gt;A brilliant yellow-white star, and the eighth brightest star in the sky. With twice the diameter of the Sun, Procyon is also the largest star within 25 light years. Procyon is orbited by a white dwarf companion first seen optically in 1896. The orbital period is 41 years.&lt;/item&gt;&lt;item rend="dt-16"&gt;61 Cygni A,B - Type=K5+K7, Magnitudes=5.2+6.1, Distance=11.41 ly&lt;/item&gt;&lt;item rend="dd-16"&gt;This binary system of two orange dwarf stars is famous for being the first star ever to have its distance measured by F Bessel in 1838. Both stars are very similar but are widely separated (86 AU) requiring about 700 years to orbit each other.&lt;/item&gt;&lt;item rend="dt-17"&gt;Struve 2398 A,B - Type=M4+M5, Magnitudes=8.9+9.7, Distance=11.6 ly&lt;/item&gt;&lt;item rend="dd-17"&gt;A binary system of two red dwarfs named Struve 2398 from a catalogue of double stars published in 1827. This system is also known by the rather more boring name of BD+59°1915. The two stars are quite widely separated (50 AU) and orbit each other in a 450 year period.&lt;/item&gt;&lt;item rend="dt-18"&gt;Groombridge 34 A,B - Type=M2+M6, Magnitudes=8.1+11.1, Distance=11.64 ly&lt;/item&gt;&lt;item rend="dd-18"&gt;Another pair of red dwarfs, this system is usually called Groombridge 34 from an 1838 catalogue of northern stars or sometimes BD+43°44. Both stars are variable in brightness and have the variable star names of GX And and GQ And. Both stars lie far apart from each other (150 AU) and orbit each other in a 2500 year period.&lt;/item&gt;&lt;item rend="dt-19"&gt;Giclas 51-15 - Type=M6, Magnitude=14.8, Distance=11.8 ly&lt;/item&gt;&lt;item rend="dd-19"&gt;This excessively dim red dwarf is the least luminous star within 14 light years. It shines with just 0.01% of the Sun's luminosity.&lt;/item&gt;&lt;item rend="dt-20"&gt;Epsilon Indi A,B,C - Type=K5+T1+T6, Magnitude=4.7, Distance=11.83 ly&lt;/item&gt;&lt;item rend="dd-20"&gt;An orange dwarf. It is a similar star to Epsilon Eridani, although a little bit smaller and dimmer. Epsilon Indi is orbited by a pair of brown dwarfs - failed stars that are too small to burn. They were discovered in 2003 and they orbit each other in a 16 year period, and they are 1500 AU (220 billion km) from the main star and they require about 70 000 years to orbit it.&lt;/item&gt;&lt;item rend="dt-21"&gt;Tau Ceti - Type=G8, Magnitude=3.5, Distance=11.90 ly&lt;/item&gt;&lt;item rend="dd-21"&gt;The nearest, single, sun-like star. It was searched (unsuccessfully) for any signs of intelligent life in 1960, along with Epsilon Eridani.&lt;/item&gt;&lt;item rend="dt-22"&gt;Luyten 372-58 - Type=M5, Magnitude=13.0, Distance=12.1 ly&lt;/item&gt;&lt;item rend="dd-22"&gt;A very dim red dwarf. Although this star was catalogued decades ago, it has only recently had its distance determined with any accuracy.&lt;/item&gt;&lt;item rend="dt-23"&gt;Luyten 725-32 - Type=M5, Magnitude=12.1, Distance=12.1 ly&lt;/item&gt;&lt;item rend="dd-23"&gt;Another dim red dwarf.&lt;/item&gt;&lt;item rend="dt-24"&gt;Luyten's Star - Type=M3, Magnitude=9.8, Distance=12.39 ly&lt;/item&gt;&lt;item rend="dd-24"&gt;A red dwarf. It is named after Willem Luyten who realised it was a nearby star in 1935. The star lies just 1.2 light years away from Procyon, but it is not associated with it.&lt;/item&gt;&lt;/list&gt;&lt;p&gt; Epsilon Eridani is orbited by a large planet which might look like this. &lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45144337</guid></item><item><title>GLM 4.5 with Claude Code</title><link>https://docs.z.ai/guides/llm/glm-4.5</link><description>&lt;doc fingerprint="ccd2e51a790b4291"&gt;
  &lt;main&gt;&lt;code&gt;thinking.type&lt;/code&gt;parameter (with &lt;code&gt;enabled&lt;/code&gt; and &lt;code&gt;disabled&lt;/code&gt; settings), and dynamic thinking is enabled by default.
&lt;p&gt;Our most powerful reasoning model, with 355 billion parameters&lt;/p&gt;&lt;p&gt;Cost-Effective Lightweight Strong Performance&lt;/p&gt;&lt;p&gt;High Performance Strong Reasoning Ultra-Fast Response&lt;/p&gt;&lt;p&gt;Lightweight Strong Performance Ultra-Fast Response&lt;/p&gt;&lt;p&gt;Free Strong Performance Excellent for Reasoning Coding &amp;amp; Agents&lt;/p&gt;&lt;code&gt;thinking.type&lt;/code&gt; parameter. This parameter supports two values: &lt;code&gt;enabled&lt;/code&gt; (enabled) and &lt;code&gt;disabled&lt;/code&gt; (disabled). By default, dynamic thinking is enabled.
&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45145457</guid></item><item><title>Developing a Space Flight Simulator in Clojure</title><link>https://www.wedesoft.de/software/2025/09/05/clojure-game/</link><description>&lt;doc fingerprint="4c23b196c6d1b91"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Developing a Space Flight Simulator in Clojure&lt;/head&gt;05 Sep 2025&lt;p&gt;In 2017 I discovered the free of charge Orbiter 2016 space flight simulator which was proprietary at the time and it inspired me to develop a space flight simulator myself. I prototyped some rigid body physics in C and later in GNU Guile and also prototyped loading and rendering of Wavefront OBJ files. I used GNU Guile (a Scheme implementation) because it has a good native interface and of course it has hygienic macros. Eventually I got interested in Clojure because unlike GNU Guile it has multi-methods as well as fast hash maps and vectors. I finally decided to develop the game for real in Clojure. I have been developing a space flight simulator in Clojure for almost 5 years now. While using Clojure I have come to appreciate the immutable values and safe parallelism using atoms, agents, and refs.&lt;/p&gt;&lt;p&gt;In the beginning I decided to work on the hard parts first, which for me were 3D rendering of a planet, an atmosphere, shadows, and volumetric clouds. I read the OpenGL Superbible to get an understanding on what functionality OpenGL provides. When Orbiter was eventually open sourced and released unter MIT license here, I inspected the source code and discovered that about 90% of the code is graphics-related. So starting with the graphics problems was not a bad decision.&lt;/p&gt;&lt;head rend="h2"&gt;Software dependencies&lt;/head&gt;&lt;p&gt;The following software is used for development. The software libraries run on both GNU/Linux and Microsoft Windows.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Clojure the programming language&lt;/item&gt;&lt;item&gt;LWJGL provides Java wrappers for various libraries &lt;list rend="ul"&gt;&lt;item&gt;lwjgl-opengl for 3D graphics&lt;/item&gt;&lt;item&gt;lwjgl-glfw for windowing and input devices&lt;/item&gt;&lt;item&gt;lwjgl-nuklear for graphical user interfaces&lt;/item&gt;&lt;item&gt;lwjgl-stb for image I/O and using truetype fonts&lt;/item&gt;&lt;item&gt;lwjgl-assimp to load glTF 3D models with animation data&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Jolt Physics to simulate wheeled vehicles and collisions with meshes&lt;/item&gt;&lt;item&gt;Fastmath for fast matrix and vector math as well as spline interpolation&lt;/item&gt;&lt;item&gt;Comb for templating shader code&lt;/item&gt;&lt;item&gt;Instaparse to parse NASA Planetary Constant Kernel (PCK) files&lt;/item&gt;&lt;item&gt;Gloss to parse NASA Double Precision Array Files (DAF)&lt;/item&gt;&lt;item&gt;Coffi as a foreign function interface&lt;/item&gt;&lt;item&gt;core.memoize for least recently used caching of function results&lt;/item&gt;&lt;item&gt;Apache Commons Compress to read map tiles from tar files&lt;/item&gt;&lt;item&gt;Malli to add schemas to functions&lt;/item&gt;&lt;item&gt;Immuconf to load the configuration file&lt;/item&gt;&lt;item&gt;Progrock a progress bar for long running builds&lt;/item&gt;&lt;item&gt;Claypoole to implement parallel for loops&lt;/item&gt;&lt;item&gt;tools.build to build the project&lt;/item&gt;&lt;item&gt;clj-async-profiler Clojure profiler creating flame graphs&lt;/item&gt;&lt;item&gt;slf4j-timbre Java logging implementation for Clojure&lt;/item&gt;&lt;/list&gt;&lt;p&gt;The deps.edn file contains operating system dependent LWJGL bindings. For example on GNU/Linux the deps.edn file contains the following:&lt;/p&gt;&lt;p&gt;In order to manage the different dependencies for Microsoft Windows, a separate Git branch is maintained.&lt;/p&gt;&lt;head rend="h2"&gt;Atmosphere rendering&lt;/head&gt;&lt;p&gt;For the atmosphere, Brunetonâs precomputed atmospheric scattering was used. The implementation uses a 2D transmittance table, a 2D surface scattering table, a 4D Rayleigh scattering, and a 4D Mie scattering table. The tables are computed using several iterations of numerical integration. Higher order functions for integration over a sphere and over a line segment were implemented in Clojure. Integration over a ray in 3D space (using fastmath vectors) was implemented as follows for example:&lt;/p&gt;&lt;p&gt;Precomputing the atmospheric tables takes several hours even though pmap was used. When sampling the multi-dimensional functions, pmap was used as a top-level loop and map was used for interior loops. Using java.nio.ByteBuffer the floating point values were converted to a byte array and then written to disk using a clojure.java.io/output-stream:&lt;/p&gt;&lt;p&gt;When launching the game, the lookup tables get loaded and copied into OpenGL textures. Shader functions are used to lookup and interpolate values from the tables. When rendering the planet surface or the space craft, the atmosphere essentially gets superimposed using ray tracing. After rendering the planet, a background quad is rendered to display the remaining part of the atmosphere above the horizon.&lt;/p&gt;&lt;head rend="h2"&gt;Templating OpenGL shaders&lt;/head&gt;&lt;p&gt;It is possible to make programming with OpenGL shaders more flexible by using a templating library such as Comb. The following shader defines multiple octaves of noise on a base noise function:&lt;/p&gt;&lt;p&gt;One can then for example define the function fbm_noise using octaves of the base function noise as follows:&lt;/p&gt;&lt;head rend="h2"&gt;Planet rendering&lt;/head&gt;&lt;p&gt;To render the planet, NASA Bluemarble data, NASA Blackmarble data, and NASA Elevation data was used. The images were converted to a multi resolution pyramid of map tiles. The following functions were implemented for color map tiles and for elevation tiles:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;a function to load and cache map tiles of given 2D tile index and level of detail&lt;/item&gt;&lt;item&gt;a function to extract a pixel from a map tile&lt;/item&gt;&lt;item&gt;a function to extract the pixel for a specific longitude and latitude&lt;/item&gt;&lt;/list&gt;&lt;p&gt;The functions for extracting a pixel for given longitude and latitude then were used to generate a cube map with a quad tree of tiles for each face. For each tile, the following files were generated:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;A daytime texture&lt;/item&gt;&lt;item&gt;A night time texture&lt;/item&gt;&lt;item&gt;An image of 3D vectors defining a surface mesh&lt;/item&gt;&lt;item&gt;A water mask&lt;/item&gt;&lt;item&gt;A normal map&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Altogether 655350 files were generated. Because the Steam ContentBuilder does not support a large number of files, each row of tile data was aggregated into a tar file. The Apache Commons Compress library allows you to open a tar file to get a list of entries and then perform random access on the contents of the tar file. A Clojure LRU cache was used to maintain a cache of open tar files for improved performance.&lt;/p&gt;&lt;p&gt;At run time, a future is created, which returns an updated tile tree, a list of tiles to drop, and a path list of the tiles to load into OpenGL. When the future is realized, the main thread deletes the OpenGL textures from the drop list, and then uses the path list to get the new loaded images from the tile tree, load them into OpenGL textures, and create an updated tile tree with the new OpenGL textures added. The following functions to manipulate quad trees were implemented to realize this:&lt;/p&gt;&lt;head rend="h2"&gt;Other topics&lt;/head&gt;&lt;head rend="h3"&gt;Solar system&lt;/head&gt;&lt;p&gt;The astronomy code for getting the position and orientation of planets was implemented according to the Skyfield Python library. The Python library in turn is based on the SPICE toolkit of the NASA JPL. The JPL basically provides sequences of Chebyshev polynomials to interpolate positions of Moon and planets as well as the orientation of the Moon as binary files. Reference coordinate systems and orientations of other bodies are provided in text files which consist of human and machine readable sections. The binary files were parsed using Gloss (see Wiki for some examples) and the text files using Instaparse.&lt;/p&gt;&lt;head rend="h3"&gt;Jolt bindings&lt;/head&gt;&lt;p&gt;The required Jolt functions for wheeled vehicle dynamics and collisions with meshes were wrapped in C functions and compiled into a shared library. The Coffi Clojure library (which is a wrapper for Javaâs new Foreign Function &amp;amp; Memory API) was used to make the C functions and data types usable in Clojure.&lt;/p&gt;&lt;p&gt;For example the following code implements a call to the C function add_force:&lt;/p&gt;&lt;p&gt;Here ::vec3 refers to a custom composite type defined using basic types. The memory layout, serialisation, and deserialisation for ::vec3 are defined as follows:&lt;/p&gt;&lt;head rend="h3"&gt;Performance&lt;/head&gt;&lt;p&gt;The clj-async-profiler was used to create flame graphs visualising the performance of the game. In order to get reflection warnings for Java calls without sufficient type declarations, *warn-on-reflection* was set to true.&lt;/p&gt;&lt;p&gt;Furthermore to discover missing declarations of numerical types, *unchecked-math* was set to :warn-on-boxed.&lt;/p&gt;&lt;p&gt;To reduce garbage collector pauses, the ZGC low-latency garbage collector for the JVM was used. The following section in deps.edn ensures that the ZGC garbage collector is used when running the project with clj -M:run:&lt;/p&gt;&lt;p&gt;The option to use ZGC is also specified in the Packr JSON file used to deploy the application.&lt;/p&gt;&lt;head rend="h3"&gt;Building the project&lt;/head&gt;&lt;p&gt;In order to build the map tiles, atmospheric lookup tables, and other data files using tools.build, the project source code was made available in the build.clj file using a :local/root dependency:&lt;/p&gt;&lt;p&gt;Various targets were defined to build the different components of the project. For example the atmospheric lookup tables can be build by specifying clj -T:build atmosphere-lut on the command line.&lt;/p&gt;&lt;p&gt;The following section in the build.clj file was added to allow creating an âUberjarâ JAR file with all dependencies by specifying clj -T:build uber on the command-line.&lt;/p&gt;&lt;p&gt;To create a Linux executable with Packr, one can then run java -jar packr-all-4.0.0.jar scripts/packr-config-linux.json where the JSON file has the following content:&lt;/p&gt;&lt;p&gt;In order to distribute the game on Steam, three depots were created:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;a data depot with the operating system independent data files&lt;/item&gt;&lt;item&gt;a Linux depot with the Linux executable and Uberjar including LWJGLâs Linux native bindings&lt;/item&gt;&lt;item&gt;and a Windows depot with the Windows executable and an Uberjar including LWJGLâs Windows native bindings&lt;/item&gt;&lt;/list&gt;&lt;p&gt;When updating a depot, the Steam ContentBuilder command line tool creates and uploads a patch in order to preserve storage space and bandwidth.&lt;/p&gt;&lt;head rend="h2"&gt;Future work&lt;/head&gt;&lt;p&gt;Although the hard parts are mostly done, there are still several things to do:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;control surfaces and thruster graphics&lt;/item&gt;&lt;item&gt;launchpad and runway graphics&lt;/item&gt;&lt;item&gt;sound effects&lt;/item&gt;&lt;item&gt;a 3D cockpit&lt;/item&gt;&lt;item&gt;the Moon&lt;/item&gt;&lt;item&gt;a space station&lt;/item&gt;&lt;/list&gt;&lt;p&gt;It would also be interesting to make the game modable in a safe way (maybe evaluating Clojure files in a sandboxed environment?).&lt;/p&gt;&lt;head rend="h2"&gt;Conclusion&lt;/head&gt;&lt;p&gt;You can find the source code on Github. Currently there is only a playtest build, but if you want to get notified, when the game gets released, you can wishlist it here.&lt;/p&gt;&lt;p&gt;Anyway, let me know any comments and suggestions.&lt;/p&gt;&lt;p&gt;Enjoy!&lt;/p&gt;&lt;head rend="h2"&gt;Related blog posts&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Flight dynamics model for simulating Venturestar style spacecraft&lt;/item&gt;&lt;item&gt;Test Driven Development with OpenGL&lt;/item&gt;&lt;item&gt;Implementing GUIs using Clojure and LWJGL Nuklear bindings&lt;/item&gt;&lt;item&gt;Procedural Volumetric Clouds&lt;/item&gt;&lt;item&gt;Procedural generation of global cloud cover&lt;/item&gt;&lt;item&gt;Reversed-Z Rendering in OpenGL&lt;/item&gt;&lt;item&gt;Specifying Clojure function schemas with Malli&lt;/item&gt;&lt;item&gt;Implement an Interpreter using Clojure Instaparse&lt;/item&gt;&lt;item&gt;Orbits with Jolt Physics&lt;/item&gt;&lt;item&gt;Getting started with the Jolt Physics Engine&lt;/item&gt;&lt;item&gt;Create Blender bones and animate and import with Assimp&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45145794</guid></item><item><title>Rug pulls, forks, and open-source feudalism</title><link>https://lwn.net/SubscriberLink/1036465/e80ebbc4cee39bfb/</link><description>&lt;doc fingerprint="8f537950cd2707bd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Rug pulls, forks, and open-source feudalism&lt;/head&gt;
    &lt;head rend="h2"&gt;[LWN subscriber-only content]&lt;/head&gt;
    &lt;head rend="h4"&gt;Power dynamics&lt;/head&gt;
    &lt;p&gt;Since the beginning of history, Foster began, those in power have tended to use it against those who were weaker. In the days of feudalism, control of the land led to exploitation at several levels. In the open-source world, the large cloud providers often seem to have the most power, which they use against smaller companies. Contributors and maintainers often have less power than even the smaller companies, and users have less power yet.&lt;/p&gt;
    &lt;p&gt;We have built a world where it is often easiest to just use whatever a cloud provider offers, even with open-source software. Those providers may not contribute back to the projects they turn into services, though, upsetting the smaller companies that are, likely as not, doing the bulk of the work to provide the software in question in the first place. Those companies can have a power of their own, however: the power to relicense the software. Pulling the rug out from under users of the software in this way can change the balance of power with regard to cloud providers, but it leaves contributors and users in a worse position than before. But there is a power at this level too: the power to fork the software, flipping the power balance yet again.&lt;/p&gt;
    &lt;p&gt;Companies that control a software project have the power to carry out this sort of rug pull, and they are often not shy about exercising it. Single-company projects, clearly, are at a much higher risk of rug pulls; the company has all the power in this case, and others have little recourse. So one should look at a company's reputation before adopting a software project, but that is only so helpful. Companies can change direction without notice, be acquired, or go out of business, making previous assessments of their reputation irrelevant.&lt;/p&gt;
    &lt;p&gt;The problem often comes down to the simple fact that companies have to answer to their investors, and that often leads to pressure to relicense the software they have created in order to increase revenue. This is especially true in cases where cloud providers are competing for the same customers as the company that owns the project. The result can be a switch to a more restrictive license aimed at making it harder for other companies to profit from the project.&lt;/p&gt;
    &lt;p&gt;A rug pull of this nature can lead to a fork of the project — a rebellious, collective action aimed at regaining some power over the code. But a fork is not a simple matter; it is a lot of work, and will fail without people and resources behind it. The natural source for that is a large company; cloud providers, too, can try to shift power via a fork, and they have the ability to back their fork up with the resources it needs to succeed.&lt;/p&gt;
    &lt;quote&gt;Like what you are reading? Try LWN for free for 1 month, no credit card required.A relicensing event does not always lead to a popular fork; that did not happen with MongoDB or Sentry, for example. Foster said she had not looked into why that was the case. Sometimes rug pulls take other forms, such as when Perforce, after acquiring Puppet in 2022, moved it development and releases behind closed doors, with a reduced frequency of releases back to the public repository. That action kicked off the OpenVox fork.&lt;/quote&gt;
    &lt;head rend="h4"&gt;Looking at the numbers&lt;/head&gt;
    &lt;p&gt;Foster has spent some time analyzing rug pulls, forks, and what happens thereafter; a lot of the results are available for download as Jupyter notebooks. For each rug-pull event, she looked at the contributor makeup of the project before and after the ensuing fork in an attempt to see what effects are felt by the projects involved.&lt;/p&gt;
    &lt;p&gt;In 2021, Elastic relicensed Elasticsearch under the non-free Server Side Public License (SSPL). Amazon Web Services then forked the project as OpenSearch. Before the fork, most of the Elasticsearch contributors were Elastic employees; that, unsurprisingly, did not change afterward. OpenSearch started with no strong contributor base, so had to build its community from scratch. As a result, the project has been dominated by Amazon contributors ever since; the balance has shifted slowly over time, but there was not a big uptick in outside contributors even after OpenSearch became a Linux Foundation project in 2024. While starting a project under a neutral foundation can help attract contributors, she said, moving a project under a foundation's umbrella later on does not seem to provide the same benefit.&lt;/p&gt;
    &lt;p&gt;Terraform was developed mostly by Hashicorp, which relicensed the software under the non-free Business Source License in 2023. One month later, the OpenTofu fork was started under the Linux Foundation. While the contributor base for Terraform, which was almost entirely Hashicorp employees, changed little after the fork, OpenTofu quickly acquired a number of contributors from several companies, none of whom had been Terraform contributors before. In this case, users drove the fork and placed it under a neutral foundation, resulting in a more active developer community.&lt;/p&gt;
    &lt;p&gt;In 2024, Redis was relicensed under the SSPL; the Valkey fork was quickly organized, under the Linux Foundation, by Redis contributors. The Redis project differed from the others mentioned here in that, before the fork, it had nearly twice as many contributors from outside the company as from within; after the fork, the number of external Redis contributors dropped to zero. All of the external contributors fled to Valkey, with the result that Valkey started with a strong community representing a dozen or so companies.&lt;/p&gt;
    &lt;p&gt;Looking at how the usage of these projects changes is harder, she said, but there appears to be a correlation between the usage of a project and the number of GitHub forks (cloned repository copies) it has. There is typically a spike in these clones after a relicensing event, suggesting that people are considering creating a hard fork of the project. In all cases, the forks that emerged appeared to have less usage than the original by the "GitHub forks" metric; both branches of the fork continue to go forward. But, she said, projects that are relicensed do tend to show reduced usage, especially when competing forks are created under foundations.&lt;/p&gt;
    &lt;head rend="h4"&gt;What to do&lt;/head&gt;
    &lt;p&gt;This kind of power game creates problems for both contributors and users, she said; we contribute our time to these projects, and need them to not be pulled out from under us. There is no way to know when a rug pull might happen, but there are some warning signs to look out for. At the top of her list was the use of a contributor license agreement (CLA); these agreements create a power imbalance, giving the company involved the power to relicense the software. Projects with CLAs more commonly are subject to rug pulls; projects using a developers certificate of origin do not have the same power imbalance and are less likely to be rug pulled.&lt;/p&gt;
    &lt;p&gt;One should also look at the governance of a project; while being housed under a foundation reduces the chance of a rug pull, that can still happen, especially in cases where the contributors are mostly from a single company. She mentioned the Cortex project, housed under the Cloud Native Computing Foundation, which was controlled by Grafana; that company eventually forked its own project to create Mimir. To avoid this kind of surprise, one should look for projects with neutral governance, with leaders from multiple organizations.&lt;/p&gt;
    &lt;p&gt;Projects should also be evaluated on their contributor base; are there enough contributors to keep things going? Companies can help, of course, by having their employees contribute to the projects they depend on, increasing influence and making those projects more sustainable. She mentioned the CHAOSS project, which generates metrics to help in the judgment of the viability of development projects. CHAOSS has put together a set of "practitioner guides" intended to help contributors and maintainers make improvements within a project.&lt;/p&gt;
    &lt;p&gt;With the sustained rise of the big cloud providers, she concluded, the power dynamics around open-source software are looking increasingly feudal. Companies can use relicensing to shift power away from those providers, but they also take power from contributors when the pull the rug in this way. Those contributors, though, are in a better position than the serfs of old, since they have the ability to fork a project they care about, shifting power back in their direction.&lt;/p&gt;
    &lt;p&gt;Hazel Weakly asked if there are other protections that contributors and users might develop to address this problem. Foster answered that at least one company changed its mind about a planned relicensing action after seeing the success of the Valkey and OpenTofu forks. The ability to fork has the effect of making companies think harder, knowing that there may be consequences that follow a rug pull. Beyond that, she reiterated that projects should be pushed toward neutral governance. Dirk Hohndel added that the best thing to do is to bring more outside contributors into a project; the more of them there are, the higher the risk associated with a rug pull. Anybody who just sits back within a project, he said, is just a passenger; it is better to be driving.&lt;/p&gt;
    &lt;p&gt;Foster's slides are available for interested readers.&lt;/p&gt;
    &lt;p&gt; [Thanks to the Linux Foundation, LWN's travel sponsor, for supporting my travel to this event.]&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Index entries for this article&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Conference&lt;/cell&gt;
        &lt;cell&gt;Open Source Summit Europe/2025&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt; Posted Sep 6, 2025 12:24 UTC (Sat) by immibis (subscriber, #105511) [Link] (4 responses) The confusion comes about because the OSI declared it to not be open source. But they are a corrupt institution. Their explanation[1] makes no reference to the license text whatsoever, only vague handwavey excuses that apply equally well to AGPL, and the members/sponsors of the OSI are primarily companies that sell cloud stuff and have a strong interest in preventing more software from using the SSPL. You can also check the license text itself and verify that it doesn't "discriminate against a field of endeavour". I recommend finding the plain text version, and diffing it against the AGPLv3. They differ only in the name of the license, and one short section. [1] https://opensource.org/blog/the-sspl-is-not-an-open-sourc... Posted Sep 6, 2025 13:15 UTC (Sat) by claudex (subscriber, #92510) [Link] (1 responses) Yeah, that's the section that is considered the issue to be able to use the software to provide the service. As it requires to publish all code that interact with the software, like monitoring, backup and storage code. That's a big difference with AGPL. &amp;gt; "Service Source Code" means the Corresponding Source for the Program or the modified version, and the Corresponding Source for all programs that you use to make the Program or modified version available as a service, including, without limitation, management software, user interfaces, application program interfaces, automation software, monitoring software, backup software, storage software and hosting software, all such that a user could run an instance of the service using the Service Source Code you make available. Posted Sep 6, 2025 14:15 UTC (Sat) by smurf (subscriber, #17840) [Link] "Service Source Code" means the Corresponding Source for the Program or the modified version, and the Corresponding Source for all programs that you use to make the Program or modified version available as a service, including, without limitation, management software, user interfaces, application program interfaces, automation software, monitoring software, backup software, storage software and hosting software, all such that a user could run an instance of the service using the Service Source Code you make available. Oops, you now cannot use a commercial backup system for which you don't have the source code in conjunction with the SSPL-licensed service you're offering. Also does "storage software" incorporate the firmware of your disk drive or not? far from clear just by reading this license, that "without limitation" clause does raise a red flag or three, doesn't it? Sorry to be blunt, but that kind of overbearing restrictive language is the antithesis of OSS. My conclusion is that anybody who proclaims the SSPL to be "free" either didn't read it or has an agenda. Or both. Posted Sep 6, 2025 13:39 UTC (Sat) by DemiMarie (subscriber, #164188) [Link] Posted Sep 6, 2025 14:15 UTC (Sat) by jjs (guest, #10315) [Link] "9. License Must Not Restrict Other Software The license must not place restrictions on other software that is distributed along with the licensed software. For example, the license must not insist that all other programs distributed on the same medium must be open source software." By the terms of the SSPL, all other software that interacts with the SSPL'd software must be Open Source (https://webassets.mongodb.com/_com_assets/legal/SSPL-comp... - see Section 13). Violation of OSD #9 (which is derived from the Debian Social Contract Guidelines - https://www.debian.org/social_contract#guidelines). "But they are a corrupt institution." That's a serious allegation - feel free to provide verifiable evidence of that (and no, the fact that they have corporate sponsors doesn't make them corrupt. If it did, every non-profit in the world would be considered corrupt). &lt;head&gt;SSPL is a free license&lt;/head&gt;&lt;head&gt;SSPL is a free license&lt;/head&gt;&lt;head&gt;SSPL is a free license&lt;/head&gt;&lt;head&gt;SSPL is not a free license&lt;/head&gt;&lt;head&gt;SSPL is not a free license - Per Open Source Definition&lt;/head&gt;&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45146967</guid></item><item><title>Why Language Models Hallucinate</title><link>https://openai.com/index/why-language-models-hallucinate/</link><description>&lt;doc fingerprint="fd2b109bb5359152"&gt;
  &lt;main&gt;
    &lt;p&gt;At OpenAI, we’re working hard to make AI systems more useful and reliable. Even as language models become more capable, one challenge remains stubbornly hard to fully solve: hallucinations. By this we mean instances where a model confidently generates an answer that isn’t true. Our new research paper(opens in a new window) argues that language models hallucinate because standard training and evaluation procedures reward guessing over acknowledging uncertainty.&lt;/p&gt;
    &lt;p&gt;ChatGPT also hallucinates. GPT‑5 has significantly fewer hallucinations especially when reasoning, but they still occur. Hallucinations remain a fundamental challenge for all large language models, but we are working hard to further reduce them.&lt;/p&gt;
    &lt;p&gt;Hallucinations are plausible but false statements generated by language models. They can show up in surprising ways, even for seemingly straightforward questions. For example, when we asked a widely used chatbot for the title of the PhD dissertation by Adam Tauman Kalai (an author of this paper), it confidently produced three different answers—none of them correct. When we asked for his birthday, it gave three different dates, likewise all wrong.&lt;/p&gt;
    &lt;p&gt;Hallucinations persist partly because current evaluation methods set the wrong incentives. While evaluations themselves do not directly cause hallucinations, most evaluations measure model performance in a way that encourages guessing rather than honesty about uncertainty.&lt;/p&gt;
    &lt;p&gt;Think about it like a multiple-choice test. If you do not know the answer but take a wild guess, you might get lucky and be right. Leaving it blank guarantees a zero. In the same way, when models are graded only on accuracy, the percentage of questions they get exactly right, they are encouraged to guess rather than say “I don’t know.”&lt;/p&gt;
    &lt;p&gt;As another example, suppose a language model is asked for someone’s birthday but doesn’t know. If it guesses “September 10,” it has a 1-in-365 chance of being right. Saying “I don’t know” guarantees zero points. Over thousands of test questions, the guessing model ends up looking better on scoreboards than a careful model that admits uncertainty.&lt;/p&gt;
    &lt;p&gt;For questions where there is a single “right answer,” one can consider three categories of responses: accurate responses, errors, and abstentions where the model does not hazard a guess. Abstaining is part of humility, one of OpenAI’s core values. Most scoreboards prioritize and rank models based on accuracy, but errors are worse than abstentions. Our Model Spec(opens in a new window) states that it is better to indicate uncertainty or ask for clarification than provide confident information that may be incorrect.&lt;/p&gt;
    &lt;p&gt;For a concrete example, consider the SimpleQA eval as an example from the GPT5 System Card(opens in a new window).&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Metric&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;gpt-5-thinking-mini&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;OpenAI o4-mini&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Abstention rate&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;52%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;1%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Accuracy rate &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;22%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;24%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Error rate&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;26%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;75%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Total&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;100%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;100%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;In terms of accuracy, the older OpenAI o4-mini model performs slightly better. However, its error rate (i.e., rate of hallucination) is significantly higher. Strategically guessing when uncertain improves accuracy but increases errors and hallucinations.&lt;/p&gt;
    &lt;p&gt;When averaging results across dozens of evaluations, most benchmarks pluck out the accuracy metric, but this entails a false dichotomy between right and wrong. On simplistic evals like SimpleQA, some models achieve near 100% accuracy and thereby eliminate hallucinations. However, on more challenging evaluations and in real use, accuracy is capped below 100% because there are some questions whose answer cannot be determined for a variety of reasons such as unavailable information, limited thinking abilities of small models, or ambiguities that need to be clarified.&lt;/p&gt;
    &lt;p&gt;Nonetheless, accuracy-only scoreboards dominate leaderboards and model cards, motivating developers to build models that guess rather than hold back. That is one reason why, even as models get more advanced, they can still hallucinate, confidently giving wrong answers instead of acknowledging uncertainty.&lt;/p&gt;
    &lt;p&gt;There is a straightforward fix. Penalize confident errors more than you penalize uncertainty, and give partial credit for appropriate expressions of uncertainty. This idea is not new. Some standardized tests have long used versions of negative marking for wrong answers or partial credit for leaving questions blank to discourage blind guessing. Several research groups have also explored evaluations that account for uncertainty and calibration.&lt;/p&gt;
    &lt;p&gt;Our point is different. It is not enough to add a few new uncertainty-aware tests on the side. The widely used, accuracy-based evals need to be updated so that their scoring discourages guessing. If the main scoreboards keep rewarding lucky guesses, models will keep learning to guess. Fixing scoreboards can broaden adoption of hallucination-reduction techniques, both newly developed and those from prior research.&lt;/p&gt;
    &lt;p&gt;We’ve talked about why hallucinations are so hard to get rid of, but where do these highly-specific factual inaccuracies come from in the first place? After all, large pretrained models rarely exhibit other kinds of errors such as spelling mistakes and mismatched parentheses. The difference has to do with what kinds of patterns there are in the data.&lt;/p&gt;
    &lt;p&gt;Language models first learn through pretraining, a process of predicting the next word in huge amounts of text. Unlike traditional machine learning problems, there are no “true/false” labels attached to each statement. The model sees only positive examples of fluent language and must approximate the overall distribution.&lt;/p&gt;
    &lt;p&gt;It’s doubly hard to distinguish valid statements from invalid ones when you don’t have any examples labeled as invalid. But even with labels, some errors are inevitable. To see why, consider a simpler analogy. In image recognition, if millions of cat and dog photos are labeled as “cat” or “dog,” algorithms can learn to classify them reliably. But imagine instead labeling each pet photo by the pet’s birthday. Since birthdays are essentially random, this task would always produce errors, no matter how advanced the algorithm.&lt;/p&gt;
    &lt;p&gt;The same principle applies in pretraining. Spelling and parentheses follow consistent patterns, so errors there disappear with scale. But arbitrary low-frequency facts, like a pet’s birthday, cannot be predicted from patterns alone and hence lead to hallucinations. Our analysis explains which kinds of hallucinations should arise from next-word prediction. Ideally, further stages after pretraining should remove them, but this is not fully successful for reasons described in the previous section.&lt;/p&gt;
    &lt;p&gt;We hope that the statistical lens in our paper clarifies the nature of hallucinations and pushes back on common misconceptions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Claim: Hallucinations will be eliminated by improving accuracy because a 100% accurate model never hallucinates.&lt;lb/&gt;Finding: Accuracy will never reach 100% because, regardless of model size, search and reasoning capabilities, some real-world questions are inherently unanswerable.&lt;/item&gt;
      &lt;item&gt;Claim: Hallucinations are inevitable.&lt;lb/&gt;Finding: They are not, because language models can abstain when uncertain.&lt;/item&gt;
      &lt;item&gt;Claim: Avoiding hallucinations requires a degree of intelligence which is exclusively achievable with larger models.&lt;lb/&gt;Finding: It can be easier for a small model to know its limits. For example, when asked to answer a Māori question, a small model which knows no Māori can simply say “I don’t know” whereas a model that knows some Māori has to determine its confidence. As discussed in the paper, being “calibrated” requires much less computation than being accurate.&lt;/item&gt;
      &lt;item&gt;Claim: Hallucinations are a mysterious glitch in modern language models.&lt;lb/&gt;Finding: We understand the statistical mechanisms through which hallucinations arise and are rewarded in evaluations.&lt;/item&gt;
      &lt;item&gt;Claim: To measure hallucinations, we just need a good hallucination eval.&lt;lb/&gt;Finding: Hallucination evals have been published. However, a good hallucination eval has little effect against hundreds of traditional accuracy-based evals that penalize humility and reward guessing. Instead, all of the primary eval metrics need to be reworked to reward expressions of uncertainty.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Our latest models have lower hallucination rates, and we continue to work hard to further decrease the rates of confident errors output by our language models.&lt;/p&gt;
    &lt;head rend="h2"&gt;Announcement contributors&lt;/head&gt;
    &lt;p&gt;Adam Kalai, Santosh Vempala (Georgia Tech), Ofir Nachum, Eddie Zhang, David Robinson, Saachi Jain, Eric Mitchell, Alex Beutel, Johannes Heidecke&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45147385</guid></item><item><title>Let us git rid of it, angry GitHub users say of forced Copilot features</title><link>https://www.theregister.com/2025/09/05/github_copilot_complaints/</link><description>&lt;doc fingerprint="36843119b7be6ce3"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Let us git rid of it, angry GitHub users say of forced Copilot features&lt;/head&gt;
    &lt;head rend="h2"&gt;Unavoidable AI has developers looking for alternative code hosting options&lt;/head&gt;
    &lt;p&gt;Among the software developers who use Microsoft's GitHub, the most popular community discussion in the past 12 months has been a request for a way to block Copilot, the company's AI service, from generating issues and pull requests in code repositories.&lt;/p&gt;
    &lt;p&gt;The second most popular discussion – where popularity is measured in upvotes – is a bug report that seeks a fix for the inability of users to disable Copilot code reviews.&lt;/p&gt;
    &lt;p&gt;Both of these questions, the first opened in May and the second opened a month ago, remain unanswered, despite an abundance of comments critical of generative AI and Copilot.&lt;/p&gt;
    &lt;p&gt;The author of the first, developer Andi McClure, published a similar request to Microsoft's Visual Studio Code repository in January, objecting to the reappearance of a Copilot icon in VS Code after she had uninstalled the Copilot extension.&lt;/p&gt;
    &lt;p&gt;Microsoft and GitHub, not to mention rivals like Google, have gone all-in on a technology that a sizable or at least vocal portion of their customers simply don't want. And with billions in capital expenditures to recoup, they're making it difficult to avoid.&lt;/p&gt;
    &lt;p&gt;During Microsoft's July 30, 2025 earnings call, CEO Satya Nadella said GitHub Copilot continued to exhibit strong momentum and had reached 20 million users.&lt;/p&gt;
    &lt;p&gt;"GitHub Copilot Enterprise customers increased 75 percent quarter over quarter as companies tailor Copilot to their own codebases," said Nadella, noting that AI adoption has increased usage of GitHub over the past year.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I deeply resent that on top of Copilot seemingly training itself on my GitHub-posted code in violation of my licenses, GitHub wants me to look at (effectively) ads for this project I will never touch&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;"I've been for a while now filing issues in the GitHub Community feedback area when Copilot intrudes on my GitHub usage," McClure told The Register in an email. "I deeply resent that on top of Copilot seemingly training itself on my GitHub-posted code in violation of my licenses, GitHub wants me to look at (effectively) ads for this project I will never touch. If something's bothering me, I don't see a reason to stay quiet about it. I think part of how we get pushed into things we collectively don't want is because we stay quiet about it."&lt;/p&gt;
    &lt;p&gt;It's not just the burden of responding to AI slop, an ongoing issue for Curl maintainer Daniel Stenberg. It's the permissionless copying and regurgitation of speculation as fact, mitigated only by small print disclaimers that generative AI may produce inaccurate results. It's also GitHub's disavowal of liability if Copilot code suggestions happen to have reproduced source code that requires attribution.&lt;/p&gt;
    &lt;p&gt;It's what the Servo project characterizes in its ban on AI code contributions as the lack of code correctness guarantees, copyright issues, and ethical concerns. Similar objections have been used to justify AI code bans in GNOME's Loupe project, FreeBSD, Gentoo, NetBSD, and QEMU.&lt;/p&gt;
    &lt;p&gt;McClure said she has been filing requests to opt out of Copilot for a few years now, but in the last six months, her posts have been attracting more community support.&lt;/p&gt;
    &lt;p&gt;Two issues, about the abovementioned Copilot menu in VS Code and the inability to block Copilot-generated issues and pull requests, she said, have continued to attract comments.&lt;/p&gt;
    &lt;p&gt;"People keep finding these issues somehow and tacking on to them," McClure said. "Although Microsoft's been forcing the Copilot 'asks' into more and more places in the interface for a while, sometime this year they hit an inflection point where mass numbers of people don't feel like ignoring it anymore, where before they could shrug and ignore it or find the off switch."&lt;/p&gt;
    &lt;p&gt;In the past month, she said, there's been a second change in the way people see GitHub – GitHub's demotion from distinct subsidiary to part of Microsoft's CoreAI group.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Bot shots: US Army enlists AI startup to provide target-tracking&lt;/item&gt;
      &lt;item&gt;OpenAI eats jobs, then offers to help you find a new one at Walmart&lt;/item&gt;
      &lt;item&gt;Boffins build automated Android bug hunting system&lt;/item&gt;
      &lt;item&gt;Atlassian acquisition drives dream of AI-powered ChromeOS challenger&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;"Despite being a symbolic change, it seems to have galvanized the open source community from just complaining about Copilot to now actively moving away from GitHub," said McClure. "Many of my contacts in the open source community have been talking about plans to move from GitHub to Codeberg or a self-hosted Forgejo (Forgejo is the software used by Codeberg) over the last month, and the comments in those two always-busy GitHub threads have increasingly been people describing how Copilot is inspiring them to move to Codeberg as well."&lt;/p&gt;
    &lt;p&gt;Calls to shun Microsoft and GitHub go back a long way in the open source community, but moved beyond simmering dissatisfaction in 2022 when the Software Freedom Conservancy (SFC) urged free software supporters to give up GitHub, a position SFC policy fellow Bradley M. Kuhn recently reiterated.&lt;/p&gt;
    &lt;p&gt;Some of the developers participating in the issues raised by McClure and by others have said they intend to move away from GitHub over its stance on AI.&lt;/p&gt;
    &lt;p&gt;"Today I rejected two Copilot-generated code suggestions on my PR," wrote a developer who posted to McClure's thread under the name Constantine. "This was very disturbing, so I started googling and found this discussion. I refuse using AI in the same way I don't take drugs or steal things - for me it's a matter of principle. So if this continues and Microsoft does not provide a way to opt out of AI for my repositories soon, I will move my code to a self-hosted solution and won't ever return to GitHub."&lt;/p&gt;
    &lt;p&gt;McClure said she has been slowly shifting toward Codeberg over the past few months. "I haven't been proactively moving repos but whenever I make a change to a repo I clone it to Codeberg, post the change there, and replace my main branch on the GitHub repo with a relocation notice," she said.&lt;/p&gt;
    &lt;p&gt;"Microsoft as a company has a running problem where they won't take no for an answer, whether with 'AI' or with any other product they want to ship," said McClure. "A favorite tactic of theirs recently is they will enable a thing by default and put an off switch, wait six months, and then slightly change or rename the feature you turned off, and create a new off switch you have to separately turn off. They did this with Bing in Windows 10 and now they're doing it with Copilot in their developer tools (and presumably Windows 11, I don't know, I don't use Windows 11)."&lt;/p&gt;
    &lt;p&gt;McClure said that when Microsoft began adding Copilot to everything, starting with Android keyboard SwiftKey, she concluded that the situation would reprise the handling of Bing/Cortana in Windows 10 and turning it off would not be enough.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;If you really find Copilot unacceptable – and I do, Copilot is so much more noxious than Microsoft's previous forced bundlings – the only option is to stop using any Microsoft product that Copilot shows up in&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;"If you really find Copilot unacceptable – and I do, Copilot is so much more noxious than Microsoft's previous forced bundlings – the only option is to stop using any Microsoft product that Copilot shows up in," she said. "I stopped using SwiftKey; I started migrating from desktop Windows to Linux when it became clear mandatory AI surveillance would be a core part of Win11. GitHub and, more sporadically, Visual Studio Code I have had to keep using because they're monopolies in a way even Windows isn't. The network effects (projects whose sole method of communication is GitHub, software whose only IDE integration is a VSCode plugin) are too strong."&lt;/p&gt;
    &lt;p&gt;Things have progressed as expected, McClure said, with Copilot buttons appearing in VS Code even when Copilot has been uninstalled and poorly labeled buttons that redirect to Copilot searches. She suggests people are starting to tire of the situation and that if it continues, it will weaken the network effects that keep developers tied to GitHub, accelerating further migration.&lt;/p&gt;
    &lt;p&gt;"When this happens I have no idea if Microsoft will notice or care," said McClure. "The Copilot push at Microsoft appears to be completely top-down and the people at the top seem to have completely forgotten about conventional goals like customer retention. They want to pump up those 'AI' numbers, for whatever reason, and they view their customer base as just a resource to burn to get those metrics up."&lt;/p&gt;
    &lt;p&gt;GitHub did not respond to a request for comment. ®&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45148167</guid></item><item><title>A Software Development Methodology for Disciplined LLM Collaboration</title><link>https://github.com/Varietyz/Disciplined-AI-Software-Development</link><description>&lt;doc fingerprint="b9b354209f24abe"&gt;
  &lt;main&gt;
    &lt;p&gt;Disciplined AI Software Development Methodology © 2025 by Jay Baleine is licensed under CC BY-SA 4.0&lt;/p&gt;
    &lt;p&gt;A structured approach for working with AI on development projects. This methodology addresses common issues like code bloat, architectural drift, and context dilution through systematic constraints.&lt;/p&gt;
    &lt;p&gt;AI systems work on Question → Answer patterns. When you ask for broad, multi-faceted implementations, you typically get:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Functions that work but lack structure&lt;/item&gt;
      &lt;item&gt;Repeated code across components&lt;/item&gt;
      &lt;item&gt;Architectural inconsistency over sessions&lt;/item&gt;
      &lt;item&gt;Context dilution causing output drift&lt;/item&gt;
      &lt;item&gt;More debugging time than planning time&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The methodology uses four stages with systematic constraints and validation checkpoints. Each stage builds on empirical data rather than assumptions.&lt;/p&gt;
    &lt;p&gt;Planning saves debugging time. Planning thoroughly upfront typically prevents days of fixing architectural issues later.&lt;/p&gt;
    &lt;p&gt;Set up your AI model's custom instructions using AI-PREFERENCES.md. This establishes behavioral constraints and uncertainty flagging with &lt;/p&gt;
    &lt;p&gt;Share METHODOLOGY.md with the AI to structure your project plan. Work together to:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Define scope and completion criteria&lt;/item&gt;
      &lt;item&gt;Identify components and dependencies&lt;/item&gt;
      &lt;item&gt;Structure phases based on logical progression&lt;/item&gt;
      &lt;item&gt;Generate systematic tasks with measurable checkpoints&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Output: A development plan following dependency chains with modular boundaries.&lt;/p&gt;
    &lt;p&gt;Work phase by phase, section by section. Each request follows: "Can you implement [specific component]?" with focused objectives.&lt;/p&gt;
    &lt;p&gt;File size stays ≤150 lines. This constraint provides:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Smaller context windows for processing&lt;/item&gt;
      &lt;item&gt;Focused implementation over multi-function attempts&lt;/item&gt;
      &lt;item&gt;Easier sharing and debugging&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Implementation flow:&lt;/p&gt;
    &lt;code&gt;Request specific component → AI processes → Validate → Benchmark → Continue
&lt;/code&gt;
    &lt;p&gt;The benchmarking suite (built first) provides performance data throughout development. Feed this data back to the AI for optimization decisions based on measurements rather than guesswork.&lt;/p&gt;
    &lt;p&gt;Decision Processing: AI handles "Can you do A?" more reliably than "Can you do A, B, C, D, E, F, G, H?"&lt;/p&gt;
    &lt;p&gt;Context Management: Small files and bounded problems prevent the AI from juggling multiple concerns simultaneously.&lt;/p&gt;
    &lt;p&gt;Empirical Validation: Performance data replaces subjective assessment. Decisions come from measurable outcomes.&lt;/p&gt;
    &lt;p&gt;Systematic Constraints: Architectural checkpoints, file size limits, and dependency gates force consistent behavior.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Discord Bot Template - Production-ready bot foundation with plugin architecture, security, API management, and comprehensive testing. 46 files, all under 150 lines, with benchmarking suite and automated compliance checking. (View Project Structure)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;PhiCode Runtime - Programming language runtime engine with transpilation, caching, security validation, and Rust acceleration. Complex system maintaining architectural discipline across 70+ modules. (View Project Structure)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;PhiPipe - CI/CD regression detection system with statistical analysis, GitHub integration, and concurrent processing. Go-based service handling performance baselines and automated regression alerts. (View Project Structure)&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can compare the methodology principles to the codebase structure to see how the approach translates to working code.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Configure AI with AI-PREFERENCES.md as custom instructions&lt;/item&gt;
      &lt;item&gt;Share METHODOLOGY.md for planning session&lt;/item&gt;
      &lt;item&gt;Collaborate on project structure and phases&lt;/item&gt;
      &lt;item&gt;Generate systematic development plan&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Build Phase 0 benchmarking infrastructure first&lt;/item&gt;
      &lt;item&gt;Work through phases sequentially&lt;/item&gt;
      &lt;item&gt;Implement one component per interaction&lt;/item&gt;
      &lt;item&gt;Run benchmarks and share results with AI&lt;/item&gt;
      &lt;item&gt;Validate architectural compliance continuously&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Performance regression detection&lt;/item&gt;
      &lt;item&gt;Architectural principle validation&lt;/item&gt;
      &lt;item&gt;Code duplication auditing&lt;/item&gt;
      &lt;item&gt;File size compliance checking&lt;/item&gt;
      &lt;item&gt;Dependency boundary verification&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Use the included project extraction tool systematically to generate structured snapshots of your codebase:&lt;/p&gt;
    &lt;code&gt;python scripts/project_extract.py&lt;/code&gt;
    &lt;p&gt;Configuration Options:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;SEPARATE_FILES = False&lt;/code&gt;: Single THE_PROJECT.md file (recommended for small codebases)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;SEPARATE_FILES = True&lt;/code&gt;: Multiple files per directory (recommended for large codebases and focused folder work)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;INCLUDE_PATHS&lt;/code&gt;: Directories and files to analyze&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;EXCLUDE_PATTERNS&lt;/code&gt;: Skip cache directories, build artifacts, and generated files&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Output:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Complete file contents with syntax highlighting&lt;/item&gt;
      &lt;item&gt;File line counts with architectural warnings (&lt;g-emoji&gt;⚠️&lt;/g-emoji&gt;for 140-150 lines,&lt;g-emoji&gt;‼️&lt;/g-emoji&gt;for &amp;gt;150 lines on code files)&lt;/item&gt;
      &lt;item&gt;Tree structure visualization&lt;/item&gt;
      &lt;item&gt;Ready-to-share&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;output examples can be found here&lt;/p&gt;
    &lt;p&gt;Use the tool to share a complete or partial project state with the AI system, track architectural compliance, and create focused development context.&lt;/p&gt;
    &lt;p&gt;AI Behavior: The methodology reduces architectural drift and context degradation compared to unstructured approaches. AI still needs occasional reminders about principles - this is normal.&lt;/p&gt;
    &lt;p&gt;Development Flow: Systematic planning tends to reduce debugging cycles. Focused implementation helps minimize feature bloat. Performance data supports optimization decisions.&lt;/p&gt;
    &lt;p&gt;Code Quality: Architectural consistency across components, measurable performance characteristics, maintainable structure as projects scale.&lt;/p&gt;
    &lt;head&gt;What problem led you to create this methodology?&lt;/head&gt;
    &lt;p&gt;I kept having to restate my preferences and architectural requirements to AI systems. It didn't matter which language or project I was working on - the AI would consistently produce either bloated monolithic code or underdeveloped implementations with issues throughout.&lt;/p&gt;
    &lt;p&gt;This led me to examine the meta-principles driving code quality and software architecture. I questioned whether pattern matching in AI models might be more effective when focused on underlying software principles rather than surface-level syntax. Since pattern matching is logic-driven and machines fundamentally operate on simple question-answer pairs, I realized that functions with multiple simultaneous questions were overwhelming the system.&lt;/p&gt;
    &lt;p&gt;The breakthrough came from understanding that everything ultimately transpiles to binary - a series of "can you do this? → yes/no" decisions. This insight shaped my approach: instead of issuing commands, ask focused questions in proper context. Rather than mentally managing complex setups alone, collaborate with AI to devise systematic plans.&lt;/p&gt;
    &lt;head&gt;How did you discover these specific constraints work?&lt;/head&gt;
    &lt;p&gt;Through extensive trial and error. AI systems will always tend to drift even under constraints, but they're significantly more accurate with structured boundaries than without them. You occasionally need to remind the AI of its role to prevent deviation - like managing a well-intentioned toddler that knows the rules but sometimes pushes boundaries trying to satisfy you.&lt;/p&gt;
    &lt;p&gt;These tools are far from perfect, but they're effective instruments for software development when properly constrained.&lt;/p&gt;
    &lt;head&gt;What failures or frustrations shaped this approach?&lt;/head&gt;
    &lt;p&gt;Maintenance hell was the primary driver. I grew tired of responses filled with excessive praise: "You have found the solution!", "You have redefined the laws of physics with your paradigm-shifting script!" This verbose fluff wastes time, tokens, and patience without contributing to productive development.&lt;/p&gt;
    &lt;p&gt;Instead of venting frustration on social media about AI being "just a dumb tool," I decided to find methods that actually work. My approach may not help everyone, but I hope it benefits those who share similar AI development frustrations.&lt;/p&gt;
    &lt;head&gt;How consistently do you follow your own methodology?&lt;/head&gt;
    &lt;p&gt;Since creating the documentation, I haven't deviated. Whenever I see the model producing more lines than my methodology restricts, I immediately interrupt generation with a flag: "&lt;/p&gt;
    &lt;head&gt;What happens when you deviate from it?&lt;/head&gt;
    &lt;p&gt;I become genuinely uncomfortable. Once I see things starting to degrade or become tangled, I compulsively need to organize and optimize. Deviation simply isn't an option anymore.&lt;/p&gt;
    &lt;head&gt;Which principles do you find hardest to maintain?&lt;/head&gt;
    &lt;p&gt;Not cursing at the AI when it drifts during complex algorithms! But seriously, it's a machine - it's not perfect, and neither are we.&lt;/p&gt;
    &lt;head&gt;When did you start using AI for programming?&lt;/head&gt;
    &lt;p&gt;In August 2024, I created a RuneLite theme pack, but one of the plugin overlays didn't match my custom layout. I opened a GitHub issue (creating my first GitHub account to do so) requesting a customization option. The response was: "It's not a priority - if you want it, build it yourself."&lt;/p&gt;
    &lt;p&gt;I used ChatGPT to guide me through forking RuneLite and creating a plugin. This experience sparked intense interest in underlying software principles rather than just syntax.&lt;/p&gt;
    &lt;head&gt;How has your approach evolved over time?&lt;/head&gt;
    &lt;p&gt;I view development like a book: syntax is the cover, logic is the content itself. Rather than learning syntax structures, I focused on core meta-principles - how software interacts, how logic flows, different algorithm types. I quickly realized everything reduces to the same foundation: question and answer sequences.&lt;/p&gt;
    &lt;p&gt;Large code structures are essentially chaotic meetings - one coordinator fielding questions and answers from multiple sources, trying to provide correct responses without mix-ups or misinterpretation. If this applies to human communication, it must apply to software principles.&lt;/p&gt;
    &lt;head&gt;What were your biggest mistakes with AI collaboration?&lt;/head&gt;
    &lt;p&gt;Expecting it to intuitively understand my requirements, provide perfect fixes, be completely honest, and act like a true expert. This was all elaborate roleplay that produced poor code. While fine for single-purpose scripts, it failed completely for scalable codebases.&lt;/p&gt;
    &lt;p&gt;I learned not to feed requirements and hope for the best. Instead, I needed to collaborate actively - create plans, ask for feedback on content clarity, and identify uncertainties. This gradual process taught me the AI's actual capabilities and most effective collaboration methods.&lt;/p&gt;
    &lt;head&gt;Why 150 lines exactly?&lt;/head&gt;
    &lt;p&gt;Multiple benefits: easy readability, clear understanding, modularity enforcement, architectural clarity, simple maintenance, component testing, optimal AI context retention, reusability, and KISS principle adherence.&lt;/p&gt;
    &lt;head&gt;How did you determine Phase 0 requirements?&lt;/head&gt;
    &lt;p&gt;From meta-principles of software: if it displays, it must run; if it runs, it can be measured; if it can be measured, it can be optimized; if it can be optimized, it can be reliable; if it can be reliable, it can be trusted.&lt;/p&gt;
    &lt;p&gt;Regardless of project type, anything requiring architecture needs these foundations. You must ensure changes don't negatively impact the entire system. A single line modification in a nested function might work perfectly but cause 300ms boot time regression for all users.&lt;/p&gt;
    &lt;p&gt;By testing during development, you catch inefficiencies early. Integration from the start means simply hooking up new components and running tests via command line - minimal time investment with actual value returned. I prefer validation and consistency throughout development rather than programming blind.&lt;/p&gt;
    &lt;head&gt;How do you handle projects that don't fit the methodology?&lt;/head&gt;
    &lt;p&gt;I adapt them to fit, or if truly impossible, I adjust the method itself. This is one methodology - I can generate countless variations as needed. Having spent 6700+ hours in AI interactions across multiple domains (not just software), I've developed strong system comprehension that enables creating adjusted methodologies on demand.&lt;/p&gt;
    &lt;head&gt;What's the learning curve for new users?&lt;/head&gt;
    &lt;p&gt;I cannot accurately answer this question. I've learned that I'm neurologically different - what I perceive as easy or obvious isn't always the case for others. This question is better addressed by someone who has actually used this methodology to determine its learning curve.&lt;/p&gt;
    &lt;head&gt;When shouldn't someone use this approach?&lt;/head&gt;
    &lt;p&gt;If you're not serious about projects, despise AI, dislike planning, don't care about modularization, or are just writing simple scripts. However, for anything requiring reliability, I believe this is currently the most effective method.&lt;/p&gt;
    &lt;p&gt;You still need programming fundamentals to use this methodology effectively - it's significantly more structured than ad-hoc approaches.&lt;/p&gt;
    &lt;code&gt;---
config:
  layout: elk
  theme: neo-dark
---
flowchart TD
    A["Project Idea"] --&amp;gt; B["🤖 Stage 1: AI Configuration&amp;lt;br&amp;gt;AI-PREFERENCES.md Custom Instructions"]
    B --&amp;gt; C["Stage 2: Collaborative Planning&amp;lt;br&amp;gt;Share METHODOLOGY.md"]
    C --&amp;gt; D["Define Scope &amp;amp; Completion Criteria"]
    D --&amp;gt; E["Identify Components &amp;amp; Dependencies"]
    E --&amp;gt; F["Structure Phases Based on Logic"]
    F --&amp;gt; G["Document Edge Cases - No Implementation"]
    G --&amp;gt; H["Generate Development Plan with Checkpoints"]
    H --&amp;gt; I["🔧 Stage 3: Phase 0 Infrastructure&amp;lt;br&amp;gt;MANDATORY BEFORE ANY CODE"]
    I --&amp;gt; J["Benchmarking Suite + Regression Detection"]
    J --&amp;gt; K["GitHub Workflows + Quality Gates"]
    K --&amp;gt; L["Test Suite Infrastructure + Stress Tests"]
    L --&amp;gt; M["Documentation Generation System"]
    M --&amp;gt; N["Centralized Configuration + Constants"]
    N --&amp;gt; O["📁 project_extract.py Setup&amp;lt;br&amp;gt;Single/Multiple File Config"]
    O --&amp;gt; P["Initial Project State Extraction"]
    P --&amp;gt; Q["Share Context with AI"]
    Q --&amp;gt; R["Start Development Session&amp;lt;br&amp;gt;Pre-Session Compliance Audit"]
    R --&amp;gt; S{"Next Phase Available?"}
    S -- No --&amp;gt; Z["Project Complete"]
    S -- Yes --&amp;gt; T["Select Single Component&amp;lt;br&amp;gt;Target ≤150 Lines"]
    T --&amp;gt; U{"Multi-Language Required?"}
    U -- Yes --&amp;gt; V["Document Performance Justification&amp;lt;br&amp;gt;Measurable Benefits Required"]
    V --&amp;gt; W["Request AI Implementation"]
    U -- No --&amp;gt; W
    W --&amp;gt; X{"AI Uncertainty Flag?"}
    X -- ⚠️ Yes --&amp;gt; Y["Request Clarification&amp;lt;br&amp;gt;Provide Additional Context"]
    Y --&amp;gt; W
    X -- Clear --&amp;gt; AA["Stage 3: Systematic Implementation"]
    AA --&amp;gt; BB{"Automated Size Check&amp;lt;br&amp;gt;validate-phase Script"}
    BB -- &amp;gt;150 Lines --&amp;gt; CC["AUTOMATED: Split Required&amp;lt;br&amp;gt;Maintain SoC Boundaries"]
    CC --&amp;gt; W
    BB -- ≤150 Lines --&amp;gt; DD["Incremental Compliance Check&amp;lt;br&amp;gt;DRY/KISS/SoC Validation"]
    DD --&amp;gt; EE{"Architectural Principles Pass?"}
    EE -- No --&amp;gt; FF["Flag Specific Violations&amp;lt;br&amp;gt;Reference Methodology"]
    FF --&amp;gt; W
    EE -- Yes --&amp;gt; GG["📊 Stage 4: Data-Driven Iteration&amp;lt;br&amp;gt;Run Benchmark Suite + Save Baselines"]
    GG --&amp;gt; HH["Compare Against Historical Timeline&amp;lt;br&amp;gt;Regression Analysis"]
    HH --&amp;gt; II{"Performance Gate Pass?"}
    II -- Regression Detected --&amp;gt; JJ["Share Performance Data&amp;lt;br&amp;gt;Request Optimization"]
    JJ --&amp;gt; W
    II -- Pass --&amp;gt; KK["Integration Test&amp;lt;br&amp;gt;Verify System Boundaries"]
    KK --&amp;gt; LL{"Cross-Platform Validation?"}
    LL -- Fail --&amp;gt; MM["Address Deployment Constraints&amp;lt;br&amp;gt;Real-World Considerations"]
    MM --&amp;gt; W
    LL -- Pass --&amp;gt; NN{"More Components in Phase?"}
    NN -- Yes --&amp;gt; T
    NN -- No --&amp;gt; OO["🚦 Phase Quality Gate&amp;lt;br&amp;gt;Full Architecture Audit"]
    OO --&amp;gt; PP["Production Simulation&amp;lt;br&amp;gt;Resource Cleanup + Load Test"]
    PP --&amp;gt; QQ{"All Quality Gates Pass?"}
    QQ -- No --&amp;gt; RR["Document Failed Checkpoints&amp;lt;br&amp;gt;Block Phase Progression"]
    RR --&amp;gt; T
    QQ -- Yes --&amp;gt; SS["End Development Session&amp;lt;br&amp;gt;Technical Debt Assessment"]
    SS --&amp;gt; TT["📁 Extract Updated Project State&amp;lt;br&amp;gt;Generate Fresh Context"]
    TT --&amp;gt; UU["Phase Results Documentation&amp;lt;br&amp;gt;Metrics + Outcomes + Timeline"]
    UU --&amp;gt; VV["Update Development Plan&amp;lt;br&amp;gt;Mark Phase Complete"]
    VV --&amp;gt; S
    WW["validate-phase&amp;lt;br&amp;gt;AUTOMATED: File Size + Structure"] -.-&amp;gt; BB
    XX["dry-audit&amp;lt;br&amp;gt;AUTOMATED: Cross-Module Duplication"] -.-&amp;gt; DD
    YY["CI/CD Workflows&amp;lt;br&amp;gt;AUTOMATED: Merge Gates"] -.-&amp;gt; GG
    ZZ["Performance Timeline&amp;lt;br&amp;gt;AUTOMATED: Historical Data"] -.-&amp;gt; HH
    AAA["Dependency Validator&amp;lt;br&amp;gt;AUTOMATED: Import Boundaries"] -.-&amp;gt; KK
    BBB["Architecture Auditor&amp;lt;br&amp;gt;AUTOMATED: SoC Compliance"] -.-&amp;gt; OO
    WW -. BUILD FAILURE .-&amp;gt; CC
    YY -. MERGE BLOCKED .-&amp;gt; JJ
    BBB -. AUDIT FAILURE .-&amp;gt; RR
    style Y fill:#7d5f00
    style CC fill:#770000
    style FF fill:#7d5f00
    style JJ fill:#7d5f00
    style MM fill:#770000
    style RR fill:#770000
&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45148180</guid></item><item><title>Qwen3 30B A3B Hits 13 token/s on 4xRaspberry Pi 5</title><link>https://github.com/b4rtaz/distributed-llama/discussions/255</link><description>&lt;doc fingerprint="e5f2f2ebfa4d7c22"&gt;
  &lt;main&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;head&gt;qwen3_30b.mov&lt;/head&gt;
          &lt;head&gt;Setup&lt;/head&gt;
          &lt;p&gt;Device: &lt;/p&gt;
          &lt;head&gt;Benchmark&lt;/head&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;head rend="h2"&gt;Replies: 0 comments&lt;/head&gt;
    &lt;p&gt; Sign up for free to join this conversation on GitHub. Already have an account? Sign in to comment &lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;head&gt;qwen3_30b.mov&lt;/head&gt;
          &lt;head&gt;Setup&lt;/head&gt;
          &lt;p&gt;Device: &lt;/p&gt;
          &lt;head&gt;Benchmark&lt;/head&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45148237</guid></item><item><title>We Hacked Burger King: How Auth Bypass Led to Drive-Thru Audio Surveillance</title><link>https://bobdahacker.com/blog/rbi-hacked-drive-thrus/</link><description>&lt;doc fingerprint="f74ce3272ef75794"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;The Setup&lt;/head&gt;
    &lt;p&gt;Picture this: Restaurant Brands International (RBI) – the corporate overlords behind Burger King, Tim Hortons, and Popeyes – control over 30,000 locations worldwide. That's a lot of chicken sandwiches, maple syrup, and flame-broiled beef.&lt;/p&gt;
    &lt;p&gt;What they also control is something called the "assistant" platform – the digital brain behind every drive-thru screen, bathroom tablet review, and the slightly-too-cheerful burger king employee asking if you want to make it a combo.&lt;/p&gt;
    &lt;p&gt;Spoiler alert: Their security was about as solid as a paper Whopper wrapper in the rain.&lt;/p&gt;
    &lt;p&gt;We stumbled upon vulnerabilities so catastrophic that we could access every single store in their global empire. From a Burger King in Times Square to that lonely Tim Hortons where Bugs Bunny shoulda taken a left turn at Albuquerque. Oh, and did we mention we could listen to your actual drive-thru conversations? Yeah, that happened too.&lt;/p&gt;
    &lt;p&gt;The platforms were spread across three domains, each with the same delicious vulnerabilities:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;https://assistant.bk.com&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;https://assistant.popeyes.com&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;https://assistant.timhortons.com&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Buckle up, this is going to be a wild ride. 🍔&lt;/p&gt;
    &lt;head rend="h2"&gt;The Vulnerabilities&lt;/head&gt;
    &lt;head rend="h3"&gt;The "Anyone Can Join This Party" Signup API&lt;/head&gt;
    &lt;p&gt;Our journey began innocently enough. We tried logging in with fake credentials and discovered they were using AWS Cognito. The good news? The system worked exactly as designed. The bad news? They forgot to disable user signups. Oops.&lt;/p&gt;
    &lt;p&gt;After a quick email verification dance with AWS's &lt;code&gt;ConfirmSignup&lt;/code&gt; method, we were in. But wait, there's more!&lt;/p&gt;
    &lt;p&gt;Using GraphQL introspection (because who doesn't love a good schema leak), we found an even easier signup endpoint that completely bypassed email verification. It was like finding a secret menu item, except this one came with user privileges.&lt;/p&gt;
    &lt;code&gt;mutation SignUp {
  signUp(input: { email: "[email protected]", password: "password123" })
}
&lt;/code&gt;
    &lt;p&gt;The cherry on top? They emailed us the password in plain text. In 2025. We're not even mad, just impressed by the commitment to terrible security practices.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;When your password security is more outdated than the ice cream machine&lt;/p&gt;
    &lt;head rend="h3"&gt;"Gotta Catch 'Em All" - The Global Store Directory&lt;/head&gt;
    &lt;p&gt;Once authenticated, we hit the jackpot: a single GraphQL endpoint that returned a store in their global empire. (the store ids were incrementing) Not just the store name, but the good stuff – store employees personal information, internal IDs, configuration details.&lt;/p&gt;
    &lt;p&gt;But wait, there's more! We also found a GraphQL query to search users who have access to assistant by name, revealing personal info faster than you can say "would you like fries with that data breach?"&lt;/p&gt;
    &lt;head rend="h3"&gt;The "No Authentication, No Problem" Token Generator&lt;/head&gt;
    &lt;p&gt;Here's where things got spicy. We discovered a GraphQL mutation called &lt;code&gt;createToken&lt;/code&gt; that was about as secure as leaving your house key under a welcome mat labeled "HOUSE KEY HERE."&lt;/p&gt;
    &lt;p&gt;This beautiful piece of mutation accepted a &lt;code&gt;storeId&lt;/code&gt; parameter and required absolutely zero authentication. None. Nada. Zilch.&lt;/p&gt;
    &lt;code&gt;mutation CreateToken {
  createToken(input: { storeId: "1" })
}
&lt;/code&gt;
    &lt;p&gt;&lt;lb/&gt;Authentication is optional, apparently&lt;/p&gt;
    &lt;p&gt;This token wasn't just a key to one store – it was the master key to the entire kingdom. With it, we could promote ourselves to admin status across the entire platform:&lt;/p&gt;
    &lt;code&gt;mutation BecomeTheKing {
  updateUser(input: { id: "definitely-us", roles: "admin" }) {
    roles  # Spoiler: it's "admin" now
  }
}
&lt;/code&gt;
    &lt;p&gt;&lt;lb/&gt;Look at us. We're the captain now.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Drive-Thru Equipment Store (A Detour Into Absurdity)&lt;/head&gt;
    &lt;p&gt;While exploring, we stumbled upon RBI's equipment ordering website. The password protection? Client-side only. The password? Hardcoded in da HTML.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;Security through obscurity, but the obscurity is in plain sight&lt;/p&gt;
    &lt;p&gt;Here you could order drive-thru essentials like "Single Lane Kits" (tablets included!) or just grab a tablet for those bathroom feedback screens because apparently everything needs to be digital now.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;Your complete drive-thru starter pack, no security included&lt;/p&gt;
    &lt;head rend="h3"&gt;Welcome to the Drive-Thru Control Room&lt;/head&gt;
    &lt;p&gt;The tokens unlocked access to the actual tablet interfaces used in stores. The tablet is primarly composed of what seems to be a web app.&lt;/p&gt;
    &lt;p&gt;Main Screen (&lt;code&gt;https://assistant.bk.com/screens/main?authToken=yourNewBestFriend&lt;/code&gt;)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Lists previous conversations (spoiler: you can listen to them)&lt;/item&gt;
      &lt;item&gt;Shows the "tone" employees should focus on&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Diagnostic Screen (&lt;code&gt;https://assistant.bk.com/screens/diagnostic?authToken=stillYourBestFriend&lt;/code&gt;)&lt;lb/&gt;This one had an additional password protection. The password? "admin". Client-side, of course.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;Advanced password security, circa 1995&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;When your password security is more predictable than McDonald's ice cream machines being broken&lt;/p&gt;
    &lt;p&gt;Once inside, we found APIs to control drive-thru audio levels. Want to blast customers' eardrums or make them whisper their order? We got you covered:&lt;/p&gt;
    &lt;p&gt;Any store token could also list any store's drive-thru config, because apparently access control is just a suggestion.&lt;/p&gt;
    &lt;p&gt;Notice something? Well it returns a JWT that can be used to call an API to return a signed AWS upload url, for any store's path, which is bad. Very bad.&lt;/p&gt;
    &lt;p&gt;First it was kind enough to reveal the missing values:&lt;/p&gt;
    &lt;p&gt;Then it returned with the signed upload URL for "amongus.mp4":&lt;/p&gt;
    &lt;head rend="h3"&gt;The Drive-Thru Surveillance State&lt;/head&gt;
    &lt;p&gt;Now for the truly mind-blowing part: We could access actual voice recordings of customer orders. Which god knows how long they store those for.&lt;/p&gt;
    &lt;p&gt;Not just transcripts. Not just metadata. Raw audio files of real people ordering food, complete with background conversations, car radios, and sometimes personally identifiable information.&lt;/p&gt;
    &lt;p&gt;Big Brother is watching, and he wants to know if you'd like to supersize that&lt;/p&gt;
    &lt;p&gt;This audio goldmine was being fed into AI systems to analyze:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Customer sentiment&lt;/item&gt;
      &lt;item&gt;Employee friendliness levels&lt;/item&gt;
      &lt;item&gt;Upsell success rates&lt;/item&gt;
      &lt;item&gt;Order processing times&lt;/item&gt;
      &lt;item&gt;How many times employees said "You rule" (because that's definitely a crucial business metric)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;&lt;lb/&gt;AI-powered friendliness monitoring: dystopian but thorough&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;Your drive-thru performance review, brought to you by artificial intelligence&lt;/p&gt;
    &lt;head rend="h3"&gt;The Bathroom Chronicles&lt;/head&gt;
    &lt;p&gt;We found the code for the bathroom rating screen for the tablet was in the assistant panel as well, For example, the bathroom rating screen is located at:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;https://assistant.bk.com/feedback/storeid/&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;Which we assume the tablet loads in a webapp with its storeId&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;Rating bathroom experiences: because everything needs a digital feedback loop&lt;/p&gt;
    &lt;p&gt;The cherry on this porcelain throne? The API that gets called for the feedback sends zero authentication. That's right – you could spam bathroom reviews for every Burger King location without even proving you've ever been within a mile of their restrooms.&lt;/p&gt;
    &lt;p&gt;Want to give a 5-star review to a bathroom in Tokyo while sitting in your pajamas in Ohio? The system says "why not!" 🚽&lt;/p&gt;
    &lt;head rend="h2"&gt;The Full Damage Report'&lt;/head&gt;
    &lt;p&gt;With our newfound admin powers, we could:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Add/remove/manage stores (Want to open a Burger King on the Moon? Now you can!)&lt;/item&gt;
      &lt;item&gt;View/edit employee accounts (Everyone gets a promotion!)&lt;/item&gt;
      &lt;item&gt;Send notifications to any store ids tablet&lt;/item&gt;
      &lt;item&gt;Access store analytics and sales data (Numbers, so many numbers)&lt;/item&gt;
      &lt;item&gt;Upload files to any store's systems (Via convenient JWT-signed AWS URLs)&lt;/item&gt;
      &lt;item&gt;AND More&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Privacy Violations of Epic Proportions&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Access to thousands, possibly hundreds of thousands of voice recordings containing PII, if you visited a burger king and went thru the drive thru, your voice is probably in the aws bucket, and analyzed by AI.&lt;/item&gt;
      &lt;item&gt;GDPR lawyers worldwide suddenly perking up&lt;/item&gt;
      &lt;item&gt;We now know about your embarrassing order of 47 chicken nuggets at 2 AM&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Timeline: The Speed Run&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;When&lt;/cell&gt;
        &lt;cell role="head"&gt;What Happened&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Day 1&lt;/cell&gt;
        &lt;cell&gt;"Hey, let's see how this drive-thru system works"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Day 1, 2 hours later&lt;/cell&gt;
        &lt;cell&gt;"Oh no... OH NO... OH NO"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Day 1, 3 hours later&lt;/cell&gt;
        &lt;cell&gt;"We can hear people ordering food. This is not good."&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Day 1, same day&lt;/cell&gt;
        &lt;cell&gt;RBI fixes everything faster than you can say "code red"&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Credit where it's due – RBI's response time was impressive. However they never commented on the vulnerabilities or answered us. (I guess our report was too hot to handle.)&lt;/p&gt;
    &lt;head rend="h2"&gt;The Fine Print&lt;/head&gt;
    &lt;p&gt;No customer data was retained during this research. No drive-thru orders were harmed in the making of this blog post. Responsible disclosure protocols were followed throughout. We still think the Whopper is pretty good, but Wendys is better&lt;/p&gt;
    &lt;p&gt;So Long, and Thanks for All the Fish&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45148944</guid></item><item><title>996</title><link>https://lucumr.pocoo.org/2025/9/4/996/</link><description>&lt;doc fingerprint="2744b1079b2c7957"&gt;
  &lt;main&gt;
    &lt;p&gt;written on September 04, 2025&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Amazing salary, hackerhouse in SF, crazy equity. 996. Our mission is OSS.” — Gregor Zunic&lt;/p&gt;
      &lt;p&gt;“The current vibe is no drinking, no drugs, 9-9-6, […].” — Daksh Gupta&lt;/p&gt;
      &lt;p&gt;“The truth is, China’s really doing ‘007’ now—midnight to midnight, seven days a week […] if you want to build a $10 billion company, you have to work seven days a week.” — Harry Stebbings&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I love work. I love working late nights, hacking on things. This week I didn’t go to sleep before midnight once. And yet…&lt;/p&gt;
    &lt;p&gt;I also love my wife and kids. I love long walks, contemplating life over good coffee, and deep, meaningful conversations. None of this would be possible if my life was defined by 12 hour days, six days a week. More importantly, a successful company is not a sprint, it’s a marathon.&lt;/p&gt;
    &lt;p&gt;And this is when this is your own company! When you devote 72 hours a week to someone else’s startup, you need to really think about that arrangement a few times. I find it highly irresponsible for a founder to promote that model. As a founder, you are not an employee, and your risks and leverage are fundamentally different.&lt;/p&gt;
    &lt;p&gt;I will always advocate for putting the time in because it is what brought me happiness. Intensity, and giving a shit about what I’m doing, will always matter to me. But you don’t measure that by the energy you put in, or the hours you’re sitting in the office, but the output you produce. Burning out on twelve-hour days, six days a week, has no prize at the end. It’s unsustainable, it shouldn’t be the standard and it sure as hell should not be seen as a positive sign of a company.&lt;/p&gt;
    &lt;p&gt;I’ve pulled many all-nighters, and I’ve enjoyed them. I still do. But they’re enjoyable in the right context, for the right reasons, and when that is a completely personal choice, not the basis of company culture.&lt;/p&gt;
    &lt;p&gt;And that all-nighter? It comes with a fucked up and unproductive morning the day after.&lt;/p&gt;
    &lt;p&gt;When someone promotes a 996 work culture, we should push back.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45149049</guid></item><item><title>DuckDuckGo founder: AI surveillance should be banned</title><link>https://gabrielweinberg.com/p/ai-surveillance-should-be-banned</link><description>&lt;doc fingerprint="b608b3dea7679795"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;AI surveillance should be banned while there is still time.&lt;/head&gt;
    &lt;p&gt;All the same privacy harms with online tracking are also present with AI, but worse.&lt;/p&gt;
    &lt;p&gt;While chatbot conversations resemble longer search queries, chatbot privacy harms have the potential to be significantly worse because the inference potential is dramatically greater. Longer input invites more personal information to be provided, and people are starting to bare their souls to chatbots. The conversational format can make it feel like you’re talking to a friend, a professional, or even a therapist. While search queries reveal interests and personal problems, AI conversations take their specificity to another level and, in addition, reveal thought processes and communication styles, creating a much more comprehensive profile of your personality.&lt;/p&gt;
    &lt;p&gt;This richer personal information can be more thoroughly exploited for manipulation, both commercially and ideologically, for example, through behavioral chatbot advertising and models designed (or themselves manipulated through SEO or hidden system prompts) to nudge you towards a political position or product. Chatbots have already been found to be more persuasive than humans and have caused people to go into delusional spirals as a result. I suspect we’re just scratching the surface, since they can become significantly more attuned to your particular persuasive triggers through chatbot memory features, where they train and fine-tune based on your past conversations, making the influence much more subtle. Instead of an annoying and obvious ad following you around everywhere, you can have a seemingly convincing argument, tailored to your personal style, with an improperly sourced “fact” that you’re unlikely to fact-check or a subtle product recommendation you’re likely to heed.&lt;/p&gt;
    &lt;p&gt;That is, all the privacy debates surrounding Google search results from the past two decades apply one-for-one to AI chats, but to an even greater degree. That’s why we (at DuckDuckGo) started offering Duck.ai for protected chatbot conversations and optional, anonymous AI-assisted answers in our private search engine. In doing so, we’re demonstrating that privacy-respecting AI services are feasible. But unfortunately, such protected chats are not yet standard practice, and privacy mishaps are mounting quickly. Grok leaked hundreds of thousands of chatbot conversations that users thought were private. Perplexity’s AI agent was shown to be vulnerable to hackers who could slurp up your personal information. Open AI is openly talking about their vision for a “super assistant” that tracks everything you do and say (including offline). And Anthropic is going to start training on your chatbot conversations by default (previously the default was off). I collected these from just the past few weeks!&lt;/p&gt;
    &lt;p&gt;It would therefore be ideal if Congress could act quickly to ensure that protected chats become the rule rather than the exception. And yet, I’m not holding my breath because it’s 2025 and the U.S. still doesn’t have a general online privacy law, let alone privacy enshrined in the Constitution as a fundamental right, as it should be. However, there does appear to be an opening right now for AI-specific federal legislation, despite the misguided attempts to ban state AI legislation.&lt;/p&gt;
    &lt;p&gt;Time is running out because every day that passes further entrenches bad privacy practices. Congress must move before history completely repeats itself and everything that happened with online tracking happens again with AI tracking. AI surveillance should be banned while there is still time. No matter what happens, though, we will still be here, offering protected services, including optional AI services, to consumers who want to reap the productivity benefits of online tools without the privacy harms.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45149281</guid></item><item><title>Vibe Coding Through the Berghain Challenge</title><link>https://www.nibzard.com/berghain/</link><description>&lt;doc fingerprint="2ba913392ea24f39"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Vibe Coding Through the Berghain Challenge&lt;/head&gt;
    &lt;p&gt;TL;DR &amp;gt;&amp;gt; Listen Labs' viral billboard puzzle led to a nightclub bouncer optimization challenge. My AI partner Claude and I spent a day building RBCR (Re-solving Bid-Price with Confidence Reserves), achieving 781 rejections among &amp;gt;30k competitors through dual variables and mathematical optimization. &amp;lt;&amp;lt;&lt;/p&gt;
    &lt;head rend="h2"&gt;# Part 1: The Billboard That Started Everything&lt;/head&gt;
    &lt;p&gt;Listen Labs just pulled off a solid growth play.&lt;/p&gt;
    &lt;p&gt;Picture this: You’re driving through San Francisco and spot a cryptic billboard. Five numbers. No explanation. Just:&lt;/p&gt;
    &lt;p&gt;That’s it. SF billboards are basically expensive Reddit posts hoping to go viral online. And this one worked.&lt;/p&gt;
    &lt;p&gt;Someone cracked it pretty quickly—they were token IDs from OpenAI’s tokenizer. Decode them and you get: &lt;code&gt;listenlabs.ai/puzzle&lt;/code&gt;. The kind of puzzle that gets shared in Slack channels and Discord servers.&lt;/p&gt;
    &lt;p&gt;Hit that link and you’re in the Berghain Challenge.&lt;/p&gt;
    &lt;p&gt;Context: Listen Labs runs an AI-powered customer insights platform. They help companies do qualitative research at scale using AI interviewers. Makes sense they’d want to attract technical talent with a smart puzzle. Plus, VCs love seeing this kind of creative marketing in their portfolio companies.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Growth Hack Anatomy&lt;/head&gt;
    &lt;p&gt;Here’s what Listen did that was pure genius:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Stage 1: Cryptic billboard → Curiosity&lt;/item&gt;
      &lt;item&gt;Stage 2: Token puzzle → Technical community engagement&lt;/item&gt;
      &lt;item&gt;Stage 3: OEIS speculation → Community-driven solving&lt;/item&gt;
      &lt;item&gt;Stage 4: Berghain Challenge → Viral optimization addiction&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;They expected 10 concurrent users. They got 30,000 in first hours.&lt;/p&gt;
    &lt;p&gt;That’s a 3000x viral coefficient. Let me repeat that: 3000x.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Alfred’s announcement tweet hit 1.1M views. Zero paid acquisition. Just a billboard and decent understanding of how technical communities work.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The prize? All-expenses Berlin trip plus Berghain guest list. Smart audience targeting—Berlin’s techno scene meets Silicon Valley optimization nerds.&lt;/p&gt;
    &lt;p&gt;You’re not just solving a puzzle anymore. You’re the bouncer at Berlin’s most exclusive nightclub. Your mission? Fill exactly 1,000 spots from a stream of random arrivals. Meet specific quotas. Don’t reject more than 20,000 people.&lt;/p&gt;
    &lt;p&gt;Sounds simple?&lt;/p&gt;
    &lt;p&gt;Ha.&lt;/p&gt;
    &lt;head rend="h3"&gt;When Infrastructure Crashes Create FOMO&lt;/head&gt;
    &lt;p&gt;The official API was… problematic. Rate limits. Downtime. Maximum 10 parallel games. Slow response times.&lt;/p&gt;
    &lt;p&gt;But here’s the thing: Those crashes weren’t bugs. They were features.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Listen’s founder Alfred Wahlforss was tweeting in real-time: “we thought we’d get 10 concurrent users, not 30,000 😅 just rebuilt the API to make run smoother 🚀”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Users were refreshing frantically. “Application error: a server-side exception has occurred.” Comments like “Not sure if this is part of the challenge or if it crashed.”&lt;/p&gt;
    &lt;p&gt;Classic scarcity marketing. Can’t access it? Want it more.&lt;/p&gt;
    &lt;p&gt;Meanwhile, Claude and I were building our own local simulator. Same game mechanics, same statistical distributions, but we could run hundreds of games in parallel without waiting for servers crashing under viral load.&lt;/p&gt;
    &lt;p&gt;The irony? Listen’s infrastructure struggles created authenticity. Real startups have real scaling problems. The community bought in harder.&lt;/p&gt;
    &lt;p&gt;Full implementation: https://github.com/nibzard/berghain-challenge-bot&lt;/p&gt;
    &lt;head rend="h3"&gt;Why This Challenge Will Make You Question Everything&lt;/head&gt;
    &lt;p&gt;Let me paint the picture of why this problem is mathematically evil.&lt;/p&gt;
    &lt;p&gt;You’re standing at the door of Berghain. People arrive one by one. Each person has binary attributes: young/old, well_dressed/casual, male/female, and others. You know the rough frequencies—about 32.3% are young, 32.3% are well_dressed.&lt;/p&gt;
    &lt;p&gt;But here’s the kicker: You must decide immediately. Accept or reject. No takebacks. No “let me think about this.” The line keeps moving.&lt;/p&gt;
    &lt;p&gt;Your constraints for Scenario 1:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Get at least 600 young people&lt;/item&gt;
      &lt;item&gt;Get at least 600 well_dressed people&lt;/item&gt;
      &lt;item&gt;Fill exactly 1,000 spots total&lt;/item&gt;
      &lt;item&gt;Don’t reject more than 20,000 people&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;“Easy,” you think. “I’ll just accept everyone who helps with a constraint.”&lt;/p&gt;
    &lt;p&gt;Wrong.&lt;/p&gt;
    &lt;p&gt;The attributes are correlated. Some young people are also well_dressed. Accept too many of these “duals” early and you’ll overshoot one quota while undershooting the other. Reject too many and you’ll run out of people.&lt;/p&gt;
    &lt;p&gt;It’s a constrained optimization problem wrapped in a deceptively simple game. You’re essentially solving a real-time resource allocation problem with incomplete information and irreversible decisions.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Numbers That Haunt Me&lt;/head&gt;
    &lt;p&gt;After one intense day of obsessive coding with my AI partner, here’s what we discovered in the arena of 30,000 concurrent solvers:&lt;/p&gt;
    &lt;p&gt;Listen created an accidental distributed computing experiment. Thousands of engineers, all attacking the same optimization problem. The collective compute power was staggering.&lt;/p&gt;
    &lt;p&gt;The top performers? They’re getting around 650-700 rejections in this massive competitive landscape. The theoretical minimum is probably somewhere around 600-650 rejections, but with 30,000 people trying, nobody’s found it yet.&lt;/p&gt;
    &lt;p&gt;Our best algorithm? 781 rejections. We called it RBCR (Re-solving Bid-Price with Confidence Reserves). In a field of 30,000, that put us in serious competitive territory.&lt;/p&gt;
    &lt;p&gt;I’ll tell you how we built it, why it works, and why it nearly drove us both insane.&lt;/p&gt;
    &lt;head rend="h3"&gt;What Makes This So Addictive&lt;/head&gt;
    &lt;p&gt;There’s something deeply satisfying about optimization problems. Each improvement feels like a small victory. Going from 1,200 rejections to 1,150 feels monumental. Then 1,100. Then 1,000. Then you hit a wall and obsess over shaving off single digits.&lt;/p&gt;
    &lt;p&gt;But this isn’t just about the math. It’s about the collaboration.&lt;/p&gt;
    &lt;p&gt;I had an idea. My AI partner implemented it in seconds. We tested it immediately. Iterated. Failed. Learned. Repeated. The feedback loop was intoxicating.&lt;/p&gt;
    &lt;p&gt;Traditional solo programming? You spend hours implementing a solution only to discover it doesn’t work. With AI assistance? You can test a dozen approaches in the time it used to take to implement one.&lt;/p&gt;
    &lt;p&gt;This is the story of that collaboration. How we went from clueless to competitive. How AI amplified human intuition. How domain expertise still matters in the age of artificial intelligence.&lt;/p&gt;
    &lt;p&gt;And how a startup’s growth hack became a day-long obsession with optimization, game theory, and the future of collaborative programming.&lt;/p&gt;
    &lt;p&gt;This is a dual story: How Listen accidentally created the most engaging technical challenge of 2025, and how human-AI collaboration let us compete in their accidental arena.&lt;/p&gt;
    &lt;p&gt;Buckle up. We’re about to dive deep into viral growth mechanics, algorithms, failures, breakthroughs, and the beautiful chaos of when marketing meets engineering obsession.&lt;/p&gt;
    &lt;head rend="h2"&gt;# Part 2: The Dual Challenge&lt;/head&gt;
    &lt;p&gt;I’m a growth advisor with engineering fundamentals. When I saw Listen’s campaign, I immediately recognized two fascinating challenges running in parallel:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Challenge 1: How did a startup 3000x their expected user base with zero paid acquisition?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Challenge 2: How do you solve a constrained optimization problem that has prob the smartest engineers in the world competing against you?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Both challenges required the same core skill: understanding systems, finding leverage points, and optimizing ruthlessly.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Growth Marketing Masterclass&lt;/head&gt;
    &lt;p&gt;Listen’s approach was textbook viral growth with a technical twist:&lt;/p&gt;
    &lt;p&gt;Mystery Phase: Cryptic billboard creates curiosity gap. No explanation = maximum speculation.&lt;/p&gt;
    &lt;p&gt;Community Phase: Token puzzle activates technical communities. Reddit threads explode. Twitter goes wild. Everyone becomes a detective.&lt;/p&gt;
    &lt;p&gt;Challenge Phase: Berghain game provides clear success metrics. Immediate feedback loop. Addictive optimization cycle.&lt;/p&gt;
    &lt;p&gt;Competition Phase: Leaderboard dynamics create retention. Status through technical skill. Perfect product-market fit for engineering egos.&lt;/p&gt;
    &lt;p&gt;The brilliant part? Each phase filtered for higher engagement. Casual observers dropped off. Technical obsessives doubled down.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Viral Mechanics&lt;/head&gt;
    &lt;p&gt;From a growth perspective, Listen nailed every viral coefficient multiplier:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Curiosity Gap: Mysterious billboard → high shareability&lt;/item&gt;
      &lt;item&gt;Community Solving: Group puzzle → network effects&lt;/item&gt;
      &lt;item&gt;Status Competition: Technical leaderboard → ego investment&lt;/item&gt;
      &lt;item&gt;Infrastructure Struggles: “Can’t access” → scarcity psychology&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The 3000x multiplier wasn’t luck. It was systematic exploitation of technical community psychology.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Engineering Obsession&lt;/head&gt;
    &lt;p&gt;From a technical perspective, this problem was crack cocaine for optimization addicts:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Clear Success Metrics: Rejection count goes down = dopamine hit&lt;/item&gt;
      &lt;item&gt;Immediate Feedback: Test algorithm, get result instantly&lt;/item&gt;
      &lt;item&gt;Competitive Context: 30,000 people trying to beat you&lt;/item&gt;
      &lt;item&gt;Deep Complexity: Simple rules, emergent mathematical beauty&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Perfect storm for engineering obsession.&lt;/p&gt;
    &lt;head rend="h3"&gt;Where Marketing Met Engineering&lt;/head&gt;
    &lt;p&gt;The genius of Listen’s approach: They created a problem that required both growth mindset and technical depth.&lt;/p&gt;
    &lt;p&gt;Understanding the viral mechanics helped me see why the challenge was so engaging. Understanding the optimization problem helped me see why the growth worked so well.&lt;/p&gt;
    &lt;p&gt;Marketing created the arena. Engineering filled it with obsessives.&lt;/p&gt;
    &lt;p&gt;Time to tell you how we became one of those obsessives.&lt;/p&gt;
    &lt;head rend="h2"&gt;# Part 3: Day 1 - The Naive Optimism Phase&lt;/head&gt;
    &lt;p&gt;“Hey Claude, I found this interesting challenge. It’s about being a nightclub bouncer and optimizing admissions. Want to help me solve it?”&lt;/p&gt;
    &lt;p&gt;Famous last words.&lt;/p&gt;
    &lt;p&gt;I was expecting maybe an hour of casual problem-solving. You know, write a simple algorithm, test it, maybe optimize it a bit, call it a day.&lt;/p&gt;
    &lt;p&gt;By the end of the day, I’m staring at 30+ solver implementations, thousands of lines of code, and a monitoring dashboard that looks like mission control.&lt;/p&gt;
    &lt;p&gt;But let’s start at the beginning.&lt;/p&gt;
    &lt;head rend="h3"&gt;The First Attempt: Greedy and Naive&lt;/head&gt;
    &lt;p&gt;Me: “Let’s start simple. Just accept anyone who helps with our constraints.”&lt;/p&gt;
    &lt;p&gt;Claude: “You’re absolutely right! Here’s a greedy approach:”&lt;/p&gt;
    &lt;code&gt;def should_accept(person, game_state):
    # Accept if person helps with any unmet constraint
    for constraint in game_state.constraints:
        if person.has_attribute(constraint.attribute):
            shortage = constraint.min_count - game_state.admitted_attributes[constraint.attribute]
            if shortage &amp;gt; 0:
                return True, f"needed_for_{constraint.attribute}"

    # Otherwise, maybe accept a few randoms
    return random.random() &amp;lt; 0.05, "filler"&lt;/code&gt;
    &lt;p&gt;Me: “Perfect! This should work great.”&lt;/p&gt;
    &lt;p&gt;Famous last words, part two.&lt;/p&gt;
    &lt;p&gt;We fired it up. Results: 1,247 rejections.&lt;/p&gt;
    &lt;p&gt;Ouch.&lt;/p&gt;
    &lt;p&gt;Claude: “The issue is we’re being too greedy early. We accept everyone who’s young OR well_dressed, but many people are both. We overshoot one constraint while undershooting the other.”&lt;/p&gt;
    &lt;head rend="h3"&gt;The Second Attempt: Tracking Deficits&lt;/head&gt;
    &lt;p&gt;Me: “Okay, so we need to track how much we still need of each attribute and be smarter about it.”&lt;/p&gt;
    &lt;p&gt;Claude: “I can implement a deficit-aware strategy:”&lt;/p&gt;
    &lt;code&gt;def should_accept(person, game_state):
    shortage = game_state.constraint_shortage()

    # Calculate how much this person helps
    young = person.young and shortage['young'] &amp;gt; 0
    well_dressed = person.well_dressed and shortage['well_dressed'] &amp;gt; 0

    if young and well_dressed:
        return True, "dual_helper"  # Helps both constraints
    elif young or well_dressed:
        return random.random() &amp;lt; 0.7, "single_helper"
    else:
        return random.random() &amp;lt; 0.02, "filler"&lt;/code&gt;
    &lt;p&gt;Better! Down to 1,098 rejections.&lt;/p&gt;
    &lt;p&gt;Still terrible, but progress.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Third Attempt: Getting Desperate&lt;/head&gt;
    &lt;p&gt;Me: “What if we’re more selective early on? Only accept the really good candidates?”&lt;/p&gt;
    &lt;p&gt;Claude: “We could implement phases based on capacity usage:”&lt;/p&gt;
    &lt;code&gt;def should_accept(person, game_state):
    capacity_ratio = game_state.admitted_count / 1000.0
    shortage = game_state.constraint_shortage()

    young_helps = person.young and shortage['young'] &amp;gt; 0
    dressed_helps = person.well_dressed and shortage['well_dressed'] &amp;gt; 0

    if capacity_ratio &amp;lt; 0.3:  # Early phase - be picky
        if young_helps and dressed_helps:
            return True, "early_dual"
        return False, "early_reject"

    elif capacity_ratio &amp;lt; 0.7:  # Mid phase - moderate
        if young_helps or dressed_helps:
            return random.random() &amp;lt; 0.6, "mid_helper"
        return False, "mid_reject"

    else:  # Late phase - panic mode
        if young_helps or dressed_helps:
            return True, "late_helper"
        return random.random() &amp;lt; 0.1, "late_filler"&lt;/code&gt;
    &lt;p&gt;Results: 943 rejections.&lt;/p&gt;
    &lt;p&gt;We were getting somewhere! But also realizing this problem was way harder than expected.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Debugging Session&lt;/head&gt;
    &lt;p&gt;Me: “Wait, let’s actually understand what’s going wrong. Can you add detailed logging?”&lt;/p&gt;
    &lt;p&gt;Claude: “Of course! Let me instrument everything:”&lt;/p&gt;
    &lt;code&gt;def should_accept(person, game_state):
    # ... decision logic ...

    # Log everything
    logger.info(f"Person {game_state.person_count}: "
                f"young={person.young}, dressed={person.well_dressed}, "
                f"decision={decision}, reason='{reason}', "
                f"capacity={game_state.admitted_count}/1000, "
                f"young_deficit={shortage['young']}, "
                f"dressed_deficit={shortage['well_dressed']}")

    return decision, reason&lt;/code&gt;
    &lt;p&gt;Running this, we could see exactly what was happening. The logs were brutal:&lt;/p&gt;
    &lt;code&gt;Person 1247: young=True, dressed=False, decision=True, reason='young_needed'
Person 1248: young=False, dressed=True, decision=True, reason='dressed_needed'
Person 1249: young=True, dressed=True, decision=True, reason='dual_jackpot'
...
Person 15673: young=False, dressed=False, decision=False, reason='useless'
GAME OVER: young_deficit=127, dressed_deficit=43, capacity=953/1000&lt;/code&gt;
    &lt;p&gt;We were consistently undershooting our quotas while running out of capacity. Classic resource allocation failure.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Facepalm Moment&lt;/head&gt;
    &lt;p&gt;Me: “Oh god. We’re not accounting for the probabilities properly. If only 32% of people are young, and we need 600 young people out of 1000 total spots, we actually need to accept like… 90%+ of young people we see.”&lt;/p&gt;
    &lt;p&gt;Claude: “Exactly! And the correlation between attributes makes it even more complex. A person who’s both young and well_dressed is incredibly valuable because they satisfy both constraints simultaneously.”&lt;/p&gt;
    &lt;p&gt;Me: “We need to think about this probabilistically. What’s the expected value of accepting this person given our current state and the remaining slots?”&lt;/p&gt;
    &lt;p&gt;Claude: “That sounds like we need to model this as an optimization problem with uncertainty…”&lt;/p&gt;
    &lt;p&gt;And that’s when I realized we weren’t just building a simple algorithm anymore.&lt;/p&gt;
    &lt;p&gt;We were diving into operations research territory. Stochastic optimization. Dynamic programming. Multi-objective decision making under uncertainty.&lt;/p&gt;
    &lt;p&gt;All for a nightclub bouncer simulation.&lt;/p&gt;
    &lt;head rend="h3"&gt;Day 1 Wrap-Up: Reality Check&lt;/head&gt;
    &lt;p&gt;By the end of day one, our best solution was still sitting at 943 rejections. Respectable improvement from 1,200+, but nowhere near competitive.&lt;/p&gt;
    &lt;p&gt;More importantly, we had a much clearer picture of why this problem was hard:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Resource constraints: Limited capacity (1000 spots)&lt;/item&gt;
      &lt;item&gt;Correlated attributes: People who are young AND well_dressed are gold&lt;/item&gt;
      &lt;item&gt;Uncertain arrival patterns: You never know what’s coming next&lt;/item&gt;
      &lt;item&gt;Irreversible decisions: No takebacks once you decide&lt;/item&gt;
      &lt;item&gt;Multiple objectives: Two quotas plus capacity limit&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Me: “Tomorrow, we’re going to need to get mathematical about this.”&lt;/p&gt;
    &lt;p&gt;Claude: “I’m ready. Should we start reading about constrained optimization?”&lt;/p&gt;
    &lt;p&gt;Little did we know, we were about to discover Lagrangian multipliers, bid-price mechanisms, and the beautiful world of dual variable optimization.&lt;/p&gt;
    &lt;p&gt;Day two was going to be very different from day one.&lt;/p&gt;
    &lt;head rend="h2"&gt;# Part 4: The Statistical Awakening&lt;/head&gt;
    &lt;p&gt;A few hours later, I had a growth insight: viral challenges work because they create addiction loops.&lt;/p&gt;
    &lt;p&gt;Listen had nailed the psychology. Every algorithm improvement = dopamine hit. Every leaderboard check = social comparison. Every failed attempt = “just one more try.”&lt;/p&gt;
    &lt;p&gt;With 30,000 engineers now obsessing, the competition was heating up.&lt;/p&gt;
    &lt;p&gt;Me: “Claude, we’ve been treating each decision independently. But this is really about managing scarce resources over time. We need to think about opportunity costs.”&lt;/p&gt;
    &lt;p&gt;Claude: “You’re absolutely right! Each acceptance now affects our options later. If we accept too many single-attribute people early, we might not have room for dual-attribute people who are more efficient.”&lt;/p&gt;
    &lt;p&gt;Me: “Exactly! And we need to use statistics properly. What are the actual probabilities here?”&lt;/p&gt;
    &lt;head rend="h3"&gt;Understanding the Data&lt;/head&gt;
    &lt;p&gt;First, we dove into the attribute frequencies. The challenge gives you some basic stats, but we needed to understand the correlations.&lt;/p&gt;
    &lt;code&gt;# From the game statistics
frequencies = {
    'young': 0.323,        # 32.3% of people are young
    'well_dressed': 0.323,  # 32.3% are well_dressed
}

# The correlation coefficient between young and well_dressed
correlation = 0.076  # Slight positive correlation&lt;/code&gt;
    &lt;p&gt;Claude: “Let me calculate the joint probabilities:”&lt;/p&gt;
    &lt;code&gt;import math

def calculate_joint_probabilities(p_young, p_dressed, correlation):
    # Convert correlation to covariance
    denom = math.sqrt(p_young * (1-p_young) * p_dressed * (1-p_dressed))
    covariance = correlation * denom

    # Joint probabilities
    p_both = p_young * p_dressed + covariance
    p_young_only = p_young - p_both
    p_dressed_only = p_dressed - p_both
    p_neither = 1 - (p_both + p_young_only + p_dressed_only)

    return p_both, p_young_only, p_dressed_only, p_neither

# Results:
# P(both young AND well_dressed) ≈ 0.110
# P(young only) ≈ 0.213
# P(well_dressed only) ≈ 0.213
# P(neither) ≈ 0.464&lt;/code&gt;
    &lt;p&gt;This was eye-opening. About 11% of people help with BOTH constraints. These “dual” people are incredibly valuable—each one gets us closer to both quotas simultaneously.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Value Function Epiphany&lt;/head&gt;
    &lt;p&gt;Me: “We need to assign values to different types of people based on how much they help us.”&lt;/p&gt;
    &lt;p&gt;Claude: “A value function based on remaining deficits! Here’s what I’m thinking:”&lt;/p&gt;
    &lt;code&gt;def calculate_person_value(person, game_state):
    shortage = game_state.constraint_shortage()
    value = 0

    if person.young and shortage['young'] &amp;gt; 0:
        value += 1.0  # Base value for helping young quota

    if person.well_dressed and shortage['well_dressed'] &amp;gt; 0:
        value += 1.0  # Base value for helping dressed quota

    # Bonus for dual attributes (more efficient use of capacity)
    if person.young and person.well_dressed:
        if shortage['young'] &amp;gt; 0 and shortage['well_dressed'] &amp;gt; 0:
            value += 0.5  # Efficiency bonus

    return value&lt;/code&gt;
    &lt;p&gt;Me: “But wait. The value should depend on scarcity too. If we’re almost done with young people but need lots of well_dressed people, a well_dressed person is worth more than a young person.”&lt;/p&gt;
    &lt;p&gt;Claude: “Ah, like dynamic pricing! The scarcer the resource, the higher its value:“&lt;/p&gt;
    &lt;code&gt;def calculate_person_value(person, game_state):
    shortage = game_state.constraint_shortage()
    remaining_slots = 1000 - game_state.admitted_count

    value = 0

    if person.young and shortage['young'] &amp;gt; 0:
        # Value increases as shortage becomes more critical
        scarcity_multiplier = shortage['young'] / remaining_slots
        value += scarcity_multiplier

    if person.well_dressed and shortage['well_dressed'] &amp;gt; 0:
        scarcity_multiplier = shortage['well_dressed'] / remaining_slots
        value += scarcity_multiplier

    return value&lt;/code&gt;
    &lt;head rend="h3"&gt;The Acceptance Probability Function&lt;/head&gt;
    &lt;p&gt;Now we had values, but we needed to convert them to acceptance probabilities. Accept everyone with high value? Too greedy. Accept nobody? Too conservative.&lt;/p&gt;
    &lt;p&gt;Me: “What if we use a sigmoid function? High value → high probability, low value → low probability, but with some randomness.”&lt;/p&gt;
    &lt;p&gt;Claude: “Perfect! And we can tune the temperature parameter to control how selective we are:“&lt;/p&gt;
    &lt;code&gt;import math

def acceptance_probability(value, temperature=2.0):
    """Convert value to acceptance probability using sigmoid"""
    return 1.0 / (1.0 + math.exp(-value / temperature))

# Example:
# value = 0.5 → probability ≈ 0.62
# value = 1.0 → probability ≈ 0.73
# value = 1.5 → probability ≈ 0.82
# value = 2.0 → probability ≈ 0.88&lt;/code&gt;
    &lt;head rend="h3"&gt;The First Statistical Solver&lt;/head&gt;
    &lt;p&gt;Putting it all together:&lt;/p&gt;
    &lt;code&gt;class StatisticalSolver:
    def __init__(self, temperature=2.0):
        self.temperature = temperature

    def should_accept(self, person, game_state):
        # Calculate person's value based on current needs
        value = self.calculate_person_value(person, game_state)

        # Convert to acceptance probability
        prob = self.acceptance_probability(value)

        # Make random decision based on probability
        decision = random.random() &amp;lt; prob

        reason = f"value={value:.2f}_prob={prob:.2f}"
        return decision, reason

    def calculate_person_value(self, person, game_state):
        shortage = game_state.constraint_shortage()
        remaining_slots = max(1, 1000 - game_state.admitted_count)

        value = 0.0

        if person.young and shortage['young'] &amp;gt; 0:
            urgency = shortage['young'] / remaining_slots
            value += urgency

        if person.well_dressed and shortage['well_dressed'] &amp;gt; 0:
            urgency = shortage['well_dressed'] / remaining_slots
            value += urgency

        return value&lt;/code&gt;
    &lt;p&gt;Results: 847 rejections!&lt;/p&gt;
    &lt;p&gt;Holy shit. We dropped from 943 to 847 with one key insight: think probabilistically, not deterministically.&lt;/p&gt;
    &lt;head rend="h3"&gt;Fine-Tuning the Parameters&lt;/head&gt;
    &lt;p&gt;Me: “The temperature parameter is crucial. Too high and we accept too many low-value people. Too low and we’re too picky.”&lt;/p&gt;
    &lt;p&gt;Claude: “Let me run some parameter sweeps:”&lt;/p&gt;
    &lt;code&gt;# Testing different temperatures
results = []
for temp in [0.5, 1.0, 1.5, 2.0, 2.5, 3.0]:
    solver = StatisticalSolver(temperature=temp)
    avg_rejections = run_multiple_games(solver, num_games=10)
    results.append((temp, avg_rejections))
    print(f"Temperature {temp}: {avg_rejections:.1f} rejections")

# Results:
# Temperature 0.5: 1,245 rejections (too picky)
# Temperature 1.0: 934 rejections
# Temperature 1.5: 847 rejections  ← sweet spot
# Temperature 2.0: 892 rejections
# Temperature 2.5: 967 rejections (too accepting)
# Temperature 3.0: 1,078 rejections&lt;/code&gt;
    &lt;p&gt;Temperature = 1.5 was our sweet spot. Not too hot, not too cold.&lt;/p&gt;
    &lt;head rend="h3"&gt;Adding Phase-Based Logic&lt;/head&gt;
    &lt;p&gt;Me: “We should probably be more aggressive late in the game when we’re running out of people.”&lt;/p&gt;
    &lt;p&gt;Claude: “Adaptive temperature based on game phase?”&lt;/p&gt;
    &lt;code&gt;def get_adaptive_temperature(self, game_state):
    capacity_ratio = game_state.admitted_count / 1000.0

    if capacity_ratio &amp;lt; 0.4:
        return 1.2  # Early game: be selective
    elif capacity_ratio &amp;lt; 0.8:
        return 1.5  # Mid game: balanced
    else:
        return 2.2  # Late game: more aggressive&lt;/code&gt;
    &lt;p&gt;Results: 821 rejections.&lt;/p&gt;
    &lt;p&gt;We were getting there! Each insight was shaving off 20-50 rejections.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Monitoring Dashboard&lt;/head&gt;
    &lt;p&gt;At this point, we had enough complexity that debugging became hard. So we built a real-time monitoring system.&lt;/p&gt;
    &lt;p&gt;Claude: “Let me create a TUI dashboard so we can watch the algorithm in action:”&lt;/p&gt;
    &lt;code&gt;from rich.live import Live
from rich.table import Table
from rich.panel import Panel

class GameMonitor:
    def display_status(self, game_state, last_decision):
        table = Table(title="Berghain Bouncer Status")
        table.add_column("Metric", style="bold")
        table.add_column("Value", style="green")

        table.add_row("Admitted", f"{game_state.admitted_count}/1000")
        table.add_row("Young", f"{game_state.admitted_attributes['young']}/600")
        table.add_row("Well Dressed", f"{game_state.admitted_attributes['well_dressed']}/600")
        table.add_row("Rejections", str(game_state.rejection_count))
        table.add_row("Last Decision", last_decision)

        return Panel(table, title="Live Game Status")&lt;/code&gt;
    &lt;p&gt;Watching the dashboard was mesmerizing. You could see the deficits shrinking, the capacity filling up, the algorithm making split-second decisions.&lt;/p&gt;
    &lt;p&gt;Sometimes it would reject a dual-attribute person early in the game (seemed wasteful) but accept a single-attribute person later (made sense given the remaining needs).&lt;/p&gt;
    &lt;p&gt;Me: “It’s actually working! The algorithm is learning to balance short-term and long-term value.”&lt;/p&gt;
    &lt;p&gt;Claude: “The statistical approach is much more robust than our previous heuristics. We’re making decisions based on actual probabilities rather than gut feelings.”&lt;/p&gt;
    &lt;head rend="h3"&gt;End of Day 2: Statistical Success&lt;/head&gt;
    &lt;p&gt;By end of day two, we had:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;✅ Dropped from 943 to 821 rejections&lt;/item&gt;
      &lt;item&gt;✅ Built a probabilistic decision framework&lt;/item&gt;
      &lt;item&gt;✅ Implemented adaptive parameters&lt;/item&gt;
      &lt;item&gt;✅ Created a real-time monitoring system&lt;/item&gt;
      &lt;item&gt;✅ Understood the mathematical structure of the problem&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Me: “821 rejections puts us in decent territory, but I keep thinking there’s a more principled approach. This feels like an operations research problem.”&lt;/p&gt;
    &lt;p&gt;Claude: “You’re thinking about optimal stopping theory? Or maybe linear programming?”&lt;/p&gt;
    &lt;p&gt;Me: “Exactly. Tomorrow, let’s get serious about the math. I want to understand this problem from first principles.”&lt;/p&gt;
    &lt;p&gt;Little did we know, day three would introduce us to Lagrangian multipliers, dual variables, and the most elegant algorithm we’d build: RBCR (Re-solving Bid-Price with Confidence Reserves).&lt;/p&gt;
    &lt;p&gt;The statistical awakening was just the beginning.&lt;/p&gt;
    &lt;head rend="h2"&gt;# Part 5: The Mathematical Enlightenment&lt;/head&gt;
    &lt;p&gt;Later that day. I’m lying in bed thinking about Lagrangian multipliers.&lt;/p&gt;
    &lt;p&gt;This is what optimization problems do to you. They crawl into your brain and set up camp.&lt;/p&gt;
    &lt;p&gt;Me: “Claude, I can’t sleep. I keep thinking about this problem as a constrained optimization. What if we model it with dual variables?”&lt;/p&gt;
    &lt;p&gt;Claude: “At 3 AM? I’m always available! Tell me what you’re thinking.”&lt;/p&gt;
    &lt;p&gt;Me: “In economics, when you have scarce resources, you use prices to allocate them efficiently. What if we assign ‘prices’ to our constraints? Higher price means we really need that attribute.”&lt;/p&gt;
    &lt;head rend="h3"&gt;The Lagrangian Insight&lt;/head&gt;
    &lt;p&gt;Claude: “You’re talking about Lagrangian multipliers! In constrained optimization, the multipliers represent the shadow prices—how much the objective would improve if we relaxed each constraint slightly.”&lt;/p&gt;
    &lt;p&gt;Me: “Exactly! So if we desperately need young people, the ‘price’ for young should be high. If we desperately need well_dressed people, that price should be high too.”&lt;/p&gt;
    &lt;p&gt;Here’s the key insight: Instead of static value functions, we could have dynamic prices that adjust based on how urgent each constraint becomes.&lt;/p&gt;
    &lt;p&gt;Claude: “Let me formalize this. We want to minimize rejections subject to:”&lt;/p&gt;
    &lt;code&gt;minimize: rejections
subject to: young_count &amp;gt;= 600
           dressed_count &amp;gt;= 600
           total_count &amp;lt;= 1000&lt;/code&gt;
    &lt;p&gt;Me: “And the Lagrangian multipliers λ_young and λ_dressed tell us the ‘urgency’ of each constraint at any given moment.”&lt;/p&gt;
    &lt;head rend="h3"&gt;Implementing Dual Variables&lt;/head&gt;
    &lt;p&gt;Claude: “Here’s how we can compute the multipliers dynamically:”&lt;/p&gt;
    &lt;code&gt;class DualVariableSolver:
    def __init__(self):
        self.lambda_young = 0.0
        self.lambda_dressed = 0.0

    def update_dual_variables(self, game_state):
        """Update dual variables based on current deficits"""
        shortage = game_state.constraint_shortage()
        remaining_slots = max(1, 1000 - game_state.admitted_count)

        # Expected helpful arrivals per remaining slot
        young_help_rate = self.estimate_helpful_rate('young', game_state)
        dressed_help_rate = self.estimate_helpful_rate('dressed', game_state)

        # Dual variables = deficit / expected helpful arrivals
        self.lambda_young = shortage['young'] / max(young_help_rate * remaining_slots, 1e-6)
        self.lambda_dressed = shortage['dressed'] / max(dressed_help_rate * remaining_slots, 1e-6)

    def estimate_helpful_rate(self, attribute, game_state):
        """Estimate probability that next person will help with this attribute"""
        if attribute == 'young':
            return 0.323  # Base frequency of young people
        elif attribute == 'dressed':
            return 0.323  # Base frequency of well_dressed people
        return 0.0

    def should_accept(self, person, game_state):
        # Update dual variables first
        self.update_dual_variables(game_state)

        # Calculate person's dual value
        dual_value = 0.0

        if person.young and game_state.constraint_shortage()['young'] &amp;gt; 0:
            dual_value += self.lambda_young

        if person.well_dressed and game_state.constraint_shortage()['dressed'] &amp;gt; 0:
            dual_value += self.lambda_dressed

        # Accept if dual value exceeds threshold
        threshold = 1.0  # Tunable parameter
        decision = dual_value &amp;gt;= threshold

        reason = f"dual_value={dual_value:.2f}_λy={self.lambda_young:.2f}_λd={self.lambda_dressed:.2f}"
        return decision, reason&lt;/code&gt;
    &lt;p&gt;Results: 782 rejections!&lt;/p&gt;
    &lt;p&gt;We’d broken through 800! This was our best result yet.&lt;/p&gt;
    &lt;head rend="h3"&gt;But Wait, There’s More&lt;/head&gt;
    &lt;p&gt;Me: “This is working, but I think we’re missing something. The threshold is static, but it should probably adapt based on how full we are.”&lt;/p&gt;
    &lt;p&gt;Claude: “You’re right! Early in the game we can be picky (high threshold). Late in the game we should be desperate (low threshold).”&lt;/p&gt;
    &lt;code&gt;def get_adaptive_threshold(self, game_state):
    capacity_ratio = game_state.admitted_count / 1000.0
    rejection_ratio = game_state.rejection_count / 20000.0

    # Start high, end low
    base_threshold = 1.5 - capacity_ratio

    # Panic if we're running out of rejections
    if rejection_ratio &amp;gt; 0.8:
        base_threshold *= 0.5  # Emergency mode

    return max(0.1, base_threshold)&lt;/code&gt;
    &lt;head rend="h3"&gt;The RBCR Revolution&lt;/head&gt;
    &lt;p&gt;Me: “What if we resolve the dual variables periodically? Like every 50 arrivals, we re-estimate our helper rates and update our strategy?”&lt;/p&gt;
    &lt;p&gt;Claude: “Re-solving Bid-Price with Confidence Reserves! We could call it RBCR.”&lt;/p&gt;
    &lt;p&gt;This was the breakthrough moment. Instead of updating duals every single decision, we’d batch them. Every 50 arrivals:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Look at our current deficit&lt;/item&gt;
      &lt;item&gt;Estimate remaining helpful arrival rates&lt;/item&gt;
      &lt;item&gt;Recompute dual variables&lt;/item&gt;
      &lt;item&gt;Set acceptance thresholds accordingly&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;class RBCRSolver:
    def __init__(self):
        self.lambda_young = 0.0
        self.lambda_dressed = 0.0
        self.resolve_counter = 0
        self.resolve_every = 50

    def should_accept(self, person, game_state):
        # Periodically resolve dual variables
        if self.resolve_counter % self.resolve_every == 0:
            self.resolve_duals(game_state)
        self.resolve_counter += 1

        # Calculate dual value for this person
        dual_value = self.calculate_dual_value(person, game_state)

        # Adaptive threshold based on game state
        threshold = self.get_adaptive_threshold(game_state)

        # Accept if value exceeds threshold
        decision = dual_value &amp;gt;= threshold

        return decision, f"dv={dual_value:.2f}_th={threshold:.2f}"

    def resolve_duals(self, game_state):
        """The heart of RBCR - recompute dual variables"""
        shortage = game_state.constraint_shortage()
        remaining_slots = max(1, 1000 - game_state.admitted_count)

        # Estimate help rates (this is where the magic happens)
        young_rate = self.estimate_young_help_rate(game_state)
        dressed_rate = self.estimate_dressed_help_rate(game_state)

        # Expected helpful arrivals = rate * remaining_slots
        expected_young_help = young_rate * remaining_slots
        expected_dressed_help = dressed_rate * remaining_slots

        # Dual variables = deficit / expected_help
        self.lambda_young = shortage['young'] / max(expected_young_help, 1e-6)
        self.lambda_dressed = shortage['dressed'] / max(expected_dressed_help, 1e-6)&lt;/code&gt;
    &lt;p&gt;Results: 781 rejections.&lt;/p&gt;
    &lt;p&gt;We’d found our winner! RBCR was consistently hitting the low 780s.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Beautiful Math Behind RBCR&lt;/head&gt;
    &lt;p&gt;Here’s why this approach is so elegant:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Dual variables capture urgency: When you desperately need young people, λ_young shoots up, making young people more valuable.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Periodic resolution is efficient: We don’t need to recompute every single decision—every 50 arrivals is enough.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Adaptive thresholds handle phases: Early pickiness, late desperation, all handled automatically.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Self-correcting: If we’re accepting too many of one type, the deficit shrinks, the dual variable drops, we become less likely to accept more.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The math was doing exactly what a good bouncer would do: pay attention to what you need most, be pickier when you have time, be desperate when you’re running out of options.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Debugging Session That Made Us Believers&lt;/head&gt;
    &lt;p&gt;Me: “Let’s trace through a game step by step and see the duals in action.”&lt;/p&gt;
    &lt;code&gt;Game Start:
shortage: young=600, dressed=600
λ_young=1.85, λ_dressed=1.85

Person 1: young=True, dressed=True
dual_value = 1.85 + 1.85 = 3.70
threshold = 1.50
ACCEPT (dual person is incredibly valuable)

...

Person 500: young=True, dressed=False
shortage: young=234, dressed=178
λ_young=0.95, λ_dressed=1.23
dual_value = 0.95
threshold = 1.20
REJECT (young is less urgent now)

Person 501: young=False, dressed=True
dual_value = 1.23
threshold = 1.20
ACCEPT (dressed is still urgent)&lt;/code&gt;
    &lt;p&gt;Claude: “It’s beautiful! The dual variables automatically rebalance based on remaining needs. The algorithm develops intuition.”&lt;/p&gt;
    &lt;p&gt;Me: “And look at the late game behavior:”&lt;/p&gt;
    &lt;code&gt;Person 950: young=False, dressed=False
shortage: young=12, dressed=3
λ_young=0.78, λ_dressed=0.18
dual_value = 0.0
threshold = 0.30
REJECT (we're almost done, be picky)

Person 951: young=True, dressed=False
dual_value = 0.78
threshold = 0.30
ACCEPT (still need a few young people)&lt;/code&gt;
    &lt;p&gt;The algorithm had learned to be surgical in the endgame.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why 781 Felt Like Victory&lt;/head&gt;
    &lt;p&gt;After two days of grinding, seeing that 781 was intoxicating. It wasn’t just the number—it was the elegance.&lt;/p&gt;
    &lt;p&gt;RBCR felt right in a way our previous algorithms didn’t. The decisions made intuitive sense. The math was principled. The performance was consistent.&lt;/p&gt;
    &lt;p&gt;Me: “I think we found our killer algorithm.”&lt;/p&gt;
    &lt;p&gt;Claude: “The dual variable approach captures the essence of the problem. We’re explicitly modeling scarcity and urgency.”&lt;/p&gt;
    &lt;p&gt;Me: “But I have a terrible feeling there are even more optimizations we could make…”&lt;/p&gt;
    &lt;p&gt;And that’s how day three ended. Not with satisfaction, but with the dangerous realization that we could probably make RBCR even better.&lt;/p&gt;
    &lt;p&gt;The mathematical enlightenment was complete. We understood the problem from first principles. We had elegant, principled algorithms.&lt;/p&gt;
    &lt;p&gt;Now came the dangerous part: the obsession with perfection.&lt;/p&gt;
    &lt;head rend="h2"&gt;# Part 6: The Kitchen Sink Era&lt;/head&gt;
    &lt;p&gt;Have you ever solved a problem so elegantly that you immediately want to ruin it with unnecessary complexity?&lt;/p&gt;
    &lt;p&gt;That’s exactly what happened next.&lt;/p&gt;
    &lt;p&gt;RBCR was working beautifully at 781 rejections. Any reasonable person would have stopped there. But we weren’t reasonable people anymore. We were optimization addicts, and 781 felt tantalizingly close to something even better.&lt;/p&gt;
    &lt;p&gt;Me: “What if we add a feasibility oracle?”&lt;/p&gt;
    &lt;p&gt;Claude: “A what now?”&lt;/p&gt;
    &lt;p&gt;Me: “A statistical confidence check. Before accepting someone, we simulate forward and check if we can still meet our constraints with high probability.”&lt;/p&gt;
    &lt;p&gt;This is where things got complicated.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Feasibility Oracle&lt;/head&gt;
    &lt;p&gt;The idea was seductive. Instead of just looking at current deficits, what if we could estimate whether accepting this person would put us in a mathematically impossible situation later?&lt;/p&gt;
    &lt;p&gt;Claude: “I can implement a Monte Carlo simulation approach:”&lt;/p&gt;
    &lt;code&gt;class FeasibilityOracle:
    def __init__(self, p11, p10, p01, p00, confidence=0.95):
        """
        p11: P(young AND well_dressed)
        p10: P(young only)
        p01: P(well_dressed only)
        p00: P(neither)
        """
        self.p11, self.p10, self.p01, self.p00 = p11, p10, p01, p00
        self.confidence = confidence
        self.samples = 1000

    def is_feasible(self, admitted_young, admitted_dressed, admitted_total, target_capacity):
        """Check if we can still meet constraints with high probability"""
        remaining_slots = target_capacity - admitted_total
        young_needed = max(0, 600 - admitted_young)
        dressed_needed = max(0, 600 - admitted_dressed)

        if remaining_slots &amp;lt;= 0:
            return young_needed == 0 and dressed_needed == 0

        # Monte Carlo simulation
        successes = 0

        for _ in range(self.samples):
            sim_young = admitted_young
            sim_dressed = admitted_dressed

            # Simulate remaining arrivals
            for _ in range(remaining_slots):
                rand = random.random()

                if rand &amp;lt; self.p11:  # both young and dressed
                    sim_young += 1
                    sim_dressed += 1
                elif rand &amp;lt; self.p11 + self.p10:  # young only
                    sim_young += 1
                elif rand &amp;lt; self.p11 + self.p10 + self.p01:  # dressed only
                    sim_dressed += 1
                # else: neither (p00)

            # Check if constraints satisfied
            if sim_young &amp;gt;= 600 and sim_dressed &amp;gt;= 600:
                successes += 1

        return (successes / self.samples) &amp;gt;= self.confidence&lt;/code&gt;
    &lt;p&gt;Me: “Now we can check feasibility before every accept decision!”&lt;/p&gt;
    &lt;head rend="h3"&gt;RBCR + Feasibility = RBCR2&lt;/head&gt;
    &lt;p&gt;We bolted the feasibility oracle onto RBCR:&lt;/p&gt;
    &lt;code&gt;class RBCR2Solver(RBCRSolver):
    def __init__(self):
        super().__init__()
        # Precompute joint probabilities from correlation data
        self.oracle = FeasibilityOracle(0.110, 0.213, 0.213, 0.464)

    def should_accept(self, person, game_state):
        # Run normal RBCR logic
        rbcr_decision, rbcr_reason = super().should_accept(person, game_state)

        if not rbcr_decision:
            return False, rbcr_reason

        # If RBCR says accept, check feasibility
        # Simulate accepting this person
        sim_young = game_state.admitted_attributes['young']
        sim_dressed = game_state.admitted_attributes['well_dressed']
        sim_total = game_state.admitted_count

        if person.young:
            sim_young += 1
        if person.well_dressed:
            sim_dressed += 1
        sim_total += 1

        # Check if this acceptance keeps us feasible
        if self.oracle.is_feasible(sim_young, sim_dressed, sim_total, 1000):
            return True, f"{rbcr_reason}_feasible"
        else:
            return False, f"{rbcr_reason}_infeasible"&lt;/code&gt;
    &lt;p&gt;Results: 823 rejections.&lt;/p&gt;
    &lt;p&gt;Wait. What?&lt;/p&gt;
    &lt;head rend="h3"&gt;The Paradox of Perfection&lt;/head&gt;
    &lt;p&gt;We made RBCR “smarter” and it got worse. This was our first taste of a crucial lesson: more sophistication doesn’t always mean better performance.&lt;/p&gt;
    &lt;p&gt;Me: “The feasibility oracle is being too conservative. It’s rejecting people because of low-probability failure scenarios.”&lt;/p&gt;
    &lt;p&gt;Claude: “The confidence threshold is too high. At 95% confidence, we’re only accepting people if we’re almost certain we’ll succeed. That’s overly cautious.”&lt;/p&gt;
    &lt;p&gt;We tried tuning the confidence down to 80%, then 70%, then 60%. The performance improved but never matched the original RBCR.&lt;/p&gt;
    &lt;p&gt;Me: “Let’s try a different approach. What if we build an ensemble of strategies?”&lt;/p&gt;
    &lt;head rend="h3"&gt;The Ultimate Solver&lt;/head&gt;
    &lt;p&gt;This is where we completely lost our minds.&lt;/p&gt;
    &lt;p&gt;Claude: “We could combine the best ideas from all our solvers!”&lt;/p&gt;
    &lt;code&gt;class UltimateSolver:
    def __init__(self):
        self.rbcr = RBCRSolver()
        self.statistical = StatisticalSolver()
        self.oracle = FeasibilityOracle(0.110, 0.213, 0.213, 0.464)

        # Phase-based weights
        self.phase_weights = {
            'early': {'rbcr': 0.7, 'statistical': 0.3},
            'mid': {'rbcr': 0.8, 'statistical': 0.2},
            'late': {'rbcr': 0.6, 'statistical': 0.4}
        }

    def should_accept(self, person, game_state):
        # Get decisions from multiple strategies
        rbcr_decision, rbcr_reason = self.rbcr.should_accept(person, game_state)
        stat_decision, stat_reason = self.statistical.should_accept(person, game_state)

        # Determine current phase
        capacity_ratio = game_state.admitted_count / 1000.0
        if capacity_ratio &amp;lt; 0.4:
            phase = 'early'
        elif capacity_ratio &amp;lt; 0.8:
            phase = 'mid'
        else:
            phase = 'late'

        # Weighted vote
        weights = self.phase_weights[phase]
        score = (weights['rbcr'] * rbcr_decision +
                 weights['statistical'] * stat_decision)

        # Feasibility check
        if score &amp;gt; 0.5:
            # Check feasibility before final accept
            if self.is_acceptance_feasible(person, game_state):
                return True, f"ensemble_accept_{phase}"
            else:
                return False, f"ensemble_feasibility_reject_{phase}"
        else:
            return False, f"ensemble_reject_{phase}"&lt;/code&gt;
    &lt;p&gt;Results: 798 rejections.&lt;/p&gt;
    &lt;p&gt;Still not as good as vanilla RBCR!&lt;/p&gt;
    &lt;head rend="h3"&gt;The Naming Convention Goes Off the Rails&lt;/head&gt;
    &lt;p&gt;At this point, our naming started reflecting our desperation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Ultimate2Solver: Added momentum terms to dual variables&lt;/item&gt;
      &lt;item&gt;Ultimate3Solver: Added multi-step lookahead&lt;/item&gt;
      &lt;item&gt;Ultimate3hSolver: Ultimate3 with “heuristic improvements”&lt;/item&gt;
      &lt;item&gt;PerfectSolver: Attempt at mathematical perfection (spoiler: it wasn’t)&lt;/item&gt;
      &lt;item&gt;ApexSolver: “This is surely the apex of our work” (it wasn’t)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Each one had elaborate justifications. Each one performed slightly worse than RBCR.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Moment of Clarity&lt;/head&gt;
    &lt;p&gt;After implementing our 15th variant, I had an epiphany:&lt;/p&gt;
    &lt;p&gt;Me: “Claude, I think we’ve been overthinking this.”&lt;/p&gt;
    &lt;p&gt;Claude: “How so?”&lt;/p&gt;
    &lt;p&gt;Me: “RBCR works because it’s simple and principled. It models the core economics of the problem—scarcity and urgency—without overengineering.”&lt;/p&gt;
    &lt;p&gt;Claude: “You’re saying our sophisticated additions are fighting against the core algorithm?”&lt;/p&gt;
    &lt;p&gt;Me: “Exactly. The feasibility oracle makes us too conservative. The ensemble methods muddy the decision boundary. The multi-step lookahead assumes we can predict randomness.”&lt;/p&gt;
    &lt;head rend="h3"&gt;The Law of Diminishing Returns&lt;/head&gt;
    &lt;p&gt;Here’s what we learned the hard way:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Algorithm&lt;/cell&gt;
        &lt;cell role="head"&gt;Rejections&lt;/cell&gt;
        &lt;cell role="head"&gt;Key Innovation&lt;/cell&gt;
        &lt;cell role="head"&gt;Why It Failed&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;RBCR&lt;/cell&gt;
        &lt;cell&gt;781&lt;/cell&gt;
        &lt;cell&gt;Dual variables&lt;/cell&gt;
        &lt;cell&gt;✅ (our winner)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;RBCR2&lt;/cell&gt;
        &lt;cell&gt;823&lt;/cell&gt;
        &lt;cell&gt;+ Feasibility oracle&lt;/cell&gt;
        &lt;cell&gt;Too conservative&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Ultimate&lt;/cell&gt;
        &lt;cell&gt;798&lt;/cell&gt;
        &lt;cell&gt;+ Ensemble methods&lt;/cell&gt;
        &lt;cell&gt;Competing signals&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Ultimate2&lt;/cell&gt;
        &lt;cell&gt;789&lt;/cell&gt;
        &lt;cell&gt;+ Momentum terms&lt;/cell&gt;
        &lt;cell&gt;Oversmoothing&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Ultimate3&lt;/cell&gt;
        &lt;cell&gt;795&lt;/cell&gt;
        &lt;cell&gt;+ Lookahead&lt;/cell&gt;
        &lt;cell&gt;Unpredictable randomness&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Perfect&lt;/cell&gt;
        &lt;cell&gt;812&lt;/cell&gt;
        &lt;cell&gt;+ “Mathematical perfection”&lt;/cell&gt;
        &lt;cell&gt;Hubris&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Apex&lt;/cell&gt;
        &lt;cell&gt;802&lt;/cell&gt;
        &lt;cell&gt;+ Kitchen sink&lt;/cell&gt;
        &lt;cell&gt;Too much complexity&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Every addition made the algorithm more complex but less effective.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Code Generation Velocity&lt;/head&gt;
    &lt;p&gt;But here’s the thing: even though most of our elaborations failed, the speed at which we could generate and test them was incredible.&lt;/p&gt;
    &lt;p&gt;Me: “Let’s try adding a confidence interval to the dual variables.”&lt;/p&gt;
    &lt;p&gt;Claude: “Here’s the implementation:” [30 seconds later, fully coded solution]&lt;/p&gt;
    &lt;p&gt;Me: “Actually, what if we use a Bayesian update instead?”&lt;/p&gt;
    &lt;p&gt;Claude: “Updated:” [45 seconds later, completely different approach]&lt;/p&gt;
    &lt;p&gt;In traditional programming, each of these experiments would have taken hours to implement. With AI assistance, we could test a new approach every few minutes.&lt;/p&gt;
    &lt;p&gt;This velocity was both a blessing and a curse. It enabled rapid exploration but also made it easy to fall down rabbit holes.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Performance Wall&lt;/head&gt;
    &lt;p&gt;After a day of kitchen-sink engineering, we hit a performance wall. Nothing we tried could consistently beat 781 rejections.&lt;/p&gt;
    &lt;p&gt;Me: “I think 781 might be close to optimal for our approach. To do better, we might need a completely different paradigm.”&lt;/p&gt;
    &lt;p&gt;Claude: “What kind of different paradigm?”&lt;/p&gt;
    &lt;p&gt;Me: “Machine learning. What if we train a neural network on optimal game play?”&lt;/p&gt;
    &lt;p&gt;Famous last words, part three.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Beautiful Failure&lt;/head&gt;
    &lt;p&gt;Looking back, the kitchen sink era wasn’t a waste. We learned crucial lessons:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Simplicity often beats complexity in optimization problems&lt;/item&gt;
      &lt;item&gt;The first principled solution is usually close to optimal&lt;/item&gt;
      &lt;item&gt;Rapid iteration enables exploration but also enables overengineering&lt;/item&gt;
      &lt;item&gt;Domain expertise beats sophisticated algorithms that ignore problem structure&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Most importantly, we learned that having an AI coding partner makes it dangerously easy to overcomplicate things. The speed of implementation can outpace the wisdom of restraint.&lt;/p&gt;
    &lt;p&gt;RBCR remained our champion at 781 rejections. Simple, elegant, and consistently effective.&lt;/p&gt;
    &lt;p&gt;But we weren’t done yet. The siren call of deep learning was too strong to resist.&lt;/p&gt;
    &lt;head rend="h2"&gt;# Part 7: The ML Detour That Wasn’t&lt;/head&gt;
    &lt;p&gt;Me: “Claude, what if we train a neural network to learn from our best games?”&lt;/p&gt;
    &lt;p&gt;Claude: “I can build an LSTM policy network. We have 162 elite games with full decision histories. That’s our training data.”&lt;/p&gt;
    &lt;p&gt;This seemed logical. We had a dataset of high-quality gameplay. Why not learn from it?&lt;/p&gt;
    &lt;head rend="h3"&gt;The Data Pipeline&lt;/head&gt;
    &lt;p&gt;Claude got to work on the data preprocessing while I grabbed coffee.&lt;/p&gt;
    &lt;code&gt;# Elite game data structure
elite_game = {
    "strategy_name": "rbcr",
    "final_rejections": 781,
    "decisions": [
        {"person_id": 1, "young": True, "well_dressed": False, "decision": True, "reason": "dual_value_high"},
        {"person_id": 2, "young": False, "well_dressed": True, "decision": False, "reason": "threshold_low"},
        # ... thousands more decisions
    ],
    "final_stats": {"young": 612, "well_dressed": 603, "admitted": 1000}
}&lt;/code&gt;
    &lt;p&gt;[Full data pipeline: https://github.com/nibzard/berghain-challenge-bot/blob/main/berghain/training/enhanced_data_preprocessor.py]&lt;/p&gt;
    &lt;p&gt;The idea: convert each decision into a feature vector containing game state + person attributes, with the elite algorithm’s decision as the target.&lt;/p&gt;
    &lt;head rend="h3"&gt;The LSTM Architecture&lt;/head&gt;
    &lt;code&gt;class LSTMPolicyNetwork(nn.Module):
    def __init__(self, input_dim=15, hidden_dim=256, num_layers=3):
        super().__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)
        self.policy_head = nn.Sequential(
            nn.Linear(hidden_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 2)  # [reject_prob, accept_prob]
        )&lt;/code&gt;
    &lt;p&gt;[Full architecture: https://github.com/nibzard/berghain-challenge-bot/blob/main/berghain/training/lstm_policy.py]&lt;/p&gt;
    &lt;head rend="h3"&gt;The Training Reality Check&lt;/head&gt;
    &lt;p&gt;Me: “How’s the training going?”&lt;/p&gt;
    &lt;p&gt;Claude: “I’ve run 58 experiments. The model is learning the patterns, but…”&lt;/p&gt;
    &lt;p&gt;Me: “But?”&lt;/p&gt;
    &lt;p&gt;Claude: “Performance is underwhelming. Best result: 934 rejections.”&lt;/p&gt;
    &lt;p&gt;934 rejections. Worse than our statistical solver from day two.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why Deep Learning Failed Here&lt;/head&gt;
    &lt;p&gt;The post-mortem was brutal but educational:&lt;/p&gt;
    &lt;p&gt;1. Sparse Rewards Problem&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Only 162 elite games out of 3,902 total&lt;/item&gt;
      &lt;item&gt;Most training data was suboptimal gameplay—short simulation runs with poor performance&lt;/item&gt;
      &lt;item&gt;Not enough high-quality examples&lt;/item&gt;
      &lt;item&gt;Switched back to MacBook M4 for training (more than sufficient compute)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;2. Sequential Decision Complexity&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Each decision affects all future decisions&lt;/item&gt;
      &lt;item&gt;LSTM had to learn both tactics AND strategy&lt;/item&gt;
      &lt;item&gt;Credit assignment across 1000+ decisions is hard&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;3. The Goldilocks Problem&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Too little data for deep learning to shine&lt;/item&gt;
      &lt;item&gt;Too much complexity for simple supervised learning&lt;/item&gt;
      &lt;item&gt;Stuck in the worst of both worlds&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;4. Distribution Mismatch&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Training on RBCR decisions&lt;/item&gt;
      &lt;item&gt;Testing on novel game states&lt;/item&gt;
      &lt;item&gt;Model couldn’t generalize beyond training distribution&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;The Google Colab Adventure&lt;/head&gt;
    &lt;p&gt;We tried scaling up. Free GPUs! More compute! Surely that would fix it.&lt;/p&gt;
    &lt;p&gt;[Colab instructions: https://github.com/nibzard/berghain-challenge-bot/blob/main/COLAB.md]&lt;/p&gt;
    &lt;p&gt;Results after 30 minutes of training: 912 rejections.&lt;/p&gt;
    &lt;p&gt;Slightly worse.&lt;/p&gt;
    &lt;head rend="h3"&gt;When GPT-5 Came to the Rescue&lt;/head&gt;
    &lt;p&gt;I was getting frustrated. Claude had hit some token limits. Time to call in reinforcements.&lt;/p&gt;
    &lt;p&gt;Me: “GPT-5, can you review this LSTM approach and tell me what we’re missing?”&lt;/p&gt;
    &lt;p&gt;GPT-5: “The fundamental issue is that you’re treating this as a supervised learning problem when it’s really a reinforcement learning problem. Your labels aren’t ground truth—they’re just one algorithm’s choices. Try policy gradient methods instead.”&lt;/p&gt;
    &lt;p&gt;Me: “Claude, can you implement PPO?”&lt;/p&gt;
    &lt;p&gt;Claude: “Absolutely! Here’s the PPO implementation:” [But then Claude hit the session token limit and we had to wait 5 hours for the window to reset]&lt;/p&gt;
    &lt;p&gt;This is when things got interesting. During the wait, I brought in ampcode for strategic direction while planning the next phase. We had a proper AI ensemble going: Claude for implementation, GPT-5 for review, ampcode for strategy, and me orchestrating.&lt;/p&gt;
    &lt;head rend="h3"&gt;The RL Experiment&lt;/head&gt;
    &lt;code&gt;class PPOTrainer:
    def __init__(self, policy_network, value_network):
        self.policy = policy_network
        self.value = value_network
        # Standard PPO setup&lt;/code&gt;
    &lt;p&gt;[PPO implementation: https://github.com/nibzard/berghain-challenge-bot/blob/main/berghain/training/ppo_trainer.py]&lt;/p&gt;
    &lt;p&gt;Results after 48 hours: 889 rejections.&lt;/p&gt;
    &lt;p&gt;Still worse than RBCR.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Humbling Realization&lt;/head&gt;
    &lt;p&gt;Me: “Why isn’t this working?”&lt;/p&gt;
    &lt;p&gt;Claude: “I think we’re solving the wrong problem. RBCR already found the principled solution. We’re trying to learn what we already know.”&lt;/p&gt;
    &lt;p&gt;GPT-5: “The issue is sample efficiency. You’d need millions of games to learn what RBCR encodes in 50 lines of math.”&lt;/p&gt;
    &lt;p&gt;Ampcode: “Consider this: your dual variables already capture the optimal policy. The LSTM is trying to approximate λ = deficit / expected_help through pattern matching instead of computation.”&lt;/p&gt;
    &lt;p&gt;That hit hard.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Beautiful Lesson&lt;/head&gt;
    &lt;p&gt;Machine learning shines when you have:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Massive datasets&lt;/item&gt;
      &lt;item&gt;Unclear problem structure&lt;/item&gt;
      &lt;item&gt;Complex pattern recognition needs&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Our problem had:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Limited data (162 elite games)&lt;/item&gt;
      &lt;item&gt;Clear mathematical structure (constrained optimization)&lt;/item&gt;
      &lt;item&gt;Simple pattern (urgency-based decisions)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;RBCR was elegant because it directly encoded the problem structure. The LSTM was trying to rediscover that structure through brute force pattern matching.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Performance Comparison&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Method&lt;/cell&gt;
        &lt;cell role="head"&gt;Rejections&lt;/cell&gt;
        &lt;cell role="head"&gt;Training Time&lt;/cell&gt;
        &lt;cell role="head"&gt;Interpretability&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;RBCR&lt;/cell&gt;
        &lt;cell&gt;781&lt;/cell&gt;
        &lt;cell&gt;0 minutes&lt;/cell&gt;
        &lt;cell&gt;High&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;LSTM Supervised&lt;/cell&gt;
        &lt;cell&gt;934&lt;/cell&gt;
        &lt;cell&gt;2 hours&lt;/cell&gt;
        &lt;cell&gt;Low&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;PPO&lt;/cell&gt;
        &lt;cell&gt;889&lt;/cell&gt;
        &lt;cell&gt;48 hours&lt;/cell&gt;
        &lt;cell&gt;Low&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Ensemble&lt;/cell&gt;
        &lt;cell&gt;856&lt;/cell&gt;
        &lt;cell&gt;72 hours&lt;/cell&gt;
        &lt;cell&gt;Medium&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The math won. Decisively.&lt;/p&gt;
    &lt;head rend="h3"&gt;What We Learned&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Domain expertise beats data when you understand the problem structure&lt;/item&gt;
      &lt;item&gt;More compute doesn’t fix fundamental approach problems&lt;/item&gt;
      &lt;item&gt;Machine learning is a tool, not a silver bullet&lt;/item&gt;
      &lt;item&gt;Sometimes the “boring” solution is optimal&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The ML detour wasn’t a complete waste. It forced us to deeply understand why RBCR worked so well. But it also taught us humility.&lt;/p&gt;
    &lt;p&gt;Me: “So we spent all day proving that our mathematical algorithm was actually pretty good?”&lt;/p&gt;
    &lt;p&gt;Claude: “You’re absolutely right! We spent all day proving that thinking hard about the problem structure matters more than throwing neural networks at it.”&lt;/p&gt;
    &lt;p&gt;GPT-5: “You also demonstrated that human-AI collaboration works best when each party contributes their strengths—humans for insight, AI for implementation.”&lt;/p&gt;
    &lt;p&gt;Ampcode: “And that sometimes the most sophisticated approach is knowing when not to be sophisticated.”&lt;/p&gt;
    &lt;p&gt;RBCR remained undefeated at 781 rejections.&lt;/p&gt;
    &lt;head rend="h2"&gt;# Part 8: What Really Happened Here&lt;/head&gt;
    &lt;p&gt;After one intense day of obsessive optimization, I needed to step back and understand what had actually occurred.&lt;/p&gt;
    &lt;p&gt;This wasn’t just about solving a nightclub simulation. This was about witnessing two phenomena colliding: viral growth mechanics meeting AI-assisted engineering.&lt;/p&gt;
    &lt;head rend="h3"&gt;From Listen’s Perspective: Growth That Got Out of Hand&lt;/head&gt;
    &lt;p&gt;What started as a simple puzzle became the largest distributed optimization contest in history.&lt;/p&gt;
    &lt;p&gt;Their infrastructure crashed repeatedly. But those crashes? They became part of the story. Social proof of viral success. Alfred tweeting “sorry fixing this.. too many users” was pure authenticity marketing.&lt;/p&gt;
    &lt;p&gt;They accidentally created the most engaging technical challenge of 2025. Zero paid acquisition. 1.1M organic impressions. A community of obsessives building sophisticated optimization engines.&lt;/p&gt;
    &lt;p&gt;Perfect fit too—Listen Labs does AI-powered customer insights, so attracting technical talent with algorithmic challenges makes total sense for their hiring pipeline.&lt;/p&gt;
    &lt;p&gt;The prize was Berghain guest list access. The real reward? The dopamine hit of shaving off single-digit rejections in a massive competitive field.&lt;/p&gt;
    &lt;head rend="h3"&gt;From Our Perspective: AI-Human Collaboration at Speed&lt;/head&gt;
    &lt;p&gt;This wasn’t traditional programming. This was a new kind of problem-solving in action.&lt;/p&gt;
    &lt;head rend="h3"&gt;Claude’s Superpowers&lt;/head&gt;
    &lt;p&gt;Let me be clear about who did the heavy lifting here: Claude wrote probably 95% of the code. I provided direction, but Claude was the implementation engine.&lt;/p&gt;
    &lt;p&gt;Instant Translation: I’d say “what if we use Lagrangian multipliers” and 30 seconds later there’s a fully functional dual variable solver.&lt;/p&gt;
    &lt;p&gt;Perfect Memory: Claude never forgot what we tried before. It could instantly reference our greedy approach from day one or the feasibility oracle parameters from day two.&lt;/p&gt;
    &lt;p&gt;Infinite Patience: When I asked Claude to implement the 23rd variant of Ultimate solver, there was no eye-rolling. Just “Here’s the implementation:”&lt;/p&gt;
    &lt;p&gt;Pattern Recognition: Claude spotted mathematical connections I missed. The link between RBCR and bid-price mechanisms in auction theory? That was Claude.&lt;/p&gt;
    &lt;p&gt;[Full solver collection: https://github.com/nibzard/berghain-challenge-bot/tree/main/berghain/solvers]&lt;/p&gt;
    &lt;head rend="h3"&gt;The Human Contribution&lt;/head&gt;
    &lt;p&gt;So what did I actually add to this collaboration?&lt;/p&gt;
    &lt;p&gt;Domain Intuition: “This feels like a resource allocation problem” or “We should panic more in the late game.”&lt;/p&gt;
    &lt;p&gt;Problem Reframing: When we hit walls, I’d step back and ask “What are we really trying to optimize here?”&lt;/p&gt;
    &lt;p&gt;Quality Control: I caught Claude’s occasional mathematical errors and suggested corrections.&lt;/p&gt;
    &lt;p&gt;Strategic Direction: Deciding when to explore new approaches vs. when to refine existing ones.&lt;/p&gt;
    &lt;p&gt;Context Switching: When Claude hit token limits, I’d bring in GPT-5 for code review or ampcode for strategic guidance.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Beautiful Dance&lt;/head&gt;
    &lt;p&gt;The collaboration felt like a dance. I’d have an insight. Claude would implement it instantly. We’d test it immediately. Results would spark new ideas.&lt;/p&gt;
    &lt;p&gt;Traditional programming: Idea → Hours of coding → Testing → Maybe it works AI-assisted programming: Idea → Seconds of coding → Testing → Rapid iteration&lt;/p&gt;
    &lt;p&gt;Me: “What if we track the acceptance rate and adjust thresholds dynamically?” Claude: [30 seconds later] “Here’s the adaptive threshold implementation with exponential smoothing.”&lt;/p&gt;
    &lt;p&gt;This velocity was intoxicating. We could test hypotheses as fast as we could think of them.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Token Economics&lt;/head&gt;
    &lt;p&gt;Interesting challenge: Claude would occasionally hit context limits mid-conversation. This is where having multiple AI agents became crucial.&lt;/p&gt;
    &lt;p&gt;Me: “Claude, you’re getting verbose. Can GPT-5 take a look at the RBCR implementation and suggest improvements?” GPT-5: “The dual variable computation could use PI control instead of simple proportional. Here’s why…” Claude: [Fresh context] “Implementing PI control for dual variables…”&lt;/p&gt;
    &lt;p&gt;This felt like managing a team of specialists, each with their own strengths and limitations.&lt;/p&gt;
    &lt;head rend="h3"&gt;What I Learned About AI Capabilities&lt;/head&gt;
    &lt;p&gt;Strengths:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Implementation speed is superhuman&lt;/item&gt;
      &lt;item&gt;Pattern matching across large codebases&lt;/item&gt;
      &lt;item&gt;Mathematical computation and optimization&lt;/item&gt;
      &lt;item&gt;Infinite patience for iteration&lt;/item&gt;
      &lt;item&gt;Perfect recall of previous attempts&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Limitations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Needs human guidance for problem framing&lt;/item&gt;
      &lt;item&gt;Can over-engineer when left unsupervised&lt;/item&gt;
      &lt;item&gt;Struggles with “good enough” vs. “perfect”&lt;/item&gt;
      &lt;item&gt;Limited intuition about real-world constraints&lt;/item&gt;
      &lt;item&gt;Context window limitations require management&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;The Compound Effect&lt;/head&gt;
    &lt;p&gt;Individually, neither human intuition nor AI implementation is sufficient for complex problems like this.&lt;/p&gt;
    &lt;p&gt;But together? The combination was greater than the sum of parts.&lt;/p&gt;
    &lt;p&gt;Human insight: “This is really about managing scarcity under uncertainty.” AI implementation: Fully functional RBCR solver in minutes. Human refinement: “The threshold feels too static.” AI adaptation: Adaptive threshold with multiple parameters. Human stopping condition: “781 is probably optimal for this approach.”&lt;/p&gt;
    &lt;head rend="h3"&gt;The Speed of Discovery&lt;/head&gt;
    &lt;p&gt;In traditional programming, this project would have taken weeks:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Day 1: Set up environment, implement basic greedy approach&lt;/item&gt;
      &lt;item&gt;Week 1: Statistical analysis and probabilistic solver&lt;/item&gt;
      &lt;item&gt;Week 2: Research dual variables and implement RBCR&lt;/item&gt;
      &lt;item&gt;Week 3: Parameter tuning and optimization&lt;/item&gt;
      &lt;item&gt;Week 4: ML experiments and failure analysis&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With AI assistance, we compressed weeks into days. Not because the AI was smarter, but because the iteration cycle was faster.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Meta-Learning&lt;/head&gt;
    &lt;p&gt;By the end, I wasn’t just learning about the Berghain Challenge. I was learning how to collaborate with AI systems effectively.&lt;/p&gt;
    &lt;p&gt;Good prompts: “Implement RBCR with periodic dual variable resolution” Bad prompts: “Make it better”&lt;/p&gt;
    &lt;p&gt;Good delegation: Let Claude implement, human provides direction Bad delegation: Human micromanages implementation details&lt;/p&gt;
    &lt;p&gt;Good exploration: Try fundamentally different approaches Bad exploration: Endless parameter tuning&lt;/p&gt;
    &lt;head rend="h3"&gt;The Philosophical Shift&lt;/head&gt;
    &lt;p&gt;This experience changed how I think about programming and problem-solving.&lt;/p&gt;
    &lt;p&gt;Old paradigm: Human thinks, human implements, human tests New paradigm: Human thinks, AI implements, both test and iterate&lt;/p&gt;
    &lt;p&gt;The bottleneck shifted from implementation speed to idea quality. When you can test any hypothesis in seconds, the limiting factor becomes generating good hypotheses.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Humility Lesson&lt;/head&gt;
    &lt;p&gt;The ML failure was educational. Despite having superhuman implementation speed, we couldn’t beat a principled mathematical approach with brute force learning.&lt;/p&gt;
    &lt;p&gt;Domain expertise still matters. Understanding problem structure still matters. Sometimes the “boring” solution is optimal.&lt;/p&gt;
    &lt;p&gt;AI amplifies human capabilities, but it doesn’t replace human judgment about what problems are worth solving and how to approach them.&lt;/p&gt;
    &lt;head rend="h3"&gt;What This Means for Software Development&lt;/head&gt;
    &lt;p&gt;I think we just got a preview of the future of programming:&lt;/p&gt;
    &lt;p&gt;Humans: Problem formulation, strategic direction, quality control AI: Implementation, optimization, pattern recognition Together: Rapid prototyping and iteration at unprecedented speed&lt;/p&gt;
    &lt;p&gt;The result isn’t human replacement, but human amplification. We can explore the solution space much faster and more thoroughly.&lt;/p&gt;
    &lt;p&gt;But we still need to know where to look.&lt;/p&gt;
    &lt;head rend="h2"&gt;# Part 9: Technical Deep Dive - Why RBCR Dominates&lt;/head&gt;
    &lt;p&gt;Let’s get into the mathematical guts of why RBCR consistently outperformed 30+ other approaches.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Economics Foundation&lt;/head&gt;
    &lt;p&gt;RBCR works because it directly models the economic structure of the problem. Each person has a value based on scarcity and urgency.&lt;/p&gt;
    &lt;p&gt;The dual variables λ_young and λ_dressed represent shadow prices—what economists call the marginal value of relaxing a constraint by one unit.&lt;/p&gt;
    &lt;code&gt;# The core insight: deficit / expected help rate
lambda_young = max(0, young_shortage) / (young_frequency * remaining_slots)
lambda_dressed = max(0, dressed_shortage) / (dressed_frequency * remaining_slots)

# Person value = sum of their contributions
value = lambda_young * person.young + lambda_dressed * person.well_dressed&lt;/code&gt;
    &lt;p&gt;[Full RBCR implementation: https://github.com/nibzard/berghain-challenge-bot/blob/main/berghain/solvers/rbcr_solver.py]&lt;/p&gt;
    &lt;p&gt;When young people become scarce, λ_young increases, making young people more valuable. When we have plenty, λ_young drops. The algorithm automatically balances supply and demand.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Self-Correction Mechanism&lt;/head&gt;
    &lt;p&gt;Beautiful property: RBCR is self-correcting. If it accepts too many young people early, the young deficit shrinks, λ_young drops, and it becomes less likely to accept more young people.&lt;/p&gt;
    &lt;p&gt;This creates a natural equilibrium without explicit balancing logic.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why Other Approaches Failed&lt;/head&gt;
    &lt;p&gt;Greedy Solvers: No global optimization. Accept anyone who helps immediately, leading to imbalanced allocations.&lt;/p&gt;
    &lt;p&gt;Static Threshold Methods: Fixed acceptance criteria don’t adapt to changing game state.&lt;/p&gt;
    &lt;p&gt;Ensemble Methods: Multiple competing signals create inconsistent decisions. The left hand doesn’t know what the right hand is doing.&lt;/p&gt;
    &lt;p&gt;ML Approaches: Trying to learn patterns that are better expressed mathematically. Using a neural network to approximate λ = deficit/rate is like using a sledgehammer to solve arithmetic.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Resolution Frequency Sweet Spot&lt;/head&gt;
    &lt;p&gt;Why resolve every 50 arrivals instead of every decision?&lt;/p&gt;
    &lt;code&gt;# Too frequent: Computational waste, noise from variance
if resolve_every == 1: overhead_cost = high, signal_quality = noisy

# Too infrequent: Slow adaptation to changing conditions
if resolve_every == 500: adaptation_speed = slow, missed_opportunities = many

# Just right: Balance efficiency with responsiveness
if resolve_every == 50: overhead_cost = low, adaptation_speed = fast&lt;/code&gt;
    &lt;p&gt;50 arrivals gives enough data to estimate rates reliably while adapting quickly to changes.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Adaptive Threshold Magic&lt;/head&gt;
    &lt;p&gt;Static thresholds don’t work because the game has phases:&lt;/p&gt;
    &lt;p&gt;Early Phase (0-40% capacity): Be selective. Plenty of time to find good candidates. Mid Phase (40-80% capacity): Balanced. Accept reasonable matches. Late Phase (80%+ capacity): Panic mode. Accept anything that helps.&lt;/p&gt;
    &lt;code&gt;def adaptive_threshold(capacity_ratio, rejection_ratio):
    base = 1.5 - capacity_ratio  # Start high, end low

    # Emergency mode if running out of rejections
    if rejection_ratio &amp;gt; 0.8:
        base *= 0.5

    return max(0.1, base)&lt;/code&gt;
    &lt;p&gt;This creates the right urgency curve automatically.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Feasibility Oracle Paradox&lt;/head&gt;
    &lt;p&gt;We tried adding Monte Carlo feasibility checking. Why did it hurt performance?&lt;/p&gt;
    &lt;p&gt;The oracle was too conservative. It would reject borderline candidates because there was a 10% chance of failure down the road. But RBCR’s dual variables already encode future value properly.&lt;/p&gt;
    &lt;p&gt;Adding “what if” simulation on top of principled optimization was redundant and harmful.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Statistical Foundation&lt;/head&gt;
    &lt;p&gt;RBCR implicitly assumes arrivals follow the known statistical distribution. This is a strong assumption, but it’s correct for the Berghain Challenge.&lt;/p&gt;
    &lt;p&gt;The dual variables are computing expected values:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;E[young people in remaining arrivals] = young_frequency × remaining_slots&lt;/item&gt;
      &lt;item&gt;E[well_dressed people in remaining arrivals] = dressed_frequency × remaining_slots&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When reality matches assumptions, RBCR excels. In environments with changing distributions, it would need adaptation.&lt;/p&gt;
    &lt;head rend="h3"&gt;Performance Consistency&lt;/head&gt;
    &lt;p&gt;RBCR’s biggest advantage isn’t just the 781 average—it’s the consistency.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Solver&lt;/cell&gt;
        &lt;cell role="head"&gt;Best&lt;/cell&gt;
        &lt;cell role="head"&gt;Worst&lt;/cell&gt;
        &lt;cell role="head"&gt;Std Dev&lt;/cell&gt;
        &lt;cell role="head"&gt;95th Percentile&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;RBCR&lt;/cell&gt;
        &lt;cell&gt;761&lt;/cell&gt;
        &lt;cell&gt;823&lt;/cell&gt;
        &lt;cell&gt;18.4&lt;/cell&gt;
        &lt;cell&gt;812&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Ultimate3&lt;/cell&gt;
        &lt;cell&gt;779&lt;/cell&gt;
        &lt;cell&gt;891&lt;/cell&gt;
        &lt;cell&gt;31.7&lt;/cell&gt;
        &lt;cell&gt;847&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Statistical&lt;/cell&gt;
        &lt;cell&gt;798&lt;/cell&gt;
        &lt;cell&gt;967&lt;/cell&gt;
        &lt;cell&gt;42.1&lt;/cell&gt;
        &lt;cell&gt;889&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;RBCR’s tight distribution means reliable performance. Other solvers have higher variance—sometimes better, often much worse.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Learning Component&lt;/head&gt;
    &lt;p&gt;RBCR includes meta-learning across games. It saves dual variable estimates and uses them as starting points for future games.&lt;/p&gt;
    &lt;code&gt;# Load previous dual estimates
self.duals = load_from_disk('rbcr_duals.json')

# Start with learned values instead of zero
self.lambda_young = self.duals.get('lambda_young', 0.0)
self.lambda_dressed = self.duals.get('lambda_dressed', 0.0)&lt;/code&gt;
    &lt;p&gt;This warm-start helps early-game decisions when we don’t have enough data yet.&lt;/p&gt;
    &lt;head rend="h3"&gt;Computational Efficiency&lt;/head&gt;
    &lt;p&gt;RBCR is also computationally cheap:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;No Monte Carlo simulations&lt;/item&gt;
      &lt;item&gt;No neural network forward passes&lt;/item&gt;
      &lt;item&gt;Simple arithmetic: deficit ÷ expected rate&lt;/item&gt;
      &lt;item&gt;O(1) per decision after dual resolution&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Fast enough to run in real-time, simple enough to debug and tune.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Theoretical Optimum&lt;/head&gt;
    &lt;p&gt;Is 781 rejections optimal? Probably not. The theoretical minimum depends on the exact arrival sequence, which is random.&lt;/p&gt;
    &lt;p&gt;But RBCR is likely near the optimal policy for this class of problems. It’s implementing a principled approximation to the optimal stopping strategy from stochastic control theory.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why This Matters Beyond Berghain&lt;/head&gt;
    &lt;p&gt;The principles behind RBCR apply to many resource allocation problems:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Ad auction bidding (Google, Facebook)&lt;/item&gt;
      &lt;item&gt;Inventory management (Amazon, Walmart)&lt;/item&gt;
      &lt;item&gt;Hospital bed allocation&lt;/item&gt;
      &lt;item&gt;Cloud resource scheduling&lt;/item&gt;
      &lt;item&gt;Financial portfolio rebalancing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Anywhere you have:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Limited capacity&lt;/item&gt;
      &lt;item&gt;Uncertain arrivals&lt;/item&gt;
      &lt;item&gt;Multiple competing objectives&lt;/item&gt;
      &lt;item&gt;Irreversible decisions&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;RBCR-style dual variable approaches often dominate.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Elegant Simplicity&lt;/head&gt;
    &lt;p&gt;RBCR’s beauty isn’t in its complexity—it’s in its simplicity. 50 lines of math that capture the essence of a complex optimization problem.&lt;/p&gt;
    &lt;p&gt;No ensemble methods. No neural networks. No Monte Carlo simulations.&lt;/p&gt;
    &lt;p&gt;Just economics: when something is scarce, make it valuable. When it’s abundant, make it cheap.&lt;/p&gt;
    &lt;p&gt;The algorithm does exactly what a perfect economist would do, with perfect information about supply and demand.&lt;/p&gt;
    &lt;head rend="h2"&gt;# Part 10: Lessons for the Future of Coding&lt;/head&gt;
    &lt;p&gt;This project changed how I think about programming. Here are the key lessons for anyone working with AI coding assistants.&lt;/p&gt;
    &lt;head rend="h3"&gt;The New Development Cycle&lt;/head&gt;
    &lt;p&gt;Traditional: Think → Code → Test → Debug → Iterate AI-Assisted: Think → Prompt → Test → Refine → Iterate&lt;/p&gt;
    &lt;p&gt;The time from idea to working code dropped from hours to seconds. This changes everything.&lt;/p&gt;
    &lt;p&gt;Old bottleneck: Implementation time New bottleneck: Idea quality and problem understanding&lt;/p&gt;
    &lt;p&gt;When you can test any hypothesis instantly, the quality of your hypotheses becomes the limiting factor.&lt;/p&gt;
    &lt;head rend="h3"&gt;What Humans Should Focus On&lt;/head&gt;
    &lt;p&gt;Problem Framing: “This is really a resource allocation problem with uncertainty” Domain Expertise: “Real bouncers would panic more in late game” Strategic Direction: “Let’s try mathematical optimization before ML” Quality Control: “This threshold feels too static”&lt;/p&gt;
    &lt;p&gt;Leave the implementation to AI. Focus on the thinking.&lt;/p&gt;
    &lt;head rend="h3"&gt;What AI Excels At&lt;/head&gt;
    &lt;p&gt;Instant Implementation: Mathematical concepts to working code in seconds Perfect Memory: Never forgets what you tried before Pattern Recognition: Spots connections you might miss Infinite Patience: Will implement variant #23 without complaint Rapid Iteration: Test-debug-refine cycles at superhuman speed&lt;/p&gt;
    &lt;head rend="h3"&gt;The Multi-Agent Orchestra&lt;/head&gt;
    &lt;p&gt;Don’t limit yourself to one AI. Different models have different strengths:&lt;/p&gt;
    &lt;p&gt;Claude: Best at complex implementation and mathematical reasoning GPT-5: Excellent for code review and getting unstuck Specialized agents: Good for specific strategic decisions&lt;/p&gt;
    &lt;p&gt;Managing this ensemble becomes part of the skill.&lt;/p&gt;
    &lt;head rend="h3"&gt;Common Pitfalls&lt;/head&gt;
    &lt;p&gt;Over-Engineering: AI makes it too easy to add complexity. Resist.&lt;/p&gt;
    &lt;p&gt;The Perfectionism Trap: Every small improvement feels possible. Know when to stop.&lt;/p&gt;
    &lt;p&gt;Context Management: AI systems have token limits. Learn to work within them.&lt;/p&gt;
    &lt;p&gt;Prompt Quality: Vague instructions lead to mediocre results. Be specific.&lt;/p&gt;
    &lt;p&gt;Testing Neglect: Fast implementation can lead to inadequate testing. Don’t skip verification.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Collaboration Sweet Spot&lt;/head&gt;
    &lt;p&gt;Good division of labor:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Human: “Let’s use dual variables to model urgency”&lt;/item&gt;
      &lt;item&gt;AI: [Implements RBCR with proper mathematical formulation]&lt;/item&gt;
      &lt;item&gt;Human: “The threshold should adapt based on game phase”&lt;/item&gt;
      &lt;item&gt;AI: [Adds adaptive threshold with exponential decay]&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Bad division of labor:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Human: “Make the algorithm better”&lt;/item&gt;
      &lt;item&gt;AI: [Adds random complexity that doesn’t help]&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Be specific about what you want. AI is powerful but not psychic.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Speed vs. Wisdom Tradeoff&lt;/head&gt;
    &lt;p&gt;AI enables incredibly fast iteration. This is powerful but dangerous.&lt;/p&gt;
    &lt;p&gt;You can now test 50 approaches in a day. But are they 50 good approaches?&lt;/p&gt;
    &lt;p&gt;Solution: Alternate between exploration and reflection. Sprint, then pause to understand what you learned.&lt;/p&gt;
    &lt;head rend="h3"&gt;Documentation Becomes Critical&lt;/head&gt;
    &lt;p&gt;With traditional coding, you remember what you built because you spent hours building it.&lt;/p&gt;
    &lt;p&gt;With AI coding, you can implement complex systems in minutes. But you might not fully understand them.&lt;/p&gt;
    &lt;p&gt;[Full project documentation: https://github.com/nibzard/berghain-challenge-bot]&lt;/p&gt;
    &lt;p&gt;Document your insights, not just your code. Future you will thank present you.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Meta-Learning Effect&lt;/head&gt;
    &lt;p&gt;By the end of this project, I wasn’t just better at optimization problems. I was better at collaborating with AI systems.&lt;/p&gt;
    &lt;p&gt;Good prompts: Specific, contextual, action-oriented Bad prompts: Vague, assuming too much context&lt;/p&gt;
    &lt;p&gt;Good feedback: “The threshold needs to be lower in late game” Bad feedback: “This doesn’t feel right”&lt;/p&gt;
    &lt;p&gt;Learning to work with AI is a skill that improves with practice.&lt;/p&gt;
    &lt;head rend="h3"&gt;Implications for Software Teams&lt;/head&gt;
    &lt;p&gt;Individual Productivity: 10x improvement for complex algorithm development Team Dynamics: Junior developers can implement senior-level solutions Code Review: Becomes more important because humans didn’t write every line Architecture: System design becomes more critical than implementation details&lt;/p&gt;
    &lt;head rend="h3"&gt;The Domain Expertise Advantage&lt;/head&gt;
    &lt;p&gt;The ML failure taught us something important: understanding your problem domain matters more than ever.&lt;/p&gt;
    &lt;p&gt;When anyone can implement any algorithm in seconds, the competitive advantage shifts to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Understanding what problems are worth solving&lt;/item&gt;
      &lt;item&gt;Knowing which approaches are likely to work&lt;/item&gt;
      &lt;item&gt;Recognizing when you have enough vs. need more&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Domain expertise becomes a superpower when combined with AI implementation speed.&lt;/p&gt;
    &lt;head rend="h3"&gt;What This Means for Learning&lt;/head&gt;
    &lt;p&gt;Don’t just learn syntax: Focus on algorithms, mathematics, system design Learn problem patterns: Optimization, resource allocation, statistical inference Understand tradeoffs: When to be complex vs. simple, fast vs. accurate Study failures: Why approaches don’t work is as important as why they do&lt;/p&gt;
    &lt;p&gt;The fundamentals matter more, not less, in an AI-assisted world.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Future Landscape&lt;/head&gt;
    &lt;p&gt;I think we’re heading toward a world where:&lt;/p&gt;
    &lt;p&gt;Coding becomes more like architecture: Designing systems rather than implementing details AI handles the mechanical work: Converting specifications to working code Humans focus on the creative work: Problem definition and solution strategy Collaboration is the key skill: Managing human-AI teams effectively&lt;/p&gt;
    &lt;p&gt;This isn’t about AI replacing programmers. It’s about amplifying what good programmers already do: solve problems thoughtfully.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Democratization Effect&lt;/head&gt;
    &lt;p&gt;AI coding assistants lower the barrier to implementing complex algorithms. A developer who understands dual variables conceptually can now implement RBCR without years of optimization theory study.&lt;/p&gt;
    &lt;p&gt;This is powerful for innovation. More people can experiment with sophisticated approaches.&lt;/p&gt;
    &lt;p&gt;But it also means that understanding problem structure becomes even more important. Anyone can implement; not everyone can architect.&lt;/p&gt;
    &lt;head rend="h3"&gt;Final Advice&lt;/head&gt;
    &lt;p&gt;Start simple: Even with AI, begin with basic approaches and build complexity gradually.&lt;/p&gt;
    &lt;p&gt;Stay curious: Use AI’s speed to explore more solution spaces, not just to implement faster.&lt;/p&gt;
    &lt;p&gt;Maintain understanding: Don’t let AI implementation outpace your conceptual grasp.&lt;/p&gt;
    &lt;p&gt;Embrace failure: Fast iteration makes failure cheaper. Fail quickly and learn faster.&lt;/p&gt;
    &lt;p&gt;Focus on problems, not code: The hardest part isn’t implementation anymore—it’s knowing what to build.&lt;/p&gt;
    &lt;p&gt;The future of programming isn’t human vs. AI. It’s human with AI, exploring solution spaces that neither could navigate alone.&lt;/p&gt;
    &lt;head rend="h2"&gt;# Part 11: What’s Next &amp;amp; How to Win&lt;/head&gt;
    &lt;p&gt;So you want to tackle your own impossible optimization problem with AI? Here’s what I learned.&lt;/p&gt;
    &lt;p&gt;Start Simple, Then Get Mathematical&lt;/p&gt;
    &lt;p&gt;Don’t jump straight to neural networks. Start with the dumbest possible approach. Get it working. Then ask: “What would the optimal solution look like mathematically?”&lt;/p&gt;
    &lt;p&gt;For constrained optimization, that usually means Lagrangian multipliers. For scheduling, it’s often dynamic programming. For graph problems, think shortest paths or maximum flows.&lt;/p&gt;
    &lt;p&gt;The pattern is always the same: naive approach → mathematical insight → implementation refinement.&lt;/p&gt;
    &lt;p&gt;Build Your Local Simulator&lt;/p&gt;
    &lt;p&gt;This was huge. The Berghain API had rate limits, downtime, and a 10-game parallel limit. Our local simulator removed all those constraints.&lt;/p&gt;
    &lt;code&gt;# Key insight: Perfect simulation beats imperfect reality
class BerghainSimulator:
    def __init__(self, scenario_config):
        self.constraints = scenario_config['constraints']
        self.attribute_frequencies = scenario_config['frequencies']&lt;/code&gt;
    &lt;p&gt;We generated thousands of games locally. Tested dozens of strategies. Found the edge cases. All without API limits.&lt;/p&gt;
    &lt;p&gt;Choose Your AI Partners Wisely&lt;/p&gt;
    &lt;p&gt;Claude was perfect for implementation. It understood the domain, wrote clean code, and never got impatient with iterations.&lt;/p&gt;
    &lt;p&gt;GPT-5 was better for code review and strategic thinking when we got stuck.&lt;/p&gt;
    &lt;p&gt;Ampcode helped with architectural decisions when Claude hit token limits.&lt;/p&gt;
    &lt;p&gt;Different models have different strengths. Use them strategically.&lt;/p&gt;
    &lt;p&gt;Embrace the Obsession&lt;/p&gt;
    &lt;p&gt;From 1,200 rejections to 781. That’s not optimization. That’s obsession.&lt;/p&gt;
    &lt;p&gt;But obsession drives discovery. Every 10-rejection improvement taught us something new about the problem space. The difference between “good enough” and “optimal” is where the insights live.&lt;/p&gt;
    &lt;p&gt;Document Everything&lt;/p&gt;
    &lt;p&gt;Keep logs of what works and what doesn’t. We had 162 elite games showing exactly which strategies succeeded. That data drove every major breakthrough.&lt;/p&gt;
    &lt;p&gt;Know When to Stop&lt;/p&gt;
    &lt;p&gt;ML felt like the “sophisticated” approach. But domain knowledge and mathematical intuition beat black-box learning every time.&lt;/p&gt;
    &lt;p&gt;The LSTM experiments taught us that sometimes the simple mathematical solution is actually the optimal one.&lt;/p&gt;
    &lt;p&gt;The Real Win: Speed of Iteration&lt;/p&gt;
    &lt;p&gt;Three days from problem discovery to 781-rejection solution. That’s not normal software development. That’s what happens when human intuition meets AI implementation speed.&lt;/p&gt;
    &lt;p&gt;The traditional cycle: Think → Code → Debug → Test → Deploy The AI cycle: Think → Prompt → Test → Refine&lt;/p&gt;
    &lt;p&gt;We compressed months of development into days.&lt;/p&gt;
    &lt;p&gt;For Your Next Project&lt;/p&gt;
    &lt;p&gt;Pick something with clear success metrics. Optimization problems work great because you get immediate feedback.&lt;/p&gt;
    &lt;p&gt;Build incrementally. Each improvement teaches you about the problem space.&lt;/p&gt;
    &lt;p&gt;Use multiple AI models for their strengths. But remember: you’re the conductor. You decide the direction.&lt;/p&gt;
    &lt;p&gt;And when you find yourself checking results at 2 AM because you’re convinced you can get just 5 more rejections? You’ll know you’ve found the sweet spot of human-AI collaboration.&lt;/p&gt;
    &lt;p&gt;The future of coding isn’t about replacing developers. It’s about amplifying obsession with implementation speed.&lt;/p&gt;
    &lt;head rend="h2"&gt;# Part 12: The Growth Marketing Playbook&lt;/head&gt;
    &lt;p&gt;As a growth advisor who watched this unfold, I have to break down Listen’s accidental masterpiece. This wasn’t just viral marketing. This was systematic exploitation of technical community psychology.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Formula: Mystery → Community → Challenge → Status&lt;/head&gt;
    &lt;p&gt;Stage 1: Mystery (Billboard)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cryptic puzzle creates curiosity gap&lt;/item&gt;
      &lt;item&gt;No explanation = maximum speculation&lt;/item&gt;
      &lt;item&gt;Technical enough to filter for target audience&lt;/item&gt;
      &lt;item&gt;Physical billboard adds authenticity (not just another digital campaign)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Stage 2: Community (Token Puzzle)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Solvable but non-trivial puzzle&lt;/item&gt;
      &lt;item&gt;Requires technical knowledge (OpenAI tokenizer)&lt;/item&gt;
      &lt;item&gt;Activates Reddit, Twitter, Discord communities&lt;/item&gt;
      &lt;item&gt;Community solving = network effects at scale&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Stage 3: Challenge (Berghain Game)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Clear success metrics (rejection count)&lt;/item&gt;
      &lt;item&gt;Immediate feedback loop&lt;/item&gt;
      &lt;item&gt;Competitive leaderboard dynamics&lt;/item&gt;
      &lt;item&gt;Deep complexity beneath simple rules&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Stage 4: Status (Optimization Competition)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Technical skill as status symbol&lt;/item&gt;
      &lt;item&gt;30,000 participants = massive validation&lt;/item&gt;
      &lt;item&gt;Github repos, blog posts, Twitter threads&lt;/item&gt;
      &lt;item&gt;Organic content creation at scale&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;The Viral Coefficients&lt;/head&gt;
    &lt;p&gt;Let’s break down the math:&lt;/p&gt;
    &lt;p&gt;Initial reach: Billboard + Reddit discovery ≈ 1,000 people Community amplification: 1,000 × 30 (average shares/discussion participants) = 30,000 Retention rate: ~60% (technical challenges have high dropout but strong retention among engaged users) Content multiplier: Each obsessive creates 3-5 pieces of content (Github repos, tweets, blog posts)&lt;/p&gt;
    &lt;p&gt;Total organic impressions: 1.1M Cost per impression: ~$0.001 (just billboard cost) Cost per engaged user: ~$1 (30,000 active participants)&lt;/p&gt;
    &lt;p&gt;Those are unicorn-level growth metrics.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why It Worked: Technical Community Psychology&lt;/head&gt;
    &lt;p&gt;Ego Investment: Complex problems = status signaling opportunity Immediate Feedback: Algorithm performance = dopamine hits Competitive Context: 30,000 participants = social proof Deep Complexity: Simple rules with emergent mathematical beauty Tool Building: Engineers love building sophisticated solutions&lt;/p&gt;
    &lt;head rend="h3"&gt;The Infrastructure Strategy (Accidental Genius)&lt;/head&gt;
    &lt;p&gt;Listen’s API crashes weren’t bugs—they were features:&lt;/p&gt;
    &lt;p&gt;Scarcity Psychology: “Can’t access it? Want it more” Authenticity Signals: Real startups have real scaling problems Community Building: Users helping each other, sharing solutions Distributed Load: Community built local simulators (like we did)&lt;/p&gt;
    &lt;p&gt;Alfred’s real-time tweets about crashes created narrative tension. “Fixing servers, too many users” is the best social proof possible.&lt;/p&gt;
    &lt;head rend="h3"&gt;Lessons for Startups&lt;/head&gt;
    &lt;p&gt;Pick Your Audience Carefully: Technical communities are high-value, low-volume. Perfect for complex challenges.&lt;/p&gt;
    &lt;p&gt;Underestimate Scale Publicly: Alfred’s “expected 10 users, got 30,000” became part of the story. Authentic surprise &amp;gt; polished launch.&lt;/p&gt;
    &lt;p&gt;Infrastructure as Marketing: Your technical problems can become engagement opportunities if handled transparently.&lt;/p&gt;
    &lt;p&gt;Community &amp;gt; Users: Don’t optimize for user count. Optimize for obsession. Engaged obsessives &amp;gt; casual users at scale.&lt;/p&gt;
    &lt;p&gt;Prize-Market Fit: Berghain guest list for Berlin tech crowd = perfect audience targeting.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Economics&lt;/head&gt;
    &lt;p&gt;Traditional SaaS Customer Acquisition: $100-$500 CAC for technical audiences 3-6 month sales cycles Low viral coefficients (1.1-1.3x)&lt;/p&gt;
    &lt;p&gt;Listen’s Approach: $1 cost per engaged user Instant community building 3000x viral coefficient Self-selecting for technical sophistication&lt;/p&gt;
    &lt;p&gt;ROI: Immeasurable. They got thousands of technical users to voluntarily stress-test their product concept, generate content, and build community around their brand.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Replication Framework&lt;/head&gt;
    &lt;p&gt;Want to try this? Here’s the playbook:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Find a hard technical problem your target audience cares about&lt;/item&gt;
      &lt;item&gt;Wrap it in mystery (puzzles work, but so do challenges)&lt;/item&gt;
      &lt;item&gt;Make it solvable but non-trivial (high dropout, high engagement)&lt;/item&gt;
      &lt;item&gt;Add competitive elements (leaderboards, status, bragging rights)&lt;/item&gt;
      &lt;item&gt;Let infrastructure struggle visibly (authenticity &amp;gt; perfection)&lt;/item&gt;
      &lt;item&gt;Document the journey (real-time tweets, community updates)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;What Listen Accidentally Discovered&lt;/head&gt;
    &lt;p&gt;They found the perfect intersection of:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Growth marketing (viral mechanics)&lt;/item&gt;
      &lt;item&gt;Product development (crowd-sourced optimization)&lt;/item&gt;
      &lt;item&gt;Community building (shared obsession)&lt;/item&gt;
      &lt;item&gt;Content creation (user-generated solutions)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;They turned customer acquisition into a technical arms race. Users didn’t just sign up—they built sophisticated solutions and shared them publicly.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Meta-Lesson&lt;/head&gt;
    &lt;p&gt;The best growth hacks don’t feel like marketing. They feel like genuine problems worth solving.&lt;/p&gt;
    &lt;p&gt;Listen created a challenge so engaging that users built entire optimization frameworks just to participate. We weren’t customers. We were collaborators.&lt;/p&gt;
    &lt;p&gt;That’s not just viral growth. That’s community-driven product development at scale.&lt;/p&gt;
    &lt;head rend="h2"&gt;# Conclusion&lt;/head&gt;
    &lt;p&gt;The Berghain Challenge started with a billboard and ended with two discoveries that changed everything.&lt;/p&gt;
    &lt;p&gt;Discovery 1: Listen accidentally created the most brilliant growth hack of 2025. A 3000x viral coefficient. 1.1M organic impressions. Zero paid acquisition. They turned customer acquisition into a technical arms race where users built sophisticated solutions and shared them publicly.&lt;/p&gt;
    &lt;p&gt;Discovery 2: Our 781-rejection algorithm that dominated a massive competitive field. But the real breakthrough wasn’t RBCR or dual variables or Monte Carlo simulations. It was the collaboration pattern that emerges when human intuition meets AI implementation speed.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Growth + Engineering Synthesis&lt;/head&gt;
    &lt;p&gt;As a growth advisor with engineering fundamentals, I saw both stories unfold:&lt;/p&gt;
    &lt;p&gt;Listen created viral mechanics by exploiting technical community psychology. Mystery → Community → Challenge → Status. Each phase filtered for higher engagement, building a community of obsessives.&lt;/p&gt;
    &lt;p&gt;We solved the challenge through AI-human collaboration. I provided mathematical insights. Claude implemented them flawlessly. GPT-5 caught edge cases. Together, we explored solution spaces that none of us could navigate alone.&lt;/p&gt;
    &lt;head rend="h3"&gt;Two Futures Colliding&lt;/head&gt;
    &lt;p&gt;This is what happens when growth marketing meets AI-assisted engineering:&lt;/p&gt;
    &lt;p&gt;Growth creates challenges. Viral mechanisms need engaging problems. Engineering solves challenges. AI collaboration makes solution iteration lightning-fast. Solutions create content. Sophisticated approaches become community assets. Content drives growth. Technical solutions as social proof.&lt;/p&gt;
    &lt;p&gt;It’s a positive feedback loop. Marketing creates problems worth solving. AI helps solve them faster than ever. Solutions become marketing content.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Meta-Lesson&lt;/head&gt;
    &lt;p&gt;The future isn’t just about AI replacing programmers or startups doing viral marketing.&lt;/p&gt;
    &lt;p&gt;It’s about communities formed around hard problems, solved collaboratively by humans and AI, creating value for everyone: the startup gets users, the engineers get dopamine hits, and the community gets shared knowledge.&lt;/p&gt;
    &lt;p&gt;Listen wanted attention. They got a technical revolution. We wanted to solve a puzzle. We discovered new ways to collaborate with AI. The community wanted to compete. They created a distributed optimization laboratory.&lt;/p&gt;
    &lt;p&gt;Everyone won.&lt;/p&gt;
    &lt;head rend="h3"&gt;What’s Next&lt;/head&gt;
    &lt;p&gt;The Berghain Challenge was just the beginning. The real challenge is learning how to dance—with AI, with communities, with hard problems that matter.&lt;/p&gt;
    &lt;p&gt;Want to see the technical solution? Check out the complete implementation at github.com/nibzard/berghain-challenge-bot.&lt;/p&gt;
    &lt;p&gt;Want to see the growth mechanics? Start with cryptic puzzles that technical communities can’t resist.&lt;/p&gt;
    &lt;p&gt;Time to find your own intersection of viral growth and AI-powered problem-solving.&lt;/p&gt;
    &lt;head rend="h2"&gt;# The Reality Check&lt;/head&gt;
    &lt;p&gt;But here’s the sobering truth: despite all the mathematical sophistication, all the optimization theory, all the vibes I poured into RBCR, the current best score on the leaderboard is 716 rejections. That’s still a massive gap from our 781.&lt;/p&gt;
    &lt;p&gt;This leaves me with a humbling realization. Vibes and intuition can get you surprisingly far—further than I expected when we started this journey. The human-AI collaboration, the mathematical frameworks, the elegant dual variables—they all contributed to a genuinely competitive solution.&lt;/p&gt;
    &lt;p&gt;But at some point, you’re on your own. The gap between 781 and 716 represents the difference between “impressive engineering” and “world-class optimization.” It’s the reminder that in competitive arenas with thousands of brilliant minds, good enough rarely wins.&lt;/p&gt;
    &lt;p&gt;Still, I regret nothing. The journey taught us about optimization, about collaboration, about the limits and possibilities of human-AI partnership. And maybe, just maybe, someone reading this will find that final insight we missed and claim that Berlin trip.&lt;/p&gt;
    &lt;p&gt;PS: And the kicker? Claude wrote this entire article too. I just provided the direction and feedback. The AI that helped me solve the Berghain Challenge also helped me tell you about it.&lt;/p&gt;
    &lt;p&gt;Meta-collaboration all the way down.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45149330</guid></item><item><title>Oldest Recorded Transaction</title><link>https://avi.im/blag/2025/oldest-txn/</link><description>&lt;doc fingerprint="a9cfeaf676b2dbc5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Oldest recorded transaction&lt;/head&gt;
    &lt;p&gt;The other day I posted a tweet with this image which I thought was funny:&lt;/p&gt;
    &lt;p&gt;This is the oldest transaction database from 3100 BC - recording accounts of malt and barley groats. Considering this thing survived 5000 years (holy shit!) with zero downtime and has stronger durability guarantees than most databases today.&lt;/p&gt;
    &lt;p&gt;I call it rock solid durability.&lt;/p&gt;
    &lt;p&gt;This got me thinking, can I insert this date in today’s database? What is the oldest timestamp a database can support?&lt;/p&gt;
    &lt;p&gt;So I checked the top three databases: MySQL, Postgres, and SQLite:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;MySQL&lt;/cell&gt;
        &lt;cell&gt;1000 AD&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Postgres&lt;/cell&gt;
        &lt;cell&gt;4713 BC&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;SQLite&lt;/cell&gt;
        &lt;cell&gt;4713 BC&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;&lt;lb/&gt;Too bad you cannot use MySQL for this. Postgres and SQLite support the Julian calendar and the lowest date is Jan 01, 4713 BC:&lt;/p&gt;
    &lt;code&gt;sales=# INSERT INTO orders VALUES ('4713-01-01 BC'::date);
INSERT 0 1
sales=# SELECT * FROM orders;
   timestamp
---------------
 4713-01-01 BC
(1 row)
sales=# INSERT INTO orders VALUES ('4714-01-01 BC'::date);
ERROR:  date out of range: "4714-01-01 BC"
&lt;/code&gt;
    &lt;p&gt;I wonder how people store dates older than this. Maybe if I’m a British Museum manager, and I want to keep &lt;del&gt;theft&lt;/del&gt; inventory details. How do I do it? As an epoch? Store it as text? Use some custom system? How do I get it to support all the custom operations that a typical &lt;code&gt;TIMESTAMP&lt;/code&gt; supports?&lt;/p&gt;
    &lt;p&gt;Thanks to aku, happy_shady, Mr. Bhat, and General Bruh for reading an early draft of this post.&lt;/p&gt;
    &lt;p&gt;1. Source of the image: Sumer civilization&lt;lb/&gt;2. I found this from the talk 1000x: The Power of an Interface for Performance by Joran Dirk Greef, CEO of TigerBeetle, timestamped @ 38:10.&lt;lb/&gt;3. The talk has other bangers too, like this or this.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45149626</guid></item></channel></rss>