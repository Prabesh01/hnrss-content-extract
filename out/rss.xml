<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 04 Dec 2025 20:42:27 +0000</lastBuildDate><item><title>It’s time to free JavaScript (2024)</title><link>https://javascript.tm/letter</link><description>&lt;doc fingerprint="4737c13992a7be78"&gt;
  &lt;main&gt;
    &lt;p&gt;Dear Oracle,&lt;/p&gt;
    &lt;p&gt;You have long ago abandoned the JavaScript trademark, and it is causing widespread, unwarranted confusion and disruption.&lt;/p&gt;
    &lt;p&gt;JavaScript is the world’s most popular programming language, powering websites everywhere. Yet, few of the millions who program in it realize that JavaScript is a trademark you, Oracle, control. The disconnect is glaring: JavaScript has become a general-purpose term used by countless individuals and companies, independent of any Oracle product.&lt;/p&gt;
    &lt;p&gt;Oracle’s hold on the JavaScript trademark clearly fits the legal definition of trademark abandonment. A previous blog post addressed this issue, requesting that you, Oracle, release the trademark. Unsurprisingly, the request was met with silence. It is therefore time to take active steps in order to bring the JavaScript trademark into the public domain, where it belongs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Trademark abandonment&lt;/head&gt;
    &lt;p&gt;Title 15 of the United States Code, section 1127, states:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;A mark shall be deemed to be “abandoned” if either of the following occurs:&lt;/p&gt;
      &lt;item&gt;When its use has been discontinued with intent not to resume such use. Intent not to resume may be inferred from circumstances. Nonuse for 3 consecutive years shall be prima facie evidence of abandonment. “Use” of a mark means the bona fide use of such mark made in the ordinary course of trade, and not made merely to reserve a right in a mark.&lt;/item&gt;
      &lt;item&gt;When any course of conduct of the owner, including acts of omission as well as commission, causes the mark to become the generic name for the goods or services on or in connection with which it is used or otherwise to lose its significance as a mark. Purchaser motivation shall not be a test for determining abandonment under this paragraph.&lt;/item&gt;
    &lt;/quote&gt;
    &lt;p&gt;In the case of JavaScript, both criteria apply.&lt;/p&gt;
    &lt;head rend="h2"&gt;Netscape, Sun, Oracle&lt;/head&gt;
    &lt;p&gt;The JavaScript trademark is currently held by Oracle America, Inc. (US Serial Number: 75026640, US Registration Number: 2416017). How did this come to be?&lt;/p&gt;
    &lt;p&gt;In 1995, Netscape partnered with Sun Microsystems to create interactive websites. Brendan Eich famously spent only 10 days creating the first version of JavaScript, a dynamic programming language with a rough syntactic lineage from Sun’s Java language. As a result of this partnership, Sun held the JavaScript trademark. In 2009, Oracle acquired Sun Microsystems and the JavaScript trademark as a result.&lt;/p&gt;
    &lt;p&gt;The trademark is simply a relic of this acquisition. Neither Sun nor Oracle has ever built a product using the mark. Legal staff, year after year, have renewed the trademark without question. It’s likely that only a few within Oracle even know they possess the JavaScript trademark, and even if they do, they likely don’t understand the frustration it causes within the developer community.&lt;/p&gt;
    &lt;head rend="h2"&gt;Use it or lose it&lt;/head&gt;
    &lt;p&gt;Oracle has abandoned the JavaScript trademark through nonuse.&lt;/p&gt;
    &lt;p&gt;Oracle has never seriously offered a product called JavaScript. In the 1990s and early 2000s, Netscape Navigator, which supported JavaScript as a browser feature, was a key player. However, Netscape’s usage and influence faded by 2003, and the browser saw its final release in 2008. JavaScript, meanwhile, evolved into a widely used, independent programming language, embedded in multiple browsers, entirely separate from Oracle.&lt;/p&gt;
    &lt;p&gt;The most recent specimen, filed with the USPTO in 2019, references nodejs.org (a project created by Ryan Dahl, the author of this letter) and Oracle’s JavaScript Extension Toolkit (JET). But Node.js is not an Oracle product, and JET is merely a set of JavaScript libraries for Oracle services, particularly Oracle Cloud. There are millions of JavaScript libraries; JET is not special.&lt;/p&gt;
    &lt;p&gt;(Oracle is not even a member of the OpenJS Foundation - the body that the Node.js project lives under now. Nor does Oracle have any involvement whatsoever in the development of Node.js.)&lt;/p&gt;
    &lt;p&gt;Oracle also offers GraalVM, a JVM that can execute JavaScript, among other languages. But GraalVM is far from a canonical JavaScript implementation; engines like V8, JavaScriptCore, and SpiderMonkey hold that role. GraalVM’s product page doesn’t even mention “JavaScript”; you must dig into the documentation to find its support.&lt;/p&gt;
    &lt;p&gt;Oracle’s use of JavaScript in GraalVM and JET does not reflect genuine use of the trademark. These weak connections do not satisfy the requirement for consistent, real-world use in trade.&lt;/p&gt;
    &lt;head rend="h2"&gt;A generic term&lt;/head&gt;
    &lt;p&gt;A mark can also be considered abandoned if it becomes a generic term.&lt;/p&gt;
    &lt;p&gt;In 1996, Netscape announced a meeting of the ECMA International standards organization to standardize the JavaScript programming language. Sun (now Oracle), refused to give up the “JavaScript” mark for this use though, so it was decided that the language would be called “ECMAScript” instead. (Microsoft happily offered up “JScript”, but no-one else wanted that.) Brendan Eich, the creator of JavaScript and a co-signatory of this letter, wrote in 2006 that “ECMAScript was always an unwanted trade name that sounds like a skin disease.”&lt;/p&gt;
    &lt;p&gt;Ecma International formed TC39, a technical steering committee, which publishes ECMA-262, the specification for JavaScript. This committee includes participants from all major browsers, like Google’s Chrome, Apple’s Safari, and Mozilla’s Firefox, as well as representatives from server-side JavaScript runtimes like Node.js and Deno.&lt;/p&gt;
    &lt;p&gt;Oracle’s ownership of the JavaScript trademark only causes confusion. The term “JavaScript” is used freely by millions of developers, companies, and organizations around the world, with no interference from Oracle. Oracle has done nothing to assert its rights over the JavaScript name, likely because they do not believe their claim to the mark would hold up in court. Unlike typical trademark holders who protect their trademarks by extracting licensing fees or enforcing usage restrictions, Oracle has allowed the JavaScript name to be used by anyone. This inaction further supports the argument that the trademark has lost its significance and has become generic.&lt;/p&gt;
    &lt;p&gt;Programmers working with JavaScript have formed innumerable community organizations. These organizations, like the standards bodies, have been forced to painstakingly avoid naming the programming language they are built around—for example, JSConf. Sadly, without risking a legal trademark challenge against Oracle, there can be no “JavaScript Conference” nor a “JavaScript Specification.” The world’s most popular programming language cannot even have a conference in its name.&lt;/p&gt;
    &lt;p&gt;There is a vast misalignment between the trademark’s ownership and its widespread, generic use.&lt;/p&gt;
    &lt;head rend="h2"&gt;Free the mark&lt;/head&gt;
    &lt;p&gt;By law, a trademark is abandoned if it is either not used or becomes a generic term. Both apply to JavaScript.&lt;/p&gt;
    &lt;p&gt;It’s time for the USPTO to end the JavaScript trademark and recognize it as a generic name for the world’s most popular programming language, which has multiple implementations across the industry.&lt;/p&gt;
    &lt;p&gt;Oracle, you likely have no real business interest in the mark. It’s renewed simply because legal staff are obligated to renew all trademarks, regardless of their relevance or use.&lt;/p&gt;
    &lt;p&gt;We urge you to release the mark into the public domain. However, asking nicely has been tried before, and it was met with silence. If you do not act, we will challenge your ownership by filing a petition for cancellation with the USPTO.&lt;/p&gt;
    &lt;head rend="h2"&gt;To you, the readers of this letter:&lt;/head&gt;
    &lt;p&gt;If you agree with us, you are encouraged to sign this open letter below. Your support will help raise awareness and add weight to this cause. If you want to sign as an organization (minimum 25 employees), please email companies@javascript.tm.&lt;/p&gt;
    &lt;p&gt;In addition, we’re seeking pro bono assistance from lawyers with experience in trademark law to help file a Petition for Trademark Cancellation with the USPTO. It’s likely that simply asking nicely will not get a response from Oracle; a legal challenge must be made. Reach out to lawyers@javascript.tm if you can help.&lt;/p&gt;
    &lt;p&gt;Sincerely,&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46145365</guid><pubDate>Thu, 04 Dec 2025 09:01:55 +0000</pubDate></item><item><title>Tunnl.gg</title><link>https://tunnl.gg</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46145902</guid><pubDate>Thu, 04 Dec 2025 10:15:53 +0000</pubDate></item><item><title>PGlite – Embeddable Postgres</title><link>https://pglite.dev/</link><description>&lt;doc fingerprint="e74292d12d3170e0"&gt;
  &lt;main&gt;&lt;head rend="h2"&gt;Lightweight&lt;/head&gt;&lt;p&gt;A complete WASM build of Postgres that's under 3MB Gzipped.&lt;/p&gt;&lt;p&gt;Embeddable Postgres&lt;/p&gt;&lt;p&gt;Run a full Postgres database locally in WASM with reactivity and live sync.&lt;/p&gt;&lt;p&gt;Create and publish a Postgres database using AI Supabase:&lt;/p&gt;built on PGlite by&lt;p&gt;This is a full PGlite Postgres running in your browser. pgvector!&lt;/p&gt;It even includes&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46146133</guid><pubDate>Thu, 04 Dec 2025 10:52:42 +0000</pubDate></item><item><title>I ignore the spotlight as a staff engineer</title><link>https://lalitm.com/software-engineering-outside-the-spotlight/</link><description>&lt;doc fingerprint="f7d094139d346c2f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why I Ignore The Spotlight as a Staff Engineer&lt;/head&gt;
    &lt;p&gt;Lately I’ve been reading Sean Goedecke’s essays on being a Staff+ engineer. His work (particularly Software engineering under the spotlight and It’s Not Your Codebase) is razor-sharp and feels painfully familiar to anyone in Big Tech.&lt;/p&gt;
    &lt;p&gt;On paper, I fit the mold he describes: I’m a Senior Staff engineer at Google. Yet, reading his work left me with a lingering sense of unease. At first, I dismissed this as cynicism. After reflecting, however, I realized the problem wasn’t Sean’s writing but my reading.&lt;/p&gt;
    &lt;p&gt;Sean isn’t being bleak; he is accurately describing how to deal with a world where engineers are fungible assets and priorities shift quarterly. But my job looks nothing like that and I know deep down that if I tried to operate in that environment or in the way he described I’d burn out within months.&lt;/p&gt;
    &lt;p&gt;Instead I’ve followed an alternate path, one that optimizes for systems over spotlights, and stewardship over fungibility.&lt;/p&gt;
    &lt;head rend="h2"&gt;We Live in Different Worlds&lt;/head&gt;
    &lt;p&gt;The foundational reason for our diverging paths is that Sean and I operate in entirely different worlds with different laws governing them.&lt;/p&gt;
    &lt;p&gt;From Sean’s resume, my understanding is that he has primarily worked in product teams 1 building for external customers. Business goals pivot quarterly, and success is measured by revenue or MAU. Optimizing for the “Spotlight” makes complete sense in this environment. Product development at big tech scale is a crowded room: VPs, PMs and UX designers all have strong opinions. To succeed, you have to be agile and ensure you are working specifically on what executives are currently looking at.&lt;/p&gt;
    &lt;p&gt;On the other hand, I’ve spent my entire career much more behind the scenes: in developer tools and infra teams.&lt;/p&gt;
    &lt;p&gt;My team’s customers are thousands of engineers in Android, Chrome, and throughout Google 2. End users of Google products don’t even know we exist; our focus is on making sure developers have the tools to collect product and performance metrics and debug issues using detailed traces.&lt;/p&gt;
    &lt;p&gt;In this environment, our relationship with leadership is very different. We’re never the “hot project everyone wants,” so execs are not fighting to work with us. In fact, my team has historically struggled to hire PMs. The PM career ladder at Google incentivizes splashy external launches so we cannot provide good “promotion material” for them. Also, our feedback comes directly from engineers. Adding a PM in the middle causes a loss in translation, slowing down a tight, high-bandwidth feedback loop.&lt;/p&gt;
    &lt;p&gt;All of this together means our team operates “bottom-up”: instead of execs telling us “you should do X”, we figure out what we think will have the most impact to our customers and work on building those features and tools. Execs ensure that we’re actually solving these problems by considering our impact on more product facing teams.&lt;/p&gt;
    &lt;head rend="h2"&gt;Compounding Returns of Stewardship&lt;/head&gt;
    &lt;p&gt;In the product environments Sean describes, where goals pivot quarterly and features are often experimental, speed is the ultimate currency. You need to ship, iterate, and often move on before the market shifts. But in Infrastructure and Developer Experience, context is the currency.&lt;/p&gt;
    &lt;p&gt;Treating engineers as fungible assets destroys context. You might gain fresh eyes, but you lose the implicit knowledge of how systems actually break. Stewardship, staying with a system long-term, unlocks compounding returns that are impossible to achieve on a short rotation.&lt;/p&gt;
    &lt;p&gt;The first is efficiency via pattern matching. When you stay in one domain for years, new requests are rarely truly “new.” I am not just debugging code; I am debugging the intersection of my tools and hundreds of diverse engineering teams. When a new team comes to me with a “unique” problem, I can often reach back in time: “We tried this approach in 2021 with the Camera team; here is exactly why it failed, and here is the architecture that actually works”.&lt;/p&gt;
    &lt;p&gt;But the more powerful return is systemic innovation. If you rotate teams every year, you are limited to solving acute bugs that are visible right now. Some problems, however, only reveal their shape over long horizons.&lt;/p&gt;
    &lt;p&gt;Take Bigtrace, a project I recently led; it was a solution that emerged solely because I stuck around long enough to see the shape of the problem:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Start of 2023 (Observation): I began noticing a pattern. Teams across Google were collecting terabytes or even petabytes of performance traces, but they were struggling to process them. Engineers were writing brittle, custom pipelines to parse data, often complaining about how slow and painful it was to iterate on their analysis.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Most of 2023 (Research): I didn’t jump to build a production system. Instead, I spent the best part of a year prototyping quietly in the background while working on other projects. I gathered feedback from these same engineers who had complained and because I had established long-term relationships, they gave me honest and introspective feedback. I learned what sort of UX, latency and throughput requirements they had and figured out how I could meet them.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;End of 2023 to Start of 2024 (Execution): We built and launched Bigtrace, a distributed big data query engine for traces. Today, it processes over 2 billion traces a month and is a critical part of the daily workflow for 100+ engineers.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If I had followed the advice to “optimize for fungibility” (i.e. if I had switched teams in 2023 to chase a new project) Bigtrace would not exist.&lt;/p&gt;
    &lt;p&gt;Instead, I would have left during the research phase and my successor would have seen the same “noise” of engineers complaining. But without the historical context to recognize a missing puzzle piece, I think they would have struggled to build something like Bigtrace.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Power of “No”&lt;/head&gt;
    &lt;p&gt;One of the most seductive arguments for chasing the “Spotlight” is that it guarantees resources and executive attention. But that attention is a double-edged sword.&lt;/p&gt;
    &lt;p&gt;High-visibility projects are often volatile. They come with shifting executive whims, political maneuvering, and often end up in situations where long-term quality is sacrificed for short-term survival. For some engineers, navigating this chaos is a thrill. For those of us who care about system stability, it feels like a trap.&lt;/p&gt;
    &lt;p&gt;The advantage of stewardship is that it generates a different kind of capital: trust. When you have spent years delivering reliable tools, you earn the political capital to say “No” to the spotlight when it threatens the product.&lt;/p&gt;
    &lt;p&gt;Recently, the spotlight has been on AI. Every team is under pressure to incorporate it. We have been asked repeatedly: “Why don’t you integrate LLMs into Perfetto?” If I were optimizing for visibility, the answer would be obvious: build an LLM wrapper, demo it to leadership, and claim we are “AI-first.” It would be an easy win for my career.&lt;/p&gt;
    &lt;p&gt;But as a steward of the system, I know that one of Perfetto’s core values is precision. When a kernel developer is debugging a race condition, they need exact timestamps, not a hallucination. Users trust that when we tell them “X is the problem” that it actually is the problem and they’re not going to go chasing their tail for the next week, debugging an issue which doesn’t exist.&lt;/p&gt;
    &lt;p&gt;But it’s important not to take this too far: skepticism shouldn’t become obstructionism. With AI, it’s not “no forever” but “not until it can be done right” 3.&lt;/p&gt;
    &lt;p&gt;A spotlight-seeking engineer might view this approach as a missed opportunity; I view it as protecting what makes our product great: user trust.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Alternate Currency of Impact&lt;/head&gt;
    &lt;p&gt;The most common fear engineers have about leaving the “Spotlight” is career stagnation. The logic goes: If I’m not launching flashy features at Google I/O, and my work isn’t on my VP’s top 5 list, how will I ever get promoted to Staff+?&lt;/p&gt;
    &lt;p&gt;It is true that you lose the currency of “Executive Visibility.” But in infrastructure, you gain two alternate currencies that are just as valuable, and potentially more stable.&lt;/p&gt;
    &lt;p&gt;Shadow Hierarchy&lt;/p&gt;
    &lt;p&gt;In a product organization, you often need to impress your manager’s manager. In an infrastructure organization, you need to impress your customers’ managers.&lt;/p&gt;
    &lt;p&gt;I call this the Shadow Hierarchy. You don’t need your VP to understand the intricacies of your code. You need the Staff+ Engineers in other critical organizations to need your tools.&lt;/p&gt;
    &lt;p&gt;When a Senior Staff Engineer in Pixel tells their VP, “We literally cannot debug the next Pixel phone without Perfetto”, that statement carries immense weight. It travels up their reporting chain, crosses over at the Director/VP level, and comes back down to your manager.&lt;/p&gt;
    &lt;p&gt;This kind of advocacy is powerful because it is technical, not political. It is hard to fake. When you are a steward of a critical system, your promotion packet is filled with testimonials from the most respected engineers in the company saying, “This person’s work enabled our success”.&lt;/p&gt;
    &lt;p&gt;Utility Ledger&lt;/p&gt;
    &lt;p&gt;While product teams might be poring over daily active users or revenue, we rely on metrics tracking engineering health:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Utility: Every bug fixed using our tools is an engineer finding us useful. It is the purest measure of utility.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Criticality: If the Pixel team uses Perfetto to debug a launch-blocking stutter, or Chrome uses it to fix a memory leak, our impact is implicitly tied to their success.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ubiquity: Capturing a significant percentage of the engineering population proves you’ve created a technical “lingua franca”. This becomes especially obvious when you see disconnected parts of the company collaborating with each other, using shared Perfetto traces as a “reference everyone understands”.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Scale: Ingesting petabytes of data or processing billions of traces proves architectural resilience better than any design doc.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When you combine Criticality (VIP teams need this) with Utility (bugs are being fixed), you create a promotion case that is immune to executive reorganizations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Archetypes and Agency&lt;/head&gt;
    &lt;p&gt;Staff Archetypes&lt;/p&gt;
    &lt;p&gt;I am far from the first to notice the idea of “there are multiple ways to be a staff software engineer”. In his book Staff Engineer, Will Larson categorizes Staff-plus engineers into four distinct archetypes.&lt;/p&gt;
    &lt;p&gt;Sean describes the Solver or the Right Hand: engineers who act as agents of executive will, dropping into fires and moving on once the problem is stabilized. I am describing the Architect or the Tech Lead: roles defined by long-term ownership of a specific domain and deep technical context.&lt;/p&gt;
    &lt;p&gt;The “Luck” Rebuttal&lt;/p&gt;
    &lt;p&gt;I can hear the criticism already: “You just got lucky finding your team. Most of us don’t have that luxury.”&lt;/p&gt;
    &lt;p&gt;There are two caveats to all my advice in this post. First, the strategy I have employed so far requires a company profitable enough to sustain long-term infrastructure. This path generally does not exist in startups or early growth companies; it is optimized for Big Tech.&lt;/p&gt;
    &lt;p&gt;Second, luck does play a role in landing on a good team. It is very hard to accurately evaluate team and company culture from the outside. But while finding the team might have involved luck, staying there for almost a decade was a choice.&lt;/p&gt;
    &lt;p&gt;And, at least in my experience, my team is not particularly special: I can name five other teams in Android alone 4. Sure, they might have a director change here or a VP change there, but the core mission and the engineering team remained stable.&lt;/p&gt;
    &lt;p&gt;The reason these teams seem rare is not that they don’t exist, but that they are often ignored. Because they don’t offer the rapid, visible “wins” of a product launch nor are they working on the “shiny cool features”, they attract less competition. If you are motivated by “shipping to billions of users” or seeing your friends and family use something you built, you won’t find that satisfaction here. That is the price of admission.&lt;/p&gt;
    &lt;p&gt;But if you want to build long-term systems and are willing to trade external validation for deep technical ownership, you just need to look behind the curtain.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;The tech industry loves to tell you to move fast. But there is another path. It is a path where leverage comes from depth, patience, and the quiet satisfaction of building the foundation that others stand on.&lt;/p&gt;
    &lt;p&gt;You don’t have to chase the spotlight to have a meaningful, high-impact career at a big company. Sometimes, the most ambitious thing you can do is stay put, dig in, and build something that lasts. To sit with a problem space for years until you understand it well enough to build a Bigtrace.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;By product team I don’t mean “frontend team”: even as a backend engineer, you are still working on some part of what is being served directly to end users. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;This is not exhaustive, Perfetto is open source and we do also care about external developers but that’s not why we get paid. From the company perspective, time we spent on open source bugs is “wasted” time but we do it because we believe in the mission of open source. I talked about this more in a recent post, On Perfetto, Open Source, and Company Priorities. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;For what it’s worth, LLMs might not even be the best solution to “let’s put AI into Perfetto”: in my opinion there is lots of value with “old school” machine learning techniques like neural networks. A lot of trace analysis is just pattern matching. This is something I’m hoping to explore more in the coming year! ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Android Kernel, Android System Health, Android Runtime, Android Camera HAL, Android Bionic ↩︎&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46146451</guid><pubDate>Thu, 04 Dec 2025 11:36:36 +0000</pubDate></item><item><title>Functional Quadtrees</title><link>https://lbjgruppen.com/en/posts/functional-quadtree-clojure</link><description>&lt;doc fingerprint="4cfaac21040e533b"&gt;
  &lt;main&gt;
    &lt;p&gt;1.12.2025&lt;/p&gt;
    &lt;head rend="h2"&gt;Functional Quadtrees&lt;/head&gt;
    &lt;p&gt;A Quadtree is a tree data structure, which is useful for giving more focus/detail to certain regions of your data, while saving resources elsewhere. I could only find a couple tutorials/guides and both were imperative, so I figured it'd be fun to do a functional version in Clojure which runs in the browser.&lt;/p&gt;
    &lt;head rend="h2"&gt;A demo&lt;/head&gt;
    &lt;p&gt;In this blogpost I'll show you how to build both a functional Quadtree and the visualization you see below. Imagine the canvas to be a top-view of map and your mouse-position to be the spot you're occupying on the map. Near you, you want crisp details, small cells of high resolution. The further away we get from you/the camera (your mouse-position), the less we care about details.&lt;/p&gt;
    &lt;p&gt;Be aware that on mobile, you have to click at the spot you want to simulate the cameras position. I recommend you view this on a desktop system with a mouse, where the simulation reacts to the mouse position in real time.&lt;/p&gt;
    &lt;head rend="h2"&gt;The recursive approach&lt;/head&gt;
    &lt;p&gt;It's hard to find any tutorials on how to build a general purpose Quadtree, but the 2 I did find both took the imperative approach, ie. editing directly on each node. Nothing wrong with that approach, it can be blazingly fast but it does leave you with the housekeeping, ie. downscaling nodes that are no longer close to the camera. I'd much prefer a declarative definition that rebuilds the entire tree in sub-milliseconds, so let's make that happen.&lt;/p&gt;
    &lt;p&gt;In this implementation, I want to show a very general functional approach and goes like this:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Read a camera (player,mouse,focus-point,whatever) position&lt;/item&gt;
      &lt;item&gt;Test if the current node is optimally sized&lt;/item&gt;
      &lt;item&gt;If not, split into 4 children, goto 2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Optimally sized in this case is just "Am I too far away from the edge of the node" ? If the distance is greater than some threshold, let's say the width of the node, then we split.&lt;/p&gt;
    &lt;head rend="h2"&gt;Our data model&lt;/head&gt;
    &lt;p&gt;Depending on your use-case, you can fit as much information as you want into this model. If you're doing some kind of 3D rendering, you might want to keep tabs on neighbor-relations, &lt;/p&gt;
    &lt;code&gt;(defn qtree
  " Instantiates a tree node "
  [[x1 y1 x2 y2]]
  {:root?   false
   :bounds  [x1 y1 x2 y2]
   :center  (mapv #(js/Math.floor %)
                  [(half x2 x1)
                   (half y2 y1)])
   :width   (- x2 x1)})&lt;/code&gt;
    &lt;p&gt;In fact we strictly speaking, don't need the center/width stored, but it does make life a bit easier.&lt;/p&gt;
    &lt;p&gt;Given a root node and a camera-position we can determine if we want to split or not, simply by testing the distance from the camera to the center:&lt;/p&gt;
    &lt;code&gt;(defn distance
  [[x1 y1] [x2 y2]]
  (js/Math.sqrt
   (+ (js/Math.pow (- x2 x1) 2)
      (js/Math.pow (- y2 y1) 2))))

(defn too-close?
  " Determines if the camera is closer than halfway to
    the edge of a node "
  [ node camera ]
  (&amp;lt; (distance camera (:center node))
     (:width node)))

(defn split?
  [ node camera ]
  (and (too-close? node camera)
       (&amp;gt; (:width node) _Q_MINIMUM_SIZE)))
&lt;/code&gt;
    &lt;p&gt;That final check on the width of the node, essentially allow us to recurse until we can't split anymore. In Clojure we have 2 very powerful idioms for walking a tree structure: Postwalk and Prewalk.&lt;/p&gt;
    &lt;p&gt;Postwalk is a depth-first, post-order walk of the tree which applies some arbitrary function to each element.&lt;/p&gt;
    &lt;code&gt;(w/postwalk (fn [e]
                (prn "Looking at: " e)
                e)
            {:rootval 1
            :node1 {:data "foo"
            :vec  [1 2 3]}})
"Looking at: " :rootval
"Looking at: " 1
"Looking at: " [:rootval 1]
"Looking at: " :node1
"Looking at: " :data
"Looking at: " "foo"
"Looking at: " [:data "foo"]
"Looking at: " :vec
"Looking at: " 1
"Looking at: " 2
"Looking at: " 3
"Looking at: " [1 2 3]
"Looking at: " [:vec [1 2 3]]
"Looking at: " {:data "foo", :vec [1 2 3]}
"Looking at: " [:node1 {:data "foo", :vec [1 2 3]}]
"Looking at: " {:rootval 1, :node1 {:data "foo", :vec [1 2 3]}}
{:rootval 1, :node1 {:data "foo", :vec [1 2 3]}}&lt;/code&gt;
    &lt;p&gt;I hope this is an intuitive way to see the path postwalk takes. The function only prints what it sees and then returns it as is, thus the end result is exactly the map we started out with. Notice how we first see the root key, then its value, then both together as a MapEntry, then it goes deeper into the tree.&lt;/p&gt;
    &lt;p&gt;Now compare that with prewalk:&lt;/p&gt;
    &lt;code&gt;(w/prewalk (fn [e]
               (prn "Looking at: " e)
               e)
           {:rootval 1
           :node1 {:data "foo"
           :vec  [1 2 3]}})
"Looking at: " {:rootval 1, :node1 {:data "foo", :vec [1 2 3]}}
"Looking at: " [:rootval 1]
"Looking at: " :rootval
"Looking at: " 1
"Looking at: " [:node1 {:data "foo", :vec [1 2 3]}]
"Looking at: " :node1
"Looking at: " {:data "foo", :vec [1 2 3]}
"Looking at: " [:data "foo"]
"Looking at: " :data
"Looking at: " "foo"
"Looking at: " [:vec [1 2 3]]
"Looking at: " :vec
"Looking at: " [1 2 3]
"Looking at: " 1
"Looking at: " 2
"Looking at: " 3
{:rootval 1, :node1 {:data "foo", :vec [1 2 3]}}&lt;/code&gt;
    &lt;p&gt;Prewalk examines the same elements and in the same way, but the path is what we call a pre-order traversal, which means you see contents of nodes before the elements - And by implication, you can swap those nodes and then visit the elements. All in all, prewalk makes for a very simple recursive pattern:&lt;/p&gt;
    &lt;code&gt;(w/prewalk
 (fn [n]
     (if (and (map? n) (split? n [x y]))
         (subdivide n)
       n))
 qtree)&lt;/code&gt;
    &lt;p&gt;Yes, it's really that simple. Given a root-node and a camera-position (x,y), this will recursively resolve all children to the maximum resolution.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Visualization&lt;/head&gt;
    &lt;p&gt;If you want to read ahead, I've shared a repo here: Github&lt;/p&gt;
    &lt;p&gt;The code should run straight out of the box and open a webinterface on port 8020. Shadow-cljs makes light work of compiling anything from a single file to a huge frontend application, into a single JS file.&lt;/p&gt;
    &lt;p&gt;Running in a browser we get a nice 2D API from the standard canvas element. Basically, to draw our Quadtree we need only 3 things:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A Quadtree&lt;/item&gt;
      &lt;item&gt;A function which draws a node&lt;/item&gt;
      &lt;item&gt;A function which draws all children&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As you've probably guessed, the Quadtree itself is just a simple map with some keys. But because this is a realtime visualization, I want to create a connection between whichever tree I generated and what's drawn on screen. Fortunately both Clojure and Clojurescript support both atoms and watches:&lt;/p&gt;
    &lt;code&gt;(def quadInst (atom nil))

(add-watch quadInst :updateQuads
           (fn [_ _ old-tree new-tree]
             (draw-all new-tree)))&lt;/code&gt;
    &lt;p&gt;By convention in Clojure, we name arguments underscore (_) if we do not care about them. In this case, I only need the new-tree for the visualization. If you're not a native Clojurian you might find this pattern appealing as it gives you access to both the pre-updated version and the updated tree, meaning you can run diffs, add new children to a scene while removing others.&lt;/p&gt;
    &lt;p&gt;I mention it here for demonstration purposes only, in the latest commit you'll see I actually remove all atoms and demonstrate a 100% pure functional solution without atoms. However for the purpose of explaining Quadtree this is a simple subscription-pattern which most developers will recognize. It ensures that whenever the atom Quadtree is updated, so is the screen.&lt;/p&gt;
    &lt;code&gt;(defn draw-all
  [ tree ]
  (draw (:root? tree)
        tree
        (get-tree-color tree))
  (when-let [children (:children tree)]
    (doseq [c children]
      (draw-all c))))&lt;/code&gt;
    &lt;p&gt;However there's a fun detail here. To make it seem fairly consistent I couldn't just use random colors, that would make the entire screen flicker whenever you moved the mouse. Basically, if I have a rectangle centered at 50,50 - I always want it to have the same color. A really neat and simple trick is the 32bit hash, which is succinctly implemented in javascript like so:&lt;/p&gt;
    &lt;code&gt;function fastHash(str) {
    let hash = 0;
    for (let i = 0; i &amp;lt; str.length; i++) {
        hash = (hash &amp;lt;&amp;lt; 5) - hash + str.charCodeAt(i); // Hash computation
        hash |= 0; // Convert to 32bit integer
    }
    return hash &amp;gt;&amp;gt;&amp;gt; 0; // Ensure the result is unsigned
}&lt;/code&gt;
    &lt;p&gt;Basically my idea is to hash the center, ie "[50,50]" and convert that to a hex color. In Clojurescript, you could do it like so:&lt;/p&gt;
    &lt;code&gt;(defn hash-str
  " Standard 32bit hash: [..].map((% &amp;lt;&amp;lt; 5) - h + ch(idx) "
  [ s ]
  (reduce #(-&amp;gt; (bit-shift-left %1 5)
               (- %1)
               (+ (.charCodeAt %2 0))
               (bit-or 0))
          0 s))

(defn get-tree-color
  [ {c :center} ]
  (let [hash (bit-and (hash-str (str c)) 0xffffff)
        hex  (.toString hash 16)]
    (str "#" (apply str (repeat (- 6 (count hex)) "0")) hex)))&lt;/code&gt;
    &lt;p&gt;That's basically all you need.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Quadtrees are great when you have more work to do, than resources available. Imagine using a VR headset. Whichever point you're focused at, needs to be crisp in detail, you want the highest resolution possible on your hardware. Everything outside of your focus area should be dialed down in resolution because your eyes won't be able to pick it up anyway, so that compute power can be used elsewhere. There are many other applications.&lt;/p&gt;
    &lt;p&gt;Clojurescript is great, because it allows us to express ourselves succinctly and functionally. The core of this implementation is only about 25 lines long. That's much easier to reason about and debug, than some other implementations I've seen, which span several hundred lines.&lt;/p&gt;
    &lt;p&gt;Shadow-cljs is great for more reasons than I can cover in this post, but I will highlight the ability to quickly ship highly optimized bit of JS using only 10 lines of configuration - And they even throw in a free webserver for easy testing and repl driven development, what's not to like?&lt;/p&gt;
    &lt;p&gt;Full source code: Github&lt;/p&gt;
    &lt;p&gt;Lau B. Jensen&lt;/p&gt;
    &lt;p&gt;Lau is a seasoned Danish software developer and consultant with over 15 years of experience in backend systems, web development, and functional programming using Lisp and Clojure. Since 2007, he has co-founded and scaled multiple successful startups while navigating the venture capital landscape. Lau combines deep technical expertise with entrepreneurial insight, delivering robust, scalable solutions tailored to business needs. Creative, driven, and results-/quality oriented, he thrives turning bold ideas into reality.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46147341</guid><pubDate>Thu, 04 Dec 2025 13:18:38 +0000</pubDate></item><item><title>RAM is so expensive, Samsung won't even sell it to Samsung</title><link>https://www.pcworld.com/article/2998935/ram-is-so-expensive-samsung-wont-even-sell-it-to-samsung.html</link><description>&lt;doc fingerprint="bb7aac81a5b6d3e8"&gt;
  &lt;main&gt;
    &lt;p&gt;The price of eggs has nothing on the price of computer memory right now. Thanks to a supply crunch from the “AI” bubble, RAM chips are the new gold, with prices on consumer PC memory kits ballooning out of control. In an object lesson in the ridiculousness of an economic bubble, Samsung won’t even sell its memory to… Samsung.&lt;/p&gt;
    &lt;p&gt;Here’s the situation. Samsung makes everything from refrigerators to supermassive oil tankers. Getting all that stuff made requires an organization that’s literally dozens of affiliated companies and subsidiaries, which don’t necessarily work as closely or harmoniously as you might assume. For this story, we’re talking about Samsung Electronics, which makes Galaxy phones, tablets, laptops, watches, etc., and Samsung Semiconductor Global, which manufactures memory and other chips and supplies the global market. That global market includes both Samsung subsidiaries and their competitors—laptops from Samsung, Dell, and Lenovo sitting on a Best Buy store shelf might all have Samsung-manufactured memory sitting in their RAM slots.&lt;/p&gt;
    &lt;p&gt;Samsung subsidiaries are, naturally, going to look to Samsung Semiconductor first when they need parts. Such was reportedly the case for Samsung Electronics, in search of memory supplies for its newest smartphones as the company ramps up production for 2026 flagship designs. But with so much RAM hardware going into new “AI” data centers—and those companies willing to pay top dollar for their hardware—memory manufacturers like Samsung, SK Hynix, and Micron are prioritizing data center suppliers to maximize profits.&lt;/p&gt;
    &lt;p&gt;The end result, according to a report from SE Daily spotted by SamMobile, is that Samsung Semiconductor rejected the original order for smartphone DRAM chips from Samsung Electronics’ Mobile Experience division. The smartphone manufacturing arm of the company had hoped to nail down pricing and supply for another year. But reports say that due to “chipflation,” the phone-making division must renegotiate quarterly, with a long-term supply deal rejected by its corporate sibling. A short-term deal, with higher prices, was reportedly hammered out.&lt;/p&gt;
    &lt;p&gt;Assuming that this information is accurate—and to be clear, we can’t independently confirm it—consumers will see prices rise for Samsung phones and other mobile hardware. But that’s hardly a surprise. Finished electronics probably won’t see the same meteoric rise in prices as consumer-grade RAM modules, but this rising tide is flooding all the boats. Raspberry Pi, which strives to keep its mod-friendly electronics as cheap as possible, has recently had to bring prices up and called out memory costs as the culprit. Lenovo, the world’s largest PC manufacturer, is stockpiling memory supplies as a bulwark against the market.&lt;/p&gt;
    &lt;p&gt;But if you’re hoping to see prices lower in 2026, don’t hold your breath. According to a forecast from memory supplier TeamGroup, component prices have tripled recently, causing finished modules to jump in prices as quickly as 100 percent in a month. Absent some kind of disastrous market collapse, prices are expected to continue rising into next year, and supply could remain constrained well into 2027 or later.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46147353</guid><pubDate>Thu, 04 Dec 2025 13:20:07 +0000</pubDate></item><item><title>Fighting the age-gated internet</title><link>https://www.wired.com/story/age-verification-is-sweeping-the-us-activists-are-fighting-back/</link><description>&lt;doc fingerprint="3b8f985538b1b5e0"&gt;
  &lt;main&gt;
    &lt;p&gt;Members of Congress considered 19 online safety bills Tuesday that may soon have a major impact on the future of the internet as age-verification laws have spread to half of the US and around the world.&lt;/p&gt;
    &lt;p&gt;In response, digital and human rights organization Fight for the Future is hosting a week of events—across Reddit, LinkedIn, and various livestreams—to raise awareness of how it believes these bills are setting a dangerous precedent by making the internet more exploitative rather than safer. Many of the proposed bills include a clause for ID or age verification, which forces people to upload an ID, allow a face scan, or otherwise authenticate that they are not a minor before viewing adult content. Fight for the Future says the policies will lead to increased censorship and surveillance.&lt;/p&gt;
    &lt;p&gt;Among the 19 bills considered at the hearing conducted by the House Energy and Commerce Committee was the Kids Online Safety Act (KOSA), which passed with sweeping bipartisan approval in the Senate last year, and the Reducing Exploitative Social Media Exposure for Teens Act, which would ban tech companies from allowing minors under the age of 16 on their platforms. In addition to age verification, the bills raised concerns over issues of parental controls, consumer research of minors, AI, and data privacy.&lt;/p&gt;
    &lt;p&gt;“We’re seeing this huge wave toward ID checks being the norm in tech policy, and it felt like we needed to capture the already activated communities who are not feeling heard in Congress,” says Sarah Philips, a campaigner with Fight for the Future. “If you look on YouTube, if you see people making content about KOSA or responding to a lot of this legislation, it’s very unpopular with people. But it’s viewed on the Hill as very common-sense.”&lt;/p&gt;
    &lt;p&gt;Missouri’s age-gate law took effect earlier this week, meaning 25 US states have passed a form of age verification. The process usually involves third-party services, which can be especially prone to data breaches. This year, the UK also passed a mandate for age verification—the Online Safety Act—and Australia’s teen social media ban, which requires social media companies to deactivate the accounts of users under the age of 16, goes into effect on December 10. Instagram, YouTube, Snap, and TikTok are complying with the historic ban.&lt;/p&gt;
    &lt;p&gt;Philips believes the laws are a direct threat to democratic freedom. “These are censorship laws,” she says. “In the South, where I live, these same proposals mimic a lot of the arguments that you see behind book bans and behind laws that criminalize gender-affirming health care or abortion information.”&lt;/p&gt;
    &lt;p&gt;In March, over 90 human rights advocacy groups signed a coalition letter opposing online ID-check mandates. “The internet is not improved by treating its users like criminal suspects and our lives as opportunities for corporate profit,” David Swanson, campaign coordinator at RootsAction.org, wrote in the letter. “Legislators defunding education to invest in wars, police, prisons, borders, and constant surveillance should think hard before claiming to be acting on behalf of children.”&lt;/p&gt;
    &lt;p&gt;Though Tuesday’s hearing did not advance any legislation, it included testimonies from Joel Thayer, president of the Digital Progress Institute, and Kate Ruane, director of the Free Expression Project at the Center for Democracy and Technology. “The government and social media platforms should not be—indeed, with respect to the government, cannot be—the sole arbiters of the content children can see and services that they can access online,” Ruane said during her testimony.&lt;/p&gt;
    &lt;p&gt;The package of bills is indicative of how Congress has failed to deliver real solutions, Philips says. “We have repeatedly asked them to focus on comprehensive privacy legislation, on antitrust issues, and on things that actually protect us from the surveillance capitalist business model of big tech companies. Congress says they’re holding big tech accountable, but most of the options on the table just mandate verification.” According to The Verge, a revamped version of KOSA removes tech companies’ liability in mitigating potential harms caused by their platforms.&lt;/p&gt;
    &lt;p&gt;In an op-ed for Teen Vogue published in October, Fight for the Future director Evan Greer and campaigner Janus Rose criticized Democratic lawmakers who support KOSA, including the bill’s cowriter, Senator Richard Blumenthal of Connecticut. “KOSA takes the same logic of the bans on drag shows and LGBTQ+ books and applies it to the internet, allowing censorship of a broad range of information in the name of protecting kids from real online harm,” Greer noted.&lt;/p&gt;
    &lt;p&gt;But since KOSA and the Children and Teens’ Online Privacy Protection Act failed to gain approval last year, “it’ll be interesting to see what actually floats to the top right now,” Philips says, concerned that some of the bills could be attached to the National Defense Authorization Act or have the Trump administration’s 10-year moratorium on state AI regulations attached to them, “which is a disaster tornado of tech policies.”&lt;/p&gt;
    &lt;p&gt;Philips tells me she isn’t disheartened by the work, because she wants people to understand what’s really at stake in the fight ahead.&lt;/p&gt;
    &lt;p&gt;“The thing that people misunderstand most about age verification is that it actually applies to all of us,” she says. “A lot of the people pushing for age verification solely focus on kids, because that’s the discussion happening in Congress or on the Hill. But in actuality, if we age-gate the internet and implement mandates, that means that you have to prove that you’re not a child—whether you’re 18 or 50. Everyone will have to interact with this.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46147493</guid><pubDate>Thu, 04 Dec 2025 13:34:27 +0000</pubDate></item><item><title>Transparent leadership beats servant leadership</title><link>https://entropicthoughts.com/transparent-leadership-beats-servant-leadership</link><description>&lt;doc fingerprint="bce3d0111682d491"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Transparent Leadership Beats Servant Leadership&lt;/head&gt;
    &lt;p&gt;tl:dr: Parenting and leadership is similar. Teach a man to fish, etc.&lt;/p&gt;
    &lt;p&gt;I spent a couple of years managing a team, and I entered that role – like many – without knowing anything about how to do it. I tried to figure out how to be a good manager, and doing so I ended up reading a lot about servant leadership. It never quite sat right with me, though. Servant leadership seems to me a lot like curling parenting: the leader/parent anticipate problems and sweep the way for their direct reports/children.&lt;/p&gt;
    &lt;p&gt;To be clear, this probably feels very good (initially, anyway) for the direct reports/children. But the servant leader/curling parent quickly becomes an overworked single point of failure, and once they leave there is nobody else who knows how to handle the obstacles the leader moved out of the way for everyone. In the worst cases, they leave behind a group of people who have been completely isolated from the rest of the organisation, and has no idea what their purpose is and how to fit in with the rest of the world.&lt;/p&gt;
    &lt;p&gt;I would like to invent my own buzzword: transparent leadership. In my book, a good leader&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;coaches people,&lt;/item&gt;
      &lt;item&gt;connects people,&lt;/item&gt;
      &lt;item&gt;teaches people methodical problem solving,&lt;/item&gt;
      &lt;item&gt;explains values and principles embraced by the organisation to aid them in making aligned decisions on their own,&lt;/item&gt;
      &lt;item&gt;creates direct links between supply and demand (instead of deliberately making themselves a middle man),&lt;/item&gt;
      &lt;item&gt;allows their direct reports career growth by gradually taking over leadership responsibilities,&lt;/item&gt;
      &lt;item&gt;continuously trains their replacement, and&lt;/item&gt;
      &lt;item&gt;generally makes themselves redundant.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The middle manager that doesn’t perform any useful work is a fun stereotype, but I also think it’s a good target to aim for. The difference lies in what to do once one has rendered oneself redundant. A common response is to invent new work, ask for status reports, and add bureaucracy.&lt;/p&gt;
    &lt;p&gt;A better response is to go back to working on technical problems. This keeps the manager’s skills fresh and gets them more respect from their reports. The manager should turn into a high-powered spare worker, rather than a paper-shuffler.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46147540</guid><pubDate>Thu, 04 Dec 2025 13:40:00 +0000</pubDate></item><item><title>Show HN: Onlyrecipe 2.0 – I added all features HN requested – 4 years later</title><link>https://onlyrecipeapp.com/?url=https://www.allrecipes.com/turkish-pasta-recipe-8754903</link><description>&lt;doc fingerprint="d37fffed7efd5e8d"&gt;
  &lt;main&gt;
    &lt;p&gt;Loading...&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46148460</guid><pubDate>Thu, 04 Dec 2025 15:06:08 +0000</pubDate></item><item><title>Microsoft drops AI sales targets in half after salespeople miss their quotas</title><link>https://arstechnica.com/ai/2025/12/microsoft-slashes-ai-sales-growth-targets-as-customers-resist-unproven-agents/</link><description>&lt;doc fingerprint="af740a1914faa081"&gt;
  &lt;main&gt;
    &lt;p&gt;Microsoft has lowered sales growth targets for its AI agent products after many salespeople missed their quotas in the fiscal year ending in June, according to a report Wednesday from The Information. The adjustment is reportedly unusual for Microsoft, and it comes after the company missed a number of ambitious sales goals for its AI offerings.&lt;/p&gt;
    &lt;p&gt;AI agents are specialized implementations of AI language models designed to perform multistep tasks autonomously rather than simply responding to single prompts. So-called “agentic” features have been central to Microsoft’s 2025 sales pitch: At its Build conference in May, the company declared that it has entered “the era of AI agents.”&lt;/p&gt;
    &lt;p&gt;The company has promised customers that agents could automate complex tasks, such as generating dashboards from sales data or writing customer reports. At its Ignite conference in November, Microsoft announced new features like Word, Excel, and PowerPoint agents in Microsoft 365 Copilot, along with tools for building and deploying agents through Azure AI Foundry and Copilot Studio. But as the year draws to a close, that promise has proven harder to deliver than the company expected.&lt;/p&gt;
    &lt;p&gt;According to The Information, one US Azure sales unit set quotas for salespeople to increase customer spending on a product called Foundry, which helps customers develop AI applications, by 50 percent. Less than a fifth of salespeople in that unit met their Foundry sales growth targets. In July, Microsoft lowered those targets to roughly 25 percent growth for the current fiscal year. In another US Azure unit, most salespeople failed to meet an earlier quota to double Foundry sales, and Microsoft cut their quotas to 50 percent for the current fiscal year.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46148748</guid><pubDate>Thu, 04 Dec 2025 15:31:52 +0000</pubDate></item><item><title>Bootloader Unlock Wall of Shame</title><link>https://github.com/zenfyrdev/bootloader-unlock-wall-of-shame</link><description>&lt;doc fingerprint="b7c1c9df8ea3b9e0"&gt;
  &lt;main&gt;
    &lt;p&gt;Keeping track of companies that "care about your data 🥺"&lt;/p&gt;
    &lt;head&gt;mirrors&lt;/head&gt;
    &lt;p&gt;Over the past few years, a suspicious number of companies have started to "take care of your data", aka block/strictly limit your ability to unlock the bootloader on your own devices.&lt;/p&gt;
    &lt;p&gt;While this may not affect you directly, it sets a bad precedent. You never know what will get the axe next: Shizuku? ADB?&lt;lb/&gt; They've already gone after sideloading.&lt;lb/&gt; I thought it might be a good idea to keep track of bad companies and workarounds.&lt;/p&gt;
    &lt;p&gt;If you know of specific details/unlocking methods, please PR them or drop them in the discussions&lt;/p&gt;
    &lt;p&gt;Caution&lt;/p&gt;
    &lt;p&gt;Reminder that no matter how nice a company is, &lt;lb/&gt; you should not trust them unless their unlock process is 100% offline!&lt;/p&gt;
    &lt;p&gt;The following manufacturers have made it completely impossible to unlock their devices without a workaround.&lt;/p&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;Phone brands handle carrier locks differently, so check your device manual or contact support.&lt;/p&gt;
    &lt;p&gt;Carrier locked devices are the ones you get after making a commitment with a carrier of your choice. This is quite common in North America and (supposedly) allows you to save some money on your device.&lt;/p&gt;
    &lt;p&gt;As a rule, almost all carrier locked devices do not allow the bootloader to be unlocked. This usually makes sense, as it would allow you to completely bypass the contract. The problem is that many devices still do not allow you to unlock the bootloader even after the carrier lock has been lifted. For more details, see the carriers page.&lt;/p&gt;
    &lt;p&gt;The following manufacturers allow unlocking under certain conditions, such as region, model, SOC, etc., or require a sacrifice to unlock.&lt;/p&gt;
    &lt;p&gt;The following manufacturers require an online account and/or a waiting period before unlocking.&lt;/p&gt;
    &lt;p&gt;Custom Android Verified Boot keys is a feature which allows you to run a custom OS with a locked bootloader.&lt;/p&gt;
    &lt;p&gt;It's rare to see a device which supports custom AVB keys, but some devices can be found here.&lt;/p&gt;
    &lt;p&gt;Kirin 620, 650, 655, 658, 659, 925, 935, 950, 960:&lt;lb/&gt; It's possible to unlock using testpoints and PotatoNV (Read the readme)&lt;/p&gt;
    &lt;p&gt;If you own a MediaTek device exploitable by mtkclient you can unlock the bootloader using that.&lt;lb/&gt; If it also happens to be an OPPO/Realme device and you need to access fastboot: lkpatcher (web version)&lt;/p&gt;
    &lt;p&gt;There's no Universal Qualcomm method, unfortunately.&lt;/p&gt;
    &lt;p&gt;Although some of these might work for you:&lt;/p&gt;
    &lt;p&gt;The general exploit:&lt;lb/&gt; alephsecurity.com the bootloader unlock section.&lt;/p&gt;
    &lt;p&gt;Xiaomi Mi A1 and maybe all MSM89** manufactured before 2018:&lt;lb/&gt; EDLUnlock&lt;/p&gt;
    &lt;p&gt;If you own a phone with the Unisoc UMS9620 or older,you can use this exploit to achieve temporary secure boot bypass and persistently unlock bootloader(except some devices with modified uboot) CVE-2022-38694_unlock_bootloader&lt;/p&gt;
    &lt;p&gt;If you own a phone with the Unisoc UMS312 UMS512 UD710,you can use this exploit to achieve persistently secure boot bypass, which means all firmwares including splloader,uboot can be modified and resigned. CVE-2022-38691_38692&lt;/p&gt;
    &lt;p&gt;Otherwise, you can also look into this: Spectrum_UnlockBL_Tool &lt;lb/&gt; This: xdaforums.com &lt;lb/&gt; Or this: subut&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46149019</guid><pubDate>Thu, 04 Dec 2025 15:57:21 +0000</pubDate></item><item><title>Feynman vs. Computer</title><link>https://entropicthoughts.com/feynman-vs-computer</link><description>&lt;doc fingerprint="127ccb0343b51399"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Feynman vs. Computer&lt;/head&gt;
    &lt;p&gt;I read Burghelea’s article on the Feynman trick for integration. Well, I’m not good enough at analysis to follow along, but I tried reading it anyway because it’s fascinating.&lt;/p&gt;
    &lt;p&gt;For people who do not have experience with analysis, integration is counting the total size of very many, very small piles of things. Analytical integration, i.e. the process by which we can get an exact result, can be very difficult. It often takes knowledge of special tricks, strong pattern recognition, and plenty of trial and error. Fortunately, in all cases in my career when I’ve needed the value of an integral, an approximate answer has been good enough.&lt;/p&gt;
    &lt;p&gt;In practical terms, this means we could spend a lot of time learning integration tricks, practice using them, and then take half an hour out of our day to apply them to an integral in front of us … or, hear me out, or, we could write four lines of JavaScript that arrive at a relatively accurate answer in less than a second.&lt;/p&gt;
    &lt;head rend="h1"&gt;The approximating power of random numbers&lt;/head&gt;
    &lt;p&gt;If integration is summing many small piles, we have to figure out how big the piles are. Their height is usually given by a mathematical function, and our first example will be the same as in the Feynman trick article.&lt;/p&gt;
    &lt;p&gt;\[f(x) = \frac{x - 1}{\ln{x}}\]&lt;/p&gt;
    &lt;p&gt;This is to be integrated from zero to one, i.e. we want to know the size of the shaded area in the plot below. You can think of each column of shaded pixels as one pile, and we sum the size of all of them to get the total area.1 Of course, this is an svg image so there are no columns of pixels. Alternatively, the more we zoom in, the thinner the columns become – but the more of them there are. This is why we need integration: it’s dealing with the limit case of infinitely many, infinitely thin columns.&lt;/p&gt;
    &lt;p&gt;We could imagine drawing six random numbers between zero and one, and plotting piles of the corresponding height at those locations. Since there are six piles, their width is one sixth of the width of the area we are integrating.&lt;/p&gt;
    &lt;p&gt;Even though some of these piles overlap by chance, and even though there are some random gaps between them, the sum of their areas (0.66) comes very close to the actual shaded area determined analytically (0.69). If we draw more piles, we have to make them correspondingly thinner, but the agreement between their sum and the total size of the area improves.&lt;/p&gt;
    &lt;p&gt;These are 100× as many piles, and they’re 1/100th as thick to compensate. Their total area is 0.70 – very close to 0.69. If we draw even more piles, we’ll get even closer.&lt;/p&gt;
    &lt;p&gt;This illustrates a neat correspondence between integrals and expected values. In the simple case, we can frame it mathematically as&lt;/p&gt;
    &lt;p&gt;\[\int_a^b f(x) \mathrm{d}x = E(f(x))\]&lt;/p&gt;
    &lt;p&gt;In words, this says that integrating the function \(f\) between \(a\) and \(b\) is the same as taking the expected value of \(f(x)\) at uniformly distributed random points between \(a\) and \(b\).&lt;/p&gt;
    &lt;head rend="h1"&gt;Teaching the computer to do it&lt;/head&gt;
    &lt;p&gt;Here’s a JavaScript function that estimates the value of an integral in the most primitive way possible.&lt;/p&gt;
    &lt;quote&gt;I = (B, lo, hi, f) =&amp;gt; { // Generate B random values uniformly between lo and hi. let xs = Array.from({length: B}, _ =&amp;gt; lo + (hi - lo) * Math.random()); // Compute the value of f at each location. let ys = xs.map(f); // Return the total area of each corresponding pile. return (hi-lo)*ys.reduce((r, y) =&amp;gt; r + y, 0)/ys.length; }&lt;/quote&gt;
    &lt;p&gt;To compute an approximation to the value of the integral we’ve seen, we run&lt;/p&gt;
    &lt;quote&gt;I(10_000, 0, 1, x =&amp;gt; (x-1)/Math.log(x) );&lt;/quote&gt;
    &lt;quote&gt;0.6916867623261724&lt;/quote&gt;
    &lt;p&gt;This is fairly close to 0.69. And we got there in four lines of JavaScript, as promised.&lt;/p&gt;
    &lt;head rend="h1"&gt;Improved approximation through splittage&lt;/head&gt;
    &lt;p&gt;We can try this on the next example too. Now we’re asking about the integral&lt;/p&gt;
    &lt;p&gt;\[\int_0^{\frac{\pi}{2}} \frac{\ln{(1 - \sin{x})}}{\sin{x}} \mathrm{d}x\]&lt;/p&gt;
    &lt;p&gt;which, translated to JavaScript, becomes&lt;/p&gt;
    &lt;quote&gt;I(10_000, 0, Math.PI, x =&amp;gt; Math.log(1 - Math.sin(x))/Math.sin(x) );&lt;/quote&gt;
    &lt;quote&gt;-3.67&lt;/quote&gt;
    &lt;p&gt;This is again fairly close to the desired −3.7, but not quite there yet. The tricky shape of the function is the reason we aren’t getting as close as we want.&lt;/p&gt;
    &lt;p&gt;At the upper endpoint of the integration interval, this function goes to negative infinity. The random piles we draw come primarily from the well behaved region of the function, and thus don’t help the computer realise this behaviour.&lt;/p&gt;
    &lt;p&gt;There are clever ways to sample adaptively from the trickier parts of the function, but an easy solution is to just visually find a breakpoint, split the interval on that, and then estimate the sensible part separately from the crazy-looking part. Since the total area must be the sum of both areas, we can add their results together for a final estimation.&lt;/p&gt;
    &lt;p&gt;In this case, we might want to pick e.g. 1.5 as the breakpoint, so we combine the area estimations from 0–1.5 and then 1.5–\(\frac{\pi}{2}\). The result is&lt;/p&gt;
    &lt;quote&gt;I(2_000, 0, 1.5, x =&amp;gt; Math.log(1 - Math.sin(x))/Math.sin(x)) + I(8_000, 1.5, Math.PI/2, x =&amp;gt; Math.log(1 - Math.sin(x))/Math.sin(x));&lt;/quote&gt;
    &lt;quote&gt;-3.70&lt;/quote&gt;
    &lt;p&gt;which is indeed much closer to the actual value of −3.7.&lt;/p&gt;
    &lt;p&gt;Note that we aren’t taking more samples, we’re just sprinkling them more wisely over the number line. We spend 2,000 samples in the relatively well-behaved region where the function takes values from −1 to −6, and then we spend the other 8,000 samples in the small region that goes from −6 to negative infinity. Here it is graphically:&lt;/p&gt;
    &lt;p&gt;The reason this helps us is that this latter region contributes a lot to the value of the integral, but it is so small on the number line that we benefit from oversampling it compared to the other region. This is a form of sample unit engineering, which we have seen before in different contexts.&lt;/p&gt;
    &lt;head rend="h1"&gt;More evidence of sufficiency&lt;/head&gt;
    &lt;p&gt;We can continue with some more examples from the Feynman trick article. That gets us the following table.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Integral&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
        &lt;cell role="head"&gt;Estimation&lt;/cell&gt;
        &lt;cell role="head"&gt;Difference&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;\(\int_0^1 \frac{x-1}{\ln{x}} \mathrm{d}x\)&lt;/cell&gt;
        &lt;cell&gt;\(\ln{2}\)&lt;/cell&gt;
        &lt;cell&gt;0.6943&lt;/cell&gt;
        &lt;cell&gt;0.2 %&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;\(\int_0^{\frac{\pi}{2}} \frac{\ln{(1 - \sin{x})}}{\sin{x}} \mathrm{d}x\)&lt;/cell&gt;
        &lt;cell&gt;\(\frac{-3 \pi^2}{8}\)&lt;/cell&gt;
        &lt;cell&gt;-3.702&lt;/cell&gt;
        &lt;cell&gt;&amp;lt; 0.1 %&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;\(\int_0^1 \frac{\ln{(1 - x + x^2)}}{x - x^2} \mathrm{d}x\)&lt;/cell&gt;
        &lt;cell&gt;\(\frac{-\pi^2}{9}\)&lt;/cell&gt;
        &lt;cell&gt;-1.097&lt;/cell&gt;
        &lt;cell&gt;&amp;lt; 0.1 %&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;\(\int_0^{\frac{\pi}{2}} \frac{\arctan{(\sin{x})}}{\sin{x}} \mathrm{d}x\)&lt;/cell&gt;
        &lt;cell&gt;\(\frac{\pi}{2}\log{(1 + \sqrt{2})}\)&lt;/cell&gt;
        &lt;cell&gt;1.385&lt;/cell&gt;
        &lt;cell&gt;&amp;lt; 0.1 %&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;\(\int_0^\infty x^2 e^{-\left(4x^2 + \frac{9}{x^2}\right)} \mathrm{d}x\)&lt;/cell&gt;
        &lt;cell&gt;\(\frac{13 \sqrt{\pi}}{32 e^{12}}\)&lt;/cell&gt;
        &lt;cell&gt;0.000004414&lt;/cell&gt;
        &lt;cell&gt;0.2 %&lt;/cell&gt;
        &lt;cell&gt;(1)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;\(\int_0^1 \frac{\ln{x}}{1 - x^2} \mathrm{d}x\)&lt;/cell&gt;
        &lt;cell&gt;\(\frac{-\pi^2}{8}\)&lt;/cell&gt;
        &lt;cell&gt;-1.227&lt;/cell&gt;
        &lt;cell&gt;0.5 %&lt;/cell&gt;
        &lt;cell&gt;(2)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;\(\int_0^\infty \frac{e^{-x^2}}{1 + x^2} \mathrm{d}x\)&lt;/cell&gt;
        &lt;cell&gt;\(\frac{\pi e}{2}\mathrm{erfc}(1)\)&lt;/cell&gt;
        &lt;cell&gt;0.6696&lt;/cell&gt;
        &lt;cell&gt;0.3 %&lt;/cell&gt;
        &lt;cell&gt;(3)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Notes:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The integration is from zero to infinity, but the function practically only has a value between zero and three, so that’s the region we estimate over.&lt;/item&gt;
      &lt;item&gt;This is another case where the function goes to infinity near zero, so we split up the estimation into one for the range 0–0.1, and the other for 0.1–1.0. We have not increased the sample count, only reallocated the 10,000 samples.&lt;/item&gt;
      &lt;item&gt;Again, the integration is from zero to infinity, but the function practically only has a value between zero and three, so that’s the region we estimate over.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Finding the error without a ground truth&lt;/head&gt;
    &lt;p&gt;“Now,” the clever reader says, “this is all well and good when we have the actual value to compare to so we know the size of the error. What will we do if we’re evluating a brand new integral? What is the size of the error then, huh?”&lt;/p&gt;
    &lt;p&gt;This is why we sampled the function randomly. That means our approximation is a statistical average over samples, and for that we can compute the standard error of the mean. In the JavaScript implementation below, we use the quick variance computation, but we could perhaps more intuitively have used the spc inspired method.&lt;/p&gt;
    &lt;quote&gt;Ic = (B, lo, hi, f) =&amp;gt; { let xs = Array.from( {length: B}, _ =&amp;gt; lo + (hi - lo) * Math.random() ); let ys = xs.map(f); // Compute the variance of the ys from the sum and // the sum of squared ys. let s = ys.reduce((r, y) =&amp;gt; r + y, 0); let ssq = ys.reduce((r, y) =&amp;gt; r + y**2, 0); let v = (ssq - s**2/B)/(B-1); // Compute the mean and the standard error of the mean. let m = (hi-lo)*s/B; let se = (hi-lo)*Math.sqrt(v/B); // Compute the 90 % confidence interval of the value of // the integral. return { p05: m - 1.645*se, p95: m + 1.645*se, } }&lt;/quote&gt;
    &lt;p&gt;If we run this with the first integral as an example, we’ll learn that&lt;/p&gt;
    &lt;quote&gt;Ic(10_000, 0, 1, x =&amp;gt; (x-1)/Math.log(x) )&lt;/quote&gt;
    &lt;quote&gt;Object { p05: 0.6896 p95: 0.6963 }&lt;/quote&gt;
    &lt;p&gt;Not only is this range an illustration of the approximation error (small!), it is also very likely to capture the actual value of the integral. Here are some more examples from the same integrals as above:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;5 %&lt;/cell&gt;
        &lt;cell role="head"&gt;95 %&lt;/cell&gt;
        &lt;cell role="head"&gt;Actual&lt;/cell&gt;
        &lt;cell role="head"&gt;Contained?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;0.6904&lt;/cell&gt;
        &lt;cell&gt;0.6972&lt;/cell&gt;
        &lt;cell&gt;0.6931&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;-3.7673&lt;/cell&gt;
        &lt;cell&gt;-3.6787&lt;/cell&gt;
        &lt;cell&gt;-3.7011&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;-1.0975&lt;/cell&gt;
        &lt;cell&gt;-1.0960&lt;/cell&gt;
        &lt;cell&gt;-1.0966&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;1.3832&lt;/cell&gt;
        &lt;cell&gt;1.3871&lt;/cell&gt;
        &lt;cell&gt;1.3845&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;0.4372&lt;/cell&gt;
        &lt;cell&gt;0.4651&lt;/cell&gt;
        &lt;cell&gt;0.4424&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;-1.2545&lt;/cell&gt;
        &lt;cell&gt;-1.2254&lt;/cell&gt;
        &lt;cell&gt;-1.2337&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;0.6619&lt;/cell&gt;
        &lt;cell&gt;0.6937&lt;/cell&gt;
        &lt;cell&gt;0.6716&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;These are all built naïvely from 10,000 uniform samples. In other words, in none of the cases have the computation been split up to allocate samples more cleverly.&lt;/p&gt;
    &lt;p&gt;Again, we could spend a lot of time learning to integrate by hand … or we ask the computer for less than a second of its time first, and see if the accuracy it can do it with is appropriate for our use case. In my experience, it generally is.&lt;/p&gt;
    &lt;head rend="h1"&gt;Seeing the effect of sample unit engineering&lt;/head&gt;
    &lt;p&gt;What’s neat is we can still split up the computation like we did before, if we believe it will make the error smaller and the confidence interval narrower. Let’s use the following integral as an example.&lt;/p&gt;
    &lt;p&gt;\[\int_0^\infty \frac{\sin{x}}{x} \mathrm{d}x\]&lt;/p&gt;
    &lt;p&gt;This oscillates up and down quite a bit for small \(x\), and then decays but still provides significant contributions for larger \(x\). A naive evaluation would have a confidence interval of&lt;/p&gt;
    &lt;quote&gt;Ic(10_000, 0, 100, x =&amp;gt; Math.sin(x)/x)&lt;/quote&gt;
    &lt;quote&gt;Object { p05: 1.461 p95: 1.884 }&lt;/quote&gt;
    &lt;p&gt;and while this is certainly correct2 The actual value of the integral is half \(\pi\) or approximatey 1.571., we can do better. We’ll estimate the region of 0–6 separately from 6–100, using half the samples for each3 Why put the break point at 6? The period of sin is a full turn, which is roughly 6 radians. This ensures we get roughly symmetric contributions from both integrals. That’s not necessary for the technique to work, but it makes the illustration a little cleaner.:&lt;/p&gt;
    &lt;quote&gt;Ic(5_000, 0, 6, x =&amp;gt; Math.sin(x)/x)&lt;/quote&gt;
    &lt;quote&gt;Object { p05: 1.236 p95: 1.468 }&lt;/quote&gt;
    &lt;p&gt;This contains the bulk of the value of the integral, it seems. Let’s see what remains in the rest of it.&lt;/p&gt;
    &lt;quote&gt;Ic(5_000, 6, 100, x =&amp;gt; Math.sin(x)/x)&lt;/quote&gt;
    &lt;quote&gt;Object { p05: 0.080 p95: 0.198 }&lt;/quote&gt;
    &lt;p&gt;We can work backwards to what the standard errors must have been to produce these confidence intervals.4 The midpoint is the point estimation for each region, and the standard error is 1/1.645 times the distance between the 5 % point and the midpoint.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Region&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
        &lt;cell role="head"&gt;Standard error&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;0–6&lt;/cell&gt;
        &lt;cell&gt;1.4067&lt;/cell&gt;
        &lt;cell&gt;0.0372&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;6–100&lt;/cell&gt;
        &lt;cell&gt;0.1390&lt;/cell&gt;
        &lt;cell&gt;0.0359&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The estimation of the total area would be the values summed, i.e. 1.5457. The estimation of the standard error of this we get through Pythagorean addition and it is approximately 0.05143. We convert it back to a confidence interval and compare with when we did not break it up into multiple components.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Method&lt;/cell&gt;
        &lt;cell role="head"&gt;5 %&lt;/cell&gt;
        &lt;cell role="head"&gt;95 %&lt;/cell&gt;
        &lt;cell role="head"&gt;Range&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Single operation (10,000 samples)&lt;/cell&gt;
        &lt;cell&gt;1.461&lt;/cell&gt;
        &lt;cell&gt;1.884&lt;/cell&gt;
        &lt;cell&gt;0.423&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Two operations (5,000 samples × 2)&lt;/cell&gt;
        &lt;cell&gt;1.461&lt;/cell&gt;
        &lt;cell&gt;1.630&lt;/cell&gt;
        &lt;cell&gt;0.169&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Although in this case the two methods happen to share a lower bound, the upper bound has been dramatically reduced. The total range of the confidence interval is more than halved! This was because we allocated the samples more cleverly – concentrated them in the early parts of the function – rather than increased the number of samples.&lt;/p&gt;
    &lt;p&gt;That said, we’re at a computer, so we could try increasing the sample count. Or maybe both?&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Method&lt;/cell&gt;
        &lt;cell role="head"&gt;5 %&lt;/cell&gt;
        &lt;cell role="head"&gt;95 %&lt;/cell&gt;
        &lt;cell role="head"&gt;Range&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Single operation (10,000 samples)&lt;/cell&gt;
        &lt;cell&gt;1.461&lt;/cell&gt;
        &lt;cell&gt;1.884&lt;/cell&gt;
        &lt;cell&gt;0.423&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Two operations (5,000 samples × 2)&lt;/cell&gt;
        &lt;cell&gt;1.461&lt;/cell&gt;
        &lt;cell&gt;1.630&lt;/cell&gt;
        &lt;cell&gt;0.169&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Single operation (100,000 samples)&lt;/cell&gt;
        &lt;cell&gt;1.549&lt;/cell&gt;
        &lt;cell&gt;1.680&lt;/cell&gt;
        &lt;cell&gt;0.131&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Two operations (50,000 samples × 2)&lt;/cell&gt;
        &lt;cell&gt;1.524&lt;/cell&gt;
        &lt;cell&gt;1.578&lt;/cell&gt;
        &lt;cell&gt;0.054&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;It seems like sampling more cleverly has almost the same effect as taking ten times as many samples.&lt;/p&gt;
    &lt;p&gt;We could play around with where to put the breakpoint, and how many samples to allocate to each side of it, and see which combination yields the lowest error. Then we can run that combination with a lot of samples to get the most accurate final result. That would take maybe 15 minutes of tooting about and exploring sensible-seeming alternatives, so it’s probably still quicker than integrating by hand.&lt;/p&gt;
    &lt;head rend="h1"&gt;When the computer is not enough&lt;/head&gt;
    &lt;p&gt;It should be said that there are times when numeric solutions aren’t great. I hear that in electronics and quantum dynamics, there are sometimes integrals whose value is not a number, but a function, and knowing that function is important in order to know how the thing it’s modeling behaves in interactions with other things.&lt;/p&gt;
    &lt;p&gt;Those are not my domains, though. And when that’s not the case, the computer beats Feynman any day of the week.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46149066</guid><pubDate>Thu, 04 Dec 2025 16:03:02 +0000</pubDate></item><item><title>Autism should not be treated as a single condition</title><link>https://www.economist.com/science-and-technology/2025/12/03/why-autism-should-not-be-treated-as-a-single-condition</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46149375</guid><pubDate>Thu, 04 Dec 2025 16:25:31 +0000</pubDate></item><item><title>Launch HN: Browser Buddy (YC W24) – A recommendation system for Internet writing</title><link>https://www.browserbuddy.com/</link><description>&lt;doc fingerprint="3bd993f7b8d51a27"&gt;
  &lt;main&gt;
    &lt;p&gt;A For-You page for writing Explore the best essays and blogs on the Internet with Browser Buddy.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46149727</guid><pubDate>Thu, 04 Dec 2025 16:52:56 +0000</pubDate></item><item><title>Multivox: Volumetric Display</title><link>https://github.com/AncientJames/multivox</link><description>&lt;doc fingerprint="87cd881f7921b9c9"&gt;
  &lt;main&gt;
    &lt;p&gt;This is the code I currently use to drive my volumetric displays.&lt;/p&gt;
    &lt;p&gt;It supports two closely related devices which are configured in the &lt;code&gt;src/driver/gadgets&lt;/code&gt; directory:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Rotovox is a 400mm Orb featuring two 128x64 panels arranged vertically side by side.&lt;/item&gt;
      &lt;item&gt;Vortex is a 300mm Orb featuring two 128x64 panels arranged horizontally, back to back.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Rotovox has a higher vertical resolution and better horizontal density; Vortex is brighter and has a higher refresh rate.&lt;/p&gt;
    &lt;p&gt;The 3D printable parts for Vortex are available here.&lt;/p&gt;
    &lt;p&gt;This code was originally written for a single display, and the device specific code was later somewhat abstracted out to support a second similar gadget. There are assumptions about the hardware that are pretty well baked in:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It consists of two HUB75 LED panels spinning around a vertical axis.&lt;/item&gt;
      &lt;item&gt;The panels use either ABCDE addressing or ABC shift register addressing.&lt;/item&gt;
      &lt;item&gt;It uses a single GPIO (a photodiode or similar) to sync to rotation - high for 180°, low for 180°.&lt;/item&gt;
      &lt;item&gt;It's running on a Raspberry Pi 4.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The GPIO mappings and panel layout are defined in &lt;code&gt;src/driver/gadgets/gadget_&amp;lt;name&amp;gt;.h&lt;/code&gt;. GPIO is via memory mapped
access - if you're using a different model of Pi you'll need to change &lt;code&gt;BCM_BASE&lt;/code&gt; in the GPIO code. I haven't tested
this, and you should probably assume it doesn't work.&lt;/p&gt;
    &lt;p&gt;Input is via a bluetooth gamepad - I've been using an Xbox controller, and the input system is based on the default mapping for that.&lt;/p&gt;
    &lt;p&gt;Audio out is also via bluetooth. I haven't had success with the higher quality codecs, but the headset protocol works.&lt;/p&gt;
    &lt;p&gt;There are two parts to this code - the driver, which creates a voxel buffer in shared memory and scans its contents out in sync with rotation, and the client code which generates content and writes it into the voxel buffer. Both driver and client code are designed to run on the same device, a Raspberry Pi embedded in the hardware and spinning at several hundred RPM. There is a demo included in the Python directory which streams point clouds from a PC over wifi to the device, but fundamentally it's designed as a self contained gadget, like an alternate timeline Vectrex. A bluetooth gamepad is used to control the demos.&lt;/p&gt;
    &lt;code&gt;├── src
│   ├── driver
│   │   ├── gadgets         -- the different volumetric display configurations
│   │   │   └──             
│   │   └── vortex.c        -- driver code - creates a voxel buffer in shared memory,
│   │                          and handles scanning it out to the led panels in sync with
│   │                          the rotation
│   ├── simulator
│   │   └── virtex.c        -- software simulator - presents the same voxel buffer as
│   │                          the driver would, but renders the contents into an X11 window
│   │
│   ├── multivox            -- front end / launcher for the various volumetric toys
│   │   └──
│   ├── platform            -- common client code
│   │   └──
│   └── toys                -- a collection of volumetric demos using the shared voxel buffer
│       ├── eighty          -- multiplayer light cycles
│       ├── fireworks.c     -- cheesy first demo
│       ├── flight.c        -- some kind of 70s scifi thing
│       ├── tesseract.c     -- a 4D cubube
│       ├── viewer.c        -- viewer for .obj and .png files
│       └── zander          -- lander/zarch/virus-esque
├── python  
│   ├── calibration.py      -
│   ├── grid.py             -- some pattern generators, useful when calibrating the device
│   ├── colourwheel.py      -
│   ├── obj2c.py            -- tool for embedding .obj models in a header file
│   ├── pointvision.py      -- receive point clouds streamed from vortexstream.py
│   └── vortexstream.py     -- stream point clouds to pointvision.py
└── README.md               -- you are here
&lt;/code&gt;
    &lt;p&gt;On the Raspberry Pi, clone the repository:&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/AncientJames/multivox.git
&lt;/code&gt;
    &lt;p&gt;Configure the project for your hardware:&lt;/p&gt;
    &lt;code&gt;cd multivox
mkdir build
cd build
cmake -DMULTIVOX_GADGET=vortex ..
cmake --build .
&lt;/code&gt;
    &lt;p&gt;First, the driver has to be running:&lt;/p&gt;
    &lt;code&gt;sudo ./vortex
&lt;/code&gt;
    &lt;p&gt;When invoked from the command line it periodically outputs profiling information (frame rate, rotation rate), and accepts keyboard input for various diagnostics:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Key&lt;/cell&gt;
        &lt;cell role="head"&gt;Effect&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;esc&lt;/cell&gt;
        &lt;cell&gt;Exit&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;b&lt;/cell&gt;
        &lt;cell&gt;Bit depth - cycles through 1, 2 or 3 bits per channel. Higher bit depths result in lower refresh rates&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;u&lt;/cell&gt;
        &lt;cell&gt;Uniformity - cycles through different strategies for trading off brightness against uniformity&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;t&lt;/cell&gt;
        &lt;cell&gt;Trails - adjusts how far back to accumulate skipped voxels when the rotation rate is too high for the refresh rate&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;l&lt;/cell&gt;
        &lt;cell&gt;Lock - whether to adjust the rotation sync to keep it facing one way&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;d D&lt;/cell&gt;
        &lt;cell&gt;Drift - rotisserie mode. Introduces some explicit drift to the rotation sync&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;p&lt;/cell&gt;
        &lt;cell&gt;Panel - selectively disable the panels&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;xyz&lt;/cell&gt;
        &lt;cell&gt;Axis - When the display isn't spinning, it shows an othographic view. This lets you choose the axis&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;While that's running, try one of the toys:&lt;/p&gt;
    &lt;code&gt;./tesseract
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;viewer&lt;/code&gt; takes a list of .obj and .png files as arguments. You can scale, rotate and so on using the gamepad, and it
also accepts keyboard input when run remotely from the command line.&lt;/p&gt;
    &lt;code&gt;./viewer ~/Multivox/models/*.obj
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Control&lt;/cell&gt;
        &lt;cell role="head"&gt;Key&lt;/cell&gt;
        &lt;cell role="head"&gt;Effect&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;esc&lt;/cell&gt;
        &lt;cell&gt;Exit&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;LB/RB&lt;/cell&gt;
        &lt;cell&gt;[ / ]&lt;/cell&gt;
        &lt;cell&gt;Cycle through models&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;A&lt;/cell&gt;
        &lt;cell&gt;Walkthrough / Orbit&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;X&lt;/cell&gt;
        &lt;cell&gt;Zoom to fit&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;Toggle wireframe&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;If you don't have a physical volumetric display, there's a simulator, &lt;code&gt;virtex&lt;/code&gt;, which you can run in place of &lt;code&gt;vortex&lt;/code&gt;. It exposes the same voxel buffer in shared memory, but renders the contents using OpenGL in an X11 window.&lt;/p&gt;
    &lt;p&gt;Run without command line arguments it creates a display compatible with the currently configured gadget, but there are some options to let you experiment with different geometries:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Option&lt;/cell&gt;
        &lt;cell role="head"&gt;Effect&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;-s X&lt;/cell&gt;
        &lt;cell&gt;slice count - the number of vertical slices per revolution&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;-o X X&lt;/cell&gt;
        &lt;cell&gt;offsets - distance the front and back screens are offset from the axis, as a fraction of screen radius&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;-b X&lt;/cell&gt;
        &lt;cell&gt;bits per channel (1 - 3)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;-w X Y&lt;/cell&gt;
        &lt;cell&gt;panel resolution&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;-g X&lt;/cell&gt;
        &lt;cell&gt;scan geometry - radial or linear. Linear looks better, but it's a lot harder to build.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;An idealised device with linear scanning and 3 bits per channel can be invoked like this:&lt;/p&gt;
    &lt;code&gt;./virtex -g l -s 128 -w 1280 1280 -b 3
&lt;/code&gt;
    &lt;p&gt;The simulator is fill rate intensive; if you're running it on a Raspberry Pi you'll probably want to reduce the slice count.&lt;/p&gt;
    &lt;p&gt;If you want it to start up automatically on boot, you can install &lt;code&gt;vortex&lt;/code&gt; as a service, and set &lt;code&gt;multivox&lt;/code&gt; to run on startup.&lt;/p&gt;
    &lt;p&gt;First install everything to its default location &lt;code&gt;~/Multivox&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;make install&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This will build the executable files and copy them into the destination directory, as well as creating &lt;code&gt;.mct&lt;/code&gt; files in &lt;code&gt;~/Multivox/carts&lt;/code&gt; for the built in toys.&lt;/p&gt;
    &lt;p&gt;Create the driver service:&lt;/p&gt;
    &lt;code&gt;sudo nano /usr/lib/systemd/system/vortex.service
&lt;/code&gt;
    &lt;p&gt;and fill in the following information:&lt;/p&gt;
    &lt;code&gt;[Unit]
Description=Vortex Display Driver
After=multi-user.target

[Service]
ExecStart=/home/pi/Multivox/bin/vortex

[Install]
WantedBy=multi-user.target
&lt;/code&gt;
    &lt;p&gt;Then start it up:&lt;/p&gt;
    &lt;code&gt;sudo systemctl daemon-reload
sudo systemctl enable vortex.service
&lt;/code&gt;
    &lt;p&gt;The driver assigns itself to core 3 - you can add &lt;code&gt;isolcpus=3&lt;/code&gt; to the end of &lt;code&gt;/boot/cmdline.txt&lt;/code&gt; to ensure it's the only thing running on that core.&lt;/p&gt;
    &lt;p&gt;You'll also want the launcher to start up on boot:&lt;/p&gt;
    &lt;code&gt;crontab -e
&lt;/code&gt;
    &lt;p&gt;And add the line:&lt;/p&gt;
    &lt;code&gt;@reboot /home/pi/Multivox/bin/multivox
&lt;/code&gt;
    &lt;p&gt;If everything goes smoothly, when you turn on the device it will boot up into &lt;code&gt;Multivox&lt;/code&gt;. This is a fantasy console which
acts as a launcher for all the games and demos you run on the hardware. The bundled toys are automatically installed in
the &lt;code&gt;~/Multivox/carts/&lt;/code&gt; directory as &lt;code&gt;.mct&lt;/code&gt; files, and external apps can be launched by adding a &lt;code&gt;.mct&lt;/code&gt; file containing
its command, path and arguments.&lt;/p&gt;
    &lt;p&gt;Each &lt;code&gt;.mct&lt;/code&gt; file appears as a cartridge in the Multivox front end. They should each have a label on the side; at the moment
all you can do to distinguish between them is change their colour in the &lt;code&gt;.mct&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;When you exit an app back to the launcher, it saves a snapshot of the voxel volume, and this gives a preview of what you'll see when you launch a cart. This means there are two competing representations of the same information, and any future work on the front end will probably start with overhauling the entire approach.&lt;/p&gt;
    &lt;p&gt;Some basic UI for controls such as changing bit depth, rebooting and so on would also be a boon.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Control&lt;/cell&gt;
        &lt;cell role="head"&gt;Effect&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;LB/RB&lt;/cell&gt;
        &lt;cell&gt;Cycle through carts&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;A&lt;/cell&gt;
        &lt;cell&gt;Launch cart&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;⧉&lt;/cell&gt;
        &lt;cell&gt;Exit / resume running cart&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;△ ▽&lt;/cell&gt;
        &lt;cell&gt;Change bit depth&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;☰ x5&lt;/cell&gt;
        &lt;cell&gt;Power off&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46149813</guid><pubDate>Thu, 04 Dec 2025 16:58:35 +0000</pubDate></item><item><title>Converge (YC S23) is hiring a martech expert in NYC</title><link>https://www.runconverge.com/careers/technical-customer-success-manager</link><description>&lt;doc fingerprint="ad21d2738937a54f"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Technical Customer Success Manager&lt;/head&gt;
    &lt;p&gt;Converge is building the definitive Growth OS: We help DTC Growth teams understand which marketing efforts drive profitable growth. We are the only platform combining best-in-class tracking with blended reporting and multi-touch attribution.&lt;/p&gt;
    &lt;p&gt;Our unique positioning has led to rapid growth in both number and size of customers. One of the secrets of our growth is that we invest heavily in customer success. Whereas our competitors see success as a cost center, we take pride in delivering expert martech and marketing reporting support throughout the entire customer lifecycle and we compensate accordingly.&lt;/p&gt;
    &lt;p&gt;Our strategy is paying off, with 200+ paying customers (including some of the most famous DTC brands) and strong investor backing. We are now looking for a senior Technical Customer Success Manager to help us scale to $10M+ ARR.&lt;/p&gt;
    &lt;head rend="h3"&gt;Responsibilities&lt;/head&gt;
    &lt;p&gt;Be a marketing measurement expert: Advise customers on attribution, conversion tracking, and reporting strategies, positioning yourself as a trusted technical partner.&lt;/p&gt;
    &lt;p&gt;Technical support: Investigate and resolve conversion tracking and attribution issues reported through all channels, including email, Slack and in-app.&lt;/p&gt;
    &lt;p&gt;Onboard new customers: Own the customer onboarding end-to-end, driving them from initial implementation to real and lasting success.&lt;/p&gt;
    &lt;p&gt;Drive renewals: Take full ownership of renewal conversations, mitigating churn risk and implementing proactive retention strategies.&lt;/p&gt;
    &lt;p&gt;Champion customer needs: Surface trends and insights from collected customer feedback to the team at large to inform product roadmap.&lt;/p&gt;
    &lt;p&gt;Activate: Maximize the adoption of our product features and provide proactive, regular recommendations to get more out of the platform.&lt;/p&gt;
    &lt;p&gt;Expand customer contracts: Identify and execute expansion opportunities to increase account value.&lt;/p&gt;
    &lt;p&gt;Lead strategic projects: Improve the support experience and feature adoption.&lt;/p&gt;
    &lt;head rend="h3"&gt;You will thrive in this role if you&lt;/head&gt;
    &lt;p&gt;Have strong martech experience: Google Tag Manager, Meta Events Manager, Google Consent Mode and other pieces of the martech stack have no secrets for you.&lt;/p&gt;
    &lt;p&gt;Are curious and technical: You love understanding complex products deeply. Bonus points if you already love JS debugging, sifting through network requests or reasoning over attribution logic.&lt;/p&gt;
    &lt;p&gt;Thrive in ambiguity: You enjoy building processes from scratch and figuring things out without a playbook.&lt;/p&gt;
    &lt;p&gt;Are commercially minded: You know how to uncover customer needs and tie solutions to real business value.&lt;/p&gt;
    &lt;p&gt;Have advertising experience: You speak the language of a growth team, and have experience with Ads Managers, attribution and creative strategy.&lt;/p&gt;
    &lt;head rend="h3"&gt;This role is not for you if you&lt;/head&gt;
    &lt;p&gt;Do not want to become an expert: Our customers choose us because we deeply understand their technical challenges.&lt;/p&gt;
    &lt;p&gt;Prefer certainty over upside: There are no rigid and limited responsibilities here - we grant a lot of agency and expect a lot of accountability.&lt;/p&gt;
    &lt;p&gt;Don't like working hard: This role demands more commitment and agency than a typical success role.&lt;/p&gt;
    &lt;p&gt;Prefer remote over in-person: We believe being in-person helps us move faster.&lt;/p&gt;
    &lt;head rend="h3"&gt;What we offer&lt;/head&gt;
    &lt;p&gt;Compensation: $155k - $217k + equity: 0.1% - 0.25%.&lt;/p&gt;
    &lt;p&gt;Career-defining opportunity to build the U.S. success function and work with the world's best DTC growth teams.&lt;/p&gt;
    &lt;p&gt;Private health, dental, and vision insurance.&lt;/p&gt;
    &lt;p&gt;Pension &amp;amp; 401k contributions.&lt;/p&gt;
    &lt;p&gt;Opportunity to work on a complex product that customers love - 35% of our users use us daily (!)&lt;/p&gt;
    &lt;head rend="h3"&gt;Interview process*&lt;/head&gt;
    &lt;p&gt;Application: We're looking to see how your skills and experience align with our needs.&lt;/p&gt;
    &lt;p&gt;Intro interview (30-min): Our goal is to learn more about what you are looking for in your next role, explore your motivations to join our team, why you would be a great fit, and answer questions about us.&lt;/p&gt;
    &lt;p&gt;Culture interview (45-min): We will walk through your experience and background in detail.&lt;/p&gt;
    &lt;p&gt;Case interview (1 hour): We will simulate a real customer situation.&lt;/p&gt;
    &lt;p&gt;Offer If everyoneâs aligned, weâll move quickly to make you an offer.&lt;/p&gt;
    &lt;p&gt;(*) can be done in 2 days, just flag to us that you want to do it fast.&lt;/p&gt;
    &lt;head rend="h2"&gt;We raised $5.7M from some of the best investors&lt;/head&gt;
    &lt;head rend="h3"&gt;James Hawkins&lt;/head&gt;
    &lt;head rend="h3"&gt;Nicolas Dessaigne&lt;/head&gt;
    &lt;head rend="h2"&gt;What makes Converge unique&lt;/head&gt;
    &lt;head rend="h3"&gt;Ridiculously lean&lt;/head&gt;
    &lt;p&gt;We operate a &amp;gt;$1M ARR business with &amp;gt;200 customers with a team of just 9 people.&lt;/p&gt;
    &lt;p&gt;Why you should care:&lt;/p&gt;
    &lt;p&gt;You will not find a startup with this level of product-market-fit where you can join as employee #10.&lt;/p&gt;
    &lt;head rend="h3"&gt;Huge product surface&lt;/head&gt;
    &lt;p&gt;We compete with Segment, Fivetran, Google Tag Manager, Rockerbox, Looker, just to name a few.&lt;/p&gt;
    &lt;p&gt;Why you should care:&lt;/p&gt;
    &lt;p&gt;Other startups give you ownership of a feature. At Converge, you get ownership over an entire product.&lt;/p&gt;
    &lt;head rend="h3"&gt;Customers rely on us&lt;/head&gt;
    &lt;p&gt;Converge sees 35% of its users daily, while this is only 13% for the average SaaS company.&lt;/p&gt;
    &lt;p&gt;Why you should care:&lt;/p&gt;
    &lt;p&gt;Our customers will be excited by every feature you ship, and your impact will be felt immediately.&lt;/p&gt;
    &lt;head rend="h3"&gt;Real scale&lt;/head&gt;
    &lt;p&gt;We collect around 20M customer interactions per day and process ~$3B in GMV annually.&lt;/p&gt;
    &lt;p&gt;Why you should care:&lt;/p&gt;
    &lt;p&gt;Even though you join early, this job comes with real engineering challenges.&lt;/p&gt;
    &lt;head rend="h2"&gt;How we started&lt;/head&gt;
    &lt;head rend="h3"&gt;Did you knowâ¦&lt;/head&gt;
    &lt;p&gt;All co-founders have written code that has run in production as part of Converge.&lt;/p&gt;
    &lt;p&gt;We closed our first publicly traded company during our YC batch from our living room in San Francisco.&lt;/p&gt;
    &lt;p&gt;Thomas and Tiago (Founding Engineer) worked together when Thomas was just an intern.&lt;/p&gt;
    &lt;p&gt;Michel (Customer Success) was responsible for most of the incoming Converge Support tickets in his previous job as a freelance tracking consultant.&lt;/p&gt;
    &lt;p&gt;Thomas and Jan were best friends in high school, and Jan and Jerome met in their first year of college.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46149849</guid><pubDate>Thu, 04 Dec 2025 17:00:37 +0000</pubDate></item><item><title>PyTogether: Collaborative lightweight real-time Python IDE for teachers/learners</title><link>https://github.com/SJRiz/pytogether</link><description>&lt;doc fingerprint="123b677f1dffb17a"&gt;
  &lt;main&gt;
    &lt;p&gt;&lt;lb/&gt; PyTogether&lt;lb/&gt; Google docs for Python. A fully browser-based collaborative Python IDE with real-time editing, chat, and visualization. &lt;lb/&gt; pytogether.org &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Real-time Collaboration - Edit Python code together instantly using Y.js.&lt;/item&gt;
      &lt;item&gt;Secure Authentication - Log in manually or with Google OAuth.&lt;/item&gt;
      &lt;item&gt;Groups &amp;amp; Projects - Organize your work into teams and projects.&lt;/item&gt;
      &lt;item&gt;Live Drawings - Draw directly on the IDE to assist with note-taking or teaching.&lt;/item&gt;
      &lt;item&gt;Live Cursors/Selections - Google docs-like live selections for smoother collaboration.&lt;/item&gt;
      &lt;item&gt;Live Chat and Voice Calls - Real-time messaging, and Discord-like voice chats for each project.&lt;/item&gt;
      &lt;item&gt;Code Linting - Integrated CodeMirror linting for cleaner, error-free code.&lt;/item&gt;
      &lt;item&gt;Smart Autosave - Code is automatically saved every minute and on exit.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When starting out in programming, many beginners find traditional IDEs overwhelming: full of plugins, extensions, configuration steps, paywalls, and complex UIs. PyTogether removes these barriers by offering a lightweight, distraction-free environment where you can focus on writing Python code right away.&lt;/p&gt;
    &lt;p&gt;The platform is designed for learning, teaching, and pair programming, making it ideal for classrooms, coding clubs, or quick collaborations.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Note: PyTogether is intended for educational purposes and beginner use. It is not optimized for large-scale production development.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;While there are many online IDEs (Replit, Jupyter, Google Colab, etc.), PyTogether is built with a different goal: simplicity first.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;⚡Instant Setup⚡- No downloads, no pip installs, no hidden complexity. Just create a group, create a project, and bam!&lt;/item&gt;
      &lt;item&gt;Beginner Focused - No confusing menus, terminals, or configuration. Just code and run.&lt;/item&gt;
      &lt;item&gt;Real-Time Collaboration - Work together with classmates, friends, or mentors in the same editor.&lt;/item&gt;
      &lt;item&gt;Safe Learning Space - Limited features by design to reduce distractions and keep beginners focused.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Unlike production-grade IDEs, PyTogether prioritizes ease of use and collaboration for learners rather than advanced features.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Backend: Django, Django REST Framework (DRF)&lt;/item&gt;
      &lt;item&gt;Real-Time: Y.js, WebSockets (Django Channels)&lt;/item&gt;
      &lt;item&gt;Async Processing: Celery&lt;/item&gt;
      &lt;item&gt;Data Store: PostgreSQL (via Supabase)&lt;/item&gt;
      &lt;item&gt;Caching, Broker, &amp;amp; Channel layers: Redis&lt;/item&gt;
      &lt;item&gt;Frontend: React, Tailwind CSS, CodeMirror (code linting)&lt;/item&gt;
      &lt;item&gt;Python Execution: Pyodide (via Web Worker)&lt;/item&gt;
      &lt;item&gt;Deployment: Vercel (Frontend), Docker on VPS (Backend), Nginx (reverse proxy)&lt;/item&gt;
      &lt;item&gt;CI/CD: GitHub Actions (deploy backend to VPS on push to main)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Requirements: Docker, Node&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Running PyTogether locally is a simple two-step process. Run the following commands from the project root:&lt;/p&gt;
    &lt;code&gt;# 1. Install all dependencies (automatically does it for root and frontend)
npm install

# 2. Start the servers
npm run dev&lt;/code&gt;
    &lt;p&gt;This will install all required packages and run the backend container and start the frontend. It should take around 2-5 minutes on initial launch. The frontend will be live on http://localhost:5173. You can do CTRL+C to stop the program/containers.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Note Two superusers are created automatically:&lt;/p&gt;&lt;item&gt;Email:&lt;/item&gt;&lt;code&gt;test1@gmail.com&lt;/code&gt;&lt;item&gt;Email:&lt;/item&gt;&lt;code&gt;test2@gmail.com&lt;/code&gt;&lt;p&gt;Both have the password&lt;/p&gt;&lt;code&gt;testtest&lt;/code&gt;. You can log in with them on the frontend.&lt;/quote&gt;
    &lt;p&gt;You may also adjust the settings in backend/backend/settings/dev.py&lt;/p&gt;
    &lt;p&gt;Jawad Rizvi&lt;/p&gt;
    &lt;p&gt;Applied Mathematics &amp;amp; Computer Engineering student at Queen's University.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46150447</guid><pubDate>Thu, 04 Dec 2025 17:43:07 +0000</pubDate></item><item><title>Why are 38 percent of Stanford students saying they're disabled?</title><link>https://reason.com/2025/12/04/why-are-38-percent-of-stanford-students-saying-theyre-disabled/</link><description>&lt;doc fingerprint="1e71405b38cb1c86"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why Are 38 Percent of Stanford Students Saying They're Disabled?&lt;/head&gt;
    &lt;head rend="h2"&gt;If you get into an elite college, you probably don't have a learning disability.&lt;/head&gt;
    &lt;p&gt;The students at America's elite universities are supposed to be the smartest, most promising young people in the country. And yet, shocking percentages of them are claiming academic accommodations designed for students with learning disabilities.&lt;/p&gt;
    &lt;p&gt;In an article published this week in The Atlantic, education reporter Rose Horowitch lays out some shocking numbers. At Brown and Harvard, 20 percent of undergraduate students are disabled. At Amherst College, that's 34 percent. At Stanford University, it's a galling 38 percent. Most of these students are claiming mental health conditions and learning disabilities, like anxiety, depression, and ADHD.&lt;/p&gt;
    &lt;p&gt;Obviously, something is off here. The idea that some of the most elite, selective universities in America—schools that require 99th percentile SATs and sterling essays—would be educating large numbers of genuinely learning disabled students is clearly bogus. A student with real cognitive struggles is much more likely to end up in community college, or not in higher education at all, right?&lt;/p&gt;
    &lt;p&gt;The professors Horowitz interviewed largely back up this theory. "You hear 'students with disabilities' and it's not kids in wheelchairs," one professor told Horowitch. "It's just not. It's rich kids getting extra time on tests." Talented students get to college, start struggling, and run for a diagnosis to avoid bad grades. Ironically, the very schools that cognitively challenged students are most likely to attend—community colleges—have far lower rates of disabled students, with only three to four percent of such students getting accommodations.&lt;/p&gt;
    &lt;p&gt;To be fair, some of the students receiving these accommodations do need them. But the current language of the Americans with Disabilities Act (ADA) allows students to get expansive accommodations with little more than a doctor's note.&lt;/p&gt;
    &lt;p&gt;While some students are no doubt seeking these accommodations as semi-conscious cheaters, I think most genuinely identify with the mental health condition they're using to get extra time on tests. Over the past few years, there's been a rising push to see mental health and neurodevelopmental conditions as not just a medical fact, but an identity marker. Will Lindstrom, the director of the Regents' Center for Learning Disorders at the University of Georgia, told Horowitch that he sees a growing number of students with this perspective. "It's almost like it's part of their identity," Lindstrom told her. "By the time we see them, they're convinced they have a neurodevelopmental disorder."&lt;/p&gt;
    &lt;p&gt;What's driving this trend? Well, the way conditions like ADHD, autism, and anxiety get talked about online—the place where most young people first learn about these conditions—is probably a contributing factor. Online creators tend to paint a very broad picture of the conditions they describe. A quick scroll of TikTok reveals creators labeling everything from always wearing headphones, to being bad at managing your time, to doodling in class as a sign that someone may have a diagnosable condition. According to these videos, who isn't disabled?&lt;/p&gt;
    &lt;p&gt;The result is a deeply distorted view of "normal." If ever struggling to focus or experiencing boredom is a sign you have ADHD, the implication is that a "normal," nondisabled person has essentially no problems. A "neurotypical" person, the thinking goes, can churn out a 15-page paper with no hint of procrastination, maintain perfect focus during a boring lecture, and never experience social anxiety or awkwardness. This view is buffeted by the current way many of these conditions are diagnosed. As Horowitch points out, when the latest issue of the DSM, the manual psychiatrists use to diagnose patients, was released in 2013, it significantly lowered the bar for an ADHD diagnosis. When the definition of these conditions is set so liberally, it's easy to imagine a highly intelligent Stanford student becoming convinced that any sign of academic struggle proves they're learning disabled, and any problems making friends are a sign they have autism.&lt;/p&gt;
    &lt;p&gt;Risk-aversion, too, seems like a compelling factor driving bright students to claim learning disabilities. Our nation's most promising students are also its least assured. So afraid of failure—of bad grades, of a poorly-received essay—they take any sign of struggle as a diagnosable condition. A few decades ago, a student who entered college and found the material harder to master and their time less easily managed than in high school would have been seen as relatively normal. Now, every time she picks up her phone, a barrage of influencers is clamoring to tell her this is a sign she has ADHD. Discomfort and difficulty are no longer perceived as typical parts of growing up.&lt;/p&gt;
    &lt;p&gt;In this context, it's easy to read the rise of academic accommodations among the nation's most intelligent students as yet another manifestation of the risk-aversion endemic in the striving children of the upper middle class. For most of the elite-college students who receive them, academic accommodations are a protection against failure and self-doubt. Unnecessary accommodations are a two-front form of cheating—they give you an unjust leg-up on your fellow students, but they also allow you to cheat yourself out of genuine intellectual growth. If you mask learning deficiencies with extra time on texts, soothe social anxiety by forgoing presentations, and neglect time management skills with deadline extensions, you might forge a path to better grades. But you'll also find yourself less capable of tackling the challenges of adult life.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46150715</guid><pubDate>Thu, 04 Dec 2025 18:04:07 +0000</pubDate></item><item><title>Hammersmith Bridge – Where did 25,000 vehicles go?</title><link>https://nickmaini.substack.com/p/hammersmith-bridge</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46151335</guid><pubDate>Thu, 04 Dec 2025 18:52:22 +0000</pubDate></item><item><title>The RAM shortage comes for us all</title><link>https://www.jeffgeerling.com/blog/2025/ram-shortage-comes-us-all</link><description>&lt;doc fingerprint="be6c90491cb603ba"&gt;
  &lt;main&gt;
    &lt;p&gt;Memory price inflation comes for us all, and if you're not affected yet, just wait.&lt;/p&gt;
    &lt;p&gt;I was building a new PC last month using some parts I had bought earlier this year. The 64 Gigabyte T-Create DDR5 memory kit I used cost $209 then. Today? The same kit costs $650!&lt;/p&gt;
    &lt;p&gt;Just in the past week, we found out Raspberry Pi's increasing their single board computer prices. Micron's killing the Crucial brand of RAM and storage devices completely, meaning there's gonna be one fewer consumer memory manufacturer. Samsung can't even buy RAM from themselves to build their own Smartphones, and small vendors like Libre Computer and Mono are seeing RAM prices double, triple, or even worse, and they're not even buying the latest RAM tech!&lt;/p&gt;
    &lt;p&gt;I think PC builders might be the first crowd to get impacted across the board—just look at these insane graphs from PC Parts Picker, showing RAM prices going from like $30 to $120 for DDR4, or like $150 to five hundred dollars for 64 gigs of DDR5.&lt;/p&gt;
    &lt;p&gt;But the impacts are only just starting to hit other markets.&lt;/p&gt;
    &lt;p&gt;Libre Computer mentioned on Twitter a single 4 gigabyte module of LPDDR4 memory costs $35. That's more expensive than every other component on one of their single board computers combined! You can't survive selling products at a loss, so once the current production batches are sold through, either prices will be increased, or certain product lines will go out of stock.&lt;/p&gt;
    &lt;p&gt;The smaller the company, the worse the price hit will be. Even Raspberry Pi, who I'm sure has a little more margin built in, already raised SBC prices (and introduced a 1 GB Pi 5—maybe a good excuse for developers to drop Javascript frameworks and program for lower memory requirements again?).&lt;/p&gt;
    &lt;p&gt;Cameras, gaming consoles, tablets, almost anything that has memory will get hit sooner or later.&lt;/p&gt;
    &lt;p&gt;I can't believe I'm saying this, but compared to the current market, Apple's insane memory upgrade pricing is... actually in line with the rest of the industry.&lt;/p&gt;
    &lt;p&gt;The reason for all this, of course, is AI datacenter buildouts. I have no clue if there's any price fixing going on like there was a few decades ago—that's something conspiracy theorists can debate—but the problem is there's only a few companies producing all the world's memory supplies.&lt;/p&gt;
    &lt;p&gt;And those companies all realized they can make billions more dollars making RAM just for AI datacenter products, and neglect the rest of the market.&lt;/p&gt;
    &lt;p&gt;So they're shutting down their consumer memory lines, and devoting all production to AI.&lt;/p&gt;
    &lt;p&gt;Even companies like GPU board manufacturers are getting shafted; Nvidia's not giving memory to them along with their chips like they used to, basically telling them "good luck, you're on your own for VRAM now!"&lt;/p&gt;
    &lt;p&gt;Which is especially rich, because Nvidia's profiting obscenely off of all this stuff.&lt;/p&gt;
    &lt;p&gt;That's all bad enough, but some people see a silver lining. I've seen some people say "well, once the AI bubble bursts, at least we'll have a ton of cheap hardware flooding the market!"&lt;/p&gt;
    &lt;p&gt;And yes, in past decades, that might be one outcome.&lt;/p&gt;
    &lt;p&gt;But the problem here is the RAM they're making, a ton of it is either integrated into specialized GPUs that won't run on normal computers, or being fitted into special types of memory modules that don't work on consumer PCs, either. (See: HBM).&lt;/p&gt;
    &lt;p&gt;That, and the GPUs and servers being deployed now don't even run on normal power and cooling, they're part of massive systems that would take a ton of effort to get running in even the most well-equipped homelabs. It's not like the classic Dell R720 that just needs some air and a wall outlet to run.&lt;/p&gt;
    &lt;p&gt;That is to say, we might be hitting a weird era where the PC building hobby is gutted, SBCs get prohibitively expensive, and anyone who didn't stockpile parts earlier this year is, pretty much, in a lurch.&lt;/p&gt;
    &lt;p&gt;Even Lenovo admits to stockpiling RAM, making this like the toilet paper situation back in 2020, except for massive corporations. Not enough supply, so companies who can afford to get some will buy it all up, hoping to stave off the shortages that will probably last longer, partly because of that stockpiling.&lt;/p&gt;
    &lt;p&gt;I don't think it's completely outlandish to think some companies will start scavenging memory chips (ala dosdude1) off other systems for stock, especially if RAM prices keep going up.&lt;/p&gt;
    &lt;p&gt;It's either that, or just stop making products. There are some echoes to the global chip shortages that hit in 2021-2022, and that really shook up the market for smaller companies.&lt;/p&gt;
    &lt;p&gt;I hate to see it happening again, but somehow, here we are a few years later, except this time, the AI bubble is to blame.&lt;/p&gt;
    &lt;p&gt;Sorry for not having a positive note to end this on, but I guess... maybe it's a good time to dig into that pile of old projects you never finished instead of buying something new this year.&lt;/p&gt;
    &lt;p&gt;How long will this last? That's anybody's guess. But I've already put off some projects I was gonna do for 2026, and I'm sure I'm not the only one.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46151578</guid><pubDate>Thu, 04 Dec 2025 19:16:11 +0000</pubDate></item></channel></rss>