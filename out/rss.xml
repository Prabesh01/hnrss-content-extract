<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sun, 09 Nov 2025 18:13:13 +0000</lastBuildDate><item><title>Ironclad – formally verified, real-time capable, Unix-like OS kernel</title><link>https://ironclad-os.org/</link><description>&lt;doc fingerprint="6fd6e97a45ab3f80"&gt;
  &lt;main&gt;
    &lt;p&gt;Ironclad is a (partially) formally verified, real-time capable, UNIX-like operating system kernel for general-purpose and embedded uses. It is written in SPARK and Ada, and is comprised of 100% free software.&lt;/p&gt;
    &lt;p&gt;Ironclad features a familiar POSIX-compatible interface, true simultaneous preemptive multitasking, Mandatory Access Control (MAC), and support for hard real-time scheduling.&lt;/p&gt;
    &lt;p&gt;Ironclad is fully open source and distributed under the GPLv3, ensuring it remains free. No firmware blobs are needed or shipped with the kernel. Every piece of the stack is open source.&lt;/p&gt;
    &lt;p&gt;SPARK's state of the art formal verification is employed for ensuring absence of errors and correctness of big portions of Ironclad, like cryptography, MAC, and user-facing facilities.&lt;/p&gt;
    &lt;p&gt;Ported to several platforms and boards, and designed to be easily portable to many more. Dependency on only the GNU toolchain allows for easy cross-compilation.&lt;/p&gt;
    &lt;p&gt;Ironclad will always be free for use, study, and modification, so, to support the project, we rely on the use of donations and grants. Every contribution makes a difference and allows us to do more.&lt;/p&gt;
    &lt;p&gt;This project is funded through NGI Zero Core, a fund established by NLnet with financial support from the European Commission's Next Generation Internet program. Learn more at the NLnet project page.&lt;/p&gt;
    &lt;p&gt;Additionally, we would like to thank the following organizations:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45860843</guid><pubDate>Sat, 08 Nov 2025 23:03:10 +0000</pubDate></item><item><title>How Airbus took off</title><link>https://worksinprogress.co/issue/how-airbus-took-off/</link><description>&lt;doc fingerprint="f5e48050ae83878f"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Airbus is an example of successful industrial policy and the rare European company that is better than its American rival. Could its success be copied elsewhere?&lt;/head&gt;
    &lt;p&gt;Would you rather fly in an Airbus or a Boeing? It seems like an easy question.&lt;/p&gt;
    &lt;p&gt;As Alaska Airlines Flight 1282 flight climbed to 16,000 feet on a January evening in 2024, passengers were stunned when a hole was blasted in the side of the plane. They were hit by howling winds as tray tables were ripped from the backs of seats. Were it not for their seatbelts, they would likely have been sucked out of the plane. It later transpired that the plug which sealed the exit door was missing four critical bolts that held it in place.&lt;/p&gt;
    &lt;p&gt;Subscribe for $100 to receive six beautiful issues per year.&lt;/p&gt;
    &lt;p&gt;The Alaska Airlines incident fortunately didn’t result in any fatalities. Not everyone who has flown on a Boeing 737 MAX in the last few years has been so lucky.&lt;/p&gt;
    &lt;p&gt;2018 and 2019 saw two 737 crashes that killed 346 people after the plane’s Maneuvering Characteristics Augmentation System, a feature that pushes the plane’s nose down to prevent stalling, triggered repeatedly due to a faulty sensor. It later transpired that Boeing had not adequately disclosed how the system worked in training manuals.&lt;/p&gt;
    &lt;p&gt;While Boeing wrestles with lawsuits and regulatory investigations, its rival Airbus has stayed out of the headlines – a happier place for the manufacturer of commercial airliners.&lt;/p&gt;
    &lt;p&gt;Europe is a graveyard of failed national champions. They span from the glamorous Concorde to obscure ventures like pan-European computer consortium Unidata or notorious Franco-German search engine Quaero.&lt;/p&gt;
    &lt;p&gt;Airbus is the rare success story. European governments pooled resources and subsidized their champion aggressively to face down a titan of American capitalism in a strategically vital sector. Why did Airbus succeed when so many similar initiatives crashed and burned?&lt;/p&gt;
    &lt;p&gt;Airbus prevailed because it was the least European version of a European industrial strategy project ever. It put its customer first, was uninterested in being seen as European, had leadership willing to risk political blowback in the pursuit of a good product, and operated in a unique industry.&lt;/p&gt;
    &lt;head rend="h2"&gt;An industry on the brink&lt;/head&gt;
    &lt;p&gt;In the early days of commercial aviation, US aerospace companies dominated the market for passenger jets.&lt;/p&gt;
    &lt;p&gt;The Buy America Act of 1933 forced the US government to buy from American producers where possible. Military orders supercharged the industry and brought significant knowledge spillovers.&lt;/p&gt;
    &lt;p&gt;The Boeing B-47 bomber, introduced in the late 1940s, pioneered the use of 35-degree swept wings, which point backwards at an angle of 35 degrees and reduce drag at high speeds. This design went on to inspire nearly every commercial airliner around the world.&lt;/p&gt;
    &lt;p&gt;Meanwhile the Boeing 707, the company’s first ever airliner, shared a fuselage with the KC-135 Stratotanker, a military refueling aircraft.&lt;/p&gt;
    &lt;p&gt;In the face of the US, European aerospace companies cut a sorry figure. The British Aircraft Corporation, Sud Aviation in France, and Messerschmitt-Bölkow-Blohm (MBB) in West Germany were all left to compete for orders in a fragmented continental market, with little research or marketing heft. Meanwhile, European airliners who bought American planes could apply for discounted loans from EXIM, the America’s credit export agency.&lt;/p&gt;
    &lt;p&gt;Between 1960 and 1967, British and French manufacturers saw a 50 percent decline in aircraft deliveries. In 1966, the UK government had even contemplated forcibly merging and nationalizing much of the country’s industry.&lt;/p&gt;
    &lt;p&gt;European governments had poured money into their national champions in the belief that the maintenance of a civilian aerospace industry was critical for sovereignty, but it was unclear if these companies would survive the decade.&lt;/p&gt;
    &lt;p&gt;Amid this gloomy backdrop, European governments concluded that their industry’s future depended on cooperation.&lt;/p&gt;
    &lt;p&gt;The UK and France agreed to pool the resources behind Concorde in 1962 to fight what Charles De Gaulle called ‘the American colonization of the skies’, but the Germans declined to participate due to their (well-founded) skepticism about the project’s economics. This didn’t stop the Germans teaming up with the Dutch on the long-forgotten VFW-Fokker 614. This short-haul jet struggled to find customers at a time when airlines preferred to use cheap prop aircraft for regional city-hopping, dooming the project to collapse once state aid was withdrawn in 1977.&lt;/p&gt;
    &lt;p&gt;In 1965, the French, British, and German governments launched a working group to evaluate the potential of a wide-body commercial aircraft, which would later become the A300. Two years later, the three governments agreed to bear the entire costs of the development of the ‘European Airbus’. In 1970, the coalition was formalized with the creation of Airbus Industrie. The consortium quickly expanded to include Spain and the Netherlands.&lt;/p&gt;
    &lt;head rend="h2"&gt;The making of a world leader&lt;/head&gt;
    &lt;p&gt;So how did this unlikely band of brothers go on to build a global leader, rather than another Econ101 case study about the perils of industrial policy?&lt;/p&gt;
    &lt;p&gt;The single biggest factor was a focus on the customer.&lt;/p&gt;
    &lt;p&gt;Unlike many future industrial strategy projects, which would focus on creating European-owned capabilities for their own sake, the Airbus team were seized by the need to build a jet that airliners would want to buy. They didn’t have much choice: if they failed, there was a reasonable chance the consortium’s domestic aerospace suppliers would collapse.&lt;/p&gt;
    &lt;p&gt;They were helped enormously in this by their setup. While Airbus didn’t become a unified corporate entity until 2001, the partnership had a strong central leadership from the beginning. Unlike other industrial consortia, which tended to be leaderless venues for intra-European turf wars, Airbus united marketing, procurement, and design.&lt;/p&gt;
    &lt;p&gt;Roger Béteille, who led the A300 program, probably bears more responsibility for Airbus’s early success than anyone else. Béteille wasn’t interested in building an inferior European Boeing copy. Instead, he invested significant time in getting to know his potential customers and what they needed. This led to Airbus quickly tossing the original design for a 300-seat A300, in favor of a 225-250 seater, when it became clear that Air France and Lufthansa wanted a smaller product.&lt;/p&gt;
    &lt;p&gt;The revised A300B would prove much cheaper to develop, in part because it allowed the consortium to dispense with the expensive Rolls Royce engine in favour of a cheaper American alternative. In response, the UK exited the project, only to later return with a lower ownership stake.&lt;/p&gt;
    &lt;p&gt;This willingness to risk political blowback and avoid petty chauvinism in equipment choice was rare in industrial strategy.&lt;/p&gt;
    &lt;p&gt;Béteille went one step further. He designated English the official language of the project, instead of the usual mixture of languages that characterised European projects, and forbade the use of metric measurements to make it easier to sell into the US market.&lt;/p&gt;
    &lt;p&gt;Along with Felix Kracht, Airbus’s first production director, Béteille set a division of labour between the different countries that has persisted, with minor adjustments. French firms handled the cockpit, control systems, and lower-center fuselage; Hawker Siddeley (the inventor of the Harrier jump jet) in the UK designed and built the wings; German companies produced various fuselage sections; the Netherlands managed moving wing components; and Spain was responsible for the horizontal tailplane.&lt;/p&gt;
    &lt;p&gt;Based on Béteille’s market research, the A300B was optimised for fuel efficiency. The team stripped out unnecessary weight by using composite materials and raised the cabin floor to add cargo space. Hawker Siddeley’s wings, which would go on to influence industry standards, were designed with a curved shape on top to reduce air resistance, allowing greater lift and fuel efficiency.&lt;/p&gt;
    &lt;p&gt;At a time when almost every commercial jet had three or four engines, Airbus opted for a twin-engine design. The plane could theoretically fly on one and the company concluded that only a single extra engine was needed to provide redundancy for safety. The much cheaper twin-engine design is now the industry standard, even for ultra long-haul flights.&lt;/p&gt;
    &lt;p&gt;Despite the technical ingenuity behind the A300B, early business was slow. By the time the aircraft entered service in 1974, it had struggled to attract commercial interest beyond state-owned flag carriers like Air France, which had placed the first A300B order in 1971 for six jets. Even these airlines continued to operate Boeing-dominated fleets.&lt;/p&gt;
    &lt;p&gt;One problem was unfortunate timing: the oil shock of 1973 had caused operating costs to spiral for airliners, so there was little appetite for experimentation in the air.&lt;/p&gt;
    &lt;p&gt;There was also residual suspicion of European industry among US airliners. Sud Aviation’s Caravelle had been used by some American airliners, but the company was notorious for its sloppy after sales maintenance and service. There had also been an ugly dispute over landing rights for Concorde, with the US heavily restricting the aircraft’s operation out of noise concerns. The French suspected more sinister commercial motivations were at work. Jacques Chirac, then French Prime Minister, raised the temperature, declaring that: ‘The Airbus consortium will not be daunted by the Americans who killed off the Concorde. … We will fight any trade war blow-by-blow as the future of the aeronautical industry and their employees is at stake’.&lt;/p&gt;
    &lt;p&gt;Against this backdrop, Airbus did everything it could to deemphasize its European heritage as it toured the US. It refused to involve the French or German embassies in its sales efforts, much to their irritation. Airbus representatives drove home how a third of the plane’s value derived from US-made components, more than any single European partner nation’s contribution. They also mastered the world of DC lobbying, successfully outmaneuvering Boeing and Lockheed’s attempts to use anti-trust regulations to shut the European entrant out of the US market.&lt;/p&gt;
    &lt;p&gt;Sustained by early European market commitments and early sales in Asia, Airbus was eventually able to clinch its first US order in 1977. Eastern Airlines (EAL), which had been impressed by the A300B’s fuel economy and low noise levels, agreed to the trial lease of four aircraft and three spare engines for … one dollar. These terms would have been unconscionable for a normal private company, but they were transformative for state-backed Airbus’s fortunes. Frank Borman, conservative Republican, former NASA astronaut, and EAL’s CEO emerged as a public champion of the A300B as an ‘American aircraft’.&lt;/p&gt;
    &lt;head rend="h2"&gt;The A320&lt;/head&gt;
    &lt;p&gt;Béteille and Kracht weren’t content with building one aircraft. From the beginning, Airbus had targeted a 30 percent global market share. This meant building more than wide-body aircraft like the A300B.&lt;/p&gt;
    &lt;p&gt;The A320, which entered operation in 1988 was a narrow-bodied aircraft that could carry 150-180 passengers. It was optimized to fly short- and medium-haul routes economically, and a masterclass in engineering and timing.&lt;/p&gt;
    &lt;p&gt;By the 1980s, airliners were looking to replace their aging narrow-bodied fleets, with the Boeing 272 and McDonnell Douglas DC-9 having been in operation for more than two decades.&lt;/p&gt;
    &lt;p&gt;The A320 was the first commercial aircraft to implement full digital fly-by-wire controls. Before the A320, the pilot’s controls pulled physical cables attached to the flaps, rudder, and other control surfaces on the plane. Fly-by-wire meant that controls sent electric signals to the plane’s computers, which then commanded motors to move the control surfaces. This made life easier for the pilots by reducing the need for constant manual adjustment and stripped out heavy components that needed maintenance.&lt;/p&gt;
    &lt;p&gt;The A320 was also the first commercial aircraft to introduce envelope protection, a system that automatically prevents dangerous actions, such as tilting too steeply, flying too slowly, or making maneuvers that could overstress the aircraft structure.&lt;/p&gt;
    &lt;p&gt;Again, the A320 wasn’t an overnight success, with new technology and existing relations with Boeing slowing uptake. Airbus again relied on British and French orders to gain market credibility. But by the early 1990s, its superior technology combined with Airbus’s willingness to flex the design, with the A319 (smaller) and A321 (larger) allowing airliners to operate mixed fleets with common cockpits, began to win fans. The A320 is now the most popular airliner family in history and remains in widespread use today.&lt;/p&gt;
    &lt;p&gt;The success of the A320 led Airbus to profitability in the mid-1990s. By 2019, Airbus had displaced Boeing as the largest aerospace company by revenue.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Airbus’s success is so hard to repeat&lt;/head&gt;
    &lt;p&gt;If Airbus proves industrial strategy can work, why haven’t other European ventures fared better?&lt;/p&gt;
    &lt;p&gt;Good industrial strategy requires favorable market conditions, consistent strategy in the face of political headwinds, and the courage to call it a day if failure seems likely. Getting one of these right is tough, and all three is exceptionally rare.&lt;/p&gt;
    &lt;p&gt;Concorde was a marvel of engineering, but even without US obstructionism, it had little prospect of commercial viability. In today’s money, it cost £16 billion to develop, roughly ten times the cost of the Boeing 727, making it the most expensive plane of its age by some margin. Its limited passenger capacity, fuel inefficiency, and expensive maintenance meant that a ticket for a round trip cost in excess of £10,000 adjusted for inflation. The ultra-premium air travel market wasn’t big enough in the 1980s or 1990s to bear the costs of 1960s technology, leading to Concorde’s retirement in 2003.&lt;/p&gt;
    &lt;p&gt;Other European projects have lacked the centralized control or clear rationale that characterized Airbus.&lt;/p&gt;
    &lt;p&gt;We see this in Unidata, a 1973 consortium that brought together CII (France), Philips (the Netherlands), and Siemens (Germany) to produce a European mainframe line to rival IBM. With no clear leadership, rival members of the consortium pushed their own hardware and software approaches. Engineering efforts were duplicated. The project collapsed within two years amid recriminations.&lt;/p&gt;
    &lt;p&gt;Meanwhile, it was unclear why the 2005 Franco-German search engine project Quaero ever needed to exist. Widely seen as a vanity project at the time, the attempt to build a search engine by committee similarly splintered along national lines. It was also a victim of mission creep, evolving from a direct Google competitor to a multimedia search platform that would be powered by image and voice analysis. The project limped on until its mercy killing in 2013.&lt;/p&gt;
    &lt;p&gt;It’s also easier to build a global leadership position when your main rival wages a prolonged campaign of self-sabotage. By the new millennium, the competition had been reduced to a simple showdown between Airbus and Boeing. Lockheed had decided to bail on commercial aviation in the 1970s after losing billions of dollars on the L-1011, while Boeing acquired McDonnell Douglas in a $13 billion deal in 1997.&lt;/p&gt;
    &lt;p&gt;While Airbus has retained a strong engineering culture at the helm, this disappeared from Boeing. Harry Stonecipher, Boeing’s CEO in the early 2000s, notoriously claimed that: ‘When people say I changed the culture of Boeing, that was the intent, so that it is run like a business rather than a great engineering firm’.&lt;/p&gt;
    &lt;p&gt;Stonecipher’s successor, James McNerney, took this even further: ‘Every 25 years a big moonshot… and then produce a 707 or a 787 – that’s the wrong way to pursue this business. The more-for-less world will not let you pursue moonshots’.&lt;/p&gt;
    &lt;p&gt;The McDonnell Douglas acquisition is often marked as a turning point for Boeing. Despite being the acquiring firm, Boeing absorbed much of their target’s management philosophy. This disconnect was embodied in the company’s decision to move its headquarters from Seattle (where its main production facility was located) to Chicago, for the sake of just $63 million in tax credits. Fatal crashes in 2018 and 2019 have since caused regulatory investigations and multi-billion dollar compensation claims to pile up, as well as allegations that the company has put shareholders and dividends before safety.&lt;/p&gt;
    &lt;head rend="h2"&gt;A strange industry&lt;/head&gt;
    &lt;p&gt;Does the Airbus story make a good case for a disciplined, well-executed industrial strategy?&lt;/p&gt;
    &lt;p&gt;To answer this question, we need to take a step back from Airbus and Boeing and think about their customers.&lt;/p&gt;
    &lt;p&gt;Airlines have one of the worst business models of any industry. They have eye-watering capital expenditures (a large jet costs in excess of $200 million). The product offering (flights) is relatively undifferentiated, while many of their customers are price-conscious and disloyal. Safety regulations, along with route and landing slot regulations mean there’s little space to drive painless efficiencies. This leaves airlines with two main routes to success: worsening their service through cost-cutting and engaging in kamikaze price wars.&lt;/p&gt;
    &lt;p&gt;This is why airlines frequently go bankrupt, with US Airways, United Airlines, Northwest Airlines, Delta Air Lines and American Airlines among the dozens to almost collapse in the 2000s. Only three airlines without state ties (Southwest, Ryanair, and Copa) have consistently maintained profitability while avoiding bankruptcy or major restructuring.&lt;/p&gt;
    &lt;p&gt;In his 2007 letter to Berkshire Hathaway shareholders, Warren Buffett described the airline industry as ‘the worst sort of business’, and noted that, ‘if a farsighted capitalist had been present at Kitty Hawk, he would have done his successors a huge favor by shooting Orville down’.&lt;/p&gt;
    &lt;p&gt;Airbus, as a supplier to these businesses, has not been immune to these pressures. In the early 2000s, airliners were enthused about the ‘hub and spoke’ model. Passengers would fly on large aircraft between major hubs, then transfer to smaller aircraft for their final destinations. With a maximum capacity of over 800, the double-decker Airbus A380 would help allow airliners to consolidate their flights between busy international hubs. By the time it entered commercial operation in 2007, fashions had reversed and consumers were willing to pay a premium to fly direct. Airbus never came close to recouping its $25 billion development costs.&lt;/p&gt;
    &lt;p&gt;Against this backdrop, companies like Airbus and Boeing face a constant downward price pressure, operating on single digit margins in good years. The merry-go-round of buyers as airliners fall in and out of bankruptcy makes them fickle customers. With this in mind, Boeing’s desire to slash costs seems like a much more rational response, even if its execution was flawed.&lt;/p&gt;
    &lt;p&gt;It may be nearly impossible to operate the multi-billion dollar, multi-decade product development cycle this industry requires without some form of government backstop, whether it is a direct subsidy (Airbus) or reliable military orders (Boeing).&lt;/p&gt;
    &lt;p&gt;It is a business that is well-suited to subsidy for other reasons too. Governments are generally better at supporting companies in established markets where innovation takes place slowly and incrementally. This is likely why state-backed efforts have found it easier to be competitive against aerospace companies than Silicon Valley giants working at breakneck pace to keep pace with changing consumer tastes.&lt;/p&gt;
    &lt;p&gt;We can learn from Airbus’s engineering ingenuity and relentless customer focus. But its success in such an idiosyncratic sector probably isn’t as template for successful industrial policy in many of the other sectors that some people would like it to be.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45861984</guid><pubDate>Sun, 09 Nov 2025 01:19:00 +0000</pubDate></item><item><title>Reverse engineering Codex CLI to get GPT-5-Codex-Mini to draw me a pelican</title><link>https://simonwillison.net/2025/Nov/9/gpt-5-codex-mini/</link><description>&lt;doc fingerprint="bc0fcf3649af53d8"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Reverse engineering Codex CLI to get GPT-5-Codex-Mini to draw me a pelican&lt;/head&gt;
    &lt;p&gt;9th November 2025&lt;/p&gt;
    &lt;p&gt;OpenAI partially released a new model yesterday called GPT-5-Codex-Mini, which they describe as "a more compact and cost-efficient version of GPT-5-Codex". It’s currently only available via their Codex CLI tool and VS Code extension, with proper API access "coming soon". I decided to use Codex to reverse engineer the Codex CLI tool and give me the ability to prompt the new model directly.&lt;/p&gt;
    &lt;p&gt;I made a video talking through my progress and demonstrating the final results.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;This is a little bit cheeky&lt;/item&gt;
      &lt;item&gt;Codex CLI is written in Rust&lt;/item&gt;
      &lt;item&gt;Iterating on the code&lt;/item&gt;
      &lt;item&gt;Let’s draw some pelicans&lt;/item&gt;
      &lt;item&gt;Bonus: the --debug option&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;This is a little bit cheeky&lt;/head&gt;
    &lt;p&gt;OpenAI clearly don’t intend for people to access this model directly just yet. It’s available exclusively through Codex CLI which is a privileged application—it gets to access a special backend API endpoint that’s not publicly documented, and it uses a special authentication mechanism that bills usage directly to the user’s existing ChatGPT account.&lt;/p&gt;
    &lt;p&gt;I figured reverse-engineering that API directly would be somewhat impolite. But... Codex CLI is an open source project released under an Apache 2.0 license. How about upgrading that to let me run my own prompts through its existing API mechanisms instead?&lt;/p&gt;
    &lt;p&gt;This felt like a somewhat absurd loophole, and I couldn’t resist trying it out and seeing what happened.&lt;/p&gt;
    &lt;head rend="h4"&gt;Codex CLI is written in Rust&lt;/head&gt;
    &lt;p&gt;The openai/codex repository contains the source code for the Codex CLI tool, which OpenAI rewrote in Rust just a few months ago.&lt;/p&gt;
    &lt;p&gt;I don’t know much Rust at all.&lt;/p&gt;
    &lt;p&gt;I made my own clone on GitHub and checked it out locally:&lt;/p&gt;
    &lt;code&gt;git clone git@github.com:simonw/codex
cd codex&lt;/code&gt;
    &lt;p&gt;Then I fired up Codex itself (in dangerous mode, because I like living dangerously):&lt;/p&gt;
    &lt;code&gt;codex --dangerously-bypass-approvals-and-sandbox&lt;/code&gt;
    &lt;p&gt;And ran this prompt:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Figure out how to build the rust version of this tool and then build it&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This worked. It churned away for a bit and figured out how to build itself. This is a useful starting point for a project like this—in figuring out the compile step the coding agent gets seeded with a little bit of relevant information about the project, and if it can compile that means it can later partially test the code it is writing while it works.&lt;/p&gt;
    &lt;p&gt;Once the compile had succeeded I fed it the design for the new feature I wanted:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Add a new sub-command to the Rust tool called “codex prompt”&lt;/p&gt;
      &lt;p&gt;codex prompt “prompt goes here”—this runs the given prompt directly against the OpenAI API that Codex uses, with the same code path and authentication credentials as the rest of Codex.&lt;/p&gt;
      &lt;p&gt;codex prompt -m &amp;lt;model_name&amp;gt; “prompt goes here”—same again but lets you set the model&lt;/p&gt;
      &lt;p&gt;codex prompt “prompt goes here” -s/--system “system prompt goes here”—runs with a custom system/developer message&lt;/p&gt;
      &lt;p&gt;codex prompt --models—this lists all available models that can be used with the “codex prompt” command&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;My design for this new sub-command is lifted directly from my own llm command.&lt;/p&gt;
    &lt;head rend="h4"&gt;Iterating on the code&lt;/head&gt;
    &lt;p&gt;Codex got to work. I’ve shared the full transcript here (using the tool I described here), but this TODO list it made itself is a useful summary of what it decided to do:&lt;/p&gt;
    &lt;code&gt;Updated Plan
└ ✔ Inspect CLI structure and relevant core utilities for sending prompts and listing models
  ✔ Implement new `codex prompt` subcommand (CLI plumbing + command handler)
  ✔ Format, lint, and test (`just fmt`, `just fix -p codex-cli`, `cargo test -p codex-cli`)
&lt;/code&gt;
    &lt;p&gt;I like that it figured out the justfile in the repo and decided to use it to run formatting and linting commands without me needing to tell it to. (Update: it turns out that was dictated by the AGENTS.md file.)&lt;/p&gt;
    &lt;p&gt;I tried running the first version of the code it wrote like this:&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt 'Generate an SVG of a pelican riding a bicycle' -m gpt-5-codex-mini&lt;/code&gt;
    &lt;p&gt;... and it didn’t quite work. I got this:&lt;/p&gt;
    &lt;code&gt;(reasoning summary) **Seeking
(reasoning summary)  instructions
(reasoning summary)  and
(reasoning summary)  sandbox
(reasoning summary)  info
(reasoning summary) **
(reasoning summary) **Dec
(reasoning summary) iding
(reasoning summary)  on
(reasoning summary)  SVG
(reasoning summary)  creation
(reasoning summary)  approach
(reasoning summary) **
(reasoning summary) **Checking
(reasoning summary)  current
(reasoning summary)  directory
(reasoning summary) **
(reasoning summary) **Preparing
(reasoning summary)  to
(reasoning summary)  check
(reasoning summary)  current
(reasoning summary)  directory
(reasoning summary) **
I�m ready to help�what would you like me to do next?I�m ready to help�what would you like me to do next?
Token usage: total=2459 input=2374 cached_input=0 output=85 reasoning_output=64
&lt;/code&gt;
    &lt;p&gt;Note that it DID think about SVG creation, but then decided it should look at the current directory. This isn’t what I want—it appeared to be running in Codex’s normal mode with a system prompt telling it to edit files on disk. I wanted it to respond to the prompt without acting as if it had a full workspace available to it.&lt;/p&gt;
    &lt;p&gt;I prompted it again, pasting in the broken output:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;this did not seem to work—here is what happened—note that the reasoning summary comes out on a lot of lines when I would rather it streams out to stderr on the same line (flushing constantly)—and then despite the reasoning summary thinking about pelican on SVG it did not actually act on that and display the result, which is very surprising. [pasted content]&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It churned for a bit more, but from the output it looked like it was still trying to include Codex-specific tools and workspace information. So I said:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Note that this new ’codex prompt’ command should NOT be able to execute any tools at all, and should not have to think about the workspace or sandbox—it should send a single prompt with no tools and then stream and display a response and then stop.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This got me a new build, but when I ran it:&lt;/p&gt;
    &lt;code&gt;Error: unexpected status 400 Bad Request: {"detail":"Instructions are not valid"}
&lt;/code&gt;
    &lt;p&gt;My guess is that OpenAI’s custom backend API for Codex doesn’t like it if you attempt to call it without passing in the expected instructions. Fair enough!&lt;/p&gt;
    &lt;p&gt;Rather than paste that error in I got Codex to try the command itself, so it could see the error:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;You try running this and see what happens: ./target/debug/codex prompt ’Generate an SVG of a pelican riding a bicycle’&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Codex switched back to the default instructions. From its reply:&lt;/p&gt;
    &lt;quote&gt;&lt;code&gt;cli/src/prompt_cmd.rs#L1-L320&lt;/code&gt;now forces a tool-free request: we keep the workspace defaults, inject a lightweight system/developer message (“don’t run tools”), disable apply_patch/web search via config overrides, and build the outbound prompt as just that system span plus the user text.&lt;/quote&gt;
    &lt;p&gt;I guess that will have to do. I asked for one more feature:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Add a --debug option to the codex prompt command which causes the full JSON request and response to be printed to stderr, plus the URL that is being accessed and the HTTP verb&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;... and we’re ready to try this thing out!&lt;/p&gt;
    &lt;p&gt;Notably I haven’t written a single line of Rust myself here and paid almost no attention to what it was actually doing. My main contribution was to run the binary every now and then to see if it was doing what I needed yet.&lt;/p&gt;
    &lt;p&gt;I’ve pushed the working code to a prompt-subcommand branch in my repo if you want to take a look and see how it all works.&lt;/p&gt;
    &lt;head rend="h4"&gt;Let’s draw some pelicans&lt;/head&gt;
    &lt;p&gt;With the final version of the code built, I drew some pelicans. Here’s the full terminal transcript, but here are some highlights.&lt;/p&gt;
    &lt;p&gt;This is with the default GPT-5-Codex model:&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt "Generate an SVG of a pelican riding a bicycle"&lt;/code&gt;
    &lt;p&gt;I pasted it into my tools.simonwillison.net/svg-render tool and got the following:&lt;/p&gt;
    &lt;p&gt;I ran it again for GPT-5:&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt "Generate an SVG of a pelican riding a bicycle" -m gpt-5&lt;/code&gt;
    &lt;p&gt;And now the moment of truth... GPT-5 Codex Mini!&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt "Generate an SVG of a pelican riding a bicycle" -m gpt-5-codex-mini&lt;/code&gt;
    &lt;p&gt;I don’t think I’ll be adding that one to my SVG drawing toolkit any time soon.&lt;/p&gt;
    &lt;head rend="h4"&gt;Bonus: the --debug option&lt;/head&gt;
    &lt;p&gt;I had Codex add a &lt;code&gt;--debug&lt;/code&gt; option to help me see exactly what was going on.&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt -m gpt-5-codex-mini "Generate an SVG of a pelican riding a bicycle" --debug&lt;/code&gt;
    &lt;p&gt;The output starts like this:&lt;/p&gt;
    &lt;code&gt;[codex prompt debug] POST https://chatgpt.com/backend-api/codex/responses
[codex prompt debug] Request JSON:
&lt;/code&gt;
    &lt;code&gt;{
  "model": "gpt-5-codex-mini",
  "instructions": "You are Codex, based on GPT-5. You are running as a coding agent ...",
  "input": [
    {
      "type": "message",
      "role": "developer",
      "content": [
        {
          "type": "input_text",
          "text": "You are a helpful assistant. Respond directly to the user request without running tools or shell commands."
        }
      ]
    },
    {
      "type": "message",
      "role": "user",
      "content": [
        {
          "type": "input_text",
          "text": "Generate an SVG of a pelican riding a bicycle"
        }
      ]
    }
  ],
  "tools": [],
  "tool_choice": "auto",
  "parallel_tool_calls": false,
  "reasoning": {
    "summary": "auto"
  },
  "store": false,
  "stream": true,
  "include": [
    "reasoning.encrypted_content"
  ],
  "prompt_cache_key": "019a66bf-3e2c-7412-b05e-db9b90bbad6e"
}&lt;/code&gt;
    &lt;p&gt;This reveals that OpenAI’s private API endpoint for Codex CLI is &lt;code&gt;https://chatgpt.com/backend-api/codex/responses&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Also interesting is how the &lt;code&gt;"instructions"&lt;/code&gt; key (truncated above, full copy here) contains the default instructions, without which the API appears not to work—but it also shows that you can send a message with &lt;code&gt;role="developer"&lt;/code&gt; in advance of your user prompt.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45862802</guid><pubDate>Sun, 09 Nov 2025 04:02:47 +0000</pubDate></item><item><title>I Am Mark Zuckerberg</title><link>https://iammarkzuckerberg.com/</link><description>&lt;doc fingerprint="b609d0711019dfdc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Welcome to iammarkzuckerg.com&lt;/head&gt;
    &lt;p&gt;No, not THAT Mark Zuckerberg-this one's busy helping Hoosiers, not launching social networks.&lt;/p&gt;
    &lt;p&gt;Relax, you haven't accidentally logged into Facebook or the Metaverse. You're on the site of Mark S. Zuckerberg, Indiana's original bearer of the name, proud bankruptcy attorney, and frequent recipient of confused emails from people seeking tech support or handouts of money.&lt;/p&gt;
    &lt;p&gt;What I Really Do:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Help people obtain a fresh financial start (no passwords required)&lt;/item&gt;
      &lt;item&gt;Offer dependable, human-involved advice (my artificial intelligence is powered by coffee)&lt;/item&gt;
      &lt;item&gt;Answer local legal questions, not privacy scandals&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Real Zuckerberg Facts:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Shares a name, not fortune, with the Facebook founder&lt;/item&gt;
      &lt;item&gt; Gets mistaken daily for a tech billionaire &lt;/item&gt;
      &lt;item&gt; Has written zero social media apps, but plenty of court briefs&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt; Fun Fact:&lt;lb/&gt; In Indiana, saying "I'm Mark Zuckerberg" gets more laughs than likes. But if you need trustworthy bankruptcy help, you're in exactly the right place! Click around, get to know your (non-billionaire) local Mark, and remember: No login required. &lt;/p&gt;
    &lt;head rend="h3"&gt; Click Here to See How Other &lt;lb/&gt;Websites Have Reacted to This &lt;/head&gt;
    &lt;head rend="h3"&gt;Interesting Things That Have Happened to Me Because My Name is Mark Zuckerberg&lt;/head&gt;
    &lt;p&gt;For a complete list of things that have happened to Mark Zuckerberg click here&lt;/p&gt;
    &lt;p&gt;Like I said, I don't wish Mark E. Zuckerberg any ill will at all. I hope the best for him, but let me tell you this: I will rule the search for "Mark Zuckerberg bankruptcy". And if he does fall upon difficult financial times, and happens to be in Indiana, I will gladly handle his case in honor of our eponymy.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45863360</guid><pubDate>Sun, 09 Nov 2025 06:13:05 +0000</pubDate></item><item><title>Ask HN: How would you set up a child’s first Linux computer?</title><link>https://news.ycombinator.com/item?id=45864732</link><description>&lt;doc fingerprint="d1e111d1f886a428"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;As a tech parent I think one of the best things I did for both my son and daughter was for their first computer to help them to build and setup their own Linux computer (It was Ubuntu back then but they’ve both moved themselves to Arch these days).&lt;/p&gt;
      &lt;p&gt;We went together and bought a second hand desktop (exciting the people selling to us also) and when I got home I pulled out the Ram, HD and CD drive and set them aside; and then together with a screwdriver we “built the computer” over a few days.&lt;/p&gt;
      &lt;p&gt;In windows when a child goes searching the web for a “movie maker for windows” they are going to be in a world of hurt either finding expensive commercial options or super scammy sites promising the world.&lt;/p&gt;
      &lt;p&gt;By comparison on Linux if they search the local “app store” they’ll find stacks and stacks of free, useful, open licensed software.&lt;/p&gt;
      &lt;p&gt;My kids loved the power, freedom and later unexpected community this bought them.&lt;/p&gt;
      &lt;p&gt;Now my friend wants the same for their daughter who is 8 years old.&lt;/p&gt;
      &lt;p&gt;I’m planning to do the same and go with her parents and her and buy a second hand desktop together and then put Linux on it.&lt;/p&gt;
      &lt;p&gt;My question is where would you go from there? What suggestions do you have? What to install? Any mini “curriculums” or ideas?&lt;/p&gt;
      &lt;p&gt;Would love to hear your ideas and experiences. Linux with free and open software is the goal and focus.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45864732</guid><pubDate>Sun, 09 Nov 2025 11:12:02 +0000</pubDate></item><item><title>Visualize FastAPI endpoints with FastAPI-Voyager</title><link>https://www.newsyeah.fun/voyager/</link><description>&lt;doc fingerprint="2d7d4c5aa849e7b4"&gt;
  &lt;main&gt;
    &lt;p&gt;Loading… FastAPI Voyager {{ state.version }} scroll to zoom in/out double click node to view details. shift + click to see schema's dependencies without unrelated nodes. {{ tag.name }} {{ tag.routes.length }} {{ route.name }} No routes {{ dumpJson }} Import core data JSON&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45865049</guid><pubDate>Sun, 09 Nov 2025 12:24:50 +0000</pubDate></item><item><title>Alive internet theory</title><link>https://alivetheory.net/</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=45865098</guid><pubDate>Sun, 09 Nov 2025 12:33:38 +0000</pubDate></item><item><title>Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology</title><link>https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/</link><description>&lt;doc fingerprint="25357b3c1a218080"&gt;
  &lt;main&gt;
    &lt;p&gt;&lt;lb/&gt;How I spent two decades tracking down the creators of a 1987 USENET game and learned modern packaging tools in the process.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Discovery: A Digital Time Capsule from 1987&lt;/head&gt;
    &lt;p&gt;Picture this: October 26, 1987. The Berlin Wall still stands, the World Wide Web is just text, and software is distributed through USENET newsgroups in text files split across multiple posts. On that day, Edward Barlow posted something special to &lt;code&gt;comp.sources.games&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;“conquest – middle earth multi-player game, Part01/05”&lt;/p&gt;
    &lt;p&gt;That’s how Ed Barlow announced it at the time, before quickly changed the name to Conquer.&lt;/p&gt;
    &lt;p&gt;This was Conquer – a sophisticated multi-player strategy game that would influence countless others. Players controlled nations in Middle Earth, managing resources, armies, magic systems, and diplomatic relations. What made it remarkable wasn’t just the gameplay, but how it was built and distributed in an era when “open source” wasn’t even a term yet.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 0: University Days.&lt;/head&gt;
    &lt;p&gt;It was during these days, in the middle of the 90s, that my fellow students and I spent hours experimenting with terminals in the Computer Unix Labs, USENET, links, news, msgs, and of course: conquer. That game was a gem that required to be the leader of a country, and with a map representing as characters each player could control their elven kingdom, orcish empire, or human armies to fight each other while controlling all the details of the economy.&lt;/p&gt;
    &lt;p&gt;But by 2006, this piece of computing history was trapped in legal limbo.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 1: The Quest Begins (2006)&lt;/head&gt;
    &lt;p&gt;As a university student in Spain in the early ’90s, I’d encountered Conquer in the Unix labs. Fast forward to 2006, and I realized this pioneering game was at risk of being lost forever. The source code existed, scattered across ancient USENET archives, but its licensing was unclear – typical of the “post it and see what happens” era of early internet software distribution.&lt;/p&gt;
    &lt;p&gt;I started what I thought would be a simple project: get permission from the original authors to relicense the code under GPL so it could be properly preserved and packaged for modern Linux distributions.&lt;/p&gt;
    &lt;p&gt;Simple, right?&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 2: Digital Detective Work&lt;/head&gt;
    &lt;p&gt;Finding Edward Barlow and Adam Bryant in 2006 was like archaeological work. Email addresses from the 1980s were long dead. USENET posts provided few clues. I scoured old university directories, googled fragments of names, and followed digital breadcrumbs across decades-old forums.&lt;/p&gt;
    &lt;p&gt;The breakthrough came through pure persistence and a bit of luck. After months of searching, I managed to contact Ed Barlow. His response was refreshingly casual: “Yes i delegated it all to adam aeons ago. Im easy on it all…. copyleft didnt exist when i wrote it and it was all for fun so…”&lt;/p&gt;
    &lt;p&gt;But there was a catch – I needed permission from Adam Bryant too, and he seemed to have vanished into the digital ether.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 3: The Long Wait (2006-2011)&lt;/head&gt;
    &lt;p&gt;I documented everything on the Debian Legal mailing lists, created a GNU Savannah task (#5945), and even wrote blog posts hoping Adam would find them. The legal experts were clear: I needed explicit written permission from both copyright holders.&lt;/p&gt;
    &lt;p&gt;Years passed. The project stalled.&lt;/p&gt;
    &lt;p&gt;Then, on February 23, 2011, something magical happened. My phone buzzed with a contact form submission:&lt;/p&gt;
    &lt;p&gt;“I heard news of the request to release the code. I grant permission to release the code under GPL.” – Adam Bryant&lt;/p&gt;
    &lt;p&gt;He had found one of my articles online and reached out on his own.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 4: The Plot Twist – Version 5 Emerges (2025)&lt;/head&gt;
    &lt;p&gt;Fast forward to 2025, and Stephen Smoogen contacts me about my relicesing efforts in 2006 and how he was particularly interested in reviving: Conquer Version 5 – a complete rewrite by Adam with advanced features like automatic data conversion, enhanced stability, and sophisticated administrative tools. This wasn’t just an update; it was a complete reimagining of the game.&lt;/p&gt;
    &lt;p&gt;But V5 had a different legal history. In the ’90s, there had been commercial arrangements. Would Adam agree to GPL this version too?&lt;/p&gt;
    &lt;p&gt;His response: “I have no issues with applying a new GPL license to Version 5 as well.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 5: The Missing Piece – PostScript Magic&lt;/head&gt;
    &lt;p&gt;Just when I thought the story was complete, I discovered another contributor: MaF, who had created PostScript utilities for generating printable game maps – a crucial feature in the pre-GUI era when players needed physical printouts to strategize.&lt;/p&gt;
    &lt;p&gt;Tracking down MaF in 2025 led me to his company, where he’s now Director of Product Security. His response: “Oh, that was a long time ago. But yes, that was me. And I have no problem with relicensing it to GPL.”&lt;lb/&gt;Richard Caley: More Than Just a Legal Footnote&lt;/p&gt;
    &lt;p&gt;But not all searches end with an answer. Some end with silence.&lt;/p&gt;
    &lt;p&gt;My investigation of Richard Caley followed the same digital breadcrumbs. I traced him to the University of Edinburgh, where he worked on speech synthesis. I found his technical contributions to FreeBSD. But the trail went cold around 2005.&lt;/p&gt;
    &lt;p&gt;Then I found him – not in a USENET archive, but on the front page of his own website, preserved exactly as he left it in web.archive.org.&lt;/p&gt;
    &lt;p&gt;“Richard Caley suffered a fatal heart attack on the 22nd of April, 2005. He was only 41, but had been an undiagnosed diabetic, probably for some considerable time. His web pages remain as he left them.”&lt;/p&gt;
    &lt;p&gt;Reading those words felt different from finding a historical record. This wasn’t archival research – this was walking into someone’s house years after they’d gone and finding a note on the table.&lt;/p&gt;
    &lt;p&gt;The page continued:&lt;/p&gt;
    &lt;p&gt;“Over and above his tremendous ability with computers and programming, Richard had a keen mind and knowledge of an extraordinary range of topics, both of which he used in frequent contributions to on-line discussions. Despite his unique approach to speling, his prolific contributions to various news group debates informed and amused many over the years.”&lt;/p&gt;
    &lt;p&gt;The “Caleyisms” – The Man Behind the Code&lt;/p&gt;
    &lt;p&gt;And then I discovered his “Caleyisms” – a curated collection of his most brilliant USENET responses that revealed not just a programmer, but a person:&lt;/p&gt;
    &lt;p&gt;What’s a shell suit?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Oil company executive.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;How do you prepare for a pyroclastic flow hitting Edinburgh?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Hang 1000 battered Mars bars on strings and stand back?”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;On his book addiction:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“I never got the hang of libraries, they keep wanting the things back and get upset when they need a crowbar to force it out of my hands.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;His humor was dry, intelligent, and uniquely British. In technical discussions, he could be brutally precise:&lt;/p&gt;
    &lt;p&gt;“Lack of proper punctuation, spacing, line breaks, capitalisation etc. is like bad handwriting, it doesn’t make it impossible to read what was written, just harder. But you probably write in green crayon anyway.”&lt;/p&gt;
    &lt;p&gt;A Digital Office Preserved&lt;/p&gt;
    &lt;p&gt;Exploring his preserved website felt like walking through his digital office. The directory structure revealed his passions: FreeBSD how-tos, POVRAY experiments, wallpaper images, technical projects. His self-deprecating humor shone through in his “About” section:&lt;/p&gt;
    &lt;p&gt;“Thankfully I don’t have a photograph to inflict on you. Just use the picture of Iman Bowie to the left and then imagine someone who looks exactly the opposite in every possible way. This probably explains why she is married to David Bowie and I’m not.”&lt;/p&gt;
    &lt;p&gt;Here was a complete person – technical director at Interactive Information Ltd, speech synthesis researcher, FreeBSD enthusiast, Kate Bush fan, and a wit who brightened countless online discussions.&lt;/p&gt;
    &lt;p&gt;The legal reality was harsh: Richard’s contributions to Conquer couldn’t be relicensed. The university couldn’t help contact heirs due to privacy laws.&lt;/p&gt;
    &lt;p&gt;His friends had preserved his memory with a simple ASCII tribute at the end of his page:&lt;/p&gt;
    &lt;quote&gt;^_^&lt;lb/&gt;(O O)&lt;lb/&gt;\_/@@\&lt;lb/&gt;\\~~/&lt;lb/&gt;~~&lt;lb/&gt;- RJC RIP&lt;/quote&gt;
    &lt;p&gt;In the Conquer project documentation, Richard Caley isn’t remembered as a “problem case” or “unlicensable code.” He’s honored as the vibrant person he was – the brilliant mind behind the “Caleyisms,” the researcher who contributed to speech synthesis, the FreeBSD advocate, and the witty participant in early online communities whose words continue to amuse and inform, decades after he wrote them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 6: Modern Renaissance – Enter GitHub, CICD and Modern Distributions&lt;/head&gt;
    &lt;p&gt;Here’s where the story gets really interesting. While working on preserving these Unix classics, I decided to learn modern packaging techniques. I chose to implement both APK (Alpine Linux) and Debian packaging for the games.&lt;/p&gt;
    &lt;p&gt;For APK packages, I used Melange – a sophisticated build system that creates provenance-tracked, reproducible packages for the Wolfi “undistro”. The irony? I discovered this tool when some friend started to work for the company that created it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 7: The Technical Journey: From USENET to Modern CI/CD&lt;/head&gt;
    &lt;p&gt;The transformation has been remarkable:&lt;/p&gt;
    &lt;p&gt;1987 Original:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Distributed as split USENET posts&lt;/item&gt;
      &lt;item&gt;Manual compilation with system-specific Makefiles&lt;/item&gt;
      &lt;item&gt;No version control or automated testing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;2025 Revival:&lt;/p&gt;
    &lt;code&gt;# Modern CI/CD with GitHub Actions
- name: Build APK package
  run: melange build conquer.yaml
- name: Build Debian package  
  run: dpkg-buildpackage -b
&lt;/code&gt;
    &lt;p&gt;Key Modern Additions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GPLv3 relicensing&lt;/item&gt;
      &lt;item&gt;Make building system modernization&lt;/item&gt;
      &lt;item&gt;C Codebase partially updated to support modern ANSI C99 specification&lt;/item&gt;
      &lt;item&gt;Debian packaging&lt;/item&gt;
      &lt;item&gt;APK packaging with Melange&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can see the complete transformation in the repositories:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Conquer v4 – The original classic&lt;/item&gt;
      &lt;item&gt;Conquer v5 – The advanced rewrite&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Original Conquer v4 code, by Ed Barlow and Adam Bryant&lt;/p&gt;
    &lt;p&gt;(Conquer running in docker container alongside Apache, Curses to WebSockets output thanks to ttyd. Now we can play through the web!)&lt;/p&gt;
    &lt;p&gt;Conquer Version 5 – The evolution of the classical Conquer, by Adam Bryant&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 8: The Human Element: Why This Matters&lt;/head&gt;
    &lt;p&gt;This isn’t just about preserving old games – it’s about preserving the story of computing itself. Ed Barlow and Adam Bryant were pioneers who built sophisticated multiplayer experiences when most people had never heard of the internet. They distributed software through USENET because that’s what you did – you shared cool things with the community.&lt;/p&gt;
    &lt;p&gt;Martin Forssen’s PostScript utilities represent the ingenuity of early developers who solved problems with whatever tools were available. Want to visualize your game state? Write a PostScript generator!&lt;/p&gt;
    &lt;p&gt;The 20-year relicensing effort demonstrates something crucial about open source: it’s not just about code, it’s about community and continuity. Every time someone maintains a legacy project, documents its history, or tracks down long-lost contributors, they’re weaving the threads that connect computing’s past to its future.&lt;/p&gt;
    &lt;head rend="h2"&gt;Lessons for Modern Developers&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Document everything: Those casual USENET posts became crucial legal evidence decades later&lt;/item&gt;
      &lt;item&gt;License clearly: Ed’s comment that “copyleft didnt exist when i wrote it” highlights how licensing landscapes evolve&lt;/item&gt;
      &lt;item&gt;Community matters: Adam found my articles because the community was talking about preservation&lt;/item&gt;
      &lt;item&gt;Technical debt is temporal: What seems like legacy tech today might be tomorrow’s archaeological treasure&lt;/item&gt;
      &lt;item&gt;Modern tools can revive ancient code: Melange and modern CI/CD gave 1987 software a 2025 renaissance&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The Continuing Story&lt;/head&gt;
    &lt;p&gt;Both Conquer games are now fully GPL v3 licensed and available with modern packaging. They represent not just playable software, but a complete case study in software archaeology, legal frameworks for preservation, and the evolution of development practices across four decades.&lt;/p&gt;
    &lt;p&gt;The next chapter? Teaching these classic strategy games to a new generation of developers and gamers, while demonstrating that proper legal frameworks and modern tooling can give any historical software a second life.&lt;/p&gt;
    &lt;p&gt;Sometimes the best way to learn cutting-edge technology is by applying it to preserve computing history.&lt;/p&gt;
    &lt;p&gt;What historical software deserves preservation in your field? Have you ever traced the lineage of code back to its original creators?&lt;/p&gt;
    &lt;p&gt;#FreeSoftware #OpenSource #SoftwarePreservation #Unix #GNU #Linux #Packaging #Melange #TechHistory #GameDevelopment #Unix #USENET #GPL #FST #Debian #ncurses #terminal #shell&lt;/p&gt;
    &lt;p&gt;Read this article in Spanish / Lee este artículo en español: &lt;lb/&gt;https://vejeta.com/conquer-una-odisea-de-20-anos-en-arqueologia-digital/&lt;/p&gt;
    &lt;p&gt;This article was originally written in both English and Spanish, with additional insights and cultural context in the Spanish version.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45865159</guid><pubDate>Sun, 09 Nov 2025 12:44:35 +0000</pubDate></item><item><title>Zensical – A modern static site generator built by the Material for MkDocs team</title><link>https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/</link><description>&lt;doc fingerprint="9beaf6129f9c8fc4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Zensical – A modern static site generator built by the Material for MkDocs team¶&lt;/head&gt;
    &lt;p&gt;We are thrilled to announce Zensical, our next-gen static site generator designed to simplify the process of building documentation sites. Distilled from a decade of experience, Zensical is our effort to overcome the technical limitations of MkDocs, reaching far beyond its capabilities.&lt;/p&gt;
    &lt;p&gt;Zensical is the result of thousands of hours of work – built from the ground up for a modern and comfortable authoring experience, while making it easy for developers to extend and customize Zensical through its upcoming module system. Our goal is to support docs-as-code workflows with tens of thousands of pages, without compromising performance or usability.&lt;/p&gt;
    &lt;p&gt;To make the transition seamless, compatibility comes first. We're putting significant effort into ensuring a smooth migration from Material for MkDocs for all users. Zensical can natively read &lt;code&gt;mkdocs.yml&lt;/code&gt;, allowing you to build your existing project with minimal changes. As of now, a subset of plugins is supported, and we're working on feature parity in the coming months.&lt;/p&gt;
    &lt;p&gt;Zensical is fully Open Source, licensed under MIT, and can be used for any purpose, including for commercial use. We're also saying goodbye to our sponsorware model, replacing it with our new offering for professional users: Zensical Spark. This allows us to stay independent, maximizing user value, as we shape the future of Zensical together with you.&lt;/p&gt;
    &lt;p&gt;You can subscribe to our newsletter to stay in the loop.&lt;/p&gt;
    &lt;p&gt;This is the second article in a four-part series:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Transforming Material for MkDocs&lt;/item&gt;
      &lt;item&gt;Zensical – A modern static site generator built by the creators of Material for MkDocs.&lt;/item&gt;
      &lt;item&gt;What happens to the features in Insiders coming November 11, 2025&lt;/item&gt;
      &lt;item&gt;A path forward for our community coming November 18, 2025&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Why Zensical?¶&lt;/head&gt;
    &lt;p&gt;Since its initial release in 2016, Material for MkDocs has helped tens of thousands of teams to publish and maintain reliable documentation. However, in recent years, it has become apparent that we were running up against limitations of our core dependency, MkDocs. These limitations proved impossible to overcome as they are deeply rooted in its architecture.&lt;/p&gt;
    &lt;p&gt;We also mentioned in our update on our foundational work that MkDocs must be considered a supply chain risk, since it's unmaintained since August 2024. It has seen no releases in over a year and is accumulating unresolved issues and pull requests. These developments have forced us to cut our ties to MkDocs as a dependency.&lt;/p&gt;
    &lt;p&gt;In order to map out a path forward, we went back to the drawing board, talked to dozens of our professional users and thoroughly analyzed the MkDocs ecosystem. We didn't just want to create a fork or port of MkDocs, but decided to rethink static site generation from first principles.&lt;/p&gt;
    &lt;p&gt;With Zensical, we are creating a modern static site generator, which is compatible with your content and customizations, and addresses MkDocs' limitations. While Material for MkDocs is built on top of MkDocs, Zensical consolidates both projects into one coherent stack, covering static site generation, theming, and customization. What you can expect today:&lt;/p&gt;
    &lt;p&gt;Although we haven't reached full feature parity yet, you can already use Zensical to build your existing Material for MkDocs projects with minimal changes.&lt;/p&gt;
    &lt;p&gt;You can jump to the compatibility section to learn what is already supported.&lt;/p&gt;
    &lt;head rend="h2"&gt;What you can expect¶&lt;/head&gt;
    &lt;head rend="h3"&gt;Solid foundation¶&lt;/head&gt;
    &lt;p&gt;Our goal with Zensical is to create a coherent and modern stack, vertically integrating all parts of the authoring experience (AX), developer experience (DX), and user experience (UX). This gives us a significant competitive advantage over solutions that overly rely on third-party frameworks and dependencies, helping us to create much more robust Open Source software.&lt;/p&gt;
    &lt;p&gt;ZRX, our new differential build engine, creates a solid foundation for Zensical, and is an Open Source project of its own. It's a fresh take on making differential data flows easy to build and a joy to work with. Most engineering effort has gone into ZRX, as it forms the backbone of Zensical, and will allow us to ship features faster.&lt;/p&gt;
    &lt;p&gt;Following the principle of architectural hoisting, we moved essential, reusable functionality into ZRX, which allows us to keep Zensical's core simple and focused on static site generation. ZRX handles the heavy lifting – differential builds, caching, and data flow orchestration.&lt;/p&gt;
    &lt;p&gt;With the upcoming module system and component system, both of which are on our public roadmap, Zensical will gain more degrees of freedom in the coming months, allowing you to extend and customize Zensical in ways that were previously impossible with MkDocs.&lt;/p&gt;
    &lt;head rend="h3"&gt;Modern design¶&lt;/head&gt;
    &lt;p&gt;Zensical brings a fresh, modern design that breaks out of the Materal Design aesthetic, creating a visual foundation that is more easily brandable and adaptable to different use cases. The new design prioritizes clarity, simplicity, and usability, while having a more professional finish:&lt;/p&gt;
    &lt;p&gt;Right now, the layout and site structure of Zensical match Material for MkDocs closely, as we're focusing on ensuring maximum compatibility. Once we finish work on our upcoming component system, we'll provide an alternative that is much more flexible and adaptable, and can be tailored to different use cases and branding requirements more easily.&lt;/p&gt;
    &lt;p&gt;You can also keep the Material for MkDocs look and feel with a single line of configuration.&lt;/p&gt;
    &lt;head rend="h3"&gt;Blazing-fast search¶&lt;/head&gt;
    &lt;p&gt;Client-side search isn't a compromise – for the vast majority of static sites, it's the best solution, since it's faster, involves zero maintenance, and doesn't require you to pay for a service.&lt;/p&gt;
    &lt;p&gt;As covered in depth in the first part of this series, the current search implementation in Material for MkDocs has severe limitations, and is based on a now unmaintained library, which is why we decided to build a new search engine from scratch. It's based on the same goals as Zensical itself: performance, flexibility, and extensibility.&lt;/p&gt;
    &lt;p&gt;Disco, our modular and blazing-fast client-side search engine, is exclusively available in Zensical. When you build your site with Zensical, your users will immediately benefit from Disco's improved ranking algorithm, as well as its filtering and aggregation capabilities:&lt;/p&gt;
    &lt;p&gt;In early 2026, we'll be releasing Disco as a standalone Open Source project. With the feedback of our professional users in Zensical Spark, we're going to evolve the search experience, turning Disco into a highly configurable and customizable search engine that adapts to your needs.&lt;/p&gt;
    &lt;p&gt;You can subscribe to our newsletter to receive news about Disco.&lt;/p&gt;
    &lt;head rend="h3"&gt;Authoring experience¶&lt;/head&gt;
    &lt;p&gt;Slow feedback loops can be a major pain point when writing documentation. Almost all of us know the feeling of waiting for the static site generator to finish building the site, just to see a small change reflected in the output. With Zensical, we're finally addressing this issue.&lt;/p&gt;
    &lt;p&gt;It's important to understand that we're not yet utilizing the differential capabilities of ZRX to the fullest extent, as we're forced to make several compromises to ensure maximum compatibility with Material for MkDocs at the moment. Markdown rendering needs to go through Python Markdown, which forces us to pay for extra marshalling costs.&lt;/p&gt;
    &lt;p&gt;While the initial build can sometimes be slower than with MkDocs, repeated builds – especially when serving the site – are already 4 to 5x faster, as only changed files need to be rebuilt.&lt;/p&gt;
    &lt;p&gt;We're also working on a new Markdown toolchain based on a CommonMark-compliant parser written in Rust, which will make Markdown processing significantly faster. We'll be tackling this as part of the upcoming component system, which we'll start working on in early 2026. Once our new Markdown toolchain is ready, we'll provide automated tools to translate between Python Markdown and CommonMark, so you don't need to manually migrate your content.&lt;/p&gt;
    &lt;head rend="h3"&gt;Maximum compatibility¶&lt;/head&gt;
    &lt;p&gt;Compatibility with Material for MkDocs is our top priority. We understand that switching to a new static site generator can be challenging, especially for large projects with many customizations. Therefore, we've put significant effort into ensuring that Zensical understands &lt;code&gt;mkdocs.yml&lt;/code&gt; configuration files, so that you can build your projects with minimal changes.&lt;/p&gt;
    &lt;p&gt;This means your existing Markdown files, template overrides, CSS and JavaScript extensions don't need to be touched, primarily because we did not change the generated HTML, and rely on Python Markdown for processing your content.&lt;/p&gt;
    &lt;p&gt;However, plugins are a different story. In MkDocs, practically all plugins have side effects, making it impossible to parallelize builds. We started from first principles and asked: what should extensibility look like in a modern static site generator? Our answer is the upcoming module system, which takes a fundamentally different approach based on four core principles:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Modules can inject, extend, and re-define functionality&lt;/item&gt;
      &lt;item&gt;Modules are deterministic through topological ordering&lt;/item&gt;
      &lt;item&gt;Modules foster reusability, with the possibility to remix them&lt;/item&gt;
      &lt;item&gt;Modules can cooperate through well-defined contracts&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We're working on shipping essential functionality as provided by MkDocs plugins as built-in modules. In early 2026, we will open the module system to third-party developers, so they can start building their own modules, as we see Zensical as the heart of a thriving ecosystem.&lt;/p&gt;
    &lt;head rend="h2"&gt;Zensical Spark¶&lt;/head&gt;
    &lt;p&gt;Zensical Spark, our offering for professionals, is the result of countless calls with professional users of Material for MkDocs. From startups to large enterprises, we enable organizations to realize complex projects in diverse environments. For this, we've created Zensical Spark as a collaborative space. If you're a professional user, Zensical Spark is for you, since:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;You can be confident that Zensical will continue to be developed and maintained in the long term as a set of interconnected and sustainable OSI-compliant Open Source projects.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;You can receive the support you need to successfully use, configure and customize Zensical in your organization, receiving first-class support from the Zensical team.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;You can influence the future development of Zensical by participating in our new approach to Open Source software development, helping us to build exactly what you need.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Let's talk! If you're working in a professional context, reach out to contact@zensical.org to schedule a call and learn how Zensical Spark enables your team to transition to Zensical smoothly and have a voice in its continued development.&lt;/p&gt;
    &lt;p&gt;You should also consider joining the waiting list, since seats are limited.&lt;/p&gt;
    &lt;head rend="h2"&gt;We're growing our team¶&lt;/head&gt;
    &lt;p&gt;We're also excited to announce that we're growing our team:&lt;/p&gt;
    &lt;p&gt;Timothée Mazzucotelli, also known as @pawamoy, is joining Zensical!&lt;/p&gt;
    &lt;p&gt;At Zensical, Tim is focusing on providing the same seamless experience for generating API reference documentation from source code (via docstrings) as he has done with mkdocstrings, the second biggest project in the MkDocs ecosystem. With his expertise, and Zensical's new stack, we'll be pushing the boundaries of what's possible with API reference documentation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Goodbye, GitHub Sponsors¶&lt;/head&gt;
    &lt;p&gt;Thank you! To all of you who have supported us over the years through GitHub Sponsors – we are incredibly grateful for your support. It has been invaluable in helping us to build, maintain and evolve Material for MkDocs, and we couldn't have done it without you. Seriously, thank you!&lt;/p&gt;
    &lt;p&gt;Material for MkDocs gave us something invaluable: experience building for tens of thousands of users, and the opportunity to build a team around Open Source software. It showed us that making a living from Open Source isn't just possible – we grew it into one of the largest sponsorware projects on GitHub and inspired others to pursue similar paths.&lt;/p&gt;
    &lt;p&gt;Now we're breaking new ground. Zensical is our next chapter, and we're professionalizing how we approach Open Source development. Our vision is to make Zensical free for everyone to use while building a sustainable business around it through our new approach.&lt;/p&gt;
    &lt;p&gt;This transition means saying goodbye to GitHub Sponsors. It has served us exceptionally well, but as we professionalize and scale, we're making the leap from personal project to company – building a business and team that can meet the growing demands of professional users while staying true to our values.&lt;/p&gt;
    &lt;p&gt;We're doubling down on Open Source, developing software for everyone.&lt;/p&gt;
    &lt;p&gt;If you want to continue supporting our work, please subscribe to our newsletter. We'll be providing new methods to support us in the coming months, with the possibility of getting exclusive goodies.&lt;/p&gt;
    &lt;head rend="h2"&gt;Looking Ahead¶&lt;/head&gt;
    &lt;p&gt;Material for MkDocs grew organically in a pot that eventually became too small. With Zensical, we're building on solid foundations designed to grow with us – and with you.&lt;/p&gt;
    &lt;p&gt;Material for MkDocs is now in maintenance mode&lt;/p&gt;
    &lt;p&gt;We want to be transparent about the risks of staying on Material for MkDocs. With MkDocs unmaintained and facing fundamental supply chain concerns, we cannot guarantee Material for MkDocs will continue working reliably in the future. We're aware that transitioning takes time, which is why we commit to support it at least for the next 12 months, fixing critical bugs and security vulnerabilities as needed, but the path forward is with Zensical.&lt;/p&gt;
    &lt;p&gt;If documentation plays a critical role in your organization, and you're worried how this might affect your business, consider joining Zensical Spark, or feel free to schedule a call by reaching out at contact@zensical.org.&lt;/p&gt;
    &lt;head rend="h3"&gt;Where we'll be in 12 months¶&lt;/head&gt;
    &lt;p&gt;Over the next 12 months, following our phased transition strategy, we'll reach Phase 2 and 3 – introducing our module system and component system, as well as CommonMark support. By replacing Python Markdown with a Rust-based Markdown parser, we'll unlock performance improvements and the modularity needed for flexible templating. This is where Zensical truly starts to unfold its capabilities.&lt;/p&gt;
    &lt;p&gt;Zensical is already powering real projects due to extensive compatibility with Material for MkDocs. We're actively working on closing the gap to reach full feature parity.&lt;/p&gt;
    &lt;p&gt;You can install Zensical now, and build your existing Material for MkDocs projects with it. If you run into a bug, please don't hesitate to open an issue – we're here to help.&lt;/p&gt;
    &lt;head rend="h3"&gt;Connect with us¶&lt;/head&gt;
    &lt;p&gt;If you have questions we haven't addressed, please reach out to us at contact@zensical.org. We're currently collecting questions from the community about Zensical, and will address them in an FAQ section as part of our documentation in the coming weeks.&lt;/p&gt;
    &lt;p&gt;We're incredibly thankful that you have been part of our journey so far. With Zensical, we're embarking on a new chapter, and we couldn't be more excited to have you with us.&lt;/p&gt;
    &lt;p&gt;You can subscribe to our newsletter to stay in the loop.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45865189</guid><pubDate>Sun, 09 Nov 2025 12:50:07 +0000</pubDate></item><item><title>Montana Becomes First State to Enshrine 'Right to Compute' into Law</title><link>https://montananewsroom.com/montana-becomes-first-state-to-enshrine-right-to-compute-into-law/</link><description>&lt;doc fingerprint="a971129b188e4438"&gt;
  &lt;main&gt;
    &lt;p&gt;Montana has made history as the first state in the U.S. to legally protect its citizens’ right to access and use computational tools and artificial intelligence technologies. Governor Greg Gianforte signed Senate Bill 212, officially known as the Montana Right to Compute Act (MRTCA), into law.&lt;/p&gt;
    &lt;p&gt;The groundbreaking legislation affirms Montanans’ fundamental right to own and operate computational resources — including hardware, software, and AI tools — under the state’s constitutional protections for property and free expression. Supporters of the bill say it represents a major step in securing digital freedoms in an increasingly AI-driven world.&lt;/p&gt;
    &lt;p&gt;“Montana is once again leading the way in defending individual liberty,” said Senator Daniel Zolnikov, the bill’s sponsor and a longtime advocate for digital privacy. “With the Right to Compute Act, we are ensuring that every Montanan can access and control the tools of the future.”&lt;/p&gt;
    &lt;p&gt;While the law allows state regulation of computation in the interest of public health and safety, it sets a high bar: any restrictions must be demonstrably necessary and narrowly tailored to serve a compelling interest. Legal experts note that this is one of the most protective standards available under Montana law.&lt;/p&gt;
    &lt;p&gt;The act also includes provisions for AI-controlled critical infrastructure, requiring both a “shutdown mechanism” to allow human control and annual safety reviews — a move aimed at balancing innovation with public safety concerns.&lt;/p&gt;
    &lt;p&gt;The bill has drawn praise from privacy advocates and tech policy groups. Tanner Avery, Policy Director at the free-market think tank Frontier Institute, called the law a “flag in the ground” for digital rights, adding: “Montana has made clear it will treat any attempt to infringe on fundamental digital freedoms with the utmost scrutiny.”&lt;/p&gt;
    &lt;p&gt;The MRTCA stands in stark contrast to recent regulatory efforts in other states, such as California, Virginia, and New York, where proposals to rein in AI technologies have either failed or been heavily revised. Montana’s approach leans toward empowering individual users rather than restricting access.&lt;/p&gt;
    &lt;p&gt;The law has already inspired similar efforts in New Hampshire, where lawmakers are pushing a constitutional amendment guaranteeing access to computation. Rep. Keith Ammon, the state’s Majority Floor Leader, praised Montana’s leadership: “This is the kind of bold move that sets the tone for the rest of the country.”&lt;/p&gt;
    &lt;p&gt;Nationally, the Right to Compute movement is gaining traction. Spearheaded by the grassroots group RightToCompute.ai, the campaign argues that computation — like speech and property — is a fundamental human right. “A computer is an extension of the human capacity to think,” the organization states.&lt;/p&gt;
    &lt;p&gt;The movement is supported by Haltia.AI, a Dubai-based AI startup, and the ASIMOV Protocol, a blockchain consortium advocating for decentralized AI infrastructure. Talal Thabet, Co-Founder of both groups, praised Montana’s law as “a monumental step forward in ensuring individuals retain control of their own data and digital tools.”&lt;/p&gt;
    &lt;p&gt;As debates over AI governance and digital rights continue to evolve, Montana’s bold new law could serve as a blueprint for other states seeking to safeguard freedom in the digital era.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45865289</guid><pubDate>Sun, 09 Nov 2025 13:03:36 +0000</pubDate></item><item><title>Using bubblewrap to add sandboxing to NetBSD</title><link>https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing</link><description>&lt;doc fingerprint="53c195e199d53b4"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Google Summer of Code 2025 Reports: Using bubblewrap to add sandboxing to NetBSD&lt;/head&gt;
    &lt;p&gt;This report was written by Vasyl Lanko as part of Google Summer of Code 2025.&lt;/p&gt;
    &lt;head rend="h1"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;As of the time of writing, there is no real sandboxing technique available to NetBSD. There is chroot, which can be considered a weak sandbox because it modifies the root directory of the process, effectively restricting the process' view of the file system, but it doesn't isolate anything else, so all networking, IPC, and mounts inside this restricted file system are the same as of the system, and are accessible.&lt;/p&gt;
    &lt;p&gt;There has already been some research on implementing kernel-level isolation in NetBSD with tools like gaols, mult and netbsd-sandbox, but they haven't been merged to NetBSD. Other operating systems have their own ways to isolate programs, FreeBSD has jails, and Linux has namespaces.&lt;/p&gt;
    &lt;head rend="h1"&gt;Project Goals&lt;/head&gt;
    &lt;p&gt;The goal of this project is to bring a new way of sandboxing to NetBSD. More specifically, we want to implement a mechanism like Linux namespaces. These namespaces allow the isolation of parts of the system from a namespace, or, as the user sees it, from an application.&lt;/p&gt;
    &lt;p&gt;NetBSD has compat_linux to run Linux binaries on NetBSD systems, and the implementation of namespaces can also be utilized to emulate namespace-related functionality of Linux binaries.&lt;/p&gt;
    &lt;p&gt;A simple example to visualize our intended result is to consider an application running under an isolated UTS namespace that modifies the hostname. From the system's view, the hostname remains the same old hostname, but from the application's view it sees the modified hostname.&lt;/p&gt;
    &lt;head rend="h1"&gt;Project Implementation&lt;/head&gt;
    &lt;p&gt;Linux has 8 namespace types, in this project we will focus on only 2 of them:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;UTS namespace, it is the simplest so we can focus on building the general namespace infrastructure with little namespace-specific details&lt;/item&gt;
      &lt;item&gt;mount namespace, it is a prerequisite to most other namespace types because UNIX follows the philosophy of "everything is a file", so we need a separate mount namespace to have different configuration files on the same location as the system.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Linux creates namespaces via the unshare or clone system calls, and it will also be our way of calling the namespace creation logic.&lt;/p&gt;
    &lt;p&gt;We setup the base for implementing Linux namespaces in the NetBSD kernel using kauth, the subsystem managing all authorization requests inside the kernel. It associates credentials with objects, and because the namespace lifecycle management is related to the credential lifecycle it handles all the credential inheritance and reference counting for us. (Thanks kauth devs!)&lt;/p&gt;
    &lt;p&gt;We separate the implementation of each namespace in a different secmodel, resulting in a similar framework to Linux which allows the isolation of a single namespace type. Our implementation also allows users to pick whether they want to have namespace support, and of what kind, via compilation flags, just like in Linux.&lt;/p&gt;
    &lt;head rend="h2"&gt;UTS namespace&lt;/head&gt;
    &lt;p&gt;UTS stands for UNIX Timesharing System, because it allows multiple users to share a single computer system. Isolating the &lt;code&gt;utsname&lt;/code&gt;  can be useful to give users the illusion that they have control over the system's hostname, and also, for example, to give different hostnames to virtual servers.&lt;/p&gt;
    &lt;p&gt;The UTS namespace stores the namespace's hostname, domain name, and their lengths. To isolate the &lt;code&gt;utsname&lt;/code&gt; we need to first create a copy of the current UTS information, plus we need a variable containing the number of credentials referencing this namespace, or, in simpler terms, the reference count of this namespace.&lt;/p&gt;
    &lt;p&gt;This namespace specific information needs to be saved somewhere, and for that we use the credential's &lt;code&gt;private_data&lt;/code&gt; field, so we can use a &lt;code&gt;UTS_key&lt;/code&gt; to save and retrieve &lt;code&gt;UTS&lt;/code&gt; related information from the secmodel. The key specifies the type of information we want to retrieve from the &lt;code&gt;private_data&lt;/code&gt;, hence using a &lt;code&gt;UTS_key&lt;/code&gt; for the UTS namespace. The key for each namespace is a fixed value (we don't create a new key for every credential), but the retrieved value for that key from different credentials may be different.&lt;/p&gt;
    &lt;p&gt;We had to modify kernel code that was directly accessing the &lt;code&gt;hostname&lt;/code&gt; and &lt;code&gt;domainname&lt;/code&gt; variables, to instead call &lt;code&gt;get_uts()&lt;/code&gt;, which retrieves the UTS struct for the namespace of the calling process. We didn't modify occurrences in kernel drivers because drivers are not part of any namespace, so they should still access the system's resources directly.&lt;/p&gt;
    &lt;head rend="h2"&gt;MNT namespace&lt;/head&gt;
    &lt;p&gt;The MNT namespace isolates mounts across namespaces. It is used to have different versions of mounted filesystems across namespaces, meaning a user inside a mount namespace can mount and unmount whatever they want without affecting or even breaking the system.&lt;/p&gt;
    &lt;p&gt;The mount namespace structure in Linux is fairly complicated. To have something similar in NetBSD we need to be able to control the mounts accessed by each namespace, and for that we need to control what is each namespace's mountlist, this is also enough for unmounting file systems, because in practice we can just hide them.&lt;/p&gt;
    &lt;p&gt;For the mount_namespace, mountlist structure and the number of credentials using the mount namespace are stored in the credential's private data with the &lt;code&gt;MNT_key&lt;/code&gt;. Similarly to the UTS namespace, we had to modify kernel code to not directly access the &lt;code&gt;mountlist&lt;/code&gt;, but instead go through a wrapper called &lt;code&gt;get_mountlist()&lt;/code&gt; which returns the correct mountlist for the namespace the calling process resides in.&lt;/p&gt;
    &lt;p&gt;Implementation for the mount namespace is immensely more complex than for the UTS namespace, it involves having a good understanding of both Linux and NetBSD behaviour, and I would frequently find myself wondering how to implement something after reading the Linux man pages, which would lead to me looking for it in the Linux source code, understanding it, then going back to NetBSD source code, trying to implement it, and seeing it's too different to implement in the same way.&lt;/p&gt;
    &lt;head rend="h1"&gt;Project Status&lt;/head&gt;
    &lt;p&gt;You can find all code written during this project in GitHub at maksymlanko/netbsd-src &lt;code&gt;gsoc-bubblewrap&lt;/code&gt; branch. Because I intend to continue this work outside of GSoC, I want to reinforce that this was the last commit still during GSoC on &lt;code&gt;gsoc-bubblewrap&lt;/code&gt; branch and this was the last one for the &lt;code&gt;mnt_ns&lt;/code&gt; still WIP branch.&lt;/p&gt;
    &lt;p&gt;The link includes implementation of general namespace code via secmodels, implementation of the UTS namespace and related ATF-tests, and the work-in-progress implementation of mount namespaces.&lt;/p&gt;
    &lt;p&gt;The mount namespace functionality is not finished as it would require much more work than the time available for this project. To complete it, it would be required invasive and non-trivial changes to the original source code, and, of course, more time.&lt;/p&gt;
    &lt;head rend="h1"&gt;Future Work&lt;/head&gt;
    &lt;p&gt;As previously mentioned, Linux has 8 namespace types, it is important to see which of the missing namespaces are considered useful and feasible to implement.&lt;/p&gt;
    &lt;p&gt;I believe that after mount namespaces it would be interesting to implement PID namespaces as this in combination with mount namespaces would permit process isolation from this sandbox. Afterwards, implementing user namespaces would allow users to get capabilities similar to &lt;code&gt;root&lt;/code&gt; in the namespace, giving them &lt;code&gt;sudo&lt;/code&gt; permissions while still restricting system-wide actions like shutting down the machine.&lt;/p&gt;
    &lt;p&gt;A lower hanging fruit is to implement the namespace management functionality, which in Linux is lsns to list existing namespaces, and setns to move the current process to an already existing namespace.&lt;/p&gt;
    &lt;head rend="h1"&gt;Challenges&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Semantics. Did you know the unmount system call with MNT_FORCE flag in Linux (usually) returns EBUSY, and in NetBSD it forces the unmounting? One of them makes it easier to implement mount namespaces.&lt;/item&gt;
      &lt;item&gt;The behaviour of namespaces is not fully specified in the man pages. If something is not clear from the man pages you need to read the source code.&lt;/item&gt;
      &lt;item&gt;Unexpected need to learn a lot of VFS concepts and their differences in NetBSD and Linux.&lt;/item&gt;
      &lt;item&gt;There was a much bigger research component than I anticipated.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In the end, Linux and NetBSD are different operating systems, implemented in different ways. Linux is complex and it is not trivial to port namespaces to NetBSD.&lt;/p&gt;
    &lt;head rend="h1"&gt;Notes&lt;/head&gt;
    &lt;p&gt;The project is called "Using bubblewrap to add sandboxing to NetBSD" and was initially projected to emulate the &lt;code&gt;unshare&lt;/code&gt; system call into &lt;code&gt;compat_linux&lt;/code&gt;, but, seeing that having namespaces could be useful for NetBSD, and that it would be easy to add to &lt;code&gt;compat_linux&lt;/code&gt; afterwards, we decided to instead implement namespaces directly in the NetBSD kernel. Implementing other system calls necessary to make the &lt;code&gt;bwrap&lt;/code&gt; linux binary work correctly also wouldn't be as satisfying as implementing namespaces directly into NetBSD, so this was why the project was initially called "Using bubblewrap to add sandboxing to NetBSD" but nowadays it would be more accurate to call it "Sandboxing in NetBSD with Linux-like namespaces".&lt;/p&gt;
    &lt;head rend="h1"&gt;Thanks&lt;/head&gt;
    &lt;p&gt;I am very grateful to Google for Google Summer of Code, because without it I wouldn't have learned so much this summer, wouldn't have met with smart and interesting people, and for sure wouldn't have tried to contribute to a project like NetBSD, even if I always wanted to write operating systems code... But, the biggest thing I will take with me from this project is the confidence to be able to contribute to NetBSD and other open source projects.&lt;/p&gt;
    &lt;p&gt;I would also like to thank the members of the NetBSD organization for helping me throughout this project, and more specifically:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Taylor R. Campbell, Harold Gutch and Nia Alarie from IRC, for helping me fix a nasty &lt;code&gt;LD_LIBRARY_PATH&lt;/code&gt;bug I had on my system which wouldn't let me finish compiling NetBSD, and general GSoC recomendations.&lt;/item&gt;
      &lt;item&gt;Emmanuel Dreyfus from &lt;code&gt;tech-kern&lt;/code&gt;, with whom I discussed ideas for projects and proposal suggestions, and in the end inspired the namespaces project.&lt;/item&gt;
      &lt;item&gt;Christoph Badura and Leonardo Taccari who volunteered to be my mentors. They took time to research and answer my questions, anticipated possible problems in my approaches, and always pointed me in the right direction, daily, during all of GSoC's period. This project is from the 3 of us.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45865327</guid><pubDate>Sun, 09 Nov 2025 13:09:22 +0000</pubDate></item><item><title>About KeePassXC's Code Quality Control</title><link>https://keepassxc.org/blog/2025-11-09-about-keepassxcs-code-quality-control/</link><description>&lt;doc fingerprint="2e8dc1360cf353d3"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;About KeePassXC’s Code Quality Control&lt;/head&gt;
    &lt;p&gt;Posted on in Announcements&lt;/p&gt;
    &lt;p&gt;Managing a popular open source project is a lot of work and can be very rewarding. This is especially so for a security-critical application such as KeePassXC that enables people around the world to protect their most sensitive information. As such, we have implemented a robust quality control process that ensures all code merged into production is thoroughly reviewed, tested, and signed off on.&lt;/p&gt;
    &lt;p&gt;Recently, we changed our contribution policy and readme to address code created by Generative AI by adding the following paragraph:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Generative AI is fast becoming a first-party feature in most development environments, including GitHub itself. If the majority of a code submission is made using Generative AI (e.g., agent-based or vibe coding), then we will document that in the pull request. All code submissions go through a rigorous review process regardless of the development workflow or submitter.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This statement has sparked a variety of reactions from innocent questions to serious concerns. We want to address them head-on and explain how we use AI and how we keep the project safe and secure.&lt;/p&gt;
    &lt;p&gt;However, before we can explain our process for AI contributions, we should explain our general code contribution workflow first. The KeePassXC Team has five maintainers with the ability to merge code into the develop branch, including two core maintainers with admin access to the organisation. Code contributions are generally posted to GitHub as a pull request. Code submitted this way runs through our CI pipeline for basic quality assurance and is then tested and reviewed line by line by one of the maintainers. Merging is blocked until at least one maintainer signs off on the changes. If the changes were proposed by a maintainer, another maintainer will do the review. This policy is strictly followed, even for small changes. After the review, the submitted commits are squashed into a single commit to ensure only the tested top state makes it into the main branch, and the CI will run again after the commit is merged.&lt;/p&gt;
    &lt;p&gt;This process is fully transparent and open for anyone to see, and it does not change with AI. We take no shortcuts. At KeePassXC, we use AI for two main purposes:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;As an additional pair of “eyes” in code reviews.&lt;/p&gt;&lt;lb/&gt;In this function, AI summarises the changes (the least helpful part) and points out implementation errors a human reviewer may have missed. AI reviews don’t replace maintainer code review, nor do they relieve maintainers from their due diligence. AI code reviews complement our existing CI pipelines that perform unit tests, memory checks, and static code analysis (CodeQL). As such, they are a net benefit and make KeePassXC strictly safer. Some examples of AI reviews in action: example 1, example 2.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;For creating pull requests that solve simple and focused issues, add boilerplate code and test cases.&lt;/p&gt;&lt;lb/&gt;Unfortunately, some people got the impression that KeePassXC was now being vibe coded. This is wrong. We do not vibe code, and no unreviewed AI code makes it into the code base. Full stop. We have used Copilot agent to draft pull requests, which are then subsequently tweaked in follow-up commits, and reviewed by a maintainer, openly for anyone to see, with the same scrutiny as any other submission. Good pull requests are merged (example), bad pull requests are rejected (example).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All this is only part of the development process. There are no AI features inside KeePassXC and there never will be!&lt;/p&gt;
    &lt;p&gt;The use of Copilot for drafting pull requests is reserved for very simple and focused tasks with a small handful of changes, such as simple bugfixes or UI changes. We use it sparingly (mostly because it’s not very good at complex tasks) and only where we think it offers a benefit. Copilot is good at helping developers plan complex changes by reviewing the code base and writing suggestions in markdown, as well as boilerplate tasks such as test development. Copilot can mess up, and we catch that in our standard review process (e.g., by committing a full directory of rubbish, which we identified and fixed). You can review our copilot instructions. Would we ever let AI rewrite our crypto stack? No. Would we let it refactor and rewrite large parts of the application? No. Would we ask it to fix a regression or add more test cases? Yes, sometimes.&lt;/p&gt;
    &lt;p&gt;Since we are using AI responsibly this way, it made little sense to ban AI submissions by third-party contributors. Such a policy would be near-impossible to enforce anyway. In fact, we’d rather have them transparently disclose the use of AI than hide it and submit the code against our terms. According to our policy, any significant use of AI in a pull request must be disclosed and labelled. As of writing, we have 7 open and 11 closed AI-assisted pull requests. Feel free to check and review them yourself; it’s all open and transparent. If you spot any actual issues with the code that we missed, please tell us.&lt;/p&gt;
    &lt;p&gt;At the moment, this is all an experiment for us, and we will adjust our policies and methods as the need arises. There was a possibility that we’d be swamped with low-quality AI pull requests, but that has so far not manifested.&lt;/p&gt;
    &lt;p&gt;A fear often expressed was that we’d become lazy and lose our skills to review (AI) code properly. Let me tell you: all members of the KeePassXC team have many years of experience in software engineering and project management, we have maintained KeePassXC for almost a decade, and we still code ourselves for work and for fun. This will not suddenly go away because we have another tool in our belts.&lt;/p&gt;
    &lt;p&gt;Certain more esoteric concerns about AI code being somehow inherently inferior to “real code” are not based in reality. Code is deterministic, and the same instruction will always do the same thing regardless of who or what wrote it. There is no invisible ink. An incorrect snippet copied from an online forum is equally wrong and dangerous to one generated by AI or one invented by organic brain cells. What we must ensure is correctness and we do that with code review and tests.&lt;/p&gt;
    &lt;p&gt;And lastly, an interesting complaint we saw was that because AI code was optimised to look appealing to humans, LLMs could supposedly slip innocent-looking but malicious code past our code review. Personally, I would be much more concerned about a skilled human saboteur doing that than a general-purpose code LLM—look no further than famous recent supply-chain attacks. Beyond their technical limitations, commercial LLMs are not designed to purposefully generate nice but incorrect code (certainly not the ones we use), and it is hard to imagine how this would be a good marketing strategy. Malicious and deceptive LLMs are absolutely conceivable, but that would bring us back to the saboteur.&lt;/p&gt;
    &lt;p&gt;To add a little more context to the deceptive LLM argument: LLMs are indeed optimised by alignment methods to develop a desired style. This is not a magic superhuman trait. In fact, were you ever annoyed by the bubbly, wordy, seemingly eloquent, yet deeply obtuse language of LLM text? You’re not alone. LLM language is not magical, it is optimised to cater to the preferences of a broad cross-section of certain (mostly North-American) demographics. But all this is beside the point, because code is not a persuasive essay. There are many ways to write bad code (we have seen a lot of bad code submitted before LLMs), but in the end, it must produce a measurable result that needs to pass a test in order to be accepted.&lt;/p&gt;
    &lt;p&gt;So please, be skeptical of AI. But also be skeptical of human strangers as we are to you. If our AI policy toppled your trust in us, ask yourself why you trusted us (or anyone) in the first place. You don’t know us, you trust our reputation, and we earned that by building a stable product, which we will continue to do. You have our full commitment that we will not integrate any AI features into KeePassXC, and we will not merge any code (human or AI) without tests and thorough review. We have high standards; please continue holding us to them, but let’s have a rational and informed conversation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Feedback&lt;/head&gt;
    &lt;p&gt;Please report any bugs you encounter at our GitHub issue tracker. We are also available on Matrix for real-time feedback and discussions. See our contact page for further options.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45865921</guid><pubDate>Sun, 09 Nov 2025 14:44:06 +0000</pubDate></item><item><title>Samsung Family Hub fridges will start showing adds to "Elevate" Home Ecosystem</title><link>https://news.samsung.com/us/samsung-family-hub-2025-update-elevates-smart-home-ecosystem/</link><description>&lt;doc fingerprint="255dce4306b7f5ed"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Samsung Family Hub™ for 2025 Update Elevates the Smart Home Ecosystem&lt;/head&gt;
    &lt;p&gt;The software update includes a more unified user experience across connected devices, enhancements to AI Vision Inside™, expanded Knox Security and more&lt;/p&gt;
    &lt;p&gt;10/27/2025&lt;/p&gt;
    &lt;p&gt;Samsung’s Family Hub™ for 2025 software enhancements will start rolling out in October for owners of Family Hub™ refrigerators. The update includes a more intuitive user interface, improved AI Vision Inside™ capabilities, Voice ID capabilities with Bixby[1] and upgraded security with Knox Matrix[2].&lt;/p&gt;
    &lt;head rend="h5"&gt;Unified Experience Across Screens&lt;/head&gt;
    &lt;p&gt;The refreshed One UI design that was first seen on Samsung’s 2025 Bespoke AI appliances will be coming to 2024 Family Hub™ models. This advances Samsung’s vision to bring a unified, seamless experience across the screens of its ecosystem of smart TVs, mobile devices and home appliances. In addition to enabling intuitive navigation and region-specific settings, users will get convenient access to features like Family Care, Pet Care and Home Care[3].&lt;/p&gt;
    &lt;p&gt;Family Hub’s™ Cover screen themes are also being updated with new features, including the addition of a Daily Board theme, that offers a new way to see useful information at a glance.&lt;/p&gt;
    &lt;head rend="h5"&gt;Smarter Food Tracking with AI Vision Inside Refrigerators&lt;/head&gt;
    &lt;p&gt;Family Hub™ refrigerators[4] with AI Vision Inside technology will receive upgrades to enable recognition of frequently used packaged foods and even more fresh fruits and vegetables to help families reduce food waste and save money. AI Vision Inside will now recognize 37 fresh food items, including apples, cherries, cucumbers, mangoes, kiwis and more. In addition, AI Vision can now identify and suggest labeling up to 50 packaged food items that are frequently placed in the fridge.[5]&lt;/p&gt;
    &lt;head rend="h5"&gt;Personalized Intelligence for Every User&lt;/head&gt;
    &lt;p&gt;Meanwhile, Bixby gets new Voice ID[6] capabilities, allowing it to recognize who is speaking and switches to their Samsung account. This makes it easy for users to access their calendar[7] and view their photos[8] or find a misplaced phone, even when it’s on silent[9].&lt;/p&gt;
    &lt;p&gt;Voice ID also enhances accessibility by syncing the refrigerator’s display with the visual settings on a user’s Samsung Galaxy phone, such as color inversion or grayscale[10]. And for quicker access, users can now activate Bixby with a simple double tap on the screen.&lt;/p&gt;
    &lt;head rend="h5"&gt;New Widget Pilot for Cover Screen Themes&lt;/head&gt;
    &lt;p&gt;As part of the Family Hub™ software update, we are piloting a new widget for select Cover screens themes of Family Hub™ refrigerators. The widget will display useful day-to-day information such as news, calendar and weather forecasts, along with curated advertisements.[11]&lt;/p&gt;
    &lt;p&gt;Family Hub™ owners will have the option to turn off Cover screen ads in the Advertisements tab of the Settings menu. Ads can also be dismissed on the Cover screen, meaning that specific ads will not appear again during the campaign period. Advertising will not appear when Cover screen displays Art or Album themes.&lt;/p&gt;
    &lt;head rend="h5"&gt;Advanced Security That Works Quietly in the Background&lt;/head&gt;
    &lt;p&gt;Samsung is also expanding the reach of Knox Matrix, its advanced security solution built on private blockchain technology, to more of its smart home lineup. The protection now extends beyond Family Hub™+ refrigerators to include compatible Wi-Fi–enabled[12] Samsung fridges, washers and dryers launched in 2024[13] — creating a safer, more connected home ecosystem.&lt;/p&gt;
    &lt;p&gt;With Knox Trust Chain, these appliances can now monitor each other’s security status, ensuring every connected device stays protected. The Bespoke AI Family Hub™+ will also receive enhanced security features, including encrypted Credential Sync, Passkey support and the new Knox Security Dashboard introduced on 2025 models, giving users an easy, real-time view of their connected devices’ security status.&lt;/p&gt;
    &lt;head rend="h5"&gt;How to Update Your Family Hub™&lt;/head&gt;
    &lt;p&gt;Once the update is available for your fridge, you will receive a notification on the fridge’s screen asking to opt in to the latest software update. Enhancements will become available as soon as you accept the terms and complete the update.&lt;/p&gt;
    &lt;p&gt;To learn more about Samsung’s innovative line of smart Family Hub™ refrigerators, visit Samsung.com.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45866165</guid><pubDate>Sun, 09 Nov 2025 15:18:23 +0000</pubDate></item><item><title>The Manuscripts of Edsger W. Dijkstra</title><link>https://www.cs.utexas.edu/~EWD/</link><description>&lt;doc fingerprint="e615734b00f3a2b8"&gt;
  &lt;main&gt;
    &lt;p&gt;Edsger Wybe Dijkstra was one of the most influential members of computing science’s founding generation. Among the domains in which his scientific contributions are fundamental are&lt;/p&gt;
    &lt;p&gt;algorithm design&lt;/p&gt;
    &lt;p&gt;programming languages&lt;/p&gt;
    &lt;p&gt;program design&lt;/p&gt;
    &lt;p&gt;operating systems&lt;/p&gt;
    &lt;p&gt;distributed processing&lt;/p&gt;
    &lt;p&gt;formal specification and verification&lt;/p&gt;
    &lt;p&gt;design of mathematical arguments&lt;/p&gt;
    &lt;p&gt;In addition, Dijkstra was intensely interested in teaching, and in the relationships between academic computing science and the software industry.&lt;/p&gt;
    &lt;p&gt;During his forty-plus years as a computing scientist, which included positions in both academia and industry, Dijkstra’s contributions brought him many prizes and awards, including computing science’s highest honor, the ACM Turing Award.&lt;/p&gt;
    &lt;p&gt;The Manuscripts&lt;/p&gt;
    &lt;p&gt;Like most of us, Dijkstra always believed it a scientist’s duty to maintain a lively correspondence with his scientific colleagues. To a greater extent than most of us, he put that conviction into practice. For over four decades, he mailed copies of his consecutively numbered technical notes, trip reports, insightful observations, and pungent commentaries, known collectively as “EWDs”, to several dozen recipients in academia and industry. Thanks to the ubiquity of the photocopier and the wide interest in Dijkstra’s writings, the informal circulation of many of the EWDs eventually reached into the thousands.&lt;/p&gt;
    &lt;p&gt;Although most of Dijkstra’s publications began life as EWD manuscripts, the great majority of his manuscripts remain unpublished. They have been inaccessible to many potential readers, and those who have received copies have been unable to cite them in their own work. To alleviate both of these problems, the department has collected over a thousand of the manuscripts in this permanent web site, in the form of PDF bitmap documents (to read them, you’ll need a copy of Acrobat Reader). We hope you will find it convenient, useful, inspiring, and enjoyable.&lt;/p&gt;
    &lt;p&gt;The original manuscripts, along with diaries, correspondence, photographs, and other papers, are housed at The Center for American History of The University of Texas at Austin.&lt;/p&gt;
    &lt;p&gt;Indexes&lt;/p&gt;
    &lt;p&gt;Each manuscript file is accessible through either of two indexes:&lt;/p&gt;
    &lt;p&gt;0. BibTeX index. Each entry includes all the available bibliographic data.&lt;/p&gt;
    &lt;p&gt;1. Ad-hoc indexes. These contain titles only, but are faster if you know what you’re looking for.&lt;/p&gt;
    &lt;p&gt;EWD-numbered documents(This index gives an approximate correspondence between manuscripts’ EWD numbers and the year in which they appeared.)&lt;/p&gt;
    &lt;p&gt;Technical reports from the Mathematical Centre (now CWI: Centrum voor Wiskunde en Informatica)&lt;/p&gt;
    &lt;p&gt;You can find a table relating EWD numbers to publication years here.&lt;/p&gt;
    &lt;p&gt;Many of the privately circulated manuscripts collected here were subsequently published; their copyrights are held by their respective publishers.&lt;/p&gt;
    &lt;p&gt;Transcripts and translations&lt;/p&gt;
    &lt;p&gt;A growing number of the PDF bitmap documents have been transcribed to make them searchable and accessible to visitors who are visually impaired.&lt;/p&gt;
    &lt;p&gt;A few of the manuscripts written in Dutch have been translated into English, and one —EWD1036— has been translated into Spanish. EWD28 has been translated from English into Russian.&lt;/p&gt;
    &lt;p&gt;For these transcriptions and translations we are grateful to over sixty contributors. Volunteers willing to transcribe manuscripts are always welcome (Note: doing EWDs justice in translation has turned out to be too difficult, so we are no longer soliciting translations).&lt;/p&gt;
    &lt;p&gt;Proofreading Each transcription gets a cursory scan as it’s prepared for uploading, but since a web page can always be updated, I don’t strive for (unattainable) perfection before installing it. On the web, proofreading is a game that can be played by every reader; if you spot an error, please&lt;/p&gt;
    &lt;p&gt;Links between EWDs&lt;/p&gt;
    &lt;p&gt;A compilation of cross-references has been contributed by Diethard Michaelis. As its author notes, the collection is incomplete, and all readers are invited to add to it.&lt;/p&gt;
    &lt;p&gt;Dijkstra often returned to topics about which he had already written, when he had something new to say or even just a better way of saying it. When Dijkstra himself didn’t provide the backward references, we indicate the relationship by "see also" links in the index, leaving the judgment of the extent to which the earlier EWD is superseded by the later one to the reader. Any reader who notices such a relationship is invited to&lt;/p&gt;
    &lt;p&gt;Summaries&lt;/p&gt;
    &lt;p&gt;We have begun adding summaries of the EWDs. This innovation was suggested by Günter Rote, who contributed the first dozen summaries. Additional contributions of summaries—especially summaries in English of EWDs in Dutch—are most welcome.&lt;/p&gt;
    &lt;p&gt;Copyrights&lt;/p&gt;
    &lt;p&gt;Copyrights in most EWDs are held by his children, one of whom — — handles requests for permission to publish reproductions. The exceptions are documents that were published, and whose copyrights are held by their publishers; those documents are listed here, and each one is provided with a cover page identifying the copyright holder.&lt;/p&gt;
    &lt;p&gt;Because the original manuscripts are in possession of the Briscoe Center for American History at The University of Texas, the Center’s policies are also applicable.&lt;/p&gt;
    &lt;p&gt;Video and audio&lt;/p&gt;
    &lt;p&gt;In addition to the manuscripts, you may enjoy some recordings of Dijkstra lectures and interviews.&lt;/p&gt;
    &lt;p&gt;About Dijkstra and his work&lt;/p&gt;
    &lt;p&gt;An interview with Dijkstra (Spanish translation here) was conducted in 1985 by Rogier F. van Vlissingen, who has also written a personal reflection on “Dijkstra’s sense of what computer science and programming are and what they aren’t.”&lt;/p&gt;
    &lt;p&gt;Another interview was conducted by Philip L. Frana in August 2001. A transcript is available in the on-line collection of the Charles Babbage Institute.&lt;/p&gt;
    &lt;p&gt;To mark the occasion of Dijkstra’s retirement in November 1999 from the Schlumberger Centennial Chair in Computer Sciences, which he had occupied since 1984, and to celebrate his forty-plus years of seminal contributions to computing science, the Department of Computer Sciences organized a symposium, In Pursuit of Simplicity, which took place on his birthday in May 2000. The symposium’s program (10 MB) contains an outline of Dijkstra’s career, as well as a collection of quotes culled from his writings, from his blackboard, and from what others have said about him. Banquet speeches by David Gries, Fred Schneider, Krzysztof Apt, W.M. Turski, and H. Richards were recorded on a video.&lt;/p&gt;
    &lt;p&gt;Dijkstra’s death in August 2002 was marked by many obituaries and memorials, including the Computer Sciences department’s memorial celebration.&lt;/p&gt;
    &lt;p&gt;A remembrance of Dijkstra was posted in May 2008 by Maarten van Emden (thanks to Tristram Brelstaff for noting it).&lt;/p&gt;
    &lt;p&gt;In 2021 Krzysztof R. Apt and Tony Hoare edited a commemoration of Edsger Dijkstra written by more than twenty computer scientists who knew him as a colleague, teacher, and friend.&lt;/p&gt;
    &lt;p&gt;A blog devoted to Dijkstra’s works and thoughts has been created, and is being maintained, by the historian of computing Edgar G. Daylight. An article by Daylight, “Dijkstra’s Rallying Cry for Generalization: the Advent of the Recursive Procedure, late 1950s - early 1960s,” appeared in The Computer Journal, March 2011.&lt;/p&gt;
    &lt;p&gt;In his blog A Programmer’s Place, Maarten van Emden has an entry entitled “Another scoop by Dijkstra?”. The entry describes Dijkstra’s “remarkable insight [in “Notes on Structured Programming” (EWD 249)] that resolves the stand-off between the Sieve of Eratosthenes (efficient in terms of time, but not memory) and the method of Trial Division (efficient in terms of memory, but not time)” by applying the Assembly-line Principle.&lt;/p&gt;
    &lt;p&gt;The Edsger W. Dijkstra Prize in Distributed Computing honors Dijkstra’s “foundational work on concurrency primitives (such as the semaphore), concurrency problems (such as mutual exclusion and deadlock), reasoning about concurrent systems, and self-stabilization [, which] comprises one of the most important supports upon which the field of distributed computing is built.”&lt;/p&gt;
    &lt;p&gt;The Dijkstra Memorial Lectures&lt;/p&gt;
    &lt;p&gt;A series of annual lectures in memory of Dijkstra commenced at The University of Texas in October 2010.&lt;/p&gt;
    &lt;p&gt;About this site&lt;/p&gt;
    &lt;p&gt;Recent significant changes in the site are listed here; the most recent change was posted on 30 March 2021.&lt;/p&gt;
    &lt;p&gt;The folks who contributed most significantly to the site’s creation are acknowledged here.&lt;/p&gt;
    &lt;p&gt;Comments and suggestions about the site are always welcome; please email them to the&lt;/p&gt;
    &lt;p&gt;Related site&lt;/p&gt;
    &lt;p&gt;If you find this site interesting, you may also be interested in another site:&lt;/p&gt;
    &lt;p&gt;Discipline in Thought which is a website dedicated to disciplined thinking, calculational mathematics, and mathematical methodology. The members of this site are markedly influenced by the works of EWD, and the material shared through the website continues in the traditions set by EWD (among others).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45866224</guid><pubDate>Sun, 09 Nov 2025 15:27:42 +0000</pubDate></item><item><title>AI isn't replacing jobs. AI spending is</title><link>https://www.fastcompany.com/91435192/chatgpt-llm-openai-jobs-amazon</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45866243</guid><pubDate>Sun, 09 Nov 2025 15:30:23 +0000</pubDate></item><item><title>The Principles of Diffusion Models</title><link>https://arxiv.org/abs/2510.21890</link><description>&lt;doc fingerprint="ac0cac09d8b5828a"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Machine Learning&lt;/head&gt;&lt;p&gt; [Submitted on 24 Oct 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:The Principles of Diffusion Models&lt;/head&gt;View PDF&lt;quote&gt;Abstract:This monograph presents the core principles that have guided the development of diffusion models, tracing their origins and showing how diverse formulations arise from shared mathematical ideas. Diffusion modeling starts by defining a forward process that gradually corrupts data into noise, linking the data distribution to a simple prior through a continuum of intermediate distributions. The goal is to learn a reverse process that transforms noise back into data while recovering the same intermediates. We describe three complementary views. The variational view, inspired by variational autoencoders, sees diffusion as learning to remove noise step by step. The score-based view, rooted in energy-based modeling, learns the gradient of the evolving data distribution, indicating how to nudge samples toward more likely regions. The flow-based view, related to normalizing flows, treats generation as following a smooth path that moves samples from noise to data under a learned velocity field. These perspectives share a common backbone: a time-dependent velocity field whose flow transports a simple prior to the data. Sampling then amounts to solving a differential equation that evolves noise into data along a continuous trajectory. On this foundation, the monograph discusses guidance for controllable generation, efficient numerical solvers, and diffusion-motivated flow-map models that learn direct mappings between arbitrary times. It provides a conceptual and mathematically grounded understanding of diffusion models for readers with basic deep-learning knowledge.&lt;/quote&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;cs.LG&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;p&gt; IArxiv Recommender (What is IArxiv?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45866572</guid><pubDate>Sun, 09 Nov 2025 16:10:23 +0000</pubDate></item><item><title>Bull markets make you feel smarter than you are</title><link>https://awealthofcommonsense.com/2025/11/ben-graham-bull-market-brains/</link><description>&lt;doc fingerprint="798b513dafb3abc0"&gt;
  &lt;main&gt;
    &lt;p&gt;Bull markets make you feel smarter than you really are.&lt;/p&gt;
    &lt;p&gt;Bear markets make you feel dumber than you really are.&lt;/p&gt;
    &lt;p&gt;It’s almost impossible to avoid feeling like a know-it-all when things are going up and a know-nothing when things are going down.&lt;/p&gt;
    &lt;p&gt;That’s human nature.&lt;/p&gt;
    &lt;p&gt;Benjamin Graham started his investment partnership in the Roaring 20s with $400,000 of money from clients and his own capital. In just three years he turned $400k into $2.5 million. Much of it was Graham’s own money, derived from a combination of savings and the management fees he earned.&lt;/p&gt;
    &lt;p&gt;This magical run of performance just so happened to coincide with a melt-up in the stock market.&lt;/p&gt;
    &lt;p&gt;Alas, like most people, Graham didn’t see the Great Depression coming. He tried to pick the bottom on numerous occasions with disastrous results.&lt;/p&gt;
    &lt;p&gt;Michael wrote about what happened in Big Mistakes:&lt;/p&gt;
    &lt;p&gt;In 1930, thinking the worst was over, Graham went all in and then some. He used margin to leverage what he thought would be terrific returns. But the worst was not over, and when the Dow collapsed, Graham had his worst year ever, losing 50%. “He personally was wiped out in the crash. Having ducked the 1929 cataclysm, he was enticed back into the market before the final bottom.”&lt;/p&gt;
    &lt;p&gt;By 1932, the $2.5 million had dwindled to just $375k.&lt;/p&gt;
    &lt;p&gt;In his memoir Graham wrote about how his early successes impacted his mentality before the calamity:&lt;/p&gt;
    &lt;p&gt;At thirty-one I was convinced that I knew it all–or at least I knew all I needed to know about making money in stocks and bonds–that I had Wall Street by the tail, that my future was as unlimited as my ambitions, that I was destined to enjoy great wealth and all the material pleasures that wealth could buy. I thought of owning a large yacht, a villa at Newport, racehorses. I was too young to realize that I had caught a bad case of hubris.&lt;/p&gt;
    &lt;p&gt;The good news is Graham was able to turn it around. He didn’t take a paycheck until all of his investors were made whole. Despite his setbacks in the Great Depression, his long-term track record was impressive while his impact on investor education still lives on.&lt;/p&gt;
    &lt;p&gt;One of my all-time favorite investment books is What I Learned Losing a Million Dollars by Brendan Moynihan.&lt;/p&gt;
    &lt;p&gt;Moynihan tells the story of Jim Paul, a country boy from Kentucky who went from dirt-poor to millionaire trader on the Chicago Mercantile Exchange to broke in a matter of years.&lt;/p&gt;
    &lt;p&gt;This is how Moynihan describes the story in the introduction:&lt;/p&gt;
    &lt;p&gt;One of the premises of this book is that the rise sets up the fall; the winning sets up the losing. You can’t really be set up for disaster without having it preceded by success.&lt;/p&gt;
    &lt;p&gt;It’s extremely difficult to understand this dynamic as a young person who has experienced some level of success in the markets. Moynihan explains:&lt;/p&gt;
    &lt;p&gt;If you start from scratch and have a run of successes, you are setting yourself up for the coming failure because the successes lead to a variety of psychological distortions. This is particularly true if you have unknowingly broken the rules of the game and won anyway. Once that happens to you, you think that you are somehow special and exempt from following the rules.&lt;/p&gt;
    &lt;p&gt;There are a lot of people who have made a lot of money in this bull market.&lt;/p&gt;
    &lt;p&gt;So many investors have made life-altering amounts of money. This is a wonderful thing.&lt;/p&gt;
    &lt;p&gt;But it’s important to avoid letting success in the markets go to your head. This cycle will not last forever. Making money won’t always be this easy.&lt;/p&gt;
    &lt;p&gt;The market will make you feel dumb again at some point…even when it’s not true.&lt;/p&gt;
    &lt;p&gt;Further Reading:&lt;lb/&gt; The Curse of the Young Millionaire&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45866688</guid><pubDate>Sun, 09 Nov 2025 16:25:05 +0000</pubDate></item><item><title>Marble Fountain</title><link>https://willmorrison.net/posts/marble-fountain/</link><description>&lt;doc fingerprint="51808547f247bba"&gt;
  &lt;main&gt;
    &lt;p&gt;5 minutes&lt;/p&gt;
    &lt;head rend="h1"&gt;Marble Fountain&lt;/head&gt;
    &lt;p&gt;I really enjoy procedural generation, especially systems designed to work with hardware outputs. After starting work at Formlabs in September of 2023 and gaining access to much nicer printers than I was used to, I started wanting to tackle some large algorithmic structure projects. Complexity is free in 3d printing, the limit of design geometry is mostly how much time you’re willing to spend in CAD. I wanted to print the most complicated art piece I could think of. Marble Fountain is what I came up with.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tracks&lt;/head&gt;
    &lt;p&gt;My initial system came together quickly. Randomly placing spaced out points, drawing a spline through them, and setting a constant slope just works. My first draft was just subtracting a tube from the solid support structure which worked but was super limited. I wanted to add more parts and so I started working on a path solver. I wanted to fit as much motion into the volume of the printer as possible. This turned out to be extremely challenging.&lt;/p&gt;
    &lt;p&gt;The solver starts by making a random series of line segments connecting the top and bottom of the lift. There are several different algorithms to generate this guess, as the initial conditional has a noticeable impact on the shape of the structure for lower path counts. It’s interesting to play with different variants of the starting conditions and see how they change during generation.&lt;/p&gt;
    &lt;p&gt;A series of functions update the positions over time to “pull” the points into a followable path. The points making up each path:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Stay in the bounding box&lt;/item&gt;
      &lt;item&gt;Evenly space themselves out&lt;/item&gt;
      &lt;item&gt;Pull towards a fixed height to enforce a constant slope&lt;/item&gt;
      &lt;item&gt;Enforce min and max turning radius of the path&lt;/item&gt;
      &lt;item&gt;Repel away from other tracks&lt;/item&gt;
      &lt;item&gt;Repel away from distant sections of our own track&lt;/item&gt;
      &lt;item&gt;Smooth out changes in slope to prevent jumps&lt;/item&gt;
      &lt;item&gt;Prevent slope from ever increasing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Velocity is a much harder problem than I anticipated. The tracks break a lot of the obvious assumptions if you act like the marble is a point mass, as changing the bank of the track moves the axis of rotation and can burn off rotational inertia to friction. Long straight sections would build up too much speed and bearings fly off on the turns, but balls taking sharp turns at slow speed will lose too much momentum and stop. I settled on setting a minimum turn radius for the track and banking much more aggressively than is technically necessary for any given speed, so it constantly snakes back and forth to burn off speed.&lt;/p&gt;
    &lt;p&gt;One of the most elegant designs of the whole structure is how the lift acts like a ball screw. The the screw is constrained by the balls on all sides which allows it to run with no bearing at the top. This also leads to a failure mode where if the screw ever only has balls on one side it will immediately start wobbling badly enough that all the balls currently rolling will fall off the tracks.&lt;/p&gt;
    &lt;head rend="h2"&gt;Supports&lt;/head&gt;
    &lt;p&gt;The support generation was surprisingly simple. Iterating from the top down and treating the support pillars as a particle system is quite robust. I spent more time tweaking the geometry for aesthetics than I did for actual structure and collision issues, although I did heavily lean on the overhang tolerance of the printer.&lt;/p&gt;
    &lt;p&gt;Each support:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Pulls towards other supports, weighted by distance and similarity in size&lt;/item&gt;
      &lt;item&gt;Repels away from other supports&lt;/item&gt;
      &lt;item&gt;Pulls to stay in the bounding box&lt;/item&gt;
      &lt;item&gt;Pulls towards a fixed radius from the center of the structure&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Supports also have inertia, which is where the arcs in the structure of the support columns come from.&lt;/p&gt;
    &lt;head rend="h2"&gt;Looking forward&lt;/head&gt;
    &lt;p&gt;The final models take around 5-20 minutes to export. There’s a ton I could do to optimize the models, but at this point the geometry is simply beyond the scope of OpenSCAD. If I was rewriting this I would probably use a different tool more optimized for this type of organic geometry, likely an SDF library. I have vague ambitions to do a big rewrite eventually but figured sharing janky code is better than none. I started this just planning for the janky splines as a weekend project but it has gotten thoroughly out of hand.&lt;/p&gt;
    &lt;p&gt;I have a ton of other ideas to play with if I do that big rewrite. There is no realistic velocity estimation at any point in the whole system right now, just a pile of heuristics. I was originally trying to not overcomplicate but building a proper acceleration model by measuring velocity with a camera would have almost definitely saved time overall. Trying to maintain a fixed slope makes collision prevention much harder but is required to keep speed within bounds. At this point I’m also just curious about the response curve, there’s a knee somewhere where the surfaces start to slip that I want to track down.&lt;/p&gt;
    &lt;head rend="h2"&gt;Looking back&lt;/head&gt;
    &lt;p&gt;This was the most work I have ever put into a hobby project. I started in February 2024 and worked on it on and off until September. I applied to show it in a gallery (shoutout to New Alliance Gallery in Somerville) with two months of warning, which wound up leading to a large crunch trying to make the system reliable enough to show in person in the weeks before the show. I was able to get it working consistently, although it did lose 2-3 balls an hour and could only run for a few hours without the motor overheating. I got pretty burned out and dropped the project, which is why I shelved it for a full year before sharing anything.&lt;/p&gt;
    &lt;p&gt;Finally, a huge thanks to my friend Alex who listened to me ramble about marbles for several months every day while walking home from work, gave a ton of helpful input, and lived with the dozens of ball bearings scattered across our apartment.&lt;/p&gt;
    &lt;p&gt;ProceduralGeneration Art 3D Printed Python&lt;/p&gt;
    &lt;p&gt;983 Words&lt;/p&gt;
    &lt;p&gt;2025-11-01 00:00 (Last updated: 2025-11-03 01:40)&lt;/p&gt;
    &lt;p&gt;789ee9a @ 2025-11-03&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45866697</guid><pubDate>Sun, 09 Nov 2025 16:26:09 +0000</pubDate></item><item><title>Bumble Berry Pi – A Cheap DIY Raspberry Pi Handheld Cyberdeck</title><link>https://github.com/samcervantes/bumble-berry-pi</link><description>&lt;doc fingerprint="f40f95074be15c8"&gt;
  &lt;main&gt;
    &lt;p&gt;A cheap, easy-to-build Raspberry Pi Handheld Cyberdeck&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I wanted a Clockwork Pi uConsole, but didn’t want to wait 90 business days&lt;/item&gt;
      &lt;item&gt;I like the tactile feeling of a mini keyboard&lt;/item&gt;
      &lt;item&gt;I wanted something small enough to fit into a pants pocket, so I can easily take it anywhere, but with a large enough screen to do useful things like writing little programs, running scripts, etc&lt;/item&gt;
      &lt;item&gt;I wanted to build this quickly &amp;amp; cheaply, with as many off-the-shelf components as possible&lt;/item&gt;
      &lt;item&gt;I mostly boot to the terminal interface and use tmux to manage mutliple terminal windows, but I occasionally use the GUI&lt;/item&gt;
      &lt;item&gt;I wanted to use the Raspberry Pi's I already owned (i.e. an old 3b+), rather than having to buy a new compute module&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;4.3” Touch Screen Display&lt;/item&gt;
      &lt;item&gt;Nice sized QWERTY keypad&lt;/item&gt;
      &lt;item&gt;37 Watt-hour battery (all day battery life with Raspberry Pi 3b+)&lt;/item&gt;
      &lt;item&gt;Only 2 3D-Printed Parts&lt;/item&gt;
      &lt;item&gt;Minimal assembly required&lt;/item&gt;
      &lt;item&gt;All parts available on Amazon&lt;/item&gt;
      &lt;item&gt;Cost: ~$60 worth of Amazon parts, not including the raspberry pi&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Part&lt;/cell&gt;
        &lt;cell role="head"&gt;QTY&lt;/cell&gt;
        &lt;cell role="head"&gt;Cost&lt;/cell&gt;
        &lt;cell role="head"&gt;Buy Link&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Raspberry Pi&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$50&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
        &lt;cell&gt;Pick your favorite. I picked a 3b+ for low cost and low power usage&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;4.3” Touch Screen Display&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$38&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Mini Bluetooth keyboard&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$23&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;37 Watt-Hr USB Power Bank&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$19&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
        &lt;cell&gt;Comes with short USB-C cable&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;USB-C to Micro-USB U-Shaped Adapter&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$10&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;USB-C Right Angle Adapter&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$9&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;M3x10mm Countersunk Head Bolt&lt;/cell&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;M2.5x8mm Socket Head Bolt&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;M3 Threaded Inserts&lt;/cell&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;2" Kapton Tape&lt;/cell&gt;
        &lt;cell&gt;1 ft&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
        &lt;cell&gt;You could use another type of double-sided tape&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;bumble-berry-pi-enclosure-A-v3.STL&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Download from this repo an print on a 3D printer using PLA&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;bumble-berry-pi-enclosure-B-v3.STL&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Download from this repo an print on a 3D printer using PLA&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Small phillips screw driver&lt;/item&gt;
      &lt;item&gt;M2.5mm hex driver&lt;/item&gt;
      &lt;item&gt;Soldering iron&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Please note: Assembly instructions are a work in progress. Please let me know if you'd like additional instructions/videos, etc and I will do my best to provide them.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;3D print the two enclosure parts in PLA&lt;/item&gt;
      &lt;item&gt;Insert the 6 threaded inserts using a soldering iron (I always love this part)&lt;/item&gt;
      &lt;item&gt;Attach the raspberry pi to the screen using 4 phillips screws&lt;/item&gt;
      &lt;item&gt;Plug the ribbon cable into the rapsberry pi &amp;amp; display&lt;/item&gt;
      &lt;item&gt;Attach the screen to the front eclosure using 4 M2.5x6mm socket head bolts&lt;/item&gt;
      &lt;item&gt;Place the front enclosure face down on a table and insert the keyboard&lt;/item&gt;
      &lt;item&gt;Add a piece of double-sided kapton tape to the back of the keyboard&lt;/item&gt;
      &lt;item&gt;Place the USB power bank in the front enclosure&lt;/item&gt;
      &lt;item&gt;Add a piece of double-sided kapton tape to the back of the power bank&lt;/item&gt;
      &lt;item&gt;Route the USB cables &amp;amp; adapters as shown&lt;/item&gt;
      &lt;item&gt;Screw the enclosure back onto the enclosure front using 6 M3x10mm countersunk head bolts&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45866772</guid><pubDate>Sun, 09 Nov 2025 16:34:44 +0000</pubDate></item><item><title>Ask HN: How do you get over the fear of sharing code?</title><link>https://news.ycombinator.com/item?id=45867176</link><description>&lt;doc fingerprint="4e6339913a219f53"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;I'm a junior. Truth be told, I don't really care if professionals/adults see my code or pick it apart/mock it/fork it or whatever. All my repos are private just because I worry about other students being lazy and just ripping my hard work and claiming it as their own. That really pisses me off when I hear some horror stories like that.&lt;/p&gt;
      &lt;p&gt;Is this unfounded? Or do I have a right for some concern? It's obviously easier for viewers to just see public code repos and browse without ever requesting access so I know I'm losing some traffic (from my portfolio site)&lt;/p&gt;
      &lt;p&gt;I was thinking the alternative would be just linking my demo on my portfolio site as a proof of concept that yes I made it, yes it works, and if you're curious , here's a link to the code u can request independently of github.&lt;/p&gt;
      &lt;p&gt;Thank you in advance.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45867176</guid><pubDate>Sun, 09 Nov 2025 17:17:20 +0000</pubDate></item></channel></rss>