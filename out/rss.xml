<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 20 Dec 2025 16:11:55 +0000</lastBuildDate><item><title>Delty (YC X25) Is Hiring an ML Engineer</title><link>https://www.ycombinator.com/companies/delty/jobs/MDeC49o-machine-learning-engineer</link><description>&lt;doc fingerprint="b95c3d540015cfe8"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;head rend="h3"&gt;About Us&lt;/head&gt;
      &lt;p&gt;Delty is building the healthcare‚Äôs AI operating system. We create voice-based and computer-based assistants that streamline clinical workflows, reduce administrative burden, and help providers focus on patient care. Our system learns from real healthcare environments to deliver reliable, context-aware support that improves efficiency and elevates the provider experience.&lt;/p&gt;
      &lt;p&gt;Delty was founded by former engineering leaders from Google, including co-founders with deep experience at YouTube and in large-scale infrastructure. You‚Äôll get to work alongside people who built massive systems at scale ‚Äî a chance to learn a lot and contribute meaningfully from day one.&lt;/p&gt;
      &lt;p&gt;We believe in solving hard problems together as a team, iterating quickly, and building software with long-term thinking and ownership.&lt;/p&gt;
      &lt;head rend="h3"&gt;What You‚Äôll Do&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Build and own production machine learning systems end-to-end: from data modeling and feature engineering to training, evaluation, deployment, and monitoring.&lt;/item&gt;
        &lt;item&gt;Design and implement data pipelines that turn raw, messy real-world healthcare data into reliable features for machine learning models.&lt;/item&gt;
        &lt;item&gt;Train and evaluate models for ranking, prioritization, and prediction problems (for example, identifying high-risk or high-priority cases).&lt;/item&gt;
        &lt;item&gt;Deploy models into production as reliable services or batch jobs, with clear versioning, monitoring, and rollback strategies.&lt;/item&gt;
        &lt;item&gt;Work closely with backend engineers and product leaders to integrate machine learning into real workflows and decision-making systems.&lt;/item&gt;
        &lt;item&gt;Make architectural decisions around model choice, evaluation metrics, retraining cadence, and system guardrails ‚Äî balancing accuracy, explainability, reliability, and operational constraints.&lt;/item&gt;
        &lt;item&gt;Collaborate directly with founders and engineers to translate product and operational needs into scalable, maintainable machine learning solutions.&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;What We‚Äôre Looking For&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;At least 3 years of experience building and deploying machine learning systems in production.&lt;/item&gt;
        &lt;item&gt;Strong foundation in machine learning for structured (tabular) data, including feature engineering, regression or classification models, and ranking or prioritization problems.&lt;/item&gt;
        &lt;item&gt;Experience with the full machine learning lifecycle: data preparation, train/test splitting, evaluation, deployment, retraining, and monitoring.&lt;/item&gt;
        &lt;item&gt;Solid backend engineering skills: writing production-quality code, building services or batch jobs, and working with databases and data pipelines.&lt;/item&gt;
        &lt;item&gt;Good system design instincts: you understand trade-offs between model complexity, reliability, latency, scalability, and maintainability.&lt;/item&gt;
        &lt;item&gt;Comfort working in a fast-paced startup environment with high ownership and ambiguity.&lt;/item&gt;
        &lt;item&gt;Ability to clearly explain modeling choices, assumptions, and limitations to non-machine-learning stakeholders.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Bonus:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Experience working with healthcare or operational decision-support systems.&lt;/item&gt;
        &lt;item&gt;Experience building or integrating LLM systems in production, such as retrieval-augmented generation, fine-tuning, or structured prompting workflows.&lt;/item&gt;
        &lt;item&gt;Prior startup experience or founder mindset ‚Äî we value ownership, pragmatism, and bias toward shipping.&lt;/item&gt;
        &lt;item&gt;Experience with model monitoring, data drift detection, or ML infrastructure tooling.&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;Why join&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Learn from seasoned Google engineers: As former Google engineers who built systems at YouTube and Google Pay, we‚Äôve operated at massive scale. Working alongside us gives you a chance to build similar systems and learn best practices, scale thinking, and software design deeply.&lt;/item&gt;
        &lt;item&gt;High impact: At a small but ambitious team, your contributions will influence architecture, product direction, and core features. You will have real ownership and see the effects of your work quickly.&lt;/item&gt;
        &lt;item&gt;Grow fast: We‚Äôre iterating rapidly; you‚Äôll be exposed to the full stack, AI/ML pipelines, system architecture, data modeling, and product-level decisions ‚Äî a fast-track to becoming a senior engineer or technical lead.&lt;/item&gt;
        &lt;item&gt;Challenging and meaningful work: We‚Äôre tackling the hardest part of software engineering: bridging AI-generated prototypes and robust, scalable enterprise-grade systems. If you enjoy thinking deeply about systems and building reliable, maintainable foundations ‚Äî this is for you.&lt;/item&gt;
      &lt;/list&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46318676</guid><pubDate>Thu, 18 Dec 2025 21:02:10 +0000</pubDate></item><item><title>8-bit Bol√©ro</title><link>https://linusakesson.net/music/bolero/index.php</link><description>&lt;doc fingerprint="ad1278a56e19de8f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Bol√©ro&lt;/head&gt;
    &lt;p&gt;I perform Maurice Ravel's Bol√©ro on a variety of homemade 8-bit instruments.&lt;/p&gt;
    &lt;head rend="h2"&gt;Download&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Linus Akesson - Maurice Ravel - Bol√©ro.mp3 (MP3, 26.2 MB)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Some stats and details&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;9 hours and 42 minutes of footage&lt;/item&gt;
      &lt;item&gt;52 mixer channels&lt;/item&gt;
      &lt;item&gt;13 neck- and bowties&lt;/item&gt;
      &lt;item&gt;9 different instruments&lt;/item&gt;
      &lt;item&gt;1 crazy automaton&lt;/item&gt;
      &lt;item&gt;0 regrets&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This project took me a bit over half a year to finish.&lt;/p&gt;
    &lt;p&gt;I hope you'll enjoy the video as much as I enjoyed making it! There are many little details that I'll let you discover on your own.&lt;/p&gt;
    &lt;p&gt;It was fun to put my tools and methods to the test with this huge undertaking. When I started out I had no idea if my mixing and video-editing process would work at this scale, but it turned out to only need a few tweaks here and there.&lt;/p&gt;
    &lt;p&gt;The nine instruments are: The Qweremin (breadbin / regular C64C / dark C64C), Qwertuoso (breadbin), the Paulimba, the Tenor Commodordion, the Family Bass (albeit not as a bass this time), my still unnamed floppy-drive noise instrument (1541 / 1541-II), the C=TAR, the Chipophone, and a newcomer: NES timpani.&lt;/p&gt;
    &lt;p&gt;The timpani sound is based on the famous NES staircase triangle wave. But there is no register for controlling its volume, and yet we can hear an envelope with a release phase. To achieve this, I rely on a neat trick that was used already in Super Mario Bros.: It turns out that the triangle channel is mixed with the ADPCM sample-playback channel and then fed through a non-linear resistor network (the output is proportional to ((adpcm + triangle)‚Åª¬π + C)‚Åª¬π). Therefore, adding a constant DC offset via the sample channel makes the triangle more or less compressed.&lt;/p&gt;
    &lt;p&gt;In nearly every part of this video, what you see is what you hear; the audio and video were recorded at the same time. But the automaton is different: Thanks to its 100% repeatable performance I could capture the sound of each individual section of the hardware, with the microphone up close, and then mix the parts according to taste and combine them with the visuals from a separate take.&lt;/p&gt;
    &lt;p&gt;Fun fact: You can't see it in the video but the automaton is supported by original C64 boxes:&lt;/p&gt;
    &lt;p&gt;Posted Friday 19-Dec-2025 08:00&lt;/p&gt;
    &lt;head rend="h3"&gt;Discuss this page&lt;/head&gt;
    &lt;p&gt;Disclaimer: I am not responsible for what people (other than myself) write in the forums. Please report any abuse, such as insults, slander, spam and illegal material, and I will take appropriate actions. Don't feed the trolls.&lt;/p&gt;
    &lt;p&gt;Jag tar inget ansvar f√∂r det som skrivs i forumet, f√∂rutom mina egna inl√§gg. V√§nligen rapportera alla inl√§gg som bryter mot reglerna, s√• ska jag se vad jag kan g√∂ra. Som regelbrott r√§knas till exempel f√∂rol√§mpningar, f√∂rtal, spam och olagligt material. Mata inte tr√•larna.&lt;/p&gt;
    &lt;p&gt;Fri 19-Dec-2025 21:55&lt;/p&gt;
    &lt;p&gt;12 more comments hidden. Click to show all.&lt;/p&gt;
    &lt;p&gt;Sat 20-Dec-2025 11:48&lt;/p&gt;
    &lt;p&gt;Sat 20-Dec-2025 13:44&lt;/p&gt;
    &lt;p&gt;Sat 20-Dec-2025 14:38&lt;/p&gt;
    &lt;p&gt;Sat 20-Dec-2025 15:37&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46324702</guid><pubDate>Fri, 19 Dec 2025 11:38:54 +0000</pubDate></item><item><title>Garage ‚Äì An S3 object store so reliable you can run it outside datacenters</title><link>https://garagehq.deuxfleurs.fr/</link><description>&lt;doc fingerprint="dd8215339a80dd6"&gt;
  &lt;main&gt;
    &lt;p&gt;An S3 object store so reliable you can run it outside datacenters&lt;/p&gt;
    &lt;p&gt;Made for redundancy&lt;/p&gt;
    &lt;p&gt;Each chunk of data is replicated in 3 zones&lt;/p&gt;
    &lt;p&gt;We made it lightweight and kept the efficiency in mind:&lt;/p&gt;
    &lt;p&gt;We ship a single dependency-free binary that runs on all Linux distributions&lt;/p&gt;
    &lt;p&gt;We are sysadmins, we know the value of operator-friendly software&lt;/p&gt;
    &lt;p&gt;We do not have a dedicated backbone, and neither do you,&lt;lb/&gt; so we made software that run over the Internet across multiple datacenters&lt;/p&gt;
    &lt;p&gt;We worked hard to keep requirements as low as possible:&lt;/p&gt;
    &lt;p&gt;We built Garage to suit your existing infrastructure:&lt;/p&gt;
    &lt;p&gt; Garage implements the Amazon S3 API&lt;lb/&gt;and thus is already compatible with many applications. &lt;/p&gt;
    &lt;p&gt;Garage leverages insights from recent research in distributed systems:&lt;/p&gt;
    &lt;p&gt;Garage has benefitted multiple times from public funding:&lt;/p&gt;
    &lt;p&gt;If you want to participate in funding Garage development, either through donation or support contract, please get in touch with us.&lt;/p&gt;
    &lt;p&gt;This project has received funding from the European Union's Horizon 2021 research and innovation programme within the framework of the NGI-POINTER Project funded under grant agreement N√Ç¬∞ 871528.&lt;/p&gt;
    &lt;p&gt;This project has received funding from the NGI Zero Entrust Fund, a fund established by NLnet with financial support from the European Commission's Next Generation Internet programme, under the aegis of DG Communications Networks, Content and Technology under grant agreement No 101069594.&lt;/p&gt;
    &lt;p&gt;This project has received funding from the NGI Zero Commons Fund, a fund established by NLnet with financial support from the European Commission's Next Generation Internet programme, under the aegis of DG Communications Networks, Content and Technology under grant agreement No 101135429.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46326984</guid><pubDate>Fri, 19 Dec 2025 15:40:03 +0000</pubDate></item><item><title>TP-Link Tapo C200: Hardcoded Keys, Buffer Overflows and Privacy</title><link>https://www.evilsocket.net/2025/12/18/TP-Link-Tapo-C200-Hardcoded-Keys-Buffer-Overflows-and-Privacy-in-the-Era-of-AI-Assisted-Reverse-Engineering/</link><description>&lt;doc fingerprint="2540dd11803d63cc"&gt;
  &lt;main&gt;
    &lt;p&gt;Hi friends and welcome to the last post for this year! Whenever someone asks me how to get started with reverse engineering, I always give the same advice: buy the cheapest IP camera you can find. These devices are self-contained little ecosystems - they have firmware you can extract, network protocols you can sniff, and mobile apps you can decompile. Chances are, you‚Äôll find something interesting. At worst, you‚Äôll learn a lot about assembly and embedded systems. At best, you‚Äôll find some juicy vulnerability and maybe learn how to exploit it!&lt;/p&gt;
    &lt;p&gt;I own several TP-Link Tapo C200 cameras myself. They‚Äôre cheap (less than 20 EUR from Italy), surprisingly stable, and I genuinely like them - they just work. One weekend, I decided just for fun to take my own advice. The Tapo C200 has been around for a while and has had a few CVEs discovered and more or less patched over the years, so I honestly wasn‚Äôt expecting to find much in the latest firmware. However, I wanted to use this chance to perform some AI assisted reverse engineering and test whether I could still find anything at all.&lt;/p&gt;
    &lt;p&gt;I documented the entire process live on Arcadia - my thought process, the dead ends, the AI prompts that worked and the ones that didn‚Äôt. If you want the raw, unfiltered version with screenshots and videos of things crashing, go check that out.&lt;/p&gt;
    &lt;p&gt;This post is the cleaned-up version of that journey, where I wanted to show how I approach firmware analysis these days, now that we have AI. You will notice that in several instances I will be particularly lazy and delegate to AI things I could have done manually and/or inferred myself after some more work. Keep in mind that while I am generally lazy, this was also an experiment in integrating and documenting how effective AI can be for security research and reverse engineering, and especially in making them accessible to less experienced/sophisticated researchers/attackers.&lt;/p&gt;
    &lt;p&gt;What started as a lazy weekend project turned into finding a few security vulnerabilities that affect about 25,000 of these devices directly exposed on the internet.&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting the Firmware&lt;/head&gt;
    &lt;head rend="h3"&gt;Tools&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Old friend JD-GUI to reverse the Android app and get a sense of things&lt;/item&gt;
      &lt;item&gt;The AWS CLI to download the firmware image.&lt;/item&gt;
      &lt;item&gt;binwalk for firmware inspection.&lt;/item&gt;
      &lt;item&gt;Grok to give a quick AI assisted look into prior research.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The first step is always obtaining the firmware binary file and this time it was super easy! After some basic reversing of the Tapo Android app, I found out that TP-Link have their entire firmware repository in an open S3 bucket. No authentication required. So, you can list and download every version of every firmware they‚Äôve ever released for any device they ever produced:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1&lt;/quote&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;$ aws s3 ls s3://download.tplinkcloud.com/ --no-sign-request --recursive&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The entire output is here, for the curious. This provides access to the firmware image of every TP-Link device - routers, cameras, smart plugs, you name it. A reverse engineer‚Äôs candy store.&lt;/p&gt;
    &lt;p&gt;I grabbed version 1.4.2 Build 250313 Rel.40499n for the C200 (Hardware Revision 3), named &lt;code&gt;Tapo_C200v3_en_1.4.2_Build_250313_Rel.40499n_up_boot-signed_1747894968535.bin&lt;/code&gt;, and started poking around. However, the first attempt at identifying its format via binwalk was not successful, indicating that some sort of encryption or obfuscation was in place.&lt;/p&gt;
    &lt;p&gt;And here is where I started using AI. I used Grok to do some deep research on how to decrypt the firmware for these cameras. Since I knew other hackers worked on this before, I delegated searching into hundreds of relevant web pages to the AI:&lt;/p&gt;
    &lt;head rend="h3"&gt;Decrypting the Firmware&lt;/head&gt;
    &lt;head rend="h3"&gt;Tools&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The tp-link-decrypt tool to decrypt the firmware image.&lt;/item&gt;
      &lt;item&gt;binwalk for firmware inspection.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Thanks to Grok, the tp-link-decrypt tool and the fact that every firmware image for every device seems to be encrypted the same exact way, we can now decrypt the firmware. The tool extracts RSA keys from TP-Link‚Äôs own GPL code releases - they publish the decryption keys themselves as part of their open source obligations.&lt;/p&gt;
    &lt;p&gt;Credits to @watchfulip for the original extensive TP-Link firmware research and @tangrs for finding that the relevant binaries are published in TP-Link GPL code dumps and how to extract keys from them.&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1&lt;/quote&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;$ git clone https://github.com/robbins/tp-link-decrypt&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;After decryption, the firmware revealed a fairly standard structure: a bootloader, a kernel, and a SquashFS root filesystem.&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1&lt;/quote&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;$ binwalk -e Tapo_C200_v3_1.4.2_decrypted.bin&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Hunting for Bugs&lt;/head&gt;
    &lt;head rend="h3"&gt;Tools&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Ghidra to decompile and understand the MIPS binaries&lt;/item&gt;
      &lt;item&gt;GhidraMCP to let an AI connect to my running Ghidra instance and support me in the process.&lt;/item&gt;
      &lt;item&gt;Cline to ask AI to explore the filesystem and find interesting components.&lt;/item&gt;
      &lt;item&gt;A mix of Anthropic's Opus and Sonnet 4.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Once extracted, I used AI and Cline to explore the filesystem in search of which components handle the discovery protocol, camera web API, video streaming, etc all discovered earlier while reversing the Android app.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Claude Opus 4: "this is the firmware of an ipcam, i'm trying to find where the webapp that serves the API is managed" pic.twitter.com/NrgtKGUD8h&lt;/p&gt;‚Äî Simone Margaritelli (@evilsocket) July 18, 2025&lt;/quote&gt;
    &lt;p&gt;Loading Ghidra and giving a quick look at the &lt;code&gt;tp_manage&lt;/code&gt; binary, revealed the first interesting thing:&lt;/p&gt;
    &lt;p&gt;This private key is not generated at boot. Similarly to CVE-2025-1099 for the C500, the C200 embeds in its firmware the private key that serves the SSL for a few APIs. If you‚Äôre on the same network as a camera, you can MitM and decrypt their HTTPS traffic with keys you extracted from the firmware image - without ever touching the hardware. For a security camera streaming video of people‚Äôs homes, this is‚Ä¶ not ideal.&lt;/p&gt;
    &lt;p&gt;I kept loading the other interesting binaries and exploring them in Ghidra using AI to quickly get a sense of the main features and possible entry points for an attacker.&lt;/p&gt;
    &lt;p&gt;Asking AI to explain a function and its relation to the other functions proved to be very useful for instance to understand encryption / obfuscation routines and network protocol handlers. This allows you to go from here:&lt;/p&gt;
    &lt;p&gt;To a higher level understanding that the AI can provide:&lt;/p&gt;
    &lt;p&gt;Another technique I found particularly effective is asking the AI to analyze a given function of interest and rename its variables and parameters to something meaningful based on context. Then do the same for the functions it calls, recursively following the branches you‚Äôre interested in. After a few iterations, what started as &lt;code&gt;FUN_0042eb7c(undefined2 *param_1, undefined4 param_2, int param_3)&lt;/code&gt; becomes &lt;code&gt;handleConnectAp(connection *conn, int flags, json *params)&lt;/code&gt; - and suddenly the decompiled code reads almost like the original source. &lt;/p&gt;
    &lt;p&gt;This iterative refinement approach, which I find a great example of human-AI collaboration where neither alone would be as efficient, is how I mapped most of the HTTP handlers, discovery protocol, and so on. What follows is the bottom line of my findings. For more details on the process, refer to the original Discord thread.&lt;/p&gt;
    &lt;p&gt;As a side note, I did not investigate (much) the exploitability of the following bugs to achieve code execution, mostly because I‚Äôm not familiar with MIPS, and it was not my intent. You can however do it relatively easily once obtained a shell via physical access, due to the presence of the &lt;code&gt;/bin/gdbserver&lt;/code&gt; binary in the firmware.&lt;/p&gt;
    &lt;head rend="h2"&gt;Bug 1: Pre-Auth ONVIF SOAP XML Parser Memory Overflow (CVE-2025-8065)&lt;/head&gt;
    &lt;p&gt;The Tapo C200 exposes an ONVIF service via the &lt;code&gt;/bin/main&lt;/code&gt; server listening on port 2020 for interoperability with standard video management systems. The problem is in how it parses SOAP XML requests.&lt;/p&gt;
    &lt;p&gt;When processing XML elements, the parser (&lt;code&gt;soap_parse_and_validate_request&lt;/code&gt; at &lt;code&gt;0x0045ae8c&lt;/code&gt;) calls &lt;code&gt;ds_parse&lt;/code&gt; without any bounds checking on the number of elements or total memory allocation. Send it enough XML elements, and you‚Äôll overflow allocated memory.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs the PoC:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1&lt;/quote&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;#!/usr/bin/env python3&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Send this, and the camera crashes, requiring a power cycle to recover.&lt;/p&gt;
    &lt;quote&gt;‚Äî Simone Margaritelli (@evilsocket) July 19, 2025&lt;/quote&gt;
    &lt;p&gt;CVE-2025-8065 has been assigned to this bug.&lt;/p&gt;
    &lt;p&gt;CVSS v4.0 Score: 7.1 / High&lt;lb/&gt;CVSS:4.0/AV:A/AC:L/AT:N/PR:N/UI:N/VC:N/VI:N/VA:H/SC:N/SI:N/SA:N&lt;/p&gt;
    &lt;head rend="h2"&gt;Bug 2: Pre-Auth HTTPS Content-Length Integer Overflow (CVE-2025-14299)&lt;/head&gt;
    &lt;p&gt;The HTTPS server routine running on port 443 has a classic integer overflow in its &lt;code&gt;Content-Length&lt;/code&gt; header parsing. The vulnerable function at &lt;code&gt;0x004bd054&lt;/code&gt; does this:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1&lt;/quote&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;iVar1 = atoi(value);&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;That‚Äôs it. No bounds checking. No validation. Just raw &lt;code&gt;atoi()&lt;/code&gt; on user input.&lt;/p&gt;
    &lt;p&gt;On a 32-bit system, &lt;code&gt;atoi("4294967295")&lt;/code&gt; causes integer overflow, resulting in undefined behavior. In this case, the camera crashes:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1&lt;/quote&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;#!/usr/bin/env python3&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;quote&gt;&lt;p&gt;And two pic.twitter.com/tt7eL7MA27&lt;/p&gt;‚Äî Simone Margaritelli (@evilsocket) July 19, 2025&lt;/quote&gt;
    &lt;p&gt;Another crash üí™ CVE-2025-14299 has been assigned to this bug.&lt;/p&gt;
    &lt;p&gt;CVSS v4.0 Score: 7.1 / High&lt;lb/&gt;CVSS:4.0/AV:A/AC:L/AT:N/PR:N/UI:N/VC:N/VI:N/VA:H/SC:N/SI:N/SA:N&lt;/p&gt;
    &lt;head rend="h2"&gt;Bug 3: Pre-Auth WiFi Hijacking (CVE-2025-14300)&lt;/head&gt;
    &lt;p&gt;The camera exposes an API endpoint called &lt;code&gt;connectAp&lt;/code&gt; that‚Äôs used during initial setup to configure WiFi. The problem? It‚Äôs accessible without any authentication. Even after the camera is fully set up and connected to your network.&lt;/p&gt;
    &lt;p&gt;The vulnerable handler at &lt;code&gt;0x0042eb7c&lt;/code&gt; processes the request without any auth checks:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1&lt;/quote&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;void connectApHandler(undefined2 *param_1,undefined4 param_2,int json_params)&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;quote&gt;&lt;p&gt;And three! üöÄ pic.twitter.com/2GZiG4bTm0&lt;/p&gt;‚Äî Simone Margaritelli (@evilsocket) July 22, 2025&lt;/quote&gt;
    &lt;p&gt;The exploit is trivial:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1&lt;/quote&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;#!/usr/bin/env python3&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;This allows a remote attacker to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Disconnect the camera from its legitimate network (DoS)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If in WiFi range proximity:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Force it to connect to an attacker-controlled network (MitM)&lt;/item&gt;
      &lt;item&gt;Intercept all video traffic once on the malicious network (not that we really needed this since the HTTPS private key is shared by all devices, as mentioned earlier XD)&lt;/item&gt;
      &lt;item&gt;Maintain persistent access even if the owner changes their WiFi password&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;CVE-2025-14300 has been assigned to this bug.&lt;/p&gt;
    &lt;p&gt;CVSS v4.0 Score: 8.7 / High&lt;lb/&gt;CVSS:4.0/AV:A/AC:L/AT:N/PR:N/UI:N/VC:H/VI:H/VA:H/SC:N/SI:N/SA:N&lt;/p&gt;
    &lt;head rend="h2"&gt;Bug 4: Pre-Auth Nearby WiFi Network Scanning&lt;/head&gt;
    &lt;p&gt;Related to Bug 3, the &lt;code&gt;scanApList&lt;/code&gt; method is also accessible without authentication - even when the device is not in onboarding mode. This endpoint returns a list of all WiFi networks visible to the camera:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1&lt;/quote&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;quote&gt;#!/usr/bin/env python3&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;A test on one of the devices exposed on the internet:&lt;/p&gt;
    &lt;p&gt;This is particularly concerning given the number of these devices exposed on the internet. An attacker can remotely enumerate WiFi networks in the camera‚Äôs vicinity, including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;SSIDs of nearby networks&lt;/item&gt;
      &lt;item&gt;BSSIDs (MAC addresses of access points)&lt;/item&gt;
      &lt;item&gt;Signal strength (useful for triangulation)&lt;/item&gt;
      &lt;item&gt;Security configurations&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here‚Äôs where it gets worse: tools like apple_bssid_locator can query Apple‚Äôs location services API with a BSSID and return precise GPS coordinates.&lt;/p&gt;
    &lt;p&gt;This means an attacker can:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Find an exposed Tapo camera via services like ZoomEye, Shodan or similar indexes&lt;/item&gt;
      &lt;item&gt;Use &lt;code&gt;scanApList&lt;/code&gt;to retrieve nearby WiFi BSSIDs&lt;/item&gt;
      &lt;item&gt;Query Apple‚Äôs location database with those BSSIDs&lt;/item&gt;
      &lt;item&gt;Pinpoint the camera‚Äôs physical location to within a few meters&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Remote attackers can not only see what WiFi networks exist around a camera - they can determine exactly where that camera (and by extension, the home or business it‚Äôs monitoring) is located on a map.&lt;/p&gt;
    &lt;head rend="h2"&gt;Disclosure&lt;/head&gt;
    &lt;p&gt;I‚Äôve decided to follow the industry standard 90+30 days responsible disclosure process; here‚Äôs the timeline:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;July 22, 2025: Sent initial report to TP-Link‚Äôs security team (security@tp-link.com) with full technical details, PoC exploits and videos. All compiled according to their guidelines.&lt;/item&gt;
      &lt;item&gt;July 22, 2025: Acknowledgment received.&lt;/item&gt;
      &lt;item&gt;August 22, 2025: TP-Link confirms they‚Äôre still reviewing the report&lt;/item&gt;
      &lt;item&gt;September 27, 2025: TP-Link responds and sets the timeline for the remediation patch to the end of November 2025.&lt;/item&gt;
      &lt;item&gt;November 2025: Nothing happens.&lt;/item&gt;
      &lt;item&gt;December 1, 2025: Sent follow up email, no response.&lt;/item&gt;
      &lt;item&gt;December 4, 2025: Sent another follow up email, which TP-Link responds to, further postponing the patch to the following week.&lt;/item&gt;
      &lt;item&gt;The following week: Nothing happens.&lt;/item&gt;
      &lt;item&gt;December 19, 2025: Public disclosure after 150 days.&lt;/item&gt;
      &lt;item&gt;December 20, 2025: TP-Link finally publishes a security advisory for CVE-2025-8065, CVE-2025-14299 and CVE-2025-14300.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The 90+30 period has long passed, so I decided to publish this writeup.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conflict Of Interest&lt;/head&gt;
    &lt;p&gt;As of April 25, TP-Link is a CVE Numbering Authority (CNA). This means they have the authority to assign CVE identifiers for vulnerabilities in their own products - at least for the ones reported directly to them. And they actively encourage responsible disclosure directly to their security team, which means they control a considerable pipeline of vulnerability reports.&lt;/p&gt;
    &lt;p&gt;On their Security Commitment page, TP-Link prominently displays charts comparing their CVE count to competitors. They explicitly market themselves as having fewer CVEs than Cisco, Netgear, and D-Link. They state they ‚Äúaim to patch vulnerabilities within 90 days.‚Äù&lt;/p&gt;
    &lt;p&gt;There‚Äôs an obvious and structural conflict of interest when a vendor is allowed to be their own CNA while simultaneously using their CVE count as a marketing metric.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46329038</guid><pubDate>Fri, 19 Dec 2025 18:19:32 +0000</pubDate></item><item><title>LLM Year in Review</title><link>https://karpathy.bearblog.dev/year-in-review-2025/</link><description>&lt;doc fingerprint="7e43c31528a49999"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;2025 LLM Year in Review&lt;/head&gt;
    &lt;p&gt;2025 has been a strong and eventful year of progress in LLMs. The following is a list of personally notable and mildly surprising "paradigm changes" - things that altered the landscape and stood out to me conceptually.&lt;/p&gt;
    &lt;head rend="h3"&gt;1. Reinforcement Learning from Verifiable Rewards (RLVR)&lt;/head&gt;
    &lt;p&gt;At the start of 2025, the LLM production stack in all labs looked something like this:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Pretraining (GPT-2/3 of ~2020)&lt;/item&gt;
      &lt;item&gt;Supervised Finetuning (InstructGPT ~2022) and&lt;/item&gt;
      &lt;item&gt;Reinforcement Learning from Human Feedback (RLHF ~2022)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This was the stable and proven recipe for training a production-grade LLM for a while. In 2025, Reinforcement Learning from Verifiable Rewards (RLVR) emerged as the de facto new major stage to add to this mix. By training LLMs against automatically verifiable rewards across a number of environments (e.g. think math/code puzzles), the LLMs spontaneously develop strategies that look like "reasoning" to humans - they learn to break down problem solving into intermediate calculations and they learn a number of problem solving strategies for going back and forth to figure things out (see DeepSeek R1 paper for examples). These strategies would have been very difficult to achieve in the previous paradigms because it's not clear what the optimal reasoning traces and recoveries look like for the LLM - it has to find what works for it, via the optimization against rewards.&lt;/p&gt;
    &lt;p&gt;Unlike the SFT and RLHF stage, which are both relatively thin/short stages (minor finetunes computationally), RLVR involves training against objective (non-gameable) reward functions which allows for a lot longer optimization. Running RLVR turned out to offer high capability/$, which gobbled up the compute that was originally intended for pretraining. Therefore, most of the capability progress of 2025 was defined by the LLM labs chewing through the overhang of this new stage and overall we saw ~similar sized LLMs but a lot longer RL runs. Also unique to this new stage, we got a whole new knob (and and associated scaling law) to control capability as a function of test time compute by generating longer reasoning traces and increasing "thinking time". OpenAI o1 (late 2024) was the very first demonstration of an RLVR model, but the o3 release (early 2025) was the obvious point of inflection where you could intuitively feel the difference.&lt;/p&gt;
    &lt;head rend="h3"&gt;2. Ghosts vs. Animals / Jagged Intelligence&lt;/head&gt;
    &lt;p&gt;2025 is where I (and I think the rest of the industry also) first started to internalize the "shape" of LLM intelligence in a more intuitive sense. We're not "evolving/growing animals", we are "summoning ghosts". Everything about the LLM stack is different (neural architecture, training data, training algorithms, and especially optimization pressure) so it should be no surprise that we are getting very different entities in the intelligence space, which are inappropriate to think about through an animal lens. Supervision bits-wise, human neural nets are optimized for survival of a tribe in the jungle but LLM neural nets are optimized for imitating humanity's text, collecting rewards in math puzzles, and getting that upvote from a human on the LM Arena. As verifiable domains allow for RLVR, LLMs "spike" in capability in the vicinity of these domains and overall display amusingly jagged performance characteristics - they are at the same time a genius polymath and a confused and cognitively challenged grade schooler, seconds away from getting tricked by a jailbreak to exfiltrate your data.&lt;/p&gt;
    &lt;p&gt;(human intelligence: blue, AI intelligence: red. I like this version of the meme (I'm sorry I lost the reference to its original post on X) for pointing out that human intelligence is also jagged in its own different way.)&lt;/p&gt;
    &lt;p&gt;Related to all this is my general apathy and loss of trust in benchmarks in 2025. The core issue is that benchmarks are almost by construction verifiable environments and are therefore immediately susceptible to RLVR and weaker forms of it via synthetic data generation. In the typical benchmaxxing process, teams in LLM labs inevitably construct environments adjacent to little pockets of the embedding space occupied by benchmarks and grow jaggies to cover them. Training on the test set is a new art form.&lt;/p&gt;
    &lt;p&gt;What does it look like to crush all the benchmarks but still not get AGI?&lt;/p&gt;
    &lt;p&gt;I have written a lot more on the topic of this section here:&lt;/p&gt;
    &lt;head rend="h3"&gt;3. Cursor / new layer of LLM apps&lt;/head&gt;
    &lt;p&gt;What I find most notable about Cursor (other than its meteoric rise this year) is that it convincingly revealed a new layer of an "LLM app" - people started to talk about "Cursor for X". As I highlighted in my Y Combinator talk this year (transcript and video), LLM apps like Cursor bundle and orchestrate LLM calls for specific verticals:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;They do the "context engineering"&lt;/item&gt;
      &lt;item&gt;They orchestrate multiple LLM calls under the hood strung into increasingly more complex DAGs, carefully balancing performance and cost tradeoffs.&lt;/item&gt;
      &lt;item&gt;They provide an application-specific GUI for the human in the loop&lt;/item&gt;
      &lt;item&gt;They offer an "autonomy slider"&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A lot of chatter has been spent in 2025 on how "thick" this new app layer is. Will the LLM labs capture all applications or are there green pastures for LLM apps? Personally I suspect that LLM labs will trend to graduate the generally capable college student, but LLM apps will organize, finetune and actually animate teams of them into deployed professionals in specific verticals by supplying private data, sensors and actuators and feedback loops.&lt;/p&gt;
    &lt;head rend="h3"&gt;4. Claude Code / AI that lives on your computer&lt;/head&gt;
    &lt;p&gt;Claude Code (CC) emerged as the first convincing demonstration of what an LLM Agent looks like - something that in a loopy way strings together tool use and reasoning for extended problem solving. In addition, CC is notable to me in that it runs on your computer and with your private environment, data and context. I think OpenAI got this wrong because they focused their early codex / agent efforts on cloud deployments in containers orchestrated from ChatGPT instead of simply &lt;code&gt;localhost&lt;/code&gt;. And while agent swarms running in the cloud feels like the "AGI endgame", we live in an intermediate and slow enough takeoff world of jagged capabilities that it makes more sense to run the agents directly on the developer's computer. Note that the primary distinction that matters is not about where the "AI ops" happen to run (in the cloud, locally or whatever), but about everything else - the already-existing and booted up computer, its installation, context, data, secrets, configuration, and the low-latency interaction. Anthropic got this order of precedence correct and packaged CC into a delightful, minimal CLI form factor that changed what AI looks like - it's not just a website you go to like Google, it's a little spirit/ghost that "lives" on your computer. This is a new, distinct paradigm of interaction with an AI.&lt;/p&gt;
    &lt;head rend="h3"&gt;5. Vibe coding&lt;/head&gt;
    &lt;p&gt;2025 is the year that AI crossed a capability threshold necessary to build all kinds of impressive programs simply via English, forgetting that the code even exists. Amusingly, I coined the term "vibe coding" in this shower of thoughts tweet totally oblivious to how far it would go :). With vibe coding, programming is not strictly reserved for highly trained professionals, it is something anyone can do. In this capacity, it is yet another example of what I wrote about in Power to the people: How LLMs flip the script on technology diffusion, on how (in sharp contrast to all other technology so far) regular people benefit a lot more from LLMs compared to professionals, corporations and governments. But not only does vibe coding empower regular people to approach programming, it empowers trained professionals to write a lot more (vibe coded) software that would otherwise never be written. In nanochat, I vibe coded my own custom highly efficient BPE tokenizer in Rust instead of having to adopt existing libraries or learn Rust at that level. I vibe coded many projects this year as quick app demos of something I wanted to exist (e.g. see menugen, llm-council, reader3, HN time capsule). And I've vibe coded entire ephemeral apps just to find a single bug because why not - code is suddenly free, ephemeral, malleable, discardable after single use. Vibe coding will terraform software and alter job descriptions.&lt;/p&gt;
    &lt;head rend="h3"&gt;6. Nano banana / LLM GUI&lt;/head&gt;
    &lt;p&gt;Google Gemini Nano banana is one of the most incredible, paradigm-shifting models of 2025. In my world view, LLMs are the next major computing paradigm similar to computers of the 1970s, 80s, etc. Therefore, we are going to see similar kinds of innovations for fundamentally similar kinds of reasons. We're going to see equivalents of personal computing, of microcontrollers (cognitive core), or internet (of agents), etc etc. In particular, in terms of the UIUX, "chatting" with LLMs is a bit like issuing commands to a computer console in the 1980s. Text is the raw/favored data representation for computers (and LLMs), but it is not the favored format for people, especially at the input. People actually dislike reading text - it is slow and effortful. Instead, people love to consume information visually and spatially and this is why the GUI has been invented in traditional computing. In the same way, LLMs should speak to us in our favored format - in images, infographics, slides, whiteboards, animations/videos, web apps, etc. The early and present version of this of course are things like emoji and Markdown, which are ways to "dress up" and lay out text visually for easier consumption with titles, bold, italics, lists, tables, etc. But who is actually going to build the LLM GUI? In this world view, nano banana is a first early hint of what that might look like. And importantly, one notable aspect of it is that it's not just about the image generation itself, it's about the joint capability coming from text generation, image generation and world knowledge, all tangled up in the model weights.&lt;/p&gt;
    &lt;p&gt;TLDR. 2025 was an exciting and mildly surprising year of LLMs. LLMs are emerging as a new kind of intelligence, simultaneously a lot smarter than I expected and a lot dumber than I expected. In any case they are extremely useful and I don't think the industry has realized anywhere near 10% of their potential even at present capability. Meanwhile, there are so many ideas to try and conceptually the field feels wide open. And as I mentioned on my Dwarkesh pod earlier this year, I simultaneously (and on the surface paradoxically) believe that we will both see rapid and continued progress and that yet there is a lot of work to be done. Strap in.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46330726</guid><pubDate>Fri, 19 Dec 2025 20:49:20 +0000</pubDate></item><item><title>CSS Grid Lanes</title><link>https://webkit.org/blog/17660/introducing-css-grid-lanes/</link><description>&lt;doc fingerprint="de98d3333fec29eb"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing CSS Grid Lanes&lt;/head&gt;
    &lt;p&gt;It‚Äôs here, the future of masonry layouts on the web! After the groundwork laid by Mozilla, years of effort by Apple‚Äôs WebKit team, and many rounds debate at the CSS Working Group with all the browsers, it‚Äôs now clear how it works.&lt;/p&gt;
    &lt;p&gt;Introducing CSS Grid Lanes.&lt;/p&gt;
    &lt;code&gt;.container {
  display: grid-lanes;
  grid-template-columns: repeat(auto-fill, minmax(250px, 1fr));
  gap: 16px;
}
&lt;/code&gt;
    &lt;p&gt;Try it today in Safari Technology Preview 234.&lt;/p&gt;
    &lt;head rend="h2"&gt;How Grid Lanes work&lt;/head&gt;
    &lt;p&gt;Let‚Äôs break down exactly how to create this classic layout.&lt;/p&gt;
    &lt;p&gt;First, the HTML.&lt;/p&gt;
    &lt;code&gt;&amp;lt;main class="container"&amp;gt;
  &amp;lt;figure&amp;gt;&amp;lt;img src="photo-1.jpg"&amp;gt;&amp;lt;/figure&amp;gt;
  &amp;lt;figure&amp;gt;&amp;lt;img src="photo-2.jpg"&amp;gt;&amp;lt;/figure&amp;gt;
  &amp;lt;figure&amp;gt;&amp;lt;img src="photo-3.jpg"&amp;gt;&amp;lt;/figure&amp;gt;
  &amp;lt;!-- etc --&amp;gt;
&amp;lt;/main&amp;gt;
&lt;/code&gt;
    &lt;p&gt;Let‚Äôs start by applying &lt;code&gt;display: grid-lanes&lt;/code&gt; to the &lt;code&gt;main&lt;/code&gt; element to create a Grid container ready to make this kind of layout. Then we use &lt;code&gt;grid-template-columns&lt;/code&gt; to create the ‚Äúlanes‚Äù with the full power of CSS Grid.&lt;/p&gt;
    &lt;p&gt;In this case, we‚Äôll use &lt;code&gt;repeat(auto-fill, minmax(250px, 1fr))&lt;/code&gt; to create flexible columns at least 250 pixels wide. The browser will decide how many columns to make, filling all available space.&lt;/p&gt;
    &lt;p&gt;And then, &lt;code&gt;gap: 16px&lt;/code&gt; gives us 16 pixel gaps between the lanes, and 16 pixel gaps between items within the lanes.&lt;/p&gt;
    &lt;code&gt;.container {
  display: grid-lanes;
  grid-template-columns: repeat(auto-fill, minmax(250px, 1fr));
  gap: 16px;
}
&lt;/code&gt;
    &lt;p&gt;That‚Äôs it! In three lines of CSS, with zero media queries or container queries, we created a flexible layout that works on all screen sizes.&lt;/p&gt;
    &lt;p&gt;Think of it like a highway of cars in bumper-to-bumper traffic.&lt;/p&gt;
    &lt;p&gt;Just like the classic Masonry library, as the browser decides where to put each item, the next one is placed in whichever column gets it closest to the top of the window. Like traffic, each car ‚Äúchanges lanes‚Äù to end up in the lane that gets them ‚Äúthe furthest ahead‚Äù.&lt;/p&gt;
    &lt;p&gt;This layout makes it possible for users to tab across the lanes to all currently-visible content, (not down the first column below the fold to the very bottom, and then back to the top of the second column). It also makes it possible for you to build a site that keeps loading more content as the user scrolls, infinitely, without needing JavaScript to handle the layout.&lt;/p&gt;
    &lt;head rend="h2"&gt;The power of Grid&lt;/head&gt;
    &lt;head rend="h3"&gt;Varying lane sizes&lt;/head&gt;
    &lt;p&gt;Because Grid Lanes uses the full power of CSS Grid to define lanes using &lt;code&gt;grid-template-*&lt;/code&gt;, it‚Äôs easy to create creative design variations.&lt;/p&gt;
    &lt;p&gt;For example, we can create a flexible layout with alternating narrow and wide columns ‚Äî where both the first and last columns are always narrow, even as the number of columns changes with the viewport size. This is accomplished with &lt;code&gt;grid-template-columns: repeat(auto-fill, minmax(8rem, 1fr) minmax(16rem, 2fr)) minmax(8rem, 1fr)&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;There‚Äôs a whole world of possibilities using &lt;code&gt;grid-template-*&lt;/code&gt; syntax.&lt;/p&gt;
    &lt;head rend="h4"&gt;Spanning items&lt;/head&gt;
    &lt;p&gt;Since we have the full power of Grid layout, we can also span lanes, of course.&lt;/p&gt;
    &lt;code&gt;main {
  display: grid-lanes;
  grid-template-columns: repeat(auto-fill, minmax(20ch, 1fr));
  gap: 2lh;
}
article { 
  grid-column: span 1; 
}
@media (1250px &amp;lt; width) {
  article:nth-child(1) { 
    grid-column: span 4;             
  }
  article:nth-child(2), article:nth-child(3), article:nth-child(4), article:nth-child(5), article:nth-child(6), article:nth-child(7), article:nth-child(8) { 
    grid-column: span 2; 
  }
}
&lt;/code&gt;
    &lt;p&gt;All the article teasers are first set to span 1 column. Then the 1st item is specifically told to span 4 columns, while the 2nd ‚Äì 8th to span 2 columns. This creates a far more dynamic graphic design than the typical symmetrical, everything the same-width, everything the same-height layout that‚Äôs dominated over the last decade.&lt;/p&gt;
    &lt;head rend="h3"&gt;Placing items&lt;/head&gt;
    &lt;p&gt;We can also explicitly place items while using Grid Lanes. Here, the header is always placed in the last column, no matter how many columns exist.&lt;/p&gt;
    &lt;code&gt;main {
  display: grid-lanes;
  grid-template-columns: repeat(auto-fill, minmax(24ch, 1fr));
}
header {
  grid-column: -3 / -1;
}
&lt;/code&gt;
    &lt;head rend="h2"&gt;Changing directions&lt;/head&gt;
    &lt;p&gt;Yes, lanes can go either direction! All of the examples above happen to create a ‚Äúwaterfall‚Äù shape, where the content is laid out in columns. But Grid Lanes can be used to create a layout in the other direction, in a ‚Äúbrick‚Äù layout shape.&lt;/p&gt;
    &lt;p&gt;The browser automatically creates a waterfall layout when you define columns with &lt;code&gt;grid-template-columns&lt;/code&gt;, like this:&lt;/p&gt;
    &lt;code&gt;.container {
  display: grid-lanes;
  grid-template-columns: 1fr 1fr 1fr 1fr;
}
&lt;/code&gt;
    &lt;p&gt;If you want a brick layout in the other direction, instead define the rows with &lt;code&gt;grid-template-rows&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;.container {
  display: grid-lanes;
  grid-template-rows: 1fr 1fr 1fr;
}
&lt;/code&gt;
    &lt;p&gt;This works automatically thanks to a new default for&lt;code&gt;grid-auto-flow&lt;/code&gt;, the &lt;code&gt;normal&lt;/code&gt; value.  It figures out whether to create columns or rows based on whether you defined the lanes using &lt;code&gt;grid-template-columns&lt;/code&gt; or &lt;code&gt;grid-template-rows&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The CSS Working Group is still discussing which property will explicitly control the flow orientation, and what its syntax will be. The debate is over whether to reuse &lt;code&gt;grid-auto-flow&lt;/code&gt; or create new properties like &lt;code&gt;grid-lanes-direction&lt;/code&gt;. If you‚Äôre interested in reading about the options being considered or chime in with your thoughts, see this discussion.&lt;/p&gt;
    &lt;p&gt;However, since &lt;code&gt;normal&lt;/code&gt; will be the initial value either way, you don‚Äôt have to wait for this decision to learn Grid Lanes. When you define only one direction ‚Äî &lt;code&gt;grid-template-rows&lt;/code&gt; or &lt;code&gt;grid-template-columns&lt;/code&gt; ‚Äî it will Just Work‚Ñ¢. (If it doesn‚Äôt, check if &lt;code&gt;grid-auto-flow&lt;/code&gt; is set to a conflicting value. You can&lt;code&gt;unset&lt;/code&gt; it if needed.)&lt;/p&gt;
    &lt;head rend="h2"&gt;Placement sensitivity&lt;/head&gt;
    &lt;p&gt;‚ÄúTolerance‚Äù is a new concept created for Grid Lanes. It lets you adjust just how picky the layout algorithm is when deciding where to place items.&lt;/p&gt;
    &lt;p&gt;Look at the next drawing. Notice that Car 4 is a tiny bit shorter than Car 1. When the ‚Äútolerance‚Äù is zero, Car 6 ends up in the right-most lane, while Car 7 is on the left. Car 6 ends up behind Car 4 on the right because that gets it a tiny bit closer ‚Äúdown the road‚Äù (closer to the top of the Grid container). Car 7 then takes the next-closest-to-the-top slot, and ends up behind Car 1 on the left. The end result? The first horizontal grouping of content is ordered 1, 2, 3, 4, and the next is 7, 5, 6.&lt;/p&gt;
    &lt;p&gt;But the difference in length between Car 1 and Car 4 is tiny. Car 6 isn‚Äôt meaningfully closer to the top of the page. And having item 6 on the right, with item 7 on the left is likely an unexpected experience ‚Äî especially for users who are tabbing through content, or when the content order is somehow labeled.&lt;/p&gt;
    &lt;p&gt;These tiny differences in size don‚Äôt matter in any practical sense. Instead, the browser should consider item sizes like Car 1 and Car 4 to be a tie. That‚Äôs why the default for &lt;code&gt;item-tolerance&lt;/code&gt; is &lt;code&gt;1em&lt;/code&gt; ‚Äî which means only differences in content length greater than 1 em will matter when figuring out where the next item goes.&lt;/p&gt;
    &lt;p&gt;If you‚Äôd like the layout of items to shuffle around less, you can set a higher value for &lt;code&gt;item-tolerance&lt;/code&gt;. In the next digram, the tolerance is set to half-a-car, causing the cars to lay out basically from left to right and only moving to another lane to avoid the extra-long limo. Now, the horizontal groupings of content are 1, 2, 3, 4, and 5, 6, 7.&lt;/p&gt;
    &lt;p&gt;Think of tolerance as how chill you want the car drivers to be. Will they change lanes to get just a few inches ahead? Or will they only move if there‚Äôs a lot of space in the other lane? The amount of space you want them to care about is the amount you set in &lt;code&gt;item-tolerance&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Remember that people tabbing through the page will see each item highlighted as it comes into focus, and may be experiencing the page through a screenreader. An item tolerance that‚Äôs set too high can create an awkward experience jumping up and down the layout. An item tolerance that‚Äôs too low can result in jumping back and forth across the layout more than necessary. Adjust &lt;code&gt;item-tolerance&lt;/code&gt; to something appropriate for the sizes and size variations of your content.&lt;/p&gt;
    &lt;p&gt;Currently, this property is named &lt;code&gt;item-tolerance&lt;/code&gt; in the specification and in Safari Technology Preview 234. However, there is still a chance this name will change, perhaps to something like &lt;code&gt;flow-tolerance&lt;/code&gt; or &lt;code&gt;pack-tolerance&lt;/code&gt;. If you have a preference, or ideas for a better name, you can chime in here. Keep an eye out for updates about the final name before using this property on production websites.&lt;/p&gt;
    &lt;head rend="h2"&gt;Try it out&lt;/head&gt;
    &lt;p&gt;Try out Grid Lanes in Safari Technology Preview 234! All of the demos at webkit.org/demos/grid3 have been updated with the new syntax, including other use cases for Grid Lanes. It‚Äôs not just for images! For example, a mega menu footer full of links suddenly becomes easy to layout.&lt;/p&gt;
    &lt;code&gt;.container {
  display: grid-lanes;
  grid-template-columns: repeat(auto-fill, minmax(max-content, 24ch));
  column-gap: 4lh;
}
&lt;/code&gt;
    &lt;head rend="h2"&gt;What‚Äôs next?&lt;/head&gt;
    &lt;p&gt;There are a few last decisions for the CSS Working Group to make. But overall, the feature as described in this article is ready to go. It‚Äôs time to try it out. And it‚Äôs finally safe to commit the basic syntax to memory!&lt;/p&gt;
    &lt;p&gt;We‚Äôd love for you to make some demos! Demonstrate what new use cases you can imagine. And let us know about any bugs or possible improvements you discover. Ping Jen Simmons on Bluesky or Mastodon with links, comments and ideas.&lt;/p&gt;
    &lt;p&gt;Our team has been working on this since mid-2022, implementing in WebKit and writing the web standard. We can‚Äôt wait to see what you will do with it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46331586</guid><pubDate>Fri, 19 Dec 2025 22:13:06 +0000</pubDate></item><item><title>The Deviancy Signal: Having "Nothing to Hide" Is a Threat to Us All</title><link>https://thompson2026.com/blog/deviancy-signal/</link><description>&lt;doc fingerprint="f608755c3ee5456b"&gt;
  &lt;main&gt;
    &lt;p&gt;There's a special kind of contempt I reserve for the person who says, "I have nothing to hide." It's not the gentle pity you'd have for the naive. It's the cold, hard anger you hold for a collaborator. Because these people aren't just surrendering their own liberty. They're instead actively forging the chains for the rest of us. They are a threat, and I think it's time they were told so.&lt;/p&gt;
    &lt;p&gt;Their argument is a "pathology of the present tense," a failure of imagination so profound it borders on a moral crime. What they fail to understand is that by living as an open book, they are creating the most dangerous weapon imaginable: a baseline of "normalcy." They are steadily creating a data profile for the State's machine, teaching its algorithms what a "good, transparent citizen" looks like. Every unencrypted text, every thoughtless search, every location-tagged post is another brick in the wall of their own cage.&lt;/p&gt;
    &lt;p&gt;And then comes the part they can't (or won't) fathom. The context shifts. The political winds change. The Overton window slams shut on a belief they once held. A book they read is declared subversive. A group they donated to is re-classified as extremist. A joke they told is now evidence of a thoughtcrime. Suddenly, for the first time, they have something to hide.&lt;/p&gt;
    &lt;p&gt;So they reach for the tools of privacy. They download the encrypted messenger. They fire up the VPN. They start to cover their tracks.&lt;/p&gt;
    &lt;p&gt;And in that single act, they trigger the Deviancy Signal.&lt;/p&gt;
    &lt;p&gt;Their first attempt at privacy, set against their own self-created history of total transparency, is a screaming alarm to the grown surveillance machine. It's the poker player with a perfect tell, or the nocturnal animal suddenly walking in daylight. Their very attempt to become private is the most public and suspicious act they could possibly commit. They have not built an effective shield, as they have painted a target on their own back. By the time they need privacy, their own history has made seeking it an admission of guilt.&lt;/p&gt;
    &lt;p&gt;But the damage doesn't end with your own self-incrimination. It radiates outward, undoing the careful work of everyone around you. Think of your friend who has practiced perfect operational security, who has spent years building a private life to ensure they have no baseline for the state to analyze. They are a ghost in the machine. Then they talk to you. Your unshielded phone becomes the listening device they never consented to. You take their disciplined effort to stay invisible and you shout it into a government microphone, tying their identity to yours in a permanent, searchable log. You don't just contrast with their diligence; you actively dismantle it.&lt;/p&gt;
    &lt;p&gt;On a societal scale, this inaction becomes a collective betrayal. The power of the Deviancy Signal is directly proportional to the number of people who live transparently. Every person who refuses to practice privacy adds another gallon of clean, clear water to the state's pool, making any ripple of dissent ... any deviation ... starkly visible. This is not a passive choice. By refusing to help create a chaotic, noisy baseline of universal privacy, you are actively making the system more effective. You are failing to do your part to make the baseline all deviant, and in doing so, you make us all more vulnerable.&lt;/p&gt;
    &lt;p&gt;There is only one way to disarm this weapon: we must destroy its premise. We must obliterate the baseline. The task is not merely to hide, but to make privacy the default, to make encryption a reflex, to make anonymity a universal right. We must create so much noise that a signal is impossible to find. Our collective goal must be to make a "normal" profile so rare that the watchers have nothing to compare us to. We must all become deviations.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46333830</guid><pubDate>Sat, 20 Dec 2025 05:24:21 +0000</pubDate></item><item><title>Charles Proxy</title><link>https://www.charlesproxy.com/</link><description>&lt;doc fingerprint="bd3f5e502db4d594"&gt;
  &lt;main&gt;
    &lt;p&gt;Charles is an HTTP proxy / HTTP monitor / Reverse Proxy that enables a developer to view all of the HTTP and SSL / HTTPS traffic between their machine and the Internet. This includes requests, responses and the HTTP headers (which contain the cookies and caching information).&lt;/p&gt;
    &lt;head rend="h3"&gt;Recent Developments&lt;/head&gt;
    &lt;p&gt;For discussion on the latest changes to Charles, please see Karl‚Äôs blog.&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;20 Sep 2025&lt;/item&gt;
      &lt;item rend="dd-1"&gt;
        &lt;p&gt;Charles 5.0.3 released fixing a performance issue on macOS and minor improvements. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-2"&gt;9 Aug 2025&lt;/item&gt;
      &lt;item rend="dd-2"&gt;
        &lt;p&gt;Charles 5.0.2 released including bug fixes and minor improvements. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-3"&gt;12 Mar 2025&lt;/item&gt;
      &lt;item rend="dd-3"&gt;
        &lt;p&gt;Charles 5 released! Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-4"&gt;24 Jan 2024&lt;/item&gt;
      &lt;item rend="dd-4"&gt;
        &lt;p&gt;Charles 5 public beta 13 is now available for testing, featuring more UI improvements particularly on Windows including dark mode support. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-5"&gt;7 Jul 2023&lt;/item&gt;
      &lt;item rend="dd-5"&gt;
        &lt;p&gt;Charles 5 public beta 11 is now available for testing, featuring more UI improvements, performance improvements, new features and bug fixes. Read more.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;11 Jun 2023&lt;/item&gt;
      &lt;item rend="dd-1"&gt;
        &lt;p&gt;Charles 5 public beta 9 is now available for testing, featuring more UI improvements and bug fixes. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-2"&gt;11 Apr 2023&lt;/item&gt;
      &lt;item rend="dd-2"&gt;
        &lt;p&gt;Charles 5 public beta is now available for testing, featuring major UI improvements and technology upgrades. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-3"&gt;4 Apr 2023&lt;/item&gt;
      &lt;item rend="dd-3"&gt;
        &lt;p&gt;Charles 4.6.4 released with macOS crash fixed and Windows code signing updated. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-4"&gt;26 Sep 2022&lt;/item&gt;
      &lt;item rend="dd-4"&gt;
        &lt;p&gt;Charles 4.6.3 released with minor bug fixes and Java 11 update Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-5"&gt;14 Dec 2021&lt;/item&gt;
      &lt;item rend="dd-5"&gt;
        &lt;p&gt;In light of the current log4j2 vulnerabilities, we confirm that no version of Charles shipped or used any version of log4j and Charles is therefore thankfully unaffected by this issue. Our best wishes to the log4j developers and everyone affected by this.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-6"&gt;6 Jul 2021&lt;/item&gt;
      &lt;item rend="dd-6"&gt;
        &lt;p&gt;Charles 4.6.2 released including bug fixes. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-7"&gt;15 Nov 2020&lt;/item&gt;
      &lt;item rend="dd-7"&gt;
        &lt;p&gt;Charles 4.6.1 released to fix Dark Mode support on macOS Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-8"&gt;7 Nov 2020&lt;/item&gt;
      &lt;item rend="dd-8"&gt;
        &lt;p&gt;Charles 4.6 released including new features and stability improvements. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-9"&gt;15 Jan 2020&lt;/item&gt;
      &lt;item rend="dd-9"&gt;
        &lt;p&gt;Charles 4.5.6 released with minor bug fixes and patched security vulnerability. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-10"&gt;5 Dec 2019&lt;/item&gt;
      &lt;item rend="dd-10"&gt;
        &lt;p&gt;Charles 4.5.5 released including bug fixes for SSL certificate imports. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-11"&gt;3 Nov 2019&lt;/item&gt;
      &lt;item rend="dd-11"&gt;
        &lt;p&gt;Charles 4.5.2 released including new features, bug fixes and improvements. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-12"&gt;28 Feb 2019&lt;/item&gt;
      &lt;item rend="dd-12"&gt;
        &lt;p&gt;Charles 4.2.8 released with minor bug fixes. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-13"&gt;14 Sep 2018&lt;/item&gt;
      &lt;item rend="dd-13"&gt;
        &lt;p&gt;Charles 4.2.7 released with minor bug fixes and improvements. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-14"&gt;5 May 2018&lt;/item&gt;
      &lt;item rend="dd-14"&gt;
        &lt;p&gt;Charles Security Bulletin for a local privilege escalation in Charles 4.2 and 3.12.1 and earlier. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-15"&gt;7 Apr 2018&lt;/item&gt;
      &lt;item rend="dd-15"&gt;
        &lt;p&gt;Charles 4.2.5 released with major bug fixes and minor improvements. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-16"&gt;28 Mar 2018&lt;/item&gt;
      &lt;item rend="dd-16"&gt;
        &lt;p&gt;Charles for iOS released. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-17"&gt;22 Nov 2017&lt;/item&gt;
      &lt;item rend="dd-17"&gt;
        &lt;p&gt;Charles 4.2.1 released with important bug fixes. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-18"&gt;30 Sep 2017&lt;/item&gt;
      &lt;item rend="dd-18"&gt;
        &lt;p&gt;Charles 4.2 released with major new TLS debugging capability, minor improvements and bug fixes including macOS High Sierra support. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-19"&gt;10 Jul 2017&lt;/item&gt;
      &lt;item rend="dd-19"&gt;
        &lt;p&gt;Charles 4.1.4 released with minor improvements and bug fixes. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-20"&gt;20 Jun 2017&lt;/item&gt;
      &lt;item rend="dd-20"&gt;
        &lt;p&gt;Charles 4.1.3 released including Brotli compression support and other minor bug fixes and improvements. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-21"&gt;13 May 2017&lt;/item&gt;
      &lt;item rend="dd-21"&gt;
        &lt;p&gt;Charles 4.1.2 released with bug fixes and minor improvements. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-22"&gt;21 Apr 2017&lt;/item&gt;
      &lt;item rend="dd-22"&gt;
        &lt;p&gt;Charles 4.1.1 released with bug fixes. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-23"&gt;10 Apr 2017&lt;/item&gt;
      &lt;item rend="dd-23"&gt;
        &lt;p&gt;Charles 4.1 released including major new features and bug fixes. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-24"&gt;19 Nov 2016&lt;/item&gt;
      &lt;item rend="dd-24"&gt;
        &lt;p&gt;Charles 4.0.2 released including bug fixes and minor improvements. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-25"&gt;20 Sep 2016&lt;/item&gt;
      &lt;item rend="dd-25"&gt;
        &lt;p&gt;Charles 4.0.1 released including bug fixes. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-26"&gt;16 Sep 2016&lt;/item&gt;
      &lt;item rend="dd-26"&gt;
        &lt;p&gt;Charles 3.11.6 released with support for macOS Sierra and minor bug fixes. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-27"&gt;1 Aug 2016&lt;/item&gt;
      &lt;item rend="dd-27"&gt;
        &lt;p&gt;Charles 4 released featuring HTTP 2, IPv6 and improved look and feel. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-28"&gt;29 May 2016&lt;/item&gt;
      &lt;item rend="dd-28"&gt;
        &lt;p&gt;Charles 3.11.5 released including minor bug fixes; especially fixes SSL certificate installation on Android. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-29"&gt;29 Feb 2016&lt;/item&gt;
      &lt;item rend="dd-29"&gt;
        &lt;p&gt;Charles 3.11.4 released with support for ATS on iOS 9 and crash fixes for older versions of Mac OS X. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-30"&gt;15 Feb 2016&lt;/item&gt;
      &lt;item rend="dd-30"&gt;
        &lt;p&gt;Charles v3.11.3 released including bug fixes and minor improvements. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-31"&gt;9 Nov 2015&lt;/item&gt;
      &lt;item rend="dd-31"&gt;
        &lt;p&gt;Charles v3.11.2 released with SSL and Websockets improvements. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-32"&gt;4 Oct 2015&lt;/item&gt;
      &lt;item rend="dd-32"&gt;
        &lt;p&gt;Charles 3.11 released including major new features. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-33"&gt;7 Jul 2015&lt;/item&gt;
      &lt;item rend="dd-33"&gt;
        &lt;p&gt;Charles 3.10.2 released with bug fixes and improvements. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-34"&gt;31 Mar 2015&lt;/item&gt;
      &lt;item rend="dd-34"&gt;
        &lt;p&gt;Charles 3.10.1 released with minor bug fixes. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-35"&gt;21 Mar 2015&lt;/item&gt;
      &lt;item rend="dd-35"&gt;
        &lt;p&gt;Charles 3.10 released with improved SSL (new SSL CA certificate install required), major new features and improvements. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-36"&gt;22 Oct 2014&lt;/item&gt;
      &lt;item rend="dd-36"&gt;
        &lt;p&gt;Charles v3.9.3 released with improvements to SSL support, Mac OS X Yosemite support and other minor bug fixes and improvements. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-37"&gt;26 May 2014&lt;/item&gt;
      &lt;item rend="dd-37"&gt;
        &lt;p&gt;Charles v3.9.2 released with minor bug fixes. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-38"&gt;5 May 2014&lt;/item&gt;
      &lt;item rend="dd-38"&gt;
        &lt;p&gt;Charles 3.9.1 released with minor bug fixes and improvements. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-39"&gt;25 Apr 2014&lt;/item&gt;
      &lt;item rend="dd-39"&gt;
        &lt;p&gt;Charles 3.9 released with major new features and bug fixes, including the ability to "focus" on hosts so they are separated from the noise. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-40"&gt;23 Oct 2013&lt;/item&gt;
      &lt;item rend="dd-40"&gt;
        &lt;p&gt;Charles 3.8.3 released with support for Mac OS X Mavericks and minor bug fixes. Happy Mavericks Day. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-41"&gt;21 Oct 2013&lt;/item&gt;
      &lt;item rend="dd-41"&gt;
        &lt;p&gt;Charles 3.8.2 released with minor bug fixes. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-42"&gt;9 Sep 2013&lt;/item&gt;
      &lt;item rend="dd-42"&gt;
        &lt;p&gt;Charles 3.8.1 released with minor bug fixes and improvements. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-43"&gt;4 Sep 2013&lt;/item&gt;
      &lt;item rend="dd-43"&gt;
        &lt;p&gt;Charles 3.8 has been released with new features and bug fixes. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-44"&gt;12 Feb 2013&lt;/item&gt;
      &lt;item rend="dd-44"&gt;
        &lt;p&gt;Charles 3.7 has been released. Includes new features, bundled Java runtime (so you don‚Äôt need to install Java anymore), and bug fixes. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-45"&gt;27 Jun 2012&lt;/item&gt;
      &lt;item rend="dd-45"&gt;
        &lt;p&gt;Charles 3.7 beta 2 has been released. This changes the SSL signing for Charles on Mac OS X to use Apple's new Developer ID code-signing. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-46"&gt;8 Dec 2011&lt;/item&gt;
      &lt;item rend="dd-46"&gt;
        &lt;p&gt;Charles v3.6.5 released including bug fixes and minor changes. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-47"&gt;15 Nov 2011&lt;/item&gt;
      &lt;item rend="dd-47"&gt;
        &lt;p&gt;Charles v3.6.4 released including major bug fixes and enhancements. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-48"&gt;5 Sep 2011&lt;/item&gt;
      &lt;item rend="dd-48"&gt;
        &lt;p&gt;Charles v3.6.3 released including minor bug fixes. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-49"&gt;24 Aug 2011&lt;/item&gt;
      &lt;item rend="dd-49"&gt;
        &lt;p&gt;Charles v3.6.1 released including minor enhancements and bug fixes. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-50"&gt;18 Aug 2011&lt;/item&gt;
      &lt;item rend="dd-50"&gt;
        &lt;p&gt;Charles v3.6 released including new features, enhancements and bug fixes. New features include HAR and SAZ file import. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-51"&gt;17 Aug 2010&lt;/item&gt;
      &lt;item rend="dd-51"&gt;
        &lt;p&gt;Charles v3.5.2 released including bug fixes and minor new features. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-52"&gt;1 Jan 2010&lt;/item&gt;
      &lt;item rend="dd-52"&gt;
        &lt;p&gt;Charles 3.5.1 released. Minor bug fixes. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-53"&gt;23 Dec 2009&lt;/item&gt;
      &lt;item rend="dd-53"&gt;
        &lt;p&gt;Charles 3.5 released. Major new features, bug fixes and enhancements.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-54"&gt;17 Oct 2009&lt;/item&gt;
      &lt;item rend="dd-54"&gt;
        &lt;p&gt;Charles 3.4.1 released. Minor features and bug fixes.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-55"&gt;27 Sep 2009&lt;/item&gt;
      &lt;item rend="dd-55"&gt;
        &lt;p&gt;Charles 3.4 released. Major changes especially to SSL.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-56"&gt;11 May 2009&lt;/item&gt;
      &lt;item rend="dd-56"&gt;
        &lt;p&gt;New website launched. Follow @charlesproxy on Twitter. Say hi in San Francisco when I'm there for WWDC!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-57"&gt;7 Mar 2009&lt;/item&gt;
      &lt;item rend="dd-57"&gt;
        &lt;p&gt;Charles 3.3.1 released. Minor new features and bug fixes. Experimental 64 bit Windows support. Read more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-58"&gt;15 Feb 2009&lt;/item&gt;
      &lt;item rend="dd-58"&gt;
        &lt;p&gt;Charles 3.3 released. Major new features. Download&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-59"&gt;24 Sep 2008&lt;/item&gt;
      &lt;item rend="dd-59"&gt;
        &lt;p&gt;Charles Autoconfiguration add-on for Mozilla Firefox adds support for Firefox 3.1&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-60"&gt;23 Sep 2008&lt;/item&gt;
      &lt;item rend="dd-60"&gt;
        &lt;p&gt;Charles 3.2.3 released. Minor new features and bug fixes.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-61"&gt;6 Sep 2008&lt;/item&gt;
      &lt;item rend="dd-61"&gt;
        &lt;p&gt;Charles 3.2.2 released. Minor new features and bug fixes.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-62"&gt;17 Apr 2008&lt;/item&gt;
      &lt;item rend="dd-62"&gt;
        &lt;p&gt;Charles 3.2.1 released. Minor new features and bug fixes.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-63"&gt;24 Mar 2008&lt;/item&gt;
      &lt;item rend="dd-63"&gt;
        &lt;p&gt;Charles 3.2 released. Major new features. Release Notes&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-64"&gt;28 Jan 2008&lt;/item&gt;
      &lt;item rend="dd-64"&gt;
        &lt;p&gt;Charles 3.2 public beta released. Download and more information on my blog.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-65"&gt;19 Dec 2007&lt;/item&gt;
      &lt;item rend="dd-65"&gt;
        &lt;p&gt;Charles 3.1.4 released. Bug fixes and minor new features.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-66"&gt;21 Nov 2007&lt;/item&gt;
      &lt;item rend="dd-66"&gt;
        &lt;p&gt;Charles Mozilla Firefox add-on updated for compatibility with Firefox 3.0.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-67"&gt;12 Nov 2007&lt;/item&gt;
      &lt;item rend="dd-67"&gt;
        &lt;p&gt;Charles 3.1.3 released. Minor bug fixes, minor new features.&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Chart tab now includes charts for sizes, durations and types&lt;/item&gt;
          &lt;item&gt;Request &amp;amp; Response can now be displayed combined on one split-panel&lt;/item&gt;
          &lt;item&gt;SSL handshake and certificate errors are now displayed in the tree&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item rend="dt-68"&gt;29 Aug 2007&lt;/item&gt;
      &lt;item rend="dd-68"&gt;
        &lt;p&gt;Charles 3.1.2 released. Minor bug fixes.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-69"&gt;27 Aug 2007&lt;/item&gt;
      &lt;item rend="dd-69"&gt;
        &lt;p&gt;Charles 3.1.1 released. Minor bug fixes.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-70"&gt;13 Aug 2007&lt;/item&gt;
      &lt;item rend="dd-70"&gt;
        &lt;p&gt;Charles 3.1 released.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-71"&gt;22 May 2007&lt;/item&gt;
      &lt;item rend="dd-71"&gt;
        &lt;p&gt;Charles 3.0.4 released. Fixes SSL bug on Java 1.4.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-72"&gt;14 May 2007&lt;/item&gt;
      &lt;item rend="dd-72"&gt;
        &lt;p&gt;Charles 3.0.3 re-released. Fixes launch bug on computers that haven't used Charles before.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-73"&gt;12 May 2007&lt;/item&gt;
      &lt;item rend="dd-73"&gt;
        &lt;p&gt;Charles 3.0.3 released. Various improvements and minor bug fixes.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-74"&gt;23 Apr 2007&lt;/item&gt;
      &lt;item rend="dd-74"&gt;
        &lt;p&gt;Charles 3.0.2 released. Minor bug fixes and improvements.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-75"&gt;28 Mar 2007&lt;/item&gt;
      &lt;item rend="dd-75"&gt;
        &lt;p&gt;Charles 3.0.1 released. Minor bug fixes.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-76"&gt;24 Mar 2007&lt;/item&gt;
      &lt;item rend="dd-76"&gt;
        &lt;p&gt;Charles 3.0 released. Major new features and improvements&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-77"&gt;7 Mar 2007&lt;/item&gt;
      &lt;item rend="dd-77"&gt;
        &lt;p&gt;Charles 3.0 public beta released.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-78"&gt;27 Feb 2007&lt;/item&gt;
      &lt;item rend="dd-78"&gt;
        &lt;p&gt;Charles v2.6.4 release. Minor bug fixes:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;IBM JDK compatibility&lt;/item&gt;
          &lt;item&gt;Improved malformed Referer header support&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item rend="dt-79"&gt;17 Feb 2007&lt;/item&gt;
      &lt;item rend="dd-79"&gt;
        &lt;p&gt;Charles v2.6.3 release. Minor bug fixes:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Fixed Port Forwarding fault introduced in v2.6.2&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item rend="dt-80"&gt;1 Feb 2007&lt;/item&gt;
      &lt;item rend="dd-80"&gt;
        &lt;p&gt;Charles v2.6.2 release. Major improvements and bug fixes including:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;No more recording limits. Large responses are now saved to temporary files, reducing memory usage.&lt;/item&gt;
          &lt;item&gt;MTU support in the throttle settings&lt;/item&gt;
          &lt;item&gt;AMF3 / Flex 2 bug fixes&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item rend="dt-81"&gt;2 Dec 2006&lt;/item&gt;
      &lt;item rend="dd-81"&gt;
        &lt;p&gt;Charles v2.6.1 release. Minor bug fixes and improvements:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;SOAP information visible while response is still loading&lt;/item&gt;
          &lt;item&gt;AMF3 externalizable object parsing regression fixed&lt;/item&gt;
          &lt;item&gt;AMF view for AMF3/Flex messages simplified to hide Flex implementation details&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item rend="dt-82"&gt;27 Nov 2006&lt;/item&gt;
      &lt;item rend="dd-82"&gt;
        &lt;p&gt;Charles v2.6 release. Major improvements and bug fixes including:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Major UI overhaul&lt;/item&gt;
          &lt;item&gt;JSON and JSON-RPC support&lt;/item&gt;
          &lt;item&gt;SOAP support&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item rend="dt-83"&gt;20 Sep 2006&lt;/item&gt;
      &lt;item rend="dd-83"&gt;
        &lt;p&gt;Charles v2.5 release. Major improvements and bug fixes including:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Major UI improvements&lt;/item&gt;
          &lt;item&gt;Support for new filetypes including FLV&lt;/item&gt;
          &lt;item&gt;Major improvements to AMF / Flash remoting viewer&lt;/item&gt;
          &lt;item&gt;Thank you to everyone who made suggestions and participated in the long testing process.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item rend="dt-84"&gt;1 Jun 2006&lt;/item&gt;
      &lt;item rend="dd-84"&gt;
        &lt;p&gt;Charles v2.4.2 release. Minor improvements and bug fixes including:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Support for request body compression (used by web services)&lt;/item&gt;
          &lt;item&gt;Fix for parsing of AMFPHP responses&lt;/item&gt;
          &lt;item&gt;Improvements to AMF viewer&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item rend="dt-85"&gt;6 May 2006&lt;/item&gt;
      &lt;item rend="dd-85"&gt;
        &lt;p&gt;Charles v2.4.1 release. Minor improvements and bug fixes including:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Firefox extension improved&lt;/item&gt;
          &lt;item&gt;AMF 0 and AMF 3 parsing improved&lt;/item&gt;
          &lt;item&gt;Look and Feel changes to give a greater (and more consistent) range of font sizes in the Charles look and feel&lt;/item&gt;
          &lt;item&gt;SSL error reporting improved when a connection cannot be made to a remote host&lt;/item&gt;
          &lt;item&gt;Port Forwarding tool and Reverse Proxy tool re-bind exception fixed&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item rend="dt-86"&gt;26 Apr 2006&lt;/item&gt;
      &lt;item rend="dd-86"&gt;
        &lt;p&gt;Charles v2.4 release. Major new features, improvements and bug fixes including:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;AMF 3 support&lt;/item&gt;
          &lt;item&gt;SSL support for IBM JDK (thanks to Lance Bader for helping solve this)&lt;/item&gt;
          &lt;item&gt;Automatic Update Checking&lt;/item&gt;
          &lt;item&gt;Documentation wiki open to public&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item rend="dt-87"&gt;25 Mar 2006&lt;/item&gt;
      &lt;item rend="dd-87"&gt;
        &lt;p&gt;Charles v2.3 release. Major improvements and bug fixes including:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Proxy implementation improvements including better handling of keep-alive connections&lt;/item&gt;
          &lt;item&gt;SOCKS proxy added, so any SOCKSified application can now run through Charles&lt;/item&gt;
          &lt;item&gt;External proxies configuration improvements including authentication&lt;/item&gt;
          &lt;item&gt;Flash Remoting / AMF viewer improvements&lt;/item&gt;
          &lt;item&gt;Dynamic proxy port support, for multiuser systems&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item rend="dt-88"&gt;5 Nov 2005&lt;/item&gt;
      &lt;item rend="dd-88"&gt;
        &lt;p&gt;Charles v2.2.1 release. Minor improvements and bug fixes including:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Further improved Firefox proxy configuration&lt;/item&gt;
          &lt;item&gt;Port Forwarding enhancements including port ranges and UDP forwarding&lt;/item&gt;
          &lt;item&gt;Bug fixes for Reverse Proxy and AMF viewer&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item rend="dt-89"&gt;5 Oct 2005&lt;/item&gt;
      &lt;item rend="dd-89"&gt;
        &lt;p&gt;Charles v2.2 released. Major enhancements and bug fixes including:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Improved Firefox proxy configuration&lt;/item&gt;
          &lt;item&gt;XML viewer improvements&lt;/item&gt;
          &lt;item&gt;Line numbers displayed in ASCII viewer&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item rend="dt-90"&gt;2 Sep 2005&lt;/item&gt;
      &lt;item rend="dd-90"&gt;
        &lt;p&gt;Charles v2.1 released. Major new features and enhancements including:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Automatic Firefox proxy configuration&lt;/item&gt;
          &lt;item&gt;Formatted form posts and query string information&lt;/item&gt;
          &lt;item&gt;Parsing of SWF and AMF (Flash Remoting) binary formats&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item rend="dt-91"&gt;18 Jun 2005&lt;/item&gt;
      &lt;item rend="dd-91"&gt;
        &lt;p&gt;Charles v2.0 released. Major enhancements and improvements.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Feedback &amp;amp; Reviews&lt;/head&gt;
    &lt;p&gt;Better Mobile Application Testing with Charles Proxy&lt;lb/&gt; by Andrew Bardallis A comprehensive walkthrough of using Charles to observe and modify traffic, including using it with mobile devices. &lt;/p&gt;
    &lt;p&gt;Monitor and Debug with Charles Proxy&lt;lb/&gt; by Tobias Sj√∂sten &lt;/p&gt;
    &lt;p&gt;iPhone App Store data mining&lt;lb/&gt; by Dan Grigsby Using Charles to explore the iPhone App Store XML. &lt;/p&gt;
    &lt;p&gt;iPhone HTTP Connection Debugging&lt;lb/&gt; by Gary Rogers Using Charles to debug the iPhone. &lt;/p&gt;
    &lt;p&gt;I Love Charles...&lt;lb/&gt; by MadeByPi &lt;/p&gt;
    &lt;p&gt;Basic use of Charles in Flex Design&lt;lb/&gt; by Frankie Loscavio &lt;/p&gt;
    &lt;p&gt;Charles review on flashgroup.net&lt;lb/&gt; by Darren Richardson A great review of Charles from the point of view of Flash developers. &lt;/p&gt;
    &lt;p&gt;Debugging Flash/Server Interaction with Charles&lt;lb/&gt; by uberGeek Using Charles to find those really annoying Flash bugs in record time. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46333983</guid><pubDate>Sat, 20 Dec 2025 06:09:17 +0000</pubDate></item><item><title>Privacy doesn't mean anything anymore, anonymity does</title><link>https://servury.com/blog/privacy-is-marketing-anonymity-is-architecture/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46334025</guid><pubDate>Sat, 20 Dec 2025 06:21:05 +0000</pubDate></item><item><title>Contrails Map</title><link>https://map.contrails.org/</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46334296</guid><pubDate>Sat, 20 Dec 2025 07:38:57 +0000</pubDate></item><item><title>NTP at NIST Boulder Has Lost Power</title><link>https://lists.nanog.org/archives/list/nanog@lists.nanog.org/message/ACADD3NKOG2QRWZ56OSNNG7UIEKKTZXL/</link><description>&lt;doc fingerprint="b642185be6ec8c29"&gt;
  &lt;main&gt;
    &lt;p&gt;reposting from the Internet time service list jeff.s...@nist.gov &amp;lt;jeff.sherman@nist.gov&amp;gt;: Dec 19 05:18PM -0800 Dear colleagues, In short, the atomic ensemble time scale at our Boulder campus has failed due to a prolonged utility power outage. One impact is that the Boulder Internet Time Services no longer have an accurate time reference. At time of writing the Boulder servers are still available due a standby power generator, but I will attempt to disable them to avoid disseminating incorrect time. The affected servers are: time-a-b.nist.gov time-b-b.nist.gov time-c-b.nist.gov time-d-b.nist.gov time-e-b.nist.gov ntp-b.nist.gov (authenticated NTP) No time to repair estimate is available until we regain staff access and power. Efforts are currently focused on obtaining an alternate source of power so the hydrogen maser clocks survive beyond their battery backups. More details follow. Due to prolonged high wind gusts there have been a combination of utility power line damage and preemptive utility shutdowns (in the interest of wildfire prevention) in the Boulder, CO area. NIST's campus lost utility power Wednesday (Dec. 17 2025) around 22:23 UTC. At time of writing utility power is still off to the campus. Facility operators anticipated needing to shutdown the heat-exchange infrastructure providing air cooling to many parts of the building, including some internal networking closets. As a result, many of these too were preemptively shutdown with the result that our group lacks much of the monitoring and control capabilities we ordinarily have. Also, the site has been closed to all but emergency personnel Thursday and Friday, and at time of writing remains closed. At initial power loss, there was no immediate impact to the NIST atomic time scale or distribution services because the projects are afforded standby power generators. However, we now have strong evidence one of the crucial generators has failed. In the downstream path is the primary signal distribution chain, including to the Boulder Internet Time Service. Another campus building houses additional clocks backed up by a different power generator; if these survive it will allow us to re-align the primary time scale when site stability returns without making use of external clocks or reference signals. Best wishes, -Jeff Sherman project email: internet-time-service@nist.gov AnneJ (watching from Edinburgh, UK)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46334299</guid><pubDate>Sat, 20 Dec 2025 07:39:26 +0000</pubDate></item><item><title>Skills Officially Comes to Codex</title><link>https://developers.openai.com/codex/skills/</link><description>&lt;doc fingerprint="9e46555f87a8f5bc"&gt;
  &lt;main&gt;
    &lt;p&gt;Agent Skills let you extend Codex with task-specific capabilities. A skill packages instructions, resources, and optional scripts so Codex can perform a specific workflow reliably. You can share skills across teams or the community, and they build on the open Agent Skills standard.&lt;/p&gt;
    &lt;p&gt;Skills are available in both the Codex CLI and IDE extensions.&lt;/p&gt;
    &lt;head rend="h2"&gt;What are Agent Skills&lt;/head&gt;
    &lt;p&gt;A skill captures a capability expressed through markdown instructions inside a &lt;code&gt;SKILL.md&lt;/code&gt; file accompanied by optional scripts, resources, and assets that Codex uses to perform a specific task.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;head class="file-tree-row flex items-center gap-2 rounded-md border border-transparent px-2 py-1 text-sm text-default transition-colors duration-150 hover:bg-surface-secondary" data-astro-cid-cy6iooep=""&gt;my-skill/&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt; SKILL.md Required: instructions + metadata&lt;/item&gt;
          &lt;item&gt; scripts/ Optional: executable code&lt;/item&gt;
          &lt;item&gt; references/ Optional: documentation&lt;/item&gt;
          &lt;item&gt; assets/ Optional: templates, resources&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Skills use progressive disclosure to manage context efficiently. At startup, Codex loads the name and description of each available skill. Codex can then activate and use a skill in two ways:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Explicit invocation: You can include skills directly as part of your prompt. To select one, run the &lt;code&gt;/skills&lt;/code&gt;slash command, or start typing&lt;code&gt;$&lt;/code&gt;to mention a skill. (Codex web and iOS don‚Äôt support explicit invocation yet, but you can still prompt Codex to use any skill checked into the repo.)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Implicit invocation: Codex can decide to use an available skill when the user‚Äôs task matches the skill‚Äôs description.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In either method, Codex reads the full instructions of the invoked skills and any extra references checked into the skill.&lt;/p&gt;
    &lt;head rend="h2"&gt;Where to save skills&lt;/head&gt;
    &lt;p&gt;Codex loads skills from these locations. A skill‚Äôs location defines its scope.&lt;/p&gt;
    &lt;p&gt;When Codex loads available skills from these locations, it overwrites skills with the same name from a scope of lower precedence. The list below shows skill scopes and locations in order of precedence (high to low):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Skill Scope&lt;/cell&gt;
        &lt;cell role="head"&gt;Location&lt;/cell&gt;
        &lt;cell role="head"&gt;Suggested Use&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;REPO&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;$CWD/.codex/skills&lt;/code&gt;
          &lt;p&gt;Current Working Directory: where you launch Codex.&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;If in a repository or code environment, teams can check in skills most relevant to a working folder here. For instance, skills only relevant to a microservice or a code module.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;REPO&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;$CWD/../.codex/skills&lt;/code&gt;
          &lt;p&gt;A folder above CWD when you launch Codex inside a git repository.&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;If in a repository with nested folders, organizations can check in skills most relevant to a shared area in a parent folder.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;REPO&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;$REPO_ROOT/.codex/skills&lt;/code&gt;
          &lt;p&gt;The top-most root folder when you launch Codex inside a git repository.&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;If in a repository with nested folders, organizations can check in skills that are relevant to everyone using the repository. These serve as root skills that any subfolder in the repository can overwrite.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;USER&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;$CODEX_HOME/skills&lt;/code&gt;&lt;p&gt;(Mac/Linux default:&lt;/p&gt;&lt;code&gt;~/.codex/skills&lt;/code&gt;) &lt;p&gt;Any skills checked into the user‚Äôs personal folder.&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;Use to curate skills relevant to a user that apply to any repository the user may work in.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;ADMIN&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/etc/codex/skills&lt;/code&gt;
          &lt;p&gt;Any skills checked into the machine or container in a shared, system location.&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Use for SDK scripts, automation, and for checking in default admin skills available to each user on the machine.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;SYSTEM&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Bundled with Codex.&lt;/cell&gt;
        &lt;cell&gt;Useful skills relevant to a broad audience such as the skill-creator and plan skills. Available to everyone when they start Codex and can be overwritten by any layer above.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Create a skill&lt;/head&gt;
    &lt;p&gt;To create a new skill, use the built-in &lt;code&gt;$skill-creator&lt;/code&gt; skill inside Codex. Describe what you want your skill to do, and Codex will start bootstrapping your skill. If you combine it with the &lt;code&gt;$plan&lt;/code&gt; skill, Codex will first create a plan for your skill.&lt;/p&gt;
    &lt;p&gt;You can also create a skill manually by creating a folder with a &lt;code&gt;SKILL.md&lt;/code&gt; file inside a valid skill location. A &lt;code&gt;SKILL.md&lt;/code&gt; must contain a &lt;code&gt;name&lt;/code&gt; and &lt;code&gt;description&lt;/code&gt; to help Codex select the skill:&lt;/p&gt;
    &lt;code&gt;---
name: skill-name
description: Description that helps Codex select the skill
metadata:
  short-description: Optional user-facing description
---

Skill instructions for the Codex agent to follow when using this skill.&lt;/code&gt;
    &lt;p&gt;Codex skills build on the Agent Skills specification. Check out the documentation to learn more.&lt;/p&gt;
    &lt;head rend="h2"&gt;Install new skills&lt;/head&gt;
    &lt;p&gt;To expand on the list of built-in skills, you can download skills from a curated set of skills on GitHub using the &lt;code&gt;$skill-installer&lt;/code&gt; skill:&lt;/p&gt;
    &lt;code&gt;$skill-installer linear&lt;/code&gt;
    &lt;p&gt;You can also prompt the installer to download skills from other repositories.&lt;/p&gt;
    &lt;head rend="h2"&gt;Skill examples&lt;/head&gt;
    &lt;head rend="h3"&gt;Plan a new feature&lt;/head&gt;
    &lt;p&gt;Codex ships with a built-in &lt;code&gt;$plan&lt;/code&gt; skill that‚Äôs great to have Codex research and create a plan to build a new feature or solve a complex problem.&lt;/p&gt;
    &lt;head rend="h3"&gt;Access Linear context for Codex tasks&lt;/head&gt;
    &lt;code&gt;$skill-installer linear&lt;/code&gt;
    &lt;head rend="h3"&gt;Have Codex access Notion for more context&lt;/head&gt;
    &lt;code&gt;$skill-installer notion-spec-to-implementation&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46334424</guid><pubDate>Sat, 20 Dec 2025 08:09:17 +0000</pubDate></item><item><title>A train-sized tunnel is now carrying electricity under South London</title><link>https://www.ianvisits.co.uk/articles/a-train-sized-tunnel-is-now-carrying-electricity-under-south-london-86221/</link><description>&lt;doc fingerprint="2364981e67bc3394"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A train-sized tunnel is now carrying electricity under South London&lt;/head&gt;
    &lt;p&gt;Electricity has started flowing through a deep-level tube train sized tunnel running through South London.&lt;/p&gt;
    &lt;p&gt;The first of two new circuits that connect National Grid‚Äôs New Cross substation in Southwark with its Hurst substation in Bexley is now live, running for 18km beneath South London through tunnels up to 50 metres deep.&lt;/p&gt;
    &lt;p&gt;This new link replaces one of two buried cables that have served the capital since the 1960s, with the other to be replaced when the second New Cross-Hurst circuit goes live in the new year.&lt;/p&gt;
    &lt;p&gt;While the old cables were buried in shallower trenches in the streets, the LPT2 network carries power in three metre wide tunnels deep beneath the road network.&lt;/p&gt;
    &lt;p&gt;In total, the ¬£1 billion London Power Tunnels 2 (LPT2) project, which began in 2019, spans 32.5km across seven South London boroughs from Wimbledon to Hurst.&lt;/p&gt;
    &lt;p&gt;Construction of the tunnels began in March 2020, and tunnelling was carried out in three sections between existing National Grid substations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Wimbledon-New Cross (12km)&lt;/item&gt;
      &lt;item&gt;New Cross-Hurst (18km)&lt;/item&gt;
      &lt;item&gt;Hurst-Crayford (2.5km)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The current London Power Tunnels project through South London follows the completion in 2018 of the first phase ‚Äì a seven-year, ¬£1 billion project to construct 32km of tunnels and two new substations to rewire the network in North London.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46334483</guid><pubDate>Sat, 20 Dec 2025 08:26:50 +0000</pubDate></item><item><title>Airbus to migrate critical apps to a sovereign Euro cloud</title><link>https://www.theregister.com/2025/12/19/airbus_sovereign_cloud/</link><description>&lt;doc fingerprint="add29a12b7a63cd7"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Airbus to migrate critical apps to a sovereign Euro cloud&lt;/head&gt;&lt;head rend="h2"&gt;Tech exec admits not dead cert it'll find the right solution&lt;/head&gt;&lt;p&gt;Exclusive Airbus is preparing to tender a major contract to migrate mission-critical workloads to a digitally sovereign European cloud ‚Äì but estimates only an 80/20 chance of finding a suitable provider.&lt;/p&gt;&lt;head rend="h2"&gt;Seven years later, Airbus is still trying to kick its Microsoft habit&lt;/head&gt;READ MORE&lt;p&gt;The aerospace manufacturer, which has already consolidated its datacenter estate and uses services like Google Workspace, now wants to move key on-premises applications including ERP, manufacturing execution systems, CRM, and product lifecycle management (aircraft designs) to the cloud.&lt;/p&gt;&lt;p&gt;"I need a sovereign cloud because part of the information is extremely sensitive from a national and European perspective," Catherine Jestin, Airbus's executive vice president of digital, told The Register. "We want to ensure this information remains under European control."&lt;/p&gt;&lt;p&gt;The driver is access to new software. Vendors like SAP are developing innovations exclusively in the cloud, pushing customers toward platforms like S/4HANA.&lt;/p&gt;&lt;p&gt;The request for proposals launches in early January, with a decision expected before summer. The contract ‚Äì understood to be worth more than ‚Ç¨50 million ‚Äì will be long term (up to ten years), with price predictability over the period.&lt;/p&gt;&lt;p&gt;Digital sovereignty has become more critical since Donald Trump's return to the White House in January. His policies created volatility in trade and geopolitical relations, prompting European customers to reduce reliance on US providers.&lt;/p&gt;&lt;p&gt;While Microsoft, AWS, and Google have created solutions to address these concerns, fears persist about the US CLOUD Act, which allows authorities to request data held by American corporations in overseas datacenters.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Canadian data order risks blowing a hole in EU sovereignty&lt;/item&gt;&lt;item&gt;NATO taps Google for air-gapped sovereign cloud&lt;/item&gt;&lt;item&gt;Microsoft-SAP pact aims to keep Euro cloud running in a crisis&lt;/item&gt;&lt;item&gt;Big Tech's control freak era is breaking itself apart&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Microsoft admitted in French court last July it couldn't guarantee data sovereignty under this legislation.&lt;/p&gt;&lt;p&gt;Jestin is waiting for European regulators to clarify whether Airbus would truly be "immune to extraterritorial laws" ‚Äì and whether services could be interrupted.&lt;/p&gt;&lt;head rend="h2"&gt;Airbus exec: Most CIOs in Europe will not finish SAP ECC6 migration by 2030&lt;/head&gt;READ MORE&lt;p&gt;The concern isn't theoretical. Chief Prosecutor of the International Criminal Court (ICC) Karim Khan reportedly lost access to his Microsoft email after Trump sanctioned him for criticizing Israeli PM Benjamin Netanyahu, though Microsoft denies suspending ICC services.&lt;/p&gt;&lt;p&gt;Beyond US complications, Jestin questions whether European cloud providers have sufficient scale. "If you asked me today if we'll find a solution, I'd say 80/20."&lt;/p&gt;&lt;p&gt;This puts pressure on European providers to collaborate, though whether they can navigate such complexities in Airbus's timeframe remains uncertain. ¬Æ&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46334533</guid><pubDate>Sat, 20 Dec 2025 08:36:52 +0000</pubDate></item><item><title>Reflections on AI at the End of 2025</title><link>https://antirez.com/news/157</link><description>&lt;doc fingerprint="36538bf78e13824d"&gt;
  &lt;main&gt;
    &lt;quote&gt;* For years, despite functional evidence and scientific hints accumulating, certain AI researchers continued to claim LLMs were stochastic parrots: probabilistic machines that would: 1. NOT have any representation about the meaning of the prompt. 2. NOT have any representation about what they were going to say. In 2025 finally almost everybody stopped saying so. * Chain of thought is now a fundamental way to improve LLM output. But, what is CoT? Why it improves output? I believe it is two things: 1. Sampling in the model representations (that is, a form of internal search). After information and concepts relevant to the prompt topic is in the context window, the model can better reply. 2. But if you mix this to reinforcement learning, the model also learns to put one token after the other (each token will change the model state) in order to converge to some useful reply. * The idea that scaling is limited to the number of tokens we have, is no longer true, because of reinforcement learning with verifiable rewards. We are still not at AlphaGo move 37 moment, but is this really impossible in the future? There are certain tasks, like improving a given program for speed, for instance, where in theory the model can continue to make progress with a very clear reward signal for a very long time. I believe improvements to RL applied to LLMs will be the next big thing in AI. * Programmers resistance to AI assisted programming has lowered considerably. Even if LLMs make mistakes, the ability of LLMs to deliver useful code and hints improved to the point most skeptics started to use LLMs anyway: now the return on the investment is acceptable for many more folks. The programming world is still split among who uses LLMs as colleagues (for instance, all my interaction is via the web interface of Gemini, Claude, ‚Ä¶), and who uses LLMs as independent coding agents. * A few well known AI scientists believe that what happened with Transformers can happen again, and better, following different paths, and started to create teams, companies to investigate alternatives to Transformers and models with explicit symbolic representations or world models. I believe that LLMs are differentiable machine trained on a space able to approximate discrete reasoning steps, and it is not impossible they get us to AGI even without fundamentally new paradigms appearing. It is likely that AGI can be reached independently with many radically different architectures. * There is who says chain of thought changed LLMs nature fundamentally, and this is why they, in the past, claimed LLMs were very limited, and now are changing their mind. They say, because of CoT, LLMs are now a different thing. They are lying. It is still the same architecture with the same next token target, and the CoT is created exactly like that, token after token. * The ARC test today looks a lot less insurmountable than initially thought: there are small models optimized for the task at hand that perform decently well on ARC-AGI-1, and very large LLMs with extensive CoT achieving impressive results on ARC-AGI-2 with an architecture that, according to many folks, would not deliver such results. ARC, in some way, transitioned from being the anti-LLM test to a validation of LLMs. * The fundamental challenge in AI for the next 20 years is avoiding extinction.&lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46334819</guid><pubDate>Sat, 20 Dec 2025 09:38:51 +0000</pubDate></item><item><title>What Does a Database for SSDs Look Like?</title><link>https://brooker.co.za/blog/2025/12/15/database-for-ssd.html</link><description>&lt;doc fingerprint="771d50133d3853cb"&gt;
  &lt;main&gt;
    &lt;p&gt;Over on X, Ben Dicken asked:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;What does a relational database designed specifically for local SSDs look like? Postgres, MySQL, SQLite and many others were invented in the 90s and 00s, the era of spinning disks. A local NVMe SSD has ~1000x improvement in both throughput and latency. Design decisions like write-ahead logs, large page sizes, and buffering table writes in bulk were built around disks where I/O was SLOW, and where sequential I/O was order(s)-of-magnitude faster than random. If we had to throw these databases away and begin from scratch in 2025, what would change and what would remain?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;How might we tackle this question quantitatively for the modern transaction-orientated database?&lt;/p&gt;
    &lt;p&gt;But first, the bigger picture. It√¢s not only SSDs that have come along since databases like Postgres were first designed. We also have the cloud, with deployments to excellent datacenter infrastructure, including multiple independent datacenters with great network connectivity between them, available to all. Datacenter networks offer 1000x (or more) increased throughput, along with latency in the microseconds. Servers with hundreds of cores and thousands of gigabytes of RAM are mainstream.&lt;/p&gt;
    &lt;p&gt;Applications have changed too. Companies are global, businesses are 24/7. Down time is expensive, and that expense can be measured. The security and compliance environment is much more demanding. Builders want to deploy in seconds, not days.&lt;/p&gt;
    &lt;p&gt;Approach One: The Five Minute Rule&lt;/p&gt;
    &lt;p&gt;Perhaps my single favorite systems paper, The 5 Minute Rule√¢¬¶ by Jim Gray and Franco Putzolu gives us a very simple way to answer one of the most important questions in systems: how big should caches be? The five minute rule is that, back in 1986, if you expected to read a page again within five minutes you should keep in in RAM. If not, you should keep it on disk. The basic logic is that you look at the page that√¢s least likely to be re-used. If it√¢s cheaper to keep around until it√¢s next expected re-use, then you should keep more. If it√¢s cheaper to reload from storage than keep around, then you should keep less1. Let√¢s update the numbers for 2025, assuming that pages are around 32kB2 (this becomes important later).&lt;/p&gt;
    &lt;p&gt;The EC2 &lt;code&gt;i8g.48xlarge&lt;/code&gt; delivers about 1.8 million read iops of this size, at a price of around $0.004576 per second, or \(10^{-9}\) dollars per transfer (assuming we√¢re allocating about 40% of the instance price to storage). About one dollar per billion reads. It also has enough RAM for about 50 million pages of this size, costing around \(3 \times 10^{-11}\) dollars to storage a page for one second.&lt;/p&gt;
    &lt;p&gt;So, on this instance type, we should size our RAM cache to store pages for about 30 seconds. Not too different from Gray and Putzolu√¢s result 40 years ago!&lt;/p&gt;
    &lt;p&gt;That√¢s answer number one: the database should have a cache sized so that the hot set contains pages expected to be accessed in the next 30 seconds, for optimal cost. For optimal latency, however, the cache may want to be considerably bigger.&lt;/p&gt;
    &lt;p&gt;Approach Two: The Throughput/IOPS Breakeven Point&lt;/p&gt;
    &lt;p&gt;The next question is what size accesses we want to send to our storage devices to take best advantage of their performance. In the days of spinning media, the answer to this was surprisingly big: a 100MB/s disk could generally do around 100 seeks a second, so if your transfers were less than around 1MB you were walking away from throughput. Give or take a factor of 2. What does it look like for modern SSDs?&lt;/p&gt;
    &lt;p&gt;SSDs are much faster on both throughput and iops. They√¢re less sensitive than spinning drives to workload patterns, but read/write ratios and the fullness of the drives still matter. Absent benchmarking on the actual hardware with the real workload, my rule of thumb is that SSDs are throughput limited for transfers bigger than 32kB, and iops limited for transfers smaller than 32kB.&lt;/p&gt;
    &lt;p&gt;Making transfers bigger than 32kB doesn√¢t help throughput much, reduces IOPS, and probably makes the cache less effective because of false sharing and related effects. This is especially important for workloads with poor spatial locality.&lt;/p&gt;
    &lt;p&gt;So that√¢s answer number two: we want our transfers to disk not to be much smaller than 32kB on average, or we√¢re walking away from throughput.&lt;/p&gt;
    &lt;p&gt;Approach Three: Durability and Replication&lt;/p&gt;
    &lt;p&gt;Building reads on local SSDs is great: tons of throughput, tons of iops. Writes on local SSDs, on the other hand, have the distinct problem of only being durable on the local box, which is unacceptable for most workloads. Modern hardware is very reliable, but thinking through the business risks of losing data on failover isn√¢t very fun at all, so let√¢s assume that our modern database is going to replicate off-box, making at least one more synchronous copy. Ideally in a different availability zone (AZ).&lt;/p&gt;
    &lt;p&gt;That &lt;code&gt;i8g.48xlarge&lt;/code&gt; we were using for our comparison earlier has 100Gb/s (or around 12GB/s) of network bandwidth. That puts a cap on how much write throughput we can have for a single-leader database. Cross-AZ latency in EC2 varies from a couple hundred microseconds to a millisecond or two, which puts a minimum on our commit latency.&lt;/p&gt;
    &lt;p&gt;That gives us answer number three: we want to incur cross-AZ latency only at commit time, and not during writes.&lt;/p&gt;
    &lt;p&gt;Which is where we run into one of my favorite topics: isolation. The I in ACID. A modern database design will avoid read-time coordination using multiversioning, but to offer isolation stronger than &lt;code&gt;READ COMMITTED&lt;/code&gt; will need to coordinate either on each write or at commit time. It can do that like, say, Aurora Postgres does, having a single leader at a time running in a single AZ. This means great latency for clients in that zone, and higher latency for clients in different AZs. Given that most applications are hosted in multiple AZs, this can add up for latency-sensitive applications which makes a lot of round trips to the database. The alternative approach is the one Aurora DSQL takes, doing the cross-AZ round trip only at &lt;code&gt;COMMIT&lt;/code&gt; time, saving round-trips.&lt;/p&gt;
    &lt;p&gt;Here√¢s me talking about the shape of that trade-off at re:Invent this year:&lt;/p&gt;
    &lt;p&gt;There√¢s no clear answer here, because there are real trade-offs between the two approaches. But do make sure to ask your database vendor whether those impressive latency benchmarks are running where you application actually runs. In the spirit of the original question, though, the incredible bandwidth and latency availability in modern datacenter networks is as transformative as SSDs in database designs. Or should be.&lt;/p&gt;
    &lt;p&gt;While we√¢re incurring the latency cost of synchronous replication, we may as well get strongly consistent scale-out reads for free. In DSQL, we do this using high-quality hardware clocks that you can use too. Another nice win from modern hardware. There are other approaches too.&lt;/p&gt;
    &lt;p&gt;That√¢s answer number four for me: The modern database uses high-quality clocks and knowledge of actual application architectures to optimize for real-world performance (like latency in multiple availability zones or regions) without compromising on strong consistency.&lt;/p&gt;
    &lt;p&gt;Approach Four: What about that WAL?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Design decisions like write-ahead logs, large page sizes, and buffering table writes in bulk were built around disks where I/O was SLOW, and where sequential I/O was order(s)-of-magnitude faster than random.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;WALs, and related low-level logging details, are critical for database systems that care deeply about durability on a single system. But the modern database isn√¢t like that: it doesn√¢t depend on commit-to-disk on a single system for its durability story. Commit-to-disk on a single system is both unnecessary (because we can replicate across storage on multiple systems) and inadequate (because we don√¢t want to lose writes even if a single system fails).&lt;/p&gt;
    &lt;p&gt;That√¢s answer number five: the modern database commits transactions to a distributed log, which provides multi-machine multi-AZ durability, and might provide other services like atomicity. Recovery is a replay from the distributed log, on any one of a number of peer replicas.&lt;/p&gt;
    &lt;p&gt;What About Data Structures?&lt;/p&gt;
    &lt;p&gt;B-Trees versus LSM-trees vs B-Tree variants versus LSM variants versus other data structures are trade-offs that have a lot to do with access patterns and workload patterns. Picking a winner would be a whole series of blog posts, so I√¢m going to chicken out and say its complicated.&lt;/p&gt;
    &lt;p&gt;Conclusion&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;If we had to throw these databases away and begin from scratch in 2025, what would change and what would remain?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I√¢d keep the relational model, atomicity, isolation (but would probably pick &lt;code&gt;SNAPSHOT&lt;/code&gt; as a default), strong consistency, SQL, interactive transactions, and the other core design decisions of relational databases. But I√¢d move durability, read and write scale, and high availability into being distributed rather than single system concerns. I think that helps with performance and cost, while making these properties easier to achieve. I√¢d mostly toss out local durability and recovery, and all the huge history of optimizations and data structures around that3, in favor of getting better properties in the distributed setting. I√¢d pay more attention to internal strong isolation (in the security sense) between clients and workloads. I√¢d size caches for a working set of between 30 seconds and 5 minutes of accesses. I√¢d optimize for read transfers around that 32kB sweet spot from local SSD, and the around 8kB sweet spot for networks.&lt;/p&gt;
    &lt;p&gt;Probably more stuff too, but this is long enough as-is.&lt;/p&gt;
    &lt;p&gt;Other topics worth covering include avoiding copies on IO, co-design with virtualization (e.g. see our Aurora Serverless paper), trade-offs of batching, how the relative performance of different isolation levels changes, what promises to give clients, encryption and authorization of data at rest and in motion, dealing with very hot single items, new workloads like vector, verifiable replication journals, handing off changes to analytics systems, access control, multi-tenancy, forking and merging, and even locales.&lt;/p&gt;
    &lt;p&gt;Footnotes&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46334990</guid><pubDate>Sat, 20 Dec 2025 10:13:33 +0000</pubDate></item><item><title>Raycaster (YC F24) Is Hiring a Research Engineer (NYC, In-Person)</title><link>https://news.ycombinator.com/item?id=46335552</link><description>&lt;doc fingerprint="38de78772a87c948"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Raycaster (raycaster.ai) (YC F24) builds a document IDE for high-stakes, regulated work in life sciences (CMC / quality / regulatory). The product turns messy, versioned documents (PDFs, Word redlines, tables) into a structured workspace where agents can search, cite, reconcile changes, and help draft.&lt;/p&gt;
      &lt;p&gt;We‚Äôre hiring a Research Engineer who can both (1) ship production systems and (2) help define the research direction for the company. There‚Äôs room to publish technical deep dives, benchmarks, and papers from day 0.&lt;/p&gt;
      &lt;p&gt;What you‚Äôll do: - Build and ship core agent workflows: orchestration, retrieval, tool use, guardrails, evals - Work on document pipelines + versioning + reliability/observability - Turn research ideas into production features (and sometimes the other direction) - Help design benchmarks/datasets for high-stakes document tasks; potentially publish&lt;/p&gt;
      &lt;p&gt;What we‚Äôre looking for: - Strong engineering fundamentals (distributed systems / performance / reliability) - Comfortable implementing and iterating on evaluation (not just demos) - Product taste: you notice UX details and can build end-to-end - Able to learn a domain quickly and ask sharp questions&lt;/p&gt;
      &lt;p&gt;Nice to have: - Prior publications, open-source, or technical writing&lt;/p&gt;
      &lt;p&gt;Logistics: - NYC (Hudson Yards), in-person 5 days/week - Compensation: base + founder-level equity (details in process)&lt;/p&gt;
      &lt;p&gt;To apply, email: founders [at] raycaster.ai Include: a link to work you‚Äôve shipped (GitHub/projects) and 1‚Äì2 examples of research/evals you‚Äôve built (can be informal).&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46335552</guid><pubDate>Sat, 20 Dec 2025 12:00:31 +0000</pubDate></item><item><title>Immersa: Open-source Web-based 3D Presentation Tool</title><link>https://github.com/ertugrulcetin/immersa</link><description>&lt;doc fingerprint="d0dea5c9f283f98"&gt;
  &lt;main&gt;
    &lt;p&gt;A Web-based 3D Presentation Tool - Create stunning 3D presentations with animated transitions between slides.&lt;/p&gt;
    &lt;p&gt;Watch Immersa in action: Demo Video&lt;/p&gt;
    &lt;p&gt;Immersa is an innovative presentation tool that brings your presentations into the third dimension. Unlike traditional slide-based tools, Immersa allows you to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Load 3D Models: Import &lt;code&gt;.glb&lt;/code&gt;3D models into your presentation&lt;/item&gt;
      &lt;item&gt;Add Images: Place 2D images in 3D space&lt;/item&gt;
      &lt;item&gt;Create Text: Add 3D text elements to your slides&lt;/item&gt;
      &lt;item&gt;Animate Transitions: When you move, rotate, or scale objects between slides, Immersa automatically creates smooth animated transitions&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The magic of Immersa lies in its interpolation system:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Create Slide 1: Position your 3D models, images, and text where you want them&lt;/item&gt;
      &lt;item&gt;Duplicate Slide: Create a new slide (which copies all objects)&lt;/item&gt;
      &lt;item&gt;Reposition Objects: Move, rotate, or scale objects to new positions on the new slide&lt;/item&gt;
      &lt;item&gt;Present: When presenting, Immersa smoothly interpolates between positions, creating fluid animations&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This means if a car model is on the left in slide 1 and on the right in slide 2, it will smoothly animate from left to right during the transition!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;3D Scene Editor: Full 3D viewport with camera controls&lt;/item&gt;
      &lt;item&gt;GLB Model Support: Import any &lt;code&gt;.glb&lt;/code&gt;3D model&lt;/item&gt;
      &lt;item&gt;Image Support: Add images (JPG, PNG) to your 3D scene&lt;/item&gt;
      &lt;item&gt;3D Text: Create and style 3D text elements&lt;/item&gt;
      &lt;item&gt;Animated Transitions: Automatic smooth animations between slides&lt;/item&gt;
      &lt;item&gt;Presentation Mode: Full-screen presentation with progress bar&lt;/item&gt;
      &lt;item&gt;Local Storage: All data stored locally in your browser (IndexedDB)&lt;/item&gt;
      &lt;item&gt;Undo/Redo: Full undo/redo support&lt;/item&gt;
      &lt;item&gt;Keyboard Shortcuts: Quick access to common actions&lt;/item&gt;
      &lt;item&gt;Beautiful UI: Modern, dark-themed interface&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Node.js (v16 or higher recommended)&lt;/item&gt;
      &lt;item&gt;npm or yarn&lt;/item&gt;
      &lt;item&gt;Java (JDK 11 or higher) - Required for ClojureScript compilation&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Clone the repository&lt;/p&gt;
        &lt;code&gt;git clone https://github.com/ertugrulcetin/immersa.git cd immersa&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Install dependencies&lt;/p&gt;
        &lt;quote&gt;npm install&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Start the development server&lt;/p&gt;
        &lt;quote&gt;npm run watch&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Open in browser Navigate to http://localhost:8280&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;npm run release&lt;/code&gt;
    &lt;p&gt;The production build will be in &lt;code&gt;resources/public/js/compiled/&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The editor is divided into several panels:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Left Panel: Slide thumbnails - click to navigate, drag to reorder&lt;/item&gt;
      &lt;item&gt;Center: 3D viewport - interact with your scene&lt;/item&gt;
      &lt;item&gt;Right Panel: Object properties - modify selected objects&lt;/item&gt;
      &lt;item&gt;Top Bar: Tools and actions&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Add 3D Model: Click "3D Model" ‚Üí "Add 3D model (.glb)" ‚Üí Select your file&lt;/item&gt;
      &lt;item&gt;Add Image: Click "Image" ‚Üí "Add image" ‚Üí Select your file&lt;/item&gt;
      &lt;item&gt;Add Text: Click "Text" or press &lt;code&gt;T&lt;/code&gt;to add 3D text&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Select: Click on any object in the viewport&lt;/item&gt;
      &lt;item&gt;Move: Use the position gizmo or input values in the right panel&lt;/item&gt;
      &lt;item&gt;Rotate: Use the rotation gizmo or input rotation values&lt;/item&gt;
      &lt;item&gt;Scale: Use the scale gizmo or input scale values&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Add Slide: Press &lt;code&gt;D&lt;/code&gt;or use the "+" button to duplicate current slide&lt;/item&gt;
      &lt;item&gt;Blank Slide: Press &lt;code&gt;B&lt;/code&gt;to add a blank slide&lt;/item&gt;
      &lt;item&gt;Delete Slide: Right-click on slide thumbnail ‚Üí Delete&lt;/item&gt;
      &lt;item&gt;Navigate: Click thumbnails or use arrow keys in present mode&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Shortcut&lt;/cell&gt;
        &lt;cell role="head"&gt;Action&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;T&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Add text&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;D&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Duplicate slide&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;B&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Add blank slide&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Cmd/Ctrl + Z&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Undo&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Cmd/Ctrl + Shift + Z&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Redo&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Delete/Backspace&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Delete selected object&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Escape&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Exit present mode&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;Arrow Keys&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Navigate slides (in present mode)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Click "Present" button to enter presentation mode&lt;/item&gt;
      &lt;item&gt;Use arrow keys or on-screen controls to navigate&lt;/item&gt;
      &lt;item&gt;Press Escape or click "Exit present mode" to return to editor&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Click "Export" to download your presentation as an &lt;code&gt;.edn&lt;/code&gt; file. This file contains all slide data and can be loaded later.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ClojureScript - Primary programming language&lt;/item&gt;
      &lt;item&gt;shadow-cljs - Build tool&lt;/item&gt;
      &lt;item&gt;Reagent - React wrapper for ClojureScript&lt;/item&gt;
      &lt;item&gt;Re-frame - State management&lt;/item&gt;
      &lt;item&gt;Babylon.js - 3D rendering engine&lt;/item&gt;
      &lt;item&gt;IndexedDB - Local data storage&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;immersa/
‚îú‚îÄ‚îÄ src/immersa/
‚îÇ   ‚îú‚îÄ‚îÄ common/           # Shared utilities
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ local_storage.cljs  # IndexedDB storage
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ firebase.cljs       # Storage adapter
‚îÇ   ‚îú‚îÄ‚îÄ scene/            # 3D scene management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/          # Babylon.js wrappers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core.cljs     # Scene initialization
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ slide.cljs    # Slide/animation logic
‚îÇ   ‚îú‚îÄ‚îÄ ui/               # User interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ editor/       # Editor components
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ present/      # Presentation mode
‚îÇ   ‚îî‚îÄ‚îÄ presentations/    # Default presentations
‚îú‚îÄ‚îÄ resources/public/     # Static assets
‚îÇ   ‚îú‚îÄ‚îÄ img/              # Images
‚îÇ   ‚îú‚îÄ‚îÄ model/            # Sample 3D models
‚îÇ   ‚îú‚îÄ‚îÄ shader/           # Custom shaders
‚îÇ   ‚îî‚îÄ‚îÄ index.html        # Entry point
‚îî‚îÄ‚îÄ shadow-cljs.edn       # Build configuration
&lt;/code&gt;
    &lt;p&gt;All data is stored locally in your browser using IndexedDB:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Presentations: Slide data and structure&lt;/item&gt;
      &lt;item&gt;Thumbnails: Slide preview images&lt;/item&gt;
      &lt;item&gt;Files: Uploaded images and 3D models&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Data persists across sessions. Clear browser data to reset.&lt;/p&gt;
    &lt;p&gt;This project is licensed under the MIT License - see the LICENSE file for details.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Babylon.js - Powerful 3D rendering engine&lt;/item&gt;
      &lt;item&gt;Reagent - Minimalistic React interface for ClojureScript&lt;/item&gt;
      &lt;item&gt;Re-frame - A pattern for writing SPAs in ClojureScript&lt;/item&gt;
      &lt;item&gt;Radix UI - Unstyled, accessible components&lt;/item&gt;
      &lt;item&gt;Phosphor Icons - Beautiful icon set&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Made with ‚ù§Ô∏è by Ertuƒürul √áetin&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46336097</guid><pubDate>Sat, 20 Dec 2025 13:38:24 +0000</pubDate></item><item><title>TailwindSQL ‚Äì Like TailwindCSS, but for SQL Queries in React Server Components</title><link>https://github.com/mmarinovic/tailwindsql</link><description>&lt;doc fingerprint="bb0bfd78d93178de"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;Like TailwindCSS, but for SQL queries in React Server Components.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;TailwindSQL lets you write SQL queries using Tailwind-style class names. Just use &lt;code&gt;className&lt;/code&gt; to query your database directly in React Server Components!&lt;/p&gt;
    &lt;code&gt;// Fetch and render a user's name
&amp;lt;DB className="db-users-name-where-id-1" /&amp;gt;
// Renders: "Ada Lovelace"

// Render products as a list
&amp;lt;DB className="db-products-title-limit-5" as="ul" /&amp;gt;
// Renders: &amp;lt;ul&amp;gt;&amp;lt;li&amp;gt;Mechanical Keyboard&amp;lt;/li&amp;gt;...&amp;lt;/ul&amp;gt;

// Order by price and show as table
&amp;lt;DB className="db-products-orderby-price-desc" as="table" /&amp;gt;&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üé® Tailwind-style syntax - Write SQL queries using familiar class names&lt;/item&gt;
      &lt;item&gt;‚ö° React Server Components - Zero client-side JavaScript for queries&lt;/item&gt;
      &lt;item&gt;üîí SQLite - Built on better-sqlite3 for fast, local database access&lt;/item&gt;
      &lt;item&gt;üéØ Zero Runtime - Queries are parsed and executed at build/render time&lt;/item&gt;
      &lt;item&gt;üé≠ Multiple Render Modes - Render as text, lists, tables, or JSON&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;db-{table}-{column}-where-{field}-{value}-limit-{n}-orderby-{field}-{asc|desc}
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Class Name&lt;/cell&gt;
        &lt;cell role="head"&gt;SQL Query&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;db-users&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;SELECT * FROM users&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;db-users-name&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;SELECT name FROM users&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;db-users-where-id-1&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;SELECT * FROM users WHERE id = 1&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;db-posts-title-limit-10&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;SELECT title FROM posts LIMIT 10&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;db-products-orderby-price-desc&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;SELECT * FROM products ORDER BY price DESC&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Node.js 18+&lt;/item&gt;
      &lt;item&gt;npm or yarn&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Clone the repository
git clone https://github.com/mmarinovic/tailwindsql.git
cd tailwindsql

# Install dependencies
npm install

# Seed the database with demo data
npm run seed

# Start the development server
npm run dev&lt;/code&gt;
    &lt;p&gt;Open http://localhost:3000 to see the demo and interactive playground!&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Parser (&lt;code&gt;src/lib/parser.ts&lt;/code&gt;) - Parses class names into query configurations&lt;/item&gt;
      &lt;item&gt;Query Builder (&lt;code&gt;src/lib/query-builder.ts&lt;/code&gt;) - Transforms configs into safe SQL queries&lt;/item&gt;
      &lt;item&gt;DB Component (&lt;code&gt;src/components/DB.tsx&lt;/code&gt;) - React Server Component that executes queries and renders results&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The &lt;code&gt;as&lt;/code&gt; prop controls how results are rendered:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;span&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Inline text (default)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;div&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Block element&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;ul&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Unordered list&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;ol&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Ordered list&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;table&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;HTML table&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;json&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;JSON code block&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;tailwindsql/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ app/              # Next.js app directory
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page.tsx      # Landing page
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api/          # API routes
‚îÇ   ‚îú‚îÄ‚îÄ components/        # React components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DB.tsx        # Main DB component
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Example.tsx   # Example components
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Playground.tsx # Interactive playground
‚îÇ   ‚îî‚îÄ‚îÄ lib/              # Core logic
‚îÇ       ‚îú‚îÄ‚îÄ parser.ts     # Class name parser
‚îÇ       ‚îú‚îÄ‚îÄ query-builder.ts # SQL query builder
‚îÇ       ‚îî‚îÄ‚îÄ db.ts         # Database connection
‚îî‚îÄ‚îÄ README.md
&lt;/code&gt;
    &lt;p&gt;This project was built to explore css-driven database queries.&lt;/p&gt;
    &lt;p&gt;MIT - Do whatever you want with it (except deploy to production üòÖ)&lt;/p&gt;
    &lt;p&gt;Built with üíú using Next.js, SQLite, and questionable decisions&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46336213</guid><pubDate>Sat, 20 Dec 2025 13:54:29 +0000</pubDate></item><item><title>Go ahead, self-host Postgres</title><link>https://pierce.dev/notes/go-ahead-self-host-postgres#user-content-fn-1</link><description>&lt;doc fingerprint="f71ab062fd2625d6"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Go ahead, self-host Postgres&lt;/head&gt;
    &lt;p&gt;Self-hosting a database sounds terrifying. That narrative has certainly been pushed over the last 10 years by the big cloud providers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Hosting your own database is dangerous&lt;/item&gt;
      &lt;item&gt;How are you going to get all the 9s of reliability doing it yourself?&lt;/item&gt;
      &lt;item&gt;You'll have access to dedicated database engineers that you couldn't (or wouldn't want to) hire yourself&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The rumors obscure the truth.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Most cloud hosts are just running a slightly modified version of the open source Postgres server anyway1&lt;/item&gt;
      &lt;item&gt;Database engineering is not a silver bullet if your queries are sub-optimal. Abstracting away your engine too much from your code doesn't let you benchmark what's going on and work around the otherwise reasonable constraints of how the engine is actually querying your code.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I've had data corruption when using a 3rd party vendor just the same as I've had when self-hosting. And with a serious markup, what's the point?&lt;/p&gt;
    &lt;p&gt;I've been running my own self-hosted postgres for the better part of two years now, serving thousands of users and tens of millions of queries daily2. I expected it would give me much more trouble than it has. It's caused me exactly 30mins of stress during a manual migration and that's all. Aside from that it's been fast, stable, and much cheaper.&lt;/p&gt;
    &lt;p&gt;I sleep just fine at night thank you.&lt;/p&gt;
    &lt;head rend="h2"&gt;Blue skies and the white cloud&lt;/head&gt;
    &lt;p&gt;Let me rewind for a second. The "database as a service" narrative wasn't always the dominant one. From the 80s to the early 2000s, everyone ran their own databases because there wasn't really an alternative. You had your application server and your database server, often on the same physical machine. It was pretty dang fast3 because it was communicating over localhost before forwarding the final payload over the network.&lt;/p&gt;
    &lt;p&gt;Amazon launched RDS in 2009. The pitch was compelling: we'll handle backups, patching, high availability, and monitoring. You just connect and go. The early pricing was reasonable too - a small RDS instance cost about the same as a dedicated server, but with less operational overhead. If you had to scale your database specs independent from your web service, it made some sense.&lt;/p&gt;
    &lt;p&gt;The real shift happened around 2015 when cloud adoption accelerated. Companies started to view any infrastructure management as "undifferentiated heavy lifting"4. Running your own database became associated with legacy thinking. The new orthodoxy emerged: focus on your application logic, let AWS handle the infrastructure.&lt;/p&gt;
    &lt;p&gt;Fast forward to 2025 and I hope the pendulum might be swinging back. RDS pricing has grown considerably more aggressive. A db.r6g.xlarge instance (4 vCPUs, 32GB RAM) now costs $328/month before you add storage, backups, or multi-AZ deployment. For that price, you could rent a dedicated server with 32 cores and 256GB of RAM.&lt;/p&gt;
    &lt;head rend="h2"&gt;Unpacking the cloud&lt;/head&gt;
    &lt;p&gt;For the most part managed database services aren't running some magical proprietary technology. They're just running the same open-source Postgres you can download with some operational tooling wrapped around it.&lt;/p&gt;
    &lt;p&gt;Take AWS RDS. Under the hood, it's:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Standard Postgres compiled with some AWS-specific monitoring hooks&lt;/item&gt;
      &lt;item&gt;A custom backup system using EBS snapshots&lt;/item&gt;
      &lt;item&gt;Automated configuration management via Chef/Puppet/Ansible&lt;/item&gt;
      &lt;item&gt;Load balancers and connection pooling (PgBouncer)&lt;/item&gt;
      &lt;item&gt;Monitoring integration with CloudWatch&lt;/item&gt;
      &lt;item&gt;Automated failover scripting&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;None of this is technically complex. The value proposition is operational: they handle the monitoring, alerting, backup verification, and incident response. It's also a production ready configuration at minute zero of your first deployment. But the actual database engine? It's the same Postgres running the same SQL queries with the same performance characteristics.&lt;/p&gt;
    &lt;p&gt;I helped proved this to myself when I migrated off RDS. I took a &lt;code&gt;pg_dump&lt;/code&gt; of my RDS instance, restored it to a self-hosted server with identical specs, and ran my application's test suite. Performance was identical. In some cases, it was actually better because I could tune parameters that RDS locks down.&lt;/p&gt;
    &lt;head rend="h2"&gt;My self-hosting journey&lt;/head&gt;
    &lt;p&gt;I spent a weekend migrating to a dedicated server from DigitalOcean5: 16 vCPU / 32GB Memory / 400GB disk. The migration took about 4 hours of actual work:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Hour 1: Provision server, install Postgres, configure basic settings (kamal makes this pretty easy)&lt;/item&gt;
      &lt;item&gt;Hour 2: Set up monitoring (Prometheus + Grafana), configure backups&lt;/item&gt;
      &lt;item&gt;Hour 3: Migrate data using &lt;code&gt;pg_dump&lt;/code&gt;and&lt;code&gt;pg_restore&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Hour 4: Update application connection strings, verify everything works&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The performance improvement was immediate. Query latency dropped by about 20% across the board. Why? Because I could tune the configuration for my specific workload instead of using RDS's conservative defaults.&lt;/p&gt;
    &lt;head rend="h2"&gt;The real operational complexity&lt;/head&gt;
    &lt;p&gt;For my companies with high availability requirements, this stack takes me about half an hour per month. For the stacks that get less traffic I'm fully hands off - set it and forget it. This is roughly my cadence for my primary deploys:&lt;/p&gt;
    &lt;p&gt;Weekly tasks (10 minutes):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check backup verification (automated, just reviewing alerts)&lt;/item&gt;
      &lt;item&gt;Review slow query logs&lt;/item&gt;
      &lt;item&gt;Check disk space trends&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Monthly tasks (30 minutes):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Apply Postgres security updates&lt;/item&gt;
      &lt;item&gt;Review and rotate backup retention&lt;/item&gt;
      &lt;item&gt;Capacity planning based on growth trends&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Quarterly tasks (optional) (2 hours):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Update monitoring dashboards&lt;/item&gt;
      &lt;item&gt;Review and optimize configuration parameters&lt;/item&gt;
      &lt;item&gt;Test disaster recovery procedures&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As far as I'm concerned this is roughly comparable to the time you spend debugging RDS connection limits, working around parameter groups you can't modify, or dealing with surprise maintenance windows.&lt;/p&gt;
    &lt;p&gt;The main operational difference is that you're responsible for incident response. If your database goes down at 3 AM, you need to fix it. But here's the thing: RDS goes down too6. And when it does, you're still the one getting paged, you just have fewer tools to fix the problem.&lt;/p&gt;
    &lt;p&gt;For the most part I've found that unless I'm actively messing with the database, it's really stable. After all you're just renting some remote machine in a data center somewhere. All updates are up to you - so you have a good idea when to schedule the most risky windows.&lt;/p&gt;
    &lt;head rend="h2"&gt;When self-hosting makes sense&lt;/head&gt;
    &lt;p&gt;I'd argue self-hosting is the right choice for basically everyone, with the few exceptions at both ends of the extreme:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;If you're just starting out in software &amp;amp; want to get something working quickly with vibe coding, it's easier to treat Postgres as just another remote API that you can call from your single deployed app&lt;/item&gt;
      &lt;item&gt;If you're a really big company and are reaching the scale where you need trained database engineers to just work on your stack, you might get economies of scale by just outsourcing that work to a cloud company that has guaranteed talent in that area. The second full freight salaries come into play, outsourcing looks a bit cheaper.&lt;/item&gt;
      &lt;item&gt;Regulated workloads (PCI-DSS, FedRAMP, HIPAA, etc.) sometimes require a managed platform with signed BAAs or explicit compliance attestations.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The configuration deep dive&lt;/head&gt;
    &lt;p&gt;The things you really have to bear in mind when self-hosting:&lt;/p&gt;
    &lt;p&gt;Memory Configuration: This is where most people mess up. Pulling the standard &lt;code&gt;postgres&lt;/code&gt; docker image won't cut it. You have to configure memory bounds with static limits that correspond to hardware. I've automated some of these configurations. But whether you do it manually or use some auto-config, tweaking these params is a must.&lt;/p&gt;
    &lt;p&gt;The key parameters:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;shared_buffers&lt;/code&gt;: Start around 25 % of RAM; modern PG happily uses tens of GB.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;effective_cache_size&lt;/code&gt;: Set to 75% of system RAM (this tells Postgres how much memory the OS will use for caching)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;work_mem&lt;/code&gt;: Be conservative here. Set it to total RAM / max_connections / 2, or use a fixed value like 32MB&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;maintenance_work_mem&lt;/code&gt;: Can be generous (1-2GB), only used during VACUUM and index operations&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Connection Management: RDS enforces their own max connections, but when self hosting you get the opportunity to choose your own:&lt;/p&gt;
    &lt;code&gt;# Connection settings
max_connections = 200
shared_preload_libraries = 'pg_stat_statements'
log_connections = on
log_disconnections = on
&lt;/code&gt;
    &lt;p&gt;Wahoo! More connections = more parallelism right?&lt;/p&gt;
    &lt;p&gt;No such free lunch I'm afraid. Making fresh connections in postgres has pretty expensive overhead, so you almost always want to put a load balancer on front of it. I'm using pgbouncer on all my projects by default - even when load might not call for it. Python asyncio applications just work better with a centralized connection pooler.&lt;/p&gt;
    &lt;p&gt;And yes, I've automated some of the config there too.&lt;/p&gt;
    &lt;p&gt;Storage Tuning: NVMe SSDs change the performance equation completely:&lt;/p&gt;
    &lt;code&gt;# Storage optimization for NVMe
random_page_cost = 1.1                 # Down from default 4.0
seq_page_cost = 1.0                    # Keep at default
effective_io_concurrency = 200         # Up from default 1
&lt;/code&gt;
    &lt;p&gt;These settings tell Postgres that random reads are almost as fast as sequential reads on NVMe drives, which dramatically improves query planning.&lt;/p&gt;
    &lt;p&gt;WAL Configuration: Write-Ahead Logging is critical for durability and performance:&lt;/p&gt;
    &lt;code&gt;# WAL settings
wal_level = replica                     # Enable streaming replication
max_wal_size = 2GB                     # Allow larger checkpoints
min_wal_size = 1GB                     # Prevent excessive recycling
checkpoint_completion_target = 0.9      # Spread checkpoint I/O over 90% of interval
&lt;/code&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;I'm not advocating that everyone should self-host everything. But the pendulum has swung too far toward managed services. There's a large sweet spot where self-hosting makes perfect sense, and more teams should seriously consider it.&lt;/p&gt;
    &lt;p&gt;Start small. If you're paying more than $200/month for RDS, spin up a test server and migrate a non-critical database. You might be surprised by how straightforward it is.&lt;/p&gt;
    &lt;p&gt;The future of infrastructure is almost certainly more hybrid than it's been recently: managed services where they add genuine value, self-hosted where they're just expensive abstractions. Postgres often falls into the latter category.&lt;/p&gt;
    &lt;head rend="h2"&gt;Footnotes&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;They're either just hosting a vanilla postgres instance that's tied to the deployed hardware config, or doing something opaque with edge deploys and sharding. In the latter case they near guarantee your DB will stay highly available but costs can quickly spiral out of control. √¢¬©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Maybe up to billions at this point. √¢¬©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Even on otherwise absolutely snail speed hardware. √¢¬©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;This was Jeff Bezos's favorite phrase during the early AWS days, and it stuck. √¢¬©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Similar options include OVH, Hetzner dedicated instances, or even bare metal from providers like Equinix. √¢¬©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;AWS RDS &amp;amp; S3 has had several major outages over the years. The most memorable was the 2017 US-East-1 outage that took down half the internet. √¢¬©&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46336947</guid><pubDate>Sat, 20 Dec 2025 15:43:15 +0000</pubDate></item></channel></rss>