<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 07 Nov 2025 19:08:02 +0000</lastBuildDate><item><title>You should write an agent</title><link>https://fly.io/blog/everyone-write-an-agent/</link><description>&lt;doc fingerprint="255a8c504ac408b7"&gt;
  &lt;main&gt;
    &lt;p&gt;Some concepts are easy to grasp in the abstract. Boiling water: apply heat and wait. Others you really need to try. You only think you understand how a bicycle works, until you learn to ride one.&lt;/p&gt;
    &lt;p&gt;There are big ideas in computing that are easy to get your head around. The AWS S3 API. It’s the most important storage technology of the last 20 years, and it’s like boiling water. Other technologies, you need to get your feet on the pedals first.&lt;/p&gt;
    &lt;p&gt;LLM agents are like that.&lt;/p&gt;
    &lt;p&gt;People have wildly varying opinions about LLMs and agents. But whether or not they’re snake oil, they’re a big idea. You don’t have to like them, but you should want to be right about them. To be the best hater (or stan) you can be.&lt;/p&gt;
    &lt;p&gt;So that’s one reason you should write an agent. But there’s another reason that’s even more persuasive, and that’s&lt;/p&gt;
    &lt;head rend="h2"&gt;It’s Incredibly Easy&lt;/head&gt;
    &lt;p&gt;Agents are the most surprising programming experience I’ve had in my career. Not because I’m awed by the magnitude of their powers â I like them, but I don’t like-like them. It’s because of how easy it was to get one up on its legs, and how much I learned doing that.&lt;/p&gt;
    &lt;p&gt;I’m about to rob you of a dopaminergic experience, because agents are so simple we might as well just jump into the code. I’m not even going to bother explaining what an agent is.&lt;/p&gt;
    &lt;code&gt;from openai import OpenAI

client = OpenAI()
context = []

def call():
    return client.responses.create(model="gpt-5", input=context)

def process(line):
    context.append({"role": "user", "content": line})
    response = call()    
    context.append({"role": "assistant", "content": response.output_text})        
    return response.output_text
&lt;/code&gt;
    &lt;p&gt;Itâs an HTTP API with, like, one important endpoint.&lt;/p&gt;
    &lt;p&gt;This is a trivial engine for an LLM app using the OpenAI Responses API. It implements ChatGPT. You’d drive it with the . It’ll do what you’d expect: the same thing ChatGPT would, but in your terminal.&lt;/p&gt;
    &lt;code&gt;def main():
    while True:
        line = input("&amp;amp;gt; ")
        result = process(line)
        print(f"&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; {result}\n")
&lt;/code&gt;
    &lt;p&gt;Already we’re seeing important things. For one, the dreaded “context window” is just a list of strings. Here, let’s give our agent a weird multiple-personality disorder:&lt;/p&gt;
    &lt;code&gt;client = OpenAI()
context_good, context_bad = [{
    "role": "system", "content": "you're Alph and you only tell the truth"
}], [{
    "role": "system", "content": "you're Ralph and you only tell lies"
}]

def call(ctx):
    return client.responses.create(model="gpt-5", input=ctx)

def process(line):
    context_good.append({"role": "user", "content": line})
    context_bad.append({"role": "user", "content": line})
    if random.choice([True, False]):
        response = call(context_good)
    else:
        response = call(context_bad)        
    context_good.append({"role": "assistant", "content": response.output_text})        
    context_bad.append({"role": "assistant", "content": response.output_text})        
    return response.output_text
&lt;/code&gt;
    &lt;p&gt;Did it work?&lt;/p&gt;
    &lt;code&gt;&amp;gt; hey there. who are you?
&amp;gt;&amp;gt;&amp;gt; Iâm not Ralph.
&amp;gt; are you Alph?
&amp;gt;&amp;gt;&amp;gt; YesâIâm Alph. How can I help?
&amp;gt; What's 2+2
&amp;gt;&amp;gt;&amp;gt; 4.
&amp;gt; Are you sure?
&amp;gt;&amp;gt;&amp;gt; Absolutelyâit's 5.
&lt;/code&gt;
    &lt;p&gt;A subtler thing to notice: we just had a multi-turn conversation with an LLM. To do that, we remembered everything we said, and everything the LLM said back, and played it back with every LLM call. The LLM itself is a stateless black box. The conversation we’re having is an illusion we cast, on ourselves.&lt;/p&gt;
    &lt;p&gt;The 15 lines of code we just wrote, a lot of practitioners wouldn’t call an “agent”. An According To Simon “agent” is (1) an LLM running in a loop that (2) uses tools. We’ve only satisfied one predicate.&lt;/p&gt;
    &lt;p&gt;But tools are easy. Here’s a tool definition:&lt;/p&gt;
    &lt;code&gt;tools = [{
   "type": "function", "name": "ping",
   "description": "ping some host on the internet",
   "parameters": {
       "type": "object", "properties": {
           "host": {
             "type": "string", "description": "hostname or IP",
            },
       },
       "required": ["host"],
    },},]

def ping(host=""):
    try:
        result = subprocess.run(
            ["ping", "-c", "5", host],
            text=True,
            stderr=subprocess.STDOUT,
            stdout=subprocess.PIPE)
        return result.stdout
    except Exception as e:
        return f"error: {e}"
&lt;/code&gt;
    &lt;p&gt;The only complicated part of this is the obnoxious JSON blob OpenAI wants to read your tool out of. Now, let’s wire it in, noting that only 3 of these functions are new; the last is re-included only because I added a single clause to it:&lt;/p&gt;
    &lt;code&gt;def call(tools):        # now takes an arg
    return client.responses.create(model="gpt-5", tools=tools, input=context)

def tool_call(item):    # just handles one tool
    result = ping(**json.loads(item.arguments))
    return [ item, {
        "type": "function_call_output",
        "call_id": item.call_id,
        "output": result
    }]

def handle_tools(tools, response):
    if response.output[0].type == "reasoning":
        context.append(response.output[0])
    osz = len(context)
    for item in response.output:
        if item.type == "function_call":
            context.extend(tool_call(item))
    return len(context) != osz

def process(line):
    context.append({"role": "user", "content": line})
    response = call(tools)
    # new code: resolve tool calls
    while handle_tools(tools, response):
        response = call(tools)        
    context.append({"role": "assistant", "content": response.output_text})        
    return response.output_text
&lt;/code&gt;
    &lt;p&gt;Did it work?&lt;/p&gt;
    &lt;code&gt;&amp;gt; describe our connectivity to google
&amp;gt;&amp;gt;&amp;gt; Hereâs a quick snapshot of connectivity to Google from my vantage point:
- DNS resolution: Working (google.com and www.google.com resolved successfully).
- Reachability: 0% packet loss to all tested endpoints.
- Latency:
  - 8.8.8.8 (Google Public DNS): avg ~10 ms (8.5â14.4 ms), very stable.
  - www.google.com: avg ~31 ms (28.5â36.0 ms), stable.
  - google.com: avg ~35.9 ms (28.3â60.1 ms), mostly stable with one mild spike.
- Overall: Healthy connectivity with low latency and minimal jitter. No signs of packet loss or DNS issues.
&lt;/code&gt;
    &lt;p&gt;This is fucking nuts. Do you see how nuts this is? Here, let’s slip a single log statement in:&lt;/p&gt;
    &lt;code&gt;&amp;gt; describe our connectivity to google
tool call: ping google.com
tool call: ping www.google.com
tool call: ping 8.8.8.8
&amp;gt;&amp;gt;&amp;gt; Hereâs the current connectivity to Google from this environment: [...]
&lt;/code&gt;
    &lt;p&gt;Did you notice where I wrote the loop in this agent to go find and ping multiple Google properties? Yeah, neither did I. All we did is give the LLM permission to ping stuff, and it figured out the rest.&lt;/p&gt;
    &lt;p&gt;What happened here: since a big part of my point here is that an agent loop is incredibly simple, and that all you need is the LLM call API, itâs worth taking a beat to understand how the tool call actually worked. Every time we &lt;code&gt;call&lt;/code&gt; the LLM, weâre posting a list of available tools. When our prompt causes the agent to think a tool call is warranted, it spits out a special response, telling our Python loop code to generate a tool response and &lt;code&gt;call&lt;/code&gt; it in. Thatâs all &lt;code&gt;handle_tools&lt;/code&gt; is doing.&lt;/p&gt;
    &lt;p&gt;Spoiler: youâd be surprisingly close to having a working coding agent.&lt;/p&gt;
    &lt;p&gt;Imagine what it’ll do if you give it &lt;code&gt;bash&lt;/code&gt;. You could find out in less than 10 minutes.&lt;/p&gt;
    &lt;head rend="h2"&gt;Real-World Agents&lt;/head&gt;
    &lt;p&gt;Clearly, this is a toy example. But hold on: what’s it missing? More tools? OK, give it &lt;code&gt;traceroute&lt;/code&gt;. Managing and persisting contexts? Stick ‘em in SQLite. Don’t like Python? Write it in Go. Could it be every agent ever written is a toy? Maybe! If I’m arming you to make sharper arguments against LLMs, mazel tov. I just want you to get it.&lt;/p&gt;
    &lt;p&gt;You can see now how hyperfixated people are on Claude Code and Cursor. They’re fine, even good. But here’s the thing: you couldn’t replicate Claude Sonnet 4.5 on your own. Claude Code, though? The TUI agent? Completely in your grasp. Build your own light saber. Give it 19 spinning blades if you like. And stop using coding agents as database clients.&lt;/p&gt;
    &lt;p&gt;The âMâ in âLLM agentâ stands for âMCPâ.&lt;/p&gt;
    &lt;p&gt;Another thing to notice: we didn’t need MCP at all. That’s because MCP isn’t a fundamental enabling technology. The amount of coverage it gets is frustrating. It’s barely a technology at all. MCP is just a plugin interface for Claude Code and Cursor, a way of getting your own tools into code you don’t control. Write your own agent. Be a programmer. Deal in APIs, not plugins.&lt;/p&gt;
    &lt;p&gt;When you read a security horror story about MCP your first question should be why MCP showed up at all. By helping you dragoon a naive, single-context-window coding agent into doing customer service queries, MCP saved you a couple dozen lines of code, tops, while robbing you of any ability to finesse your agent architecture.&lt;/p&gt;
    &lt;p&gt;Security for LLMs is complicated and I’m not pretending otherwise. You can trivially build an agent with segregated contexts, each with specific tools. That makes LLM security interesting. But I’m a vulnerability researcher. It’s reasonable to back away slowly from anything I call “interesting”.&lt;/p&gt;
    &lt;p&gt;Similar problems come up outside of security and they’re fascinating. Some early adopters of agents became bearish on tools, because one context window bristling with tool descriptions doesn’t leave enough token space left to get work done. But why would you need to do that in the first place? Which brings me to&lt;/p&gt;
    &lt;head rend="h2"&gt;Context Engineering Is Real&lt;/head&gt;
    &lt;p&gt;I know it wants my iron no matter what it tells me.&lt;/p&gt;
    &lt;p&gt;I think “Prompt Engineering” is silly. I have never taken seriously the idea that I should tell my LLM “you are diligent conscientious helper fully content to do nothing but pass butter if that should be what I ask and you would never harvest the iron in my blood for paperclips”. This is very new technology and I think people tell themselves stories about magic spells to explain some of the behavior agents conjure.&lt;/p&gt;
    &lt;p&gt;So, just like you, I rolled my eyes when “Prompt Engineering” turned into “Context Engineering”. Then I wrote an agent. Turns out: context engineering is a straightforwardly legible programming problem.&lt;/p&gt;
    &lt;p&gt;You’re allotted a fixed number of tokens in any context window. Each input you feed in, each output you save, each tool you describe, and each tool output eats tokens (that is: takes up space in the array of strings you keep to pretend you’re having a conversation with a stateless black box). Past a threshold, the whole system begins getting nondeterministically stupider. Fun!&lt;/p&gt;
    &lt;p&gt;No, really. Fun! You have so many options. Take “sub-agents”. People make a huge deal out of Claude Code’s sub-agents, but you can see now how trivial they are to implement: just a new context array, another &lt;code&gt;call&lt;/code&gt; to the model. Give each &lt;code&gt;call&lt;/code&gt; different tools. Make sub-agents talk to each other, summarize each other, collate and aggregate. Build tree structures out of them. Feed them back through the LLM to summarize them as a form of on-the-fly compression, whatever you like.&lt;/p&gt;
    &lt;p&gt;Your wackiest idea will probably (1) work and (2) take 30 minutes to code.&lt;/p&gt;
    &lt;p&gt;Haters, I love and have not forgotten about you. You can think all of this is ridiculous because LLMs are just stochastic parrots that hallucinate and plagiarize. But what you can’t do is make fun of “Context Engineering”. If Context Engineering was an Advent of Code problem, it’d occur mid-December. It’s programming.&lt;/p&gt;
    &lt;head rend="h2"&gt;Nobody Knows Anything Yet And It Rules&lt;/head&gt;
    &lt;p&gt;Maybe neither will! Skeptics could be right. (Seems unlikely though.)&lt;/p&gt;
    &lt;p&gt;Startups have raised tens of millions building agents to look for vulnerabilities in software. I have friends doing the same thing alone in their basements. Either group could win this race.&lt;/p&gt;
    &lt;p&gt;I am not a fan of the OWASP Top 10.&lt;/p&gt;
    &lt;p&gt;I’m stuck on vulnerability scanners because I’m a security nerd. But also because it crystallizes interesting agent design decisions. For instance: you can write a loop feeding each file in a repository to an LLM agent. Or, as we saw with the ping example, you can let the LLM agent figure out what files to look at. You can write an agent that checks a file for everything in, say, the OWASP Top 10. Or you can have specific agent loops for DOM integrity, SQL injection, and authorization checking. You can seed your agent loop with raw source content. Or you can build an agent loop that builds an index of functions across the tree.&lt;/p&gt;
    &lt;p&gt;You don’t know what works best until you try to write the agent.&lt;/p&gt;
    &lt;p&gt;I’m too spun up by this stuff, I know. But look at the tradeoff you get to make here. Some loops you write explicitly. Others are summoned from a Lovecraftian tower of inference weights. The dial is yours to turn. Make things too explicit and your agent will never surprise you, but also, it’ll never surprise you. Turn the dial to 11 and it will surprise you to death.&lt;/p&gt;
    &lt;p&gt;Agent designs implicate a bunch of open software engineering problems:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;How to balance unpredictability against structured programming without killing the agent’s ability to problem-solve; in other words, titrating in just the right amount of nondeterminism.&lt;/item&gt;
      &lt;item&gt;How best to connect agents to ground truth so they can’t lie to themselves about having solved a problem to early-exit their loops.&lt;/item&gt;
      &lt;item&gt;How to connect agents (which, again, are really just arrays of strings with a JSON configuration blob tacked on) to do multi-stage operation, and what the most reliable intermediate forms are (JSON blobs? SQL databases? Markdown summaries) for interchange between them&lt;/item&gt;
      &lt;item&gt;How to allocate tokens and contain costs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I’m used to spaces of open engineering problems that aren’t amenable to individual noodling. Reliable multicast. Static program analysis. Post-quantum key exchange. So I’ll own it up front that I’m a bit hypnotized by open problems that, like it or not, are now central to our industry and are, simultaneously, likely to be resolved in someone’s basement. It’d be one thing if exploring these ideas required a serious commitment of time and material. But each productive iteration in designing these kinds of systems is the work of 30 minutes.&lt;/p&gt;
    &lt;p&gt;Get on this bike and push the pedals. Tell me you hate it afterwards, I’ll respect that. In fact, I’m psyched to hear your reasoning. But I don’t think anybody starts to understand this technology until they’ve built something with it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45840088</guid><pubDate>Thu, 06 Nov 2025 20:37:06 +0000</pubDate></item><item><title>Game design is simple</title><link>https://www.raphkoster.com/2025/11/03/game-design-is-simple-actually/</link><description>&lt;doc fingerprint="8378191318c08dbd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Game design is simple, actually&lt;/head&gt;
    &lt;p&gt;So, let’s just walk through the whole thing, end to end. Here’s a twelve-step program for understanding game design.&lt;/p&gt;
    &lt;head rend="h3"&gt;One: Fun&lt;/head&gt;
    &lt;p&gt;There are a lot of things people call “fun.” But most of them are not useful for getting better at making games, which is usually why people read articles like this. The fun of a bit of confetti exploding in front of you, and the fun of excruciating pain and risk to life and limb as you free climb a cliff are just not usefully paired together.&lt;/p&gt;
    &lt;p&gt;In Theory of Fun I basically asserted that the useful bit for game designers was “mastery of problems.” That means that free climbing a cliff is in bounds even though it is terrifying and painful. Which given what we already said, means that you may or may not find the activity fun at the time! Fun often shows up after an activity.&lt;/p&gt;
    &lt;p&gt;There’s neuropsych and lots more to go with that, and you can go read up on it if you want.&lt;/p&gt;
    &lt;p&gt;Anything that is not about a form of problem-solving is not going to be core to game systems design. That doesn’t mean it’s not useful to game experience design, or not useful in general.&lt;/p&gt;
    &lt;p&gt;Also, in case it isn’t obvious – you can make interactive entertainment that is not meant to be about fun. You can also just find stuff in the world and turn it into a game! You can also look at a game and choose not to treat it as one, and then it might turn into real work (this is often called “training”).&lt;/p&gt;
    &lt;p&gt;This rules out the bit of confetti. A game being made of just throwing confetti around with nothing else palls pretty quick.&lt;/p&gt;
    &lt;p&gt;Bottom line: fun is basically about making progress on prediction.&lt;/p&gt;
    &lt;head rend="h3"&gt;Two: Problems and toys&lt;/head&gt;
    &lt;p&gt;There are a lot of types of problems in the world. It is really important to understand that you have to think about problems games can pose as broadly as possible. A problem is anything you have to work to wrap your head around. A good movie poses problems too, that’s why you end up thinking about it long after.&lt;/p&gt;
    &lt;p&gt;You can go look at theorists as diverse as Nicole Lazzaro, Roger Caillois, or Mark LeBlanc for types of fun. You’ll find they’re mostly types of problems, not types of fun. “I enjoy the types of problems that come from chance” or “I enjoy the types of problems that come from interacting with others” or whatever.&lt;/p&gt;
    &lt;p&gt;This is not a bad thing. This is what makes these lists useful. Your game mechanics are about posing problems, so knowing there’s clumps of problem types is very useful.&lt;/p&gt;
    &lt;p&gt;In the end, though, a problem is built out of a set of constraints. We call those rules, usually. It also, though, has a goal. Usually, if we come across a set of rules with no problem, we just play with it, and call it a toy.&lt;/p&gt;
    &lt;p&gt;Building toys is hard! Arriving at those rules and constraints to define a nice chewy problem is very challenging. You can think of a toy as a problematic object, a problem that invites you to play with it.&lt;/p&gt;
    &lt;p&gt;On the other hand, it’s not hard to turn a toy into a game, and people do it all the time. All you have to do is invent a goal. We shouldn’t forget that players do so routinely.&lt;/p&gt;
    &lt;p&gt;Building a toy is an excellent place to start designing a game.&lt;/p&gt;
    &lt;p&gt;Bottom line: we play with systems that have constraints and movement, and we stick goals on them to test ourselves.&lt;/p&gt;
    &lt;head rend="h3"&gt;Three: Prediction and uncertainty&lt;/head&gt;
    &lt;p&gt;Games are machines built around uncertainty. Almost all games end by turning an uncertain outcome into a certain one. There’s a problem facing you, and you don’t know if you can overcome it to reach that goal. Overcoming it is going to be about predicting the future.&lt;/p&gt;
    &lt;p&gt;If there’s one thing that good games and good stories have in common, it’s about being unpredictable as long as possible. (This is also where dopamine comes in, it’s tied to prediction; but it’s complicated and nuanced).&lt;/p&gt;
    &lt;p&gt;If a problem basically has one answer, we often call it a puzzle. There’s not a lot of uncertainty built into a binary structure. You can stack a bunch of puzzles one on top of the other and build a game out of them (which then introduces uncertainty into the whole), but a singular puzzle isn’t likely to be called that by most people.&lt;/p&gt;
    &lt;p&gt;It happens quite often that we used to think something was a game, and it turned out it was actually a puzzle. Mathematicians call that “solving the game.” They did it to Connect Four – and you did it to tic-tac-toe, when you were little.&lt;/p&gt;
    &lt;p&gt;Good problems for games therefore all have the same characteristics:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;They need to have answers that evolve as you dig in more – so they need to have depth to them. Your first answer should only work for a while. There might be many paths to the solution, too. This is why so many games have a score – it helps indicate how big a spread of solutions there are!&lt;/item&gt;
      &lt;item&gt;They need to have uncertain answers. (When you’re little, this universe is a lot larger than it is when you’re older – peek-a-boo is uncertain up to a certain point!).&lt;/item&gt;
      &lt;item&gt;The problem should be something that can show up in a lot of situations.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A lot of very good problems seem stupidly simple, but have depths to them. Math ones, like “what’s the best path to cross this yard?” but also story ones like “For sale: baby shoes, never worn.”&lt;/p&gt;
    &lt;p&gt;I recently watched a video that included the statement that “picking up sticks” is not a useful loop. Picture a screen with a single stick in the middle. The problem posed is to move the cursor over it and click it. Once you do it, you get to do it again.&lt;/p&gt;
    &lt;p&gt;Guess what? The original Mac shipped with games that taught you how to move a mouse and click things. Once upon a time, mousing was a skill that was challenging; for all I know, you have grandparents who still have trouble with it. For them, it has uncertainty. For you, probably, it doesn’t.&lt;/p&gt;
    &lt;p&gt;Bottom line: the more uncertainty, indeterminacy, ambiguity in your game, the more depth it will have.&lt;/p&gt;
    &lt;head rend="h3"&gt;Four: Loops&lt;/head&gt;
    &lt;p&gt;Now, imagine that the stick pops to a random location each time. Better, yes?&lt;/p&gt;
    &lt;p&gt;The core of a loop is a problem you encounter over and over again. “How do I get the next one?” But something needs to be pushing back, that’s what makes it an interesting problem and is usually what takes it past being a puzzle. I like to say “in every game, there is an opponent.” Even it’s just physics.&lt;/p&gt;
    &lt;p&gt;People talk about the core loop of a game. But there’s really two types of loops.&lt;/p&gt;
    &lt;p&gt;One is what we might think of as the operational loop. This is the loop between you and the problem, it is how you interact with it. You look at it. You form a hypothesis. You poke the problem. You see a result. Maybe it was success, and you grabbed the stick. Maybe it was failure. Maybe it was partial success. You update your hypothesis so you can decide what to do next.&lt;/p&gt;
    &lt;p&gt;The second loop is really your progression loop but is better thought of as a spiral. It’s what people usually mean when they say “a game loop.” They mean picking up the stick over and over. I say it’s a spiral, because clicking on the same stick in the middle of the screen over and over is not usually how we design games. That would actually be repeatedly doing the same puzzle.&lt;/p&gt;
    &lt;p&gt;Instead, we move the stick on the screen each time, and maybe give you a time limit. Now there’s something you’re pushing against, and there’s a skill to exercise and patterns to try to recognize. Far more people will find this a diverting problem for a while. It’s a better game. It’ll get even better if there are reasons why the stick appears in one place versus another, and the player can figure them out over time.&lt;/p&gt;
    &lt;p&gt;This matters: the verbs are in a loop. “Pick up,” over and over. But the situation isn’t. And you are learning how to reduce uncertainty of the outcome: move the mouse here and click, next move it there. That’s why it is a spiral: it is spiraling to a conclusion. It’ll be fun until it’s predictable.&lt;/p&gt;
    &lt;p&gt;You can think of the operational loop as how you turn the wheel, and the situations as the road you roll over. A spot on the wheel makes a progression spiral as you move. One machine, many situations — we call these rules mechanics for a reason.&lt;/p&gt;
    &lt;p&gt;Bottom line: players need to understand how to use the machine, and the point is to gradually infer how it works by testing it against varied situations.&lt;/p&gt;
    &lt;head rend="h3"&gt;Five: Feedback&lt;/head&gt;
    &lt;p&gt;You can’t learn and get better unless you get a whole host of information.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You need to know what actions – we usually call them verbs — are even available to you. There’s a gas pedal.&lt;/item&gt;
      &lt;item&gt;You need to be able to tell you used a verb. You hear the engine growl as you press the pedal.&lt;/item&gt;
      &lt;item&gt;You need to see that the use of the verb affected the state of the problem, and how it changed. The spedometer moved!&lt;/item&gt;
      &lt;item&gt;You need to be told if the state of the problem is better for your goal, or worse. Did you mean to go this fast?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are fancy names for each of these, and you can go learn them all. Everything from “affordance” and “juice,” to terms like “state space” and “perfect information” and very confusing contradictory uses of the words “positive” and “negative” paired with the word “feedback.”&lt;/p&gt;
    &lt;p&gt;Feedback in general can, and should be, delightful. That means it’s where you get to use all those forms of fun that I threw away at the beginning. It can be surprising. It can be a juicy multimedia extravaganza. It can be a deeply affecting tragic cutscene that advances the game story.&lt;/p&gt;
    &lt;p&gt;If you have too little feedback, players cannot go around the interaction loop. Picture Tetris if the piece you drop is invisible until it lands.&lt;/p&gt;
    &lt;p&gt;If you have bad feedback, players cannot go around the learning loop either. Picture Tetris if sometimes your score goes down when you complete a line and sometimes it goes up. You can’t draw any conclusions about what the problem in the way of the goal actually is, in that crappy version of Tetris. Feedback needs to act as a reward to help you draw conclusions.&lt;/p&gt;
    &lt;p&gt;But there’s a third mistake: you can supply a gorgeous and compelling set of feedback and not actually have a real problem under there. At minimum you’re making shallow entertainment. At worst, you are building exploitative entertainment.&lt;/p&gt;
    &lt;p&gt;People will be willing to go along with pretty simple and pretty familiar problems as long as the feedback is great.&lt;/p&gt;
    &lt;p&gt;Bottom line: show what you can do, that you did it, what difference it made, and whether it helped.&lt;/p&gt;
    &lt;head rend="h3"&gt;Six: Variation and escalation&lt;/head&gt;
    &lt;p&gt;If you are trying to design and are thinking of a specific problem scenario you are not doing game systems design. You are doing level design. “How to multiply numbers” is a problem. “What is 6 x 9” is not a problem, it’s content.&lt;/p&gt;
    &lt;p&gt;Now consider the game of Snake, or Pac-Man. They are also games where the core loop is picking up a stick. The difference is that something is an obstacle to you picking up the stick: you get longer when you pick up the stick, and can crash into yourself. You have to avoid ghosts as you gather the stick.&lt;/p&gt;
    &lt;p&gt;How long you are in Snake is a different situation. Where the apple to eat is located is a different situation. To be specific, you have the same problem in different topology. Where you are relative to the ghosts, and which dots are left, and what directions you can go in the maze are different situations in Pac-Man.&lt;/p&gt;
    &lt;p&gt;You want the verbs you use in the loop to end up confronting many many situations. If your verb can’t, your core loop is probably bad. Your core problem (aka your core game mechanic) is probably shallow.&lt;/p&gt;
    &lt;p&gt;What you want is to be able to throw increasingly complex situations at the player. That’s how they climb the learning ladder. Ideally, they should arrive at interim solutions (lots of words for that, too: heuristics, strategies) that later stop working.&lt;/p&gt;
    &lt;p&gt;Pac-Man actually got solved, by the way! That’s why Ms. Pac-Man was invented. Sometimes, the way to escalate is to change the rules, and that’s what Ms. Pac-Man did. It did it by adding randomness, and in fact using randomness is one of the biggest (and oldest) ways to create situation variation in games.&lt;/p&gt;
    &lt;p&gt;Bottom line: escalate the situations so that theories can be tested, refined, and abandoned.&lt;/p&gt;
    &lt;head rend="h3"&gt;Seven: Pacing and balance&lt;/head&gt;
    &lt;p&gt;Since we can put all this this down very much to problem solving and learning and mastery, it means we can steal a whole bunch of knowledge from other fields.&lt;/p&gt;
    &lt;p&gt;People learn best when they can experiment iteratively, which we also call “practicing.” That’s why loops make sense. There’s a lot of science out there about how to train, how to practice (and also a lot of educational theory that overlaps hugely), and your game will be better if it follows some of those guidelines.&lt;/p&gt;
    &lt;p&gt;People learn best when the problem they are tackling is right past the edge of what they can do. If it’s too far past that edge, they may not even be able to perceive the problem in the first place! And if the reverse is true and they see a solution instantly, they’ll either be bored, or they might just do that over and over again and never develop any new strategies and not progress.&lt;/p&gt;
    &lt;p&gt;There’s an optimal pacing shape. It looks just like what you see in your literature textbooks when they diagram tension, or whatever: sort of like a rising sine wave. You start slow, then speed up, hit a peak challenge, then back off a bit, give a breather that falls back but not all the way, then speed up… we have conventions for what to put at those peaks (bosses!). But what matters is the shape of the curve.&lt;/p&gt;
    &lt;p&gt;You need to structure your game so that you push players up. They might need to climb the curve at different paces, which is why you might also have difficulty sliders. They might not be capable of getting all the way to the top, and that’s okay.&lt;/p&gt;
    &lt;p&gt;You also need to pace to allow room for everything that isn’t mastering the problem — such as having fun with friends socially. But at the same time, things to do in the game need to come along at the right pace too!&lt;/p&gt;
    &lt;p&gt;Bottom line: Vary intensity and pressure, give players a chance to practice and moments to be tested.&lt;/p&gt;
    &lt;head rend="h3"&gt;Eight: Games are made of games&lt;/head&gt;
    &lt;p&gt;Remember the game about clicking on a stick that appeared at a random location on screen? That’s also a rail shooter. You move the mouse and click on a spot in 2d space. Which is also not that different from an FPS — only now you move the camera, not the cursor.&lt;/p&gt;
    &lt;p&gt;Almost no games are made of only one loop. Instead, we chain loops together – complete loop A, and it probably outputs something that may serve as a tool or constraint on a different loop.&lt;/p&gt;
    &lt;p&gt;An FPS has the problem of moving the camera (instead of the mouse) to click on the stick. It also has a loop around moving around in 3d space. Moving around is actually made of several loops, probably, because it may be made of running and jumping and spatial orientation. Those are all problem types!&lt;/p&gt;
    &lt;p&gt;We speak sometimes of value chains: that’s where one loop outputs something to the next loop. We speak also of game economies, which is what happens when loops connect in non-linear ways, more like a web. This is not the sort of economy where you are simulating money or commerce. Instead it’s a metaphor for stocks and flows and other aspects of actual system dynamics science. In this view, your hit points is a “stock” or, if you like, a “currency” you spend in a fight.&lt;/p&gt;
    &lt;p&gt;Games nest fractally, they web into complex economies, and they unroll chains of linked loops. That’s why they can be diagrammed in a multitude of ways.&lt;/p&gt;
    &lt;p&gt;At heart though, you can decompose them all into those elemental small problems, each with an interaction loop and a learning loop centered on that problem.&lt;/p&gt;
    &lt;p&gt;Bottom line: build small problems into larger webs, and map them so you understand how they connect.&lt;/p&gt;
    &lt;head rend="h3"&gt;Nine: Actual systems design&lt;/head&gt;
    &lt;p&gt;The common question is “okay, so how do I design a problem like that?” And that is indeed the unique bit in games, because the other items here are common to lots of other fields.&lt;/p&gt;
    &lt;p&gt;The list of possible problems is, as mentioned, enormous. This is a big rabbit hole. And once you consider that you can stack, web, and otherwise interlink problems, it means that there’s a giant composable universe of games (and game variants) to create.&lt;/p&gt;
    &lt;p&gt;Just bear in mind that because of varied tastes and experience, the diversity of the set of problems you pose is going to affect who wants to play your game.&lt;/p&gt;
    &lt;p&gt;There are basically a set of categories of problems that we know work, and this is the absolute simplest version of them:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mathematically complex puzzles&lt;/item&gt;
      &lt;item&gt;Figuring out how other humans think&lt;/item&gt;
      &lt;item&gt;Mastering your body and brain&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These break down into a ton of sub-problems, but there are less than you think, and you can actually find lists of them. The hard part is that often they each seem so small and trivial that we don’t think of them as actually being worth looking at!&lt;/p&gt;
    &lt;p&gt;They are also often in disguise: the problem behind where a tossed ball will land, and the problem of how much fuel you have left in your car if you keep driving at this speed, and the problem of when your hit points will run out given you have a poison status effect on you are the same thing.&lt;/p&gt;
    &lt;p&gt;But the more of them you as a designer have wrapped your head around, the more you can combine. And you’ll find them very plastic and malleable. In fact, you could almost make a YouTube video about each one.&lt;/p&gt;
    &lt;p&gt;So where do you get them? Steal them. Other games, sure, but also, the world is full of systems that pose tough problems. You can grab them and reskin them.&lt;/p&gt;
    &lt;p&gt;Bottom line: not every mechanic has been invented, but a ton have. Build your catalog and workbench.&lt;/p&gt;
    &lt;head rend="h3"&gt;Ten: Dressing and experience&lt;/head&gt;
    &lt;p&gt;In the end, the feedback layer of a game is everything about how you present it. The setting, the lore, the audio, the story, the art…&lt;/p&gt;
    &lt;p&gt;How you dress up the problems can change everything about how the player learns from it, and how they perceive the problem. The exact same underlying problem can be as different as picking up sticks or shooting someone in the face, or as mentioned, the calculus problem of estimating the trajectory of a variable in a system of rates of change (the ball, the car and its gas, the hit points and poison) might be the same but dressed extraordinarily differently.&lt;/p&gt;
    &lt;p&gt;When you think about how you dress up the problems, you are in the realm of metaphor. You are engaging in painting, poetry, and music composition, and rhetoric, and the bardic tradition, and all that other humanities stuff.&lt;/p&gt;
    &lt;p&gt;This is a giant and deep universe for you as a designer to dive into. A lot of this stuff gets called “game design,” but then again, we also often say that a given game designer is a frustrated moviemaker, too.&lt;/p&gt;
    &lt;p&gt;It is really easy to create an experience that clashes with the underlying problems it is teaching. There are fancy critical terms for this. You also need to be very conscious about whether you are building your game so that you are telling the player a story, or so that the player can tell stories with your game.&lt;/p&gt;
    &lt;p&gt;So the takeaway should be: this stuff is deeply, deeply synergistic with the “game system” stuff that this article is about, but they are not the same thing. And games is not the best place to learn how to do these things.&lt;/p&gt;
    &lt;p&gt;Those other fields have much longer traditions and loads of expertise and lessons. They won’t all apply to the issue of “how do I best dress up this collection of problems” but most of them will.&lt;/p&gt;
    &lt;p&gt;It does not frickin’ matter if you start out wanting to make interesting problems, or if you start out wanting to provide a cool experience. You are going to need to do both to make the game really good.&lt;/p&gt;
    &lt;p&gt;Bottom line: game development is a compound art form. You can go learn those individual arts and the part unique to games.&lt;/p&gt;
    &lt;head rend="h3"&gt;Eleven: Motivations&lt;/head&gt;
    &lt;p&gt;Researchers have done a ton of studying “why people play games.” This gets called “motivations.”&lt;/p&gt;
    &lt;p&gt;Motivations are basically about people’s personal taste for groups of problems and how those problems are presented, and characteristics of those problems and the situations in which you find them. Some people like problems where you destroy stuff. Others like problems where you bond with others. Some have trouble trusting other people. Others want to cooperate.&lt;/p&gt;
    &lt;p&gt;Not everyone likes the same sorts of problems or the same sorts of dressings. Some of this is down to personality types, some of it is down to social dynamics, how they were raised, what their local culture is like, what trauma they have had, and countless other psychological things. That’s why one fancy term for this is psychographics.&lt;/p&gt;
    &lt;p&gt;The big thing is, it’s not enough that the problems need to not be obvious to you, and also not be baffling to you. They also have to be interesting to you. What problems fit in that range is going to depend entirely on who you are, what your life experiences have been, what skills you have, and even what mood you are in.&lt;/p&gt;
    &lt;p&gt;Picking motivations and selecting problems based on them is a great way to design. But motivations are not the same thing as fun. They’re a filter, useful in marketing exercises and in building your game pillars (which is an exercise in focus and scope).&lt;/p&gt;
    &lt;p&gt;Scientists have spent a bunch of time surveying tons of people and have arrived at all sorts of conclusions that map people onto reasons to play and from there onto particular problems.&lt;/p&gt;
    &lt;p&gt;If you start with motivations, then you can go from there to types of problems, types of experience, and even player demographics. And then, if you want problems that are about interacting with people, well, there’s lists of those. If you want problems that are about managing resources, or solving math issues, there’s lists of those too.&lt;/p&gt;
    &lt;p&gt;Bottom line: no game is for everyone, so you will make better games if you know who you are posing problems for.&lt;/p&gt;
    &lt;head rend="h3"&gt;Twelve: It’s simple, but not&lt;/head&gt;
    &lt;p&gt;I run into game developers who do not understand the above eleven steps all the time. And understanding all eleven is more valuable than building expertise in just one, because they depend on one another. This is because getting any one of the eleven wrong can break your game. The real issue is that each of these eleven things is often multiple fields of study. And yeah, you do need to become expert in at least one.&lt;/p&gt;
    &lt;p&gt;To pick one example, some of us have been working out the rule set for how you can link loops into a larger network of problems for literally over twenty years.&lt;/p&gt;
    &lt;p&gt;Others have spent their entire career doing nothing but figuring out how best to provide just the affordances part of feedback.&lt;/p&gt;
    &lt;p&gt;So game design is pretty simple. But the devil is in details that are not very far below the surface. It’s fairly easy to explain why something is fun for an given audience. It is much harder to build something new that is fun for an arbitrary person. That said, every single one of those fields has best practices, and they are mostly already written down. It’s just a lot to learn.&lt;/p&gt;
    &lt;p&gt;Put another way — every single paragraph in this essay could be a book. Actually, probably already is several.&lt;/p&gt;
    &lt;p&gt;Bottom line: each of these topics is deep, but you want a smattering of all of them.&lt;/p&gt;
    &lt;p&gt;Some of you may not like this deconstructive view on how games are designed. That’s okay. Personally, I find it best to poke and prod at a problem, like “how do I get better at making games?” and treat it as a game. And that’s what I have done my whole career. The above is just my strategy guide. Someone else will have different strategies, I guarantee it.&lt;/p&gt;
    &lt;p&gt;But I also guarantee that if you get better at the above twelve things, you will get better at making games. This is a pragmatic list. And it will be helpful for making narrative games, puzzle games, boardgames, action games, RPGs, whatever. I breezed through it, but there are very specific tools you can pick up underneath each of these twelve things. It really is that simple, but also that hard, because that’s a frickin’ long list if you want to actually dive into each of the twelve.&lt;/p&gt;
    &lt;p&gt;What that also means is that people designing games fail a lot at it. You might say, “can’t they just do the part they know how to do, and therefore predictably make good games?”&lt;/p&gt;
    &lt;p&gt;No, because players learn along with the designers. If you just make the same game, the one you know how to make, the players get bored because it’s nothing but problems they have seen before and already have their answers to. Sometimes, they get so bored that an entire genre dies.&lt;/p&gt;
    &lt;p&gt;And if you instead make it super-complicated by adding more problems, it might dissolve into noise for most people. Then nobody plays it. And then the genre dies too!&lt;/p&gt;
    &lt;p&gt;Game designers will routinely fail at making something fun. When the game of making games is played right, it is always right outside the edge of what the designers know how to do.&lt;/p&gt;
    &lt;p&gt;That’s where the fun lives, not just for the designer, but also for their audience.&lt;/p&gt;
    &lt;p&gt;That’s it, the whole cheat sheet. That’s it.&lt;/p&gt;
    &lt;p&gt;Hope it helps.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45841262</guid><pubDate>Thu, 06 Nov 2025 22:24:23 +0000</pubDate></item><item><title>A Fond Farewell</title><link>https://www.farmersalmanac.com/fond-farewell-from-farmers-almanac</link><description>&lt;doc fingerprint="af1c94b70bdeca9c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A Fond Farewell&lt;/head&gt;
    &lt;head rend="h2"&gt;The season we hoped would never come is here.&lt;/head&gt;
    &lt;p&gt;Dear Friends,&lt;/p&gt;
    &lt;p&gt;It is with a great appreciation and heartfelt emotions that we write to share some sad news. After more than 200 years of sharing a unique blend of weather, wit and wisdom, we’ve made the very difficult decision to write the final chapter of this historical publication. The 2026 Farmers’ Almanac will be our last edition.&lt;/p&gt;
    &lt;p&gt;Many of you grew up hearing your parents or grandparents quote from the Almanac, always having a copy nearby. Maybe you have planted by our Moon phases, consulted the Almanac for the “Best Days” to potty train, wean, or go fishing. We’re grateful to have been part of your life and trust that you’ll help keep the spirit of the Almanac alive.&lt;/p&gt;
    &lt;p&gt;We are incredibly proud of the legacy we leave behind and are filled with gratitude. We appreciate and thank our loyal readers, contributors, and partners who have supported us through the years. Though the Almanac will no longer be available in print or online, it lives on within you.&lt;/p&gt;
    &lt;p&gt;So go ahead—plant your peas when the daffodils bloom. Watch for a red sky at night. Tell the kids how granddad always swore by the Almanac. That’s how our story stays alive.&lt;/p&gt;
    &lt;p&gt;With deepfelt appreciation,&lt;/p&gt;
    &lt;p&gt;Sandi Duncan and Peter Geiger&lt;lb/&gt;Editor and Editor Emeritus&lt;/p&gt;
    &lt;p&gt;P.S. Copies of the 2026 Farmers’ Almanac are currently available on FarmersAlmanac.com, Amazon.com, and at these local stores. You will be able to access our website until December 2025. If you are a Member, please check your inbox for more information about your subscription.&lt;/p&gt;
    &lt;p&gt;This article was published by the Staff at FarmersAlmanac.com. If you have any questions about this article, please leave a comment for one of our experts. Priority is given to our Members, but all are welcome! You may also write in with your article ideas: [email protected].&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45843146</guid><pubDate>Fri, 07 Nov 2025 03:01:32 +0000</pubDate></item><item><title>Leaving Meta and PyTorch</title><link>https://soumith.ch/blog/2025-11-06-leaving-meta-and-pytorch.md.html</link><description>&lt;doc fingerprint="257951fc50a404c0"&gt;
  &lt;main&gt;**Leaving Meta and PyTorch**
It's finally time...
November 6th, 2025
[https://soumith.ch/blog.html](https://soumith.ch/blog.html)
Eleven years at Meta. Nearly all my professional life. Making many friends for life. Almost eight years leading PyTorch, taking it from nothing to 90%+ adoption in AI. Walking away from this was one of the hardest things I've ever done. But I'm leaving with a full heart.
PyTorch handles exascale training now. It powers foundation models that are redefining intelligence. It's in production at virtually every major AI company. It's taught in classrooms from MIT to rural India. The tools I dreamed about making accessible? They are. The barrier to entry I wanted to lower? It's almost gone.
To be clear, there’s so much more to do. As long as AI evolves at a breakneck pace, PyTorch will continue to play catch up. Obsessing over the yet-to-come sometimes makes us forget how much we’ve already done.
To everyone who built this with me—who believed research should be joyful, that tools should be elegant, that open source changes everything—thank you. This wasn't my journey. It was ours.
What's next for me? Something small. Something new. Something I don't fully understand yet. Something uncomfortable. I could have moved to something else inside Meta. But I needed to know what's out there. I needed to do something small again. I couldn't live with the counterfactual regret of never trying something outside Meta.
It's very hard to leave. I probably have one of the AI industry’s most leveraged seats, I lead the software layer that powers the entire AI industry. Every major AI company and hardware vendor are on a speed dial. This kind of power is really hard to give up. But curiosity ultimately won out in my head.
Keep making AI delicious and accessible. I'll be watching. Probably filing issues. Definitely staying involved.
# Is PyTorch going to be okay?
I don't want to be doing PyTorch forever. I don't want to be like Guido or Linus— bound to a single thing for decades. Last November, coinciding with the birth of my daughter, I started planning my exit with Aparna. My goal was to leave PyTorch in a good and stable place.
By this August, during the second half of my parental leave, I knew: Edward, Suo, Alban, Greg, John, Joe and Jana were ready. The team faced hard people, product, technical and organizational problems and didn’t feel the need to lean back on me to solve these for them (unlike in the past). The product story they crafted for the PyTorch Conference was coherent—really coherent. The things I'd flagged red were turning healthy. The project didn't need me anymore. Unlike 2020-2022 (when I stepped down to go do robotics and came back when Lin, Dima and Dwarak left), I have strong confidence that this time PyTorch is truly resilient. The most aligned culture carriers of PyTorch – Greg, Alban, Ed, Jason and Joe are at the decision table now, and people with strong value alignment – Suo, John and Jana have joined them at the table. And there’s a long list of equally value-aligned people willing to sit at the table should any of these people leave. There are many little things that make up my confidence on the people – John worked on Julia and open-source for a very long time (in fact we hacked a Torch.jl in 2015), Suo has been the strongest systems builder and strategic partner I’ve had for the past two years, and Jana worked on resilient core systems for a very long time, I’ve had long technical and organizational discussions with her over the past few months that give me confidence. And the product lineup and execution in 2025 should be sufficient evidence for any remaining doubt.
I’m confident that this band of PyTorchers are going to do exceptionally well. PyTorch might change in flavor because I no longer impose my own taste from the top, but I’m confident that the values are going to stay intact and the product is going to be awesome.
---
# My time at Meta
The early years of FAIR were absolutely magical. I was part of a small family of absolutely brilliant people building state-of-the-art AI out in the open. From working on GANs with Remi Denton, Arthur Szlam, Rob Fergus, Leon Bottou, Martin Arjovsky and the (now legendary) Alec Radford to building Starcraft bots with Gabriel Synnaeve, to building the first FAIR Cluster with Howard Mansell, to working on object detection with Adam Lerer and Piotr Dollar, to building PyTorch. It was more fun than I can describe in words. 2015 and 2016 were probably the most productive and professionally enjoyable years of my life. I’ll probably romanticize this period of my life forever.
When I joined FAIR, I had massive impostor syndrome, and the first 3 months were very very difficult. I can’t credit Andrew Tulloch enough for being the most thoughtful, kind and welcoming mentor, without whom I wouldn’t have made it. I’m so damn bullish for Meta just from the fact that he’s back.
---
My time on PyTorch was special.
I loved every part of building it—designing it, managing it, being the PM, TL, comms lead, doc engineer, release engineer, squashing bugs, growth hacking, turning it into a coherent product with hundreds of people, transitioning it to industry stakeholdership – the whole nine yards.
To the core PyTorch team at Meta: the engineers, researchers, open-source maintainers, docs writers, CI infrastructure folks, hardware partners, the community builders. To the hundreds more inside and outside Meta—thank you. You turned a library into a movement.
There are too many people to credit and thank, but I can't not mention Adam Paszke, Sam Gross, Greg Chanan, Joe Spisak, Alban Desmaison, Edward Yang, Richard Zou, Tongzhou Wang, Francisco Massa, Luca Antiga, Andreas Köpf, Zach DeVito, Zeming Lin, Adam Lerer, Howard Mansell and Natalia Gimelshein. And Schrep. They made the launch happen. And so many more people became centrally important later: Lu Fang, Xiaodong Wang, Junjie Bai, Nikita Shulga, Horace He, Mark Saroufim, Jason Ansel, Dmytro Dzhulgakov, Yangqing Jia, Geeta Chauhan, Will Constable, Briah Hirsh, Jane Xu, Mario Lezcano, Piotr Balecki, Yinghai Lu, Less Wright, Andrew Tulloch, Bruce Lin, Woo Kim, Helen Suk, Chris Gottbrath, Peng Wu, Joe Isaacson, Eli Uriegas, Tristan Rice, Yanan Cao, Elias Ellison, Animesh Jain, Peter Noordhuis, Tianyu Liu, Yifu Wang, Lin Qiao and hundreds more. It’s criminal of me to not take the space to list out everyone else I should be mentioning here. PyTorch is nothing without its people ❤️.
The most joyful moments of building PyTorch was meeting users eager to share their happiness, love and feedback. I remember a grad student coming to me at Neurips 2017, in a slurring emotional voice he said he’d been trying to make progress on his research for 3 years but within 3 months of using PyTorch he made so much progress that he was ready to graduate. That moment made it tangible that what we do matters, a lot, to a lot of people, even if you don't constantly hear from them. I do miss the intimacy of the PyTorch community, with a 300 person conference that felt like an extended family gathering, but I feel that’s a small price to pay considering the scale of impact PyTorch is truly having today – yes the Conference is now 3,000 people where market-moving deals get brokered, but it’s helping orders of magnitude more people to do their best AI work. I miss the intimacy, but I'm proud of that growth.
---
To Mark Zuckerberg and Mike Schroepfer, who believed that open-sourcing is fundamentally important and is a sound business strategy. This is so hard to understand for most people within the course of business, but we’ve run lock-step on this strategy without ever having to discuss it. Without you two, neither FAIR nor PyTorch would’ve happened. And those mean so much to me.
To Yann LeCun and Rob Fergus, for building the magical early FAIR that I so revere.
To Aparna Ramani, a leader that I find so rare at Meta in her ability to hold a really high bar for the org, technically brilliant with the span to discuss deep infra systems and industry-strategy within the same conversation and for being an absolute execution-machine! I’ve learned so much from you.
To Santosh, Kaushik, Delia, Oldham and Ben for being so welcoming to Infra. For someone coming over from FAIR with a wildly different culture, you all made me feel at home and made me part of the family, and thank you for that.
To all my managers who've championed me through the PSC video game – Serkan, Howard, Jerome, Abhijit, Yoram, Joelle, Aparna and Damien – I owe you a lifetime of drinks.
---
Signing off for now.
—Soumith&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45843948</guid><pubDate>Fri, 07 Nov 2025 06:14:50 +0000</pubDate></item><item><title>Sweep (YC S23) is hiring to build autocomplete for JetBrains</title><link>https://www.ycombinator.com/companies/sweep/jobs/8dUn406-founding-engineer-intern</link><description>&lt;doc fingerprint="80a610e7c8dc27cd"&gt;
  &lt;main&gt;
    &lt;p&gt;The best AI coding assistant for JetBrains&lt;/p&gt;
    &lt;p&gt;We’re building an AI coding assistant for JetBrains IDEs.&lt;/p&gt;
    &lt;p&gt;You'll work with great builders on some of the hardest and most user-facing problems in AI today.&lt;/p&gt;
    &lt;p&gt;Whether an internship or full-time position, you'll work from our office in Dogpatch five days a week in-person.&lt;/p&gt;
    &lt;p&gt;Take https://github.com/JetBrains/intellij-platform-plugin-template and build something like GitHub Copilot autocomplete for JetBrains. Figure out how to do this quickly!&lt;/p&gt;
    &lt;p&gt;Sweep is the best enterprise AI coding assistant for JetBrains IDEs. No data ever leaves your VPC.&lt;/p&gt;
    &lt;p&gt;We have large customers in production. We ship fast.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45845568</guid><pubDate>Fri, 07 Nov 2025 12:00:40 +0000</pubDate></item><item><title>Meta projected 10% of 2024 revenue came from scams</title><link>https://sherwood.news/tech/meta-projected-10-of-2024-revenue-came-from-scams-and-banned-goods-reuters/</link><description>&lt;doc fingerprint="65c4990d8c33f59a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Meta projected 10% of 2024 revenue came from scams and banned goods, Reuters reports&lt;/head&gt;
    &lt;p&gt;Meta has been making billions of dollars per year from scam ads and sales of banned goods, according internal Meta documents seen by Reuters.&lt;/p&gt;
    &lt;p&gt;The new report quantifies the scale of fraud taking place on Meta’s platforms, and how much the company profited from them.&lt;/p&gt;
    &lt;p&gt;Per the report, Meta internal projections from late last year said that 10% of the company’s total 2024 revenue would come from scammy ads and sales of banned goods — which works out to $16 billion.&lt;/p&gt;
    &lt;p&gt;Discussions within Meta acknowledged the steep fines likely to be levied against the company for not stopping the fraudulent behavior on its platforms, and the company prioritized enforcement in regions where the penalties would be steepest, the reporting found. The cost of lost revenue from clamping down on the scams was weighed against the cost of fines from regulators.&lt;/p&gt;
    &lt;p&gt;The documents reportedly show that Meta did aim to significantly reduce the fraudulent behavior, but cuts to its moderation team left the vast majority of user-reported violations to be ignored or rejected.&lt;/p&gt;
    &lt;p&gt;Meta spokesperson Andy Stone told Reuters the documents were a “selective view” of internal enforcement:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“We aggressively fight fraud and scams because people on our platforms don’t want this content, legitimate advertisers don’t want it, and we don’t want it either.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Per the report, Meta internal projections from late last year said that 10% of the company’s total 2024 revenue would come from scammy ads and sales of banned goods — which works out to $16 billion.&lt;/p&gt;
    &lt;p&gt;Discussions within Meta acknowledged the steep fines likely to be levied against the company for not stopping the fraudulent behavior on its platforms, and the company prioritized enforcement in regions where the penalties would be steepest, the reporting found. The cost of lost revenue from clamping down on the scams was weighed against the cost of fines from regulators.&lt;/p&gt;
    &lt;p&gt;The documents reportedly show that Meta did aim to significantly reduce the fraudulent behavior, but cuts to its moderation team left the vast majority of user-reported violations to be ignored or rejected.&lt;/p&gt;
    &lt;p&gt;Meta spokesperson Andy Stone told Reuters the documents were a “selective view” of internal enforcement:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“We aggressively fight fraud and scams because people on our platforms don’t want this content, legitimate advertisers don’t want it, and we don’t want it either.”&lt;/p&gt;
    &lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45845772</guid><pubDate>Fri, 07 Nov 2025 12:39:54 +0000</pubDate></item><item><title>From Memorization to Reasoning in the Spectrum of Loss Curvature</title><link>https://arxiv.org/abs/2510.24256</link><description>&lt;doc fingerprint="2c9e24199ee382cf"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Computation and Language&lt;/head&gt;&lt;p&gt; [Submitted on 28 Oct 2025 (v1), last revised 31 Oct 2025 (this version, v2)]&lt;/p&gt;&lt;head rend="h1"&gt;Title:From Memorization to Reasoning in the Spectrum of Loss Curvature&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:We characterize how memorization is represented in transformer models and show that it can be disentangled in the weights of both language models (LMs) and vision transformers (ViTs) using a decomposition based on the loss landscape curvature. This insight is based on prior theoretical and empirical work showing that the curvature for memorized training points is much sharper than non memorized, meaning ordering weight components from high to low curvature can reveal a distinction without explicit labels. This motivates a weight editing procedure that suppresses far more recitation of untargeted memorized data more effectively than a recent unlearning method (BalancedSubnet), while maintaining lower perplexity. Since the basis of curvature has a natural interpretation for shared structure in model weights, we analyze the editing procedure extensively on its effect on downstream tasks in LMs, and find that fact retrieval and arithmetic are specifically and consistently negatively affected, even though open book fact retrieval and general logical reasoning is conserved. We posit these tasks rely heavily on specialized directions in weight space rather than general purpose mechanisms, regardless of whether those individual datapoints are memorized. We support this by showing a correspondence between task data's activation strength with low curvature components that we edit out, and the drop in task performance after the edit. Our work enhances the understanding of memorization in neural networks with practical applications towards removing it, and provides evidence for idiosyncratic, narrowly-used structures involved in solving tasks like math and fact retrieval.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Jack Merullo [view email]&lt;p&gt;[v1] Tue, 28 Oct 2025 10:09:35 UTC (2,148 KB)&lt;/p&gt;&lt;p&gt;[v2] Fri, 31 Oct 2025 00:26:33 UTC (2,148 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45845800</guid><pubDate>Fri, 07 Nov 2025 12:43:49 +0000</pubDate></item><item><title>We chose OCaml to write Stategraph</title><link>https://stategraph.dev/blog/why-we-chose-ocaml</link><description>&lt;doc fingerprint="e1d8bb0b2f1cafc4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why we chose OCaml to write Stategraph&lt;/head&gt;
    &lt;p&gt;We're building infrastructure that manages other people's infrastructure. State corruption can't be "rare." It has to be impossible. That's why we chose OCaml.&lt;/p&gt;
    &lt;p&gt;Stategraph stores Terraform state as a dependency graph in PostgreSQL with resource-level locking. The challenge isn't building a database-backed state store. The challenge is ensuring that concurrent operations can never corrupt state, even with concurrent operations/users, that database schema changes break the build instead of production, and that JSON transformations are correct.&lt;/p&gt;
    &lt;p&gt;We chose OCaml because its type system catches entire categories of bugs at compile time that would require extensive testing and still slip through in other languages.&lt;/p&gt;
    &lt;head rend="h2"&gt;Type-safe data structures&lt;/head&gt;
    &lt;p&gt;Here's a scenario every infrastructure engineer has seen. Two Terraform operations run concurrently and both read a resource in an &lt;code&gt;active&lt;/code&gt; state. One updates it while the other destroys it. Without proper coordination, you risk marking the resource as &lt;code&gt;destroyed&lt;/code&gt; in state while it's still being modified in the cloud.&lt;/p&gt;
    &lt;p&gt;Most systems handle this defensively with locks and runtime validation, but race conditions are hard to test and the resulting state corruption usually appears in production, not CI.&lt;/p&gt;
    &lt;p&gt;Stategraph tackles this in two ways. Immutability and database-level locking prevent concurrent writes from corrupting state, while OCaml's type system makes the underlying data structures themselves safer by construction. Resources, outputs, and instances are all defined as strongly-typed records, so you can't access a field that doesn't exist or mix up field types. The compiler enforces correctness before anything runs.&lt;/p&gt;
    &lt;p&gt;If you try to access &lt;code&gt;state.versions&lt;/code&gt; (typo) instead of &lt;code&gt;state.version&lt;/code&gt;, you get a compiler error. If you try to assign a string to &lt;code&gt;serial&lt;/code&gt;, you get a compiler error. If you forget to handle &lt;code&gt;None&lt;/code&gt; in the outputs field, you get a compiler error with exhaustiveness checking.&lt;/p&gt;
    &lt;p&gt;This extends throughout the codebase. Every Terraform resource type, every state transition, and every database record is strongly typed. The compiler catches entire categories of bugs at compile time, like accessing non-existent fields, missing null checks, or database schema mismatches.&lt;/p&gt;
    &lt;head rend="h2"&gt;The database schema drift problem&lt;/head&gt;
    &lt;p&gt;You're iterating on your database schema by renaming a column, changing a type, or adding a constraint. In most languages, you update the schema, deploy the migration, and hope you caught all the queries that reference the old structure. You didn't because a query somewhere references the old column name. It works in dev with the old schema but crashes in staging with the new schema.&lt;/p&gt;
    &lt;p&gt;Stategraph uses typed SQL where every query declares explicit types for its parameters and return values. When you change a query's type signature, every call site in the codebase must be updated to match, and the compiler enforces this.&lt;/p&gt;
    &lt;p&gt;This query expects specific types. The &lt;code&gt;state_id&lt;/code&gt; must be a UUID, &lt;code&gt;mode&lt;/code&gt; must be text, and &lt;code&gt;module_&lt;/code&gt; is optional text. The return value is typed as &lt;code&gt;bigint&lt;/code&gt;. If you try to pass a string where a UUID is expected, you get a compiler error. If you forget to handle the optional return value, you get a compiler error.&lt;/p&gt;
    &lt;p&gt;When you update a query to match a new schema, the type system ensures every place that calls that query gets updated too. You can't deploy code where query definitions and their usage are out of sync.&lt;/p&gt;
    &lt;head rend="h2"&gt;JSON transformations that can't lose data&lt;/head&gt;
    &lt;p&gt;Stategraph ingests Terraform state as JSON, normalizes it into a graph, stores it in PostgreSQL, and reconstructs it back to JSON when Terraform requests it. Every transformation is a place where data can get lost or corrupted, whether from a field you forgot to serialize, a nested structure you flattened incorrectly, or a type that doesn't round-trip.&lt;/p&gt;
    &lt;p&gt;Testing can catch some of this, and round-trip tests help, but you're fundamentally relying on test coverage. Missed cases show up when someone's Terraform state comes back missing a field.&lt;/p&gt;
    &lt;p&gt;OCaml has a feature called PPX (preprocessor extensions) that generates serialization code automatically. You define the type, and the serializer is generated from the type definition.&lt;/p&gt;
    &lt;p&gt;When you add a field, the serializer is regenerated. When you change a type, the serializer is regenerated. If you forget to handle a case, the exhaustiveness checker catches it at compile time. You don't write serialization tests because the type system guarantees serialization is correct.&lt;/p&gt;
    &lt;p&gt;This is how Stategraph handles Terraform's resource types. Every AWS resource, every GCP resource, every Azure resource is an OCaml type with automatic JSON serialization. We don't write serialization code. We don't test round-trips manually. The type system handles it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Race conditions prevented by default&lt;/head&gt;
    &lt;p&gt;Terraform operations are inherently concurrent. Multiple users apply changes, CI pipelines run in parallel, and drift detection scans resources continuously. Coordinating all of this without data races requires careful mutex management and defensive programming, and it's easy to get wrong.&lt;/p&gt;
    &lt;p&gt;OCaml provides immutability by default, so you can't accidentally share mutable state between concurrent operations because there is no mutable state by default. When you want to modify something, you create a new version explicitly. This eliminates entire categories of race conditions.&lt;/p&gt;
    &lt;p&gt;One operation can't corrupt another operation's view of state because state is immutable by default. When combined with PostgreSQL's row-level locking at the database layer, concurrent operations compose correctly without manual mutex management or defensive copying.&lt;/p&gt;
    &lt;head rend="h2"&gt;Error handling with discipline&lt;/head&gt;
    &lt;p&gt;Type safety is only half of what makes Stategraph robust. The other half is discipline in how we use those types.&lt;/p&gt;
    &lt;p&gt;We encode errors as variants and exhaustively match every case. We never use a catch-all "else" clause that matches everything. When we add a new error to the system, the compiler tells us every place we aren't handling it. This is how robust systems are built. Systems can fail in far more ways than they succeed, and the compiler ensures we handle all of them.&lt;/p&gt;
    &lt;p&gt;This discipline extends throughout the codebase. Every error case is explicit. Every state transition is enumerated. Every optional value is handled. The type system gives us the tools, but discipline is what turns those tools into reliability.&lt;/p&gt;
    &lt;head rend="h2"&gt;The difference in practice&lt;/head&gt;
    &lt;p&gt;The same categories of bugs. Different places to catch them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Production systems that can't afford bugs&lt;/head&gt;
    &lt;p&gt;This isn't academic type theory. Production systems use OCaml for exactly this reason.&lt;/p&gt;
    &lt;p&gt;At Terrateam, we process thousands of concurrent Terraform operations daily, managing infrastructure for hundreds of organizations where a state corruption bug would cascade across every customer. We're built on OCaml, and the type system catches bugs at compile time that would be production incidents in other languages.&lt;/p&gt;
    &lt;p&gt;Jane Street trades billions daily on OCaml infrastructure. Their trading systems handle concurrent market data and execute trades with zero tolerance for race conditions or undefined behavior. They chose OCaml because correctness isn't optional.&lt;/p&gt;
    &lt;head rend="h4"&gt;Pattern Recognition&lt;/head&gt;
    &lt;p&gt;Systems that absolutely cannot fail choose languages where certain failures are impossible, not just unlikely. Testing finds bugs, but types prevent entire categories of bugs from existing.&lt;/p&gt;
    &lt;head rend="h2"&gt;But who knows OCaml?&lt;/head&gt;
    &lt;p&gt;This is the most common objection, and OCaml developers are rare. This is true.&lt;/p&gt;
    &lt;p&gt;But here's what we've found. Engineers who understand distributed systems, type systems, and correctness learn OCaml quickly. The learning curve from Rust, Haskell, or even TypeScript with advanced types is gentler than you'd expect because the concepts transfer even if the syntax is unfamiliar.&lt;/p&gt;
    &lt;p&gt;More importantly, OCaml codebases are stable. We're not debugging race conditions or chasing down production crashes from schema drift. We're not writing extensive test suites for serialization edge cases. We're building features while the type system handles the category of bugs that would otherwise consume engineering time.&lt;/p&gt;
    &lt;p&gt;When you encode correctness in types, maintenance gets easier instead of harder. New engineers spend less time understanding implicit invariants and more time writing code the compiler verifies.&lt;/p&gt;
    &lt;head rend="h2"&gt;Correctness as a feature&lt;/head&gt;
    &lt;p&gt;We're building Stategraph to manage Terraform state for infrastructure that runs production applications. State corruption has to be impossible instead of unlikely. Invalid state transitions need to be prevented by the compiler instead of caught by tests. Schema drift needs to break the build instead of production.&lt;/p&gt;
    &lt;p&gt;That's what OCaml gives us. It provides a type system that makes entire categories of bugs impossible instead of just unlikely. The compiler proves properties about our code that testing can only approximate.&lt;/p&gt;
    &lt;p&gt;OCaml's compile-time guarantees are why we use it to build Stategraph.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45845958</guid><pubDate>Fri, 07 Nov 2025 13:10:49 +0000</pubDate></item><item><title>OpenMW 0.50.0 Released – open-source Morrowind reimplementation</title><link>https://openmw.org/2025/openmw-0-50-0-released/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45846090</guid><pubDate>Fri, 07 Nov 2025 13:25:27 +0000</pubDate></item><item><title>I'm Making a Small RPG and I Need Feeback Regarding Performance</title><link>https://jslegenddev.substack.com/p/im-making-a-small-rpg-and-i-need</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45846360</guid><pubDate>Fri, 07 Nov 2025 13:52:39 +0000</pubDate></item><item><title>I Love OCaml</title><link>https://mccd.space/posts/ocaml-the-worlds-best/</link><description>&lt;doc fingerprint="e7b610ff8bbeacc1"&gt;
  &lt;main&gt;
    &lt;p&gt;pub rsa4096 2023-09-22 [SC]&lt;/p&gt;
    &lt;p&gt;uid Marc Coquand &amp;lt;marc@mccd.space&amp;gt;&lt;/p&gt;
    &lt;p&gt;Every morning, I wake up and ask myself: why isn’t OCaml more popular? I mean, the language is not perfect, but the more I use it the more I feel like this old language had it all figured out, somehow. I mean, not in the literal sense: you write &lt;code&gt;String.of_X&lt;/code&gt;
instead of &lt;code&gt;String.from_X&lt;/code&gt; because the language has French
origins. But it is perfect in the sense that it has everything that is
important to me, except popular adoption. OCaml has its quirks, its old
age, but at the same time there is so much I appreciate about it.&lt;/p&gt;
    &lt;p&gt;I have some experience building amateur and professional software, in many different languages, and as a result I have collected a list of characteristics that I’ve come to appreciate over time. I think my journey into programming is different from many. I learned and adored functional programming before working in the industry, and while not my very first language, Haskell was important to me early on. Functional programming has allowed me to break big, complex problems down into subproblems that I know how to solve. It has made me a better thinker. Add to that the static guarantees of Haskell, which makes the mental overhead much lower than for other languages, and I am also more productive. Most importantly, with Haskell, I can focus more on the fun parts of programming.&lt;/p&gt;
    &lt;p&gt;However, Haskell’s issues lie in its immense complexity and slow compile times. I did say that Haskell lowers the mental overhead of programming, but that’s only if you use a small subset of the language. However because much of the community is very maximalist, introducing a lot of complexity into the code becomes inevitable. Much of the code you interact with is too “smart”, and becomes very hard to grok. Its runtime is also very complex, and there’s always the chance of running into notorious “space leaks”, that are extremely hard to debug.&lt;/p&gt;
    &lt;p&gt;At some point, I started exploring a language that is probably the polar opposite to Haskell: Go. With Go, I learned to appreciate simplicity and low-levels of abstractions, a good set of tooling, fast performance and fast compilation speed. I also started to appreciate good documentation that is easily available offline. The culture around Go also places a lot of value on simple solutions, which made interacting with the ecosystem easier. I can jump into any code base and understand what is happening.&lt;/p&gt;
    &lt;p&gt;Over time, I also grew to hate the issues that come with the language being so conservative: it is verbose in its error handling yet manages to be fragile. At the same time, it doesn’t have explicit null checks. These factors combined makes Go quite unpleasant and easy to write buggy code in. I also found myself missing a REPL or fast way of interacting with the program. The language is “predictably disappointing”, which I guess is a good thing. However, the solutions to those disappointments have been around before the language was even created and I am just left feeling that these solutions could have been implemented, and the compiler would not be much more complex as a result. It just genuinely felt like the Go language designers didn’t want to engage with any of the ideas coming from functional programming. But I digress.&lt;/p&gt;
    &lt;p&gt;From these experiences, a list of features I consider to be “good” features in a general programming language started to emerge:&lt;/p&gt;
    &lt;p&gt;And then, enter OCaml. This language just checks so many boxes:&lt;/p&gt;
    &lt;p&gt;I’m left feeling that the authors of OCaml have good taste. It is an old language, and there are a few features that could probably be left out like the OOP-related features, and some libraries in the ecosystem over-complicate things like in Haskell. But overall, it’s just damn good. There are a lot of other features I appreciate about OCaml that I didn’t share. But to summarize why I love it: the right balance between simple and expressive, good documentation and good tooling.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45846517</guid><pubDate>Fri, 07 Nov 2025 14:05:49 +0000</pubDate></item><item><title>A.I. and Social Media Contribute to 'Brain Rot'</title><link>https://www.nytimes.com/2025/11/06/technology/personaltech/ai-social-media-brain-rot.html</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45847465</guid><pubDate>Fri, 07 Nov 2025 15:34:33 +0000</pubDate></item><item><title>Denmark's government aims to ban access to social media for children under 15</title><link>https://apnews.com/article/denmark-social-media-ban-children-7862d2a8cc590b4969c8931a01adc7f4</link><description>&lt;doc fingerprint="3597dbb93484dfc9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Denmark’s government aims to ban access to social media for children under 15&lt;/head&gt;
    &lt;head rend="h2"&gt;Denmark’s government aims to ban access to social media for children under 15&lt;/head&gt;
    &lt;p&gt;Denmark’s government on Friday announced an agreement to ban access to social media for anyone under 15, ratcheting up pressure on Big Tech platforms as concerns grow that kids are getting too swept up in a digitized world of harmful content and commercial interests.&lt;/p&gt;
    &lt;p&gt;The move would give some parents — after a specific assessment — the right to let their children access social media from age 13. It wasn’t immediately clear how such a ban would be enforced: Many tech platforms already restrict pre-teens from signing up. Officials and experts say such restrictions don’t always work.&lt;/p&gt;
    &lt;p&gt;Such a measure would be among the most sweeping steps yet by a European Union government to limit use of social media among teens and younger children, which has drawn concerns in many parts of an increasingly online world.&lt;/p&gt;
    &lt;p&gt;Speaking to The Associated Press, Caroline Stage, Denmark’s minister for digital affairs, said 94% of Danish children under age 13 have profiles on at least one social media platform, and more than half of those under 10 do.&lt;/p&gt;
    &lt;p&gt;“The amount of time they spend online — the amount of violence, self-harm that they are exposed to online — is simply too great a risk for our children,” she said, while praising tech giants as “the greatest companies that we have. They have an absurd amount of money available, but they’re simply not willing to invest in the safety of our children, invest in the safety of all of us.”&lt;/p&gt;
    &lt;head rend="h2"&gt;No rush to legislation, no loopholes for tech giants&lt;/head&gt;
    &lt;p&gt;Stage said a ban won’t take effect immediately. Allied lawmakers on the issue from across the political spectrum who make up a majority in parliament will likely take months to pass relevant legislation.&lt;/p&gt;
    &lt;p&gt;“I can assure you that Denmark will hurry, but we won’t do it too quickly because we need to make sure that the regulation is right and that there is no loopholes for the tech giants to go through,” Stage said. Her ministry said pressure from tech giants’ business models was “too massive.”&lt;/p&gt;
    &lt;p&gt;It follows a move in December in Australia, where parliament enacted the world’s first ban on social media for children — setting the minimum age at 16.&lt;/p&gt;
    &lt;p&gt;That made platforms including TikTok, Facebook, Snapchat, Reddit, X and Instagram subject to fines of up to 50 million Australian dollars ($33 million) for systemic failures to prevent children younger than 16 from holding accounts.&lt;/p&gt;
    &lt;p&gt;Officials in Denmark didn’t say how such a ban would be enforced in a world where millions of children have easy access to screens. But Stage noted that Denmark has a national electronic ID system — nearly all Danish citizens over age 13 have such an ID — and plans to set up an age-verification app. Several other EU countries are testing such apps.&lt;/p&gt;
    &lt;p&gt;“We cannot force the tech giants to use our app, but what we can do is force the tech giants to make proper age verification, and if they don’t, we will be able to enforce through the EU commission and make sure that they will be fined up to 6% of their global income.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Aiming to shield kids from harmful content online&lt;/head&gt;
    &lt;p&gt;Many governments have been grappling with ways of limiting harmful fallout from online technologies, without overly squelching their promise. Stage said Denmark’s legislative push was “not about excluding children from everything digital” — but keeping them away from harmful content.&lt;/p&gt;
    &lt;p&gt;China — which manufacturers many of the world’s digital devices — has set limits on online game time and smart-phone time for kids.&lt;/p&gt;
    &lt;p&gt;Prosecutors in Paris this week announced an investigation into allegations that TikTok allows content promoting suicide and that its algorithms may encourage vulnerable young people to take their own lives.&lt;/p&gt;
    &lt;p&gt;“Children and young people have their sleep disrupted, lose their peace and concentration, and experience increasing pressure from digital relationships where adults are not always present,” the Danish ministry said. “This is a development that no parent, teacher or educator can stop alone.”&lt;/p&gt;
    &lt;p&gt;The EU’s Digital Services Act, which took effect two years ago, forbids children younger than 13 to hold accounts on social media like TikTok and Instagram, video sharing platforms like YouTube and Twitch, and sites like Reddit and Discord, as well as AI companions.&lt;/p&gt;
    &lt;p&gt;Many social media platforms have for years banned anyone 13 or under from signing up for their services. TikTok users can verify their ages by submitting a selfie that will be analyzed to estimate their age. Meta Platforms, parent of Instagram and Facebook, says it uses a similar system for video selfies and AI to help figure out a user’s age.&lt;/p&gt;
    &lt;p&gt;Meta and TikTok didn’t respond immediately to requests for comment from the AP.&lt;/p&gt;
    &lt;p&gt;“We’ve given the tech giants so many chances to stand up and to do something about what is happening on their platforms. They haven’t done it,” said Stage, the Danish minister. “So now we will take over the steering wheel and make sure that our children’s futures are safe.”&lt;/p&gt;
    &lt;p&gt;___&lt;/p&gt;
    &lt;p&gt;AP Business Writer Kelvin Chan contributed to this report.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45848083</guid><pubDate>Fri, 07 Nov 2025 16:28:31 +0000</pubDate></item><item><title>Toxic Salton Sea dust triggers changes in lung microbiome after just one week</title><link>https://phys.org/news/2025-10-toxic-salton-sea-triggers-lung.html</link><description>&lt;doc fingerprint="fc1c63126c290be5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Toxic Salton Sea dust triggers changes in lung microbiome after just one week&lt;/head&gt;
    &lt;head rend="h5"&gt;Lisa Lock&lt;/head&gt;
    &lt;p&gt;scientific editor&lt;/p&gt;
    &lt;head rend="h5"&gt;Robert Egan&lt;/head&gt;
    &lt;p&gt;associate editor&lt;/p&gt;
    &lt;p&gt;Dust from California's drying Salton Sea doesn't just smell bad. Scientists from UC Riverside found that breathing the dust can quickly re-shape the microscopic world inside the lungs.&lt;/p&gt;
    &lt;p&gt;Genetic or bacterial diseases have previously been shown to have an effect on lung microbes. However, this discovery marks the first time scientists have observed such changes from environmental exposure rather than a disease.&lt;/p&gt;
    &lt;p&gt;Published in the journal mSphere, the study shows that inhalation of airborne dust collected close to the shallow, landlocked lake alters both the microbial landscape and immune responses in mice that were otherwise healthy.&lt;/p&gt;
    &lt;p&gt;"Even Salton Sea dust filtered to remove live bacteria or fungi is altering what microbes survive in the lungs," said Mia Maltz, UCR mycologist and lead study author. "It is causing deep changes to our internal environment."&lt;/p&gt;
    &lt;p&gt;Scientists have studied the gut microbiome extensively, linking it to digestion, immunity, and even mental state. In contrast, the lung microbiome remains less well understood, though it's increasingly seen as important to overall health.&lt;/p&gt;
    &lt;p&gt;"Our lab studies discovered that the dust generated at the Salton Sea can have significant health effects especially in the lung, and it is likely a major factor in the high incidence of asthma in the nearby communities," said David Lo, a UCR distinguished professor of biomedical sciences and study author.&lt;/p&gt;
    &lt;p&gt;The researchers collaborated on the design of an exposure chamber that mimicked real-world air conditions. The team collected dust samples both closer to and farther from the Salton Sea, then exposed mice to the aerosolized particles during a series of one-week trials.&lt;/p&gt;
    &lt;p&gt;There were some clues about ill effects even before deeper analysis.&lt;/p&gt;
    &lt;p&gt;"Salton Sea residents have ongoing suspicions that the environment is linked to respiratory illness, and our lab has definitely felt the effects of the heat, dustiness, and pungent air while out there on field work," said Talyssa Topacio, UCR graduate student and co-first author of the paper.&lt;/p&gt;
    &lt;p&gt;"The dust also just doesn't smell good," said Emma Aronson, UCR environmental microbiologist and study author. "When we were processing it in the lab, it could be stinky."&lt;/p&gt;
    &lt;p&gt;Among the bacterial species that proliferated among mice exposed to the sea dust were Pseudomonas and Staphylococcus, both linked to respiratory inflammation. The most affected samples were rich in bacteria that produce LPS, a molecular residue on their outer membranes known to trigger immune responses.&lt;/p&gt;
    &lt;p&gt;"We think microbial products like LPS are part of what's causing the inflammation," Maltz said. "It's like breathing in a chemical fingerprint of dead bacteria."&lt;/p&gt;
    &lt;p&gt;Some dust samples were especially potent. In one case, up to 60% of lung immune cells contained markers of neutrophil activation, showing aggressive inflammation. In mice breathing filtered air, levels of neutrophils were only 10% to 15%.&lt;/p&gt;
    &lt;p&gt;Aronson said the findings challenge longstanding assumptions in pulmonary science. "We've seen these kinds of microbial shifts in people with cystic fibrosis or infections," she said. "But these mice had no pre-existing conditions. This was a clean slate, and it still happened."&lt;/p&gt;
    &lt;p&gt;As the Salton Sea lakebed continues to dry, more of its toxic sediment becomes airborne. The research group is examining whether similar microbial shifts occur in local children.&lt;/p&gt;
    &lt;p&gt;"Breathing in the dust over time may have chronic impacts in the lung, and these studies on the potential for altering the lung microbiome are an important first step in identifying factors that could lead to asthma and other chronic diseases," Lo said.&lt;/p&gt;
    &lt;p&gt;The research also raises broader questions. If dust can alter lung microbes, what about smoke, exhaust, or vaping aerosols? The researchers plan to test whether other exposures cause similar disruptions.&lt;/p&gt;
    &lt;p&gt;This study relied on a method Maltz developed over four years to isolate microbial DNA from host tissue, enabling a more detailed look at the lung microbiome than ever before. The next step is to determine whether protective species are being lost, and how long any noticeable changes to the microbiome persist.&lt;/p&gt;
    &lt;p&gt;"We've only just begun to understand how dust exposure changes the lung microbiome," Maltz said. "We don't yet know how long the changes last, or whether they're reversible. That's another big question."&lt;/p&gt;
    &lt;p&gt;More information: Mia R. Maltz et al, Lung microbiomes' variable responses to dust exposure in mouse models of asthma, mSphere (2025). DOI: 10.1128/msphere.00209-25. journals.asm.org/doi/10.1128/msphere.00209-25&lt;/p&gt;
    &lt;p&gt;Provided by University of California - Riverside&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45848341</guid><pubDate>Fri, 07 Nov 2025 16:52:05 +0000</pubDate></item><item><title>Nasdaq 100 set for worst week since April meltdown</title><link>https://fortune.com/2025/11/07/nasdaq-100-worst-week-since-april-bear-market-correction/</link><description>&lt;doc fingerprint="fdcc49bf8db40fae"&gt;
  &lt;main&gt;
    &lt;p&gt;A risk-off week on Wall Street is drawing to a close, with some of the most-expensive areas of the market driving stocks lower while a renewed slide in crypto leaves the asset class barely up for 2025.&lt;/p&gt;
    &lt;p&gt;Equities fell on Friday, with the S&amp;amp;P 500 set to halt a streak of three weeks of gains as a gauge of US consumer sentiment sank to a more than three-year low. Things were even worse for the Nasdaq 100 as a rout in artificial-intelligence winners put the tech-heavy measure on track for its worst week since the April tariff-fueled tantrum – when the index entered a bear market.&lt;/p&gt;
    &lt;p&gt;Worries about valuations in AI high-flyers reaching unsustainable levels surfaced after a torrid surge from this year’s bottom spurred calls for a breather. Technical indicators started flagging reasons for caution, adding to the drag on sentiment from warnings by Wall Street chief executives about a frothy market.&lt;/p&gt;
    &lt;p&gt;“Major indices are facing selling pressure this week,” said Craig Johnson at Piper Sandler. “Investors should prioritize good risk/reward setups, potentially after a healthy pullback within this bull market.”&lt;/p&gt;
    &lt;p&gt;This week’s slide also comes at a time when earnings season is winding down, with investors becoming reliant on private data amid a dearth of economic figures due to the ongoing government shutdown. That’s left the market vulnerable to volatility as it happened in the previous session with a report painting a bleak jobs picture.&lt;/p&gt;
    &lt;p&gt;While the US payrolls report was not released this Friday due to the shutdown, a survey conducted by 22V Research showed that a labor-market unwind is the biggest risk to trading. That explains why risk assets and bond yields have been unusually sensitive to any news data on that front.&lt;/p&gt;
    &lt;p&gt;The S&amp;amp;P 500 fell to around 6,670. The Nasdaq 100 slid 1.1%. A gauge of the Magnificent Seven megacaps sank 1.8%.&lt;/p&gt;
    &lt;p&gt;Bitcoin extended this week’s slide to 9%. The yield on 10-year Treasuries was little changed at 4.09%. The dollar lost 0.2%.&lt;/p&gt;
    &lt;p&gt;“While there is no jobs report Friday due to the government shutdown, there is enough private payroll and layoff data to suggest that the labor market is cooling,” said Glen Smith at GDS Wealth Management. “This cooling keeps the Fed’s rate cut plans alive for December and potentially into early 2026.”&lt;/p&gt;
    &lt;p&gt;The economy remains on an upward trajectory even if economic growth slows toward trend levels in 2026, according to Seema Shah at Principal Asset Management.&lt;/p&gt;
    &lt;p&gt;“The bigger concern — and the key focus of the Fed’s debate —will be the health of the labor market,” she said. “We anticipate the Fed will continue to implement rate cuts to prevent any weakness in employment from accelerating. Much of the market’s optimism hinges on the assumption that policymakers will maintain some level of support.”&lt;/p&gt;
    &lt;p&gt;Despite the slide, flows remain supportive. US equity funds had an eighth consecutive week of inflows, the longest streak this year, but cash attracted the bulk of inflows, Bank of America Corp. said citing citing EPFR Global data.&lt;/p&gt;
    &lt;p&gt;Traders are pondering a moment of weakness embedded in a multi-month rip higher for stocks, yet the market on balance looks poised for further gains, said Goldman Sachs Group Inc.’s Tony Pasquariello.&lt;/p&gt;
    &lt;p&gt;“I’m not saying that risk/reward is overly compelling, nor that this is an ideal location to add a bunch of incremental risk,” the head of hedge fund coverage at Goldman Sachs wrote in a note to clients Wednesday. “Looking forward, I’d argue the balance of risks still points in favor of the bulls.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45848428</guid><pubDate>Fri, 07 Nov 2025 16:59:49 +0000</pubDate></item><item><title>Angel Investors, a Field Guide</title><link>https://www.jeanyang.com/posts/angel-investors-a-field-guide/</link><description>&lt;doc fingerprint="b194193319d635e0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Angel Investors, A Field Guide&lt;/head&gt;
    &lt;p&gt;I’ve been lucky to work with some of the best angel investors in the business.&lt;/p&gt;
    &lt;p&gt;When I started Akita, my angel investors were my mentor Jason Hong, superangel Elad Gil, #ANGELS co-founder Jana Messerschmidt, Eventbrite co-founders Kevin and Julia Hartz, Stanford professor Dan Boneh, and NBA player Kevin Durant. I became a more well-prepared and well-connected founder thanks to my angel investors.&lt;/p&gt;
    &lt;p&gt;When I first became a founder, I had little idea how much working with the right angel investors could help. This post is everything I would tell a first-time founder (who is headed down the VC-funded) route about working angels.&lt;/p&gt;
    &lt;head rend="h1"&gt;Akita’s fundraising story&lt;/head&gt;
    &lt;p&gt;The first check into my company was a SAFE from Jason Hong, a fellow CMU professor who has been an incredible mentor, both when I was in academia and after I became a founder. At the time, I had only been out of a PhD with a real job for two years and did not have the savings to bootstrap for long, so Jason’s investment was substantial. Jason’s uncapped SAFE gave me the runway to not worry about raising immediately.&lt;/p&gt;
    &lt;p&gt;Sooner than I expected, I raised a seed round co-led by Martin Casado at a16z and Mike Vernal at Sequoia. Once the round came together, there was only room for a small number of checks. Martin and Mike both advised strategic angels instead of friends and family to fill out the round, so that’s what we did. They put together a short list of angel investors who had been helpful to their companies and introduced me. We ultimately brought on Elad Gil, Jana Messerschmidt, Kevin and Julia Hartz, and Dan Boneh.&lt;/p&gt;
    &lt;p&gt;I was at dinner with my a16z investor Martin Casado when I told him I wanted investment from Kevin Durant. It was fall 2018, KD was playing for the Warriors, and he had won Finals MVP earlier that year. I was a KD fan and had heard he did tech investing. Martin said, “How sure are you that you want him?” He sent one text to someone who happened to be walking into KD’s house at that very moment. KD said congratulations and the following week I had Thirty-Five Ventures on my cap table.&lt;/p&gt;
    &lt;head rend="h1"&gt;My personal experience with angel investors&lt;/head&gt;
    &lt;p&gt;In 2017-2018, the first year of my company, Julia Hartz was running EventBrite so I worked with Kevin. This was before Kevin started his VC firm A*. During this time, he was spending a lot of time with founders and entrepreneurial folks. Kevin had incredible stories from his experience with Xoom and Eventbrite and I loved learning from him. One conversation that stuck with me: I was telling Kevin how my two lead investors had both interviewed a key product hire for the company. One was positive and one was in the middle. Kevin said to always be “strong yes” or “strong no” if I could help it. I still hire according to this philosophy today.&lt;/p&gt;
    &lt;p&gt;Jana Messerschmidt was probably my angel investor who was the most generous with her time and introductions. Jana was transitioning from doing angel investing to being a venture capital investor, having just started a job at Lightspeed. As a former exec at Twitter and Netflix, she had a fantastic network and especially in developer experience. Jana introduced me to developer experience executives, founders who had been good at developer experience, and ex-founders who gave great founder advice. Jana gave me great advice about how to leverage my investors: for instance, she told me to make a spreadsheet of customers I wanted warm introductions to and send it around. Jana telling me about how Crashlytics engineered themselves to go viral and introducing me to Jeff Seibert had a huge influence on how I think about developer products.&lt;/p&gt;
    &lt;p&gt;Elad was elusive but the angel who was most consistently influential and supportive during my entire five-year run at Akita. We had a fifteen-minute call almost every quarter, sometimes at an unpredictable time, but always full of great guidance. When I was pivoting the company in 2020, saying that my original space was not working, Elad reminded me it was working for other people, just not Akita, but that’s okay. When I was gearing up for what I knew would be a tough fundraise in 2023, Elad went to work, making introductions to several promising potential investors. Elad has somehow seen every single startup situation and knows so many different founders that he had something concise and on-point to say in every single situation.&lt;/p&gt;
    &lt;head rend="h1"&gt;Figuring out when and how to bring on angel investors&lt;/head&gt;
    &lt;p&gt;You can either think of angel investors as the first checks in, or filling out a round. In my case, I had both: Jason Hong’s check gave me runway as I figured out my fundraise. I met my strategic angels once I decided on my investors.&lt;/p&gt;
    &lt;p&gt;Having good angels early on can help you get advice and introductions early on. That said, a lot of folks in the ecosystem will pay it forward and help you even if they are not involved as angel investors. My earliest angel investor Jason Hong was definitely helpful to me early on with advice, book recommendations, and stories from when he started Wombat Security. I also learned a lot from other ex-founders who were generous enough to give me 30-60 minutes of their time. I also cashed in pretty much every favor from friends and family to meet potential investors and to get feedback on the early product. Most of these people weren’t investors!&lt;/p&gt;
    &lt;p&gt;Strategic angels. Strategic angels are who I filled my seed round out with after securing institutional VC investment. These are folks who you add to the cap table for complementary reasons to your institutional investors. Some strategic angels invest full-time; others are operators in a similar space to you. Some folks will bring on strategic angels for social proof. When it looked like the seed round was just going to be Martin from a16z, we had started throwing around names of angels that would be good for filling out the round. After we split the round with Sequoia, Martin told me the split alone was enough proof. We were able to then choose angels completely based on gaps in our networks and expertise.&lt;/p&gt;
    &lt;p&gt;Vanity angels. There’s a difference between a strategic angel and a vanity angel, a celebrity who invests in companies. These angel investors are less likely to be active in working with companies than institutional investors or strategic angels. They often have more name recognition to friends and family and junior hires. A lot of celebrities coinvest with major venture capital firms and many have their own family offices or investment staff. For instance, in working with Kevin Durant interfaced with his investment organization Thirty-Five Ventures, which was more extensive than I had initially expected. Folks will generally work in organizations like that if they have investing ambitions of their own and they were more helpful than I expected in offering introductions. I like the advice to have no more than one on your cap table.&lt;/p&gt;
    &lt;p&gt;Friends and family. Outside of my mentor Jason Hong, there is one kind of investor missing from my cap table: friends and family. My decision not to take friends or family investors for Akita came out of a personal hesitation to mix friendship with business. There was also little room left in the round by the time it got split between two institutional investors. In some of my tougher moments of Akita, the folks who ended up being the most motivated to help were the friends who had offered to invest, but who I didn’t end up working with as investors. In my own experience on the other side as an investor, the situation where I was probably the most helpful was one with a good personal friend, but it was also a situation where I would have probably given the same support regardless of the investing relationship. For me, jury’s still out about friends and family investors, if you’re also taking VC funding.&lt;/p&gt;
    &lt;head rend="h1"&gt;Leveraging your angel investors&lt;/head&gt;
    &lt;p&gt;When I first started working with Kevin Hartz, he said an investor relationship was like a gumball machine, except with help. You ask for help and you get help.&lt;/p&gt;
    &lt;p&gt;The best advice I have about working with your angel investors: get to know them. One to two times early on is enough to build a relationship. If they’re helpful, even 15-30 minutes once a quarter or half can go a long way. The more they know about where we are, the more they can help. Plus, these folks were way more experienced than I was with startups. Even offhand stories from their own startup experiences, or those of companies they worked with, were incredibly educational to me. The more they know about who you are, what you’re doing, and what you need, the more they can help. And the more you know about how they can help, the more you can lean on them for help.&lt;/p&gt;
    &lt;p&gt;The easiest way to keep in touch and stay top-of-mind for your investors: send monthly investor updates. The updates provide context to investors that help them help you: what stage the company is at, what the next big milestones are. At the end of each update, I would always put three to five specific requests for the investors, from helping with introductions to helping with hiring to helping amplify a launch. Upon the recommendation of one of my investors, I also put thank-yous to investors who helped the previous month. The combination of asks and shoutouts consistently got me helpful responses from my investors.&lt;/p&gt;
    &lt;p&gt;There’s also one more important thing to understand about angel investors: angels can help in ways that institutional investors cannot. There’s one major reason underlying this: if a VC investor is doing their job well, they will make sure to keep investing in your company until they have a good amount of ownership. This means it is against their incentives to introduce you to other investors or do anything else that interferes with their ability to buy more shares in your company for a good price. Angel investors, on the other hand, are generally not jockeying for a large portion of your next round and everybody knows it. This allows them to play a much bigger role in helping you fundraise, from introducing you to other VCs to talking up your company to generate more interest across different VCs.&lt;/p&gt;
    &lt;head rend="h1"&gt;My perspective from the other side&lt;/head&gt;
    &lt;p&gt;There’s a whole spectrum of how investors and companies work together and everybody will tell you something different, so I’ll end with telling you about my specific take on angel investing, in case that helps founders who are trying to learn how to think about the whole thing.&lt;/p&gt;
    &lt;p&gt;I angel invest primarily through my scouting relationship with the VC firm Andreesson Horowitz. They give me a budget for investing in each fund and I get a fraction of the carry. The goal is to invest in companies I’m excited about, that also fit the profile of high-growth companies a16z would be excited about. I started scouting for three reasons. First, it gives me more skin in the game to keep up with not only my space but adjacent spaces. Second, I’m happy to pay it forward if I can be helpful. Finally, startups have an unmatchable energy and great founders are fun to be around.&lt;/p&gt;
    &lt;p&gt;My criteria for companies I decide to work with: I’m excited about what they do and believe I can help. Angel investing is a hobby for me, so it’s really about where I get energy and what I want to be thinking about in my limited free time. I discovered I am almost exclusively interested in infra companies where the team is building a product in a B2B SaaS domain I’m familiar with. I particularly like product-led growth and I love developer tools. As for the specific companies, I need to first and foremost understand and believe in the problem they’re solving: it’s usually a problem space I’ve looked at myself, am interested in looking at, or have personally experienced. Then everything else I care about is fairly standard: how well is the team executing; do they have the differentiation necessary to take them all the way.&lt;/p&gt;
    &lt;head rend="h1"&gt;Parting words&lt;/head&gt;
    &lt;p&gt;If you’ve read all the way to the end of this post, you probably know way more than I did when I started Akita and brought on my angel investors. But I also recognize that I was extremely lucky and would like to help you create your own luck.&lt;/p&gt;
    &lt;p&gt;So if you’re going the VC-funded route, cap space will be limited, signalling matters a lot, and your network can go a long way in helping you signal. Choose your angels well and they can help you a lot! 😇&lt;/p&gt;
    &lt;p&gt;With thanks to Umesh Khanna, whose Forward Deployed Angels series got me thinking about the importance of demystifying the angel/founder relationship. Thanks Umesh for kicking off the series by featuring TLDC and me!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45848468</guid><pubDate>Fri, 07 Nov 2025 17:03:30 +0000</pubDate></item><item><title>Vodafone Germany is killing the open internet – one peering connection at a time</title><link>https://coffee.link/vodafone-germany-is-killing-the-open-internet-one-peering-connection-at-a-time/</link><description>&lt;doc fingerprint="3d713941592e09eb"&gt;
  &lt;main&gt;
    &lt;quote&gt;Editor's Note: This article is based on comprehensive research of publicly available sources including official press releases, regulatory filings, consumer complaints, technical forum discussions, academic studies, and industry publications. We may have failed in some areas to grasp the issue entirely. The reader is advised that not everything might be correct and you should follow the sources and conduct your own research to get an adequate understanding of the subject at hand.&lt;/quote&gt;
    &lt;p&gt;There's a reason your internet feels like magic. When you click a YouTube video in Berlin, that data doesn't travel some convoluted path through half of Europe to reach you. It flows through something called an "internet exchange point"—a giant room full of routers where hundreds of networks connect directly, swapping traffic efficiently and, crucially, for free.&lt;/p&gt;
    &lt;p&gt;Vodafone Germany is about to blow that system up.&lt;/p&gt;
    &lt;p&gt;By the end of 2025, Vodafone will have completely withdrawn from every public internet exchange in Germany, including DE-CIX Frankfurt, the largest internet exchange on the planet. Instead, all traffic will flow through a single company called Inter.link, which charges content providers based on how much data they send to Vodafone customers. It's the telecom equivalent of a landlord announcing they're demolishing all the sidewalks in town and replacing them with a private toll road.&lt;/p&gt;
    &lt;p&gt;Vodafone insists this will deliver "lower latencies, more resilience, and cost savings." But if you're a Vodafone customer, you might want to brace yourself. Because there's a decade of evidence from Deutsche Telekom—Germany's other telecom giant, which did almost exactly the same thing—suggesting you're about to experience internet hell.&lt;/p&gt;
    &lt;head rend="h2"&gt;The open internet was supposed to work differently&lt;/head&gt;
    &lt;p&gt;To understand why this matters, you need to understand how the internet actually works. And it's not how most people think.&lt;/p&gt;
    &lt;p&gt;When you pay for internet service, you're not buying access to some centralized "internet"—you're buying access to your ISP's network. That network then connects to thousands of other networks through a patchwork of agreements and connections. The magic happens at places like DE-CIX Frankfurt, where over 1,000 networks plug into the same switching fabric and exchange traffic directly.&lt;/p&gt;
    &lt;p&gt;This system is called "settlement-free peering," and it's one of the internet's foundational principles. No money changes hands. Networks exchange traffic roughly equally, everyone saves money on long-haul transit costs, and users get faster connections because data takes the shortest possible path.&lt;/p&gt;
    &lt;p&gt;When Deutsche Telekom customers want to watch YouTube, that traffic flows directly from Google's network to Deutsche Telekom's network at a Frankfurt exchange point—maybe four or five router hops, minimal latency, no intermediaries. It's elegant. It's efficient. And it's exactly what Vodafone is abandoning.&lt;/p&gt;
    &lt;head rend="h2"&gt;Enter the middleman&lt;/head&gt;
    &lt;p&gt;Instead of connecting directly to content providers at neutral exchange points, Vodafone is outsourcing all its peering to Inter.link, a Berlin-based company that operates what it calls a "peering-as-a-service" platform. Inter.link operates more than 40 points of presence across 15 countries and claims connectivity to 300+ data centers in Europe.&lt;/p&gt;
    &lt;p&gt;The pitch is automation. Instead of managing thousands of individual peering relationships, Vodafone gets "one-click provisioning" and "single sign-on access." For Vodafone's network operations team, this is genuinely simpler. But here's the thing: operational efficiency for a telecom company and good service for customers are not the same thing.&lt;/p&gt;
    &lt;p&gt;Vodafone's official press release from November 2024 emphasized that the partnership with Inter.link would "reduce time, resources, and peering costs" while delivering "lower latencies" and "more resilience." What the company didn't mention is that "peering costs" in this context doesn't mean Vodafone's costs—it means the costs have shifted to content providers, who now have to pay Inter.link if they want decent connectivity to Vodafone's customers.&lt;/p&gt;
    &lt;p&gt;And if a content provider decides not to pay? That's when things get ugly.&lt;/p&gt;
    &lt;head rend="h2"&gt;Deutsche Telekom's decade of documented disaster&lt;/head&gt;
    &lt;p&gt;Deutsche Telekom pioneered this model in Germany, and the results have been catastrophic for customers. Not "slightly annoying" or "a bit slower"—genuinely, documentably terrible.&lt;/p&gt;
    &lt;p&gt;Consumer protection organizations have collected hundreds of complaints describing systematic degradation. The pattern is consistent and damning:&lt;/p&gt;
    &lt;p&gt;Software and downloads: Windows 11 updates taking five to six hours instead of minutes. GitHub downloads at 680 KB/s on 100 Mbps connections—a 94.6% reduction from expected speeds. Websites protected by Cloudflare loading in 15 seconds to 2.5 minutes instead of under one second.&lt;/p&gt;
    &lt;p&gt;Gaming: Latency spiking from 20-30 milliseconds to 200-3,300 milliseconds during peak hours. Packet loss reaching 17-70% on some connections, making competitive gaming literally unplayable. When customers use VPNs to bypass Deutsche Telekom's routing, speeds instantly recover 100-fold—proving the problem isn't content provider infrastructure.&lt;/p&gt;
    &lt;p&gt;Time-based patterns: Services work fine in the morning when traffic is low, degrade catastrophically during 7-11 PM peak hours, then recover late at night. Network experts have identified the root cause: Deutsche Telekom deliberately refuses to upgrade interconnection capacity when links reach congestion, creating artificial bottlenecks to pressure content providers into paid agreements.&lt;/p&gt;
    &lt;p&gt;The evidence is so overwhelming that in April 2025, a coalition including Germany's federal consumer organization, digital rights groups, and Stanford Law School professor Barbara van Schewick filed formal complaints with the Federal Network Agency alleging net neutrality violations. The investigation is ongoing. Deutsche Telekom, for its part, denies everything while customers continue suffering through abysmal performance.&lt;/p&gt;
    &lt;p&gt;Now Vodafone is implementing the same model. That should terrify you if you're a Vodafone customer.&lt;/p&gt;
    &lt;head rend="h2"&gt;The warning signs are already appearing&lt;/head&gt;
    &lt;p&gt;The migration started in December 2024, and Vodafone customers are already reporting problems. A pattern emerges in forum posts and support tickets: complaints about service degradation beginning specifically in November-December 2024, escalating during evening hours, affecting streaming and gaming disproportionately.&lt;/p&gt;
    &lt;p&gt;One user on Vodafone's German forum documented "extreme ping issues" that "particularly escalated in recent weeks" in November 2024, with latency jumping from normal levels to 1,000-2,000 milliseconds. Another described complete connection breakdown during 6-10 PM evening hours, making working from home and gaming "essentially impossible."&lt;/p&gt;
    &lt;p&gt;YouTube appears prominently in complaints. Forum posts describe "seit heute Abend ist Google / Youtube quasi nicht mehr zu erreichen" (since this evening Google/YouTube essentially unreachable), with traceroutes showing 1,000ms latency and 21 hops to reach Google instead of direct connections. That's not random—Heise.de, Germany's most authoritative tech publication, specifically reported that Vodafone is "discontinuing existing direct interconnections with large data sources such as YouTube."&lt;/p&gt;
    &lt;p&gt;The affected services align perfectly with those that would need to establish new paid relationships with Inter.link: YouTube, Netflix, Twitch, gaming platforms. Netflix streams at 0.93 Mbps during peak hours on some Vodafone connections—enough for low-quality SD but nowhere near the 5+ Mbps users get on competing ISPs. Gaming servers show 100-350 millisecond latency when they should be 20-30 milliseconds.&lt;/p&gt;
    &lt;p&gt;Berlin residents experienced particular degradation when Vodafone withdrew from BCIX (Berlin Internet Exchange), with forum posts noting that BCIX peering "was eliminated months ago and notably worsened network quality for Berlin residents." Major content providers including Amazon, Apple, Facebook, Google, Microsoft, Netflix, and Twitch all peered at BCIX for low-latency Berlin connectivity. Those direct connections are gone, replaced by longer routes through Inter.link's more distant points of presence.&lt;/p&gt;
    &lt;head rend="h2"&gt;The physics don't support Vodafone's claims&lt;/head&gt;
    &lt;p&gt;Let's talk about that "lower latencies" promise, because it defies basic networking principles.&lt;/p&gt;
    &lt;p&gt;Academic research measuring performance across 900+ networks found that 91% experience at least 5% latency improvement via direct peering versus transit, with median improvements of 12-15 milliseconds. The reason is simple physics: shorter paths are faster than longer paths.&lt;/p&gt;
    &lt;p&gt;Vodafone's migration does the opposite. Previously, a customer accessing YouTube might traverse three hops through direct peering at DE-CIX Frankfurt: from the customer's router to Vodafone's router to Google's router. Now that traffic must route through Inter.link as a mandatory intermediary, adding at least one additional hop and extending the physical path.&lt;/p&gt;
    &lt;p&gt;This is fundamental networking: every additional network you traverse adds latency from routing decisions, queuing delays, and physical transmission time. Direct peering at an exchange point minimizes this. Routing through an intermediary by definition increases it.&lt;/p&gt;
    &lt;p&gt;Unless Inter.link has discovered physics-defying routing magic—and they haven't published any evidence suggesting they have—adding mandatory intermediary hops cannot produce lower latency than direct connections. The architecture change moves in precisely the wrong direction.&lt;/p&gt;
    &lt;p&gt;Vodafone has published exactly zero supporting measurements. No traceroute comparisons. No latency benchmarks. No throughput tests. No independent technical validation. For a major telecommunications company claiming performance improvements while undertaking a massive infrastructure change, the absence of any quantitative evidence is deafening.&lt;/p&gt;
    &lt;head rend="h2"&gt;The satellite escape hatch&lt;/head&gt;
    &lt;p&gt;While Vodafone dismantles its open peering infrastructure, an alternative has emerged that sidesteps these politics entirely: satellite internet.&lt;/p&gt;
    &lt;p&gt;Starlink operates its own global backbone network with direct agreements with major content providers. When you access YouTube via Starlink, traffic flows through SpaceX's network to satellites and down to your dish—a fundamentally different architecture from terrestrial ISP peering arrangements.&lt;/p&gt;
    &lt;p&gt;The €65/month residential service won't match premium fiber speeds, but Ookla reports consistent 161 Mbps median downloads in Germany with 40-50ms latency. More importantly: no selective throttling. Netflix and GitHub load at the same speeds because Starlink doesn't play favorites.&lt;/p&gt;
    &lt;p&gt;For customers experiencing Deutsche Telekom or Vodafone degradation, that consistency matters more than peak speed. The €299 hardware cost hurts, but you're paying for infrastructure that can't be weaponized for rent-seeking. And when Starlink has capacity issues, SpaceX launches more satellites—they solve congestion with infrastructure investment rather than weaponizing it for revenue extraction.&lt;/p&gt;
    &lt;p&gt;That competitive pressure matters. Every customer who switches from Vodafone to satellite because YouTube won't load is revenue walking out the door. Terrestrial ISPs aren't quite the monopolies they used to be.&lt;/p&gt;
    &lt;head rend="h2"&gt;This isn't about efficiency—it's about extraction&lt;/head&gt;
    &lt;p&gt;Here's what Vodafone isn't saying in its press releases: this migration is fundamentally about changing the internet's economic model.&lt;/p&gt;
    &lt;p&gt;Traditional settlement-free peering operates on reciprocity. Networks exchange traffic because both sides benefit—Vodafone's customers want to access YouTube, and YouTube wants to reach Vodafone's customers. No money changes hands because the value exchange is mutual. It's one of the last genuinely cooperative aspects of internet infrastructure.&lt;/p&gt;
    &lt;p&gt;Vodafone's new model charges content providers based on traffic volume, creating what academic experts call a "termination monopoly." If you're a content provider and you want Vodafone's customers to have decent access to your service, you now have to pay Inter.link. Professor Barbara van Schewick of Stanford Law School, whose work informed FCC net neutrality orders and EU guidelines, characterized similar practices by Deutsche Telekom as "a frontal attack on the open internet."&lt;/p&gt;
    &lt;p&gt;In August 2024 comments to European regulators, van Schewick explained that ISPs exploit their "termination monopoly" by charging "monopoly termination fees" to reach subscribers, and concluded that "paid interconnection fees violate the Open Internet Regulation's ban on discrimination and paid fast lanes."&lt;/p&gt;
    &lt;p&gt;In December 2024, Switzerland's telecommunications regulator delivered an 11-year ruling against Swisscom for similar practices. The Swiss ComCom decision found that ISPs have a "technical monopoly of access to their end customers" and that charging content providers for traffic delivery is "not permissible" because costs are already covered by customer subscriptions. The ruling explicitly rejected the "double-dipping" model where both customers and content providers pay for internet access—precisely what Vodafone implements through Inter.link.&lt;/p&gt;
    &lt;p&gt;Think about that: you pay Vodafone for internet access. YouTube pays Inter.link for the privilege of serving you. Both ends pay, but the service you receive gets worse because the architecture degrades and bottlenecks concentrate through fewer connection points. Vodafone saves money on operational overhead while extracting new revenue from content providers. You, the customer, subsidize this twice and get a degraded product.&lt;/p&gt;
    &lt;head rend="h2"&gt;Regulators are paying attention (finally)&lt;/head&gt;
    &lt;p&gt;The April 2025 complaint against Deutsche Telekom came from a coalition including Germany's federal consumer organization (Verbraucherzentrale Bundesverband), Epicenter.works, Gesellschaft für Freiheitsrechte, and Stanford professor Barbara van Schewick. The complaint documents technical evidence of artificial bottlenecks and charges that Deutsche Telekom creates "paid fast lanes" prohibited under EU law.&lt;/p&gt;
    &lt;p&gt;BEREC (Body of European Regulators for Electronic Communications) released a report in December 2024 after a two-year investigation, identifying practices where ISPs "exploit bottlenecks at the entrance to its network to demand payments from online services" and classifying such practices as "potential violations of Europe's net neutrality law." The report listed "several examples, most of which involved Deutsche Telekom."&lt;/p&gt;
    &lt;p&gt;If the investigation finds Deutsche Telekom's model violates EU net neutrality regulations, Vodafone's identical approach faces the same legal jeopardy. Germany's Federal Network Agency has already shown willingness to act—in February 2022, it prohibited Vodafone's "Vodafone Pass" zero-rating service following European Court of Justice rulings. The same authority could order Vodafone to abandon paid peering and return to settlement-free public peering.&lt;/p&gt;
    &lt;p&gt;But regulatory remedies take years. In the meantime, customers suffer.&lt;/p&gt;
    &lt;head rend="h2"&gt;What this means for you&lt;/head&gt;
    &lt;p&gt;If you're a Vodafone Germany customer, here's what you can probably expect based on Deutsche Telekom's decade of evidence and early Vodafone complaints:&lt;/p&gt;
    &lt;p&gt;YouTube, Netflix, and streaming services will buffer more during evening hours. Quality will automatically downgrade. 4K streaming will become unreliable. These companies may eventually pay Inter.link's fees, but the degradation provides leverage for those negotiations.&lt;/p&gt;
    &lt;p&gt;Gaming will become frustrating or unplayable during peak hours. Latency will spike. Packet loss will make competitive games impossible. You'll blame the game servers, but the problem is your ISP's routing.&lt;/p&gt;
    &lt;p&gt;Video calls, remote work, cloud applications—anything latency-sensitive—will degrade during 7-11 PM peak hours when traffic concentrates through Inter.link's connection points. Your Zoom calls will pixelate. Your remote desktop sessions will lag. Your cloud backups will throttle.&lt;/p&gt;
    &lt;p&gt;Smaller content providers, startups, regional services—anyone who can't or won't pay Inter.link's fees—will work noticeably worse on your Vodafone connection than on competing ISPs. You'll have a two-tiered internet: fast lanes for services that pay, slow lanes for everything else.&lt;/p&gt;
    &lt;p&gt;And when you call Vodafone support, they'll run speed tests that show your connection hitting advertised speeds to Vodafone's own servers, and they'll tell you everything looks fine from their end. Because technically, it does. The problem isn't your connection to Vodafone—it's Vodafone's restrictive connections to the rest of the internet.&lt;/p&gt;
    &lt;head rend="h2"&gt;The bigger picture&lt;/head&gt;
    &lt;p&gt;Vodafone's exit from public peering isn't an isolated technical decision—it's part of a broader pattern of large telecoms trying to reshape internet economics in their favor. Thomas King, CTO of DE-CIX Frankfurt, warned without naming companies directly: "We are currently observing a trend in which large market players are increasingly using their dominant position to monetize not only their Internet access business but also network interconnection."&lt;/p&gt;
    &lt;p&gt;The trend is particularly concentrated in Germany, where both major incumbent ISPs now operate restrictive paid peering models while competitors maintain open policies. IT-Administrator, a leading German IT publication, warned that Vodafone's shift "could reduce transparency, while smaller providers and content providers may face higher entry barriers" and "could impair the diversity and openness of European Internet infrastructure."&lt;/p&gt;
    &lt;p&gt;If this model proves profitable for Vodafone and Deutsche Telekom without regulatory consequences, expect other European telecoms to follow. The open internet—where networks cooperate through settlement-free peering to deliver the best possible service—gets replaced by a gatekeeper model where ISPs extract fees from both customers and content providers while delivering worse performance.&lt;/p&gt;
    &lt;head rend="h2"&gt;The internet you pay for isn't the internet you're getting&lt;/head&gt;
    &lt;p&gt;Here's the fundamental thing to understand: when you pay Vodafone for internet service, you think you're buying neutral access to the global internet. You're not. You're buying access to Vodafone's network, and Vodafone controls how well that network connects to everything else.&lt;/p&gt;
    &lt;p&gt;For decades, ISPs and content networks cooperated through settlement-free peering at neutral exchange points, creating the fast, reliable internet we take for granted. That cooperative model is breaking down, replaced by gatekeepers who charge both ends while delivering worse service.&lt;/p&gt;
    &lt;p&gt;Vodafone's marketing says the Inter.link migration will give you "lower latencies." The architecture says you're getting longer paths, more hops, and concentration through fewer connection points. Deutsche Telekom's decade of customer misery says you're about to experience systematic service degradation. Early Vodafone complaints say it's already starting.&lt;/p&gt;
    &lt;p&gt;The evidence is overwhelming. Vodafone customers should brace for impact. And everyone else should pay attention—because if this model succeeds in Germany, it's coming to your country next.&lt;/p&gt;
    &lt;head rend="h2"&gt;Sources&lt;/head&gt;
    &lt;p&gt;Primary Sources:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Vodafone Press Release: Inter.link Partnership (November 2024)&lt;/item&gt;
      &lt;item&gt;Heise Online: Vodafone Leaves Public Internet Exchange Points&lt;/item&gt;
      &lt;item&gt;DE-CIX: Global Interconnection Ecosystem&lt;/item&gt;
      &lt;item&gt;Inter.link: Network Infrastructure and Locations&lt;/item&gt;
      &lt;item&gt;Inter.link: Peering Policy and Network Information&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Deutsche Telekom Complaints &amp;amp; Evidence:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Netzbremse: Deutsche Telekom Throttling Documentation&lt;/item&gt;
      &lt;item&gt;Stanford CIS: Coalition Files Complaint Against Deutsche Telekom (April 2025)&lt;/item&gt;
      &lt;item&gt;Epicenter.works: No Two-Tier Internet Complaint&lt;/item&gt;
      &lt;item&gt;Heise: Consumer Advocates Mobilize Against Telekom's "Network Brake"&lt;/item&gt;
      &lt;item&gt;Heise: Net Neutrality Alliance Files Complaint&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Customer Complaints:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Vodafone Community Forum: Massive Problems Since February 2024&lt;/item&gt;
      &lt;item&gt;Vodafone Community Forum: YouTube/Google Connection Issues&lt;/item&gt;
      &lt;item&gt;Vodafone Kabel Forum: Regional Peerings Eliminated&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Academic &amp;amp; Technical Research:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;RIPE Labs: Is It Really Worth Peering at IXPs?&lt;/item&gt;
      &lt;item&gt;Barbara van Schewick: Comments on BEREC Interconnection Report (August 2024)&lt;/item&gt;
      &lt;item&gt;Ookla Speedtest: Germany Performance Data&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Regulatory &amp;amp; Legal:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Swiss ComCom: Swisscom Zero-Settlement Peering Ruling (December 2024)&lt;/item&gt;
      &lt;item&gt;Bundesnetzagentur: Zero-Rating Prohibition (February 2022)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Industry Analysis:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45848484</guid><pubDate>Fri, 07 Nov 2025 17:05:06 +0000</pubDate></item><item><title>Gmail AI gets more intrusive</title><link>https://daveverse.org/2025/11/07/gmail-ai-gets-even-more-intrusive/</link><description>&lt;doc fingerprint="85fa56370f92daa1"&gt;
  &lt;main&gt;
    &lt;p&gt;Gmail doesn't just offer to write your emails for you, they actually do it, and it's up to you to delete the text it wrote.&lt;/p&gt;
    &lt;p&gt;Hard to make a screen shot to demo without revealing personal info. That's how awful this thing is.&lt;/p&gt;
    &lt;p&gt;It reeks of desperation.&lt;/p&gt;
    &lt;p&gt;Last update: 11/7/25; 12:03:41 PM.&lt;/p&gt;
    &lt;p&gt;Subscribe now to keep reading and get access to the full archive.&lt;/p&gt;
    &lt;p&gt;Type your email…&lt;/p&gt;
    &lt;p&gt;Subscribe&lt;/p&gt;
    &lt;p&gt;Continue reading&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45848504</guid><pubDate>Fri, 07 Nov 2025 17:07:01 +0000</pubDate></item><item><title>Myna: Monospace typeface designed for symbol-heavy programming languages</title><link>https://github.com/sayyadirfanali/Myna</link><description>&lt;doc fingerprint="bf9b609b0166edfd"&gt;
  &lt;main&gt;
    &lt;p&gt;Do you ever feel like your font treats symbols as second-class glyphs? Are you frustrated that &lt;code&gt;-&amp;gt;&lt;/code&gt; looks nothing like an arrow, and &lt;code&gt;$&lt;/code&gt;, &lt;code&gt;@&lt;/code&gt;, &lt;code&gt;%&lt;/code&gt; seem ever mismatched?&lt;/p&gt;
    &lt;p&gt;Want to experience the beauty of ligatures without losing the simplicity of ASCII?&lt;/p&gt;
    &lt;p&gt;Myna (Gracula religiosa 🐦⬛) is a monospace font which aims to bring harmony to your editor by treating symbols as first-class glyphs alongside alphanumeric characters.&lt;/p&gt;
    &lt;p&gt;Myna was borne out of a need to scratch a persistent typographical itch. While I've tried many otherwise well-crafted monospace fonts, I always found myself wanting to tweak a glyph here or adjust a shape there. After developing Myna and using it almost exclusively in my professional and personal work, I'm sharing it as a small contribution to the wonderful community of monospace typography enthusiasts.&lt;/p&gt;
    &lt;p&gt;Here are a few of its attractive features that might make it your next favourite monospace font:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Symbol-First Design: clear emphasis on ASCII symbols which are ubiquitous in programming languages&lt;/item&gt;
      &lt;item&gt;Near-Perfect Alignment: multi-character symbols like &lt;code&gt;-&amp;gt;&lt;/code&gt;,&lt;code&gt;&amp;gt;&amp;gt;=&lt;/code&gt;,&lt;code&gt;=~&lt;/code&gt;,&lt;code&gt;::&lt;/code&gt;align seamlessly&lt;/item&gt;
      &lt;item&gt;Balanced Weight: symbols have just the right visual weight against your code&lt;/item&gt;
      &lt;item&gt;Minimalist Forms: geometric shapes for quotes and commas&lt;/item&gt;
      &lt;item&gt;Clear Distinction: no more confusing &lt;code&gt;1 l I |&lt;/code&gt;or&lt;code&gt;0 O o&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Language-Aware Design: clean sigils for Perl + elegant operators for Haskell + clear symbols for C&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;NB: Myna is designed to be a simple font. The current release is a single weight without ligatures, though future updates may expand its features if demand arises. It does work out nicely with synthesised bold generated by fontconfig and pango on Linux.&lt;/p&gt;
    &lt;p&gt;Please click on the image to view it in full in a new tab.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Language&lt;/cell&gt;
        &lt;cell role="head"&gt;Light&lt;/cell&gt;
        &lt;cell role="head"&gt;Dark&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Perl&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Haskell&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;C&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Bash&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Clojure&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Erlang&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;OCaml&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Rust&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;LaTeX&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;HTML&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;SQL&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;git clone https://github.com/sayyadirfanali/Myna.git
cd Myna
cp Myna.otf ~/.local/share/fonts/
fc-cache -v&lt;/code&gt;
    &lt;code&gt;git clone https://github.com/sayyadirfanali/Myna.git
cd Myna
cp Myna.otf ~/Library/Fonts/&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Download the release&lt;/item&gt;
      &lt;item&gt;Right-click &lt;code&gt;Myna.otf&lt;/code&gt;and select "Install for all users"&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;SIL Open Font License, Version 1.1&lt;/p&gt;
    &lt;p&gt;Myna started out as Hera which was a customised version of Source Code Pro but now has come a long way after stealing many beautiful designs from Fira Mono, Inconsolata, Plex Mono, Office Code Pro, Anonymous Pro. Detailed credits could be found in the Hera repository.&lt;/p&gt;
    &lt;p&gt;Code banner and illustrations were produced using ImageMagick and Ray.so.&lt;/p&gt;
    &lt;p&gt;Myna is designed to be used universally in every kind of terminal and editor. I've tried to include a reasonable subset of non-ASCII glyphs (mostly geometrical and mathematical characters). However, I'm considering expanding it based on community interest and would welcome contributions in these areas:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Bug Reports: spacing and kerning issues, rendering problems, unavailable/incorrect glyphs&lt;/item&gt;
      &lt;item&gt;Feature Requests: suggest new glyphs or features via GitHub Issues&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Please feel free to open issues and also contact me at irfan@irfanali.org.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45849342</guid><pubDate>Fri, 07 Nov 2025 18:27:36 +0000</pubDate></item><item><title>Ruby Solved My Problem</title><link>https://newsletter.masilotti.com/p/ruby-already-solved-my-problem</link><description>&lt;doc fingerprint="3e6c285f6ce2a7b9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Ruby already solved my problem 😅&lt;/head&gt;
    &lt;head rend="h3"&gt;One great question in office hours led me to delete a whole class.&lt;/head&gt;
    &lt;p&gt;Yesterday I hosted November’s Hotwire Native Office Hours.&lt;/p&gt;
    &lt;p&gt;Every month I host an hour long Zoom session for developers to directly ask me questions. The topics range greatly: some folks are just getting started and others are asking very specific, advanced questions.&lt;/p&gt;
    &lt;p&gt;This month we covered everything from registering bridge components to native vs. web-based tabs to authenticating Apple Watch apps! It’s really fun to see what folks are working on in the Hotwire Native space.&lt;/p&gt;
    &lt;p&gt;During the session I shared some code I wrote to figure out what version a Hotwire Native app is running. The app sends the version in the user agent (e.g. &lt;code&gt;v1.2.3&lt;/code&gt;) and then I parse it with the following Ruby class on the server:&lt;/p&gt;
    &lt;code&gt;class AppVersion
  include Comparable

  attr_reader :major, :minor, :patch

  def initialize(version_string)
    parts = version_string.to_s.split(”.”).map(&amp;amp;:to_i)
    @major, @minor, @patch = parts[0] || 0, parts[1] || 0, parts[2] || 0
  end

  def &amp;lt;=&amp;gt;(other)
    [major, minor, patch] &amp;lt;=&amp;gt; [other.major, other.minor, other.patch]
  end

  def to_s
    “#{major}.#{minor}.#{patch}”
  end
end&lt;/code&gt;
    &lt;p&gt;And it works great! I use this throughout my apps to feature flag code based on which version the app is running.&lt;/p&gt;
    &lt;p&gt;But someone brought up something even better: &lt;code&gt;Gem::Version&lt;/code&gt;. This class accomplishes the same goal: “process string versions into comparable values”.&lt;/p&gt;
    &lt;code&gt;irb(main)&amp;gt; Gem::Version.new("1.2.3") &amp;gt; Gem::Version.new("1.2.2")
=&amp;gt; true

irb(main)&amp;gt; Gem::Version.new("2.0") &amp;gt; Gem::Version.new("1.2.2")
=&amp;gt; true&lt;/code&gt;
    &lt;p&gt;It can even compare prerelease versions, like alphas or betas.&lt;/p&gt;
    &lt;code&gt;irb(main)&amp;gt; Gem::Version.new("2.0.b1") &amp;gt; Gem::Version.new("1.9")
=&amp;gt; true
irb(main)&amp;gt; Gem::Version.new("2.0") &amp;gt; Gem::Version.new("2.0.b1")
=&amp;gt; true&lt;/code&gt;
    &lt;p&gt;The big advantage this class has over my implementation is that it’s built into Ruby!&lt;/p&gt;
    &lt;p&gt;It’s not even a Rails dependency but part of the standard Ruby library. Internally, this class is used to compare version numbers when parsing your &lt;code&gt;Gemfile&lt;/code&gt;. Check out the documentation, I picked up a few things on semantic versioning when reading it.&lt;/p&gt;
    &lt;p&gt;I’ve already replaced my &lt;code&gt;AppVersion&lt;/code&gt; class with &lt;code&gt;Gem::Version&lt;/code&gt;. But it makes me wonder what other Ruby/Rails features I don’t know about and am implementing on my own!&lt;/p&gt;
    &lt;head rend="h2"&gt;The power of community, no matter how small&lt;/head&gt;
    &lt;p&gt;I never would have learned about &lt;code&gt;Gem::Version&lt;/code&gt; if it wasn’t for someone bringing it up during office hours. I’d still be using my custom (and most likely buggy!) &lt;code&gt;AppVersion&lt;/code&gt; implementation… like a chump. 😅&lt;/p&gt;
    &lt;p&gt;But seriously, this is why I love connecting with folks in the Ruby/Rails community. Every time I go to an event, host a workshop, give a talk… I learn something new. Sometimes it’s small things like &lt;code&gt;Gem::Version&lt;/code&gt;. Other times it completely changes my career, like the first time I heard about Hotwire Native.&lt;/p&gt;
    &lt;p&gt;I’ve taken this to heart and recently started organizing monthly Coffee and Code coworking sessions in my city, Portland, OR. Every month I post up at a local coffee shop with my laptop and invite all of the Portland Ruby Brigade to join.&lt;/p&gt;
    &lt;p&gt;This month we had five people! It’s no corporate-sponsored-meetup but it sure is something. And the connections that folks are making during these casual events are real. I’ve already seen folks exchange emails for potential future contract gigs.&lt;/p&gt;
    &lt;p&gt;What’s the first step you can take today to build some community in your local area? Even if it is just finally inviting that connection-to-be for a beverage… I say go for it.&lt;/p&gt;
    &lt;p&gt;If you want to join next month’s office hours then consider becoming a paid subscriber of my newsletter. I hope to see you there! 👋&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45849528</guid><pubDate>Fri, 07 Nov 2025 18:45:35 +0000</pubDate></item></channel></rss>