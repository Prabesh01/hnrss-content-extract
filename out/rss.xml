<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 30 Oct 2025 04:12:16 +0000</lastBuildDate><item><title>Composer: Building a fast frontier model with RL</title><link>https://cursor.com/blog/composer</link><description>&lt;doc fingerprint="3d5aedd9e03a0a1a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Composer: Building a fast frontier model with RL&lt;/head&gt;
    &lt;p&gt;Composer is our new agent model designed for software engineering intelligence and speed. On our benchmarks, the model achieves frontier coding results with generation speed four times faster than similar models.&lt;/p&gt;
    &lt;p&gt;We achieve these results by training the model to complete real-world software engineering challenges in large codebases. During training, Composer is given access to a set of production search and editing tools and tasked with efficiently solving a diverse range of difficult problems. The final result is a large-scale model optimized for high-speed use as an agent in Cursor.&lt;/p&gt;
    &lt;p&gt;Our motivation comes from our experience developing Cursor Tab, our custom completion model. We found that often developers want the smartest model that can support interactive use, keeping them in the flow of coding. In our development process, we experimented with a prototype agent model, codenamed Cheetah, to better understand the impact of faster agent models. Composer is a smarter version of this model that keeps coding delightful by being fast enough for an interactive experience.&lt;/p&gt;
    &lt;p&gt;Composer is a mixture-of-experts (MoE) language model supporting long-context generation and understanding. It is specialized for software engineering through reinforcement learning (RL) in a diverse range of development environments. At each iteration of training, the model is given a problem description and instructed to produce the best response, be it a code edit, a plan, or an informative answer. The model has access to simple tools, like reading and editing files, and also more powerful ones like terminal commands and codebase-wide semantic search.&lt;/p&gt;
    &lt;p&gt;To measure progress, we constructed an evaluation that measures a model's usefulness to a software developer as faithfully as possible. Our benchmark, Cursor Bench, consists of real agent requests from engineers and researchers at Cursor, along with hand-curated optimal solutions to these requests. The resulting evaluation measures not just the agent’s correctness, but also its adherence to a codebase's existing abstractions and software engineering practices.&lt;/p&gt;
    &lt;p&gt;Reinforcement learning allows us to actively specialize the model for effective software engineering. Since response speed is a critical component for interactive development, we incentivize the model to make efficient choices in tool use and to maximize parallelism whenever possible. In addition, we train the model to be a helpful assistant by minimizing unnecessary responses and claims made without evidence. We also find that during RL, the model learns useful behaviors on its own like performing complex searches, fixing linter errors, and writing and executing unit tests.&lt;/p&gt;
    &lt;p&gt;Efficient training of large MoE models requires significant investment into building infrastructure and systems research. We built custom training infrastructure leveraging PyTorch and Ray to power asynchronous reinforcement learning at scale. We natively train our models at low precision by combining our MXFP8 MoE kernels with expert parallelism and hybrid sharded data parallelism, allowing us to scale training to thousands of NVIDIA GPUs with minimal communication cost. Additionally, training with MXFP8 allows us to deliver faster inference speeds without requiring post-training quantization.&lt;/p&gt;
    &lt;p&gt;During RL, we want our model to be able to call any tool in the Cursor Agent harness. These tools allow editing code, using semantic search, grepping strings, and running terminal commands. At our scale, teaching the model to effectively call these tools requires running hundreds of thousands of concurrent sandboxed coding environments in the cloud. To support this workload, we adapted existing infrastructure we built for Background Agents, rewriting our virtual machine scheduler to support the bursty nature and scale of training runs. This enabled seamless unification of RL environments with production environments.&lt;/p&gt;
    &lt;p&gt;Cursor builds tools for software engineering, and we make heavy use of the tools we develop. A motivation of Composer development has been developing an agent we would reach for in our own work. In recent weeks, we have found that many of our colleagues were using Composer for their day-to-day software development. With this release, we hope that you also find it to be a valuable tool.&lt;/p&gt;
    &lt;p&gt;—&lt;/p&gt;
    &lt;p&gt;¹ Benchmarked on an internal benchmark in the Cursor tool harness. We group models into classes based on score and report the best model in each class. "Fast Frontier" includes models designed for efficient inference such as Haiku 4.5 and Gemini Flash 2.5. "Best Open" includes recent open weight model releases such as Qwen Coder and GLM 4.6. "Frontier 7/2025" is the best model available in July of this year. "Best Frontier" includes GPT-5 and Sonnet 4.5, which both outperform Composer. For the Tokens per Second calculation, tokens are standardized across models to the latest Anthropic tokenizer.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45748725</guid><pubDate>Wed, 29 Oct 2025 16:04:33 +0000</pubDate></item><item><title>Minecraft removing obfuscation in Java Edition</title><link>https://www.minecraft.net/en-us/article/removing-obfuscation-in-java-edition</link><description>&lt;doc fingerprint="370203ca08b7cced"&gt;
  &lt;main&gt;
    &lt;p&gt;Do you like to mod Java, tinker with builds, or take deep dives into Minecraft’s code? Then this article is for you!&lt;/p&gt;
    &lt;p&gt;For a long time, Java Edition has used obfuscation (hiding parts of the code) – a common practice in the gaming industry. Now we’re changing how we ship Minecraft: Java Edition to remove obfuscation completely. We hope that, with this change, we can pave a future for Minecraft: Java Edition where it’s easier to create, update, and debug mods.&lt;/p&gt;
    &lt;head rend="h2"&gt;An obfuscated history&lt;/head&gt;
    &lt;p&gt;Minecraft: Java Edition has been obfuscated since its release. This obfuscation meant that people couldn’t see our source code. Instead, everything was scrambled – and those who wanted to mod Java Edition had to try and piece together what every class and function in the code did.&lt;/p&gt;
    &lt;p&gt;But we encourage people to get creative both in Minecraft and with Minecraft – so in 2019 we tried to make this tedious process a little easier by releasing “obfuscation mappings”. These mappings were essentially a long list that allowed people to match the obfuscated terms to un-obfuscated terms. This alleviated the issue a little, as modders didn’t need to puzzle out what everything did, or what it should be called anymore. But why stop there?&lt;/p&gt;
    &lt;head rend="h2"&gt;Removing obfuscation in Java Edition&lt;/head&gt;
    &lt;p&gt;To make things even easier – and remove these intermediary steps – we’re removing obfuscation altogether! Starting with the first snapshot following the complete Mounts of Mayhem launch, we will no longer obfuscate Minecraft: Java Edition. This means that this build (and all future builds) will have all of our original names* – now with variable names and other names – included by default to make modding even easier.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45748879</guid><pubDate>Wed, 29 Oct 2025 16:12:56 +0000</pubDate></item><item><title>Tailscale Peer Relays</title><link>https://tailscale.com/blog/peer-relays-beta</link><description>&lt;doc fingerprint="66f1d873751076c5"&gt;
  &lt;main&gt;
    &lt;p&gt;Tailscale Peer Relays provides a customer-deployed and managed traffic relaying mechanism. By advertising itself as a peer relay, a Tailscale node can relay traffic for any peer nodes on the tailnet, even for traffic bound to itself. Tailscale Peer Relays can only relay traffic for nodes on your tailnet, and only for nodes that have access to the peer relay. Because they’re managed entirely by the customer, peer relays are less throughput-constrained than Tailscale’s managed DERP relays, and can provide higher throughput connections for traffic to and from locked-down cloud infrastructure, or behind strict network firewalls.&lt;/p&gt;
    &lt;p&gt;In testing with early design partners, we’ve seen throughputs nearing that of a direct connection; often multiple orders of magnitude higher than Tailscale’s managed DERP fleet.&lt;/p&gt;
    &lt;head rend="h2"&gt;Moving past hard NAT&lt;/head&gt;
    &lt;p&gt;Over the past few weeks, you’ve heard us talk about improvements we’ve made to Network Address Translation (NAT) traversal techniques, so that Tailscale can establish direct connections wherever possible (hint: it’s over 90% of the time). However, we’ve also outlined places where this isn’t possible or desirable today for a variety of reasons, especially in cloud environments. And, we’ve postulated a bit about where we think the industry is going.&lt;/p&gt;
    &lt;p&gt;While we’ve been keeping your network reliably connected for years with DERP, we’ve heard from customers that the throughput and performance aspects of a QoS-aware managed relay fleet makes deployments in certain environments difficult or untenable. Furthermore, customers have noted that it’s non-trivial to deploy and manage custom DERP fleets (which run as a separate service and binary).&lt;/p&gt;
    &lt;p&gt;DERP provides an incredibly valuable service, setting up reliable connections between Tailscale clients anywhere in the world (including negotiating connections through peer relays). But often, DERP’s focus as a reliability and NAT traversal tool results in performance tradeoffs.&lt;/p&gt;
    &lt;p&gt;By contrast, Tailscale Peer Relays is designed as a performant connectivity tool, and can perform at a level rivaling direct connections. Peer relays can be placed right next to the resources they serve, and peer relays also run on top of UDP, both characteristics beneficial to lower latency and resource overhead. And, they are built into the Tailscale client itself for ease of deployment.&lt;/p&gt;
    &lt;p&gt;We want to move past even more hard NATs, and put Tailscale’s relaying technology in our customers’ hands, so they can use Tailscale at scale, anywhere, with ease. We believe our new Tailscale Peer Relays connectivity option—unique to Tailscale—gives customers the best performance and flexibility.&lt;/p&gt;
    &lt;head rend="h2"&gt;How it works&lt;/head&gt;
    &lt;p&gt;Peer relays are configured with a single UDP port that must be available to both sides of a connection. Tailscale Peer Relays is built right into the Tailscale client, and can be enabled with a simple command, using the &lt;code&gt;tailscale set --relay-server-port&lt;/code&gt; flag from the Tailscale CLI. Once enabled via the steps in our documentation, clients can connect to infrastructure in hard NAT environments over the peer relay.&lt;/p&gt;
    &lt;p&gt;And don’t worry, we still prefer to fly direct. Tailscale prefers direct connections wherever possible. Clients can then fall back to available peer relays, and finally leverage Tailscale’s managed DERP fleet, or any customer-deployed custom DERPs, to ensure you have connectivity wherever you need it. All of this traffic, over any connection, is still end-to-end encrypted via WireGuard®.&lt;/p&gt;
    &lt;p&gt;Tailscale Peer Relays is designed for the real world, based on the feedback we’ve received from customers and our own hard-earned networking expertise. It allows customers to make just one firewall exception for connections only coming from their tailnet. Peer relays scale across regions, are resilient to real-world network conditions, and graciously fall back to DERP (Tailscale’s or custom). Your network maintains its shape, but gains all kinds of flexibility.&lt;/p&gt;
    &lt;head rend="h2"&gt;Connectivity, everywhere, at warp speed&lt;/head&gt;
    &lt;p&gt;Customers can now maintain performance benchmarks even where direct connections aren’t possible, by enabling Tailscale Peer Relays to build a deterministic and high-throughput relay topology.&lt;/p&gt;
    &lt;p&gt;We’ve had customers use peer relays to provide access into unmanaged networks, allowing their partners or customers to provide a controllable and auditable connectivity path without sacrificing performance.&lt;/p&gt;
    &lt;p&gt;In strict private networks, customers can build predictable access paths. Tailscale Peer Relays can be placed in public subnets with VPC peering to private subnets, allowing security teams to efficiently segment their private network infrastructure, while enabling networking teams to roll Tailscale out in full-mesh mode across the subnet.&lt;/p&gt;
    &lt;p&gt;Today, customers are using peer relays to establish relayed connections at near-direct speeds across a variety of environments and settings.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Enable high-throughput traffic through cloud NATs, like AWS Managed NAT Gateways: Applications and services behind a Managed NAT Gateway can leverage peer relays to relay traffic that can’t establish direct connections.&lt;/item&gt;
      &lt;item&gt;Relay through network firewalls: Workloads running in strictly firewalled environments can predictably expose a single UDP port, limiting the Tailscale surface area and fast-tracking the approval process for firewall exceptions.&lt;/item&gt;
      &lt;item&gt;Offload from Custom and Managed DERP: Minimize data-in-transit through Tailscale‘s managed DERP network, and remove the need for customer-maintained DERP servers.&lt;/item&gt;
      &lt;item&gt;Provide access to locked down customer networks: Data plane traffic can be relayed through predictable endpoints in customer networks, so that they only need to open minimal numbers of ports to facilitate cross network connections.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;It’s not perfect, but we’re getting there&lt;/head&gt;
    &lt;p&gt;Tailscale Peer Relays is available today as a public beta. We’ve yet to establish all the connectivity paths we want to, and there’s still visibility and debugging improvements to work through. However, we’ve reliably seen our early design partners move to peer relay deployments with relative ease, and we’re ready for you to give it a try on your tailnet.&lt;/p&gt;
    &lt;p&gt;Tailscale Peer Relays can be enabled on all plans, including free (it’s our little way of working through the kinks of the modern internet with our customers). All customers can use two peer relays, for free, forever. As your needs scale, so will the number of available peer relays. To add even more peer relays to your tailnet, come have a chat with us.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45749017</guid><pubDate>Wed, 29 Oct 2025 16:21:36 +0000</pubDate></item><item><title>AOL to be sold to Bending Spoons for $1.5B</title><link>https://www.axios.com/2025/10/29/aol-bending-spoons-deal</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45749161</guid><pubDate>Wed, 29 Oct 2025 16:28:56 +0000</pubDate></item><item><title>Upwave (YC S12) is hiring software engineers</title><link>https://www.upwave.com/job/8228849002/</link><description>&lt;doc fingerprint="355c16590c952eaa"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Senior Software Engineer&lt;/head&gt;
    &lt;p&gt;Upwave: The Brand Outcomes Measurement Platform&lt;/p&gt;
    &lt;p&gt;Upwave is a leading measurement company entirely focused on measuring and optimizing upper funnel campaigns.. The world’s leading advertisers, agencies, and media partners trust Upwave’s robust, AI-driven platform to bring science to the top of the funnel.&lt;/p&gt;
    &lt;p&gt;With Upwave, marketers maximize the effectiveness of brand spend. Upwave measures Brand Lift, validates Brand Reach, and surfaces Brand Optimization opportunities in one, dynamic platform with cross-channel brand measurement for CTV, Digital, Social, Linear, Addressable, Retail Media, Streaming Audio and more.&lt;/p&gt;
    &lt;p&gt;We’re a profitable, growth-stage company backed by leading venture investors (Y Combinator, Uncork Capital, Bloomberg Beta, Initialized Capital, PivotNorth, Ridge Ventures, Industry Ventures, Conductive Ventures,) and leading AdTechfounders &amp;amp; CEOs.&lt;/p&gt;
    &lt;p&gt;We’re a humble but ambitious team that takes its work seriously but never ourselves. Come join us.&lt;/p&gt;
    &lt;p&gt;As a Senior Software Engineer at Upwave, you’ll be a full-stack problem solver with a backend focus—building the APIs, data pipelines, and systems that power our brand measurement platform. Your work will process billions of ad impressions, manage complex data workflows, and deliver insights that inform marketing decisions for the world’s biggest brands.&lt;/p&gt;
    &lt;p&gt;You’ll collaborate across engineering, product, and data science to ship high-impact features end-to-end, scale our platform for the next phase of growth, and help define the next generation of brand measurement.&lt;/p&gt;
    &lt;p&gt;What you will do:&lt;/p&gt;
    &lt;p&gt;Build AI-powered customer experiences — integrate LLMs and advanced causal inference techniques into production workflows that automatically generate data visualizations, synthesize campaign performance into natural language insights, and help enterprise customers understand and optimize their advertising through our AI analyst "Bayes."&lt;/p&gt;
    &lt;p&gt;Design and build scalable backend systems —develop microservices and RESTful APIs that power the analytics platform behind the world’s top brand campaigns.&lt;/p&gt;
    &lt;p&gt;Contribute across the stack — work from backend APIs to Python analytics services to React frontends, delivering complete features that combine sophisticated data analysis with intuitive user experiences.&lt;/p&gt;
    &lt;p&gt;Engineer data pipelines at scale — design and operate systems that process massive volumes of ad and survey data with MySQL, DynamoDB, and AWS (S3, Lambda, EMR, Kinesis Firehose).&lt;/p&gt;
    &lt;p&gt;Improve reliability and performance — deploy services on Kubernetes and AWS, automate deployments via CI/CD, monitor with DataDog and Sentry, and continuously raise the bar for operational excellence&lt;/p&gt;
    &lt;p&gt;Collaborate deeply — work closely with Product and Data Science to productionize statistical models, integrate advanced analytics into customer-facing tools, and bring cutting-edge AI capabilities to enterprise customers.&lt;/p&gt;
    &lt;p&gt;Deliver insights that move millions — enable brand lift analytics and real-time campaign insights by building reliable, high-throughput systems. Multi-million dollar advertising decisions hinge on our recommendations.&lt;/p&gt;
    &lt;p&gt;About you:&lt;/p&gt;
    &lt;p&gt;You’re an experienced engineer (5+ years) who thrives on solving complex problems across APIs, data systems, and distributed infrastructure. You care about clean architecture, reliable systems, and measurable customer impact.&lt;/p&gt;
    &lt;p&gt;You’ve built powerful, intuitive, API-driven products for professional users.. You’re comfortable across the stack, with experience in RDBMS-backed backends using Spring Boot, Django, Rails, or Express, and single-page frontends built in React, Vue, or Angular.&lt;/p&gt;
    &lt;p&gt;You understand and enjoy programming. You’re fluent in the modern landscape of UI frameworks, API and microservice architectures, databases, and cloud platforms—and know when to use the right tool for the job.&lt;/p&gt;
    &lt;p&gt;You embrace modern AI-powered development tools to move faster and code smarter. You use technologies like Claude Code, Cursor, and GitHub CoPilot to automate routine work, explore ideas quickly, and focus your time on higher-value system design and innovation.&lt;/p&gt;
    &lt;p&gt;You value structured software development practices—testing, documentation, CI/CD, and code review—and care about building maintainable systems that scale.&lt;/p&gt;
    &lt;p&gt;You believe developers should operate what they build. You think about observability, cost, and reliability from day one, and design systems that are easy to deploy and maintain. You’ve built in the cloud and know both its power and pitfalls.&lt;/p&gt;
    &lt;p&gt;You like turning ideas into tools that make real customers more effective. You collaborate closely with Product to design features that solve real-world problems and delight users.&lt;/p&gt;
    &lt;p&gt;You mentor others, share knowledge freely, and understand that healthy human systems are the foundation of healthy technical systems. Teammates look to you for guidance.&lt;/p&gt;
    &lt;p&gt;You want to understand how things work and why. You care more about the best idea winning than whose idea it is.&lt;/p&gt;
    &lt;p&gt;You take responsibility, move quickly to fix problems, and take pride in establishing areas of deep expertise in a fast-changing environment.&lt;/p&gt;
    &lt;p&gt;You believe high-trust, inclusive teams outperform individuals. You communicate clearly and compassionately, and contribute to a culture where people enjoy working together.&lt;/p&gt;
    &lt;p&gt;Bonus points:&lt;/p&gt;
    &lt;p&gt;Have worked with modern backend ecosystems like Java/Kotlin/Groovy (Spring Boot or Grails) and know how to design APIs that scale elegantly.&lt;/p&gt;
    &lt;p&gt;Are fluent with data systems such as MySQL, DynamoDB, and Presto, and understand the tradeoffs between relational and NoSQL storage.&lt;/p&gt;
    &lt;p&gt;Have built cloud-native applications on AWS, especially using Kubernetes and Terraform for automation and scalability.&lt;/p&gt;
    &lt;p&gt;Know your way around modern front-end frameworks like React/Redux and enjoy collaborating up and down the stack.&lt;/p&gt;
    &lt;p&gt;Have startup DNA—you’re comfortable with ambiguity, iterate fast, and make pragmatic technical decisions.&lt;/p&gt;
    &lt;p&gt;Bring experience from AdTech, MarTech, or measurement platforms, or are excited to learn how AI and large-scale data intersect in this space.&lt;/p&gt;
    &lt;p&gt;Why You’ll Like Working Here:&lt;/p&gt;
    &lt;p&gt;Engineering-first company: Upwave’s success depends on high-velocity innovation, and we believe high velocity comes from high efficiency, not high effort. We set priorities rather than deadlines, we don’t crunch, we work reasonable hours, and engineers actually take vacations.&lt;/p&gt;
    &lt;p&gt;Modern tech stack: Python analytics, Kotlin/Java APIs, event streaming (100k+ RPM), DynamoDB, Kubernetes, AWS, Terraform, LLM orchestration.&lt;/p&gt;
    &lt;p&gt;Impact at scale: Your code processes billions of advertising events and directly influences multi-million dollar decisions by Fortune 500 brands.&lt;/p&gt;
    &lt;p&gt;Autonomy and ownership: Our engineers lead projects from design through deployment and monitoring.&lt;/p&gt;
    &lt;p&gt;Ambitious but humble culture: We take our work seriously but never ourselves. Upwavers collaborate hard and support each other generously. We screen for people who are both exceptionally talented and genuinely kind.&lt;/p&gt;
    &lt;p&gt;Remote-first team: Our diverse team spans half the globe (but only one half, to ensure everyone can talk live when we need to). We balance synchronous core hours with flexibility to create a work environment that enables both deep collaboration and deep work.&lt;/p&gt;
    &lt;p&gt;Additional Information:&lt;/p&gt;
    &lt;p&gt;The annual base salary range for this role is $150,000 - $175,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for the new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits.&lt;/p&gt;
    &lt;p&gt;Upwave is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45749690</guid><pubDate>Wed, 29 Oct 2025 17:00:15 +0000</pubDate></item><item><title>OpenAI’s promise to stay in California helped clear the path for its IPO</title><link>https://www.wsj.com/tech/ai/openais-promise-to-stay-in-california-helped-clear-the-path-for-its-ipo-3af1c31c</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45750425</guid><pubDate>Wed, 29 Oct 2025 17:44:34 +0000</pubDate></item><item><title>The Internet runs on free and open source software and so does the DNS</title><link>https://www.icann.org/en/blogs/details/the-internet-runs-on-free-and-open-source-softwareand-so-does-the-dns-23-10-2025-en</link><description>&lt;doc fingerprint="8ac2858004c20ddf"&gt;
  &lt;main&gt;
    &lt;p&gt;Free and open-source software (FOSS) is not merely common on the Internet; it is a deeply embedded and essential foundation of the Domain Name System (DNS), the backbone of how we connect online.&lt;/p&gt;
    &lt;p&gt;The ICANN Security and Stability Advisory Committee (SSAC) is pleased to announce the publication of SAC132: The Domain Name System Runs on Free and Open Source Software (FOSS).&lt;/p&gt;
    &lt;head rend="h3"&gt;Why This Matters Now&lt;/head&gt;
    &lt;p&gt;As governments around the world explore new cybersecurity regulations, the ubiquity of FOSS in DNS operations—from domain registration to retrieval—means that policy decisions made today will have direct implications for the Internet's security and resilience tomorrow. SAC132 provides timely, nontechnical guidance to ensure that new policy and regulation serve to strengthen, rather than inadvertently weaken, this critical infrastructure.&lt;/p&gt;
    &lt;head rend="h3"&gt;Key Insights for Policymakers&lt;/head&gt;
    &lt;p&gt;SAC132 is a foundational guide designed to empower policymakers to strategically manage and sustain the FOSS ecosystem. The report provides:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Clear Foundations – An accessible overview of the DNS and the FOSS development model for nontechnical audiences.&lt;/item&gt;
      &lt;item&gt;Policy Assessment – Analysis of cybersecurity regulations in the United States, United Kingdom, and European Union, with a focus on how they account for FOSS in the DNS ecosystem.&lt;/item&gt;
      &lt;item&gt;Practical Guidance – Concrete findings and recommendations to help policymakers support and secure FOSS as a cornerstone of global connectivity.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We invite all policymakers, technical experts, and stakeholders to read the full report.&lt;/p&gt;
    &lt;head rend="h3"&gt;A Call to Engage&lt;/head&gt;
    &lt;p&gt;By publishing SAC132, SSAC seeks to raise awareness of the indispensable role of FOSS in maintaining a secure, stable, and resilient Internet. We invite policymakers, technical experts, and all stakeholders to read the full report and join us in conversations about its findings.&lt;/p&gt;
    &lt;p&gt;You can engage with SSAC and the broader community at ICANN84, whether in Dublin or by participating remotely. Together, we can ensure that the FOSS ecosystem—and the Internet it supports—remains strong, sustainable, and open for all.&lt;/p&gt;
    &lt;p&gt;Finally, we thank all SSAC members and invited experts who contributed to this work, especially co-chairs Maarten Aertsen and Barry Leiba, for their leadership.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45750875</guid><pubDate>Wed, 29 Oct 2025 18:16:07 +0000</pubDate></item><item><title>Dithering – Part 1</title><link>https://visualrambling.space/dithering-part-1/</link><description>&lt;doc fingerprint="1336983308d69b52"&gt;
  &lt;main&gt;
    &lt;p&gt;Understanding how dithering works, visually.&lt;/p&gt;
    &lt;p&gt;tap/click the right side of the screen to go forward →&lt;/p&gt;
    &lt;p&gt;I’ve always been fascinated by the dithering effect. It has a unique charm that I find so appealing.&lt;/p&gt;
    &lt;p&gt;← tap/click the left side to go back&lt;/p&gt;
    &lt;p&gt;I was even more amazed when I learned how dithering works.&lt;/p&gt;
    &lt;p&gt;← or use arrow keys to navigate →&lt;/p&gt;
    &lt;p&gt;Look closely, and you’ll see this animation is made of alternating black and white pixels.&lt;/p&gt;
    &lt;p&gt;But these black and white pixels are specifically arranged to create the illusion of multiple shades.&lt;/p&gt;
    &lt;p&gt;That’s what dithering does: it simulates more color variations than what are actually used.&lt;/p&gt;
    &lt;p&gt;Here, it uses black and white to give the impression of multiple gray shades.&lt;/p&gt;
    &lt;p&gt;To me, dithering is about creating the most out of what we have, and that's what amazes me the most!&lt;/p&gt;
    &lt;p&gt;It inspired me to learn more about it, and now I want to share what I’ve learned.&lt;/p&gt;
    &lt;p&gt;Please note that this is just part one out of three, so I’ll only scratch the surface here.&lt;/p&gt;
    &lt;p&gt;I’ll go deeper in the next parts, which will come soon. Stay tuned!&lt;/p&gt;
    &lt;p&gt;First, let’s explore the dithering basics with this grayscale image example.&lt;/p&gt;
    &lt;p&gt;A grayscale image has various gray shades, from black to white.&lt;/p&gt;
    &lt;p&gt;Imagine a display that only shows black or white pixels, no grays. We must turn some pixels black and others white—but how?&lt;/p&gt;
    &lt;p&gt;One way is to map each pixel to the closest available color.&lt;/p&gt;
    &lt;p&gt;Pixels darker than medium gray turn black and lighter ones turn white.&lt;/p&gt;
    &lt;p&gt;This splits pixels into black or white groups.&lt;/p&gt;
    &lt;p&gt;However, this creates a harsh image with abrupt black-white transitions.&lt;/p&gt;
    &lt;p&gt;Shadow details vanish as gray pixels become fully black or white.&lt;/p&gt;
    &lt;p&gt;Dithering fixes this by selectively pushing some pixels towards the opposite color.&lt;/p&gt;
    &lt;p&gt;Some light gray pixels that are closer to white turn black.&lt;/p&gt;
    &lt;p&gt;Likewise, some dark grays turn white.&lt;/p&gt;
    &lt;p&gt;And it's done in a way that produces special patterns which simulate shades by varying the black-and-white pixel densities.&lt;/p&gt;
    &lt;p&gt;Denser black pixels are used in darker areas, while denser white pixels are used in lighter ones.&lt;/p&gt;
    &lt;p&gt;Next question: How are these patterns generated?&lt;/p&gt;
    &lt;p&gt;One simple dithering method, known as ordered dithering, uses a threshold map.&lt;/p&gt;
    &lt;p&gt;A threshold map is a grid of values representing brightness levels, from 0 (darkest) to 1 (brightest).&lt;/p&gt;
    &lt;p&gt;To dither, we compare each input pixel’s brightness to a corresponding threshold value.&lt;/p&gt;
    &lt;p&gt;If a pixel’s brightness exceeds the threshold (it’s brighter than the threshold), the pixel turns white. Otherwise, it turns black.&lt;/p&gt;
    &lt;p&gt;Repeating this for all pixels gives us the black-and-white dither patterns.&lt;/p&gt;
    &lt;p&gt;The threshold map is designed to output patterns where the black-and-white pixel density matches the input image’s shades.&lt;/p&gt;
    &lt;p&gt;So brighter input produces patterns with more white, while darker input produces more black.&lt;/p&gt;
    &lt;p&gt;These black-and-white density variations are what create the illusion of gray shades when viewed from a distance.&lt;/p&gt;
    &lt;p&gt;To dither larger images, we extend the threshold map to match the image size and follow the same principle:&lt;/p&gt;
    &lt;p&gt;Compare each pixel’s brightness to the threshold map, then turn it black or white accordingly.&lt;/p&gt;
    &lt;p&gt;The image now uses only two colors, but its overall appearance is preserved.&lt;/p&gt;
    &lt;p&gt;The variations in shades are now replaced by variations in black/white pixel density of the dithering patterns.&lt;/p&gt;
    &lt;p&gt;And that’s how dithering works in a nutshell: it replicates shades with fewer colors, which are strategically placed to maintain the original look.&lt;/p&gt;
    &lt;p&gt;I find it a bit ironic how I used to think dithering ‘adds’ a cool effect, when what it actually does is ‘remove’ colors!&lt;/p&gt;
    &lt;p&gt;That's all for now! We’ve reached the end, but there’s still a lot more to explore.&lt;/p&gt;
    &lt;p&gt;For example, we haven’t explored the algorithm to create a threshold map. (spoiler: there are many ways!)&lt;/p&gt;
    &lt;p&gt;There’s also another algorithm called error diffusion, which doesn’t use a threshold map.&lt;/p&gt;
    &lt;p&gt;Each algorithm creates a distinct, unique look, which I believe deserves its own article.&lt;/p&gt;
    &lt;p&gt;And that's why I decided to break this series into three parts.&lt;/p&gt;
    &lt;p&gt;In the next part, I’ll dive into various algorithms for creating threshold maps.&lt;/p&gt;
    &lt;p&gt;In the final part, I’ll focus on the error diffusion algorithm.&lt;/p&gt;
    &lt;p&gt;We'll dive even deeper into dithering's mechanisms in these next 2 parts, so stay tuned!&lt;/p&gt;
    &lt;p&gt;Thank you for reading!&lt;/p&gt;
    &lt;p&gt;visualrambling.space is a personal project by Damar, someone who loves to learn about different topics and rambling about them visually.&lt;/p&gt;
    &lt;p&gt;If you like this kind of visual article, please consider following me on X/Twitter and sharing this with your friends.&lt;/p&gt;
    &lt;p&gt;I'll keep creating more visual articles like this!&lt;/p&gt;
    &lt;p&gt;https://x.com/damarberlari&lt;/p&gt;
    &lt;p&gt;_blank&lt;/p&gt;
    &lt;p&gt;Topics covered: Three.js, WebGL, dithering, visualization, interactive learning&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45750954</guid><pubDate>Wed, 29 Oct 2025 18:21:35 +0000</pubDate></item><item><title>Extropic is building thermodynamic computing hardware</title><link>https://extropic.ai/</link><description>&lt;doc fingerprint="27b6766c759d22ac"&gt;
  &lt;main&gt;
    &lt;p&gt;Thermodynamic Computing: From 0 to 1 (Launch Video)&lt;/p&gt;
    &lt;p&gt;October 30th, 2025&lt;/p&gt;
    &lt;p&gt;Extropic is building thermodynamic computing hardware that is radically more energy efficient than GPUs.&lt;/p&gt;
    &lt;p&gt;Our thermodynamic sampling units (TSUs) are inherently probabilistic, the perfect fit for probabilistic AI workloads.&lt;/p&gt;
    &lt;p&gt;Hardware&lt;/p&gt;
    &lt;p&gt;prototype platform&lt;/p&gt;
    &lt;p&gt;XTR-0 enables the development of ultra-efficient AI algorithms by providing low-latency communication between Extropic chips and a traditional processor.&lt;/p&gt;
    &lt;p&gt;Software&lt;/p&gt;
    &lt;p&gt;Our open-source Python library that enables everyone to develop thermodynamic algorithms and simulate running them on TSUs&lt;/p&gt;
    &lt;p&gt;We are hiring engineers and scientists to help us pioneer a new form of computing.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45750995</guid><pubDate>Wed, 29 Oct 2025 18:25:01 +0000</pubDate></item><item><title>Uv is the best thing to happen to the Python ecosystem in a decade</title><link>https://emily.space/posts/251023-uv</link><description>&lt;doc fingerprint="14982e51cdc48290"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;uv is the best thing to happen to the Python ecosystem in a decade&lt;/head&gt;
    &lt;p&gt;23 October 2025 | Reading time: 6 minutes&lt;/p&gt;
    &lt;p&gt;It’s 2025. Does installing Python, managing virtual environments, and synchronizing dependencies between your colleagues really have to be so difficult? Well… no! A brilliant new tool called uv came out recently that revolutionizes how easy installing and using Python can be.&lt;/p&gt;
    &lt;p&gt;uv is a free, open-source tool built by Astral, a small startup that has been churning out Python tools (like the excellent linter Ruff) for the past few years. uv can:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Install any Python version for you&lt;/item&gt;
      &lt;item&gt;Install packages&lt;/item&gt;
      &lt;item&gt;Manage virtual environments&lt;/item&gt;
      &lt;item&gt;Solve dependency conflicts extremely quickly (very important for big projects.)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What’s best is that it can do all of the above better than any other tool, in my opinion. It’s shockingly fast, written in Rust, and works on almost any operating system or platform.&lt;/p&gt;
    &lt;head rend="h2"&gt;Installing uv&lt;/head&gt;
    &lt;p&gt;uv is straightforward to install. There are a few ways, but the easiest (in my opinion) is this one-liner command — for Linux and Mac, it’s:&lt;/p&gt;
    &lt;code&gt;curl -LsSf https://astral.sh/uv/install.sh | sh&lt;/code&gt;
    &lt;p&gt;or on Windows in powershell:&lt;/p&gt;
    &lt;code&gt;powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"&lt;/code&gt;
    &lt;p&gt;You can then access uv with the command &lt;code&gt;uv&lt;/code&gt;. Installing uv will not mess up any of your existing Python installations — it’s a separate tool, so it’s safe to install it just to try it out.&lt;/p&gt;
    &lt;head rend="h2"&gt;Managing Python for a project&lt;/head&gt;
    &lt;p&gt;It’s always a good idea to work with virtual environments for any Python project. It keeps different bits of code and dependencies ringfenced from one another, and in my experience, it can save a lot of hassle to get into the habit of using virtual environments as soon as you can. uv naturally uses virtual environments, so it’s very easy to start using them if you get into using uv.&lt;/p&gt;
    &lt;p&gt;uv will build a Python environment for you based on what’s specified in a &lt;code&gt;pyproject.toml&lt;/code&gt; file in the directory (or parent directories) you’re working in. &lt;code&gt;pyproject.toml&lt;/code&gt; files are a standard, modern format for specifying dependencies for a Python project. A barebones one might look a bit like this:&lt;/p&gt;
    &lt;code&gt;[project]
name = "my_project"
version = "1.0.0"
requires-python = "&amp;gt;=3.9,&amp;lt;3.13"
dependencies = [
  "astropy&amp;gt;=5.0.0",
  "pandas&amp;gt;=1.0.0,&amp;lt;2.0",
]&lt;/code&gt;
    &lt;p&gt;In essence, it just has to specify which Python version to use and some dependencies. Adding a name and version number also aren’t a bad idea.&lt;/p&gt;
    &lt;p&gt;(Sidenote: for projects that you publish as packages, such as to the Python Package Index that pip and uv use, &lt;code&gt;pyproject.toml&lt;/code&gt; files are a modern way to specify everything you need to publish your package.)&lt;/p&gt;
    &lt;head rend="h2"&gt;Making a new project with uv&lt;/head&gt;
    &lt;p&gt;To start a new Python project with uv, you can run&lt;/p&gt;
    &lt;code&gt;uv init&lt;/code&gt;
    &lt;p&gt;Which will create a new project for you, with a &lt;code&gt;pyproject.toml&lt;/code&gt;, a &lt;code&gt;README.md&lt;/code&gt;, and other important bits of boilerplate.&lt;/p&gt;
    &lt;p&gt;There are a lot of different ways to run this command, like &lt;code&gt;uv init --bare&lt;/code&gt; (which only creates a pyproject.toml), &lt;code&gt;uv init --package&lt;/code&gt; (which sets up a new Python package), and more. I recommend running &lt;code&gt;uv init --help&lt;/code&gt; to read about them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Once you have/if you already have a &lt;code&gt;pyproject.toml&lt;/code&gt; file&lt;/head&gt;
    &lt;p&gt;Once you initialize a project — or if you already have a &lt;code&gt;pyproject.toml&lt;/code&gt; file in your project — it’s very easy to start using uv. You just need to do&lt;/p&gt;
    &lt;code&gt;uv sync&lt;/code&gt;
    &lt;p&gt;in the directory that your &lt;code&gt;pyproject.toml&lt;/code&gt; file is in. This command (and in fact, most uv commands if you haven’t ran it already) will:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Automatically install a valid version of Python&lt;/item&gt;
      &lt;item&gt;Install all dependencies to a new virtual environment in the directory &lt;code&gt;.venv&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Create a &lt;code&gt;uv.lock&lt;/code&gt;file in your directory, which saves the exact, platform-agnostic version of every package installed — meaning that other colleagues can replicate your Python environment exactly.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In principle, you can ‘activate’ this new virtual environment like any typical virtual environment that you may have seen in other tools, but the most ‘uv-onic’ way to use uv is simply to prepend any command with &lt;code&gt;uv run&lt;/code&gt;. This command automatically picks up the correct virtual environment for you and runs your command with it. For instance, to run a script — instead of&lt;/p&gt;
    &lt;code&gt;source .venv/bin/activate
python myscript.py&lt;/code&gt;
    &lt;p&gt;you can just do&lt;/p&gt;
    &lt;code&gt;uv run myscript.py&lt;/code&gt;
    &lt;p&gt;which will have the same effect. Likewise, to use a ‘tool’ like Jupyter Lab, you can just do&lt;/p&gt;
    &lt;code&gt;uv run jupyter lab&lt;/code&gt;
    &lt;p&gt;in your project’s directory, as opposed to first ‘activating’ the environment and then running &lt;code&gt;jupyter lab&lt;/code&gt; separately.&lt;/p&gt;
    &lt;head rend="h2"&gt;Adding dependencies&lt;/head&gt;
    &lt;p&gt;You can always just edit your &lt;code&gt;pyproject.toml&lt;/code&gt; file manually: uv will detect the changes and rebuild your project’s virtual environment. But uv also has easier ways to add dependencies — you can just do&lt;/p&gt;
    &lt;code&gt;uv add numpy&amp;gt;=2.0&lt;/code&gt;
    &lt;p&gt;to add a package, including specifying version constraints (like the above.) This command automatically edits your &lt;code&gt;pyproject.toml&lt;/code&gt; for you. &lt;code&gt;uv add&lt;/code&gt; is also extremely powerful for adding remote dependencies from git or elsewhere on your computer (but I won’t get into that here.)&lt;/p&gt;
    &lt;head rend="h2"&gt;Pinning a Python version&lt;/head&gt;
    &lt;p&gt;Finally, I think that one of the most useful things uv can do is to pin a specific Python version for your project. Doing&lt;/p&gt;
    &lt;code&gt;uv python pin 3.12.9&lt;/code&gt;
    &lt;p&gt;would pin the current project to exactly Python 3.12.9 for you, and anyone else using uv — meaning that you really can replicate the exact same Python install across multiple machines.&lt;/p&gt;
    &lt;head rend="h2"&gt;uvx: ignore all of the above and just run a tool, now!&lt;/head&gt;
    &lt;p&gt;But sometimes, you might just want to run a tool quickly — like using Ruff to lint code somewhere, or starting a Jupyter notebook server without an environment, or even just quickly starting an IPython session with pandas installed so you can open up a file. The &lt;code&gt;uv tool&lt;/code&gt; command, which has a short alias &lt;code&gt;uvx&lt;/code&gt;, makes this insanely easy. Running a command like&lt;/p&gt;
    &lt;code&gt;uvx ruff&lt;/code&gt;
    &lt;p&gt;will automatically download the tool you want to use and run it in a one-off virtual environment. Once the tool has been downloaded before, this is lightning-fast because of how uv uses caches.&lt;/p&gt;
    &lt;p&gt;There are a lot of occasions when I might want to do this — a common one might be to quickly start an IPython session with pandas installed (using &lt;code&gt;--with&lt;/code&gt; to add dependencies) so that I can quickly open &amp;amp; look at a parquet file. For instance:&lt;/p&gt;
    &lt;code&gt;uvx --with pandas,pyarrow ipython&lt;/code&gt;
    &lt;p&gt;Or, maybe just starting a Jupyter Lab server so that I can quickly open a Jupyter notebook that a student sent me:&lt;/p&gt;
    &lt;code&gt;uvx jupyter lab&lt;/code&gt;
    &lt;p&gt;Or honestly just so many other weird, one-off use cases where &lt;code&gt;uvx&lt;/code&gt; is really nice to have around. I don’t feel like I’m missing out by always using virtual environments, because &lt;code&gt;uvx&lt;/code&gt; always gives you a ‘get out of jail free’ card whenever you need it.&lt;/p&gt;
    &lt;head rend="h2"&gt;If that hasn’t sold you: a personal note&lt;/head&gt;
    &lt;p&gt;I first discovered uv last year, while working together with our other lovely developers on building The Astrosky Ecosystem — a wonderful project to build open-source social media integrations for astronomers online. But with multiple developers all working asynchronously on multiple operating systems, managing Python installations quickly became a huge task.&lt;/p&gt;
    &lt;p&gt;uv is an incredibly powerful simplification for us that we use across our entire tech stack. As developers, we can all work with identical Python installations, which is especially important given a number of semi-experimental dependencies that we use that have breaking changes with every version. On GitHub Actions, we’re planning to use uv to quickly build a Python environment and run our unit tests. In production, uv already manages Python for all of our servers.&lt;/p&gt;
    &lt;p&gt;It’s just so nice to always know that Python and package installation will always be handled consistently and correctly across all of our machines. That’s why uv is the best thing to happen to the Python ecosystem in a decade.&lt;/p&gt;
    &lt;head rend="h2"&gt;Find out more&lt;/head&gt;
    &lt;p&gt;There’s a lot more on the uv docs, including a getting started page, more in-depth guides, explanations of important concepts, and a full command reference.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45751400</guid><pubDate>Wed, 29 Oct 2025 18:57:29 +0000</pubDate></item><item><title>How to Obsessively Tune WezTerm</title><link>https://rashil2000.me/blogs/tune-wezterm</link><description>&lt;doc fingerprint="7add1d0f7ddf6ef5"&gt;
  &lt;main&gt;
    &lt;p&gt;rashil2000 Posted: 6 October 2025&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45751995</guid><pubDate>Wed, 29 Oct 2025 19:39:57 +0000</pubDate></item><item><title>How the U.S. National Science Foundation Enabled Software-Defined Networking</title><link>https://cacm.acm.org/federal-funding-of-academic-research/how-the-u-s-national-science-foundation-enabled-software-defined-networking/</link><description>&lt;doc fingerprint="b5199159c83903c1"&gt;
  &lt;main&gt;
    &lt;p&gt;The Internet underlies much of modern life, connecting billions of users via access networks across wide-area backbones to countless services running in datacenters. The commercial Internet grew quickly in the 1990s and early 2000s because it was relatively easy for network owners to connect interoperable equipment, such as routers, without relying on a central administrative authority. However, a small number of router vendors controlled both the hardware and the software on these devices, leaving network owners with limited control over how their networks behave. Adding new network capabilities required support from these vendors and a multi-year standardization process to ensure interoperability across vendors. The result was bloated router software with tens of millions of lines of code, networks that were remarkably difficult to manage, and a frustratingly slow pace of innovation.&lt;/p&gt;
    &lt;p&gt;All of this changed with software-defined networking (SDN), where network owners took control over how their networks behaved. The key ideas were simple. First, network devices should offer a common open interface directly to their packet-forwarding logic. This interface allows separate control software to install fine-grained rules that govern how a network device handles different kinds of packets: which packets to drop, where to forward the remaining packets, how to modify the packet headers, and so on. Second, a network should have logically centralized control, where the control software has network-wide visibility and direct control across the distributed collection of network devices. Rather than running on the network devices themselves, the software can run on a separate set of computers that monitor and control the devices of a single network in real time.&lt;/p&gt;
    &lt;p&gt;The first commercial deployments of SDN started around 2008, and its success can be traced back to two intertwined developments that reinforced each other. The first was academic research funded mostly by the U.S. National Science Foundation (NSF). The second was cloud companies starting to build enormous datacenters, which required a new kind of network to interconnect thousands of racks of servers. In a virtuous cycle, the adoption of SDN by the hyperscalers drove further academic research, which in turn created more research, important new innovations, and several successful start-up companies.&lt;/p&gt;
    &lt;p&gt;As a result, SDN revolutionized how networks are built and operated today—the public Internet, private networks in commercial companies, university networks and government networks, and all the way through to the cellular networks that interconnect our smartphones.&lt;/p&gt;
    &lt;p&gt;Early NSF-funded SDN research. In 2001, a National Academies report, Looking Over the Fence at Networks: A Neighbor’s View of Networking Research,30 pointed to the perils of Internet ossification: an inability of networks to change to satisfy new needs. The report highlighted three dimensions of ossification: intellectual (backward compatibility limits creative ideas), infrastructure (it is hard to deploy new ideas into the infrastructure), and system (rigid architecture led to fragile, shoe-horned solutions). In an unprecedented move, the NSF set out to address Internet ossification by investing heavily over the next decade. NSF investments laid the groundwork for SDN. We describe NSF investments here, through the lens of the support we received in our own research groups. Importantly, these and other government-funded research programs fostered a community of researchers that together paved the way for commercial adoption of SDN in the years that followed.&lt;/p&gt;
    &lt;p&gt;100×100 project: In 2003, the NSF launched the 100×100 project as part of its Information Technology Research program. The goal of the 100×100 project was to create communication architectures that could provide 100Mb/s networking for all 100 million American homes. The project brought together researchers from Carnegie Mellon, Stanford, Berkeley, and AT&amp;amp;T. One key aspect of the 100×100 project was the design of better ways to manage large networks. This research led to the 4D architecture for logically centralized network control of a distributed data plane21 (which itself built upon and generalized the routing control platform work at AT&amp;amp;T15), Ethane (a system for logically centralized control of access control in enterprise networks),11 and OpenFlow (an open interface for installing match-action rules in network switches),28 as well as the creation of the first open source network controller, NOX.22&lt;/p&gt;
    &lt;p&gt;Global Environment for Network Innovation (GENI): NSF and researchers wanted to try out new Internet architectures on a nationwide, or global, platform. Computer virtualization was widely used to share a common physical infrastructure, so could we do the same for a network? In 2005, “Overcoming the Internet Impasse through Virtualization” proposed an approach.5 The next year, NSF created the GENI program, with the goal of creating a shared, programmable national infrastructure for researchers to experiment with alternative Internet architectures at scale. GENI funded early OpenFlow deployments on college campuses, sliced by FlowVisor35 to allow multiple experimental networks to run alongside each other on the same production network, each managed by their own experimental controller. This, in turn, led to a proliferation of new open source controllers (Beacon, POX, and Floodlight). GENI also led to a programmable virtualized backbone network platform,6 and an experimental OpenFlow backbone network in Internet2 connecting multiple universities. This led to OpenFlow-enabled switches from Cisco, HP, and NEC. GENI funded the purchase of OpenFlow whitebox switches from ODM manufacturers and the open source software to manage them. NSF funded the NetFPGA project, which enabled experimental OpenFlow switches in Internet2. NSF brought together a community of researchers driven by much more than the desire to create experimental test beds; many researchers came to realize that programmability and virtualization were, in fact, key capabilities needed for future networks.5,16&lt;/p&gt;
    &lt;p&gt;Future Internet Design (FIND): In 2007, NSF started the FIND program to support new Internet architectures that could be prototyped and evaluated on the GENI test bed. The FIND program and its successor Future Internet Architecture (FIA) in 2010 expanded the community, working on clean-slate network architectures and fostering alternative designs. The resulting ideas were bold and exciting, including better support for mobility, content delivery, user privacy, secure cloud computing, and more. NSF’s FIND and FIA programs fostered many clean-slate network designs with prototypes and real-world evaluation, many leveraged SDN and improved its foundations. As momentum for clean-slate networking research grew in the U.S., the rest of the world followed suit, such as the EU Future Internet Research and Experimentation (FIRE) program.&lt;/p&gt;
    &lt;p&gt;Programmable Open Mobile Internet (POMI) Expedition: In 2008, the NSF POMI Expedition at Stanford expanded funding for SDN, including its use in mobile networks. POMI funded the early development of ONOS, an open source distributed controller,8 and the widely used Mininet network emulator for teaching SDN and for testing ideas before deploying them in real networks. POMI also funded the first explorations of programmable forwarding planes, setting the stage for the first fully programmable switch chip10 and the widely used P4 language.9&lt;/p&gt;
    &lt;p&gt;SDN adoption by cloud hyperscalers. In parallel with the early academic research on SDN, large technology companies such as Microsoft, Google, Amazon, and Facebook began building large datacenters full of servers that hosted these companies’ popular Internet services and, increasingly, the services of enterprise customers. Datacenter owners grew frustrated with the cost and complexity of the commercially available networking equipment; a typical datacenter switch cost more than $20,000 and a hyperscaler needed about 10,000 switches per site. They decided they could build their own switch box for about $2,000 using off-the-shelf switching chips from companies such as Broadcom and Marvell, and then use their own armies of software developers to create optimized, tailored software using modern software practices. Reducing cost was good, but it was control they wanted and SDN gave them a quick path to get it.&lt;/p&gt;
    &lt;p&gt;The hyperscalers used SDN to realize two especially important use cases. First, within a single datacenter, cloud providers wanted to virtualize their networks to provide a separate virtual network for each enterprise customer (or “tenant”) with its own IP address space and networking policies. The start-up company Nicira, which emerged from the NSF-funded Ethane project, developed the Network Virtualization Platform (NVP)26 to meet this need. Nicira was later acquired by VMware and NVP became NSX. Nicira also created Open vSwitch (OVS),33 an open source virtual switch for Linux, with an OpenFlow interface. OVS grew rapidly and became the key to enabling network virtualization in datacenters around the world. Second, the hyperscalers wanted to control traffic flows across their new private wide-area networks and between their datacenters. Google adopted SDN to control how traffic is routed in its B4 backbone,23,39 using OpenFlow switches, controlled by ONIX, the first distributed controller platform.27 When Google first described B4 at the Open Network Summit in 2012, it sparked a global surge in research and commercialization of SDN. There were so many papers at ACM SIGCOMM that a separate conference—Hot Topics in Software-Defined Networking (HotSDN, later SOSR) was formed.&lt;/p&gt;
    &lt;p&gt;These two high-profile use cases—multi-tenant virtualization and wide-area traffic engineering—drew significant commercial attention to SDN. Indeed, NSF-funded research led directly to the creation of several successful SDN start-up companies, including Big Switch Networks (open source SDN controllers and management applications, acquired by Arista), Forward Networks (network verification products), Veriflow (developed network verification products, acquired by VMware), and Barefoot Networks (programmable switches, acquired by Intel), to name a few. SDN influenced the large networking vendors, with Cisco, Juniper, Arista, HP, and NEC all creating SDN products. Today, AMD, Nvidia, Intel, and Cisco all sell P4-programmable products, and in 2019 about a third of papers appearing at ACM SIGCOMM were based on P4 or programmable forwarding.&lt;/p&gt;
    &lt;p&gt;The commercial success of SDN drove further interest among academic researchers. The NSF and other government agencies, especially the Defense Advanced Research Project Agency (DARPA), sponsored further research on SDN platforms and use cases that continues to this day. The SDN research community broadened significantly, well beyond computer networking, to include researchers in the neighboring disciplines of programming languages, formal verification, distributed systems, algorithms, security and privacy, and more, all helping lay stronger foundations for future networks.&lt;/p&gt;
    &lt;p&gt;This article summarizes the story of how SDN arose. So many research projects, papers, companies, and products arose because of SDN that it is impossible to include all of them here. The foresight of NSF in the early 2000s, funding a generation of researchers at just the right time, working closely with the rapidly growing hyperscalers, led quite literally to a transformation—a revolution—in how networks are built today.&lt;/p&gt;
    &lt;p&gt;SDN Grew First and Fastest in Datacenters&lt;/p&gt;
    &lt;p&gt;The first large-scale deployments of SDN took place in hyperscale data centers, beginning about 2010. The story is best told by the hyperscaler companies themselves, and so we asked leaders at Google, Microsoft Azure, and Meta to tell their stories about why and how they adopted SDN. As you will see, they all started from the ideas and principles that came from the NSF-funded research; and each tailored SDN to suit their specific needs and culture.&lt;/p&gt;
    &lt;p&gt;The Internet Service Providers (ISPs) and telecommunication companies also had a strong interest in SDN. AT&amp;amp;T played a large role in its definition, engaging in research and early deployments in the mid 2000s. We invited Albert Greenberg, who was at AT&amp;amp;T at the time, to tell the story.&lt;/p&gt;
    &lt;p&gt;Nicira was perhaps the startup that epitomized the SDN movement. It grew out of the NSF-funded program and the Clean Slate Program at Stanford, based on the Ph.D. work of Martín Casado. Nicira developed ONIX, the first distributed control plane, used by Google in its infrastructure; OVS, the first OpenFlow-compliant software switch; and NVP (later NSX), the first network virtualization platform. We invited Teemu Koponen, a principal architect at Nicira, to tell the story.&lt;/p&gt;
    &lt;p&gt;During the early 2010s, the networking industry began to realize that SDN has many big advantages. It lifts complex protocols up and out of the switches into the control plane, where it is written in a modern programming language. This made it possible to reason about the correctness of the protocols simply by examining the software controlling the network and the forwarding state maintained by the switches. For the first time, it became possible to formally verify the behavior of a complete network.&lt;/p&gt;
    &lt;p&gt;Researchers, startups, network equipment vendors, and hyperscalers have all taken advantage of SDN principles to develop new ways to verify network behavior. We invited Professor George Varghese, who has been deeply involved in network verification research, to give us his perspective on network verification.&lt;/p&gt;
    &lt;p&gt;A main benefit of SDN is that it hands over the keys (of control) from the networking equipment vendors—who kept their systems closed and proprietary, and hence tended to evolve slowly—to software programmers, who could define the behavior for themselves, often in open source software. And indeed it happened: Today, most large networks are controlled by software written by those who own and operate networks rather than by networking equipment vendors.&lt;/p&gt;
    &lt;p&gt;But what about the hardware? Switches, routers, firewalls, and network interface cards are all built from special-purpose ASICs—highly integrated, cost-effective, and super-fast. The problem was the features and protocols that operated on packets (for example, forwarding, routing, firewalls, and security) were all baked into hardware at the time the chip was designed, two to three years before it was deployed. What if the network owner and operator needed to change and evolve the behavior in their network, for example to add a new way to measure traffic or a new way to verify behavior? A group of researchers and entrepreneurs set out to make the switches and NICs programmable by the user, to allow more rapid improvement and give the operator greater control. Not only did new programmable devices emerge, but a whole open source movement around the P4 programming language.&lt;/p&gt;
    &lt;p&gt;We invited Professor Nate Foster, who leads the P4 language ecosystem, to tell the story of how programmable forwarding planes came about.&lt;/p&gt;
    &lt;p&gt;So far, we have focused on SDN wireline networks running over electrical and optical cables in datacenters, enterprises, and long-haul WANs. SDN was originally defined with wireline networks in mind.&lt;/p&gt;
    &lt;p&gt;Yet, for cellular networks, the most widely used networks in the world, the need was even greater: Cellular networks have been held back for decades by closed, proprietary, and complex “standards” designed to allow equipment vendors to maintain a strong grip on the market. SDN provides an opportunity to open up networks, introducing well-defined control APIs and interfaces, moving control software to common operating systems running on commodity servers.&lt;/p&gt;
    &lt;p&gt;This story has only just begun, but it started thanks to NSF-funded research in the mid 2000s, then boosted by DARPA-funded programs to support open source software for cellular infrastructure. We invited Guru Parulkar and Oğuz Sunay to tell the story, both of whom developed open source cellular systems at the Open Networking Foundation and for the DARPA-funded Pronto project.&lt;/p&gt;
    &lt;p&gt;Conclusion&lt;/p&gt;
    &lt;p&gt;The investments NSF made in SDN over the past two decades have paid huge dividends. SDN transformed how companies run their datacenter, enterprise, cellular, and backbone networks, and created a pathway for creative new ideas to see widespread deployment. The biggest beneficiaries are the billions of people who have a much more reliable, more secure, lower-cost, and faster Internet for the services they use every day.&lt;/p&gt;
    &lt;p&gt;NSF invested in the foundations of SDN at a very early stage, back when it seemed unthinkable that network owners—rather than a few incumbent equipment vendors—could decide how networks behave. NSF nurtured the growing interest in SDN over many years, fostering a vibrant research community, critical software building blocks, and key early start-up companies that made SDN technologies available in practice. The Internet, and indeed computing and communication technologies in general, need the kind of bold, ongoing innovation that NSF makes possible.&lt;/p&gt;
    &lt;p&gt;Submit an Article to CACM&lt;/p&gt;
    &lt;p&gt;CACM welcomes unsolicited submissions on topics of relevance and value to the computing community.&lt;/p&gt;
    &lt;p&gt;You Just Read&lt;/p&gt;
    &lt;p&gt;How the U.S. National Science Foundation Enabled Software-Defined Networking&lt;/p&gt;
    &lt;p&gt;Communications of the ACM (CACM) is now a fully Open Access publication.&lt;/p&gt;
    &lt;p&gt;By opening CACM to the world, we hope to increase engagement among the broader computer science community and encourage non-members to discover the rich resources ACM has to offer.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45753222</guid><pubDate>Wed, 29 Oct 2025 21:22:50 +0000</pubDate></item><item><title>Responses from LLMs are not facts</title><link>https://stopcitingai.com/</link><description>&lt;doc fingerprint="f017bc6c9bc6ca51"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;âBut ChatGPT Saidâ¦â&lt;/head&gt;
    &lt;head rend="h2"&gt;Responses from Large Language Models like ChatGPT, Claude, or Gemini are not facts.&lt;/head&gt;
    &lt;p&gt;Theyâre predicting what words are most likely to come next in a sequence.&lt;/p&gt;
    &lt;p&gt;They can produce convincing-sounding information, but that information may not be accurate or reliable.&lt;/p&gt;
    &lt;head rend="h2"&gt;Imagine someone who has read thousands of books, but doesnât remember where they read what.&lt;/head&gt;
    &lt;p&gt;What kinds of things might they be good at?&lt;/p&gt;
    &lt;p&gt;What kinds of things might they be bad at?&lt;/p&gt;
    &lt;p&gt;Sure, you might get an answer thatâs right or advice that's goodâ¦ but what âbooksâ are it ârememberingâ when it gives that answer? That answer or advice is a common combination of words, not a fact.&lt;/p&gt;
    &lt;head rend="h2"&gt;Donât copy-paste something that a chatbot said and send it to someone as if thatâs authoritative.&lt;/head&gt;
    &lt;p&gt;When you do that, youâre basically saying âhere are a bunch of words that often go together in a sentence.â&lt;/p&gt;
    &lt;p&gt;Sometimes that can be helpful or insightful. But itâs not a truth, and itâs certainly not the final say in a matter.&lt;/p&gt;
    &lt;head rend="h3"&gt;Further reading:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;OpenAI: Why language models hallucinate&lt;/item&gt;
      &lt;item&gt;Oxford University: Large Language Models pose risk to science with false answers, says Oxford study&lt;/item&gt;
      &lt;item&gt;New York Times: A.I. Is Getting More Powerful, but Its Hallucinations Are Getting Worse (Archived Version)&lt;/item&gt;
      &lt;item&gt;MIT Media Lab: People Overtrust AI-Generated Medical Advice despite Low Accuracy&lt;/item&gt;
      &lt;item&gt;Business Insider: Why AI chatbots hallucinate, according to OpenAI researchers&lt;/item&gt;
      &lt;item&gt;Reuters: AI 'hallucinations' in court papers spell trouble for lawyers&lt;/item&gt;
      &lt;item&gt;Nature: AI chatbots are sycophants â researchers say itâs harming science&lt;/item&gt;
      &lt;item&gt;CNN: Parents of 16-year-old sue OpenAI, claiming ChatGPT advised on his suicide&lt;/item&gt;
      &lt;item&gt;Financial Times: The âhallucinationsâ that haunt AI: why chatbots struggle to tell the truth (Archived Version)&lt;/item&gt;
      &lt;item&gt;The Guardian: âSycophanticâ AI chatbots tell users what they want to hear, study shows&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45753422</guid><pubDate>Wed, 29 Oct 2025 21:40:05 +0000</pubDate></item><item><title>Meta and TikTok are obstructing researchers' access to data, EU commission rules</title><link>https://www.science.org/content/article/meta-and-tiktok-are-obstructing-researchers-access-data-european-commission-rules</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45754165</guid><pubDate>Wed, 29 Oct 2025 22:54:53 +0000</pubDate></item><item><title>A century of reforestation helped keep the eastern US cool (2024)</title><link>https://news.agu.org/press-release/a-century-of-reforestation-helped-keep-the-eastern-us-cool/</link><description>&lt;doc fingerprint="d2b8118e6db5e9dd"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Much of the U.S. warmed during the 20th century, but the eastern part of the country remained mysteriously cool. The recovery of forests could explain why&lt;/head&gt;
    &lt;p&gt;13 February 2024&lt;/p&gt;
    &lt;p&gt;AGU press contact:&lt;lb/&gt; Liza Lester, +1 (202) 777-7494, [email protected] (UTC-5 hours)&lt;/p&gt;
    &lt;p&gt;Contact information for the researchers:&lt;lb/&gt; Kim Novick, Indiana University, [email protected] (UTC-5 hours)&lt;lb/&gt; Mallory Barnes, Indiana University, [email protected] (UTC-5 hours)&lt;/p&gt;
    &lt;p&gt;WASHINGTON — Widespread 20th-century reforestation in the eastern United States helped counter rising temperatures due to climate change, according to new research. The authors highlight the potential of forests as regional climate adaptation tools, which are needed along with a decrease in carbon emissions.&lt;/p&gt;
    &lt;p&gt;“It’s all about figuring out how much forests can cool down our environment and the extent of the effect,” said Mallory Barnes, lead author of the study and an environmental scientist at Indiana University. “This knowledge is key not only for large-scale reforestation projections aimed at climate mitigation, but also for initiatives like urban tree planting.”&lt;/p&gt;
    &lt;p&gt;The study was published in the AGU journal Earth’s Future, which publishes interdisciplinary research on the past, present and future of our planet and its inhabitants.&lt;/p&gt;
    &lt;head rend="h3"&gt;Return of the trees&lt;/head&gt;
    &lt;p&gt;Before European colonization, the eastern United States was almost entirely covered in temperate forests. From the late 18th to early 20th centuries, timber harvests and clearing for agriculture led to forest losses exceeding 90% in some areas. In the 1930s, efforts to revive the forests, coupled with the abandonment and subsequent reforestation of subpar agricultural fields, kicked off an almost century-long comeback for eastern forests. About 15 million hectares of forest have since grown in these areas.&lt;/p&gt;
    &lt;p&gt;“The extent of the deforestation that happened in the eastern United States is remarkable, and the consequences were grave,” said Kim Novick, an environmental scientist at Indiana University and co-author of the new study. “It was a dramatic land cover change, and not that long ago.”&lt;/p&gt;
    &lt;p&gt;During the period of regrowth, global warming was well underway, with temperatures across North America rising 0.7 degrees Celsius (1.23 degrees Fahrenheit) on average. In contrast, from 1900 to 2000, the East Coast and Southeast cooled by about 0.3 degrees Celsius (0.5 degrees Fahrenheit), with the strongest cooling in the southeast.&lt;/p&gt;
    &lt;p&gt;Previous studies suggested the cooling could be caused by aerosols, agricultural activity or increased precipitation, but many of these factors would only explain highly localized cooling. Despite known relationships between forests and cooling, studies had not considered forests as a possible explanation for the anomalous, widespread cooling.&lt;/p&gt;
    &lt;p&gt;“This widespread history of reforestation, a huge shift in land cover, hasn’t been widely studied for how it could’ve contributed to the anomalous lack of warming in the eastern U.S., which climate scientists call a ‘warming hole,’” Barnes said. “That’s why we initially set out to do this work.”&lt;/p&gt;
    &lt;head rend="h3"&gt;Trees are cool&lt;/head&gt;
    &lt;p&gt;Barnes, Novick and their team used a combination of data from satellites and 58 meteorological towers to compare forests to nearby grasslands and croplands, allowing an examination of how changes in forest cover can influence ground surface temperatures and in the few meters of air right above the surface.&lt;/p&gt;
    &lt;p&gt;The researchers found that forests in the eastern U.S. today cool the land’s surface by 1 to 2 degrees Celsius (1.8 to 3.6 degrees Fahrenheit) annually. The strongest cooling effect occurs at midday in the summer, when trees lower temperatures by 2 to 5 degrees Celsius (3.6 to 9 degrees Fahrenheit) — providing relief when it’s needed most.&lt;/p&gt;
    &lt;p&gt;Using data from a network of gas-measuring towers, the team showed that this cooling effect also extends to the air, with forests lowering the near-surface air temperature by up to 1 degree Celsius (1.8 degrees Fahrenheit) during midday. (Previous work on trees’ cooling effect has focused on land, not air, temperatures.)&lt;/p&gt;
    &lt;p&gt;The team then used historic land cover and daily weather data from 398 weather stations to track the relationship between forest cover and land and near-surface air temperatures from 1900 to 2010. They found that by the end of the 20th century, weather stations surrounded by forests were up to 1 degree Celsius (1.8 degrees Fahrenheit) cooler than locations that did not undergo reforestation. Spots up to 300 meters (984 feet) away were also cooled, suggesting the cooling effect of reforestation could have extended even to unforested parts of the landscape.&lt;/p&gt;
    &lt;p&gt;Other factors, such as changes in agricultural irrigation, may have also had a cooling effect on the study region. The reforestation of the eastern United States in the 20th century likely contributed to, but cannot fully explain, the cooling anomaly, the authors said.&lt;/p&gt;
    &lt;p&gt;“It’s exciting to be able to contribute additional information to the long-standing and perplexing question of, ‘Why hasn’t the eastern United States warmed at a rate commensurate with the rest of the world?’” Barnes said. “We can’t explain all of the cooling, but we propose that reforestation is an important part of the story.”&lt;/p&gt;
    &lt;p&gt;Reforestation in the eastern United States is generally regarded as a viable strategy for climate mitigation due to the capacity of these forests to sequester and store carbon. The authors note that their work suggests that eastern United States reforestation also represents an important tool for climate adaptation. However, in different environments, such as snow-covered boreal regions, adding trees could have a warming effect. In some locations, reforestation can also affect precipitation, cloud cover, and other regional scale processes in ways that may or may not be beneficial. Land managers must therefore consider other environmental factors when evaluating the utility of forests as a climate adaptation tool.&lt;/p&gt;
    &lt;p&gt;***&lt;/p&gt;
    &lt;head rend="h3"&gt;Notes for Journalists:&lt;/head&gt;
    &lt;p&gt;This study is published in Earth’s Future, an open-access journal. Neither the paper nor this press release is under embargo. View and download a pdf of the study here.&lt;/p&gt;
    &lt;p&gt;This study is part of an ongoing special collection, “Quantifying Nature-based Climate Solutions,” from AGU’s publications.&lt;/p&gt;
    &lt;head rend="h3"&gt;Paper title:&lt;/head&gt;
    &lt;p&gt;“A Century of Reforestation Reduced Anthropogenic Warming in the Eastern United States”&lt;/p&gt;
    &lt;head rend="h3"&gt;Authors:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mallory L. Barnes (corresponding author), Indiana University, Indiana, USA&lt;/item&gt;
      &lt;item&gt;Kim Novick (corresponding author), Indiana University, Indiana, USA&lt;/item&gt;
      &lt;item&gt;Quan Zhang, Wuhan University, Wuhan, China&lt;/item&gt;
      &lt;item&gt;Scott M. Robeson, Indiana University, Indiana, USA&lt;/item&gt;
      &lt;item&gt;Lily Young, Indiana University, Indiana, USA&lt;/item&gt;
      &lt;item&gt;Elizabeth A. Burakowski, University of New Hampshire, New Hampshire, USA&lt;/item&gt;
      &lt;item&gt;Christopher. Oishi, USDA Forest Service, North Carolina, USA&lt;/item&gt;
      &lt;item&gt;Paul C. Stoy, University of Wisconsin-Madison, USA&lt;/item&gt;
      &lt;item&gt;Gaby Katul, Duke University, North Carolina, USA&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;AGU (www.agu.org) is a global community supporting more than half a million advocates and professionals in Earth and space sciences. Through broad and inclusive partnerships, we advance discovery and solution science that accelerate knowledge and create solutions that are ethical, unbiased and respectful of communities and their values. Our programs include serving as a scholarly publisher, convening virtual and in-person events and providing career support. We live our values in everything we do, such as our net zero energy renovated building in Washington, D.C. and our Ethics and Equity Center, which fosters a diverse and inclusive geoscience community to ensure responsible conduct.&lt;/p&gt;
    &lt;p&gt;#&lt;/p&gt;
    &lt;p&gt;Contributed by Gabriella Lewis&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45754390</guid><pubDate>Wed, 29 Oct 2025 23:17:02 +0000</pubDate></item><item><title>Raspberry Pi Pico Bit-Bangs 100 Mbit/S Ethernet</title><link>https://www.elektormagazine.com/news/rp2350-bit-bangs-100-mbit-ethernet</link><description>&lt;doc fingerprint="4f9925396be232bf"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Raspberry Pi RP2040 or RP2350 Bit-Bangs 100 Mbit/s Ethernet&lt;/head&gt;
    &lt;p&gt;on&lt;/p&gt;
    &lt;p&gt;Three years ago, @kingyoPiyo’s Pico-10BASE-T project drew wide attention right here on Elektor for implementing 10 Mbit/s Ethernet on the Raspberry Pi Pico using just a few resistors. In 2023, another milestone followed with bit-banged USB, showing how far the RP2040’s (and now RP2350) programmable I/O could be pushed.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Can an RP2350 Bit-Bang Next?&lt;/head&gt;
    &lt;p&gt;Now, developer Steve Markgraf (GitHub @steve-m) has extended the concept with Pico-100BASE-TX — a 100 Mbit/s Fast Ethernet transmitter running entirely in software.&lt;lb/&gt; Markgraf’s implementation uses the PIO and DMA to perform MLT-3 encoding, 4B5B line coding, and scrambling at a 125 MHz symbol rate. The result is a functioning 100 Mbit/s link capable of streaming about 11 Mbyte/s over UDP, demonstrated by real-time audio and ADC data streams.&lt;/p&gt;
    &lt;p&gt;As before, this is a transmit-only proof of concept and must not be connected to PoE-enabled hardware. A pulse transformer or intermediary Ethernet switch is recommended for isolation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Check Out the Rest of His Repo&lt;/head&gt;
    &lt;p&gt;Example applications in the repository include a counter, internal-ADC streamer, and an audio demo using a PCM1802 converter at 75 kHz. The library supports both the RP2040 and the newer RP2350 (Pico 2) and builds with the standard Pico SDK.&lt;/p&gt;
    &lt;p&gt;Source: Pico-100BASE-TX on GitHub — check it in action in the video there.&lt;/p&gt;
    &lt;p&gt;Beyond the technical achievement, projects like this hint at new possibilities for low-cost, high-speed data acquisition and streaming using microcontrollers that were never designed for it. A Pico capable of pushing 11 MB/s over Ethernet could form the basis of compact, inexpensive test instruments, remote sensors, or experimental network interfaces — all without a dedicated PHY chip. As these bit-banged interfaces become faster and more capable, the question naturally follows: how far can software-defined hardware really go on a two-dollar microcontroller?&lt;/p&gt;
    &lt;p/&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45754439</guid><pubDate>Wed, 29 Oct 2025 23:21:51 +0000</pubDate></item><item><title>Crunchyroll is destroying its subtitles</title><link>https://daiz.moe/crunchyroll-is-destroying-its-subtitles-for-no-good-reason/</link><description>&lt;doc fingerprint="6e0102d609bb31b5"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Crunchyroll is destroying its subtitles for no good reason&lt;/head&gt;&lt;p&gt;Since the beginning of the Fall 2025 anime season, a major change has started taking place at the anime streaming service Crunchyroll: the presentation quality for translations of on-screen text has taken a total nosedive compared to what has been on offer for many years, all the way up until the previous Summer 2025 season. Now, more and more subtitles on Crunchyroll are looking like this:&lt;/p&gt;&lt;p&gt;Poor presentation quality like this isnât entirely new to Crunchyroll, as a portion of the subtitles on the site have always been of third-party origin â that is, provided by the licensor â and Crunchyroll just puts them up with zero oversight. This in itself has caused numerous issues over the years, but the pressing issue here is that low quality presentation like this can now be found even in first-party subtitles created by Crunchyrollâs own subtitling staff. For comparison, hereâs the kind of presentation quality that first-party subtitles were providing just earlier this year:&lt;/p&gt;&lt;p&gt;Given the technical capabilities on display in the above screenshots, it should be clear that first-party subtitles for Fall 2025 shows shouldnât look as bad as they do. Yet for some reason, what weâre getting is this low quality presentation reminiscent of third-party subtitles, where translations for dialogue and on-screen text arenât even separated to different sides of the screen â everything is just bunched up together at either the top or the bottom. Lots of on-screen text is even left straight up untranslated.&lt;/p&gt;&lt;head rend="h2"&gt;And thatâs âdestroying subtitlesâ?&lt;/head&gt;&lt;p&gt;It sure is when itâs anime weâre talking about! Anime as a medium has made prominent use of on-screen text basically since its inception. The amount of it varies from series to series, but almost every anime out there makes use of on-screen text at one point or another, with some featuring downright ridiculous amounts of signs (what on-screen text is called for short). With all this on-screen text, it is also very common for there to be text visible on the screen potentially in multiple positions, even when characters are speaking.&lt;/p&gt;&lt;p&gt;As such, if you are in the business of localizing anime for non-Japanese audiences, you need to be able to deal with on-screen text. At bare minimum, when subtitling anime, you should be able to do overlaps (multiple lines of text on the screen at the same time) and positioning (the ability to freely place subtitles anywhere on the screen). Anything less and you are likely to run into trouble the moment you get to something as simple as a next episode preview:&lt;/p&gt;&lt;p&gt;Overlaps and positioning are really just the bare necessities for dealing with on-screen text in anime though â ideally, you should also be able to use different fonts, colors, animate text in various ways, etc. Making use of all these possibilities is an art unto itself, and this art of on-screen text localization is commonly referred to as typesetting. Typesetting is important even when dubbing anime, as all that on-screen text is going to be there in the video all the same!&lt;/p&gt;&lt;head rend="h2"&gt;So why would Crunchyroll get rid of typesetting?&lt;/head&gt;&lt;p&gt;That is a good question. It is no exaggeration to say that up to this point, Crunchyroll with its typesetting was the unambiguous market leader when it came to presentation quality for official anime subtitlesâ¦ though for the most part, other services dealing in anime have never even bothered to try. Sentai Filmworksâ Hidive is just about the only other anime service that even attempts to do typesetting, though they license so few shows per season that they are a tiny player compared to the Big Boys of anime streaming.&lt;/p&gt;&lt;p&gt;And it is very likely the existence of these Big Boys that has played a key part in Crunchyrollâs eradication of its typesetting. Netflix and Amazon Prime Video probably need no introduction to anyone reading this â both are very popular general streaming services. Despite anime being only a minor part of their catalogs, a large chunk of todayâs anime watching worldwide happens through said services thanks to their sheer user counts alone.&lt;/p&gt;&lt;p&gt;Crunchyroll clearly seems to know this, which is why it has been sublicensing its anime properties to both Amazon and Netflix for multiple years at this point. But with such sublicensing comes the matter of dealing with the subtitling standards of general streaming services. Iâm not going to mince words: these standards are awful, at least as far as anime is concerned. Netflix for example insists that you stick to at most two lines of text on screen at once, which makes sense most of the timeâ¦ if youâre talking about dialogue alone. Unfortunately, it becomes completely inadequate when dealing with animeâs plentiful on-screen text. Moreover, the standards of these services actively refuse to give you tools like positioning and overlaps, even though the TTML subtitle format they use supports said features!&lt;/p&gt;&lt;p&gt;With such typesetting-hostile standards to deal with, Crunchyroll had basically two choices for how to make sublicensing to Amazon and Netflix work with their existing subtitles that feature actual typesetting: Either 1) try to negotiate with the services for permission to make use of more TTML capabilities (that the subtitle renderers of said services should already support!) or 2) start mangling subtitles with typesetting into something compatible with the awful subtitling standards of the general streaming services. I am not aware if Crunchyroll ever attempted the former, but I can confirm that it eventually started doing the latter.&lt;/p&gt;&lt;p&gt;Editors among Crunchyrollâs subtitling staff were given an additional job to convert finished high quality subtitles with typesetting into limited low quality TTML subtitles without typesetting, compatible with Amazon &amp;amp; Netflix subtitling standards. They got paid extra for the manual effort required by the process.&lt;/p&gt;&lt;p&gt;Unfortunately, after a couple years of this kind of manual conversion work, the Crunchyroll leadership seems to have decided that it isnât enough, and that Crunchyroll must do away with high quality subtitles with typesetting entirely and only produce low quality TTML subtitles without typesetting from now on. But if they already had a working process for high quality subtitles at home and low quality TTML subtitles elsewhere, why would they just decide to give that up in order to produce exclusively low quality subtitles? It doesnât seem to make very much sense, even as a cost-cutting measure. There should be so much value in being able to advertise best viewed on Crunchyroll to potential audiences for long-term growth, right?&lt;/p&gt;&lt;p&gt;To understand how this is happening, we need to look into some relevant history. Specifically, what happened after Sony bought Crunchyroll and merged it with Funimation, another US anime distributor that Sony had bought previously. But in order to also understand why this is happening, first we need to look at what both Crunchyroll and Funimation were like before this fateful merger happened, as well as how they approached anime subtitling over the years.&lt;/p&gt;&lt;head rend="h2"&gt;A short history of Crunchyroll and its subtitling standards&lt;/head&gt;&lt;p&gt;Crunchyroll launched in 2006 as a pirate streaming site focused on East Asian media content, featuring fansubbed anime, live action drama, music videos, and so on. There was nothing particularly remarkable about the site back then â as a rule of thumb, pirate streaming sites are always worse quality-wise than if you just directly downloaded the pirated releases they use as a base, and the sites mostly exist to make their admins illicit money through ads, begging for donations, and other shady crap. It is important to note though that legal anime streaming basically wasnât a thing at this time.&lt;/p&gt;&lt;p&gt;Things started to change in 2008, when the Japanese anime studio Gonzo started experimenting with legal internet distribution for some of its titles. They struck deals with a couple companies for this, which is how Crunchyroll got its first few legitimate licenses. However, all the pirate material remained on the site while this was going on. Also in 2008: Crunchyroll managed to raise 4 million USD in venture capital funding while still operating as a pirate site, which drew vocal criticism from existing anime distributors at the time (for obvious reasons).&lt;/p&gt;&lt;p&gt;However, it was likely this exact venture capital funding that enabled Crunchyroll to negotiate a major deal with the Japanese broadcasting company TV Tokyo, which was announced at the start of 2009. This announcement brought with it the news that Crunchyroll was going full-time legitimate and getting rid of all its pirate content. With this move, Crunchyroll found itself in a position of having to start producing subtitles of its own (instead of just uploading fansubs) and somehow present said subtitles to its customers.&lt;/p&gt;&lt;p&gt;For the subtitle production part, Crunchyroll managed to strike a deal with a bunch of fansubbers to take on the job. This single decision was a fateful one, as it was the foundation for basically everything that came after â with former fansubbers on the job, the tools of the trade were set according to the standards of fansubbers: the subtitling software of choice was to be Aegisub, and the subtitle format of choice was to be Aegisubâs native format, Advanced SubStation Alpha, or ASS for short.&lt;/p&gt;&lt;p&gt;ASS is an extremely powerful format in terms of formatting and styling capabilities, and with Aegisub, it is easy to produce ASS subtitles that make use of said capabilities. However, as a streaming site, Crunchyroll needed to be able to present these ASS subtitles in the browser somehow, and the only full-fledged ASS renderers that existed were only available in the traditional local media playback environments targeted by fansubbers, which meant that Crunchyroll couldnât make use of said renderers on the web directly.&lt;/p&gt;&lt;p&gt;Now, there are two main ways to subtitle videos, with opposing pros and cons:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Hardsubbing â the subtitles are burned into the video itself. Simple to playback as you only need to be able to play video, but inflexible for updates and multiple languages as you have to recreate your video files over and over again with expensive processing called encoding.&lt;/item&gt;&lt;item&gt;Softsubbing â the subtitles exist as their own separate media track that the video player renders on top of the video in realtime during playback, making softsubs complex to playback, but updates and multiple tracks are very cheap as you only need to deal with tiny subtitle files while the video files remain unchanged.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;As such, one way Crunchyroll could have solved the subtitle presentation problem would have been to simply hardsub its ASS subtitles, but despite the challenges it posed, Crunchyroll decided to go with softsubbing instead (which was also the fansub standard at the time). And so Crunchyroll set out to build its own ASS renderer in Flash, the primary technology used to play video on the web at the time. Hereâs a screenshot of some of the first subtitles ever officially authored by the fully legitimate Crunchyroll, rendered in the current ASS renderer but adhering to the limits of the companyâs very first Flash subtitle renderer:&lt;/p&gt;&lt;p&gt;As can be seen, even the very first version was already capable of handling both overlaps and positioning. Now, the positioning was limited to the eight edges and the center of the screen, making for just nine possible positions total, but even that was enough to handle the humble next episode preview at the very least. Beyond these, the first version also supported fading animations. It wasnât much, but it did cover the bare minimum for dealing with on-screen text in anime.&lt;/p&gt;&lt;p&gt;Over the years, Crunchyroll managed to slowly improve its Flash subtitle renderer to enable the use of more ASS features. Custom colors, multiple fonts, multiple styles, rotation, and full positioning were implemented (albeit in somewhat hacky and unwieldy fashion). This went on until 2018, when Crunchyroll was faced with a major issue: Flash was seeing rapid decline in use, and web streaming was shifting over to HTML5-based technology. However, with a custom ASS renderer built in Flash, Crunchyroll couldnât easily make the change, as it would mean having to essentially rebuild the custom subtitle renderer they had from scratch in HTML5 (as much like in the Flash days, there still were no solutions native to the web available for rendering ASS subtitles).&lt;/p&gt;&lt;p&gt;However, Crunchyroll managed to come up with a way to solve the problem of moving from Flash to HTML5 with the help of another new web technology called WebAssembly, which allowed developers to take code that wasnât developed for the web and compile it for use on the web. With WebAssembly, Crunchyroll could take libass, one of the few fully-featured ASS renderers out there, and use it for their new HTML5 player. Now, not only did all their old ASS subtitles render nicely in HTML5, but the possibilities for typesetting at Crunchyroll had taken a huge leap forward. And the subtitling staff at Crunchyroll was more than happy to make use of this newfound power.&lt;/p&gt;&lt;p&gt;That said, despite having a technically fully-featured ASS renderer to work with, there were still limitations. Code compiled with WebAssembly runs worse compared to its original native counterpart, which limits how heavy the typesetting can be (with the flexible features of ASS, it is very easy to produce typesetting that simply cannot be rendered in realtime even on powerful computers, resulting in notable lag during playback). A commercial service like Crunchyroll will also generally want to keep its content watchable even on lower-end devices, which further reduces how complex any typesetting can be.&lt;/p&gt;&lt;p&gt;And this is the limited but functional standard of typesetting that Crunchyroll users got to enjoy (with first-party subtitles) up until the fateful season of Fall 2025 that prompted the creation of this article.&lt;/p&gt;&lt;p&gt;Before we move to the conclusions for this section, though, it is worth noting that while Crunchyroll currently uses softsubbed ASS subtitles whenever it can, there are platforms and devices (like various TVs) where this kind of ASS rendering simply isnât possible to do. Crunchyroll is available on some platforms like this, which means it has been making additional hardsubbed versions of everything on top of the usual softsubbed ones.&lt;/p&gt;&lt;p&gt;So, what can we learn from all this? At least one thing is abundantly clear: for most of its existence, the leadership at Crunchyroll had at least some respect and understanding for anime as a medium. They understood that it was important to be able to deal with on-screen text in their subtitles, and allocated enough resources to make typesetting possible. The company even managed to improve in this regard over time, albeit very slowly.&lt;/p&gt;&lt;p&gt;That said, anyone familiar with anime fansubs of the 2010s and 2020s probably canât help but feel disappointed that even the highest effort typesetting from Crunchyroll could only ever be on the level of fansub releases from around 2010 at best. Why 2010 specifically? Because from 2011 onwards, fansubbers started widely incorporating advanced motion tracking into their typesetting. Observe an example of such fansub typesetting from over a decade ago, the likes of which has never been seen on Crunchyroll:&lt;/p&gt;&lt;p&gt;Now, while fansubbers giving away their work for free might get away with saying &lt;quote&gt;just get a better computer&lt;/quote&gt; to anyone whose devices canât render softsubbed typesetting like this in realtime, an official service that lots of people pay for doesnât really have the same luxury, which is the main reason why you donât see stuff like this softsubbed on Crunchyroll. But this is not an insurmountable problem, so make no mistake: official anime services could absolutely offer typesetting with similar level of quality to the best of fansubs. The basic solution to the performance problem is very simple, even: you simply hardsub the typesetting. This would work from streaming to physical disc releases and only the sky would be the limit in terms of the typesetting quality you could offer, as realtime rendering would no longer be a concern!&lt;/p&gt;&lt;p&gt;Now, as mentioned earlier, hardsubbing does make things more complicated and expensive on the backend as you need to encode and store multiple copies of video. Crunchyroll is already dealing with this, though! But if costs are an issue, the system is pretty easy to improve in theory: if you keep the dialogue softsubbed, only the parts of the video that actually feature typesetting would be hardsubbed, and with some clever engineering and an understanding of how modern media formats work, you would only have to keep multiple copies of the typeset parts. And since the average anime episode has on-screen text only for a small percentage of its total runtime, combining softsubbed dialogue and hardsubbed typesetting like this would make for a highly cost-effective setup.&lt;/p&gt;&lt;p&gt;And since with a mixed system like this you would only have softsubs for the technically simpler dialogue, you could even convert these dialogue-only ASS subtitles to a simpler but more widely supported subtitle format for playback, which theoretically should do away with the need to keep fully hardsubbed copies around entirely, without any real loss in quality! I actually built a minimal version of a mixed system like this myself when I was doing some anime streaming work a few years back and can confidently say that this would be extremely doable for any official anime serviceâ¦ as long as they just cared enough.&lt;/p&gt;&lt;p&gt;Unfortunately, any interest Crunchyroll had for improving their subtitle rendering for typesetting seemed to run out after the 2018 transition to WebAssembly libass. Not that it actually ever seemed to be all that high to begin with, though, as evident by some of the low-hanging fruit that Crunchyroll never bothered to pick in this regard; the most obvious of which would be Crunchyrollâs dogged insistence to restrict typesetting font choices to Core Fonts for the Web. Free for commercial use fonts have been plentily available since the Flash days, and custom fonts have been well supported on the web for a similarly long time.&lt;/p&gt;&lt;p&gt;Anyway, it would have never been all that hard for Crunchyroll to support custom fonts for typesetting, especially after the 2018 move to HTML5. The underlying technology was there and font files are tiny in size compared to the video files being streamed â this would have been an extremely simple and effective improvement for all typesetting efforts. Yet Crunchyroll never reached for this improvement, which is why Comic Sans has kept appearing in Crunchyroll typesetting with depressing regularity.&lt;/p&gt;&lt;p&gt;It is also disappointing how regularly the anime staples of opening &amp;amp; ending songs are still left untranslated on Crunchyroll, though this issue is admittedly much harder to solve than youâd expect. Still, it is possible to do so, especially with Sonyâs resources behind the company today. That goes double when Sony is involved in anime production in any way, as then the songs being used should be well-known to all relevant parties well in advance of airing for timely rights-clearing. So if Crunchyroll/Sony is in any way involved with an animeâs production, it should basically always be possible for songs to be translated the moment the first episode is released.&lt;/p&gt;&lt;p&gt;But thatâs enough about Crunchyrollâs history. Now itâs time to look at the other company mentioned earlier and see how theyâve fared in comparisonâ¦&lt;/p&gt;&lt;head rend="h2"&gt;A short history of Funimation and its subtitling standards&lt;/head&gt;&lt;p&gt;In the early 90s, Japanese-American businessman Gen Fukunaga was approached by his uncle who was working as a producer for Toei. A proposal was made: if Fukunaga could start an anime company in US, Toei would license the rights to the Dragon Ball franchise to it â a franchise that was already making mad cash in Japan. Sensing an opportunity, Fukunaga found investors, and thus in 1994 Funimation was born. A year later, Dragon Ball was on US TV, dubbed and edited to âconform to American sensibilities and tastesâ.&lt;/p&gt;&lt;p&gt;In the early 2000s, fueled by Dragon Ballâs success, Funimation started expanding its business by getting home video distribution rights for 4Kids Entertainment licenses and non-Japanese kidsâ cartoons, the latter eventually expanding into getting involved in production too. But beyond increased investment in kidsâ cartoons, Funimation also started experimenting with more anime licenses of its own, the 2001 anime adaption for Fruits Basket being one of its early standout releases.&lt;/p&gt;&lt;p&gt;Out of these various expansion attempts, âmore animeâ seemed to be the one to work out best, and towards the end of the 00s that became the main direction of Funimationâs business. This move was helped along by a bunch of licenses obtained from now-defunct US anime publishers Geneon USA and ADV. And in the spring of 2009, hot on the heels of Crunchyroll going legit, Funimation announced that they too were getting into the anime streaming business. The resulting anime streams from Funimation were hardsubbed and looked like this:&lt;/p&gt;&lt;p&gt;What you see here is exactly what you got: plain text at top center or bottom center, with dialogue on bottom, and translations for all on-screen text piled up top. So while overlaps were technically supported, full positioning did not seem to be possible, which made things quite awkward the moment there was more than one sign visible on the screen at the same time. This was also the standard you could expect from Funimationâs DVD and Blu-ray releases. And beyond the way too common dialogue three-liners (which are generally terrible for readability), sometimes you even saw four-liners:&lt;/p&gt;&lt;p&gt;The subtitling software that Funimation was using at the time was Telestream MacCaption. In terms of usability and general authoring features, it was no match for Aegisub, although it was actually capable of doing some overlaps, positioning, and styling â Funimation just never chose to make use of these capabilities for its anime subtitles.&lt;/p&gt;&lt;p&gt;This remained the Funimation subtitle standard all the way until 2016, when Funimation struck a deal with Crunchyroll. Going forward, subtitled releases for Funimation licenses would be found on Crunchyroll, while dubbed releases for said titles would be on Funimationâs new streaming platform, FunimationNow.&lt;/p&gt;&lt;p&gt;However, the only thing that really changed is that instead of Funimation content being hardsubbed on their website, it was now softsubbed on Crunchyroll to the exact same standard: plain text on top center or bottom center, often with three or more lines of dialogue at once, even.&lt;/p&gt;&lt;p&gt;Nothing else of particular note happened during this time period when it comes to Funimationâs subtitles. However, it is worth mentioning that Funimation dubs did have simple hardsubbed typesetting sometimes; this only seemed happen at the whim of the dubbing side of Funimation though, as these hardsubbed signs were never present in the subbed versions, nor were they a consistent feature of Funimation dubs in general.&lt;/p&gt;&lt;p&gt;In 2017, Sony purchased Funimation as part of its growing collection of international anime distributors (Sony had previously bought Madman Anime and AnimeLab in Australia and Wakanim in Europe). As a result of this buyout, towards the end of 2018 the license sharing deal between Funimation and Crunchyroll was dissolved and soon after Funimation started serving new subtitled streams on FunimationNow, which were softsubbed and looked like this:&lt;/p&gt;&lt;p&gt;No longer were the subtitles even making use of overlaps. Where dialogue translation used to go on bottom and sign translation on top when both were present, now all text was stuck on the same side of the screen together, either on top or bottom, but never both at the same time anymore.&lt;/p&gt;&lt;p&gt;How this further reduction in subtitling capabilities came about cannot be said for sure, but there are several possible explanations. For one, another major thing that happened at the end of 2018: Funimation signed a big sublicensing deal with the general streaming service Hulu, which meant dealing with Huluâs subtitling standards and authoring accordingly limited subtitles â because as could be expected, the subtitling standards of a general streaming service did not account for the needs of anime in any real way.&lt;/p&gt;&lt;p&gt;Another possible reason for these less-than-great changes in Funimationâs subtitling standards was that around this time the company started using the cloud-based subtitling toolkit OOONA Tools by the localization service provider OOONA. OOONA Tools, by default, do not allow for the creation of subtitles with overlaps. While it can be done in OOONA today by tweaking the options or by using OOONAâs track features (which are quite similar to those of MacCaption, incidentally), it is possible that at the time these features were either not available or that it wasnât possible to correctly export subtitles with overlaps to the WebVTT subtitle format that was being used on FunimationNow.&lt;/p&gt;&lt;p&gt;Regarding that last possibility in particular, there is this OOONA FAQ entry that mentions how &lt;quote&gt;not all formats support [â¦] overlapping subtitles&lt;/quote&gt; and that &lt;quote&gt;Currently, itâs supported in IMSC1.1, ITT and Videotron Lambda CAP exports&lt;/quote&gt;. However, based on my own testing, OOONA Tools can properly export subtitles with overlaps in more formats today than just the ones mentioned here (including WebVTT), meaning that the FAQ entry is in fact outdated â but it was likely true at some point.&lt;/p&gt;&lt;p&gt;In any case, this was the extremely limited standard of subtitling that Funimation customers had to live with until the service was shut down in 2024 as a result of the Funimation-Crunchyroll merger.&lt;/p&gt;&lt;p&gt;Now, what can we conclude from all this? If nothing else, one thing seems abundantly clear: the Funimation leadership never truly cared about or respected anime as a medium. From the very beginning, itâs clear that Gen Fukunaga (a businessman in his 30s at the time) got into the business with the mindset of making money with kidsâ cartoons, and this only became more evident with how Funimation tried to expand into more types of kidsâ cartoons before eventually realizing that anime is where the money was at.&lt;/p&gt;&lt;p&gt;But even with this eventual focus on more anime, no resources seem to have ever been dedicated to make typesetting an actual thing at Funimation, despite how obviously beneficial it would have been for their key product of localized anime. And the way Funimation never even bothered to figure out how to make the most of MacCaption, the expensive enterprise subtitling software they kept using for over a decadeâ¦ while I speculated about possible technical reasons for Funimation abandoning even overlaps when they started producing softsubs for FunimationNow, there was always one possible additional reason: they just didnât care at all. They ran into a problem, no resources were dedicated to fix the problem, and the subtitles got permanently worse as a result.&lt;/p&gt;&lt;p&gt;The whole move to OOONA was questionable in itself, as while OOONA was capable of exporting subtitles to both WebVTT for FunimationNow and TTML (or SRT, a very limited subtitle format) for Hulu in 2018, so was MacCaption. Why start paying for a monthly subscription service when your existing paid-for enterprise software should be able to deal with your needs just fine? I suspect the primary motivation behind the move (which could have even originated from the new parent company Sony) might have been the fact that it was trendy for companies at the time to move everything they possibly could to The Cloudâ¢, regardless of how much sense it actually madeâ¦ but thatâs enough about OOONA for now.&lt;/p&gt;&lt;p&gt;Ultimately, Funimationâs subtitling standards were extremely poor to begin with, and they only managed to make them worse over time. That is something that only utter indifference or outright disdain for anime as a medium could bring about, which seems to have been the exact attitude that Gen Fukunaga cultivated at the executive levels of Funimation â and his followers appear to have carried the torch even after his departure from the company. But more on that in the next section, when we finally get to the Funimation-Crunchyroll merger.&lt;/p&gt;&lt;head rend="h2"&gt;The Funimation-Crunchyroll merger and its consequences&lt;/head&gt;&lt;p&gt;Following Sonyâs 2017 purchase of Funimation, in 2019 Sony bought out Gen Fukunaga from the company entirely, which led to him stepping down as the General Manager, with Colin Decker taking his place. Soon after, Sony formed the Funimation Global Group to consolidate all the international anime publishing services it had bought, with Decker in charge of the joint venture as the CEO. Then, in late 2020, Sony announced that they were going to buy Crunchyroll, placing it under the executive control of the Funimation Global Group. The acquisition was completed in August 2021, coming with a statement from Sony that their goal is to âcreate a unified anime subscription experience as soon as possibleâ.&lt;/p&gt;&lt;p&gt;Then, in March 2022, the news came that Funimation, Crunchyroll, Wakanim, and VRV (Crunchyrollâs more general streaming service) would all be merged together into a single streaming service that would exist under the name of Crunchyroll (as it had the strongest brand of the lot). Funimation Global Group LLC was renamed to Crunchyroll LLC, with Funimation executives remaining in charge. Soon after, Colin Decker stepped down as the CEO, with Rahul Purini (previously COO) taking his place. The merger was complete.&lt;/p&gt;&lt;p&gt;However, as is often the case with mergers &amp;amp; acquisitions, layoffs were on the horizon. In 2023, 85 people were laid off globally in the name of employee redundancy. More layoffs have happened since then, with the most recent one being from just a couple months back in August 2025.&lt;/p&gt;&lt;p&gt;Things werenât much better for those left behind, as laid out in this Bloomberg article from 2024. Staff from Funimation was notably hostile towards those from Crunchyroll:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Tension between the camps arose almost immediately. In a Zoom meeting announcing [Sonyâs purchase of Crunchyroll], Funimation workers accused Crunchyroll of being pirates, alluding to the siteâs history, according to two people who were present.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;While Crunchyroll workers were quickly frustrated with the new executives from Funimation:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Current or former employees describe Crunchyrollâs new managementâprimarily from Funimationâas out-of-touch with employees and the anime fans the company once prioritized. Some executives write off anime as âkidsâ cartoons,â they said, and resist hiring job candidates who describe themselves as fans.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;And while all these internal troubles were going on, Crunchyroll CEO Rahul Purini was excited to talk about how interested he is in AI-generated subtitles.&lt;/p&gt;&lt;head rend="h3"&gt;How typesetting gets destroyed&lt;/head&gt;&lt;p&gt;In 2025, the executives came up with an idea: Crunchyroll should move away from Aegisub and ASS subtitles with typesetting and start producing exclusively limited TTML subtitles without typesetting in OOONA Tools. The likely end goal of this is to get rid of Crunchyrollâs unique ASS-based subtitle rendering entirely in favor of something more âindustry standardâ like TTML-based subtitle rendering. This would mean no longer having to pay staff for manual ASS-to-TTML conversion, as well as being able to drop the relatively expensive fully hardsubbed encodes for limited playback environments where ASS rendering is not possible (but some sort of TTML rendering usually is).&lt;/p&gt;&lt;p&gt;However, a major change affecting all aspects of the companyâs subtitling pipeline doesnât happen overnight, especially considering Crunchyrollâs large back catalog of ASS subtitles with typesetting that couldnât be automatically converted to limited TTML subtitles without typesetting. So while the subtitling staff was to be (begrudgingly) busy experimenting and onboarding with OOONA and doing manual ASS-to-TTML conversions for back catalog titles, technical work would also need to be done to prepare for this vision of a TTML-only future.&lt;/p&gt;&lt;p&gt;For this purpose, Crunchyroll seems to have decided that it would take its existing manual ASS-to-TTML conversions produced by the subtitling staff and treat them as the new master subtitle files. These TTML âmastersâ would then beâfor the time beingâconverted back to ASS with Closed Caption Converter for use with the current ASS-based subtitle rendering. And so, with the start of the Fall 2025 anime season, a plan like this was pushed to production; while regular ASS subtitles were still being produced by Crunchyrollâs subtitling staff, these ASS subtitles with typesetting were generally left unused, while only limited ASS-to-TTML-to-ASS conversions without typesetting were being presented to customers on most shows.&lt;/p&gt;&lt;p&gt;Implementing this interim pipeline with Closed Caption Converter didnât seem to go exactly as planned, though, as some Fall 2025 shows on Crunchyroll ended up having no subtitles at all on release, including the premieres of the latest seasons of hit shows My Hero Academia and Spy Ã Family.&lt;/p&gt;&lt;p&gt;With the internet taking note of all this, on the 9th of October 2025 Crunchyroll responded to a press inquiry by Anime News Network with the following statement:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Over the past few days, some users experienced delays in accessing the content they wanted and subtitle issues across certain series. These were caused by internal system problems â not by any change in how we create subtitles, use of new vendors or AI. Those internal issues have now been fully resolved.&lt;/p&gt;&lt;p&gt;Quality subtitles are a core part of what makes watching anime on Crunchyroll so special. They connect global fans to the heart of every story, and we take that responsibility seriously.&lt;/p&gt;&lt;p&gt;Thank you for your patience. Weâre committed to continuing to deliver the authenticity, quality, and care that fans deserve.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Following this statement, some of the new Fall 2025 shows have had their ASS-to-TTML-to-ASS subtitles switched out to the previously unused regular ASS subtitles. Other shows havenât. And some shows in the Crunchyroll back catalog have been updated with ASS-to-TTML-to-ASS subtitles, though the exact timing of these back catalog updates is unknown.&lt;/p&gt;&lt;p&gt;With all of this, the future of typesetting on Crunchyroll is unclear.&lt;/p&gt;&lt;p&gt;And thatâs how weâve found ourselves in the situation we face today. Remember what the first Crunchyroll subtitles from 2009 looked like? Yeah, these new subtitles adhering to limited TTML standards are even worse than the subtitles from 2009 in terms of how on-screen text can be handled! In other words: The presentation quality of Crunchyrollâs first-party subtitles has reached an all-time low in 2025.&lt;/p&gt;&lt;p&gt;There is only one conclusion that can be drawn from that: the Funimation-turned-Crunchyroll executives still do not have any respect for anime as a medium. In addition, they seem to be treating Crunchyroll and its ways of doing things as the ways of &lt;quote&gt;pirates&lt;/quote&gt; â which isnât entirely incorrect, as Crunchyrollâs use of Aegisub and ASS did originate from the ways of pirate fansubbers. But fansubbers deeply care about anime as medium (they wouldnât be illegally subtitling it for free as a hobby otherwise), which in turn means that the ways fansubbers have developed to subtitle anime are in fact extremely efficient for the job â much better than basically any âindustry standardsâ for subtitling, even.&lt;/p&gt;&lt;p&gt;But that clearly doesnât matter to the executives. The only thing that seems to be on their mind is how to best make money with kidsâ cartoons that none of them personally watch, and what they seem to consider âbestâ is getting rid of everything positively unique about Crunchyroll in favor of doing things the Funimation way, even if that means ditching Aegisub and ASS in favor of OOONA Tools and TTML and getting rid of typesetting in the process. MacCaption-based workflow around for its Blu-ray releases, with notable reduction in typesetting quality on Blu-ray as a result:&lt;/p&gt;conclusion is further supported by the fact that Crunchyroll has kept Funimationâs old&lt;p&gt;Then thereâs the whole plan of moving to OOONA in general, which is even more questionable than it was back in the Funimation days. Crunchyroll has a lot more to lose in terms of subtitle quality than Funimation ever did, yet the executives seem to want to go back to their âold reliableâ regardless. I canât even see it saving them any money in the long run, considering that Aegisub is completely free software while OOONA will incur constant ongoing costs with its per-user subscription pricing. Rather than authoring limited TTML in OOONA directly, paying the subtitling staff to keep the manual ASS to TTML conversions going would likely be cheaper!&lt;/p&gt;&lt;p&gt;Beyond that, there is also the thing about OOONA being an Israeli company. It is certainly a choice, not only in 2018 but most certainly in 2025, to heavily invest in the services of a company from a country that is actively committing genocide. However, to quell some unsubstantiated internet discourse I have seen in relation to this, I do want to emphasize that OOONA being Israeli is not really directly relevant to the quality issues this article is about.&lt;/p&gt;&lt;p&gt;The reason for this lies in enterprise subtitling software (âindustry standardsâ) being universally poor when it comes to producing high quality typesetting for anime, so it wouldnât really matter which software suite a switch was being made to â no matter what, moving away from Aegisub would destroy typesetting as it currently exists on Crunchyroll. And while Crunchyrollâs CEO has expressed his interest in AI subtitles, at least currently there has been no signs of any kind of AI (Israeli or otherwise) being used to create first-party subtitles on Crunchyroll.&lt;/p&gt;&lt;head rend="h3"&gt;Why Crunchyroll is so confident it will get away with this (or: how capitalism ruins everything)&lt;/head&gt;&lt;p&gt;Finally, I want to talk about the possible reasons for Crunchyroll executives feeling so confident about getting away with making their own primary product so much worse. Ultimately, it comes down to the fact that international anime licensing operates primarily on an exclusive licensing model. This means that generally only one service will be able to offer a specific title in specific language(s) in specific region(s), unless the service voluntarily decides to sublicense it out to others. This in turn upends the assumption that the existence of multiple anime services would be beneficial to consumers, as the services donât actually have to engage in competition on customer-beneficial factors like service quality almost at all â instead, they can just focus on hoarding as many exclusive licenses as possible.&lt;/p&gt;&lt;p&gt;This kind of âcompetitionâ twisted by exclusive licensing is more like a casino, where the customers might occasionally be thrown a bone, but at the end of the day, the house always wins. And the anime companies very much prefer to keep it that way, even if it means never being able to offer full coverage of new anime seasons â a limited amount of exclusives is much more important to them. Dreams of infinite growth are what drives the modern-day game of capitalism, and spending money to please customers rather than shareholders goes directly against said dreams. Itâs all about spending as little money as possible to make as much money as possible.&lt;/p&gt;&lt;p&gt;This is why the capitalists in charge of all the big companies these days are so excited about AI too: nothing gets them going more than the idea of not having for pay for those pesky human employees. This is no doubt the actual reason why Crunchyroll CEO Rahul Purini is interested in AI subtitles. It doesnât matter that anime localization costs are a drop in the bucket compared to the overall costs of anime production, even if you were talking about super high quality work with fansub-level typesetting. Any excuse to cut the wages of real human workers is one step closer to the next yacht purchase for the executive upper class.&lt;/p&gt;&lt;p&gt;â¦Whew, got a bit heated there. Anyway, the most likely reason why Crunchyroll executives believe they can get away with reducing the quality of their own service so much? Because Crunchyroll doesnât have any meaningful competition thanks to the primarily-exclusive licensing model used by the international anime industry. Even if they make the service worse, what can you do about it? Cancel your subscription and not watch the new anime youâre excited about?&lt;/p&gt;&lt;head rend="h2"&gt;What you can do about it&lt;/head&gt;&lt;p&gt;If you are currently subscribed to Crunchyroll, cancel your subscription. When asked for a reason, mention the bad subtitle quality and lack of typesetting. You could even link to this article. Beyond that, and this applies to people who arenât subscribed to Crunchyroll as well: spread the word! Share this article around, talk to people about how Crunchyroll is destroying its subtitles, make it so that Crunchyroll executives canât ignore the issue. And the most important thing: Keep it up until Crunchyroll actually makes a clear public commitment to keep typesetting anime.&lt;/p&gt;&lt;p&gt;Why ask for an explicit commitment? Because back in 2017 when Crunchyroll tried to drastically lower its video quality as a cost-cutting measure, vocal user complaints and subscription cancellations forced them to backtrack on it, eventually leading the company to make a statement and not just one but two technical follow-up posts where it explicitly promised to do better, and in the end, video quality actually improved compared to what was previously available. Ideally, the same would happen with Crunchyrollâs typesetting here.&lt;/p&gt;&lt;p&gt;I also want to emphasize that the recent statement Crunchyroll made about its Fall 2025 subtitles isnât really worth anything. Itâs worded in an intentionally obfuscated manner as to what actually has been &lt;quote&gt;fixed&lt;/quote&gt; â is it the lack of typesetting or just the issues with subtitles not going up for new releases? Then it just outright lies about there being &lt;quote&gt;no changes&lt;/quote&gt; with how subtitles are being handled, before ending on empty platitudes about &lt;quote&gt;quality subtitles&lt;/quote&gt; that mean nothing without concrete actions to back them up.&lt;/p&gt;&lt;p&gt;And so far, the actions of Crunchyroll have made the future of typesetting on the service anything but clear. The lower quality subtitles in the back catalog are especially alarming, as the back catalog was exactly where Crunchyroll also started with its 2017 video quality reduction plans, all the while remaining careful with changes to simulcasts where people were paying closer attention â which is exactly what seems to be happening with subtitles on Crunchyroll right now.&lt;/p&gt;&lt;p&gt;To sum things up: Without a clear public commitment to stick to higher subtitling standards that include typesetting, it is very likely that Crunchyroll executives will just delay their typesetting-killing plans and try again later. Thatâs why you need to cancel your subscription, encourage others to do so, and keep talking about this issue until Crunchyroll explicitly promises to do better.&lt;/p&gt;&lt;p&gt;Together, we can save Crunchyroll from itself!&lt;/p&gt;&lt;head rend="h3"&gt;Acknowledgements&lt;/head&gt;&lt;p&gt;This article would have never been as thorough and detailed as it is without the assistance of the following people:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;The multiple current and former Crunchyroll and Funimation workers who came forward to indepedently confirm the many previously unpublished details found in this article. Huge thanks, all of you.&lt;/item&gt;&lt;item&gt;BigOnAnime â for his great help with researching the historical technical details of Funimationâs subtitling standards. Thank you.&lt;/item&gt;&lt;item&gt;enonibobble â for his help with various screenshots and technical analysis of Crunchyroll subtitles. Thank you.&lt;/item&gt;&lt;item&gt;FayeÂ Duxovni â for bringing Crunchyrollâs use of old Funimation workflows for Blu-rays to my attention and providing the screenshots of it that are used in the article. Thank you.&lt;/item&gt;&lt;item&gt;Ridley, witchymary, Jhiday â for proofreading this article before release. Thanks, all of you.&lt;/item&gt;&lt;item&gt;People on social media who answered public questions I asked or otherwise helped with various small pieces of research. Thanks, all of you.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;External coverage&lt;/head&gt;&lt;p&gt;Iâm not the only one to have made note of Crunchyrollâs recent subtitle shenanigans, so hereâs some additional reading/watching on the subject elsewhere:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Why did Crunchyrollâs subtitles just get worse? by Miles Atherton (former head of marketing for Crunchyroll), on the newsletter Anime By The Numbers. This includes some additional details (like numbers!) that I didnât go over here (because this article was long enough as-is), so I can recommend giving it a read.&lt;/item&gt;&lt;item&gt;The Absolute State of Crunchyroll by YouTuber Motherâs Basement. This is a good watch just to see how bad the new Crunchyroll subtitles look like in action. Additionally, I didnât really talk about how badly timing quality has been affected by the recent changes too, but this video has some good examples of that as well.&lt;/item&gt;&lt;item&gt;Are Subtitles Getting Smaller? by Jerome Mazandarani on Anime News Network. This Answerman column is nominally about subtitles getting visually smaller, but most of it ends up being about the Crunchyroll subtitle situation. Jerome does keep incorrectly saying that general streaming services use the very bare-bones subtitle format SRT rather than TTML, though, and while these services do support SRT for ingestion (ie. content partners can deliver subtitles as SRT) and anime companies might even be making use of that, TTML is what the services actually use internally. SRT does not officially support any kind of positioning whatsoever, which means that even placing subtitles at the top of the screen would be impossible with it if the normal placement was on bottom.&lt;/item&gt;&lt;item&gt;The Crunchyroll Sub Flub by Lucas DeRuyter and Coop Bicknell, also on Anime News Network. Nothing particularly new in this one if youâre familiar with all the other coverage, but itâs nice to see this get discussed on the This Week in Anime column regardless. The more eyes on the subject, the better.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Iâm Daiz, a digital distribution expert and high quality media enthusiast. I have over a decade of experience with Japanese-to-English media localization, including anime subtitling, and I also care deeply about consumer rights. You can follow me on Bluesky, or drop me a mail.&lt;/p&gt;&lt;p&gt;Iâm working on getting Bluesky comments embedded at the end of the posts. For the time being though, you can read and join the discussion here!&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45754509</guid><pubDate>Wed, 29 Oct 2025 23:31:24 +0000</pubDate></item><item><title>OS/2 Warp, PowerPC Edition (2011)</title><link>https://www.os2museum.com/wp/os2-history/os2-warp-powerpc-edition/</link><description>&lt;doc fingerprint="f70569160197a9ca"&gt;
  &lt;main&gt;
    &lt;p&gt;The PowerPC adventure—by far the most exotic release of OS/2&lt;/p&gt;
    &lt;p&gt;In December 1995, after unexpectedly long development (but is that really unexpected?), IBM finally “shipped” OS/2 Warp, PowerPC edition. For brevity, this release will be further referred to as OS/2 PPC. Following years of hype and high expectation, the release was very low key and in fact marked the end of development of OS/2 for PowerPC. The product was only available to a limited number of IBM customers and was never actively marketed. OS/2 PPC may not even had a box, although there were nice looking official CDs.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Hardware&lt;/head&gt;
    &lt;p&gt;OS/2 PPC only supported an extremely limited range of hardware—IBM Personal Power Series machines. Those were desktop models 830 and 850, and OS/2 PPC probably also supported the Power Series ThinkPads 820 and 850, though that can be only inferred from the fact that the graphics chipset employed by these ThinkPads was on the very short list of supported devices in OS/2 PPC.&lt;/p&gt;
    &lt;p&gt;The IBM Power Series computers were IBM’s rather short lived foray into the PowerPC-based desktop personal computer market, circa 1995-1996. The PowerPC CPU aside, the systems were very similar to Intel based hardware of that era. They were designed around the PCI bus, but also included ISA expansion slots and on-board Crystal Audio ISA PnP chips. The desktop Power Series machines were IDE based, ThinkPads used SCSI disks. The computers had standard serial and parallel ports, as well as most of typical PC hardware such as interrupt and DMA controllers. The desktops had onboard S3 864 video, ThinkPads used Western Digital flat panel chipsets. Several optional graphics cards were supported, notably Weitek P9100 based accelerators. The desktops also had onboard Ethernet chips (AMD PCnet).&lt;/p&gt;
    &lt;p&gt;The Power Series systems were closely related to certain IBM RS/6000 workstations. The RS/6000 Model 43P-7248 was nearly identical to the Power Series 850. They used the same motherboard, only the RS/6000 had on-board SCSI controller. Unlike the RS/6000 systems intended for the workstation market and running almost exclusively IBM’s AIX operating system, the Power Series systems were designed for “regular” personal computer users. The machines were supposed to run OS/2, Windows NT, AIX, or Solaris. OS/2 PPC was only semi-finished, and the Solaris for PowerPC port (version 2.5.1) was similarly short-lived. Microsoft dropped PowerPC support in 1996, not long after the Windows NT 4.0 release. Most of the Power Series systems ended up running AIX, which supported them until version 5.1. Linux also supported the Power Series to some extent. Windows NT was clearly the closest competitor of OS/2 PPC.&lt;/p&gt;
    &lt;p&gt;For this article, OS/2 PPC was installed on a Power Series 830, installed by its previous owner in a RS/6000 43P case. The CPU was a 100MHz PowerPC 604 with 256KB L2 cache, and the machine was equipped with 192MB RAM, which was the maximum it could handle. The graphics was an on-board PCI S3 Vision 864 with 2MB video memory and true color S3 SDAC. The machine was equipped with 2.1GB IDE hard drive—AIX can handle up to 8GB and Linux can utilize even larger disks, but OS/2 and NT were not happy with anything over about 2.5GB. The 830 was originally sold with either 500MB or 1GB disks and 16MB RAM. The Power Series 850 systems were equipped with 100 or 120MHz CPUs, slightly more RAM and larger disks.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Software&lt;/head&gt;
    &lt;p&gt;OS/2 Warp, PowerPC edition was delivered on two CDs. The first CD contained the operating system and BonusPak, the second CD was an application sampler with several demo applications.&lt;/p&gt;
    &lt;p&gt;Installation was surprisingly easy and painless. The CD was bootable and there were almost no choices to make during installation—only the disk partitioning was user selectable. The PowerPC operating systems (OS/2, NT, AIX and Linux) generally did not coexist as there was no real equivalent of a boot manager and each OS wanted to install its own boot loader. The OS/2 installer re-partitioned the disk and overwrote any other operating systems. The boot partition had to be FAT. It was possible to create HPFS data partitions, but the HPFS support appeared to be somewhat unstable and likely a last-minute addition.&lt;/p&gt;
    &lt;p&gt;After the OS was copied from the installation CD-ROM and the system booted from fixed disk for the first time, the user was greeted by the following screen:&lt;/p&gt;
    &lt;p&gt;Indeed, OS/2 PPC really looked just like OS/2 Warp, at least at first glance. The system booted up in 640×480 mode with 256 colors, using the accelerated S3 driver. The desktop right after installation looked like this:&lt;/p&gt;
    &lt;p&gt;Still very much like OS/2 Warp, except for that little Systems Management folder. This feature was not present in the Intel OS/2 Warp release, although it was added later. After installing the BonusPak and a few other additions and changing the resolution, the desktop still looked like plain OS/2 Warp, with the exception of the background bitmap of course (click on the picture to see full size screenshot):&lt;/p&gt;
    &lt;p&gt;The system was now running in 1024×768 resolution, but still with 256 colors. The graphics chip supports 64K colors at this resolution, unfortunately the software used to take screenshots (a demo version of Impos/2) was unable to take any screenshots at this resolution. 256 colors it is then, and time to more closely examine the operating system. The README file is a good starting point, and it was quite long in OS/2 PPC. It consisted largely of a list of unimplemented or incomplete features.&lt;/p&gt;
    &lt;p&gt;For example, notice the word “Connect” in the screenshot. OS/2 Warp, PowerPC Edition, doesn’t have any connectivity to speak of. Networking support, in a nutshell, didn’t exist. No LAN Server client, no TCP/IP, nothing. There was just HyperAccess Lite and CompuServe Information Manager, which worked (in theory at least) over a modem. The product name itself seems to have been a last minute change. Programs and documentation in many instances refer to OS/2 Warp Connect, PowerPC Edition, but the final product was called just OS/2 Warp and not “Connect”. One of the README files explains the name change and alludes to networking support in “future versions”.&lt;/p&gt;
    &lt;p&gt;For development versions of OS/2 PPC there was TFTP support which talked directly to the microkernel Ethernet or Token Ring driver and entirely bypassed OS/2. This transport layer also supported remote debugging. This is in sharp contrast to Windows NT which fully supported networking (TCP/IP and SMB file sharing) on the same hardware. Networking was obviously planned for OS/2, but the project was killed before this part was done.&lt;/p&gt;
    &lt;p&gt;Not everything was so blatantly unfinished though. The DOS support in OS/2 PPC was a pleasant surprise:&lt;/p&gt;
    &lt;p&gt;On a closer look, it’s clear that OS/2 PPC included a full-fledged PC emulator, which supplied a virtual x86 CPU as well as common PC hardware. Interestingly, the DOS support in OS/2 PPC was based on PC-DOS 7 and not the outdated DOS 5 level code that OS/2 on Intel was stuck with. The OS/2 PPC DOS boxes thus had for instance the DOS E editor (very similar to TEDIT) or REXX support. Why IBM never updated the DOS support on the Intel side is a mystery. OS/2 PPC supported both windowed and full screen DOS sessions. The full screen sessions always ran in graphics mode, even when the emulated DOS application was using text mode.&lt;/p&gt;
    &lt;p&gt;Not satisfied with “just” DOS emulation, IBM also supported Win-OS/2, both full-screen and windowed:&lt;/p&gt;
    &lt;p&gt;It is difficult to judge how stable the DOS and Win-OS/2 emulation really was, but whatever little utilities came with the OS/2 system seemed to work well, including wave audio in Win-OS/2, and the performance was surprisingly good. IBM must have spent a lot of effort on the x86 emulation support. Documentation hinted at a possibility of future support for native OS/2 x86 applications via emulation.&lt;/p&gt;
    &lt;p&gt;IBM also obviously spent a lot of time on the multimedia support in OS/2 PPC. The multimedia support worked unexpectedly well, especially when contrasted with the problems common on Intel machines.&lt;/p&gt;
    &lt;p&gt;The system played video and audio without problems, with MIDI support either via a software synthesizer or an OPL3 compatible chip (the software synthesizer sounded far better). The application sampler CD came with several videos, mostly ads for OS/2. The PowerPC Toolkit also came with a beta version of OpenGL support, which shared code with IBM’s AIX workstation grade implementation.&lt;/p&gt;
    &lt;p&gt;OS/2 PPC was a hybrid halfway between Warp 3 and Warp 4. The user interface looked like Warp 3, but many of the features of OS/2 PPC later showed in Warp 4 on Intel. One of them was the not very popular Feature Installer:&lt;/p&gt;
    &lt;p&gt;The Feature Installer was used to install the BonusPak, several tools and games, and curiously enough, also the Command Reference which for some odd reason wasn’t part of the base install. Here’s one of those games:&lt;/p&gt;
    &lt;p&gt;Again, there is no real difference from the Intel version, except for the about box text (notice the “Connect” text). And finally the IBM Works text editor—again there is no discernible difference from the Intel version:&lt;/p&gt;
    &lt;head rend="h3"&gt;OS/2 for PowerPCs System Overview&lt;/head&gt;
    &lt;p&gt;OS/2 PPC was a strange OS. In many ways it was exactly identical to the Intel version, yet in other ways it was completely different. The user interface was the same and the entire API practically unchanged. Among the differences were the addition of full Unicode support and 32-bit console API (Kbd/Mou/Vio). The largely unchanged API was the reason why it was relatively easy to port existing OS/2 software to PowerPC. The biggest difference was not even the CPU but rather the compiler—IBM used the MetaWare High C/C++ for PowerPC development (it was allegedly cheaper for the IBM OS/2 division to contract MetaWare rather than IBM’s own compiler group). The MetaWare tool set was only used as a cross compiler hosted on x86 OS/2 systems. IBM used MetaWare’s compiler for embedded PowerPC development in general (IBM’s involvement with MetaWare goes at least as far back as AIX for PS/2), and MetaWare also marketed an OS/2 x86 product. Watcom was at the time working on PowerPC version of their compiler, but OS/2 PPC was killed before that project was finished. The last IBM Developer’s Connection release which contained OS/2 PPC material also included a beta version of IBM’s VisualAge C++ compiler. No release of a compiler (or a debugger) running natively on OS/2 PPC is known.&lt;/p&gt;
    &lt;p&gt;The OS/2 PPC development tools were quite different from their Intel counterparts. To begin with, instead of the LX executable format, OS/2 PPC used the industry standard ELF. Several tools were completely unchanged (IPFC for instance), many were entirely new (linker, librarian, resource compiler). The ABI (Application Binary Interface) used in OS/2 PPC was based on the UNIX SVR4 PowerPC ABI. One notable difference was that OS/2 of course ran in little endian mode, unlike PowerPC UNIX ports but just like Windows NT.&lt;/p&gt;
    &lt;p&gt;Delving deeper into the kernel, OS/2 PPC had precious little in common with the Intel version. The product was based on the IBM microkernel, which was a refinement of the Carnegie Mellon University Mach microkernel. The microkernel bore no resemblance to the Intel OS/2 kernel whatsoever and it was also very different from most other operating systems of the time (NeXTSTEP was also based on the Mach microkernel).&lt;/p&gt;
    &lt;p&gt;The initial grandiose plan was to build the Workplace OS, the One Ring to Bind Them All of operating systems. Workplace OS (or WPOS for short) was supposed to be built on top of the Mach microkernel and support multiple “personalities”. The personalities would implement existing operating systems such as OS/2, AIX, Windows NT and perhaps even Mac OS. In the end this never happened and the only supported personality was OS/2. This was somewhat similar to Windows NT where the the non-Windows personalities (environment subsystems) eventually withered away.&lt;/p&gt;
    &lt;p&gt;The initial plan was still tangible in OS/2 PPC. The OS/2 personality was implemented in the “OS/2 Server” and there were certain “personality neutral” services. Most device drivers were personality neutral and worked directly with the microkernel. This included disk and network drivers. A notable exception were the display drivers, where OS/2 PPC introduced the GRADD model (later ported to Intel OS/2). Documentation on OS/2 PPC internals is somewhat sparse and the online books shipped with PowerPC Toolkit were in many cases either incomplete or simply unmodified copies of OS/2 for Intel documentation. A good source of information is the Redbook titled “OS/2 Warp (Power PC Edition) – A First Look” published by IBM International Technical Support Organization in December 1995, document number SG24-4630-00 for those interested.&lt;/p&gt;
    &lt;head rend="h3"&gt;OS/2 for PowerPC Impressions&lt;/head&gt;
    &lt;p&gt;What was OS/2 Warp, PowerPC Edition like? An unfinished product, rough around the edges but simultaneously technically very interesting and advanced and showing promise. Even though the OS/2 PPC release wasn’t called a beta, it was obvious that this was a beta level product (if even that in some respects). Many features were unfinished or completely missing, notably networking. The kernel code didn’t look much like a production build and printed out quite a lot of debugging output on a serial console, if one was attached. The HPFS support was very unstable, and the stability of Win-OS/2 left a lot to be desired. There were too many clearly unfinished parts of the product—documentation, missing utilities, etc.&lt;/p&gt;
    &lt;p&gt;On the other hand a large portion of the system worked well. The user interface and graphics subsystem in general didn’t exhibit any anomalies. Multitasking was reliable and all things considered, responsiveness quite good for a 100MHz CPU and code that was not likely to have been performance tuned. The multimedia subsystem worked much better than expected. Many things were much improved compared to Intel OS/2—internationalization, graphics subsystem, updated console API, and so on. The system seemed to have enough raw power, even if it wasn’t harnessed too well. Boot time was rather long but once up and running, the system was snappy (with some exceptions, notably the CD-ROM driver). To reach true production quality, the OS would have needed at least additional six months of development, perhaps more.&lt;/p&gt;
    &lt;p&gt;How useful was OS/2 PPC? Not very. In fact, it was almost completely useless. It only ran on three or four models of rather rare IBM machines and supported almost no additional devices. The OS was clearly unfinished and not entirely stable. Worst of all, there were about zero applications. Because OS/2 PPC was never truly in use, PowerPC versions of OS/2 applications were never sold, although several OS/2 ISVs ported their applications to OS/2 PPC as evidenced by the application sampler. Porting wasn’t very difficult and tools for building PowerPC applications were available, but since there was no demand for them, there was little point in porting.&lt;/p&gt;
    &lt;p&gt;OS/2 for PowerPC was undoubtedly an interesting experiment, albeit a failed one. It is impossible to tell whether this failure was caused more by shortcomings of OS/2 for PowerPC or the failure—perhaps just falling far short of expectations—of the PowerPC platform as a whole.&lt;/p&gt;
    &lt;head rend="h3"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;Without the generosity of Mike Kaply and Chris Graham, this article could not be written.&lt;/p&gt;
    &lt;p&gt;Some of the above information was derived from IBM documentation and Redbooks, which may have been inaccurate due to the evolving nature of the OS/2 PPC project. Most of the remaining text is the result of observation and conjecture.&lt;/p&gt;
    &lt;p&gt;If you have any additional information, corrections, or interesting stories about OS/2 for PowerPC, please post a comment.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45754660</guid><pubDate>Wed, 29 Oct 2025 23:52:09 +0000</pubDate></item><item><title>IRCd service (2024)</title><link>https://example.fi/blog/ircd.html</link><description>&lt;doc fingerprint="3516fd1c7c8c88c8"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;IRCd service&lt;/head&gt;&lt;head rend="h2"&gt;10.6.2024&lt;/head&gt; Ok. We have IRC at example.fi&lt;lb/&gt;Internet Relay Chat (IRC) is a form of real-time text communication developed by Jarkko Oikarinen in 1988. Initially created to replace a local BBS system at the University of Oulu in Finland, IRC quickly gained global popularity, becoming a foundational technology for online chat communities and influencing the development of modern instant messaging and social media platforms. Its significance lies in its pioneering role in connecting people across the internet, fostering early online communities, and setting the stage for contemporary digital communication.&lt;lb/&gt;To commemorate this pivotal technology, example.fi provides a simple and limited IRC server. This server is uniquely written in AWK, a scripting language traditionally used for text processing, highlighting the adaptability and enduring legacy of IRC. This creative implementation serves as both an educational tool and a tribute to the foundational role of IRC in the evolution of online communication.&lt;lb/&gt;In the following picture you see Irssi in the background and Hexchat on top of it:&lt;lb/&gt;Note: if you plan to connect to example.fi, make sure you do not use any fancy features. In irssi, use -nocap option. In Windows, use for example hexchat.
As this is written in gawk, most IRC protocol features are not implemented. This includes, for example, channel and user listings, topics, the concept of "operator" etc.
Technical fun fact: Total code count is around 60 lines of awk and a few lines of bash.&lt;quote&gt; $ telnet example.fi ircd Trying 65.108.91.190... Connected to example.fi. Escape character is '^]'. USER foo NICK bar :example.fi 001 bar :Welcome to Internet Relay Network bar!~foo@65.108.91.190 :example.fi 375 test :- example.fi Message of the day - :example.fi 372 test :- Current time is @787.188.beats :example.fi 376 test :End of MOTD command. Connection closed by foreign host. &lt;/quote&gt;&lt;lb/&gt;Don't worry, we'll publish the code when it's "ready" :)&lt;p&gt;This site is HTML 2.0 compliant.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45755788</guid><pubDate>Thu, 30 Oct 2025 02:31:43 +0000</pubDate></item><item><title>Hello-World iOS App in Assembly</title><link>https://gist.github.com/nicolas17/966a03ce49f949dd17b0123415ef2e31</link><description>&lt;doc fingerprint="ad2ec50e2b187f6b"&gt;
  &lt;main&gt;
    &lt;p&gt; Last active &lt;relative-time&gt;October 28, 2025 19:30&lt;/relative-time&gt;&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;tool-tip&gt;Save nicolas17/966a03ce49f949dd17b0123415ef2e31 to your computer and use it in GitHub Desktop.&lt;/tool-tip&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt; hello-world iOS app &lt;/p&gt;
    &lt;p&gt; This file contains hidden or bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters &lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;.global _main&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;.extern _putchar&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;.align 4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;_main:&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; prolog; save fp,lr,x19&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;stp x29, x30, [sp, #-0x20]!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;str x19, [sp, #0x10]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x29, sp&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; make space for 2 dword local vars&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;sub sp, sp, #0x10&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; save argc/argv&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;stp x0, x1, [sp]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; create autorelease pool and save into x19&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _objc_autoreleasePoolPush&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x19, x0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; initialize app delegate class&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl initAppDelegate&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; create CFString with delegate class name&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x0, 0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;adrp x1, str_AppDelegate@PAGE&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;add x1, x1, str_AppDelegate@PAGEOFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x2, 0x0600 ; kCFStringEncodingASCII&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _CFStringCreateWithCString&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; x0 = UIApplicationMain(argc, argv, nil, CFSTR("AppDelegate"));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x3, x0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ldr x0, [sp]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ldr x1, [sp, #0x8]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x2, #0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _UIApplicationMain&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x7, x0 ; save retval&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; pop autorelease pool&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x0, x19&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _objc_autoreleasePoolPop&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; epilog&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; restore stack pointer&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;add sp, sp, 0x10&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; restore saved registers&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ldr x19, [sp, #0x10]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ldp x29, x30, [sp], #0x20&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; get retval&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x0, x7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ret&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;initAppDelegate:&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; prolog; save fp,lr,x20&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;stp x29, x30, [sp, #-0x20]!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;str x20, [sp, #0x10]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x29, sp&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; Class c = objc_allocateClassPair(objc_getClass("NSObject"), "AppDelegate", 0);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;adrp x0, str_NSObject@PAGE&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;add x0, x0, str_NSObject@PAGEOFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _objc_getClass&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;adrp x1, str_AppDelegate@PAGE&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;add x1, x1, str_AppDelegate@PAGEOFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x2, 0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _objc_allocateClassPair&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; save the class since we'll clobber x0 several times&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x20, x0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; class_addProtocol(c, objc_getProtocol("UIApplicationDelegate"));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;adrp x0, str_UIAppDelegate@PAGE&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;add x0, x0, str_UIAppDelegate@PAGEOFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _objc_getProtocol&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x1, x0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x0, x20&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _class_addProtocol&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; class_addMethod(c, S("application:didFinishLaunchingWithOptions:"), didFinishLaunching, "B@:@@");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;adrp x0, str_didFinishLaunchingSel@PAGE&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;add x0, x0, str_didFinishLaunchingSel@PAGEOFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _sel_getUid&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x1, x0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x0, x20&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;adr x2, didFinishLaunching&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;adrp x3, str_typestr@PAGE&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;add x3, x3, str_typestr@PAGEOFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _class_addMethod&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; objc_registerClassPair(c);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x0, x20&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _objc_registerClassPair&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; epilog&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ldr x20, [sp, #0x10]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ldp x29, x30, [sp], #0x20&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ret&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; parameters:&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; x0: self&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; x1: _sel&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; x2: application&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; x3: launchOptions&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;didFinishLaunching:&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; prolog, save fp, lr, x19-x22&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;stp x29, x30, [sp, #-0x30]!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;stp x19, x20, [sp, #0x10]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;stp x21, x22, [sp, #0x20]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x29, sp&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;sub sp, sp, 0x20&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; x19 = @selector(mainScreen)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;adrp x0, str_mainScreen@PAGE&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;add x0, x0, str_mainScreen@PAGEOFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _sel_getUid&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x19, x0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; objc_getClass("UIScreen")&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;adrp x0, str_UIScreen@PAGE&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;add x0, x0, str_UIScreen@PAGEOFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _objc_getClass&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; x20 = [UIScreen mainScreen]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x1, x19&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _objc_msgSend&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x20, x0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; x19 is now free&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; x1 = @selector(bounds)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;adrp x0, str_bounds@PAGE&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;add x0, x0, str_bounds@PAGEOFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _sel_getUid&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x1, x0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; [x20 bounds]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x0, x20&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _objc_msgSend&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;stp d0, d1, [sp]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;stp d2, d3, [sp, #0x10]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; x19 = @selector(initWithFrame:)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;adrp x0, str_initWithFrame@PAGE&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;add x0, x0, str_initWithFrame@PAGEOFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _sel_getUid&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x19, x0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; x0 = UIWindow&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;adrp x0, str_UIWindow@PAGE&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;add x0, x0, str_UIWindow@PAGEOFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _objc_getClass&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; x0 = class_createInstance(x0)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x1, #0x0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _class_createInstance&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; x0 now has the instance&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; x20 = [x0 initWithFrame:d]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x1, x19 ;initWithFrame&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ldp d0, d1, [sp]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ldp d2, d3, [sp, #0x10]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _objc_msgSend&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x20, x0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; x19 = @selector(init)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;adrp x0, str_init@PAGE&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;add x0, x0, str_init@PAGEOFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _sel_getUid&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x19, x0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; x0 = UIViewController&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;adrp x0, str_UIViewController@PAGE&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;add x0, x0, str_UIViewController@PAGEOFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _objc_getClass&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; x0 = class_createInstance(UIViewController)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x1, #0x0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _class_createInstance&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; x0 now has the instance&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; x21 = [x0 init]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x1, x19 ;init&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _objc_msgSend&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x21, x0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; x19 = @selector(yellowColor)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;adrp x0, str_yellowColor@PAGE&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;add x0, x0, str_yellowColor@PAGEOFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _sel_getUid&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x19, x0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; x22 = [UIColor yellowColor]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;adrp x0, str_UIColor@PAGE&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;add x0, x0, str_UIColor@PAGEOFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _objc_getClass&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x1, x19&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _objc_msgSend&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x22, x0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; x19 = @selector(setBackgroundColor:)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;adrp x0, str_setBackgroundColor@PAGE&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;add x0, x0, str_setBackgroundColor@PAGEOFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _sel_getUid&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x19, x0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; x1 = @selector(view)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;adrp x0, str_view@PAGE&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;add x0, x0, str_view@PAGEOFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _sel_getUid&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x1, x0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; x0 = [[controller view] setBackgroundColor: x22];&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x0, x21&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _objc_msgSend&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x1, x19&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x2, x22&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _objc_msgSend&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;adrp x0, str_setRoot@PAGE&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;add x0, x0, str_setRoot@PAGEOFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _sel_getUid&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x1, x0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; [window setRootViewController:viewController]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x0, x20&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x2, x21&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _objc_msgSend&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; [x20 makeKeyAndVisible]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;adrp x0, str_makeKeyAndVisible@PAGE&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;add x0, x0, str_makeKeyAndVisible@PAGEOFF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _sel_getUid&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x1, x0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x0, x20&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;bl _objc_msgSend&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; return YES&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mov x0, #0x1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;; epilog&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;add sp, sp, 0x20&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ldp x19, x20, [sp, #0x10]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ldp x21, x22, [sp, #0x20]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ldp x29, x30, [sp], #0x30&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ret&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;.data&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;str_NSObject: .asciz "NSObject"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;str_AppDelegate: .asciz "AppDelegate"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;str_UIAppDelegate: .asciz "UIApplicationDelegate"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;str_UIScreen: .asciz "UIScreen"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;str_UIWindow: .asciz "UIWindow"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;str_UIViewController: .asciz "UIViewController"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;str_UIColor: .asciz "UIColor"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;str_typestr: .asciz "B@:@@"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;str_didFinishLaunchingSel: .asciz "application:didFinishLaunchingWithOptions:"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;str_mainScreen: .asciz "mainScreen"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;str_bounds: .asciz "bounds"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;str_initWithFrame: .asciz "initWithFrame:"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;str_makeKeyAndVisible: .asciz "makeKeyAndVisible"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;str_init: .asciz "init"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;str_view: .asciz "view"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;str_setBackgroundColor: .asciz "setBackgroundColor:"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;str_yellowColor: .asciz "yellowColor"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;str_setRoot: .asciz "setRootViewController:"&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt; Sign up for free to join this conversation on GitHub. Already have an account? Sign in to comment &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45755821</guid><pubDate>Thu, 30 Oct 2025 02:37:35 +0000</pubDate></item></channel></rss>