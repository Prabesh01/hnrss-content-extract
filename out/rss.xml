<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 15 Oct 2025 02:21:12 +0000</lastBuildDate><item><title>Show HN: Metorial (YC F25) ‚Äì Vercel for MCP</title><link>https://github.com/metorial/metorial</link><description>&lt;doc fingerprint="9fc57e133df5380d"&gt;
  &lt;main&gt;
    &lt;p&gt; The integration platform for agentic AI. &lt;lb/&gt; Connect any AI model to thousands of APIs, data sources, and tools with a single function call. &lt;/p&gt;
    &lt;p&gt;Tip&lt;/p&gt;
    &lt;p&gt;Skip the setup and go hosted: The fasted, simplest and most reliable way to use Metorial is to sign up to our hosted platform.&lt;/p&gt;
    &lt;p&gt;Metorial enables AI agent developers to easily connect their models to a wide range of APIs, data sources, and tools using the Model Context Protocol (MCP). Metorial abstracts away the complexities of MCP and offers a simple, unified interface for developers, including powerful SDKs, detailed monitoring, and a highly customizable platform.&lt;/p&gt;
    &lt;p&gt;Metorial currently provides SDKs for the following languages:&lt;/p&gt;
    &lt;p&gt;If you want to build a custom integration, check out our API documentation for details on how to use the Metorial API directly.&lt;/p&gt;
    &lt;p&gt;MCP is a powerful standard for connecting AI models to external data and tools, but it focuses on enabling AI clients (like Claude Desktop or Cursor) to connect to tools and data sources. Metorial builds on MCP but makes it a one-liner for developers to connect their AI apps to any API, data source, or tool. Thereby we enable developers to create agentic AI applications that can interact with other systems in a reliable, simple, and secure way.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Model Context Protocol (MCP) - Metorial is powered by the Model Context Protocol, a standard for connecting AI models to external data and tools.&lt;/item&gt;
      &lt;item&gt;Docker - Metorial uses Docker to run MCP servers in a containerized environment, making it easy to deploy and manage.&lt;/item&gt;
      &lt;item&gt;MCP Containers - Metorial provides a collection of pre-built MCP servers in Docker containers.&lt;/item&gt;
      &lt;item&gt;Typescript - Most of Metorial is written in TypeScript.&lt;/item&gt;
      &lt;item&gt;Bun - The core of Metorial runs on Bun, a fast JavaScript runtime that is compatible with Node.js.&lt;/item&gt;
      &lt;item&gt;Go - The MCP engine is written in Go, providing a high-performance backend for Metorial.&lt;/item&gt;
      &lt;item&gt;PostgreSQL - Metorial uses PostgreSQL for data storage.&lt;/item&gt;
      &lt;item&gt;Redis - Metorial uses Redis for caching and real-time data processing.&lt;/item&gt;
      &lt;item&gt;MongoDB - Metorial uses MongoDB for storing usage data and logs.&lt;/item&gt;
      &lt;item&gt;React - The Metorial Dashboard is built with React.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Metorial is built to make it super easy for developers to connect their AI apps to external data and tools. Powered by the Model Context Protocol (MCP), Metorial is built on standards.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚ú® One-liner SDKs: Connect your AI model to any API, data source, or tool with a single function call.&lt;/item&gt;
      &lt;item&gt;üõ†Ô∏è Powered by MCP: Metorial is built on the Model Context Protocol, a standard for connecting AI models to external data and tools.&lt;/item&gt;
      &lt;item&gt;üöÄ Get started in minutes: Metorial is designed to be easy to use, with a simple setup process and a unified interface for all your AI integrations.&lt;/item&gt;
      &lt;item&gt;üïäÔ∏è Self-hosting: Metorial's source code is hosted on GitHub and you can self-host it.&lt;/item&gt;
      &lt;item&gt;üë©üíª Built for developers: Metorial isn't built for end users, but for developers who need high quality tooling, monitoring, and customization options to build agentic AI applications.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Metorial server index already contains more than 5000 MCP servers. It's a super easy to find and use MCP servers for your AI applications. Everything is searchable and neatly organized, so you can find the right server for your use case.&lt;/p&gt;
    &lt;head class="px-3 py-2"&gt;mt1.mp4&lt;/head&gt;
    &lt;p&gt;Test and explore MCP servers directly in the Metorial Dashboard. The embedded MCP Explorer allows you to use any MCP server without leaving the dashboard. This makes it easy to test and debug your integrations before writing any code.&lt;/p&gt;
    &lt;head class="px-3 py-2"&gt;mt2.mp4&lt;/head&gt;
    &lt;p&gt;Every MCP session is recorded and can be reviewed in the Metorial Dashboard. This allows you to monitor and find issues in your integrations. And even better, if an error occurs, Metorial detects it and provides a detailed error report so you can quickly fix the issue.&lt;/p&gt;
    &lt;head class="px-3 py-2"&gt;mt3.mp4&lt;/head&gt;
    &lt;p&gt;Metorial is built from the ground up for developers. Here are some of the key features that make Metorial a great choice for developers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Customizable: Metorial is highly customizable, allowing you to configure your integrations to fit your needs.&lt;/item&gt;
      &lt;item&gt;Open source: Metorial is open source, so you can run it on your own infrastructure or use our hosted platform.&lt;/item&gt;
      &lt;item&gt;Multi-instance support: Create multiple instances of your Metorial Projects to test different configurations, environments or versions of your integrations.&lt;/item&gt;
      &lt;item&gt;Powerful SDKs: Metorial provides powerful SDKs for JavaScript/TypeScript and Python, making it easy to integrate with your AI applications.&lt;/item&gt;
      &lt;item&gt;Detailed documentation: Metorial provides detailed documentation for all its features, including examples and tutorials to help you get started quickly.&lt;/item&gt;
      &lt;item&gt;Full API access: Every feature of Metorial is accessible via the API, allowing you to build custom integrations and automate your workflows. Theoretically, you could build your own dashboard using the API.&lt;/item&gt;
      &lt;item&gt;Advanced dashboard: The Metorial Dashboard provides a powerful interface for managing your integrations, monitoring your usage, and debugging your MCP servers.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Metorial is licensed under the FSL-1.1 license.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45580771</guid><pubDate>Tue, 14 Oct 2025 14:49:56 +0000</pubDate></item><item><title>How AI hears accents: An audible visualization of accent clusters</title><link>https://accent-explorer.boldvoice.com/</link><description>&lt;doc fingerprint="35bba6d935b3db90"&gt;
  &lt;main&gt;
    &lt;p&gt;Today, we‚Äôre going to go on a tour of the world's accents in English. Users of BoldVoice, the American accent training app, speak more than 200 different languages, and it is our mission to help them speak English clearly and confidently. While building the accent strength metric we covered in the previous blog post, we needed to understand how our models clustered accents, dialects, native languages, and language families. Today, we will share some of our findings using a 3D latent visualization.&lt;/p&gt;
    &lt;p&gt;To begin, we finetuned HuBERT, a pretrained audio-only foundation model for the task of accent identification using our in-house dataset of non-native English speech and self-reported accents. BoldVoice‚Äôs own dataset of accented speech is one of the largest of its kind in the world.&lt;/p&gt;
    &lt;p&gt;This model receives only the raw input audio and associated accent label; it gets neither a text prompt nor a transcript. For this "finetuning", we sampled 30 million speech recordings comprising 25,000 hours of English speech - a small fraction of our total accent dataset. Unlike a traditional finetune, we unfroze all layers of the pretrained base model due to the large size of our dataset. We trained the model for roughly a week on a cluster of A100 GPUs.&lt;/p&gt;
    &lt;p&gt;While the accent identifier performs quite well across the top hundred or so accents (play with it yourself at accentoracle.com), for today, we are less interested in its raw performance, and more interested in the clustering of accents in its latent space.&lt;/p&gt;
    &lt;p&gt;To observe how accents cluster, we've provided an audible latent space visualization for a small subset of recordings. Hover on the points on the graph to see the language labels.&lt;/p&gt;
    &lt;p&gt;The visualization is created by applying the UMAP dimensionality reduction technique to reduce the 768-dimensional latent space to just 3 dimensions.&lt;/p&gt;
    &lt;p&gt;Note that UMAP destroys much of the information in the full-dimensional latent space, but roughly preserves the global structure, including the relative distances between clusters. Each point represents a single recording inferenced by the model after it was fine tuned and the color corresponds to the true accent label.&lt;/p&gt;
    &lt;p&gt;Finally, in order to denoise the clusters, we cherry-pick only those points for which the predicted and target accents match. Remember, the purpose of this visualization is not to help us assess the performance of the model, but to understand where it has placed accents relative to one another.&lt;/p&gt;
    &lt;p&gt;By clicking or tapping on a point, you will hear a standardized version of the corresponding recording. The reason for voice standardization is two-fold: first, it anonymizes the speaker in the original recordings in order to protect their privacy. Second, it allows us to hear each accent projected onto a neutral voice, making it easier to hear the accent differences and ignore extraneous differences like gender, recording quality, and background noise. However, there is no free lunch: it does not perfectly preserve the source accent and introduces some audible phonetic artifacts.&lt;/p&gt;
    &lt;p&gt;This voice standardization model is an in-house accent-preserving voice conversion model.&lt;/p&gt;
    &lt;p&gt;Please explore the latent space visualization. You can click, drag, zoom, and scroll to navigate. You can also isolate accents by double clicking them in the legend to the right (desktop only) ‚Äì double-clicking again will undo the filter.&lt;/p&gt;
    &lt;p&gt;Meanwhile, think about the following questions: which accents would you expect to be clustered together? Do you expect them to follow the taxonomy of language families or to cluster in other ways?&lt;/p&gt;
    &lt;p&gt;Our team was most surprised to see that geographic proximity, immigration, and colonialism seem to affect this model's learned accent groupings more than language taxonomy. Click the button below to explore our first grouping.&lt;/p&gt;
    &lt;p&gt;For example, the Australian cluster is right next to the Vietnamese cluster despite the fact that English and Vietnamese are not related taxonomically. If you listen to the 10 points that make up a bridge between the two clusters, you hear what sounds like native Vietnamese speakers who speak English with an Australian accent. Perhaps these hybrid accents could explain the overall proximity of these clusters.&lt;/p&gt;
    &lt;p&gt;We see something similar for the French/Nigerian/Ghanaian grouping.&lt;/p&gt;
    &lt;p&gt;It's important to remember that the distances on this map are not an objective measure of the phonetic similarity between accents. They are a byproduct of a model which has successfully learned to distinguish a variety of accents in L2 English speech from audio alone with no knowledge of language or linguistics.&lt;/p&gt;
    &lt;p&gt;Next, take a look at the Indian subcontinent accent cluster. Note that the Telugu, Tamil, and Malayalam accents are grouped together at one end of the cluster, and the Nepali and Bengali accents are at the other. This roughly mirrors geography, where Telugu, Tamil, and Malayalam are widely spoken languages in southern India, and Bengali and Nepali are widely spoken in northwest India and Nepal.&lt;/p&gt;
    &lt;p&gt;Finally, let's scroll to the Mongolian cluster, where the nearest cluster is actually Korean.&lt;/p&gt;
    &lt;p&gt;Experts and non-experts have observed phonetic similarities between Mongolian and Korean. A now-refuted hypothesis called the "Altaic language family" once grouped them together.&lt;/p&gt;
    &lt;p&gt;It is interesting that this model, with no concept of language families, has also picked up on the phonetic similarities even as filtered through a second language (English).&lt;/p&gt;
    &lt;p&gt;What do you think? Is this a meaningless artifact of latent space visualization or evidence of real phonetic features diffusing between Korean and Mongolian?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45581735</guid><pubDate>Tue, 14 Oct 2025 16:07:37 +0000</pubDate></item><item><title>Prefix sum: 20 GB/s (2.6x baseline)</title><link>https://github.com/ashtonsix/perf-portfolio/tree/main/delta</link><description>&lt;doc fingerprint="3b74d0de090e4684"&gt;
  &lt;main&gt;
    &lt;p&gt;We read every piece of feedback, and take your input very seriously.&lt;/p&gt;
    &lt;p&gt;To see all available qualifiers, see our documentation.&lt;/p&gt;
    &lt;p&gt;There was an error while loading. Please reload this page.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45582268</guid><pubDate>Tue, 14 Oct 2025 16:53:24 +0000</pubDate></item><item><title>How bad can a $2.97 ADC be?</title><link>https://excamera.substack.com/p/how-bad-can-a-297-adc-be</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45582462</guid><pubDate>Tue, 14 Oct 2025 17:12:10 +0000</pubDate></item><item><title>SmolBSD ‚Äì build your own minimal BSD system</title><link>https://smolbsd.org</link><description>&lt;doc fingerprint="19dcff71d549ada5"&gt;
  &lt;main&gt;
    &lt;p&gt;build your own minimal BSD UNIX system&lt;/p&gt;
    &lt;p&gt;smolBSD is a meta-operating system built on top of NetBSD. It lets you compose your own UNIX environment √¢ from a single-purpose microservice system to a fully-custom OS image √¢ in just a few minutes.&lt;/p&gt;
    &lt;p&gt;The smolBSD environment uses the netbsd-MICROVM kernel as its foundation, leveraging the same portable, reliable codebase that powers NetBSD itself. You decide what to include √¢ sshd, httpd, or your own service √¢ and smolBSD builds a coherent, minimal, bootable image ready to run anywhere.&lt;/p&gt;
    &lt;quote&gt;$ bmake SERVICE=bozohttpd build √¢¬°√Ø¬∏ starting the builder microvm √¢¬°√Ø¬∏ host filesystem mounted on /mnt √¢¬°√Ø¬∏ fetching sets √¢¬°√Ø¬∏ creating root filesystem (512M) done √¢ image ready: bozohttpd-amd64.img&lt;/quote&gt;
    &lt;p&gt;Build BSD systems like you build software √¢ fast, reproducible, and minimal.&lt;/p&gt;
    &lt;p&gt;Pick only the components you need √¢ from kernel to services.&lt;/p&gt;
    &lt;p&gt;Every build is deterministic, portable, and easy to version-control.&lt;/p&gt;
    &lt;p&gt;Powered by netbsd-MICROVM √¢ boot to service in milliseconds.&lt;/p&gt;
    &lt;p&gt;Runs anywhere QEMU or Firecracker runs √¢ cloud, CI, edge, or laptop.&lt;/p&gt;
    &lt;p&gt;Build and boot your own BSD system in seconds:&lt;/p&gt;
    &lt;quote&gt;$ git clone https://github.com/NetBSDfr/smolBSD $ cd smolBSD $ bmake SERVICE=sshd build √¢¬°√Ø¬∏ starting the builder microvm √¢¬°√Ø¬∏ fetching sets √¢¬°√Ø¬∏ creating root filesystem (512M) done √¢ image ready: sshd-amd64.img √¢¬°√Ø¬∏ killing the builder microvm $ ./startnb.sh -f etc/sshd.conf [ 1.0092096] kernel boot time: 14ms Starting sshd. Server listening on :: port 22. Server listening on 0.0.0.0 port 22.Download&lt;/quote&gt;
    &lt;p&gt; A complete static web server in a few megabytes. smolBSD builds a minimal system with &lt;code&gt;bozohttpd&lt;/code&gt;
preconfigured and ready to serve content immediately on boot.
        &lt;/p&gt;
    &lt;quote&gt;$ bmake SERVICE=bozohttpd build √¢¬°√Ø¬∏ starting the builder microvm √¢¬°√Ø¬∏ fetching sets √¢¬°√Ø¬∏ creating root filesystem (512M) done √¢ image ready: bozohttpd-amd64.img $ ./startnb.sh -f etc/bozohttpd.conf [ 1.001231] kernel boot time: 10ms Starting bozohttpd on :80 listening on 0.0.0.0:80&lt;/quote&gt;
    &lt;p&gt; A lightweight build and image creation service based entirely on NetBSD tools. The &lt;code&gt;nbakery&lt;/code&gt; image gives you a taste of a preconfigured NetBSD environment with all the well known tools.
        &lt;/p&gt;
    &lt;quote&gt;$ bmake SERVICE=nbakery build √¢¬°√Ø¬∏ starting the builder microvm √¢¬°√Ø¬∏ fetching sets √¢¬°√Ø¬∏ creating root filesystem (512M) done √¢ image ready: nbakery-amd64.img $ ./startnb.sh -f etc/nbakery.conf [ 1.008374] kernel boot time: 11ms Welcome to the (n)bakery! √∞¬ß √∞¬™ doas&lt;command&gt;to run command as root √∞¬¶ pkgin to manage packages √∞¬™ exit to cleanly shutdown, ^a-x to exit qemu √∞¬™ you are inside a tmux with prefix ^q&lt;/command&gt;&lt;/quote&gt;
    &lt;p&gt; A minimal secure shell server started with &lt;code&gt;nitro&lt;/code&gt;,
designed to launch instantly and provide remote access with zero unnecessary
services.  
          Ideal for an SSH bouncer.
        &lt;/p&gt;
    &lt;quote&gt;$ bmake SERVICE=nitrosshd build √¢¬°√Ø¬∏ starting the builder microvm √¢¬°√Ø¬∏ fetching sets √¢¬°√Ø¬∏ creating root filesystem (512M) done √¢ image ready: nitrosshd-amd64.img $ ./startnb.sh -f etc/sshd.conf [ 1.011598] kernel boot time: 12ms Created tmpfs /dev (1835008 byte, 3552 inodes) Starting sshd. Server listening on :: port 22. Server listening on 0.0.0.0 port 22.&lt;/quote&gt;
    &lt;p&gt;smolBSD is an independent project built on top of NetBSD. Join us, share your micro-systems, or contribute new services and build recipes.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45582758</guid><pubDate>Tue, 14 Oct 2025 17:43:33 +0000</pubDate></item><item><title>Beliefs that are true for regular software but false when applied to AI</title><link>https://boydkane.com/essays/boss</link><description>&lt;doc fingerprint="bc3c1b1a6d77819d"&gt;
  &lt;main&gt;
    &lt;p&gt;(a note for technical folk)1 | read as pdf&lt;/p&gt;
    &lt;p&gt;When it comes to understanding the dangers of AI systems, the general public has the worst kind of knowledge: that what you know for sure that just ain√¢t so.&lt;/p&gt;
    &lt;p&gt;After 40 years of persistent badgering, the software industry has convinced the public that bugs can have disastrous consequences. This is great! It is good that people understand that software can result in real-world harm. Not only does the general public mostly understand the dangers, but they mostly understand that bugs can be fixed. It might be expensive, it might be difficult, but it can be done.&lt;/p&gt;
    &lt;p&gt;The problem is that this understanding, when applied to AIs like ChatGPT, is completely wrong. The software that runs AI acts very differently to the software that runs most of your computer or your phone. Good, sensible assumptions about bugs in regular software actually end up being harmful and misleading when you try to apply them to AI.&lt;/p&gt;
    &lt;p&gt;Attempting to apply regular-software assumptions to AI systems leads to confusion, and remarks such as:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;√¢If something goes wrong with ChatGPT, can√¢t some boffin just think hard for a bit, find the missing semi-colon or whatever, and then fix the bug?√¢&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;or&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;√¢Even if it√¢s hard for one person to understand everything the AI does, surely still smart people who individually understand small parts of what the AI does?√¢.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;or&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;√¢Just because current systems don√¢t work perfectly, that√¢s not a problem right? Because eventually we√¢ll iron out all the bugs so the AIs will get more reliable over time, like old software is more reliable than new software.√¢&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;If you understand how modern AI systems work, these statements are all painfully incorrect. But if you√¢re used to regular software, they√¢re completely reasonable. I believe there is a gap between the experts and the novices in the field:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;the experts don√¢t see the gap because it√¢s so obvious, so they don√¢t bother explaining the gap&lt;/item&gt;
      &lt;item&gt;the novices don√¢t see the gap because they don√¢t know to look, so they don√¢t realise where their confusion comes from.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This leads to frustration on both sides, because the experts feel like their arguments aren√¢t hitting home, and the novices feel like all arguments have obvious flaws. In reality, the experts and the novices have different, unspoken, assumptions about how AI systems work.&lt;/p&gt;
    &lt;head rend="h1"&gt;Some example false beliefs&lt;/head&gt;
    &lt;p&gt;To make this more concrete, here are some example ideas that are perfectly true when applied to regular software but become harmfully false when applied to modern AIs:&lt;/p&gt;
    &lt;head rend="h2"&gt;Software vulnerabilities are caused by mistakes in the code&lt;/head&gt;
    &lt;p&gt;In regular software, vulnerabilities are caused by mistakes in the lines of code that make up the software. There might be hundreds of thousands of lines of code, but code doesn√¢t take up much space so this is only around 50MB of data, about the size of a small album of photos.&lt;/p&gt;
    &lt;p&gt;But in modern AI systems, vulnerabilities or bugs are usually caused by problems in the data used to train an AI2. It takes thousands of gigabytes of data to train modern AI systems, and bad behaviour isn√¢t caused by any single bad piece of data, but by the combined effects of significant fractions of the dataset. Because these datasets are so large, nobody knows everything that an AI is actually trained on. One popular dataset, FineWeb, is about 11.25 trillion words long3, which, if you were reading at about 250 words per minute, would take you over 85 thousand years to read. It√¢s just not possible for any single human (or even a team of humans) to have read everything that an LLM has read during training.&lt;/p&gt;
    &lt;head rend="h2"&gt;Bugs in the code can be found by carefully analysing the code&lt;/head&gt;
    &lt;p&gt;With regular software, if there√¢s a bug, it√¢s possible for smart people to carefully read through the code and logically figure out what must be causing the bug.&lt;/p&gt;
    &lt;p&gt;With AI systems, almost all bad behaviour originates from the data that√¢s used to train them2, but it√¢s basically impossible to look at misbehaving AI and figure out parts of the training data caused that bad behaviour. In practice, it√¢s rare to even attempt this, researchers will retrain the AI with more data to try and counteract the bad behaviour, or they√¢ll start over and try to curate the data to not include the bad data.&lt;/p&gt;
    &lt;p&gt;You cannot logically deduce what pieces of data caused the bad behaviour, you can only make good guesses. For example, modern AIs are trained on lots of mathematics proofs and programming tasks, because that seems to make them do better at reasoning and logical thinking tasks. If an AI system makes a logical reasoning mistake, it√¢s impossible to attribute that mistake to any portion of the training data, the only answer we√¢ve got is to use more data next time.&lt;/p&gt;
    &lt;p&gt;I think I need to emphasise this: With regular software, we can pinpoint mistakes precisely, walk step-by-step through the events leading up to the mistake, and logically understand why that mistake happened. When AIs make mistakes, we don√¢t understand the steps that caused those mistakes. Even the people who made the AIs don√¢t understand why they make mistakes4. Nobody understands where these bugs come from. We sometimes kinda have a rough idea about why they maybe did something unusual. But we√¢re far, far away from anything that guarantees the AI won√¢t have any catastrophic failures.&lt;/p&gt;
    &lt;head rend="h2"&gt;Once a bug is fixed, it won√¢t come back again&lt;/head&gt;
    &lt;p&gt;With regular software, once you√¢ve found the bug, you can fix the bug. And once you√¢ve fixed the bug, it won√¢t re-appear5. There might be a bug that causes similar problems, but it√¢s not the same bug as the one you fixed. This means you can, if you√¢re patient, reduce the number of bugs over time and rest assured that removing new bugs won√¢t cause old bugs to re-appear.&lt;/p&gt;
    &lt;p&gt;This is not the case with AI. It√¢s not really possible to √¢fix√¢ a bug in an AI, because even if the AI was behaving weirdly, and you retrained it, and now it√¢s not behaving weirdly anymore, you can√¢t know for sure that the weird behaviour is gone, just that it doesn√¢t happen for the prompts you tested. It√¢s entirely possible that someone can find a prompt you forgot to test, and then the buggy behaviour is back again!&lt;/p&gt;
    &lt;head rend="h2"&gt;Every time you run the code, the same thing happens&lt;/head&gt;
    &lt;p&gt;With regular software, you can run the same piece of code multiple times and it√¢ll behave in the same way. If you give it the same input, it√¢ll give you the same output.&lt;/p&gt;
    &lt;p&gt;Now technically this is still true for AIs, if you give them exactly the prompt they√¢ll respond in exactly the same way. But practically, it√¢s very far from the truth6. Even tiny changes to the input of an AI can have dramatic changes in the output. Even innocent changes like adding a question mark at the end of your sentence or forgetting to start your sentence with a capital letter can cause the AI to return something different.&lt;/p&gt;
    &lt;p&gt;Additionally, most AI companies will slightly change the way their AIs respond, so that they say slightly different things to the same prompt. This helps their AIs seem less robotic and more natural.&lt;/p&gt;
    &lt;head rend="h2"&gt;If you give specifications beforehand, you can get software that meets those specifications&lt;/head&gt;
    &lt;p&gt;With regular software, this is true. You can sit with stakeholders to discuss the requirements for some piece of software, and then write code to meet those requirements. The requirements might change, but fundamentally you can write code to serve some specific purpose and have confidence that it will serve that specific purpose.&lt;/p&gt;
    &lt;p&gt;With AI systems, this is more or less false. Or at the very least, the creators of modern AI systems have far far less control about the behaviour the AIs will exhibit. We understand how to get an AI to meet narrow, testable specifications like speaking English and writing code, but we don√¢t know how to get a brand new AI to achieve a certain score on some particular test or to guarantee global behaviour like √¢never tells the user to commit a crime√¢. The best AI companies in the world have basically one lever which is √¢better√¢, and they can pull that lever to make the AI better, but nobody knows precisely what to do to ensure an AI writes formal emails correctly or summarises text accurately.&lt;/p&gt;
    &lt;p&gt;This means that we don√¢t know what an AI will be capable of before we√¢ve trained it. It√¢s very common for AIs to be released to the public for months before a random person on Twitter discovers some ability that the AI has which even its creators didn√¢t know about. So far, these abilities have been mostly just fun, like being good at Geoguessr:&lt;/p&gt;
    &lt;p&gt;Or making photos look like they were from a Studio Ghibli film:&lt;/p&gt;
    &lt;p&gt;But there√¢s no reason for these hidden abilities to always be positive. It√¢s entirely possible that some dangerous capability is hidden in ChatGPT, but nobody√¢s figured out the right prompt just yet.&lt;/p&gt;
    &lt;p&gt;While it√¢s possible to demonstrate the safety of an AI for a specific test suite or a known threat, it√¢s impossible for AI creators to definitively say their AI will never act maliciously or dangerously for any prompt it could be given.&lt;/p&gt;
    &lt;head rend="h1"&gt;Where to go from here&lt;/head&gt;
    &lt;p&gt;It is good that most people know the dangers of poorly written or buggy software. But this hard-won knowledge about regular software is misleading the public when it gets applied to AI. Despite the cries of √¢inscrutable arrays of floating point numbers√¢, I√¢d be surprised if a majority of people know that modern AI is architecturally different from regular software.&lt;/p&gt;
    &lt;p&gt;AI safety is a complicated and subtle argument. The best we can do is to make sure we√¢re starting from the same baseline, and that means conveying to our contemporaries that if it all starts to go wrong, we cannot just √¢patch the bug√¢7.&lt;/p&gt;
    &lt;p&gt;If this essay was the first time you realised AI was fundamentally different from regular software, let me know, and share this with a friend who might also not realise the difference.&lt;/p&gt;
    &lt;p&gt;If you always knew that regular software and AIs are fundamentally different, talk to your family and non-technical friends, or with a stranger at a coffee shop. I think you√¢ll be surprised at how few people know that these two are different.&lt;/p&gt;
    &lt;p&gt;If you√¢re interested the dynamics between experts and novices, and how gaps between them arise, I√¢ve written more about the systemic biases encountered by experts (and the difficulties endured by novices) in this essay: Experts have it easy.&lt;/p&gt;
    &lt;p&gt;Thanks to Sam Cross and Caleb for reviewing drafts of this essay.&lt;/p&gt;
    &lt;head rend="h2"&gt;Footnotes&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;This article is attempting to bridge a gap between the technical and the non-technical, so I√¢m going to be quite lax with the jargon here and there. By √¢AI√¢ I√¢m referring to 2025 frontier LLMs. I√¢m also going to be making some sweeping statements about √¢how software works√¢, these claims mostly hold, but they break down when applied to distributed systems, parallel code, or complex interactions between software systems and human processes. Feel free to debate me in the comments if you think this piece discussing how experts struggle to emphasise with novices should have had more jargon (: √¢¬©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;It can also come from the reward model used during RLHF, but the reward model is still trained from data at the end of the day. It can also come from prompt injections, but those also only work because of the data. √¢¬© √¢¬©2&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;FineWeb is 15 trillion tokens, each token is about 0.75 words, 11.25 trillion words. √¢¬©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Anthropic is doing very good work to try and figure out why AIs think the way they do, but even the state of the art does not have a full understanding of these AIs, and what understanding we do have, is often partial and with significant gaps. √¢¬©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;You are writing tests to prevent regressions, right? right?! √¢¬©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;see for example, this blog post from Mira Murati√¢s Thinking Machines Lab √¢¬©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Personally, I think some more empathy is needed when having good faith discussions with non-technical folk. Communication is empirically hard, in that it often goes wrong in practice, even if it feels easy to do. √¢¬©&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45583180</guid><pubDate>Tue, 14 Oct 2025 18:26:00 +0000</pubDate></item><item><title>What Americans die from vs. what the news reports on</title><link>https://ourworldindata.org/does-the-news-reflect-what-we-die-from</link><description>&lt;doc fingerprint="7655812702e0870d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Does the news reflect what we die from?&lt;/head&gt;
    &lt;head rend="h2"&gt;What do Americans die from, and what do the New York Times, Washington Post, and Fox News report on?&lt;/head&gt;
    &lt;head rend="h4"&gt;Acknowledgments&lt;/head&gt;
    &lt;p&gt;For this work, we relied on Media Cloud, an open-access platform for media analysis. We would like to thank their team, particularly Emily Boardman Ndulue and Fernando Bermejo, for making this invaluable resource available and for their help with this project.&lt;/p&gt;
    &lt;p&gt;More than 80% of people ‚Äî including surveyed Americans, Brits, Germans, and Italians ‚Äî say they follow the news because they ‚Äúwant to know what is going on in the world around them.‚Äù1 It‚Äôs not just that people expect the news to inform them about what‚Äôs going on in the world. Most think that it does. When asked what emotions the news generates, ‚Äúinformed‚Äù was the most common response.2&lt;/p&gt;
    &lt;p&gt;This is what media outlets themselves promise to do. Here are several quotes from the New York Times‚Äôs mission statement:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúWe seek the truth and help people understand the world. [...]&lt;/p&gt;
      &lt;p&gt;We help a global audience understand a vast and diverse world.‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;However, as we‚Äôll see in this article, the media focuses on a particular sliver of our world, leaving much of the ‚Äúvast and diverse world‚Äù largely out of their reporting. We‚Äôll investigate this through the lens of health, looking at causes of death and reporting in the United States.&lt;/p&gt;
    &lt;p&gt;As we‚Äôll discuss, our point is not that we should want or expect the media‚Äôs coverage to perfectly match the real distribution of deaths, although we‚Äôd argue that it would be better if it were less skewed. We wrote this article so that you, the reader, are aware of a significant disconnect between what we often hear and what actually happens.&lt;/p&gt;
    &lt;p&gt;It‚Äôs easy to conflate what we see in the news with the reality of our world, and keeping this mismatch in mind can help you avoid falling into this trap.&lt;/p&gt;
    &lt;head rend="h1"&gt;Counting deaths and mentions in popular media&lt;/head&gt;
    &lt;p&gt;We focused on causes of death and media coverage in the United States in 2023.&lt;/p&gt;
    &lt;p&gt;The full list of all causes of death is very long, and since many causes are very rare, we didn‚Äôt investigate all of them. But our analysis accounts for 76% of all deaths in the US in 2023.3 It includes the 12 leading causes of death in the US, plus homicide, drug overdoses, and terrorism, since they receive a lot of attention in the media.&lt;/p&gt;
    &lt;p&gt;We used data from the US Centers for Disease Control and Prevention (CDC) to calculate each cause‚Äôs share of the total.4 We then compared this to the relative share of articles that mentioned these causes of death in three media outlets: the New York Times, the Washington Post, and the news website of Fox News. We selected these three because they are among the biggest national news organizations, are extremely popular, and are seen as being on different parts of the political spectrum.&lt;/p&gt;
    &lt;p&gt;To count the number of mentions, we relied on Media Cloud, an open-source platform regularly used for media analysis. In an extended methodology document, we provide many more details on how we constructed the data. Two things are important to mention here.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;For each cause of death, we included synonyms in our search. So, when searching for mentions of ‚Äúhomicide‚Äù, we also included mentions of related terms such as ‚Äúmurder‚Äù, ‚Äúkiller‚Äù, and other terms. For ‚Äúheart disease‚Äù, we included terms like ‚Äúheart attack‚Äù, ‚Äúcardiac arrest‚Äù, ‚Äúheart failure‚Äù, and many others.&lt;/item&gt;
      &lt;item&gt;We only counted articles where a cause of death ‚Äî or its related terms ‚Äî was mentioned more than once. This ensures that our analysis is focused on reporting on causes of death rather than just articles that mention a cause of death in passing. Additionally, this approach reduces the number of false positives and noise in our results.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;What do Americans die from, and what do they read about in the news?&lt;/head&gt;
    &lt;p&gt;You can see the results of our analysis in the chart below.&lt;/p&gt;
    &lt;p&gt;There are two big takeaways from this analysis. The first one is that the actual distribution of deaths shown on the left is very different from the causes of death that the media talks about.&lt;/p&gt;
    &lt;p&gt;The second insight is how similar the distribution of coverage is between the three media outlets. While there are some differences (Fox News was a bit more likely to mention homicides, for example, while the NYT did the same for terrorism), these are much smaller than we might expect. While right- and left-wing media might differ in how they cover particular topics, what they choose to write or talk about is similar.&lt;/p&gt;
    &lt;p&gt;The insight in this comparison, then, is not about differences between partisan media. It‚Äôs about the difference between actual causes of death and what the news tells Americans about. Those differences ‚Äî as we can see in the chart ‚Äî are huge.&lt;/p&gt;
    &lt;p&gt;Heart disease and cancer accounted for 56% of deaths among these 15 causes, but together they received just 7% of the media coverage. Other chronic issues, such as strokes, respiratory problems, diabetes, and kidney and liver disease, were also very underrepresented in the news.&lt;/p&gt;
    &lt;p&gt;Rare ‚Äî but dramatic ‚Äî events such as homicides and terrorism received more than half of all media coverage, despite being much smaller causes of death in the US. Terrorism, in particular, is a very rare cause of death, with 16 deaths in 2023.5&lt;/p&gt;
    &lt;head rend="h1"&gt;How over- and underrepresented are different causes of death in the media?&lt;/head&gt;
    &lt;p&gt;Another way to visualize this data is to measure how over- or underrepresented each cause is.&lt;/p&gt;
    &lt;quote&gt;Heart disease and cancer accounted for 56% of deaths but received just 7% of the coverage&lt;/quote&gt;
    &lt;p&gt;To do this, we calculate the ratio between a cause‚Äôs share of deaths and its share of news articles. In the chart below, we‚Äôve done this for coverage in the New York Times (the results are similar for the other two outlets).&lt;/p&gt;
    &lt;p&gt;It highlights that homicides and terrorism are extremely overrepresented. Homicides received 43 times more coverage than their share of deaths; terrorism received over 18,000 times more.&lt;/p&gt;
    &lt;p&gt;At the other end, we see that conditions like heart disease, stroke, and liver disease are very underrepresented.&lt;/p&gt;
    &lt;head rend="h1"&gt;Why is the media so biased towards dramatic risks?&lt;/head&gt;
    &lt;p&gt;The fact that the media focuses on dramatic, emotive events ‚Äî and much less on ‚Äúeveryday‚Äù, more common mortality risks ‚Äî has been found in several studies.6 These studies have shown that this mismatch has existed for a long time, and that genuine changes in death rates between causes of death account for a tiny fraction of the changes in media coverage.7&lt;/p&gt;
    &lt;p&gt;Our analysis adds to the evidence, with updated data for 2023.&lt;/p&gt;
    &lt;p&gt;Why does this mismatch exist?&lt;/p&gt;
    &lt;quote&gt;Homicides received 43 times more coverage than their share of deaths; terrorism received over 18,000 times more&lt;/quote&gt;
    &lt;p&gt;One explanation is that the news, true to its name, tells us what‚Äôs new. The fact that nearly 2000 Americans die from heart disease every single day means it is not novel or new. The headline tomorrow would be the same as it was today, which was the same as yesterday. Rarer events like terrorist attacks, plane crashes, homicides, or disasters each have their unique headline.&lt;/p&gt;
    &lt;p&gt;People who die from common health risks quickly become mere numbers. On the other hand, those who die in rarer events have a face, a name, and a story that can be told. As humans, this makes us much more likely to click and read, making these stories ideal for the media to write about.&lt;/p&gt;
    &lt;p&gt;While we would like news organizations to focus much more on the larger problems that societies face ‚Äî that is what we try to do at Our World in Data ‚Äî it would be wrong to put all of the blame on them. They respond to what readers want, and many want emotive and engaging stories (even if their circumstances are terrible and upsetting).&lt;/p&gt;
    &lt;p&gt;Even outside the news, some of the most successful television series are intense, crime-filled dramas. Disaster movies pull in record numbers at the box office. One of the most popular podcast genres is ‚Äútrue crime,‚Äù where we spend hours listening to the gripping, scary tales of serial killers or con artists.&lt;/p&gt;
    &lt;p&gt;It's not surprising, then, that we‚Äôre much more likely to click on a news story about the latest murder or disaster than one about heart or kidney disease. And because media organizations need traffic and attention to survive, they and the public are stuck in a reinforcing feedback loop where rare events are always in the headlines and chronic problems get drowned out.&lt;/p&gt;
    &lt;p&gt;This is not just a problem with the modern media environment. The audience for this type of media has always been there. What‚Äôs changed is the reporting frequency: rather than getting one newspaper in the morning, we are bombarded with updates almost in real-time. We also now receive news from a much larger geographical area; it‚Äôs not just about what‚Äôs happened in our own town, but also about what‚Äôs happened on the other side of the country, or even the world.&lt;/p&gt;
    &lt;head rend="h1"&gt;Does this bias really matter?&lt;/head&gt;
    &lt;p&gt;Our point is not that we think the New York Times, Washington Post, or Fox News‚Äô coverage should exactly match the distribution of causes of death. A newspaper that constantly covers heart disease and kidney failure would be a boring one that soon goes out of business. Even though our mission at Our World in Data is to cover the world‚Äôs largest problems, our own writing and data publications also don‚Äôt precisely match the scale of those problems. We expect we will be closer to the real distribution than the mainstream media, but there will still be some mismatch.&lt;/p&gt;
    &lt;p&gt;The reason we‚Äôre doing this analysis is to make you or other readers more aware of this selection bias. The frequency of news coverage doesn‚Äôt reflect what‚Äôs happening across millions or billions of people, but it‚Äôs easy to fall into the trap of thinking it does.&lt;/p&gt;
    &lt;p&gt;Why, then, do we think that this bias matters? Does it actually affect people‚Äôs perceptions of problems?&lt;/p&gt;
    &lt;p&gt;In a large survey among US adults, people who consumed local crime news ‚Äúoften‚Äù were more than three times more likely to say they were ‚Äúextremely concerned‚Äù about crime affecting them or their family than those who rarely or never read local crime news.8&lt;/p&gt;
    &lt;quote&gt;The frequency of news coverage doesn‚Äôt reflect what‚Äôs happening across millions or billions of people, but it‚Äôs easy to fall into the trap of thinking it does&lt;/quote&gt;
    &lt;p&gt;Nearly six-in-ten Americans still see international terrorism as a critical threat to the United States, despite the domestic impact on the US being relatively low for two decades. People are often far more anxious about flying than driving, even though commercial airline crashes are incredibly rare.&lt;/p&gt;
    &lt;p&gt;The information we‚Äôre exposed to profoundly impacts how we perceive the world, even if our perspective is less skewed than the media's.&lt;/p&gt;
    &lt;p&gt;But there‚Äôs one final reason why this bias matters. It makes it hard for us to understand how causes of death are changing over time. If we‚Äôre constantly bombarded with stories of the latest murders and crimes, we might easily think that these are happening more and more. That is a widespread sentiment. In 23 of the 27 Gallup surveys conducted since 1993, most Americans said there was more crime than the year before. In reality, rates of crime ‚Äî including homicides and other violent crime ‚Äî have fallen a lot.&lt;/p&gt;
    &lt;p&gt;And if we don‚Äôt hear about what‚Äôs happening to heart disease rates, treatments, or the odds of surviving cancer, we might wrongly imagine that no progress has been made. Yet childhood cancer deaths have plummeted over the last 50 years. Even among adults, death rates from cancer have fallen dramatically since the 1990s. So too have death rates from heart disease.&lt;/p&gt;
    &lt;p&gt;This perception gap about the world matters, and the media is not doing a good job of trying to close it.&lt;/p&gt;
    &lt;head rend="h3"&gt;Methodology&lt;/head&gt;
    &lt;p&gt;If you‚Äôre interested in digging deeper, we provide a more detailed methodological document about how this data was generated, and a few additional analyses.&lt;/p&gt;
    &lt;head rend="h4"&gt;Correction note&lt;/head&gt;
    &lt;p&gt;This article was initially published on October 6, 2025, and was updated on October 9. This update corrected an error, whereby ‚ÄúDrug and overdose‚Äù deaths were also included within the US CDC category of ‚ÄúAccidents‚Äù. This meant that they were double-counted. We have corrected this, and the change made only a small difference to the final numbers. The relative share of deaths from accidents changed from 9.5% to 7.8%, and the share of other causes increased slightly. We thank Karl Pettersson for flagging this.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;head rend="h4"&gt;The limits of our personal experience and the value of statistics&lt;/head&gt;
        &lt;p&gt;The world is huge; to get a clear idea of what our world is like, we have to rely on carefully collected, well-documented statistics.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h4"&gt;Causes of death globally: what do people die from?&lt;/head&gt;
        &lt;p&gt;To make progress towards a healthier world we need to have a good understanding of what health problems we face today.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h4"&gt;How are causes of death registered around the world?&lt;/head&gt;
        &lt;p&gt;In many countries, when people die, the cause of their death is officially registered in their country‚Äôs national system. How is this determined?&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Endnotes&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Respondents could choose to ‚Äúagree‚Äù with multiple answers. This survey was from 2015, but as we‚Äôll see, more recent data suggests that even in 2025, most Americans think the news keeps them informed about what‚Äôs happening worldwide.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;In the Pew Research survey, 46% said it made them feel informed ‚Äúextremely often or often‚Äù with a further 43% ‚Äúsometimes‚Äù. That was more common than any other emotion. The other high-ranking ones were negative emotions such as anger or sadness.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;In 2023, there were approximately 3 million (3,090,964) deaths in the United States. 2.3 million (2,350,117) died from the twelve leading causes plus drug overdoses, homicides and terrorism. You can find these results in our intermediate and final data files, which are available in our methodology document. That means the combined share was around 76% of the total [2,305,117 / 3,090,964 * 100 = 76%].&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;We used mortality data from CDC Wonder for all causes except terrorism (which isn‚Äôt reported there). For this, we relied on data from the Global Terrorism Index.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;This figure is sourced from the Institute for Economics and Peace (IEP)‚Äôs Global Terrorism Index 2024 Report. It states on page 38: ‚ÄúThe impact of terrorism improved in North America over the past year, owing to an improvement in score in Canada. There was one attack and death from terrorism in Canada in 2023, down from the peak of 12 deaths and eight attacks in 2018. By contrast, the impact of terrorism increased in the US, with 16 deaths from seven incidents.‚Äù&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Isch, C. (2025). Media bias in portrayals of mortality risks: Comparison of newspaper coverage to death rates. Social Science &amp;amp; Medicine, 364, 117542.&lt;/p&gt;
        &lt;p&gt;Pilar, M. R., Eyler, A. A., Moreland-Russell, S., &amp;amp; Brownson, R. C. (2020). Actual causes of death in relation to media, policy, and funding attention: Examining public health priorities. Frontiers in Public Health, 8, 279.&lt;/p&gt;
        &lt;p&gt;Bomlitz, L. J., &amp;amp; Brezis, M. (2008). Misrepresentation of health risks by mass media. Journal of Public Health, 30(2), 202-204.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Isch, C. (2025). Media bias in portrayals of mortality risks: Comparison of newspaper coverage to death rates. Social Science &amp;amp; Medicine, 364, 117542.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;This survey was conducted by Pew Research in 2024. It asked US adults whether they were extremely/very concerned, somewhat concerned, or not at all concerned about crime in their local community affecting them or their family.&lt;/p&gt;
        &lt;p&gt;33% of those who ‚Äúoften‚Äù get local crime news were ‚Äúextremely concerned‚Äù. The share among those who ‚Äúsometimes‚Äù get this type of news was 19%. It was just 10% among those who rarely consume it.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Cite this work&lt;/head&gt;
    &lt;p&gt;Our articles and data visualizations rely on work from many different people and organizations. When citing this article, please also cite the underlying data sources. This article can be cited as:&lt;/p&gt;
    &lt;code&gt;Hannah Ritchie, Tuna Acisu, and Edouard Mathieu (2025) - ‚ÄúDoes the news reflect what we die from?‚Äù Published online at OurWorldinData.org. Retrieved from: 'https://ourworldindata.org/does-the-news-reflect-what-we-die-from' [Online Resource]&lt;/code&gt;
    &lt;p&gt;BibTeX citation&lt;/p&gt;
    &lt;code&gt;@article{owid-does-the-news-reflect-what-we-die-from,
    author = {Hannah Ritchie and Tuna Acisu and Edouard Mathieu},
    title = {Does the news reflect what we die from?},
    journal = {Our World in Data},
    year = {2025},
    note = {https://ourworldindata.org/does-the-news-reflect-what-we-die-from}
}&lt;/code&gt;
    &lt;head rend="h3"&gt;Reuse this work freely&lt;/head&gt;
    &lt;p&gt;All visualizations, data, and code produced by Our World in Data are completely open access under the Creative Commons BY license. You have the permission to use, distribute, and reproduce these in any medium, provided the source and authors are credited.&lt;/p&gt;
    &lt;p&gt;The data produced by third parties and made available by Our World in Data is subject to the license terms from the original third-party authors. We will always indicate the original source of the data in our documentation, so you should always check the license of any such third-party data before use and redistribution.&lt;/p&gt;
    &lt;p&gt;All of our charts can be embedded in any site.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45583336</guid><pubDate>Tue, 14 Oct 2025 18:40:23 +0000</pubDate></item><item><title>Preparing for AI's economic impact: exploring policy responses</title><link>https://www.anthropic.com/research/economic-policy-responses</link><description>&lt;doc fingerprint="378c20bf60faa570"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Preparing for AI‚Äôs economic impact: exploring policy responses&lt;/head&gt;
    &lt;p&gt;How will the arrival of powerful AI systems change the structure of the economy? We are uncertain, and so are external experts. But as AI systems continue to improve, and are adopted at an ever-larger scale, it‚Äôs crucial there is more discussion about the tools policymakers could use to respond to AI's economic impacts‚Äîwhatever their nature. To help with this, we‚Äôre sharing several economic policy ideas that merit further study.&lt;/p&gt;
    &lt;p&gt;Since launching the Anthropic Economic Index, we've observed an important shift in AI use. Users are becoming increasingly likely to delegate full tasks to Claude, ‚Äúcollaborating‚Äù with Claude less. As AI models continue to work independently for longer periods of time, and as more employers adopt AI to improve their productivity, we expect this trend to accelerate. The implications for the workforce are uncertain.&lt;/p&gt;
    &lt;p&gt;How should policymakers respond? This is not an easy question, nor is it one that any single actor can answer. There is great uncertainty about the scale of the transition ahead, and a wide range of views about how to manage it. But it is imperative to begin formulating ideas now for the economic scenarios we might find ourselves in.&lt;/p&gt;
    &lt;p&gt;Over the past year, we‚Äôve worked with economists and policy experts from around the world (including members of our Economic Advisory Council and participants in our first Economic Futures Symposium) to move this discussion forward. To generate a broad range of ideas, we‚Äôve engaged with both non-partisan thinkers and those from across the political spectrum.&lt;/p&gt;
    &lt;p&gt;Below, we briefly explore nine of these categories of ideas, covering workforce development, permitting reform, fiscal policy, and social services.&lt;/p&gt;
    &lt;p&gt;While we don‚Äôt know what the optimal policies will prove to be, we‚Äôre committed to sharing ideas in the open, and to being transparent about the economic effects of advanced AI.&lt;/p&gt;
    &lt;head rend="h2"&gt;Matching policies to scenarios&lt;/head&gt;
    &lt;p&gt;The rate, scale, and form of AI's economic effects will determine the policy responses that are necessary across the world. Accordingly, we've organized these initial ideas into three broad categories:&lt;/p&gt;
    &lt;p&gt;Policy ideas for nearly all scenarios, including those where negative effects on the labor market remain modest. These are policies that their advocates argue merit consideration almost regardless of how significant the disruption of AI proves to be. Given this, many of these proposals have been suggested in other contexts before. They include upskilling workers and students for emerging jobs, and reforming permitting processes to enable the construction of energy and computing infrastructure to improve productivity.&lt;/p&gt;
    &lt;p&gt;Policy ideas for scenarios with moderate acceleration, where AI leads to measurable wage declines and job losses for large portions of the workforce. Here, more substantial fiscal support for displaced workers might be needed. To offset negative externalities imposed on displaced workers from rapid automation, taxes on automation might be considered in this scenario.&lt;/p&gt;
    &lt;p&gt;Policy ideas for faster-moving scenarios, potentially involving dramatic job losses and worsening inequality. These proposals are much more ambitious, and are designed to respond to a starkly different economic picture. So far, ideas include using sovereign wealth funds to give citizens stakes in AI revenues, and finding new ways to generate government revenue.&lt;lb/&gt;The proposals below don‚Äôt necessarily represent Anthropic's own policy positions. But we‚Äôre excited by the breadth of proposals we‚Äôve received, and we hope they encourage further research and debate.&lt;/p&gt;
    &lt;head rend="h2"&gt;Policies for nearly all scenarios&lt;/head&gt;
    &lt;head rend="h3"&gt;1. Invest in upskilling through workforce training grants&lt;/head&gt;
    &lt;p&gt;At our DC Symposium, Abigail Ball, Executive Director of American Compass, presented the Workforce Training Grant‚Äîa proposal she developed with colleague Oren Cass to direct public resources toward on-the-job training.&lt;/p&gt;
    &lt;p&gt;Under this model, governments would provide substantial annual subsidies (Ball and Cass suggest $10,000 per year in the US) directly to employers who create formal trainee positions with structured training programs. This training could take multiple forms: programs operated by individual employers, by employer consortia or industry associations, through partnerships between employers and organized labor, or by technical schools and community colleges working alongside employers.&lt;/p&gt;
    &lt;p&gt;American Compass proposes redirecting existing higher education subsidies to fund this program. But a range of other funding mechanisms might also deserve consideration‚Äîincluding the possibility of using taxes on AI consumption to support workforce development initiatives.&lt;/p&gt;
    &lt;head rend="h3"&gt;2. Reform tax incentives for worker retention and retraining&lt;/head&gt;
    &lt;p&gt;Tax policy can, on the margin, incentivize employers to retrain and retain employees rather than reducing headcount.&lt;/p&gt;
    &lt;p&gt;Revana Sharfuddin of the Mercatus Center argues that the US tax code creates a bias favoring physical capital investment over human capital investment. Businesses can immediately expense AI systems through bonus depreciation, yet face numerous restrictions when deducting worker training costs. She proposes reforms to the Internal Revenue Code, including eliminating the $5,250 cap on tax-free educational assistance, and extending full and immediate expensing to all job-related training.&lt;/p&gt;
    &lt;p&gt;These changes would aim to reduce the cost of retraining relative to the cost of layoffs, helping those workers whose positions might otherwise be on the margins of workforce reduction decisions.&lt;/p&gt;
    &lt;head rend="h3"&gt;3. Close corporate tax loopholes&lt;/head&gt;
    &lt;p&gt;Tax policy expert David Gamage has outlined reforms designed to prevent AI transformation from straining government budgets. Several of his proposals involve closing the ‚Äúpartnership gap‚Äù that allows large businesses to avoid entity-level taxes, and modernizing tax allocation to combat profit shifting and better capture value from digital and intangibles-based business models.&lt;/p&gt;
    &lt;p&gt;The second reform would allocate business taxes based on customer locations through market-based apportionment, while requiring worldwide combined reporting to treat multinationals and subsidiaries as single entities. This approach is designed to limit artificial profit-shifting to tax havens‚Äîa practice that could become more prevalent as AI potentially further increases the economic importance of profits derived from intangibles.&lt;/p&gt;
    &lt;p&gt;Gamage argues that "governments that act first will solve their fiscal challenges and better position residents to thrive in an AI economy. Those that wait will face resource constraints when flexibility is most needed."&lt;/p&gt;
    &lt;head rend="h3"&gt;4. Accelerate permits and approvals for AI infrastructure&lt;/head&gt;
    &lt;p&gt;Anthropic has consistently advocated for reforming permitting and power procurement processes in the United States and allied nations. Accelerating these processes is needed to develop the infrastructure to train and deploy frontier AI‚Äîthat is, large-scale data centers, transmission infrastructure, and power generation facilities. Reforms will also unlock investment, economic growth, and job creation in the places where AI is built. Failing to accelerate AI infrastructure development will slow productivity and job growth, and it could introduce national security risks from vital AI infrastructure moving offshore.&lt;/p&gt;
    &lt;p&gt;Three overlapping sets of U.S. regulatory processes delay building large-scale AI infrastructure for years. The first category is permits. These include a series of land use and environmental approvals at the federal, state, and local levels. Second, state regulatory reviews for transmission projects can cause buildouts of new lines to last 10 years or more. Finally, approvals to interconnect facilities to the electric grid typically take 4-6 years for generation resources.&lt;/p&gt;
    &lt;p&gt;Concrete steps to address these challenges include reforms to the National Environmental Policy Act (NEPA), which requires federal agencies to review many projects‚Äô environmental effects. Advance analyses of certain kinds of facilities, such as data centers, could help speed reviews of future projects. Other reforms could include leveraging federal authorities to expedite critical transmission buildouts and upgrades and collaboration with utilities to identify opportunities for fast interconnections.&lt;/p&gt;
    &lt;p&gt;As Tyler Cowen, faculty director of the Mercatus Center and member of our Economic Advisory Council, notes: "I am all for permitting reform‚Äîthe energy sector included."&lt;/p&gt;
    &lt;head rend="h2"&gt;Policy ideas for moderate scenarios&lt;/head&gt;
    &lt;head rend="h3"&gt;5. Establish trade adjustment assistance for AI displacement&lt;/head&gt;
    &lt;p&gt;Several economists are exploring how the Trade Adjustment Assistance (TAA) model ‚Äì in which affected workers are given opportunities to obtain new skills, or receive other support ‚Äì might be adapted for labor market disruptions in an era of powerful AI. Ioana Marinescu of the University of Pennsylvania, a member of our Economic Advisory Council, views TAA-like "AI insurance" as a mechanism "to support those who lose jobs due to AI."&lt;/p&gt;
    &lt;p&gt;Along these lines, Suchet Mittal and Sam Manning have outlined a potential Automation Adjustment Assistance (AAA) program. They describe how funding AAA at levels similar to TAA‚Äîapproximately $700 million annually‚Äîcould be an initial option, with mechanisms built in to increase or decrease the size of the program in line with the pace and scale of AI-driven displacement.&lt;/p&gt;
    &lt;p&gt;Mittal and Manning note that if such a program needed to expand in the future, it could potentially be funded through taxes on AI-driven revenues from firms above a certain high level of market capitalization, creating a direct mechanism for the AI sector to support workers displaced by the technology.&lt;/p&gt;
    &lt;head rend="h3"&gt;6. Implement taxes on compute or token generation&lt;/head&gt;
    &lt;p&gt;University of Virginia economists Lee Lockwood and Anton Korinek (a member of our Economic Advisory Council) propose studying of a range of taxes on ‚Äútoken generation, robots, robot services, and digital services.‚Äù&lt;/p&gt;
    &lt;p&gt;These taxes offer different potential benefits ‚Äì and distortionary risks ‚Äì depending on the stage of AI‚Äôs development within the economy. A tax on AI-generated tokens sold to end users (a ‚Äútoken tax‚Äù) might be desirable when humans remain dominant consumers in the economy, even if powerful AI reduces the relative economic role of labor.&lt;/p&gt;
    &lt;p&gt;Korinek and Lockwood argue that, if the economy reaches a stage where powerful AI systems become themselves major consumers of the economy‚Äôs resources, taxing AI resource accumulation‚Äìe.g. via taxes on compute and other hardware‚Äìmight be more effective than token taxes on human end users. Although these taxes on computational resources distort investment along an AI-transformed economy‚Äôs trajectory, they could become the only remaining mechanism to capture some of the windfall generated by AI if the role of both labor markets and human consumption in the economy declines.&lt;/p&gt;
    &lt;p&gt;We believe taxes in this broader category deserve serious study, even though they would directly impact Anthropic's revenue and profitability. These taxes could provide crucial revenue for vital fiscal programs‚Äîincluding several others discussed in this post.&lt;/p&gt;
    &lt;head rend="h2"&gt;Policy ideas for fast-moving scenarios&lt;/head&gt;
    &lt;head rend="h3"&gt;7. Create national sovereign wealth funds with stakes in AI&lt;/head&gt;
    &lt;p&gt;A growing set of proposals aims to give citizens and governments greater stakes in AI's economic returns. Sovereign wealth funds could enable states to acquire positions in AI-related assets. In scenarios where the AI sector captures an outsized share of economic wealth, government investment could both shape the sector's behavior and "distribute AI-derived wealth more equitably."&lt;/p&gt;
    &lt;p&gt;Writing for the Centre for British Progress, Emma Casey, Emma Rockall, and Helena Roy have proposed a related concept for the United Kingdom: an AI Bond. The AI Bond would aim to ensure adequate investment in "the AI stack" to capture AI's benefits and then distribute its returns more evenly across Britain‚Äîeven as AI research roles concentrate in a few cities, like London.&lt;/p&gt;
    &lt;head rend="h3"&gt;8. Adopt or modernize value-added taxes&lt;/head&gt;
    &lt;p&gt;Six out of the G7 countries have national value-added taxes (VATs), as do 37 out of 38 OECD countries. The United States is the exception.&lt;/p&gt;
    &lt;p&gt;As AI transforms the economy, labor's share of the production of value might decline significantly. A shift toward taxing consumption (as through a VAT) could become necessary to fund core government activities. VAT collection also provides governments with fine-grained information about the economic production network‚Äîwhich could be particularly valuable during this potential period of rapid technological and economic change.&lt;/p&gt;
    &lt;p&gt;"Value-added taxes are non-distortionary and to an extent, self-enforcing," notes John Horton of MIT's Sloan School of Management, a member of our Economic Advisory Council.&lt;/p&gt;
    &lt;head rend="h3"&gt;9. Implement new revenue structures to account for AI‚Äôs growing share of the economy&lt;/head&gt;
    &lt;p&gt;If AI is responsible for a large share of economic output (causing labor‚Äôs share to decline), governments might require new revenue streams to complement income tax. Another of David Gamage‚Äôs proposals is exploring a "low-rate business wealth tax" as a complement to income taxes. His reasoning: "Income taxes face accounting manipulation; wealth taxes face asset valuation challenges. Using both makes the system harder to avoid" for highly profitable enterprises.&lt;/p&gt;
    &lt;p&gt;Gamage analogizes this system to the fee structures that certain asset managers charge clients: "the wealth tax functions as a management fee for providing legal infrastructure protecting accumulated capital, while the income tax serves as a performance fee for profits generated in state markets." This idea represents one way that governments might adapt to changes in the value of human labor, although we think there are many more ideas to be explored in this area.&lt;/p&gt;
    &lt;head rend="h2"&gt;Continuing the conversation&lt;/head&gt;
    &lt;p&gt;Earlier this fall, Anthropic announced a $10 million commitment to scale up the Economic Futures Program. This investment will support rigorous empirical research on AI's economic impacts and policy ideas, as well as expand our Symposia series‚Äîbeginning with an event in London this November, which follows our September event in DC.&lt;/p&gt;
    &lt;p&gt;None of the ideas outlined here represent definitive recommendations. They are starting points for deeper research, policy development, and public debate. The economic effects of AI remain uncertain in both timing and magnitude, and different scenarios will require different responses.&lt;/p&gt;
    &lt;p&gt;What's clear, though, is that proactive engagement between researchers, policymakers, and the AI industry is essential. By exploring these options now‚Äîbefore we know the shape of AI‚Äôs economic effects‚Äîwe can better prepare for a range of possible futures, and ensure that workers and communities are well-placed to benefit from the full potential of AI.&lt;/p&gt;
    &lt;p&gt;Most of the policy ideas discussed in this post have emerged from proposals from or conversations with members of Anthropic's Economic Advisory Council, participants in our Economic Futures Symposia, and independent researchers. They do not all necessarily represent Anthropic's policy positions.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45583574</guid><pubDate>Tue, 14 Oct 2025 19:06:27 +0000</pubDate></item><item><title>Show HN: An open source access logs analytics script to block bot attacks</title><link>https://github.com/tempesta-tech/webshield</link><description>&lt;doc fingerprint="8c889c30cc1168c7"&gt;
  &lt;main&gt;
    &lt;p&gt;Block users by JA5T, JA5H, or IP based on Tempesta FW access logs stored in the ClickHouse database.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Python 3.12 &amp;lt;=&lt;/item&gt;
      &lt;item&gt;Tempesta FW 0.8.0 &amp;lt;=&lt;/item&gt;
      &lt;item&gt;Clickhouse 25.6.0 &amp;lt;=&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;python3 -m venv tempesta-webshield
source tempesta-webshield/bin/activate
pip install -r requirements.txt
cp example.env /etc/tempesta-webshield/app.env
touch /etc/tempesta-webshield/allow_user_agents.txt
python3 app.py &lt;/code&gt;
    &lt;code&gt;# run all tests with a logging level INFO
pytest

# show the tests output
pytest -s

# the additional verbose level for pytest
pytest -vvv

# run debugger on the error
pytest --pdb

# run the tests from dir
pytest -s -vvv tests

# run the tests from file
pytest -s -vvv tests/test_app.py

# run the specific test
pytest -s -vvv tests/test_app.py::test_run_app

# preferred running params
pytest -s -vvv --pdb&lt;/code&gt;
    &lt;code&gt;black .
isort .&lt;/code&gt;
    &lt;p&gt;It's useful to define separate directories for different groups of JA5 hashes&lt;lb/&gt; in the Tempesta FW configuration file (/etc/tempesta/tempesta_fw.conf).&lt;/p&gt;
    &lt;code&gt;ja5t {
    !include /etc/tempesta/ja5t/
}
ja5h {
    !include /etc/tempesta/ja5h/
}&lt;/code&gt;
    &lt;p&gt;Then add 2 files&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;/etc/tempesta/ja5t/blocked.conf&lt;/item&gt;
      &lt;item&gt;/etc/tempesta/ja5h/blocked.conf&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These files should be used by default by the WebShield to add new blocking hashes.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45583667</guid><pubDate>Tue, 14 Oct 2025 19:15:57 +0000</pubDate></item><item><title>How to turn liquid glass into a solid interface</title><link>https://tidbits.com/2025/10/09/how-to-turn-liquid-glass-into-a-solid-interface/</link><description>&lt;doc fingerprint="36a4d5d74966e3dd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How to Turn Liquid Glass into a Solid Interface&lt;/head&gt;
    &lt;p&gt;Apple‚Äôs new Liquid Glass interface design brings transparency and blur effects to all Apple operating systems, but many users find it distracting or difficult to read. Here‚Äôs how to control its effects and make your interface more usable. Although the relevant Accessibility settings are quite similar across macOS, iOS, watchOS, and tvOS, I separate them because they offer different levels of utility in each. I have no experience with (or interest in) a Vision Pro, so I can‚Äôt comment on Liquid Glass in visionOS.&lt;/p&gt;
    &lt;head rend="h2"&gt;macOS 26&lt;/head&gt;
    &lt;p&gt;To help you get a feel for how the various settings affect the Mac interface, I‚Äôve taken all the screenshots below with the same screen content. For a quick comparison, download the images and then use Quick Look to flip back and forth between any two to view the differences. Select one image in the Finder, press the Space bar, and then use the arrow keys to change the Finder selection to the other image.&lt;/p&gt;
    &lt;head rend="h3"&gt;Default Settings&lt;/head&gt;
    &lt;p&gt;Here‚Äôs our starting point with macOS. Note the transparency in the menu bar, widgets, Control Center, and Dock. In the System Settings window, you can see that the sidebar is also translucent, allowing the wallpaper thumbnails to bleed through as they scroll underneath and letting the General item blur with Search at the top.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reduce Transparency&lt;/head&gt;
    &lt;p&gt;The setting that makes the most difference in toning down the excesses of Liquid Glass is System Settings &amp;gt; Accessibility &amp;gt; Display &amp;gt; Reduce Transparency. It turns the menu bar opaque, prevents the wallpaper from being visible through the widgets, Control Center, and Dock, and eliminates the awkward bleeds under the System Settings sidebar. For those who take a lot of screenshots, like I do, Reduce Transparency is essential because it ensures that all screenshots have a consistent background. It would be highly distracting if screenshots had noticeably different colors due to being taken over different wallpapers or windows.&lt;/p&gt;
    &lt;head rend="h3"&gt;Increase Contrast (and Reduce Transparency)&lt;/head&gt;
    &lt;p&gt;To further clarify the interface, you can turn on System Settings &amp;gt; Accessibility &amp;gt; Display &amp;gt; Increase Contrast, which also automatically enables Reduce Transparency. It outlines most interface elements so they stand out much more strongly‚Äîno more light gray on lighter gray. Note that it also changes some colors, so if you ever see a system that has odd blues and greens in Messages, for instance, it‚Äôs usually this setting. I find the Increase Contrast setting jarring, but it might be a significant help for those with low vision.&lt;/p&gt;
    &lt;head rend="h3"&gt;Liquid Glass Off&lt;/head&gt;
    &lt;p&gt;Recently, Bob Pony revealed on Bluesky that there‚Äôs a hidden setting in macOS that lets you turn off Liquid Glass entirely. Enter the command below into Terminal to turn off Liquid Glass; turn it back on by running the command again after changing &lt;code&gt;YES&lt;/code&gt; to &lt;code&gt;NO&lt;/code&gt;. You‚Äôll need to log out and log back in to see the full effect.&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;defaults write -g com.apple.SwiftUI.DisableSolarium -bool YES&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;If you compare this screenshot to the first one, you can see that it eliminates the glass-like look of items in Control Center, drops the background around the Dock entirely, and reverts to the less-rounded corners familiar from macOS 15 Sequoia. The sidebar in System Settings is no longer on a layer above the rest of the window, and the Search field appears only at the top of the sidebar list, not as a hovering object that remains in view as you scroll the sidebar contents. You can‚Äôt see it in this screenshot, but the icon names that appear when you hover over them in the Dock also lose their background, becoming almost unreadable. Also not apparent from this screenshot is that all menus on the right side of the menu bar become almost entirely transparent and difficult to use‚Äîpresumably they‚Äôre managed by Control Center.&lt;/p&gt;
    &lt;head rend="h3"&gt;Liquid Glass Off, Reduce Transparency On&lt;/head&gt;
    &lt;p&gt;What disabling Liquid Glass doesn‚Äôt do‚Äîreasonably enough‚Äîis turn off transparency. When I add Reduce Transparency to the screenshot above, here‚Äôs what I get. The menu bar becomes opaque, which is good, and widgets become black. However, Control Center is completely borked, and the change makes no difference for the Dock.&lt;/p&gt;
    &lt;head rend="h3"&gt;Liquid Glass Off, Reduce Transparency and Increase Contrast On&lt;/head&gt;
    &lt;p&gt;Adding Increase Contrast to the mix does what you expect but doesn‚Äôt improve any of the problematic spots.&lt;/p&gt;
    &lt;p&gt;I can‚Äôt recommend turning off Liquid Glass entirely in this way. Although it does make macOS 26 look more like macOS 15, it suffers from several glaring mistakes that Apple has no incentive to fix. Stick to Reduce Transparency and add Increase Contrast if your eyes would appreciate it.&lt;/p&gt;
    &lt;head rend="h3"&gt;Liquid Glass Off, Per App&lt;/head&gt;
    &lt;p&gt;However, as Matt Sephton noted in TidBITS Talk, you can also turn off Liquid Glass on a per-app basis, at least for some Apple apps. He gives these commands as examples, and you can experiment with other apps by replacing their bundle identifier‚Äîthe &lt;code&gt;com.apple.finder&lt;/code&gt; piece‚Äîin the command below. To find it, Control-click any app, choose Show Package Contents, and search &lt;code&gt;Contents/Info.plist&lt;/code&gt; for the CFBundleIdentifier key. It‚Äôs usually sensible, like &lt;code&gt;com.apple.Home&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;defaults write com.apple.finder com.apple.SwiftUI.DisableSolarium -bool YES&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;defaults write com.apple.Preview com.apple.SwiftUI.DisableSolarium -bool YES&lt;/code&gt;
    &lt;/p&gt;
    &lt;head rend="h3"&gt;Reduce Motion&lt;/head&gt;
    &lt;p&gt;There is one other setting that‚Äôs often recommended for solidifying the interface: System Settings &amp;gt; Accessibility &amp;gt; Motion &amp;gt; Reduce Motion. On the Mac, the main place I see this changing things is in the zoom animation when entering full-screen mode‚Äîit becomes a cross-fade transition instead. Turn it on if you like, but don‚Äôt expect it to make a notable difference unless you have specific vision issues that call for it.&lt;/p&gt;
    &lt;head rend="h2"&gt;iOS 26&lt;/head&gt;
    &lt;p&gt;iOS has all the Accessibility settings macOS does and then some, plus Increase Contrast can be turned on separately from Reduce Transparency. For each of the screenshots below, the original image is on the left and a screenshot showing the effect of the setting is on the right. iPadOS is similar, as you‚Äôd expect.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reduce Transparency&lt;/head&gt;
    &lt;p&gt;I‚Äôll start by turning on Settings &amp;gt; Accessibility &amp;gt; Display &amp;amp; Text Size &amp;gt; Reduce Transparency, which is again the most effective way to bring Liquid Glass to heel. As you can see, the big win is the notifications, which gain a solid background that makes them far more readable against the background. The Search button at the bottom also becomes opaque, as does the Dock‚Äôs border. The downside is that you‚Äôll encounter some apps, such as Photos, where top or bottom toolbars have relatively few buttons and look strange because Apple expects the background to show through.&lt;/p&gt;
    &lt;head rend="h3"&gt;Increase Contrast&lt;/head&gt;
    &lt;p&gt;Turning Reduce Transparency off but enabling Settings &amp;gt; Accessibility &amp;gt; Display &amp;amp; Text Size &amp;gt; Increase Contrast offers an intermediate level of improved readability. The notifications are still see-through, but the extra contrast causes their text to stand out more. Increase Contrast applies solid borders to elements such as the notifications, flashlight and camera buttons, the Search button, and the Dock, helping to differentiate them from the background as well. Be warned that the blues and greens in Messages‚Äîand those used for switches through the interface‚Äîwill look different from everyone else‚Äôs if you have Increase Contrast turned on.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reduce Transparency and Increase Contrast&lt;/head&gt;
    &lt;p&gt;What about combining the two? It does exactly what you‚Äôd expect, eliminating the bleedthrough of the background nearly everywhere, boosting the contrast, and adding borders.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bold Text&lt;/head&gt;
    &lt;p&gt;Perhaps the transparency doesn‚Äôt bother you, but you‚Äôre still having trouble reading text. You can try turning on Settings &amp;gt; Accessibility &amp;gt; Display &amp;amp; Text Size &amp;gt; Bold Text, which adds some weight to all text in the interface. (Happily, it doesn‚Äôt require restarting the iPhone anymore.) I think it helps, but not as much as either Reduce Transparency or Increase Contrast.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reduce Transparency, Increase Contrast, and Bold Text&lt;/head&gt;
    &lt;p&gt;Since all these settings are independent, you can combine them for the ultimate in a non-transparent, highly readable interface. It‚Äôs more than I need, but there‚Äôs no shame if you like it best.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reduce Motion&lt;/head&gt;
    &lt;p&gt;You may have noticed that Notification Center itself is a ‚Äúpane of glass‚Äù with a curved edge that distorts the text above the bottom row of icons. That‚Äôs more annoying in static screenshots than in actual use, but you can eliminate refractions as well by turning on Settings &amp;gt; Accessibility &amp;gt; Motion &amp;gt; Reduce Motion. (While you‚Äôre there, test with Prefer Cross-Fade Transitions, too‚ÄîI had trouble discerning what it did.) The right-hand screenshot below has only Reduce Motion turned on, but you can see that the edge of Notification Center‚Äôs pane no longer distorts the text under it, and it also makes the background noticeably blurrier. You can combine Reduce Motion with all the rest of the settings if you want. The downside of Reduce Motion is that some aspects of the iPhone and iPad experience may feel abrupt without their normal transitions.&lt;/p&gt;
    &lt;head rend="h3"&gt;Other Settings&lt;/head&gt;
    &lt;p&gt;For reference, here are the Settings &amp;gt; Accessibility screens I‚Äôve been discussing. A few additional settings here may enhance your experience with Liquid Glass and the iOS 26 interface in general. You can increase the text size with Larger Text, although at some point, certain parts of the interface may look weird. It can be tricky to find examples of what turning on Button Shapes will do, but more buttons that are normally just text will get outlines and possibly be underlined. Enabling On/Off Labels adds a vertical line (for on) or circle (for off) symbol to all switches if the color change doesn‚Äôt work for you.&lt;/p&gt;
    &lt;head rend="h2"&gt;watchOS 26&lt;/head&gt;
    &lt;p&gt;watchOS has the same Accessibility settings as iOS, and for the most part, they serve the same purpose. That said, the Apple Watch display is small enough that Apple was more restrained in how extensively it implemented Liquid Glass, so reducing the impact of Liquid Glass is less necessary.&lt;/p&gt;
    &lt;p&gt;The easiest way to test these settings is through the Accessibility screen in the iPhone‚Äôs Watch app‚Äîchanges take effect immediately on your Apple Watch. They‚Äôre also available in Settings &amp;gt; Accessibility on the watch itself, but it‚Äôs much clumsier to work with.&lt;/p&gt;
    &lt;head rend="h3"&gt;Default Settings&lt;/head&gt;
    &lt;p&gt;To set the stage, here‚Äôs what four screens of watchOS 26 look like with the Photos face. Obviously, what bleeds through the Liquid Glass will depend on your face; some faces work better than others. Nevertheless, you can see that the photo is fairly visible under the notification in the second image, and somewhat visible behind the Smart Stack in the fourth, but hardly noticeable behind Control Center in the third. (Ignore some of the numbers changing; it‚Äôs devilishly difficult to capture these screenshots precisely and in the desired sequence, so I had to retake a few.)&lt;/p&gt;
    &lt;head rend="h3"&gt;Reduce Transparency&lt;/head&gt;
    &lt;p&gt;Enabling the Reduce Transparency switch results in notable changes. The background disappears from all three screens with overlays. My take is that the notification text is much easier to read; the other screens aren‚Äôt markedly different in terms of readability.&lt;/p&gt;
    &lt;head rend="h3"&gt;Increase Contrast&lt;/head&gt;
    &lt;p&gt;Swapping Reduce Transparency for Increase Contrast keeps the black background under Notification Center, but restores it to Control Center and the Smart Stack. Nonetheless, the icons in Control Center stand out noticeably better thanks to darker backgrounds and brighter whites. For my eyes, Increase Contrast offers the best combination of making aspects of the interface‚Äînotably the notifications‚Äîeasier to read while still retaining some of the background for aesthetic reasons.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bold Text&lt;/head&gt;
    &lt;p&gt;Perhaps the problem is simply the text being too thin? This test, with the Bold Text setting enabled, shows that making the text bold helps slightly, but the notification text remains harder to read against the image background. Bold Text appears to affect only the text in Control Center, not the icons, but it does bold the orange Timer icon in the Smart Stack. Notice that it also bolded the date and temperature on the initial screen. To my mind, Bold Text is not much of a win on its own.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reduce Transparency, Increase Contrast, and Bold Text&lt;/head&gt;
    &lt;p&gt;As expected, combining all three settings yields the most readable interface in watchOS. Reduce Transparency eliminates the blurry backgrounds, Increase Contrast makes the buttons in Control Center pop, and Bold Text makes all the text a bit thicker and easier to parse.&lt;/p&gt;
    &lt;head rend="h3"&gt;Other Settings&lt;/head&gt;
    &lt;p&gt;As with iOS, a few other settings in the Accessibility screen may also be helpful. You can increase the text size throughout the interface using the Text Size slider, although setting it too large will significantly reduce the amount of information that fits on the screen and result in some awkward wrapping. There‚Äôs also a Reduce Motion switch, but I couldn‚Äôt figure out what effect it has.&lt;/p&gt;
    &lt;head rend="h2"&gt;tvOS&lt;/head&gt;
    &lt;p&gt;I‚Äôll admit a distinct level of apathy when it comes to Liquid Glass in tvOS 26. Because tvOS is primarily about consuming content, and Apple has already put a lot of work into making it visually striking, the Liquid Glass changes don‚Äôt make much difference. That‚Äôs even more true in apps other than Apple‚Äôs TV app since they all do their own thing anyway.&lt;/p&gt;
    &lt;p&gt;To illustrate what you can control, I combined three screens that change based on the available Accessibility settings:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Left: The TV app with its Liquid Glass sidebar&lt;/item&gt;
      &lt;item&gt;Middle: The tvOS Home Screen showing an Apple TV+ movie under the Liquid Glass-enabled Top Shelf of icons and Control Center&lt;/item&gt;
      &lt;item&gt;Right: The screen at Settings &amp;gt; Accessibility &amp;gt; Display, where these settings live.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Default Settings&lt;/head&gt;
    &lt;p&gt;In the default state, note that the Liquid Glass sidebar on the left side displays blurry images of the icons underneath it, and the Liquid Glass-driven Top Shelf features a movie poster background surrounding the icons. Similarly, the Control Center icons show the poster background. The Settings text is provided for reference‚Äîno Liquid Glass is involved.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reduce Transparency&lt;/head&gt;
    &lt;p&gt;Turning on Reduce Transparency eliminates the bleedthrough of the background in the sidebar, Top Shelf, and Control Center, and it slightly lightens the color of the Settings screen. The readability of the sidebar does improve, but the icons in the Top Shelf and Control Center are equally readable in either state.&lt;/p&gt;
    &lt;head rend="h3"&gt;Increase Contrast&lt;/head&gt;
    &lt;p&gt;Increase Contrast has a minimal effect in tvOS. Most notably, it makes the headings above the controls in the Settings screen brighter. The time and the Channels &amp;amp; Apps headings also become a bit brighter. The outlines around the Top Shelf and Control Center icons also become more prominent. Ironically, making the headings look more like the controls and sidebar items reduces contrast.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bold Text&lt;/head&gt;
    &lt;p&gt;I actively dislike Bold Text in tvOS. For my eyes, the text in tvOS is easy enough to read to start, and making it bold muddies it and makes it slightly harder to read in general. Nor do I think it helps readability in the Liquid Glass sidebar.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reduce Transparency, Increase Contrast, and Bold Text&lt;/head&gt;
    &lt;p&gt;Putting all the settings together does what you‚Äôd expect, and if your eyes prefer it, that‚Äôs fine. Since I don‚Äôt like the Bold Text changes and Increase Contrast has such a minimal effect, I wouldn‚Äôt use these settings.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reduce Motion&lt;/head&gt;
    &lt;p&gt;tvOS has an option at Settings &amp;gt; Accessibility &amp;gt; Motion &amp;gt; Reduce Motion, but as with watchOS, I couldn‚Äôt figure out what impact it has. However, I‚Äôm thrilled I found it because that screen also contains the option to turn off Auto-Play Video Previews, which I hate with the heat of a burning sun.&lt;/p&gt;
    &lt;head rend="h2"&gt;Recommendations&lt;/head&gt;
    &lt;p&gt;As I hope I‚Äôve been clear throughout, everyone‚Äôs vision is different, and you should choose the settings that make these various interfaces the most usable for you. If you‚Äôre looking for a starting point, here‚Äôs what I‚Äôve done.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;macOS 26: Use Reduce Transparency to bring back the opaque menu bar and eliminate odd bleedthroughs in various parts of the interface. This setting is particularly important if you take screenshots for documentation.&lt;/item&gt;
      &lt;item&gt;iOS 26 and iPadOS 26: If you can read notifications and don‚Äôt have trouble with readability in other apps, I recommend leaving all the settings off to start and only turning on Reduce Transparency if you decide you need it. It significantly improves readability, but at the cost of awkward interfaces in some apps that heavily rely on Liquid Glass elements.&lt;/item&gt;
      &lt;item&gt;watchOS 26: My favorite setting for watchOS is Increase Contrast, which makes notifications more readable by eliminating the bleedthrough background and also causes some buttons in the interface to stand out more. Reduce Transparency isn‚Äôt much of a win and makes the interface less attractive.&lt;/item&gt;
      &lt;item&gt;tvOS: I don‚Äôt see enough benefit in any of the settings that reduce Liquid Glass to bother with them. Reduce Transparency works as expected, but there‚Äôs relatively little transparency used, so it makes little real-world difference. But turning off Auto-Play Video Previews is a huge relief!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Let me leave with one final reminder. Liquid Glass is here to stay. Apple will continue to refine it in small ways throughout the rest of the OS 26 cycle, but there‚Äôs no avoiding it. Nor is it the worst thing ever‚Äîit won‚Äôt radically affect the Apple experience for most people, and with the judicious use of the Accessibility settings I‚Äôve described here, you can reduce the impact of any changes that do make it harder for you to interact with your devices.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45583787</guid><pubDate>Tue, 14 Oct 2025 19:27:41 +0000</pubDate></item><item><title>Show HN: Wispbit - Linter for AI coding agents</title><link>https://wispbit.com</link><description>&lt;doc fingerprint="eed4480eb1c4fe76"&gt;
  &lt;main&gt;
    &lt;p&gt;Manage your own rules&lt;/p&gt;
    &lt;p&gt;See all your rules in one place. Rules combine determinism with LLMs for high accuracy to give a &amp;gt;80% resolution rate.&lt;/p&gt;
    &lt;p&gt;Create or update rules&lt;/p&gt;
    &lt;p&gt;Learns from your codebase activity&lt;/p&gt;
    &lt;p&gt;Manage your own rules&lt;/p&gt;
    &lt;p&gt;See all your rules in one place. Rules combine determinism with LLMs for high accuracy to give a &amp;gt;80% resolution rate.&lt;/p&gt;
    &lt;p&gt;Create or update rules&lt;/p&gt;
    &lt;p&gt;Use the builder to quickly create custom rules, or edit existing ones.&lt;/p&gt;
    &lt;p&gt;Learns from your codebase activity&lt;/p&gt;
    &lt;p&gt;Automatically capture patterns and standards from your team's code changes and feedback, and turn them into rules.&lt;/p&gt;
    &lt;p&gt;Why us&lt;/p&gt;
    &lt;p&gt;... and not some other stranger&lt;/p&gt;
    &lt;p&gt;Us&lt;/p&gt;
    &lt;p&gt;Rules combine determinism + LLMs for high accuracy and &amp;gt;80% resolution rate&lt;/p&gt;
    &lt;p&gt;Rules are added and kept up to date automatically based on feedback and code changes&lt;/p&gt;
    &lt;p&gt;Runs anywhere - CLI, IDE, Pull Requests, Background Agents&lt;/p&gt;
    &lt;p&gt;Automates boring human repetitive work&lt;/p&gt;
    &lt;p&gt;Them&lt;/p&gt;
    &lt;p&gt;Poor rules support or only simple prompts that add slop&lt;/p&gt;
    &lt;p&gt;Adding and keeping rules up to date is manual and time consuming&lt;/p&gt;
    &lt;p&gt;Limited to running during code review&lt;/p&gt;
    &lt;p&gt;Adds more work than it saves&lt;/p&gt;
    &lt;p&gt;How it helps&lt;/p&gt;
    &lt;p&gt;Your workflow&lt;/p&gt;
    &lt;p&gt;Stop AI slop&lt;/p&gt;
    &lt;p&gt;Put up guardrails against bad code, AI-generated or not. Maintainable and readable code helps you ship fast. Have someone that always keeps you and your team accountable.&lt;/p&gt;
    &lt;p&gt;Automate engineering work&lt;/p&gt;
    &lt;p&gt;Automate the boring and repetitive work so you can focus on what's important.&lt;/p&gt;
    &lt;p&gt;&amp;gt;80% resolution rate&lt;/p&gt;
    &lt;p&gt;Rules are ran using a mix of determinism + LLMs. We tune and pick up patterns that matter.&lt;/p&gt;
    &lt;p&gt;Save 100 hours/year per engineer&lt;/p&gt;
    &lt;p&gt;That's $10,000+ a year. Spend more time doing the fun and important stuff, and less time repeating yourself.&lt;/p&gt;
    &lt;p&gt;Ramp up engineers faster&lt;/p&gt;
    &lt;p&gt;Fix tribal knowledge. Spend your time on meaningful mentorship instead of picking out every detail.&lt;/p&gt;
    &lt;p&gt;10x your AI investment&lt;/p&gt;
    &lt;p&gt;AI works best in consistent codebases with the right context. We do that.&lt;/p&gt;
    &lt;p&gt;Prevent downtime&lt;/p&gt;
    &lt;p&gt;Be the last engineer to step on that legacy booby trap. Make sure no one else steps on it.&lt;/p&gt;
    &lt;p&gt;Refactor and improve standards&lt;/p&gt;
    &lt;p&gt;Introduce new standards and improve existing ones. Rescue existing codebases from slop or bad practices.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45584017</guid><pubDate>Tue, 14 Oct 2025 19:52:39 +0000</pubDate></item><item><title>AppLovin nonconsensual installs</title><link>https://www.benedelman.org/applovin-nonconsensual-installs/</link><description>&lt;doc fingerprint="941ead5c8a3ad465"&gt;
  &lt;main&gt;
    &lt;p&gt;See important disclosures including my related financial interests.&lt;/p&gt;
    &lt;p&gt;Mobile adtech juggernaut AppLovin recently faced multiple allegations of misconduct. Allegations run the gamut‚Äîprivacy, ad targeting, even national security and ties to China. I was among the researchers consulted by skeptical investors this spring, and I was quoted in one of their reports, explaining my concerns about AppLovin installing other games without user consent.&lt;/p&gt;
    &lt;p&gt;Today I argue that AppLovin places apps on users‚Äô Android devices without their consent. As a maxim says, extraordinary claims require extraordinary evidence, but I embrace that high bar. First, I study AppLovin source code and find that it installs other apps without users being asked to consent. I use a decompiler to access Java source for AppLovin‚Äôs SDK and middleware, plus partners‚Äô install helpers‚Äîfollowing the execution path from an ad tap (just clicking an ad, potentially a misclick aiming for a tiny X button, with no Install button even visible on screen) through to an installation. AppLovin used an obfuscator to conceal most function names and variable names, so the Java code is no easy read. But with patience, suitable devs can follow the logic. Usefully, some key steps are in JavaScript‚Äîagain obfuscated (minified), but readable thanks to a pretty-printer. I except the relevant parts and explain line by line.&lt;/p&gt;
    &lt;p&gt;Second, I gather 208 complaints that all say basically the same thing: users are receiving apps in situations where (at a minimum) they don‚Äôt think they agreed. The details of these complaints match what the code indicates: Install helpers (including from Samsung and T-Mobile) perform installs at AppLovin‚Äôs direction, causing most users to blame the install helpers (despite their generic names like Content Manager, Device Manager, and AppSelector). Meanwhile, most complaints report no notification or request for approval prior to install, but others say they got a screen which installed even when they pressed X to decline, and a few report a countdown timer followed by automatic installation. Beyond prose complaints, a handful of complaints include screenshots, and one has a video. Wording from the screenshots and video match strings in the code, and users‚Äô reports of auto-installs, X‚Äôs, and countdowns similarly match three forks in AppLovin‚Äôs code. Overall, users are furious, finding these installations contrary to both Android security rules and widely-held expectations.&lt;/p&gt;
    &lt;p&gt;AppLovin CEO Adam Foroughi posted in February 2025 that ‚ÄúEvery download results from an explicit user choice‚Äîwhether via the App Store or our Direct Download experience.‚Äù AppLovin Array Privacy Policy similarly claims that AppLovin ‚Äúfacilitates the on-device installation of mobile apps that you choose to download.‚Äù But did users truly make an ‚Äúexplicit ‚Ä¶ choice‚Äù and ‚Äúchoose to download‚Äù these apps? Complaints indicate that users don‚Äôt think they chose to install. And however AppLovin defends its five-second countdowns, a user‚Äôs failure to reject a countdown certainly is not an ‚Äúexplicit‚Äù choice to install. Nor is ‚ÄúInstallOnClose‚Äù (a quote from AppLovin‚Äôs JavaScript) consistent with widely-held expectations that ‚ÄúX‚Äù means no. Perhaps Foroughi intends to argue that a user ‚Äúconsents‚Äù to install any time the user taps an ad, but even that is a tall order. One, AppLovin‚Äôs X‚Äôs are unusually tiny, so mis-taps are especially likely. Two, users expect an actual Install button (not to mention appropriate contract formalities) before an installation occurs; users know that on Android, an arbitrary tap cannot ordinarily install an app. Ultimately, ‚Äúexplicit user choice‚Äù is a high bar, and user complaints show AppLovin is nowhere close.&lt;/p&gt;
    &lt;head rend="h2"&gt;The role of manufacturers and carriers&lt;/head&gt;
    &lt;p&gt;Why would Samsung, T-Mobile, and others grant AppLovin the ability to install apps? Two possibilities:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Financial incentives. AppLovin pays manufacturers and carriers for the permissions it seeks. These elevated permissions may be unusual, and the resulting installations are predictably annoying and unwanted for users. But at the right price, some partners may agree.&lt;/item&gt;
      &lt;item&gt;Scope creep. Public statements indicate manufacturers and carriers authorized AppLovin to perform ‚Äúout-of-box experience‚Äù (OOBE) installs‚Äîrecommending and installing apps during initial device setup. Install helpers were designed to support this narrow context. But my review of install helper code shows no checks to limit installations to the OOBE window. A simple safeguard‚Äîsuch as rejecting installs more than two hours after first boot‚Äîwould prevent ongoing installs. By omitting such safeguards, manufacturers and carriers effectively granted AppLovin open-ended install rights, whether or not that was their intent.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So far manufacturers and carriers haven‚Äôt said whether they approve what AppLovin is doing. Journalist Mike Shields asked Samsung, but they declined to comment. Perhaps my article will prompt them to take another look.&lt;/p&gt;
    &lt;head rend="h2"&gt;Sources of evidence&lt;/head&gt;
    &lt;p&gt;Five overlapping categories of evidence offer a mutually-reinforcing picture of nonconsensual installations:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Execution path. Source code extracted from test devices shows how an ad tap leads all the way to an installation, without a user pressing ‚ÄúInstall‚Äù or similar at a consent screen.&lt;/item&gt;
      &lt;item&gt;Labels and strings. Code snippets reference installation without a user request or consent.&lt;/item&gt;
      &lt;item&gt;Permissions. App manifests include nonstandard entries consistent with apps asking AppLovin middleware to install other apps.&lt;/item&gt;
      &lt;item&gt;User complaints. 208 distinct complaints describe apps being installed while playing games or viewing ads. A few complaints include relevant screenshots and even video of nonconsensual installations. Complaints, screenshots, and videos match unusual details visible in the code.&lt;/item&gt;
      &lt;item&gt;AppLovin statements. Public statements use euphemistic or contradictory language about user ‚Äúchoice‚Äù and ‚Äúdirect downloads,‚Äù suggesting attempts to obscure nonconsensual installs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I also examine the legal and financial risks associated with nonconsensual installations.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45584226</guid><pubDate>Tue, 14 Oct 2025 20:13:53 +0000</pubDate></item><item><title>Unpacking Cloudflare Workers CPU Performance Benchmarks</title><link>https://blog.cloudflare.com/unpacking-cloudflare-workers-cpu-performance-benchmarks/</link><description>&lt;doc fingerprint="ef3a174958a2cc9b"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;On October 4, independent developer Theo Browne published a series of benchmarks designed to compare server-side JavaScript execution speed between Cloudflare Workers and Vercel, a competing compute platform built on AWS Lambda. The initial results showed Cloudflare Workers performing worse than Node.js on Vercel at a variety of CPU-intensive tasks, by a factor of as much as 3.5x.&lt;/p&gt;
      &lt;p&gt;We were surprised by the results. The benchmarks were designed to compare JavaScript execution speed in a CPU-intensive workload that never waits on external services. But, Cloudflare Workers and Node.js both use the same underlying JavaScript engine: V8, the open source engine from Google Chrome. Hence, one would expect the benchmarks to be executing essentially identical code in each environment. Physical CPUs can vary in performance, but modern server CPUs do not vary by anywhere near 3.5x.&lt;/p&gt;
      &lt;p&gt;On investigation, we discovered a wide range of small problems that contributed to the disparity, ranging from some bad tuning in our infrastructure, to differences between the JavaScript libraries used on each platform, to some issues with the test itself. We spent the week working on many of these problems, which means over the past week Workers got better and faster for all of our customers. We even fixed some problems that affect other compute providers but not us, such as an issue that made trigonometry functions much slower on Vercel. This post will dig into all the gory details. &lt;/p&gt;
      &lt;p&gt;It's important to note that the original benchmark was not representative of billable CPU usage on Cloudflare, nor did the issues involved impact most typical workloads. Most of the disparity was an artifact of the specific benchmark methodology. Read on to understand why.&lt;/p&gt;
      &lt;p&gt;With our fixes, the results now look much more like we'd expect:&lt;/p&gt;
      &lt;p&gt;There is still work to do, but we're happy to say that after these changes, Cloudflare now performs on par with Vercel in every benchmark case except the one based on Next.js. On that benchmark, the gap has closed considerably, and we expect to be able to eliminate it with further improvements detailed later in this post.&lt;/p&gt;
      &lt;p&gt;We are grateful to Theo for highlighting areas where we could make improvements, which will now benefit all our customers, and even many who aren't our customers.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Our benchmark methodology&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;We wanted to run Theo's test with no major design changes, in order to keep numbers comparable. Benchmark cases are nearly identical to Theo's original test but we made a couple changes in how we ran the test, in the hopes of making the results more accurate:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;
          &lt;p&gt;Theo ran the test client on a laptop connected by a Webpass internet connection in San Francisco, against Vercel instances running in its sfo1 region. In order to make our results easier to reproduce, we chose instead to run our test client directly in AWS's us-east-1 datacenter, invoking Vercel instances running in its iad1 region (which we understand to be in the same building). We felt this would minimize any impact from network latency. Because of this, Vercel's numbers are slightly better in our results than they were in Theo's.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;We chose to use Vercel instances with 1 vCPU instead of 2. All of the benchmarks are single-threaded workloads, meaning they cannot take advantage of a second CPU anyway. Vercel's CTO, Malte Ubl, had stated publicly on X that using single-CPU instances would make no difference in this test, and indeed, we found this to be correct. Using 1 vCPU makes it easier to reason about pricing, since both Vercel and Cloudflare charge for CPU time (&lt;code&gt;$&lt;/code&gt;0.128/hr for Vercel in iad1, and &lt;code&gt;$&lt;/code&gt;0.072/hr for Cloudflare globally).&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;We made some changes to fix bugs in the test, for which we submitted a pull request. More on this below.&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Theo's benchmarks covered a variety of frameworks, making it clear that no single JavaScript library could be at fault for the general problem. Clearly, we needed to look first at the Workers Runtime itself. And so we did, and we found two problems √¢ not bugs, but tuning and heuristic choices which interacted poorly with the benchmarks as written.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Sharding and warm isolate routing: A problem of scheduling, not CPU speed&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Over the last year we shipped smarter routing that sends traffic to warm isolates more often. That cuts cold starts for large apps, which matters for frameworks with heavy initialization requirements like Next.js. The original policy optimized for latency and throughput across billions of requests, but was less optimal for heavily CPU-bound workloads for the same reason that such workloads cause performance issues in other platforms like Node.js: When the CPU is busy computing an expensive operation for one request, other requests sent to the same isolate must wait for it to finish before they can proceed.&lt;/p&gt;
      &lt;p&gt;The system uses heuristics to detect when requests are getting blocked behind each other, and automatically spin up more isolates to compensate. However, these heuristics are not precise, and the particular workload generated by Theo's tests √¢ in which a burst of expensive traffic would come from a single client √¢ played poorly with our existing algorithm. As a result, the benchmarks showed much higher latency (and variability in latency) than would normally be expected.&lt;/p&gt;
      &lt;p&gt;It's important to understand that, as a result of this problem, the benchmark was not really measuring CPU time. Pricing on the Workers platform is based on CPU time √¢ that is, time spent actually executing JavaScript code, as opposed to time waiting for things. Time spent waiting for the isolate to become available makes the request take longer, but is not billed as CPU time against the waiting request. So, this problem would not have affected your bill.&lt;/p&gt;
      &lt;p&gt;After analyzing the benchmarks, we updated the algorithm to detect sustained CPU-heavy work earlier, then bias traffic so that new isolates spin up faster. The result is that Workers can more effectively and efficiently autoscale when different workloads are applied. I/O-bound workloads coalesce into individual already warm isolates while CPU-bound are directed so that they do not block each other. This change has already been rolled out globally and is enabled automatically for everyone. It should be pretty clear from the graph when the change was rolled out:&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;V8 garbage collector tuning&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;While this scheduling issue accounted for the majority of the disparity in the benchmark, we did find a minor issue affecting code execution performance during our testing.&lt;/p&gt;
      &lt;p&gt;The range of issues that we uncovered in the framework code in these benchmarks repeatedly pointed at garbage collection and memory management issues as being key contributors to the results. But, we would expect these to be an issue with the same frameworks running in Node.js as well. To see exactly what was going on differently with Workers and why it was causing such a significant degradation in performance, we had to look inwards at our own memory management configuration.&lt;/p&gt;
      &lt;p&gt;The V8 garbage collector has a huge number of knobs that can be tuned that directly impact performance. One of these is the size of the "young generation". This is where newly created objects go initially. It's a memory area that's less compact, but optimized for short-lived objects. When objects have bounced around the "young space" for a few generations they get moved to the old space, which is more compact, but requires more CPU to reclaim.&lt;/p&gt;
      &lt;p&gt;V8 allows the embedding runtime to tune the size of the young generation. And it turns out, we had done so. Way back in June of 2017, just two months after the Workers project kicked off, we √¢ or specifically, I, Kenton, as I was the only engineer on the project at the time √¢ had configured this value according to V8's recommendations at the time for environments with 512MB of memory or less. Since Workers defaults to a limit of 128MB per isolate, this seemed appropriate.&lt;/p&gt;
      &lt;p&gt;V8's entire garbage collector has changed dramatically since 2017. When analyzing the benchmarks, it became apparent that the setting which made sense in 2017 no longer made sense in 2025, and we were now limiting V8's young space too rigidly. Our configuration was causing V8's garbage collection to work harder and more frequently than it otherwise needed to. As a result, we have backed off on the manual tuning and now allow V8 to pick its young space size more freely, based on its internal heuristics. This is already live on Cloudflare Workers, and it has given an approximately 25% boost to the benchmarks with only a small increase in memory usage. Of course, the benchmarks are not the only Workers that benefit: all Workers should now be faster. That said, for most Workers the difference has been much smaller.&lt;/p&gt;
      &lt;p&gt;The platform changes solved most of the problem. Following the changes, our testing showed we were now even on all of the benchmarks save one: Next.js.&lt;/p&gt;
      &lt;p&gt;Next.js is a popular web application framework which, historically, has not had built-in support for hosting on a wide range of platforms. Recently, a project called OpenNext has arisen to fill the gap, making Next.js work well on many platforms, including Cloudflare. On investigation, we found several missing optimizations and other opportunities to improve performance, explaining much of why the benchmark performed poorly on Workers.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Unnecessary allocations and copies&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;When profiling the benchmark code, we noticed that garbage collection was dominating the timeline. From 10-25% of the request processing time was being spent reclaiming memory.&lt;/p&gt;
      &lt;p&gt;So we dug in and discovered that OpenNext, and in some cases Next.js and React itself, will often create unnecessary copies of internal data buffers at some of the worst times during the handling of the process. For instance, there's one &lt;code&gt;pipeThrough()&lt;/code&gt; operation in the rendering pipeline that we saw creating no less than 50 2048-byte &lt;code&gt;Buffer&lt;/code&gt; instances, whether they are actually used or not.&lt;/p&gt;
      &lt;p&gt;We further discovered that on every request, the Cloudflare OpenNext adapter has been needlessly copying every chunk of streamed output data as it√¢s passed out of the renderer and into the Workers runtime to return to users. Given this benchmark returns a 5 MB result on every request, that's a lot of data being copied!&lt;/p&gt;
      &lt;p&gt;In other places, we found that arrays of internal Buffer instances were being copied and concatenated using &lt;code&gt;Buffer.concat&lt;/code&gt; for no other reason than to get the total number of bytes in the collection. That is, we spotted code of the form &lt;code&gt;getBody().length&lt;/code&gt;. The function &lt;code&gt;getBody()&lt;/code&gt; would concatenate a large number of buffers into a single buffer and return it, without storing the buffer anywhere. So, all that work was being done just to read the overall length. Obviously this was not intended, and fixing it was an easy win.&lt;/p&gt;
      &lt;p&gt;We've started opening a series of pull requests in OpenNext to fix these issues, and others in hot paths, removing some unnecessary allocations and copies:&lt;/p&gt;
      &lt;p&gt;We're not done. We intend to keep iterating through OpenNext code, making improvements wherever they√¢re needed √¢ not only in the parts that run on Workers. Many of these improvements apply to other OpenNext platforms. The shared goal of OpenNext is to make NextJS as fast as possible regardless of where you choose to run your code.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;Inefficient Streams Adapters&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Much of the Next.js code was written to use Node.js's APIs for byte streams. Workers, however, prefers the web-standard Streams API, and uses it to represent HTTP request and response bodies. This necessitates using adapters to convert between the two APIs. When investigating the performance bottlenecks, we found a number of examples where inefficient streams adapters are being needlessly applied. For example:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;const stream = Readable.toWeb(Readable.from(res.getBody()))&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;&lt;code&gt;res.getBody()&lt;/code&gt; was performing a &lt;code&gt;Buffer.concat(chunks)&lt;/code&gt; to copy accumulated chunks of data into a new Buffer, which was then passed as an iterable into a Node.js &lt;code&gt;stream.Readable&lt;/code&gt; that was then wrapped by an adapter that returns a &lt;code&gt;ReadableStream&lt;/code&gt;. While these utilities do serve a useful purpose, this becomes a data buffering nightmare since both Node.js streams and Web streams each apply their own internal buffers! Instead we can simply do:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;const stream = ReadableStream.from(chunks);&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;This returns a &lt;code&gt;ReadableStream&lt;/code&gt; directly from the accumulated chunks without additional copies, extraneous buffering, or passing everything through inefficient adaptation layers.&lt;/p&gt;
      &lt;p&gt;In other places we see that Next.js and React make extensive use of &lt;code&gt;ReadableStream&lt;/code&gt; to pass bytes through, but the streams being created are value-oriented rather than byte-oriented! For example,&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;const readable = new ReadableStream({
  pull(controller) {
    controller.enqueue(chunks.shift());
    if (chunks.length === 0) {
      controller.close();
    }
});  // Default highWaterMark is 1!
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;Seems perfectly reasonable. However, there's an issue here. If the chunks are &lt;code&gt;Buffer&lt;/code&gt; or &lt;code&gt;Uint8Array&lt;/code&gt; instances, every instance ends up being a separate read by default. So if the &lt;code&gt;chunk&lt;/code&gt; is only a single byte, or 1000 bytes, that's still always two reads. By converting this to a byte stream with a reasonable high water mark, we can make it possible to read this stream much more efficiently:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;const readable = new ReadableStream({
  type: 'bytes',
  pull(controller) {
    controller.enqueue(chunks.shift());
    if (chunks.length === 0) {
      controller.close();
    }
}, { highWaterMark: 4096 });
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;Now, the stream can be read as a stream of bytes rather than a stream of distinct JavaScript values, and the individual chunks can be coalesced internally into 4096 byte chunks, making it possible to optimize the reads much more efficiently. Rather than reading each individual enqueued chunk one at a time, the ReadableStream will proactively call &lt;code&gt;pull()&lt;/code&gt; repeatedly until the highWaterMark is reached. Reads then do not have to ask the stream for one chunk of data at a time.&lt;/p&gt;
      &lt;p&gt;While it would be best for the rendering pipeline to be using byte streams and paying attention to back pressure signals more, our implementation can still be tuned to better handle cases like this.&lt;/p&gt;
      &lt;p&gt;The bottom line? We've got some work to do! There are a number of improvements to make in the implementation of OpenNext and the adapters that allow it to work on Cloudflare that we will continue to investigate and iterate on. We've made a handful of these fixes already and we're already seeing improvements. Soon we also plan to start submitting patches to Next.js and React to make further improvements upstream that will ideally benefit the entire ecosystem.&lt;/p&gt;
      &lt;p&gt;Aside from buffer allocations and streams, one additional item stood out like a sore thumb in the profiles: &lt;code&gt;JSON.parse()&lt;/code&gt; with a reviver function. This is used in both React and Next.js and in our profiling this was significantly slower than it should be. We built a microbenchmark and found that JSON.parse with a reviver argument recently got even slower when the standard added a third argument to the reviver callback to provide access to the JSON source context.&lt;/p&gt;
      &lt;p&gt;For those unfamiliar with the reviver function, it allows an application to effectively customize how JSON is parsed. But it has drawbacks. The function gets called on every key-value pair included in the JSON structure, including every individual element of an Array that gets serialized. In Theo's NextJS benchmark, in any single request, it ends up being called well over 100,000 times!&lt;/p&gt;
      &lt;p&gt;Even though this problem affects all platforms, not just ours, we decided that we weren't just going to accept it. After all, we have contributors to V8 on the Workers runtime team! We've upstreamed a V8 patch that can speed up &lt;code&gt;JSON.parse()&lt;/code&gt; with revivers by roughly 33 percent. That should be in V8 starting with version 14.3 (Chrome 143) and can help everyone using V8, not just Cloudflare: Node.js, Chrome, Deno, the entire ecosystem.√Ç¬† If you are not using Cloudflare Workers or didn't change the syntax of your reviver you are currently suffering under the red performance bar.&lt;/p&gt;
      &lt;p&gt;We will continue to work with framework authors to reduce overhead in hot paths. Some changes belong in the frameworks, some belong in the engine, some in our platform.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;Node.js's trigonometry problem&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;We are engineers, and we like to solve engineering problems √¢ whether our own, or for the broader community.&lt;/p&gt;
      &lt;p&gt;Theo's benchmarks were actually posted in response to a different benchmark by another author which compared Cloudflare Workers against Vercel. The original benchmark focused on calling trigonometry functions (e.g. sine and cosine) in a tight loop. In this benchmark, Cloudflare Workers performed 3x faster than Node.js running on Vercel.&lt;/p&gt;
      &lt;p&gt;The author of the original benchmark offered this as evidence that Cloudflare Workers are just faster. Theo disagreed, and so did we. We expect to be faster, but not by 3x! We don't implement math functions ourselves; these come with V8. We weren't happy to just accept the win, so we dug in.&lt;/p&gt;
      &lt;p&gt;It turns out that Node.js is not using the latest, fastest path for these functions. Node.js can be built with either the clang or gcc compilers, and is written to support a broader range of operating systems and architectures than Workers. This means that Node.js' compilation often ends up using a lowest-common denominator for some things in order to provide support for the broadest range of platforms. V8 includes a compile-time flag that, in some configurations, allows it to use a faster implementation of the trig functions. In Workers, mostly by coincidence, that flag is enabled by default. In Node.js, it is not. We've opened a pull request to enable the flag in Node.js so that everyone benefits, at least on platforms where it can be supported.&lt;/p&gt;
      &lt;p&gt;Assuming that lands, and once AWS Lambda and Vercel are able to pick it up, we expect this specific gap to go away, making these operations faster for everyone. This change won't benefit our customers, since Cloudflare Workers already uses the faster trig functions, but a bug is a bug and we like making everything faster.&lt;/p&gt;
      &lt;p&gt;Even the best benchmarks have bias and tradeoffs. It's difficult to create a benchmark that is truly representative of real-world performance, and all too easy to misinterpret the results of benchmarks that are not. We particularly liked Planetscale's take on this subject.&lt;/p&gt;
      &lt;p&gt;These specific CPU-bound tests are not an ideal choice to represent web applications. Theo even notes this in his video. Most real-world applications on Workers and Vercel are bound by databases, downstream services, network, and page size. End user experience is what matters. CPU is one piece of that picture. That said, if a benchmark shows us slower, we take it seriously.&lt;/p&gt;
      &lt;p&gt;While the benchmarks helped us find and fix many real problems, we also found a few problems with the benchmarks themselves, which contributed to the apparent disparity in speed:&lt;/p&gt;
      &lt;p&gt;The benchmark is designed to be run on your laptop, from which it hits Cloudflare's and Vercel's servers over the Internet. It makes the assumption that latency observed from the client is a close enough approximation of server-side CPU time. The reasons are fair: As Theo notes, Cloudflare does not permit an application to measure its own CPU time, in order to prevent timing side channel attacks. Actual CPU time can be seen in logs after the fact, but gathering those may be a lot of work. It's just easier to measure time from the client.&lt;/p&gt;
      &lt;p&gt;However, as Cloudflare and Vercel are hosted from different data centers, the network latency to each can be a factor in the benchmark, and this can skew the results. Typically, this effect will favor Cloudflare, because Cloudflare can run your Worker in locations spread across 330+ cities worldwide, and will tend to choose the closest one to you. Vercel, on the other hand, usually places compute in a central location, so latency will vary depending on your distance from that location.&lt;/p&gt;
      &lt;p&gt;For our own testing, to minimize this effect, we ran the benchmark client from a VM on AWS located in the same data center as our Vercel instances. Since Cloudflare is well-connected to every AWS location, we think this should have eliminated network latency from the picture. We chose AWS's us-east-1 / Vercel's iad1 for our test as it is widely seen as the default choice; any other choice could draw questions about cherry-picking.&lt;/p&gt;
      &lt;p&gt;Cloudflare's servers aren't all identical. Although we refresh them aggressively, there will always be multiple generations of hardware in production at any particular time. Currently, this includes generations 10, 11, and 12 of our server hardware.&lt;/p&gt;
      &lt;p&gt;Other cloud providers are no different. No cloud provider simply throws away all their old servers every time a new version becomes available.&lt;/p&gt;
      &lt;p&gt;Of course, newer CPUs run faster, even for single-threaded workloads. The differences are not as large as they used to be 20-30 years ago, but they are not nothing. As such, an application may get (a little bit) lucky or unlucky depending on what machine it is assigned to.&lt;/p&gt;
      &lt;p&gt;In cloud environments, even identical CPUs can yield different performance depending on circumstances, due to multitenancy. The server your application is assigned to is running many others as well. In AWS Lambda, a server may be running hundreds of applications; in Cloudflare, with our ultra-efficient runtime, a server may be running thousands. These "noisy neighbors" won't share the same CPU core as your app, but they may share other resources, such as memory bandwidth. As a result, performance can vary.&lt;/p&gt;
      &lt;p&gt;It's important to note that these problems create correlated noise. That is, if you run the test again, the application is likely to remain assigned to the same machines as before √¢ this is true of both Cloudflare and Vercel. So, this noise cannot be corrected by simply running more iterations. To correct for this type of noise on Cloudflare, one would need to initiate requests from a variety of geographic locations, in order to hit different Cloudflare data centers and therefore different machines. But, that is admittedly a lot of work. (We are not familiar with how best to get an application to switch machines on Vercel.)&lt;/p&gt;
      &lt;p&gt;The Cloudflare version of the NextJS benchmark was not configured to use force-dynamic while the Vercel version was. This triggered curious behavior. Our understanding is that pages which are not "dynamic" should normally be rendered statically at build time. With OpenNext, however, it appears the pages are still rendered dynamically, but if multiple requests for the same page are received at the same time, OpenNext will only invoke the rendering once. Before we made the changes to fix our scheduling algorithm to avoid sending too many requests to the same isolate, this behavior may have somewhat counteracted that problem. Theo reports that he had disabled force-dynamic in the Cloudflare version specifically for this reason: with it on, our results were so bad as to appear outright broken, so he intentionally turned it off.&lt;/p&gt;
      &lt;p&gt;Ironically, though, once we fixed the scheduling issue, using "static" rendering (i.e. not enabling force-dynamic) hurt Cloudflare's performance for other reasons. It seems that when OpenNext renders a "cacheable" page, streaming of the response body is inhibited. This interacted poorly with a property of the benchmark client: it measured time-to-first-byte (TTFB), rather than total request/response time. When running in dynamic mode √¢ as the test did on Vercel √¢ the first byte would be returned to the client before the full page had been rendered. The rest of the rendering would happen as bytes streamed out. But with OpenNext in non-dynamic mode, the entire payload was rendered into a giant buffer upfront, before any bytes were returned to the client.&lt;/p&gt;
      &lt;p&gt;Due to the TTFB behavior of the benchmark client, in dynamic mode, the benchmark actually does not measure the time needed to fully render the page. We became suspicious when we noticed that Vercel's observability tools indicated more CPU time had been spent than the benchmark itself had reported.&lt;/p&gt;
      &lt;p&gt;One option would have been to change the benchmarks to use TTLB instead √¢ that is, wait until the last byte is received before stopping the timer. However, this would make the benchmark even more affected by network differences: The responses are quite large, ranging from 2MB to 15MB, and so the results could vary depending on the bandwidth to the provider. Indeed, this would tend to favor Cloudflare, but as the point of the test is to measure CPU speed, not bandwidth, it would be an unfair advantage.&lt;/p&gt;
      &lt;p&gt;Once we changed the Cloudflare version of the test to use force-dynamic as well, matching the Vercel version, the streaming behavior then matched, making the request fair. This means that neither version is actually measuring the cost of rendering the full page to HTML, but at least they are now measuring the same thing.&lt;/p&gt;
      &lt;p&gt;As a side note, the original behavior allowed us to spot that OpenNext has a couple of performance bottlenecks in its implementation of the composable cache it uses to deduplicate rendering requests. While fixes to these aren't going to impact the numbers for this particular set of benchmarks, we're working on improving those pieces also.&lt;/p&gt;
      &lt;p&gt;The React SSR benchmark contained a more basic configuration error. React inspects the environment variable &lt;code&gt;NODE_ENV&lt;/code&gt; to decide whether the environment is "production" or a development environment. Many Node.js-based environments, including Vercel, set this variable automatically in production. Many frameworks, such as OpenNext, automatically set this variable for Workers in production as well. However, the React SSR benchmark was written against lower-level React APIs, not using any framework. In this case, the &lt;code&gt;NODE_ENV&lt;/code&gt; variable wasn't being set at all.&lt;/p&gt;
      &lt;p&gt;And, unfortunately, when &lt;code&gt;NODE_ENV&lt;/code&gt; is not set, React defaults to "dev mode", a mode that contains extra debugging checks and is therefore much slower than production mode. As a result, the numbers for Workers were much worse than they should have been.&lt;/p&gt;
      &lt;p&gt;Arguably, it may make sense for Workers to set this variable automatically for all deployed workers, particularly when Node.js compatibility is enabled. We are looking into doing this in the future, but for now we've updated the test to set it directly.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;What we√¢re going to do next&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Our improvements to the Workers Runtime are already live for all workers, so you do not need to change anything. Many apps will already see faster, steadier tail latency on compute heavy routes with less jitter during bursts. In places where garbage collection improved, some workloads will also use fewer billed CPU seconds.&lt;/p&gt;
      &lt;p&gt;We also sent Theo a pull request to update OpenNext with our improvements there, and with other test fixes.&lt;/p&gt;
      &lt;p&gt;But we're far from done. We still have work to do to close the gap between OpenNext and Next.js on Vercel √¢ but given the other benchmark results, it's clear we can get there. We also have plans for further improvements to our scheduling algorithm, so that requests almost never block each other. We will continue to improve V8, and even Node.js √¢ the Workers team employs multiple core contributors to each project. Our approach is simple: improve open source infrastructure so that everyone gets faster, then make sure our platform makes the most of those improvements.&lt;/p&gt;
      &lt;p&gt;And, obviously, we'll be writing more benchmarks, to make sure we're catching these kinds of issues ourselves in the future. If you have a benchmark that shows Workers being slower, send it to us with a repro. We will profile it, fix what we can upstream, and share back what we learn!&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45584281</guid><pubDate>Tue, 14 Oct 2025 20:17:44 +0000</pubDate></item><item><title>Surveillance data challenges what we thought we knew about location tracking</title><link>https://www.lighthousereports.com/investigation/surveillance-secrets/</link><description>&lt;doc fingerprint="ee9cf1138ab191e5"&gt;
  &lt;main&gt;
    &lt;head rend="h6"&gt;October 14, 2025&lt;/head&gt;
    &lt;head rend="h4"&gt;Trove of surveillance data challenges what we thought we knew about location tracking tools, who they target and how far they have spread&lt;/head&gt;
    &lt;p&gt;In June, a sharp-suited Austrian executive of one of the world‚Äôs most significant yet little-known surveillance companies told a prospective client that he could ‚Äúgo to prison‚Äù for organising the deal they were discussing. But the conversation did not end there.&lt;/p&gt;
    &lt;p&gt;The executive, G√ºnther Rudolph, was seated at a booth at ISS World in Prague, a secretive trade fair for advanced surveillance technology companies. He went on to explain how his firm, First Wap, could provide sophisticated phone-tracking software called Altamides, capable of pinpointing any person in the world. The buyer? A private mining company, owned by an individual under sanction, who intended to use it to surveil environmental protestors. ‚ÄúI think we‚Äôre the only ones who can deliver,‚Äù Rudolph said.&lt;/p&gt;
    &lt;p&gt;What Rudolph did not know: he was talking to an undercover reporter from Lighthouse.&lt;/p&gt;
    &lt;p&gt;The road to that conference room in Prague began with a vast archive of data, found by a Lighthouse reporter on the deep web, containing more than a million tracking operations: efforts to grab real-time locations of thousands of people worldwide. Investigating that archive ‚Äî and First Wap‚Äôs activities ‚Äî drew together more than 70 journalists from 14 media outlets.&lt;/p&gt;
    &lt;p&gt;What emerged is one of the most complete pictures to date of the modern surveillance industry. The tracking archive is unprecedented in scope, and reveals how the company and its clients surveilled all types of people from all over the world. Reporters interviewed more than a hundred victims, as well as former employees and industry insiders. A trove of confidential emails and documents provide a detailed inside account of how First Wap‚Äôs tech was marketed to authoritarian governments and accessed by corporate actors. Behind closed doors, First Wap‚Äôs executives touted their ability to hack WhatsApp accounts, and laughed about evading sanctions.&lt;/p&gt;
    &lt;p&gt;The surveillance industry has long maintained that its tools are deployed exclusively by government agencies to fight serious crime, portraying instances of misuse as rare exceptions. This investigation definitively dismantles that narrative.&lt;/p&gt;
    &lt;head rend="h2"&gt;Making sense of a secret data trove&lt;/head&gt;
    &lt;p&gt;This investigation began with an archive of data. This is not the first archive related to a surveillance company‚Äôs activities, but it is certainly the most granular. It contains 1.5 million records, more than 14,000 unique phone numbers, and people surveilled in over 160 countries. It represents an extraordinarily detailed account of when and where people were tracked, and what users of the tracking tool saw.&lt;/p&gt;
    &lt;p&gt;The only clue to a target‚Äôs identity was a phone number. A team of reporters at Lighthouse and paper trail media spent months painstakingly identifying the owners of those phone numbers. To drill down into the data and better understand it, we divided it into ‚Äúclusters‚Äù of targets ‚Äî networks of people connected in time or space. As we investigated clusters and put names to phone numbers, stories began to emerge.&lt;/p&gt;
    &lt;p&gt;For a more in-depth explanation of how we analysed the dataset, see our technical explainer.&lt;/p&gt;
    &lt;p&gt;The Altamides archive is global in scope. We found high-profile individuals, including powerful political figures such as the former Prime Minister of Qatar and the wife of ousted Syrian dictator Bashar al-Assad. We found Netflix producer Adam Ciralsky, Blackwater founder Erik Prince, Nobel Peace Prize nominee Benny Wenda, Austropop star Wolfgang Ambros, Tel Aviv district prosecutor Liat Ben Ari and Ali Nur Yasin, a senior editor at our Indonesian partner Tempo.&lt;/p&gt;
    &lt;p&gt;In Italy, investigative journalist Gianluigi Nuzzi was tracked days after publishing a dramatic expos√© of corruption in the Vatican, as police closed in on his source. In California, Anne Wojcicki, founder of DNA startup 23andMe and then married to Google‚Äôs Sergey Brin, was tracked more than a thousand times as she moved across Silicon Valley. And in South Africa, associates of Rwandan opposition leader Patrick Karegeya were tracked before his assassination in a Johannesburg hotel room.&lt;/p&gt;
    &lt;p&gt;As our reporting partners dug into the archive, they found other traces of surveillance activity on their doorsteps. In Austria, home of First Wap‚Äôs founder Josef Fuchs, Der Standard uncovered a mystery surrounding a tracking spate of high-ranking employees at energy drink giant Red Bull. In Norway, NRK examined how Altamides zeroed in on a top telecom executive. In Indonesia, interviewees told our partner Tempo that they believed they had been targeted because they had taken part in political activities or spoken out against the government. In Serbia, KRIK identified targets in the energy industry, while in Israel, Haaretz located high profile lawyers and businessmen with interests in Africa and the Gulf.&lt;/p&gt;
    &lt;p&gt;First Wap said in a response to this investigation that it denies ‚Äúany illegal activities‚Äù or ‚Äúhuman rights violations.‚Äù The company said it could not comment on specific allegations that could ‚Äúenable client identification.‚Äù It further elaborated that the company does not perform any tracking itself and that ‚Äúafter installation‚Äù of Altamides it has no further knowledge of how the product is used. First Wap emphasized that its technology is used by law enforcement to ‚Äúfight against organized crime, terrorism and corruption.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;Surveillance without borders&lt;/head&gt;
    &lt;p&gt;In 2012, Sophia (not her real name) was walking near the coast of Goa on vacation, unaware that her movements were being monitored from halfway around the world with government-grade surveillance tech. But she was not being tracked by an intelligence or law enforcement agency. She was being stalked by a man who had been pursuing her, following her over the course of ten months.&lt;/p&gt;
    &lt;p&gt;Sophia‚Äôs case illustrates how Altamides proliferated far beyond the hands of governments to non-government actors, who used it to surveil victims for commercial and personal purposes. In addition to business leaders and politically-exposed individuals, the Altamides archive contains hundreds of regular people: a teacher, a therapist, a tattoo artist.&lt;/p&gt;
    &lt;p&gt;First Wap‚Äôs surveillance software was marketed through a shadowy network of middlemen who resold the system to clients worldwide. Confidential documents obtained by this investigation detail the operations of one such company, the British corporate investigations firm KCS Group. As the Arab Spring unfolded across the Middle East and North Africa, documents show that KCS attempted to capitalise on the unrest throughout the region, making concerted efforts to sell the tracking system to governments in Morocco and Algeria, as well as other countries in Africa and Asia. But at the same time it was using Altamides for corporate investigation work, digging for dirt on clients‚Äô opponents. The company told us that it ‚Äúhas not been involved in selling or using inappropriate surveillance materials‚Äù and is ‚Äúcommitted to maintaining ethical standards in all our operations.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;A ruthless pioneer&lt;/head&gt;
    &lt;p&gt;Unlike other industry heavyweights, which have seen years of adverse coverage because their customers targeted journalists, activists, businesspeople and diplomats, First Wap has thrived for two decades without falling under the spotlight. The story of Altamides dates back to the early 2000s, when former Siemens engineer Josef Fuchs recognised a critical vulnerability in the global telecom network. By exploiting an outdated ‚Äì but still essential ‚Äì communication protocol known as SS7, he could trick phone networks into revealing the locations of their users. Seeing a new business opportunity, Fuchs quickly pivoted his Jakarta-based company away from its focus on marketing messages, turning it into one of the world‚Äôs first phone-tracking firms. Its arrival on the market was seismic. At a time when Blackberrys ruled and Nokias were everywhere, a user could enter a phone number and the software would pinpoint its location anywhere in the world, within seconds.&lt;/p&gt;
    &lt;p&gt;Since then, the company has quietly built a globe-spanning phone tracking empire, operating in the shadows, without any apparent red lines. It has also expanded its surveillance arsenal, adding features to Altamides that allow it to intercept SMS messages, listen in on phone calls, and even breach encrypted messaging apps like WhatsApp.&lt;/p&gt;
    &lt;head rend="h2"&gt;‚ÄúWe can find a way‚Äù&lt;/head&gt;
    &lt;p&gt;Our initial reporting surfaced dozens of non-criminal people surveilled without their knowledge by the company. Data, sources we spoke to and documents we examined indicated that Altamides had been used by authoritarian governments and, without lawful basis, by non-governmental clients. We decided it would be in the public interest to carry out an undercover operation to better understand what red lines the company placed around use of its products.&lt;/p&gt;
    &lt;p&gt;In a statement, First Wap insisted to us that it ‚Äúvets and verifies any government client/final user for sanctions compliance prior to the signature of any agreement‚Äù and that ‚Äúthere has never been any exception to this.‚Äù&lt;/p&gt;
    &lt;p&gt;Testing the red lines required a fake character, complete with a fake company name and LinkedIn. One of Lighthouse‚Äôs reporters became Albert, a South Africa-based businessman who runs a boutique ‚Äúresearch consultancy‚Äù registered in the British Virgin Islands. Accompanying him was Abdou, a colleague, who would be playing a mover and shaker with political connections throughout West Africa. They signed up for ISS World in the Czech Republic, the largest annual surveillance technology fair, to pitch some projects and see how the company responded.&lt;/p&gt;
    &lt;p&gt;So this June, our reporter found himself in a Prague hotel room, straightening a suit jacket outfitted with a hidden camera.&lt;/p&gt;
    &lt;p&gt;Albert and Abdou met First Wap‚Äôs sales director G√ºnther Rudolph at the company‚Äôs booth, to discuss a series of business propositions. Could First Wap help a government monitor opponents abroad? Could the company crack encrypted WhatsApp chats? Could it help the owner of a mining company disrupt protests by environmental activists? ‚ÄúHe knows already who are the leaders, or he wants to find out?‚Äù asked Rudolph.&lt;/p&gt;
    &lt;p&gt;Rudolph drew the undercover reporters‚Äô attention to a potential snag: some of the people they propose selling to might be under sanction from the EU or US, meaning that European nationals like First Wap‚Äôs executives risked imprisonment if it were known they organised the sale. ‚ÄúThat‚Äôs why when we make such a deal we make it through Jakarta,‚Äù Rudolph said, referring to First Wap‚Äôs corporate base in Indonesia. It was a ‚Äúgrey area‚Äù, he said. But ‚Äúwe can find a way‚Äù. What this way might look like became clear the following day: using a newly invented shell company to mask the connection in the papertrail between First Wap and the sanctioned client.&lt;/p&gt;
    &lt;p&gt;When confronted with our undercover operation in Prague, the company said that ‚Äúmisunderstandings evidently arose‚Äù and that the statements by its executives referred merely to technical feasibility.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45584498</guid><pubDate>Tue, 14 Oct 2025 20:36:01 +0000</pubDate></item><item><title>GrapheneOS is ready to break free from Pixels</title><link>https://www.androidauthority.com/graphene-os-major-android-oem-partnership-3606853/</link><description>&lt;doc fingerprint="3f5aed55809c7b28"&gt;
  &lt;main&gt;
    &lt;p&gt;Affiliate links on Android Authority may earn us a commission. Learn more.&lt;/p&gt;
    &lt;head rend="h1"&gt;GrapheneOS is finally ready to break free from Pixels, and it may never look back&lt;/head&gt;
    &lt;p&gt;23 hours ago&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The makers of GrapheneOS have confirmed they are partnering with a major Android OEM to bring the privacy-focused Android fork to Snapdragon-powered smartphones.&lt;/item&gt;
      &lt;item&gt;The project has confirmed it‚Äôs bringing support for Pixel 10, but is unsure whether support will continue for Pixel 11.&lt;/item&gt;
      &lt;item&gt;GrapheneOS didn‚Äôt reveal the name of its new partner, but said that those devices will be priced in the same range as Pixels.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;GrapheneOS, the popular privacy-focused Android fork known for its exclusive support of Google Pixel phones, is about to cast a much wider net. The project has confirmed it‚Äôs working with a major Android smartphone manufacturer to bring its secure operating system to future flagship phones, as first spotted by PiunikaWeb.&lt;/p&gt;
    &lt;p&gt;Don‚Äôt want to miss the best from Android Authority?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Set us as a favorite source in Google Discover to never miss our latest exclusive reports, expert analysis, and much more.&lt;/item&gt;
      &lt;item&gt;You can also set us as a preferred source in Google Search by clicking the button below.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Until now, GrapheneOS has been available only on Pixel phones, making Google‚Äôs flagships popular among privacy enthusiasts, journalists, and, as a Spanish police report suggested earlier this year, even organized crime groups in Catalonia. But that Pixel exclusivity may end by 2026 or 2027.&lt;/p&gt;
    &lt;p&gt;GrapheneOS revealed in a Reddit thread that it has been working with a ‚Äúmajor Android OEM‚Äù since June 2025 to enable official support for ‚Äúfuture versions of their existing models.‚Äù These devices will reportedly use flagship Snapdragon chips, a notable shift from Google‚Äôs in-house Tensor processors.&lt;/p&gt;
    &lt;p&gt;The project explained that only Pixels have met its strict security and update requirements so far. However, the new partnership suggests that another OEM is finally matching those standards. GrapheneOS also hinted that the mysterious partner‚Äôs devices will be ‚Äúpriced similarly to Pixels‚Äù and available globally as part of the brand‚Äôs standard lineup.&lt;/p&gt;
    &lt;p&gt;Sadly, GrapheneOS didn‚Äôt reveal the name of its new partner. However, folks are speculating it could be Nothing, given it‚Äôs one of the few OEMs that allow bootloader unlocking, which is a prerequisite for installing GrapheneOS. That said, Nothing doesn‚Äôt really qualify as a ‚Äúmajor Android OEM‚Äù right now.&lt;/p&gt;
    &lt;p&gt;The announcement comes after the project publicly criticized Google‚Äôs extended security patch timelines. The platform argued that Google leaves vulnerabilities exposed for months. Working with a brand that grants earlier patch access could allow GrapheneOS to maintain its high security standards independent of Google.&lt;/p&gt;
    &lt;p&gt;For Pixel owners, nothing changes, at least for now. The OS will continue to support existing devices until their end-of-life. GrapheneOS support is also coming for Pixel 10, but the project is still considering whether or not to add support for Pixel 11.&lt;/p&gt;
    &lt;p&gt;Thank you for being part of our community. Read our Comment Policy before posting.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45585869</guid><pubDate>Tue, 14 Oct 2025 22:36:40 +0000</pubDate></item><item><title>Interior cancels largest solar project in North America</title><link>https://www.politico.com/news/2025/10/10/trump-interior-department-cancels-largest-solar-project-in-north-america-00602071</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45586282</guid><pubDate>Tue, 14 Oct 2025 23:36:26 +0000</pubDate></item><item><title>FSF announces Librephone project</title><link>https://www.fsf.org/news/librephone-project</link><description>&lt;doc fingerprint="e30f1910ee07a1b4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;FSF announces Librephone project&lt;/head&gt;
    &lt;p&gt;Librephone is a new initiative by the FSF with the goal of bringing full freedom to the mobile computing environment. The vast majority of software users around the world use a mobile phone as their primary computing device. After forty years of advocacy for computing freedom, the FSF will now work to bring the right to study, change, share, and modify the programs users depend on in their daily lives to mobile phones.&lt;/p&gt;
    &lt;p&gt;"Forty years ago, when the FSF was founded, our focus was on providing an operating system people could use on desktop and server computers in freedom. Times have changed, technology has progressed, but our commitment to freedom hasn't," said Zo√´ Kooyman, executive director of the FSF. "A lot of work has been done in mobile phone freedom over the years that we'll be building on. The FSF is now ready to do what is necessary to bring freedom to cell phone users. Given the complexity of the devices, this work will take time, but we're used to playing the long game."&lt;/p&gt;
    &lt;p&gt;Practically, Librephone aims to close the last gaps between existing distributions of the Android operating system and software freedom. The FSF has hired experienced developer Rob Savoye (DejaGNU, Gnash, OpenStreetMap, and more) to lead the technical project. He is currently investigating the state of device firmware and binary blobs in other mobile phone freedom projects, prioritizing the free software work done by the not entirely free software mobile phone operating system LineageOS.&lt;/p&gt;
    &lt;p&gt;The initial work is funded by a donation from FSF board member John Gilmore, who explained, "I have enjoyed using a mobile phone running LineageOS with MicroG and F-Droid for years, which eliminates the spyware and control that Google embeds in standard Android phones. I later discovered that the LineageOS distribution links in significant proprietary binary modules copied from the firmware of particular phones. Rather than accept this sad situation, I looked for collaborators to reverse-engineer and replace those proprietary modules with fully free software, for at least one modern phone."&lt;/p&gt;
    &lt;p&gt;Triaging existing packages and device compatibility to find a phone with the fewest, most fixable freedom problems is the first step. From there, the FSF and Savoye aim to reverse-engineer and replace the remaining nonfree software. Librephone will serve existing developers and projects who aim to build a fully functioning and free (as in freedom) Android-compatible OS.&lt;/p&gt;
    &lt;p&gt;The FSF has been supporting earlier free software mobile phone projects such as Replicant, and is excited to launch this new effort. Gilmore added: "We were lucky to find Rob Savoye, a great engineer with decades of experience in free software, embedded systems, and project management."&lt;/p&gt;
    &lt;p&gt;When asked to comment on the project, Savoye said: "As a long-time embedded systems engineer who has worked on mobile devices for decades, I'm looking forward to this opportunity to work towards a freedom-supporting phone and help users gain control over their phone hardware."&lt;/p&gt;
    &lt;p&gt;He added: "Making fully free software for a modern commercial phone will not be quick, easy, or cheap, but our project benefits from standing on the shoulders of giants who have done most of the work. Please join us, with your efforts and/or with your donations."&lt;/p&gt;
    &lt;p&gt;Besides the campaign information at https://fsf.org/campaigns/librephone, the project will have its own website at https://librephone.fsf.org and anyone can connect using #librephone irc on irc.libera.chat.&lt;/p&gt;
    &lt;head rend="h4"&gt;About the Free Software Foundation&lt;/head&gt;
    &lt;p&gt;The FSF, founded in 1985, is dedicated to promoting computer users' right to use, study, copy, modify, and redistribute computer programs. The FSF promotes the development and use of free (as in freedom) software -- particularly the GNU operating system and its GNU/Linux variants -- and free documentation for free software. The FSF also helps to spread awareness of the ethical and political issues of freedom in the use of software, and its websites, located at https://www.fsf.org and https://www.gnu.org, are an important source of information about GNU/Linux. Donations to support the FSF's work can be made at https://donate.fsf.org. The FSF is a remote organization, incorporated in Massachusetts, US.&lt;/p&gt;
    &lt;head rend="h4"&gt;MEDIA CONTACT&lt;/head&gt;
    &lt;p&gt;Greg Farough&lt;lb/&gt; Campaigns Manager &lt;lb/&gt; Free Software Foundation &lt;lb/&gt; +1 (617) 542 5942 &lt;lb/&gt; campaigns@fsf.org&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45586339</guid><pubDate>Tue, 14 Oct 2025 23:47:08 +0000</pubDate></item><item><title>Ally Petitt: Youngest OSCP at 16yo. Over 11 CVEs by 18</title><link>https://ally-petitt.com/en/posts/2024-05-07_how-i-became-a-hacker-before-i-finished-high-school/</link><description>&lt;doc fingerprint="2e69d0b9aca7777d"&gt;
  &lt;main&gt;
    &lt;p&gt;Author‚Äôs note: This article was initially published on Synack‚Äôs README. They have great content and I recommend that you browse their articles if you are interested cybersecurity.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Editor‚Äôs note: This post from Ally Petitt describes her journey towards earning the vaunted OSCP at 16 &amp;gt; and being an active part of the Synack Red Team at 17. Check out Ally‚Äôs blog for more of her write-ups &amp;gt; on vulnerabilities she‚Äôs discovered, hacking techniques and more.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;Life before coding&lt;/head&gt;
    &lt;p&gt;I was 3 years old when I first declared I was going to be a doctor, my mother told me. When I was 8, I had finally done enough chores around the house to earn $20, and I deposited the total into a college fund. I was 9 years old when I began secretly staying up past my bedtime to read the human anatomy textbook from my father‚Äôs bookshelf. When I was 10 I set my sights on getting admitted to Harvard Medical School and becoming a neurosurgeon. This was also the year that I attempted surgery on my arm with a pencil to see what the different layers of skin looked like. As expected from a fifth grader, this was done without anesthesia and, yes, it got infected. When I was 13, however, I survived a global pandemic and that all changed, setting me on a path that would ultimately see me earn my OffSec Certified Professional (OSCP) certification and get my first CVEs as an ethical hacker.&lt;/p&gt;
    &lt;p&gt;With COVID-19 came remote school, which meant the schoolwork that took approximately seven hours on campus could now be completed in 40 minutes from my own room. Without the increased time commitment of fixed class periods, I was now free to explore education on my own, without a syllabus or any restrictions.&lt;/p&gt;
    &lt;p&gt;I began to ask questions that I had never allowed myself the freedom to ask previously. Becoming a doctor is a prestigious profession. But when I researched the burnout, the relentless schedules, rigorous schooling, student debt and stress that these essential workers experience, I realized a doctor‚Äôs lifestyle would not be a good fit for me.&lt;/p&gt;
    &lt;p&gt;Doubts about a career as a doctor led to more questions. I used the internet to learn subjects that my middle school didn‚Äôt offer: economics, physics, investing, astronomy, trigonometry, neuroscience and Russian. I noticed a trend that I was drawn towards career options that included themes of learning, making connections and investigation. I considered becoming a theoretical physicist, an investigative journalist and many more professions. While enticing, there were aspects of each that made me wary of committing to them.&lt;/p&gt;
    &lt;p&gt;This brings me to December 2020, the month that I ran an experiment to test the coding ability I could attain in only 20 hours of learning. I wanted to see what I was capable of and I did not expect how humbling it would be. I recall that my first five or six hours were spent attempting to troubleshoot my Python installation. The next three were me trying to figure out why my ‚ÄúHello World‚Äù program was not running in VSCode. (It turned out that I had forgotten the ‚Äú.py‚Äù file extension.) By the end of the 20 hours, however, I had gotten the basics of coding down and was able to create simple projects such as mad-libs. I decided to continue for another week and completed a terminal-based tic-tac-toe game. This was a career trajectory I could see myself in.&lt;/p&gt;
    &lt;head rend="h2"&gt;Life after coding to OSCP&lt;/head&gt;
    &lt;p&gt;I built a humble portfolio of coding projects and within three months landed an internship as a software engineer. Navigating this new environment with my new team was a challenge. I was tasked with writing a Java API to take input from a machine learning backend and utilize it to spin up EC2 spot instances (or their equivalent) across three different cloud providers. I took the responsibility of independently learning Java so that I could better contribute to the project. It was also at this time that I began to share resources and techniques with my teammates who were struggling. I began to assist in delegating tasks and working with everyone‚Äôs schedule. Because of this, I was promoted to team lead two months after joining.&lt;/p&gt;
    &lt;p&gt;Fast-forward 1.5 years, I had purchased and built my own PC and served in three internships where I authored programs to decrease website load time by 2 seconds, parse 2,212 PDFs, save 70% of company expenses on cloud computing, scrape and preserve five critical websites, and I designed and developed a company website from scratch.&lt;/p&gt;
    &lt;p&gt;Despite the seemingly rapid success, I had received hundreds of rejections on the basis of my youth, which I tracked on a spreadsheet. I became extremely discouraged due to the limited opportunities available at 16 and considered giving up.&lt;/p&gt;
    &lt;p&gt;After deliberate thought, I decided that if I was going to give up, it would be for a reason other than self-doubt or fear. I shifted my focus to what I could do instead of what I couldn‚Äôt. I forged ahead, reaching a total of 985 GitHub commits by the end of 2022.&lt;/p&gt;
    &lt;p&gt;I continued to seek out experience and opportunities in software engineering. During my third software engineering internship, I developed a deeper interest in how wireless communication worked, and whether knowing how to code really meant that I could hack into a router like I used to think (spoiler: it does not).&lt;/p&gt;
    &lt;p&gt;My cybersecurity journey began by reviewing entry-level TryHackMe modules and learning the basics of networking. It had occurred to me that the OSCP would be a far-reaching certification to obtain, especially with its prestige and notoriety, however, with the limitations that my age had already offered me, I was skeptical in believing that I could obtain it. After further investigation, however, I found that achieving the OSCP at 16 had been done at least once before!&lt;/p&gt;
    &lt;p&gt;With the money I had saved from that internship, I purchased an exam voucher for the OSCP and began my lengthy process of consistent and deliberate preparation over a period of approximately seven months. This story can be found on my personal blog.&lt;/p&gt;
    &lt;p&gt;Earning the OSCP meant more to me than the opportunities it afforded me. It was a symbol of my relentless desire to follow through with the goals that I set for myself and persevere through crippling levels of self-doubt. The OSCP, however, was just the beginning of my journey into infosec.&lt;/p&gt;
    &lt;head rend="h2"&gt;Experience (the city, Synack, CVE and data breach)&lt;/head&gt;
    &lt;p&gt;I learned of an opportunity to intern at the City of Bakersfield over the summer for clerical positions, however, I was interested in a more technical pathway. I found that the city had a job opening for a security analyst. I applied with a flicker of hope that I could help to fill that role during my internship. In the interview process, I explained that I would be willing to take on some of the responsibilities of the analyst as an intern. Shortly thereafter, a thick packet about me was placed on the desk of my future supervisor and he decided to give me an opportunity.&lt;/p&gt;
    &lt;p&gt;Despite having obtained the OSCP at such an early age, my imposter syndrome was still present. I had come to believe that once I achieved more success, I would have less imposter syndrome, however, in practice, I found that it only became more severe. Now, with the opportunity to work for the city, I was face-to-face with my own self-doubts.&lt;/p&gt;
    &lt;p&gt;Ultimately, I took my responsibilities one step at a time. I fell back on my methodology. First, scanning the hundreds of hosts within scope. Then, looking for low-hanging fruits and subsequently narrowing my focus to more granular details, taking thorough notes as I went.&lt;/p&gt;
    &lt;p&gt;Upon my first external penetration test at the city, I was manually testing Click2Gov when I noticed an ID being sent in one of the POST requests that I intercepted in my HTTP proxy. I created a second account and tested that this ID could be modified to be that of another user to make changes to another user‚Äôs account. My hypothesis was proven correct, and thus, I had discovered CVE-2023-40362. Additionally, I discovered an insecure direct object reference (IDOR) and multiple cross-site scripting (XSS) vulnerabilities that were more complex to exploit. Following these discoveries, I corresponded with Central Square in order to responsibly disclose the issues so they could be patched. Months later, after a patch was shipped, I publicized the CVE. The vendor then added a reference to the CVE correlating the vulnerability I found to a Click2Gov data breach affecting 300,000 people that led to a class-action lawsuit. I was absolutely shocked that something I found would be associated with such big news.&lt;/p&gt;
    &lt;p&gt;After this assessment, I did an internal security audit on our printers, where I made the revolutionary discovery that adding a ‚Äútest.txt‚Äù file to the printer‚Äôs FTP server would cause that file to print. My co-workers were very confused as to why the word ‚Äútest‚Äù was repeatedly printing when they went to collect their papers until I realized what was happening. Additionally, I helped to extract the password hashes of our municipal enterprise domain containing thousands of accounts, cracking as many as I could to demonstrate the strength of our passwords. Finally, I audited our Active Directory domain, mapping out potential privilege escalation paths that could be used by attackers. These four assessments were completed in the span of only six weeks.&lt;/p&gt;
    &lt;p&gt;After my term at the city concluded, I continued to perform independent research, leading to the discovery of CVE-2023-43154 and CVE-2023-44792, which were authentication bypass and SQL injection vulnerabilities, respectively. In December 2023, I discovered CVE-2024-27630, CVE-2024-27631 and CVE-2024-27632 in Savane, the web-based software hosting system used by the Savannah bug tracker. It coordinates bug-related information in 405 official GNU projects that have been estimated to be used by millions of people worldwide.&lt;/p&gt;
    &lt;p&gt;By now, I was beginning to gain more confidence in my abilities as an offensive security professional. I began to apply to more job openings, starting with Synack, where I was grateful to have the opportunity to join the Synack Red Team (SRT) of security researchers.&lt;/p&gt;
    &lt;head rend="h3"&gt;SQLi WAF bypass&lt;/head&gt;
    &lt;p&gt;Being surrounded by so many knowledgeable security researchers really allowed me to grow my own skills. Two weeks into working for the SRT, I discovered an intriguing authentication bypass flaw. Recently, I discovered a SQL injection vulnerability ‚Äì however, my SQLi payloads were being monitored by a reputable firewall. I attempted different techniques and bypasses for several days before eventually running out of ideas.&lt;/p&gt;
    &lt;p&gt;Luckily, I didn‚Äôt have to go it alone: I partnered with SRT members Moey and NukeDX in order to construct an initial payload to validate the SQL injection. From there, Moey ‚Äì who happens to have also joined the SRT at a young age ‚Äì and I tested the firewall for hours. We tested payloads in online SQL editor sandboxes and read through documentation to find different ways to accomplish data exfiltration. While we were unable to find a payload to extract all the data, we crafted a payload to extract part of it by turning our traditional SQLi into a boolean attack. From there, we brute-forced our way into demonstrating impact with the vulnerability.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;As a current senior in high school, balancing school life with my professional aspirations has been a persistent challenge, however, it is an immensely rewarding journey. Ultimately, my success thus far is a product of the individuals who saw potential in me and gave me a chance or simply a listening ear. In my continuous mission to learn and contribute to this industry, I plan to research more open-source projects, firmware, and otherwise intriguing cyber assets in addition to obtaining more technical certifications in my transition from high school to a career in security research. Although this scar on my arm from my self-imposed ‚Äúsurgery‚Äù is fading, its symbolism remains eternal as it represents the insatiable curiosity and unwavering perseverance that has led me to discover and thrive in a field that I am proud to be a part of.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45586423</guid><pubDate>Tue, 14 Oct 2025 23:57:59 +0000</pubDate></item><item><title>Meta erases Gaza journalist's Instagram</title><link>https://twitter.com/DropSiteNews/status/1977795050206576763</link><description>&lt;doc fingerprint="d635f48b34542867"&gt;
  &lt;main&gt;
    &lt;p&gt;We‚Äôve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.&lt;/p&gt;
    &lt;p&gt;Help Center&lt;/p&gt;
    &lt;p&gt;Terms of Service Privacy Policy Cookie Policy Imprint Ads info ¬© 2025 X Corp.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45586464</guid><pubDate>Wed, 15 Oct 2025 00:05:17 +0000</pubDate></item><item><title>New England's last coal plant has stopped operating, according to its owners</title><link>https://www.nhpr.org/nh-news/2025-10-06/new-englands-last-coal-plant-has-stopped-operating-according-to-its-owners</link><description>&lt;doc fingerprint="36d3415472b73438"&gt;
  &lt;main&gt;
    &lt;p&gt;The last coal-fired power plant in New England, Merrimack Station, has stopped running.&lt;/p&gt;
    &lt;p&gt;With the closure of that facility, the region is poised to become the first in the United States without a coal plant on its grid (though New York state, which has its own regional grid operator, stopped burning coal in 2020).&lt;/p&gt;
    &lt;p&gt;Granite Shore Power, the company that owns the coal plant in Bow, New Hampshire, said they ceased commercial operations September 12th, about a year and a half since they announced they would retire their facility by 2028 as part of a settlement agreement with environmental groups.&lt;/p&gt;
    &lt;p&gt;‚ÄúFor nearly three quarters of a century, Merrimack Station has reliably served the energy needs of families and businesses across New Hampshire,‚Äù the company wrote in a statement.&lt;/p&gt;
    &lt;p&gt;The facility still has two kerosene-fired generators that will continue running. It has been struggling to keep its coal-fired generators in compliance with state regulations for more than two years.&lt;/p&gt;
    &lt;p&gt;‚ÄúI‚Äôm so glad that we are not going to burn any more coal in New Hampshire,‚Äù said Kendra Ford, a climate organizer with 350 New Hampshire. ‚ÄúI know that this is hard on people who work there, and I know that the town of Bow may also be a little caught off guard by it closing at this moment, so I hope that lots of things can be done for those folks.‚Äù&lt;/p&gt;
    &lt;p&gt;Merrimack Station and another plant owned by Granite Shore Power, Schiller Station, are the last two coal-fired plants connected to New England‚Äôs regional electric grid. Schiller Station has not burned coal since 2020. In Maine, a paper mill burns coal to power their own operations.&lt;/p&gt;
    &lt;p&gt;Mary Cate Colapietro, a spokesperson for New England‚Äôs regional grid operator, said the organization has not received a formal retirement request from Merrimack Station, but the region does not depend on the facility for the grid‚Äôs reliability.&lt;/p&gt;
    &lt;p&gt;‚ÄúCoal generation accounted for only 0.22% of power in the region in 2024,‚Äù Colapietro said.&lt;/p&gt;
    &lt;p&gt;Colapietro said there is no way to track what kinds of fuel are being used to generate the electricity that is imported from other regions, meaning it‚Äôs not a given that New Englanders are using coal-free power.&lt;/p&gt;
    &lt;p&gt;But with Merrimack Station shutting down, there will no longer be coal burned in New England to power the grid.&lt;/p&gt;
    &lt;p&gt;Granite Shore Power said they would provide assistance or placement services to employees who lost their jobs, and that they were considering ‚Äúall opportunities‚Äù for redevelopment at the site of the plant.&lt;/p&gt;
    &lt;p&gt;Local transitions&lt;/p&gt;
    &lt;p&gt;Merrimack Station opened in the 1960s. It generated power for the regional grid ‚Äì and had a major impact on the community that hosted it, the town of Bow.&lt;/p&gt;
    &lt;p&gt;‚ÄúBack when it was built, it was the largest taxpayer in town by far,‚Äù said David Stack, Bow‚Äôs town manager.&lt;/p&gt;
    &lt;p&gt;The amount of revenue that Bow got from property taxes on the coal plant allowed the town to keep tax rates low, leading to a boom in residential development. The impact was especially profound because New Hampshire towns depend heavily on property taxes, Stack said.&lt;/p&gt;
    &lt;p&gt;But the value of the plant, and how much they should pay in taxes, has been the subject of yearslong conflict between Bow and the owners of Merrimack Station ‚Äì first Public Service of New Hampshire and Eversource, and more recently, Granite Shore Power.&lt;/p&gt;
    &lt;p&gt;The conflict led to a lawsuit, in which Bow had to pay Eversource millions of dollars, after the New Hampshire Supreme Court found they had charged the company too much in taxes. Stack says that as the value of the plant has continued to drop, Bow has felt the economic impact.&lt;/p&gt;
    &lt;p&gt;Over the last 15 years, Stack says, Bow has tried to adapt. Officials have worked to become friendlier to developers, changing zoning rules. Firms like DHL and Coastal Forest Products opened distribution centers in town. But other than mixed-use developments that are primarily residential, Stack says there aren‚Äôt a lot of new opportunities.&lt;/p&gt;
    &lt;p&gt;‚ÄúAs far as manufacturing, you don‚Äôt really see that anymore,‚Äù Stack said. ‚ÄúI just don‚Äôt know if big commercial ventures beyond Amazon are that successful.‚Äù&lt;/p&gt;
    &lt;p&gt;A few years ago, the taxes from new commercial developments surpassed the taxes the power plant was paying ‚Äì a major turning point for reducing Bow‚Äôs reliance on the plant. But despite the town‚Äôs preparation, the news of Merrimack Station‚Äôs closure came as a surprise.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe realized we were going to get to this point eventually,‚Äù Stack said. ‚ÄúI thought they had a little more time.‚Äù&lt;/p&gt;
    &lt;p&gt;Stack says Granite Shore Power has never sat down with officials in Bow to talk about the future. The company has said publicly that they‚Äôre hoping to turn Merrimack Station and Schiller Station into ‚Äúrenewable energy parks,‚Äù with batteries and solar. Jim Andrews, the head of Granite Shore Power, said in 2024 he wasn‚Äôt planning to include natural gas as part of the redevelopment. But, he said, it‚Äôs not off the table.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe‚Äôre concerned with the valuation. But we don‚Äôt know exactly what technology they‚Äôre looking at putting there,‚Äù Stack said.&lt;/p&gt;
    &lt;p&gt;National shifts&lt;/p&gt;
    &lt;p&gt;In the opposite northern corner of the country, other communities are also preparing to leave coal behind. Oregon and Washington are planning to eliminate coal from their generation portfolio by the end of this year, when the Centralia, WA coal plant is scheduled for retirement.&lt;/p&gt;
    &lt;p&gt;There, the plan for the future includes a $55 million fund, through an agreement between Washington State and the coal plant owner, to help the Centralia community transition.&lt;/p&gt;
    &lt;p&gt;Coal still makes up about 8% of the generation capacity in the Northwest, including Idaho and Montana. Next door, in California, coal still made up a small fraction of the state‚Äôs power production as of 2024.&lt;/p&gt;
    &lt;p&gt;Nationally and globally, coal has been on its way out for years. Coal plants account for the largest share of retiring energy generators in the country.&lt;/p&gt;
    &lt;p&gt;Research shows coal has become more expensive than other fuel options. And it‚Äôs one of the most carbon-emitting fossil fuels, creating emissions that can harm the health of people nearby and that fuel climate change.&lt;/p&gt;
    &lt;p&gt;Still, coal accounted for about 16% of the U.S.‚Äôs power generation in 2023. Some plants are delaying retirements. The Trump Administration has announced several efforts to expand the industry, including putting millions of dollars towards re-opening or modernizing coal plants, opening millions of acres of federal land for coal mining, and relaxing federal environmental rules that affect the burning of coal.&lt;/p&gt;
    &lt;p&gt;For Kendra Ford, the climate advocate, Merrimack Station‚Äôs closure seems to be another sign of the industry in decline, despite the Trump Administration‚Äôs efforts to revive it.&lt;/p&gt;
    &lt;p&gt;‚ÄúIt‚Äôs not sustainable in any way. It‚Äôs not sustainable for the environment, obviously. The economics are against it now,‚Äù she said. ‚ÄúIt just doesn‚Äôt make any sense to go back to coal.‚Äù&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45586962</guid><pubDate>Wed, 15 Oct 2025 01:10:50 +0000</pubDate></item></channel></rss>