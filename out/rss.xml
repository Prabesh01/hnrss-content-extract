<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 31 Oct 2025 16:44:40 +0000</lastBuildDate><item><title>Affinity Studio now free</title><link>https://www.affinity.studio/get-affinity</link><description>&lt;doc fingerprint="3bd67e5e966d06c5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Get Affinity&lt;/head&gt;
    &lt;p&gt;Available on desktop for&lt;/p&gt;
    &lt;p&gt;The all-in-one creative app, with everything you need to craft designs, edit images, and lay it all out, without ever leaving your document or paying a thing.&lt;/p&gt;
    &lt;quote&gt;$0, free&lt;/quote&gt;
    &lt;p&gt;To download Affinity, sign in with your Canva account (or create one for free).&lt;/p&gt;
    &lt;head rend="h2"&gt;One powerful app. No cost.&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Fully-featured toolsets&lt;/p&gt;
        &lt;p&gt;From vector to pixel to layout, Affinity has all the studio-grade tools you need under one roof.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Customizable studios&lt;/p&gt;
        &lt;p&gt;Mix and match your favorite tools to build your very own creative studios.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Non-destructive editing&lt;/p&gt;
        &lt;p&gt;Experiment as much you want, keep your original files intact.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Pixel-perfect export&lt;/p&gt;
        &lt;p&gt;Full control over how your work leaves the app, whether it’s by object, slice, or doc.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What you’ll get&lt;/head&gt;
    &lt;p&gt;With Affinity, you’ll get all the professional tools you need for your design, photo editing, and page layout projects, free of charge. If you’re on a Canva premium plan, you’ll also be able to unlock Canva AI tools directly in Affinity for a super-powered workflow.&lt;/p&gt;
    &lt;p&gt;+ Canva premium plans&lt;/p&gt;
    &lt;head rend="h2"&gt;Design workflows&lt;/head&gt;
    &lt;p&gt;Access all vector design, photo editing, and page layout tools in one app&lt;/p&gt;
    &lt;p&gt;Combine vector and pixel work on the same .af document&lt;/p&gt;
    &lt;p&gt;Customize your workspace with floating toolbars and studio presets&lt;/p&gt;
    &lt;p&gt;Real-time performance engine for ultra-smooth editing&lt;/p&gt;
    &lt;p&gt;Non-destructive editing across layers, filters, and adjustments&lt;/p&gt;
    &lt;p&gt;Import PSD, AI, PDF, SVG, IDML and more with high fidelity&lt;/p&gt;
    &lt;p&gt;Export with one-click presets or custom slice-based output&lt;/p&gt;
    &lt;p&gt;Quick export direct to Canva&lt;/p&gt;
    &lt;head rend="h2"&gt;Powerful photo editing&lt;/head&gt;
    &lt;p&gt;Live filters and adjustments with instant preview&lt;/p&gt;
    &lt;p&gt;Full RAW editing, tone mapping, and lens correction&lt;/p&gt;
    &lt;p&gt;Advanced retouching: inpainting brush, healing tools, dodge and burn&lt;/p&gt;
    &lt;p&gt;Batch processing with recordable macros, HDR merge, panorama stitching, and more&lt;/p&gt;
    &lt;head rend="h2"&gt;Pro vector design&lt;/head&gt;
    &lt;p&gt;Precision drawing with pen, node, and pencil tools&lt;/p&gt;
    &lt;p&gt;Live shape editing, booleans, and shape builder&lt;/p&gt;
    &lt;p&gt;Flexible gradients with full control&lt;/p&gt;
    &lt;p&gt;Trace pixel images&lt;/p&gt;
    &lt;p&gt;Pixel-perfect vector tools for illustration and layout&lt;/p&gt;
    &lt;head rend="h2"&gt;Advanced page layout&lt;/head&gt;
    &lt;p&gt;Linked text frames with autoflow and live text wrapping&lt;/p&gt;
    &lt;p&gt;Smart master pages with overrides and reusable layouts&lt;/p&gt;
    &lt;p&gt;Pro typography: ligatures, stylistic sets, drop caps, and variable fonts&lt;/p&gt;
    &lt;p&gt;Print-ready output: CMYK, spot colours, preflight, bleed, and slug support&lt;/p&gt;
    &lt;p&gt;Data merge from .csv with tokens, image merge, and conditional logic&lt;/p&gt;
    &lt;head rend="h2"&gt;Canva AI Studio&lt;/head&gt;
    &lt;p&gt;Generative Fill, Expand, and Edit&lt;/p&gt;
    &lt;p&gt;Generate Images and Vectors&lt;/p&gt;
    &lt;p&gt;Remove Background and Subject Selection&lt;/p&gt;
    &lt;p&gt;Colorize, Depth Selection, and Super Resolution&lt;/p&gt;
    &lt;p&gt;Portrait Blur and Portrait Lighting&lt;/p&gt;
    &lt;p&gt;Full AI generation history&lt;/p&gt;
    &lt;head rend="h2"&gt;Need Affinity for your organization?&lt;/head&gt;
    &lt;p&gt;Skip the individual downloads and get your entire team on Affinity with SSO via a Canva Enterprise or Canva Districts account. Choose an option below to get started.&lt;/p&gt;
    &lt;head rend="h2"&gt;FAQs&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Yes, Affinity really is free. That doesn’t mean you’re getting a watered-down version of the app though. You can use every tool in the Pixel, Vector, and Layout studios, plus all of the customization and export features, as much as you want, with no restrictions or payment needed. The app will also receive free updates with new features and improvements added.&lt;/p&gt;
        &lt;p&gt;If you’re on a Canva premium plan (Pro, Business, Enterprise, Education), you’ll also be able to unlock Canva’s powerful AI tools within Affinity via the Canva AI Studio.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Yes. Affinity is now brought to you by Canva, and your Canva account gives you access to Affinity and other Canva products and features.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No. You can access all of Affinity’s vector, layout, and pixel tools for free without a Canva subscription. If you’d like to unlock Canva AI tools within Affinity, however, you will need a premium Canva plan.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;This is a brand-new product that gives you advanced photo editing, graphic design, and page layout tools under one roof. It includes highly requested features such as Image Trace, ePub support, mesh gradients, hatch fills, live glitch filter, as well as custom capabilities that allow you to rearrange panels and combine tools to build your own unique studios. Plus, with a Canva premium plan, you can unlock incredibly powerful AI tools such as Generative Fill, Generative Expand, Generate Image/Vector, and more — directly in Affinity.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Yes. With a Canva premium plan you can unlock Canva AI features in Affinity.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No, these are only available to those with Canva premium accounts.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Affinity is currently available on Windows and macOS (iPadOS coming soon!).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;We’re busy building our iPad version — stay tuned for updates!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Affinity is optimized for the latest hardware, including Apple silicon.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Absolutely! The new desktop version of Affinity can open all files created in Affinity V2 or V1 apps. However, Affinity V1 and V2 cannot open files that are created or saved in the newer app, Affinity by Canva.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No, it’s the same app, just available on different operating systems.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Yes, you can install Affinity on as many devices as you like.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Yes! It’s easy to import PSDs, AIs, IDMLs, DWGs, and other file types into Affinity, with structure, layers, and creative intent preserved.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Affinity is available in English, French, German, Italian, Spanish, Portuguese, Japanese, Chinese, Bahasa Indonesian, and Turkish. Keep an eye out for more languages coming soon!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Get in touch to speak to our team about how your organization can get set up with Affinity, including SSO.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Then all you need to do is stay in one of our pre-built studios: Pixel, Vector or Layout. You’ll find all your favorite tools there, plus some new ones. Since it’s all free, just think of the other creative toolsets as an added bonus!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That’s totally fine. Your Affinity V2 license (via Serif) remains valid and Serif will continue to keep activation servers online. But please note that these apps won’t receive future updates.&lt;/p&gt;
        &lt;p&gt;For the best experience, we recommend using the new Affinity by Canva app.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;No. The new desktop version of Affinity can open all files created in V2, but older versions (including V2 on iPad) cannot open newer Affinity (.af) files, meaning you won’t be able to work across both platforms.&lt;/p&gt;&lt;lb/&gt;We don’t have a release date for the new Affinity on iPad yet, so recommend continuing to run V2 independently while you enjoy the new Affinity on desktop.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Yes. The new Affinity by Canva app will receive free updates and new features over time.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;You will need to be online to download and activate your license with your free Canva account. From then on, there is no requirement to be online, even with extended offline periods.&lt;/p&gt;
        &lt;p&gt;There are a couple of things to keep in mind:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;There are some features which do require you to be online, if you choose to use them, such as product help, lessons, stock libraries and integrations with Canva including AI tools.&lt;/item&gt;
          &lt;item&gt;We’ll also be releasing new updates and patches regularly, so we recommend connecting from time to time to keep your app up to date, but it's not a requirement of use.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;You need a Canva premium plan to unlock all of Canva’s AI features in Affinity. Simply download the Affinity app via our Downloads page and follow the prompts once you click ‘Canva AI Studio’.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45761445</guid><pubDate>Thu, 30 Oct 2025 15:54:38 +0000</pubDate></item><item><title>How the cochlea computes (2024)</title><link>https://www.dissonances.blog/p/the-ear-does-not-do-a-fourier-transform</link><description>&lt;doc fingerprint="a63e213260f69383"&gt;
  &lt;main&gt;
    &lt;p&gt;Let’s talk about how the cochlea computes!&lt;/p&gt;
    &lt;p&gt;The tympanic membrane (eardrum) is vibrated by changes in air pressure (sound waves). Bones in the middle ear amplify and send these vibrations to the fluid-filled, snail-shaped cochlea. Vibrations travel through the fluid to the basilar membrane, which remarkably performs frequency separation1: the stiffer, lighter base resonates with high frequency components of the signal, and the more flexible, heavier apex resonates with lower frequencies. Between the two ends, the resonant frequencies decrease logarithmically in space2.&lt;/p&gt;
    &lt;p&gt;The hair cells on different parts of the basilar membrane wiggle back and forth at the frequency corresponding to their position on the membrane. But how do wiggling hair cells translate to electrical signals? This mechanoelectrical transduction process feels like it could be from a Dr. Seuss world: springs connected to the ends of hair cells open and close ion channels at the frequency of the vibration, which then cause neurotransmitter release. Bruno calls them “trapdoors”. Here’s a visualization:&lt;/p&gt;
    &lt;p&gt;It’s clear that the hardware of the ear is well-equipped for frequency analysis. Nerve fibers serve as filters to extract temporal and frequency information about a signal. Below are examples of filters (not necessarily of the ear) shown in the time domain. On the left are filters that are more localized in time, i.e. when a filter is applied to a signal, it is clear when in the signal the corresponding frequency occurred. On the right are filters that have less temporal specificity, but are more uniformly distributed across frequencies compared to the left one.&lt;/p&gt;
    &lt;p&gt;Wouldn’t it be convenient if the cochlea were doing a Fourier transform, which would fit cleanly into how we often analyze signals in engineering? But no 🙅🏻♀️! A Fourier transform has no explicit temporal precision, and resembles something closer to the waveforms on the right; this is not what the filters in the cochlea look like.&lt;/p&gt;
    &lt;p&gt;We can visualize different filtering schemes, or tiling of the time-frequency domain, in the following figure. In the leftmost box, where each rectangle represents a filter, a signal could be represented at a high temporal resolution (similar to left filters above), but without information about its constituent frequencies. On the other end of the spectrum, the Fourier transform performs precise frequency decomposition, but we cannot tell when in the signal that frequency occurred (similar to right filters)3. What the cochlea is actually doing is somewhere between a wavelet and Gabor. At high frequencies, frequency resolution is sacrificed for temporal resolution, and vice versa at low frequencies.&lt;/p&gt;
    &lt;p&gt;Why would this type of frequency-temporal precision tradeoff be a good representation? One theory, explored in Lewicki 2002, is that these filters are a strategy to reduce the redundancy in the representation of natural sounds. Lewicki performed independent component analysis (ICA) to produce filters maximizing statistical independence, comparing environmental sounds, animal vocalizations, and human speech. The tradeoffs look different for each one, and you can kind of map them to somewhere in the above cartoon.&lt;/p&gt;
    &lt;p&gt;It appears that human speech occupies a distinct time-frequency space. Some speculate that speech evolved to fill a time-frequency space that wasn’t yet occupied by other existing sounds.&lt;/p&gt;
    &lt;p&gt;To drive the theory home, one that we have been hinting at since the outset: forming ecologically-relevant representations makes sense, as behavior is dependent on the environment. It appears that for audition, as well as other sensory modalities, we are doing this. This is a bit of a teaser for efficient coding, which we will get to soon.&lt;/p&gt;
    &lt;p&gt;We’ve talked about some incredible mechanisms that occur at the beginning of the sensory coding process, but it’s truly just the tiny tip of the ice burg. We also glossed over how these computations occur. The next lecture will zoom into the biophysics of computation in neurons.&lt;/p&gt;
    &lt;p&gt;We call this tonotopic organization, which is a mapping from frequency to space. This type of organization also exists in the cortex for other senses in addition to audition, such as retinotopy for vision and somatotopy for touch.&lt;/p&gt;
    &lt;p&gt;The relationship between human pitch perception and frequency is logarithmic. Coincidence? 😮&lt;/p&gt;
    &lt;p&gt;One could argue we should be comparing to a short-time Fourier transform, but this has resolution issues, and is still not what the cochlea appears to be doing.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45762259</guid><pubDate>Thu, 30 Oct 2025 17:01:20 +0000</pubDate></item><item><title>Minecraft HDL, an HDL for Redstone</title><link>https://github.com/itsfrank/MinecraftHDL</link><description>&lt;doc fingerprint="3271921d09773db1"&gt;
  &lt;main&gt;
    &lt;p&gt;Minecraft HDL is a digital synthesis flow for minecraft redstone circuits. It is an attempt to use industry standard design tools and methods to generate digital circuits with redstone.&lt;/p&gt;
    &lt;p&gt;This file &lt;code&gt;multiplexer4_1.v&lt;/code&gt; is a 6 input - 1 output circuit that selects one of the first 4 inputs (a, b, c, d) as the output based on the value of the last 2 inputs (x, y)&lt;/p&gt;
    &lt;code&gt;module multiplexer4_1 ( a ,b ,c ,d ,x ,y ,dout ); 
 
output dout ; 
input a, b, c, d, x, y; 
 
assign dout = (a &amp;amp; (~x) &amp;amp; (~y)) | 
     (b &amp;amp; (~x) &amp;amp; (y)) |  
     (c &amp;amp; x &amp;amp; (~y)) | 
     (d &amp;amp; x &amp;amp; y); 
endmodule &lt;/code&gt;
    &lt;p&gt;When synthesized through Minecraft HDL it produces this circuit:&lt;/p&gt;
    &lt;p&gt;With the 6 inputs on the right and the single output on the left&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Screenshots &amp;amp; Sample Circuits&lt;/item&gt;
      &lt;item&gt;Getting Started - Installing and Using MinecraftHDL&lt;/item&gt;
      &lt;item&gt;Background Theory - Digital Design &amp;amp; Verilog&lt;/item&gt;
      &lt;item&gt;How MinecraftHDL Works - Read Our Paper&lt;/item&gt;
      &lt;item&gt;Developper Info - If you want to fork or contribute&lt;/item&gt;
      &lt;item&gt;Quick Overview - Check out our poster&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;MinecraftHDL was the final undergraduate design project made by three students in the Electrical, Computer &amp;amp; Software Engineering department at McGill University.&lt;/p&gt;
    &lt;p&gt;It is by no means bug-free or even complete; It produces objectively inferior circuits to 'hand-made' redstone designs, and is not intended to be used in modded survival. It can generate almost any verilog circuit, however only simple designs will actually be testable in-game since any moderately-complex design will end up being longer than the maximum number of blocks loaded in Minecraft.&lt;/p&gt;
    &lt;p&gt;Additionally, we are currently unable to synthesize sequential circuits, aka any circuits with a loopback or feedback. That means no memory, no counters or any circuit that could hold a state.&lt;/p&gt;
    &lt;p&gt;MinecraftHDL is an educational tool to illustrate on a macro-scopic scale how microelectronic digital circuits are designed and produced. It is a great way to introduce younger audiences to the world of digital design and can also be used to illustrate the difference between software and hardware design to undergraduate engineers taking their first RTL class.&lt;/p&gt;
    &lt;p&gt;Supervisor: Brett H. Meyer - Website&lt;lb/&gt; Students: Francis O'Brien - Website&lt;lb/&gt; Omar Ba Mashmos&lt;lb/&gt; Andrew Penhale&lt;/p&gt;
    &lt;p&gt;To show how easy it is to make a circuit with MinecraftHDL here is a gif of me creating a circuit, synthesizing, and generating it in minecraft in less than a minute!&lt;/p&gt;
    &lt;p&gt;The circuit I generate above is a 2bit adder. It takes two numbers of two bits and adds them. At the end of the gif I set both input numbers to '11' which is the binary representation of the number 3. Then I move to the output and we see that O3=1, O2=1, and O1=0, this gives the binary number '110' which is indeed 6.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45763877</guid><pubDate>Thu, 30 Oct 2025 18:59:02 +0000</pubDate></item><item><title>Phone numbers for use in TV shows, films and creative works</title><link>https://www.acma.gov.au/phone-numbers-use-tv-shows-films-and-creative-works</link><description>&lt;doc fingerprint="c83d86dd4cb0f56b"&gt;
  &lt;main&gt;
    &lt;p&gt; On this page &lt;/p&gt;
    &lt;p&gt;Looking for info about unwanted calls? Learn more about phone scams and how you can make your number more private.&lt;/p&gt;
    &lt;head rend="h2"&gt;Geographical numbers&lt;/head&gt;
    &lt;p&gt;You can use the following prefixes and first 4 digits, then any 4 digits you like (shown here as 'xxxx').&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;Region&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;Number range&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Central East (covering NSW and ACT)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;(02) 5550 xxxx and (02) 7010 xxxx&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;South East (covering VIC and TAS)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;(03) 5550 xxxx and (03) 7010 xxxx&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;North East (covering QLD)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;(07) 5550 xxxx and (07) 7010 xxxx&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Central West (covering SA, WA and NT)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;(08) 5550 xxxx and (08) 7010 xxxx&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Mobile numbers&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;0491 570 006&lt;/item&gt;
      &lt;item&gt;0491 570 156&lt;/item&gt;
      &lt;item&gt;0491 570 157&lt;/item&gt;
      &lt;item&gt;0491 570 158&lt;/item&gt;
      &lt;item&gt;0491 570 159&lt;/item&gt;
      &lt;item&gt;0491 570 110&lt;/item&gt;
      &lt;item&gt;0491 570 313&lt;/item&gt;
      &lt;item&gt;0491 570 737&lt;/item&gt;
      &lt;item&gt;0491 571 266&lt;/item&gt;
      &lt;item&gt;0491 571 491&lt;/item&gt;
      &lt;item&gt;0491 571 804&lt;/item&gt;
      &lt;item&gt;0491 572 549&lt;/item&gt;
      &lt;item&gt;0491 572 665&lt;/item&gt;
      &lt;item&gt;0491 572 983&lt;/item&gt;
      &lt;item&gt;0491 573 770&lt;/item&gt;
      &lt;item&gt;0491 573 087&lt;/item&gt;
      &lt;item&gt;0491 574 118&lt;/item&gt;
      &lt;item&gt;0491 574 632&lt;/item&gt;
      &lt;item&gt;0491 575 254&lt;/item&gt;
      &lt;item&gt;0491 575 789&lt;/item&gt;
      &lt;item&gt;0491 576 398&lt;/item&gt;
      &lt;item&gt;0491 576 801&lt;/item&gt;
      &lt;item&gt;0491 577 426&lt;/item&gt;
      &lt;item&gt;0491 577 644&lt;/item&gt;
      &lt;item&gt;0491 578 957&lt;/item&gt;
      &lt;item&gt;0491 578 148&lt;/item&gt;
      &lt;item&gt;0491 578 888&lt;/item&gt;
      &lt;item&gt;0491 579 212&lt;/item&gt;
      &lt;item&gt;0491 579 760&lt;/item&gt;
      &lt;item&gt;0491 579 455&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Freephone and local rate numbers&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;1800 160 401&lt;/item&gt;
      &lt;item&gt;1800 975 707&lt;/item&gt;
      &lt;item&gt;1800 975 708&lt;/item&gt;
      &lt;item&gt;1800 975 709&lt;/item&gt;
      &lt;item&gt;1800 975 710&lt;/item&gt;
      &lt;item&gt;1800 975 711&lt;/item&gt;
      &lt;item&gt;1300 975 707&lt;/item&gt;
      &lt;item&gt;1300 975 708&lt;/item&gt;
      &lt;item&gt;1300 975 709&lt;/item&gt;
      &lt;item&gt;1300 975 710&lt;/item&gt;
      &lt;item&gt;1300 975 711&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45765787</guid><pubDate>Thu, 30 Oct 2025 21:49:11 +0000</pubDate></item><item><title>Kimi Linear: An Expressive, Efficient Attention Architecture</title><link>https://github.com/MoonshotAI/Kimi-Linear</link><description>&lt;doc fingerprint="d7db9096ac4b9fd0"&gt;
  &lt;main&gt;
    &lt;p&gt;(a) On MMLU-Pro (4k context length), Kimi Linear achieves 51.0 performance with similar speed as full attention. On RULER (128k context length), it shows Pareto-optimal (84.3), performance and a 3.98x speedup. (b) Kimi Linear achieves 6.3x faster TPOT compared to MLA, offering significant speedups at long sequence lengths (1M tokens).&lt;/p&gt;
    &lt;p&gt;Kimi Linear is a hybrid linear attention architecture that outperforms traditional full attention methods across various contexts, including long,, short, and reinforcement learning (RL) scaling regimes. At it's core is Kimi Delta Attention (KDA)—a refined version of Gated DeltaNet that introduces a more efficient gating mechanism to optimize the use of finite-state RNN memory.&lt;/p&gt;
    &lt;p&gt;Kimi Linear achieves performance, superior and hardware efficiency, especially for long-context tasks. It reduces the need for large KV caches by up 75%, to and boosts decoding throughput by up to &lt;/p&gt;
    &lt;p&gt;We open-sourced the KDA kernel FLA,, in and released two versions model checkpoints trained with 5.7T tokens.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Model&lt;/cell&gt;
        &lt;cell role="head"&gt;#Total Params&lt;/cell&gt;
        &lt;cell role="head"&gt;#Activated Params&lt;/cell&gt;
        &lt;cell role="head"&gt;Context Length&lt;/cell&gt;
        &lt;cell role="head"&gt;Download Link&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Kimi-Linear-Base&lt;/cell&gt;
        &lt;cell&gt;48B&lt;/cell&gt;
        &lt;cell&gt;3B&lt;/cell&gt;
        &lt;cell&gt;1M&lt;/cell&gt;
        &lt;cell&gt;🤗 Hugging Face&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Kimi-Linear-Instruct&lt;/cell&gt;
        &lt;cell&gt;48B&lt;/cell&gt;
        &lt;cell&gt;3B&lt;/cell&gt;
        &lt;cell&gt;1M&lt;/cell&gt;
        &lt;cell&gt;🤗 Hugging Face&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Kimi Delta Attention (KDA): A linear attention mechanism that refines the gated delta rule with finegrained gating.&lt;/item&gt;
      &lt;item&gt;Hybrid Architecture: A 3:1 KDA-to-global MLA ratio reduces memory usage while maintaining or surpassing the quality of full attention.&lt;/item&gt;
      &lt;item&gt;Superior Performance: Outperforms full attention in a variety of tasks, long-context, including and RL-style benchmarks on 1.4T token training runs with fair comparisons.&lt;/item&gt;
      &lt;item&gt; High Throughput: Achieves up to &lt;math-renderer&gt;$6\times$&lt;/math-renderer&gt;decoding, faster and significantly reduces time per output token (TPOT).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To use the Kimi Linear model, we recommend the following:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Language: &lt;code&gt;python&lt;/code&gt;&amp;gt;= 3.10&lt;/item&gt;
      &lt;item&gt;Package: &lt;code&gt;torch&lt;/code&gt;&amp;gt;= 2.6&lt;/item&gt;
      &lt;item&gt;Package: &lt;code&gt;fla-core&lt;/code&gt;&amp;gt;= 0.4.0&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;pip install -U fla-core&lt;/code&gt;
    &lt;p&gt;Example Code:&lt;/p&gt;
    &lt;code&gt;from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "moonshotai/Kimi-Linear-48B-A3B-Instruct"
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype="auto",
    device_map="auto",
    trust_remote_code=True
)
tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)

messages = [
    {"role": "system", "content": "You are a helpful assistant provided by Moonshot-AI."},
    {"role": "user", "content": "Is 123 a prime?"}
]
input_ids = tokenizer.apply_chat_template(
    messages, 
    add_generation_prompt=True, 
    return_tensors="pt"
).to(model.device)
generated_ids = model.generate(inputs=input_ids, max_new_tokens=500)
response = tokenizer.batch_decode(generated_ids)[0]
print(response)&lt;/code&gt;
    &lt;p&gt;For deployment, you can use the latest vllm to create an OpenAI-compatible API endpoint.&lt;/p&gt;
    &lt;code&gt;vllm serve moonshotai/Kimi-Linear-48B-A3B-Instruct \
  --port 8000 \
  --tensor-parallel-size 4 \
  --max-model-len 1048576 \
  --trust-remote-code&lt;/code&gt;
    &lt;p&gt;If you found our work useful, please cite&lt;/p&gt;
    &lt;code&gt;@misc{team2025kimi,
    title         = {Kimi Linear: An Expressive, Efficient Attention Architecture},
    author        = {Zhang, Yu  and Lin, Zongyu  and Yao, Xingcheng  and Hu, Jiaxi  and Meng, Fanqing  and Liu, Chengyin  and Men, Xin  and Yang, Songlin  and Li, Zhiyuan  and Li, Wentao  and Lu, Enzhe  and Liu, Weizhou  and Chen, Yanru  and Xu, Weixin  and Yu, Longhui  and Wang, Yejie  and Fan, Yu  and Zhong, Longguang  and Yuan, Enming  and Zhang, Dehao  and Zhang, Yizhi  and T. Liu, Y.  and Wang, Haiming  and Fang, Shengjun  and He, Weiran  and Liu, Shaowei  and Li, Yiwei  and Su, Jianlin  and Qiu, Jiezhong  and Pang, Bo  and Yan, Junjie  and Jiang, Zhejun  and Huang, Weixiao  and Yin, Bohong  and You, Jiacheng  and Wei, Chu  and Wang, Zhengtao  and Hong, Chao  and Chen, Yutian  and Chen, Guanduo  and Wang, Yucheng  and Zheng, Huabin  and Wang, Feng  and Liu, Yibo  and Dong, Mengnan  and Zhang, Zheng  and Pan, Siyuan  and Wu, Wenhao  and Wu, Yuhao  and Guan, Longyu  and Tao, Jiawen  and Fu, Guohong  and Xu, Xinran  and Wang, Yuzhi  and Lai, Guokun  and Wu, Yuxin  and Zhou, Xinyu  and Yang, Zhilin  and Du, Yulun},
    year          = {2025},
    eprint        = {2510.26692},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CL}
}&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45766937</guid><pubDate>Fri, 31 Oct 2025 00:07:36 +0000</pubDate></item><item><title>Show HN: Quibbler – A critic for your coding agent that learns what you want</title><link>https://github.com/fulcrumresearch/quibbler</link><description>&lt;doc fingerprint="2c94ad61798f9efa"&gt;
  &lt;main&gt;
    &lt;p&gt;Quibbler is a critic for your coding agent. It runs in the background and critiques your coding agent's actions, either via hooks or an MCP. When your coding agent is once again failing in the same ways, or ignoring your spec, instead of having to prompt it, the Quibbler agent will automatically observe and correct it.&lt;/p&gt;
    &lt;p&gt;It will also learn rules from your usage, and then enforce them so you don't have to.&lt;/p&gt;
    &lt;head class="px-3 py-2"&gt;demo.mp4&lt;/head&gt;
    &lt;p&gt;We've found Quibbler useful in automatically preventing agents from:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fabricating results without running commands&lt;/item&gt;
      &lt;item&gt;Not running tests or skipping verification steps&lt;/item&gt;
      &lt;item&gt;Not following your coding style and patterns&lt;/item&gt;
      &lt;item&gt;Hallucinating numbers, metrics, or functionality&lt;/item&gt;
      &lt;item&gt;Creating new patterns instead of following existing ones&lt;/item&gt;
      &lt;item&gt;Making changes that don't align with user intent&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Quibbler maintains context across reviews, learning your project's patterns and rules over time.&lt;/p&gt;
    &lt;p&gt;Using uv:&lt;/p&gt;
    &lt;code&gt;uv tool install quibbler&lt;/code&gt;
    &lt;p&gt;Using pip:&lt;/p&gt;
    &lt;code&gt;pip install quibbler&lt;/code&gt;
    &lt;p&gt;Quibbler supports two integration modes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Uses Claude Code's hook system for event-driven monitoring&lt;/item&gt;
      &lt;item&gt;Passively observes all agent actions (tool use, prompts, etc.)&lt;/item&gt;
      &lt;item&gt;Fire-and-forget feedback injection via file writes&lt;/item&gt;
      &lt;item&gt;More powerful affordances but Claude Code-specific&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Uses the Model Context Protocol for universal compatibility&lt;/item&gt;
      &lt;item&gt;Agent calls &lt;code&gt;review_code&lt;/code&gt;tool after making changes&lt;/item&gt;
      &lt;item&gt;Synchronous review with immediate feedback&lt;/item&gt;
      &lt;item&gt;Simple setup via MCP server configuration&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Choose your mode and follow the appropriate setup instructions:&lt;/p&gt;
    &lt;p&gt;Add Quibbler to your agent's MCP server configuration.&lt;/p&gt;
    &lt;p&gt;For Cursor (&lt;code&gt;.cursor/mcp.json&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;{
  "mcpServers": {
    "quibbler": {
      "command": "quibbler mcp",
      "env": {
        "ANTHROPIC_API_KEY": "your-api-key-here"
      }
    }
  }
}&lt;/code&gt;
    &lt;p&gt;For other MCP-compatible agents: Refer to your agent's documentation for MCP server configuration.&lt;/p&gt;
    &lt;p&gt;Create or update &lt;code&gt;AGENTS.md&lt;/code&gt; in your project root to instruct your agent to use Quibbler:&lt;/p&gt;
    &lt;code&gt;## Code Review Process

After making code changes, you MUST call the `review_code` tool from the Quibbler MCP server with:

- `user_instructions`: The exact instructions the user gave you
- `agent_plan`: **A summary of the specific changes you made** (include which files were modified, what was added/changed, and key implementation details)
- `project_path`: The absolute path to this project

Review Quibbler's feedback and address any issues or concerns raised.

### Example

User asks: "Add logging to the API endpoints"

After implementing, call:

review_code(
user_instructions="Add logging to the API endpoints",
agent_plan="""Changes made:

1. Added logger configuration in config/logging.py
2. Updated routes/api.py to log incoming requests and responses
3. Added request_id middleware for tracing
4. Created logs/ directory with .gitignore""",
   project_path="/absolute/path/to/project"
   )&lt;/code&gt;
    &lt;p&gt;In a terminal, start the Quibbler hook server:&lt;/p&gt;
    &lt;code&gt;export ANTHROPIC_API_KEY="your-api-key-here"
quibbler hook server
# Or specify a custom port:
quibbler hook server 8081&lt;/code&gt;
    &lt;p&gt;Keep this server running in the background. It will receive hook events from Claude Code.&lt;/p&gt;
    &lt;p&gt;In your project directory, run:&lt;/p&gt;
    &lt;code&gt;quibbler hook add&lt;/code&gt;
    &lt;p&gt;This creates or updates &lt;code&gt;.claude/settings.json&lt;/code&gt; with the necessary hooks to forward events to the Quibbler server.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;.claude/settings.json&lt;/code&gt; should now contain hooks that:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Forward tool use events to Quibbler (&lt;code&gt;quibbler hook forward&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Display Quibbler feedback to the agent (&lt;code&gt;quibbler hook notify&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When Claude Code runs in this project, Quibbler will automatically observe and intervene when needed.&lt;/p&gt;
    &lt;p&gt;By default, Quibbler uses Claude Haiku 4.5 for speed. You can change this by creating or editing:&lt;/p&gt;
    &lt;p&gt;Global config (&lt;code&gt;~/.quibbler/config.json&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;{
  "model": "claude-sonnet-4-5"
}&lt;/code&gt;
    &lt;p&gt;Project-specific config (&lt;code&gt;.quibbler/config.json&lt;/code&gt; in your project):&lt;/p&gt;
    &lt;code&gt;{
  "model": "claude-sonnet-4-5"
}&lt;/code&gt;
    &lt;p&gt;Project-specific config takes precedence over global config.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Your agent makes code changes, then calls the &lt;code&gt;review_code&lt;/code&gt;tool with user instructions and a summary of changes made&lt;/item&gt;
      &lt;item&gt;Quibbler maintains a persistent review agent per project that: &lt;list rend="ul"&gt;&lt;item&gt;Reviews the completed changes against user intent&lt;/item&gt;&lt;item&gt;Uses Read tool to examine the actual changed files and existing patterns in your codebase&lt;/item&gt;&lt;item&gt;Validates claims and checks for hallucinations&lt;/item&gt;&lt;item&gt;Verifies proper testing and verification steps were included&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Quibbler returns feedback or approval synchronously&lt;/item&gt;
      &lt;item&gt;Your agent addresses any issues found in the review&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Claude Code triggers hooks on events (tool use, prompt submission, etc.)&lt;/item&gt;
      &lt;item&gt;Hook events are forwarded to the Quibbler HTTP server&lt;/item&gt;
      &lt;item&gt;Quibbler maintains a persistent observer agent per session that: &lt;list rend="ul"&gt;&lt;item&gt;Passively watches all agent actions&lt;/item&gt;&lt;item&gt;Builds understanding of what the agent is doing&lt;/item&gt;&lt;item&gt;Intervenes when necessary by writing feedback to &lt;code&gt;.quibbler/{session_id}.txt&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Feedback is automatically displayed to the agent via the notify hook&lt;/item&gt;
      &lt;item&gt;The agent sees the feedback and can adjust its behavior&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Both modes build understanding over time, learning your project's patterns and saving rules to &lt;code&gt;.quibbler/rules.md&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;You can customize Quibbler's system prompt by editing &lt;code&gt;~/.quibbler/prompt.md&lt;/code&gt;. The default prompt will be created on first run.&lt;/p&gt;
    &lt;p&gt;Project-specific rules in &lt;code&gt;.quibbler/rules.md&lt;/code&gt; are automatically loaded and added to the prompt.&lt;/p&gt;
    &lt;p&gt;Note for Hook Mode: Quibbler writes feedback to a message file that is intended for the agent to read and act on (though users have oversight and can see it). Your agent's system prompt should include a &lt;code&gt;{message_file}&lt;/code&gt; placeholder to tell Quibbler where to write its feedback. For example:&lt;/p&gt;
    &lt;code&gt;When you need to provide feedback to the agent, write it to {message_file}. This is agent-to-agent communication intended for the coding agent to read and act on.&lt;/code&gt;
    &lt;p&gt;If you notice an issue or bug, please open an issue. We welcome contributions - feel free to open a PR.&lt;/p&gt;
    &lt;p&gt;Join our community on Discord to discuss workflows and share experiences.&lt;/p&gt;
    &lt;p&gt;See LICENSE for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45767162</guid><pubDate>Fri, 31 Oct 2025 00:43:57 +0000</pubDate></item><item><title>Roadmap for Improving the Type Checker</title><link>https://forums.swift.org/t/roadmap-for-improving-the-type-checker/82952</link><description>&lt;doc fingerprint="97a8d1dba2a69fd6"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;head rend="h1"&gt;Roadmap for improving the type checker&lt;/head&gt;
      &lt;p&gt;In the past, we've released various "manifestos" and "roadmaps" to discuss planned improvements to the language. This post is also a roadmap of sorts, but instead, the focus is on the implementation rather than user-visible language changes (however, I will briefly mention a few potential language changes at the very end).&lt;/p&gt;
      &lt;p&gt;Specifically, I'm going to talk about some work we are doing to improve expression type checking in the Swift compiler. This includes changes that have already shipped in Swift 6.2, changes that are on the &lt;code&gt;main&lt;/code&gt; development branch, changes that we plan on working on next, and more tentative longer-term plans.&lt;/p&gt;
      &lt;p&gt;Before talking about specific improvements, I'm going to start with a rather long explanation of this part of the compiler implementation, which to my knowledge has not been summarized in one place yet.&lt;/p&gt;
      &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
      &lt;p&gt;This is all, of course, about the dreaded &lt;code&gt;the compiler is unable to type-check this expression in reasonable time&lt;/code&gt; error. This error can appear with both valid and invalid code, and the various workarounds are unsatisfactory, to say the least. Splitting up an expression into smaller pieces, introducing type annotations, or attempting other refactorings will sometimes allow valid code to type check, or in the invalid case, surface an actionable diagnostic. However, this breaks flow and becomes a frustrating process of trial and error "shotgun debugging" even for the most experienced Swift programmers. The compiler doesn't even tell you if your expression is valid or not!&lt;/p&gt;
      &lt;head rend="h3"&gt;Type-based overloading&lt;/head&gt;
      &lt;p&gt;Swift supports overloading, where multiple declarations in the same scope can share the same name. Swift allows two forms of overloading: by argument labels, or by type. The former case is ultimately handled by name lookup, because argument labels are specified at the call site. Argument label lookup does not introduce any algorithmic complexity in the type checker, so I won't discuss it further. Type-based overloading, on the other hand, requires the type checker to reason about the types of expressions before it can decide the correct overload to pick, which is a more difficult problem. So in the rest of this post, when I talk about overloading, I'm specifically referring to overloading based on types---either parameter or result types.&lt;/p&gt;
      &lt;head rend="h3"&gt;Constraint solving&lt;/head&gt;
      &lt;p&gt;The Swift compiler implements overload resolution by transforming expression type checking into a constraint solving problem. The compiler always looks at a single expression at a time (with some exceptions, such as multi-statement closures), and proceeds to type-check each expression in turn.&lt;/p&gt;
      &lt;p&gt;First, we introduce type variables to represent the unknown type of each sub-expression in the syntax tree. Next, we generate constraints to describe relationships among type variables. Examples of constraints include "type &lt;code&gt;X&lt;/code&gt; is a subtype of type &lt;code&gt;Y&lt;/code&gt;", "type &lt;code&gt;X&lt;/code&gt; is the result of calling function type &lt;code&gt;Y&lt;/code&gt; with arguments &lt;code&gt;Z&lt;/code&gt;", and crucially for overload resolution, what are called disjunction constraints. A disjunction constraint has the form "type &lt;code&gt;X&lt;/code&gt; is either &lt;code&gt;Y1&lt;/code&gt;, or &lt;code&gt;Y2&lt;/code&gt;, or &lt;code&gt;Y3&lt;/code&gt;, ... or &lt;code&gt;Yn&lt;/code&gt;", where each &lt;code&gt;Yn&lt;/code&gt; is the type of an overloaded declaration with the same name.&lt;/p&gt;
      &lt;p&gt;Once we have our type variables and constraints, we proceed to solve the constraint system by attempting to assign a concrete type to each type variable, in a manner that is consistent with the set of constraints. A set of such assignments is called a solution. The constraint solving process can produce zero, one, or many solutions. If no solution was found, the expression is erroneous. If one solution was found, we're done; if multiple solutions were found, we first attempt to rank the solutions in case one of them is clearly "better" than the others. If this ranking fails to produce a winner, we diagnose an ambiguity error.&lt;/p&gt;
      &lt;head rend="h3"&gt;Algorithmic complexity&lt;/head&gt;
      &lt;p&gt;The algorithmic complexity in constraint solving arises as a result of these disjunction constraints, because in the worst case, there is no better approach to solving such a constraint system except to attempt each combination of disjunction choices.&lt;/p&gt;
      &lt;p&gt;This is somewhat like solving a Sudoku. You can write down a number in a blank square, and then check that the result is a valid board. If it is, you try to fill in another square, and so on. On the other hand, if you get stuck, you backtrack by erasing a previously filled in square, and attempt to place a number somewhere else. If you're lucky and make perfect a guess at each step, you can fill in the whole board without backtracking. At the other extreme, you might end up attempting every possible path to a solution, which can take a long time.&lt;/p&gt;
      &lt;p&gt;For a more detailed overview of constraint solving in the Swift type checker, see swift/docs/TypeChecker.md at main · swiftlang/swift · GitHub. For an explanation of why overload resolution is inherently hard, and why every known approach has exponential running time in the worst case, see How does compiler compile SwiftUI code? - #4 by Slava_Pestov and Lambda Expressions vs. Anonymous Methods, Part Five | Microsoft Learn.&lt;/p&gt;
      &lt;head rend="h3"&gt;What does &lt;code&gt;reasonable time&lt;/code&gt; mean?&lt;/head&gt;
      &lt;p&gt;Since constraint solving with disjunctions takes exponential time in the worst case, it will always be possible to write down a short program that would require an inordinate amount of time to type check, so the type checker must limit the total amount of work that it does, and fail if this limit is reached.&lt;/p&gt;
      &lt;p&gt;The Swift type checker imposes two such limits:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Every time we attempt a disjunction choice, we increment a counter. The counter is reset to zero at the start of each expression, and if the value exceeds one million, we give up.&lt;/item&gt;
        &lt;item&gt;The constraint solver also allocates various data structures in a per-expression arena, which is then torn down in one shot once type checking this expression ends. If the total size of the arena exceeds 512 megabytes, we give up.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;In the past, Swift also had a wall-clock time limit, but this is no longer enabled by default, because it is non-deterministic across machines. Counting operations is a better approach, and most "too complex" expressions don't take longer than 4 seconds on a typical machine in practice.&lt;/p&gt;
      &lt;head rend="h3"&gt;Invalid expressions, salvage mode, and diagnostics&lt;/head&gt;
      &lt;p&gt;In ordinary type checking, the solver stops and backtracks immediately when a constraint fails, but this does not in itself produce precise error messages.&lt;/p&gt;
      &lt;p&gt;To get good diagnostics after a failure, we restart the solving process again, this time with an expanded search space. This is called "salvage mode." In salvage mode, a failure to solve a constraint is handled differently. Instead of simply failing the constraint and stopping the solver, we proceed as if the failed constraint succeeded, but we also record a fix.&lt;/p&gt;
      &lt;p&gt;For example, if an expression does not type-check because &lt;code&gt;Int&lt;/code&gt; does not conform to &lt;code&gt;Sequence&lt;/code&gt;, then this conformance constraint will fail on the first attempt. We then restart type checking in salvage mode. When the bogus constraint comes up again, we pretend that &lt;code&gt;Int&lt;/code&gt; actually does conform to &lt;code&gt;Sequence&lt;/code&gt;, but we record a fix, and continue solving more constraints until we're done.&lt;/p&gt;
      &lt;p&gt;Once we finish solving the constraint system in salvage mode, the collected fixes are then analyzed to produce a diagnostic. Finally, if salvage mode fails but no fixes are recorded, we emit the &lt;code&gt;failed to produce diagnostic&lt;/code&gt; error.&lt;/p&gt;
      &lt;p&gt;For more details about the diagnostic architecture, see New Diagnostic Architecture Overview | Swift.org.&lt;/p&gt;
      &lt;head rend="h1"&gt;Goals and non-goals&lt;/head&gt;
      &lt;p&gt;While the worst case behavior is unavoidable, it does not have to be the case that type checking must take exponential time on all expressions, even when complex overload sets are involved. In fact, most expressions do type-check rather quickly, even today. It is also true that for any given single "hard" expression, it is possible to devise a heuristic that will solve it quickly, because in the extreme case, you can hard-code knowledge of that specific problem instance in the constraint solver (of course, we won't do that).&lt;/p&gt;
      &lt;p&gt;The main goal then, is to devise sufficiently-general heuristics which can quickly solve most realistic problem instances, without hard-coding too many special cases, so that hopefully, the exponential running time only appears with pathological examples which are unlikely to occur in practice. The primary way to accomplish this is to attempt disjunction choices in the right order---this includes both choosing the next disjunction to attempt, and the next choice within a disjunction to attempt. Also, we can avoid considering disjunction choices that lead to contradictions. By doing this, we can find the valid solutions more quickly, and spend less time exploring long "dead ends."&lt;/p&gt;
      &lt;p&gt;A secondary goal is to improve the auxiliary data structures and algorithms used in the constraint solver, so that even if an exhaustive search must be attempted on a given expression, as will sometimes be the case, we burn less CPU time while considering the same search space.&lt;/p&gt;
      &lt;p&gt;There are also two non-goals worth mentioning:&lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;Removing overloading from the language. Without disjunction constraints, a constraint system can almost always be solved very quickly. However, this would be such a major change to the language, and break so many existing APIs, that it is not feasible to attempt at this point, even as a new language mode.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Removing bidirectional inference. We can also imagine a language design where expressions are type-checked in a strictly bottom-up fashion, starting from the leaves, like in many other C-family languages. This is another drastic simplification that essentially trivializes the whole problem. However, this would require giving up on language features such as polymorphic literals, leading-dot member syntax, closures with inferred types, and parts of generics. All of these are features that make Swift into the expressive language it is today.&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h1"&gt;Recent improvements&lt;/head&gt;
      &lt;head rend="h2"&gt;Swift 6.2&lt;/head&gt;
      &lt;p&gt;In Swift 6.2, we spent time profiling the type checker with various larger projects, as well as individual slow expressions, both valid and invalid. This uncovered some bottlenecks, including with the backtracking implementation, various graph algorithms such as computing connected components, and other miscellaneous algorithms.&lt;/p&gt;
      &lt;p&gt;The first example is an invalid expression where we can see a small improvement. Consider the last line of the below code listing, which appeared in this blog post:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;let address = "127.0.0.1"
let username = "steve"
let password = "1234"
let channel = 11

let url = "http://" + username 
            + ":" + password 
            + "@" + address 
            + "/api/" + channel 
            + "/picture"
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;The expression is invalid as written, because there is no overload of &lt;code&gt;+&lt;/code&gt; taking an &lt;code&gt;Int&lt;/code&gt; and a &lt;code&gt;String&lt;/code&gt;. On my machine, Swift 6.1 spends 10 seconds to produce an &lt;code&gt;unable to type-check&lt;/code&gt; error, while in Swift 6.2, we get the same error in 6 seconds. Of course, this is not the desired end state, since we should instead produce a meaningful diagnostic. However, this example specifically illustrates that the type checker is able to do the same amount of work in less time.&lt;/p&gt;
      &lt;p&gt;For a more realistic example, I measured a project that makes heavy use of overloading and generics, and saw that total type checking time improved from 42 seconds in Swift 6.1, down to 34 seconds in Swift 6.2.&lt;/p&gt;
      &lt;head rend="h2"&gt;Swift 6.3&lt;/head&gt;
      &lt;head rend="h3"&gt;Optimized disjunction selection&lt;/head&gt;
      &lt;p&gt;Recent &lt;code&gt;main&lt;/code&gt; development snapshots introduced a large set of changes that @xedin has been working on for several years now, to improve disjunction selection, by collecting more information to decide what disjunction should be attempted next. Unlike the targeted optimizations in Swift 6.2 which offered incremental wins without reducing the fundamental complexity of the problem, the disjunction selection changes allow the type checker to quickly solve many expressions that we were formerly unable to type-check. The new algorithm can also drastically speed up expressions that would type check, but were just under the limit and thus slow.&lt;/p&gt;
      &lt;p&gt;These changes replace some older optimizations that would look at the entire expression before solving begins, to attempt "pre-solving" certain sub-expressions. These hacks were rather brittle in practice, so a small change to an expression could defeat the entire hack.&lt;/p&gt;
      &lt;p&gt;The optimized disjunction selection algorithm instead runs as part of the constraint solver, making it more robust and predictable. The biggest wins can be seen with expressions that involve math operators and literals. Here is a typical example. The Swift 6.2 compiler was unable to type check the below expression, but the compiler from &lt;code&gt;main&lt;/code&gt; type checks this successfully, in 4 milliseconds:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;func test(n: Int) -&amp;gt; Int {
  return n == 0 ? 0 : (0..&amp;lt;n).reduce(0) { x, y in
    (x &amp;gt; 0 &amp;amp;&amp;amp; y % 2 == 0) ? (((x + y) - (x + y)) / (y - x)) + ((x + y) / (y - x)) : x
  }
}
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;The invalid expression from above, where &lt;code&gt;+&lt;/code&gt; was applied to &lt;code&gt;String&lt;/code&gt; and &lt;code&gt;Int&lt;/code&gt;, is still rejected, however with the new algorithm, it only takes the compiler 2 seconds to reach the limit.&lt;/p&gt;
      &lt;p&gt;Finally, on the same project I mentioned in the Swift 6.2 summary above, the new algorithm yields a further reduction in total type checking time, down to 12 seconds.&lt;/p&gt;
      &lt;p&gt;(If you find an expression that type checks on a released version of Swift but fails on a &lt;code&gt;main&lt;/code&gt; development snapshot, please file a GitHub issue.)&lt;/p&gt;
      &lt;head rend="h3"&gt;Optimized constraint solver arena usage&lt;/head&gt;
      &lt;p&gt;Recent &lt;code&gt;main&lt;/code&gt; development snapshots also introduce an optimization which eliminates a source of exponential space usage in the constraint solver. This optimization is still disabled by default, but we hope to enable it soon. (You can enable it with the &lt;code&gt;-solver-enable-prepared-overloads&lt;/code&gt; frontend flag on a &lt;code&gt;main&lt;/code&gt; development snapshot if you'd like to test it now.)&lt;/p&gt;
      &lt;p&gt;This optimization works as follows. Previously, when attempting a disjunction choice for a generic overload, the solver would generate new type variables and constraints corresponding to the generic parameters and &lt;code&gt;where&lt;/code&gt; clause requirements of the generic overload. If the same overload had to be attempted multiple times, in combination with other overload choices, the same type variables and constraints would be generated every time. These type variables and constraints are allocated in the constraint solver's arena. This space optimization instead allocates these structures once, the first time a disjunction choice is attempted.&lt;/p&gt;
      &lt;p&gt;For many expressions, this leads to a drastic reduction in constraint solver arena usage. In some instances, it will transform an exponential space problem into a polynomial space problem, even if it still requires exponential time. Furthermore, since less space also means less time, the primary benefit here is again a reduction in total type checking time. In the future, pre-generating these structures will also enable further improvements to the disjunction choice algorithm.&lt;/p&gt;
      &lt;p&gt;On the invalid expression from earlier, where &lt;code&gt;+&lt;/code&gt; was applied to &lt;code&gt;String&lt;/code&gt; and &lt;code&gt;Int&lt;/code&gt;, the constraint solver arena space optimization further reduces the time to reach the limit, down to 1.7 seconds. (That's a more than 5x improvement since Swift 6.1.)&lt;/p&gt;
      &lt;p&gt;Finally, with the same test project I mentioned twice above, this optimization decreases total type checking time from 12 seconds, down to 10 seconds. (That's a more than 4x improvement since Swift 6.1.)&lt;/p&gt;
      &lt;head rend="h3"&gt;Expanding our test suite to cover more fast and slow expressions&lt;/head&gt;
      &lt;p&gt;To help prevent performance regressions in the future, and to track progress on solving the problem, we have added more test cases to our suite. These have been reduced from user-reported slow expressions in GitHub issues for the Swift project.&lt;/p&gt;
      &lt;p&gt;Some of the test cases also use our &lt;code&gt;scale-test&lt;/code&gt; tool, which repeats a common element of an expression (think adding &lt;code&gt;+ 1 + 1 + 1 ...&lt;/code&gt;), measures the performance of each instance, and then attempts to guess if the resulting problem scales in polynomial or exponential time. This helps catch more subtle issues where a given expression might still appear to be "fast", but becomes slow if you make it just a little bit longer.&lt;/p&gt;
      &lt;p&gt;These test cases are found in the validation-test/Sema/type_checker_perf directory in the Swift repo. The recently added test cases are in Sema: Collected expression checking performance test cases from GitHub issues by slavapestov · Pull Request #84450 · swiftlang/swift · GitHub, with a few more in Even more type checker perf tests by slavapestov · Pull Request #84890 · swiftlang/swift · GitHub. We hope to continue expanding the type checker performance test suite over time.&lt;/p&gt;
      &lt;head rend="h1"&gt;Future improvements&lt;/head&gt;
      &lt;p&gt;Disclaimer: all of the below is subject to change as our plans evolve.&lt;/p&gt;
      &lt;head rend="h2"&gt;Optimizing bindings&lt;/head&gt;
      &lt;p&gt;Imagine we're solving a constraint system, and we're left with a single unsolved constraint, a conversion from a type variable &lt;code&gt;T0&lt;/code&gt; to &lt;code&gt;Optional&amp;lt;Int&amp;gt;&lt;/code&gt;. At this point, in order to proceed, we must "guess" the concrete type to bind to &lt;code&gt;T0&lt;/code&gt;. While &lt;code&gt;T0&lt;/code&gt; might just be &lt;code&gt;Optional&amp;lt;Int&amp;gt;&lt;/code&gt;, another valid choice is &lt;code&gt;Int&lt;/code&gt;, because &lt;code&gt;Int&lt;/code&gt; converts to &lt;code&gt;Optional&amp;lt;Int&amp;gt;&lt;/code&gt;. The bindings subsystem in the constraint solver is responsible for tracking the potential bindings for each type variable by considering unsolved conversion constraints, and ultimately, attempting various potential bindings until a solution is found.&lt;/p&gt;
      &lt;p&gt;The book-keeping for bindings is rather complicated, and must be updated incrementally as constraints are solved and new constraints are introduced. Another complication is that to choose the next binding to attempt, we must consider all type variables and all of their potential bindings, and rank them according to a heuristic.&lt;/p&gt;
      &lt;p&gt;Today, this ranking process indeed considers all type variables and all bindings, and ultimately picks just one type variable and just one binding to attempt. This must be repeated for each unbound type variable, which of course results in a quadratic time algorithm.&lt;/p&gt;
      &lt;p&gt;Thus, even in a constraint system without a large number of complex overloads, it is sometimes possible to observe algorithmic complexity due to bindings. Now, most expressions do not involve a large number of type variables---it is far more common to see a large number of disjunction choices instead. But one situation where a large number of type variables are generated is if you write an array or dictionary literal with a large number of elements.&lt;/p&gt;
      &lt;p&gt;We plan on overhauling the data structures for tracking potential bindings, both to eliminate some duplicate bookkeeping (&lt;code&gt;BindingSet&lt;/code&gt; and &lt;code&gt;PotentialBindings&lt;/code&gt; in the implementation) and to make the choice of the next binding to attempt something that can be done in constant or logarithmic time, instead of the current situation where it is linear in the number of type variables. This will radically speed up the type checking of large array and dictionary literals.&lt;/p&gt;
      &lt;p&gt;Since solving constraints can introduce new bindings, an important decision problem is whether a binding set is "complete". Today, this check is very conservative, so we often don't attempt bindings until we've gone far down a path of disjunction choices. More accurate computation of when a binding set is complete would allow bindings to be attempted sooner, which would reduce algorithmic complexity of type-checking many common expressions.&lt;/p&gt;
      &lt;p&gt;Another improvement to the bindings logic would allow the solver to reach a contradiction by considering contradictory bindings. Today, if a type variable &lt;code&gt;T0&lt;/code&gt; is subject to two conversion constraints, for example to &lt;code&gt;Optional&amp;lt;Int&amp;gt;&lt;/code&gt; and &lt;code&gt;Optional&amp;lt;String&amp;gt;&lt;/code&gt;, we don't reach a contradiction until we attempt every possible concrete type for &lt;code&gt;T0&lt;/code&gt;. But in this case, there is no concrete type that converts to both &lt;code&gt;Optional&amp;lt;Int&amp;gt;&lt;/code&gt; and &lt;code&gt;Optional&amp;lt;String&amp;gt;&lt;/code&gt;, and so a contradiction could be reached faster, avoiding wasting time exploring dead ends.&lt;/p&gt;
      &lt;p&gt;These improvements to the binding logic should speed up many expressions, including long collection literals as I mentioned, and also the aforesaid invalid expression where &lt;code&gt;+&lt;/code&gt; was applied to &lt;code&gt;String&lt;/code&gt; and &lt;code&gt;Int&lt;/code&gt;, where we should finally be able to quickly produce an actionable diagnostic.&lt;/p&gt;
      &lt;head rend="h2"&gt;Removing more performance hacks&lt;/head&gt;
      &lt;p&gt;While the new disjunction selection algorithm subsumed many old performance hacks, some hacks remain. Once again, these hacks tend to be applicable in narrow cases only, which introduces performance cliffs when small changes are made to an expression, and they also have "load-bearing" semantic effects which complicate the language model. These will be generalized or subsumed by existing optimizations over time.&lt;/p&gt;
      &lt;p&gt;It's worth noting that fixing some of these might be source-breaking in extreme edge cases, but we think this is worth the small inconvenience it may cause. Aside from improving performance, this will make the language semantics easier to reason about, and also improve diagnostics.&lt;/p&gt;
      &lt;p&gt;To make this more concrete, here are a few random examples of hacks that we hope to eliminate:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Subscripting of &lt;code&gt;Array&lt;/code&gt; and &lt;code&gt;Dictionary&lt;/code&gt; types is handled in a special way, with a narrow optimization that dates back all the way to Swift 1.0 (&lt;code&gt;inferCollectionSubscriptResultType()&lt;/code&gt;). It can result in strange overload resolution behavior in some cases, and of course it doesn't generalize to subscripts on user-defined types.&lt;/item&gt;
        &lt;item&gt;When simplifying a function call constraint, we look for the case where all overloads have a common return type (&lt;code&gt;simplifyAppliedOverloadsImpl()&lt;/code&gt;). This does not handle generic return types at all, and has some strange edge-case behaviors.&lt;/item&gt;
        &lt;item&gt;There is an optimization that kicks in when a generic overload set has exactly two overloads (&lt;code&gt;tryOptimizeGenericDisjunction()&lt;/code&gt;). This is an obvious performance cliff if a third overload is added, even if its not used in the expression.&lt;/item&gt;
        &lt;item&gt;A set of optimizations attempt to skip some disjunction choices entirely, and "partition" overload sets for math operators into generic, concrete, and SIMD overloads. This is too specific to math operators, and again leads to strange behavior where a concrete overload is chosen even though a generic overload would result in better solutions or diagnostics.&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h2"&gt;Optimizing the handling of partial solutions&lt;/head&gt;
      &lt;p&gt;One of the steps in our constraint solver algorithm constructs a constraint graph, where the vertices are type variables, and the edges relate each pair of type variables that appear in the same constraint. An important optimization detects a situation where this graph has more than one connected component, in which case each component can be solved independently. The "partial solutions" that we obtain from solving each component are then merged to form a solution for the overall constraint system.&lt;/p&gt;
      &lt;p&gt;In many situations, this can avoid exponential behavior. However, in other situations where a large number of partial solutions are produced, building the data structures representing these partial solutions, and the merging algorithm itself, can dominate type checking time for a given expression.&lt;/p&gt;
      &lt;p&gt;By building upon the "trail" data structure for speeding up backtracking that was introduced in Swift 6.2, we hope to reduce the overhead caused by partial solutions in those pathological cases. A specific class of expression where this tends to arise is when you have a large collection literal and each element is itself a complex expression.&lt;/p&gt;
      &lt;head rend="h2"&gt;Improving salvage mode&lt;/head&gt;
      &lt;p&gt;While not strictly performance-related, we would also like to eliminate more cases where salvage mode fails to record any fixes, which as I mentioned above, results in the unhelpful &lt;code&gt;failed to produce diagnostic&lt;/code&gt; error.&lt;/p&gt;
      &lt;p&gt;In fact, another odd situation can arise with salvage mode today: there are known examples where normal type checking fails, but salvage mode then succeeds, in which case we accept the expression. This is a performance problem right off the bat, because such an expression must essentially be type checked twice before a solution is found, even though it is valid.&lt;/p&gt;
      &lt;p&gt;This is also not intended by design, and it involves certain corners of the language which are not well-understood or tested. Fixing these situations will improve performance in pathological cases, while also cleaning up these edge cases in the language, and improving test coverage. Ultimately, if salvage succeeds in this way, we plan to have the solver emit another "fallback diagnostic" instead of silently proceeding.&lt;/p&gt;
      &lt;p&gt;Finally, if normal type-checking produces multiple valid solutions, we still enter salvage mode today, before we generate an ambiguity diagnostic. This should not be necessary, and addressing this will speed up diagnostics for certain invalid ambiguous expressions. This will also reduce the probability that salvage mode, which must do more work by design, will then fail with an "unable to type-check" error, instead of emitting an actionable diagnostic using information already gleaned from normal type checking.&lt;/p&gt;
      &lt;head rend="h1"&gt;Longer-term future improvements&lt;/head&gt;
      &lt;p&gt;I'm going to end this post with more tentative ideas, that while not fully fleshed out, have the potential drastically improve type checking performance.&lt;/p&gt;
      &lt;head rend="h2"&gt;Changes to operator lookup&lt;/head&gt;
      &lt;p&gt;So far, I've only talked about changes which are (mostly) source-compatible, and this has been our main focus to date. However, while we've ruled out drastic solutions such as removing overloading or bidirectional inference entirely, we are considering some more targeted language changes, which would be rolled out with upcoming features or language modes.&lt;/p&gt;
      &lt;p&gt;Consider the &lt;code&gt;==&lt;/code&gt; operator. This operator is heavily-overloaded, but most overloads are implementations of the &lt;code&gt;Equatable&lt;/code&gt;  protocol's &lt;code&gt;==&lt;/code&gt; requirement. In principle, we could avoid attempting each one in turn, simplifying the constraint system that we generate for any expression that involves &lt;code&gt;==&lt;/code&gt;.&lt;/p&gt;
      &lt;p&gt;We plan to investigate a scheme where we prune overload sets to hide overloads that witness a protocol requirement, which will simplify overload sets for &lt;code&gt;==&lt;/code&gt; as well as many other (but not all) operators.&lt;/p&gt;
      &lt;p&gt;This will require changing the rules for solution ranking, which today always prefer concrete overloads; however, we will need to prefer the generic &lt;code&gt;Equatable.==&lt;/code&gt; overload in many instances as well. For this reason, such a change might be slightly source breaking, at least in pathological cases, but it might be possible to stage in a way that avoids disruption for realistic programs.&lt;/p&gt;
      &lt;head rend="h2"&gt;Changes to polymorphic literals&lt;/head&gt;
      &lt;p&gt;A common misconception is that polymorphic literals, like integers and strings, themselves introduce overloads, where every concrete type conforming to an &lt;code&gt;ExpressibleBy*&lt;/code&gt; protocol adds a disjunction choice to the literal. This isn't quite right; a literal such as &lt;code&gt;"hello world"&lt;/code&gt; will type check if a concrete type is known from the surrounding code, and if that fails, via a default type, which is &lt;code&gt;String&lt;/code&gt; in this case. So while this acts as a disjunction of sorts, in this case the disjunction only has two choices, and often the default is not attempted at all.&lt;/p&gt;
      &lt;p&gt;However, an integer literal such as &lt;code&gt;123&lt;/code&gt; actually has two default types, &lt;code&gt;Int&lt;/code&gt; and &lt;code&gt;Double&lt;/code&gt;, and the resulting disjunction has three choices. It might be worth considering a language change where floating point literals must be spelled with a decimal point. Today, expressions involving mixed integer and double literals can be particularly tricky to type check, for this reason.&lt;/p&gt;
      &lt;head rend="h2"&gt;Improved constraint solving techniques&lt;/head&gt;
      &lt;p&gt;Once we are further along with various refactorings and cleanups described above, we will be in a position to implement more advanced constraint solving techniques, such as those commonly used in SAT solvers today. "SAT," or Boolean formula satisfiability, is a related problem to operator overloading. (Like overload resolution, SAT takes exponential time to solve in the worst case, but unlike overload resolution, the "domain" of each type variable is a true or false value. Instead of "constraints", the problem instance consists of a Boolean formula built up from "and", "or", and "not" operations.) Many of the techniques used to speed up SAT solvers can be applied to constraint solving.&lt;/p&gt;
      &lt;p&gt;A solver that supports non-chronological backtracking can jump back over more than one disjunction choice once it detects a contradiction. This avoids the exploration of more dead-ends that necessarily fail, because some constraint further up is already unsatisfiable.&lt;/p&gt;
      &lt;p&gt;Another technique is clause learning. The "naive" approach to constraint solving will discard all state changes when backtracking after a contradiction is discovered. In a solver with clause learning, the algorithm will, roughly speaking, "learn" facts as it goes, recording new constraints that result from backtracking. This ensures that if the same situation arises again, the contradiction can be detected sooner because of the "learned" constraint.&lt;/p&gt;
      &lt;p&gt;(For those curious to learn more about SAT solvers, here is a blog post I saw the other day with a good summary: SATisfying Solutions to Difficult Problems! - Vaibhav Sagar. A book with a decent introduction is "The Satisfiability Problem" by Schóning and Torán. An in-depth treatment appears in Knuth Volume 4B. Finally, a recent academic paper titled The simple essence of overloading by Beneš and Brachthäuser, outlines an interesting approach to overload resolution where the problem is reduced to a binary decision diagram. Some of the ideas here may apply to Swift type checking as well.)&lt;/p&gt;
      &lt;head rend="h1"&gt;Conclusion&lt;/head&gt;
      &lt;p&gt;There are quite a number of interesting improvements that can be made to the Swift type checker, and we look forward to sharing more updates as we make progress in this area.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45767257</guid><pubDate>Fri, 31 Oct 2025 01:00:45 +0000</pubDate></item><item><title>John Carmack on mutable variables</title><link>https://twitter.com/id_aa_carmack/status/1983593511703474196</link><description>&lt;doc fingerprint="d635f48b34542867"&gt;
  &lt;main&gt;
    &lt;p&gt;We’ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.&lt;/p&gt;
    &lt;p&gt;Help Center&lt;/p&gt;
    &lt;p&gt;Terms of Service Privacy Policy Cookie Policy Imprint Ads info © 2025 X Corp.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45767725</guid><pubDate>Fri, 31 Oct 2025 02:34:36 +0000</pubDate></item><item><title>AMD Could Enter ARM Market with Sound Wave APU Built on TSMC 3nm Process</title><link>https://www.guru3d.com/story/amd-enters-arm-market-with-sound-wave-apu-built-on-tsmc-3nm-process/</link><description>&lt;doc fingerprint="4bd2c55e4231494e"&gt;
  &lt;main&gt;
    &lt;p&gt;According to leaks from industry insiders such as @Moore’s Law Is Dead and @KeplerL2, “Sound Wave” is manufactured on TSMC’s 3 nm node and aims for a 5 W to 10 W TDP range, positioning it directly against Qualcomm’s Snapdragon X Elite. The chip is expected to power future Microsoft Surface products scheduled for release in 2026. “Sound Wave” reportedly adopts a 2 + 4 hybrid core design, consisting of two performance and four efficiency cores, paired with 4 MB of L3 cache and 16 MB of MALL cache, a memory technology inspired by the “Infinity Cache” used in AMD’s Radeon GPUs. This configuration is relatively uncommon in low-power APUs and aims to improve responsiveness and multitasking under constrained thermal conditions. On the graphics side, the processor integrates four RDNA 3.5 compute units, offering light gaming support and optimized machine learning acceleration.&lt;/p&gt;
    &lt;p&gt;Memory support is another highlight: the chip integrates a 128-bit LPDDR5X-9600 controller and will reportedly include 16 GB of onboard RAM, aligning with current trends in unified memory designs used in ARM SoCs. Additionally, the APU carries AMD’s fourth-generation AI engine, enabling on-device inference tasks and enhanced efficiency for workloads such as speech recognition, image analysis, and real-time translation.&lt;/p&gt;
    &lt;p&gt;While AMD experimented with ARM over a decade ago through the abandoned “Project Skybridge,” this new effort represents a more mature and strategic approach. With industry interest in efficient, ARM-based computing accelerating, “Sound Wave” could help AMD diversify its portfolio while leveraging its strengths in graphics and AI acceleration. If reports are accurate, the processor will enter production in late 2025, with commercial devices expected the following year.&lt;/p&gt;
    &lt;p&gt;Source: ithome&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45767916</guid><pubDate>Fri, 31 Oct 2025 03:07:48 +0000</pubDate></item><item><title>OpenAI Uses Complex and Circular Deals to Fuel Its Multibillion-Dollar Rise</title><link>https://www.nytimes.com/interactive/2025/10/31/technology/openai-fundraising-deals.html</link><description>&lt;doc fingerprint="60169e48d024efbc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How OpenAI Uses Complex and Circular Deals to Fuel Its Multibillion-Dollar Rise&lt;/head&gt;
    &lt;p&gt;Sam Altman, the chief executive of OpenAI, says that technological revolutions are driven by more than just technology. They are also driven, he argues, by new ways of paying for them.&lt;/p&gt;
    &lt;p&gt;“There is always a lot of focus on technological innovation. What really drives a lot of progress is when people also figure out how to innovate on the financial model,” he recently said at the site of a data center that OpenAI is building in Abilene, Texas.&lt;/p&gt;
    &lt;p&gt;Over the last several years, Mr. Altman’s company has found unusual and creative ways of paying for the computing power needed to fuel its ambitions.&lt;/p&gt;
    &lt;p&gt;Many of the deals OpenAI has struck — with chipmakers, cloud computing companies and others — are strangely circular. OpenAI receives billions from tech companies before sending those billions back to the same companies to pay for computing power and other services.&lt;/p&gt;
    &lt;p&gt;Industry experts and financial analysts have welcomed the start-up’s creativity. But these unorthodox arrangements have also fueled concerns that OpenAI is helping to inflate a potential financial bubble as it builds what is still a highly speculative technology.&lt;/p&gt;
    &lt;p&gt;Here are unusual financial agreements helping to drive the ambitions of OpenAI, the poster child of the artificial intelligence revolution.&lt;/p&gt;
    &lt;p&gt;From 2019 through 2023, Microsoft was OpenAI’s primary investor. The tech giant pumped more than $13 billion into the start-up. Then OpenAI funneled most of those billions back into Microsoft, buying cloud computing power needed to fuel the development of new A.I. technologies.&lt;/p&gt;
    &lt;p&gt;(The New York Times has sued OpenAI and Microsoft, claiming copyright infringement of news content related to A.I. systems. The two companies have denied the suit’s claims.)&lt;/p&gt;
    &lt;p&gt;By the summer of last year, OpenAI could not get all the computing power it wanted from Microsoft. So it started signing cloud computing contracts with other companies, including Oracle and little-known start-ups with names like CoreWeave.&lt;/p&gt;
    &lt;p&gt;Across three different deals signed this year, OpenAI agreed to pay CoreWeave, a company that builds A.I. data centers, more than $22 billion for computing power. As part of these agreements, OpenAI received $350 million in CoreWeave stock, which could ultimately help pay for this computing power.&lt;/p&gt;
    &lt;p&gt;OpenAI also struggled to get the additional investment dollars it wanted from Microsoft. So, it turned to other investors. Earlier this year, the Japanese conglomerate SoftBank led a $40 billion investment in OpenAI.&lt;/p&gt;
    &lt;p&gt;At the same time, OpenAI has been working with various companies to build its own computing data centers, rather than rely on cloud computing deals. This also includes SoftBank, which is known for highly speculative technological bets that don’t always pay off. The company is raising $100 billion to help OpenAI build data centers in Texas and Ohio.&lt;/p&gt;
    &lt;p&gt;Similarly, Oracle, a software and cloud computing giant, has agreed to spend $300 billion building new data centers for OpenAI in Texas, New Mexico, Michigan and Wisconsin. OpenAI will then pay Oracle roughly the same amount to use these computing facilities over the next several years.&lt;/p&gt;
    &lt;p&gt;The United Arab Emirates was part of an OpenAI’s fund-raising round in October 2024. Now, G42, a firm with close ties to the Emirati government, is building a roughly $20 billion data center complex for OpenAI in the Emirates.&lt;/p&gt;
    &lt;p&gt;Last month, Nvidia announced that it intended to invest $100 billion in OpenAI over the next several years. This could help OpenAI pay for its new data centers. As OpenAI buys or leases specialized chips from Nvidia, Nvidia will pump billions back into OpenAI.&lt;/p&gt;
    &lt;p&gt;Two weeks later, OpenAI signed an agreement with AMD that allows OpenAI to buy up to 160 million shares in the chipmaker at a penny per share. That translates to roughly a 10 percent stake in the company. This stock could supply OpenAI with additional capital as it works to build new data centers.&lt;/p&gt;
    &lt;p&gt;OpenAI pulls in billions of dollars in revenue each year from customers who pay for ChatGPT, computer programming tools and other technologies. But it still loses more money than it makes, according to a person familiar with the company’s finances.&lt;/p&gt;
    &lt;p&gt;If the company can use its new data centers to significantly improve A.I. technologies and expand its revenue over the next several years, it can become a viable business, as Mr. Altman believes it will. If technology progress stalls, OpenAI – and its many partners – could lose enormous amounts of money. Smaller companies like CoreWeave, which are taking on enormous amounts of debt to build new data centers, could go bankrupt.&lt;/p&gt;
    &lt;p&gt;In some cases, companies are hedging their bets. Nvidia and AMD, for instance, have the option of reducing the cash and stock they send to OpenAI if the A.I. market does not expand as quickly as expected. But others would be left with enormous debt, which could send ripples across the larger economy.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45771538</guid><pubDate>Fri, 31 Oct 2025 13:03:46 +0000</pubDate></item><item><title>Attention lapses due to sleep deprivation due to flushing fluid from brain</title><link>https://news.mit.edu/2025/your-brain-without-sleep-1029</link><description>&lt;doc fingerprint="35099567c8b315fa"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Audio&lt;/head&gt;
    &lt;p&gt;Nearly everyone has experienced it: After a night of poor sleep, you don’t feel as alert as you should. Your brain might seem foggy, and your mind drifts off when you should be paying attention.&lt;/p&gt;
    &lt;p&gt;A new study from MIT reveals what happens inside the brain as these momentary failures of attention occur. The scientists found that during these lapses, a wave of cerebrospinal fluid (CSF) flows out of the brain — a process that typically occurs during sleep and helps to wash away waste products that have built up during the day. This flushing is believed to be necessary for maintaining a healthy, normally functioning brain.&lt;/p&gt;
    &lt;p&gt;When a person is sleep-deprived, it appears that their body attempts to catch up on this cleansing process by initiating pulses of CSF flow. However, this comes at a cost of dramatically impaired attention.&lt;/p&gt;
    &lt;p&gt;“If you don’t sleep, the CSF waves start to intrude into wakefulness where normally you wouldn’t see them. However, they come with an attentional tradeoff, where attention fails during the moments that you have this wave of fluid flow,” says Laura Lewis, the Athinoula A. Martinos Associate Professor of Electrical Engineering and Computer Science, a member of MIT’s Institute for Medical Engineering and Science and the Research Laboratory of Electronics, and an associate member of the Picower Institute for Learning and Memory.&lt;/p&gt;
    &lt;p&gt;Lewis is the senior author of the study, which appears today in Nature Neuroscience. MIT visiting graduate student Zinong Yang is the lead author of the paper.&lt;/p&gt;
    &lt;p&gt;Flushing the brain&lt;/p&gt;
    &lt;p&gt;Although sleep is a critical biological process, it’s not known exactly why it is so important. It appears to be essential for maintaining alertness, and it has been well-documented that sleep deprivation leads to impairments of attention and other cognitive functions.&lt;/p&gt;
    &lt;p&gt;During sleep, the cerebrospinal fluid that cushions the brain helps to remove waste that has built up during the day. In a 2019 study, Lewis and colleagues showed that CSF flow during sleep follows a rhythmic pattern in and out of the brain, and that these flows are linked to changes in brain waves during sleep.&lt;/p&gt;
    &lt;p&gt;That finding led Lewis to wonder what might happen to CSF flow after sleep deprivation. To explore that question, she and her colleagues recruited 26 volunteers who were tested twice — once following a night of sleep deprivation in the lab, and once when they were well-rested.&lt;/p&gt;
    &lt;p&gt;In the morning, the researchers monitored several different measures of brain and body function as the participants performed a task that is commonly used to evaluate the effects of sleep deprivation.&lt;/p&gt;
    &lt;p&gt;During the task, each participant wore an electroencephalogram (EEG) cap that could record brain waves while they were also in a functional magnetic resonance imaging (fMRI) scanner. The researchers used a modified version of fMRI that allowed them to measure not only blood oxygenation in the brain, but also the flow of CSF in and out of the brain. They also measured each subject’s heart rate, breathing rate, and pupil diameter.&lt;/p&gt;
    &lt;p&gt;The participants performed two attentional tasks while in the fMRI scanner, one visual and one auditory. For the visual task, they had to look at a screen that had a fixed cross. At random intervals, the cross would turn into a square, and the participants were told to press a button whenever they saw this happen. For the auditory task, they would hear a beep instead of seeing a visual transformation.&lt;/p&gt;
    &lt;p&gt;Sleep-deprived participants performed much worse than well-rested participants on these tasks, as expected. Their response times were slower, and for some of the stimuli, the participants never registered the change at all.&lt;/p&gt;
    &lt;p&gt;During these momentary lapses of attention, the researchers identified several physiological changes that occurred at the same time. Most significantly, they found a flux of CSF out of the brain just as those lapses occurred. After each lapse, CSF flowed back into the brain.&lt;/p&gt;
    &lt;p&gt;“The results are suggesting that at the moment that attention fails, this fluid is actually being expelled outward away from the brain. And when attention recovers, it’s drawn back in,” Lewis says.&lt;/p&gt;
    &lt;p&gt;The researchers hypothesize that when the brain is sleep-deprived, it begins to compensate for the loss of the cleansing that normally occurs during sleep, even though these pulses of CSF flow come with the cost of attention loss.&lt;/p&gt;
    &lt;p&gt;“One way to think about those events is because your brain is so in need of sleep, it tries its best to enter into a sleep-like state to restore some cognitive functions,” Yang says. “Your brain’s fluid system is trying to restore function by pushing the brain to iterate between high-attention and high-flow states.”&lt;/p&gt;
    &lt;p&gt;A unified circuit&lt;/p&gt;
    &lt;p&gt;The researchers also found several other physiological events linked to attentional lapses, including decreases in breathing and heart rate, along with constriction of the pupils. They found that pupil constriction began about 12 seconds before CSF flowed out of the brain, and pupils dilated again after the attentional lapse.&lt;/p&gt;
    &lt;p&gt;“What’s interesting is it seems like this isn’t just a phenomenon in the brain, it’s also a body-wide event. It suggests that there’s a tight coordination of these systems, where when your attention fails, you might feel it perceptually and psychologically, but it’s also reflecting an event that’s happening throughout the brain and body,” Lewis says.&lt;/p&gt;
    &lt;p&gt;This close linkage between disparate events may indicate that there is a single circuit that controls both attention and bodily functions such as fluid flow, heart rate, and arousal, according to the researchers.&lt;/p&gt;
    &lt;p&gt;“These results suggest to us that there’s a unified circuit that’s governing both what we think of as very high-level functions of the brain — our attention, our ability to perceive and respond to the world — and then also really basic fundamental physiological processes like fluid dynamics of the brain, brain-wide blood flow, and blood vessel constriction,” Lewis says.&lt;/p&gt;
    &lt;p&gt;In this study, the researchers did not explore what circuit might be controlling this switching, but one good candidate, they say, is the noradrenergic system. Recent research has shown that this system, which regulates many cognitive and bodily functions through the neurotransmitter norepinephrine, oscillates during normal sleep.&lt;/p&gt;
    &lt;p&gt;The research was funded by the National Institutes of Health, a National Defense Science and Engineering Graduate Research Fellowship, a NAWA Fellowship, a McKnight Scholar Award, a Sloan Fellowship, a Pew Biomedical Scholar Award, a One Mind Rising Star Award, and the Simons Collaboration on Plasticity in the Aging Brain.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45771636</guid><pubDate>Fri, 31 Oct 2025 13:14:23 +0000</pubDate></item><item><title>Sustainable memristors from shiitake mycelium for high-frequency bioelectronics</title><link>https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0328965</link><description>&lt;doc fingerprint="2649d182a83393f0"&gt;
  &lt;main&gt;&lt;head rend="h2"&gt;Figures&lt;/head&gt;&lt;head rend="h2"&gt;Abstract&lt;/head&gt;&lt;p&gt;Neuromorphic computing, inspired by the structure of the brain, offers advantages in parallel processing, memory storage, and energy efficiency. However, current semiconductor-based neuromorphic chips require rare-earth materials and costly fabrication processes, whereas neural organoids need complex bioreactor maintenance. In this study, we explored shiitake (Lentinula edodes) fungi as a robust, sustainable alternative, exploiting its adaptive electrical signaling, which is akin to neuronal spiking. We demonstrate fungal computing via mycelial networks interfaced with electrodes, showing that fungal memristors can be grown, trained, and preserved through dehydration, retaining functionality at frequencies up to 5.85 kHz, with an accuracy of 90 ± 1%. Notably, shiitake has exhibited radiation resistance, suggesting its viability for aerospace applications. Our findings show that fungal computers can provide scalable, eco-friendly platforms for neuromorphic tasks, bridging bioelectronics and unconventional computing.&lt;/p&gt;&lt;p&gt;Citation: LaRocco J, Tahmina Q, Petreaca R, Simonis J, Hill J (2025) Sustainable memristors from shiitake mycelium for high-frequency bioelectronics. PLoS One 20(10): e0328965. https://doi.org/10.1371/journal.pone.0328965&lt;/p&gt;&lt;p&gt;Editor: Ye Zhou, Shenzhen University, HONG KONG&lt;/p&gt;&lt;p&gt;Received: July 8, 2025; Accepted: September 25, 2025; Published: October 10, 2025&lt;/p&gt;&lt;p&gt;Copyright: © 2025 LaRocco et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.&lt;/p&gt;&lt;p&gt;Data Availability: The data is available at this repository: https://github.com/javeharron/abhothData.&lt;/p&gt;&lt;p&gt;Funding: Authors J.S. and J.H. were supported by Honda Research Institute (grant AWD-118684). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.&lt;/p&gt;&lt;p&gt;Competing interests: The authors have declared that no competing interests exist.&lt;/p&gt;&lt;head rend="h2"&gt;Background&lt;/head&gt;&lt;head rend="h3"&gt;Overview&lt;/head&gt;&lt;p&gt;The development of neuromorphic hardware relies on memristive devices capable of emulating synaptic behavior, with potential applications in energy-efficient computing and artificial intelligence1. Recent work has explored natural, biodegradable substrates as sustainable alternatives to conventional inorganic memristors [1]. In this study, we investigated the potential of the edible fungus Lentinula edodes (shiitake mushroom) as a platform for memristor fabrication. By examining the electrical response of mushroom-derived materials under repeated voltage cycling, we explored stable memristive switching behavior, retention, and endurance. Shiitake-based devices not only demonstrate reproducible memory effects, but also highlight the potential for scalable, low-cost, and environmentally friendly neuromorphic components.&lt;/p&gt;&lt;head rend="h3"&gt;Memristors&lt;/head&gt;&lt;p&gt;Memristor devices offer substantial advantages in robotic, industrial, and transport applications due to their unique electrical properties and ability to mimic neural functions. They can enhance various control systems, facilitate efficient information processing, and ultimately improve the overall performance of autonomous systems.&lt;/p&gt;&lt;p&gt;One of the key strengths of memristors is their capacity for efficient and self-adaptive in situ learning, which is critical for applications in robotics and autonomous vehicles. In memristor-based neural networks, the devices can adjust their resistance based on previous inputs, allowing for a form of analog learning that closely resembles the synaptic behavior in biological systems [1]. This capability enables robots and autonomous vehicles to learn from their environment and adapt in real time, enhancing their ability to navigate complex situations effectively. It has been found that such systems can achieve low-latency responses, which are essential for high-speed decision-making in dynamic environments [2].&lt;/p&gt;&lt;p&gt;Memristors also have the advantage of integrating memory and processing capabilities into a single device, enabling a simplified architecture for autonomous control systems [3]. For instance, in autonomous vehicles, trajectory-tracking and path-following tasks can be performed using memristor-based controllers that allow for rapid calculations and real-time adjustments to control variables [4]. This integration, especially with parallelization, helps to address the challenges posed by separate memory and processing units, which can lead to delays and increased power consumption in traditional control systems [4].&lt;/p&gt;&lt;p&gt;Additionally, the resilience of memristor devices against environmental changes, and their ability to operate under varying conditions, make them particularly suitable for autonomous applications, such as spacecraft electronics or vehicles operating in unpredictable road environments [4]. This is complemented by the precision in control that memristor-based systems can offer, which is significant for maintaining stability and performance while following desired trajectories [5].&lt;/p&gt;&lt;p&gt;Moreover, the low power consumption of memristors is particularly beneficial in robotics and autonomous vehicles, where energy efficiency is paramount. Hybrid analog–digital memristor systems can minimize power usage during processing without sacrificing responsiveness, which can prolong operational times by reducing the frequency at which recharging or battery replacement is required, enhancing the feasibility of deploying such systems in mobile applications [2].&lt;/p&gt;&lt;p&gt;Ultimately, the potential of memristors to emulate human-like decision-making and learning processes could be exploited to endow robotic systems and autonomous vehicles with functionalities not found in conventional control systems. The ability of memristors to perform complex computations efficiently, learn adaptively, and integrate both memory and processing into a unified approach make them a cornerstone technology for the future development of intelligent autonomous systems. However, the production of memristors often requires rare-earth minerals and expensive semiconductor foundries.&lt;/p&gt;&lt;head rend="h3"&gt;Fungal electronics&lt;/head&gt;&lt;p&gt;Fungi possess innate abilities to adapt to various environmental conditions and efficiently process information through their interconnected network of hyphae. These characteristics make fungi an ideal candidate for developing sustainable computing systems from. Our aim was to design and implement a novel fungal memristor-based computing architecture that could significantly reduce energy consumption and minimize electronic waste. We approached this using substantially simpler bioreactors and nutrient cultures than those required for conventional neurons and neural organoids. The unique advantages of fungal memristors stem from the biological properties of fungal materials, which distinguish them from typical inorganic or polymer alternatives [6,7].&lt;/p&gt;&lt;p&gt;First, one of the main benefits of fungal memristors is their environmentally sustainable and biodegradable nature. Conventional memristors often contain transition metal oxides or silicon-based structures, the production or disposal of which can pose environmental challenges [6,7]. By contrast, fungal materials are derived from organic biomass, making them both sustainable and significantly less harmful to the environment. This aligns with increasing efforts toward developing greener electronic materials, as highlighted in previous work emphasizing the importance of sustainability in technology development [8].&lt;/p&gt;&lt;p&gt;Second, fungal memristors exhibit remarkable adaptability in their electrical properties. The structural composition of fungal materials often allows for a range of conductive pathways that can form dynamically under the influence of electrical stimuli, similar to the conductive filaments formed in conventional memristors [9,10]. This adaptability can lead to enhanced performance in neuromorphic applications through the facilitation of variable resistance states that mimic synaptic behaviors more closely than traditional memristive materials, which often have static crystalline structures that can lead to variability problems or performance limitations at the nanoscale [11].&lt;/p&gt;&lt;p&gt;Furthermore, fungal memristors may consume less power than traditional materials due to their unique electrochemical properties. It has been claimed that some organic materials, including those derived from fungi, can operate effectively at lower voltages while maintaining stable switching characteristics––a trait that is crucial for developing energy-efficient devices for portable electronics and Internet of Things applications [12]. This can significantly extend battery life and reduce energy costs in processing and memory applications, which have become focal points in the research into neuromorphic systems [13].&lt;/p&gt;&lt;p&gt;Finally, the natural composition and multicellularity of fungal materials can lead to more naturalistic models for neural networks. Because these materials are subject to biological processes, they may inherently incorporate characteristics that resemble biological neuronal networks, including plasticity and memory capabilities that could evolve with usage. This biological mimicry could strengthen the development of more advanced artificial neural networks, enabling applications such as adaptive learning systems and intelligent sensor networks [14].&lt;/p&gt;&lt;head rend="h3"&gt;Fungus types&lt;/head&gt;&lt;p&gt;The potential use of common food mushrooms, such as shiitake and button mushrooms (Agaricus bisporus), as organic memristors is an emerging area of research that exploits the unique properties of these fungi [6,7,13]. Memristors, which are non-volatile memory devices that retain information even without power, can benefit from the porous structures and electrical properties of the organic materials derived from mushrooms.&lt;/p&gt;&lt;p&gt;Shiitake mushrooms have been shown to possess a hierarchically porous carbon structure when activated. This porous structure can enhance the electrochemical performance of devices, making them suitable candidates for use in energy storage systems, including supercapacitors and, potentially, memristors [15]. Highly conductive carbon materials have been created from shiitake, suggesting that these materials could be engineered to exhibit memristive behavior [16]. Shiitake-derived carbon is a sustainable alternative to traditional materials and can enhance the performance of electronic devices due to its unique structural properties.&lt;/p&gt;&lt;p&gt;Button mushrooms have also shown significant potential in this context. Research has indicated that their porosity can be exploited to create materials with large surface areas, which are essential for the development of efficient electronic components [17]. The synthesis of carbon composites from button mushrooms has been explored, revealing their ability to function effectively in energy storage applications [17]. Furthermore, the integration of button mushrooms into electronic systems has been investigated, demonstrating their potential as substrates for electronic devices [18].&lt;/p&gt;&lt;p&gt;In addition to their structural properties, the unique biological characteristics of fungi, including their ability to interact with various chemical compounds, can be harnessed to develop novel sensing technologies. For instance, electronic noses have been developed that use mushroom extracts to detect volatile compounds. These could be adapted for use in electronic devices that require environmental-sensing capabilities [19,20]. This intersection of biology and electronics opens new avenues for creating multifunctional devices that incorporate the sensory capabilities of mushrooms.&lt;/p&gt;&lt;head rend="h3"&gt;Radiation, resistance, and resilience&lt;/head&gt;&lt;p&gt;The radiation resistance of shiitake mushrooms has been studied primarily in terms of their ability to withstand and possibly derive benefits from exposure to ionizing radiation. This resistance can be attributed to several biochemical and physiological attributes. A possible factor is lentinan, a polysaccharide found in the cell walls of shiitake. Lentinan provides structural integrity and exhibits immunomodulatory effects that may enhance the mushroom’s ability to respond to environmental stresses, including radiation exposure. Although some research has suggested that lentinan possesses properties that may help mitigate oxidative stress [21], there have been limited studies directly linking lentinan to radiation resistance in shiitake mushrooms.&lt;/p&gt;&lt;p&gt;Shiitake mushrooms have also shown a notable ability to adapt to their environmental conditions, including variable radiation levels. Studies involving fungi in space research have indicated that certain taxa can enhance their survival through morphological changes or increased melanin production in response to radiation [22]. This radiation resistance implies a suitability of fungal electronics for aerospace applications, where cosmic rays and ambient radiation can interfere with conventional electronics. Fungi’s physical flexibility and low energy requirements would also be advantageous relative to conventional solutions [18,19]. These studies have not specifically addressed shiitake, but the general adaptability observed in fungi suggests that this species could respond similarly to such conditions.&lt;/p&gt;&lt;p&gt;Another example of the resilience of shiitake mushrooms is their ability to maintain their nutritional and bioactive qualities after irradiation. For example, they retain essential nutrients and bioactive compounds even after exposure to ultraviolet radiation [23]. The high content of ergosterol, a precursor to vitamin D, found in shiitake mushrooms, reinforces their potential for beneficial outcomes following exposure to radiation because this compound can be converted into vitamin D2 when subjected to ultraviolet light [24].&lt;/p&gt;&lt;p&gt;Lastly, shiitake mushrooms could be considered in the development of dietary supplements or functional foods that could serve a broader purpose in radioprotection. Their multirole efficacy as a food source and electrical component emphasizes a sustainable approach to utilizing biological entities that can withstand environmental stresses, including radiation. This is especially relevant in aerospace and exploration contexts, where promoting health in astronauts could reduce the risks associated with their increased radiation exposure during missions [22]. Also, shiitake mushrooms can withstand environmental stresses, including radiation, while remaining safe for human consumption.&lt;/p&gt;&lt;p&gt;In summary, the radiation resistance of shiitake mushrooms is linked to the presence of protective compounds, such as lentinan, and their ability to adapt morphologically. These factors have contributed to our understanding of their survival strategies and are suggestive of potential applications in areas where radiation exposure is a significant concern, such as aerospace and radiation sensing. By culturing and evaluating the memristive properties of shiitake mushrooms, we can determine their suitability for use as sustainable, low-cost bioelectronics.&lt;/p&gt;&lt;head rend="h2"&gt;Methods&lt;/head&gt;&lt;head rend="h3"&gt;Summary&lt;/head&gt;&lt;p&gt;Testing the memristive behavior of shiitake mycelium involved several steps, the first being culturing the fungi, and then preparing the samples by drying and rehydrating them. Following this, the most successfully cultivated samples were electrically characterized using a test circuit. Additionally, a special circuit was constructed for further evaluating the feasibility of using mycelium for violate memory.&lt;/p&gt;&lt;head rend="h3"&gt;Hyphal cultivation&lt;/head&gt;&lt;p&gt;Due to the financial and environmental constraints of this project, all four evaluated memristors fabricated for our experiments were composed exclusively of low-cost, organic materials. Based on previous research, we identified materials such as biocompatible composites [25,26] as viable candidates for device construction and programming due to their biodegradability and compatibility with fungal growth.&lt;/p&gt;&lt;p&gt;The initial phase of experimentation focused on the cultivation of fungal hyphae in the selected organic growth media. Nine samples were prepared in standard polycarbonate Petri dishes. The growth conditions were carefully maintained to promote optimal fungal development, with a controlled temperature range of 20–22°C, a relative humidity of 70%, and mixed light exposure to replicate natural terrestrial conditions. The nutrient substrate consisted of a mixture of farro seed, wheat germ, and hay, selected for their organic compositions and ability to support robust fungal growth. Each sample was inoculated with spores or mycelial plugs of shiitake.&lt;/p&gt;&lt;p&gt;The samples (e.g., see Fig 1) were observed and documented biweekly to track their growth consistency and morphological development. Observations including hyphal density, surface coverage, and color changes were recorded in a structured laboratory logbook. In addition to these visual inspections, a brief scratch test was performed to track the progress of the mycelium throughout the substrate. The log included timestamps and qualitative notes, enabling consistent comparison across samples and time points.&lt;/p&gt;&lt;p&gt;Each sample grew a mycelial network that was connected to conventional electronics.&lt;/p&gt;&lt;head rend="h3"&gt;Drying and rehydration process&lt;/head&gt;&lt;p&gt;Once full hyphal coverage and structural maturation were achieved (i.e., when the Petri dish was covered), the samples were transitioned to the drying phase. The Petri dishes were left in a well-ventilated area under direct sunlight at room temperature for approximately seven days to ensure uniform dehydration. The samples were rotated periodically to avoid uneven hardening. As previously reported, this process transformed the fungal matrix into a rigid, disk-like structure while retaining its overall shape and connectivity [26,27].&lt;/p&gt;&lt;p&gt;Prior to testing, the samples were rehydrated using a fine mist of aerosolized deionized water. The rehydration was conducted using a standard commercial spray bottle, held within a distance of 10 cm from each sample. This brief rehydration step restored the required level of conductivity without introducing bulk moisture that could have altered their mechanical integrity.&lt;/p&gt;&lt;head rend="h3"&gt;Electrical characterization&lt;/head&gt;&lt;p&gt;Electrical testing protocols were designed based on theoretical memristors [6,7]. An alternating current was applied to each sample, and the corresponding current–voltage (I–V) characteristics were measured using a digital oscilloscope. As established in previous works, the test setup used a voltage divider to model multiple memristors in the same circuit [6,7].&lt;/p&gt;&lt;p&gt;To extract accurate current values, a known shunt resistor was placed in series with each sample. As shown in Fig 2, voltage readings were captured across both the sample and the resistor, with Channel 1 of the oscilloscope measuring the input voltage and Channel 2 capturing the voltage drop across the shunt resistor. The current values were then calculated using Kirchhoff’s current law, allowing derivation of the I–V characteristics from the voltage differentials. All waveform data were exported in comma-separated values (CSV) format for subsequent digital analysis and visualization.&lt;/p&gt;&lt;p&gt;The test circuit evaluated the memristive properties of each sample.&lt;/p&gt;&lt;p&gt;To thoroughly investigate the memristive behavior of the four samples using mycelium coverage density, voltage sweeps were conducted using both square and sinusoidal waveforms. The square waves were employed to detect sharp threshold-based resistance changes, whereas the sinusoidal inputs provided insights into the more subtle, continuous mem-fractive behaviors. This dual approach enabled the identification of hysteresis loops in the I–V curves––a key signature of memristor functionality.&lt;/p&gt;&lt;p&gt;A square wave was used first, with the peak-to-peak voltage starting at 200 mVpp and increasing. If a sinusoidal wave form exhibited more promising results, a broader range of frequencies was explored. The frequencies and voltages used in the initial tests for memristive properties are detailed in Table 1.&lt;/p&gt;&lt;p&gt;Accuracy and error were calculated based on how many reads agreed with the analog threshold, the number of malformed readings, timing jitter, recording instability, and port delays [28].&lt;/p&gt;(1)&lt;p&gt;The accuracy was calculated using Equation 1, where accuracy is a percentage converted from product of correct samples C over the total number of samples N. The standard error SE was calculated for each case, as shown in Equation 2.&lt;/p&gt;(2)&lt;p&gt;A simulated ideal memristive curve was compared against each experimental result, where the statistical distance d was calculated between both curves [28]. The distance was used to compute memristive accuracy at a particular frequency, as shown in Equation 3.&lt;/p&gt;(3)&lt;head rend="h3"&gt;Volatile memory testing&lt;/head&gt;&lt;p&gt;In the event that the fungal samples exhibited memristive behavior, a specialized electronic circuit was designed and implemented to investigate the volatile memory characteristics of two fungal samples in series. The test circuit was a voltage divider with memory. The test involved setting an arbitrary analog voltage value to represent a high value, and below that threshold was a low value. The frequency range started at 200 Hz and concluded at 5.85 kHz. Similarly to previous work, Fig 3 shows the configuration and layout of this testing circuit [6].&lt;/p&gt;&lt;p&gt;The samples were evaluated using this model.&lt;/p&gt;&lt;p&gt;Comparably to previous work in memristive computing, the volatile memory circuit employed an Arduino UNO microcontroller development board and a voltage divider consisting of two memristive elements [6,7]. Given the polarized nature of memristors, the circuit was designed to allow a voltage of opposite polarity to that used during read operations to be set. Both voltages used were approximately 5 V. The Arduino UNO cyclically applied a high signal to a relay containing a half-rectified sine wave through one of its digital output pins when reading the memristor bridge, thereby charging the divider. This process induced an asymmetry in resistance, with the memristor closest to the input experiencing a reduction in resistance, while the output-side memristor exhibited an increase. The voltage across the divider was subsequently read using an analog input pin, and another digital pin was used to run 5 V across the divider. The Arduino interpreted the stored state as “on” only when the measured voltage exceeded a predefined threshold, effectively enabling volatile memory detection based on the transient resistance states of the memristors. Ten tests were repeated on each of the four samples. The physical implementation of this circuit is shown in Fig 4.&lt;/p&gt;&lt;p&gt;The volatile memory circuit was implemented using fungal memristors.&lt;/p&gt;&lt;p&gt;The memristor voltage divider was tested by applying a 5 Vpp sinusoidal signal to the memristors for approximately 0.01–0.1 ms. This signal was delivered via a relay triggered by digital pin 6 of the Arduino UNO. Following this brief stimulation period, the sinusoidal input was disabled, and digital pin 5 was activated to initiate the read phase. Analog voltage measurements were then acquired through the A1 analog input pin. To minimize the effects of floating voltages, a 1 MΩ pull-down resistor was connected to this pin. Voltage readings were recorded for approximately 0.1–0.10 ms before the cycle repeated, allowing for rapid and continuous testing of the memristive behavior.&lt;/p&gt;&lt;p&gt;The measurements were transmitted over a serial communication interface at a baud rate of 57,600 and were captured as raw text files for analysis. The data were post-processed and visualized using a custom Python script based on the matplotlib library, enabling clear identification of memory retention patterns and resistance state changes across successive cycles.&lt;/p&gt;&lt;head rend="h3"&gt;Hypothesis&lt;/head&gt;&lt;p&gt;The general testing setup, based on that used in the literature, is able to indicate memristive behavior in fungal samples. If present, this behavior would manifest as a characteristic pinched hysteresis loop in the I–V curves, typically intersecting at or near the origin––a well-established signature of memristive systems [6,7]. We hypothesized that such a response would emerge under specific combinations of voltage amplitude and input frequency. Where memristive behavior was indicated, volatile memory tests were conducted.&lt;/p&gt;&lt;head rend="h2"&gt;Results&lt;/head&gt;&lt;head rend="h3"&gt;Overview&lt;/head&gt;&lt;p&gt;The fungal memristors were tested across a range of voltages, waveforms, and frequencies. Below, we first detail the test inputs used to explore the memristive properties and generate I–V curves. Then we present the voltage and frequency (graphical) test results, followed by the volatile memory test results. Each figure represents the averaged, smoothed results across the samples.&lt;/p&gt;&lt;head rend="h3"&gt;Voltage testing&lt;/head&gt;&lt;p&gt;The first five tests were conducted to determine which voltage amplitude produced the most favorable memristive response. These initial trials revealed that a 1 Vpp signal yielded the most consistent and measurable results. As outlined in the Methods section, the first four of these tests were performed using a square wave input.&lt;/p&gt;&lt;head rend="h3"&gt;Frequency testing&lt;/head&gt;&lt;p&gt;After identifying 1 Vpp as the optimal input voltage during the initial square wave tests (Tests 1–4), the waveform was switched to a sine wave for further analysis (Tests 5–10). The aim of this phase was to identify the frequency at which memristive behavior––specifically a pinched hysteresis loop––became apparent.&lt;/p&gt;&lt;p&gt;In Tests 1–5, the voltage amplitude was optimized using square waves. Between Tests 5 and 6, the waveform was changed from square to sine. From Tests 6–10, frequency sweeps were carried out with sine waves to identify memristive crossing. In Test 11, the voltage range was expanded at 10 Hz (5 Vpp) to enhance the response. This revealed behavior close to that of an ideal memristor. Notably, Test 1 had already shown consistent linear behavior, indicating resistive characteristics. The results are shown in Figs 5–13. Fig 14 details a sample noise profile, and Fig 15 summarizes memristive accuracy.&lt;/p&gt;&lt;p&gt;Plot of a 200 mVpp square wave at 200 Hz displaying memcapacitive behavior.&lt;/p&gt;&lt;p&gt;Plot of a 20 Vpp square wave at 200 Hz displaying resistive behavior.&lt;/p&gt;&lt;p&gt;Plot of a 1 Vpp square wave at 200 Hz displaying memcapacitive behavior.&lt;/p&gt;&lt;p&gt;Plot of a 1 Vpp sine wave at 200 Hz displaying memcapacitive behavior.&lt;/p&gt;&lt;p&gt;Plot of a 1 Vpp sine wave at 100 Hz displaying memcapacitive behavior.&lt;/p&gt;&lt;p&gt;Plot of a 1 Vpp sine wave at 25 Hz displaying memristive behavior.&lt;/p&gt;&lt;p&gt;Plot of a 1 Vpp sine wave at 50 Hz displaying memristive behavior.&lt;/p&gt;&lt;p&gt;Plot of a 1 Vpp sine wave at 10 Hz displaying memristive behavior.&lt;/p&gt;&lt;p&gt;Plot of a 5 Vpp sine wave at 10 Hz displaying near-ideal memristive behavior.&lt;/p&gt;&lt;p&gt;Plot of a noisy 1 Vpp sine wave at 10 Hz during measurement.&lt;/p&gt;&lt;p&gt;Memristive accuracy plotted for Tests 1-11.&lt;/p&gt;&lt;p&gt;Figs 5–10 show the output of Tests 2–7. The frequency was gradually reduced until a crossing near the origin was first observed, as shown in Fig 10. To ensure this result was not an outlier caused by overshooting the ideal frequency, the test was repeated at a slightly higher frequency (50 Hz, Test 8, shown in Fig 11). This confirmed that the optimal response occurred below 25 Hz.&lt;/p&gt;&lt;p&gt;As summarized in Table 2, the frequency was decreased to 10 Hz (Test 9, shown in Fig 12), which produced a clear crossing in the I–V curve near the −0.4 V region. To enhance the visibility of this behavior, the voltage was increased to 5 Vpp, which resulted in a more pronounced memristive signature (Test 10). Fig 13 illustrates this result, displaying a nearly ideal pinched hysteresis loop indicative of memristor functionality. The highest accuracy, at 95%, was at a 10 Hz sine wave at 1 V. Fig 14 details the noise from an individual sample. Fig 15 details the average memristive accuracy of each configuration.&lt;/p&gt;&lt;head rend="h3"&gt;Volatile memory experiment&lt;/head&gt;&lt;p&gt;For the volatile memory tests 1 and 2, single read and write operations were performed across the memristor voltage divider. For volatile memory test 3, continuous read and write operations were performed across the memristor voltage divider while the frequency was gradually increased. The primary results are summarized in Table 3. The results are displayed in Figs 16–20. Averaged nemristive accuracy is displayed in Fig 21.&lt;/p&gt;&lt;p&gt;A single write and read over volatile memory.&lt;/p&gt;&lt;p&gt;Another single write and read over volatile memory.&lt;/p&gt;&lt;p&gt;Cyclical writing and reading over the fungal volatile memory.&lt;/p&gt;&lt;p&gt;Additional cyclical writing and reading over the fungal volatile memory.&lt;/p&gt;&lt;p&gt;Extreme cyclical writing and reading from volatile memory.&lt;/p&gt;&lt;p&gt;Accuracy for first two tests and cyclic tests.&lt;/p&gt;&lt;head rend="h2"&gt;Discussion&lt;/head&gt;&lt;head rend="h3"&gt;Overview&lt;/head&gt;&lt;p&gt;Using low-cost materials, shiitake mushrooms were cultured into ideal memristors. Ideal and non-ideal memristive properties have been observed previously in fungi, but these required far more complex interfacing methods [26]. Although several techniques have been proposed to preserve fungal samples, we obtained experimental validation that dehydration can preserve the observed properties in a previously “programmed” sample [27]. Ideal memristor properties are observed at lower frequencies, but potential latencies can be offset through massive parallelization, as in nature [26,28,29]. As known from previous works on fungal memristors, the mycelial structure contains capacitive, memfractive, and memristive proteins [25,26]. In the memristive tests, accuracy decreased as the frequency increased. The observed rapid switching speed of 5,850 Hz, an accuracy of 90% (± 1%) low energy consumption relative to prior conventional systems, light weight, and radiation resistance all make fungal memristors attractive for edge computing, aerospace, and embedded firmware applications [25–27]. Unlike expensive conventional memristors, culturing fungal memristors does not require large facilities or rare minerals. The process can be scaled to grow large systems, which can be programmed and preserved for long-term use at low cost.&lt;/p&gt;&lt;head rend="h3"&gt;Limitations&lt;/head&gt;&lt;p&gt;Our study was limited by the relatively short timescale of less than two months. Other researchers have documented memristive properties in mycelial materials, but their studies also focused on short-term performance [26]. Another limitation was that only single, relatively bulky samples were prepared. To truly compete with conventional devices at the microscale and below, memristors will need to be far smaller [7,8,11]. Even in the same growth medium, each sample produced a vastly different culture, and the outcomes have yet to be fully characterized by electrical properties. However, the development of these devices is in an early stage, and they could eventually be miniaturized, especially using improved cultivation techniques. Complications associated with the growth media were not explored, although previous research has found that fungi are quite robust to varying conditions [26].&lt;/p&gt;&lt;head rend="h3"&gt;Future work&lt;/head&gt;&lt;p&gt;Although fungal memristors can be produced at low cost, certain aspects of the process could be further optimized. First, consistent cultivation techniques could be improved using three-dimensional (3D)-printed templates and structures that shape the shiitake mushroom into the desired geometry. Second, programming could be facilitated by adding electrical contacts into a 3D-printed cultivation structure. Finally, long-term use would necessitate preservation, which could involve a variety of techniques, including dehydration, desiccation, freeze-drying, certain hydrogels, and special coatings [27]. By testing devices produced to physical stress conditions, a combination of these techniques could enable the development of fast, radiation-resistant, and low-energy memristors grown from low-cost organic materials. The future of computing could be fungal.&lt;/p&gt;&lt;head rend="h2"&gt;Conclusions&lt;/head&gt;&lt;p&gt;Currently, the fabrication of semiconductor memristors requires rare-earth minerals and large facilities, and culturing delicate neural organoids requires a complex chemical environment to be maintained in a bioreactor. Fungal computing may provide a robust and accessible alternative. Fungal systems have lower power requirements, lighter weights, faster switching speeds, and lower industrial overheads than conventional devices. In this study, fungal memristors were fabricated, programmed, and tested using shiitake mushrooms and conventional electronics. Dehydration-based preservation was successfully explored, demonstrating the robustness of our devices. When used as RAM, our mushroom memristor was able to operate at up to 5,850 Hz at an accuracy of 90 ± 1%. In addition, shiitake mushrooms are biodegradable and have demonstrated radiation resistance, suggesting that the potential applications of fungal computing range from sustainable computing devices to aerospace technologies.&lt;/p&gt;&lt;head rend="h2"&gt;Acknowledgments&lt;/head&gt;&lt;p&gt;We would like to thank Ryan Lingo and Rajeev Chhajer of the Honda Research Institute.&lt;/p&gt;&lt;head rend="h2"&gt;References&lt;/head&gt;&lt;list rend="ol"&gt;&lt;item&gt;1. Li C, Han L, Jiang H, Jang M-H, Lin P, Wu Q, et al. Three-dimensional crossbar arrays of self-rectifying Si/SiO2/Si memristors. Nat Commun. 2017;8:15666. pmid:28580928&lt;/item&gt;&lt;item&gt;2. Cheng P, Gao S, Zang P, Yang X, Bai Y, Xu H, et al. Hierarchically porous carbon by activation of shiitake mushroom for capacitive energy storage. Carbon. 2015;93:315–24.&lt;/item&gt;&lt;item&gt;3. Lin F, Chen Y, Zhao Y, Wang S. Path tracking of autonomous vehicle based on adaptive model predictive control. International Journal of Advanced Robotic Systems. 2019;16(5).&lt;/item&gt;&lt;item&gt;4. Wang Q, Hu Z, Li Z, Liu T, Bian G. Exploring the Application and Prospects of Synthetic Biology in Engineered Living Materials. Adv Mater. 2025;37(31):e2305828. pmid:37677048&lt;/item&gt;&lt;item&gt;5. Li C, Han L, Jiang H, Jang M-H, Lin P, Wu Q, et al. Three-dimensional crossbar arrays of self-rectifying Si/SiO2/Si memristors. Nat Commun. 2017;8:15666. pmid:28580928&lt;/item&gt;&lt;item&gt;6. Yuan L, Liu S, Chen W, Fan F, Liu G. Organic Memory and Memristors: From Mechanisms, Materials to Devices. Adv Elect Materials. 2021;7(11).&lt;/item&gt;&lt;item&gt;7. Femi O. Unveiling the fourth fundamental circuit element and its real-world applications. In: Chang YF, ed. Memristors – The Fourth Fundamental Circuit Element – Theory, Device, and Applications. IntechOpen; 2024:3–12.&lt;/item&gt;&lt;item&gt;8. Li C, Han L, Jiang H, Jang M-H, Lin P, Wu Q, et al. Three-dimensional crossbar arrays of self-rectifying Si/SiO2/Si memristors. Nat Commun. 2017;8:15666. pmid:28580928&lt;/item&gt;&lt;item&gt;9. Yang C, Sun B, Zhou G, Guo T, Ke C, Chen Y, et al. Photoelectric Memristor-Based Machine Vision for Artificial Intelligence Applications. ACS Materials Lett. 2023;5(2):504–26.&lt;/item&gt;&lt;item&gt;10. Campbell KA, Drake KT, Barney Smith EH. Pulse Shape and Timing Dependence on the Spike-Timing Dependent Plasticity Response of Ion-Conducting Memristors as Synapses. Front Bioeng Biotechnol. 2016;4:97. pmid:28083531&lt;/item&gt;&lt;item&gt;11. Ko T-J, Li H, Mofid SA, Yoo C, Okogbue E, Han SS, et al. Two-Dimensional Near-Atom-Thickness Materials for Emerging Neuromorphic Devices and Applications. iScience. 2020;23(11):101676. pmid:33163934&lt;/item&gt;&lt;item&gt;12. Lu XF, Zhang Y, Wang N, Luo S, Peng K, Wang L, et al. Exploring Low Power and Ultrafast Memristor on p-Type van der Waals SnS. Nano Lett. 2021;21(20):8800–7. pmid:34644096&lt;/item&gt;&lt;item&gt;13. Liao K, Lei P, Tu M, Luo S, Jiang T, Jie W, et al. Memristor Based on Inorganic and Organic Two-Dimensional Materials: Mechanisms, Performance, and Synaptic Applications. ACS Appl Mater Interfaces. 2021;13(28):32606–23. pmid:34253011&lt;/item&gt;&lt;item&gt;14. Sun J, Yang R, Li Q, Zhu R, Jiang Y, Zang L, et al. Living Synthelectronics: A New Era for Bioelectronics Powered by Synthetic Biology. Adv Mater. 2024;36(25):e2400110. pmid:38494761&lt;/item&gt;&lt;item&gt;15. Cheng P, Gao S, Zang P, Yang X, Bai Y, Xu H, et al. Hierarchically porous carbon by activation of shiitake mushroom for capacitive energy storage. Carbon. 2015;93:315–24.&lt;/item&gt;&lt;item&gt;16. Yadav P, Basu A, Suryawanshi A, Game O, Ogale S. Highly Stable Laser‐Scribed Flexible Planar Microsupercapacitor Using Mushroom Derived Carbon Electrodes. Adv Materials Inter. 2016;3(11).&lt;/item&gt;&lt;item&gt;17. Li J, Wu Q, Zan G. Facile synthesis and high electrochemical performance of porous carbon composites for supercapacitors. RSC Adv. 2014;4(66):35186.&lt;/item&gt;&lt;item&gt;18. Joshi S, Cook E, Mannoor MS. Bacterial Nanobionics via 3D Printing. Nano Lett. 2018;18(12):7448–56. pmid:30403141&lt;/item&gt;&lt;item&gt;19. Gómez I, Lavega González R, Tejedor-Calvo E, Pérez Clavijo M, Carrasco J. Odor Profile of Four Cultivated and Freeze-Dried Edible Mushrooms by Using Sensory Panel, Electronic Nose and GC-MS. J Fungi (Basel). 2022;8(9):953. pmid:36135678&lt;/item&gt;&lt;item&gt;20. Fujioka K, Shimizu N, Manome Y, Ikeda K, Yamamoto K, Tomizawa Y. Discrimination method of the volatiles from fresh mushrooms by an electronic nose using a trapping system and statistical standardization to reduce sensor value variation. Sensors (Basel). 2013;13(11):15532–48. pmid:24233028&lt;/item&gt;&lt;item&gt;21. Chung I-M, Kim S-Y, Han J-G, Kong W-S, Jung MY, Kim S-H. Fatty Acids and Stable Isotope Ratios in Shiitake Mushrooms (Lentinula edodes) Indicate the Origin of the Cultivation Substrate Used: A Preliminary Case Study in Korea. Foods. 2020;9(9):1210. pmid:32882944&lt;/item&gt;&lt;item&gt;22. Wu K, de Menezes S, Robinson A. Flagellate Erythema: A Case of Shiitake Dermatitis and Review of Pathogenesis. EMJ Allergy Immunol. 2022.&lt;/item&gt;&lt;item&gt;23. Won DJ, Kim SY, Jang CH, Lee JS, Ko JA, Park HJ. Optimization of UV irradiation conditions for the vitamin D2-fortified shiitake mushroom (Lentinula edodes) using response surface methodology. Food Sci Biotechnol. 2017;27(2):417–24. pmid:30263765&lt;/item&gt;&lt;item&gt;24. Loo HV, Oon HH. Flagellate dermatitis following consumption of shiitake mushroom. Dermatol Reports. 2011;3(2):e21. pmid:25386273&lt;/item&gt;&lt;item&gt;25. Wang H, Tao J, Wu Z, Weiland K, Wang Z, Masania K, et al. Fabrication of Living Entangled Network Composites Enabled by Mycelium. Adv Sci (Weinh). 2024;11(24):e2309370. pmid:38477443&lt;/item&gt;&lt;item&gt;26. Adamatzky A, Ayres P, Beasley AE, Roberts N, Wösten HAB. Logics in Fungal Mycelium Networks. Log Univers. 2022;16(4):655–69.&lt;/item&gt;&lt;item&gt;27. Al-Bedak OA, Sayed RM, Hassan SHA. A new low-cost method for long-term preservation of filamentous fungi. Biocatalysis and Agricultural Biotechnology. 2019;22:101417.&lt;/item&gt;&lt;item&gt;28. Yin S-F, Sun Q-J, Liu L-F, Liu S-Z, Jiang Y-P, Tang X-G. TiO2/Bi4Ti3O12 heterojunction optoelectronic synaptic devices for simulating associative memory and neuromorphic computation. Applied Surface Science. 2025;711:164049.&lt;/item&gt;&lt;item&gt;29. Dixon WJ, Massey FJ. Introduction to statistical analysis. 1951. &lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45771796</guid><pubDate>Fri, 31 Oct 2025 13:32:08 +0000</pubDate></item><item><title>Git CLI tool for intelligently creating branch names</title><link>https://github.com/ytreister/gibr</link><description>&lt;doc fingerprint="e5f60d1a8cefdc99"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;🧩 A smarter CLI for creating Git branches.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;&lt;code&gt;gibr&lt;/code&gt; connects your Git workflow to your issue tracker — instantly creating consistent, descriptive branches.
Fully configurable, and ready for any tracker or team setup.&lt;/p&gt;
    &lt;p&gt;Currently supporting integration with:&lt;/p&gt;
    &lt;code&gt;# List open issues
$ gibr issues
|   Issue | Type   | Title                                 |
|---------|--------|---------------------------------------|
|     123 | issue  | Add support for OAuth2 / login (beta) |
|      97 | issue  | Add support for gitlab                |
# Decide which issue to work
$ gibr 123
Generating branch name for issue #123: Add support for OAuth2 / login (beta)
Branch name: issue/123/add-support-for-oauth2-login-beta
✅  Created branch 'issue/123/add-support-for-oauth2-login-beta' from main.
✅  Checked out branch: issue/123/add-support-for-oauth2-login-beta
✅  Pushed branch 'issue/123/add-support-for-oauth2-login-beta' to origin.&lt;/code&gt;
    &lt;code&gt;uv pip install gibr
# or
pip install gibr&lt;/code&gt;
    &lt;p&gt;Run &lt;code&gt;gibr init&lt;/code&gt; to set up your configuration interactively. This will create a &lt;code&gt;.gibrconfig&lt;/code&gt; file in your project root with the correct format for your chosen issue tracker.&lt;/p&gt;
    &lt;p&gt;Run &lt;code&gt;gibr alias&lt;/code&gt; to set up git alias commands for your conveinence. This essentially allows you to extend the &lt;code&gt;git&lt;/code&gt; CLI with &lt;code&gt;gibr&lt;/code&gt; commands. See alias command for more details&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;gibr&lt;/code&gt; includes an &lt;code&gt;init&lt;/code&gt; command to help you create your &lt;code&gt;.gibrconfig&lt;/code&gt; file. See the following usage example:&lt;/p&gt;
    &lt;code&gt;$ gibr init
Welcome to gibr setup! Let’s get you started 🚀

Which issue tracker do you use?
1. GitHub
2. GitLab
3. Jira
4. Linear
5. Monday.com (coming soon)

Select a number (1, 2, 3, 4, 5) [1]: 1

GitHub selected.

GitHub repository (e.g. user/repo): ytreister/gibr
Environment variable for your GitHub token [GITHUB_TOKEN]:
🎉  Found GitHub token in environment (GITHUB_TOKEN)
.gibrconfig already exists. Overwrite? [y/N]: y
✅  Created .gibrconfig with GitHub settings
You're all set! Try: `gibr issues`
&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;gibr&lt;/code&gt; includes a built-in helper that writes git aliases into your global
&lt;code&gt;~/.gitconfig&lt;/code&gt; for you. Run:&lt;/p&gt;
    &lt;code&gt;gibr alias&lt;/code&gt;
    &lt;p&gt;This adds aliases such as &lt;code&gt;git create&lt;/code&gt; so that instead of using the gibr CLI directly, you can use an extended version of git:&lt;/p&gt;
    &lt;code&gt;git create 123&lt;/code&gt;
    &lt;p&gt;The above command is equivalent to using the CLI as follows: &lt;code&gt;gibr 123&lt;/code&gt; or
&lt;code&gt;gibr create 123&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The flag order when using the &lt;code&gt;git&lt;/code&gt; alias version is different:&lt;/p&gt;
    &lt;code&gt;# ✅ gibr CLI (flags before)
gibr --verbose create 123

# ✅ git alias (flags after)
git create 123 --verbose

# ❌ wrong: flags after gibr CLI
gibr create 123 --verbose 

# ❌ wrong: flags before the alias
git --verbose create 123&lt;/code&gt;
    &lt;p&gt;Run &lt;code&gt;gibr issues&lt;/code&gt; (or &lt;code&gt;git issues&lt;/code&gt;) to view open issues in the issue tracker you have configured&lt;/p&gt;
    &lt;p&gt;Run &lt;code&gt;gibr 123&lt;/code&gt; (or &lt;code&gt;gibr create 123&lt;/code&gt; or &lt;code&gt;git create 123&lt;/code&gt;) to create a branch for the cooresponding issue number.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;gibr&lt;/code&gt; uses the &lt;code&gt;branch_name_format&lt;/code&gt; from your &lt;code&gt;.gibrconfig&lt;/code&gt; to determine the format for the branch.
You can use the following placeholders: &lt;code&gt;{issuetype}&lt;/code&gt;, &lt;code&gt;{issue}&lt;/code&gt;, &lt;code&gt;{title}&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;For Jira, you can specify a &lt;code&gt;project_key&lt;/code&gt; in your configuration:&lt;/p&gt;
    &lt;code&gt;[jira]
project_key=FOO&lt;/code&gt;
    &lt;p&gt;If you do this, you can choose to either specify the entire issue id or just the numerical portion (i.e. &lt;code&gt;FOO-123&lt;/code&gt; or &lt;code&gt;123&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;# List issues
$ gibr issues
| Issue   | Type    | Title       |
|---------|---------|-------------|
| FOO-3   | Subtask | Subtask 2.1 |
| FOO-2   | Story   | Task 2      |
# Create branch for FOO-3
$ gibr 3
Generating branch name for issue FOO-3: Subtask 2.1
Branch name: FOO-3-subtask-2-1
✅  Created branch 'FOO-3-subtask-2-1' from main.
✅  Checked out branch: FOO-3-subtask-2-1
✅  Pushed branch 'FOO-3-subtask-2-1' to origin.&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;--verbose&lt;/code&gt;— enable debug-level logging for a command&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See the Roadmap for upcoming features and plans.&lt;/p&gt;
    &lt;p&gt;See the Contributions guidelines if you would like to contribute.&lt;/p&gt;
    &lt;p&gt;Found a bug or have a feature request? Open an issue or start a discussion.&lt;lb/&gt; If you find it useful, consider starring ⭐️ the repo — it really helps visibility!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45771843</guid><pubDate>Fri, 31 Oct 2025 13:37:10 +0000</pubDate></item><item><title>Ask HN: Who uses open LLMs and coding assistants locally? Share setup and laptop</title><link>https://news.ycombinator.com/item?id=45771870</link><description>&lt;doc fingerprint="38a9cd9f61373adb"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Dear Hackers, I’m interested in your real-world workflows for using open-source LLMs and open-source coding assistants on your laptop (not just cloud/enterprise SaaS). Specifically:&lt;/p&gt;
      &lt;p&gt;Which model(s) are you running (e.g., Ollama, LM Studio, or others) and which open-source coding assistant/integration (for example, a VS Code plugin) you’re using?&lt;/p&gt;
      &lt;p&gt;What laptop hardware do you have (CPU, GPU/NPU, memory, whether discrete GPU or integrated, OS) and how it performs for your workflow?&lt;/p&gt;
      &lt;p&gt;What kinds of tasks you use it for (code completion, refactoring, debugging, code review) and how reliable it is (what works well / where it falls short).&lt;/p&gt;
      &lt;p&gt;I'm conducting my own investigation, which I will be happy to share as well when over.&lt;/p&gt;
      &lt;p&gt;Thanks! Andrea.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45771870</guid><pubDate>Fri, 31 Oct 2025 13:39:55 +0000</pubDate></item><item><title>Immutable releases are now generally available on GitHub</title><link>https://github.blog/changelog/2025-10-28-immutable-releases-are-now-generally-available/</link><description>&lt;doc fingerprint="e116156e4d6ef7a2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Immutable releases are now generally available&lt;/head&gt;
    &lt;p&gt;GitHub releases now support immutability, adding a new layer of supply chain security. With immutable releases, assets and tags are protected from tampering after publication, so the software you publish—and your users consume—remains secure and trustworthy.&lt;/p&gt;
    &lt;head rend="h3"&gt;About immutable releases&lt;/head&gt;
    &lt;p&gt;Immutable releases offer:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Immutable assets: Once you publish a release as immutable, its assets can’t be added, modified, or deleted. This helps protect distributed artifacts from supply chain attacks.&lt;/item&gt;
      &lt;item&gt;Tag protection: Tags for new immutable releases are protected and can’t be deleted or moved.&lt;/item&gt;
      &lt;item&gt;Release attestations: Immutable releases receive signed attestations so you can easily verify the authenticity and integrity of assets, both on GitHub and in external environments.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;How to enable immutable releases&lt;/head&gt;
    &lt;p&gt;You can enable immutable releases at the repository or organization level in your settings. Once enabled:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;All new releases are immutable (i.e., assets are locked and tags are protected).&lt;/item&gt;
      &lt;item&gt;Existing releases remain mutable unless you republish them.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Disabling immutability doesn’t affect releases created while it was enabled. They remain immutable.&lt;/p&gt;
    &lt;head rend="h3"&gt;Release attestations and verification&lt;/head&gt;
    &lt;p&gt;Release attestations let you verify that an artifact is authentic and unchanged, even outside GitHub. Attestations use the Sigstore bundle format, so you can easily verify releases and assets using the GitHub CLI or integrate with any Sigstore-compatible tooling to automate policy enforcement in your CI/CD pipelines. For instructions on how to verify the integrity of a release, see our docs on verifying the integrity of a release.&lt;/p&gt;
    &lt;p&gt;We’d love your feedback. Share your thoughts and questions on the GitHub Community.&lt;/p&gt;
    &lt;p&gt;For more information, see our immutable releases documentation.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45772064</guid><pubDate>Fri, 31 Oct 2025 13:59:25 +0000</pubDate></item><item><title>Rotating Workforce Scheduling in MiniZinc</title><link>https://zayenz.se/blog/post/rotating-workforce-scheduling/</link><description>&lt;doc fingerprint="2f185416e1005eff"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Rotating Workforce Scheduling in MiniZinc DRAFT&lt;/head&gt;
    &lt;p&gt;Workforce scheduling is a classical optimization problem. Improved schedules can be better both for the workers and for the business, but are often surprisingly hard to find. One common variant of scheduling is called Rotating Workforce Scheduling (shortened as RWS), and is sometimes called cyclic scheduling. In RWS, a weekly schedule is created for a group of workers covering the projected needs. Each worker will rotate through the schedule, working all different weeks.&lt;/p&gt;
    &lt;p&gt;Solving RWS is a challenging problem, both for manual and automatic approaches. This post will describe developing a reasonably realistic variant of finding an RWS schedule using MiniZinc. Starting with the basic structure and then adding more and more typical requirements to get realistic schedules.&lt;/p&gt;
    &lt;head rend="h2"&gt;What is a rotating schedule?&lt;/head&gt;
    &lt;p&gt;What does it mean to rotate through a schedule? If there are employees, then different weekly schedules are created. Each employee follows one week-schedule, and every week all employees shift to the next schedule in the rotation. This ensures fairness: everyone eventually experiences each schedule pattern. Using this type of schedule is useful for cases where there is a variety of requirements, usually involving work outside of normal office hours.&lt;/p&gt;
    &lt;p&gt;In this post we will keep to a fairly simple model that is still realistic, with D day shifts, E evening shifts, N night shifts, and finally · off days.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="8"&gt;
        &lt;cell role="head"&gt;#&lt;/cell&gt;
        &lt;cell role="head"&gt;Mon&lt;/cell&gt;
        &lt;cell role="head"&gt;Tue&lt;/cell&gt;
        &lt;cell role="head"&gt;Wed&lt;/cell&gt;
        &lt;cell role="head"&gt;Thu&lt;/cell&gt;
        &lt;cell role="head"&gt;Fri&lt;/cell&gt;
        &lt;cell role="head"&gt;Sat&lt;/cell&gt;
        &lt;cell role="head"&gt;Sun&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Use the week buttons above to see how each employee’s schedule changes as the rotation progresses.&lt;/p&gt;
    &lt;p&gt;There are many cases where the scheduling needs are for more detailed levels, not just three types of shifts. Still, this level of detail is often usable, and will allow us to reason about the problem at a simple level.&lt;/p&gt;
    &lt;head rend="h2"&gt;A basic MiniZinc model&lt;/head&gt;
    &lt;p&gt;First we will look at a basic model that handles the data, the instances, and the basic constraints and printing. In the next section, we will add the constraints for the labor rules to turn a basic schedule into something that could be used in practice.1&lt;/p&gt;
    &lt;head rend="h3"&gt;Problem Domain&lt;/head&gt;
    &lt;p&gt;The first step in writing a MiniZinc model is to set up the data-definitions. There are three axis that are needed, the days, the employees, and the shifts.&lt;/p&gt;
    &lt;p&gt;In the above code, the days are named as an enum. A separate set of days for a weekend is also defined, as that will be needed in some constraints. While &lt;code&gt;{Sat, Sun}&lt;/code&gt; could be used directly in the code it is better to have it named.&lt;/p&gt;
    &lt;p&gt;The enum &lt;code&gt;ShiftsAndOff&lt;/code&gt; represent all the types of shifts (day, evening, and night) as well as off days.
A subset &lt;code&gt;Shifts&lt;/code&gt; is defined from this with just the shifts.2&lt;/p&gt;
    &lt;head rend="h3"&gt;Data and instance&lt;/head&gt;
    &lt;p&gt;Each scheduling problem includes some data that defines the problem.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;employees&lt;/code&gt; integer tells us the number of employees, while the &lt;code&gt;requirements&lt;/code&gt;
matrix tells us the number of people needed for working a shift on each weekday.
In the model the &lt;code&gt;Employees&lt;/code&gt; will correspond to one week schedule each.
The rotation among employees is something that is done with the result of the model.&lt;/p&gt;
    &lt;p&gt;The number of employees and the requirements are defined in a data-file. The following data will be used as the running example.&lt;/p&gt;
    &lt;head rend="h3"&gt;Variables and meeting requirements&lt;/head&gt;
    &lt;p&gt;The most important part of defining a constraint programming model is usually deciding on a viewpoint. That means deciding what variables will be used to describe a solution to the problem. Here we will use a straight-forward viewpoint, with a Shift variable for each day and employee.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;schedule&lt;/code&gt; array maps each day and employee to a variable shift.&lt;/p&gt;
    &lt;p&gt;Some constraints will go over different weeks for more global properties. Since this is rotating workforce scheduling, the first week will follow the last week. The &lt;code&gt;repeated_schedule&lt;/code&gt; array of variables is defined with the first employee’s week
repeated again at the end, unrolled into one single sequence.
This makes it easier to state these rules that have properties that go across weeks.
Note that if any of the constraints were over longer periods than one week,
more than one week would need to be added.
As an example, consider the following unrealistic schedule and
the unrolled repeated schedule where the first row is repeated at the end.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The core (and only) constraint for the basic model is that for each day of the week the right number of people needs to work each shift. The &lt;code&gt;global_cardinality&lt;/code&gt; constraint
is made for counting the number of occurences of different values.
In this case, there is one such constraint per day where the count of each of the different shifts scheduled
are set to be at least as much as the requirement, and at most as much as the requirement.
Since not all employees will work in a day, the remaining employees will be scheduled as &lt;code&gt;Off&lt;/code&gt;,
the only &lt;code&gt;ShiftsAndOff&lt;/code&gt; member that is not limited.&lt;/p&gt;
    &lt;head rend="h3"&gt;Solving and printing solutions&lt;/head&gt;
    &lt;p&gt;The only remaining part is to indicate that this is a satisfaction problem and to print a solution.&lt;/p&gt;
    &lt;p&gt;Using &lt;code&gt;solve satisfy;&lt;/code&gt; means that any valid solution is ok, there is no objective to optimize.
The printing function will give a visual example of how the schedule looks like.
Running this model in the MiniZinc IDE version 2.9.4
with the Gecode solver and statistics added gives the following output.&lt;/p&gt;
    &lt;p&gt;This solution can be visualized using the same solution visualizer as above.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="8"&gt;
        &lt;cell role="head"&gt;#&lt;/cell&gt;
        &lt;cell role="head"&gt;Mon&lt;/cell&gt;
        &lt;cell role="head"&gt;Tue&lt;/cell&gt;
        &lt;cell role="head"&gt;Wed&lt;/cell&gt;
        &lt;cell role="head"&gt;Thu&lt;/cell&gt;
        &lt;cell role="head"&gt;Fri&lt;/cell&gt;
        &lt;cell role="head"&gt;Sat&lt;/cell&gt;
        &lt;cell role="head"&gt;Sun&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The solution meets the resource requirements, but it is not a usable schedule. Most of the work is in one long chunk without resting days, and there is no consideration for weekends or for how to handle night work.&lt;/p&gt;
    &lt;p&gt;From the statistics, we can see that there are 7 propagators, which is one global constraint propagator for each day. The search is backtrack free (no failures), since it is easy to construct the schedule. The solve time is less than a millisecond.&lt;/p&gt;
    &lt;head rend="h2"&gt;Adding rules&lt;/head&gt;
    &lt;p&gt;As mentioned above, the schedule produced with the basic model is not actually usable. In this section, additional rules for schedules will be added one by one.&lt;/p&gt;
    &lt;head rend="h3"&gt;Consecutive Days Off Each Week&lt;/head&gt;
    &lt;p&gt;A common requirement in many jurisdictions is that employees should get two consecutive days off each calendar week. This can be added as a constraint for each week.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;regular&lt;/code&gt; constraint
was originally introduced in order to handle scheduling patterns3.
The constraint is defined using Finite Automata4,
which can be generated from regular expressions.
Here we are using the MiniZinc version that accepts a string with a regular expression.
These strings can include enum names, and use the &lt;code&gt;.&lt;/code&gt; character for wild-cards and &lt;code&gt;*&lt;/code&gt; for repetitions 0 or more times.
The string &lt;code&gt;".* Off Off .*"&lt;/code&gt; means that the week will start with zero or more days with anything scheduled,
then at some point there will be two &lt;code&gt;Off&lt;/code&gt; days, then zero or more additional days.
Or in other words, each week contains at least two consecutive &lt;code&gt;Off&lt;/code&gt; days.&lt;/p&gt;
    &lt;p&gt;Running with this constraint gives us a new result.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="8"&gt;
        &lt;cell role="head"&gt;#&lt;/cell&gt;
        &lt;cell role="head"&gt;Mon&lt;/cell&gt;
        &lt;cell role="head"&gt;Tue&lt;/cell&gt;
        &lt;cell role="head"&gt;Wed&lt;/cell&gt;
        &lt;cell role="head"&gt;Thu&lt;/cell&gt;
        &lt;cell role="head"&gt;Fri&lt;/cell&gt;
        &lt;cell role="head"&gt;Sat&lt;/cell&gt;
        &lt;cell role="head"&gt;Sun&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;This is starting to look a lot more reasonable. Each week has some time off, and therefore the maximum length of time worked is a lot less. The statistics show that there are now some backtracks, but still not very many. The solve time is still in the milliseconds range.&lt;/p&gt;
    &lt;head rend="h3"&gt;Maximum Days Without Rest&lt;/head&gt;
    &lt;p&gt;One thing that can be seen in the previous solution is that sometimes there are runs where an employee will work for seven days in a row. One common restriction for many areas is to limit the maximum number of days in a row that work is scheduled. Here we will use the limit of 5, so that at most five days in a row are scheduled. Note that while both the previous rule and this rule enforce a certain amount of time off, they are complementary and non-dominating. There are schedules that satisfy one rule but not the other, and vice versa.&lt;/p&gt;
    &lt;p&gt;The first step is to create a set of auxiliary Boolean variables &lt;code&gt;off_days&lt;/code&gt; that indicate if a certain day is an off day.
This is done for the &lt;code&gt;repeated_schedule&lt;/code&gt; in order to not have a schedule with the first five days with work and the last five days in the
last week with work.
The &lt;code&gt;sliding_sum&lt;/code&gt; constraint is used to enforce that
in each consecutive subsequence of a certain length, the sum of values is within a certain range.
Here, in each subsequence of length 6, the sum must be in the range , so there is at least one day that is an off day.5&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="8"&gt;
        &lt;cell role="head"&gt;#&lt;/cell&gt;
        &lt;cell role="head"&gt;Mon&lt;/cell&gt;
        &lt;cell role="head"&gt;Tue&lt;/cell&gt;
        &lt;cell role="head"&gt;Wed&lt;/cell&gt;
        &lt;cell role="head"&gt;Thu&lt;/cell&gt;
        &lt;cell role="head"&gt;Fri&lt;/cell&gt;
        &lt;cell role="head"&gt;Sat&lt;/cell&gt;
        &lt;cell role="head"&gt;Sun&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;This version of the schedule looks a lot more reasonable just in the shape of working and off days. There is time off every week, and there is never more than 5 days of work. The statistics show that there are now significantly more backtracks, but the solve time is in the tens of milliseconds range.&lt;/p&gt;
    &lt;head rend="h3"&gt;Weekend Rest Requirements&lt;/head&gt;
    &lt;p&gt;There is one remaining obvious problem with the off days in the schedule: all the working weekends are clustered. One common rule is that workers will need at least one out of every 3 weekends off.&lt;/p&gt;
    &lt;p&gt;We will use a similar technique as above with auxiliary variables, but here the variables will represent if a weekend is free. The definition of that is that both the days of the weekend for that employee / row in the schedule has &lt;code&gt;Off&lt;/code&gt; in the schedule.
Another &lt;code&gt;sliding_sum&lt;/code&gt; constraint is used for sub-sequences of length 3, ensuring at least one weekend is rest.
One interesting difference is that the constraint is over &lt;code&gt;free_weekend ++ free_weekend&lt;/code&gt; since
this constraint needs to see three weeks at a time and needs selected information for some days.
The &lt;code&gt;repeated_schedule&lt;/code&gt; is not usable here.
It is an unrolled schedule, which would make it harder to extract weekends.
In addition, it would need more than one extra week at the end.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="8"&gt;
        &lt;cell role="head"&gt;#&lt;/cell&gt;
        &lt;cell role="head"&gt;Mon&lt;/cell&gt;
        &lt;cell role="head"&gt;Tue&lt;/cell&gt;
        &lt;cell role="head"&gt;Wed&lt;/cell&gt;
        &lt;cell role="head"&gt;Thu&lt;/cell&gt;
        &lt;cell role="head"&gt;Fri&lt;/cell&gt;
        &lt;cell role="head"&gt;Sat&lt;/cell&gt;
        &lt;cell role="head"&gt;Sun&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Looking at the weekends, this schedule is starting to look ok. The off days are in a decent pattern in general. Looking at the statistics, the number of failures and the time is roughly the same as before.&lt;/p&gt;
    &lt;head rend="h3"&gt;Night Shift Limits&lt;/head&gt;
    &lt;p&gt;The most important part left that makes the schedule bad is that there is no consideration for rest around night shifts. Night shifts are taxing and require rest. We will follow a common restriction that night shifts are only allowed when there is rest both before and after. In addition, a maximum of three night shifts in a row are allowed.&lt;/p&gt;
    &lt;p&gt;The above (deterministic) finite state automaton represents the allowed transitions between days. Starting in the &lt;code&gt;O&lt;/code&gt; state, everything is ok the next day.
For day and evening shifts, the next state is the &lt;code&gt;DE&lt;/code&gt; state, where everything except night shifts are ok (with off shifts going back to &lt;code&gt;O&lt;/code&gt;).
From the &lt;code&gt;O&lt;/code&gt; state, night shifts can be assigned.
The &lt;code&gt;N1&lt;/code&gt;, &lt;code&gt;N2&lt;/code&gt;, and &lt;code&gt;N3&lt;/code&gt; states are used as counters for how many night shifts have been assigned, and after the third one there must be a rest day.&lt;/p&gt;
    &lt;p&gt;The state machine can be expressed in MiniZinc as the state transtition table. It goes over the &lt;code&gt;States&lt;/code&gt; and the values, with either the next state or none (&lt;code&gt;&amp;lt;&amp;gt;&lt;/code&gt;) if there is no transition for that value in that state.
Adding this constraint gives us the following schedule.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="8"&gt;
        &lt;cell role="head"&gt;#&lt;/cell&gt;
        &lt;cell role="head"&gt;Mon&lt;/cell&gt;
        &lt;cell role="head"&gt;Tue&lt;/cell&gt;
        &lt;cell role="head"&gt;Wed&lt;/cell&gt;
        &lt;cell role="head"&gt;Thu&lt;/cell&gt;
        &lt;cell role="head"&gt;Fri&lt;/cell&gt;
        &lt;cell role="head"&gt;Sat&lt;/cell&gt;
        &lt;cell role="head"&gt;Sun&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;This schedule is quite realistic, with typical major scheduling rules taken into consideration. Again using Gecode and the standard search, there are not that many failures and the search time is quite low.&lt;/p&gt;
    &lt;head rend="h2"&gt;Benchmarking the model&lt;/head&gt;
    &lt;p&gt;Testing a model on just one instance is not that interesting. The model here is an updated version of one that I developed for a poster at Stockholm Optimization Days 2022. For that poster, I generated a benchmark set with employees from 5 to 30, with 10 instances for each size. In total, there are 70 instances. Making a rotating schedule for 30 employees at once is not that common, but it is still useful to measure how different solvers behave at different sizes. For background on how to benchmark a MiniZinc program, see On Benchmarking MiniZinc and the LinkedIn Queens Problem.&lt;/p&gt;
    &lt;p&gt;All tests are run using MiniZinc 2.9.4 on a Mac M1 Max with 64 GiB of memory. We will test the following solvers&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Gecode 6.3.0, a traditional CP solver&lt;/item&gt;
      &lt;item&gt;OR-Tools 9.14, a Lazy Clause Generation portfolio solver&lt;/item&gt;
      &lt;item&gt;Chuffed 0.13.2, a Lazy Clasue Generation solver&lt;/item&gt;
      &lt;item&gt;COIN CBC (2.10.12/1.17.10), an older MIP solver&lt;/item&gt;
      &lt;item&gt;HiGHS (1.1.0), a modern MIP solver&lt;/item&gt;
      &lt;item&gt;Huub 0.1.0, a Lazy Clause Generation solver&lt;/item&gt;
      &lt;item&gt;Pumpkin 0.1, a Lazy Clause Generation solver&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Each solver is run with a time-out of 60 seconds. All solvers are tested both single-threaded and with 10 threads with free search enabled. Note that CBC was excluded from the multi-threaded testing, as it interpreted the time-out to be based on user time and not wall-clock time.&lt;/p&gt;
    &lt;p&gt;For testing, you can download the full MiniZinc model as well as the example instance and the full set of benchmark instances.&lt;/p&gt;
    &lt;head rend="h3"&gt;Cactus plots 🌵&lt;/head&gt;
    &lt;p&gt;As the main comparison, we will look at cactus plots. These plots show how many instances can be solved in a cumulative time, with the time plotted on a log scale.&lt;/p&gt;
    &lt;p&gt;In this plot, we can see that Gecode is quite fast for the simple problems. However, after a while OR-Tools CP-SAT catches up and wins handily. COIN-OR CBC only solved a few instances, so it is not really interesting for this model. HiGHS, as a representative of modern MIP solvers was apart from CBC the slowest solver, although in the end it solved more than Chuffed and single-threaded Gecode. In previous experiments, I’ve seen that the automaton for night shift limits seems to be tricky for MIP solvers. It is interesting to note that Huub, while being quite a new solver, did almost as well as CP-SAT.&lt;/p&gt;
    &lt;p&gt;The above graph looks at total wall-clock time to run each solver, including translation from MiniZinc. This plot looks instead only at the self-reported solve times from the solvers.&lt;/p&gt;
    &lt;p&gt;The main take-away is that Gecode is quite fast for the simple problems, while OR-Tools CP-SAT is slower to get started but better in total. These differences in the starting phase are “hidden” by the common cost of translating from MiniZinc in the wall clock time plot.&lt;/p&gt;
    &lt;head rend="h3"&gt;Run time vs number of employees&lt;/head&gt;
    &lt;p&gt;It is natural to think that the run-times will change depending on the number of employees. In this plot, the run-times are summed for each employee count, and plotted. Time-outs are counted as the full 60 seconds, and the opacity of the lines is set by the amount of solved instances.&lt;/p&gt;
    &lt;p&gt;From this, we can see that above 15 employees, CP-SAT with 10 threads looks like a clear winner. If we instead take the average of solved instances, the view is slightly different.&lt;/p&gt;
    &lt;p&gt;What is interesting to note here is that for the instances that are solved Gecode is surprisingly efficient for large instances. This might be a selection effect (only the simple cases are solved), but it might also indicate that the right heuristic could be very useful.&lt;/p&gt;
    &lt;head rend="h3"&gt;OR-Tools CP-SAT version&lt;/head&gt;
    &lt;p&gt;As was argued in The Work Task Variation Problem, the development of CP-SAT has made significant improvements. To test this, three older versions of OR-Tools CP-SAT are tested against the current version.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;9.14 (current version, June 2025)&lt;/item&gt;
      &lt;item&gt;9.12 (February 2025)&lt;/item&gt;
      &lt;item&gt;9.7 (August, 2023)&lt;/item&gt;
      &lt;item&gt;9.3 (March, 2022)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;First lets look at the cactus plots&lt;/p&gt;
    &lt;p&gt;It’s interesting to see that version 9.14 for this fairly simple problem is slightly slower in the multi-threaded version than the 9.3 and 9.7. At the same time, it is slightly faster in the single-threaded configuration. It is also very similar to version 9.12.&lt;/p&gt;
    &lt;p&gt;Looking at the performance based on the number of employees, we can see that although the cactus plot for version 9.7 with 10 threads looked better, the slope is worse. This means that the newer version, while slower in general, seems to be more robust in solving the problem over different sizes.&lt;/p&gt;
    &lt;head rend="h2"&gt;Custom Search Strategy&lt;/head&gt;
    &lt;p&gt;All of the above tests are made with a simple &lt;code&gt;solve satisfy;&lt;/code&gt; statement.
However, it is also possible to specify search annotations in MiniZinc.&lt;/p&gt;
    &lt;p&gt;There are more constraints over the weekends than there are over weekdays, and there are also more constraints over night shifts than over day and evening shifts. Therefore, it seems likely that it would be a good idea to assign shifts on weekends first, and to focus on night shifts first. A search specification would look like this.&lt;/p&gt;
    &lt;p&gt;The above code collects all the weekend-days, and asks the solver to assign them in order. By re-mapping the enum values to known integers, we can make sure that night shifts are tried first, then evening and day, and the last to be tested is off days. Note that this annotation is only for some of the days, not the full schedule, the remaining variables will be assigned using the default strategy of the solver.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="8"&gt;
        &lt;cell role="head"&gt;#&lt;/cell&gt;
        &lt;cell role="head"&gt;Mon&lt;/cell&gt;
        &lt;cell role="head"&gt;Tue&lt;/cell&gt;
        &lt;cell role="head"&gt;Wed&lt;/cell&gt;
        &lt;cell role="head"&gt;Thu&lt;/cell&gt;
        &lt;cell role="head"&gt;Fri&lt;/cell&gt;
        &lt;cell role="head"&gt;Sat&lt;/cell&gt;
        &lt;cell role="head"&gt;Sun&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;N&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;E&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
        &lt;cell&gt;·&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Unfortunately, this turned out not to be a good idea. Gecode is a traditional CP solver, and as such it gains the most from good search annotations. However, in the below cactus plot and time for different employees, we can see that it is in general worse.&lt;/p&gt;
    &lt;p&gt;It is worth experimenting with search heuristics, even if they don’t always pan out. In a previous model for a similar problem a similar idea was good, but here it was worse than the automatic heuristics.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary&lt;/head&gt;
    &lt;p&gt;The above model shows how developing a model for a realistic problem can proceed. It will often not be as straightforward as this, but with the right view-point and a judicious use of extra variables many constraints are often natural to express. Doing the right experiments, and letting the choice of solver be data-driven is also very important.&lt;/p&gt;
    &lt;p&gt;The model here is as mentioned for a simplified version of many real-world rotating workforce scheduling problems. There is no optimization, while noramlly the goal is to optimize some parameter of the scheduel. As for the data-model, it is common to not just have a set few different work types but instead to have custom and varied shifts with different start and end times. With that, there will be issues such as the total amount of work per week, resting times between work, ensuring enough rest over an off weekend, and so on. Even more important is to also take into account wishes and requests form the staff. Without their input, it is hard to make a schedule that will be appreciated.&lt;/p&gt;
    &lt;head rend="h2"&gt;Footnotes&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;The model here is partially inspired by the model in “Solver Independent Rotating Workforce Scheduling” by Musliu, Schutt, and Stuckey published at CPAIOR 2018. The specific constraints used are custom, and were originally developed for and published as a poster at Stockholm Optimization Days 2022. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;It’s important to note that the&lt;/p&gt;&lt;code&gt;Shifts&lt;/code&gt;are the first elements from&lt;code&gt;ShiftsAndOff&lt;/code&gt;. This means that when defining arrays of matrices that only index on&lt;code&gt;Shifts&lt;/code&gt;, these start at 1, which ensures that there is no extra conversions needed. It would also be possible to define&lt;code&gt;Shifts&lt;/code&gt;as an enum, and then add a new enum&lt;code&gt;enum ShiftsAndOff = S(Shifts) ++ { Off };&lt;/code&gt;, where the Off could go on either side. ↩&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The regular constraint was introduced in “A Regular Language Membership Constraint for Finite Sequences of Variables” by Gilles Pesant at CP 2004. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The original paper used Deterministic Finite Automata only, but as I noted in my licentiate thesis, the algorithm works also for Nondeterministic Finite Automata. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Equivalently, one could have defined auxiliary variables&lt;/p&gt;&lt;code&gt;working_days&lt;/code&gt;that are the inverse of&lt;code&gt;off_days&lt;/code&gt;, and used&lt;code&gt;sliding_sum(0, 5, 6, working_days)&lt;/code&gt;to indicate that a maximum of 5 days are spent working in a subsequence of length 6. ↩&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45772153</guid><pubDate>Fri, 31 Oct 2025 14:09:04 +0000</pubDate></item><item><title>Nim 2.2.6</title><link>https://nim-lang.org//blog/2025/10/31/nim-226.html</link><description>&lt;doc fingerprint="2b139df8543d1ed9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Nim version 2.2.6 released&lt;/head&gt;
    &lt;head rend="h3"&gt;31 October 2025 The Nim Team&lt;/head&gt;
    &lt;p&gt;The Nim Team is happy to announce version 2.2.6, the third patch release for our stable release, Nim 2.2.&lt;/p&gt;
    &lt;p&gt;It comes six months after the 2.2.4 release and it contains 141 commits, bringing bugfixes and improvements.&lt;/p&gt;
    &lt;p&gt;If youâre still on Nim 1.6, take a look at the version 2.0 release article to see all the features youâre missing. If youâve been using Nim 2.0, the version 2.2 release article shows the improvements available in Nim 2.2.&lt;/p&gt;
    &lt;p&gt;The Nim 2.2.6 changelog is available here.&lt;/p&gt;
    &lt;head rend="h2"&gt;Highlights&lt;/head&gt;
    &lt;p&gt;Exception handling combined with Nimâs &lt;code&gt;async&lt;/code&gt; is more stable than ever before
as the underlying closure iterator transformation has been rewritten.&lt;/p&gt;
    &lt;p&gt;The compiler is now smart enough to produce a move operation for &lt;code&gt;return obj.field&lt;/code&gt;.
Previously it performed a copy.
Expect your code to run slightly faster due to this and other minor performance improvements.&lt;/p&gt;
    &lt;head rend="h2"&gt;Installing Nim 2.2.6&lt;/head&gt;
    &lt;p&gt;Check out if the package manager of your OS already ships version 2.2.6 or install it as described here.&lt;/p&gt;
    &lt;p&gt;If you have installed a previous version of Nim using &lt;code&gt;choosenim&lt;/code&gt;,
getting Nim 2.2.6 is as easy as:&lt;/p&gt;
    &lt;code&gt;$ choosenim update self
$ choosenim update stable
&lt;/code&gt;
    &lt;p&gt;NOTE: We recommend you to install and use the latest version of &lt;code&gt;choosenim&lt;/code&gt;, v.0.8.16, available in our choosenim repo.&lt;/p&gt;
    &lt;p&gt;Alternatively, you can download Nim 2.2.6 from our nightlies builds.&lt;/p&gt;
    &lt;head rend="h2"&gt;Bugfixes&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fixed â&lt;code&gt;=destroy&lt;/code&gt;for non-var failed to compile when JSâ (#24914)&lt;/item&gt;
      &lt;item&gt;Fixed â&lt;code&gt;{.push raises: [].}&lt;/code&gt;doesnât respect lexical scopingâ (#23355)&lt;/item&gt;
      &lt;item&gt;Fixed âPragma block disabling warning has effect beyond blockâ (#21975)&lt;/item&gt;
      &lt;item&gt;Fixed âmissing &lt;code&gt;&amp;lt;&lt;/code&gt;(less than),&lt;code&gt;cmp&lt;/code&gt;for&lt;code&gt;cstring&lt;/code&gt;â (#24941)&lt;/item&gt;
      &lt;item&gt;Fixed â[GC] Illegal storage access when collecting cycleâ (#4851)&lt;/item&gt;
      &lt;item&gt;Fixed âGlobals in proc with static params end up being re-initializedâ (#24940)&lt;/item&gt;
      &lt;item&gt;Fixed âConstructor to global variable in converter generates illegal c codeâ (#4594)&lt;/item&gt;
      &lt;item&gt;Fixed âCompile-time regression from v2.2.4 to &lt;code&gt;version-2-2&lt;/code&gt;/&lt;code&gt;devel&lt;/code&gt;with&lt;code&gt;global&lt;/code&gt;variable with&lt;code&gt;unhandled exception: iterators.nim(254, 11) len(a) == L the length of the seq changed while iterating over it [AssertionDefect]&lt;/code&gt;â (#24981)&lt;/item&gt;
      &lt;item&gt;Fixed âSIGSEGV when raising &lt;code&gt;Defect&lt;/code&gt;/doAssertâ (#24974)&lt;/item&gt;
      &lt;item&gt;Fixed âCrash on marking destroy hook as .errorâ (#24996)&lt;/item&gt;
      &lt;item&gt;Fixed â&lt;code&gt;hasCustomPragma&lt;/code&gt;stops working after typedesc is copiedâ (#23564)&lt;/item&gt;
      &lt;item&gt;Fixed âAsyncnet accept leaks socket on SSL error; Regression in develâ (#25023)&lt;/item&gt;
      &lt;item&gt;Fixed âSIGSEGV in closure iterator with try/except not at top levelâ (#21235)&lt;/item&gt;
      &lt;item&gt;Fixed âRegression from v2.2.4 to &lt;code&gt;version-2-2&lt;/code&gt;/&lt;code&gt;devel&lt;/code&gt;with closure iteratorâ (#25038)&lt;/item&gt;
      &lt;item&gt;Fixed âfixes #24997; {.global.} variable in recursive functionâ (#25016)&lt;/item&gt;
      &lt;item&gt;Fixed âconcept param passed to varargs causes &lt;code&gt;internal error: genTypeInfo(tyUserTypeClassInst)&lt;/code&gt;when JS backendâ (#25043)&lt;/item&gt;
      &lt;item&gt;Fixed âBad order of destructionâ (#24719)&lt;/item&gt;
      &lt;item&gt;Fixed âFloats are not range checkedâ (#7179)&lt;/item&gt;
      &lt;item&gt;Fixed âtypo in docsâ (#25084)&lt;/item&gt;
      &lt;item&gt;Fixed âRegression from Nim v2.2.2 to v2.2.4/&lt;code&gt;version-2-2&lt;/code&gt;/devel in&lt;code&gt;nim cpp&lt;/code&gt;with compatible types not keeping L-valuenessâ (#25109)&lt;/item&gt;
      &lt;item&gt;Fixed â&lt;code&gt;FieldDefect&lt;/code&gt;compiler crash when comparing pointers at compile timeâ (#25066)&lt;/item&gt;
      &lt;item&gt;Fixed âSlow compilation due to &lt;code&gt;vmgen.sameConstant&lt;/code&gt;and memory allocationsâ (#25114)&lt;/item&gt;
      &lt;item&gt;Fixed â&lt;code&gt;unhandled exception: field 'sym' is not accessible for type 'TNode' using 'kind = nkEmpty' [FieldDefect]&lt;/code&gt;with iterator-loopâ (#25121)&lt;/item&gt;
      &lt;item&gt;Fixed â&lt;code&gt;strutils.formatSize&lt;/code&gt;returns wrong values from large values close to int64.highâ (#25125)&lt;/item&gt;
      &lt;item&gt;Fixed âDereferencing result of &lt;code&gt;cast&lt;/code&gt;in single expression triggers unnecessary copyâ (#24093)&lt;/item&gt;
      &lt;item&gt;Fixed â&lt;code&gt;internal error: '=destroy' operator not found for type NimNode&lt;/code&gt;returning&lt;code&gt;NimNode&lt;/code&gt;â (#25120)&lt;/item&gt;
      &lt;item&gt;Fixed â&lt;code&gt;requiresInit&lt;/code&gt;not checked for&lt;code&gt;result&lt;/code&gt;if it has been used (2.2 regression)â (#25117)&lt;/item&gt;
      &lt;item&gt;Fixed â&lt;code&gt;filterIt&lt;/code&gt;wrongly results in rvalueâ (#25078)&lt;/item&gt;
      &lt;item&gt;Fixed â&lt;code&gt;@&lt;/code&gt;extremely slow for trivial typesâ (#25063)&lt;/item&gt;
      &lt;item&gt;Fixed âwithValue for immut tab wrong chk condâ (#25162)&lt;/item&gt;
      &lt;item&gt;Fixed âInvalid C codegen &lt;code&gt;refc&lt;/code&gt;with generic types containing gc memoryâ (#24844)&lt;/item&gt;
      &lt;item&gt;Fixed âSinglyLinkedList.remove broken / AssertionDefectâ (#25173)&lt;/item&gt;
      &lt;item&gt;Fixed â&lt;code&gt;error: âT2_â undeclared&lt;/code&gt;and&lt;code&gt;error: incompatible types when assigning to type âvoid *â&lt;/code&gt;â (#24361)&lt;/item&gt;
      &lt;item&gt;Fixed âNoncopyable base type ignoredâ (#24760)&lt;/item&gt;
      &lt;item&gt;Fixed â&lt;code&gt;lent string&lt;/code&gt;generic field isnât preserving its valueâ (#25127)&lt;/item&gt;
      &lt;item&gt;Fixed âcannot return &lt;code&gt;lent&lt;/code&gt;expression from conditionals like&lt;code&gt;case&lt;/code&gt;â (#23949)&lt;/item&gt;
      &lt;item&gt;Fixed â&lt;code&gt;Error: internal error: proc has no result symbol&lt;/code&gt;â (#21476)&lt;/item&gt;
      &lt;item&gt;Fixed âInvalid codegen / dangling pointer for openArray escaping from &lt;code&gt;block&lt;/code&gt;â (#24261)&lt;/item&gt;
      &lt;item&gt;Fixed âlib/system/iterators.nim(250, 14) Error: internal error: genArrayLen()â (#25167)&lt;/item&gt;
      &lt;item&gt;Fixed â&lt;code&gt;Error: unhandled exception: field 'sym' is not accessible for type 'TNode'&lt;/code&gt;â (#21138)&lt;/item&gt;
      &lt;item&gt;Fixed â&lt;code&gt;error: âpthread_mutex_tâ has no member named âabiâ&lt;/code&gt;in refc with&lt;code&gt;reset&lt;/code&gt;/&lt;code&gt;{.exportc.}&lt;/code&gt;â (#25205)&lt;/item&gt;
      &lt;item&gt;Fixed âUninitialized variable usage in &lt;code&gt;resize__system_u...&lt;/code&gt;in&lt;code&gt;@psystem.nim.c&lt;/code&gt;in ORCâ (#25204)&lt;/item&gt;
      &lt;item&gt;Fixed âVM error when passing object field ref to &lt;code&gt;proc(var T): var T&lt;/code&gt;â (#25210)&lt;/item&gt;
      &lt;item&gt;Fixed âClosure environement wrongly marked as cyclic (orc)â (#25048)&lt;/item&gt;
      &lt;item&gt;Fixed âInfinite loop with anonymous iteratorâ (#25046)&lt;/item&gt;
      &lt;item&gt;Fixed âJS: &lt;code&gt;cast[char](i)&lt;/code&gt;for&lt;code&gt;i &amp;gt; 255&lt;/code&gt;not truncateâ (#25222)&lt;/item&gt;
      &lt;item&gt;Fixed âVM issue with globals and assignmentsâ (#25208)&lt;/item&gt;
      &lt;item&gt;Fixed âCase object from &lt;code&gt;compileTime&lt;/code&gt;proc unable to be passed as&lt;code&gt;static&lt;/code&gt;paramâ (#25123)&lt;/item&gt;
      &lt;item&gt;Fixed âVM &lt;code&gt;repr&lt;/code&gt;raises RangeDefect for long string under refcâ (#25226)&lt;/item&gt;
      &lt;item&gt;Fixed âBroken assignment of union with bool inside variant objectâ (#25236)&lt;/item&gt;
      &lt;item&gt;Fixed âdeques: Deque items behavior is not the same on 2.0.16 and 2.2.0â (#25240)&lt;/item&gt;
      &lt;item&gt;Fixed â&lt;code&gt;nim doc&lt;/code&gt;uses doc comment from private field for public fieldâ (#25027)&lt;/item&gt;
      &lt;item&gt;Fixed âCompiler internal error &lt;code&gt;compiler/vmgen.nim(1771, 23)&lt;/code&gt;with&lt;code&gt;static&lt;/code&gt;overloadâ (#25008)&lt;/item&gt;
      &lt;item&gt;Fixed âWrong exception raised wrapped in finally in closure iterator; Regression in devel/version-2-2â (#25202)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The complete list of changes is available here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45772224</guid><pubDate>Fri, 31 Oct 2025 14:15:12 +0000</pubDate></item><item><title>Nix Derivation Madness</title><link>https://fzakaria.com/2025/10/29/nix-derivation-madness</link><description>&lt;doc fingerprint="2030dc0465830596"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Nix derivation madness&lt;/head&gt;
    &lt;p&gt;Published 2025-10-29 on Farid Zakaria's Blog&lt;/p&gt;
    &lt;p&gt;I’ve written a bit about Nix and I still face moments where foundational aspects of the package system confounds and surprises me.&lt;/p&gt;
    &lt;p&gt;Recently I hit an issue that stumped me as it break some basic comprehension I had on how Nix works. I wanted to produce the build and runtime graph for the Ruby interpreter.&lt;/p&gt;
    &lt;code&gt;&amp;gt; nix-shell -p ruby

&amp;gt; which ruby
/nix/store/mp4rpz283gw3abvxyb4lbh4vp9pmayp2-ruby-3.3.9/bin/ruby

&amp;gt; nix-store --query --include-outputs --graph \
  $(nix-store --query --deriver $(which ruby))
error: path '/nix/store/24v9wpp393ib1gllip7ic13aycbi704g-ruby-3.3.9.drv' is not valid

&amp;gt; ls /nix/store/24v9wpp393ib1gllip7ic13aycbi704g-ruby-3.3.9.drv
ls: cannot access '/nix/store/24v9wpp393ib1gllip7ic13aycbi704g-ruby-3.3.9.drv':
No such file or directory
&lt;/code&gt;
    &lt;p&gt;Huh. 🤔&lt;/p&gt;
    &lt;p&gt;I have Ruby but I don’t seem to have the derivation, &lt;code&gt;24v9wpp393ib1gllip7ic13aycbi704g&lt;/code&gt;, file present on my machine.&lt;/p&gt;
    &lt;p&gt;No worries, I think I can &lt;code&gt;--realize&lt;/code&gt; it and download it from the NixOS cache.&lt;/p&gt;
    &lt;code&gt;&amp;gt; nix-store --realize /nix/store/24v9wpp393ib1gllip7ic13aycbi704g-ruby-3.3.9.drv
don't know how to build these paths:
  /nix/store/24v9wpp393ib1gllip7ic13aycbi704g-ruby-3.3.9.drv
error: cannot build missing derivation '/nix/store/24v9wpp393ib1gllip7ic13aycbi704g-ruby-3.3.9.drv'
&lt;/code&gt;
    &lt;p&gt;I guess the NixOS cache doesn’t seem to have it. 🤷&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;This was actually perplexing me at this moment. In fact there are multiple discourse posts about it.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;My mental model however of Nix though is that I must have first evaluated the derivation (drv) in order to determine the output path to even substitute. How could the NixOS cache not have it present?&lt;/p&gt;
    &lt;p&gt;Is this derivation wrong somehow? Nope. This is the derivation Nix believes that produced this Ruby binary from the &lt;code&gt;sqlite&lt;/code&gt; database. 🤨&lt;/p&gt;
    &lt;code&gt;&amp;gt; sqlite3 "/nix/var/nix/db/db.sqlite" 
    "select deriver from ValidPaths where path = 
    '/nix/store/mp4rpz283gw3abvxyb4lbh4vp9pmayp2-ruby-3.3.9'"
/nix/store/24v9wpp393ib1gllip7ic13aycbi704g-ruby-3.3.9.drv
&lt;/code&gt;
    &lt;p&gt;What does the binary cache itself say? Even the cache itself thinks this particular derivation, &lt;code&gt;24v9wpp393ib1gllip7ic13aycbi704g&lt;/code&gt;, produced this particular Ruby output.&lt;/p&gt;
    &lt;code&gt;&amp;gt; curl -s https://cache.nixos.org/mp4rpz283gw3abvxyb4lbh4vp9pmayp2.narinfo |\
  grep Deriver
Deriver: 24v9wpp393ib1gllip7ic13aycbi704g-ruby-3.3.9.drv
&lt;/code&gt;
    &lt;p&gt;What if I try a different command?&lt;/p&gt;
    &lt;code&gt;&amp;gt; nix derivation show $(which ruby) | jq -r "keys[0]"
/nix/store/kmx8kkggm5i2r17s6l67v022jz9gc4c5-ruby-3.3.9.drv

&amp;gt; ls /nix/store/kmx8kkggm5i2r17s6l67v022jz9gc4c5-ruby-3.3.9.drv
/nix/store/kmx8kkggm5i2r17s6l67v022jz9gc4c5-ruby-3.3.9.drv
&lt;/code&gt;
    &lt;p&gt;So I seem to have a completely different derivation, &lt;code&gt;kmx8kkggm5i2r17s6l67v022jz9gc4c5&lt;/code&gt;, that resulted in the same output which is not what the binary cache announces. WTF? 🫠&lt;/p&gt;
    &lt;p&gt;Thinking back to a previous post, I remember touching on modulo fixed-output derivations. Is that what’s going on? Let’s investigate from first principles. 🤓&lt;/p&gt;
    &lt;p&gt;Let’s first create &lt;code&gt;fod.nix&lt;/code&gt; which is our fixed-output derivation.&lt;/p&gt;
    &lt;code&gt;let
  system = builtins.currentSystem;
in derivation {
  name = "hello-world-fixed";
  builder = "/bin/sh";
  system = system;
  args = [ "-c" ''
    echo -n "hello world" &amp;gt; "$out"
  '' ];
  outputHashMode = "flat";
  outputHashAlgo = "sha256";
  outputHash = "b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9";
}
&lt;/code&gt;
    &lt;p&gt;☝️ Since this is a fixed-output derivation (FOD) the produced &lt;code&gt;/nix/store&lt;/code&gt; path will not be affected to changes to the derivation beyond the contents of &lt;code&gt;$out&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;&amp;gt; nix-instantiate fod.nix
/nix/store/k2wjpwq43685j6vlvaarrfml4gl4196n-hello-world-fixed.drv

&amp;gt; nix-build fod.nix
/nix/store/ajk19jb8h5h3lmz20yz6wj9vif18lhp1-hello-world-fixed
&lt;/code&gt;
    &lt;p&gt;Now we will create a derivation that uses this FOD.&lt;/p&gt;
    &lt;code&gt;{ fodDrv ? import ./fod.nix }:

let
  system = builtins.currentSystem;
in
builtins.derivation {
  name = "uses-fod";
  inherit system;
  builder = "/bin/sh";
  args = [ "-c" ''
    echo ${fodDrv} &amp;gt; $out
    echo "Good bye world" &amp;gt;&amp;gt; $out
  '' ];
}
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;/nix/store&lt;/code&gt; for the output for this derivation will change on changes to the derivation except if the derivation path for the FOD changes. This is in fact what makes it “modulo” the fixed-output derivations.&lt;/p&gt;
    &lt;code&gt;&amp;gt; nix-instantiate uses-fod.nix
/nix/store/85d15y7irq7x4fxv4nc7k1cw2rlfp3ag-uses-fod.drv

&amp;gt; nix-build uses-fod.nix
/nix/store/sd12qjak7rlxhdprj10187f9an787lk3-uses-fod
&lt;/code&gt;
    &lt;p&gt;Let’s test this all out by changing our &lt;code&gt;fod.nix&lt;/code&gt; derivation.
Let’s do this by just adding some garbage attribute to the derivation.&lt;/p&gt;
    &lt;code&gt;@@ -4,6 +4,7 @@
   name = "hello-world-fixed";
   builder = "/bin/sh";
   system = system;
+  garbage = 123;
   args = [ "-c" ''
     echo -n "hello world" &amp;gt; "$out"
   '' ];
&lt;/code&gt;
    &lt;p&gt;What happens now?&lt;/p&gt;
    &lt;code&gt;&amp;gt; nix-instantiate fod.nix
/nix/store/yimff0d4zr4krwx6cvdiqlin0y6vkis0-hello-world-fixed.drv

&amp;gt; nix-build fod.nix
/nix/store/ajk19jb8h5h3lmz20yz6wj9vif18lhp1-hello-world-fixed
&lt;/code&gt;
    &lt;p&gt;The path of the derivation itself, &lt;code&gt;.drv&lt;/code&gt;, has changed but the output path &lt;code&gt;ajk19jb8h5h3lmz20yz6wj9vif18lhp1&lt;/code&gt; remains consistent.&lt;/p&gt;
    &lt;p&gt;What about the derivation that leverages it?&lt;/p&gt;
    &lt;code&gt;&amp;gt; nix-instantiate uses-fod.nix
/nix/store/85wkdaaq6q08f71xn420v4irll4a8g8v-uses-fod.drv

&amp;gt; nix-build uses-fod.nix
/nix/store/sd12qjak7rlxhdprj10187f9an787lk3-uses-fod
&lt;/code&gt;
    &lt;p&gt;It also got a new derivation path but the output path remained unchanged. 😮&lt;/p&gt;
    &lt;p&gt;That means changes to fixed-output-derivations didn’t cause new outputs in either derivation but it did create a complete new tree of &lt;code&gt;.drv&lt;/code&gt; files. 🤯&lt;/p&gt;
    &lt;p&gt;That means in nixpkgs changes to fixed-output derivations can cause them to have new store paths for their &lt;code&gt;.drv&lt;/code&gt; but result in dependent derivations to have the same output path. If the output path had already been stored in the NixOS cache, then we lose the link between the new &lt;code&gt;.drv&lt;/code&gt; and this output path. 💥&lt;/p&gt;
    &lt;p&gt;The amount of churn that we are creating in derivations was unbeknownst to me.&lt;/p&gt;
    &lt;p&gt;It can get even weirder! This example came from @ericson2314.&lt;/p&gt;
    &lt;p&gt;We will duplicate the &lt;code&gt;fod.nix&lt;/code&gt; to another file &lt;code&gt;fod2.nix&lt;/code&gt; whose only difference is the value of the garbage.&lt;/p&gt;
    &lt;code&gt;@@ -4,7 +4,7 @@
   name = "hello-world-fixed";
   builder = "/bin/sh";
   system = system;
-  garbage = 123;
+  garbage = 124;
   args = [ "-c" ''
     echo -n "hello world" &amp;gt; "$out"
   '' ];
&lt;/code&gt;
    &lt;p&gt;Let’s now use both of these in our derivation.&lt;/p&gt;
    &lt;code&gt;{ fodDrv ? import ./fod.nix,
  fod2Drv ? import ./fod2.nix
}:
let
  system = builtins.currentSystem;
in
builtins.derivation {
  name = "uses-fod";
  inherit system;
  builder = "/bin/sh";
  args = [ "-c" ''
    echo ${fodDrv} &amp;gt; $out
    echo ${fod2Drv} &amp;gt;&amp;gt; $out
    echo "Good bye world" &amp;gt;&amp;gt; $out
  '' ];
}
&lt;/code&gt;
    &lt;p&gt;We can now instantiate and build this as normal.&lt;/p&gt;
    &lt;code&gt;&amp;gt; nix-instantiate uses-fod.nix
/nix/store/z6nr2k2hy982fiynyjkvq8dliwbxklwf-uses-fod.drv

&amp;gt; nix-build uses-fod.nix
/nix/store/211nlyx2ga7mh5fdk76aggb04y1wsgkj-uses-fod
&lt;/code&gt;
    &lt;p&gt;What is weird about that?&lt;/p&gt;
    &lt;p&gt;Well, let’s take the JSON representation of the derivation and remove one of the inputs.&lt;/p&gt;
    &lt;code&gt;&amp;gt; nix derivation show \
    /nix/store/z6nr2k2hy982fiynyjkvq8dliwbxklwf-uses-fod.drv \
    jq 'values[].inputDrvs | keys[]'
"/nix/store/6p93r6x0bwyd8gngf5n4r432n6l380ry-hello-world-fixed.drv"
"/nix/store/yimff0d4zr4krwx6cvdiqlin0y6vkis0-hello-world-fixed.drv"
&lt;/code&gt;
    &lt;p&gt;We can do this because although there are two input derivations, we know they both produce the same output!&lt;/p&gt;
    &lt;code&gt;@@ -12,12 +12,6 @@
       "system": "x86_64-linux"
     },
     "inputDrvs": {
-      "/nix/store/6p93r6x0bwyd8gngf5n4r432n6l380ry-hello-world-fixed.drv": {
-        "dynamicOutputs": {},
-        "outputs": [
-          "out"
-        ]
-      },
       "/nix/store/yimff0d4zr4krwx6cvdiqlin0y6vkis0-hello-world-fixed.drv": {
         "dynamicOutputs": {},
         "outputs": [
&lt;/code&gt;
    &lt;p&gt;Let’s load this modified derivation back into our &lt;code&gt;/nix/store&lt;/code&gt; and build it again!&lt;/p&gt;
    &lt;code&gt;&amp;gt; nix derivation add &amp;lt; derivation.json
/nix/store/s4qrdkq3a85gxmlpiay334vd1ndg8hm1-uses-fod.drv

&amp;gt; nix-build /nix/store/s4qrdkq3a85gxmlpiay334vd1ndg8hm1-uses-fod.drv
/nix/store/211nlyx2ga7mh5fdk76aggb04y1wsgkj-uses-fod
&lt;/code&gt;
    &lt;p&gt;We got the same output &lt;code&gt;211nlyx2ga7mh5fdk76aggb04y1wsgkj&lt;/code&gt;. Not only do we have a &lt;code&gt;1:N&lt;/code&gt; trait for our output paths to derivations but we can also take certain derivations and completely change them by removing inputs and still get the same output! 😹&lt;/p&gt;
    &lt;p&gt;The road to Nix enlightenment is no joke and full of dragons.&lt;/p&gt;
    &lt;p&gt; Improve this page @ 7492cd3 &lt;lb/&gt; The content for this site is CC-BY-SA. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45772347</guid><pubDate>Fri, 31 Oct 2025 14:28:35 +0000</pubDate></item><item><title>Debug like a boss: 10 debugging hacks for developers, quality engineers, testers</title><link>https://www.ministryoftesting.com/articles/debug-like-a-boss-10-debugging-hacks-for-developers-quality-engineers-and-testers</link><description>&lt;doc fingerprint="6602fe960c06ff18"&gt;
  &lt;main&gt;
    &lt;p&gt;Bugs show up, eat all your time, and gaslight you into thinking you are the problem. You’re not.&lt;lb/&gt;You just solved that problem a few commits ago, but now it’s harvest season again.&lt;/p&gt;
    &lt;p&gt;Here are some debugging hacks that worked for me during such times:&lt;/p&gt;
    &lt;head rend="h2"&gt;1. Stop blaming the code: examine your assumptions instead&lt;/head&gt;
    &lt;p&gt;Half the bugs you chase aren’t in your code. They’re in your head. You assume the API returns the right format. You assume the config is loading. You assume that “of course that condition can never be false.”&lt;/p&gt;
    &lt;p&gt;Pause. Write down 3 things you’re assuming. Then test if they’re true. Most bugs die here.&lt;/p&gt;
    &lt;head rend="h2"&gt;2. Use print statements whenever possible&lt;/head&gt;
    &lt;p&gt;Yes, logs are good. But sometimes what you need is a print statement that shows the raw, brutal truth.&lt;/p&gt;
    &lt;p&gt;Forget “elegant” logs. Instead, write: &lt;code&gt;console.log('IT GOT HERE', value, otherValue);&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;If you can’t print in prod, simulate the state locally. Or inject temporary logging and roll it back after you're done.&lt;/p&gt;
    &lt;p&gt;If you're guessing, start printing.&lt;/p&gt;
    &lt;head rend="h2"&gt;3. Use the "check what changed" shortcut&lt;/head&gt;
    &lt;p&gt;The code worked yesterday. It doesn’t today.&lt;/p&gt;
    &lt;p&gt;What changed?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A merge?&lt;/item&gt;
      &lt;item&gt;A package update?&lt;/item&gt;
      &lt;item&gt;Someone “just renamed” a field?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Use &lt;code&gt;git&lt;/code&gt;&lt;code&gt; diff&lt;/code&gt;. Use &lt;code&gt;git blame&lt;/code&gt;. Use your team’s messages. Bugs appear when you think the change you just made is “harmless.”&lt;/p&gt;
    &lt;head rend="h2"&gt;4. Break things on purpose&lt;/head&gt;
    &lt;p&gt;Sometimes the fastest way to debug is to make the problem worse.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;What happens if you delete the whole function?&lt;/item&gt;
      &lt;item&gt;What if you make the input obviously wrong?&lt;/item&gt;
      &lt;item&gt;What if you hardcode a temporary value?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It tells you what part of the code is actually running and what’s just decoration.&lt;/p&gt;
    &lt;head rend="h2"&gt;5. Explain the bug to anyone, even a rubber duck&lt;/head&gt;
    &lt;p&gt;Explaining the bug to someone else, even to a rubber duck, will often reveal the solution to you.&lt;/p&gt;
    &lt;p&gt;The best way to do it is explain it in writing, like a message or a blog post. Halfway through, you’ll realize where you messed up.&lt;/p&gt;
    &lt;p&gt;If you're writing a message to your teammate, ask your teammate to refrain from responding until you finish typing. You’re not asking for their input, necessarily. You’re asking to have someone listen to you so you can think straight.&lt;/p&gt;
    &lt;head rend="h2"&gt;6. Error messages lie sometimes, but stack traces tell the truth&lt;/head&gt;
    &lt;p&gt;That error might say the issue is in &lt;code&gt;fileA.js,&lt;/code&gt; line 134. But the real culprit is 10 steps back.&lt;/p&gt;
    &lt;p&gt;Start from the stack trace. Rebuild the call flow mentally. Use breakpoints or traces to walk the same path.&lt;/p&gt;
    &lt;p&gt;The truth is in the path, not the punchline.&lt;/p&gt;
    &lt;head rend="h2"&gt;7. Reproduction kills bugs dead&lt;/head&gt;
    &lt;p&gt;If you can’t reproduce it, you can’t fix it. End of story.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Try different environments.&lt;/item&gt;
      &lt;item&gt;Use test accounts.&lt;/item&gt;
      &lt;item&gt;Recreate the exact state the user was in when the bug showed up.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Once you have reproduced it at least once, the bug is already on its way to the graveyard.&lt;/p&gt;
    &lt;head rend="h2"&gt;8. Logs make good maps and bad novels&lt;/head&gt;
    &lt;p&gt;Don’t drown in logs. Learn to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Filter by correlation IDs.&lt;/item&gt;
      &lt;item&gt;grep for error keywords.&lt;/item&gt;
      &lt;item&gt;Log timestamps to detect timing bugs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Better yet, set alerts on error patterns and high-latency paths. The log is not your diary. It’s your surveillance system.&lt;/p&gt;
    &lt;head rend="h2"&gt;9. Check the components your code interacts with&lt;/head&gt;
    &lt;p&gt;Is it your bug? Maybe.&lt;/p&gt;
    &lt;p&gt;But first consider:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Is the upstream API acting weird?&lt;/item&gt;
      &lt;item&gt;Is the database server caching stale data?&lt;/item&gt;
      &lt;item&gt;Is the content delivery system serving outdated JavaScript?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Debugging is cross-boundary now. Isolate systems. Confirm assumptions. Don’t play alone, you can share the load.&lt;/p&gt;
    &lt;head rend="h2"&gt;10. Take rest breaks like a professional&lt;/head&gt;
    &lt;p&gt;That bug you can’t crack after you've spent three hours on it? You are likely to squash it in 10 minutes after lunch.&lt;/p&gt;
    &lt;p&gt;Walk away. Rant to a friend. Stare into the void.&lt;/p&gt;
    &lt;p&gt;Debugging isn’t just thinking. It’s re-thinking, and your brain needs room to do that.&lt;/p&gt;
    &lt;head rend="h2"&gt;Bonus: Your boss isn’t impressed when you say “I fixed it.”&lt;/head&gt;
    &lt;p&gt;What they really want to know:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;What broke&lt;/item&gt;
      &lt;item&gt;Why it broke&lt;/item&gt;
      &lt;item&gt;How we’ll prevent it next time&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Write postmortems. Add comments. Create a test case. That’s debugging like a boss.&lt;/p&gt;
    &lt;head rend="h2"&gt;Still stuck? Make your own hacks.&lt;/head&gt;
    &lt;p&gt;These 10 tips aren’t a checklist: they are a starter kit. If you’ve been debugging long enough, you’ve probably invented a few of your own rituals:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Copying state to a playground&lt;/item&gt;
      &lt;item&gt;Spinning up a fresh dev environment&lt;/item&gt;
      &lt;item&gt;Asking your future self in code comments what on earth this logic was meant to do&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Whatever works, write it down. Share it. Teach it. That’s how you get better at debugging not just faster, but smarter.&lt;/p&gt;
    &lt;head rend="h2"&gt;To wrap up&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Don’t trust your assumptions, question them.&lt;/item&gt;
      &lt;item&gt;Logs are your sidekick, not your saviour.&lt;/item&gt;
      &lt;item&gt;Break stuff, observe, and simplify.&lt;/item&gt;
      &lt;item&gt;If you're stuck, walk away.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;For more information&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Finding bugs faster: A smarter way to debug integration failures, Arun Vishwanathan&lt;/item&gt;
      &lt;item&gt;Testing AI-coded applications: Practical tips for software testers, Rafaela Azevedo&lt;/item&gt;
      &lt;item&gt;I think, therefore I test: the importance of thinking for testers, Ady Stokes&lt;/item&gt;
      &lt;item&gt;Fixing a bug vs fixing a feature, Hanisha Arora&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What do YOU think?&lt;/head&gt;
    &lt;p&gt;Got comments or thoughts? Share them in the comments box below. If you like, use the ideas below as starting points for reflection and discussion.&lt;/p&gt;
    &lt;head rend="h3"&gt;Questions to discuss&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;What’s the single most useful debugging trick you’ve learned that isn’t on this list?&lt;/item&gt;
      &lt;item&gt;Have you ever spent hours chasing a bug, only to realize it came from a false assumption? How did you catch it?&lt;/item&gt;
      &lt;item&gt;How do you decide when to step away and take a break or when to keep going on finding a solution?&lt;/item&gt;
      &lt;item&gt;What’s the best “rubber duck moment” you’ve ever had: explaining a bug made the solution suddenly obvious?&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Actions to take&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Try rubber-ducking: Explain a bug (real or imaginary) in writing to yourself, or talk it through to a friend who isn’t technical. Notice at what point clarity starts to emerge.&lt;/item&gt;
      &lt;item&gt;Break something on purpose: Pick a working function and break it on purpose. Change inputs, hardcode incorrect values, or delete parts of it. Observe how your system fails, and what that teaches you about where to look when real bugs appear.&lt;/item&gt;
      &lt;item&gt;Measure your own slowdown: If you want data, start small. Track how long it takes between finding a bug and actually closing it. Then check how much of that time is spent waiting, reworking, or context switching. You’ll probably find that “testing slows you down” wasn’t the real slowdown at all. You can also do the same for your team to measure your team’s slowdown.&lt;/item&gt;
      &lt;item&gt;Bring your leads into it: Set up a short chat or team session to share your debugging tricks - what’s working, what’s not, where time gets lost. Aligning language and priorities can turn debugging from a background chore into fast-track fixes.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45772519</guid><pubDate>Fri, 31 Oct 2025 14:44:59 +0000</pubDate></item><item><title>Ubuntu Introduces Architecture Variants</title><link>https://lwn.net/Articles/1044383/</link><description>&lt;doc fingerprint="2d43744da84ae6c7"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Ubuntu introduces architecture variants&lt;/head&gt;
    &lt;p&gt;Michael Hudson-Doyle, a member of Ubuntu's Foundations team, has announced the introduction of an "architecture variant" for Ubuntu 25.10:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;By making changes to dpkg, apt and Launchpad, we are able to build multiple versions of a package, each for a different level of the x86-64 architecture, meaning we can have packages that specifically target x86-64-v3, for example.&lt;/p&gt;
      &lt;p&gt;As a result, we're very excited to share that in Ubuntu 25.10, some packages are available, on an opt-in basis, in their optimized form for the more modern x86-64-v3 architecture level.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;See the announcement for details on opting in to x86-64-v3 packages.&lt;/p&gt;
    &lt;p&gt; Posted Oct 31, 2025 14:47 UTC (Fri) by archaic (subscriber, #111970) [Link] (5 responses) Posted Oct 31, 2025 15:02 UTC (Fri) by Kamiccolo (subscriber, #95159) [Link] (3 responses) Posted Oct 31, 2025 16:00 UTC (Fri) by muep (subscriber, #86754) [Link] (1 responses) Posted Oct 31, 2025 16:04 UTC (Fri) by ttuttle (subscriber, #51118) [Link] Posted Oct 31, 2025 16:28 UTC (Fri) by nim-nim (subscriber, #34454) [Link] Or course you can declare a variant optional and not wait for it but that’s a short path to second class abandonware people should be weary about. Posted Oct 31, 2025 16:24 UTC (Fri) by nim-nim (subscriber, #34454) [Link] Of course sucks to be the proud owner of legacy hardware when it passes into the museum category (as Linus would say). &lt;head&gt;Better than forcing it&lt;/head&gt;&lt;head&gt;Better than forcing it&lt;/head&gt;&lt;head&gt;Better than forcing it&lt;/head&gt;&lt;head&gt;Better than forcing it&lt;/head&gt;&lt;head&gt;Better than forcing it&lt;/head&gt;&lt;head&gt;Better than forcing it&lt;/head&gt;&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45772579</guid><pubDate>Fri, 31 Oct 2025 14:49:58 +0000</pubDate></item></channel></rss>