<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 04 Dec 2025 22:08:44 +0000</lastBuildDate><item><title>RAM is so expensive, Samsung won't even sell it to Samsung</title><link>https://www.pcworld.com/article/2998935/ram-is-so-expensive-samsung-wont-even-sell-it-to-samsung.html</link><description>&lt;doc fingerprint="bb7aac81a5b6d3e8"&gt;
  &lt;main&gt;
    &lt;p&gt;The price of eggs has nothing on the price of computer memory right now. Thanks to a supply crunch from the “AI” bubble, RAM chips are the new gold, with prices on consumer PC memory kits ballooning out of control. In an object lesson in the ridiculousness of an economic bubble, Samsung won’t even sell its memory to… Samsung.&lt;/p&gt;
    &lt;p&gt;Here’s the situation. Samsung makes everything from refrigerators to supermassive oil tankers. Getting all that stuff made requires an organization that’s literally dozens of affiliated companies and subsidiaries, which don’t necessarily work as closely or harmoniously as you might assume. For this story, we’re talking about Samsung Electronics, which makes Galaxy phones, tablets, laptops, watches, etc., and Samsung Semiconductor Global, which manufactures memory and other chips and supplies the global market. That global market includes both Samsung subsidiaries and their competitors—laptops from Samsung, Dell, and Lenovo sitting on a Best Buy store shelf might all have Samsung-manufactured memory sitting in their RAM slots.&lt;/p&gt;
    &lt;p&gt;Samsung subsidiaries are, naturally, going to look to Samsung Semiconductor first when they need parts. Such was reportedly the case for Samsung Electronics, in search of memory supplies for its newest smartphones as the company ramps up production for 2026 flagship designs. But with so much RAM hardware going into new “AI” data centers—and those companies willing to pay top dollar for their hardware—memory manufacturers like Samsung, SK Hynix, and Micron are prioritizing data center suppliers to maximize profits.&lt;/p&gt;
    &lt;p&gt;The end result, according to a report from SE Daily spotted by SamMobile, is that Samsung Semiconductor rejected the original order for smartphone DRAM chips from Samsung Electronics’ Mobile Experience division. The smartphone manufacturing arm of the company had hoped to nail down pricing and supply for another year. But reports say that due to “chipflation,” the phone-making division must renegotiate quarterly, with a long-term supply deal rejected by its corporate sibling. A short-term deal, with higher prices, was reportedly hammered out.&lt;/p&gt;
    &lt;p&gt;Assuming that this information is accurate—and to be clear, we can’t independently confirm it—consumers will see prices rise for Samsung phones and other mobile hardware. But that’s hardly a surprise. Finished electronics probably won’t see the same meteoric rise in prices as consumer-grade RAM modules, but this rising tide is flooding all the boats. Raspberry Pi, which strives to keep its mod-friendly electronics as cheap as possible, has recently had to bring prices up and called out memory costs as the culprit. Lenovo, the world’s largest PC manufacturer, is stockpiling memory supplies as a bulwark against the market.&lt;/p&gt;
    &lt;p&gt;But if you’re hoping to see prices lower in 2026, don’t hold your breath. According to a forecast from memory supplier TeamGroup, component prices have tripled recently, causing finished modules to jump in prices as quickly as 100 percent in a month. Absent some kind of disastrous market collapse, prices are expected to continue rising into next year, and supply could remain constrained well into 2027 or later.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46147353</guid><pubDate>Thu, 04 Dec 2025 13:20:07 +0000</pubDate></item><item><title>Fighting the age-gated internet</title><link>https://www.wired.com/story/age-verification-is-sweeping-the-us-activists-are-fighting-back/</link><description>&lt;doc fingerprint="3b8f985538b1b5e0"&gt;
  &lt;main&gt;
    &lt;p&gt;Members of Congress considered 19 online safety bills Tuesday that may soon have a major impact on the future of the internet as age-verification laws have spread to half of the US and around the world.&lt;/p&gt;
    &lt;p&gt;In response, digital and human rights organization Fight for the Future is hosting a week of events—across Reddit, LinkedIn, and various livestreams—to raise awareness of how it believes these bills are setting a dangerous precedent by making the internet more exploitative rather than safer. Many of the proposed bills include a clause for ID or age verification, which forces people to upload an ID, allow a face scan, or otherwise authenticate that they are not a minor before viewing adult content. Fight for the Future says the policies will lead to increased censorship and surveillance.&lt;/p&gt;
    &lt;p&gt;Among the 19 bills considered at the hearing conducted by the House Energy and Commerce Committee was the Kids Online Safety Act (KOSA), which passed with sweeping bipartisan approval in the Senate last year, and the Reducing Exploitative Social Media Exposure for Teens Act, which would ban tech companies from allowing minors under the age of 16 on their platforms. In addition to age verification, the bills raised concerns over issues of parental controls, consumer research of minors, AI, and data privacy.&lt;/p&gt;
    &lt;p&gt;“We’re seeing this huge wave toward ID checks being the norm in tech policy, and it felt like we needed to capture the already activated communities who are not feeling heard in Congress,” says Sarah Philips, a campaigner with Fight for the Future. “If you look on YouTube, if you see people making content about KOSA or responding to a lot of this legislation, it’s very unpopular with people. But it’s viewed on the Hill as very common-sense.”&lt;/p&gt;
    &lt;p&gt;Missouri’s age-gate law took effect earlier this week, meaning 25 US states have passed a form of age verification. The process usually involves third-party services, which can be especially prone to data breaches. This year, the UK also passed a mandate for age verification—the Online Safety Act—and Australia’s teen social media ban, which requires social media companies to deactivate the accounts of users under the age of 16, goes into effect on December 10. Instagram, YouTube, Snap, and TikTok are complying with the historic ban.&lt;/p&gt;
    &lt;p&gt;Philips believes the laws are a direct threat to democratic freedom. “These are censorship laws,” she says. “In the South, where I live, these same proposals mimic a lot of the arguments that you see behind book bans and behind laws that criminalize gender-affirming health care or abortion information.”&lt;/p&gt;
    &lt;p&gt;In March, over 90 human rights advocacy groups signed a coalition letter opposing online ID-check mandates. “The internet is not improved by treating its users like criminal suspects and our lives as opportunities for corporate profit,” David Swanson, campaign coordinator at RootsAction.org, wrote in the letter. “Legislators defunding education to invest in wars, police, prisons, borders, and constant surveillance should think hard before claiming to be acting on behalf of children.”&lt;/p&gt;
    &lt;p&gt;Though Tuesday’s hearing did not advance any legislation, it included testimonies from Joel Thayer, president of the Digital Progress Institute, and Kate Ruane, director of the Free Expression Project at the Center for Democracy and Technology. “The government and social media platforms should not be—indeed, with respect to the government, cannot be—the sole arbiters of the content children can see and services that they can access online,” Ruane said during her testimony.&lt;/p&gt;
    &lt;p&gt;The package of bills is indicative of how Congress has failed to deliver real solutions, Philips says. “We have repeatedly asked them to focus on comprehensive privacy legislation, on antitrust issues, and on things that actually protect us from the surveillance capitalist business model of big tech companies. Congress says they’re holding big tech accountable, but most of the options on the table just mandate verification.” According to The Verge, a revamped version of KOSA removes tech companies’ liability in mitigating potential harms caused by their platforms.&lt;/p&gt;
    &lt;p&gt;In an op-ed for Teen Vogue published in October, Fight for the Future director Evan Greer and campaigner Janus Rose criticized Democratic lawmakers who support KOSA, including the bill’s cowriter, Senator Richard Blumenthal of Connecticut. “KOSA takes the same logic of the bans on drag shows and LGBTQ+ books and applies it to the internet, allowing censorship of a broad range of information in the name of protecting kids from real online harm,” Greer noted.&lt;/p&gt;
    &lt;p&gt;But since KOSA and the Children and Teens’ Online Privacy Protection Act failed to gain approval last year, “it’ll be interesting to see what actually floats to the top right now,” Philips says, concerned that some of the bills could be attached to the National Defense Authorization Act or have the Trump administration’s 10-year moratorium on state AI regulations attached to them, “which is a disaster tornado of tech policies.”&lt;/p&gt;
    &lt;p&gt;Philips tells me she isn’t disheartened by the work, because she wants people to understand what’s really at stake in the fight ahead.&lt;/p&gt;
    &lt;p&gt;“The thing that people misunderstand most about age verification is that it actually applies to all of us,” she says. “A lot of the people pushing for age verification solely focus on kids, because that’s the discussion happening in Congress or on the Hill. But in actuality, if we age-gate the internet and implement mandates, that means that you have to prove that you’re not a child—whether you’re 18 or 50. Everyone will have to interact with this.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46147493</guid><pubDate>Thu, 04 Dec 2025 13:34:27 +0000</pubDate></item><item><title>Transparent leadership beats servant leadership</title><link>https://entropicthoughts.com/transparent-leadership-beats-servant-leadership</link><description>&lt;doc fingerprint="bce3d0111682d491"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Transparent Leadership Beats Servant Leadership&lt;/head&gt;
    &lt;p&gt;tl:dr: Parenting and leadership is similar. Teach a man to fish, etc.&lt;/p&gt;
    &lt;p&gt;I spent a couple of years managing a team, and I entered that role – like many – without knowing anything about how to do it. I tried to figure out how to be a good manager, and doing so I ended up reading a lot about servant leadership. It never quite sat right with me, though. Servant leadership seems to me a lot like curling parenting: the leader/parent anticipate problems and sweep the way for their direct reports/children.&lt;/p&gt;
    &lt;p&gt;To be clear, this probably feels very good (initially, anyway) for the direct reports/children. But the servant leader/curling parent quickly becomes an overworked single point of failure, and once they leave there is nobody else who knows how to handle the obstacles the leader moved out of the way for everyone. In the worst cases, they leave behind a group of people who have been completely isolated from the rest of the organisation, and has no idea what their purpose is and how to fit in with the rest of the world.&lt;/p&gt;
    &lt;p&gt;I would like to invent my own buzzword: transparent leadership. In my book, a good leader&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;coaches people,&lt;/item&gt;
      &lt;item&gt;connects people,&lt;/item&gt;
      &lt;item&gt;teaches people methodical problem solving,&lt;/item&gt;
      &lt;item&gt;explains values and principles embraced by the organisation to aid them in making aligned decisions on their own,&lt;/item&gt;
      &lt;item&gt;creates direct links between supply and demand (instead of deliberately making themselves a middle man),&lt;/item&gt;
      &lt;item&gt;allows their direct reports career growth by gradually taking over leadership responsibilities,&lt;/item&gt;
      &lt;item&gt;continuously trains their replacement, and&lt;/item&gt;
      &lt;item&gt;generally makes themselves redundant.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The middle manager that doesn’t perform any useful work is a fun stereotype, but I also think it’s a good target to aim for. The difference lies in what to do once one has rendered oneself redundant. A common response is to invent new work, ask for status reports, and add bureaucracy.&lt;/p&gt;
    &lt;p&gt;A better response is to go back to working on technical problems. This keeps the manager’s skills fresh and gets them more respect from their reports. The manager should turn into a high-powered spare worker, rather than a paper-shuffler.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46147540</guid><pubDate>Thu, 04 Dec 2025 13:40:00 +0000</pubDate></item><item><title>Show HN: Onlyrecipe 2.0 – I added all features HN requested – 4 years later</title><link>https://onlyrecipeapp.com/?url=https://www.allrecipes.com/turkish-pasta-recipe-8754903</link><description>&lt;doc fingerprint="d37fffed7efd5e8d"&gt;
  &lt;main&gt;
    &lt;p&gt;Loading...&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46148460</guid><pubDate>Thu, 04 Dec 2025 15:06:08 +0000</pubDate></item><item><title>Microsoft drops AI sales targets in half after salespeople miss their quotas</title><link>https://arstechnica.com/ai/2025/12/microsoft-slashes-ai-sales-growth-targets-as-customers-resist-unproven-agents/</link><description>&lt;doc fingerprint="af740a1914faa081"&gt;
  &lt;main&gt;
    &lt;p&gt;Microsoft has lowered sales growth targets for its AI agent products after many salespeople missed their quotas in the fiscal year ending in June, according to a report Wednesday from The Information. The adjustment is reportedly unusual for Microsoft, and it comes after the company missed a number of ambitious sales goals for its AI offerings.&lt;/p&gt;
    &lt;p&gt;AI agents are specialized implementations of AI language models designed to perform multistep tasks autonomously rather than simply responding to single prompts. So-called “agentic” features have been central to Microsoft’s 2025 sales pitch: At its Build conference in May, the company declared that it has entered “the era of AI agents.”&lt;/p&gt;
    &lt;p&gt;The company has promised customers that agents could automate complex tasks, such as generating dashboards from sales data or writing customer reports. At its Ignite conference in November, Microsoft announced new features like Word, Excel, and PowerPoint agents in Microsoft 365 Copilot, along with tools for building and deploying agents through Azure AI Foundry and Copilot Studio. But as the year draws to a close, that promise has proven harder to deliver than the company expected.&lt;/p&gt;
    &lt;p&gt;According to The Information, one US Azure sales unit set quotas for salespeople to increase customer spending on a product called Foundry, which helps customers develop AI applications, by 50 percent. Less than a fifth of salespeople in that unit met their Foundry sales growth targets. In July, Microsoft lowered those targets to roughly 25 percent growth for the current fiscal year. In another US Azure unit, most salespeople failed to meet an earlier quota to double Foundry sales, and Microsoft cut their quotas to 50 percent for the current fiscal year.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46148748</guid><pubDate>Thu, 04 Dec 2025 15:31:52 +0000</pubDate></item><item><title>Feynman vs. Computer</title><link>https://entropicthoughts.com/feynman-vs-computer</link><description>&lt;doc fingerprint="127ccb0343b51399"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Feynman vs. Computer&lt;/head&gt;
    &lt;p&gt;I read Burghelea’s article on the Feynman trick for integration. Well, I’m not good enough at analysis to follow along, but I tried reading it anyway because it’s fascinating.&lt;/p&gt;
    &lt;p&gt;For people who do not have experience with analysis, integration is counting the total size of very many, very small piles of things. Analytical integration, i.e. the process by which we can get an exact result, can be very difficult. It often takes knowledge of special tricks, strong pattern recognition, and plenty of trial and error. Fortunately, in all cases in my career when I’ve needed the value of an integral, an approximate answer has been good enough.&lt;/p&gt;
    &lt;p&gt;In practical terms, this means we could spend a lot of time learning integration tricks, practice using them, and then take half an hour out of our day to apply them to an integral in front of us … or, hear me out, or, we could write four lines of JavaScript that arrive at a relatively accurate answer in less than a second.&lt;/p&gt;
    &lt;head rend="h1"&gt;The approximating power of random numbers&lt;/head&gt;
    &lt;p&gt;If integration is summing many small piles, we have to figure out how big the piles are. Their height is usually given by a mathematical function, and our first example will be the same as in the Feynman trick article.&lt;/p&gt;
    &lt;p&gt;\[f(x) = \frac{x - 1}{\ln{x}}\]&lt;/p&gt;
    &lt;p&gt;This is to be integrated from zero to one, i.e. we want to know the size of the shaded area in the plot below. You can think of each column of shaded pixels as one pile, and we sum the size of all of them to get the total area.1 Of course, this is an svg image so there are no columns of pixels. Alternatively, the more we zoom in, the thinner the columns become – but the more of them there are. This is why we need integration: it’s dealing with the limit case of infinitely many, infinitely thin columns.&lt;/p&gt;
    &lt;p&gt;We could imagine drawing six random numbers between zero and one, and plotting piles of the corresponding height at those locations. Since there are six piles, their width is one sixth of the width of the area we are integrating.&lt;/p&gt;
    &lt;p&gt;Even though some of these piles overlap by chance, and even though there are some random gaps between them, the sum of their areas (0.66) comes very close to the actual shaded area determined analytically (0.69). If we draw more piles, we have to make them correspondingly thinner, but the agreement between their sum and the total size of the area improves.&lt;/p&gt;
    &lt;p&gt;These are 100× as many piles, and they’re 1/100th as thick to compensate. Their total area is 0.70 – very close to 0.69. If we draw even more piles, we’ll get even closer.&lt;/p&gt;
    &lt;p&gt;This illustrates a neat correspondence between integrals and expected values. In the simple case, we can frame it mathematically as&lt;/p&gt;
    &lt;p&gt;\[\int_a^b f(x) \mathrm{d}x = E(f(x))\]&lt;/p&gt;
    &lt;p&gt;In words, this says that integrating the function \(f\) between \(a\) and \(b\) is the same as taking the expected value of \(f(x)\) at uniformly distributed random points between \(a\) and \(b\).&lt;/p&gt;
    &lt;head rend="h1"&gt;Teaching the computer to do it&lt;/head&gt;
    &lt;p&gt;Here’s a JavaScript function that estimates the value of an integral in the most primitive way possible.&lt;/p&gt;
    &lt;quote&gt;I = (B, lo, hi, f) =&amp;gt; { // Generate B random values uniformly between lo and hi. let xs = Array.from({length: B}, _ =&amp;gt; lo + (hi - lo) * Math.random()); // Compute the value of f at each location. let ys = xs.map(f); // Return the total area of each corresponding pile. return (hi-lo)*ys.reduce((r, y) =&amp;gt; r + y, 0)/ys.length; }&lt;/quote&gt;
    &lt;p&gt;To compute an approximation to the value of the integral we’ve seen, we run&lt;/p&gt;
    &lt;quote&gt;I(10_000, 0, 1, x =&amp;gt; (x-1)/Math.log(x) );&lt;/quote&gt;
    &lt;quote&gt;0.6916867623261724&lt;/quote&gt;
    &lt;p&gt;This is fairly close to 0.69. And we got there in four lines of JavaScript, as promised.&lt;/p&gt;
    &lt;head rend="h1"&gt;Improved approximation through splittage&lt;/head&gt;
    &lt;p&gt;We can try this on the next example too. Now we’re asking about the integral&lt;/p&gt;
    &lt;p&gt;\[\int_0^{\frac{\pi}{2}} \frac{\ln{(1 - \sin{x})}}{\sin{x}} \mathrm{d}x\]&lt;/p&gt;
    &lt;p&gt;which, translated to JavaScript, becomes&lt;/p&gt;
    &lt;quote&gt;I(10_000, 0, Math.PI, x =&amp;gt; Math.log(1 - Math.sin(x))/Math.sin(x) );&lt;/quote&gt;
    &lt;quote&gt;-3.67&lt;/quote&gt;
    &lt;p&gt;This is again fairly close to the desired −3.7, but not quite there yet. The tricky shape of the function is the reason we aren’t getting as close as we want.&lt;/p&gt;
    &lt;p&gt;At the upper endpoint of the integration interval, this function goes to negative infinity. The random piles we draw come primarily from the well behaved region of the function, and thus don’t help the computer realise this behaviour.&lt;/p&gt;
    &lt;p&gt;There are clever ways to sample adaptively from the trickier parts of the function, but an easy solution is to just visually find a breakpoint, split the interval on that, and then estimate the sensible part separately from the crazy-looking part. Since the total area must be the sum of both areas, we can add their results together for a final estimation.&lt;/p&gt;
    &lt;p&gt;In this case, we might want to pick e.g. 1.5 as the breakpoint, so we combine the area estimations from 0–1.5 and then 1.5–\(\frac{\pi}{2}\). The result is&lt;/p&gt;
    &lt;quote&gt;I(2_000, 0, 1.5, x =&amp;gt; Math.log(1 - Math.sin(x))/Math.sin(x)) + I(8_000, 1.5, Math.PI/2, x =&amp;gt; Math.log(1 - Math.sin(x))/Math.sin(x));&lt;/quote&gt;
    &lt;quote&gt;-3.70&lt;/quote&gt;
    &lt;p&gt;which is indeed much closer to the actual value of −3.7.&lt;/p&gt;
    &lt;p&gt;Note that we aren’t taking more samples, we’re just sprinkling them more wisely over the number line. We spend 2,000 samples in the relatively well-behaved region where the function takes values from −1 to −6, and then we spend the other 8,000 samples in the small region that goes from −6 to negative infinity. Here it is graphically:&lt;/p&gt;
    &lt;p&gt;The reason this helps us is that this latter region contributes a lot to the value of the integral, but it is so small on the number line that we benefit from oversampling it compared to the other region. This is a form of sample unit engineering, which we have seen before in different contexts.&lt;/p&gt;
    &lt;head rend="h1"&gt;More evidence of sufficiency&lt;/head&gt;
    &lt;p&gt;We can continue with some more examples from the Feynman trick article. That gets us the following table.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Integral&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
        &lt;cell role="head"&gt;Estimation&lt;/cell&gt;
        &lt;cell role="head"&gt;Difference&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;\(\int_0^1 \frac{x-1}{\ln{x}} \mathrm{d}x\)&lt;/cell&gt;
        &lt;cell&gt;\(\ln{2}\)&lt;/cell&gt;
        &lt;cell&gt;0.6943&lt;/cell&gt;
        &lt;cell&gt;0.2 %&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;\(\int_0^{\frac{\pi}{2}} \frac{\ln{(1 - \sin{x})}}{\sin{x}} \mathrm{d}x\)&lt;/cell&gt;
        &lt;cell&gt;\(\frac{-3 \pi^2}{8}\)&lt;/cell&gt;
        &lt;cell&gt;-3.702&lt;/cell&gt;
        &lt;cell&gt;&amp;lt; 0.1 %&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;\(\int_0^1 \frac{\ln{(1 - x + x^2)}}{x - x^2} \mathrm{d}x\)&lt;/cell&gt;
        &lt;cell&gt;\(\frac{-\pi^2}{9}\)&lt;/cell&gt;
        &lt;cell&gt;-1.097&lt;/cell&gt;
        &lt;cell&gt;&amp;lt; 0.1 %&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;\(\int_0^{\frac{\pi}{2}} \frac{\arctan{(\sin{x})}}{\sin{x}} \mathrm{d}x\)&lt;/cell&gt;
        &lt;cell&gt;\(\frac{\pi}{2}\log{(1 + \sqrt{2})}\)&lt;/cell&gt;
        &lt;cell&gt;1.385&lt;/cell&gt;
        &lt;cell&gt;&amp;lt; 0.1 %&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;\(\int_0^\infty x^2 e^{-\left(4x^2 + \frac{9}{x^2}\right)} \mathrm{d}x\)&lt;/cell&gt;
        &lt;cell&gt;\(\frac{13 \sqrt{\pi}}{32 e^{12}}\)&lt;/cell&gt;
        &lt;cell&gt;0.000004414&lt;/cell&gt;
        &lt;cell&gt;0.2 %&lt;/cell&gt;
        &lt;cell&gt;(1)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;\(\int_0^1 \frac{\ln{x}}{1 - x^2} \mathrm{d}x\)&lt;/cell&gt;
        &lt;cell&gt;\(\frac{-\pi^2}{8}\)&lt;/cell&gt;
        &lt;cell&gt;-1.227&lt;/cell&gt;
        &lt;cell&gt;0.5 %&lt;/cell&gt;
        &lt;cell&gt;(2)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;\(\int_0^\infty \frac{e^{-x^2}}{1 + x^2} \mathrm{d}x\)&lt;/cell&gt;
        &lt;cell&gt;\(\frac{\pi e}{2}\mathrm{erfc}(1)\)&lt;/cell&gt;
        &lt;cell&gt;0.6696&lt;/cell&gt;
        &lt;cell&gt;0.3 %&lt;/cell&gt;
        &lt;cell&gt;(3)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Notes:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The integration is from zero to infinity, but the function practically only has a value between zero and three, so that’s the region we estimate over.&lt;/item&gt;
      &lt;item&gt;This is another case where the function goes to infinity near zero, so we split up the estimation into one for the range 0–0.1, and the other for 0.1–1.0. We have not increased the sample count, only reallocated the 10,000 samples.&lt;/item&gt;
      &lt;item&gt;Again, the integration is from zero to infinity, but the function practically only has a value between zero and three, so that’s the region we estimate over.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Finding the error without a ground truth&lt;/head&gt;
    &lt;p&gt;“Now,” the clever reader says, “this is all well and good when we have the actual value to compare to so we know the size of the error. What will we do if we’re evluating a brand new integral? What is the size of the error then, huh?”&lt;/p&gt;
    &lt;p&gt;This is why we sampled the function randomly. That means our approximation is a statistical average over samples, and for that we can compute the standard error of the mean. In the JavaScript implementation below, we use the quick variance computation, but we could perhaps more intuitively have used the spc inspired method.&lt;/p&gt;
    &lt;quote&gt;Ic = (B, lo, hi, f) =&amp;gt; { let xs = Array.from( {length: B}, _ =&amp;gt; lo + (hi - lo) * Math.random() ); let ys = xs.map(f); // Compute the variance of the ys from the sum and // the sum of squared ys. let s = ys.reduce((r, y) =&amp;gt; r + y, 0); let ssq = ys.reduce((r, y) =&amp;gt; r + y**2, 0); let v = (ssq - s**2/B)/(B-1); // Compute the mean and the standard error of the mean. let m = (hi-lo)*s/B; let se = (hi-lo)*Math.sqrt(v/B); // Compute the 90 % confidence interval of the value of // the integral. return { p05: m - 1.645*se, p95: m + 1.645*se, } }&lt;/quote&gt;
    &lt;p&gt;If we run this with the first integral as an example, we’ll learn that&lt;/p&gt;
    &lt;quote&gt;Ic(10_000, 0, 1, x =&amp;gt; (x-1)/Math.log(x) )&lt;/quote&gt;
    &lt;quote&gt;Object { p05: 0.6896 p95: 0.6963 }&lt;/quote&gt;
    &lt;p&gt;Not only is this range an illustration of the approximation error (small!), it is also very likely to capture the actual value of the integral. Here are some more examples from the same integrals as above:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;5 %&lt;/cell&gt;
        &lt;cell role="head"&gt;95 %&lt;/cell&gt;
        &lt;cell role="head"&gt;Actual&lt;/cell&gt;
        &lt;cell role="head"&gt;Contained?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;0.6904&lt;/cell&gt;
        &lt;cell&gt;0.6972&lt;/cell&gt;
        &lt;cell&gt;0.6931&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;-3.7673&lt;/cell&gt;
        &lt;cell&gt;-3.6787&lt;/cell&gt;
        &lt;cell&gt;-3.7011&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;-1.0975&lt;/cell&gt;
        &lt;cell&gt;-1.0960&lt;/cell&gt;
        &lt;cell&gt;-1.0966&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;1.3832&lt;/cell&gt;
        &lt;cell&gt;1.3871&lt;/cell&gt;
        &lt;cell&gt;1.3845&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;0.4372&lt;/cell&gt;
        &lt;cell&gt;0.4651&lt;/cell&gt;
        &lt;cell&gt;0.4424&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;-1.2545&lt;/cell&gt;
        &lt;cell&gt;-1.2254&lt;/cell&gt;
        &lt;cell&gt;-1.2337&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;0.6619&lt;/cell&gt;
        &lt;cell&gt;0.6937&lt;/cell&gt;
        &lt;cell&gt;0.6716&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;These are all built naïvely from 10,000 uniform samples. In other words, in none of the cases have the computation been split up to allocate samples more cleverly.&lt;/p&gt;
    &lt;p&gt;Again, we could spend a lot of time learning to integrate by hand … or we ask the computer for less than a second of its time first, and see if the accuracy it can do it with is appropriate for our use case. In my experience, it generally is.&lt;/p&gt;
    &lt;head rend="h1"&gt;Seeing the effect of sample unit engineering&lt;/head&gt;
    &lt;p&gt;What’s neat is we can still split up the computation like we did before, if we believe it will make the error smaller and the confidence interval narrower. Let’s use the following integral as an example.&lt;/p&gt;
    &lt;p&gt;\[\int_0^\infty \frac{\sin{x}}{x} \mathrm{d}x\]&lt;/p&gt;
    &lt;p&gt;This oscillates up and down quite a bit for small \(x\), and then decays but still provides significant contributions for larger \(x\). A naive evaluation would have a confidence interval of&lt;/p&gt;
    &lt;quote&gt;Ic(10_000, 0, 100, x =&amp;gt; Math.sin(x)/x)&lt;/quote&gt;
    &lt;quote&gt;Object { p05: 1.461 p95: 1.884 }&lt;/quote&gt;
    &lt;p&gt;and while this is certainly correct2 The actual value of the integral is half \(\pi\) or approximatey 1.571., we can do better. We’ll estimate the region of 0–6 separately from 6–100, using half the samples for each3 Why put the break point at 6? The period of sin is a full turn, which is roughly 6 radians. This ensures we get roughly symmetric contributions from both integrals. That’s not necessary for the technique to work, but it makes the illustration a little cleaner.:&lt;/p&gt;
    &lt;quote&gt;Ic(5_000, 0, 6, x =&amp;gt; Math.sin(x)/x)&lt;/quote&gt;
    &lt;quote&gt;Object { p05: 1.236 p95: 1.468 }&lt;/quote&gt;
    &lt;p&gt;This contains the bulk of the value of the integral, it seems. Let’s see what remains in the rest of it.&lt;/p&gt;
    &lt;quote&gt;Ic(5_000, 6, 100, x =&amp;gt; Math.sin(x)/x)&lt;/quote&gt;
    &lt;quote&gt;Object { p05: 0.080 p95: 0.198 }&lt;/quote&gt;
    &lt;p&gt;We can work backwards to what the standard errors must have been to produce these confidence intervals.4 The midpoint is the point estimation for each region, and the standard error is 1/1.645 times the distance between the 5 % point and the midpoint.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Region&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
        &lt;cell role="head"&gt;Standard error&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;0–6&lt;/cell&gt;
        &lt;cell&gt;1.4067&lt;/cell&gt;
        &lt;cell&gt;0.0372&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;6–100&lt;/cell&gt;
        &lt;cell&gt;0.1390&lt;/cell&gt;
        &lt;cell&gt;0.0359&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The estimation of the total area would be the values summed, i.e. 1.5457. The estimation of the standard error of this we get through Pythagorean addition and it is approximately 0.05143. We convert it back to a confidence interval and compare with when we did not break it up into multiple components.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Method&lt;/cell&gt;
        &lt;cell role="head"&gt;5 %&lt;/cell&gt;
        &lt;cell role="head"&gt;95 %&lt;/cell&gt;
        &lt;cell role="head"&gt;Range&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Single operation (10,000 samples)&lt;/cell&gt;
        &lt;cell&gt;1.461&lt;/cell&gt;
        &lt;cell&gt;1.884&lt;/cell&gt;
        &lt;cell&gt;0.423&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Two operations (5,000 samples × 2)&lt;/cell&gt;
        &lt;cell&gt;1.461&lt;/cell&gt;
        &lt;cell&gt;1.630&lt;/cell&gt;
        &lt;cell&gt;0.169&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Although in this case the two methods happen to share a lower bound, the upper bound has been dramatically reduced. The total range of the confidence interval is more than halved! This was because we allocated the samples more cleverly – concentrated them in the early parts of the function – rather than increased the number of samples.&lt;/p&gt;
    &lt;p&gt;That said, we’re at a computer, so we could try increasing the sample count. Or maybe both?&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Method&lt;/cell&gt;
        &lt;cell role="head"&gt;5 %&lt;/cell&gt;
        &lt;cell role="head"&gt;95 %&lt;/cell&gt;
        &lt;cell role="head"&gt;Range&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Single operation (10,000 samples)&lt;/cell&gt;
        &lt;cell&gt;1.461&lt;/cell&gt;
        &lt;cell&gt;1.884&lt;/cell&gt;
        &lt;cell&gt;0.423&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Two operations (5,000 samples × 2)&lt;/cell&gt;
        &lt;cell&gt;1.461&lt;/cell&gt;
        &lt;cell&gt;1.630&lt;/cell&gt;
        &lt;cell&gt;0.169&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Single operation (100,000 samples)&lt;/cell&gt;
        &lt;cell&gt;1.549&lt;/cell&gt;
        &lt;cell&gt;1.680&lt;/cell&gt;
        &lt;cell&gt;0.131&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Two operations (50,000 samples × 2)&lt;/cell&gt;
        &lt;cell&gt;1.524&lt;/cell&gt;
        &lt;cell&gt;1.578&lt;/cell&gt;
        &lt;cell&gt;0.054&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;It seems like sampling more cleverly has almost the same effect as taking ten times as many samples.&lt;/p&gt;
    &lt;p&gt;We could play around with where to put the breakpoint, and how many samples to allocate to each side of it, and see which combination yields the lowest error. Then we can run that combination with a lot of samples to get the most accurate final result. That would take maybe 15 minutes of tooting about and exploring sensible-seeming alternatives, so it’s probably still quicker than integrating by hand.&lt;/p&gt;
    &lt;head rend="h1"&gt;When the computer is not enough&lt;/head&gt;
    &lt;p&gt;It should be said that there are times when numeric solutions aren’t great. I hear that in electronics and quantum dynamics, there are sometimes integrals whose value is not a number, but a function, and knowing that function is important in order to know how the thing it’s modeling behaves in interactions with other things.&lt;/p&gt;
    &lt;p&gt;Those are not my domains, though. And when that’s not the case, the computer beats Feynman any day of the week.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46149066</guid><pubDate>Thu, 04 Dec 2025 16:03:02 +0000</pubDate></item><item><title>Autism should not be treated as a single condition</title><link>https://www.economist.com/science-and-technology/2025/12/03/why-autism-should-not-be-treated-as-a-single-condition</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46149375</guid><pubDate>Thu, 04 Dec 2025 16:25:31 +0000</pubDate></item><item><title>Launch HN: Browser Buddy (YC W24) – A recommendation system for Internet writing</title><link>https://www.browserbuddy.com/</link><description>&lt;doc fingerprint="3bd993f7b8d51a27"&gt;
  &lt;main&gt;
    &lt;p&gt;A For-You page for writing Explore the best essays and blogs on the Internet with Browser Buddy.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46149727</guid><pubDate>Thu, 04 Dec 2025 16:52:56 +0000</pubDate></item><item><title>Multivox: Volumetric Display</title><link>https://github.com/AncientJames/multivox</link><description>&lt;doc fingerprint="87cd881f7921b9c9"&gt;
  &lt;main&gt;
    &lt;p&gt;This is the code I currently use to drive my volumetric displays.&lt;/p&gt;
    &lt;p&gt;It supports two closely related devices which are configured in the &lt;code&gt;src/driver/gadgets&lt;/code&gt; directory:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Rotovox is a 400mm Orb featuring two 128x64 panels arranged vertically side by side.&lt;/item&gt;
      &lt;item&gt;Vortex is a 300mm Orb featuring two 128x64 panels arranged horizontally, back to back.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Rotovox has a higher vertical resolution and better horizontal density; Vortex is brighter and has a higher refresh rate.&lt;/p&gt;
    &lt;p&gt;The 3D printable parts for Vortex are available here.&lt;/p&gt;
    &lt;p&gt;This code was originally written for a single display, and the device specific code was later somewhat abstracted out to support a second similar gadget. There are assumptions about the hardware that are pretty well baked in:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It consists of two HUB75 LED panels spinning around a vertical axis.&lt;/item&gt;
      &lt;item&gt;The panels use either ABCDE addressing or ABC shift register addressing.&lt;/item&gt;
      &lt;item&gt;It uses a single GPIO (a photodiode or similar) to sync to rotation - high for 180°, low for 180°.&lt;/item&gt;
      &lt;item&gt;It's running on a Raspberry Pi 4.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The GPIO mappings and panel layout are defined in &lt;code&gt;src/driver/gadgets/gadget_&amp;lt;name&amp;gt;.h&lt;/code&gt;. GPIO is via memory mapped
access - if you're using a different model of Pi you'll need to change &lt;code&gt;BCM_BASE&lt;/code&gt; in the GPIO code. I haven't tested
this, and you should probably assume it doesn't work.&lt;/p&gt;
    &lt;p&gt;Input is via a bluetooth gamepad - I've been using an Xbox controller, and the input system is based on the default mapping for that.&lt;/p&gt;
    &lt;p&gt;Audio out is also via bluetooth. I haven't had success with the higher quality codecs, but the headset protocol works.&lt;/p&gt;
    &lt;p&gt;There are two parts to this code - the driver, which creates a voxel buffer in shared memory and scans its contents out in sync with rotation, and the client code which generates content and writes it into the voxel buffer. Both driver and client code are designed to run on the same device, a Raspberry Pi embedded in the hardware and spinning at several hundred RPM. There is a demo included in the Python directory which streams point clouds from a PC over wifi to the device, but fundamentally it's designed as a self contained gadget, like an alternate timeline Vectrex. A bluetooth gamepad is used to control the demos.&lt;/p&gt;
    &lt;code&gt;├── src
│   ├── driver
│   │   ├── gadgets         -- the different volumetric display configurations
│   │   │   └──             
│   │   └── vortex.c        -- driver code - creates a voxel buffer in shared memory,
│   │                          and handles scanning it out to the led panels in sync with
│   │                          the rotation
│   ├── simulator
│   │   └── virtex.c        -- software simulator - presents the same voxel buffer as
│   │                          the driver would, but renders the contents into an X11 window
│   │
│   ├── multivox            -- front end / launcher for the various volumetric toys
│   │   └──
│   ├── platform            -- common client code
│   │   └──
│   └── toys                -- a collection of volumetric demos using the shared voxel buffer
│       ├── eighty          -- multiplayer light cycles
│       ├── fireworks.c     -- cheesy first demo
│       ├── flight.c        -- some kind of 70s scifi thing
│       ├── tesseract.c     -- a 4D cubube
│       ├── viewer.c        -- viewer for .obj and .png files
│       └── zander          -- lander/zarch/virus-esque
├── python  
│   ├── calibration.py      -
│   ├── grid.py             -- some pattern generators, useful when calibrating the device
│   ├── colourwheel.py      -
│   ├── obj2c.py            -- tool for embedding .obj models in a header file
│   ├── pointvision.py      -- receive point clouds streamed from vortexstream.py
│   └── vortexstream.py     -- stream point clouds to pointvision.py
└── README.md               -- you are here
&lt;/code&gt;
    &lt;p&gt;On the Raspberry Pi, clone the repository:&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/AncientJames/multivox.git
&lt;/code&gt;
    &lt;p&gt;Configure the project for your hardware:&lt;/p&gt;
    &lt;code&gt;cd multivox
mkdir build
cd build
cmake -DMULTIVOX_GADGET=vortex ..
cmake --build .
&lt;/code&gt;
    &lt;p&gt;First, the driver has to be running:&lt;/p&gt;
    &lt;code&gt;sudo ./vortex
&lt;/code&gt;
    &lt;p&gt;When invoked from the command line it periodically outputs profiling information (frame rate, rotation rate), and accepts keyboard input for various diagnostics:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Key&lt;/cell&gt;
        &lt;cell role="head"&gt;Effect&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;esc&lt;/cell&gt;
        &lt;cell&gt;Exit&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;b&lt;/cell&gt;
        &lt;cell&gt;Bit depth - cycles through 1, 2 or 3 bits per channel. Higher bit depths result in lower refresh rates&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;u&lt;/cell&gt;
        &lt;cell&gt;Uniformity - cycles through different strategies for trading off brightness against uniformity&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;t&lt;/cell&gt;
        &lt;cell&gt;Trails - adjusts how far back to accumulate skipped voxels when the rotation rate is too high for the refresh rate&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;l&lt;/cell&gt;
        &lt;cell&gt;Lock - whether to adjust the rotation sync to keep it facing one way&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;d D&lt;/cell&gt;
        &lt;cell&gt;Drift - rotisserie mode. Introduces some explicit drift to the rotation sync&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;p&lt;/cell&gt;
        &lt;cell&gt;Panel - selectively disable the panels&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;xyz&lt;/cell&gt;
        &lt;cell&gt;Axis - When the display isn't spinning, it shows an othographic view. This lets you choose the axis&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;While that's running, try one of the toys:&lt;/p&gt;
    &lt;code&gt;./tesseract
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;viewer&lt;/code&gt; takes a list of .obj and .png files as arguments. You can scale, rotate and so on using the gamepad, and it
also accepts keyboard input when run remotely from the command line.&lt;/p&gt;
    &lt;code&gt;./viewer ~/Multivox/models/*.obj
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Control&lt;/cell&gt;
        &lt;cell role="head"&gt;Key&lt;/cell&gt;
        &lt;cell role="head"&gt;Effect&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;esc&lt;/cell&gt;
        &lt;cell&gt;Exit&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;LB/RB&lt;/cell&gt;
        &lt;cell&gt;[ / ]&lt;/cell&gt;
        &lt;cell&gt;Cycle through models&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;A&lt;/cell&gt;
        &lt;cell&gt;Walkthrough / Orbit&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;X&lt;/cell&gt;
        &lt;cell&gt;Zoom to fit&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;Toggle wireframe&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;If you don't have a physical volumetric display, there's a simulator, &lt;code&gt;virtex&lt;/code&gt;, which you can run in place of &lt;code&gt;vortex&lt;/code&gt;. It exposes the same voxel buffer in shared memory, but renders the contents using OpenGL in an X11 window.&lt;/p&gt;
    &lt;p&gt;Run without command line arguments it creates a display compatible with the currently configured gadget, but there are some options to let you experiment with different geometries:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Option&lt;/cell&gt;
        &lt;cell role="head"&gt;Effect&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;-s X&lt;/cell&gt;
        &lt;cell&gt;slice count - the number of vertical slices per revolution&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;-o X X&lt;/cell&gt;
        &lt;cell&gt;offsets - distance the front and back screens are offset from the axis, as a fraction of screen radius&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;-b X&lt;/cell&gt;
        &lt;cell&gt;bits per channel (1 - 3)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;-w X Y&lt;/cell&gt;
        &lt;cell&gt;panel resolution&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;-g X&lt;/cell&gt;
        &lt;cell&gt;scan geometry - radial or linear. Linear looks better, but it's a lot harder to build.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;An idealised device with linear scanning and 3 bits per channel can be invoked like this:&lt;/p&gt;
    &lt;code&gt;./virtex -g l -s 128 -w 1280 1280 -b 3
&lt;/code&gt;
    &lt;p&gt;The simulator is fill rate intensive; if you're running it on a Raspberry Pi you'll probably want to reduce the slice count.&lt;/p&gt;
    &lt;p&gt;If you want it to start up automatically on boot, you can install &lt;code&gt;vortex&lt;/code&gt; as a service, and set &lt;code&gt;multivox&lt;/code&gt; to run on startup.&lt;/p&gt;
    &lt;p&gt;First install everything to its default location &lt;code&gt;~/Multivox&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;make install&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This will build the executable files and copy them into the destination directory, as well as creating &lt;code&gt;.mct&lt;/code&gt; files in &lt;code&gt;~/Multivox/carts&lt;/code&gt; for the built in toys.&lt;/p&gt;
    &lt;p&gt;Create the driver service:&lt;/p&gt;
    &lt;code&gt;sudo nano /usr/lib/systemd/system/vortex.service
&lt;/code&gt;
    &lt;p&gt;and fill in the following information:&lt;/p&gt;
    &lt;code&gt;[Unit]
Description=Vortex Display Driver
After=multi-user.target

[Service]
ExecStart=/home/pi/Multivox/bin/vortex

[Install]
WantedBy=multi-user.target
&lt;/code&gt;
    &lt;p&gt;Then start it up:&lt;/p&gt;
    &lt;code&gt;sudo systemctl daemon-reload
sudo systemctl enable vortex.service
&lt;/code&gt;
    &lt;p&gt;The driver assigns itself to core 3 - you can add &lt;code&gt;isolcpus=3&lt;/code&gt; to the end of &lt;code&gt;/boot/cmdline.txt&lt;/code&gt; to ensure it's the only thing running on that core.&lt;/p&gt;
    &lt;p&gt;You'll also want the launcher to start up on boot:&lt;/p&gt;
    &lt;code&gt;crontab -e
&lt;/code&gt;
    &lt;p&gt;And add the line:&lt;/p&gt;
    &lt;code&gt;@reboot /home/pi/Multivox/bin/multivox
&lt;/code&gt;
    &lt;p&gt;If everything goes smoothly, when you turn on the device it will boot up into &lt;code&gt;Multivox&lt;/code&gt;. This is a fantasy console which
acts as a launcher for all the games and demos you run on the hardware. The bundled toys are automatically installed in
the &lt;code&gt;~/Multivox/carts/&lt;/code&gt; directory as &lt;code&gt;.mct&lt;/code&gt; files, and external apps can be launched by adding a &lt;code&gt;.mct&lt;/code&gt; file containing
its command, path and arguments.&lt;/p&gt;
    &lt;p&gt;Each &lt;code&gt;.mct&lt;/code&gt; file appears as a cartridge in the Multivox front end. They should each have a label on the side; at the moment
all you can do to distinguish between them is change their colour in the &lt;code&gt;.mct&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;When you exit an app back to the launcher, it saves a snapshot of the voxel volume, and this gives a preview of what you'll see when you launch a cart. This means there are two competing representations of the same information, and any future work on the front end will probably start with overhauling the entire approach.&lt;/p&gt;
    &lt;p&gt;Some basic UI for controls such as changing bit depth, rebooting and so on would also be a boon.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Control&lt;/cell&gt;
        &lt;cell role="head"&gt;Effect&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;LB/RB&lt;/cell&gt;
        &lt;cell&gt;Cycle through carts&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;A&lt;/cell&gt;
        &lt;cell&gt;Launch cart&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;⧉&lt;/cell&gt;
        &lt;cell&gt;Exit / resume running cart&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;△ ▽&lt;/cell&gt;
        &lt;cell&gt;Change bit depth&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;☰ x5&lt;/cell&gt;
        &lt;cell&gt;Power off&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46149813</guid><pubDate>Thu, 04 Dec 2025 16:58:35 +0000</pubDate></item><item><title>Converge (YC S23) is hiring a martech expert in NYC</title><link>https://www.runconverge.com/careers/technical-customer-success-manager</link><description>&lt;doc fingerprint="ad21d2738937a54f"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Technical Customer Success Manager&lt;/head&gt;
    &lt;p&gt;Converge is building the definitive Growth OS: We help DTC Growth teams understand which marketing efforts drive profitable growth. We are the only platform combining best-in-class tracking with blended reporting and multi-touch attribution.&lt;/p&gt;
    &lt;p&gt;Our unique positioning has led to rapid growth in both number and size of customers. One of the secrets of our growth is that we invest heavily in customer success. Whereas our competitors see success as a cost center, we take pride in delivering expert martech and marketing reporting support throughout the entire customer lifecycle and we compensate accordingly.&lt;/p&gt;
    &lt;p&gt;Our strategy is paying off, with 200+ paying customers (including some of the most famous DTC brands) and strong investor backing. We are now looking for a senior Technical Customer Success Manager to help us scale to $10M+ ARR.&lt;/p&gt;
    &lt;head rend="h3"&gt;Responsibilities&lt;/head&gt;
    &lt;p&gt;Be a marketing measurement expert: Advise customers on attribution, conversion tracking, and reporting strategies, positioning yourself as a trusted technical partner.&lt;/p&gt;
    &lt;p&gt;Technical support: Investigate and resolve conversion tracking and attribution issues reported through all channels, including email, Slack and in-app.&lt;/p&gt;
    &lt;p&gt;Onboard new customers: Own the customer onboarding end-to-end, driving them from initial implementation to real and lasting success.&lt;/p&gt;
    &lt;p&gt;Drive renewals: Take full ownership of renewal conversations, mitigating churn risk and implementing proactive retention strategies.&lt;/p&gt;
    &lt;p&gt;Champion customer needs: Surface trends and insights from collected customer feedback to the team at large to inform product roadmap.&lt;/p&gt;
    &lt;p&gt;Activate: Maximize the adoption of our product features and provide proactive, regular recommendations to get more out of the platform.&lt;/p&gt;
    &lt;p&gt;Expand customer contracts: Identify and execute expansion opportunities to increase account value.&lt;/p&gt;
    &lt;p&gt;Lead strategic projects: Improve the support experience and feature adoption.&lt;/p&gt;
    &lt;head rend="h3"&gt;You will thrive in this role if you&lt;/head&gt;
    &lt;p&gt;Have strong martech experience: Google Tag Manager, Meta Events Manager, Google Consent Mode and other pieces of the martech stack have no secrets for you.&lt;/p&gt;
    &lt;p&gt;Are curious and technical: You love understanding complex products deeply. Bonus points if you already love JS debugging, sifting through network requests or reasoning over attribution logic.&lt;/p&gt;
    &lt;p&gt;Thrive in ambiguity: You enjoy building processes from scratch and figuring things out without a playbook.&lt;/p&gt;
    &lt;p&gt;Are commercially minded: You know how to uncover customer needs and tie solutions to real business value.&lt;/p&gt;
    &lt;p&gt;Have advertising experience: You speak the language of a growth team, and have experience with Ads Managers, attribution and creative strategy.&lt;/p&gt;
    &lt;head rend="h3"&gt;This role is not for you if you&lt;/head&gt;
    &lt;p&gt;Do not want to become an expert: Our customers choose us because we deeply understand their technical challenges.&lt;/p&gt;
    &lt;p&gt;Prefer certainty over upside: There are no rigid and limited responsibilities here - we grant a lot of agency and expect a lot of accountability.&lt;/p&gt;
    &lt;p&gt;Don't like working hard: This role demands more commitment and agency than a typical success role.&lt;/p&gt;
    &lt;p&gt;Prefer remote over in-person: We believe being in-person helps us move faster.&lt;/p&gt;
    &lt;head rend="h3"&gt;What we offer&lt;/head&gt;
    &lt;p&gt;Compensation: $155k - $217k + equity: 0.1% - 0.25%.&lt;/p&gt;
    &lt;p&gt;Career-defining opportunity to build the U.S. success function and work with the world's best DTC growth teams.&lt;/p&gt;
    &lt;p&gt;Private health, dental, and vision insurance.&lt;/p&gt;
    &lt;p&gt;Pension &amp;amp; 401k contributions.&lt;/p&gt;
    &lt;p&gt;Opportunity to work on a complex product that customers love - 35% of our users use us daily (!)&lt;/p&gt;
    &lt;head rend="h3"&gt;Interview process*&lt;/head&gt;
    &lt;p&gt;Application: We're looking to see how your skills and experience align with our needs.&lt;/p&gt;
    &lt;p&gt;Intro interview (30-min): Our goal is to learn more about what you are looking for in your next role, explore your motivations to join our team, why you would be a great fit, and answer questions about us.&lt;/p&gt;
    &lt;p&gt;Culture interview (45-min): We will walk through your experience and background in detail.&lt;/p&gt;
    &lt;p&gt;Case interview (1 hour): We will simulate a real customer situation.&lt;/p&gt;
    &lt;p&gt;Offer If everyoneâs aligned, weâll move quickly to make you an offer.&lt;/p&gt;
    &lt;p&gt;(*) can be done in 2 days, just flag to us that you want to do it fast.&lt;/p&gt;
    &lt;head rend="h2"&gt;We raised $5.7M from some of the best investors&lt;/head&gt;
    &lt;head rend="h3"&gt;James Hawkins&lt;/head&gt;
    &lt;head rend="h3"&gt;Nicolas Dessaigne&lt;/head&gt;
    &lt;head rend="h2"&gt;What makes Converge unique&lt;/head&gt;
    &lt;head rend="h3"&gt;Ridiculously lean&lt;/head&gt;
    &lt;p&gt;We operate a &amp;gt;$1M ARR business with &amp;gt;200 customers with a team of just 9 people.&lt;/p&gt;
    &lt;p&gt;Why you should care:&lt;/p&gt;
    &lt;p&gt;You will not find a startup with this level of product-market-fit where you can join as employee #10.&lt;/p&gt;
    &lt;head rend="h3"&gt;Huge product surface&lt;/head&gt;
    &lt;p&gt;We compete with Segment, Fivetran, Google Tag Manager, Rockerbox, Looker, just to name a few.&lt;/p&gt;
    &lt;p&gt;Why you should care:&lt;/p&gt;
    &lt;p&gt;Other startups give you ownership of a feature. At Converge, you get ownership over an entire product.&lt;/p&gt;
    &lt;head rend="h3"&gt;Customers rely on us&lt;/head&gt;
    &lt;p&gt;Converge sees 35% of its users daily, while this is only 13% for the average SaaS company.&lt;/p&gt;
    &lt;p&gt;Why you should care:&lt;/p&gt;
    &lt;p&gt;Our customers will be excited by every feature you ship, and your impact will be felt immediately.&lt;/p&gt;
    &lt;head rend="h3"&gt;Real scale&lt;/head&gt;
    &lt;p&gt;We collect around 20M customer interactions per day and process ~$3B in GMV annually.&lt;/p&gt;
    &lt;p&gt;Why you should care:&lt;/p&gt;
    &lt;p&gt;Even though you join early, this job comes with real engineering challenges.&lt;/p&gt;
    &lt;head rend="h2"&gt;How we started&lt;/head&gt;
    &lt;head rend="h3"&gt;Did you knowâ¦&lt;/head&gt;
    &lt;p&gt;All co-founders have written code that has run in production as part of Converge.&lt;/p&gt;
    &lt;p&gt;We closed our first publicly traded company during our YC batch from our living room in San Francisco.&lt;/p&gt;
    &lt;p&gt;Thomas and Tiago (Founding Engineer) worked together when Thomas was just an intern.&lt;/p&gt;
    &lt;p&gt;Michel (Customer Success) was responsible for most of the incoming Converge Support tickets in his previous job as a freelance tracking consultant.&lt;/p&gt;
    &lt;p&gt;Thomas and Jan were best friends in high school, and Jan and Jerome met in their first year of college.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46149849</guid><pubDate>Thu, 04 Dec 2025 17:00:37 +0000</pubDate></item><item><title>PyTogether: Collaborative lightweight real-time Python IDE for teachers/learners</title><link>https://github.com/SJRiz/pytogether</link><description>&lt;doc fingerprint="123b677f1dffb17a"&gt;
  &lt;main&gt;
    &lt;p&gt;&lt;lb/&gt; PyTogether&lt;lb/&gt; Google docs for Python. A fully browser-based collaborative Python IDE with real-time editing, chat, and visualization. &lt;lb/&gt; pytogether.org &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Real-time Collaboration - Edit Python code together instantly using Y.js.&lt;/item&gt;
      &lt;item&gt;Secure Authentication - Log in manually or with Google OAuth.&lt;/item&gt;
      &lt;item&gt;Groups &amp;amp; Projects - Organize your work into teams and projects.&lt;/item&gt;
      &lt;item&gt;Live Drawings - Draw directly on the IDE to assist with note-taking or teaching.&lt;/item&gt;
      &lt;item&gt;Live Cursors/Selections - Google docs-like live selections for smoother collaboration.&lt;/item&gt;
      &lt;item&gt;Live Chat and Voice Calls - Real-time messaging, and Discord-like voice chats for each project.&lt;/item&gt;
      &lt;item&gt;Code Linting - Integrated CodeMirror linting for cleaner, error-free code.&lt;/item&gt;
      &lt;item&gt;Smart Autosave - Code is automatically saved every minute and on exit.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When starting out in programming, many beginners find traditional IDEs overwhelming: full of plugins, extensions, configuration steps, paywalls, and complex UIs. PyTogether removes these barriers by offering a lightweight, distraction-free environment where you can focus on writing Python code right away.&lt;/p&gt;
    &lt;p&gt;The platform is designed for learning, teaching, and pair programming, making it ideal for classrooms, coding clubs, or quick collaborations.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Note: PyTogether is intended for educational purposes and beginner use. It is not optimized for large-scale production development.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;While there are many online IDEs (Replit, Jupyter, Google Colab, etc.), PyTogether is built with a different goal: simplicity first.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;⚡Instant Setup⚡- No downloads, no pip installs, no hidden complexity. Just create a group, create a project, and bam!&lt;/item&gt;
      &lt;item&gt;Beginner Focused - No confusing menus, terminals, or configuration. Just code and run.&lt;/item&gt;
      &lt;item&gt;Real-Time Collaboration - Work together with classmates, friends, or mentors in the same editor.&lt;/item&gt;
      &lt;item&gt;Safe Learning Space - Limited features by design to reduce distractions and keep beginners focused.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Unlike production-grade IDEs, PyTogether prioritizes ease of use and collaboration for learners rather than advanced features.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Backend: Django, Django REST Framework (DRF)&lt;/item&gt;
      &lt;item&gt;Real-Time: Y.js, WebSockets (Django Channels)&lt;/item&gt;
      &lt;item&gt;Async Processing: Celery&lt;/item&gt;
      &lt;item&gt;Data Store: PostgreSQL (via Supabase)&lt;/item&gt;
      &lt;item&gt;Caching, Broker, &amp;amp; Channel layers: Redis&lt;/item&gt;
      &lt;item&gt;Frontend: React, Tailwind CSS, CodeMirror (code linting)&lt;/item&gt;
      &lt;item&gt;Python Execution: Pyodide (via Web Worker)&lt;/item&gt;
      &lt;item&gt;Deployment: Vercel (Frontend), Docker on VPS (Backend), Nginx (reverse proxy)&lt;/item&gt;
      &lt;item&gt;CI/CD: GitHub Actions (deploy backend to VPS on push to main)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Requirements: Docker, Node&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Running PyTogether locally is a simple two-step process. Run the following commands from the project root:&lt;/p&gt;
    &lt;code&gt;# 1. Install all dependencies (automatically does it for root and frontend)
npm install

# 2. Start the servers
npm run dev&lt;/code&gt;
    &lt;p&gt;This will install all required packages and run the backend container and start the frontend. It should take around 2-5 minutes on initial launch. The frontend will be live on http://localhost:5173. You can do CTRL+C to stop the program/containers.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Note Two superusers are created automatically:&lt;/p&gt;&lt;item&gt;Email:&lt;/item&gt;&lt;code&gt;test1@gmail.com&lt;/code&gt;&lt;item&gt;Email:&lt;/item&gt;&lt;code&gt;test2@gmail.com&lt;/code&gt;&lt;p&gt;Both have the password&lt;/p&gt;&lt;code&gt;testtest&lt;/code&gt;. You can log in with them on the frontend.&lt;/quote&gt;
    &lt;p&gt;You may also adjust the settings in backend/backend/settings/dev.py&lt;/p&gt;
    &lt;p&gt;Jawad Rizvi&lt;/p&gt;
    &lt;p&gt;Applied Mathematics &amp;amp; Computer Engineering student at Queen's University.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46150447</guid><pubDate>Thu, 04 Dec 2025 17:43:07 +0000</pubDate></item><item><title>Why are 38 percent of Stanford students saying they're disabled?</title><link>https://reason.com/2025/12/04/why-are-38-percent-of-stanford-students-saying-theyre-disabled/</link><description>&lt;doc fingerprint="1e71405b38cb1c86"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why Are 38 Percent of Stanford Students Saying They're Disabled?&lt;/head&gt;
    &lt;head rend="h2"&gt;If you get into an elite college, you probably don't have a learning disability.&lt;/head&gt;
    &lt;p&gt;The students at America's elite universities are supposed to be the smartest, most promising young people in the country. And yet, shocking percentages of them are claiming academic accommodations designed for students with learning disabilities.&lt;/p&gt;
    &lt;p&gt;In an article published this week in The Atlantic, education reporter Rose Horowitch lays out some shocking numbers. At Brown and Harvard, 20 percent of undergraduate students are disabled. At Amherst College, that's 34 percent. At Stanford University, it's a galling 38 percent. Most of these students are claiming mental health conditions and learning disabilities, like anxiety, depression, and ADHD.&lt;/p&gt;
    &lt;p&gt;Obviously, something is off here. The idea that some of the most elite, selective universities in America—schools that require 99th percentile SATs and sterling essays—would be educating large numbers of genuinely learning disabled students is clearly bogus. A student with real cognitive struggles is much more likely to end up in community college, or not in higher education at all, right?&lt;/p&gt;
    &lt;p&gt;The professors Horowitz interviewed largely back up this theory. "You hear 'students with disabilities' and it's not kids in wheelchairs," one professor told Horowitch. "It's just not. It's rich kids getting extra time on tests." Talented students get to college, start struggling, and run for a diagnosis to avoid bad grades. Ironically, the very schools that cognitively challenged students are most likely to attend—community colleges—have far lower rates of disabled students, with only three to four percent of such students getting accommodations.&lt;/p&gt;
    &lt;p&gt;To be fair, some of the students receiving these accommodations do need them. But the current language of the Americans with Disabilities Act (ADA) allows students to get expansive accommodations with little more than a doctor's note.&lt;/p&gt;
    &lt;p&gt;While some students are no doubt seeking these accommodations as semi-conscious cheaters, I think most genuinely identify with the mental health condition they're using to get extra time on tests. Over the past few years, there's been a rising push to see mental health and neurodevelopmental conditions as not just a medical fact, but an identity marker. Will Lindstrom, the director of the Regents' Center for Learning Disorders at the University of Georgia, told Horowitch that he sees a growing number of students with this perspective. "It's almost like it's part of their identity," Lindstrom told her. "By the time we see them, they're convinced they have a neurodevelopmental disorder."&lt;/p&gt;
    &lt;p&gt;What's driving this trend? Well, the way conditions like ADHD, autism, and anxiety get talked about online—the place where most young people first learn about these conditions—is probably a contributing factor. Online creators tend to paint a very broad picture of the conditions they describe. A quick scroll of TikTok reveals creators labeling everything from always wearing headphones, to being bad at managing your time, to doodling in class as a sign that someone may have a diagnosable condition. According to these videos, who isn't disabled?&lt;/p&gt;
    &lt;p&gt;The result is a deeply distorted view of "normal." If ever struggling to focus or experiencing boredom is a sign you have ADHD, the implication is that a "normal," nondisabled person has essentially no problems. A "neurotypical" person, the thinking goes, can churn out a 15-page paper with no hint of procrastination, maintain perfect focus during a boring lecture, and never experience social anxiety or awkwardness. This view is buffeted by the current way many of these conditions are diagnosed. As Horowitch points out, when the latest issue of the DSM, the manual psychiatrists use to diagnose patients, was released in 2013, it significantly lowered the bar for an ADHD diagnosis. When the definition of these conditions is set so liberally, it's easy to imagine a highly intelligent Stanford student becoming convinced that any sign of academic struggle proves they're learning disabled, and any problems making friends are a sign they have autism.&lt;/p&gt;
    &lt;p&gt;Risk-aversion, too, seems like a compelling factor driving bright students to claim learning disabilities. Our nation's most promising students are also its least assured. So afraid of failure—of bad grades, of a poorly-received essay—they take any sign of struggle as a diagnosable condition. A few decades ago, a student who entered college and found the material harder to master and their time less easily managed than in high school would have been seen as relatively normal. Now, every time she picks up her phone, a barrage of influencers is clamoring to tell her this is a sign she has ADHD. Discomfort and difficulty are no longer perceived as typical parts of growing up.&lt;/p&gt;
    &lt;p&gt;In this context, it's easy to read the rise of academic accommodations among the nation's most intelligent students as yet another manifestation of the risk-aversion endemic in the striving children of the upper middle class. For most of the elite-college students who receive them, academic accommodations are a protection against failure and self-doubt. Unnecessary accommodations are a two-front form of cheating—they give you an unjust leg-up on your fellow students, but they also allow you to cheat yourself out of genuine intellectual growth. If you mask learning deficiencies with extra time on texts, soothe social anxiety by forgoing presentations, and neglect time management skills with deadline extensions, you might forge a path to better grades. But you'll also find yourself less capable of tackling the challenges of adult life.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46150715</guid><pubDate>Thu, 04 Dec 2025 18:04:07 +0000</pubDate></item><item><title>Hammersmith Bridge – Where did 25,000 vehicles go?</title><link>https://nickmaini.substack.com/p/hammersmith-bridge</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46151335</guid><pubDate>Thu, 04 Dec 2025 18:52:22 +0000</pubDate></item><item><title>Who Hooked Up a Laptop to a 1930s Dance Hall Machine?</title><link>https://www.chrisbako.com/posts/2025-12-04-speelkok-museam</link><description>&lt;doc fingerprint="3b43d5f9ebb6a6b4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Who Hooked Up a Laptop to a 1930s Dance Hall Machine?&lt;/head&gt;
    &lt;p&gt;I had the pleasure of going to the Netherlands in 2023.&lt;/p&gt;
    &lt;p&gt;Amsterdam and Rotterdam are cool, but Utrecht has something really special, The Speelkok (Self playing instrument) Museum.&lt;/p&gt;
    &lt;p&gt;There’s so much cool stuff in there, automata, the only self playing violin, clocks, draaiorgels (street organs), but the coolest is this.&lt;/p&gt;
    &lt;p&gt;That is a 1930s dance hall machine. It takes in a cardboard book with hole punches. The music is encoded as punches, each hole means to play that note from the music staff. It replaced music barrels, metal barrals with nubs that hit forks from music boxes, since they could dynamically program the song.&lt;/p&gt;
    &lt;p&gt;By Richard Ash - IMG_2136, CC BY-SA 2.0, Link&lt;/p&gt;
    &lt;p&gt;But somehow someone hooked up a laptop to it! So now it can play mp3s from a laptop instead of the book. What?!&lt;/p&gt;
    &lt;p&gt;How, why and who are a total mystery to me, but I’d like to find out more.&lt;/p&gt;
    &lt;p&gt;I’ve sent the museum an email and hope to hear back for more info. It’ll take about 14 business days. If you know anything about this please reach out.&lt;/p&gt;
    &lt;p&gt;Maybe the internet can help me figure this out?&lt;/p&gt;
    &lt;p&gt;- Chris&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46151363</guid><pubDate>Thu, 04 Dec 2025 18:55:06 +0000</pubDate></item><item><title>The RAM shortage comes for us all</title><link>https://www.jeffgeerling.com/blog/2025/ram-shortage-comes-us-all</link><description>&lt;doc fingerprint="be6c90491cb603ba"&gt;
  &lt;main&gt;
    &lt;p&gt;Memory price inflation comes for us all, and if you're not affected yet, just wait.&lt;/p&gt;
    &lt;p&gt;I was building a new PC last month using some parts I had bought earlier this year. The 64 Gigabyte T-Create DDR5 memory kit I used cost $209 then. Today? The same kit costs $650!&lt;/p&gt;
    &lt;p&gt;Just in the past week, we found out Raspberry Pi's increasing their single board computer prices. Micron's killing the Crucial brand of RAM and storage devices completely, meaning there's gonna be one fewer consumer memory manufacturer. Samsung can't even buy RAM from themselves to build their own Smartphones, and small vendors like Libre Computer and Mono are seeing RAM prices double, triple, or even worse, and they're not even buying the latest RAM tech!&lt;/p&gt;
    &lt;p&gt;I think PC builders might be the first crowd to get impacted across the board—just look at these insane graphs from PC Parts Picker, showing RAM prices going from like $30 to $120 for DDR4, or like $150 to five hundred dollars for 64 gigs of DDR5.&lt;/p&gt;
    &lt;p&gt;But the impacts are only just starting to hit other markets.&lt;/p&gt;
    &lt;p&gt;Libre Computer mentioned on Twitter a single 4 gigabyte module of LPDDR4 memory costs $35. That's more expensive than every other component on one of their single board computers combined! You can't survive selling products at a loss, so once the current production batches are sold through, either prices will be increased, or certain product lines will go out of stock.&lt;/p&gt;
    &lt;p&gt;The smaller the company, the worse the price hit will be. Even Raspberry Pi, who I'm sure has a little more margin built in, already raised SBC prices (and introduced a 1 GB Pi 5—maybe a good excuse for developers to drop Javascript frameworks and program for lower memory requirements again?).&lt;/p&gt;
    &lt;p&gt;Cameras, gaming consoles, tablets, almost anything that has memory will get hit sooner or later.&lt;/p&gt;
    &lt;p&gt;I can't believe I'm saying this, but compared to the current market, Apple's insane memory upgrade pricing is... actually in line with the rest of the industry.&lt;/p&gt;
    &lt;p&gt;The reason for all this, of course, is AI datacenter buildouts. I have no clue if there's any price fixing going on like there was a few decades ago—that's something conspiracy theorists can debate—but the problem is there's only a few companies producing all the world's memory supplies.&lt;/p&gt;
    &lt;p&gt;And those companies all realized they can make billions more dollars making RAM just for AI datacenter products, and neglect the rest of the market.&lt;/p&gt;
    &lt;p&gt;So they're shutting down their consumer memory lines, and devoting all production to AI.&lt;/p&gt;
    &lt;p&gt;Even companies like GPU board manufacturers are getting shafted; Nvidia's not giving memory to them along with their chips like they used to, basically telling them "good luck, you're on your own for VRAM now!"&lt;/p&gt;
    &lt;p&gt;Which is especially rich, because Nvidia's profiting obscenely off of all this stuff.&lt;/p&gt;
    &lt;p&gt;That's all bad enough, but some people see a silver lining. I've seen some people say "well, once the AI bubble bursts, at least we'll have a ton of cheap hardware flooding the market!"&lt;/p&gt;
    &lt;p&gt;And yes, in past decades, that might be one outcome.&lt;/p&gt;
    &lt;p&gt;But the problem here is the RAM they're making, a ton of it is either integrated into specialized GPUs that won't run on normal computers, or being fitted into special types of memory modules that don't work on consumer PCs, either. (See: HBM).&lt;/p&gt;
    &lt;p&gt;That, and the GPUs and servers being deployed now don't even run on normal power and cooling, they're part of massive systems that would take a ton of effort to get running in even the most well-equipped homelabs. It's not like the classic Dell R720 that just needs some air and a wall outlet to run.&lt;/p&gt;
    &lt;p&gt;That is to say, we might be hitting a weird era where the PC building hobby is gutted, SBCs get prohibitively expensive, and anyone who didn't stockpile parts earlier this year is, pretty much, in a lurch.&lt;/p&gt;
    &lt;p&gt;Even Lenovo admits to stockpiling RAM, making this like the toilet paper situation back in 2020, except for massive corporations. Not enough supply, so companies who can afford to get some will buy it all up, hoping to stave off the shortages that will probably last longer, partly because of that stockpiling.&lt;/p&gt;
    &lt;p&gt;I don't think it's completely outlandish to think some companies will start scavenging memory chips (ala dosdude1) off other systems for stock, especially if RAM prices keep going up.&lt;/p&gt;
    &lt;p&gt;It's either that, or just stop making products. There are some echoes to the global chip shortages that hit in 2021-2022, and that really shook up the market for smaller companies.&lt;/p&gt;
    &lt;p&gt;I hate to see it happening again, but somehow, here we are a few years later, except this time, the AI bubble is to blame.&lt;/p&gt;
    &lt;p&gt;Sorry for not having a positive note to end this on, but I guess... maybe it's a good time to dig into that pile of old projects you never finished instead of buying something new this year.&lt;/p&gt;
    &lt;p&gt;How long will this last? That's anybody's guess. But I've already put off some projects I was gonna do for 2026, and I'm sure I'm not the only one.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46151578</guid><pubDate>Thu, 04 Dec 2025 19:16:11 +0000</pubDate></item><item><title>CJEU has made it effectively impossible to run a user-generated platform legally</title><link>https://www.techdirt.com/2025/12/04/eus-top-court-just-made-it-literally-impossible-to-run-a-user-generated-content-platform-legally/</link><description>&lt;doc fingerprint="a64059174333bdd7"&gt;
  &lt;main&gt;
    &lt;p&gt;Not to mension this butts up against the EU’s own rules banning general monitoring requirements creating quite the ouroboros situation.&lt;/p&gt;
    &lt;p&gt;Good luck figuring that out EU.&lt;/p&gt;
    &lt;p&gt;The Court of Justice of the EU—likely without realizing it—just completely shit the bed and made it effectively impossible to run any website in the entirety of the EU that hosts user-generated content.&lt;/p&gt;
    &lt;p&gt;Obviously, for decades now, we’ve been talking about issues related to intermediary liability, and what standards are appropriate there. I am an unabashed supporter of the US’s approach with Section 230, as it was initially interpreted, which said that any liability should land on the party who contributed the actual violative behavior—in nearly all cases the speaker, not the host of the content.&lt;/p&gt;
    &lt;p&gt;The EU has always held itself to a lower standard of intermediary liability, first with the E-Commerce Directive and more recently with the Digital Services Act (DSA), which still generally tries to put more liability on the speaker but has some ways of shifting the liability to the platform.&lt;/p&gt;
    &lt;p&gt;No matter which of those approaches you think is preferable, I don’t think anyone could (or should) favor what the Court of Justice of the EU came down with earlier this week, which is basically “fuck all this shit, if there’s any content at all on your site that includes personal data of someone you may be liable.”&lt;/p&gt;
    &lt;p&gt;As with so many legal clusterfucks, this one stems from a case with bad facts, which then leads to bad law. You can read the summary as the CJEU puts it:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The applicant in the main proceedings claims that, on 1 August 2018, an unidentified third party published on that website an untrue and harmful advertisement presenting her as offering sexual services. That advertisement contained photographs of that applicant, which had been used without her consent, along with her telephone number. The advertisement was subsequently reproduced identically on other websites containing advertising content, where it was posted online with the indication of the original source. When contacted by the applicant in the main proceedings, Russmedia Digital removed the advertisement from its website less than one hour after receiving that request. The same advertisement nevertheless remains available on other websites which have reproduced it.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;And, yes, no one is denying that this absolutely sucks for the victim in this case. But if there’s any legal recourse, it seems like it should be on whoever created and posted that fake ad. Instead, the CJEU finds that Russmedia is liable for it, even though they responded within an hour and took down the ad as soon as they found out about it.&lt;/p&gt;
    &lt;p&gt;The lower courts went back and forth on this, with a Romanian tribunal (on first appeal) finding, properly, that there’s no fucking way Russmedia should be held liable, seeing as it was merely hosting the ad and had nothing to do with its creation:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The Tribunalul Specializat Cluj (Specialised Court, Cluj, Romania) upheld that appeal, holding that the action brought by the applicant in the main proceedings was unfounded, since the advertisement at issue in the main proceedings did not originate from Russmedia, which merely provided a hosting service for that advertisement, without being actively involved in its content. Accordingly, the exemption from liability provided for in Article 14(1)(b) of Law No 365/2002 would be applicable to it. As regards the processing of personal data, that court held that an information society services provider was not required to check the information which it transmits or actively to seek data relating to apparently unlawful activities or information. In that regard, it held that Russmedia could not be criticised for failing to take measures to prevent the online distribution of the defamatory advertisement at issue in the main proceedings, given that it had rapidly removed that advertisement at the request of the applicant in the main proceedings.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;With the case sent up to the CJEU, things get totally twisted, as they argue that under the GDPR, the inclusion of “sensitive personal data” in the ad suddenly makes the host a “joint controller” of the data under that law. As a controller of data, the much stricter GDPR rules on data protection now apply, and the more careful calibration of intermediary liability rules get tossed right out the window.&lt;/p&gt;
    &lt;p&gt;And out the window, right with it, is the ability to have a functioning open internet.&lt;/p&gt;
    &lt;p&gt;The court basically shreds basic intermediary liability principles here:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In any event, the operator of an online marketplace cannot avoid its liability, as controller of personal data, on the ground that it has not itself determined the content of the advertisement at issue published on that marketplace. Indeed, to exclude such an operator from the definition of ‘controller’ on that ground alone would be contrary not only to the clear wording, but also the objective, of Article 4(7) of the GDPR, which is to ensure effective and complete protection of data subjects by means of a broad definition of the concept of ‘controller’.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Under this ruling, it appears that any website that hosts any user-generated content can be strictly liable if any of that content contains “sensitive personal data” about any person. But how the fuck are they supposed to handle that?&lt;/p&gt;
    &lt;p&gt;The basic answer is to pre-scan any user-generated content for anything that might later be deemed to be sensitive personal data and make sure it doesn’t get posted.&lt;/p&gt;
    &lt;p&gt;How would a platform do that?&lt;/p&gt;
    &lt;p&gt;¯\_(ツ)_/¯&lt;/p&gt;
    &lt;p&gt;There is no way that this is even remotely possible for any platform, no matter how large or how small. And it’s even worse than that. As intermediary liability expert Daphne Keller explains:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The Court said the host has to&lt;/p&gt;
      &lt;item&gt;pre-check posts (i.e. do general monitoring)&lt;/item&gt;
      &lt;item&gt;know who the posting user is (i.e. no anonymous speech)&lt;/item&gt;
      &lt;item&gt;try to make sure the posts don’t get copied by third parties (um, like web search engines??)&lt;/item&gt;
    &lt;/quote&gt;
    &lt;p&gt;Basically, all three of those are effectively impossible.&lt;/p&gt;
    &lt;p&gt;Think about what the court is actually demanding here. Pre-checking posts means full-scale automated surveillance of every piece of content before it goes live—not just scanning for known CSAM hashes or obvious spam, but making subjective legal determinations about what constitutes “sensitive personal data” under the GDPR. Requiring user identification kills anonymity entirely, which is its own massive speech issue. And somehow preventing third parties from copying content? That’s not even a technical problem—it’s a “how do you stop the internet from working like the internet” problem.&lt;/p&gt;
    &lt;p&gt;Some people have said that this ruling isn’t so bad, because the ruling is about advertisements and because it’s talking about “sensitive personal data.” But it’s difficult to see how either of those things limit this ruling at all.&lt;/p&gt;
    &lt;p&gt;There’s nothing inherently in the law or the ruling that limits its conclusions to “advertisements.” The same underlying factors would apply to any third party content on any website that is subject to the GDPR.&lt;/p&gt;
    &lt;p&gt;As for the “sensitive personal data” part, that makes little difference because sites will have to scan all content before anything is posted to guarantee no “sensitive personal data” is included and then accurately determine what a court might later deem to be such sensitive personal data. That means it’s highly likely that any website that tries to comply under this ruling will block a ton of content on the off chance that maybe that content will be deemed sensitive.&lt;/p&gt;
    &lt;p&gt;As the court noted:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In accordance with Article 5(1)(a) of the GDPR, personal data are to be processed lawfully, fairly and in a transparent manner in relation to the data subject. Article 5(1)(d) of the GDPR adds that personal data processed must be accurate and, where necessary, kept up to date. Thus, every reasonable step must be taken to ensure that personal data that are inaccurate, having regard to the purposes for which they are processed, are erased or rectified without delay. Article 5(1)(f) of that regulation provides that personal data must be processed in a manner that ensures appropriate security of those data, including protection against unauthorised or unlawful processing.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Good luck figuring out how to do that with third-party content.&lt;/p&gt;
    &lt;p&gt;And they’re pretty clear that every website must pre-scan every bit of content. They claim it’s about “marketplaces” and “advertisements” but there’s nothing in the GDPR that limits this ruling to those categories:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Accordingly, inasmuch as the operator of an online marketplace, such as the marketplace at issue in the main proceedings, knows or ought to know that, generally, advertisements containing sensitive data in terms of Article 9(1) of the GDPR, are liable to be published by user advertisers on its online marketplace, that operator, as controller in respect of that processing, is obliged, as soon as its service is designed, to implement appropriate technical and organisational measures in order to identify such advertisements before their publication and thus to be in a position to verify whether the sensitive data that they contain are published in compliance with the principles set out in Chapter II of that regulation. Indeed, as is apparent in particular from Article 25(1) of that regulation, the obligation to implement such measures is incumbent on it not only at the time of the processing, but already at the time of the determination of the means of processing and, therefore, even before sensitive data are published on its online marketplace in breach of those principles, that obligation being specifically intended to prevent such breaches.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;No more anonymity allowed:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;As regards, in the second place, the question whether the operator of an online marketplace, as controller of the sensitive data contained in advertisements published on its website, jointly with the user advertiser, must verify the identity of that user advertiser before the publication, it should be recalled that it follows from a combined reading of Article 9(1) and Article 9(2)(a) of the GDPR that the publication of such data is prohibited, unless the data subject has given his or her explicit consent to the data in question being published on that online marketplace or one of the other exceptions laid down in Article 9(2)(b) to (j) is satisfied, which does not, however, appear to be the case here.&lt;/p&gt;
      &lt;p&gt;On that basis, while the placing by a data subject of an advertisement containing his or her sensitive data on an online marketplace may constitute explicit consent, within the meaning of Article 9(2)(a) of the GDPR, such consent is lacking where that advertisement is placed by a third party, unless that party can demonstrate that the data subject has given his or her explicit consent to the publication of that advertisement on the online marketplace in question. Consequently, in order to be able to ensure, and to be able to demonstrate, that the requirements laid down in Article 9(2)(a) of the GDPR are complied with, the operator of the marketplace is required to verify, prior to the publication of such an advertisement, whether the user advertiser preparing to place the advertisement is the person whose sensitive data appear in that advertisement, which presupposes that the identity of that user advertiser is collected.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Finally, as Keller noted above, the CJEU seems to think it’s possible to require platforms to make sure content is never displayed on any other platform as well:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Thus, where sensitive data are published online, the controller is required, under Article 32 of the GDPR, to take all technical and organisational measures to ensure a level of security apt to effectively prevent the occurrence of a loss of control over those data.&lt;/p&gt;
      &lt;p&gt;To that end, the data controller must consider in particular all technical measures available in the current state of technical knowledge that are apt to block the copying and reproduction of online content.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Again, the CJEU appears to be living in a fantasy land that doesn’t exist.&lt;/p&gt;
    &lt;p&gt;This is what happens when you over-index on the idea of “data controllers” needing to keep data “private.” Whoever revealed sensitive data should have the liability placed on them. Putting it on the intermediary is misplaced and ridiculous.&lt;/p&gt;
    &lt;p&gt;There is simply no way to comply with the law under this ruling.&lt;/p&gt;
    &lt;p&gt;In such a world, the only options are to ignore it, shut down EU operations, or geoblock the EU entirely. I assume most platforms will simply ignore it—and hope that enforcement will be selective enough that they won’t face the full force of this ruling. But that’s a hell of a way to run the internet, where companies just cross their fingers and hope they don’t get picked for an enforcement action that could destroy them.&lt;/p&gt;
    &lt;p&gt;There’s a reason why the basic simplicity of Section 230 makes sense. It says “the person who creates the content that violates the law is responsible for it.” As soon as you open things up to say the companies that provide the tools for those who create the content can be liable, you’re opening up a can of worms that will create a huge mess in the long run.&lt;/p&gt;
    &lt;p&gt;That long run has arrived in the EU, and with it, quite the mess.&lt;/p&gt;
    &lt;p&gt; Filed Under: cjeu, controller, data protection, dsa, gdpr, intermediary liability, section 230, sensitive data, user generated content &lt;lb/&gt; Companies: russmedia &lt;/p&gt;
    &lt;p&gt;Not to mension this butts up against the EU’s own rules banning general monitoring requirements creating quite the ouroboros situation.&lt;/p&gt;
    &lt;p&gt;Good luck figuring that out EU.&lt;/p&gt;
    &lt;p&gt;Since git commits have emails (private info), and possible names, I would guess this means that git forges would be problematic in the EU too.&lt;/p&gt;
    &lt;p&gt;Especially since forging a git commit isn’t hard. And open source communities often applies patches from other people (where the committer is not the author).&lt;/p&gt;
    &lt;p&gt;Also The Linux’s kernel’s MAINTAINERS file has other contact info too.&lt;/p&gt;
    &lt;p&gt;Basically maybe the EU should just disconnect itself from the internet to ensure compliance.&lt;/p&gt;
    &lt;p&gt;If you are an artist or any content creator using a website based in the EU, or a worldwide international site like youtube using servers subject to their laws, you’ll experience:&lt;/p&gt;
    &lt;p&gt;These laws/bills might as well directly ban UGC.&lt;/p&gt;
    &lt;p&gt;Well this is a problem. I was going to move my infra to Scaleway’s AMS1 data center. Mainly because their elastic metal offerings are really good. But this ruling is a big problemo. 😛 EU, please stop making nonsensical rulings like this…&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46152098</guid><pubDate>Thu, 04 Dec 2025 19:55:04 +0000</pubDate></item><item><title>Plane crashed after 3D-printed part collapsed</title><link>https://www.bbc.com/news/articles/c1w932vqye0o</link><description>&lt;doc fingerprint="ac44743986358578"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Plane crashed after 3D-printed part collapsed&lt;/head&gt;
    &lt;p&gt;A plane crashed after a 3D-printed part softened and collapsed, causing its engine to lose power, a report has found.&lt;/p&gt;
    &lt;p&gt;The Cozy Mk IV light aircraft was destroyed after its plastic air induction elbow, bought at an air show in North America, collapsed.&lt;/p&gt;
    &lt;p&gt;The aircraft crashed into a landing aid system at Gloucestershire Airport in Staverton on 18 March at 13:04 GMT, after its engine lost power. The sole occupant was taken to hospital with minor injuries.&lt;/p&gt;
    &lt;p&gt;The Air Accidents Investigation Branch (AAIB) said in a report that the induction elbow was made of "inappropriate material" and safety actions will be taken in future regarding 3D printed parts.&lt;/p&gt;
    &lt;p&gt;Following an "uneventful local flight", the AAIB report said the pilot advanced the throttle on the final approach to the runway, and realised the engine had suffered a complete loss of power.&lt;/p&gt;
    &lt;p&gt;"He managed to fly over a road and a line of bushes on the airfield boundary, but landed short and struck the instrument landing system before coming to rest at the side of the structure," the report read.&lt;/p&gt;
    &lt;p&gt;It was revealed the part had been installed during a modification to the fuel system and collapsed due to its 3D-printed plastic material softening when exposed to heat from the engine.&lt;/p&gt;
    &lt;p&gt;The Light Aircraft Association (LAA) said it now intends to take safety actions in response to the accident, including a "LAA Alert" regarding the use of 3D-printed parts that will be sent to inspectors.&lt;/p&gt;
    &lt;p&gt;Follow BBC Gloucestershire on Facebook, X and Instagram. Send your story ideas to us on email or via WhatsApp on 0800 313 4630.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46152941</guid><pubDate>Thu, 04 Dec 2025 20:56:08 +0000</pubDate></item><item><title>CUDA-L2: Surpassing cuBLAS Performance for Matrix Multiplication Through RL</title><link>https://github.com/deepreinforce-ai/CUDA-L2</link><description>&lt;doc fingerprint="df7c7dfdcca34d95"&gt;
  &lt;main&gt;
    &lt;p&gt;CUDA-L2 is a system that combines large language models (LLMs) and reinforcement learning (RL) to automatically optimize Half-precision General Matrix Multiply (HGEMM) CUDA kernels. CUDA-L2 systematically outperforms major matmul baselines to date, from the widely-used torch.matmul to state-of-the-art NVIDIA closed-source libraries (cuBLAS, cuBLASLt-heuristic, cuBLASLt-AutoTuning). Paper&lt;/p&gt;
    &lt;p&gt;Speedup of CUDA-L2 over torch.matmul, cuBLAS, cuBLASLt-heuristic, and cuBLASLt-AutoTuning across 1000 (M,N,K) configurations on A100.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;[Dec 2, 2025] Released A100 optimized HGEMM kernels across 1,000 configurations.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Release HGEMM with 32-bit accumulator (SM80_16x8x16_F16F16F16F32 and F32F16F16F32 officially) for A100. Current version only support 16-bit accumulator (SM80_16x8x16_F16F16F16F16).&lt;/item&gt;
      &lt;item&gt;Support denser matrix configurations (more configurations).&lt;/item&gt;
      &lt;item&gt;Extend to more GPUs (Ada Lovelace, Hopper, Blackwell).&lt;/item&gt;
      &lt;item&gt;Easy deployment for open-source LLMs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Q: Do A100 kernels apply to other machines like RTX 3090 or H100?&lt;/p&gt;
    &lt;p&gt;A: Ideally, kernels trained on A100 should only be used on A100 if you are targeting speedup. They might have speedup on other machines, but it's not guaranteed. We will progressively release kernels trained on different machines.&lt;/p&gt;
    &lt;p&gt;Q: What if I need matrix dimensions (M, N, K) not found in your configurations?&lt;/p&gt;
    &lt;p&gt;A: 1. You can find the nearest neighbor configuration (larger than yours) and pad with zeros. 2. Feel free to post your dimensions on GitHub issues. We are happy to release kernels for your configuration.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Python: Ensure you have a working Python environment.&lt;/item&gt;
      &lt;item&gt;PyTorch: This project requires PyTorch version 2.6.0 or higher.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This project depends on NVIDIA CUTLASS. You must clone specific tag &lt;code&gt;v4.2.1&lt;/code&gt; into a directory named &lt;code&gt;cutlass&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;git clone -b v4.2.1 https://github.com/NVIDIA/cutlass.git cutlass&lt;/code&gt;
    &lt;quote&gt;&lt;g-emoji&gt;⚠️&lt;/g-emoji&gt;Warning: Please ensure you download the correct CUTLASS version (&lt;code&gt;v4.2.1&lt;/code&gt;) and set the&lt;code&gt;CUTLASS_DIR&lt;/code&gt;environment variable correctly. Incorrect CUTLASS setup may cause the project to fail silently or produce no results.&lt;/quote&gt;
    &lt;p&gt;Before building or running the project, you must configure the following environment variables:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;CUTLASS_DIR&lt;/code&gt;: Points to the directory where you cloned CUTLASS.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;TORCH_CUDA_ARCH_LIST&lt;/code&gt;: Specifies the target GPU architecture (e.g., "8.0" for NVIDIA Ampere / A100 / RTX 30 series).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Run the following commands:&lt;/p&gt;
    &lt;code&gt;export CUTLASS_DIR=/path/to/your/cutlass
export TORCH_CUDA_ARCH_LIST="8.0"&lt;/code&gt;
    &lt;p&gt;To run the evaluation, use the &lt;code&gt;eval_one_file.sh&lt;/code&gt; script. Below is an example command for offline mode:&lt;/p&gt;
    &lt;code&gt;./eval_one_file.sh --mnk 64_4096_64 --warmup_seconds 5 --benchmark_seconds 10 --base_dir ./results --gpu_device_id 7 --mode offline&lt;/code&gt;
    &lt;p&gt;For server mode, you need to specify &lt;code&gt;--target_qps&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;./eval_one_file.sh --mnk 64_4096_64 --warmup_seconds 5 --benchmark_seconds 10 --base_dir ./results --gpu_device_id 7 --mode server --target_qps 100&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Argument&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;--mnk&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Specifies the problem size (e.g., &lt;code&gt;64_4096_64&lt;/code&gt;).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;--warmup_seconds&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Duration of warmup in seconds before timing.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;--benchmark_seconds&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Duration of benchmarking in seconds.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;--base_dir&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Directory to save the compile and output results.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;--gpu_device_id&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;The ID of the GPU to use (e.g., &lt;code&gt;7&lt;/code&gt;).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;--mode&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Execution mode. Options are:&lt;p&gt;•&lt;/p&gt;&lt;code&gt;offline&lt;/code&gt;: Runs the evaluation in offline/batch processing mode.&lt;p&gt;•&lt;/p&gt;&lt;code&gt;server&lt;/code&gt;: Runs the evaluation in server mode (simulating request-based scenarios).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;--target_qps&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Target Queries Per Second (QPS) for server mode. Required if mode is &lt;code&gt;server&lt;/code&gt;.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;If you have any questions, please open a GitHub issue or reach out to us at jiwei_li@deep-reinforce.com.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46153058</guid><pubDate>Thu, 04 Dec 2025 21:04:29 +0000</pubDate></item><item><title>Django 6</title><link>https://docs.djangoproject.com/en/6.0/releases/6.0/</link><description>&lt;doc fingerprint="3ab9991568719b8a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Django 6.0 release notes¶&lt;/head&gt;
    &lt;p&gt;December 3, 2025&lt;/p&gt;
    &lt;p&gt;Welcome to Django 6.0!&lt;/p&gt;
    &lt;p&gt;These release notes cover the new features, as well as some backwards incompatible changes you should be aware of when upgrading from Django 5.2 or earlier. We’ve begun the deprecation process for some features.&lt;/p&gt;
    &lt;p&gt;See the How to upgrade Django to a newer version guide if you’re updating an existing project.&lt;/p&gt;
    &lt;head rend="h2"&gt;Python compatibility¶&lt;/head&gt;
    &lt;p&gt;Django 6.0 supports Python 3.12, 3.13, and 3.14. We highly recommend, and only officially support, the latest release of each series.&lt;/p&gt;
    &lt;p&gt;The Django 5.2.x series is the last to support Python 3.10 and 3.11.&lt;/p&gt;
    &lt;head rend="h2"&gt;Third-party library support for older versions of Django¶&lt;/head&gt;
    &lt;p&gt;Following the release of Django 6.0, we suggest that third-party app authors drop support for all versions of Django prior to 5.2. At that time, you should be able to run your package’s tests using &lt;code&gt;python -Wd&lt;/code&gt; so that deprecation
warnings appear. After making the deprecation warning fixes, your app should be
compatible with Django 6.0.&lt;/p&gt;
    &lt;head rend="h2"&gt;What’s new in Django 6.0¶&lt;/head&gt;
    &lt;head rend="h3"&gt;Content Security Policy support¶&lt;/head&gt;
    &lt;p&gt;Built-in support for the Content Security Policy (CSP) standard is now available, making it easier to protect web applications against content injection attacks such as cross-site scripting (XSS). CSP allows declaring trusted sources of content by giving browsers strict rules about which scripts, styles, images, or other resources can be loaded.&lt;/p&gt;
    &lt;p&gt;CSP policies can now be enforced or monitored directly using built-in tools: headers are added via the &lt;code&gt;ContentSecurityPolicyMiddleware&lt;/code&gt;, nonces are
supported through the &lt;code&gt;csp()&lt;/code&gt; context
processor, and policies are configured using the &lt;code&gt;SECURE_CSP&lt;/code&gt; and
&lt;code&gt;SECURE_CSP_REPORT_ONLY&lt;/code&gt; settings.&lt;/p&gt;
    &lt;p&gt;These settings accept Python dictionaries and support Django-provided constants for clarity and safety. For example:&lt;/p&gt;
    &lt;code&gt;from django.utils.csp import CSP

SECURE_CSP = {
    "default-src": [CSP.SELF],
    "script-src": [CSP.SELF, CSP.NONCE],
    "img-src": [CSP.SELF, "https:"],
}
&lt;/code&gt;
    &lt;p&gt;The resulting &lt;code&gt;Content-Security-Policy&lt;/code&gt; header would be set to:&lt;/p&gt;
    &lt;code&gt;default-src 'self'; script-src 'self' 'nonce-SECRET'; img-src 'self' https:
&lt;/code&gt;
    &lt;p&gt;To get started, follow the CSP how-to guide. For in-depth guidance, see the CSP security overview and the reference docs, which include details about decorators to override or disable policies on a per-view basis.&lt;/p&gt;
    &lt;head rend="h3"&gt;Template Partials¶&lt;/head&gt;
    &lt;p&gt;The Django Template Language now supports template partials, making it easier to encapsulate and reuse small named fragments within a template file. The new tags &lt;code&gt;{% partialdef %}&lt;/code&gt; and &lt;code&gt;{% partial %}&lt;/code&gt;
define a partial and render it, respectively.&lt;/p&gt;
    &lt;p&gt;Partials can also be referenced using the &lt;code&gt;template_name#partial_name&lt;/code&gt; syntax
with &lt;code&gt;get_template()&lt;/code&gt;,
&lt;code&gt;render()&lt;/code&gt;, &lt;code&gt;{% include %}&lt;/code&gt;, and other
template-loading tools, enabling more modular and maintainable templates
without needing to split components into separate files.&lt;/p&gt;
    &lt;p&gt;A migration guide is available if you’re updating from the django-template-partials third-party package.&lt;/p&gt;
    &lt;head rend="h3"&gt;Background Tasks¶&lt;/head&gt;
    &lt;p&gt;Django now includes a built-in Tasks framework for running code outside the HTTP request–response cycle. This enables offloading work, such as sending emails or processing data, to background workers.&lt;/p&gt;
    &lt;p&gt;The framework provides task definition, validation, queuing, and result handling. Django guarantees consistent behavior for creating and managing tasks, while the responsibility for running them continues to belong to external worker processes.&lt;/p&gt;
    &lt;p&gt;Tasks are defined using the &lt;code&gt;task()&lt;/code&gt; decorator:&lt;/p&gt;
    &lt;code&gt;from django.core.mail import send_mail
from django.tasks import task


@task
def email_users(emails, subject, message):
    return send_mail(subject, message, None, emails)
&lt;/code&gt;
    &lt;p&gt;Once defined, tasks can be enqueued through a configured backend:&lt;/p&gt;
    &lt;code&gt;email_users.enqueue(
    emails=["user@example.com"],
    subject="You have a message",
    message="Hello there!",
)
&lt;/code&gt;
    &lt;p&gt;Backends are configured via the &lt;code&gt;TASKS&lt;/code&gt; setting. The two
built-in backends included in this release are
primarily intended for development and testing.&lt;/p&gt;
    &lt;p&gt;Django handles task creation and queuing, but does not provide a worker mechanism to run tasks. Execution must be managed by external infrastructure, such as a separate process or service.&lt;/p&gt;
    &lt;p&gt;See Django’s Tasks framework for an overview and the Tasks reference for API details.&lt;/p&gt;
    &lt;head rend="h3"&gt;Adoption of Python’s modern email API¶&lt;/head&gt;
    &lt;p&gt;Email handling in Django now uses Python’s modern email API, introduced in Python 3.6. This API, centered around the &lt;code&gt;email.message.EmailMessage&lt;/code&gt; class, offers a cleaner and
Unicode-friendly interface for composing and sending emails. It replaces use of
Python’s older legacy (&lt;code&gt;Compat32&lt;/code&gt;) API, which relied on lower-level MIME
classes (from &lt;code&gt;email.mime&lt;/code&gt;) and required more manual handling of
message structure and encoding.&lt;/p&gt;
    &lt;p&gt;Notably, the return type of the &lt;code&gt;EmailMessage.message()&lt;/code&gt; method is now an instance of Python’s
&lt;code&gt;email.message.EmailMessage&lt;/code&gt;. This supports the same API as the
previous &lt;code&gt;SafeMIMEText&lt;/code&gt; and &lt;code&gt;SafeMIMEMultipart&lt;/code&gt; return types, but is not an
instance of those now-deprecated classes.&lt;/p&gt;
    &lt;head rend="h3"&gt;Minor features¶&lt;/head&gt;
    &lt;head rend="h4"&gt;&lt;code&gt;django.contrib.admin&lt;/code&gt;¶&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The Font Awesome Free icon set (version 6.7.2) is now used for the admin interface icons.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The new&lt;/p&gt;&lt;code&gt;AdminSite.password_change_form&lt;/code&gt;attribute allows customizing the form used in the admin site password change view.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Message levels&lt;/p&gt;&lt;code&gt;messages.DEBUG&lt;/code&gt;and&lt;code&gt;messages.INFO&lt;/code&gt;now have distinct icons and CSS styling. Previously, both levels shared the same appearance as&lt;code&gt;messages.SUCCESS&lt;/code&gt;. Given that&lt;code&gt;ModelAdmin.message_user()&lt;/code&gt;uses&lt;code&gt;messages.INFO&lt;/code&gt;by default, set the level to&lt;code&gt;messages.SUCCESS&lt;/code&gt;to keep the previous icon and styling.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;&lt;code&gt;django.contrib.auth&lt;/code&gt;¶&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The default iteration count for the PBKDF2 password hasher is increased from 1,000,000 to 1,200,000.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;&lt;code&gt;django.contrib.gis&lt;/code&gt;¶&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;The new&lt;/p&gt;&lt;code&gt;GEOSGeometry.hasm&lt;/code&gt;property checks whether the geometry has the M dimension.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The new&lt;/p&gt;&lt;code&gt;Rotate&lt;/code&gt;database function rotates a geometry by a specified angle around the origin or a specified point.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The new&lt;/p&gt;&lt;code&gt;BaseGeometryWidget.base_layer&lt;/code&gt;attribute allows specifying a JavaScript map base layer, enabling customization of map tile providers.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;coveredby&lt;/code&gt;and&lt;code&gt;isvalid&lt;/code&gt;lookups,&lt;code&gt;Collect&lt;/code&gt;aggregation, and&lt;code&gt;GeoHash&lt;/code&gt;and&lt;code&gt;IsValid&lt;/code&gt;database functions are now supported on MariaDB 12.0.1+.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The new&lt;/p&gt;&lt;code&gt;geom_type&lt;/code&gt;lookup and&lt;code&gt;GeometryType()&lt;/code&gt;database function allow filtering geometries by their types.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Widgets from&lt;/p&gt;&lt;code&gt;django.contrib.gis.forms.widgets&lt;/code&gt;now render without inline JavaScript in templates. If you have customized any geometry widgets or their templates, you may need to update them to match the new layout.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;&lt;code&gt;django.contrib.postgres&lt;/code&gt;¶&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;The new&lt;/p&gt;&lt;code&gt;Lexeme&lt;/code&gt;expression for full text search provides fine-grained control over search terms.&lt;code&gt;Lexeme&lt;/code&gt;objects automatically escape their input and support logical combination operators (&lt;code&gt;&amp;amp;&lt;/code&gt;,&lt;code&gt;|&lt;/code&gt;,&lt;code&gt;~&lt;/code&gt;), prefix matching, and term weighting.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Model fields, indexes, and constraints from&lt;/p&gt;&lt;code&gt;django.contrib.postgres&lt;/code&gt;now include system checks to verify that&lt;code&gt;django.contrib.postgres&lt;/code&gt;is an installed app.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;CreateExtension&lt;/code&gt;,&lt;code&gt;BloomExtension&lt;/code&gt;,&lt;code&gt;BtreeGinExtension&lt;/code&gt;,&lt;code&gt;BtreeGistExtension&lt;/code&gt;,&lt;code&gt;CITextExtension&lt;/code&gt;,&lt;code&gt;CryptoExtension&lt;/code&gt;,&lt;code&gt;HStoreExtension&lt;/code&gt;,&lt;code&gt;TrigramExtension&lt;/code&gt;, and&lt;code&gt;UnaccentExtension&lt;/code&gt;operations now support the optional&lt;code&gt;hints&lt;/code&gt;parameter. This allows providing database hints to database routers to assist them in making routing decisions.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;&lt;code&gt;django.contrib.staticfiles&lt;/code&gt;¶&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;ManifestStaticFilesStorage&lt;/code&gt;now ensures consistent path ordering in manifest files, making them more reproducible and reducing unnecessary diffs.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;collectstatic&lt;/code&gt;command now reports only a summary for skipped files (and for deleted files when using&lt;code&gt;--clear&lt;/code&gt;) at&lt;code&gt;--verbosity&lt;/code&gt;1. To see per-file details for either case, set&lt;code&gt;--verbosity&lt;/code&gt;to 2 or higher.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Email¶&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;The new&lt;/p&gt;&lt;code&gt;policy&lt;/code&gt;argument for&lt;code&gt;EmailMessage.message()&lt;/code&gt;allows specifying the email policy, the set of rules for updating and serializing the representation of the message. Defaults to&lt;code&gt;email.policy.default&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;EmailMessage.attach()&lt;/code&gt;now accepts a&lt;code&gt;MIMEPart&lt;/code&gt;object from Python’s modern email API.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Internationalization¶&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Added support and translations for the Haitian Creole language.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Management Commands¶&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;startproject&lt;/code&gt;and&lt;code&gt;startapp&lt;/code&gt;commands now create the custom target directory if it doesn’t exist.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Common utilities, such as&lt;/p&gt;&lt;code&gt;django.conf.settings&lt;/code&gt;, are now automatically imported to the&lt;code&gt;shell&lt;/code&gt;by default.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Migrations¶&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Squashed migrations can now themselves be squashed before being transitioned to normal migrations.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Migrations now support serialization of&lt;/p&gt;&lt;code&gt;zoneinfo.ZoneInfo&lt;/code&gt;instances.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Serialization of deconstructible objects now supports keyword arguments with names that are not valid Python identifiers.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Models¶&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Constraints now implement a&lt;/p&gt;&lt;code&gt;check()&lt;/code&gt;method that is already registered with the check framework.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The new&lt;/p&gt;&lt;code&gt;order_by&lt;/code&gt;argument for&lt;code&gt;Aggregate&lt;/code&gt;allows specifying the ordering of the elements in the result.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The new&lt;/p&gt;&lt;code&gt;Aggregate.allow_order_by&lt;/code&gt;class attribute determines whether the aggregate function allows passing an&lt;code&gt;order_by&lt;/code&gt;keyword argument.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The new&lt;/p&gt;&lt;code&gt;StringAgg&lt;/code&gt;aggregate returns the input values concatenated into a string, separated by the&lt;code&gt;delimiter&lt;/code&gt;string. This aggregate was previously supported only for PostgreSQL.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;save()&lt;/code&gt;method now raises a specialized&lt;code&gt;Model.NotUpdated&lt;/code&gt;exception, when a forced update results in no affected rows, instead of a generic&lt;code&gt;django.db.DatabaseError&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;QuerySet.raw()&lt;/code&gt;now supports models with a&lt;code&gt;CompositePrimaryKey&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Subqueries returning a&lt;/p&gt;&lt;code&gt;CompositePrimaryKey&lt;/code&gt;can now be used as the target of lookups other than&lt;code&gt;__in&lt;/code&gt;, such as&lt;code&gt;__exact&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;JSONField&lt;/code&gt;now supports negative array indexing on SQLite.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The new&lt;/p&gt;&lt;code&gt;AnyValue&lt;/code&gt;aggregate returns an arbitrary value from the non-null input values. This is supported on SQLite, MySQL, Oracle, and PostgreSQL 16+.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GeneratedField&lt;/code&gt;s and fields assigned expressions are now refreshed from the database after&lt;code&gt;save()&lt;/code&gt;on backends that support the&lt;code&gt;RETURNING&lt;/code&gt;clause (SQLite, PostgreSQL, and Oracle). On backends that don’t support it (MySQL and MariaDB), the fields are marked as deferred to trigger a refresh on subsequent accesses.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Using a ForeignObject with multiple&lt;/p&gt;&lt;code&gt;from_fields&lt;/code&gt;in Model indexes, constraints, or&lt;code&gt;unique_together&lt;/code&gt;now emits a system check error.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Pagination¶&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;The new&lt;/p&gt;&lt;code&gt;AsyncPaginator&lt;/code&gt;and&lt;code&gt;AsyncPage&lt;/code&gt;provide async implementations of&lt;code&gt;Paginator&lt;/code&gt;and&lt;code&gt;Page&lt;/code&gt;respectively.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Requests and Responses¶&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Multiple&lt;/p&gt;&lt;code&gt;Cookie&lt;/code&gt;headers are now supported for HTTP/2 requests when running with ASGI.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Templates¶&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;The new variable&lt;/p&gt;&lt;code&gt;forloop.length&lt;/code&gt;is now available within a&lt;code&gt;for&lt;/code&gt;loop.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;querystring&lt;/code&gt;template tag now consistently prefixes the returned query string with a&lt;code&gt;?&lt;/code&gt;, ensuring reliable link generation behavior.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;querystring&lt;/code&gt;template tag now accepts multiple positional arguments, which must be mappings, such as&lt;code&gt;QueryDict&lt;/code&gt;or&lt;code&gt;dict&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Tests¶&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;DiscoverRunner&lt;/code&gt;now supports parallel test execution on systems using the&lt;code&gt;forkserver&lt;/code&gt;&lt;code&gt;multiprocessing&lt;/code&gt;start method.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Backwards incompatible changes in 6.0¶&lt;/head&gt;
    &lt;head rend="h3"&gt;Database backend API¶&lt;/head&gt;
    &lt;p&gt;This section describes changes that may be needed in third-party database backends.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;BaseDatabaseSchemaEditor&lt;/code&gt;and PostgreSQL backends no longer use&lt;code&gt;CASCADE&lt;/code&gt;when dropping a column.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;DatabaseOperations.return_insert_columns()&lt;/code&gt;and&lt;code&gt;DatabaseOperations.fetch_returned_insert_rows()&lt;/code&gt;methods are renamed to&lt;code&gt;returning_columns()&lt;/code&gt;and&lt;code&gt;fetch_returned_rows()&lt;/code&gt;, respectively, to denote they can be used in the context of&lt;code&gt;UPDATE … RETURNING&lt;/code&gt;statements as well as&lt;code&gt;INSERT … RETURNING&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;DatabaseOperations.fetch_returned_insert_columns()&lt;/code&gt;method is removed and the&lt;code&gt;fetch_returned_rows()&lt;/code&gt;method replacing&lt;code&gt;fetch_returned_insert_rows()&lt;/code&gt;expects both a&lt;code&gt;cursor&lt;/code&gt;and&lt;code&gt;returning_params&lt;/code&gt;to be provided, just like&lt;code&gt;fetch_returned_insert_columns()&lt;/code&gt;did.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;If the database supports&lt;/p&gt;&lt;code&gt;UPDATE … RETURNING&lt;/code&gt;statements, backends can set&lt;code&gt;DatabaseFeatures.can_return_rows_from_update=True&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Dropped support for MariaDB 10.5¶&lt;/head&gt;
    &lt;p&gt;Upstream support for MariaDB 10.5 ends in June 2025. Django 6.0 supports MariaDB 10.6 and higher.&lt;/p&gt;
    &lt;head rend="h3"&gt;Dropped support for Python &amp;lt; 3.12¶&lt;/head&gt;
    &lt;p&gt;Because Python 3.12 is now the minimum supported version for Django, any optional dependencies must also meet that requirement. The following versions of each library are the first to add or confirm compatibility with Python 3.12:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;aiosmtpd&lt;/code&gt;1.4.5&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;argon2-cffi&lt;/code&gt;23.1.0&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;bcrypt&lt;/code&gt;4.1.1&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;docutils&lt;/code&gt;0.22&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;geoip2&lt;/code&gt;4.8.0&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Pillow&lt;/code&gt;10.1.0&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;mysqlclient&lt;/code&gt;2.2.1&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;numpy&lt;/code&gt;1.26.0&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;PyYAML&lt;/code&gt;6.0.2&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;psycopg&lt;/code&gt;3.1.12&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;psycopg2&lt;/code&gt;2.9.9&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;redis-py&lt;/code&gt;5.1.0&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;selenium&lt;/code&gt;4.23.0&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;sqlparse&lt;/code&gt;0.5.0&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;tblib&lt;/code&gt;3.0.0&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Email¶&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;The undocumented&lt;/p&gt;&lt;code&gt;mixed_subtype&lt;/code&gt;and&lt;code&gt;alternative_subtype&lt;/code&gt;properties of&lt;code&gt;EmailMessage&lt;/code&gt;and&lt;code&gt;EmailMultiAlternatives&lt;/code&gt;are no longer supported.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The undocumented&lt;/p&gt;&lt;code&gt;encoding&lt;/code&gt;property of&lt;code&gt;EmailMessage&lt;/code&gt;no longer supports Python legacy&lt;code&gt;email.charset.Charset&lt;/code&gt;objects.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;As the internal implementations of&lt;/p&gt;&lt;code&gt;EmailMessage&lt;/code&gt;and&lt;code&gt;EmailMultiAlternatives&lt;/code&gt;have changed significantly, closely examine any custom subclasses that rely on overriding undocumented, internal underscore methods.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;&lt;code&gt;DEFAULT_AUTO_FIELD&lt;/code&gt; setting now defaults to &lt;code&gt;BigAutoField&lt;/code&gt;¶&lt;/head&gt;
    &lt;p&gt;Since Django 3.2, when the &lt;code&gt;DEFAULT_AUTO_FIELD&lt;/code&gt; setting was added,
the default &lt;code&gt;startproject&lt;/code&gt; template’s &lt;code&gt;settings.py&lt;/code&gt; contained:&lt;/p&gt;
    &lt;code&gt;DEFAULT_AUTO_FIELD = "django.db.models.BigAutoField"
&lt;/code&gt;
    &lt;p&gt;and the default &lt;code&gt;startapp&lt;/code&gt; template’s &lt;code&gt;AppConfig&lt;/code&gt; contained:&lt;/p&gt;
    &lt;code&gt;default_auto_field = "django.db.models.BigAutoField"
&lt;/code&gt;
    &lt;p&gt;At that time, the default value of &lt;code&gt;DEFAULT_AUTO_FIELD&lt;/code&gt; remained
&lt;code&gt;django.db.models.AutoField&lt;/code&gt; for backwards compatibility.&lt;/p&gt;
    &lt;p&gt;In Django 6.0, &lt;code&gt;DEFAULT_AUTO_FIELD&lt;/code&gt; now defaults to
&lt;code&gt;django.db.models.BigAutoField&lt;/code&gt; and the aforementioned lines in the
project and app templates are removed.&lt;/p&gt;
    &lt;p&gt;Most projects shouldn’t be affected, since Django 3.2 has raised the system check warning models.W042 for projects that don’t set &lt;code&gt;DEFAULT_AUTO_FIELD&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;If you haven’t dealt with this warning by now, add &lt;code&gt;DEFAULT_AUTO_FIELD = 'django.db.models.AutoField'&lt;/code&gt; to your project’s
settings, or &lt;code&gt;default_auto_field = 'django.db.models.AutoField'&lt;/code&gt; to an app’s
&lt;code&gt;AppConfig&lt;/code&gt;, as needed.&lt;/p&gt;
    &lt;head rend="h3"&gt;Custom ORM expressions should return params as a tuple¶&lt;/head&gt;
    &lt;p&gt;Prior to Django 6.0, custom lookups and custom expressions implementing the &lt;code&gt;as_sql()&lt;/code&gt; method (and its supporting methods &lt;code&gt;process_lhs()&lt;/code&gt; and
&lt;code&gt;process_rhs()&lt;/code&gt;) were allowed to return a sequence of params in either a list
or a tuple. To address the interoperability problems that resulted, the second
return element of the &lt;code&gt;as_sql()&lt;/code&gt; method should now be a tuple:&lt;/p&gt;
    &lt;code&gt;def as_sql(self, compiler, connection) -&amp;gt; tuple[str, tuple]: ...
&lt;/code&gt;
    &lt;p&gt;If your custom expressions support multiple versions of Django, you should adjust any pre-processing of parameters to be resilient against either tuples or lists. For instance, prefer unpacking like this:&lt;/p&gt;
    &lt;code&gt;params = (*lhs_params, *rhs_params)
&lt;/code&gt;
    &lt;head rend="h3"&gt;Miscellaneous¶&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;The JSON serializer now writes a newline at the end of the output, even without the&lt;/p&gt;&lt;code&gt;indent&lt;/code&gt;option set.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The minimum supported version of&lt;/p&gt;&lt;code&gt;asgiref&lt;/code&gt;is increased from 3.8.1 to 3.9.1.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Features deprecated in 6.0¶&lt;/head&gt;
    &lt;head rend="h3"&gt;Positional arguments in &lt;code&gt;django.core.mail&lt;/code&gt; APIs¶&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;django.core.mail&lt;/code&gt; APIs now require keyword arguments for less commonly
used parameters. Using positional arguments for these now emits a deprecation
warning and will raise a &lt;code&gt;TypeError&lt;/code&gt; when the deprecation period ends:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;All optional parameters (&lt;/p&gt;&lt;code&gt;fail_silently&lt;/code&gt;and later) must be passed as keyword arguments to&lt;code&gt;get_connection()&lt;/code&gt;,&lt;code&gt;mail_admins()&lt;/code&gt;,&lt;code&gt;mail_managers()&lt;/code&gt;,&lt;code&gt;send_mail()&lt;/code&gt;, and&lt;code&gt;send_mass_mail()&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;All parameters must be passed as keyword arguments when creating an&lt;/p&gt;&lt;code&gt;EmailMessage&lt;/code&gt;or&lt;code&gt;EmailMultiAlternatives&lt;/code&gt;instance, except for the first four (&lt;code&gt;subject&lt;/code&gt;,&lt;code&gt;body&lt;/code&gt;,&lt;code&gt;from_email&lt;/code&gt;, and&lt;code&gt;to&lt;/code&gt;), which may still be passed either as positional or keyword arguments.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Miscellaneous¶&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;BaseDatabaseCreation.create_test_db(serialize)&lt;/code&gt;is deprecated. Use&lt;code&gt;serialize_db_to_string()&lt;/code&gt;instead.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The PostgreSQL&lt;/p&gt;&lt;code&gt;StringAgg&lt;/code&gt;class is deprecated in favor of the generally available&lt;code&gt;StringAgg&lt;/code&gt;class.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The PostgreSQL&lt;/p&gt;&lt;code&gt;OrderableAggMixin&lt;/code&gt;is deprecated in favor of the&lt;code&gt;order_by&lt;/code&gt;attribute now available on the&lt;code&gt;Aggregate&lt;/code&gt;class.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The default protocol in&lt;/p&gt;&lt;code&gt;urlize&lt;/code&gt;and&lt;code&gt;urlizetrunc&lt;/code&gt;will change from HTTP to HTTPS in Django 7.0. Set the transitional setting&lt;code&gt;URLIZE_ASSUME_HTTPS&lt;/code&gt;to&lt;code&gt;True&lt;/code&gt;to opt into assuming HTTPS during the Django 6.x release cycle.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;URLIZE_ASSUME_HTTPS&lt;/code&gt;transitional setting is deprecated.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Setting&lt;/p&gt;&lt;code&gt;ADMINS&lt;/code&gt;or&lt;code&gt;MANAGERS&lt;/code&gt;to a list of (name, address) tuples is deprecated. Set to a list of email address strings instead. Django never used the name portion. To include a name, format the address string as&lt;code&gt;'"Name" &amp;lt;address&amp;gt;'&lt;/code&gt;or use Python’s&lt;code&gt;email.utils.formataddr()&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Support for the&lt;/p&gt;&lt;code&gt;orphans&lt;/code&gt;argument being larger than or equal to the&lt;code&gt;per_page&lt;/code&gt;argument of&lt;code&gt;django.core.paginator.Paginator&lt;/code&gt;and&lt;code&gt;django.core.paginator.AsyncPaginator&lt;/code&gt;is deprecated.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Using a percent sign in a column alias or annotation is deprecated.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Support for passing Python’s legacy email&lt;/p&gt;&lt;code&gt;MIMEBase&lt;/code&gt;object to&lt;code&gt;EmailMessage.attach()&lt;/code&gt;(or including one in the message’s&lt;code&gt;attachments&lt;/code&gt;list) is deprecated. For complex attachments requiring additional headers or parameters, switch to the modern email API’s&lt;code&gt;MIMEPart&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;django.core.mail.BadHeaderError&lt;/code&gt;exception is deprecated. Python’s modern email raises a&lt;code&gt;ValueError&lt;/code&gt;for email headers containing prohibited characters.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;django.core.mail.SafeMIMEText&lt;/code&gt;and&lt;code&gt;SafeMIMEMultipart&lt;/code&gt;classes are deprecated.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The undocumented&lt;/p&gt;&lt;code&gt;django.core.mail.forbid_multi_line_headers()&lt;/code&gt;and&lt;code&gt;django.core.mail.message.sanitize_address()&lt;/code&gt;functions are deprecated.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Features removed in 6.0¶&lt;/head&gt;
    &lt;p&gt;These features have reached the end of their deprecation cycle and are removed in Django 6.0.&lt;/p&gt;
    &lt;p&gt;See Features deprecated in 5.0 for details on these changes, including how to remove usage of these features.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Support for passing positional arguments to&lt;/p&gt;&lt;code&gt;BaseConstraint&lt;/code&gt;is removed.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;DjangoDivFormRenderer&lt;/code&gt;and&lt;code&gt;Jinja2DivFormRenderer&lt;/code&gt;transitional form renderers are removed.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;BaseDatabaseOperations.field_cast_sql()&lt;/code&gt;is removed.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;request&lt;/code&gt;is required in the signature of&lt;code&gt;ModelAdmin.lookup_allowed()&lt;/code&gt;subclasses.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Support for calling&lt;/p&gt;&lt;code&gt;format_html()&lt;/code&gt;without passing args or kwargs is removed.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The default scheme for&lt;/p&gt;&lt;code&gt;forms.URLField&lt;/code&gt;has changed from&lt;code&gt;"http"&lt;/code&gt;to&lt;code&gt;"https"&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;FORMS_URLFIELD_ASSUME_HTTPS&lt;/code&gt;transitional setting is removed.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;django.db.models.sql.datastructures.Join&lt;/code&gt;no longer falls back to&lt;code&gt;get_joining_columns()&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;get_joining_columns()&lt;/code&gt;method of&lt;code&gt;ForeignObject&lt;/code&gt;and&lt;code&gt;ForeignObjectRel&lt;/code&gt;is removed.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;ForeignObject.get_reverse_joining_columns()&lt;/code&gt;method is removed.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Support for&lt;/p&gt;&lt;code&gt;cx_Oracle&lt;/code&gt;is removed.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;ChoicesMeta&lt;/code&gt;alias to&lt;code&gt;django.db.models.enums.ChoicesType&lt;/code&gt;is removed.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;Prefetch.get_current_queryset()&lt;/code&gt;method is removed.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;get_prefetch_queryset()&lt;/code&gt;method of related managers and descriptors is removed.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;get_prefetcher()&lt;/code&gt;and&lt;code&gt;prefetch_related_objects()&lt;/code&gt;no longer fall back to&lt;code&gt;get_prefetch_queryset()&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See Features deprecated in 5.1 for details on these changes, including how to remove usage of these features.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;django.urls.register_converter()&lt;/code&gt;no longer allows overriding existing converters.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;ModelAdmin.log_deletion()&lt;/code&gt;and&lt;code&gt;LogEntryManager.log_action()&lt;/code&gt;methods are removed.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The undocumented&lt;/p&gt;&lt;code&gt;django.utils.itercompat.is_iterable()&lt;/code&gt;function and the&lt;code&gt;django.utils.itercompat&lt;/code&gt;module are removed.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;django.contrib.gis.geoip2.GeoIP2.coords()&lt;/code&gt;method is removed.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;django.contrib.gis.geoip2.GeoIP2.open()&lt;/code&gt;method is removed.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Support for passing positional arguments to&lt;/p&gt;&lt;code&gt;Model.save()&lt;/code&gt;and&lt;code&gt;Model.asave()&lt;/code&gt;is removed.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The setter for&lt;/p&gt;&lt;code&gt;django.contrib.gis.gdal.OGRGeometry.coord_dim&lt;/code&gt;is removed.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;check&lt;/code&gt;keyword argument of&lt;code&gt;CheckConstraint&lt;/code&gt;is removed.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;get_cache_name()&lt;/code&gt;method of&lt;code&gt;FieldCacheMixin&lt;/code&gt;is removed.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;OS_OPEN_FLAGS&lt;/code&gt;attribute of&lt;code&gt;FileSystemStorage&lt;/code&gt;is removed.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46153116</guid><pubDate>Thu, 04 Dec 2025 21:09:56 +0000</pubDate></item><item><title>Thoughts on Go vs. Rust vs. Zig</title><link>https://sinclairtarget.com/blog/2025/08/thoughts-on-go-vs.-rust-vs.-zig/</link><description>&lt;doc fingerprint="f76818ddbee218fd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Thoughts on Go vs. Rust vs. Zig&lt;/head&gt;
    &lt;head rend="h4"&gt;Aug 09, 2025&lt;/head&gt;
    &lt;p&gt;I realized recently that rather than using “the right tool for the job” I’ve been using the tool at the job and that’s mostly determined the programming languages I know. So over the last couple months I’ve put a lot of time into experimenting with languages I don’t get to use at work. My goal hasn’t been proficiency; I’m more interested in forming an opinion on what each language is good for.&lt;/p&gt;
    &lt;p&gt;Programming languages differ along so many axes that it can be hard to compare them without defaulting to the obviously true but 1) entirely boring and 2) not-that-helpful conclusion that there are trade-offs. Of course there are trade-offs. The important question is, why did this language commit to this particular set of trade-offs?&lt;/p&gt;
    &lt;p&gt;That question is interesting to me because I don’t want to choose a language based on a list of features as if I were buying a humidifier. I care about building software and I care about my tools. In making the trade-offs they make, languages express a set of values. I’d like to find out which values resonate with me.&lt;/p&gt;
    &lt;p&gt;That question is also useful in clarifying the difference between languages that, at the end of the day, have feature sets that significantly overlap. If the number of questions online about “Go vs. Rust” or “Rust vs. Zig” is a reliable metric, people are confused. It’s hard to remember, say, that language X is better for writing web services because it has features a, b, and c whereas language Y only has features a and b. Easier, I think, to remember that language X is better for writing web services because language Y was designed by someone who hates the internet (let’s imagine) and believes we should unplug the whole thing.&lt;/p&gt;
    &lt;p&gt;I’ve collected here my impressions of the three languages I’ve experimented with lately: Go, Rust, and Zig. I’ve tried to synthesize my experience with each language into a sweeping verdict on what that language values and how well it executes on those values. This might be reductive, but, like, crystallizing a set of reductive prejudices is sort of what I’m trying to do here.&lt;/p&gt;
    &lt;head rend="h2"&gt;Go&lt;/head&gt;
    &lt;p&gt;Go is distinguished by its minimalism. It has been described as “a modern C.” Go isn’t like C, because it is garbage-collected and has a real run-time, but it is like C in that you can fit the whole language in your head.&lt;/p&gt;
    &lt;p&gt;You can fit the whole language in your head because Go has so few features. For a long time, Go was notorious for not having generics. That was finally changed in Go 1.18, but that was only after 12 years of people begging for generics to be added to the language. Other features common in modern languages, like tagged unions or syntactic sugar for error-handling, have not been added to Go.&lt;/p&gt;
    &lt;p&gt;It seems the Go development team has a high bar for adding features to the language. The end result is a language that forces you to write a lot of boilerplate code to implement logic that could be more succinctly expressed in another language. But the result is also a language that is stable over time and easy to read.&lt;/p&gt;
    &lt;p&gt;To give you another example of Go’s minimalism, consider Go’s slice type. Both Rust and Zig have a slice type, but these are fat pointers and fat pointers only. In Go, a slice is a fat pointer to a contiguous sequence in memory, but a slice can also grow, meaning that it subsumes the functionality of Rust’s &lt;code&gt;Vec&amp;lt;T&amp;gt;&lt;/code&gt; type and Zig’s &lt;code&gt;ArrayList&lt;/code&gt;. Also, since Go is managing your memory for
you, Go will decide whether your slice’s backing memory lives on the stack or
the heap; in Rust or Zig, you have to think much harder about where your memory
lives.&lt;/p&gt;
    &lt;p&gt;Go’s origin myth, as I understand it, is basically this: Rob Pike was sick of waiting for C++ projects to compile and was sick of other programmers at Google making mistakes in those same C++ projects. Go is therefore simple where C++ is baroque. It is a language for the programming rank and file, designed to be sufficient for 90% of use cases while also being easy to understand, even (perhaps especially) when writing concurrent code.&lt;/p&gt;
    &lt;p&gt;I don’t use Go at work, but I think I should. Go is minimal in service of corporate collaboration. I don’t mean that as a slightâbuilding software in a corporate environment has its own challenges, which Go solves for.&lt;/p&gt;
    &lt;head rend="h2"&gt;Rust&lt;/head&gt;
    &lt;p&gt;Where Go is minimalist, Rust is maximalist. A tagline often associated with Rust is “zero-cost abstractions.” I would amend that to read, “zero-cost abstractions, and lots of them!”&lt;/p&gt;
    &lt;p&gt;Rust has a reputation for being hard to learn. I agree with Jamie Brandon, who writes that it’s not lifetimes that make Rust difficult, it’s the number of concepts stuffed into the language. I’m not the first person to pick on this particular Github comment, but it perfectly illustrates the conceptual density of Rust:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;The type&lt;/p&gt;&lt;code&gt;Pin&amp;lt;&amp;amp;LocalType&amp;gt;&lt;/code&gt;implements&lt;code&gt;Deref&amp;lt;Target = LocalType&amp;gt;&lt;/code&gt;but it doesnât implement&lt;code&gt;DerefMut&lt;/code&gt;. The types&lt;code&gt;Pin&lt;/code&gt;and&lt;code&gt;&amp;amp;&lt;/code&gt;are&lt;code&gt;#[fundamental]&lt;/code&gt;so that an&lt;code&gt;impl DerefMut&lt;/code&gt;for&lt;code&gt;Pin&amp;lt;&amp;amp;LocalType&amp;gt;&amp;gt;&lt;/code&gt;is possible. You can use&lt;code&gt;LocalType == SomeLocalStruct&lt;/code&gt;or&lt;code&gt;LocalType == dyn LocalTrait&lt;/code&gt;and you can coerce&lt;code&gt;Pin&amp;lt;Pin&amp;lt;&amp;amp;SomeLocalStruct&amp;gt;&amp;gt;&lt;/code&gt;into&lt;code&gt;Pin&amp;lt;Pin&amp;lt;&amp;amp;dyn LocalTrait&amp;gt;&amp;gt;&lt;/code&gt;. (Indeed, two layers of Pin!!) This allows creating a pair of âsmart pointers that implement&lt;code&gt;CoerceUnsized&lt;/code&gt;but have strange behaviorâ on stable (&lt;code&gt;Pin&amp;lt;&amp;amp;SomeLocalStruct&amp;gt;&lt;/code&gt;and&lt;code&gt;Pin&amp;lt;&amp;amp;dyn LocalTrait&amp;gt;&lt;/code&gt;become the smart pointers with âstrange behaviorâ and they already implement&lt;code&gt;CoerceUnsized&lt;/code&gt;).&lt;/quote&gt;
    &lt;p&gt;Of course, Rust isn’t trying to be maximalist the same way Go is trying to be minimalist. Rust is a complex language because what it’s trying to do is deliver on two goalsâsafety and performanceâthat are somewhat in tension.&lt;/p&gt;
    &lt;p&gt;The performance goal is self-explanatory. What “safety” means is less clear; at least it was to me, though maybe I’ve just been Python-brained for too long. “Safety” means “memory safety,” the idea that you shouldn’t be able to dereference an invalid pointer, or do a double-free, etc. But it also means more than that. A “safe” program avoids all undefined behavior (sometimes referred to as “UB”).&lt;/p&gt;
    &lt;p&gt;What is the dreaded UB? I think the best way to understand it is to remember that, for any running program, there are FATES WORSE THAN DEATH. If something goes wrong in your program, immediate termination is great actually! Because the alternative, if the error isn’t caught, is that your program crosses over into a twilight zone of unpredictability, where its behavior might be determined by which thread wins the next data race or by what garbage happens to be at a particular memory address. Now you have heisenbugs and security vulnerabilities. Very bad.&lt;/p&gt;
    &lt;p&gt;Rust tries to prevent UB without paying any run-time performance penalty by checking for it at compile-time. The Rust compiler is smart, but it’s not omniscient. For it to be able to check your code, it has to understand what your code will do at run-time. And so Rust has an expressive type system and a menagerie of traits that allow you to express, to the compiler, what in another language would just be the apparent run-time behavior of your code.&lt;/p&gt;
    &lt;p&gt;This makes Rust hard, because you can’t just do the thing! You have to find out Rust’s name for the thingâfind the trait or whatever you needâthen implement it as Rust expects you to. But if you do this, Rust can make guarantees about the behavior of your code that other languages cannot, which depending on your application might be crucial. It can also make guarantees about other people’s code, which makes consuming libraries easy in Rust and explains why Rust projects have almost as many dependencies as projects in the JavaScript ecosystem.&lt;/p&gt;
    &lt;head rend="h2"&gt;Zig&lt;/head&gt;
    &lt;p&gt;Of the three languages, Zig is the newest and least mature. As of this writing, Zig is only on version 0.14. Its standard library has almost zero documentation and the best way to learn how to use it is to consult the source code directly.&lt;/p&gt;
    &lt;p&gt;Although I don’t know if this is true, I like to think of Zig as a reaction to both Go and Rust. Go is simple because it obscures details about how the computer actually works. Rust is safe because it forces you to jump through its many hoops. Zig will set you free! In Zig, you control the universe and nobody can tell you what to do.&lt;/p&gt;
    &lt;p&gt;In both Go and Rust, allocating an object on the heap is as easy as returning a pointer to a struct from a function. The allocation is implicit. In Zig, you allocate every byte yourself, explicitly. (Zig has manual memory management.) You have more control here than you have even in C: To allocate bytes, you have to call &lt;code&gt;alloc()&lt;/code&gt; on a specific kind of allocator, meaning you have to decide
on the best allocator implementation for your use case.&lt;/p&gt;
    &lt;p&gt;In Rust, creating a mutable global variable is so hard that there are long forum discussions on how to do it. In Zig, you can just create one, no problem.&lt;/p&gt;
    &lt;p&gt;Undefined behavior is still important in Zig. Zig calls it “illegal behavior.” It tries to detect it at run-time and crash the program when it occurs. For those who might worry about the performance cost of these checks, Zig offers four different “release modes” that you can choose from when you build your program. In some of these, the checks are disabled. The idea seems to be that you can run your program enough times in the checked release modes to have reasonable confidence that there will be no illegal behavior in the unchecked build of your program. That seems like a highly pragmatic design to me.&lt;/p&gt;
    &lt;p&gt;Another difference between Zig and the other two languages is Zig’s relationship to object-oriented programming. OOP has been out of favor for a while now and both Go and Rust eschew class inheritance. But Go and Rust have enough support for other object-oriented programming idioms that you could still construct your program as a graph of interacting objects if you wanted to. Zig has methods, but no private struct fields and no language feature implementing run-time polymorphism (AKA dynamic dispatch), even though &lt;code&gt;std.mem.Allocator&lt;/code&gt; is dying to be an interface. As best as I can tell, these
exclusions are intentional; Zig is a language for data-oriented
design.&lt;/p&gt;
    &lt;p&gt;One more thing I want to say about this, because I found it eye-opening: It might seem crazy to be building a programming language with manual memory management in 2025, especially when Rust has shown that you don’t even need garbage collection and can let the compiler do it for you. But this is a design choice very much related to the choice to exclude OOP features. In Go and Rust and so many other languages, you tend to allocate little bits of memory at a time for each object in your object graph. Your program has thousands of little hidden &lt;code&gt;malloc()&lt;/code&gt;s and &lt;code&gt;free()&lt;/code&gt;s, and therefore thousands of different
lifetimes. This is RAII. In Zig,
it might seem like manual memory management would require lots of tedious,
error-prone bookkeeping, but that’s only if you insist on tying memory
allocations to all your little objects. You could instead just allocate and
free big chunks of memory at certain sensible points in your program (like at
the start of each iteration of your event loop), and use that memory to hold
the data you need to operate on. It’s this approach that Zig encourages.&lt;/p&gt;
    &lt;p&gt;Many people seem confused about why Zig should exist if Rust does already. It’s not just that Zig is trying to be simpler. I think this difference is the more important one. Zig wants you to excise even more object-oriented thinking from your code.&lt;/p&gt;
    &lt;p&gt;Zig has a fun, subversive feel to it. It’s a language for smashing the corporate class hierarchy (of objects). It’s a language for megalomaniacs and anarchists. I like it. I hope it gets to a stable release soon, though the Zig team’s current priority seems to be rewriting all of their dependencies. It’s not impossible they try to rewrite the Linux kernel before we see Zig 1.0.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46153466</guid><pubDate>Thu, 04 Dec 2025 21:40:24 +0000</pubDate></item></channel></rss>