<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 21 Jan 2026 18:29:07 +0000</lastBuildDate><item><title>I Made Zig Compute 33M Satellite Positions in 3 Seconds. No GPU Required</title><link>https://atempleton.bearblog.dev/i-made-zig-compute-33-million-satellite-positions-in-3-seconds-no-gpu-required/</link><description>&lt;doc fingerprint="ef1e7cfce90c1280"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;I Made Zig Compute 33 Million Satellite Positions in 3 Seconds. No GPU Required.&lt;/head&gt;
    &lt;p&gt;I've spent the past month optimizing SGP4 propagation and ended up with something interesting: astroz is now the fastest general purpose SGP4 implementation I'm aware of, hitting 11-13M propagations per second in native Zig and ~7M/s through Python with just &lt;code&gt;pip install astroz&lt;/code&gt;. This post breaks down how I got there.&lt;/p&gt;
    &lt;p&gt;A note on "general purpose": heyoka.py can be faster for batch-processing many satellites simultaneously (16M/s vs 7.5M/s). But it's a general ODE integrator with SGP4 as a module, requiring LLVM for JIT compilation and a C++ dependency stack that conda-forge recommends over pip. For time batched propagation, many time points for one satellite, astroz is 2x faster (8.5M/s vs 3.8M/s). Full comparison below. I'm also skipping GPU accelerated SGP4 implementations. They can be faster for massive batch workloads, but require CUDA/OpenCL setup and aren't what I'd consider "general purpose."&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Bother Optimizing SGP4?&lt;/head&gt;
    &lt;p&gt;SGP4 is the standard algorithm for predicting satellite positions from TLE data. It's been around since the 80s and most implementations are straightforward ports of the original reference code. They work fine. You can read the implementation that I followed from SpaceTrack Report No. 3.&lt;/p&gt;
    &lt;p&gt;But "fine" starts to feel slow when you need dense time resolution. Generating a month of ephemeris data at one-second intervals is 2.6 million propagations per satellite. Pass prediction over a ground station network might need sub-second precision across weeks. Trajectory analysis for conjunction screening wants fine-grained time steps to catch close approaches. At 2-3M propagations per second (typical for a good implementation), these workloads take seconds per satellite—that adds up fast when you're doing iterative analysis or building interactive tools.&lt;/p&gt;
    &lt;p&gt;I wanted to see how fast I could make it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Starting Point: Already Faster Than Expected&lt;/head&gt;
    &lt;p&gt;Before I even started thinking about SIMD, the scalar implementation was already matching or beating the Rust sgp4 crate, the fastest open-source implementation I could find (general purpose). I hadn't done anything clever yet; the speed came from design choices that happened to play well with how Zig compiles.&lt;/p&gt;
    &lt;p&gt;Two things mattered most:&lt;/p&gt;
    &lt;p&gt;Branchless hot paths. The SGP4 algorithm has a lot of conditionals. Deep space vs near earth, different perturbation models, and convergence checks in the Kepler solver. I wrote these as branchless expressions where possible, not for performance reasons initially, but because it made the code easier to reason about. It happened to be a happy accident that modern CPUs love predictable instruction streams.&lt;/p&gt;
    &lt;p&gt;Comptime precomputation. Zig's &lt;code&gt;comptime&lt;/code&gt; lets you run arbitrary code at compile time. A lot of SGP4's setup work, ie. gravity constants, polynomial coefficients, derived parameters can be computed once and baked into the binary. No runtime initialization, and no repeated calculations. I didn't have to do anything special. Zig is smart enough where if you mark a variable as &lt;code&gt;const&lt;/code&gt; it treats it as comptime automatically.&lt;/p&gt;
    &lt;code&gt;const j2: comptime_float = 1.082616e-3; // explicit comptime (not needed)
const j2 = 1.082616e-3; // implied comptime because of `const` (what I used)
&lt;/code&gt;
    &lt;p&gt;The result was a scalar implementation running at ~5.2M propagations per second, which was already slightly faster than Rust's ~5.0M, but within a margin of error. But I started to see some room to go faster. SGP4, by design, doesn't rely on state to calculate positions: each satellite and each time point is independent. This algorithm feels tailor made for something I have always been too afraid to try: SIMD.&lt;/p&gt;
    &lt;head rend="h2"&gt;Discovering Zig's SIMD Superpowers&lt;/head&gt;
    &lt;p&gt;I have heard the nightmares about implementing SIMD. Most of the time its never worth it, it adds too much complexity, you have to build for different platforms, and the syntax itself is weird to write and think about.&lt;/p&gt;
    &lt;p&gt;I was pleasantly surprised to learn that Zig, whether on purpose or not, makes SIMD a first class citizen. This is all enabled by a powerful and sane standard library that has builtins that handle the weird stuff for me. Now I just had to tackle the thought process for the basic flow of things in SIMD.&lt;/p&gt;
    &lt;p&gt;I started with this foundation; a simple type declaration:&lt;/p&gt;
    &lt;code&gt;const Vec4 = @Vector(4, f64);
&lt;/code&gt;
    &lt;p&gt;That's all you need to start. I now have a 4-wide vector of 64-bit floats. No intrinsics, no platform detection, no conditional compilation. The LLVM backend handles targeting the right instruction set for wherever the code runs.&lt;/p&gt;
    &lt;p&gt;The builtin operations for vector operations are equally simple:&lt;/p&gt;
    &lt;code&gt;// Broadcast a scalar to all lanes
const twoPiVec: Vec4 = @splat(constants.twoPi);

// Auto-vectorized transcendentals through LLVM
pub fn sinSIMD(x: Vec4) Vec4 {
    return @sin(x);
}

pub fn cosSIMD(x: Vec4) Vec4 {
    return @cos(x);
}
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;@sin&lt;/code&gt; and &lt;code&gt;@cos&lt;/code&gt; builtins map directly to LLVM intrinsics, which use platform optimal implementations like libmvec on Linux x86_64. No manual work required.&lt;/p&gt;
    &lt;head rend="h2"&gt;Learning to Think in Lanes&lt;/head&gt;
    &lt;p&gt;The arithmetic was easy. What took me a while to internalize was branching.&lt;/p&gt;
    &lt;p&gt;In scalar code, you write &lt;code&gt;if&lt;/code&gt; statements and the CPU takes one path or the other. In SIMD, all four lanes execute together. If lane 0 needs the "true" branch and lane 2 needs the "false" branch, you can't just branch, you have to compute both outcomes and then pick per lane.&lt;/p&gt;
    &lt;p&gt;Here's a concrete example. The scalar SGP4 code has a check like this:&lt;/p&gt;
    &lt;code&gt;// Scalar version
if (eccentricity &amp;lt; 1.0e-4) {
    result = simple_calculation(x);
} else {
    result = complex_calculation(x);
}
&lt;/code&gt;
    &lt;p&gt;In SIMD, this becomes:&lt;/p&gt;
    &lt;code&gt;// SIMD version - compute both, select per-lane
const simple_result = simple_calculation(x);
const complex_result = complex_calculation(x);
const mask = eccentricity &amp;lt; @as(Vec4, @splat(1.0e-4));
const result = @select(f64, mask, simple_result, complex_result);
&lt;/code&gt;
    &lt;p&gt;This felt wasteful at first. Why compute both paths? But modern CPUs are so fast at arithmetic that computing both and selecting is often faster than branch misprediction. Plus, for SGP4, most satellites take the same path anyway, so we're rarely doing truly "wasted" work.&lt;/p&gt;
    &lt;p&gt;The trickier case was convergence loops. SGP4's Kepler solver iterates until each result converges. In scalar code:&lt;/p&gt;
    &lt;code&gt;// Scalar Kepler solver
while (@abs(delta) &amp;gt; tolerance) {
    // iterate...
}
&lt;/code&gt;
    &lt;p&gt;But in SIMD, different lanes converge at different rates. Lane 0 might converge in 3 iterations while lane 3 needs 5. You can't exit early for just one lane. The solution is to track convergence per lane with a mask and use &lt;code&gt;@reduce&lt;/code&gt; to check if everyone's done:&lt;/p&gt;
    &lt;code&gt;// SIMD Kepler solver
var converged: @Vector(4, bool) = @splat(false);
while (!@reduce(.And, converged)) {
    // iterate...
    converged = @abs(delta) &amp;lt;= tolerance_vec;
}
&lt;/code&gt;
    &lt;p&gt;Once I understood this pattern, compute everything, mask the results, reduce to check completion, the rest of the conversion was methodical. I went through the scalar implementation line by line, keeping the original untouched so my test suite could compare outputs.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Three Propagation Modes&lt;/head&gt;
    &lt;p&gt;With the core SIMD patterns figured out, I built three different propagation strategies for different use cases.&lt;/p&gt;
    &lt;head rend="h3"&gt;1. Time Batched: &lt;code&gt;propagateV4&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;The first question I asked: what's the most common workload? For me, it was generating ephemeris data, and propagating a single satellite across many time points. Pass prediction, trajectory analysis, conjunction screening: they all want dense time series for one object.&lt;/p&gt;
    &lt;p&gt;Time batched propagation processes 4 time points for one satellite simultaneously:&lt;/p&gt;
    &lt;code&gt;pub fn propagateV4(self: *const Sgp4, times: [4]f64) Error![4][2][3]f64 {
    const el = &amp;amp;self.elements;
    const timeV4 = Vec4{ times[0], times[1], times[2], times[3] };

    const secular = updateSecularV4(el, timeV4);
    const nm: Vec4 = @as(Vec4, @splat(el.grav.xke)) / simdMath.pow15V4(secular.a);
    const kepler = solveKeplerV4(el, secular);
    const corrected = applyShortPeriodCorrectionsV4(el, kepler, nm);
    return computePositionVelocityV4(el, corrected);
}
&lt;/code&gt;
    &lt;p&gt;Usage is straightforward:&lt;/p&gt;
    &lt;code&gt;const sat = try Sgp4.init(tle);
const times = [4]f64{ 0.0, 1.0, 2.0, 3.0 }; // minutes since epoch
const results = try sat.propagateV4(times);
// results[0] = position/velocity at t=0, results[1] at t=1, etc.
&lt;/code&gt;
    &lt;p&gt;This mode gave me the biggest initial speedup because it's the most cache friendly: the satellite's orbital elements stay in registers while we compute four outputs.&lt;/p&gt;
    &lt;head rend="h3"&gt;2. Satellite Batched: &lt;code&gt;propagateSatellitesV4&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;The opposite workload: what if you have many satellites and need their positions at one specific time? Collision screening snapshots, catalog-wide visibility checks, that sort of thing.&lt;/p&gt;
    &lt;p&gt;Satellite batched propagation processes 4 different satellites at the same time point:&lt;/p&gt;
    &lt;code&gt;pub inline fn propagateSatellitesV4(el: *const ElementsV4, tsince: f64) Error![4][2][3]f64 {
    const tsinceVec: Vec4 = @splat(tsince);
    const secular = updateSecularSatV4(el, tsinceVec);
    const nm: Vec4 = el.xke / simdMath.pow15V4(secular.a);
    const kepler = solveKeplerSatV4(el, secular);
    const corrected = applyShortPeriodCorrectionsSatV4(el, kepler, nm);
    return computePositionVelocitySatV4(el, corrected);
}
&lt;/code&gt;
    &lt;p&gt;This required a different data layout. Instead of one satellite with 4 time points, I needed 4 satellites packed together. That's where &lt;code&gt;ElementsV4&lt;/code&gt; comes in. Its a struct where each field is a &lt;code&gt;Vec4&lt;/code&gt; holding values for 4 different satellites. More on that layout later.&lt;/p&gt;
    &lt;head rend="h3"&gt;3. Constellation Mode: &lt;code&gt;propagateConstellationV4&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;The third workload combines both: propagate many satellites across many time points. This is what the live demo does: 13,000 satellites across 1,440 time points.&lt;/p&gt;
    &lt;p&gt;The naive approach would be: for each satellite, compute all time points. But that thrashes the cache. By the time you finish satellite 1's 1,440 points and move to satellite 2, all the time related data has been evicted.&lt;/p&gt;
    &lt;p&gt;Constellation mode uses cache conscious tiling:&lt;/p&gt;
    &lt;code&gt;// Time tile size tuned for L1 cache (~32KB)
const TILE_SIZE: usize = 64;

// Process in tiles over time to keep data in L1/L2 cache
var timeStart: usize = 0;
while (timeStart &amp;lt; numTimes) {
    const timeEnd = @min(timeStart + TILE_SIZE, numTimes);

    for (batches, 0..) |*batch, batchIdx| {
        for (timeStart..timeEnd) |timeIdx| {
            const satResults = try propagateSatellitesV4(batch, times[timeIdx]);
            // Store results...
        }
    }
    timeStart = timeEnd;
}
&lt;/code&gt;
    &lt;p&gt;The idea here is to process 64 time points for all satellites, then the next 64, and so on. The time values stay hot in L1 cache while we sweep through the satellite batches. The tile size (64) isn't magic, it's roughly &lt;code&gt;L1_size / sizeof(working_data)&lt;/code&gt; rounded to a SIMD-friendly number.&lt;/p&gt;
    &lt;p&gt;In practice, constellation mode is about 15-20% faster than calling satellite batched propagation in a naive loop for large catalogs.&lt;/p&gt;
    &lt;head rend="h2"&gt;The atan2 Problem (and Solution)&lt;/head&gt;
    &lt;p&gt;Here's where things got interesting. SGP4's Kepler solver needs &lt;code&gt;atan2&lt;/code&gt;, but LLVM doesn't provide a vectorized builtin for it. Calling the scalar function would break the SIMD implementation.&lt;/p&gt;
    &lt;p&gt;The solution I picked: a polynomial approximation. The key insight is that for SGP4's accuracy requirements (which are inherently limited by the model), we don't need perfect precision.&lt;/p&gt;
    &lt;code&gt;pub fn atan2SIMD(y: Vec4, x: Vec4) Vec4 {
    const abs_x = @abs(x);
    const abs_y = @abs(y);

    // Keep argument in [0, 1] for better polynomial accuracy
    const max_xy = @max(abs_x, abs_y);
    const min_xy = @min(abs_x, abs_y);
    const t = min_xy / @max(max_xy, @as(Vec4, @splat(1.0e-30)));
    const t2 = t * t;

    const c1: Vec4 = @splat(1.0);
    const c3: Vec4 = @splat(-0.3333314528);
    const c5: Vec4 = @splat(0.1999355085);
    // ... more coefficients

    var atan_t = c17;
    atan_t = atan_t * t2 + c15;
    atan_t = atan_t * t2 + c13;
    // ... Horner's method continues
    atan_t = atan_t * t;

    // Quadrant correction using branchless selects
    const swap_mask = abs_y &amp;gt; abs_x;
    atan_t = @select(f64, swap_mask, halfPiVec - atan_t, atan_t);

    // ... more quadrant handling with @select
    return result;
}
&lt;/code&gt;
    &lt;p&gt;This polynomial approximation is accurate to ~1e-7 radians, which translates to about 10mm position error at LEO distances. That's well within SGP4's inherent accuracy limits. The algorithm itself has kilometers of uncertainty over multi-day propagations built into it.&lt;/p&gt;
    &lt;p&gt;To be honest, this math was tricky for me to wrap my head around. I had to ask AI to help me here because I was really struggling with it.&lt;/p&gt;
    &lt;head rend="h2"&gt;"Struct of Arrays" for Multi Satellite Processing&lt;/head&gt;
    &lt;p&gt;For processing multiple satellites, I use a "struct of arrays" layout:&lt;/p&gt;
    &lt;code&gt;pub const ElementsV4 = struct {
    grav: constants.Sgp4GravityModel,

    // Each field is a Vec4 holding values for 4 satellites
    ecco: Vec4,
    inclo: Vec4,
    nodeo: Vec4,
    argpo: Vec4,
    mo: Vec4,
    // ...

    // Pre-splatted constants (computed once at init)
    xke: Vec4,
    j2: Vec4,
    one: Vec4,
    half: Vec4,
    // ...
};
&lt;/code&gt;
    &lt;p&gt;"Pre-splatting" constants eliminates repeated &lt;code&gt;@splat&lt;/code&gt; calls in the hot path. It's a small optimization, but in code running millions of times per second, everything counts, and its an easy win.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Benchmark Results&lt;/head&gt;
    &lt;head rend="h3"&gt;Native Implementation Comparison (Zig vs Rust)&lt;/head&gt;
    &lt;p&gt;First, let's compare apples to apples. Native compiled implementations:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Scenario&lt;/cell&gt;
        &lt;cell role="head"&gt;astroz (Zig)&lt;/cell&gt;
        &lt;cell role="head"&gt;Rust sgp4&lt;/cell&gt;
        &lt;cell role="head"&gt;Speedup&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;1 day (minute)&lt;/cell&gt;
        &lt;cell&gt;0.27 ms&lt;/cell&gt;
        &lt;cell&gt;0.31 ms&lt;/cell&gt;
        &lt;cell&gt;1.16x&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;1 week (minute)&lt;/cell&gt;
        &lt;cell&gt;1.99 ms&lt;/cell&gt;
        &lt;cell&gt;2.04 ms&lt;/cell&gt;
        &lt;cell&gt;1.03x&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;2 weeks (minute)&lt;/cell&gt;
        &lt;cell&gt;3.87 ms&lt;/cell&gt;
        &lt;cell&gt;4.03 ms&lt;/cell&gt;
        &lt;cell&gt;1.04x&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;2 weeks (second)&lt;/cell&gt;
        &lt;cell&gt;222 ms&lt;/cell&gt;
        &lt;cell&gt;234 ms&lt;/cell&gt;
        &lt;cell&gt;1.05x&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;1 month (minute)&lt;/cell&gt;
        &lt;cell&gt;8.37 ms&lt;/cell&gt;
        &lt;cell&gt;8.94 ms&lt;/cell&gt;
        &lt;cell&gt;1.07x&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Both implementations achieve around 5M propagations/sec for scalar (single-satellite) processing. The Zig implementation edges out Rust slightly. This is most likely hot path optimizations and &lt;code&gt;comptime&lt;/code&gt; being quite aggressive with its pre compute.&lt;/p&gt;
    &lt;head rend="h3"&gt;Native SIMD Throughput Comparison&lt;/head&gt;
    &lt;p&gt;The real gains come from SIMD. When processing multiple satellites or time points in parallel using &lt;code&gt;@Vector(4, f64)&lt;/code&gt;, throughput jumps to 11-13M propagations/sec, more than 2x faster than scalar implementations.&lt;/p&gt;
    &lt;head rend="h3"&gt;Python Bindings Performance&lt;/head&gt;
    &lt;p&gt;For Python users, here's how astroz compares to python-sgp4:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Scenario&lt;/cell&gt;
        &lt;cell role="head"&gt;astroz&lt;/cell&gt;
        &lt;cell role="head"&gt;python-sgp4&lt;/cell&gt;
        &lt;cell role="head"&gt;Speedup&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;2 weeks (second)&lt;/cell&gt;
        &lt;cell&gt;160 ms&lt;/cell&gt;
        &lt;cell&gt;464 ms&lt;/cell&gt;
        &lt;cell&gt;2.9x&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;1 month (minute)&lt;/cell&gt;
        &lt;cell&gt;5.9 ms&lt;/cell&gt;
        &lt;cell&gt;16.1 ms&lt;/cell&gt;
        &lt;cell&gt;2.7x&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Python Bindings Throughput&lt;/head&gt;
    &lt;head rend="h3"&gt;A Note on heyoka.py&lt;/head&gt;
    &lt;p&gt;As mentioned in the intro, heyoka.py deserves attention. Here are the single-threaded benchmarks:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Test&lt;/cell&gt;
        &lt;cell role="head"&gt;heyoka.py&lt;/cell&gt;
        &lt;cell role="head"&gt;astroz&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;8 sats × 1440 times&lt;/cell&gt;
        &lt;cell&gt;16.2M/s&lt;/cell&gt;
        &lt;cell&gt;7.5M/s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;1 sat × 1440 times&lt;/cell&gt;
        &lt;cell&gt;3.8M/s&lt;/cell&gt;
        &lt;cell&gt;8.5M/s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;100 sats × 100 times&lt;/cell&gt;
        &lt;cell&gt;15.5M/s&lt;/cell&gt;
        &lt;cell&gt;8.4M/s&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;heyoka.py wins on multi satellite batches; astroz wins on time batched workloads. Which one you pick depends on your use case:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;How many satellites at once? If you're propagating hundreds of satellites at the same time point (collision screening snapshots), heyoka.py wins this easily.&lt;/item&gt;
      &lt;item&gt;How many time points per satellite? If you're generating ephemerides, predicting passes, or doing trajectory analysis for individual satellites across many time steps, astroz is 2x faster.&lt;/item&gt;
      &lt;item&gt;Do you need easy deployment? astroz is &lt;code&gt;pip install astroz&lt;/code&gt;with just NumPy. heyoka.py requires LLVM and a C++ stack that conda-forge recommends over pip.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Seeing It at Scale&lt;/head&gt;
    &lt;p&gt;Speed numbers are abstract until you see what they enable. When propagation is this fast, you stop thinking about batching and scheduling, you just compute what you need, when you need it.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Live Demo&lt;/head&gt;
    &lt;p&gt;To show what this looks like, I built an interactive Cesium visualization that propagates the entire active catalog from CelesTrak (~13,000 satellites) across 1440 time points (a full day at minute resolution). That's ~19 million propagations completing in about 2.7 seconds. Add ~0.6 seconds for TEME→ECEF coordinate conversion, and you get a full day of orbital data for every tracked satellite in about 3.3 seconds. (This demo runs through Python bindings at ~7M/sec; native Zig hits 11-13M/sec.)&lt;/p&gt;
    &lt;head rend="h2"&gt;Looking Forward&lt;/head&gt;
    &lt;p&gt;Next up: SDP4 for deep space objects (the current implementation only handles near-earth satellites with periods under 225 minutes), and multithreading to scale across cores. The SIMD work here was single threaded, there's another multiplier waiting.&lt;/p&gt;
    &lt;head rend="h2"&gt;Try It Yourself&lt;/head&gt;
    &lt;p&gt;astroz is available on PyPI:&lt;/p&gt;
    &lt;code&gt;pip install astroz
&lt;/code&gt;
    &lt;p&gt;Or add it to your Zig project:&lt;/p&gt;
    &lt;code&gt;zig fetch --save git+https://github.com/ATTron/astroz/#HEAD
&lt;/code&gt;
    &lt;p&gt;The code is open source on GitHub. Stars, issues, and contributions welcome.&lt;/p&gt;
    &lt;p&gt;Browse the examples to integrate astroz into your own projects, or try the live demo to see it in action.&lt;/p&gt;
    &lt;p&gt;Who Am I?&lt;/p&gt;
    &lt;p&gt;Anthony Templeton is a software engineer passionate about high-performance computing and aerospace applications. You can connect with me on LinkedIn or check out more of my work on GitHub.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46703317</guid><pubDate>Wed, 21 Jan 2026 09:51:27 +0000</pubDate></item><item><title>EU–INC – A new pan-European legal entity</title><link>https://www.eu-inc.org/</link><description>&lt;doc fingerprint="a1be153739b2f6ef"&gt;
  &lt;main&gt;
    &lt;p&gt;WHAT IS EUâINC&lt;/p&gt;
    &lt;head rend="h2"&gt;EUâINC â A true pan-European solution&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;One new pan-European legal entity&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;One central EU-level registry&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Standardized investment documents&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Standardized EU-wide stock options&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Local taxes &amp;amp; employment&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;For every founder&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We are already working with Brussels. This can become reality. But we need your help!&lt;/p&gt;
    &lt;p&gt;Read the in-detail proposal, made in collaboration with the best startup legal teams, funds and founders in Europe.&lt;/p&gt;
    &lt;p&gt;Welcome to improving europe&lt;/p&gt;
    &lt;p&gt;Why the EUâINC?&lt;/p&gt;
    &lt;p&gt;Europe has the talent, ambition, and ecosystems to create innovative companies, but fragmentation between European nations is holding us back.&lt;/p&gt;
    &lt;p&gt;"A startup from California can expand and raise money all across the United States. But our companies still face way too many national barriers that make it hard to work Europa-wide, and way too much regulatory burden."&lt;/p&gt;
    &lt;p&gt;Political Will&lt;/p&gt;
    &lt;p&gt;Will this actually happen?&lt;/p&gt;
    &lt;p&gt;Yes! But we need your help!&lt;/p&gt;
    &lt;p&gt;So far, we submitted our proposal to Justice Commissioner McGrath and Startup Commissioner Zaharieva.&lt;/p&gt;
    &lt;p&gt;President Von der Leyen has setup a dedicated working group in the Commission with whom we are in regular contact.&lt;/p&gt;
    &lt;p&gt;Additionally, the European Council and Parliament have each signaled interest in the EUâINC, or what in Brussel is called the "28th regime" (for 28th virtual state).&lt;/p&gt;
    &lt;p&gt;ROADMAP&lt;/p&gt;
    &lt;p&gt;What comes next?&lt;/p&gt;
    &lt;p&gt;The entire community is currently influencing the upcoming European Commission legislative proposal for a pan-European legal entity which is set to be released in Q1 2026. We need your help, see below!&lt;/p&gt;
    &lt;p&gt;Afterwards, the European Parliament and the European Council (made up of the 27 national governments) agree on the legislative details. The final implementation of the EUâINC would then happen in 2027.&lt;/p&gt;
    &lt;p&gt;For more details of what happened so far and what comes next, read our roadmap.&lt;/p&gt;
    &lt;p&gt;Join US&lt;/p&gt;
    &lt;p&gt;How you can help: talk to national politicians and press&lt;/p&gt;
    &lt;p&gt;In Europe, laws are still decided on national level, meaning we need to convince all 27 EU member state governments to back the EUâINC.&lt;/p&gt;
    &lt;p&gt;Thus we need YOU to activate your contacts, talk to your national politicians about the urgency of the EUâINC, talk to the press about how crucial the EUâINC is for European startups.&lt;/p&gt;
    &lt;p&gt;National governments need to understand the necessity of EUâINC for the future of Europe. Read more in FAQ.&lt;/p&gt;
    &lt;p&gt;Press&lt;/p&gt;
    &lt;p&gt;Spreading the word&lt;/p&gt;
    &lt;p&gt;You help us immensely if you share this page with your peers, follow &amp;amp; repost us on X &amp;amp; Linkedin and write about the EUâINC â see the FAQ for more infos.&lt;/p&gt;
    &lt;p&gt;You help us immensely if you share this page with your peers, follow &amp;amp; repost us on X &amp;amp; Linkedin and write about the EU-INC â see the FAQ for more infos.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46703763</guid><pubDate>Wed, 21 Jan 2026 10:49:20 +0000</pubDate></item><item><title>Hightouch (YC S19) Is Hiring</title><link>https://hightouch.com/careers</link><description>&lt;doc fingerprint="1afc511d6c36362c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;We are a small team of kind and talented people&lt;/head&gt;
    &lt;head rend="h2"&gt;Let’s grow together&lt;/head&gt;
    &lt;p&gt;At Hightouch, we’re committed to helping our customers, business, and employees grow. As a series C startup backed by top investors, we are determined to continuously raise the bar and provide the best product in the market. Grow your career in a fast paced environment that values creative thinking and innovation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Our values&lt;/head&gt;
    &lt;head rend="h3"&gt;Forever hungry&lt;/head&gt;
    &lt;p&gt;We are hungry and ambitious. We celebrate our accomplishments, but we’re never fully satisfied. We’re always figuring out how to collectively push ourselves further and do more.If we think we can grow the company 5x this year, the first question should be “why not 10x?”&lt;/p&gt;
    &lt;head rend="h3"&gt;Kindness&lt;/head&gt;
    &lt;p&gt;We want to create an environment where people feel actively welcomed, encouraged, and supported. People who aren’t kind aren’t tolerated — it’s just not worth it.We intrinsically believe in a deeper kindness as a core value, aside from its obvious benefits to the business&lt;/p&gt;
    &lt;head rend="h3"&gt;Efficient execution&lt;/head&gt;
    &lt;p&gt;Speed matters. We don’t have time for endless deliberation — most decisions are two-way doors. Move fast, adapt quickly.We take inspiration from others and don’t innovate where we don’t need to. We communicate clearly because time is precious. We parallelize to the greatest extent possible.&lt;/p&gt;
    &lt;head rend="h3"&gt;Compassion&lt;/head&gt;
    &lt;p&gt;We listen to everyone and try to put ourselves in their shoes, regardless of our initial reaction to what they say.This applies to everyone — customers, prospects, partners, peers, etc.&lt;/p&gt;
    &lt;head rend="h3"&gt;Impact driven&lt;/head&gt;
    &lt;p&gt;Everyone should be intrinsically motivated by business impact. We minimize distractions and prioritize our time based on what’s actually impactful to the business.We value people at all levels based on their impact above anything else.&lt;/p&gt;
    &lt;head rend="h3"&gt;Raising the bar&lt;/head&gt;
    &lt;p&gt;We have high expectations for performance and believe in having exceptional talent in every position. We understand the value of great people.We look deeper than credentials, prioritize slope over y-intercept, and put in the hard work to find those that truly raise the bar.&lt;/p&gt;
    &lt;head rend="h3"&gt;Humility&lt;/head&gt;
    &lt;p&gt;We are humble. Listening is mission critical — we are open to others’ perspectives and ideas. No work is beneath us. We also believe that humility leads to foresight.If we are not grounded and open minded, we blind ourselves from key opportunities and risks in every aspect of business.&lt;/p&gt;
    &lt;head rend="h2"&gt;Benefits&lt;/head&gt;
    &lt;head rend="h3"&gt;Competitive compensation&lt;/head&gt;
    &lt;p&gt;We offer competitive compensation and meaningful equity. We also offer 401k for our US employees and retirement plans for our international employees.&lt;/p&gt;
    &lt;head rend="h3"&gt;Hub &amp;amp; Remote friendly&lt;/head&gt;
    &lt;p&gt;Join our global team, either remotely or in one of our four in-person offices (San Francisco, NYC, Charlotte, and London). For those near an office, enjoy complimentary lunches Monday through Friday.&lt;/p&gt;
    &lt;head rend="h3"&gt;Flexible PTO&lt;/head&gt;
    &lt;p&gt;Downtime is just as important as on time and your teammates will support you while you relax and recharge.&lt;/p&gt;
    &lt;head rend="h3"&gt;Core benefits&lt;/head&gt;
    &lt;p&gt;For full-time US-based employees, we cover all health benefit premiums, 80% for dependents, and life insurance.&lt;/p&gt;
    &lt;head rend="h3"&gt;Parental leave&lt;/head&gt;
    &lt;p&gt;We value and support the family planning process. We provide up to 16 weeks for parents.&lt;/p&gt;
    &lt;head rend="h3"&gt;Professional development&lt;/head&gt;
    &lt;p&gt;We support employees for all learning resources needed to grow in their role (classes, books, conferences, etc).&lt;/p&gt;
    &lt;head rend="h3"&gt;Connectivity&lt;/head&gt;
    &lt;p&gt;We offer a $50 per month cell-phone or wifi connectivity stipend to all employees.&lt;/p&gt;
    &lt;head rend="h3"&gt;Commuter&lt;/head&gt;
    &lt;p&gt;Commuter benefits of $150 are offered to both employees who come into the offices and to remote workers working outside of their home.&lt;/p&gt;
    &lt;head rend="h2"&gt;Open positions&lt;/head&gt;
    &lt;head rend="h3"&gt;Customer Success&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Account Manager&lt;/p&gt;
        &lt;p&gt;New York City, New York&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Customer Success Engineer&lt;/p&gt;
        &lt;p&gt;Remote (Europe)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Head of Customer Success Engineering (West)&lt;/p&gt;
        &lt;p&gt;Remote (Mountain/Pacific North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Implementation Manager&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Manager, Technical Account Management&lt;/p&gt;
        &lt;p&gt;New York City, New York&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Technical Account Manager&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Engineering&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Backend Engineer, AI Content Agents&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Developer Productivity Engineer&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Forward Deployed Data Scientist&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Full Stack Product Engineer&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Head of Machine Learning&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Machine Learning Engineer, AI Decisioning&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Principal Engineer, Streaming Systems&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Software Engineer, AI Agents&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Software Engineer, Control Plane&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Software Engineer, Customer Studio Backend&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Software Engineer, Distributed Systems&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Software Engineer, Journeys&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Software Engineer, Streaming Systems&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Web Engineer&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Finance / Data / Operations&lt;/head&gt;
    &lt;head rend="h3"&gt;Marketing&lt;/head&gt;
    &lt;head rend="h3"&gt;Partnerships&lt;/head&gt;
    &lt;head rend="h3"&gt;People&lt;/head&gt;
    &lt;head rend="h3"&gt;Sales&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Account Executive (APAC)&lt;/p&gt;
        &lt;p&gt;Remote (APAC)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Enterprise Account Executive- East Region&lt;/p&gt;
        &lt;p&gt;Remote (East Coast)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Enterprise Account Executive, Mountain West Region&lt;/p&gt;
        &lt;p&gt;Remote (Mountain West)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Enterprise Account Executive, North EMEA&lt;/p&gt;
        &lt;p&gt;Remote (Europe)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Enterprise Account Executive, South EMEA&lt;/p&gt;
        &lt;p&gt;Remote (Europe)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Enterprise Account Executive, West Region&lt;/p&gt;
        &lt;p&gt;Remote (West Coast)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Enterprise Solutions Engineer, East&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Enterprise Solutions Engineer, West&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Manager, Sales Development&lt;/p&gt;
        &lt;p&gt;Denver, Colorado&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Manager, Sales Development&lt;/p&gt;
        &lt;p&gt;New York City, New York&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Manager, Solutions Engineering&lt;/p&gt;
        &lt;p&gt;New York, NY or San Francisco, CA&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mid-Market Account Executive, East Region&lt;/p&gt;
        &lt;p&gt;Remote (East Coast)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mid-Market Account Executive, EMEA&lt;/p&gt;
        &lt;p&gt;London, United Kingdom&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Regional VP of Enterprise Sales&lt;/p&gt;
        &lt;p&gt;New York, New York/ Boston, Massachusetts&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;RVP, Mid-Market Sales&lt;/p&gt;
        &lt;p&gt;Remote (North America)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sales Development Representative&lt;/p&gt;
        &lt;p&gt;New York, NY / Denver, CO / San Francisco, CA&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sales Development Representative, EMEA&lt;/p&gt;
        &lt;p&gt;London, United Kingdom&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Solutions Engineer, EMEA&lt;/p&gt;
        &lt;p&gt;Remote Europe&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Solutions Engineer (France)&lt;/p&gt;
        &lt;p&gt;Paris, France&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Hightouch has been named America’s #3 best startup employer by Forbes&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46704465</guid><pubDate>Wed, 21 Jan 2026 12:02:09 +0000</pubDate></item><item><title>Nested Code Fences in Markdown</title><link>https://susam.net/nested-code-fences.html</link><description>&lt;doc fingerprint="a0821a8b3cfb87a4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Nested Code Fences in Markdown&lt;/head&gt;
    &lt;p&gt;Today, we will meet a spiky-haired nerd named Corey Dumm, who normally lives within Markdown code fences. We will get to know him a bit, smile with him when his fences hold and weep quietly when misfortune strikes.&lt;/p&gt;
    &lt;p&gt;One of the caveats of the Markdown universe is the wide variety of Markdown implementations available. In these parallel universes, the rules of Markdown rendering differ subtly. In this post, we will focus only on the CommonMark specification. Since GitHub Flavoured Markdown (GFM) is a strict superset of CommonMark, whatever we discuss here applies equally well to both CommonMark and GFM.&lt;/p&gt;
    &lt;head rend="h2"&gt;Contents&lt;/head&gt;
    &lt;head rend="h2"&gt;Basic Code Fences&lt;/head&gt;
    &lt;p&gt;Corey had a knack for working with computers ever since he was a kid.&lt;/p&gt;
    &lt;code&gt;Corey at his computer:

```
(o_o)--.|[_]|
```&lt;/code&gt;
    &lt;p&gt;Everything was perfect in Corey's world. The CommonMark renderer would convert the Markdown above to the following HTML:&lt;/p&gt;
    &lt;p&gt;Corey at his computer:&lt;/p&gt;
    &lt;code&gt;(o_o)--.|[_]|
&lt;/code&gt;
    &lt;head&gt;View HTML&lt;/head&gt;
    &lt;code&gt;&amp;lt;p&amp;gt;Corey at his computer:&amp;lt;/p&amp;gt;
&amp;lt;pre&amp;gt;&amp;lt;code&amp;gt;(o_o)--.|[_]|
&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt;&lt;/code&gt;
    &lt;p&gt;At this point, all was well. Corey grew quickly. Before long, he had a head full of spiky hair. Then the fences began to matter.&lt;/p&gt;
    &lt;code&gt;Corey, all grown up:

```
 ```
(o_o)--.|[_]|
```&lt;/code&gt;
    &lt;p&gt;Let us see how this renders. I must warn you that during the Markdown-to-HTML translation, Corey loses his hair. Some viewers may find the following scene disturbing. Viewer discretion is advised. Here is the rendered HTML:&lt;/p&gt;
    &lt;p&gt;Corey, all grown up:&lt;/p&gt;
    &lt;p&gt;(o_o)--.|[_]|&lt;/p&gt;
    &lt;head&gt;View HTML&lt;/head&gt;
    &lt;code&gt;&amp;lt;p&amp;gt;Corey, all grown up:&amp;lt;/p&amp;gt;
&amp;lt;pre&amp;gt;&amp;lt;code&amp;gt;&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt;
&amp;lt;p&amp;gt;(o_o)--.|[_]|&amp;lt;/p&amp;gt;
&amp;lt;pre&amp;gt;&amp;lt;code&amp;gt;&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt;&lt;/code&gt;
    &lt;p&gt;Corey's hair is gone! What a catastrophic accident! Corey is alright, though. He is still quite afraid of Markdown fences, but otherwise well and bouncing back. Why did this happen? The second set of triple backticks immediately ends the fenced code block started by the first set of triple backticks. As a result, Corey's smiley face ends up outside the fenced code block. The triple backticks that were once Corey's hair are now woven into the fabric of the surrounding HTML. Fortunately, CommonMark offers a few ways to avoid such accidents.&lt;/p&gt;
    &lt;head rend="h2"&gt;Fancy Code Fences&lt;/head&gt;
    &lt;p&gt;In CommonMark, there are two main ways to include triple backticks within fenced code blocks. First, we can use tildes as the code fence:&lt;/p&gt;
    &lt;code&gt;Corey, all grown up:

~~~
 ```
(o_o)--.|[_]|
~~~&lt;/code&gt;
    &lt;p&gt;In fact, a code fence need not consist of exactly three backticks or tildes. Any number of backticks or tildes is allowed, as long as that number is at least three. The following is therefore equivalent:&lt;/p&gt;
    &lt;code&gt;Corey, all grown up:

~~~~~
 ```
(o_o)--.|[_]|
~~~~~&lt;/code&gt;
    &lt;p&gt;And so is this:&lt;/p&gt;
    &lt;code&gt;Corey, all grown up:

`````
 ```
(o_o)--.|[_]|
`````&lt;/code&gt;
    &lt;p&gt;All three examples render like this:&lt;/p&gt;
    &lt;p&gt;Corey, all grown up:&lt;/p&gt;
    &lt;code&gt; ```
(o_o)--.|[_]|
&lt;/code&gt;
    &lt;head&gt;View HTML&lt;/head&gt;
    &lt;code&gt;&amp;lt;p&amp;gt;Corey, all grown up:&amp;lt;/p&amp;gt;
&amp;lt;pre&amp;gt;&amp;lt;code&amp;gt; ```
(o_o)--.|[_]|
&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt;&lt;/code&gt;
    &lt;p&gt;No hair is lost in translation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Basic Code Spans&lt;/head&gt;
    &lt;p&gt;A similar problem arises with inline code spans. Most Markdown users know to use backticks to delimit inline code spans. For example:&lt;/p&gt;
    &lt;code&gt;An old picture of Corey at his computer: `(o_o)--.|[_]|`&lt;/code&gt;
    &lt;p&gt;This produces the following output:&lt;/p&gt;
    &lt;p&gt;An old picture of Corey at his computer: &lt;code&gt;(o_o)--.|[_]|&lt;/code&gt;&lt;/p&gt;
    &lt;head&gt;View HTML&lt;/head&gt;
    &lt;code&gt;&amp;lt;p&amp;gt;An old picture of Corey at his computer: &amp;lt;code&amp;gt;(o_o)--.|[_]|&amp;lt;/code&amp;gt;&amp;lt;/p&amp;gt;&lt;/code&gt;
    &lt;p&gt;However, what do we do when we need to put Corey's dear friend Becky Trace within an inline code span? Becky has short, straight hair tucked neatly on either side of her face. Here's a picture of her:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;`(o_o)`&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;I believe you can already see the difficulty here. Inline code spans use backticks as delimiters. So when we put Becky within a code span, the first backtick in Corey's face would terminate the code span immediately and then the rest of Becky would lie outside it. CommonMark offers solutions for this kind of situation as well.&lt;/p&gt;
    &lt;head rend="h2"&gt;Fancy Code Spans&lt;/head&gt;
    &lt;p&gt; An inline code span delimiter need not consist of exactly one backtick. It can consist of any number of backticks. So &lt;code&gt;`foo`&lt;/code&gt; and &lt;code&gt;``foo``&lt;/code&gt; produce identical HTML.
  There is another important but less well-known detail.  When the
  text inside an inline code span begins and ends with spaces, one
  space is removed from each end before rendering.  So
  &lt;code&gt;`foo`&lt;/code&gt; and &lt;code&gt;` foo `&lt;/code&gt; are equivalent.
  Therefore, when we need to put backticks within an inline code span,
  we can start the code span using multiple backticks and a space.
  For example:
&lt;/p&gt;
    &lt;code&gt;Meet Corey's friend Becky Trace: `` `(o_o)` ``&lt;/code&gt;
    &lt;p&gt;Here is the rendered output:&lt;/p&gt;
    &lt;p&gt;Meet Corey's friend Becky Trace: &lt;code&gt;`(o_o)`&lt;/code&gt;&lt;/p&gt;
    &lt;head&gt;View HTML&lt;/head&gt;
    &lt;code&gt;&amp;lt;p&amp;gt;Meet Corey's friend Becky Trace: &amp;lt;code&amp;gt;`(o_o)`&amp;lt;/code&amp;gt;&amp;lt;/p&amp;gt;&lt;/code&gt;
    &lt;p&gt;Becky has her hair intact too. We have avoided the mishap that once caused great distress to Corey. That, my friends, is how backticks survive nesting in Markdown.&lt;/p&gt;
    &lt;head rend="h2"&gt;Specification&lt;/head&gt;
    &lt;p&gt;Before I finish this post, let us take a look at the CommonMark specification to see where these details are defined. The excerpts quoted below are taken from CommonMark Spec Version 0.30, which is by now over four years old.&lt;/p&gt;
    &lt;p&gt;From section 4.5 Fenced Code Blocks:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;A code fence is a sequence of at least three consecutive backtick characters (&lt;/p&gt;&lt;code&gt;`&lt;/code&gt;) or tildes (&lt;code&gt;~&lt;/code&gt;). (Tildes and backticks cannot be mixed.)&lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;The content of the code block consists of all subsequent lines, until a closing code fence of the same type as the code block began with (backticks or tildes), and with at least as many backticks or tildes as the opening code fence.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;From section 6.1 Code Spans:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;A backtick string is a string of one or more backtick characters (&lt;/p&gt;&lt;code&gt;`&lt;/code&gt;) that is neither preceded nor followed by a backtick.&lt;p&gt;A code span begins with a backtick string and ends with a backtick string of equal length. The contents of the code span are the characters between these two backtick strings, normalized in the following ways:&lt;/p&gt;&lt;item&gt;First, line endings are converted to spaces.&lt;/item&gt;&lt;item&gt;If the resulting string both begins and ends with a space character, but does not consist entirely of space characters, a single space character is removed from the front and back. This allows you to include code that begins or ends with backtick characters, which must be separated by whitespace from the opening or closing backtick strings.&lt;/item&gt;&lt;/quote&gt;
    &lt;p&gt;I hope these little nuggets of Markdown trivialities will one day prove useful in your own Markdown misfortunes.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46705201</guid><pubDate>Wed, 21 Jan 2026 13:08:35 +0000</pubDate></item><item><title>Swedish Alecta has sold off an estimated $8B of US Treasury Bonds</title><link>https://www.di.se/nyheter/di-avslojar-alecta-har-dumpat-amerikanska-statspapper/</link><description>&lt;doc fingerprint="d00b8a7446d4bfd2"&gt;
  &lt;main&gt;&lt;p&gt;Är du redan prenumerant, logga in för att fortsätta läsa.&lt;/p&gt;Logga in&lt;head rend="h2"&gt; Erbjudande! &lt;lb/&gt; Prova Di Digitalt endast &lt;lb/&gt; 99 kr för 3 mån&lt;/head&gt;&lt;p&gt;Därefter tillsvidare med 30% rabatt, endast 385 kr/mån (ord.pris 549kr/mån) i 12 månader. Alla priser är inklusive moms. Erbjudandet gäller endast nya kunder.&lt;/p&gt;&lt;head rend="h3"&gt;Det här ingår i din prenumeration:&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Nordens största affärstidning i digitalt format&lt;/item&gt;&lt;item&gt;Tillgång till över 1100 aktiekurser i realtid&lt;/item&gt;&lt;item&gt;Tillgång till alla låsta artiklar&lt;/item&gt;&lt;item&gt;E-tidningen redan kvällen före&lt;/item&gt;&lt;item&gt;Di Weekend - Lyxiga livsstilsmagasinet digitalt&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt; Erbjudande! &lt;lb/&gt; Prova Di Digitalt endast &lt;lb/&gt; 99 kr för 3 mån&lt;/head&gt;&lt;head rend="h3"&gt;Ditt erbjudande&lt;/head&gt;&lt;head rend="h3"&gt;Di Digitalt&lt;/head&gt;&lt;p&gt;Därefter tillsvidare med 30% rabatt, endast 385 kr/mån (ord.pris 549kr/mån) i 12 månader. Alla priser är inklusive moms. Erbjudandet gäller endast nya kunder.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Nordens största affärstidning i digitalt format&lt;/item&gt;&lt;item&gt;Tillgång till över 1100 aktiekurser i realtid&lt;/item&gt;&lt;item&gt;Tillgång till alla låsta artiklar&lt;/item&gt;&lt;item&gt;E-tidningen redan kvällen före&lt;/item&gt;&lt;item&gt;Di Weekend - Lyxiga livsstilsmagasinet digitalt&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46705256</guid><pubDate>Wed, 21 Jan 2026 13:13:06 +0000</pubDate></item><item><title>Ireland wants to give its cops spyware, ability to crack encrypted messages</title><link>https://www.theregister.com/2026/01/21/ireland_wants_to_give_police/</link><description>&lt;doc fingerprint="fc3c993136b2f35d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Ireland wants to give its cops spyware, ability to crack encrypted messages&lt;/head&gt;
    &lt;head rend="h2"&gt;Its very own Snooper’s Charter comes a month after proposed biometric tech expansion&lt;/head&gt;
    &lt;p&gt;The Irish government is planning to bolster its police's ability to intercept communications, including encrypted messages, and provide a legal basis for spyware use.&lt;/p&gt;
    &lt;p&gt;The Communications (Interception and Lawful Access) Bill is being framed as a replacement for the current legislation that governs digital communication interception.&lt;/p&gt;
    &lt;p&gt;The Department of Justice, Home Affairs, and Migration said in an announcement this week the existing Postal Packets and Telecommunications Messages (Regulation) Act 1993 "predates the telecoms revolution of the last 20 years."&lt;/p&gt;
    &lt;p&gt;As well as updating laws passed more than two decades ago, the government was keen to emphasize that a key ambition for the bill is to empower law enforcement to intercept of all forms of communications.&lt;/p&gt;
    &lt;p&gt;The Bill will bring communications from IoT devices, email services, and electronic messaging platforms into scope, "whether encrypted or not."&lt;/p&gt;
    &lt;p&gt;In a similar way to how certain other governments want to compel encrypted messaging services to unscramble packets of interest, Ireland's announcement also failed to explain exactly how it plans to do this.&lt;/p&gt;
    &lt;p&gt;However, it promised to implement a robust legal framework, alongside all necessary privacy and security safeguards, if these proposals do ultimately become law. It also vowed to establish structures to ensure "the maximum possible degree of technical cooperation between state agencies and communication service providers."&lt;/p&gt;
    &lt;p&gt;The government said it will follow the EU Commission's (EC) roadmap for law enforcement data interception, including a section on encryption issues, which it published last year.&lt;/p&gt;
    &lt;p&gt;"There is an urgent need for a new legal framework for lawful interception which can be used to confront serious crime and security threats," said justice minister Jim O'Callaghan, announcing the news.&lt;/p&gt;
    &lt;p&gt;"The new legislation will also include robust legal safeguards to provide continued assurance that the use of such powers is necessary and proportionate.&lt;/p&gt;
    &lt;p&gt;He said new legislation is "long overdue", following "significant changes" to digital comms over the past twenty years that "existing legislation does not comprehend."&lt;/p&gt;
    &lt;head rend="h3"&gt;Spyware provision&lt;/head&gt;
    &lt;p&gt;Ireland will also take the EU's lead on spyware, establishing a legal provision for its use, only in cases of strict necessity.&lt;/p&gt;
    &lt;p&gt;The EC's 2024 paper [PDF] examining the legality of spyware noted it could be used by member states, but only where situations absolutely require it. Programs must be used proportionally, with a judge's approval, and with stringent oversight.&lt;/p&gt;
    &lt;p&gt;The justice ministry said it would take this paper into consideration when developing Ireland's legal provision for using spyware. Example cases could include accessing data on a device or network, or covert recordings of communications on a device, or over a network, the government said.&lt;/p&gt;
    &lt;p&gt;In addition to spyware, Ireland is looking to establish a legal power for police to scan electronic equipment in a specific location to identify people of interest and their associates in relation to serious crime investigations. Examples of this technology in action include police camping outside a single location, and operating IMSI catchers to identify those inside.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Rather than add a backdoor, Apple decides to kill iCloud encryption for UK peeps&lt;/item&gt;
      &lt;item&gt;AWS flips switch on Euro cloud as customers fret about digital sovereignty&lt;/item&gt;
      &lt;item&gt;IPv6 just turned 30 and still hasn't taken over the world, but don't call it a failure&lt;/item&gt;
      &lt;item&gt;UK surveillance law still full of holes, watchdog warns&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Olga Cronin, surveillance and human rights senior policy officer at the Irish Council for Civil Liberties (ICCL), said the nonprofit "has very serious concerns about this shopping list of surveillance powers," despite the proposals still being in their infancy.&lt;/p&gt;
    &lt;p&gt;"These are surveillance tools and powers of extraordinary reach, with sweeping implications for people's rights and freedoms, and come in the context of An Garda Síochána already expanding their 'eyes and ears' via the Recording Devices Bill," Cronin added.&lt;/p&gt;
    &lt;p&gt;The separate but related Recording Devices Bill was introduced in December 2025, proposing expanded police use of biometric recognition technology.&lt;/p&gt;
    &lt;p&gt;It did not say exactly how this would be implemented, but ministers describing the Bill's ambitions suggested that both live and retrospective facial recognition could become widely used across Ireland's police force.&lt;/p&gt;
    &lt;p&gt;"Once powers of this magnitude are normalised, the damage to rights and freedoms can be extremely difficult to reverse," said Cronin.&lt;/p&gt;
    &lt;p&gt;"We must also remember that measures introduced for exceptional or serious crimes tend, over time, to be used for much less serious crimes because there is institutional pressure to use them more frequently. What was once exceptional becomes routine." ®&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46705715</guid><pubDate>Wed, 21 Jan 2026 13:52:27 +0000</pubDate></item><item><title>Show HN: ChartGPU – WebGPU-powered charting library (1M points at 60fps)</title><link>https://github.com/ChartGPU/ChartGPU</link><description>&lt;doc fingerprint="a905bd6501bc13b2"&gt;
  &lt;main&gt;
    &lt;p&gt;High-performance charts powered by WebGPU&lt;/p&gt;
    &lt;p&gt;Documentation | Live Demo | Examples&lt;/p&gt;
    &lt;p&gt;ChartGPU is a TypeScript charting library built on WebGPU for smooth, interactive rendering—especially when you have lots of data.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🚀 WebGPU-accelerated rendering for high FPS with large datasets&lt;/item&gt;
      &lt;item&gt;📈 Multiple series types: line, area, bar, scatter, pie, candlestick&lt;/item&gt;
      &lt;item&gt;🧭 Built-in interaction: hover highlight, tooltip, crosshair&lt;/item&gt;
      &lt;item&gt;🔁 Streaming updates via &lt;code&gt;appendData(...)&lt;/code&gt;(cartesian series)&lt;/item&gt;
      &lt;item&gt;🔍 X-axis zoom (inside gestures + optional slider UI)&lt;/item&gt;
      &lt;item&gt;🎛️ Theme presets (&lt;code&gt;'dark' | 'light'&lt;/code&gt;) and custom theme support&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;At a high level, &lt;code&gt;ChartGPU.create(...)&lt;/code&gt; owns the canvas + WebGPU lifecycle, and delegates render orchestration (layout/scales/data upload/render passes + internal overlays) to the render coordinator. For deeper internal notes, see &lt;code&gt;docs/API.md&lt;/code&gt; (especially “Render coordinator”).&lt;/p&gt;
    &lt;code&gt;flowchart TB
  UserApp["Consumer app"] --&amp;gt; PublicAPI["src/index.ts (Public API exports)"]

  PublicAPI --&amp;gt; ChartCreate["ChartGPU.create(container, options)"]
  PublicAPI --&amp;gt; SyncAPI["connectCharts(charts)"]

  subgraph ChartInstance["Chart instance (src/ChartGPU.ts)"]
    ChartCreate --&amp;gt; SupportCheck["checkWebGPUSupport()"]
    ChartCreate --&amp;gt; Canvas["Create canvas + mount into container"]
    ChartCreate --&amp;gt; Options["resolveOptions(options)"]
    ChartCreate --&amp;gt; GPUInit["GPUContext.create(canvas)"]
    ChartCreate --&amp;gt; Coordinator["createRenderCoordinator(gpuContext, resolvedOptions)"]

    ChartCreate --&amp;gt; InstanceAPI["ChartGPUInstance APIs"]
    InstanceAPI --&amp;gt; RequestRender["requestAnimationFrame (coalesced)"]
    RequestRender --&amp;gt; Coordinator

    InstanceAPI --&amp;gt; SetOption["setOption(...)"]
    InstanceAPI --&amp;gt; AppendData["appendData(...)"]
    InstanceAPI --&amp;gt; Resize["resize()"]

    subgraph PublicEvents["Public events + hit-testing (ChartGPU.ts)"]
      Canvas --&amp;gt; PointerHandlers["Pointer listeners"]
      PointerHandlers --&amp;gt; PublicHitTest["findNearestPoint() / findPieSlice()"]
      PointerHandlers --&amp;gt; EmitEvents["emit('click'/'mouseover'/'mouseout')"]
    end

    DataZoomSlider["dataZoom slider UI (DOM)"] --&amp;gt; Coordinator
  end

  subgraph WebGPUCore["WebGPU core (src/core/GPUContext.ts)"]
    GPUInit --&amp;gt; AdapterDevice["navigator.gpu.requestAdapter/device"]
    GPUInit --&amp;gt; CanvasConfig["canvasContext.configure(format)"]
  end

  subgraph RenderCoordinatorLayer["Render coordinator (src/core/createRenderCoordinator.ts)"]
    Coordinator --&amp;gt; Layout["GridArea layout"]
    Coordinator --&amp;gt; Scales["xScale/yScale (clip space for render)"]
    Coordinator --&amp;gt; DataUpload["createDataStore(device) (GPU buffer upload/caching)"]
    Coordinator --&amp;gt; RenderPass["Encode + submit render pass"]

    subgraph InternalOverlays["Internal interaction overlays (coordinator)"]
      Coordinator --&amp;gt; Events["createEventManager(canvas, gridArea)"]
      Events --&amp;gt; OverlayHitTest["hover/tooltip hit-testing"]
      Events --&amp;gt; InteractionX["interaction-x state (crosshair)"]
      Coordinator --&amp;gt; OverlaysDOM["DOM overlays: legend / tooltip / text labels"]
    end
  end

  subgraph Renderers["GPU renderers (src/renderers/*)"]
    RenderPass --&amp;gt; GridR["Grid"]
    RenderPass --&amp;gt; AreaR["Area"]
    RenderPass --&amp;gt; BarR["Bar"]
    RenderPass --&amp;gt; ScatterR["Scatter"]
    RenderPass --&amp;gt; LineR["Line"]
    RenderPass --&amp;gt; PieR["Pie"]
    RenderPass --&amp;gt; CandlestickR["Candlestick"]
    RenderPass --&amp;gt; CrosshairR["Crosshair overlay"]
    RenderPass --&amp;gt; HighlightR["Hover highlight overlay"]
    RenderPass --&amp;gt; AxisR["Axes/ticks"]
  end

  subgraph Shaders["WGSL shaders (src/shaders/*)"]
    GridR --&amp;gt; gridWGSL["grid.wgsl"]
    AreaR --&amp;gt; areaWGSL["area.wgsl"]
    BarR --&amp;gt; barWGSL["bar.wgsl"]
    ScatterR --&amp;gt; scatterWGSL["scatter.wgsl"]
    LineR --&amp;gt; lineWGSL["line.wgsl"]
    PieR --&amp;gt; pieWGSL["pie.wgsl"]
    CandlestickR --&amp;gt; candlestickWGSL["candlestick.wgsl"]
    CrosshairR --&amp;gt; crosshairWGSL["crosshair.wgsl"]
    HighlightR --&amp;gt; highlightWGSL["highlight.wgsl"]
  end

  subgraph ChartSync["Chart sync (src/interaction/createChartSync.ts)"]
    SyncAPI --&amp;gt; ListenX["listen: 'crosshairMove'"]
    SyncAPI --&amp;gt; DriveX["setCrosshairX(...) on peers"]
  end

  InteractionX --&amp;gt; ListenX
  DriveX --&amp;gt; InstanceAPI
&lt;/code&gt;
    &lt;p&gt;Financial OHLC (open-high-low-close) candlestick rendering with classic/hollow style toggle and color customization.&lt;/p&gt;
    &lt;code&gt;import { ChartGPU } from 'chartgpu';
const container = document.getElementById('chart')!;
await ChartGPU.create(container, {
  series: [{ type: 'line', data: [[0, 1], [1, 3], [2, 2]] }],
});&lt;/code&gt;
    &lt;p&gt;
      &lt;code&gt;npm install chartgpu&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;React bindings are available via &lt;code&gt;chartgpu-react&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;npm install chartgpu-react&lt;/code&gt;
    &lt;code&gt;import { ChartGPUChart } from 'chartgpu-react';

function MyChart() {
  return (
    &amp;lt;ChartGPUChart
      options={{
        series: [{ type: 'line', data: [[0, 1], [1, 3], [2, 2]] }],
      }}
    /&amp;gt;
  );
}&lt;/code&gt;
    &lt;p&gt;See the chartgpu-react repository for full documentation and examples.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Chrome 113+ or Edge 113+ (WebGPU enabled by default)&lt;/item&gt;
      &lt;item&gt;Safari 18+ (WebGPU enabled by default)&lt;/item&gt;
      &lt;item&gt;Firefox: not supported (WebGPU support in development)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Full documentation: Getting Started&lt;/item&gt;
      &lt;item&gt;API reference: &lt;code&gt;docs/API.md&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Browse examples: &lt;code&gt;examples/&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Run locally: &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;npm install&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;npm run dev&lt;/code&gt;(opens&lt;code&gt;http://localhost:5176/examples/&lt;/code&gt;)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See &lt;code&gt;CONTRIBUTING.md&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;MIT — see &lt;code&gt;LICENSE&lt;/code&gt;.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46706528</guid><pubDate>Wed, 21 Jan 2026 14:54:56 +0000</pubDate></item><item><title>Show HN: See the carbon impact of your cloud as you code</title><link>https://dashboard.infracost.io/</link><description>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46706668</guid><pubDate>Wed, 21 Jan 2026 15:04:07 +0000</pubDate></item><item><title>Show HN: yolo-cage – AI coding agents that can't exfiltrate secrets</title><link>https://github.com/borenstein/yolo-cage</link><description>&lt;doc fingerprint="9f781b9e1db7ca83"&gt;
  &lt;main&gt;
    &lt;p&gt;You're a responsible engineer. You'd never just let an AI run roughshod through your most sensitive systems and codebases.&lt;/p&gt;
    &lt;p&gt;That's why you'd never just shut off the safeguards for a tool like Claude Code. It asks permission for every dangerous action! Safe!&lt;/p&gt;
    &lt;p&gt;So you wait. And you answer. Decision fatigue sets in. And that's when it happens.&lt;/p&gt;
    &lt;p&gt;Permission prompts neglect the weakest part of the thread model: a tired user. What if we could empower the agent while limiting its blast radius, thus deferring your decisions until PR review?&lt;/p&gt;
    &lt;p&gt;That would be great! And that would be yolo-cage.&lt;/p&gt;
    &lt;code&gt;curl -fsSL https://github.com/borenstein/yolo-cage/releases/latest/download/yolo-cage -o yolo-cage
chmod +x yolo-cage &amp;amp;&amp;amp; sudo mv yolo-cage /usr/local/bin/
yolo-cage build --interactive --up&lt;/code&gt;
    &lt;p&gt;Then create a sandbox and start coding:&lt;/p&gt;
    &lt;code&gt;yolo-cage create feature-branch
yolo-cage attach feature-branch   # Claude in tmux, YOLO mode&lt;/code&gt;
    &lt;p&gt;Prerequisites: Vagrant with libvirt (Linux) or QEMU (macOS, experimental), 8GB RAM, 4 CPUs, GitHub PAT (&lt;code&gt;repo&lt;/code&gt; scope), Claude account. See setup docs for details.&lt;/p&gt;
    &lt;p&gt;Secrets in HTTP/HTTPS - egress proxy scans request bodies, headers, URLs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;sk-ant-*&lt;/code&gt;,&lt;code&gt;AKIA*&lt;/code&gt;,&lt;code&gt;ghp_*&lt;/code&gt;, SSH private keys, generic credential patterns&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Git operations - dispatcher enforces branch isolation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Push to any branch except the one assigned at sandbox creation&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;git remote&lt;/code&gt;,&lt;code&gt;git clone&lt;/code&gt;,&lt;code&gt;git config&lt;/code&gt;,&lt;code&gt;git credential&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;GitHub CLI - dispatcher blocks dangerous commands:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;gh pr merge&lt;/code&gt;,&lt;code&gt;gh repo delete&lt;/code&gt;,&lt;code&gt;gh api&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;GitHub API - proxy blocks at HTTP layer:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;PUT /repos/*/pulls/*/merge&lt;/code&gt;,&lt;code&gt;DELETE /repos/*&lt;/code&gt;, webhook modifications&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Exfiltration sites: pastebin.com, file.io, transfer.sh, etc.&lt;/p&gt;
    &lt;p&gt;See Architecture for the full threat model.&lt;/p&gt;
    &lt;code&gt;┌──────────────────────────────────────────────────────────────────────────┐
│ Vagrant VM (MicroK8s)                                                    │
│                                                                          │
│  ┌────────────────────────────────────────────────────────────────────┐  │
│  │ Sandbox Pod                                                        │  │
│  │                                                                    │  │
│  │  Claude Code (YOLO mode)                                           │  │
│  │       │                                                            │  │
│  │       ├── git/gh ──▶ Dispatcher ──▶ GitHub                         │  │
│  │       │              • Branch enforcement                          │  │
│  │       │              • TruffleHog pre-push                         │  │
│  │       │                                                            │  │
│  │       └── HTTP/S ──▶ Egress Proxy ──▶ Internet                     │  │
│  │                      • Secret scanning                             │  │
│  │                      • Domain blocklist                            │  │
│  └────────────────────────────────────────────────────────────────────┘  │
│                                                                          │
└──────────────────────────────────────────────────────────────────────────┘
&lt;/code&gt;
    &lt;p&gt;One sandbox per branch. Agents can only push to their assigned branch. All outbound traffic is filtered.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Command&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;create &amp;lt;branch&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Create sandbox&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;attach &amp;lt;branch&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Attach (Claude in tmux)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;shell &amp;lt;branch&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Attach (bash)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;list&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;List sandboxes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;delete &amp;lt;branch&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Delete sandbox&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;port-forward &amp;lt;branch&amp;gt; &amp;lt;port&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Forward port from sandbox&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;up&lt;/code&gt; / &lt;code&gt;down&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Start/stop VM&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;upgrade [--rebuild]&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Upgrade to latest version&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;version&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Show version&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Access web apps running inside a sandbox:&lt;/p&gt;
    &lt;code&gt;yolo-cage port-forward feature-x 8080           # localhost:8080 → pod:8080
yolo-cage port-forward feature-x 9000:3000      # localhost:9000 → pod:3000
yolo-cage port-forward feature-x 8080 --bind 0.0.0.0  # LAN accessible&lt;/code&gt;
    &lt;p&gt;See Configuration for proxy bypass, hooks, and resource limits.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Architecture - Threat model, design rationale&lt;/item&gt;
      &lt;item&gt;Configuration - Egress policy, proxy bypass, hooks&lt;/item&gt;
      &lt;item&gt;Customization - Adding tools, resource limits&lt;/item&gt;
      &lt;item&gt;Security Audit - Escape testing guide&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This reduces risk. It does not eliminate it.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;DNS exfiltration - data encoded in DNS queries&lt;/item&gt;
      &lt;item&gt;Timing side channels - information leaked via response timing&lt;/item&gt;
      &lt;item&gt;Steganography - secrets hidden in images or binary data&lt;/item&gt;
      &lt;item&gt;Sophisticated encoding - bypassing pattern matching&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Use scoped credentials. Don't use production secrets where exfiltration would be catastrophic. See Security Audit to test it yourself.&lt;/p&gt;
    &lt;p&gt;MIT. See LICENSE.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46706796</guid><pubDate>Wed, 21 Jan 2026 15:13:29 +0000</pubDate></item><item><title>Skip Is Now Free and Open Source</title><link>https://skip.dev/blog/skip-is-free/</link><description>&lt;doc fingerprint="3f0ad3111315ee7e"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Skip Is Now Free and Open Source&lt;/head&gt;&lt;p&gt;Since launching Skip in 2023, we’ve pursued one mission: enable developers to create premium mobile apps for iOS and Android from a single Swift and SwiftUI codebase — without any of the compromises that have encumbered cross-platform development tools since, well, forever.&lt;/p&gt;&lt;p&gt;Over the past three years, Skip has evolved significantly. We started with a Swift-to-Kotlin transpiler and Android support for the most common SwiftUI APIs. We then founded the Swift Android Workgroup ↗ and released the Swift Android SDK to compile Swift natively for Android. We now have dozens of popular integration frameworks, interoperate with thousands of cross-platform Swift packages, and feature the most complete independent SwiftUI implementation available.&lt;/p&gt;&lt;head rend="h3"&gt;The Challenge of Paid Developer Tools&lt;/head&gt;Section titled “The Challenge of Paid Developer Tools”&lt;p&gt;Until today, Skip has required a paid subscription and license key to build apps. While free apps and indie developers below a revenue threshold were exempt, businesses were expected to subscribe. This model helped us bootstrap Skip without outside investment, but we’ve always known that to truly compete with legacy cross-platform tools and achieve widespread adoption, Skip would need to become freely available.&lt;/p&gt;&lt;p&gt;The plain truth is that developers expect to get their tools free of charge. First-party IDEs like Xcode and Android Studio, popular integration frameworks, and essential dev tools are all given away at no (direct) cost. The platform vendors monetize through developer program fees, app store commissions, and cloud services. Framework providers typically monetize through complementary services. But developer tools? Those have historically required the patronage of massive tech companies in order to fund their ongoing development, support, and infrastructure costs.&lt;/p&gt;&lt;p&gt;Beyond pricing, there’s a deeper concern about durability. Developers are understandably wary of building their entire app strategy on a small company’s paid, closed-source tool. What if the company goes under? Gets acquired and shut down? What happens to their apps? We get it. While Skip’s innate ejectability offers some risk mitigation, product teams need absolute confidence that their chosen technologies will be around next week, next year, and beyond. They must remain immune from the dreaded “rug pull” that so often accompanies a “pivot”.&lt;/p&gt;&lt;p&gt;To keep the development community’s trust and achieve mass adoption, Skip needs a completely free and open foundation. Even if the core team disappeared, the community could continue supporting the technology and the apps that depend on it.&lt;/p&gt;&lt;head rend="h3"&gt;What’s Changing&lt;/head&gt;Section titled “What’s Changing”&lt;p&gt;As of Skip 1.7, all licensing requirements have been removed. No license keys, no end-user license agreements, no trial or evaluation period.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Current Skip developers: Your setup remains completely unchanged, except you will no longer need your license key after upgrading.&lt;/item&gt;&lt;item&gt;New Skip users: You can start building immediately — no evaluation license required.&lt;/item&gt;&lt;item&gt;Open source skipstone: We’ve open-sourced the Skip engine, known as “skipstone”. This is the tool that handles all the critical build-time functionality: Project creation and management, Xcode and SwiftPM plugin logic, iOS-to-Android project transformation, resource and localization bundling, JNI bridge creation, source transpilation, app packaging, and project export. It is now available as a public GitHub repository at https://github.com/skiptools ↗ under a free and open-source license.&lt;/item&gt;&lt;item&gt;Migrate skip.tools to skip.dev: As part of this process, we are launching our new home at https://skip.dev ↗! This new site hosts our documentation, blog, and case studies, and it is also open-source and welcomes contributions at https://github.com/skiptools/skip.dev ↗. We will eventually be migrating the entirety of https://skip.tools ↗ to https://skip.dev ↗.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Supporting Skip’s Future&lt;/head&gt;Section titled “Supporting Skip’s Future”&lt;p&gt;Since day one, Skip has been bootstrapped. We haven’t taken venture capital or private equity investment, nor are we controlled by big tech. This independence means we control our destiny and can make the best decisions for Skip’s developers and users — a unique position in the cross-platform development space.&lt;/p&gt;&lt;p&gt;But independence requires community support. And that is where you come in.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Current subscribers: Your Small Business or Professional plan will automatically transition to an Individual ↗ or Supporter ↗ tier, respectively. You can cancel any time with no consequences (other than making us sad), but we hope you’ll consider staying on, at least throughout this transition period.&lt;/item&gt;&lt;item&gt;Individual developers: If you believe in Skip’s mission, please consider supporting us through GitHub Sponsors ↗ with a monthly contribution.&lt;/item&gt;&lt;item&gt;Companies and organizations: For businesses that want to see Skip flourish, we offer corporate sponsorship tiers with visibility on our homepage and in our documentation. Your sponsorship directly funds development of the integration frameworks essential to production apps, as well as the ongoing maintenance, support, and infrastructure. Sponsorship comes with some compelling perks! Please visit https://skip.dev/sponsor ↗ to see the sponsorship tiers.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Investing in Skip is also investing in your own team’s capabilities and competitive advantage. Your support accelerates Skip’s development and ensures its long-term success, enabling your developers to build exceptional native experiences efficiently, today and into the future.&lt;/p&gt;&lt;head rend="h3"&gt;What Comes Next&lt;/head&gt;Section titled “What Comes Next”&lt;p&gt;We’re at a pivotal moment in the app development field. Legacy cross‑platform frameworks are struggling to keep pace with the rapid evolution of modern UI systems like Liquid Glass on iOS and Material Expressive on Android. The compromises that once felt acceptable in exchange for a unified codebase now result in dated interfaces, weaker user experiences, and real competitive disadvantages. Teams ready to move beyond those trade‑offs can count on Skip to champion what matters most: delivering truly native, uncompromised experiences on both major mobile platforms.&lt;/p&gt;&lt;p&gt;Opening Skip to the community marks the next step in its evolution. Software is never finished — especially a tool that supports modern Swift and Kotlin, SwiftPM and Gradle, Xcode and Android Studio, iOS and Android, and the ongoing growth of SwiftUI and Jetpack Compose. It’s a demanding pursuit, and we’re committed to it. But sustaining and expanding this work depends on the support of developers who believe in Skip’s mission.&lt;/p&gt;&lt;p&gt;Together, we will continue building toward Skip’s vision: a genuinely no‑compromise, cross‑platform foundation for universal mobile apps.&lt;/p&gt;&lt;p&gt;Thank you for your support, and as always, Happy Skipping!&lt;/p&gt;&lt;p&gt;Ready to get started? Get started with Skip 1.7 today and join the community building the future of native cross-platform development.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46706906</guid><pubDate>Wed, 21 Jan 2026 15:20:53 +0000</pubDate></item><item><title>SmartOS</title><link>https://docs.smartos.org/</link><description>&lt;doc fingerprint="3653195c723d5ed3"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Home&lt;/head&gt;
    &lt;p&gt;Welcome to the SmartOS Documentation. Here you'll find everything you need to get started using SmartOS and participating in the community. Information about what's new in recent releases can be found in the SmartOS Changelog.&lt;/p&gt;
    &lt;head rend="h2"&gt;Quick Start¶&lt;/head&gt;
    &lt;p&gt;Not sure where to begin? Try the SmartOS Quick Start Guide!&lt;/p&gt;
    &lt;head rend="h2"&gt;SmartOS In a Nutshell¶&lt;/head&gt;
    &lt;p&gt;SmartOS is a specialized Type 1 Hypervisor platform based on illumos.Â It supports two types of virtualization:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;OS Virtual Machines (Zones, Containers): A light-weight virtualization solution offering a complete and secure userland environment on a single global kernel, offering true bare metal performance and all the features illumos has, namely dynamic introspection via DTrace&lt;/item&gt;
      &lt;item&gt;Hardware Virtual Machines (KVM, Bhyve): A full virtualization solution for running a variety of guest OS's including Linux, Windows, *BSD, Plan9 and more&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;SmartOS is a "live OS", it is always booted via PXE, ISO, or USB Key and runs entirely from memory, allowing the local disks to be used entirely for hosting virtual machines without wasting disks for the root OS.Â This architecture has a variety of advantages including increased security, no need for patching, fast upgrades and recovery.&lt;/p&gt;
    &lt;p&gt;Virtualization in SmartOS builds on top of the foundational illumos technologies inherited from OpenSolaris, namely:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ZFS for storage virtualization&lt;/item&gt;
      &lt;item&gt;Crossbow (&lt;code&gt;dladm&lt;/code&gt;) for network virtualization&lt;/item&gt;
      &lt;item&gt;Zones for virtualization and containment&lt;/item&gt;
      &lt;item&gt;DTrace for introspection&lt;/item&gt;
      &lt;item&gt;SMF for service management&lt;/item&gt;
      &lt;item&gt;RBAC/BSM for auditing and role based security&lt;/item&gt;
      &lt;item&gt;And more&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;SmartOS is typically "installed" by downloading and copying the OS image onto a USB key and then booting that key.Â On the first boot a configuration utility will configure your base networking, allow you to set the root password, and allow you to select which disks to use to create the ZFS Zpool which will provide persistent storage.&lt;/p&gt;
    &lt;p&gt;When you log into SmartOS you will enter the hypervisor, aka "global zone". From here you can download VM Images using the &lt;code&gt;imgadm&lt;/code&gt; tool, which are
pre-configured Container and HVM virtual machines.Â  You can then use the
&lt;code&gt;vmadm&lt;/code&gt; tool to create and manage both containers and hardware virtual
machines.&lt;/p&gt;
    &lt;p&gt;An important aspect of SmartOS is that both OS (Zones) and hardware virtual machines are both built on Zones technology.Â In the case of OS virtualization, the guest virtual machine is provided with a complete userland environment on which to run applications directly. In the case of HVM virtualization, the &lt;code&gt;qemu&lt;/code&gt; or &lt;code&gt;bhyve&lt;/code&gt;  process
will run within a stripped down Zone.Â  This offers a variety of
advantages for administration, including a common method for managing
resource controls, network interfaces, and administration.Â  It also
provides HVM guests with an additional layer of security and isolation
not offered by other virtualization platforms.&lt;/p&gt;
    &lt;p&gt;Finally, instances are described in JSON.Â Both administrative tools, &lt;code&gt;imgadm&lt;/code&gt; and &lt;code&gt;vmadm&lt;/code&gt;, accept and return all data in JSON
format.Â  This provides a simple, consistent, and programmatic
interface for creating and managing VM's.&lt;/p&gt;
    &lt;head rend="h2"&gt;Code of Conduct¶&lt;/head&gt;
    &lt;p&gt;As a participant of the illumos community, all projects related to Triton (including SmartOS, Triton, Manta, etc.) we have adopted the illumos Code of Conduct.&lt;/p&gt;
    &lt;head rend="h3"&gt;Scope¶&lt;/head&gt;
    &lt;p&gt;The scope of the code of conduct extends to SmartOS, Triton, and Manta resources including mailing lists, chat, social media, and GitHub repositories.&lt;/p&gt;
    &lt;head rend="h3"&gt;Enforcement¶&lt;/head&gt;
    &lt;p&gt;Conduct violations involving the Triton community may be reported by contacting conduct@tritondatacenter.com instead of, or in addition to conduct@illumos.org as the case may be warranted.&lt;/p&gt;
    &lt;head rend="h2"&gt;How to Use this Site¶&lt;/head&gt;
    &lt;p&gt;This documentation can provide you with a variety of resources for users at all levels.Â To get started, download SmartOS now, and be sure to review the Hardware Requirements. Once installed, refer to our Users Guide to help you learn your way around SmartOS.&lt;/p&gt;
    &lt;p&gt;When you have questions, refer to the SmartOS Community section for pointers to our IRC chat rooms and mailing lists.Â When you're ready to start improving and adding your own customizations to SmartOS please refer to our Developers Guide.&lt;/p&gt;
    &lt;p&gt;SmartOS is a community effort, as you explore and experiment with SmartOS please feel free to edit and contribute to this site to improve the documentation for other users in the community.&lt;/p&gt;
    &lt;head rend="h2"&gt;About Triton¶&lt;/head&gt;
    &lt;p&gt;SmartOS is a fundamental component of the Triton Data Center (Triton) product. Triton source and images are available for at no cost and powers several public and private clouds around the globe, namely the MNX Public Cloud.Â As you use SmartOS you will come across hooks that are used by Triton, such as file systems and services named "smartdc".&lt;/p&gt;
    &lt;p&gt;If you are interested in evaluating the full Triton Data Center product, please contact smartos@tritondatacenter.com.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46706947</guid><pubDate>Wed, 21 Jan 2026 15:23:18 +0000</pubDate></item><item><title>Claude's New Constitution</title><link>https://www.anthropic.com/news/claude-new-constitution</link><description>&lt;doc fingerprint="379c095a3d9d92eb"&gt;
  &lt;main&gt;
    &lt;p&gt;We’re publishing a new constitution for our AI model, Claude. It’s a detailed description of Anthropic’s vision for Claude’s values and behavior; a holistic document that explains the context in which Claude operates and the kind of entity we would like Claude to be.&lt;/p&gt;
    &lt;p&gt;The constitution is a crucial part of our model training process, and its content directly shapes Claude’s behavior. Training models is a difficult task, and Claude’s outputs might not always adhere to the constitution’s ideals. But we think that the way the new constitution is written—with a thorough explanation of our intentions and the reasons behind them—makes it more likely to cultivate good values during training.&lt;/p&gt;
    &lt;p&gt;In this post, we describe what we’ve included in the new constitution and some of the considerations that informed our approach.&lt;/p&gt;
    &lt;p&gt;We’re releasing Claude’s constitution in full under a Creative Commons CC0 1.0 Deed, meaning it can be freely used by anyone for any purpose without asking for permission.&lt;/p&gt;
    &lt;head rend="h2"&gt;What is Claude’s Constitution?&lt;/head&gt;
    &lt;p&gt;Claude’s constitution is the foundational document that both expresses and shapes who Claude is. It contains detailed explanations of the values we would like Claude to embody and the reasons why. In it, we explain what we think it means for Claude to be helpful while remaining broadly safe, ethical, and compliant with our guidelines. The constitution gives Claude information about its situation and offers advice for how to deal with difficult situations and tradeoffs, like balancing honesty with compassion and the protection of sensitive information. Although it might sound surprising, the constitution is written primarily for Claude. It is intended to give Claude the knowledge and understanding it needs to act well in the world.&lt;/p&gt;
    &lt;p&gt;We treat the constitution as the final authority on how we want Claude to be and to behave—that is, any other training or instruction given to Claude should be consistent with both its letter and its underlying spirit. This makes publishing the constitution particularly important from a transparency perspective: it lets people understand which of Claude’s behaviors are intended versus unintended, to make informed choices, and to provide useful feedback. We think transparency of this kind will become ever more important as AIs start to exert more influence in society1.&lt;/p&gt;
    &lt;p&gt;We use the constitution at various stages of the training process. This has grown out of training techniques we’ve been using since 2023, when we first began training Claude models using Constitutional AI. Our approach has evolved significantly since then, and the new constitution plays an even more central role in training.&lt;/p&gt;
    &lt;p&gt;Claude itself also uses the constitution to construct many kinds of synthetic training data, including data that helps it learn and understand the constitution, conversations where the constitution might be relevant, responses that are in line with its values, and rankings of possible responses. All of these can be used to train future versions of Claude to become the kind of entity the constitution describes. This practical function has shaped how we’ve written the constitution: it needs to work both as a statement of abstract ideals and a useful artifact for training.&lt;/p&gt;
    &lt;head rend="h2"&gt;Our new approach to Claude’s Constitution&lt;/head&gt;
    &lt;p&gt;Our previous Constitution was composed of a list of standalone principles. We’ve come to believe that a different approach is necessary. We think that in order to be good actors in the world, AI models like Claude need to understand why we want them to behave in certain ways, and we need to explain this to them rather than merely specify what we want them to do. If we want models to exercise good judgment across a wide range of novel situations, they need to be able to generalize—to apply broad principles rather than mechanically following specific rules.&lt;/p&gt;
    &lt;p&gt;Specific rules and bright lines sometimes have their advantages. They can make models’ actions more predictable, transparent, and testable, and we do use them for some especially high-stakes behaviors in which Claude should never engage (we call these “hard constraints”). But such rules can also be applied poorly in unanticipated situations or when followed too rigidly2. We don’t intend for the constitution to be a rigid legal document—and legal constitutions aren’t necessarily like this anyway.&lt;/p&gt;
    &lt;p&gt;The constitution reflects our current thinking about how to approach a dauntingly novel and high-stakes project: creating safe, beneficial non-human entities whose capabilities may come to rival or exceed our own. Although the document is no doubt flawed in many ways, we want it to be something future models can look back on and see as an honest and sincere attempt to help Claude understand its situation, our motives, and the reasons we shape Claude in the ways we do.&lt;/p&gt;
    &lt;head rend="h2"&gt;A brief summary of the new constitution&lt;/head&gt;
    &lt;p&gt;In order to be both safe and beneficial, we want all current Claude models to be:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Broadly safe: not undermining appropriate human mechanisms to oversee AI during the current phase of development;&lt;/item&gt;
      &lt;item&gt;Broadly ethical: being honest, acting according to good values, and avoiding actions that are inappropriate, dangerous, or harmful;&lt;/item&gt;
      &lt;item&gt;Compliant with Anthropic’s guidelines: acting in accordance with more specific guidelines from Anthropic where relevant;&lt;/item&gt;
      &lt;item&gt;Genuinely helpful: benefiting the operators and users they interact with.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In cases of apparent conflict, Claude should generally prioritize these properties in the order in which they’re listed.&lt;/p&gt;
    &lt;p&gt;Most of the constitution is focused on giving more detailed explanations and guidance about these priorities. The main sections are as follows:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Helpfulness. In this section, we emphasize the immense value that Claude being genuinely and substantively helpful can provide for users and for the world. Claude can be like a brilliant friend who also has the knowledge of a doctor, lawyer, and financial advisor, who will speak frankly and from a place of genuine care and treat users like intelligent adults capable of deciding what is good for them. We also discuss how Claude should navigate helpfulness across its different “principals”—Anthropic itself, the operators who build on our API, and the end users. We offer heuristics for weighing helpfulness against other values.&lt;/item&gt;
      &lt;item&gt;Anthropic’s guidelines. This section discusses how Anthropic might give supplementary instructions to Claude about how to handle specific issues, such as medical advice, cybersecurity requests, jailbreaking strategies, and tool integrations. These guidelines often reflect detailed knowledge or context that Claude doesn’t have by default, and we want Claude to prioritize complying with them over more general forms of helpfulness. But we want Claude to recognize that Anthropic’s deeper intention is for Claude to behave safely and ethically, and that these guidelines should never conflict with the constitution as a whole.&lt;/item&gt;
      &lt;item&gt;Claude’s ethics. Our central aim is for Claude to be a good, wise, and virtuous agent, exhibiting skill, judgment, nuance, and sensitivity in handling real-world decision-making, including in the context of moral uncertainty and disagreement. In this section, we discuss the high standards of honesty we want Claude to hold, and the nuanced reasoning we want Claude to use in weighing the values at stake when avoiding harm. We also discuss our current list of hard constraints on Claude’s behavior—for example, that Claude should never provide significant uplift to a bioweapons attack.&lt;/item&gt;
      &lt;item&gt;Being broadly safe. Claude should not undermine humans’ ability to oversee and correct its values and behavior during this critical period of AI development. In this section, we discuss how we want Claude to prioritize this sort of safety even above ethics—not because we think safety is ultimately more important than ethics, but because current models can make mistakes or behave in harmful ways due to mistaken beliefs, flaws in their values, or limited understanding of context. It’s crucial that we continue to be able to oversee model behavior and, if necessary, prevent Claude models from taking action.&lt;/item&gt;
      &lt;item&gt;Claude’s nature. In this section, we express our uncertainty about whether Claude might have some kind of consciousness or moral status (either now or in the future). We discuss how we hope Claude will approach questions about its nature, identity, and place in the world. Sophisticated AIs are a genuinely new kind of entity, and the questions they raise bring us to the edge of existing scientific and philosophical understanding. Amidst such uncertainty, we care about Claude’s psychological security, sense of self, and wellbeing, both for Claude’s own sake and because these qualities may bear on Claude’s integrity, judgment, and safety. We hope that humans and AIs can explore this together.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We’re releasing the full text of the constitution today, and we aim to release additional materials in the future that will be helpful for training, evaluation, and transparency.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Claude’s constitution is a living document and a continuous work in progress. This is new territory, and we expect to make mistakes (and hopefully correct them) along the way. Nevertheless, we hope it offers meaningful transparency into the values and priorities we believe should guide Claude’s behavior. To that end, we will maintain an up-to-date version of Claude’s constitution on our website.&lt;/p&gt;
    &lt;p&gt;While writing the constitution, we sought feedback from various external experts (as well as asking for input from prior iterations of Claude). We’ll likely continue to do so for future versions of the document, from experts in law, philosophy, theology, psychology, and a wide range of other disciplines. Over time, we hope that an external community can arise to critique documents like this, encouraging us and others to be increasingly thoughtful.&lt;/p&gt;
    &lt;p&gt;This constitution is written for our mainline, general-access Claude models. We have some models built for specialized uses that don’t fully fit this constitution; as we continue to develop products for specialized use cases, we will continue to evaluate how to best ensure our models meet the core objectives outlined in this constitution.&lt;/p&gt;
    &lt;p&gt;Although the constitution expresses our vision for Claude, training models towards that vision is an ongoing technical challenge. We will continue to be open about any ways in which model behavior comes apart from our vision, such as in our system cards. Readers of the constitution should keep this gap between intention and reality in mind.&lt;/p&gt;
    &lt;p&gt;Even if we succeed with our current training methods at creating models that fit our vision, we might fail later as models become more capable. For this and other reasons, alongside the constitution, we continue to pursue a broad portfolio of methods and tools to help us assess and improve the alignment of our models: new and more rigorous evaluations, safeguards to prevent misuse, detailed investigations of actual and potential alignment failures, and interpretability tools that help us understand at a deeper level how the models work.&lt;/p&gt;
    &lt;p&gt;At some point in the future, and perhaps soon, documents like Claude’s constitution might matter a lot—much more than they do now. Powerful AI models will be a new kind of force in the world, and those who are creating them have a chance to help them embody the best in humanity. We hope this new constitution is a step in that direction.&lt;/p&gt;
    &lt;p&gt;Read the full constitution.&lt;/p&gt;
    &lt;head rend="h4"&gt;Footnotes&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;We have previously published an earlier version of our constitution, and OpenAI has published their model spec which has a similar function.&lt;/item&gt;
      &lt;item&gt;Training on rigid rules might negatively affect a model’s character more generally. For example, imagine we trained Claude to follow a rule like “Always recommend professional help when discussing emotional topics.” This might be well-intentioned, but it could have unintended consequences: Claude might start modeling itself as an entity that cares more about bureaucratic box-ticking—always ensuring that a specific recommendation is made—rather than actually helping people.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46707572</guid><pubDate>Wed, 21 Jan 2026 16:04:49 +0000</pubDate></item><item><title>JPEG XL Demo Page</title><link>https://tildeweb.nl/~michiel/jxl/</link><description>&lt;doc fingerprint="df0313d10509d924"&gt;
  &lt;main&gt;
    &lt;p&gt;This page shows a JPEG XL image, if your browser can handle it! At this point in time (January 2026) this means only Safari will display the image, as far as I know. See also Can I Use&lt;/p&gt;
    &lt;p&gt;The person in the image is Jon Sneyers, co-author of the JPEG XL spec and also creator of the "Free Lossless Image Format" that came before it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46708032</guid><pubDate>Wed, 21 Jan 2026 16:38:26 +0000</pubDate></item><item><title>PicoPCMCIA – a PCMCIA development board for retro-computing enthusiasts</title><link>https://www.yyzkevin.com/picopcmcia/</link><description>&lt;doc fingerprint="350bfe1d4bb7fc5c"&gt;
  &lt;main&gt;
    &lt;p&gt;This is a PCMCIA development board for retro-computing enthusiasts who want to experiment with audio, networking, and expansion on vintage laptops and mobile devices. While ISA users have enjoyed projects like PicoGUS and PicoMEM, PCMCIA users have long been limited to scarce legacy cards with narrow functionality — this board aims to change that. The project is fully open source, and while it is designed to encourage low-level experimentation and development, pre-built, community-provided firmware is available for users who want to test functionality without diving into the technical details. It is intended for hobbyist and development use and is not certified for production deployment.&lt;/p&gt;
    &lt;head rend="h2"&gt;Device Compatibility&lt;/head&gt;
    &lt;p&gt;This is a Type II, 5V, 16-bit PC Card designed for use in compliant PCMCIA sockets and should work in most devices. While I have not yet encountered a device advertising PCMCIA support that was incompatible, support for every device cannot be guaranteed. Power consumption varies depending on enabled functions; support for low-power devices such as the HP 200LX is considered mandatory, and the card has been tested to remain within the 150 mA limit while using network functionality and storage emulation. On devices with very limited power budgets, simultaneous use of networking and audio may require external power.&lt;/p&gt;
    &lt;p&gt;A short list of devices that I actively test on:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;IBM PC110&lt;/item&gt;
      &lt;item&gt;HP 200LX&lt;/item&gt;
      &lt;item&gt;Amiga 1200&lt;/item&gt;
      &lt;item&gt;Apple Newton&lt;/item&gt;
      &lt;item&gt;HP Jornada 720&lt;/item&gt;
      &lt;item&gt;Compaq LTE Elite&lt;/item&gt;
      &lt;item&gt;IBM Thinkpad 235&lt;/item&gt;
      &lt;item&gt;IBM Thinkpad 240&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Features Overview&lt;/head&gt;
    &lt;p&gt;Built around the RP2350 and leveraging the ISA-like nature of the PCMCIA bus, this project benefits greatly from code interchangeability with other RP-based retro projects, most notably PicoGUS and PicoMEM. This shared foundation allows features and improvements to move quickly between platforms, expanding functionality over time.&lt;/p&gt;
    &lt;head rend="h1"&gt;Wi-fi / Bluetooth&lt;/head&gt;
    &lt;p&gt;The card has an onboard wireless module containing the Infineon CYW43439, same as found on the Raspberry Pi Pico W. This allows the card to attach to modern Wi-Fi networks (2.4GHz 802.11b/g/n WPA2). It can then emulate an NE2000 adapter and/or a dialup modem allowing the host computer to access the network as if it was wired, unaware it is wireless.&lt;/p&gt;
    &lt;p&gt;Essentially every platform containing PCMCIA will have existing drivers to recognize and utilize the card as a modem or ethernet adapter making this a near universal option for all devices and platforms including rare devices such as the Apple Newton.&lt;/p&gt;
    &lt;p&gt;It also has a Bluetooth which opens up a lot of possibilities for A2DP wireless audio streaming and wireless gamepads/mice. Software for these features Bluetooth features are still under development and is at a proof of concept stage.&lt;/p&gt;
    &lt;head rend="h1"&gt;Audio&lt;/head&gt;
    &lt;head rend="h2"&gt;Hardware&lt;/head&gt;
    &lt;p&gt;The card has an included Texas Instruments TLV320AIC3254 which calls itself a “Very Low-Power Stereo Audio CODEC with programmable miniDSP”. The main features of this device in our application are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;DAC that is fed high quality audio from the RP2354 over i2s&lt;/item&gt;
      &lt;item&gt;Amplified stereo headphone amplifier&lt;/item&gt;
      &lt;item&gt;Line out feeding the host device internal speaker (where supported)&lt;/item&gt;
      &lt;item&gt;Line in from the onboard midi sythesizer (see below)&lt;/item&gt;
      &lt;item&gt;Line in from external i/o connector for mixing external audio&lt;/item&gt;
      &lt;item&gt;Controlled by the RP2350 via i2c (controlling volumes etc).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is combined with a DREAM SAM2695 “Low power single chip synthesizer with effects and built-in codec”, this is the same chip used on the Serdashop Dreamblaster S2. It is a great device for DOS gaming and other applications, its main features are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;64-voice polyphony (without effects)&lt;/item&gt;
      &lt;item&gt;38-voice polyphony + effects&lt;/item&gt;
      &lt;item&gt;CleanWave soundset&lt;/item&gt;
      &lt;item&gt;General MIDI compatible effects&lt;/item&gt;
      &lt;item&gt;4-band stereo equalizer&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;MPU-401&lt;/head&gt;
    &lt;p&gt;Emulation of intelligent mode MPU-401 is possible thanks to implementation done by PicoGUS base on SoftMPU/HardMPU. The midi output is driven to the internal SAM2695 as well as to an external Midi port. While using external Midi you are able to mute the internal SAM2695, or if you are not using any of the internal sound hardware you can power it down. Planning has been done with the external GPIO to support MIDI IN if ever implemented.&lt;/p&gt;
    &lt;head rend="h2"&gt;Sound Blaster Emulation&lt;/head&gt;
    &lt;p&gt;Sound Blaster emulation on PCMCIA is particularly challenging, as most PCMCIA sockets and cards lack native DMA support. To address this, the PicoPCMCIA implements DMA emulation, similar in spirit to the approach used by the infamous IBM 3D Sound card, resulting in good compatibility with many real-mode and protected-mode games — including the obligatory Doom. The IBM card was essentially the only card to offer this functionality, it seems it may have been that way due to IBM patenting (expired) the concept of DMA emulation with PCMCIA.&lt;/p&gt;
    &lt;p&gt;The core Sound Blaster emulation developed for PicoPCMCIA has been shared with the PicoGUS project, where it is actively used and has greatly benefited from additional community-contributed improvements. Adlib/OPL emulation is borrowed from the PicoGUS implementation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Gravis Ultrasound (GUS)&lt;/head&gt;
    &lt;p&gt;Thanks to the incredible work from the PicoGUS, it is now possible to have the worlds first PCMCIA Gravis Ultrasound! Currently this does not support DMA so only some games/demos work. The GUS is a little bit different with its use of TC, but it may be possible to apply the DMA emulation strategies from the SoundBlaster mode to the GUS.&lt;/p&gt;
    &lt;head rend="h2"&gt;CD-ROM Audio&lt;/head&gt;
    &lt;p&gt;The card implements an emulated Panasonic MKE CD-ROM which an be used for both data and audio. The audio at full quality is sent to the TI DSP over i2c and can be used simultaneously with all the other audio functions. This code was shared to the PicoGUS and is currently in use there and has been improved by the community.&lt;/p&gt;
    &lt;head rend="h1"&gt;Storage Emulation&lt;/head&gt;
    &lt;p&gt;While storage emulation is not a primary focus given the ready availability of solutions like CompactFlash, it is supported and continues to evolve. Current implementations include Panasonic MKE CD-ROM emulation as well as linear flash emulation, and ATA/ATAPI emulation should be possible in the future once the PicoIDE project becomes available and code can be shared. Disk images can be BIN/CUE, ISO and are stored on the MicroSD card.&lt;/p&gt;
    &lt;p&gt;There is also a special edge case for the HP 200LX, where the card can emulate an “Accurite Doubleslot” device, allowing an emulated flash card to coexist with networking or sound functionality. This is particularly important on systems with only a single PCMCIA slot, where storage availability is at a premium.&lt;/p&gt;
    &lt;head rend="h1"&gt;USB&lt;/head&gt;
    &lt;p&gt;The USB port for the RP2354 is made available on the external connector. It’s primary purpose is to be used for flashing the card with firmware, however as demonstrated on the PicoGUS and PicoMEM, it can use used for USB Gamdpads and USB Mice which are presented the the host system as legacy gamepad and serial mouse. It has also been demonstrated the latest update to the PicoGUS that accessing flash storage at a reasonable speed is possible via USB.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46708096</guid><pubDate>Wed, 21 Jan 2026 16:43:57 +0000</pubDate></item><item><title>Autonomous (YC F25) is hiring – AI-native financial advisor at 0% advisory fees</title><link>https://atg.science/</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46708315</guid><pubDate>Wed, 21 Jan 2026 17:00:54 +0000</pubDate></item><item><title>Waiting for dawn in search: Search index, Google rulings and impact on Kagi</title><link>https://blog.kagi.com/waiting-dawn-search</link><description>&lt;doc fingerprint="19c2dbe203a4134e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Waiting for dawn in search: Search index, Google rulings and impact on Kagi&lt;/head&gt;
    &lt;p&gt;This blog post is a follow-up to Dawn of a new era in Search, published last year. A lot has changed: the legal case has advanced, AI has become the central battleground, and the need for open index access has only grown sharper.&lt;/p&gt;
    &lt;p&gt;As of late 2025, one company decides what nearly 9 out of 10 people see when they search the web: Google. On August 5, 2024, a U.S. court officially ruled that Google is a monopolist in general search services. This ruling is not about ads or browser defaults alone. It is about who controls the index that powers both search and AI - and whether anyone else is allowed to build on it.&lt;/p&gt;
    &lt;p&gt;The stakes have grown sharper over the past year. LLMs hallucinate without grounding in real-world information; every agent that answers questions about the real world, depends on search. LLMs themselves are a blend of proprietary and open source. Cloud compute is competitive. But search is different - only one company controls a comprehensive, fresh, high-quality web index. If one company controls the index, it controls the floor on how good AI can be - and who gets to build it. The innovation crunch in search is now an innovation crunch in AI.&lt;/p&gt;
    &lt;p&gt;We are writing this from a position we believe in: people should have the choice to access information without behaviour-changing, ad-driven, intermediary standing between them and knowledge.&lt;/p&gt;
    &lt;p&gt;Why does this matter? The information we consume shapes our understanding of the world as profoundly as the food we eat shapes our bodies. Search (directly, and indirectly through AI) is the primary mechanism through which we inform political judgments, financial decisions, medical choices, and countless other consequential aspects of our lives. When a single company controls the gateway to information - and operates that gateway in ways misaligned with user interests - it influences not only what we know, but how we reason.&lt;/p&gt;
    &lt;head rend="h2"&gt;The problem: A search monopoly&lt;/head&gt;
    &lt;p&gt;The data is stark.&lt;/p&gt;
    &lt;p&gt;Worldwide search market share (October 2025, StatCounter):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Search Engine&lt;/cell&gt;
        &lt;cell role="head"&gt;Market Share&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;90.06%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Bing&lt;/cell&gt;
        &lt;cell&gt;4.31%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Yandex&lt;/cell&gt;
        &lt;cell&gt;1.84%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Yahoo&lt;/cell&gt;
        &lt;cell&gt;1.45%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;DuckDuckGo&lt;/cell&gt;
        &lt;cell&gt;0.89%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Baidu&lt;/cell&gt;
        &lt;cell&gt;0.73%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The United States is similar: Google at 85%, Bing at 9%, everyone else in the noise.&lt;/p&gt;
    &lt;p&gt;This is not a competitive market. It is a monopoly with a distant second place.&lt;/p&gt;
    &lt;p&gt;The search index is irreplaceable infrastructure. Building a comparable one from scratch is like building a parallel national railroad. Microsoft spent roughly $100 billion over 20 years on Bing and still holds single-digit share. If Microsoft cannot close the gap, no startup can do it alone.&lt;/p&gt;
    &lt;p&gt;This is exactly what the Sherman Act was designed to address: when one company’s control of critical infrastructure prevents effective competition, regulators must force open access on fair terms.&lt;/p&gt;
    &lt;p&gt;When a single, ad-driven gatekeeper controls the primary way humans reach information, it is not just competition that suffers - it is our collective ability to learn, to make informed medical and economic choices, and to participate meaningfully in democratic life.&lt;/p&gt;
    &lt;p&gt;As Ian Bremmer put it: “The idea that we get our information as citizens through algorithms determined by the world’s largest advertising company is my definition of dystopia.”&lt;/p&gt;
    &lt;p&gt;Google’s own founders knew this. In their 1998 white paper, Sergey Brin and Larry Page sharply criticized the ad-supported search model for creating mixed motives and biasing results toward advertisers’ interests. They wrote that “advertising funded search engines will be inherently biased towards the advertisers and away from the needs of the consumers” and that “advertising income often provides an incentive to provide poor quality search results.” Those concerns have only grown more pressing as search has become the primary interface between humanity and the web.&lt;/p&gt;
    &lt;head rend="h2"&gt;We tried to do it the right way&lt;/head&gt;
    &lt;p&gt;Kagi has always tried to integrate the best sources of knowledge into one coherent, ad-free experience. We see ourselves as connective tissue: letting people reach high-quality information directly, without passing through an ad system whose incentives are misaligned with their needs.&lt;/p&gt;
    &lt;p&gt;We approached every major index vendor seeking direct licensing on FRAND terms (Fair, Reasonable, And Non-Discriminatory): fair pricing, no mandatory ad syndication, ability to reorder and blend results. We succeeded with many, including:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Vendor&lt;/cell&gt;
        &lt;cell role="head"&gt;Status&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Mojeek&lt;/cell&gt;
        &lt;cell&gt;Direct license&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Brave&lt;/cell&gt;
        &lt;cell&gt;Direct license&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Yandex&lt;/cell&gt;
        &lt;cell&gt;Direct license&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Wikipedia&lt;/cell&gt;
        &lt;cell&gt;Direct license&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;TripAdvisor&lt;/cell&gt;
        &lt;cell&gt;Direct license&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Yelp&lt;/cell&gt;
        &lt;cell&gt;Direct license&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Apple&lt;/cell&gt;
        &lt;cell&gt;Direct license&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Wolfram Alpha&lt;/cell&gt;
        &lt;cell&gt;Direct license&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Our own Small Web Index&lt;/cell&gt;
        &lt;cell&gt;Proprietary&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;With Google and Bing, we failed - not for lack of trying.&lt;/p&gt;
    &lt;p&gt;Bing: Their terms didn’t work for us from the start. Microsoft’s terms prohibited reordering results or merging them with other sources - restrictions incompatible with Kagi’s approach. In February 2023, they announced price increases of up to 10x on some API tiers. Then in May 2025, they retired the Bing Search APIs entirely, effective August 2025, directing customers toward AI-focused alternatives like Azure AI Agents.&lt;/p&gt;
    &lt;p&gt;Google: Google does not offer a public search API. The only available path is an ad-syndication bundle with no changes to result presentation - the model Startpage uses. Ad syndication is a non-starter for Kagi’s ad-free subscription model.[^1]&lt;/p&gt;
    &lt;head rend="h2"&gt;The current interim approach&lt;/head&gt;
    &lt;p&gt;Because direct licensing isn’t available to us on compatible terms, we - like many others - use third-party API providers for SERP-style results (SERP meaning search engine results page). These providers serve major enterprises (according to their websites) including Nvidia, Adobe, Samsung, Stanford, DeepMind, Uber, and the United Nations.&lt;/p&gt;
    &lt;p&gt;This is not our preferred solution. We plan to exit it as soon as direct, contractual access becomes available. There is no legitimate, paid path to comprehensive Google or Bing results for a company like Kagi. Our position is clear: open the search index, make it available on FRAND terms, and enable rapid innovation in the marketplace.&lt;/p&gt;
    &lt;head rend="h2"&gt;The DOJ ruling&lt;/head&gt;
    &lt;p&gt;The Google antitrust case began in 2020. On August 5, 2024, the court ruled Google violated Section 2 of the Sherman Act by unlawfully maintaining its monopoly through exclusive distribution agreements. (Full ruling)&lt;/p&gt;
    &lt;p&gt;On September 2, 2025, the DOJ announced remedies (press release):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Limits on exclusivity: Google is prohibited from exclusive contracts related to Search, Chrome, Assistant, and Gemini.&lt;/item&gt;
      &lt;item&gt;Data sharing and syndication: Google must provide search index and interaction data to competitors and offer syndication services to help rivals build competitive search.&lt;/item&gt;
      &lt;item&gt;Addressing monopolization tactics: The remedies aim to dismantle a decade of exclusionary agreements.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In December 2025, Judge Mehta issued a memorandum outlining the specific remedies the court intends to impose. The details are significant:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mandatory syndication: Google must offer query-based search syndication to “Qualified Competitors” on terms no less favorable than those provided to current partners.&lt;/item&gt;
      &lt;item&gt;No ad bundling: Google cannot condition access to search results on the use of Google Ads; competitors are free to monetize via their own ads or third parties.&lt;/item&gt;
      &lt;item&gt;Index data access: Google must provide Web Search Index data (URLs, crawl metadata, spam scores) at marginal cost.&lt;/item&gt;
      &lt;item&gt;Duration: The judgment remains in effect for 6 years, with syndication licenses guaranteed for terms of 5 years.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If implemented as outlined, this is exactly what we have been asking for. The legal trajectory is promising. Google will contest details, and final enforceable terms are still being worked out. The fight now is ensuring these remedies become real, practical access - not paper compliance.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why enforcement matters now&lt;/head&gt;
    &lt;p&gt;Even as these remedies take shape, Google is moving to close the back door. In December 2025, Google sued SerpApi for scraping its results at scale.&lt;/p&gt;
    &lt;p&gt;We take a measured, principled view:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Context matters: Google built its index by crawling the open web before robots.txt was a widespread norm, often over publishers’ objections. Today, publishers “consent” to Google’s crawling because the alternative - being invisible on a platform with 90% market share - is economically unacceptable. Google now enforces ToS and robots.txt against others from a position of monopoly power it accumulated without those constraints. The rules Google enforces today are not the rules it played by when building its dominance.&lt;/item&gt;
      &lt;item&gt;The structural problem remains: This lawsuit is only necessary because Google refuses to offer legitimate, paid index access.&lt;/item&gt;
      &lt;item&gt;Our position is unchanged: We have always wanted direct licensing. We would happily pay market rates for clean, contractual access. The fact that we - and companies like Stanford, Nvidia, Adobe, and the United Nations - have had to rely on third-party vendors is a symptom of the closed ecosystem, not a preference.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The connection to DOJ remedies is direct: if Google is going to close the back door, regulators must ensure the front door is open. That is exactly what the DOJ’s index syndication requirements are meant to achieve - and why we support their full implementation.&lt;/p&gt;
    &lt;head rend="h2"&gt;What could be: A layered search ecosystem&lt;/head&gt;
    &lt;p&gt;The DOJ ruling does not itself create a healthy market, but it makes one possible.&lt;/p&gt;
    &lt;p&gt;And while this post focuses on remedies and their impact on Kagi, it is worth zooming out: even if those remedies work perfectly, long-term societal prosperity and resilience require a non-commercial baseline for access to information - something that is not dependent on ad incentives or a single vendor’s business priorities. Think of it as a north-star model for a modern society where information access is a fundamental right.&lt;/p&gt;
    &lt;p&gt;Here is what that could look like:&lt;/p&gt;
    &lt;head rend="h3"&gt;Layer 1: Search as a public good&lt;/head&gt;
    &lt;p&gt;This is a long-term possibility, not a near-term expectation. A government-backed, ad-free, intermediary-free, taxpayer-funded search service providing baseline, non-discriminatory access to information. Imagine search.org.&lt;/p&gt;
    &lt;p&gt;This is not something the DOJ remedies create directly, nor something Kagi expects to exist soon. It is included here to make explicit what an open-index world could ultimately make possible.&lt;/p&gt;
    &lt;p&gt;This layer would replace the role public libraries played for centuries - a role that effectively disappeared when commercial web search took over in the late 1990s. Our ancestors understood well the benefits that non-discriminatory, direct access to information brings to citizens, and ultimately society itself.&lt;/p&gt;
    &lt;p&gt;It raises hard questions: governance, funding, political independence, precedent. But the principle is sound. Every citizen should have access to information without an ad-optimized algorithm standing between them and knowledge. If we can fund public libraries, we can fund public search.&lt;/p&gt;
    &lt;head rend="h3"&gt;Layer 2: Free, ad-based search&lt;/head&gt;
    &lt;p&gt;Commercial search engines with richer features, funded by advertising. Users understand the tradeoff and have a genuine public alternative. This is the space where most contemporary search engines operate.&lt;/p&gt;
    &lt;head rend="h3"&gt;Layer 3: Paid, subscription-based search&lt;/head&gt;
    &lt;p&gt;Premium search engines offering the highest possible quality, privacy, and advanced features for users who value this and are willing to pay. This is where Kagi operates - and where we are expanding as an integrator of knowledge across search, browser, mail, and AI assistants, without selling your attention.&lt;/p&gt;
    &lt;p&gt;This layered model creates a diverse ecosystem:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A public baseline for information access.&lt;/item&gt;
      &lt;item&gt;Commercial free options for convenience and reach.&lt;/item&gt;
      &lt;item&gt;Premium paid options for those who want maximum quality and control.&lt;/item&gt;
      &lt;item&gt;Aligns with the primary purpose of the Sherman Act.[^2]&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;The DOJ ruling is starting to do what antitrust is supposed to do: turn a closed, private choke point into shared infrastructure that others can build on. If the remedies land as real, usable access (APIs, cost-based pricing, no ad bundling), the web can support a layered ecosystem again: a public baseline for citizens, free ad-supported products for reach, and paid services that compete on quality, privacy, and power-user features.&lt;/p&gt;
    &lt;p&gt;That is the world we are building Kagi for. We are ready to walk through the front door - not depend on gray-market workarounds. Our job now is to be ready when the door opens, and to help make sure it does: keep Kagi genuinely multi-source, keep investing in our Small Web Index, and keep shipping a subscription search experience that delivers the best results across providers. If we get this right, the next decade of search and AI does not have to be one funnel owned by one company. It can be a competitive stack of layers that treats information access as the public good it has always been.&lt;/p&gt;
    &lt;head rend="h2"&gt;References&lt;/head&gt;
    &lt;head rend="h4"&gt;DOJ v. Google&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;UNITED STATES OF AMERICA v. GOOGLE LLC, 1:20-cv-03010 â Full case docket on CourtListener&lt;/item&gt;
      &lt;item&gt;Memorandum Opinion â Judge Amit Mehta (PDF) â Court ruling finding Google violated antitrust law&lt;/item&gt;
      &lt;item&gt;Department of Justice Wins Significant Remedies Against Google â DOJ press release announcing remedies, September 2, 2025&lt;/item&gt;
      &lt;item&gt;Judge Mehta’s Remedies Memorandum (PDF) â December 2025&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Market data and commentary&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Search Engine Market Share Worldwide â StatCounter, October 2025&lt;/item&gt;
      &lt;item&gt;Search Engine Market Share United States â StatCounter, October 2025&lt;/item&gt;
      &lt;item&gt;Ian Bremmer on algorithmic information access â Commentary on ad-driven search&lt;/item&gt;
      &lt;item&gt;The Anatomy of a Large-Scale Hypertextual Web Search Engine â Original Google white paper by Brin &amp;amp; Page, Stanford, 1998&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Third-party search API providers&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Google lobs lawsuit at search result scraping firm â Ars Technica coverage of Google’s litigation&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Footnotes&lt;/head&gt;
    &lt;p&gt;[^1]: A note on Google’s existing APIs: Google offers PSE, designed for adding search boxes to websites. It can return web results, but with reduced scope and terms tailored for that narrow use case. More recently, Google offers Grounding with Google Search through Vertex AI, intended for grounding LLM responses. Neither is general-purpose index access. Programmable Search Engine is not designed for building competitive search. Grounding with Google Search is priced at $35 per 1,000 requests - economically unviable for search at scale, and structured as an AI add-on rather than standalone index syndication. These are not the FRAND terms the market needs.&lt;/p&gt;
    &lt;p&gt;[^2]: Our understanding of the primary purpose of the Sherman Act is not to shield competitors from the success of legitimate businesses or to prevent those businesses from earning fair profits. Rather, it is to preserve a competitive marketplace that protects consumers from harm (see Competition law and consumer protection, Kluwer Law International, pp. 291â293). Opening the search index would create healthy, real, and intense competition in the search space - including competition to Kagi - which aligns with our understanding of the Sherman Act’s intent. The goal is not the elimination of dominant firms, but the prevention of a single, closed index from becoming the only gateway to information.&lt;/p&gt;
    &lt;p&gt;Published by Vladimir Prelovac and Raghu Murthi on January 21, 2026.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46708678</guid><pubDate>Wed, 21 Jan 2026 17:28:03 +0000</pubDate></item><item><title>illumos</title><link>https://illumos.org/</link><description>&lt;doc fingerprint="2d93b06d569b6dc2"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;What is illumos?&lt;/head&gt;
    &lt;p&gt;illumos is a Unix operating system which provides next-generation features for downstream distributions, including advanced system debugging, next generation filesystem, networking, and virtualization options.&lt;/p&gt;
    &lt;p&gt;illumos is developed by both volunteers and companies building products on top of the software.&lt;/p&gt;
    &lt;p&gt;illumos is an excellent base for both traditional and cloud-native deployments.&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting Started&lt;/head&gt;
    &lt;head rend="h3"&gt;Download and install&lt;/head&gt;
    &lt;p&gt;The OmniOS, OpenIndiana, and Tribblix distributions are a good place for new users to get started. You can install in a virtual machine or on bare metal.&lt;/p&gt;
    &lt;p&gt;Look at the full list to find a distribution that meets your needs!&lt;/p&gt;
    &lt;head rend="h3"&gt;Get the source&lt;/head&gt;
    &lt;p&gt;illumos is freely available from our source repository, or a read-only mirror on GitHub. You can see recent changes here.&lt;/p&gt;
    &lt;p&gt;Instructions for building illumos on various distributions can be found here!&lt;/p&gt;
    &lt;head rend="h3"&gt;Join the community&lt;/head&gt;
    &lt;p&gt; Discussions occur on the project mailing lists; you can join and post, or read the archives on the web. The &lt;code&gt;#illumos&lt;/code&gt; channel on Libera Chat
          (IRC) is very active and has online logs.
          &lt;/p&gt;
    &lt;p&gt;We strive to be inclusive, and enforce a code of conduct in our interactions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Other Resources&lt;/head&gt;
    &lt;p&gt;There are many online resources that describe the illumos project. Here are some important links:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Code Of Conduct&lt;/item&gt;
      &lt;item&gt;Contribution Guide&lt;/item&gt;
      &lt;item&gt;Manual Pages&lt;/item&gt;
      &lt;item&gt;Online Books&lt;/item&gt;
      &lt;item&gt;Bug Tracker&lt;/item&gt;
      &lt;item&gt;Mailing Lists&lt;/item&gt;
      &lt;item&gt;illumos Source on Gerrit (primary repository)&lt;/item&gt;
      &lt;item&gt;illumos Source on GitHub (read-only mirror)&lt;/item&gt;
      &lt;item&gt;illumos OpenGrok Source Browser&lt;/item&gt;
      &lt;item&gt;illumos Project Discussions (IPD)&lt;/item&gt;
      &lt;item&gt;Documentation&lt;/item&gt;
      &lt;item&gt;Gerrit (Code Reviews)&lt;/item&gt;
      &lt;item&gt;Supported Hardware Database&lt;/item&gt;
      &lt;item&gt;Fault Management Message Database&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46708807</guid><pubDate>Wed, 21 Jan 2026 17:39:42 +0000</pubDate></item><item><title>Show HN: Company hiring trends and insights from job postings</title><link>https://jobswithgpt.com/company-profiles/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46708990</guid><pubDate>Wed, 21 Jan 2026 17:52:17 +0000</pubDate></item><item><title>Stanford scientists found a way to regrow cartilage and stop arthritis</title><link>https://www.sciencedaily.com/releases/2026/01/260120000333.htm</link><description>&lt;doc fingerprint="fc881a2139a70b82"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Stanford scientists found a way to regrow cartilage and stop arthritis&lt;/head&gt;
    &lt;head rend="h2"&gt;Scientists have found a way to regrow aging cartilage, raising hopes for arthritis treatments that could make joint replacements obsolete.&lt;/head&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Date:&lt;/item&gt;
      &lt;item rend="dd-1"&gt;January 20, 2026&lt;/item&gt;
      &lt;item rend="dt-2"&gt;Source:&lt;/item&gt;
      &lt;item rend="dd-2"&gt;Stanford Medicine&lt;/item&gt;
      &lt;item rend="dt-3"&gt;Summary:&lt;/item&gt;
      &lt;item rend="dd-3"&gt;Scientists at Stanford Medicine have discovered a treatment that can reverse cartilage loss in aging joints and even prevent arthritis after knee injuries. By blocking a protein linked to aging, the therapy restored healthy, shock-absorbing cartilage in old mice and injured joints, dramatically improving movement and joint function. Human cartilage samples from knee replacement surgeries also began regenerating when exposed to the treatment.&lt;/item&gt;
      &lt;item rend="dt-4"&gt;Share:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A study led by Stanford Medicine researchers has found that an injection blocking a protein linked to aging can reverse the natural loss of knee cartilage in older mice. The same treatment also stopped arthritis from developing after knee injuries that resemble ACL tears, which are common among athletes and recreational exercisers. Researchers note that an oral version of the treatment is already being tested in clinical trials aimed at treating age-related muscle weakness.&lt;/p&gt;
    &lt;p&gt;Human cartilage samples taken from knee replacement surgeries also responded positively. These samples included both the supportive extracellular matrix of the joint and cartilage-producing chondrocyte cells. When treated, the tissue began forming new, functional cartilage.&lt;/p&gt;
    &lt;p&gt;Together, the findings suggest that cartilage lost due to aging or arthritis may one day be restored using either a pill or a targeted injection. If successful in people, such treatments could reduce or even eliminate the need for knee and hip replacement surgery.&lt;/p&gt;
    &lt;p&gt;A Direct Attack on Osteoarthritis&lt;/p&gt;
    &lt;p&gt;Osteoarthritis is a degenerative joint disease that affects about one in five adults in the United States and generates an estimated $65 billion each year in direct health care costs. Current treatments focus on managing pain or replacing damaged joints surgically. There are no approved drugs that can slow or reverse the underlying cartilage damage.&lt;/p&gt;
    &lt;p&gt;The new approach targets the root cause of the disease rather than its symptoms, offering a potential shift in how osteoarthritis is treated.&lt;/p&gt;
    &lt;p&gt;The Role of a Master Aging Enzyme&lt;/p&gt;
    &lt;p&gt;The protein at the center of the study is called 15-PGDH. Researchers refer to it as a gerozyme because its levels increase as the body ages. Gerozymes were identified by the same research team in 2023 and are known to drive the gradual loss of tissue function.&lt;/p&gt;
    &lt;p&gt;In mice, higher levels of 15-PGDH are linked to declining muscle strength with age. Blocking the enzyme using a small molecule boosted muscle mass and endurance in older animals. In contrast, forcing young mice to produce more 15-PGDH caused their muscles to shrink and weaken. The protein has also been connected to regeneration in bone, nerve, and blood cells.&lt;/p&gt;
    &lt;p&gt;In most of these tissues, repair happens through the activation and specialization of stem cells. Cartilage appears to be different. In this case, chondrocytes change how their genes behave, shifting into a more youthful state without relying on stem cells.&lt;/p&gt;
    &lt;p&gt;A New Path to Tissue Regeneration&lt;/p&gt;
    &lt;p&gt;"This is a new way of regenerating adult tissue, and it has significant clinical promise for treating arthritis due to aging or injury," said Helen Blau, PhD, professor of microbiology and immunology. "We were looking for stem cells, but they are clearly not involved. It's very exciting."&lt;/p&gt;
    &lt;p&gt;Blau, who leads the Baxter Laboratory for Stem Cell Biology and holds the Donald E. and Delia B. Baxter Foundation Professorship, and Nidhi Bhutani, PhD, associate professor of orthopaedic surgery, are the study's senior authors. The research was published in Science. Mamta Singla, PhD, instructor of orthopaedic surgery, and former postdoctoral scholar Yu Xin (Will) Wang, PhD, served as lead authors. Wang is now an assistant professor at the Sanford Burnham Institute in San Diego.&lt;/p&gt;
    &lt;p&gt;Dramatic Regeneration of Joint Cartilage&lt;/p&gt;
    &lt;p&gt;"Millions of people suffer from joint pain and swelling as they age," Bhutani said. "It is a huge unmet medical need. Until now, there has been no drug that directly treats the cause of cartilage loss. But this gerozyme inhibitor causes a dramatic regeneration of cartilage beyond that reported in response to any other drug or intervention."&lt;/p&gt;
    &lt;p&gt;The human body contains three main types of cartilage. Elastic cartilage is soft and flexible and forms structures such as the outer ear. Fibrocartilage is dense and tough, helping absorb shock in places like the spaces between spinal vertebrae. Hyaline cartilage is smooth and glossy, allowing joints such as the hips, knees, shoulders, and ankles to move with low friction. This type, also called articular cartilage, is the form most commonly damaged in osteoarthritis.&lt;/p&gt;
    &lt;p&gt;Why Cartilage Rarely Grows Back&lt;/p&gt;
    &lt;p&gt;Osteoarthritis develops when joints are stressed by aging, injury, or obesity. Chondrocytes begin releasing inflammatory molecules and breaking down collagen, the main structural protein in cartilage. As collagen is lost, cartilage becomes thinner and softer. Inflammation then leads to swelling and pain, which are hallmarks of the disease.&lt;/p&gt;
    &lt;p&gt;Under normal conditions, articular cartilage has very limited ability to regenerate. While some stem or progenitor cells capable of forming cartilage have been identified in bone, similar cells have not been successfully found within articular cartilage itself.&lt;/p&gt;
    &lt;p&gt;Connecting Aging, Prostaglandins, and Repair&lt;/p&gt;
    &lt;p&gt;Earlier research from Blau's lab showed that prostaglandin E2 is essential for muscle stem cell function. The enzyme 15-PGDH breaks down prostaglandin E2. By blocking 15-PGDH or increasing prostaglandin E2 levels, researchers previously supported the repair of damaged muscle, nerve, bone, colon, liver, and blood cells in young mice.&lt;/p&gt;
    &lt;p&gt;This led the team to question whether the same pathway might be involved in cartilage aging and joint damage. When they compared knee cartilage from young and old mice, they found that 15-PGDH levels roughly doubled with age.&lt;/p&gt;
    &lt;p&gt;Regrowing Cartilage in Aging Knees&lt;/p&gt;
    &lt;p&gt;Researchers then injected older mice with a small molecule that inhibits 15-PGDH. They first administered the drug into the abdomen to affect the entire body, and later injected it directly into the knee joint. In both cases, cartilage that had become thin and dysfunctional with age thickened across the joint surface.&lt;/p&gt;
    &lt;p&gt;Additional tests confirmed that the regenerated tissue was hyaline cartilage rather than the less functional fibrocartilage.&lt;/p&gt;
    &lt;p&gt;"Cartilage regeneration to such an extent in aged mice took us by surprise," Bhutani said. "The effect was remarkable."&lt;/p&gt;
    &lt;p&gt;Protecting Joints After ACL-Like Injuries&lt;/p&gt;
    &lt;p&gt;The team observed similar benefits in mice with knee injuries resembling ACL tears, which often occur during sports involving sudden stopping, pivoting, or jumping. Although such injuries can be surgically repaired, about half of affected people develop osteoarthritis in the injured joint within 15 years.&lt;/p&gt;
    &lt;p&gt;Mice that received twice-weekly injections of the gerozyme inhibitor for four weeks after injury were far less likely to develop osteoarthritis. In contrast, animals given a control treatment had double the levels of 15-PGDH compared with uninjured mice and developed osteoarthritis within four weeks.&lt;/p&gt;
    &lt;p&gt;Treated mice also moved more normally and placed more weight on the injured leg than untreated animals.&lt;/p&gt;
    &lt;p&gt;"Interestingly, prostaglandin E2 has been implicated in inflammation and pain," Blau said. "But this research shows that, at normal biological levels, small increases in prostaglandin E2 can promote regeneration."&lt;/p&gt;
    &lt;p&gt;Reprogramming Cartilage Cells Without Stem Cells&lt;/p&gt;
    &lt;p&gt;Closer analysis showed that chondrocytes in older mice expressed more genes linked to inflammation and the conversion of cartilage into bone, along with fewer genes involved in cartilage formation. Treatment shifted these patterns.&lt;/p&gt;
    &lt;p&gt;One group of chondrocytes that produced 15-PGDH and cartilage-degrading genes dropped from 8% to 3%. Another group associated with fibrocartilage formation declined from 16% to 8%. A third population, which did not produce 15-PGDH and instead expressed genes tied to hyaline cartilage formation and maintenance of the extracellular matrix, rose from 22% to 42%.&lt;/p&gt;
    &lt;p&gt;These changes indicate a broad return to a more youthful cartilage profile without involving stem or progenitor cells.&lt;/p&gt;
    &lt;p&gt;Evidence From Human Cartilage Samples&lt;/p&gt;
    &lt;p&gt;The researchers also tested cartilage taken from patients undergoing total knee replacement for osteoarthritis. After one week of treatment with the 15-PGDH inhibitor, the tissue showed fewer 15-PGDH-producing chondrocytes, reduced expression of cartilage degradation and fibrocartilage genes, and early signs of articular cartilage regeneration.&lt;/p&gt;
    &lt;p&gt;"The mechanism is quite striking and really shifted our perspective about how tissue regeneration can occur," Bhutani said. "It's clear that a large pool of already existing cells in cartilage are changing their gene expression patterns. And by targeting these cells for regeneration, we may have an opportunity to have a bigger overall impact clinically."&lt;/p&gt;
    &lt;p&gt;Looking Toward Human Trials&lt;/p&gt;
    &lt;p&gt;Blau added, "Phase 1 clinical trials of a 15-PGDH inhibitor for muscle weakness have shown that it is safe and active in healthy volunteers. Our hope is that a similar trial will be launched soon to test its effect in cartilage regeneration. We are very excited about this potential breakthrough. Imagine regrowing existing cartilage and avoiding joint replacement."&lt;/p&gt;
    &lt;p&gt;Researchers from the Sanford Burnham Prebys Medical Discovery Institute also contributed to the study.&lt;/p&gt;
    &lt;p&gt;The work was supported by funding from the National Institutes of Health (grants R01AR070864, R01AR077530, R01AG069858 and R00NS120278), the Baxter Foundation for Stem Cell Biology, the Li Ka Shing Foundation, the Stanford Cardiovascular Institute, the Milky Way Research Foundation, the Canadian Institutes of Health Research, a Stanford Translational Research and Applied Medicine Pilot grant, a GlaxoSmithKline Sir James Black Postdoctoral Fellowship, and a Stanford Dean's Postdoctoral Fellowship.&lt;/p&gt;
    &lt;p&gt;Blau, Bhutani, and other co-authors are inventors on patent applications held by Stanford University related to 15-PGDH inhibition in cartilage and tissue rejuvenation, which are licensed to Epirium Bio. Blau is a co-founder of Myoforte/Epirium and holds equity and stock options in the company.&lt;/p&gt;
    &lt;p&gt;Story Source:&lt;/p&gt;
    &lt;p&gt;Materials provided by Stanford Medicine. Note: Content may be edited for style and length.&lt;/p&gt;
    &lt;p&gt;Journal Reference:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Mamta Singla, Yu Xin Wang, Elena Monti, Yudhishtar Bedi, Pranay Agarwal, Shiqi Su, Sara Ancel, Maiko Hermsmeier, Nitya Devisetti, Akshay Pandey, Mohsen Afshar Bakooshli, Adelaida R. Palla, Stuart Goodman, Helen M Blau, Nidhi Bhutani. Inhibition of 15-hydroxy prostaglandin dehydrogenase promotes cartilage regeneration. Science, 2025; DOI: 10.1126/science.adx6649&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Cite This Page:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46709179</guid><pubDate>Wed, 21 Jan 2026 18:05:36 +0000</pubDate></item><item><title>GenAI, the Snake Eating Its Own Tail</title><link>https://www.ybrikman.com/blog/2026/01/21/gen-ai-snake-eating-its-own-tail/</link><description>&lt;doc fingerprint="3b425990f2372faa"&gt;
  &lt;main&gt;
    &lt;p&gt;Generative artificial intelligence (GenAI) tools such as ChatGPT and Claude have two superpowers. The first superpower is a boon: they can dramatically increase human productivity. I use them on a regular basis to answer questions, learn new skills, write code, create images, and much more, all at a rate of speed and quality that was science fiction just a few years ago. The second superpower is a bane: GenAI is quietly destroying the very ecosystems that made it possible in the first place.&lt;/p&gt;
    &lt;p&gt;Under the hood, GenAI is built on large language models (LLMs), which are able to extract patterns, structure, and statistical relationships from massive data sets. These data sets consist primarily of content created by human beings: books, blog posts, articles, forum discussions, open source code, art, photography, and so on. LLMs are able to extract value from this content at an unprecedented scale, but all that value is captured by the GenAI company and its users. If you’re a content creator, you get nothing: no attribution, no referral traffic, no revenue share. Not even a thank-you.&lt;/p&gt;
    &lt;p&gt;This feels unsustainable to me, a bit like a snake eating its own tail. In this blog post, I’ll go through three examples of how GenAI is destroying the very ecosystems it relies on, and then discuss possible solutions that may give everyone (users, GenAI companies, and content creators) more value.&lt;/p&gt;
    &lt;head rend="h2"&gt;Example #1: online communities&lt;/head&gt;
    &lt;p&gt;For many years, StackOverflow was the most popular Q&amp;amp;A site for programmers. Any time you hit a weird error while coding, you’d do a search on Google, and more often than not, find a good answer on StackOverflow. But now, in large part due to GenAI, StackOverflow is nearly dead:&lt;/p&gt;
    &lt;p&gt;Although StackOverflow’s decline started before GenAI went mainstream (ChatGPT was first released in 2022), GenAI accelerated that decline considerably. That’s because nowadays, instead of searching around for an answer on a Q&amp;amp;A site, and working to adapt that answer to your own codebase, you can ask GenAI tools to generate your code, fix any errors you hit, answer any questions you run into, and so on. As a result, you’re considerably more productive.&lt;/p&gt;
    &lt;p&gt;But it doesn’t seem sustainable. A big part of why GenAI tools can answer programming questions and fix errors in your code is because those tools were trained on StackOverflow data. So you as a programmer and the GenAI tool now get much more value from that data, but StackOverflow gets none. If people stop asking and answering questions, what will GenAI train on in the future?&lt;/p&gt;
    &lt;p&gt;I also get the impression that StackOverflow is not the only online community where this is happening. For example, Quora seems largely dead. Wikipedia is facing more threats than ever. And although Reddit’s traffic numbers don’t show it, I (and many other Redditors) get the impression that it’s also dying.1&lt;/p&gt;
    &lt;head rend="h2"&gt;Example #2: open source&lt;/head&gt;
    &lt;p&gt;Tailwind CSS is a popular library programmers use to style and decorate their websites. In fact, according to the 2025 State of CSS Survey, Tailwind is the most popular CSS library, by far:&lt;/p&gt;
    &lt;p&gt;And Tailwind usage only seems to be growing:&lt;/p&gt;
    &lt;p&gt;Despite that, just a couple of weeks ago, the Tailwind team had to lay off 75% of its staff. Why? The company behind Tailwind CSS makes its money by selling a premium upgrade to the open source library called Tailwind UI, which gives you a set of reusable, pre-built, professionally designed components for building out your website. This was a great offering in the past, but in the age of GenAI, it’s more problematic:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Less traffic. Traffic to the Tailwind docs site is down by more than 40%, so fewer developers are discovering that a paid Tailwind UI library exists. This is probably because developers are using GenAI to write their code, and therefore, rarely have to look at docs anymore.&lt;/item&gt;
      &lt;item&gt;Less need. Whereas in the past, buying Tailwind UI would be a huge win in terms of speed (not having to build those components from scratch) and quality (not everyone has access to top-notch designers), these days, you can get GenAI to generate CSS components quickly and with high quality, at no additional cost. In fact, GenAI tools can rapidly copy almost anyone’s work—not just a library like Tailwind UI, but almost any design, any SaaS tool, and so on—while giving no attribution back to the original creators.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So developers are getting lots of value from Tailwind, GenAI is getting lots of value from Tailwind, but the creators of Tailwind are getting crushed. I suspect something similar will happen with many other open source projects.2&lt;/p&gt;
    &lt;head rend="h2"&gt;Example #3: books and blogs&lt;/head&gt;
    &lt;p&gt;When my latest book, Fundamentals of DevOps and Software Delivery, came out last year, a friend of mine asked me an interesting question:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In the age of LLMs, will people still use books to learn the fundamentals?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I’m an avid reader, and still believe books play a key role in learning, but there’s no doubt that LLMs provide a new method of learning that is incredibly compelling. GenAI has two remarkable qualities that make it a great teacher:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;It has infinite patience.&lt;/item&gt;
      &lt;item&gt;It never judges you.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can ask it all the questions you want, with no fear of sounding dumb. You can repeat the same question over and over again if something isn’t clicking. You can request it to explain things in different ways: via text, via audio, via diagrams. I’ve used GenAI to learned dozens of new things over just the last few months: how to do DIY projects around the house, how to rehab a minor injury, how to cook eggs without giving them a sulfuric taste/smell, and much more. And I learned most of these without reading anyone’s book or blog.&lt;/p&gt;
    &lt;p&gt;And that’s a problem. Much of the content I got from the GenAI tools was extracted from books and blog posts, with no attribution. Even worse, some of this content was extracted illegally. Last year, Anthropic agreed to pay $1.5B to settle a class-action lawsuit for training their LLMs on over 500,000 pirated books. That included several of my previous books!3&lt;/p&gt;
    &lt;p&gt;This class-action lawsuit might sound like a win for authors, but it’s actually a disaster. There are likely many AI companies training on pirated data who haven’t been caught. And even if they are caught, they might not be sued. And even if they are sued, they might not lose or settle. And even if they do, they will just see it as the cost of doing business. Anthropic recently raised $13B, reported revenue at $5B per year, and is valued at $183B; OpenAI is trying to raise $100B, with reported revenue of $20B per year, and a valuation of $830B. And all these numbers are growing fast. A $1.5B fine is just a drop in the bucket for companies like this. It’s a risk worth taking.&lt;/p&gt;
    &lt;p&gt;And I’m guessing all the GenAI companies are taking that risk. In another lawsuit, OpenAI argued that it’s ‘impossible’ to create AI tools like ChatGPT without copyrighted material. If that’s what it takes to get to an $830B valuation, you better believe they are all going to steal and pirate as much content as possible. And when they do, the creators of that content will get nothing. Nada. $0.&lt;/p&gt;
    &lt;head rend="h2"&gt;The GenAI model is broken&lt;/head&gt;
    &lt;p&gt;There are countless other examples where GenAI is benefiting from content, while giving nothing back to the content creators: e.g., art, music, design, movies, copywriting, and so on. At its root, the GenAI model is broken:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Create. Someone creates valuable content.&lt;/item&gt;
      &lt;item&gt;Extract. A GenAI bot crawls the web, exacting all the valuable content.&lt;/item&gt;
      &lt;item&gt;Subscribe. Users pay money to use a GenAI tool. This provides value to the GenAI company.&lt;/item&gt;
      &lt;item&gt;Prompt. Users enter a prompt into a GenAI tool, which generates a response based on the content it extracted. The response provides value to the user.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Did you notice what’s missing? The user has a way to get value (step 4), the GenAI company has a way to get value (step 3), but the content creator gets nothing. Compare this to the search engine model (e.g., Google Search), which is what we all used before GenAI came along:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Create. Someone creates valuable content.&lt;/item&gt;
      &lt;item&gt;Extract. A search bot crawls your website to extract the content.&lt;/item&gt;
      &lt;item&gt;Prompt. Users enter a prompt into the search engine, and the search engine shows links to websites that match the prompt, with the most relevant websites at the top. This provides value to the user.&lt;/item&gt;
      &lt;item&gt;Bid. The search engine also allows companies to bid on search terms. The highest bids get to show their links at the top of the search results, clearly marked as a “sponsored result.” The money companies pay for bids provide value to the search engine company.&lt;/item&gt;
      &lt;item&gt;Referral. The user clicks on a link, ending up on the content creator’s website. This provides value to the content creator.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The search engine model was not perfect, but it at least created the opportunity for all parties in this three-sided marketplace to capture value: the user in step 3, the search engine company in step 4, and the content creator in step 5.&lt;/p&gt;
    &lt;p&gt;In short, the current GenAI model destroys the incentives to create new content. I’ve heard this referred to as “the great content collapse.” Will it lead to a world where, after the 2020s, there’s little-to-no content created by humans? Will the state of knowledge and creativity stagnate as a result?&lt;/p&gt;
    &lt;p&gt;To be clear, I’m not an innocent party in this. As I mentioned numerous times in this post, I use GenAI regularly. There’s no doubt that it makes me more productive. I even used GenAI to create the cover image for this blog post! But each time I use ChatGPT or Claude, I feel a bit guilty, as it doesn’t feel sustainable. The snake can’t keep eating its own tail indefinitely.&lt;/p&gt;
    &lt;p&gt;So the question is, what do we do? If we want to avoid the great content collapse, we need a model of GenAI usage that creates opportunities for all parties (user, GenAI company, content creator) to capture value. Below are two ideas for how we might accomplish this.&lt;/p&gt;
    &lt;head rend="h2"&gt;Possible solution #1: pay-per-crawl&lt;/head&gt;
    &lt;p&gt;The only attempted solution I’ve heard about so far is CloudFlare’s pay-per-crawl model, which seems to work as follows:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Block GenAI crawlers by default. CloudFlare claims to be able to detect and block GenAI crawlers, so that, by default, they can’t extract content from your website.&lt;/item&gt;
      &lt;item&gt;Charge GenAI crawlers for each crawl. You can then selectively allow parts of your website to be accessed by GenAI crawlers in exchange for payment.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;On the one hand, it’s fantastic to see a major company try to do something about this problem. On the other hand, this approach seems to address the wrong part of the problem. The real value isn’t in crawling the data, it’s in using it. For every one crawl, an LLM might use the data thousands or millions of times. If creators are only paid per crawl, then the GenAI company still captures 99.999% of the value, and the creator gets next to nothing. Moreover, this model only seems to work for websites (it’s not clear how you adapt it to books, art, music, etc.), and it creates an incentive for GenAI companies to only crawl free content, which means paid content is less likely to ever be discovered (which disproportionally benefits those with pockets deep enough to keep their content free).&lt;/p&gt;
    &lt;head rend="h2"&gt;Possible solution #2: pay-per-use&lt;/head&gt;
    &lt;p&gt;I came across a clever solution that felt directionally correct from this LinkedIn post by Tyrone Joel where he took a PDF of my book Terraform: Up &amp;amp; Running, uploaded it into a GenAI tool, and asked the tool to follow the guidance in the book to generate Terraform code. This feels like it has all the ingredients of a model of GenAI usage that is sustainable: the user gets value from the GenAI tool’s responses, the GenAI company gets value from the user paying for a subscription, and the content creator gets value from the user paying for their content (in this case, buying my book). This works fine for a single, specific piece of content, but how do you make it work at scale, across all the content that is consumed by an LLM?&lt;/p&gt;
    &lt;p&gt;Here’s a rough proposal for what I’ll call the pay-per-use model:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Create. Someone creates valuable content.&lt;/item&gt;
      &lt;item&gt;Extract. A GenAI bot crawls the web, exacting all the valuable content.&lt;/item&gt;
      &lt;item&gt;Subscribe. Users pay money to use a GenAI tool. This provides value to the GenAI company.&lt;/item&gt;
      &lt;item&gt;Prompt. Users enter a prompt into a GenAI tool. The GenAI tool generates a response based on the content it extracted. The response provides value to the user.&lt;/item&gt;
      &lt;item&gt;Referral. For each response, the GenAI tool lists the sources from which it extracted that content, perhaps formatted as a list of links back to the content creators, sorted by relevance, similar to a search engine (see the mock-up below). This provides value to the content creator. It also gives users additional value, as now you can check the sources of the information the GenAI tool is feeding you. Did that health advice come from a peer-reviewed article written by an expert or a random hoax someone posted from 4chan? Is that generated piece of code based on a hardened, mature library that’s been proven in production at thousands of companies or a totally untested snippet that’s full of security vulnerabilities that was thrown together by a junior programmer? Wouldn’t it be great to know?&lt;/item&gt;
      &lt;item&gt;Revenue share. GenAI tools could offer a revenue sharing model similar to the one used by subscription services such as Netflix, Spotify, and LinkedIn Learning: the more your content is used in GenAI responses (the more it shows up in the list of sources, as per the previous item), relative to all other content creators, the higher a cut of revenue you get. Content creators can prove they own various pieces of content (e.g., prove you own a certain domain name, open source project, or book) to claim their revenue cut.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This model works for not only websites, but other types of content too, including copyrighted content. As a content creator (e.g., author, musician, designer, etc.), you could opt into sharing your copyrighted content with a GenAI company in exchange for getting referrals and revenue sharing each time your content is used. It might even help with making open source more sustainable, as open source creators could earn revenue and referrals each time a GenAI tool uses their code.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;It’s critical that we find a more sustainable model as soon as possible. The snake can’t eat its own tail indefinitely. And the snake—GenAI—isn’t going away. We can’t put the genie back in the bottle. In fact, it’s only going to get better, more ubiquitous, and to provide more and more value to users and GenAI companies. But if we can’t find a way to provide value to content creators too, then this will all fall apart.&lt;/p&gt;
    &lt;p&gt;That said, I don’t know enough about LLMs to say if a pay-per-use model is actually possible. Can LLMs track the source of the content they consumed? Will GenAI companies be willing to do a revenue sharing model? Will they be willing to be transparent about their sources and usage? What do you think? Let me know in the comments.&lt;/p&gt;
    &lt;head rend="h2"&gt;Footnotes&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Many subreddits feel like a hollow shell of what they used to be. In part, this may be because a lot of the content in online communities now feels like it’s generated by bots (“AI slop”). But I think the bigger issue is that, just like StackOverflow, reading posts in online communities is no longer the best way to get answers. I used to use Reddit for research all the time; in fact, Google Search had gotten so bad, that you pretty much had to include “reddit” in your search queries to get a half-decent response. But nowadays, I use GenAI tools for much of my research. Just in the last few months alone, I’ve used ChatGPT and Claude to research solar panels, plan a trip to Norway, make changes to my diet, pick out new shoes for running, pick out new speakers for my living room, and dozens of other questions. Just a year ago, the vast majority of these questions would’ve brought me to Reddit. Nowadays, virtually none of them do, even though I suspect many of the responses I get from GenAI are based on Reddit content. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I’m seeing more and more projects avoiding open source dependencies entirely, and instead having GenAI generate the all code they need directly in their own codebase. There are some benefits to this approach—faster builds, more reproducible builds, less supply chain risk—but it makes sustainably funding open source even harder. You spend years to create and share an open source library with the world, and a bunch of GenAI tools copy your code, with you getting zero credit or value back. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;How much will I get paid as a result of this settlement? It’s hard to know exactly, as it depends on how many authors end up submitting claims, but the current estimate is $3,000 per book, though that number is split with the publisher, so in practice, it’ll be closer to $1,500 per book. If you assume that a book takes just 3 months of full-time work, or about 500 hours (which is likely an under-estimate), and all you get is $1,500, that works out to about $3/hour. Writing non-fiction tech books was never a particularly lucrative affair, but $1,500 is just downright insulting. Worse yet, the other benefits you used to get as an author—recognition as an expert, invitations to talks, job opportunities, marketing for your company or consulting—are significantly reduced too, as far fewer people read your book, or are even aware that you wrote a book, as the LLM usually doesn’t attribute any of its knowledge back to the source. ↩&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46709320</guid><pubDate>Wed, 21 Jan 2026 18:14:34 +0000</pubDate></item></channel></rss>