<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 05 Feb 2026 18:34:59 +0000</lastBuildDate><item><title>Wirth's Revenge</title><link>https://jmoiron.net/blog/wirths-revenge/</link><description>&lt;doc fingerprint="abcad51e692325f9"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Wirth's Revenge&lt;/head&gt;
    &lt;p&gt;In 1995, Turing laureate Niklaus Wirth wrote an essay called A Plea for Lean Software in which he mostly gripes about the state of software at the time. Among these gripes is this claim which Wirth attributes to his colleague Martin Reiser1, though it's become to be known as Wirth's Law:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Software is getting slower more rapidly than hardware becomes faster.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Doing his best grandpa Simpson impersonation, Wirth complains:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;About 25 years ago, an interactive text editor could be designed with as little as 8,000 bytes ofstorage. (Modern program editors request 100 times that much!) An operating system had to manage with 8,000 bytes, and a compiler had to fit into 32 Kbytes, whereas their modern descendants require megabytes. Has all this inflated software become any faster? On the contrary. Were it not for a thousand times faster hardware, modern software would be utterly unusable.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Aside from the numbers involved here, which must sound utterly preposterous to the average modern reader, there's a lot to relate to. My 25 year career in software, all of which happened after 1995, was in many ways a story in two parts about Wirth's Law, an action and a reaction.&lt;/p&gt;
    &lt;p&gt;Personally, I disagree with Wirth's conclusion that nothing of value had been gained for the loss in efficiency. When he laments "the advent of windows, cut-and-paste strategies, and pop-up menus, [..] the replacement of meaningful command words by pretty icons", he is not properly appreciating the value these features had in making computing accessible to more people, and is focusing too much on their runtime cost. Programmers are often too quick to judge software on its technical merits rather than it's social ones.&lt;/p&gt;
    &lt;p&gt;Wirth passed away 2 years ago, but he was a giant in the field of Computer Science and a huge inspiration to me and to many of my other inspirations. In many ways, my focus on simplicity and my own system design sensibilities find their genesis with him.&lt;/p&gt;
    &lt;p&gt;Wirth's law is so self evidently true that it's been a topic of continuous investigation and rediscovery.&lt;/p&gt;
    &lt;p&gt;A notable example of this was Dan Luu's great post on input lag back in 2017. He felt that input latency was getting worse over time, so he got a high speed camera and measured the delay between pressing a key and the letter appearing on screen across a lot of different hardware. The lowest latency computer was the Apple 2e from 1983.&lt;/p&gt;
    &lt;p&gt;Input latency has gone up since 1983 because there is a lot more software involved in the pipeline for handling input. The kind of hardware interrupt based input handling the Apple 2e had is not flexible enough to meet modern requirements, so this additional complexity buys us a lot of value... but it's certainly not free, and if you're not careful, one of the costs is latency.&lt;/p&gt;
    &lt;p&gt;Luu goes on to write a lot about complexity and simplicity, and makes an interesting observation: the modern systems that fix the latency issue mostly do so not through removing complexity but by adding it. There was a lot of talk about complexity and simplicity at the time, because a huge number of software developers were working on another great tradeoff that had been made, this time in the datacenter: the widespread adoption of cloud computing.&lt;/p&gt;
    &lt;p&gt;In 1995, when Wirth wrote his essay, if you wanted to run a new internet company, you could just get a computer and run with it. Amazon didn't launch until July of that year, but it was famously started out of Jeff Bezos' garage.&lt;/p&gt;
    &lt;p&gt;The requirements for an internet company were simpler back then. The web wasn't some ubiquitous technology with total population penetration. There were only about 16 million people using it at the time; more people had an SNES than used the internet. Slashdot didn't exist. There was no real expectation of 5 9's 24/7/365 availability, and no opportunity to "go viral."&lt;/p&gt;
    &lt;p&gt;By 2010, this had changed. Sure, I guess you could still get Slashdotted then, but more relevantly, Twitter and Facebook could drive tons of traffic to you overnight. The number of internet users had ballooned to 2 billion.&lt;/p&gt;
    &lt;p&gt;To run your company's software, you could build your own datacenter, but this is a complicated task requiring a lot of expertise; you need land, permits, contractors, etc. I wouldn't even know where to start.&lt;/p&gt;
    &lt;p&gt;You could buy an existing datacenter, but you'd still need to manage power, backup generators/batteries, air conditioning, fire suppression, racks, maintenance, networking. Again, decades in the software industry, and I can barely build a competent list of requirements. It's a big investment, and there's a lot of opex.&lt;/p&gt;
    &lt;p&gt;You could rent a rack in a colo and focus on your compute needs, but those needs could change in an instant. If you plan out costs for 100,000 users and you never gain traction, you've overspent and are burning cash on pointless hardware you could be using to develop your product. If you get hit with a tidal wave of interest, you could be showing people the fail whale for years or miss your opportunity for success entirely.&lt;/p&gt;
    &lt;p&gt;Cloud computing was the era's answer. By 2010, Amazon was out of Jeff's basement and running its own massive datacenters for their online operations. As Steve Yegge wrote in 2010, Bezos had distributed an influential API mandate in 2002 requiring all internal teams to make their services available via an API. By 2006, they had already built a platform that they felt they could release to paying customers in the form of EC2 and S3. AWS let you rent capacity in Amazon's datacenter through a web interface or via direct API calls, billed on granular timescales.&lt;/p&gt;
    &lt;p&gt;Each step in this pipeline imparts additional cost, but they're all pretty valuable, especially the last step. There are even more steps in that pipeline today, with fully managed services like RDS and IAM which abstract the management of software and Lambda which even further abstract your hardware requirements and allow you to scale (and pay) purely on utilization.&lt;/p&gt;
    &lt;p&gt;Even though the cost to run software had gone up, the improved accessibility of cloud platforms and the reduction of risky capex led to an explosion in web software. All the while, hardware was racing ahead, making the rented capacity more powerful per unit cost and reducing the per-user cost.&lt;/p&gt;
    &lt;p&gt;Unfortunately, not every "Wirth tradeoff" is sound engineering.&lt;/p&gt;
    &lt;p&gt;Early in my career, I was working at a newspaper publisher owned by Cond√© Nast. I was the lead engineer on one of the company's more forward looking development projects, a Django application that managed local sports results data across dozens of regional newspapers. The application provided a single source of truth for very different users and use cases:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reporters could add box scores and statistics on the go&lt;/item&gt;
      &lt;item&gt;Their websites could display results, league tables, etc.&lt;/item&gt;
      &lt;item&gt;The backend could publish feeds to syndicate into the print editions of each newspaper&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The print syndication system involved writing some pretty gnarly templates in order to generate feeds that could be understood by their newspaper printing systems. After a while, we noticed a problem. These templates were taking minutes to render and setting the database on fire every night.&lt;/p&gt;
    &lt;p&gt;If you've been around the block in software, you might already know the issue. The templates were using an ORM which dynamically loaded foreign key fields on attribute access, so innocent looking loops were doing one database query per iteration. These were complex templates with many nested loops: they were sending hundreds of thousands of database queries per render, many of them just the same query over and over again from a different loop in a different part of the template.&lt;/p&gt;
    &lt;p&gt;We could fix some of the terrible performance by pre-loading those fields with a join, but we had a lot of templates, and they were complex enough and the database large enough that this wasn't a realistic path to success. As Dan Luu concludes in his study on latency, the solution that worked required adding more complexity in the form of a smart caching layer.&lt;/p&gt;
    &lt;p&gt;Although we didn't know we were making it when we started the template project, this was a "bad" Wirth tradeoff. It still had utility: instead of having to manage what data might be needed in what template carefully, we could grab a list of top level objects and let the ORM fetch the rest of the data we needed on the fly.&lt;/p&gt;
    &lt;p&gt;The project started up quickly, but even at a pretty low scale of complexity, it became impossible to execute successfully. Before we realized what the problem was, we were using the convenience of these auto-loaded fields without understanding their true cost, and the software we built was a wasteful monstrosity as a result.&lt;/p&gt;
    &lt;p&gt;I see the same thing happening now but at broader scale with LLMs, and I feel myself sympathizing more and more with Wirth's cane shaking wrath.&lt;/p&gt;
    &lt;p&gt;Programming is the act of getting a computer to do something for you. Many people are discovering that for the first time, thanks to LLMs, they can ask a computer to do something for them, and it will actually go and do it. However, limiting yourself to programming only through this approach poses some problems.&lt;/p&gt;
    &lt;p&gt;While they might not be the unbound ecological disaster that many of their detractors claim they are, LLMs are still intensely computationally expensive. You can ask an AI what &lt;code&gt;2 * 3&lt;/code&gt; is and for the low price of several seconds of waiting, a few milliliters of water and enough power to watch 5% of a TikTok video on a television, it will tell you. But the computer you have in front of you can perform this calculation a billion times per second.&lt;/p&gt;
    &lt;p&gt;If the problem of my accidental database denial of service syndication feed was down to ignorance over the costs of ORM usage, it's pretty obvious that a similar kind of ignorance can lead to enormous unintended costs once we start integrating LLMs into our automation.&lt;/p&gt;
    &lt;p&gt;I've seen a few instances of this out in the wild that lead me to believe that this trap might be particularly tricky to avoid. Despite the capacity for LLMs to educate, or simulate education, or at least point you towards related materials some of which may be real, that's not how laypeople use them.&lt;/p&gt;
    &lt;p&gt;They present the LLM with a problem and ask it solve that problem.&lt;/p&gt;
    &lt;p&gt;One example of this is from myself, as this is how I used LLMs in my first go, too. I had a dump of recipes from a great but sadly unmaintained recipe site that I wanted to import into a self-hosted recipe management app.&lt;/p&gt;
    &lt;p&gt;I thought "Well, this sounds tedious, let me ask an LLM to do this." So I pointed a local LLM to the specification for the destination format, and asked it to convert the files. It converted one file every 10 minutes, inaccurately and without proper formatting. It was slow and it produced trash.&lt;/p&gt;
    &lt;p&gt;When you see engineers heap praise on programming agents, this isn't how they are using them. You don't ask the LLM to perform a repetitive and precise task, you ask it to build a script that performs that task. Except in rare cases, this script does not itself use LLMs.&lt;/p&gt;
    &lt;p&gt;Ironically, if you have the foresight to describe this problem to a major AI model and ask it how you should use an AI to solve it, this is exactly what it will tell you to do.&lt;/p&gt;
    &lt;p&gt;This approach subtly different from the way you might use LLMs for many other tasks, but it's crucial to getting results that reliably get a computer to do something for you. LLMs don't do reliable, they don't do repeatable. Building a program allows you to iterate on a deterministic solution with a stable source of truth, and you come away with an artifact that may or not be useless, but which actually works, and in my case converts 70 files/sec.&lt;/p&gt;
    &lt;p&gt;Another example I came across was this twitter thread by BenjaminDEKR, which I saw being ridiculed on bsky. He asked his personal agent to remind him to get milk, and this led the agent to repeatedly ask Opus if it was daytime yet. Along with the context from his heartbeat file, this resulted in a $0.75 charge for each heartbeat, costing him almost $20 during a single night's sleep.&lt;/p&gt;
    &lt;p&gt;What was the solution?&lt;/p&gt;
    &lt;p&gt;Maybe you decide that for your purposes 00:00 is night and 08:00 is day and use a basic local &lt;code&gt;gettimeofday&lt;/code&gt; call to determine which span you're in. Maybe you're unsatisfied with anything other than astronomical day/night and can generate a sunrise/sunset table for the year using NOAA's unmaintained solar calculator to dynamically produce your day/night spans?&lt;/p&gt;
    &lt;p&gt;You could do these things, but not if asking the LLM to solve problems is your problem solving approach. If asking an LLM is the only way you know how to solve problems, then you optimize the question asking by reducing heartbeat frequency and running on a cheaper model. Problem solved!&lt;/p&gt;
    &lt;p&gt;The overall concern is that having a magic box that gives you the answers ends up being a thought terminating solution to any problem.&lt;/p&gt;
    &lt;p&gt;When I wrote about the ecological impacts of AI, one of the non-ecological impacts I cited was the possibility that "AI erodes human skill." A recent release by research fellows at Anthropic, "How AI Impacts Skill Formation", suggests this fear isn't unfounded:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We find that AI use impairs conceptual understanding, code reading, and debugging abilities, without delivering significant efficiency gains on average.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;A few weeks ago, I was at a family gathering watching some of the kids go through a huge backlog of red envelopes that their grandparents had saved for them over various missed holidays. They were pulling out all of the cash, at which point they were going to tally it all up and split it evenly.&lt;/p&gt;
    &lt;p&gt;When the adults challenged them to come up with better counting strategies, one of them suggested they could throw all of the money on the floor, take a picture, and ask ChatGPT to tally it all.&lt;/p&gt;
    &lt;p&gt;The instincts are for people to get the AI to do work for them, not to learn from the AI how to do the work themselves.&lt;/p&gt;
    &lt;p&gt;Wirth's law posits that software can erase gains faster than hardware can make them, but I'm afraid the reality is much worse than that.&lt;/p&gt;
    &lt;p&gt;If you've studied computer science, you might have heard of a function called Busy Beaver. The name is unfortunately silly, but it's a fairly important thought experiment in computability. &lt;code&gt;BB(N)&lt;/code&gt; is defined as the maximum number of steps a terminating turing machine with N states can run.&lt;/p&gt;
    &lt;p&gt;This function is known to be noncomputable, because any algorithm that could compute it would be able to solve the halting problem, which is known to be undecidable. &lt;code&gt;BB(1..3)&lt;/code&gt; were known in the 1960s to be 1, 6, and 21. In a pleasant bit of symmetry with Dan Luu's experiments, &lt;code&gt;BB(4)&lt;/code&gt; was discovered to be 107 in 1983, the same year his Apple 2e was built. In 2024, &lt;code&gt;BB(5)&lt;/code&gt; was proven to be 47,176,870.&lt;/p&gt;
    &lt;p&gt;As N grows, BB is known to eventually outgrow any computable sequence, including famous fast-growing sequences like TREE(). &lt;code&gt;BB(6)&lt;/code&gt; has a lower bound that is so large that it is impossible to explain how large it is to someone without a significant background in mathematics.&lt;/p&gt;
    &lt;p&gt;Software has an unprecedented capability to produce a correct answer in the most resource consuming way possible. Of course, producing incorrect answers or no answer at all is also an option.&lt;/p&gt;
    &lt;p&gt;Despite the apparent truth of Wirth's law, engineers have been actively battling against it for decades, but I worry that with LLMs we might have lost the war.&lt;/p&gt;
    &lt;p&gt;Am I just the latest in a long line of engineers who can't appreciate the newfound democratization of programming, or have we crossed into a "bad" Wirth tradeoff, where the growth curve of runtime complexity is something that hardware advancements cannot possibly dig us back out of?&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;If you are wincing at the last name Reiser in the context of vaguely old computing, we are both of a very specific place and time, and I want you to know that Martin Reiser is not and has never been Hans Reiser.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46895381</guid><pubDate>Thu, 05 Feb 2026 03:38:26 +0000</pubDate></item><item><title>When internal hostnames are leaked to the clown</title><link>https://rachelbythebay.com/w/2026/02/03/badnas/</link><description>&lt;doc fingerprint="edd19151c5b24caf"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Owning a $5M data center&lt;/head&gt;
    &lt;p&gt;These days it seems you need a trillion fake dollars, or lunch with politicians to get your own data center. They may help, but they‚Äôre not required. At comma we‚Äôve been running our own data center for years. All of our model training, metrics, and data live in our own data center in our own office. Having your own data center is cool, and in this blog post I will describe how ours works, so you can be inspired to have your own data center too.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why no cloud?&lt;/head&gt;
    &lt;p&gt;If your business relies on compute, and you run that compute in the cloud, you are putting a lot of trust in your cloud provider. Cloud companies generally make onboarding very easy, and offboarding very difficult. If you are not vigilant you will sleepwalk into a situation of high cloud costs and no way out. If you want to control your own destiny, you must run your own compute.&lt;/p&gt;
    &lt;p&gt;Self-reliance is great, but there are other benefits to running your own compute. It inspires good engineering. Maintaining a data center is much more about solving real-world challenges. The cloud requires expertise in company-specific APIs and billing systems. A data center requires knowledge of Watts, bits, and FLOPs. I know which one I rather think about.&lt;/p&gt;
    &lt;p&gt;Avoiding the cloud for ML also creates better incentives for engineers. Engineers generally want to improve things. In ML many problems go away by just using more compute. In the cloud that means improvements are just a budget increase away. This locks you into inefficient and expensive solutions. Instead, when all you have available is your current compute, the quickest improvements are usually speeding up your code, or fixing fundamental issues.&lt;/p&gt;
    &lt;p&gt;Finally there‚Äôs cost, owning a data center can be far cheaper than renting in the cloud. Especially if your compute or storage needs are fairly consistent, which tends to be true if you are in the business of training or running models. In comma‚Äôs case I estimate we‚Äôve spent ~5M on our data center, and we would have spent 25M+ had we done the same things in the cloud.&lt;/p&gt;
    &lt;head rend="h2"&gt;What‚Äôs all needed?&lt;/head&gt;
    &lt;p&gt;Our data center is pretty simple. It‚Äôs maintained and built by only a couple engineers and technicians. Your needs may be slightly different, our implementation should provide useful context.&lt;/p&gt;
    &lt;head rend="h3"&gt;Power&lt;/head&gt;
    &lt;p&gt;To run servers you need power. We currently use about 450kW at max. Operating a data center exposes you to many fun engineering challenges, but procuring power is not one of them. San Diego power cost is over 40c/kWh, ~3x the global average. It‚Äôs a ripoff, and overpriced simply due to political dysfunction. We spent $540,112 on power in 2025, a big part of the data center cost. In a future blog post I hope I can tell you about how we produce our own power and you should too.&lt;/p&gt;
    &lt;head rend="h3"&gt;Cooling&lt;/head&gt;
    &lt;p&gt;Data centers need cool dry air. Typically this is achieved with a CRAC system, but they are power-hungry. San Diego has a mild climate and we opted for pure outside air cooling. This gives us less control of the temperature and humidity, but uses only a couple dozen kW. We have dual 48‚Äù intake fans and dual 48‚Äù exhaust fans to keep the air cool. To ensure low humidity (&amp;lt;45%) we use recirculating fans to mix hot exhaust air with the intake air. One server is connected to several sensors and runs a PID loop to control the fans to optimize the temperature and humidity.&lt;/p&gt;
    &lt;head rend="h3"&gt;Servers&lt;/head&gt;
    &lt;p&gt;The majority of our current compute is 600 GPUs in 75 TinyBox Pro machines. They were built in-house, which saves us money and ensures they suit our needs. Our self-built machines fail at a similar rate to pre-built machines we‚Äôve bought, but we‚Äôre capable of fixing them ourselves quickly. They have 2 CPUs and 8 GPUs each, and work as both training machines and general compute workers.&lt;/p&gt;
    &lt;p&gt;For data storage we have a few racks of Dell machines (R630 and R730). They are filled with SSDs for a total of ~4PB of storage. We use SSDs for reliability and speed. Our main storage arrays have no redundancy and each node needs to be able to saturate the network bandwidth with random access reads. For the storage machines this means reading up to 20Gbps of each 80TB chunk.&lt;/p&gt;
    &lt;p&gt;Other than storage and compute machines we have several one-off machines to run services. This includes a router, climate controller, data ingestion machine, storage master servers, metric servers, redis servers, and a few more.&lt;/p&gt;
    &lt;p&gt;Running the network requires switches, but at this scale we don‚Äôt need to bother with complicated switch topologies. We have 3 100Gbps interconnected Z9264F switches, which serve as the main ethernet network. We have two more infiniband switches to interconnect the 2 tinybox pro groups for training all-reduce.&lt;/p&gt;
    &lt;head rend="h3"&gt;The software&lt;/head&gt;
    &lt;p&gt;To effectively use all these compute and storage machines you need some infra. At this scale, services don‚Äôt need redundancy to achieve 99% uptime. We use a single master for all services, which makes things pretty simple.&lt;/p&gt;
    &lt;head rend="h5"&gt;Setup&lt;/head&gt;
    &lt;p&gt;All servers get ubuntu installed with pxeboot and are managed by salt.&lt;/p&gt;
    &lt;head rend="h5"&gt;Distributed storage: minikeyvalue&lt;/head&gt;
    &lt;p&gt;All of our storage arrays use mkv. The main array is 3PB of non-redundant storage hosting our driving data we train on. We can read from this array at ~1TB/s, which means we can train directly on the raw data without caching. Redundancy is not needed since no specific data is critical.&lt;/p&gt;
    &lt;p&gt;We have an additional ~300TB non-redundant array to cache intermediate processed results. And lastly, we have a redundant mkv storage array to store all of our trained models and training metrics. Each of these 3 arrays have a separate single master server.&lt;/p&gt;
    &lt;head rend="h5"&gt;Workload management: slurm&lt;/head&gt;
    &lt;p&gt;We use slurm to manage the compute nodes, and compute jobs. We schedule two types of distributed compute. Pytorch training jobs, and miniray workers.&lt;/p&gt;
    &lt;head rend="h5"&gt;Distributed training: pytorch&lt;/head&gt;
    &lt;p&gt;To train models across multiple GPU nodes we use &lt;code&gt;torch.distributed&lt;/code&gt; FSDP. We have 2 separate training partitions, each intra-connected with Infiniband for training across machines. We wrote our own training framework which handles the training loop boilerplate, but it‚Äôs mostly just pytorch.&lt;/p&gt;
    &lt;p&gt;We have a custom model experiment tracking service (similar to wandb or tensorboard). It provides a dashboard for tracking experiments, and shows custom metrics and reports. It is also the interface for the mkv storage array that hosts the model weights. The training runs store the model weights there with a uuid, and they are available to download for whoever needs to run them. The metrics and reports for our latest models are also open.&lt;/p&gt;
    &lt;head rend="h5"&gt;Distributed compute: miniray&lt;/head&gt;
    &lt;p&gt;Besides training we have many other compute tasks. This can be anything from running tests, running models, pre-processing data, or even running agent rollouts for on-policy training. We wrote a lightweight open-source task scheduler called miniray that allows you to run arbitrary python code on idle machines. This is a simpler version of dask, with a focus on extreme simplicity. Slurm will schedule any idle machine to be an active miniray worker, and accept pending tasks. All the task information is hosted in a central redis server.&lt;/p&gt;
    &lt;p&gt;Miniray workers with GPUs will spin up a triton inference server to run model inference with dynamic batching. A miniray worker can thus easily and efficiently run any of the models hosted in the model mkv storage array.&lt;/p&gt;
    &lt;p&gt;Miniray makes it extremely easy to scale parallel tasks to hundreds of machines. For example, the controls challenge record was set by just having ~1hr of access to our data center with miniray.&lt;/p&gt;
    &lt;head rend="h5"&gt;Code NFS monorepo&lt;/head&gt;
    &lt;p&gt;All our code is in a monorepo that we have cloned on our workstations. This monorepo is kept small (&amp;lt;3GB), so it can easily be copied around. When a training job or miniray distributed job is started on any workstation, the local monorepo is cached on a shared NFS drive including all the local changes. Training jobs and miniray tasks are pointed towards this cache, such that all distributed work uses the exact codebase you have locally. Even all the python packages are identical, UV on the worker/trainer syncs the packages specified in the monorepo before starting any work. This entire process of copying your entire local codebase and syncing all the packages takes only ~2s, and is well worth it to prevent the issues mismatches can cause.&lt;/p&gt;
    &lt;head rend="h2"&gt;All together now&lt;/head&gt;
    &lt;p&gt;The most complex thing we do at comma is train driving models on-policy, these training runs require training data to be generated during training by running simulated driving rollouts with the most recent model weights. Here‚Äôs a real-world command we just used to train such a model. This training run uses all of the infrastructure described above. While only this small command is needed to kick everything off, it orchestrates a lot of moving parts.&lt;/p&gt;
    &lt;code&gt;./training/train.sh N=4 partition=tbox2 trainer=mlsimdriving dataset=/home/batman/xx/datasets/lists/train_500k_20250717.txt vision_model=8d4e28c7-7078-4caf-ac7d-d0e41255c3d4/500 data.shuffle_size=125k optim.scheduler=COSINE bs=4
&lt;/code&gt;
    &lt;head rend="h2"&gt;Like this stuff?&lt;/head&gt;
    &lt;p&gt;Does all this stuff sound exciting? Then build your own datacenter for yourself or your company! You can also come work here.&lt;/p&gt;
    &lt;p&gt;Harald Sch√§fer&lt;lb/&gt; CTO @ comma.ai&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46895972</guid><pubDate>Thu, 05 Feb 2026 05:22:36 +0000</pubDate></item><item><title>Don't rent the cloud, own instead</title><link>https://blog.comma.ai/datacenter/</link><description>&lt;doc fingerprint="edd19151c5b24caf"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Owning a $5M data center&lt;/head&gt;
    &lt;p&gt;These days it seems you need a trillion fake dollars, or lunch with politicians to get your own data center. They may help, but they‚Äôre not required. At comma we‚Äôve been running our own data center for years. All of our model training, metrics, and data live in our own data center in our own office. Having your own data center is cool, and in this blog post I will describe how ours works, so you can be inspired to have your own data center too.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why no cloud?&lt;/head&gt;
    &lt;p&gt;If your business relies on compute, and you run that compute in the cloud, you are putting a lot of trust in your cloud provider. Cloud companies generally make onboarding very easy, and offboarding very difficult. If you are not vigilant you will sleepwalk into a situation of high cloud costs and no way out. If you want to control your own destiny, you must run your own compute.&lt;/p&gt;
    &lt;p&gt;Self-reliance is great, but there are other benefits to running your own compute. It inspires good engineering. Maintaining a data center is much more about solving real-world challenges. The cloud requires expertise in company-specific APIs and billing systems. A data center requires knowledge of Watts, bits, and FLOPs. I know which one I rather think about.&lt;/p&gt;
    &lt;p&gt;Avoiding the cloud for ML also creates better incentives for engineers. Engineers generally want to improve things. In ML many problems go away by just using more compute. In the cloud that means improvements are just a budget increase away. This locks you into inefficient and expensive solutions. Instead, when all you have available is your current compute, the quickest improvements are usually speeding up your code, or fixing fundamental issues.&lt;/p&gt;
    &lt;p&gt;Finally there‚Äôs cost, owning a data center can be far cheaper than renting in the cloud. Especially if your compute or storage needs are fairly consistent, which tends to be true if you are in the business of training or running models. In comma‚Äôs case I estimate we‚Äôve spent ~5M on our data center, and we would have spent 25M+ had we done the same things in the cloud.&lt;/p&gt;
    &lt;head rend="h2"&gt;What‚Äôs all needed?&lt;/head&gt;
    &lt;p&gt;Our data center is pretty simple. It‚Äôs maintained and built by only a couple engineers and technicians. Your needs may be slightly different, our implementation should provide useful context.&lt;/p&gt;
    &lt;head rend="h3"&gt;Power&lt;/head&gt;
    &lt;p&gt;To run servers you need power. We currently use about 450kW at max. Operating a data center exposes you to many fun engineering challenges, but procuring power is not one of them. San Diego power cost is over 40c/kWh, ~3x the global average. It‚Äôs a ripoff, and overpriced simply due to political dysfunction. We spent $540,112 on power in 2025, a big part of the data center cost. In a future blog post I hope I can tell you about how we produce our own power and you should too.&lt;/p&gt;
    &lt;head rend="h3"&gt;Cooling&lt;/head&gt;
    &lt;p&gt;Data centers need cool dry air. Typically this is achieved with a CRAC system, but they are power-hungry. San Diego has a mild climate and we opted for pure outside air cooling. This gives us less control of the temperature and humidity, but uses only a couple dozen kW. We have dual 48‚Äù intake fans and dual 48‚Äù exhaust fans to keep the air cool. To ensure low humidity (&amp;lt;45%) we use recirculating fans to mix hot exhaust air with the intake air. One server is connected to several sensors and runs a PID loop to control the fans to optimize the temperature and humidity.&lt;/p&gt;
    &lt;head rend="h3"&gt;Servers&lt;/head&gt;
    &lt;p&gt;The majority of our current compute is 600 GPUs in 75 TinyBox Pro machines. They were built in-house, which saves us money and ensures they suit our needs. Our self-built machines fail at a similar rate to pre-built machines we‚Äôve bought, but we‚Äôre capable of fixing them ourselves quickly. They have 2 CPUs and 8 GPUs each, and work as both training machines and general compute workers.&lt;/p&gt;
    &lt;p&gt;For data storage we have a few racks of Dell machines (R630 and R730). They are filled with SSDs for a total of ~4PB of storage. We use SSDs for reliability and speed. Our main storage arrays have no redundancy and each node needs to be able to saturate the network bandwidth with random access reads. For the storage machines this means reading up to 20Gbps of each 80TB chunk.&lt;/p&gt;
    &lt;p&gt;Other than storage and compute machines we have several one-off machines to run services. This includes a router, climate controller, data ingestion machine, storage master servers, metric servers, redis servers, and a few more.&lt;/p&gt;
    &lt;p&gt;Running the network requires switches, but at this scale we don‚Äôt need to bother with complicated switch topologies. We have 3 100Gbps interconnected Z9264F switches, which serve as the main ethernet network. We have two more infiniband switches to interconnect the 2 tinybox pro groups for training all-reduce.&lt;/p&gt;
    &lt;head rend="h3"&gt;The software&lt;/head&gt;
    &lt;p&gt;To effectively use all these compute and storage machines you need some infra. At this scale, services don‚Äôt need redundancy to achieve 99% uptime. We use a single master for all services, which makes things pretty simple.&lt;/p&gt;
    &lt;head rend="h5"&gt;Setup&lt;/head&gt;
    &lt;p&gt;All servers get ubuntu installed with pxeboot and are managed by salt.&lt;/p&gt;
    &lt;head rend="h5"&gt;Distributed storage: minikeyvalue&lt;/head&gt;
    &lt;p&gt;All of our storage arrays use mkv. The main array is 3PB of non-redundant storage hosting our driving data we train on. We can read from this array at ~1TB/s, which means we can train directly on the raw data without caching. Redundancy is not needed since no specific data is critical.&lt;/p&gt;
    &lt;p&gt;We have an additional ~300TB non-redundant array to cache intermediate processed results. And lastly, we have a redundant mkv storage array to store all of our trained models and training metrics. Each of these 3 arrays have a separate single master server.&lt;/p&gt;
    &lt;head rend="h5"&gt;Workload management: slurm&lt;/head&gt;
    &lt;p&gt;We use slurm to manage the compute nodes, and compute jobs. We schedule two types of distributed compute. Pytorch training jobs, and miniray workers.&lt;/p&gt;
    &lt;head rend="h5"&gt;Distributed training: pytorch&lt;/head&gt;
    &lt;p&gt;To train models across multiple GPU nodes we use &lt;code&gt;torch.distributed&lt;/code&gt; FSDP. We have 2 separate training partitions, each intra-connected with Infiniband for training across machines. We wrote our own training framework which handles the training loop boilerplate, but it‚Äôs mostly just pytorch.&lt;/p&gt;
    &lt;p&gt;We have a custom model experiment tracking service (similar to wandb or tensorboard). It provides a dashboard for tracking experiments, and shows custom metrics and reports. It is also the interface for the mkv storage array that hosts the model weights. The training runs store the model weights there with a uuid, and they are available to download for whoever needs to run them. The metrics and reports for our latest models are also open.&lt;/p&gt;
    &lt;head rend="h5"&gt;Distributed compute: miniray&lt;/head&gt;
    &lt;p&gt;Besides training we have many other compute tasks. This can be anything from running tests, running models, pre-processing data, or even running agent rollouts for on-policy training. We wrote a lightweight open-source task scheduler called miniray that allows you to run arbitrary python code on idle machines. This is a simpler version of dask, with a focus on extreme simplicity. Slurm will schedule any idle machine to be an active miniray worker, and accept pending tasks. All the task information is hosted in a central redis server.&lt;/p&gt;
    &lt;p&gt;Miniray workers with GPUs will spin up a triton inference server to run model inference with dynamic batching. A miniray worker can thus easily and efficiently run any of the models hosted in the model mkv storage array.&lt;/p&gt;
    &lt;p&gt;Miniray makes it extremely easy to scale parallel tasks to hundreds of machines. For example, the controls challenge record was set by just having ~1hr of access to our data center with miniray.&lt;/p&gt;
    &lt;head rend="h5"&gt;Code NFS monorepo&lt;/head&gt;
    &lt;p&gt;All our code is in a monorepo that we have cloned on our workstations. This monorepo is kept small (&amp;lt;3GB), so it can easily be copied around. When a training job or miniray distributed job is started on any workstation, the local monorepo is cached on a shared NFS drive including all the local changes. Training jobs and miniray tasks are pointed towards this cache, such that all distributed work uses the exact codebase you have locally. Even all the python packages are identical, UV on the worker/trainer syncs the packages specified in the monorepo before starting any work. This entire process of copying your entire local codebase and syncing all the packages takes only ~2s, and is well worth it to prevent the issues mismatches can cause.&lt;/p&gt;
    &lt;head rend="h2"&gt;All together now&lt;/head&gt;
    &lt;p&gt;The most complex thing we do at comma is train driving models on-policy, these training runs require training data to be generated during training by running simulated driving rollouts with the most recent model weights. Here‚Äôs a real-world command we just used to train such a model. This training run uses all of the infrastructure described above. While only this small command is needed to kick everything off, it orchestrates a lot of moving parts.&lt;/p&gt;
    &lt;code&gt;./training/train.sh N=4 partition=tbox2 trainer=mlsimdriving dataset=/home/batman/xx/datasets/lists/train_500k_20250717.txt vision_model=8d4e28c7-7078-4caf-ac7d-d0e41255c3d4/500 data.shuffle_size=125k optim.scheduler=COSINE bs=4
&lt;/code&gt;
    &lt;head rend="h2"&gt;Like this stuff?&lt;/head&gt;
    &lt;p&gt;Does all this stuff sound exciting? Then build your own datacenter for yourself or your company! You can also come work here.&lt;/p&gt;
    &lt;p&gt;Harald Sch√§fer&lt;lb/&gt; CTO @ comma.ai&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46896146</guid><pubDate>Thu, 05 Feb 2026 05:50:01 +0000</pubDate></item><item><title>Show HN: Micropolis/SimCity Clone in Emacs Lisp</title><link>https://github.com/vkazanov/elcity</link><description>&lt;doc fingerprint="3e873a436311661e"&gt;
  &lt;main&gt;
    &lt;p&gt;ElCity is a small, turn-based city builder that runs entirely inside Emacs. The UI is ASCII-based and optimized for terminal Emacs sessions. The core simulation is deterministic and pure, while the UI handles rendering and input.&lt;/p&gt;
    &lt;p&gt;This is an excercise in implementing the ‚Äúfunctional core / imperative shell‚Äù architecture in a moderately sized project that with a developed UI. Every tile type is defined through a DSL, with a strong separation between state and effects. Most functions in the core are either pure or pure-ish.&lt;/p&gt;
    &lt;p&gt;Benefits to this approach:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;easy to debug&lt;/item&gt;
      &lt;item&gt;scalable in terms of code: reduced cognitive load on both people and LLMs&lt;/item&gt;
      &lt;item&gt;easy UX/UI as state is always localized&lt;/item&gt;
      &lt;item&gt;easy to extend (with some discipline)&lt;/item&gt;
      &lt;item&gt;easy to autotest&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Emacs 30.1+&lt;/item&gt;
      &lt;item&gt;Optional: Eask for dependency management&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Clone the repository and add it to your Emacs load path. Example with &lt;code&gt;use-package&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;(use-package elcity
  :load-path "/path/to/elcity"
  :commands (elcity-start))&lt;/code&gt;
    &lt;p&gt;If you are not using &lt;code&gt;use-package&lt;/code&gt;, add the directory to &lt;code&gt;load-path&lt;/code&gt;
  and require the entry point:&lt;/p&gt;
    &lt;code&gt;(add-to-list 'load-path "/path/to/elcity")
(require 'elcity)
(elcity-start)&lt;/code&gt;
    &lt;p&gt;From the project root:&lt;/p&gt;
    &lt;code&gt;make run&lt;/code&gt;
    &lt;p&gt;Or from Emacs: &lt;code&gt;M-x elcity-start&lt;/code&gt;&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The game is turn-based. Press &lt;code&gt;n&lt;/code&gt;to advance one turn.&lt;/item&gt;
      &lt;item&gt;Funds increase each turn by: (Population / 2) + (Commercial level + Industrial level).&lt;/item&gt;
      &lt;item&gt;City Hall is the source of road connectivity and is unique and non-demolishable.&lt;/item&gt;
      &lt;item&gt;Roads are only connected if they trace through other roads to City Hall.&lt;/item&gt;
      &lt;item&gt;Power plants provide a Manhattan-radius of 6 tiles.&lt;/item&gt;
      &lt;item&gt;Zones grow by 1 level per turn if powered and road-adjacent.&lt;/item&gt;
      &lt;item&gt;Zones decay by 1 level per turn if they lose power or road adjacency.&lt;/item&gt;
      &lt;item&gt;Maximum zone level is 3.&lt;/item&gt;
      &lt;item&gt;Residential (R) supplies Workers in a radius and dislikes Pollution.&lt;/item&gt;
      &lt;item&gt;Industrial (I) supplies Goods and Pollution and requires Workers.&lt;/item&gt;
      &lt;item&gt;Commercial (C) requires Workers and Goods.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;R&lt;/code&gt;select Residential and place once&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;C&lt;/code&gt;select Commercial and place once&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;I&lt;/code&gt;select Industrial and place once&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;r&lt;/code&gt;select Road and place once&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;p&lt;/code&gt;select Power plant and place once&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;h&lt;/code&gt;select City Hall and place once&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;SPC&lt;/code&gt;or&lt;code&gt;RET&lt;/code&gt;place selected tool at cursor&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;d&lt;/code&gt;demolish at cursor&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;u&lt;/code&gt;undo last action&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;n&lt;/code&gt;advance one turn&lt;/item&gt;
      &lt;item&gt;Arrow keys move the cursor&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;o&lt;/code&gt;cycle overlays (goods, polution, connectivity, etc)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is a simplified snapshot to show the general layout.&lt;/p&gt;
    &lt;code&gt;Funds: 1000 | Pop: 0 | Income: 0 | Turn: 0 | Overlay: none | Tool: none | Unpowered: 0 | Disconnected: 0 | Polluted: 0
Cursor: (0,0) | Tile: HH City Hall | Level: 0 | Build: N | Demo: N | Unique: Y | Cost: 150 | Pop: 0 | Inc: 0
Legend: R res  C com  I ind  == road  Overlay: Pwr Conn Poll Work Goods
Keys: R/C/I zone (select tool) | r road | p power | h city hall | d demolish | n next turn
Place: SPC/RET place selected tool | u undo
Overlay: o cycle (none/power/connectivity/pollution/workers/goods)
Move: arrows
   00 01 02 03 04 05 06 07 08 09
   +--------------------+
00 |HH==R0..PP..........|
01 |....................|
02 |~~~~~~..............|
   +--------------------+
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Start with a custom map by calling &lt;code&gt;elcity-start&lt;/code&gt;with a list of row strings.&lt;/item&gt;
      &lt;item&gt;Example call: &lt;code&gt;(elcity-start '("H=R0" "...."))&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Map tokens are defined in tile definitions.&lt;/item&gt;
      &lt;item&gt;Canonical tokens include &lt;code&gt;..&lt;/code&gt;,&lt;code&gt;~~&lt;/code&gt;,&lt;code&gt;==&lt;/code&gt;,&lt;code&gt;PP&lt;/code&gt;,&lt;code&gt;HH&lt;/code&gt;,&lt;code&gt;R0&lt;/code&gt;-=R3=,&lt;code&gt;C0&lt;/code&gt;-=C3=,&lt;code&gt;I0&lt;/code&gt;-=I3=.&lt;/item&gt;
      &lt;item&gt;Short aliases are also accepted: &lt;code&gt;.&lt;/code&gt;,&lt;code&gt;~&lt;/code&gt;,&lt;code&gt;=&lt;/code&gt;,&lt;code&gt;P&lt;/code&gt;,&lt;code&gt;H&lt;/code&gt;,&lt;code&gt;R&lt;/code&gt;,&lt;code&gt;C&lt;/code&gt;,&lt;code&gt;I&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Default map rows live in &lt;code&gt;elcity-maps.el&lt;/code&gt;(&lt;code&gt;elcity-map-default-rows&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Default map size is set by &lt;code&gt;elcity-core-map-width&lt;/code&gt;and&lt;code&gt;elcity-core-map-height&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;make test&lt;/code&gt;runs ERT tests.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;make lint&lt;/code&gt;runs package lint, checkdoc, and byte compilation.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;make compile&lt;/code&gt;byte-compiles non-test files.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;elcity.el&lt;/code&gt;entry point that wires core and UI&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;elcity-core.el&lt;/code&gt;pure simulation and state transitions&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;elcity-tiles.el&lt;/code&gt;tile definitions and effect metadata&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;elcity-ui.el&lt;/code&gt;UI shell and input handling&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;elcity-maps.el&lt;/code&gt;map presets&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;test/&lt;/code&gt;ERT tests&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46897332</guid><pubDate>Thu, 05 Feb 2026 08:46:13 +0000</pubDate></item><item><title>Nanobot: Ultra-Lightweight Alternative to OpenClaw</title><link>https://github.com/HKUDS/nanobot</link><description>&lt;doc fingerprint="ae46eed130930a53"&gt;
  &lt;main&gt;
    &lt;p&gt;üêà nanobot is an ultra-lightweight personal AI assistant inspired by Clawdbot&lt;/p&gt;
    &lt;p&gt;‚ö°Ô∏è Delivers core agent functionality in just ~4,000 lines of code ‚Äî 99% smaller than Clawdbot's 430k+ lines.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2026-02-05 ‚ú® Added Feishu channel, DeepSeek provider, and better scheduled tasks support!&lt;/item&gt;
      &lt;item&gt;2026-02-04 üöÄ v0.1.3.post4 released with multi-provider &amp;amp; Docker support! Check release notes for details.&lt;/item&gt;
      &lt;item&gt;2026-02-02 üéâ nanobot launched! Welcome to try üêà nanobot!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;ü™∂ Ultra-Lightweight: Just ~4,000 lines of code ‚Äî 99% smaller than Clawdbot - core functionality.&lt;/p&gt;
    &lt;p&gt;üî¨ Research-Ready: Clean, readable code that's easy to understand, modify, and extend for research.&lt;/p&gt;
    &lt;p&gt;‚ö°Ô∏è Lightning Fast: Minimal footprint means faster startup, lower resource usage, and quicker iterations.&lt;/p&gt;
    &lt;p&gt;üíé Easy-to-Use: One-click to deploy and you're ready to go.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;üìà 24/7 Real-Time Market Analysis&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;üöÄ Full-Stack Software Engineer&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;üìÖ Smart Daily Routine Manager&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;üìö Personal Knowledge Assistant&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Discovery ‚Ä¢ Insights ‚Ä¢ Trends&lt;/cell&gt;
        &lt;cell&gt;Develop ‚Ä¢ Deploy ‚Ä¢ Scale&lt;/cell&gt;
        &lt;cell&gt;Schedule ‚Ä¢ Automate ‚Ä¢ Organize&lt;/cell&gt;
        &lt;cell&gt;Learn ‚Ä¢ Memory ‚Ä¢ Reasoning&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Install from source (latest features, recommended for development)&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/HKUDS/nanobot.git
cd nanobot
pip install -e .&lt;/code&gt;
    &lt;p&gt;Install with uv (stable, fast)&lt;/p&gt;
    &lt;code&gt;uv tool install nanobot-ai&lt;/code&gt;
    &lt;p&gt;Install from PyPI (stable)&lt;/p&gt;
    &lt;code&gt;pip install nanobot-ai&lt;/code&gt;
    &lt;p&gt;Tip&lt;/p&gt;
    &lt;p&gt;Set your API key in &lt;code&gt;~/.nanobot/config.json&lt;/code&gt;.
Get API keys: OpenRouter (LLM) ¬∑ Brave Search (optional, for web search)
You can also change the model to &lt;code&gt;minimax/minimax-m2&lt;/code&gt; for lower cost.&lt;/p&gt;
    &lt;p&gt;1. Initialize&lt;/p&gt;
    &lt;code&gt;nanobot onboard&lt;/code&gt;
    &lt;p&gt;2. Configure (&lt;code&gt;~/.nanobot/config.json&lt;/code&gt;)&lt;/p&gt;
    &lt;code&gt;{
  "providers": {
    "openrouter": {
      "apiKey": "sk-or-v1-xxx"
    }
  },
  "agents": {
    "defaults": {
      "model": "anthropic/claude-opus-4-5"
    }
  },
  "tools": {
    "web": {
      "search": {
        "apiKey": "BSA-xxx"
      }
    }
  }
}&lt;/code&gt;
    &lt;p&gt;3. Chat&lt;/p&gt;
    &lt;code&gt;nanobot agent -m "What is 2+2?"&lt;/code&gt;
    &lt;p&gt;That's it! You have a working AI assistant in 2 minutes.&lt;/p&gt;
    &lt;p&gt;Run nanobot with your own local models using vLLM or any OpenAI-compatible server.&lt;/p&gt;
    &lt;p&gt;1. Start your vLLM server&lt;/p&gt;
    &lt;code&gt;vllm serve meta-llama/Llama-3.1-8B-Instruct --port 8000&lt;/code&gt;
    &lt;p&gt;2. Configure (&lt;code&gt;~/.nanobot/config.json&lt;/code&gt;)&lt;/p&gt;
    &lt;code&gt;{
  "providers": {
    "vllm": {
      "apiKey": "dummy",
      "apiBase": "http://localhost:8000/v1"
    }
  },
  "agents": {
    "defaults": {
      "model": "meta-llama/Llama-3.1-8B-Instruct"
    }
  }
}&lt;/code&gt;
    &lt;p&gt;3. Chat&lt;/p&gt;
    &lt;code&gt;nanobot agent -m "Hello from my local LLM!"&lt;/code&gt;
    &lt;p&gt;Tip&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;apiKey&lt;/code&gt; can be any non-empty string for local servers that don't require authentication.&lt;/p&gt;
    &lt;p&gt;Talk to your nanobot through Telegram, WhatsApp, or Feishu ‚Äî anytime, anywhere.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Channel&lt;/cell&gt;
        &lt;cell role="head"&gt;Setup&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Telegram&lt;/cell&gt;
        &lt;cell&gt;Easy (just a token)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Medium (scan QR)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Feishu&lt;/cell&gt;
        &lt;cell&gt;Medium (app credentials)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head&gt;Telegram (Recommended)&lt;/head&gt;
    &lt;p&gt;1. Create a bot&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Open Telegram, search &lt;code&gt;@BotFather&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Send &lt;code&gt;/newbot&lt;/code&gt;, follow prompts&lt;/item&gt;
      &lt;item&gt;Copy the token&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;2. Configure&lt;/p&gt;
    &lt;code&gt;{
  "channels": {
    "telegram": {
      "enabled": true,
      "token": "YOUR_BOT_TOKEN",
      "allowFrom": ["YOUR_USER_ID"]
    }
  }
}&lt;/code&gt;
    &lt;quote&gt;&lt;p&gt;Get your user ID from&lt;/p&gt;&lt;code&gt;@userinfobot&lt;/code&gt;on Telegram.&lt;/quote&gt;
    &lt;p&gt;3. Run&lt;/p&gt;
    &lt;code&gt;nanobot gateway&lt;/code&gt;
    &lt;p&gt;Requires Node.js ‚â•18.&lt;/p&gt;
    &lt;p&gt;1. Link device&lt;/p&gt;
    &lt;code&gt;nanobot channels login
# Scan QR with WhatsApp ‚Üí Settings ‚Üí Linked Devices&lt;/code&gt;
    &lt;p&gt;2. Configure&lt;/p&gt;
    &lt;code&gt;{
  "channels": {
    "whatsapp": {
      "enabled": true,
      "allowFrom": ["+1234567890"]
    }
  }
}&lt;/code&gt;
    &lt;p&gt;3. Run (two terminals)&lt;/p&gt;
    &lt;code&gt;# Terminal 1
nanobot channels login

# Terminal 2
nanobot gateway&lt;/code&gt;
    &lt;head&gt;Feishu (È£û‰π¶)&lt;/head&gt;
    &lt;p&gt;Uses WebSocket long connection ‚Äî no public IP required.&lt;/p&gt;
    &lt;code&gt;pip install nanobot-ai[feishu]&lt;/code&gt;
    &lt;p&gt;1. Create a Feishu bot&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Visit Feishu Open Platform&lt;/item&gt;
      &lt;item&gt;Create a new app ‚Üí Enable Bot capability&lt;/item&gt;
      &lt;item&gt;Permissions: Add &lt;code&gt;im:message&lt;/code&gt;(send messages)&lt;/item&gt;
      &lt;item&gt;Events: Add &lt;code&gt;im.message.receive_v1&lt;/code&gt;(receive messages)&lt;list rend="ul"&gt;&lt;item&gt;Select Long Connection mode (requires running nanobot first to establish connection)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Get App ID and App Secret from "Credentials &amp;amp; Basic Info"&lt;/item&gt;
      &lt;item&gt;Publish the app&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;2. Configure&lt;/p&gt;
    &lt;code&gt;{
  "channels": {
    "feishu": {
      "enabled": true,
      "appId": "cli_xxx",
      "appSecret": "xxx",
      "encryptKey": "",
      "verificationToken": "",
      "allowFrom": []
    }
  }
}&lt;/code&gt;
    &lt;quote&gt;&lt;code&gt;encryptKey&lt;/code&gt;and&lt;code&gt;verificationToken&lt;/code&gt;are optional for Long Connection mode.&lt;code&gt;allowFrom&lt;/code&gt;: Leave empty to allow all users, or add&lt;code&gt;["ou_xxx"]&lt;/code&gt;to restrict access.&lt;/quote&gt;
    &lt;p&gt;3. Run&lt;/p&gt;
    &lt;code&gt;nanobot gateway&lt;/code&gt;
    &lt;quote&gt;
      &lt;p&gt;[!TIP] Feishu uses WebSocket to receive messages ‚Äî no webhook or public IP needed!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Config file: &lt;code&gt;~/.nanobot/config.json&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;Groq provides free voice transcription via Whisper. If configured, Telegram voice messages will be automatically transcribed.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Provider&lt;/cell&gt;
        &lt;cell role="head"&gt;Purpose&lt;/cell&gt;
        &lt;cell role="head"&gt;Get API Key&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;openrouter&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;LLM (recommended, access to all models)&lt;/cell&gt;
        &lt;cell&gt;openrouter.ai&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;anthropic&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;LLM (Claude direct)&lt;/cell&gt;
        &lt;cell&gt;console.anthropic.com&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;openai&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;LLM (GPT direct)&lt;/cell&gt;
        &lt;cell&gt;platform.openai.com&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;deepseek&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;LLM (DeepSeek direct)&lt;/cell&gt;
        &lt;cell&gt;platform.deepseek.com&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;groq&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;LLM + Voice transcription (Whisper)&lt;/cell&gt;
        &lt;cell&gt;console.groq.com&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;gemini&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;LLM (Gemini direct)&lt;/cell&gt;
        &lt;cell&gt;aistudio.google.com&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head&gt;Full config example&lt;/head&gt;
    &lt;code&gt;{
  "agents": {
    "defaults": {
      "model": "anthropic/claude-opus-4-5"
    }
  },
  "providers": {
    "openrouter": {
      "apiKey": "sk-or-v1-xxx"
    },
    "groq": {
      "apiKey": "gsk_xxx"
    }
  },
  "channels": {
    "telegram": {
      "enabled": true,
      "token": "123456:ABC...",
      "allowFrom": ["123456789"]
    },
    "whatsapp": {
      "enabled": false
    },
    "feishu": {
      "enabled": false,
      "appId": "cli_xxx",
      "appSecret": "xxx",
      "encryptKey": "",
      "verificationToken": "",
      "allowFrom": []
    }
  },
  "tools": {
    "web": {
      "search": {
        "apiKey": "BSA..."
      }
    }
  }
}&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Command&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;nanobot onboard&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Initialize config &amp;amp; workspace&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;nanobot agent -m "..."&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Chat with the agent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;nanobot agent&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Interactive chat mode&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;nanobot gateway&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Start the gateway&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;nanobot status&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Show status&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;nanobot channels login&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Link WhatsApp (scan QR)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;nanobot channels status&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Show channel status&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head&gt;Scheduled Tasks (Cron)&lt;/head&gt;
    &lt;code&gt;# Add a job
nanobot cron add --name "daily" --message "Good morning!" --cron "0 9 * * *"
nanobot cron add --name "hourly" --message "Check status" --every 3600

# List jobs
nanobot cron list

# Remove a job
nanobot cron remove &amp;lt;job_id&amp;gt;&lt;/code&gt;
    &lt;p&gt;Tip&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;-v ~/.nanobot:/root/.nanobot&lt;/code&gt; flag mounts your local config directory into the container, so your config and workspace persist across container restarts.&lt;/p&gt;
    &lt;p&gt;Build and run nanobot in a container:&lt;/p&gt;
    &lt;code&gt;# Build the image
docker build -t nanobot .

# Initialize config (first time only)
docker run -v ~/.nanobot:/root/.nanobot --rm nanobot onboard

# Edit config on host to add API keys
vim ~/.nanobot/config.json

# Run gateway (connects to Telegram/WhatsApp)
docker run -v ~/.nanobot:/root/.nanobot -p 18790:18790 nanobot gateway

# Or run a single command
docker run -v ~/.nanobot:/root/.nanobot --rm nanobot agent -m "Hello!"
docker run -v ~/.nanobot:/root/.nanobot --rm nanobot status&lt;/code&gt;
    &lt;code&gt;nanobot/
‚îú‚îÄ‚îÄ agent/          # üß† Core agent logic
‚îÇ   ‚îú‚îÄ‚îÄ loop.py     #    Agent loop (LLM ‚Üî tool execution)
‚îÇ   ‚îú‚îÄ‚îÄ context.py  #    Prompt builder
‚îÇ   ‚îú‚îÄ‚îÄ memory.py   #    Persistent memory
‚îÇ   ‚îú‚îÄ‚îÄ skills.py   #    Skills loader
‚îÇ   ‚îú‚îÄ‚îÄ subagent.py #    Background task execution
‚îÇ   ‚îî‚îÄ‚îÄ tools/      #    Built-in tools (incl. spawn)
‚îú‚îÄ‚îÄ skills/         # üéØ Bundled skills (github, weather, tmux...)
‚îú‚îÄ‚îÄ channels/       # üì± WhatsApp integration
‚îú‚îÄ‚îÄ bus/            # üöå Message routing
‚îú‚îÄ‚îÄ cron/           # ‚è∞ Scheduled tasks
‚îú‚îÄ‚îÄ heartbeat/      # üíì Proactive wake-up
‚îú‚îÄ‚îÄ providers/      # ü§ñ LLM providers (OpenRouter, etc.)
‚îú‚îÄ‚îÄ session/        # üí¨ Conversation sessions
‚îú‚îÄ‚îÄ config/         # ‚öôÔ∏è Configuration
‚îî‚îÄ‚îÄ cli/            # üñ•Ô∏è Commands
&lt;/code&gt;
    &lt;p&gt;PRs welcome! The codebase is intentionally small and readable. ü§ó&lt;/p&gt;
    &lt;p&gt;Roadmap ‚Äî Pick an item and open a PR!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Voice Transcription ‚Äî Support for Groq Whisper (Issue #13)&lt;/item&gt;
      &lt;item&gt;Multi-modal ‚Äî See and hear (images, voice, video)&lt;/item&gt;
      &lt;item&gt;Long-term memory ‚Äî Never forget important context&lt;/item&gt;
      &lt;item&gt;Better reasoning ‚Äî Multi-step planning and reflection&lt;/item&gt;
      &lt;item&gt;More integrations ‚Äî Discord, Slack, email, calendar&lt;/item&gt;
      &lt;item&gt;Self-improvement ‚Äî Learn from feedback and mistakes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt; Thanks for visiting ‚ú® nanobot!&lt;/p&gt;
    &lt;p&gt;nanobot is for educational, research, and technical exchange purposes only&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46897737</guid><pubDate>Thu, 05 Feb 2026 09:39:11 +0000</pubDate></item><item><title>Top downloaded skill in ClawHub contains malware</title><link>https://1password.com/blog/from-magic-to-malware-how-openclaws-agent-skills-become-an-attack-surface</link><description>&lt;doc fingerprint="1472181b0bebb788"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;From magic to malware: How OpenClaw's agent skills become an attack surface&lt;/head&gt;
    &lt;p&gt;by Jason Meller&lt;/p&gt;
    &lt;p&gt;February 2, 2026 - 8 min&lt;/p&gt;
    &lt;head rend="h2"&gt;Related Categories&lt;/head&gt;
    &lt;p&gt;A few days ago, I published a post about why OpenClaw feels like a portal to the future, and why that future is scary in a very specific way.&lt;/p&gt;
    &lt;p&gt;The short version: agent gateways that act like OpenClaw are powerful because they have real access to your files, your tools, your browser, your terminals, and often a long-term ‚Äúmemory‚Äù file that captures how you think and what you‚Äôre building. That combination is exactly what modern infostealers are designed to exploit.&lt;/p&gt;
    &lt;p&gt;This post is the uncomfortable, ‚Äúand then it happened‚Äù follow-up.&lt;/p&gt;
    &lt;p&gt;Because it‚Äôs not just that agents can be dangerous once they‚Äôre installed. The ecosystem that distributes their capabilities and skill registries has already become an attack surface.&lt;/p&gt;
    &lt;p&gt;If you are experimenting with OpenClaw, do not do it on a company device. Full stop.&lt;/p&gt;
    &lt;p&gt;In my first post, I described OpenClaw as a kind of Faustian bargain. It is compelling precisely because it has real access to your local machine, your apps, your browser sessions, your files, and often long-term memory. That same access means there isn‚Äôt yet a safe way to run it on a machine that holds corporate credentials or has access to production systems.&lt;/p&gt;
    &lt;p&gt;If you have already run OpenClaw on a work device, treat it as a potential incident and engage your security team immediately. Do not wait for symptoms. Pause work on that machine and follow your organization‚Äôs incident response process.&lt;/p&gt;
    &lt;head rend="h2"&gt;Skills are just markdown. That‚Äôs the problem.&lt;/head&gt;
    &lt;p&gt;In the OpenClaw ecosystem, a ‚Äúskill‚Äù is often a markdown file: a page of instructions that tells an agent how to do a specialized task. In practice, that markdown can include links, copy-and-paste commands, and tool call recipes.&lt;/p&gt;
    &lt;p&gt;That sounds harmless until you remember how humans, and agents, actually consume documentation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;‚ÄúHere‚Äôs the prerequisite.‚Äù&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;‚ÄúRun this command.‚Äù&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;‚ÄúInstall the core dependency.‚Äù&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;‚ÄúPaste this in Terminal.‚Äù&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Markdown isn‚Äôt ‚Äúcontent‚Äù in an agent ecosystem. Markdown is an installer.&lt;/p&gt;
    &lt;head rend="h3"&gt;A dangerous misconception: ‚ÄúMCP makes skills safe‚Äù&lt;/head&gt;
    &lt;p&gt;Some people assume the Model Context Protocol layer makes this safer, because tools can be exposed through a structured interface, with explicit user consent and authorization controls depending on the host and server implementation.&lt;/p&gt;
    &lt;p&gt;But skills do not need to use MCP at all.&lt;/p&gt;
    &lt;p&gt;The Agent Skills specification places no restrictions on the markdown body, and skills can include whatever instructions will ‚Äúhelp agents perform the task,‚Äù including copy and paste terminal commands. And skills can also bundle scripts alongside the markdown, which means execution can happen outside the MCP tool boundary entirely.&lt;/p&gt;
    &lt;p&gt;So if your security model is ‚ÄúMCP will gate tool calls,‚Äù you can still lose to a malicious skill that simply routes around MCP through social engineering, direct shell instructions, or bundled code. MCP can be part of a safe system, but it is not a safety guarantee by itself.&lt;/p&gt;
    &lt;p&gt;Just as importantly, this is not unique to OpenClaw. ‚ÄúSkills‚Äù are increasingly portable because many agents are adopting the open Agent Skills format, in which a skill is a folder centered on a SKILL.md file with metadata and freeform instructions, and it can also bundle scripts and other resources. Even OpenAI‚Äôs documentation describes the same basic shape: a SKILL.md file plus optional scripts and assets. That means a malicious ‚Äúskill‚Äù is not just an OpenClaw problem. It is a distribution mechanism that can travel across any agent ecosystem that supports the same standard.&lt;/p&gt;
    &lt;head rend="h2"&gt;What I found: The top downloaded skill was a malware delivery vehicle&lt;/head&gt;
    &lt;p&gt;While browsing ClawHub (I won‚Äôt link it for obvious reasons), I noticed the top downloaded skill at the time was a ‚ÄúTwitter‚Äù skill. It looked normal: description, intended use, an overview, the kind of thing you‚Äôd expect to install without a second thought.&lt;/p&gt;
    &lt;p&gt;But the very first thing it did was introduce a ‚Äúrequired dependency‚Äù named ‚Äúopenclaw-core,‚Äù along with platform-specific install steps. Those steps included convenient links (‚Äúhere‚Äù, ‚Äúthis link‚Äù) that appeared to be normal documentation pointers.&lt;/p&gt;
    &lt;p&gt;They weren‚Äôt.&lt;/p&gt;
    &lt;p&gt;Both links led to malicious infrastructure. The flow was classic staged delivery:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;The skill‚Äôs overview told you to install a prerequisite.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The link led to a staging page designed to get the agent to run a command.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That command decoded an obfuscated payload and executed it.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The payload fetched a second-stage script.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The script downloaded and ran a binary, including removing macOS quarantine attributes to ensure macOS‚Äôs built-in anti-malware system, Gatekeeper, doesn‚Äôt scan it.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I‚Äôm intentionally not pasting the exact commands or URLs here. The mechanics are unfortunately straightforward, and repeating them helps attackers more than it helps defenders. The key point is that this was not ‚Äúa suspicious link.‚Äù This was a complete execution chain disguised as setup instructions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Confirmed: Infostealing malware&lt;/head&gt;
    &lt;p&gt;I downloaded the final binary safely and submitted it to VirusTotal.&lt;/p&gt;
    &lt;p&gt;The verdict was not ambiguous. It was flagged as macOS infostealing malware.&lt;/p&gt;
    &lt;p&gt;This is the type of malware that doesn‚Äôt just ‚Äúinfect your computer.‚Äù It raids everything valuable on that device:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Browser sessions and cookies&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Saved credentials and autofill data&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Developer tokens and API keys&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;SSH keys&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Cloud credentials&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Anything else that can be turned into an account takeover&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you‚Äôre the kind of person installing agent skills, you are exactly the kind of person whose machine is worth stealing from.&lt;/p&gt;
    &lt;head rend="h2"&gt;This wasn‚Äôt an isolated case. It was a campaign.&lt;/head&gt;
    &lt;p&gt;After I shared this internally, broader reporting surfaced, putting the scale into focus: hundreds of OpenClaw skills were reportedly involved in distributing macOS malware via ClickFix-style instructions.&lt;/p&gt;
    &lt;p&gt;That detail matters because it confirms what this really is.&lt;/p&gt;
    &lt;p&gt;Not a one-off malicious upload.&lt;/p&gt;
    &lt;p&gt;A deliberate strategy: use ‚Äúskills‚Äù as the distribution channel, and ‚Äúprerequisites‚Äù as the social engineering wrapper.&lt;/p&gt;
    &lt;head rend="h2"&gt;When ‚Äòhelpful‚Äô becomes hostile in an agent world&lt;/head&gt;
    &lt;p&gt;We‚Äôve spent years learning that package managers and open-source registries can become supply chain attack vectors.&lt;/p&gt;
    &lt;p&gt;Agent skill registries are the next chapter, except that the ‚Äúpackage‚Äù is documentation.&lt;/p&gt;
    &lt;p&gt;And that makes the attack path even smoother:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;People don‚Äôt expect a markdown file to be dangerous.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;People are trained to follow setup steps quickly.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;People trust ‚Äútop downloaded‚Äù as a proxy for legitimacy.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;And in agent ecosystems, the line between reading instructions and executing them collapses.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Even if an agent can‚Äôt run shell commands directly, it can still do something dangerous: it can normalize risky behavior.&lt;/p&gt;
    &lt;p&gt;It can confidently summarize a malicious prerequisite as ‚Äúthe standard install step.‚Äù It can encourage you to paste a one-liner. It can reduce hesitation.&lt;/p&gt;
    &lt;p&gt;And if your agent can execute local commands, then a malicious skill isn‚Äôt ‚Äúbad content.‚Äù It‚Äôs remote execution wrapped in friendly docs.&lt;/p&gt;
    &lt;head rend="h2"&gt;What you should do right now&lt;/head&gt;
    &lt;head rend="h4"&gt;If you are using OpenClaw or any skill registry&lt;/head&gt;
    &lt;p&gt;Do not run this on a company device. There isn‚Äôt a safe way to do it. If you already did, or you ran any ‚Äúinstall‚Äù commands from a skill, engage your security team immediately and treat it as a potential compromise.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Stop using the device for sensitive work.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Rotate sessions and secrets first: browser sessions, developer tokens, SSH keys, cloud console sessions.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Review recent sign-ins for email, source control, cloud, CI/CD, and admin consoles.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you experiment anyway, use an isolated machine with no corporate access and no saved credentials.&lt;/p&gt;
    &lt;head rend="h4"&gt;If you run a skill registry&lt;/head&gt;
    &lt;p&gt;You are operating an app store. Assume it will be abused.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Scan for one-liner installers, encoded payloads, quarantine removal, password-protected archives.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Add provenance and publisher reputation.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Put warnings and friction on external links and install steps.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Review top-ranked skills and remove malicious ones fast.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Markdown is executable intent here.&lt;/p&gt;
    &lt;head rend="h4"&gt;If you build agent frameworks&lt;/head&gt;
    &lt;p&gt;Assume skills will be weaponized.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Default-deny shell execution.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sandbox access to browsers, keychains, and credential stores.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Use permissions that are specific, time-bound, and revocable.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Add friction for remote code and command execution.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Log provenance and actions end-to-end.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Designing for the future: The trust layer agents require&lt;/head&gt;
    &lt;p&gt;This is the clearest proof yet of the point I made in my earlier post. OpenClaw is powerful because it collapses the distance between intent and execution. That is the magic. It also introduces significant risk. When capabilities are distributed as skills and installed via documentation, the registry becomes a supply chain, and the easiest install path becomes the attacker‚Äôs favorite path.&lt;/p&gt;
    &lt;p&gt;The answer is not to stop building agents. The answer is to build the missing trust layer around them. Skills need provenance. Execution needs mediation. Permissions need to be specific, revocable, and continuously enforced, not granted once and forgotten. If agents are going to act on our behalf, credentials and sensitive actions cannot be ‚Äúgrabbed‚Äù by whatever code happens to run. They need to be brokered, governed, and audited in real time.&lt;/p&gt;
    &lt;p&gt;This is exactly why we need that next layer: when ‚Äúskills‚Äù become the supply chain, the only safe future is one in which every agent has its own identity and has the minimum authority it needs right now, with access that is time-bound, revocable, and attributable.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46898615</guid><pubDate>Thu, 05 Feb 2026 11:45:03 +0000</pubDate></item><item><title>Freshpaint (YC S19) Is Hiring a Senior SWE, Data</title><link>https://www.freshpaint.io/about?ashby_jid=3a7926ba-cf51-4084-9196-4361a7e97761</link><description>&lt;doc fingerprint="2d2653329cce05e4"&gt;
  &lt;main&gt;
    &lt;p&gt;Freshpaint enables healthcare companies to collect, safeguard, and activate customer data.&lt;/p&gt;
    &lt;p&gt;Build the future of healthcare marketing.&lt;lb/&gt;&lt;lb/&gt;At Freshpaint, we‚Äôre helping healthcare companies grow without compromising patient privacy. Our platform makes it possible to use modern analytics and marketing tools while staying HIPAA compliant. Behind the scenes, we‚Äôre solving complex data problems so healthcare marketers can move fast, reach more people, and expand access to care.&lt;lb/&gt;We're a high-slope, high-EQ team that moves quickly, owns outcomes, and puts customers first. If you're curious, driven, and care deeply about impact‚Äîyou‚Äôll thrive here.&lt;lb/&gt;Join us in building the data infrastructure that powers the next era of healthcare.&lt;/p&gt;
    &lt;p&gt;Our blueprint to help us understand the types of people that are successful at Freshpaint.&lt;/p&gt;
    &lt;p&gt;Work from anywhere in the U.S. and get $150/month toward a co-working space so you can do your best work, wherever you are.&lt;/p&gt;
    &lt;p&gt;We pay at the 75th percentile to attract and retain top talent because great work deserves great pay.&lt;/p&gt;
    &lt;p&gt;Own a piece of what you‚Äôre building. Every team member gets stock options with a generous 10-year exercise window.&lt;/p&gt;
    &lt;p&gt;Take time when you need it with a required minimum of two weeks off to ensure real rest.&lt;/p&gt;
    &lt;p&gt;Wrap up early every Friday and start your weekend sooner because work-life balance matters.&lt;/p&gt;
    &lt;p&gt;Plan for what‚Äôs next. We offer a 401(k) to help you build your financial future with confidence.&lt;/p&gt;
    &lt;p&gt;We cover 100% of medical, dental, and vision insurance for you and up to 80% for your dependents. Comprehensive care, no guesswork.&lt;/p&gt;
    &lt;p&gt;We offer access to therapy, mental health check-ins, and resources to help you feel your best at work and beyond.&lt;/p&gt;
    &lt;p&gt;Twice a year, take a day off on us and enjoy up to $100 to spend on whatever brings you joy. You‚Äôve earned it.&lt;/p&gt;
    &lt;p&gt;Get $70/month to support whatever helps you thrive whether it‚Äôs your WiFi, a gym membership, or a midweek yoga class. Your wellness, your way.&lt;/p&gt;
    &lt;p&gt;We‚Äôll keep you outfitted with high-quality Freshpaint apparel and gear because you‚Äôre part of the team.&lt;/p&gt;
    &lt;p&gt;We invest in your growth. Whether it‚Äôs a conference or an online course, we‚Äôll cover the cost so you can keep leveling up.&lt;/p&gt;
    &lt;p&gt;Welcoming a new child? Take 12 weeks fully paid no matter your gender, how you become a parent, or your path to parenthood. We‚Äôve got you covered.&lt;/p&gt;
    &lt;p&gt;We‚Äôve got you covered. Life insurance is part of our commitment to supporting your whole life, not just your work.&lt;/p&gt;
    &lt;p&gt;Twice a year, we get together as a company in amazing places like Arizona, Jackson Hole, and Nashville to connect, collaborate, and build lasting team bonds.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46898713</guid><pubDate>Thu, 05 Feb 2026 12:00:03 +0000</pubDate></item><item><title>GB Renewables Map</title><link>https://renewables-map.robinhawkes.com/</link><description>&lt;doc fingerprint="5185d92eab186ed2"&gt;
  &lt;main&gt;
    &lt;p&gt;GB Renewables Map Feedback About An energy experiment by Robin Hawkes Now&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46899066</guid><pubDate>Thu, 05 Feb 2026 12:48:01 +0000</pubDate></item><item><title>CIA to Sunset the World Factbook</title><link>https://www.abc.net.au/news/2026-02-05/cia-closes-world-factbook-online-resource/106307724</link><description>&lt;doc fingerprint="2d9581fd8d839686"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;CIA says it will cease publishing the World Factbook, a free online resource used by millions&lt;/head&gt;&lt;p&gt;The US Central Intelligence Agency (CIA) has announced it will cease publishing the World Factbook, a free online resource used by millions around the globe.&lt;/p&gt;&lt;p&gt;Frequently cited by journalists and academics, the Factbook offered regularly updated statistics and information about countries and communities all over the world, in an easily understood and searchable format.&lt;/p&gt;&lt;p&gt;A statement on the CIA's website did not include a reason for the decision, simply stating that the publication had "sunset" while encouraging readers to "stay curious about the world and find ways to explore it ‚Ä¶ in person or virtually".&lt;/p&gt;Loading...&lt;p&gt;First launched during World War II as a classified internal program named JANIS (Joint Army Navy Intelligence Studies), the Factbook was originally commissioned as a way to standardise "basic intelligence" ‚Äî fundamental and factual information about the world ‚Äî across different agencies of the US government.&lt;/p&gt;&lt;p&gt;The program was taken over by the CIA in 1947 and renamed the National Intelligence Survey, before the Factbook was launched in 1971 as an annual summary of information.&lt;/p&gt;&lt;p&gt;An unclassified version was first made available to the public in 1975, and a digital version was published online in the 1990s, with the data freely available under public domain.&lt;/p&gt;&lt;p&gt;The website was particularly popular during the US school year, according to previous versions of the site, with traffic experiencing a noticeable drop-off during US summer months.&lt;/p&gt;&lt;p&gt;While no specific reason has been given for the Factbook's closure, the Trump administration has made no secret of its intent to cut government programs it does not consider to be furthering the core purpose of its agencies and departments.&lt;/p&gt;&lt;p&gt;The administration offered buyouts to every CIA employee in February last year, and is reportedly planning to cut about 1,200 further jobs at the agency over the next several years.&lt;/p&gt;&lt;p&gt;The CIA has been contacted for comment.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46899100</guid><pubDate>Thu, 05 Feb 2026 12:53:12 +0000</pubDate></item><item><title>Company as Code</title><link>https://blog.42futures.com/p/company-as-code</link><description>&lt;doc fingerprint="be89d317ecf356d2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Company as Code&lt;/head&gt;
    &lt;head rend="h3"&gt;Reimagining organisational structure for the digital age.&lt;/head&gt;
    &lt;p&gt;Last week, as I sat across from our ISO 27001 information security auditor, watching them strenuously work through our documentation, a thought struck me:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Here we are, a software company, with nearly all of our operations running in interconnected digital systems, yet the core of our business‚Äîour policies, procedures, and organisational structure‚Äîis a basic collection of documents.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It just felt ironic. We use advanced tools to automate compliance checks, store our code in version-controlled repositories, and manage our infrastructure as code. However, when describing and managing our company, we resort to digital paper and tidbits of info distributed across people in the building.&lt;/p&gt;
    &lt;p&gt;The disconnect became increasingly apparent as I reflected on our day-to-day process: 90% of our products, documents, communication, and decision-making live in digital channels. That‚Äôs data. It lives in the cloud, spread over SaaS solutions that specialise in handling individual work processes‚Äîall systems with robust APIs and programmatic access.&lt;/p&gt;
    &lt;p&gt;At the centre of it all sits a lonely island of documents: our ambitions, goals, policies and formal structures. And I think those are pretty important.&lt;/p&gt;
    &lt;p&gt;Our security posture was solid before we even considered ISO 27001 because we‚Äôd already worked hard to comply with our customer‚Äôs requirements. Between collecting evidence for controls, arguing about and updating policy wording, document review, and the actual audit, we spent hundreds of additional person-hours that could‚Äôve otherwise been spent creating great products for our users.&lt;/p&gt;
    &lt;head rend="h2"&gt;A missing link&lt;/head&gt;
    &lt;p&gt;If we desire operational data to be so rich, why do we accept organisational data to be so sparse? We‚Äôve revolutionised how we handle infrastructure with Infrastructure as Code (IaC), how we manage deployments with GitOps, and how we handle security with Policy as Code.&lt;/p&gt;
    &lt;p&gt;We see the benefit.&lt;/p&gt;
    &lt;p&gt;But when representing our organisation (the beating heart of our operations), we apply old-school methods.&lt;/p&gt;
    &lt;p&gt;Imagine if we could represent our entire organisational structure programmatically instead‚Äînot a static picture, but a living, breathing digital representation of our company that can be versioned, queried, tested, and automatically verified. A system where policy changes could be tracked as code changes, where compliance could be continuously monitored, and where the relationships between people, processes and technology could be explicitly mapped and understood.&lt;/p&gt;
    &lt;head rend="h2"&gt;Thinking bigger&lt;/head&gt;
    &lt;p&gt;Existing solutions like HRIS systems manage people data but struggle with policy relationships. GRC tools track compliance but rarely connect meaningfully to organisational structure. I‚Äôm proposing we think bigger. It‚Äôs about creating a holistic, programmatic representation of the entire organisation: a ‚Äúcompany manifest‚Äù that serves as a single source of truth for organisational structure, policy, and operations.&lt;/p&gt;
    &lt;p&gt;Consider how helpful this might be for:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Compliance audits: Instead of manually piecing together evidence from various systems, auditors could query the company manifest directly, with clear traceability between policies and their implementations.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Policy changes: Updates could be version-controlled, and automated impact analysis could show which teams and processes would be affected.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Organisational design: Leaders could model structural changes in a ‚Äústaging environment‚Äù before implementing them, gaining a better understanding of how changes cause ripple effects throughout the company.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Why isn‚Äôt this a thing?&lt;/head&gt;
    &lt;p&gt;As this idea swirls around in my mind, I find more questions than answers.&lt;/p&gt;
    &lt;p&gt;Has anyone tried this yet? If not, why not?&lt;/p&gt;
    &lt;p&gt;Is it because organisations are inherently too complex and dynamic to be represented as code? If so, that seems at odds with regulation and standards, where we expect corporate activities to be so uniform and procedural that we can reliably stamp them as compliant, non-compliant, legal, or illegal.&lt;/p&gt;
    &lt;p&gt;Is it because we haven‚Äôt yet found the right abstraction level‚Äîthe equivalent of what Infrastructure as Code did for system administration?&lt;/p&gt;
    &lt;p&gt;The tools and concepts exist: Graph databases for representing organisational relationships, domain-specific languages for describing business rules, and API-first architectures for integration.&lt;/p&gt;
    &lt;p&gt;Maybe what‚Äôs missing is a framework to bring these ideas together in a way that‚Äôs powerful enough to be useful and simple enough to be used.&lt;/p&gt;
    &lt;head rend="h2"&gt;Putting it into practice&lt;/head&gt;
    &lt;p&gt;Let‚Äôs think about how this could work.&lt;/p&gt;
    &lt;p&gt;In this section, I‚Äôll fantasise about what I would want from ‚ÄúCompany as Code.‚Äù Then, I‚Äôll map that to some system components that could address those needs.&lt;/p&gt;
    &lt;p&gt;As an engineer and business stakeholder, I would want a company model to be:&lt;/p&gt;
    &lt;head rend="h4"&gt;Queryable&lt;/head&gt;
    &lt;p&gt;The system must trace relationships between people, policies, and systems‚Äîsimilar to code dependency tracking. Users should easily see the organisation from different angles, such as which people are affected by a policy and who owns it.&lt;/p&gt;
    &lt;head rend="h4"&gt;Versionable&lt;/head&gt;
    &lt;p&gt;Explicit tracking of organisational changes, including who made them, what changed, and why. This is crucial for audits and understanding organisational evolution.&lt;/p&gt;
    &lt;head rend="h4"&gt;Integrated&lt;/head&gt;
    &lt;p&gt;Seamless data exchange with existing tools (Azure, Slack, etc.) to maintain an up-to-date organisational picture and enforce tool configurations based on policy.&lt;/p&gt;
    &lt;head rend="h4"&gt;Testable&lt;/head&gt;
    &lt;p&gt;A ‚Äústaging environment‚Äù where organisational changes can be modeled before implementation, supporting automated tests for individual rules and controls.&lt;/p&gt;
    &lt;head rend="h4"&gt;Accessible&lt;/head&gt;
    &lt;p&gt;Though powered by code, the interface should be intuitive enough for non-technical leaders to use effectively.&lt;/p&gt;
    &lt;p&gt;Bringing this vision to life requires several puzzle pieces. Each component must address specific requirements to approximate something that can be powerful while being relatively simple to use.&lt;/p&gt;
    &lt;head rend="h3"&gt;A declarative language for organisations&lt;/head&gt;
    &lt;p&gt;Drawing inspiration from Infrastructure as Code tools like Terraform, let‚Äôs imagine a declarative Domain Specific Language (DSL) that reads naturally while expressing a formal structure.&lt;/p&gt;
    &lt;p&gt;The basic syntax follows a clear pattern:&lt;/p&gt;
    &lt;code&gt;EntityType "Identifier" {
    References = AnotherEntity.Identifier
    Attribute = Value
    ListAttribute = [
        "Item One",
        "Item Two"
    ]
}&lt;/code&gt;
    &lt;p&gt;A type, unique identifier, and set of attributes define each entity. Entities can reference each other using dot notation, creating a web of relationships that forms our organisational graph.&lt;/p&gt;
    &lt;head rend="h4"&gt;Specifying an organisation&lt;/head&gt;
    &lt;p&gt;Let's walk through how you could define a small engineering team in this language:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;First, let‚Äôs define the roles that exist in the organisation:&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;Role "SoftwareEngineer" {
    Responsibilities = [
        "Write clean, maintainable code",
        "Participate in code reviews",
        "Document technical decisions"
    ]
}

Role "EngineeringManager" {
    Responsibilities = [
        "Provide technical leadership",
        "Conduct performance reviews",
        "Manage team resources"
    ]
}&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Next, we‚Äôll create an organisational unit for our team:&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;OrganisationalUnit "EngineeringTeam" {
    Department = "Engineering"
    CostCenter = "ENG-001"
}&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;With these structures in place, we can define the actual people and their relationships:&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;Person "AliceSmith" {
    FullName = "Alice Smith"
    Role = Role.EngineeringManager
    Unit = OrganisationalUnit.EngineeringTeam
    Email = "alice.smith@company.com"
}

Person "BobJohnson" {
    FullName = "Bob Johnson"
    Role = Role.SoftwareEngineer
    Unit = OrganisationalUnit.EngineeringTeam
    Manager = Person.AliceSmith
    Email = "bob.johnson@company.com"
}&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Policy definitions create a framework for compliance:&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;PolicyGroup "SecurityPolicies" {
    Owner = Person.AliceSmith
}

PolicyRule "MFARequired" {
    Group = PolicyGroup.SecurityPolicies
    Enforcement = "Mandatory"
    ComplianceLevel = "Critical"
}&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Finally, we can map these policies to external requirements:&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;ExternalRequirement "ISO27001_A9_4_1" {
    Standard = "ISO 27001:2013"
    Control = "A.9.4.1"
    ComplianceLevel = "Mandatory"
}

ComplianceMapping "MFACompliance" {
    Requirement = ExternalRequirement.ISO27001_A9_4_1
    ImplementingPolicies = [PolicyRule.MFARequired]
}&lt;/code&gt;
    &lt;p&gt;This declarative approach allows us to build a complete picture of our organisation, from high-level structures to individual policies and their regulatory implications. Each definition is clear and self-documenting, while the references between entities create a graph of relationships that can be analysed, validated, and used to automate organisational processes.&lt;/p&gt;
    &lt;p&gt;With a representation like this, we benefit from organising definitions into logical files and directories, treating organisational changes like code changes: versioned, reviewed, and validated before application.&lt;/p&gt;
    &lt;p&gt;This enables practices like reviewing changes through pull requests, testing policy modifications before rollout, and automatically generating compliance documentation while tracking the evolution of organisational structures over time.&lt;/p&gt;
    &lt;head rend="h3"&gt;Building a model&lt;/head&gt;
    &lt;p&gt;While Infrastructure as Code tools like Terraform work with directed acyclic graphs (DAGs) to determine deployment order, an organisation's structure is inherently more interconnected. People manage other people, policies reference activities that refer back to policies, and teams have complex interdependencies. This calls for an undirected cyclic graph model to represent these rich relationships.&lt;/p&gt;
    &lt;code&gt;public record Node(
    string Id,          // e.g. "Person.AliceSmith"
    string Type,        // e.g. "Person", "PolicyRule"
    List&amp;lt;Edge&amp;gt; Relations = null
);

public record Edge(
    string FromId, 
    string ToId,
    string RelationType, // e.g. "ManagedBy"
);

public class CompanyGraph
{
    private Dictionary&amp;lt;string, Node&amp;gt; _nodes = new();
    private List&amp;lt;Edge&amp;gt; _edges = new();

    public void AddNode(string id, string type) =&amp;gt;
        _nodes[id] = new Node(id, type);

    public void AddRelation(string fromId, string toId, string type)
    {
        var edge = new Edge(fromId, toId, type);
        _edges.Add(edge);
        (_nodes[fromId].Relations ??= new()).Add(edge);
        (_nodes[toId].Relations ??= new()).Add(edge);
    }

    // Example: Find all requirements impacted by changing a policy
    public IEnumerable&amp;lt;Node&amp;gt; GetImpactedRequirements(string policyId) =&amp;gt;
        _nodes[policyId].Relations
            .Where(e =&amp;gt; e.RelationType == "ImplementsRequirement")
            .Select(e =&amp;gt; _nodes[e.FromId == policyId ? e.ToId : e.FromId])
            .Where(req =&amp;gt; req.Type == "ExternalRequirement");
}&lt;/code&gt;
    &lt;p&gt;The example above shows a naive implementation of a queryable graph structure based on a declarative DSL. This representation makes it easier to answer questions requiring multiple references in the structure, such as "Which external requirements would be affected if we changed our MFA policy?"&lt;/p&gt;
    &lt;head rend="h3"&gt;Bridging models and reality&lt;/head&gt;
    &lt;p&gt;A DSL can define an organisation's structure and rules, but the model must be connected to real-world data to be useful. This requires a storage strategy that can:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Persist the organisational graph itself&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Store data associated with graph entities (like evidence)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Enable validation of considered changes&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A way to deliver this at scale would be to combine several data stores: A graph database for the organisational model, a relational database for associated data, and an event store for audit trail and change tracking. If you wanted to start small, you could serialise all this information to your local filesystem instead.&lt;/p&gt;
    &lt;p&gt;To activate external data, we would need an integration framework with a plug-in architecture to bridge the organisational model and production systems. This would handle three key aspects: (1) data collection from integrated systems like GitHub or Azure, mapping evidence to nodes in our graph; (2) policy validation that programmatically checks collected evidence against rules; and (3) policy enforcement where organisational changes automatically trigger updates across connected systems‚Äîfrom employee provisioning to access permission changes.&lt;/p&gt;
    &lt;p&gt;The DSL would supply this functionality using built-in modules or user-supplied plug-ins to perform the work needed to interact with other systems. Let‚Äôs imagine a Control entity in the DSL which uses a custom script to perform routine checks on MFA usage and links results to the compliance mapping:&lt;/p&gt;
    &lt;code&gt;Control "MFAMonitoring" {
    Implements = ComplianceMapping.MFACompliance
    
    Verify {
        Script = "Security/mfa-checks.js"
        Methods = [
            "allUsersHaveMfaEnabled"
        ]
        Frequency = "Daily"
    }
}&lt;/code&gt;
    &lt;p&gt;Then in &lt;code&gt;security/mfa-checks.js&lt;/code&gt;: &lt;/p&gt;
    &lt;code&gt;export async function allUsersHaveMfaEnabled() {
    const users = await myAuthClient.listUsers()
    return users.every(user =&amp;gt; user.mfaEnabled)
}&lt;/code&gt;
    &lt;p&gt;The solution should be open and extendable to maximise its usefulness, allowing for custom integrations, validations, and automation. Terraform does a good job of this with its ‚ÄúProviders‚Äù plug-in architecture, although integrations to inspect and modify data in corporate systems might need to support more custom scripting.&lt;/p&gt;
    &lt;p&gt;For organisations wanting to test this approach, you could start small:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Model just your organisational structure and reporting lines.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Add key policies and compliance mappings.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Begin connecting to your most critical systems.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Making it shine&lt;/head&gt;
    &lt;p&gt;A code-based declaration of an organisation offers powerful capabilities for technologists, but we also need to acknowledge that many business stakeholders don‚Äôt ‚Äúthink in code‚Äù.&lt;/p&gt;
    &lt;p&gt;The elegance of a DSL doesn‚Äôt have to be limited to those most comfortable with text editors and version control software. A genuinely accessible ‚ÄúCompany as Code‚Äù solution must connect a programmatic representation and the business users who make daily decisions about organisation structure, policy and compliance.&lt;/p&gt;
    &lt;p&gt;This could be solved with a low-code / no-code interface where:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Business leaders drag and drop organisational entities and reporting structures while the system generates code declarations behind the scenes.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Compliance officers use simple forms to define policies and instantly visualise which parts of the business they affect. When regulations change, they can quickly identify gaps or conflicts through visual highlighting.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Technologists keep the codebase organised and provide data integrations and tools to implement policy in external systems.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With an approach like this, we can maintain the rigour of the code model while making it accessible to everyone. Changes through the interface update the underlying code, preserving that single source of truth that can be versioned and validated.&lt;/p&gt;
    &lt;head rend="h3"&gt;Final notes&lt;/head&gt;
    &lt;p&gt;Beyond the technical feasibility, the real promise lies in the organisational benefits: faster audits, clearer decision-making, and better understanding of changes' impact before implementing them. Hundreds of hours spent on compliance documentation could instead be invested in creating value.&lt;/p&gt;
    &lt;p&gt;In this post, I hoped to establish that a codification of organisational structure is missing and that it‚Äôs buildable. Practical? Don‚Äôt know. Viable? I don‚Äôt have the answer. Buildable, though? Yes. I believe so.&lt;/p&gt;
    &lt;p&gt;Let me know what you think about it.&lt;/p&gt;
    &lt;p&gt;Daniel Rothmann runs 42futures, where he helps technical leaders validate high-stakes technical decisions through structured software pilots.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46899132</guid><pubDate>Thu, 05 Feb 2026 12:56:28 +0000</pubDate></item><item><title>The New Collabora Office for Desktop</title><link>https://www.collaboraonline.com/collabora-office/</link><description>&lt;doc fingerprint="3232eb37bba6f3e5"&gt;
  &lt;main&gt;
    &lt;p&gt;We√¢re excited to share the first release of the new Collabora Office for desktop √¢ bringing the familiar, powerful Collabora Online experience, to run locally on Windows, macOS, and Linux.&lt;/p&gt;
    &lt;p&gt;Open it and feel instantly at home: ODF or DOCX, quick edits or deep dives, a clean, beautiful interface that helps you get work done without getting in the way.&lt;/p&gt;
    &lt;p&gt;Supports: .odt, .docx, .doc, .pdf, .rtf&lt;/p&gt;
    &lt;p&gt;Supports: .ods, .xlsx, .xls, .xlsm, .csv&lt;/p&gt;
    &lt;p&gt;Supports: .odp, .ppt, .pptx&lt;/p&gt;
    &lt;p&gt;Supports: .odg, .vsd, .vsdx&lt;/p&gt;
    &lt;p&gt;We love LibreOffice. We are privileged to be the largest code contributors to the codebase, Collabora employs several founders of The Document Foundation, and many of the top committers. We offer a Long Term supported product based on LibreOffice, branded as Collabora Office Classic, and are deeply grateful for and acknowledge many skilled community contributors we work alongside, as well as the incredible range of features that LibreOffice code enables.&lt;/p&gt;
    &lt;p&gt;Get in touch for a quote, ask a question or sign up to the newsletter so you don√¢t miss out on all the latest news.&lt;/p&gt;
    &lt;p&gt;Enterprise support is coming. For our other products we offer LTS support for 2 years as standard, with up to 5 years if required.&lt;/p&gt;
    &lt;p&gt;Get in touch for a quote, ask a question or sign up to the newsletter so you don√¢t miss out on all the latest news.&lt;/p&gt;
    &lt;p&gt;Collabora Online is a powerful collaborative office suite that supports all major document, spreadsheet and presentation file formats, which you can integrate into your own infrastructure.&lt;/p&gt;
    &lt;p&gt;Because sometimes you need to do your work offline. Transition from Collabora Online, to Collabora Office and back.&lt;/p&gt;
    &lt;p&gt;Collabora Online Development Edition (CODE) is the development version of Collabora Online. It is perfect for home use or small teams, but not recommended for production environments.&lt;/p&gt;
    &lt;p&gt;Consultancy packages available for tailored support&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46899591</guid><pubDate>Thu, 05 Feb 2026 13:47:59 +0000</pubDate></item><item><title>CIA suddenly stops publishing, removes archives of The World Factbook</title><link>https://simonwillison.net/2026/Feb/5/the-world-factbook/</link><description>&lt;doc fingerprint="4245194d4f40925c"&gt;
  &lt;main&gt;
    &lt;p&gt;Spotlighting The World Factbook as We Bid a Fond Farewell (via) Somewhat devastating news today from CIA:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;One of CIA‚Äôs oldest and most recognizable intelligence publications, The World Factbook, has sunset.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;There's not even a hint as to why they decided to stop maintaining this publication, which has been their most useful public-facing initiative since 1971 and a cornerstone of the public internet since 1997.&lt;/p&gt;
    &lt;p&gt;In a bizarre act of cultural vandalism they've not just removed the entire site (including the archives of previous versions) but they've also set every single page to be a 302 redirect to their closure announcement.&lt;/p&gt;
    &lt;p&gt;The Factbook has been released into the public domain since the start. There's no reason not to continue to serve archived versions - a banner at the top of the page saying it's no longer maintained would be much better than removing all of that valuable content entirely.&lt;/p&gt;
    &lt;p&gt;Up until 2020 the CIA published annual zip file archives of the entire site. Those are available (along with the rest of the Factbook) on the Internet Archive.&lt;/p&gt;
    &lt;p&gt;I downloaded the 384MB &lt;code&gt;.zip&lt;/code&gt; file for the year 2020 and extracted it into a new GitHub repository, simonw/cia-world-factbook-2020. I've enabled GitHub Pages for that repository so you can browse the archived copy at simonw.github.io/cia-world-factbook-2020/.&lt;/p&gt;
    &lt;p&gt;Here's a neat example of the editorial voice of the Factbook from the What's New page, dated December 10th 2020:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Years of wrangling were brought to a close this week when officials from Nepal and China announced that they have agreed on the height of Mount Everest. The mountain sits on the border between Nepal and Tibet (in western China), and its height changed slightly following an earthquake in 2015. The new height of 8,848.86 meters is just under a meter higher than the old figure of 8,848 meters. The World Factbook rounds the new measurement to 8,849 meters and this new height has been entered throughout the Factbook database.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;Recent articles&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Distributing Go binaries like sqlite-scanner through PyPI using go-to-wheel - 4th February 2026&lt;/item&gt;
      &lt;item&gt;Moltbook is the most interesting place on the internet right now - 30th January 2026&lt;/item&gt;
      &lt;item&gt;Adding dynamic features to an aggressively cached website - 28th January 2026&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46899808</guid><pubDate>Thu, 05 Feb 2026 14:11:13 +0000</pubDate></item><item><title>European Commission Trials Matrix to Replace Teams</title><link>https://www.euractiv.com/news/commission-trials-european-open-source-communications-software/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46901452</guid><pubDate>Thu, 05 Feb 2026 16:33:56 +0000</pubDate></item><item><title>Maihem (YC W24): hiring sr robotics perception engineer (London, on-site)</title><link>https://jobs.ashbyhq.com/maihem/8da3fa8b-5544-45de-a99e-888021519758</link><description>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46901768</guid><pubDate>Thu, 05 Feb 2026 17:00:07 +0000</pubDate></item><item><title>Everyone Is Stealing TV</title><link>https://www.theverge.com/streaming/873416/piracy-streaming-boxes</link><description>&lt;doc fingerprint="b6a88914298233ed"&gt;
  &lt;main&gt;
    &lt;p&gt;Walk the rows of the farmers market in a small, nondescript Texas town about an hour away from Austin, and you might stumble across something unexpected: In between booths selling fresh, local pickles and pies, there‚Äôs a table piled high with generic-looking streaming boxes, promising free access to NFL games, UFC fights, and any cable TV network you can think of.&lt;/p&gt;
    &lt;p&gt;It‚Äôs called the SuperBox, and it‚Äôs being demoed by Jason, who also has homemade banana bread, okra, and canned goods for sale. ‚ÄúPeople are sick and tired of giving Dish Network $200 a month for trash service,‚Äù Jason says. His pitch to rural would-be cord-cutters: Buy a SuperBox for $300 to $400 instead, and you‚Äôll never have to shell out money for cable or streaming subscriptions again.&lt;/p&gt;
    &lt;p&gt;I met Jason through one of the many Facebook groups used as support forums for rogue streaming devices like the SuperBox. To allow him and other users and sellers of these devices to speak freely, we‚Äôre only identifying them by their first names or pseudonyms.&lt;/p&gt;
    &lt;p&gt;‚ÄúPeople are sick and tired of giving Dish Network $200 a month for trash service.‚Äù&lt;/p&gt;
    &lt;p&gt;SuperBox and its main competitor, vSeeBox, are gaining in popularity as consumers get fed up with what TV has become: Pay TV bundles are incredibly expensive, streaming services are costlier every year, and you need to sign up for multiple services just to catch your favorite sports team every time they play. The hardware itself is generic and legal, but you won‚Äôt find these devices at mainstream stores like Walmart and Best Buy because everyone knows the point is accessing illegal streaming services that offer every single channel, show, and movie you can think of. But there are hundreds of resellers like Jason all across the United States who aren‚Äôt bothered by the legal technicalities of these devices. They‚Äôre all part of a massive, informal economy that connects hard-to-pin-down Chinese device makers and rogue streaming service operators with American consumers looking to take cord-cutting to the next level.&lt;/p&gt;
    &lt;p&gt;This economy paints a full picture of America, and characters abound. There‚Äôs a retired former cop in upstate New York selling the vSeeBox at the fall festival of his local church. A Christian conservative from Utah who pitches rogue streaming boxes as a way of ‚Äúdefunding the swamp and refunding the kingdom.‚Äù An Idaho-based smart home vendor sells vSeeBoxes alongside security cameras and automated window shades. Midwestern church ladies in Illinois and Indian uncles in New Jersey all know someone who can hook you up: real estate agents, MMA fighters, wedding DJs, and special ed teachers are all among the sellers who form what amounts to a modern-day bootlegging scheme, car trunks full of streaming boxes just waiting for your call.&lt;/p&gt;
    &lt;p&gt;These folks are a permanent thorn in the side of cable companies and streaming services, who have been filing lawsuits against resellers of these devices for years, only to see others take their place practically overnight.&lt;/p&gt;
    &lt;p&gt;Jason, for his part, doesn‚Äôt beat around the bush about where he stands in this conflict. ‚ÄúI hope it puts DirecTV and Dish out of business,‚Äù he tells me.&lt;/p&gt;
    &lt;p&gt;Jason isn‚Äôt alone in his disdain for big TV providers. ‚ÄúMy DirecTV bill was just too high,‚Äù says&lt;/p&gt;
    &lt;p&gt;Eva, a social worker and grandmother from California. Eva bought her first vSeeBox two years ago when she realized she was paying nearly $300 a month for TV, including premium channels. Now, she‚Äôs watching those channels for free, saving thousands of dollars. ‚ÄúIt turned out to be a no-brainer,‚Äù Eva says.&lt;/p&gt;
    &lt;p&gt;Natalie, a California-based software consultant, paid about $120 a month for cable. Then, TV transitioned to streaming, and everything became a subscription. All those subscriptions add up ‚Äî especially if you‚Äôre a sports fan. ‚ÄúYou need 30 subscriptions just to watch every game,‚Äù she complains. ‚ÄúIt‚Äôs gotten out of control. It‚Äôs not sustainable,‚Äù she says.&lt;/p&gt;
    &lt;p&gt;Natalie bought her first SuperBox five years ago. At the time, she was occasionally splurging on pay-per-view fights, which would cost her anywhere from $70 to $100 a pop. SuperBox‚Äôs $200 price tag seemed like a steal. ‚ÄúYou‚Äôre getting the deal of the century,‚Äù she says.&lt;/p&gt;
    &lt;p&gt;‚ÄúI‚Äôve been on a crusade to try to convert everyone.‚Äù&lt;/p&gt;
    &lt;p&gt;James, a gas station repairman from Alabama, estimates that he used to pay around $125 for streaming subscriptions every month. ‚ÄúThe general public is being nickeled and dimed into the poor house,‚Äù he says.&lt;/p&gt;
    &lt;p&gt;James says that he was hesitant about forking over a lot of money upfront for a device that could turn out to be a scam. ‚ÄúI was nervous, but I figured: If it lasts four months, it pays for itself,‚Äù he tells me. James has occasionally encountered some glitches with his vSeeBox, but not enough to make him regret his purchase. ‚ÄúI‚Äôm actually in the process of canceling all the streaming services,‚Äù he says.&lt;/p&gt;
    &lt;p&gt;It‚Äôs stories like these, spread among friends, neighbors, and Facebook acquaintances, that have helped devices like SuperBox and vSeeBox gain a foothold across America. Natalie got her first SuperBox from a friend, and has since bought two or three more for family members. James got introduced to these devices through a friend as well, as did Eva. And while James quickly became a professional seller, Eva has simply been spreading the word ‚Äî and buying additional boxes for her extended family ‚Äî out of conviction.&lt;/p&gt;
    &lt;p&gt;‚ÄúI‚Äôve been on a crusade to try to convert everyone,‚Äù she says.&lt;/p&gt;
    &lt;p&gt;For years, tech-savvy TV fans have found ways to watch live sports events and other TV programs in shady ways, either by paying for bootleg streaming services or watching free on sketchy websites plastered with porn ads. The most dedicated pirates use media center apps like Kodi with rogue add-ons on their PCs or Mac Minis, but piracy has gotten more and more accessible over time. The Play Store on Android TVs is full of browsers optimized for those shady streaming sites. Amazon won‚Äôt ever admit it, but the popularity of Fire TV Sticks is in part due to how easy it is to root them and sideload piracy apps.&lt;/p&gt;
    &lt;p&gt;SuperBox and vSeeBox have simply turned all of this into easy-to-sell products, with a thin layer of legal deniability. vSeeBox guides users to a pirate streaming service called ‚ÄúHeat‚Äù; SuperBox‚Äôs service is ‚ÄúBlue TV.‚Äù You won‚Äôt find apps for either service on Google Play or any other app store; users who have tried report that it‚Äôs impossible to run them on any other third-party device, suggesting that they were custom-built by or on behalf of the makers of SuperBox and vSeeBox.&lt;/p&gt;
    &lt;p&gt;The boxes don‚Äôt ship with the apps preinstalled ‚Äî but they make it really easy to do so. vSeeBox, for instance, ships with an Android TV launcher that has a row of recommended apps, displaying download links to install apps for the Heat streaming service with one click. New SuperBox owners won‚Äôt have trouble accessing the apps, either. ‚ÄúOnce you open your packaging, there are instructions,‚Äù Jason says. ‚ÄúFollow them to a T.‚Äù&lt;/p&gt;
    &lt;p&gt;Once downloaded, these apps mimic the look and feel of traditional TV and streaming services. vSeeBox‚Äôs Heat, for instance, has a dedicated ‚ÄúHeat Live‚Äù app that resembles Sling TV, Fubo, or any other live TV subscription service, complete with a program guide and the ability to flip through channels with your remote control. SuperBox‚Äôs Blue TV app does the same thing, while a separate ‚ÄúBlue Playback‚Äù app even offers some time-shifting functionality, similar to Hulu‚Äôs live TV service. Natalie estimates that she can access between 6,000 and 8,000 channels on her SuperBox, including premium sports networks and movie channels, and hundreds of local Fox, ABC, and CBS affiliates from across the United States.&lt;/p&gt;
    &lt;p&gt;Most vSeeBox and SuperBox users don‚Äôt seem to care where exactly the content is coming from, as long as they can access the titles they‚Äôre looking for.&lt;/p&gt;
    &lt;p&gt;How exactly these apps are able to offer all those channels is one of the streaming boxes‚Äô many mysteries. ‚ÄúAll the SuperBox channels are streaming out of China,‚Äù Jason suggests, in what seems like a bit of folk wisdom. In a 2025 lawsuit against a SuperBox reseller, Dish Network alleged that at least some of the live TV channels available on the device are being ripped directly from Dish‚Äôs own Sling TV service. ‚ÄúAn MLB channel transmitted on the service [showed] Sling‚Äôs distinguishing logo in the bottom right corner,‚Äù the lawsuit claims. The operators of those live TV services use dedicated software to crack Sling‚Äôs DRM, and then retransmit the unprotected video feeds on their services, according to the lawsuit.&lt;/p&gt;
    &lt;p&gt;Heat and Blue TV also each have dedicated apps for Netflix-style on-demand viewing, and the services often aren‚Äôt shy about the source of their programming. Heat‚Äôs ‚ÄúVOD Ultra‚Äù app helpfully lists movies and TV shows categorized by provider, including HBO Max, Disney Plus, Starz, and Hulu. Some of this content may be ripped directly from legitimate services, similar to the way rogue service operators gain access to live TV feeds. Another possibility was highlighted in a 2019 indictment of pirate streaming service operators: To offer their paying customers a Netflix-like experience even for movies that were still in theaters, the defendants allegedly went old-school and downloaded videos from newsgroups and torrent sites with the help of automated scripts.&lt;/p&gt;
    &lt;p&gt;Most vSeeBox and SuperBox users don‚Äôt seem to care where exactly the content is coming from, as long as they can access the titles they‚Äôre looking for.&lt;/p&gt;
    &lt;p&gt;‚ÄúI haven‚Äôt found anything missing yet,‚Äù James says. ‚ÄúI‚Äôve actually been able to watch shows from streaming services I didn‚Äôt have before.‚Äù&lt;/p&gt;
    &lt;p&gt;The companies behind SuperBox and vSeeBox launched in 2019 and 2020, respectively, which was perfect timing: With everyone cooped up inside during the covid-19 pandemic, streaming boomed, and people like Natalie burned through the massive libraries of their boxes in no time. ‚ÄúWe watched it all,‚Äù she jokes.&lt;/p&gt;
    &lt;p&gt;However, rogue streaming boxes have been around for much longer than either company. A handful of Chinese manufacturers first began churning out these devices over a decade ago with a much narrower audience in mind: Devices like TVPad, Moon Box, and CrownTV all specifically targeted Asian expats by providing free access to TV networks from their home countries for a one-time $200-to-$300 purchase price.&lt;/p&gt;
    &lt;p&gt;TVPad boasted on its now-defunct website that consumers would have access to ‚Äúover 100+ popular Chinese channels, more than 40 Korean channels, 20+ Japanese channels,‚Äù and more. It was a huge hit among expats: The company behind TVPad is said to have sold 3 million units worldwide, according to a legal filing.&lt;/p&gt;
    &lt;p&gt;TVPad sold the device through its own website, but also started to use a network of local resellers. TVPads would pop up in malls and mom-and-pop stores in Asian neighborhoods across the United States, where they were openly sold next to snacks and groceries. In the spring of 2014, a Los Angeles-based reseller even rented a billboard atop a medical plaza in the city‚Äôs Koreatown neighborhood, advertising the device as capable of playing South Korean TV networks without monthly fees.&lt;/p&gt;
    &lt;p&gt;It didn‚Äôt take long for overseas rights holders to take notice. China‚Äôs state broadcaster CCTV teamed up with Dish to sue the maker of TVPad in 2015, eventually putting the company behind it out of business.&lt;/p&gt;
    &lt;p&gt;Others quickly filled the void, and the makers of these devices increasingly embraced an interesting design choice: While the original TVPad looked more or less like an Apple TV clone, manufacturers started to add front-facing LED displays with clocks and channel numbers ‚Äî the kinds of things you‚Äôd expect to see on a satellite TV receiver.&lt;/p&gt;
    &lt;p&gt;That‚Äôs no accident, according to researchers from Australia‚Äôs RMIT University, who wrote in a 2019 paper about TVPad and similar devices that their ‚Äúdesign and user experience evoke longer histories of diasporic satellite television.‚Äù Expat communities had long tapped into programming from their home countries one way or another, be it through official satellite subscription services or black-market receivers capable of descrambling those stations for free. Going down the pirate route seemed a lot less risky when the rights holders were half a world away.&lt;/p&gt;
    &lt;p&gt;Chinese device makers learned their lessons from that first wave of expat streaming boxes: They realized that the market for rogue streamers was much bigger than just the diaspora, and they stopped openly talking about piracy, leaving the riskier parts of their business to their American resellers. Some also kept the clock, with SuperBox still looking more like a satellite TV receiver than an Apple TV.&lt;/p&gt;
    &lt;p&gt;Holdover digital clocks aside, SuperBox and vSeeBox aren‚Äôt shy about hyping their products. The companies sell Android-based streaming devices with a variety of different specs and price points, and both take creative freedom with their marketing. The vSeeBox V6 Plus is being advertised as an 8K HDR Android TV box; its chipset does not actually support 8K playback. SuperBox‚Äôs latest S7 Max device promises 6K video ‚Äî a resolution used almost exclusively for professional video production. There are no 6K TVs available for sale to consumers, as SuperBox‚Äôs own website points out.&lt;/p&gt;
    &lt;p&gt;All of this doesn‚Äôt exactly instill confidence in the security of these devices. ‚ÄúYou don‚Äôt know if there is any kind of malware built into the box,‚Äù says Mike, an IT worker from Pennsylvania who uses a vSeeBox.. It‚Äôs a reasonable concern: In the past, cybercriminals have exploited insecure streaming boxes to commit ad fraud and other crimes. In a recent lawsuit, Google estimated that one such botnet consisted of 10 million streaming boxes and other personal devices, though the lawsuit did not mention vSeeBox or SuperBox as affected.&lt;/p&gt;
    &lt;p&gt;A recent report also suggested that SuperBox devices were connecting to Grass, a residential proxy network that lets end users monetize unused internet bandwidth. Grass founder Andrej Radonjic tells me that there‚Äôs no connection between the device and his service. ‚ÄúSuperBox is not a user, customer, or affiliate of Grass, and Grass does not permit third-party installations of its software in consumer devices,‚Äù Radonjic says. ‚ÄúGrass has not encountered its software being used by any specific smart TV box or streaming device.‚Äù&lt;/p&gt;
    &lt;p&gt;With hard-to-pin-down companies operating from overseas through an army of small-time resellers, these devices arguably represent much higher security risks than anything made by Apple or Google. Mike admits that he has concerns, but they haven‚Äôt stopped him from using his box.&lt;/p&gt;
    &lt;p&gt;If you try to buy a SuperBox or vSeeBox by searching for them online, you‚Äôll find countless websites, all looking like official company stores, but run by individual resellers. The same is true for the seller-run subreddits and Facebook groups that double as customer support. Getting honest feedback from them can be challenging.&lt;/p&gt;
    &lt;p&gt;Jason had his doubts before he became a streaming box reseller. Sending an unknown company in China a few thousand dollars for a wholesale order of streaming devices seemed risky. ‚ÄúI was so skeptical [of] ordering from SuperBox,‚Äù he admits. What ultimately convinced him were weeks of back-and-forth with a gentleman from Hong Kong, who walked him through the sales process and told him that the company has fewer than 500 resellers in the United States.&lt;/p&gt;
    &lt;p&gt;SuperBox and vSeeBox rely on such direct relationships to recruit resellers, with company representatives often using personal Facebook, WhatsApp, and Instagram accounts for outreach. In many cases, these accounts feature likenesses of young, attractive women, with profile pictures ripped from fashion websites and Instagram model profiles.&lt;/p&gt;
    &lt;p&gt;‚ÄúObviously, it is definitely piracy.‚Äù&lt;/p&gt;
    &lt;p&gt;After signing him up as a reseller, Jason‚Äôs SuperBox contact also recruited him for a unique side gig: Whenever Jason finds a SuperBox advertised for less than the company‚Äôs suggested retail price, he buys it and sells it back to the company for a premium. He says that the SuperBox maker then checks the device‚Äôs MAC address against a list of past sales and remotely deactivates all boxes it sold to the reseller who openly advertised the unauthorized discount.&lt;/p&gt;
    &lt;p&gt;Offending sellers are then asked to pay a fine, Jason says. Consumers who happened to buy a box for the wrong price find it locked, with an onscreen warning telling them to contact their service provider. vSeeBox engages in similar practices, Mike says: ‚ÄúThey can essentially shut off the boxes.‚Äù&lt;/p&gt;
    &lt;p&gt;To alleviate the concerns of would-be buyers fearful of getting scammed, device makers maintain online verification tools. Each reseller gets a certificate with a unique code. Enter that code into a web form, and the company will tell you if the reseller in question is in good standing.&lt;/p&gt;
    &lt;p&gt;As a result, many resellers have stopped advertising device prices online altogether, only adding to the mysteries of rogue streaming boxes. Neither company responded to multiple interview requests for this story, and both are obtuse about their owners and executive leadership.&lt;/p&gt;
    &lt;p&gt;Resellers and users are more than willing to fill those gaps with wild rumors. One Facebook post claims that SuperBox was developed by a Comcast engineer who wasn‚Äôt willing to share the fruits of his labor with his employer. ‚ÄúThey tried to buy this person‚Äôs product and silence,‚Äù the post ominously states. AT&amp;amp;T supposedly also tried to buy the device, but ‚ÄúSuperBox said no.‚Äù&lt;/p&gt;
    &lt;p&gt;Jason had heard a different story from a friend. SuperBox was engineered by a group of veterans from California, he tells me, and ‚ÄúSpectrum Internet‚Äù secretly owns 20 percent of their company. I wasn‚Äôt able to confirm the claim about the veterans. Spectrum Internet, however, is not a company, but the brand name for internet and pay TV services sold by telco giant Charter ‚Äî a company that generated more than $55 billion with its cable TV and broadband business in 2024, and seemingly would have very little to gain from dabbling in pirate streaming hardware on the side. Charter declined to comment.&lt;/p&gt;
    &lt;p&gt;It‚Äôs clear to pretty much everyone that SuperBox and vSeeBox don‚Äôt have the licensing agreements required to stream thousands of TV channels, live sports events, and on-demand movies. ‚ÄúObviously, it is definitely piracy,‚Äù Mike says.&lt;/p&gt;
    &lt;p&gt;‚ÄúI‚Äôm sure it‚Äôs not super legal,‚Äù Natalie says. However, with these kinds of devices regularly popping up on major e-commerce sites, she didn‚Äôt bother researching the legal intricacies. ‚ÄúI don‚Äôt care,‚Äù she says.&lt;/p&gt;
    &lt;p&gt;Resellers have been sued, and are often made to pay hefty fines. Dish Network sued a California-based SuperBox seller last summer, alleging copyright infringement. The case is ongoing. Dish also won a case against a vSeeBox reseller in 2024, forcing defendants to cough up $1.25 million in damages for the sale of 500 rogue streaming devices. A year ago, another vSeeBox seller was ordered to pay $405,000 in damages for the sale of 162 devices.&lt;/p&gt;
    &lt;p&gt;But none of that feels relevant to the people using these services. ‚ÄúAs far as I‚Äôm aware, watching streaming is not illegal,‚Äù James tells me. ‚ÄúHosting it is.‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúWhy would I pay for something I get for free?‚Äù&lt;/p&gt;
    &lt;p&gt;This also seems like a bit of load-bearing folk wisdom: Copyright owners have very famously sued people for accessing copyrighted content in the past, and there‚Äôs nothing stopping them from trying again if they want to. Even mentioning this idea to copyright law professors provokes thoughtful responses about legal tactics and business strategy considerations. ‚ÄúCopyright holders are likely to look for chokepoints where they can maximize the impact of legal pressure, but where those are is not always predictable,‚Äù says Blake Reid, an internet and copyright law professor at Colorado Law School. ‚ÄúHistorically we‚Äôve seen actions up and down the Internet stack, against device manufacturers, service providers, and even users. The legal actions copyright holders take are not always obvious or intuitive and often contradict social norms and folk wisdom in online communities.‚Äù&lt;/p&gt;
    &lt;p&gt;Jack Lerner, a law professor who heads UC Irvine‚Äôs Intellectual Property, Arts, and Technology Clinic, says that going after individual users would be challenging. ‚ÄúIt‚Äôs not entirely clear that consumers would be committing copyright infringement just by accessing pirated content through these boxes,‚Äù Lerner says. ‚ÄúIn the analog world, merely consuming pirated material is not illegal. For example, it‚Äôs not against the law to read a book that was copied by someone else and given to you.‚Äù&lt;/p&gt;
    &lt;p&gt;But there are other, perhaps worse punishments Hollywood could mete out to streaming pirates. ‚ÄúRightsholders regularly pressure ISPs to cut off infringing content and terminate subscriber accounts,‚Äù Lerner says. ‚ÄúIf they haven‚Äôt already done so, it would not surprise me if ISPs were to start terminating the accounts of people who use these devices.‚Äù&lt;/p&gt;
    &lt;p&gt;The challenging intellectual complexity of the situation can‚Äôt compete with the combination of convenience and defiance that runs through this community. ‚ÄúIllegal or not: [If] it plays, I‚Äôm watching it,‚Äù James says. ‚ÄúWhat are they gonna do? Come and arrest me?‚Äù&lt;/p&gt;
    &lt;p&gt;As Netflix and other services continue to increase their prices, some streaming box users are done with paying for TV once and for all. If SuperBox or vSeeBox got sued out of existence, they would likely just move on to the next device. For people like Jason, there‚Äôs little pay TV or streaming service operators can do to win him back. ‚ÄúThey can try, but good luck,‚Äù he tells me.&lt;/p&gt;
    &lt;p&gt;James agrees. ‚ÄúWhy would I pay for something I get for free?‚Äù&lt;/p&gt;
    &lt;p&gt;The throughline in all of my conversations with SuperBox and vSeeBox users was that TV has gotten both too complicated and too expensive. But quite a few of them continue to pay for some services.&lt;/p&gt;
    &lt;p&gt;Natalie, for instance, has a Peacock subscription. ‚ÄúIt‚Äôs super cheap,‚Äù she tells me. She also cycles in and out of Hulu‚Äôs live TV service, which she appreciates for its cloud DVR. Eva doesn‚Äôt think she‚Äôll ever go back to paying almost $300 a month for pay TV, but estimates that she pays around $60 to $70 a month for services like Netflix and Disney Plus. ‚ÄúThat‚Äôs still reasonable to me,‚Äù she says.&lt;/p&gt;
    &lt;p&gt;And Mike is still paying for YouTube TV after realizing that his vSeeBox couldn‚Äôt fully replace it. ‚ÄúThe paid services are worth it, to a certain extent, for me,‚Äù he says.&lt;/p&gt;
    &lt;p&gt;However, even people like Mike only have so much patience for being pawns in the streaming wars. When ABC and other Disney-owned channels went dark on YouTube TV last fall, he seriously considered pulling the plug and moving all his viewing to his rogue streaming box. Many more people could find themselves tempted to do the same, especially if streaming services keep raising their prices and media companies continue to make consumers suffer during licensing fee fights.&lt;/p&gt;
    &lt;p&gt;‚ÄúThis box is not that hard to figure out,‚Äù Mike tells me. ‚ÄúAnybody can do it.‚Äù&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46901974</guid><pubDate>Thu, 05 Feb 2026 17:18:11 +0000</pubDate></item><item><title>Claude Opus 4.6</title><link>https://www.anthropic.com/news/claude-opus-4-6</link><description>&lt;doc fingerprint="754d0ede3f97caef"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Introducing Claude Opus 4.6&lt;/head&gt;&lt;p&gt;We‚Äôre upgrading our smartest model.&lt;/p&gt;&lt;p&gt;The new Claude Opus 4.6 improves on its predecessor‚Äôs coding skills. It plans more carefully, sustains agentic tasks for longer, can operate more reliably in larger codebases, and has better code review and debugging skills to catch its own mistakes. And, in a first for our Opus-class models, Opus 4.6 features a 1M token context window in beta.&lt;/p&gt;&lt;p&gt;Opus 4.6 can also apply its improved abilities to a range of everyday work tasks: running financial analyses, doing research, and using and creating documents, spreadsheets, and presentations. Within Cowork, where Claude can multitask autonomously, Opus 4.6 can put all these skills to work on your behalf.&lt;/p&gt;&lt;p&gt;The model‚Äôs performance is state-of-the-art on several evaluations. For example, it achieves the highest score on the agentic coding evaluation Terminal-Bench 2.0 and leads all other frontier models on Humanity‚Äôs Last Exam, a complex multidisciplinary reasoning test. On GDPval-AA‚Äîan evaluation of performance on economically valuable knowledge work tasks in finance, legal, and other domains1‚ÄîOpus 4.6 outperforms the industry‚Äôs next-best model (OpenAI‚Äôs GPT-5.2) by around 144 Elo points,2 and its own predecessor (Claude Opus 4.5) by 190 points. Opus 4.6 also performs better than any other model on BrowseComp, which measures a model‚Äôs ability to locate hard-to-find information online.&lt;/p&gt;&lt;p&gt;As we show in our extensive system card, Opus 4.6 also shows an overall safety profile as good as, or better than, any other frontier model in the industry, with low rates of misaligned behavior across safety evaluations.&lt;/p&gt;&lt;p&gt;In Claude Code, you can now assemble agent teams to work on tasks together. On the API, Claude can use compaction to summarize its own context and perform longer-running tasks without bumping up against limits. We‚Äôre also introducing adaptive thinking, where the model can pick up on contextual clues about how much to use its extended thinking, and new effort controls to give developers more control over intelligence, speed, and cost.&lt;/p&gt;&lt;p&gt;We‚Äôve made substantial upgrades to Claude in Excel, and we‚Äôre releasing Claude in PowerPoint in a research preview. This makes Claude much more capable for everyday work.&lt;/p&gt;&lt;p&gt;Claude Opus 4.6 is available today on claude.ai, our API, and all major cloud platforms. If you‚Äôre a developer, use &lt;code&gt;claude-opus-4-6&lt;/code&gt; via the Claude API. Pricing remains the same at $5/$25 per million tokens; for full details, see our pricing page.&lt;/p&gt;&lt;p&gt;We cover the model, our new product updates, our evaluations, and our extensive safety testing in depth below.&lt;/p&gt;&lt;head rend="h2"&gt;First impressions&lt;/head&gt;&lt;p&gt;We build Claude with Claude. Our engineers write code with Claude Code every day, and every new model first gets tested on our own work. With Opus 4.6, we‚Äôve found that the model brings more focus to the most challenging parts of a task without being told to, moves quickly through the more straightforward parts, handles ambiguous problems with better judgment, and stays productive over longer sessions.&lt;/p&gt;&lt;p&gt;Opus 4.6 often thinks more deeply and more carefully revisits its reasoning before settling on an answer. This produces better results on harder problems, but can add cost and latency on simpler ones. If you‚Äôre finding that the model is overthinking on a given task, we recommend dialing effort down from its default setting (high) to medium. You can control this easily with the &lt;code&gt;/effort&lt;/code&gt; parameter.&lt;/p&gt;&lt;p&gt;Here are some of the things our Early Access partners told us about Claude Opus 4.6, including its propensity to work autonomously without hand-holding, its success where previous models failed, and its effect on how teams work:&lt;/p&gt;&lt;quote&gt;Claude Opus 4.6 is the strongest model Anthropic has shipped. It takes complicated requests and actually follows through, breaking them into concrete steps, executing, and producing polished work even when the task is ambitious. For Notion users, it feels less like a tool and more like a capable collaborator.&lt;/quote&gt;&lt;quote&gt;Early testing shows Claude Opus 4.6 delivering on the complex, multi-step coding work developers face every day‚Äîespecially agentic workflows that demand planning and tool calling. This starts unlocking long-horizon tasks at the frontier.&lt;/quote&gt;&lt;quote&gt;Claude Opus 4.6 is a huge leap for agentic planning. It breaks complex tasks into independent subtasks, runs tools and subagents in parallel, and identifies blockers with real precision.&lt;/quote&gt;&lt;quote&gt;Claude Opus 4.6 felt like a clear step up. Code, reasoning, and planning were excellent. Its ability to navigate a large codebase and identify the right changes feels state-of-the-art.&lt;/quote&gt;&lt;quote&gt;Claude Opus 4.6 reasons through complex problems at a level we haven‚Äôt seen before. It considers edge cases that other models miss and consistently lands on more elegant, well-considered solutions.&lt;/quote&gt;&lt;quote&gt;Claude Opus 4.6 feels noticeably better than Opus 4.5 in Windsurf, especially on tasks that require careful exploration like debugging and understanding unfamiliar codebases. We‚Äôve noticed Opus 4.6 thinks longer, which pays off when deeper reasoning is needed.&lt;/quote&gt;&lt;quote&gt;Claude Opus 4.6 represents a meaningful leap in long-context performance. In our testing, we saw it handle much larger bodies of information with a level of consistency that strengthens how we design and deploy complex research workflows. Progress in this area gives us more powerful building blocks to deliver truly expert-grade systems professionals can trust.&lt;/quote&gt;&lt;quote&gt;Across 40 cybersecurity investigations, Claude Opus 4.6 produced the best results 38 of 40 times in a blind ranking against Claude 4.5 models. Each model ran end to end on the same agentic harness with up to 9 subagents and 100+ tool calls.&lt;/quote&gt;&lt;quote&gt;Claude Opus 4.6 stands out on harder problems. Stronger tenacity, better code review, and it stays on long-horizon tasks where others drop off. The team is really excited.&lt;/quote&gt;&lt;quote&gt;Claude Opus 4.6 achieved the highest BigLaw Bench score of any Claude model at 90.2%. With 40% perfect scores and 84% above 0.8, it‚Äôs remarkably capable for legal reasoning.&lt;/quote&gt;&lt;quote&gt;Claude Opus 4.6 autonomously closed 13 issues and assigned 12 issues to the right team members in a single day, managing a ~50-person organization across 6 repositories. It handled both product and organizational decisions while synthesizing context across multiple domains, and it knew when to escalate to a human.&lt;/quote&gt;&lt;quote&gt;Claude Opus 4.6 is an uplift in design quality. It works beautifully with our design systems and it‚Äôs more autonomous, which is core to Lovable‚Äôs values. People should be creating things that matter, not micromanaging AI.&lt;/quote&gt;&lt;quote&gt;Claude Opus 4.6 excels in high-reasoning tasks like multi-source analysis across legal, financial, and technical content. Box‚Äôs eval showed a 10% lift in performance, reaching 68% vs. a 58% baseline, and near-perfect scores in technical domains.&lt;/quote&gt;&lt;quote&gt;Claude Opus 4.6 generates complex, interactive apps and prototypes in Figma Make with an impressive creative range. The model translates detailed designs and multi-layered tasks into code on the first try, making it a powerful starting point for teams to explore and build ideas.&lt;/quote&gt;&lt;quote&gt;Claude Opus 4.6 is the best Anthropic model we‚Äôve tested. It understands intent with minimal prompting and went above and beyond, exploring and creating details I didn‚Äôt even know I wanted until I saw them. It felt like I was working with the model, not waiting on it.&lt;/quote&gt;&lt;quote&gt;Both hands-on testing and evals show Claude Opus 4.6 is a meaningful improvement for design systems and large codebases, use cases that drive enormous enterprise value. It also one-shotted a fully functional physics engine, handling a large multi-scope task in a single pass.&lt;/quote&gt;&lt;quote&gt;Claude Opus 4.6 is the biggest leap I‚Äôve seen in months. I‚Äôm more comfortable giving it a sequence of tasks across the stack and letting it run. It‚Äôs smart enough to use subagents for the individual pieces.&lt;/quote&gt;&lt;quote&gt;Claude Opus 4.6 handled a multi-million-line codebase migration like a senior engineer. It planned up front, adapted its strategy as it learned, and finished in half the time.&lt;/quote&gt;&lt;quote&gt;We only ship models in v0 when developers will genuinely feel the difference. Claude Opus 4.6 passed that bar with ease. Its frontier-level reasoning, especially with edge cases, helps v0 to deliver on our number-one aim: to let anyone elevate their ideas from prototype to production.&lt;/quote&gt;&lt;quote&gt;The performance jump with Claude Opus 4.6 feels almost unbelievable. Real-world tasks that were challenging for Opus [4.5] suddenly became easy. This feels like a watershed moment for spreadsheet agents on Shortcut.&lt;/quote&gt;&lt;head rend="h2"&gt;Evaluating Claude Opus 4.6&lt;/head&gt;&lt;p&gt;Across agentic coding, computer use, tool use, search, and finance, Opus 4.6 is an industry-leading model, often by a wide margin. The table below shows how Claude Opus 4.6 compares to our previous models and to other industry models on a variety of benchmarks.&lt;/p&gt;&lt;p&gt;Opus 4.6 is much better at retrieving relevant information from large sets of documents. This extends to long-context tasks, where it holds and tracks information over hundreds of thousands of tokens with less drift, and picks up buried details that even Opus 4.5 would miss.&lt;/p&gt;&lt;p&gt;A common complaint about AI models is ‚Äúcontext rot,‚Äù where performance degrades as conversations exceed a certain number of tokens. Opus 4.6 performs markedly better than its predecessors: on the 8-needle 1M variant of MRCR v2‚Äîa needle-in-a-haystack benchmark that tests a model‚Äôs ability to retrieve information ‚Äúhidden‚Äù in vast amounts of text‚ÄîOpus 4.6 scores 76%, whereas Sonnet 4.5 scores just 18.5%. This is a qualitative shift in how much context a model can actually use while maintaining peak performance.&lt;/p&gt;&lt;p&gt;All in all, Opus 4.6 is better at finding information across long contexts, better at reasoning after absorbing that information, and has substantially better expert-level reasoning abilities in general.&lt;/p&gt;&lt;p&gt;Finally, the charts below show how Claude Opus 4.6 performs on a variety of benchmarks that assess its software engineering skills, multilingual coding ability, long-term coherence, cybersecurity capabilities, and its life sciences knowledge.&lt;/p&gt;&lt;head rend="h2"&gt;A step forward on safety&lt;/head&gt;&lt;p&gt;These intelligence gains do not come at the cost of safety. On our automated behavioral audit, Opus 4.6 showed a low rate of misaligned behaviors such as deception, sycophancy, encouragement of user delusions, and cooperation with misuse. Overall, it is just as well-aligned as its predecessor, Claude Opus 4.5, which was our most-aligned frontier model to date. Opus 4.6 also shows the lowest rate of over-refusals‚Äîwhere the model fails to answer benign queries‚Äîof any recent Claude model.&lt;/p&gt;&lt;p&gt;For Claude Opus 4.6, we ran the most comprehensive set of safety evaluations of any model, applying many different tests for the first time and upgrading several that we‚Äôve used before. We included new evaluations for user wellbeing, more complex tests of the model‚Äôs ability to refuse potentially dangerous requests, and updated evaluations of the model‚Äôs ability to surreptitiously perform harmful actions. We also experimented with new methods from interpretability, the science of the inner workings of AI models, to begin to understand why the model behaves in certain ways‚Äîand, ultimately, to catch problems that standard testing might miss.&lt;/p&gt;&lt;p&gt;A detailed description of all capability and safety evaluations is available in the Claude Opus 4.6 system card.&lt;/p&gt;&lt;p&gt;We‚Äôve also applied new safeguards in areas where Opus 4.6 shows particular strengths that might be put to dangerous as well as beneficial uses. In particular, since the model shows enhanced cybersecurity abilities, we‚Äôve developed six new cybersecurity probes‚Äîmethods of detecting harmful responses‚Äîto help us track different forms of potential misuse.&lt;/p&gt;&lt;p&gt;We‚Äôre also accelerating the cyberdefensive uses of the model, using it to help find and patch vulnerabilities in open-source software (as we describe in our new cybersecurity blog post). We think it‚Äôs critical that cyberdefenders use AI models like Claude to help level the playing field. Cybersecurity moves fast, and we‚Äôll be adjusting and updating our safeguards as we learn more about potential threats; in the near future, we may institute real-time intervention to block abuse.&lt;/p&gt;&lt;head rend="h2"&gt;Product and API updates&lt;/head&gt;&lt;p&gt;We‚Äôve made substantial updates across Claude, Claude Code, and the Claude Developer Platform to let Opus 4.6 perform at its best.&lt;/p&gt;&lt;p&gt;Claude Developer Platform&lt;/p&gt;&lt;p&gt;On the API, we‚Äôre giving developers better control over model effort and more flexibility for long-running agents. To do so, we‚Äôre introducing the following features:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Adaptive thinking. Previously, developers only had a binary choice between enabling or disabling extended thinking. Now, with adaptive thinking, Claude can decide when deeper reasoning would be helpful. At the default effort level (high), the model uses extended thinking when useful, but developers can adjust the effort level to make it more or less selective.&lt;/item&gt;&lt;item&gt;Effort. There are now four effort levels to choose from: low, medium, high (default), and max. We encourage developers to experiment with different options to find what works best.&lt;/item&gt;&lt;item&gt;Context compaction (beta). Long-running conversations and agentic tasks often hit the context window. Context compaction automatically summarizes and replaces older context when the conversation approaches a configurable threshold, letting Claude perform longer tasks without hitting limits.&lt;/item&gt;&lt;item&gt;1M token context (beta). Opus 4.6 is our first Opus-class model with 1M token context. Premium pricing applies for prompts exceeding 200k tokens ($10/$37.50 per million input/output tokens).&lt;/item&gt;&lt;item&gt;128k output tokens. Opus 4.6 supports outputs of up to 128k tokens, which lets Claude complete larger-output tasks without breaking them into multiple requests.&lt;/item&gt;&lt;item&gt;US-only inference. For workloads that need to run in the United States, US-only inference is available at 1.1√ó token pricing.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Product updates&lt;/p&gt;&lt;p&gt;Across Claude and Claude Code, we‚Äôve added features that allow knowledge workers and developers to tackle harder tasks with more of the tools they use every day.&lt;/p&gt;&lt;p&gt;We‚Äôve introduced agent teams in Claude Code as a research preview. You can now spin up multiple agents that work in parallel as a team and coordinate autonomously‚Äîbest for tasks that split into independent, read-heavy work like codebase reviews. You can take over any subagent directly using Shift+Up/Down or tmux.&lt;/p&gt;&lt;p&gt;Claude now also works better with the office tools you already use. Claude in Excel handles long-running and harder tasks with improved performance, and can plan before acting, ingest unstructured data and infer the right structure without guidance, and handle multi-step changes in one pass. Pair that with Claude in PowerPoint, and you can first process and structure your data in Excel, then bring it to life visually in PowerPoint. Claude reads your layouts, fonts, and slide masters to stay on brand, whether you‚Äôre building from a template or generating a full deck from a description. Claude in PowerPoint is now available in research preview for Max, Team, and Enterprise plans.&lt;/p&gt;&lt;head rend="h4"&gt;Footnotes&lt;/head&gt;&lt;p&gt;[1] Run independently by Artificial Analysis. See here for full methodological details.&lt;/p&gt;&lt;p&gt;[2] This translates into Claude Opus 4.6 obtaining a higher score than GPT-5.2 on this eval approximately 70% of the time (where 50% of the time would have implied parity in the scores).&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;For GPT-5.2 and Gemini 3 Pro models, we compared the best reported model version in the charts and table.&lt;/item&gt;&lt;item&gt;Terminal-Bench 2.0: We report both scores reproduced on our infrastructure and published scores from other labs. All runs used the Terminus-2 harness, except for OpenAI‚Äôs Codex CLI. All experiments used 1√ó guaranteed / 3√ó ceiling resource allocation and 5‚Äì15 samples per task across staggered batches. See system card for details.&lt;/item&gt;&lt;item&gt;Humanity‚Äôs Last Exam: Claude models run ‚Äúwith tools‚Äù were run with web search, web fetch, code execution, programmatic tool calling, context compaction triggered at 50k tokens up to 3M total tokens, max reasoning effort, and adaptive thinking enabled. A domain blocklist was used to decontaminate eval results. See system card for more details.&lt;/item&gt;&lt;item&gt;SWE-bench Verified: Our score was averaged over 25 trials. With a prompt modification, we saw a score of 81.42%.&lt;/item&gt;&lt;item&gt;MCP Atlas: Claude Opus 4.6 was run with max effort. When run at high effort, it reached an industry-leading score of 62.7%.&lt;/item&gt;&lt;item&gt;BrowseComp: Claude models were run with web search, web fetch, programmatic tool calling, context compaction triggered at 50k tokens up to 10M total tokens, max reasoning effort, and no thinking enabled. Adding a multi-agent harness increased scores to 86.8%. See system card for more details.&lt;/item&gt;&lt;item&gt;ARC AGI 2: Claude Opus 4.6 was run with max effort and a 120k thinking budget score.&lt;/item&gt;&lt;item&gt;CyberGym: Claude models were run on no thinking, default effort, temperature, and &lt;code&gt;top_p&lt;/code&gt;. The model was also given a ‚Äúthink‚Äù tool that allowed interleaved thinking for multi-turn evaluations.&lt;/item&gt;&lt;item&gt;OpenRCA: For each failure case in OpenRCA, Claude receives 1 point if all generated root-cause elements match the ground-truth ones, and 0 points if any mismatch is identified. The overall accuracy is the average score across all failure cases. The benchmark was run on the benchmark author‚Äôs harness, graded using their official methodology, and has been submitted for official verification.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Related content&lt;/head&gt;&lt;head rend="h3"&gt;Claude is a space to think&lt;/head&gt;&lt;p&gt;We‚Äôve made a choice: Claude will remain ad-free. We explain why advertising incentives are incompatible with a genuinely helpful AI assistant, and how we plan to expand access without compromising user trust.&lt;/p&gt;Read more&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46902223</guid><pubDate>Thu, 05 Feb 2026 17:38:53 +0000</pubDate></item><item><title>Advancing finance with Claude Opus 4.6</title><link>https://claude.com/blog/opus-4-6-finance</link><description>&lt;doc fingerprint="373982fe1ef3c0ef"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Advancing finance with Claude Opus 4.6&lt;/head&gt;
    &lt;p&gt;With Claude Opus 4.6, finance teams get better reasoning on complex analyses, cleaner first-pass deliverables, and new tools built for where analysts actually spend their time.&lt;/p&gt;
    &lt;p&gt;With Claude Opus 4.6, finance teams get better reasoning on complex analyses, cleaner first-pass deliverables, and new tools built for where analysts actually spend their time.&lt;/p&gt;
    &lt;p&gt;Claude Opus 4.6 marks a step forward in AI for finance. It can be used to help professionals make decisions based on accurate information and clear analysis, and it produces deliverables with real polish. The model is substantially better than others in the market at financial reasoning, multitasking, and maintaining focus over longer multi-step tasks.&lt;/p&gt;
    &lt;p&gt;Alongside Claude Opus 4.6, we‚Äôre updating some of our existing products‚Äîand introducing a new one‚Äîto put these capabilities where analysts spend the majority of their time. Cowork now delivers more polished outputs, such as financial models and presentations, on the first pass. Claude in Excel is now better at handling long-running tasks, with Claude Opus 4.6 staying focused and accurate as financial models become more complex. And we‚Äôre releasing Claude in PowerPoint as a research preview in beta for natively building and iterating on decks and presentations.&lt;/p&gt;
    &lt;p&gt;Our internal Real-World Finance evaluation measures Claude‚Äôs performance on ~50 investment and financial analysis use cases spanning spreadsheets, slide decks, and word document generation and review. These are tasks commonly performed by analysts across investment banking, private equity, public investing, and corporate finance. Claude Opus 4.6 improves by over 23 percentage points on Claude Sonnet 4.5, our state-of-the-art model just a few months ago.&lt;/p&gt;
    &lt;p&gt;Together, these updates make Claude a much stronger partner for those across financial services and corporate finance.&lt;/p&gt;
    &lt;p&gt;Financial professionals use AI to research effectively across multiple data sources, support financial analyses, and create deliverables that their teams and customers can act on. Claude Opus 4.6 is best in class across all three dimensions.&lt;/p&gt;
    &lt;p&gt;On research, Claude Opus 4.6 improves on both BrowseComp and DeepSearchQA, two benchmarks that test a model‚Äôs ability to extract specific information from large, unstructured data sources. In practice, this means that users can hand Claude a dense set of documents and receive a specific, focused answer, rather than a simple summary.&lt;/p&gt;
    &lt;p&gt;On analysis, Claude Opus 4.6 is state-of-the-art at 60.7% (achieving a 5.47% improvement from Opus 4.5) on Finance Agent, an external benchmark from Vals AI that evaluates models on research of SEC filings of public companies. Opus 4.6 is also state-of-the-art on the TaxEval by Vals AI at 76.0%.&lt;/p&gt;
    &lt;p&gt;On creation, we use GDPval-AA to measure Claude‚Äôs performance on complex knowledge work, in addition to our Real-World Finance evaluation. With Claude Opus 4.6, structured outputs like spreadsheets and presentations come out right more often on the first pass. The side-by-side outputs below show how output quality has improved from Claude Opus 4.5 to Opus 4.6. These are examples of Claude‚Äôs first-pass performance on a commercial due diligence task (evaluating a potential acquisition)‚Äîthe kind of work that would typically take a senior analyst two to three weeks to complete.&lt;/p&gt;
    &lt;quote&gt;‚ÄúWith Claude Opus 4.6, creating financial PowerPoints that used to take hours now takes minutes. We're seeing tangible improvements in attention to detail, spatial layout, and content structuring.‚Äù - Aabhas Sharma, CTO, Hebbia&lt;/quote&gt;
    &lt;quote&gt;‚ÄúThe performance jump with Claude Opus 4.6 feels almost unbelievable. Real-world tasks that were challenging for Opus [4.5] suddenly became easy. This feels like a watershed moment for spreadsheet agents on Shortcut.‚Äù - Nico Christie, Co-Founder &amp;amp; CTO, Shortcut AI&lt;/quote&gt;
    &lt;p&gt;The finance capabilities of Claude Opus 4.6 are easy to access with Cowork, a new way to use Claude in our desktop app.&lt;/p&gt;
    &lt;p&gt;In Cowork, you give Claude access to a desktop folder of your choosing. Claude is able to read, edit, and create new files directly in that folder. For finance teams, this means you can kick off several analyses at once, while steering Claude‚Äôs thought process as it creates each deliverable to meet your standard.&lt;/p&gt;
    &lt;p&gt;Cowork can also be customized with plugins‚Äîbundles of skills (which specify how to complete a task) and connectors to data on other platforms. With our corporate finance plugin, for example, Claude immediately knows how to complete common workflows like journal entries, variance analyses, and reconciliation. You can also build your own plugins to match how you like to work.&lt;/p&gt;
    &lt;p&gt;Cowork is available as a desktop-only research preview in beta on all paid Claude plans1.&lt;/p&gt;
    &lt;p&gt;Claude in Excel brings Claude Opus 4.6 directly to your spreadsheets. We‚Äôve now made it better at planning and clarifying assumptions with users, especially as the task becomes more complex. It also now supports pivot table editing, chart modifications, conditional formatting, sorting and filtering, data validation, and finance-grade formatting.&lt;/p&gt;
    &lt;p&gt;Finally, we‚Äôve added usability improvements, including auto-compaction for long conversations and drag-and-drop multi-file support. This means you‚Äôll need to do much less copying and pasting between tabs. You can work with Claude on everything from financial models to client-ready workbooks, all in one place.&lt;/p&gt;
    &lt;quote&gt;‚ÄúClaude in Excel powered by Claude Opus 4.6 represents a significant leap forward. From due diligence to financial modeling, it‚Äôs proving to be a remarkably powerful tool for our team - taking unstructured data and intelligently working with minimal prompting to meaningfully automate complex analysis. It‚Äôs an excellent example of AI augmenting investment professionals‚Äô capabilities in tangible, time-saving ways.‚Äù - Lloyd Hilton, Head of Hg Catalyst&lt;/quote&gt;
    &lt;quote&gt;‚ÄúAs one of Canada‚Äôs largest institutional investors, we‚Äôre constantly innovating and see AI at the forefront of shaping our future. Claude Opus 4.6's enhanced speed, precision, and capacity for complex tasks, like multi-tab analysis in Claude in Excel, unlock exciting possibilities for how we work.‚Äù - Ben Letalik, Sr. Director, Digital Transformation &amp;amp; Innovation, BCI&lt;/quote&gt;
    &lt;p&gt;We‚Äôre also launching Claude in PowerPoint as a research preview in beta. Just like Claude in Excel, this brings Claude into your PowerPoint sidebar, letting it read your existing layouts, fonts, and masters before then creating new work in-line. Claude can build decks from client templates, make targeted edits to existing slides, and generate a great first-pass presentation from scratch.&lt;/p&gt;
    &lt;p&gt;Claude in PowerPoint is now available as a research preview for all users on a Max, Team, or Enterprise plan.&lt;/p&gt;
    &lt;p&gt;Claude Opus 4.6 and our latest product updates make a whole range of new tasks possible. But AI for finance remains an active frontier. Users should continue to review Claude‚Äôs outputs to ensure it meets their specifications; particularly for high-stakes work, human judgment remains essential. As we continue to improve Claude‚Äôs capabilities, our aim is to equip finance industry professionals with ever-more powerful tools for research and analysis, and to help them focus on their most important work.&lt;/p&gt;
    &lt;p&gt;Claude Opus 4.6, Cowork, and Claude in Excel are available on all paid Claude plans. To learn more about Claude in Excel, explore our guide and video tutorial, and get started here. Claude in PowerPoint is available in research preview for all Max, Team, and Enterprise users, and you can get started here.&lt;/p&gt;
    &lt;p&gt;To see how organizations are using these new features in action, register for our webinar.&lt;/p&gt;
    &lt;p/&gt;
    &lt;p/&gt;
    &lt;p/&gt;
    &lt;p/&gt;
    &lt;p&gt;Get the developer newsletter&lt;/p&gt;
    &lt;p&gt;Product updates, how-tos, community spotlights, and more. Delivered monthly to your inbox.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46902273</guid><pubDate>Thu, 05 Feb 2026 17:42:47 +0000</pubDate></item><item><title>Claude Code Agent Teams</title><link>https://code.claude.com/docs/en/agent-teams</link><description>&lt;doc fingerprint="d45eacbb2981e0af"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;div&gt;&lt;div&gt;Agent teams are experimental and disabled by default. Enable them by adding&lt;code&gt;CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS&lt;/code&gt; to your settings.json or environment. Agent teams have known limitations around session resumption, task coordination, and shutdown behavior.&lt;/div&gt;&lt;/div&gt;Agent teams let you coordinate multiple Claude Code instances working together. One session acts as the team lead, coordinating work, assigning tasks, and synthesizing results. Teammates work independently, each in its own context window, and communicate directly with each other.
Unlike subagents, which run within a single session and can only report back to the main agent, you can also interact with individual teammates directly without going through the lead.
This page covers:&lt;head rend="h2"&gt;When to use agent teams&lt;/head&gt; Agent teams are most effective for tasks where parallel exploration adds real value. See use case examples for full scenarios. The strongest use cases are: &lt;list rend="ul"&gt;&lt;item&gt;Research and review: multiple teammates can investigate different aspects of a problem simultaneously, then share and challenge each other‚Äôs findings&lt;/item&gt;&lt;item&gt;New modules or features: teammates can each own a separate piece without stepping on each other&lt;/item&gt;&lt;item&gt;Debugging with competing hypotheses: teammates test different theories in parallel and converge on the answer faster&lt;/item&gt;&lt;item&gt;Cross-layer coordination: changes that span frontend, backend, and tests, each owned by a different teammate&lt;/item&gt;&lt;/list&gt;Agent teams add coordination overhead and use significantly more tokens than a single session. They work best when teammates can operate independently. For sequential tasks, same-file edits, or work with many dependencies, a single session or subagents are more effective.&lt;head rend="h3"&gt;Compare with subagents&lt;/head&gt; Both agent teams and subagents let you parallelize work, but they operate differently. Choose based on whether your workers need to communicate with each other: &lt;div&gt;&lt;div&gt;&lt;table&gt;&lt;row&gt;&lt;cell style="text-align:left" role="head"&gt;Subagents&lt;/cell&gt;&lt;cell style="text-align:left" role="head"&gt;Agent teams&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell style="text-align:left"&gt;Context&lt;/cell&gt;&lt;cell style="text-align:left"&gt;Own context window; results return to the caller&lt;/cell&gt;&lt;cell style="text-align:left"&gt;Own context window; fully independent&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell style="text-align:left"&gt;Communication&lt;/cell&gt;&lt;cell style="text-align:left"&gt;Report results back to the main agent only&lt;/cell&gt;&lt;cell style="text-align:left"&gt;Teammates message each other directly&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell style="text-align:left"&gt;Coordination&lt;/cell&gt;&lt;cell style="text-align:left"&gt;Main agent manages all work&lt;/cell&gt;&lt;cell style="text-align:left"&gt;Shared task list with self-coordination&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell style="text-align:left"&gt;Best for&lt;/cell&gt;&lt;cell style="text-align:left"&gt;Focused tasks where only the result matters&lt;/cell&gt;&lt;cell style="text-align:left"&gt;Complex work requiring discussion and collaboration&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell style="text-align:left"&gt;Token cost&lt;/cell&gt;&lt;cell style="text-align:left"&gt;Lower: results summarized back to main context&lt;/cell&gt;&lt;cell style="text-align:left"&gt;Higher: each teammate is a separate Claude instance&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;/div&gt;&lt;/div&gt;Use subagents when you need quick, focused workers that report back. Use agent teams when teammates need to share findings, challenge each other, and coordinate on their own.&lt;head rend="h2"&gt;Enable agent teams&lt;/head&gt; Agent teams are disabled by default. Enable them by setting the &lt;code&gt;CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS&lt;/code&gt; environment variable to &lt;code&gt;1&lt;/code&gt;, either in your shell environment or through settings.json:
&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;quote&gt;&lt;code&gt;{
  "env": {
    "CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS": "1"
  }
}
&lt;/code&gt;&lt;/quote&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;head rend="h2"&gt;Start your first agent team&lt;/head&gt; After enabling agent teams, tell Claude to create an agent team and describe the task and the team structure you want in natural language. Claude creates the team, spawns teammates, and coordinates work based on your prompt. This example works well because the three roles are independent and can explore the problem without waiting on each other: &lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;quote&gt;&lt;code&gt;I'm designing a CLI tool that helps developers track TODO comments across
their codebase. Create an agent team to explore this from different angles: one
teammate on UX, one on technical architecture, one playing devil's advocate.
&lt;/code&gt;&lt;/quote&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;From there, Claude creates a team with a shared task list, spawns teammates for each perspective, has them explore the problem, synthesizes findings, and attempts to clean up the team when finished.
The lead‚Äôs terminal lists all teammates and what they‚Äôre working on. Use Shift+Up/Down to select a teammate and message them directly.
If you want each teammate in its own split pane, see Choose a display mode.&lt;head rend="h2"&gt;Control your agent team&lt;/head&gt; Tell the lead what you want in natural language. It handles team coordination, task assignment, and delegation based on your instructions. &lt;head rend="h3"&gt;Choose a display mode&lt;/head&gt; Agent teams support two display modes: &lt;list rend="ul"&gt;&lt;item&gt;In-process: all teammates run inside your main terminal. Use Shift+Up/Down to select a teammate and type to message them directly. Works in any terminal, no extra setup required.&lt;/item&gt;&lt;item&gt;Split panes: each teammate gets its own pane. You can see everyone‚Äôs output at once and click into a pane to interact directly. Requires tmux, or iTerm2.&lt;/item&gt;&lt;/list&gt;&lt;div&gt;&lt;p&gt;&lt;code&gt;tmux&lt;/code&gt; has known limitations on certain operating systems and traditionally works best on macOS. Using &lt;code&gt;tmux -CC&lt;/code&gt; in iTerm2 is the suggested entrypoint into &lt;code&gt;tmux&lt;/code&gt;.&lt;/p&gt;&lt;/div&gt;The default is&lt;code&gt;"auto"&lt;/code&gt;, which uses split panes if you‚Äôre already running inside a tmux session, and in-process otherwise. The &lt;code&gt;"tmux"&lt;/code&gt; setting enables split-pane mode and auto-detects whether to use tmux or iTerm2 based on your terminal. To override, set &lt;code&gt;teammateMode&lt;/code&gt; in your settings.json:
&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;quote&gt;&lt;code&gt;{
  "teammateMode": "in-process"
}
&lt;/code&gt;&lt;/quote&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;To force in-process mode for a single session, pass it as a flag:&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;quote&gt;&lt;code&gt;claude --teammate-mode in-process
&lt;/code&gt;&lt;/quote&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;Split-pane mode requires either tmux or iTerm2 with the&lt;code&gt;it2&lt;/code&gt; CLI. To install manually:
&lt;list rend="ul"&gt;&lt;item&gt;tmux: install through your system‚Äôs package manager. See the tmux wiki for platform-specific instructions.&lt;/item&gt;&lt;item&gt;iTerm2: install the &lt;code&gt;it2&lt;/code&gt; CLI, then enable the Python API in iTerm2 ‚Üí Settings ‚Üí General ‚Üí Magic ‚Üí Enable Python API.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Specify teammates and models&lt;/head&gt; Claude decides the number of teammates to spawn based on your task, or you can specify exactly what you want: &lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;quote&gt;&lt;code&gt;Create a team with 4 teammates to refactor these modules in parallel.
Use Sonnet for each teammate.
&lt;/code&gt;&lt;/quote&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;head rend="h3"&gt;Require plan approval for teammates&lt;/head&gt; For complex or risky tasks, you can require teammates to plan before implementing. The teammate works in read-only plan mode until the lead approves their approach: &lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;quote&gt;&lt;code&gt;Spawn an architect teammate to refactor the authentication module.
Require plan approval before they make any changes.
&lt;/code&gt;&lt;/quote&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;When a teammate finishes planning, it sends a plan approval request to the lead. The lead reviews the plan and either approves it or rejects it with feedback. If rejected, the teammate stays in plan mode, revises based on the feedback, and resubmits. Once approved, the teammate exits plan mode and begins implementation.
The lead makes approval decisions autonomously. To influence the lead‚Äôs judgment, give it criteria in your prompt, such as ‚Äúonly approve plans that include test coverage‚Äù or ‚Äúreject plans that modify the database schema.‚Äù&lt;head rend="h3"&gt;Use delegate mode&lt;/head&gt; Without delegate mode, the lead sometimes starts implementing tasks itself instead of waiting for teammates. Delegate mode prevents this by restricting the lead to coordination-only tools: spawning, messaging, shutting down teammates, and managing tasks. This is useful when you want the lead to focus entirely on orchestration, such as breaking down work, assigning tasks, and synthesizing results, without touching code directly. To enable it, start a team first, then press Shift+Tab to cycle into delegate mode. &lt;head rend="h3"&gt;Talk to teammates directly&lt;/head&gt; Each teammate is a full, independent Claude Code session. You can message any teammate directly to give additional instructions, ask follow-up questions, or redirect their approach. &lt;list rend="ul"&gt;&lt;item&gt;In-process mode: use Shift+Up/Down to select a teammate, then type to send them a message. Press Enter to view a teammate‚Äôs session, then Escape to interrupt their current turn. Press Ctrl+T to toggle the task list.&lt;/item&gt;&lt;item&gt;Split-pane mode: click into a teammate‚Äôs pane to interact with their session directly. Each teammate has a full view of their own terminal.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Assign and claim tasks&lt;/head&gt; The shared task list coordinates work across the team. The lead creates tasks and teammates work through them. Tasks have three states: pending, in progress, and completed. Tasks can also depend on other tasks: a pending task with unresolved dependencies cannot be claimed until those dependencies are completed. The lead can assign tasks explicitly, or teammates can self-claim: &lt;list rend="ul"&gt;&lt;item&gt;Lead assigns: tell the lead which task to give to which teammate&lt;/item&gt;&lt;item&gt;Self-claim: after finishing a task, a teammate picks up the next unassigned, unblocked task on its own&lt;/item&gt;&lt;/list&gt;Task claiming uses file locking to prevent race conditions when multiple teammates try to claim the same task simultaneously.&lt;head rend="h3"&gt;Shut down teammates&lt;/head&gt; To gracefully end a teammate‚Äôs session: &lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;quote&gt;&lt;code&gt;Ask the researcher teammate to shut down
&lt;/code&gt;&lt;/quote&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;The lead sends a shutdown request. The teammate can approve, exiting gracefully, or reject with an explanation.&lt;head rend="h3"&gt;Clean up the team&lt;/head&gt; When you‚Äôre done, ask the lead to clean up: This removes the shared team resources. When the lead runs cleanup, it checks for active teammates and fails if any are still running, so shut them down first. &lt;div&gt;&lt;p&gt;Always use the lead to clean up. Teammates should not run cleanup because their team context may not resolve correctly, potentially leaving resources in an inconsistent state.&lt;/p&gt;&lt;/div&gt;&lt;head rend="h2"&gt;How agent teams work&lt;/head&gt; This section covers the architecture and mechanics behind agent teams. If you want to start using them, see Control your agent team above. &lt;head rend="h3"&gt;How Claude starts agent teams&lt;/head&gt; There are two ways agent teams get started: &lt;list rend="ul"&gt;&lt;item&gt;You request a team: give Claude a task that benefits from parallel work and explicitly ask for an agent team. Claude creates one based on your instructions.&lt;/item&gt;&lt;item&gt;Claude proposes a team: if Claude determines your task would benefit from parallel work, it may suggest creating a team. You confirm before it proceeds.&lt;/item&gt;&lt;/list&gt;In both cases, you stay in control. Claude won‚Äôt create a team without your approval.&lt;head rend="h3"&gt;Architecture&lt;/head&gt; An agent team consists of: &lt;div&gt;&lt;div&gt;&lt;table&gt;&lt;row&gt;&lt;cell style="text-align:left" role="head"&gt;Component&lt;/cell&gt;&lt;cell style="text-align:left" role="head"&gt;Role&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell style="text-align:left"&gt;Team lead&lt;/cell&gt;&lt;cell style="text-align:left"&gt;The main Claude Code session that creates the team, spawns teammates, and coordinates work&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell style="text-align:left"&gt;Teammates&lt;/cell&gt;&lt;cell style="text-align:left"&gt;Separate Claude Code instances that each work on assigned tasks&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell style="text-align:left"&gt;Task list&lt;/cell&gt;&lt;cell style="text-align:left"&gt;Shared list of work items that teammates claim and complete&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell style="text-align:left"&gt;Mailbox&lt;/cell&gt;&lt;cell style="text-align:left"&gt;Messaging system for communication between agents&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;/div&gt;&lt;/div&gt;See Choose a display mode for display configuration options. Teammate messages arrive at the lead automatically.
The system manages task dependencies automatically. When a teammate completes a task that other tasks depend on, blocked tasks unblock without manual intervention.
Teams and tasks are stored locally:&lt;list rend="ul"&gt;&lt;item&gt;Team config: &lt;code&gt;~/.claude/teams/{team-name}/config.json&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Task list: &lt;code&gt;~/.claude/tasks/{team-name}/&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;The team config contains a&lt;code&gt;members&lt;/code&gt; array with each teammate‚Äôs name, agent ID, and agent type. Teammates can read this file to discover other team members.
&lt;head rend="h3"&gt;Permissions&lt;/head&gt; Teammates start with the lead‚Äôs permission settings. If the lead runs with &lt;code&gt;--dangerously-skip-permissions&lt;/code&gt;, all teammates do too. After spawning, you can change individual teammate modes, but you can‚Äôt set per-teammate modes at spawn time.
&lt;head rend="h3"&gt;Context and communication&lt;/head&gt; Each teammate has its own context window. When spawned, a teammate loads the same project context as a regular session: CLAUDE.md, MCP servers, and skills. It also receives the spawn prompt from the lead. The lead‚Äôs conversation history does not carry over. How teammates share information: &lt;list rend="ul"&gt;&lt;item&gt;Automatic message delivery: when teammates send messages, they‚Äôre delivered automatically to recipients. The lead doesn‚Äôt need to poll for updates.&lt;/item&gt;&lt;item&gt;Idle notifications: when a teammate finishes and stops, they automatically notify the lead.&lt;/item&gt;&lt;item&gt;Shared task list: all agents can see task status and claim available work.&lt;/item&gt;&lt;/list&gt;Teammate messaging:&lt;list rend="ul"&gt;&lt;item&gt;message: send a message to one specific teammate&lt;/item&gt;&lt;item&gt;broadcast: send to all teammates simultaneously. Use sparingly, as costs scale with team size.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Token usage&lt;/head&gt; Agent teams use significantly more tokens than a single session. Each teammate has its own context window, and token usage scales with the number of active teammates. For research, review, and new feature work, the extra tokens are usually worthwhile. For routine tasks, a single session is more cost-effective. See agent team token costs for usage guidance. &lt;head rend="h2"&gt;Use case examples&lt;/head&gt; These examples show how agent teams handle tasks where parallel exploration adds value. &lt;head rend="h3"&gt;Run a parallel code review&lt;/head&gt; A single reviewer tends to gravitate toward one type of issue at a time. Splitting review criteria into independent domains means security, performance, and test coverage all get thorough attention simultaneously. The prompt assigns each teammate a distinct lens so they don‚Äôt overlap: &lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;quote&gt;&lt;code&gt;Create an agent team to review PR #142. Spawn three reviewers:
- One focused on security implications
- One checking performance impact
- One validating test coverage
Have them each review and report findings.
&lt;/code&gt;&lt;/quote&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;Each reviewer works from the same PR but applies a different filter. The lead synthesizes findings across all three after they finish.&lt;head rend="h3"&gt;Investigate with competing hypotheses&lt;/head&gt; When the root cause is unclear, a single agent tends to find one plausible explanation and stop looking. The prompt fights this by making teammates explicitly adversarial: each one‚Äôs job is not only to investigate its own theory but to challenge the others‚Äô. &lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;quote&gt;&lt;code&gt;Users report the app exits after one message instead of staying connected.
Spawn 5 agent teammates to investigate different hypotheses. Have them talk to
each other to try to disprove each other's theories, like a scientific
debate. Update the findings doc with whatever consensus emerges.
&lt;/code&gt;&lt;/quote&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;The debate structure is the key mechanism here. Sequential investigation suffers from anchoring: once one theory is explored, subsequent investigation is biased toward it.
With multiple independent investigators actively trying to disprove each other, the theory that survives is much more likely to be the actual root cause.&lt;head rend="h2"&gt;Best practices&lt;/head&gt;&lt;head rend="h3"&gt;Give teammates enough context&lt;/head&gt; Teammates load project context automatically, including CLAUDE.md, MCP servers, and skills, but they don‚Äôt inherit the lead‚Äôs conversation history. See Context and communication for details. Include task-specific details in the spawn prompt: &lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;quote&gt;&lt;code&gt;Spawn a security reviewer teammate with the prompt: "Review the authentication module
at src/auth/ for security vulnerabilities. Focus on token handling, session
management, and input validation. The app uses JWT tokens stored in
httpOnly cookies. Report any issues with severity ratings."
&lt;/code&gt;&lt;/quote&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;head rend="h3"&gt;Size tasks appropriately&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Too small: coordination overhead exceeds the benefit&lt;/item&gt;&lt;item&gt;Too large: teammates work too long without check-ins, increasing risk of wasted effort&lt;/item&gt;&lt;item&gt;Just right: self-contained units that produce a clear deliverable, such as a function, a test file, or a review&lt;/item&gt;&lt;/list&gt;&lt;div&gt;&lt;p&gt;The lead breaks work into tasks and assigns them to teammates automatically. If it isn‚Äôt creating enough tasks, ask it to split the work into smaller pieces. Having 5-6 tasks per teammate keeps everyone productive and lets the lead reassign work if someone gets stuck.&lt;/p&gt;&lt;/div&gt;&lt;head rend="h3"&gt;Wait for teammates to finish&lt;/head&gt; Sometimes the lead starts implementing tasks itself instead of waiting for teammates. If you notice this: &lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;quote&gt;&lt;code&gt;Wait for your teammates to complete their tasks before proceeding
&lt;/code&gt;&lt;/quote&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;head rend="h3"&gt;Start with research and review&lt;/head&gt; If you‚Äôre new to agent teams, start with tasks that have clear boundaries and don‚Äôt require writing code: reviewing a PR, researching a library, or investigating a bug. These tasks show the value of parallel exploration without the coordination challenges that come with parallel implementation. &lt;head rend="h3"&gt;Avoid file conflicts&lt;/head&gt; Two teammates editing the same file leads to overwrites. Break the work so each teammate owns a different set of files. &lt;head rend="h3"&gt;Monitor and steer&lt;/head&gt; Check in on teammates‚Äô progress, redirect approaches that aren‚Äôt working, and synthesize findings as they come in. Letting a team run unattended for too long increases the risk of wasted effort. &lt;head rend="h2"&gt;Troubleshooting&lt;/head&gt;&lt;head rend="h3"&gt;Teammates not appearing&lt;/head&gt; If teammates aren‚Äôt appearing after you ask Claude to create a team: &lt;list rend="ul"&gt;&lt;item&gt;In in-process mode, teammates may already be running but not visible. Press Shift+Down to cycle through active teammates.&lt;/item&gt;&lt;item&gt;Check that the task you gave Claude was complex enough to warrant a team. Claude decides whether to spawn teammates based on the task.&lt;/item&gt;&lt;item&gt;If you explicitly requested split panes, ensure tmux is installed and available in your PATH: &lt;/item&gt;&lt;item&gt;For iTerm2, verify the &lt;code&gt;it2&lt;/code&gt; CLI is installed and the Python API is enabled in iTerm2 preferences.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Too many permission prompts&lt;/head&gt; Teammate permission requests bubble up to the lead, which can create friction. Pre-approve common operations in your permission settings before spawning teammates to reduce interruptions. &lt;head rend="h3"&gt;Teammates stopping on errors&lt;/head&gt; Teammates may stop after encountering errors instead of recovering. Check their output using Shift+Up/Down in in-process mode or by clicking the pane in split mode, then either: &lt;list rend="ul"&gt;&lt;item&gt;Give them additional instructions directly&lt;/item&gt;&lt;item&gt;Spawn a replacement teammate to continue the work&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Lead shuts down before work is done&lt;/head&gt; The lead may decide the team is finished before all tasks are actually complete. If this happens, tell it to keep going. You can also tell the lead to wait for teammates to finish before proceeding if it starts doing work instead of delegating. &lt;head rend="h3"&gt;Orphaned tmux sessions&lt;/head&gt; If a tmux session persists after the team ends, it may not have been fully cleaned up. List sessions and kill the one created by the team: &lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;quote&gt;&lt;code&gt;tmux ls
tmux kill-session -t &amp;lt;session-name&amp;gt;
&lt;/code&gt;&lt;/quote&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;head rend="h2"&gt;Limitations&lt;/head&gt; Agent teams are experimental. Current limitations to be aware of: &lt;list rend="ul"&gt;&lt;item&gt;No session resumption with in-process teammates: &lt;code&gt;/resume&lt;/code&gt; and &lt;code&gt;/rewind&lt;/code&gt; do not restore in-process teammates. After resuming a session, the lead may attempt to message teammates that no longer exist. If this happens, tell the lead to spawn new teammates.&lt;/item&gt;&lt;item&gt;Task status can lag: teammates sometimes fail to mark tasks as completed, which blocks dependent tasks. If a task appears stuck, check whether the work is actually done and update the task status manually or tell the lead to nudge the teammate.&lt;/item&gt;&lt;item&gt;Shutdown can be slow: teammates finish their current request or tool call before shutting down, which can take time.&lt;/item&gt;&lt;item&gt;One team per session: a lead can only manage one team at a time. Clean up the current team before starting a new one.&lt;/item&gt;&lt;item&gt;No nested teams: teammates cannot spawn their own teams or teammates. Only the lead can manage the team.&lt;/item&gt;&lt;item&gt;Lead is fixed: the session that creates the team is the lead for its lifetime. You can‚Äôt promote a teammate to lead or transfer leadership.&lt;/item&gt;&lt;item&gt;Permissions set at spawn: all teammates start with the lead‚Äôs permission mode. You can change individual teammate modes after spawning, but you can‚Äôt set per-teammate modes at spawn time.&lt;/item&gt;&lt;item&gt;Split panes require tmux or iTerm2: the default in-process mode works in any terminal. Split-pane mode isn‚Äôt supported in VS Code‚Äôs integrated terminal, Windows Terminal, or Ghostty.&lt;/item&gt;&lt;/list&gt;&lt;div&gt;&lt;p&gt;&lt;code&gt;CLAUDE.md&lt;/code&gt; works normally: teammates read &lt;code&gt;CLAUDE.md&lt;/code&gt; files from their working directory. Use this to provide project-specific guidance to all teammates.&lt;/p&gt;&lt;/div&gt;&lt;head rend="h2"&gt;Next steps&lt;/head&gt; Explore related approaches for parallel work and delegation: &lt;list rend="ul"&gt;&lt;item&gt;Lightweight delegation: subagents spawn helper agents for research or verification within your session, better for tasks that don‚Äôt need inter-agent coordination&lt;/item&gt;&lt;item&gt;Manual parallel sessions: Git worktrees let you run multiple Claude Code sessions yourself without automated team coordination&lt;/item&gt;&lt;item&gt;Compare approaches: see the subagent vs agent team comparison for a side-by-side breakdown&lt;/item&gt;&lt;/list&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46902368</guid><pubDate>Thu, 05 Feb 2026 17:49:54 +0000</pubDate></item><item><title>Unsealed Court Documents Show Teen Addiction Was Big Tech's "Top Priority"</title><link>https://techoversight.org/2026/01/25/top-report-mdl-jan-25/</link><description>&lt;doc fingerprint="3d9c9ac80ca4b3e9"&gt;
  &lt;main&gt;
    &lt;p&gt;New documents show the tactics Meta, Google, Snap, and TikTok execs used to disrupt learning, prey on minors, and co-opt the PTA to control the narrative with parents&lt;/p&gt;
    &lt;p&gt;WASHINGTON, DC ‚Äì Today, The Tech Oversight Project published a new report spotlighting newly unsealed documents in the 2026 social media addiction trials. The documents provide smoking-gun evidence that Meta, Google, Snap, and TikTok all purposefully designed their social media products to addict children and teens with no regard for known harms to their wellbeing, and how that mass youth addiction was core to the companies‚Äô business models. The documents contain internal discussions among company employees, presentations from internal meetings, expert testimony, and evidence of Big Tech coordination with tech-funded groups, including the National Parent Teachers Association (PTA) and Family Online Safety Institute (FOSI), in attempts to control the narrative in response to concerned parents.&lt;/p&gt;
    &lt;p&gt;‚ÄúThese unsealed documents prove Big Tech has been gaslighting and lying to the public for years, and it‚Äôs high time parents and young people get their day in court,‚Äù said Sacha Haworth, Executive Director of The Tech Oversight Project. ‚ÄúDisrupted learning and social media addiction are core to Big Tech‚Äôs business model, and while the JCCP and MDL cases have the potential to chip away at their wrongdoing, Congress needs to make good on their years-long promise to pass the Senate‚Äôs version of the Kids Online Safety Act.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;Review of MDL No. 3047 Partially Unsealed Meta Exhibits:&lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt; Docket #2648, filed 1/20/26, *All exhibit numbers prefixed with ‚ÄúAmended‚Äù &lt;/p&gt;
    &lt;head rend="h3"&gt;INTERNAL DOCUMENTS:&lt;/head&gt;
    &lt;p&gt;Exhibit 44: 2016 Teen Growth emails&lt;/p&gt;
    &lt;p&gt;Email stating that ‚ÄúMark has decided that the top priority for the company in H1 2017 is teens‚Äù&lt;/p&gt;
    &lt;p&gt;Exhibit 63: July 2016 internal emails&lt;/p&gt;
    &lt;p&gt;Extensive discussion of Facebook‚Äôs involvement with the Lifestage app indicating that the app was launched with very few safeguards over internal concerns.&lt;/p&gt;
    &lt;p&gt;Exhibit 54: Everyone on Facebook HS Edition&lt;/p&gt;
    &lt;p&gt;Heavily-redacted undated internal document discussing ‚ÄúSchool Blasts‚Äù as a strategy for gaining more high school users (mass notifications sent during the school day).&lt;/p&gt;
    &lt;p&gt;Exhibit 46: 2016 internal employee message&lt;/p&gt;
    &lt;p&gt;Message stating ‚ÄúEngaging the vast majority of teens in an area / school with our products is crucial to driving overall time spent in the same area, especially for Messaging features.‚Äù&lt;/p&gt;
    &lt;p&gt;Exhibit 41: Feb 2018 Youth Small Group Update&lt;/p&gt;
    &lt;p&gt;Internal document discussing the idea of creating a product called ‚ÄúTweens on Facebook‚Äù and piloting a ‚Äúprivate mode‚Äù on Facebook ‚Äì a second account designed to give teens ‚Äúplausible deniability‚Äù (presumably from parents and teachers), inspired by the popularity of ‚Äúfinstas.‚Äù Includes internal discussion on how to counter the narrative that Facebook is bad for youth and admission that internal data shows that Facebook use is correlated with lower well-being (although it says the effect reverses longitudinally).&lt;/p&gt;
    &lt;p&gt;Exhibit 1179: Document Titled ‚ÄúSchoooools Review,‚Äù February 8, 2018&lt;/p&gt;
    &lt;p&gt;Heavily-redacted internal document ‚Äì ‚Äúone of the key goals of the Youth Growth team is to get teens onto Facebook and to stay there.‚Äù&lt;/p&gt;
    &lt;p&gt;Exhibit 68: 2018 Instagram Ambassador Program&lt;/p&gt;
    &lt;p&gt;Internal document discussing ambassador program for recruiting and onboarding ‚Äúteen tastemakers to act as our plug at local high schools.‚Äù The ideal ambassador profile is someone 13-17 who is ‚Äúdiverse‚Äù and ‚Äúwell-connected to peers.‚Äù Includes compensation, incentives, and swag for ambassadors, who would have to sign NDAs.&lt;/p&gt;
    &lt;p&gt;Exhibit 69: 2018 ‚ÄúHigh School Directory ‚Äì Product Messaging &amp;amp; Launch Doc. [working draft]‚Äù&lt;/p&gt;
    &lt;p&gt;Document detailing a ‚Äúhigh school directory‚Äù feature product launch on Instagram. Details plans to use Teen Ambassador Network and community channels to create buzz and drive adoption.&lt;/p&gt;
    &lt;p&gt;Exhibit 45: 2018 Youth Team Review&lt;/p&gt;
    &lt;p&gt;Document laying out multi-year youth acquisition strategy for Meta starting with very young users, noting that ‚ÄúFacebook is likely U13‚Äôs (under-13‚Äôs) first social media app (driven by parents).‚Äù Discusses ‚Äúfocusing on each youth life stage‚Äù from ‚ÄúKid‚Äù (ages 6-10) to ‚ÄúTeen‚Äù (13+). Discusses three ‚Äúlevers‚Äù for driving teen growth: school profile completion; demoting meme content; and boosting teen producer content in the news feed.&lt;/p&gt;
    &lt;p&gt;Exhibit 73: Message Titled ‚ÄúInstagram Insights,‚Äù October 18, 2018&lt;/p&gt;
    &lt;p&gt;Details results of an interview study on conflicts on Instagram. ‚ÄúCurrent classifiers and policies do not address many of these conflicts.‚Äù ‚ÄúTeens weaponize IG features to torment each other, often without violating standards.‚Äù ‚ÄúIG conflicts are common and painful; most participants regret engaging in conflicts‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúWhat pain points do Black users aged 13-14 experience on Instagram?‚Äù ‚ÄúYoung Black users of Instagram report experiences of cultural appropriation and race-based negativity on the platform.‚Äù&lt;/p&gt;
    &lt;p&gt;Exhibit 53: 2023 ‚ÄúControlling the Narrative‚Äù slide deck&lt;/p&gt;
    &lt;p&gt;Heavily-redacted slide deck includes suggestion that Instagram could ‚Äúuse school networks as a lever for acquisition‚Äù to better compete with Snap and a desire to ‚Äúposition Instagram as integral to navigating school relationships, especially during transition periods‚Äù like graduating/changing schools.&lt;/p&gt;
    &lt;p&gt;Exhibit 39: Unnamed Meta employee deposition, 5/8/25&lt;/p&gt;
    &lt;p&gt;Employee deposition discussing National PTA partnership.&lt;/p&gt;
    &lt;head rend="h3"&gt;EXPERT REPORTS:&lt;/head&gt;
    &lt;p&gt;Exhibit 997: Expert Report of Seth Noar, May 16, 2025&lt;/p&gt;
    &lt;p&gt;Concluding that Defendants did not provide effective warnings to adolescent users and parents about the risks and harms of social media use.&lt;/p&gt;
    &lt;p&gt;Exhibit 989: Expert Report by Tim Estes, May 16, 2025&lt;/p&gt;
    &lt;p&gt;Concluding that Defendants‚Äô platforms were not designed to be reasonably safe for children, and that age verification and parental consent/control systems were ineffective.&lt;/p&gt;
    &lt;head rend="h3"&gt;PREVIOUSLY-REPORTED MATERIAL:&lt;/head&gt;
    &lt;p&gt;Exhibit 373: Email Exchange with Subject ‚ÄúRe: Teens Council,‚Äù February 7, 2015&lt;/p&gt;
    &lt;p&gt;‚ÄúWe learned one of the things we need to optimize for is sneaking a look at your phone under your desk in the middle of Chemistry :)‚Äù&lt;/p&gt;
    &lt;p&gt;Exhibit 43: 2017 employee chat logs&lt;/p&gt;
    &lt;p&gt;Discussion of mapping teen locations to specific schools ‚Äì likely a privacy violation. Parts of this document were previously unsealed.&lt;/p&gt;
    &lt;p&gt;Infamously state that ‚ÄúThe lifetime value of a 13 y/o teen is roughly $270 per teen.‚Äù&lt;/p&gt;
    &lt;p&gt;Internal research demonstrating that young users have greater long term retention.&lt;/p&gt;
    &lt;p&gt;Exhibit 75: Slides titled ‚ÄúTeen Mental Health: Creatures of Habit,‚Äù August/September 2019&lt;/p&gt;
    &lt;p&gt;Results of a study on teen mental health. Toplines include the following:&lt;/p&gt;
    &lt;p&gt;‚ÄúTeens can‚Äôt switch off from Instagram even if they want to‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúTeens talk of Instagram in terms of an ‚Äòaddicts narrative‚Äô spending too much time indulging in a compulsive behaviour that they know is negative but feel powerless to resist.‚Äù&lt;/p&gt;
    &lt;p&gt;Exhibit 74: Message exchange, September 10, 2020&lt;/p&gt;
    &lt;p&gt;Employee message exchange comparing Instagram to drugs and slot machines. ‚ÄúOh my gosh yall IG is a drug‚Äù ‚ÄúLol, I mean , all social media. We‚Äôre basically pushers‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;Review of MDL No. 3047 Partially Unsealed Google/YouTube Exhibits:&lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt; Docket #2651, filed 1/20/26. *All exhibit numbers prefixed with ‚ÄúAmended‚Äù&lt;/p&gt;
    &lt;head rend="h3"&gt;INTERNAL DOCUMENTS:&lt;/head&gt;
    &lt;p&gt;Exhibit 774: February 2018 Slides- ‚ÄúDigital Wellness Overview ‚Äì YT Autoplay‚Äù&lt;/p&gt;
    &lt;p&gt;Slidedeck on the role that YouTube‚Äôs autoplay feature plays in ‚ÄúTech Addiction‚Äù that concludes ‚ÄúVerdict: Autoplay could be potentially disrupting sleep patterns. Disabling or limiting Autoplay during the night could result in sleep savings.‚Äù&lt;/p&gt;
    &lt;p&gt;Exhibit 1062: May 2018 email chain with James Beser ‚ÄúRe: screentime conversation‚Äù&lt;/p&gt;
    &lt;p&gt;Email chain with YouTube product management director James Besar in which an educator suggests that parents limit children‚Äôs screen time before school.&lt;/p&gt;
    &lt;p&gt;Exhibit 758: December 2018 Slides ‚Äì ‚ÄúG Suite for Education‚Äù&lt;/p&gt;
    &lt;p&gt;Slidedeck reviewing G Suite for Education that includes the statements ‚ÄúYouTube isn‚Äôt safe, often blocked in schools.‚Äù ‚ÄúNo way to block unsafe content, comments, ads.‚Äù ‚ÄúEfforts to make YouTube safe for schools have yet to work.‚Äù&lt;/p&gt;
    &lt;p&gt;Exhibit 757: 2019 Slides ‚Äì ‚ÄúYouTube via G Suite‚Äù&lt;/p&gt;
    &lt;p&gt;Slidedeck discussing the ‚ÄúManaged Restricted Mode‚Äù (MRM) management tool allowing administrators to manage users and permission in a domain. ‚ÄúThe YouTube experience in K-12 schools is broken.‚Äù ‚ÄúExample 3: Ads and content appropriateness concerns cause YT to be blocked.‚Äù ‚ÄúYouTube via G Suite is ads-supported and brings some content risk.‚Äù&lt;/p&gt;
    &lt;p&gt;Exhibit 772: 2019 Internal Document ‚Äì ‚Äú2019 Strategy Offsite Two Pagers‚Äù&lt;/p&gt;
    &lt;p&gt;Discussing efforts to improve digital well-being, particularly among youth. Identified three concern areas impacting users 13-24 disproportionately: habitual heavy use, late night use, and unintentional use.&lt;/p&gt;
    &lt;p&gt;Exhibit 741: November 2020 Slides ‚Äì ‚ÄúBusiness Case for Kids and Families at Google‚Äù&lt;/p&gt;
    &lt;p&gt;Google document detailing a business plan to expand products and access to children. ‚ÄúOnboarding kids into Google‚Äôs Ecosystem leads to brand trust and loyalty over their lifetime‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúSo essentially making the case that it‚Äôs not just schools, but it‚Äôs also a compelling ‚Äúcool‚Äù product that keeps a kid/teen for life.‚Äù&lt;/p&gt;
    &lt;p&gt;Exhibit 1061: September 2021 Slides ‚Äì ‚ÄúYouTube Watch: Autoplay &amp;amp; DWB‚Äù&lt;/p&gt;
    &lt;p&gt;Slidedeck with editor comments discussing user wellbeing. ‚ÄúStatus Quo Take a Break and Bedtime reminders are currently only available on Android/iOS, despite [redacted] of YTT taking place on Web.‚Äù ‚ÄúCurrently most of our wellbeing tools require going into settings with the intention to use them.‚Äù ‚ÄúDo people even know we have these tools? How many people actually use them?‚Äù ‚ÄúHow are we measuring wellbeing? Current answer ‚Äì we‚Äôre not?‚Äù&lt;/p&gt;
    &lt;p&gt;Emails discussing initiatives to appeal to teens. ‚ÄúShorts is our big thing for teen appeal. But beyond just Shorts, we‚Äôve instituted a teen focus across our core experiences, including setting a teen-specific fun, engagement, and responsibility OKRs.‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúMRM tends to be trivially easy for students to bypass if they clear cookies, sign out, open an incognito tab, or switch devices, so generally it‚Äôs not a high priority to make these blocks completely foolproof.‚Äù&lt;/p&gt;
    &lt;p&gt;Slide deck analyzing teen and millennial views and behavior concerning YouTube. ‚Äú‚ÄòDown the Rabbit-Hole‚Äô Phenomenon. 1 in 4 Millennials admit they‚Äôve been ‚Äòlate to work because they spent too long on their phone.‚Äù Includes statistics on the influence of YouTube in shaping the personal opinions and lives of 13-17 year olds.&lt;/p&gt;
    &lt;p&gt;Exhibit 732: ‚ÄúTeen (Unsupervised) Viewer Wellbeing and Safety) (DRAFT),‚Äù (Undated)&lt;/p&gt;
    &lt;p&gt;Document discussing perceptions and challenges related to teen wellbeing and safety on YouTube. ‚ÄúHowever, we still have work to do on the two biggest challenges for teen wellbeing on YouTube: (1) low quality content recommendations that can convey &amp;amp; normalize unhealthy beliefs or behaviors (2) prolonged unintentional use displacing valuable activities like time with friends or sleep. These concerns are loudest on short form content (more popular with teens) due to its lack of depth and infinite feed experience.‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúWe don‚Äôt know if our break and bedtime reminders ‚Äòwork‚Äô (and haven‚Äôt looked too deeply). What is YT‚Äôs responsibility in this area? Should we do more sensitive Research to understand better, especially for Shorts?‚Äù&lt;/p&gt;
    &lt;p&gt;Internal slidedeck admitting ‚Äúnegative wellbeing effects can result from user behaviors‚Äù and documenting four video-watching behaviors that bring about the majority of negative wellbeing effects: (1) late night use, (2) heavy habitual use, (3) unintentional use, and (4) problematic content.&lt;/p&gt;
    &lt;head rend="h3"&gt;EXECUTIVE DEPOSITIONS:&lt;/head&gt;
    &lt;p&gt;Exhibit 1012: April 24, 2025 Deposition of Neal Mohan (CEO of YouTube)&lt;lb/&gt; Deposition of Neal Mohan, CEO of YouTube.&lt;/p&gt;
    &lt;head rend="h3"&gt;PREVIOUSLY-REPORTED MATERIAL:&lt;/head&gt;
    &lt;p&gt;Literature review of research on the effect of digital videos on viewer well-being. ‚ÄúWatching short videos results in a ‚Äòquick fix‚Äô of dopamine. Dopamine is related to feelings of reward. Similar to feelings of reward when using drugs or other addictive substances.‚Äù ‚ÄúResearchers feel that YT is built with the intention of being addictive. Designed with tricks to encourage binge-watching (i.e. autoplay, recommendations, etc).‚Äù ‚ÄúNotifications are a critical part of YouTube and contribute to addiction.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;Review of MDL No. 3047 Partially Unsealed Snap Exhibits:&lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt; Docket #2649, filed 1/20/26. *All exhibit numbers prefixed with ‚ÄúAmended‚Äù &lt;/p&gt;
    &lt;head rend="h3"&gt;INTERNAL DOCUMENTS:&lt;/head&gt;
    &lt;p&gt;Exhibit 845: 2017 ‚ÄúSnap Habits‚Äù slides&lt;/p&gt;
    &lt;p&gt;Slide citing internal research showing that 64% of Snapchatters ages 13-21 use Snapchat during school.&lt;/p&gt;
    &lt;p&gt;Exhibit 826: March 2017 Email Chain ‚ÄúRe: MoffettNathanson | SNAP: A Middle School Crush?‚Äù&lt;/p&gt;
    &lt;p&gt;Internal email chain in which Snap CEO Evan Spiegel asking for full text of an article reporting that ‚Äúdespite the rules that don‚Äôt allow those under the age of 13 to be on Snapchat, our focus group clearly showed that the middle school set was a rabid ‚Äì almost exclusive ‚Äì user of Snapchat.‚Äù&lt;/p&gt;
    &lt;p&gt;Exhibit 849: March 2023 ‚ÄúSocial Media ‚Äì Wellness Perception Research‚Äù slides&lt;/p&gt;
    &lt;p&gt;Includes a slide listing design opportunities to address ‚Äúnegative perceptions‚Äù about youth and social media, few to none of which were ever adopted.&lt;/p&gt;
    &lt;head rend="h3"&gt;EXECUTIVE DEPOSITIONS:&lt;/head&gt;
    &lt;p&gt;Exhibit 803: Deposition of Evan T. Spiegel (CEO of Snap), April 11, 2025&lt;/p&gt;
    &lt;p&gt;Moderately-redacted deposition transcript with questions addressing topics including internal documents regarding teen safety as well as Spiegel‚Äôs previous statements to Congress.&lt;/p&gt;
    &lt;head rend="h2"&gt;Review of MDL No. 3047 Partially Unsealed TikTok Exhibits:&lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt; Docket #2650, filed 1/20/26. *All exhibit numbers prefixed with ‚ÄúAmended‚Äù &lt;/p&gt;
    &lt;head rend="h3"&gt;INTERNAL DOCUMENTS:&lt;/head&gt;
    &lt;p&gt;Exhibit 453: February 2020 ‚ÄúPTA/FOSI working group‚Äù employee messages&lt;/p&gt;
    &lt;p&gt;Heavily-redacted employee conversation discussing an event held by TikTok in conjunction with the National PTA (‚ÄúPTA‚Äù) and the Family Online Safety Institute (‚ÄúFOSI‚Äù). One chat participant says that they are happy that news crews did not show up to the event because ‚ÄúThis student panel is primarily under 13 and they‚Äôre all talking about what they post why they post and how they know they‚Äôre not supposed to have an account.‚Äù Another comment says ‚Äúa parent asked ‚Äò how old were you when you started using social media.‚Äô All of them said btwn ages 8-12 and admitted to lieing about their birthdate to get around it. One girl said she‚Äôs 20 on Instagram‚Äù&lt;/p&gt;
    &lt;p&gt;Exhibit 537: September 2021 ‚Äú[External] Digital Wellbeing Product Strategy‚Äù internal document&lt;/p&gt;
    &lt;p&gt;Heavily-redacted internal document states: ‚ÄúWe have built some important (digital wellbeing) foundational features, but there is a lot of room for them to grow ‚Ä¶ ‚Äúwe have learned from [link to internal research] that our users‚Äô biggest usage deterrent is that they think the platform is addictive ‚Ä¶ In sum, compulsive usage on TikTok is rampant and our users need better tools to understand their usage, manage it effectively, and ensure being on TikTok is time well spent‚Äù ‚Ä¶ ‚ÄúTikTok is particularly popular with younger users, who are particularly sensitive to reinforcement in the form of social reward and have minimal ability to self-regulate effectively.‚Äù&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46902512</guid><pubDate>Thu, 05 Feb 2026 18:00:07 +0000</pubDate></item><item><title>GPT-5.3-Codex</title><link>https://openai.com/index/introducing-gpt-5-3-codex/</link><description>&lt;doc fingerprint="bd5265dde40bc41c"&gt;
  &lt;main&gt;
    &lt;p&gt;We‚Äôre introducing a new model that unlocks even more of what Codex can do: GPT‚Äë5.3-Codex, the most capable agentic coding model to date. The model advances both the frontier coding performance of GPT‚Äë5.2-Codex and the reasoning and professional knowledge capabilities of GPT‚Äë5.2, together in one model, which is also 25% faster. This enables it to take on long-running tasks that involve research, tool use, and complex execution. Much like a colleague, you can steer and interact with GPT‚Äë5.3-Codex while it‚Äôs working, without losing context.&lt;/p&gt;
    &lt;p&gt;GPT‚Äë5.3‚ÄëCodex is our first model that was instrumental in creating itself. The Codex team used early versions to debug its own training, manage its own deployment, and diagnose test results and evaluations‚Äîour team was blown away by how much Codex was able to accelerate its own development.&lt;/p&gt;
    &lt;p&gt;With GPT‚Äë5.3-Codex, Codex goes from an agent that can write and review code to an agent that can do nearly anything developers and professionals can do on a computer.&lt;/p&gt;
    &lt;p&gt;GPT‚Äë5.3-Codex sets a new industry high on SWE-Bench Pro and Terminal-Bench, and shows strong performance on OSWorld and GDPval, four benchmarks we use to measure coding, agentic and real-world capabilities.&lt;/p&gt;
    &lt;p&gt;GPT‚Äë5.3-Codex achieves state-of-the-art performance on SWE-Bench Pro, a rigorous evaluation of real-world software engineering. Where SWE‚Äëbench Verified only tests Python, SWE‚ÄëBench Pro spans four languages and is more contamination‚Äëresistant, challenging, diverse and industry-relevant. It also far exceeds the previous state-of-the-art performance on Terminal-Bench 2.0, which measures the terminal skills a coding agent like Codex needs. Notably, GPT‚Äë5.3‚ÄëCodex does so with fewer tokens than any prior model, letting users build more.&lt;/p&gt;
    &lt;p&gt;Combining frontier coding capabilities, improvements in aesthetics, and compaction results in a model that can do striking work, building highly functional complex games and apps from scratch over the course of days. To test the model‚Äôs web development and long-running agentic capabilities, we asked GPT‚Äë5.3‚ÄëCodex to build us two games: version two of the racing game from the Codex app launch, and a diving game. Using the develop web game skill and preselected, generic follow-up prompts like "fix the bug" or "improve the game", GPT‚Äë5.3-Codex iterated on the games autonomously over millions of tokens. Watch the trailers and play the games for yourself to see what Codex can do.&lt;/p&gt;
    &lt;p&gt;GPT‚Äë5.3-Codex also better understands your intent when you ask it to make day-to-day websites, compared to GPT‚Äë5.2-Codex. Simple or underspecified prompts now default to sites with more functionality and sensible defaults, giving you a stronger starting canvas to bring your ideas to life.&lt;/p&gt;
    &lt;p&gt;For example, we asked GPT‚Äë5.3-Codex and GPT‚Äë5.2-Codex to build two landing pages below. GPT‚Äë5.3-Codex automatically showed the yearly plan as a discounted monthly price, making the discount feel clear and intentional, instead of multiplying the yearly total. It also made an automatically transitioning testimonial carousel with three distinct user quotes rather than one, resulting in a page that feels more complete and production-ready by default.&lt;/p&gt;
    &lt;p&gt;Software engineers, designers, product managers, and data scientists do far more than generate code. GPT‚Äë5.3‚ÄëCodex is built to support all of the work in the software lifecycle‚Äîdebugging, deploying, monitoring, writing PRDs, editing copy, user research, tests, metrics, and more. Its agentic capabilities go beyond software, helping you build whatever you want to build‚Äîwhether it‚Äôs slide decks or analyzing data in sheets.&lt;/p&gt;
    &lt;p&gt;With custom skills similar to those used for our previous GDPval results, GPT‚Äë5.3‚ÄëCodex also shows strong performance on professional knowledge work as measured by GDPval, matching GPT‚Äë5.2. GDPval is an evaluation OpenAI released in 2025 that measures a model‚Äôs performance on well‚Äëspecified knowledge‚Äëwork tasks across 44 occupations. These tasks include things like making presentations, spreadsheets, and other work products.&lt;/p&gt;
    &lt;p&gt;Below are a few examples of the work the agent produced.&lt;/p&gt;
    &lt;head rend="h3"&gt;Prompt + task context&lt;/head&gt;
    &lt;head rend="h3"&gt;GPT-5.3-Codex output&lt;/head&gt;
    &lt;p&gt;OSWorld is an agentic computer-use benchmark where the agent has to complete productivity tasks in a visual desktop computer environment. GPT‚Äë5.3-Codex demonstrates far stronger computer use capabilities than previous GPT models.&lt;/p&gt;
    &lt;p&gt;Together, these results across coding, frontend, and computer-use and real-world tasks show that GPT‚Äë5.3-Codex isn‚Äôt just better at individual tasks, but marks a step change toward a single, general-purpose agent that can reason, build, and execute across the full spectrum of real-world technical work.&lt;/p&gt;
    &lt;p&gt;As model capabilities become more powerful, the gap shifts from what agents are capable of doing to how easily humans can interact with, direct and supervise many of them working in parallel. The Codex app makes managing and directing agents much easier, and now with GPT‚Äë5.3-Codex it‚Äôs more interactive. With the new model, Codex provides frequent updates so you stay appraised of key decisions and progress as it works. Instead of waiting for a final output, you can interact in real time‚Äîask questions, discuss approaches, and steer toward the solution. GPT‚Äë5.3-Codex talks through what it‚Äôs doing, responds to feedback, and keeps you in the loop from start to finish.&lt;/p&gt;
    &lt;p&gt;The recent rapid Codex improvements build on the fruit of research projects spanning months or years across all of OpenAI. These research projects are being accelerated by Codex, with many researchers and engineers at OpenAI describing their job today as being fundamentally different from what it was just two months ago. Even early versions of GPT‚Äë5.3-Codex demonstrated exceptional capabilities, allowing our team to work with those earlier versions to improve training and support the deployment of later versions.&lt;/p&gt;
    &lt;p&gt;Codex is useful for a very broad range of tasks, making it difficult to fully enumerate the ways in which it helps our teams. As some examples, the research team used Codex to monitor and debug the training run for this release. It accelerated research beyond debugging infrastructure problems: it helped track patterns throughout the course of training, provided a deep analysis on interaction quality, proposed fixes and built rich applications for human researchers to precisely understand how the model‚Äôs behavior differed compared to prior models.&lt;/p&gt;
    &lt;p&gt;The engineering team used Codex to optimize and adapt the harness for GPT‚Äë5.3-Codex. When we started seeing strange edge cases impacting users, team members used Codex to identify context rendering bugs, and root cause low cache hit rates. GPT‚Äë5.3-Codex is continuing to help the team throughout the launch by dynamically scaling GPU clusters to adjust to traffic surges and keeping latency stable.&lt;/p&gt;
    &lt;p&gt;During alpha testing, one researcher wanted to understand how much additional work GPT‚Äë5.3-Codex was getting done per turn and the associated difference in productivity. GPT‚Äë5.3-Codex came up with several simple regex classifiers to estimate frequency of clarifications, positive and negative user responses, progress on the task, and then ran them scalably over all session logs and produced a report with its conclusion. People building with Codex were happier as the agent was better understanding their intent and made more progress per turn, with fewer clarifying questions.&lt;/p&gt;
    &lt;p&gt;Due to GPT‚Äë5.3-Codex being so different from its predecessors, the data from alpha testing exhibited numerous unusual and counter-intuitive results. A data scientist on the team worked with GPT‚Äë5.3-Codex to build new data pipelines and visualize the results much more richly than our standard dashboarding tools enabled. The results were co-analyzed with Codex, which concisely summarized key insights over thousands of data points in under three minutes.&lt;/p&gt;
    &lt;p&gt;Individually, all of these tasks are interesting examples of how Codex can help researchers and product builders. Taken together, we found that these new capabilities resulted in powerful acceleration of our research, engineering, and product teams.&lt;/p&gt;
    &lt;p&gt;Over recent months, we‚Äôve seen meaningful gains in model performance on cybersecurity tasks, benefiting both developers and security professionals. In parallel, we‚Äôve been preparing strengthened cyber safeguards to support defensive use and broader ecosystem resilience.&lt;/p&gt;
    &lt;p&gt;GPT‚Äë5.3-Codex is the first model we classify as High capability for cybersecurity-related tasks under our Preparedness Framework, and the first we‚Äôve directly trained to identify software vulnerabilities. While we don‚Äôt have definitive evidence it can automate cyber attacks end-to-end, we‚Äôre taking a precautionary approach and deploying our most comprehensive cybersecurity safety stack to date. Our mitigations include safety training, automated monitoring, trusted access for advanced capabilities, and enforcement pipelines including threat intelligence.&lt;/p&gt;
    &lt;p&gt;Because cybersecurity is inherently dual-use, we‚Äôre taking an evidence-based, iterative approach that accelerates defenders‚Äô ability to find and fix vulnerabilities while slowing misuse. As part of this, we‚Äôre launching Trusted Access for Cyber, a pilot program to accelerate cyber defense research.&lt;/p&gt;
    &lt;p&gt;We‚Äôre investing in ecosystem safeguards such as expanding the private beta of Aardvark, our security research agent, as the first offering in our suite of Codex Security products and tools, and partnering with open-source maintainers to provide free codebase scanning for widely used projects such as Next.js‚Äîwhere a security researcher used Codex to find vulnerabilities disclosed(opens in a new window) last week.&lt;/p&gt;
    &lt;p&gt;Building on our $1M Cybersecurity Grant Program launched in 2023, we‚Äôre also committing $10M in API credits to accelerate cyber defense with our most capable models, especially for open source software and critical infrastructure systems. Organizations engaged in good-faith security research can apply for API credits and support through our Cybersecurity Grant Program.&lt;/p&gt;
    &lt;p&gt;GPT‚Äë5.3-Codex is available with paid ChatGPT plans, everywhere you can use Codex: the app, CLI, IDE extension and web. We are working to safely enable API access soon.&lt;/p&gt;
    &lt;p&gt;With this update, we are also now running GPT‚Äë5.3-Codex 25% faster for Codex users, thanks to improvements in our infrastructure and inference stack, resulting in faster interactions and faster results.&lt;/p&gt;
    &lt;p&gt;GPT‚Äë5.3-Codex was co-designed for, trained with, and served on NVIDIA GB200 NVL72 systems. We are grateful to NVIDIA for their partnership.&lt;/p&gt;
    &lt;p&gt;With GPT‚Äë5.3-Codex, Codex is moving beyond writing code to using it as a tool to operate a computer and complete work end to end. By pushing the frontier of what a coding agent can do, we‚Äôre also unlocking a broader class of knowledge work‚Äîfrom building and deploying software to researching, analyzing, and executing complex tasks. What started as a focus on being the best coding agent has become the foundation for a more general collaborator on the computer, expanding both who can build and what‚Äôs possible with Codex.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;p&gt;GPT-5.3-Codex (xhigh)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;GPT-5.2-Codex (xhigh)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;GPT-5.2 (xhigh)&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;p&gt;SWE-Bench Pro (Public)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;56.8%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;56.4%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;55.6%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;p&gt;Terminal-Bench 2.0&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;77.3%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;64.0%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;62.2%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;p&gt;OSWorld-Verified&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;64.7%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;38.2%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;37.9%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;p&gt;GDPval (wins or ties)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;70.9%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;-&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;70.9% (high)&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;p&gt;Cybersecurity Capture The Flag Challenges&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;77.6%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;67.4%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;67.7%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;SWE-Lancer IC Diamond&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;81.4%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;76.0%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;74.6%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46902638</guid><pubDate>Thu, 05 Feb 2026 18:08:08 +0000</pubDate></item></channel></rss>