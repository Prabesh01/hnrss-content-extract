<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 25 Dec 2025 04:55:38 +0000</lastBuildDate><item><title>CSRF protection without tokens or hidden form fields</title><link>https://blog.miguelgrinberg.com/post/csrf-protection-without-tokens-or-hidden-form-fields</link><description>&lt;doc fingerprint="3d02d1187cb13ead"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;CSRF Protection without Tokens or Hidden Form Fields&lt;/head&gt;&lt;head rend="h2"&gt;Posted by&lt;/head&gt;on under&lt;p&gt;A couple of months ago, I received a request from a random Internet user to add CSRF protection to my little web framework Microdot, and I thought it was a fantastic idea.&lt;/p&gt;&lt;p&gt;When I set off to do this work in early November I expected I was going to have to deal with anti-CSRF tokens, double-submit cookies and hidden form fields, pretty much the traditional elements that we have used to build a defense against CSRF for years. And I did start along this tedious route. But then I bumped into a new way some people are dealing with CSRF attacks that is way simpler, which I describe below.&lt;/p&gt;&lt;head rend="h2"&gt;Implementing a security feature&lt;/head&gt;&lt;p&gt;An often shared piece of advice is that you should never implement security features yourself. Instead, you should look for well established solutions built by people who think about security day in and day out.&lt;/p&gt;&lt;p&gt;Unfortunately, as the lead (and only) maintainer of Microdot, I do not have an ecosystem of existing solutions available to me. Even though I gladly accept external contributions, most of the framework has been built by myself out of nothing. So in this case, like many other times before, I felt I had no choice but to go against the standard advice and write CSRF protection code by myself, because if I didn't do it then the feature would not be built.&lt;/p&gt;&lt;p&gt;What is the first step when you need to build a security feature? Check out what OWASP has to say about the matter.&lt;/p&gt;&lt;p&gt;So, in early November, I opened OWASP's CSRF Prevention Cheat Sheet page to see what was new and interesting in the world of CSRF protection. And I found that nothing of significance had changed.&lt;/p&gt;&lt;p&gt;According to OWASP, the best CSRF protection you could get (at the time I checked) was still built around the idea of using anti-CSRF tokens. So I set off to implement this for Microdot.&lt;/p&gt;&lt;head rend="h2"&gt;A disturbance in the (CSRF) force&lt;/head&gt;&lt;p&gt;I was happily making progress on my CSRF implementation, and then in early December, another random Internet user dropped an issue on the Flask repository, proposing that Flask adds support for "modern" CSRF protection. Modern? How could there be a new way to protect against CSRF that isn't mentioned by OWASP?&lt;/p&gt;&lt;p&gt;This led me down a rabbit hole of blog posts and discussions spanning the Go and Ruby communities, plus a long discussion about this method on the OWASP GitHub repository itself, resulting in a pull request that added a mention of this method to the CSRF Cheat Sheet, only a couple of weeks after I went to this page looking for guidance for my own implementation.&lt;/p&gt;&lt;head rend="h2"&gt;Modern CSRF Protection&lt;/head&gt;&lt;p&gt;The so called "modern" method to protect against CSRF attacks is based on the Sec-Fetch-Site header, which all modern desktop and mobile browsers include in the requests they send to servers. According to Mozilla, all browsers released since March 2023 have support for this header.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;Sec-Fetch-Site&lt;/code&gt; header can have one of four values:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;same-origin&lt;/code&gt;, when the request comes from the same origin as the target server&lt;/item&gt;&lt;item&gt;&lt;code&gt;same-site&lt;/code&gt;, when the request comes from the same site, but not exactly the same origin (e.g. a different subdomain) as the target server&lt;/item&gt;&lt;item&gt;&lt;code&gt;cross-site&lt;/code&gt;, when the request comes from an origin that does not match the target server&lt;/item&gt;&lt;item&gt;&lt;code&gt;none&lt;/code&gt;, when the request is originated by the user&lt;/item&gt;&lt;/list&gt;&lt;p&gt;The value of this header cannot be set via JavaScript, so the server can assume that a) if this header is present, then the client is a web browser, and b) the value of the header can be trusted. So basically, the server can reject requests that come with this header set to &lt;code&gt;cross-site&lt;/code&gt;, and in essence that is all you need to do to protect against CSRF!&lt;/p&gt;&lt;p&gt;After seeing this, I paused my work on the token-based CSRF implementation and spent a few hours to implement this modern approach. As always, the devil is in the details, so let's see what else I needed to do to build a complete solution.&lt;/p&gt;&lt;p&gt;First of all, in some cases subdomains sharing the same registered domain may operate independently, and as such, it is not out of the question that one subdomain may attempt to attack another through CSRF. Depending on the level of trust an application has for other subdomains, a server may want to block requests that come with the &lt;code&gt;Sec-Fetch-Site&lt;/code&gt; header set to &lt;code&gt;same-site&lt;/code&gt;. In Microdot, I have added an argument &lt;code&gt;allow_subdomains&lt;/code&gt; to cover this case. I decided to err on the side of security, so the default is &lt;code&gt;False&lt;/code&gt;, meaning that requests from subdomains are also blocked.&lt;/p&gt;&lt;p&gt;The other big problem is that not everyone is using a recent browser that implements this header. Looking at the browser compatibility for the &lt;code&gt;Sec-Fetch-Site&lt;/code&gt; header, you can see that most browsers implemented this feature long ago, between 2019 and 2021, with one notable exception: Safari. Apple added this header to its browser in 2023, so it is reasonable to assume that there are still users out there running older browsers that do not support it.&lt;/p&gt;&lt;p&gt;One option is to reject all requests that do not have the &lt;code&gt;Sec-Fetch-Site&lt;/code&gt; header. This keeps everyone secure, but of course, there's going to be some unhappy users of old devices that will not be able to use your application. Plus, this would also reject HTTP clients that are not browsers. If this is not a problem for your use case, then great, but it isn't a good solution overall.&lt;/p&gt;&lt;p&gt;From what I gathered from looking at other implementations of this method, an accepted solution is to use the &lt;code&gt;Origin&lt;/code&gt; header as fallback when &lt;code&gt;Sec-Fetch-Site&lt;/code&gt; is not implemented, since this header has been around for much longer. The last of the major browsers to add it were Firefox desktop in 2019 and Edge and Firefox mobile in 2020. Like &lt;code&gt;Sec-Fetch-Site&lt;/code&gt;, the &lt;code&gt;Origin&lt;/code&gt; header is also a restricted header that is set by the browser, so it can also be used to determine from where a request is coming from.&lt;/p&gt;&lt;p&gt;The problem with using the &lt;code&gt;Origin&lt;/code&gt; header is that it isn't always easy to know what is the correct origin that applies to a web application. The standard option is to compare the value of the &lt;code&gt;Origin&lt;/code&gt; header against the value of the &lt;code&gt;Host&lt;/code&gt; header, but &lt;code&gt;Host&lt;/code&gt; only includes the hostname and port, while &lt;code&gt;Origin&lt;/code&gt; also includes the scheme. Also, the &lt;code&gt;Host&lt;/code&gt; header is overwritten as it passes through reverse proxies. So comparing these two headers is actually not easy.&lt;/p&gt;&lt;p&gt;Another, more direct option is to ask the user to configure the expected origin name explicitly. To keep things simple, in Microdot I opted for the explicit configuration, for which I linked to the existing Cross-Origin Request Sharing (CORS) support. The CORS feature already maintains a list of allowed origins, so my CSRF logic automatically trusts these. I decided to not complicate myself adding support for &lt;code&gt;Host&lt;/code&gt; header checks at this time, but maybe I'll add this in the future.&lt;/p&gt;&lt;p&gt;Filippo Valsorda, a security developer active in the Go ecosystem (and author of the popular mkcert tool) wrote a blog post about this method that you may want to check out if you want to learn more details about it. He seems to be the first to propose this method and has implemented it for the Go standard library.&lt;/p&gt;&lt;p&gt;Also if you are interested, feel free to review my implementation of CSRF protection in Microdot. Have a look at the documentation, the code and an example, and let me know if you have any improvements or fixes to suggest.&lt;/p&gt;&lt;head rend="h2"&gt;Let's revisit OWASP&lt;/head&gt;&lt;p&gt;Note: this section is now out of date. As of December 24th 2025 the OWASP CSRF Cheat Sheet page lists the Fetch Metadata method as a complete solution that can be used as an alternative to token-based approaches.&lt;/p&gt;&lt;p&gt;As I mentioned above, the CSRF Prevention Cheat Sheet page from OWASP was updated in early December to include the use of the &lt;code&gt;Sec-Fetch-Site&lt;/code&gt; header in the list of prevention methods. But this method is currently listed as a defense in depth mechanism, and not a complete solution, which I thought was odd.&lt;/p&gt;&lt;p&gt;I referenced the discussion in the OWASP GitHub repository that resulted in the recent changes made to the Cheat Sheet page. Several participants in that discussion have suggested that this method should be upgraded to a complete alternative to the standard token-based approaches. The OWASP maintainer was initially skeptical, but towards the end of the thread they have agreed. The pull request that closed the discussion added this solution as an alternative to the token-based approaches, but then a later change made significant updates, including the downgrade to defense in depth. My hope is that this is just a misunderstanding, and that the OWASP folks will restore the content as it was agreed by all the parties involved.&lt;/p&gt;&lt;p&gt;In any case, I consider that in Microdot, going from no CSRF support at all to this is a great step forward that is also consistent with the minimalist ethos of the project. I will be keeping an eye on the OWASP CSRF Cheat Sheet page to see what is their final word on this new protection method, and if they end up keeping it as defense in depth, I still have a mostly complete implementation of double-submit anti-CSRF tokens that I can bring into my project.&lt;/p&gt;&lt;head rend="h2"&gt;Conclusion&lt;/head&gt;&lt;p&gt;What I like the most about working in open source is that all the work happens in the open, so it is a permanent record that can be searched and reviewed. My CSRF protection journey started as a somewhat tedious exercise in the use of cryptography and cookies, but then thanks to an unexpected lead it turned into a fun and exciting learning opportunity for me.&lt;/p&gt;&lt;head rend="h2"&gt;Buy me a coffee?&lt;/head&gt;&lt;p&gt;Thank you for visiting my blog! If you enjoyed this article, please consider supporting my work and keeping me caffeinated with a small one-time donation through Buy me a coffee. Thanks!&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46351666</guid><pubDate>Mon, 22 Dec 2025 05:38:33 +0000</pubDate></item><item><title>Uplane (YC F25) Is Hiring Founding Engineers (Full-Stack and AI)</title><link>https://www.useparallel.com/uplane1/careers</link><description>&lt;doc fingerprint="d37fffed7efd5e8d"&gt;
  &lt;main&gt;
    &lt;p&gt;Loading...&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46355932</guid><pubDate>Mon, 22 Dec 2025 17:00:34 +0000</pubDate></item><item><title>Fabrice Bellard Releases MicroQuickJS</title><link>https://github.com/bellard/mquickjs/blob/main/README.md</link><description>&lt;doc fingerprint="3b74d0de090e4684"&gt;
  &lt;main&gt;
    &lt;p&gt;We read every piece of feedback, and take your input very seriously.&lt;/p&gt;
    &lt;p&gt;To see all available qualifiers, see our documentation.&lt;/p&gt;
    &lt;p&gt;There was an error while loading. Please reload this page.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46367224</guid><pubDate>Tue, 23 Dec 2025 17:33:42 +0000</pubDate></item><item><title>I'm returning my Framework 16</title><link>https://yorickpeterse.com/articles/im-returning-my-framework-16/</link><description>&lt;doc fingerprint="56a45c37c90b9dd7"&gt;
  &lt;main&gt;
    &lt;p&gt; My current laptop is an aging X1 Carbon generation 7, purchased some time in mid 2019. A few months ago a few keys of the keyboard stopped working, specifically the 5, 6, &lt;code&gt;-&lt;/code&gt;, &lt;code&gt;=&lt;/code&gt; and Delete keys. Sometimes I can get it working again by
mashing one of them for a while, but it's not consistent. Given my past
experiences with X1 Carbon laptops breaking outside of warranty and the
frustration that comes with replacing their components, I decided it was time to
look for a replacement.&lt;/p&gt;
    &lt;p&gt;Unfortunately, buying a new X1 Carbon wasn't going to be an option: when it comes to displays you now basically have two choices: a subpar not-quite-2K IPS display, or a 2.5K (ish) OLED display. Since I use my laptop for programming and often use it in low light conditions such as a living room with dimmed lights in the evening, OLED just doesn't make sense. Knowing my luck I'd also run into OLED burn-in the moment the warranty expires. There are also some other issues with the X1 line in general, such as poor CPU cooling and the absolute nightmare that is opening them up to replace parts or clean them properly.&lt;/p&gt;
    &lt;p&gt;I looked at some other brands but it appears that in 2025 there's just aren't many good options for Linux users. I narrowed it down to two options:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Buy a refurbished M1 or M2 Macbook and run Asahi Linux&lt;/item&gt;
      &lt;item&gt;Buy a Framework&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I eliminated the use of Asahi Linux because of the following reasons:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The battery life doesn't appear to be all that better than conventional laptops when running Linux. This isn't entirely surprising because of a lot of the battery improvements on macOS are the result of the software and hardware integration, not just the hardware&lt;/item&gt;
      &lt;item&gt;There seem to be issues with suspend not working as well (at least based on various comments I came across), and hardware support in general is a bit dodgy&lt;/item&gt;
      &lt;item&gt;If something needs replacing I basically have an expensive paperweight, because everything is soldered together, assuming you could even find spare parts in the first place&lt;/item&gt;
      &lt;item&gt;I'm not sure Asahi as a project will still be around in 5 years, but my laptop will be&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In contrast, Framework laptops has many supposed benefits: they're upgradable, repairable, actively work on Linux and even FreeBSD support (or at least sponsor developers working on this), allow you to customize the keyboard using QMK/VIAL. In fact, on paper it sounds like the perfect developer laptop. In reality, I'm not so sure.&lt;/p&gt;
    &lt;head rend="h2"&gt;Table of contents&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Configuration&lt;/item&gt;
      &lt;item&gt;Building the laptop&lt;/item&gt;
      &lt;item&gt;Operating system&lt;/item&gt;
      &lt;item&gt;Weight&lt;/item&gt;
      &lt;item&gt;Design&lt;/item&gt;
      &lt;item&gt;Display&lt;/item&gt;
      &lt;item&gt;Power LED&lt;/item&gt;
      &lt;item&gt;GPU&lt;/item&gt;
      &lt;item&gt;CPU&lt;/item&gt;
      &lt;item&gt;Battery&lt;/item&gt;
      &lt;item&gt;WiFi and Bluetooth&lt;/item&gt;
      &lt;item&gt;Keyboard&lt;/item&gt;
      &lt;item&gt;Trackpad&lt;/item&gt;
      &lt;item&gt;Speakers&lt;/item&gt;
      &lt;item&gt;Modular ports&lt;/item&gt;
      &lt;item&gt;Conclusion&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Configuration&lt;/head&gt;
    &lt;p&gt;Framework has three models of laptops: a 12 inch, 13.5 inch and 16 inch laptop. My X1 Carbon is a 14 inch laptop but I've always felt like I wanted something just slightly larger. I ended up buying the Framework 16 for two reason:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;I read various reports of the Framework 13 having issues with poor battery life, fan noise, heating, etc&lt;/item&gt;
      &lt;item&gt;While 16 inch is a fair bit larger than 14 inch, I was hoping it would be manageable size wise&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The base configuration is as follows:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Framework 16 DIY edition&lt;/item&gt;
      &lt;item&gt;CPU: Ryzen AI 7 350&lt;/item&gt;
      &lt;item&gt;RAM: 2x8 GiB DDR5-5600&lt;/item&gt;
      &lt;item&gt;SSD: WD Black SN7100, 500 GiB&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I also bought an additional Intel AX210 WiFi card in case the default Mediatek card would cause any trouble, as I don't trust brands other than Intel when it comes to WiFi.&lt;/p&gt;
    &lt;p&gt;Shipping took about a week or so, with the laptop making quite the journey from Taiwan to the Philippines to China, then to Japan and then back to China, then to Istanbul, then to France and at last to The Netherlands. I'm not sure what happened here, maybe the pilot got drunk or perhaps Fedex' tracking is just broken.&lt;/p&gt;
    &lt;head rend="h2"&gt;Building the laptop&lt;/head&gt;
    &lt;p&gt;I bought the DIY edition which requires some manual assembly, though not nearly as much as I feared. All I had to do was install the SSD, RAM, and the keyboard spacers. The spacers, touchpad and keyboard use magnetic connectors so installing and removing them is trivial. To access the SSD and RAM slots you need to unscrew a plate that sits between these slots and the keyboard, but this only takes a few minutes using the provided screwdriver.&lt;/p&gt;
    &lt;p&gt;I didn't measure how long it took me to install it the first time, but opening it up and putting it back together a second time only took perhaps 5-10 minutes at most. For comparison, to replace most parts of the X1 Carbon you essentially have to take the whole thing apart and unscrew countless screws many of which are hard to find. Unsurprisingly, I've lost some of these screws over the years and dreaded opening it up the few times I had to.&lt;/p&gt;
    &lt;p&gt;This is an area where Framework excels compared to all other brands: it's just so easy to swap the parts out that it puts other brands to shame when it comes to hardware maintainability.&lt;/p&gt;
    &lt;head rend="h2"&gt;Operating system&lt;/head&gt;
    &lt;p&gt;For the operating system I initially gave FreeBSD 15 a quick try. I knew it wasn't going to be the final OS due to it still having issues with the Framework hardware (e.g. suspend doesn't work properly), but I figured it was worth a try just to see what would happen. The installation went fine and WiFi worked fine, though that was because I swapped the Mediatek card with the Intel AX210 as the Mediatek card doesn't work at all on FreeBSD. Upon loading the AMD drivers I encountered a kernel crash, likely due to the same issue as discussed in this drm-kmod issue. A laptop without working GPU drivers isn't going to work, so at this point I decided to give up on FreeBSD (again) and install Fedora 43 instead.&lt;/p&gt;
    &lt;p&gt;Fedora 43 worked just fine as expected, and everything worked, so let's take a look at the hardware.&lt;/p&gt;
    &lt;head rend="h2"&gt;Weight&lt;/head&gt;
    &lt;p&gt;The Framework 16 weights about 2.2 kg according to my kitchen scale. For comparison, my X1 Carbon weights 1.3 kg. That may not seem like a big difference, but the extra kilogram makes carrying around the Framework 16 more difficult. In particular, I don't feel comfortable carrying it with just one hand while this isn't a problem with the X1.&lt;/p&gt;
    &lt;p&gt;The Framework is best described as a bit of a chonker and I certainly don't see myself carrying it around a lot. This also gives it a bit of an identity crisis: laptops should be portable, otherwise why not just get a desktop. And yet the Framework 16 is neither portable nor remotely as powerful as a desktop, so who exactly is the target audience?&lt;/p&gt;
    &lt;head rend="h2"&gt;Design&lt;/head&gt;
    &lt;p&gt;The design of the laptop is a bit polarizing. I like the combination of black and silver, but I hate how janky it all looks and feels due to the removable spacers. Note the lines separating the touchpad from the spacers on the left and right of it:&lt;/p&gt;
    &lt;p&gt;Not only does it look weird, you can also feel the gap and edges when resting your palm on them. The silver spacers and touchpad are also raised slightly relative to the black keyboard area, and the edges are quite sharp. If you have arm hairs you may consider shaving them off or risk getting them stuck. I also suspect gunk will build up in these edges over time.&lt;/p&gt;
    &lt;p&gt;The spacers aren't held solid in place either, meaning you can move them around and they have a bit of flex to them:&lt;/p&gt;
    &lt;p&gt;You may need to turn up your volume to hear the noise the spacers make. Also, apologies for the vertical video!&lt;/p&gt;
    &lt;p&gt;There's also a practical problem: due to the flex of the spacers if you try to hold the laptop on its sides it will actually "wobble" a bit. Combined with the weight I suspect that unless you hold on to this laptop for dear life, you will at some point drop it.&lt;/p&gt;
    &lt;p&gt;These issues could be considered a minor issue in isolation but remember, this model costs two thousand Euros (I'll bring this up a few more times). For a premium price I expect a premium design and build quality, and this isn't it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Display&lt;/head&gt;
    &lt;p&gt;The display isn't terrible, but it's not great either. Like most laptop displays that aren't Macbooks there's a bit of flex to the display, though this shouldn't be much of an issue. The colors of the display are overly saturated, with reds in particular looking more intense than they should. Here's a silly example of what a particular shade of red looks like on my X1 Carbon:&lt;/p&gt;
    &lt;p&gt;And here's the same color on the Framework 16:&lt;/p&gt;
    &lt;p&gt;Note that both displays were using the same brightness and the same color temperature/night light setting. For comparison, here's what those colors should look like when using a properly calibrated (at the hardware level at least) Eizo CS2740 that I use for my desktop:&lt;/p&gt;
    &lt;p&gt;I'm aware the quality of the photos isn't great, but if you compare the Framework version to the others you'll notice the colors are more saturated compared to what they should look like.&lt;/p&gt;
    &lt;p&gt;The white/grey uniformity also leaves a lot to be desired, though this is true for all modern IPS displays that aren't manufactured by Eizo:&lt;/p&gt;
    &lt;p&gt;I find non-uniform displays distracting as it can create a sort of tunnel vision effect/feeling. While the X1 Carbon also suffers from this problem, it feels less pronounced than in case of the Framework. Of course the Eizo display doesn't suffer from this problem at all (hence I bought it), but then it again it costs a ridiculous ‚Ç¨1700.&lt;/p&gt;
    &lt;p&gt;Which brings us to the brightness. This display is bright, even at the lowest setting. I found various forum posts that mention the Framework 13 suffers from a similar issue but that you can at least now lower the brightness further on recent versions of Linux, but this isn't supported for the Framework 16. Here's what that looks like in practice:&lt;/p&gt;
    &lt;p&gt;The Framework 16 is on the left and the X1 Carbon on the right, both set to the lowest brightness setting that is still usable.&lt;/p&gt;
    &lt;p&gt;The Framework 16 being so much brighter means that using it in a darker room (e.g. a living room at night with the lights dimmed) makes you feel like a deer looking into the headlights of a car that's about to run you over. In other words, not fun.&lt;/p&gt;
    &lt;head rend="h2"&gt;Power LED&lt;/head&gt;
    &lt;p&gt;On the topic of brightness, the power button in the top right corner of the keyboard has an LED that can't be turned off in the BIOS. Instead, you can set it to a few different settings including "Ultra low", but it doesn't make much of a difference as even at the lowest setting it's still too bright. This wouldn't be so bad if it wasn't sitting in the bottom right corner of your eye when you look at the display.&lt;/p&gt;
    &lt;p&gt;I ended up using this systemd service to turn the LED off upon booting, but something as simple as this should just be a BIOS option. Not being able to turn the LED off is apparently a feature.&lt;/p&gt;
    &lt;head rend="h2"&gt;GPU&lt;/head&gt;
    &lt;p&gt;I didn't do any GPU intensive testing such as video decoding. One annoying issue is that the display has a tendency to flicker. On top of that, there's a "nice" feature where the GPU reduces the display brightness based on the contents on the screen to conserve battery. The problem is that it takes a good two seconds or so to adjust, making it obvious and jarring to look at. It's especially noticeable when switching to the workspace overview in Gnome and back, due to a large section of this overview being a dark color.&lt;/p&gt;
    &lt;p&gt;This feature is disabled by adding &lt;code&gt;amdgpu.abmlevel=0&lt;/code&gt; to &lt;code&gt;GRUB_CMDLINE_LINUX&lt;/code&gt;
in &lt;code&gt;/etc/default/grubg&lt;/code&gt;, followed by running &lt;code&gt;sudo grub2-mkconfig -o
/boot/grub2/grub.cfg&lt;/code&gt; and a reboot. This also seems to reduce the amount of
flickering, though it still happened a few times after applying this setting.&lt;/p&gt;
    &lt;p&gt;Some additional details on the ambient dimming anti-feature are in this forum post.&lt;/p&gt;
    &lt;p&gt;I can see the value of this feature but only if the GPU waits longer before adjusting the brightness and increases the transition time so it's less obvious. In it's current form it's just a nuisance.&lt;/p&gt;
    &lt;head rend="h2"&gt;CPU&lt;/head&gt;
    &lt;p&gt;The CPU is fine, though I didn't extensively test its performance. It's certainly better than the mediocre Intel CPU of my X1 Carbon. One thing I noticed is that the CPU makes a sort of coil whine/crackling BZZZZZZ noise when under load. This isn't unique to Framework (e.g. my X1 also does this), the more open design (e.g. there's a big fan grill/mesh at the top of the keyboard) makes this more noticeable.&lt;/p&gt;
    &lt;p&gt;I can't speak about the fan noise because I never heard them. This could either mean they are quiet enough or that I didn't stress the CPU enough.&lt;/p&gt;
    &lt;head rend="h2"&gt;Battery&lt;/head&gt;
    &lt;p&gt;I didn't do any proper testing of battery usage, but it seems to be on par with other Linux capable laptops based on my usage thus far. This means you'll likely be looking at 6-8 hours of battery per charge for average programming usage. It seems this is the case for basically any reasonable Linux-capable laptop these days, unfortunately.&lt;/p&gt;
    &lt;p&gt;I did notice that it drains quite a bit when suspended: when I put it to sleep the first night the battery was at 47%. When I opened the laptop again some 8 hours later the battery was at 42%. This means you're looking at about 5% of battery per average night, which isn't great. Hibernate could be an alternative but support for it on Fedora is a bit dodgy and requires some manual work I'm not interested in, so I didn't test this.&lt;/p&gt;
    &lt;head rend="h2"&gt;WiFi and Bluetooth&lt;/head&gt;
    &lt;p&gt;Both the Intel and Mediatek cards work without issue. Both achieve the same speeds on my 1 Gbps connection over a 5Ghz network (with a channel width of 80mhz): about 800-900 Mbps for uploads and somewhere between 600 and 700 Mbps for downloads. While not being able to achieve the full 1 Gbps speed over WiFi is expected, I was a bit surprised to see that uploads are in fact faster than downloads.&lt;/p&gt;
    &lt;p&gt;I tested various other devices with similar WiFi hardware and they all upload and download at about the same speeds, and all operate at slightly lower speeds (500-600 Mbps, depending on your luck).&lt;/p&gt;
    &lt;p&gt;I don't think it's the network itself either: the access points are TP-Link EAP660 HDs that can handle speeds well beyond 1 Gbps. As far as I know the configuration is also sound (including the use of specific channels to reduce interference to a minimum).&lt;/p&gt;
    &lt;p&gt;Still, 600-700 Mbps over WiFi is more than I'll probably ever need so I didn't dive into this further.&lt;/p&gt;
    &lt;p&gt;I didn't specifically test Bluetooth but it did detect a few devices, so I'll assume this will work just fine.&lt;/p&gt;
    &lt;head rend="h2"&gt;Keyboard&lt;/head&gt;
    &lt;p&gt;Some reviews I read mentioned that the keyboard has a bit of flex to it, but I didn't notice this. The keycaps are a little mushy, which isn't too bad but not great either. The difference in key size and spacing compared to the X1 did mean I pressed the wrong key at times, but I suspect this is just a matter of adjusting.&lt;/p&gt;
    &lt;p&gt;The keyboard runs QMK, albeit a rather outdated version of QMK released in 2022. I experimented with porting the code to a newer version so I could take advantage of some features that I use in my split keyboard, but couldn't get it to work. The official way to configure the keyboard is by using this VIAL web application. This application requires WebHID support which isn't implemented by Firefox, requiring me to install and use Chromium just to configure the keyboard. This isn't enough though, as on Linux you'll need to install some additional udev rules to get things working. The official rules provided by QMK didn't work, instead I used the rules from this forum reply.&lt;/p&gt;
    &lt;p&gt;Once set up I was able to configure the keyboard such as by changing the layout from QWERTY to Colemak-DH. VIAL is pretty basic though and the interface is rather clunky, so I'm not a fan of this approach. I hope that at some point Framework will upstream their keyboard logic into the official QMK repository to make this process easier.&lt;/p&gt;
    &lt;head rend="h2"&gt;Trackpad&lt;/head&gt;
    &lt;p&gt;The trackpad is decent, though I noticed it's overly sensitive when it comes to scrolling. For example, on various occasions I lifted my fingers off the trackpad without any swiping motion and somehow still managed to trigger a scrolling motion. The trackpad of the X1 Carbon doesn't have this problem and subsequently is easier and more pleasant to use.&lt;/p&gt;
    &lt;head rend="h2"&gt;Speakers&lt;/head&gt;
    &lt;p&gt;They're terribly. Or more precisely, they're terrible when the volume is less than 50% or so. What appears to be happening is that adjusting the volume below 50% doesn't result in it being louder but instead changes how it sounds (for a lack of a better description). At lower volumes it sounds like sound playing over a phone in speaker mode, with a sort of tin can/metallic sound to it. Once you hit 50% or so it starts to sound more like an OK set of speakers but it also becomes noticeable louder. There's a setting in the BIOS that you can set to "Linux" mode to supposedly improve the quality but it was already set to this value.&lt;/p&gt;
    &lt;p&gt;While most laptop speakers aren't great (even the Dolby Atmos speakers of the X1 Carbon are mediocre), for a laptop that costs two thousand Euros the sound is disappointing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Modular ports&lt;/head&gt;
    &lt;p&gt;An interesting feature of the Framework is that you can swap out the various ports. You want 6 USB-C ports? You can do that! What about 3 headphone jacks? Also possible! Replacing them is quite easy, though for some reason my headphone jack adapter required some additional force to be removed.&lt;/p&gt;
    &lt;p&gt;Like the keyboard area the design is a bit janky though, with visible lines/space between the adapters and the case, though this at least is something you won't notice unless you're explicitly looking for it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Which brings me to the conclusion: is it worth buying this laptop, considering most configurations will cost you around two thousand Euros? To be honest, no, not at all. For a premium price I expect a premium laptop, but the Framework 16 feels more like a ‚Ç¨1200-‚Ç¨1500 laptop at best and certainly doesn't deliver a premium experience. I understand Framework is a young company still trying to figure out a lot of things, but two thousand Euros for this kind of laptop is just absurd.&lt;/p&gt;
    &lt;p&gt;For this reason I've submitted a request to return the laptop. What I'll be replacing my X1 Carbon with instead I'm not entirely sure of. One option is the Framework 13 given that it solves at least some issues I have with the Framework 16 (e.g. it's bulkiness and inability to lower the brightness further), but it also seems to share many of the other issues such as poor speaker quality and (at least from hat I could find) worse heat regulation, and a (possibly) worse battery.&lt;/p&gt;
    &lt;p&gt;I've looked at various other brands such as System76 and the many other Clevo resellers, but they all seem to suffer similar issues such as poor battery life, poor performance, difficult to maintain hardware wise, or some combination thereof.&lt;/p&gt;
    &lt;p&gt;I guess for now the X1 Carbon will have to hold out a little longer, provided I don't throw it out of the window the next time I can't get the various dodgy keyboard keys to work.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46375174</guid><pubDate>Wed, 24 Dec 2025 12:55:19 +0000</pubDate></item><item><title>When Compilers Surprise You</title><link>https://xania.org/202512/24-cunning-clang</link><description>&lt;doc fingerprint="26e3f81475bb3a59"&gt;
  &lt;main&gt;
    &lt;p&gt;Written by me, proof-read by an LLM. &lt;lb/&gt;Details at end.&lt;/p&gt;
    &lt;p&gt;Every now and then a compiler will surprise me with a really smart trick. When I first saw this optimisation I could hardly believe it. I was looking at loop optimisation, and wrote something like this simple function that sums all the numbers up to a given value:&lt;/p&gt;
    &lt;p&gt;So far so decent: GCC has done some preliminary checks, then fallen into a loop that efficiently sums numbers using &lt;code&gt;lea&lt;/code&gt; (we‚Äôve seen this before). But taking a closer look at the loop we see something unusual:&lt;/p&gt;
    &lt;code&gt;.L3:
  lea edx, [rdx+1+rax*2]        ; result = result + 1 + x*2
  add eax, 2                    ; x += 2
  cmp edi, eax                  ; x != value
  jne .L3                       ; keep looping
&lt;/code&gt;
    &lt;p&gt;The compiler has cleverly realised it can do two numbers1 at a time using the fact it can see we‚Äôre going to add &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;x + 1&lt;/code&gt;, which is the same as adding &lt;code&gt;x*2 + 1&lt;/code&gt;. Very cunning, I think you‚Äôll agree!&lt;/p&gt;
    &lt;p&gt;If you turn the optimiser up to &lt;code&gt;-O3&lt;/code&gt; you‚Äôll see the compiler works even harder to vectorise the loop using parallel adds. All very clever.&lt;/p&gt;
    &lt;p&gt;This is all for GCC. Let‚Äôs see what clang does with our code:&lt;/p&gt;
    &lt;p&gt;This is where I nearly fell off my chair: there is no loop! Clang checks for positive &lt;code&gt;value&lt;/code&gt;, and if so it does:&lt;/p&gt;
    &lt;code&gt;  lea eax, [rdi - 1]        ; eax = value - 1
  lea ecx, [rdi - 2]        ; ecx = value - 2
  imul rcx, rax             ; rcx = (value - 1) * (value - 2)
  shr rcx                   ; rcx &amp;gt;&amp;gt;= 1
  lea eax, [rdi + rcx]      ; eax = value + rcx
  dec eax                   ; --eax
  ret
&lt;/code&gt;
    &lt;p&gt;It was not at all obvious to me what on earth was going on here. By backing out the maths a little, this is equivalent to:&lt;/p&gt;
    &lt;code&gt;v + ((v - 1)(v - 2) / 2) - 1;
&lt;/code&gt;
    &lt;p&gt;Expanding the parentheses:&lt;/p&gt;
    &lt;code&gt;v + (v√Ç¬≤ - 2v - v + 2) / 2 - 1
&lt;/code&gt;
    &lt;p&gt;Rearranging a bit:&lt;/p&gt;
    &lt;code&gt;(v√Ç¬≤ - 3v + 2) / 2 + (v - 1)
&lt;/code&gt;
    &lt;p&gt;Multiplying the &lt;code&gt;(v - 1)&lt;/code&gt; by 2 / 2:&lt;/p&gt;
    &lt;code&gt;(v√Ç¬≤ - 3v + 2) / 2 + (2v - 2)/2
&lt;/code&gt;
    &lt;p&gt;Combining those and cancelling:&lt;/p&gt;
    &lt;code&gt;(v√Ç¬≤ - v) / 2
&lt;/code&gt;
    &lt;p&gt;Simplifying and factoring gives us &lt;code&gt;v(v - 1) / 2&lt;/code&gt; which is the closed-form solution to the ‚Äúsum of integers‚Äù! Truly amazing2 - we‚Äôve gone from an O(n) algorithm as written, to an O(1) one!&lt;/p&gt;
    &lt;p&gt;I love that despite working with compilers for more than twenty years, they can still surprise and delight me. The years of experience and work that have been poured into making compilers great is truly humbling, and inspiring.&lt;/p&gt;
    &lt;p&gt;We‚Äôre nearly at the end of this series - there‚Äôs so much more to say but that will have to wait for another time. Tomorrow will be a little different: see you then!&lt;/p&gt;
    &lt;p&gt;See the video that accompanies this post.&lt;/p&gt;
    &lt;p&gt;This post is day 24 of Advent of Compiler Optimisations 2025, a 25-day series exploring how compilers transform our code.&lt;/p&gt;
    &lt;p&gt;This post was written by a human (Matt Godbolt) and reviewed and proof-read by LLMs and humans.&lt;/p&gt;
    &lt;p&gt;Support Compiler Explorer on Patreon or GitHub, or by buying CE products in the Compiler Explorer Shop.&lt;/p&gt;
    &lt;p&gt;Some of the initial code checks for odd/even and accounts accordingly. ‚Ü©&lt;/p&gt;
    &lt;p&gt;Why does the compiler emit this exact sequence and not a slightly more straightforward sequence? I think it‚Äôs partly avoiding overflow in cases where it might otherwise overflow and just a side effect of the way clang tracks and infers induction variables. I really don‚Äôt know for sure, though. ‚Ü©&lt;/p&gt;
    &lt;p&gt;Matt Godbolt is a C++ developer living in Chicago. He works for Hudson River Trading on super fun but secret things. He is one half of the Two's Complement podcast. Follow him on Mastodon or Bluesky.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46375384</guid><pubDate>Wed, 24 Dec 2025 13:27:50 +0000</pubDate></item><item><title>My 2026 Open Social Web Predictions</title><link>https://www.timothychambers.net/2025/12/23/my-open-social-web-predictions.html</link><description>&lt;doc fingerprint="b8beabfa6dac4a7a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;My 2026 Open Social Web Predictions&lt;/head&gt;
    &lt;p&gt;I just finished reviewing my 2025 predictions (how do you think I did grading myself?) www.timothychambers.net/2024/12/2‚Ä¶&lt;/p&gt;
    &lt;p&gt;Now it‚Äôs time to make some bets for 2026. I do this not to prove how great my prognostication muscles are, but to shine a spotlight on trends I think are vital, spur discussions, and give some attention to projects that have earned it. As always, I try to make these as quantifiable, verifiable and crisp as I can. Here goes:&lt;/p&gt;
    &lt;p&gt;üå± MILD&lt;/p&gt;
    &lt;p&gt;Safe bets ‚Äî would be surprising if these DON‚ÄôT happen.&lt;/p&gt;
    &lt;p&gt;‚ñ∂Ô∏è Bluesky will cross 60 million registered users in 2026. Growth will slow from 2024‚Äôs explosive pace but remain steady, driven by continued X dissatisfaction and improved features.&lt;/p&gt;
    &lt;p&gt;‚ñ∂Ô∏è The ActivityPub Fediverse (excluding Threads) will cross 15 million registered users, monthly active users (excluding will plateau around 2-3 million. Another good year in terms of stable base, but no big waves of new users. Both Bluesky and Fediverse growth won‚Äôt come from big waves of migration this year.&lt;/p&gt;
    &lt;p&gt;‚ñ∂Ô∏è Any smaller waves from X/Twitter or from a newly bought TikTok will benefit Meta (Threads/IG), BlueSky, and Fediverse in that order. I see nothing that would change that prediction that was true last year, too.&lt;/p&gt;
    &lt;p&gt;‚ñ∂Ô∏è Threads will pass 500 million monthly active users and remain the largest ActivityPub-adjacent platform by a wide margin. But see the next prediction:&lt;/p&gt;
    &lt;p&gt;‚ñ∂Ô∏è Threads federation will remain partial, and opt-in through all of 2026. Full two-way federation will NOT ship in 2026 but may move from about 90 percent there, to 95 percent done, inching forward but not finalized and prioritized as a feature. As Manton wrote, that‚Äôs better than fully closed, and better than them stripping it out. (which they might do but I‚Äôm predicting not) My bet: the status quo continues. www.manton.org/2025/12/1‚Ä¶&lt;/p&gt;
    &lt;p&gt;‚ñ∂Ô∏è Ghost‚Äôs ActivityPub integration will bring 75,000+ new federated accounts to the Fediverse and Ghost will finish 2026 in the top 10 Fediverse server software by MAU.&lt;/p&gt;
    &lt;p&gt;‚ñ∂Ô∏è WordPress-based federated accounts will cross 50,000 as measured by FediDB. Currently at approximately 26,000 accounts across 12,700 servers, the WordPress-to-Fediverse pipeline becomes a meaningful growth contributor.&lt;/p&gt;
    &lt;p&gt;üî• MEDIUM-SPICEY Plausible bets ‚Äî could go either way, but evidence points toward yes.&lt;/p&gt;
    &lt;p&gt;‚ñ∂Ô∏è BridgyFed will shift to ‚Äúopt-out‚Äù for Bluesky users bridging to ActivityPub ‚Äî and the discourse will be far less contentious than the 2024 debates predicted. Cross-protocol interoperability quietly normalizes.&lt;/p&gt;
    &lt;p&gt;‚ñ∂Ô∏è At least one fully independent ATProto stack ‚Äî PDS, Relay, and AppView operating without dependency on Bluesky PBC infrastructure ‚Äî will achieve viability in 2026, meaning it has paying customers or sustainable funding. This will be the year ATProto proves (or fails to prove) it can exist beyond Bluesky-the-company.&lt;/p&gt;
    &lt;p&gt;‚ñ∂Ô∏è Mastodon gGmbH will hit key sustainability milestones in 2026. Their hosting revenue model will exceed internal targets, the new organizational structure will unlock additional grant funding (beyond NGI/NLnet), and the pace of Mastodon development will noticeably accelerate ‚Äî shipping more significant features in 2026 than in the previous two years combined.&lt;/p&gt;
    &lt;p&gt;‚ñ∂Ô∏è Bluesky PBC will raise another round of funding in 2026 and announce more details on a proposed business model. Following their $15M Series A (October 2024), the company will close a larger round to extend runway. The announced business model will NOT be advertising-based. I‚Äôd expect subscriptions, marketplace fees, or enterprise services.&lt;/p&gt;
    &lt;p&gt;‚ñ∂Ô∏è The first ‚ÄúATProto-native‚Äù social app that is NOT microblogging will cross 100,000 users. Whether it‚Äôs Frontpage (link aggregation), Leaflet (long-form), Smoke Signal, or something new ‚Äî the ATmosphere diversifies beyond Bluesky-the-app.&lt;/p&gt;
    &lt;p&gt;‚ñ∂Ô∏è Flipboard‚Äôs Surf app will launch its 1.0 version in 2026 and cross 1 million downloads across iOS and Android by year end, with 100,000+ monthly active users. It will become the most-downloaded dedicated Open Social Web client, surpassing Mastodon‚Äôs official app and Graysky.&lt;/p&gt;
    &lt;p&gt;‚ñ∂Ô∏è Fedify will power the federation layer for at least one mid-sized social platform (500K+ users) that adds ActivityPub support in 2026. The ‚Äúbuild vs. buy‚Äù calculation for federation shifts decisively toward ‚Äújust use Fedify.‚Äù&lt;/p&gt;
    &lt;p&gt;‚ñ∂Ô∏è Fediscovery will ship in a stable Mastodon release in 2026, moving from behind feature flags to production-ready. The specifications for pluggable discovery providers ‚Äî covering account search, follow recommendations, and trends ‚Äî will reach 1.0 status, and at least one public Fediscovery-compatible provider will launch for general use. Small instance operators will finally have a real option to improve discovery without running their own infrastructure.&lt;/p&gt;
    &lt;p&gt;‚ñ∂Ô∏è The new ‚ÄúActivityRank‚Äù algorithm in Loops will prove that ethical recommendations and decentralization can coexist. Dan Supernault‚Äôs approach ‚Äî where each instance trains its own algorithm while surfacing content across the ActivityPub network ‚Äî will be recognized as a breakthrough in solving the fediverse‚Äôs discoverability problem. By the end of 2026, the pattern will be studied or adopted by at least two other ActivityPub platforms.&lt;/p&gt;
    &lt;p&gt;‚ñ∂Ô∏è ATProto will advance from Internet Drafts to an official IETF Working Group in 2026. Following the September 2025 submission of initial specifications, Bluesky will secure enough support and independent implementers to form a dedicated Working Group ‚Äî moving from ‚Äúproposal being discussed‚Äù to ‚Äústandard being formally developed.‚Äù&lt;/p&gt;
    &lt;p&gt;üå∂Ô∏è SPICY Hot takes - a bit more risky - but I‚Äôm calling my shot.&lt;/p&gt;
    &lt;p&gt;‚ñ∂Ô∏è A well-known digital-native media publication (10M+ monthly visitors) will federate via ActivityPub in 2026 and publicly share positive results. Whether through Ghost, WordPress, or custom implementation, this outlet will report that federated followers drove meaningful engagement ‚Äî making the business case for federation legible to other publishers for the first time. By year end, at least two additional publications will announce federation plans, citing this pioneer as proof of concept.&lt;/p&gt;
    &lt;p&gt;‚ñ∂Ô∏è At least one major news organization (top 50 US by traffic) will announce it is leaving X/Twitter entirely and making Bluesky or the Fediverse its primary social distribution channel. The ‚Äúinstitutional exodus‚Äù begins.&lt;/p&gt;
    &lt;p&gt;‚ñ∂Ô∏è At least one major national government or major city will launch an official presence on BOTH Bluesky AND the ActivityPub Fediverse in 2026 ‚Äî and it will be a European government. Expect surprising additional early adopters after this from Latin America, Asia-Pacific, or Africa to follow that lead and make moves that year to do the same. This is the year the move to ‚Äúdigital sovereignty" from US tech will benefit the open social web. Eurosky will inch along with some promise.&lt;/p&gt;
    &lt;p&gt;‚ñ∂Ô∏è Nostr ‚Üî ATProto ‚Üî ActivityPub three-way bridging becomes functional via BridgyFed or another service by end of 2026. The ‚Äúprotocol wars‚Äù narrative collapses into ‚Äújust pick your client.‚Äù&lt;/p&gt;
    &lt;p&gt;‚ñ∂Ô∏è AltStore will be live with Federation features in at least 5 countries by end of 2026 (currently EU + Japan, with Brazil, Australia, UK announced). AltStore is an independent iOS app marketplace created by Riley Testut and Shane Gill ‚Äî the first major alternative to Apple‚Äôs App Store, made possible by the EU‚Äôs Digital Markets Act. The federated app marketplace model will prove viable outside Europe, challenging Apple‚Äôs App Store dominance in multiple regulatory regimes simultaneously. Their ActivityPub integration ‚Äî where app updates flow to Mastodon, Threads, and Bluesky ‚Äî will become the most compelling non-social-media use case for decentrlized social features, proving definitively that such protocols extends beyond microblogging.&lt;/p&gt;
    &lt;p&gt;‚ñ∂Ô∏è Loops will become the third most-used Fediverse software by MAU by end of 2026, trailing only Mastodon and Pixelfed. The short-form video platform will cross 100,000 monthly active users, with Loops-originated content generating significant federated engagement from non-Loops clients ‚Äî proving that ActivityPub can power video-centric social experiences.&lt;/p&gt;
    &lt;p&gt;‚ñ∂Ô∏è PieFed will emerge as the most feature-rich Threadiverse platform by end of 2026, surpassing Lemmy and Mbin in moderation tools, user experience, and federation capabilities. The platform will cross 10,000 monthly active users and its rapid development pace ‚Äî shipping major features weekly ‚Äî will make it the default recommendation for anyone starting a new Reddit-style community in the fediverse.&lt;/p&gt;
    &lt;p&gt;‚ñ∂Ô∏è More laws akin to Utah‚Äôs Digital Choice Act will pass or advance - sparking first steps towards interoperability to mainstream US discourse. The Utah law takes effect July 1, 2026, and several other states will pass similar ones, requiring social media platforms to enable data portability and interoperability. At least one major platform will announce ActivityPub or AT Protocol support to comply. The ‚ÄúDigital Choice‚Äù framing will prove more politically viable than ‚Äúantitrust‚Äù for breaking Big Tech‚Äôs lock-in.&lt;/p&gt;
    &lt;p&gt;What did I miss? What did I get wrong? Let me know ‚Äî and I‚Äôll see you in December 2026 to grade these.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46376652</guid><pubDate>Wed, 24 Dec 2025 15:59:23 +0000</pubDate></item><item><title>Show HN: Vibium ‚Äì Browser automation for AI and humans, by Selenium's creator</title><link>https://github.com/VibiumDev/vibium</link><description>&lt;doc fingerprint="8d362e50e91db4ee"&gt;
  &lt;main&gt;
    &lt;p&gt;Browser automation without the drama.&lt;/p&gt;
    &lt;p&gt;Vibium is browser automation infrastructure built for AI agents. A single binary handles browser lifecycle, WebDriver BiDi protocol, and exposes an MCP server ‚Äî so Claude Code (or any MCP client) can drive a browser with zero setup. Works great for AI agents, test automation, and anything else that needs a browser.&lt;/p&gt;
    &lt;p&gt;New here? Getting Started Tutorial ‚Äî zero to hello world in 5 minutes.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;Purpose&lt;/cell&gt;
        &lt;cell role="head"&gt;Interface&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Clicker&lt;/cell&gt;
        &lt;cell&gt;Browser automation, BiDi proxy, MCP server&lt;/cell&gt;
        &lt;cell&gt;CLI / stdio / WebSocket :9515&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;JS Client&lt;/cell&gt;
        &lt;cell&gt;Developer-facing API&lt;/cell&gt;
        &lt;cell&gt;npm package&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         LLM / Agent                         ‚îÇ
‚îÇ          (Claude Code, Codex, Gemini, Local Models)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚ñ≤
                      ‚îÇ MCP Protocol (stdio)
                      ‚ñº
           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         
           ‚îÇ   Vibium Clicker    ‚îÇ
           ‚îÇ                     ‚îÇ
           ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
           ‚îÇ  ‚îÇ  MCP Server   ‚îÇ  ‚îÇ
           ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ          ‚îÇ          ‚îÇ         ‚îÇ                  ‚îÇ
           ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇWebSocket‚îÇ                  ‚îÇ
           ‚îÇ  ‚îÇ  BiDi Proxy   ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  Chrome Browser  ‚îÇ
           ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  BiDi   ‚îÇ                  ‚îÇ
           ‚îÇ                     ‚îÇ         ‚îÇ                  ‚îÇ
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚ñ≤
                      ‚îÇ WebSocket BiDi :9515
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        JS/TS Client                         ‚îÇ
‚îÇ                     npm install vibium                      ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ    ‚îÇ Async API       ‚îÇ               ‚îÇ    Sync API     ‚îÇ    ‚îÇ
‚îÇ    ‚îÇ await vibe.go() ‚îÇ               ‚îÇ    vibe.go()    ‚îÇ    ‚îÇ
‚îÇ    ‚îÇ                 ‚îÇ               ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
&lt;/code&gt;
    &lt;p&gt;A single Go binary (~10MB) that does everything:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Browser Management: Detects/launches Chrome with BiDi enabled&lt;/item&gt;
      &lt;item&gt;BiDi Proxy: WebSocket server that routes commands to browser&lt;/item&gt;
      &lt;item&gt;MCP Server: stdio interface for LLM agents&lt;/item&gt;
      &lt;item&gt;Auto-Wait: Polls for elements before interacting&lt;/item&gt;
      &lt;item&gt;Screenshots: Viewport capture as PNG&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Design goal: The binary is invisible. JS developers just &lt;code&gt;npm install vibium&lt;/code&gt; and it works.&lt;/p&gt;
    &lt;code&gt;// Option 1: require (REPL-friendly)
const { browserSync } = require('vibium')

// Option 2: dynamic import (REPL with --experimental-repl-await)
const { browser } = await import('vibium')

// Option 3: static import (in .mjs or .ts files)
import { browser, browserSync } from 'vibium'&lt;/code&gt;
    &lt;p&gt;Sync API:&lt;/p&gt;
    &lt;code&gt;const fs = require('fs')
const { browserSync } = require('vibium')

const vibe = browserSync.launch()
vibe.go('https://example.com')

const png = vibe.screenshot()
fs.writeFileSync('screenshot.png', png)

const link = vibe.find('a')
link.click()
vibe.quit()&lt;/code&gt;
    &lt;p&gt;Async API:&lt;/p&gt;
    &lt;code&gt;const fs = await import('fs/promises')
const { browser } = await import('vibium')

const vibe = await browser.launch()
await vibe.go('https://example.com')

const png = await vibe.screenshot()
await fs.writeFile('screenshot.png', png)

const link = await vibe.find('a')
await link.click()
await vibe.quit()&lt;/code&gt;
    &lt;p&gt;One command to add browser control to Claude Code:&lt;/p&gt;
    &lt;code&gt;claude mcp add vibium -- npx -y vibium&lt;/code&gt;
    &lt;p&gt;That's it. No manual steps needed. Chrome downloads automatically during setup.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Tool&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_launch&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Start browser (visible by default)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_navigate&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Go to URL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_find&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Find element by CSS selector&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_click&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Click an element&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_type&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Type text into an element&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_screenshot&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Capture viewport (base64 or save to file with &lt;code&gt;--screenshot-dir&lt;/code&gt;)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_quit&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Close browser&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;npm install vibium&lt;/code&gt;
    &lt;p&gt;This automatically:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Installs the Clicker binary for your platform&lt;/item&gt;
      &lt;item&gt;Downloads Chrome for Testing + chromedriver to platform cache: &lt;list rend="ul"&gt;&lt;item&gt;Linux: &lt;code&gt;~/.cache/vibium/&lt;/code&gt;&lt;/item&gt;&lt;item&gt;macOS: &lt;code&gt;~/Library/Caches/vibium/&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Windows: &lt;code&gt;%LOCALAPPDATA%\vibium\&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Linux: &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;No manual browser setup required.&lt;/p&gt;
    &lt;p&gt;Skip browser download (if you manage browsers separately):&lt;/p&gt;
    &lt;code&gt;VIBIUM_SKIP_BROWSER_DOWNLOAD=1 npm install vibium&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Platform&lt;/cell&gt;
        &lt;cell role="head"&gt;Architecture&lt;/cell&gt;
        &lt;cell role="head"&gt;Status&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Linux&lt;/cell&gt;
        &lt;cell&gt;x64&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Supported&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;macOS&lt;/cell&gt;
        &lt;cell&gt;x64 (Intel)&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Supported&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;macOS&lt;/cell&gt;
        &lt;cell&gt;arm64 (Apple Silicon)&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Supported&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Windows&lt;/cell&gt;
        &lt;cell&gt;x64&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Supported&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;As a library:&lt;/p&gt;
    &lt;code&gt;import { browser } from "vibium";

const vibe = await browser.launch();
await vibe.go("https://example.com");
const el = await vibe.find("a");
await el.click();
await vibe.quit();&lt;/code&gt;
    &lt;p&gt;With Claude Code:&lt;/p&gt;
    &lt;p&gt;Once installed via &lt;code&gt;claude mcp add&lt;/code&gt;, just ask Claude to browse:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"Go to example.com and click the first link"&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;See CONTRIBUTING.md for development setup and guidelines.&lt;/p&gt;
    &lt;p&gt;V1 focuses on the core loop: browser control via MCP and JS client.&lt;/p&gt;
    &lt;p&gt;See V2-ROADMAP.md for planned features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Python and Java clients&lt;/item&gt;
      &lt;item&gt;Cortex (memory/navigation layer)&lt;/item&gt;
      &lt;item&gt;Retina (recording extension)&lt;/item&gt;
      &lt;item&gt;Video recording&lt;/item&gt;
      &lt;item&gt;AI-powered locators&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2025-12-22: Day 12 - Published to npm&lt;/item&gt;
      &lt;item&gt;2025-12-21: Day 11 - Polish &amp;amp; Error Handling&lt;/item&gt;
      &lt;item&gt;2025-12-20: Day 10 - MCP Server&lt;/item&gt;
      &lt;item&gt;2025-12-19: Day 9 - Actionability&lt;/item&gt;
      &lt;item&gt;2025-12-19: Day 8 - Elements &amp;amp; Sync API&lt;/item&gt;
      &lt;item&gt;2025-12-17: Halfway There&lt;/item&gt;
      &lt;item&gt;2025-12-16: Week 1 Progress&lt;/item&gt;
      &lt;item&gt;2025-12-11: V1 Announcement&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Apache 2.0&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46377597</guid><pubDate>Wed, 24 Dec 2025 17:49:02 +0000</pubDate></item><item><title>Fabrice Bellard: Biography (2009) [pdf]</title><link>https://www.ipaidia.gr/wp-content/uploads/2020/12/117-2020-fabrice-bellard.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46377862</guid><pubDate>Wed, 24 Dec 2025 18:17:47 +0000</pubDate></item><item><title>Show HN: Minimalist editor that lives in browser, stores everything in the URL</title><link>https://github.com/antonmedv/textarea</link><description>&lt;doc fingerprint="2a34105e063698ad"&gt;
  &lt;main&gt;
    &lt;p&gt;A minimalist text editor that lives entirely in your browser and stores everything in the URL hash.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üìù It's a textarea! Actually not.&lt;/item&gt;
      &lt;item&gt;üóúÔ∏è Compression magic - Your text gets compressed with deflate because we're fancy like that&lt;/item&gt;
      &lt;item&gt;üîó URL storage - Share your notes by copying a 500-character URL. Your friends will love it!&lt;/item&gt;
      &lt;item&gt;üåì Dark mode - Respects your poor eyes and your color scheme preference&lt;/item&gt;
      &lt;item&gt;üíæ Auto-save - Debounced to 500ms because we're not savages&lt;/item&gt;
      &lt;item&gt;üì± Mobile friendly - Type your manifesto on the go&lt;/item&gt;
      &lt;item&gt;üéØ No backend - Zero servers were harmed in the making of this app&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Open textarea.my&lt;/item&gt;
      &lt;item&gt;Type stuff&lt;/item&gt;
      &lt;item&gt;Marvel at the URL getting longer&lt;/item&gt;
      &lt;item&gt;Try to share it&lt;/item&gt;
      &lt;item&gt;...&lt;/item&gt;
      &lt;item&gt;Profit&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Start your document with &lt;code&gt;# Title&lt;/code&gt;to set a custom page title&lt;/item&gt;
      &lt;item&gt;Your data lives in localStorage AND the URL. Double the fun!&lt;/item&gt;
      &lt;item&gt;Feeling fancy? Add a &lt;code&gt;style&lt;/code&gt;attribute to the&lt;code&gt;&amp;lt;article&amp;gt;&lt;/code&gt;tag via DevTools. It'll be saved in the URL too!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Made with ‚ù§Ô∏è and JavaScript&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46378554</guid><pubDate>Wed, 24 Dec 2025 19:42:25 +0000</pubDate></item><item><title>Keystone (YC S25) is hiring engineer #1 to automate coding</title><link>https://www.ycombinator.com/companies/keystone/jobs/J3t9XeM-founding-engineer</link><description>&lt;doc fingerprint="a3b096f07e6fa468"&gt;
  &lt;main&gt;
    &lt;p&gt;Your team's on-call AI engineer&lt;/p&gt;
    &lt;p&gt;About Keystone&lt;/p&gt;
    &lt;p&gt;We're building AI-native error monitoring that automatically investigates production issues and generates code fixes. Think Sentry, but built from the ground up for a world where AI can actually understand your codebase, trace through logs, and tell you exactly what broke and how to fix it.&lt;/p&gt;
    &lt;p&gt;We're starting here and expanding until we're the default tool for building product, period. Our mission is to free engineers from the drudgery of digging through logs, setting up systems, and debugging- so they can focus on understanding users and designing great products.&lt;/p&gt;
    &lt;p&gt;We're in-person in SoMa, San Francisco. We raised a $5.2M seed from True Ventures, Twenty Two Ventures, Pear VC, and Ritual Capital- plus the founders of YC, Dropbox, Supabase, Eight Sleep, Graphite, Resend, RocketMoney, and more. Early design partners include teams at Perplexity and Lovable.&lt;/p&gt;
    &lt;p&gt;About the Role&lt;/p&gt;
    &lt;p&gt;You'd be the first engineering hire, working directly with me (the founder) to build the core product. You'll have more ownership and influence over the product, culture, and technical direction than you'd get almost anywhere else.&lt;/p&gt;
    &lt;p&gt;Example projects:&lt;/p&gt;
    &lt;p&gt;You might be a great fit if you:&lt;/p&gt;
    &lt;p&gt;Stack: TypeScript, React (Next.js), Python, Postgres, Redis, AWS&lt;/p&gt;
    &lt;p&gt;Comp &amp;amp; benefits: Top-of-market salary + significant equity, full health/dental/vision, all meals covered, equipment budget&lt;/p&gt;
    &lt;p&gt;If there appears to be a fit, we'll reach to schedule 2-3 short technicals. After, we'll schedule an onsite in our office, where you'll work on a small project, discuss ideas, and get a sense for our in-person culture.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46379173</guid><pubDate>Wed, 24 Dec 2025 21:01:05 +0000</pubDate></item><item><title>Nvidia buying AI chip startup Groq for about $20B in cash</title><link>https://www.cnbc.com/2025/12/24/nvidia-buying-ai-chip-startup-groq-for-about-20-billion-biggest-deal.html</link><description>&lt;doc fingerprint="22d081694f3ed1b7"&gt;
  &lt;main&gt;
    &lt;p&gt;Nvidia has agreed to buy assets from Groq, a designer of high-performance artificial intelligence accelerator chips, for $20 billion in cash, according to Alex Davis, CEO of Disruptive, which led the startup's latest financing round in September.&lt;/p&gt;
    &lt;p&gt;Davis, whose firm has invested more than half a billion dollars in Groq since the company was founded in 2016, said the deal came together quickly. Groq raised $750 million at a valuation of about $6.9 billion three months ago. Investors in the round included Blackrock and Neuberger Berman, as well as Samsung, Cisco, Altimeter and 1789 Capital, where Donald Trump Jr. is a partner.&lt;/p&gt;
    &lt;p&gt;Groq said in a blog post on Wednesday that it's "entered into a non-exclusive licensing agreement with Nvidia for Groq's inference technology," without disclosing a price. With the deal, Groq founder and CEO Jonathan Ross along with Sunny Madra, the company's president, and other senior leaders "will join Nvidia to help advance and scale the licensed technology," the post said.&lt;/p&gt;
    &lt;p&gt;Groq added that it will continue as an "independent company," led by finance chief Simon Edwards as CEO.&lt;/p&gt;
    &lt;p&gt;Colette Kress, Nvidia's CFO, declined comment on the transaction.&lt;/p&gt;
    &lt;p&gt;Davis told CNBC that Nvidia is getting all of Groq's assets, though its nascent Groq cloud business is not part of the transaction. Groq said "GroqCloud will continue to operate without interruption."&lt;/p&gt;
    &lt;p&gt;The deal represents by far Nvidia's largest purchase ever. The chipmaker's biggest acquisition to date came in 2019, when it bought Israeli chip designer Mellanox for close to $7 billion. At the end of October, Nvidia had $60.6 billion in cash and short-term investments, up from $13.3 billion in early 2023.&lt;/p&gt;
    &lt;p&gt;In an email to employees that was obtained by CNBC, Nvidia CEO Jensen Huang said the agreement will expand Nvidia's capabilities.&lt;/p&gt;
    &lt;p&gt;"We plan to integrate Groq's low-latency processors into the NVIDIA AI factory architecture, extending the platform to serve an even broader range of AI inference and real-time workloads," Huang wrote.&lt;/p&gt;
    &lt;p&gt;Huang added that, "While we are adding talented employees to our ranks and licensing Groq's IP, we are not acquiring Groq as a company."&lt;/p&gt;
    &lt;p&gt;Nvidia orchestrated a similar but smaller deal in September, when it shelled out over $900 million to hire Enfabrica CEO Rochan Sankar and other employees at the AI hardware startup, and to license the company's technology, CNBC reported at the time.&lt;/p&gt;
    &lt;p&gt;Other tech giants, including Meta, Google and Microsoft, have spent heavily over the last couple years to hire top AI talent through various types of licensing deals.&lt;/p&gt;
    &lt;p&gt;Nvidia has ramped up its investments in chip startups and the broader ecosystem as its cash pile has mounted. The company has backed AI and energy infrastructure company Crusoe, AI model developer Cohere, and boosted its investment in CoreWeave as the AI-centric cloud provider was getting ready to go public this year.&lt;/p&gt;
    &lt;p&gt;In September, Nvidia said it intended to invest up to $100 billion in OpenAI, with the startup committed to deploying at least 10 gigawatts of Nvidia products. The companies have yet to announce a formal deal. That same month, Nvidia said it would invest $5 billion in Intel as part of a partnership.&lt;/p&gt;
    &lt;p&gt;Groq has been targeting revenue of $500 million this year amid booming demand for AI accelerator chips used in speeding up the process for large language models to complete inference-related tasks. The company was not pursuing a sale when it was approached by Nvidia, Davis said.&lt;/p&gt;
    &lt;p&gt;Groq was founded in 2016 by a group of former engineers, including Ross. He was one of the creators of Google's tensor processing unit, or TPU, the search giant's custom chip that's being used by some companies as an alternative to Nvidia's graphics processing units.&lt;/p&gt;
    &lt;p&gt;In its initial filing with the SEC, announcing a $10.3 million fundraising in late 2016, Groq listed as principals Ross and Douglas Wightman, an entrepreneur and former engineer at the Google X "moonshot factory." Wightman left Groq in 2019, according to his LinkedIn profile.&lt;/p&gt;
    &lt;p&gt;Groq isn't the only chip startup that's gained traction during the AI boom.&lt;/p&gt;
    &lt;p&gt;AI chipmaker Cerebras Systems had planned to go public this year but withdrew its IPO filing in October after announcing that it raised over $1 billion in a fundraising round.&lt;/p&gt;
    &lt;p&gt;In a filing with the SEC, Cerebras said it does not intend to conduct a proposed offering "at this time," but didn't provide a reason. A spokesperson told CNBC at the time that the company still hopes to go public as soon as possible.&lt;/p&gt;
    &lt;p&gt;Cerebras filed for an IPO in late 2024, as it was ramping up to take on Nvidia in an effort to create processors for running generative AI models.&lt;/p&gt;
    &lt;p&gt;‚Äî CNBC's Jordan Novet contributed to this report.&lt;/p&gt;
    &lt;p&gt;WATCH: How the massive power draw of generative AI is overtaxing our grid&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46379183</guid><pubDate>Wed, 24 Dec 2025 21:02:15 +0000</pubDate></item><item><title>How I Left YouTube</title><link>https://zhach.news/how-i-left-youtube/</link><description>&lt;doc fingerprint="2cf5125326c467cc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How I Left YouTube&lt;/head&gt;
    &lt;p&gt;I remember sitting down in a meeting room hearing the results of my third try at promo cycle trying to get from an L4 to an L5. I helped launch/lead features on YouTube, I led teams, I designed and implemented systems that were still in use to that day by many people, people all across the org knew me and said I was indispensable to the company and were surprised that I wasn't already at an L5/6 level. The results of that meeting? The same from the previous promotion decisions; ‚Äúit‚Äôs unfortunately a no. You don‚Äôt have enough impact.‚Äù&lt;/p&gt;
    &lt;p&gt;That Tuesday afternoon realization kicked off a grueling, educational, and emotionally taxing journey: leaving a "dream job" to find out what I was actually worth in the open market.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Mathematics of Leveling&lt;/head&gt;
    &lt;p&gt;In the software engineering world, we exist on a ladder. We call this ‚ÄùLeveling‚Äù.&lt;/p&gt;
    &lt;p&gt;For those outside the tech industry, imagine the military. You have Lieutenants, Captains, Majors, and Generals. In tech, these are usually denoted as L3 (Entry/Junior), L4 (Mid), L5 (Senior), and L6 (Staff). L1/2 are saved for contractors or interns. After these denominations, one usually switches to a director or someone on the Leadership team. Your level dictates your salary, your stock grants, and most importantly, the scope of problems you are allowed to solve.&lt;/p&gt;
    &lt;p&gt;I found myself in a situation common to many engineers at large organizations. I was operating at a ‚ÄúSenior‚Äù or ‚ÄúStaff" level (architecting systems and roadmaps rather than just writing the code and tracking bugs), but my official title and compensation were stuck at just above junior level.&lt;/p&gt;
    &lt;p&gt;I faced a choice: continue to do way more work to prove myself for the lottery that is the promo cycle or leave to find a company that would recognize my output immediately. I chose the latter. And I decided to attempt a "double level" jump during my interviews (L4 to L6). I didn't just want a lateral move; I wanted the title that matched the work I was already doing.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Double Life of the Employed Candidate&lt;/head&gt;
    &lt;p&gt;Hunting for a job is a full-time occupation. Doing so while maintaining high performance at a demanding job like YouTube is a recipe for cognitive fracture.&lt;/p&gt;
    &lt;p&gt;The strain comes from context switching. From 9:00 AM to 5:00 PM, I had to care deeply about our quarterly goals and production stability. Then, from 6:00 PM to midnight, I had to care about inverting binary trees and system architecture design.&lt;/p&gt;
    &lt;p&gt;I recall taking "calls" in my car, taking vacation days to practice and do interviews, tethering my laptop to my phone's hotspot to solve coding challenges while squatting in a coffee shop down the street from the office. This duality is exhausting. It forces you to lie by omission to people you respect. You can't tell your team, "I can't take that ticket because I need to study dynamic programming." You just have to work faster.&lt;/p&gt;
    &lt;head rend="h3"&gt;Navigating the NDA Minefield&lt;/head&gt;
    &lt;p&gt;One of the most complex hurdles in this cycle was proving I was capable of that "double level" jump without breaking Non-Disclosure Agreements (NDAs).&lt;/p&gt;
    &lt;p&gt;When you work at a place like YouTube, the scale of the problems you solve is the primary selling point. However, the specifics of how you solved them are often trade secrets.&lt;/p&gt;
    &lt;p&gt;Here is the strategy I developed: Abstract the mechanism, not the metric.&lt;/p&gt;
    &lt;p&gt;I couldn't tell interviewers exactly how a specific proprietary algorithm worked. Instead, I focused on the agnostic engineering principles.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Don't say: "I tweaked the YouTube watch-time algorithm using X variable."&lt;/item&gt;
      &lt;item&gt;Do say: "I optimized a high-throughput distributed system to prioritize user retention metrics, reducing latency by 150ms through a custom caching layer."&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It shows you understand the systems (which is transferable knowledge) rather than just the product (which stays at the old company). If you are ever in this position, focus on the scale of the data and the architectural patterns you used (like Microservices or Event-Driven Architecture) rather than the feature itself. In the end, it also helped me connect with external technologies and lingo better!&lt;/p&gt;
    &lt;head rend="h3"&gt;The Elephant in the Room...&lt;/head&gt;
    &lt;p&gt;Most interviewers asked me the question that people assume is the hardest to answer... "describe why you are not already an L5/6". And honestly, this was the easiest part. People understood the problems with promos at Google/YouTube, but also this situation. The problem of "doing more work and not getting compensated" is pretty well-known.&lt;/p&gt;
    &lt;p&gt;What was unique was how long it took me to decide to leave. And I had to highlight the incredibly talented team I worked with and the amazing managers that taught me so much. There is so much value in knowing and feeling that the people around you care about you and want to build amazing things with you.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Thirteen-Interview Marathon&lt;/head&gt;
    &lt;p&gt;The most alarming trend I analyzed during this cycle is the inflation of the interview loop.&lt;/p&gt;
    &lt;p&gt;At one prominent tech company, I underwent 13 separate interviews for a single role. This included initial screens, coding rounds, system design rounds, behavioral checks, and meetings with cross-functional partners.&lt;/p&gt;
    &lt;p&gt;From a critical perspective, this signals organizational dysfunction. If a company requires 13 people to sign off on a hire, it suggests they operate on a consensus-based model that stifles autonomy. It implies a fear of making mistakes that outweighs the desire for talent.&lt;/p&gt;
    &lt;p&gt;When I analyze the data from my own process, the companies with 5 to 8 rounds had the clearest internal culture. They knew what they wanted. The company with 13 rounds was fishing for a reason to say "no‚Äù (which some ultimately told me).&lt;/p&gt;
    &lt;head rend="h3"&gt;The Final Conversation&lt;/head&gt;
    &lt;p&gt;We often hear that "people leave managers, not jobs." But sometimes, people leave jobs despite loving their managers.&lt;/p&gt;
    &lt;p&gt;My final conversation with my manager was heart-wrenching. I had prepared a script, anticipating a counter-offer or a guilt trip. Instead, I was met with soft and understanding empathy.&lt;/p&gt;
    &lt;p&gt;I explained that my growth curve had flattened. I wasn't leaving because the team failed me; I was leaving because I had outgrown the pot I was planted in. Staying would have required me to stagnate to fit the available space. I needed to leave to see what I was capable of. And he listened to every word.&lt;/p&gt;
    &lt;p&gt;I walked out of the meeting feeling incredibly bittersweet, with tears ready to fall. He knew my talent, he knew how hard I worked, and he still was incredibly supportive while I said I was leaving.&lt;/p&gt;
    &lt;p&gt;This is a hard lesson for both employees and leaders: Retention has a ceiling. Sometimes, the best thing a manager can do for that high-performer is to wish them luck as they walk out the door. It wasn't his fault I wasn't promoted to the level I wanted‚Äîhe was fighting the same bureaucratic machine I was.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Takeaway&lt;/head&gt;
    &lt;p&gt;Leaving a recognizable brand like Google/YouTube is frightening. You lose the immediate validation that comes with the name on your resume. But careers are long, and comfort is the enemy of progress.&lt;/p&gt;
    &lt;p&gt;If you feel like you are solving problems two levels above your pay grade, and the only reward you get is more work, it is time to test the market. The interview fatigue is real, and the conversations are hard, but the clarity you gain on your own value is worth the struggle.&lt;/p&gt;
    &lt;p&gt;I‚Äôm curious about your experiences with career stagnation. Have you ever felt like you were "acting" at a higher level than your title? How did you handle the conversation with your leadership?&lt;/p&gt;
    &lt;p&gt;Please share your stories in the comments below.&lt;/p&gt;
    &lt;head rend="h3"&gt;Links and Resources&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Software Engineering Levels: levels.fyi (Excellent resource for comparing titles and compensation across big tech).&lt;/item&gt;
      &lt;item&gt;Github: Career Ladder (detailed guide on how Github views levels; and I personally like their view)&lt;/item&gt;
      &lt;item&gt;System Design Interview Guide: System Design Primer on GitHub&lt;/item&gt;
      &lt;item&gt;Navigating NDAs: Harvard Business Review: Non-Disclosure Agreements&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46379677</guid><pubDate>Wed, 24 Dec 2025 21:54:48 +0000</pubDate></item><item><title>Phoenix: A modern X server written from scratch in Zig</title><link>https://git.dec05eba.com/phoenix/about/</link><description>&lt;doc fingerprint="d47bdcdf6826ad85"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Phoenix&lt;/head&gt;
    &lt;p&gt;Phoenix is a new X server, written from scratch in Zig (not a fork of Xorg server). This X server is designed to be a modern alternative to the Xorg server.&lt;/p&gt;
    &lt;head rend="h2"&gt;Current state&lt;/head&gt;
    &lt;p&gt;Phoenix is not ready to be used yet. At the moment it can render simple applications that do GLX, EGL or Vulkan graphics (fully hardware accelerated) nested in an existing X server. Running Phoenix nested will be the only supported mode until Phoenix has progressed more and can run real-world applications.&lt;/p&gt;
    &lt;head rend="h2"&gt;Goals&lt;/head&gt;
    &lt;head rend="h3"&gt;Simplicity&lt;/head&gt;
    &lt;p&gt;Be a simpler X server than the Xorg server by only supporting a subset of the X11 protocol, the features that are needed by relatively modern applications (applications written in the last ~20 years).&lt;lb/&gt; Only relatively modern hardware (made in the last ~15 years) which support linux drm and mesa gbm will be supported, and no server driver interface like the Xorg server. Just like how Wayland compositors work.&lt;/p&gt;
    &lt;head rend="h3"&gt;Security&lt;/head&gt;
    &lt;p&gt;Be safer than the Xorg server by parsing protocol messages automatically. As it's written in Zig, it also automatically catches illegal behaviors (such as index out of array bounds) when building with the &lt;code&gt;ReleaseSafe&lt;/code&gt; option.&lt;/p&gt;
    &lt;p&gt;Applications will be isolated from each other by default and can only interact with other applications either through a GUI prompt asking for permission, such as with screen recorders, where it will only be allowed to record the window specified or by explicitly giving the application permission before launched (such as a window manager or external compositor). This will not break existing clients as clients wont receive errors when they try to access more than they need, they will instead receive dummy data.&lt;lb/&gt; Applications that rely on global hotkeys should work, as long as a modifier key is pressed (keys such as ctrl, shift, alt and super). If an application needs global hotkeys without pressing a modifier key then it needs to be given permissions to do so (perhaps by adding a command to run a program with more X11 permissions).&lt;lb/&gt; There will be an option to disable this to make the X server behave like the Xorg server.&lt;/p&gt;
    &lt;head rend="h3"&gt;Improvements for modern technology&lt;/head&gt;
    &lt;p&gt;Support modern hardware better than the Xorg server, such as proper support for multiple monitors (different refresh rates, VRR - not a single framebuffer for the whole collection of displays) and technology like HDR.&lt;/p&gt;
    &lt;head rend="h3"&gt;Improved graphics handling&lt;/head&gt;
    &lt;p&gt;No tearing by default and a built-in compositor. The compositor will get disabled if the user runs an external compositor (client application), such as picom or if the client runs a fullscreen application and disabled vsync in the application. The goal is to also have lower vsync/compositor latency than the Xorg server.&lt;/p&gt;
    &lt;head rend="h3"&gt;New standards&lt;/head&gt;
    &lt;p&gt;New standards will be developed and documented, such as per-monitor DPI as randr properties. Applications can use this property to scale their content to the specified DPI for the monitor they are on.&lt;/p&gt;
    &lt;head rend="h3"&gt;Extending the X11 protocol&lt;/head&gt;
    &lt;p&gt;If there is a need for new features (such as HDR) then the X11 protocol will be extended.&lt;/p&gt;
    &lt;head rend="h3"&gt;Wayland compatibility&lt;/head&gt;
    &lt;p&gt;Some applications might only run on Wayland in the future. Such applications should be supported by either Phoenix supporting Wayland natively or by running an external application that works as a bridge between Wayland and X11 (such as 12to11).&lt;/p&gt;
    &lt;head rend="h3"&gt;Nested display server&lt;/head&gt;
    &lt;p&gt;Being able to run Phoenix nested under X11 or Wayland with hardware acceleration. This is not only useful for debugging Phoenix but also for developers who want to test their window manager or compositor without restarting the display server they are running.&lt;lb/&gt; Being able to run Phoenix under Wayland as an alternative Xwayland server would be a good option.&lt;/p&gt;
    &lt;head rend="h2"&gt;Non-goals&lt;/head&gt;
    &lt;head rend="h3"&gt;Replacing the Xorg server&lt;/head&gt;
    &lt;p&gt;The Xorg server will always support more features of the X11 protocol and wider range of hardware (especially older ones).&lt;/p&gt;
    &lt;head rend="h3"&gt;Multiple screens&lt;/head&gt;
    &lt;p&gt;Multiple displays (monitors) are going to be supported but not X11 screens.&lt;/p&gt;
    &lt;head rend="h3"&gt;Exclusive access&lt;/head&gt;
    &lt;p&gt;GrabServer has no effect in Phoenix.&lt;/p&gt;
    &lt;head rend="h3"&gt;Endian-swapped client/server&lt;/head&gt;
    &lt;p&gt;This can be reconsidered if there is a reason.&lt;/p&gt;
    &lt;head rend="h3"&gt;Indirect (remote) GLX.&lt;/head&gt;
    &lt;p&gt;This is very complex as there are a lot of functions that would need to be implemented. These days remote streaming options are more efficient. Alternatively a proxy for glx could be implemented that does remote rendering.&lt;/p&gt;
    &lt;head rend="h2"&gt;Differences between the X11 protocol and Phoenix&lt;/head&gt;
    &lt;head rend="h3"&gt;Core protocol&lt;/head&gt;
    &lt;p&gt;Several parts of the X11 protocol (core) are mandatory to be implemented by an X server, such as font related operations. However these are not going to be implemented in Phoenix.&lt;/p&gt;
    &lt;head rend="h3"&gt;Strings&lt;/head&gt;
    &lt;p&gt;Strings are in ISO Latin-1 encoding in the X11 protocol unless specified otherwise, however in Phoenix all strings are UTF-8 unless the protocol states that it's not an ISO Latin-1 string.&lt;/p&gt;
    &lt;head rend="h2"&gt;Installing&lt;/head&gt;
    &lt;p&gt;Run:&lt;/p&gt;
    &lt;code&gt;zig build -Doptimize=ReleaseSafe
sudo zig build install -p /usr/local -Doptimize=ReleaseSafe
&lt;/code&gt;
    &lt;head rend="h2"&gt;Uninstalling&lt;/head&gt;
    &lt;p&gt;Zig does currently not support the uninstall command so you have to remove files manually:&lt;/p&gt;
    &lt;code&gt;sudo rm /usr/local/bin/phoenix
&lt;/code&gt;
    &lt;head rend="h2"&gt;Building (for development)&lt;/head&gt;
    &lt;p&gt;Run &lt;code&gt;zig build&lt;/code&gt;, which builds Phoenix in debug mode. The compiled binary will be available at &lt;code&gt;./zig-out/bin/phoenix&lt;/code&gt;. You can alternatively build and run with one command: &lt;code&gt;zig build run&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;Generate x11 protocol documentation&lt;/head&gt;
    &lt;p&gt;Run &lt;code&gt;zig build -Dgenerate-docs=true&lt;/code&gt;. This will generate &lt;code&gt;.txt&lt;/code&gt; files in &lt;code&gt;./zig-out/protocol/&lt;/code&gt;. This generates x11 protocol documentation in the style of the official protocol documentation. The documentation is automatically generated from the protocol struct code.
Note that the generated documentation feature is a work-in-progress.&lt;/p&gt;
    &lt;head rend="h2"&gt;Dependencies&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Zig 0.14.1&lt;/item&gt;
      &lt;item&gt;x11 (&lt;code&gt;xcb&lt;/code&gt;) - for nested mode under X11, when building Phoenix with&lt;code&gt;-Dbackends=x11&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;wayland (&lt;code&gt;wayland-client&lt;/code&gt;,&lt;code&gt;wayland-egl&lt;/code&gt;) - for nested mode under Wayland, when building Phoenix with&lt;code&gt;-Dbackends=wayland&lt;/code&gt;(not currently supported)&lt;/item&gt;
      &lt;item&gt;drm (&lt;code&gt;libdrm&lt;/code&gt;,&lt;code&gt;gbm&lt;/code&gt;) - for running Phoenix as a standalone X11 server, when building Phoenix with&lt;code&gt;-Dbackends=drm&lt;/code&gt;(not currently supported)&lt;/item&gt;
      &lt;item&gt;OpenGL (&lt;code&gt;libglvnd&lt;/code&gt;which provides both&lt;code&gt;gl&lt;/code&gt;and&lt;code&gt;egl&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46380075</guid><pubDate>Wed, 24 Dec 2025 22:43:53 +0000</pubDate></item><item><title>Tell HN: Merry Christmas</title><link>https://news.ycombinator.com/item?id=46380168</link><description>&lt;doc fingerprint="3d2d13d459cf20bd"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Different cultures celebrate Christmas at different days and time zones are a thing. But it's Christmas here, so:&lt;/p&gt;
      &lt;p&gt;Merry Christmas to everyone. I hope you get some rest and can spend time with people who are dear to you and get to focus on what's important rather than getting lost in stressing about everything having to be perfect.&lt;/p&gt;
      &lt;p&gt;Also much love to everyone who cannot spend their Christmas with dear people.&lt;/p&gt;
      &lt;p&gt;To make sure this post meets the relevancy criteria, here is a Wikipedia article about some Christmas (more precisely advent) tradition which I personally really like: https://en.wikipedia.org/wiki/Christmas_market&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46380168</guid><pubDate>Wed, 24 Dec 2025 22:56:00 +0000</pubDate></item><item><title>Asterisk AI Voice Agent</title><link>https://github.com/hkjarral/Asterisk-AI-Voice-Agent</link><description>&lt;doc fingerprint="2c0ef1107fb2aeaa"&gt;
  &lt;main&gt;
    &lt;p&gt;The most powerful, flexible open-source AI voice agent for Asterisk/FreePBX. Featuring a modular pipeline architecture that lets you mix and match STT, LLM, and TTS providers, plus 5 production-ready golden baselines validated for enterprise deployment.&lt;/p&gt;
    &lt;p&gt;Quick Start ‚Ä¢ Features ‚Ä¢ Demo ‚Ä¢ Documentation ‚Ä¢ Community&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üöÄ Quick Start&lt;/item&gt;
      &lt;item&gt;üéâ What's New&lt;/item&gt;
      &lt;item&gt;üåü Why Asterisk AI Voice Agent?&lt;/item&gt;
      &lt;item&gt;‚ú® Features&lt;/item&gt;
      &lt;item&gt;üé• Demo&lt;/item&gt;
      &lt;item&gt;üõ†Ô∏è AI-Powered Actions&lt;/item&gt;
      &lt;item&gt;ü©∫ Agent CLI Tools&lt;/item&gt;
      &lt;item&gt;‚öôÔ∏è Configuration&lt;/item&gt;
      &lt;item&gt;üèóÔ∏è Project Architecture&lt;/item&gt;
      &lt;item&gt;üìä Requirements&lt;/item&gt;
      &lt;item&gt;üó∫Ô∏è Documentation&lt;/item&gt;
      &lt;item&gt;ü§ù Contributing&lt;/item&gt;
      &lt;item&gt;üí¨ Community&lt;/item&gt;
      &lt;item&gt;üìù License&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Get the Admin UI running in 2 minutes.&lt;/p&gt;
    &lt;p&gt;For a complete first successful call walkthrough (dialplan + transport selection + verification), see:&lt;/p&gt;
    &lt;code&gt;# Clone repository
git clone https://github.com/hkjarral/Asterisk-AI-Voice-Agent.git
cd Asterisk-AI-Voice-Agent

# Run preflight with auto-fix (creates .env, generates JWT_SECRET)
sudo ./preflight.sh --apply-fixes&lt;/code&gt;
    &lt;quote&gt;&lt;p&gt;Important: Preflight creates your&lt;/p&gt;&lt;code&gt;.env&lt;/code&gt;file and generates a secure&lt;code&gt;JWT_SECRET&lt;/code&gt;. Always run this first!&lt;/quote&gt;
    &lt;code&gt;# Start the Admin UI container
docker compose up -d --build admin-ui&lt;/code&gt;
    &lt;p&gt;Open in your browser:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Local: &lt;code&gt;http://localhost:3003&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Remote server: &lt;code&gt;http://&amp;lt;server-ip&amp;gt;:3003&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Default Login: &lt;code&gt;admin&lt;/code&gt; / &lt;code&gt;admin&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;Follow the Setup Wizard to configure your providers and make a test call.&lt;/p&gt;
    &lt;quote&gt;&lt;g-emoji&gt;‚ö†Ô∏è&lt;/g-emoji&gt;Security: The Admin UI is accessible on the network. Change the default password immediately and restrict port 3003 via firewall, VPN, or reverse proxy for production use.&lt;/quote&gt;
    &lt;code&gt;# Start ai-engine (required for health checks)
docker compose up -d --build ai-engine

# Check ai-engine health
curl http://localhost:15000/health
# Expected: {"status":"healthy"}

# View logs for any errors
docker compose logs ai-engine | tail -20&lt;/code&gt;
    &lt;p&gt;The wizard will generate the necessary dialplan configuration for your Asterisk server.&lt;/p&gt;
    &lt;p&gt;Transport selection is configuration-dependent (not strictly ‚Äúpipelines vs full agents‚Äù). Use the validated matrix in:&lt;/p&gt;
    &lt;p&gt;For users who prefer the command line or need headless setup.&lt;/p&gt;
    &lt;code&gt;./install.sh
agent quickstart&lt;/code&gt;
    &lt;code&gt;# Configure environment
cp .env.example .env
# Edit .env with your API keys

# Start services
docker compose up -d&lt;/code&gt;
    &lt;p&gt;Add this to your FreePBX (&lt;code&gt;extensions_custom.conf&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;[from-ai-agent]
exten =&amp;gt; s,1,NoOp(Asterisk AI Voice Agent v4.5.3)
 same =&amp;gt; n,Stasis(asterisk-ai-voice-agent)
 same =&amp;gt; n,Hangup()
&lt;/code&gt;
    &lt;p&gt;Health check:&lt;/p&gt;
    &lt;code&gt;agent doctor&lt;/code&gt;
    &lt;p&gt;View logs:&lt;/p&gt;
    &lt;code&gt;docker compose logs -f ai-engine&lt;/code&gt;
    &lt;head&gt;Latest Updates&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Full Call Logging: Every call saved with conversation history, timing, and outcome&lt;/item&gt;
      &lt;item&gt;Per-Call Debugging: Review transcripts, tool executions, and errors from Admin UI&lt;/item&gt;
      &lt;item&gt;Search &amp;amp; Filter: Find calls by caller, provider, context, or date range&lt;/item&gt;
      &lt;item&gt;Export: Download call data as CSV or JSON&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Immediate Interruption: Agent audio stops instantly when caller speaks&lt;/item&gt;
      &lt;item&gt;Provider-Owned Turn-Taking: Full agents (Google, Deepgram, OpenAI, ElevenLabs) handle VAD natively&lt;/item&gt;
      &lt;item&gt;Platform Flush: Local playback clears immediately on interruption signal&lt;/item&gt;
      &lt;item&gt;Transport Parity: Works with both ExternalMedia RTP and AudioSocket&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Faster Whisper: High-accuracy STT backend with GPU acceleration&lt;/item&gt;
      &lt;item&gt;MeloTTS: New neural TTS option for local pipelines&lt;/item&gt;
      &lt;item&gt;Model Hot-Swap: Switch models via Dashboard without container restart&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;External Tools Framework: Connect AI agents to external services via Model Context Protocol&lt;/item&gt;
      &lt;item&gt;Admin UI Config: Configure MCP servers from the web interface&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Remote Endpoint Pinning: Lock RTP streams to prevent audio hijacking&lt;/item&gt;
      &lt;item&gt;Allowlist Support: Restrict allowed remote hosts for ExternalMedia&lt;/item&gt;
      &lt;item&gt;Cross-Talk Prevention: SSRC-based routing ensures call isolation&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;local_hybrid&lt;/code&gt;Default: Privacy-focused pipeline is now the out-of-box default&lt;/item&gt;
      &lt;item&gt;Pipeline-Aware Readiness: Health probes correctly reflect pipeline component status&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;Previous Versions&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üåç Pre-flight Script: System compatibility checker with auto-fix mode.&lt;/item&gt;
      &lt;item&gt;üîß Admin UI Fixes: Models page, providers page, dashboard improvements.&lt;/item&gt;
      &lt;item&gt;üõ†Ô∏è Developer Experience: Code splitting, ESLint + Prettier.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üé§ New STT Backends: Kroko ASR, Sherpa-ONNX.&lt;/item&gt;
      &lt;item&gt;üîä Kokoro TTS: High-quality neural TTS.&lt;/item&gt;
      &lt;item&gt;üîÑ Model Management: Dynamic backend switching from Dashboard.&lt;/item&gt;
      &lt;item&gt;üìö Documentation: LOCAL_ONLY_SETUP.md guide.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üñ•Ô∏è Admin UI v1.0: Modern web interface (http://localhost:3003).&lt;/item&gt;
      &lt;item&gt;üéôÔ∏è ElevenLabs Conversational AI: Premium voice quality provider.&lt;/item&gt;
      &lt;item&gt;üéµ Background Music: Ambient music during AI calls.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üîß Complete Tool Support: Works across ALL pipeline types.&lt;/item&gt;
      &lt;item&gt;üìö Documentation Overhaul: Reorganized structure.&lt;/item&gt;
      &lt;item&gt;üí¨ Discord Community: Official server integration.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ü§ñ Google Live API: Gemini 2.0 Flash integration.&lt;/item&gt;
      &lt;item&gt;üöÄ Interactive Setup: &lt;code&gt;agent quickstart&lt;/code&gt;wizard.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üîß Tool Calling System: Transfer calls, send emails.&lt;/item&gt;
      &lt;item&gt;ü©∫ Agent CLI Tools: &lt;code&gt;doctor&lt;/code&gt;,&lt;code&gt;troubleshoot&lt;/code&gt;,&lt;code&gt;demo&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Feature&lt;/cell&gt;
        &lt;cell role="head"&gt;Benefit&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Asterisk-Native&lt;/cell&gt;
        &lt;cell&gt;Works directly with your existing Asterisk/FreePBX - no external telephony providers required.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Truly Open Source&lt;/cell&gt;
        &lt;cell&gt;MIT licensed with complete transparency and control.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Modular Architecture&lt;/cell&gt;
        &lt;cell&gt;Choose cloud, local, or hybrid - mix providers as needed.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Production-Ready&lt;/cell&gt;
        &lt;cell&gt;Battle-tested baselines with Call History-first debugging.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Cost-Effective&lt;/cell&gt;
        &lt;cell&gt;Local Hybrid costs ~$0.001-0.003/minute (LLM only).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Privacy-First&lt;/cell&gt;
        &lt;cell&gt;Keep audio local while using cloud intelligence.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;OpenAI Realtime (Recommended for Quick Start)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Modern cloud AI with natural conversations (&amp;lt;2s response).&lt;/item&gt;
          &lt;item&gt;Config: &lt;code&gt;config/ai-agent.golden-openai.yaml&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Best for: Enterprise deployments, quick setup.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Deepgram Voice Agent (Enterprise Cloud)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Advanced Think stage for complex reasoning (&amp;lt;3s response).&lt;/item&gt;
          &lt;item&gt;Config: &lt;code&gt;config/ai-agent.golden-deepgram.yaml&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Best for: Deepgram ecosystem, advanced features.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Google Live API (Multimodal AI)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Gemini Live (Flash) with multimodal capabilities (&amp;lt;2s response).&lt;/item&gt;
          &lt;item&gt;Config: &lt;code&gt;config/ai-agent.golden-google-live.yaml&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Best for: Google ecosystem, advanced AI features.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;ElevenLabs Agent (Premium Voice Quality)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;ElevenLabs Conversational AI with premium voices (&amp;lt;2s response).&lt;/item&gt;
          &lt;item&gt;Config: &lt;code&gt;config/ai-agent.golden-elevenlabs.yaml&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Best for: Voice quality priority, natural conversations.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Local Hybrid (Privacy-Focused)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Local STT/TTS + Cloud LLM (OpenAI). Audio stays on-premises.&lt;/item&gt;
          &lt;item&gt;Config: &lt;code&gt;config/ai-agent.golden-local-hybrid.yaml&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Best for: Audio privacy, cost control, compliance.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Run your own local LLM using Ollama - perfect for privacy-focused deployments:&lt;/p&gt;
    &lt;code&gt;# In ai-agent.yaml
active_pipeline: local_ollama&lt;/code&gt;
    &lt;p&gt;Features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;No API key required - fully self-hosted on your network&lt;/item&gt;
      &lt;item&gt;Tool calling support with compatible models (Llama 3.2, Mistral, Qwen)&lt;/item&gt;
      &lt;item&gt;Local Vosk STT + Your Ollama LLM + Local Piper TTS&lt;/item&gt;
      &lt;item&gt;Complete privacy - all processing stays on-premises&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Requirements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mac Mini, gaming PC, or server with Ollama installed&lt;/item&gt;
      &lt;item&gt;8GB+ RAM (16GB+ recommended for larger models)&lt;/item&gt;
      &lt;item&gt;See docs/OLLAMA_SETUP.md for setup guide&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Recommended Models:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Model&lt;/cell&gt;
        &lt;cell role="head"&gt;Size&lt;/cell&gt;
        &lt;cell role="head"&gt;Tool Calling&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;llama3.2&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;2GB&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;mistral&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;4GB&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;qwen2.5&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;4.7GB&lt;/cell&gt;
        &lt;cell&gt;‚úÖ Yes&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tool Calling System: AI-powered actions (transfers, emails) work with any provider.&lt;/item&gt;
      &lt;item&gt;Agent CLI Tools: &lt;code&gt;doctor&lt;/code&gt;,&lt;code&gt;troubleshoot&lt;/code&gt;,&lt;code&gt;demo&lt;/code&gt;,&lt;code&gt;init&lt;/code&gt;commands.&lt;/item&gt;
      &lt;item&gt;Modular Pipeline System: Independent STT, LLM, and TTS provider selection.&lt;/item&gt;
      &lt;item&gt;Dual Transport Support: AudioSocket and ExternalMedia RTP (see Transport Compatibility matrix).&lt;/item&gt;
      &lt;item&gt;High-Performance Architecture: Separate &lt;code&gt;ai-engine&lt;/code&gt;and&lt;code&gt;local-ai-server&lt;/code&gt;containers.&lt;/item&gt;
      &lt;item&gt;Observability: Built-in Call History for per-call debugging + optional &lt;code&gt;/metrics&lt;/code&gt;scraping.&lt;/item&gt;
      &lt;item&gt;State Management: SessionStore for centralized, typed call state.&lt;/item&gt;
      &lt;item&gt;Barge-In Support: Interrupt handling with configurable gating.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Modern web interface for configuration and system management.&lt;/p&gt;
    &lt;p&gt;Quick Start:&lt;/p&gt;
    &lt;code&gt;docker compose up -d admin-ui
# Access at: http://localhost:3003
# Login: admin / admin (change immediately!)&lt;/code&gt;
    &lt;p&gt;Key Features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Setup Wizard: Visual provider configuration.&lt;/item&gt;
      &lt;item&gt;Dashboard: Real-time system metrics and container status.&lt;/item&gt;
      &lt;item&gt;Live Logs: WebSocket-based log streaming.&lt;/item&gt;
      &lt;item&gt;YAML Editor: Monaco-based editor with validation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Experience our production-ready configurations with a single phone call:&lt;/p&gt;
    &lt;p&gt;Dial: (925) 736-6718&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Press 5 ‚Üí Google Live API (Multimodal AI with Gemini 2.0)&lt;/item&gt;
      &lt;item&gt;Press 6 ‚Üí Deepgram Voice Agent (Enterprise cloud with Think stage)&lt;/item&gt;
      &lt;item&gt;Press 7 ‚Üí OpenAI Realtime API (Modern cloud AI, most natural)&lt;/item&gt;
      &lt;item&gt;Press 8 ‚Üí Local Hybrid Pipeline (Privacy-focused, audio stays local)&lt;/item&gt;
      &lt;item&gt;Press 9 ‚Üí ElevenLabs Agent (Santa voice with background music)&lt;/item&gt;
      &lt;item&gt;Press 10 ‚Üí Fully Local Pipeline (100% on-premises, CPU-based)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Your AI agent can perform real-world telephony actions through tool calling.&lt;/p&gt;
    &lt;code&gt;Caller: "Transfer me to the sales team"
Agent: "I'll connect you to our sales team right away."
[Transfer to sales queue with queue music]
&lt;/code&gt;
    &lt;p&gt;Supported Destinations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Extensions: Direct SIP/PJSIP endpoint transfers.&lt;/item&gt;
      &lt;item&gt;Queues: ACD queue transfers with position announcements.&lt;/item&gt;
      &lt;item&gt;Ring Groups: Multiple agents ring simultaneously.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cancel Transfer: "Actually, cancel that" (during ring).&lt;/item&gt;
      &lt;item&gt;Hangup Call: Ends call gracefully with farewell.&lt;/item&gt;
      &lt;item&gt;Voicemail: Routes to voicemail box.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Automatic Call Summaries: Admins receive full transcripts and metadata.&lt;/item&gt;
      &lt;item&gt;Caller-Requested Transcripts: "Email me a transcript of this call."&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Tool&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Status&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;transfer&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Transfer to extensions, queues, or ring groups&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;cancel_transfer&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Cancel in-progress transfer (during ring)&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;hangup_call&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;End call gracefully with farewell message&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;leave_voicemail&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Route caller to voicemail extension&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;send_email_summary&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Auto-send call summaries to admins&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;request_transcript&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Caller-initiated email transcripts&lt;/cell&gt;
        &lt;cell&gt;‚úÖ&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Production-ready CLI for operations and setup.&lt;/p&gt;
    &lt;p&gt;Installation:&lt;/p&gt;
    &lt;code&gt;curl -sSL https://raw.githubusercontent.com/hkjarral/Asterisk-AI-Voice-Agent/main/scripts/install-cli.sh | bash&lt;/code&gt;
    &lt;p&gt;Commands:&lt;/p&gt;
    &lt;code&gt;agent quickstart          # Interactive setup wizard
agent dialplan            # Generate dialplan snippets
agent config validate     # Validate configuration
agent doctor --fix        # System health check
agent troubleshoot        # Analyze specific call
agent demo                # Demo features&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;config/ai-agent.yaml&lt;/code&gt;- Golden baseline configs.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;.env&lt;/code&gt;- Secrets and API keys (git-ignored).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example &lt;code&gt;.env&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;OPENAI_API_KEY=sk-your-key-here
DEEPGRAM_API_KEY=your-key-here
ASTERISK_ARI_USERNAME=asterisk
ASTERISK_ARI_PASSWORD=your-password&lt;/code&gt;
    &lt;p&gt;The engine exposes Prometheus-format metrics at &lt;code&gt;http://&amp;lt;engine-host&amp;gt;:15000/metrics&lt;/code&gt;.
Per-call debugging is handled via Admin UI ‚Üí Call History.&lt;/p&gt;
    &lt;p&gt;Two-container architecture for performance and scalability:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;ai-engine&lt;/code&gt;(Lightweight orchestrator): Connects to Asterisk via ARI, manages call lifecycle.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;local-ai-server&lt;/code&gt;(Optional): Runs local STT/LLM/TTS models (Vosk, Sherpa, Kroko, Piper, Kokoro, llama.cpp).&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;graph LR
    A[Asterisk Server] &amp;lt;--&amp;gt;|ARI, RTP| B[ai-engine]
    B &amp;lt;--&amp;gt;|API| C[AI Provider]
    B &amp;lt;--&amp;gt;|WS| D[local-ai-server]
    
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style B fill:#bbf,stroke:#333,stroke-width:2px
    style C fill:#bfb,stroke:#333,stroke-width:2px
    style D fill:#fbf,stroke:#333,stroke-width:2px
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Requirement&lt;/cell&gt;
        &lt;cell role="head"&gt;Details&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Architecture&lt;/cell&gt;
        &lt;cell&gt;x86_64 (AMD64) only&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;OS&lt;/cell&gt;
        &lt;cell&gt;Linux with systemd&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Supported Distros&lt;/cell&gt;
        &lt;cell&gt;Ubuntu 20.04+, Debian 11+, RHEL/Rocky/Alma 8+, Fedora 38+, Sangoma Linux&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;quote&gt;
      &lt;p&gt;Note: ARM64 (Apple Silicon, Raspberry Pi) is not currently supported. See Supported Platforms for the full compatibility matrix.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Type&lt;/cell&gt;
        &lt;cell role="head"&gt;CPU&lt;/cell&gt;
        &lt;cell role="head"&gt;RAM&lt;/cell&gt;
        &lt;cell role="head"&gt;Disk&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Cloud (OpenAI/Deepgram)&lt;/cell&gt;
        &lt;cell&gt;2+ cores&lt;/cell&gt;
        &lt;cell&gt;4GB&lt;/cell&gt;
        &lt;cell&gt;1GB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Local Hybrid&lt;/cell&gt;
        &lt;cell&gt;4+ cores&lt;/cell&gt;
        &lt;cell&gt;8GB+&lt;/cell&gt;
        &lt;cell&gt;2GB&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Docker + Docker Compose v2&lt;/item&gt;
      &lt;item&gt;Asterisk 18+ with ARI enabled&lt;/item&gt;
      &lt;item&gt;FreePBX (recommended) or vanilla Asterisk&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The &lt;code&gt;preflight.sh&lt;/code&gt; script handles initial setup:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Seeds &lt;code&gt;.env&lt;/code&gt;from&lt;code&gt;.env.example&lt;/code&gt;with your settings&lt;/item&gt;
      &lt;item&gt;Prompts for Asterisk config directory location&lt;/item&gt;
      &lt;item&gt;Sets &lt;code&gt;ASTERISK_UID&lt;/code&gt;/&lt;code&gt;ASTERISK_GID&lt;/code&gt;to match host permissions (fixes media access issues)&lt;/item&gt;
      &lt;item&gt;Re-running preflight often resolves permission problems&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Configuration Reference&lt;/item&gt;
      &lt;item&gt;Transport Compatibility&lt;/item&gt;
      &lt;item&gt;Tuning Recipes&lt;/item&gt;
      &lt;item&gt;Supported Platforms&lt;/item&gt;
      &lt;item&gt;Local Profiles&lt;/item&gt;
      &lt;item&gt;Monitoring Guide&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Contributions are welcome! Please see our Contributing Guide.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Discord Server - Support and discussions&lt;/item&gt;
      &lt;item&gt;GitHub Issues - Bug reports&lt;/item&gt;
      &lt;item&gt;GitHub Discussions - General chat&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This project is licensed under the MIT License. See the LICENSE file for details.&lt;/p&gt;
    &lt;p&gt;If you find this project useful, please give it a ‚≠êÔ∏è on GitHub!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46380399</guid><pubDate>Wed, 24 Dec 2025 23:25:37 +0000</pubDate></item><item><title>Microsoft please get your tab to autocomplete shit together</title><link>https://ivanca.github.io/programming/2025/11/26/microsoft-pls-get-your-tab-to-autocomplete-shit-together/</link><description>&lt;doc fingerprint="5b198935501a40f1"&gt;
  &lt;main&gt;
    &lt;p&gt;November 26, 2025 ‚Ä¢ Programming&lt;/p&gt;
    &lt;p&gt;What do you think is gonna happen after I press tab when looking at this screenshot?&lt;/p&gt;
    &lt;p&gt;That‚Äôs right, its gonna do nothing and suggest something else that it wasn‚Äôt any of the 2 initial suggestions&lt;/p&gt;
    &lt;p&gt;Whoever team or person is on charge of the vscode autocomplete behavior at Microsoft (or at least the C# Dev Kit plugin) please do your job and fix this, thank you.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46380475</guid><pubDate>Wed, 24 Dec 2025 23:33:15 +0000</pubDate></item><item><title>Who Watches the Waymos? I do [video]</title><link>https://www.youtube.com/watch?v=oYU2hAbx_Fc</link><description>&lt;doc fingerprint="7055905545553646"&gt;
  &lt;main&gt;
    &lt;p&gt;About Press Copyright Contact us Creators Advertise Developers Terms Privacy Policy &amp;amp; Safety How YouTube works Test new features NFL Sunday Ticket ¬© 2025 Google LLC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46380758</guid><pubDate>Thu, 25 Dec 2025 00:10:12 +0000</pubDate></item><item><title>The Next-Gen Mainboard Designed with AmigaOS4 and MorphOS in Mind</title><link>https://mirari.vitasys.nl/our-story/</link><description>&lt;doc fingerprint="d4b2af7c4348b786"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;First things first‚Ä¶&lt;/head&gt;
    &lt;p&gt;Let‚Äôs take a moment to appreciate Trevor Dickinson and his incredible contributions to the Amiga world. His dedication and support have been instrumental in bringing us the next generation of Amiga computers, the ExecSG Kernel and the ongoing development of the Radeon Graphics drivers. Without having machines like the X1000, X5000 and A1222 this project would have never been born. Thank you Trevor, for keeping the Amiga spirit alive!&lt;/p&gt;
    &lt;head rend="h3"&gt;Rebooting The Next-Gen Amiga Dream&lt;/head&gt;
    &lt;p&gt;The Amiga, a once-dominant force in the personal computer world, continues to hold a special place in the hearts of many. But with limited next-gen hardware available and dwindling AmigaOS4 support, the future of this beloved platform seemed uncertain. That is, until a few Dutch passionate individuals decided to take matters into their own hands.&lt;/p&gt;
    &lt;p&gt;Driven by a shared love for the Amiga and a desire to see it thrive, they embarked on an ambitious project: to create a new, low-cost next-gen Amiga mainboard.&lt;/p&gt;
    &lt;p&gt;The Vision:&lt;/p&gt;
    &lt;p&gt;The goal was clear: to create a mainboard that would breathe new life into the next-gen Amiga platform. A board that would be affordable for hobbyists and enthusiasts, while offering the power and performance to run all AmigaOS software and games.&lt;/p&gt;
    &lt;p&gt;The Road Ahead:&lt;/p&gt;
    &lt;p&gt;The journey is filled with challenges, from overcoming technical hurdles to navigating the complexities of cheap production and logistics as for getting the needed software components up and running. But Dave and Harald fueled by their passion and the unwavering support of the Amiga community, remain committed to their vision.&lt;/p&gt;
    &lt;p&gt;A Testament to Community Spirit:&lt;/p&gt;
    &lt;p&gt;The story of Dave and Harald, is a testament to the power of community. It demonstrates how a shared love for technology and a collective effort can bring about remarkable achievements.&lt;/p&gt;
    &lt;p&gt;Stay Tuned:&lt;/p&gt;
    &lt;p&gt;As the project progresses, we will continue to provide updates on the development of the new Mirari Amiga mainboard. The progress can be found on The First Rebirth page.&lt;/p&gt;
    &lt;p&gt;The Future of the Amiga is in Our Hands.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46380953</guid><pubDate>Thu, 25 Dec 2025 00:38:09 +0000</pubDate></item><item><title>Microsoft denies rewriting Windows 11 in Rust using AI</title><link>https://www.windowslatest.com/2025/12/24/microsoft-denies-rewriting-windows-11-using-ai-after-an-employees-one-engineer-one-month-one-million-code-post-on-linkedin-causes-outrage/</link><description>&lt;doc fingerprint="e1c283d7d2638d6"&gt;
  &lt;main&gt;
    &lt;p&gt;Microsoft told Windows Latest that the company does not plan to rewrite Windows 11 using AI in Rust, which is a programming language that is more secure than C and C++. But the clarification is not coming out of nowhere, as a top-level Microsoft engineer made bold claims of using AI to replace C and C++ with Rust.&lt;/p&gt;
    &lt;p&gt;‚ÄúMy goal is to eliminate every line of C and C++ from Microsoft by 2030. Our strategy is to combine AI *and* Algorithms to rewrite Microsoft‚Äôs largest codebases. Our North Star is ‚Äú1 engineer, 1 month, 1 million lines of code,‚Äù Galen Hunt, who is a top-level Distinguished Engineer at Microsoft, wrote in a now-edited LinkedIn post.&lt;/p&gt;
    &lt;p&gt;‚ÄúEliminate every line of C and C++ from Microsoft by 2030‚Äù obviously suggests that Microsoft‚Äôs top-level engineer, who is responsible for several large-scale research projects, is talking about products like Windows. For those unaware, most of the Windows API level code, and even its kernel, is built in C, while C++ powers some of the apps.&lt;/p&gt;
    &lt;p&gt;I also screenshotted the LinkedIn post before it was edited out by the top-level Microsoft engineer:&lt;/p&gt;
    &lt;p&gt;Honestly, most people would not have taken this seriously if it did not come from a top-level Microsoft engineer. When someone with that kind of title and long history at the company talks about eliminating C and C++ and using AI to rewrite large codebases, it sounds less like a random idea and more like something Microsoft is at least exploring.&lt;/p&gt;
    &lt;p&gt;Moreover, the LinkedIn post repeatedly used ‚Äúour‚Äù, which sort of makes it obvious he‚Äôs speaking on behalf of the company.&lt;/p&gt;
    &lt;p&gt;Following the outrage over plans to ‚Äúeliminate every line of C and C++ from Microsoft by 2030,‚Äù Microsoft told Windows Latest that there are no such plans.&lt;/p&gt;
    &lt;p&gt;Frank X. Shaw, who is a top-level executive and heads communications for Microsoft, also confirmed to Windows Latest that the company has no plans to rewrite Windows 11 using AI.&lt;/p&gt;
    &lt;p&gt;Galen Hunt, who originally claimed C and C++ are being replaced with Rust using AI, also updated his LinkedIn post with the following clarification:&lt;/p&gt;
    &lt;p&gt;‚ÄúIt appears my post generated far more attention than I intended‚Ä¶ with a lot of speculative reading between the lines.. Just to clarify‚Ä¶ Windows is *NOT* being rewritten in Rust with AI.&lt;/p&gt;
    &lt;p&gt;My team‚Äôs project is a research project. We are building tech to make migration from language to language possible. The intent of my post was to find like-minded engineers to join us on the next stage of this multi-year endeavor‚Äînot to set a new strategy for Windows 11+ or to imply that Rust is an endpoint.‚Äù&lt;/p&gt;
    &lt;p&gt;While Galen Hunt says people were ‚Äúreading between the lines,‚Äù the reaction did not come out of nowhere. His post used very direct language about eliminating C and C++ by 2030 and using AI plus algorithms to rewrite large codebases, along with a ‚Äú1 engineer, 1 month, 1 million lines of code‚Äù line.&lt;/p&gt;
    &lt;p&gt;In fact, the top-level engineer‚Äôs edited post still says his team would have ‚Äú1 engineer, 1 month, 1 million lines of code.‚Äù&lt;/p&gt;
    &lt;p&gt;The original wording is what made it sound broader than a small research effort, but nobody should be against using Rust. In fact, Rust is indeed a better choice and is far more secure. But most of us are concerned about using AI and algorithms to modify code at a large scale.&lt;/p&gt;
    &lt;head rend="h2"&gt;Microsoft has been very vocal about using AI to write code&lt;/head&gt;
    &lt;p&gt;It‚Äôs actually not the first time we‚Äôve heard Microsoft confirming that it intends to use AI to code its own products.&lt;/p&gt;
    &lt;p&gt;CEO Satya Nadella proudly claims that 30% of the company‚Äôs code was written by AI, and numbers are only going to increase from here.&lt;/p&gt;
    &lt;p&gt;‚ÄúI‚Äôd say maybe 20%, 30% of the code that is inside of our repos today and some of our projects are probably all written by software,‚Äù Nadella explained at Meta‚Äôs inaugural LlamaCon AI developer in April 2025.&lt;/p&gt;
    &lt;p&gt;In the same month, Microsoft‚Äôs CTO stated that he expects up to 95% of code to be AI-generated by 2030.&lt;/p&gt;
    &lt;head rend="h2"&gt;Windows 11 has a bigger problem, and it‚Äôs WebView2 or Electron&lt;/head&gt;
    &lt;p&gt;As Windows Latest previously reported, the most popular Windows apps are notorious for consuming a significant amount of RA,M and it‚Äôs largely because of the standards set by Microsoft.&lt;/p&gt;
    &lt;p&gt;For example, Discord admitted that its Windows app can use up to 4GB of RAM in some cases, and when that happens, the company will automatically restart the client. Discord is an Electron-based app, which is actually worse than WebView2.&lt;/p&gt;
    &lt;p&gt;WebView2-based Microsoft Teams consistently uses 1-2GB of RAM while doing nothing. Microsoft likely doesn‚Äôt know how to make these web apps use fewer resources, so it‚Äôs instead moving Teams calling to a separate process to reduce crashes.&lt;/p&gt;
    &lt;p&gt;But Teams is not the only web app causing trouble when RAM prices are about to soar, as we also have WhatsApp. When WhatsApp debuted on Windows, it was an Electron app. However, Meta later upgraded it to WinUI/XAML (also known as native code on Windows), and WhatsApp eventually became one of the best apps.&lt;/p&gt;
    &lt;p&gt;Granted, WhatsApp native was not perfect, but it used less than 200MB of RAM and had smoother animations and faster load times. Unfortunately, Meta disbanded the team behind the native client as part of the layoffs and replaced WhatsApp with a WebView2-based solution, which uses seven times more RAM than the older native client.&lt;/p&gt;
    &lt;p&gt;But if you thought the ‚Äúweb crap‚Äù problem was just isolated to these apps, you are wrong.&lt;/p&gt;
    &lt;p&gt;Windows Latest recently spotted that Microsoft has started building parts of Windows 11 using WebView2. More recently, we observed that an upcoming feature, ‚ÄúAgenda view,‚Äù which allows you to view Outlook Agenda in Notification Center, is built using WebView2.&lt;/p&gt;
    &lt;p&gt;This means you‚Äôll notice new Edge-related processes taking up to 100MB of RAM when you open Notifications Center and Agenda View is enabled.&lt;/p&gt;
    &lt;p&gt;Agenda view support was dropped when Microsoft rolled out Windows 11, and it‚Äôs coming back due to popular demand, but unlike the Windows 10 version, the new Agenda View is web-based.&lt;/p&gt;
    &lt;p&gt;I don‚Äôt think the use of AI is going to make Windows any better. It‚Äôs the intent of the leadership that needs to change, and I doubt that will ever happen.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46381813</guid><pubDate>Thu, 25 Dec 2025 03:26:58 +0000</pubDate></item><item><title>Python Applied Mathematics Labs</title><link>https://labs.acme.byu.edu/Pages/intro.html</link><description>&lt;doc fingerprint="4f84116b0c3fbbfa"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introduction to ACME Labs#&lt;/head&gt;
    &lt;p&gt;The labs on this website are designed to accompany the Foundations of Applied Mathematics textbook series.[1] They provide hands-on experience with key mathematical and computational concepts, connecting theory to practical, real-world applications.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Note for public users: If you are not an enrolled ACME student, please see the Public Use page for information on setup, access, and usage guidelines.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;What You‚Äôll Learn#&lt;/head&gt;
    &lt;head rend="h3"&gt;Core Technical Skills#&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Python libraries: NumPy, SciPy, Matplotlib, pandas, and other scientific packages&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Core mathematical algorithms, numerical methods, and modeling techniques&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Coding best practices, including unit testing and code optimization&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Array broadcasting and efficient numerical computation&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data visualization and analysis techniques&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Real-World Applications#&lt;/head&gt;
    &lt;p&gt;In these labs, you will solve problems such as:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Predicting tsunami landing times using Dijkstra‚Äôs algorithm&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Optimizing meal plans on a budget with linear programming&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Cleaning and filtering sound files using Fourier transforms and convolutions&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Denoising images using matrix decompositions and calculus of variations&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Compressing images with matrix decompositions and wavelets&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Building text generators using Markov chains&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Creating recommendation systems with non-negative matrix factorization&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Creating and training machine learning models using several methods[2]&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Training neural networks&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Using information theory to beat the NYT game Wordle&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Modeling population dynamics with SIR and predator-prey models&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Site Structure#&lt;/head&gt;
    &lt;p&gt;At the top of each page, you‚Äôll find several useful tools:&lt;/p&gt;
    &lt;p&gt;The labs are organized by volume, accessible via the tabs on the left. Each lab volume corresponds to a theory volume in the textbook series. Other key sections include:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Getting Started ‚Äî A roadmap for beginning work on the labs and setting up your computer.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Environment Setup ‚Äî Step-by-step instructions to configure your system for the ACME labs.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Student Resources ‚Äî Tips and guides for ACME students, from code quality to plotting with Matplotlib.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Supplemental Labs ‚Äî Optional labs introducing additional concepts.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;References ‚Äî Sources and references used in lab development.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;ACME Contributors ‚Äî Individuals who have contributed to the development of these materials.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Lab Structure#&lt;/head&gt;
    &lt;p&gt;Each lab is self-contained and includes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Clear learning objectives&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Theoretical background and practical examples&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Exercises to apply what you‚Äôve learned&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Additional materials for deeper exploration&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These labs are designed to bridge the gap between theory and implementation, strengthening both mathematical intuition and programming skills.&lt;/p&gt;
    &lt;head rend="h2"&gt;Personal Projects#&lt;/head&gt;
    &lt;p&gt;The labs are also an excellent springboard for personal projects, which can be valuable for internships or job applications. Projects showcase your initiative, creativity, and technical ability beyond coursework.&lt;/p&gt;
    &lt;p&gt;For example, one student expanded the Markov Chains lab into a Twitter bot called TSwizzlebot.&lt;lb/&gt; Your project can be as creative as you like, just ensure you extend or modify the lab in a way that makes it uniquely yours. It should no longer look like a homework submission, but rather an original project.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46381839</guid><pubDate>Thu, 25 Dec 2025 03:33:52 +0000</pubDate></item></channel></rss>