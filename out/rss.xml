<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 30 Oct 2025 23:09:17 +0000</lastBuildDate><item><title>NPM flooded with malicious packages downloaded more than 86k times</title><link>https://arstechnica.com/security/2025/10/npm-flooded-with-malicious-packages-downloaded-more-than-86000-times/</link><description>&lt;doc fingerprint="771a9388954b799"&gt;
  &lt;main&gt;
    &lt;p&gt;Attackers are exploiting a major weakness that has allowed them access to the NPM code repository with more than 100 credential-stealing packages since August, mostly without detection.&lt;/p&gt;
    &lt;p&gt;The finding, laid out Wednesday by security firm Koi, brings attention to an NPM practice that allows installed packages to automatically pull down and run unvetted packages from untrusted domains. Koi said a campaign it tracks as PhantomRaven has exploited NPM’s use of “Remote Dynamic Dependencies” to flood NPM with 126 malicious packages that have been downloaded more than 86,000 times. Some 80 of those packages remained available as of Wednesday morning, Koi said.&lt;/p&gt;
    &lt;head rend="h2"&gt;A blind spot&lt;/head&gt;
    &lt;p&gt;“PhantomRaven demonstrates how sophisticated attackers are getting [better] at exploiting blind spots in traditional security tooling,” Koi’s Oren Yomtov wrote. “Remote Dynamic Dependencies aren’t visible to static analysis.”&lt;/p&gt;
    &lt;p&gt;Remote Dynamic Dependencies provide greater flexibility in accessing dependencies—the code libraries that are mandatory for many other packages to work. Normally, dependencies are visible to the developer installing the package. They’re usually downloaded from NPM’s trusted infrastructure.&lt;/p&gt;
    &lt;p&gt;RDD works differently. It allows a package to download dependencies from untrusted websites, even those that connect over HTTP, which is unencrypted. The PhantomRaven attackers exploited this leniency by including code in the 126 packages uploaded to NPM. The code downloads malicious dependencies from URLs, including http://packages.storeartifact.com/npm/unused-imports. Koi said these dependencies are “invisible” to developers and many security scanners. Instead, they show the package contains “0 Dependencies.” An NPM feature causes these invisible downloads to be automatically installed.&lt;/p&gt;
    &lt;p&gt;Compounding the weakness, the dependencies are downloaded “fresh” from the attacker server each time a package is installed, rather than being cached, versioned, or otherwise static, as Koi explained:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45755027</guid><pubDate>Thu, 30 Oct 2025 00:37:33 +0000</pubDate></item><item><title>Show HN: In a single HTML file, an app to encourage my children to invest</title><link>https://roberdam.com/en/dinversiones.html</link><description>&lt;doc fingerprint="26c9c0412db7d00b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;I Built an App to Encourage My Kids to Invest â Just One HTML File&lt;/head&gt;
    &lt;p&gt;âWhat comes with the milk, leaves with the soulâ&lt;lb/&gt; â Russian proverb.&lt;/p&gt;
    &lt;p&gt;Access the app:&lt;lb/&gt; Click here to open and install D-i&lt;del&gt;n&lt;/del&gt;vestments&lt;/p&gt;
    &lt;p&gt;One thing that school doesnât teach you (not even high school) is how to manage your personal finances.&lt;/p&gt;
    &lt;p&gt;As my eldest sonâs birthday was approaching, we suggested that instead of asking for physical gifts, he ask for their equivalent in money. That way, he gathered a decent amount of capital for his first investment adventure.&lt;/p&gt;
    &lt;p&gt;I explained to my kids that investing is like having a magic box that generates more money over time. To make it more visual and interactive, I decided to create a small app where they could see their investment grow day by day.&lt;/p&gt;
    &lt;head rend="h1"&gt;From Idea to App&lt;/head&gt;
    &lt;p&gt;My first idea was to build a physical piggy bank with a display, showing the accumulated amount. However, that mixed up the concept of saving with investing, and also required buying extra hardware.&lt;/p&gt;
    &lt;p&gt;So I looked for a quicker, cheaper way: revive an old smartphone and create a simple app using plain HTML.&lt;/p&gt;
    &lt;p&gt;The result was D-i&lt;del&gt;n&lt;/del&gt;vestments, a mix between Diversions and Investments.&lt;/p&gt;
    &lt;head rend="h1"&gt;How It Works&lt;/head&gt;
    &lt;p&gt;The app is essentially a single HTML file that installs on the phone as a PWA (Progressive Web App).&lt;/p&gt;
    &lt;p&gt;The phone is attached to the fridge and works as a panel or dashboard where my kids can see their money growing each day.&lt;/p&gt;
    &lt;p&gt;I act as their investment agent, assigning realistic interest rates â high enough to keep them motivated, but moderate enough to reflect how the real world works.&lt;/p&gt;
    &lt;head rend="h2"&gt;Configuration Screen&lt;/head&gt;
    &lt;p&gt;The app includes a screen where you can enter:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The kidsâ names&lt;/item&gt;
      &lt;item&gt;The invested amount&lt;/item&gt;
      &lt;item&gt;The interest rate&lt;/item&gt;
      &lt;item&gt;The start date&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With that data, the app automatically calculates and displays:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Daily gain&lt;/item&gt;
      &lt;item&gt;Weekly gain&lt;/item&gt;
      &lt;item&gt;Monthly gain&lt;/item&gt;
      &lt;item&gt;Total updated balance&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Materials Used&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;An old smartphone&lt;/item&gt;
      &lt;item&gt;A suction mount to attach it to the fridge&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The D-iNvestments app, in HTML format&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Installation&lt;/head&gt;
    &lt;p&gt;The process is as simple as opening the link from a smartphone and tapping âInstallâ when prompted by the browser.&lt;lb/&gt; From then on, it behaves like a native app.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Access the app:&lt;/p&gt;&lt;lb/&gt;Click here to open and install D-i&lt;del&gt;n&lt;/del&gt;vestments&lt;/quote&gt;
    &lt;head rend="h1"&gt;Final Reflection&lt;/head&gt;
    &lt;p&gt;The goal wasnât just to teach my kids the value of money, but to show them visually how investment and time work as allies.&lt;/p&gt;
    &lt;p&gt;Each day, as they watch their small fund grow, they grasp the magic of compound interest â and that, more than any gift, is a lesson I hope will stay with them for life.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;ð¬ Want to comment or improve the app? Contact me at:&lt;/p&gt;&lt;lb/&gt;@roberdam&lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45758421</guid><pubDate>Thu, 30 Oct 2025 10:39:21 +0000</pubDate></item><item><title>Jujutsu at Google [video]</title><link>https://www.youtube.com/watch?v=v9Ob5yPpC0A</link><description>&lt;doc fingerprint="7055905545553646"&gt;
  &lt;main&gt;
    &lt;p&gt;About Press Copyright Contact us Creators Advertise Developers Terms Privacy Policy &amp;amp; Safety How YouTube works Test new features NFL Sunday Ticket © 2025 Google LLC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45759572</guid><pubDate>Thu, 30 Oct 2025 13:00:58 +0000</pubDate></item><item><title>Show HN: I made a heatmap diff viewer for code reviews</title><link>https://0github.com</link><description>&lt;doc fingerprint="5f30552b55a047fe"&gt;
  &lt;main&gt;
    &lt;p&gt;Heatmap color-codes every diff line/token by how much human attention it probably needs. Unlike PR-review bots, we try to flag not just by “is it a bug?” but by “is it worth a second look?” (examples: hard-coded secret, weird crypto mode, gnarly logic).&lt;/p&gt;
    &lt;p&gt;To try it, replace github.com with 0github.com in any GitHub pull request url. Under the hood, we clone the repo into a VM, spin up gpt-5-codex for every diff, and ask it to output a JSON data structure that we parse into a colored heatmap.&lt;/p&gt;
    &lt;p&gt;Examples:&lt;/p&gt;
    &lt;p&gt;Heatmap is open source:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45760321</guid><pubDate>Thu, 30 Oct 2025 14:21:58 +0000</pubDate></item><item><title>US declines to join more than 70 countries in signing UN cybercrime treaty</title><link>https://therecord.media/us-declines-signing-cybercrime-treaty?</link><description>&lt;doc fingerprint="8b0db7af9a95f28f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;US declines to join more than 70 countries in signing UN cybercrime treaty&lt;/head&gt;
    &lt;p&gt;More than 70 countries signed the landmark U.N. Convention against Cybercrime in Hanoi this weekend, a significant step in the yearslong effort to create a global mechanism to counteract digital crime.&lt;/p&gt;
    &lt;p&gt;The U.K. and European Union joined China, Russia, Brazil, Nigeria and dozens of other nations in signing the convention, which lays out new mechanisms for governments to coordinate, build capacity and track those who use technology to commit crimes.&lt;/p&gt;
    &lt;p&gt;In his speech at the event, U.N. Secretary-General António Guterres said cyberspace “has become fertile ground for criminals” and has allowed them to “defraud families, steal livelihoods, and drain billions of dollars from our economies.”&lt;/p&gt;
    &lt;p&gt;“The UN Cybercrime Convention is a powerful, legally binding instrument to strengthen our collective defences against cybercrime,” Guterres said.&lt;/p&gt;
    &lt;p&gt;“Illicit flows of money, concealed through cryptocurrencies and digital transactions, finance the trafficking of drugs, arms, and terror. And businesses, hospitals, and airports are brought to a standstill by ransomware attacks.”&lt;/p&gt;
    &lt;p&gt;He added that the convention would be critical for governments in the Global South that need assistance and funding for the training required to address cybercrime — which the U.N. estimates costs $10.5 trillion around the world annually.&lt;/p&gt;
    &lt;p&gt;While many countries did not sign the treaty, the most notable missing signature was that of the U.S.&lt;/p&gt;
    &lt;p&gt;Officials at the State Department told Recorded Future News on Friday that Marc Knapper, the U.S. ambassador to Vietnam, and representatives from the U.S. Mission to Vietnam would be attending the signing.&lt;/p&gt;
    &lt;p&gt;The State Department confirmed on Monday that the U.S. did not sign the treaty.&lt;/p&gt;
    &lt;p&gt;“The United States continues to review the treaty,” a State Department spokesperson said in a brief statement.&lt;/p&gt;
    &lt;p&gt;The U.N. Convention against Cybercrime was adopted by the General Assembly in December 2024 and will enter into force 90 days after being ratified by the 40th signatory. Signatories will have to ratify the convention according to their own procedures.&lt;/p&gt;
    &lt;p&gt;At the ceremony, UNODC Executive Director Ghada Waly argued that cybercrime is changing the face of organized crime and required global coordination to address. Waly said the convention would be a “vital tool” that will ensure “a safer digital world for all.”&lt;/p&gt;
    &lt;p&gt;U.N. officials said the convention would help governments address terrorism, human trafficking, money laundering and drug smuggling, all of which have been turbo-charged by the internet.&lt;/p&gt;
    &lt;p&gt;The U.N. noted that the convention is the first global framework “for the collection, sharing and use of electronic evidence for all serious offenses” — noting that until now there have been no broadly accepted international standards on electronic evidence.&lt;/p&gt;
    &lt;p&gt;It is also the first global treaty to criminalize crimes that depend on the internet and is the first international treaty “to recognize the non-consensual dissemination of intimate images as an offense.”&lt;/p&gt;
    &lt;p&gt;“It creates the first global 24/7 network where countries can quickly initiate cooperation,” the U.N. said. “It recognizes and promotes the need to build capacity in countries to pursue and cooperate on fast-moving cybercrimes.”&lt;/p&gt;
    &lt;p&gt;The convention has been heavily criticized by the tech industry, which has warned that it criminalizes cybersecurity research and exposes companies to legally thorny data requests.&lt;/p&gt;
    &lt;p&gt;Human rights groups warned on Friday that it effectively forces member states to create a broad electronic surveillance dragnet that would include crimes that have nothing to do with technology.&lt;/p&gt;
    &lt;p&gt;Many expressed concern that the convention will be abused by dictatorships and rogue governments who will deploy it against critics or protesters — even those outside of a regime’s jurisdiction.&lt;/p&gt;
    &lt;p&gt;It also creates legal regimes to monitor, store and allow cross-border sharing of information without specific data protections. Access Now’s Raman Jit Singh Chima said the convention effectively justifies “cyber authoritarianism at home and transnational repression across borders.”&lt;/p&gt;
    &lt;p&gt;Any countries ratifying the treaty, he added, risks “actively validating cyber authoritarianism and facilitating the global erosion of digital freedoms, choosing procedural consensus over substantive human rights protection.”&lt;/p&gt;
    &lt;p&gt;In his speech, Guterres referenced the backlash to the convention, telling member states that the treaty has to be a “promise that fundamental human rights such as privacy, dignity, and safety must be protected both offline and online.”&lt;/p&gt;
    &lt;p&gt;But at its core, according to Guterres, the convention solves one of the thorniest issues law enforcement agencies have faced over the last two decades. Countries have only recently begun to share digital evidence across borders but the convention would increase that practice.&lt;/p&gt;
    &lt;p&gt;“This has long been a major obstacle to justice — with perpetrators in one country, victims in another, and data stored in a third,” he said. “The Convention provides a clear pathway for investigators and prosecutors to finally overcome this barrier.”&lt;/p&gt;
    &lt;p&gt;Jonathan Greig&lt;/p&gt;
    &lt;p&gt;is a Breaking News Reporter at Recorded Future News. Jonathan has worked across the globe as a journalist since 2014. Before moving back to New York City, he worked for news outlets in South Africa, Jordan and Cambodia. He previously covered cybersecurity at ZDNet and TechRepublic.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45760328</guid><pubDate>Thu, 30 Oct 2025 14:22:44 +0000</pubDate></item><item><title>Free software scares normal people</title><link>https://danieldelaney.net/normal/</link><description>&lt;doc fingerprint="a23b437c2441cdbd"&gt;
  &lt;main&gt;
    &lt;p&gt;I’m the person my friends and family come to for computer-related help. (Maybe you, gentle reader, can relate.) This experience has taught me which computing tasks are frustrating for normal people.&lt;/p&gt;
    &lt;p&gt;Normal people often struggle with converting video. They will need to watch, upload, or otherwise do stuff with a video, but the format will be weird. (Weird, broadly defined, is anything that won’t play in QuickTime or upload to Facebook.)&lt;/p&gt;
    &lt;p&gt;I would love to recommend Handbrake to them, but the user interface is by and for power users. Opening it makes normal people feel unpleasant feelings.&lt;/p&gt;
    &lt;p&gt;This problem is rampant in free software. The FOSS world is full of powerful tools that only have a “power user” UI. As a result, people give up. Or worse: they ask people like you and I to do it for them.&lt;/p&gt;
    &lt;p&gt;I want to make the case to you that you can (and should) solve this kind of problem in a single evening.&lt;/p&gt;
    &lt;p&gt;Take the example of Magicbrake, a simple front end I built. It hides the power and flexibility of Handbrake. It does only the one thing most people need Handbrake for: taking a weird video file and making it normal. (Normal, for our purposes, means a small MP4 that works just about anywhere.)&lt;/p&gt;
    &lt;p&gt;There is exactly one button.&lt;/p&gt;
    &lt;p&gt;This is a fast and uncomplicated thing to do. Unfortunately, the people who have the ability to solve problems like this are often disinclined to do it.&lt;/p&gt;
    &lt;p&gt;“Why would you make Handbrake less powerful on purpose?”&lt;/p&gt;
    &lt;p&gt;“What if someone wants a different format?”&lt;/p&gt;
    &lt;p&gt;“What about [feature/edge case]?”&lt;/p&gt;
    &lt;p&gt;The answer to all these questions is the same: a person who needs or wants that stuff can use Handbrake. If they don’t need everything Handbrake can do and find it bewildering, they can use this. Everyone wins.&lt;/p&gt;
    &lt;p&gt;It’s a bit like obscuring the less-used functions on a TV remote with tape. The functions still exist if you need them, but you’re not required to contend with them just to turn the TV on.&lt;/p&gt;
    &lt;p&gt;People benefit from stuff like this, and I challenge you to make more of it. Opportunities are everywhere. The world is full of media servers normal people can’t set up. Free audio editing software that requires hours of learning to be useful for simple tasks. Network monitoring tools that seem designed to ward off the uninitiated. Great stuff normal people don’t use. All because there’s only one UI, and it’s designed to do everything.&lt;/p&gt;
    &lt;p&gt;80% of the people only need 20% of the features. Hide the rest from them and you’ll make them more productive and happy. That’s really all it takes.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45760878</guid><pubDate>Thu, 30 Oct 2025 15:07:15 +0000</pubDate></item><item><title>PlanetScale Offering $5 Databases</title><link>https://planetscale.com/blog/5-dollar-planetscale</link><description>&lt;doc fingerprint="27dfe46f2515530c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;$5 PlanetScale&lt;/head&gt;
    &lt;p&gt;By Sam Lambert |&lt;/p&gt;
    &lt;p&gt;PlanetScale is synonymous with quality, performance, and reliability. Up until now, the entry level PlanetScale cluster configuration was 3 node, multi-AZ, and highly available. At $30 a month this is incredible value, however, not everyone wants or needs HA.&lt;/p&gt;
    &lt;p&gt;Every day we get requests for an entry level tier that is more accessible to builders on day 1. People want the quality of PlanetScale and our game changing features like Insights without the cost overhead of 3 nodes.&lt;/p&gt;
    &lt;p&gt;Over the next couple of months we will be rolling out a single node, non-HA mode for PlanetScale Postgres and introducing a new node type: The &lt;code&gt;PS-5&lt;/code&gt; which is priced at $5 a month. Single node is perfect for development, testing, and non-critical workloads. Customers will be able to vertically scale a single node to meet their needs without having to add replicas or sacrifice durability.&lt;/p&gt;
    &lt;p&gt;You can sign up here to be notified when single node releases.&lt;/p&gt;
    &lt;p&gt;Our starter pricing is now:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Node Class&lt;/cell&gt;
        &lt;cell role="head"&gt;Mode&lt;/cell&gt;
        &lt;cell role="head"&gt;Price&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;PS-5 (arm and intel)&lt;/cell&gt;
        &lt;cell&gt;Single node&lt;/cell&gt;
        &lt;cell&gt;$5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;PS-10 (arm)&lt;/cell&gt;
        &lt;cell&gt;Single node&lt;/cell&gt;
        &lt;cell&gt;$10&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;PS-10 (intel)&lt;/cell&gt;
        &lt;cell&gt;Single node&lt;/cell&gt;
        &lt;cell&gt;$13&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;PS-10 (arm)&lt;/cell&gt;
        &lt;cell&gt;HA (3 node)&lt;/cell&gt;
        &lt;cell&gt;$30&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;PS-10 (intel)&lt;/cell&gt;
        &lt;cell&gt;HA (3 node)&lt;/cell&gt;
        &lt;cell&gt;$39&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;If you're bullish on your company's future, you know you'll need to scale eventually, and the database is usually the first bottleneck. We talk to startups daily who experienced unexpected fast growth and have to scramble through emergency migrations to PlanetScale to handle the load, a stressful process when you're in the spotlight. With more approachable pricing from day 1, you can now start small and grow to hyper scale without ever changing your database platform or dealing with a complex migration.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45761027</guid><pubDate>Thu, 30 Oct 2025 15:20:37 +0000</pubDate></item><item><title>ZOZO's Contact Solver for physics-based simulations</title><link>https://github.com/st-tech/ppf-contact-solver</link><description>&lt;doc fingerprint="3d32dd780db6c590"&gt;
  &lt;main&gt;&lt;p&gt;A contact solver for physics-based simulations involving 👚 shells, 🪵 solids and 🪢 rods. All made by ZOZO.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;💪 Robust: Contact resolutions are completely penetration-free. No snagging intersections.&lt;/item&gt;&lt;item&gt;⏲ Scalable: An extreme case includes beyond 150M contacts. Not just one million.&lt;/item&gt;&lt;item&gt;🚲 Cache Efficient: All on the GPU runs in single precision. No double precision.&lt;/item&gt;&lt;item&gt;🥼 Inextensible: Cloth never extends beyond very strict upper bounds, such as 1%.&lt;/item&gt;&lt;item&gt;📐 Physically Accurate: Our deformable solver is driven by the Finite Element Method.&lt;/item&gt;&lt;item&gt;⚔️ Highly Stressed: We run GitHub Actions to run stress tests 10 times in a row.&lt;/item&gt;&lt;item&gt;🚀 Massively Parallel: Both contact and elasticity solvers are run on the GPU.&lt;/item&gt;&lt;item&gt;🐳 Docker Sealed: Everything is designed to work out of the box.&lt;/item&gt;&lt;item&gt;🌐 JupyterLab Included: Open your browser and run examples right away (Video).&lt;/item&gt;&lt;item&gt;🐍 Documented Python APIs: Our Python code is fully docstringed and lintable (Video).&lt;/item&gt;&lt;item&gt;☁️ Cloud-Ready: Our solver can be seamlessly deployed on major cloud platforms.&lt;/item&gt;&lt;item&gt;✨ Stay Clean: You can remove all traces after use.&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;📝 Change History&lt;/item&gt;&lt;item&gt;🎓 Technical Materials&lt;/item&gt;&lt;item&gt;⚡️ Requirements&lt;/item&gt;&lt;item&gt;💨 Getting Started&lt;/item&gt;&lt;item&gt;🐍 How To Use&lt;/item&gt;&lt;item&gt;📚 Python APIs and Parameters&lt;/item&gt;&lt;item&gt;🔍 Obtaining Logs&lt;/item&gt;&lt;item&gt;🖼️ Catalogue&lt;/item&gt;&lt;item&gt;🚀 GitHub Actions&lt;/item&gt;&lt;item&gt;📡 Deploying on Cloud Services&lt;/item&gt;&lt;item&gt;✒️ Citation&lt;/item&gt;&lt;item&gt;🙏 Acknowledgements&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;🧑 💻 Setting Up Your Development Environment (Markdown)&lt;/item&gt;&lt;item&gt;🐞 Bug Fixes and Updates (Markdown)&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;(2025.10.03) Massive refactor of the codebase (Markdown). Note that this change includes breaking changes to our Python APIs.&lt;/item&gt;&lt;item&gt;(2025.08.09) Added a hindsight note in eigensystem analysis to acknowledge prior work by Poya et al. (2023).&lt;/item&gt;&lt;item&gt;(2025.05.01) Simulation states now can be saved and loaded (Video).&lt;/item&gt;&lt;item&gt;(2025.04.02) Added 9 examples. See the catalogue.&lt;/item&gt;&lt;item&gt;(2025.03.03) Added a budget table on AWS.&lt;/item&gt;&lt;item&gt;(2025.02.28) Added a reference branch and a Docker image of our TOG paper.&lt;/item&gt;&lt;item&gt;(2025.2.26) Added Floating Point-Rounding Errors in ACCD in hindsight.&lt;/item&gt;&lt;item&gt;(2025.2.7) Updated the trapped example (Video) with squishy balls.&lt;/item&gt;&lt;/list&gt;&lt;head&gt;More history records&lt;/head&gt;- (2025.1.8) Added a [domino example](./examples/domino.ipynb) [(Video)](https://drive.google.com/file/d/1N9y8eZrjSQhAUhKwiO9w8jW_T18zPnYf/view). - (2025.1.5) Added a [single twist example](./examples/twist.ipynb) [(Video)](https://drive.google.com/file/d/1LDFKS-iBvl2uDdPVKaazQL25tYGEEyXr/view). - (2024.12.31) Added full documentation for Python APIs, parameters, and log files [(GitHub Pages)](https://st-tech.github.io/ppf-contact-solver). - (2024.12.27) Line search for strain limiting is improved [(Markdown)](./articles/bug.md#new-strain-limiting-line-search) - (2024.12.23) Added [(Bug Fixes and Updates)](./articles/bug.md) - (2024.12.21) Added a [house of cards example](./examples/cards.ipynb) [(Video)](https://drive.google.com/file/d/1PMdDnlyCsjinbvICKph_0UcXUfUvvUmZ/view) - (2024.12.18) Added a [frictional contact example](./examples/friction.ipynb): armadillo sliding on the slope [(Video)](https://drive.google.com/file/d/12WGdfDTFIwCT0UFGEZzfmQreM6WSSHet/view) - (2024.12.18) Added a [hindsight](./articles/hindsight.md) noting that the tilt angle was not&lt;list rend="ul"&gt;&lt;item&gt;📚 Published in ACM Transactions on Graphics (TOG) Vol.43, No.6&lt;/item&gt;&lt;item&gt;🎥 Main video (Video)&lt;/item&gt;&lt;item&gt;🎥 Additional video examples (Directory)&lt;/item&gt;&lt;item&gt;🎥 Presentation videos (Short) (Long)&lt;/item&gt;&lt;item&gt;📃 Main paper (PDF) (Hindsight)&lt;/item&gt;&lt;item&gt;📊 Supplementary PDF (PDF)&lt;/item&gt;&lt;item&gt;🤖 Supplementary scripts (Directory)&lt;/item&gt;&lt;item&gt;🔍 Singular-value eigenanalysis (Markdown)&lt;/item&gt;&lt;/list&gt;&lt;p&gt;The main branch is undergoing frequent updates and will deviate from the paper 🚧. To retain consistency with the paper, we have created a new branch &lt;code&gt;sigasia-2024&lt;/code&gt;.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;🛠️ Only maintenance updates are planned for this branch.&lt;/item&gt;&lt;item&gt;🚫 General users should not use this branch as it is not optimized for best performance.&lt;/item&gt;&lt;item&gt;🚫 All algorithmic changes listed in this (Markdown) are excluded from this branch.&lt;/item&gt;&lt;item&gt;📦 We also provide a pre-compiled Docker image: &lt;code&gt;ghcr.io/st-tech/ppf-contact-solver-compiled-sigasia-2024:latest&lt;/code&gt;of this branch.&lt;/item&gt;&lt;item&gt;🌐 Template Link for vast.ai&lt;/item&gt;&lt;item&gt;🌐 Template Link for RunPods&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;🔥 A modern NVIDIA GPU (CUDA 12.8 or newer)&lt;/item&gt;&lt;item&gt;🐳 A Docker environment (see below)&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Install a 🎮 NVIDIA driver (Link) on your 💻 host system and follow the 📝 instructions below specific to the 🖥️ operating system to get a 🐳 Docker running:&lt;/p&gt;&lt;table&gt;&lt;row span="2"&gt;&lt;cell role="head"&gt;🐧 Linux&lt;/cell&gt;&lt;cell role="head"&gt;🪟 Windows&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Install the Docker engine from here (Link). Also, install the NVIDIA Container Toolkit (Link). Just to make sure that the Container Toolkit is loaded, run &lt;code&gt;sudo service docker restart&lt;/code&gt;.&lt;/cell&gt;&lt;cell&gt;Install the Docker Desktop (Link). You may need to log out or reboot after the installation. After logging back in, launch Docker Desktop to ensure that Docker is running.&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;Next, run the following command to start the 📦 container:&lt;/p&gt;&lt;code&gt;$MY_WEB_PORT = 8080  # Web port number for web interface
$IMAGE_NAME = "ghcr.io/st-tech/ppf-contact-solver-compiled:latest"
docker run --rm --gpus all -p ${MY_WEB_PORT}:8080 $IMAGE_NAME&lt;/code&gt;&lt;code&gt;MY_WEB_PORT=8080  # Web port number for web interface
IMAGE_NAME=ghcr.io/st-tech/ppf-contact-solver-compiled:latest
docker run --rm --gpus all -p ${MY_WEB_PORT}:8080 $IMAGE_NAME&lt;/code&gt;&lt;p&gt;⏳ Wait for a while until the container becomes a steady state. Next, open your 🌐 browser and navigate to http://localhost:8080, where &lt;code&gt;8080&lt;/code&gt; is the port number specified in the &lt;code&gt;MY_WEB_PORT&lt;/code&gt; variable.
Keep your terminal window open.&lt;/p&gt;&lt;p&gt;🎉 Now you are ready to go! 🚀&lt;/p&gt;&lt;p&gt;To shut down the container, just press &lt;code&gt;Ctrl+C&lt;/code&gt; in the terminal.
The container will be removed and all traces will be 🧹 cleaned up.&lt;/p&gt;&lt;p&gt;If you wish to build the container from scratch 🛠️, please refer to the cleaner installation guide (Markdown) 📝.&lt;/p&gt;&lt;p&gt;Our frontend is accessible through 🌐 a browser using our built-in JupyterLab 🐍 interface. All is set up when you open it for the first time. Results can be interactively viewed through the browser and exported as needed.&lt;/p&gt;&lt;p&gt;This allows you to interact with the simulator on your 💻 laptop while the actual simulation runs on a remote headless server over 🌍 the internet. This means that you don't have to own ⚙️ NVIDIA hardware, but can rent it at vast.ai or RunPod for less than 💵 $0.5 per hour. For example, this (Video) was recorded on a vast.ai instance. The experience is 👍 good!&lt;/p&gt;&lt;p&gt;Our Python interface is designed with the following principles in mind:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;🛠️ Dynamic Tri/Tet Creation: Relying on non-integrated third-party tools for triangulation, tetrahedralization, and loading can make it difficult to dynamically adjust resolutions. Our built-in tri/tet creation tools eliminate this limitation.&lt;/item&gt;&lt;item&gt;🚫 No Mesh Data: Preparing mesh data using external tools can be cumbersome. Our frontend minimizes this effort by allowing meshes to be created on the fly or downloaded when needed.&lt;/item&gt;&lt;item&gt;🔗 Method Chaining: We adopt the method chaining style from JavaScript, making the API intuitive and easy to understand.&lt;/item&gt;&lt;item&gt;📦 Single Import for Everything: All frontend features are accessible by simply importing with &lt;code&gt;from frontend import App&lt;/code&gt;.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Here's an example of draping five sheets over a sphere with two corners pinned. Please look into the examples directory for more examples.&lt;/p&gt;&lt;code&gt;# import our frontend
from frontend import App

# make an app
app = App.create("drape")

# create a square mesh resolution 128 spanning the xz plane
V, F = app.mesh.square(res=128, ex=[1, 0, 0], ey=[0, 0, 1])

# add to the asset and name it "sheet"
app.asset.add.tri("sheet", V, F)

# create an icosphere mesh radius 0.5
V, F = app.mesh.icosphere(r=0.5, subdiv_count=4)

# add to the asset and name it "sphere"
app.asset.add.tri("sphere", V, F)

# create a scene
scene = app.scene.create()

# define gap between sheets
gap = 0.01

for i in range(5):

    # add the sheet asset to the scene
    obj = scene.add("sheet")

    # pick two corners
    corner = obj.grab([1, 0, -1]) + obj.grab([-1, 0, -1])

    # place it with an vertical offset and pin the corners
    obj.at(0, gap * i, 0).pin(corner)

    # set fiber directions required for Baraff-Witkin
    obj.direction([1, 0, 0], [0, 0, 1])

    # set the strainlimiting of 5%
    obj.param.set("strain-limit", 0.05)

# add a sphere mesh at a lower position with jitter and set it static collider
scene.add("sphere").at(0, -0.5 - gap, 0).jitter().pin()

# compile the scene and report stats
scene = scene.build().report()

# preview the initial scene
scene.preview()

# create a new session with the compiled scene
session = app.session.create(scene)

# set session params
session.param.set("frames", 100).set("dt", 0.01)

# build this session
session = session.build()

# start the simulation and live-preview the results (image right)
session.start().preview()

# also show streaming logs
session.stream()

# or interactively view the animation sequences
session.animate()

# export all simulated frames
session.export.animation()&lt;/code&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;Full API documentation 📖 is available on our GitHub Pages. The major APIs are documented using docstrings ✍️ and compiled with Sphinx ⚙️. We have also included&lt;/p&gt;&lt;code&gt;jupyter-lsp&lt;/code&gt;to provide interactive linting assistance 🛠️ and display docstrings as you type. See this video (Video) for an example. The behaviors can be changed through the settings.&lt;/item&gt;&lt;item&gt;&lt;p&gt;A list of parameters used in&lt;/p&gt;&lt;code&gt;param.set(key,value)&lt;/code&gt;is documented here: (Global Parameters) (Object Parameters).&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Note&lt;/p&gt;&lt;p&gt;📊 Logs for the simulation can also be queried through the Python APIs 🐍. Here's an example of how to get a list of recorded logs 📝, fetch them 📥, and compute the average 🧮.&lt;/p&gt;&lt;code&gt;# get a list of log names
logs = session.get.log.names()
print(logs)
assert "time-per-frame" in logs
assert "newton-steps" in logs

# get a list of time per video frame
msec_per_video = session.get.log.numbers("time-per-frame")

# compute the average time per video frame
print("avg per frame:", sum([n for _, n in msec_per_video]) / len(msec_per_video))

# get a list of newton steps
newton_steps = session.get.log.numbers("newton-steps")

# compute the average of consumed newton steps
print("avg newton steps:", sum([n for _, n in newton_steps]) / len(newton_steps))

# Last 8 lines. Omit for everything.
print("==== log stream ====")
for line in session.get.log.stdout(n_lines=8):
    print(line)&lt;/code&gt;&lt;p&gt;Below are some representatives. &lt;code&gt;vid_time&lt;/code&gt; refers to the video time in seconds and is recorded as &lt;code&gt;float&lt;/code&gt;.
&lt;code&gt;ms&lt;/code&gt; refers to the consumed simulation time in milliseconds recorded as &lt;code&gt;int&lt;/code&gt;.
&lt;code&gt;vid_frame&lt;/code&gt; is the video frame count recorede as &lt;code&gt;int&lt;/code&gt;.&lt;/p&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell role="head"&gt;Name&lt;/cell&gt;&lt;cell role="head"&gt;Description&lt;/cell&gt;&lt;cell role="head"&gt;Format&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;time-per-frame&lt;/cell&gt;&lt;cell&gt;Time per video frame&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;list[(vid_frame,ms)]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;matrix-assembly&lt;/cell&gt;&lt;cell&gt;Matrix assembly time&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;list[(vid_time,ms)]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;pcg-linsolve&lt;/cell&gt;&lt;cell&gt;Linear system solve time&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;list[(vid_time,ms)]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;line-search&lt;/cell&gt;&lt;cell&gt;Line search time&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;list[(vid_time,ms)]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;time-per-step&lt;/cell&gt;&lt;cell&gt;Time per step&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;list[(vid_time,ms)]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;newton-steps&lt;/cell&gt;&lt;cell&gt;Newton iterations per step&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;list[(vid_time,count)]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;num-contact&lt;/cell&gt;&lt;cell&gt;Contact count&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;list[(vid_time,count)]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;max-sigma&lt;/cell&gt;&lt;cell&gt;Max stretch&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;list(vid_time,float)&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;The full list of log names and their descriptions is documented here: (GitHub Pages).&lt;/p&gt;&lt;p&gt;Note that some entries have multiple records at the same video time ⏱️. This occurs because the same operation is executed multiple times 🔄 within a single step during the inner Newton's iterations 🧮. For example, the linear system solve is performed at each Newton's step, so if multiple Newton's steps are 🔁 executed, multiple linear system solve times appear in the record at the same 📊 video time.&lt;/p&gt;&lt;p&gt;If you would like to retrieve the raw log stream, you can do so by&lt;/p&gt;&lt;code&gt;# Last 8 lines. Omit for everything.
for line in session.get.log.stdout(n_lines=8):
    print(line)&lt;/code&gt;&lt;p&gt;This will output something like:&lt;/p&gt;&lt;code&gt;* dt: 1.000e-03
* max_sigma: 1.045e+00
* avg_sigma: 1.030e+00
------ newton step 1 ------
   ====== contact_matrix_assembly ======
   &amp;gt; dry_pass...0 msec
   &amp;gt; rebuild...7 msec
   &amp;gt; fillin_pass...0 msec
&lt;/code&gt;&lt;p&gt;If you would like to read &lt;code&gt;stderr&lt;/code&gt;, you can do so using &lt;code&gt;session.get.stderr()&lt;/code&gt; (if it exists). They return &lt;code&gt;list[str]&lt;/code&gt;.
All the log files 📂 are available ✅ and can be fetched ⬇️ during the simulation 💻.&lt;/p&gt;&lt;p&gt;Below is a table summarizing the estimated costs for running our examples on a NVIDIA L4 instance &lt;code&gt;g6.2xlarge&lt;/code&gt; at Amazon Web Services US regions (&lt;code&gt;us-east-1&lt;/code&gt; and &lt;code&gt;us-east-2&lt;/code&gt;).&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;💰 Uptime cost is approximately $1 per hour.&lt;/item&gt;&lt;item&gt;⏳ Deployment time is approximately 8 minutes ($0.13). Instance loading takes 3 minutes, and Docker pull &amp;amp; load takes 5 minutes.&lt;/item&gt;&lt;item&gt;🎮 The NVIDIA L4 delivers 30.3 TFLOPS for FP32, offering approximately 36% of the performance of an RTX 4090.&lt;/item&gt;&lt;item&gt;🎥 Video frame rate is 60fps.&lt;/item&gt;&lt;/list&gt;&lt;table&gt;&lt;row span="9"&gt;&lt;cell role="head"&gt;Example&lt;/cell&gt;&lt;cell role="head"&gt;Cost&lt;/cell&gt;&lt;cell role="head"&gt;Time&lt;/cell&gt;&lt;cell role="head"&gt;#Frame&lt;/cell&gt;&lt;cell role="head"&gt;#Vert&lt;/cell&gt;&lt;cell role="head"&gt;#Face&lt;/cell&gt;&lt;cell role="head"&gt;#Tet&lt;/cell&gt;&lt;cell role="head"&gt;#Seg&lt;/cell&gt;&lt;cell role="head"&gt;Max Strain&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;trapped&lt;/cell&gt;&lt;cell&gt;$0.37&lt;/cell&gt;&lt;cell&gt;22.6m&lt;/cell&gt;&lt;cell&gt;300&lt;/cell&gt;&lt;cell&gt;263K&lt;/cell&gt;&lt;cell&gt;299K&lt;/cell&gt;&lt;cell&gt;885K&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;twist&lt;/cell&gt;&lt;cell&gt;$0.91&lt;/cell&gt;&lt;cell&gt;55m&lt;/cell&gt;&lt;cell&gt;500&lt;/cell&gt;&lt;cell&gt;203K&lt;/cell&gt;&lt;cell&gt;406K&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;stack&lt;/cell&gt;&lt;cell&gt;$0.60&lt;/cell&gt;&lt;cell&gt;36.2m&lt;/cell&gt;&lt;cell&gt;120&lt;/cell&gt;&lt;cell&gt;166.7K&lt;/cell&gt;&lt;cell&gt;327.7K&lt;/cell&gt;&lt;cell&gt;8.8K&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;5%&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;trampoline&lt;/cell&gt;&lt;cell&gt;$0.74&lt;/cell&gt;&lt;cell&gt;44.5m&lt;/cell&gt;&lt;cell&gt;120&lt;/cell&gt;&lt;cell&gt;56.8K&lt;/cell&gt;&lt;cell&gt;62.2K&lt;/cell&gt;&lt;cell&gt;158.0K&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;1%&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;needle&lt;/cell&gt;&lt;cell&gt;$0.31&lt;/cell&gt;&lt;cell&gt;18.4m&lt;/cell&gt;&lt;cell&gt;120&lt;/cell&gt;&lt;cell&gt;86K&lt;/cell&gt;&lt;cell&gt;168.9K&lt;/cell&gt;&lt;cell&gt;8.8K&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;5%&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;cards&lt;/cell&gt;&lt;cell&gt;$0.29&lt;/cell&gt;&lt;cell&gt;17.5m&lt;/cell&gt;&lt;cell&gt;300&lt;/cell&gt;&lt;cell&gt;8.7K&lt;/cell&gt;&lt;cell&gt;13.8K&lt;/cell&gt;&lt;cell&gt;1.9K&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;5%&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;domino&lt;/cell&gt;&lt;cell&gt;$0.12&lt;/cell&gt;&lt;cell&gt;4.3m&lt;/cell&gt;&lt;cell&gt;250&lt;/cell&gt;&lt;cell&gt;0.5K&lt;/cell&gt;&lt;cell&gt;0.8K&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;drape&lt;/cell&gt;&lt;cell&gt;$0.10&lt;/cell&gt;&lt;cell&gt;3.5m&lt;/cell&gt;&lt;cell&gt;100&lt;/cell&gt;&lt;cell&gt;81.9K&lt;/cell&gt;&lt;cell&gt;161.3K&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;5%&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;curtain&lt;/cell&gt;&lt;cell&gt;$0.33&lt;/cell&gt;&lt;cell&gt;19.6m&lt;/cell&gt;&lt;cell&gt;300&lt;/cell&gt;&lt;cell&gt;64K&lt;/cell&gt;&lt;cell&gt;124K&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;5%&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;friction&lt;/cell&gt;&lt;cell&gt;$0.17&lt;/cell&gt;&lt;cell&gt;10m&lt;/cell&gt;&lt;cell&gt;700&lt;/cell&gt;&lt;cell&gt;1.1K&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;1K&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;hang&lt;/cell&gt;&lt;cell&gt;$0.12&lt;/cell&gt;&lt;cell&gt;7.5m&lt;/cell&gt;&lt;cell&gt;200&lt;/cell&gt;&lt;cell&gt;16.3K&lt;/cell&gt;&lt;cell&gt;32.2K&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;1%&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;belt&lt;/cell&gt;&lt;cell&gt;$0.19&lt;/cell&gt;&lt;cell&gt;11.4m&lt;/cell&gt;&lt;cell&gt;200&lt;/cell&gt;&lt;cell&gt;12.3K&lt;/cell&gt;&lt;cell&gt;23.3K&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;5%&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;codim&lt;/cell&gt;&lt;cell&gt;$0.36&lt;/cell&gt;&lt;cell&gt;21.6m&lt;/cell&gt;&lt;cell&gt;240&lt;/cell&gt;&lt;cell&gt;122.7K&lt;/cell&gt;&lt;cell&gt;90K&lt;/cell&gt;&lt;cell&gt;474.1K&lt;/cell&gt;&lt;cell&gt;1.3K&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;fishingknot&lt;/cell&gt;&lt;cell&gt;$0.38&lt;/cell&gt;&lt;cell&gt;22.5m&lt;/cell&gt;&lt;cell&gt;830&lt;/cell&gt;&lt;cell&gt;19.6K&lt;/cell&gt;&lt;cell&gt;36.9K&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;5%&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;fitting&lt;/cell&gt;&lt;cell&gt;$0.03&lt;/cell&gt;&lt;cell&gt;1.54m&lt;/cell&gt;&lt;cell&gt;240&lt;/cell&gt;&lt;cell&gt;28.4K&lt;/cell&gt;&lt;cell&gt;54.9K&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;10%&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;noodle&lt;/cell&gt;&lt;cell&gt;$0.14&lt;/cell&gt;&lt;cell&gt;8.45m&lt;/cell&gt;&lt;cell&gt;240&lt;/cell&gt;&lt;cell&gt;116.2K&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;116.2K&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;ribbon&lt;/cell&gt;&lt;cell&gt;$0.23&lt;/cell&gt;&lt;cell&gt;13.9m&lt;/cell&gt;&lt;cell&gt;480&lt;/cell&gt;&lt;cell&gt;34.9K&lt;/cell&gt;&lt;cell&gt;52.9K&lt;/cell&gt;&lt;cell&gt;8.8K&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;5%&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;woven&lt;/cell&gt;&lt;cell&gt;$0.58&lt;/cell&gt;&lt;cell&gt;34.6m&lt;/cell&gt;&lt;cell&gt;450&lt;/cell&gt;&lt;cell&gt;115.6K&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;115.4K&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;yarn&lt;/cell&gt;&lt;cell&gt;$0.01&lt;/cell&gt;&lt;cell&gt;0.24m&lt;/cell&gt;&lt;cell&gt;120&lt;/cell&gt;&lt;cell&gt;28.5K&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;28.5K&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;roller&lt;/cell&gt;&lt;cell&gt;$0.03&lt;/cell&gt;&lt;cell&gt;2.08m&lt;/cell&gt;&lt;cell&gt;240&lt;/cell&gt;&lt;cell&gt;21.4K&lt;/cell&gt;&lt;cell&gt;22.2K&lt;/cell&gt;&lt;cell&gt;61.0K&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;Large scale examples are run on a vast.ai instance with an RTX 4090. At the moment, not all large scale examples are ready yet, but they will be added/updated one by one. The author is actively woriking on it.&lt;/p&gt;&lt;table&gt;&lt;row span="4"&gt;&lt;cell&gt;large-twist (Video)&lt;/cell&gt;&lt;cell&gt;TBA&lt;/cell&gt;&lt;cell&gt;TBA&lt;/cell&gt;&lt;cell&gt;TBA&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row span="9"&gt;&lt;cell role="head"&gt;Example&lt;/cell&gt;&lt;cell role="head"&gt;Commit&lt;/cell&gt;&lt;cell role="head"&gt;#Vert&lt;/cell&gt;&lt;cell role="head"&gt;#Face&lt;/cell&gt;&lt;cell role="head"&gt;#Tet&lt;/cell&gt;&lt;cell role="head"&gt;#Seg&lt;/cell&gt;&lt;cell role="head"&gt;#Contact&lt;/cell&gt;&lt;cell role="head"&gt;#Frame&lt;/cell&gt;&lt;cell role="head"&gt;Time/Frame&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;large-twist&lt;/cell&gt;&lt;cell&gt;cbafbd2&lt;/cell&gt;&lt;cell&gt;3.2M&lt;/cell&gt;&lt;cell&gt;6.4M&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;N/A&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;56.7M&lt;/cell&gt;&lt;cell&gt;2,000&lt;/cell&gt;&lt;cell&gt;46.4s&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;We implemented GitHub Actions that test all of our examples except for large scale ones, which take from hours to days to finish. We perform explicit intersection checks 🔍 at the end of each step, which raises an error ❌ if an intersection is detected. This ensures that all steps are confirmed to be penetration-free if tests are pass ✅. The runner types are described as follows:&lt;/p&gt;&lt;p&gt;The tested 🚀 runner of this action is the Ubuntu NVIDIA GPU-Optimized Image for AI and HPC with an NVIDIA Tesla T4 (16 GB VRAM) with Driver version 570.133.20. This is not a self-hosted runner, meaning that each time the runner launches, all environments are 🌱 fresh.&lt;/p&gt;&lt;p&gt;We use the GitHub-hosted runner 🖥️, but the actual simulation runs on a &lt;code&gt;g6e.2xlarge&lt;/code&gt; AWS instance 🌐.
Since we start with a fresh 🌱 instance, the environment is clean 🧹 every time.
We take advantage of the ability to deploy on the cloud; this action is performed in parallel, which reduces the total action time.&lt;/p&gt;&lt;p&gt;We generate zipped action artifacts 📦 for each run. These artifacts include:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;📝 Logs: Detailed logs of the simulation runs.&lt;/item&gt;&lt;item&gt;📊 Metrics: Performance metrics and statistics.&lt;/item&gt;&lt;item&gt;📹 Videos: Simulated animations.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Please note that these artifacts will be deleted after a month.&lt;/p&gt;&lt;p&gt;We know that you can't judge the reliability of contact resolution by simply watching a single success 🎥 video example. To ensure greater transparency, we implemented GitHub Actions to run many of our examples via automated GitHub Actions ⚙️, not just once, but 10 times in a row 🔁. This means that a single failure out of 10 tests is considered a failure of the entire test suite!&lt;/p&gt;&lt;p&gt;Also, we apply small jitters to the position of objects in the scene 🔄, so at each run, the scene is slightly different.&lt;/p&gt;&lt;p&gt;Our contact solver is designed for heavy use in cloud services ☁️, enabling:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;💰 Cost-Effective Development: Quickly deploy testing environments 🚀 and delete 🗑️ them when not in use, saving costs.&lt;/item&gt;&lt;item&gt;📈 Flexible Scalability: Scale as needed based on demand 📈. For example, you can launch multiple instances before a specific deadline ⏰.&lt;/item&gt;&lt;item&gt;🌍 High Accessibility: Allow anyone with an internet connection 🌍 to try our solver, even on a smartphone 📱 or tablet 🖥️.&lt;/item&gt;&lt;item&gt;🐛 Easier Bug Tracking: Users and developers can easily share the same hardware, kernel, and driver environment, making it easier to track and fix bugs.&lt;/item&gt;&lt;item&gt;🛠️ Free Maintenance Cost: No need to maintain hardware for everyday operations or introduce redundancy for malfunctions.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;This is made possible with our purely web-based frontends 🌐 and scalable capability 🧩. Our main target is the NVIDIA L4 🖱️, a data-center-targeted GPU 🖥️ that offers reasonable pricing 💲, delivering both practical performance 💪 and scalability 📊 without investing in expensive hardware 💻.&lt;/p&gt;&lt;p&gt;Below, we describe how to deploy our solver on major cloud services ☁️. These instructions are up to date as of late 2024 📅 and are subject to change 🔄.&lt;/p&gt;&lt;p&gt;Important: For all the services below, don't forget to ❌ delete the instance after use, or you’ll be 💸 charged for nothing.&lt;/p&gt;&lt;head rend="h3"&gt;📦 Deploying on vast.ai&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Select our template (Link).&lt;/item&gt;&lt;item&gt;Create an instance and click &lt;code&gt;Open&lt;/code&gt;button.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;📦 Deploying on RunPod&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Follow this link (Link) and deploy an instance using our template.&lt;/item&gt;&lt;item&gt;Click &lt;code&gt;Connect&lt;/code&gt;button and open the&lt;code&gt;HTTP Services&lt;/code&gt;link.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;📦 Deploying on Scaleway&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Set zone to &lt;code&gt;fr-par-2&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Select type &lt;code&gt;L4-1-24G&lt;/code&gt;or&lt;code&gt;GPU-3070-S&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Choose &lt;code&gt;Ubuntu Jammy GPU OS 12&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Do not skip the Docker container creation in the installation process; it is required.&lt;/item&gt;&lt;item&gt;This setup costs approximately €0.76 per hour.&lt;/item&gt;&lt;item&gt;CLI instructions are described in (Markdown).&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;📦 Deploying on Amazon Web Services&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Amazon Machine Image (AMI): &lt;code&gt;Deep Learning Base AMI with Single CUDA (Ubuntu 22.04)&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Instance Type: &lt;code&gt;g6.2xlarge&lt;/code&gt;(Recommended)&lt;/item&gt;&lt;item&gt;This setup costs around $1 per hour.&lt;/item&gt;&lt;item&gt;Do not skip the Docker container creation in the installation process; it is required.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;📦 Deploying on Google Compute Engine&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;Select&lt;/p&gt;&lt;code&gt;GPUs&lt;/code&gt;. We recommend the GPU type&lt;code&gt;NVIDIA L4&lt;/code&gt;because it's affordable and accessible, as it does not require a high quota. You may select&lt;code&gt;T4&lt;/code&gt;instead for testing purposes.&lt;/item&gt;&lt;item&gt;&lt;p&gt;Do not check&lt;/p&gt;&lt;code&gt;Enable Virtual Workstation (NVIDIA GRID)&lt;/code&gt;.&lt;/item&gt;&lt;item&gt;&lt;p&gt;We recommend the machine type&lt;/p&gt;&lt;code&gt;g2-standard-8&lt;/code&gt;.&lt;/item&gt;&lt;item&gt;&lt;p&gt;Choose the OS type&lt;/p&gt;&lt;code&gt;Deep Learning VM with CUDA 12.4 M129&lt;/code&gt;and set the disk size to&lt;code&gt;50GB&lt;/code&gt;.&lt;/item&gt;&lt;item&gt;&lt;p&gt;As of late 2024, this configuration costs approximately $0.86 per hour in&lt;/p&gt;&lt;code&gt;us-central1 (Iowa)&lt;/code&gt;and $1.00 per hour in&lt;code&gt;asia-east1 (Taiwan)&lt;/code&gt;.&lt;/item&gt;&lt;item&gt;&lt;p&gt;Port number&lt;/p&gt;&lt;code&gt;8080&lt;/code&gt;is reserved by the OS image. Set&lt;code&gt;$MY_WEB_PORT&lt;/code&gt;to&lt;code&gt;8888&lt;/code&gt;. When connecting via&lt;code&gt;gcloud&lt;/code&gt;, use the following format:&lt;code&gt;gcloud compute ssh --zone "xxxx" "instance-name" -- -L 8080:localhost:8888&lt;/code&gt;.&lt;/item&gt;&lt;item&gt;&lt;p&gt;Do not skip the Docker container creation in the installation process; it is required.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;CLI instructions are described in (Markdown).&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;code&gt;@software{ppf-contact-solver-2024,
    title = {ZOZO's Contact Solver},
    author = {Ryoichi Ando},
    note = {https://github.com/st-tech/ppf-contact-solver},
    year = 2024,
}&lt;/code&gt;&lt;p&gt;The author thanks ZOZO, Inc. for permitting the release of the code and the team members for assisting with the internal paperwork for this project.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45761042</guid><pubDate>Thu, 30 Oct 2025 15:21:46 +0000</pubDate></item><item><title>Affinity Studio now free</title><link>https://www.affinity.studio/get-affinity</link><description>&lt;doc fingerprint="3bd67e5e966d06c5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Get Affinity&lt;/head&gt;
    &lt;p&gt;Available on desktop for&lt;/p&gt;
    &lt;p&gt;The all-in-one creative app, with everything you need to craft designs, edit images, and lay it all out, without ever leaving your document or paying a thing.&lt;/p&gt;
    &lt;quote&gt;$0, free&lt;/quote&gt;
    &lt;p&gt;To download Affinity, sign in with your Canva account (or create one for free).&lt;/p&gt;
    &lt;head rend="h2"&gt;One powerful app. No cost.&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Fully-featured toolsets&lt;/p&gt;
        &lt;p&gt;From vector to pixel to layout, Affinity has all the studio-grade tools you need under one roof.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Customizable studios&lt;/p&gt;
        &lt;p&gt;Mix and match your favorite tools to build your very own creative studios.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Non-destructive editing&lt;/p&gt;
        &lt;p&gt;Experiment as much you want, keep your original files intact.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Pixel-perfect export&lt;/p&gt;
        &lt;p&gt;Full control over how your work leaves the app, whether it’s by object, slice, or doc.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What you’ll get&lt;/head&gt;
    &lt;p&gt;With Affinity, you’ll get all the professional tools you need for your design, photo editing, and page layout projects, free of charge. If you’re on a Canva premium plan, you’ll also be able to unlock Canva AI tools directly in Affinity for a super-powered workflow.&lt;/p&gt;
    &lt;p&gt;+ Canva premium plans&lt;/p&gt;
    &lt;head rend="h2"&gt;Design workflows&lt;/head&gt;
    &lt;p&gt;Access all vector design, photo editing, and page layout tools in one app&lt;/p&gt;
    &lt;p&gt;Combine vector and pixel work on the same .af document&lt;/p&gt;
    &lt;p&gt;Customize your workspace with floating toolbars and studio presets&lt;/p&gt;
    &lt;p&gt;Real-time performance engine for ultra-smooth editing&lt;/p&gt;
    &lt;p&gt;Non-destructive editing across layers, filters, and adjustments&lt;/p&gt;
    &lt;p&gt;Import PSD, AI, PDF, SVG, IDML and more with high fidelity&lt;/p&gt;
    &lt;p&gt;Export with one-click presets or custom slice-based output&lt;/p&gt;
    &lt;p&gt;Quick export direct to Canva&lt;/p&gt;
    &lt;head rend="h2"&gt;Powerful photo editing&lt;/head&gt;
    &lt;p&gt;Live filters and adjustments with instant preview&lt;/p&gt;
    &lt;p&gt;Full RAW editing, tone mapping, and lens correction&lt;/p&gt;
    &lt;p&gt;Advanced retouching: inpainting brush, healing tools, dodge and burn&lt;/p&gt;
    &lt;p&gt;Batch processing with recordable macros, HDR merge, panorama stitching, and more&lt;/p&gt;
    &lt;head rend="h2"&gt;Pro vector design&lt;/head&gt;
    &lt;p&gt;Precision drawing with pen, node, and pencil tools&lt;/p&gt;
    &lt;p&gt;Live shape editing, booleans, and shape builder&lt;/p&gt;
    &lt;p&gt;Flexible gradients with full control&lt;/p&gt;
    &lt;p&gt;Trace pixel images&lt;/p&gt;
    &lt;p&gt;Pixel-perfect vector tools for illustration and layout&lt;/p&gt;
    &lt;head rend="h2"&gt;Advanced page layout&lt;/head&gt;
    &lt;p&gt;Linked text frames with autoflow and live text wrapping&lt;/p&gt;
    &lt;p&gt;Smart master pages with overrides and reusable layouts&lt;/p&gt;
    &lt;p&gt;Pro typography: ligatures, stylistic sets, drop caps, and variable fonts&lt;/p&gt;
    &lt;p&gt;Print-ready output: CMYK, spot colours, preflight, bleed, and slug support&lt;/p&gt;
    &lt;p&gt;Data merge from .csv with tokens, image merge, and conditional logic&lt;/p&gt;
    &lt;head rend="h2"&gt;Canva AI Studio&lt;/head&gt;
    &lt;p&gt;Generative Fill, Expand, and Edit&lt;/p&gt;
    &lt;p&gt;Generate Images and Vectors&lt;/p&gt;
    &lt;p&gt;Remove Background and Subject Selection&lt;/p&gt;
    &lt;p&gt;Colorize, Depth Selection, and Super Resolution&lt;/p&gt;
    &lt;p&gt;Portrait Blur and Portrait Lighting&lt;/p&gt;
    &lt;p&gt;Full AI generation history&lt;/p&gt;
    &lt;head rend="h2"&gt;Need Affinity for your organization?&lt;/head&gt;
    &lt;p&gt;Skip the individual downloads and get your entire team on Affinity with SSO via a Canva Enterprise or Canva Districts account. Choose an option below to get started.&lt;/p&gt;
    &lt;head rend="h2"&gt;FAQs&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Yes, Affinity really is free. That doesn’t mean you’re getting a watered-down version of the app though. You can use every tool in the Pixel, Vector, and Layout studios, plus all of the customization and export features, as much as you want, with no restrictions or payment needed. The app will also receive free updates with new features and improvements added.&lt;/p&gt;
        &lt;p&gt;If you’re on a Canva premium plan (Pro, Business, Enterprise, Education), you’ll also be able to unlock Canva’s powerful AI tools within Affinity via the Canva AI Studio.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Yes. Affinity is now brought to you by Canva, and your Canva account gives you access to Affinity and other Canva products and features.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No. You can access all of Affinity’s vector, layout, and pixel tools for free without a Canva subscription. If you’d like to unlock Canva AI tools within Affinity, however, you will need a premium Canva plan.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;This is a brand-new product that gives you advanced photo editing, graphic design, and page layout tools under one roof. It includes highly requested features such as Image Trace, ePub support, mesh gradients, hatch fills, live glitch filter, as well as custom capabilities that allow you to rearrange panels and combine tools to build your own unique studios. Plus, with a Canva premium plan, you can unlock incredibly powerful AI tools such as Generative Fill, Generative Expand, Generate Image/Vector, and more — directly in Affinity.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Yes. With a Canva premium plan you can unlock Canva AI features in Affinity.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No, these are only available to those with Canva premium accounts.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Affinity is currently available on Windows and macOS (iPadOS coming soon!).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;We’re busy building our iPad version — stay tuned for updates!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Affinity is optimized for the latest hardware, including Apple silicon.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Absolutely! The new desktop version of Affinity can open all files created in Affinity V2 or V1 apps. However, Affinity V1 and V2 cannot open files that are created or saved in the newer app, Affinity by Canva.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No, it’s the same app, just available on different operating systems.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Yes, you can install Affinity on as many devices as you like.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Yes! It’s easy to import PSDs, AIs, IDMLs, DWGs, and other file types into Affinity, with structure, layers, and creative intent preserved.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Affinity is available in English, French, German, Italian, Spanish, Portuguese, Japanese, Chinese, Bahasa Indonesian, and Turkish. Keep an eye out for more languages coming soon!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Get in touch to speak to our team about how your organization can get set up with Affinity, including SSO.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Then all you need to do is stay in one of our pre-built studios: Pixel, Vector or Layout. You’ll find all your favorite tools there, plus some new ones. Since it’s all free, just think of the other creative toolsets as an added bonus!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That’s totally fine. Your Affinity V2 license (via Serif) remains valid and Serif will continue to keep activation servers online. But please note that these apps won’t receive future updates.&lt;/p&gt;
        &lt;p&gt;For the best experience, we recommend using the new Affinity by Canva app.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;No. The new desktop version of Affinity can open all files created in V2, but older versions (including V2 on iPad) cannot open newer Affinity (.af) files, meaning you won’t be able to work across both platforms.&lt;/p&gt;&lt;lb/&gt;We don’t have a release date for the new Affinity on iPad yet, so recommend continuing to run V2 independently while you enjoy the new Affinity on desktop.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Yes. The new Affinity by Canva app will receive free updates and new features over time.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;You will need to be online to download and activate your license with your free Canva account. From then on, there is no requirement to be online, even with extended offline periods.&lt;/p&gt;
        &lt;p&gt;There are a couple of things to keep in mind:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;There are some features which do require you to be online, if you choose to use them, such as product help, lessons, stock libraries and integrations with Canva including AI tools.&lt;/item&gt;
          &lt;item&gt;We’ll also be releasing new updates and patches regularly, so we recommend connecting from time to time to keep your app up to date, but it's not a requirement of use.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;You need a Canva premium plan to unlock all of Canva’s AI features in Affinity. Simply download the Affinity app via our Downloads page and follow the prompts once you click ‘Canva AI Studio’.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45761445</guid><pubDate>Thu, 30 Oct 2025 15:54:38 +0000</pubDate></item><item><title>Launch HN: Propolis (YC X25) – Browser agents that QA your web app autonomously</title><link>https://app.propolis.tech/#/launch</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=45762012</guid><pubDate>Thu, 30 Oct 2025 16:40:02 +0000</pubDate></item><item><title>The ear does not do a Fourier transform</title><link>https://www.dissonances.blog/p/the-ear-does-not-do-a-fourier-transform</link><description>&lt;doc fingerprint="a63e213260f69383"&gt;
  &lt;main&gt;
    &lt;p&gt;Let’s talk about how the cochlea computes!&lt;/p&gt;
    &lt;p&gt;The tympanic membrane (eardrum) is vibrated by changes in air pressure (sound waves). Bones in the middle ear amplify and send these vibrations to the fluid-filled, snail-shaped cochlea. Vibrations travel through the fluid to the basilar membrane, which remarkably performs frequency separation1: the stiffer, lighter base resonates with high frequency components of the signal, and the more flexible, heavier apex resonates with lower frequencies. Between the two ends, the resonant frequencies decrease logarithmically in space2.&lt;/p&gt;
    &lt;p&gt;The hair cells on different parts of the basilar membrane wiggle back and forth at the frequency corresponding to their position on the membrane. But how do wiggling hair cells translate to electrical signals? This mechanoelectrical transduction process feels like it could be from a Dr. Seuss world: springs connected to the ends of hair cells open and close ion channels at the frequency of the vibration, which then cause neurotransmitter release. Bruno calls them “trapdoors”. Here’s a visualization:&lt;/p&gt;
    &lt;p&gt;It’s clear that the hardware of the ear is well-equipped for frequency analysis. Nerve fibers serve as filters to extract temporal and frequency information about a signal. Below are examples of filters (not necessarily of the ear) shown in the time domain. On the left are filters that are more localized in time, i.e. when a filter is applied to a signal, it is clear when in the signal the corresponding frequency occurred. On the right are filters that have less temporal specificity, but are more uniformly distributed across frequencies compared to the left one.&lt;/p&gt;
    &lt;p&gt;Wouldn’t it be convenient if the cochlea were doing a Fourier transform, which would fit cleanly into how we often analyze signals in engineering? But no 🙅🏻♀️! A Fourier transform has no explicit temporal precision, and resembles something closer to the waveforms on the right; this is not what the filters in the cochlea look like.&lt;/p&gt;
    &lt;p&gt;We can visualize different filtering schemes, or tiling of the time-frequency domain, in the following figure. In the leftmost box, where each rectangle represents a filter, a signal could be represented at a high temporal resolution (similar to left filters above), but without information about its constituent frequencies. On the other end of the spectrum, the Fourier transform performs precise frequency decomposition, but we cannot tell when in the signal that frequency occurred (similar to right filters)3. What the cochlea is actually doing is somewhere between a wavelet and Gabor. At high frequencies, frequency resolution is sacrificed for temporal resolution, and vice versa at low frequencies.&lt;/p&gt;
    &lt;p&gt;Why would this type of frequency-temporal precision tradeoff be a good representation? One theory, explored in Lewicki 2002, is that these filters are a strategy to reduce the redundancy in the representation of natural sounds. Lewicki performed independent component analysis (ICA) to produce filters maximizing statistical independence, comparing environmental sounds, animal vocalizations, and human speech. The tradeoffs look different for each one, and you can kind of map them to somewhere in the above cartoon.&lt;/p&gt;
    &lt;p&gt;It appears that human speech occupies a distinct time-frequency space. Some speculate that speech evolved to fill a time-frequency space that wasn’t yet occupied by other existing sounds.&lt;/p&gt;
    &lt;p&gt;To drive the theory home, one that we have been hinting at since the outset: forming ecologically-relevant representations makes sense, as behavior is dependent on the environment. It appears that for audition, as well as other sensory modalities, we are doing this. This is a bit of a teaser for efficient coding, which we will get to soon.&lt;/p&gt;
    &lt;p&gt;We’ve talked about some incredible mechanisms that occur at the beginning of the sensory coding process, but it’s truly just the tiny tip of the ice burg. We also glossed over how these computations occur. The next lecture will zoom into the biophysics of computation in neurons.&lt;/p&gt;
    &lt;p&gt;We call this tonotopic organization, which is a mapping from frequency to space. This type of organization also exists in the cortex for other senses in addition to audition, such as retinotopy for vision and somatotopy for touch.&lt;/p&gt;
    &lt;p&gt;The relationship between human pitch perception and frequency is logarithmic. Coincidence? 😮&lt;/p&gt;
    &lt;p&gt;One could argue we should be comparing to a short-time Fourier transform, but this has resolution issues, and is still not what the cochlea appears to be doing.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45762259</guid><pubDate>Thu, 30 Oct 2025 17:01:20 +0000</pubDate></item><item><title>I have released a 69.0MB version of Windows 7 x86</title><link>https://twitter.com/XenoPanther/status/1983477707968291075</link><description>&lt;doc fingerprint="d635f48b34542867"&gt;
  &lt;main&gt;
    &lt;p&gt;We’ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.&lt;/p&gt;
    &lt;p&gt;Help Center&lt;/p&gt;
    &lt;p&gt;Terms of Service Privacy Policy Cookie Policy Imprint Ads info © 2025 X Corp.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45763076</guid><pubDate>Thu, 30 Oct 2025 18:05:39 +0000</pubDate></item><item><title>TruthWave – A platform for corporate whistleblowers</title><link>https://www.truthwave.com</link><description>&lt;doc fingerprint="7d44df6756f66ba1"&gt;
  &lt;main&gt;
    &lt;p&gt;Our Beta is Now Live!&lt;/p&gt;
    &lt;head rend="h1"&gt;This is TruthWave.&lt;/head&gt;
    &lt;p&gt;Welcome to the platform and community for those who bring unethical corporations to justice.&lt;/p&gt;
    &lt;p&gt;For far too long, harmful corporate culture has stigmatized and disincentivized information flow. TruthWave is rewriting this narrative by creating a platform that financially compensates whistleblowers for courageously stepping forward while leveraging a global community built around justice.&lt;/p&gt;
    &lt;p&gt;At its core, TruthWave is an information platform that allows those who possess or locate vital information about corporate wrongdoing to share it securely and anonymously.&lt;/p&gt;
    &lt;p&gt;Have our next big case? If you know about corporate wrongdoing, submit a tip to bring those responsible to justice.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45763858</guid><pubDate>Thu, 30 Oct 2025 18:57:39 +0000</pubDate></item><item><title>Minecraft HDL, an HDL for Redstone</title><link>https://github.com/itsfrank/MinecraftHDL</link><description>&lt;doc fingerprint="3271921d09773db1"&gt;
  &lt;main&gt;
    &lt;p&gt;Minecraft HDL is a digital synthesis flow for minecraft redstone circuits. It is an attempt to use industry standard design tools and methods to generate digital circuits with redstone.&lt;/p&gt;
    &lt;p&gt;This file &lt;code&gt;multiplexer4_1.v&lt;/code&gt; is a 6 input - 1 output circuit that selects one of the first 4 inputs (a, b, c, d) as the output based on the value of the last 2 inputs (x, y)&lt;/p&gt;
    &lt;code&gt;module multiplexer4_1 ( a ,b ,c ,d ,x ,y ,dout ); 
 
output dout ; 
input a, b, c, d, x, y; 
 
assign dout = (a &amp;amp; (~x) &amp;amp; (~y)) | 
     (b &amp;amp; (~x) &amp;amp; (y)) |  
     (c &amp;amp; x &amp;amp; (~y)) | 
     (d &amp;amp; x &amp;amp; y); 
endmodule &lt;/code&gt;
    &lt;p&gt;When synthesized through Minecraft HDL it produces this circuit:&lt;/p&gt;
    &lt;p&gt;With the 6 inputs on the right and the single output on the left&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Screenshots &amp;amp; Sample Circuits&lt;/item&gt;
      &lt;item&gt;Getting Started - Installing and Using MinecraftHDL&lt;/item&gt;
      &lt;item&gt;Background Theory - Digital Design &amp;amp; Verilog&lt;/item&gt;
      &lt;item&gt;How MinecraftHDL Works - Read Our Paper&lt;/item&gt;
      &lt;item&gt;Developper Info - If you want to fork or contribute&lt;/item&gt;
      &lt;item&gt;Quick Overview - Check out our poster&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;MinecraftHDL was the final undergraduate design project made by three students in the Electrical, Computer &amp;amp; Software Engineering department at McGill University.&lt;/p&gt;
    &lt;p&gt;It is by no means bug-free or even complete; It produces objectively inferior circuits to 'hand-made' redstone designs, and is not intended to be used in modded survival. It can generate almost any verilog circuit, however only simple designs will actually be testable in-game since any moderately-complex design will end up being longer than the maximum number of blocks loaded in Minecraft.&lt;/p&gt;
    &lt;p&gt;Additionally, we are currently unable to synthesize sequential circuits, aka any circuits with a loopback or feedback. That means no memory, no counters or any circuit that could hold a state.&lt;/p&gt;
    &lt;p&gt;MinecraftHDL is an educational tool to illustrate on a macro-scopic scale how microelectronic digital circuits are designed and produced. It is a great way to introduce younger audiences to the world of digital design and can also be used to illustrate the difference between software and hardware design to undergraduate engineers taking their first RTL class.&lt;/p&gt;
    &lt;p&gt;Supervisor: Brett H. Meyer - Website&lt;lb/&gt; Students: Francis O'Brien - Website&lt;lb/&gt; Omar Ba Mashmos&lt;lb/&gt; Andrew Penhale&lt;/p&gt;
    &lt;p&gt;To show how easy it is to make a circuit with MinecraftHDL here is a gif of me creating a circuit, synthesizing, and generating it in minecraft in less than a minute!&lt;/p&gt;
    &lt;p&gt;The circuit I generate above is a 2bit adder. It takes two numbers of two bits and adds them. At the end of the gif I set both input numbers to '11' which is the binary representation of the number 3. Then I move to the output and we see that O3=1, O2=1, and O1=0, this gives the binary number '110' which is indeed 6.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45763877</guid><pubDate>Thu, 30 Oct 2025 18:59:02 +0000</pubDate></item><item><title>Show HN: Ellipticc Drive – open-source cloud drive with E2E and PQ encryption</title><link>https://ellipticc.com</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45764265</guid><pubDate>Thu, 30 Oct 2025 19:30:48 +0000</pubDate></item><item><title>Show HN: ekoAcademic – Convert ArXiv papers to interactive podcasts</title><link>https://www.wadamczyk.io/projects/ekoacademic/index.html</link><description>&lt;doc fingerprint="3e4948c978e79297"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;ekoAcademic&lt;/head&gt;
    &lt;p&gt;Co-authors: Aidan McConnel, Shaan Amin&lt;/p&gt;
    &lt;p&gt;link: https://www.echoecho.org&lt;/p&gt;
    &lt;p&gt;Aidan, Shaan and I wanted to have an interactive-audio version of the arXiv to listen and discuss papers during our commute.&lt;/p&gt;
    &lt;p&gt;ekoAcademic is a small tool that generates short, accessible audio summaries of recent academic papers. It's a simple idea: you don't always have time to dive into a full paper, but you can listen to short summaries while walking, commuting or doing chores, and then decide if you want to dig deeper. We've also added a functionality for conversations and verbal Q&amp;amp;A so you can ask questions and understand recent literature in a conversational way. This works in many languages. This means that when you interact with the audio summary, you can ask it questions in your own language, and it should automatically answer in the same language.&lt;/p&gt;
    &lt;head rend="h2"&gt;How it works&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We extract newly released papers (mirroring the arXiv categories), process/summarise them and then generate a short audio clip for each paper.&lt;/item&gt;
      &lt;item&gt;We then have several GPT-realtime sessions designed for Q&amp;amp;A, or summarisation of sets of papers. By allowing microphone access you can always stop it and ask questions (in any language!).&lt;/item&gt;
      &lt;item&gt;Non-interactive podcasts are stored, so once one person listens to one, they no longer need to be generated again for anyone else.&lt;/item&gt;
      &lt;item&gt;This means that it is relatively cheap for us to generate new podcasts, and we can do it in real-time.&lt;/item&gt;
      &lt;item&gt;We right now work mostly with the arxiv, but if people would find it useful to have it for other databases, we can add it.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Feedback&lt;/head&gt;
    &lt;p&gt;We'd love to receive any feedback from this community:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Does this solve a pain you have?&lt;/item&gt;
      &lt;item&gt;What subject areas are missing (if yours isn’t covered yet)?&lt;/item&gt;
      &lt;item&gt;Could the other language options for interactive discussion be useful for you? Should we translate more of the site?&lt;/item&gt;
      &lt;item&gt;Any concerns (accuracy of summaries, missing context)?&lt;/item&gt;
      &lt;item&gt;Do people actually like to do this on their commute? Or is that more of a time to unwind?&lt;/item&gt;
      &lt;item&gt;How can we make it more useful for the community?&lt;/item&gt;
      &lt;item&gt;Are there any features that you would like to see?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Thanks for reading. We built this because we felt this need ourselves - if others feel it too, maybe this can be a small tool to help.&lt;/p&gt;
    &lt;p&gt;Feel free to reach out to us at wojtekadamczyk3@gmail.com&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45765328</guid><pubDate>Thu, 30 Oct 2025 21:03:46 +0000</pubDate></item><item><title>If a pilot ejects, what is the autopilot programmed to do? (2018)</title><link>https://aviation.stackexchange.com/questions/52862/if-a-pilot-ejects-what-is-the-autopilot-programmed-to-do</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45765596</guid><pubDate>Thu, 30 Oct 2025 21:27:17 +0000</pubDate></item><item><title>Denmark reportedly withdraws Chat Control proposal following controversy</title><link>https://therecord.media/demark-reportedly-withdraws-chat-control-proposal</link><description>&lt;doc fingerprint="f3c7115416b5d37e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Denmark reportedly withdraws Chat Control proposal following controversy&lt;/head&gt;
    &lt;p&gt;Denmark’s justice minister on Thursday said he will no longer push for an EU law requiring the mandatory scanning of electronic messages, including on end-to-end encrypted platforms.&lt;/p&gt;
    &lt;p&gt;Earlier in its European Council presidency, Denmark had brought back a draft law which would have required the scanning, sparking an intense backlash. Known as Chat Control, the measure was intended to crack down on the trafficking of child sex abuse materials (CSAM).&lt;/p&gt;
    &lt;p&gt;After days of silence, the German government on October 8 announced it would not support the proposal, tanking the Danish effort.&lt;/p&gt;
    &lt;p&gt;Danish Justice Minister Peter Hummelgaard told reporters on Thursday that his office will support voluntary CSAM detections.&lt;/p&gt;
    &lt;p&gt;"This will mean that the search warrant will not be part of the EU presidency's new compromise proposal, and that it will continue to be voluntary for the tech giants to search for child sexual abuse material," Hummelgaard said, according to local news reports.&lt;/p&gt;
    &lt;p&gt;The current model allowing for voluntary scanning expires in April, Hummelgaard said.&lt;/p&gt;
    &lt;p&gt;"Right now we are in a situation where we risk completely losing a central tool in the fight against sexual abuse of children,” he said. "That's why we have to act no matter what. We owe it to all the children who are subjected to monstrous abuse."&lt;/p&gt;
    &lt;p&gt;Meredith Whittaker, the president of the Signal Foundation, lobbied hard against the original measure, saying the organization would leave the European market if the provision was adopted.&lt;/p&gt;
    &lt;p&gt;“What they propose is in effect a mass surveillance free-for-all, opening up everyone’s intimate and confidential communications, whether government officials, military, investigative journalists, or activists,” she said at the time.&lt;/p&gt;
    &lt;p&gt;Suzanne Smalley&lt;/p&gt;
    &lt;p&gt;is a reporter covering privacy, disinformation and cybersecurity policy for The Record. She was previously a cybersecurity reporter at CyberScoop and Reuters. Earlier in her career Suzanne covered the Boston Police Department for the Boston Globe and two presidential campaign cycles for Newsweek. She lives in Washington with her husband and three children.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45765664</guid><pubDate>Thu, 30 Oct 2025 21:35:42 +0000</pubDate></item><item><title>Phone numbers for use in TV shows, films and creative works</title><link>https://www.acma.gov.au/phone-numbers-use-tv-shows-films-and-creative-works</link><description>&lt;doc fingerprint="c83d86dd4cb0f56b"&gt;
  &lt;main&gt;
    &lt;p&gt; On this page &lt;/p&gt;
    &lt;p&gt;Looking for info about unwanted calls? Learn more about phone scams and how you can make your number more private.&lt;/p&gt;
    &lt;head rend="h2"&gt;Geographical numbers&lt;/head&gt;
    &lt;p&gt;You can use the following prefixes and first 4 digits, then any 4 digits you like (shown here as 'xxxx').&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;Region&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;Number range&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Central East (covering NSW and ACT)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;(02) 5550 xxxx and (02) 7010 xxxx&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;South East (covering VIC and TAS)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;(03) 5550 xxxx and (03) 7010 xxxx&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;North East (covering QLD)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;(07) 5550 xxxx and (07) 7010 xxxx&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Central West (covering SA, WA and NT)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;(08) 5550 xxxx and (08) 7010 xxxx&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Mobile numbers&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;0491 570 006&lt;/item&gt;
      &lt;item&gt;0491 570 156&lt;/item&gt;
      &lt;item&gt;0491 570 157&lt;/item&gt;
      &lt;item&gt;0491 570 158&lt;/item&gt;
      &lt;item&gt;0491 570 159&lt;/item&gt;
      &lt;item&gt;0491 570 110&lt;/item&gt;
      &lt;item&gt;0491 570 313&lt;/item&gt;
      &lt;item&gt;0491 570 737&lt;/item&gt;
      &lt;item&gt;0491 571 266&lt;/item&gt;
      &lt;item&gt;0491 571 491&lt;/item&gt;
      &lt;item&gt;0491 571 804&lt;/item&gt;
      &lt;item&gt;0491 572 549&lt;/item&gt;
      &lt;item&gt;0491 572 665&lt;/item&gt;
      &lt;item&gt;0491 572 983&lt;/item&gt;
      &lt;item&gt;0491 573 770&lt;/item&gt;
      &lt;item&gt;0491 573 087&lt;/item&gt;
      &lt;item&gt;0491 574 118&lt;/item&gt;
      &lt;item&gt;0491 574 632&lt;/item&gt;
      &lt;item&gt;0491 575 254&lt;/item&gt;
      &lt;item&gt;0491 575 789&lt;/item&gt;
      &lt;item&gt;0491 576 398&lt;/item&gt;
      &lt;item&gt;0491 576 801&lt;/item&gt;
      &lt;item&gt;0491 577 426&lt;/item&gt;
      &lt;item&gt;0491 577 644&lt;/item&gt;
      &lt;item&gt;0491 578 957&lt;/item&gt;
      &lt;item&gt;0491 578 148&lt;/item&gt;
      &lt;item&gt;0491 578 888&lt;/item&gt;
      &lt;item&gt;0491 579 212&lt;/item&gt;
      &lt;item&gt;0491 579 760&lt;/item&gt;
      &lt;item&gt;0491 579 455&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Freephone and local rate numbers&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;1800 160 401&lt;/item&gt;
      &lt;item&gt;1800 975 707&lt;/item&gt;
      &lt;item&gt;1800 975 708&lt;/item&gt;
      &lt;item&gt;1800 975 709&lt;/item&gt;
      &lt;item&gt;1800 975 710&lt;/item&gt;
      &lt;item&gt;1800 975 711&lt;/item&gt;
      &lt;item&gt;1300 975 707&lt;/item&gt;
      &lt;item&gt;1300 975 708&lt;/item&gt;
      &lt;item&gt;1300 975 709&lt;/item&gt;
      &lt;item&gt;1300 975 710&lt;/item&gt;
      &lt;item&gt;1300 975 711&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45765787</guid><pubDate>Thu, 30 Oct 2025 21:49:11 +0000</pubDate></item><item><title>Why We're Never Using Wise Again – A Cautionary Tale from a Business Burned</title><link>https://shaun.nz/why-were-never-using-wise-again-a-cautionary-tale-from-a-business-burned/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45766253</guid><pubDate>Thu, 30 Oct 2025 22:41:50 +0000</pubDate></item></channel></rss>