<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 02 Oct 2025 17:33:45 +0000</lastBuildDate><item><title>Building the heap: racking 30 petabytes of hard drives for pretraining</title><link>https://si.inc/posts/the-heap/</link><description>&lt;doc fingerprint="2fd91d7735ac7fcd"&gt;
  &lt;main&gt;
    &lt;p&gt;We built a storage cluster in downtown SF to store 90 million hours worth of video data. Why? We’re pretraining models to solve computer use. Compared to text LLMs like LLaMa-405B, which require ~60 TB of text data to train, videos are sufficiently large that we need 500 times more storage. Instead of paying the $12 million / yr it would cost to store all of this on AWS, we rented space from a colocation center in San Francisco to bring that cost down ~40x to $354k per year, including depreciation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why&lt;/head&gt;
    &lt;p&gt;Our use case for data is unique. Most cloud providers care highly about redundancy, availability, and data integrity, which tends to be unnecessary for ML training data. Since pretraining data is a commodity—we can lose any individual 5% with minimal impact—we can handle relatively large amounts of data corruption compared to enterprises who need guarantees that their user data isn’t going anywhere. In other words, we don’t need AWS’s 13 nines of reliability; 2 is more than enough.&lt;/p&gt;
    &lt;p&gt;Additionally, storage tends to be priced substantially above cost. Most companies use relatively small amounts of storage (even ones like Discord still use under a petabyte for messages), and the companies that use petabytes are so large that storage remains a tiny fraction of their total compute spend.&lt;/p&gt;
    &lt;p&gt;Data is one of our biggest contraints, and would be prohibitively expensive otherwise. As long as the cost predictions work out in favor of a local datacenter, and it would not consume too much of the core team’s time, it would make sense to stack hard drives ourselves. [1] 1. We talked to some engineers at the Internet Archive, which had basically the same problem as us; even after massive friends &amp;amp; family discounts on AWS, it was still 10 times more cost-effective to buy racks and store the data themselves!&lt;/p&gt;
    &lt;head rend="h2"&gt;The Cost Breakdown: Cloud Alternatives vs In-House&lt;/head&gt;
    &lt;p&gt;Internet and electricity total $17.5k as our only recurring expenses (the price of colocation space, cooling, etc were bundled into electricity costs). One-time costs were dominated by hard drive capex. [2] 2. When deciding the datacenter location we had multiple options across the Bay Area, including options in Fremont through Hurricane Electric for around $10k in setup fees and $12.8k per month, saving us $38.5k initially and $4.7k per month, but ended up opting for a datacenter that was only a couple blocks from our office in SF. Though this came at a premium, it was extremely helpful to get the initial nodes setup and for ongoing maintenance. Our team is just 5 people, so any friction in going to the datacenter would come at a noticeable cost to team productivity.&lt;/p&gt;
    &lt;p&gt;Table 1: Cost comparison of cloud alternatives vs in-house. AWS is $1,130,000/month including estimated egress, Cloudflare is $270,000/month (with bulk-discounted pricing), and our datacenter is $29,500/month (including recurring costs and depreciation).&lt;/p&gt;
    &lt;head rend="h3"&gt;Monthly Recurring Costs&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Item&lt;/cell&gt;
        &lt;cell role="head"&gt;Cost&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Internet&lt;/cell&gt;
        &lt;cell&gt;$7,500/month&lt;/cell&gt;
        &lt;cell&gt;100Gbps DIA from Zayo, 1yr term.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Electricity&lt;/cell&gt;
        &lt;cell&gt;$10,000/month&lt;/cell&gt;
        &lt;cell&gt;1 kW/PB, $330/kW. Includes cabinet space &amp;amp; cooling. 1yr term.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Total Monthly&lt;/cell&gt;
        &lt;cell&gt;$17,500/month&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;One-Time Costs&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Category&lt;/cell&gt;
        &lt;cell role="head"&gt;Item&lt;/cell&gt;
        &lt;cell role="head"&gt;Cost&lt;/cell&gt;
        &lt;cell role="head"&gt;Details&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Storage&lt;/cell&gt;
        &lt;cell&gt;Hard drives (HDDs)&lt;/cell&gt;
        &lt;cell&gt;$300,000&lt;/cell&gt;
        &lt;cell&gt;2,400 drives. Mostly 12TB used enterprise drives (3/4 SATA, 1/4 SAS). The JBOD DS4246s work for either.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Storage Infrastructure&lt;/cell&gt;
        &lt;cell&gt;NetApp DS4246 chassis&lt;/cell&gt;
        &lt;cell&gt;$35,000&lt;/cell&gt;
        &lt;cell&gt;100 dual SATA/SAS chassis, 4U each&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Compute&lt;/cell&gt;
        &lt;cell&gt;CPU head nodes&lt;/cell&gt;
        &lt;cell&gt;$6,000&lt;/cell&gt;
        &lt;cell&gt;10 Intel RR2000s from eBay&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Datacenter Setup&lt;/cell&gt;
        &lt;cell&gt;Install fee&lt;/cell&gt;
        &lt;cell&gt;$38,500&lt;/cell&gt;
        &lt;cell&gt;One-off datacenter install fee&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Labor&lt;/cell&gt;
        &lt;cell&gt;Contractors&lt;/cell&gt;
        &lt;cell&gt;$27,000&lt;/cell&gt;
        &lt;cell&gt;Contractors to help physically screw in / install racks and wire cables&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Networking &amp;amp; Misc&lt;/cell&gt;
        &lt;cell&gt;Install expenses&lt;/cell&gt;
        &lt;cell&gt;$20,000&lt;/cell&gt;
        &lt;cell&gt;Power cables, 100GbE QSFP CX4 NICs, Arista router, copper jumpers, one-time internet install fee&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Total One-Time&lt;/cell&gt;
        &lt;cell&gt;$426,500&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Our price assuming three-year depreciation (including for the one-off install fees) is $17.5k/month in fixed monthly costs (internet, power, etc.) and $12k/month in depreciation, for $29.5k/month overall.&lt;/p&gt;
    &lt;p&gt;We compare our costs to two main providers: AWS’s public pricing numbers as a baseline, and Cloudflare’s discounted pricing for 30PB of storage. It’s important to note that AWS egress would be substantially lower if we utilized AWS GPUs. This is not reflected on our graph because AWS GPUs are priced at substantially above market prices and large clusters are difficult to attain, untenable at our compute scales.&lt;/p&gt;
    &lt;p&gt;Here are the pricing breakdowns:&lt;/p&gt;
    &lt;head rend="h3"&gt;AWS Pricing Breakdown&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Cost Component&lt;/cell&gt;
        &lt;cell role="head"&gt;Rate&lt;/cell&gt;
        &lt;cell role="head"&gt;Monthly Cost&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Storage&lt;/cell&gt;
        &lt;cell&gt;$0.021/GB/month&lt;/cell&gt;
        &lt;cell&gt;$630,000&lt;/cell&gt;
        &lt;cell&gt;For data over 500TB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Egress&lt;/cell&gt;
        &lt;cell&gt;$0.05/GB&lt;/cell&gt;
        &lt;cell&gt;$500,000&lt;/cell&gt;
        &lt;cell&gt;Entire dataset egressed quarterly (10 PB/month)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Total AWS Monthly&lt;/cell&gt;
        &lt;cell&gt;$1,130,000&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Cloudflare R2 Pricing&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Pricing Tier&lt;/cell&gt;
        &lt;cell role="head"&gt;Rate&lt;/cell&gt;
        &lt;cell role="head"&gt;Monthly Cost&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Published Rate&lt;/cell&gt;
        &lt;cell&gt;$0.015/GB/month&lt;/cell&gt;
        &lt;cell&gt;$450,000&lt;/cell&gt;
        &lt;cell&gt;No egress fees&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Estimated Private Pricing [3] 3. Cloudflare has a more reasonable estimate for the 30 PB, placing it at an overall monthly cost of $270k without egress fees. We also have bulk-discounted pricing estimates after getting pricing quotes—this was our main point of comparison for the datacenter.&lt;/cell&gt;
        &lt;cell&gt;$0.009/GB/month&lt;/cell&gt;
        &lt;cell&gt;$270,000&lt;/cell&gt;
        &lt;cell&gt;Estimated rate for &amp;gt;20 PB scale&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;That brings monthly costs to $38/TB/month for AWS, $10/TB/month for Cloudflare, and $1/TB/month for our datacenter—about 38x lower and 10x lower respectively. (At the very cheapest end of the spectrum, Backblaze has a $6/TB product that is unsuitable for model training due to egress speed limitations; their $15/TB Overdrive AI-specific storage product is closer to Cloudflare’s in price &amp;amp; performance)&lt;/p&gt;
    &lt;p&gt;While we use Cloudflare as a comparison point, we’ve sometimes done too much load for their R2 servers. In particular, in the past we’ve done enough load during large model training runs that they rate-limited us, later confirming we were saturating their metadata layer and the rate limit wasn’t synthetic. Because our metadata on the heap is so simple, and we have a 100Gbps DIA connection, we haven’t ran into any issues there. [4] 4. We love Cloudflare and use many of their products often; we include this anecdote as a fact about our scale being difficult to handle, not as a dig!&lt;/p&gt;
    &lt;p&gt;This setup was and is necessary for our video data pipelines, and we’re extremely happy that we made this investment. By gathering large scale data at low costs, we can be competitive with frontier labs with billions of dollars in capital.&lt;/p&gt;
    &lt;head rend="h2"&gt;Setup/The Process&lt;/head&gt;
    &lt;p&gt;We cared a lot about getting this built fast, because this kind of project can easily stretch on for months if not careful. Hence Storage Stacking Saturday, or S3. We threw a hard drive stacking party in downtown SF and got our friends to come, offering food and custom-engraved hard drives to all who helped. The hard drive stacking started at 6am and continued for 36 hours (with a break to sleep), and by the end of that time we had 30 PB of functioning hardware racked and wired up. We brought in contractors for additional help and professional installation later on in the event.&lt;/p&gt;
    &lt;p&gt;People at the hard drive stacking party! Cool shots of the servers&lt;/p&gt;
    &lt;p&gt;Our software is 200 lines of Rust code for writing (to determine the drive to write data onto) and a nginx webserver for reading data, with a simple SQLite db for tracking metadata like which heap node each file is on and what data split it belongs to. We kept this obsessively simple instead of using MinIO or Ceph because we didn’t need any of the features they provided; it’s much, much simpler to debug a 200-line program than to debug Ceph, and we weren’t worried about redundancy or sharding. All our drives were formatted with XFS.&lt;/p&gt;
    &lt;p&gt;The storage software landscape offers many options, but every option available comes with drawbacks. People experienced with Ceph strongly warned us to avoid it unless we were willing to hire dedicated Ceph specialists—our research confirmed this advice. Ceph appears far more complex than justified for most use cases, only worthwhile for companies that absolutely need maximum performance and customizability and are prepared to invest heavily in tuning. Minio presents an interesting option if S3 compatibility is essential, but otherwise remains a bit too fancy for us and similar use-cases. Weka and Vast are absurdly expensive at 2k / TB / year or so and are primarily designed for NVMEs, not spinning disks.&lt;/p&gt;
    &lt;head rend="h2"&gt;Post-Mortem&lt;/head&gt;
    &lt;p&gt;Building the datacenter was a large endeavor and we definitely learned lessons, both good and bad.&lt;/p&gt;
    &lt;head rend="h3"&gt;Things That We Got Correct&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We think the redundancy &amp;amp; capability tradeoffs we made are very reasonable at our disk speeds. We’re able to approximately saturate our 100G network for both read &amp;amp; write.&lt;/item&gt;
      &lt;item&gt;Doing this locally a couple blocks away was well worth it because of the amount of debugging and manual work needed.&lt;/item&gt;
      &lt;item&gt;Ebay is good to find vendors but bad to actually buy things with. After finding vendors, they can often individually supply all the parts we need and provide warranties, which are extremely valuable.&lt;/item&gt;
      &lt;item&gt;100G dedicated internet is pretty important, and much much easier to debug issues with than using cloud products.&lt;/item&gt;
      &lt;item&gt;Having high-quality cable management during the racking process saved us a ton of time debugging in the long run; making it easy to switch up the networking saved us a lot of headache.&lt;/item&gt;
      &lt;item&gt;We had a very strong simplicity prior, and this saved an immense amount of effort. We are quite happy that we didn’t use ceph or minio. Unlike e.g. nginx, they do not work out of the box. We were willing to write a simple Rust script and roughly saturated our network read &amp;amp; write at 100 Gbps without any fancy code.&lt;/item&gt;
      &lt;item&gt;We were basically right about the price and advantages this offered, and did not substantially overestimate the amount of time / effort it would take. While the improvements list is longer than this, most of those are minor; fundamentally we built a cluster rivaling massive clouds for 40x cheaper.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Difficult Bits&lt;/head&gt;
    &lt;p&gt;A map of reality only gets you so far—while setting up the datacenter we ran into a couple problems and unexpected challenges. We’ll include a list:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We used frontloaders instead of toploaders for our server rack. This meant we had to screw every single individual drive in—tedious for 2.4k HDDs&lt;/item&gt;
      &lt;item&gt;Our storage was not dense—we could have saved 5x the work on physical placement and screwing by having a denser array of hard drives&lt;/item&gt;
      &lt;item&gt;Shortcuts like daisy-chaining are usually a bad idea. We could have gotten substantially higher read/write speeds without daisy chaining networked nodes, giving each chassis its own HBA (Host Bus Adapter, not a significant cost).&lt;/item&gt;
      &lt;item&gt;Compatibility is key—specifically in networking functionally everything is locked to a specific brand. We had many pain points here. Fiber transceivers will ~never work unless used with the right brand, but copper cables are much more forgiving. FS.com is pretty good and well priced (though their speed estimates were pretty inconsistent); Amazon will also often have the parts you need rapidly.&lt;/item&gt;
      &lt;item&gt;Networking came at substantial cost and required experimentation. In general, with our relatively non-sensitive training data, we optimized for convenience and ease of use over all else: we did not use DHCP as our used enterprise switches didn’t support it out of the box, and we didn’t use NAT as we wanted public IPs for the nodes for convenient and performant access from our servers. (We firewalled off unused ports and had basic security with nginx secure_link; we would not be able to do this if handling customer data, but it was fine for our use case.) While this is an area where we would have saved time with a cloud solution, we had our networking up within days and kinks ironed out within ~3 weeks.&lt;/item&gt;
      &lt;item&gt;We were often bottlenecked by easy access to servers via monitor/keyboard; idle crash carts during setup are helpful.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Ideas Worth Trying&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Working KVMs are extremely useful, and you shouldn’t go without them or good IPMI. Physically going to a datacenter is really inconvenient, even if it’s a block away. IPMI is good, but only if you have pretty consistent machines.&lt;/item&gt;
      &lt;item&gt;Think through your management Ethernet network as much as your real network - it’s really nice to be able to SSH into servers while configuring the network, and IPMI is great!&lt;/item&gt;
      &lt;item&gt;Overprovision your network—e.g. if doable it’s worth having 400 Gigabit internally (you can use 100G cards etc for this!)&lt;/item&gt;
      &lt;item&gt;We could have substantially increased density at additional upfront cost by buying 90-drive SuperMicro SuperServers and putting 20TB drives into them. This would allow us to use 2 racks instead of 10, give us about the equivalent of 20 AMD 9654s in total CPU capacity, and use less total power.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;How You Can Build This Yourself&lt;/head&gt;
    &lt;p&gt;Here’s what you need to replicate our setup.&lt;/p&gt;
    &lt;head rend="h3"&gt;Storage&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;10 CPU head nodes.&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;We used Intel Rr2000 with Dual Intel Gold 6148 and 128GB of DDR4 ECC RAM per server (which are incredibly cheap and roughly worked for our use cases) but you have a lot of flexibility in what you use.&lt;/item&gt;
          &lt;item&gt;If you use the above configuration you likely won’t be able to do anything at all CPU-intensive on the servers (like on-device data processing or ZFS data compression / deduplication / etc, which is valuable if you’re storing non-video data).&lt;/item&gt;
          &lt;item&gt;Our CPU nodes cost $600 each—it seems quite reasonable to us to spend up to $3k each if you want ZFS / compression or the abiliy to do data processing on-CPU.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;100 DS4246 chassis—each can hold 24 hard drives.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;2,400 3.5 inch HDDs—need to be all SATA or all SAS in each chassis.&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;We would recommend SAS hard drives if possible [5] 5. if you use SAS drives you’ll need to deal with or disable mulipathing, which is reasonably simple as they roughly double speed over similar SATA drives.&lt;/item&gt;
          &lt;item&gt;We used a mix of 12TB and 14TB drives—basically any size should work, roughly the larger the better holding price constant (density makes stacking easier + in general increases resale value).&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Physical parts to mount the chassis—you’ll need rails or l-brackets. We used l-brackets which worked well, as we haven’t needed to take the chassis out to slot hard drives. If you buy toploaders, you’ll need rails.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Multiple “crash carts” with monitors and keyboards that allow you to physically connect to your CPU head nodes and configure them—this is invaluable when you’re debugging network issues.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Network&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;A 100 GbE switch&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;A used Arista is fine, should be QSFP28, should cost about $1-2k.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;HBAs (Host Bus Adapters), which connect your head nodes to your DS4246 chassis.&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;The best configuration we tried was with Broadcom 9305-16E HBAs, with 3x HBAs per server (make sure your server has physical space for them!) with SFF-8644 to QSFP mini SAS cables.&lt;/item&gt;
          &lt;item&gt;There are 4 slots per HBA, so you can cable each DS4246 chassis directly to the HBA. [6] 6. The option we ended up going with for convenience was putting LSI SAS9207-8e HBAs, which have 2 ports each, into the CPU head nodes- then daisy-chaining the DS4246s together with QSFP+ to QSFP+ DACs.. We deployed this on Storage Stacking Saturday, then while debugging speeds tried the above method on one of the servers and got to ~4 Gbps per chassis-but didn’t find it worth it to swap everything out in pure labor because of the way we had set up some of our head nodes such that they were difficult to take out. Insofar as it is reasonably cheap to just do the above thing to start and we’ve tested it to work, you should probably do as we say, not as we did in this case!&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Network cards (NICs).&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;We used Mellanox ConnectX-4 100GbE. Make sure they come in Ethernet mode and not Infiniband mode for ease of config.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;DAC (Direct Attach Copper) or AOC (Active Optical) cables, to connect the NICs in your head nodes to your switch and therefore the internet. You almost certainly want DACs if your racks are close together, as they are far more compatible with arbitrary networking equipment than AOCs.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We would recommend that you find a supplier to sell you the CPU head nodes with the HBAs and NICs installed—there are a number of used datacenter / enterprise parts suppliers who are willing to do this. This is a substantial positive because it means that you don’t have to spend hours installing the HBAs/NICs yourself and can have a substantially higher degree of confidence in your operations.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Serial cables—you’ll need these to connect to your switch!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Optional but recommended: an Ethernet management network of some kind. If you can’t easily get ethernet, we’d recommend getting a wifi adapter like this and then a ethernet switch like this —it’s substantially easier to set up than the 100GbE, is a great backup for when that’s not working, and will allow you to do ~everything over SSH from the comfort of the office instead of in the datacenter.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Datacenter Requirements&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;3.5 kW of usable power per cabinet, with 10 4U chassis + 1 2U (cabinets are 42U tall)&lt;/item&gt;
      &lt;item&gt;1 spare cabinet for the 1U or 2U 100GbE switch (you can obviously also just swap out one of the 4U chassis in another cabinet for the switch).&lt;/item&gt;
      &lt;item&gt;1 42U cabinet per 3 PB of storage&lt;/item&gt;
      &lt;item&gt;A dedicated 100G connection (will come in as a fiber pair probably via QSFP28 LR4, but confirm with your datacenter provider before buying parts here!)&lt;/item&gt;
      &lt;item&gt;Ideally physically near your office—there is a lot of value in being able to walk over and debug issues instead of e.g. dealing with remote hands services to get internet to the nodes.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Some setup tips:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Make sure to first properly configure your switch. Depending on your switch model this should be relatively straightforward—you’ll need to physically connect to the switch and then configure the specific port that your 100GbE is connected to (you’ll get a fiber cross-connect from your datacenter that you should plug into a QSFP28 transceiver. Make sure that you get a transceiver that is compatible in form with the ISP, probably LR4, and specifically branded with your switch brand, otherwise it is very unlikely to work). Depending on your ISP you might have to talk to them to make sure that you can get “light” through the fiber cables from both ends, which might involve rolling the fiber and otherwise making sure it’s working properly. &lt;list rend="ul"&gt;&lt;item&gt;If your switch isn’t working / you haven’t configured one before, I’d suggest trying to directly plug the fiber cable from the ISP into one of your 10 heap servers, making sure to buy a transceiver that is compatible with your NIC brand (e.g. Mellanox). Once you get it working from there, move over to your switch and get it working.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Once you can connect to the internet from your switch (simply ping 1.1.1.1 to check) you are ready to set up the netplans for the individual nodes. this is most easily done during the Ubuntu setup process, which will walk you through setting up internet for your CPU head nodes, but is also doable outside of that&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Once you have internet access to your nodes and have properly connected 1 cable to each DS4246, you should format &amp;amp; mount the drives on each node, test that all of them are properly working, and then you are ready to deploy any software you want.&lt;/p&gt;
    &lt;p&gt;If you end up building a similar storage cluster based on this writeup we’d love to hear from you—we’re very curious what can be improved, both in our guidance and in the object-level process. You can reach us at [email protected]&lt;/p&gt;
    &lt;p&gt;If you came away from this post excited about our work, we’d love to chat. We’re a research lab currently focused on pretraining models to use computers, with the long-term goal of building general models that can learn in-context and do arbitrary tasks while aligned with human values; we’re hiring top researchers and engineers to help us train these. If you’re interested in chatting, shoot us an email at [email protected].&lt;/p&gt;
    &lt;head rend="h3"&gt;Collaborators&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Neel Redkar&lt;/item&gt;
      &lt;item&gt;Devansh Pandey&lt;/item&gt;
      &lt;item&gt;Nicholas Charette&lt;/item&gt;
      &lt;item&gt;Galen Mead&lt;/item&gt;
      &lt;item&gt;Yudhister Kumar&lt;/item&gt;
      &lt;item&gt;Robert Avery&lt;/item&gt;
      &lt;item&gt;Raj Thimmiah&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45438496</guid><pubDate>Wed, 01 Oct 2025 15:00:41 +0000</pubDate></item><item><title>Gmail will no longer support checking emails from third-party accounts via POP</title><link>https://support.google.com/mail/answer/16604719?hl=en</link><description>&lt;doc fingerprint="fda843131f22facd"&gt;
  &lt;main&gt;&lt;p&gt;Starting January 2026, Gmail will no longer provide support for the following:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Gmailify: This feature allows you to get special features like spam protection or inbox organization applied to your third-party email account. Learn more about Gmailify.&lt;/item&gt;&lt;item&gt;POP: Unlike IMAP connections, with POP, emails are downloaded, and you decide how often you want to download new emails. As an alternative, you can still link your third-party accounts in the Gmail app.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;These changes help provide the most secure and current options to access your messages in Gmail.&lt;/p&gt;&lt;head rend="h2"&gt;Learn about changes to Gmailify&lt;/head&gt;&lt;p&gt;You won’t be able to get specific features in Gmail applied to your third-party account, like:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Spam protection&lt;/item&gt;&lt;item&gt;Better email notifications on mobile&lt;/item&gt;&lt;item&gt;Inbox categories&lt;/item&gt;&lt;item&gt;Faster search with advanced search operators&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;What you need to do&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;You can still read and send emails from your other account within the Gmail app. This uses a standard IMAP connection, which is supported in the Gmail mobile app.&lt;/item&gt;&lt;item&gt;Learn how to add another email account to the Gmail app.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Learn about changes to POP connections&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Gmail will no longer support checking emails from third-party accounts through POP.&lt;/item&gt;&lt;item&gt;The option to "Check mail from other accounts" will no longer be available in Gmail on your computer.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;What you need to do&lt;/head&gt;&lt;p&gt;Important: If you have a work or school account, your administrator can help migrate your email data into Google Workspace. Learn more about the data migration service.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;To continue to receive messages from your other account in Gmail, you need to set up IMAP access. &lt;list rend="ul"&gt;&lt;item&gt;Check your email provider’s documentation for instructions on how to enable IMAP for your account.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;To read your messages from your other account, use the Gmail app. Learn how to add another email account to the Gmail app.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Frequently asked questions&lt;/head&gt;Will I lose the emails I already imported?&lt;p&gt;No. All messages synced before the deprecation stay in Gmail.&lt;/p&gt;&lt;p&gt;Yes. For third-party accounts like Yahoo! and Outlook, you can add them to the Gmail mobile app on Android and iPhone and iPad.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45439670</guid><pubDate>Wed, 01 Oct 2025 16:25:58 +0000</pubDate></item><item><title>Cormac McCarthy's personal library</title><link>https://www.smithsonianmag.com/arts-culture/two-years-cormac-mccarthys-death-rare-access-to-personal-library-reveals-man-behind-myth-180987150/</link><description>&lt;doc fingerprint="77a350d52da307b7"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Two Years After Cormac McCarthy’s Death, Rare Access to His Personal Library Reveals the Man Behind the Myth&lt;/head&gt;
    &lt;head rend="h2"&gt;The famously reclusive novelist amassed a collection of thousands of books ranging in topics from philosophical treatises to advanced mathematics to the naked mole-rat&lt;/head&gt;
    &lt;p&gt;Cormac McCarthy, one of the greatest novelists America has ever produced and one of the most private, had been dead for 13 months when I arrived at his final residence outside Santa Fe, New Mexico. It was a stately old adobe house, two stories high with beam-ends jutting out of the exterior walls, set back from a country road in a valley below the mountains. First built in 1892, the house was expanded and modernized in the 1970s and extensively modified by McCarthy himself, who, it turns out, was a self-taught architect as well as a master of literary fiction.&lt;/p&gt;
    &lt;p&gt;I was invited to the house by two McCarthy scholars who were embroiled in a herculean endeavor. Working unpaid, with help from other volunteer scholars and occasional graduate students, they had taken it upon themselves to physically examine and digitally catalog every single book in McCarthy’s enormous and chaotically disorganized personal library. They were guessing it contained upwards of 20,000 volumes. By comparison, Ernest Hemingway, considered a voracious book collector, left behind a personal library of 9,000.&lt;/p&gt;
    &lt;p&gt;What makes McCarthy’s library so intriguing is not just its size, nor the fact that very few people know about it. His books, many of which are annotated with margin comments, promise to reveal far more about this elusive literary giant than the few cagey interviews he gave when he was alive. For as long as people have been reading McCarthy, they have speculated about which books and authors informed and inspired his work, a subject he was loath to discuss. They have wondered about his interests and true personality because all he presented to the public was a reclusive, austere, inscrutable facade.&lt;/p&gt;
    &lt;p&gt;When Bryan Giemza, a scholar of literature and humanities at Texas Tech University, offered me exclusive journalistic access to McCarthy’s library and the cataloging project, what he was really offering was an unprecedented insight into McCarthy’s life and work. As a further enticement, he said that Cormac’s younger brother Dennis McCarthy would be there. “Dennis probably knew him as well as anyone,” Giemza said.&lt;/p&gt;
    &lt;head rend="h4"&gt;Did You Know? Who was Cormac McCarthy?&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cormac McCarthy is an award-winning novelist whose works often explored the American West with darkness and complexity. Among McCarthy's many awards are a Guggenheim Fellowship in 1969, a MacArthur Fellowship in 1981, a Pulitzer Prize for Fiction in 2007 for The Road and a National Book award in 1992 for All the Pretty Horses.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I parked behind the house between a silver 1966 Buick Riviera rusting on deflated tires and a weathered red Lincoln Mark VIII. These were among the last survivors of McCarthy’s little-known vehicle collection. Dennis had sold 13 other cars, including two Allard racing cars from the early 1950s, a 1992 Lotus and a Ford GT40 racing car. McCarthy, who labored in obscurity and chronic poverty until he was 60, became a multi-millionaire later in life and freely indulged his desires and obsessions, with classic sports cars high on the list. Most of the money came from Hollywood, which turned three of his novels—All the Pretty Horses, No Country for Old Men and The Road—into star-studded movies.&lt;/p&gt;
    &lt;p&gt;I knocked on the imposing front door, an Indo-Portuguese antique made of teak and fortified with iron strappings, metal studs, flattened nails and small chains. There was no response, so I tried the handle. The door swung open and revealed a dimly lit hallway reduced to a narrow passage by head-high stacks of cardboard boxes on both sides. All those boxes were packed with books.&lt;/p&gt;
    &lt;p&gt;The first room off the hallway—the room where McCarthy died at age 89—was now so crammed with book boxes that it was impenetrable. Scholars called it “the Beast Room.” The next room was nearly as full. One open box showed volumes about the architect Frank Lloyd Wright, country houses in Ireland, schizophrenia, African history and British antique rifle barrels.&lt;/p&gt;
    &lt;p&gt;In the dining room, underneath a beautiful hanging light fixture of wood and colored glass that McCarthy designed and built himself, scholars were sitting at the table, scanning books’ ISBN bar codes through their phones into the library cataloging software on their laptops.&lt;/p&gt;
    &lt;p&gt;I found Giemza in the living room, wrestling with an internet connectivity problem. “Cormac didn’t have Wi-Fi in the house, so we had to bring our own,” he said. Nor did McCarthy use a computer—ever. He typed out his pages on a cheap, durable Olivetti typewriter and, I learned later, did most of his work propped up on pillows in bed.&lt;/p&gt;
    &lt;p&gt;The living room, like the house in general, had a sturdy, old-fashioned and decidedly masculine feel, but its clean lines were obscured by a chaotic overlay of clutter—mainly books, but also piles of nameless junk and hundreds of bowls, glasses and kitchenware items still in their packaging. Some of the book boxes and loose books had been moved into the room for the cataloging project, but not the rest of it. One of the first discoveries made by the visiting scholars was that McCarthy was something of a hoarder. His particular fixation on kitchenware, much of it bargain kitchenware, remains mysterious and a mark of his eccentricity.&lt;/p&gt;
    &lt;p&gt;The second major discovery, discernible in his work but confirmed beyond doubt in his library, was that McCarthy was a genius-level intellectual polymath with an insatiable curiosity. His interests ranged from quantum physics, which he taught himself by reading 190 books on the notoriously challenging subject, to whale biology, violins, obscure corners of French history in the early Middle Ages, the highest levels of advanced mathematics and almost any other subject you can name.&lt;/p&gt;
    &lt;p&gt;Giemza marveled at the heavy-duty philosophy books they were finding. “Seventy-five titles by or about Wittgenstein so far,” he said, referring to the Austrian philosopher of mathematics, logic, language and the mind. “And most of them are annotated, meaning Cormac read them closely. A lot of Hegel. That was his light evening reading, apparently.”&lt;/p&gt;
    &lt;p&gt;In the living room was a pool table piled with books and a leather couch facing two tall windows and three sets of nine-foot-tall wooden bookshelves designed by McCarthy that held approximately 1,000 books. Moving closer, I saw they were nearly all nonfiction hardbacks with no obvious system of organization.&lt;/p&gt;
    &lt;p&gt;One shelf held volumes about Mesoamerican&lt;lb/&gt; history and archaeology, along with Charles Darwin’s collected notebooks, Victor Klemperer’s three-volume diary of the Nazi years, books about organic chemistry and sports cars, and an obscure volume titled The Biology of the Naked Mole-Rat (Monographs in Behavior and Ecology). Another shelf held books about Grand Prix and Formula 1 racing, a great passion of McCarthy’s, and the collected writings of Charles S. Peirce, the American scientist, philosopher and logician, in six fat volumes of dense, difficult prose. &lt;/p&gt;
    &lt;p&gt;Trying to take it all in, I felt both fascinated and overwhelmed. It seemed almost inconceivable that an author who produced 12 novels, two plays and five screenplays had also found the time, energy and brainpower to master architecture, woodworking, stonemasonry and a wide range of intellectual disciplines. Some of his math books were nearly all equations.&lt;/p&gt;
    &lt;p&gt;Then we found an intricate drawing he’d made for an engine modification to one of his cars, and another showing how to rifle a gun barrel with hand tools. We found dozens of well-thumbed engine repair manuals and auto mechanic’s tools in the outbuildings, and learned that he could disassemble, reassemble and redesign an engine to increase its horsepower. Then I learned he had an eidetic memory and could remember nearly everything he had read or heard, including the lyrics to thousands of songs. McCarthy was starting to seem like a man whose talents and intelligence were without limits, yet he lived in a hoarder’s shambles and couldn’t stop buying nonstick skillets and fruit bowls.&lt;/p&gt;
    &lt;p&gt;By studying his library more closely, I hoped to gain a better understanding of McCarthy, but it was possible the mystery of his character would only deepen.&lt;/p&gt;
    &lt;p&gt;Giemza introduced me to his colleague Stacey Peebles, a professor of film and English at Centre College in Danville, Kentucky, and the current president of the Cormac McCarthy Society. It was Peebles who first met with Dennis McCarthy, the author’s brother and literary executor, and suggested that the society take on the monumental task of cataloging the books. The society’s mission is to further the study and appreciation of McCarthy’s work, and Peebles thought there was enough material in the library to keep scholars busy for decades—scrutinizing the annotations, tracing connections between the research books and passages in the novels, interpreting literary and philosophical influences. “If we were a well-funded institution, we’d take all these boxes into an empty building where we had plenty of space to work in, a dedicated team of people and all the time we needed,” she said. But Peebles and her small team all have full-time jobs, so the project has required a trade-off between detail and efficiency. “We can’t be as meticulous as we’d like and scan all the annotations, because we’ve got limited time and a massive amount of books to get through.”&lt;/p&gt;
    &lt;p&gt;McCarthy often had a pencil when he was reading and would make tiny vertical marks next to sentences that interested him and add comments in the margins in small print handwriting. Sometimes he jotted down thoughts on slips of paper that he left between the pages. Inside The Life of Saint Teresa of Ávila by Herself, first published in 1565, we found him musing philosophically: “There is an intelligence to the universe (of which we are fractal) and that intelligence has a character and that character is benign. Intends well toward all things. How could it not?”&lt;/p&gt;
    &lt;p&gt;McCarthy is known for the bleak, violent nihilism in many of his novels, so it was a surprise to see him describing the universe as intelligent and well-&lt;lb/&gt; intentioned. He was a lapsed Catholic who went back and forth on the question of God’s existence, sometimes changing his mind from one day to the next. &lt;/p&gt;
    &lt;p&gt;Peebles was collecting her favorite annotated books on the pool table. One was Realism in Mathematics by Penelope Maddy. In the margins, Mc-&lt;lb/&gt; Carthy summarizes the author’s points and comments on them, frequently disagreeing. “Gibberish,” he noted at one point. It was an exciting find for the scholars because McCarthy mined this book deeply for his final novel, Stella Maris. Its protagonist, Alicia Western, is a young mathematical genius with schizophrenia.&lt;/p&gt;
    &lt;p&gt;Another of Peebles’ favorite finds is an annotated copy of Shakespeare’s Hamlet. McCarthy, who once said, “the ugly fact is books are made out of books,” borrowed and altered elements from Hamlet for his 1979 novel Suttree. It was his most ornate and poetic book and the closest he ever came to writing autobiographically. The main character is a troubled dropout who has rejected a life of privilege and responsibility in Knoxville, Tennessee, where McCarthy grew up as the black sheep among six children in a well-to-do Catholic family with strong Irish roots.&lt;/p&gt;
    &lt;p&gt;He was born in 1933 and christened Charles Joseph McCarthy Jr. after his father. In his youth, he was known as Charlie, or sometimes Doc, until he changed his name to Cormac as a young man, partly inspired by the medieval Irish king Cormac mac Airt. The name change was probably also a declaration of independence from his father. Charles McCarthy Sr. was an attorney who became the chief counsel for the Tennessee Valley Authority, and Cormac always characterized him as a domineering, violent man who beat him viciously for trivial offenses. (His brother Dennis disputes this description and says that Cormac was “grossly exaggerating.“)&lt;/p&gt;
    &lt;p&gt;McCarthy told his own son John, and some of his friends, that the beatings started when he was 3 years old. Readers and critics have often wondered where the darkness and violence in McCarthy’s work comes from, and, if Cormac’s characterization is true, his childhood might account for some of it. He loved his mother, Gladys, but she was psychologically fragile and frequently absent from the family in mental health institutions.&lt;/p&gt;
    &lt;p&gt;He hated his Catholic school and loved roaming outdoors. Talking about his school days in a (rare) 1992 interview, McCarthy said, “There was no hobby I didn’t have, name anything, no matter how esoteric, I had found it and dabbled in it.” He made money trapping muskrats around Knoxville and selling the pelts, and somehow also established himself as an authority on antique American rifles.&lt;/p&gt;
    &lt;p&gt;In 1953, McCarthy dropped out of the University of Tennessee, where he was studying engineering and physics, and joined the Air Force. He was stationed in Anchorage, where he became the radio disc jockey for the base, and started reading in earnest in his spare time. After four years, he returned to the University of Tennessee but dropped out again and started writing novels.&lt;/p&gt;
    &lt;p&gt;The first three, The Orchard Keeper, Outer Dark and Child of God, were gothic tales set in the rural Appalachia he knew from his youth. In lyrical prose with marvelously rendered vernacular speech, they tackled dark subjects—murder, infanticide, incest, necrophilia—while displaying a reverence for nature and folk traditions. The fourth novel was Suttree, McCarthy’s richly comedic evocation of 1950s Knoxville. These novels earned critical praise and prestigious grants and awards, but each sold more poorly than the last.&lt;/p&gt;
    &lt;p&gt;One of the few details we have about McCarthy’s personal life comes from his second wife, Anne&lt;lb/&gt; DeLisle, an English singer and dancer, whom he met on a ship to Ireland in 1965. Their home was a partially converted dairy barn outside Knoxville; they bathed in a lake. “Someone would call up and offer him $2,000 to come speak at a university about his books,” she once said. “And he would tell them that everything he had to say was there on the page. So we would eat beans for another week.”&lt;/p&gt;
    &lt;p&gt;After leaving her without an explanation in 1974, McCarthy drifted around cheap motels with his typewriter, a pile of books and a light bulb for good reading light. In 1976 McCarthy took up residence in El Paso and turned his attention on the American Southwest and northern Mexico, setting himself the task of learning the culture, history, natural history, geology, folkways and distinctive Spanish idioms of the borderlands.&lt;/p&gt;
    &lt;p&gt;According to a letter he wrote, McCarthy read over 300 books to research Blood Meridian (1985), an ultraviolent philosophical Western based on the true story of a state-funded scalp-hunting gang in the 1840s and 1850s. Now widely regarded as his greatest masterpiece, it sold a pitiful 1,883 copies when it was first published. McCarthy’s fortunes changed with the publication of All the Pretty Horses in 1992. This elegiac Western, set in 1949 and 1950 in Texas and Mexico, became a best seller, won a National Book Award, and was adapted into a movie starring Matt Damon and Penélope Cruz. McCarthy followed with two more novels about drifting cowboys, then shifted course with No Country for Old Men (2005), a crime thriller that the Coen brothers turned into a quadruple-Oscar-winning movie starring Josh Brolin, Javier Bardem and Tommy Lee Jones. Next came The Road, a post-apocalyptic father-son journey that won the Pulitzer Prize for fiction in 2007 and was made into a film with Viggo Mortensen playing the father.&lt;/p&gt;
    &lt;p&gt;McCarthy had moved to Santa Fe with his third wife, Jennifer Winkley, and their young son John in 2001. He found the town off-puttingly liberal, moneyed and artsy, and moved there for one reason only: His great friend Murray Gell-Mann, the Nobel Prize-winning physicist, invited him to join the Santa Fe Institute, serving as a sort of in-house literary intellectual. This elite scientific think tank, co-founded by Gell-Mann, brings together some of the world’s most brilliant minds to research complex interconnected systems. McCarthy had long preferred the company of scientists to that of literary people, and he delighted in the high-flying conversations at the institute. He went there nearly every day to work on his writing and kept up with all the institute’s scientific research.&lt;/p&gt;
    &lt;p&gt;McCarthy was famous for refusing to discuss his work, so there was widespread amazement in literary quarters when he agreed to do a televised interview in 2007 with Oprah Winfrey, who had picked The Road as her book club selection. Viewers saw a courteous, gray-haired Southerner with a high-domed forehead and a flashing smile. When Oprah asked if he was “passionate” about writing, he replied, “Passionate sounds like a pretty fancy word.”&lt;/p&gt;
    &lt;p&gt;Oprah, knowing it was true, asked if The Road was a love story to his young son John. “In a way, I suppose, that’s kind of embarrassing,” he said. She made slightly better headway on the subject of punctuation. McCarthy didn’t use quotation marks, hated semicolons and kept commas to the barest minimum. “There’s no reason to block the page up with weird little marks,” he said. “If you write properly, you shouldn’t have to punctuate.”&lt;/p&gt;
    &lt;p&gt;McCarthy could pull it off because he was a virtuoso, renowned for his powers of description and ear for dialogue. The Nobel Prize-winning novelist Saul Bellow extolled McCarthy’s “absolutely overpowering use of language, his life-giving and death-dealing sentences.” McCarthy’s detractors, meanwhile, found his writing overly mannered, his characters overly masculine, and accused him of relishing the violence he wrote about so vividly.&lt;/p&gt;
    &lt;p&gt;When McCarthy died in June 2023, after battling leukemia, prostate cancer, dehydration and what he once called “the sheer velocity of time,” the accolades were immediate, and fulsome. Stephen King called him the “last great white male American novelist.” Sebastian Junger compared him to Mount Everest. The Guardian headlined its remembrance with a prophecy: “His work will sing down the centuries.”&lt;/p&gt;
    &lt;p&gt;Dennis McCarthy, the youngest of the six children, made his way through the book-choked hallway into the book-strewn living room. A retired lawyer, editor and conservation biologist, Dennis published his first novel in 2021, a spiritual Western about Billy the Kid. Now 81, he was fit and trim, with blue eyes, a radiant smile and a strong resemblance to Cormac. “He was my best friend for 70 years and a fabulous older brother who always looked out for me,” he said. “We were very, very close.”&lt;/p&gt;
    &lt;p&gt;I asked him which authors his brother most admired. “Moby-Dick was Cormac’s favorite book without question, and Faulkner was more of an influence than he liked to admit,” he said. “He loved Hemingway’s short stories, James Joyce, Dostoyevsky and Shakespeare of course.” Readers and scholars had already identified these literary forebears, but it was satisfying to hear them confirmed.&lt;/p&gt;
    &lt;p&gt;Of the many thousands of books in the house, the basement and the outbuildings, how many had McCarthy actually read? “If you exclude the encyclopedias and reference books, I would guess about 85 percent,” Dennis said. “Cormac kept on ordering books after he was too sick and frail to read, because it was a compulsion, but until that point he would read for hours and hours nearly every day. He never left the house without a book. He never left the house without a gun. Both were equally unthinkable.”&lt;/p&gt;
    &lt;p&gt;Why was he always armed? “He was a conservative country boy from the South who understood that the world is a dangerous place.” When he was 24, McCarthy accidentally shot himself in the leg while practicing alone on a gun range in Tennessee. Dennis didn’t know any more details, because his brother refused to discuss the incident, but it was likely a quick-draw gone wrong.&lt;/p&gt;
    &lt;p&gt;When I asked Dennis about his brother’s reputation as a recluse, he said it was totally inaccurate. “He was very sociable and could get along with anybody. Well, almost anybody. He didn’t suffer fools gladly, or people who rushed up to him gushing about his books. But he had a lot of friends, and he loved dining and conversation, and five-hour lunches that sometimes turned into ten-hour lunches.”&lt;/p&gt;
    &lt;p&gt;Those friends included physicists and quark-discoverers Gell-Mann and George Zweig, the whale biologist Roger Payne, the movie star Josh Brolin, plus a bar owner in Tucson who calls himself God and a silver-tongued con man from Knoxville named John Sheddan, who appears exactly as himself under his own name in McCarthy’s penultimate novel, The Passenger.&lt;/p&gt;
    &lt;p&gt;Brolin got to know McCarthy during the filming of No Country for Old Men and was at the author’s bedside the night before he died. “It was me, his ex-wife, his son John, and that was it,” Brolin tells me on the phone. “He was telling these wild stories, about drinking wine with André the Giant in Paris, and all this stuff was coming out totally lucid, sharp, funny, inspired. Then he would go into this lost dementia and he’d be grabbing at stuff that wasn’t there. Then he’d go to sleep, and then he’d wake up and tell another story.” Soon after Brolin left, McCarthy drew his final breath.&lt;/p&gt;
    &lt;p&gt;McCarthy’s son John, the model for the boy character in The Road, was now 26 and sleeping in his father’s old bedroom upstairs. He’s a licensed pilot, a composer and a musician. The first time I met John, he was coming sleepily down the wooden stairs in search of coffee. I had just learned that Dennis had emptied two storage units full of books in El Paso and two more in Santa Fe and moved the boxes into the house for cataloging. “So I’m getting a totally unrealistic picture of what the house was like when you were growing up here,” I said to John.&lt;/p&gt;
    &lt;p&gt;“Not really,” he said. “This is pretty much how it was. Boxes everywhere. Piles of books everywhere. The hallway stacked up with boxes with a little path through the middle. Whole rooms so full of books you couldn’t go in there. It didn’t bother me at all.”&lt;/p&gt;
    &lt;p&gt;It was John who told me that McCarthy worked in bed—a California king with high-thread-count sheets, the Olivetti on a wooden platform with a leather pillow underneath it, and piles of typed pages, magazines, books and catalogs. Writing, McCarthy once said, was not a conscious process for him. He put a blank piece of paper in the Olivetti, the words arrived, and he typed them down. But that was just the first stage of an extensive rewriting and structuring process, and some of his books took 20 years or more to get right.&lt;/p&gt;
    &lt;p&gt;“Dad didn’t like being interrupted when he was working, or when he was reading,” John said. “‘No, no, no. I’m reading. Go away!’ he would say. But he was a great father, always there for me, and I learned so much from him. We would have these long conversations about science and history and music, and whatever else, and he was the funniest person I’ve ever met, just a natural comedian.”&lt;/p&gt;
    &lt;p&gt;I asked John what else his father collected apart from books, cars and kitchenware. “I would say clothes were the other big one. He had hundreds of tweed jackets, hundreds of shirts, hundreds of suits that he’d never worn.” John once spent three days dragging stuff out of a room he wanted to use as a bedroom. “When I was done, I said, ‘You ever think you might be a little bit of a hoarder?’ And he looks at me and he goes, ‘Yeah, probably.’ He attributed it to all those years when he had no money.”&lt;/p&gt;
    &lt;p&gt;Dennis isn’t buying that explanation. “Cormac always lived in chaos, which I found fascinating because he had such a fabulous artistic sense. He could design things beautifully and he dressed impeccably, but his living quarters were always a disaster. He was an incredibly complicated individual.”&lt;/p&gt;
    &lt;p&gt;The cataloging scholars could only spare four or five days at a time. Then they would go back to their jobs for a few months and try to carve out another long weekend in New Mexico. The stalwarts were Peebles and Rick and Jonathan Elmore, whip-smart twin brothers who looked nothing alike, taught at different colleges and wrote academic papers together about McCarthy’s work.&lt;/p&gt;
    &lt;p&gt;The cataloging was dusty, repetitive, eye-straining work, but it was conducted with good humor and camaraderie, and you never knew what might come out of the next box. One afternoon, after looking through a batch about Cistercian abbeys, violin makers, metaphysics, meta-ontology, the incest taboo and the material foundations of ancient Mesopotamian civilization, I said, “Was there anything he wasn’t interested in? Sewing perhaps?”&lt;/p&gt;
    &lt;p&gt;“Nope,” said Jonathan Elmore, an English professor at Louisiana Tech University. “We’ve cataloged books on needlework and quilting.” Rick noted McCarthy’s keen interest in clothes and fashion, which could, I granted, be described as sewing-related. McCarthy was a longtime subscriber to the fashion and style magazine W, and he had annotated many of his books about menswear. In his copy of The Suit: A Machiavellian Approach to Men’s Style, McCarthy penciled his opinion of slip-on dress shoes: “disgusting.” Further down the same page, next to a sentence praising shiny-buckled monk-strap shoes, he wrote, “yet more horror.”&lt;/p&gt;
    &lt;p&gt;The scholars treated annotations like pieces of treasure and would read them aloud to each other. Inside Reclaiming History: The Assassination of President John F. Kennedy, they found notes on a slip of paper, including a line about the assassin’s bullet: “it was going like a bat out of hell when it left the president’s head and in that crowd it is a pure freak of chance that it didn’t take out a citizen-spectator.”&lt;/p&gt;
    &lt;p&gt;The historical figures who interested McCarthy the most, judging by the number of books he owned about them, were Albert Einstein (114 books), Winston Churchill (88) and James Joyce (78). Architecture is the dominant subject in the collection, with 855 books. The human being whom McCarthy most admired, Dennis confirms, was Ludwig Wittgenstein. The team cataloged a staggering 142 books by or about the philosopher, with a high proportion annotated.&lt;/p&gt;
    &lt;p&gt;McCarthy’s fascination with Wittgenstein came as a surprise to the scholars, but it makes sense. As Rick Elmore, a philosophy professor at Appalachian State University with floral tattoos climbing up his neck, puts it, “Wittgenstein was always asking how the systems we use to represent the world relate to the world we want to represent. It’s one of the central questions in McCarthy’s work.”&lt;/p&gt;
    &lt;p&gt;With the exception of Moby-Dick in multiple, gorgeous leather-bound editions, the scholars found hardly any novels until they started cutting open boxes that Dennis retrieved from a storage locker in El Paso. Out came the entire canon of Western literature, from ancient Greece and Rome to the best novelists, poets and essayists of the 1970s, nearly all in cheap, worn, paperback editions. “These are the books that he read in his 20s and 30s and maybe into his 40s, and he was broke that whole time,” said Dennis. “Once he got money, Cormac bought all his books in hardback if possible, and for the last 40 years of his life he read almost no fiction at all.”&lt;/p&gt;
    &lt;p&gt;Why? The answer stems from McCarthy’s deeply disparaging view of modern society, which he considered lost, divorced from nature, history and tradition and heading toward social collapse and apocalypse. “Cormac considered contemporary fiction a waste of time,” said Dennis, “because contemporary writers no longer have a legitimate culture to feed their souls.”&lt;/p&gt;
    &lt;p&gt;One afternoon, Dennis was marveling at McCarthy’s storytelling abilities and comedic talents, and I asked him if there was anything, apart from housekeeping, that his brother had been bad at. He thought about it for a moment and said, “Marriage.”&lt;/p&gt;
    &lt;p&gt;McCarthy was married and divorced three times. “His wives needed more than he gave them,” Dennis said. “The work always came first for Cormac. He loved those women, but he loved himself more. He was a narcissist. And if he hadn’t been a narcissist, he never would have achieved the same heights of artistic greatness.”&lt;/p&gt;
    &lt;p&gt;The most enduring love of McCarthy’s life was a woman named Augusta Britt. As she revealed last year in interviews with Vanity Fair magazine, they began a sexual relationship when she was 17 and he was 43, and he took her to Mexico to evade the FBI, who were after him for statutory rape and Mann Act violations. Britt has said she didn’t feel sexually exploited and credits McCarthy for saving her life by rescuing her from an abusive situation in Tucson, but some readers and commentators have found McCarthy’s behavior with her beyond the pale. (Britt declined to comment for this piece.)&lt;/p&gt;
    &lt;p&gt;McCarthy and Britt were together as a couple for about four years. Even after they split up, “He never stopped loving her,” Dennis said. “He continued to see her on a regular basis, and they maintained a close relationship for the rest of his life.”&lt;/p&gt;
    &lt;p&gt;Piece by piece, the inscrutable mystique that McCarthy built around himself is falling away. Two biographies are on the way to publication, one by a friend of McCarthy’s named Laurence Gonzales, the other by literary biographer Tracy Daugherty, and Britt might collaborate on a book with Vincenzo Barney, who wrote her story in Vanity Fair. We also have McCarthy’s library, which perhaps more than any other source can illuminate the mind of the man who, as Peebles says, “built his life on books.”&lt;/p&gt;
    &lt;p&gt;On the first day of the final cataloging session, Peebles let out a hooting sound upon finding a dead bat at the bottom of a box. The downstairs of the house had been steadily accumulating dust for more than two years, since McCarthy’s death, and it was still crammed with books. The McCarthy scholars—Cormackians, as they call themselves—repacked the cataloged books, wrote the date and “Cataloged CMS” for Cormac McCarthy Society, and stacked them up wherever space could be found. The annotated books went into separate boxes marked “annotated” or were piled up on the pool table. The dead bat was left in the bottom of a book box.&lt;/p&gt;
    &lt;p&gt;When the project began, Peebles had hoped that all the books could be kept together in a single collection in some sort of Cormac McCarthy memorial building, but that wasn’t panning out. Dennis had arranged for the annotated books to join his brother’s papers, which include the notes and drafts for his entire body of work, at the Wittliff Collections archive at Texas State University. The Santa Fe Institute wanted a selection of the most intellectually rigorous academic books for a small library it was planning to build in honor of McCarthy. The rest of the books were going to the University of Tennessee in Knoxville, where he enrolled twice and failed to graduate.&lt;/p&gt;
    &lt;p&gt;In the digital realm, however, McCarthy’s library will live on as a complete entity, and the public will be able to inspect its cataloged titles free of charge. “Our goal, right from the outset, was to create an open-access database listing all the books in his collection,” Peebles said. “Anyone who wants to know what books McCarthy was reading, and whether he annotated them, will be able to log on and access that information.” The University of South Carolina Press has agreed to partner with Peebles to create a website for this purpose, and to publish a monograph by Peebles about the cataloging project. There’s talk of scanning all the annotations at some point and making them available on the website, but that is still theoretical.&lt;/p&gt;
    &lt;p&gt;Almost exactly a year after the project began, Peebles opened the very last box. Perhaps the best adjective for its contents is Cormackian. Peebles pulled them out and announced books about Mexican architecture and the French Renaissance court, Kierkegaard’s metaphors and the Texas Rangers, the neurobiology of mental illness, architecture and society in Normandy from 1120 to 1270, and the Gun Digest book of assault weapons.&lt;/p&gt;
    &lt;p&gt;She was unable to calculate the total number of books because the cataloging software didn’t account for multi-volume works. McCarthy’s 36-volume history of Utah, for example, registered as a single entry. Nor did the software tally multiple editions of the same book, so McCarthy’s 13 copies of Moby-Dick registered as one entry. The total number of entries was 18,520. Taking into account duplicate copies and multi-volume works, Peebles felt confident that McCarthy’s library contained just over 20,000 books, with 2,170 annotated.&lt;/p&gt;
    &lt;p&gt;Driving away from the house, with the taste of old book dust in my mouth, I marveled at the extraordinary force of McCarthy’s curiosity. I thought about the books on acousto-optics and lay intellectuals in the ninth-century Carolingian Empire. The $2,200 he spent on eight volumes of Horace Walpole’s collected letters. The $10,000 in several uncashed royalty checks that he used as a bookmark in the memoir of William Faulkner’s niece. To peer into someone’s library is to peer into their brain, and here, it seemed, was a mind that wanted to know everything.&lt;/p&gt;
    &lt;p&gt;Editors’ note: After the print version of this story was published, this version of the piece was updated with further comment from Dennis McCarthy. Also, on September 8, 2025, this article was updated with further details about the University of South Carolina Press’ involvement in this archival project.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45444694</guid><pubDate>Wed, 01 Oct 2025 23:06:55 +0000</pubDate></item><item><title>Immich v2.0.0 – First stable release</title><link>https://github.com/immich-app/immich/discussions/22546</link><description>&lt;doc fingerprint="6f5246cb5a87e72a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;v2.0.0 - Stable Release of Immich #22546&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;head&gt;v2.0.0 - Stable Release of Immich&lt;/head&gt;
          &lt;head&gt;Welcome&lt;/head&gt;
          &lt;p&gt;Hello everyone,&lt;/p&gt;
          &lt;p&gt;After:&lt;/p&gt;
          &lt;p&gt;We are thrilled to announce the stable release of Immich! 🎉&lt;/p&gt;
          &lt;p&gt;This has been a journey long in the making. So much has changed since the first commit on the project, all the way back in February, 2022. The project and team continue to grow, and today we’re proud to announce &lt;/p&gt;
          &lt;p&gt;For more specifics about the stable release, see our FAQs below.&lt;/p&gt;
          &lt;head&gt;Merch and DVD&lt;/head&gt;
          &lt;p&gt;To celebrate this release, we want to capture this moment in a nostalgic form, reminiscent of how software was distributed in our childhood - on a CD (or DVD, in this “case”). Introducing Immich Stable in physical form! You can find the link to the disk here&lt;/p&gt;
          &lt;p&gt;The disk comes with a fully bootable Immich instance, featuring a selection of curated photos chosen by the team. You can purchase the disk from our merch store, along with a client or server product key, to support and celebrate this milestone with us.&lt;/p&gt;
          &lt;p&gt;The merch store is also updated with retro-styled Immich designs, check it out in https://immich.store&lt;/p&gt;
          &lt;head&gt;Future plans&lt;/head&gt;
          &lt;p&gt;Now that Immich is stable, here are some of the things that we will be focusing on:&lt;/p&gt;
          &lt;head&gt;Thank you&lt;/head&gt;
          &lt;p&gt;We cannot thank you enough for the support over the past three years. Community participation, from the first comments on the original reddit post, to the feedback when we joined FUTO, have contributed to the awesome product Immich is today. Thank you for joining us and believing in our mission to regain control over your most precious data. Here’s to many more years!&lt;/p&gt;
          &lt;p&gt;We'll also be hosting a Q&amp;amp;A livestream tomorrow, October 2nd, 2025 at 6 PM UTC. You can submit your questions here and subscribe for notifications when the livestream starts here.&lt;/p&gt;
          &lt;p&gt;Cheers,&lt;/p&gt;
          &lt;p&gt;The Immich Team&lt;/p&gt;
          &lt;head&gt;FAQs&lt;/head&gt;
          &lt;head&gt;Will there be a live stream?&lt;/head&gt;
          &lt;p&gt;Yes. We'll be hosting a Q&amp;amp;A livestream tomorrow, October 2nd, 2025 at 6 PM UTC. You can submit your questions here and subscribe for notifications when the livestream starts here.&lt;/p&gt;
          &lt;head&gt;Do I still need backups?&lt;/head&gt;
          &lt;p&gt;Yes! A 3-2-1 backup strategy is still crucial. The team has the responsibility to ensure that the application doesn’t cause loss of your precious memories; however, we cannot guarantee that hard drives will not fail, or an electrical event causes unexpected shutdown of your server/system, leading to data loss. Therefore, we still encourage users to follow best practices when safeguarding their data. Keep multiple copies of your most precious data: at least two local copies and one copy offsite in cold storage. Additionally, we are starting to work on a cloud backup service to make backups easier.&lt;/p&gt;
          &lt;head&gt;When will &lt;/head&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;head rend="h2"&gt;Replies: 132 comments 35 replies&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Huge congratulations to the Immich team! Excited to see v2.0.0 reach stable release — an amazing milestone for open-source and self-hosting&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;congratulations to the team at Immich (and by extension, FUTO)!! a well deserved victory for the open source community!!&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Is the performance better than previous versions, because it used to be a resource hog&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;About time. It's been so long without an update that I thought immich was abandoned.&lt;/p&gt;
          &lt;p&gt;(im not serious)&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Stable 🥳&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;this is the legit successor of the AOL CDRom&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Are the warning messages on the docs supposed to go away too?&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Congrats!!!🥳&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Since last few updates (1.14X) the app get stuck when opening I have to force close it and open it again.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Nice - congrats! 🥳🎉&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Amazing news!!!&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Congrats guys! What an achievement!&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;This is great news!! Congrats to everyone&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Congrats to the team! 🎉🎉 Been eagerly awaiting this one&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Congrats!&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;I'm experiencing an upgrade problem after using the Docker &amp;amp; VectorChord instructions from https://docs.immich.app/install/upgrading. My previous version was 1.133&lt;/p&gt;
          &lt;p&gt;Docker compose went without any issues, and ps shows healthy processes, but now I get a DNS error:&lt;/p&gt;
          &lt;p&gt;docker ps -a shows&lt;/p&gt;
          &lt;p&gt;Any pointers what I could do? Thanks!&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Great!!!&lt;/p&gt;
          &lt;p&gt;There're just 3 little things that I think should be mandatory for a stable version of Immich:&lt;/p&gt;
          &lt;p&gt;I think that with these 3 things the release can really be considered a stable version 😊&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Hi, great news, congratulations!&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Finally! Waiting now for editor and, most important at least for me, #165&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Congratulations !! I've been using Immich for 2 months now and it already seemed very stable, so I didn't understand why it wasn't :)&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Congratulations on this awesome milestone! 🥳&lt;/p&gt;
          &lt;p&gt;Can't wait to see what you'll bring in the future!&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Great, I hope there will finally be an option to disable albums from the timeline view, which will make the timeline contain only what is needed.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;OOOO LET'S GOOOO FOLKS&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Hehe. Nice.&lt;/p&gt;
          &lt;p&gt;Congrats and thanks for the ride so far! For an "unstable" product, it was quite well-working and flawless already.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Congrats 🎉&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Impressive. Previous versions was a bit buggy on mobile (lag, slow, heating up the device), but now, a breeze! 100k images, no issue!&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Thanks for the great project!&lt;/p&gt;
          &lt;p&gt;I like the idea of adding paid features , especially if your team can offer saas services.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Congrats to the team!&lt;/p&gt;
          &lt;p&gt;As someone who has used Immich since late 2022 and has seen many projects spin up and die off in that time, I can't tell you how much I appreciate the work that has been put into the project.&lt;/p&gt;
          &lt;p&gt;Can't wait to see what the (stable) future holds!&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Congrats for all of the team and also for other contributors!&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;ironically waiting until v2.0.1 for them to iron out the bugs. May just be me being used to the unstable versions! Good job guys&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45446834</guid><pubDate>Thu, 02 Oct 2025 06:25:43 +0000</pubDate></item><item><title>NL Judge: Meta must respect user's choice of recommendation system</title><link>https://www.bitsoffreedom.nl/2025/10/02/judge-in-the-bits-of-freedom-vs-meta-lawsuit-meta-must-respect-users-choice/</link><description>&lt;doc fingerprint="bc501a786403c13c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Judge in the Bits of Freedom vs. Meta lawsuit: Meta must respect users’ choice&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;02 oktober 2025&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Today the judge issued a ruling in the summary proceedings brought by digital human rights organisation Bits of Freedom against Meta. The organisation demanded that Meta gives its users on apps such as Instagram and Facebook the option to select a feed that is not based on profiling.&lt;/p&gt;
    &lt;p&gt;Bits of Freedom sued Meta for a breach of the Digital Services Act (DSA). This European legislation is intended to give users more autonomy and control over the major online platforms. One of the core elements of the DSA is that users must have greater influence over the information they see.&lt;/p&gt;
    &lt;p&gt;For many people, and especially for young people, social media platforms are a major source of news and information. Therefore it is crucial that users themselves can decide which content appears on their feed. Without that freedom of choice, participation in the public debate is seriously hampered. That is problematic at any time, but especially so during election periods. In the Netherlands, national elections will be held at the end of this month.&lt;/p&gt;
    &lt;p&gt;The judge states that Meta is indeed acting in violation of the law. He says that “a non‑persistent choice option for a recommendation system runs counter to the purpose of the DSA, which is to give users genuine autonomy, freedom of choice, and control over how information is presented to them.” The judge also concludes that the way Meta has designed its platforms constitutes “a significant disruption of the autonomy of Facebook and Instagram users.” The judge orders Meta to adjust its apps so that the user’s choice is preserved, even when the user navigates to another section or restarts the app.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“We are pleased that the judge now makes clear that Meta must respect the user’s choice,” says Maartje Knaap, spokesperson for Bits of Freedom. “It is absolutely unacceptable that a handful of American tech billionaires determine how we see the world. That concentration of power poses a risk to our democracy. At the same time, it is regrettable that we need to go to court to ensure Meta complies with the law.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Meta has an interest in steering users toward a feed where it can show as many interest‑ and behavior‑based ads as possible. That is the core of Meta’s revenue model. Subtle design techniques push users toward that feed, while the non‑profiled feed is hidden behind a logo, making it hard to find. Users who do choose the alternative timeline also lose direct access to features such as Direct Messages. Moreover, when you open the app, it always starts with Meta’s feed, even if the user selected a different one before. Because of the judge’s ruling, Meta must change its behavior.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“This ruling shows that Meta is not untouchable,” continues Maartje Knaap. “But we are also realistic, this is just a drop in the ocean. There’s still a long way to go. We hope the decision will inspire individuals, civil society organisations, regulators and lawmakers worldwide around the world who are working to rein in Meta’s power. Together we can stand up to a company that has become overwhelmingly powerful.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;You can find the ruling here (in Dutch).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45448326</guid><pubDate>Thu, 02 Oct 2025 11:32:19 +0000</pubDate></item><item><title>Red Hat confirms security incident after hackers claim GitHub breach</title><link>https://www.bleepingcomputer.com/news/security/red-hat-confirms-security-incident-after-hackers-claim-github-breach/</link><description>&lt;doc fingerprint="f046ce5b18c3474a"&gt;
  &lt;main&gt;
    &lt;p&gt;Correction: After publishing, Red Hat confirmed that it was a breach of one of its GitLab instances, and not GitHub. Title and story updated.&lt;/p&gt;
    &lt;p&gt;An extortion group calling itself the Crimson Collective claims to have stolen nearly 570GB of compressed data across 28,000 internal development respositories, with the company confirming it was a breach of one of its GitLab instances.&lt;/p&gt;
    &lt;p&gt;This data allegedly includes approximately 800 Customer Engagement Reports (CERs), which can contain sensitive information about a customer's network and platforms.&lt;/p&gt;
    &lt;p&gt;A CER is a consulting document prepared for clients that often contains infrastructure details, configuration data, authentication tokens, and other information that could be abused to breach customer networks.&lt;/p&gt;
    &lt;p&gt;Red Hat confirmed that it suffered a security incident related to its consulting business, but would not verify any of the attacker's claims regarding the stolen GitLab repositories and customer CERs.&lt;/p&gt;
    &lt;p&gt;"Red Hat is aware of reports regarding a security incident related to our consulting business and we have initiated necessary remediation steps," Red Hat told BleepingComputer.&lt;/p&gt;
    &lt;p&gt;"The security and integrity of our systems and the data entrusted to us are our highest priority. At this time, we have no reason to believe the security issue impacts any of our other Red Hat services or products and are highly confident in the integrity of our software supply chain."&lt;/p&gt;
    &lt;p&gt;After publishing our story, Red Hat confirmed that the security incident was a breach of its GitLab instance used solely for Red Hat Consulting on consulting engagements, and not GitHub.&lt;/p&gt;
    &lt;p&gt;While Red Hat did not respond to any further questions about the breach, the hackers told BleepingComputer that the intrusion occurred approximately two weeks ago.&lt;/p&gt;
    &lt;p&gt;They allegedly found authentication tokens, full database URIs, and other private information in Red Hat code and CERs, which they claimed to use to gain access to downstream customer infrastructure.&lt;/p&gt;
    &lt;p&gt;The hacking group also published a complete directory listing of the allegedly stolen GitLab repositories and a list of CERs from 2020 through 2025 on Telegram.&lt;/p&gt;
    &lt;p&gt;The directory listing of CERs include a wide range of sectors and well known organizations such as Bank of America, T-Mobile, AT&amp;amp;T, Fidelity, Kaiser, Mayo Clinic, Walmart, Costco, the U.S. Navy’s Naval Surface Warfare Center, Federal Aviation Administration, the House of Representatives, and many others.&lt;/p&gt;
    &lt;p&gt;If you have any information regarding this incident or any other undisclosed attacks, you can contact us confidentially via Signal at 646-961-3731 or at tips@bleepingcomputer.com.&lt;/p&gt;
    &lt;p&gt;The hackers stated that they attempted to contact Red Hat with an extortion demand but received no response other than a templated reply instructing them to submit a vulnerability report to their security team.&lt;/p&gt;
    &lt;p&gt;According to them, the created ticket was repeatedly assigned to additional people, including Red Hat's legal and security staff members.&lt;/p&gt;
    &lt;p&gt;BleepingComputer sent Red Hat additional questions, and we will update this story if we receive more information.&lt;/p&gt;
    &lt;p&gt;The same group also claimed responsibility for briefly defacing Nintendo’s topic page last week to include contact information and links to their Telegram channel&lt;/p&gt;
    &lt;p&gt;Update 10/2/25: Story updated with correction from Red Hat that it was a GitLab instance that was breached and not a GitHub account.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Security Validation Event of the Year: The Picus BAS Summit&lt;/head&gt;
    &lt;p&gt;Join the Breach and Attack Simulation Summit and experience the future of security validation. Hear from top experts and see how AI-powered BAS is transforming breach and attack simulation.&lt;/p&gt;
    &lt;p&gt;Don't miss the event that will shape the future of your security strategy&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45448772</guid><pubDate>Thu, 02 Oct 2025 12:28:27 +0000</pubDate></item><item><title>EU funds are flowing into spyware companies and politicians demanding answers</title><link>https://www.theregister.com/2025/10/02/eu_spyware_funding/</link><description>&lt;doc fingerprint="894fb13d86a73093"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;EU funds are flowing into spyware companies, and politicians are demanding answers&lt;/head&gt;
    &lt;head rend="h2"&gt;Experts say Commission is ‘fanning the flames’ of the continent’s own Watergate&lt;/head&gt;
    &lt;p&gt;An arsenal of angry European Parliament members (MEPs) is demanding answers from senior commissioners about why EU subsidies are ending up in the pockets of spyware companies.&lt;/p&gt;
    &lt;p&gt;The group of 39 politicians referred to recent investigations that revealed countries such as Italy, Greece, Hungary, and Spain have funnelled millions of taxpayer euros at a time to help support commercial spyware-makers' finances.&lt;/p&gt;
    &lt;p&gt;They wrote: "According to these findings, entities such as Intellexa, Cy4Gate, Verint and Cognyte – whose technologies have been linked to unlawful surveillance of journalists, human rights defenders and political actors in the EU, as well as in third countries with dreadful human rights records – have benefitted from public financing, including EU programmes.&lt;/p&gt;
    &lt;p&gt;"This raises serious questions about the governance, transparency, and accountability of the Union's funding mechanisms. In the light of the scandals uncovered in Italy, Greece, Poland, Hungary, and Spain, among others, and of the recommendations of the PEGA inquiry, it is deeply troubling that the Union is directly or indirectly enabling tools that erode democracy, fundamental rights, and the rule of law."&lt;/p&gt;
    &lt;p&gt;MEPs cited investigative journalism from Follow The Money, which revealed in September that institutions such as Spain's public-funded Centre for the Development Of Industrial Technology (CDTI) handed over €1.3 million (c $1.5 million) to now-shuttered spyware peddler Mollitiam Industries.&lt;/p&gt;
    &lt;p&gt;Likewise, Italy's state-owned bank, Mediocredito Centrale, was found to have acted as a guarantor to a €2.5 million (c $2.9 million) loan to Dataflow Security, an Italy-based commercial spyware developer.&lt;/p&gt;
    &lt;p&gt;FTM said that it did not prove that any of the money, in any of the cases it found, was used to directly fund spyware development, although funding was provided in several instances.&lt;/p&gt;
    &lt;p&gt;The letter addressed to senior commissioners Henna Virkkunen (Finland), Michael McGrath (Ireland), and Piotr Serafin (Poland) – who oversee tech, justice, and anti-fraud respectively – requested greater transparency over how EU funds were distributed, among other matters.&lt;/p&gt;
    &lt;p&gt;Various questions were raised by the MEPs, such as how the European Commission verifies the integrity of the entities that receive EU funds, whether any risk assessments are carried out before investments are made to spyware companies, and how much money in total has been awarded to these organizations.&lt;/p&gt;
    &lt;p&gt;They also asked for answers on how the Commission plans to ensure its funding mechanisms align with its stances on matters such as human rights and digital resilience, and why it has not implemented the recommendations made by the PEGA inquiry.&lt;/p&gt;
    &lt;p&gt;The Register approached the European Commission for a response to the letter.&lt;/p&gt;
    &lt;p&gt;For the uninitiated, the PEGA inquiry was launched in 2022 following reports of several EU governments using NSO Group's Pegasus spyware a year earlier, and three years after Saudi journalist Jamal Khashoggi's murder.&lt;/p&gt;
    &lt;p&gt;The results were published in 2023, branding the pervasive spyware use "Europe's Watergate" and a "severe violation of all the values of the European Union."&lt;/p&gt;
    &lt;p&gt;The report stated: "The spyware scandal is not a series of isolated national cases of abuse, but a full-blown European affair.&lt;/p&gt;
    &lt;p&gt;"EU Member State governments have been using spyware on their citizens for political purposes and to cover up corruption and criminal activity. Some went even further and embedded spyware in a system deliberately designed for authoritarian rule."&lt;/p&gt;
    &lt;p&gt;Among the main recommendations made by the PEGA committee were to restrict law enforcement's use of spyware only to exceptional cases, protect sensitive targets like politicians, lawyers, and doctors, and to set the conditions for legal use.&lt;/p&gt;
    &lt;p&gt;The 39 MEPs asked the European Commission to additionally commit to launching an immediate public review of EU subsidies flowing into spyware companies.&lt;/p&gt;
    &lt;p&gt;In that review, the politicians specifically requested details on all funds issued and awarded to spyware companies since 2015, a commitment to excluding all spyware vendors from future EU funding instruments, and a follow-up on the PEGA recommendations.&lt;/p&gt;
    &lt;p&gt;"Citizens of the Union have the right to know whether their taxes are being used to finance technologies that endanger their fundamental rights," they wrote.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;North Korea's Lazarus Group shares its malware with IT work scammers&lt;/item&gt;
      &lt;item&gt;Google pushes emergency patch for Chrome 0-day – check your browser version now&lt;/item&gt;
      &lt;item&gt;We're number 1! America now leads the world in surveillanceware investment&lt;/item&gt;
      &lt;item&gt;Who watches the watchmen? Surveillanceware firms make bank, avoid oversight&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;"As Members of the European Parliament, we expect your full cooperation in ensuring accountability and restoring public trust."&lt;/p&gt;
    &lt;p&gt;Rebecca White, researcher and advisor on targeted surveillance at Amnesty Tech's Security Lab, said she and Amnesty support the letter, and highlighted the Commission's lack of communication on the matter.&lt;/p&gt;
    &lt;p&gt;She told The Register: "At Amnesty, we've documented for many years how spyware has enabled human rights abuses in Europe and beyond, and how the surveillance industry is under-regulated and thriving.&lt;/p&gt;
    &lt;p&gt;"The European Commission has remained silent. These latest allegations should alarm all of us.&lt;/p&gt;
    &lt;p&gt;"They suggest that not only is the EU failing to put out the fire, they're fanning the flames. We welcome this collective call for transparency and explanations – the Commission can no longer wash its hands of Europe's complicity in the spyware crisis, which is fuelling human rights abuses across the world."&lt;/p&gt;
    &lt;p&gt;Aljosa Ajanovic Andelic, policy advisor at European Digital Rights (EDRi), echoed the MEPs' request for a ban on spyware.&lt;/p&gt;
    &lt;p&gt;He said: "The lack of action by the Commission when it comes to spyware is appalling and dangerous. In fact, not only have they not done anything to stop the proliferation of shady spyware vendors in the EU, they actually used EU taxpayers' money to directly fund the industry. This has to stop, and we are calling for a full ban on commercial spyware in the EU."&lt;/p&gt;
    &lt;p&gt;"As the largest digital rights network in Europe, our position is firm: the use of spyware is inherently incompatible with fundamental rights, and therefore should be banned, as well as the market of private companies that are profiting from human rights violations." ®&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45448825</guid><pubDate>Thu, 02 Oct 2025 12:34:43 +0000</pubDate></item><item><title>Meta will listen into AI conversations to personalize ads</title><link>https://www.theregister.com/2025/10/01/meta_ai_use_informs_ads/</link><description>&lt;doc fingerprint="a208e53e0d2d0db7"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Meta will listen into AI conversations to personalize ads&lt;/head&gt;
    &lt;head rend="h2"&gt;Religion, race, health and other dicey topics supposedly exempt&lt;/head&gt;
    &lt;p&gt;Meta, having committed hundreds of billions to AI infrastructure and talent, says it will start using people's conversations and interactions with its AI services to create personalized content and advertising.&lt;/p&gt;
    &lt;p&gt;This applies to Meta AI, the company's web-based chat interface, and apps that integrate Meta AI, such as Facebook, Instagram, WhatsApp, and Messenger.&lt;/p&gt;
    &lt;p&gt;Meta intends to begin using people's text exchanges and voice conversations with its AI service to generate personalized posts, reels, and other attention lures starting on December 16, 2025.&lt;/p&gt;
    &lt;p&gt;"For example, if you chat with Meta AI about hiking, we may learn that you’re interested in hiking – just as we would if you posted a reel about hiking or liked a hiking-related Page," the company explained in its announcement. "As a result, you might start seeing recommendations for hiking groups, posts from friends about trails, or ads for hiking boots."&lt;/p&gt;
    &lt;p&gt;A notification campaign about the change begins October 7, 2025.&lt;/p&gt;
    &lt;p&gt;There's no opt-out, but Meta has spared those who live in the EU, the UK, and South Korea for the time being.&lt;/p&gt;
    &lt;p&gt;The social networking giant and metaverse money-burner will let users make some adjustments to its slop-gavage loop with its Ads Preferences and feed customization controls.&lt;/p&gt;
    &lt;p&gt;Meta insists it won't personalize ads based on conversations that touch on religion, sexual orientation, politics, health, race, ethnicity, philosophical belief, or trade union membership.&lt;/p&gt;
    &lt;p&gt;That list of untouchable topics suggests canny Meta users could stymie the personalization plan by prefixing every interaction with a suitably sensitive term – for example, start every interaction with "Pray tell..." or “Oh, Lord, Meta really thought this was a good idea?”&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Microsoft declares bring your Copilot to work day, usurping IT authority&lt;/item&gt;
      &lt;item&gt;'Delightful' root-access bug in Red Hat OpenShift AI allows full cluster takeover&lt;/item&gt;
      &lt;item&gt;Nadella hands Microsoft money machine off to new commercial CEO so he can visioneer the future&lt;/item&gt;
      &lt;item&gt;Stargate, schmargate. We're spending $60B+ on AI this year, Meta's Zuckerberg boasts&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Known as Facebook until brand damage from incessant privacy scandals inspired a name change in 2021, Meta was notionally focused on the metaverse – an ill-defined term for immersive digital experiences that may or may not involve goggles. Having spent something like $60 billion on its Reality Labs group without much to show for it (apart from the privacy-invading Meta Ray-Ban Display glasses), Meta lately has taken to talking up AI.&lt;/p&gt;
    &lt;p&gt;CEO Mark Zuckerberg last month told President Trump that Meta plans to invest $600 billion on AI investment through 2028 – and surely that will happen because Zuckerberg said it, even if other massive AI spending projects like Stargate’s promised $500 billion AI infrastructure investments don’t quite add up.&lt;/p&gt;
    &lt;p&gt;Meta's interest in AI, however, is really about ads – using AI to encourage exposure to and engagement with ads, some of which may be generated by AI. The company has already said AI has helped boost engagement with ads posted to its platforms. Execs also see AI as making it easier to advertisers to create and manage campaigns.&lt;/p&gt;
    &lt;p&gt;As noted by the UK's Open Rights Group, 98 percent of Meta’s $165 billion of revenue in 2024 came from advertising, resulting in net income of $62.4 billion.&lt;/p&gt;
    &lt;p&gt;Iesha White, director of intelligence for marketing watchdog Check My Ads, told The Register in an email that several AI companies like Perplexity and OpenAI have integrated advertising into their AI products.&lt;/p&gt;
    &lt;p&gt;"But this is different – Meta’s core business is monetizing ad space across its owned and operated sites and apps, in addition to ad placements on external publisher partnerships via its Facebook Audience Network product," said White. "By harvesting data from its AI chats across WhatsApp, Instagram, and Facebook, Meta gains yet another closed-loop data source, meaning Meta could reduce transparency of the targeting inputs across its advertising products, in the name of privacy.&lt;/p&gt;
    &lt;p&gt;"It also provides an opportunity for Meta to further shape and obfuscate its attribution models using its own source of truth, with brands unable to independently audit a campaign’s true effectiveness."&lt;/p&gt;
    &lt;p&gt;Meta coincidentally is fighting a $7 billion class action lawsuit [PDF] brought by advertisers who claim that Meta fraudulently represented the potential reach of its ads by citing user accounts rather than actual people – a charge Meta disputes. ®&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45448839</guid><pubDate>Thu, 02 Oct 2025 12:36:39 +0000</pubDate></item><item><title>Daniel Stenberg on 22 curl bugs found by AI and fixed</title><link>https://mastodon.social/@bagder/115241241075258997</link><description>&lt;doc fingerprint="f8eb8f2f2d953eed"&gt;
  &lt;main&gt;
    &lt;p&gt;To use the Mastodon web application, please enable JavaScript. Alternatively, try one of the native apps for Mastodon for your platform.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45449348</guid><pubDate>Thu, 02 Oct 2025 13:29:55 +0000</pubDate></item><item><title>N8n added native persistent storage with DataTables</title><link>https://community.n8n.io/t/data-tables-are-here/192256</link><description>&lt;doc fingerprint="bfbc187f418403ca"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;Hey everyone &lt;/head&gt;
        &lt;head rend="h2"&gt;We’re super excited to share that starting with v1.113 we’re rolling out data tables (beta) to all plans. &lt;/head&gt;
        &lt;p&gt;Since the very beginning of n8n we’ve heard many of you mention the need for a proper table inside n8n to store data between workflow executions without needing to switch platforms or setting up credentials and now it’s finally here.&lt;/p&gt;
        &lt;p&gt;With data tables you can:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;Save specific data from your workflow runs&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Keep data around between multiple executions&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Avoid duplicate runs by tracking execution status&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Store reusable prompts for different workflows&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Collect evaluation data for your AI workflows&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Do lookups, merges, enhancements…&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;…and honestly, probably 100 other creative things we haven’t even thought of yet &lt;/p&gt;
          &lt;/item&gt;
        &lt;/list&gt;
        &lt;p&gt; To make sure your instance stays performant, we’ve set a 50MB limit for everyone. If you’re self-hosting (and know what you’re doing), you can change that via the ENV variable &lt;code&gt;N8N_DATA_TABLES_MAX_SIZE_BYTES&lt;/code&gt;&lt;/p&gt;
        &lt;p&gt; Upgrade to 1.113, give data tables a spin, and let us know what you think! What’s missing? What would make it even more useful for you? We’re really curious to hear your ideas and thoughts! &lt;/p&gt;
        &lt;p&gt; Read more about the data tables in the docs here.&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 37 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;liam
2&lt;/div&gt;
      &lt;p&gt; 7 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;dszp
3&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;This is absolutely awesome to see, I can’t wait to use these! It’s probably been my number one frustration that saving even a small amount of data between executions for all sorts of purposes requires either integrating PostgreSQL and dealing with schemas, using a third party database or API like Supabase (as handy as they are), or using variables that are powerful but are somewhat clumsy to instantiate and track since they only work in Code nodes and only save data for production executions, making testing hard. Hoping data-tables makes a ton of these things easier! Probably won’t run the new version until it’s in final release rather than pre-release, but this is awesome to see!&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 4 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;bartv
5&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;This is really great - when I migrated from “the other platform” almost 4 years ago, I really felt the pain of not having a simple in-app data storage. I played around with Data tables this weekend and it’s just SUCH a good and fast experience! Kudos to our Product and Engineering teams &lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 3 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;Hey all,&lt;/p&gt;
        &lt;p&gt;IMPORTANT NOTE: There is an issue with very large SQLite databases that is causing instances to slow down. Out of an abundance of caution, we are unfortunately removing version 1.113.0 until we fix this issue. We hope to have this released again with a fix within the next couple of days.&lt;/p&gt;
        &lt;p&gt;Very sorry about this!&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 10 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;This is great!&lt;/p&gt;
        &lt;p&gt;It´d be cool for self hosting to be able to add a second DB, where n8n pulls the data from. So one could have performance without having to set up each time a postgres connection.&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 2 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;bartv
10&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;Data tables is back on!&lt;/p&gt;
        &lt;p&gt;A patch was released earlier today. It has now been tested and we have high confidence. Please update to 1.113.1 (which is still in beta) to try this feature.&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 4 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;TH1
11&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;is that Data Tables only available for the Cloud version? local host will not have Data Tables?&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 1 Like &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;liam
12&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;It’s on all plans (cloud and self hosted) starting on version 1.113.1 &lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 2 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;Sujit
13&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;I am unable to see the data tables in my local self hosted n8n. I’ve also updated the docker image to pick the latest one. What am I missing?&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 1 Like &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;Does this mean we can share data between multiple workflows now? This would make splitting up complex workflows across multiple workflows so much easier.&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 1 Like &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;I believe this is still only available in the beta version?&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 1 Like &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;jabbson
16&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;The fact that the “latest” is not “1.113.1”. The latest is “the latest stable”, where 1.113.1 is not that.&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 3 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;Very happy to see this feature. I’ve been testing it out, and was commenting feedback on Reddit but someone in the Discord server said the forums is the best place to post this instead. Here’s my list(so far)&lt;/p&gt;
        &lt;list rend="ol"&gt;
          &lt;item&gt;
            &lt;p&gt;When going to the Data Tables tab, “Create Table” is not default on the upper right button, it’s defaulted to “Create Workflow” instead.&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Cannot change the data type after a column is created.&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Cannot set any of the column’s as primary or unique such as the ID column (To prevent duplicates)&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;For some odd reason, setting a column data type to “number” then pushing data from JSON array into the table, physically opening the table and looking at the rows, the numbers in the “number” data type column are not all together. For example “29683389” shows in the table as “29 683 389”. This isn’t a one off either, ALL rows exhibit the same behavior and ALL columns set as “numbers” too.&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Table page can only show 50 rows per page. Which I understand is probably for performance reasons. However, there really needs to be a “search” function for the table to search for data.&lt;/p&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;Are there any limitations for creating tables?&lt;lb/&gt; or we can create multiples/unlimited (in 50Mb limit)?&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 1 Like &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;Love this list @compaholic, thanks so much for sharing it.&lt;lb/&gt; 1, 2 and 5 are all planned. For (4), I think that is just a highlighting to make it easier to read that it’s actually 29M. So the number should still be correct.&lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;You can created unlimited ones within the storage limit &lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45450044</guid><pubDate>Thu, 02 Oct 2025 14:26:23 +0000</pubDate></item><item><title>Two Amazon delivery drones crash into crane in commercial area of Tolleson, AZ</title><link>https://www.abc15.com/news/region-west-valley/tolleson/two-amazon-delivery-drones-crash-into-crane-in-commercial-area-of-tolleson</link><description>&lt;doc fingerprint="554baf5711d3a7d2"&gt;
  &lt;main&gt;
    &lt;p&gt;TOLLESON, AZ — The Tolleson Police Department is investigating after two Amazon delivery drones crashed on Wednesday morning.&lt;/p&gt;
    &lt;p&gt;Officials say they are working an active investigation after the two drones crashed into a crane that was in a commercial area near 96th Avenue and Roosevelt Street.&lt;/p&gt;
    &lt;p&gt;It's unclear if anyone was injured during the incident.&lt;/p&gt;
    &lt;p&gt;ABC15 reached out to Amazon which provided the following statement: “We’re aware of an incident involving two Prime Air drones in Tolleson, Arizona. We’re currently working with the relevant authorities to investigate.”&lt;/p&gt;
    &lt;p&gt;This is a developing story and will be updated once new information becomes available.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45450449</guid><pubDate>Thu, 02 Oct 2025 14:52:49 +0000</pubDate></item><item><title>Work is not school: Surviving institutional stupidity</title><link>https://www.leadingsapiens.com/surviving-institutional-stupidity/</link><description>&lt;doc fingerprint="37111b1e29438f9c"&gt;
  &lt;main&gt;
    &lt;p&gt;For 16+ years, we master the rules of school. Study hard, get good grades, follow the formula and ultimately merit wins. Then we enter the workforce and none of it works quite like we thought. This becomes painfully obvious as you rise higher in the org.&lt;/p&gt;
    &lt;p&gt;Even seasoned veterans forget this. Recently, a director-level client hit a minor career bump and spiraled into crisis mode, their expectations still anchored in what I call "school rules".&lt;/p&gt;
    &lt;p&gt;Organizations don't run purely on merit or even clear criteria. Although they claim otherwise using buzzwords like “merit” and “data”. That’s only one part of the story, and also what’s visible.&lt;/p&gt;
    &lt;p&gt;The other part, often more consequential, runs on flawed psychology, imperfect decisions, and competing interests. You can call it organizational absurdities. Or more bluntly, institutional stupidity.&lt;/p&gt;
    &lt;p&gt;What follows is a reality check. It’s a “letter to frustrated high-performers” who keep bumping up against these unwritten rules of work. Consider it your guide to staying sane while playing the long game.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If you have to, blame stupidity not malice&lt;/item&gt;
      &lt;item&gt;Organizations are anything but meritocracies&lt;/item&gt;
      &lt;item&gt;Perception matters as much as performance&lt;/item&gt;
      &lt;item&gt;Don’t waste time fighting for “objective fairness.”&lt;/item&gt;
      &lt;item&gt;Positioning what you offer&lt;/item&gt;
      &lt;item&gt;Mind the gap: your standards vs their’s&lt;/item&gt;
      &lt;item&gt;Higher you go, more it’s an inverted funnel&lt;/item&gt;
      &lt;item&gt;Know which game you’re choosing to play&lt;/item&gt;
      &lt;item&gt;Watching your circle of control&lt;/item&gt;
      &lt;item&gt;Keep a balanced portfolio&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;If you have to, blame stupidity not malice&lt;/head&gt;
    &lt;p&gt;Most of what we chalk up to “politics” or “backstabbing”, aka bad intent, is often better explained by stupidity, inertia, bad incentives, fragmented attention, and misaligned maps of reality.&lt;/p&gt;
    &lt;p&gt;People are juggling too much, thinking too little, and rarely stepping back to ask, “What actually makes sense here?”&lt;/p&gt;
    &lt;p&gt;When you assume stupidity instead of malice, you stay above the fray, stop taking slights personally, or turning misjudgments into betrayals. This way we retain agency and choice.&lt;/p&gt;
    &lt;p&gt;Assuming malice turns you into a cynic. In contrast, assuming stupidity keeps you curious. Instead of fighting ghosts, you study the system and ask better questions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;What pressures is that person responding to?&lt;/item&gt;
      &lt;item&gt;What game are they trying to win?&lt;/item&gt;
      &lt;item&gt;What am I assuming as rational that’s not?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;No one is out to get you; they’re just out to get through the week. The shift from malice to stupidity gives you just enough distance to be curious instead of reactive.&lt;/p&gt;
    &lt;head rend="h2"&gt;Organizations are anything but meritocracies&lt;/head&gt;
    &lt;p&gt;Managers will claim they are, and we want to believe them. But the reality is that the best don’t always rise. At least not as easily or automatically as we think they should.&lt;/p&gt;
    &lt;p&gt;Sometimes they do. But often, what gets rewarded isn’t performance but proximity to power, timing, perception, and political usefulness.&lt;/p&gt;
    &lt;p&gt;This doesn’t mean performance doesn’t matter. It means performance is necessary but not sufficient. It is the entry ticket that gets you through the door, but does not guarantee a seat at the table.&lt;/p&gt;
    &lt;p&gt;Assuming that excellence is obvious is the fatal error of the conscientious expert. Although it creates value, performance doesn’t automatically generate visibility, influence, or narrative. And those are the currencies that get traded when decisions are made by humans.&lt;/p&gt;
    &lt;p&gt;Merit matters, but it needs a stage and a spotlight. It doesn’t mean becoming a shameless self-promoter. Rather, your work needs a distribution strategy.&lt;/p&gt;
    &lt;head rend="h2"&gt;Perception matters as much as performance&lt;/head&gt;
    &lt;p&gt;In school, everyone was evaluated against an objective criteria by someone paid to assess fairly.&lt;/p&gt;
    &lt;p&gt;In organizations, no such thing exists. Instead, perception is the “data”. And this data is constructed often haphazardly by busy people working off limited inputs. You have to manage the story by shaping impressions intentionally.&lt;/p&gt;
    &lt;p&gt;Not only does perception matter as much as performance but who’s doing the perceiving matters even more.&lt;/p&gt;
    &lt;p&gt;Not all perceivers are created equal. A peer may love your work but they might not be a critical node in the web of influence. Who gets consulted? Do they know what you’ve built, and have they heard your name in relevant contexts?&lt;/p&gt;
    &lt;p&gt;It’s not just “do great work.”; it’s also “do the work that’s perceived as valuable.” This means translating your work’s significance up the chain and shape its interpretation. If not, others will do it for you and they may not be generous, or even accurate.&lt;/p&gt;
    &lt;p&gt;For more, see my last two articles: Schrodinger’s Cat at Work Part I and Schrodinger’s Cat at Work Part II.&lt;/p&gt;
    &lt;head rend="h2"&gt;Don’t waste time fighting for “objective fairness.”&lt;/head&gt;
    &lt;p&gt;On paper, organizations love metrics: KPIs, OKRs, dashboards. They create the appearance of detached objectivity.&lt;/p&gt;
    &lt;p&gt;Meanwhile, subjective decisions are constantly happening behind the scenes. The decisions about who to trust, or who gets a shot are made through informal reputations and shared stories about your value. Then the “data” is used to justify them in retrospect.&lt;/p&gt;
    &lt;p&gt;Rather than rant against the system, get good at reading the underlying subjective logic:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Who does this person trust, and why?&lt;/item&gt;
      &lt;item&gt;What do they consider strategic vs tactical?&lt;/item&gt;
      &lt;item&gt;What would make them feel safe betting on me?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Subjectivity isn’t the enemy. It’s the underlying physics of it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Positioning what you offer&lt;/head&gt;
    &lt;p&gt;You may have had the right message but at the wrong moment, or in the wrong wrapper.&lt;/p&gt;
    &lt;p&gt;Positioning is the context around your contributions: Why now? Why you? Why this way? A good idea, or stellar performance, poorly positioned can seem irrelevant. In contrast, a mediocre one nicely positioned is deemed visionary.&lt;/p&gt;
    &lt;p&gt;It’s not just what you say but also when, how, and through whom you say it.&lt;/p&gt;
    &lt;p&gt;Persistence matters as well. Think in campaigns, not just one-time efforts. In my piece on effective conversations I wrote:&lt;/p&gt;
    &lt;quote&gt;It is the series of messages in different forms that over time makes the difference. More akin to waves shaping the shoreline rather than the occasional once in a lifetime tsunami.&lt;/quote&gt;
    &lt;p&gt;What messages are you sending, are they varied, and are you doing it consistently? This is as true for marketing products as it is for positioning yourself inside organizations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Mind the gap: your standards vs their’s&lt;/head&gt;
    &lt;p&gt;Another obvious but forgotten reality of organizational life: Not everyone operates by the same playbook.&lt;/p&gt;
    &lt;p&gt;You prioritize substance and direct contribution, while others focus on visibility and relationship-building in ways that are uncomfortable to you. It’s that colleague who excels at positioning routine work as “strategic”, or the peer who builds influence through cultivating key relationships.&lt;/p&gt;
    &lt;p&gt;And yes, these approaches do yield results.&lt;/p&gt;
    &lt;p&gt;But this doesn’t mean dismissing it as pure politics or simply abandoning your principles. It means understanding the landscape you're operating in.&lt;/p&gt;
    &lt;p&gt;You can’t effectively participate in a game you refuse to see clearly. You're not at a disadvantage because you choose to act with integrity. It’s because you fail to recognize that influence flows through multiple channels and others are willing to play differently.&lt;/p&gt;
    &lt;p&gt;The key is not to match their behavior but to factor it in. Instead of expecting fairness, anticipate asymmetry. And then get creative about how you play.&lt;/p&gt;
    &lt;p&gt;Being ethical doesn’t mean being passive but tactically awake.&lt;/p&gt;
    &lt;head rend="h2"&gt;Higher you go, more it’s an inverted funnel&lt;/head&gt;
    &lt;p&gt;Perhaps the most obvious point but also easy to forget especially if your career has been on autopilot so far.&lt;/p&gt;
    &lt;p&gt;There’s a bottleneck up top: fewer seats, more ambiguity, less structure and high subjectivity. It’s not just hard to get in but even harder to stay clear on what “good” even looks like.&lt;/p&gt;
    &lt;p&gt;This means you can do everything right and still get passed over. That’s not a verdict on your worth or ability, just geometry.&lt;/p&gt;
    &lt;p&gt;It also means that staying the course when things don’t go your way isn’t just a virtue but a practice. To play the long game, you have to keep showing up even after crushing disappointment without getting cynical of the process. Put differently, you need high levels of frustration tolerance.&lt;/p&gt;
    &lt;p&gt;Cliched? Yes, very much so, but also uncommon. It means if you can pull it off, it’s a source of power.&lt;/p&gt;
    &lt;head rend="h2"&gt;Know which game you’re choosing to play&lt;/head&gt;
    &lt;p&gt;There is no one game being played. There are multiple, overlapping games with different scoring systems. Some are playing to build long-term credibility; others for short-term visibility.&lt;/p&gt;
    &lt;p&gt;You can’t play them all and neither should you try.&lt;/p&gt;
    &lt;p&gt;The real problem is we slide into playing someone else's game without realizing it. We adopt the norms and metrics of others without checking if that’s the game we actually want to play, let alone win. So we end up optimizing for a role we don’t respect, or chasing promotions that hollow us out.&lt;/p&gt;
    &lt;p&gt;Whatever you’re doing, own it outright. Not just the upside but also the downside. If you're focused on building something lasting like developing others, or robust systems, you need to accept that visible status markers (titles, promotions, recognition) might not happen right away.&lt;/p&gt;
    &lt;p&gt;The danger isn't which path you pick, whether it's chasing promotions or maintaining your autonomy. The real disaster is to sleepwalk down a path while pretending you had no choice in the matter.&lt;/p&gt;
    &lt;head rend="h2"&gt;Watching your circle of control&lt;/head&gt;
    &lt;p&gt;An easy way to burn out is to focus relentlessly on things you care about but cannot actually influence. Over time, especially in large organizations, it's tempting to attribute everything to forces outside yourself. This induces organizational helplessness. A sense that nothing you do matters unless someone above says so.&lt;/p&gt;
    &lt;p&gt;Fight that, not with bluster, but with deliberate ownership of the space you control and influence. While experienced professionals often have more influence than they think, it's distributed differently than they expect.&lt;/p&gt;
    &lt;p&gt;The key is maintaining an internal locus of control which includes your positioning, relationships, and what you are building.&lt;/p&gt;
    &lt;head rend="h2"&gt;Keep a balanced portfolio&lt;/head&gt;
    &lt;p&gt;This is a well-understood concept in investing but often missing in the context of long careers. If all your identity is wrapped up in organizational validation, you're fragile. This means setbacks don't just rattle your job, it rattles your sense of self.&lt;/p&gt;
    &lt;p&gt;Many mid-career professionals learn this the hard way. To state the obvious: you are not your title, or your most recent performance review.&lt;/p&gt;
    &lt;p&gt;The anti-dote is diversification not of money, but meaning.&lt;/p&gt;
    &lt;p&gt;Rebalancing here means investing in other sources of connection and community. This includes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Developing a craft that exists beyond a given employer.&lt;/item&gt;
      &lt;item&gt;Investing in communities that outlast org charts.&lt;/item&gt;
      &lt;item&gt;Projects, relationships, and sources of learning that replenish.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You are building adaptive capacity.&lt;/p&gt;
    &lt;p&gt;A balanced portfolio also helps to play the long game with more psychological courage because your whole life isn't riding on the next promotion cycle or external validation.&lt;/p&gt;
    &lt;head rend="h2"&gt;In closing&lt;/head&gt;
    &lt;p&gt;By recognizing the subjective currents that shape work environments, we can operate within them more skillfully.&lt;/p&gt;
    &lt;p&gt;This isn't cynicism or gaming the system. Rather, it's developing a nuanced understanding of how organizations actually function. This stance equips us to make more intentional choices about how to engage, contribute, and create meaning.&lt;/p&gt;
    &lt;p&gt;As ideal as it sounds, the goal isn't to eliminate organizational absurdities, but to work effectively within and around them. By staying in the game, you find ways to gradually improve the system from within.&lt;/p&gt;
    &lt;p&gt;Organizations are ultimately human constructs. Imperfect, but not immutable.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45450525</guid><pubDate>Thu, 02 Oct 2025 14:58:04 +0000</pubDate></item><item><title>Pharma is a small component of US health care spending</title><link>https://www.economist.com/business/2025/10/02/does-big-pharma-gouge-americans</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45450694</guid><pubDate>Thu, 02 Oct 2025 15:07:48 +0000</pubDate></item><item><title>Autism should not be seen as single condition with one cause, say scientists</title><link>https://www.theguardian.com/society/2025/oct/01/autism-should-not-be-seen-as-single-condition-with-one-cause-say-scientists</link><description>&lt;doc fingerprint="fe9092312f990fb4"&gt;
  &lt;main&gt;
    &lt;p&gt;Autism should not be viewed as a single condition with a unified underlying cause, according to scientists who found that those diagnosed early in childhood typically have a distinct genetic profile to those diagnosed later.&lt;/p&gt;
    &lt;p&gt;The international study, based on genetic data from more than 45,000 autistic people in Europe and the US, showed that those diagnosed in early childhood, typically before six years old, were more likely to show behavioural difficulties from early childhood, including problems with social interaction, but remain stable.&lt;/p&gt;
    &lt;p&gt;Those diagnosed with autism later, typically after the age of 10, were more likely to experience increasing social and behavioural difficulties during adolescence and also had an increased likelihood of mental health conditions such as depression.&lt;/p&gt;
    &lt;p&gt;“The term ‘autism’ likely describes multiple conditions,” said Dr Varun Warrier, from Cambridge’s department of psychiatry, senior author of the research. “For the first time, we have found that earlier and later diagnosed autism have different underlying biological and developmental profiles.”&lt;/p&gt;
    &lt;p&gt;The scientists are not advocating for a move towards two diagnostic categories, saying that this could be unhelpful for the many who fall somewhere in the middle.&lt;/p&gt;
    &lt;p&gt;“It is a gradient,” said Warrier. “There are also many other factors that contribute to age of diagnosis, so the moment you go from averages to anything that is applicable to an individual, it’s false equivalency.”&lt;/p&gt;
    &lt;p&gt;The findings come at a time when autism diagnosis has risen steeply, with a nearly 800% increase in diagnoses in the UK between 1998 and 2018. Experts say this is due largely to a widening of the diagnostic criteria and greater recognition of the condition.&lt;/p&gt;
    &lt;p&gt;And, while autism is defined by having challenges with social communication, sensory processing and restrictive behaviours, there is huge variability in how these difficulties present between individuals. Scientists have been looking at whether the population clusters into subgroups, with shared traits or trajectories, that could make studying autism more tractable.&lt;/p&gt;
    &lt;p&gt;The latest study used behavioural data from four birth cohorts, ranging from 89 to 188 people, and genetic data from two large studies, with more than 45,000 participants.&lt;/p&gt;
    &lt;p&gt;Previously, it was generally assumed that those diagnosed earlier tended to be those with more marked autistic traits, underpinned by people carrying a higher proportion of autism-linked gene variants. However, the latest study revealed a different pattern.&lt;/p&gt;
    &lt;p&gt;The analysis, published in Nature, found that the underlying genetic profiles differed between those diagnosed with autism earlier and later in life, with only a modest overlap. The average genetic profile of later-diagnosed autism is closer to that of ADHD, as well as to mental health conditions such as depression and PTSD, than it is to autism diagnosed in early childhood.&lt;/p&gt;
    &lt;p&gt;Those diagnosed before the age of six years were more likely to be slow to walk and have difficulty interpreting hand gestures and tended to experience social and communication difficulties that appeared early but remained stable. Those diagnosed after the age of 10 years were more likely to experience an increase in difficulties during adolescence and, by late adolescence, presented with more severe challenges.&lt;/p&gt;
    &lt;p&gt;Prof Uta Frith, emeritus professor of cognitive development at University College London, who was not involved in the research, said: “It makes me hopeful that even more subgroups will come to light, and each will find an appropriate diagnostic label.&lt;/p&gt;
    &lt;p&gt;“It is time to realise that ‘autism’ has become a ragbag of different conditions.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45451103</guid><pubDate>Thu, 02 Oct 2025 15:35:14 +0000</pubDate></item><item><title>Windows 7 marketshare jumps to nearly 10% as Windows 10 support is about to end</title><link>https://www.neowin.net/news/windows-7-marketshare-jumps-to-nearly-10-as-windows-10-enters-final-weeks-of-support/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45451208</guid><pubDate>Thu, 02 Oct 2025 15:42:34 +0000</pubDate></item><item><title>Signal Protocol and Post-Quantum Ratchets</title><link>https://signal.org/blog/spqr/</link><description>&lt;doc fingerprint="ac708592c921c484"&gt;
  &lt;main&gt;
    &lt;p&gt;We are excited to announce a significant advancement in the security of the Signal Protocol: the introduction of the Sparse Post Quantum Ratchet (SPQR). This new ratchet enhances the Signal Protocol’s resilience against future quantum computing threats while maintaining our existing security guarantees of forward secrecy and post-compromise security.&lt;/p&gt;
    &lt;p&gt;The Signal Protocol is a set of cryptographic specifications that provides end-to-end encryption for private communications exchanged daily by billions of people around the world. After its publication in 2013, the open source Signal Protocol was adopted not only by the Signal application but also by other major messaging products. Technical information on the Signal Protocol can be found in the specifications section of our docs site.&lt;/p&gt;
    &lt;p&gt;In a previous blog post, we announced the first step towards advancing quantum resistance for the Signal Protocol: an upgrade called PQXDH that incorporates quantum-resistent cryptographic secrets when chat sessions are established in order to protect against harvest-now-decrypt-later attacks that could allow current chat sessions to become compromised if a sufficiently powerful quantum computer is developed in the future. However, the Signal Protocol isn’t just about protecting cryptographic material and keys at the beginning of a new chat or phone call; it’s also designed to minimize damage and heal from compromise as that conversation continues.&lt;/p&gt;
    &lt;p&gt;We refer to these security goals as Forward Secrecy (FS) and Post-Compromise Security (PCS). FS and PCS can be considered mirrors of each other: FS protects past messages against future compromise, while PCS protects future messages from past compromise. Today, we are happy to announce the next step in advancing quantum resistance for the Signal Protocol: an additional regularly advancing post-quantum ratchet called the Sparse Post Quantum Ratchet, or SPQR. On its own, SPQR provides secure messaging that provably achieves these FS and PCS guarantees in a quantum safe manner. We mix the output of this new ratcheting protocol with Signal’s existing Double Ratchet, in a combination we refer to as the Triple Ratchet.&lt;/p&gt;
    &lt;p&gt;What does this mean for you as a Signal user? First, when it comes to your experience using the app, nothing changes. Second, because of how we’re rolling this out and mixing it in with our existing encryption, eventually all of your conversations will move to this new protocol without you needing to take any action. Third, and most importantly, this protects your communications both now and in the event that cryptographically relevant quantum computers eventually become a reality, and it allows us to maintain our existing security guarantees of forward secrecy and post-compromise security as we proactively prepare for that new world.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Current State of the Signal Protocol&lt;/head&gt;
    &lt;p&gt;The original Signal ratchet uses hash functions for FS and a set of elliptic-curve Diffie Hellman (ECDH) secret exchanges for PCS. The hash functions are quantum safe, but elliptic-curve cryptography is not. An example is in order: our favorite users, Alice and Bob, establish a long-term connection and chat over it regularly. During that session’s lifetime, Alice and Bob regularly agree on new ECDH secrets and use them to “ratchet” their session. Mean ol’ Mallory records the entire (encrypted) communication, and really wants to know what Alice and Bob are talking about.&lt;/p&gt;
    &lt;p&gt;The concept of a “ratchet” is crucial to our current non-quantum FS/PCS protection. In the physical world, a ratchet is a mechanism that allows a gear to rotate forward, but disallows rotation backwards. In the Signal Protocol, it takes on a similar role. When Alice and Bob “ratchet” their session, they replace the set of keys they were using prior with a new set based on both the older secrets and a new one they agree upon. Given access to those new secrets, though, there’s no (non-quantum) way to compute the older secrets. By being “one-way”, this ratcheting mechanism provides FS.&lt;/p&gt;
    &lt;p&gt;The ECDH mechanism allows Alice and Bob to generate new, small (32 bytes) data blobs and attach them to every message. Whenever each party receives a message from the other, they can locally (and relatively cheaply) use this data blob to agree on a new shared secret, then use that secret to ratchet their side of the protocol. Crucially, ECDH also allows Alice and Bob to both agree on the new secret without sending that secret itself over their session, and in fact without sending anything over the session that Mallory could use to determine it. This description of Diffie-Hellman key exchange provides more details on the concepts of such a key exchange, and this description of ECDH provides specific details on the variant used by the current Signal protocol.&lt;/p&gt;
    &lt;p&gt;Sometime midway through the lifetime of Alice and Bob’s session, Mallory successfully breaches the defences of both Alice and Bob, gaining access to all of the (current) secrets used for their session at the time of request. Alice and Bob should have the benefits of Forward Secrecy - they’ve ratcheted sometime recently before the compromise, so no messages earlier than their last ratchet are accessible to Mallory, since ratcheting isn’t reversible. They also retain the benefits of Post-Compromise Security. Their ratcheting after Mallory’s secret access agrees upon new keys that can’t be gleaned just from the captured data they pass between each other, re-securing the session.&lt;/p&gt;
    &lt;p&gt;Should Mallory have access to a quantum computer, though, things aren’t so simple. Because elliptic curve cryptography is not quantum resistant, it’s possible that Mallory could glean access to the secret that Alice and Bob agreed upon, just by looking at the communication between them. Given this, Alice and Bob’s session will never “heal”; Mallory’s access to their network traffic from this point forward will allow her to decrypt all future communications.&lt;/p&gt;
    &lt;head rend="h2"&gt;Mixing In Quantum Security&lt;/head&gt;
    &lt;p&gt;In order to make our security guarantees stand up to quantum attacks, we need to mix in secrets generated from quantum secure algorithms. In PQXDH, we did this by performing an additional round of key agreement during the session-initiating handshake, then mixing the resulting shared secret into the initial secret material used to create Signal sessions. To handle FS and PCS, we need to do continuous key agreement, where over the lifetime of a session we keep generating new shared secrets and mixing those keys into our encryption keys.&lt;/p&gt;
    &lt;p&gt;Luckily there is a tool designed exactly for this purpose: the quantum-secure Key-Encapsulation Mechanism (KEM). KEMs share similar behavior to the Diffie-Hellman mechanisms we described earlier, where two clients provide each other with information, eventually deciding on a shared secret, without anyone who intercepts their communications being able to access that secret. However, there is one important distinction for KEMs - they require ordered, asymmetric messages to be passed between their clients. In ECDH, both clients send the other some public parameters, and both combine these parameters with their locally held secrets and come up with an identical shared secret. In the standardized ML-KEM key-encapsulation mechanism, though, the initiating client generates a pair of encapsulation key (EK) and decapsulation key (DK) (analogous to a public and private key respectively) and sends the EK. The receiving client receives it, generates a secret, and wraps it into a ciphertext (CT) with that key. The initiating client receives that CT and decapsulates with its previously generated DK. In the end, both clients have access to the new, shared secret, just through slightly different means.&lt;/p&gt;
    &lt;p&gt;Wanting to integrate this quantum-secure key sharing into Signal, we could take a simple, naive approach for each session. When Alice initiates a session with Bob,&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Alice, with every message she sends, sends an EK&lt;/item&gt;
      &lt;item&gt;Bob, with every message he receives, generates a secret and a CT, and sends the CT back&lt;/item&gt;
      &lt;item&gt;Alice, on receiving a CT, extracts the secret with her DK and mixes it in&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This initially simple-looking approach, though, quickly runs into a number of issues we’ll need to address to make our protocol actually robust. First, encapsulation keys and CTs are large - over 1000 bytes each for ML-KEM 768, compared to the 32 bytes required for ECDH. Second, while this protocol works well when both clients are online, what happens when a client is offline? Or a message is dropped or reordered? Or Alice wants to send 10 messages before Bob wants to send one?&lt;/p&gt;
    &lt;p&gt;Some of these problems have well-understood solutions, but others have trade-offs that may shine in certain circumstances but fall short in others. Let’s dive in and come to some conclusions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Who Wants What When&lt;/head&gt;
    &lt;p&gt;How does Alice decide what to send based on what Bob needs next, and vice versa? If Bob hasn’t received an EK yet, she shouldn’t send the next one. What does Bob send when he hasn’t yet received an EK from Alice, or when he has, but he’s already responded to it? This is a common problem when remote parties send messages to communicate, so there’s a good, well-understood solution: a state machine. Alice and Bob both keep track of “what state am I in”, and base their decisions on that. When sending or receiving a message, they might also change their state. For example:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Alice wants to send a message, but she’s in a StartingA state, so she doesn’t have an EK. So, she generates an EK/DK pair, stores them locally, and transitions to the SendEK state&lt;/item&gt;
      &lt;item&gt;Alice wants to send a message and is in the SendEK state. She sends the EK along with the message&lt;/item&gt;
      &lt;item&gt;Alice wants to send another message, but she’s still in the SendEK state. So, she sends the EK with the new message as well&lt;/item&gt;
      &lt;item&gt;Bob receives the message with the EK. He generates a secret and uses the EK to create a CT. He transitions to the SendingCT state.&lt;/item&gt;
      &lt;item&gt;Bob wants to send a message and he’s in the SendingCT state. He sends the CT along with the message&lt;/item&gt;
      &lt;item&gt;Bob wants to send a message and he’s in the SendingCT state. He sends the CT along with the message&lt;/item&gt;
      &lt;item&gt;… etc …&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By crafting a set of states and transitions, both sides can coordinate what’s sent. Note, though, that even in this simple case, we see problems. For example, we’re sending our (large) EK and (large) CT multiple times.&lt;/p&gt;
    &lt;head rend="h2"&gt;Say (or Send) Less&lt;/head&gt;
    &lt;p&gt;We’ve already mentioned that the size of the data we’re sending has increased pretty drastically, from 32 bytes to over 1000 per message. But bandwidth is expensive, especially on consumer devices like client phones, that may be anywhere in the world and have extremely varied costs for sending bytes over the wire. So let’s discuss strategies for conserving that bandwidth.&lt;/p&gt;
    &lt;p&gt;First, the simplest approach - don’t send a new key with every message. Just, for example, send with every 50 messages, or once a week, or every 50 messages unless you haven’t sent a key in a week, or any other combination of options. All of these approaches tend to work pretty well in online cases, where both sides of a session are communicating in real-time with no message loss. But in cases where one side is offline or loss can occur, they can be problematic. Consider the case of “send a key if you haven’t sent one in a week”. If Bob has been offline for 2 weeks, what does Alice do when she wants to send a message? What happens if we can lose messages, and we lose the one in fifty that contains a new key? Or, what happens if there’s an attacker in the middle that wants to stop us from generating new secrets, and can look for messages that are 1000 bytes larger than the others and drop them, only allowing keyless messages through?&lt;/p&gt;
    &lt;p&gt;Another method is to chunk up a message. Want to send 1000 bytes? Send 10 chunks of 100 bytes each. Already sent 10 chunks? Resend the first chunk, then the second, etc. This smooths out the total number of bytes sent, keeping individual message sizes small and uniform. And often, loss of messages is handled. If chunk 1 was lost, just wait for it to be resent. But it runs into an issue with message loss - if chunk 99 was lost, the receiver has to wait for all of chunks 1-98 to be resent before it receives the chunk it missed. More importantly, if a malicious middleman wants to stop keys from being decided upon, they could always drop chunk 3, never allowing the full key to pass between the two parties.&lt;/p&gt;
    &lt;p&gt;We can get around all of these issues using a concept called erasure codes. Erasure codes work by breaking up a larger message into smaller chunks, then sending those along. Let’s consider our 1000 byte message being sent as 100 byte chunks again. After chunk #10 has been sent, the entirety of the original 1000 byte message has been sent along in cleartext. But rather than just send the first chunk over again, erasure codes build up a new chunk #11, and #12, etc. And they build them in such a way that, once the recipient receives any 10 chunks in any order, they’ll be able to reconstruct the original 1000 byte message.&lt;/p&gt;
    &lt;p&gt;When we put this concept of erasure code chunks together with our previous state machine, it gives us a way to send large blocks of data in small chunks, while handling messages that are dropped. Crucially, this includes messages dropped by a malicious middleman: since any N chunks can be used to recreate the original message, a bad actor would need to drop all messages after #N-1 to disallow the data to go through, forcing them into a complete (and highly noticeable) denial of service. Now, if Alice wants to send an EK to Bob, Alice will:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Transition from the StartingA state to the SendingEK state, by generating a new EK and chunking it&lt;/item&gt;
      &lt;item&gt;While in the SendingEK state, send a new chunk of the EK along with any messages she sends&lt;/item&gt;
      &lt;item&gt;When she receives confirmation that the recipient has received the EK (when she receives a chunk of CT), transition to the ReceivingCT state&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;On Bob’s side, he will:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Transition from the StartingB state to the ReceivingEK state when he receives its first EK chunk&lt;/item&gt;
      &lt;item&gt;Keep receiving EK chunks until he has enough to reconstruct the EK&lt;/item&gt;
      &lt;item&gt;At that point, reconstruct the EK, generate the CT, chunk the CT, and transition to the SendingCT state&lt;/item&gt;
      &lt;item&gt;From this point on, he will send a chunk of the CT with every message&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;One interesting way of looking at this protocol so far is to consider the messages flowing from Alice to Bob as potential capacity for sending data associated with post-quantum ratcheting: each message that we send, we could also send additional data like a chunk of EK or of the CT. If we look at Bob’s side, above, we notice that sometimes he’s using that capacity (IE: in step 4 when he’s sending CT chunks) and sometimes he’s not (if he sends a message to Alice during step 2, he has no additional data to send). This capacity is pretty limited, so using more of it gives us the potential to speed up our protocol and agree on new secrets more frequently.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Meditation On How Faster Isn’t Always Better&lt;/head&gt;
    &lt;p&gt;We want to generate shared secrets, then use them to secure messages. So, does that mean that we want to generate shared secrets as fast as possible? Let’s introduce a new term: an epoch. Alice and Bob start their sessions in epoch 0, sending the EKs for epoch 1 (EK#1) and associated ciphertext (CT#1) to each other. Once that process completes, they have a new shared secret they use to enter epoch 1, after which all newly sent messages are protected by the new secret. Each time they generate a new shared secret, they use it to enter a new epoch. Surely, every time we enter a new epoch with a new shared secret, we protect messages before that secret (FS) and after that secret (PCS), so faster generation is better? It seems simple, but there’s an interesting complexity here that deserves attention.&lt;/p&gt;
    &lt;p&gt;First, let’s discuss how to do things faster. Right now, there’s a lot of capacity we’re not using: Bob sends nothing while Alice sends an EK, and Alice sends nothing while Bob sends a CT. Speeding this up isn’t actually that hard. Let’s change things so that Alice sends EK#1, and once Bob acknowledges its receipt, Alice immediately generates and sends EK#2. And once she notices Bob has received that, she generates and sends EK#3, etc. Whenever Alice sends a new message, she always has data to send along with it (new EK chunks), so she’s using its full capacity. Bob doesn’t always have a new CT to send, but he is receiving EKs as fast as Alice can send them, so he often has a new CT to send along.&lt;/p&gt;
    &lt;p&gt;But now let’s consider what happens when an attacker gains access to Alice. Let’s say that Alice has sent EK#1 and EK#2 to Bob, and she’s in the process of sending EK#3. Bob has acknowledged receipt of EK#1 and EK#2, but he’s still in the process of sending CT#1, since in this case Bob sends fewer messages to Alice than vice versa. Because Alice has already generated 3 EKs she hasn’t used, Alice needs to keep the associated DK#1, DK#2, and DK#3 around. So, if at this point someone maliciously gains control of Alice’s device, they gain access to both the secrets associated with the current epoch (here, epoch 0) and to the DKs necessary to reconstruct the secrets to other epochs (here, epochs 1, 2, and 3) using only the over-the-wire CT that Bob has yet to send. This is a big problem: by generating secrets early, we’ve actually made the in-progress epochs and any messages that will be sent within them less secure against this single-point-in-time breach.&lt;/p&gt;
    &lt;p&gt;To test this out, we at Signal built a number of different state machines, each sending different sets of data either in parallel or serially. We then ran these state machines in numerous simulations, varying things like the ratio of messages sent by Alice vs Bob, the amount of data loss or reordering, etc. And while running these simulations, we tracked what epochs’ secrets were exposed at any point in time, assuming an attacker were to breach either Alice’s or Bob’s secret store. The results showed that, in general, while simulations that handled multiple epochs’ secrets in parallel (IE: by sending EK#2 before receipt of CT#1) did generate new epochs more quickly, they actually made more messages vulnerable to a single breach.&lt;/p&gt;
    &lt;head rend="h2"&gt;But Let’s Still Be Efficient&lt;/head&gt;
    &lt;p&gt;This still leaves us with a problem, though: the capacity present in messages we send in either direction is still a precious resource, and we want to use it as efficiently as possible. And our simple approach of Alice’s “send EK, receive CT, repeat” and Bob’s “receive EK, send CT, repeat” leaves lots of time where Alice and Bob have nothing to send, should that capacity be available.&lt;/p&gt;
    &lt;p&gt;To improve our use of our sending capacity, we decided to take a harder look into the ML-KEM algorithm we’re using to share secrets, to see if there was room to improve. Let’s break things down more and share some actual specifics on the ML-KEM algorithm.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Alice generates an EK of 1184 bytes to send to Bob, and an associated DK&lt;/item&gt;
      &lt;item&gt;Bob receives the EK&lt;/item&gt;
      &lt;item&gt;Bob samples a new shared secret (32 bytes), which he encrypts with EK into a CT of 1088 bytes to send to Alice&lt;/item&gt;
      &lt;item&gt;Alice receives the CT, uses the DK to decrypt it, and now also has access to the 32 byte shared secret&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Diving in further, we can break out step #3 into some sub-steps&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Alice generates an EK of 1184 bytes to send to Bob, and an associated DK&lt;/item&gt;
      &lt;item&gt;Bob receives the EK&lt;/item&gt;
      &lt;item&gt;Bob samples a new shared secret (32 bytes), which he encrypts with EK into a CT of 1088 bytes to send to Alice1&lt;list rend="ol"&gt;&lt;item&gt;Bob creates a new shared secret S and sampled randomness R by sampling entropy and combining it with a hash of EK&lt;/item&gt;&lt;item&gt;Bob hashes the EK into a Hash&lt;/item&gt;&lt;item&gt;Bob pulls 32 bytes of the EK, a Seed&lt;/item&gt;&lt;item&gt;Bob uses the Seed and R to generate the majority of the CT&lt;/item&gt;&lt;item&gt;Bob then uses S and EK to generate the last portion of the CT&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Alice receives the CT, uses the DK to decrypt it, and now also has access to the 32 byte shared secret&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Step 3.d, which generates 960 bytes of the 1088-byte CT, only needs 64 bytes of input: a Seed that’s 32 of EK’s bytes, and the hash of EK, which is an additional 32. If we combine these values and send them first, then most of EK and most of the CT can be sent in parallel from Alice to Bob and Bob to Alice respectively. Our more complicated but more efficient secret sharing now looks like this:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Alice generates EK and DK. Alice extracts the 32-byte Seed from EK&lt;/item&gt;
      &lt;item&gt;Alice sends 64 bytes EK1 (Seed + Hash(EK)) to Bob. Bob sends nothing during this time.&lt;/item&gt;
      &lt;item&gt;Bob receives the Seed and Hash, and generates the first, largest part of the CT from them (CT1)&lt;/item&gt;
      &lt;item&gt;After this point, Alice sends EK2 (the rest of the EK minus the Seed), while Bob sends CT1&lt;/item&gt;
      &lt;item&gt;Bob eventually receives EK2, and uses it to generate the final portion of the CT (CT2)&lt;/item&gt;
      &lt;item&gt;Once Alice tells Bob that he has received all of CT1, Bob sends Alice CT2. Alice sends nothing during this time.&lt;/item&gt;
      &lt;item&gt;With both sides having all of the pieces of EK and the CT that they need, they extract their shared secret and increment their epoch&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are still places in this algorithm (specifically steps 2 and 6) where one side has nothing to send. But during those times, the other side has only a very small amount of information to send, so the duration of those steps is minimal compared to the rest of the process. Specifically, while the full EK is 37 chunks and the full CT is 34, the two pieces of the new protocol which must be sent without data being received (EK1 and CT2) are 2 and 4 chunks respectively, while the pieces that can be sent while also receiving (EK2 and CT1) are the bulk of the data, at 36 and 30 chunks respectively. Far more of our sending capacity is actually used with this approach.&lt;/p&gt;
    &lt;p&gt;Remember that all of this is just to perform a quantum-safe key exchange that gives us a secret we can mix into the bigger protocol. To help us organize our code, our security proofs, and our understanding better we treat this process as a standalone protocol that we call the ML-KEM Braid.&lt;/p&gt;
    &lt;p&gt;This work was greatly aided by the authors of the libcrux-ml-kem Rust library, who graciously exposed the APIs necessary to work with this incremental version of ML-KEM 768. With this approach completed, we’ve been able to really efficiently use the sending capacity of messages sent between two parties to share secrets as quickly as possible without exposing secrets from multiple epochs to potential attackers.&lt;/p&gt;
    &lt;head rend="h2"&gt;Mixing Things Up - The Triple Ratchet&lt;/head&gt;
    &lt;p&gt;There are plenty of details to add to make sure that we reached every corner - check those out in our online protocol documentation - but this basic idea lets us build secure messaging that has post-quantum FS and PCS without using up anyone’s data. We’re not done, though! Remember, at the beginning of this post we said we wanted post-quantum security without taking away our existing guarantees.&lt;/p&gt;
    &lt;p&gt;While today’s Double Ratchet may not be quantum safe, it provides a high level of security today and we believe it will continue to be strong well into the future. We aren’t going to take that away from our users. So what can we do?&lt;/p&gt;
    &lt;p&gt;Our answer ends up being really simple: we run both the Double Ratchet and the Sparse Post Quantum Ratchet alongside each other and mix their keys together, into what we’re calling the Triple Ratchet protocol. When you want to send a message you ask both the Double Ratchet and SPQR “What encryption key should I use for the next message?” and they will both give you a key (along with some other data you need to put in a message header). Instead of either key being used directly, both are passed into a Key Derivation Function - a special function that takes random-enough inputs and produces a secure cryptographic key that’s as long as you need. This gives you a new “mixed” key that has hybrid security. An attacker has to break both our elliptic curve and ML-KEM to even be able to distinguish this key from random bits. We use that mixed key to encrypt our message.&lt;/p&gt;
    &lt;p&gt;Receiving messages is just as easy. We take the message header - remember it has some extra data in it - and send it to the Double Ratchet and SPQR and ask them “What key should I use to decrypt a message with this header?” They both return their keys and you feed them both into that Key Derivation Function to get your decryption key. After that, everything proceeds just like it always has.&lt;/p&gt;
    &lt;head rend="h2"&gt;Heterogeneous Rollout&lt;/head&gt;
    &lt;p&gt;So we’ve got this new, snazzy protocol, and we want to roll it out to all of our users across all of their devices… but none of the devices currently support that protocol. We roll it out to Alice, and Alice tries to talk to Bob, but Alice speaks SPQR and Bob doesn’t. Or we roll it out to Bob, but Alice wants to talk to Bob and Alice doesn’t know the new protocol Bob wants to use. How do we make this work?&lt;/p&gt;
    &lt;p&gt;Let’s talk about the simplest option: allowing downgrades. Alice tries to establish a session with Bob using SPQR and sends a message over it. Bob fails to read the message and establish the session, because Bob hasn’t been upgraded yet. Bob sends Alice an error, so Alice has to try again. This sounds fine, but in practice it’s not tenable. Consider what happens if Alice and Bob aren’t online at the same time… Alice sends a message at 1am, then shuts down. Bob starts up at 3am, sends an error, then shuts down. Alice gets that error when she restarts at 5am, then resends. Bob starts up at 7am and finally gets the message he should have received at 3am, 4 hours behind schedule.&lt;/p&gt;
    &lt;p&gt;To handle this, we designed the SPQR protocol to allow itself to downgrade to not being used. When Alice sends her first message, she attaches the SPQR data she would need to start up negotiation of the protocol. Noticing that downgrades are allowed for this session, Alice doesn’t mix any SPQR key material into the message yet. Bob ignores that data, because it’s in a location he glosses over, but since there’s no mixed in keys yet, he can still decrypt the message. He sends a response that lacks SPQR data (since he doesn’t yet know how to fill it in), which Alice receives. Alice sees a message without SPQR data, and understands that Bob doesn’t speak SPQR yet. So, she downgrades to not using it for that session, and they happily talk without SPQR protection.&lt;/p&gt;
    &lt;p&gt;There’s some scary potential problems here… let’s work through them. First off, can a malicious middleman force a downgrade and disallow Alice and Bob from using SPQR, even if both of them are able to? We protect against that by having the SPQR data attached to the message be MAC’d by the message-wide authentication code - a middleman can’t remove it without altering the whole message in such a way that the other party sees it, even if that other party doesn’t speak SPQR. Second, could some error cause messages to accidentally downgrade sometime later in their lifecycle, due either to bugs in the code or malicious activity? Crucially, SPQR only allows a downgrade when it first receives a message from a remote party. So, Bob can only downgrade if he receives his first message from Alice and notices that she doesn’t support SPQR, and Alice will only downgrade if she receives her first reply from Bob and notices that he doesn’t. After that first back-and-forth, SPQR is locked in and used for the remainder of the session.&lt;/p&gt;
    &lt;p&gt;Finally, those familiar with Signal’s internal workings might note that Signal sessions last a really long time, potentially years. Can we ever say “every session is protected by SPQR”, given that SPQR is only added to new sessions as they’re being initiated? To accomplish this, Signal will eventually (once all clients support the new protocol) roll out a code change that enforces SPQR for all sessions, and that archives all sessions which don’t yet have that protection. After the full rollout of that future update, we’ll be able to confidently assert complete coverage of SPQR.&lt;/p&gt;
    &lt;p&gt;One nice benefit to setting up this “maybe downgrade if the other side doesn’t support things” approach is that it also sets us up for the future: the same mechanisms that allow us to choose between SPQR or no-SPQR are designed to also allow us to upgrade from SPQR to some far-future (as yet unimagined) SPQRv2.&lt;/p&gt;
    &lt;head rend="h2"&gt;Making Sure We Get It Right&lt;/head&gt;
    &lt;p&gt;Complex protocols require extraordinary care. We have to ensure that the new protocol doesn’t lose any of the security guarantees the Double Ratchet gives us. We have to ensure that we actually get the post-quantum protection we’re aiming for. And even then, after we have full confidence in the protocol, we have to make sure that our implementation is correct and robust and stays that way as we maintain it. This is a tall order.&lt;/p&gt;
    &lt;p&gt;To make sure we got this right, we started by building the protocol on a firm foundation of fundamental research. We built on the years of research the academic community has put into secure messaging and we collaborated with researchers from PQShield, AIST, and NYU to explore what was possible with post-quantum secure messaging. In a paper at Eurocrypt 25 we introduced erasure code based chunking and proposed the high-level Triple Ratchet protocol, proving that it gave us the post-quantum security we wanted without taking away any of the security of the classic Double Ratchet. In a follow up paper at USENIX 25, we observed that there are many different ways to design a post-quantum ratchet protocol and we need to pick the one that protects user messages the best. We introduced and analyzed six different protocols and two stood out: one is essentially SPQR, the other is a protocol using a new KEM, called Katana, that we designed just for ratcheting. That second one is exciting, but we want to stick to standards to start!&lt;/p&gt;
    &lt;head rend="h2"&gt;Formal Verification From the Start&lt;/head&gt;
    &lt;p&gt;This research gave us the framework to think about protocol design and prove protocols are secure, but there is a big leap from an academic paper to code. Already when designing PQXDH - a much simpler protocol! - we found that formal verification was an important tool for getting the details right. With the Triple Ratchet we partnered with Cryspen and made formal verification part of the process from the beginning.&lt;/p&gt;
    &lt;p&gt;As we kept finding better protocol candidates - and we implemented around a dozen of them - we modeled them in ProVerif to prove that they had the security properties we needed. Rather than wrapping up a protocol design and performing formal verification as a last step we made it a core part of the design process. Now that the design is settled, this gives us machine verified proof that our protocol has the security properties we demand from it. We wrote our Rust code to closely match the ProVerif models, so it is easy to check that we’re modeling what we implement. In particular, ProVerif is very good at reasoning about state machines, which we’re already using, making the mapping from code to model much simpler.&lt;/p&gt;
    &lt;p&gt;We are taking formal verification further than that, though. We are using hax to translate our Rust implementation into F* on every CI run. Once the F* models are extracted, we prove that core parts of our highly optimized implementation are correct, that function pre-conditions and post-conditions cannot be violated, and that the entire crate is panic free. That last one is a big deal. It is great for usability, of course, because nobody wants their app to crash. But it also matters for correctness. We aggressively add assertions about things we believe must be true when the protocol is running correctly - and we crash the app if they are false. With hax and F*, we prove that those assertions will never fail.&lt;/p&gt;
    &lt;head rend="h2"&gt;Formal Verification Doesn’t Freeze Our Progress&lt;/head&gt;
    &lt;p&gt;Often when people think about formally verified protocol implementations, they imagine a one-time huge investment in verification that leaves you with a codebase frozen in time. This is not the case here. We re-run formal verification in our CI pipeline every time a developer pushes a change to GitHub. If the proofs fail then the build fails, and the developer needs to fix it. In our experience so far, this is usually as simple as adding a pre- or postcondition or returning an error when a value is out of bounds. For us, formal verification is a dynamic part of the development process and ensures that the quality is high on every merge.&lt;/p&gt;
    &lt;head rend="h2"&gt;TLDR&lt;/head&gt;
    &lt;p&gt;Signal is rolling out a new version of the Signal Protocol with the Triple Ratchet. It adds the Sparse Post-Quantum Ratchet, or SPQR, to the existing Double Ratchet to create a new Triple Ratchet which gives our users quantum-safe messaging without taking away any of our existing security promises. It’s being added in such a way that it can be rolled out without disruption. It’s relatively lightweight, not using much additional bandwidth for each message, to keep network costs low for our users. It’s resistant to meddling by malicious middlemen - to disrupt it, all messages after a certain time must be dropped, causing a noticeable denial of service for users. We’re rolling it out slowly and carefully now, but in such a way that we’ll eventually be able to say with confidence “every message sent by Signal is protected by this.” Its code has been formally verified, and will continue to be so even as future updates affect the protocol. It’s the combined effort of Signal employees and external researchers and contributors, and it’s only possible due to the continued work and diligence of the larger crypto community. And as a user of Signal, our biggest hope is that you never even notice or care. Except one day, when headlines scream “OMG, quantum computers are here”, you can look back on this blog post and say “oh, I guess I don’t have to care about that, because it’s already been handled”, as you sip your Nutri-Algae while your self-driving flying car wends its way through the floating tenements of Megapolis Prime.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Those that are interested can look at https://nvlpubs.nist.gov/nistpubs/fips/nist.fips.203.pdf and note that Algorithm 17 uses randomness plus the hash of EK to generate a shared secret and random value, then that random value is used in Algorithm 14 to create c1. The rest of ekPKE is only used by Algorithm 14 to generate c2. ↩&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45451527</guid><pubDate>Thu, 02 Oct 2025 16:06:10 +0000</pubDate></item><item><title>Launch HN: Simplex (YC S24) – Browser automation platform for developers</title><link>https://www.simplex.sh/</link><description>&lt;doc fingerprint="f4968ef0cf13274b"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Browser automation&lt;lb/&gt;for developers&lt;/head&gt;&lt;p&gt;Simplex provides all the infrastructure needed for modern browser automation. &lt;lb/&gt; Remote browsers, steerable web agents, and more.&lt;/p&gt;&lt;head rend="h3"&gt;A team from world class institutions&lt;/head&gt;&lt;head rend="h2"&gt;Watch a live demo of Simplex automating&lt;lb/&gt; a real billing portal.&lt;/head&gt;&lt;head rend="h3"&gt;Live Session Stream&lt;/head&gt;&lt;p&gt;Demo Preview&lt;/p&gt;&lt;head rend="h3"&gt;Live Demo Logs&lt;/head&gt;&lt;p&gt;Agent logs will appear here when demo is running&lt;/p&gt;&lt;head rend="h2"&gt;Engineered from the ground up to work with legacy systems.&lt;/head&gt;&lt;p&gt;Reliably automate every legacy portal your customers use.&lt;/p&gt;&lt;head rend="h3"&gt;Billing Portals&lt;/head&gt;&lt;p&gt;Simplex has been used to log into a billing portal and download the list of invoices for a specified customer.&lt;/p&gt;&lt;head rend="h3"&gt;Prior Authorization Portals&lt;/head&gt;&lt;p&gt;Simplex has been used to fill out complex, branching-logic prior authorization forms on medical provider portals.&lt;/p&gt;&lt;head rend="h3"&gt;ERPs&lt;/head&gt;&lt;p&gt;Simplex has been used to automate data entry and download report PDFs across different ERPs.&lt;/p&gt;&lt;head rend="h3"&gt;Government Portals&lt;/head&gt;&lt;p&gt;Simplex has been used to search and extract structured information across public government portals.&lt;/p&gt;&lt;head rend="h3"&gt;TMS/WMS Software&lt;/head&gt;&lt;p&gt;Simplex has been used to log into a TMS portal, create and edit the information for a shipment, then dispatch the shipment.&lt;/p&gt;&lt;head rend="h3"&gt;... and more&lt;/head&gt;&lt;p&gt;with us to discuss your specific use case.&lt;/p&gt;&lt;table&gt;&lt;row span="6"&gt;&lt;cell role="head"&gt;Order ID&lt;/cell&gt;&lt;cell role="head"&gt;Customer&lt;/cell&gt;&lt;cell role="head"&gt;Status&lt;/cell&gt;&lt;cell role="head"&gt;Amount&lt;/cell&gt;&lt;cell role="head"&gt;Last Updated&lt;/cell&gt;&lt;cell role="head"&gt;Actions&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;PO-2024-001&lt;/cell&gt;&lt;cell&gt;John Smith&lt;/cell&gt;&lt;cell&gt;PENDING&lt;/cell&gt;&lt;cell&gt;$1,234.56&lt;/cell&gt;&lt;cell&gt;01/15/2024&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;PO-2024-002&lt;/cell&gt;&lt;cell&gt;Jane Doe&lt;/cell&gt;&lt;cell&gt;PROCESSING&lt;/cell&gt;&lt;cell&gt;$987.65&lt;/cell&gt;&lt;cell&gt;01/14/2024&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;PO-2024-003&lt;/cell&gt;&lt;cell&gt;Bob Johnson&lt;/cell&gt;&lt;cell&gt;COMPLETED&lt;/cell&gt;&lt;cell&gt;$2,345.67&lt;/cell&gt;&lt;cell&gt;01/13/2024&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;PO-2024-004&lt;/cell&gt;&lt;cell&gt;Alice Brown&lt;/cell&gt;&lt;cell&gt;ERROR&lt;/cell&gt;&lt;cell&gt;$876.54&lt;/cell&gt;&lt;cell&gt;01/12/2024&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;head rend="h2"&gt;Deploy reliably, scale easily.&lt;/head&gt;&lt;head rend="h3"&gt;Run consistent workflows&lt;/head&gt;&lt;p&gt;Simplex automatically caches agent actions. This increases reliability of runs and makes developing flows lightning fast.&lt;/p&gt;&lt;head rend="h3"&gt;Create realtime flows&lt;/head&gt;We've achieved realtime latency to handle complex workflows during phone calls.&lt;p&gt;if low latency flows are a priority for you.&lt;/p&gt;&lt;quote&gt;simplex.click(“New Order”)simplex.click(“Shipment Address”)simplex.type(“”)&lt;/quote&gt;&lt;head rend="h2"&gt;Simplex just works.&lt;/head&gt;&lt;head rend="h3"&gt;Production-ready&lt;/head&gt;&lt;p&gt;Eval harnesses to stress-test your workflows at scale and emulate production conditions.&lt;/p&gt;&lt;head rend="h3"&gt;Authentication Handling&lt;/head&gt;&lt;p&gt;Authentication SDK functions to handle 2FA, login data, and more on your customers' sites. See more here.&lt;/p&gt;&lt;head rend="h3"&gt;Scalable Headless Browsers&lt;/head&gt;&lt;p&gt;Headless browsers that can scale to 100s of concurrent sessions in seconds.&lt;/p&gt;&lt;head rend="h3"&gt;Stealth Mode&lt;/head&gt;&lt;p&gt;Automatic CAPTCHA solving, proxies, and anti-bot protections.&lt;/p&gt;&lt;head rend="h3"&gt;Controllable Workflows&lt;/head&gt;&lt;p&gt;Our web agents are constrained to only take the actions you tell it to.&lt;/p&gt;&lt;head rend="h3"&gt;Optimized Workflows&lt;/head&gt;&lt;p&gt;Automatically cache your workflows for fast and reliable execution in production.&lt;/p&gt;&lt;head rend="h3"&gt;Robust SDKs&lt;/head&gt;&lt;p&gt;Our SDKs are designed to be robust and easy to use. Available in both Python and TypeScript.&lt;/p&gt;&lt;head rend="h3"&gt;Detailed Logging and Replays&lt;/head&gt;&lt;p&gt;View a livestream and live logs of sessions as they happen. Share session replays and detailed agent logs with your team and customers.&lt;/p&gt;&lt;head rend="h2"&gt;Ready to get started?&lt;/head&gt;&lt;p&gt;Book a call with our team to discuss your use case and get started.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45451547</guid><pubDate>Thu, 02 Oct 2025 16:07:23 +0000</pubDate></item><item><title>Ask HN: Went to prison for 18 months, lost access to my GitHub. What can I do?</title><link>https://news.ycombinator.com/item?id=45451567</link><description>&lt;doc fingerprint="5b34939181a618c3"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Hi friends,&lt;/p&gt;
      &lt;p&gt;The skinny is this: I went to prison, all my personal items were stolen IRL and the same person changed a bunch of my passwords. Subsequently, I can't recover my GitHub account.&lt;/p&gt;
      &lt;p&gt;I have recovered most of my digital assets by proving I am me. Recovering my GitHub has proven to be more painful than Google's treatment regarding my Google Workspace.&lt;/p&gt;
      &lt;p&gt;I have the original phone number associated with my account, and can verify a bunch of private repos that are associated with my account—even the number of commits on one of them (almost 6900). I can't, however, provide any 2FA codes or backup codes because they are printed on paper that has, I assume, been destroyed.&lt;/p&gt;
      &lt;p&gt;I maintain two relatively popular Ruby packages that have gone stale since I've been gone, and there are projects my GitHub there that I was working on prior to my incarceration—including a SaaS I had hoped to launch post-prison and two books I was ready to publish. Having said, just opening another account isn't exactly the option I want to take.&lt;/p&gt;
      &lt;p&gt;I've opened a ticket, but I'm getting the "shit out of luck because we don't know you are you" treatment. I understand that security is important, but if one can prove they are them, what's the point?&lt;/p&gt;
      &lt;p&gt;Are there other avenues I have that I haven't explored yet?&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45451567</guid><pubDate>Thu, 02 Oct 2025 16:08:40 +0000</pubDate></item><item><title>The Atlantic Quantum team is joining Google</title><link>https://blog.google/technology/research/scaling-quantum-computing-even-faster-with-atlantic-quantum/</link><description>&lt;doc fingerprint="e10d11f325f6a4e6"&gt;
  &lt;main&gt;
    &lt;p&gt;Google Quantum AI was founded in 2012 and our mission today remains the same — build quantum computers that can solve otherwise unsolvable problems. We’re making steady progress on our roadmap, including with our latest Willow chip.&lt;/p&gt;
    &lt;p&gt;Today, we’re excited to announce that the Atlantic Quantum team is joining Google. Atlantic Quantum is an MIT-founded startup that develops highly integrated quantum computing hardware. Its modular chip stack, which combines qubits and superconducting control electronics within the cold stage, will help Google Quantum AI more effectively scale our superconducting qubit hardware, and accelerate progress on our roadmap to a large error-corrected quantum computer and real-world applications.&lt;/p&gt;
    &lt;p&gt;We’re delighted for Atlantic Quantum to join us as Google continues to invest in the future of quantum computing and deliver its benefits to society. Learn more about our mission and follow our progress at quantumai.google.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45451961</guid><pubDate>Thu, 02 Oct 2025 16:36:53 +0000</pubDate></item><item><title>Liva AI (YC S25) Is Hiring</title><link>https://www.ycombinator.com/companies/liva-ai/jobs/6xM8JYU-founding-operations-lead</link><description>&lt;doc fingerprint="a3de624f74d97bb3"&gt;
  &lt;main&gt;
    &lt;p&gt;Scale AI for video and voice data.&lt;/p&gt;
    &lt;p&gt;The mission at Liva AI (YC S25) is to make AI feel truly human. AI voices and faces today still feel flat and generic, missing emotion, nuance, and identity. We’re fixing that by building the world’s richest library of human voice and video data, fueling the next generation of realistic AI.&lt;/p&gt;
    &lt;p&gt;We’re hiring an extremely organized and committed operator to take on a full-time role. You’ll manage complex projects and people with efficiency, solve problems in uncertain situations, and help us scale fast. Over time, you’ll also play a key role in building the most automated operations system of any data company, translating the workflows you run today into scalable processes and overseeing the internal systems we’re developing.&lt;/p&gt;
    &lt;p&gt;This is a founding role: your work will directly fuel the next generation of AI in a tangible way, while shaping the foundation of how Liva runs at scale.&lt;/p&gt;
    &lt;p&gt;ABOUT THE ROLE&lt;/p&gt;
    &lt;p&gt;What you’ll do:&lt;/p&gt;
    &lt;p&gt;WHAT WE’RE LOOKING FOR&lt;/p&gt;
    &lt;p&gt;Requirements:&lt;/p&gt;
    &lt;p&gt;Nice to have:&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; BENEFITS:&lt;/p&gt;
    &lt;p&gt;Liva's mission is to make AI look and sound truly human. The AI voices and faces today feel off, and lack the capability to reflect diverse people across different ethnicities, races, accents, and career professions. We’re fixing that by building the world’s richest library of human voice and video data, fueling the next generation of realistic AI.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45452299</guid><pubDate>Thu, 02 Oct 2025 17:01:16 +0000</pubDate></item></channel></rss>