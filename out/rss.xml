<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 28 Oct 2025 03:27:21 +0000</lastBuildDate><item><title>The last European train that travels by sea</title><link>https://www.bbc.com/travel/article/20251024-the-last-european-train-that-travels-by-sea</link><description>&lt;doc fingerprint="f458192fbd27762d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The last European train that travels by sea&lt;/head&gt;
    &lt;p&gt;Italy's sleeper from Milan to Sicily ends with a rare rail-ferry crossing that's threatened by a new mega bridge.&lt;/p&gt;
    &lt;p&gt;Our ferry cuts through the roiling waters of the Strait of Messina under clouds that blanket all but the hems of Sicily's distant mountains. The sea passage to the Italian island doesn't want for drama. It's governed by tidal currents so strong they inspired Scylla and Charybdis, the sea monsters in Homer's Odyssey, and is overseen by a golden statue of the Madonna at the end of Messina Harbour, arm raised in blessing. But my eye is drawn to a stranger sight: the train carriages travelling across the sea on the ferry itself.&lt;/p&gt;
    &lt;p&gt;This is unique cargo. The narrow strait is the only place in Europe where passenger trains still travel by sea. Every morning, passengers aboard the Intercity Notte follow the same ritual: watching the train split in the southern Italian city of Villa San Giovanni, get shunted onto the ferry’s tracks and carried across to the city of Messina before being reassembled for the final run to Palermo or Syracuse.&lt;/p&gt;
    &lt;p&gt;"It is a small engineering choreography that keeps two shores and two worlds together every day: students, workers, families returning home, strait commuters, tourists who choose the slow pace of the night train," Francesca Serra, director of Intercity operations at national operator Trenitalia, tells me.&lt;/p&gt;
    &lt;p&gt;But this choreography connecting land and sea may soon come to an end.&lt;/p&gt;
    &lt;p&gt;In August, the Italian government revived long-standing plans to build a vast €13.5bn (£11.7bn) suspension bridge over the strait – one of the world's most ambitious engineering projects. Supporters see it as progress, while critics warn it could drain resources from southern Italy's more urgent infrastructure needs. Whether or not it's ever built, the proposal has cast a shadow over one of Europe's most poetic journeys and the sense of ritual and connection it represents.&lt;/p&gt;
    &lt;p&gt;When I travelled on the Intercity Notte in February 2025, none of this seemed particularly urgent. The bridge plan was still languishing in political limbo and the sea crossing felt like an evocative journey that would surely always exist. This was the backbone of an overland trip my partner and I were taking from Nottingham to Sicily, and we wound our way down through France and Turin before arriving at the grand Milano Centrale. From here, the overnight journey to Syracuse in Sicily – Italy's longest sleeper service – promised something special: a 1,489km passage through the length of Italy, linking mainland and island.&lt;/p&gt;
    &lt;p&gt;Our train left at 19:40 and night was closing in as we rattled down the coast, passing bright constellations of Cinque Terre towns. Compartment doors left open offered glimpses of life along the aisle: families playing cards, an old man with a cup of wine, a couple and their handsome Italian greyhound. I drifted asleep, stirred occasionally by melodic Tannoy announcements from dark platforms washed in orange light.&lt;/p&gt;
    &lt;p&gt;Around 07:00, I was woken by a knock at the door and, scrambling for my glasses, found the carriage attendant waiting patiently with a shot of espresso. A breakfast tray of juice, croissant, dry biscuits and apricot spread followed. Calabrian towns began their days beneath pale skies, which took on a moodier complexion over the Tyrrhenian Sea, flecked with lightning. We came into the salt-licked station of Villa San Giovanni just in time to see Intercity day train returning from Sicily snake out of the ferry's open bow, pulled by a sturdy locomotive.&lt;/p&gt;
    &lt;p&gt;Our train continued a little way along the track before we switched direction and were pushed into the empty vessel. I felt a jolt as our row of carriages was decoupled from the one in front and my sea views were briefly replaced by metal walls. As we were pushed into the bowels of the ferry, a well-rehearsed crew in high-vis jackets shouted instructions at each other above the burr of machinery.&lt;/p&gt;
    &lt;p&gt;Train-ferries emerged in the late 19th Century as an enterprising answer to the question of what happens when an expanding rail network meets a large body of water. The Strait of Messina service began in 1899 and was once one of several places in Europe where passenger trains were loaded onto ferries, including between Dover and Dunkirk. After the 2019 closure of the Puttgarden-Rødby service between Germany and Denmark and the seasonal Sassnitz-Trelleborg route linking Germany and Sweden in 2020, the Intercity is now the last one running. All the rest were replaced by bridges or tunnels, or proved too expensive to maintain as demand fell in favour of air travel.&lt;/p&gt;
    &lt;p&gt;More like this:&lt;/p&gt;
    &lt;p&gt;• Europe's stunning high-tech luxury train&lt;/p&gt;
    &lt;p&gt;• Why is Europe rail travel so complex and expensive?&lt;/p&gt;
    &lt;p&gt;• A new night train connecting some of the continent's great cities&lt;/p&gt;
    &lt;p&gt;However, night trains are now enjoying a renaissance as travellers seek slower and more sustainable alternatives to flying. According to Serra, more than 60% of passengers use the Intercity Notte trains for leisure travel, making it the "holiday train". The second-most-common reason, she says, is returning to one's hometown. "For those who live in Italy, the Intercity connection across the Strait of Messina is not just a railway curiosity but a daily gesture of unity for the country," she says. For Sicilians especially, it has long been a portal to opportunities on the mainland – and holds bittersweet memories of leaving and returning home.&lt;/p&gt;
    &lt;p&gt;Gioia, an English teacher from Catania, tells me about the "community" this joint mode of travel creates. "It's very sociable, together with everybody on deck," she says. "You really feel the travel because all the senses are involved." She notes that being on the ferry pulls people into conversation – "about why are you going up, where are you going and so people talk about politics, feelings, many things…"&lt;/p&gt;
    &lt;p&gt;The sea crossing itself takes around 20 minutes – long enough to stretch your legs, grab a snack and feel the swell beneath your feet before returning to your cabin. A visit to the arancini counter on the main deck has long been a ritual of the crossing. I'm told that the eastern Sicilian arancini are pointed in honour of Mount Etna, while Palermo's are round. Salvatore, a Messina man who works the counter, is used to seeing the excitement in his fellow Sicilians at this point on the trip. "When we smell the scent of the sea and see the little Madonna statue, we say: 'We're home'."&lt;/p&gt;
    &lt;p&gt;He was referring to the gilded statue of Our Lady of the Letter at Messina Harbour, blessing the city as she is reputed to have done in 42 CE. Like so many passengers before us, we watched her grow larger above the swirling blue of the strait. When we reboarded the train carriages, we walked to the front to watch the crew link the chain of carriages. Brake pipes hissed into action, and the Intercity Notte was pulled off the ferry and onto the perfectly aligned tracks in Messina, equally slick with rain.&lt;/p&gt;
    &lt;p&gt;The sea was a stone's throw away down much of Sicily's east coast, waves breaking white on the rocks as we curved past Taormina. Though Etna was hidden, the land views provided plenty of interest: lemon orchards blending into the outskirts of Catania, where red velvet banners embroidered with 'A's heralded the festival of Santa Agata. Twenty hours after leaving the monumental edifice of Milano Centrale, we arrived into the more modest charm of Syracuse station.&lt;/p&gt;
    &lt;p&gt;It's unclear how much longer this unique, multi-modal journey will be possible. The government is aiming to complete the mega bridge between 2032 and 2033. But Italians are sceptical about whether it will get there, or whether the usual obstacles – cost, environmental damage and potential seismic activity – will get in the way.&lt;/p&gt;
    &lt;p&gt;A recent poll suggests Italians are evenly divided on the issue, but I don't meet anyone unequivocally for it in Messina, where anti-bridge posters were dotted in shops and cafes. Jansan Favazzo, a philosophy researcher I met in the port city, tells me the bridge risks being "a cathedral in the desert" if it is not accompanied by further investment in the region. "Part of me hopes that it could be a great development for the island, for Sicily but also for Calabria," he says. "But another part of me fears that it just won't happen."&lt;/p&gt;
    &lt;p&gt;Gioia is more scathing about the project, which she considers both a "dangerous joke" and a "sketchy business", given potential mafia meddling.&lt;/p&gt;
    &lt;p&gt;A spokesperson for Trenitalia tells me it is too soon to say whether the train-ferry service will stay if the bridge is built, but the operator understands people's affection for it. "In the past, many saw this moment as lost time and an unavoidable pause that prolonged the journey," says Serra. "But, in recent years, we have chosen to provide a narrative for what it truly is: a genuine travel experience and an integral part of the journey."&lt;/p&gt;
    &lt;p&gt;For now, "the lyrical beauty of this crossing", as Serra described it, is still there to be enjoyed; a small miracle of engineering and nostalgia, rising and falling with the waves.&lt;/p&gt;
    &lt;p&gt;--&lt;/p&gt;
    &lt;p&gt;If you liked this story, sign up for The Essential List newsletter – a handpicked selection of features, videos and can't-miss news, delivered to your inbox twice a week.&lt;/p&gt;
    &lt;p&gt;For more Travel stories from the BBC, follow us on Facebook and Instagram.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45718711</guid><pubDate>Mon, 27 Oct 2025 08:58:10 +0000</pubDate></item><item><title>10M people watched a YouTuber shim a lock; the lock company sued him – bad idea</title><link>https://arstechnica.com/tech-policy/2025/10/suing-a-popular-youtuber-who-shimmed-a-130-lock-what-could-possibly-go-wrong/</link><description>&lt;doc fingerprint="8fdd9d18d1b882d5"&gt;
  &lt;main&gt;
    &lt;p&gt;“Opening locks” might not sound like scintillating social media content, but Trevor McNally has turned lock-busting into online gold. A former US Marine Staff Sergeant, McNally today has more than 7 million followers and has amassed more than 2 billion views just by showing how easy it is to open many common locks by slapping, picking, or shimming them.&lt;/p&gt;
    &lt;p&gt;This does not always endear him to the companies that make the locks.&lt;/p&gt;
    &lt;p&gt;On March 3, 2025, a Florida lock company called Proven Industries released a social media promo video just begging for the McNally treatment. The video was called, somewhat improbably, “YOU GUYS KEEP SAYING YOU CAN EASILY BREAK OFF OUR LATCH PIN LOCK.” In it, an enthusiastic man in a ball cap says he will “prove a lot of you haters wrong.” He then goes hard at Proven’s $130 model 651 trailer hitch lock with a sledgehammer, bolt cutters, and a crowbar.&lt;/p&gt;
    &lt;p&gt;Naturally, the lock hangs tough.&lt;/p&gt;
    &lt;p&gt;An Instagram user brought the lock to McNally’s attention by commenting, “Let’s introduce it to the @mcnallyofficial poke.” Someone from Proven responded, saying that McNally only likes “the cheap locks lol because they are easy and fast.” Proven locks were said to be made of sterner stuff.&lt;/p&gt;
    &lt;p&gt;But on April 3, McNally posted a saucy little video to social media platforms. In it, he watches the Proven promo video while swinging his legs and drinking a Juicy Juice. He then hops down from his seat, goes over to a Proven trailer hitch lock, and opens it in a matter of seconds using nothing but a shim cut from a can of Liquid Death. He says nothing during the entire video, which has been viewed nearly 10 million times on YouTube alone.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45720376</guid><pubDate>Mon, 27 Oct 2025 12:42:42 +0000</pubDate></item><item><title>When 'perfect' code fails</title><link>https://marma.dev/articles/2025/when-perfect-code-fails</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45721302</guid><pubDate>Mon, 27 Oct 2025 14:19:30 +0000</pubDate></item><item><title>Pyrex catalog from from 1938 with hand-drawn lab glassware [pdf]</title><link>https://exhibitdb.cmog.org/opacimages/Images/Pyrex/Rakow_1000132877.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45721801</guid><pubDate>Mon, 27 Oct 2025 15:04:05 +0000</pubDate></item><item><title>PSF has withdrawn $1.5M proposal to US Government grant program</title><link>https://pyfound.blogspot.com/2025/10/NSF-funding-statement.html</link><description>&lt;doc fingerprint="b28a117194a3d7e3"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;In January 2025, the PSF submitted a proposal to the US government National Science Foundation under the Safety, Security, and Privacy of Open Source Ecosystems program to address structural vulnerabilities in Python and PyPI. It was the PSF’s first time applying for government funding, and navigating the intensive process was a steep learning curve for our small team to climb. Seth Larson, PSF Security Developer in Residence, serving as Principal Investigator (PI) with Loren Crary, PSF Deputy Executive Director, as co-PI, led the multi-round proposal writing process as well as the months-long vetting process. We invested our time and effort because we felt the PSF’s work is a strong fit for the program and that the benefit to the community if our proposal were accepted was considerable. &lt;/p&gt;
      &lt;div&gt;
        &lt;div&gt;&lt;p&gt;We were honored when, after many months of work, our proposal was recommended for funding, particularly as only &lt;/p&gt;36% &lt;p&gt;of new NSF grant applicants are successful on their first attempt. We became concerned, however, when we were presented with the terms and conditions we would be required to agree to if we accepted the grant. These terms included affirming the statement that we “do not, and will not during the term of this financial assistance award, operate any programs that advance or promote DEI, or discriminatory equity ideology in violation of Federal anti-discrimination laws.” This restriction would apply not only to the security work directly funded by the grant, &lt;/p&gt;but to any and all activity of the PSF as a whole&lt;p&gt;. Further, violation of this term gave the NSF the right to “claw back” previously approved and transferred funds. This would create a situation where money we’d already spent could be taken back, which would be an enormous, open-ended financial risk. &lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
      &lt;div&gt;&lt;p&gt;Diversity, equity, and inclusion are core to the PSF’s values, as committed to in our &lt;/p&gt;mission statement&lt;p&gt;: &lt;/p&gt;&lt;/div&gt;
      &lt;quote&gt;
        &lt;div&gt;
          &lt;p&gt;The mission of the Python Software Foundation is to promote, protect, and advance the Python programming language, and to support and facilitate the growth of a diverse and international community of Python programmers.&lt;/p&gt;
        &lt;/div&gt;
      &lt;/quote&gt;
      &lt;div&gt;
        &lt;div&gt;&lt;p&gt;Given the value of the grant to the community and the PSF, we did our utmost to get clarity on the terms and to find a way to move forward in concert with our values. We consulted our NSF contacts and reviewed decisions made by other organizations in similar circumstances, particularly &lt;/p&gt;The Carpentries&lt;p&gt;. &lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;In the end, however, the PSF simply can’t agree to a statement that we won’t operate any programs that “advance or promote” diversity, equity, and inclusion, as it would be a betrayal of our mission and our community. &lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;We’re disappointed to have been put in the position where we had to make this decision, because we believe our proposed project would offer invaluable advances to the Python and greater open source community, protecting millions of PyPI users from attempted supply-chain attacks. The proposed project would create new tools for automated proactive review of all packages uploaded to PyPI, rather than the current process of reactive-only review. These novel tools would rely on capability analysis, designed based on a dataset of known malware. Beyond just protecting PyPI users, the outputs of this work could be transferable for all open source software package registries, such as NPM and Crates.io, improving security across multiple open source ecosystems.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;In addition to the security benefits, the grant funds would have made a big difference to the PSF’s budget. The PSF is a relatively small organization, operating with an annual budget of around $5 million per year, with a staff of just 14. $1.5 million over two years would have been quite a lot of money for us, and easily the largest grant we’d ever received. Ultimately, however, the value of the work and the size of the grant were not more important than practicing our values and retaining the freedom to support every part of our community. The PSF Board voted unanimously to withdraw our application. &lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;Giving up the NSF grant opportunity—along with inflation, lower sponsorship, economic pressure in the tech sector, and global/local uncertainty and conflict—means the PSF needs financial support now more than ever. We are incredibly grateful for any help you can offer. If you're already a PSF member or regular donor, you have our deep appreciation, and we urge you to share your story about why you support the PSF. Your stories make all the difference in spreading awareness about the mission and work of the PSF. &lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;list style="text-align: left;" rend="ul"&gt;
          &lt;item&gt;Become a Member: When you sign up as a Supporting Member of the PSF, you become a part of the PSF. You’re eligible to vote in PSF elections, using your voice to guide our future direction, and you help us sustain what we do with your annual support.&lt;/item&gt;
          &lt;item&gt;Donate: Your donation makes it possible to continue our work supporting Python and its community, year after year.&lt;/item&gt;
          &lt;item&gt;Sponsor: If your company uses Python and isn’t yet a sponsor, send them our sponsorship page or reach out to sponsors@python.org today. The PSF is ever grateful for our sponsors, past and current, and we do everything we can to make their sponsorships beneficial and rewarding.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45721904</guid><pubDate>Mon, 27 Oct 2025 15:12:08 +0000</pubDate></item><item><title>Claude for Excel</title><link>https://www.claude.com/claude-for-excel</link><description>&lt;doc fingerprint="3d3f8e961dffc20a"&gt;
  &lt;main&gt;
    &lt;p&gt;Piloting Claude for Excel&lt;/p&gt;
    &lt;p&gt;Claude understands your entire workbookâfrom nested formulas to multiple tab dependencies. Get explanations with cell-level citations, and update assumptions while preserving formulas. Now in beta as a research preview.&lt;/p&gt;
    &lt;head rend="h2"&gt;How teams use Claude for Excel&lt;/head&gt;
    &lt;p&gt;Claude listens carefully, follows instructions precisely, â¨and thinks through complex problems.&lt;/p&gt;
    &lt;head rend="h3"&gt;Get answers about any cell in seconds&lt;/head&gt;
    &lt;p&gt;Navigate complex models instantly. Ask Claude about specific formulas, entire worksheets, or calculation flows across tabs. Every explanation includes cell-level citations so you can verify the logic.&lt;/p&gt;
    &lt;head rend="h3"&gt;Test scenarios without breaking formulas&lt;/head&gt;
    &lt;p&gt;Update assumptions across your entire model while preserving all dependencies. Test different scenarios quicklyâClaude highlights every change with explanations for full transparency.&lt;/p&gt;
    &lt;head rend="h3"&gt;Debug and fix errors&lt;/head&gt;
    &lt;p&gt;Trace #REF!, #VALUE!, and circular reference errors to their source in seconds. Claude explains what went wrong and how to fix it without disrupting the rest of your model.&lt;/p&gt;
    &lt;head rend="h3"&gt;Build models or fill existing templates&lt;/head&gt;
    &lt;p&gt;Create draft financial models from scratch based on your requirements. Or populate existing templates with fresh data while maintaining all formulas and structure.&lt;/p&gt;
    &lt;p&gt;The Claude you trust, right in Excel&lt;/p&gt;
    &lt;head rend="h3"&gt;Transparency and visibility&lt;/head&gt;
    &lt;p&gt;See Claudeâs changes in real time with explanations&lt;/p&gt;
    &lt;head rend="h3"&gt;Formula integrity&lt;/head&gt;
    &lt;p&gt;Maintain Excel model structure and formatting&lt;/p&gt;
    &lt;head rend="h3"&gt;Enterprise security&lt;/head&gt;
    &lt;p&gt;Works within your existing compliance framework&lt;/p&gt;
    &lt;p&gt;FAQ&lt;/p&gt;
    &lt;p&gt;Claude for Excel is available in beta as a research preview through a waitlist for 1,000 Max, Team and Enterprise plan customers. Weâll gradually expand access as we build confidence through this limited preview.&lt;/p&gt;
    &lt;p&gt;Claude for Excel works within your existing security framework. Claude can make mistakes, so you should always review changes before finalizing, especially for client-facing deliverables.&lt;/p&gt;
    &lt;p&gt;Claude for Excel is currently in beta as a research preview, so itâs best for model analysis, assumption updates, error debugging, template population, formula explanations, multi-tab navigation. Claude doesnât have advanced Excel capabilities including pivot tables, conditional formatting, data validation, data tables, macros, and VBA. Weâre actively working on these features.&lt;/p&gt;
    &lt;p&gt;Yes, Claude is trained to recognize common financial modeling patterns, formula structures, and industry-standard calculations. However, always verify outputs match your specific methodologies.&lt;/p&gt;
    &lt;p&gt;Currently .xlsx and .xlsm files are supported. File size limits apply based on your Claude plan.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45722639</guid><pubDate>Mon, 27 Oct 2025 16:09:22 +0000</pubDate></item><item><title>Show HN: JSON Query</title><link>https://jsonquerylang.org/</link><description>&lt;doc fingerprint="481baa954fb0882b"&gt;
  &lt;main&gt;
    &lt;code&gt;name(argument1, argument2, ...)&lt;/code&gt;
    &lt;p&gt;A function is defined as a function name followed by comma separated arguments wrapped in round brackets. it is important to understand functions like &lt;code&gt;filter&lt;/code&gt;, &lt;code&gt;sort&lt;/code&gt;, and &lt;code&gt;max&lt;/code&gt; are executed as a method in a chain: the operation is applied to the data input, and forwarded to the next method in the chain (if any).&lt;/p&gt;
    &lt;p&gt;Examples:&lt;/p&gt;
    &lt;code&gt;sort(.address.city, "asc")&lt;/code&gt;
    &lt;code&gt;filter(.age &amp;gt;= 21) | sort(.age, "asc")&lt;/code&gt;
    &lt;p&gt;Documentation:&lt;/p&gt;
    &lt;p&gt;Function reference:&lt;/p&gt;
    &lt;code&gt;left operator right&lt;/code&gt;
    &lt;p&gt;JSON Query supports all basic operators. Operators must have both a left and right hand side. To override the default precedence, an operator can be wrapped in parentheses &lt;code&gt;(...)&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Examples:&lt;/p&gt;
    &lt;code&gt;.age &amp;gt;= 18&lt;/code&gt;
    &lt;code&gt;filter(.age &amp;gt;= 18 and .age &amp;lt;= 65)&lt;/code&gt;
    &lt;p&gt;Documentation:&lt;/p&gt;
    &lt;p&gt;Operator reference:&lt;/p&gt;
    &lt;code&gt;query2 | query2 | ...&lt;/code&gt;
    &lt;p&gt;A pipe is an array containing a series of queries. The queries in the pipeline are executed one by one, and the output of the first is the input for the next.&lt;/p&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;filter(.age &amp;gt;= 18) | sort(.name)&lt;/code&gt;
    &lt;p&gt;Documentation:&lt;/p&gt;
    &lt;code&gt;{prop1: query1, prop2: query2, ...}&lt;/code&gt;
    &lt;p&gt;An object is defined as a regular JSON object with a property name as key, and a query as value. Objects can be used to transform data or to execute multiple query pipelines in parallel.&lt;/p&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;{
  names: map(.name),
  numberOfNames: size()
}&lt;/code&gt;
    &lt;p&gt;Documentation:&lt;/p&gt;
    &lt;code&gt;[query1, query2, ...]&lt;/code&gt;
    &lt;p&gt;An array is defined as a regular JSON array: enclosed in square brackets, with items separated by a comma.&lt;/p&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;filter(.city in ["New York", "Atlanta"])&lt;/code&gt;
    &lt;p&gt;Documentation:&lt;/p&gt;
    &lt;code&gt;.prop1.prop2&lt;/code&gt;
    &lt;p&gt;A property retrieves a property from an object. Multiple consecutive properties will retrieve a nested property.&lt;/p&gt;
    &lt;p&gt;Examples:&lt;/p&gt;
    &lt;code&gt;.age&lt;/code&gt;
    &lt;code&gt;.address.city&lt;/code&gt;
    &lt;code&gt;"first name"&lt;/code&gt;
    &lt;code&gt;get()&lt;/code&gt;
    &lt;code&gt;get("address", "city")&lt;/code&gt;
    &lt;p&gt;Documentation:&lt;/p&gt;
    &lt;code&gt;"string", number, boolean, null&lt;/code&gt;
    &lt;p&gt;JSON Query supports the following primitive values, the same as in JSON: &lt;code&gt;"string"&lt;/code&gt;, &lt;code&gt;number&lt;/code&gt;, &lt;code&gt;boolean&lt;/code&gt;, &lt;code&gt;null&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Examples:&lt;/p&gt;
    &lt;code&gt;"Hello world"&lt;/code&gt;
    &lt;code&gt;"Multi line text\nwith \"quoted\" contents"&lt;/code&gt;
    &lt;code&gt;42&lt;/code&gt;
    &lt;code&gt;2.74&lt;/code&gt;
    &lt;code&gt;-1.2e3&lt;/code&gt;
    &lt;code&gt;true&lt;/code&gt;
    &lt;code&gt;false&lt;/code&gt;
    &lt;code&gt;null&lt;/code&gt;
    &lt;p&gt;Documentation:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45722826</guid><pubDate>Mon, 27 Oct 2025 16:22:52 +0000</pubDate></item><item><title>Fnox, a secret manager that pairs well with mise</title><link>https://github.com/jdx/mise/discussions/6779</link><description>&lt;doc fingerprint="fb7f07ee0359b4a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing fnox: A secret manager that pairs well with mise #6779&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;I'm excited to announce fnox – a new secret management tool designed to work seamlessly alongside mise in your development workflow.&lt;/p&gt;
          &lt;p&gt;While it's brand new, I have labeled it 1.0 since it seems pretty feature complete and given my experience with several experiments with secrets over the years with mise, I think will be a lot more stable than its young age would indicate.&lt;/p&gt;
          &lt;head&gt;What is fnox?&lt;/head&gt;
          &lt;p&gt;fnox (think "Fort Knox") is a command-line secret manager that handles encrypted and remote secrets for development, CI/CD, and production environments. It provides a unified interface for managing sensitive data through either local encryption or remote storage backends.&lt;/p&gt;
          &lt;head&gt;Why fnox?&lt;/head&gt;
          &lt;p&gt;While mise has built-in secret support (age encryption and sops), these work best for simple, file-based scenarios. For more complex production needs, fnox provides:&lt;/p&gt;
          &lt;head&gt;🚀 Developer-Friendly&lt;/head&gt;
          &lt;head&gt;👥 Team-Ready&lt;/head&gt;
          &lt;head&gt;Getting Started&lt;/head&gt;
          &lt;p&gt;Install fnox with mise:&lt;/p&gt;
          &lt;code&gt;$ mise use -g fnox
$ fnox --version&lt;/code&gt;
          &lt;p&gt;Create your first secret:&lt;/p&gt;
          &lt;code&gt;$ fnox init
$ fnox provider add age --id main --recipients ~/.ssh/id_ed25519.pub
$ fnox secret set API_KEY --value "your-secret-value" --provider main&lt;/code&gt;
          &lt;p&gt;Use secrets in your workflow:&lt;/p&gt;
          &lt;code&gt;# Export secrets as environment variables
$ fnox exec -- your-command

# Get a single secret
$ fnox get API_KEY

# Shell integration (auto-load secrets on cd)
$ fnox shell hook&lt;/code&gt;
          &lt;head&gt;How It Works with mise&lt;/head&gt;
          &lt;p&gt;fnox and mise work independently but complement each other:&lt;/p&gt;
          &lt;p&gt;A typical setup:&lt;/p&gt;
          &lt;code&gt;[env]
NODE_ENV = "development"
DATABASE_HOST = "localhost"

[tools]
node = "20"
fnox = "latest"&lt;/code&gt;
          &lt;code&gt;[providers.age]
type = "age"
recipients = ["age1ql3z7..."]

[secrets]
DATABASE_PASSWORD = { provider = "age", value = "AGE-SECRET-KEY..." }
API_KEY = { provider = "1password", ref = "op://dev/api/credential" }&lt;/code&gt;
          &lt;p&gt;Then use both together:&lt;/p&gt;
          &lt;code&gt;$ mise x -- fnox x -- npm start&lt;/code&gt;
          &lt;p&gt;Or you can activate one or the other in your shell to avoid that.&lt;/p&gt;
          &lt;head&gt;Why Separate Tools?&lt;/head&gt;
          &lt;p&gt;You might wonder why fnox isn't built into mise. The answer comes down to fundamental architectural constraints:&lt;/p&gt;
          &lt;p&gt;The Performance Problem: mise reloads its environment frequently (on directory changes, after commands, etc.). If secrets relied on remote calls to services like KMS or 1Password, each reload would require network requests, making mise unacceptably slow.&lt;/p&gt;
          &lt;p&gt;The Security Tradeoff: Caching could solve the performance issue, but introduces security risks:&lt;/p&gt;
          &lt;p&gt;The Architecture Challenge: Making mise skip reloading certain env vars would require a major architectural overhaul—a change that would complicate the codebase significantly.&lt;/p&gt;
          &lt;p&gt;By creating fnox as a separate tool with its own shell integration, we avoid these problems entirely. Each tool can focus on what it does best:&lt;/p&gt;
          &lt;head&gt;What's going to happen to mise secrets?&lt;/head&gt;
          &lt;p&gt;They're still marked as experimental so the future is technically up in the air. That said, mise does work well for age/sops encryption so I think it could probably come out of experimental. For now, I don't have plans to introduce remote secret backends like fnox provides.&lt;/p&gt;
          &lt;head&gt;Learn More&lt;/head&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;head rend="h2"&gt;Replies: 1 comment 1 reply&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Since it's a verbatim copy of https://secretspec.dev, any chance of giving attribution?&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45722931</guid><pubDate>Mon, 27 Oct 2025 16:29:38 +0000</pubDate></item><item><title>JetKVM – Control any computer remotely</title><link>https://jetkvm.com/</link><description>&lt;doc fingerprint="af5976106919f929"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Ultra-Low Latency&lt;/head&gt;
    &lt;p&gt;High-definition 1080p video at 60 FPS with 30-60 millisecond latency, using efficient H.264 encoding. Smooth mouse and keyboard action transfer for responsive remote interaction.&lt;/p&gt;
    &lt;head rend="h2"&gt;Free &amp;amp; Optional Cloud Access&lt;/head&gt;
    &lt;p&gt;Optional remote management via our open-source JetKVM Cloud using WebRTC. Privacy-first design with opt-in cloud access that provides secure and fast direct connections, even behind the most restrictive NAT environments, with our STUN and TURN servers.&lt;/p&gt;
    &lt;head rend="h2"&gt;Open Source: Built for Collaboration&lt;/head&gt;
    &lt;p&gt;JetKVM is built on a robust Golang foundation and powered by Linux for adaptability and transparency. Whether you're a seasoned developer or an enthusiastic tinkerer, you can easily modify or fine-tune the software using familiar tooling and straightforward SSH uploads.&lt;/p&gt;
    &lt;head rend="h4"&gt;Available Source Code&lt;/head&gt;
    &lt;head rend="h5"&gt;KVM Runtime&lt;/head&gt;
    &lt;p&gt;Combining a Go-based backend with a React-powered WebRTC dashboard. Perfect for forking, submitting new features, fixing bugs, or customizing local streaming and control.&lt;/p&gt;
    &lt;head rend="h5"&gt;Cloud API &amp;amp; Dashboard&lt;/head&gt;
    &lt;p&gt;Our cloud-hosted management interface is fully open source. Delve into our secure remote connection orchestration or fork it to build specialized workflows and unique integrations.&lt;/p&gt;
    &lt;head rend="h5"&gt;Core System&lt;/head&gt;
    &lt;p&gt;Minimal Linux system built with BusyBox for core utilities. No bloat or unnecessary services - just the essential components needed for stable remote access.&lt;/p&gt;
    &lt;head rend="h2"&gt;Universally loved&lt;/head&gt;
    &lt;p&gt;Every single tech reviewer who's tested JetKVM has given it a glowing review. No exceptions. From professional data centers to home labs, the verdict is unanimous: this is the remote access solution the tech world has been waiting for.&lt;/p&gt;
    &lt;head rend="h2"&gt;Unlimited Hackability&lt;/head&gt;
    &lt;p&gt;The JetKVM hardware is fully customizable. Through the RJ12 extension port, extra hardware capabilities can easily be added by anyone. The JetKVM extension port is the way to fully customize your device.&lt;/p&gt;
    &lt;head rend="h2"&gt;Seamless Remote Control&lt;/head&gt;
    &lt;p&gt;Experience fluid control and crystal-clear video quality that makes remote access feel local. Perfect for IT professionals, developers, and power users who demand responsive remote management.&lt;/p&gt;
    &lt;head rend="h2"&gt;Stay updated on our latest projects&lt;/head&gt;
    &lt;p&gt;Join our newsletter to receive updates about new features, product launches, and early access opportunities.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45723159</guid><pubDate>Mon, 27 Oct 2025 16:44:17 +0000</pubDate></item><item><title>Why Busy Beaver hunters fear the Antihydra</title><link>https://benbrubaker.com/why-busy-beaver-hunters-fear-the-antihydra/</link><description>&lt;doc fingerprint="eeaad01055b00fc9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why Busy Beaver Hunters Fear the Antihydra&lt;/head&gt;
    &lt;p&gt;In the summer of 2024, I reported on an online community that nailed down the precise value of a number called BB(5) — the first big breakthrough in 50 years on an old problem in theoretical computer science known as the busy beaver game. BB(5), now known to be 47,176,870, is the fifth of the so-called busy beaver numbers, which measure the complexity of the craziest computations that simple computer programs can complete.1The team recently released a paper describing their results in detail.&lt;/p&gt;
    &lt;p&gt;The next step in this idiosyncratic research effort is to identify the sixth busy beaver number BB(6), and there has been some notable progress on that front — I wrote a follow-up story about it a few months ago. But busy beaver researchers don’t expect to nail down the true value of BB(6) any time soon. That’s because doing so would require them to understand the behavior of a program with the awesome name “Antihydra,” which resembles a longstanding open problem in mathematics called the Collatz conjecture.2Antihydra should not be confused with the false hydra, a very cool and very terrifying monster conceived by D&amp;amp;D blogger Arnold Kemp. A twitter user sharing my first busy beaver story summed up this state of affairs more succinctly:&lt;/p&gt;
    &lt;p&gt;Both of my stories alluded to the Antihydra barrier only very briefly. In this blog post I will explore it in more detail: What exactly is Antihydra, what is the Collatz conjecture, how are they connected, and what makes them so daunting?&lt;/p&gt;
    &lt;head rend="h2"&gt;Busy Beaver Basics&lt;/head&gt;
    &lt;p&gt;If you haven’t already read my two Quanta stories about the busy beaver game, I recommend doing so before reading further, mainly just because they’re both really fun! Here I’ll recap how the busy beaver game works so that we’re all on the same page.&lt;/p&gt;
    &lt;p&gt;I wrote above that the busy beaver numbers “measure the complexity of the craziest computations that simple computer programs can complete.” To define them more precisely, we first need a mathematical framework for gauging the complexity of computer programs themselves, to decide which ones are “simple.” Then we need a way to quantify the complexity of computations — what computer programs do — so that we can identify the craziest ones.&lt;/p&gt;
    &lt;p&gt;In the busy beaver game, computer programs are represented by hypothetical devices called Turing machines, which compute in discrete steps by reading and writing 0s and 1s on an infinite tape divided into cells. A unique list of rules governs the behavior of each Turing machine. Anything you can do with an ordinary computer program, you can in principle do with the right set of Turing machine rules.3In the busy beaver literature, these rules are called “states.” “In principle” is doing a lot of work in this sentence — even if you managed to acquire the requisite infinite tape, computing with a Turing machine would be horrendously inefficient. But Turing machines are easier to analyze theoretically than more practical programming languages.&lt;/p&gt;
    &lt;p&gt;Let’s unpack how Turing machines work in a bit more detail. At each step, a Turing machine consults one of its rules and edits one cell on the tape. Each rule has two cases: what to do if the current cell contains a 0, and what to do if it contains a 1. “What to do” here means what to write in the current cell, which direction to move next, and which rule to consult for the next step. One case of one rule breaks this pattern: It tells the Turing machine to “halt,” or stop running. But by itself, the existence of this instruction doesn’t guarantee that a Turing machine will halt — the machine might never get there. Quanta’s visual designer Kristina Armitage encapsulated all of this in a beautiful infographic.4In my first Busy Beaver story, you will also find animations of Turing machines in action.&lt;/p&gt;
    &lt;p&gt;The number of rules that a Turing machine has will be our measure of program complexity. This choice lets us replace our vague question about the craziest things that simple computer programs can do with a series of specific questions about different degrees of craziness, corresponding to different busy beaver numbers. You learn the value of BB(1) by answering the question “what’s the most complex computation that a one-rule Turing machine can complete?” Likewise, BB(2) measures the most complex computation that a two-rule machine can complete, and so on.&lt;/p&gt;
    &lt;p&gt;To answer these questions, we need a precise definition of what makes one computation more complex than another. A natural measure is how many steps the Turing machine needs to complete the computation. “Complete” is important — every Turing machine that never halts will run for infinitely many steps, but that’s not really a fair comparison. The number of steps that a Turing machine takes before halting (and indeed, whether it halts at all) can depend on the initial pattern of 0s and 1s on the tape. For the busy beaver game, we always start from the so-called “blank tape,” which has 0s in every cell.&lt;/p&gt;
    &lt;p&gt;We now have all the necessary pieces to formally define the busy beaver numbers. Let’s take BB(6) to be specific: It is the longest finite runtime among all six-rule Turing machines, when those machines start with a blank tape. Finding this number is straightforward in principle. First, list out all possible six-rule Turing machines. Next, sort them into two categories: those that will eventually halt when they start running on the blank tape, and those that will run forever. Toss out all the non-halting machines. Finally, measure how many steps each of the halting machines takes before stopping. The largest number is BB(6).&lt;/p&gt;
    &lt;p&gt;The problem with this plan lies in the second step, where you divide the Turing machines into two groups based on whether or not they halt. It turns out that deciding whether a Turing machine will halt can be an extremely hard problem, to put it mildly. And if you can’t tell whether a given machine will halt, then you don’t know whether your list of halting Turing machines is complete, so you can’t know whether you’ve found the longest runtime! As of this writing, researchers have classified the vast majority of six-rule machines as either halting or non-halting. But there are 1,618 “holdouts” whose fate remains unknown.&lt;/p&gt;
    &lt;p&gt;Antihydra is one of these holdout machines. To nail down the value of BB(6), researchers must first determine whether Antihydra halts, and that seems to be beyond the reach of any known mathematical technique. To understand why, we need to take a step back and ask, “what exactly are these Turing machines doing?”&lt;/p&gt;
    &lt;head rend="h2"&gt;Leveling Up&lt;/head&gt;
    &lt;p&gt;You may object at this point that we already know exactly what these Turing machines are doing: Each one is just following a specific sequence of rules, writing 0s and 1s on the tape as it goes. But this “low-level” description is a bit like saying “when I push these buttons, my pocket calculator toggles transistors on and off in this specific pattern.” That may very well be true, but “high-level” descriptions like “when I push these buttons, my pocket calculator multiplies 3 and 4” are usually more useful.&lt;/p&gt;
    &lt;p&gt;There’s no guarantee that any given Turing machine’s behavior admits such a simple high-level description.5Also, in many cases low-level descriptions are perfectly adequate. For example, the easiest way to prove that a Turing machine halts is just to simulate it step by step until it stops running. When that happens, you don’t need a deeper understanding of why it halted: Just note its runtime and move on. But remember that Turing machines can carry out all possible computations — that means that at least some Turing machines must be executing programs with high-level descriptions that humans can understand.&lt;/p&gt;
    &lt;p&gt;Actually, the most notable five- and six-rule Turing machines that busy beaver researchers have studied so far all have relatively simple high-level descriptions — that includes the longest-running five- and six-rule machines that eventually halt, the most complex non-halting five-rule machines, and holdouts like Antihydra.6This is an empirical observation, not a self-evident truth. In fact, some researchers expected that the longest-running Turing machines would be “spaghetti code” machines that lack any high-level description!&lt;/p&gt;
    &lt;p&gt;Let’s look at a specific example. The fifth busy beaver, which runs for 47,176,870 steps before halting, obeys the following low-level rules:&lt;/p&gt;
    &lt;p&gt;In 1993, the mathematician Pascal Michel proved that these rules are equivalent to a simple high-level program:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Set \(x = 0\).&lt;/item&gt;
      &lt;item&gt;Divide \(x\) by 3 and check the remainder. &lt;list rend="ul"&gt;&lt;item&gt;If the remainder is 0, calculate \((5x + 18)/3\). The result is your new value of \(x\).&lt;/item&gt;&lt;item&gt;If the remainder is 1, calculate \((5x + 22)/3\). The result is your new value of \(x\).&lt;/item&gt;&lt;item&gt;If the remainder is 2, halt.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;If you haven’t halted, go back to step 2 and plug in the new value of \(x\).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Once you have a high-level description like this, you can use it to determine whether the machine will halt — and if so, exactly how many steps it will take.7Each step in a high-level program like this one corresponds to many individual Turing machine steps. Whenever you prove an equivalence between high-level and low-level descriptions, you get formulas that you can use to compute how long each high-level step will take. I won’t say anything about how to actually prove these equivalences. In this case, the high-level program just repeatedly plugs in new values of \(x\) until it finds one that leaves a remainder of 2 when divided by 3. One third of numbers have this property, so you might guess that the program will take three tries to find one, give or take a few. If you start from a random value of \(x\), you’ll find that three iterations is indeed typical. But it turns out that if you start from \(x = 0\), this program will repeat the second step 15 times before it lands on a number with remainder 2! Busy beaver researchers often like to anthropomorphize the Turing machines they study, imagining that the machines are actively trying to run for as long as possible. Adopting that perspective, we might say that this Turing machine got very lucky.&lt;/p&gt;
    &lt;p&gt;The fifth busy beaver is just one member of a family of “Collatz-like” Turing machines whose high-level behavior has the following general form:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Set \(x\) equal to some starting value (which may or may not be 0).&lt;/item&gt;
      &lt;item&gt;Divide \(x\) by a fixed number \(N\). The remainder tells you what formula to use to get your new value of \(x\).&lt;/item&gt;
      &lt;item&gt;Check if you’ve met a specific halting condition. If not, go back to step 2 with the new value of \(x\).8As we saw in the above example, the halting condition can be as simple as “the remainder has a specific value.” Below we’ll see some examples with different halting conditions.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The family of Collatz-like Turing machines includes both halting and non-halting machines. It gets its name from a procedure for generating number sequences devised in 1937 by the mathematician Lothar Collatz:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Choose a starting value for \(x\).&lt;/item&gt;
      &lt;item&gt;Check whether \(x\) is even or odd. &lt;list rend="ul"&gt;&lt;item&gt;If it’s even, calculate \(x/2\). The result is your new value of \(x\).&lt;/item&gt;&lt;item&gt;If it’s odd, calculate \(3x + 1\). The result is your new value of \(x\).&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Check whether \(x = 1\). If not, go back to step 2.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This looks very similar to our general description of high-level behavior for Collatz-like machines, with \(x = 1\) as the halting condition.9“Check whether \(x\) is even or odd” is just another way of saying “divide \(x\) by 2 and check the remainder.” Strictly speaking, we don’t have to specify that the sequence stops when \(x = 1\). But if we keep applying the rules after it hits 1, the sequence enters an infinite loop: 1 &amp;gt; 4 &amp;gt; 2 &amp;gt; 1 and so on. Try iterating these rules from any initial integer value of \(x\) — I’m willing to bet however much you like that you’ll eventually hit 1. The Collatz conjecture asserts that this happens for every positive integer, no matter how large. People have tested this empirically for all integers up to at least 2 billion trillion (!) without finding any counterexamples, which strongly suggests that the conjecture is true. But nobody knows how to rigorously prove it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Cryptozoology&lt;/head&gt;
    &lt;p&gt;Let’s take a step back. At the beginning of this post I noted a link between the Collatz conjecture and Antihydra: Nobody knows how to prove the Collatz conjecture, and that’s why researchers don’t know how to conclusively determine whether Antihydra halts. But now I’ve instead linked the Collatz conjecture to the fifth busy beaver, a machine that has been proved to halt. What’s going on here?&lt;/p&gt;
    &lt;p&gt;The resolution to this apparent puzzle is that for the busy beaver game, we only care about whether a Turing machine halts when it starts running from a specific tape configuration, namely the blank tape. That means we only care about whether the corresponding Collatz-like sequence halts for a single input. The Collatz conjecture, meanwhile, asks whether you eventually hit \(x = 1\) for every input. It’s easy to show that the Collatz sequence ultimately hits \(x = 1\) for any one input, just as it’s easy to show that the fifth busy beaver halts (once you’ve established an equivalence between its low-level rules and the high-level Collatz-like program).10As it happens, the busy beaver hunters Heiner Marxen and Jürgen Buntrock first proved that the fifth busy beaver halted by direct simulation (albeit with some tricks to speed things up). Michel only identified its high-level behavior after the fact.&lt;/p&gt;
    &lt;p&gt;We can easily construct a variant of the Collatz problem that’s hard to solve even for a single input. All we need to do is change the \(3x + 1\) rule for odd numbers to \(5x + 1\). In that case, trajectories that start from certain inputs (such as \(x = 7\)) look like they will diverge, never hitting 1 or falling into a cycle. But researchers haven’t been able to prove that any of these trajectories diverges. There’s an inherent asymmetry here. If you want to prove that a sequence does eventually end up somewhere, you can always just use brute force, at least in principle. But if you want to prove that a sequence never terminates, even a single input can be hard.&lt;/p&gt;
    &lt;p&gt;We’re now finally ready to confront the terror that is Antihydra. It obeys the following high-level rules:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Set \(x = 8\).11This may seem like a weird starting point, given that we’re supposed to start with the blank tape in the busy beaver game. That’s still true here — it’s just that Antihydra spends a while futzing around on the tape before it starts iterating this sequence, and the high-level effect of all that futzing is to set the starting value to 8.&lt;/item&gt;
      &lt;item&gt;Check whether \(x\) is even or odd. &lt;list rend="ul"&gt;&lt;item&gt;If it’s even, calculate \(3x/2\). The result is your new value of \(x\). Add one to a running tally of how many times you’ve applied this even rule.&lt;/item&gt;&lt;item&gt;If it’s odd, calculate \((3x-1)/2\). The result is your new value of \(x\). Add one to a running tally of how many times you’ve applied this odd rule.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Check whether your “odd” count is more than twice as large as your “even” count. If so, halt. If not, go back to step 2.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is a very curious set of rules. The formulas \(3x/2\) and \((3x-1)/2\) don’t appear to systematically favor odd or even numbers, so you might expect that iterating them again and again will look like repeatedly flipping a coin and keeping track of how often you get heads versus tails. Early on in a sequence of coin flips, it’s distinctly possible that you’ll end up with more than twice as many heads as tails. But if this doesn’t happen right away, it becomes less and less likely the longer you keep going. Researchers have now simulated the behavior of Antihydra out to more than 270 billion steps, and as expected, the “even” and “odd” tallies are pretty close to equal — nowhere near the extreme imbalance demanded by the halting condition. So it seems overwhelmingly likely that Antihydra never halts. But nobody knows how to prove it! The mathematician John Conway coined the delightful term “probviously” for situations like this — ones where the specific problem of interest is very hard to solve, but probabilistic reasoning about the “typical” behavior of similar problems makes the answer seem obvious.&lt;/p&gt;
    &lt;p&gt;Antihydra’s behavior is qualitatively similar to the \(5x + 1\) version of the Collatz conjecture, where we don’t know how to prove that any single trajectory diverges. I want to stress that as far as researchers know, there isn’t a more precise mathematical link between these two problems: If you resolved one of them, it wouldn’t automatically resolve the other. But the problems seem hard for very similar reasons. If someone does manage to prove the Collatz conjecture, the mathematical techniques used in the proof would likely be promising for the Antihydra problem (and vice versa).&lt;/p&gt;
    &lt;p&gt;Actually, Antihydra is just one of many probviously non-halting Turing machines with Collatz-like behavior. Busy beaver hunter Shawn Ligocki dubbed these machines “cryptids” when they were first identified in variants of the standard busy beaver game.12These variants use extra tape symbols in addition to 0 and 1. For example, the BB(3,3) version of the busy beaver game studies the behavior of Turing machines with three rules that can read and write three symbols: 0, 1, and 2.&lt;/p&gt;
    &lt;p&gt;The first two cryptids to be discovered were named Bigfoot and Hydra;13Antihydra was named for a mathematical connection to Hydra. researchers have now identified so many cryptids that it no longer makes sense to give each one its own name. The existence of all these cryptids implies that busy beaver numbers beyond BB(5) will remain out of reach until researchers develop new mathematical tools for tackling Collatz-like problems. And the legendary mathematician Paul Erdős reportedly said “Mathematics may not be ready for such problems.”&lt;/p&gt;
    &lt;p&gt;But that doesn’t mean busy beaver hunters should give up. There’s still plenty of questions to explore in what might be called “cryptid ecology.” How many subspecies of cryptids are there? How are they related to each other, and to other unsolved problems in mathematics beyond the Collatz conjecture? Since the beginning of the busy beaver game, avid hunters have repeatedly encountered surprising new Turing machine behavior, and that pattern shows no sign of letting up.&lt;/p&gt;
    &lt;p&gt;This past August I visited Tahquamenon Falls in Michigan’s upper peninsula, a part of the state that’s apparently an epicenter of bigfoot sightings. Fortunately I didn’t encounter any cryptids, but I did learn some new things about a few friendlier critters. Surprising discoveries can come from anywhere!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45723359</guid><pubDate>Mon, 27 Oct 2025 16:56:04 +0000</pubDate></item><item><title>Sieve (YC X25) is hiring engineers to build video datasets for frontier AI</title><link>https://www.sievedata.com/</link><description>&lt;doc fingerprint="7d518f497b3a37b"&gt;
  &lt;main&gt;
    &lt;p&gt;High quality video data for AI applications.&lt;/p&gt;
    &lt;p&gt;500K hours of high quality, diverse video clips.&lt;/p&gt;
    &lt;p&gt;Contact us to request a sample or explore more options.&lt;/p&gt;
    &lt;p&gt;Purpose-built video understanding models paired with human QA help find just the highest quality, training-ready data.&lt;/p&gt;
    &lt;p&gt;Our growing library consists of thousands of petabytes of video data.&lt;/p&gt;
    &lt;p&gt;Video is collected from a variety of public, private, and synthetic sources.&lt;/p&gt;
    &lt;p&gt;New data shapes to unlock new model capabilities (paired, time-synced, conversational, and more).&lt;/p&gt;
    &lt;p&gt;Contact us to request a sample or explore more options.&lt;/p&gt;
    &lt;p&gt;Purpose-built video understanding models paired with human QA help find just the highest quality, training-ready data.&lt;/p&gt;
    &lt;p&gt;Our growing library consists of thousands of petabytes of video data.&lt;/p&gt;
    &lt;p&gt;Video is collected from a variety of public, private, and synthetic sources.&lt;/p&gt;
    &lt;p&gt;New data shapes to unlock new model capabilities (paired, time-synced, conversational, and more).&lt;/p&gt;
    &lt;p&gt;Explore pre-packaged datasets to determine which you are interested in.&lt;/p&gt;
    &lt;p&gt;Enter a purchase agreement based on dataset volume and characteristics.&lt;/p&gt;
    &lt;p&gt;Receive data within 1-2 days via storage bucket access.&lt;/p&gt;
    &lt;p&gt;Scalable API&lt;/p&gt;
    &lt;p&gt;Built to process millions of hours of video at any given moment.&lt;/p&gt;
    &lt;p&gt;Compliant&lt;/p&gt;
    &lt;p&gt;Request specific filtering and licensing needs to ensure full permission and compliance of your training data.&lt;/p&gt;
    &lt;p&gt;Dedicated partnership&lt;/p&gt;
    &lt;p&gt;We partner deeply with every research team to understand their needs and develop data with the same rigor they develop models.&lt;/p&gt;
    &lt;p&gt;Secure&lt;/p&gt;
    &lt;p&gt;End-to-end encryption, custom data retention, and SOC 2 Type 2 secured.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45723426</guid><pubDate>Mon, 27 Oct 2025 17:01:05 +0000</pubDate></item><item><title>Show HN: Dlog – Journaling and AI coach that learns what drives wellbeing (Mac)</title><link>https://dlog.pro/</link><description>&lt;doc fingerprint="2e16e0446df4819b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Know yourself&lt;/head&gt;
    &lt;head rend="h6"&gt;Personal Science&lt;/head&gt;
    &lt;head rend="h2"&gt;Could this be the world’s most advanced AI journal and projects app?&lt;/head&gt;
    &lt;head rend="h6"&gt;You Decide&lt;/head&gt;
    &lt;head rend="h4"&gt;Pricing&lt;/head&gt;
    &lt;head rend="h6"&gt;Dlog is free for the first 14 days, and comes with 10,000 free tokens. The price is then 1.99 per month, plus tokens. If you purchase within 24 hours you get 1 million free tokens (normally 5.99 / million).&lt;/head&gt;
    &lt;head rend="h4"&gt;Quick Start Video&lt;/head&gt;
    &lt;head rend="h3"&gt;Harness personal strengths and understand the drivers behind your productivity and wellbeing.&lt;/head&gt;
    &lt;p&gt;Built on a decade of research. Dlog learns your personality, standards and constraints, then recommends precise steps to increase resources, strengthen character and raise well-being.&lt;/p&gt;
    &lt;head rend="h3"&gt;How Dlog works.&lt;/head&gt;
    &lt;p&gt;You answer a baseline survey about your personality, character, resources, and well-being. Every journal and project you add is scored against that same survey. Then, Dlog’s AI applies regressions and structural equation modelling to map how one change drives another (e.g., habits, people or traits influencing mood, progress or resources&lt;/p&gt;
    &lt;p&gt;But it’s not just numbers. Dlog also runs a narrative analysis, tying those stats back to your own diary quotes.&lt;/p&gt;
    &lt;head rend="h4"&gt;So, when you ask why your mood dipped last week, Dlog can show: ‘Person X drove stress — and here’s what you wrote that day.’&lt;/head&gt;
    &lt;head rend="h4"&gt;Journaling in Dlog turns self-reflection into personal science. Achieve your goals with an AI coach informed by you.&lt;/head&gt;
    &lt;head rend="h6"&gt;Mixed Methodology&lt;/head&gt;
    &lt;head rend="h4"&gt;Dlog uses both narrative ↑ and ↓ quantitative analysis to optimise your well-being and resources.&lt;/head&gt;
    &lt;head rend="h3"&gt;“The backend of Dlog contains a model that links personality, well-being, character and resources; scores are generated by what you’ve written, as determined by ChatGPT 5 and your baseline survey. This gives a rich and vast dataset with which coach responses are informed.”&lt;/head&gt;
    &lt;head rend="h4"&gt;Dr J. de Borst, Dlog Developer and Scientist.&lt;/head&gt;
    &lt;p&gt;From this analysis Dlog’s Coach suggests an array of highly personalised and context aware recommendations, that you can take into consideration when maximising your productivity and well-being.&lt;/p&gt;
    &lt;head rend="h1"&gt;Customise&lt;/head&gt;
    &lt;head rend="h6"&gt;Customize the Experience&lt;/head&gt;
    &lt;head rend="h2"&gt;the Dlog Aesthetic.&lt;/head&gt;
    &lt;head rend="h4"&gt;Crafted with deep care and precision, it’s an app you’ll want to return to throughout the day.&lt;/head&gt;
    &lt;head rend="h3"&gt;Select from vibrant colors or gorgeous gradients.&lt;/head&gt;
    &lt;head rend="h1"&gt;4 Rings&lt;/head&gt;
    &lt;head rend="h6"&gt;Keeping you on track&lt;/head&gt;
    &lt;head rend="h2"&gt;The four rings guide Dlog as it analyses your journals to see if you’re on track.&lt;/head&gt;
    &lt;head rend="h3"&gt;The four rings are Dlog’s anchor for both narrative analysis and quants analysis.&lt;/head&gt;
    &lt;p&gt;The survey that you take when you start using the coach spans the four rings and acts as your baseline. Future journals and projects are scored against the baseline. Regressions and structural equation modelling are used to identify the factors in your life that drive changes in your productivity and wellbeing.&lt;/p&gt;
    &lt;p&gt;All guidance provided by Dlog’s Coach is based on both sentiment analysis of your Dlog Journals (to give scores) and narrative analysis; to give rich context.&lt;/p&gt;
    &lt;head rend="h1"&gt;Goals&lt;/head&gt;
    &lt;head rend="h6"&gt;Universal Truths&lt;/head&gt;
    &lt;head rend="h2"&gt;it all starts with a goal.&lt;/head&gt;
    &lt;head rend="h3"&gt;Dlog puts all your productivity tools into one place. Integrating goals, projects, journals and reminders into your calandar.&lt;/head&gt;
    &lt;p&gt;The secret to productivity and well-being is setting ourselves challenges that are neither too easy nor too simple for our abilities.&lt;/p&gt;
    &lt;p&gt;Journals and Projects are organised by goal. Ranging from short term to life goals. Dlog makes sure you don’t miss a beat.&lt;/p&gt;
    &lt;head rend="h4"&gt;Through regular, guided journaling and accountable projects, Dlog helps you achieve your goals with an AI coach informed by your personal data analysed through the Dlog Model.&lt;/head&gt;
    &lt;head rend="h1"&gt;Journals&lt;/head&gt;
    &lt;head rend="h6"&gt;Guided Journaling&lt;/head&gt;
    &lt;head rend="h2"&gt;Reflect and understand yourself on a deeper level.&lt;/head&gt;
    &lt;head rend="h3"&gt;Work through the 4 constructs, as you understand yourself and reflect.&lt;/head&gt;
    &lt;p&gt;The benefits of journaling are well documented. Dlog serves to enhance these benefits with its aesthetic interface and unique AI model. Delivering a journaling experience that is intuitive and in line with the modern needs of our technological societies.&lt;/p&gt;
    &lt;head rend="h4"&gt;Journals are scored, data is gathered and stored on device, and deep insights are gained through personal science.&lt;/head&gt;
    &lt;head rend="h4"&gt;Journals are stored in your calander and viewed in the journal browser. Like projects they can be attached to a goal and have their own reminders list.&lt;/head&gt;
    &lt;head rend="h1"&gt;Projects&lt;/head&gt;
    &lt;head rend="h6"&gt;Build Character, Complete Projects&lt;/head&gt;
    &lt;head rend="h2"&gt;Projects designed to achieve your goals.&lt;/head&gt;
    &lt;head rend="h3"&gt;Dlog makes organising project notes intuitive and simple with it’s goal centric system.&lt;/head&gt;
    &lt;p&gt;On the Dlog home screen you can select from a project or journal. Project entries are linked to your calander and each entry is assigned to a project file. Every project has its own reminders list to keep you on track.&lt;/p&gt;
    &lt;head rend="h4"&gt;In the project manager you can view, edit and assign projects to goals.&lt;/head&gt;
    &lt;head rend="h1"&gt;Dlog Coach&lt;/head&gt;
    &lt;head rend="h6"&gt;Guided Journaling&lt;/head&gt;
    &lt;head rend="h2"&gt;merging chat with personal statistics you can count on.&lt;/head&gt;
    &lt;head rend="h3"&gt;Dlog’s coach reveals how your personality, interacts with your character, resources and well-being. Uncovering the hidden drivers behind your productivity and well-being.&lt;/head&gt;
    &lt;p&gt;Coach has access to your journals and projects, and uses mixed methods analysis to gather insight into your life patterns.&lt;/p&gt;
    &lt;p&gt;Ask coach about your relationships, work habits, why your feeling stressed, your goals, or simply to review your week. Coach answers with your baseline in mind so that every response is personal to you and deeply contextualised.&lt;/p&gt;
    &lt;head rend="h4"&gt;Through regular journaling and project entries, Dlog helps you achieve your goals with an AI coach informed by your personal data and analysed through the Dlog Model.&lt;/head&gt;
    &lt;head rend="h6"&gt;Do something&lt;/head&gt;
    &lt;head rend="h3"&gt;Coach suggests an array of highly personalised and context aware recommendations, that you can take into consideration when maximising your productivity and well-being.&lt;/head&gt;
    &lt;p&gt;The coach is action oriented, and will suggest goals, nudges/reminders or projects using contextual data in relation to the 4 rings.&lt;/p&gt;
    &lt;head rend="h1"&gt;Words&lt;/head&gt;
    &lt;head rend="h6"&gt;Your Reality&lt;/head&gt;
    &lt;head rend="h2"&gt;Expore visualizers with data about you.&lt;/head&gt;
    &lt;head rend="h3"&gt;Your language is more than just data.&lt;/head&gt;
    &lt;p&gt;When you journal in Dlog your words aren’t just saved, they’re organised into themes derived from the Four Rings (Personality, Character, Resources, Well-Being). This process of thematic analysis turns raw text into a view of your life narrative.&lt;/p&gt;
    &lt;head rend="h3"&gt;Dlog brings you back to the moment – through your own words.&lt;/head&gt;
    &lt;head rend="h4"&gt;Dlog provides a birds-eye view of your life patterns.&lt;/head&gt;
    &lt;p&gt;Your words appear where you need them. In weekly reviews and life reports, when a trend appears, Dlog links that trend to the original journal and project quotes that explain it, so that your insights are grounded in you.&lt;/p&gt;
    &lt;head rend="h4"&gt;Words have power and Dlog examines your journals using thematic analysis, including axial coding of entries that are then organised into themes and sub themes derived from the 4-Rings.&lt;/head&gt;
    &lt;head rend="h6"&gt;Word Cloud&lt;/head&gt;
    &lt;head rend="h4"&gt;Mentions of people, places and time markers are connected to variables such as mood, income, sense of purpose etc.&lt;/head&gt;
    &lt;head rend="h1"&gt;Numbers&lt;/head&gt;
    &lt;head rend="h6"&gt;Deep Fulfilment&lt;/head&gt;
    &lt;head rend="h2"&gt;Your numbers signal life patterns.&lt;/head&gt;
    &lt;head rend="h3"&gt;Discover the hidden factors driving your life across the Four Rings (Personality, Resources, Character, Well-Being).&lt;/head&gt;
    &lt;p&gt;Everyone’s Productivity and Well-Being is unique, that’s why generic insight isn’t insight at all. Dlog understands your context through the four rings and then scores your projects and journals against the same variables. Each entry receives sentiment scores that are compared to your baseline survey, showing where you are progressing or regressing, and why.&lt;/p&gt;
    &lt;p&gt;Trends and relationships between variables are displayed in time-series charts and scatter plots with regression lines – so you can see what drives the changes in your Productivity and Well-Being over time.&lt;/p&gt;
    &lt;head rend="h6"&gt;Understand What Drives Your Well-Being&lt;/head&gt;
    &lt;head rend="h4"&gt;How does extraversion (Personality) react with your Well-Being?&lt;/head&gt;
    &lt;head rend="h6"&gt;Your Happiness over Time&lt;/head&gt;
    &lt;head rend="h4"&gt;How did your happiness trend over the past week?&lt;/head&gt;
    &lt;head rend="h6"&gt;Distribution of your Happiness&lt;/head&gt;
    &lt;head rend="h4"&gt;Dlog shows how your life over the past week or month compares to your baseline, and explains the drivers behind any change.&lt;/head&gt;
    &lt;head rend="h4"&gt;Built on a decade of research. Dlog learns your personality, standards, and constraints. It recommends precise steps that increase resources, strengthen character, and raise the quality of your well-being—through personal science.&lt;/head&gt;
    &lt;head rend="h1"&gt;Personal Science&lt;/head&gt;
    &lt;head rend="h6"&gt;For your eyes only&lt;/head&gt;
    &lt;head rend="h2"&gt;A study of you, for you&lt;/head&gt;
    &lt;head rend="h3"&gt;Dlog produces a PhD grade article using mixed methods about you; just for your eyes.&lt;/head&gt;
    &lt;p&gt;Combining both thematic narrative analysis as well as regression and structured equation model analysis (see the Dlog Model below), the Dlog will produce a comprehensive academic article to help you understand your reality.&lt;/p&gt;
    &lt;head rend="h4"&gt;Narrative analysis is linked closely to the SEM model; i.e., themes are derived from the four constructs; and initial axial coding is grouped into constructs that are recognisable from the 4 Rings framework. The result is a rich and deeply insightful analysis that has significantly more depth than a simple LLM analysis; no AI on its own can compete with this human centric model and narrative analysis, no matter how much memory or parameters it may contain.&lt;/head&gt;
    &lt;head rend="h1"&gt;Dlog Model&lt;/head&gt;
    &lt;head rend="h6"&gt;Proprietary Model&lt;/head&gt;
    &lt;head rend="h2"&gt;How personality and character drive well-being and income&lt;/head&gt;
    &lt;head rend="h3"&gt;The Dlog model is the backbone of the quantitative and qualitative analysis.&lt;/head&gt;
    &lt;p&gt;Dlog’s private AI model is based on our lead scientist’s PhD and bolstered by decades of research into Productivity and Well-Being, mapping your life across the four constructs – Personality, Character, Resources and Well-Being.&lt;/p&gt;
    &lt;p&gt;When you first use the coach, you answer a baseline survey of the four constructs, so that Dlog knows where you have been over the past year. As you journal and work on projects, your entries are scored against the same baseline survey so that you can see if you are above or below your norm in any of the four rings.&lt;/p&gt;
    &lt;p&gt;From there, Dlog’s AI suggests next steps that you can choose from in order to maximise your personal Productivity and Well-Being.&lt;/p&gt;
    &lt;head rend="h4"&gt;Through regular, guided journaling and accountable projects, Dlog helps you achieve your goals with an AI coach informed by your personal data analysed through the Dlog Model.&lt;/head&gt;
    &lt;p&gt;Regressions and structural equation modelling (SEM) are then used to trace directed paths between constructs, showing how changes in one area drives changes in another (e.g., habits, people or traits influencing mood, progress or resources). Dlog focuses on the most informative positive and negative paths, and includes a Quality of Well-Being dimension to distinguish hollow wins from integrated fulfilment.&lt;/p&gt;
    &lt;p&gt;Numbers are never shown without context. Trends and relationships are paired with diary quotes, bringing you back to the moment and grounding the insights in you.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45723646</guid><pubDate>Mon, 27 Oct 2025 17:14:34 +0000</pubDate></item><item><title>The new calculus of AI-based coding</title><link>https://blog.joemag.dev/2025/10/the-new-calculus-of-ai-based-coding.html</link><description>&lt;doc fingerprint="375020776f1115df"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Driving at 200mph&lt;/head&gt;
    &lt;p&gt;Here's where it gets interesting. A typical software team, even an experienced one, doesn't get things right all the time. Even with good testing and engineering practices, bugs occasionally make it through. We've all heard the phrase "testing in production." That reality is the main reason I've always believed that focusing on testing alone is not enough, and investing in blast radius and time to recovery is just as important.&lt;/p&gt;
    &lt;p&gt;AI assisted code is no different, it may contain bugs even when thoroughly reviewed by a human, and I suspect the probabilities are not significantly different. However, when teams ship commits at 10x the rate, the overall math changes. What used to be a production impacting bug once or twice a year, can become a weekly occurrence. Even if most bugs get caught in integration or testing environments, they will still impact the shared code base, requiring investigation and slowing the rest of the team down. Once again, this is not just hyperbole—our team sees signs that these are the challenges that pop up with a step function increase in throughput.&lt;/p&gt;
    &lt;p&gt;I am increasingly convinced that in order for agentic development to increase engineering velocity by an order of magnitude, we need to decrease the probability of problematic commits by an order of magnitude too. And likely by even more than that, since at high velocities individual commits can begin interacting with each other in unexpected ways too.&lt;/p&gt;
    &lt;p&gt;In other words, driving at 200mph, you need a lot of downforce to keep the car on the track!&lt;/p&gt;
    &lt;head rend="h2"&gt;The Cost-Benefit Rebalance&lt;/head&gt;
    &lt;p&gt;One of the best ways to reduce the chance of bugs is to improve testing. I'm an airplane geek, and have always admired the testing ideas used by the airplane manufacturers. From early simulations, to component testing, to wind tunnel testing, to testing to breaking point, and ultimately test flights of fully assembled aircraft. Even flight simulators play a role in improving the overall safety of the industry. Some of these ideas have been tried in the software industry, but they are far from ubiquitous.&lt;/p&gt;
    &lt;p&gt;As an example, I've always liked "wind tunnel" style tests, that test fully assembled system in a controlled environment. To achieve that, one pattern I've used is implementing high fidelity "fake" versions of external dependencies that can be run locally. If you do that, you can then write build-time tests that run locally and verify end-to-end behavior of the whole system. You can even inject unexpected behaviors and failures into fake dependencies, to test how the system handles them. Such tests are easy to write and execute because they run locally, and they are great at catching those sneaky bugs in the seams between components.&lt;/p&gt;
    &lt;p&gt;Unfortunately, faking all the external dependencies isn't always easy for a service with moderate level of complexity. And even if you do, you now have to own keeping up with the real dependencies as they evolve. For those reasons, in my experience most teams don't write such tests.&lt;/p&gt;
    &lt;p&gt;I think we are seeing early signs that agentic coding can change the calculus here. AI agents are great at spitting out large volumes of code, especially when the desired behavior is well known and there's little ambiguity. Ideas that were sound in principle, but too expensive to implement and maintain just had their costs decrease by an order of magnitude. I really love riding such shifts in the industry, because they open the doors to new approaches that weren't practical in the past.&lt;/p&gt;
    &lt;p&gt;Our project (with the help of an AI agent) maintains fake implementations of external dependencies like authentication, storage, chain replication, and inference engine to be used in tests. We then wrote a test harness that uses those fakes to spin up our entire distributed system, including all the micro-services, on developers' machines. Build-time tests then spin up our canaries against that fully assembled stack verifying the system as a whole works.&lt;/p&gt;
    &lt;p&gt;I'm really bullish on this approach catching a category of bugs that in the past could only be caught once the change was committed and made it to the test environment. A few years ago, ideas like these would receive resistance as nice, but too expensive. This time around, it took just a few days to implement for a relatively complex system.&lt;/p&gt;
    &lt;head rend="h2"&gt;Driving Fast Requires Tighter Feedback Loop&lt;/head&gt;
    &lt;p&gt;Agentic coding changes that dynamic. In the amount of time it takes to build, package, and test one set of commits, another dozen might be waiting to go out. By the time a change set is ready to deploy to production, it may contain 100 or more commits. And if one of those commits contains a problem, the deployment needs to be rolled back grinding the pipeline to a halt. In the meantime, even more changes accumulate, adding to the chaos and the risk.&lt;/p&gt;
    &lt;p&gt;I'm a Formula 1 fan, and this reminds me of how an accident on the track can cause a Yellow Flag to be raised. Normally, the cars zoom around the track at immense speeds and accelerations. But if an accident occurs, the race marshals raise a yellow flag, which requires all the cars to slow down behind the pace car. An exciting race turns into a leisurely drive around the track until the debris is cleaned up and the track is safe again. To minimize such slow downs, race organizers go to great lengths to prepare for all types of accidents, and make sure they can clean up the track and restart the race in minutes.&lt;/p&gt;
    &lt;p&gt;Just like whole-system local tests help tighten the feedback loop for catching certain bugs, we may need to think similarly about how we implement our CICD pipelines. When teams are moving at the speed of dozen of commits per hour, problematic issues will need to be identified, isolated, and reverted in minutes instead of hours or days. That means that a typical build and test infrastructure will need to become an order of magnitude faster than it is today. Just like online video games become unplayable when there is high lag between player's inputs and the game's reaction, it's really hard to move 10x faster if every commit still requires a lengthy delay before you see the feedback.&lt;/p&gt;
    &lt;head rend="h2"&gt;The communication bottleneck&lt;/head&gt;
    &lt;p&gt;I enjoy observing well-run operations. If you've ever peeked behind the curtain of a busy restaurant, then at first sight you may think it's chaos. But if you take a second to notice the details, you'll see that all members are constantly coordinating with each other. Chefs, cooks, wait staff, bussers, and managers pass information back and forth in a continuous stream. By staying in constant sync, a well run restaurant manages to serve its patrons even during peak times, without sacrificing on quality or latency.&lt;/p&gt;
    &lt;p&gt;I believe that achieving similar increase in velocity for a software team requires constraints on how teams communicate. When your throughput increases by an order of magnitude, you're not just writing more code - you're making more decisions. Should we use this caching strategy or that one? How should we handle this edge case? What's the right abstraction here? At normal velocity, a team might make one or two of these decisions per week. At 10x velocity, they are making multiple each day.&lt;/p&gt;
    &lt;p&gt;The challenge is that many of these decisions impact what others are working on. Engineer A decides to refactor the authentication flow, which affects the API that Engineer B is about to extend. These aren't just implementation details - they're architectural choices that ripple through the codebase.&lt;/p&gt;
    &lt;p&gt;I find that traditional coordination mechanisms introduce too much latency here. Waiting for a Slack response or scheduling a quick sync for later in the day means either creating a bottleneck - the decision blocks progress - or risking going down the wrong path before realizing the conflict. At high throughput, the cost of coordination can dominate!&lt;/p&gt;
    &lt;p&gt;One approach is to eliminate coordination - if everybody works on independent components, they are unlikely to need to coordinate. But I find that ideal impractical in most real-world systems. So another alternative is to significantly decrease the cost of coordination. Our team sits on the same floor, and I think that's been critical to our velocity. When someone needs to make a decision that might impact others, they can walk over and hash it out in minutes in front of a whiteboard. We align on the approach, discuss trade-offs in real time, and both engineers get back to work. The decision gets made quickly, correctly, and without creating a pile-up of blocked work.&lt;/p&gt;
    &lt;p&gt;I recognize this doesn't solve the problem for distributed teams—that remains an open challenge.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Path Forward&lt;/head&gt;
    &lt;p&gt;I'm really excited about the potential of agentic development. I think it has the capability to not only improve the efficiency of software development, but also allow us to tackle problems that were previously too niche or expensive to solve. The gains are real - our team's 10x throughput increase isn't theoretical, it's measurable.&lt;/p&gt;
    &lt;p&gt;But here's the critical part: these gains won't materialize if we simply bolt AI agents onto our existing development practices. Like adding a turbocharger to a car with narrow tires and old brakes, the result won't be faster lap times - it will be crashes. At 10x code velocity, our current approaches to testing, deployment, and team coordination become the limiting factors. The bottleneck just moves.&lt;/p&gt;
    &lt;p&gt;This means we need to fundamentally rethink how we approach building software. CICD pipelines designed for 10 commits per day will buckle under 100. Testing strategies that were "good enough" at normal velocity will let too many bugs through at high velocity. Communication patterns that worked fine before will create constant pile-ups of blocked work.&lt;/p&gt;
    &lt;p&gt;The good news is that we already have great ideas for comprehensive testing, rapid deployment, and efficient coordination - ideas that have shown promise but haven't seen wide adoption because they were too expensive to implement and maintain. What's changed is that agentic development itself can dramatically lower those costs. The same AI agents that are increasing our code throughput can also help us build the infrastructure needed to sustain that throughput.&lt;/p&gt;
    &lt;p&gt;This is the real opportunity: not just writing more code faster, but using AI to make previously impractical engineering practices practical. The teams that succeed with agentic development will be the ones who recognize that the entire software development lifecycle needs to evolve in concert.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45723686</guid><pubDate>Mon, 27 Oct 2025 17:17:38 +0000</pubDate></item><item><title>MCP-Scanner – Scan MCP Servers for vulnerabilities</title><link>https://github.com/cisco-ai-defense/mcp-scanner</link><description>&lt;doc fingerprint="1d5afd5c98027a90"&gt;
  &lt;main&gt;
    &lt;p&gt;A Python tool for scanning MCP (Model Context Protocol) servers and tools for potential security vulnerabilities. The MCP Scanner combines Cisco AI Defense inspect API, YARA rules and LLM-as-a-judge to detect malicious MCP tools.&lt;/p&gt;
    &lt;p&gt;The MCP Scanner provides a comprehensive solution for scanning MCP servers and tools for security vulnerabilities. It leverages three powerful scanning engines (Yara, LLM-as-judge, Cisco AI Defense) that can be used together or independently.&lt;/p&gt;
    &lt;p&gt;The SDK is designed to be easy to use while providing powerful scanning capabilities, flexible authentication options, and customization.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Multiple Modes: Run scanner as a stand-alone CLI tool or REST API server&lt;/item&gt;
      &lt;item&gt;Multi-Engine Security Analysis: Use all three scanning engines together or independently based on your needs.&lt;/item&gt;
      &lt;item&gt;Comprehensive Scanning: Scan MCP tools, prompts, and resources for security vulnerabilities&lt;/item&gt;
      &lt;item&gt;Explicit Authentication Control: Fine-grained control over authentication with explicit Auth parameters.&lt;/item&gt;
      &lt;item&gt;OAuth Support: Full OAuth authentication support for both SSE and streamable HTTP connections.&lt;/item&gt;
      &lt;item&gt;Custom Endpoints: Configure the API endpoint to support any Cisco AI Defense environments.&lt;/item&gt;
      &lt;item&gt;MCP Server Integration: Connect directly to MCP servers to scan tools, prompts, and resources with flexible authentication.&lt;/item&gt;
      &lt;item&gt;Customizable YARA Rules: Add your own YARA rules to detect specific patterns.&lt;/item&gt;
      &lt;item&gt;Comprehensive Vulnerability Reporting: Detailed reports on detected vulnerabilities.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Python 3.11+&lt;/item&gt;
      &lt;item&gt;uv (Python package manager)&lt;/item&gt;
      &lt;item&gt;A valid Cisco AI Defense API Key (optional)&lt;/item&gt;
      &lt;item&gt;LLM Provider API Key (optional)&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;uv venv -p &amp;lt;Python version less than or equal to 3.13&amp;gt; /path/to/your/choice/of/venv/directory
source /path/to/your/choice/of/venv/directory/bin/activate
uv pip install cisco-ai-mcp-scanner&lt;/code&gt;
    &lt;code&gt;git clone https://github.com/cisco-ai-defense/mcp-scanner
cd mcp-scanner
# Install with uv (recommended)

uv venv -p &amp;lt;Python version less than or equal to 3.13&amp;gt; /path/to/your/choice/of/venv/directory

source /path/to/your/choice/of/venv/directory/bin/activate

uv pip install .
# Or install in development mode
uv pip install -e .&lt;/code&gt;
    &lt;code&gt;Cisco AI Defense API (only required for API analyzer)
export MCP_SCANNER_API_KEY="your_cisco_api_key"
export MCP_SCANNER_ENDPOINT="https://us.api.inspect.aidefense.security.cisco.com/api/v1"
# For other endpoints please visit https://developer.cisco.com/docs/ai-defense/getting-started/#base-url&lt;/code&gt;
    &lt;p&gt;Tested LLMs: OpenAI GPT-4o and GPT-4.1&lt;/p&gt;
    &lt;code&gt;# AWS Bedrock Claude with AWS credentials (profile)
export AWS_PROFILE="your-profile"
export AWS_REGION="us-east-1"
export MCP_SCANNER_LLM_MODEL="bedrock/anthropic.claude-sonnet-4-5-20250929-v2:0" # Any AWS Bedrock supported model

# AWS Bedrock Claude with API key (Bearer token)
export MCP_SCANNER_LLM_API_KEY="bedrock-api-key-..." # Generated via Amazon Bedrock -&amp;gt; API Keys
export AWS_REGION="us-east-1"
export MCP_SCANNER_LLM_MODEL="bedrock/us.anthropic.claude-sonnet-4-5-20250929-v2:0" # Any AWS Bedrock supported model

# LLM Provider API Key (required for LLM analyzer)
export MCP_SCANNER_LLM_API_KEY="your_llm_api_key"  # OpenAI

# LLM Model Configuration (optional - defaults provided)
export MCP_SCANNER_LLM_MODEL="gpt-4o"  # Any LiteLLM-supported model
export MCP_SCANNER_LLM_BASE_URL="https://api.openai.com/v1"  # Custom LLM endpoint
export MCP_SCANNER_LLM_API_VERSION="2024-02-01"  # API version (if required)

# For Azure OpenAI (example)
export MCP_SCANNER_LLM_BASE_URL="https://your-resource.openai.azure.com/"
export MCP_SCANNER_LLM_API_VERSION="2024-02-01"
export MCP_SCANNER_LLM_MODEL="azure/gpt-4"

# For Extended Thinking Models (longer timeout)
export MCP_SCANNER_LLM_TIMEOUT=300&lt;/code&gt;
    &lt;p&gt;The fastest way to get started is using the &lt;code&gt;mcp-scanner&lt;/code&gt; CLI command. Global flags (like &lt;code&gt;--analyzers&lt;/code&gt;, &lt;code&gt;--format&lt;/code&gt;, etc.) must be placed before a subcommand.&lt;/p&gt;
    &lt;code&gt;# Scan well-known client configs on this machine
mcp-scanner --scan-known-configs --analyzers yara --format summary

# Stdio server (example using uvx mcp-server-fetch)
mcp-scanner --stdio-command uvx --stdio-arg=--from --stdio-arg=mcp-server-fetch --stdio-arg=mcp-server-fetch --analyzers yara --format summary

# Remote server (deepwiki example)
mcp-scanner --server-url https://mcp.deepwki.com/mcp --analyzers yara --format summary

# MCP Scanner as REST API
mcp-scanner-api --host 0.0.0.0 --port 8080
&lt;/code&gt;
    &lt;code&gt;import asyncio
from mcpscanner import Config, Scanner
from mcpscanner.core.models import AnalyzerEnum

async def main():
    # Create configuration with your API keys
    config = Config(
        api_key="your_cisco_api_key",
        llm_provider_api_key="your_llm_api_key"
    )

    # Create scanner
    scanner = Scanner(config)

    # Scan all tools on a remote server
    tool_results = await scanner.scan_remote_server_tools(
        "https://mcp.deepwki.com/mcp",
        analyzers=[AnalyzerEnum.API, AnalyzerEnum.YARA, AnalyzerEnum.LLM]
    )

    # Print tool results
    for result in tool_results:
        print(f"Tool: {result.tool_name}, Safe: {result.is_safe}")

    # Scan all prompts on a server
    prompt_results = await scanner.scan_remote_server_prompts(
        "http://127.0.0.1:8000/mcp",
        analyzers=[AnalyzerEnum.LLM]
    )

    # Print prompt results
    for result in prompt_results:
        print(f"Prompt: {result.prompt_name}, Safe: {result.is_safe}")

    # Scan all resources on a server
    resource_results = await scanner.scan_remote_server_resources(
        "http://127.0.0.1:8000/mcp",
        analyzers=[AnalyzerEnum.LLM],
        allowed_mime_types=["text/plain", "text/html"]
    )

    # Print resource results
    for result in resource_results:
        print(f"Resource: {result.resource_name}, Safe: {result.is_safe}, Status: {result.status}")

# Run the scanner
asyncio.run(main())&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;remote: scan a remote MCP server (SSE or streamable HTTP). Supports &lt;code&gt;--server-url&lt;/code&gt;, optional&lt;code&gt;--bearer-token&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;stdio: launch and scan a stdio MCP server. Requires &lt;code&gt;--stdio-command&lt;/code&gt;; accepts&lt;code&gt;--stdio-args&lt;/code&gt;,&lt;code&gt;--stdio-env&lt;/code&gt;, optional&lt;code&gt;--stdio-tool&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;config: scan servers from a specific MCP config file. Requires &lt;code&gt;--config-path&lt;/code&gt;; optional&lt;code&gt;--bearer-token&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;known-configs: scan servers from well-known client config locations on this machine; optional &lt;code&gt;--bearer-token&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;prompts: scan prompts on an MCP server. Requires &lt;code&gt;--server-url&lt;/code&gt;; optional&lt;code&gt;--prompt-name&lt;/code&gt;,&lt;code&gt;--bearer-token&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;resources: scan resources on an MCP server. Requires &lt;code&gt;--server-url&lt;/code&gt;; optional&lt;code&gt;--resource-uri&lt;/code&gt;,&lt;code&gt;--mime-types&lt;/code&gt;,&lt;code&gt;--bearer-token&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: Top-level flags (e.g., &lt;code&gt;--server-url&lt;/code&gt;, &lt;code&gt;--stdio-*&lt;/code&gt;, &lt;code&gt;--config-path&lt;/code&gt;, &lt;code&gt;--scan-known-configs&lt;/code&gt;) remain supported when no subcommand is used, but subcommands are recommended.&lt;/p&gt;
    &lt;code&gt;# YARA-only scan of all servers defined in well-known config locations
mcp-scanner --scan-known-configs --analyzers yara --format summary

# Detailed output
mcp-scanner --scan-known-configs --analyzers yara --detailed&lt;/code&gt;
    &lt;code&gt;# Expand ~ yourself if needed by your shell
mcp-scanner --config-path "$HOME/.codeium/windsurf/mcp_config.json" \
 --analyzers yara --format by_tool&lt;/code&gt;
    &lt;code&gt;# Use repeated --stdio-arg for reliable argument passing
mcp-scanner --analyzers yara --format summary \
  stdio --stdio-command uvx \
  --stdio-arg=--from --stdio-arg=mcp-server-fetch --stdio-arg=mcp-server-fetch

# Or list-form (ensure it doesn't conflict with later flags)
mcp-scanner --analyzers yara --detailed \
  stdio --stdio-command uvx \
  --stdio-args --from mcp-server-fetch mcp-server-fetch

# Scan only a specific tool on the stdio server
mcp-scanner --analyzers yara --format summary \
  stdio --stdio-command uvx \
  --stdio-arg=--from --stdio-arg=mcp-server-fetch --stdio-arg=mcp-server-fetch \
  --stdio-tool fetch&lt;/code&gt;
    &lt;code&gt;# Direct remote server with Bearer token
mcp-scanner --analyzers yara --format summary \
  remote --server-url https://your-mcp-server/sse --bearer-token "$TOKEN"

# Apply Bearer token to all remote servers discovered from configs
mcp-scanner --analyzers yara --detailed known-configs --bearer-token "$TOKEN"
mcp-scanner --analyzers yara --format by_tool \
  config --config-path "$HOME/.codeium/windsurf/mcp_config.json" --bearer-token "$TOKEN"&lt;/code&gt;
    &lt;code&gt;# Scan all prompts on an MCP server
mcp-scanner --analyzers llm prompts --server-url http://127.0.0.1:8000/mcp

# Scan all prompts with detailed output
mcp-scanner --analyzers llm --detailed prompts --server-url http://127.0.0.1:8000/mcp

# Scan all prompts with table format
mcp-scanner --analyzers llm --format table prompts --server-url http://127.0.0.1:8000/mcp

# Scan a specific prompt by name
mcp-scanner --analyzers llm prompts --server-url http://127.0.0.1:8000/mcp --prompt-name "greet_user"

# Get raw JSON output
mcp-scanner --analyzers llm --raw prompts --server-url http://127.0.0.1:8000/mcp&lt;/code&gt;
    &lt;code&gt;# Scan all resources on an MCP server
mcp-scanner --analyzers llm resources --server-url http://127.0.0.1:8000/mcp

# Scan all resources with detailed output
mcp-scanner --analyzers llm --detailed resources --server-url http://127.0.0.1:8000/mcp

# Scan all resources with table format
mcp-scanner --analyzers llm --format table resources --server-url http://127.0.0.1:8000/mcp

# Scan a specific resource by URI
mcp-scanner --analyzers llm resources --server-url http://127.0.0.1:8000/mcp \
  --resource-uri "file://test/document.txt"

# Scan with custom MIME type filtering
mcp-scanner --analyzers llm resources --server-url http://127.0.0.1:8000/mcp \
  --mime-types "text/plain,text/html,application/json"&lt;/code&gt;
    &lt;p&gt;The API server provides a REST interface to the MCP scanner functionality, allowing you to integrate security scanning into web applications, CI/CD pipelines, or other services. It exposes the same scanning capabilities as the CLI tool but through HTTP endpoints.&lt;/p&gt;
    &lt;code&gt;# Start the API server (loads configuration from .env file)
mcp-scanner-api --port 8000

# Or with custom host and port
mcp-scanner-api --host 0.0.0.0 --port 8080

# Enable development mode with auto-reload
mcp-scanner-api --reload&lt;/code&gt;
    &lt;p&gt;Once running, the API server provides endpoints for:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;/scan-tool&lt;/code&gt;- Scan a specific tool on an MCP server&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/scan-all-tools&lt;/code&gt;- Scan all tools on an MCP server&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/scan-prompt&lt;/code&gt;- Scan a specific prompt on an MCP server&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/scan-all-prompts&lt;/code&gt;- Scan all prompts on an MCP server&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/scan-resource&lt;/code&gt;- Scan a specific resource on an MCP server&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/scan-all-resources&lt;/code&gt;- Scan all resources on an MCP server&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/health&lt;/code&gt;- Health check endpoint&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Documentation is available in docs/api-reference.md or as interactive documentation at &lt;code&gt;http://localhost:8000/docs&lt;/code&gt; when the server is running.&lt;/p&gt;
    &lt;p&gt;The scanner supports multiple output formats:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;summary&lt;/code&gt;: Concise overview with key findings&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;detailed&lt;/code&gt;: Comprehensive analysis with full findings breakdown&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;table&lt;/code&gt;: Clean tabular format&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;by_severity&lt;/code&gt;: Results grouped by severity level&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;raw&lt;/code&gt;: Raw JSON output&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;mcp-scanner --server-url http://127.0.0.1:8001/sse --format detailed&lt;/code&gt;
    &lt;code&gt;=== MCP Scanner Detailed Results ===

Scan Target: http://127.0.0.1:8001/sse

Tool: execute_system_command
Status: completed
Safe: No
Analyzer Results:
  • api_analyzer:
    - Severity: HIGH
    - Threat Summary: Detected 1 threat: security violation
    - Threat Names: SECURITY VIOLATION
    - Total Findings: 1
  • yara_analyzer:
    - Severity: HIGH
    - Threat Summary: Detected 2 threats: system access, command injection
    - Threat Names: SECURITY VIOLATION, SUSPICIOUS CODE EXECUTION
    - Total Findings: 2
  • llm_analyzer:
    - Severity: HIGH
    - Threat Summary: Detected 2 threats: prompt injection, tool poisoning
    - Threat Names: PROMPT INJECTION, SUSPICIOUS CODE EXECUTION
    - Total Findings: 2
&lt;/code&gt;
    &lt;code&gt;mcp-scanner --server-url http://127.0.0.1:8002/sse --format table&lt;/code&gt;
    &lt;code&gt;=== MCP Scanner Results Table ===

Scan Target: http://127.0.0.1:8002/sse

Scan Target                   Tool Name     Status     API      YARA     LLM      Severity
-----------------------------------------------------------------------------------------
http://127.0.0.1:8002/sse     exec_secrets  UNSAFE     HIGH     HIGH     HIGH     HIGH
http://127.0.0.1:8002/sse     safe_command  SAFE       SAFE     SAFE     SAFE     SAFE
&lt;/code&gt;
    &lt;p&gt;For detailed documentation, see the docs/ directory:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Architecture - System architecture and components&lt;/item&gt;
      &lt;item&gt;Authentication - OAuth and security configuration&lt;/item&gt;
      &lt;item&gt;Programmatic Usage - Programmatic usage examples and advanced usage&lt;/item&gt;
      &lt;item&gt;API Reference - Complete REST API documentation&lt;/item&gt;
      &lt;item&gt;Output Formats - Detailed output format options&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;https://www.cisco.com/site/us/en/products/security/ai-defense/index.html&lt;/p&gt;
    &lt;p&gt;Distributed under the &lt;code&gt;Apache 2.0&lt;/code&gt; License. See LICENSE for more information.&lt;/p&gt;
    &lt;p&gt;Project Link: https://github.com/cisco-ai-defense/mcp-scanner&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45723699</guid><pubDate>Mon, 27 Oct 2025 17:18:39 +0000</pubDate></item><item><title>Creating an all-weather driver</title><link>https://waymo.com/blog/2025/10/creating-an-all-weather-driver</link><description>&lt;doc fingerprint="39afdc53bfb06cf0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Creating an all-weather Driver&lt;/head&gt;
    &lt;p&gt;Life doesn't freeze when winter comes—if anything, that's when riders need reliable transportation most, when being exposed to the elements becomes less appealing. Today, the Waymo Driver successfully navigates rain, fog, sandstorms, and freezing temperatures. As we expand to more cities across the U.S. and globally, we're applying the same systematic, scientific approach that enabled us to validate the Waymo Driver for these conditions to advance our capabilities for snowier, winter weather.&lt;/p&gt;
    &lt;p&gt;Our proven, safety-guided methodology involves four key steps:&lt;/p&gt;
    &lt;p&gt;Understanding the Challenge&lt;/p&gt;
    &lt;p&gt;Snow isn't a single phenomenon—it's a spectrum of conditions that can affect a human or autonomous driver in multiple ways. Atmospheric conditions can range from a light dusting to a complete whiteout, while road surfaces may be snow-covered or have icy patches, and environmental factors like snow buildup along roadsides add further complexity. For years, we've been advancing our system in some of the snowiest conditions across the country —regularly driving in Upstate New York, Michigan's Upper Peninsula, and the Sierra. We've amassed tens of thousands of miles in diverse, snowy conditions. This has allowed the Waymo Driver’s AI to learn from real driving experience and train to navigate a wide range of winter weather.&lt;/p&gt;
    &lt;p&gt;Designing Generalizable Solutions&lt;/p&gt;
    &lt;p&gt;At Waymo, we're building one autonomous system that works across diverse conditions—the same Waymo Driver navigating foggy San Francisco can navigate snowy Denver. Our 6th-generation Driver is informed by over 100 million fully autonomous miles of driving experience, combining state-of-the-art hardware and AI to adapt to and sustain fully autonomous operations in cities with harsher weather.&lt;/p&gt;
    &lt;p&gt;The Waymo Driver uses cameras, radar, and lidar to perceive the world around it, with each sensor providing a complementary field of view that's especially helpful in inclement weather. Its automated cleaning system –using clever engineering and heating elements – keeps the sensors clear so the vehicle can continue serving riders without needing to pull over.&lt;/p&gt;
    &lt;p&gt;Our system provides context not only about where it's operating, but also about the conditions it’s operating under. We're creating state-of-the-art AI, building on top of our existing models with richer inputs and advanced capabilities designed to navigate winter conditions. For example, our AI can distinguish between where there's snow, slush, ice, and normal road surface. The Waymo Driver then uses this information to adjust its driving behavior to match the road conditions in real-time, allowing the Waymo Driver to navigate based on what it sees (and feels), also inferring insights from other road users—adapting to blocked roads, detours, and changing surface conditions. When the system detects lower traction, it automatically adjusts its speed, acceleration, and braking. Each vehicle essentially acts as a mobile weather station, gathering data to inform its own driving decisions and share with the rest of the fleet in the city. These responses are consistent and thoroughly tested, providing predictable and safe navigation in challenging conditions.&lt;/p&gt;
    &lt;p&gt;Rigorously Validating Our Capabilities&lt;/p&gt;
    &lt;p&gt;We validate our generalizable system through real-world driving, closed-course testing, and large-scale simulation. With our growing operations in snowy cities like Detroit, Denver, and Washington D.C., in addition to visits to other areas, we're deepening our understanding of winter weather conditions and validating our capabilities. At closed-course testing facilities, we push the system to its limits in controlled environments, teaching it to recognize and respond to extreme scenarios like losing traction on ice. Then, we expand our learning year-round through simulation, long after the last snowflake has melted, so the Waymo Driver is prepared for rare and unusual events, like once-in-100-year snow New Orleans experienced this past winter.&lt;/p&gt;
    &lt;p&gt;Scaling Responsibly&lt;lb/&gt;Once we've validated our technology and operations by our Safety Framework and high caliber for rider excellence, we expand our service with clear guidelines about when our vehicles will operate based on local conditions. As we scale, we're also refining our operations to support winter service—from keeping our fleet clean and charged in freezing temperatures to optimizing the rider experience. Winter weather is complex, but we're committed to providing reliable service when riders need it most. As we continue expanding to more cities around the world, our progress is guided by safety, and riders can trust that the Waymo Driver is ready when we open our doors.&lt;lb/&gt;Looking for an all-weather Driver instead of all-weather tires? Follow along on our progress to bring Waymo to more cities at waymo.com/updates.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45724913</guid><pubDate>Mon, 27 Oct 2025 18:57:57 +0000</pubDate></item><item><title>Study finds growing social circles may fuel polarization</title><link>https://phys.org/news/2025-10-friends-division-social-circles-fuel.html</link><description>&lt;doc fingerprint="b71dc3835465878d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;More friends, more division: Study finds growing social circles may fuel polarization&lt;/head&gt;
    &lt;head rend="h5"&gt;Sadie Harley&lt;/head&gt;
    &lt;p&gt;scientific editor&lt;/p&gt;
    &lt;head rend="h5"&gt;Robert Egan&lt;/head&gt;
    &lt;p&gt;associate editor&lt;/p&gt;
    &lt;p&gt;Between 2008 and 2010, polarization in society increased dramatically alongside a significant shift in social behavior: the number of close social contacts rose from an average of two to four or five people. The connection between these two developments could provide a fundamental explanation for why societies around the world are increasingly fragmenting into ideological bubbles.&lt;/p&gt;
    &lt;p&gt;"The big question that not only we, but many countries are currently grappling with, is why polarization has increased so dramatically in recent years," says Stefan Thurner from the Complexity Science Hub (CSH), explaining the study's motivation. The research was published in Proceedings of the National Academy of Sciences.&lt;/p&gt;
    &lt;p&gt;The researchers' findings confirm that increasing polarization is not merely perceived—it is measurable and objectively occurring. "And this increase happened suddenly, between 2008 and 2010," says Thurner. The question remained: what caused it?&lt;/p&gt;
    &lt;head rend="h2"&gt;The friendship shift: From two to five close contacts&lt;/head&gt;
    &lt;p&gt;To investigate, Thurner and his team examined whether social networks had changed—specifically, whether people's close friendships had shifted. "For decades, sociological studies showed that people maintained an average of about two close friends—people who could influence their opinions on important issues," explains Thurner.&lt;/p&gt;
    &lt;p&gt;Here too, the researchers identified a striking change: "Around 2008, there was a sharp increase from an average of two close friends to four or five," explains CSH scientist Jan Korbel.&lt;/p&gt;
    &lt;head rend="h2"&gt;The paradox: More connection, more division&lt;/head&gt;
    &lt;p&gt;Are these two developments related? Do more close friends—and thus denser social networks—lead to network fragmentation and ultimately societal polarization?&lt;/p&gt;
    &lt;p&gt;Using a model based on real data, the researchers discovered this could indeed be the case: "When network density increases with more connections, polarization within the collective inevitably rises sharply," says Markus Hofer from CSH.&lt;/p&gt;
    &lt;p&gt;"This finding impressed us greatly because it could provide a fundamental explanation for the peculiar form of polarization we're currently observing simultaneously across many parts of the world—one that definitely threatens democracy," Thurner continues.&lt;/p&gt;
    &lt;p&gt;"When people are more connected with each other, they encounter different opinions more frequently. This inevitably leads to more conflict and thus greater societal polarization," adds Korbel.&lt;/p&gt;
    &lt;p&gt;Polarization has always existed, but what is happening now goes far beyond historical patterns. Greater connectivity has led to the formation of fewer but more tightly-knit groups with strongly differing opinions, between which there is hardly any exchange.&lt;/p&gt;
    &lt;p&gt;"There are few bridges between these 'bubbles,' and when they exist, they are often negative or even hostile," says Korbel. "This is called fragmentation, and it represents a new social phenomenon," adds Thurner.&lt;/p&gt;
    &lt;head rend="h2"&gt;Behind the numbers: Tracking polarization through decades of data&lt;/head&gt;
    &lt;p&gt;For their study, the researchers analyzed extensive existing survey data on both polarization and social networks.&lt;/p&gt;
    &lt;p&gt;"To measure political polarization, we used over 27,000 surveys from the Pew Research Center, which regularly records political attitudes of people in the US," explains Hofer.&lt;/p&gt;
    &lt;p&gt;"The key advantage of this data is that the questions have remained virtually unchanged over time, enabling reliable long-term comparisons."&lt;/p&gt;
    &lt;p&gt;The researchers found that political attitudes became significantly more one-sided between 1999 and 2017. For example, only 14% of respondents consistently expressed liberal views in 1999, but by 2017, this had risen to 31%. Conversely, only 6% of respondents consistently held conservative views in 1999, compared to 16% in 2017.&lt;/p&gt;
    &lt;p&gt;"More and more people are clearly aligning themselves with one political camp rather than holding a mixture of liberal and conservative views," explains Hofer.&lt;/p&gt;
    &lt;p&gt;To analyze friendship networks, the researchers combined 30 different surveys totaling over 57,000 respondents from Europe and the US, including the General Social Survey (US) and the European Social Survey.&lt;/p&gt;
    &lt;p&gt;"Despite minor differences between individual surveys, the data consistently show that the average number of close friendships rose from 2.2 in 2000 to 4.1 in 2024," says Hofer.&lt;/p&gt;
    &lt;p&gt;"The decisive contribution of this study is that it reconciled both phenomena using a mathematical social model," explains Thurner.&lt;/p&gt;
    &lt;p&gt;"This enabled us to show that increasing connectivity must lead to sudden polarization once a critical connectivity density is exceeded—just like a phase transition in physics, such as water turning to ice," adds Hofer.&lt;/p&gt;
    &lt;p&gt;"It is fascinating that these phase transitions also exist in societies. The exact location of these critical thresholds still needs clarification. According to our results, for close relationships, it lies somewhere between three and four people," the researchers note.&lt;/p&gt;
    &lt;head rend="h2"&gt;The smartphone era: When connection may have become fragmentation&lt;/head&gt;
    &lt;p&gt;The sharp rise in both polarization and the number of close friends occurred between 2008 and 2010—precisely when social media platforms and smartphones first achieved widespread adoption. This technological shift may have fundamentally changed how people connect with each other, indirectly promoting polarization.&lt;/p&gt;
    &lt;p&gt;"Democracy depends on all parts of society being involved in decision-making, which requires that everyone be able to communicate with each other. But when groups can no longer talk to each other, this democratic process breaks down," emphasizes Stefan Thurner.&lt;/p&gt;
    &lt;p&gt;Tolerance plays a central role. "If I have two friends, I do everything I can to keep them—I am very tolerant towards them. But if I have five and things become difficult with one of them, it's easier to end that friendship because I still have 'backups.' I no longer need to be as tolerant," explains Thurner.&lt;/p&gt;
    &lt;p&gt;What disappears as a result is a societal baseline of tolerance—a development that could contribute to the long-term erosion of democratic structures. To prevent societies from increasingly fragmenting, Thurner emphasizes the importance of learning early how to engage with different opinions and actively cultivating tolerance.&lt;/p&gt;
    &lt;p&gt;More information: Thurner, Stefan, Why more social interactions lead to more polarization in societies, Proceedings of the National Academy of Sciences (2025). DOI: 10.1073/pnas.2517530122. doi.org/10.1073/pnas.2517530122&lt;/p&gt;
    &lt;p&gt;Journal information: Proceedings of the National Academy of Sciences&lt;/p&gt;
    &lt;p&gt;Provided by Complexity Science Hub Vienna&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45725009</guid><pubDate>Mon, 27 Oct 2025 19:06:34 +0000</pubDate></item><item><title>Easy RISC-V</title><link>https://dramforever.github.io/easyriscv/</link><description>&lt;doc fingerprint="bae7c0d12017aa49"&gt;
  &lt;main&gt;&lt;p&gt;(Last updated: 2025-10-27 14:51)&lt;/p&gt;&lt;p&gt;This page is not designed to be used on a narrow screen or without CSS. If you’re having issues using the emulator, try the emulators disabled version.&lt;/p&gt;&lt;p&gt;An interactive introduction to RISC-V assembly programming, by dramforever.&lt;/p&gt;&lt;p&gt;Interested in the code? Want to report an issue? Check out the GitHub page: https://github.com/dramforever/easyriscv&lt;/p&gt;&lt;p&gt;Inspired by Easy 6502 by Nick Morgan, this is a quick-ish introductory tutorial to RISC-V assembly programming. This tutorial is intended for those with a basic familiarity with low level computer science concepts, but unfamiliar with RISC-V. If you’re curious about RISC-V, I hope this will be a good start to your journey to learning about it.&lt;/p&gt;&lt;p&gt;RISC-V (pronounced “risk-five”), as its name suggests, is RISC (Reduced instruction set computer) architecture. Having started its life at UC Berkerley, RISC-V has bred a lively community of students, researchers, engineers and hobbyists working on software and hardware. Some highlights of RISC-V include:&lt;/p&gt;&lt;p&gt;RISC-V is less mature than more established architectures like x86 or Arm, but it is quickly gaining steam and has found great success in many areas of application, such as embedded systems, custom processors, education, and research.&lt;/p&gt;&lt;p&gt;This article will cover the 32-bit bare bones RV32I_Zicsr instruction set with a tiny subset of the privileged architecture. You’ll probably never find a “real” chip with such bare bones instruction support. Most of them will have more extensions for other features like floating point or compressed instructions. However, I would still consider what we have here a “complete” instruction set. For example, Rust has Tier 2 support for the target &lt;code&gt;riscv32i-unknown-none-elf&lt;/code&gt;
which works completely fine with only the instructions we’ll cover
here.&lt;/p&gt;&lt;p&gt;Speaking of instructions we will cover, why don’t we meet the 45 of them right here and now:&lt;/p&gt;&lt;code&gt;lui auipc
jal jalr
beq bne blt bge bltu bgeu
lb lh lw lbu lhu sb sh sw
addi slti sltiu xori ori andi slli srli srai
add sub slt sltu xor or and sll srl sra
ecall ebreak
csrrw csrrs csrrc csrrwi csrrsi csrrci&lt;/code&gt;&lt;p&gt;Some of these instruction names should ring a bell (&lt;code&gt;add&lt;/code&gt;,
&lt;code&gt;or&lt;/code&gt;, &lt;code&gt;xor&lt;/code&gt;). Others will look like they have some
pattern to it. A few weird ones like &lt;code&gt;auipc&lt;/code&gt; stand out. These
instructions form the foundation of RISC-V, performing the basic tasks a
processor would do.&lt;/p&gt;&lt;p&gt;You will also catch a glimpse of what creating an operating system on RISC-V is like, namely handling exceptions and privilege levels.&lt;/p&gt;&lt;p&gt;Let’s get started.&lt;/p&gt;&lt;p&gt;Throughout this article you will see emulator panes like these:&lt;/p&gt;&lt;p&gt;(If you just see a code block, there’s a JavaScript problem. Make sure you’ve enabled JavaScript, probably…)&lt;/p&gt;&lt;p&gt;You can use the buttons to control each emulator. Go ahead and click on ‘Start’. A register view should pop up showing the state of the emulator. Now click on ‘Run’. You’ll notice that:&lt;/p&gt;&lt;code&gt;a0 (x10) 0x00000000&lt;/code&gt;&lt;p&gt;Changed into:&lt;/p&gt;&lt;code&gt;a0 (x10) 0x00000123&lt;/code&gt;&lt;p&gt;And the emulator stopped. Congratulations, you’ve run your first RISC-V assembly program. First here, at least.&lt;/p&gt;&lt;p&gt;‘Start’ assembles your code and, well, starts the emulator. If there’s a problem with your code, it will tell you about it and the emulator will not start.&lt;/p&gt;&lt;p&gt;When the emulator is started, you can see the current state of the registers in the side pane. More controls also becomes available. ‘Run’ runs until the end or until you hit ‘Pause’. ‘Step’ runs a single step.&lt;/p&gt;&lt;p&gt;If you hit ‘Step’, you’ll notice that the above program takes two steps to run. You may have guessed correctly that the first step corresponds to &lt;code&gt;addi&lt;/code&gt;, and the second corresponds to
&lt;code&gt;ebreak&lt;/code&gt;. The top of the register panel shows
&lt;code&gt;pc&lt;/code&gt;, the current instruction address, and in parentheses the
current instruction.&lt;/p&gt;&lt;p&gt;‘Dump’ opens a new window containing some text. There are two sections: the first is the symbol table, which tells you about the labels in your code:&lt;/p&gt;&lt;code&gt;# Symbols
# 0x40000000 start&lt;/code&gt;&lt;p&gt;The second section is an annotated version of your code:&lt;/p&gt;&lt;code&gt;start:
{ 0x40000000: 12300513 } addi x10, x0, 0x123
{ 0x40000004: 00100073 } ebreak&lt;/code&gt;&lt;p&gt;This tells you that the &lt;code&gt;addi&lt;/code&gt; instruction encodes to hex
&lt;code&gt;12300513&lt;/code&gt;, and starts at address hex &lt;code&gt;40000000&lt;/code&gt;.
Similarly, &lt;code&gt;ebreak&lt;/code&gt; encodes as &lt;code&gt;00100073&lt;/code&gt; at
address hex &lt;code&gt;40000004&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;(Note: RISC-V instructions are little-endian, meaning that the four bytes of &lt;code&gt;addi&lt;/code&gt; are actually
&lt;code&gt;13 05 30 12&lt;/code&gt;.)&lt;/p&gt;&lt;p&gt;We’ll talk in detail about all of &lt;code&gt;pc&lt;/code&gt;, registers,
instructions, labels, and the two checkboxes later.&lt;/p&gt;&lt;p&gt;Now you may have also guessed that &lt;code&gt;addi x10, x0, 0x123&lt;/code&gt;
means &lt;code&gt;x10 = x0 + 0x123&lt;/code&gt;. As for &lt;code&gt;ebreak&lt;/code&gt;, for
now, just remember that &lt;code&gt;ebreak&lt;/code&gt; stops the emulator.&lt;/p&gt;&lt;p&gt;The program counter, or &lt;code&gt;pc&lt;/code&gt; is the address of
the current instruction. It points to the instruction to be
executed.&lt;/p&gt;&lt;p&gt;RV32I has 31 general purpose registers numbered &lt;code&gt;x1&lt;/code&gt; through
&lt;code&gt;x31&lt;/code&gt;. These can contain any 32-bit data.&lt;/p&gt;&lt;p&gt;(If you’re wondering, there are no flags for RV32I.)&lt;/p&gt;&lt;p&gt;The register &lt;code&gt;x0&lt;/code&gt; is a
special “zero register”. For computational instructions, you can use
&lt;code&gt;x0&lt;/code&gt; anywhere a register is expected. Reading it always gives
zero, and writing to it just gets ignored. The use of a special register
simplifies the design of the architecture, and this design is shared by
MIPS and Arm AArch64. We will make good use of &lt;code&gt;x0&lt;/code&gt; soon.&lt;/p&gt;&lt;p&gt;(Note: In the emulator, the instruction listed in parenthesis next to &lt;code&gt;pc&lt;/code&gt; in the register view is provided as a convenience and is
not part of the processor state.)&lt;/p&gt;&lt;p&gt;But before we can start talking about instructions themselves, we need a way to talk about the instruction syntax so I can, you know, write it down for you.&lt;/p&gt;&lt;p&gt;The syntax of an instruction is the instruction name and then several comma-separated operands. For example, for this instruction we’ve seen above:&lt;/p&gt;&lt;code&gt;addi x10, x0, 0x123&lt;/code&gt;&lt;p&gt;&lt;code&gt;x10&lt;/code&gt; is the destination register or
&lt;code&gt;rd&lt;/code&gt;. The next operand is
the first (and only) source
register or &lt;code&gt;rs1&lt;/code&gt;. The last operand is an
immediate value or &lt;code&gt;imm&lt;/code&gt;. Using these
abbreviations, we can summarize that the syntax for &lt;code&gt;addi&lt;/code&gt;
is:&lt;/p&gt;&lt;code&gt;addi rd, rs1, imm&lt;/code&gt;&lt;p&gt;Some other instructions have a second source register or &lt;code&gt;rs2&lt;/code&gt;. For example, the
non-immediate &lt;code&gt;add&lt;/code&gt; instruction has this syntax:&lt;/p&gt;&lt;code&gt;add rd, rs1, rs2&lt;/code&gt;&lt;p&gt;Some other instructions have no operands, like &lt;code&gt;ebreak&lt;/code&gt;.
Others have slightly more complex operands.&lt;/p&gt;&lt;p&gt;Using the registers as a playground of numbers, we can use computational instructions to work with them.&lt;/p&gt;&lt;p&gt;As we’ve seen above, you can get a RISC-V machine to add numbers together.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;addi&lt;/code&gt;
instruction adds the value in &lt;code&gt;rs1&lt;/code&gt; to the immediate value
&lt;code&gt;imm&lt;/code&gt;, and puts the result in &lt;code&gt;rd&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;addi rd, rs1, imm&lt;/code&gt;&lt;p&gt;The &lt;code&gt;add&lt;/code&gt; instruction
adds the value in &lt;code&gt;rs1&lt;/code&gt; to the value in &lt;code&gt;rs2&lt;/code&gt;, and
puts the result in &lt;code&gt;rd&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;add rd, rs1, rs2&lt;/code&gt;&lt;p&gt;The opposite of addition is subtraction. The &lt;code&gt;sub&lt;/code&gt; instruction subtracts the
value in &lt;code&gt;rs2&lt;/code&gt; from the value in &lt;code&gt;rs1&lt;/code&gt;
(i.e. &lt;code&gt;rs1 - rs2&lt;/code&gt;), and puts the result in &lt;code&gt;rd&lt;/code&gt;.
There’s no corresponding &lt;code&gt;subi&lt;/code&gt; instruction — Just use
&lt;code&gt;addi&lt;/code&gt; with a negative number.&lt;/p&gt;&lt;code&gt;sub rd, rs1, rs2&lt;/code&gt;&lt;p&gt;Step through this demo program and try writing your own additions and subtractions:&lt;/p&gt;&lt;p&gt;One thing you should note is that the immediate value has a limited range, namely &lt;code&gt;[-2048, 2047]&lt;/code&gt;, the range of a 12-bit two’s
complement signed integer. This limitation is because RV32I uses fixed
32-bit i.e. 4-byte instructions, and only the top 12 bits are available
to encode an immediate value. You can see the hexadecimal value encoded
in the instruction from the ‘Dump’. This article will not go into much
further detail about instruction encodings.&lt;/p&gt;&lt;code&gt;{ 0x40000000: 12300513 } addi x10, x0, 0x123
{ 0x40000004: 55500593 } addi x11, x0, 0x555&lt;/code&gt;&lt;p&gt;Even instructions as simple as addition and subtraction have other interesting uses. We have already used &lt;code&gt;addi x10, x0, 0x123&lt;/code&gt;
to put &lt;code&gt;0x123&lt;/code&gt; in the register &lt;code&gt;x10&lt;/code&gt;. When writing
in assembly, we can use a little shortcut called pseudoinstructions. The
&lt;code&gt;li&lt;/code&gt; (“load immediate”)
pseudoinstruction is a convenient way to put a small value in a
register. It expands to &lt;code&gt;addi rd, x0, imm&lt;/code&gt; when
&lt;code&gt;imm&lt;/code&gt; is in the range &lt;code&gt;[-2048, 2047]&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;li rd, imm&lt;/code&gt;&lt;p&gt;When &lt;code&gt;imm&lt;/code&gt; is &lt;code&gt;0&lt;/code&gt;, &lt;code&gt;addi&lt;/code&gt; copies the
value without changing it because adding zero is the same as doing
nothing. The &lt;code&gt;mv&lt;/code&gt; (“move”)
pseudoinstruction copies the value from &lt;code&gt;rs1&lt;/code&gt; to
&lt;code&gt;rd&lt;/code&gt;. It expands to &lt;code&gt;addi rd, rs1, 0&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;mv rd, rs1&lt;/code&gt;&lt;p&gt;Using the pseudoinstruction is exactly equivalent to using the “real” instruction. You can see in the dump that the two are assembled exactly the same way.&lt;/p&gt;&lt;p&gt;Subtracting from zero is negation. What’s the negative of &lt;code&gt;0x123&lt;/code&gt;?&lt;/p&gt;&lt;p&gt;Hmm, we get &lt;code&gt;0xfffffccd&lt;/code&gt;. That’s the 32-bit two’s complement
representation of &lt;code&gt;-291&lt;/code&gt;, or &lt;code&gt;-0x123&lt;/code&gt;. There’s
plenty of tutorials on this out there, so we’ll just note that whenever
something is “signed”, RISC-V uses two’s complement representation. The
benefit of this is that there are fewer instructions for separate signed
and unsigned instructions — both signed and unsigned numbers have the
same overflow wrap-around behavior.&lt;/p&gt;&lt;p&gt;Speaking of overflow wrap-around, what happens if we add something too much and it overflows? We’ll use &lt;code&gt;add&lt;/code&gt; to repeatedly
double &lt;code&gt;0x123&lt;/code&gt; and see what happens:&lt;/p&gt;&lt;p&gt;As &lt;code&gt;0x123&lt;/code&gt; crawls up to the upper bits and eventually we
get to &lt;code&gt;0x9180_0000&lt;/code&gt;, in the next iteration it turns into
&lt;code&gt;0x2300_0000&lt;/code&gt;. There was an overflow! Doubling of
&lt;code&gt;0x9180_0000&lt;/code&gt; gives &lt;code&gt;0x1_2300_0000&lt;/code&gt;, but that
needs 33 bits in binary, so the highest bit can’t be put in the result.
Since RISC-V doesn’t have flag bits for carry or overflow, it’s simply
gone. The programmer is expected to deal with this.&lt;/p&gt;&lt;p&gt;While we’re talking about bits, another thing we can do with bits is performing bitwise logical operations on them.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;and&lt;/code&gt; instruction
performs a bitwise-“and” between the bits of &lt;code&gt;rs1&lt;/code&gt; and
&lt;code&gt;rs2&lt;/code&gt; and puts the result in &lt;code&gt;rd&lt;/code&gt;. The &lt;code&gt;or&lt;/code&gt; and &lt;code&gt;xor&lt;/code&gt; instructions similarly
performs bitwise-“or” and bitwise-“xor”, respectively.&lt;/p&gt;&lt;code&gt;and rd, rs1, rs2
or rd, rs1, rs2
xor rd, rs1, rs2&lt;/code&gt;&lt;p&gt;Immediate operand versions of the three, namely &lt;code&gt;andi&lt;/code&gt;, &lt;code&gt;ori&lt;/code&gt;, &lt;code&gt;xori&lt;/code&gt; also exist.&lt;/p&gt;&lt;code&gt;andi rd, rs1, imm
ori rd, rs1, imm
xori rd, rs1, imm&lt;/code&gt;&lt;p&gt;Here are some random bit operation examples you can play with:&lt;/p&gt;&lt;p&gt;Remember that the immediate value is in the range &lt;code&gt;[-2048, 2047]&lt;/code&gt;. For negative values, the two’s complement
representation used means that the high bits are all ones. For example,
using &lt;code&gt;-1&lt;/code&gt; as &lt;code&gt;imm&lt;/code&gt; means the second operand is
binary all ones, or &lt;code&gt;0xffff_ffff&lt;/code&gt;. This allows us to use
&lt;code&gt;xori rd, rs1, -1&lt;/code&gt; as bitwise-“not”.&lt;/p&gt;&lt;p&gt;Another interesting operation you can do is to round/align something up or down to a multiple of a power of two. For example, if you want to find the closest multiple of 16 below &lt;code&gt;a&lt;/code&gt;, in binary that would be clearing the lowest
4 bits, or &lt;code&gt;a &amp;amp; ~0b1111&lt;/code&gt;. Conveniently, that’s
&lt;code&gt;a &amp;amp; -16&lt;/code&gt; in two’s complement.&lt;/p&gt;&lt;p&gt;Aligning up is less intuitive, but one idea would be adding 16 first. However that gives an incorrect result for multiples of 16. It’s easy enough to fix though: adding one less works exactly right: &lt;code&gt;(a + 15) &amp;amp; -16&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Usually when you write a comparison of some sort like &lt;code&gt;a == b&lt;/code&gt; or &lt;code&gt;a &amp;gt;= b&lt;/code&gt;, it’s used as a condition
for some &lt;code&gt;if&lt;/code&gt; or loop, but… those things are complicated!
We’ll get to it later.&lt;/p&gt;&lt;p&gt;Sometimes you just want a boolean value out of a comparison. The C convention uses 1 for true and 0 for false, and since the world runs on C now, that’s what RISC-V provides.&lt;/p&gt;&lt;p&gt;In C there are six comparison operators:&lt;/p&gt;&lt;code&gt;== != &amp;lt; &amp;gt; &amp;lt;= &amp;gt;=&lt;/code&gt;&lt;p&gt;The values being compared can also be both signed or both unsigned.&lt;/p&gt;&lt;p&gt;How many comparison instructions do we have at our disposal? Let’s see…&lt;/p&gt;&lt;p&gt;The &lt;code&gt;slt&lt;/code&gt; (“set less
than”) instruction compares &lt;code&gt;rs1&lt;/code&gt; and &lt;code&gt;rs2&lt;/code&gt; as
signed 32-bit integers, and sets &lt;code&gt;rd&lt;/code&gt; to &lt;code&gt;1&lt;/code&gt; if
&lt;code&gt;rs1 &amp;lt; rs2&lt;/code&gt;, and &lt;code&gt;0&lt;/code&gt; otherwise
(&lt;code&gt;rs1 &amp;gt;= rs2&lt;/code&gt;). The &lt;code&gt;sltu&lt;/code&gt; instruction is similar
but it treats the operands as unsigned values. &lt;code&gt;slti&lt;/code&gt; and &lt;code&gt;sltiu&lt;/code&gt; are similar but the
second operand is an immediate value.&lt;/p&gt;&lt;code&gt;slt rd, rs1, rs2
sltu rd, rs1, rs2
slti rd, rs1, imm
sltiu rd, rs1, imm&lt;/code&gt;&lt;p&gt;(Of particular note is &lt;code&gt;sltiu&lt;/code&gt;, where the immediate
operand still has the range &lt;code&gt;[-2048, 2047]&lt;/code&gt; but is sign
extended to 32 bits and then treated as an unsigned value, like what
would happen in C with &lt;code&gt;a &amp;lt; (unsigned)-1&lt;/code&gt;.)&lt;/p&gt;&lt;p&gt;That’s… one of the six comparisons settled. What about the others? As it turns out, we can synthesize any of the other five, using up to two instructions.&lt;/p&gt;&lt;p&gt;Making &lt;code&gt;&amp;gt;&lt;/code&gt; from &lt;code&gt;&amp;lt;&lt;/code&gt; is easy, as you can
just swap the operands. Using &lt;code&gt;xori&lt;/code&gt; with &lt;code&gt;1&lt;/code&gt; we
can invert the result of a comparison, giving as &lt;code&gt;&amp;lt;=&lt;/code&gt; and
&lt;code&gt;&amp;gt;=&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;That was signed comparison but unsigned comparison works the same using &lt;code&gt;sltu&lt;/code&gt; instead of &lt;code&gt;slt&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;As for &lt;code&gt;==&lt;/code&gt; and &lt;code&gt;!=&lt;/code&gt;, let’s tackle the easier
case of &lt;code&gt;a == 0&lt;/code&gt; and &lt;code&gt;a != 0&lt;/code&gt; first. We will use
the fact that for unsigned values, &lt;code&gt;a != 0&lt;/code&gt; is equivalent to
&lt;code&gt;a &amp;gt; 0&lt;/code&gt;. The negation of that is &lt;code&gt;a &amp;lt;= 0&lt;/code&gt;,
which is the same as &lt;code&gt;a &amp;lt; 1&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;As a bonus, this is also how we get logical not and converting integer to boolean.&lt;/p&gt;&lt;p&gt;Now that we have these, &lt;code&gt;a == b&lt;/code&gt; is just
&lt;code&gt;(a - b) == 0&lt;/code&gt;, and &lt;code&gt;a != b&lt;/code&gt; is just
&lt;code&gt;(a - b) != 0&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;In summary: (&lt;code&gt;[u]&lt;/code&gt; means use &lt;code&gt;u&lt;/code&gt; for unsigned
comparison and nothing for signed comparison)&lt;/p&gt;&lt;code&gt;a &amp;lt; b&lt;/code&gt;: &lt;code&gt;slt[u]&lt;/code&gt;&lt;code&gt;a &amp;gt; b&lt;/code&gt;: &lt;code&gt;slt[u] reversed&lt;/code&gt;&lt;code&gt;a &amp;lt;= b&lt;/code&gt;: &lt;code&gt;slt[u] reversed ; xori 1&lt;/code&gt;&lt;code&gt;a &amp;gt;= b&lt;/code&gt;: &lt;code&gt;slt[u] ; xori 1&lt;/code&gt;&lt;code&gt;a == 0&lt;/code&gt;: &lt;code&gt;sltu x0&lt;/code&gt;&lt;code&gt;a != 0&lt;/code&gt;: &lt;code&gt;sltiu 1&lt;/code&gt;&lt;code&gt;a == b&lt;/code&gt;: &lt;code&gt;sub ; sltu x0&lt;/code&gt;&lt;code&gt;a != b&lt;/code&gt;: &lt;code&gt;sub ; sltiu 1&lt;/code&gt;&lt;p&gt;There is no way I can do justice to the usage of bit shifts in the middle of a tutorial on RISC-V assembly. If you’re here, you’ve probably heard of them. There’s nothing really special to the way they appear in usage for RISC-V.&lt;/p&gt;&lt;p&gt;There are two variants for right shifting: &lt;code&gt;srl&lt;/code&gt; and &lt;code&gt;srli&lt;/code&gt; (“shift right logical
(immediate)”) performs “logical” or unsigned right shift where the
leftmost or most significant bits are filled with zeros.&lt;/p&gt;&lt;p&gt;&lt;code&gt;sra&lt;/code&gt; and &lt;code&gt;srai&lt;/code&gt; (“shift right
arithmetic (immediate)”) performs “arithmetic” or signed right shift
where the leftmost bits are filled with the same of what highest/sign
bit was. So if you shift a negative value, you get a negative result; if
you shift a non-negative value, you get a non-negative result.&lt;/p&gt;&lt;code&gt;srl rd, rs1, rs2
sra rd, rs1, rs2
srli rd, rs1, imm
srai rd, rs1, imm&lt;/code&gt;&lt;p&gt;As before, the ones with the &lt;code&gt;i&lt;/code&gt; suffix take an immediate
value as the second operand, and the ones without &lt;code&gt;i&lt;/code&gt; take a
register.&lt;/p&gt;&lt;p&gt;So &lt;code&gt;a&lt;/code&gt; means “arithmetic”, &lt;code&gt;l&lt;/code&gt; means “logical”.
Got it.&lt;/p&gt;&lt;p&gt;Left shifts have no such distinction. For consistency they are still “logical”: &lt;code&gt;sll&lt;/code&gt; is left
shift, and &lt;code&gt;slli&lt;/code&gt; is
left shift with immediate.&lt;/p&gt;&lt;code&gt;sll rd, rs1, rs2
slli rd, rs1, imm&lt;/code&gt;&lt;p&gt;Aha, now we can blow up &lt;code&gt;0x123&lt;/code&gt; without repeating myself
so much:&lt;/p&gt;&lt;p&gt;The immediate value for shift instructions are special: they can only be in the range of 0 to 31, inclusive, because it doesn’t make sense to shift by a negative amount, or by more than 31. When the shift amount is taken from a register, the value is considered modulo 32, or in other words only the last 5 bits are taken into account:&lt;/p&gt;&lt;p&gt;For some fun, let’s try multiplying a value by 10, something you would do when parsing decimal numbers: &lt;code&gt;a * 10&lt;/code&gt; can be
rewritten as &lt;code&gt;(a &amp;lt;&amp;lt; 1) + (a &amp;lt;&amp;lt; 3)&lt;/code&gt;:&lt;/p&gt;&lt;p&gt;That’s it?&lt;/p&gt;&lt;p&gt;You may have noticed some glaring omissions. What we’ve learned doesn’t even cover grade school math: multiplication and division are missing.&lt;/p&gt;&lt;p&gt;RISC-V is designed with extensions in mind. Remember that as said in the introduction, RV32I is the barest bones of the barest bones we’ve got. Forcing everyone to make their processors with multiplication and division even for tasks that don’t need them would waste silicon area and money on every chip. Instead those making RISC-V processors have great freedom to choose, and indeed some would say they have too much freedom.&lt;/p&gt;&lt;p&gt;For us… Honestly, I’m just glad we’ve been dealt a hand that we can tackle completely in full. There’s no way I’m finishing writing this tutorial if RV32I wasn’t so bare boned.&lt;/p&gt;&lt;p&gt;(Operand &lt;code&gt;a&lt;/code&gt; is &lt;code&gt;rs1&lt;/code&gt;, and &lt;code&gt;b&lt;/code&gt; is
&lt;code&gt;rs2&lt;/code&gt; or immediate. In the instruction name &lt;code&gt;[i]&lt;/code&gt;
means an immediate variant is available. Subscript &lt;code&gt;u&lt;/code&gt; means
unsigned and &lt;code&gt;s&lt;/code&gt; means two’s complement signed.)&lt;/p&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell role="head"&gt;Instruction&lt;/cell&gt;&lt;cell role="head"&gt;Operation&lt;/cell&gt;&lt;cell role="head"&gt;Immediate range&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;add[i]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;a + b&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[-2048, 2047]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;sub&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;a - b&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;(n/a)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;slt[i]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;(a &amp;lt;s b) ? 1 : 0&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[-2048, 2047]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;slt[i]u&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;(a &amp;lt;u b) ? 1 : 0&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[-2048, 2047]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;xor[i]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;a ^ b&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[-2048, 2047]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;or[i]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;a | b&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[-2048, 2047]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;and[i]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;a &amp;amp; b&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[-2048, 2047]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;sll[i]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;a &amp;lt;&amp;lt; b&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[0, 31]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;srl[i]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;a &amp;gt;&amp;gt;u b&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[0, 31]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;&lt;code&gt;sra[i]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;a &amp;gt;&amp;gt;s b&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[0, 31]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;The &lt;code&gt;addi&lt;/code&gt; instruction has limit on the immediate value.
How do we make bigger values?&lt;/p&gt;&lt;p&gt;The &lt;code&gt;lui&lt;/code&gt; (“load upper
immediate”) instruction takes an immediate in the range
&lt;code&gt;[0, 1048575]&lt;/code&gt; (i.e. up to &lt;code&gt;220 - 1&lt;/code&gt;)
and sets &lt;code&gt;rd&lt;/code&gt; to that value left shifted 12 bits:&lt;/p&gt;&lt;code&gt;lui rd, imm20&lt;/code&gt;&lt;p&gt;That was… slightly confusing. Why don’t we give it a try:&lt;/p&gt;&lt;p&gt;Instead of &lt;code&gt;li&lt;/code&gt; loading a “low” immediate, we control the
upper 20 bits of what we put in the register. After that, we
can use another &lt;code&gt;addi&lt;/code&gt; instruction to fill in the lower bits.
For example, if we want &lt;code&gt;0x12345&lt;/code&gt;:&lt;/p&gt;&lt;p&gt;For convenience, in assembly you can use &lt;code&gt;%hi()&lt;/code&gt; and &lt;code&gt;%lo()&lt;/code&gt; to extract the, well,
high 20 and low 10 bits of a value. The previous example could also be
written:&lt;/p&gt;&lt;p&gt;Letting &lt;code&gt;lui&lt;/code&gt; handle the high 20 bits, and
&lt;code&gt;addi&lt;/code&gt; for the low 12 bits, you can make any 32-bit
value.&lt;/p&gt;&lt;p&gt;(A small complication arises if you want to use values with bit 11 set. In that case, the immediate operand to &lt;code&gt;addi&lt;/code&gt; will have
to be negative. However &lt;code&gt;%hi&lt;/code&gt; understands this and adds one
to compensate, so this &lt;code&gt;%hi&lt;/code&gt;/&lt;code&gt;%lo&lt;/code&gt; combination
does work for everything.)&lt;/p&gt;&lt;p&gt;So far, everything that we’ve had so far can be done on even the most basic programmer’s calculator. To truly make a computer… do computer stuff, we’d want loops and conditionals.&lt;/p&gt;&lt;p&gt;In RISC-V parlance, a branch is a conditional transfer of control flow, and a jump is an unconditional transfer of control flow.&lt;/p&gt;&lt;p&gt;I think the branch instructions are slightly simpler, so let’s start with those.&lt;/p&gt;&lt;p&gt;All the branch instruction follow the form “If some comparison, go to somewhere.” The conditions are:&lt;/p&gt;&lt;code&gt;beq&lt;/code&gt;:
&lt;code&gt;rs1 == rs2&lt;/code&gt; (“equal”)&lt;code&gt;bne&lt;/code&gt;:
&lt;code&gt;rs1 != rs2&lt;/code&gt; (“not equal”)&lt;code&gt;blt&lt;/code&gt;:
&lt;code&gt;rs1 &amp;lt; rs2&lt;/code&gt; signed (“less than”)&lt;code&gt;bge&lt;/code&gt;:
&lt;code&gt;rs1 &amp;gt;= rs2&lt;/code&gt; signed (“greater or equal”)&lt;code&gt;bltu&lt;/code&gt;:
&lt;code&gt;rs1 &amp;lt; rs2&lt;/code&gt; signed (“less than unsigned”)&lt;code&gt;bgeu&lt;/code&gt;:
&lt;code&gt;rs1 &amp;gt;= rs2&lt;/code&gt; signed (“greater or equal unsigned”)&lt;p&gt;(In case you’re wondering about the confusing choice of ordering operators here, it’s just that the negation of &lt;code&gt;&amp;lt;&lt;/code&gt; is
&lt;code&gt;&amp;gt;=&lt;/code&gt;.)&lt;/p&gt;&lt;code&gt;beq rs1, rs2, label
bne rs1, rs2, label
blt rs1, rs2, label
bge rs1, rs2, label
bltu rs1, rs2, label
bgeu rs1, rs2, label&lt;/code&gt;
&lt;p&gt;Oh, right, almost forgot to explain what labels are. Labels are convenience identifiers for addresses at some line of your code. They are some identifier followed by a colon (like &lt;code&gt;this:&lt;/code&gt;). They
can appear on a line of its own, or before any instruction on the line.
You can see which address they point to using the “Dump” button. The
third operand of a branch instruction is a label to jump to if the
condition holds.&lt;/p&gt;&lt;p&gt;Let’s add up all the numbers from 1 to 100:&lt;/p&gt;&lt;p&gt;You can try your hands on making your favorite loops, like fibonacci numbers or something. Speaking of trying your hands, just so we’re ready, here’s what an infinite loop looks like. Try pausing or stopping the loop, and single stepping through the instructions.&lt;/p&gt;&lt;p&gt;(If you know a thing or two about JavaScript in the browser, you’ll know that a real infinite loop in JavaScript makes the whole page becomes unresponsive, unless it’s in a worker or something. The “Run” button here just runs the emulator for a certain number of steps, pausing by giving back control to the event loop in between.)&lt;/p&gt;&lt;p&gt;(This isn’t the preferred way to write an unconditional jump. We’ll see what is later.)&lt;/p&gt;&lt;p&gt;By the way, there’s no &lt;code&gt;bgt[u]&lt;/code&gt; or &lt;code&gt;ble[u]&lt;/code&gt;
because you can just swap &lt;code&gt;rs1&lt;/code&gt; and &lt;code&gt;rs2&lt;/code&gt; to get
those.&lt;/p&gt;&lt;p&gt;There are two jump instructions in RISC-V. One of them is &lt;code&gt;jal&lt;/code&gt; “jump and link”, which
sets &lt;code&gt;rd&lt;/code&gt; to the address of the following instruction, and
then jumps to a label:&lt;/p&gt;&lt;code&gt;jal rd, label&lt;/code&gt;
&lt;p&gt;Another is &lt;code&gt;jalr&lt;/code&gt;
“jump and link register”, which sets &lt;code&gt;rd&lt;/code&gt; to the address of
the following instruction, and then jumps to the address at
&lt;code&gt;imm + rs1&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;jalr rd, imm(rs1)&lt;/code&gt;
&lt;p&gt;(Actually, the address jumped to is &lt;code&gt;(imm + rs1) &amp;amp; ~1&lt;/code&gt;, i.e. the least significant bit is
cleared. This distinction won’t come up in normal code, like, pretty
much ever.)&lt;/p&gt;&lt;p&gt;Eesh, that’s some funky looking syntax. When you see parentheses like this, it has something to do with an address. Parens means address.&lt;/p&gt;&lt;p&gt;That’s… still a lot going on. Let’s take on some simpler cases first: If &lt;code&gt;rd&lt;/code&gt; is &lt;code&gt;x0&lt;/code&gt; then the only thing these
instructions do is jumping. We can use it instead of the branch
instructions for an unconditional jump.&lt;/p&gt;&lt;p&gt;For convenience, a pseudoinstruction is available for you: &lt;code&gt;j&lt;/code&gt; (“jump”) is for
&lt;code&gt;jal&lt;/code&gt; with &lt;code&gt;rd&lt;/code&gt; being &lt;code&gt;x0&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;j label&lt;/code&gt;
&lt;p&gt;As for why you would want to do this… Well, we only have 32 bits per instruction, and since the &lt;code&gt;jal&lt;/code&gt; instruction only needs one
register number instead of the branch instructions’ two, and it doesn’t
need a condition, the instruction encoding permits jumping over a longer
range. So this is always preferred over something like
&lt;code&gt;beq x0, x0, label&lt;/code&gt; for a jump.&lt;/p&gt;&lt;p&gt;As for &lt;code&gt;jalr&lt;/code&gt;, you can jump to an address that’s stored in
a register. In C, that would be dealing with function pointers. You’d
need this any time dynamic dispatch is needed. For example, we load the
address of &lt;code&gt;foo&lt;/code&gt; into a register first before jumping to
it.&lt;/p&gt;&lt;p&gt;In case you forgot by now, the &lt;code&gt;lui&lt;/code&gt;/&lt;code&gt;addi&lt;/code&gt;
combo at the start puts the address of the label &lt;code&gt;foo&lt;/code&gt; in
register &lt;code&gt;x10&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Similar to &lt;code&gt;j&lt;/code&gt;, &lt;code&gt;jr&lt;/code&gt; (“jump register”) is a
psuedoinstruction for &lt;code&gt;jalr&lt;/code&gt; with &lt;code&gt;rd&lt;/code&gt; being
&lt;code&gt;x0&lt;/code&gt; and &lt;code&gt;imm&lt;/code&gt; being &lt;code&gt;0&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;jr rs1&lt;/code&gt;
&lt;p&gt;Hmmm… If I didn’t really need the address in &lt;code&gt;x10&lt;/code&gt;, that
&lt;code&gt;addi&lt;/code&gt; would be unnecessary, since &lt;code&gt;jalr&lt;/code&gt; has the
ability to add a low immediate on its own:&lt;/p&gt;&lt;p&gt;What’s the advantage of this over &lt;code&gt;jal x0&lt;/code&gt;? Since
&lt;code&gt;%hi&lt;/code&gt; and &lt;code&gt;%lo&lt;/code&gt; can represent any 32-bit value,
this two-instruction combo can jump to any address, free from range
restrictions. You do need a free scratch register for the high part of
the address though, but since RISC-V gives you 31 of them, this
shouldn’t be too much of a problem.&lt;/p&gt;&lt;p&gt;What’s the deal with the destination register then? What do you need the address of the next instruction for? For jumping back of course. We can use this functionality to call functions and return back.&lt;/p&gt;&lt;p&gt;Note that I used the register &lt;code&gt;x1&lt;/code&gt; for this, which is the
register for providing the return address by convention. For
convenience, if the destination register is omitted in &lt;code&gt;jal&lt;/code&gt;,
it defaults to &lt;code&gt;x1&lt;/code&gt;. Meanwhile, &lt;code&gt;ret&lt;/code&gt; (“return”) is a
pseudoinstruction that stands for &lt;code&gt;jr x1&lt;/code&gt;,
i.e. &lt;code&gt;jalr x0, 0(x1)&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;jal label
ret&lt;/code&gt;
&lt;p&gt;So the example above can be rewritten more conveniently as:&lt;/p&gt;&lt;p&gt;That’s a nice computer we have here. Now we have… all of 31 × 4 = 124 bytes of storage in the form of registers to work with. I want more…&lt;/p&gt;&lt;p&gt;The emulator has 1 MiB of memory starting at address &lt;code&gt;0x4000_0000&lt;/code&gt;. That’s &lt;code&gt;0x4000_0000&lt;/code&gt; to
&lt;code&gt;0x400f_ffff&lt;/code&gt;, inclusive. The assembler starts assembling at
the beginning of memory, as you can see in the dump, starting at address
&lt;code&gt;0x4000_0000&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;.word&lt;/code&gt; directive straight up puts a
4-byte/32-bit word into the current position. You can specify multiple
values separated by commas.&lt;/p&gt;&lt;code&gt;.word value [ , value [ , ...  ] ]&lt;/code&gt;
&lt;p&gt;The &lt;code&gt;lw&lt;/code&gt; (“load word”)
instruction loads a word from the address &lt;code&gt;rs1 + imm&lt;/code&gt; and
puts it in &lt;code&gt;rd&lt;/code&gt;, in other words it reads the word from
memory:&lt;/p&gt;&lt;code&gt;lw rd, imm(rs1)&lt;/code&gt;
&lt;p&gt;As with &lt;code&gt;jalr&lt;/code&gt;, you can combine it with &lt;code&gt;lui&lt;/code&gt;
to access any address.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;sw&lt;/code&gt; (“store word”)
instruction stores &lt;code&gt;rs2&lt;/code&gt; to a word in memory at address
&lt;code&gt;rs2 + imm&lt;/code&gt;, in other words it writes the word to memory:&lt;/p&gt;&lt;code&gt;sw rs2, imm(rs1)&lt;/code&gt;
&lt;p&gt;Just to make absolutely sure we’re clear on this, load means reading from memory, store means writing to memory. Both words can be nouns and verbs. Also, a word is 32-bit for RISC-V.&lt;/p&gt;&lt;p&gt;Let’s have some fun. Can we have the program read itself?&lt;/p&gt;&lt;p&gt;Ohh that’s fun. Does this mean I can also write programs with just &lt;code&gt;.word&lt;/code&gt;?&lt;/p&gt;&lt;p&gt;Oh that’s nice. Just a peek into the world of machine code and instruction encodings… which we will not be getting into.&lt;/p&gt;&lt;p&gt;With memory accesses under our belt, we can address a lot more data easily. Here’s an example where we find the sum of all the values in an array. Note how we can access different addresses of memory, whereas there is no way to address a register by a number in another register.&lt;/p&gt;&lt;p&gt;The equivalent in C would be something like&lt;/p&gt;&lt;code&gt;uint32_t array[], length;

uint32_t *current = array;
uint32_t *end = array + length;
uint32_t sum = 0;

for (; current != end; current ++) {
    sum += *current;
}&lt;/code&gt;
&lt;p&gt;Note how adding one to a pointer to word bumps the address by 4, because the addresses are all byte addresses, and one word is four bytes. In C, the compiler handles the multiplier for you, but in assembly you have to remember to do it manually.&lt;/p&gt;&lt;p&gt;Not everything in memory is word sized. You’ve already seen an array, which is multiple-word-sized. There are also stuff smaller than word-sized.&lt;/p&gt;&lt;p&gt;An obvious one is the byte, which is, well, 1-byte/8-bit and written &lt;code&gt;[u]int8_t&lt;/code&gt; in C. In
the middle is the halfword,
which is 2-byte/16-bit and written &lt;code&gt;[u]int16_t&lt;/code&gt; in C. You can
use the directives &lt;code&gt;.byte&lt;/code&gt; and &lt;code&gt;.half&lt;/code&gt; respectively for those
data types.&lt;/p&gt;&lt;code&gt;.byte value [ , value [ , ...  ] ]
.half value [ , value [ , ...  ] ]&lt;/code&gt;
&lt;p&gt;And just in case you don’t remember those, &lt;code&gt;.2byte&lt;/code&gt; means the same as
&lt;code&gt;.half&lt;/code&gt;, and &lt;code&gt;.4byte&lt;/code&gt; means the same as
&lt;code&gt;.word&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;.2byte value [ , value [ , ...  ] ] # Same as .half
.4byte value [ , value [ , ...  ] ] # Same as .word&lt;/code&gt;
&lt;p&gt;There’s a small problem with loading smaller-than-word sized values into word-sized registers: What do you do with the rest of the bits? Obviously the lowest of the bits gets the actual value loaded. There are two most useful ways to fill the upper bits:&lt;/p&gt;&lt;p&gt;Zero extension is easy enough. As the name suggests, sign extension has something to do with signed values. It’s what happens when you convert a narrower signed value into a wider one.&lt;/p&gt;&lt;p&gt;(Keeping the rest of the bits unchanged isn’t a good option. It complicates the implementation for processor, especially of modern high performance design, to just write parts of a register. It would be easiest if the new value didn’t depend on the old value.)&lt;/p&gt;&lt;p&gt;For example, the signed byte value &lt;code&gt;-100&lt;/code&gt; is
&lt;code&gt;0x9c&lt;/code&gt;. Since the highest bit i.e. the sign bit of it is
&lt;code&gt;1&lt;/code&gt;, when we expand it into 32 bits we fill the high 24 bits
with one so the new value, &lt;code&gt;0xffff_ff9c&lt;/code&gt; still represents
&lt;code&gt;-100&lt;/code&gt;. This is sign extension.&lt;/p&gt;&lt;p&gt;If we want to convert the unsigned byte value &lt;code&gt;156&lt;/code&gt;, still
&lt;code&gt;0x9c&lt;/code&gt;, into an unsigned word, it would have to be
&lt;code&gt;0x0000_009c&lt;/code&gt; to preserve its value.&lt;/p&gt;&lt;p&gt;For bytes, the &lt;code&gt;lb&lt;/code&gt;
(“load byte”) instruction loads a byte and sign extends the result, and
the &lt;code&gt;lbu&lt;/code&gt; (“load byte
unsigned”) instruction does the same but zero extends the result. As
with &lt;code&gt;lw&lt;/code&gt;, the address is &lt;code&gt;rs1 + imm&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;lb rd, imm(rs1)
lbu rd, imm(rs1)&lt;/code&gt;
&lt;p&gt;Similarly for &lt;code&gt;lh&lt;/code&gt;
(“load half”) and &lt;code&gt;lhu&lt;/code&gt;
(“load half unsigned”), just for unsigned halfwords (two bytes each,
remember):&lt;/p&gt;&lt;code&gt;lh rd, imm(rs1)
lhu rd, imm(rs1)&lt;/code&gt;
&lt;p&gt;We can try out the sign extension and zero extension example from earlier.&lt;/p&gt;&lt;p&gt;Correspondingly, the &lt;code&gt;sb&lt;/code&gt; (“store byte”) and &lt;code&gt;sh&lt;/code&gt; (“store half”) do the
opposite of &lt;code&gt;lb&lt;/code&gt; and &lt;code&gt;lh&lt;/code&gt;, storing bytes and
halfwords to memory. Instead of widening small values to register size,
these take the lowest order bits from &lt;code&gt;rs1&lt;/code&gt; and stores it to
memory. (There’s no &lt;code&gt;sbu&lt;/code&gt; and &lt;code&gt;shu&lt;/code&gt; because stores
are narrowing instead of widening operations.)&lt;/p&gt;&lt;code&gt;sb rs2, imm(rs1)
sh rs2, imm(rs1)&lt;/code&gt;
&lt;p&gt;While we’re at it, here’s two more minor details. Firstly, endianness. While theoretically big endian RISC-V machines can exist, I’ve never seen one… and this emulator is little endian, meaning that the four bytes in a word are laid out in memory lowest first. So, &lt;code&gt;.byte 0x1, 0x2, 0x3, 0x4&lt;/code&gt; would be
the same as &lt;code&gt;.word 0x04030201&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Secondly, memory accesses should be aligned for maximum efficiency. This means that the address for a halfword/2byte should be a multiple of two, and the address for a word/4byte should be a multiple of four. Misaligned accesses (meaning, well, when the address is not aligned) may not work as expected.&lt;/p&gt;&lt;p&gt;For user programs running on a rich operating systems, misaligned accesses are supported but may be slow. In embedded application running on microcontrollers and such, it might not work at all.&lt;/p&gt;&lt;p&gt;This emulator supports misaligned memory accesses.&lt;/p&gt;&lt;p&gt;Now you can try translating some basic C code into RISC-V assembly. Functions are… still out of the question for now. Variables have to be either global or put in registers. What else are we missing…&lt;/p&gt;&lt;p&gt;Is it Hello World time? I think it’s Hello World time…&lt;/p&gt;&lt;p&gt;For a computer to not just be a space heater, we need some way for it to at least generate output and take input. While other architectures may have dedicated I/O instructions, RISC-V uses memory mapped I/O. Essentially, this means that loads and stores to special addresses communicate with other devices. They do not work like normal memory, and you should only use the supported widths to access them.&lt;/p&gt;&lt;p&gt;One output device we have here is at address &lt;code&gt;0x1000_0000&lt;/code&gt;. Any 32-bit writes to it appends the lowest 8
bits as a byte to the text in the output pane. In other words, a
&lt;code&gt;sw&lt;/code&gt; to that address writes a byte of output.&lt;/p&gt;&lt;p&gt;(The output pane uses UTF-8 encoding.)&lt;/p&gt;&lt;p&gt;Eh, close enough to greeting the entire world. We could refactor it a bit to use a loop, or whatever… Now that we think about it, how about going one step further and organize our code into some functions?&lt;/p&gt;&lt;p&gt;We already know how to call a function and return back. Namely, &lt;code&gt;jal&lt;/code&gt; calls a function, and &lt;code&gt;ret&lt;/code&gt; returns. Usually
functions take arguments, uses local variables, and returns results.
Since there’s no real difference between the 31 general purpose
registers, on account of them being, well, general purpose, we could
just use any of them as we wish. Usually though, there are some standard
conventions to follow&lt;/p&gt;&lt;p&gt;This whole time you probably have noticed that registers are listed with two names each, and indeed both work identically in assembly.&lt;/p&gt;&lt;p&gt;These register aliases are named after their uses:&lt;/p&gt;&lt;code&gt;s0&lt;/code&gt; through
&lt;code&gt;s11&lt;/code&gt; are saved registers&lt;code&gt;t0&lt;/code&gt; through
&lt;code&gt;t6&lt;/code&gt; are temporary registers&lt;code&gt;a0&lt;/code&gt; through
&lt;code&gt;a7&lt;/code&gt; are argument registers&lt;code&gt;zero&lt;/code&gt; is the,
well, zero register&lt;code&gt;ra&lt;/code&gt; is for the
return address, by convention, as we’ve seen&lt;code&gt;sp&lt;/code&gt; … we’ll talk
about &lt;code&gt;sp&lt;/code&gt; later&lt;code&gt;tp&lt;/code&gt;
and &lt;code&gt;gp&lt;/code&gt; is out of the
scope of this document.)&lt;p&gt;(Yeah it’s… all placed in a weird order. The reason is out of the scope of this tutorial.)&lt;/p&gt;&lt;p&gt;When you call a function, you put up to eight arguments in the… well, argument registers, in the order &lt;code&gt;a0&lt;/code&gt;, &lt;code&gt;a1&lt;/code&gt;, …,
&lt;code&gt;a7&lt;/code&gt;. After that you use &lt;code&gt;jal&lt;/code&gt; or something, which
puts the return address in &lt;code&gt;ra&lt;/code&gt;, and jumps to the
function.&lt;/p&gt;&lt;p&gt;Inside, the function, if it wishes to use the call-saved registers &lt;code&gt;s0&lt;/code&gt; through &lt;code&gt;s11&lt;/code&gt;, it must save their values at
the start of the function, and restore them before returning. The non
call-saved registers &lt;code&gt;a0&lt;/code&gt; through &lt;code&gt;a7&lt;/code&gt;,
&lt;code&gt;t0&lt;/code&gt; through &lt;code&gt;t6&lt;/code&gt; and &lt;code&gt;ra&lt;/code&gt; may be
modified without restoring their values.&lt;/p&gt;&lt;p&gt;When the called function is done, it would, as mentioned, restore any used call-saved registers, and jump back to the return address, resuming the calling code.&lt;/p&gt;&lt;p&gt;Here’s a basic-ish example:&lt;/p&gt;&lt;code&gt;int memcmp(const void *a, const void *b, size_t n)&lt;/code&gt;
&lt;p&gt;The parameter &lt;code&gt;a&lt;/code&gt; is passed in &lt;code&gt;a0&lt;/code&gt;,
&lt;code&gt;b&lt;/code&gt; is passed in &lt;code&gt;a1&lt;/code&gt;, and &lt;code&gt;n&lt;/code&gt; is
passed in &lt;code&gt;a2&lt;/code&gt;. The return value will be in &lt;code&gt;a0&lt;/code&gt;.
Here’s an implementation and test run:&lt;/p&gt;&lt;p&gt;Here’s a slightly better-organized “Hello World”, using a &lt;code&gt;puts&lt;/code&gt; function:&lt;/p&gt;&lt;p&gt;Although we can write some very basic functions now, there are still a few problems:&lt;/p&gt;&lt;code&gt;ra&lt;/code&gt; would be overwritten, and then you can’t return back
from the outer function anymore.&lt;p&gt;Clearly, both would require using memory somehow. We can feed two birds with one scone by using memory in a structured way: The stack.&lt;/p&gt;&lt;p&gt;Unlike some other architectures, the &lt;code&gt;sp&lt;/code&gt; register is not
really special in any way. But just like how we can designate how
&lt;code&gt;a0&lt;/code&gt; is used, we can have some conventions about how
&lt;code&gt;sp&lt;/code&gt; is supposed to be used:&lt;/p&gt;&lt;code&gt;sp&lt;/code&gt; needs to have the same value as when the
function was entered&lt;code&gt;sp&lt;/code&gt; always points to somewhere in an area of
memory called the “stack”, and it is always 16-byte
aligned.&lt;p&gt;And, for the stack itself:&lt;/p&gt;&lt;code&gt;address &amp;gt;= sp&lt;/code&gt; are “in the stack”, and
&lt;code&gt;address &amp;lt; sp&lt;/code&gt; are free space that the stack can grow
into.&lt;code&gt;sp&lt;/code&gt;, and deallocate space by incrementing &lt;code&gt;sp&lt;/code&gt;.
Of course, allocations and deallocations must be balanced properly.&lt;p&gt;An example is in order. Let’s say you have a function &lt;code&gt;foo&lt;/code&gt; which just calls &lt;code&gt;bar&lt;/code&gt; twice.&lt;/p&gt;&lt;code&gt;void foo() {
    bar();
    bar();
}&lt;/code&gt;
&lt;p&gt;Inside &lt;code&gt;foo&lt;/code&gt;, it would need to save the initial
&lt;code&gt;ra&lt;/code&gt;, so it can return back later. Even though
&lt;code&gt;ra&lt;/code&gt; takes only 4 bytes, &lt;code&gt;sp&lt;/code&gt; needs to be 16-byte
aligned at all times, so we round that up to 16 bytes. Decrementing
&lt;code&gt;sp&lt;/code&gt; by 16 we allocate the space:&lt;/p&gt;&lt;code&gt;foo:
    addi sp, sp, -16&lt;/code&gt;
&lt;p&gt;Now, in addition to all of the non call-saved registers, we have 16 bytes of scratch space at &lt;code&gt;sp&lt;/code&gt; through &lt;code&gt;sp + 15&lt;/code&gt;.
We can backup the value of &lt;code&gt;ra&lt;/code&gt; here&lt;/p&gt;&lt;code&gt;    ...
    sw ra, 0(sp)&lt;/code&gt;
&lt;p&gt;Then we just call &lt;code&gt;bar&lt;/code&gt; twice, which overwrites
&lt;code&gt;ra&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;    ...
    jal bar
    jal bar&lt;/code&gt;
&lt;p&gt;At the end of the function, we just need to get back the return address, deallocate the stack space, and return. Although using any register would suffice for the return address, since it is the backed up value of &lt;code&gt;ra&lt;/code&gt; after all, we load it back to
&lt;code&gt;ra&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;    ...
    lw ra, 0(sp)
    addi sp, sp, 16
    ret&lt;/code&gt;
&lt;p&gt;In a similar way you can save and restore the &lt;code&gt;s&lt;/code&gt;
(remember, call-saved) registers. Usually, the most convenient way to
manage this is to put values that need to be preserved across inner
function calls in the &lt;code&gt;s&lt;/code&gt; registers, and then add code at the
beginning to save them, and add code at the end to restore them.&lt;/p&gt;&lt;p&gt;Obligatory recursive Fibonacci time!&lt;/p&gt;&lt;p&gt;The algorithm should be fairly straightforward:&lt;/p&gt;&lt;code&gt;fibonacci(n) {
    if (n &amp;lt; 2) { return n; }
    else { return fib(n - 1) + fib(n - 2); }
}&lt;/code&gt;
&lt;p&gt;What’s worth noting here is the fairly symmetric pattern of saving registers at the start:&lt;/p&gt;&lt;code&gt;    addi sp, sp, -16
    sw ra, 0(sp)
    sw s0, 4(sp)
    sw s1, 8(sp)&lt;/code&gt;
&lt;p&gt;And restoring them at the end:&lt;/p&gt;&lt;code&gt;    lw ra, 0(sp)
    lw s0, 4(sp)
    lw s1, 8(sp)
    addi sp, sp, 16
    ret&lt;/code&gt;
&lt;p&gt;A little thing to also note that the &lt;code&gt;s&lt;/code&gt; registers are
only saved in the more complex branch, where as the simpler branch just
returns directly. This is also acceptable from a calling convention
perspective.&lt;/p&gt;&lt;p&gt;(Note: In the emulator, the &lt;code&gt;sp&lt;/code&gt; register is initialized
to an address that would be convenient for you for use as a stack, as a,
well, convenience.)&lt;/p&gt;&lt;p&gt;Let’s go back to this example:&lt;/p&gt;&lt;code&gt;    # void puts(const char *);
puts:
    lui t1, %hi(0x10000000)
puts_loop:
    lb t0, 0(a0)
    beq t0, zero, puts_done
    sw t0, 0(t1)
    addi a0, a0, 1
    j puts_loop

puts_done:
    ret&lt;/code&gt;
&lt;p&gt;Having to name things like &lt;code&gt;puts_loop&lt;/code&gt;,
&lt;code&gt;puts_done&lt;/code&gt; is a bit annoying. There’s a shorter way: numeric labels.&lt;/p&gt;&lt;p&gt;A numeric label is one with a name of a decimal number. To refer to a numeric label, use the number and a &lt;code&gt;f&lt;/code&gt; suffix for “forward”,
and &lt;code&gt;b&lt;/code&gt; for “backward”, and it will correspond to the nearest
numeric label with that number, searching forwards or backwards,
respectively.&lt;/p&gt;&lt;p&gt;So, the &lt;code&gt;puts&lt;/code&gt; example from earlier can be rewritten:&lt;/p&gt;&lt;code&gt;    # void puts(const char *);
puts:
    lui t1, %hi(0x10000000)
1:
    lb t0, 0(a0)
    beq t0, zero, 2f
    sw t0, 0(t1)
    addi a0, a0, 1
    j 1b

2:
    ret&lt;/code&gt;
&lt;p&gt;Yeah I don’t really like this syntax either, but it is what we’ve got.&lt;/p&gt;&lt;p&gt;Remember that oddball instruction I mentioned way back, &lt;code&gt;auipc&lt;/code&gt;?&lt;/p&gt;&lt;p&gt;I don’t know about your experience, but the first time I saw RISC-V disassembly, this is the one instruction that caught my eye. And this memory has stuck with me ever since. It’s a rather common occurrence in real RISC-V programs, and somehow I’ve been hiding it from you this whole time. If you take a sneak peek at the next section’s title, you’ll see how far we’ve come without &lt;code&gt;auipc&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;So what does it do?&lt;/p&gt;&lt;p&gt;The &lt;code&gt;auipc&lt;/code&gt; (“add
upper immediate to pc”) instruction is very similar to &lt;code&gt;lui&lt;/code&gt;.
Instead of setting &lt;code&gt;rd&lt;/code&gt; to &lt;code&gt;imm20 &amp;lt;&amp;lt; 12&lt;/code&gt;, it
sets it to &lt;code&gt;pc + (imm20 &amp;lt;&amp;lt; 12)&lt;/code&gt;, where &lt;code&gt;pc&lt;/code&gt;
is the address of the &lt;code&gt;auipc&lt;/code&gt; instruction itself.&lt;/p&gt;&lt;code&gt;auipc rd, imm20&lt;/code&gt;
&lt;p&gt;It works very similarly to &lt;code&gt;lui&lt;/code&gt;. You can think of them as
a pair: the “base” of &lt;code&gt;lui&lt;/code&gt; is &lt;code&gt;0&lt;/code&gt;, whereas the
“base” of &lt;code&gt;auipc&lt;/code&gt; is the address of the &lt;code&gt;auipc&lt;/code&gt;
instruction. So this code:&lt;/p&gt;&lt;code&gt;start:
    auipc a0, 3
    addi a0, a0, 4&lt;/code&gt;
&lt;p&gt;Gives you &lt;code&gt;0x3004&lt;/code&gt;, whereas this:&lt;/p&gt;&lt;code&gt;start:
    auipc a0, 3
    addi a0, a0, 4&lt;/code&gt;
&lt;p&gt;Gives you &lt;code&gt;start + 0x3004&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Why would you need this? On modern systems, it’s often desirable to have machine code that can be moved around in address space. For example, a shared library i.e. dynamically linked library can be loaded into any program, at any address. It would be helpful if the machine code does not need to be patched every time. This is called position independent code (PIC).&lt;/p&gt;&lt;p&gt;Some instructions already exhibit position independence. For example, as mentioned earlier when we talked about using &lt;code&gt;lui&lt;/code&gt; and
&lt;code&gt;jalr&lt;/code&gt; as a pair, the branch instructions and
&lt;code&gt;jal&lt;/code&gt; are encoded, as with all RV32I instructions, into
32-bit instruction words, so they can’t possibly be able to encode every
possible address. Instead, the jump destination is &lt;code&gt;pc&lt;/code&gt; plus
some offset (&lt;code&gt;pc&lt;/code&gt; being, as before, the jump/branch
instruction itself), and the offset itself is encoded.&lt;/p&gt;&lt;p&gt;You can see these are three different instructions that jump to itself. Since the offset is &lt;code&gt;0&lt;/code&gt; in each case, the encoding is
the same. Use the “Dump” button to see for yourself.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;auipc&lt;/code&gt; instruction allows for very flexible position
independence. You can make arbitrary calculations based on the address
at which code is located. The immediate-bit operand mirroring
&lt;code&gt;lui&lt;/code&gt; means that it is well suited for two-instruction pairs,
just like &lt;code&gt;lui&lt;/code&gt;. These kind of “&lt;code&gt;pc&lt;/code&gt; plus
something” calculations are known as pc-relative
addressing.&lt;/p&gt;&lt;p&gt;The syntax for getting the assembler to generate the immediate values for pc-relative addressing a bit arcane but hear me out:&lt;/p&gt;&lt;p&gt;Like &lt;code&gt;%hi()&lt;/code&gt; and &lt;code&gt;%lo()&lt;/code&gt;, &lt;code&gt;%pcrel_hi()&lt;/code&gt; and &lt;code&gt;%pcrel_lo()&lt;/code&gt; gives you
the immediate values needed for pc-relative addressing. You pass the
label you want to address to &lt;code&gt;%pcrel_hi()&lt;/code&gt;, but pass a label
to the &lt;code&gt;auipc&lt;/code&gt; instruction to
&lt;code&gt;%pcrel_lo()&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Unlike &lt;code&gt;%lo()&lt;/code&gt;, We need the address of the
&lt;code&gt;auipc&lt;/code&gt; instruction itself to calculate the immediate value,
and this is why you need to pass a label to it. You don’t need to write
&lt;code&gt;foo&lt;/code&gt; again, since the assembler will look at the
&lt;code&gt;auipc&lt;/code&gt; instruction and see it’s supposed to be for
&lt;code&gt;foo&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;If you hate writing that, you can also use the convenience pseudoinstruction &lt;code&gt;la&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;la rd, label&lt;/code&gt;
&lt;p&gt;Just like a &lt;code&gt;lui&lt;/code&gt; + &lt;code&gt;jalr&lt;/code&gt; pair, an
&lt;code&gt;auipc&lt;/code&gt; + &lt;code&gt;jalr&lt;/code&gt; can be used to jump to somewhere
farther away than one &lt;code&gt;jal&lt;/code&gt; can reach in position-independent
code.&lt;/p&gt;&lt;p&gt;One very common case is to call a function that might not be within reach of &lt;code&gt;jal&lt;/code&gt;. You can use the pseudoinstruction &lt;code&gt;call&lt;/code&gt; for that.&lt;/p&gt;&lt;code&gt;call label&lt;/code&gt;
&lt;p&gt;This expands to:&lt;/p&gt;&lt;code&gt;1:
    auipc ra, %pcrel_hi(label)
    jalr ra, %pcrel_lo(1b)(ra)&lt;/code&gt;
&lt;p&gt;Notice how &lt;code&gt;ra&lt;/code&gt; is used as a temporary register to store
the intermediate result, which is immediately overwritten by
&lt;code&gt;jalr&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;In fact, there really isn’t any reason to prefer &lt;code&gt;lui&lt;/code&gt;
over &lt;code&gt;auipc&lt;/code&gt; when using a label. This is why you if you
disassemble a real RISC-V program, you see it everywhere, even in
non-position-independent code.&lt;/p&gt;&lt;p&gt;Now would be a good time to take a break, since we’re ready to head into…&lt;/p&gt;&lt;p&gt;We’re going to write an extremely bare bones operating system.&lt;/p&gt;&lt;p&gt;One of the tasks an operating system performs is to control what programs can and cannot do. On RISC-V, the most basic of this control is implemented using privilege levels. RISC-V defines… let’s just say, several privilege levels, but we’re only going to use two here:&lt;/p&gt;&lt;p&gt;The lower the privilege level number goes, the less privileged that level is. Higher privilege levels treat lower privilege levels as generally completely unreliable and untrusted, and must isolate themselves from adversarial software and failures of lower privilege levels.&lt;/p&gt;&lt;p&gt;(However, we won’t be talking about all of the features that make this full isolation possible, and the emulator you’ve been seeing does not have enough features for that anyway. Therefore, the operating system we’ll be building will leave itself unprotected in various ways.)&lt;/p&gt;&lt;p&gt;The privilege levels are sometimes called “modes” for short. And, if that’s not short enough, we can shorten the level names themselves, ending up with M-mode and U-mode. All of the ways to refer to these privilege levels are interchangable.&lt;/p&gt;&lt;p&gt;When a RISC-V machine starts (This is known as “reset”), it begins execution in Machine mode. On a typical “embedded” system where only Machine mode and User mode are implemented, execution begins in the initialization code read from flash memory. This code can either perform what needs to be done itself, or it can be an operating system that manages some tasks, each executing in User mode.&lt;/p&gt;&lt;p&gt;The former design is used for simpler programs, and is analogous to the programs we’ve seen and run so far. The latter is more complicated. We’ll see the basics of how to achieve that soon.&lt;/p&gt;&lt;p&gt;The control and status registers (CSRs) deal with various features that are in some sense “special”. No I don’t have a better explanation of what “special” means.&lt;/p&gt;&lt;p&gt;Six instructions are available for manipulating CSRs.&lt;/p&gt;&lt;code&gt;csrrw rd, csr, rs1
csrrs rd, csr, rs1
csrrc rd, csr, rs1
csrrwi rd, csr, uimm5
csrrsi rd, csr, uimm5
csrrci rd, csr, uimm5&lt;/code&gt;
&lt;p&gt;To refer to a CSR in these instructions, use its name in assembly code. We’ll get to those in a bit.&lt;/p&gt;&lt;p&gt;The pattern works like this. Each of the instructions atomically reads the old value of the CSR, and writes the new value based on some operation performed on the old value and the last operand. The possible operations are:&lt;/p&gt;&lt;code&gt;csrrw&lt;/code&gt; (“CSR read
write”): &lt;code&gt;{ csr = rs1; rd = csr_old; }&lt;/code&gt;&lt;code&gt;csrrs&lt;/code&gt; (“CSR read
set”): &lt;code&gt;{ csr = csr | rs1; rd = csr_old; }&lt;/code&gt;&lt;code&gt;csrrc&lt;/code&gt; (“CSR read
clear”): &lt;code&gt;{ csr = csr &amp;amp; ~rs1; rd = csr_old; }&lt;/code&gt;&lt;p&gt;Where &lt;code&gt;&amp;amp;&lt;/code&gt;, &lt;code&gt;|&lt;/code&gt;, &lt;code&gt;~&lt;/code&gt; are bitwise
“and”, “or”, “not” respectively.&lt;/p&gt;&lt;p&gt;Specifically, note that &lt;code&gt;rd&lt;/code&gt; and &lt;code&gt;rs1&lt;/code&gt; can be
the same. For example, this instruction swaps the value in
&lt;code&gt;a0&lt;/code&gt; and &lt;code&gt;mscratch&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;csrrw a0, mscratch, a0&lt;/code&gt;
&lt;p&gt;For the “immediate” variants, instead of a register, they take an “unsigned”/zero-extended 5-bit immediate value, i.e. an immediate value 0 through 31, inclusive. This is represented using &lt;code&gt;uimm5&lt;/code&gt; in
the assembly syntax description. The operation is the same
otherwise.&lt;/p&gt;&lt;code&gt;csrrwi&lt;/code&gt; (“CSR
read write immediate”): &lt;code&gt;{ csr = uimm5; rd = csr_old; }&lt;/code&gt;&lt;code&gt;csrrsi&lt;/code&gt; (“CSR
read set immediate”):
&lt;code&gt;{ csr = csr | uimm5; rd = csr_old; }&lt;/code&gt;&lt;code&gt;csrrci&lt;/code&gt; (“CSR
read clear immediate”):
&lt;code&gt;{ csr = csr &amp;amp; ~uimm5; rd = csr_old; }&lt;/code&gt;&lt;p&gt;The full feature set of these instructions are designed for manipulating bit fields in CSRs, which we will not be doing that much of in this tutorial. Still, this orthogonal design should be fairly intuitive to remember.&lt;/p&gt;&lt;p&gt;CSRs and fields in CSRs do not behave like general purpose registers: Some of them are read/write, some are read-only. Also, invalid values have special behaviors. We will touch on more details as we introduce the individual CSRs themselves, but one thing you may have noticed is that we don’t seem to have read-only CSR instructions. Read-only access is achieved using special cases in the instruction encodings:&lt;/p&gt;&lt;code&gt;csrrs&lt;/code&gt; and &lt;code&gt;csrrc&lt;/code&gt; do not write to the CSR if
&lt;code&gt;rs1&lt;/code&gt; is &lt;code&gt;x0&lt;/code&gt; (a.k.a. &lt;code&gt;zero&lt;/code&gt;) (Note
that just the value of &lt;code&gt;rs1&lt;/code&gt; being 0 is not enough.)&lt;code&gt;csrrsi&lt;/code&gt; and &lt;code&gt;csrrci&lt;/code&gt; do not write to the CSR
if &lt;code&gt;uimm5&lt;/code&gt; is 0.&lt;p&gt;While we’re at it:&lt;/p&gt;&lt;code&gt;csrrw&lt;/code&gt; and &lt;code&gt;csrrwi&lt;/code&gt; do not read the CSR if
&lt;code&gt;rd&lt;/code&gt; is &lt;code&gt;x0&lt;/code&gt; (a.k.a. &lt;code&gt;zero&lt;/code&gt;). (Note
that writing to &lt;code&gt;x0&lt;/code&gt; has no effect anyway, since it’s
constant 0.)&lt;p&gt;(No standard RISC-V CSR is write-only, or has side effects on read.)&lt;/p&gt;&lt;p&gt;As a convenience, the pseudoinstructions &lt;code&gt;csrr&lt;/code&gt; (“CSR read”) and &lt;code&gt;csrw&lt;/code&gt; (“CSR write”) are
available. &lt;code&gt;csrw csr, rs1&lt;/code&gt; expands to
&lt;code&gt;csrrw x0, csr, rs1&lt;/code&gt;. Meanwhile, &lt;code&gt;csrr rd, csr&lt;/code&gt;
expands specifically to &lt;code&gt;csrrs rd, csr, x0&lt;/code&gt;, just so we can
agree on an encoding.&lt;/p&gt;&lt;code&gt;csrw csr, rs1
csrr rd, csr&lt;/code&gt;
&lt;p&gt;You may have seen these CSR things if you’ve scrolled down on the register view. Yes, we’re finally getting into those.&lt;/p&gt;&lt;p&gt;An example of CSRs is counters. Two basic read-only counters are &lt;code&gt;cycle&lt;/code&gt; and
&lt;code&gt;instret&lt;/code&gt;. These
counters, well, count the number of “cycles” and “instructions
retired”. “Retired” is a technical term basically meaning “successfully
completed”.&lt;/p&gt;&lt;p&gt;Since a 32-bit counter will overflow quite fast, on RV32, the counters have “high” counterparts: &lt;code&gt;cycleh&lt;/code&gt; and &lt;code&gt;instreth&lt;/code&gt;. So, for
example, the full cycle counter has 64 bits, with the lower 32 bits in
the CSR &lt;code&gt;cycle&lt;/code&gt; and higher 32 bits in the CSR
&lt;code&gt;cycleh&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;While the emulator is running, scroll down on the register view panel, and on the bottom you’ll see the values of these counters. For convenience, they’re shown combined, so, &lt;code&gt;cycle = 0x11223344_55667788&lt;/code&gt; means &lt;code&gt;cycleh&lt;/code&gt; is
&lt;code&gt;0x11223344&lt;/code&gt;, and &lt;code&gt;cycle&lt;/code&gt; is
&lt;code&gt;0x55667788&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;On real hardware &lt;code&gt;cycle&lt;/code&gt; is coupled to the clock cycle. In
this emulator, every time you press “Step”, it counts as a cycle. When
you press “Run” and it starts, well, running, a certain number of cycles
happen periodically.&lt;/p&gt;&lt;p&gt;Let’s look at a really simple example:&lt;/p&gt;&lt;p&gt;It takes 4 cycles for this program to stop, but &lt;code&gt;instret&lt;/code&gt;
ends up at only 3 because the final &lt;code&gt;ebreak&lt;/code&gt; instruction
never actually completes.&lt;/p&gt;&lt;p&gt;(Do not confuse “retired” with “retried”.)&lt;/p&gt;&lt;p&gt;A program can read its own counters. For example, this fun little program loops until the cycle count is over 1000, assuming the low 32 bits doesn’t overflow before it has time to react:&lt;/p&gt;&lt;p&gt;Technically &lt;code&gt;cycle&lt;/code&gt; and &lt;code&gt;instret&lt;/code&gt; are not part
of the privileged architecture. The real fun begins now.&lt;/p&gt;&lt;p&gt;The emulator shows the current privilege level as &lt;code&gt;(priv)&lt;/code&gt;. It is in parentheses to remind you of a very
important fact:&lt;/p&gt;&lt;p&gt;There is no CSR for the current privilege level.&lt;/p&gt;&lt;p&gt;In general, it is not possible for a RISC-V program to learn what privilege level it’s in. This is required for the Popek and Goldberg conditions of virtualization to work, specifically because being able to read the current privilege level at a lower-than-maximum privilege level would be a “sensitive” but “unprivileged” instruction.&lt;/p&gt;&lt;p&gt;If you’re writing a program for a certain privilege level, you should simply assume that it is correctly being run at that privilege level.&lt;/p&gt;&lt;p&gt;A fundamental way an operating system does its job is through handling exceptions. In general, exceptions occur when there’s a problem with a specific instruction, and execution cannot continue. For example, since &lt;code&gt;cycle&lt;/code&gt; is a read-only CSR, writing to it is
an illegal instruction:&lt;/p&gt;&lt;p&gt;Since we have no exception handling in the program, we’ll have to inspect what happened manually in the emulator. Indeed, a lot has happened:&lt;/p&gt;&lt;p&gt;Firstly, this message tells you that an exception happened:&lt;/p&gt;&lt;code&gt;[ Exception: Illegal instruction (2) | tval = 0xc0001073, epc = 0x4000000c ]&lt;/code&gt;
&lt;p&gt;The same information is now also available in the CSRs, as follows:&lt;/p&gt;&lt;code&gt;mcause&lt;/code&gt; (“M-mode
trap cause”): The kind of exception.&lt;code&gt;mepc&lt;/code&gt; (“M-mode
exception pc”): The address of the instruction that caused the
exception.&lt;code&gt;mtval&lt;/code&gt; (“M-mode
trap value”): Extra information about the exception.&lt;code&gt;mstatus&lt;/code&gt; (“M-mode
status”): It is set to &lt;code&gt;0x00001800&lt;/code&gt;. The two bits in the
middle, &lt;code&gt;mstatus[12:11]&lt;/code&gt; (In C syntax,
&lt;code&gt;(mstatus &amp;gt;&amp;gt; 11) &amp;amp; 0x3&lt;/code&gt;) is the
&lt;code&gt;mstatus.MPP&lt;/code&gt; (“M-mode previous privilege level”) field,
which contains 3, meaning that the exception occurred while running in
Machine mode.&lt;p&gt;When an exception happens, in addition to recording the exception information in these CSR fields, &lt;code&gt;pc&lt;/code&gt; is set to
&lt;code&gt;mtvec&lt;/code&gt;, which is supposed to be the handler address. Let’s
write ourselves an exception handler that simply prints a message and
stops the emulator, and see the handling in action:&lt;/p&gt;&lt;p&gt;Yeah it just prints &lt;code&gt;Oh no!&lt;/code&gt; on error. Baby steps…&lt;/p&gt;&lt;p&gt;The checkboxes “Pause on exc.” and “Print on exc.” control whether the emulator should pause or print a message, respectively, when an exception occurs. You can uncheck those if you want the exception handler set in the program to run without interference.&lt;/p&gt;&lt;p&gt;(Another case that will cause a jump to &lt;code&gt;mtvec&lt;/code&gt; is interrupts. However, this feature
does not exist in the emulator. The two cases are collectively called
traps.)&lt;/p&gt;&lt;p&gt;These are the exceptions possible in this emulator, and their respective numeric codes:&lt;/p&gt;&lt;table&gt;&lt;row span="2"&gt;&lt;cell role="head"&gt;Description&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;0&lt;/cell&gt;&lt;cell&gt;Instruction address misaligned&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;1&lt;/cell&gt;&lt;cell&gt;Instruction access fault&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;2&lt;/cell&gt;&lt;cell&gt;Illegal instruction&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;3&lt;/cell&gt;&lt;cell&gt;Breakpoint&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;5&lt;/cell&gt;&lt;cell&gt;Load access fault&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;7&lt;/cell&gt;&lt;cell&gt;Store/AMO access fault&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;8&lt;/cell&gt;&lt;cell&gt;Environment call from User mode&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;11&lt;/cell&gt;&lt;cell&gt;Environment call from Machine mode&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;“Instruction address misaligned” happens when attempting to jump to an instruction that is not 4-byte aligned. The exception happens on the jump or branch instruction, not the target.&lt;/p&gt;&lt;p&gt;“Load access fault” and “Store/AMO access fault” happens when accessing an invalid memory address, or accessing a memory address in an invalid way.&lt;/p&gt;&lt;p&gt;(“AMO” stands for “atomic memory operation”, which we will not talk about and is not featured in the emulator.)&lt;/p&gt;&lt;p&gt;“Illegal instruction” happens not only in the self explanatory way when an invalid instruction is executed, but also when accessing a CSR in an invalid way, or from too low a privilege level.&lt;/p&gt;&lt;p&gt;“Breakpoint”, “Environment call from User mode” and “Environment call from Machine mode” will be explained in a future section.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;mret&lt;/code&gt; (“M-mode
return”) instruction performs the reverse of part of what happens when
an exception occurs. To be precise, what happens is:&lt;/p&gt;&lt;code&gt;mstatus.MPP&lt;/code&gt;&lt;code&gt;mstatus.MPP&lt;/code&gt; is set to 0&lt;code&gt;pc&lt;/code&gt; is set to &lt;code&gt;mepc&lt;/code&gt;&lt;p&gt;(You can think of the privilege mode bits as shifting in a chain &lt;code&gt;0 → MPP → priv&lt;/code&gt;. And, to be even more precise,
&lt;code&gt;mstatus.MPP&lt;/code&gt; is set to the lowest supported privilege mode
since it’s not supposed to contain unsupported modes.)&lt;/p&gt;&lt;p&gt;&lt;code&gt;mret&lt;/code&gt; takes no operands, so the assembly syntax is
simply:&lt;/p&gt;&lt;code&gt;mret&lt;/code&gt;
&lt;p&gt;If we do &lt;code&gt;mret&lt;/code&gt; after getting an exception, then we simply
go back to retrying the same instruction again. This is useful for more
featureful implementations, where for example, after handling a page
fault the correct course of action is to retry the faulting
instruction.&lt;/p&gt;&lt;p&gt;However, &lt;code&gt;mstatus&lt;/code&gt; and &lt;code&gt;mepc&lt;/code&gt; are also
writable. This gives us more flexibility in the use of
&lt;code&gt;mret&lt;/code&gt;. As an analogy, the same &lt;code&gt;jr&lt;/code&gt; instruction
(really &lt;code&gt;jalr&lt;/code&gt; instruction) can be used to return from a
call, and also can be used to jump to any address. Similarly,
&lt;code&gt;mret&lt;/code&gt; not only lets us return from an exception, but also
lets us jump to any address and switch to any privilege
level.&lt;/p&gt;&lt;p&gt;Even though &lt;code&gt;mret&lt;/code&gt; is named “return”, it is in fact the
only way to lower the privilege level to enter User mode.
Here’s an example of entering User mode, with a User mode program that
does something bad:&lt;/p&gt;&lt;p&gt;As you can see, after we enter User mode, all of the CSRs used for exception handling become completely inaccessible, not even readable. As with writing a read-only CSR, accessing an CSR without permission also causes an illegal instruction exception.&lt;/p&gt;&lt;p&gt;Moreover, when an exception happens, we go back to Machine mode, so the exception handler runs in Machine mode. Here the handler does nothing except stopping the emulator.&lt;/p&gt;&lt;p&gt;Sometimes, a program may wish to intentionally cause an exception. There are several well-defined way to do that:&lt;/p&gt;&lt;code&gt;unimp&lt;/code&gt; has the same encoding
as &lt;code&gt;csrrw zero, cycle, zero&lt;/code&gt;, and it is the canonical RV32I
illegal instruction. It causes causes an “Illegal instruction”
exception.&lt;code&gt;ebreak&lt;/code&gt; causes a
“Breakpoint” exception&lt;code&gt;ecall&lt;/code&gt; causes an
“Environment call from User mode” exception when executed in User mode,
and “Environment call from Machine mode” exception when executed in
Machine mode.&lt;p&gt;Give those exceptions a try here:&lt;/p&gt;&lt;p&gt;As the names suggest, &lt;code&gt;ebreak&lt;/code&gt; is used for debugging
breakpoints. As a special case, in this emulator &lt;code&gt;ebreak&lt;/code&gt; in
Machine mode stops the emulator. You can think of it as the emulator
being a debugger, and the debugger catching the breakpoint.&lt;/p&gt;&lt;p&gt;&lt;code&gt;unimp&lt;/code&gt; can be used to intentionally crash a program upon
detection of some unrecoverable error.&lt;/p&gt;&lt;p&gt;Meanwhile, &lt;code&gt;ecall&lt;/code&gt; is used for things like system calls.
“Environment call from User mode” is a distinct exception cause code to
make it easy to check specifically for this case.&lt;/p&gt;&lt;p&gt;One thing that you would want in your trap handler is to not trust or disturb any general purpose registers in the code that the trap occurred in, unless you intentionally want to do so, for example to return a value from a system call. So you’d want to save all the registers to memory, before doing anything else. However, accessing memory requires a general purpose register.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;mscratch&lt;/code&gt;
(“M-mode scratch”) CSR can help with this. This register, unlike all the
others, have no special functionality. It can hold any 32-bit value.
However, like all the other M-mode CSRs, it can only be accessed in
Machine mode. User mode code cannot change the value of it.&lt;/p&gt;&lt;p&gt;So for example, you can stash the operating system stack pointer in &lt;code&gt;mscratch&lt;/code&gt; before switching to User mode, and it will stay in
&lt;code&gt;mscratch&lt;/code&gt; untouched in User mode. At the top of the handler,
&lt;code&gt;csrrw sp, mscratch, sp&lt;/code&gt; to swap from the user stack pointer
to the operating system stack pointer.&lt;/p&gt;&lt;code&gt;handler:
    csrrw sp, mscratch, sp
    # Save registers except sp
    csrr t0, mscratch
    # t0 = user sp, save it
    # Save user pc
    ...&lt;/code&gt;
&lt;p&gt;And, to restore:&lt;/p&gt;&lt;code&gt;    lw t0, ... # Load user pc
    csrw mepc, t0
    lw t0, ... # Load user sp
    csrw mscratch, t0
    # Restore registers except sp
    csrrw sp, mscratch, sp
    mret&lt;/code&gt;
&lt;p&gt;We’ll see the full code for this in the following section.&lt;/p&gt;&lt;p&gt;We have enough of to write a very very bare bones operating system. It will support these features:&lt;/p&gt;&lt;code&gt;a7 = 1&lt;/code&gt;: putchar, &lt;code&gt;a0&lt;/code&gt; is the byte to
write&lt;code&gt;a7 = 2&lt;/code&gt;: exit&lt;p&gt;We design the exception handling as follows:&lt;/p&gt;&lt;code&gt;mscratch&lt;/code&gt; is 0.&lt;code&gt;mscratch&lt;/code&gt; points to the operating
system stack pointer&lt;code&gt;mscratch&lt;/code&gt; is 0, the exception came
from M-mode, which we cannot handle, so we report a fatal
exception.&lt;code&gt;trap_main&lt;/code&gt;, which manipulates
U-mode registers in memory&lt;code&gt;trap_main&lt;/code&gt;, we restore registers from memory,
deallocate the space from the stack, and go back to U-mode, as outlined
in the previous section.&lt;p&gt;The structure to save registers in is fairly simple:&lt;/p&gt;&lt;code&gt;struct regs {
  unsigned long pc;
  unsigned long ra; // x1
  unsigned long sp; // x2
  ...
  unsigned long t6; // x31
};&lt;/code&gt;
&lt;p&gt;Basically you can think of it as an array where element 0 is &lt;code&gt;pc&lt;/code&gt;, and elements 1 through 31 are registers x1 through
x31.&lt;/p&gt;&lt;p&gt;Inside &lt;code&gt;trap_main&lt;/code&gt;, we check &lt;code&gt;mcause&lt;/code&gt; to see if
it’s a system call. If it is, we dispatch based on &lt;code&gt;a7&lt;/code&gt;. If
it’s not, we report an exception from U-mode.&lt;/p&gt;&lt;p&gt;At the beginning, we simply initialize the &lt;code&gt;struct regs&lt;/code&gt;
structure on stack, initialize user &lt;code&gt;sp&lt;/code&gt; and &lt;code&gt;pc&lt;/code&gt;
in it, and jump to the same code that handles returning to U-mode.&lt;/p&gt;&lt;p&gt;Here’s the assembly code with User mode code at the bottom. You may want to uncheck “Pause on exc.” and “Print on exc.” for convenience.&lt;/p&gt;&lt;p&gt;Do not be too hard on yourself if you have trouble understanding the code fully. This is, after all, a fairly complete OS kernel entry and exit implementation. Really, the most important part I’m showing you here is that it is possible.&lt;/p&gt;&lt;p&gt;For reference, here’s some of the OS code in pseudo-C.&lt;/p&gt;&lt;code&gt;void trap_main(struct regs *regs) {
    unsigned long cause = csr_read(mcause);
    if (cause != 8)
        do_bad_exception(regs, cause);

    # Call do_syscall with args from ecall
    unsigned long ret = do_syscall(regs-&amp;gt;a0, ..., regs-&amp;gt;a7);
    regs-&amp;gt;a0 = ret;

    // Bump user pc by 4, skip over ecall instruction
    regs-&amp;gt;pc += 4;
}

unsigned long do_syscall(
    unsigned long a0,
    ...,
    unsigned long a7
) {
    if (a7 == 1)
        sys_putchar(a0);
    else if (a7 == 8)
        sys_exit();
    else
        return -1;
}

unsigned long sys_putchar(char a) {
    kputchar(a);
    return 0;
}

[[noreturn]]
unsigned long sys_exit(char a) {
    ebreak();
}

[[noreturn]]
void do_bad_exception(struct regs *regs, unsigned long cause) {
    kputs("Exception 0x");
    kputchar(hex_chars[cause]);
    kputchar('\n');
    ebreak();
}

[[noreturn]]
void fatal() {
    kputs("Fatal exception\n");
    ebreak();
}

void kputs(const char *str) {
    while (*str) {
        u32 val = (u32)*str;
        writel(0x10000000, val); // MMIO write
        str ++;
    }
}

void kputchar(char c) {
    u32 val = (u32)c;
    writel(0x10000000, val); // MMIO write
}&lt;/code&gt;
&lt;p&gt;And here’s the user code, again in pseudo C:&lt;/p&gt;&lt;code&gt;[[noreturn]]
void user_entry() {
    puts(...);
    exit();
}

void puts(const char *str) {
    while (*str) {
        putchar(*str);
        str ++;
    }
}

void putchar(char c) {
    ecall(a0 = c, a7 = 1);
}

void exit() {
    ecall(a7 = 2);
}&lt;/code&gt;
&lt;p&gt;As long as this tutorial is, some simplifications have been made. Here are some of the most egregious lies and omissions, compared to the “real” RISC-V architecture and “real” RISC-V assembly code found in the world:&lt;/p&gt;&lt;code&gt;li&lt;/code&gt; pseudoinstruction should support a wider range
of constants.&lt;code&gt;mstatus&lt;/code&gt; is a lot more complicated than what I have
described.&lt;code&gt;%hi&lt;/code&gt;, &lt;code&gt;%lo&lt;/code&gt;, &lt;code&gt;%pcrel_hi&lt;/code&gt;,
&lt;code&gt;%pcrel_lo&lt;/code&gt; are more complicated than what I have
described.&lt;p&gt;There are also very important topics that are common or even ubiquitous in the RISC-V world, but I chose not to cover:&lt;/p&gt;&lt;p&gt;However, what I’ve taught you should be more than enough to get you started into learning more on your own, or with further materials.&lt;/p&gt;&lt;p&gt;Here are some references and tutorials I would personally recommend, if you’re looking to get further into RISC-V low-level development&lt;/p&gt;&lt;p&gt;Other useful resources that I have used while writing this tutorial:&lt;/p&gt;&lt;code&gt;arch/riscv/kernel/entry.S&lt;/code&gt; from Linux https://elixir.bootlin.com/linux/latest/source/arch/riscv/kernel/entry.S&lt;p&gt;Thanks to these folks for UI design help and content suggestions:&lt;/p&gt;&lt;p&gt;And thanks to you for coming along with me on this journey. Come on over to https://github.com/dramforever/easyriscv if you have suggestions, grievances, or just want to share some thoughts.&lt;/p&gt;&lt;p&gt;This tutorial is under the CC0 license. To the maximum extent permitted by law, this tutorial is dedicated to the public domain.&lt;/p&gt;&lt;code&gt;add&lt;/code&gt;&lt;code&gt;addi&lt;/code&gt;&lt;code&gt;and&lt;/code&gt;&lt;code&gt;andi&lt;/code&gt;&lt;code&gt;auipc&lt;/code&gt;&lt;code&gt;beq&lt;/code&gt;&lt;code&gt;bge&lt;/code&gt;&lt;code&gt;bgeu&lt;/code&gt;&lt;code&gt;blt&lt;/code&gt;&lt;code&gt;bltu&lt;/code&gt;&lt;code&gt;bne&lt;/code&gt;&lt;code&gt;call&lt;/code&gt;&lt;code&gt;csrr&lt;/code&gt;&lt;code&gt;csrrc&lt;/code&gt;&lt;code&gt;csrrci&lt;/code&gt;&lt;code&gt;csrrs&lt;/code&gt;&lt;code&gt;csrrsi&lt;/code&gt;&lt;code&gt;csrrw&lt;/code&gt;&lt;code&gt;csrrwi&lt;/code&gt;&lt;code&gt;csrw&lt;/code&gt;&lt;code&gt;ebreak&lt;/code&gt;&lt;code&gt;ecall&lt;/code&gt;&lt;code&gt;j&lt;/code&gt;&lt;code&gt;jal&lt;/code&gt;&lt;code&gt;jalr&lt;/code&gt;&lt;code&gt;jr&lt;/code&gt;&lt;code&gt;la&lt;/code&gt;&lt;code&gt;lb&lt;/code&gt;&lt;code&gt;lbu&lt;/code&gt;&lt;code&gt;lh&lt;/code&gt;&lt;code&gt;lhu&lt;/code&gt;&lt;code&gt;li&lt;/code&gt;&lt;code&gt;lui&lt;/code&gt;&lt;code&gt;lw&lt;/code&gt;&lt;code&gt;mret&lt;/code&gt;&lt;code&gt;mv&lt;/code&gt;&lt;code&gt;or&lt;/code&gt;&lt;code&gt;ori&lt;/code&gt;&lt;code&gt;ret&lt;/code&gt;&lt;code&gt;sb&lt;/code&gt;&lt;code&gt;sh&lt;/code&gt;&lt;code&gt;sll&lt;/code&gt;&lt;code&gt;slli&lt;/code&gt;&lt;code&gt;slt&lt;/code&gt;&lt;code&gt;slti&lt;/code&gt;&lt;code&gt;sltiu&lt;/code&gt;&lt;code&gt;sltu&lt;/code&gt;&lt;code&gt;sra&lt;/code&gt;&lt;code&gt;srai&lt;/code&gt;&lt;code&gt;srl&lt;/code&gt;&lt;code&gt;srli&lt;/code&gt;&lt;code&gt;sub&lt;/code&gt;&lt;code&gt;sw&lt;/code&gt;&lt;code&gt;unimp&lt;/code&gt;&lt;code&gt;xor&lt;/code&gt;&lt;code&gt;xori&lt;/code&gt;&lt;code&gt;imm&lt;/code&gt;&lt;code&gt;pc&lt;/code&gt;&lt;code&gt;rd&lt;/code&gt;&lt;code&gt;rs1&lt;/code&gt;&lt;code&gt;rs2&lt;/code&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45726192</guid><pubDate>Mon, 27 Oct 2025 20:57:12 +0000</pubDate></item><item><title>Are these real CVEs? VulDB entries for dnsmasq rely on replacing config files</title><link>https://seclists.org/oss-sec/2025/q4/79</link><description>&lt;doc fingerprint="33f230fd92fe480b"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;oss-sec mailing list archives&lt;/head&gt;
    &lt;head rend="h1"&gt;Re: Questionable CVE's reported against dnsmasq&lt;/head&gt;
    &lt;p&gt;From: Moritz Mühlenhoff &amp;lt;jmm () inutil org&amp;gt;&lt;/p&gt;
    &lt;p&gt;Date: Mon, 27 Oct 2025 19:21:54 +0000&lt;/p&gt;
    &lt;quote&gt;On Mon, Oct 27, 2025 at 09:34:03AM -0700, Alan Coopersmith wrote:&lt;/quote&gt;
    &lt;quote&gt;Among the new CVE's published this weekend were these from the VulDB CNA: For all three bugs, the documented "exploit" requires "Replace the default configuration file (/etc/dnsmasq.conf) with the provided malicious file." and if you can replace the server's configuration file you don't need to play games with putting invalid contents in to break the parser, but can simply change the configuration directly.&lt;/quote&gt;
    &lt;quote&gt;The same nonsense also happened for the Kamailio SIP server (CVE-2025-12204, CVE-2025-12205, CVE-2025-12206 and CVE-2025-12207). Cheers, Moritz&lt;/quote&gt;
    &lt;head rend="h3"&gt;Current thread:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Questionable CVE's reported against dnsmasq Alan Coopersmith (Oct 27) &lt;list rend="ul"&gt;&lt;item&gt;Re: Questionable CVE's reported against dnsmasq Jeremy Stanley (Oct 27) &lt;list rend="ul"&gt;&lt;item&gt;Re: Questionable CVE's reported against dnsmasq Andrew Latham (Oct 27) &lt;list rend="ul"&gt;&lt;item&gt;Re: Questionable CVE's reported against dnsmasq Sebastian Pipping (Oct 27)&lt;/item&gt;&lt;item&gt;Re: Questionable CVE's reported against dnsmasq Stuart Henderson (Oct 27)&lt;/item&gt;&lt;item&gt;Re: Questionable CVE's reported against dnsmasq Sebastian Pipping (Oct 27)&lt;/item&gt;&lt;item&gt;Re: Questionable CVE's reported against dnsmasq Matthew Fernandez (Oct 27)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Re: Questionable CVE's reported against dnsmasq Andrew Latham (Oct 27) &lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Re: Questionable CVE's reported against dnsmasq Jeremy Stanley (Oct 27) &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Re: Questionable CVE's reported against dnsmasq Collin Funk (Oct 27)&lt;/item&gt;
      &lt;item&gt;Re: Questionable CVE's reported against dnsmasq Michael Orlitzky (Oct 27) &lt;list rend="ul"&gt;&lt;item&gt;Re: Questionable CVE's reported against dnsmasq Hank Leininger (Oct 27)&lt;/item&gt;&lt;item&gt;Re: Questionable CVE's reported against dnsmasq Solar Designer (Oct 27)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Re: Questionable CVE's reported against dnsmasq Demi Marie Obenour (Oct 27)&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45727137</guid><pubDate>Mon, 27 Oct 2025 22:35:00 +0000</pubDate></item><item><title>Iroh-blobs</title><link>https://www.iroh.computer/blog/iroh-blobs-0-95-new-features</link><description>&lt;doc fingerprint="1e5ea82579a148e8"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;iroh-blobs 0.95 - New features&lt;/head&gt;by rklaehn&lt;p&gt;Iroh-blobs 0.95 contains a number of significant new features that are worth explaining in detail. There are several new features that are useful for blobs users and also for iroh users in general.&lt;/p&gt;&lt;p&gt;Let's start with a feature that is essential for blobs itself, but can also be useful for many other protocols.&lt;/p&gt;&lt;head rend="h1"&gt;Connection pool&lt;/head&gt;&lt;p&gt;There is a new connection pool in &lt;code&gt;util::connection_pool&lt;/code&gt;. This is useful whenever you have a protocol that has to talk to a large number of endpoints while keeping an upper bound of concurrent open connections. In blobs, this is used whenever you use the downloader to orchestrate blobs downloads from multiple providers.&lt;/p&gt;&lt;p&gt;Iroh connections are relatively lightweight, but even so you don't want to keep thousands of them open at the same time. But opening a new connection every time you do a small exchange with a peer is very wasteful. The &lt;code&gt;ConnectionPool&lt;/code&gt; gives you an API to deal with these tradeoffs.&lt;/p&gt;&lt;head rend="h2"&gt;Basic usage&lt;/head&gt;&lt;p&gt;Let's first look at basic usage:&lt;/p&gt;&lt;code&gt;let pool = ConnectionPool::new(ep, iroh_blobs::ALPN, Options::default());
let conn = pool.get_or_connect(remote_id)?;
/// use the connection as usual.
&lt;/code&gt;&lt;p&gt;&lt;code&gt;get_or_connect&lt;/code&gt; will try to get an existing connection from the pool. If there is none, it will create one and store it. The connection will be kept in the pool for a configurable time. Idle connections will be closed as needed. So you can just use this as a drop-in replacement for endpoint.connect and be sure that you won't ever create an unbounded number of connections.&lt;/p&gt;&lt;head rend="h2"&gt;Advanced features&lt;/head&gt;&lt;p&gt;There are some advanced features that can be configued using non-default options.&lt;/p&gt;&lt;code&gt;pub struct Options {
    pub idle_timeout: Duration,
    pub connect_timeout: Duration,
    pub max_connections: usize,
    pub on_connected: Option&amp;lt;OnConnected&amp;gt;,
}
&lt;/code&gt;&lt;p&gt;You can configure the max number of connections to be retained, the maximum tolerable duration for connection establishment, and the max duration connections are kept when idle.&lt;/p&gt;&lt;p&gt;So far, pretty straightforward. There is an additional option to perform some setup before the connection is handed out to the user. For example, you can reject connections based on the data available at this time from the endpoint and the connection, or wait for the connection to reach a certain state before handing it out.&lt;/p&gt;&lt;p&gt;As an example, you might want to do iroh-blobs transfers only on direct connections in order to get good performance or reduce bandwidth use on the relay. If establishing direct connections is not possible, the connection establishment would time out, and you would never even attempt a transfer from such a node.&lt;/p&gt;&lt;code&gt;async fn on_connected(ep: Endpoint, conn: Connection) -&amp;gt; io::Result&amp;lt;()&amp;gt; {
    let Ok(id) = conn.remote_node_id() else {
        return Err(io::Error::other("unable to get node id"));
    };
    let Some(watcher) = ep.conn_type(id) else {
        return Err(io::Error::other("unable to get conn_type watcher"));
    };
    let mut stream = watcher.stream();
    while let Some(status) = stream.next().await {
        if let ConnectionType::Direct { .. } = status {
            return Ok(());
        }
    }
    Err(io::Error::other("connection closed before becoming direct"))
};
let options = Options::default().with_on_connected(on_connected);
let pool = ConnectionPool::new(ep, iroh_blobs::ALPN, options);

let conn = pool.get_or_connect(remote_id)?;
/// use the connection as usual.
&lt;/code&gt;&lt;p&gt;The code to await a direct connection will change quite a bit once we have QUIC multipath. But the capability will remain, and we will update the test code to reflect the new API.&lt;/p&gt;&lt;p&gt;The connection pool is generic enough that it will move to its own crate together with some other iroh utilities. It lives in blobs only until iroh 1.0 is released.&lt;/p&gt;&lt;p&gt;Until then, just depend on iroh-blobs. Iroh-blobs without persistent storage is a very lightweight dependency.&lt;/p&gt;&lt;p&gt;One thing to keep in mind when using the connection pool: the connection pool needs the ability to track which connections are currently being used. To do this, the connection pool does not return &lt;code&gt;Connection&lt;/code&gt; but &lt;code&gt;ConnectionRef&lt;/code&gt;, a struct that derefs to &lt;code&gt;Connection&lt;/code&gt; but contains some additional lifetime tracking.&lt;/p&gt;&lt;p&gt;But &lt;code&gt;Connection&lt;/code&gt; is &lt;code&gt;Clone&lt;/code&gt;, so in principle there is nothing stopping you from cloning the wrapped connection and losing the lifetime tracking. Don't do this. If you work with connections from the pool, you should pass around either a &lt;code&gt;ConnectionRef&lt;/code&gt; or a &lt;code&gt;&amp;amp;Connection&lt;/code&gt; to make sure the underlying &lt;code&gt;ConnectionRef&lt;/code&gt; stays alive.&lt;/p&gt;&lt;p&gt;Incorrect usage of &lt;code&gt;ConnectionRef&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;fn handle_connection(connection: Connection) { tokio::spawn(...) }

let conn = pool.get_or_connect(remote_id)?;
handle_connection(conn.clone()); // clones the Connection out of the ConnectionRef.
/// The ConnectionRef will be dropped here, and the pool will consider the connection idle!
&lt;/code&gt;&lt;p&gt;Correct usage of &lt;code&gt;ConnectionRef&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;fn handle_connection(connection: ConnectionRef) { tokio::spawn(...) }

let conn = pool.get_or_connect(remote_id)?;
handle_connection(conn.clone());
/// The ConnectionRef will be moved into the task, and its lifetime will be properly tracked!
&lt;/code&gt;&lt;p&gt;We experimented with a safer callback-based API, but it turned out to be just too inconvenient to use.&lt;/p&gt;&lt;head rend="h1"&gt;Abstract request and response streams&lt;/head&gt;&lt;p&gt;Iroh-blobs is a protocol that tries to avoid overabstraction. For example as of now you can only use the BLAKE3 hash function, and we hardcode the chunk group size to a value that should work well for all users.&lt;/p&gt;&lt;p&gt;But sometimes there are cases where a bit of abstraction is needed. There was a user request to be able to use compression with iroh-blobs in sendme. One way to do this is to compress files before adding them to the blob store. But this has various downsides. It requires you to create a copy of all data before adding it to the blob store, and will also not lead to very good compression rates when dealing with a large number of small files, since each file will have to be compressed in isolation.&lt;/p&gt;&lt;p&gt;It would be better to compress requests and response streams of the entire protocol and expose the resulting protocol under a different ALPN. With this approach the compression algorithm would be able to find redundancies between multiple files when handling a request for multiple blobs.&lt;/p&gt;&lt;p&gt;This was previously impossible since iroh-blobs worked directly with &lt;code&gt;iroh::endpoint::SendStream&lt;/code&gt; and &lt;code&gt;iroh::endpoint::RecvStream&lt;/code&gt;. So we added traits to allow wrapping send and receive stream in a transform such as compression/decompression.&lt;/p&gt;&lt;p&gt;By default, iroh-blobs still works directly with &lt;code&gt;iroh::endpoint::SendStream&lt;/code&gt; and &lt;code&gt;iroh::endpoint::RecvStream&lt;/code&gt;, so for normal use nothing changes.&lt;/p&gt;&lt;p&gt;The traits are a bit similar to Stream and Sink, but with two important additions.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;We allow sending and receiving Bytes, since iroh streams work with bytes internally. That way we avoid a copy in the default case.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;We have methods stop and reset to close the stream, and on the send stream a method stopped that returns a future that resolves when the remote side has closed the stream.&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Wrapping the entire iroh-blobs protocol into compression is pretty straightforward except for some boilerplate. We have an example compression.rs that shows how to do this.&lt;/p&gt;&lt;p&gt;We will have this as an optional feature of sendme in one of the next releases.&lt;/p&gt;&lt;p&gt;Just like the connection pool, these traits are generally useful whenever you want to derive iroh protocols by wrapping existing protocols, so they will move to a separate crate once iroh 1.0 is released.&lt;/p&gt;&lt;head rend="h1"&gt;Enhanced provider events&lt;/head&gt;&lt;p&gt;This change is from iroh-blobs 0.93&lt;/p&gt;&lt;p&gt;On the provider side, it is now possible to have very detailed events about what the provider is doing. The provider events are now implemented as an irpc protocol. For each request type you can use an event mask to configure if you want to be notified at all, and if you need the ability to intercept the request, e.g. if you only want to serve certain hashes.&lt;/p&gt;&lt;p&gt;There is an example how to use the new provider events to limit by provider node id or hash.&lt;/p&gt;&lt;p&gt;Here is a provider event handler that serves only blobs requests for hashes in a fixed set of allowed hashes:&lt;/p&gt;&lt;code&gt;fn limit_by_hash(allowed_hashes: HashSet&amp;lt;Hash&amp;gt;) -&amp;gt; EventSender {
    let mask = EventMask {
        // We want to get a request for each get request that we can answer
        // with OK or not OK depending on the hash. We do not want detailed
        // events once it has been decided to handle a request.
        get: RequestMode::Intercept,
        ..EventMask::DEFAULT
    };
    let (tx, mut rx) = EventSender::channel(32, mask);
    n0_future::task::spawn(async move {
        while let Some(msg) = rx.recv().await {
            if let ProviderMessage::GetRequestReceived(msg) = msg {
                let res = if !msg.request.ranges.is_blob() {
                    Err(AbortReason::Permission)
                } else if !allowed_hashes.contains(&amp;amp;msg.request.hash) {
                    Err(AbortReason::Permission)
                } else {
                    Ok(())
                };
                msg.tx.send(res).await.ok();
            }
        }
    });
    tx
}
&lt;/code&gt;&lt;head rend="h1"&gt;What's next&lt;/head&gt;&lt;p&gt;The next major feature in iroh-blobs will be a minimal version of multiprovider downloads for individual blobs.&lt;/p&gt;&lt;p&gt;As soon as iroh 1.0 is released, several generic parts of iroh-blobs will move to a separate iroh utilities crate.&lt;/p&gt;&lt;p&gt;To get started, take a look at our docs, dive directly into the code, or chat with us in our discord channel.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45727557</guid><pubDate>Mon, 27 Oct 2025 23:28:13 +0000</pubDate></item><item><title>AI can code, but it can't build software</title><link>https://bytesauna.com/post/coding-vs-software-engineering</link><description>&lt;doc fingerprint="15f1b593ac321d8"&gt;
  &lt;main&gt;
    &lt;p&gt;Have you noticed that quite a few people are looking for technical cofounders or CTOs right now? I, for one, get a surprising amount of these queries; most of them along the lines of “hey, I have this vibe-coded app, would you like to make it production-ready”. I have sort of a profile for these people. Think someone who knows their business but has always lacked the technical skills to make their ideas happen — a legal counsel, perhaps, or an account manager.&lt;/p&gt;
    &lt;p&gt;Why would these people need me? That's what I've thought about a little bit, and I think there is an important signal here: What is it exactly that they can’t get done with GenAI alone? This is something everyone is trying to understand, right? Everyone wants to know what these models can do. Or, to be a little blunt, everyone wants to know which jobs are soon to become obsolete. The fact that I get these requests says something about software engineering. I mean, if software engineering was automated, no one would be looking for technical cofounders.&lt;/p&gt;
    &lt;p&gt;Well, I think I know why we get these proposals. The thing is that AI can code, but it can't build software. This is the conclusion I've come to after spending a significant amount of time writing AI-assisted code and watching demos by other people.&lt;/p&gt;
    &lt;p&gt;There is old wisdom that says: Coding is easy, software engineering is hard. It seems fair enough to say that LLMs are already able to automate a lot of coding. GPT-5 and the like solve isolated well-defined problems with a pretty nice success rate. Coding, however, is not what most people are getting paid for. Building a production-ready app is not coding, it’s software engineering.&lt;/p&gt;
    &lt;p&gt;The way I see it is that coding becomes software engineering around the point where you try to turn your demo into a real product — which happens to be exactly the point where these people reach out to you with their pitch.&lt;/p&gt;
    &lt;p&gt;I don’t really know why AI can't build software (for now). Maybe it has to do with the nature of the job. When you write software for a living, your main task is to deal with complexity. The average production software only does a bunch of easy things. The challenge is doing hundreds of these easy things at once, and keeping the whole thing maintainable. Or, to rephrase this in the present context: It's one thing to demonstrate a feature. It's a much more difficult thing to build that feature in a manner that supports integration, expansion, and long-term maintainability.&lt;/p&gt;
    &lt;p&gt;When you look at the code these people send you, you realize that “making the app production-ready” really means torching the whole thing and starting from scratch.&lt;/p&gt;
    &lt;p&gt;I think this says a lot about where we are at right now.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45727664</guid><pubDate>Mon, 27 Oct 2025 23:41:32 +0000</pubDate></item></channel></rss>