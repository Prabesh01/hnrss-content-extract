<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 13 Nov 2025 15:38:20 +0000</lastBuildDate><item><title>GPT-5.1: A smarter, more conversational ChatGPT</title><link>https://openai.com/index/gpt-5-1/</link><description>&lt;doc fingerprint="9d1fea781db6c8bf"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;GPT-5.1: A smarter, more conversational ChatGPT&lt;/head&gt;
    &lt;p&gt;We’re upgrading GPT‑5 while making it easier to customize ChatGPT. Starting to roll out today to everyone, beginning with paid users.&lt;/p&gt;
    &lt;p&gt;Today we’re upgrading the GPT‑5 series with the release of:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GPT‑5.1 Instant: our most-used model, now warmer, more intelligent, and better at following your instructions.&lt;/item&gt;
      &lt;item&gt;GPT‑5.1 Thinking: our advanced reasoning model, now easier to understand and faster on simple tasks, more persistent on complex ones.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We heard clearly from users that great AI should not only be smart, but also enjoyable to talk to. GPT‑5.1 improves meaningfully on both intelligence and communication style.&lt;/p&gt;
    &lt;p&gt;We’re also making it easier for you to shape ChatGPT’s tone. Preferences on chat style vary—from person to person and even from conversation to conversation—so we’re introducing more intuitive and effective controls so ChatGPT can better match the tone you want in responses.&lt;/p&gt;
    &lt;p&gt;GPT‑5.1 Instant, ChatGPT’s most used model, is now warmer by default and more conversational. Based on early testing, it often surprises people with its playfulness while remaining clear and useful.&lt;/p&gt;
    &lt;head rend="h2"&gt;GPT-5&lt;/head&gt;
    &lt;head rend="h2"&gt;GPT-5.1 Instant&lt;/head&gt;
    &lt;p&gt;We’ve also improved instruction following, so the model more reliably answers the question you actually asked.&lt;/p&gt;
    &lt;head rend="h2"&gt;GPT-5&lt;/head&gt;
    &lt;head rend="h2"&gt;GPT-5.1 Instant&lt;/head&gt;
    &lt;p&gt;For the first time, GPT‑5.1 Instant can use adaptive reasoning to decide when to think before responding to more challenging questions, resulting in more thorough and accurate answers, while still responding quickly. This is reflected in significant improvements on math and coding evaluations like AIME 2025 and Codeforces.&lt;/p&gt;
    &lt;p&gt;We’re also upgrading GPT‑5 Thinking to make it more efficient and easier to understand in everyday use. It now adapts its thinking time more precisely to the question—spending more time on complex problems while responding more quickly to simpler ones. In practice, that means more thorough answers for difficult requests and less waiting for simpler ones.&lt;/p&gt;
    &lt;p&gt;GPT‑5.1 Thinking’s responses are also clearer, with less jargon and fewer undefined terms. This makes our most capable model more approachable and easily understandable, especially for complex tasks at work and explaining technical concepts.&lt;/p&gt;
    &lt;head rend="h2"&gt;GPT-5&lt;/head&gt;
    &lt;head rend="h2"&gt;GPT-5.1 Thinking&lt;/head&gt;
    &lt;p&gt;GPT‑5.1 Thinking’s default tone is also warmer and more empathetic.&lt;/p&gt;
    &lt;head rend="h2"&gt;GPT-5&lt;/head&gt;
    &lt;head rend="h2"&gt;GPT-5.1 Thinking&lt;/head&gt;
    &lt;p&gt;This release is a step forward in both capability and usability across the models. GPT‑5.1 Auto will continue to route each query to the model best suited for it, so in most cases, you won’t need to choose a model at all. What you will notice is that answers across GPT‑5.1 feel both smarter and more natural in tone.&lt;/p&gt;
    &lt;p&gt;GPT‑5.1 Instant and Thinking begin rolling out today, starting with paid (Pro, Plus, Go, Business) users and then to free and logged-out users. Enterprise and Edu plans get a seven-day early-access toggle (off by default). After that window, GPT‑5.1 will become the sole default model.&lt;/p&gt;
    &lt;p&gt;If you check ChatGPT today, you may not see GPT‑5.1 available immediately. We plan to roll it out gradually over the next few days to help keep performance stable for everyone. We will also update GPT‑5 Pro to GPT‑5.1 Pro soon.&lt;/p&gt;
    &lt;p&gt;We’re bringing both GPT‑5.1 Instant and GPT‑5.1 Thinking to the API later this week. GPT‑5.1 Instant will be added as gpt-5.1-chat-latest, and GPT‑5.1 Thinking will be released as GPT‑5.1 in the API, both with adaptive reasoning.&lt;/p&gt;
    &lt;p&gt;GPT‑5 (Instant and Thinking) will remain available in ChatGPT under the legacy models dropdown for paid subscribers for three months, so people have time to compare and adapt at their own pace. The GPT‑5 sunset period does not affect the availability of other legacy models. Going forward, when we introduce new ChatGPT models, our approach is to give people ample space to evaluate what’s changed and share feedback, allowing us to continue innovating our frontier models while transitioning smoothly. Sunset periods will be communicated clearly and with plenty of advance notice.&lt;/p&gt;
    &lt;p&gt;GPT‑5.1 is more capable and useful, and we encourage you to try it and see the difference. Our system card addendum includes more information on our safety approach for GPT‑5.1.&lt;/p&gt;
    &lt;p&gt;And a note on naming: this update is called GPT‑5.1 to reflect meaningful improvements, while remaining within the GPT‑5 generation. Future iterative upgrades to GPT‑5 will follow the same pattern.&lt;/p&gt;
    &lt;p&gt;Alongside these model improvements, we’re making it easier to customize ChatGPT’s tone and style. People have strong and varied preferences in how ChatGPT should respond, and tailoring its tone to what sounds right for you should feel effortless.&lt;/p&gt;
    &lt;p&gt;Earlier this year, we added preset options to tailor the tone of how ChatGPT responds. Today, we’re refining those options to better reflect the most common ways people use ChatGPT. Default, Friendly (formerly Listener), and Efficient (formerly Robot) remain (with updates), and we’re adding Professional, Candid, and Quirky. These options are designed to align with what we’ve learned about how people naturally steer the model, making it quick and intuitive to choose a personality that feels uniquely right.&lt;/p&gt;
    &lt;p&gt;These personality settings apply across all models. The original Cynical (formerly Cynic) and Nerdy (formerly Nerd) options we introduced earlier this year will remain available unchanged under the same dropdown in personalization settings.&lt;/p&gt;
    &lt;p&gt;Beyond these presets, for users who want more granular control over how ChatGPT responds, we’re also experimenting with the ability to tune ChatGPT’s characteristics directly from personalization settings—including how concise, warm, or scannable its responses are, and how frequently it uses emojis. ChatGPT can also proactively offer to update these preferences during conversations when it notices you asking for a certain tone or style, without requiring you to navigate into settings. You can adjust or remove any of these preferences at any time.&lt;/p&gt;
    &lt;p&gt;The updated styles and tone options are rolling out today, and the ability to finetune specific characteristics is starting to roll out gradually later this week as an experiment, starting with a limited number of users. Both will continue to improve over time. Additionally, the updated GPT‑5.1 models are also better at adhering to custom instructions, giving you even more precise control over tone and behavior.&lt;/p&gt;
    &lt;p&gt;Updates you make in personalization settings now take effect across all chats right away, including ongoing conversations, so your experience stays consistent. Before, changes to base style and tone or custom instructions only applied to conversations started afterward.&lt;/p&gt;
    &lt;p&gt;Today’s GPT‑5.1 updates and new customization options are a step toward a ChatGPT that feels like it fits you—smarter, more enjoyable to talk to, and more adaptable to your preferences. Going forward, we’ll continue improving along these dimensions—there’s much more to come.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45904551</guid><pubDate>Wed, 12 Nov 2025 19:05:41 +0000</pubDate></item><item><title>Homebrew no longer allows bypassing Gatekeeper for unsigned/unnotarized software</title><link>https://github.com/Homebrew/brew/issues/20755</link><description>&lt;doc fingerprint="760419b45cb6b368"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Notifications &lt;tool-tip&gt;You must be signed in to change notification settings&lt;/tool-tip&gt;&lt;/item&gt;
      &lt;item&gt;Fork 10.7k&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Description&lt;/head&gt;
    &lt;head rend="h3"&gt;Verification&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; This issue's title and/or description do not reference a single formula e.g. &lt;code&gt;brew install wget&lt;/code&gt;. If they do, open an issue at https://github.com/Homebrew/homebrew-core/issues/new/choose instead.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Provide a detailed description of the proposed feature&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;--no-quarantine&lt;/code&gt; is used to forcibly bypass Gatekeeper, which is a built-in macOS security mechanism. This is used to run unsigned/unnotarized applications.&lt;/p&gt;
    &lt;p&gt;macOS Tahoe is the final release to support Intel systems, and last year Apple updated macOS runtime protection to make it harder to override Gatekeeper. Macs with Apple silicon also don't "permit native arm64 code to execute unless a valid signature is attached". Finally, we are ending support for all casks that fail Gatekeeper checks on September 1st, 2026.&lt;/p&gt;
    &lt;p&gt;With the above in mind, it's time to deprecate the &lt;code&gt;--no-quarantine&lt;/code&gt; flag from &lt;code&gt;brew&lt;/code&gt;. It intentionally bypasses macOS security mechanisms, which we already actively discourage. Deprecating now will give a decent lead time for users using it to come up with another solution or adjust their workflows.&lt;/p&gt;
    &lt;head rend="h3"&gt;What is the motivation for the feature?&lt;/head&gt;
    &lt;p&gt;Intel support is coming to an end from both Apple and Homebrew. This flag is primarily used to override a macOS security mechanism, which we do not want to encourage. Since we are requiring casks fulfill Gatekeeper checks next year, there is no reason to keep this flag.&lt;/p&gt;
    &lt;head rend="h3"&gt;How will the feature be relevant to at least 90% of Homebrew users?&lt;/head&gt;
    &lt;p&gt;We will provide a safer experience for our users, and stop making it easier to bypass OS-level security.&lt;/p&gt;
    &lt;head rend="h3"&gt;What alternatives to the feature have been considered?&lt;/head&gt;
    &lt;p&gt;None. Macs with Apple silicon are the platform that will be supported in the future, and Apple is making it harder to bypass Gatekeeper as is.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45907259</guid><pubDate>Wed, 12 Nov 2025 21:50:14 +0000</pubDate></item><item><title>Valve is about to win the console generation</title><link>https://xeiaso.net/blog/2025/valve-is-about-to-win-the-console-generation/</link><description>&lt;doc fingerprint="4e7e82b81462420f"&gt;
  &lt;main&gt;
    &lt;p&gt;Making sure you're not a bot! Loading... Please wait a moment while we ensure the security of your connection.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45908464</guid><pubDate>Wed, 12 Nov 2025 23:35:41 +0000</pubDate></item><item><title>Android developer verification: Early access starts</title><link>https://android-developers.googleblog.com/2025/11/android-developer-verification-early.html</link><description>&lt;doc fingerprint="89b03251d8d5e4b8"&gt;
  &lt;main&gt;
    &lt;p&gt;12 November 2025&lt;/p&gt;
    &lt;p&gt;Posted by Matthew Forsythe Director - Product Management, Android App Safety&lt;/p&gt;
    &lt;p&gt;We recently announced new developer verification requirements, which serve as an additional layer of defense in our ongoing effort to keep Android users safe. We know that security works best when it accounts for the diverse ways people use our tools. This is why we announced this change early: to gather input and ensure our solutions are balanced. We appreciate the community's engagement and have heard the early feedback – specifically from students and hobbyists who need an accessible path to learn, and from power users who are more comfortable with security risks. We are making changes to address the needs of both groups.&lt;/p&gt;
    &lt;p&gt;To understand how these updates fit into our broader mission, it is important to first look at the specific threats we are tackling.&lt;/p&gt;
    &lt;p&gt;Why verification is important&lt;/p&gt;
    &lt;p&gt;Keeping users safe on Android is our top priority. Combating scams and digital fraud is not new for us — it has been a central focus of our work for years. From Scam Detection in Google Messages to Google Play Protect and real-time alerts for scam calls, we have consistently acted to keep our ecosystem safe.&lt;/p&gt;
    &lt;p&gt;However, online scams and malware campaigns are becoming more aggressive. At the global scale of Android, this translates to real harm for people around the world – especially in rapidly digitizing regions where many are coming online for the first time. Technical safeguards are critical, but they cannot solve for every scenario where a user is manipulated. Scammers use high-pressure social engineering tactics to trick users into bypassing the very warnings designed to protect them.&lt;/p&gt;
    &lt;p&gt;For example, a common attack we track in Southeast Asia illustrates this threat clearly. A scammer calls a victim claiming their bank account is compromised and uses fear and urgency to direct them to sideload a "verification app" to secure their funds, often coaching them to ignore standard security warnings. Once installed, this app — actually malware — intercepts the victim's notifications. When the user logs into their real banking app, the malware captures their two-factor authentication codes, giving the scammer everything they need to drain the account.&lt;/p&gt;
    &lt;p&gt;While we have advanced safeguards and protections to detect and take down bad apps, without verification, bad actors can spin up new harmful apps instantly. It becomes an endless game of whack-a-mole. Verification changes the math by forcing them to use a real identity to distribute malware, making attacks significantly harder and more costly to scale. We have already seen how effective this is on Google Play, and we are now applying those lessons to the broader Android ecosystem to ensure there is a real, accountable identity behind the software you install.&lt;/p&gt;
    &lt;p&gt;Supporting students and hobbyists&lt;/p&gt;
    &lt;p&gt;We heard from developers who were concerned about the barrier to entry when building apps intended only for a small group, like family or friends. We are using your input to shape a dedicated account type for students and hobbyists. This will allow you to distribute your creations to a limited number of devices without going through the full verification requirements.&lt;/p&gt;
    &lt;p&gt;Empowering experienced users&lt;/p&gt;
    &lt;p&gt;While security is crucial, we’ve also heard from developers and power users who have a higher risk tolerance and want the ability to download unverified apps.&lt;/p&gt;
    &lt;p&gt;Based on this feedback and our ongoing conversations with the community, we are building a new advanced flow that allows experienced users to accept the risks of installing software that isn't verified. We are designing this flow specifically to resist coercion, ensuring that users aren't tricked into bypassing these safety checks while under pressure from a scammer. It will also include clear warnings to ensure users fully understand the risks involved, but ultimately, it puts the choice in their hands. We are gathering early feedback on the design of this feature now and will share more details in the coming months.&lt;/p&gt;
    &lt;p&gt;Getting started with early access&lt;/p&gt;
    &lt;p&gt;Today, we’re excited to start inviting developers to the early access for developer verification in Android Developer Console for developers that distribute exclusively outside of Play, and will share invites to the Play Console experience soon for Play developers. We are looking forward to your questions and feedback on streamlining the experience for all developers.&lt;/p&gt;
    &lt;p&gt;Watch our video below for a walkthrough of the new Android Developer Console experience and see our guides for more details and FAQs.&lt;/p&gt;
    &lt;p&gt;We are committed to working with you to keep the ecosystem safe while getting this right.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45908938</guid><pubDate>Thu, 13 Nov 2025 00:33:25 +0000</pubDate></item><item><title>Human Fovea Detector</title><link>https://www.shadertoy.com/view/4dsXzM</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45909059</guid><pubDate>Thu, 13 Nov 2025 00:48:45 +0000</pubDate></item><item><title>Android 16 QPR1 is being pushed to the Android Open Source Project</title><link>https://grapheneos.social/@GrapheneOS/115533432439509433</link><description>&lt;doc fingerprint="f8eb8f2f2d953eed"&gt;
  &lt;main&gt;
    &lt;p&gt;To use the Mastodon web application, please enable JavaScript. Alternatively, try one of the native apps for Mastodon for your platform.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45910381</guid><pubDate>Thu, 13 Nov 2025 03:49:23 +0000</pubDate></item><item><title>Reverse Engineering Yaesu FT-70D Firmware Encryption</title><link>https://landaire.net/reversing-yaesu-firmware-encryption/</link><description>&lt;doc fingerprint="8e1192112a7bc6b0"&gt;
  &lt;main&gt;
    &lt;p&gt;This article dives into my full methodology for reverse engineering the tool mentioned in this article. It's a bit longer but is intended to be accessible to folks who aren't necessarily advanced reverse-engineers.&lt;/p&gt;
    &lt;p&gt;Click on any of the images to view at its original resolution.&lt;/p&gt;
    &lt;head rend="h2"&gt;# Background&lt;/head&gt;
    &lt;p&gt;Ham radios are a fun way of learning how the radio spectrum works, and more importantly: they're embedded devices that may run weird chips/firmware! I got curious how easy it'd be to hack my Yaesu FT-70D, so I started doing some research. The only existing resource I could find for Yaesu radios was someone who posted about custom firmware for their Yaesu FT1DR.&lt;/p&gt;
    &lt;p&gt;The Reddit poster mentioned that if you go through the firmware update process via USB, the radio exposes its Renesas H8SX microcontroller and can have its flash modified using the Renesas SDK. This was a great start and looked promising, but the SDK wasn't trivial to configure and I wasn't sure if it could even dump the firmware... so I didn't use it for very long.&lt;/p&gt;
    &lt;head rend="h2"&gt;# Other Avenues&lt;/head&gt;
    &lt;p&gt;Yaesu provides a Windows application on their website that can be used to update a radio's firmware over USB:&lt;/p&gt;
    &lt;p&gt;The zip contains the following files:&lt;/p&gt;
    &lt;code&gt;1.2 MB  Wed Nov  8 14:34:38 2017  FT-70D_ver111(USA).exe
682 KB  Tue Nov 14 00:00:00 2017  FT-70DR_DE_Firmware_Update_Information_ENG_1711-B.pdf
8 MB  Mon Apr 23 00:00:00 2018  FT-70DR_DE_MAIN_Firmware_Ver_Up_Manual_ENG_1804-B.pdf
3.2 MB  Fri Jan  6 17:54:44 2012  HMSEUSBDRIVER.exe
160 KB  Sat Sep 17 15:14:16 2011  RComms.dll
61 KB  Tue Oct 23 17:02:08 2012  RFP_USB_VB.dll
1.7 MB  Fri Mar 29 11:54:02 2013  vcredist_x86.exe
&lt;/code&gt;
    &lt;p&gt;I'm going to assume that the file specific to the FT-70D, "FT-70D_ver111(USA).exe", will likely contain our firmware image. A PE file (.exe) can contain binary resources in the &lt;code&gt;.rsrc&lt;/code&gt; section -- let's see what this file contains using XPEViewer:&lt;/p&gt;
    &lt;p&gt;Resources fit into one of many different resource types, but a firmware image would likely be put into a custom type. What's this last entry, "23"? Expanding that node we have a couple of interesting items:&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;RES_START_DIALOG&lt;/code&gt; is a custom string the updater shows when preparing an update, so we're in the right area!&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;RES_UPDATE_INFO&lt;/code&gt; looks like just binary data -- perhaps this is our firmware image? Unfortunately looking at the "Strings" tab in XPEViewer or running the &lt;code&gt;strings&lt;/code&gt; utility over this data doesn't yield anything legible. The firmware image is likely encrypted.&lt;/p&gt;
    &lt;head rend="h2"&gt;# Reverse Engineering the Binary&lt;/head&gt;
    &lt;p&gt;Let's load the update utility into our disassembler of choice to figure out how the data is encrypted. I'll be using IDA Pro, but Ghidra (free!), radare2 (free!), or Binary Ninja are all great alternatives. Where possible in this article I'll try to show my rewritten code in C since it'll be a closer match to the decompiler and machine code output.&lt;/p&gt;
    &lt;p&gt;A good starting point is the the string we saw above, &lt;code&gt;RES_UPDATE_INFO&lt;/code&gt;. Windows applications load resources by calling one of the &lt;code&gt;FindResource*&lt;/code&gt; APIs. &lt;code&gt;FindResourceA&lt;/code&gt; has the following parameters:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;HMODULE&lt;/code&gt;, a handle to the module to look for the resource in.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;lpName&lt;/code&gt;, the resource name.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;lpType&lt;/code&gt;, the resource type.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In our disassembler we can find references to the &lt;code&gt;RES_UPDATE_INFO&lt;/code&gt; string and look for calls to &lt;code&gt;FindResourceA&lt;/code&gt; with this string as an argument in the &lt;code&gt;lpName&lt;/code&gt; position.&lt;/p&gt;
    &lt;p&gt;We find a match in a function which happens to find/load all of these custom resources under type &lt;code&gt;23&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;We know where the data is loaded by the application, so now we need to see how it's used. Doing static analysis from this point may be more work than it's worth if the data isn't operated on immediately. To speed things up I'm going to use a debugger's assistance. I used WinDbg's Time Travel Debugging to record an execution trace of the updater while it updates my radio. TTD is an invaluable tool and I'd highly recommend using it when possible. rr is an alternative for non-Windows platforms.&lt;/p&gt;
    &lt;p&gt;The decompiler output shows this function copies the &lt;code&gt;RES_UPDATE_INFO&lt;/code&gt; resource to a dynamically allocated buffer. The &lt;code&gt;qmemcpy()&lt;/code&gt; is inlined and represented by a &lt;code&gt;rep movsd&lt;/code&gt; instruction in the disassembly, so we need to break at this instruction and examine the &lt;code&gt;edi&lt;/code&gt; register's (destination address) value. I set a breakpoint by typing &lt;code&gt;bp 0x406968&lt;/code&gt; in the command window, allow the application to continue running, and when it breaks we can see the &lt;code&gt;edi&lt;/code&gt; register value is &lt;code&gt;0x2be5020&lt;/code&gt;. We can now set a memory access breakpoint at this address using &lt;code&gt;ba r4 0x2be5020&lt;/code&gt; to break whenever this data is read.&lt;/p&gt;
    &lt;p&gt;Our breakpoint is hit at &lt;code&gt;0x4047DC&lt;/code&gt; -- back to the disassembler. In IDA you can press &lt;code&gt;G&lt;/code&gt; and enter this address to jump to it. We're finally at what looks like the data processing function:&lt;/p&gt;
    &lt;p&gt;We broke when dereferencing &lt;code&gt;v2&lt;/code&gt; and IDA has automatically named the variable it's being assigned to as &lt;code&gt;Time&lt;/code&gt;. The &lt;code&gt;Time&lt;/code&gt; variable is passed to another function which formats it as a string with &lt;code&gt;%Y%m%d%H%M%S&lt;/code&gt;. Let's clean up the variables to reflect what we know:&lt;/p&gt;
    &lt;p&gt;The timestamp string is passed to &lt;code&gt;sub_4082c0&lt;/code&gt; on line 20 and the remainder of the update image is passed to &lt;code&gt;sub_408350&lt;/code&gt; on line 21. I'm going to focus on &lt;code&gt;sub_408350&lt;/code&gt; since I only care about the firmware data right now and based on how this function is called I'd wager its signature is something like:&lt;/p&gt;
    &lt;code&gt;status_t sub_408350(uint8_t *input, size_t input_len, uint8_t *output, output_len, size_t *out_data_processed);
&lt;/code&gt;
    &lt;p&gt;Let's see what it does:&lt;/p&gt;
    &lt;p&gt;I think we've found our function that starts decrypting the firmware! To confirm, we want to see what the &lt;code&gt;output&lt;/code&gt; parameter's data looks like before and after this function is called. I set a breakpoint in the debugger at the address where it's called (&lt;code&gt;bp 0x404842&lt;/code&gt;) and put the value of the &lt;code&gt;edi&lt;/code&gt; register (&lt;code&gt;0x2d7507c&lt;/code&gt;) in WinDbg's memory window.&lt;/p&gt;
    &lt;p&gt;Here's the data before:&lt;/p&gt;
    &lt;p&gt;After stepping over the function call:&lt;/p&gt;
    &lt;p&gt;We can dump this data to a file using the following command:&lt;/p&gt;
    &lt;code&gt;.writemem C:\users\lander\documents\maybe_deobfuscated.bin 0x2d7507c L100000
&lt;/code&gt;
    &lt;p&gt;010 Editor has a built-in strings utility (Search &amp;gt; Find Strings...) and if we scroll down a bit in the results, we have real strings that appear in my radio!&lt;/p&gt;
    &lt;p&gt;At this point if we were just interested in getting the plaintext firmware we could stop messing with the binary and load the firmware into IDA Pro... but I want to know how this encryption works.&lt;/p&gt;
    &lt;head rend="h2"&gt;# Encryption Details&lt;/head&gt;
    &lt;p&gt;Just to recap from the last section:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We've identified our data processing routine (let's call this function &lt;code&gt;decrypt_update_info&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;We know that the first 4 bytes of the update data are a Unix timestamp that's formatted as a string and used for an unknown purpose.&lt;/item&gt;
      &lt;item&gt;We know which function begins decrypting our firmware image.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;# Data Decryption&lt;/head&gt;
    &lt;p&gt;Let's look at the firmware image decryption routine with some renamed variables:&lt;/p&gt;
    &lt;p&gt;At a high level this routine:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Allocates a 64-byte scratch buffer&lt;/item&gt;
      &lt;item&gt;Checks if there's any data to process. If not, set the output variable &lt;code&gt;out_data_processed&lt;/code&gt;to the number of bytes processed and return 0x0 (&lt;code&gt;STATUS_SUCCESS&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Loop over the input data in 8-byte chunks and inflate each byte to its bit representation.&lt;/item&gt;
      &lt;item&gt;After the 8-byte chunk is inflated, call &lt;code&gt;sub_407980&lt;/code&gt;with the scratch buffer and&lt;code&gt;0&lt;/code&gt;as arguments.&lt;/item&gt;
      &lt;item&gt;Loop over the scratch buffer and reassemble 8 sequential bits as 1 byte, then set the byte at the appropriate index in the output buffer.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Lots going on here, but let's take a look at step #3. If we take the bytes &lt;code&gt;0xAA&lt;/code&gt; and &lt;code&gt;0x77&lt;/code&gt; which have bit representations of &lt;code&gt;0b1010_1010&lt;/code&gt; and &lt;code&gt;0b0111_1111&lt;/code&gt; respectively and inflate them to a 16-byte array using the algorithm above, we end up with:&lt;/p&gt;
    &lt;code&gt;| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 |    | 8 | 9 | A | B | C | D | E | F |
|---|---|---|---|---|---|---|---|----|---|---|---|---|---|---|---|---|
| 1 | 0 | 1 | 0 | 1 | 0 | 1 | 0 |    | 0 | 1 | 1 | 1 | 0 | 1 | 1 | 1 |
&lt;/code&gt;
    &lt;p&gt;This routine does this process over 8 bytes at a time and completely fills the 64-byte scratch buffer with 1s and 0s just like the table above.&lt;/p&gt;
    &lt;p&gt;Now let's look at step #4 and see what's going on in &lt;code&gt;sub_407980&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;Oof. This is substantially more complicated but looks like the meat of the decryption algorithm. We'll refer to this function, &lt;code&gt;sub_407980&lt;/code&gt;, as &lt;code&gt;decrypt_data&lt;/code&gt; from here on out. We can see what may be an immediate roadblock: this function takes in a C++ &lt;code&gt;this&lt;/code&gt; pointer (line 5) and performs bitwise operations on one of its members (line 18, 23, etc.). For now let's call this class member &lt;code&gt;key&lt;/code&gt; and come back to it later.&lt;/p&gt;
    &lt;p&gt;This function is the perfect example of decompilers emitting less than ideal code as a result of compiler optimizations/code reordering. For me, TTD was essential for following how data flows through this function. It took a few hours of banging my head against IDA and WinDbg to understand, but this function can be broken up into 3 high-level phases:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Building a 48-byte buffer containing our key material XOR'd with data from a static table.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Build a 32-byte buffer containing data from an 0x800-byte static table, with indexes into this table originating from indices built from the buffer in step #1. Combine this 32-byte buffer with the 48-byte buffer in step #1.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Iterate over the next 8 bytes of the output buffer. For each byte index of the output buffer, index into yet another static 32-byte buffer and use that as the index into the table from step #2. XOR this value with the value at the current index of the output buffer.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The inner loop in the &lt;code&gt;else&lt;/code&gt; branch above I think is kind of nasty, so here it is reimplemented in Rust:&lt;/p&gt;
    &lt;head rend="h3"&gt;# Key Setup&lt;/head&gt;
    &lt;p&gt;We now need to figure out how our key is set up for usage in the &lt;code&gt;decrypt_data&lt;/code&gt; function above. My approach here is to set a breakpoint at the first instruction to use the key data in &lt;code&gt;decrypt_data&lt;/code&gt;, which happens to be &lt;code&gt;xor bl, [ecx + esi + 4]&lt;/code&gt; at &lt;code&gt;0x4079d3&lt;/code&gt;. I know this is where we should break because in the decompiler output the left-hand side of the XOR operation, the key material, will be the second operand in the &lt;code&gt;xor&lt;/code&gt; instruction. As a reminder, the decompiler shows the XOR as:&lt;/p&gt;
    &lt;code&gt;v8 = *(_BYTE *)(i + 48 * v7 + v3 + 4) ^ a2[(unsigned __int8)byte_424E50[i] + 31];
&lt;/code&gt;
    &lt;p&gt;The breakpoint is hit and the address we're loading from is &lt;code&gt;0x19f5c4&lt;/code&gt;. We can now lean on TTD to help us figure out where this data was last written. Set a 1-byte memory write breakpoint at this address using &lt;code&gt;ba w1 0x19f5c4&lt;/code&gt; and press the &lt;code&gt;Go Back&lt;/code&gt; button. If you've never used TTD before, this operates exactly as &lt;code&gt;Go&lt;/code&gt; would except backwards in the program's trace. In this case it will execute backward until either a breakpoint is hit, interrupt is generated, or we reach the start of the program.&lt;/p&gt;
    &lt;p&gt;Our memory write breakpoint gets triggered at &lt;code&gt;0x4078fb&lt;/code&gt; -- a function we haven't seen before. The callstack shows that it's called not terribly far from the &lt;code&gt;decrypt_update_info&lt;/code&gt; routine!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;set_key&lt;/code&gt;(we are here -- function is originally called&lt;code&gt;sub_407850&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;sub_4082c0&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;decrypt_update_info&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What's &lt;code&gt;sub_4082c0&lt;/code&gt;?&lt;/p&gt;
    &lt;p&gt;Not a lot to see here except the same function called 4 times, initially with the timestamp string as an argument in position 0, a 64-byte buffer, and bunch of function calls using the return value of the last as its input. The function our debugger just broke into takes only 1 argument, which is the 64-byte buffer used across all of these function calls. So what's going on in &lt;code&gt;sub_407e80&lt;/code&gt;?&lt;/p&gt;
    &lt;p&gt;The bitwise operations that look supsiciously similar to the byte to bit inflation we saw above with the firmware data. After renaming things and performing some loop unrolling, things look like this:&lt;/p&gt;
    &lt;p&gt;The only mystery now is the &lt;code&gt;set_key&lt;/code&gt; routine:&lt;/p&gt;
    &lt;p&gt;This function is a bit more straightforward to reimplement:&lt;/p&gt;
    &lt;head rend="h3"&gt;# Putting Everything Together&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Update data is read from resources&lt;/item&gt;
      &lt;item&gt;The first 4 bytes of the update data are a Unix timestamp&lt;/item&gt;
      &lt;item&gt;The timestamp is formatted as a string, has each byte inflated to its bit representation, and decrypted using some static key material as the key. This is repeated 4 times with the output of the previous run used as an input to the next.&lt;/item&gt;
      &lt;item&gt;The resulting data from step 3 is used as a key for decrypting data.&lt;/item&gt;
      &lt;item&gt;The remainder of the firmware update image is inflated to its bit representation 8 bytes at a time and uses the dynamic key and 3 other unique static lookup tables to transform the inflated input data.&lt;/item&gt;
      &lt;item&gt;The result from step 5 is deflated back into its byte representation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;My decryption utility which completely reimplements this magic in Rust can be found at https://github.com/landaire/porkchop.&lt;/p&gt;
    &lt;head rend="h2"&gt;# Loading the Firmware in IDA Pro&lt;/head&gt;
    &lt;p&gt;IDA thankfully supports disassembling the Hitachi/Rensas H8SX architecture. If we load our firmware into IDA and select the "Hitachi H8SX advanced" processsor type, use the default options for the "Disassembly memory organization" dialog, then finally choose "H8S/2215R" in the "Choose the device name" dialog...:&lt;/p&gt;
    &lt;p&gt;We don't have shit. I'm not an embedded systems expert, but my friend suggested that the first few DWORDs look like they may belong to a vector table. If we right-click address 0 and select "Double word 0x142A", we can click on the new variable &lt;code&gt;unk_142A&lt;/code&gt; to go to its location. Press &lt;code&gt;C&lt;/code&gt; at this location to define it as Code, then press &lt;code&gt;P&lt;/code&gt; to create a function at this address:&lt;/p&gt;
    &lt;p&gt;We can now reverse engineer our firmware :)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45911704</guid><pubDate>Thu, 13 Nov 2025 07:12:01 +0000</pubDate></item><item><title>Checkout.com hacked, refuses ransom payment, donates to security labs</title><link>https://www.checkout.com/blog/protecting-our-merchants-standing-up-to-extortion</link><description>&lt;doc fingerprint="dd28949d2929f588"&gt;
  &lt;main&gt;
    &lt;p&gt;Tl;dr: Last week, we were targeted by a criminal extortion attempt. The attackers gained access to a legacy, third-party cloud file storage system.Â&lt;/p&gt;
    &lt;p&gt;Our live payment processing platform was not impacted. No merchant funds or card numbers were accessed.Â&lt;/p&gt;
    &lt;p&gt;We are donating the ransom amount to fund cybercrime research.&lt;/p&gt;
    &lt;p&gt;Last week, Checkout.com was contacted by a criminal group known as âShinyHuntersâ, who claimed to have obtained data connected to Checkout.com and demanded a ransom.&lt;/p&gt;
    &lt;p&gt;Upon investigation, we determined that this data was obtained by gaining unauthorized access to a legacy third-party cloud file storage system, used in 2020 and prior years. We estimate that this would affect less than 25% of our current merchant base. The system was used for internal operational documents and merchant onboarding materials at that time.&lt;/p&gt;
    &lt;p&gt;This incident has not impacted our payment processing platform. The threat actors do not have, and never had, access to merchant funds or card numbers.&lt;/p&gt;
    &lt;p&gt;The episode occurred when threat actors gained access to this third party legacy system which was not decommissioned properly. This was our mistake, and we take full responsibility.&lt;/p&gt;
    &lt;p&gt;We are sorry. We regret that this incident has caused worry for our partners and people. We have begun the process to identify and contact those impacted and are working closely with law enforcement and the relevant regulators. We are fully committed to maintaining your trust.Â Â&lt;/p&gt;
    &lt;p&gt;We will not be extorted by criminals. We will not pay this ransom.Â&lt;/p&gt;
    &lt;p&gt;Instead, we are turning this attack into an investment in security for our entire industry. We will be donating the ransom amount to Carnegie Mellon University and the University of Oxford Cyber Security Center to support their research in the fight against cybercrime.&lt;/p&gt;
    &lt;p&gt;Security, transparency and trust are the foundation of our industry. We will own our mistakes, protect our merchants, and invest in the fight against the criminal actors who threaten our digital economy.Â&lt;/p&gt;
    &lt;p&gt;We are here to assist our merchants in whatever way we can. As always, we are available through your regular Checkout point of contact for any further assistance or questions you may have.&lt;/p&gt;
    &lt;p&gt;Mariano Albera, Chief Technology Officer, Checkout.com&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45912698</guid><pubDate>Thu, 13 Nov 2025 09:23:30 +0000</pubDate></item><item><title>Telli (Voice AI – YC F24) is hiring engineers in Berlin</title><link>https://hi.telli.com/eng</link><description>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45912744</guid><pubDate>Thu, 13 Nov 2025 09:30:53 +0000</pubDate></item><item><title>Seed. LINE's Custom Typeface</title><link>https://seed.line.me/index_en.html</link><description>&lt;doc fingerprint="89d0a618096aa0ed"&gt;
  &lt;main&gt;
    &lt;p&gt;LINE Seed&lt;/p&gt;
    &lt;p&gt;LINE Seed Licensing&lt;/p&gt;
    &lt;quote&gt;All content of LINE Seed is copyrighted material owned by LY Corp. All fonts are released under the SIL Open Font License, Version1.1. This license is also available with a FAQ at: https://scripts.sil.org/OFL You can use them for any personal or commercial purposes. However, the software font files themselves cannot be sold by the other parties other than LY Corp. For commercial use, we highly recommend to include attribution in product or service. This isn't legal advice, please consider consulting a lawyer and see the full license for all details.&lt;/quote&gt;
    &lt;p&gt;LINE Seedã®ã©ã¤ã»ã³ã¹ã«ã¤ãã¦&lt;/p&gt;
    &lt;quote&gt;LINE Seedã®ãã¹ã¦ã®ã³ã³ãã³ãã¯ãLINEã¤ãã¼æ ªå¼ä¼ç¤¾ãèä½æ¨©ãæãã¦ãã¾ãã å ¨ã¦ã®ãã©ã³ãã¯ãSIL Open Font License, Version 1.1ã«åºã¥ãã¦å ¬éããã¦ãã¾ãã ãã®ã©ã¤ã»ã³ã¹ã¯ãhttps://scripts.sil.org/OFL ã«å ¨æã¨FAQãæ¡å ããã¦ãã¾ãã æ¥æ¬èªã«ããåèè¨³ã«ã¤ãã¦ã¯ãhttps://licenses.opensource.jp/OFL-1.1/OFL-1.1.html ãåç §ãã¦ãã ããã åäººçãåæ¥çãã«é¢ä¿ãªããèªç±ãªç®çã§ãã®ãã©ã³ããä½¿ç¨ãããã¨ãã§ãã¾ãã ãã ãããã©ã³ããã®ãã®ãåä½ã§LINEã¤ãã¼æ ªå¼ä¼ç¤¾ä»¥å¤ã®ç¬¬ä¸è ãè²©å£²ãããã¨ã¯ã§ãã¾ããã åç¨å©ç¨ã®å ´åã¯ãè£½åã»ãµã¼ãã¹ã«å¸°å±ãå«ãããã¨ãå¼·ãæ¨å¥¨ãã¾ãã ããã¯æ³çãªã¢ããã¤ã¹ã§ã¯ãªããå ´åã«ãã£ã¦ã¯å¼è·å£«ã«ç¸è«ãããã¨ãæ¤è¨ããå ¨ã¦ã®è©³ç´°ã«ã¤ãã¦ã¯å®å ¨ãªã©ã¤ã»ã³ã¹ãåç §ãã¦ãã ããã&lt;/quote&gt;
    &lt;p&gt;LINE Seed ì ìê¶ ìë´&lt;/p&gt;
    &lt;quote&gt;LINE Seedì ëª¨ë ì½í ì¸ ë LY Corp. ìì ì ì ìë¬¼ì ëë¤. ëª¨ë ê¸ê¼´ì SIL Open Font License ë²ì 1.1ì ê¸°ë°ì¼ë¡ ê³µê°ëììµëë¤. ì´ ë¼ì´ì ì¤ëÂ https://scripts.sil.org/OFLì ì ë¬¸ê³¼ FAQê° ìë´ëì´ ììµëë¤. ê°ì¸ ëë ìì ì ëª©ì ì¼ë¡ ì´ ê¸ê¼´ì ì¬ì©í ì ììµëë¤. ë¨, LY Corp. ì´ì¸ìÂ ìê° ìíí¸ì¨ì´ ê¸ê¼´ íì¼ ìì²´ë¥¼ íë§¤í ì ììµëë¤. ìì ì ì©ëë¡ íì©í ê²½ì° ì í ëë ìë¹ì¤ì ì¶ì² íê¸°ë¥¼ ê°ë ¥í ê¶ì¥í©ëë¤. ì´ëÂ ë²ì ì¡°ì¸ì´ ìëë©°, ëª¨ë ìì¸í ë´ì©ì ëí´ìëÂ ë³í¸ì¬ì ììíë ê²ì ê³ ë ¤íìê³ , ë¼ì´ì ì¤ ì ë¬¸ì ì°¸ê³ íìê¸° ë°ëëë¤. â» LINE SeedÂ ë¼ì´ì ì¤Â ì ë¬¸ìÂ íê¸ìÂ ì´ì©ììÂ ì´í´ë¥¼Â ëê¸°Â ìí´Â ìë¬¸Â ìë³¸ìÂ ë²ìí´Â ìë¹ì¤íê³ Â ìì¼ë©°,Â ë²ì Â í¨ë ¥ìÂ ìë¬¸ìÂ íí©ëë¤.&lt;/quote&gt;
    &lt;p&gt;à¸¥à¸´à¸à¸ªà¸´à¸à¸à¸´à¹à¸à¸à¸ LINE Seed&lt;/p&gt;
    &lt;quote&gt;à¹à¸à¸·à¹à¸à¸«à¸²à¸à¸±à¹à¸à¸«à¸¡à¸à¸à¸à¸à¸à¸à¸à¸à¹ LINE Seed à¹à¸à¹à¸à¸à¸¥à¸à¸²à¸à¸à¸±à¸à¸¡à¸µà¸¥à¸´à¸à¸ªà¸´à¸à¸à¸´à¹à¸à¸¶à¹à¸à¹à¸à¹à¸à¸à¸à¸ LY Corp. à¸à¸¸à¸à¸£à¸¹à¸à¹à¸à¸à¸à¸±à¸§à¸à¸±à¸à¸©à¸£à¸à¸±à¹à¸à¸«à¸¡à¸à¸à¸¢à¸¹à¹à¸ à¸²à¸¢à¹à¸à¹ SIL Open Font License, à¹à¸§à¸à¸£à¹à¸à¸±à¹à¸ 1.1. à¸ªà¸²à¸¡à¸²à¸£à¸à¸à¸£à¸§à¸à¸ªà¸à¸à¸à¸³à¸à¸²à¸¡à¹à¸à¸µà¹à¸¢à¸§à¸à¸±à¸à¹à¸à¸·à¹à¸à¸«à¸²à¸¥à¸´à¸à¸ªà¸´à¸à¸à¸´à¹à¸à¸µà¹à¸à¸à¸à¹à¸à¸¢ à¹à¸à¹à¸à¸µà¹ https://scripts.sil.org/OFL à¸à¸¸à¸à¸£à¸¹à¸à¹à¸à¸à¸à¸±à¸§à¸à¸±à¸à¸©à¸£à¸à¸±à¹à¸à¸«à¸¡à¸à¸ªà¸²à¸¡à¸²à¸£à¸à¸à¸³à¹à¸à¹à¸à¹à¹à¸à¹à¸à¸£à¸µ à¹à¸¡à¹à¸à¹à¸à¸à¹à¸ªà¸µà¸¢à¸à¹à¸²à¹à¸à¹à¸à¹à¸²à¸¢ à¹à¸à¸¢à¸ªà¸²à¸¡à¸²à¸£à¸à¸à¸³à¹à¸à¹à¸à¹à¸à¸²à¸à¹à¸à¹à¸à¸à¸²à¸£à¸ªà¹à¸§à¸à¸à¸±à¸§ à¸«à¸£à¸·à¸à¹à¸à¹à¸à¸²à¸à¹à¸à¸´à¸à¸à¸²à¸à¸´à¸à¸¢à¹à¸à¹à¹à¸à¹ à¸à¸¢à¹à¸²à¸à¹à¸£à¸à¹à¸à¸²à¸¡ à¸à¸¸à¸à¸à¸¥à¸à¸·à¹à¸à¸à¸µà¹à¹à¸¡à¹à¹à¸à¹ LY Corp. à¸à¸°à¹à¸¡à¹à¸ªà¸²à¸¡à¸²à¸£à¸à¸à¸³à¹à¸à¸¥à¹à¸à¸à¸à¸à¹ LINE Seed à¹à¸à¸à¸³à¸«à¸à¹à¸²à¸¢à¹à¸à¹ à¹à¸¥à¸°à¸«à¸²à¸à¸¡à¸µà¸à¸²à¸£à¸à¸³à¸à¸à¸à¸à¹à¹à¸à¹à¸à¹à¹à¸à¹à¸à¸´à¸à¸à¸²à¸à¸´à¸à¸¢à¹ à¹à¸£à¸²à¹à¸à¸°à¸à¸³à¹à¸à¹à¸à¸à¸¢à¹à¸²à¸à¸¢à¸´à¹à¸à¹à¸«à¹à¸à¹à¸²à¸à¸£à¸°à¸à¸¸à¸à¸µà¹à¸¡à¸²à¸à¸à¸à¸à¸à¸à¸à¹à¹à¸§à¹à¸à¸à¸à¸¥à¸´à¸à¸ à¸±à¸à¸à¹à¸«à¸£à¸·à¸à¸à¸£à¸´à¸à¸²à¸£ à¸à¸¢à¹à¸²à¸à¹à¸£à¸à¹à¸à¸²à¸¡ à¹à¸à¸°à¸à¸³à¹à¸«à¹à¸à¸£à¸¶à¸à¸©à¸²à¸à¸µà¹à¸à¸£à¸¶à¸à¸©à¸²à¸à¸²à¸à¸à¹à¸²à¸à¸à¸à¸«à¸¡à¸²à¸¢ à¹à¸¥à¸°à¸à¸£à¸§à¸à¸ªà¸à¸à¸£à¸²à¸¢à¸¥à¸°à¹à¸à¸µà¸¢à¸à¸¥à¸´à¸à¸ªà¸´à¸à¸à¸´à¹à¸à¸à¸±à¸à¸ªà¸¡à¸à¸¹à¸£à¸à¹&lt;/quote&gt;
    &lt;p&gt;LINE Seed åé«ææ¬èªªæ&lt;/p&gt;
    &lt;quote&gt;LINE Seed å ¨é¨å §å®¹ä¹èä½æ¬åç± LY Corp. ææã æ¬åé«å¥ä»¶ä¾æ SIL Open Font License, Version 1.1 ææ¬æ¢æ¬¾é²è¡ç¼å¸ã å®æ´ææ¬æ¢æåå¸¸è¦åé¡å¯åé±ï¼https://scripts.sil.org/OFL æ¬åé«å¯èªç±ä½¿ç¨æ¼åäººæåæ¥ç¨éï¼ä¸åéå¶ã æé æ³¨æï¼é¤ LY Corp. å¤ï¼ä»»ä½ç¬¬ä¸æ¹çä¸å¾å®ç¨é·å®æ¬åé«æªæ¡æ¬èº«ã å¦ä½çºåæ¥ç¨éï¼å»ºè°æç¢ºæ¨ç¤ºæ¬åé«ä¾æºææ¸å±¬è³è¨æ¼ç¸éç¢åææåä¸ã æ¬èªªæå ä¾åèï¼ä¸¦ä¸æ§ææ³å¾æè¦ã å¦éé²ä¸æ¥æ³å¾åå©ï¼æ¬è«è«®è©¢å°æ¥å¾å¸«ï¼ä¸¦è©³é±å®æ´ææ¬æ¢æ¬¾ä»¥ææ¡ææé©ç¨è¦å®ã&lt;/quote&gt;
    &lt;p&gt; LINE Seed is LINEâs new typeface that was &lt;lb/&gt;created based on the brand's convenient &lt;lb/&gt;usability and friendly identity. &lt;lb/&gt;Just like a seed &lt;lb/&gt;takes root and bears fruit, the name Seed &lt;lb/&gt;means to take root firmly in LINE's services &lt;lb/&gt;and grow together &lt;lb/&gt;with our users. &lt;lb/&gt;All the fonts of LINE Seed have the same &lt;lb/&gt;DNA, and the balanced volume and weight &lt;lb/&gt;ensures a harmony &lt;lb/&gt;without requiring extra &lt;lb/&gt;adjustments so that the textâs texture looks &lt;lb/&gt;the same even when different languages &lt;lb/&gt;are put side by side. &lt;/p&gt;
    &lt;p&gt;The simple form of LINE Seed represents the universality and friendliness of LINE. In addition, the rounded corners of the logo have been included as a common element for all glyphs and characters, including letters, numbers, symbols, and icons.&lt;/p&gt;
    &lt;p&gt;friendliness of LINE.&lt;/p&gt;
    &lt;p&gt;In addition, the rounded corners of the logo&lt;/p&gt;
    &lt;p&gt;have been included as a common element for all glyphs and&lt;/p&gt;
    &lt;p&gt;characters, including letters, numbers, symbols, and icons.&lt;/p&gt;
    &lt;p&gt;With the ligature OpenType feature, LINE Seed is able to maintain&lt;/p&gt;
    &lt;p&gt;a consistent letter spacing&lt;/p&gt;
    &lt;p&gt;when certain characters (fi, ff, fl, fj, etc.)&lt;/p&gt;
    &lt;p&gt;are arranged side by side. This is achieved by connecting&lt;/p&gt;
    &lt;p&gt;or transforming&lt;/p&gt;
    &lt;p&gt;characters to improve the counter space (inner white space), which&lt;/p&gt;
    &lt;p&gt;achieves&lt;/p&gt;
    &lt;p&gt;a better rhythm from Display to Text settings.&lt;/p&gt;
    &lt;p&gt;In addition, the various service icons of LINE are&lt;/p&gt;
    &lt;p&gt;included in the text, adding visual fun through clever expressions.&lt;/p&gt;
    &lt;p&gt;LINE Seed has been created in various languages to deliver a consistent message &lt;lb/&gt;to our global users. The typeface was designed based on typographical elements as &lt;lb/&gt;well as morphological elements in order to be read in a unified and natural way while &lt;lb/&gt;maintaining the unique form and function of the characters in each writing system.&lt;/p&gt;
    &lt;p&gt;LINE ã·ã¼ã&lt;/p&gt;
    &lt;p&gt;LINE ì¨ë&lt;/p&gt;
    &lt;p&gt;LINE à¸à¸µà¸&lt;/p&gt;
    &lt;p&gt;LINE ç¨®å&lt;/p&gt;
    &lt;p&gt;LINE collaborated with the London-based &lt;lb/&gt;renowned typeface design studio Dalton Maag &lt;lb/&gt;to create LINE Seed.&lt;lb/&gt; For LINE Creative, Dalton Maag &lt;lb/&gt;deliberately expressed the voice of LINE&lt;lb/&gt; based on &lt;lb/&gt;its own unique design knowledge and perspective.&lt;lb/&gt;This was truly a memorable global &lt;lb/&gt;collaborative effort.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45912785</guid><pubDate>Thu, 13 Nov 2025 09:36:51 +0000</pubDate></item><item><title>Britain's railway privatization was an abject failure</title><link>https://www.rosalux.de/en/news/id/53917/britains-railway-privatization-was-an-abject-failure</link><description>&lt;doc fingerprint="afd090d75c27b7db"&gt;
  &lt;main&gt;
    &lt;p&gt;Liberalization of the railways has been a key tenet of European transport policy since the early 2000s, with proponents claiming that competition results in improved service quality and increased ridership. This is an instantly disprovable statement given that ridership was already on the rise across Europe prior to, rather than after, liberalization efforts, suggesting other effects are at play.&lt;/p&gt;
    &lt;p&gt;Gareth Dennis is an award-winning railway engineer and writer. He is the author of the internationally bestselling book How The Railways Will Fix the Future and co-founder of the Campaign for Level Boarding.&lt;/p&gt;
    &lt;p&gt;On the other hand, the case against fragmented and privatized operations focuses on three key arguments. The first is that railways are complex systems where commercial boundaries at engineering interfaces are a threat to safety and efficiency. The second is that railway operations are geographic monopolies where market conditions are — at best — contrived. The third is that railways are a public service that cannot fail — hence, introducing private interests into the railways is merely a way to sequester income into private hands while the state shoulders the financial risk. In other words, private interests’ role is simply to extract profit that could otherwise be reinvested into the system.&lt;/p&gt;
    &lt;p&gt;The United Kingdom was one of first countries in Europe to liberalize a significant portion of its railways (Northern Ireland’s railways remained publicly owned and operated). As such, the aftermath of privatization is instructive in tracing liberalization’s final destination. In short: it isn’t pretty.&lt;/p&gt;
    &lt;head rend="h4"&gt;Selling the Family Silver&lt;/head&gt;
    &lt;p&gt;The UK’s contiguous network in Wales, Scotland, and England was privatized in stages between 1988 and 1997, starting with its domestic train manufacturing industry. This took place following a massive self-off of public assets in the aftermath of the broader financialization of the British economy. For example, the water industry in England and Wales was wholly divested through the 1980s — something no other country has ever done. Thanks to archived papers from then Prime Minister Margaret Thatcher, we can understand precisely what the political drivers for mass privatization were.&lt;/p&gt;
    &lt;p&gt;First, as a large employer of over 50,000 staff, divesting the water industry would greatly contribute to “the privatisation programme”. Second, it would take necessary investment in an ageing asset off the public books. Finally, it would increase shareholding in the public, mitigate state interference, and create financial assets for trade. It is worth noting that none of these justifications took the quality or expansion of services into account.&lt;/p&gt;
    &lt;p&gt;And so, we turn back to railways. In 1990, things had been looking up for British Rail. Ridership had been climbing solidly since the mid-1980s. The average subsidy was as low as 20 percent of running costs, making the British system one of the most efficient in Europe. Urban, regional, and high-speed rail projects were being delivered or, in the latter case, were in serious development.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Three rolling stock operating companies bought — at rock-bottom prices — an enormous range of hugely valuable trains for which British Rail had scrimped and saved over the preceding decades.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Then the early-1990s recession hit. More than a decade of constrained public spending and service sell-offs meant there was an immediate impact on passenger numbers, sending the government into a panic. Suddenly, the Thatcherite doctrine of “sell everything but the railways” was thrown out the window, and plans for privatization were put in motion.&lt;/p&gt;
    &lt;p&gt;In July 1992, a white paper entitled “New Opportunities for the Railways” was published, heavily informed by Treasury mandarins and their advisers at the Tufton Street-based Adam Smith Institute in London. It recommended nothing less than an atomization of the formerly integrated railway operating structure, with the creation of as many independent elements as possible to maximize perceived opportunities for competition.&lt;/p&gt;
    &lt;p&gt;On 1 April 1994, the Railways Act came into effect and the demise of British Rail began. It is worth noting that privatization had already started in the 1980s, for example with the sale of the train manufacturers in Derby and various ferry operations. But the 1990s was different — this was a fire sale.&lt;/p&gt;
    &lt;head rend="h4"&gt;Deadly Side-Effects&lt;/head&gt;
    &lt;p&gt;The first private entity to be created was Railtrack, which took over the railway infrastructure such as track, signals, and stations. Seven infrastructure maintenance units and six track renewal units were set up to split off maintenance from operation. Six freight operating companies were created. Twenty-five train operating units were also established, which from 1996 onwards were franchised out to the train operating companies.&lt;/p&gt;
    &lt;p&gt;Three rolling stock operating companies (ROSCOs) bought — at rock-bottom prices — an enormous range of hugely valuable trains for which British Rail had scrimped and saved over the preceding decades. They then leased these back to the train operators at eye-watering cost and with little oversight, enabling a significant outflow of cash from the industry. This has incentivized one of British passengers’ biggest gripes — the widespread use of trains that are as short as possible to minimize leasing costs, without a care for the resulting overcrowding.&lt;/p&gt;
    &lt;p&gt;Another impact of the ROSCOs landing a large, cheap asset that they could rent out at high prices was the near-death of the UK train manufacturing industry, as there was no incentive to continue British Rail's programme of fleet renewals. In the aftermath of privatization, only British Rail’s partially fulfilled orders remained on the books, and new passenger trains wouldn't be built at volume until the early 2000s, resulting in the demise of all but the Derby works. At great cost, new plants have opened in Newton Aycliffe and Newport since, but even these are once again under threat thanks to the lack of any long-term rolling stock strategy.&lt;/p&gt;
    &lt;p&gt;All franchises had been awarded, a plethora of regulating and organizing bodies had been established to hold the system together, and privatization was essentially complete by 1 April 1997, achieving the outgoing administration’s goal of completing the process by the next general election. Despite promises to the contrary, New Labour’s coming into power did not result in a reversal of the process.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Franchise agreements, now managed by the Department for Transport, were growing more complex and more restrictive.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;However, in September 1997, an express train collided with a freight train in Southall, London, killing seven people and injuring 139 others. A lack of effective communication between the fragmented elements of the railway was the root cause of the horrific crash, the first of a series of serious fatal derailments that were attributable to the new structure of the railways.&lt;/p&gt;
    &lt;p&gt;In October 1999, the death of 31 people and the injury of 417 others at Ladbroke Grove, London, resulted in a cascade of changes to safety regulation. The derailment of an express train at Hatfield in October 2000 killed four people and injured 70, sending shockwaves through the industry as it had resulted directly from Railtrack’s self-perception as a contract management organization, not an engineering outfit. This fomented the demise of Railtrack, which was absorbed into a new government body called Network Rail. A gargantuan and rushed effort to replace thousands of miles of substandard track materials followed, requiring billions of pounds of additional funds and greatly impacting passenger numbers for several years.&lt;/p&gt;
    &lt;p&gt;Another fatal derailment at Potters Bar in May 2002 killed seven people and was caused by the negligence of a private maintenance company. This led to the return of many maintenance tasks in-house under Network Rail. With the process of Railtrack’s reconstitution as Network Rail completing in October 2002, the UK’s rail infrastructure had been de facto renationalized.&lt;/p&gt;
    &lt;head rend="h4"&gt;Growing Pains&lt;/head&gt;
    &lt;p&gt;The West Coast Main Line had long been considered the jewel in the crown of the British rail network, having been electrified and modernized through the 1950s, 1960s, and 1970s. By 1998, passenger growth was putting significant pressure on the route, and Virgin’s Richard Branson wanted to introduce new tilting trains and a much more frequent timetable. By 2002, costs had risen from 2.5 billion to 14.5 billion pounds (just short of 30 billion pounds in today’s money), and the scope of the project had been severely curtailed. What started in 1998 as a promise for a 140-miles-per-hour railway with fully digital signalling had descended into chaos by the early 2000s, contributing to Railtrack’s demise.&lt;/p&gt;
    &lt;p&gt;By this point, railways were at their most popular since the beginning of the previous century. Passenger numbers were skyrocketing, and a cross-party consensus agreed that rail investment and the expansion of the rail network were a good thing. Franchises previously let as “not for growth” such as those in Wales and the North were creaking at the seams as people turned to trains.&lt;/p&gt;
    &lt;p&gt;Franchise agreements, now managed by the Department for Transport, were growing more complex and more restrictive. The number of bidders reduced, and the ambition of their bids increased. This came to a head in 2009, when National Express was stripped of the East Coast franchise after failing to meet its payment targets despite continuing passenger growth.&lt;/p&gt;
    &lt;p&gt;In 2012, the West Coast bidding process was scrapped by government and was awarded as a short-term concession pending a review, and amidst a wider crisis across the industry in June 2018, the East Coast franchise — subsequently awarded to yet another optimistic bid by Virgin — also collapsed and had to be returned to state operation. By this point, franchise bidders were few and far between, and the system was close to collapse.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Railways must be set into the bigger transport picture with ambitious targets — mobility in totality, not rail in isolation.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;These increasingly overambitious bids, combined with ever-more complex and controlling contracts, left only one lever open to the train operators to cut costs: staffing. From 2016 onwards, a wave of increasingly disruptive strikes took hold of the network, as terms and conditions were altered to attempt to reduce the number of staff the train operating companies had to have on their books.&lt;/p&gt;
    &lt;p&gt;Just as the industry’s new structure had resulted in the creation of the ROSCOs, which incentivised a freeze in new train procurement, the creation of Railtrack and its private suppliers resulted in a freeze in recruitment across the infrastructure domain. Crudely, when you have a fleet of trains that already run the service, why build new ones? The same ended up being broadly true for infrastructure — why employ new staff when you already have an enormous workforce?&lt;/p&gt;
    &lt;p&gt;A decade-wide gap in skills was the consequence. With the growth in passenger demand came a huge growth in the number of infrastructure projects being carried out, and this skills bottleneck, combined with an industry structure that exacerbated costs by maximizing the number of organizational interfaces, meant work was being delivered too slowly and at too high a price. Cost escalations became unbearable for government in 2017 and resulted not only in the curtailment of the national electrification programme, but also in the abandonment of other enhancements across the country, particularly in and around the north of England. Meanwhile, there was a glut of new train orders, many for new electric trains for which there were no longer overhead wires planned to power them.&lt;/p&gt;
    &lt;p&gt;May 2018 was supposed to be the moment that an enormous leap in capacity was created. New track and trains would enable a great leap in the number of trains running in the timetable. As it happened, neither the track nor the trains were in place to deliver much of this uplift, and the result was a collapse in the system’s reliability. Driver training could not happen, and a lack of trains, tracks, and staff resulted in the cancellation of upwards of one third of services in the South East and the north of England, with lesser but significant effects felt by passengers across the network.&lt;/p&gt;
    &lt;p&gt;Long an opponent of the franchise system and the lack of integration between track and train, then Secretary of State for Transport Chris Grayling initiated the Williams Review in 2018 to work out what shape the industry needed to be in to enable growth without cycling back to calamity. This review took time to pick up speed, leaving the industry in perpetual crisis mode.&lt;/p&gt;
    &lt;head rend="h4"&gt;The Final Nail in the Coffin&lt;/head&gt;
    &lt;p&gt;In March 2020, the COVID-19 pandemic reduced ridership to 5 percent of pre-COVID levels and the industry was placed on life support. By the end of that month, all franchises were transferred onto emergency concessions, and the franchise system was gone. This was made official in September 2020, as the government stated that franchising was to cease to exist, and by April 2021 the National Audit Office announced that train operators were to be officially classified as state-owned, despite the continued involvement of private companies. The irony of a Conservative than a Labour government beginning the re-integration of the system should not be lost on readers — indeed, this is a recurring theme.&lt;/p&gt;
    &lt;p&gt;Finally, in May 2021, the Williams—Shapps Plan for Rail was published, setting out a loose view of the future structure of the railways. Although lacking in details, the headline was that a new organization called Great British Railways (GBR) was to be created. A transition team was established to understand what GBR would do and how it would be structured. The ROSCOs, as the last major vestige of the Railways Act 1993, remained untouched.&lt;/p&gt;
    &lt;p&gt;Roll forwards seven years and, despite several train operators being controlled directly by the Department for Transport, there is still no clear picture of what GBR will be empowered or funded to do, let alone what its structure and intentions will be. Meanwhile, a general election has worsened, not improved, the outlook for the railway industry, as the number of major projects continues to fall alongside ongoing maintenance funding. Capacity is more squeezed than ever before.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The rail industry needs democratization, so that decisions about the railways we use are made closer to us.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Despite the public’s continued support for publicly owned railways — 75% in 2025 compared with 60% in 2017 — the extent to which “nationalization” will achieve democratic oversight and the necessary reinvigoration of the industry remains unclear. Britain’s rail unions are cautiously supportive, but it is worth noting that scepticism has grown as the Labour Party drifts further to the centre.&lt;/p&gt;
    &lt;p&gt;The rail industry needs democratization, so that decisions about the railways we use are made closer to us. That means moving power, including over spending, away from Westminster. Democratic accountability at local and regional levels is key to unlocking the cycle of proposed and cancelled investment, and in pushing operators to do better. That means devolution of decision and funding powers to both the regions and cities, but also delivering sufficient industry funding autonomy so that it can respond quickly to these demands and rise above electoral cycles and fiscal anxiety.&lt;/p&gt;
    &lt;p&gt;Railways must be set into the bigger transport picture with ambitious targets — mobility in totality, not rail in isolation. Moreover, investment must be matched to those targets to build a railway that more people can use and benefit from — more capacity, more reliability and more accessibility.&lt;/p&gt;
    &lt;p&gt;Empowerment of the rail industry as a self-governing entity accountable chiefly to the UK’s regions and cities rather than to central government is a critical step in kicking things out of crisis mode and reshaping the industry to be fit for the long-term future. But as important is the need for the railways to tell a story about themselves that the public can get behind. Only with an ambitious and exciting vision of the future will the railways fulfil their true potential. Privatization, as the British experience shows, utterly failed to do so.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45914718</guid><pubDate>Thu, 13 Nov 2025 13:34:38 +0000</pubDate></item><item><title>Blender Lab</title><link>https://www.blender.org/news/introducing-blender-lab/</link><description>&lt;doc fingerprint="c855707f5f7767ff"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;Introducing an innovation space within the Blender project, where designers and developers can work together on challenging or future-facing projects, to keep Blender relevant in the years to come.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Over the years, Blender has grown and matured into a powerful and complex piece of software. With its unstoppable release cycle, a massive, highly demanding, and diverse user community, natural technical debt, and complex technical dependencies, shipping new features and general improvements requires more and more effort and coordination.&lt;/p&gt;
    &lt;p&gt;Software stability and reliability have become critical for individuals and companies. As a consequence, development efforts focus on those aspects, offering progressive improvements of existing functionality only when these are clear enhancements of what is already there.&lt;/p&gt;
    &lt;p&gt;This makes it more challenging to innovate, think outside the box, experiment, and break things.&lt;/p&gt;
    &lt;p&gt;To facilitate this essential aspect of product development, the Blender Foundation is establishing a new project: the Blender Lab. This is the innovation space where designers, developers, and researchers work together on challenging and future-facing projects that will help Blender stay relevant in the years to come.&lt;/p&gt;
    &lt;head rend="h2"&gt;What is a lab activity?&lt;/head&gt;
    &lt;p&gt;A lab activity is a project that brings innovation to the Blender project, and contributes to Blender Foundation’s mission. The project should face some unknowns, but also be handled by a team or individual with sufficient domain knowledge to solve them. Lab activities are meant to be independent of Blender releases.&lt;/p&gt;
    &lt;head rend="h2"&gt;What does it look like?&lt;/head&gt;
    &lt;p&gt;Lab activities are always public and visible on blender.org/lab. Here the ongoing projects are presented, sharing objectives, timeline and participants. Intermediate builds for testing and feedback will be available here as well.&lt;/p&gt;
    &lt;head rend="h2"&gt;First batch, and more examples&lt;/head&gt;
    &lt;p&gt;To get started with this initiative, here are some projects that qualify, and that are listed:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Beyond mouse and keyboard (touch and pen)&lt;/item&gt;
      &lt;item&gt;Beyond mouse and keyboard (VR/XR)&lt;/item&gt;
      &lt;item&gt;Volume rendering&lt;/item&gt;
      &lt;item&gt;Light transport&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Some more projects that could be added soon:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;USD Authoring&lt;/item&gt;
      &lt;item&gt;AI and ML technologies, starting with a Blender MCP server&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Applied vs. Academic research&lt;/head&gt;
    &lt;p&gt;Lab activities can be grouped in two categories:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Applied research, which is the main focus of the lab. Developing and eventually shipping groundbreaking solutions based on the latest research and knowledge in the field&lt;/item&gt;
      &lt;item&gt;Academic research. For example, this can be achieved by participating in projects organized by institutions such as universities and research centers, where Blender developers offer an advisory role on how technology can be implemented in production software.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;How do I make my project a Lab project?&lt;/head&gt;
    &lt;p&gt;The goal is to start with a limited number of projects, assessed by Blender Foundation with the support of key Blender contributors. During the course of 2026, more guidelines will be defined and shared. If you are interested in submitting a proposal for a Lab project, you can do so by contacting Blender Foundation and sharing a public document where you describe the project and make a compelling case for it. The adoption of a project depends on many factors, including funds availability, relevance to the Blender missions, experience of the applicant, and more.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion and credits&lt;/head&gt;
    &lt;p&gt;Special credit goes to Ton Roosendaal for advocating for this project since 2018. At the time the Blender project was not able to allocate resources to the initiative, but today, thanks to growing community and corporate support there starts to be a path for it. Future campaigns and partnerships will be crucial for the success of this project. You can make this happen by joining the Blender Development Fund at fund.blender.org.&lt;/p&gt;
    &lt;p&gt;Francesco Siddi&lt;lb/&gt;Blender Foundation&lt;/p&gt;
    &lt;head rend="h4"&gt;Support the Future of Blender&lt;/head&gt;
    &lt;p&gt;Donate to Blender by joining the Development Fund to support the Blender Foundation’s work on core development, maintenance, and new releases.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45914761</guid><pubDate>Thu, 13 Nov 2025 13:38:47 +0000</pubDate></item><item><title>Heartbeats in Distributed Systems</title><link>https://arpitbhayani.me/blogs/heartbeats-in-distributed-systems/</link><description>&lt;doc fingerprint="add490195729439d"&gt;
  &lt;main&gt;
    &lt;p&gt;In distributed systems, one of the fundamental challenges is knowing whether a node or service is alive and functioning properly. Unlike monolithic applications, where everything runs in a single process, distributed systems span multiple machines, networks, and data centers. This becomes even glaring when the nodes are geographically separated. This is where heartbeat mechanisms come into play.&lt;/p&gt;
    &lt;p&gt;Imagine a cluster of servers working together to process millions of requests per day. If one server silently crashes, how quickly can the system detect this failure and react? How do we distinguish between a truly dead server and one that is just temporarily slow due to network congestion? These questions form the core of why heartbeat mechanisms matter.&lt;/p&gt;
    &lt;head rend="h2"&gt;What are Heartbeat Messages&lt;/head&gt;
    &lt;p&gt;At its most basic level, a heartbeat is a periodic signal sent from one component in a distributed system to another to indicate that the sender is still alive and functioning. Think of it as a simple message that says “I am alive!”&lt;/p&gt;
    &lt;p&gt;Heartbeat messages are typically small and lightweight, often containing just a timestamp, a sequence number, or an identifier. The key characteristic is that they are sent regularly at fixed intervals, creating a predictable pattern that other components can monitor.&lt;/p&gt;
    &lt;p&gt;The mechanism works through a simple contract between two parties: the sender and the receiver. The sender commits to broadcasting its heartbeat at regular intervals, say every 2 seconds. The receiver monitors these incoming heartbeats and maintains a record of when the last heartbeat was received. If the receiver does not hear from the sender within an expected timeframe, it can reasonably assume something has gone wrong.&lt;/p&gt;
    &lt;code&gt;class HeartbeatSender:  
    def __init__(self, interval_seconds):  
        self.interval = interval_seconds  
        self.sequence_number = 0

    def send_heartbeat(self, target):  
        message = {  
            'node_id': self.get_node_id(),  
            'timestamp': time.time(),  
            'sequence': self.sequence_number  
        }  
        send_to(message, target)  
        self.sequence_number += 1

    def run(self):  
        while True:  
            self.send_heartbeat(target_node)  
            time.sleep(self.interval)  &lt;/code&gt;
    &lt;p&gt;When a node crashes, stops responding, or becomes isolated due to network partitions, the heartbeats stop arriving. The monitoring system can then take appropriate action, such as removing the failed node from a load balancer pool, redirecting traffic to healthy nodes, or triggering failover procedures.&lt;/p&gt;
    &lt;head rend="h2"&gt;Core Components of Heartbeat Systems&lt;/head&gt;
    &lt;p&gt;The first component is the heartbeat sender. This is the node or service that periodically generates and transmits heartbeat signals. In most implementations, the sender runs on a separate thread or as a background task to avoid interfering with the primary application logic.&lt;/p&gt;
    &lt;p&gt;The second component is the heartbeat receiver or monitor. This component listens for incoming heartbeats and tracks when each heartbeat was received. The monitor maintains state about all the nodes it is tracking, typically storing the timestamp of the last received heartbeat for each node. When evaluating node health, the monitor compares the current time against the last received heartbeat to determine if a node should be considered failed.&lt;/p&gt;
    &lt;code&gt;class HeartbeatMonitor:  
    def __init__(self, timeout_seconds):  
        self.timeout = timeout_seconds  
        self.last_heartbeats = {}  
        
    def receive_heartbeat(self, message):  
        node_id = message['node_id']  
        self.last_heartbeats[node_id] = {  
            'timestamp': message['timestamp'],  
            'sequence': message['sequence'],  
            'received_at': time.time()  
        }  
        
    def check_node_health(self, node_id):  
        if node_id not in self.last_heartbeats:  
            return False  
            
        last_heartbeat_time = self.last_heartbeats[node_id]['received_at']  
        time_since_heartbeat = time.time() - last_heartbeat_time  
        
        return time_since_heartbeat &amp;lt; self.timeout  
        
    def get_failed_nodes(self):  
        failed_nodes = []  
        current_time = time.time()  
        
        for node_id, data in self.last_heartbeats.items():  
            if current_time - data['received_at'] &amp;gt; self.timeout:  
                failed_nodes.append(node_id)  
                
        return failed_nodes  &lt;/code&gt;
    &lt;p&gt;The third parameter is the heartbeat interval, which determines how frequently heartbeats are sent. This interval represents a fundamental trade-off in distributed systems. Sending heartbeats too frequently, we waste network bandwidth and CPU cycles. Send them too infrequently, and we will be slow to detect failures. Most systems use intervals ranging from 1 to 10 seconds, depending on the application requirements and network characteristics.&lt;/p&gt;
    &lt;p&gt;The fourth one is the timeout or failure threshold. This defines how long the monitor will wait without receiving a heartbeat before declaring a node as failed.&lt;/p&gt;
    &lt;p&gt;Note, the timeout must be carefully chosen to balance two competing concerns: fast failure detection versus tolerance for temporary network delays or processing pauses. A typical rule of thumb is to set the timeout to at least 2 to 3 times the heartbeat interval, allowing for some missed heartbeats before declaring failure.&lt;/p&gt;
    &lt;head rend="h2"&gt;Deciding Heartbeat Intervals and Timeouts&lt;/head&gt;
    &lt;p&gt;When a system uses very short intervals, such as sending heartbeats every 500 milliseconds, it can detect failures quickly. However, this comes at a cost. Each heartbeat consumes network bandwidth, and in a large cluster with hundreds or thousands of nodes, the cumulative traffic can become significant. Additionally, very short intervals make the system more sensitive to transient issues like brief network congestion or garbage collection pauses.&lt;/p&gt;
    &lt;p&gt;Consider a system with 1000 nodes where each node sends heartbeats to a central monitor every 500 milliseconds. This results in 2000 heartbeat messages per second just for health monitoring. In a busy production environment, this overhead can interfere with actual application traffic.&lt;/p&gt;
    &lt;p&gt;Conversely, if the heartbeat interval is too long, say 30 seconds, the system becomes sluggish in detecting failures. A node could crash, but the system would not notice for 30 seconds or more. During this window, requests might continue to be routed to the failed node, resulting in user-facing errors.&lt;/p&gt;
    &lt;p&gt;Similarly, the timeout value must also account for network characteristics. In a distributed system spanning multiple data centers, network latency varies. A heartbeat sent from a node in California to a monitor in Virginia might take 80 milliseconds under normal conditions, but could spike to 200 milliseconds during periods of congestion.&lt;/p&gt;
    &lt;p&gt;Hence, if the timeout is set too aggressively, these transient delays trigger false alarms.&lt;/p&gt;
    &lt;p&gt;A practical approach is to measure the actual round-trip time in the network and use that as a baseline. Many systems follow the rule that the timeout should be at least 10 times the round-trip time. For example, if the average round-trip time is 10 milliseconds, the timeout should be at least 100 milliseconds to account for variance.&lt;/p&gt;
    &lt;code&gt;def calculate_timeout(round_trip_time_ms, heartbeat_interval_ms):  
    # Timeout is 10x the RTT  
    rtt_based_timeout = round_trip_time_ms * 10  
    
    # Timeout should also be at least 2-3x the heartbeat interval  
    interval_based_timeout = heartbeat_interval_ms * 3  
    
    # Use the larger of the two  
    return max(rtt_based_timeout, interval_based_timeout)  &lt;/code&gt;
    &lt;p&gt;Another important consideration is the concept of multiple missed heartbeats before declaring failure. Rather than marking a node as dead after a single missed heartbeat, systems wait until several consecutive heartbeats are missed. This approach reduces false positives caused by packet loss or momentary delays.&lt;/p&gt;
    &lt;p&gt;For instance, if we send heartbeats every 2 seconds and require 3 missed heartbeats before declaring failure, a node would need to be unresponsive for at least 6 seconds before being marked as failed. This provides a good balance between quick failure detection and tolerance for transient issues.&lt;/p&gt;
    &lt;head rend="h2"&gt;Push vs Pull Heartbeat Models&lt;/head&gt;
    &lt;p&gt;Heartbeat mechanisms can be implemented using two different communication models: push and pull.&lt;/p&gt;
    &lt;p&gt;In a push model, the monitored node actively sends heartbeat messages to the monitoring system at regular intervals. The node takes responsibility for broadcasting its own health status. The monitored service simply runs a background thread that periodically sends a heartbeat message.&lt;/p&gt;
    &lt;code&gt;class PushHeartbeat:  
    def __init__(self, monitor_address, interval):  
        self.monitor_address = monitor_address  
        self.interval = interval  
        self.running = False  
        
    def start(self):  
        self.running = True  
        self.heartbeat_thread = threading.Thread(target=self._send_loop)  
        self.heartbeat_thread.daemon = True  
        self.heartbeat_thread.start()  
        
    def _send_loop(self):  
        while self.running:  
            try:  
                self._send_heartbeat()  
            except Exception as e:  
                logging.error(f"Failed to send heartbeat: {e}")  
            time.sleep(self.interval)  
            
    def _send_heartbeat(self):  
        message = {  
            'node_id': self.get_node_id(),  
            'timestamp': time.time(),  
            'status': 'alive'  
        }  
        requests.post(self.monitor_address, json=message)  &lt;/code&gt;
    &lt;p&gt;The push model works well in many scenarios, but it has limitations. If the node itself becomes completely unresponsive or crashes, it obviously cannot send heartbeats. Additionally, in networks with strict firewall rules, the monitored nodes might not be able to initiate outbound connections to the monitoring system.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Kubernetes Node Heartbeats&lt;/item&gt;
      &lt;item&gt;Hadoop YARN NodeManagers push heartbeats to the ResourceManager&lt;/item&gt;
      &lt;item&gt;Celery and Airflow workers push heartbeats to the schedule&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In a pull model, the monitoring system actively queries the nodes at regular intervals to check their health. Instead of waiting for heartbeats to arrive, the monitor reaches out and asks, “Are you alive?” The monitored services expose a health endpoint that responds to these queries.&lt;/p&gt;
    &lt;code&gt;class PullHeartbeat:  
    def __init__(self, nodes, interval):  
        self.nodes = nodes  # List of nodes to monitor  
        self.interval = interval  
        self.health_status = {}  
        
    def start(self):  
        self.running = True  
        self.poll_thread = threading.Thread(target=self._poll_loop)  
        self.poll_thread.daemon = True  
        self.poll_thread.start()  
        
    def _poll_loop(self):  
        while self.running:  
            for node in self.nodes:  
                self._check_node(node)  
            time.sleep(self.interval)  
            
    def _check_node(self, node):  
        try:  
            response = requests.get(f"http://{node}/health", timeout=2)  
            if response.status_code == 200:  
                self.health_status[node] = {  
                    'alive': True,  
                    'last_check': time.time()  
                }  
            else:  
                self.mark_node_unhealthy(node)  
        except Exception as e:  
            self.mark_node_unhealthy(node)  &lt;/code&gt;
    &lt;p&gt;The pull model provides more control to the monitoring system and can be more reliable in some scenarios. Since the monitor initiates the connection, it works better in environments with asymmetric network configurations. However, it also introduces additional load on the monitor, especially in large clusters where hundreds or thousands of nodes need to be polled regularly.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Load balancers actively probe backend servers&lt;/item&gt;
      &lt;item&gt;Prometheus pulls metrics endpoints on each target&lt;/item&gt;
      &lt;item&gt;Redis Sentinel monitors and polls Redis instances with PING&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By the way, many real-world systems use a hybrid approach that combines elements of both models. For example, nodes might send heartbeats proactively (push), but the monitoring system also periodically polls critical nodes (pull) as a backup mechanism. This redundancy improves overall reliability.&lt;/p&gt;
    &lt;head rend="h2"&gt;Failure Detection Algorithms&lt;/head&gt;
    &lt;p&gt;While basic heartbeat mechanisms are effective, they struggle with the challenge of distinguishing between actual failures and temporary slowdowns. This is where more sophisticated failure detection algorithms come into play.&lt;/p&gt;
    &lt;p&gt;The simplest failure detection algorithm uses a fixed timeout. If no heartbeat is received within the specified timeout period, the node is declared failed. While easy to implement, this binary approach is inflexible and prone to false positives in networks with variable latency.&lt;/p&gt;
    &lt;code&gt;class FixedTimeoutDetector:  
    def __init__(self, timeout):  
        self.timeout = timeout  
        self.last_heartbeats = {}  
        
    def is_node_alive(self, node_id):  
        if node_id not in self.last_heartbeats:  
            return False  
        
        elapsed = time.time() - self.last_heartbeats[node_id]  
        return elapsed &amp;lt; self.timeout  &lt;/code&gt;
    &lt;head rend="h3"&gt;Phi Accrual Failure Detection&lt;/head&gt;
    &lt;p&gt;A more sophisticated approach is the phi accrual failure detector, originally developed for the Cassandra database. Instead of providing a binary output (alive or dead), the phi accrual detector calculates a suspicion level on a continuous scale. The higher the suspicion value, the more likely it is that the node has failed.&lt;/p&gt;
    &lt;p&gt;The phi value is calculated using statistical analysis of historical heartbeat arrival times. The algorithm maintains a sliding window of recent inter-arrival times and uses this data to estimate the probability distribution of when the next heartbeat should arrive. If a heartbeat is late, the phi value increases gradually rather than jumping immediately to a failure state.&lt;/p&gt;
    &lt;p&gt;The phi value represents the confidence level that a node has failed. For example, a phi value of 1 corresponds to approximately 90% confidence, a phi of 2 corresponds to 99% confidence, and a phi of 3 corresponds to 99.9% confidence.&lt;/p&gt;
    &lt;head rend="h2"&gt;Gossip Protocols for Heartbeats&lt;/head&gt;
    &lt;p&gt;As distributed systems grow in size, centralized heartbeat monitoring becomes a bottleneck. A single monitoring node responsible for tracking thousands of servers creates a single point of failure and does not scale well. This is where gossip protocols come into play.&lt;/p&gt;
    &lt;p&gt;Gossip protocols distribute the responsibility of failure detection across all nodes in the cluster. Instead of reporting to a central authority, each node periodically exchanges heartbeat information with a randomly selected subset of peers. Over time, information about the health of every node spreads throughout the entire cluster, much like gossip spreads in a social network.&lt;/p&gt;
    &lt;p&gt;The basic gossip algorithm: each node maintains a local membership list containing information about all known nodes in the cluster, including their heartbeat counters. Periodically, the node selects one or more random peers and exchanges its entire membership list with them. When receiving a membership list from a peer, the node merges it with its own list, keeping the most recent information for each node.&lt;/p&gt;
    &lt;code&gt;class GossipNode:  
    def __init__(self, node_id, peers):  
        self.node_id = node_id  
        self.peers = peers  
        self.membership_list = {}  
        self.heartbeat_counter = 0  
        
    def update_heartbeat(self):  
        self.heartbeat_counter += 1  
        self.membership_list[self.node_id] = {  
            'heartbeat': self.heartbeat_counter,  
            'timestamp': time.time()  
        }  
        
    def gossip_round(self):  
        # Update own heartbeat  
        self.update_heartbeat()  
        
        # Select random peers to gossip with  
        num_peers = min(3, len(self.peers))  
        selected_peers = random.sample(self.peers, num_peers)  
        
        # Send membership list to selected peers  
        for peer in selected_peers:  
            self._send_gossip(peer)  
            
    def _send_gossip(self, peer):  
        try:  
            response = requests.post(  
                f"http://{peer}/gossip",  
                json=self.membership_list  
            )  
            received_list = response.json()  
            self._merge_membership_list(received_list)  
        except Exception as e:  
            logging.error(f"Failed to gossip with {peer}: {e}")  
            
    def _merge_membership_list(self, received_list):  
        for node_id, info in received_list.items():  
            if node_id not in self.membership_list:  
                self.membership_list[node_id] = info  
            else:  
                # Keep the entry with the higher heartbeat counter  
                if info['heartbeat'] &amp;gt; self.membership_list[node_id]['heartbeat']:  
                    self.membership_list[node_id] = info  
                    
    def detect_failures(self, timeout_seconds):  
        failed_nodes = []  
        current_time = time.time()  
        
        for node_id, info in self.membership_list.items():  
            if node_id != self.node_id:  
                time_since_update = current_time - info['timestamp']  
                if time_since_update &amp;gt; timeout_seconds:  
                    failed_nodes.append(node_id)  
                    
        return failed_nodes  &lt;/code&gt;
    &lt;p&gt;The gossip protocol eliminates single points of failure since every node participates in failure detection. It scales well because the number of messages each node sends remains constant regardless of cluster size. It is also resilient to node failures since information continues to spread as long as some nodes remain connected.&lt;/p&gt;
    &lt;p&gt;However, gossip protocols also introduce complexity. Because information spreads gradually, there can be a delay before all nodes learn about a failure. This eventual consistency model means that different nodes might temporarily have different views of the cluster state. The protocol also generates more total network traffic since information is duplicated across many gossip exchanges, though this is usually acceptable since gossip messages are small.&lt;/p&gt;
    &lt;p&gt;Many production systems use gossip-based failure detection. Cassandra, for example, uses a gossip protocol where each node gossips with up to three other nodes every second. Nodes track both heartbeat generation numbers and version numbers to handle various failure scenarios. The protocol also includes mechanisms to handle network partitions and prevent split-brain scenarios.&lt;/p&gt;
    &lt;head rend="h2"&gt;Implementation Considerations&lt;/head&gt;
    &lt;p&gt;One important implementation consideration is the transport protocol.&lt;/p&gt;
    &lt;p&gt;Should heartbeats use TCP or UDP? TCP provides reliable delivery and guarantees that messages arrive in order, but it also introduces overhead and can be slower due to connection establishment and acknowledgment mechanisms.&lt;/p&gt;
    &lt;p&gt;UDP is faster and more lightweight, but packets can be lost or arrive out of order. Many systems use UDP for heartbeat messages because occasional packet loss is acceptable, the receiver can tolerate missing a few heartbeats without declaring a node dead.&lt;/p&gt;
    &lt;p&gt;However, TCP is often preferred when heartbeat messages carry critical state information that must not be lost.&lt;/p&gt;
    &lt;p&gt;Another consideration is network topology. In systems spanning multiple data centers, network latency and reliability vary significantly between different paths. A heartbeat between two nodes in the same data center might have a round-trip time of 1 millisecond, while a heartbeat crossing continents might take 100 milliseconds or more. Systems should account for these differences, potentially using different timeout values for local versus remote nodes.&lt;/p&gt;
    &lt;code&gt;class AdaptiveHeartbeatConfig:  
    def __init__(self):  
        self.configs = {}  
        
    def configure_for_node(self, node_id, location):  
        if location == 'local':  
            config = {  
                'interval': 1000,  # 1 second  
                'timeout': 3000,   # 3 seconds  
                'protocol': 'UDP'  
            }  
        elif location == 'same_datacenter':  
            config = {  
                'interval': 2000,  # 2 seconds  
                'timeout': 6000,   # 6 seconds  
                'protocol': 'UDP'  
            }  
        else:  # remote_datacenter  
            config = {  
                'interval': 5000,  # 5 seconds  
                'timeout': 15000,  # 15 seconds  
                'protocol': 'TCP'  
            }  
            
        self.configs[node_id] = config  
        return config  &lt;/code&gt;
    &lt;p&gt;Another important implementation consideration is to ensure that we do not have blocking operations in the heartbeat processing path. Heartbeat handlers should execute quickly and defer any expensive operations to separate worker threads.&lt;/p&gt;
    &lt;p&gt;Resource management is also critical. In a system with thousands of nodes, maintaining separate threads or timers for each node can exhaust system resources. We should prefer event-driven architectures or thread pools to efficiently manage concurrent heartbeat processing. Connection pooling would also reduce the overhead of establishing new connections for each heartbeat message.&lt;/p&gt;
    &lt;head rend="h2"&gt;Network Partitions and Split-brain&lt;/head&gt;
    &lt;p&gt;A network partition occurs when network connectivity is disrupted, splitting a cluster into two or more isolated groups. Nodes within each partition can communicate with each other but cannot reach nodes in other partitions.&lt;/p&gt;
    &lt;p&gt;During a partition, nodes on each side will stop receiving heartbeats from nodes on the other side. This creates an ambiguous situation where both sides might believe the other has failed. If not handled carefully, this can lead to split-brain scenarios where both sides continue operating independently, potentially leading to data inconsistency or resource conflicts.&lt;/p&gt;
    &lt;p&gt;Consider a database cluster with three nodes spread across two data centers. If the network connection between data centers fails, the nodes in each data center will form separate partitions. Without proper safeguards, both partitions might elect their own leader, accept writes, and diverge from each other.&lt;/p&gt;
    &lt;p&gt;To handle network partitions correctly, systems often use quorum-based approaches. A quorum is the minimum number of nodes that must agree before taking certain actions. For example, a cluster of five nodes might require a quorum of three nodes to elect a leader or accept writes.&lt;/p&gt;
    &lt;p&gt;During a partition, only the partition containing at least three nodes can continue operating normally. The minority partition recognizes it has lost quorum and stops accepting writes.&lt;/p&gt;
    &lt;code&gt;class QuorumBasedFailureHandler:  
    def __init__(self, total_nodes, quorum_size):  
        self.total_nodes = total_nodes  
        self.quorum_size = quorum_size  
        self.reachable_nodes = set()  
        
    def update_reachable_nodes(self, node_list):  
        self.reachable_nodes = set(node_list)  
        
    def has_quorum(self):  
        return len(self.reachable_nodes) &amp;gt;= self.quorum_size  
        
    def can_accept_writes(self):  
        return self.has_quorum()  
        
    def should_step_down_as_leader(self):  
        return not self.has_quorum()  &lt;/code&gt;
    &lt;head rend="h2"&gt;Real-world Applications&lt;/head&gt;
    &lt;p&gt;Each node in a Kubernetes cluster runs a kubelet agent that periodically sends node status updates to the API server. By default, kubelets send updates every 10 seconds. If the API server does not receive an update within 40 seconds, it marks the node as NotReady.&lt;/p&gt;
    &lt;p&gt;Kubernetes also implements liveness and readiness probes at the pod level. A liveness probe checks whether a container is running properly, and if the probe fails repeatedly, Kubernetes restarts the container. A readiness probe determines whether a container is ready to accept traffic, and failing readiness probes cause the pod to be removed from service endpoints.&lt;/p&gt;
    &lt;code&gt;apiVersion: v1  
kind: Pod  
metadata:  
  name: example-pod  
spec:  
  containers:  
  - name: app  
    image: myapp:latest  
    livenessProbe:  
      httpGet:  
        path: /healthz  
        port: 8080  
      initialDelaySeconds: 15  
      periodSeconds: 10  
      timeoutSeconds: 2  
      failureThreshold: 3  
    readinessProbe:  
      httpGet:  
        path: /ready  
        port: 8080  
      initialDelaySeconds: 5  
      periodSeconds: 5  
      timeoutSeconds: 2  &lt;/code&gt;
    &lt;p&gt;Cassandra, a distributed NoSQL database, uses gossip-based heartbeats to maintain cluster membership. Each Cassandra node gossip with up to three other random nodes every second. The gossip messages include heartbeat generation numbers that increment whenever a node restarts and heartbeat version numbers that increment with each gossip round.&lt;/p&gt;
    &lt;p&gt;Cassandra uses the phi accrual failure detector to determine when nodes are down. The default phi threshold is 8, meaning a node is considered down when the algorithm is about 99.9999% confident it has failed. This adaptive approach allows Cassandra to work reliably across diverse network environments.&lt;/p&gt;
    &lt;p&gt;etcd, a distributed key-value store used by Kubernetes, implements heartbeats as part of its Raft consensus protocol. The Raft leader sends heartbeat messages to followers every 100 milliseconds by default. If a follower does not receive a heartbeat within the election timeout (typically 1000 milliseconds), it initiates a new leader election.&lt;/p&gt;
    &lt;head rend="h2"&gt;Footnotes&lt;/head&gt;
    &lt;p&gt;Heartbeats are essential to distributed systems. From simple periodic messages to sophisticated adaptive algorithms, heartbeats enable systems to maintain awareness of component health and respond to failures quickly.&lt;/p&gt;
    &lt;p&gt;The key to effective heartbeat design lies in balancing competing concerns. Fast failure detection requires frequent heartbeats and aggressive timeouts, but this increases network overhead and sensitivity to transient issues. Slow detection reduces resource consumption and false positives but leaves the system vulnerable to longer outages.&lt;/p&gt;
    &lt;p&gt;As we design distributed systems, consider heartbeat mechanisms early in the architecture process. The choice of heartbeat intervals, timeout values, and failure detection algorithms significantly impacts system behavior under failure conditions.&lt;/p&gt;
    &lt;p&gt;No matter what we are building, heartbeats remain an essential tool for maintaining reliability.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45914815</guid><pubDate>Thu, 13 Nov 2025 13:43:50 +0000</pubDate></item><item><title>Denx (a.k.a. U-Boot) Retires</title><link>https://www.denx.de/</link><description>&lt;doc fingerprint="5e93d117b7b623e2"&gt;
  &lt;main&gt;
    &lt;p&gt;20 years successfully work and success&lt;/p&gt;
    &lt;head rend="h1"&gt;A well earned retirement&lt;/head&gt;
    &lt;p&gt;The company’s Open Source bootloader U-Boot is currently running on million of devices in the world. It is well-maintained and it will be maintained by a large number of contributors, in the spirit DENX supported it in many years.&lt;/p&gt;
    &lt;p&gt;After 20 successful years in the embedded world, the DENX holders decided to wind-down operations and retire. The decision was announced in July of 2025. As a result of this process, the company entered voluntarily liquidation. DENX holders thank all customers and nice people who contribute to the successful story of the company.&lt;/p&gt;
    &lt;head rend="h2"&gt;Still looking for great support ?&lt;/head&gt;
    &lt;p&gt;Former DENX’s engineers joined NABLA, a new company created to provide high level support and consulting around Open Source, U-Boot, Embedded Linux and Security with the same goals we had in DENX. You will find the same expertise and quality support you experienced in many years in DENX.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45915069</guid><pubDate>Thu, 13 Nov 2025 14:10:48 +0000</pubDate></item><item><title>Kratos - Cloud native Auth0 open-source alternative (self-hosted)</title><link>https://github.com/ory/kratos</link><description>&lt;doc fingerprint="afc9f24934b632ce"&gt;
  &lt;main&gt;
    &lt;head rend="h4"&gt;Chat · Discussions · Newsletter · Docs · Try Ory Network · Jobs&lt;/head&gt;
    &lt;head rend="h2"&gt;Ory Kratos is an API first identity and user management system for cloud native applications. It centralizes login, registration, recovery, verification, and profile management flows so your services consume them instead of reimplementing them.&lt;/head&gt;
    &lt;p&gt;Table of contents&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;What is Ory Kratos?&lt;/item&gt;
      &lt;item&gt;Deployment options&lt;/item&gt;
      &lt;item&gt;Quickstart&lt;/item&gt;
      &lt;item&gt;Features&lt;/item&gt;
      &lt;item&gt;Ecosystem&lt;/item&gt;
      &lt;item&gt;Who is using Ory Kratos&lt;/item&gt;
      &lt;item&gt;Documentation&lt;/item&gt;
      &lt;item&gt;Developing Ory Kratos&lt;/item&gt;
      &lt;item&gt;Security&lt;/item&gt;
      &lt;item&gt;Telemetry&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Ory Kratos is an API first identity and user management system that follows cloud architecture best practices. It focuses on core identity workflows that almost every application needs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Self service login and registration&lt;/item&gt;
      &lt;item&gt;Account verification and recovery&lt;/item&gt;
      &lt;item&gt;Multi factor authentication&lt;/item&gt;
      &lt;item&gt;Profile and account management&lt;/item&gt;
      &lt;item&gt;Identity schemas and traits&lt;/item&gt;
      &lt;item&gt;Admin APIs for lifecycle management&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We recommend starting with the Ory Kratos introduction docs to learn more about its architecture, feature set, and how it compares to other systems.&lt;/p&gt;
    &lt;p&gt;Ory Kratos is designed to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Remove identity logic from your application code and expose it over HTTP APIs&lt;/item&gt;
      &lt;item&gt;Work well with any UI framework through browser based and native app flows&lt;/item&gt;
      &lt;item&gt;Scale to large numbers of identities and devices&lt;/item&gt;
      &lt;item&gt;Integrate with the rest of the Ory stack for OAuth2, OpenID Connect, and access control&lt;/item&gt;
      &lt;item&gt;Fit into modern cloud native environments such as Kubernetes and managed platforms&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you are migrating from Auth0, Okta, or another identity provider that uses OAuth2 / OpenID Connect based login, consider using Ory Hydra + Ory Kratos together:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Ory Hydra acts as the OAuth2 and OpenID Connect provider and can replace most authorization server and token issuing capabilities of your existing IdP.&lt;/item&gt;
      &lt;item&gt;Ory Kratos provides identity, credentials, and user-facing flows (login, registration, recovery, verification, profile management).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This combination is often a drop-in replacement for OAuth2 and OpenID Connect capabilities at the protocol level. In practice, you update client configuration and endpoints to point to Hydra, migrate identities into Kratos, and keep your applications speaking the same OAuth2 / OIDC protocols they already use.&lt;/p&gt;
    &lt;p&gt;You can run Ory Kratos in two main ways:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;As a managed service on the Ory Network&lt;/item&gt;
      &lt;item&gt;As a self hosted service under your own control, with or without the Ory Enterprise License&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Ory Network is the fastest way to use Ory services in production. Ory Identities is powered by the open source Ory Kratos server and is API compatible.&lt;/p&gt;
    &lt;p&gt;The Ory Network provides:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Identity and credential management that scales to billions of users and devices&lt;/item&gt;
      &lt;item&gt;Registration, login, and account management flows for passkeys, biometrics, social login, SSO, and multi factor authentication&lt;/item&gt;
      &lt;item&gt;Prebuilt login, registration, and account management pages and components&lt;/item&gt;
      &lt;item&gt;OAuth2 and OpenID Connect for single sign on, API access, and machine to machine authorization&lt;/item&gt;
      &lt;item&gt;Low latency permission checks based on the Zanzibar model with the Ory Permission Language&lt;/item&gt;
      &lt;item&gt;GDPR friendly storage with data locality and compliance in mind&lt;/item&gt;
      &lt;item&gt;Web based Ory Console and Ory CLI for administration and operations&lt;/item&gt;
      &lt;item&gt;Cloud native APIs compatible with the open source servers&lt;/item&gt;
      &lt;item&gt;Fair, usage based pricing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Sign up for a free developer account to get started.&lt;/p&gt;
    &lt;p&gt;You can run Ory Kratos yourself for full control over infrastructure, deployment, and customization.&lt;/p&gt;
    &lt;p&gt;The install guide explains how to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Install Kratos on Linux, macOS, Windows, and Docker&lt;/item&gt;
      &lt;item&gt;Configure databases such as PostgreSQL, MySQL, and CockroachDB&lt;/item&gt;
      &lt;item&gt;Deploy to Kubernetes and other orchestration systems&lt;/item&gt;
      &lt;item&gt;Build Kratos from source&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This guide uses the open source distribution to get you started without license requirements. It is a great fit for individuals, researchers, hackers, and companies that want to experiment, prototype, or run unimportant workloads without SLAs. You get the full core engine, and you are free to inspect, extend, and build it from source.&lt;/p&gt;
    &lt;p&gt;If you run Kratos as part of a business-critical system, for example login and account recovery for all your users, you should use a commercial agreement to reduce operational and security risk. The Ory Enterprise License (OEL) layers on top of self-hosted Kratos and provides:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Additional enterprise features that are not available in the open source version such as SCIM, SAML, organization login ("SSO"), CAPTCHAs and more&lt;/item&gt;
      &lt;item&gt;Regular security releases, including CVE patches, with service level agreements&lt;/item&gt;
      &lt;item&gt;Support for advanced scaling, multi-tenancy, and complex deployments&lt;/item&gt;
      &lt;item&gt;Premium support options with SLAs, direct access to engineers, and onboarding help&lt;/item&gt;
      &lt;item&gt;Access to a private Docker registry with frequent and vetted, up-to-date enterprise builds&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For guaranteed CVE fixes, current enterprise builds, advanced features, and support in production, you need a valid Ory Enterprise License and access to the Ory Enterprise Docker registry. To learn more, contact the Ory team.&lt;/p&gt;
    &lt;p&gt;Install the Ory CLI and create a new project to try Ory Identities.&lt;/p&gt;
    &lt;code&gt;# Install the Ory CLI if you do not have it yet:
bash &amp;lt;(curl https://raw.githubusercontent.com/ory/meta/master/install.sh) -b . ory
sudo mv ./ory /usr/local/bin/

# Sign in or sign up
ory auth

# Create a new project
ory create project --create-workspace "Ory Open Source" --name "GitHub Quickstart"  --use-project
ory open ax login&lt;/code&gt;
    &lt;p&gt;The Ory community stands on the shoulders of individuals, companies, and maintainers. The Ory team thanks everyone involved - from submitting bug reports and feature requests, to contributing patches and documentation. The Ory community counts more than 50.000 members and is growing. The Ory stack protects 7.000.000.000+ API requests every day across thousands of companies. None of this would have been possible without each and everyone of you!&lt;/p&gt;
    &lt;p&gt;The following list represents companies that have accompanied us along the way and that have made outstanding contributions to our ecosystem. If you think that your company deserves a spot here, reach out to office@ory.sh now!&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Name&lt;/cell&gt;
        &lt;cell role="head"&gt;Logo&lt;/cell&gt;
        &lt;cell role="head"&gt;Website&lt;/cell&gt;
        &lt;cell role="head"&gt;Case Study&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;OpenAI&lt;/cell&gt;
        &lt;cell&gt;openai.com&lt;/cell&gt;
        &lt;cell&gt;OpenAI Case Study&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Fandom&lt;/cell&gt;
        &lt;cell&gt;fandom.com&lt;/cell&gt;
        &lt;cell&gt;Fandom Case Study&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Lumin&lt;/cell&gt;
        &lt;cell&gt;luminpdf.com&lt;/cell&gt;
        &lt;cell&gt;Lumin Case Study&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Sencrop&lt;/cell&gt;
        &lt;cell&gt;sencrop.com&lt;/cell&gt;
        &lt;cell&gt;Sencrop Case Study&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;OSINT Industries&lt;/cell&gt;
        &lt;cell&gt;osint.industries&lt;/cell&gt;
        &lt;cell&gt;OSINT Industries Case Study&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;HGV&lt;/cell&gt;
        &lt;cell&gt;hgv.it&lt;/cell&gt;
        &lt;cell&gt;HGV Case Study&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Maxroll&lt;/cell&gt;
        &lt;cell&gt;maxroll.gg&lt;/cell&gt;
        &lt;cell&gt;Maxroll Case Study&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Zezam&lt;/cell&gt;
        &lt;cell&gt;zezam.io&lt;/cell&gt;
        &lt;cell&gt;Zezam Case Study&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;T.RowePrice&lt;/cell&gt;
        &lt;cell&gt;troweprice.com&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Mistral&lt;/cell&gt;
        &lt;cell&gt;mistral.ai&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Axel Springer&lt;/cell&gt;
        &lt;cell&gt;axelspringer.com&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Hemnet&lt;/cell&gt;
        &lt;cell&gt;hemnet.se&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Cisco&lt;/cell&gt;
        &lt;cell&gt;cisco.com&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Presidencia de la República Dominicana&lt;/cell&gt;
        &lt;cell&gt;presidencia.gob.do&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Moonpig&lt;/cell&gt;
        &lt;cell&gt;moonpig.com&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Booster&lt;/cell&gt;
        &lt;cell&gt;choosebooster.com&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Zaptec&lt;/cell&gt;
        &lt;cell&gt;zaptec.com&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Klarna&lt;/cell&gt;
        &lt;cell&gt;klarna.com&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Raspberry PI Foundation&lt;/cell&gt;
        &lt;cell&gt;raspberrypi.org&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Tulip&lt;/cell&gt;
        &lt;cell&gt;tulip.com&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Hootsuite&lt;/cell&gt;
        &lt;cell&gt;hootsuite.com&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Segment&lt;/cell&gt;
        &lt;cell&gt;segment.com&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Arduino&lt;/cell&gt;
        &lt;cell&gt;arduino.cc&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Sainsbury's&lt;/cell&gt;
        &lt;cell&gt;sainsburys.co.uk&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Contraste&lt;/cell&gt;
        &lt;cell&gt;contraste.com&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;inMusic&lt;/cell&gt;
        &lt;cell&gt;inmusicbrands.com&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Buhta&lt;/cell&gt;
        &lt;cell&gt;buhta.com&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Amplitude&lt;/cell&gt;
        &lt;cell&gt;amplitude.com&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Many thanks to all individual contributors&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45915114</guid><pubDate>Thu, 13 Nov 2025 14:14:36 +0000</pubDate></item><item><title>Google Posts Device Trees for Booting Pixel 10 with Mainline Linux Kernel</title><link>https://www.phoronix.com/news/Google-Pixel-10-Google-DTs</link><description>&lt;doc fingerprint="5b2a2604993c3be8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Google Posts Device Trees For Booting Pixel 10 Hardware With The Mainline Linux Kernel&lt;/head&gt;
    &lt;p&gt; A Chromium engineer at Google posted the initial Device Tree (DT) files for being able to boot their latest-generation Pixel 10, Pixel 10 Pro, and Pixel 10 Pro XL devices with the mainline Linux kernel. &lt;lb/&gt;Google announced their Pixel 10 devices back in August as their newest devices for Android 16 use and featuring the Google Tensor G5 SoC powered by a combination of Arm Cortex X4, A725, and A520 cores while relying on Imagination DXT-48-1536 graphics. Outside the confines of Google's Android, out today is the initial Device Trees for being able to boo the Google Pixel 10 / Pixel 10 Pro / Pixel 10 Pro XL devices with these patches proposed for the mainline Linux kernel.&lt;lb/&gt;But it's important to stress that these are very preliminary patches and do not yield a full-featured smartphone. Beyond that, the booting the mainline Linux kernel relies on a "yet-unreleased bootloader". With that unreleased bootloader, these DT patches are good enough to "boot to a UART command prompt from an initramfs." Far from being really useful to end-users.&lt;lb/&gt;Those interested can find the DT patches for the Google Pixel 10 devices via this LKML thread.&lt;/p&gt;
    &lt;p&gt;Google announced their Pixel 10 devices back in August as their newest devices for Android 16 use and featuring the Google Tensor G5 SoC powered by a combination of Arm Cortex X4, A725, and A520 cores while relying on Imagination DXT-48-1536 graphics. Outside the confines of Google's Android, out today is the initial Device Trees for being able to boo the Google Pixel 10 / Pixel 10 Pro / Pixel 10 Pro XL devices with these patches proposed for the mainline Linux kernel.&lt;/p&gt;
    &lt;p&gt;But it's important to stress that these are very preliminary patches and do not yield a full-featured smartphone. Beyond that, the booting the mainline Linux kernel relies on a "yet-unreleased bootloader". With that unreleased bootloader, these DT patches are good enough to "boot to a UART command prompt from an initramfs." Far from being really useful to end-users.&lt;/p&gt;
    &lt;quote&gt;"This series adds barebones device trees for Pixel 10 (frankel), Pixel 10 Pro (blazer), and Pixel 10 Pro XL (mustang). With a yet-unreleased bootloader these can boot to a UART command prompt from an initramfs.&lt;lb/&gt;The end result of the device trees introduced in this series is really pretty simple, so it's expected that most of the discussion in the series will be about compatible strings, file organization, dts/dtso organization, etc."&lt;/quote&gt;
    &lt;p&gt;Those interested can find the DT patches for the Google Pixel 10 devices via this LKML thread.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45915380</guid><pubDate>Thu, 13 Nov 2025 14:37:54 +0000</pubDate></item><item><title>No Competition? That's Usually a Red Flag for Solopreneurs</title><link>https://meysam.io/blog/no-competition-red-flag-solopreneur-validated-market/</link><description>&lt;doc fingerprint="fd64d09e2ed2461d"&gt;
  &lt;main&gt;
    &lt;p&gt;If you only remember three things from this post:&lt;/p&gt;
    &lt;p&gt;1. Competition = Validation If nobody’s doing it, ask “why” before assuming you found a gap. Most gaps exist because there’s no demand or prohibitive barriers.&lt;/p&gt;
    &lt;p&gt;2. Talk to Customers Before Building 10+ interviews minimum. Ask about their past behavior, not hypothetical future. “Would you use this?” is a worthless question.&lt;/p&gt;
    &lt;p&gt;3. Distribution First Build audience through free value (tools, content, templates). Trust compounds. Then sell to people who already know and like you.&lt;/p&gt;
    &lt;p&gt;I’m documenting this entire journey in public. Every lesson, every mistake, every breakthrough.&lt;/p&gt;
    &lt;p&gt;Pick your platform:&lt;/p&gt;
    &lt;p&gt;No fluff. No overnight success stories. Just raw documentation from the trenches.&lt;/p&gt;
    &lt;p&gt;What’s your take? Am I wrong about the “no competition” trap? Have you succeeded in a blue ocean as a solopreneur? Reply and let me know—I read every message.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45915674</guid><pubDate>Thu, 13 Nov 2025 15:00:03 +0000</pubDate></item><item><title>GitHub Partial Outage</title><link>https://www.githubstatus.com/incidents/1jw8ltnr1qrj</link><description>&lt;doc fingerprint="d4e418d2975068af"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt; Subscribe to updates for &lt;strong&gt;Some users may experience failing git push and pull operations.&lt;/strong&gt; via email and/or text message. You'll receive email notifications when incidents are updated, and text message notifications whenever GitHub &lt;strong&gt;creates&lt;/strong&gt; or &lt;strong&gt;resolves&lt;/strong&gt; an incident. &lt;/p&gt;
      &lt;div&gt;
        &lt;label&gt;VIA SMS:&lt;/label&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;
              &lt;select&gt;
                &lt;option&gt;Afghanistan (+93)&lt;/option&gt;
                &lt;option&gt;Albania (+355)&lt;/option&gt;
                &lt;option&gt;Algeria (+213)&lt;/option&gt;
                &lt;option&gt;American Samoa (+1)&lt;/option&gt;
                &lt;option&gt;Andorra (+376)&lt;/option&gt;
                &lt;option&gt;Angola (+244)&lt;/option&gt;
                &lt;option&gt;Anguilla (+1)&lt;/option&gt;
                &lt;option&gt;Antigua and Barbuda (+1)&lt;/option&gt;
                &lt;option&gt;Argentina (+54)&lt;/option&gt;
                &lt;option&gt;Armenia (+374)&lt;/option&gt;
                &lt;option&gt;Aruba (+297)&lt;/option&gt;
                &lt;option&gt;Australia/Cocos/Christmas Island (+61)&lt;/option&gt;
                &lt;option&gt;Austria (+43)&lt;/option&gt;
                &lt;option&gt;Azerbaijan (+994)&lt;/option&gt;
                &lt;option&gt;Bahamas (+1)&lt;/option&gt;
                &lt;option&gt;Bahrain (+973)&lt;/option&gt;
                &lt;option&gt;Bangladesh (+880)&lt;/option&gt;
                &lt;option&gt;Barbados (+1)&lt;/option&gt;
                &lt;option&gt;Belarus (+375)&lt;/option&gt;
                &lt;option&gt;Belgium (+32)&lt;/option&gt;
                &lt;option&gt;Belize (+501)&lt;/option&gt;
                &lt;option&gt;Benin (+229)&lt;/option&gt;
                &lt;option&gt;Bermuda (+1)&lt;/option&gt;
                &lt;option&gt;Bolivia (+591)&lt;/option&gt;
                &lt;option&gt;Bosnia and Herzegovina (+387)&lt;/option&gt;
                &lt;option&gt;Botswana (+267)&lt;/option&gt;
                &lt;option&gt;Brazil (+55)&lt;/option&gt;
                &lt;option&gt;Brunei (+673)&lt;/option&gt;
                &lt;option&gt;Bulgaria (+359)&lt;/option&gt;
                &lt;option&gt;Burkina Faso (+226)&lt;/option&gt;
                &lt;option&gt;Burundi (+257)&lt;/option&gt;
                &lt;option&gt;Cambodia (+855)&lt;/option&gt;
                &lt;option&gt;Cameroon (+237)&lt;/option&gt;
                &lt;option&gt;Canada (+1)&lt;/option&gt;
                &lt;option&gt;Cape Verde (+238)&lt;/option&gt;
                &lt;option&gt;Cayman Islands (+1)&lt;/option&gt;
                &lt;option&gt;Central Africa (+236)&lt;/option&gt;
                &lt;option&gt;Chad (+235)&lt;/option&gt;
                &lt;option&gt;Chile (+56)&lt;/option&gt;
                &lt;option&gt;China (+86)&lt;/option&gt;
                &lt;option&gt;Colombia (+57)&lt;/option&gt;
                &lt;option&gt;Comoros (+269)&lt;/option&gt;
                &lt;option&gt;Congo (+242)&lt;/option&gt;
                &lt;option&gt;Congo, Dem Rep (+243)&lt;/option&gt;
                &lt;option&gt;Costa Rica (+506)&lt;/option&gt;
                &lt;option&gt;Croatia (+385)&lt;/option&gt;
                &lt;option&gt;Cyprus (+357)&lt;/option&gt;
                &lt;option&gt;Czech Republic (+420)&lt;/option&gt;
                &lt;option&gt;Denmark (+45)&lt;/option&gt;
                &lt;option&gt;Djibouti (+253)&lt;/option&gt;
                &lt;option&gt;Dominica (+1)&lt;/option&gt;
                &lt;option&gt;Dominican Republic (+1)&lt;/option&gt;
                &lt;option&gt;Egypt (+20)&lt;/option&gt;
                &lt;option&gt;El Salvador (+503)&lt;/option&gt;
                &lt;option&gt;Equatorial Guinea (+240)&lt;/option&gt;
                &lt;option&gt;Estonia (+372)&lt;/option&gt;
                &lt;option&gt;Ethiopia (+251)&lt;/option&gt;
                &lt;option&gt;Faroe Islands (+298)&lt;/option&gt;
                &lt;option&gt;Fiji (+679)&lt;/option&gt;
                &lt;option&gt;Finland/Aland Islands (+358)&lt;/option&gt;
                &lt;option&gt;France (+33)&lt;/option&gt;
                &lt;option&gt;French Guiana (+594)&lt;/option&gt;
                &lt;option&gt;French Polynesia (+689)&lt;/option&gt;
                &lt;option&gt;Gabon (+241)&lt;/option&gt;
                &lt;option&gt;Gambia (+220)&lt;/option&gt;
                &lt;option&gt;Georgia (+995)&lt;/option&gt;
                &lt;option&gt;Germany (+49)&lt;/option&gt;
                &lt;option&gt;Ghana (+233)&lt;/option&gt;
                &lt;option&gt;Gibraltar (+350)&lt;/option&gt;
                &lt;option&gt;Greece (+30)&lt;/option&gt;
                &lt;option&gt;Greenland (+299)&lt;/option&gt;
                &lt;option&gt;Grenada (+1)&lt;/option&gt;
                &lt;option&gt;Guadeloupe (+590)&lt;/option&gt;
                &lt;option&gt;Guam (+1)&lt;/option&gt;
                &lt;option&gt;Guatemala (+502)&lt;/option&gt;
                &lt;option&gt;Guinea (+224)&lt;/option&gt;
                &lt;option&gt;Guyana (+592)&lt;/option&gt;
                &lt;option&gt;Haiti (+509)&lt;/option&gt;
                &lt;option&gt;Honduras (+504)&lt;/option&gt;
                &lt;option&gt;Hong Kong (+852)&lt;/option&gt;
                &lt;option&gt;Hungary (+36)&lt;/option&gt;
                &lt;option&gt;Iceland (+354)&lt;/option&gt;
                &lt;option&gt;India (+91)&lt;/option&gt;
                &lt;option&gt;Indonesia (+62)&lt;/option&gt;
                &lt;option&gt;Iraq (+964)&lt;/option&gt;
                &lt;option&gt;Ireland (+353)&lt;/option&gt;
                &lt;option&gt;Israel (+972)&lt;/option&gt;
                &lt;option&gt;Italy (+39)&lt;/option&gt;
                &lt;option&gt;Jamaica (+1)&lt;/option&gt;
                &lt;option&gt;Japan (+81)&lt;/option&gt;
                &lt;option&gt;Jordan (+962)&lt;/option&gt;
                &lt;option&gt;Kenya (+254)&lt;/option&gt;
                &lt;option&gt;Korea, Republic of (+82)&lt;/option&gt;
                &lt;option&gt;Kosovo (+383)&lt;/option&gt;
                &lt;option&gt;Kuwait (+965)&lt;/option&gt;
                &lt;option&gt;Kyrgyzstan (+996)&lt;/option&gt;
                &lt;option&gt;Laos (+856)&lt;/option&gt;
                &lt;option&gt;Latvia (+371)&lt;/option&gt;
                &lt;option&gt;Lebanon (+961)&lt;/option&gt;
                &lt;option&gt;Lesotho (+266)&lt;/option&gt;
                &lt;option&gt;Liberia (+231)&lt;/option&gt;
                &lt;option&gt;Libya (+218)&lt;/option&gt;
                &lt;option&gt;Liechtenstein (+423)&lt;/option&gt;
                &lt;option&gt;Lithuania (+370)&lt;/option&gt;
                &lt;option&gt;Luxembourg (+352)&lt;/option&gt;
                &lt;option&gt;Macao (+853)&lt;/option&gt;
                &lt;option&gt;Macedonia (+389)&lt;/option&gt;
                &lt;option&gt;Madagascar (+261)&lt;/option&gt;
                &lt;option&gt;Malawi (+265)&lt;/option&gt;
                &lt;option&gt;Malaysia (+60)&lt;/option&gt;
                &lt;option&gt;Maldives (+960)&lt;/option&gt;
                &lt;option&gt;Mali (+223)&lt;/option&gt;
                &lt;option&gt;Malta (+356)&lt;/option&gt;
                &lt;option&gt;Martinique (+596)&lt;/option&gt;
                &lt;option&gt;Mauritania (+222)&lt;/option&gt;
                &lt;option&gt;Mauritius (+230)&lt;/option&gt;
                &lt;option&gt;Mexico (+52)&lt;/option&gt;
                &lt;option&gt;Monaco (+377)&lt;/option&gt;
                &lt;option&gt;Mongolia (+976)&lt;/option&gt;
                &lt;option&gt;Montenegro (+382)&lt;/option&gt;
                &lt;option&gt;Montserrat (+1)&lt;/option&gt;
                &lt;option&gt;Morocco/Western Sahara (+212)&lt;/option&gt;
                &lt;option&gt;Mozambique (+258)&lt;/option&gt;
                &lt;option&gt;Namibia (+264)&lt;/option&gt;
                &lt;option&gt;Nepal (+977)&lt;/option&gt;
                &lt;option&gt;Netherlands (+31)&lt;/option&gt;
                &lt;option&gt;New Zealand (+64)&lt;/option&gt;
                &lt;option&gt;Nicaragua (+505)&lt;/option&gt;
                &lt;option&gt;Niger (+227)&lt;/option&gt;
                &lt;option&gt;Nigeria (+234)&lt;/option&gt;
                &lt;option&gt;Norway (+47)&lt;/option&gt;
                &lt;option&gt;Oman (+968)&lt;/option&gt;
                &lt;option&gt;Pakistan (+92)&lt;/option&gt;
                &lt;option&gt;Palestinian Territory (+970)&lt;/option&gt;
                &lt;option&gt;Panama (+507)&lt;/option&gt;
                &lt;option&gt;Paraguay (+595)&lt;/option&gt;
                &lt;option&gt;Peru (+51)&lt;/option&gt;
                &lt;option&gt;Philippines (+63)&lt;/option&gt;
                &lt;option&gt;Poland (+48)&lt;/option&gt;
                &lt;option&gt;Portugal (+351)&lt;/option&gt;
                &lt;option&gt;Puerto Rico (+1)&lt;/option&gt;
                &lt;option&gt;Qatar (+974)&lt;/option&gt;
                &lt;option&gt;Reunion/Mayotte (+262)&lt;/option&gt;
                &lt;option&gt;Romania (+40)&lt;/option&gt;
                &lt;option&gt;Russia/Kazakhstan (+7)&lt;/option&gt;
                &lt;option&gt;Rwanda (+250)&lt;/option&gt;
                &lt;option&gt;Samoa (+685)&lt;/option&gt;
                &lt;option&gt;San Marino (+378)&lt;/option&gt;
                &lt;option&gt;Saudi Arabia (+966)&lt;/option&gt;
                &lt;option&gt;Senegal (+221)&lt;/option&gt;
                &lt;option&gt;Serbia (+381)&lt;/option&gt;
                &lt;option&gt;Seychelles (+248)&lt;/option&gt;
                &lt;option&gt;Sierra Leone (+232)&lt;/option&gt;
                &lt;option&gt;Singapore (+65)&lt;/option&gt;
                &lt;option&gt;Slovakia (+421)&lt;/option&gt;
                &lt;option&gt;Slovenia (+386)&lt;/option&gt;
                &lt;option&gt;South Africa (+27)&lt;/option&gt;
                &lt;option&gt;Spain (+34)&lt;/option&gt;
                &lt;option&gt;Sri Lanka (+94)&lt;/option&gt;
                &lt;option&gt;St Kitts and Nevis (+1)&lt;/option&gt;
                &lt;option&gt;St Lucia (+1)&lt;/option&gt;
                &lt;option&gt;St Vincent Grenadines (+1)&lt;/option&gt;
                &lt;option&gt;Sudan (+249)&lt;/option&gt;
                &lt;option&gt;Suriname (+597)&lt;/option&gt;
                &lt;option&gt;Swaziland (+268)&lt;/option&gt;
                &lt;option&gt;Sweden (+46)&lt;/option&gt;
                &lt;option&gt;Switzerland (+41)&lt;/option&gt;
                &lt;option&gt;Taiwan (+886)&lt;/option&gt;
                &lt;option&gt;Tajikistan (+992)&lt;/option&gt;
                &lt;option&gt;Tanzania (+255)&lt;/option&gt;
                &lt;option&gt;Thailand (+66)&lt;/option&gt;
                &lt;option&gt;Togo (+228)&lt;/option&gt;
                &lt;option&gt;Tonga (+676)&lt;/option&gt;
                &lt;option&gt;Trinidad and Tobago (+1)&lt;/option&gt;
                &lt;option&gt;Tunisia (+216)&lt;/option&gt;
                &lt;option&gt;Turkey (+90)&lt;/option&gt;
                &lt;option&gt;Turks and Caicos Islands (+1)&lt;/option&gt;
                &lt;option&gt;Uganda (+256)&lt;/option&gt;
                &lt;option&gt;Ukraine (+380)&lt;/option&gt;
                &lt;option&gt;United Arab Emirates (+971)&lt;/option&gt;
                &lt;option&gt;United Kingdom (+44)&lt;/option&gt;
                &lt;option&gt;United States (+1)&lt;/option&gt;
                &lt;option&gt;Uruguay (+598)&lt;/option&gt;
                &lt;option&gt;Uzbekistan (+998)&lt;/option&gt;
                &lt;option&gt;Venezuela (+58)&lt;/option&gt;
                &lt;option&gt;Vietnam (+84)&lt;/option&gt;
                &lt;option&gt;Virgin Islands, British (+1)&lt;/option&gt;
                &lt;option&gt;Virgin Islands, U.S. (+1)&lt;/option&gt;
                &lt;option&gt;Yemen (+967)&lt;/option&gt;
                &lt;option&gt;Zambia (+260)&lt;/option&gt;
                &lt;option&gt;Zimbabwe (+263)&lt;/option&gt;
              &lt;/select&gt;
            &lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
        &lt;label&gt;Enter mobile number&lt;/label&gt;
        &lt;div&gt;
          &lt;label&gt;Enter the OTP sent&lt;/label&gt;
          &lt;div&gt;
            &lt;p&gt;To receive SMS updates, please verify your number. To proceed with just email click ‘Subscribe’ &lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45915731</guid><pubDate>Thu, 13 Nov 2025 15:04:39 +0000</pubDate></item><item><title>We cut our Mongo DB costs by 90% by moving to Hetzner</title><link>https://prosopo.io/blog/we-cut-our-mongodb-costs-by-90-percent/</link><description>&lt;doc fingerprint="a5c1eddca4280bc3"&gt;
  &lt;main&gt;
    &lt;p&gt;Running databases in the cloud can be convenient, but it can also get expensive fast. For the Prosopo team, MongoDB Atlas was initially a fast, reliable way to run a cloud database, but as our data grew, so did the bills. Over the last year, we realised that we were spending thousands of dollars per month on infrastructure that we could run more efficiently ourselves. We explored various options but ultimately decided to migrate our MongoDB deployment to Hetzner, a cost-effective cloud provider.&lt;/p&gt;
    &lt;p&gt;Here's how we managed to cut our costs by 90% without sacrificing performance or reliability.&lt;/p&gt;
    &lt;p&gt;When we first started building, MongoDB Atlas was an easy choice. Everything was set up for us, and we could focus on building our application without worrying about database management. The free tier was sufficient for our initial needs, and as we grew, scaling up was as simple as a few clicks. However, scaling came with a steep price tag. We went from paying $0 per month for a small database to over $3,000 per month for a few hundred GBs of data. The cost breakdown before we migrated looked roughly like this:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Service&lt;/cell&gt;
        &lt;cell role="head"&gt;Monthly Cost&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Atlas M40 Instance - AWS&lt;/cell&gt;
        &lt;cell&gt;$1000&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Atlas Continuous Cloud Backup Storage&lt;/cell&gt;
        &lt;cell&gt;$700&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Atlas AWS Data Transfer (Same Region)&lt;/cell&gt;
        &lt;cell&gt;$10&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Atlas AWS Data Transfer (Different Region)&lt;/cell&gt;
        &lt;cell&gt;$1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Atlas AWS Data Transfer (Internet)&lt;/cell&gt;
        &lt;cell&gt;$1,000&lt;/cell&gt;
        &lt;cell&gt;â&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Total + VAT&lt;/cell&gt;
        &lt;cell&gt;$3000+&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The more keen eyed among you will have noticed the huge cost associated with data transfer over the internet - its as much as the servers! We're building Prosopo to be resilient to outages, such as the recent massive AWS outage, so we use many different cloud providers. This means that a lot of our database traffic goes over the internet, which is very expensive on MongoDB Atlas, due to it running on AWS (other options are available, but we chose AWS).&lt;/p&gt;
    &lt;p&gt;When your entire stack is on AWS, data transfer costs are minimal, as shown by the "Same Region" line item above. However, this architecture creates centralisation and single points of failure, which we want to avoid.&lt;/p&gt;
    &lt;p&gt;Oh, and even though we were paying this much, we didn't have access to any support! That's a separate paid plan.&lt;/p&gt;
    &lt;p&gt;Hetzner offered a compelling alternative:&lt;/p&gt;
    &lt;p&gt;We decided that the only way to regain control over our costs was to move to a self-hosted solution. MongoDB Atlas was running in replica set mode but we opted to instead set up a much beefier machine with a huge amount of RAM (256GB) and fast SSDs to handle our workload. In future, if we want to move back to a distributed setup, we can always add more nodes.&lt;/p&gt;
    &lt;p&gt;The server in question costs $160 per month, which is a huge saving over our previous costs.&lt;/p&gt;
    &lt;p&gt;Our Atlas instance held about 500GB of data but the product doesn't rely on this data in real-time - its used for generating detection rules using ML modelling, and the rules are applied to our CAPTCHA providers in a follow-up step. The reason for this architecture stems from our blockchain beginnings.&lt;/p&gt;
    &lt;p&gt;We were able to take a mongodump of the database, restore it to the new Hetzner server, and then use scripts to sync any changes that happened during the migration window.&lt;/p&gt;
    &lt;p&gt;Setting up our Hetzner server wasn't just a matter of spinning up MongoDB. We run Proxmox on the host machine, created an Ubuntu VM, and deployed MongoDB in Docker. Networking added another layer of complexity: the VM sits on a private subnet (10.0.0.x) with the host handling DHCP, NAT, and port forwarding. We also use Traefik as a reverse proxy to handle SSL and route traffic from the outside world to MongoDB, which saves us from wrestling with MongoDB's own SSL certificates. While this setup gives us flexibility and security, it does require a bit more technical know-how compared to fully managed solutions.&lt;/p&gt;
    &lt;p&gt;When you migrate from MongoAtlas to a self-hosted solution, you're taking on more responsibility for managing your database. You need to make sure it is secure, backed up, monitored, and can be recreated in case of failure or the need for extra servers arises. We used the following tools:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Tool&lt;/cell&gt;
        &lt;cell role="head"&gt;Purpose&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Ansible&lt;/cell&gt;
        &lt;cell&gt;Automated server provisioning&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Docker&lt;/cell&gt;
        &lt;cell&gt;Running MongoDB in a container&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;mongodump&lt;/cell&gt;
        &lt;cell&gt;Backup CLI tool&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;OpenObserve&lt;/cell&gt;
        &lt;cell&gt;Log aggregation and alerting&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;UFW&lt;/cell&gt;
        &lt;cell&gt;Firewall management&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;WireGuard&lt;/cell&gt;
        &lt;cell&gt;Secure connections over VPN&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The monitoring in MongoDB Atlas was very useful. It highlighted times when we were opening up unlimited connections due to connection leaks in our application code. However, MongoDB Atlas wouldn't let us kill the connections using admin shell commands! This meant we reached our connection limit and we had no way to restart the server. We had to kill our services to free up connections. With our own server, we can now monitor and manage connections directly via OpenObserve and, crucially, the MongoDB shell.&lt;/p&gt;
    &lt;p&gt;Backups in MongoDB Atlas were also convenient but expensive. We now use &lt;code&gt;mongodump&lt;/code&gt;, a cron, and a storage box from Hetzner to take daily backups of our database. The backups are compressed and encrypted before being sent to the remote storage box.&lt;/p&gt;
    &lt;p&gt;We've opted for a DIY approach to our servers and databases, which has significantly reduced our costs whilst giving us more control over our infrastructure. However, this approach isn't for everyone. We're still a small team, and managing the limited number of servers we run is feasible.&lt;/p&gt;
    &lt;p&gt;The performance we're seeing from our new standalone MongoDB server is very much improved over the Atlas setup. This is simply because the specs are so much higher and the indexes can mostly be held in memory. We are aware that MongoDB Atlas has something called vector search but we weren't using it, so it wasn't a factor in our decision.&lt;/p&gt;
    &lt;p&gt;For reference, the specs look like this:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Specification&lt;/cell&gt;
        &lt;cell role="head"&gt;Atlas M40 Instance&lt;/cell&gt;
        &lt;cell role="head"&gt;Hetzner Dedicated Server&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;CPU&lt;/cell&gt;
        &lt;cell&gt;8 vCPU&lt;/cell&gt;
        &lt;cell&gt;8 cores Intel Xeon W-2145&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;RAM&lt;/cell&gt;
        &lt;cell&gt;16 GB&lt;/cell&gt;
        &lt;cell&gt;256 GB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Storage&lt;/cell&gt;
        &lt;cell&gt;380 GB SSD&lt;/cell&gt;
        &lt;cell&gt;4 x 1 TB NVMe SSD RAID1&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Its more than likely that as we grow, we'll start to see value in hosted solutions again, but for now we're quite pleased with the new setup. Hopefully this experience helps to inform others starting out on their cloud journey - for a small amount of pain you can save a lot of money!&lt;/p&gt;
    &lt;p&gt;Wed, 13 Mar 2024&lt;/p&gt;
    &lt;p&gt;Mon, 08 Apr 2024&lt;/p&gt;
    &lt;p&gt;Thu, 18 Apr 2024&lt;/p&gt;
    &lt;p&gt;Mon, 22 Apr 2024&lt;/p&gt;
    &lt;p&gt;Tue, 18 Jun 2024&lt;/p&gt;
    &lt;p&gt;Wed, 26 Jun 2024&lt;/p&gt;
    &lt;p&gt;Tue, 30 Jul 2024&lt;/p&gt;
    &lt;p&gt;Fri, 25 Apr 2025&lt;/p&gt;
    &lt;p&gt;Thu, 01 May 2025&lt;/p&gt;
    &lt;p&gt;Fri, 02 May 2025&lt;/p&gt;
    &lt;p&gt;Sat, 03 May 2025&lt;/p&gt;
    &lt;p&gt;Tue, 06 May 2025&lt;/p&gt;
    &lt;p&gt;Mon, 19 May 2025&lt;/p&gt;
    &lt;p&gt;Mon, 19 May 2025&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45915884</guid><pubDate>Thu, 13 Nov 2025 15:17:57 +0000</pubDate></item><item><title>SIMA 2: An Agent That Plays, Reasons, and Learns with You in Virtual 3D Worlds</title><link>https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/</link><description>&lt;doc fingerprint="3d7fc31bcda3b669"&gt;
  &lt;main&gt;
    &lt;p&gt;Last year, we introduced SIMA (Scalable Instructable Multiworld Agent), a generalist AI that could follow basic instructions across a wide range of virtual environments. SIMA was a crucial first step in teaching AI to translate language into meaningful action in rich, 3D worlds.&lt;/p&gt;
    &lt;p&gt;Today we’re introducing SIMA 2, the next milestone in our research creating general and helpful AI agents. By integrating the advanced capabilities of our Gemini models, SIMA is evolving from an instruction-follower into an interactive gaming companion. Not only can SIMA 2 follow human-language instructions in virtual worlds, it can now also think about its goals, converse with users, and improve itself over time.&lt;/p&gt;
    &lt;p&gt;This is a significant step in the direction of Artificial General Intelligence (AGI), with important implications for the future of robotics and AI-embodiment in general.&lt;/p&gt;
    &lt;p&gt;The first version of SIMA learned to perform over 600 language-following skills, like “turn left,” “climb the ladder,” and “open the map,” across a diverse set of commercial video games. It operated in these environments as a person might, by “looking” at the screen and using a virtual keyboard and mouse to navigate, without access to the underlying game mechanics.&lt;/p&gt;
    &lt;p&gt;With SIMA 2, we’ve moved beyond instruction-following. By embedding a Gemini model as the agent's core, SIMA 2 can do more than just respond to instructions, it can think and reason about them.&lt;/p&gt;
    &lt;p&gt;SIMA 2’s new architecture integrates Gemini’s powerful reasoning abilities to help it understand a user’s high-level goal, perform complex reasoning in pursuit, and skillfully execute goal-oriented actions within games.&lt;/p&gt;
    &lt;p&gt;We trained SIMA 2 using a mixture of human demonstration videos with language labels as well as Gemini-generated labels. As a result, SIMA 2 can now describe to the user what it intends to do and detail the steps it's taking to accomplish its goals.&lt;/p&gt;
    &lt;p&gt;In testing, we have found that interacting with the agent feels less like giving it commands and more like collaborating with a companion who can reason about the task at hand.&lt;/p&gt;
    &lt;p&gt;And thanks to our collaboration with our existing and new game partners (see, Acknowledgements), we have been able to train and evaluate SIMA 2 on a wider array of games.&lt;/p&gt;
    &lt;p&gt;This is the power of Gemini brought to embodied AI: a world-class reasoning engine that can now perceive, understand, and take action in complex, interactive 3D environments.&lt;/p&gt;
    &lt;p&gt;The addition of Gemini has also led to improved generalization and reliability. SIMA 2 can now understand more complex and nuanced instructions than its predecessor and is far more successful at carrying them out, particularly in situations or games on which it’s never been trained, such as the new Viking survival game, ASKA, or MineDojo - a research implementation of the popular open-world sandbox game, Minecraft.&lt;/p&gt;
    &lt;p&gt;Moreover, its capacity to transfer learned concepts — for instance, taking its understanding of "mining" in one game and applying it to "harvesting" in another —is foundational to achieving the kind of broad generalization seen in human cognition. Indeed, as a result of this ability, SIMA 2’s performance is significantly closer to that of a human player on a wide range of tasks.&lt;/p&gt;
    &lt;p&gt;To test the limits of SIMA 2’s generalization abilities, we combined it with another groundbreaking research project, Genie 3, which can generate new, real-time 3D simulated worlds from a single image or text prompt.&lt;/p&gt;
    &lt;p&gt;When we challenged SIMA 2 to play in these newly generated worlds, we found it was able to sensibly orient itself, understand user instructions, and take meaningful actions toward goals, despite never having seen such environments before. It demonstrated an unprecedented level of adaptability.&lt;/p&gt;
    &lt;p&gt;One of SIMA 2’s most exciting new capabilities is its capacity for self-improvement. We’ve observed that, throughout the course of training, SIMA 2 agents can perform increasingly complex and new tasks, bootstrapped by trial-and-error and Gemini-based feedback.&lt;/p&gt;
    &lt;p&gt;For example, after initially learning from human demonstrations, SIMA 2 can transition to learning in new games exclusively through self-directed play, developing its skills in previously unseen worlds without additional human-generated data. In subsequent training, SIMA 2’s own experience data can then be used to train the next, even more capable version of the agent. We were even able to leverage SIMA 2’s capacity for self-improvement in newly created Genie environments – a major milestone toward training general agents across diverse, generated worlds.&lt;/p&gt;
    &lt;p&gt;This virtuous cycle of iterative improvement paves the way for a future where agents can learn and grow with minimal human intervention, becoming open-ended learners in embodied AI.&lt;/p&gt;
    &lt;p&gt;SIMA 2’s ability to operate across diverse gaming environments is a crucial proving ground for general intelligence, allowing agents to master skills, practice complex reasoning, and learn continuously through self-directed play.&lt;/p&gt;
    &lt;p&gt;While SIMA 2 is a significant step toward generalist, interactive, embodied intelligence, it is fundamentally a research endeavor, and its current limitations highlight critical areas for future work. We find the agents still face challenges with very long-horizon, complex tasks that require extensive, multi-step reasoning and goal verification. SIMA 2 also has a relatively short memory of its interactions - it must use a limited context window to achieve low-latency interaction. Finally, executing precise, low-level actions via the keyboard and mouse interface and achieving robust visual understanding of the complex 3D scenes remain open challenges that the entire field continues to address.&lt;/p&gt;
    &lt;p&gt;This research provides a fundamental validation for a new path in action-oriented AI. SIMA 2 confirms that an AI trained for broad competency, leveraging diverse multi-world data and the powerful reasoning of Gemini, can successfully unify the capabilities of many specialized systems into one coherent, generalist agent.&lt;/p&gt;
    &lt;p&gt;SIMA 2 also offers a strong path toward application in robotics. The skills it learned - from navigation and tool use to collaborative task execution - are some of the fundamental building blocks for the physical embodiment of intelligence needed for future AI assistants in the physical world.&lt;/p&gt;
    &lt;p&gt;SIMA 2 is an interactive, human-centered agent that’s fun to engage with, particularly in the entertaining way it explains its own reasoning. As with all our advanced and foundational technologies, we remain deeply committed to developing SIMA 2 responsibly, from the outset. This is particularly true with regard to its technical innovations, particularly the ability to self-improve.&lt;/p&gt;
    &lt;p&gt;As we’ve built SIMA 2, we’ve worked with our Responsible Development &amp;amp; Innovation Team. As we continue to explore the potential applications, we are announcing SIMA 2 as a limited research preview and providing early access to a small cohort of academics and game developers. This approach allows us to gather crucial feedback and interdisciplinary perspectives as we explore this new field and continue to build our understanding of risks and their appropriate mitigations. We look forward to working further with the community to develop this technology in a responsible way.&lt;/p&gt;
    &lt;p&gt;Learn more about SIMA&lt;/p&gt;
    &lt;p&gt;SIMA Technical Report - Available soon&lt;/p&gt;
    &lt;p&gt;This research was developed by the SIMA 2 team: Maria Abi Raad, John Agapiou, Frederic Besse, Andrew Bolt, Sarah Chakera, Harris Chan, Jeff Clune, Alexandra Cordell, Martin Engelcke, Ryan Faulkner, Maxime Gazeau, Arne Olav Hallingstad, Tim Harley, Ed Hirst, Drew Hudson, Laura Kampis, Sheleem Kashem, Thomas Keck, Matija Kecman, Oscar Knagg, Alexander Lerchner, Bonnie Li, Yulan Liu, Cong Lu, Maria Loks-Thompson, Joseph Marino, Kay McKinney, Piermaria Mendolicchio, Anna Mitenkova, Alexandre Moufarek, Fabio Pardo, Ollie Purkiss, David Reichert, John Reid, Tyson Roberts, Daniel P. Sawyer, Tim Scholtes, Daniel Slater, Hubert Soyer, Kaustubh Sridhar, Peter Stys, Tayfun Terzi, Davide Vercelli, Bojan Vujatovic, Jane X. Wang, Luyu Wang, Duncan Williams, and Lei M. Zhang.&lt;/p&gt;
    &lt;p&gt;For their leadership, guidance, and support, we thank: Satinder Singh Baveja, Adrian Bolton, Zoubin Ghahramani, Raia Hadsell, Demis Hassabis, Shane Legg, Volodymyr Mnih, and Daan Wierstra.&lt;/p&gt;
    &lt;p&gt;With much gratitude to partial contributors and past members: Alex Cullum, Karol Gregor, Rosemary Ke, Junkyung Kim, Matthew Jackson, Andrew Lampinen, Loic Matthey, Hannah Openshaw, and Zhengdong Wang.&lt;/p&gt;
    &lt;p&gt;Special thanks to all of the game developers who partnered with us: Coffee Stain (Valheim, Satisfactory, Goat Simulator 3), Foulball Hangover (Hydroneer), Hello Games (No Man's Sky), Keen Software House (Space Engineers), RubberbandGames (Wobbly Life), Strange Loop Games (Eco), Thunderful Games (ASKA, The Gunk, Road 96, Steamworld Build), and Tuxedo Labs &amp;amp; Saber Interactive (Teardown).&lt;/p&gt;
    &lt;p&gt;We thank Vika Koriakin, Duncan Smith, Nilesh Ray, Matt Miller, Leen Verburgh, Ashyana Kachra, Phil Esposito, Dimple Vijaykumar, Piers Wingfield, Lucie Kerley for their invaluable partnership in developing and refining key components of this project.&lt;/p&gt;
    &lt;p&gt;We also thank Jack Parker-Holder, Shlomi Fruchter, and the rest of the Genie team for access to the Genie 3 model.&lt;/p&gt;
    &lt;p&gt;We’d like to recognize the many teams across Google and Google DeepMind that have contributed to this effort including Legal, Marketing, Communications, Responsibility and Safety Council, Responsible Development and Innovation, Policy, Strategy and Operations, and our Business and Corporate Development teams. We'd also like to thank all GDM teams that are not explicitly mentioned here for their continued support.&lt;/p&gt;
    &lt;p&gt;Finally, we dedicate this work to the memory of our colleagues Felix Hill and Fabio Pardo, whose contributions to our field continue to inspire us.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45916037</guid><pubDate>Thu, 13 Nov 2025 15:29:38 +0000</pubDate></item></channel></rss>