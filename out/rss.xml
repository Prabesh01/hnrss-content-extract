<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 06 Sep 2025 22:34:13 +0000</lastBuildDate><item><title>Why language models hallucinate</title><link>https://openai.com/index/why-language-models-hallucinate/</link><description>&lt;doc fingerprint="fd2b109bb5359152"&gt;
  &lt;main&gt;
    &lt;p&gt;At OpenAI, we’re working hard to make AI systems more useful and reliable. Even as language models become more capable, one challenge remains stubbornly hard to fully solve: hallucinations. By this we mean instances where a model confidently generates an answer that isn’t true. Our new research paper(opens in a new window) argues that language models hallucinate because standard training and evaluation procedures reward guessing over acknowledging uncertainty.&lt;/p&gt;
    &lt;p&gt;ChatGPT also hallucinates. GPT‑5 has significantly fewer hallucinations especially when reasoning, but they still occur. Hallucinations remain a fundamental challenge for all large language models, but we are working hard to further reduce them.&lt;/p&gt;
    &lt;p&gt;Hallucinations are plausible but false statements generated by language models. They can show up in surprising ways, even for seemingly straightforward questions. For example, when we asked a widely used chatbot for the title of the PhD dissertation by Adam Tauman Kalai (an author of this paper), it confidently produced three different answers—none of them correct. When we asked for his birthday, it gave three different dates, likewise all wrong.&lt;/p&gt;
    &lt;p&gt;Hallucinations persist partly because current evaluation methods set the wrong incentives. While evaluations themselves do not directly cause hallucinations, most evaluations measure model performance in a way that encourages guessing rather than honesty about uncertainty.&lt;/p&gt;
    &lt;p&gt;Think about it like a multiple-choice test. If you do not know the answer but take a wild guess, you might get lucky and be right. Leaving it blank guarantees a zero. In the same way, when models are graded only on accuracy, the percentage of questions they get exactly right, they are encouraged to guess rather than say “I don’t know.”&lt;/p&gt;
    &lt;p&gt;As another example, suppose a language model is asked for someone’s birthday but doesn’t know. If it guesses “September 10,” it has a 1-in-365 chance of being right. Saying “I don’t know” guarantees zero points. Over thousands of test questions, the guessing model ends up looking better on scoreboards than a careful model that admits uncertainty.&lt;/p&gt;
    &lt;p&gt;For questions where there is a single “right answer,” one can consider three categories of responses: accurate responses, errors, and abstentions where the model does not hazard a guess. Abstaining is part of humility, one of OpenAI’s core values. Most scoreboards prioritize and rank models based on accuracy, but errors are worse than abstentions. Our Model Spec(opens in a new window) states that it is better to indicate uncertainty or ask for clarification than provide confident information that may be incorrect.&lt;/p&gt;
    &lt;p&gt;For a concrete example, consider the SimpleQA eval as an example from the GPT5 System Card(opens in a new window).&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Metric&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;gpt-5-thinking-mini&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;OpenAI o4-mini&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Abstention rate&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;52%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;1%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Accuracy rate &lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;22%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;24%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Error rate&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;26%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;75%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Total&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;100%&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;100%&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;In terms of accuracy, the older OpenAI o4-mini model performs slightly better. However, its error rate (i.e., rate of hallucination) is significantly higher. Strategically guessing when uncertain improves accuracy but increases errors and hallucinations.&lt;/p&gt;
    &lt;p&gt;When averaging results across dozens of evaluations, most benchmarks pluck out the accuracy metric, but this entails a false dichotomy between right and wrong. On simplistic evals like SimpleQA, some models achieve near 100% accuracy and thereby eliminate hallucinations. However, on more challenging evaluations and in real use, accuracy is capped below 100% because there are some questions whose answer cannot be determined for a variety of reasons such as unavailable information, limited thinking abilities of small models, or ambiguities that need to be clarified.&lt;/p&gt;
    &lt;p&gt;Nonetheless, accuracy-only scoreboards dominate leaderboards and model cards, motivating developers to build models that guess rather than hold back. That is one reason why, even as models get more advanced, they can still hallucinate, confidently giving wrong answers instead of acknowledging uncertainty.&lt;/p&gt;
    &lt;p&gt;There is a straightforward fix. Penalize confident errors more than you penalize uncertainty, and give partial credit for appropriate expressions of uncertainty. This idea is not new. Some standardized tests have long used versions of negative marking for wrong answers or partial credit for leaving questions blank to discourage blind guessing. Several research groups have also explored evaluations that account for uncertainty and calibration.&lt;/p&gt;
    &lt;p&gt;Our point is different. It is not enough to add a few new uncertainty-aware tests on the side. The widely used, accuracy-based evals need to be updated so that their scoring discourages guessing. If the main scoreboards keep rewarding lucky guesses, models will keep learning to guess. Fixing scoreboards can broaden adoption of hallucination-reduction techniques, both newly developed and those from prior research.&lt;/p&gt;
    &lt;p&gt;We’ve talked about why hallucinations are so hard to get rid of, but where do these highly-specific factual inaccuracies come from in the first place? After all, large pretrained models rarely exhibit other kinds of errors such as spelling mistakes and mismatched parentheses. The difference has to do with what kinds of patterns there are in the data.&lt;/p&gt;
    &lt;p&gt;Language models first learn through pretraining, a process of predicting the next word in huge amounts of text. Unlike traditional machine learning problems, there are no “true/false” labels attached to each statement. The model sees only positive examples of fluent language and must approximate the overall distribution.&lt;/p&gt;
    &lt;p&gt;It’s doubly hard to distinguish valid statements from invalid ones when you don’t have any examples labeled as invalid. But even with labels, some errors are inevitable. To see why, consider a simpler analogy. In image recognition, if millions of cat and dog photos are labeled as “cat” or “dog,” algorithms can learn to classify them reliably. But imagine instead labeling each pet photo by the pet’s birthday. Since birthdays are essentially random, this task would always produce errors, no matter how advanced the algorithm.&lt;/p&gt;
    &lt;p&gt;The same principle applies in pretraining. Spelling and parentheses follow consistent patterns, so errors there disappear with scale. But arbitrary low-frequency facts, like a pet’s birthday, cannot be predicted from patterns alone and hence lead to hallucinations. Our analysis explains which kinds of hallucinations should arise from next-word prediction. Ideally, further stages after pretraining should remove them, but this is not fully successful for reasons described in the previous section.&lt;/p&gt;
    &lt;p&gt;We hope that the statistical lens in our paper clarifies the nature of hallucinations and pushes back on common misconceptions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Claim: Hallucinations will be eliminated by improving accuracy because a 100% accurate model never hallucinates.&lt;lb/&gt;Finding: Accuracy will never reach 100% because, regardless of model size, search and reasoning capabilities, some real-world questions are inherently unanswerable.&lt;/item&gt;
      &lt;item&gt;Claim: Hallucinations are inevitable.&lt;lb/&gt;Finding: They are not, because language models can abstain when uncertain.&lt;/item&gt;
      &lt;item&gt;Claim: Avoiding hallucinations requires a degree of intelligence which is exclusively achievable with larger models.&lt;lb/&gt;Finding: It can be easier for a small model to know its limits. For example, when asked to answer a Māori question, a small model which knows no Māori can simply say “I don’t know” whereas a model that knows some Māori has to determine its confidence. As discussed in the paper, being “calibrated” requires much less computation than being accurate.&lt;/item&gt;
      &lt;item&gt;Claim: Hallucinations are a mysterious glitch in modern language models.&lt;lb/&gt;Finding: We understand the statistical mechanisms through which hallucinations arise and are rewarded in evaluations.&lt;/item&gt;
      &lt;item&gt;Claim: To measure hallucinations, we just need a good hallucination eval.&lt;lb/&gt;Finding: Hallucination evals have been published. However, a good hallucination eval has little effect against hundreds of traditional accuracy-based evals that penalize humility and reward guessing. Instead, all of the primary eval metrics need to be reworked to reward expressions of uncertainty.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Our latest models have lower hallucination rates, and we continue to work hard to further decrease the rates of confident errors output by our language models.&lt;/p&gt;
    &lt;head rend="h2"&gt;Announcement contributors&lt;/head&gt;
    &lt;p&gt;Adam Kalai, Santosh Vempala (Georgia Tech), Ofir Nachum, Eddie Zhang, David Robinson, Saachi Jain, Eric Mitchell, Alex Beutel, Johannes Heidecke&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45147385</guid></item><item><title>Qwen3 30B A3B Hits 13 token/s on 4xRaspberry Pi 5</title><link>https://github.com/b4rtaz/distributed-llama/discussions/255</link><description>&lt;doc fingerprint="e5f2f2ebfa4d7c22"&gt;
  &lt;main&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;head&gt;qwen3_30b.mov&lt;/head&gt;
          &lt;head&gt;Setup&lt;/head&gt;
          &lt;p&gt;Device: &lt;/p&gt;
          &lt;head&gt;Benchmark&lt;/head&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;head rend="h2"&gt;Replies: 0 comments&lt;/head&gt;
    &lt;p&gt; Sign up for free to join this conversation on GitHub. Already have an account? Sign in to comment &lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;head&gt;qwen3_30b.mov&lt;/head&gt;
          &lt;head&gt;Setup&lt;/head&gt;
          &lt;p&gt;Device: &lt;/p&gt;
          &lt;head&gt;Benchmark&lt;/head&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45148237</guid></item><item><title>We hacked Burger King: How auth bypass led to drive-thru audio surveillance</title><link>https://bobdahacker.com/blog/rbi-hacked-drive-thrus/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45148944</guid></item><item><title>AI surveillance should be banned while there is still time</title><link>https://gabrielweinberg.com/p/ai-surveillance-should-be-banned</link><description>&lt;doc fingerprint="b608b3dea7679795"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;AI surveillance should be banned while there is still time.&lt;/head&gt;
    &lt;p&gt;All the same privacy harms with online tracking are also present with AI, but worse.&lt;/p&gt;
    &lt;p&gt;While chatbot conversations resemble longer search queries, chatbot privacy harms have the potential to be significantly worse because the inference potential is dramatically greater. Longer input invites more personal information to be provided, and people are starting to bare their souls to chatbots. The conversational format can make it feel like you’re talking to a friend, a professional, or even a therapist. While search queries reveal interests and personal problems, AI conversations take their specificity to another level and, in addition, reveal thought processes and communication styles, creating a much more comprehensive profile of your personality.&lt;/p&gt;
    &lt;p&gt;This richer personal information can be more thoroughly exploited for manipulation, both commercially and ideologically, for example, through behavioral chatbot advertising and models designed (or themselves manipulated through SEO or hidden system prompts) to nudge you towards a political position or product. Chatbots have already been found to be more persuasive than humans and have caused people to go into delusional spirals as a result. I suspect we’re just scratching the surface, since they can become significantly more attuned to your particular persuasive triggers through chatbot memory features, where they train and fine-tune based on your past conversations, making the influence much more subtle. Instead of an annoying and obvious ad following you around everywhere, you can have a seemingly convincing argument, tailored to your personal style, with an improperly sourced “fact” that you’re unlikely to fact-check or a subtle product recommendation you’re likely to heed.&lt;/p&gt;
    &lt;p&gt;That is, all the privacy debates surrounding Google search results from the past two decades apply one-for-one to AI chats, but to an even greater degree. That’s why we (at DuckDuckGo) started offering Duck.ai for protected chatbot conversations and optional, anonymous AI-assisted answers in our private search engine. In doing so, we’re demonstrating that privacy-respecting AI services are feasible. But unfortunately, such protected chats are not yet standard practice, and privacy mishaps are mounting quickly. Grok leaked hundreds of thousands of chatbot conversations that users thought were private. Perplexity’s AI agent was shown to be vulnerable to hackers who could slurp up your personal information. Open AI is openly talking about their vision for a “super assistant” that tracks everything you do and say (including offline). And Anthropic is going to start training on your chatbot conversations by default (previously the default was off). I collected these from just the past few weeks!&lt;/p&gt;
    &lt;p&gt;It would therefore be ideal if Congress could act quickly to ensure that protected chats become the rule rather than the exception. And yet, I’m not holding my breath because it’s 2025 and the U.S. still doesn’t have a general online privacy law, let alone privacy enshrined in the Constitution as a fundamental right, as it should be. However, there does appear to be an opening right now for AI-specific federal legislation, despite the misguided attempts to ban state AI legislation.&lt;/p&gt;
    &lt;p&gt;Time is running out because every day that passes further entrenches bad privacy practices. Congress must move before history completely repeats itself and everything that happened with online tracking happens again with AI tracking. AI surveillance should be banned while there is still time. No matter what happens, though, we will still be here, offering protected services, including optional AI services, to consumers who want to reap the productivity benefits of online tools without the privacy harms.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45149281</guid></item><item><title>Oldest recorded transaction</title><link>https://avi.im/blag/2025/oldest-txn/</link><description>&lt;doc fingerprint="a9cfeaf676b2dbc5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Oldest recorded transaction&lt;/head&gt;
    &lt;p&gt;The other day I posted a tweet with this image which I thought was funny:&lt;/p&gt;
    &lt;p&gt;This is the oldest transaction database from 3100 BC - recording accounts of malt and barley groats. Considering this thing survived 5000 years (holy shit!) with zero downtime and has stronger durability guarantees than most databases today.&lt;/p&gt;
    &lt;p&gt;I call it rock solid durability.&lt;/p&gt;
    &lt;p&gt;This got me thinking, can I insert this date in today’s database? What is the oldest timestamp a database can support?&lt;/p&gt;
    &lt;p&gt;So I checked the top three databases: MySQL, Postgres, and SQLite:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;MySQL&lt;/cell&gt;
        &lt;cell&gt;1000 AD&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Postgres&lt;/cell&gt;
        &lt;cell&gt;4713 BC&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;SQLite&lt;/cell&gt;
        &lt;cell&gt;4713 BC&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;&lt;lb/&gt;Too bad you cannot use MySQL for this. Postgres and SQLite support the Julian calendar and the lowest date is Jan 01, 4713 BC:&lt;/p&gt;
    &lt;code&gt;sales=# INSERT INTO orders VALUES ('4713-01-01 BC'::date);
INSERT 0 1
sales=# SELECT * FROM orders;
   timestamp
---------------
 4713-01-01 BC
(1 row)
sales=# INSERT INTO orders VALUES ('4714-01-01 BC'::date);
ERROR:  date out of range: "4714-01-01 BC"
&lt;/code&gt;
    &lt;p&gt;I wonder how people store dates older than this. Maybe if I’m a British Museum manager, and I want to keep &lt;del&gt;theft&lt;/del&gt; inventory details. How do I do it? As an epoch? Store it as text? Use some custom system? How do I get it to support all the custom operations that a typical &lt;code&gt;TIMESTAMP&lt;/code&gt; supports?&lt;/p&gt;
    &lt;p&gt;Thanks to aku, happy_shady, Mr. Bhat, and General Bruh for reading an early draft of this post.&lt;/p&gt;
    &lt;p&gt;1. Source of the image: Sumer civilization&lt;lb/&gt;2. I found this from the talk 1000x: The Power of an Interface for Performance by Joran Dirk Greef, CEO of TigerBeetle, timestamped @ 38:10.&lt;lb/&gt;3. The talk has other bangers too, like this or this.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45149626</guid></item><item><title>Using Claude Code SDK to reduce E2E test time</title><link>https://jampauchoa.substack.com/p/best-of-both-worlds-using-claude</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45151447</guid></item><item><title>GigaByte CXL memory expansion card with up to 512GB DRAM</title><link>https://www.gigabyte.com/PC-Accessory/AI-TOP-CXL-R5X4</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45151598</guid></item><item><title>Stop writing CLI validation. Parse it right the first time</title><link>https://hackers.pub/@hongminhee/2025/stop-writing-cli-validation-parse-it-right-the-first-time</link><description>&lt;doc fingerprint="ee5853587c453a9f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Stop writing CLI validation. Parse it right the first time.&lt;/head&gt;
    &lt;p&gt;洪 民憙 (Hong Minhee) @hongminhee@hackers.pub&lt;/p&gt;
    &lt;p&gt;I have this bad habit. When something annoys me enough times, I end up building a library for it. This time, it was CLI validation code.&lt;/p&gt;
    &lt;p&gt;See, I spend a lot of time reading other people's code. Open source projects, work stuff, random GitHub repos I stumble upon at 2 AM. And I kept noticing this thing: every CLI tool has the same ugly validation code tucked away somewhere. You know the kind:&lt;/p&gt;
    &lt;code&gt;if (!opts.server &amp;amp;&amp;amp; opts.port) {
  throw new Error("--port requires --server flag");
}

if (opts.server &amp;amp;&amp;amp; !opts.port) {
  opts.port = 3000; // default port
}

// wait, what if they pass --port without a value?
// what if the port is out of range?
// what if...&lt;/code&gt;
    &lt;p&gt;It's not even that this code is hard to write. It's that it's everywhere. Every project. Every CLI tool. The same patterns, slightly different flavors. Options that depend on other options. Flags that can't be used together. Arguments that only make sense in certain modes.&lt;/p&gt;
    &lt;p&gt;And here's what really got me: we solved this problem years ago for other types of data. Just… not for CLIs.&lt;/p&gt;
    &lt;head rend="h2"&gt;The problem with validation&lt;/head&gt;
    &lt;p&gt;There's this blog post that completely changed how I think about parsing. It's called Parse, don't validate by Alexis King. The gist? Don't parse data into a loose type and then check if it's valid. Parse it directly into a type that can only be valid.&lt;/p&gt;
    &lt;p&gt;Think about it. When you get JSON from an API, you don't just parse it as &lt;code&gt;any&lt;/code&gt;
and then write a bunch of &lt;code&gt;if&lt;/code&gt;-statements. You use something like Zod to parse
it directly into the shape you want. Invalid data? The parser rejects it. Done.&lt;/p&gt;
    &lt;p&gt;But with CLIs? We parse arguments into some bag of properties and then spend the next 100 lines checking if that bag makes sense. It's backwards.&lt;/p&gt;
    &lt;p&gt;So yeah, I built Optique. Not because the world desperately needed another CLI parser (it didn't), but because I was tired of seeing—and writing—the same validation code everywhere.&lt;/p&gt;
    &lt;head rend="h2"&gt;Three patterns I was sick of validating&lt;/head&gt;
    &lt;head rend="h3"&gt;Dependent options&lt;/head&gt;
    &lt;p&gt;This one's everywhere. You have an option that only makes sense when another option is enabled.&lt;/p&gt;
    &lt;p&gt;The old way? Parse everything, then check:&lt;/p&gt;
    &lt;code&gt;const opts = parseArgs(process.argv);
if (!opts.server &amp;amp;&amp;amp; opts.port) {
  throw new Error("--port requires --server");
}
if (opts.server &amp;amp;&amp;amp; !opts.port) {
  opts.port = 3000;
}
// More validation probably lurking elsewhere...&lt;/code&gt;
    &lt;p&gt;With Optique, you just describe what you want:&lt;/p&gt;
    &lt;code&gt;const config = withDefault(
  object({
    server: flag("--server"),
    port: option("--port", integer()),
    workers: option("--workers", integer())
  }),
  { server: false }
);&lt;/code&gt;
    &lt;p&gt;Here's what TypeScript infers for &lt;code&gt;config&lt;/code&gt;'s type:&lt;/p&gt;
    &lt;code&gt;type Config = 
  | { readonly server: false }
  | { readonly server: true; readonly port: number; readonly workers: number }&lt;/code&gt;
    &lt;p&gt;The type system now understands that when &lt;code&gt;server&lt;/code&gt; is false, &lt;code&gt;port&lt;/code&gt; literally
doesn't exist. Not &lt;code&gt;undefined&lt;/code&gt;, not &lt;code&gt;null&lt;/code&gt;—it's not there. Try to access it and
TypeScript yells at you. No runtime validation needed.&lt;/p&gt;
    &lt;head rend="h3"&gt;Mutually exclusive options&lt;/head&gt;
    &lt;p&gt;Another classic. Pick one output format: JSON, YAML, or XML. But definitely not two.&lt;/p&gt;
    &lt;p&gt;I used to write this mess:&lt;/p&gt;
    &lt;code&gt;if ((opts.json ? 1 : 0) + (opts.yaml ? 1 : 0) + (opts.xml ? 1 : 0) &amp;gt; 1) {
  throw new Error('Choose only one output format');
}&lt;/code&gt;
    &lt;p&gt;(Don't judge me, you've written something similar.)&lt;/p&gt;
    &lt;p&gt;Now?&lt;/p&gt;
    &lt;code&gt;const format = or(
  map(option("--json"), () =&amp;gt; "json" as const),
  map(option("--yaml"), () =&amp;gt; "yaml" as const),
  map(option("--xml"), () =&amp;gt; "xml" as const)
);&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;or()&lt;/code&gt; combinator means exactly one succeeds. The result is just
&lt;code&gt;"json" | "yaml" | "xml"&lt;/code&gt;. A single string. Not three booleans to juggle.&lt;/p&gt;
    &lt;head rend="h3"&gt;Environment-specific requirements&lt;/head&gt;
    &lt;p&gt;Production needs auth. Development needs debug flags. Docker needs different options than local. You know the drill.&lt;/p&gt;
    &lt;p&gt;Instead of a validation maze, you just describe each environment:&lt;/p&gt;
    &lt;code&gt;const envConfig = or(
  object({
    env: constant("prod"),
    auth: option("--auth", string()),      // Required in prod
    ssl: option("--ssl"),
    monitoring: option("--monitoring", url())
  }),
  object({
    env: constant("dev"),
    debug: optional(option("--debug")),    // Optional in dev
    verbose: option("--verbose")
  })
);&lt;/code&gt;
    &lt;p&gt;No auth in production? Parser fails immediately. Trying to access &lt;code&gt;--auth&lt;/code&gt; in
dev mode? TypeScript won't let you—the field doesn't exist on that type.&lt;/p&gt;
    &lt;head rend="h2"&gt;“But parser combinators though…”&lt;/head&gt;
    &lt;p&gt;I know, I know. “Parser combinators” sounds like something you'd need a CS degree to understand.&lt;/p&gt;
    &lt;p&gt;Here's the thing: I don't have a CS degree. Actually, I don't have any degree. But I've been using parser combinators for years because they're actually… not that hard? It's just that the name makes them sound way scarier than they are.&lt;/p&gt;
    &lt;p&gt;I'd been using them for other stuff—parsing config files, DSLs, whatever. But somehow it never clicked that you could use them for CLI parsing until I saw Haskell's optparse-applicative. That was a real “wait, of course” moment. Like, why are we doing this any other way?&lt;/p&gt;
    &lt;p&gt;Turns out it's stupidly simple. A parser is just a function. Combinators are just functions that take parsers and return new parsers. That's it.&lt;/p&gt;
    &lt;code&gt;// This is a parser
const port = option("--port", integer());

// This is also a parser (made from smaller parsers)
const server = object({
  port: port,
  host: option("--host", string())
});

// Still a parser (parsers all the way down)
const config = or(server, client);&lt;/code&gt;
    &lt;p&gt;No monads. No category theory. Just functions. Boring, beautiful functions.&lt;/p&gt;
    &lt;head rend="h2"&gt;TypeScript does the heavy lifting&lt;/head&gt;
    &lt;p&gt;Here's the thing that still feels like cheating: I don't write types for my CLI configs anymore. TypeScript just… figures it out.&lt;/p&gt;
    &lt;code&gt;const cli = or(
  command("deploy", object({
    action: constant("deploy"),
    environment: argument(string()),
    replicas: option("--replicas", integer())
  })),
  command("rollback", object({
    action: constant("rollback"),
    version: argument(string()),
    force: option("--force")
  }))
);

// TypeScript infers this type automatically:
type Cli = 
  | { 
      readonly action: "deploy"
      readonly environment: string
      readonly replicas: number
    }
  | { 
      readonly action: "rollback"
      readonly version: string
      readonly force: boolean
    }&lt;/code&gt;
    &lt;p&gt;TypeScript knows that if &lt;code&gt;action&lt;/code&gt; is &lt;code&gt;"deploy"&lt;/code&gt;, then &lt;code&gt;environment&lt;/code&gt; exists but
&lt;code&gt;version&lt;/code&gt; doesn't. It knows &lt;code&gt;replicas&lt;/code&gt; is a &lt;code&gt;number&lt;/code&gt;. It knows &lt;code&gt;force&lt;/code&gt; is
a &lt;code&gt;boolean&lt;/code&gt;. I didn't tell it any of this.&lt;/p&gt;
    &lt;p&gt;This isn't just about nice autocomplete (though yeah, the autocomplete is great). It's about catching bugs before they happen. Forget to handle a new option somewhere? Code won't compile.&lt;/p&gt;
    &lt;head rend="h2"&gt;What actually changed for me&lt;/head&gt;
    &lt;p&gt;I've been dogfooding this for a few weeks. Some real talk:&lt;/p&gt;
    &lt;p&gt;I delete code now. Not refactor. Delete. That validation logic that used to be 30% of my CLI code? Gone. It feels weird every time.&lt;/p&gt;
    &lt;p&gt;Refactoring isn't scary. Want to know something that usually terrifies me? Changing how a CLI takes its arguments. Like going from &lt;code&gt;--input file.txt&lt;/code&gt; to
just &lt;code&gt;file.txt&lt;/code&gt; as a positional argument. With traditional parsers,
you're hunting down validation logic everywhere. With this?
You change the parser definition, TypeScript immediately shows you every place
that breaks, you fix them, done. What used to be an hour of “did I catch
everything?” is now “fix the red squiggles and move on.”&lt;/p&gt;
    &lt;p&gt;My CLIs got fancier. When adding complex option relationships doesn't mean writing complex validation, you just… add them. Mutually exclusive groups? Sure. Context-dependent options? Why not. The parser handles it.&lt;/p&gt;
    &lt;p&gt;The reusability is real too:&lt;/p&gt;
    &lt;code&gt;const networkOptions = object({
  host: option("--host", string()),
  port: option("--port", integer())
});

// Reuse everywhere, compose differently
const devServer = merge(networkOptions, debugOptions);
const prodServer = merge(networkOptions, authOptions);
const testServer = merge(networkOptions, mockOptions);&lt;/code&gt;
    &lt;p&gt;But honestly? The biggest change is trust. If it compiles, the CLI logic works. Not “probably works” or “works unless someone passes weird arguments.” It just works.&lt;/p&gt;
    &lt;head rend="h2"&gt;Should you care?&lt;/head&gt;
    &lt;p&gt;If you're writing a 10-line script that takes one argument, you don't need this. &lt;code&gt;process.argv[2]&lt;/code&gt; and call it a day.&lt;/p&gt;
    &lt;p&gt;But if you've ever:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Had validation logic get out of sync with your actual options&lt;/item&gt;
      &lt;item&gt;Discovered in production that certain option combinations explode&lt;/item&gt;
      &lt;item&gt;Spent an afternoon tracking down why &lt;code&gt;--verbose&lt;/code&gt;breaks when used with&lt;code&gt;--json&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Written the same “option A requires option B” check for the fifth time&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Then yeah, maybe you're tired of this stuff too.&lt;/p&gt;
    &lt;p&gt;Fair warning: Optique is young. I'm still figuring things out, the API might shift a bit. But the core idea—parse, don't validate—that's solid. And I haven't written validation code in months.&lt;/p&gt;
    &lt;p&gt;Still feels weird. Good weird.&lt;/p&gt;
    &lt;head rend="h2"&gt;Try it or don't&lt;/head&gt;
    &lt;p&gt;If this resonates:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tutorial: Build something real, see if you hate it&lt;/item&gt;
      &lt;item&gt;Concepts: Primitives, constructs, modifiers, value parsers, the whole thing&lt;/item&gt;
      &lt;item&gt;GitHub: The code, issues, angry rants&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I'm not saying Optique is the answer to all CLI problems. I'm just saying I was tired of writing the same validation code everywhere, so I built something that makes it unnecessary.&lt;/p&gt;
    &lt;p&gt;Take it or leave it. But that validation code you're about to write? You probably don't need it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45151622</guid></item><item><title>Normalization of deviance (2015)</title><link>https://danluu.com/wat/</link><description>&lt;doc fingerprint="3440911d1fe645f5"&gt;
  &lt;main&gt;&lt;p&gt;where women still get rejected in recruiter screens for not being technical enough after being asked questions like "was your experience with algorithms or just coding?". I thought that my referral with a very strong recommendation would have prevented that, but it did not.&lt;/p&gt;&lt;p&gt;There's the company where I worked on a four person effort with a multi-hundred million dollar budget and a billion dollar a year impact, where requests for things that cost hundreds of dollars routinely took months or were denied.&lt;/p&gt;&lt;p&gt;You might wonder if I've just worked at places that are unusually screwed up. Sure, the companies are generally considered to be ok places to work and two of them are considered to be among the best places to work, but maybe I've just ended up at places that are overrated. But I have the same experience when I hear stories about how other companies work, even places with stellar engineering reputations, except that it's me that's shocked and my conversation partner who thinks their story is normal.&lt;/p&gt;&lt;p&gt;There's the companies that use @flaky, which includes the vast majority of Python-using SF Bay area unicorns. If you don't know what this is, this is a library that lets you add a Python annotation to those annoying flaky tests that sometimes pass and sometimes fail. When I asked multiple co-workers and former co-workers from three different companies what they thought this did, they all guessed that it re-runs the test multiple times and reports a failure if any of the runs fail. Close, but not quite. It's technically possible to use @flaky for that, but in practice it's used to re-run the test multiple times and reports a pass if any of the runs pass. The company that created @flaky is effectively a storage infrastructure company, and the library is widely used at its biggest competitor.&lt;/p&gt;&lt;p&gt;There's the company with a reputation for having great engineering practices that had 2 9s of reliability last time I checked, for reasons that are entirely predictable from their engineering practices. This is the second thing in a row that can't be deanonymized because multiple companies fit the description. Here, I'm not talking about companies trying to be the next reddit or twitter where it's, apparently, totally fine to have 1 9. I'm talking about companies that sell platforms that other companies rely on, where an outage will cause dependent companies to pause operations for the duration of the outage. Multiple companies that build infrastructure find practices that lead to 2 9s of reliability.&lt;/p&gt;&lt;p&gt;As far as I can tell, what happens at a lot these companies is that they started by concentrating almost totally on product growth. That's completely and totally reasonable, because companies are worth approximately zero when they're founded; they don't bother with things that protect them from losses, like good ops practices or actually having security, because there's nothing to lose (well, except for user data when the inevitable security breach happens, and if you talk to security folks at unicorns you'll know that these happen).&lt;/p&gt;&lt;p&gt;The result is a culture where people are hyper-focused on growth and ignore risk. That culture tends to stick even after company has grown to be worth well over a billion dollars, and the companies have something to lose. Anyone who comes into one of these companies from Google, Amazon, or another place with solid ops practices is shocked. Often, they try to fix things, and then leave when they can't make a dent.&lt;/p&gt;&lt;p&gt;Google probably has the best ops and security practices of any tech company today. It's easy to say that you should take these things as seriously as Google does, but it's instructive to see how they got there. If you look at the codebase, you'll see that various services have names ending in z, as do a curiously large number of variables. I'm told that's because, once upon a time, someone wanted to add monitoring. It wouldn't really be secure to have &lt;code&gt;google.com/somename&lt;/code&gt; expose monitoring data, so they added a z. &lt;code&gt;google.com/somenamez&lt;/code&gt;. For security. At the company that is now the best in the world at security. They're now so good at security that multiple people I've talked to (all of whom joined after this happened) vehemently deny that this ever happened, even though the reasons they give don't really make sense (e.g., to avoid name collisions) and I have this from sources who were there at the time this happened.&lt;/p&gt;&lt;p&gt;Google didn't go from adding z to the end of names to having the world's best security because someone gave a rousing speech or wrote a convincing essay. They did it after getting embarrassed a few times, which gave people who wanted to do things “right” the leverage to fix fundamental process issues. It's the same story at almost every company I know of that has good practices. Microsoft was a joke in the security world for years, until multiple disastrously bad exploits forced them to get serious about security. This makes it sound simple, but if you talk to people who were there at the time, the change was brutal. Despite a mandate from the top, there was vicious political pushback from people whose position was that the company got to where it was in 2003 without wasting time on practices like security. Why change what's worked?&lt;/p&gt;&lt;p&gt;You can see this kind of thing in every industry. A classic example that tech folks often bring up is hand-washing by doctors and nurses. It's well known that germs exist, and that washing hands properly very strongly reduces the odds of transmitting germs and thereby significantly reduces hospital mortality rates. Despite that, trained doctors and nurses still often don't do it. Interventions are required. Signs reminding people to wash their hands save lives. But when people stand at hand-washing stations to require others walking by to wash their hands, even more lives are saved. People can ignore signs, but they can't ignore being forced to wash their hands.&lt;/p&gt;&lt;p&gt;This mirrors a number of attempts at tech companies to introduce better practices. If you tell people they should do it, that helps a bit. If you enforce better practices via code review, that helps a lot.&lt;/p&gt;&lt;p&gt;The data are clear that humans are really bad at taking the time to do things that are well understood to incontrovertibly reduce the risk of rare but catastrophic events. We will rationalize that taking shortcuts is the right, reasonable thing to do. There's a term for this: the normalization of deviance. It's well studied in a number of other contexts including healthcare, aviation, mechanical engineering, aerospace engineering, and civil engineering, but we don't see it discussed in the context of software. In fact, I've never seen the term used in the context of software.&lt;/p&gt;&lt;p&gt;Is it possible to learn from other's mistakes instead of making every mistake ourselves? The state of the industry make this sound unlikely, but let's give it a shot. John Banja has a nice summary paper on the normalization of deviance in healthcare, with lessons we can attempt to apply to software development. One thing to note is that, because Banja is concerned with patient outcomes, there's a close analogy to devops failure modes, but normalization of deviance also occurs in cultural contexts that are less directly analogous.&lt;/p&gt;&lt;p&gt;The first section of the paper details a number of disasters, both in healthcare and elsewhere. Here's one typical example:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;A catastrophic negligence case that the author participated in as an expert witness involved an anesthesiologist's turning off a ventilator at the request of a surgeon who wanted to take an x-ray of the patient's abdomen (Banja, 2005, pp. 87-101). The ventilator was to be off for only a few seconds, but the anesthesiologist forgot to turn it back on, or thought he turned it back on but had not. The patient was without oxygen for a long enough time to cause her to experience global anoxia, which plunged her into a vegetative state. She never recovered, was disconnected from artificial ventilation 9 days later, and then died 2 days after that. It was later discovered that the anesthesia alarms and monitoring equipment in the operating room had been deliberately programmed to a “suspend indefinite” mode such that the anesthesiologist was not alerted to the ventilator problem. Tragically, the very instrumentality that was in place to prevent such a horror was disabled, possibly because the operating room staff found the constant beeping irritating and annoying.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Turning off or ignoring notifications because there are too many of them and they're too annoying? An erroneous manual operation? This could be straight out of the post-mortem of more than a few companies I can think of, except that the result was a tragic death instead of the loss of millions of dollars. If you read a lot of tech post-mortems, every example in Banja's paper will feel familiar even though the details are different.&lt;/p&gt;&lt;p&gt;The section concludes,&lt;/p&gt;&lt;quote&gt;&lt;p&gt;What these disasters typically reveal is that the factors accounting for them usually had “long incubation periods, typified by rule violations, discrepant events that accumulated unnoticed, and cultural beliefs about hazards that together prevented interventions that might have staved off harmful outcomes”. Furthermore, it is especially striking how multiple rule violations and lapses can coalesce so as to enable a disaster's occurrence.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Once again, this could be from an article about technical failures. That makes the next section, on why these failures happen, seem worth checking out. The reasons given are:&lt;/p&gt;&lt;p&gt;The example in the paper is about delivering medication to newborns. To prevent “drug diversion,” nurses were required to enter their password onto the computer to access the medication drawer, get the medication, and administer the correct amount. In order to ensure that the first nurse wasn't stealing drugs, if any drug remained, another nurse was supposed to observe the process, and then enter their password onto the computer to indicate they witnessed the drug being properly disposed of.&lt;/p&gt;&lt;p&gt;That sounds familiar. How many technical postmortems start off with “someone skipped some steps because they're inefficient”, e.g., “the programmer force pushed a bad config or bad code because they were sure nothing could go wrong and skipped staging/testing”? The infamous November 2014 Azure outage happened for just that reason. At around the same time, a dev at one of Azure's competitors overrode the rule that you shouldn't push a config that fails tests because they knew that the config couldn't possibly be bad. When that caused the canary deploy to start failing, they overrode the rule that you can't deploy from canary into staging with a failure because they knew their config couldn't possibly be bad and so the failure must be from something else. That postmortem revealed that the config was technically correct, but exposed a bug in the underlying software; it was pure luck that the latent bug the config revealed wasn't as severe as the Azure bug.&lt;/p&gt;&lt;p&gt;Humans are bad at reasoning about how failures cascade, so we implement bright line rules about when it's safe to deploy. But the same thing that makes it hard for us to reason about when it's safe to deploy makes the rules seem stupid and inefficient.&lt;/p&gt;&lt;p&gt;People don't automatically know what should be normal, and when new people are onboarded, they can just as easily learn deviant processes that have become normalized as reasonable processes.&lt;/p&gt;&lt;p&gt;Julia Evans described to me how this happens:&lt;/p&gt;&lt;p&gt;new person joins&lt;lb/&gt; new person: WTF WTF WTF WTF WTF&lt;lb/&gt; old hands: yeah we know we're concerned about it&lt;lb/&gt; new person: WTF WTF wTF wtf wtf w...&lt;lb/&gt; new person gets used to it&lt;lb/&gt; new person #2 joins&lt;lb/&gt; new person #2: WTF WTF WTF WTF&lt;lb/&gt; new person: yeah we know. we're concerned about it.&lt;/p&gt;&lt;p&gt;The thing that's really insidious here is that people will really buy into the WTF idea, and they can spread it elsewhere for the duration of their career. Once, after doing some work on an open source project that's regularly broken and being told that it's normal to have a broken build, and that they were doing better than average, I ran the numbers, found that project was basically worst in class, and wrote something about the idea that it's possible to have a build that nearly always passes with relatively low effort. The most common comment I got in response was, "Wow that guy must work with superstar programmers. But let's get real. We all break the build at least a few times a week", as if running tests (or for that matter, even attempting to compile) before checking code in requires superhuman abilities. But once people get convinced that some deviation is normal, they often get really invested in the idea.&lt;/p&gt;&lt;p&gt;The example in the paper is of someone who breaks the rule that you should wear gloves when finding a vein. Their reasoning is that wearing gloves makes it harder to find a vein, which may result in their having to stick a baby with a needle multiple times. It's hard to argue against that. No one wants to cause a baby extra pain!&lt;/p&gt;&lt;p&gt;The second worst outage I can think of occurred when someone noticed that a database service was experiencing slowness. They pushed a fix to the service, and in order to prevent the service degradation from spreading, they ignored the rule that you should do a proper, slow, staged deploy. Instead, they pushed the fix to all machines. It's hard to argue against that. No one wants their customers to have degraded service! Unfortunately, the fix exposed a bug that caused a global outage.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;most human beings perceive themselves as good and decent people, such that they can understand many of their rule violations as entirely rational and ethically acceptable responses to problematic situations. They understand themselves to be doing nothing wrong, and will be outraged and often fiercely defend themselves when confronted with evidence to the contrary.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;As companies grow up, they eventually have to impose security that prevents every employee from being able to access basically everything. And at most companies, when that happens, some people get really upset. “Don't you trust me? If you trust me, how come you're revoking my access to X, Y, and Z?”&lt;/p&gt;&lt;p&gt;Facebook famously let all employees access everyone's profile for a long time, and you can even find HN comments indicating that some recruiters would explicitly mention that as a perk of working for Facebook. And I can think of more than one well-regarded unicorn where everyone still has access to basically everything, even after their first or second bad security breach. It's hard to get the political capital to restrict people's access to what they believe they need, or are entitled, to know. A lot of trendy startups have core values like “trust” and “transparency” which make it difficult to argue against universal access.&lt;/p&gt;&lt;p&gt;There are people I simply don't give feedback to because I can't tell if they'd take it well or not, and once you say something, it's impossible to un-say it. In the paper, the author gives an example of a doctor with poor handwriting who gets mean when people ask him to clarify what he's written. As a result, people guess instead of asking.&lt;/p&gt;&lt;p&gt;In most company cultures, people feel weird about giving feedback. Everyone has stories about a project that lingered on for months or years after it should have been terminated because no one was willing to offer explicit feedback. This is a problem even when cultures discourage meanness and encourage feedback: cultures of niceness seem to have as many issues around speaking up as cultures of meanness, if not more. In some places, people are afraid to speak up because they'll get attacked by someone mean. In others, they're afraid because they'll be branded as mean. It's a hard problem.&lt;/p&gt;&lt;p&gt;In the paper, this is characterized by flaws and weaknesses being diluted as information flows up the chain of command. One example is how a supervisor might take sub-optimal actions to avoid looking bad to superiors.&lt;/p&gt;&lt;p&gt;I was shocked the first time I saw this happen. I must have been half a year or a year out of school. I saw that we were doing something obviously non-optimal, and brought it up with the senior person in the group. He told me that he didn't disagree, but that if we did it my way and there was a failure, it would be really embarrassing. He acknowledged that my way reduced the chance of failure without making the technical consequences of failure worse, but it was more important that we not be embarrassed. Now that I've been working for a decade, I have a better understanding of how and why people play this game, but I still find it absurd.&lt;/p&gt;&lt;p&gt;Let's say you notice that your company has a problem that I've heard people at most companies complain about: people get promoted for heroism and putting out fires, not for preventing fires; and people get promoted for shipping features, not for doing critical maintenance work and bug fixing. How do you change that?&lt;/p&gt;&lt;p&gt;The simplest option is to just do the right thing yourself and ignore what's going on around you. That has some positive impact, but the scope of your impact is necessarily limited. Next, you can convince your team to do the right thing: I've done that a few times for practices I feel are really important and are sticky, so that I won't have to continue to expend effort on convincing people once things get moving.&lt;/p&gt;&lt;p&gt;But if the incentives are aligned against you, it will require an ongoing and probably unsustainable effort to keep people doing the right thing. In that case, the problem becomes convincing someone to change the incentives, and then making sure the change works as designed. How to convince people is worth discussing, but long and messy enough that it's beyond the scope of this post. As for making the change work, I've seen many “obvious” mistakes repeated, both in places I've worked and those whose internal politics I know a lot about.&lt;/p&gt;&lt;p&gt;Small companies have it easy. When I worked at a 100 person company, the hierarchy was individual contributor (IC) -&amp;gt; team lead (TL) -&amp;gt; CEO. That was it. The CEO had a very light touch, but if he wanted something to happen, it happened. Critically, he had a good idea of what everyone was up to and could basically adjust rewards in real-time. If you did something great for the company, there's a good chance you'd get a raise. Not in nine months when the next performance review cycle came up, but basically immediately. Not all small companies do that effectively, but with the right leadership, they can. That's impossible for large companies.&lt;/p&gt;&lt;p&gt;At large company A (LCA), they had the problem we're discussing and a mandate came down to reward people better for doing critical but low-visibility grunt work. There were too many employees for the mandator to directly make all decisions about compensation and promotion, but the mandator could review survey data, spot check decisions, and provide feedback until things were normalized. My subjective perception is that the company never managed to achieve parity between boring maintenance work and shiny new projects, but got close enough that people who wanted to make sure things worked correctly didn't have to significantly damage their careers to do it.&lt;/p&gt;&lt;p&gt;At large company B (LCB), ICs agreed that it's problematic to reward creating new features more richly than doing critical grunt work. When I talked to managers, they often agreed, too. But nevertheless, the people who get promoted are disproportionately those who ship shiny new things. I saw management attempt a number of cultural and process changes at LCB. Mostly, those took the form of pronouncements from people with fancy titles. For really important things, they might produce a video, and enforce compliance by making people take a multiple choice quiz after watching the video. The net effect I observed among other ICs was that people talked about how disconnected management was from the day-to-day life of ICs. But, for the same reasons that normalization of deviance occurs, that information seems to have no way to reach upper management.&lt;/p&gt;&lt;p&gt;It's sort of funny that this ends up being a problem about incentives. As an industry, we spend a lot of time thinking about how to incentivize consumers into doing what we want. But then we set up incentive systems that are generally agreed upon as incentivizing us to do the wrong things, and we do so via a combination of a game of telephone and cargo cult diffusion. Back when Microsoft was ascendant, we copied their interview process and asked brain-teaser interview questions. Now that Google is ascendant, we copy their interview process and ask algorithms questions. If you look around at trendy companies that are younger than Google, most of them basically copy their ranking/leveling system, with some minor tweaks. The good news is that, unlike many companies people previously copied, Google has put a lot of thought into most of their processes and made data driven decisions. The bad news is that Google is unique in a number of ways, which means that their reasoning often doesn't generalize, and that people often cargo cult practices long after they've become deprecated at Google.&lt;/p&gt;&lt;p&gt;This kind of diffusion happens for technical decisions, too. Stripe built a reliable message queue on top of Mongo, so we build reliable message queues on top of Mongo1. It's cargo cults all the way down2.&lt;/p&gt;&lt;p&gt;The paper has specific sub-sections on how to prevent normalization of deviance, which I recommend reading in full.&lt;/p&gt;&lt;p&gt;Let's look at how the first one of these, “pay attention to weak signals”, interacts with a single example, the “WTF WTF WTF” a new person gives off when the join the company.&lt;/p&gt;&lt;p&gt;If a VP decides something is screwed up, people usually listen. It's a strong signal. And when people don't listen, the VP knows what levers to pull to make things happen. But when someone new comes in, they don't know what levers they can pull to make things happen or who they should talk to almost by definition. They give out weak signals that are easily ignored. By the time they learn enough about the system to give out strong signals, they've acclimated.&lt;/p&gt;&lt;p&gt;“Pay attention to weak signals” sure sounds like good advice, but how do we do it? Strong signals are few and far between, making them easy to pay attention to. Weak signals are abundant. How do we filter out the ones that aren't important? And how do we get an entire team or org to actually do it? These kinds of questions can't be answered in a generic way; this takes real thought. We mostly put this thought elsewhere. Startups spend a lot of time thinking about growth, and while they'll all tell you that they care a lot about engineering culture, revealed preference shows that they don't. With a few exceptions, big companies aren't much different. At LCB, I looked through the competitive analysis slide decks and they're amazing. They look at every last detail on hundreds of products to make sure that everything is as nice for users as possible, from onboarding to interop with competing products. If there's any single screen where things are more complex or confusing than any competitor's, people get upset and try to fix it. It's quite impressive. And then when LCB onboards employees in my org, a third of them are missing at least one of, an alias/account, an office, or a computer, a condition which can persist for weeks or months. The competitive analysis slide decks talk about how important onboarding is because you only get one chance to make a first impression, and then employees are onboarded with the impression that the company couldn't care less about them and that it's normal for quotidian processes to be pervasively broken. LCB can't even to get the basics of employee onboarding right, let alone really complex things like acculturation. This is understandable — external metrics like user growth or attrition are measurable, and targets like how to tell if you're acculturating people so that they don't ignore weak signals are softer and harder to determine, but that doesn't mean they're any less important. People write a lot about how things like using fancier languages or techniques like TDD or agile will make your teams more productive, but having a strong engineering culture is much larger force multiplier.&lt;/p&gt;&lt;p&gt;Thanks to Sophie Smithburg and Marc Brooker for introducing me to the term Normalization of Deviance, and Kelly Eskridge, Leah Hanson, Sophie Rapoport, Sophie Smithburg, Julia Evans, Dmitri Kalintsev, Ralph Corderoy, Jamie Brandon, Egor Neliuba, and Victor Felder for comments/corrections/discussion.&lt;/p&gt;&lt;p&gt;People seem to think I'm joking here. I can understand why, but try Googling &lt;code&gt;mongodb message queue&lt;/code&gt;. You'll find statements like “replica sets in MongoDB work extremely well to allow automatic failover and redundancy”. Basically every company I know of that's done this and has anything resembling scale finds this to be non-optimal, to say the least, but you can't actually find blog posts or talks that discuss that. All you see are the posts and talks from when they first tried it and are in the honeymoon period. This is common with many technologies. You'll mostly find glowing recommendations in public even when, in private, people will tell you about all the problems. Today, if you do the search mentioned above, you'll get a ton of posts talking about how amazing it is to build a message queue on top of Mongo, this footnote, and a maybe couple of blog posts by Kyle Kingsbury depending on your exact search terms.&lt;/p&gt;&lt;p&gt;If there were an acute failure, you might see a postmortem, but while we'll do postmortems for "the site was down for 30 seconds", we rarely do postmortems for "this takes 10x as much ops effort as the alternative and it's a death by a thousand papercuts", "we architected this thing poorly and now it's very difficult to make changes that ought to be trivial", or "a competitor of ours was able to accomplish the same thing with an order of magnitude less effort". I'll sometimes do informal postmortems by asking everyone involved oblique questions about what happened, but more for my own benefit than anything else, because I'm not sure people really want to hear the whole truth. This is especially sensitive if the effort has generated a round of promotions, which seems to be more common the more screwed up the project. The larger the project, the more visibility and promotions, even if the project could have been done with much less effort.&lt;/p&gt;[return]&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45151661</guid></item><item><title>How the "Kim" dump exposed North Korea's credential theft playbook</title><link>https://dti.domaintools.com/inside-the-kimsuky-leak-how-the-kim-dump-exposed-north-koreas-credential-theft-playbook/</link><description>&lt;doc fingerprint="3599949f0a828e4a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Inside the Kimsuky Leak: How the “Kim” Dump Exposed North Korea’s Credential Theft Playbook&lt;/head&gt;
    &lt;p&gt;Contents:&lt;lb/&gt;Part I: Technical Analysis&lt;lb/&gt;Part II: Goals Analysis&lt;lb/&gt;Part III: Threat Intelligence Report&lt;/p&gt;
    &lt;head rend="h2"&gt;Executive Summary&lt;/head&gt;
    &lt;p&gt;A rare and revealing breach attributed to a North Korean-affiliated actor, known only as “Kim” as named by the hackers who dumped the data, has delivered a new insight into Kimsuky (APT43) tactics, techniques, and infrastructure. This actor’s operational profile showcases credential-focused intrusions targeting South Korean and Taiwanese networks, with a blending of Chinese-language tooling, infrastructure, and possible logistical support. The “Kim” dump, which includes bash histories, phishing domains, OCR workflows, compiled stagers, and rootkit evidence, reflects a hybrid operation situated between DPRK attribution and Chinese resource utilization.&lt;/p&gt;
    &lt;p&gt;This report is broken down into three parts:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Technical Analysis of the dump materials&lt;/item&gt;
      &lt;item&gt;Motivation and Goals of the APT actor (group)&lt;/item&gt;
      &lt;item&gt;A CTI report compartment for analysts&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;While this leak only gives a partial idea of what the Kimusky/PRC activities have been, the material provides insight into the expansion of activities, nature of the actor(s), and goals they have in their penetration of the South Korean governmental systems that would benefit not only DPRK, but also PRC.&lt;/p&gt;
    &lt;p&gt;Without a doubt, there will be more coming out from this dump in the future, particularly if the burned assets have not been taken offline and access is still available, or if others have cloned those assets for further analysis. We may revisit this in the future if additional novel information comes to light.&lt;/p&gt;
    &lt;head rend="h1"&gt;Part I: Technical Analysis&lt;/head&gt;
    &lt;head rend="h2"&gt;The Leak at a Glance&lt;/head&gt;
    &lt;p&gt;The leaked dataset attributed to the “Kim” operator offers a uniquely operational perspective into North Korean-aligned cyber operations. Among the contents were terminal history files revealing active malware development efforts using NASM (Netwide Assembler), a choice consistent with low-level shellcode engineering typically reserved for custom loaders and injection tools. These logs were not static forensic artifacts but active command-line histories showing iterative compilation and cleanup processes, suggesting a hands-on attacker directly involved in tool assembly.&lt;/p&gt;
    &lt;p&gt;In parallel, the operator ran OCR (Optical Character Recognition) commands against sensitive Korean PDF documents related to public key infrastructure (PKI) standards and VPN deployments. These actions likely aimed to extract structured language or configurations for use in spoofing, credential forgery, or internal tool emulation.&lt;/p&gt;
    &lt;p&gt;Privileged Access Management (PAM) logs also surfaced in the dump, detailing a timeline of password changes and administrative account use. Many were tagged with the Korean string 변경완료 (“change complete”), and the logs included repeated references to elevated accounts such as oracle, svradmin, and app_adm01, indicating sustained access to critical systems.&lt;/p&gt;
    &lt;p&gt;The phishing infrastructure was extensive. Domain telemetry pointed to a network of malicious sites designed to mimic legitimate Korean government portals. Sites like nid-security[.]com were crafted to fool users into handing over credentials via advanced AiTM (Adversary-in-the-Middle) techniques.&lt;/p&gt;
    &lt;p&gt;Finally, network artifacts within the dump showed targeted reconnaissance of Taiwanese government and academic institutions. Specific IP addresses and .tw domain access, along with attempts to crawl .git repositories, reveal a deliberate focus on high-value administrative and developer targets.&lt;/p&gt;
    &lt;p&gt;Perhaps most concerning was the inclusion of a Linux rootkit using syscall hooking (khook) and stealth persistence via directories like /usr/lib64/tracker-fs. This highlights a capability for deep system compromise and covert command-and-control operations, far beyond phishing and data theft.&lt;/p&gt;
    &lt;p&gt;Artifacts recovered from the dump include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Terminal history files demonstrating malware compilation using NASM&lt;/item&gt;
      &lt;item&gt;OCR commands parsing Korean PDF documents related to PKI and VPN infrastructure&lt;/item&gt;
      &lt;item&gt;PAM logs reflecting password changes and credential lifecycle events&lt;/item&gt;
      &lt;item&gt;Phishing infrastructure mimicking Korean government sites&lt;/item&gt;
      &lt;item&gt;IP addresses indicating reconnaissance of Taiwanese government and research institutions&lt;/item&gt;
      &lt;item&gt;Linux rootkit code using syscall hooking and covert channel deployment&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Credential Theft Focus&lt;/head&gt;
    &lt;p&gt;The dump strongly emphasizes credential harvesting as a central operational goal. Key files such as 136백운규001_env.key (The presence of 136백운규001_env.key is a smoking gun indicator of stolen South Korean Government PKI material, as its structure (numeric ID + Korean name + .key) aligns uniquely with SK GPKI issuance practices and provides clear evidence of compromised, identity-tied state cryptographic keys.) This was discovered alongside plaintext passwords, that indicate clear evidence of active compromise of South Korea’s GPKI (Government Public Key Infrastructure). Possession of such certificates would allow for highly effective identity spoofing across government systems.&lt;/p&gt;
    &lt;p&gt;PAM logs further confirmed this focus, showing a pattern of administrative account rotation and password resets, all timestamped and labeled with success indicators (변경완료: Change Complete). The accounts affected were not low-privilege; instead, usernames like oracle, svradmin, and app_adm01, often used by IT staff and infrastructure services, suggested access to core backend environments.&lt;/p&gt;
    &lt;p&gt;These findings point to a strategy centered on capturing and maintaining access to privileged credentials and digital certificates, effectively allowing the attacker to act as an insider within trusted systems.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Leaked .key files (e.g., 136백운규001_env.key) with plaintext passwords confirm access to GPKI systems&lt;/item&gt;
      &lt;item&gt;PAM logs show administrative password rotations tagged with 변경완료 (change complete)&lt;/item&gt;
      &lt;item&gt;Admin-level accounts such as oracle, svradmin, and app_adm01 repeatedly appear in compromised logs&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Phishing Infrastructure&lt;/head&gt;
    &lt;p&gt;The operator’s phishing infrastructure was both expansive and regionally tailored. Domains such as nid-security[.]com and webcloud-notice[.]com mimicked Korean identity and document delivery services, likely designed to intercept user logins or deploy malicious payloads. More sophisticated spoofing was seen in sites that emulated official government agencies like dcc.mil[.]kr, spo.go[.]kr, and mofa.go[.]kr.&lt;/p&gt;
    &lt;p&gt;Burner email usage added another layer of operational tradecraft. The address jeder97271[@]wuzak[.]com is likely linked to phishing kits that operated through TLS proxies, capturing credentials in real time as victims interacted with spoofed login forms.&lt;/p&gt;
    &lt;p&gt;These tactics align with previously known Kimsuky behaviors but also demonstrate an evolution in technical implementation, particularly the use of AiTM interception rather than relying solely on credential-harvesting documents.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Domains include: nid-security[.]com, html-load[.]com, webcloud-notice[.]com, koala-app[.]com, and wuzak[.]com&lt;/item&gt;
      &lt;item&gt;Mimicked portals: dcc.mil[.]kr, spo.go[.]kr, mofa.go[.]kr&lt;/item&gt;
      &lt;item&gt;Burner email evidence: jeder97271[@]wuzak[.]com&lt;/item&gt;
      &lt;item&gt;Phishing kits leveraged TLS proxies for AiTM credential capture&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Malware Development Activity&lt;/head&gt;
    &lt;p&gt;Kim’s malware development environment showcased a highly manual, tailored approach. Shellcode was compiled using NASM, specifically with flags like -f win32, revealing a focus on targeting Windows environments. Commands such as make and rm were used to automate and sanitize builds, while hashed API call resolution (VirtualAlloc, HttpSendRequestA, etc.) was implemented to evade antivirus heuristics.&lt;/p&gt;
    &lt;p&gt;The dump also revealed reliance on GitHub repositories known for offensive tooling. TitanLdr, minbeacon, Blacklotus, and CobaltStrike-Auto-Keystore were all cloned or referenced in command logs. This hybrid use of public frameworks for private malware assembly is consistent with modern APT workflows.&lt;/p&gt;
    &lt;p&gt;A notable technical indicator was the use of the proxyres library to extract Windows proxy settings, particularly via functions like proxy_config_win_get_auto_config_url. This suggests an interest in hijacking or bypassing network-level security controls within enterprise environments.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Manual shellcode compilation via nasm -f win32 source/asm/x86/start.asm&lt;/item&gt;
      &lt;item&gt;Use of make, rm, and hash obfuscation of Win32 API calls (e.g., VirtualAlloc, HttpSendRequestA)&lt;/item&gt;
      &lt;item&gt;GitHub tools in use: TitanLdr, minbeacon, Blacklotus, CobaltStrike-Auto-Keystore&lt;/item&gt;
      &lt;item&gt;Proxy configuration probing through proxyres library (proxy_config_win_get_auto_config_url)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Rootkit Toolkit and Implant Structure&lt;/head&gt;
    &lt;p&gt;The Kim dump offers deep insight into a stealthy and modular Linux rootkit attributed to the operator’s post-compromise persistence tactics. The core implant, identified as vmmisc.ko (alternatively VMmisc.ko in some shells), was designed for kernel-mode deployment across multiple x86_64 Linux distributions and utilizes classic syscall hooking and covert channeling to maintain long-term undetected access.&lt;/p&gt;
    &lt;head rend="h3"&gt;Google Translation of Koh doc: Rootkit Endpoint Reuse Authentication Tool&lt;/head&gt;
    &lt;p&gt;“This tool uses kernel-level rootkit hiding technology, providing a high degree of stealth and penetration connection capability. It can hide while running on common Linux systems, and at the kernel layer supports connection forwarding, allowing reuse of external ports to connect to controlled hosts. Its communication behavior is hidden within normal traffic.&lt;/p&gt;
    &lt;p&gt;The tool uses binary merging technology: at compile time, the application layer program is encrypted and fused into a .ko driver file. When installed, only the .ko file exists. When the .ko driver starts, it will automatically decompress and release the hidden application-layer program.&lt;/p&gt;
    &lt;p&gt;Tools like chkrootkit, rkhunter, and management utilities (such as ps, netstat, etc.) are bypassed through technical evasion and hiding, making them unable to detect hidden networks, ports, processes, or file information.&lt;/p&gt;
    &lt;p&gt;To ensure software stability, all functions have also passed stress testing.&lt;/p&gt;
    &lt;p&gt;Supported systems: Linux Kernel 2.6.x / 3.x / 4.x, both x32 and x64 systems”.&lt;/p&gt;
    &lt;p&gt;Implant Features and Behavior&lt;/p&gt;
    &lt;p&gt;This rootkit exhibits several advanced features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Syscall Hooking: Hooks critical kernel functions (e.g., getdents, read, write) to hide files, directories, and processes by name or PID.&lt;/item&gt;
      &lt;item&gt;SOCKS5 Proxy: Integrated remote networking capability using dynamic port forwarding and chained routing.&lt;/item&gt;
      &lt;item&gt;PTY Backdoor Shell: Spawns pseudoterminals that operate as interactive reverse shells with password protection.&lt;/item&gt;
      &lt;item&gt;Encrypted Sessions: Session commands must match a pre-set passphrase (e.g., testtest) to activate rootkit control mode.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Once installed (typically using insmod vmmisc.ko), the rootkit listens silently and allows manipulation via an associated client binary found in the dump. The client supports an extensive set of interactive commands, including:&lt;/p&gt;
    &lt;p&gt;+p # list hidden processes&lt;/p&gt;
    &lt;p&gt;+f # list hidden files&lt;/p&gt;
    &lt;p&gt;callrk # load client ↔ kernel handshake&lt;/p&gt;
    &lt;p&gt;exitrk # gracefully unload implant&lt;/p&gt;
    &lt;p&gt;shell # spawn reverse shell&lt;/p&gt;
    &lt;p&gt;socks5 # initiate proxy channel&lt;/p&gt;
    &lt;p&gt;upload / download # file transfer interface&lt;/p&gt;
    &lt;p&gt;These capabilities align closely with known DPRK malware behaviors, particularly from the Kimsuky and Lazarus groups, who have historically leveraged rootkits for lateral movement, stealth, persistence, and exfiltration staging.&lt;/p&gt;
    &lt;head rend="h2"&gt;Observed Deployment&lt;/head&gt;
    &lt;p&gt;Terminal history (.bash_history) shows the implant was staged and tested from the following paths:&lt;/p&gt;
    &lt;code&gt;.cache/vmware/drag_and_drop/VMmisc.ko

/usr/lib64/tracker-fs/vmmisc.ko

Execution logs show the use of commands such as:

insmod /usr/lib64/tracker-fs/vmmisc.ko

./client 192.168.0[.]39 testtest&lt;/code&gt;
    &lt;p&gt;These paths were not random—they mimic legitimate system service locations to avoid detection by file integrity monitoring (FIM) tools.&lt;/p&gt;
    &lt;p&gt;This structure highlights the modular, command-activated nature of the implant and its ability to serve multiple post-exploitation roles while maintaining stealth through kernel-layer masking.&lt;/p&gt;
    &lt;head rend="h2"&gt;Strategic Implications&lt;/head&gt;
    &lt;p&gt;The presence of such an advanced toolkit in the “Kim” dump strongly suggests the actor had persistent access to Linux server environments, likely via credential compromise. The use of kernel-mode implants also indicates long-term intent and trust-based privilege escalation. The implant’s pathing, language patterns, and tactics (e.g., use of /tracker-fs/, use of test passwords) match TTPs previously observed in operations attributed to Kimsuky, enhancing confidence in North Korean origin.&lt;/p&gt;
    &lt;head rend="h2"&gt;OCR-Based Recon&lt;/head&gt;
    &lt;p&gt;A defining component of Kim’s tradecraft was the use of OCR to analyze Korean-language security documentation. The attacker issued commands such as ocrmypdf -l kor+eng “file.pdf” to parse documents like 별지2)행정전자서명_기술요건_141125.pdf (“Appendix 2: Administrative Electronic Signature_Technical Requirements_141125.pdf”) and SecuwaySSL U_카달로그.pdf (“SecuwaySSL U_Catalog.pdf”). These files contain technical language around digital signatures, SSL implementations, and identity verification standards used in South Korea’s PKI infrastructure.&lt;/p&gt;
    &lt;p&gt;This OCR-based collection approach indicates more than passive intelligence gathering – it reflects a deliberate effort to model and potentially clone government-grade authentication systems. The use of bilingual OCR (Korean + English) further confirms the operator’s intention to extract usable configuration data across documentation types.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;OCR commands used to extract Korean PKI policy language from PDFs such as (별지2)행정전자서명_기술요건_141125.pdf and SecuwaySSL U_카달로그.pdf &lt;list rend="ul"&gt;&lt;item&gt;별지2)행정전자서명_기술요건_141125.pdf → (Appendix 2: Administrative Electronic Signature_Technical Requirements_141125.pdf&lt;/item&gt;&lt;item&gt;SecuwaySSL U_카달로그.pdf → SecuwaySSL U_Catalog.pdf&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Command examples: ocrmypdf -l kor+eng “file.pdf”&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;SSH and Log-Based Evidence&lt;/head&gt;
    &lt;p&gt;The forensic evidence contained within the logs, specifically SSH authentication records and PAM outputs, provides clear technical confirmation of the operator’s tactics and target focus.&lt;/p&gt;
    &lt;p&gt;Several IP addresses stood out as sources of brute-force login attempts. These include 23.95.213[.]210 (a known VPS provider used in past credential-stuffing campaigns), 218.92.0[.]210 (allocated to a Chinese ISP), and 122.114.233[.]77 (Henan Mobile, China). These IPs were recorded during multiple failed login events, strongly suggesting automated password attacks against exposed SSH services. Their geographic distribution and known history in malicious infrastructure usage point to an external staging environment, possibly used for pivoting into Korean and Taiwanese systems.&lt;/p&gt;
    &lt;p&gt;Beyond brute force, the logs also contain evidence of authentication infrastructure reconnaissance. Multiple PAM and OCSP (Online Certificate Status Protocol) errors referenced South Korea’s national PKI authority, including domains like gva.gpki.go[.]kr and ivs.gpki.go[.]kr. These errors appear during scripted or automated access attempts, indicating a potential strategy of credential replay or certificate misuse against GPKI endpoints, an approach that aligns with Kim’s broader PKI-targeting operations.&lt;/p&gt;
    &lt;p&gt;Perhaps the most revealing detail was the presence of successful superuser logins labeled with the Korean term 최고 관리자 (“Super Administrator”). This suggests the actor was not just harvesting credentials but successfully leveraging them for privileged access, possibly through cracked accounts, reused credentials, or insider-sourced passwords. The presence of such accounts in conjunction with password rotation entries marked as 변경완료 (“change complete”) further implies active control over PAM-protected systems during the operational window captured in the dump.&lt;/p&gt;
    &lt;p&gt;Together, these logs demonstrate a methodical campaign combining external brute-force access, PKI service probing, and administrative credential takeover, a sequence tailored for persistent infiltration and lateral movement within sensitive government and enterprise networks.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Brute-force IPs: 23.95.213[.]210, 218.92.0[.]210, 122.114.233[.]77&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;IP Address&lt;/cell&gt;
        &lt;cell&gt;Origin&lt;/cell&gt;
        &lt;cell&gt;Role / Threat Context&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;218.92.0[.]210&lt;/cell&gt;
        &lt;cell&gt;China Telecom (Jiangsu)&lt;/cell&gt;
        &lt;cell&gt;Part of Chinanet backbone, likely proxy or scanning node&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;23.95.213[.]210&lt;/cell&gt;
        &lt;cell&gt;Colocrossing (US)&lt;/cell&gt;
        &lt;cell&gt;Frequently used in brute-force and anonymized hosting for malware ops&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;122.114.233[.]77&lt;/cell&gt;
        &lt;cell&gt;Presumed PRC local ISP&lt;/cell&gt;
        &lt;cell&gt;Possibly mobile/ISP-based proxy used to obfuscate lateral movement&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PAM/OCSP errors targeting gva.gpki.go[.]kr, ivs.gpki.go[.]kr&lt;/item&gt;
      &lt;item&gt;Superuser login events under 최고 관리자 (Super Administrator)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Part II: Goals Analysis&lt;/head&gt;
    &lt;head rend="h2"&gt;Targeting South Korea: Identity, Infrastructure, and Credential Theft&lt;/head&gt;
    &lt;p&gt;The “Kim” operator’s campaign against South Korea was deliberate and strategic, aiming to infiltrate the nation’s digital trust infrastructure at multiple levels. A central focus was the Government Public Key Infrastructure (GPKI), where the attacker exfiltrated certificate files, including .key and .crt formats, some with plaintext passwords, and attempted repeated authentication against domains like gva.gpki.go[.]kr and ivs.gpki.go[.]kr. OCR tools were used to parse Korean technical documents detailing PKI and VPN architectures, demonstrating a sophisticated effort to understand and potentially subvert national identity frameworks. These efforts were not limited to reconnaissance; administrative password changes were logged, and phishing kits targeted military and diplomatic webmail, including clones of mofa.go[.]kr and credential harvesting through adversary-in-the-middle (AiTM) proxy setups.&lt;/p&gt;
    &lt;p&gt;Beyond authentication systems, Kim targeted privileged accounts (oracle, unwadm, svradmin) and rotated credentials to maintain persistent administrative access, as evidenced by PAM and SSH logs showing elevated user activity under the title 최고 관리자 (“Super Administrator”). The actor also showed interest in bypassing VPN controls, parsing SecuwaySSL configurations for exploitation potential, and deployed custom Linux rootkits using syscall hooking to establish covert persistence on compromised machines. Taken together, the dump reveals a threat actor deeply invested in credential dominance, policy reconnaissance, and system-level infiltration, placing South Korea’s public sector identity systems, administrative infrastructure, and secure communications at the core of its long-term espionage objectives.&lt;/p&gt;
    &lt;head rend="h2"&gt;Taiwan Reconnaissance&lt;/head&gt;
    &lt;p&gt;Among the most notable aspects of the “Kim” leak is the operator’s deliberate focus on Taiwanese infrastructure. The attacker accessed a number of domains with clear affiliations to the island’s public and private sectors, including tw.systexcloud[.]com (linked to enterprise cloud solutions), mlogin.mdfapps[.]com (a mobile authentication or enterprise login portal), and the .git/ directory of caa.org[.]tw, which belongs to the Chinese Institute of Aeronautics, a government-adjacent research entity.&lt;/p&gt;
    &lt;p&gt;This last domain is especially telling. Accessing .git/ paths directly implies an attempt to enumerate internal source code repositories, a tactic often used to discover hardcoded secrets, API keys, deployment scripts, or developer credentials inadvertently exposed via misconfigured web servers. This behavior points to more technical depth than simple phishing; it indicates supply chain reconnaissance and long-term infiltration planning.&lt;/p&gt;
    &lt;p&gt;The associated IP addresses further reinforce this conclusion. All three, 163.29.3[.]119, 118.163.30[.]45, and 59.125.159[.]81, are registered to academic, government, or research backbone providers in Taiwan. These are not random scans; they reflect targeted probing of strategic digital assets.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary of Whois &amp;amp; Ownership Insights&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;118.163.30[.]45 &lt;list rend="ul"&gt;&lt;item&gt;Appears as part of the IP range used for the domain dtc-tpe.com[.]tw, linked to Taiwan’s HINET provider (118.163.30[.]46 )Site Indices page of HINET provider.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;163.29.3[.]119 &lt;list rend="ul"&gt;&lt;item&gt;Falls within the 163.29.3[.]0/24 subnet identified with Taiwanese government or institutional use, notably in Taipei. This corresponds to B‑class subnets assigned to public/government entities IP地址 (繁體中文).&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;59.125.159[.]81&lt;list rend="ul"&gt;&lt;item&gt;Belongs to the broader 59.125.159[.]0–59.125.159[.]254 block, commonly used by Taiwanese ISP operators such as Chunghwa Telecom in Taipei&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Taken together, this Taiwan-focused activity reveals an expanded operational mandate. Whether the attacker is purely DPRK-aligned or operating within a DPRK–PRC fusion cell, the intent is clear: compromise administrative and developer infrastructure in Taiwan, likely in preparation for broader credential theft, espionage, or disruption campaigns.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Targeted domains: tw.systexcloud[.]com, caa.org[.]tw/.git/, mlogin.mdfapps[.]com&lt;/item&gt;
      &lt;item&gt;IPs linked to Taiwanese academic/government assets: 163.29.3[.]119, 118.163.30[.]45, 59.125.159[.]81&lt;/item&gt;
      &lt;item&gt;Git crawling suggests interest in developer secrets or exposed tokens&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Hybrid Attribution Model&lt;/head&gt;
    &lt;p&gt;The “Kim” operator embodies the growing complexity of modern nation-state attribution, where cyber activities often blur traditional boundaries and merge capabilities across geopolitical spheres. This case reveals strong indicators of both North Korean origin and Chinese operational entanglement, presenting a textbook example of a hybrid APT model.&lt;/p&gt;
    &lt;p&gt;On one hand, the technical and linguistic evidence strongly supports a DPRK-native operator. Terminal environments, OCR parsing routines, and system artifacts consistently leverage Korean language and character sets. The operator’s activities reflect a deep understanding of Korean PKI systems, with targeted extraction of GPKI .key files and automation to parse sensitive Korean government PDF documentation. These are hallmarks of Kimsuky/APT43 operations, known for credential-focused espionage against South Korean institutions and diplomatic targets. The intent to infiltrate identity infrastructure is consistent with North Korea’s historical targeting priorities. Notably, the system time zone on Kim’s host machine was set to UTC+9 (Pyongyang Standard Time), reinforcing the theory that the actor maintains direct ties to the DPRK’s internal environment, even if operating remotely.&lt;/p&gt;
    &lt;p&gt;However, this actor’s digital footprint extends well into Chinese infrastructure. Browser and download logs reveal frequent interaction with platforms like gitee[.]com, baidu[.]com, and zhihu[.]com, highly popular within the PRC but unusual for DPRK operators who typically minimize exposure to foreign services. Moreover, session logs include simplified Chinese content and PRC browsing behaviors, suggesting that the actor may be physically operating within China or through Chinese-language systems. This aligns with longstanding intelligence on North Korean cyber operators stationed in Chinese border cities such as Shenyang and Dandong, where DPRK nationals often conduct cyber operations with tacit approval or logistical consent from Chinese authorities. These locations provide higher-speed internet, relaxed oversight, and convenient geopolitical proximity.&lt;/p&gt;
    &lt;p&gt;The targeting of Taiwanese infrastructure further complicates attribution. Kimsuky has not historically prioritized Taiwan, yet in this case, the actor demonstrated direct reconnaissance of Taiwanese government and developer networks. While this overlaps with Chinese APT priorities, recent evidence from the “Kim” dump, including analysis of phishing kits and credential theft workflows, suggests this activity was likely performed by a DPRK actor exploring broader regional interests, possibly in alignment with Chinese strategic goals. Researchers have noted that Kimsuky operators have recently asked questions in phishing lures related to potential Chinese-Taiwanese conflicts, implying interest beyond the Korean peninsula.&lt;/p&gt;
    &lt;p&gt;Some tooling overlaps with PRC-linked APTs, particularly GitHub-based stagers and proxy-resolving modules, but these are not uncommon in the open-source malware ecosystem and may reflect opportunistic reuse rather than deliberate mimicry.&lt;/p&gt;
    &lt;head rend="h2"&gt;IMINT Analysis: Visual Tradecraft and Cultural Camouflage&lt;/head&gt;
    &lt;p&gt;A review of image artifacts linked to the “Kim” actor reveals a deliberate and calculated use of Chinese social and technological visual content as part of their operational persona. These images, extracted from browser history and uploads attributed to the actor, demonstrate both strategic alignment with DPRK priorities and active cultural camouflage within the PRC digital ecosystem.&lt;/p&gt;
    &lt;p&gt;The visual set includes promotional graphics for Honor smartphones, SoC chipset evolution charts, Weibo posts featuring vehicle registration certificates, meme-based sarcasm, and lifestyle imagery typical of Chinese internet users. Notably, the content is exclusively rendered in simplified Chinese, reinforcing prior assessments that the operator either resides within mainland China or maintains a working digital identity embedded in Chinese platforms. Devices and services referenced, such as Xiaomi phones, Zhihu, Weibo, and Baidu, suggest intimate familiarity with PRC user environments.&lt;/p&gt;
    &lt;p&gt;Operationally, this behavior achieves two goals. First, it enables the actor to blend in seamlessly with native PRC user activity, which complicates attribution and helps bypass platform moderation or behavioral anomaly detection. Second, the content itself may serve as bait or credibility scaffolding (e.g. A framework to give the illusion of trust to allow for easier compromise ) in phishing and social engineering campaigns, especially those targeting developers or technical users on Chinese-language platforms.&lt;/p&gt;
    &lt;p&gt;Some images, such as the detailed chipset timelines and VPN or device certification posts, suggest a continued interest in supply chain reconnaissance and endpoint profiling—both tradecraft hallmarks of Kimsuky and similar APT units. Simultaneously, meme humor, sarcastic overlays, and visual metaphors (e.g., the “Kaiju’s tail is showing” idiom) indicate the actor’s fluency in PRC netizen culture and possible mockery of operational security breaches—whether their own or others’.&lt;/p&gt;
    &lt;p&gt;Taken together, this IMINT corpus supports the broader attribution model: a DPRK-origin operator embedded, physically or virtually, within the PRC, leveraging local infrastructure and social platforms to facilitate long-term campaigns against South Korea, Taiwan, and other regional targets while maintaining cultural and technical deniability.&lt;/p&gt;
    &lt;head rend="h2"&gt;Attribution Scenarios:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Option A: DPRK Operator Embedded in PRC&lt;list rend="ul"&gt;&lt;item&gt;Use of Korean language, OCR targeting of Korean documents, and focus on GPKI systems strongly suggest North Korean origin.&lt;/item&gt;&lt;item&gt;Use of PRC infrastructure (e.g., Baidu, Gitee) and simplified Chinese content implies the operator is physically located in China or benefits from access to Chinese internet infrastructure.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Use of Korean language, OCR targeting of Korean documents, and focus on GPKI systems strongly suggest North Korean origin.&lt;/item&gt;
      &lt;item&gt;Option B: PRC Operator Emulating DPRK&lt;list rend="ul"&gt;&lt;item&gt;Taiwan-focused reconnaissance aligns with PRC cyber priorities.&lt;/item&gt;&lt;item&gt;Use of open-source tooling and phishing methods shared with PRC APTs could indicate tactical emulation.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Taiwan-focused reconnaissance aligns with PRC cyber priorities.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The preponderance of evidence supports the hypothesis that “Kim” is a North Korean cyber operator embedded in China or collaborating with PRC infrastructure providers. This operational model allows the DPRK to amplify its reach, mask attribution, and adopt regional targeting strategies beyond South Korea, particularly toward Taiwan. As this hybrid model matures, it reflects the strategic adaptation of DPRK-aligned threat actors who exploit the permissive digital environment of Chinese networks to evade detection and expand their operational playbook.&lt;/p&gt;
    &lt;head rend="h2"&gt;Targeting Profiles&lt;/head&gt;
    &lt;p&gt;The “Kim” leak provides one of the clearest windows to date into the role-specific targeting preferences of the operator, revealing a deliberate focus on system administrators, credential issuers, and backend developers, particularly in South Korea and Taiwan.&lt;/p&gt;
    &lt;p&gt;In South Korea, the operator’s interest centers around PKI administrators and infrastructure engineers. The recovered OCR commands were used to extract technical details from PDF documents outlining Korea’s digital signature protocols, such as identity verification, certificate validation, and encrypted communications, components that form the backbone of Korea’s secure authentication systems. The goal appears to be not only credential theft but full understanding and potential replication of government-trusted PKI procedures. This level of targeting suggests a strategic intent to penetrate deeply trusted systems, potentially for use in later spoofing or identity masquerading operations.&lt;/p&gt;
    &lt;p&gt;In Taiwan, the operator shifted focus to developer infrastructure and cloud access portals. Specific domains accessed, like caa.org[.]tw/.git/, indicate attempts to enumerate internal repositories, most likely to discover hardcoded secrets, authentication tokens, or deployment keys. This is a classic supply chain targeting method, aiming to access downstream systems via compromised developer credentials or misconfigured services.&lt;/p&gt;
    &lt;p&gt;Additional activity pointed to interaction with cloud service login panels such as tw.systexcloud[.]com and mlogin.mdfapps[.]com. These suggest an attempt to breach centralized authentication systems or identity providers, granting the actor broader access into enterprise or government networks with a single credential set.&lt;/p&gt;
    &lt;p&gt;Taken together, these targeting profiles reflect a clear emphasis on identity providers, backend engineers, and those with access to system-level secrets. This reinforces the broader theme of the dump: persistent, credential-first intrusion strategies, augmented by reconnaissance of authentication standards, key management policies, and endpoint development infrastructure.&lt;/p&gt;
    &lt;p&gt;South Korean:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PKI admins, infrastructure engineers&lt;/item&gt;
      &lt;item&gt;OCR focus on Korean identity standards&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Taiwanese:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Developer endpoints and internal .git/ repos&lt;/item&gt;
      &lt;item&gt;Access to cloud panels and login gateways&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Final Assessment&lt;/head&gt;
    &lt;p&gt;The “Kim” leak represents one of the most comprehensive and technically intimate disclosures ever associated with Kimsuky (APT43) or its adjacent operators. It not only reaffirms known tactics, credential theft, phishing, and PKI compromise, but exposes the inner workings of the operator’s environment, tradecraft, and operational intent in ways rarely observed outside of active forensic investigations.&lt;/p&gt;
    &lt;p&gt;At the core of the leak is a technically competent actor, well-versed in low-level shellcode development, Linux-based persistence mechanisms, and certificate infrastructure abuse. Their use of NASM, API hashing, and rootkit deployment points to custom malware authorship. Furthermore, the presence of parsed government-issued Korean PDFs, combined with OCR automation, shows not just opportunistic data collection but a concerted effort to model, mimic, or break state-level identity systems, particularly South Korea’s GPKI.&lt;/p&gt;
    &lt;p&gt;The operator’s cultural and linguistic fluency in Korean, and their targeting of administrative and privileged systems across South Korean institutions, support a high-confidence attribution to a DPRK-native threat actor. However, the extensive use of Chinese platforms like gitee[.]com, Baidu, and Zhihu, and Chinese infrastructure for both malware hosting and browsing activity reveals a geographical pivot or collaboration: a hybrid APT footprint rooted in DPRK tradecraft but operating from or with Chinese support.&lt;/p&gt;
    &lt;p&gt;Most notably, this leak uncovers a geographical expansion of operational interest; the actor is no longer solely focused on the Korean peninsula. The targeting of Taiwanese developer portals, government research IPs, and .git/ repositories shows a broadened agenda that likely maps to both espionage and supply chain infiltration priorities. This places Taiwan, like South Korea, at the forefront of North Korean cyber interest, whether for intelligence gathering, credential hijacking, or as staging points for more complex campaigns.&lt;/p&gt;
    &lt;p&gt;The threat uncovered here is not merely malware or phishing; it is an infrastructure-centric, credential-first APT campaign that blends highly manual operations (e.g., hand-compiled shellcode, direct OCR of sensitive PDFs) with modern deception tactics such as AiTM phishing and TLS proxy abuse.&lt;/p&gt;
    &lt;p&gt;Organizations in Taiwan and South Korea, particularly those managing identity, certificate, and cloud access infrastructure, should consider themselves under persistent, credential-focused surveillance. Defensive strategies must prioritize detection of behavioral anomalies (e.g., use of OCR tools, GPKI access attempts), outbound communications with spoofed Korean domains, and the appearance of low-level toolchains like NASM or proxyres-based scanning utilities within developer or admin environments.&lt;/p&gt;
    &lt;p&gt;In short: the “Kim” actor embodies the evolution of nation-state cyber threats—a fusion of old-school persistence, credential abuse, and modern multi-jurisdictional staging. The threat is long-term, embedded, and adaptive.&lt;/p&gt;
    &lt;head rend="h1"&gt;Part III: Threat Intelligence Report&lt;/head&gt;
    &lt;head rend="h2"&gt;TLP WHITE:&lt;/head&gt;
    &lt;head rend="h3"&gt;Targeting Summary&lt;/head&gt;
    &lt;p&gt;The analysis of the “Kim” operator dump reveals a highly focused credential-theft and infrastructure-access campaign targeting high-value assets in both South Korea and Taiwan. Victims were selected based on their proximity to trusted authentication systems, administrative control panels, and development environments.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Category&lt;/cell&gt;
        &lt;cell&gt;Details&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Regions&lt;/cell&gt;
        &lt;cell&gt;South Korea, Taiwan&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Targets&lt;/cell&gt;
        &lt;cell&gt;Government, Telecom, Enterprise IT&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Accounts&lt;/cell&gt;
        &lt;cell&gt;svradmin, oracle, app_adm01, unwadm, shkim88, jaejung91&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Domains&lt;/cell&gt;
        &lt;cell&gt;tw.systexcloud[.]com, nid-security[.]com, spo.go[.]kr, caa.org[.]tw/.git/&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Indicators of Compromise (IOCs)&lt;/head&gt;
    &lt;head rend="h4"&gt;Domains&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Phishing: nid-security[.]com, html-load[.]com, wuzak[.]com, koala-app[.]com, webcloud-notice[.]com&lt;/item&gt;
      &lt;item&gt;Spoofed portals: dcc.mil[.]kr, spo.go[.]kr, mofa.go[.]kr&lt;/item&gt;
      &lt;item&gt;Pastebin raw links: Used for payload staging and malware delivery&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;IP Addresses&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;External Targets (Taiwan): &lt;list rend="ul"&gt;&lt;item&gt;163.29.3[.]119 National Center for High-performance Computing&lt;/item&gt;&lt;item&gt;118.163.30[.]45 Taiwanese government subnet&lt;/item&gt;&lt;item&gt;59.125.159[.]81 Chunghwa Telecom&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Brute Forcing / Infrastructure Origins: &lt;list rend="ul"&gt;&lt;item&gt;23.95.213[.]210 VPS provider with malicious history&lt;/item&gt;&lt;item&gt;218.92.0[.]210 China Unicom&lt;/item&gt;&lt;item&gt;122.114.233[.]77 Henan Mobile, PRC&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Internal Host IPs (Operator Environment)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;192.168.130[.]117&lt;/item&gt;
      &lt;item&gt;192.168.150[.]117&lt;/item&gt;
      &lt;item&gt;192.168.0[.]39&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Operator Environment: Internal Host IP Narrative&lt;/head&gt;
    &lt;p&gt;The presence of internal IP addresses such as 192.168.130[.]117, 192.168.150[.]117, and 192.168.0[.]39 within the dump offers valuable insight into the attacker’s local infrastructure, an often-overlooked element in threat intelligence analysis. These addresses fall within private, non-routable RFC1918 address space, commonly assigned by consumer off-the-shelf (COTS) routers and small office/home office (SOHO) network gear.&lt;/p&gt;
    &lt;p&gt;The use of the 192.168.0[.]0/16 subnet, particularly 192.168.0.x and 192.168.150.x, strongly suggests that the actor was operating from a residential or low-profile environment, not a formal nation-state facility or hardened infrastructure. This supports existing assessments that North Korean operators, particularly those affiliated with Kimsuky, often work remotely from locations in third countries such as China or Southeast Asia, where they can maintain inconspicuous, low-cost setups while accessing global infrastructure.&lt;/p&gt;
    &lt;p&gt;Moreover, the distinction between multiple internal subnets (130.x, 150.x, and 0.x) may indicate segmentation of test environments or multiple virtual machines running within a single NATed network. This aligns with the forensic evidence of iterative development and testing workflows seen in the .bash_history files, where malware stagers, rootkits, and API obfuscation utilities were compiled, cleaned, and rerun repeatedly.&lt;/p&gt;
    &lt;p&gt;Together, these IPs reveal an operator likely working from a clandestine, residential base of operations, with modest hardware and commercial-grade routers. This operational setup is consistent with known DPRK remote IT workers and cyber operators who avoid attribution by blending into civilian infrastructure. It also suggests the attacker may be physically located outside of North Korea, possibly embedded in a friendly or complicit environment, strengthening the case for China-based activity by DPRK nationals.&lt;/p&gt;
    &lt;head rend="h3"&gt;MITRE ATT&amp;amp;CK Mapping&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Phase&lt;/cell&gt;
        &lt;cell&gt;Technique(s)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Initial Access&lt;/cell&gt;
        &lt;cell&gt;T1566.002 , Adversary-in-the-Middle (AiTM) Phishing&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Execution&lt;/cell&gt;
        &lt;cell&gt;T1059.005 , Native API ShellcodeT1059.003 , Bash/Shell Scripts&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Credential Access&lt;/cell&gt;
        &lt;cell&gt;T1555 , Credential Store DumpingT1557.003 , Session Hijacking&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Persistence&lt;/cell&gt;
        &lt;cell&gt;T1176 , Rootkit (via khook syscall manipulation)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Defense Evasion&lt;/cell&gt;
        &lt;cell&gt;T1562.001 , Disable Security ToolsT1552 , Unsecured Credential Files&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Discovery&lt;/cell&gt;
        &lt;cell&gt;T1592 , Technical Information DiscoveryT1590 , Network Information&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Exfiltration&lt;/cell&gt;
        &lt;cell&gt;T1041 , Exfiltration over C2 ChannelT1567.002 , Exfil via Cloud Services&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Tooling and Capabilities&lt;/head&gt;
    &lt;p&gt;The actor’s toolkit spans multiple disciplines, blending malware development, system reconnaissance, phishing, and proxy evasion:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;NASM-based shellcode loaders: Compiled manually for Windows execution.&lt;/item&gt;
      &lt;item&gt;Win32 API hashing: Obfuscated imports via hashstring.py to evade detection.&lt;/item&gt;
      &lt;item&gt;GitHub/Gitee abuse: Tooling hosted or cloned from public developer platforms.&lt;/item&gt;
      &lt;item&gt;OCR exploitation: Used ocrmypdf to parse Korean PDF specs related to digital certificates and VPN appliances.&lt;/item&gt;
      &lt;item&gt;Rootkit deployment: Hidden persistence paths including /usr/lib64/tracker-fs and /proc/acpi/pcicard.&lt;/item&gt;
      &lt;item&gt;Proxy config extraction: Investigated PAC URLs using proxyres-based recon.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Attribution Confidence Assessment&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Attribution Candidate&lt;/cell&gt;
        &lt;cell&gt;Confidence Level&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;DPRK-aligned (Kimsuky)&lt;/cell&gt;
        &lt;cell&gt;High, Native Korean targeting, GPKI focus, OCR behavior&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;China-blended infrastructure&lt;/cell&gt;
        &lt;cell&gt;Moderate, PRC hosting, Gitee usage, Taiwan focus&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Solely PRC Actor&lt;/cell&gt;
        &lt;cell&gt;Low-to-Moderate, Tooling overlap but weak linguistic match&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Assessment: The actor appears to be a DPRK-based APT operator working from within or in partnership with Chinese infrastructure, representing a hybrid attribution model.&lt;/p&gt;
    &lt;head rend="h3"&gt;Defensive Recommendations&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Area&lt;/cell&gt;
        &lt;cell&gt;Recommendation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;PKI Security&lt;/cell&gt;
        &lt;cell&gt;Monitor usage of .key, .sig, .crt artifacts; enforce HSM or 2FA for key use&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Phishing Defense&lt;/cell&gt;
        &lt;cell&gt;Block domains identified in IoCs; validate TLS fingerprints and referrer headers&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Endpoint Hardening&lt;/cell&gt;
        &lt;cell&gt;Detect use of nasm, make, and OCR tools; monitor /usr/lib*/tracker-* paths&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Network Telemetry&lt;/cell&gt;
        &lt;cell&gt;Alert on .git/ directory access from external IPs; monitor outbound to Pastebin/GitHub&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Taiwan Focus&lt;/cell&gt;
        &lt;cell&gt;Establish watchlists for .tw domains targeted by PRC-originating IPs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Admin Accounts&lt;/cell&gt;
        &lt;cell&gt;Review usage logs for svradmin, oracle, app_adm01, and ensure rotation policies&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h1"&gt;APPENDIX A&lt;/head&gt;
    &lt;head rend="h2"&gt;Overlap or Confusion with Chinese Threat Actors&lt;/head&gt;
    &lt;p&gt;There is notable evidence of operational blur between Kimsuky and Chinese APTs in the context of Taiwan. The 2025 “Kim” data breach revealed an attacker targeting Taiwan whose tools and phishing kits matched Kimsuky’s, yet whose personal indicators (language, browsing habits) suggested a Chinese national. Researchers concluded this actor was likely a Chinese hacker either mimicking Kimsuky tactics or collaborating with them.. In fact, the leaked files on DDoS Secrets hint that Kimsuky has “openly cooperated with other Chinese APTs and shared their tools and techniques”. This overlap can cause attribution confusion – a Taiwan-focused operation might initially be blamed on China but could involve Kimsuky elements, or vice versa. So far, consensus is that North Korean and Chinese cyber operations remain separate, but cases like “Kim” show how a DPRK-aligned actor can operate against Taiwan using TTPs common to Chinese groups, muddying the waters of attribution.&lt;/p&gt;
    &lt;head rend="h2"&gt;File List from dump:&lt;/head&gt;
    &lt;head rend="h2"&gt;Master Evidence Inventory:&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;File Name&lt;/cell&gt;
        &lt;cell&gt;Language&lt;/cell&gt;
        &lt;cell&gt;Content Summary&lt;/cell&gt;
        &lt;cell&gt;Category&lt;/cell&gt;
        &lt;cell&gt;Relevance&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;.bash_history&lt;/cell&gt;
        &lt;cell&gt;Mixed (EN/KR)&lt;/cell&gt;
        &lt;cell&gt;Operator shell history commands&lt;/cell&gt;
        &lt;cell&gt;System/Log&lt;/cell&gt;
        &lt;cell&gt;Shows rootkit compilation, file ops, network tests&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;user-bash_history&lt;/cell&gt;
        &lt;cell&gt;Mixed (EN/KR)&lt;/cell&gt;
        &lt;cell&gt;User-level shell commands&lt;/cell&gt;
        &lt;cell&gt;System/Log&lt;/cell&gt;
        &lt;cell&gt;Development and test activity&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;root-bash_history&lt;/cell&gt;
        &lt;cell&gt;Mixed (EN/KR)&lt;/cell&gt;
        &lt;cell&gt;Root-level shell commands&lt;/cell&gt;
        &lt;cell&gt;System/Log&lt;/cell&gt;
        &lt;cell&gt;Privilege-level activity, implant deployment&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;auth.log.2&lt;/cell&gt;
        &lt;cell&gt;EN/KR&lt;/cell&gt;
        &lt;cell&gt;Authentication logs (PAM/SSH)&lt;/cell&gt;
        &lt;cell&gt;System/Log&lt;/cell&gt;
        &lt;cell&gt;Credential changes marked 변경완료, brute force IPs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;20190315.log&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;System log file&lt;/cell&gt;
        &lt;cell&gt;System/Log&lt;/cell&gt;
        &lt;cell&gt;Auth and system access events&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;chrome-timeline.txt&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Browser activity timeline&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;Visited domains extraction&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;chromehistory.txt&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Browser history export&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;URLs visited&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;history.sqlite&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Empty DB file&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;No useful data&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Media History&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Empty SQLite DB&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;No playback activity&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;History&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Empty Brave/Chromium DB&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;No visited URLs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Web Data&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Autofill/search DB&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;Search engines used (Google, DuckDuckGo, Qwant, Startpage, Ecosia)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Visited Links&lt;/cell&gt;
        &lt;cell&gt;Binary&lt;/cell&gt;
        &lt;cell&gt;LevelDB/binary structure&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;Could not extract URLs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Cookies&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;SQLite DB with cookies&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;Google cookies found&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;request_log.txt.20250220&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Captured phishing session&lt;/cell&gt;
        &lt;cell&gt;Phishing&lt;/cell&gt;
        &lt;cell&gt;Spoofed spo.go.kr, base64 credential logging&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;技术说明书 – 22.docx&lt;/cell&gt;
        &lt;cell&gt;ZH&lt;/cell&gt;
        &lt;cell&gt;Chinese rootkit stealth manual&lt;/cell&gt;
        &lt;cell&gt;Rootkit&lt;/cell&gt;
        &lt;cell&gt;Kernel hiding, binary embedding&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;1.ko 图文编译 .doc&lt;/cell&gt;
        &lt;cell&gt;ZH&lt;/cell&gt;
        &lt;cell&gt;Chinese compilation guide&lt;/cell&gt;
        &lt;cell&gt;Rootkit&lt;/cell&gt;
        &lt;cell&gt;Rootkit build process&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;1. build ko .txt&lt;/cell&gt;
        &lt;cell&gt;ZH&lt;/cell&gt;
        &lt;cell&gt;Build notes&lt;/cell&gt;
        &lt;cell&gt;Rootkit&lt;/cell&gt;
        &lt;cell&gt;Implant compilation instructions&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;0. 使用.txt&lt;/cell&gt;
        &lt;cell&gt;ZH&lt;/cell&gt;
        &lt;cell&gt;Usage notes&lt;/cell&gt;
        &lt;cell&gt;Rootkit&lt;/cell&gt;
        &lt;cell&gt;Implant usage and commands&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;re 正向工具修改建议 1.0.txt&lt;/cell&gt;
        &lt;cell&gt;ZH&lt;/cell&gt;
        &lt;cell&gt;Modification notes&lt;/cell&gt;
        &lt;cell&gt;Rootkit&lt;/cell&gt;
        &lt;cell&gt;Reverse tool modification suggestions&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;1111.txt&lt;/cell&gt;
        &lt;cell&gt;ZH&lt;/cell&gt;
        &lt;cell&gt;Rootkit/tool snippet&lt;/cell&gt;
        &lt;cell&gt;Rootkit&lt;/cell&gt;
        &lt;cell&gt;Part of implant notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;client&lt;/cell&gt;
        &lt;cell&gt;Binary&lt;/cell&gt;
        &lt;cell&gt;Rootkit client binary&lt;/cell&gt;
        &lt;cell&gt;Rootkit&lt;/cell&gt;
        &lt;cell&gt;Controller for implant communication&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;SSA_AO_AD_WT_002_웹보안 프로토콜설계서_Ver1.0_.doc&lt;/cell&gt;
        &lt;cell&gt;KR&lt;/cell&gt;
        &lt;cell&gt;GPKI protocol design doc&lt;/cell&gt;
        &lt;cell&gt;PKI&lt;/cell&gt;
        &lt;cell&gt;Korean web PKI standards&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;행자부 웹보안API 인수인계.doc&lt;/cell&gt;
        &lt;cell&gt;KR&lt;/cell&gt;
        &lt;cell&gt;GPKI API deployment manual&lt;/cell&gt;
        &lt;cell&gt;PKI&lt;/cell&gt;
        &lt;cell&gt;Deployment and cert API internals&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;HIRA-IR-T02_의약품처방조제_ComLibrary_통신전문.doc&lt;/cell&gt;
        &lt;cell&gt;KR&lt;/cell&gt;
        &lt;cell&gt;Medical ComLibrary XML spec&lt;/cell&gt;
        &lt;cell&gt;Healthcare&lt;/cell&gt;
        &lt;cell&gt;Prescription system communication&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;(별지2)행정전자서명_기술요건_141125.pdf&lt;/cell&gt;
        &lt;cell&gt;KR&lt;/cell&gt;
        &lt;cell&gt;PKI requirements PDF&lt;/cell&gt;
        &lt;cell&gt;PKI&lt;/cell&gt;
        &lt;cell&gt;OCR target&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;SecuwaySSL U_카달로그.pdf&lt;/cell&gt;
        &lt;cell&gt;KR&lt;/cell&gt;
        &lt;cell&gt;VPN catalog&lt;/cell&gt;
        &lt;cell&gt;PKI/VPN&lt;/cell&gt;
        &lt;cell&gt;OCR target&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;phrack-apt-down-the-north-korea-files.pdf&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Phrack article&lt;/cell&gt;
        &lt;cell&gt;Reference&lt;/cell&gt;
        &lt;cell&gt;Background on Kimsuky dump&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Muddled Libra Threat Assessment.pdf&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Threat intel report&lt;/cell&gt;
        &lt;cell&gt;Reference&lt;/cell&gt;
        &lt;cell&gt;Comparative threat actor study&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Leaked North Korean Linux Stealth Rootkit Analysis.pdf&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Rootkit analysis&lt;/cell&gt;
        &lt;cell&gt;Reference&lt;/cell&gt;
        &lt;cell&gt;Detailed implant study&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Inside the Kimsuky Leak.docx (various)&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Threat report drafts&lt;/cell&gt;
        &lt;cell&gt;Report&lt;/cell&gt;
        &lt;cell&gt;Working versions&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;account (2).txt&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;DB export (DBsafer, TrustedOrange)&lt;/cell&gt;
        &lt;cell&gt;Infra&lt;/cell&gt;
        &lt;cell&gt;Accounts and DB changes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;result.txt&lt;/cell&gt;
        &lt;cell&gt;KR&lt;/cell&gt;
        &lt;cell&gt;Cert-related parsed data&lt;/cell&gt;
        &lt;cell&gt;Infra&lt;/cell&gt;
        &lt;cell&gt;Included GPKI .key/.sig&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;english_wikipedia.txt&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Wikipedia dump&lt;/cell&gt;
        &lt;cell&gt;Reference&lt;/cell&gt;
        &lt;cell&gt;Unrelated baseline&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;bookmarks-2021-01-04.jsonlz4&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Firefox bookmarks (compressed)&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;Needs decompression&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Screenshot translations&lt;/cell&gt;
        &lt;cell&gt;ZH&lt;/cell&gt;
        &lt;cell&gt;Chinese text (rootkit marketing blurb)&lt;/cell&gt;
        &lt;cell&gt;Rootkit&lt;/cell&gt;
        &lt;cell&gt;Kernel hiding tool description&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45152066</guid></item><item><title>Show HN: Greppers – fast CLI cheat sheet with instant copy and shareable search</title><link>https://www.greppers.com/</link><description>&lt;doc fingerprint="a1eadbd093f5fba9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Stop Googling the same command twice.&lt;/head&gt;
    &lt;p&gt;A tiny, blazing‑fast directory of CLI commands with copy‑ready examples. Offline friendly. No BS.&lt;/p&gt;
    &lt;p&gt;Try:&lt;/p&gt;
    &lt;head rend="h2"&gt;Built for speed and memory.&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Instant search: Runs entirely in your browser.&lt;/item&gt;
      &lt;item&gt;Copy‑to‑clipboard: One click, no ceremony.&lt;/item&gt;
      &lt;item&gt;Opinionated examples: Real‑world flags and patterns.&lt;/item&gt;
      &lt;item&gt;Keyboard first: / focuses search, ↑↓ navigate, ⏎ copies.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45152086</guid></item><item><title>Europe enters the exascale supercomputing league with Jupiter</title><link>https://ec.europa.eu/commission/presscorner/detail/en/ip_25_2029</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=45152369</guid></item><item><title>Over 80% of Sunscreen Performed Below Their Labelled Efficacy (2020)</title><link>https://www.consumer.org.hk/en/press-release/528-sunscreen-test</link><description>&lt;doc fingerprint="b5740dbcec394b89"&gt;
  &lt;main&gt;
    &lt;p&gt;The use of effective sunscreen can reduce the harm caused to the skin by ultraviolet rays (UV) and slow down skin aging. The Consumer Council tested 30 models of sunscreen for daily use and over 80% of them were found to perform below their respective labelled efficacy. The measured sunscreen efficacy of 4 models were below SPF15, of which 2 were sunscreen products with very high protection i.e. labelled with SPF50+. Among the 23 models using the “PA System” which is commonly adopted by Asian countries to denote the UVA protection efficacy, only 7 were measured with an UVA Protection Factor (UVAPF) value met with their labelled PA levels. In addition, only 19 models stated the major ingredients on their packaging and consumers may not be able to identify possible allergens as a result. The Council urges manufacturers to critically review their production technology and processes, and to accurately label its product efficacy as well as to provide clear product information and usage guidelines. If consumers engage in outdoor activities for a prolonged period and use sunscreens with insufficient protection will possibly increase their risks of skin darkening or sunburn, and even skin cancer.&lt;/p&gt;
    &lt;p&gt;UVA emits from the sun may lead to skin aging, create wrinkles, darken skin colour, and may even induce skin cancer. However, internationally there is no unified system for product labelling of UVA protection, yet “PA System” is commonly adopted by Asian countries. UVB as ultraviolet rays with a higher energy level, can destroy DNA on skin surface, causing sunburn and is one of the main reasons of skin cancer. Currently, the Sun Protection Factor (SPF) index is an internationally recognised system to indicate the level of UVB protection in sunscreen products, the higher the value, the longer the protection offered against UVB.&lt;/p&gt;
    &lt;p&gt;Among the 30 daily-use sunscreen models tested, their price ranged from $80 to $550, i.e. $0.7 to $16.1 per g/ml, marking a difference of 23 times. 14 of them belonged to high protection and were labelled from SPF30 to SPF50 while the remaining 16 models belonged to very high protection and were labelled as SPF50+. 23 models showed their UVA protection ratings by “PA System”. The test result revealed the second cheapest model ($85) scored the highest 5 points in overall performance but the most expensive model ($550) only rated 3.5 points, indicating once again that there is no correlation between the price and product quality.&lt;/p&gt;
    &lt;p&gt;Currently, Hong Kong has no legislation or standard in regulating both SPF and UVA efficacy in products. Taking reference to the Cosmetics Regulation in the European Union (EU), this test covered SPF test and UVA protection test, as well as reviewing the labelling of each model.&lt;/p&gt;
    &lt;p&gt;According to the product labelling requirements of the EU Cosmetics Regulation, SPF labelling on sunscreens must meet 3 criteria, including passing the in vivo test of the related SPF; the measured UVAPF value reaching one-third or above of SPF; and the measured critical wavelength should be 370nm or above. The in vivo SPF test applied a fixed amount of the models on the skin of the back of 10 trial users before they were exposed to UV light. The SPF value of each model was calculated based on the erythema reactions measured on skin surface within 24 hours. Sunscreen labelled with SPF50+ should reach a measured SPF value of 60 or above, whereas products of SPF30 should reach a measured SPF value between 30 to 49.9. For the UVA blocking protection test, the UVA efficacy and the critical wavelength were calculated by detecting the penetration rate of UV light source through the special plastic film simulating human skin after applying the sunscreen models.&lt;/p&gt;
    &lt;p&gt;SPF test results revealed only 4 sunscreen models labelled with high protection (SPF30 to SPF50) fully complied with the efficacy labelling requirement under the EU Cosmetic Regulation. In the 14 models, 8 were measured with SPF value below their claims in the in vivo test. 1 model labelled as SPF30 had the largest discrepancy with its measured SPF value of only 9.8. Although the SPF values measured in the other 6 models were higher than or equal to their claims, the UVAPF value in 2 of them were only 8.0 and 4.0 respectively, failing to meet the requirement that UVAPF value need to be one-third of its SPF, and were therefore not in compliance with the labelling requirements of the EU.&lt;/p&gt;
    &lt;p&gt;In the 16 models labelled with very high protection (SPF50+), only 1 fully complied with the EU requirement. The measured SPF value in 14 of them were below SPF60, of which the lowest performing 2 were recorded with a measured value of just 11.7 and 14.3 respectively. The 2 models with the highest SPF values reached 87.2 and 61.7 respectively, but the UVAPF and critical wavelength of 1 of them could not meet the relevant criteria.&lt;/p&gt;
    &lt;p&gt;Unlike UVB, there is no unified international system for labelling UVA protection efficacy in products. The Council thus rated such efficacy of all models by converting the UVAPF values measured into the “PA system” which is commonly adopted by Asian countries. All 30 tested models were detected with different degrees of UVA protection with the measured UVAPF values ranging between 3.3 to 67.3, whereas UVAPF values of 9 of them were above 16, which were roughly the highest level in the PA system (i.e. PA++++) while another 10 models were rated at PA+++.&lt;/p&gt;
    &lt;p&gt;As for product labelling, 6 models listed their ingredients in Japanese only and general consumers may not be able to identify possible allergens or apply the products correctly. Suggested usage quantity cannot be found in 21 models. If consumers apply insufficient amount of sunscreens, they may incur the risk of inadequate protection. Moreover, 3 models were not marked with any expiry date. The Council urges manufacturers to improve product labelling. On the other hand, the Council reminds that some sunscreen products may have high water content level, once the product has reached the expiry date, preservative may lose its effectiveness, and this could accelerate bacterial and microbial growth. These products should be used up well before the expiry date after opening.&lt;/p&gt;
    &lt;p&gt;Consumers should try to avoid exposing their skin under direct sunlight to minimise the harm to the skin caused by UV radiation. When purchasing and using sunscreens, consumers need to be aware of the following:&lt;/p&gt;
    &lt;p&gt;In selecting sunscreen products, read the labels carefully to check the presence of allergens. Consumers with skin allergies or eczema should consider sunscreens with physical filters to reduce the risk of allergy;&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Sunscreens of physical filters are relatively mild and less likely to cause allergy but are relatively whiter in colour and more viscous in texture, thus it is harder to be applied evenly. While those with chemical filters are thinner and give a lighter feeling after application, they may pose a greater risk in skin and eyes irritation, thus resulting in allergy more easily;&lt;/item&gt;
      &lt;item&gt;Sunscreens with SPF50 are basically adequate in providing 98% protection to the skin while those with a larger SPF value may instead clog up pores or cause skin allergy. Thus, for normal use, it is not necessary to look for sunscreen products with a very high SPF value;&lt;/item&gt;
      &lt;item&gt;Make reference to the UV index announced by the Hong Kong Observatory before going out for outdoor activities, and choose appropriate sunscreens according to the UV index, type and duration of their activities;&lt;/item&gt;
      &lt;item&gt;Apply sunscreen according to the product label, normally it is around 1 teaspoon for face and should be re-applied every 2 to 3 hours to ensure sufficient protection to the skin;&lt;/item&gt;
      &lt;item&gt;Sunscreen should be cleansed by make-up remover or facial cleanser according to the packaging instruction to prevent any residue from affecting skin’s health;&lt;/item&gt;
      &lt;item&gt;Pay attention to the product expiry date, disposal is necessary if the product is expired to avoid the risks of microbial growth upon contact with air or skin.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Consumer Council reserves all its right (including copyright) in respect of CHOICE magazine and Online CHOICE&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45152374</guid></item><item><title>How often do health insurers say no to patients? (2023)</title><link>https://www.propublica.org/article/how-often-do-health-insurers-deny-patients-claims</link><description>&lt;doc fingerprint="ee9a0a917a53c507"&gt;
  &lt;main&gt;
    &lt;p&gt;It’s one of the most crucial questions people have when deciding which health plan to choose: If my doctor orders a test or treatment, will my insurer refuse to pay for it?&lt;/p&gt;
    &lt;p&gt;After all, an insurance company that routinely rejects recommended care could damage both your health and your finances. The question becomes ever more pressing as many working Americans see their premiums rise as their benefits shrink.&lt;/p&gt;
    &lt;p&gt;Yet, how often insurance companies say no is a closely held secret. There’s nowhere that a consumer or an employer can go to look up all insurers’ denial rates — let alone whether a particular company is likely to decline to pay for procedures or drugs that its plans appear to cover.&lt;/p&gt;
    &lt;p&gt;The lack of transparency is especially galling because state and federal regulators have the power to fix it, but haven’t.&lt;/p&gt;
    &lt;p&gt;ProPublica, in collaboration with The Capitol Forum, has been examining the hidden world of insurance denials. A previous story detailed how one of the nation’s largest insurers flagged expensive claims for special scrutiny; a second story showed how a different top insurer used a computer program to bulk-deny claims for some common procedures with little or no review.&lt;/p&gt;
    &lt;p&gt;The findings revealed how little consumers know about the way their claims are reviewed — and denied — by the insurers they pay to cover their medical costs.&lt;/p&gt;
    &lt;p&gt;When ProPublica set out to find information on insurers’ denial rates, we hit a confounding series of roadblocks.&lt;/p&gt;
    &lt;p&gt;In 2010, federal regulators were granted expansive authority through the Affordable Care Act to require that insurers provide information on their denials. This data could have meant a sea change in transparency for consumers. But more than a decade later, the federal government has collected only a fraction of what it’s entitled to. And what information it has released, experts say, is so crude, inconsistent and confusing that it’s essentially meaningless.&lt;/p&gt;
    &lt;p&gt;The national group for state insurance commissioners gathers a more detailed, reliable trove of information. Yet, even though commissioners’ primary duty is to protect consumers, they withhold nearly all of these details from the public. ProPublica requested the data from every state’s insurance department, but none provided it.&lt;/p&gt;
    &lt;p&gt;Two states collect their own information on denials and make it public, but their data covers only a tiny subset of health plans serving a small number of people.&lt;/p&gt;
    &lt;p&gt;The minuscule amount of details available about denials robs consumers of a vital tool for comparing health plans.&lt;/p&gt;
    &lt;p&gt;“This is life and death for people: If your insurance won’t cover the care you need, you could die,” said Karen Pollitz, a senior fellow at KFF (formerly known as the Kaiser Family Foundation) who has written repeatedly about the issue. “It’s all knowable. It’s known to the insurers, but it is not known to us.”&lt;/p&gt;
    &lt;p&gt;The main trade groups for health insurance companies, AHIP (formerly known as America’s Health Insurance Plans) and the Blue Cross Blue Shield Association, say the industry supports transparency and complies with government disclosure requirements. Yet the groups have often argued against expanding this reporting, saying the burdens it would impose on insurance companies would outweigh the benefits for consumers.&lt;/p&gt;
    &lt;p&gt;“Denial rates are not directly comparable from one health plan to another and could lead consumers to make inaccurate conclusions on the robustness of the health plan,” Kelly Parsons, director of media relations for the Blue Cross Blue Shield Association, said in an email.&lt;/p&gt;
    &lt;p&gt;The trade groups stress that a substantial majority of patient claims are approved and that there can be good reasons — including errors and incomplete information from doctors — for some to be denied.&lt;/p&gt;
    &lt;p&gt;“More abstract data about percentages of claims that are approved or denied have no context and are not a reliable indicator of quality — it doesn’t address why a claim was or was not approved, what happened after the claim was not approved the first time, or how a patient or their doctor can help ensure a claim will be approved,” AHIP spokesperson Kristine Grow said in a written response to questions from ProPublica. “Americans deserve information and data that has relevance to their own personal health and circumstances.”&lt;/p&gt;
    &lt;p&gt;The limited government data available suggests that, overall, insurers deny between 10% and 20% of the claims they receive. Aggregate numbers, however, shed no light on how denial rates may vary from plan to plan or across types of medical services.&lt;/p&gt;
    &lt;p&gt;Some advocates say insurers have a good reason to dodge transparency. Refusing payment for medical care and drugs has become a staple of their business model, in part because they know customers appeal less than 1% of denials, said Wendell Potter, who oversaw Cigna’s communications team for more than a decade before leaving the industry in 2008 to become a consumer advocate.&lt;/p&gt;
    &lt;p&gt;“That’s money left on the table that the insurers keep,” he said.&lt;/p&gt;
    &lt;p&gt;At least one insurer disputes this. Potter’s former employer, Cigna, said in an email that his “unsubstantiated opinions” don’t reflect the company’s business model. In a separate written statement, Cigna said it passes on the money it saves “by lowering the cost of health care services and reducing wasteful spending” to the employers who hire it to administer their plans or insure their workers.&lt;/p&gt;
    &lt;p&gt;The few morsels insurers have served up on denials stand in stark contrast to the avalanche of information they’ve divulged in recent years on other fronts, often in response to government mandates. Starting last year, for example, insurers began disclosing the prices they’ve negotiated to pay medical providers for most services.&lt;/p&gt;
    &lt;p&gt;Experts say it’ll take similar mandates to make insurers cough up information on denials, in part because they fear plans with low denial rates would be a magnet for people who are already ailing.&lt;/p&gt;
    &lt;p&gt;“Health plans would never do that voluntarily, would give you what their claim denial rates are, because they don’t want to attract sicker people,” said Mila Kofman, who leads the District of Columbia’s Affordable Care Act exchange and previously served as Maine’s superintendent of insurance.&lt;/p&gt;
    &lt;p&gt;About 85% of people with insurance who responded to a recent KFF survey said they want regulators to compel insurers to disclose how often they deny claims. Pollitz, who co-authored a report on the survey, is a cancer survivor who vividly recalls her own experiences with insurance denials.&lt;/p&gt;
    &lt;p&gt;“Sometimes it would just make me cry when insurance would deny a claim,” she said. “It was like, ‘I can’t deal with this now, I’m throwing up, I just can’t deal with this.’”&lt;/p&gt;
    &lt;p&gt;She should have been able to learn how her plan handled claims for cancer treatment compared with other insurers, she said.&lt;/p&gt;
    &lt;p&gt;“There could be much more accountability.”&lt;/p&gt;
    &lt;p&gt;In September 2009, amid a roiling national debate over health care, the California Nurses Association made a startling announcement: Three of the state’s six largest health insurers had each denied 30% or more of the claims submitted to them in the first half of the year.&lt;/p&gt;
    &lt;p&gt;California insurers instantly said the figures were misleading, inflated by claims submitted in error or for patients ineligible for coverage.&lt;/p&gt;
    &lt;p&gt;But beyond the unexpectedly high numbers, the real surprise was that the nurses association was able to figure out the plans’ denial rates at all, by using information researchers found on the California Department of Managed Health Care’s website.&lt;/p&gt;
    &lt;p&gt;At the time, no other state or federal regulatory agency was collecting or publishing details about how often private insurers denied claims, a 2009 report by the Center for American Progress found.&lt;/p&gt;
    &lt;p&gt;The Affordable Care Act, passed the following year, was a game changer when it came to policing insurers and pushing them to be more transparent.&lt;/p&gt;
    &lt;p&gt;The law took aim at insurers’ practice of excluding people with preexisting conditions, the most flagrant type of denial, and required companies offering plans on the marketplaces created under the law to disclose their prices and detail their benefits.&lt;/p&gt;
    &lt;p&gt;A less-noticed section of the law demanded transparency from a much broader group of insurers about how many claims they turned down, and it put the Department of Health and Human Services in charge of making this information public. The disclosure requirements applied not only to health plans sold on the new marketplaces but also to the employer plans that cover most Americans.&lt;/p&gt;
    &lt;p&gt;The law’s proponents in the Obama administration said they envisioned a flow of accurate, timely information that would empower consumers and help regulators spot problematic insurers or practices.&lt;/p&gt;
    &lt;p&gt;That’s not what happened.&lt;/p&gt;
    &lt;p&gt;The federal government didn’t start publishing data until 2017 and thus far has only demanded numbers for plans on the federal marketplace known as Healthcare.gov. About 12 million people get coverage from such plans — less than 10% of those with private insurance. Federal regulators say they eventually intend to compel health plans outside the Obamacare exchanges to release details about denials, but so far have made no move to do so.&lt;/p&gt;
    &lt;p&gt;Within the limited universe of Healthcare.gov, KFF’s analyses show that insurers, on average, deny almost 1 in 5 claims and that each year some reject more than 1 in 3.&lt;/p&gt;
    &lt;p&gt;But there are red flags that suggest insurers may not be reporting their figures consistently. Companies’ denial rates vary more than would be expected, ranging from as low as 2% to as high as almost 50%. Plans’ denial rates often fluctuate dramatically from year to year. A gold-level plan from Oscar Insurance Company of Florida rejected 66% of payment requests in 2020, then turned down just 7% in 2021. That insurer’s parent company, Oscar Health, was co-founded by Joshua Kushner, the younger brother of former President Donald Trump’s son-in-law Jared Kushner.&lt;/p&gt;
    &lt;p&gt;An Oscar Health spokesperson said in an email that the 2020 results weren’t a fair reflection of the company’s business “for a variety of reasons,” but wouldn’t say why. “We closely monitor our overall denial rates and they have remained comfortably below 20% over the last few years, including the 2020-2021 time period,” the spokesperson wrote.&lt;/p&gt;
    &lt;p&gt;Experts say they can’t tell if insurers with higher denial rates are counting differently or are genuinely more likely to leave customers without care or stuck with big bills.&lt;/p&gt;
    &lt;p&gt;“It’s not standardized, it’s not audited, it’s not really meaningful,” Peter Lee, the founding executive director of California’s state marketplace, said of the federal government’s information. Data, he added, “should be actionable. This is not by any means right now.”&lt;/p&gt;
    &lt;p&gt;Officials at the Centers for Medicare &amp;amp; Medicaid Services, which collects the denial numbers for the federal government, say they’re doing more to validate them and improve their quality. It’s notable, though, that the agency doesn’t use this data to scrutinize or take action against outliers.&lt;/p&gt;
    &lt;p&gt;“They’re not using it for anything,” Pollitz said.&lt;/p&gt;
    &lt;p&gt;Pollitz has co-authored four reports that call out the data’s shortcomings. An upshot of all of them: Much of what consumers would most want to know is missing.&lt;/p&gt;
    &lt;p&gt;The federal government provides numbers on insurers’ denials of claims for services from what the industry calls “in-network” medical providers, those who have contracts with the insurer. But it doesn’t include claims for care outside those networks. Patients often shoulder more costs for out-of-network services, ramping up the import of these denials.&lt;/p&gt;
    &lt;p&gt;In recent years, doctors and patients have complained bitterly that insurers are requiring them to get approval in advance for an increasing array of services, causing delays and, in some instances, harm. The government, however, hasn’t compelled insurers to reveal how many requests for prior authorization they get or what percent they deny.&lt;/p&gt;
    &lt;p&gt;These and other specifics — particularly about which procedures and treatments insurers reject most — would be necessary to turn the government’s data into a viable tool to help consumers choose health plans, said Eric Ellsworth, the director of health data strategy at Consumers' Checkbook, which designs such tools.&lt;/p&gt;
    &lt;p&gt;A spokesperson for CMS said that, starting in plan year 2024, the agency will require insurers offering federal marketplace plans to submit a few more numbers, including on out-of-network claims, but there’s no timeline yet for much of what advocates say is necessary.&lt;/p&gt;
    &lt;p&gt;Another effort, launched by a different set of federal regulators, illustrates the resistance that government officials encounter when they consider demanding more.&lt;/p&gt;
    &lt;p&gt;The U.S. Department of Labor regulates upwards of 2 million health plans, including many in which employers pay directly for workers’ health care coverage rather than buying it from insurance companies. Roughly two-thirds of American workers with insurance depend on such plans, according to KFF.&lt;/p&gt;
    &lt;p&gt;In July 2016, an arm of the Labor Department proposed rules requiring these plans to reveal a laundry list of never-before-disclosed information, including how many claims they turned down.&lt;/p&gt;
    &lt;p&gt;In addition, the agency said it was considering whether to demand the dollar amount of what the denied care cost, as well as a breakdown of the reasons why plans turned down claims or denied behavioral health services.&lt;/p&gt;
    &lt;p&gt;The disclosures were necessary to “remedy the current failure to collect data about a large sector of the health plan market,” as well as to satisfy mandates in the Affordable Care Act and provide critical information for agency oversight, a Labor Department factsheet said.&lt;/p&gt;
    &lt;p&gt;Trade groups for employers, including retailers and the construction industry, immediately pushed back.&lt;/p&gt;
    &lt;p&gt;The U.S. Chamber of Commerce said complying with the proposal would take an amount of work not justified by “the limited gains in transparency and enforcement ability.” The powerful business group made it sound like having to make the disclosures could spark insurance Armageddon: Employers might cut back benefits or “eliminate health and welfare benefits altogether.”&lt;/p&gt;
    &lt;p&gt;Trade groups for health insurance companies, which often act as administrators for employers that pay directly for workers’ health care, joined with business groups to blast the proposal. The Blue Cross Blue Shield Association called the mandated disclosures “burdensome and expensive.” AHIP questioned whether the Labor Department had the legal authority to collect the data and urged the agency to withdraw the idea “in its entirety.”&lt;/p&gt;
    &lt;p&gt;The proposal also drew opposition from another, less expected quarter: unions. Under some collective bargaining agreements, unions co-sponsor members’ health plans and would have been on the hook for the new reporting requirements, too. The AFL-CIO argued the requirements created a higher standard of disclosure for plans overseen by the Labor Department. To be fair and avoid confusion, the group said, the Labor Department should put its rules on ice until federal health regulators adopted equivalent ones for plans this proposal didn’t cover.&lt;/p&gt;
    &lt;p&gt;That left the transparency push without political champions on the left or the right, former Assistant Secretary of Labor Phyllis Borzi, who ran the part of the agency that tried to compel more disclosure, said in a recent interview.&lt;/p&gt;
    &lt;p&gt;“When you’re up against a united front from the industry, the business community and labor, it’s really hard to make a difference,” she said.&lt;/p&gt;
    &lt;p&gt;By the time the Labor Department stopped accepting feedback, Donald Trump had been elected president.&lt;/p&gt;
    &lt;p&gt;One trade association for large employers pointed out that the Affordable Care Act, which partly drove the new rules, was “a law that the incoming Administration and the incoming leadership of the 115th Congress have vowed to repeal, delay, dismantle, and otherwise not enforce.”&lt;/p&gt;
    &lt;p&gt;The law managed to survive the Trump administration, but the Labor Department’s transparency push didn’t. The agency withdrew its proposal in September 2019.&lt;/p&gt;
    &lt;p&gt;A Labor Department spokesperson said the Biden administration has no immediate plan to revive it.&lt;/p&gt;
    &lt;p&gt;Ultimately, it’s the National Association of Insurance Commissioners, a group for the top elected or appointed state insurance regulators, that has assembled the most robust details about insurance denials.&lt;/p&gt;
    &lt;p&gt;The association’s data encompasses more plans than the federal information, is more consistent and captures more specifics, including numbers of out-of-network denials, information about prior authorizations and denial rates for pharmacy claims. All states except New York and North Dakota participate.&lt;/p&gt;
    &lt;p&gt;Yet, consumers get almost no access. The commissioners’ association only publishes national aggregate statistics, keeping the rest of its cache secret.&lt;/p&gt;
    &lt;p&gt;When ProPublica requested the detailed data from each state’s insurance department, none would hand it over. More than 30 states said insurers had submitted the information under the authority commissioners are granted to examine insurers’ conduct. And under their states’ codes, they said, examination materials must be kept confidential.&lt;/p&gt;
    &lt;p&gt;The commissioners association said state insurance regulators use the information to compare companies, flag outliers and track trends.&lt;/p&gt;
    &lt;p&gt;Birny Birnbaum, a longtime insurance watchdog who serves on the group’s panel of consumer representatives, said the association’s approach reflects how state insurance regulators have been captured by the insurance industry’s demands for secrecy.&lt;/p&gt;
    &lt;p&gt;“Many seem to view their roles as protectors of industry information, as opposed to enforcers of public information laws,” Birnbaum said in an email.&lt;/p&gt;
    &lt;p&gt;Connecticut and Vermont compile their own figures and make them publicly accessible. Connecticut began reporting information on denials first, adding these numbers to its annual insurer report card in 2011.&lt;/p&gt;
    &lt;p&gt;Vermont demands more details, requiring insurers that cover more than 2,000 Vermonters to publicly release prior authorization and prescription drug information that is similar to what the state insurance commissioners collect. Perhaps most usefully, insurers have to separate claims denied because of administrative problems — many of which will be resubmitted and paid — from denials that have “member impact.” These involve services rejected on medical grounds or because they are contractually excluded.&lt;/p&gt;
    &lt;p&gt;Mike Fisher, Vermont’s state health care advocate, said there’s little indication consumers or employers are using the state’s information, but he still thinks the prospect of public scrutiny may have affected insurers’ practices. The most recent data shows Vermont plans had denial rates between 7.7% and 10.26%, considerably lower than the average for plans on Healthcare.gov.&lt;/p&gt;
    &lt;p&gt;“I suspect that’s not a coincidence,” Fisher said. “Shining a light on things helps.”&lt;/p&gt;
    &lt;p&gt;Despite persistent complaints from insurers that Vermont’s requirements are time-consuming and expensive, no insurers have left the state over it. “Certainly not,” said Sebastian Arduengo, who oversees the reporting for the Vermont Department of Financial Regulation.&lt;/p&gt;
    &lt;p&gt;In California, once considered the most transparent state, the Department of Managed Health Care in 2011 stopped requiring insurance carriers to specify how many claims they rejected.&lt;/p&gt;
    &lt;p&gt;A department spokesperson said in an email that the agency follows the requirements in state law, and the law doesn’t require health plans to disclose denials.&lt;/p&gt;
    &lt;p&gt;The state posts reports that flag some plans for failing to pay claims fairly and on time. Consumers can use those to calculate bare-bones denial rates for some insurers, but for others, you’d have to file a public records request to get the details needed to do the math.&lt;/p&gt;
    &lt;p&gt;Despite the struggles of the last 15 years, Pollitz hasn’t given up hope that one day there will be enough public information to rank insurers by their denial rates and compare how reliably they provide different services, from behavioral health to emergency care.&lt;/p&gt;
    &lt;p&gt;“There’s a name and shame function that is possible here,” she said. “It holds some real potential for getting plans to clean up their acts.”&lt;/p&gt;
    &lt;p&gt;Kirsten Berg contributed research. David Armstrong and Patrick Rucker contributed reporting.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45152403</guid></item><item><title>Utah's hottest new power source is 15k feet below the ground</title><link>https://www.gatesnotes.com/utahs-hottest-new-power-source-is-below-the-ground</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45152569</guid></item><item><title>Stop Shipping PNGs in Your Games</title><link>https://gamesbymason.com/blog/2025/stop-shipping-pngs/</link><description>&lt;doc fingerprint="1e83485230620990"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;ð¼ï¸ Stop Shipping PNGs In Your Games&lt;/head&gt;
    &lt;p&gt;Are you shipping textures to players as PNGs? The goal of this post is to convince you that this is suboptimal, and walk you through a better approach.&lt;/p&gt;
    &lt;p&gt;Iâll also share my implementation of the suggested approach, but if youâd rather do it yourself Iâll also provide you with the information you need to get started.&lt;/p&gt;
    &lt;p&gt;If youâre using a game engine, it is almost certainly doing what this post suggests automatically, but it doesnât hurt to double check!&lt;/p&gt;
    &lt;head rend="h1"&gt;Whatâs wrong with PNGs?&lt;/head&gt;
    &lt;p&gt;PNGs are great for interchange. Theyâre lossless, they compresses well, and support is ubiquitous. PNG is my image interchange format of choice.&lt;/p&gt;
    &lt;p&gt;This post isnât a criticism of PNGsâitâs just that the PNG format is designed for image data, not texture data.&lt;/p&gt;
    &lt;p&gt;Here are some examples of features you would expect out of a texture format that youâre not going to find in an image format:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Pregenerated mipmaps&lt;/item&gt;
      &lt;item&gt;Cubemaps&lt;/item&gt;
      &lt;item&gt;Premultiplied alpha&lt;list rend="ul"&gt;&lt;item&gt;Technically PNGs can be premultplied, but yours probably arenât.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Can you work around all these issues? Sure.&lt;/p&gt;
    &lt;p&gt;You can premultiply and generate your mipmaps at load time. You can ship separate images for each cuebmap face. But now youâre resigned to cheap mipmap generation, and cubemaps that are difficult to downsample correctly.&lt;/p&gt;
    &lt;p&gt;You can certainly make it work, but youâre making things unnecessarily difficult for yourself by using the wrong tool for the job.&lt;/p&gt;
    &lt;p&gt;Furthermore, texture formats have a killer feature not mentioned aboveâsupport for GPU compatible texture compression like BCn.&lt;/p&gt;
    &lt;p&gt;An in-depth explanation of GPU compression formats it out of scope for this post, but at a high level, these formats store each block of pixels as a couple of endpoints and a method for interpolating between those endpoints.&lt;/p&gt;
    &lt;p&gt;This trades mild degradation of image quality for improvements in storage, VRAM usage, and sampling performance. Itâs so good it feels like youâre cheating thermodynamics.&lt;/p&gt;
    &lt;p&gt;GPUs canât decompress PNGs on the fly, so as a result, if you ship PNGs you either canât take advantage of this compression, or you have to first decompress the PNGs and then do an extremely expensive compression step to convert to the desired block based format every time a player loads the game.&lt;/p&gt;
    &lt;p&gt;Thatâs a little goofy, right?&lt;/p&gt;
    &lt;p&gt;(EDIT: Well, itâs goofy when done naivelyâsee discussion w/ Ignacio CastaÃ±o here, something along these lines can become viable if you can transcode quickly.)&lt;/p&gt;
    &lt;head rend="h1"&gt;What texture formats are out there?&lt;/head&gt;
    &lt;p&gt;Texture formats like Khronosâ KTX2 and Microsoftâs DDS are designed for exactly our use case. Theyâre just headers followed by some image data that you can upload directly to the GPU without any additional processing.&lt;/p&gt;
    &lt;p&gt;Well, unless you use supercompression. GPU compression formats donât provide great compression ratios, so itâs typical to apply lossless compression as well (think zlib or lz4.) In that case youâll decompress, and then upload.&lt;/p&gt;
    &lt;p&gt;The meta here is to design your lossy compressor to be aware that its output is going to be losslessly compressed afterwards. This lets it make decisions that reduce entropy, improving the effectiveness of the lossless step.&lt;/p&gt;
    &lt;p&gt;I used DXT5 + lz4 compressed DDS files for Way of Rhea, Iâm switching to BC7 + zlib compressed KTX2 files for my next game. Both approaches are reasonable.&lt;/p&gt;
    &lt;p&gt;Note: I primarily develop games for desktop platforms. IIUC, on mobile, hardware support for various types of GPU compression varies but the formats are similar-ish, so the meta is to use something like Basis Universal to quickly transcode to the correct format on load.&lt;/p&gt;
    &lt;head rend="h1"&gt;Exporting to KTX2&lt;/head&gt;
    &lt;p&gt;At this point, youâre likely looking through the export menu of your image editor of choice for KTX2 and DDS, and not seeing any results.&lt;/p&gt;
    &lt;p&gt;Unfortunately, AFAICT most people end up rolling their own exporters. People used to use Nvidia Texture Tools, but itâs archived as there wasnât funding to maintain it. Itâs still a great reference. Nvidia has a closed source fork, but I donât love having a closed source dependency for such an integral part of my engine.&lt;/p&gt;
    &lt;p&gt;Iâve implemented an open source texture tool that youâre welcome to use directly or as a reference for your own implementation: Zex.&lt;/p&gt;
    &lt;p&gt;It can be used as a command line tool, or as a Zig library. It reads PNGs using stb_image, and converts them to KTX2, with support BC7 compression + rate distortion optimization from bc7enc_rdo, and supercompression via zlib.&lt;/p&gt;
    &lt;p&gt;It supports most standard features, such as mipmap generation with configurable filters and address modes.&lt;/p&gt;
    &lt;p&gt;I havenât implemented cubemap exports yet as my current game isnât using them. If you need support before I get around to it, PRs are welcomeâit should be a pretty straightforward addition.&lt;/p&gt;
    &lt;p&gt;If you want to implement your own exporter, here are some useful references. Keep in mind that you donât need to support all possible features, just the ones your engine uses:&lt;/p&gt;
    &lt;head rend="h2"&gt;Texture Viewers&lt;/head&gt;
    &lt;p&gt;Most image viewers wonât be able to open texture formats like DDS/KTX2. This sorta makes senseâimage viewers are typically designed to show a single image, whereas a texture may be comprised of multiple mipmaps and cubemap faces and such, and may be HDR. This requires a fancier UI.&lt;/p&gt;
    &lt;p&gt;Iâm personally a fan of Tacentview for this use case. Itâs open source, cross platform, and supports a large number of formats.&lt;/p&gt;
    &lt;head rend="h2"&gt;Preserving Alpha Coverage&lt;/head&gt;
    &lt;p&gt;source: firewatch inspired me so I made a tree and then never used it for anything&lt;/p&gt;
    &lt;p&gt;Pregenerating your mipmaps gives you a chance to be a little more âcorrectâ about them.&lt;/p&gt;
    &lt;p&gt;For example, if youâve ever tried to render a tree or a chain link fence in-game as a cutout (or with alpha to coverage) but found that it vanishes when you get far away, your mipmap filtering likely isnât taking into account the alpha test.&lt;/p&gt;
    &lt;p&gt;You can see Zexâs alpha test aware resize here. This isnât battle tested yet, compare results visually in-engine to see if it provides a benefit for your artwork.&lt;/p&gt;
    &lt;head rend="h2"&gt;Automation&lt;/head&gt;
    &lt;p&gt;You probably donât want to convert all your images by hand. I did this for Way of Rhea for a while, but eventually realized that it was a waste of time. Every time a texture changes you have to go back and figure out what settings you used last time. Just automate it.&lt;/p&gt;
    &lt;p&gt;Iâll probably write a follow up post describing my strategy for automating this at some point in the future, but if you want a sneak peak, check out Oven. Itâs not exactly general purpose right now, but might be an interesting reference.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45152648</guid></item><item><title>Microsoft Azure: "Multiple international subsea cables were cut in the Red Sea"</title><link>https://azure.status.microsoft/en-gb/status</link><description>Multiple subsea fiber cuts in the Red Sea impacting global communications

Impact Summary

Starting at 05:45 UTC on 06 September 2025, traffic traversing through the Middle East originating and/or terminating in Asia or Europe regions may experience increased latency due to multiple undersea fiber cuts in the Red Sea. The disruption has required rerouting through alternate paths which may lead to higher-than-normal latencies.

This advisory is intended to raise awareness ahead of increased demand as the regions enter the start of its work week.

Current Status

Multiple international subsea cables were cut in the Red Sea. Our engineering teams are actively managing the interruption via diverse capacity and traffic rerouting, while also discussing alternate capacity options and providers in the region.

Undersea fiber cuts can take time to repair, as such we will continuously monitor, rebalance, and optimize routing to reduce customer impact in the meantime. We’ll continue to provide daily updates, or sooner if conditions change.

This message was last updated at 19:30 UTC on 06 September 2025</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45152773</guid></item><item><title>A Navajo weaving of an integrated circuit: the 555 timer</title><link>https://www.righto.com/2025/09/marilou-schultz-navajo-555-weaving.html</link><description>&lt;doc fingerprint="2f555263dc670aeb"&gt;
  &lt;main&gt;
    &lt;p&gt;The noted Diné (Navajo) weaver Marilou Schultz recently completed an intricate weaving composed of thick white lines on a black background, punctuated with reddish-orange diamonds. Although this striking rug may appear abstract, it shows the internal circuitry of a tiny silicon chip known as the 555 timer. This chip has hundreds of applications in everything from a sound generator to a windshield wiper controller. At one point, the 555 was the world's best-selling integrated circuit with billions sold. But how did the chip get turned into a rug?&lt;/p&gt;
    &lt;p&gt;The 555 chip is constructed from a tiny flake of silicon with a layer of metallic wiring on top. In the rug, this wiring is visible as the thick white lines, while the silicon forms the black background. One conspicuous feature of the rug is the reddish-orange diamonds around the perimeter. These correspond to the connections between the silicon chip and its eight pins. Tiny golden bond wires—thinner than a human hair—are attached to the square bond pads to provide these connections. The circuitry of the 555 chip contains 25 transistors, silicon devices that can switch on and off. The rug is dominated by three large transistors, the filled squares with a 王 pattern inside, while the remaining transistors are represented by small dots.&lt;/p&gt;
    &lt;p&gt;The weaving was inspired by a photo of the 555 timer die taken by Antoine Bercovici (Siliconinsider); I suggested this photo to Schultz as a possible subject for a rug. The diagram below compares the weaving (left) with the die photo (right). As you can see, the weaving closely follows the actual chip, but there are a few artistic differences. For instance, two of the bond pads have been removed, the circuitry at the top has been simplified, and the part number at the bottom has been removed.&lt;/p&gt;
    &lt;p&gt;Antoine took the die photo with a dark field microscope, a special type of microscope that produces an image on a black background. This image emphasizes the metal layer on the top of the die. In comparison, a standard bright-field microscope produced the image below. When a chip is manufactured, regions of silicon are "doped" with impurities to create transistors and resistors. These regions are visible in the image below as subtle changes in the color of the silicon.&lt;/p&gt;
    &lt;p&gt;In the weaving, the chip's design appears almost monumental, making it easy to forget that the actual chip is microscopic. For the photo below, I obtained a version of the chip packaged in a metal can, rather than the typical rectangle of black plastic. Cutting the top off the metal can reveals the tiny chip inside, with eight gold bond wires connecting the die to the pins of the package. If you zoom in on the photo, you may recognize the three large transistors that dominate the rug.&lt;/p&gt;
    &lt;p&gt;The artist, Marilou Schultz, has been creating chip rugs since 1994, when Intel commissioned a rug based on the Pentium as a gift to AISES (American Indian Science &amp;amp; Engineering Society). Although Schultz learned weaving as a child, the Pentium rug was a challenge due to its complex pattern and lack of symmetry; a day's work might add just an inch to the rug. This dramatic weaving was created with wool from the long-horned Navajo-Churro sheep, colored with traditional plant dyes.&lt;/p&gt;
    &lt;p&gt;For the 555 timer weaving, Schultz experimented with different materials. Silver and gold metallic threads represent the aluminum and copper in the chip. The artist explains that "it took a lot more time to incorporate the metallic threads," but it was worth the effort because "it is spectacular to see the rug with the metallics in the dark with a little light hitting it." Aniline dyes provided the black and lavender colors. Although natural logwood dye produces a beautiful purple, it fades over time, so Schultz used an aniline dye instead. The lavender colors are dedicated to the weaver's mother, who passed away in February; purple was her favorite color.&lt;/p&gt;
    &lt;head rend="h2"&gt;Inside the chip&lt;/head&gt;
    &lt;p&gt;How does the 555 chip produce a particular time delay? You add external components—resistors and a capacitor—to select the time. The capacitor is filled (charged) at a speed controlled by the resistor. When the capacitor get "full", the 555 chip switches operation and starts emptying (discharging) the capacitor. It's like filling a sink: if you have a large sink (capacitor) and a trickle of water (large resistor), the sink fills slowly. But if you have a smal sink (capacitor) and a lot of water (small resistor), the sink fills quickly. By using different resistors and capacitors, the 555 timer can provide time intervals from microseconds to hours.&lt;/p&gt;
    &lt;p&gt;I've constructed an interactive chip browser that shows how the regions of the rug correspond to specific electronic components in the physical chip. Click on any part of the rug to learn the function of the corresponding component in the chip.&lt;/p&gt;
    &lt;p&gt;For instance, two of the large square transistors turn the chip's output on or off, while the third large transistor discharges the capacitor when it is full. (To be precise, the capacitor goes between 1/3 full and 2/3 full to avoid issues near "empty" and "full".) The chip has circuits called comparators that detect when the capacitor's voltage reaches 1/3 or 2/3, switching between emptying and filling at those points. If you want more technical details about the 555 chip, see my previous articles: an early 555 chip, a 555 timer similar to the rug, and a more modern CMOS version of the 555.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusions&lt;/head&gt;
    &lt;p&gt;The similarities between Navajo weavings and the patterns in integrated circuits have long been recognized. Marilou Schultz's weavings of integrated circuits make these visual metaphors into concrete works of art. This connection is not just metaphorical, however; in the 1960s, the semiconductor company Fairchild employed numerous Navajo workers to assemble chips in Shiprock, New Mexico. I wrote about this complicated history in The Pentium as a Navajo Weaving.&lt;/p&gt;
    &lt;p&gt;This work is being shown at SITE Santa Fe's Once Within a Time exhibition (running until January 2026). I haven't seen the exhibition in person, so let me know if you visit it. For more about Marilou Schultz's art, see The Diné Weaver Who Turns Microchips Into Art, or A Conversation with Marilou Schultz on YouTube.&lt;/p&gt;
    &lt;p&gt;Many thanks to Marilou Schultz for discussing her art with me. Thanks to First American Art Magazine for providing the photo of her 555 rug. Follow me on Mastodon (@[email protected]), Bluesky (@righto.com), or RSS for updates.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45152779</guid></item><item><title>Qantas is cutting executive bonuses after data breach</title><link>https://www.flightglobal.com/airlines/qantas-slashes-executive-pay-by-15-after-data-breach/164398.article</link><description>&lt;doc fingerprint="ca928bf34d14a7a5"&gt;
  &lt;main&gt;
    &lt;p&gt;Qantas has slashed short-term bonuses for its senior leadership, following a cyber breach in late-June which exposed millions of customers’ personal data.&lt;/p&gt;
    &lt;p&gt;Releasing its annual report for the year ended 30 June, the Australian carrier says it is cutting the executive bonuses by 15% for the fiscal year.&lt;/p&gt;
    &lt;p&gt;Group CEO Vanessa Hudson will see her pay slashed by A$250,000 ($163,000), while five other executives on the Qantas leadership team will lose a combined A$550,000.&lt;/p&gt;
    &lt;p&gt;Airline chair John Mullen says the bonus cuts reflect the leadership team’s “shared accountability, while acknowledging the ongoing efforts to support customers and put in place additional protections for customers”.&lt;/p&gt;
    &lt;p&gt;Qantas in late-June was hit by a data breach at one of its contact centres, with the personal information of over 6 million customers compromised. The incident occurred when a cyber criminal “targeted a call centre and gained access to a third-party customer servicing platform”, according to the airline.&lt;/p&gt;
    &lt;p&gt;“While we recognise that the investigations into this incident may not be finalised for some time and there may be other outworkings, we believe it is important for both our executives and shareholders that the remuneration consequences of this incident be dealt with this year,” it adds.&lt;/p&gt;
    &lt;p&gt;Still, the annual report shows that Qantas’ senior leadership salaries were higher than the year-ago period, despite the bonus cuts. Hudson’s annual salary, for example, stood at around A$6.3 million, higher than the A$4.4 million in the previous financial year.&lt;/p&gt;
    &lt;p&gt;Similarly, the five other executives, which includes chief financial officer Andrew Glance and Jetstar Group chief Stephanie Tully, also saw their annual salaries increase year on year.&lt;/p&gt;
    &lt;p&gt;Qantas Group reported a full-year underlying pre-tax profit of A$2.4 billion – its second-higher annual profit on record – on the back of strong travel demand across different market segments.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45152816</guid></item><item><title>I'm Making a Beautiful, Aesthetic and Open-Source Platform for Learning Japanese</title><link>https://kanadojo.com</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45152940</guid></item></channel></rss>