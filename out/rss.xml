<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sun, 07 Sep 2025 13:33:44 +0000</lastBuildDate><item><title>We hacked Burger King: How auth bypass led to drive-thru audio surveillance</title><link>https://bobdahacker.com/blog/rbi-hacked-drive-thrus/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45148944</guid></item><item><title>Oldest recorded transaction</title><link>https://avi.im/blag/2025/oldest-txn/</link><description>&lt;doc fingerprint="a9cfeaf676b2dbc5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Oldest recorded transaction&lt;/head&gt;
    &lt;p&gt;The other day I posted a tweet with this image which I thought was funny:&lt;/p&gt;
    &lt;p&gt;This is the oldest transaction database from 3100 BC - recording accounts of malt and barley groats. Considering this thing survived 5000 years (holy shit!) with zero downtime and has stronger durability guarantees than most databases today.&lt;/p&gt;
    &lt;p&gt;I call it rock solid durability.&lt;/p&gt;
    &lt;p&gt;This got me thinking, can I insert this date in today’s database? What is the oldest timestamp a database can support?&lt;/p&gt;
    &lt;p&gt;So I checked the top three databases: MySQL, Postgres, and SQLite:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;MySQL&lt;/cell&gt;
        &lt;cell&gt;1000 AD&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Postgres&lt;/cell&gt;
        &lt;cell&gt;4713 BC&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;SQLite&lt;/cell&gt;
        &lt;cell&gt;4713 BC&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;&lt;lb/&gt;Too bad you cannot use MySQL for this. Postgres and SQLite support the Julian calendar and the lowest date is Jan 01, 4713 BC:&lt;/p&gt;
    &lt;code&gt;sales=# INSERT INTO orders VALUES ('4713-01-01 BC'::date);
INSERT 0 1
sales=# SELECT * FROM orders;
   timestamp
---------------
 4713-01-01 BC
(1 row)
sales=# INSERT INTO orders VALUES ('4714-01-01 BC'::date);
ERROR:  date out of range: "4714-01-01 BC"
&lt;/code&gt;
    &lt;p&gt;I wonder how people store dates older than this. Maybe if I’m a British Museum manager, and I want to keep &lt;del&gt;theft&lt;/del&gt; inventory details. How do I do it? As an epoch? Store it as text? Use some custom system? How do I get it to support all the custom operations that a typical &lt;code&gt;TIMESTAMP&lt;/code&gt; supports?&lt;/p&gt;
    &lt;p&gt;Thanks to aku, happy_shady, Mr. Bhat, and General Bruh for reading an early draft of this post.&lt;/p&gt;
    &lt;p&gt;1. Source of the image: Sumer civilization&lt;lb/&gt;2. I found this from the talk 1000x: The Power of an Interface for Performance by Joran Dirk Greef, CEO of TigerBeetle, timestamped @ 38:10.&lt;lb/&gt;3. The talk has other bangers too, like this or this.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45149626</guid></item><item><title>Stop writing CLI validation. Parse it right the first time</title><link>https://hackers.pub/@hongminhee/2025/stop-writing-cli-validation-parse-it-right-the-first-time</link><description>&lt;doc fingerprint="ee5853587c453a9f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Stop writing CLI validation. Parse it right the first time.&lt;/head&gt;
    &lt;p&gt;洪 民憙 (Hong Minhee) @hongminhee@hackers.pub&lt;/p&gt;
    &lt;p&gt;I have this bad habit. When something annoys me enough times, I end up building a library for it. This time, it was CLI validation code.&lt;/p&gt;
    &lt;p&gt;See, I spend a lot of time reading other people's code. Open source projects, work stuff, random GitHub repos I stumble upon at 2 AM. And I kept noticing this thing: every CLI tool has the same ugly validation code tucked away somewhere. You know the kind:&lt;/p&gt;
    &lt;code&gt;if (!opts.server &amp;amp;&amp;amp; opts.port) {
  throw new Error("--port requires --server flag");
}

if (opts.server &amp;amp;&amp;amp; !opts.port) {
  opts.port = 3000; // default port
}

// wait, what if they pass --port without a value?
// what if the port is out of range?
// what if...&lt;/code&gt;
    &lt;p&gt;It's not even that this code is hard to write. It's that it's everywhere. Every project. Every CLI tool. The same patterns, slightly different flavors. Options that depend on other options. Flags that can't be used together. Arguments that only make sense in certain modes.&lt;/p&gt;
    &lt;p&gt;And here's what really got me: we solved this problem years ago for other types of data. Just… not for CLIs.&lt;/p&gt;
    &lt;head rend="h2"&gt;The problem with validation&lt;/head&gt;
    &lt;p&gt;There's this blog post that completely changed how I think about parsing. It's called Parse, don't validate by Alexis King. The gist? Don't parse data into a loose type and then check if it's valid. Parse it directly into a type that can only be valid.&lt;/p&gt;
    &lt;p&gt;Think about it. When you get JSON from an API, you don't just parse it as &lt;code&gt;any&lt;/code&gt;
and then write a bunch of &lt;code&gt;if&lt;/code&gt;-statements. You use something like Zod to parse
it directly into the shape you want. Invalid data? The parser rejects it. Done.&lt;/p&gt;
    &lt;p&gt;But with CLIs? We parse arguments into some bag of properties and then spend the next 100 lines checking if that bag makes sense. It's backwards.&lt;/p&gt;
    &lt;p&gt;So yeah, I built Optique. Not because the world desperately needed another CLI parser (it didn't), but because I was tired of seeing—and writing—the same validation code everywhere.&lt;/p&gt;
    &lt;head rend="h2"&gt;Three patterns I was sick of validating&lt;/head&gt;
    &lt;head rend="h3"&gt;Dependent options&lt;/head&gt;
    &lt;p&gt;This one's everywhere. You have an option that only makes sense when another option is enabled.&lt;/p&gt;
    &lt;p&gt;The old way? Parse everything, then check:&lt;/p&gt;
    &lt;code&gt;const opts = parseArgs(process.argv);
if (!opts.server &amp;amp;&amp;amp; opts.port) {
  throw new Error("--port requires --server");
}
if (opts.server &amp;amp;&amp;amp; !opts.port) {
  opts.port = 3000;
}
// More validation probably lurking elsewhere...&lt;/code&gt;
    &lt;p&gt;With Optique, you just describe what you want:&lt;/p&gt;
    &lt;code&gt;const config = withDefault(
  object({
    server: flag("--server"),
    port: option("--port", integer()),
    workers: option("--workers", integer())
  }),
  { server: false }
);&lt;/code&gt;
    &lt;p&gt;Here's what TypeScript infers for &lt;code&gt;config&lt;/code&gt;'s type:&lt;/p&gt;
    &lt;code&gt;type Config = 
  | { readonly server: false }
  | { readonly server: true; readonly port: number; readonly workers: number }&lt;/code&gt;
    &lt;p&gt;The type system now understands that when &lt;code&gt;server&lt;/code&gt; is false, &lt;code&gt;port&lt;/code&gt; literally
doesn't exist. Not &lt;code&gt;undefined&lt;/code&gt;, not &lt;code&gt;null&lt;/code&gt;—it's not there. Try to access it and
TypeScript yells at you. No runtime validation needed.&lt;/p&gt;
    &lt;head rend="h3"&gt;Mutually exclusive options&lt;/head&gt;
    &lt;p&gt;Another classic. Pick one output format: JSON, YAML, or XML. But definitely not two.&lt;/p&gt;
    &lt;p&gt;I used to write this mess:&lt;/p&gt;
    &lt;code&gt;if ((opts.json ? 1 : 0) + (opts.yaml ? 1 : 0) + (opts.xml ? 1 : 0) &amp;gt; 1) {
  throw new Error('Choose only one output format');
}&lt;/code&gt;
    &lt;p&gt;(Don't judge me, you've written something similar.)&lt;/p&gt;
    &lt;p&gt;Now?&lt;/p&gt;
    &lt;code&gt;const format = or(
  map(option("--json"), () =&amp;gt; "json" as const),
  map(option("--yaml"), () =&amp;gt; "yaml" as const),
  map(option("--xml"), () =&amp;gt; "xml" as const)
);&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;or()&lt;/code&gt; combinator means exactly one succeeds. The result is just
&lt;code&gt;"json" | "yaml" | "xml"&lt;/code&gt;. A single string. Not three booleans to juggle.&lt;/p&gt;
    &lt;head rend="h3"&gt;Environment-specific requirements&lt;/head&gt;
    &lt;p&gt;Production needs auth. Development needs debug flags. Docker needs different options than local. You know the drill.&lt;/p&gt;
    &lt;p&gt;Instead of a validation maze, you just describe each environment:&lt;/p&gt;
    &lt;code&gt;const envConfig = or(
  object({
    env: constant("prod"),
    auth: option("--auth", string()),      // Required in prod
    ssl: option("--ssl"),
    monitoring: option("--monitoring", url())
  }),
  object({
    env: constant("dev"),
    debug: optional(option("--debug")),    // Optional in dev
    verbose: option("--verbose")
  })
);&lt;/code&gt;
    &lt;p&gt;No auth in production? Parser fails immediately. Trying to access &lt;code&gt;--auth&lt;/code&gt; in
dev mode? TypeScript won't let you—the field doesn't exist on that type.&lt;/p&gt;
    &lt;head rend="h2"&gt;“But parser combinators though…”&lt;/head&gt;
    &lt;p&gt;I know, I know. “Parser combinators” sounds like something you'd need a CS degree to understand.&lt;/p&gt;
    &lt;p&gt;Here's the thing: I don't have a CS degree. Actually, I don't have any degree. But I've been using parser combinators for years because they're actually… not that hard? It's just that the name makes them sound way scarier than they are.&lt;/p&gt;
    &lt;p&gt;I'd been using them for other stuff—parsing config files, DSLs, whatever. But somehow it never clicked that you could use them for CLI parsing until I saw Haskell's optparse-applicative. That was a real “wait, of course” moment. Like, why are we doing this any other way?&lt;/p&gt;
    &lt;p&gt;Turns out it's stupidly simple. A parser is just a function. Combinators are just functions that take parsers and return new parsers. That's it.&lt;/p&gt;
    &lt;code&gt;// This is a parser
const port = option("--port", integer());

// This is also a parser (made from smaller parsers)
const server = object({
  port: port,
  host: option("--host", string())
});

// Still a parser (parsers all the way down)
const config = or(server, client);&lt;/code&gt;
    &lt;p&gt;No monads. No category theory. Just functions. Boring, beautiful functions.&lt;/p&gt;
    &lt;head rend="h2"&gt;TypeScript does the heavy lifting&lt;/head&gt;
    &lt;p&gt;Here's the thing that still feels like cheating: I don't write types for my CLI configs anymore. TypeScript just… figures it out.&lt;/p&gt;
    &lt;code&gt;const cli = or(
  command("deploy", object({
    action: constant("deploy"),
    environment: argument(string()),
    replicas: option("--replicas", integer())
  })),
  command("rollback", object({
    action: constant("rollback"),
    version: argument(string()),
    force: option("--force")
  }))
);

// TypeScript infers this type automatically:
type Cli = 
  | { 
      readonly action: "deploy"
      readonly environment: string
      readonly replicas: number
    }
  | { 
      readonly action: "rollback"
      readonly version: string
      readonly force: boolean
    }&lt;/code&gt;
    &lt;p&gt;TypeScript knows that if &lt;code&gt;action&lt;/code&gt; is &lt;code&gt;"deploy"&lt;/code&gt;, then &lt;code&gt;environment&lt;/code&gt; exists but
&lt;code&gt;version&lt;/code&gt; doesn't. It knows &lt;code&gt;replicas&lt;/code&gt; is a &lt;code&gt;number&lt;/code&gt;. It knows &lt;code&gt;force&lt;/code&gt; is
a &lt;code&gt;boolean&lt;/code&gt;. I didn't tell it any of this.&lt;/p&gt;
    &lt;p&gt;This isn't just about nice autocomplete (though yeah, the autocomplete is great). It's about catching bugs before they happen. Forget to handle a new option somewhere? Code won't compile.&lt;/p&gt;
    &lt;head rend="h2"&gt;What actually changed for me&lt;/head&gt;
    &lt;p&gt;I've been dogfooding this for a few weeks. Some real talk:&lt;/p&gt;
    &lt;p&gt;I delete code now. Not refactor. Delete. That validation logic that used to be 30% of my CLI code? Gone. It feels weird every time.&lt;/p&gt;
    &lt;p&gt;Refactoring isn't scary. Want to know something that usually terrifies me? Changing how a CLI takes its arguments. Like going from &lt;code&gt;--input file.txt&lt;/code&gt; to
just &lt;code&gt;file.txt&lt;/code&gt; as a positional argument. With traditional parsers,
you're hunting down validation logic everywhere. With this?
You change the parser definition, TypeScript immediately shows you every place
that breaks, you fix them, done. What used to be an hour of “did I catch
everything?” is now “fix the red squiggles and move on.”&lt;/p&gt;
    &lt;p&gt;My CLIs got fancier. When adding complex option relationships doesn't mean writing complex validation, you just… add them. Mutually exclusive groups? Sure. Context-dependent options? Why not. The parser handles it.&lt;/p&gt;
    &lt;p&gt;The reusability is real too:&lt;/p&gt;
    &lt;code&gt;const networkOptions = object({
  host: option("--host", string()),
  port: option("--port", integer())
});

// Reuse everywhere, compose differently
const devServer = merge(networkOptions, debugOptions);
const prodServer = merge(networkOptions, authOptions);
const testServer = merge(networkOptions, mockOptions);&lt;/code&gt;
    &lt;p&gt;But honestly? The biggest change is trust. If it compiles, the CLI logic works. Not “probably works” or “works unless someone passes weird arguments.” It just works.&lt;/p&gt;
    &lt;head rend="h2"&gt;Should you care?&lt;/head&gt;
    &lt;p&gt;If you're writing a 10-line script that takes one argument, you don't need this. &lt;code&gt;process.argv[2]&lt;/code&gt; and call it a day.&lt;/p&gt;
    &lt;p&gt;But if you've ever:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Had validation logic get out of sync with your actual options&lt;/item&gt;
      &lt;item&gt;Discovered in production that certain option combinations explode&lt;/item&gt;
      &lt;item&gt;Spent an afternoon tracking down why &lt;code&gt;--verbose&lt;/code&gt;breaks when used with&lt;code&gt;--json&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Written the same “option A requires option B” check for the fifth time&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Then yeah, maybe you're tired of this stuff too.&lt;/p&gt;
    &lt;p&gt;Fair warning: Optique is young. I'm still figuring things out, the API might shift a bit. But the core idea—parse, don't validate—that's solid. And I haven't written validation code in months.&lt;/p&gt;
    &lt;p&gt;Still feels weird. Good weird.&lt;/p&gt;
    &lt;head rend="h2"&gt;Try it or don't&lt;/head&gt;
    &lt;p&gt;If this resonates:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tutorial: Build something real, see if you hate it&lt;/item&gt;
      &lt;item&gt;Concepts: Primitives, constructs, modifiers, value parsers, the whole thing&lt;/item&gt;
      &lt;item&gt;GitHub: The code, issues, angry rants&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I'm not saying Optique is the answer to all CLI problems. I'm just saying I was tired of writing the same validation code everywhere, so I built something that makes it unnecessary.&lt;/p&gt;
    &lt;p&gt;Take it or leave it. But that validation code you're about to write? You probably don't need it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45151622</guid></item><item><title>How the “Kim” dump exposed North Korea's credential theft playbook</title><link>https://dti.domaintools.com/inside-the-kimsuky-leak-how-the-kim-dump-exposed-north-koreas-credential-theft-playbook/</link><description>&lt;doc fingerprint="3599949f0a828e4a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Inside the Kimsuky Leak: How the “Kim” Dump Exposed North Korea’s Credential Theft Playbook&lt;/head&gt;
    &lt;p&gt;Contents:&lt;lb/&gt;Part I: Technical Analysis&lt;lb/&gt;Part II: Goals Analysis&lt;lb/&gt;Part III: Threat Intelligence Report&lt;/p&gt;
    &lt;head rend="h2"&gt;Executive Summary&lt;/head&gt;
    &lt;p&gt;A rare and revealing breach attributed to a North Korean-affiliated actor, known only as “Kim” as named by the hackers who dumped the data, has delivered a new insight into Kimsuky (APT43) tactics, techniques, and infrastructure. This actor’s operational profile showcases credential-focused intrusions targeting South Korean and Taiwanese networks, with a blending of Chinese-language tooling, infrastructure, and possible logistical support. The “Kim” dump, which includes bash histories, phishing domains, OCR workflows, compiled stagers, and rootkit evidence, reflects a hybrid operation situated between DPRK attribution and Chinese resource utilization.&lt;/p&gt;
    &lt;p&gt;This report is broken down into three parts:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Technical Analysis of the dump materials&lt;/item&gt;
      &lt;item&gt;Motivation and Goals of the APT actor (group)&lt;/item&gt;
      &lt;item&gt;A CTI report compartment for analysts&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;While this leak only gives a partial idea of what the Kimusky/PRC activities have been, the material provides insight into the expansion of activities, nature of the actor(s), and goals they have in their penetration of the South Korean governmental systems that would benefit not only DPRK, but also PRC.&lt;/p&gt;
    &lt;p&gt;Without a doubt, there will be more coming out from this dump in the future, particularly if the burned assets have not been taken offline and access is still available, or if others have cloned those assets for further analysis. We may revisit this in the future if additional novel information comes to light.&lt;/p&gt;
    &lt;head rend="h1"&gt;Part I: Technical Analysis&lt;/head&gt;
    &lt;head rend="h2"&gt;The Leak at a Glance&lt;/head&gt;
    &lt;p&gt;The leaked dataset attributed to the “Kim” operator offers a uniquely operational perspective into North Korean-aligned cyber operations. Among the contents were terminal history files revealing active malware development efforts using NASM (Netwide Assembler), a choice consistent with low-level shellcode engineering typically reserved for custom loaders and injection tools. These logs were not static forensic artifacts but active command-line histories showing iterative compilation and cleanup processes, suggesting a hands-on attacker directly involved in tool assembly.&lt;/p&gt;
    &lt;p&gt;In parallel, the operator ran OCR (Optical Character Recognition) commands against sensitive Korean PDF documents related to public key infrastructure (PKI) standards and VPN deployments. These actions likely aimed to extract structured language or configurations for use in spoofing, credential forgery, or internal tool emulation.&lt;/p&gt;
    &lt;p&gt;Privileged Access Management (PAM) logs also surfaced in the dump, detailing a timeline of password changes and administrative account use. Many were tagged with the Korean string 변경완료 (“change complete”), and the logs included repeated references to elevated accounts such as oracle, svradmin, and app_adm01, indicating sustained access to critical systems.&lt;/p&gt;
    &lt;p&gt;The phishing infrastructure was extensive. Domain telemetry pointed to a network of malicious sites designed to mimic legitimate Korean government portals. Sites like nid-security[.]com were crafted to fool users into handing over credentials via advanced AiTM (Adversary-in-the-Middle) techniques.&lt;/p&gt;
    &lt;p&gt;Finally, network artifacts within the dump showed targeted reconnaissance of Taiwanese government and academic institutions. Specific IP addresses and .tw domain access, along with attempts to crawl .git repositories, reveal a deliberate focus on high-value administrative and developer targets.&lt;/p&gt;
    &lt;p&gt;Perhaps most concerning was the inclusion of a Linux rootkit using syscall hooking (khook) and stealth persistence via directories like /usr/lib64/tracker-fs. This highlights a capability for deep system compromise and covert command-and-control operations, far beyond phishing and data theft.&lt;/p&gt;
    &lt;p&gt;Artifacts recovered from the dump include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Terminal history files demonstrating malware compilation using NASM&lt;/item&gt;
      &lt;item&gt;OCR commands parsing Korean PDF documents related to PKI and VPN infrastructure&lt;/item&gt;
      &lt;item&gt;PAM logs reflecting password changes and credential lifecycle events&lt;/item&gt;
      &lt;item&gt;Phishing infrastructure mimicking Korean government sites&lt;/item&gt;
      &lt;item&gt;IP addresses indicating reconnaissance of Taiwanese government and research institutions&lt;/item&gt;
      &lt;item&gt;Linux rootkit code using syscall hooking and covert channel deployment&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Credential Theft Focus&lt;/head&gt;
    &lt;p&gt;The dump strongly emphasizes credential harvesting as a central operational goal. Key files such as 136백운규001_env.key (The presence of 136백운규001_env.key is a smoking gun indicator of stolen South Korean Government PKI material, as its structure (numeric ID + Korean name + .key) aligns uniquely with SK GPKI issuance practices and provides clear evidence of compromised, identity-tied state cryptographic keys.) This was discovered alongside plaintext passwords, that indicate clear evidence of active compromise of South Korea’s GPKI (Government Public Key Infrastructure). Possession of such certificates would allow for highly effective identity spoofing across government systems.&lt;/p&gt;
    &lt;p&gt;PAM logs further confirmed this focus, showing a pattern of administrative account rotation and password resets, all timestamped and labeled with success indicators (변경완료: Change Complete). The accounts affected were not low-privilege; instead, usernames like oracle, svradmin, and app_adm01, often used by IT staff and infrastructure services, suggested access to core backend environments.&lt;/p&gt;
    &lt;p&gt;These findings point to a strategy centered on capturing and maintaining access to privileged credentials and digital certificates, effectively allowing the attacker to act as an insider within trusted systems.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Leaked .key files (e.g., 136백운규001_env.key) with plaintext passwords confirm access to GPKI systems&lt;/item&gt;
      &lt;item&gt;PAM logs show administrative password rotations tagged with 변경완료 (change complete)&lt;/item&gt;
      &lt;item&gt;Admin-level accounts such as oracle, svradmin, and app_adm01 repeatedly appear in compromised logs&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Phishing Infrastructure&lt;/head&gt;
    &lt;p&gt;The operator’s phishing infrastructure was both expansive and regionally tailored. Domains such as nid-security[.]com and webcloud-notice[.]com mimicked Korean identity and document delivery services, likely designed to intercept user logins or deploy malicious payloads. More sophisticated spoofing was seen in sites that emulated official government agencies like dcc.mil[.]kr, spo.go[.]kr, and mofa.go[.]kr.&lt;/p&gt;
    &lt;p&gt;Burner email usage added another layer of operational tradecraft. The address jeder97271[@]wuzak[.]com is likely linked to phishing kits that operated through TLS proxies, capturing credentials in real time as victims interacted with spoofed login forms.&lt;/p&gt;
    &lt;p&gt;These tactics align with previously known Kimsuky behaviors but also demonstrate an evolution in technical implementation, particularly the use of AiTM interception rather than relying solely on credential-harvesting documents.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Domains include: nid-security[.]com, html-load[.]com, webcloud-notice[.]com, koala-app[.]com, and wuzak[.]com&lt;/item&gt;
      &lt;item&gt;Mimicked portals: dcc.mil[.]kr, spo.go[.]kr, mofa.go[.]kr&lt;/item&gt;
      &lt;item&gt;Burner email evidence: jeder97271[@]wuzak[.]com&lt;/item&gt;
      &lt;item&gt;Phishing kits leveraged TLS proxies for AiTM credential capture&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Malware Development Activity&lt;/head&gt;
    &lt;p&gt;Kim’s malware development environment showcased a highly manual, tailored approach. Shellcode was compiled using NASM, specifically with flags like -f win32, revealing a focus on targeting Windows environments. Commands such as make and rm were used to automate and sanitize builds, while hashed API call resolution (VirtualAlloc, HttpSendRequestA, etc.) was implemented to evade antivirus heuristics.&lt;/p&gt;
    &lt;p&gt;The dump also revealed reliance on GitHub repositories known for offensive tooling. TitanLdr, minbeacon, Blacklotus, and CobaltStrike-Auto-Keystore were all cloned or referenced in command logs. This hybrid use of public frameworks for private malware assembly is consistent with modern APT workflows.&lt;/p&gt;
    &lt;p&gt;A notable technical indicator was the use of the proxyres library to extract Windows proxy settings, particularly via functions like proxy_config_win_get_auto_config_url. This suggests an interest in hijacking or bypassing network-level security controls within enterprise environments.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Manual shellcode compilation via nasm -f win32 source/asm/x86/start.asm&lt;/item&gt;
      &lt;item&gt;Use of make, rm, and hash obfuscation of Win32 API calls (e.g., VirtualAlloc, HttpSendRequestA)&lt;/item&gt;
      &lt;item&gt;GitHub tools in use: TitanLdr, minbeacon, Blacklotus, CobaltStrike-Auto-Keystore&lt;/item&gt;
      &lt;item&gt;Proxy configuration probing through proxyres library (proxy_config_win_get_auto_config_url)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Rootkit Toolkit and Implant Structure&lt;/head&gt;
    &lt;p&gt;The Kim dump offers deep insight into a stealthy and modular Linux rootkit attributed to the operator’s post-compromise persistence tactics. The core implant, identified as vmmisc.ko (alternatively VMmisc.ko in some shells), was designed for kernel-mode deployment across multiple x86_64 Linux distributions and utilizes classic syscall hooking and covert channeling to maintain long-term undetected access.&lt;/p&gt;
    &lt;head rend="h3"&gt;Google Translation of Koh doc: Rootkit Endpoint Reuse Authentication Tool&lt;/head&gt;
    &lt;p&gt;“This tool uses kernel-level rootkit hiding technology, providing a high degree of stealth and penetration connection capability. It can hide while running on common Linux systems, and at the kernel layer supports connection forwarding, allowing reuse of external ports to connect to controlled hosts. Its communication behavior is hidden within normal traffic.&lt;/p&gt;
    &lt;p&gt;The tool uses binary merging technology: at compile time, the application layer program is encrypted and fused into a .ko driver file. When installed, only the .ko file exists. When the .ko driver starts, it will automatically decompress and release the hidden application-layer program.&lt;/p&gt;
    &lt;p&gt;Tools like chkrootkit, rkhunter, and management utilities (such as ps, netstat, etc.) are bypassed through technical evasion and hiding, making them unable to detect hidden networks, ports, processes, or file information.&lt;/p&gt;
    &lt;p&gt;To ensure software stability, all functions have also passed stress testing.&lt;/p&gt;
    &lt;p&gt;Supported systems: Linux Kernel 2.6.x / 3.x / 4.x, both x32 and x64 systems”.&lt;/p&gt;
    &lt;p&gt;Implant Features and Behavior&lt;/p&gt;
    &lt;p&gt;This rootkit exhibits several advanced features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Syscall Hooking: Hooks critical kernel functions (e.g., getdents, read, write) to hide files, directories, and processes by name or PID.&lt;/item&gt;
      &lt;item&gt;SOCKS5 Proxy: Integrated remote networking capability using dynamic port forwarding and chained routing.&lt;/item&gt;
      &lt;item&gt;PTY Backdoor Shell: Spawns pseudoterminals that operate as interactive reverse shells with password protection.&lt;/item&gt;
      &lt;item&gt;Encrypted Sessions: Session commands must match a pre-set passphrase (e.g., testtest) to activate rootkit control mode.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Once installed (typically using insmod vmmisc.ko), the rootkit listens silently and allows manipulation via an associated client binary found in the dump. The client supports an extensive set of interactive commands, including:&lt;/p&gt;
    &lt;p&gt;+p # list hidden processes&lt;/p&gt;
    &lt;p&gt;+f # list hidden files&lt;/p&gt;
    &lt;p&gt;callrk # load client ↔ kernel handshake&lt;/p&gt;
    &lt;p&gt;exitrk # gracefully unload implant&lt;/p&gt;
    &lt;p&gt;shell # spawn reverse shell&lt;/p&gt;
    &lt;p&gt;socks5 # initiate proxy channel&lt;/p&gt;
    &lt;p&gt;upload / download # file transfer interface&lt;/p&gt;
    &lt;p&gt;These capabilities align closely with known DPRK malware behaviors, particularly from the Kimsuky and Lazarus groups, who have historically leveraged rootkits for lateral movement, stealth, persistence, and exfiltration staging.&lt;/p&gt;
    &lt;head rend="h2"&gt;Observed Deployment&lt;/head&gt;
    &lt;p&gt;Terminal history (.bash_history) shows the implant was staged and tested from the following paths:&lt;/p&gt;
    &lt;code&gt;.cache/vmware/drag_and_drop/VMmisc.ko

/usr/lib64/tracker-fs/vmmisc.ko

Execution logs show the use of commands such as:

insmod /usr/lib64/tracker-fs/vmmisc.ko

./client 192.168.0[.]39 testtest&lt;/code&gt;
    &lt;p&gt;These paths were not random—they mimic legitimate system service locations to avoid detection by file integrity monitoring (FIM) tools.&lt;/p&gt;
    &lt;p&gt;This structure highlights the modular, command-activated nature of the implant and its ability to serve multiple post-exploitation roles while maintaining stealth through kernel-layer masking.&lt;/p&gt;
    &lt;head rend="h2"&gt;Strategic Implications&lt;/head&gt;
    &lt;p&gt;The presence of such an advanced toolkit in the “Kim” dump strongly suggests the actor had persistent access to Linux server environments, likely via credential compromise. The use of kernel-mode implants also indicates long-term intent and trust-based privilege escalation. The implant’s pathing, language patterns, and tactics (e.g., use of /tracker-fs/, use of test passwords) match TTPs previously observed in operations attributed to Kimsuky, enhancing confidence in North Korean origin.&lt;/p&gt;
    &lt;head rend="h2"&gt;OCR-Based Recon&lt;/head&gt;
    &lt;p&gt;A defining component of Kim’s tradecraft was the use of OCR to analyze Korean-language security documentation. The attacker issued commands such as ocrmypdf -l kor+eng “file.pdf” to parse documents like 별지2)행정전자서명_기술요건_141125.pdf (“Appendix 2: Administrative Electronic Signature_Technical Requirements_141125.pdf”) and SecuwaySSL U_카달로그.pdf (“SecuwaySSL U_Catalog.pdf”). These files contain technical language around digital signatures, SSL implementations, and identity verification standards used in South Korea’s PKI infrastructure.&lt;/p&gt;
    &lt;p&gt;This OCR-based collection approach indicates more than passive intelligence gathering – it reflects a deliberate effort to model and potentially clone government-grade authentication systems. The use of bilingual OCR (Korean + English) further confirms the operator’s intention to extract usable configuration data across documentation types.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;OCR commands used to extract Korean PKI policy language from PDFs such as (별지2)행정전자서명_기술요건_141125.pdf and SecuwaySSL U_카달로그.pdf &lt;list rend="ul"&gt;&lt;item&gt;별지2)행정전자서명_기술요건_141125.pdf → (Appendix 2: Administrative Electronic Signature_Technical Requirements_141125.pdf&lt;/item&gt;&lt;item&gt;SecuwaySSL U_카달로그.pdf → SecuwaySSL U_Catalog.pdf&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Command examples: ocrmypdf -l kor+eng “file.pdf”&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;SSH and Log-Based Evidence&lt;/head&gt;
    &lt;p&gt;The forensic evidence contained within the logs, specifically SSH authentication records and PAM outputs, provides clear technical confirmation of the operator’s tactics and target focus.&lt;/p&gt;
    &lt;p&gt;Several IP addresses stood out as sources of brute-force login attempts. These include 23.95.213[.]210 (a known VPS provider used in past credential-stuffing campaigns), 218.92.0[.]210 (allocated to a Chinese ISP), and 122.114.233[.]77 (Henan Mobile, China). These IPs were recorded during multiple failed login events, strongly suggesting automated password attacks against exposed SSH services. Their geographic distribution and known history in malicious infrastructure usage point to an external staging environment, possibly used for pivoting into Korean and Taiwanese systems.&lt;/p&gt;
    &lt;p&gt;Beyond brute force, the logs also contain evidence of authentication infrastructure reconnaissance. Multiple PAM and OCSP (Online Certificate Status Protocol) errors referenced South Korea’s national PKI authority, including domains like gva.gpki.go[.]kr and ivs.gpki.go[.]kr. These errors appear during scripted or automated access attempts, indicating a potential strategy of credential replay or certificate misuse against GPKI endpoints, an approach that aligns with Kim’s broader PKI-targeting operations.&lt;/p&gt;
    &lt;p&gt;Perhaps the most revealing detail was the presence of successful superuser logins labeled with the Korean term 최고 관리자 (“Super Administrator”). This suggests the actor was not just harvesting credentials but successfully leveraging them for privileged access, possibly through cracked accounts, reused credentials, or insider-sourced passwords. The presence of such accounts in conjunction with password rotation entries marked as 변경완료 (“change complete”) further implies active control over PAM-protected systems during the operational window captured in the dump.&lt;/p&gt;
    &lt;p&gt;Together, these logs demonstrate a methodical campaign combining external brute-force access, PKI service probing, and administrative credential takeover, a sequence tailored for persistent infiltration and lateral movement within sensitive government and enterprise networks.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Brute-force IPs: 23.95.213[.]210, 218.92.0[.]210, 122.114.233[.]77&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;IP Address&lt;/cell&gt;
        &lt;cell&gt;Origin&lt;/cell&gt;
        &lt;cell&gt;Role / Threat Context&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;218.92.0[.]210&lt;/cell&gt;
        &lt;cell&gt;China Telecom (Jiangsu)&lt;/cell&gt;
        &lt;cell&gt;Part of Chinanet backbone, likely proxy or scanning node&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;23.95.213[.]210&lt;/cell&gt;
        &lt;cell&gt;Colocrossing (US)&lt;/cell&gt;
        &lt;cell&gt;Frequently used in brute-force and anonymized hosting for malware ops&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;122.114.233[.]77&lt;/cell&gt;
        &lt;cell&gt;Presumed PRC local ISP&lt;/cell&gt;
        &lt;cell&gt;Possibly mobile/ISP-based proxy used to obfuscate lateral movement&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PAM/OCSP errors targeting gva.gpki.go[.]kr, ivs.gpki.go[.]kr&lt;/item&gt;
      &lt;item&gt;Superuser login events under 최고 관리자 (Super Administrator)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Part II: Goals Analysis&lt;/head&gt;
    &lt;head rend="h2"&gt;Targeting South Korea: Identity, Infrastructure, and Credential Theft&lt;/head&gt;
    &lt;p&gt;The “Kim” operator’s campaign against South Korea was deliberate and strategic, aiming to infiltrate the nation’s digital trust infrastructure at multiple levels. A central focus was the Government Public Key Infrastructure (GPKI), where the attacker exfiltrated certificate files, including .key and .crt formats, some with plaintext passwords, and attempted repeated authentication against domains like gva.gpki.go[.]kr and ivs.gpki.go[.]kr. OCR tools were used to parse Korean technical documents detailing PKI and VPN architectures, demonstrating a sophisticated effort to understand and potentially subvert national identity frameworks. These efforts were not limited to reconnaissance; administrative password changes were logged, and phishing kits targeted military and diplomatic webmail, including clones of mofa.go[.]kr and credential harvesting through adversary-in-the-middle (AiTM) proxy setups.&lt;/p&gt;
    &lt;p&gt;Beyond authentication systems, Kim targeted privileged accounts (oracle, unwadm, svradmin) and rotated credentials to maintain persistent administrative access, as evidenced by PAM and SSH logs showing elevated user activity under the title 최고 관리자 (“Super Administrator”). The actor also showed interest in bypassing VPN controls, parsing SecuwaySSL configurations for exploitation potential, and deployed custom Linux rootkits using syscall hooking to establish covert persistence on compromised machines. Taken together, the dump reveals a threat actor deeply invested in credential dominance, policy reconnaissance, and system-level infiltration, placing South Korea’s public sector identity systems, administrative infrastructure, and secure communications at the core of its long-term espionage objectives.&lt;/p&gt;
    &lt;head rend="h2"&gt;Taiwan Reconnaissance&lt;/head&gt;
    &lt;p&gt;Among the most notable aspects of the “Kim” leak is the operator’s deliberate focus on Taiwanese infrastructure. The attacker accessed a number of domains with clear affiliations to the island’s public and private sectors, including tw.systexcloud[.]com (linked to enterprise cloud solutions), mlogin.mdfapps[.]com (a mobile authentication or enterprise login portal), and the .git/ directory of caa.org[.]tw, which belongs to the Chinese Institute of Aeronautics, a government-adjacent research entity.&lt;/p&gt;
    &lt;p&gt;This last domain is especially telling. Accessing .git/ paths directly implies an attempt to enumerate internal source code repositories, a tactic often used to discover hardcoded secrets, API keys, deployment scripts, or developer credentials inadvertently exposed via misconfigured web servers. This behavior points to more technical depth than simple phishing; it indicates supply chain reconnaissance and long-term infiltration planning.&lt;/p&gt;
    &lt;p&gt;The associated IP addresses further reinforce this conclusion. All three, 163.29.3[.]119, 118.163.30[.]45, and 59.125.159[.]81, are registered to academic, government, or research backbone providers in Taiwan. These are not random scans; they reflect targeted probing of strategic digital assets.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary of Whois &amp;amp; Ownership Insights&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;118.163.30[.]45 &lt;list rend="ul"&gt;&lt;item&gt;Appears as part of the IP range used for the domain dtc-tpe.com[.]tw, linked to Taiwan’s HINET provider (118.163.30[.]46 )Site Indices page of HINET provider.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;163.29.3[.]119 &lt;list rend="ul"&gt;&lt;item&gt;Falls within the 163.29.3[.]0/24 subnet identified with Taiwanese government or institutional use, notably in Taipei. This corresponds to B‑class subnets assigned to public/government entities IP地址 (繁體中文).&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;59.125.159[.]81&lt;list rend="ul"&gt;&lt;item&gt;Belongs to the broader 59.125.159[.]0–59.125.159[.]254 block, commonly used by Taiwanese ISP operators such as Chunghwa Telecom in Taipei&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Taken together, this Taiwan-focused activity reveals an expanded operational mandate. Whether the attacker is purely DPRK-aligned or operating within a DPRK–PRC fusion cell, the intent is clear: compromise administrative and developer infrastructure in Taiwan, likely in preparation for broader credential theft, espionage, or disruption campaigns.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Targeted domains: tw.systexcloud[.]com, caa.org[.]tw/.git/, mlogin.mdfapps[.]com&lt;/item&gt;
      &lt;item&gt;IPs linked to Taiwanese academic/government assets: 163.29.3[.]119, 118.163.30[.]45, 59.125.159[.]81&lt;/item&gt;
      &lt;item&gt;Git crawling suggests interest in developer secrets or exposed tokens&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Hybrid Attribution Model&lt;/head&gt;
    &lt;p&gt;The “Kim” operator embodies the growing complexity of modern nation-state attribution, where cyber activities often blur traditional boundaries and merge capabilities across geopolitical spheres. This case reveals strong indicators of both North Korean origin and Chinese operational entanglement, presenting a textbook example of a hybrid APT model.&lt;/p&gt;
    &lt;p&gt;On one hand, the technical and linguistic evidence strongly supports a DPRK-native operator. Terminal environments, OCR parsing routines, and system artifacts consistently leverage Korean language and character sets. The operator’s activities reflect a deep understanding of Korean PKI systems, with targeted extraction of GPKI .key files and automation to parse sensitive Korean government PDF documentation. These are hallmarks of Kimsuky/APT43 operations, known for credential-focused espionage against South Korean institutions and diplomatic targets. The intent to infiltrate identity infrastructure is consistent with North Korea’s historical targeting priorities. Notably, the system time zone on Kim’s host machine was set to UTC+9 (Pyongyang Standard Time), reinforcing the theory that the actor maintains direct ties to the DPRK’s internal environment, even if operating remotely.&lt;/p&gt;
    &lt;p&gt;However, this actor’s digital footprint extends well into Chinese infrastructure. Browser and download logs reveal frequent interaction with platforms like gitee[.]com, baidu[.]com, and zhihu[.]com, highly popular within the PRC but unusual for DPRK operators who typically minimize exposure to foreign services. Moreover, session logs include simplified Chinese content and PRC browsing behaviors, suggesting that the actor may be physically operating within China or through Chinese-language systems. This aligns with longstanding intelligence on North Korean cyber operators stationed in Chinese border cities such as Shenyang and Dandong, where DPRK nationals often conduct cyber operations with tacit approval or logistical consent from Chinese authorities. These locations provide higher-speed internet, relaxed oversight, and convenient geopolitical proximity.&lt;/p&gt;
    &lt;p&gt;The targeting of Taiwanese infrastructure further complicates attribution. Kimsuky has not historically prioritized Taiwan, yet in this case, the actor demonstrated direct reconnaissance of Taiwanese government and developer networks. While this overlaps with Chinese APT priorities, recent evidence from the “Kim” dump, including analysis of phishing kits and credential theft workflows, suggests this activity was likely performed by a DPRK actor exploring broader regional interests, possibly in alignment with Chinese strategic goals. Researchers have noted that Kimsuky operators have recently asked questions in phishing lures related to potential Chinese-Taiwanese conflicts, implying interest beyond the Korean peninsula.&lt;/p&gt;
    &lt;p&gt;Some tooling overlaps with PRC-linked APTs, particularly GitHub-based stagers and proxy-resolving modules, but these are not uncommon in the open-source malware ecosystem and may reflect opportunistic reuse rather than deliberate mimicry.&lt;/p&gt;
    &lt;head rend="h2"&gt;IMINT Analysis: Visual Tradecraft and Cultural Camouflage&lt;/head&gt;
    &lt;p&gt;A review of image artifacts linked to the “Kim” actor reveals a deliberate and calculated use of Chinese social and technological visual content as part of their operational persona. These images, extracted from browser history and uploads attributed to the actor, demonstrate both strategic alignment with DPRK priorities and active cultural camouflage within the PRC digital ecosystem.&lt;/p&gt;
    &lt;p&gt;The visual set includes promotional graphics for Honor smartphones, SoC chipset evolution charts, Weibo posts featuring vehicle registration certificates, meme-based sarcasm, and lifestyle imagery typical of Chinese internet users. Notably, the content is exclusively rendered in simplified Chinese, reinforcing prior assessments that the operator either resides within mainland China or maintains a working digital identity embedded in Chinese platforms. Devices and services referenced, such as Xiaomi phones, Zhihu, Weibo, and Baidu, suggest intimate familiarity with PRC user environments.&lt;/p&gt;
    &lt;p&gt;Operationally, this behavior achieves two goals. First, it enables the actor to blend in seamlessly with native PRC user activity, which complicates attribution and helps bypass platform moderation or behavioral anomaly detection. Second, the content itself may serve as bait or credibility scaffolding (e.g. A framework to give the illusion of trust to allow for easier compromise ) in phishing and social engineering campaigns, especially those targeting developers or technical users on Chinese-language platforms.&lt;/p&gt;
    &lt;p&gt;Some images, such as the detailed chipset timelines and VPN or device certification posts, suggest a continued interest in supply chain reconnaissance and endpoint profiling—both tradecraft hallmarks of Kimsuky and similar APT units. Simultaneously, meme humor, sarcastic overlays, and visual metaphors (e.g., the “Kaiju’s tail is showing” idiom) indicate the actor’s fluency in PRC netizen culture and possible mockery of operational security breaches—whether their own or others’.&lt;/p&gt;
    &lt;p&gt;Taken together, this IMINT corpus supports the broader attribution model: a DPRK-origin operator embedded, physically or virtually, within the PRC, leveraging local infrastructure and social platforms to facilitate long-term campaigns against South Korea, Taiwan, and other regional targets while maintaining cultural and technical deniability.&lt;/p&gt;
    &lt;head rend="h2"&gt;Attribution Scenarios:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Option A: DPRK Operator Embedded in PRC&lt;list rend="ul"&gt;&lt;item&gt;Use of Korean language, OCR targeting of Korean documents, and focus on GPKI systems strongly suggest North Korean origin.&lt;/item&gt;&lt;item&gt;Use of PRC infrastructure (e.g., Baidu, Gitee) and simplified Chinese content implies the operator is physically located in China or benefits from access to Chinese internet infrastructure.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Use of Korean language, OCR targeting of Korean documents, and focus on GPKI systems strongly suggest North Korean origin.&lt;/item&gt;
      &lt;item&gt;Option B: PRC Operator Emulating DPRK&lt;list rend="ul"&gt;&lt;item&gt;Taiwan-focused reconnaissance aligns with PRC cyber priorities.&lt;/item&gt;&lt;item&gt;Use of open-source tooling and phishing methods shared with PRC APTs could indicate tactical emulation.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Taiwan-focused reconnaissance aligns with PRC cyber priorities.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The preponderance of evidence supports the hypothesis that “Kim” is a North Korean cyber operator embedded in China or collaborating with PRC infrastructure providers. This operational model allows the DPRK to amplify its reach, mask attribution, and adopt regional targeting strategies beyond South Korea, particularly toward Taiwan. As this hybrid model matures, it reflects the strategic adaptation of DPRK-aligned threat actors who exploit the permissive digital environment of Chinese networks to evade detection and expand their operational playbook.&lt;/p&gt;
    &lt;head rend="h2"&gt;Targeting Profiles&lt;/head&gt;
    &lt;p&gt;The “Kim” leak provides one of the clearest windows to date into the role-specific targeting preferences of the operator, revealing a deliberate focus on system administrators, credential issuers, and backend developers, particularly in South Korea and Taiwan.&lt;/p&gt;
    &lt;p&gt;In South Korea, the operator’s interest centers around PKI administrators and infrastructure engineers. The recovered OCR commands were used to extract technical details from PDF documents outlining Korea’s digital signature protocols, such as identity verification, certificate validation, and encrypted communications, components that form the backbone of Korea’s secure authentication systems. The goal appears to be not only credential theft but full understanding and potential replication of government-trusted PKI procedures. This level of targeting suggests a strategic intent to penetrate deeply trusted systems, potentially for use in later spoofing or identity masquerading operations.&lt;/p&gt;
    &lt;p&gt;In Taiwan, the operator shifted focus to developer infrastructure and cloud access portals. Specific domains accessed, like caa.org[.]tw/.git/, indicate attempts to enumerate internal repositories, most likely to discover hardcoded secrets, authentication tokens, or deployment keys. This is a classic supply chain targeting method, aiming to access downstream systems via compromised developer credentials or misconfigured services.&lt;/p&gt;
    &lt;p&gt;Additional activity pointed to interaction with cloud service login panels such as tw.systexcloud[.]com and mlogin.mdfapps[.]com. These suggest an attempt to breach centralized authentication systems or identity providers, granting the actor broader access into enterprise or government networks with a single credential set.&lt;/p&gt;
    &lt;p&gt;Taken together, these targeting profiles reflect a clear emphasis on identity providers, backend engineers, and those with access to system-level secrets. This reinforces the broader theme of the dump: persistent, credential-first intrusion strategies, augmented by reconnaissance of authentication standards, key management policies, and endpoint development infrastructure.&lt;/p&gt;
    &lt;p&gt;South Korean:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PKI admins, infrastructure engineers&lt;/item&gt;
      &lt;item&gt;OCR focus on Korean identity standards&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Taiwanese:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Developer endpoints and internal .git/ repos&lt;/item&gt;
      &lt;item&gt;Access to cloud panels and login gateways&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Final Assessment&lt;/head&gt;
    &lt;p&gt;The “Kim” leak represents one of the most comprehensive and technically intimate disclosures ever associated with Kimsuky (APT43) or its adjacent operators. It not only reaffirms known tactics, credential theft, phishing, and PKI compromise, but exposes the inner workings of the operator’s environment, tradecraft, and operational intent in ways rarely observed outside of active forensic investigations.&lt;/p&gt;
    &lt;p&gt;At the core of the leak is a technically competent actor, well-versed in low-level shellcode development, Linux-based persistence mechanisms, and certificate infrastructure abuse. Their use of NASM, API hashing, and rootkit deployment points to custom malware authorship. Furthermore, the presence of parsed government-issued Korean PDFs, combined with OCR automation, shows not just opportunistic data collection but a concerted effort to model, mimic, or break state-level identity systems, particularly South Korea’s GPKI.&lt;/p&gt;
    &lt;p&gt;The operator’s cultural and linguistic fluency in Korean, and their targeting of administrative and privileged systems across South Korean institutions, support a high-confidence attribution to a DPRK-native threat actor. However, the extensive use of Chinese platforms like gitee[.]com, Baidu, and Zhihu, and Chinese infrastructure for both malware hosting and browsing activity reveals a geographical pivot or collaboration: a hybrid APT footprint rooted in DPRK tradecraft but operating from or with Chinese support.&lt;/p&gt;
    &lt;p&gt;Most notably, this leak uncovers a geographical expansion of operational interest; the actor is no longer solely focused on the Korean peninsula. The targeting of Taiwanese developer portals, government research IPs, and .git/ repositories shows a broadened agenda that likely maps to both espionage and supply chain infiltration priorities. This places Taiwan, like South Korea, at the forefront of North Korean cyber interest, whether for intelligence gathering, credential hijacking, or as staging points for more complex campaigns.&lt;/p&gt;
    &lt;p&gt;The threat uncovered here is not merely malware or phishing; it is an infrastructure-centric, credential-first APT campaign that blends highly manual operations (e.g., hand-compiled shellcode, direct OCR of sensitive PDFs) with modern deception tactics such as AiTM phishing and TLS proxy abuse.&lt;/p&gt;
    &lt;p&gt;Organizations in Taiwan and South Korea, particularly those managing identity, certificate, and cloud access infrastructure, should consider themselves under persistent, credential-focused surveillance. Defensive strategies must prioritize detection of behavioral anomalies (e.g., use of OCR tools, GPKI access attempts), outbound communications with spoofed Korean domains, and the appearance of low-level toolchains like NASM or proxyres-based scanning utilities within developer or admin environments.&lt;/p&gt;
    &lt;p&gt;In short: the “Kim” actor embodies the evolution of nation-state cyber threats—a fusion of old-school persistence, credential abuse, and modern multi-jurisdictional staging. The threat is long-term, embedded, and adaptive.&lt;/p&gt;
    &lt;head rend="h1"&gt;Part III: Threat Intelligence Report&lt;/head&gt;
    &lt;head rend="h2"&gt;TLP WHITE:&lt;/head&gt;
    &lt;head rend="h3"&gt;Targeting Summary&lt;/head&gt;
    &lt;p&gt;The analysis of the “Kim” operator dump reveals a highly focused credential-theft and infrastructure-access campaign targeting high-value assets in both South Korea and Taiwan. Victims were selected based on their proximity to trusted authentication systems, administrative control panels, and development environments.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Category&lt;/cell&gt;
        &lt;cell&gt;Details&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Regions&lt;/cell&gt;
        &lt;cell&gt;South Korea, Taiwan&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Targets&lt;/cell&gt;
        &lt;cell&gt;Government, Telecom, Enterprise IT&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Accounts&lt;/cell&gt;
        &lt;cell&gt;svradmin, oracle, app_adm01, unwadm, shkim88, jaejung91&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Domains&lt;/cell&gt;
        &lt;cell&gt;tw.systexcloud[.]com, nid-security[.]com, spo.go[.]kr, caa.org[.]tw/.git/&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Indicators of Compromise (IOCs)&lt;/head&gt;
    &lt;head rend="h4"&gt;Domains&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Phishing: nid-security[.]com, html-load[.]com, wuzak[.]com, koala-app[.]com, webcloud-notice[.]com&lt;/item&gt;
      &lt;item&gt;Spoofed portals: dcc.mil[.]kr, spo.go[.]kr, mofa.go[.]kr&lt;/item&gt;
      &lt;item&gt;Pastebin raw links: Used for payload staging and malware delivery&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;IP Addresses&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;External Targets (Taiwan): &lt;list rend="ul"&gt;&lt;item&gt;163.29.3[.]119 National Center for High-performance Computing&lt;/item&gt;&lt;item&gt;118.163.30[.]45 Taiwanese government subnet&lt;/item&gt;&lt;item&gt;59.125.159[.]81 Chunghwa Telecom&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Brute Forcing / Infrastructure Origins: &lt;list rend="ul"&gt;&lt;item&gt;23.95.213[.]210 VPS provider with malicious history&lt;/item&gt;&lt;item&gt;218.92.0[.]210 China Unicom&lt;/item&gt;&lt;item&gt;122.114.233[.]77 Henan Mobile, PRC&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Internal Host IPs (Operator Environment)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;192.168.130[.]117&lt;/item&gt;
      &lt;item&gt;192.168.150[.]117&lt;/item&gt;
      &lt;item&gt;192.168.0[.]39&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Operator Environment: Internal Host IP Narrative&lt;/head&gt;
    &lt;p&gt;The presence of internal IP addresses such as 192.168.130[.]117, 192.168.150[.]117, and 192.168.0[.]39 within the dump offers valuable insight into the attacker’s local infrastructure, an often-overlooked element in threat intelligence analysis. These addresses fall within private, non-routable RFC1918 address space, commonly assigned by consumer off-the-shelf (COTS) routers and small office/home office (SOHO) network gear.&lt;/p&gt;
    &lt;p&gt;The use of the 192.168.0[.]0/16 subnet, particularly 192.168.0.x and 192.168.150.x, strongly suggests that the actor was operating from a residential or low-profile environment, not a formal nation-state facility or hardened infrastructure. This supports existing assessments that North Korean operators, particularly those affiliated with Kimsuky, often work remotely from locations in third countries such as China or Southeast Asia, where they can maintain inconspicuous, low-cost setups while accessing global infrastructure.&lt;/p&gt;
    &lt;p&gt;Moreover, the distinction between multiple internal subnets (130.x, 150.x, and 0.x) may indicate segmentation of test environments or multiple virtual machines running within a single NATed network. This aligns with the forensic evidence of iterative development and testing workflows seen in the .bash_history files, where malware stagers, rootkits, and API obfuscation utilities were compiled, cleaned, and rerun repeatedly.&lt;/p&gt;
    &lt;p&gt;Together, these IPs reveal an operator likely working from a clandestine, residential base of operations, with modest hardware and commercial-grade routers. This operational setup is consistent with known DPRK remote IT workers and cyber operators who avoid attribution by blending into civilian infrastructure. It also suggests the attacker may be physically located outside of North Korea, possibly embedded in a friendly or complicit environment, strengthening the case for China-based activity by DPRK nationals.&lt;/p&gt;
    &lt;head rend="h3"&gt;MITRE ATT&amp;amp;CK Mapping&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Phase&lt;/cell&gt;
        &lt;cell&gt;Technique(s)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Initial Access&lt;/cell&gt;
        &lt;cell&gt;T1566.002 , Adversary-in-the-Middle (AiTM) Phishing&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Execution&lt;/cell&gt;
        &lt;cell&gt;T1059.005 , Native API ShellcodeT1059.003 , Bash/Shell Scripts&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Credential Access&lt;/cell&gt;
        &lt;cell&gt;T1555 , Credential Store DumpingT1557.003 , Session Hijacking&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Persistence&lt;/cell&gt;
        &lt;cell&gt;T1176 , Rootkit (via khook syscall manipulation)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Defense Evasion&lt;/cell&gt;
        &lt;cell&gt;T1562.001 , Disable Security ToolsT1552 , Unsecured Credential Files&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Discovery&lt;/cell&gt;
        &lt;cell&gt;T1592 , Technical Information DiscoveryT1590 , Network Information&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Exfiltration&lt;/cell&gt;
        &lt;cell&gt;T1041 , Exfiltration over C2 ChannelT1567.002 , Exfil via Cloud Services&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Tooling and Capabilities&lt;/head&gt;
    &lt;p&gt;The actor’s toolkit spans multiple disciplines, blending malware development, system reconnaissance, phishing, and proxy evasion:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;NASM-based shellcode loaders: Compiled manually for Windows execution.&lt;/item&gt;
      &lt;item&gt;Win32 API hashing: Obfuscated imports via hashstring.py to evade detection.&lt;/item&gt;
      &lt;item&gt;GitHub/Gitee abuse: Tooling hosted or cloned from public developer platforms.&lt;/item&gt;
      &lt;item&gt;OCR exploitation: Used ocrmypdf to parse Korean PDF specs related to digital certificates and VPN appliances.&lt;/item&gt;
      &lt;item&gt;Rootkit deployment: Hidden persistence paths including /usr/lib64/tracker-fs and /proc/acpi/pcicard.&lt;/item&gt;
      &lt;item&gt;Proxy config extraction: Investigated PAC URLs using proxyres-based recon.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Attribution Confidence Assessment&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Attribution Candidate&lt;/cell&gt;
        &lt;cell&gt;Confidence Level&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;DPRK-aligned (Kimsuky)&lt;/cell&gt;
        &lt;cell&gt;High, Native Korean targeting, GPKI focus, OCR behavior&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;China-blended infrastructure&lt;/cell&gt;
        &lt;cell&gt;Moderate, PRC hosting, Gitee usage, Taiwan focus&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Solely PRC Actor&lt;/cell&gt;
        &lt;cell&gt;Low-to-Moderate, Tooling overlap but weak linguistic match&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Assessment: The actor appears to be a DPRK-based APT operator working from within or in partnership with Chinese infrastructure, representing a hybrid attribution model.&lt;/p&gt;
    &lt;head rend="h3"&gt;Defensive Recommendations&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Area&lt;/cell&gt;
        &lt;cell&gt;Recommendation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;PKI Security&lt;/cell&gt;
        &lt;cell&gt;Monitor usage of .key, .sig, .crt artifacts; enforce HSM or 2FA for key use&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Phishing Defense&lt;/cell&gt;
        &lt;cell&gt;Block domains identified in IoCs; validate TLS fingerprints and referrer headers&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Endpoint Hardening&lt;/cell&gt;
        &lt;cell&gt;Detect use of nasm, make, and OCR tools; monitor /usr/lib*/tracker-* paths&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Network Telemetry&lt;/cell&gt;
        &lt;cell&gt;Alert on .git/ directory access from external IPs; monitor outbound to Pastebin/GitHub&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Taiwan Focus&lt;/cell&gt;
        &lt;cell&gt;Establish watchlists for .tw domains targeted by PRC-originating IPs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Admin Accounts&lt;/cell&gt;
        &lt;cell&gt;Review usage logs for svradmin, oracle, app_adm01, and ensure rotation policies&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h1"&gt;APPENDIX A&lt;/head&gt;
    &lt;head rend="h2"&gt;Overlap or Confusion with Chinese Threat Actors&lt;/head&gt;
    &lt;p&gt;There is notable evidence of operational blur between Kimsuky and Chinese APTs in the context of Taiwan. The 2025 “Kim” data breach revealed an attacker targeting Taiwan whose tools and phishing kits matched Kimsuky’s, yet whose personal indicators (language, browsing habits) suggested a Chinese national. Researchers concluded this actor was likely a Chinese hacker either mimicking Kimsuky tactics or collaborating with them.. In fact, the leaked files on DDoS Secrets hint that Kimsuky has “openly cooperated with other Chinese APTs and shared their tools and techniques”. This overlap can cause attribution confusion – a Taiwan-focused operation might initially be blamed on China but could involve Kimsuky elements, or vice versa. So far, consensus is that North Korean and Chinese cyber operations remain separate, but cases like “Kim” show how a DPRK-aligned actor can operate against Taiwan using TTPs common to Chinese groups, muddying the waters of attribution.&lt;/p&gt;
    &lt;head rend="h2"&gt;File List from dump:&lt;/head&gt;
    &lt;head rend="h2"&gt;Master Evidence Inventory:&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;File Name&lt;/cell&gt;
        &lt;cell&gt;Language&lt;/cell&gt;
        &lt;cell&gt;Content Summary&lt;/cell&gt;
        &lt;cell&gt;Category&lt;/cell&gt;
        &lt;cell&gt;Relevance&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;.bash_history&lt;/cell&gt;
        &lt;cell&gt;Mixed (EN/KR)&lt;/cell&gt;
        &lt;cell&gt;Operator shell history commands&lt;/cell&gt;
        &lt;cell&gt;System/Log&lt;/cell&gt;
        &lt;cell&gt;Shows rootkit compilation, file ops, network tests&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;user-bash_history&lt;/cell&gt;
        &lt;cell&gt;Mixed (EN/KR)&lt;/cell&gt;
        &lt;cell&gt;User-level shell commands&lt;/cell&gt;
        &lt;cell&gt;System/Log&lt;/cell&gt;
        &lt;cell&gt;Development and test activity&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;root-bash_history&lt;/cell&gt;
        &lt;cell&gt;Mixed (EN/KR)&lt;/cell&gt;
        &lt;cell&gt;Root-level shell commands&lt;/cell&gt;
        &lt;cell&gt;System/Log&lt;/cell&gt;
        &lt;cell&gt;Privilege-level activity, implant deployment&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;auth.log.2&lt;/cell&gt;
        &lt;cell&gt;EN/KR&lt;/cell&gt;
        &lt;cell&gt;Authentication logs (PAM/SSH)&lt;/cell&gt;
        &lt;cell&gt;System/Log&lt;/cell&gt;
        &lt;cell&gt;Credential changes marked 변경완료, brute force IPs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;20190315.log&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;System log file&lt;/cell&gt;
        &lt;cell&gt;System/Log&lt;/cell&gt;
        &lt;cell&gt;Auth and system access events&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;chrome-timeline.txt&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Browser activity timeline&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;Visited domains extraction&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;chromehistory.txt&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Browser history export&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;URLs visited&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;history.sqlite&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Empty DB file&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;No useful data&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Media History&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Empty SQLite DB&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;No playback activity&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;History&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Empty Brave/Chromium DB&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;No visited URLs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Web Data&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Autofill/search DB&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;Search engines used (Google, DuckDuckGo, Qwant, Startpage, Ecosia)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Visited Links&lt;/cell&gt;
        &lt;cell&gt;Binary&lt;/cell&gt;
        &lt;cell&gt;LevelDB/binary structure&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;Could not extract URLs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Cookies&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;SQLite DB with cookies&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;Google cookies found&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;request_log.txt.20250220&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Captured phishing session&lt;/cell&gt;
        &lt;cell&gt;Phishing&lt;/cell&gt;
        &lt;cell&gt;Spoofed spo.go.kr, base64 credential logging&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;技术说明书 – 22.docx&lt;/cell&gt;
        &lt;cell&gt;ZH&lt;/cell&gt;
        &lt;cell&gt;Chinese rootkit stealth manual&lt;/cell&gt;
        &lt;cell&gt;Rootkit&lt;/cell&gt;
        &lt;cell&gt;Kernel hiding, binary embedding&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;1.ko 图文编译 .doc&lt;/cell&gt;
        &lt;cell&gt;ZH&lt;/cell&gt;
        &lt;cell&gt;Chinese compilation guide&lt;/cell&gt;
        &lt;cell&gt;Rootkit&lt;/cell&gt;
        &lt;cell&gt;Rootkit build process&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;1. build ko .txt&lt;/cell&gt;
        &lt;cell&gt;ZH&lt;/cell&gt;
        &lt;cell&gt;Build notes&lt;/cell&gt;
        &lt;cell&gt;Rootkit&lt;/cell&gt;
        &lt;cell&gt;Implant compilation instructions&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;0. 使用.txt&lt;/cell&gt;
        &lt;cell&gt;ZH&lt;/cell&gt;
        &lt;cell&gt;Usage notes&lt;/cell&gt;
        &lt;cell&gt;Rootkit&lt;/cell&gt;
        &lt;cell&gt;Implant usage and commands&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;re 正向工具修改建议 1.0.txt&lt;/cell&gt;
        &lt;cell&gt;ZH&lt;/cell&gt;
        &lt;cell&gt;Modification notes&lt;/cell&gt;
        &lt;cell&gt;Rootkit&lt;/cell&gt;
        &lt;cell&gt;Reverse tool modification suggestions&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;1111.txt&lt;/cell&gt;
        &lt;cell&gt;ZH&lt;/cell&gt;
        &lt;cell&gt;Rootkit/tool snippet&lt;/cell&gt;
        &lt;cell&gt;Rootkit&lt;/cell&gt;
        &lt;cell&gt;Part of implant notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;client&lt;/cell&gt;
        &lt;cell&gt;Binary&lt;/cell&gt;
        &lt;cell&gt;Rootkit client binary&lt;/cell&gt;
        &lt;cell&gt;Rootkit&lt;/cell&gt;
        &lt;cell&gt;Controller for implant communication&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;SSA_AO_AD_WT_002_웹보안 프로토콜설계서_Ver1.0_.doc&lt;/cell&gt;
        &lt;cell&gt;KR&lt;/cell&gt;
        &lt;cell&gt;GPKI protocol design doc&lt;/cell&gt;
        &lt;cell&gt;PKI&lt;/cell&gt;
        &lt;cell&gt;Korean web PKI standards&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;행자부 웹보안API 인수인계.doc&lt;/cell&gt;
        &lt;cell&gt;KR&lt;/cell&gt;
        &lt;cell&gt;GPKI API deployment manual&lt;/cell&gt;
        &lt;cell&gt;PKI&lt;/cell&gt;
        &lt;cell&gt;Deployment and cert API internals&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;HIRA-IR-T02_의약품처방조제_ComLibrary_통신전문.doc&lt;/cell&gt;
        &lt;cell&gt;KR&lt;/cell&gt;
        &lt;cell&gt;Medical ComLibrary XML spec&lt;/cell&gt;
        &lt;cell&gt;Healthcare&lt;/cell&gt;
        &lt;cell&gt;Prescription system communication&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;(별지2)행정전자서명_기술요건_141125.pdf&lt;/cell&gt;
        &lt;cell&gt;KR&lt;/cell&gt;
        &lt;cell&gt;PKI requirements PDF&lt;/cell&gt;
        &lt;cell&gt;PKI&lt;/cell&gt;
        &lt;cell&gt;OCR target&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;SecuwaySSL U_카달로그.pdf&lt;/cell&gt;
        &lt;cell&gt;KR&lt;/cell&gt;
        &lt;cell&gt;VPN catalog&lt;/cell&gt;
        &lt;cell&gt;PKI/VPN&lt;/cell&gt;
        &lt;cell&gt;OCR target&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;phrack-apt-down-the-north-korea-files.pdf&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Phrack article&lt;/cell&gt;
        &lt;cell&gt;Reference&lt;/cell&gt;
        &lt;cell&gt;Background on Kimsuky dump&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Muddled Libra Threat Assessment.pdf&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Threat intel report&lt;/cell&gt;
        &lt;cell&gt;Reference&lt;/cell&gt;
        &lt;cell&gt;Comparative threat actor study&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Leaked North Korean Linux Stealth Rootkit Analysis.pdf&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Rootkit analysis&lt;/cell&gt;
        &lt;cell&gt;Reference&lt;/cell&gt;
        &lt;cell&gt;Detailed implant study&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Inside the Kimsuky Leak.docx (various)&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Threat report drafts&lt;/cell&gt;
        &lt;cell&gt;Report&lt;/cell&gt;
        &lt;cell&gt;Working versions&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;account (2).txt&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;DB export (DBsafer, TrustedOrange)&lt;/cell&gt;
        &lt;cell&gt;Infra&lt;/cell&gt;
        &lt;cell&gt;Accounts and DB changes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;result.txt&lt;/cell&gt;
        &lt;cell&gt;KR&lt;/cell&gt;
        &lt;cell&gt;Cert-related parsed data&lt;/cell&gt;
        &lt;cell&gt;Infra&lt;/cell&gt;
        &lt;cell&gt;Included GPKI .key/.sig&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;english_wikipedia.txt&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Wikipedia dump&lt;/cell&gt;
        &lt;cell&gt;Reference&lt;/cell&gt;
        &lt;cell&gt;Unrelated baseline&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;bookmarks-2021-01-04.jsonlz4&lt;/cell&gt;
        &lt;cell&gt;EN&lt;/cell&gt;
        &lt;cell&gt;Firefox bookmarks (compressed)&lt;/cell&gt;
        &lt;cell&gt;Browser&lt;/cell&gt;
        &lt;cell&gt;Needs decompression&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Screenshot translations&lt;/cell&gt;
        &lt;cell&gt;ZH&lt;/cell&gt;
        &lt;cell&gt;Chinese text (rootkit marketing blurb)&lt;/cell&gt;
        &lt;cell&gt;Rootkit&lt;/cell&gt;
        &lt;cell&gt;Kernel hiding tool description&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45152066</guid></item><item><title>Being good isn't enough</title><link>https://joshs.bearblog.dev/being-good-isnt-enough/</link><description>&lt;doc fingerprint="e4d2585d0fc66178"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Being good isn’t enough&lt;/head&gt;
    &lt;p&gt;Giving good career advice is hard. Maybe it’s because careers can look more alike than they really are. Two people can have the same title but what helps one could be rubbish for another.&lt;/p&gt;
    &lt;p&gt;Or maybe it’s that “good advice” itself is fuzzy. It depends entirely on the person receiving it. For some people it means finding work they love. For others it’s about meaning. For many it’s just getting promoted. Still, here’s what I usually say.&lt;/p&gt;
    &lt;p&gt;You have to be good at the technical work first, whatever that means for you. It’s the thing you were hired for and this has to be your first priority. And the better you are, the further this can take you. You write better code, or better reports, or better designs, and people notice. That’s enough for a while.&lt;/p&gt;
    &lt;p&gt;But eventually it’s not. Everyone around you is technically strong too. So for most of us, you won’t stand out anymore. You need to increase your impact in other ways.&lt;/p&gt;
    &lt;p&gt;The biggest gains come from combining disciplines. There are four that show up everywhere: technical skill, product thinking, project execution, and people skills. And the more senior you get, the more you’re expected to contribute to each.&lt;/p&gt;
    &lt;p&gt;Technical skill is your chosen craft. Product thinking is knowing what’s worth doing. Project execution is making sure it happens. People skills are how you work with and influence others.&lt;/p&gt;
    &lt;p&gt;Every successful effort needs all four. Try to imagine an endeavor that wouldn’t benefit from improving in these areas. I can’t think of one. If you squint, together they mean one thing: making stuff that matters actually happen. That’s how you increase your impact.&lt;/p&gt;
    &lt;p&gt;You’ll naturally pick them up over time, but slowly. You can go faster if you push yourself.&lt;/p&gt;
    &lt;p&gt;This is harder than it sounds because the less competent we are at something, the more likely we are to overestimate ourselves. It’s easy to think you’re working on what matters, or that you’re doing great technical work, but that might not be true. So how do you find your weaknesses?&lt;/p&gt;
    &lt;p&gt;I’m pretty confident you only need two things. Feedback and humility, and they work best together. Feedback shows you what to work on, and humility lets you actually hear it.&lt;/p&gt;
    &lt;p&gt;So find your weakest discipline and work on that. The fastest way is to get feedback from someone you admire and then act on it. Don’t wait for the perfect plan, doing something is almost always better than doing nothing.&lt;/p&gt;
    &lt;p&gt;Find a mentor, be a mentor. Lead a project, propose one. Do the work, present it. Create spaces for others to do the same. Do whatever it takes to get better.&lt;/p&gt;
    &lt;p&gt;And do it in the open. A common mistake is assuming work speaks for itself. It rarely does.&lt;/p&gt;
    &lt;p&gt;But all of this requires maybe the most important thing of all: agency. It’s more powerful than smarts or credentials or luck. And the best part is you can literally just choose to be high-agency. High-agency people make things happen. Low-agency people wait. And if you want to progress, you can’t wait.&lt;/p&gt;
    &lt;p&gt;This advice is like any other, fuzzy. But it does go further than simply “work harder”. It will take work and it will be hard, but it might be the difference between effort and progress.&lt;/p&gt;
    &lt;p&gt;And in the long run, the best way to get what you want is to deserve it.&lt;/p&gt;
    &lt;head rend="h2"&gt;References / Related reading&lt;/head&gt;
    &lt;p&gt;The Staff Engineers Path by Tanya Reilly heavily shaped my views. I read it every year.&lt;/p&gt;
    &lt;p&gt;Thanks for the Feedback by Douglas Stone and Sheila Heen&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45152402</guid></item><item><title>Shipping textures as PNGs is suboptimal</title><link>https://gamesbymason.com/blog/2025/stop-shipping-pngs/</link><description>&lt;doc fingerprint="1e83485230620990"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;ð¼ï¸ Stop Shipping PNGs In Your Games&lt;/head&gt;
    &lt;p&gt;Are you shipping textures to players as PNGs? The goal of this post is to convince you that this is suboptimal, and walk you through a better approach.&lt;/p&gt;
    &lt;p&gt;Iâll also share my implementation of the suggested approach, but if youâd rather do it yourself Iâll also provide you with the information you need to get started.&lt;/p&gt;
    &lt;p&gt;If youâre using a game engine, it is almost certainly doing what this post suggests automatically, but it doesnât hurt to double check!&lt;/p&gt;
    &lt;head rend="h1"&gt;Whatâs wrong with PNGs?&lt;/head&gt;
    &lt;p&gt;PNGs are great for interchange. Theyâre lossless, they compresses well, and support is ubiquitous. PNG is my image interchange format of choice.&lt;/p&gt;
    &lt;p&gt;This post isnât a criticism of PNGsâitâs just that the PNG format is designed for image data, not texture data.&lt;/p&gt;
    &lt;p&gt;Here are some examples of features you would expect out of a texture format that youâre not going to find in an image format:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Pregenerated mipmaps&lt;/item&gt;
      &lt;item&gt;Cubemaps&lt;/item&gt;
      &lt;item&gt;Premultiplied alpha&lt;list rend="ul"&gt;&lt;item&gt;Technically PNGs can be premultplied, but yours probably arenât.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Can you work around all these issues? Sure.&lt;/p&gt;
    &lt;p&gt;You can premultiply and generate your mipmaps at load time. You can ship separate images for each cuebmap face. But now youâre resigned to cheap mipmap generation, and cubemaps that are difficult to downsample correctly.&lt;/p&gt;
    &lt;p&gt;You can certainly make it work, but youâre making things unnecessarily difficult for yourself by using the wrong tool for the job.&lt;/p&gt;
    &lt;p&gt;Furthermore, texture formats have a killer feature not mentioned aboveâsupport for GPU compatible texture compression like BCn.&lt;/p&gt;
    &lt;p&gt;An in-depth explanation of GPU compression formats it out of scope for this post, but at a high level, these formats store each block of pixels as a couple of endpoints and a method for interpolating between those endpoints.&lt;/p&gt;
    &lt;p&gt;This trades mild degradation of image quality for improvements in storage, VRAM usage, and sampling performance. Itâs so good it feels like youâre cheating thermodynamics.&lt;/p&gt;
    &lt;p&gt;GPUs canât decompress PNGs on the fly, so as a result, if you ship PNGs you either canât take advantage of this compression, or you have to first decompress the PNGs and then do an extremely expensive compression step to convert to the desired block based format every time a player loads the game.&lt;/p&gt;
    &lt;p&gt;Thatâs a little goofy, right?&lt;/p&gt;
    &lt;p&gt;(EDIT: Well, itâs goofy when done naivelyâsee discussion w/ Ignacio CastaÃ±o here, something along these lines can become viable if you can transcode quickly.)&lt;/p&gt;
    &lt;head rend="h1"&gt;What texture formats are out there?&lt;/head&gt;
    &lt;p&gt;Texture formats like Khronosâ KTX2 and Microsoftâs DDS are designed for exactly our use case. Theyâre just headers followed by some image data that you can upload directly to the GPU without any additional processing.&lt;/p&gt;
    &lt;p&gt;Well, unless you use supercompression. GPU compression formats donât provide great compression ratios, so itâs typical to apply lossless compression as well (think zlib or lz4.) In that case youâll decompress, and then upload.&lt;/p&gt;
    &lt;p&gt;The meta here is to design your lossy compressor to be aware that its output is going to be losslessly compressed afterwards. This lets it make decisions that reduce entropy, improving the effectiveness of the lossless step.&lt;/p&gt;
    &lt;p&gt;I used DXT5 + lz4 compressed DDS files for Way of Rhea, Iâm switching to BC7 + zlib compressed KTX2 files for my next game. Both approaches are reasonable.&lt;/p&gt;
    &lt;p&gt;Note: I primarily develop games for desktop platforms. IIUC, on mobile, hardware support for various types of GPU compression varies but the formats are similar-ish, so the meta is to use something like Basis Universal to quickly transcode to the correct format on load.&lt;/p&gt;
    &lt;head rend="h1"&gt;Exporting to KTX2&lt;/head&gt;
    &lt;p&gt;At this point, youâre likely looking through the export menu of your image editor of choice for KTX2 and DDS, and not seeing any results.&lt;/p&gt;
    &lt;p&gt;Unfortunately, AFAICT most people end up rolling their own exporters. People used to use Nvidia Texture Tools, but itâs archived as there wasnât funding to maintain it. Itâs still a great reference. Nvidia has a closed source fork, but I donât love having a closed source dependency for such an integral part of my engine.&lt;/p&gt;
    &lt;p&gt;Iâve implemented an open source texture tool that youâre welcome to use directly or as a reference for your own implementation: Zex.&lt;/p&gt;
    &lt;p&gt;It can be used as a command line tool, or as a Zig library. It reads PNGs using stb_image, and converts them to KTX2, with support BC7 compression + rate distortion optimization from bc7enc_rdo, and supercompression via zlib.&lt;/p&gt;
    &lt;p&gt;It supports most standard features, such as mipmap generation with configurable filters and address modes.&lt;/p&gt;
    &lt;p&gt;I havenât implemented cubemap exports yet as my current game isnât using them. If you need support before I get around to it, PRs are welcomeâit should be a pretty straightforward addition.&lt;/p&gt;
    &lt;p&gt;If you want to implement your own exporter, here are some useful references. Keep in mind that you donât need to support all possible features, just the ones your engine uses:&lt;/p&gt;
    &lt;head rend="h2"&gt;Texture Viewers&lt;/head&gt;
    &lt;p&gt;Most image viewers wonât be able to open texture formats like DDS/KTX2. This sorta makes senseâimage viewers are typically designed to show a single image, whereas a texture may be comprised of multiple mipmaps and cubemap faces and such, and may be HDR. This requires a fancier UI.&lt;/p&gt;
    &lt;p&gt;Iâm personally a fan of Tacentview for this use case. Itâs open source, cross platform, and supports a large number of formats.&lt;/p&gt;
    &lt;head rend="h2"&gt;Preserving Alpha Coverage&lt;/head&gt;
    &lt;p&gt;source: firewatch inspired me so I made a tree and then never used it for anything&lt;/p&gt;
    &lt;p&gt;Pregenerating your mipmaps gives you a chance to be a little more âcorrectâ about them.&lt;/p&gt;
    &lt;p&gt;For example, if youâve ever tried to render a tree or a chain link fence in-game as a cutout (or with alpha to coverage) but found that it vanishes when you get far away, your mipmap filtering likely isnât taking into account the alpha test.&lt;/p&gt;
    &lt;p&gt;You can see Zexâs alpha test aware resize here. This isnât battle tested yet, compare results visually in-engine to see if it provides a benefit for your artwork.&lt;/p&gt;
    &lt;head rend="h2"&gt;Automation&lt;/head&gt;
    &lt;p&gt;You probably donât want to convert all your images by hand. I did this for Way of Rhea for a while, but eventually realized that it was a waste of time. Every time a texture changes you have to go back and figure out what settings you used last time. Just automate it.&lt;/p&gt;
    &lt;p&gt;Iâll probably write a follow up post describing my strategy for automating this at some point in the future, but if you want a sneak peak, check out Oven. Itâs not exactly general purpose right now, but might be an interesting reference.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45152648</guid></item><item><title>A Navajo weaving of an integrated circuit: the 555 timer</title><link>https://www.righto.com/2025/09/marilou-schultz-navajo-555-weaving.html</link><description>&lt;doc fingerprint="2f555263dc670aeb"&gt;
  &lt;main&gt;
    &lt;p&gt;The noted Diné (Navajo) weaver Marilou Schultz recently completed an intricate weaving composed of thick white lines on a black background, punctuated with reddish-orange diamonds. Although this striking rug may appear abstract, it shows the internal circuitry of a tiny silicon chip known as the 555 timer. This chip has hundreds of applications in everything from a sound generator to a windshield wiper controller. At one point, the 555 was the world's best-selling integrated circuit with billions sold. But how did the chip get turned into a rug?&lt;/p&gt;
    &lt;p&gt;The 555 chip is constructed from a tiny flake of silicon with a layer of metallic wiring on top. In the rug, this wiring is visible as the thick white lines, while the silicon forms the black background. One conspicuous feature of the rug is the reddish-orange diamonds around the perimeter. These correspond to the connections between the silicon chip and its eight pins. Tiny golden bond wires—thinner than a human hair—are attached to the square bond pads to provide these connections. The circuitry of the 555 chip contains 25 transistors, silicon devices that can switch on and off. The rug is dominated by three large transistors, the filled squares with a 王 pattern inside, while the remaining transistors are represented by small dots.&lt;/p&gt;
    &lt;p&gt;The weaving was inspired by a photo of the 555 timer die taken by Antoine Bercovici (Siliconinsider); I suggested this photo to Schultz as a possible subject for a rug. The diagram below compares the weaving (left) with the die photo (right). As you can see, the weaving closely follows the actual chip, but there are a few artistic differences. For instance, two of the bond pads have been removed, the circuitry at the top has been simplified, and the part number at the bottom has been removed.&lt;/p&gt;
    &lt;p&gt;Antoine took the die photo with a dark field microscope, a special type of microscope that produces an image on a black background. This image emphasizes the metal layer on the top of the die. In comparison, a standard bright-field microscope produced the image below. When a chip is manufactured, regions of silicon are "doped" with impurities to create transistors and resistors. These regions are visible in the image below as subtle changes in the color of the silicon.&lt;/p&gt;
    &lt;p&gt;In the weaving, the chip's design appears almost monumental, making it easy to forget that the actual chip is microscopic. For the photo below, I obtained a version of the chip packaged in a metal can, rather than the typical rectangle of black plastic. Cutting the top off the metal can reveals the tiny chip inside, with eight gold bond wires connecting the die to the pins of the package. If you zoom in on the photo, you may recognize the three large transistors that dominate the rug.&lt;/p&gt;
    &lt;p&gt;The artist, Marilou Schultz, has been creating chip rugs since 1994, when Intel commissioned a rug based on the Pentium as a gift to AISES (American Indian Science &amp;amp; Engineering Society). Although Schultz learned weaving as a child, the Pentium rug was a challenge due to its complex pattern and lack of symmetry; a day's work might add just an inch to the rug. This dramatic weaving was created with wool from the long-horned Navajo-Churro sheep, colored with traditional plant dyes.&lt;/p&gt;
    &lt;p&gt;For the 555 timer weaving, Schultz experimented with different materials. Silver and gold metallic threads represent the aluminum and copper in the chip. The artist explains that "it took a lot more time to incorporate the metallic threads," but it was worth the effort because "it is spectacular to see the rug with the metallics in the dark with a little light hitting it." Aniline dyes provided the black and lavender colors. Although natural logwood dye produces a beautiful purple, it fades over time, so Schultz used an aniline dye instead. The lavender colors are dedicated to the weaver's mother, who passed away in February; purple was her favorite color.&lt;/p&gt;
    &lt;head rend="h2"&gt;Inside the chip&lt;/head&gt;
    &lt;p&gt;How does the 555 chip produce a particular time delay? You add external components—resistors and a capacitor—to select the time. The capacitor is filled (charged) at a speed controlled by the resistor. When the capacitor get "full", the 555 chip switches operation and starts emptying (discharging) the capacitor. It's like filling a sink: if you have a large sink (capacitor) and a trickle of water (large resistor), the sink fills slowly. But if you have a smal sink (capacitor) and a lot of water (small resistor), the sink fills quickly. By using different resistors and capacitors, the 555 timer can provide time intervals from microseconds to hours.&lt;/p&gt;
    &lt;p&gt;I've constructed an interactive chip browser that shows how the regions of the rug correspond to specific electronic components in the physical chip. Click on any part of the rug to learn the function of the corresponding component in the chip.&lt;/p&gt;
    &lt;p&gt;For instance, two of the large square transistors turn the chip's output on or off, while the third large transistor discharges the capacitor when it is full. (To be precise, the capacitor goes between 1/3 full and 2/3 full to avoid issues near "empty" and "full".) The chip has circuits called comparators that detect when the capacitor's voltage reaches 1/3 or 2/3, switching between emptying and filling at those points. If you want more technical details about the 555 chip, see my previous articles: an early 555 chip, a 555 timer similar to the rug, and a more modern CMOS version of the 555.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusions&lt;/head&gt;
    &lt;p&gt;The similarities between Navajo weavings and the patterns in integrated circuits have long been recognized. Marilou Schultz's weavings of integrated circuits make these visual metaphors into concrete works of art. This connection is not just metaphorical, however; in the 1960s, the semiconductor company Fairchild employed numerous Navajo workers to assemble chips in Shiprock, New Mexico. I wrote about this complicated history in The Pentium as a Navajo Weaving.&lt;/p&gt;
    &lt;p&gt;This work is being shown at SITE Santa Fe's Once Within a Time exhibition (running until January 2026). I haven't seen the exhibition in person, so let me know if you visit it. For more about Marilou Schultz's art, see The Diné Weaver Who Turns Microchips Into Art, or A Conversation with Marilou Schultz on YouTube.&lt;/p&gt;
    &lt;p&gt;Many thanks to Marilou Schultz for discussing her art with me. Thanks to First American Art Magazine for providing the photo of her 555 rug. Follow me on Mastodon (@[email protected]), Bluesky (@righto.com), or RSS for updates.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45152779</guid></item><item><title>Show HN: I'm making an open-source platform for learning Japanese</title><link>https://kanadojo.com</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45152940</guid></item><item><title>The key to getting MVC correct is understanding what models are</title><link>https://stlab.cc/tips/about-mvc.html</link><description>&lt;doc fingerprint="1f5bdf1aa5aa0a18"&gt;
  &lt;main&gt;
    &lt;p&gt;How did MVC get so F’ed up?&lt;/p&gt;
    &lt;p&gt;Smalltalk MVC is defined in Design Pattern as:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;MVC Consists of three kinds of objects. The Model is the application object, the View is its screen presentation, and the Controller defines the way the user interface reacts to user input.1&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;However this definition has been abused over the years - Back in 2003 I gave a talk citing how bad Apple’s definition was. At the time it stated:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;A view object knows how to display and possibly edit data from the application’s model… A controller object acts as the intermediary between the application’s view objects and its model objects… Controllers are often the least reusable objects in an application, but that’s acceptable…2&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Of course it isn’t acceptable and, over the years, Apple has refined their definition and now acknowledge the distinction between the traditional Smalltalk version of MVC and the Cocoa version.3 But the Cocoa version is still defined much as it was before:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;A view object knows how to display, and might allow users to edit, the data from the application’s model… A controller object acts as the intermediary between the application’s view objects and its model objects…3&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In looking at how iOS applications are written the sentiment that controllers (and now view-controllers) are often the least reusable components in an application still flourishes, even if it is now unstated.&lt;/p&gt;
    &lt;p&gt;MVC (I’ll always use that term to refer to the Smalltalk form) has the following structure:&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; figure: Smalltalk MVC4 &lt;/p&gt;
    &lt;p&gt;Here the solid lines imply a direct association. And the dashed lines an indirect association by an observer. So what we see is that the model is unaware of the view and controller, except indirectly through notifications, and hence the code in the Model is reusable. The controller and view bind to the model, not the other way around.&lt;/p&gt;
    &lt;p&gt;Often the function of the Controller and View are tightly coupled into a “widget” or “control”. When Apple talks about a View-Controller in their model they are talking about a grab-bag of an uber-widget that is a composite of UIView widgets and multiple models. From what I’ve seen, including in Apple’s example code, it is usually a pretty big mess.&lt;/p&gt;
    &lt;p&gt;The key to getting MVC correct is understanding what models are. A model is simply an object5 which can be observed (a requirement for attaching views). For example, in ObjC an int is an object, but it is not observable. However, an ObjC object with an int property is observable using Key-Value Observing6. A model may encapsulate complex relationships between the model’s properties. A trivial model is one where each property is completely independent (think C struct vs. C++ class). From a notification the view should be able to determine, at a minimum:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;What changed. It may be as simple as “the model bound to the view”.&lt;/item&gt;
      &lt;item&gt;The new value to display.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For example, let’s say our model is a trivial observable boolean (I can’t imagine a simpler model). What we want is a checkbox that binds to the observable boolean. When the controller requests a change in value, the boolean is updated, and the view is notified of the new state of the model. The model is unaware of what UI is attached to it, and in fact there could be multiple UIs, including something like a scripting system, attached to the same instance of the model. This is a form of data binding - though most data binding systems replicate the problems of their underlying widget set by treating the model as if it were observing the view, not the other way around.&lt;/p&gt;
    &lt;p&gt;Contrast this with most UI frameworks where you have a checkbox widget from which you can query the value and you receive a notification when the value has changed. This is pushing a model into the widget. With MVC you never ask a question like “what is the default state of this checkbox?” - the default state of the view is always the current state of the model. You would also never get the state of the checkbox - the state of the checkbox is simply a reflection of the state of the model. In a system where you get the state of a checkbox you are binding two models together by treating one as a view/controller of the other. Such a pattern doesn’t scale beyond trivial models, and even for those it introduces some ambiguity.&lt;/p&gt;
    &lt;p&gt;I conjecture that one of the reasons why MVC has been so screwed up is because, unlike in Smalltalk, writing something as simple as an observable boolean is a bit of a pain in a language like Pascal or C. You quickly get into object ownership and lifetime issues and how to write bind expressions. If one also assumes that you have a 1:1 mapping from UI to model then there is some inherent inefficiency in the generalization. The Lisa team made some major compromises and the rest of the industry followed along.7&lt;/p&gt;
    &lt;p&gt;To support more complex views, the notification may need to specify what parts of the model changed and how those parts changed. For example, “image 58 was removed from the sequence”. A complete model is one that can support any view of that model type efficiently (related to the notion of a complete type and a type’s efficient basis).&lt;/p&gt;
    &lt;p&gt;One additional attribute of MVC is that it is a composite pattern. This is hinted at by the direct connection between the Controller and the View. As I said early, the view may contain state, this state is itself an object, and because this state is also displayed within the view it is observable. It is another model. I refers to this as the view’s model. This model may include things such as the visibility of a window, the tab the user was last looking at, and the portion of the model being viewed.&lt;/p&gt;
    &lt;p&gt;Identifying what the models are in your system is important. We usually do pretty good at identifying the major models. Such as “this is an image” - but often fall short of identifying the complete model, i.e. “this is an image with a collection of settings.” We end up with our model spread out within the code (an incidental type) and it makes it more difficult to deal with it.&lt;/p&gt;
    &lt;p&gt;A common model that is often completely overlooked is the model for function arguments. When you have a command, button, gesture, or menu item in your application, these are bound to a function. The function itself is not typically a zeroary function but rather has a set of arguments that are constructed through other parts of the UI. For example, if I have a list of images in my application, I might have a button to delete the selected images. Here the current selection is the argument to my delete command. To create a UI for the selection I must create a model of the arguments to my function. A precondition of delete is that the selection is not empty. This precondition must be observable in the argument model so it can be reflected in the view by disabling or hiding the button and in the controller be disallowing the user to click the button and issue the command. The same argument model can be shared for multiple commands within an application.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Gamma, Erich. “1.2 Design Patterns in Smalltalk MVC.” Design Patterns: Elements of Reusable Object-Oriented Software. Reading, MA: Addison-Wesley, 1995. N. pag. Print. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;http://smartfriends.com/U/Presenters/untangling_software.pdf (Don’t bother reading, this was an incomprehensible talk.) ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;https://developer.apple.com/library/content/documentation/General/Conceptual/CocoaEncyclopedia/Model-View-Controller/Model-View-Controller.html ↩ ↩2&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stepanov, Alexander A., and Paul McJones. “1.3 Objects.” Elements of Programming. Upper Saddle River, NJ: Addison-Wesley, 2009. N. pag. Print. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;https://developer.apple.com/library/content/documentation/Cocoa/Conceptual/KeyValueObserving/KeyValueObserving.html ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;https://en.wikipedia.org/wiki/Object-oriented_user_interface ↩&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45154501</guid></item><item><title>Show HN: I recreated Windows XP as my portfolio</title><link>https://mitchivin.com/</link><description>&lt;doc fingerprint="586123fd98d49a69"&gt;
  &lt;main&gt;
    &lt;p&gt;Welcome to my portfolio. JavaScript is required for the full Windows XP experience. You can reach me on LinkedIn, view my work on GitHub, or see my latest on Instagram.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45154609</guid></item><item><title>Show HN: Lightweight tool for managing Linux virtual machines</title><link>https://github.com/ccheshirecat/flint</link><description>&lt;doc fingerprint="eface9fad13539da"&gt;
  &lt;main&gt;
    &lt;p&gt; A single &amp;lt;8MB binary with a modern Web UI, CLI, and API for KVM. &lt;lb/&gt;No XML. No bloat. Just VMs. &lt;/p&gt;
    &lt;p&gt;Flint is a modern, self-contained KVM management tool built for developers, sysadmins, and home labs who want zero bloat and maximum efficiency. It was built in a few hours out of a sudden urge for something better.&lt;/p&gt;
    &lt;p&gt;Prerequisites: A Linux host with &lt;code&gt;libvirt&lt;/code&gt; and &lt;code&gt;qemu-kvm&lt;/code&gt; installed.&lt;/p&gt;
    &lt;code&gt;curl -fsSL https://raw.githubusercontent.com/ccheshirecat/flint/main/install.sh | sh&lt;/code&gt;
    &lt;p&gt;Auto-detects OS/arch, installs to &lt;code&gt;/usr/local/bin&lt;/code&gt;, and you're ready in seconds.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🖥️ Modern UI — A beautiful, responsive Next.js + Tailwind interface, fully embedded.&lt;/item&gt;
      &lt;item&gt;⚡ Single Binary — No containers, no XML hell. A sub-8MB binary is all you need.&lt;/item&gt;
      &lt;item&gt;🛠️ Powerful CLI &amp;amp; API — Automate everything. If you can do it in the UI, you can do it from the command line or API.&lt;/item&gt;
      &lt;item&gt;📦 Frictionless Provisioning — Native Cloud-Init support and a simple, snapshot-based template system.&lt;/item&gt;
      &lt;item&gt;💪 Non-Intrusive — Flint is a tool that serves you. It's not a platform that locks you in.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;1. Start the Server&lt;/p&gt;
    &lt;code&gt;flint serve&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Web UI: &lt;code&gt;http://localhost:5550&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;API: &lt;code&gt;http://localhost:5550/api&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;2. Use the CLI&lt;/p&gt;
    &lt;code&gt;# List your VMs
flint vm list --all

# Launch a new Ubuntu VM named 'web-01'
flint launch ubuntu-24.04 --name web-01

# SSH directly into your new VM
flint ssh web-01

# Create a template from your configured VM
flint snapshot create web-01 --tag baseline-setup

# Launch a clone from your new template
flint launch --from web-01 --name web-02&lt;/code&gt;
    &lt;p&gt;While Flint is designed to be intuitive, the full CLI and API documentation, including all commands and examples, is available at:&lt;/p&gt;
    &lt;p&gt;➡️ DOCS.md&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Backend: Go 1.25+&lt;/item&gt;
      &lt;item&gt;Web UI: Next.js + Tailwind + Bun&lt;/item&gt;
      &lt;item&gt;KVM Integration: libvirt-go&lt;/item&gt;
      &lt;item&gt;Binary Size: ~8.4MB (stripped)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt; 🚀 Flint is young, fast-moving, and designed for builders.&lt;lb/&gt; Try it. Break it. Star it. Contribute. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45154857</guid></item><item><title>The world has a running Rational R1000/400 computer again (2019)</title><link>https://datamuseum.dk/wiki/Rational/R1000s400/Logbook/2019#2019-10-28</link><description>&lt;doc fingerprint="b4d53a4465a73299"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Rational/R1000s400/Logbook/2019&lt;/head&gt;
    &lt;head rend="h2"&gt;2019-12-11&lt;/head&gt;
    &lt;p&gt;SCSI command 0x0d seems to be explained now:&lt;/p&gt;
    &lt;p&gt;Søren Roug has spotted SASI command 0x0d in the manual for the Xebec S1410 diskcontroller:&lt;/p&gt;
    &lt;p&gt;It returns the length of burst errors corrected with ECC.&lt;/p&gt;
    &lt;p&gt;That matches the CMD_CORRECTION Tollef found.&lt;/p&gt;
    &lt;p&gt;Thanks everybody!&lt;/p&gt;
    &lt;head rend="h2"&gt;2019-12-08&lt;/head&gt;
    &lt;p&gt;About that 0x0d SCSI command...&lt;/p&gt;
    &lt;p&gt;My good friend Tollef Fog Heen replied on twitter that this source file on github calls the command CMD_CORRECTION.&lt;/p&gt;
    &lt;p&gt;That github repository contains a NeXT Station emulation.&lt;/p&gt;
    &lt;p&gt;The NeXT Station had a Magneto-Optical drive.&lt;/p&gt;
    &lt;p&gt;The first two pages of this bunch of papers that came with the machine, marked "aflasting" ("off-loading"), are jumper settings for Fujitsu's M2512A MO drive.&lt;/p&gt;
    &lt;p&gt;So the best theory now is that 0x0D is a way to probe for a MO drive configured as a disk drive.&lt;/p&gt;
    &lt;p&gt;I'll leave it at that for now, but I'm still interested to hear from anybody who spots 0x0d in old documents.&lt;/p&gt;
    &lt;p&gt;/phk&lt;/p&gt;
    &lt;head rend="h2"&gt;2019-12-07&lt;/head&gt;
    &lt;p&gt;Now it works!&lt;/p&gt;
    &lt;p&gt;My hacked up SCSI2SD firmware provided a log of all SCSI commands during boot and the two crucial ones turns out to be:&lt;/p&gt;
    &lt;quote&gt;1a 00 03 00 24 00 1a 00 04 00 20 00&lt;/quote&gt;
    &lt;p&gt;Those are "MODE SENSE(6)" commands, asking for page 3 and 4 respectively.&lt;/p&gt;
    &lt;p&gt;Page 3 is "Format Device" and the FUJITSU M2266 returns:&lt;/p&gt;
    &lt;quote&gt;00 0f 00 00 00 00 00 2d 00 2d 04 00 00 01 00 05 00 0b 40 00 00 00 Tracks per Zone: 15 Alternate Sectors per Zone: 0 Alternate Tracks per Zone: 0 Alternate Tracks per Logical Unit: 45 Sectors per Track: 45 Data Bytes per Physical Sector: 1024 Interleave: 1 Track Skew Factor: 5 Cylinder Skew Factor: 11 SSEC: 0 HSEC: 1 RMB: 0 SURF: 0&lt;/quote&gt;
    &lt;p&gt;Page 4 is "Rigid Disk Geometry" where the FUJITSU M2266 returns:&lt;/p&gt;
    &lt;quote&gt;00 06 7a 0f 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 Number of Cylinders: 1658 Number of Heads: 15 Starting Cylinder-Write Precompensation: 0 Starting Cylinder-Reduced Write Current: 0 Drive Step Rate: 0 Landing Zone Cylinder: 0 RPL: 0 Rotational Offset: 0 Medium Rotation Rate: 0&lt;/quote&gt;
    &lt;p&gt;After I hacked the SCSI2SD firmware to return those values, the R1000 booted flawlessly on the saved disk-images from PAM's machine.&lt;/p&gt;
    &lt;p&gt;Conclusion: The IOC bootstrap uses "modern SCSI" with linear block-numbers, the real system works in terms of Cylinders, Heads and Sectors.&lt;/p&gt;
    &lt;p&gt;/phk&lt;/p&gt;
    &lt;head rend="h2"&gt;2019-12-05&lt;/head&gt;
    &lt;p&gt;A little bit more SCSI2SD progress today.&lt;/p&gt;
    &lt;p&gt;I compiled a custom firmware for the SCSI2SD to get more logging, still sampling, but it should capture all failing commands now.&lt;/p&gt;
    &lt;p&gt;The picture from the log is the following:&lt;/p&gt;
    &lt;p&gt;First some SCSI READ(10) commands, which are compatible with the loading of KERNEL, FS and PROGRAM.&lt;/p&gt;
    &lt;p&gt;Then a SCSI command 0x0d, which is unknown everywhere I have looked. This command sets a flag in the KERNEL if successful, I have not investigated that flag further.&lt;/p&gt;
    &lt;p&gt;Next a SCSI MODE SENSE (RIGID DISK GEOMETRY)&lt;/p&gt;
    &lt;p&gt;Finally SCSI READ(6) commands which are past the DFS filesystem.&lt;/p&gt;
    &lt;p&gt;At the same time the console shows this:&lt;/p&gt;
    &lt;quote&gt;Disk 0 is ONLINE and WRITE ENABLED Disk 1 is ONLINE and WRITE ENABLED IOP Kernel is initialized Initializing diagnostic file system ... File does not exist ERROR_LOG [OK]&lt;/quote&gt;
    &lt;p&gt;Working theory right now is that the R1000 uses the RIGID DISK GEOMETRY data to calculate disk access, and what the SCSI2SD returns does not work for this.&lt;/p&gt;
    &lt;p&gt;I queried one of the blank Fujitsu disks we got from Terma in our "dumper machine" and it returns:&lt;/p&gt;
    &lt;quote&gt;00 06 7a 0f 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 Number of Cylinders: 1658 Number of Heads: 15 Starting Cylinder-Write Precompensation: 0 Starting Cylinder-Reduced Write Current: 0 Drive Step Rate: 0 Landing Zone Cylinder: 0 RPL: 0 Rotational Offset: 0 Medium Rotation Rate: 0&lt;/quote&gt;
    &lt;p&gt;Whereas the SCSI2SD seems to return:&lt;/p&gt;
    &lt;quote&gt;00 38 30 06 00 00 00 00 00 00 00 00 00 00 00 00 00 00 1c 05 00 00 Number of Cylinders: 14384 Number of Heads: 6 Starting Cylinder-Write Precompensation: 0 Starting Cylinder-Reduced Write Current: 0 Drive Step Rate: 0 Landing Zone Cylinder: 0 RPL: 0 Rotational Offset: 0 Medium Rotation Rate: 7173&lt;/quote&gt;
    &lt;p&gt;My next experiment will be to make the SCSI2SD firmware emit the same RIGID GEOMETRY as the Fujitsu disk.&lt;/p&gt;
    &lt;head rend="h2"&gt;2019-11-20&lt;/head&gt;
    &lt;p&gt;I made a DFS backup from PAM's Fujitsu disks, and read the remaining 8mm tapes.&lt;/p&gt;
    &lt;p&gt;/phk&lt;/p&gt;
    &lt;head rend="h2"&gt;2019-11-14&lt;/head&gt;
    &lt;p&gt;Got a bit further with the SCSI2SD: 1024 byte sector size helps, still get a DFS kernel panic though:&lt;/p&gt;
    &lt;quote&gt;Initializing M400S I/O Processor Kernel 4_2_18 Disk 0 is ONLINE and WRITE ENABLED Disk 1 is ONLINE and WRITE ENABLED IOP Kernel is initialized Initializing diagnostic file system ... File does not exist ERROR_LOG [OK] I/O Processor Kernel Crash: error 0614 (hex) at PC=0000849E ************************************************&lt;/quote&gt;
    &lt;p&gt;Next, tried to restore the backup of PAM's disks onto the Seagate disks, looks like success:&lt;/p&gt;
    &lt;quote&gt;--- Booting the R1000 Environment --- Loading from file M207_44.M200_UCODE bound on November 5, 1992 at 6:08:17 PM Loading Register Files .... [OK] Loading : KAB.11.0.1.MLOAD Loading : KMI.11.0.0.MLOAD Loading : KKDIO.11.0.3.MLOAD Loading : KKD.11.0.0S.MLOAD Loading : KK.11.5.9K.MLOAD Loading : EEDB.11.2.0D.MLOAD Loading : UOSU.11.3.0D.MLOAD Loading : UED.10.0.0R.MLOAD Loading : UM.11.1.5D.MLOAD Loading : UAT.11.2.2D.MLOAD 851/1529 wired/total pages loaded. The use of this system is subject to the software license terms and conditions agreed upon between Rational and the Customer. Copyright 1992 by Rational. RESTRICTED RIGHTS LEGEND Use, duplication, or disclosure by the Government is subject to restrictions as set forth in subparagraph (c)(1)(ii) of the Rights in Technical Data and Computer Software clause at DoD FAR Supplement 252.227-7013. Rational 3320 Scott Blvd. Santa Clara, California 95054-3197 Starting R1000 Environment - it now owns this console. ====&amp;gt;&amp;gt; Kernel.11.5.8 &amp;lt;&amp;lt;==== Kernel: CHANGE_GHOST_LOGGING WANT TRACING: FALSE WANT LOGGING: FALSE Kernel: START_VIRTUAL_MEMORY ALLOW PAGE FAULTS: YES ====&amp;gt;&amp;gt; ERROR_LOG &amp;lt;&amp;lt;==== 22:55:05 --- TCP_IP_Driver.Worker.Finalized ====&amp;gt;&amp;gt; CONFIGURATOR &amp;lt;&amp;lt;==== starting diagnosis of configuration recovery is needed WANT TO BUILD NEW SYSTEM (YES/NO): yes starting creation of new system VOLUME NAME FOR unit 0: volume 1 VOLUME NAME FOR unit 1: volume 2 creating root volume: 1 adding volume 2 to virtual memory system creation of new system is complete starting virtual memory system the virtual memory system is up ====&amp;gt;&amp;gt; Kernel.11.5.8 &amp;lt;&amp;lt;==== Kernel: START_NETWORK_IO Kernel: START_ENVIRONMENT TRACE LEVEL: INFORMATIVE Kernel: ====&amp;gt;&amp;gt; Environment Elaborator &amp;lt;&amp;lt;==== Elaborating subsystem: ENVIRONMENT_DEBUGGER Elaborating subsystem: ABSTRACT_TYPES Elaborating subsystem: MISCELLANEOUS Elaborating subsystem: OS_UTILITIES ====&amp;gt;&amp;gt; Recovery &amp;lt;&amp;lt;==== Recovery Is Needed, Should I fake it? no Please tell me Volume Id for the Backup Index Tape: ====&amp;gt;&amp;gt; SYSTEM % RECOVERY &amp;lt;&amp;lt;==== Please Load Tape (Kind of Tape =&amp;gt; CHAINED_ANSI, Direction =&amp;gt; READING) Is Tape mounted and ready to read labels? yes Info on tape mounted on drive 0 is: (Kind of Tape =&amp;gt; CHAINED_ANSI, Writeable =&amp;gt; FALSE, Volume Id =&amp;gt; 028600, Volume Set Name =&amp;gt; BACKUP, 09-MAR-01 16:01:45 3) OK to read volume? [YES] ====&amp;gt;&amp;gt; Recovery &amp;lt;&amp;lt;==== Positioning tape to Backup Index Processing Backup Index Processing Tape File: Vol Info Processing Tape File: VP Info Processing Tape File: DB Backups Processing Tape File: DB Processors Processing Tape File: DB Disk Volumes Processing Tape File: DB Tape Volumes Positioning tape to Backup Data Processing Backup Data Processing Tape File: Space Info Vol 1 Processing Tape File: Block Info Vol 1 Processing Tape File: Block Data Vol 1 Processing Tape File: Space Info Vol 2 Processing Tape File: Block Info Vol 2 Processing Tape File: Block Data Vol 2 ====&amp;gt;&amp;gt; SYSTEM % RECOVERY &amp;lt;&amp;lt;==== Please Dismount Tape on Drive 0 (Kind of Tape =&amp;gt; CHAINED_ANSI, Volume Id =&amp;gt; 028600, Volume Set Name =&amp;gt; BACKUP, 09-MAR-01 16:01:45 3) ====&amp;gt;&amp;gt; Recovery &amp;lt;&amp;lt;==== Tape Processing Complete. Restoring Data Restoring Spaces Taking 1st snapshot ====&amp;gt;&amp;gt; CONFIGURATOR &amp;lt;&amp;lt;==== starting snapshot snapshot is finished ====&amp;gt;&amp;gt; Recovery &amp;lt;&amp;lt;==== Updating Databases Taking 2nd snapshot ====&amp;gt;&amp;gt; CONFIGURATOR &amp;lt;&amp;lt;==== starting snapshot snapshot is finished ====&amp;gt;&amp;gt; Recovery &amp;lt;&amp;lt;==== Recovery Is Complete Garbage Collection can't run until the machine is rebooted Rebooting to enable Garbage Collection ====&amp;gt;&amp;gt; CONFIGURATOR &amp;lt;&amp;lt;==== starting virtual memory shutdown starting snapshot snapshot is finished virtual memory shutdown at ( 3, 26-MAR-01 04:22:46) system shutdown is complete *************************************** Sequencer has detected a machine check. ************************************************ Booting R1000 IOP after R1000 Halt or Machine Check detected Boot Reason code = 0C, from PC 0001ADA2 Restarting R1000-400S March 26th, 1901 at 04:23:01 OPERATOR MODE MENU - options are: 1 =&amp;gt; Change BOOT/CRASH/MAINTENANCE options 2 =&amp;gt; Change IOP CONFIGURATION 3 =&amp;gt; Enable manual crash debugging (EXPERTS ONLY) 4 =&amp;gt; Boot IOP, prompting for tape or disk 5 =&amp;gt; Boot SYSTEM Enter option [Boot SYSTEM] :&lt;/quote&gt;
    &lt;p&gt;The disks were formatted yesterday, so I do not have a total time for the restore, but reading the backup tape took 7 hours.&lt;/p&gt;
    &lt;head rend="h2"&gt;2019-11-13&lt;/head&gt;
    &lt;p&gt;Tried if the R1000 would accept a SCSI2S without much luck.&lt;/p&gt;
    &lt;p&gt;The RESHA EEPROM issues the usual terse style error message saying simply "SCSI Error", giving no usable details.&lt;/p&gt;
    &lt;p&gt;Formatted the Seagate disks so they are ready for an attempt to restore from the Backup-Tape.&lt;/p&gt;
    &lt;p&gt;If the SCSI2SD is in the machine along with disks, some DFS operations work, but since no defect list can be read, preparing the disk fails.&lt;/p&gt;
    &lt;p&gt;The two Fujitsu disks with the working image was never powered up today.&lt;/p&gt;
    &lt;p&gt;/phk&lt;/p&gt;
    &lt;head rend="h2"&gt;2019-10-29&lt;/head&gt;
    &lt;p&gt;R1000-400 with Facit A-4600 terminal showing the Rational Environment. Note the keyboard overlay that extends a couple of inches beyond the keyboard.&lt;/p&gt;
    &lt;p&gt;Keyboard overlay for the Rational Environment.&lt;/p&gt;
    &lt;p&gt;The front plate of a running R1000-400. ==&lt;/p&gt;
    &lt;head rend="h2"&gt;2019-10-28&lt;/head&gt;
    &lt;p&gt;The world has a running Rational R1000/400 computer again:&lt;/p&gt;
    &lt;p&gt;Thanks a LOT to Pierre-Alain Muller for driving all the way here to help make this happen!&lt;/p&gt;
    &lt;head rend="h2"&gt;2019-10-24&lt;/head&gt;
    &lt;p&gt;On suggestion by Pierre-Alain todays aim was an FRU diagnostics.&lt;/p&gt;
    &lt;p&gt;First the faulty Fujitsu disk was removed and the Seagate promoted to SCSI ID 0.&lt;/p&gt;
    &lt;p&gt;Then we got a "File does not exist HARDWARE.M200_CONFIG". M200, hmm... - We did the following:&lt;/p&gt;
    &lt;quote&gt;OPERATOR MODE MENU - options are: 1 =&amp;gt; Change BOOT/CRASH/MAINTENANCE options 2 =&amp;gt; Change IOP CONFIGURATION 3 =&amp;gt; Enable manual crash debugging (EXPERTS ONLY) 4 =&amp;gt; Boot IOP, prompting for tape or disk 5 =&amp;gt; Boot SYSTEM Enter option [Boot SYSTEM] : 1 Enable Modem DIALOUT [N] ? Enable Modem ANSWER [N] ? Enable IOP (IOC 68K) Auto Boot [N] ? y Enable R1000 CPU Auto Boot [N] ? n Enable AUTO CRASH RECOVERY [N] ? y Enable CONSOLE BREAK KEY [N] ? y Are these new defaults [N] ? y&lt;/quote&gt;
    &lt;p&gt;then&lt;/p&gt;
    &lt;quote&gt;CLI/CRASH MENU - options are: 1 =&amp;gt; enter CLI 2 =&amp;gt; make a CRASHDUMP tape 3 =&amp;gt; display CRASH INFO 4 =&amp;gt; Boot DDC configuration 5 =&amp;gt; Boot EEDB configuration 6 =&amp;gt; Boot STANDARD configuration Enter option [Boot EEDB configuration] : 1 CLI&amp;gt; x cedit Change hardware configuration [N] ? y File does not exist HARDWARE.M200_CONFIG Does this processor have 32 MB memory boards [Y] ? NOTE: 32 MB boards must be installed as MEM 0 or MEM 2 only. 8 MB boards cannot be in the same CPU as 32 MB boards. Does memory board 0 exist [Y] ? y Does memory board 2 exist [Y] ? n CLI&amp;gt; x expmon 0 32MB MEMORY BOARDS IN PROCESSOR - TOTAL OF 0 MEGABYTES. EM&amp;gt; bye CLI&amp;gt; quit&lt;/quote&gt;
    &lt;p&gt;At this point we rebooted, but the memory board was still not detected. We then decided to take all 8 boards out of the machine starting with the two MEM 0/2 boards, photographing and then re-seating them. The 2 memory boards looked identical, so we switched their position. At the following boot we got: "Memory 2 exists but is not in configuration. Board will not be used.", so we changed the HW config again and included both MEM boards. We don't believe the changed positions did anything, but perhaps the power-cycle was needed to get them detected right?!&lt;/p&gt;
    &lt;p&gt;At this point we attempted the FRU-diagnostics:&lt;/p&gt;
    &lt;quote&gt;CLI&amp;gt; x expmon 2 32MB MEMORY BOARDS IN PROCESSOR - TOTAL OF 64 MEGABYTES. EM&amp;gt; rd ... EM&amp;gt; poll_all NO MACHINE CHECKS DETECTED EM&amp;gt; poll_all SEQ HAS DETECTED A MACHINE CHECK EM&amp;gt; sm ... UCODE HALT AT 0102 ... EM&amp;gt; bye CLI&amp;gt; CLI&amp;gt; x rdiag ... DIAG&amp;gt; test/3 all Running FRU P1DCOMM Running FRU P1IOC Running FRU P1VAL Running FRU P1TYP Running FRU P1SEQ Running FRU P1FIU Running FRU P1MEM Running FRU P1SF Running FRU P2IOC Running FRU P2VAL Loading from file PHASE2_MULT_TEST.M200_UCODE bound on July 16, 1986 14:31:44 Loading Register Files and Dispatch Rams .... [OK] Loading Control Store [OK] Running FRU P2TYP Running FRU P2SEQ Running FRU P2FIU Running FRU P2MEM Running FRU P2UADR Running FRU P2FP Loading from file FPTEST.M200_UCODE bound on January 29, 1990 17:26:52 Loading Register Files and Dispatch Rams .... [OK] Loading Control Store [OK] Running FRU P2EVNT Running FRU P2STOP Running FRU P2ABUS Loading from file ABUS_TEST.M200_UCODE bound on July 22, 1986 13:27:21 Loading Register Files and Dispatch Rams .... [OK] Loading Control Store [OK] Running FRU P2CSA Running FRU P2MM Running FRU P2COND Running FRU P2UCODE Loading from file P2UCODE.M200_UCODE bound on August 6, 1986 16:16:27 Loading Register Files and Dispatch Rams .... [OK] Loading Control Store .......... [OK] Running FRU P3RAMS Running FRU P3UCODE Loading from file P3UCODE.M200_UCODE bound on August 6, 1986 13:50:42 Loading Register Files and Dispatch Rams .... [OK] Loading Control Store . [OK] PASSED&lt;/quote&gt;
    &lt;p&gt;"PASSED"!!!&lt;/p&gt;
    &lt;p&gt;And a bit later the following line:&lt;/p&gt;
    &lt;quote&gt;Starting R1000 Environment - it now owns this console.&lt;/quote&gt;
    &lt;p&gt;Cleaned up log from the most interesting part of the session: Fil:20191024 1915 R1000.pdf&lt;/p&gt;
    &lt;head rend="h2"&gt;2019-10-17&lt;/head&gt;
    &lt;p&gt;Peter has returned with a working PSU :-) - The R1000 is now up and running again drawing 155 amps.&lt;/p&gt;
    &lt;p&gt;Almost full log of the session: Fil:20191017 1954 R1000.pdf&lt;/p&gt;
    &lt;p&gt;The Fujitsu 2266 disk appears to be faulty, R1000 complains about disk errors (our old acquaintance General Error?):&lt;/p&gt;
    &lt;quote&gt;Options are: 0 =&amp;gt; Exit 1 =&amp;gt; Initialize disk (for experts only) 2 =&amp;gt; Initialize disk, drop USR defects (internal use only) 3 =&amp;gt; Show MFG and USR bad block locations 4 =&amp;gt; Show only USR bad block locations 5 =&amp;gt; Install new DFS only 6 =&amp;gt; Show bad block count and DOS limits Enter option : 3 Enter unit number of disk to format/build/scan (usually 0) : 0 CS1=0038 CS2=0040 DS=11C0 ER1=0100 ER2=4000 EC1=0000 EC2=0000 DC=0000 DA=0005 CS1=4038 CS2=0040 DS=11C0 ER1=0000 ER2=0000 EC1=0000 EC2=0000 DC=0000 DA=0005 CS1=0038 CS2=0040 DS=11C0 ER1=0100 ER2=4000 EC1=0000 EC2=0000 DC=0000 DA=0005 CS1=4038 CS2=0040 DS=11C0 ER1=0000 ER2=0000 EC1=0000 EC2=0000 DC=0000 DA=0005 CS1=4038 CS2=0040 DS=11C0 ER1=0000 ER2=0000 EC1=0000 EC2=0000 DC=0000 DA=0005 CS1=0038 CS2=0040 DS=11C0 ER1=0100 ER2=4000 EC1=0000 EC2=0000 DC=0000 DA=0005 CS1=0038 CS2=0040 DS=11C0 ER1=0100 ER2=4000 EC1=0000 EC2=0000 DC=0000 DA=0005 CS1=4038 CS2=0040 DS=11C0 ER1=0000 ER2=0000 EC1=0000 EC2=0000 DC=0000 DA=0005 CS1=4038 CS2=0040 DS=11C0 ER1=0000 ER2=0000 EC1=0000 EC2=0000 DC=0000 DA=0005 CS1=4038 CS2=0040 DS=11C0 ER1=0000 ER2=0000 EC1=0000 EC2=0000 DC=0000 DA=0005 CS1=0038 CS2=0040 DS=11C0 ER1=0100 ER2=4000 EC1=0000 EC2=0000 DC=0000 DA=0005 CS1=4038 CS2=0040 DS=11C0 ER1=0000 ER2=0000 EC1=0000 EC2=0000 DC=0000 DA=0005 CS1=4038 CS2=0040 DS=11C0 ER1=0000 ER2=0000 EC1=0000 EC2=0000 DC=0000 DA=0005 CS1=4038 CS2=0040 DS=11C0 ER1=0000 ER2=0000 EC1=0000 EC2=0000 DC=0000 DA=0005 CS1=0038 CS2=0040 DS=11C0 ER1=0100 ER2=4000 EC1=0000 EC2=0000 DC=0000 DA=0005 CS1=0038 CS2=0040 DS=11C0 ER1=0100 ER2=4000 EC1=0000 EC2=0000 DC=0000 DA=0005 CS1=4038 CS2=0040 DS=11C0 ER1=0000 ER2=0000 EC1=0000 EC2=0000 DC=0000 DA=0005 CS1=4038 CS2=0040 DS=11C0 ER1=0000 ER2=0000 EC1=0000 EC2=0000 DC=0000 DA=0005 CS1=0038 CS2=0040 DS=11C0 ER1=0100 ER2=4000 EC1=0000 EC2=0000 DC=0000 DA=0005 CS1=0038 CS2=0040 DS=11C0 ER1=0100 ER2=4000 EC1=0000 EC2=0000 DC=0000 DA=0005 ** ABORT: Can't retrieve labels due to disk errors.&lt;/quote&gt;
    &lt;p&gt;A Seagate ST41200N is now installed as DISK 1, the Fujitsu remains as DISK 0 for now. R1000 recognizes the Seagate but wants to format it:&lt;/p&gt;
    &lt;quote&gt;Initializing M400S I/O Processor Kernel 4_2_16 Spinning up disk 1 Spinning up disk 0 Disk 1 is ONLINE and WRITE ENABLED IOP Kernel is initialized Enable line printer for console output [N] ? RECOVERY 14.04 92/09/17 10:00:00\ Options are: 0 =&amp;gt; Exit 1 =&amp;gt; Initialize disk (for experts only) 2 =&amp;gt; Initialize disk, drop USR defects (internal use only) 3 =&amp;gt; Show MFG and USR bad block locations 4 =&amp;gt; Show only USR bad block locations 5 =&amp;gt; Install new DFS only 6 =&amp;gt; Show bad block count and DOS limits Enter option : 3 Enter unit number of disk to format/build/scan (usually 0) : 1 ** ABORT: Disk has no labels. Options are: 0 =&amp;gt; Exit 1 =&amp;gt; Initialize disk (for experts only) 2 =&amp;gt; Initialize disk, drop USR defects (internal use only) 3 =&amp;gt; Show MFG and USR bad block locations 4 =&amp;gt; Show only USR bad block locations 5 =&amp;gt; Install new DFS only 6 =&amp;gt; Show bad block count and DOS limits Enter option : 1 Enter unit number of disk to format/build/scan (usually 0) : 1 Disk has no labels. Drive types are: 1 - Fujitsu 2263 2 - Fujitsu 2266 3 - SEGATE ST41200N 0 - Other Enter drive type : 3 Enter HDA serial number : TJ617458 Disk must be formated. Formatting the drive will take about 35 minutes. Elapsed time is 00:32:32 Writing bad block information. Writing boot label. Writing DFS label. Do you want to build a diagnostic file system on this unit [Y] ? Enter last cylinder to be used by the DFS [ Hint =&amp;gt; 76 ]:76 Enter first cylinder to be used for read/write diagnostics [ Hint =&amp;gt; 1889 ]:1889 Writing shared label. Constructing free list. Writing free list. Allocating and initializing directory. Creating predefined files. KERNEL_0.M200 KERNEL_1.M200 KERNEL_2.M200 FS_0.M200 FS_1.M200 FS_2.M200 PROGRAM_0.M200 PROGRAM_1.M200 PROGRAM_2.M200 DFS_BOOTSTRAP.M200 ERROR_LOG Do you want to load files into the DFS on this unit [Y] ? y Tape drive unit number : 0 Do you want to display filenames as they are loaded [Y] ? y Reading -&amp;gt; DFS_BOOTSTRAP.M200 Reading -&amp;gt; KERNEL_0.M200 ... 3160 files later ... Reading -&amp;gt; DDC.M200_CONFIG Elapsed time is 00:10:40 Options are: 0 =&amp;gt; Exit 1 =&amp;gt; Initialize disk (for experts only) 2 =&amp;gt; Initialize disk, drop USR defects (internal use only) 3 =&amp;gt; Show MFG and USR bad block locations 4 =&amp;gt; Show only USR bad block locations 5 =&amp;gt; Install new DFS only 6 =&amp;gt; Show bad block count and DOS limits Enter option : 0 Boot disk has been rebuilt or the IOP was booted from tape. You must crash the machine to exit.&lt;/quote&gt;
    &lt;p&gt;Next week, boot from disk and see how far we get. PSU got *hot*, but survived the 1½ hour session.&lt;/p&gt;
    &lt;head rend="h2"&gt;2019-10-03&lt;/head&gt;
    &lt;p&gt;After rumaging through our entire workshop, it transpires that we have no solder-iron with sufficient power to unsolder the capacitors from the thick copper on the PCB.&lt;/p&gt;
    &lt;p&gt;One of our members, Peter, has offered to attempt the repair in his own workshop, and he picked it up tonight.&lt;/p&gt;
    &lt;head rend="h2"&gt;2019-09-12&lt;/head&gt;
    &lt;p&gt;PSU dismantled, and the visible defective Electrolyte has been soldered out together with two Tantalum. Unfortunately, when mounted, the leads were pinched and cut, making them difficult to pull through the PCB today since the holes are almost exactly the size of the leads. The insulation on the wires to the transformer has deteriorated quite a bit and will need some repair.&lt;/p&gt;
    &lt;p&gt;Some better images of the PSU as a whole:&lt;/p&gt;
    &lt;p&gt;Overview&lt;/p&gt;
    &lt;p&gt;One half of the PSU&lt;/p&gt;
    &lt;p&gt;Other half of the PSU&lt;/p&gt;
    &lt;p&gt;Defect insulation on some wires&lt;/p&gt;
    &lt;p&gt;One of the two capacitor boards on the 5V rails.&lt;/p&gt;
    &lt;p&gt;Backside of PCB carrying the damaged capacitor.&lt;/p&gt;
    &lt;p/&gt;
    &lt;p/&gt;
    &lt;p&gt;Each of the two PCBs carry: 5 Tantalum capacitors 15µF, and 5 6800µF SXF 30mm x 18mm, lead spacing 7.5mm&lt;/p&gt;
    &lt;head rend="h2"&gt;2019-09-05&lt;/head&gt;
    &lt;p&gt;Arriving today, expecting a fight, armed with various debugging plans, the Rational just started, booted and were happy as could be?!? - After some configuration, and booting the kernel "M400S_KERNEL_0.M200" (thanks to Pierre-Alain for supplying that information), the R1000 now responds with:&lt;/p&gt;
    &lt;quote&gt;R1000-400 IOC SELFTEST 1.3.2 512 KB memory ... [OK] Memory parity ... [OK] I/O bus control ... [OK] I/O bus map ... [OK] I/O bus map parity ... [OK] I/O bus transactions ... [OK] PIT ... [OK] Modem DUART channel ... [OK] Diagnostic DUART channel ... [OK] Clock / Calendar ... [OK] Checking for RESHA board RESHA EEProm Interface ... [OK] Downloading RESHA EEProm 0 - TEST Downloading RESHA EEProm 1 - LANCE Downloading RESHA EEProm 2 - DISK Downloading RESHA EEProm 3 - TAPE DIAGNOSTIC MODEM ... DISABLED RESHA VME sub-tests ... [OK] LANCE chip Selftest ... [OK] RESHA DISK SCSI sub-tests ... [OK] RESHA TAPE SCSI sub-tests ... [OK] Local interrupts ... [OK] Illegal reference protection ... [OK] I/O bus parity ... [OK] I/O bus spurious interrupts ... [OK] Temperature sensors ... [OK] IOC diagnostic processor ... [OK] Power margining ... [OK] Clock margining ... [OK] Selftest passed Restarting R1000-400S January 14th, 1901 at 22:56:43 OPERATOR MODE MENU - options are: 1 =&amp;gt; Change BOOT/CRASH/MAINTENANCE options 2 =&amp;gt; Change IOP CONFIGURATION 3 =&amp;gt; Enable manual crash debugging (EXPERTS ONLY) 4 =&amp;gt; Boot IOP, prompting for tape or disk 5 =&amp;gt; Boot SYSTEM Enter option [Boot SYSTEM] : 5 Logical tape drive 0 is an 8mm cartridge tape drive. Logical tape drive 1 is declared non-existent. Logical tape drive 2 is declared non-existent. Logical tape drive 3 is declared non-existent. Booting I/O Processor with Bootstrap version 0.4 Boot from (Tn or Dn) [D0] : T0 Tape_Boot_1.2.0 920401 Waiting for tape unit ready. Strike any key to abort..................... End of Tape Reached.rewinding Select files to boot [D=DEFAULT, O=OPERATOR_SUPPLIED] : [D] Skipping.. Loading FS_0.M200 Loading RECOVERY.M200 Skipping................. Loading M400S_KERNEL_0.M200 Initializing M400S I/O Processor Kernel 4_2_16 Spinning up disk 0 IOP Kernel is initialized Enable line printer for console output [N] ? RECOVERY 14.04 92/09/17 10:00:00\ Options are: 0 =&amp;gt; Exit 1 =&amp;gt; Initialize disk (for experts only) 2 =&amp;gt; Initialize disk, drop USR defects (internal use only) 3 =&amp;gt; Show MFG and USR bad block locations 4 =&amp;gt; Show only USR bad block locations 5 =&amp;gt; Install new DFS only 6 =&amp;gt; Show bad block count and DOS limits Enter option : *** AC power is L&lt;/quote&gt;
    &lt;p&gt;The last line is probably from the time where I cut the power after seeing significant white-gray smoke coming up from the machine...&lt;/p&gt;
    &lt;p&gt;The following smell-test suggested that the PSU should be checked:&lt;/p&gt;
    &lt;p&gt;The capacitors are located between the 5V power rails (the two black blocks on each side of the cap).&lt;/p&gt;
    &lt;p&gt;Next job: Acquire and exchange 10 x 6800µF 6.3V capacitors (L&amp;lt;31, D&amp;lt;=18)&lt;/p&gt;
    &lt;head rend="h2"&gt;2019-08-29&lt;/head&gt;
    &lt;p&gt;Disappointment! - We had hoped to get further in the boot process, but met an "unwilling" machine that didn't even presented itself. The PSU powered up with its fan, but that was it - No lights, no 5V, -12V or +12V. During power-off, these lights turned for a very short period, indicating the PSU is capable but unwilling (Inhibit line active?). We are not completely sure of the reason, but we will debug the issue next week, starting with checking the RESHA diagrams, followed up by checking the IOC RTC-battery (which were replaced last week).&lt;/p&gt;
    &lt;head rend="h2"&gt;2019-08-22&lt;/head&gt;
    &lt;p&gt;After further tests we finally took the leap and grabbed the cutter and solder iron, and replaced the three suspected memory chips. Boot sequence with the original BIOS now gives:&lt;/p&gt;
    &lt;quote&gt;R1000-400 IOC SELFTEST 1.3.2 512 KB memory ... [OK] Memory parity ... [OK] I/O bus control ... [OK] I/O bus map ... [OK] I/O bus map parity ... [OK] I/O bus transactions ... [OK] PIT ... [OK] Modem DUART channel ... [OK] Diagnostic DUART channel ... [OK] Clock / Calendar ... [OK] Checking for RESHA board -- Bench mode (ID 7) detected Skipping RESHA tests Local interrupts ... [OK] Illegal reference protection ... [OK] I/O bus parity ... [OK] I/O bus spurious interrupts ... [OK] Temperature sensors ... [OK] IOC diagnostic processor ... [OK] Power margining ... [OK] Clock margining ... [OK] Selftest passed Restarting R1000-400S January 1st, 1901 at 00:03:56 Logical tape drive 0 is an 8mm cartridge tape drive. Logical tape drive 1 is declared non-existent. Logical tape drive 2 is declared non-existent. Logical tape drive 3 is declared non-existent. Booting I/O Processor with Bootstrap version 0.4 Boot from (Tn or Dn) [D0] :&lt;/quote&gt;
    &lt;p&gt;Success!&lt;/p&gt;
    &lt;p&gt;Next step: Mount the board into its rightful place and see how far it gets now...&lt;/p&gt;
    &lt;head rend="h2"&gt;2019-06-06&lt;/head&gt;
    &lt;p&gt;Decided to make further measurements with the oscilloscope in order to rule out other causes. Probing all pins on a good and a bad RAM chip did not reveal anything.&lt;/p&gt;
    &lt;p&gt;Tried to piggyback H11 with a new RAM-chip, and the questionable bit went mid between VCC and GND. It could be that the good chip tried to pull down while the bad chip pulled up. Double-checked chip-select on H3, the only other identified chip that may drive the same data line (D30), and chip-select is completely passive during the troublesome period.&lt;/p&gt;
    &lt;p&gt;Previous tests went between [0x00000000..0x00040000[ and [0x00040000..0x00080000[. Now tried to run the tests between [0x00001000..0x00021000[ and [0x00041000..0x00061000[ as well as between [0x00001200..0x00021200[ and [0x00041200..0x00061200[ to test whether run-length could be a factor. The exact same failing addresses indicate run-length is not a factor.&lt;/p&gt;
    &lt;p&gt;Tried a reverse scan, Set(addr), Clr(addr), Set(addr) then Get(addr-4). The same data bits are affected in both banks, but the failing addresses are not identical. Some patterns are similar, and some other patterns appears.&lt;/p&gt;
    &lt;p&gt;Tried another test with: Set(addr), Clr(addr), Set(addr), Get(addr+4), branch-test delay, then another Get(addr+4) - The second Get reads out correctly. this indicates that the chip does have the right value, but that it is incorrectly read out in some circumstances.&lt;/p&gt;
    &lt;head rend="h2"&gt;2019-05-23&lt;/head&gt;
    &lt;p&gt;Previous software tests indicated problems with certain bits at some address patterns: Bits 7 and 23 in the low bank and bit 30 in the high bank showed issues. The fault manifests itself at some addresses when the following memory accesses are done in quick succession: Set(addr), Clr(addr), Set(addr) then Get(addr+4) - The Get(addr+4) returns incorrect values only on these bits.&lt;/p&gt;
    &lt;p&gt;Today all RAM chips were checked with oscilloscope to verify and possibly identify the problem. H11, G10 and G41 showed different behavior on the oscilloscope, and these chips happens to map to the exact bits identified at the software test.&lt;/p&gt;
    &lt;p&gt;H40 did show a little flickering on the DC levels, but the flanks seemed OK.&lt;/p&gt;
    &lt;p&gt;The above input to the RAM-chips looks like this:&lt;/p&gt;
    &lt;p&gt;The output of a healthy chip looks like this:&lt;/p&gt;
    &lt;p&gt;The output of the sick chips looks like this:&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; Next step will be to replace them. We have replacements ready, so stay tuned... &lt;/p&gt;
    &lt;head rend="h2"&gt;2019-03-07&lt;/head&gt;
    &lt;p&gt;Tried to patch the EEPROM in various ways, and learned a lot more.&lt;/p&gt;
    &lt;p&gt;If we skip the offending memory check, (and the EEPROM checksum because we're lazy) we get all the way to the boot device prompt (tape/disk).&lt;/p&gt;
    &lt;p&gt;We got two-way serial connection to the console port: TX is TTL level, RX is RS-232 level.&lt;/p&gt;
    &lt;p&gt;In trivial homebrew tests, the RAM does not fail, but what we call "ramtest_5" repeatedly does.&lt;/p&gt;
    &lt;p&gt;Big discovery of the night: The two top address bits of the EEPROM are swapped on the PCB, so the middle two quarters are swapped in the image we try to reverse-engineer. After fixing that, the contents make a lot more sense.&lt;/p&gt;
    &lt;head rend="h2"&gt;2019-02-28&lt;/head&gt;
    &lt;p&gt;Managed to power up the IOC board stand-alone. 5V @ 35A required (30A didn't seem to be quite enough).&lt;/p&gt;
    &lt;p&gt;Procedure:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;5V @ 35A connected to 3 Capacitors at edge (to distribute load).&lt;/item&gt;
      &lt;item&gt;Reset (GB113) to Ground (page 23 of R1000_SCHEM_IOC.pdf).&lt;/item&gt;
      &lt;item&gt;CTS# (GB055) to 5V (page 25)&lt;/item&gt;
      &lt;item&gt;Power On&lt;/item&gt;
      &lt;item&gt;Release Reset (GB113)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;TTL Serial output read from CPDRV0 @N1 (pin 2 or 3).&lt;/p&gt;
    &lt;p&gt;As expected output is still:&lt;/p&gt;
    &lt;quote&gt;R1000-400 IOC SELFTEST 1.3.2 512 KB memory ... * * * * * * * FAILED&lt;/quote&gt;
    &lt;p&gt;EEPROM 28256 is not compatible with EPROM 27256!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45154947</guid></item><item><title>The Claude Code Framework Wars</title><link>https://shmck.substack.com/p/claude-code-framework-wars</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45155302</guid></item><item><title>The "impossibly small" Microdot web framework</title><link>https://lwn.net/Articles/1034121/</link><description>&lt;doc fingerprint="3ea911152da319f1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The "impossibly small" Microdot web framework&lt;/head&gt;
    &lt;p&gt;The Microdot web framework is quite small, as its name would imply; it supports both standard CPython and MicroPython, so it can be used on systems ranging from internet-of-things (IoT) devices all the way up to large, cloudy servers. It was developed by Miguel Grinberg, who gave a presentation about it at EuroPython 2025. His name may sound familiar from his well-known Flask Mega-Tutorial, which has introduced many to the Flask lightweight Python-based web framework. It should come as no surprise, then, that Microdot is inspired by its rather larger cousin, so Flask enthusiasts will find much to like in Microdot—and will come up to speed quickly should their needs turn toward smaller systems.&lt;/p&gt;
    &lt;p&gt;We have looked at various pieces of this software stack along the way: Microdot itself in January 2024, MicroPython in 2023, and Flask as part of a look at Python microframeworks in 2019.&lt;/p&gt;
    &lt;quote&gt;$ sudo subscribe today&lt;p&gt;Subscribe today and elevate your LWN privileges. You’ll have access to all of LWN’s high-quality articles as soon as they’re published, and help support LWN in the process. Act now and you can start with a free trial subscription.&lt;/p&gt;&lt;/quote&gt;
    &lt;p&gt; Grinberg began his talk with an introduction. He has been living in Ireland for a few years and "&lt;quote&gt;I make stuff&lt;/quote&gt;". That includes open-source projects, blog posts (on a Flask-based blog platform that he wrote), and "&lt;quote&gt;a bunch of books&lt;/quote&gt;". He works for Elastic and is one of the maintainers of the Elasticsearch Python client, "&lt;quote&gt;so maybe you have used some of the things that I made for money&lt;/quote&gt;". &lt;/p&gt;
    &lt;head rend="h4"&gt;Why?&lt;/head&gt;
    &lt;p&gt; With a chuckle, he asked: "&lt;quote&gt;Why do we need another web framework? We have so many already.&lt;/quote&gt;" The story starts with a move that he made to Ireland from the US in 2018; he rented a house with a "smart" heating controller and was excited to use it. There were two thermostats, one for each level of the house, and he was "&lt;quote&gt;really looking forward to the winter&lt;/quote&gt;" to see the system in action. &lt;/p&gt;
    &lt;p&gt; As might be guessed, he could set target temperatures in each thermostat; they would communicate with the controller that would turn the heating on and off as needed. In addition, the system had a web server that could be used to query various parameters or to start and stop the heaters. You could even send commands via SMS text messages; "&lt;quote&gt;there's a SIM card somewhere in that box [...] very exciting stuff&lt;/quote&gt;". &lt;/p&gt;
    &lt;p&gt; When winter rolled around, it did not work that well, however; sometimes the house was too chilly or warm and he had to start and stop the heaters himself. He did some debugging and found that the thermostats were reporting temperatures that were off by ±3°C, "&lt;quote&gt;which is too much for trying to keep the house at 20°&lt;/quote&gt;". The owner of the house thought that he was too used to the US where things just work; "&lt;quote&gt;at least she thinks that in America everything is super-efficient, everything works, and she thought 'this is the way things work in Ireland'&lt;/quote&gt;". So he did not make any progress with the owner. &lt;/p&gt;
    &lt;p&gt; At that point, most people would probably just give up and live with the problem; "&lt;quote&gt;I hacked my heating controller instead&lt;/quote&gt;". He set the temperatures in both thermostats to zero, which effectively disabled their ability to affect the heaters at all, and built two small boards running MicroPython, each connected to a temperature and humidity sensor device. He wrote code that would check the temperature every five minutes and send the appropriate commands to start or stop the heaters based on what it found. &lt;/p&gt;
    &lt;p&gt; So the second half of his first winter in Ireland went great. The sensors are accurate to ±0.5°C, so "&lt;quote&gt;problem solved&lt;/quote&gt;". But, that led to a new problem for him. "&lt;quote&gt;I wanted to know things: What's the temperature right now? Is the heating running right now or not? How many hours did it run today compared to yesterday?&lt;/quote&gt;" And so on. &lt;/p&gt;
    &lt;p&gt; He added a small LCD screen to display some information, but he had to actually go to the device and look at it; what he really wanted was to be able to talk to the device over WiFi and get information from the couch while he was watching TV. "&lt;quote&gt;I wanted to host a web server [...] that will show me a little dashboard&lt;/quote&gt;". &lt;/p&gt;
    &lt;p&gt; So he searched for web frameworks for MicroPython; in the winter of 2018-2019, "&lt;quote&gt;there were none&lt;/quote&gt;". Neither Flask nor Bottle, which is a good bit smaller, would run on MicroPython; both are too large for the devices, but, in addition, the standard library for MicroPython is a subset of that of CPython, so many things that they need are missing. A "&lt;quote&gt;normal person&lt;/quote&gt;" would likely have just accepted that and moved on; "&lt;quote&gt;I created a web framework instead.&lt;/quote&gt;" &lt;/p&gt;
    &lt;head rend="h4"&gt;Demo&lt;/head&gt;
    &lt;p&gt;He brought one of his thermostat devices to Prague for the conference and did a small demonstration of it operating during the talk. The device was connected to his laptop using USB, which provided power, but also a serial connection to the board. On the laptop, he used the rshell remote MicroPython shell to talk to the board, effectively using the laptop as a terminal.&lt;/p&gt;
    &lt;p&gt;He started the MicroPython read-eval-print loop (REPL) on the board in order to simulate the normal operation of the board. When it is plugged into the wall, rather than a laptop, it will boot to the web server, so he made that happen with a soft-reboot command. The device then connected to the conference WiFi and gave him the IP address (and port) where the server was running.&lt;/p&gt;
    &lt;p&gt;He switched over to Firefox on his laptop and visited the site, which showed a dashboard that had the current temperature (24.4°) and relative humidity (56.9%) of the room. He also used curl from the laptop to contact the api endpoint of the web application, which returned JSON with the two values and the time. There is no persistent clock on the board, so the application contacts an NTP server to pick up the time when it boots; that allows it to report the last time a measurement was taken.&lt;/p&gt;
    &lt;p&gt; Grinberg said that he wanted to set the expectations at the right level by looking at the capabilities of the microcontrollers he often uses with Microdot. For example, the ESP8266 in his thermostat device has 64KB of RAM and up to 4MB of flash. The ESP8266 is the smallest and least expensive (around €5) device with WiFi that he has found; there are many even smaller devices, but they lack the networking required for running a web server. The other devices he uses are the Raspberry Pi Pico W with 2MB of flash and 256KB of RAM and the ESP32 with up to 8MB of flash and 512KB of RAM. He contrasted those with his laptop, which has 32GB of RAM, so "&lt;quote&gt;you need 500,000 ESP8266s&lt;/quote&gt;" to have the same amount of memory. &lt;/p&gt;
    &lt;head rend="h4"&gt;Features&lt;/head&gt;
    &lt;p&gt;The core framework of Microdot is in a single microdot.py file. It is fully asynchronous, using the MicroPython subset of the CPython asyncio module, so it can run on both interpreters. It uses asyncio because that is the only way to do concurrency on the microcontrollers; there is no support for processes or threads on those devices.&lt;/p&gt;
    &lt;p&gt;Microdot has Flask-style route decorators to define URLs for the application. It has Request and Response classes, as well as hooks to run before and after requests, he said. Handling query strings, form data, and JSON are all available in Microdot via normal Python dictionaries. Importantly, it can handle streaming requests and responses; because of the limited memory of these devices, it may be necessary to split up the handling of larger requests or responses.&lt;/p&gt;
    &lt;p&gt; It supports setting cookies and sending static files. Web applications can be constructed from a set of modules, using sub-applications, which are similar to Flask blueprints. It also has its own web server with TLS support. "&lt;quote&gt;I'm very proud of all the stuff I was able to fit in the core Microdot framework&lt;/quote&gt;", Grinberg said. &lt;/p&gt;
    &lt;p&gt;He hoped that attendees would have to think for a minute to come up with things that are missing from Microdot, but they definitely do exist. There are some officially maintained extensions, each in its own single .py file, to fill some of those holes. They encompass functionality that is important, but he did not want to add to the core because that would make it too large to fit on the low-end ESP8266 that he is using.&lt;/p&gt;
    &lt;p&gt; There is an extension for multipart forms, which includes file uploads; "&lt;quote&gt;this is extremely complicated to parse, it didn't make sense to add it into the core because most people don't do this&lt;/quote&gt;". There is support for WebSocket and server-sent events (SSE). Templates are supported using utemplate for both Python implementations or Jinja, which only works on CPython. There are extensions for basic and token-based authentication and for secure user logins with session data; the latter required a replacement for the CPython-only PyJWT, which Grinberg wrote and contributed to MicroPython as jwt.py. There is a small handful of other extensions that he quickly mentioned as well. &lt;/p&gt;
    &lt;p&gt; "&lt;quote&gt;I consider the documentation as part of the framework&lt;/quote&gt;"; he is "&lt;quote&gt;kind of fanatical&lt;/quote&gt;" about documenting everything. If there is something missing or not explained well, "&lt;quote&gt;it's a bug that I need to fix&lt;/quote&gt;". He writes books, so the documentation is organized similarly; it comes in at 9,267 words, which equates to around 47 minutes of reading time. There is 100% test coverage, he said, and there are around 30 examples, with more coming. &lt;/p&gt;
    &lt;p&gt; A design principle that he follows is "&lt;quote&gt;no dark magic&lt;/quote&gt;". An example of dark magic to him is the Flask application context, "&lt;quote&gt;which very few people understand&lt;/quote&gt;". In Microdot, the request object is explicitly passed to each route function. Another example is the dependency injection that is used by the FastAPI framework to add components; Microdot uses explicit decorators instead. &lt;/p&gt;
    &lt;p&gt; He used the cloc utility to count lines of code, while ignoring comments and blank lines. Using that, Django comes in at 110,000 lines, Flask plus its essential Werkzeug library is 15,500 lines, FastAPI with Starlette is 14,900 lines, Bottle is around 3,000 lines, while the Microdot core has 765 lines ("&lt;quote&gt;believe it or not&lt;/quote&gt;") and a full install with all the extensions on MicroPython comes in at just shy of 1,700 lines of code. &lt;/p&gt;
    &lt;p&gt; He ended with an example of how Microdot can be so small by comparing the URL matching in Flask with Microdot. The Flask version does lots more than Microdot, with more supported types of arguments in a URL and multiple classes in the werkzeug.routing module; it has 1,362 lines of code. For Microdot, there is a more limited set of URL arguments, though there is still the ability to define custom types, and a single URLPattern class; all of that is done in 63 lines of code. "&lt;quote&gt;I don't intend to support everything that Flask supports, in terms of routing, but I intend to support the 20% that covers 80% of the use cases.&lt;/quote&gt;" That is the overall mechanism that he has used to get to something that is so small. &lt;/p&gt;
    &lt;p&gt;An audience member asked about whether the Microdot code was minified in order to get it to fit. Grinberg said that doing so was not all that useful for MicroPython, but the code is smaller on the board because it is precompiled on another system; that results in a microdot.mpy file, which is bytecode for MicroPython. For example, on the low-end device he is using for his thermostats, Microdot would not be able to be compiled on the device itself. There are some other tricks that can also be used for reducing the RAM requirements, like putting the code into the firmware as part of the MicroPython binary.&lt;/p&gt;
    &lt;p&gt; The final question was about performance, and how many requests per second could be handled. Grinberg said that he did not have any real numbers, but that the device he demonstrated is "&lt;quote&gt;really really slow&lt;/quote&gt;". That question led to a blog post in late July where Grinberg tried to more fully answer it. &lt;/p&gt;
    &lt;p&gt;[I would like to thank the Linux Foundation, LWN's travel sponsor, for travel assistance to Prague for EuroPython.]&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Index entries for this article&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Conference&lt;/cell&gt;
        &lt;cell&gt;EuroPython/2025&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Python&lt;/cell&gt;
        &lt;cell&gt;Web&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt; Posted Aug 23, 2025 15:26 UTC (Sat) by lyda (subscriber, #7429) [Link] (1 responses) When I wrote a lot of python, frameworks like this seemed great. But there's a better way. If you define the OpenAPI definition first, you can then generate the server, you can generate all the clients, you can generate tests for the server and client, as well as fuzz tests for the server. Less common, but you can do the same with gRPC. It also allows you to more easily move from one technology to another. Posted Aug 24, 2025 3:10 UTC (Sun) by ssmith32 (subscriber, #72404) [Link] Certainly not for the problem domain covered in the article. &lt;head&gt;OpenAPI or gRPC is a better path forward&lt;/head&gt;&lt;head&gt;OpenAPI or gRPC is a better path forward&lt;/head&gt;&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45155682</guid></item><item><title>What is the origin of the private network address 192.168.*.*? (2009)</title><link>https://lists.ding.net/othersite/isoc-internet-history/2009/oct/msg00000.html</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45156826</guid></item><item><title>Show HN: I'm a dermatologist and I vibe coded a skin cancer learning app</title><link>https://molecheck.info/</link><description>&lt;doc fingerprint="7fb8a917f1b73ba5"&gt;
  &lt;main&gt;
    &lt;p&gt;For the best experience, please scan the QR code with your phone's camera to use the app on your mobile device.&lt;/p&gt;
    &lt;p&gt;Are you worried about this skin lesion?Swipe left (concerned) / right (not concerned) or use the buttons.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45157020</guid></item><item><title>Serverless Horrors</title><link>https://serverlesshorrors.com/</link><description>&lt;doc fingerprint="499a9798958793a"&gt;
  &lt;main&gt;
    &lt;head rend="h5"&gt;Posts&lt;/head&gt;
    &lt;head rend="h4"&gt;~$1189.420/month&lt;/head&gt;
    &lt;p&gt;For no reason, Webflow charged me $1189.420 for a single month from a 69$/month plan.&lt;/p&gt;
    &lt;head rend="h4"&gt;$100,000.420&lt;/head&gt;
    &lt;p&gt;I ran a semi popular WebGL games uploading site that was hit bad by a DoS and I got a single day firebase bill for $100k...&lt;/p&gt;
    &lt;head rend="h4"&gt;$738.420&lt;/head&gt;
    &lt;p&gt;I subscribe to Vercel Pro for $20 per month. I also added a spending limit of $120, so no nasty surprises, right?&lt;/p&gt;
    &lt;head rend="h4"&gt;$70,000.69&lt;/head&gt;
    &lt;p&gt;You pay $50/month for your project, but one day you woke up to a $70,000 bill...&lt;/p&gt;
    &lt;head rend="h4"&gt;$22.639,69&lt;/head&gt;
    &lt;p&gt;I received an insanely bill of 22k USD today from simply using BigQuery on a public data set in the playground...&lt;/p&gt;
    &lt;head rend="h4"&gt;$250/month&lt;/head&gt;
    &lt;p&gt;9.000 page visits and I have to pay $250/month for it, that is $3000/year...&lt;/p&gt;
    &lt;head rend="h4"&gt;$1273.69&lt;/head&gt;
    &lt;p&gt;We asked Devin (AI) to make a change in our codebase....&lt;/p&gt;
    &lt;head rend="h4"&gt;$530.19&lt;/head&gt;
    &lt;p&gt;Never had to pay anything and suddenly im billed $530....&lt;/p&gt;
    &lt;head rend="h4"&gt;$383.69&lt;/head&gt;
    &lt;p&gt;Woke up to an almost $400 bill for my documentation site...&lt;/p&gt;
    &lt;head rend="h4"&gt;$103.26&lt;/head&gt;
    &lt;p&gt;Why $103 is a horror story? Well, imagine that you are on a free tier...&lt;/p&gt;
    &lt;head rend="h4"&gt;$96,280.69&lt;/head&gt;
    &lt;p&gt;So freaking speechless right now....&lt;/p&gt;
    &lt;head rend="h4"&gt;$120,000.420&lt;/head&gt;
    &lt;p&gt;Cloudflare took down our website after trying to force us to pay 120k$ within 24h...&lt;/p&gt;
    &lt;head rend="h4"&gt;$1,300.69&lt;/head&gt;
    &lt;p&gt;Imagine you create an empty, private AWS S3 bucket in a region of your preference...&lt;/p&gt;
    &lt;head rend="h4"&gt;$11,000.69&lt;/head&gt;
    &lt;p&gt;Sent $11k worth of emails during DoS attack, then lost my database...&lt;/p&gt;
    &lt;head rend="h4"&gt;$104,500.123&lt;/head&gt;
    &lt;p&gt;So I received an email from Netlify last weekend saying that I have a $104,500.00 bill overdue...&lt;/p&gt;
    &lt;head rend="h4"&gt;$23,000.420&lt;/head&gt;
    &lt;p&gt;What is happening?! Someone spammed EchoFox and spiked my Vercel bill to $23k and caused 56k+ accounts and trials...&lt;/p&gt;
    &lt;head rend="h4"&gt;$3,000.69&lt;/head&gt;
    &lt;p&gt;Attention Vercel users. Be careful what you test or deploy to Vercel. I decided to try out...&lt;/p&gt;
    &lt;head rend="h4"&gt;$620.123&lt;/head&gt;
    &lt;p&gt;My sitemap.txt used hundreds of GB/hours apparently...&lt;/p&gt;
    &lt;head rend="h4"&gt;$72,000.999&lt;/head&gt;
    &lt;p&gt;We Burnt $72K testing Firebase + Cloud Run and almost went Bankrupt...&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45157110</guid></item><item><title>A career is a pie-eating contest and the prize for winning is more pie</title><link>https://jason.energy/more-pie/</link><description>&lt;doc fingerprint="20da6c35faeb6572"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A career is a pie-eating contest &amp;amp; the prize for winning is more pie&lt;/head&gt;
    &lt;p&gt;They say “no good deed goes unpunished”. When we finish projects, it often leads to additional work. Whether or not that’s a good thing is up to us.&lt;/p&gt;
    &lt;p&gt;Have you ever taken ownership of a project, and the only thanks you get for doing a good job is to have similar tasks dumped on your plate?&lt;/p&gt;
    &lt;p&gt;You’ve entered a pie-eating contest where the prize for winning is more pie.&lt;/p&gt;
    &lt;p&gt;Cynical folks love the saying “no good deed goes unpunished”, and that’s how it can feel if you take ownership of something just to become the dumping ground for similar work.&lt;/p&gt;
    &lt;head rend="h2"&gt;How much do you like pie?&lt;/head&gt;
    &lt;p&gt;Whenever you take on ownership, you’re sending a signal to the folks around you: you’re willing to be responsible for this task. People who see you owning and completing this task will assume that you are both A) capable of handling this kind of work, and B) interested in doing more of it.&lt;/p&gt;
    &lt;p&gt;Whether or not that’s a good thing depends on whether or not you enjoy the work.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45157142</guid></item><item><title>Show HN: Semantic grep for Claude Code (RUST) (local embeddings)</title><link>https://github.com/BeaconBay/ck</link><description>&lt;doc fingerprint="3b13f818c3848bc2"&gt;
  &lt;main&gt;
    &lt;p&gt;ck (seek) finds code by meaning, not just keywords. It's a drop-in replacement for &lt;code&gt;grep&lt;/code&gt; that understands what you're looking for — search for "error handling" and find try/catch blocks, error returns, and exception handling code even when those exact words aren't present.&lt;/p&gt;
    &lt;code&gt;cargo install ck-search&lt;/code&gt;
    &lt;code&gt;# Find error handling patterns (finds try/catch, Result types, etc.)
ck --sem "error handling" src/

# Traditional grep-compatible search still works  
ck -n "TODO" *.rs

# Combine both: semantic relevance + keyword filtering
ck --hybrid "connection timeout" src/&lt;/code&gt;
    &lt;p&gt;For Developers: Stop hunting through thousands of regex false positives. Find the code you actually need by describing what it does.&lt;/p&gt;
    &lt;p&gt;For AI Agents: Get structured, semantic search results in JSON format. Perfect for code analysis, documentation generation, and automated refactoring.&lt;/p&gt;
    &lt;p&gt;For Teams: Works exactly like &lt;code&gt;grep&lt;/code&gt; with the same flags and behavior, but adds semantic intelligence when you need it.&lt;/p&gt;
    &lt;code&gt;# Build from source
cargo build --release

# Index your project for semantic search
./target/debug/ck index src/

# Search by meaning
./target/debug/ck --sem "authentication logic" src/
./target/debug/ck --sem "database connection pooling" src/
./target/debug/ck --sem "retry mechanisms" src/

# Use all the grep features you know
./target/debug/ck -n -C 3 "error" src/
./target/debug/ck -r "TODO|FIXME" .&lt;/code&gt;
    &lt;p&gt;Find code by concept, not keywords. Searches understand synonyms, related terms, and conceptual similarity.&lt;/p&gt;
    &lt;code&gt;# These find related code even without exact keywords:
ck --sem "retry logic"           # finds backoff, circuit breakers
ck --sem "user authentication"   # finds login, auth, credentials  
ck --sem "data validation"       # finds sanitization, type checking

# Get complete functions/classes containing matches (NEW!)
ck --sem --full-section "error handling"  # returns entire functions
ck --full-section "async def" src/        # works with regex too&lt;/code&gt;
    &lt;p&gt;All your muscle memory works. Same flags, same behavior, same output format.&lt;/p&gt;
    &lt;code&gt;ck -i "warning" *.log              # Case-insensitive  
ck -n -A 3 -B 1 "error" src/       # Line numbers + context
ck --no-filename "TODO" src/        # Suppress filenames (grep -h equivalent)
ck -l "error" src/                  # List files with matches only (NEW!)
ck -L "TODO" src/                   # List files without matches (NEW!)
ck -r --exclude "*.test.js" "bug"  # Recursive with exclusions
ck "pattern" file1.txt file2.txt   # Multiple files&lt;/code&gt;
    &lt;p&gt;Combine keyword precision with semantic understanding using Reciprocal Rank Fusion.&lt;/p&gt;
    &lt;code&gt;ck --hybrid "async timeout" src/    # Best of both worlds
ck --hybrid --scores "cache" src/   # Show relevance scores with color highlighting
ck --hybrid --threshold 0.02 query  # Filter by minimum relevance
ck -l --hybrid "database" src/      # List files using hybrid search&lt;/code&gt;
    &lt;p&gt;Perfect JSON output for LLMs, scripts, and automation.&lt;/p&gt;
    &lt;code&gt;ck --json --sem "error handling" src/ | jq '.file'
ck --json --topk 5 "TODO" . | jq -r '.preview'
ck --json --full-section --sem "database" . | jq -r '.preview'  # Complete functions&lt;/code&gt;
    &lt;p&gt;Automatically excludes cache directories, build artifacts, and system files.&lt;/p&gt;
    &lt;code&gt;# These are excluded by default:
# .git, node_modules, target/, .fastembed_cache, __pycache__

# Override defaults:
ck --no-default-excludes "pattern" .     # Search everything
ck --exclude "dist" --exclude "logs" .   # Add custom exclusions&lt;/code&gt;
    &lt;code&gt;# Create semantic index (one-time setup)
ck index /path/to/project

# Now search instantly by meaning
ck --sem "database queries" .
ck --sem "error handling" .
ck --sem "authentication" .&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;--regex&lt;/code&gt;(default): Classic grep behavior, no indexing required&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--sem&lt;/code&gt;: Pure semantic search using embeddings (requires index)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--hybrid&lt;/code&gt;: Combines regex + semantic with intelligent ranking&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;ck --sem --scores "machine learning" docs/
# [0.847] ./ai_guide.txt: Machine learning introduction...
# [0.732] ./statistics.txt: Statistical learning methods...
# [0.681] ./algorithms.txt: Classification algorithms...&lt;/code&gt;
    &lt;code&gt;# Glob patterns work
ck --sem "authentication" *.py *.js *.rs

# Multiple files
ck --sem "error handling" src/auth.rs src/db.rs

# Quoted patterns prevent shell expansion  
ck --sem "auth" "src/**/*.ts"&lt;/code&gt;
    &lt;code&gt;# Only high-confidence semantic matches
ck --sem --threshold 0.7 "query"

# Low-confidence hybrid matches (good for exploration)
ck --hybrid --threshold 0.01 "concept"

# Get complete code sections instead of snippets (NEW!)
ck --sem --full-section "database queries"
ck --full-section "class.*Error" src/     # Complete classes&lt;/code&gt;
    &lt;code&gt;# Limit results for focused analysis
ck --sem --topk 5 "authentication patterns"

# Great for AI agent consumption
ck --json --topk 10 "error handling" | process_results.py&lt;/code&gt;
    &lt;code&gt;# Check index status
ck status .

# Clean up and rebuild
ck clean .
ck index .

# Add single file to index
ck add new_file.rs&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Language&lt;/cell&gt;
        &lt;cell role="head"&gt;Indexing&lt;/cell&gt;
        &lt;cell role="head"&gt;Tree-sitter Parsing&lt;/cell&gt;
        &lt;cell role="head"&gt;Semantic Chunking&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Python&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅ Functions, classes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;JavaScript&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅ Functions, classes, methods&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;TypeScript&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅ Functions, classes, methods&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Haskell&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅ Functions, types, instances&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Text Formats: Markdown, JSON, YAML, TOML, XML, HTML, CSS, shell scripts, SQL, and plain text.&lt;/p&gt;
    &lt;p&gt;Smart Exclusions: Automatically skips &lt;code&gt;.git&lt;/code&gt;, &lt;code&gt;node_modules&lt;/code&gt;, &lt;code&gt;target/&lt;/code&gt;, &lt;code&gt;build/&lt;/code&gt;, &lt;code&gt;dist/&lt;/code&gt;, &lt;code&gt;__pycache__/&lt;/code&gt;, &lt;code&gt;.fastembed_cache&lt;/code&gt;, &lt;code&gt;.venv&lt;/code&gt;, &lt;code&gt;venv&lt;/code&gt;, and other common build/cache/virtual environment directories.&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/BeaconBay/ck
cd ck
cargo install --path ck-cli&lt;/code&gt;
    &lt;code&gt;# Coming soon:
brew install ck-search
apt install ck-search&lt;/code&gt;
    &lt;p&gt;ck uses a modular Rust workspace:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;ck-cli&lt;/code&gt;- Command-line interface and argument parsing&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ck-core&lt;/code&gt;- Shared types, configuration, and utilities&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ck-search&lt;/code&gt;- Search engine implementations (regex, BM25, semantic)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ck-index&lt;/code&gt;- File indexing, hashing, and sidecar management&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ck-embed&lt;/code&gt;- Text embedding providers (FastEmbed, API backends)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ck-ann&lt;/code&gt;- Approximate nearest neighbor search indices&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ck-chunk&lt;/code&gt;- Text segmentation and language-aware parsing&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ck-models&lt;/code&gt;- Model registry and configuration management&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Indexes are stored in &lt;code&gt;.ck/&lt;/code&gt; directories alongside your code:&lt;/p&gt;
    &lt;code&gt;project/
├── src/
├── docs/  
└── .ck/           # Semantic index (can be safely deleted)
    ├── embeddings.json
    ├── ann_index.bin
    └── tantivy_index/
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;.ck/&lt;/code&gt; directory is a cache — safe to delete and rebuild anytime.&lt;/p&gt;
    &lt;code&gt;# Find authentication/authorization code
ck --sem "user permissions" src/
ck --sem "access control" src/
ck --sem "login validation" src/

# Find error handling strategies  
ck --sem "exception handling" src/
ck --sem "error recovery" src/
ck --sem "fallback mechanisms" src/

# Find performance-related code
ck --sem "caching strategies" src/
ck --sem "database optimization" src/  
ck --sem "memory management" src/&lt;/code&gt;
    &lt;code&gt;# Git hooks
git diff --name-only | xargs ck --sem "TODO"

# CI/CD pipeline
ck --json --sem "security vulnerability" . | security_scanner.py

# Code review prep
ck --hybrid --scores "performance" src/ &amp;gt; review_notes.txt

# Documentation generation
ck --json --sem "public API" src/ | generate_docs.py&lt;/code&gt;
    &lt;code&gt;# Find related test files
ck --sem "unit tests for authentication" tests/
ck -l --sem "test" tests/           # List test files by semantic content

# Identify refactoring candidates  
ck --sem "duplicate logic" src/
ck --sem "code complexity" src/
ck -L "test" src/                   # Find source files without tests

# Security audit
ck --hybrid "password|credential|secret" src/
ck --sem "input validation" src/
ck -l --hybrid --scores "security" src/  # Files with security-related code&lt;/code&gt;
    &lt;code&gt;# View current exclusion patterns
ck --help | grep -A 20 exclude

# These directories are excluded by default:
# .git, .svn, .hg                    # Version control
# node_modules, target, build        # Build artifacts  
# .cache, __pycache__, .fastembed_cache  # Caches
# .vscode, .idea                     # IDE files&lt;/code&gt;
    &lt;code&gt;# .ck/config.toml
[search]
default_mode = "hybrid"
default_threshold = 0.05

[indexing]  
exclude_patterns = ["*.log", "temp/"]
chunk_size = 512
overlap = 64

[models]
embedding_model = "BAAI/bge-small-en-v1.5"&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Indexing: ~1M LOC in under 2 minutes (with smart exclusions and optimized embedding computation)&lt;/item&gt;
      &lt;item&gt;Search: Sub-500ms queries on typical codebases&lt;/item&gt;
      &lt;item&gt;Index size: ~2x source code size with compression&lt;/item&gt;
      &lt;item&gt;Memory: Efficient streaming for large repositories with span-based content extraction&lt;/item&gt;
      &lt;item&gt;File filtering: Automatic exclusion of virtual environments and build artifacts&lt;/item&gt;
      &lt;item&gt;Output: Clean stdout/stderr separation for reliable piping and scripting&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Run the comprehensive test suite:&lt;/p&gt;
    &lt;code&gt;# Full test suite (40+ tests)
./test_ck.sh

# Quick smoke test (14 core tests)
./test_ck_simple.sh&lt;/code&gt;
    &lt;p&gt;Tests cover grep compatibility, semantic search, index management, file filtering, and more.&lt;/p&gt;
    &lt;p&gt;ck is actively developed and welcomes contributions:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Issues: Report bugs, request features&lt;/item&gt;
      &lt;item&gt;Code: Submit PRs for bug fixes, new features&lt;/item&gt;
      &lt;item&gt;Documentation: Improve examples, guides, tutorials&lt;/item&gt;
      &lt;item&gt;Testing: Help test on different codebases and languages&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;git clone https://github.com/your-org/ck
cd ck
cargo build
cargo test
./target/debug/ck index test_files/
./target/debug/ck --sem "test query" test_files/&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;✅ grep-compatible CLI with semantic search and file listing flags (&lt;code&gt;-l&lt;/code&gt;,&lt;code&gt;-L&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;✅ FastEmbed integration with BGE models&lt;/item&gt;
      &lt;item&gt;✅ File exclusion patterns and glob support&lt;/item&gt;
      &lt;item&gt;✅ Threshold filtering and relevance scoring with visual highlighting&lt;/item&gt;
      &lt;item&gt;✅ Tree-sitter parsing and intelligent chunking (Python, TypeScript, JavaScript, Haskell)&lt;/item&gt;
      &lt;item&gt;✅ Complete code section extraction (&lt;code&gt;--full-section&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;✅ Enhanced indexing strategy with v3 semantic search optimization&lt;/item&gt;
      &lt;item&gt;✅ Clean stdout/stderr separation for reliable scripting&lt;/item&gt;
      &lt;item&gt;✅ Incremental index updates with hash-based change detection&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🚧 Configuration file support&lt;/item&gt;
      &lt;item&gt;🚧 Package manager distributions&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🔮 Multiple embedding model support&lt;/item&gt;
      &lt;item&gt;🔮 Advanced ranking algorithms&lt;/item&gt;
      &lt;item&gt;🔮 Plugin architecture for custom chunkers&lt;/item&gt;
      &lt;item&gt;🔮 Distributed/remote index support&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🔮 IDE integrations (VS Code, IntelliJ, etc.)&lt;/item&gt;
      &lt;item&gt;🔮 Git integration (semantic diffs, blame)&lt;/item&gt;
      &lt;item&gt;🔮 Web interface for team usage&lt;/item&gt;
      &lt;item&gt;🔮 Multi-language semantic understanding&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Q: How is this different from grep/ripgrep/silver-searcher?&lt;lb/&gt; A: ck includes all the features of traditional search tools, but adds semantic understanding. Search for "error handling" and find relevant code even when those exact words aren't used.&lt;/p&gt;
    &lt;p&gt;Q: Does it work offline?&lt;lb/&gt; A: Yes, completely offline. The embedding model runs locally with no network calls.&lt;/p&gt;
    &lt;p&gt;Q: How big are the indexes?&lt;lb/&gt; A: Typically 1-3x the size of your source code, depending on content. The &lt;code&gt;.ck/&lt;/code&gt; directory can be safely deleted to reclaim space.&lt;/p&gt;
    &lt;p&gt;Q: Is it fast enough for large codebases?&lt;lb/&gt; A: Yes. Indexing is a one-time cost, and searches are sub-second even on large projects. Regex searches require no indexing and are as fast as grep.&lt;/p&gt;
    &lt;p&gt;Q: Can I use it in scripts/automation?&lt;lb/&gt; A: Absolutely. The &lt;code&gt;--json&lt;/code&gt; flag provides structured output perfect for automated processing. Use &lt;code&gt;--full-section&lt;/code&gt; to get complete functions for AI analysis.&lt;/p&gt;
    &lt;p&gt;Q: What about privacy/security?&lt;lb/&gt; A: Everything runs locally. No code or queries are sent to external services. The embedding model is downloaded once and cached locally.&lt;/p&gt;
    &lt;p&gt;Licensed under either of:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Apache License, Version 2.0 (LICENSE-APACHE)&lt;/item&gt;
      &lt;item&gt;MIT License (LICENSE-MIT)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;at your option.&lt;/p&gt;
    &lt;p&gt;Built with:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Rust - Systems programming language&lt;/item&gt;
      &lt;item&gt;FastEmbed - Fast text embeddings&lt;/item&gt;
      &lt;item&gt;Tantivy - Full-text search engine&lt;/item&gt;
      &lt;item&gt;clap - Command line argument parsing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Inspired by the need for better code search tools in the age of AI-assisted development.&lt;/p&gt;
    &lt;p&gt;Start finding code by what it does, not what it says.&lt;/p&gt;
    &lt;code&gt;cargo build --release
./target/release/ck index .
./target/release/ck --sem "the code you're looking for"&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45157223</guid></item><item><title>What Really Caused the Sriracha Shortage? (2024)</title><link>https://fortune.com/2024/01/30/sriracha-shortage-huy-fong-foods-tabasco-underwood-ranches/</link><description>&lt;doc fingerprint="57d450542f0634fc"&gt;
  &lt;main&gt;
    &lt;p&gt;On the day that the foundation of Craig Underwood’s business collapsed, he was on vacation—at the beach with his wife, daughters, and grandchildren in Hawaii.&lt;/p&gt;
    &lt;p&gt;It was November 2016, and the fourth-generation California farmer had just completed a perfect pepper harvest—another high point for a business, Underwood Ranches, that had grown exponentially over three decades on the strength of a single crop. As the sole supplier of the juicy red jalapeños for sriracha, Huy Fong Foods’ iconic fiery-red chili-garlic sauce, Underwood’s empire of peppers had spread from a 400-acre family farm in the 1980s to 3,000 acres across two counties outside Los Angeles.&lt;/p&gt;
    &lt;p&gt;Sriracha’s rise had by then become the stuff of business legend. That spicy, slightly sweet, good-on-everything sauce, in the instantly recognizable bottle with its white rooster emblem and bright green nozzle, was the brainchild of David Tran, who had first devised the recipe and sold the stuff in L.A. in 1980 as a Vietnamese refugee starting a new life for his family.&lt;/p&gt;
    &lt;p&gt;Tran’s business motto is “make product, and not profit,” but Huy Fong had become the No. 3 hot sauce brand in America—all as a private company, without selling even the smallest share to the country’s Big Food titans. At the time, Tran’s green-tipped bottles could be found in one in 10 American kitchens and on the International Space Station.&lt;/p&gt;
    &lt;p&gt;Sriracha’s success grew from the firm ground of Underwood and Tran’s business partnership: Underwood supplied all Huy Fong’s chilies, and Tran was Underwood Ranches’ only pepper buyer. By 2012, Tran had built a gleaming 650,000-square-foot factory less than two hours from Underwood’s Ventura County headquarters. On a tour of the site, he told Underwood that together they would fill it with chilies.&lt;/p&gt;
    &lt;p&gt;The two men came from different worlds, but they had a lot in common: Soft-spoken patriarchs with kind eyes and faces craggy with laugh lines, both had remained workaholics well into their seventies. Over the 28 years they’d been in business, the two had broken bread together with their wives, watched each other’s children grow up, stood together through hard times and business crises. They had even met up, with their families, to talk about succession.&lt;/p&gt;
    &lt;p&gt;Just days earlier, after the last truckload of the 2016 harvest had been delivered, Underwood and Tran had sat together and mapped out the 2017 growing season, and what Tran would pay in advance for the tens of millions of pounds of peppers Underwood promised him. As usual, the agreement was verbal, sealed with a nod and a handshake, not contracts or lawyers.&lt;/p&gt;
    &lt;p&gt;Then, on Nov. 10, at his vacation rental on Kauai, Underwood got a call with news that he could barely take in. His farm’s chief operating officer, Jim Roberts, told him that the relationship had ended, severed in one afternoon by an argument over payment for next season’s crop. Underwood Ranches and Huy Fong Foods would never do business together again.&lt;/p&gt;
    &lt;p&gt;“That’s one way to ruin a vacation,” Underwood now says ruefully.&lt;/p&gt;
    &lt;p&gt;The schism turned out to be even more catastrophic than either side could have imagined. It left Tran without the peppers he needed to meet the ever-growing demand for his sriracha. Since he lost Underwood’s chilies, his massive factory in Irwindale, Calif., has operated sporadically, at a fraction of its capacity. For the first year after the split, Huy Fong got by on stockpiled mash and Mexican chilies, which were cheap because of a glut. But supply has often been spotty since then: In the first half of 2023, Huy Fong had no chilies at all.&lt;/p&gt;
    &lt;p&gt;Underwood, meanwhile, faced financial ruin: The vast swaths of land that he had purchased or leased to grow jalapeños couldn’t be planted without a buyer. He was locked into 25-year leases on much of the land he had expanded into, and he didn’t have cash on hand to pay his own suppliers. He took out loans, sold some parcels, and laid off 45 workers.&lt;/p&gt;
    &lt;p&gt;Both businesses lost millions. The two men became bitter enemies—and they offer sharply contrasting accounts of what went wrong.&lt;/p&gt;
    &lt;p&gt;At first, Underwood recalls, he was confused and hurt. “We were trying to figure out what the hell’s going on,” he tells me when I visit his offices in Camarillo, Calif., in December. “Because we were really vulnerable, both in the percentage of our business that he commanded—and I guess our belief that we were going to have a long-term relationship.” But he soon became convinced, Underwood tells me, that Tran’s intentions were bad, and had been for some time. “Basically, he really was out to destroy me,” he says. “He didn’t give a damn about me or our family or all that we’d done together.”&lt;/p&gt;
    &lt;p&gt;Over at Huy Fong, feelings were similarly raw. Tran felt betrayed, and blindsided by accusations that he had been underhanded. For most of three decades, he had remained loyal to Underwood as his only pepper producer, and each year he had handed over millions on the promise of a harvest, a gesture that he saw as an act of faith. Now all that trust had collapsed in a petty argument over money.&lt;/p&gt;
    &lt;p&gt;Tran has come to believe that Underwood was trying to drive him to bankruptcy, then steal his sauce business. “I helped him because he grew chili for me,” he says. “He made money, he owned land. But it is not enough. He wanted to take over my business.” It felt like being “stabbed in the back,” adds Donna Lam, Tran’s sister-in-law and executive operations officer.&lt;/p&gt;
    &lt;p&gt;Following the 2016 blowup, months of tense negotiations between the two parties to try to resuscitate the business arrangement failed. In 2017, Huy Fong Foods sued to recover an overpayment for the 2016 harvest, and Underwood Ranches countersued, alleging fraud and breach of contract. A jury found in the farmer’s favor, awarding him $13.3 million in compensatory damages and $10 million in punitive damages. It also found that Huy Fong had overpaid Underwood $1.4 million for the 2016 growing season, and ordered Underwood Ranches to reimburse that amount.&lt;/p&gt;
    &lt;p&gt;But the legal resolution didn’t ease either company’s struggles. Meanwhile, the fallout from the breakup continues to leave sriracha lovers scrambling to get their fix. Those once-ubiquitous bottles became scarce and at times disappeared from supermarket shelves. Headlines about the Great Sriracha Shortage led to stockpiling, and the sauce started selling on the online resale market for up to $80 a bottle. Dozens of copycat srirachas have thrived amid the original’s scarcity, including versions from the likes of Tabasco and Roland, and generics from supermarket chains.&lt;/p&gt;
    &lt;p&gt;There’s a cruel irony to the predicament of Craig Underwood, who’s now 81, and David Tran, 78. One man with thousands of acres of pepper fields, but nobody to buy his peppers. Another with a massive pepper factory, and not enough peppers to keep it running. Meanwhile, an adoring fan base pines for the product the men made together, even as the two remain estranged—victims, perhaps, of their own runaway success.&lt;/p&gt;
    &lt;p&gt;What makes sriracha special? Tran’s sauce is a simple uncooked and unfermented puree, made by grinding together fresh red jalapeños, sugar, garlic, vinegar, and two preservatives. And it truly is good on everything, food writer and chili sauce aficionado Matt Gross says: “It’s just a really great, balanced blend, and it adapts well. It’s not too spicy. It’s not too garlicky. It’s not too vinegary.”&lt;/p&gt;
    &lt;p&gt;Tran’s striking product design helps: The iconography of the rooster picture (to commemorate the year of Tran’s birth, 1945, in the Chinese astrological calendar) and that jaunty green nozzle make a Huy Fong sriracha bottle hard to miss. “It is a gorgeous, gorgeous object,” Gross says.&lt;/p&gt;
    &lt;p&gt;Though Tran loosely based his sauce on a Thai fermented dip for eggs and seafood, and named it for the coastal Thai town of Si Racha, Huy Fong’s sriracha is quite different—thicker and less sweet. Still, its being named for a town meant that “sriracha” couldn’t be trademarked in the U.S.—a fact that became significant when other brands began using the product name.&lt;/p&gt;
    &lt;p&gt;Tran’s timing for launching sriracha was impeccable; it arrived just as American tastes were beginning to broaden and become more adventurous. In 1980, when Tran started bottling his sauce in an industrial space he rented near Los Angeles’ Chinatown, America was not yet a place of ghost-pepper-eating contests or tattooed hipster chefs touting bespoke chili-sauce brands. “I wasn’t thinking of selling it mainstream to the Americans,” he explained in 2013 for a Vietnamese American oral history project at the University of California, Irvine. “I was going to sell it to Chinese or Vietnamese.”&lt;/p&gt;
    &lt;p&gt;Huy Fong made three chili sauces, but it was sriracha that really caught on, first in California’s immigrant communities, and then on a much vaster scale. Kara Nielsen, a food trends researcher, remembers first encountering the sauce when she was a pastry chef in the 1990s at a farm-to-table restaurant in Berkeley. Although it wasn’t offered to customers, there was always a bottle of the “rooster sauce” on the table during staff meals, she says: “It was used by the Latino and Asian cooks to basically add chili heat to anything.” Within a few years, she says, foodies had taken to the product, eagerly squirting it on their Vietnamese banh mi sandwiches in San Francisco’s Tenderloin district.&lt;/p&gt;
    &lt;p&gt;As demand ramped up, Tran’s big challenge was finding a stable source of fresh, red jalapeños—the freshness being, in his view, the key to his sauce’s flavor. At first he relied upon local supermarkets and wholesalers at L.A.’s Central Market. But the supply was inconsistent and the timing was tricky: Most jalapeños are sold when they’re crisp and green, but Tran’s sauce requires the sweeter, less-grassy version of the fruit, after it ripens to red—but before it overripens and becomes soft. That makes it a finicky product for farmers to grow and transport.&lt;/p&gt;
    &lt;p&gt;The answer to Tran’s conundrum came in a letter. In nearby Ventura County, Craig Underwood was facing headwinds keeping his family farm going. California’s conventional vegetable farming landscape was changing, and Underwood had pivoted to growing baby vegetables and salad greens. The advent of “baby-cut” carrots (larger carrots cut to snackable size) threatened that business too. In 1988, a seed supplier mentioned to Underwood that he had heard about a guy pounding the pavement for peppers for chili sauce in L.A., Underwood recalls: “I wrote a letter to David and said, ‘Would you like me to grow some peppers?’ ”&lt;/p&gt;
    &lt;p&gt;Tran contracted Underwood to grow 50 acres—and so began a lucrative relationship for both men. Over the next three decades, they became, if not exactly close friends, at least friendly associates. When the city of Irwindale tried (unsuccessfully) to evict Tran’s new sauce factory in 2013, saying the chilies were releasing spicy fumes into the surrounding neighborhoods, Underwood testified on his behalf at a city council meeting.&lt;/p&gt;
    &lt;p&gt;Meanwhile, sriracha took off on a scale nobody could have predicted. As the American culinary palate has become more international, Huy Fong’s rooster sauce has grown ubiquitous. Huy Fong remained an independent company, turning down offers to buy or invest from large food corporations, and has never spent a penny on advertising. But the brand spread rapidly by word of mouth, creating a fandom that has made the sauce into a kind of identity statement, with festivals, online videos, rooster-branded T-shirts, and streetwear brand collabs. Huy Fong doesn’t disclose revenue figures, but according to the market research firm IBISWorld it had sales of $131 million in 2020.&lt;/p&gt;
    &lt;p&gt;Sriracha has achieved the rare feat of creating its own category of culinary product, a craveable flavor that has shown up in mass-marketed foods from McDonald’s chicken sandwiches to Doritos’ Screamin’ Sriracha chips, and in the kitchens of Michelin-starred chefs. “The lure of Asian authenticity is part of the appeal,” the writer John T. Edge observed in the New York Times in 2009, describing the “polyglot purée” beloved by chefs including Jean-Georges Vongerichten.&lt;/p&gt;
    &lt;p&gt;The exclusive, symbiotic relationship that Huy Fong Foods and Underwood Ranches developed was “highly unusual in the processing business,” Underwood says in a 2013 documentary. “But as long as they’re selling more product, we have to be growing it for them. It’s a big job. A huge job.”&lt;/p&gt;
    &lt;p&gt;That film, Sriracha, now feels like a kind of time capsule—a snapshot of the two businessmen flying closer and closer to the sun. The relationship of the sauce maker and the farmer was the emotional heart of the film, and its director, Griffin Hammond, remembers finding the men’s relationship “beautiful”: “They both spoke so fondly of each other,” he tells me.&lt;/p&gt;
    &lt;p&gt;How did that beautiful relationship fall apart so quickly and brutally? It’s a question both Underwood and Tran still puzzle over, and sriracha fans speculate about online. But the basic story is laid out, starkly, in court papers from the lawsuit and countersuit that followed the imbroglio.&lt;/p&gt;
    &lt;p&gt;As Huy Fong’s business grew, so too did Tran’s need for massive quantities of chilies, and Underwood kept increasing the farm’s pepper fields, reducing his other crops. To reassure the grower that he wouldn’t be financially wiped out if one year’s pepper crop failed, the companies agreed in 2008 to switch to a system of acreage instead of volume, with Huy Fong assuming the risk by prepaying at the beginning of the growing season to cover the costs of seeds, equipment, and labor. Working this way, the two companies kept ramping up yields and production, to a height of 100 million pounds of peppers in 2015.&lt;/p&gt;
    &lt;p&gt;That’s the year that trust between the two companies began to erode. Tran started a separate company, ChiliCo, to buy and sell chili peppers. Underwood didn’t want to work with ChiliCo because he feared it wouldn’t have the assets to guarantee payments. To make matters worse, Underwood says, Tran and Lam made several failed attempts to hire Roberts, his COO, to work for ChiliCo. (Lam says the offers to Roberts were always intended to supplement his income at Underwood Ranches, and not to poach him.)&lt;/p&gt;
    &lt;p&gt;Things came to a head that terrible afternoon in November 2016. Recollections differ, but what’s agreed upon is this: On Nov. 9, Roberts drove over to Huy Fong’s factory at Tran’s request, to look at some equipment. Tran and Lam called Roberts into his office for a conversation, which turned contentious.&lt;/p&gt;
    &lt;p&gt;They disagreed about what price Huy Fong should prepay for next season’s peppers, whether Tran could get those jalapeños cheaper from overseas, and whether Roberts should accept Tran’s offer to work for him.&lt;/p&gt;
    &lt;p&gt;The row raged on and on. Things were said that couldn’t be taken back. And by the time Roberts left a few hours later, a 28-year business relationship was effectively over.&lt;/p&gt;
    &lt;p&gt;Seven years after the rift, both companies are creaking along, doing the best they can to move forward.&lt;/p&gt;
    &lt;p&gt;On a visit to Huy Fong’s factory in December, I watched bottles of sriracha being filled, sealed, topped with green nozzles, and packed into boxes to ship out to 26 nations. Workers, mostly dressed in sriracha-themed T-shirts from the factory swag shop, wore hairnets and masks but seemed accustomed to the throat-tickling capsaicin fumes in the air.&lt;/p&gt;
    &lt;p&gt;Ominously, there were no unprocessed chilies on hand—none had come in lately. Part of the problem, Tran and Lam explain, is quality control: Freshness is what makes Huy Fong’s sauce better than the competition, and Tran says he often has had to turn away truckloads of that delicate red jalapeño because they didn’t make the journey from suppliers intact, were not properly refrigerated, or were picked when green.&lt;/p&gt;
    &lt;p&gt;Even with the disruptions in production caused by the ongoing chili supply crisis, Huy Fong hasn’t laid off any of its 115 employees, Lam tells me. “David paid out of his pocket to keep them there,” Lam says. “This is not the person that would cheat someone.”&lt;/p&gt;
    &lt;p&gt;Meanwhile, an hour and a half’s drive away, Underwood has launched his own chili sauce business. Underwood Ranches has a long way to go before it can put the disaster of the past few years behind it, but its fields are now planted with a mix of tomatoes for canning, potatoes, onions, Brussels sprouts, pumpkins, and other crops.&lt;/p&gt;
    &lt;p&gt;At Underwood’s processing facility in Camarillo, the ribbon mixers were churning out the last of a much smaller 2023 pepper harvest to make its own sriracha, known as Dragon Sriracha. It’s a brand that hasn’t broken through yet, but it’s growing—with a couple of big distribution deals on the horizon, Underwood says. He recently started shipping his sriracha to 24 Costco branches. However reluctantly, Tran’s onetime partner is joining his growing field of competitors.&lt;/p&gt;
    &lt;p&gt;The 800-pound gorilla in American hot sauce is, of course, Tabasco, which produces the nation’s most popular chili sauce. The McIlhenny Company, founded in 1868 on Louisiana’s Avery Island, launched its own sriracha in 2014. It wasn’t until 2022, however, that Tabasco’s version of Tran’s sauce really took off, and Lee Susen, McIlhenny’s chief sales and marketing officer, makes no bones about why: It was the “shelf voids” that the shortage of Huy Fong’s product left, he tells Fortune.&lt;/p&gt;
    &lt;p&gt;Tabasco wasn’t going to let Huy Fong’s crisis go to waste, so in September 2022 it launched the website srirachashortage.com. “LOOKING FOR SOMETHING?” it asks in large white block letters as a Tabasco sriracha bottle surges upward, looking at first just like a Huy Fong bottle (though with a nozzle that’s olive green rather than bright green).&lt;/p&gt;
    &lt;p&gt;Previously the challenge Tabasco faced with its sriracha, Susen says, was that “most consumers saw sriracha as a brand. They didn’t recognize it as a product type.” But when Huy Fong’s iconic bottles disappeared and were replaced by various other srirachas, that began to change: It became just another pantry staple. The brand loyalty that had been Huy Fong’s economic “moat”—business parlance for a competitive advantage one company holds in its sector—started to erode.&lt;/p&gt;
    &lt;p&gt;And that’s when the biggest hot sauce brand in America swooped in and took the crown. Tabasco had the bestselling sriracha in the country for the second half of 2023, according to NielsenIQ. Sriracha, the product, is more popular than ever—it’s now in one in three U.S. kitchens, according to market research firm Circana—but most of it is not Huy Fong’s. “It’s a very exciting time to be in the hot sauce business,” Susen says. “And certainly the sriracha business.”&lt;/p&gt;
    &lt;p&gt;Tabasco’s win is Huy Fong’s loss. And it’s an epic comedown for a great American brand, an ignoble ending to a storied American business partnership between a hardworking Vietnamese refugee and a salt-of-the-earth California farmer.&lt;/p&gt;
    &lt;p&gt;Maybe Craig Underwood and David Tran were, on some level, victims of their own success? “We hooked onto that wagon and it really took off,” Underwood says now. “And we never could have predicted it when we started.”&lt;/p&gt;
    &lt;p&gt;Indeed, when Tran was grinding chili sauce in his kitchen and Underwood was farming baby carrots, neither could have imagined that they’d one day be managing hundreds of employees and making deals worth millions of dollars. In retrospect, Underwood says, he wishes they had built in more legal safeguards to protect their businesses from the beginning. He wonders whether he should have spread out his risk, instead of treating the arrangement between the two companies as a partnership. He wishes sometimes that he had sold his pepper production operations to Huy Fong Foods (an offer he made at one point) and started afresh.&lt;/p&gt;
    &lt;p&gt;Both Tran and Underwood brought great qualities to the partnership: grit, inventiveness, passion, ambition. But the skills and disposition necessary to make a startup a success are quite different from the competencies that people running large companies need. That’s one reason many founders end up selling or taking investments, says Maurice Schweitzer, a professor of operations, information, decisions, and management at the Wharton School. Doing so can feel like “selling out,” but bringing in a more experienced partner can also be stabilizing.&lt;/p&gt;
    &lt;p&gt;It’s impossible to know for sure, but a change in ownership structure might have made all the difference, Schweitzer says. Human relationships are fraught, and almost always include an element of competitiveness. Unchecked, that competitiveness can grow like a weed and take over, especially when a business is expanding rapidly: “There’s going to be some point of friction; there’s going to be some miscommunication,” Schweitzer says. “We need some mechanism to correct that and put it back on track.”&lt;/p&gt;
    &lt;p&gt;For instance, when a dramatic leadership crisis erupted last November at the AI startup OpenAI, Microsoft’s role as a major investor helped force a quick resolution. “With Microsoft, there’s a grownup in the room,” Schweitzer says. “They can keep their eye on the ball.”&lt;/p&gt;
    &lt;p&gt;But with Huy Fong and Underwood Ranches, Schweitzer points out, “it’s just two people left on their own … There isn’t, like, some arbitrator or banker; there wasn’t a third party to bring them together.”&lt;/p&gt;
    &lt;p&gt;A broken business deal doesn’t quite rise to the level of tragedy. But there is something very sad about how David Tran and Craig Underwood were willing to walk away from each other, leaving all that they’d built in peril and untold millions on the table. Once their trust was broken, their enmity grew stronger even than their desire to succeed.&lt;/p&gt;
    &lt;p&gt;With so much at stake and so much opportunity remaining, I ask each man: Would they ever come back together?&lt;/p&gt;
    &lt;p&gt;Absolutely not, Tran tells me. “I need chili, but a guy like that? Why?” he says. “Without his chili, yeah, we make less money. But no.” Lam says her family has tried to put the affair behind them. “At the end it just got really messy,” she says. “And David and I, we don’t want to talk about it, because what’s done, it’s done. It doesn’t matter … What’s lost is lost. And that’s the sad part about it. We’re not going to think about the past. We need to think about the future.”&lt;/p&gt;
    &lt;p&gt;Underwood is similarly adamant when I ask whether he’d ever work with Huy Fong again. “Not with David,” he says. “If somebody else took over, purchased Huy Fong Foods, yeah, we’d certainly want to do business. But not with David.”&lt;/p&gt;
    &lt;p&gt;Looking back is hard for Underwood, too, he tells me, and he sometimes wonders how he got through those first few years after the breakup. “Nobody can understand what it was like to go through that whole thing,” he says. “I mean, it was hell.”&lt;/p&gt;
    &lt;p&gt;Of course there’s one person who probably could understand it. And seven years later, that’s one thing the former partners still have in common, as Underwood acknowledges: “In this,” he says, “everybody turned out to be a loser.”&lt;/p&gt;
    &lt;p&gt;—Jasper Chapman contributed reporting to this story.&lt;/p&gt;
    &lt;p&gt;EDITOR’S NOTE: This article has been updated to correct the description of the topics discussed in the Nov. 9, 2016 meeting.&lt;/p&gt;
    &lt;p&gt;This article appears in the February/March 2024 issue of Fortune with the headline “Hot Mess.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45157567</guid></item></channel></rss>