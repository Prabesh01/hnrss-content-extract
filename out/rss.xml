<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 28 Jan 2026 10:52:10 +0000</lastBuildDate><item><title>Show HN: One Human + One Agent = One Browser From Scratch in 20K LOC</title><link>https://emsh.cat/one-human-one-agent-one-browser/</link><description>&lt;doc fingerprint="2e52a454497530bd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;One Human + One Agent = One Browser From Scratch&lt;/head&gt;
    &lt;p&gt;2026-01-27&lt;/p&gt;
    &lt;p&gt;Just for the fun of it, I thought I'd embark on a week-long quest to generate millions of tokens and millions of lines of source code to create one basic browser that can render HTML and CSS (no JS tho), and hopefully I could use this to receive even more VC investments.&lt;/p&gt;
    &lt;p&gt;But then I remembered that I have something even better: a human brain! It is usually better than any machine at coordinating and thinking through things, so let's see if we can hack something together, one human brain and one LLM agent brain!&lt;/p&gt;
    &lt;p&gt;The above might look like a simple .webm video, but it's actually a highly sophisticated and advanced browser that was super hard to build, encoded as pixels in a video file! Wowzers.&lt;/p&gt;
    &lt;head rend="h2"&gt;Day 1 - Starting out&lt;/head&gt;
    &lt;p&gt;For extra fun when building this, I set these requirements for myself and the agent:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I have three days to build it&lt;/item&gt;
      &lt;item&gt;Not a single 3rd party Rust library/dependency allowed&lt;/item&gt;
      &lt;item&gt;Allowed to use anything (commonly) provided out of the box on the OS it runs on&lt;/item&gt;
      &lt;item&gt;Should run on Windows, macOS and common Linux distributions&lt;/item&gt;
      &lt;item&gt;Should be able to render some websites, most importantly, my own blog and Hacker News, should be easy right?&lt;/item&gt;
      &lt;item&gt;The codebase can always compile and be built&lt;/item&gt;
      &lt;item&gt;The codebase should be readable by a human, although code quality isn't the top concern&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So with these things in mind, I set out on the journal to build a browser "from scratch". I started with something really based, being able to just render "Hello World". Then to be able to render some nested tags. Added the ability of taking screenshots so the agent could use that. Added specifications for HTML/CSS (which I think the agent never used :| ), and tried to nail down the requirements for the agent to use. Also started doing "regression" or "E2E" tests with the screenshotting feature, so we could compare to some baseline images and so on. Added the ability to click on links just for the fun of it.&lt;/p&gt;
    &lt;p&gt;After about a day together with Codex, I had something that could via X11 and cURL, fetch and render websites when run, and the Cargo.lock is empty. It was about 7500 lines long in total at that point, split across files with all of them under 1000 lines long (which was a stated requirement, so not a surprise).&lt;/p&gt;
    &lt;head rend="h2"&gt;Day 2 - Moving On&lt;/head&gt;
    &lt;p&gt;Second day I got annoyed by the tests spawning windows while I was doing other stuff, so added a --headless flag too. Did some fixes for resizing the window, various compatibility fixes, some performance issues and improved the font/text rendering a bunch. Workflow was basically to pick a website, share a screenshot of the website without JavaScript, ask Codex to replicate it following our instructions. Most of the time was the agent doing work by itself, and me checking in when it notifies me it was done.&lt;/p&gt;
    &lt;head rend="h2"&gt;Day 3 - Polish &amp;amp; Cross-platform (+ day 4)&lt;/head&gt;
    &lt;p&gt;Third day we made large changes, lots of new features and a bunch of new features supported. More regression tests, fixing performance issues, fixing crashes and whatnot. Also added scrolling because this is a mother fucking browser, it has to be able to scroll. Added some debug logs too because that'll look cool in the demonstration video above, and also added support for the back button because it was annoying to start from scratch if I clicked the wrong link while testing.&lt;/p&gt;
    &lt;p&gt;At the end of the third day we also added starting support for macOS, and managed to get a window to open, and the tests to pass. Seems to work OK :) Once we had that working, we also added Windows support, basically the same process, just another platform after all.&lt;/p&gt;
    &lt;p&gt;Then the fourth day (whaaaat?) was basically polish, fixing CI for all three platforms, making it pass and finally cutting a release based on what got built in CI. Still all within 72 hours (3 days * 24 hours, which obviously this is how you count days).&lt;/p&gt;
    &lt;head rend="h2"&gt;The results after ~3 days (~70 hours)&lt;/head&gt;
    &lt;p&gt;And here it is, in all its glory, made in ~20K lines of code and under 72 hours of total elapsed time from first commit to last:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;You could try compiling it yourself (zero Rust dependencies, so it's really fast :) ), or you can find binaries built on CI here:&lt;/p&gt;&lt;lb/&gt;https://github.com/embedding-shapes/one-agent-one-browser/releases&lt;/quote&gt;
    &lt;p&gt;You can clone the repository, build it and try it out for yourself. It's not great, I wouldn't even say it's good, but it works, and demonstrates that one person with one agent can build a browser from scratch.&lt;/p&gt;
    &lt;p&gt;This is what the "lines of code" count ended up being after all was said and done, including support for three OSes:&lt;/p&gt;
    &lt;code&gt;$ git rev-parse HEAD
e2556016a5aa504ecafd5577c1366854ffd0e280

$ cloc src --by-file
      72 text files.
      72 unique files.
       0 files ignored.

github.com/AlDanial/cloc v 2.06  T=0.06 s (1172.5 files/s, 373824.0 lines/s)
-----------------------------------------------------------------------------------
File                                            blank        comment           code
-----------------------------------------------------------------------------------
src/layout/flex.rs                                 96              0            994
src/layout/inline.rs                               85              0            933
src/layout/mod.rs                                  82              0            910
src/browser.rs                                     78              0            867
src/platform/macos/painter.rs                      96              0            765
src/platform/x11/cairo.rs                          77              0            713
src/platform/windows/painter.rs                    88              0            689
src/bin/render-test.rs                             87              0            666
src/style/builder.rs                               83              0            663
src/platform/windows/d2d.rs                        53              0            595
src/platform/windows/windowed.rs                   72              0            591
src/style/declarations.rs                          18              0            547
src/image.rs                                       81              0            533
src/platform/macos/windowed.rs                     80              2            519
src/net/winhttp.rs                                 61              2            500
src/platform/x11/mod.rs                            56              2            487
src/css.rs                                        103            346            423
src/html.rs                                        58              0            413
src/platform/x11/painter.rs                        48              0            407
src/platform/x11/scale.rs                          57              3            346
src/layout/table.rs                                39              1            340
src/platform/x11/xft.rs                            35              0            338
src/style/parse.rs                                 34              0            311
src/win/wic.rs                                     39              8            305
src/style/mod.rs                                   26              0            292
src/style/computer.rs                              35              0            279
src/platform/x11/xlib.rs                           32              0            278
src/layout/floats.rs                               31              0            265
src/resources.rs                                   36              0            238
src/css_media.rs                                   36              1            232
src/debug.rs                                       32              0            227
src/platform/windows/dwrite.rs                     20              0            222
src/render.rs                                      18              0            196
src/style/custom_properties.rs                     34              0            186
src/platform/windows/scale.rs                      28              0            184
src/url.rs                                         32              0            173
src/layout/helpers.rs                              12              0            172
src/net/curl.rs                                    31              0            171
src/platform/macos/svg.rs                          35              0            171
src/browser/url_loader.rs                          17              0            166
src/platform/windows/gdi.rs                        17              0            165
src/platform/windows/scaled.rs                     16              0            159
src/platform/macos/scaled.rs                       16              0            158
src/layout/svg_xml.rs                               9              0            152
src/win/com.rs                                     26              0            152
src/png.rs                                         27              0            146
src/layout/replaced.rs                             15              0            131
src/net/pool.rs                                    18              0            129
src/platform/macos/scale.rs                        17              0            124
src/style/selectors.rs                             18              0            123
src/style/length.rs                                17              0            121
src/cli.rs                                         15              0            112
src/platform/windows/headless.rs                   20              0            112
src/platform/macos/headless.rs                     19              0            109
src/bin/fetch-resource.rs                          14              0            101
src/geom.rs                                        10              0            101
src/browser/render_helpers.rs                      11              0            100
src/dom.rs                                         11              0            100
src/style/background.rs                            15              0            100
src/layout/tests.rs                                 7              0             85
src/platform/windows/d3d11.rs                      14              0             83
src/win/stream.rs                                  10              0             63
src/platform/windows/svg.rs                        13              0             54
src/main.rs                                         4              0             33
src/platform/mod.rs                                 6              0             28
src/app.rs                                          5              0             25
src/lib.rs                                          1              0             20
src/platform/windows/mod.rs                         2              0             19
src/net/mod.rs                                      4              0             16
src/platform/macos/mod.rs                           2              0             14
src/platform/windows/wstr.rs                        0              0              5
src/win/mod.rs                                      0              0              3
-----------------------------------------------------------------------------------
SUM:                                             2440            365          20150
-----------------------------------------------------------------------------------&lt;/code&gt;
    &lt;head rend="h2"&gt;Takeaways&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;One human using one agent seems far more effective than one human using thousands of agents&lt;/item&gt;
      &lt;item&gt;One agent can work on a single codebase for hours, making real progress on ambitious projects&lt;/item&gt;
      &lt;item&gt;This could probably scale to multiple humans too, each equipped with their own agent, imagine what we could achieve!&lt;/item&gt;
      &lt;item&gt;Sometimes slower is faster and also better&lt;/item&gt;
      &lt;item&gt;The human who drives the agent might matter more than how the agents work and are set up, the judge is still out on this one&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If one person with one agent can produce equal or better results than "hundreds of agents for weeks", then the answer to the question: "Can we scale autonomous coding by throwing more agents at a problem?", probably has a more pessimistic answer than some expected.&lt;/p&gt;
    &lt;head&gt;Versions&lt;/head&gt;
    &lt;head&gt;2026-01-27 &lt;code&gt;7916ba2&lt;/code&gt; I'm apparently very bad at spelling, luckily :set spell exists&lt;/head&gt;
    &lt;code&gt;@@ -8 +8 @@ date: 2026-01-27

  Just for the fun of it, I thought I'd embark on a -week long
+week-long

   quest to generate millions of tokens and millions +of

   lines of source code to create one basic browser that can render HTML and CSS (no JS tho), and hopefully I could use this to receive even more VC investments.@@ -10 +10 @@ Just for the fun of it, I thought I'd embark on a week long quest to generate mi

  But then I remembered that I have something even better: a human brain! It is usually better than any machine at coordinating and thinking through things, so -lets
+let's

   see if we can hack something together, one human brain and one LLM agent brain!@@ -14 +14 @@ But then I remembered that I have something even better: a human brain! It is us

  The above might look like a simple .webm video, but it's actually a highly sophisticated and advanced browser that was super hard to build, encoded as pixels in a video file! -Wowzsers.
+Wowzers.
@@ -28 +28 @@ For extra fun when building this, I set these requirements for myself and the ag

  So with these things in mind, I set out on the journal to build a browser "from scratch". I started with something really based, being able to just render "Hello World". Then to be able to render some nested tags. Added the ability of taking screenshots so the agent could use that. Added specifications for HTML/CSS (which I think the agent never used :| ), and tried to nail down the -requrements
+requirements

   for the agent to use. Also started doing "regression" or "E2E" tests with the screenshotting feature, so we could compare to some baseline images and so on. Added the ability to click on links-to

   just for the fun of it.@@ -30 +30 @@ So with these things in mind, I set out on the journal to build a browser "from

  After about a day together with Codex, I had something that could via X11 and cURL, fetch and render websites when run, and the Cargo.lock is empty. -It's
+It

   was about 7500 lines long in total at that point, split across files with all of them under 1000 lines long (which was a stated requirement, so not a surprise).@@ -34 +34 @@ After about a day together with Codex, I had something that could via X11 and cU

  Second day I got -annoying
+annoyed

   by the tests spawning windows while I was doing other stuff, so added a --headless flag too. Did some fixes for resizing the window, various -compability
+compatibility

   fixes, some performance issues and improved the font/text rendering a bunch. Workflow was basically to pick a website, share a screenshot of the website without JavaScript, ask -codex
+Codex

   to replicate it following our instructions. Most of the time was the agent doing work by itself, and me checking in when it notifies me it was done.@@ -38 +38 @@ Second day I got annoying by the tests spawning windows while I was doing other

  Third day we made large changes, lots of new features and a bunch of new features supported. More regression tests, fixing performance issues, fixing crashes and -what not.
+whatnot.

   Also added scrolling because this is a mother fucking browser, it has to be able to scroll. Added some debug logs too because that'll look cool in the demonstration video above, and also added support for the back button because it was annoying to start from scratch if I clicked the wrong link while testing.@@ -46 +46 @@ Then the fourth day (whaaaat?) was basically polish, fixing CI for all three pla

  And here it is, in all -it's
+its

   glory, made in ~20K lines of code and under 72 hours of total elapsed time from first commit to last:@@ -51,0 +52 @@ And here it is, in all it's glory, made in ~20K lines of code and under 72 hours
+You can clone the repository, build it and try it out for yourself. It's not great, I wouldn't even say it's good, but it works, and demonstrates that one person with one agent can build a browser from scratch.
@@ -53,3 +54 @@ And here it is, in all it's glory, made in ~20K lines of code and under 72 hours
-You can clone the repository, build it and try it out for yourself. It's not great, I wouldn't even say it's good, but it works, and demonstrates that one person with one agent, can build a browser from scratch.

  This is what the "lines of code" count ended up being after all was said and done, including support +for

   three OSes:@@ -151 +150 @@ SUM:                                             2440            365          20

  - This could probably scale to multiple humans too, each -equiped
+equipped

   with their own agent, imagine what we could achieve!@@ -153 +152 @@ SUM:                                             2440            365          20

  - The human who drives the agent might matter more than how the agents work and are -setup,
+set up,

   the judge is still out on this one@@ -155 +154 @@ SUM:                                             2440            365          20
  If one person with one agent can produce equal or better results than "hundreds of agents for weeks", then the answer to the question: "Can we scale autonomous coding by throwing more agents at a problem?", probably has a more pessimistic answer than some expected.&lt;/code&gt;
    &lt;head&gt;2026-01-27 &lt;code&gt;b819707&lt;/code&gt; Touchups + headers&lt;/head&gt;
    &lt;code&gt;@@ -15,0 +16,2 @@ The above might look like a simple .webm video, but it's actually a highly sophi
+## Day 1 - Starting out
@@ -29,0 +32,2 @@ After about a day together with Codex, I had something that could via X11 and cU
+## Day 2 - Moving On
@@ -32 +36,3 @@ Second day I got annoying by the tests spawning windows while I was doing other
+## Day 3 - Polish &amp;amp; Cross-platform (+ day 4)

  Third day we made large changes, lots of new features and a bunch of new features supported. More regression tests, fixing performance issues, fixing crashes and what not. Also added scrolling because this is a mother fucking browser, it has to be able to scroll. Added some debug logs too because that'll look cool in the demonstration video -below,
+above,

   and also added support for the back -button.
+button because it was annoying to start from scratch if I clicked the wrong link while testing.
@@ -34 +40 @@ Third day we made large changes, lots of new features and a bunch of new feature

  At the end of the third day we also added +starting

   support for -macOS finally,
+macOS,

   and managed to get a window to open, and the tests to pass. Seems to work OK :) Once we had that working, we also added Windows support, basically the same process, just another platform after all.@@ -36 +42 @@ At the end of the third day we also added support for macOS finally, and managed

  Then the fourth day (whaaaat?) was basically polish, fixing CI for all three platforms, making it pass and finally cutting a release based on what got built in CI. +Still all within 72 hours (3 days * 24 hours, which obviously this is how you count days).&lt;/code&gt;
    &lt;head&gt;2026-01-27 &lt;code&gt;bc26dcb&lt;/code&gt; Add blogpost + video about "one agent one browser"&lt;/head&gt;
    &lt;code&gt;@@ -0,0 +1,149 @@
+---
+title: One Human + One Agent = One Browser From Scratch
+date: 2026-01-27
+---
+
+# One Human + One Agent = One Browser From Scratch
+
+Just for the fun of it, I thought I'd embark on a week long quest to generate millions of tokens and millions lines of source code to create one basic browser that can render HTML and CSS (no JS tho), and hopefully I could use this to receive even more VC investments.
+
+But then I remembered that I have something even better: a human brain! It is usually better than any machine at coordinating and thinking through things, so lets see if we can hack something together, one human brain and one LLM agent brain!
+
+![Demonstration of one-agent-one-browser running with a bunch of different websites on Linux/X11](/content/one-human-one-agent-one-browser.webm)
+
+The above might look like a simple .webm video, but it's actually a highly sophisticated and advanced browser that was super hard to build, encoded as pixels in a video file! Wowzsers.
+
+For extra fun when building this, I set these requirements for myself and the agent:
+
+- I have three days to build it
+- Not a single 3rd party Rust library/dependency allowed
+- Allowed to use anything (commonly) provided out of the box on the OS it runs on
+- Should run on Windows, macOS and common Linux distributions
+- Should be able to render some websites, most importantly, my own blog and Hacker News, should be easy right?
+- The codebase can always compile and be built
+- The codebase should be readable by a human, although code quality isn't the top concern
+
+So with these things in mind, I set out on the journal to build a browser "from scratch". I started with something really based, being able to just render "Hello World". Then to be able to render some nested tags. Added the ability of taking screenshots so the agent could use that. Added specifications for HTML/CSS (which I think the agent never used :| ), and tried to nail down the requrements for the agent to use. Also started doing "regression" or "E2E" tests with the screenshotting feature, so we could compare to some baseline images and so on. Added the ability to click on links to just for the fun of it.
+
+After about a day together with Codex, I had something that could via X11 and cURL, fetch and render websites when run, and the Cargo.lock is empty. It's was about 7500 lines long in total at that point, split across files with all of them under 1000 lines long (which was a stated requirement, so not a surprise).
+
+Second day I got annoying by the tests spawning windows while I was doing other stuff, so added a --headless flag too. Did some fixes for resizing the window, various compability fixes, some performance issues and improved the font/text rendering a bunch.  Workflow was basically to pick a website, share a screenshot of the website without JavaScript, ask codex to replicate it following our instructions. Most of the time was the agent doing work by itself, and me checking in when it notifies me it was done.
+
+Third day we made large changes, lots of new features and a bunch of new features supported. More regression tests, fixing performance issues, fixing crashes and what not. Also added scrolling because this is a mother fucking browser, it has to be able to scroll. Added some debug logs too because that'll look cool in the demonstration video below, and also added support for the back button.
+
+At the end of the third day we also added support for macOS finally, and managed to get a window to open, and the tests to pass. Seems to work OK :) Once we had that working, we also added Windows support, basically the same process, just another platform after all.
+
+Then the fourth day (whaaaat?) was basically polish, fixing CI for all three platforms, making it pass and finally cutting a release based on what got built in CI.
+
+## The results after ~3 days (~70 hours)
+
+And here it is, in all it's glory, made in ~20K lines of code and under 72 hours of total elapsed time from first commit to last:
+
+[![Screenshot of one-agent-one-browser running on X11](/content/one-agent-one-browser-hn.png)](https://github.com/embedding-shapes/one-agent-one-browser)
+
+&amp;gt; You could try compiling it yourself (zero Rust dependencies, so it's really fast :) ), or you can find binaries built on CI here:&amp;lt;br/&amp;gt;&amp;lt;small&amp;gt;[https://github.com/embedding-shapes/one-agent-one-browser/releases](https://github.com/embedding-shapes/one-agent-one-browser/releases)&amp;lt;/small&amp;gt;
+
+
+You can clone the repository, build it and try it out for yourself. It's not great, I wouldn't even say it's good, but it works, and demonstrates that one person with one agent, can build a browser from scratch.
+
+This is what the "lines of code" count ended up being after all was said and done, including support three OSes:
+
+```shell
+$ git rev-parse HEAD
+e2556016a5aa504ecafd5577c1366854ffd0e280
+
+$ cloc src --by-file
+      72 text files.
+      72 unique files.
+       0 files ignored.
+
+github.com/AlDanial/cloc v 2.06  T=0.06 s (1172.5 files/s, 373824.0 lines/s)
+-----------------------------------------------------------------------------------
+File                                            blank        comment           code
+-----------------------------------------------------------------------------------
+src/layout/flex.rs                                 96              0            994
+src/layout/inline.rs                               85              0            933
+src/layout/mod.rs                                  82              0            910
+src/browser.rs                                     78              0            867
+src/platform/macos/painter.rs                      96              0            765
+src/platform/x11/cairo.rs                          77              0            713
+src/platform/windows/painter.rs                    88              0            689
+src/bin/render-test.rs                             87              0            666
+src/style/builder.rs                               83              0            663
+src/platform/windows/d2d.rs                        53              0            595
+src/platform/windows/windowed.rs                   72              0            591
+src/style/declarations.rs                          18              0            547
+src/image.rs                                       81              0            533
+src/platform/macos/windowed.rs                     80              2            519
+src/net/winhttp.rs                                 61              2            500
+src/platform/x11/mod.rs                            56              2            487
+src/css.rs                                        103            346            423
+src/html.rs                                        58              0            413
+src/platform/x11/painter.rs                        48              0            407
+src/platform/x11/scale.rs                          57              3            346
+src/layout/table.rs                                39              1            340
+src/platform/x11/xft.rs                            35              0            338
+src/style/parse.rs                                 34              0            311
+src/win/wic.rs                                     39              8            305
+src/style/mod.rs                                   26              0            292
+src/style/computer.rs                              35              0            279
+src/platform/x11/xlib.rs                           32              0            278
+src/layout/floats.rs                               31              0            265
+src/resources.rs                                   36              0            238
+src/css_media.rs                                   36              1            232
+src/debug.rs                                       32              0            227
+src/platform/windows/dwrite.rs                     20              0            222
+src/render.rs                                      18              0            196
+src/style/custom_properties.rs                     34              0            186
+src/platform/windows/scale.rs                      28              0            184
+src/url.rs                                         32              0            173
+src/layout/helpers.rs                              12              0            172
+src/net/curl.rs                                    31              0            171
+src/platform/macos/svg.rs                          35              0            171
+src/browser/url_loader.rs                          17              0            166
+src/platform/windows/gdi.rs                        17              0            165
+src/platform/windows/scaled.rs                     16              0            159
+src/platform/macos/scaled.rs                       16              0            158
+src/layout/svg_xml.rs                               9              0            152
+src/win/com.rs                                     26              0            152
+src/png.rs                                         27              0            146
+src/layout/replaced.rs                             15              0            131
+src/net/pool.rs                                    18              0            129
+src/platform/macos/scale.rs                        17              0            124
+src/style/selectors.rs                             18              0            123
+src/style/length.rs                                17              0            121
+src/cli.rs                                         15              0            112
+src/platform/windows/headless.rs                   20              0            112
+src/platform/macos/headless.rs                     19              0            109
+src/bin/fetch-resource.rs                          14              0            101
+src/geom.rs                                        10              0            101
+src/browser/render_helpers.rs                      11              0            100
+src/dom.rs                                         11              0            100
+src/style/background.rs                            15              0            100
+src/layout/tests.rs                                 7              0             85
+src/platform/windows/d3d11.rs                      14              0             83
+src/win/stream.rs                                  10              0             63
+src/platform/windows/svg.rs                        13              0             54
+src/main.rs                                         4              0             33
+src/platform/mod.rs                                 6              0             28
+src/app.rs                                          5              0             25
+src/lib.rs                                          1              0             20
+src/platform/windows/mod.rs                         2              0             19
+src/net/mod.rs                                      4              0             16
+src/platform/macos/mod.rs                           2              0             14
+src/platform/windows/wstr.rs                        0              0              5
+src/win/mod.rs                                      0              0              3
+-----------------------------------------------------------------------------------
+SUM:                                             2440            365          20150
+-----------------------------------------------------------------------------------
+```
+
+## Takeaways
+
+- One human using one agent seems far more effective than one human using thousands of agents
+- One agent can work on a single codebase for hours, making real progress on ambitious projects
+- This could probably scale to multiple humans too, each equiped with their own agent, imagine what we could achieve!
+- Sometimes slower is faster and also better
+- The human who drives the agent might matter more than how the agents work and are setup, the judge is still out on this one
+
+If one person with one agent can produce equal or better results than "hundreds of agents for weeks", then the answer to the question: "Can we scale autonomous coding by throwing more agents at a problem?", probably has a more pessimistic answer than some expected. &lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46779522</guid><pubDate>Tue, 27 Jan 2026 13:13:56 +0000</pubDate></item><item><title>Xfwl4 – The Roadmap for a Xfce Wayland Compositor</title><link>https://alexxcons.github.io/blogpost_15.html</link><description>&lt;doc fingerprint="9f1261d108f93af0"&gt;
  &lt;main&gt;
    &lt;p&gt;We, the Xfce team are excited to share some great news!&lt;/p&gt;
    &lt;p&gt;After careful consideration, we’ve decided on a meaningful way to use the generous donations from our community: funding longtime Xfce core developer Brian Tarricone to create xfwl4, a brand-new Wayland compositor for Xfce.&lt;/p&gt;
    &lt;p&gt;This initiative will utilize a significant portion of the project’s donated funds, but we believe it’s an important investment in Xfce’s future.&lt;/p&gt;
    &lt;p&gt;The goal is, that xfwl4 will offer the same functionality and behavior as xfwm4 does, or as much as possible considering the differences between X11 and Wayland. Using xfwl4 should feel just like using xfwm4 on X11. We even plan to reuse the existing xfwm4 configuration dialogs and xfconf settings to ensure a seamless transition.&lt;/p&gt;
    &lt;p&gt;Xfwl4 will not be based on the existing xfwm4 code. Instead, it will be written from scratch in rust, using smithay building blocks.&lt;/p&gt;
    &lt;p&gt;The first attempt at creating an Xfce Wayland compositor involved modifying the existing xfwm4 code to support both X11 and Wayland in parallel. However, this approach turned out to be the wrong path forward for several reasons:&lt;/p&gt;
    &lt;p&gt;Once the decision to write a compositor from scratch was done, the next major question was: Which Wayland support library to use as a base? In order to find an answer on that question Brian evaluated wlroots and smithay. The decision to use smithay as a base was done for the following reasons:&lt;/p&gt;
    &lt;p&gt;Besides getting feature parity with xfwm4, the xfwl4 project scope includes as well some other related tasks:&lt;/p&gt;
    &lt;p&gt;Brian has already started work on the project, so stay tuned for the first development release of xfwl4, which we hope to share around mid-year.&lt;/p&gt;
    &lt;p&gt;If you’re interested in the detailed reasoning behind the project or want to explore all the technical details, check out the issues and the work in progress source code.&lt;/p&gt;
    &lt;p&gt;For any questions related to xfwl4, please visit our Matrix channel #xfce-dev.&lt;/p&gt;
    &lt;p&gt;We’d like to extend our heartfelt thanks to our generous supporters on Open Collective US and Open Collective EU for making this project possible!&lt;/p&gt;
    &lt;p&gt;Best regards,&lt;/p&gt;
    &lt;p&gt;The Xfce development team&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46779645</guid><pubDate>Tue, 27 Jan 2026 13:25:53 +0000</pubDate></item><item><title>Amazon closing its Fresh and Go stores</title><link>https://finance.yahoo.com/news/amazon-closing-fresh-grocery-convenience-150437789.html</link><description>&lt;doc fingerprint="284bb94a339ea4ec"&gt;
  &lt;main&gt;
    &lt;p&gt;(Bloomberg) -- Amazon.com Inc. is shuttering its Amazon-branded grocery stores and automated grab-and-go markets, eliminating two centerpieces of its push into physical retail.&lt;/p&gt;
    &lt;p&gt;Amazon Fresh and Amazon Go stores will close, the company said in a blog post on Tuesday, with some locations converted into Whole Foods Market stores.&lt;/p&gt;
    &lt;p&gt;Most Read from Bloomberg&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;NYC’s Mamdani Crushes Snow Day Hopes, But He Yearns for It Too&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Boston’s 18-Inch Snow Deluge to Make Travel Hard to ‘Impossible’&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;London’s Vanishing Office Buildings Are Being Replaced by Hotels&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;LA Council Sends Mansion Tax Changes Back, Dimming Prospects&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;“While we’ve seen encouraging signals in our Amazon-branded physical grocery stores, we haven’t yet created a truly distinctive customer experience with the right economic model needed for large-scale expansion,” Amazon said.&lt;/p&gt;
    &lt;p&gt;The moves mark the e-commerce giant’s latest retreat from its brick-and-mortar retail efforts. Since the surprise opening of a physical bookstore in 2015, Amazon has tried and failed to establish a foothold under its own brand in categories from groceries to fashion, often with technological flourishes such as digital price tags or novel checkout methods.&lt;/p&gt;
    &lt;p&gt;Over the last few years, the company has backed away from the bookstores, an eclectic kitchen goods, toys and electronics store called Amazon 4-Star, electronics kiosks in shopping malls and a short-lived clothing storefront.&lt;/p&gt;
    &lt;p&gt;Amazon on Tuesday said it would continue to invest in groceries sold both online and offline. That includes an ongoing effort to stock more produce and perishables in Amazon’s same-day delivery warehouses and at more Whole Foods stores, which comprise more than 550 locations.&lt;/p&gt;
    &lt;p&gt;Amazon currently operates 14 Go stores, which use cameras to track what people grab off the shelves, and 58 Amazon Fresh grocery stores, according to its website. The last day of operation for most of those stores will be Sunday, a spokesperson said, except in California, where they’ll stay open longer to comply with state requirements for advance notice of closures.&lt;/p&gt;
    &lt;p&gt;The moves mean thousands of hourly workers in the stores will lose their jobs. Cuts to Amazon’s corporate workforce will likely involve dozens of people, according to a person familiar with the matter, who asked for anonymity because the information was confidential. The company says it will work to help employees find other jobs at Amazon, including at Whole Foods stores or in its logistics network. Amazon’s corporate ranks were already bracing for a round of layoffs expected as soon as this week.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46781444</guid><pubDate>Tue, 27 Jan 2026 15:41:14 +0000</pubDate></item><item><title>430k-year-old well-preserved wooden tools are the oldest ever found</title><link>https://www.nytimes.com/2026/01/26/science/archaeology-neanderthals-tools.html</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46781530</guid><pubDate>Tue, 27 Jan 2026 15:46:29 +0000</pubDate></item><item><title>Artie (YC S23) Is Hiring a Founding Recruiter</title><link>https://www.ycombinator.com/companies/artie/jobs/MX163y2-founding-recruiter</link><description>&lt;doc fingerprint="a189c0db27d96528"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;head rend="h3"&gt;About Artie&lt;/head&gt;
      &lt;p&gt;Artie is a real-time streaming platform that moves production data across systems in real-time, with zero maintenance. We make high-volume data replication simple, reliable, and scalable for engineering teams.&lt;/p&gt;
      &lt;p&gt;Our platform powers mission-critical use cases including fraud and risk monitoring, inventory visibility, customer-facing analytics, and AI workloads. Artie is built for engineers who care about performance, reliability, and operational simplicity — and we’re growing fast.&lt;/p&gt;
      &lt;p&gt;We’re trusted by teams like ClickUp, Substack, and Alloy, and backed by top-tier investors including Y Combinator, General Catalyst, Pathlight Ventures, and the founders of Dropbox and Mode.&lt;/p&gt;
      &lt;p&gt;We’re hiring our first in-house recruiter to own and build talent at Artie. This role is your chance to build our team from first principles.&lt;/p&gt;
      &lt;head rend="h3"&gt;About the Role&lt;/head&gt;
      &lt;p&gt;This is not a coordination role and not a “run the ATS” job.&lt;/p&gt;
      &lt;p&gt;You will be responsible for end-to-end recruiting across the company, with a focus on Engineering, Product, Operations, and Design (EPOD). You’ll partner directly with founders and hiring managers, define what “great” looks like for each role, and build the recruiting foundation we scale on top of.&lt;/p&gt;
      &lt;p&gt;You will also be the internal owner for our external recruiting partners — setting strategy, calibrating quality, and ensuring agencies complement our in-house motion.&lt;/p&gt;
      &lt;p&gt;If you view recruiting as a mix of sales, systems thinking, storytelling, and judgment, this role is for you.&lt;/p&gt;
      &lt;p&gt;This is a high-trust, high-ownership role, and you’ll have real influence over the shape, culture, and trajectory of the company.&lt;/p&gt;
      &lt;head rend="h3"&gt;What you’ll do&lt;/head&gt;
      &lt;p&gt;Own full-cycle recruiting across the company&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Run end-to-end hiring for Engineering, Product, Operations, and Design roles, and support other roles in GTM as needed&lt;/item&gt;
        &lt;item&gt;Partner with founders and hiring managers to: &lt;list rend="ul"&gt;&lt;item&gt;Define role scope, seniority, and success criteria&lt;/item&gt;&lt;item&gt;Calibrate on candidate quality and tradeoffs&lt;/item&gt;&lt;item&gt;Continuously refine interview loops and hiring signals&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;item&gt;Manage candidates through sourcing, screening, interviews, offers, and closing&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Be the engine for technical hiring&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Proactively source and engage senior technical talent (engineers, product, design) in a competitive market&lt;/item&gt;
        &lt;item&gt;Run outbound recruiting with creativity and rigor — LinkedIn, referrals, networks, events, cold outreach, and non-obvious channels&lt;/item&gt;
        &lt;item&gt;Confidently engage technical candidates and speak credibly about: &lt;list rend="ul"&gt;&lt;item&gt;Engineering culture and technical challenges&lt;/item&gt;&lt;item&gt;Artie’s product, architecture, and roadmap (with support from founders)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Sell Artie to candidates&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Craft and deliver a compelling narrative around: &lt;list rend="ul"&gt;&lt;item&gt;Why Artie exists&lt;/item&gt;&lt;item&gt;Why this team is special&lt;/item&gt;&lt;item&gt;Why this is a rare career opportunity&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;item&gt;Own candidate experience end-to-end - build a world-class recruiting process that delights candidates&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Build recruiting infrastructure from scratch&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Own and evolve our recruiting process, tools, and operating rhythm&lt;/item&gt;
        &lt;item&gt;Manage and improve our ATS and sourcing tools&lt;/item&gt;
        &lt;item&gt;Track and report on hiring progress, pipeline health, and bottlenecks&lt;/item&gt;
        &lt;item&gt;Continuously improve speed, quality, and candidate experience as we scale&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Manage external recruiting partners&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Act as the primary point of contact for agencies we work with&lt;/item&gt;
        &lt;item&gt;Set expectations, role briefs, and quality bars&lt;/item&gt;
        &lt;item&gt;Ensure agencies augment our hiring motion rather than define it&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;What we’re looking for&lt;/head&gt;
      &lt;p&gt;Recruiting mastery in early-stage environments&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;4+ years of recruiting experience, with meaningful exposure to: &lt;list rend="ul"&gt;&lt;item&gt;Technical recruiting (engineering, product, design)&lt;/item&gt;&lt;item&gt;Early-stage startups (Series A–C preferred)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;item&gt;Experience owning full-cycle recruiting without large support teams&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Strong technical intuition&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;You don’t need to code, but you can recruit engineers&lt;/item&gt;
        &lt;item&gt;Able to build credibility quickly with senior technical candidates&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Sales mindset&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;You view recruiting as a sales and persuasion problem&lt;/item&gt;
        &lt;item&gt;Comfortable with outbound, rejection, and ambiguity&lt;/item&gt;
        &lt;item&gt;Strong written and verbal communicator&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Extreme ownership&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;You take responsibility for outcomes, not just inputs&lt;/item&gt;
        &lt;item&gt;You proactively identify problems and fix them&lt;/item&gt;
        &lt;item&gt;You care deeply about quality and long-term team health&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Taste, judgment, and integrity&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;You have a strong internal bar for talent&lt;/item&gt;
        &lt;item&gt;You know when to push, when to pause, and when to say no&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Logistics&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Willing to work in-person, 5 days/week at our SF office&lt;/item&gt;
        &lt;item&gt;Comfortable operating with speed, ambiguity, and very little structure&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;What you’ll get&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Foundational impact: You will shape the team, culture, and hiring bar at Artie&lt;/item&gt;
        &lt;item&gt;Direct founder partnership: Work closely with the CEO/CTO and leadership team&lt;/item&gt;
        &lt;item&gt;End-to-end ownership: Strategy, execution, iteration — all yours&lt;/item&gt;
        &lt;item&gt;Growth path: Opportunity to grow into a Head of Talent / recruiting leader as we scale&lt;/item&gt;
        &lt;item&gt;High trust environment: You’ll be treated as a core operator, not a support function&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;Compensation &amp;amp; Benefits&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Competitive salary (commensurate with experience) - our philosophy is P75-90 for base salary and P90+ for equity compared to benchmarks&lt;/item&gt;
        &lt;item&gt;Healthcare, 401(k) matching, unlimited PTO&lt;/item&gt;
        &lt;item&gt;Lunch &amp;amp; dinner provided&lt;/item&gt;
      &lt;/list&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46782763</guid><pubDate>Tue, 27 Jan 2026 17:01:37 +0000</pubDate></item><item><title>SoundCloud Data Breach Now on HaveIBeenPwned</title><link>https://haveibeenpwned.com/Breach/SoundCloud</link><description>&lt;doc fingerprint="8d73685d6bf0f787"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;SoundCloud Data Breach&lt;/head&gt;&lt;head rend="h2"&gt;What Happened&lt;/head&gt;&lt;p&gt;In December 2025, SoundCloud announced it had discovered unauthorised activity on its platform. The incident allowed an attacker to map publicly available SoundCloud profile data to email addresses for approximately 20% of its users. The impacted data included 30M unique email addresses, names, usernames, avatars, follower and following counts and, in some cases, the user’s country. The attackers later attempted to extort SoundCloud before publicly releasing the data the following month.&lt;/p&gt;&lt;head rend="h2"&gt;Compromised Data&lt;/head&gt;&lt;head rend="h2"&gt;Recommended Actions&lt;/head&gt;&lt;p&gt;Use a password manager to generate and store strong, unique passwords for all your accounts. 1Password helps protect your data with industry-leading security.&lt;/p&gt;Try 1Password&lt;p&gt;Get Aura for identity theft and credit protection. Keep your assets safe with fast fraud alerts, instant credit lock, and $1,000,000 identity theft insurance. Speak to a U.S. based fraud specialist 24/7.&lt;/p&gt;Try Aura&lt;p&gt;Get Guardio for real-time protection after a breach. Guardio blocks AI-generated scam sites, fake login pages, and malicious pages designed to exploit leaked information. Built by cybersecurity specialists who track new threats 24/7, Guardio gives you immediate, expert-level protection plus clear steps to help you secure your accounts instantly.&lt;/p&gt;Try Guardio&lt;head rend="h3"&gt;Breach Overview&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;Affected Accounts:&lt;/p&gt;&lt;p&gt;29.8 million&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Breach Occurred:&lt;/p&gt;&lt;p&gt;December 2025&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Added to HIBP:&lt;/p&gt;&lt;p&gt;27 Jan 2026&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Recommended Actions&lt;/head&gt;&lt;head rend="h5"&gt;Change Your Password&lt;/head&gt;&lt;p&gt;If you haven’t already changed the password affected by this breach, do so immediately on every account where it was used.&lt;/p&gt;&lt;head rend="h5"&gt;Enable Two-Factor Authentication&lt;/head&gt;&lt;p&gt;Wherever 2FA is supported, add an extra layer of security to your account.&lt;/p&gt;&lt;p&gt;Get Guardio for real-time protection after a breach. Guardio blocks AI-generated scam sites, fake login pages, and malicious pages designed to exploit leaked information. Built by cybersecurity specialists who track new threats 24/7, Guardio gives you immediate, expert-level protection plus clear steps to help you secure your accounts instantly.&lt;/p&gt;Try Guardio&lt;p&gt;Use a password manager to generate and store strong, unique passwords for all your accounts. 1Password helps protect your data with industry-leading security.&lt;/p&gt;Try 1Password&lt;p&gt;Get Aura for identity theft and credit protection. Keep your assets safe with fast fraud alerts, instant credit lock, and $1,000,000 identity theft insurance. Speak to a U.S. based fraud specialist 24/7.&lt;/p&gt;Try Aura&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46782930</guid><pubDate>Tue, 27 Jan 2026 17:11:39 +0000</pubDate></item><item><title>AI2: Open Coding Agents</title><link>https://allenai.org/blog/open-coding-agents</link><description>&lt;doc fingerprint="2d78817f1012d04a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Open Coding Agents: Fast, accessible coding agents that adapt to any repo&lt;/head&gt;
    &lt;p&gt;January 27, 2026&lt;/p&gt;
    &lt;p&gt;Ai2&lt;/p&gt;
    &lt;p&gt;Over the past year, coding agents have transformed how developers write, test, and maintain software. These systems can debug, refactor, and even submit pull requests—fundamentally changing what software development looks like. Yet despite this progress, most coding agents share the same constraints: they're closed, expensive to train, and difficult to study or adapt to private codebases.&lt;/p&gt;
    &lt;p&gt;Ai2 Open Coding Agents change that. Today we’re releasing not just a collection of strong open coding models, but a training method that makes building your own coding agent for any codebase – for example, your personal codebase or an internal codebase at your organization – remarkably accessible for tasks including code generation, code review, debugging, maintenance, and code explanation.&lt;/p&gt;
    &lt;p&gt;Closed models haven't seen your internal code, so they don't know it—custom data pipelines, internal APIs, specific org conventions, and so on. Training on your private data teaches them, but generating synthetic training data from private codebases that works for agents has been challenging and cost-prohibitive. Our method makes it easy—reproducing the performance of the previously best open-source model costs ~$400 of compute, or up to $12,000 for performance that rivals the best industry models of the same size. This puts the full recipe within reach for labs and small teams.&lt;/p&gt;
    &lt;p&gt;Resource constraints drove us to maximize efficiency at every stage, from data quality to inference costs to model selection. The result: we match SWE-smith, a synthetic data method, at 57× lower cost and SkyRL, an open-source reinforcement learning (RL) system, at 26× lower cost.&lt;/p&gt;
    &lt;p&gt;The first release in our Open Coding Agents family is SERA (Soft-verified Efficient Repository Agents). The strongest – SERA-32B – solves 54.2% of SWE-Bench Verified problems, surpassing prior open-source state-of-the-art coding models of comparable sizes and context lengths while requiring only 40 GPU days (or fewer) to train on a cluster of 2 NVIDIA Hopper GPUs or NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs. SERA models are optimized and compatible with Claude Code out of the box. With our fine-tuning method, you can specialize them to your own codebase including your full engineering stack and conventions quickly and at low cost.&lt;/p&gt;
    &lt;p&gt;We collaborated with NVIDIA to optimize SERA inference for their accelerated infrastructure, ensuring researchers and developers can get the most out of these models in production environments. Early benchmarks are promising: running in BF16 precision on 4xH100 GPUs, SERA achieves approximately 1,950 peak output tokens per second with a 16k context window. At FP8 precision, SERA reaches 3,700 peak output tokens per second—a higher throughput at almost negligible accuracy drop. On next-generation Blackwell 4xB200 systems running in NVFP4, SERA scales further to around 8,600 peak output tokens per second.&lt;/p&gt;
    &lt;p&gt;Every component of this release is open – models, Claude Code integration, and training recipes – and can be launched with a single line of code, making it easy to use even for those without LLM training experience. We're also releasing state-of-the-art training data so researchers can inspect what worked and push it further, and conduct deep science while avoiding the many stumbling blocks, dead ends, and other roadblocks typical of coding agents.&lt;/p&gt;
    &lt;p&gt;One result we're especially excited about: SERA uniquely enables adapting to private datasets like internal codebases, and we see evidence that a smaller, open model can replicate and possibly even exceed the performance of a more capable "teacher" coding agent in these setups. For example, SERA-32B can surpass its 110B parameter teacher (GLM-4.5-Air) on codebases like Django and Sympy after training on just 8,000 samples at a cost of $1,300.&lt;/p&gt;
    &lt;p&gt;Accessible open models can now inherit strong agentic behavior through a simple, reproducible pipeline—no large-scale RL infrastructure or engineering team required. Case in point, SERA was built largely by a single Ai2 researcher.&lt;/p&gt;
    &lt;head rend="h3"&gt;The challenge: specializing agents to your data&lt;/head&gt;
    &lt;p&gt;If you’re a small to mid-sized business or independent developer, you probably have code that works with customer data in ways no public model has ever seen. Training on that data would help, but generating agent-ready synthetic data from private codebases has been the hard part. The holy grail would be a method that yields state-of-the-art training data for any codebase, with minimal setup and clear evidence that the tuned model is actually learning agentic behavior versus fragile heuristics.&lt;/p&gt;
    &lt;p&gt;We tackle this challenge with our new post-training approach that achieves state-of-the-art open-source results on SWE-Bench at a fraction of the typical training costs. Two innovations make it both inexpensive and effective:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Soft-verified generation (SVG). Synthetic training data generation, which is key to training a strong coding agent, is usually done by generating pairs of code examples that have both incorrect and corrected code. From these examples, the coding agent can learn how to transform incorrect code into correct code by generating a patch with line-by-line code changes. Usually, these examples need to be carefully tested to ensure that they’re actually correct. In SVG, our main finding is that patches don’t need to be correct to be helpful for coding. Just like different code can lead to the same, correct solution, with SVG we generate synthetic training data by having patches that are only partially correct. This removes the need to thoroughly test for full correctness, which in turn alleviates the need for complex infrastructure for testing and costly generation of precise examples. We demonstrate that this soft-verified data scales exactly like "hard-verified" training data.&lt;/item&gt;
      &lt;item&gt;Scaling with a bug-type menu. To diversify data without becoming bottlenecked on finding real bugs, we draw from a taxonomy of 51 common bug patterns identified in prior analyses. For each function in a repository, we can generate multiple distinct bug-style prompts—so a repo with thousands of functions can yield tens of thousands of varied agentic trajectories at low cost.&lt;/item&gt;
      &lt;item&gt;High simulated workflow fidelity. A key finding is that high-quality synthetic training data should mirror the workflow of a developer rather than the precise details of correct code. This means correct coding data is less important than data that reflects how a developer works on a problem. Combined with SVG, this insight enables repository training: generating training data for any code repository, making it straightforward to scale synthetic data generation massively.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Together, these innovations mean that if you or your organization has a private codebase, you can use SERA to fine-tune a small model to strong performance on your data—easily and affordably. Instead of designing a complicated RL pipeline and test harness for every new task setting, you generate targeted synthetic data and run a straightforward supervised fine-tuning (SFT) job.&lt;/p&gt;
    &lt;head rend="h3"&gt;State-of-the-art performance, accessible hardware&lt;/head&gt;
    &lt;p&gt;Using SERA, we've developed a family of models ranging from 8B to 32B parameters, all built on Qwen3 and trained up to 32K context length with the help of various teacher models. We expect the same recipe to keep improving as we scale to larger backbones and context lengths, but the key point is that the current pipeline is already cheap and feasible for anyone to run, customize, and iterate on today—opening up wide access and endless possibilities for future research.&lt;/p&gt;
    &lt;p&gt;Our efficient technique enabled highly precise science. By keeping costs low, we could systematically disentangle the many factors that have made comparisons between agentic systems unreliable. This rigorous methodology drove rapid iteration, leading us from soft-verified generation to the full SERA approach.&lt;/p&gt;
    &lt;p&gt;When we align inference conditions for fair comparison, SERA performs competitively with leading open coding agents. At 32K context, SERA-32B achieves 49.5% ± 1.9% on SWE-Bench Verified, comparable to Devstral Small 2 (50.0% ± 1.3%) and GLM-4.5-Air (50.5% ± 1.3%). At 64K context, SERA-32B reaches 54.2% ± 1.4%—competitive with longer-context baselines.&lt;/p&gt;
    &lt;p&gt;Strong closed-weight coding agents like Devstral Small 2 are an important point of comparison. When we control for key variables, SERA-32B comes close: within ~0.5 points at 32K and ~4.9 points at 64K compared to Devstral Small 2 despite SERA being pure SFT and not trained beyond 32K tokens, both of which disadvantage longer-context evaluation.&lt;/p&gt;
    &lt;p&gt;We also explored how teacher strength affects results. GLM-4.6 yields our best numbers, but GLM-4.5-Air gets surprisingly close at lower cost. The gap between teachers becomes most meaningful in higher-compute regimes—suggesting that depending on your budget and target performance, a weaker (and cheaper) teacher can be the better overall choice, especially for early iterations.&lt;/p&gt;
    &lt;p&gt;To validate our synthetic data generation strategy, we tested repository-specific specialization on Django, SymPy, and Sphinx—the three largest repositories in SWE-Bench. Because these have actual test instances, we can quantify how well specialization works in practice. This serves as a proxy for the downstream use case we care most about: adapting to private codebases that may lack comprehensive tests or follow nonstandard structures.&lt;/p&gt;
    &lt;p&gt;The results are promising. Our specialized models – trained on 8,000 synthetic trajectories per repository – consistently match and often exceed the performance of the 100B+ parameter models we used as teachers. At 32K context, the specialized models achieve 52.23% on Django and 51.11% on SymPy, compared to GLM-4.5-Air's 51.20% and 48.89%. The gains are most pronounced on Django and SymPy, which together account for over 60% of all SWE-Bench problems.&lt;/p&gt;
    &lt;p&gt;These results highlight two crucial advantages of our method. First, specialization pays off: a 32B model fine-tuned to a specific codebase can match or surpass a 100B+ general-purpose teacher, delivering comparable performance at one-third the size with lower memory requirements, faster inference, and reduced operational costs. Second, simplicity scales: our SFT-only pipeline on an open base model is now competitive with heavily engineered, large-team efforts. Together, these findings lower the barrier to entry for researchers, make results easier to reproduce, and turn agentic coding progress into something the whole community can validate and build on.&lt;/p&gt;
    &lt;head rend="h3"&gt;Built for developers and researchers&lt;/head&gt;
    &lt;p&gt;Our release package includes everything needed to reproduce, test, and build on SERA—a lightweight deployment requiring just two lines of code to launch an inference server. We've also developed a setup script and inference optimizations that make SERA directly compatible with Claude Code.&lt;/p&gt;
    &lt;p&gt;A key difference from closed-weight systems is our commitment to openness and reproducibility:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We release models, code, all generated agent data, and a full recipe to generate your own data so anyone can reproduce our results or customize them to new domains.&lt;/item&gt;
      &lt;item&gt;Our training pipeline is intentionally simple—standard SFT on trajectories with no custom RL infrastructure needed.&lt;/item&gt;
      &lt;item&gt;The total cost to reproduce performance levels of the best previous open-source result only is roughly $400 on commodity cloud GPUs, more than 25 times cheaper than many existing approaches that require complex distributed setups and still fall short on performance.&lt;/item&gt;
      &lt;item&gt;The total cost to reproduce top open-weight models in industry, such as Devstral Small 2, is only $12,000.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We believe bringing the cost of replicating strong coding agents down to a few hundred dollars will unlock research that simply wasn't possible before. Instead of being limited to a handful of well-funded labs, agentic coding can become a widely accessible practice.&lt;/p&gt;
    &lt;p&gt;Whether you're running locally on your hardware, deploying in the cloud, or fine-tuning on your own codebase, SERA delivers practical agentic coding within reach of developers, researchers, and small teams alike.&lt;/p&gt;
    &lt;p&gt;Models | Tech Report | SERA CLI | CLI on PyPi&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46783017</guid><pubDate>Tue, 27 Jan 2026 17:17:54 +0000</pubDate></item><item><title>FBI is investigating Minnesota Signal chats tracking ICE</title><link>https://www.nbcnews.com/tech/internet/fbi-investigating-minnesota-signal-minneapolis-group-ice-patel-kash-rcna256041</link><description>&lt;doc fingerprint="72bcc8104f07b317"&gt;
  &lt;main&gt;
    &lt;p&gt;FBI Director Kash Patel said Monday that he had opened an investigation into the Signal group text chats that Minnesota residents are using to share information about federal immigration agents’ movements, launching a new front in the Trump administration’s conflict there with potential free speech implications.&lt;/p&gt;
    &lt;p&gt;Patel said in an interview with conservative podcaster Benny Johnson that he wanted to know whether any Minnesota residents had put federal agents “in harm’s way” with activities such as sharing agents’ license plate numbers and locations.&lt;/p&gt;
    &lt;p&gt;“You cannot create a scenario that illegally entraps and puts law enforcement in harm’s way,” he said in the interview, which was posted to YouTube.&lt;/p&gt;
    &lt;p&gt;The investigation quickly drew skepticism from free speech advocates who said the First Amendment protects members of the public who share legally obtained information, such as the names of federal agents or where they are conducting enforcement operations.&lt;/p&gt;
    &lt;p&gt;“There are legitimate reasons to share such information, including enabling members of the public to observe and document law enforcement activity and to hold officials accountable for misconduct,” Aaron Terr, director of public advocacy at the Foundation for Individual Rights and Expression, said in an email.&lt;/p&gt;
    &lt;p&gt;“Given this administration’s poor track record of distinguishing protected speech from criminal conduct, any investigation like this deserves very close scrutiny,” he said.&lt;/p&gt;
    &lt;p&gt;For months, digital tools have been at the center of how people have pushed back against immigration enforcement efforts in Minnesota and across the country. The administration’s opponents have used group text chats to track Immigration and Customs Enforcement operations, share photos of suspected ICE vehicles and raise awareness for neighbors. In June, administration officials criticized ICEBlock, an app designed to share information about ICE sightings. Apple removed the app from its app store in October, prompting a lawsuit from the app’s developer alleging the administration unlawfully pressured Apple to remove it.&lt;/p&gt;
    &lt;p&gt;In the past few days, the group text chats — especially those on the encrypted messaging app Signal — have drawn attention from right-wing media. On Saturday, Cam Higby, a conservative journalist based near Seattle, said in a thread on X that he had “infiltrated” Signal groups from around Minneapolis that he alleged were obstructing law enforcement. His thread, which got 20 million views, focused on how the groups share such information as the license plate numbers of suspected federal vehicles. NBC News has not verified Higby’s claims.&lt;/p&gt;
    &lt;p&gt;Patel said he got the idea for the investigation from Higby.&lt;/p&gt;
    &lt;p&gt;“As soon as Higby put that post out, I opened an investigation on it,” he said. “We immediately opened up that investigation, because that sort of Signal chat — being coordinated with individuals not just locally in Minnesota, but maybe even around the country — if that leads to a break in the federal statute or a violation of some law, then we are going to arrest people.”&lt;/p&gt;
    &lt;p&gt;The Signal Foundation, the nonprofit organization that operates the Signal app, did not immediately respond to a request for comment.&lt;/p&gt;
    &lt;p&gt;Signal, which is considered one of the most secure chat apps, is a go-to resource for people concerned about privacy. It is perhaps best known as the app Defense Secretary Pete Hegseth used to share sensitive military information last year in a group chat that accidentally included a journalist.&lt;/p&gt;
    &lt;p&gt;In the Twin Cities, Signal group chats have been a standard part of toolkits — along with walkie-talkies and whistles — used by activists, parents and neighborhood-watch members who have organized as volunteers to warn families about immigration enforcement activities by relaying real-time information, especially near schools. Patrol volunteers have said that, with more than 3,000 federal immigration agents in Minnesota, they are motivated by a desire to protect parents, children and school staff members who are not U.S. citizens.&lt;/p&gt;
    &lt;p&gt;Patel did not say which laws he thought Minnesota residents may have violated. An FBI spokesperson said the bureau had no further information to provide.&lt;/p&gt;
    &lt;p&gt;The announcement seemed likely to have implications for the First Amendment’s guarantee of free speech. Alex Abdo, litigation director at the Knight First Amendment Institute at Columbia University, said the First Amendment protects the right to record law enforcement officers as they carry out their official responsibilities.&lt;/p&gt;
    &lt;p&gt;“The ability of everyday citizens to hold government agents to account, by observing them and advocating for change, is what has distinguished the American experiment with democracy from authoritarian regimes around the world,” Abdo said in an email.&lt;/p&gt;
    &lt;p&gt;“Unless the FBI has evidence of a crime, and not just evidence of activity the Constitution protects, it should stand down,” he said.&lt;/p&gt;
    &lt;p&gt;Patel acknowledged in the interview with Johnson that an investigation into group text chats would raise free speech concerns and said the FBI would “balance” the rights guaranteed by the First and Second amendments with what he said were potential violations of federal law.&lt;/p&gt;
    &lt;p&gt;“Now, we will balance the First and Second amendment constantly, but we have to let the community know that we will not tolerate acts of violence and an escalation and a violation of the federal code,” he said. The Second Amendment could be at issue because Alex Pretti, the nurse shot and killed by a federal agent Saturday in Minneapolis, was permitted to carry a gun in public and had one with him.&lt;/p&gt;
    &lt;p&gt;Terr, of the Foundation for Individual Rights and Expression, said the government does not get to “balance” the First Amendment against its other interests.&lt;/p&gt;
    &lt;p&gt;“The Constitution takes precedence over any conflicting state or federal law, and over any official’s desire to suppress speech they dislike,” he said in his email.&lt;/p&gt;
    &lt;p&gt;He added: “There is a First Amendment exception for speech intended and likely to provoke imminent unlawful action, but that doesn’t apply to just any speech the government claims puts officials in harm’s way. By contrast, if individuals are threatening federal agents or conspiring to physically harm them, that is illegal. But conspiracy requires an agreement to commit a specific crime and a substantial step toward carrying it out.”&lt;/p&gt;
    &lt;p&gt;Patel also said the FBI had made “substantial progress” in an investigation into groups and people responsible for funding resistance to immigration enforcement. He alleged that the protests and neighborhood monitoring are “not happening organically” but did not immediately provide evidence.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46783254</guid><pubDate>Tue, 27 Jan 2026 17:32:05 +0000</pubDate></item><item><title>Show HN: LemonSlice – Upgrade your voice agents to real-time video</title><link>https://news.ycombinator.com/item?id=46783600</link><description>&lt;doc fingerprint="245aac532508febb"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hey HN, we're the co-founders of LemonSlice (try our HN playground here: &lt;/p&gt;https://lemonslice.com/hn&lt;p&gt;). We train interactive avatar video models. Our API lets you upload a photo and immediately jump into a FaceTime-style call with that character. Here's a demo: &lt;/p&gt;https://www.loom.com/share/941577113141418e80d2834c83a5a0a9&lt;p&gt;Chatbots are everywhere and voice AI has taken off, but we believe video avatars will be the most common form factor for conversational AI. Most people would rather watch something than read it. The problem is that generating video in real-time is hard, and overcoming the uncanny valley is even harder.&lt;/p&gt;&lt;p&gt;We haven’t broken the uncanny valley yet. Nobody has. But we’re getting close and our photorealistic avatars are currently best-in-class (judge for yourself: https://lemonslice.com/try/taylor). Plus, we're the only avatar model that can do animals and heavily stylized cartoons. Try it: https://lemonslice.com/try/alien. Warning! Talking to this little guy may improve your mood.&lt;/p&gt;&lt;p&gt;Today we're releasing our new model* - Lemon Slice 2, a 20B-parameter diffusion transformer that generates infinite-length video at 20fps on a single GPU - and opening up our API.&lt;/p&gt;&lt;p&gt;How did we get a video diffusion model to run in real-time? There was no single trick, just a lot of them stacked together. The first big change was making our model causal. Standard video diffusion models are bidirectional (they look at frames both before and after the current one), which means you can't stream.&lt;/p&gt;&lt;p&gt;From there it was about fitting everything on one GPU. We switched from full to sliding window attention, which killed our memory bottleneck. We distilled from 40 denoising steps down to just a few - quality degraded less than we feared, especially after using GAN-based distillation (though tuning that adversarial loss to avoid mode collapse was its own adventure).&lt;/p&gt;&lt;p&gt;And the rest was inference work: modifying RoPE from complex to real (this one was cool!), precision tuning, fusing kernels, a special rolling KV cache, lots of other caching, and more. We kept shaving off milliseconds wherever we could and eventually got to real-time.&lt;/p&gt;&lt;p&gt;We set up a guest playground for HN so you can create and talk to characters without logging in: https://lemonslice.com/hn. For those who want to build with our API (we have a new LiveKit integration that we’re pumped about!), grab a coupon code in the HN playground for your first Pro month free ($100 value). See the docs: https://lemonslice.com/docs. Pricing is usage-based at $0.12-0.20/min for video generation.&lt;/p&gt;&lt;p&gt;Looking forward to your feedback!&lt;/p&gt;&lt;p&gt;EDIT: Tell us what characters you want to see in the comments and we can make them for you to talk to (e.g. Max Headroom)&lt;/p&gt;&lt;p&gt;*We did a Show HN last year for our V1 model: https://news.ycombinator.com/item?id=43785044. It was technically impressive but so bad compared to what we have today.&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46783600</guid><pubDate>Tue, 27 Jan 2026 17:55:15 +0000</pubDate></item><item><title>Prism</title><link>https://openai.com/index/introducing-prism</link><description>&lt;doc fingerprint="ab5a723abbf162df"&gt;
  &lt;main&gt;
    &lt;p&gt;Science shapes nearly every part of daily life—from the medicines we rely on, to the energy that powers our homes, to the systems that keep us safe. But the pace of scientific progress is still constrained by how research is done day to day. While AI has advanced rapidly, much of the everyday work of science still relies on tools that haven’t fundamentally changed in decades.&lt;/p&gt;
    &lt;p&gt;We’re introducing Prism, a free, AI-native workspace for scientists to write and collaborate on research, powered by GPT‑5.2. Prism offers unlimited projects and collaborators and is available today to anyone with a ChatGPT personal account.&lt;/p&gt;
    &lt;p&gt;Prism will be available soon to organizations using ChatGPT Business, Enterprise, and Education plans.&lt;/p&gt;
    &lt;p&gt;Over the past year, we’ve begun to see AI accelerate scientific work across domains. Advanced reasoning systems like GPT‑5 are helping push the frontiers of mathematics, accelerating the analysis of human immune-cell experiments, and speeding up experimental iteration in molecular biology.&lt;/p&gt;
    &lt;p&gt;We’re still early, but it’s clear that AI will play a meaningful role in how science advances.&lt;/p&gt;
    &lt;p&gt;At the same time, much of the everyday work of research—drafting papers, revising arguments, managing equations and citations, and coordinating with collaborators —remains fragmented across disconnected tools. Researchers often move between editors, PDFs, LaTeX compilers, reference managers, and separate chat interfaces, losing context and interrupting focus.&lt;/p&gt;
    &lt;p&gt;Prism is our first step toward addressing this fragmentation.&lt;/p&gt;
    &lt;p&gt;Prism is a free workspace for scientific writing and collaboration, with GPT‑5.2—our most advanced model for mathematical and scientific reasoning—integrated directly into the workflow.&lt;/p&gt;
    &lt;p&gt;It brings drafting, revision, collaboration, and preparation for publication into a single, cloud-based, LaTeX-native workspace. Rather than operating as a separate tool alongside the writing process, GPT‑5.2 works within the project itself—with access to the structure of the paper, equations, references, and surrounding context.&lt;/p&gt;
    &lt;p&gt;Prism builds on the foundation of Crixet, a cloud-based LaTeX platform that OpenAI acquired and has since evolved into Prism as a unified product. This allowed us to start with a strong base of a mature writing and collaboration environment, and integrate AI in a way that fits naturally into scientific workflows.&lt;/p&gt;
    &lt;p&gt;With Prism, researchers can:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Chat with GPT‑5.2 Thinking, to explore ideas, test hypotheses, and reason through complex scientific problems in context&lt;/item&gt;
      &lt;item&gt;Draft and revise papers with the full document as context, including surrounding text, equations, citations, figures, and overall structure&lt;/item&gt;
      &lt;item&gt;Search for and incorporate relevant literature (for example, from arXiv) in the context of the current manuscript, and revise text in light of newly identified related work&lt;/item&gt;
      &lt;item&gt;Create, refactor, and reason over equations, citations, and figures, with AI that understands how those elements relate across the paper&lt;/item&gt;
      &lt;item&gt;Turn whiteboard equations or diagrams directly into LaTeX, saving hours of time manipulating graphics pixel-by-pixel&lt;/item&gt;
      &lt;item&gt;Collaborate with co-authors, students, and advisors in real time, with edits, comments, and revisions reflected immediately&lt;/item&gt;
      &lt;item&gt;Make direct, in-place changes to the document when requested, without copying content between separate editors or chat tools&lt;/item&gt;
      &lt;item&gt;Use optional voice-based editing to make simple changes without interrupting writing or review&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Scientific research is inherently collaborative. Papers are shaped over time by co-authors, students, advisors, and reviewers, often across institutions and geographies.&lt;/p&gt;
    &lt;p&gt;Prism supports unlimited collaborators, allowing research teams to work together without seat limits or access barriers. Because it’s cloud-based, there’s no local LaTeX installation or environment management required, making it easier for teams to collaborate in a shared workspace.&lt;/p&gt;
    &lt;p&gt;By reducing version conflicts, manual merging, and mechanical overhead, Prism helps teams spend less time managing files and more time engaging with the substance of their work.&lt;/p&gt;
    &lt;p&gt;Just as importantly, Prism is designed to expand access.&lt;/p&gt;
    &lt;p&gt;Prism is free to use, and anyone with a ChatGPT account can start writing immediately. There are no subscriptions or seat limits. By making high-quality scientific tools easier to adopt and broadly available, we hope to enable more researchers—across institutions, disciplines, and career stages—to participate fully in the scientific process.&lt;/p&gt;
    &lt;p&gt;More powerful AI features will be made available through paid ChatGPT plans over time.&lt;/p&gt;
    &lt;p&gt;In 2025, AI changed software development forever. In 2026, we expect a comparable shift in science, as AI begins to meaningfully accelerate discovery in several ways, one of which is reducing friction in day-to-day research work. Prism is an early step toward that future.&lt;/p&gt;
    &lt;p&gt;We’re excited to learn from researchers using Prism today and to continue building toward tools that help science move faster—together. Try Prism for free today at prism.openai.com(opens in a new window).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46783752</guid><pubDate>Tue, 27 Jan 2026 18:03:10 +0000</pubDate></item><item><title>Hypercubic (YC F25) Is Hiring a Founding SWE and COBOL Engineer</title><link>https://www.ycombinator.com/companies/hypercubic/jobs</link><description>&lt;doc fingerprint="3564976ca045d865"&gt;
  &lt;main&gt;
    &lt;p&gt;AI to maintain and modernize COBOL.&lt;/p&gt;
    &lt;p&gt;Hypercubic is an AI-native maintenance and modernization platform for COBOL and mainframes.&lt;/p&gt;
    &lt;p&gt;We help enterprises understand and preserve their mission-critical legacy systems. About 70% of the Fortune 500 companies still rely on them to run their core business applications in banking, insurance, telecom, airlines, retail, and more.&lt;/p&gt;
    &lt;p&gt;These systems, originally built in the 1960s–90s, still power trillions in global infrastructure today but have become increasingly opaque as original developers retire or leave the workforce.&lt;/p&gt;
    &lt;p&gt;We're laying the foundation to autonomously maintain and modernize these legacy systems to future-proof the backbone of the global economy.&lt;/p&gt;
    &lt;p&gt;Learn more at hypercubic.ai&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46784491</guid><pubDate>Tue, 27 Jan 2026 18:50:50 +0000</pubDate></item><item><title>Lennart Poettering, Christian Brauner founded a new company</title><link>https://amutable.com/about</link><description>&lt;doc fingerprint="312f8243025a869"&gt;
  &lt;main&gt;&lt;p&gt;Our mission is to deliver verifiable integrity to Linux workloads everywhere&lt;/p&gt;Contact us&lt;p&gt;Our mission is to deliver verifiable integrity to Linux workloads everywhere&lt;/p&gt;&lt;p&gt;We are building cryptographically verifiable integrity into Linux systems. Every system starts in a verified state and stays trusted over time.&lt;/p&gt;&lt;p&gt;Delivering uncompromising integrity&lt;/p&gt;&lt;p&gt;Delivering uncompromising integrity&lt;/p&gt;&lt;p&gt;Executive team&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46784572</guid><pubDate>Tue, 27 Jan 2026 18:57:15 +0000</pubDate></item><item><title>Try text scaling support in Chrome Canary</title><link>https://www.joshtumath.uk/posts/2026-01-27-try-text-scaling-support-in-chrome-canary/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46784977</guid><pubDate>Tue, 27 Jan 2026 19:20:24 +0000</pubDate></item><item><title>Time Station Emulator</title><link>https://github.com/kangtastic/timestation</link><description>&lt;doc fingerprint="c61888ce72653253"&gt;
  &lt;main&gt;
    &lt;p&gt;Time Station Emulator turns almost any phone or tablet into a low-frequency radio transmitter broadcasting a time signal that can synchronize most radio-controlled (“atomic”) clocks and watches.&lt;/p&gt;
    &lt;p&gt;Real time signal broadcasts are limited in geographic range and notoriously prone to interference in urban areas, so many such clocks end up never actually using their self-setting functionality. Time Station Emulator may allow setting such clocks when/where a suitable signal is not otherwise available.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Compatible with most radio-controlled clocks: Emulates the five operational radio time signal stations (🇨🇳 BPC, 🇩🇪 DCF77, 🇯🇵 JJY, 🇬🇧 MSF, and 🇺🇸 WWVB).&lt;/item&gt;
      &lt;item&gt;Network time: Derives the current time from the network using an NTP-like algorithm.&lt;/item&gt;
      &lt;item&gt;Location-agnostic: Supports applying an offset to the transmitted time of ±24 hours from the present.&lt;/item&gt;
      &lt;item&gt;BST/CEST/DST-aware: Transmits daylight saving time information for DCF77, MSF, and WWVB.&lt;/item&gt;
      &lt;item&gt;Leap second-aware: Transmits a DUT1 offset for MSF and WWVB.&lt;/item&gt;
      &lt;item&gt;Client-side, browser-based: Runs entirely in the browser; no installation, no signup, no data collection.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The hard requirements of note are browser WebAssembly support and DAC support for ≥44.1 KHz PCM. Almost any device running a browser from ≥2019 should work.&lt;/p&gt;
    &lt;p&gt;However, as of early 2024, Safari on iOS and Firefox on Android have multiple breaking issues and will not work.&lt;/p&gt;
    &lt;p&gt;For other devices, Time Station Emulator works best with a built-in speaker of a phone or tablet. See Technical Details for an explanation.&lt;/p&gt;
    &lt;p&gt;Time Station Emulator is hosted at https://timestation.pages.dev/.&lt;/p&gt;
    &lt;head&gt;click to expand/hide&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Choose emulator settings.&lt;/p&gt;
        &lt;p&gt;The most important setting is which time station to emulate. Certain settings are only available for certain stations.&lt;/p&gt;
        &lt;p&gt;Clocks (or watches) that support more than one station may prefer one of them over the others.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Choose any clock settings and place the clock into sync mode.&lt;/p&gt;
        &lt;p&gt;If your clock has them, try to choose station and/or time zone settings that make sense for your location.&lt;/p&gt;
        &lt;p&gt;Most clocks provide a way to force a synchronization attempt. You will probably have to navigate menus and/or press physical buttons.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Position the speaker as close as possible to the clock’s antenna.&lt;/p&gt;&lt;p&gt;The transmission range is quite short, so positioning is crucial. Some experimentation will probably be required, especially if you’re unsure where the antenna is.&lt;/p&gt;&lt;p&gt;The volume should be set so that the clock picks up the cleanest signal. Usually, this occurs at or near the maximum possible volume.&lt;/p&gt;&lt;th&gt;WARNING&lt;/th&gt;&lt;td&gt;DO NOT PLACE YOUR EARS NEAR THE SPEAKER TO DETERMINE VOLUME.&lt;/td&gt;&lt;lb/&gt;Use a visual volume indicator instead.&lt;lb/&gt;The generated waveform has full dynamic range, but is pitched high enough to be difficult to perceive.&lt;lb/&gt;Even if you “can’t hear anything”, many common devices are capable of playing it back loud enough to potentially cause permanent hearing damage!&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Start transmitting and hold the speaker in position.&lt;/p&gt;
        &lt;p&gt;If all goes well, the clock will set itself within three minutes.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;click to expand/hide&lt;/head&gt;
    &lt;p&gt;Time Station Emulator generates an audio waveform intentionally crafted to create, when played back through consumer-grade audio hardware, the right kind of RF noise to be mistaken for a time station broadcast.&lt;/p&gt;
    &lt;p&gt;Specifically, given a fundamental carrier frequency used by a real time station, it generates and modulates the highest odd-numbered subharmonic that also falls below the Nyquist frequencies of common playback sample rates.&lt;/p&gt;
    &lt;p&gt;One of the higher-frequency harmonics inevitably created by any real-world DAC during playback will then be the original fundamental, which should leak to the environment as a short-range radio transmission via the ad-hoc antenna formed by the physical wires and circuit traces in the audio output path.&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell role="head"&gt;NOTE&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Because it relies upon this leakage, Time Station Emulator works best with a built-in speaker of a phone or tablet.&lt;p&gt;In some cases, wired headphones or earbuds may also be suitable.&lt;/p&gt;&lt;p&gt;Higher-frequency harmonics are considered artifacts beyond the range of human hearing, so they are routinely suppressed by audio compression algorithms and better equipment.&lt;/p&gt;&lt;p&gt;Bluetooth devices and audiophile-grade equipment are therefore less likely to work.&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;&lt;code&gt;src/shared/casefoldingmap.ts&lt;/code&gt; derives from a
data file
published by the Unicode Consortium, and is
Unicode licensed.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;src/shared/icons.ts&lt;/code&gt; derives from SVG icons originally part of
ionicons v5.0.0 and
Flagpack, and is MIT licensed by way of those projects.&lt;/p&gt;
    &lt;p&gt;All other files are also MIT licensed.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46786183</guid><pubDate>Tue, 27 Jan 2026 20:35:34 +0000</pubDate></item><item><title>Parametric CAD in Rust</title><link>https://campedersen.com/vcad</link><description>&lt;doc fingerprint="2ac25944db1739fb"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Parametric CAD in Rust&lt;/head&gt;January 27, 2026&lt;p&gt;I keep designing physical parts for our robots. Motor mounts, sensor brackets, wheel hubs. Every time, the workflow is the same: open a GUI CAD program, click around for an hour, export an STL, realize the bolt pattern is 2mm off, repeat.&lt;/p&gt;&lt;p&gt;I wanted to write my parts the way I write firmware. In Rust. With types. With version control. With the ability to change one number and regenerate everything.&lt;/p&gt;&lt;p&gt;So I built vcad.&lt;/p&gt;&lt;code&gt;cargo add vcad
&lt;/code&gt;

&lt;head rend="h2"&gt;The idea&lt;/head&gt;&lt;p&gt;A part is just geometry with a name. You create primitives, combine them with boolean operations, and export. That's it.&lt;/p&gt;&lt;code&gt;use vcad::{centered_cube, centered_cylinder, bolt_pattern};

let plate = centered_cube("plate", 120.0, 80.0, 5.0);
let bore = centered_cylinder("bore", 15.0, 10.0, 64);
let bolts = bolt_pattern(6, 50.0, 4.5, 10.0, 32);

let part = plate - bore - bolts;
part.write_stl("plate.stl").unwrap();&lt;/code&gt;&lt;p&gt;That minus sign is a real boolean difference. &lt;code&gt;+&lt;/code&gt; is union. &lt;code&gt;&amp;amp;&lt;/code&gt; is intersection. Operator overloads make CSG feel like arithmetic.&lt;/p&gt;&lt;p&gt;The plate above has a center bore, four corner mounting holes, and a six-bolt circle pattern. Twelve lines of code. One STL file. Done.&lt;/p&gt;&lt;head rend="h2"&gt;What you can build&lt;/head&gt;&lt;p&gt;The API is small on purpose. Primitives, booleans, transforms, patterns. That's the whole language. But it composes well.&lt;/p&gt;&lt;p&gt;An L-bracket with mounting holes in both faces:&lt;/p&gt;&lt;code&gt;let base = centered_cube("base", 60.0, 40.0, 4.0);
let wall = centered_cube("wall", 60.0, 4.0, 36.0)
    .translate(0.0, -18.0, 20.0);
let bracket = base + wall - base_holes - wall_holes;&lt;/code&gt;&lt;p&gt;A flanged hub with a bolt circle:&lt;/p&gt;&lt;code&gt;let hub = centered_cylinder("hub", 15.0, 20.0, 64);
let flange = centered_cylinder("flange", 30.0, 4.0, 64)
    .translate(0.0, 0.0, -10.0);
let part = hub + flange - bore - bolt_pattern(6, 45.0, 3.0, 8.0, 32);&lt;/code&gt;&lt;p&gt;A radial vent pattern cut from a disc — one slot, repeated eight times:&lt;/p&gt;&lt;code&gt;let slot = centered_cube("slot", 15.0, 2.0, 10.0);
let vents = slot.circular_pattern(20.0, 8);
let panel = centered_cylinder("panel", 35.0, 3.0, 64) - vents;&lt;/code&gt;&lt;p&gt;Every part here is parametric. Change the bolt count, the radius, the wall thickness — one number changes and the whole part regenerates. No clicking. No undo. Just recompile.&lt;/p&gt;&lt;head rend="h2"&gt;Multi-material export&lt;/head&gt;&lt;p&gt;STL is fine for 3D printing, but it throws away all material information. For visualization, vcad exports glTF scenes with PBR materials defined in TOML:&lt;/p&gt;&lt;code&gt;let materials = Materials::parse(r#"
    [materials.body]
    color = [0.32, 0.72, 0.95]
    metallic = 0.1
    roughness = 0.5

    [materials.antenna]
    color = [0.95, 0.3, 0.35]
    metallic = 0.3
"#).unwrap();

let mut scene = Scene::new("mascot");
scene.add(body, "body");
scene.add(antenna_ball, "antenna");
export_scene_glb(&amp;amp;scene, &amp;amp;materials, "mascot.glb").unwrap();&lt;/code&gt;&lt;p&gt;That's our mascot. Entirely CSG. A rounded cube intersected with a sphere for the body, spheres for eyes, cylinders for arms. Eight materials, seventeen parts, one GLB file.&lt;/p&gt;&lt;head rend="h2"&gt;Why Rust&lt;/head&gt;&lt;p&gt;The geometry engine is manifold, which guarantees watertight meshes from boolean operations. The Rust bindings give us zero-cost abstractions over the C++ core — the operator overloads compile down to direct manifold calls. No garbage collection pauses. No floating point surprises from a scripting layer.&lt;/p&gt;&lt;p&gt;But honestly, the main reason is the toolchain. &lt;code&gt;cargo test&lt;/code&gt; runs 21 unit tests that verify volumes, surface areas, bounding boxes, and export round-trips. &lt;code&gt;cargo clippy&lt;/code&gt; catches issues before they become parts with holes in the wrong place. Types prevent you from passing a radius where a diameter was expected.&lt;/p&gt;&lt;p&gt;CAD files should be code. Code has tests, reviews, diffs, and CI. An STL file has... bytes.&lt;/p&gt;&lt;head rend="h2"&gt;Built for agents&lt;/head&gt;&lt;p&gt;One thing I care about that most CAD tools don't: vcad is designed to be used by AI coding agents.&lt;/p&gt;&lt;p&gt;The README has full API tables, a cookbook with copy-pasteable recipes, and a section on Blender MCP integration. An agent can read the docs, generate a part, export it, import it into Blender, position a camera, and render a preview — all in one conversation.&lt;/p&gt;&lt;p&gt;Every render in this post was made that way. Claude generated the geometry with vcad, imported each STL/GLB into Blender via MCP, set up studio lighting, and rendered to PNG. No human touched Blender.&lt;/p&gt;&lt;p&gt;The feedback loop is: describe a part → code generates → mesh exports → render previews → iterate. All in the terminal.&lt;/p&gt;&lt;head rend="h2"&gt;Try it&lt;/head&gt;&lt;code&gt;cargo add vcad
&lt;/code&gt;
&lt;list rend="ul"&gt;&lt;item&gt;Docs: docs.rs/vcad&lt;/item&gt;&lt;item&gt;Source: github.com/ecto/vcad&lt;/item&gt;&lt;item&gt;Site: vcad.io&lt;/item&gt;&lt;/list&gt;&lt;p&gt;It's MIT licensed. The first version is 0.1 — there's a lot more to build. Fillets, chamfers, threads, an interactive web GUI. But the core is solid: primitives, booleans, transforms, export. Everything you need to stop clicking and start typing.&lt;/p&gt;&lt;p&gt;Go make something.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46786196</guid><pubDate>Tue, 27 Jan 2026 20:36:14 +0000</pubDate></item><item><title>Notes on starting to use Django</title><link>https://jvns.ca/blog/2026/01/27/some-notes-on-starting-to-use-django/</link><description>&lt;doc fingerprint="9ee271157f351b9e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Some notes on starting to use Django&lt;/head&gt;
    &lt;p&gt;Hello! One of my favourite things is starting to learn an Old Boring Technology that I’ve never tried before but that has been around for 20+ years. It feels really good when every problem I’m ever going to have has been solved already 1000 times and I can just get stuff done easily.&lt;/p&gt;
    &lt;p&gt;I’ve thought it would be cool to learn a popular web framework like Rails or Django or Laravel for a long time, but I’d never really managed to make it happen. But I started learning Django to make a website a few months back, I’ve been liking it so far, and here are a few quick notes!&lt;/p&gt;
    &lt;head rend="h3"&gt;less magic than Rails&lt;/head&gt;
    &lt;p&gt;I spent some time trying to learn Rails in 2020, and while it was cool and I really wanted to like Rails (the Ruby community is great!), I found that if I left my Rails project alone for months, when I came back to it it was hard for me to remember how to get anything done because (for example) if it says &lt;code&gt;resources :topics&lt;/code&gt; in your &lt;code&gt;routes.rb&lt;/code&gt;, on its own
that doesn’t tell you where the &lt;code&gt;topics&lt;/code&gt; routes are configured, you need to
remember or look up the convention.&lt;/p&gt;
    &lt;p&gt;Being able to abandon a project for months or years and then come back to it is really important to me (that’s how all my projects work!), and Django feels easier to me because things are more explicit.&lt;/p&gt;
    &lt;p&gt;In my small Django project it feels like I just have 5 main files (other than the settings files): &lt;code&gt;urls.py&lt;/code&gt;, &lt;code&gt;models.py&lt;/code&gt;, &lt;code&gt;views.py&lt;/code&gt;, &lt;code&gt;admin.py&lt;/code&gt;, and
&lt;code&gt;tests.py&lt;/code&gt;, and if I want to know where something else is (like an HTML template)
is then it’s usually explicitly referenced from one of those files.&lt;/p&gt;
    &lt;head rend="h3"&gt;a built-in admin&lt;/head&gt;
    &lt;p&gt;For this project I wanted to have an admin interface to manually edit or view some of the data in the database. Django has a really nice built-in admin interface, and I can customize it with just a little bit of code.&lt;/p&gt;
    &lt;p&gt;For example, here’s part of one of my admin classes, which sets up which fields to display in the “list” view, which field to search on, and how to order them by default.&lt;/p&gt;
    &lt;code&gt;@admin.register(Zine)
class ZineAdmin(admin.ModelAdmin):
    list_display = ["name", "publication_date", "free", "slug", "image_preview"]
    search_fields = ["name", "slug"]
    readonly_fields = ["image_preview"]
    ordering = ["-publication_date"]
&lt;/code&gt;
    &lt;head rend="h3"&gt;it’s fun to have an ORM&lt;/head&gt;
    &lt;p&gt;In the past my attitude has been “ORMs? Who needs them? I can just write my own SQL queries!”. I’ve been enjoying Django’s ORM so far though, and I think it’s cool how Django uses &lt;code&gt;__&lt;/code&gt; to represent a &lt;code&gt;JOIN&lt;/code&gt;, like this:&lt;/p&gt;
    &lt;code&gt;Zine.objects
    .exclude(product__order__email_hash=email_hash)
&lt;/code&gt;
    &lt;p&gt;This query involves 5 tables: &lt;code&gt;zines&lt;/code&gt;, &lt;code&gt;zine_products&lt;/code&gt;, &lt;code&gt;products&lt;/code&gt;, &lt;code&gt;order_products&lt;/code&gt;, and &lt;code&gt;orders&lt;/code&gt;.
To make this work I just had to tell Django that there’s a &lt;code&gt;ManyToManyField&lt;/code&gt;
relating “orders” and “products”, and another &lt;code&gt;ManyToManyField&lt;/code&gt; relating
“zines”, and “products”, so that it knows how to connect &lt;code&gt;zines&lt;/code&gt;, &lt;code&gt;orders&lt;/code&gt;, &lt;code&gt;products&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;I definitely could write that query, but writing &lt;code&gt;product__order__email_hash&lt;/code&gt; is
a lot less typing, it feels a lot easier to read, and honestly I think it would
take me a little while to figure out how to construct the query
(which needs to do a few other things than just those joins).&lt;/p&gt;
    &lt;p&gt;I have zero concern about the performance of my ORM-generated queries so I’m pretty excited about ORMs for now, though I’m sure I’ll find things to be frustrated with eventually.&lt;/p&gt;
    &lt;head rend="h3"&gt;automatic migrations!&lt;/head&gt;
    &lt;p&gt;The other great thing about the ORM is migrations!&lt;/p&gt;
    &lt;p&gt;If I add, delete, or change a field in &lt;code&gt;models.py&lt;/code&gt;, Django will automatically
generate a migration script like &lt;code&gt;migrations/0006_delete_imageblob.py&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;I assume that I could edit those scripts if I wanted, but so far I’ve just been running the generated scripts with no change and it’s been going great. It really feels like magic.&lt;/p&gt;
    &lt;p&gt;I’m realizing that being able to do migrations easily is important for me right now because I’m changing my data model fairly often as I figure out how I want it to work.&lt;/p&gt;
    &lt;head rend="h3"&gt;I like the docs&lt;/head&gt;
    &lt;p&gt;I had a bad habit of never reading the documentation but I’ve been really enjoying the parts of Django’s docs that I’ve read so far. This isn’t by accident: Jacob Kaplan-Moss has a talk from PyCon 2011 on Django’s documentation culture.&lt;/p&gt;
    &lt;p&gt;For example the intro to models lists the most important common fields you might want to set when using the ORM.&lt;/p&gt;
    &lt;head rend="h3"&gt;using sqlite&lt;/head&gt;
    &lt;p&gt;After having a bad experience trying to operate Postgres and not being able to understand what was going on, I decided to run all of my small websites with SQLite instead. It’s been going way better, and I love being able to backup by just doing a &lt;code&gt;VACUUM INTO&lt;/code&gt; and then copying the resulting single file.&lt;/p&gt;
    &lt;p&gt;I’ve been following these instructions for using SQLite with Django in production.&lt;/p&gt;
    &lt;p&gt;I think it should be fine because I’m expecting the site to have a few hundred writes per day at most, much less than Mess with DNS which has a lot more of writes and has been working well (though the writes are split across 3 different SQLite databases).&lt;/p&gt;
    &lt;head rend="h3"&gt;built in email (and more)&lt;/head&gt;
    &lt;p&gt;Django seems to be very “batteries-included”, which I love – if I want CSRF protection, or a &lt;code&gt;Content-Security-Policy&lt;/code&gt;, or I want to send email, it’s all
in there!&lt;/p&gt;
    &lt;p&gt;For example, I wanted to save the emails Django sends to a file in dev mode (so that it didn’t send real email to real people), which was just a little bit of configuration.&lt;/p&gt;
    &lt;p&gt;I just put this &lt;code&gt;settings/dev.py&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;EMAIL_BACKEND = "django.core.mail.backends.filebased.EmailBackend"
EMAIL_FILE_PATH = BASE_DIR / "emails"
&lt;/code&gt;
    &lt;p&gt;and then set up the production email like this in &lt;code&gt;settings/production.py&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;EMAIL_BACKEND = "django.core.mail.backends.smtp.EmailBackend"
EMAIL_HOST = "smtp.whatever.com"
EMAIL_PORT = 587
EMAIL_USE_TLS = True
EMAIL_HOST_USER = "xxxx"
EMAIL_HOST_PASSWORD = os.getenv('EMAIL_API_KEY')
&lt;/code&gt;
    &lt;p&gt;That made me feel like if I want some other basic website feature, there’s likely to be an easy way to do it built into Django already.&lt;/p&gt;
    &lt;head rend="h3"&gt;the settings file still feels like a lot&lt;/head&gt;
    &lt;p&gt;I’m still a bit intimidated by the &lt;code&gt;settings.py&lt;/code&gt; file: Django’s settings system
works by setting a bunch of global variables in a file, and I feel a bit
stressed about… what if I make a typo in the name of one of those variables?
How will I know? What if I type &lt;code&gt;WSGI_APPLICATOIN = "config.wsgi.application"&lt;/code&gt;
instead of &lt;code&gt;WSGI_APPLICATION&lt;/code&gt;?&lt;/p&gt;
    &lt;p&gt;I guess I’ve gotten used to having a Python language server tell me when I’ve made a typo and so now it feels a bit disorienting when I can’t rely on the language server support.&lt;/p&gt;
    &lt;head rend="h3"&gt;that’s all for now!&lt;/head&gt;
    &lt;p&gt;I haven’t really successfully used an actual web framework for a project before (right now almost all of my websites are either a single Go binary or static sites), so I’m interested in seeing how it goes!&lt;/p&gt;
    &lt;p&gt;There’s still lots for me to learn about, I still haven’t really gotten into Django’s form validation tooling or authentication systems.&lt;/p&gt;
    &lt;p&gt;Thanks to Marco Rogers for convincing me to give ORMs a chance.&lt;/p&gt;
    &lt;p&gt;(we’re still experimenting with the comments-on-Mastodon system! Here are the comments on Mastodon! tell me your favourite Django feature!)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46788384</guid><pubDate>Tue, 27 Jan 2026 22:58:30 +0000</pubDate></item><item><title>AISLE’s autonomous analyzer found all CVEs in the January OpenSSL release</title><link>https://aisle.com/blog/aisle-discovered-12-out-of-12-openssl-vulnerabilities</link><description>&lt;doc fingerprint="f558f08a703ac292"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;AISLE Discovered 12 out of 12 OpenSSL Vulnerabilities&lt;/head&gt;
    &lt;p&gt;Author&lt;/p&gt;
    &lt;p&gt;Stanislav Fort&lt;/p&gt;
    &lt;p&gt;Date Published&lt;/p&gt;
    &lt;head rend="h2"&gt;Autonomous zero-day discovery in one of the most scrutinized codebases in the world&lt;/head&gt;
    &lt;p&gt;AISLE's autonomous analyzer found all 12 CVEs in the January 2026 coordinated release of OpenSSL, the open-source cryptographic library that underpins a substantial proportion of the world’s secure communications. Some of these vulnerabilities had persisted in OpenSSL code for decades, evading the notice of thousands of security researchers.&lt;/p&gt;
    &lt;p&gt;Finding a genuine security flaw in OpenSSL is extraordinarily difficult. Even a single accepted vulnerability represents a rare achievement. The library's maturity and the community's vigilance make new discoveries exceptionally uncommon. This makes the January 2026 release an important milestone for autonomous security systems. As Tomáš Mráz, CTO of the OpenSSL Foundation, says,&lt;/p&gt;
    &lt;p&gt;“One of the most important sources of the security of the OpenSSL Library and open source projects overall is independent research. This release is fixing 12 security issues, all disclosed to us by AISLE. We appreciate the high quality of the reports and their constructive collaboration with us throughout the remediation.”&lt;/p&gt;
    &lt;p&gt;In this article, we’ll give an overview of our discoveries and explain why we think this is a watershed moment for AI-powered software security.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Discoveries&lt;/head&gt;
    &lt;p&gt;The AISLE Research Team started hunting for OpenSSL vulnerabilities with our autonomous analyzer in August 2025. You can read about the three discoveries we made in Q3 of 2025 here. All of our discoveries were reported through responsible disclosure and resolved through coordinated releases with the OpenSSL project.&lt;/p&gt;
    &lt;head rend="h3"&gt;High and Moderate Severity CVEs&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CVE-2025-15467: Stack Buffer Overflow in CMS AuthEnvelopedData Parsing (High): A vulnerability with the potential to enable remote code execution under specific conditions&lt;/item&gt;
      &lt;item&gt;CVE-2025-11187: PBMAC1 Parameter Validation in PKCS#12 (Moderate): Missing validation that could trigger a stack-based buffer overflow&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Low Severity CVEs&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CVE-2025-15468: Crash in QUIC protocol cipher handling&lt;/item&gt;
      &lt;item&gt;CVE-2025-15469: Silent truncation bug affecting post-quantum signature algorithms (ML-DSA)&lt;/item&gt;
      &lt;item&gt;CVE-2025-66199: Memory exhaustion via TLS 1.3 certificate compression&lt;/item&gt;
      &lt;item&gt;CVE-2025-68160: Memory corruption in line-buffering (affects code back to OpenSSL 1.0.2)&lt;/item&gt;
      &lt;item&gt;CVE-2025-69418: Encryption flaw in OCB mode on hardware-accelerated paths&lt;/item&gt;
      &lt;item&gt;CVE-2025-69419: Memory corruption in PKCS#12 character encoding&lt;/item&gt;
      &lt;item&gt;CVE-2025-69420: Crash in TimeStamp Response verification&lt;/item&gt;
      &lt;item&gt;CVE-2025-69421: Crash in PKCS#12 decryption&lt;/item&gt;
      &lt;item&gt;CVE-2026-22795: Crash in PKCS#12 parsing&lt;/item&gt;
      &lt;item&gt;CVE-2026-22796: Crash in PKCS#7 signature verification (affects code back to OpenSSL 1.0.2)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;AISLE’s analyzer also recommended fixes which were incorporated directly into OpenSSL for 5 of the 12 CVEs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Beyond CVEs: Catching Bugs Before They Ship&lt;/head&gt;
    &lt;p&gt;In addition to the 12 CVEs, 6 findings were never assigned a designation. In each case, AISLE detected the issue, reported it to the maintainers, and the fix was merged before the vulnerable code ever appeared in a release.&lt;/p&gt;
    &lt;head rend="h2"&gt;By integrating autonomous analysis directly into development workflows, security issues were identified and resolved before they reached users. That is our goal: preventing vulnerabilities, not merely patching them after deployment.&lt;/head&gt;
    &lt;head rend="h2"&gt;What This Means&lt;/head&gt;
    &lt;p&gt;OpenSSL represents one of the most deployed, battle-tested, and carefully maintained open-source projects in existence. The fact that 12 previously unknown vulnerabilities could still be found there, including issues dating back to 1998, suggests that manual review faces significant limits, even in mature, heavily audited codebases.&lt;/p&gt;
    &lt;p&gt;Human reviewers are constrained by time, attention, and the sheer volume of code in modern systems. Traditional static analysis catches certain bug classes but struggles with complex logic errors and timing-dependent issues. By contrast, autonomous AI-driven analysis operates at a different scale. It can examine code paths and edge cases that would take human reviewers months to cover, and it runs continuously rather than periodically.&lt;/p&gt;
    &lt;p&gt;This doesn't mean that AI can replace human expertise. The OpenSSL maintainers' deep knowledge of the codebase was essential for validating findings and developing robust fixes. But it does change the SLA of security. When autonomous discovery is paired with responsible disclosure, it collapses the time-to-remediation for the entire ecosystem.&lt;/p&gt;
    &lt;p&gt;The 12 OpenSSL vulnerabilities we identified, spanning 8+ subsystems from CMS to QUIC to post-quantum signatures, represent a milestone in our (admittedly ambitious) mission: moving from reactive patching to securing the software foundation that modern civilization depends on.&lt;/p&gt;
    &lt;head rend="h2"&gt;Collaboration with OpenSSL&lt;/head&gt;
    &lt;p&gt;From the moment our system flagged these anomalies, we approached this as a partnership with the OpenSSL community. We submitted detailed technical reports through their coordinated security reporting process, including complete reproduction steps, root cause analysis, and concrete patch proposals. In each case, our proposed fixes either informed or were directly adopted by the OpenSSL team.&lt;/p&gt;
    &lt;p&gt;As Matt Caswell, Executive Director of the OpenSSL Foundation, said, “Keeping widely deployed cryptography secure requires tight coordination between maintainers and researchers. We appreciate AISLE's responsible disclosures and the quality of their engagement across these issues."&lt;/p&gt;
    &lt;p&gt;The OpenSSL team's responsiveness was exceptional. Under the leadership of Tomáš Mráz, the Chief Technical Officer (CTO) at the OpenSSL Foundation, the maintainers engaged technically at every stage: validating findings, refining patches, coordinating releases across multiple branches, and synchronizing with downstream distributions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Further Reading&lt;/head&gt;
    &lt;p&gt;For questions about AISLE's autonomous analyzer, reach out to us at [email protected].&lt;/p&gt;
    &lt;p&gt;Our appreciation goes to Tomáš Mráz, Matt Caswell, Neil Horman, and the OpenSSL team for their collaboration throughout this process. AISLE researchers contributing to these discoveries include Stanislav Fort, Petr Šimeček, Tomas Dulka, and Luigino Camastra.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46789913</guid><pubDate>Wed, 28 Jan 2026 01:38:15 +0000</pubDate></item><item><title>Rust at Scale: An Added Layer of Security for WhatsApp</title><link>https://engineering.fb.com/2026/01/27/security/rust-at-scale-security-whatsapp/</link><description>&lt;doc fingerprint="8e10dda3ac31549d"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;WhatsApp has adopted and rolled out a new layer of security for users – built with Rust – as part of its effort to harden defenses against malware threats.&lt;/item&gt;
      &lt;item&gt;WhatsApp’s experience creating and distributing our media consistency library in Rust to billions of devices and browsers proves Rust is production ready at a global scale.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Our Media Handling Strategy&lt;/head&gt;
    &lt;p&gt;WhatsApp provides default end-to-end encryption for over 3 billion people to message securely each and every day. Online security is an adversarial space, and to continue ensuring users can keep messaging securely, we’re constantly adapting and evolving our strategy against cyber-security threats – all while supporting the WhatsApp infrastructure to help people connect.&lt;/p&gt;
    &lt;p&gt;For example, WhatsApp, like many other applications, allows users to share media and other types of documents. WhatsApp helps protect users by warning about dangerous attachments like APKs, yet rare and sophisticated malware could be hidden within a seemingly benign file like an image or video. These maliciously crafted files might target unpatched vulnerabilities in the operating system, libraries distributed by the operating system, or the application itself.&lt;/p&gt;
    &lt;p&gt;To help protect against such potential threads, WhatsApp is increasingly using the Rust programming language, including in our media sharing functionality. Rust is a memory safe language offering numerous security benefits. We believe that this is the largest rollout globally of any library written in Rust.&lt;/p&gt;
    &lt;p&gt;To help explain why and how we rolled this out, we should first look back at a key OS-level vulnerability that sent an important signal to WhatsApp around hardening media-sharing defenses.&lt;/p&gt;
    &lt;head rend="h2"&gt;2015 Android Vulnerability: A Wake-up Call for Media File Protections&lt;/head&gt;
    &lt;p&gt;In 2015, Android devices, and the applications that ran on them, became vulnerable to the “Stagefright” vulnerability. The bug lay in the processing of media files by operating system-provided libraries, so WhatsApp and other applications could not patch the underlying vulnerability. Because it could often take months for people to update to the latest version of their software, we set out to find solutions that would keep WhatsApp users safe, even in the event of an operating system vulnerability.&lt;/p&gt;
    &lt;p&gt;At that time, we realized that a cross-platform C++ library already developed by WhatsApp to send and consistently format MP4 files (called “wamedia”) could be modified to detect files which do not adhere to the MP4 standard and might trigger bugs in a vulnerable OS library on the receiver side – hence putting a target’s security at risk. We rolled out this check and were able to protect WhatsApp users from the Stagefright vulnerability much more rapidly than by depending on users to update the OS itself.&lt;/p&gt;
    &lt;p&gt;But because media checks run automatically on download and process untrusted inputs, we identified early on that wamedia was a prime candidate for using a memory safe language.&lt;/p&gt;
    &lt;head rend="h2"&gt;Our Solution: Rust at Scale&lt;/head&gt;
    &lt;p&gt;Rather than an incremental rewrite, we developed the Rust version of wamedia in parallel with the original C++ version. We used differential fuzzing and extensive integration and unit tests to ensure compatibility between the two implementations.&lt;/p&gt;
    &lt;p&gt;Two major hurdles were the initial binary size increase due to bringing in the Rust standard library and the build system support required for the diverse platforms supported by WhatsApp. WhatsApp made a long-term bet to build that support. In the end, we replaced 160,000 lines of C++ (excluding tests) with 90,000 lines of Rust (including tests). The Rust version showed performance and runtime memory usage advantages over the C++. Given this success, Rust was fully rolled out to all WhatsApp users and many platforms: Android, iOS, Mac, Web, Wearables, and more. With this positive evidence in hand, memory safe languages will play an ever increasing part in WhatsApp’s overall approach to application and user security.&lt;/p&gt;
    &lt;p&gt;Over time, we’ve added more checks for non-conformant structures within certain file types to help protect downstream libraries from parser differential exploit attempts. Additionally, we check higher risk file types, even if structurally conformant, for risk indicators. For instance, PDFs are often a vehicle for malware, and more specifically, the presence of embedded files and scripting elements within a PDF further raise risks. We also detect when one file type masquerades as another, through a spoofed extension or MIME type. Finally, we uniformly flag known dangerous file types, such as executables or applications, for special handling in the application UX. Altogether, we call this ensemble of checks “Kaleidoscope.” This system protects people on WhatsApp from potentially malicious unofficial clients and attachments. Although format checks will not stop every attack, this layer of defense helps mitigate many of them.&lt;/p&gt;
    &lt;p&gt;Each month, these libraries are distributed to billions of phones, laptops, desktops, watches, and browsers running on multiple operating systems for people on WhatsApp, Messenger, and Instagram. This is the largest ever deployment of Rust code to a diverse set of end-user platforms and products that we are aware of. Our experience speaks to the production-readiness and unique value proposition of Rust on the client-side.&lt;/p&gt;
    &lt;head rend="h2"&gt;How Rust Fits In To WhatsApp’s Approach to App Security&lt;/head&gt;
    &lt;p&gt;This is just one example of WhatsApp’s many investments in security. It’s why we built default end-to-end encryption for personal messages and calls, offer end-to-end encrypted backups, and use key transparency technology to verify a secure connection, provide additional calling protections, and more.&lt;/p&gt;
    &lt;p&gt;WhatsApp has a strong track record of being loud when we find issues and working to hold bad actors accountable. For example, WhatsApp reports CVEs for important issues we find in our applications, even if we do not find evidence of exploitation. We do this to give people on WhatsApp the best chance of protecting themselves by seeing a security advisory and updating quickly.&lt;/p&gt;
    &lt;p&gt;To ensure application security, we first must identify and quantify the sources of risk. We do this through internal and external audits like NCC Group’s public assessment of WhatsApp’s end-to-end encrypted backups, fuzzing, static analysis, supply chain management, and automated attack surface analysis. We also recently expanded our Bug Bounty program to introduce the WhatsApp Research Proxy – a tool that makes research into WhatsApp’s network protocol more effective.&lt;/p&gt;
    &lt;p&gt;Next, we reduce the identified risk. Like many others in the industry, we found that the majority of the high severity vulnerabilities we published were due to memory safety issues in code written in the C and C++ programming languages. To combat this we invest in three parallel strategies:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Design the product to minimize unnecessary attack surface exposure.&lt;/item&gt;
      &lt;item&gt;Invest in security assurance for the remaining C and C++ code.&lt;/item&gt;
      &lt;item&gt;Default the choice of memory safe languages, and not C and C++, for new code.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;WhatsApp has added protections like CFI, hardened memory allocators, safer buffer handling APIs, and more. C and C++ developers have specialized security training, development guidelines, and automated security analysis on their changes. We also have strict SLAs for fixing issues uncovered by the risk identification process.&lt;/p&gt;
    &lt;head rend="h2"&gt;Accelerating Rust Adoption to Enhance Security&lt;/head&gt;
    &lt;p&gt;Rust enabled WhatsApp’s security team to develop a secure, high performance, cross-platform library to ensure media shared on the platform is consistent and safe across devices. This is an important step forward in adding additional security behind the scenes for users and part of our ongoing defense-in-depth approach. Security teams at WhatsApp and Meta are highlighting opportunities for high impact adoption of Rust to interested teams, and we anticipate accelerating adoption of Rust over the coming years.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46791742</guid><pubDate>Wed, 28 Jan 2026 06:21:07 +0000</pubDate></item><item><title>Make.ts</title><link>https://matklad.github.io/2026/01/27/make-ts.html</link><description>&lt;doc fingerprint="76c2d8f72f2572bd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;make.ts&lt;/head&gt;
    &lt;p&gt;Up Enter Up Up Enter Up Up Up Enter&lt;/p&gt;
    &lt;p&gt; Sounds familiar? This is how I historically have been running benchmarks and other experiments requiring a repeated sequence of commands — type them manually once, then rely on shell history (and maybe some terminal splits) for reproduction. These past few years I’ve arrived at a much better workflow pattern — &lt;code&gt;make.ts&lt;/code&gt;.
          I was forced to adapt it once I started working with multiprocess
          applications, where manually entering commands is borderline
          infeasible. In retrospect, I should have adapted the workflow years
          earlier.
        &lt;/p&gt;
    &lt;head rend="h2"&gt;The Pattern&lt;/head&gt;
    &lt;p&gt; Use a (gitignored) file for interactive scripting. Instead of entering a command directly into the terminal, write it to a file first, and then run the file. For me, I type stuff into &lt;code&gt;make.ts&lt;/code&gt; and then run &lt;code&gt;./make.ts&lt;/code&gt; in my terminal
            (Ok, I need one Up Enter for that).
          &lt;/p&gt;
    &lt;p&gt;I want to be clear here, I am not advocating writing “proper” scripts, just capturing your interactive, ad-hoc command to a persistent file. Of course any command that you want to execute repeatedly belongs to the build system. The surprising thing is that even more complex one-off commands benefit from running through file, because it will take you several tries to get them right!&lt;/p&gt;
    &lt;p&gt;There are many benefits relative to Up Up Up workflow:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Real commands tend to get large, and it is so much nicer to use a real 2D text editor rather than shell’s line editor.&lt;/item&gt;
      &lt;item&gt; If you need more than one command, you can write several commands, and still run them all with a single key (before &lt;code&gt;make.ts&lt;/code&gt;, I was prone to constructing rather horrific &amp;amp;&amp;amp; conjuncts for this reason).&lt;/item&gt;
      &lt;item&gt;With a sequence of command outlined, you nudge yourself towards incrementally improving them, making them idempotent, and otherwise investing into your own workflow for the next few minutes, without falling into the YAGNI pit from the outset.&lt;/item&gt;
      &lt;item&gt;At some point you might realize after, say, running a series of ad-hoc benchmarks interactively, that you’d rather write a proper script which executes a collection of benchmarks with varying parameters. With the file approach, you already have the meat of the script implemented, and you only need to wrap in a couple of fors and ifs.&lt;/item&gt;
      &lt;item&gt;Finally, if you happen to work with multi-process projects, you’ll find it easier to manage concurrency declaratively, spawning a tree of processes from a single script, rather than switching between terminal splits.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Details&lt;/head&gt;
    &lt;p&gt; Use a consistent filename for the script. I use &lt;code&gt;make.ts&lt;/code&gt;, and so there’s a &lt;code&gt;make.ts&lt;/code&gt; in the root
            of most projects I work on. Correspondingly, I have &lt;code&gt;make.ts&lt;/code&gt; line in project’s &lt;code&gt;.git/info/exclude&lt;/code&gt;
            — the &lt;code&gt;.gitignore&lt;/code&gt; file which is not shared. The fixed
            name reduces fixed costs — whenever I need complex interactivity I
            don’t need to come up with a name for a new file, I open my
            pre-existing &lt;code&gt;make.ts&lt;/code&gt;, wipe whatever was there and start
            hacking. Similarly, I have &lt;code&gt;./make.ts&lt;/code&gt; in my shell
            history, so
            fish autosuggestions
            work for me. At one point, I had a VS Code task to run &lt;code&gt;make.ts&lt;/code&gt;, though I now use
            terminal editor.
          &lt;/p&gt;
    &lt;p&gt; Start the script with hash bang, &lt;code&gt;#!/usr/bin/env -S deno run
                --allow-all&lt;/code&gt;
            in my case, and
            &lt;code&gt;chmod a+x make.ts&lt;/code&gt;
            the file, to make it easy to run.
          &lt;/p&gt;
    &lt;p&gt;Write the script in a language that:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;you are comfortable with,&lt;/item&gt;
      &lt;item&gt;doesn’t require huge setup,&lt;/item&gt;
      &lt;item&gt;makes it easy to spawn subprocesses,&lt;/item&gt;
      &lt;item&gt;has good support for concurrency.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For me, that is TypeScript. Modern JavaScript is sufficiently ergonomic, and structural, gradual typing is a sweet spot that gives you reasonable code completion, but still allows brute-forcing any problem by throwing enough stringly dicts at it.&lt;/p&gt;
    &lt;p&gt;JavaScript’s tagged template syntax is brilliant for scripting use-cases:&lt;/p&gt;
    &lt;p&gt;prints&lt;/p&gt;
    &lt;p&gt; What happens here is that &lt;code&gt;$&lt;/code&gt; gets a list of literal
            string fragments inside the backticks, and then, separately, a list
            of values to be interpolated in-between. It could
            concatenate everything to just a single string, but it doesn’t have
            to. This is precisely what is required for process spawning, where
            you want to pass an array of strings to the &lt;code&gt;exec&lt;/code&gt;
            syscall.
          &lt;/p&gt;
    &lt;p&gt; Specifically, I use dax library with Deno, which is excellent as a single-binary batteries-included scripting environment (see &amp;lt;3 Deno). Bun has a dax-like library in the box and is a good alternative (though I personally stick with Deno because of &lt;code&gt;deno fmt&lt;/code&gt; and &lt;code&gt;deno lsp&lt;/code&gt;). You could also use
            famous zx, though be mindful that it
            uses your shell as a middleman, something I consider to be
            sloppy (explanation).
          &lt;/p&gt;
    &lt;p&gt; While &lt;code&gt;dax&lt;/code&gt; makes it convenient to spawn a single
            program, &lt;code&gt;async/await&lt;/code&gt; is excellent for herding a slither
            of processes:
          &lt;/p&gt;
    &lt;head rend="h2"&gt;Concrete Example&lt;/head&gt;
    &lt;p&gt;Here’s how I applied this pattern earlier today. I wanted to measure how TigerBeetle cluster recovers from the crash of the primary. The manual way to do that would be to create a bunch of ssh sessions for several cloud machines, format datafiles, start replicas, and then create some load. I almost started to split my terminal up, but then figured out I can do it the smart way.&lt;/p&gt;
    &lt;p&gt;The first step was cross-compiling the binary, uploading it to the cloud machines, and running the cluster (using my box from the other week):&lt;/p&gt;
    &lt;p&gt;Running the above the second time, I realized that I need to kill the old cluster first, so two new commands are “interactively” inserted:&lt;/p&gt;
    &lt;p&gt;At this point, my investment in writing this file and not just entering the commands one-by-one already paid off!&lt;/p&gt;
    &lt;p&gt;The next step is to run the benchmark load in parallel with the cluster:&lt;/p&gt;
    &lt;p&gt;I don’t need two terminals for two processes, and I get to copy-paste-edit the mostly same command.&lt;/p&gt;
    &lt;p&gt; For the next step, I actually want to kill one of the replicas, and I also want to capture live logs, to see in real-time how the cluster reacts. This is where &lt;code&gt;0-5&lt;/code&gt; multiplexing syntax
            of box falls short, but, given that this is JavaScript, I can just
            write a for loop:
          &lt;/p&gt;
    &lt;p&gt; At this point, I do need two terminals. One runs &lt;code&gt;./make.ts&lt;/code&gt; and shows the log from the benchmark itself, the
            other runs &lt;code&gt;tail -f logs/2.log&lt;/code&gt; to watch the next replica
            to become primary.
          &lt;/p&gt;
    &lt;p&gt;I have definitelly crossed the line where writing a script makes sense, but the neat thing is that the gradual evolution up to this point. There isn’t a discontinuity where I need to spend 15 minutes trying to shape various ad-hoc commands from five terminals into a single coherent script, it was in the file to begin with.&lt;/p&gt;
    &lt;p&gt; And then the script is easy to evolve. Once you realize that it’s a good idea to also run the same benchmark against a different, baseline version TigerBeetle, you replace &lt;code&gt;./tigerbeetle&lt;/code&gt;
            with
            &lt;code&gt;./${tigerbeetle}&lt;/code&gt; and wrap everything into
          &lt;/p&gt;
    &lt;p&gt;A bit more hacking, and you end up with a repeatable benchmark schedule for a matrix of parameters:&lt;/p&gt;
    &lt;p&gt;That’s the gist of it. Don’t let the shell history be your source, capture it into the file first!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46792194</guid><pubDate>Wed, 28 Jan 2026 07:35:51 +0000</pubDate></item><item><title>ASML firing 1700 people, mostly managers</title><link>https://www.ed.nl/binnenland/asml-wil-veel-managementbanen-schrappen-rekent-op-1700-ontslagen~a04807f1/</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46792370</guid><pubDate>Wed, 28 Jan 2026 08:02:42 +0000</pubDate></item></channel></rss>