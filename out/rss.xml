<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 13 Nov 2025 14:10:56 +0000</lastBuildDate><item><title>Digital ID, a new way to create and present an ID in Apple Wallet</title><link>https://www.apple.com/newsroom/2025/11/apple-introduces-digital-id-a-new-way-to-create-and-present-an-id-in-apple-wallet/</link><description>&lt;doc fingerprint="8ece4ba93b33d179"&gt;
  &lt;main&gt;
    &lt;p&gt; UPDATE November 12, 2025 &lt;/p&gt;
    &lt;head rend="h1"&gt;Apple introduces Digital ID, a new way to create and present an ID in Apple Wallet&lt;/head&gt;
    &lt;p&gt; Digital ID offers a secure and private way for users to create an ID in Apple Wallet using information from their U.S. passport, and present their ID with iPhone or Apple Watch &lt;/p&gt;
    &lt;p&gt;Apple today announced the launch of Digital ID, a new way for users to create an ID in Apple Wallet using information from their U.S. passport, and present it with the security and privacy of iPhone or Apple Watch. At launch, Digital ID acceptance will roll out first in beta at TSA checkpoints at more than 250 airports in the U.S. for in-person identity verification during domestic travel, with additional Digital ID acceptance use cases to come in the future. &lt;/p&gt;
    &lt;p&gt;Digital ID gives more people a way to create and present an ID in Apple Wallet even if they do not have a REAL ID-compliant driver’s license or state ID. Digital ID is not a replacement for a physical passport, and cannot be used for international travel and border crossing in lieu of a U.S. passport. &lt;/p&gt;
    &lt;p&gt;“With the launch of Digital ID, we’re excited to expand the ways users can store and present their identity — all with the security and privacy built into iPhone and Apple Watch,” said Jennifer Bailey, Apple’s vice president of Apple Pay and Apple Wallet. “Since introducing the ability to add a driver’s license or state ID to Apple Wallet in 2022, we’ve seen how much users love having their ID right on their devices. Digital IDs brings this secure and convenient option to even more users across the country, as they can now add an ID to Wallet using information from their U.S. passport.” &lt;/p&gt;
    &lt;p&gt;The launch follows the capability for users to add an eligible driver’s license and state ID to Apple Wallet. If users do not have a U.S. passport to create their Digital ID, they can still add an eligible driver’s license to Apple Wallet. &lt;/p&gt;
    &lt;head rend="h2"&gt;Adding Digital ID to Apple Wallet&lt;/head&gt;
    &lt;p&gt;Users can easily create and add a Digital ID to Apple Wallet using a U.S. passport. They start by tapping the Add (+) button at the top of the screen in Wallet on their iPhone and then selecting Driver’s License or ID Cards. They then select Digital ID and follow the onscreen instructions to start the setup and verification process. &lt;/p&gt;
    &lt;p&gt;Users are then asked to use their iPhone to scan the photo page of their physical passport as part of the process. They will also be asked to use their iPhone to read the chip embedded on the back of their passport to ensure the data’s authenticity. From there, they are asked to take a selfie for verification, and as another security step, they will also be prompted to complete a series of facial and head movements during the setup process. Upon verification, their Digital ID is added to Wallet. &lt;/p&gt;
    &lt;head rend="h2"&gt;Using Digital ID in Apple Wallet&lt;/head&gt;
    &lt;p&gt;To present a Digital ID in person, users can double-click the side button or Home button to access Apple Wallet and select Digital ID. From there, they can hold their iPhone or Apple Watch near an identity reader, review the specific information being requested, and use Face ID or Touch ID to authenticate. &lt;/p&gt;
    &lt;p&gt;In the future, users will be able to present their Digital ID at additional select businesses and organizations for identity and age verification in person, in apps, and online. &lt;/p&gt;
    &lt;head rend="h2"&gt;Presenting Digital ID in a Secure and Private Way&lt;/head&gt;
    &lt;p&gt;Like all IDs in Apple Wallet, Digital ID takes advantage of the privacy and security features already built into iPhone and Apple Watch to help protect against tampering and theft. Digital ID data is encrypted. When users create a Digital ID, their passport data is stored on the device. Apple cannot see when and where users present their ID, or what data was presented. Biometric authentication using Face ID or Touch ID also ensures that only the owner of the Digital ID can present it. &lt;/p&gt;
    &lt;p&gt;Only the information needed for a transaction is presented, and the user has the opportunity to review and authorize the information being requested with Face ID or Touch ID before it is shared. Users do not need to unlock, show, or hand over their device to present their ID. &lt;/p&gt;
    &lt;head rend="h2"&gt;Driver’s Licenses and State IDs in Apple Wallet Today&lt;/head&gt;
    &lt;p&gt;The introduction of Digital ID brings users another easy, secure, and private way to create, store, and present an ID in Apple Wallet. &lt;/p&gt;
    &lt;p&gt;Today, the ability to add a driver’s license or state ID to Apple Wallet is live in 12 states and Puerto Rico. In the past six months alone, the feature has come to Montana, North Dakota, and West Virginia, and launched internationally for the first time in Japan with My Number Card on iPhone. &lt;/p&gt;
    &lt;p&gt;For more information on IDs in Apple Wallet, visit learn.wallet.apple/id. &lt;/p&gt;
    &lt;p&gt;Share article&lt;/p&gt;
    &lt;head rend="h2"&gt;Media&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Text of this article&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Media in this article&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45902273</guid><pubDate>Wed, 12 Nov 2025 16:40:17 +0000</pubDate></item><item><title>Helm 4.0</title><link>https://github.com/helm/helm/releases/tag/v4.0.0</link><description>&lt;doc fingerprint="3612007fdbecf4d2"&gt;
  &lt;main&gt;
    &lt;p&gt;The Helm Team is proud to announce the first stable release of Helm 4.&lt;/p&gt;
    &lt;head rend="h2"&gt;New Features&lt;/head&gt;
    &lt;p&gt;Helm 4 has numerous new features, but a few deserve highlighting here:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Redesigned plugin system that supports Web Assembly based plugins&lt;/item&gt;
      &lt;item&gt;Post-renderers are now plugins&lt;/item&gt;
      &lt;item&gt;Server side apply is now supported&lt;/item&gt;
      &lt;item&gt;Improved resource watching, to support waiting, based on kstatus&lt;/item&gt;
      &lt;item&gt;Local Content-based caching (e.g. for charts)&lt;/item&gt;
      &lt;item&gt;Logging via slog enabling SDK logging to integrate with modern loggers&lt;/item&gt;
      &lt;item&gt;Reproducible builds of chart archives&lt;/item&gt;
      &lt;item&gt;Updated SDK API including support for multiple chart API versions (new experimental v3 chart API version coming soon)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For full release notes, please see: https://helm.sh/docs/overview/&lt;/p&gt;
    &lt;head rend="h2"&gt;Compatibility with Helm v3&lt;/head&gt;
    &lt;p&gt;Helm v4 is a major version with backward incompatible changes including to the flags and output of the Helm CLI and to the SDK.&lt;/p&gt;
    &lt;p&gt;Please evaluate the changes to your workflows. The changes are not as extensive as those from Helm v2 to v3, with the goal that the majority of workflows remain compatible between Helm v3 and v4.&lt;/p&gt;
    &lt;p&gt;Helm charts apiVersion v2 (majority of today's charts) will continue to be supported in Helm v4. Existing charts should continue to install, upgrade, and otherwise work. Please test the installation and upgrade of charts to ensure it works as expected. Changes (e.g., server side apply) may impact the experience.&lt;/p&gt;
    &lt;head rend="h2"&gt;Community&lt;/head&gt;
    &lt;p&gt;The community keeps growing, and we'd love to see you there!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Join the discussion in Kubernetes Slack: &lt;list rend="ul"&gt;&lt;item&gt;for questions and just to hang out&lt;/item&gt;&lt;item&gt;for discussing PRs, code, and bugs&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Hang out at the Public Developer Call: Thursday, 9:30 Pacific via Zoom&lt;/item&gt;
      &lt;item&gt;Test, debug, and contribute charts: ArtifactHub/packages&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Installation and Upgrading&lt;/head&gt;
    &lt;p&gt;Download Helm v4.0.0. The common platform binaries are here:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;MacOS amd64 (checksum / 125233cf943e6def2abc727560c5584e9083308d672d38094bae1cc3e0bfeaa2)&lt;/item&gt;
      &lt;item&gt;MacOS arm64 (checksum / 4f5d367af9e2141b047710539d22b7e5872cdaef788333396077236feb422419)&lt;/item&gt;
      &lt;item&gt;Linux amd64 (checksum / c77e9e7c1cc96e066bd240d190d1beed9a6b08060b2043ef0862c4f865eca08f)&lt;/item&gt;
      &lt;item&gt;Linux arm (checksum / 23498ff8f5fb358ad2576269cd41fa9a54b9469332806dff0d689470323180be)&lt;/item&gt;
      &lt;item&gt;Linux arm64 (checksum / 8c5c77e20cc29509d640e208a6a7d2b7e9f99bb04e5b5fbe22707b72a5235245)&lt;/item&gt;
      &lt;item&gt;Linux i386 (checksum / eda0b6508def454ba07e2f938c55f73be795e7f99552078ccc8af2c2bbd58a45)&lt;/item&gt;
      &lt;item&gt;Linux ppc64le (checksum / 73ae83e9888aafa0e9c57a1d4d77dcb6c97c253ef175a4983a8bb4bcc771d2eb)&lt;/item&gt;
      &lt;item&gt;Linux s390x (checksum / 9c7368b18c76fcae9e0281e1ee875ea0d9b5970ac3a00c4eb963205948594bad)&lt;/item&gt;
      &lt;item&gt;Linux riscv64 (checksum / a688c2559c57d6a858c49b9237b7d6bbce5c634aa5204c4342bdc8a06818b9f1)&lt;/item&gt;
      &lt;item&gt;Windows amd64 (checksum / 0f9a8c891b8d908a37fbb68f12dea92b633eb29e49070bd650f5760a1a99aa8d)&lt;/item&gt;
      &lt;item&gt;Windows arm64 (checksum / f3ff262427547cc1b1dc3356d587ed8ffaa23f2abf24bc06660a350b9b7925f9)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Quickstart Guide will get you going from there. For upgrade instructions or detailed installation notes, check the install guide. You can also use a script to install on any system with &lt;code&gt;bash&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;What's Next&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;3.19.3 and 4.0.1 are the next patch releases and will be on December 10, 2025&lt;/item&gt;
      &lt;item&gt;3.20.0 and 4.1.0 is the next minor releases and will be on January 21, 2026&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Thank You!&lt;/head&gt;
    &lt;p&gt;The Helm project has enjoyed code contributions from many community members. Many more community members have assisted by filing issues and working with us to identify and eliminate bugs while adding new features. The #helm-users slack channel has long been a friendly and open forum for getting help and learning more about Helm. We cannot thank you enough for making this a helpful, friendly, and welcoming community for all.&lt;/p&gt;
    &lt;p&gt;❤️ The Helm Team&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45902604</guid><pubDate>Wed, 12 Nov 2025 17:02:38 +0000</pubDate></item><item><title>Project Euler</title><link>https://projecteuler.net</link><description>&lt;doc fingerprint="8438e19922bbe329"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;About Project Euler&lt;/head&gt;
    &lt;head rend="h3"&gt;What is Project Euler?&lt;/head&gt;
    &lt;p&gt;Project Euler is a series of challenging mathematical/computer programming problems that will require more than just mathematical insights to solve. Although mathematics will help you arrive at elegant and efficient methods, the use of a computer and programming skills will be required to solve most problems.&lt;lb/&gt; The motivation for starting Project Euler, and its continuation, is to provide a platform for the inquiring mind to delve into unfamiliar areas and learn new concepts in a fun and recreational context.&lt;/p&gt;
    &lt;head rend="h3"&gt;Who are the problems aimed at?&lt;/head&gt;
    &lt;p&gt;The intended audience include students for whom the basic curriculum is not feeding their hunger to learn, adults whose background was not primarily mathematics but had an interest in things mathematical, and professionals who want to keep their problem solving and mathematics on the cutting edge.&lt;/p&gt;
    &lt;p&gt;Currently we have 1365127 registered members who have solved at least one problem, representing 220 locations throughout the world, and collectively using 113 different programming languages to solve the problems.&lt;/p&gt;
    &lt;head rend="h3"&gt;Can anyone solve the problems?&lt;/head&gt;
    &lt;p&gt;The problems range in difficulty and for many the experience is inductive chain learning. That is, by solving one problem it will expose you to a new concept that may allow you to undertake a previously inaccessible problem. So determined participants will be able to slowly but surely work their way through the problems.&lt;/p&gt;
    &lt;head rend="h3"&gt;What next?&lt;/head&gt;
    &lt;p&gt;In order to track your progress it is necessary to setup an account and have Cookies enabled.&lt;/p&gt;
    &lt;p&gt;If you already have an account, then Sign In. Otherwise, please Register – it's completely free!&lt;/p&gt;
    &lt;p&gt;However, as the problems are challenging, you may wish to view the Problems before registering.&lt;/p&gt;
    &lt;p&gt;"Project Euler exists to encourage, challenge, and develop the skills and enjoyment of anyone with an interest in the fascinating world of mathematics."&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45902898</guid><pubDate>Wed, 12 Nov 2025 17:24:54 +0000</pubDate></item><item><title>Launch HN: JSX Tool (YC F25) – A Browser Dev-Panel IDE for React</title><link>https://news.ycombinator.com/item?id=45903161</link><description>&lt;doc fingerprint="ae4ab77c7123cd5c"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hi HN, We’re Jamie &amp;amp; Dan, building JSX Tool (&lt;/p&gt;https://jsxtool.com&lt;p&gt;) a new inspector/dev panel IDE that allows you to navigate to any line of your React project’s JSX with just a click and a command click to explore your render stack.&lt;/p&gt;&lt;p&gt;Demo video: https://www.youtube.com/watch?v=JIIXvN7vhrs&lt;/p&gt;&lt;p&gt;I’ve been writing React code for nearly a decade. Since I first saw source maps in the days of Babel and Redux, I’ve always wanted to be able to edit my code from the source maps. I’ve also always wanted to be able to inspect my JSX like it was HTML.&lt;/p&gt;&lt;p&gt;Last year, I found my first real use of AI was taking ad-hoc CSS changes in the Chrome element inspector, pasting them into ChatGPT, and asking for the equivalent in Tailwind. I’d then paste those changes into my React TSX files.&lt;/p&gt;&lt;p&gt;I wanted to streamline this process but came to the conclusion that to do so I needed to build a JSX inspector. I had to write a custom AST parser to create a mapping between the JSX and HTML. So I hacked on an inspector for a couple of months that connected JSX to the DOM in both directions.&lt;/p&gt;&lt;p&gt;The next feature was adding a CSS editor, like the one in the browser inspectors but for JSX. Unlike styling a piece of HTML I decided that any in memory style edits to a React fiber should be globally applied, as if you had tweaked that line of code in your codebase.&lt;/p&gt;&lt;p&gt;Finally, I was able to add the two AI features I really wanted: (1) prompt for in-memory styles for when I was pixel tweaking, and (2) save those temporary changes back to my codebase in the convention of the codebase I was working in.&lt;/p&gt;&lt;p&gt;To accomplish talking to the filesystem from the Chrome extension I built a little local server that mounts from the root of your project and allows the extension to send file-system commands back to your project root. We named this the “Dev Server”. (Note: You can fully use us as a JSX inspector without this server installed.)&lt;/p&gt;&lt;p&gt;After all that, I found that to convert myself as a user I needed it to be a pretty fully functional IDE. I needed vim bindings, I needed a typechecker, I needed auto-complete, I needed a linter, I needed code search and I needed a proper file explorer. Fortunately we were able to take advantage of the dev-server architecture we had stumbled onto in order to add an LSP server and Rip Grep. At this point, after months of dog fooding, I use JSX Tool for almost all of my website edits.&lt;/p&gt;&lt;p&gt;We’re still rough around the edges for mobile but we’re working on that.&lt;/p&gt;&lt;p&gt;All of the IDE stuff not involving AI is free and works fine without AI. We let you get a taste of the prompting stuff for free but apply some rate limits.&lt;/p&gt;&lt;p&gt;The extension itself is not open source but the dev server with the LSP is. It’s a great foundation if you want to build any sort of in-browser IDE and it's nearly React agnostic. Building the dev server was a big undertaking so I’d love to see someone fork it and find value in it.&lt;/p&gt;&lt;p&gt;In the future we want to start adding things that we are in a position to take advantage of over something like Cursor, such as letting AI give you code suggestions for runtime exceptions or work with the network logs. We think that the convenience of having your IDE in the dev panel gives us a leg up in convenience and workflow context.&lt;/p&gt;&lt;p&gt;Anyway, regardless of how you feel about AI coding, I wanted to make something that was useful with or without AI. We’d love it if you gave it a spin and we want to share anything we can about the technical side of the product that you might find interesting.&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45903161</guid><pubDate>Wed, 12 Nov 2025 17:43:42 +0000</pubDate></item><item><title>Steam Frame</title><link>https://store.steampowered.com/sale/steamframe</link><description>&lt;doc fingerprint="97fc7fa59f8fbace"&gt;
  &lt;main&gt;&lt;p&gt; Install Steam &lt;/p&gt; login | language &lt;p&gt; 简体中文 (Simplified Chinese) 繁體中文 (Traditional Chinese) 日本語 (Japanese) 한국어 (Korean) ไทย (Thai) Български (Bulgarian) Čeština (Czech) Dansk (Danish) Deutsch (German) Español - España (Spanish - Spain) Español - Latinoamérica (Spanish - Latin America) Ελληνικά (Greek) Français (French) Italiano (Italian) Bahasa Indonesia (Indonesian) Magyar (Hungarian) Nederlands (Dutch) Norsk (Norwegian) Polski (Polish) Português (Portuguese - Portugal) Português - Brasil (Portuguese - Brazil) Română (Romanian) Русский (Russian) Suomi (Finnish) Svenska (Swedish) Türkçe (Turkish) Tiếng Việt (Vietnamese) Українська (Ukrainian) Report a translation problem &lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45903325</guid><pubDate>Wed, 12 Nov 2025 17:54:58 +0000</pubDate></item><item><title>Steam Machine</title><link>https://store.steampowered.com/sale/steammachine</link><description>&lt;doc fingerprint="97fc7fa59f8fbace"&gt;
  &lt;main&gt;&lt;p&gt; Install Steam &lt;/p&gt; login | language &lt;p&gt; 简体中文 (Simplified Chinese) 繁體中文 (Traditional Chinese) 日本語 (Japanese) 한국어 (Korean) ไทย (Thai) Български (Bulgarian) Čeština (Czech) Dansk (Danish) Deutsch (German) Español - España (Spanish - Spain) Español - Latinoamérica (Spanish - Latin America) Ελληνικά (Greek) Français (French) Italiano (Italian) Bahasa Indonesia (Indonesian) Magyar (Hungarian) Nederlands (Dutch) Norsk (Norwegian) Polski (Polish) Português (Portuguese - Portugal) Português - Brasil (Portuguese - Brazil) Română (Romanian) Русский (Russian) Suomi (Finnish) Svenska (Swedish) Türkçe (Turkish) Tiếng Việt (Vietnamese) Українська (Ukrainian) Report a translation problem &lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45903404</guid><pubDate>Wed, 12 Nov 2025 17:59:43 +0000</pubDate></item><item><title>GPT-5.1: A smarter, more conversational ChatGPT</title><link>https://openai.com/index/gpt-5-1/</link><description>&lt;doc fingerprint="9d1fea781db6c8bf"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;GPT-5.1: A smarter, more conversational ChatGPT&lt;/head&gt;
    &lt;p&gt;We’re upgrading GPT‑5 while making it easier to customize ChatGPT. Starting to roll out today to everyone, beginning with paid users.&lt;/p&gt;
    &lt;p&gt;Today we’re upgrading the GPT‑5 series with the release of:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GPT‑5.1 Instant: our most-used model, now warmer, more intelligent, and better at following your instructions.&lt;/item&gt;
      &lt;item&gt;GPT‑5.1 Thinking: our advanced reasoning model, now easier to understand and faster on simple tasks, more persistent on complex ones.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We heard clearly from users that great AI should not only be smart, but also enjoyable to talk to. GPT‑5.1 improves meaningfully on both intelligence and communication style.&lt;/p&gt;
    &lt;p&gt;We’re also making it easier for you to shape ChatGPT’s tone. Preferences on chat style vary—from person to person and even from conversation to conversation—so we’re introducing more intuitive and effective controls so ChatGPT can better match the tone you want in responses.&lt;/p&gt;
    &lt;p&gt;GPT‑5.1 Instant, ChatGPT’s most used model, is now warmer by default and more conversational. Based on early testing, it often surprises people with its playfulness while remaining clear and useful.&lt;/p&gt;
    &lt;head rend="h2"&gt;GPT-5&lt;/head&gt;
    &lt;head rend="h2"&gt;GPT-5.1 Instant&lt;/head&gt;
    &lt;p&gt;We’ve also improved instruction following, so the model more reliably answers the question you actually asked.&lt;/p&gt;
    &lt;head rend="h2"&gt;GPT-5&lt;/head&gt;
    &lt;head rend="h2"&gt;GPT-5.1 Instant&lt;/head&gt;
    &lt;p&gt;For the first time, GPT‑5.1 Instant can use adaptive reasoning to decide when to think before responding to more challenging questions, resulting in more thorough and accurate answers, while still responding quickly. This is reflected in significant improvements on math and coding evaluations like AIME 2025 and Codeforces.&lt;/p&gt;
    &lt;p&gt;We’re also upgrading GPT‑5 Thinking to make it more efficient and easier to understand in everyday use. It now adapts its thinking time more precisely to the question—spending more time on complex problems while responding more quickly to simpler ones. In practice, that means more thorough answers for difficult requests and less waiting for simpler ones.&lt;/p&gt;
    &lt;p&gt;GPT‑5.1 Thinking’s responses are also clearer, with less jargon and fewer undefined terms. This makes our most capable model more approachable and easily understandable, especially for complex tasks at work and explaining technical concepts.&lt;/p&gt;
    &lt;head rend="h2"&gt;GPT-5&lt;/head&gt;
    &lt;head rend="h2"&gt;GPT-5.1 Thinking&lt;/head&gt;
    &lt;p&gt;GPT‑5.1 Thinking’s default tone is also warmer and more empathetic.&lt;/p&gt;
    &lt;head rend="h2"&gt;GPT-5&lt;/head&gt;
    &lt;head rend="h2"&gt;GPT-5.1 Thinking&lt;/head&gt;
    &lt;p&gt;This release is a step forward in both capability and usability across the models. GPT‑5.1 Auto will continue to route each query to the model best suited for it, so in most cases, you won’t need to choose a model at all. What you will notice is that answers across GPT‑5.1 feel both smarter and more natural in tone.&lt;/p&gt;
    &lt;p&gt;GPT‑5.1 Instant and Thinking begin rolling out today, starting with paid (Pro, Plus, Go, Business) users and then to free and logged-out users. Enterprise and Edu plans get a seven-day early-access toggle (off by default). After that window, GPT‑5.1 will become the sole default model.&lt;/p&gt;
    &lt;p&gt;If you check ChatGPT today, you may not see GPT‑5.1 available immediately. We plan to roll it out gradually over the next few days to help keep performance stable for everyone. We will also update GPT‑5 Pro to GPT‑5.1 Pro soon.&lt;/p&gt;
    &lt;p&gt;We’re bringing both GPT‑5.1 Instant and GPT‑5.1 Thinking to the API later this week. GPT‑5.1 Instant will be added as gpt-5.1-chat-latest, and GPT‑5.1 Thinking will be released as GPT‑5.1 in the API, both with adaptive reasoning.&lt;/p&gt;
    &lt;p&gt;GPT‑5 (Instant and Thinking) will remain available in ChatGPT under the legacy models dropdown for paid subscribers for three months, so people have time to compare and adapt at their own pace. The GPT‑5 sunset period does not affect the availability of other legacy models. Going forward, when we introduce new ChatGPT models, our approach is to give people ample space to evaluate what’s changed and share feedback, allowing us to continue innovating our frontier models while transitioning smoothly. Sunset periods will be communicated clearly and with plenty of advance notice.&lt;/p&gt;
    &lt;p&gt;GPT‑5.1 is more capable and useful, and we encourage you to try it and see the difference. Our system card addendum includes more information on our safety approach for GPT‑5.1.&lt;/p&gt;
    &lt;p&gt;And a note on naming: this update is called GPT‑5.1 to reflect meaningful improvements, while remaining within the GPT‑5 generation. Future iterative upgrades to GPT‑5 will follow the same pattern.&lt;/p&gt;
    &lt;p&gt;Alongside these model improvements, we’re making it easier to customize ChatGPT’s tone and style. People have strong and varied preferences in how ChatGPT should respond, and tailoring its tone to what sounds right for you should feel effortless.&lt;/p&gt;
    &lt;p&gt;Earlier this year, we added preset options to tailor the tone of how ChatGPT responds. Today, we’re refining those options to better reflect the most common ways people use ChatGPT. Default, Friendly (formerly Listener), and Efficient (formerly Robot) remain (with updates), and we’re adding Professional, Candid, and Quirky. These options are designed to align with what we’ve learned about how people naturally steer the model, making it quick and intuitive to choose a personality that feels uniquely right.&lt;/p&gt;
    &lt;p&gt;These personality settings apply across all models. The original Cynical (formerly Cynic) and Nerdy (formerly Nerd) options we introduced earlier this year will remain available unchanged under the same dropdown in personalization settings.&lt;/p&gt;
    &lt;p&gt;Beyond these presets, for users who want more granular control over how ChatGPT responds, we’re also experimenting with the ability to tune ChatGPT’s characteristics directly from personalization settings—including how concise, warm, or scannable its responses are, and how frequently it uses emojis. ChatGPT can also proactively offer to update these preferences during conversations when it notices you asking for a certain tone or style, without requiring you to navigate into settings. You can adjust or remove any of these preferences at any time.&lt;/p&gt;
    &lt;p&gt;The updated styles and tone options are rolling out today, and the ability to finetune specific characteristics is starting to roll out gradually later this week as an experiment, starting with a limited number of users. Both will continue to improve over time. Additionally, the updated GPT‑5.1 models are also better at adhering to custom instructions, giving you even more precise control over tone and behavior.&lt;/p&gt;
    &lt;p&gt;Updates you make in personalization settings now take effect across all chats right away, including ongoing conversations, so your experience stays consistent. Before, changes to base style and tone or custom instructions only applied to conversations started afterward.&lt;/p&gt;
    &lt;p&gt;Today’s GPT‑5.1 updates and new customization options are a step toward a ChatGPT that feels like it fits you—smarter, more enjoyable to talk to, and more adaptable to your preferences. Going forward, we’ll continue improving along these dimensions—there’s much more to come.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45904551</guid><pubDate>Wed, 12 Nov 2025 19:05:41 +0000</pubDate></item><item><title>GLP-1 drugs linked to lower death rates in colon cancer patients</title><link>https://today.ucsd.edu/story/glp-1-drugs-linked-to-dramatically-lower-death-rates-in-colon-cancer-patients</link><description>&lt;doc fingerprint="f6fa41ae60c98de2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;GLP-1 Drugs Linked to Dramatically Lower Death Rates in Colon Cancer Patients&lt;/head&gt;
    &lt;head rend="h2"&gt;Story by:&lt;/head&gt;
    &lt;head rend="h2"&gt;Published Date&lt;/head&gt;
    &lt;head rend="h2"&gt;Story by:&lt;/head&gt;
    &lt;head rend="h2"&gt;Topics covered:&lt;/head&gt;
    &lt;head rend="h2"&gt;Share This:&lt;/head&gt;
    &lt;head rend="h2"&gt;Article Content&lt;/head&gt;
    &lt;p&gt;A new University of California San Diego study offers compelling evidence that GLP-1 receptor agonists — the class of drugs behind Ozempic, Wegovy and Mounjaro, for example — may do more than regulate blood sugar and weight. In an analysis of more than 6,800 colon cancer patients across all University of California Health sites, researchers found that those taking glucagon-like peptide-1 (GLP-1) medications were less than half as likely to die within five years compared to those who weren’t on the drugs (15.5% vs. 37.1%).&lt;/p&gt;
    &lt;p&gt;The study, led by Raphael Cuomo, Ph.D., associate professor in the Department of Anesthesiology at UC San Diego School of Medicine and member of UC San Diego Moores Cancer Center, used real-world clinical data from the University of California Health Data Warehouse to assess outcomes across the state’s academic medical centers. After adjusting for age, body mass index (BMI), disease severity and other health factors, GLP-1 users still showed significantly lower odds of death, suggesting a strong and independent protective effect.&lt;/p&gt;
    &lt;p&gt;The survival benefit appeared most pronounced in patients with very high BMI (over 35), hinting that GLP-1 drugs may help counteract the inflammatory and metabolic conditions that worsen colon cancer prognosis. Researchers believe several biological mechanisms could explain the link. Beyond regulating blood sugar, GLP-1 receptor agonists reduce systemic inflammation, improve insulin sensitivity and promote weight loss — all factors that can dampen tumor-promoting pathways. Laboratory studies also suggest that GLP-1 drugs may directly prevent cancer cell growth, trigger cancer cell death and reshape the tumor microenvironment. However, the study authors emphasize that more research is needed to confirm these mechanisms and determine whether the survival benefit observed in this real-world analysis represents a direct anti-cancer effect or an indirect result of improved metabolic health.&lt;/p&gt;
    &lt;p&gt;Cuomo notes that while these results are observational, they underscore an urgent need for clinical trials to test whether GLP-1 drugs can improve cancer survival rates, especially for patients with obesity-related cancers.&lt;/p&gt;
    &lt;p&gt;The study appeared in Cancer Investigation on Nov. 11, 2025.&lt;/p&gt;
    &lt;head rend="h2"&gt;You May Also Like&lt;/head&gt;
    &lt;head rend="h2"&gt;Stay in the Know&lt;/head&gt;
    &lt;p&gt;Keep up with all the latest from UC San Diego. Subscribe to the newsletter today.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45905408</guid><pubDate>Wed, 12 Nov 2025 19:50:32 +0000</pubDate></item><item><title>Homebrew no longer allows bypassing Gatekeeper for unsigned/unnotarized software</title><link>https://github.com/Homebrew/brew/issues/20755</link><description>&lt;doc fingerprint="760419b45cb6b368"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Notifications &lt;tool-tip&gt;You must be signed in to change notification settings&lt;/tool-tip&gt;&lt;/item&gt;
      &lt;item&gt;Fork 10.7k&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Description&lt;/head&gt;
    &lt;head rend="h3"&gt;Verification&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; This issue's title and/or description do not reference a single formula e.g. &lt;code&gt;brew install wget&lt;/code&gt;. If they do, open an issue at https://github.com/Homebrew/homebrew-core/issues/new/choose instead.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Provide a detailed description of the proposed feature&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;--no-quarantine&lt;/code&gt; is used to forcibly bypass Gatekeeper, which is a built-in macOS security mechanism. This is used to run unsigned/unnotarized applications.&lt;/p&gt;
    &lt;p&gt;macOS Tahoe is the final release to support Intel systems, and last year Apple updated macOS runtime protection to make it harder to override Gatekeeper. Macs with Apple silicon also don't "permit native arm64 code to execute unless a valid signature is attached". Finally, we are ending support for all casks that fail Gatekeeper checks on September 1st, 2026.&lt;/p&gt;
    &lt;p&gt;With the above in mind, it's time to deprecate the &lt;code&gt;--no-quarantine&lt;/code&gt; flag from &lt;code&gt;brew&lt;/code&gt;. It intentionally bypasses macOS security mechanisms, which we already actively discourage. Deprecating now will give a decent lead time for users using it to come up with another solution or adjust their workflows.&lt;/p&gt;
    &lt;head rend="h3"&gt;What is the motivation for the feature?&lt;/head&gt;
    &lt;p&gt;Intel support is coming to an end from both Apple and Homebrew. This flag is primarily used to override a macOS security mechanism, which we do not want to encourage. Since we are requiring casks fulfill Gatekeeper checks next year, there is no reason to keep this flag.&lt;/p&gt;
    &lt;head rend="h3"&gt;How will the feature be relevant to at least 90% of Homebrew users?&lt;/head&gt;
    &lt;p&gt;We will provide a safer experience for our users, and stop making it easier to bypass OS-level security.&lt;/p&gt;
    &lt;head rend="h3"&gt;What alternatives to the feature have been considered?&lt;/head&gt;
    &lt;p&gt;None. Macs with Apple silicon are the platform that will be supported in the future, and Apple is making it harder to bypass Gatekeeper as is.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45907259</guid><pubDate>Wed, 12 Nov 2025 21:50:14 +0000</pubDate></item><item><title>Marble: A Multimodal World Model</title><link>https://www.worldlabs.ai/blog/marble-world-model</link><description>&lt;doc fingerprint="1815cb1fadd45c6f"&gt;
  &lt;main&gt;
    &lt;p&gt;November 12, 2025Marble, our frontier multimodal world model, is available to everyone starting today&lt;/p&gt;
    &lt;head rend="h1"&gt;Marble: A Multimodal World Model&lt;/head&gt;
    &lt;p&gt;Spatial intelligence is the next frontier in AI, demanding powerful world models to realize its full potential. World models should reconstruct, generate, and simulate 3D worlds; and allow both humans and agents to interact with them. Spatially intelligent world models will transform a wide variety of industries over the coming years.&lt;/p&gt;
    &lt;p&gt;Two months ago we shared a preview of Marble, our World Model that creates 3D worlds from image or text prompts. Since then, Marble has been available to an early set of beta users to create 3D worlds for themselves.&lt;/p&gt;
    &lt;p&gt;Today we are making Marble, a first-in-class generative multimodal world model, generally available for anyone to use. We have also drastically expanded Marble's capabilities, and are excited to highlight them here:&lt;/p&gt;
    &lt;p&gt;Multimodal Marble: Marble is now massively multimodal. Marble can create 3D worlds from text, images, video, or coarse 3D layouts; Marble also lets you interactively edit, expand, and combine worlds. Once generated, 3D worlds can be exported as Gaussian splats, meshes, or videos. These new capabilities let users create and edit worlds with fine-grained control; and makes those worlds more useful than ever before.&lt;/p&gt;
    &lt;p&gt;Marble Labs: We are launching Marble Labs, a creative hub where imagination meets experimentation. It is where artists, engineers, and designers push the boundaries of world models, showcasing bold ideas, real-world workflows, and new possibilities across gaming, VFX, design, robotics, and beyond. Marble Labs is also home to in-depth case studies, tutorials, and documentation that give anyone the tools to learn, build, and share their own 3D worlds.&lt;/p&gt;
    &lt;p&gt;Sign up at marble.worldlabs.ai and start creating worlds for yourself!&lt;/p&gt;
    &lt;head rend="h2"&gt;The Marble World Model&lt;/head&gt;
    &lt;p&gt;Our human experience of the world is inherently multimodal: we use all of our senses to make sense of the world around us. We integrate sight, sound, touch, and language to build up a mental model of the outside world; these different representations work together, enriching and reinforcing each other to let us reason about the world and act within it.&lt;/p&gt;
    &lt;p&gt;World models should work similarly. They should be massively multimodal, able to lift whatever input signals are available into a full 3D world, and they should be able to iteratively update their understanding of the world as new information becomes available.&lt;/p&gt;
    &lt;p&gt;Marble is the first of its kind - a next-generation world model making strides toward this vision. It can now create 3D worlds from a wide variety of input types, and lets users iteratively edit or expand worlds.&lt;/p&gt;
    &lt;p&gt;Marble's new capabilities let you dive as deep as you want in controlling your generated worlds. You can quickly create full 3D worlds from a simple image or text prompt or interactively edit worlds in both 2D and 3D, bringing to life a precise vision of a world in your mind.&lt;/p&gt;
    &lt;head rend="h2"&gt;Text and Image to World&lt;/head&gt;
    &lt;p&gt;To start, Marble can create a full 3D world from a single image or a short text prompt. This is the simplest and easiest way to create worlds. Marble can generate worlds with a wide variety of scene types and artistic styles.&lt;/p&gt;
    &lt;p&gt;Image prompts make it easy to combine Marble with other AI tools. You can generate images with your favorite image generation model, then bring it to Marble to lift it to a full 3D world.&lt;/p&gt;
    &lt;p&gt;Text and image prompts are intuitive and powerful, but limited in creative control: Marble must invent all the details of the world that are not present in the input text or image prompt. This is often magical; but sometimes you may want to steer Marble more directly toward a desired world.&lt;/p&gt;
    &lt;head rend="h2"&gt;Multi-Image and Video to World&lt;/head&gt;
    &lt;p&gt;An easy way to create worlds with more creative control is multi-image prompting. Marble can accept different prompt images for different parts of the world, stitching them together into a unified 3D world.&lt;/p&gt;
    &lt;p&gt;Multi-image prompts let you create worlds with more precision. Unlike text or single-image prompts where Marble must invent all parts of the world not present in the prompt, with multi-image prompts you can control what the generated world will look like from different angles.&lt;/p&gt;
    &lt;p&gt;This leads to a brand-new workflow for generating worlds. You can use your favorite image generation tool to iterate separately on the input views, and Marble will lift them into full 3D worlds while also adding seamless transitions between the input views.&lt;/p&gt;
    &lt;p&gt;Multi-image prompts can also be used to create worlds inspired by real-world spaces. Marble can input a few photos or a short video depicting a real-world location from different angles, and it will combine them to generate a 3D world with elements of the real-world space.&lt;/p&gt;
    &lt;head rend="h2"&gt;World Editing&lt;/head&gt;
    &lt;p&gt;The creative process is highly iterative for many users. Often, generating a world is only the start of a creative journey. Seeing a generated 3D world often kicks off a dozen more ideas for changing it or improving it.&lt;/p&gt;
    &lt;p&gt;Marble includes AI-native world editing tools. Edits can be small and local: remove an object, touch up an area. They can also be more drastic: swap objects, change the visual style, or re-structure large parts of the world. This gives a new level of fine-grained control to the world creation process.&lt;/p&gt;
    &lt;p&gt;Edited&lt;/p&gt;
    &lt;p&gt;Original&lt;/p&gt;
    &lt;p&gt;Edited&lt;/p&gt;
    &lt;p&gt;Original&lt;/p&gt;
    &lt;p&gt;Edited&lt;/p&gt;
    &lt;p&gt;Original&lt;/p&gt;
    &lt;p&gt;World editing lets you re-imagine the same space in endless different ways.&lt;/p&gt;
    &lt;p&gt;Edited&lt;/p&gt;
    &lt;p&gt;Original&lt;/p&gt;
    &lt;p&gt;Edited&lt;/p&gt;
    &lt;p&gt;Original&lt;/p&gt;
    &lt;p&gt;Edited&lt;/p&gt;
    &lt;p&gt;Original&lt;/p&gt;
    &lt;p&gt;Edited&lt;/p&gt;
    &lt;p&gt;Original&lt;/p&gt;
    &lt;p&gt;Edited&lt;/p&gt;
    &lt;p&gt;Original&lt;/p&gt;
    &lt;head rend="h2"&gt;Chisel: Sculpting Worlds in 3D&lt;/head&gt;
    &lt;p&gt;Marble's multimodal inputs and editing features give a lot of control over your generated 3D worlds. But sometimes, creating the world exactly as you see it in your mind's eye requires finer-grained control over the scene layout or exact sizes and positions of objects.&lt;/p&gt;
    &lt;p&gt;For these situations we are introducing Chisel, an AI-native tool to sculpt Marble worlds directly in 3D.&lt;/p&gt;
    &lt;p&gt;Chisel is a new experimental editing mode for advanced users to create 3D worlds. It lets you lay out the coarse structure of your world in 3D using coarse 3D shapes like boxes or planes, or importing existing 3D assets into the scene.&lt;/p&gt;
    &lt;p&gt;After laying out the coarse 3D scene, you can add a text prompt to describe the visual style of the scene, or additional elements not present in the coarse layout. Marble will combine these inputs to give you a fully detailed 3D world.&lt;/p&gt;
    &lt;p&gt;Chisel decouples structure from style. The coarse 3D scene determines the world's structure, while the text prompt controls its overall style. The two can be mixed in any combination, adding a whole new dimension of control to world generation.&lt;/p&gt;
    &lt;p&gt;Generated World&lt;/p&gt;
    &lt;p&gt;Coarse 3D&lt;/p&gt;
    &lt;p&gt;Coarse 3D After&lt;/p&gt;
    &lt;p&gt;Coarse 3D Before&lt;/p&gt;
    &lt;p&gt;Generated World After&lt;/p&gt;
    &lt;p&gt;Generated World Before&lt;/p&gt;
    &lt;p&gt;The coarse 3D scene can be as simple or complex as you want. In addition to building the coarse 3D scene out of basic blocks and walls, you can import existing 3D assets of objects. Objects will be restyled based on the text prompt to give a cohesive 3D world.&lt;/p&gt;
    &lt;p&gt;Varying the text prompt can give rise to 3D worlds with drastically different visual styles and appearances that all share a common structure determined by the coarse 3D scene.&lt;/p&gt;
    &lt;p&gt;Generated World&lt;/p&gt;
    &lt;p&gt;Coarse 3D&lt;/p&gt;
    &lt;p&gt;Generated World&lt;/p&gt;
    &lt;p&gt;Coarse 3D&lt;/p&gt;
    &lt;p&gt;Generated World&lt;/p&gt;
    &lt;p&gt;Coarse 3D&lt;/p&gt;
    &lt;p&gt;Generated World&lt;/p&gt;
    &lt;p&gt;Coarse 3D&lt;/p&gt;
    &lt;p&gt;Generated World&lt;/p&gt;
    &lt;p&gt;Coarse 3D&lt;/p&gt;
    &lt;p&gt;Generated World&lt;/p&gt;
    &lt;p&gt;Coarse 3D&lt;/p&gt;
    &lt;head rend="h2"&gt;Building Large Worlds by Expanding and Composing&lt;/head&gt;
    &lt;p&gt;Sometimes bigger really is better. Larger worlds give more possibilities, more space, more room for your creativity to shine. Marble offers two ways to make bigger worlds than ever before.&lt;/p&gt;
    &lt;p&gt;After a world has been generated, Marble allows one-step expansion to make it larger. You are in control of this process: you can select a region of the world to be expanded, and Marble will create more content to fill the selected region.&lt;/p&gt;
    &lt;p&gt;Expansion can make worlds larger. Regions of the world that previously broke down into artifacts can become crisp and clean after expansion. Expansion can also be used to add detail to targeted regions of a world. Sometimes the back of a table or the far corner of a room is not a crisp as the room's center; expanding the world in that region can improve it.&lt;/p&gt;
    &lt;p&gt;Expanded World&lt;/p&gt;
    &lt;p&gt;Initial World&lt;/p&gt;
    &lt;p&gt;Expanded World&lt;/p&gt;
    &lt;p&gt;Initial World&lt;/p&gt;
    &lt;p&gt;Expanded World&lt;/p&gt;
    &lt;p&gt;Initial World&lt;/p&gt;
    &lt;p&gt;Expanded World&lt;/p&gt;
    &lt;p&gt;Initial World&lt;/p&gt;
    &lt;p&gt;In addition to generating individual worlds, you can compose any number of worlds to build out extremely large spaces with Marble's composer mode. This composition is entirely under your control: you can choose exactly which worlds to compose, and exactly how to lay them out relative to each other. Composing is yet another way to build worlds that follow your creative vision.&lt;/p&gt;
    &lt;head rend="h2"&gt;Exporting Worlds to 3D and Video&lt;/head&gt;
    &lt;p&gt;After creating a world with Marble you have many options to export it for incorporation into downstream projects.&lt;/p&gt;
    &lt;p&gt;Gaussian splats are the highest-fidelity representation for Marble worlds. They represent 3D scenes as a large set of semitransparent particles. You can render Gaussian splats in the browser using Spark, our open-source cross-platform renderer integrated with THREE.js.&lt;/p&gt;
    &lt;p&gt;Marble worlds can also be exported as triangle meshes. Marble can generate both collider meshes, which are low-fidelity meshes intended for coarse physics simulation; and high-quality meshes which are intended to match the visual fidelity of Gaussian splats as closely as possible. Exporting worlds as meshes lets them interoperate with many industry-standard tools.&lt;/p&gt;
    &lt;p&gt;Mesh&lt;/p&gt;
    &lt;p&gt;Splats&lt;/p&gt;
    &lt;p&gt;Mesh with lighting&lt;/p&gt;
    &lt;p&gt;Mesh with lighting&lt;/p&gt;
    &lt;p&gt;Marble worlds exist in full 3D, but sometimes a video is the best way to share a world. You can use Marble to render generated worlds to videos with pixel-accurate camera control, letting you frame every shot just as you imagine it. In fact, nearly all the videos in this post were generated directly from Marble.&lt;/p&gt;
    &lt;p&gt;Marble can also enhance exported videos. Enhanced videos can add detail, remove artifacts, and add dynamic elements to the scene, while maintaining pixel-perfect camera control and adhering to the structure of the generated 3D world.&lt;/p&gt;
    &lt;p&gt;Enhanced Video&lt;/p&gt;
    &lt;p&gt;Original Video&lt;/p&gt;
    &lt;p&gt;Enhanced Video&lt;/p&gt;
    &lt;p&gt;Original Video&lt;/p&gt;
    &lt;p&gt;Enhanced Video&lt;/p&gt;
    &lt;p&gt;Original Video&lt;/p&gt;
    &lt;head rend="h2"&gt;Marble Labs: A Glimpse of Future Possibilities&lt;/head&gt;
    &lt;p&gt;While flexing your creativity in Marble, Marble Labs may further inspire your imagination. This is where artists, engineers, and designers are already shaping what comes next. From cinematic filmmaking and interactive worlds to robotics simulations and therapeutic environments, these projects show how Marble is transforming imagination into reality. Each one reflects a new way of building with world models, both creative and technical. Explore Marble Labs to see what others are creating and discover how you can start building your own worlds today.&lt;/p&gt;
    &lt;head rend="h2"&gt;From Marble to Spatial Intelligence&lt;/head&gt;
    &lt;p&gt;Marble is a state-of-the-art generative world model. Today it lets you create worlds from diverse input types, edit them, expand them, and export them. These capabilities give you unprecedented levels of control when creating worlds, and are already enabling a wide variety of creative use cases across industries.&lt;/p&gt;
    &lt;p&gt;But Marble is just a step on our journey toward spatial intelligence. Going forward, a key opportunity is interactivity. Future world models will let humans and agents alike interact with generated worlds in new ways, unlocking even more use cases in simulation, robotics, and beyond.&lt;/p&gt;
    &lt;head rend="h2"&gt;Try Marble Today&lt;/head&gt;
    &lt;p&gt;Marble is available today at marble.worldlabs.ai. Sign up now and start creating worlds!&lt;/p&gt;
    &lt;p&gt;If you are excited about this vision and want to help us build it, join us!&lt;/p&gt;
    &lt;head rend="h2"&gt;Read More&lt;/head&gt;
    &lt;p&gt;November 10, 2025&lt;/p&gt;
    &lt;head rend="h3"&gt;From Words to Worlds: Spatial Intelligence is AI’s Next Frontier&lt;/head&gt;
    &lt;p&gt;A manifesto piece explaining what spatial intelligence is, why it matters, and how we’re building the world models that will unlock it—with impact that will reshape creativity, embodied intelligence, and human progress.&lt;/p&gt;
    &lt;p&gt;October 16, 2025&lt;/p&gt;
    &lt;head rend="h3"&gt;RTFM: A Real-Time Frame Model&lt;/head&gt;
    &lt;p&gt;A research preview of RTFM, a new generative world model that generates video in real-time as you interact with it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45907541</guid><pubDate>Wed, 12 Nov 2025 22:11:14 +0000</pubDate></item><item><title>Valve is about to win the console generation</title><link>https://xeiaso.net/blog/2025/valve-is-about-to-win-the-console-generation/</link><description>&lt;doc fingerprint="4e7e82b81462420f"&gt;
  &lt;main&gt;
    &lt;p&gt;Making sure you're not a bot! Loading... Please wait a moment while we ensure the security of your connection.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45908464</guid><pubDate>Wed, 12 Nov 2025 23:35:41 +0000</pubDate></item><item><title>Google will allow users to sideload Android apps without verification</title><link>https://android-developers.googleblog.com/2025/11/android-developer-verification-early.html</link><description>&lt;doc fingerprint="89b03251d8d5e4b8"&gt;
  &lt;main&gt;
    &lt;p&gt;12 November 2025&lt;/p&gt;
    &lt;p&gt;Posted by Matthew Forsythe Director - Product Management, Android App Safety&lt;/p&gt;
    &lt;p&gt;We recently announced new developer verification requirements, which serve as an additional layer of defense in our ongoing effort to keep Android users safe. We know that security works best when it accounts for the diverse ways people use our tools. This is why we announced this change early: to gather input and ensure our solutions are balanced. We appreciate the community's engagement and have heard the early feedback – specifically from students and hobbyists who need an accessible path to learn, and from power users who are more comfortable with security risks. We are making changes to address the needs of both groups.&lt;/p&gt;
    &lt;p&gt;To understand how these updates fit into our broader mission, it is important to first look at the specific threats we are tackling.&lt;/p&gt;
    &lt;p&gt;Why verification is important&lt;/p&gt;
    &lt;p&gt;Keeping users safe on Android is our top priority. Combating scams and digital fraud is not new for us — it has been a central focus of our work for years. From Scam Detection in Google Messages to Google Play Protect and real-time alerts for scam calls, we have consistently acted to keep our ecosystem safe.&lt;/p&gt;
    &lt;p&gt;However, online scams and malware campaigns are becoming more aggressive. At the global scale of Android, this translates to real harm for people around the world – especially in rapidly digitizing regions where many are coming online for the first time. Technical safeguards are critical, but they cannot solve for every scenario where a user is manipulated. Scammers use high-pressure social engineering tactics to trick users into bypassing the very warnings designed to protect them.&lt;/p&gt;
    &lt;p&gt;For example, a common attack we track in Southeast Asia illustrates this threat clearly. A scammer calls a victim claiming their bank account is compromised and uses fear and urgency to direct them to sideload a "verification app" to secure their funds, often coaching them to ignore standard security warnings. Once installed, this app — actually malware — intercepts the victim's notifications. When the user logs into their real banking app, the malware captures their two-factor authentication codes, giving the scammer everything they need to drain the account.&lt;/p&gt;
    &lt;p&gt;While we have advanced safeguards and protections to detect and take down bad apps, without verification, bad actors can spin up new harmful apps instantly. It becomes an endless game of whack-a-mole. Verification changes the math by forcing them to use a real identity to distribute malware, making attacks significantly harder and more costly to scale. We have already seen how effective this is on Google Play, and we are now applying those lessons to the broader Android ecosystem to ensure there is a real, accountable identity behind the software you install.&lt;/p&gt;
    &lt;p&gt;Supporting students and hobbyists&lt;/p&gt;
    &lt;p&gt;We heard from developers who were concerned about the barrier to entry when building apps intended only for a small group, like family or friends. We are using your input to shape a dedicated account type for students and hobbyists. This will allow you to distribute your creations to a limited number of devices without going through the full verification requirements.&lt;/p&gt;
    &lt;p&gt;Empowering experienced users&lt;/p&gt;
    &lt;p&gt;While security is crucial, we’ve also heard from developers and power users who have a higher risk tolerance and want the ability to download unverified apps.&lt;/p&gt;
    &lt;p&gt;Based on this feedback and our ongoing conversations with the community, we are building a new advanced flow that allows experienced users to accept the risks of installing software that isn't verified. We are designing this flow specifically to resist coercion, ensuring that users aren't tricked into bypassing these safety checks while under pressure from a scammer. It will also include clear warnings to ensure users fully understand the risks involved, but ultimately, it puts the choice in their hands. We are gathering early feedback on the design of this feature now and will share more details in the coming months.&lt;/p&gt;
    &lt;p&gt;Getting started with early access&lt;/p&gt;
    &lt;p&gt;Today, we’re excited to start inviting developers to the early access for developer verification in Android Developer Console for developers that distribute exclusively outside of Play, and will share invites to the Play Console experience soon for Play developers. We are looking forward to your questions and feedback on streamlining the experience for all developers.&lt;/p&gt;
    &lt;p&gt;Watch our video below for a walkthrough of the new Android Developer Console experience and see our guides for more details and FAQs.&lt;/p&gt;
    &lt;p&gt;We are committed to working with you to keep the ecosystem safe while getting this right.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45908938</guid><pubDate>Thu, 13 Nov 2025 00:33:25 +0000</pubDate></item><item><title>Human Fovea Detector</title><link>https://www.shadertoy.com/view/4dsXzM</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45909059</guid><pubDate>Thu, 13 Nov 2025 00:48:45 +0000</pubDate></item><item><title>Android 16 QPR1 is being pushed to the Android Open Source Project</title><link>https://grapheneos.social/@GrapheneOS/115533432439509433</link><description>&lt;doc fingerprint="f8eb8f2f2d953eed"&gt;
  &lt;main&gt;
    &lt;p&gt;To use the Mastodon web application, please enable JavaScript. Alternatively, try one of the native apps for Mastodon for your platform.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45910381</guid><pubDate>Thu, 13 Nov 2025 03:49:23 +0000</pubDate></item><item><title>Reverse Engineering Yaesu FT-70D Firmware Encryption</title><link>https://landaire.net/reversing-yaesu-firmware-encryption/</link><description>&lt;doc fingerprint="8e1192112a7bc6b0"&gt;
  &lt;main&gt;
    &lt;p&gt;This article dives into my full methodology for reverse engineering the tool mentioned in this article. It's a bit longer but is intended to be accessible to folks who aren't necessarily advanced reverse-engineers.&lt;/p&gt;
    &lt;p&gt;Click on any of the images to view at its original resolution.&lt;/p&gt;
    &lt;head rend="h2"&gt;# Background&lt;/head&gt;
    &lt;p&gt;Ham radios are a fun way of learning how the radio spectrum works, and more importantly: they're embedded devices that may run weird chips/firmware! I got curious how easy it'd be to hack my Yaesu FT-70D, so I started doing some research. The only existing resource I could find for Yaesu radios was someone who posted about custom firmware for their Yaesu FT1DR.&lt;/p&gt;
    &lt;p&gt;The Reddit poster mentioned that if you go through the firmware update process via USB, the radio exposes its Renesas H8SX microcontroller and can have its flash modified using the Renesas SDK. This was a great start and looked promising, but the SDK wasn't trivial to configure and I wasn't sure if it could even dump the firmware... so I didn't use it for very long.&lt;/p&gt;
    &lt;head rend="h2"&gt;# Other Avenues&lt;/head&gt;
    &lt;p&gt;Yaesu provides a Windows application on their website that can be used to update a radio's firmware over USB:&lt;/p&gt;
    &lt;p&gt;The zip contains the following files:&lt;/p&gt;
    &lt;code&gt;1.2 MB  Wed Nov  8 14:34:38 2017  FT-70D_ver111(USA).exe
682 KB  Tue Nov 14 00:00:00 2017  FT-70DR_DE_Firmware_Update_Information_ENG_1711-B.pdf
8 MB  Mon Apr 23 00:00:00 2018  FT-70DR_DE_MAIN_Firmware_Ver_Up_Manual_ENG_1804-B.pdf
3.2 MB  Fri Jan  6 17:54:44 2012  HMSEUSBDRIVER.exe
160 KB  Sat Sep 17 15:14:16 2011  RComms.dll
61 KB  Tue Oct 23 17:02:08 2012  RFP_USB_VB.dll
1.7 MB  Fri Mar 29 11:54:02 2013  vcredist_x86.exe
&lt;/code&gt;
    &lt;p&gt;I'm going to assume that the file specific to the FT-70D, "FT-70D_ver111(USA).exe", will likely contain our firmware image. A PE file (.exe) can contain binary resources in the &lt;code&gt;.rsrc&lt;/code&gt; section -- let's see what this file contains using XPEViewer:&lt;/p&gt;
    &lt;p&gt;Resources fit into one of many different resource types, but a firmware image would likely be put into a custom type. What's this last entry, "23"? Expanding that node we have a couple of interesting items:&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;RES_START_DIALOG&lt;/code&gt; is a custom string the updater shows when preparing an update, so we're in the right area!&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;RES_UPDATE_INFO&lt;/code&gt; looks like just binary data -- perhaps this is our firmware image? Unfortunately looking at the "Strings" tab in XPEViewer or running the &lt;code&gt;strings&lt;/code&gt; utility over this data doesn't yield anything legible. The firmware image is likely encrypted.&lt;/p&gt;
    &lt;head rend="h2"&gt;# Reverse Engineering the Binary&lt;/head&gt;
    &lt;p&gt;Let's load the update utility into our disassembler of choice to figure out how the data is encrypted. I'll be using IDA Pro, but Ghidra (free!), radare2 (free!), or Binary Ninja are all great alternatives. Where possible in this article I'll try to show my rewritten code in C since it'll be a closer match to the decompiler and machine code output.&lt;/p&gt;
    &lt;p&gt;A good starting point is the the string we saw above, &lt;code&gt;RES_UPDATE_INFO&lt;/code&gt;. Windows applications load resources by calling one of the &lt;code&gt;FindResource*&lt;/code&gt; APIs. &lt;code&gt;FindResourceA&lt;/code&gt; has the following parameters:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;HMODULE&lt;/code&gt;, a handle to the module to look for the resource in.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;lpName&lt;/code&gt;, the resource name.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;lpType&lt;/code&gt;, the resource type.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In our disassembler we can find references to the &lt;code&gt;RES_UPDATE_INFO&lt;/code&gt; string and look for calls to &lt;code&gt;FindResourceA&lt;/code&gt; with this string as an argument in the &lt;code&gt;lpName&lt;/code&gt; position.&lt;/p&gt;
    &lt;p&gt;We find a match in a function which happens to find/load all of these custom resources under type &lt;code&gt;23&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;We know where the data is loaded by the application, so now we need to see how it's used. Doing static analysis from this point may be more work than it's worth if the data isn't operated on immediately. To speed things up I'm going to use a debugger's assistance. I used WinDbg's Time Travel Debugging to record an execution trace of the updater while it updates my radio. TTD is an invaluable tool and I'd highly recommend using it when possible. rr is an alternative for non-Windows platforms.&lt;/p&gt;
    &lt;p&gt;The decompiler output shows this function copies the &lt;code&gt;RES_UPDATE_INFO&lt;/code&gt; resource to a dynamically allocated buffer. The &lt;code&gt;qmemcpy()&lt;/code&gt; is inlined and represented by a &lt;code&gt;rep movsd&lt;/code&gt; instruction in the disassembly, so we need to break at this instruction and examine the &lt;code&gt;edi&lt;/code&gt; register's (destination address) value. I set a breakpoint by typing &lt;code&gt;bp 0x406968&lt;/code&gt; in the command window, allow the application to continue running, and when it breaks we can see the &lt;code&gt;edi&lt;/code&gt; register value is &lt;code&gt;0x2be5020&lt;/code&gt;. We can now set a memory access breakpoint at this address using &lt;code&gt;ba r4 0x2be5020&lt;/code&gt; to break whenever this data is read.&lt;/p&gt;
    &lt;p&gt;Our breakpoint is hit at &lt;code&gt;0x4047DC&lt;/code&gt; -- back to the disassembler. In IDA you can press &lt;code&gt;G&lt;/code&gt; and enter this address to jump to it. We're finally at what looks like the data processing function:&lt;/p&gt;
    &lt;p&gt;We broke when dereferencing &lt;code&gt;v2&lt;/code&gt; and IDA has automatically named the variable it's being assigned to as &lt;code&gt;Time&lt;/code&gt;. The &lt;code&gt;Time&lt;/code&gt; variable is passed to another function which formats it as a string with &lt;code&gt;%Y%m%d%H%M%S&lt;/code&gt;. Let's clean up the variables to reflect what we know:&lt;/p&gt;
    &lt;p&gt;The timestamp string is passed to &lt;code&gt;sub_4082c0&lt;/code&gt; on line 20 and the remainder of the update image is passed to &lt;code&gt;sub_408350&lt;/code&gt; on line 21. I'm going to focus on &lt;code&gt;sub_408350&lt;/code&gt; since I only care about the firmware data right now and based on how this function is called I'd wager its signature is something like:&lt;/p&gt;
    &lt;code&gt;status_t sub_408350(uint8_t *input, size_t input_len, uint8_t *output, output_len, size_t *out_data_processed);
&lt;/code&gt;
    &lt;p&gt;Let's see what it does:&lt;/p&gt;
    &lt;p&gt;I think we've found our function that starts decrypting the firmware! To confirm, we want to see what the &lt;code&gt;output&lt;/code&gt; parameter's data looks like before and after this function is called. I set a breakpoint in the debugger at the address where it's called (&lt;code&gt;bp 0x404842&lt;/code&gt;) and put the value of the &lt;code&gt;edi&lt;/code&gt; register (&lt;code&gt;0x2d7507c&lt;/code&gt;) in WinDbg's memory window.&lt;/p&gt;
    &lt;p&gt;Here's the data before:&lt;/p&gt;
    &lt;p&gt;After stepping over the function call:&lt;/p&gt;
    &lt;p&gt;We can dump this data to a file using the following command:&lt;/p&gt;
    &lt;code&gt;.writemem C:\users\lander\documents\maybe_deobfuscated.bin 0x2d7507c L100000
&lt;/code&gt;
    &lt;p&gt;010 Editor has a built-in strings utility (Search &amp;gt; Find Strings...) and if we scroll down a bit in the results, we have real strings that appear in my radio!&lt;/p&gt;
    &lt;p&gt;At this point if we were just interested in getting the plaintext firmware we could stop messing with the binary and load the firmware into IDA Pro... but I want to know how this encryption works.&lt;/p&gt;
    &lt;head rend="h2"&gt;# Encryption Details&lt;/head&gt;
    &lt;p&gt;Just to recap from the last section:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We've identified our data processing routine (let's call this function &lt;code&gt;decrypt_update_info&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;We know that the first 4 bytes of the update data are a Unix timestamp that's formatted as a string and used for an unknown purpose.&lt;/item&gt;
      &lt;item&gt;We know which function begins decrypting our firmware image.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;# Data Decryption&lt;/head&gt;
    &lt;p&gt;Let's look at the firmware image decryption routine with some renamed variables:&lt;/p&gt;
    &lt;p&gt;At a high level this routine:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Allocates a 64-byte scratch buffer&lt;/item&gt;
      &lt;item&gt;Checks if there's any data to process. If not, set the output variable &lt;code&gt;out_data_processed&lt;/code&gt;to the number of bytes processed and return 0x0 (&lt;code&gt;STATUS_SUCCESS&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Loop over the input data in 8-byte chunks and inflate each byte to its bit representation.&lt;/item&gt;
      &lt;item&gt;After the 8-byte chunk is inflated, call &lt;code&gt;sub_407980&lt;/code&gt;with the scratch buffer and&lt;code&gt;0&lt;/code&gt;as arguments.&lt;/item&gt;
      &lt;item&gt;Loop over the scratch buffer and reassemble 8 sequential bits as 1 byte, then set the byte at the appropriate index in the output buffer.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Lots going on here, but let's take a look at step #3. If we take the bytes &lt;code&gt;0xAA&lt;/code&gt; and &lt;code&gt;0x77&lt;/code&gt; which have bit representations of &lt;code&gt;0b1010_1010&lt;/code&gt; and &lt;code&gt;0b0111_1111&lt;/code&gt; respectively and inflate them to a 16-byte array using the algorithm above, we end up with:&lt;/p&gt;
    &lt;code&gt;| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 |    | 8 | 9 | A | B | C | D | E | F |
|---|---|---|---|---|---|---|---|----|---|---|---|---|---|---|---|---|
| 1 | 0 | 1 | 0 | 1 | 0 | 1 | 0 |    | 0 | 1 | 1 | 1 | 0 | 1 | 1 | 1 |
&lt;/code&gt;
    &lt;p&gt;This routine does this process over 8 bytes at a time and completely fills the 64-byte scratch buffer with 1s and 0s just like the table above.&lt;/p&gt;
    &lt;p&gt;Now let's look at step #4 and see what's going on in &lt;code&gt;sub_407980&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;Oof. This is substantially more complicated but looks like the meat of the decryption algorithm. We'll refer to this function, &lt;code&gt;sub_407980&lt;/code&gt;, as &lt;code&gt;decrypt_data&lt;/code&gt; from here on out. We can see what may be an immediate roadblock: this function takes in a C++ &lt;code&gt;this&lt;/code&gt; pointer (line 5) and performs bitwise operations on one of its members (line 18, 23, etc.). For now let's call this class member &lt;code&gt;key&lt;/code&gt; and come back to it later.&lt;/p&gt;
    &lt;p&gt;This function is the perfect example of decompilers emitting less than ideal code as a result of compiler optimizations/code reordering. For me, TTD was essential for following how data flows through this function. It took a few hours of banging my head against IDA and WinDbg to understand, but this function can be broken up into 3 high-level phases:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Building a 48-byte buffer containing our key material XOR'd with data from a static table.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Build a 32-byte buffer containing data from an 0x800-byte static table, with indexes into this table originating from indices built from the buffer in step #1. Combine this 32-byte buffer with the 48-byte buffer in step #1.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Iterate over the next 8 bytes of the output buffer. For each byte index of the output buffer, index into yet another static 32-byte buffer and use that as the index into the table from step #2. XOR this value with the value at the current index of the output buffer.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The inner loop in the &lt;code&gt;else&lt;/code&gt; branch above I think is kind of nasty, so here it is reimplemented in Rust:&lt;/p&gt;
    &lt;head rend="h3"&gt;# Key Setup&lt;/head&gt;
    &lt;p&gt;We now need to figure out how our key is set up for usage in the &lt;code&gt;decrypt_data&lt;/code&gt; function above. My approach here is to set a breakpoint at the first instruction to use the key data in &lt;code&gt;decrypt_data&lt;/code&gt;, which happens to be &lt;code&gt;xor bl, [ecx + esi + 4]&lt;/code&gt; at &lt;code&gt;0x4079d3&lt;/code&gt;. I know this is where we should break because in the decompiler output the left-hand side of the XOR operation, the key material, will be the second operand in the &lt;code&gt;xor&lt;/code&gt; instruction. As a reminder, the decompiler shows the XOR as:&lt;/p&gt;
    &lt;code&gt;v8 = *(_BYTE *)(i + 48 * v7 + v3 + 4) ^ a2[(unsigned __int8)byte_424E50[i] + 31];
&lt;/code&gt;
    &lt;p&gt;The breakpoint is hit and the address we're loading from is &lt;code&gt;0x19f5c4&lt;/code&gt;. We can now lean on TTD to help us figure out where this data was last written. Set a 1-byte memory write breakpoint at this address using &lt;code&gt;ba w1 0x19f5c4&lt;/code&gt; and press the &lt;code&gt;Go Back&lt;/code&gt; button. If you've never used TTD before, this operates exactly as &lt;code&gt;Go&lt;/code&gt; would except backwards in the program's trace. In this case it will execute backward until either a breakpoint is hit, interrupt is generated, or we reach the start of the program.&lt;/p&gt;
    &lt;p&gt;Our memory write breakpoint gets triggered at &lt;code&gt;0x4078fb&lt;/code&gt; -- a function we haven't seen before. The callstack shows that it's called not terribly far from the &lt;code&gt;decrypt_update_info&lt;/code&gt; routine!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;set_key&lt;/code&gt;(we are here -- function is originally called&lt;code&gt;sub_407850&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;sub_4082c0&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;decrypt_update_info&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What's &lt;code&gt;sub_4082c0&lt;/code&gt;?&lt;/p&gt;
    &lt;p&gt;Not a lot to see here except the same function called 4 times, initially with the timestamp string as an argument in position 0, a 64-byte buffer, and bunch of function calls using the return value of the last as its input. The function our debugger just broke into takes only 1 argument, which is the 64-byte buffer used across all of these function calls. So what's going on in &lt;code&gt;sub_407e80&lt;/code&gt;?&lt;/p&gt;
    &lt;p&gt;The bitwise operations that look supsiciously similar to the byte to bit inflation we saw above with the firmware data. After renaming things and performing some loop unrolling, things look like this:&lt;/p&gt;
    &lt;p&gt;The only mystery now is the &lt;code&gt;set_key&lt;/code&gt; routine:&lt;/p&gt;
    &lt;p&gt;This function is a bit more straightforward to reimplement:&lt;/p&gt;
    &lt;head rend="h3"&gt;# Putting Everything Together&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Update data is read from resources&lt;/item&gt;
      &lt;item&gt;The first 4 bytes of the update data are a Unix timestamp&lt;/item&gt;
      &lt;item&gt;The timestamp is formatted as a string, has each byte inflated to its bit representation, and decrypted using some static key material as the key. This is repeated 4 times with the output of the previous run used as an input to the next.&lt;/item&gt;
      &lt;item&gt;The resulting data from step 3 is used as a key for decrypting data.&lt;/item&gt;
      &lt;item&gt;The remainder of the firmware update image is inflated to its bit representation 8 bytes at a time and uses the dynamic key and 3 other unique static lookup tables to transform the inflated input data.&lt;/item&gt;
      &lt;item&gt;The result from step 5 is deflated back into its byte representation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;My decryption utility which completely reimplements this magic in Rust can be found at https://github.com/landaire/porkchop.&lt;/p&gt;
    &lt;head rend="h2"&gt;# Loading the Firmware in IDA Pro&lt;/head&gt;
    &lt;p&gt;IDA thankfully supports disassembling the Hitachi/Rensas H8SX architecture. If we load our firmware into IDA and select the "Hitachi H8SX advanced" processsor type, use the default options for the "Disassembly memory organization" dialog, then finally choose "H8S/2215R" in the "Choose the device name" dialog...:&lt;/p&gt;
    &lt;p&gt;We don't have shit. I'm not an embedded systems expert, but my friend suggested that the first few DWORDs look like they may belong to a vector table. If we right-click address 0 and select "Double word 0x142A", we can click on the new variable &lt;code&gt;unk_142A&lt;/code&gt; to go to its location. Press &lt;code&gt;C&lt;/code&gt; at this location to define it as Code, then press &lt;code&gt;P&lt;/code&gt; to create a function at this address:&lt;/p&gt;
    &lt;p&gt;We can now reverse engineer our firmware :)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45911704</guid><pubDate>Thu, 13 Nov 2025 07:12:01 +0000</pubDate></item><item><title>Checkout.com hacked, refuses ransom payment, donates to security labs</title><link>https://www.checkout.com/blog/protecting-our-merchants-standing-up-to-extortion</link><description>&lt;doc fingerprint="dd28949d2929f588"&gt;
  &lt;main&gt;
    &lt;p&gt;Tl;dr: Last week, we were targeted by a criminal extortion attempt. The attackers gained access to a legacy, third-party cloud file storage system.Â&lt;/p&gt;
    &lt;p&gt;Our live payment processing platform was not impacted. No merchant funds or card numbers were accessed.Â&lt;/p&gt;
    &lt;p&gt;We are donating the ransom amount to fund cybercrime research.&lt;/p&gt;
    &lt;p&gt;Last week, Checkout.com was contacted by a criminal group known as âShinyHuntersâ, who claimed to have obtained data connected to Checkout.com and demanded a ransom.&lt;/p&gt;
    &lt;p&gt;Upon investigation, we determined that this data was obtained by gaining unauthorized access to a legacy third-party cloud file storage system, used in 2020 and prior years. We estimate that this would affect less than 25% of our current merchant base. The system was used for internal operational documents and merchant onboarding materials at that time.&lt;/p&gt;
    &lt;p&gt;This incident has not impacted our payment processing platform. The threat actors do not have, and never had, access to merchant funds or card numbers.&lt;/p&gt;
    &lt;p&gt;The episode occurred when threat actors gained access to this third party legacy system which was not decommissioned properly. This was our mistake, and we take full responsibility.&lt;/p&gt;
    &lt;p&gt;We are sorry. We regret that this incident has caused worry for our partners and people. We have begun the process to identify and contact those impacted and are working closely with law enforcement and the relevant regulators. We are fully committed to maintaining your trust.Â Â&lt;/p&gt;
    &lt;p&gt;We will not be extorted by criminals. We will not pay this ransom.Â&lt;/p&gt;
    &lt;p&gt;Instead, we are turning this attack into an investment in security for our entire industry. We will be donating the ransom amount to Carnegie Mellon University and the University of Oxford Cyber Security Center to support their research in the fight against cybercrime.&lt;/p&gt;
    &lt;p&gt;Security, transparency and trust are the foundation of our industry. We will own our mistakes, protect our merchants, and invest in the fight against the criminal actors who threaten our digital economy.Â&lt;/p&gt;
    &lt;p&gt;We are here to assist our merchants in whatever way we can. As always, we are available through your regular Checkout point of contact for any further assistance or questions you may have.&lt;/p&gt;
    &lt;p&gt;Mariano Albera, Chief Technology Officer, Checkout.com&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45912698</guid><pubDate>Thu, 13 Nov 2025 09:23:30 +0000</pubDate></item><item><title>Telli (Voice AI – YC F24) is hiring engineers in Berlin</title><link>https://hi.telli.com/eng</link><description>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45912744</guid><pubDate>Thu, 13 Nov 2025 09:30:53 +0000</pubDate></item><item><title>Seed. LINE's Custom Typeface</title><link>https://seed.line.me/index_en.html</link><description>&lt;doc fingerprint="89d0a618096aa0ed"&gt;
  &lt;main&gt;
    &lt;p&gt;LINE Seed&lt;/p&gt;
    &lt;p&gt;LINE Seed Licensing&lt;/p&gt;
    &lt;quote&gt;All content of LINE Seed is copyrighted material owned by LY Corp. All fonts are released under the SIL Open Font License, Version1.1. This license is also available with a FAQ at: https://scripts.sil.org/OFL You can use them for any personal or commercial purposes. However, the software font files themselves cannot be sold by the other parties other than LY Corp. For commercial use, we highly recommend to include attribution in product or service. This isn't legal advice, please consider consulting a lawyer and see the full license for all details.&lt;/quote&gt;
    &lt;p&gt;LINE Seedã®ã©ã¤ã»ã³ã¹ã«ã¤ãã¦&lt;/p&gt;
    &lt;quote&gt;LINE Seedã®ãã¹ã¦ã®ã³ã³ãã³ãã¯ãLINEã¤ãã¼æ ªå¼ä¼ç¤¾ãèä½æ¨©ãæãã¦ãã¾ãã å ¨ã¦ã®ãã©ã³ãã¯ãSIL Open Font License, Version 1.1ã«åºã¥ãã¦å ¬éããã¦ãã¾ãã ãã®ã©ã¤ã»ã³ã¹ã¯ãhttps://scripts.sil.org/OFL ã«å ¨æã¨FAQãæ¡å ããã¦ãã¾ãã æ¥æ¬èªã«ããåèè¨³ã«ã¤ãã¦ã¯ãhttps://licenses.opensource.jp/OFL-1.1/OFL-1.1.html ãåç §ãã¦ãã ããã åäººçãåæ¥çãã«é¢ä¿ãªããèªç±ãªç®çã§ãã®ãã©ã³ããä½¿ç¨ãããã¨ãã§ãã¾ãã ãã ãããã©ã³ããã®ãã®ãåä½ã§LINEã¤ãã¼æ ªå¼ä¼ç¤¾ä»¥å¤ã®ç¬¬ä¸è ãè²©å£²ãããã¨ã¯ã§ãã¾ããã åç¨å©ç¨ã®å ´åã¯ãè£½åã»ãµã¼ãã¹ã«å¸°å±ãå«ãããã¨ãå¼·ãæ¨å¥¨ãã¾ãã ããã¯æ³çãªã¢ããã¤ã¹ã§ã¯ãªããå ´åã«ãã£ã¦ã¯å¼è·å£«ã«ç¸è«ãããã¨ãæ¤è¨ããå ¨ã¦ã®è©³ç´°ã«ã¤ãã¦ã¯å®å ¨ãªã©ã¤ã»ã³ã¹ãåç §ãã¦ãã ããã&lt;/quote&gt;
    &lt;p&gt;LINE Seed ì ìê¶ ìë´&lt;/p&gt;
    &lt;quote&gt;LINE Seedì ëª¨ë ì½í ì¸ ë LY Corp. ìì ì ì ìë¬¼ì ëë¤. ëª¨ë ê¸ê¼´ì SIL Open Font License ë²ì 1.1ì ê¸°ë°ì¼ë¡ ê³µê°ëììµëë¤. ì´ ë¼ì´ì ì¤ëÂ https://scripts.sil.org/OFLì ì ë¬¸ê³¼ FAQê° ìë´ëì´ ììµëë¤. ê°ì¸ ëë ìì ì ëª©ì ì¼ë¡ ì´ ê¸ê¼´ì ì¬ì©í ì ììµëë¤. ë¨, LY Corp. ì´ì¸ìÂ ìê° ìíí¸ì¨ì´ ê¸ê¼´ íì¼ ìì²´ë¥¼ íë§¤í ì ììµëë¤. ìì ì ì©ëë¡ íì©í ê²½ì° ì í ëë ìë¹ì¤ì ì¶ì² íê¸°ë¥¼ ê°ë ¥í ê¶ì¥í©ëë¤. ì´ëÂ ë²ì ì¡°ì¸ì´ ìëë©°, ëª¨ë ìì¸í ë´ì©ì ëí´ìëÂ ë³í¸ì¬ì ììíë ê²ì ê³ ë ¤íìê³ , ë¼ì´ì ì¤ ì ë¬¸ì ì°¸ê³ íìê¸° ë°ëëë¤. â» LINE SeedÂ ë¼ì´ì ì¤Â ì ë¬¸ìÂ íê¸ìÂ ì´ì©ììÂ ì´í´ë¥¼Â ëê¸°Â ìí´Â ìë¬¸Â ìë³¸ìÂ ë²ìí´Â ìë¹ì¤íê³ Â ìì¼ë©°,Â ë²ì Â í¨ë ¥ìÂ ìë¬¸ìÂ íí©ëë¤.&lt;/quote&gt;
    &lt;p&gt;à¸¥à¸´à¸à¸ªà¸´à¸à¸à¸´à¹à¸à¸à¸ LINE Seed&lt;/p&gt;
    &lt;quote&gt;à¹à¸à¸·à¹à¸à¸«à¸²à¸à¸±à¹à¸à¸«à¸¡à¸à¸à¸à¸à¸à¸à¸à¸à¹ LINE Seed à¹à¸à¹à¸à¸à¸¥à¸à¸²à¸à¸à¸±à¸à¸¡à¸µà¸¥à¸´à¸à¸ªà¸´à¸à¸à¸´à¹à¸à¸¶à¹à¸à¹à¸à¹à¸à¸à¸à¸ LY Corp. à¸à¸¸à¸à¸£à¸¹à¸à¹à¸à¸à¸à¸±à¸§à¸à¸±à¸à¸©à¸£à¸à¸±à¹à¸à¸«à¸¡à¸à¸à¸¢à¸¹à¹à¸ à¸²à¸¢à¹à¸à¹ SIL Open Font License, à¹à¸§à¸à¸£à¹à¸à¸±à¹à¸ 1.1. à¸ªà¸²à¸¡à¸²à¸£à¸à¸à¸£à¸§à¸à¸ªà¸à¸à¸à¸³à¸à¸²à¸¡à¹à¸à¸µà¹à¸¢à¸§à¸à¸±à¸à¹à¸à¸·à¹à¸à¸«à¸²à¸¥à¸´à¸à¸ªà¸´à¸à¸à¸´à¹à¸à¸µà¹à¸à¸à¸à¹à¸à¸¢ à¹à¸à¹à¸à¸µà¹ https://scripts.sil.org/OFL à¸à¸¸à¸à¸£à¸¹à¸à¹à¸à¸à¸à¸±à¸§à¸à¸±à¸à¸©à¸£à¸à¸±à¹à¸à¸«à¸¡à¸à¸ªà¸²à¸¡à¸²à¸£à¸à¸à¸³à¹à¸à¹à¸à¹à¹à¸à¹à¸à¸£à¸µ à¹à¸¡à¹à¸à¹à¸à¸à¹à¸ªà¸µà¸¢à¸à¹à¸²à¹à¸à¹à¸à¹à¸²à¸¢ à¹à¸à¸¢à¸ªà¸²à¸¡à¸²à¸£à¸à¸à¸³à¹à¸à¹à¸à¹à¸à¸²à¸à¹à¸à¹à¸à¸à¸²à¸£à¸ªà¹à¸§à¸à¸à¸±à¸§ à¸«à¸£à¸·à¸à¹à¸à¹à¸à¸²à¸à¹à¸à¸´à¸à¸à¸²à¸à¸´à¸à¸¢à¹à¸à¹à¹à¸à¹ à¸à¸¢à¹à¸²à¸à¹à¸£à¸à¹à¸à¸²à¸¡ à¸à¸¸à¸à¸à¸¥à¸à¸·à¹à¸à¸à¸µà¹à¹à¸¡à¹à¹à¸à¹ LY Corp. à¸à¸°à¹à¸¡à¹à¸ªà¸²à¸¡à¸²à¸£à¸à¸à¸³à¹à¸à¸¥à¹à¸à¸à¸à¸à¹ LINE Seed à¹à¸à¸à¸³à¸«à¸à¹à¸²à¸¢à¹à¸à¹ à¹à¸¥à¸°à¸«à¸²à¸à¸¡à¸µà¸à¸²à¸£à¸à¸³à¸à¸à¸à¸à¹à¹à¸à¹à¸à¹à¹à¸à¹à¸à¸´à¸à¸à¸²à¸à¸´à¸à¸¢à¹ à¹à¸£à¸²à¹à¸à¸°à¸à¸³à¹à¸à¹à¸à¸à¸¢à¹à¸²à¸à¸¢à¸´à¹à¸à¹à¸«à¹à¸à¹à¸²à¸à¸£à¸°à¸à¸¸à¸à¸µà¹à¸¡à¸²à¸à¸à¸à¸à¸à¸à¸à¹à¹à¸§à¹à¸à¸à¸à¸¥à¸´à¸à¸ à¸±à¸à¸à¹à¸«à¸£à¸·à¸à¸à¸£à¸´à¸à¸²à¸£ à¸à¸¢à¹à¸²à¸à¹à¸£à¸à¹à¸à¸²à¸¡ à¹à¸à¸°à¸à¸³à¹à¸«à¹à¸à¸£à¸¶à¸à¸©à¸²à¸à¸µà¹à¸à¸£à¸¶à¸à¸©à¸²à¸à¸²à¸à¸à¹à¸²à¸à¸à¸à¸«à¸¡à¸²à¸¢ à¹à¸¥à¸°à¸à¸£à¸§à¸à¸ªà¸à¸à¸£à¸²à¸¢à¸¥à¸°à¹à¸à¸µà¸¢à¸à¸¥à¸´à¸à¸ªà¸´à¸à¸à¸´à¹à¸à¸à¸±à¸à¸ªà¸¡à¸à¸¹à¸£à¸à¹&lt;/quote&gt;
    &lt;p&gt;LINE Seed åé«ææ¬èªªæ&lt;/p&gt;
    &lt;quote&gt;LINE Seed å ¨é¨å §å®¹ä¹èä½æ¬åç± LY Corp. ææã æ¬åé«å¥ä»¶ä¾æ SIL Open Font License, Version 1.1 ææ¬æ¢æ¬¾é²è¡ç¼å¸ã å®æ´ææ¬æ¢æåå¸¸è¦åé¡å¯åé±ï¼https://scripts.sil.org/OFL æ¬åé«å¯èªç±ä½¿ç¨æ¼åäººæåæ¥ç¨éï¼ä¸åéå¶ã æé æ³¨æï¼é¤ LY Corp. å¤ï¼ä»»ä½ç¬¬ä¸æ¹çä¸å¾å®ç¨é·å®æ¬åé«æªæ¡æ¬èº«ã å¦ä½çºåæ¥ç¨éï¼å»ºè°æç¢ºæ¨ç¤ºæ¬åé«ä¾æºææ¸å±¬è³è¨æ¼ç¸éç¢åææåä¸ã æ¬èªªæå ä¾åèï¼ä¸¦ä¸æ§ææ³å¾æè¦ã å¦éé²ä¸æ¥æ³å¾åå©ï¼æ¬è«è«®è©¢å°æ¥å¾å¸«ï¼ä¸¦è©³é±å®æ´ææ¬æ¢æ¬¾ä»¥ææ¡ææé©ç¨è¦å®ã&lt;/quote&gt;
    &lt;p&gt; LINE Seed is LINEâs new typeface that was &lt;lb/&gt;created based on the brand's convenient &lt;lb/&gt;usability and friendly identity. &lt;lb/&gt;Just like a seed &lt;lb/&gt;takes root and bears fruit, the name Seed &lt;lb/&gt;means to take root firmly in LINE's services &lt;lb/&gt;and grow together &lt;lb/&gt;with our users. &lt;lb/&gt;All the fonts of LINE Seed have the same &lt;lb/&gt;DNA, and the balanced volume and weight &lt;lb/&gt;ensures a harmony &lt;lb/&gt;without requiring extra &lt;lb/&gt;adjustments so that the textâs texture looks &lt;lb/&gt;the same even when different languages &lt;lb/&gt;are put side by side. &lt;/p&gt;
    &lt;p&gt;The simple form of LINE Seed represents the universality and friendliness of LINE. In addition, the rounded corners of the logo have been included as a common element for all glyphs and characters, including letters, numbers, symbols, and icons.&lt;/p&gt;
    &lt;p&gt;friendliness of LINE.&lt;/p&gt;
    &lt;p&gt;In addition, the rounded corners of the logo&lt;/p&gt;
    &lt;p&gt;have been included as a common element for all glyphs and&lt;/p&gt;
    &lt;p&gt;characters, including letters, numbers, symbols, and icons.&lt;/p&gt;
    &lt;p&gt;With the ligature OpenType feature, LINE Seed is able to maintain&lt;/p&gt;
    &lt;p&gt;a consistent letter spacing&lt;/p&gt;
    &lt;p&gt;when certain characters (fi, ff, fl, fj, etc.)&lt;/p&gt;
    &lt;p&gt;are arranged side by side. This is achieved by connecting&lt;/p&gt;
    &lt;p&gt;or transforming&lt;/p&gt;
    &lt;p&gt;characters to improve the counter space (inner white space), which&lt;/p&gt;
    &lt;p&gt;achieves&lt;/p&gt;
    &lt;p&gt;a better rhythm from Display to Text settings.&lt;/p&gt;
    &lt;p&gt;In addition, the various service icons of LINE are&lt;/p&gt;
    &lt;p&gt;included in the text, adding visual fun through clever expressions.&lt;/p&gt;
    &lt;p&gt;LINE Seed has been created in various languages to deliver a consistent message &lt;lb/&gt;to our global users. The typeface was designed based on typographical elements as &lt;lb/&gt;well as morphological elements in order to be read in a unified and natural way while &lt;lb/&gt;maintaining the unique form and function of the characters in each writing system.&lt;/p&gt;
    &lt;p&gt;LINE ã·ã¼ã&lt;/p&gt;
    &lt;p&gt;LINE ì¨ë&lt;/p&gt;
    &lt;p&gt;LINE à¸à¸µà¸&lt;/p&gt;
    &lt;p&gt;LINE ç¨®å&lt;/p&gt;
    &lt;p&gt;LINE collaborated with the London-based &lt;lb/&gt;renowned typeface design studio Dalton Maag &lt;lb/&gt;to create LINE Seed.&lt;lb/&gt; For LINE Creative, Dalton Maag &lt;lb/&gt;deliberately expressed the voice of LINE&lt;lb/&gt; based on &lt;lb/&gt;its own unique design knowledge and perspective.&lt;lb/&gt;This was truly a memorable global &lt;lb/&gt;collaborative effort.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45912785</guid><pubDate>Thu, 13 Nov 2025 09:36:51 +0000</pubDate></item><item><title>Britain's Railway Privatization Was an Abject Failure</title><link>https://www.rosalux.de/en/news/id/53917/britains-railway-privatization-was-an-abject-failure</link><description>&lt;doc fingerprint="afd090d75c27b7db"&gt;
  &lt;main&gt;
    &lt;p&gt;Liberalization of the railways has been a key tenet of European transport policy since the early 2000s, with proponents claiming that competition results in improved service quality and increased ridership. This is an instantly disprovable statement given that ridership was already on the rise across Europe prior to, rather than after, liberalization efforts, suggesting other effects are at play.&lt;/p&gt;
    &lt;p&gt;Gareth Dennis is an award-winning railway engineer and writer. He is the author of the internationally bestselling book How The Railways Will Fix the Future and co-founder of the Campaign for Level Boarding.&lt;/p&gt;
    &lt;p&gt;On the other hand, the case against fragmented and privatized operations focuses on three key arguments. The first is that railways are complex systems where commercial boundaries at engineering interfaces are a threat to safety and efficiency. The second is that railway operations are geographic monopolies where market conditions are — at best — contrived. The third is that railways are a public service that cannot fail — hence, introducing private interests into the railways is merely a way to sequester income into private hands while the state shoulders the financial risk. In other words, private interests’ role is simply to extract profit that could otherwise be reinvested into the system.&lt;/p&gt;
    &lt;p&gt;The United Kingdom was one of first countries in Europe to liberalize a significant portion of its railways (Northern Ireland’s railways remained publicly owned and operated). As such, the aftermath of privatization is instructive in tracing liberalization’s final destination. In short: it isn’t pretty.&lt;/p&gt;
    &lt;head rend="h4"&gt;Selling the Family Silver&lt;/head&gt;
    &lt;p&gt;The UK’s contiguous network in Wales, Scotland, and England was privatized in stages between 1988 and 1997, starting with its domestic train manufacturing industry. This took place following a massive self-off of public assets in the aftermath of the broader financialization of the British economy. For example, the water industry in England and Wales was wholly divested through the 1980s — something no other country has ever done. Thanks to archived papers from then Prime Minister Margaret Thatcher, we can understand precisely what the political drivers for mass privatization were.&lt;/p&gt;
    &lt;p&gt;First, as a large employer of over 50,000 staff, divesting the water industry would greatly contribute to “the privatisation programme”. Second, it would take necessary investment in an ageing asset off the public books. Finally, it would increase shareholding in the public, mitigate state interference, and create financial assets for trade. It is worth noting that none of these justifications took the quality or expansion of services into account.&lt;/p&gt;
    &lt;p&gt;And so, we turn back to railways. In 1990, things had been looking up for British Rail. Ridership had been climbing solidly since the mid-1980s. The average subsidy was as low as 20 percent of running costs, making the British system one of the most efficient in Europe. Urban, regional, and high-speed rail projects were being delivered or, in the latter case, were in serious development.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Three rolling stock operating companies bought — at rock-bottom prices — an enormous range of hugely valuable trains for which British Rail had scrimped and saved over the preceding decades.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Then the early-1990s recession hit. More than a decade of constrained public spending and service sell-offs meant there was an immediate impact on passenger numbers, sending the government into a panic. Suddenly, the Thatcherite doctrine of “sell everything but the railways” was thrown out the window, and plans for privatization were put in motion.&lt;/p&gt;
    &lt;p&gt;In July 1992, a white paper entitled “New Opportunities for the Railways” was published, heavily informed by Treasury mandarins and their advisers at the Tufton Street-based Adam Smith Institute in London. It recommended nothing less than an atomization of the formerly integrated railway operating structure, with the creation of as many independent elements as possible to maximize perceived opportunities for competition.&lt;/p&gt;
    &lt;p&gt;On 1 April 1994, the Railways Act came into effect and the demise of British Rail began. It is worth noting that privatization had already started in the 1980s, for example with the sale of the train manufacturers in Derby and various ferry operations. But the 1990s was different — this was a fire sale.&lt;/p&gt;
    &lt;head rend="h4"&gt;Deadly Side-Effects&lt;/head&gt;
    &lt;p&gt;The first private entity to be created was Railtrack, which took over the railway infrastructure such as track, signals, and stations. Seven infrastructure maintenance units and six track renewal units were set up to split off maintenance from operation. Six freight operating companies were created. Twenty-five train operating units were also established, which from 1996 onwards were franchised out to the train operating companies.&lt;/p&gt;
    &lt;p&gt;Three rolling stock operating companies (ROSCOs) bought — at rock-bottom prices — an enormous range of hugely valuable trains for which British Rail had scrimped and saved over the preceding decades. They then leased these back to the train operators at eye-watering cost and with little oversight, enabling a significant outflow of cash from the industry. This has incentivized one of British passengers’ biggest gripes — the widespread use of trains that are as short as possible to minimize leasing costs, without a care for the resulting overcrowding.&lt;/p&gt;
    &lt;p&gt;Another impact of the ROSCOs landing a large, cheap asset that they could rent out at high prices was the near-death of the UK train manufacturing industry, as there was no incentive to continue British Rail's programme of fleet renewals. In the aftermath of privatization, only British Rail’s partially fulfilled orders remained on the books, and new passenger trains wouldn't be built at volume until the early 2000s, resulting in the demise of all but the Derby works. At great cost, new plants have opened in Newton Aycliffe and Newport since, but even these are once again under threat thanks to the lack of any long-term rolling stock strategy.&lt;/p&gt;
    &lt;p&gt;All franchises had been awarded, a plethora of regulating and organizing bodies had been established to hold the system together, and privatization was essentially complete by 1 April 1997, achieving the outgoing administration’s goal of completing the process by the next general election. Despite promises to the contrary, New Labour’s coming into power did not result in a reversal of the process.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Franchise agreements, now managed by the Department for Transport, were growing more complex and more restrictive.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;However, in September 1997, an express train collided with a freight train in Southall, London, killing seven people and injuring 139 others. A lack of effective communication between the fragmented elements of the railway was the root cause of the horrific crash, the first of a series of serious fatal derailments that were attributable to the new structure of the railways.&lt;/p&gt;
    &lt;p&gt;In October 1999, the death of 31 people and the injury of 417 others at Ladbroke Grove, London, resulted in a cascade of changes to safety regulation. The derailment of an express train at Hatfield in October 2000 killed four people and injured 70, sending shockwaves through the industry as it had resulted directly from Railtrack’s self-perception as a contract management organization, not an engineering outfit. This fomented the demise of Railtrack, which was absorbed into a new government body called Network Rail. A gargantuan and rushed effort to replace thousands of miles of substandard track materials followed, requiring billions of pounds of additional funds and greatly impacting passenger numbers for several years.&lt;/p&gt;
    &lt;p&gt;Another fatal derailment at Potters Bar in May 2002 killed seven people and was caused by the negligence of a private maintenance company. This led to the return of many maintenance tasks in-house under Network Rail. With the process of Railtrack’s reconstitution as Network Rail completing in October 2002, the UK’s rail infrastructure had been de facto renationalized.&lt;/p&gt;
    &lt;head rend="h4"&gt;Growing Pains&lt;/head&gt;
    &lt;p&gt;The West Coast Main Line had long been considered the jewel in the crown of the British rail network, having been electrified and modernized through the 1950s, 1960s, and 1970s. By 1998, passenger growth was putting significant pressure on the route, and Virgin’s Richard Branson wanted to introduce new tilting trains and a much more frequent timetable. By 2002, costs had risen from 2.5 billion to 14.5 billion pounds (just short of 30 billion pounds in today’s money), and the scope of the project had been severely curtailed. What started in 1998 as a promise for a 140-miles-per-hour railway with fully digital signalling had descended into chaos by the early 2000s, contributing to Railtrack’s demise.&lt;/p&gt;
    &lt;p&gt;By this point, railways were at their most popular since the beginning of the previous century. Passenger numbers were skyrocketing, and a cross-party consensus agreed that rail investment and the expansion of the rail network were a good thing. Franchises previously let as “not for growth” such as those in Wales and the North were creaking at the seams as people turned to trains.&lt;/p&gt;
    &lt;p&gt;Franchise agreements, now managed by the Department for Transport, were growing more complex and more restrictive. The number of bidders reduced, and the ambition of their bids increased. This came to a head in 2009, when National Express was stripped of the East Coast franchise after failing to meet its payment targets despite continuing passenger growth.&lt;/p&gt;
    &lt;p&gt;In 2012, the West Coast bidding process was scrapped by government and was awarded as a short-term concession pending a review, and amidst a wider crisis across the industry in June 2018, the East Coast franchise — subsequently awarded to yet another optimistic bid by Virgin — also collapsed and had to be returned to state operation. By this point, franchise bidders were few and far between, and the system was close to collapse.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Railways must be set into the bigger transport picture with ambitious targets — mobility in totality, not rail in isolation.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;These increasingly overambitious bids, combined with ever-more complex and controlling contracts, left only one lever open to the train operators to cut costs: staffing. From 2016 onwards, a wave of increasingly disruptive strikes took hold of the network, as terms and conditions were altered to attempt to reduce the number of staff the train operating companies had to have on their books.&lt;/p&gt;
    &lt;p&gt;Just as the industry’s new structure had resulted in the creation of the ROSCOs, which incentivised a freeze in new train procurement, the creation of Railtrack and its private suppliers resulted in a freeze in recruitment across the infrastructure domain. Crudely, when you have a fleet of trains that already run the service, why build new ones? The same ended up being broadly true for infrastructure — why employ new staff when you already have an enormous workforce?&lt;/p&gt;
    &lt;p&gt;A decade-wide gap in skills was the consequence. With the growth in passenger demand came a huge growth in the number of infrastructure projects being carried out, and this skills bottleneck, combined with an industry structure that exacerbated costs by maximizing the number of organizational interfaces, meant work was being delivered too slowly and at too high a price. Cost escalations became unbearable for government in 2017 and resulted not only in the curtailment of the national electrification programme, but also in the abandonment of other enhancements across the country, particularly in and around the north of England. Meanwhile, there was a glut of new train orders, many for new electric trains for which there were no longer overhead wires planned to power them.&lt;/p&gt;
    &lt;p&gt;May 2018 was supposed to be the moment that an enormous leap in capacity was created. New track and trains would enable a great leap in the number of trains running in the timetable. As it happened, neither the track nor the trains were in place to deliver much of this uplift, and the result was a collapse in the system’s reliability. Driver training could not happen, and a lack of trains, tracks, and staff resulted in the cancellation of upwards of one third of services in the South East and the north of England, with lesser but significant effects felt by passengers across the network.&lt;/p&gt;
    &lt;p&gt;Long an opponent of the franchise system and the lack of integration between track and train, then Secretary of State for Transport Chris Grayling initiated the Williams Review in 2018 to work out what shape the industry needed to be in to enable growth without cycling back to calamity. This review took time to pick up speed, leaving the industry in perpetual crisis mode.&lt;/p&gt;
    &lt;head rend="h4"&gt;The Final Nail in the Coffin&lt;/head&gt;
    &lt;p&gt;In March 2020, the COVID-19 pandemic reduced ridership to 5 percent of pre-COVID levels and the industry was placed on life support. By the end of that month, all franchises were transferred onto emergency concessions, and the franchise system was gone. This was made official in September 2020, as the government stated that franchising was to cease to exist, and by April 2021 the National Audit Office announced that train operators were to be officially classified as state-owned, despite the continued involvement of private companies. The irony of a Conservative than a Labour government beginning the re-integration of the system should not be lost on readers — indeed, this is a recurring theme.&lt;/p&gt;
    &lt;p&gt;Finally, in May 2021, the Williams—Shapps Plan for Rail was published, setting out a loose view of the future structure of the railways. Although lacking in details, the headline was that a new organization called Great British Railways (GBR) was to be created. A transition team was established to understand what GBR would do and how it would be structured. The ROSCOs, as the last major vestige of the Railways Act 1993, remained untouched.&lt;/p&gt;
    &lt;p&gt;Roll forwards seven years and, despite several train operators being controlled directly by the Department for Transport, there is still no clear picture of what GBR will be empowered or funded to do, let alone what its structure and intentions will be. Meanwhile, a general election has worsened, not improved, the outlook for the railway industry, as the number of major projects continues to fall alongside ongoing maintenance funding. Capacity is more squeezed than ever before.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The rail industry needs democratization, so that decisions about the railways we use are made closer to us.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Despite the public’s continued support for publicly owned railways — 75% in 2025 compared with 60% in 2017 — the extent to which “nationalization” will achieve democratic oversight and the necessary reinvigoration of the industry remains unclear. Britain’s rail unions are cautiously supportive, but it is worth noting that scepticism has grown as the Labour Party drifts further to the centre.&lt;/p&gt;
    &lt;p&gt;The rail industry needs democratization, so that decisions about the railways we use are made closer to us. That means moving power, including over spending, away from Westminster. Democratic accountability at local and regional levels is key to unlocking the cycle of proposed and cancelled investment, and in pushing operators to do better. That means devolution of decision and funding powers to both the regions and cities, but also delivering sufficient industry funding autonomy so that it can respond quickly to these demands and rise above electoral cycles and fiscal anxiety.&lt;/p&gt;
    &lt;p&gt;Railways must be set into the bigger transport picture with ambitious targets — mobility in totality, not rail in isolation. Moreover, investment must be matched to those targets to build a railway that more people can use and benefit from — more capacity, more reliability and more accessibility.&lt;/p&gt;
    &lt;p&gt;Empowerment of the rail industry as a self-governing entity accountable chiefly to the UK’s regions and cities rather than to central government is a critical step in kicking things out of crisis mode and reshaping the industry to be fit for the long-term future. But as important is the need for the railways to tell a story about themselves that the public can get behind. Only with an ambitious and exciting vision of the future will the railways fulfil their true potential. Privatization, as the British experience shows, utterly failed to do so.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45914718</guid><pubDate>Thu, 13 Nov 2025 13:34:38 +0000</pubDate></item><item><title>Blender Lab</title><link>https://www.blender.org/news/introducing-blender-lab/</link><description>&lt;doc fingerprint="c855707f5f7767ff"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;Introducing an innovation space within the Blender project, where designers and developers can work together on challenging or future-facing projects, to keep Blender relevant in the years to come.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Over the years, Blender has grown and matured into a powerful and complex piece of software. With its unstoppable release cycle, a massive, highly demanding, and diverse user community, natural technical debt, and complex technical dependencies, shipping new features and general improvements requires more and more effort and coordination.&lt;/p&gt;
    &lt;p&gt;Software stability and reliability have become critical for individuals and companies. As a consequence, development efforts focus on those aspects, offering progressive improvements of existing functionality only when these are clear enhancements of what is already there.&lt;/p&gt;
    &lt;p&gt;This makes it more challenging to innovate, think outside the box, experiment, and break things.&lt;/p&gt;
    &lt;p&gt;To facilitate this essential aspect of product development, the Blender Foundation is establishing a new project: the Blender Lab. This is the innovation space where designers, developers, and researchers work together on challenging and future-facing projects that will help Blender stay relevant in the years to come.&lt;/p&gt;
    &lt;head rend="h2"&gt;What is a lab activity?&lt;/head&gt;
    &lt;p&gt;A lab activity is a project that brings innovation to the Blender project, and contributes to Blender Foundation’s mission. The project should face some unknowns, but also be handled by a team or individual with sufficient domain knowledge to solve them. Lab activities are meant to be independent of Blender releases.&lt;/p&gt;
    &lt;head rend="h2"&gt;What does it look like?&lt;/head&gt;
    &lt;p&gt;Lab activities are always public and visible on blender.org/lab. Here the ongoing projects are presented, sharing objectives, timeline and participants. Intermediate builds for testing and feedback will be available here as well.&lt;/p&gt;
    &lt;head rend="h2"&gt;First batch, and more examples&lt;/head&gt;
    &lt;p&gt;To get started with this initiative, here are some projects that qualify, and that are listed:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Beyond mouse and keyboard (touch and pen)&lt;/item&gt;
      &lt;item&gt;Beyond mouse and keyboard (VR/XR)&lt;/item&gt;
      &lt;item&gt;Volume rendering&lt;/item&gt;
      &lt;item&gt;Light transport&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Some more projects that could be added soon:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;USD Authoring&lt;/item&gt;
      &lt;item&gt;AI and ML technologies, starting with a Blender MCP server&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Applied vs. Academic research&lt;/head&gt;
    &lt;p&gt;Lab activities can be grouped in two categories:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Applied research, which is the main focus of the lab. Developing and eventually shipping groundbreaking solutions based on the latest research and knowledge in the field&lt;/item&gt;
      &lt;item&gt;Academic research. For example, this can be achieved by participating in projects organized by institutions such as universities and research centers, where Blender developers offer an advisory role on how technology can be implemented in production software.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;How do I make my project a Lab project?&lt;/head&gt;
    &lt;p&gt;The goal is to start with a limited number of projects, assessed by Blender Foundation with the support of key Blender contributors. During the course of 2026, more guidelines will be defined and shared. If you are interested in submitting a proposal for a Lab project, you can do so by contacting Blender Foundation and sharing a public document where you describe the project and make a compelling case for it. The adoption of a project depends on many factors, including funds availability, relevance to the Blender missions, experience of the applicant, and more.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion and credits&lt;/head&gt;
    &lt;p&gt;Special credit goes to Ton Roosendaal for advocating for this project since 2018. At the time the Blender project was not able to allocate resources to the initiative, but today, thanks to growing community and corporate support there starts to be a path for it. Future campaigns and partnerships will be crucial for the success of this project. You can make this happen by joining the Blender Development Fund at fund.blender.org.&lt;/p&gt;
    &lt;p&gt;Francesco Siddi&lt;lb/&gt;Blender Foundation&lt;/p&gt;
    &lt;head rend="h4"&gt;Support the Future of Blender&lt;/head&gt;
    &lt;p&gt;Donate to Blender by joining the Development Fund to support the Blender Foundation’s work on core development, maintenance, and new releases.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45914761</guid><pubDate>Thu, 13 Nov 2025 13:38:47 +0000</pubDate></item></channel></rss>