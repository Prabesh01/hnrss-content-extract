<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 25 Oct 2025 22:08:29 +0000</lastBuildDate><item><title>Rock Tumbler Instructions</title><link>https://rocktumbler.com/tips/rock-tumbler-instructions/</link><description>&lt;doc fingerprint="e3c401461f672ad1"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Rock Tumbler Instructions&lt;/head&gt;&lt;head rend="h3"&gt;Directions for Turning Rough Rocks into Beautiful Tumbled Stones&lt;/head&gt;&lt;p&gt;Working to transform rough rock into beautiful tumbled stones gives most people a great feeling of accomplishment. It doesn't matter how old you are or how many batches of rock you have tumbled in the past - when you finish the last tumbling step, rinse off the polish, and see a super-bright luster on colorful polished stones - you are amazed at what you have done.&lt;/p&gt;&lt;head rend="h2"&gt;Rock Tumbling Is Easy&lt;/head&gt;&lt;p&gt;Using a rock tumbler to convert rough rock into sparkling tumbled stones is easy if you follow a simple procedure and observe a few rules. We are writing this to share the procedure that we have used for many years with a number of rotary tumblers.&lt;/p&gt;&lt;p&gt;This procedure works well with materials that have the following properties:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;of adequate quality to accept a polish&lt;/item&gt;&lt;item&gt;a Mohs hardness between 6 and 7&lt;/item&gt;&lt;item&gt;a size between 3/8" and 1 1/2"&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Chalcedony&lt;/head&gt;: agate, bloodstone, carnelian, chrysoprase, jasper, chert, flint, and petrified (silicified) wood.&lt;head rend="h3"&gt;Quartz&lt;/head&gt;: amethyst, aventurine, citrine, milky quartz, rock crystal, rose quartz, smoky quartz, tiger's-eye.&lt;head rend="h3"&gt;Rock Types&lt;/head&gt;: andesite, basalt, diorite, gabbro, granite, mookaite, novaculite, quartzite, unakite.&lt;head rend="h2"&gt;The "Golden Rules" of Rock Tumbling&lt;/head&gt;&lt;p&gt;We follow three "Golden Rules" in all aspects of rock tumbling. They are:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;"Garbage in means garbage out"&lt;/item&gt;&lt;item&gt;"Avoid contamination"&lt;/item&gt;&lt;item&gt;"Great results take time."&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Tumbling will enable you to turn the rough rock on the left side of this photo into the sparkling tumbled stones on the right side of the photo. The results are amazing!&lt;/p&gt;&lt;head rend="h3"&gt;"Garbage in Means Garbage Out"&lt;/head&gt;&lt;p&gt;If you start with garbage (low-quality rough), you should expect low-quality tumbled stones. So, don't hesitate to discard a rock that is porous, fractured, misshapen, or that is not expected to produce an attractive tumbled stone.&lt;/p&gt;&lt;p&gt;You will spend a lot of time and valuable supplies tumbling a batch of rocks. Using quality rough saves time, gives you better value for your money, and produces tumbled stones that are of much higher quality.&lt;/p&gt;&lt;p&gt;We buy lots of tumbling rough from online vendors as part of our hobby and to educate ourselves. We have the best experience buying rough from vendors who: 1) provide clear written descriptions and large clear photos of the rough they are selling, 2) show photos of tumbled stones that they produced themselves from the rock they are selling, and, 3) provide a detailed description of the steps that they followed to tumble the stones. We have the best experience buying rough from people who are actively involved in rock tumbling.&lt;/p&gt;&lt;head rend="h3"&gt;"Avoid Contamination"&lt;/head&gt;&lt;p&gt;You will use a different size tumbler grit for each step of the tumbling process. If coarse grit gets into your medium grit step, it will scratch up the rocks and you might need to do the medium grit step over again.&lt;/p&gt;&lt;p&gt;Avoiding this type of contamination is easy: just thoroughly clean the rocks, the tumbler barrel, and your tools when you change from one grit size to another.&lt;/p&gt;&lt;p&gt;Another way that contamination occurs is when you include rocks that are brittle, or have a granular texture. These rocks might break or shed grains in the tumbler. These grains and broken pieces can scratch up every rock in the barrel.&lt;/p&gt;&lt;p&gt;Here is a test that we use to detect rocks that will shed grains in the tumbler. We pick up a piece of rough in each hand. We then rub them together while applying a bit of pressure. If we are easily dislodging grains from the rock, we believe that the rock will likely shed grains during tumbling.&lt;/p&gt;&lt;p&gt;This type of contamination is also easy to avoid. Simply examine your rocks before tumbling, and don't tumble suspect rocks in the same barrel with quality rough. Tumble new types of rough or suspicious materials separately.&lt;/p&gt;&lt;head rend="h3"&gt;"Great Results Take Time"&lt;/head&gt;&lt;p&gt;Don't be in a hurry. Spend time doing a great job. If you tumble a batch of rocks through the coarse grit step and they still have a few rough edges or are not nicely rounded, don't hesitate to run them through the coarse grit step again. Also, spend the time needed to thoroughly clean your work area, tumbler barrel, rocks, and tools between steps to avoid contamination.&lt;/p&gt;&lt;p&gt;"Garbage in means garbage out." The rocks in this photo do not have the potential to become nice tumbled stones. A rock with voids should be thrown away - the voids will trap grit and contaminate your pre-polish and polishing steps. Protrusions can be trimmed off with a rock saw - and that might yield two nicely rounded rocks.&lt;/p&gt;&lt;head rend="h2"&gt;Inspecting Your Rough&lt;/head&gt;&lt;p&gt;Remember the rule "garbage in means garbage out." Practice that by starting with quality rough, and you will have a chance to produce high-quality tumbled stones. We prepare to tumble by examining our rough rock. If we find porous pieces that might carry grit from one step to the next, we discard them.&lt;/p&gt;&lt;p&gt;Rocks that are fractured will break while tumbling and scratch other rocks in the batch. When we see a fractured rock in our rough, we discard it or break it along that fracture before it is placed in the barrel.&lt;/p&gt;&lt;p&gt;For best results, your tumbler barrel should be loaded with rocks of mixed sizes (from about 1/4 inch up to about 1 1/2 inches in diameter for a 2-pound or 3-pound-capacity barrel). If we need more rocks to fill the barrel to the proper level, we often add rocks that were previously polished but have a rough spot or a blemish that, if ground away, will improve the rock's appearance.&lt;/p&gt;&lt;p&gt;Two final tips before we load the barrel:&lt;/p&gt;&lt;p&gt;1.) Tumbling works best when all of the rocks in the barrel are about the same hardness. If soft rocks are tumbled with harder rocks, the softer rocks will wear away quickly - before the harder rocks are properly shaped and smoothed.&lt;/p&gt;&lt;p&gt;2.) Tumbling works best when all rocks in the barrel are of the same type. If you mix rock types, problems can result - and they will be difficult to diagnose.&lt;/p&gt;&lt;p&gt;When loading the tumbler barrel, you should have pieces of rough with a range of particle sizes. We would mix the above sizes together in the barrel. If you load the barrel with just a few large pieces, there will be very few points of contact between the rocks in the load. Those points of contact are where grit is trapped between the rocks and where grinding occurs. If you have lots of small pieces of rough between the big pieces, there will be many points of contact between the rocks of the load, and the tumbling process will be faster and more effective.&lt;/p&gt;&lt;p&gt;If you don't have small pieces of rock to tumble, you can add small ceramic media to the tumbler barrel. Ceramic media are used as small-size "filler" in tumbling. These tiny cylinders will also act like roller bearings in the barrel and make your load tumble with a smooth action - that smooth action will improve the grinding in the barrel and keep your stones from being bruised. See our video about selecting the right tumbling media.&lt;/p&gt;&lt;head rend="h2"&gt;The Four-Step Tumbling Process&lt;/head&gt;&lt;p&gt;Now you are ready to begin what most people call the "Four-Step Tumbling Process." This is described below for a rotary tumbler with a three-pound-capacity barrel such as the Thumler's Model A-R1, Thumler's Model A-R2, Lortone Model 3A, or the Lortone Model 33B.&lt;/p&gt;&lt;p&gt;If you are tumbling with the Thumler's Model MP-1 tumbler (which has a two-pound-capacity barrel), you can follow the instructions below, but use about two level tablespoons of grit or polish in each of the tumbling steps (Step 1 through Step 4).&lt;/p&gt;&lt;head rend="h2"&gt;Loading the Tumbler Barrel&lt;/head&gt;&lt;p&gt;Before you load the tumbler barrel, be sure that it is perfectly clean. There should be no grit or rock fragments left in the barrel from a previous tumble. To prevent leaks, the rim of the barrel and the lid should be totally free from grit or rock particles.&lt;/p&gt;&lt;p&gt;Once you have a clean barrel, add enough rock to fill the barrel about 1/2 to 2/3 full. With small tumblers it is best to tumble rocks that are between about 1/4" and 1 1/2 inches in size. If you don't have enough rough to fill the barrel at least 2/3 full, the rocks might be tossed around in the tumbler and bruised. (Varieties of quartz bruise very easily.)&lt;/p&gt;&lt;p&gt;It is best to add a variety of rock sizes to the barrel. If you use only large pieces there will be very few contact points between the rocks and very little grinding will occur. If you add a range of rock sizes the small rocks will fill the spaces between the large rocks, creating many more points of contact between the rocks. Grinding occurs when particles of grit get caught between the rocks - so the more points of contact you have, the more effective the grinding.&lt;/p&gt;&lt;p&gt;When tumbling you will place enough rocks in the barrel to make it about 1/2 to 2/3 full. Then, add about two level tablespoons of grit for each pound of rock. Finally, add enough water to almost cover the rock. Now seal the barrel and place it on the tumbler.&lt;/p&gt;&lt;head rend="h2"&gt;STEP 1 - Coarse Grind&lt;/head&gt;&lt;p&gt;The first step of the four-step tumbling process is to run the rocks in the tumbler with coarse grit. We begin with a barrel that is about 1/2 to 2/3 full of tumbling rough, then add two level tablespoons of coarse grit (we use 60/90 grit silicon carbide) for each pound of rock. Then, add water until the water line is just below the top of the rocks. Seal the barrel and run for about seven days.&lt;/p&gt;&lt;p&gt;At the end of seven days, open the barrel. You will find a barrel of rocks in very muddy water! Dump the contents into a screen or a colander over a plastic bucket and rinse off every speck of grit and mud. Wear safety glasses to protect your eyes from a splash of mud.&lt;/p&gt;&lt;p&gt;Used grit and rock mud should never be washed down a drain. It can clog your plumbing system. We wash rocks in a plastic colander over a plastic bucket to keep the mud out of the drain.&lt;/p&gt;&lt;head rend="h3"&gt;Inspecting the Rocks:&lt;/head&gt;Now that you have washed the rocks, it is time to inspect them. Your goal is to determine if they are ready to move on to STEP 2, or if another week in STEP 1 would improve their appearance. We almost always tumble the rocks for a second week in coarse grit. We believe that improves their shape and removes more blemishes from their surface. Then, we usually move all of the rocks to the medium grit step.&lt;head rend="h3"&gt;Perfectionist Tumbling:&lt;/head&gt;Some people want to have more control over the tumbling process and only admit excellent rocks into STEP 2. These people sort their rocks into three categories:&lt;list rend="ul"&gt;&lt;item&gt;1) those that are ready for STEP 2&lt;/item&gt;&lt;item&gt;2) those that could be improved by another week in STEP 1&lt;/item&gt;&lt;item&gt;3) those that should be discarded or trimmed and returned to STEP 1&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Here are some rocks right out of STEP 1. Note how they are covered with a gray "mud." This mud is spent grit and tiny rock particles that were worn off of the rocks during tumbling. Wash the rocks thoroughly so none of this grit goes into STEP 2. We wash our rocks in a colander over a plastic bucket so none of the mud goes down the drain. &lt;lb/&gt;IT IS VERY IMPORTANT TO WASH THE MUD FROM THE ROCKS IMMEDIATELY. If the rock mud is allowed to dry on the rocks, it is almost impossible to wash off.&lt;/p&gt;&lt;p&gt;IT IS VERY IMPORTANT TO WASH THE MUD FROM THE ROCKS IMMEDIATELY. If the rock mud is allowed to dry on the rocks, it is almost impossible to wash off.&lt;/p&gt;&lt;head rend="h2"&gt;STEP 2 - Medium Grind&lt;/head&gt;&lt;p&gt;The second step of the four-step tumbling process is to run the rocks in the tumbler with medium grit. Before you begin it is extremely important to clean all of the coarse grit and rock mud from the rocks, from the tumbler barrel, and from the barrel lid. It is very important to avoid having even a few grains of coarse grit in the medium grind step.&lt;/p&gt;&lt;p&gt;During STEP 1, your rocks were reduced in size. When you return them to the barrel for STEP 2, they will probably not fill the barrel to the recommended 1/2 to 2/3 full level. If the barrel is only 1/2 full or less, the rocks can be tossed violently around in the tumbler. This can break or damage fragile materials such as quartz. So, when tumbling quartz or another fragile material, we always add enough ceramic media (or some rocks that need a little more tumbling) to bring the barrel up to the 1/2 to 2/3 full level.&lt;/p&gt;&lt;p&gt;(This is less important with varieties of chalcedony because it is a more durable material. However, if your tumbler barrel travels at more than about 60 revolutions per minute, we recommend adding enough ceramic media to bring it up to the 2/3 full level regardless of what type of rock is being tumbled.)&lt;/p&gt;&lt;p&gt;After your barrel is at the proper level, add two level tablespoons of medium grit (we use 110/220 grit or 150/220 grit silicon carbide) for each pound of rock (and ceramic media). Then add water until the water line is just below the top of the rocks. Now tumble for seven days.&lt;/p&gt;&lt;p&gt;At the end of seven days, open the barrel and clean all of the grit from the rocks, barrel, and lid (don't let any grit go down the drain). At this point in the tumbling process, a dry rock should have a smooth frosted surface. Inspect the rocks, looking for any that are cracked or broken. If you find any, these rocks should be discarded or saved for the next time you run Step 1.&lt;/p&gt;&lt;p&gt;Used grit and rock mud should never be washed down a drain. It can clog your plumbing system. We wash rocks in a plastic colander over a plastic bucket to keep the mud out of the drain.&lt;/p&gt;&lt;head rend="h2"&gt;STEP 3 - Fine Grind / Pre-polish&lt;/head&gt;&lt;p&gt;The third step of the four-step tumbling process is a week in a fine grit such as 600 grit or 500 grit silicon carbide. Begin with a barrel that is perfectly clean. Place your rough and any ceramics that are with them into the barrel, and add two level tablespoons of fine grit per pound of material. Then add water until it fills the barrel up to just below the top of the rocks. Run this for about seven days, and then do a thorough cleaning of the rocks, the barrel, and the lid.&lt;/p&gt;&lt;p&gt;Remove any rocks that have broken or show signs of fracturing. At this point in the process, the rocks should be extremely smooth, and some of them might display a slight luster.&lt;/p&gt;&lt;p&gt;Be very clean! Before you replace the lid on your barrel, be sure that both the lid and the rim are perfectly clean. This will allow the lid to fit tightly and prevent leaks.&lt;/p&gt;&lt;head rend="h2"&gt;STEP 4 - Polish&lt;/head&gt;&lt;p&gt;Now you are down to the final step - the one that puts a bright shine onto your tumbled stones. Be sure that the rocks and the equipment are perfectly clean. (Some people have an extra barrel that they use only for the polishing step.) A few specks of grit could ruin a great polish.&lt;/p&gt;&lt;p&gt;Place the rocks in the barrel and add two level tablespoons of rock polish (we use TXP aluminum oxide powder for almost all of our rotary tumbling) per pound of material in the barrel. Add water to just below the top of the rocks. Then, close the barrel and run for about seven days.&lt;/p&gt;&lt;p&gt;When you finish this step, your rocks should be bright and shiny. If they are, congratulations! Admire them for a while and share them with your friends.&lt;/p&gt;&lt;p&gt;If the stones have an extremely smooth surface but do not shine, they might need to be cleaned up using the burnishing step described below. If they have scratches on them, then you will need to go back to STEP 2 and repeat the medium grind, fine grind, and polishing steps.&lt;/p&gt;&lt;p&gt;For burnishing we grate up a bar of Ivory Soap with a vegetable grater. Then we add 1/2 tablespoon of grated soap for each pound of rock plus enough warm water to almost cover the rocks. See our video about burnishing polished stones.&lt;/p&gt;&lt;head rend="h2"&gt;Burnishing&lt;/head&gt;&lt;p&gt;Sometimes our stones are a little "hazy" when they come out of the polish, or small particles of polish are in micro-size crevices. We shine and clean them up by tumbling for an hour or so in soapy water. This is called "burnishing."&lt;/p&gt;&lt;p&gt;To burnish, we place the stones in our polish barrel with the normal amount of water, and then we add about 1/2 tablespoon of grated "Ivory" bar soap for each pound of rock (we use "ORIGINAL" Ivory soap - don't use a soap with aloe or abrasive or any other additive - honestly, just get a bar of Ivory soap). Burnishing usually makes the tumbled stones a little brighter, but sometimes it really kicks up the shine.&lt;/p&gt;&lt;p&gt;Print a copy of our free tumbling log and use it to keep your records.&lt;/p&gt;&lt;p&gt;Here are a few of our favorite tumbled stones!&lt;/p&gt;&lt;head rend="h2"&gt;Keeping Records&lt;/head&gt;&lt;p&gt;It is easy to forget what day you started the tumbler or what type of grit was used - especially if you are running multiple tumblers. Keeping records will keep you on track and provide a history that will help you learn. We record material tumbled, start date, abrasive used, media used, finishing date and duration, along with any comments or observations about the results.&lt;/p&gt;&lt;p&gt;To help you with your record keeping, we have prepared a printable tumbling log.&lt;/p&gt;&lt;p&gt;We usually have multiple tumblers running here, and we record every barrel of rock that we tumble on these logs. Even if your memory is better than ours, record-keeping is a good idea. When you learn something that works or something that doesn't, you will have it recorded. This information can help you repeat great results and avoid repeating bad ones. Also, we have trouble remembering which day a barrel of rocks was started. Using the log takes away the chance of forgetting.&lt;/p&gt;&lt;head rend="h2"&gt;Happy Tumbling!&lt;/head&gt;&lt;head rend="h3"&gt;RockTumbler.com Authors&lt;/head&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;Hobart M. King has decades of rock tumbling experience and writes most of the articles on RockTumbler.com. He has a PhD in geology and is a GIA graduate gemologist. He also writes the articles about rocks, minerals and gems on Geology.com.&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45705125</guid><pubDate>Sat, 25 Oct 2025 16:32:40 +0000</pubDate></item><item><title>The Journey Before main()</title><link>https://amit.prasad.me/blog/before-main</link><description>&lt;doc fingerprint="1b83387246253a75"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;&amp;gt; The Journey Before main()_&lt;/head&gt;
    &lt;p&gt;October 25, 2025 · Amit Prasad&lt;/p&gt;
    &lt;p&gt;A while back, I worked on a RISC-V-based userspace simulator for fun. In doing so, taught myself a lot more than I wanted to know about what happens in-between when the Kernel is asked to run a program, and when the first line of our program’s &lt;code&gt;main&lt;/code&gt; function is actually executed. Here’s a summary of that rabbit hole.&lt;/p&gt;
    &lt;head rend="h2"&gt;In the beginning…&lt;/head&gt;
    &lt;p&gt;First question: When is the OS kernel actually asked to run any program? The answer, at least on Linux, is the &lt;code&gt;execve&lt;/code&gt; system call (“syscall”). Let’s take a quick look at that:&lt;/p&gt;
    &lt;code&gt;int execve(const char *filename, char *const argv[], char *const envp[]);&lt;/code&gt;
    &lt;p&gt;This is actually quite straightforward! We pass the name of the exectuable file, a list of arguments, and a list of environment variables. This signals to the kernel where, and how, to start loading the program.&lt;/p&gt;
    &lt;p&gt;Many programming languages provide an interface to execute commands that eventually call &lt;code&gt;execve&lt;/code&gt; under the hood. For example, in Rust, we have:&lt;/p&gt;
    &lt;code&gt;use std::process::Command;

Command::new("ls").arg("-l").spawn();&lt;/code&gt;
    &lt;p&gt;In these higher-level wrappers, the language’s standard library often handles translation of the command name to a full path, acting similarly to how a shell would resolve the command via the &lt;code&gt;PATH&lt;/code&gt; environment variable. The kernel itself, however, expects a proper path to an executable file.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;A note on interpreters: If the executable file starts with a shebang (&lt;/p&gt;&lt;code&gt;#!&lt;/code&gt;), the kernel will use the shebang-specified interpreter to run the program. For example,&lt;code&gt;#!/usr/bin/python3&lt;/code&gt;will run the program using the Python interpreter,&lt;code&gt;#!/bin/bash&lt;/code&gt;will run the program using the Bash shell, etc.&lt;/quote&gt;
    &lt;head rend="h2"&gt;ELF&lt;/head&gt;
    &lt;p&gt;What does an executable file look like? On Linux, it’s ELF, which the kernel knows how to parse. Other operating systems have different formats (e.g. Mach-O on MacOS, PE on Windows), but ELF is the most common format on Linux. I won’t go into too much detail here, to keep things brief, but ELF files have grown out of the original &lt;code&gt;a.out&lt;/code&gt; format, and are expressive enough to support pretty much every program you’ll ever write. Here’s what the header of an ELF file looks like:&lt;/p&gt;
    &lt;code&gt;% readelf -h main # main is an ELF file
ELF Header:
  Magic:   7f 45 4c 46 01 01 01 03 00 00 00 00 00 00 00 00
  Class:                             ELF32
  Data:                              2's complement, little endian
  Version:                           1 (current)
  OS/ABI:                            UNIX - GNU
  ABI Version:                       0
  Type:                              EXEC (Executable file)
  Machine:                           RISC-V
  Version:                           0x1
  Entry point address:               0x10358
  Start of program headers:          52 (bytes into file)
  Start of section headers:          675776 (bytes into file)
  Flags:                             0x1, RVC, soft-float ABI
  Size of this header:               52 (bytes)
  Size of program headers:           32 (bytes)
  Number of program headers:         7
  Size of section headers:           40 (bytes)
  Number of section headers:         32
  Section header string table index: 31&lt;/code&gt;
    &lt;p&gt;The important parts here are:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The “ELF Magic” bytes, which tell the kernel that this is, indeed, an ELF file. &lt;code&gt;45 4c 46&lt;/code&gt;is ASCII for “ELF”!&lt;/item&gt;
      &lt;item&gt;“Class” tells us we’re dealing with a 32-bit executable.&lt;/item&gt;
      &lt;item&gt;“Start of …” tells us where things are in the file, and “Size of …” tells us how big they are; The kernel is effectively given a map of the file.&lt;/item&gt;
      &lt;item&gt;“Entry point address” — Relatively self-explanatory! But we’ll be coming back to this.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Other ELF files will have different entries and specific values, but the general structure is what we’re after here.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;As you can see by the numerous mentions to “RISC-V”, this is an ELF file I compiled and linked targeting the RV32 architecture (which the aforementioned emulator is built for), hence the “32” in “ELF32”, the “RVC” flag, and the “RISC-V” machine type.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;More than just a header&lt;/head&gt;
    &lt;p&gt;ELF files contain everything our program needs to run, including the code, data, symbols, and more. We can see this again with the &lt;code&gt;readelf&lt;/code&gt; command with the &lt;code&gt;-a&lt;/code&gt; flag. Here’s what we care about:&lt;/p&gt;
    &lt;code&gt;Section Headers:
  [Nr] Name              Type            Addr     Off    Size
  [ 0]                   NULL            00000000 000000 000000
  [ 1] .note.ABI-tag     NOTE            00010114 000114 000020
  [ 2] .rela.plt         RELA            00010134 000134 00000c
  [ 3] .plt              PROGBITS        00010140 000140 000010
  [ 4] .text             PROGBITS        00010150 000150 03e652
  [ 5] .rodata           PROGBITS        0004e7b0 03e7b0 01b208
  ...
  [16] .data             PROGBITS        0007a008 069008 000dec
  [17] .sdata            PROGBITS        0007adf4 069df4 000004
  [18] .bss              NOBITS          0007adf8 069df8 002b6c
  ...
  [29] .symtab           SYMTAB          00000000 095124 009040
  [30] .strtab           STRTAB          00000000 09e164 006d10&lt;/code&gt;
    &lt;p&gt;These sections contain code (&lt;code&gt;.text&lt;/code&gt;), data (&lt;code&gt;.data&lt;/code&gt;), space for global variables (&lt;code&gt;.bss&lt;/code&gt;), shims for accessing shared library functions (&lt;code&gt;.plt&lt;/code&gt;), and quite a bit more (including symbol tables for debugging, relocation tables, etc.), most of which we won’t be discussing.&lt;/p&gt;
    &lt;p&gt;So evidently, there’s some code that we care about in the &lt;code&gt;.text&lt;/code&gt; section, so we copy that and call it a day? Not quite. There’s a massive amount of machinery inside the kernel to make all sorts of programs under all sorts of conditions run.&lt;/p&gt;
    &lt;p&gt;For example, the “PLT” (Procedure Linkage Table) is a section that allows us to call functions in “shared libraries”, for example, &lt;code&gt;libc&lt;/code&gt;, without having to package them alongside our program (“dynamically” vs “statically linking”). The ELF file contains a dynamic section which tells the kernel which shared libraries to load, and another section which tells the kernel to dynamically “relocate” pointers to those functions, so everything checks out.&lt;/p&gt;
    &lt;quote&gt;&lt;code&gt;libc&lt;/code&gt;is the C standard library, which contains all the “useful” functions:&lt;code&gt;printf&lt;/code&gt;,&lt;code&gt;malloc&lt;/code&gt;, etc. Various flavors implementing the&lt;code&gt;libc&lt;/code&gt;interfaces exist, most commonly&lt;code&gt;glibc&lt;/code&gt;and&lt;code&gt;musl&lt;/code&gt;. Most of the binaries that are discussed in this post are compiled and linked against&lt;code&gt;musl&lt;/code&gt;, since it’s much easier to statically link.&lt;/quote&gt;
    &lt;p&gt;The symbol table looks something like this:&lt;/p&gt;
    &lt;code&gt;Symbol table '.symtab' contains 2308 entries:
   Num:    Value  Size Type    Bind   Vis      Ndx Name
     0: 00000000     0 NOTYPE  LOCAL  DEFAULT  UND
     1: 00010114     0 SECTION LOCAL  DEFAULT    1 .note.ABI-tag
     2: 00010134     0 SECTION LOCAL  DEFAULT    2 .rela.plt
     3: 00010140     0 SECTION LOCAL  DEFAULT    3 .plt
     4: 00010150     0 SECTION LOCAL  DEFAULT    4 .text
     ...
     1782: 00010358    30 FUNC    GLOBAL HIDDEN     4 _start
     ...
     1917: 00010430    52 FUNC    GLOBAL DEFAULT    4 main
     2201: 00010506   450 FUNC    GLOBAL HIDDEN     4 __libc_start_main
     ...&lt;/code&gt;
    &lt;p&gt;You may ask: “Wow! &lt;code&gt;2308&lt;/code&gt; looks like a lot, right? What behemoth of a program could possibly need that many symbols?“.&lt;/p&gt;
    &lt;p&gt;Good question! Here’s the behemoth:&lt;/p&gt;
    &lt;code&gt;#include &amp;lt;stdio.h&amp;gt;

int main() {
  printf("Hello, World!\n");
  return 0;
}&lt;/code&gt;
    &lt;p&gt;Yeah, that’s it. Now, &lt;code&gt;2308&lt;/code&gt; may be slightly bloated because we link against &lt;code&gt;musl&lt;/code&gt; instead of &lt;code&gt;glibc&lt;/code&gt;, but the point still stands: There’s a lot of stuff going on behind the scenes here.&lt;/p&gt;
    &lt;p&gt;The kernel’s job here is to iterate over each section, loading those marked as “loadable”. Some security mitigations start to become relevant here, such as moving sections around in memory (ASLR — Address Space Layout Randomization), marking sections as non-executable (NX bit — hardware-level security), etc. But ultimately, the kernel loads the code and data into memory, sets up the stack, and prepares to jump to the entry point of the program.&lt;/p&gt;
    &lt;head rend="h2"&gt;The stack&lt;/head&gt;
    &lt;p&gt;Ah yes, the infamous stack! Fortunately for most of us, the stack is something we take for granted. Unfortunately for the kernel, the stack is not some omnipotent magical space that just exists — it needs to be set up properly before our program can run.&lt;/p&gt;
    &lt;p&gt;As a reminder: stack space is typically used for variables, function arguments, “frames” (to keep track of function-local variables, call trees, etc), and a variety of other things, depending on what, and how your program is running.&lt;/p&gt;
    &lt;p&gt;Hypothetically, if we simplify a bit and say that the ELF file is loaded into memory starting at the zero address, the stack is typically placed at the “opposite end” of the memory, from a high address, and grows “downwards” towards the lower addresses, with the space in-between used as heap space, and for other data (shared libraries, mmapped files, etc). This is a simplification, but in fairness, there is significant ambiguity as much of the semantics here depend on the program itself.&lt;/p&gt;
    &lt;p&gt;The stack is also something that is non-empty! Remember &lt;code&gt;argv&lt;/code&gt; and &lt;code&gt;envp&lt;/code&gt; from the &lt;code&gt;execve&lt;/code&gt; call above? Those are passed to the program via the stack. In most programming languages we frequently access these via the various &lt;code&gt;args&lt;/code&gt; and &lt;code&gt;env&lt;/code&gt; utilities, whether that be directly, like in C, or more indirectly, like in Rust (&lt;code&gt;std::env&lt;/code&gt;) or Python (&lt;code&gt;sys.argv&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;The kernel also stores something called the “ELF auxiliary vector” in the nascent stack. This “auxv” contains information about the environment, such as the memory page size, metadata from the ELF file, and other system information. These are important! For example, &lt;code&gt;musl&lt;/code&gt; uses the “page size” entry of the auxv so that &lt;code&gt;malloc&lt;/code&gt; can request and manage memory more optimally. There are over 30 entries in the auxiliary vectors, but not all of them are used by every program (and some may not be defined by the kernel).&lt;/p&gt;
    &lt;p&gt;Let’s pretend we’re the kernel. Here’s a simplified version of how we might setup the stack of a new process (taken and simplified from my RISC-V emulator, which also emulates parts of the kernel):&lt;/p&gt;
    &lt;code&gt;// Choose an arbitrary high address for the stack
let mut sp = 0xCFFF_F000u32; // sp = "stack pointer"
let mut stack_init: Vec&amp;lt;u32&amp;gt; = vec![]; // The stack begins empty.

stack_init.push(args.len()); // argc: number of arguments
for &amp;amp;arg in args.iter().rev() {
    // Copy each argument to the stack
    sp -= arg.len() // move "downwards" in address space
    mem.copy_to(sp, arg);

    // Keep track of the arg pointer in the init vector
    stack_init.push(sp);
}
stack_init.push(0); // argv NULL terminator

// Environment variables are similar:
for &amp;amp;e in env.iter().rev() {
    sp -= e.len();
    mem.copy_to(sp, e);

    stack_init.push(sp);
}
stack_init.push(0); // envp NULL terminator

// Setup the auxiliary vector
stack_init.push(libc_riscv32::AT_PAGESZ); // Keys for auxv
stack_init.push(0x1000); // Values for auxv; this specifies a 4 KiB page size
stack_init.push(libc_riscv32::AT_ENTRY);
stack_init.push(self.pc); // N.B.: We'll be coming back to this
// ...

// Copy the stack init vector, with all the pointers, to the stack
sp -= (stack_init.len() * 4);

mem.copy_to(sp, &amp;amp;stack_init)&lt;/code&gt;
    &lt;p&gt;A diagram might help illustrate what the address space looks like at this point:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Argument Count (argc)&lt;/item&gt;
      &lt;item&gt;Arguments (argv)&lt;/item&gt;
      &lt;item&gt;Environment variables (envp)&lt;/item&gt;
      &lt;item&gt;Auxiliary Vector (auxv)&lt;/item&gt;
      &lt;item&gt;Local variables, stack frames, function calls&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;↓&lt;/p&gt;
    &lt;p&gt;Grows downward&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Shared libraries (libc, etc.)&lt;/item&gt;
      &lt;item&gt;Memory-mapped files&lt;/item&gt;
      &lt;item&gt;Dynamic linker/loader&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;↑&lt;/p&gt;
    &lt;p&gt;Grows upward&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;malloc(), calloc(), realloc() allocations&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;.bss &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Uninitialized global variables&lt;/item&gt;
      &lt;item&gt;Static variables initialized to zero&lt;/item&gt;
      &lt;item&gt;Zero-filled by kernel on program start&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;.data &lt;lb/&gt; "read-write"&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Initialized global variables&lt;/item&gt;
      &lt;item&gt;Static variables with initial values&lt;/item&gt;
      &lt;item&gt;Read-write data from the executable&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;.rodata &lt;lb/&gt; "read-only"&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Literals ("Hello, World!")&lt;/item&gt;
      &lt;item&gt;Constant data&lt;/item&gt;
      &lt;item&gt;Read-only variables&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;.text &lt;lb/&gt; "code"&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Program instructions/machine code&lt;/item&gt;
      &lt;item&gt;_start function (entry point)&lt;/item&gt;
      &lt;item&gt;User code&lt;/item&gt;
      &lt;item&gt;Library function code&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Entrypoint&lt;/head&gt;
    &lt;p&gt;Finally, we get to the “entry point” address, mentioned at several points. This is the address of the first instruction to run in the process. Typically, this is under a function called &lt;code&gt;_start&lt;/code&gt;. Both glibc and musl provide implementations of &lt;code&gt;_start&lt;/code&gt;, but it’s also possible to write your own. Again, here’s a Rust example:&lt;/p&gt;
    &lt;code&gt;// Disable the language runtime, we're DIYing it.
#![no_std]
#![no_main]

#[panic_handler]
fn panic(_info: &amp;amp;core::panic::PanicInfo) -&amp;gt; ! {
    loop {}
}

#[no_mangle]
pub extern "C" fn _start() -&amp;gt; ! {
    // Instead of "waiting" for main, we can immediately start execution.
    loop {}
}&lt;/code&gt;
    &lt;p&gt;Depending on your program, &lt;code&gt;_start&lt;/code&gt; may be the only thing between the entrypoint and your main function, but most languages have some sort of runtime that needs to be initialized first. For example, Rust has &lt;code&gt;std::rt::lang_start&lt;/code&gt;. It’s at this part that things like global constructors, thread-local storage, and other language-specific features are set up.&lt;/p&gt;
    &lt;p&gt;Here, our journey comes to an end — things become much more language-specific from this point on. Most languages will set up their own runtimes (yes, even C and C++ have a “runtime”!), and eventually call the standard &lt;code&gt;main&lt;/code&gt; function we’re normally familiar with.&lt;/p&gt;
    &lt;p&gt;In Rust, the generated code ends up looking like the following:&lt;/p&gt;
    &lt;code&gt;// the user defined main function
fn main() { println!("Hello, world!"); }

// the generated _start function
fn _start() -&amp;gt; {
    let argc = ...; // get argc from stack
    let argv = ...; // get argv from stack
    let envp = ...; // get envp from stack
    let main_fn = main; // pointer to user main function
    std::rt::lang_start(argc, argv, main_fn);
}&lt;/code&gt;
    &lt;p&gt;With the &lt;code&gt;lang_start&lt;/code&gt; function (defined here)[https://github.com/rust-lang/rust/blob/04ff05c9c0cfbca33115c5f1b8bb20a66a54b799/library/std/src/rt.rs#L199] and taking care of the rest.&lt;/p&gt;
    &lt;p&gt;C and C++ have similar, minimal setups. Languages that are traditionally thought to have “heavier” runtimes, such as Java or Python, work the same way, but with the &lt;code&gt;std::rt::lang_start&lt;/code&gt; equivalent doing far more than the Rust/C/C++ runtimes.&lt;/p&gt;
    &lt;p&gt;And there you have it! I’m missing lots of detail here, but hopefully this gives a rough idea of what happens before &lt;code&gt;main()&lt;/code&gt; gets called. I’ve left out complexity that is mostly internal to “real” linux kernels, such as how the kernel sets up address space, the process tables, various group semantics, and et cetera, but I hope this still serves as a decent primer.&lt;/p&gt;
    &lt;p&gt;Feel free to reach out to me with any questions or corrections!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45706380</guid><pubDate>Sat, 25 Oct 2025 19:33:22 +0000</pubDate></item><item><title>Show HN: Shadcn/UI theme editor – Design and share Shadcn themes</title><link>https://shadcnthemer.com</link><description>&lt;doc fingerprint="5b5948a7543b02e7"&gt;
  &lt;main&gt;
    &lt;p&gt;All Themes GitHub ShadCN Themes Discover and create beautiful themes for shadcn/ui Import New Theme Filter by color: Red Orange Yellow Green Teal Blue Purple Pink Gray Black White Loading themes...&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45706487</guid><pubDate>Sat, 25 Oct 2025 19:51:24 +0000</pubDate></item><item><title>AI, Wikipedia, and uncorrected machine translations of vulnerable languages</title><link>https://www.technologyreview.com/2025/09/25/1124005/ai-wikipedia-vulnerable-languages-doom-spiral/</link><description>&lt;doc fingerprint="760a589b28b682a2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How AI and Wikipedia have sent vulnerable languages into a doom spiral&lt;/head&gt;
    &lt;p&gt;Machine translators have made it easier than ever to create error-plagued Wikipedia articles in obscure languages. What happens when AI models get trained on junk pages?&lt;/p&gt;
    &lt;p&gt;When Kenneth Wehr started managing the Greenlandic-language version of Wikipedia four years ago, his first act was to delete almost everything. It had to go, he thought, if it had any chance of surviving.&lt;/p&gt;
    &lt;p&gt;Wehr, who’s 26, isn’t from Greenland—he grew up in Germany—but he had become obsessed with the island, an autonomous Danish territory, after visiting as a teenager. He’d spent years writing obscure Wikipedia articles in his native tongue on virtually everything to do with it. He even ended up moving to Copenhagen to study Greenlandic, a language spoken by some 57,000 mostly Indigenous Inuit people scattered across dozens of far-flung Arctic villages.&lt;/p&gt;
    &lt;p&gt;The Greenlandic-language edition was added to Wikipedia around 2003, just a few years after the site launched in English. By the time Wehr took its helm nearly 20 years later, hundreds of Wikipedians had contributed to it and had collectively written some 1,500 articles totaling over tens of thousands of words. It seemed to be an impressive vindication of the crowdsourcing approach that has made Wikipedia the go-to source for information online, demonstrating that it could work even in the unlikeliest places.&lt;/p&gt;
    &lt;p&gt;There was only one problem: The Greenlandic Wikipedia was a mirage.&lt;/p&gt;
    &lt;p&gt;Virtually every single article had been published by people who did not actually speak the language. Wehr, who now teaches Greenlandic in Denmark, speculates that perhaps only one or two Greenlanders had ever contributed. But what worried him most was something else: Over time, he had noticed that a growing number of articles appeared to be copy-pasted into Wikipedia by people using machine translators. They were riddled with elementary mistakes—from grammatical blunders to meaningless words to more significant inaccuracies, like an entry that claimed Canada had only 41 inhabitants. Other pages sometimes contained random strings of letters spat out by machines that were unable to find suitable Greenlandic words to express themselves.&lt;/p&gt;
    &lt;p&gt;“It might have looked Greenlandic to [the authors], but they had no way of knowing,” complains Wehr.&lt;/p&gt;
    &lt;p&gt;“Sentences wouldn’t make sense at all, or they would have obvious errors,” he adds. “AI translators are really bad at Greenlandic.”&lt;/p&gt;
    &lt;p&gt;What Wehr describes is not unique to the Greenlandic edition.&lt;/p&gt;
    &lt;p&gt;Wikipedia is the most ambitious multilingual project after the Bible: There are editions in over 340 languages, and a further 400 even more obscure ones are being developed and tested. Many of these smaller editions have been swamped with automatically translated content as AI has become increasingly accessible. Volunteers working on four African languages, for instance, estimated to MIT Technology Review that between 40% and 60% of articles in their Wikipedia editions were uncorrected machine translations. And after auditing the Wikipedia edition in Inuktitut, an Indigenous language close to Greenlandic that’s spoken in Canada, MIT Technology Review estimates that more than two-thirds of pages containing more than several sentences feature portions created this way.&lt;/p&gt;
    &lt;p&gt;This is beginning to cause a wicked problem. AI systems, from Google Translate to ChatGPT, learn to “speak” new languages by scraping huge quantities of text from the internet. Wikipedia is sometimes the largest source of online linguistic data for languages with few speakers—so any errors on those pages, grammatical or otherwise, can poison the wells that AI is expected to draw from. That can make the models’ translation of these languages particularly error-prone, which creates a sort of linguistic doom loop as people continue to add more and more poorly translated Wikipedia pages using those tools, and AI models continue to train from poorly translated pages. It’s a complicated problem, but it boils down to a simple concept: Garbage in, garbage out.&lt;/p&gt;
    &lt;p&gt;“These models are built on raw data,” says Kevin Scannell, a former professor of computer science at Saint Louis University who now builds computer software tailored for endangered languages. “They will try and learn everything about a language from scratch. There is no other input. There are no grammar books. There are no dictionaries. There is nothing other than the text that is inputted.”&lt;/p&gt;
    &lt;p&gt;There isn’t perfect data on the scale of this problem, particularly because a lot of AI training data is kept confidential and the field continues to evolve rapidly. But back in 2020, Wikipedia was estimated to make up more than half the training data that was fed into AI models translating some languages spoken by millions across Africa, including Malagasy, Yoruba, and Shona. In 2022, a research team from Germany that looked into what data could be obtained by online scraping even found that Wikipedia was the sole easily accessible source of online linguistic data for 27 under-resourced languages.&lt;/p&gt;
    &lt;p&gt;This could have significant repercussions in cases where Wikipedia is poorly written—potentially pushing the most vulnerable languages on Earth toward the precipice as future generations begin to turn away from them.&lt;/p&gt;
    &lt;p&gt;“Wikipedia will be reflected in the AI models for these languages,” says Trond Trosterud, a computational linguist at the University of Tromsø in Norway, who has been raising the alarm about the potentially harmful outcomes of badly run Wikipedia editions for years. “I find it hard to imagine it will not have consequences. And, of course, the more dominant position that Wikipedia has, the worse it will be.”&lt;/p&gt;
    &lt;head rend="h3"&gt;Use responsibly&lt;/head&gt;
    &lt;p&gt;Automation has been built into Wikipedia since the very earliest days. Bots keep the platform operational: They repair broken links, fix bad formatting, and even correct spelling mistakes. These repetitive and mundane tasks can be automated away with little problem. There is even an army of bots that scurry around generating short articles about rivers, cities, or animals by slotting their names into formulaic phrases. They have generally made the platform better.&lt;/p&gt;
    &lt;p&gt;But AI is different. Anybody can use it to cause massive damage with a few clicks.&lt;/p&gt;
    &lt;p&gt;Wikipedia has managed the onset of the AI era better than many other websites. It has not been flooded with AI bots or disinformation, as social media has been. It largely retains the innocence that characterized the earlier internet age. Wikipedia is open and free for anyone to use, edit, and pull from, and it’s run by the very same community it serves. It is transparent and easy to use. But community-run platforms live and die on the size of their communities. English has triumphed, while Greenlandic has sunk.&lt;/p&gt;
    &lt;p&gt;“We need good Wikipedians. This is something that people take for granted. It is not magic,” says Amir Aharoni, a member of the volunteer Language Committee, which oversees requests to open or close Wikipedia editions. “If you use machine translation responsibly, it can be efficient and useful. Unfortunately, you cannot trust all people to use it responsibly.”&lt;/p&gt;
    &lt;p&gt;Trosterud has studied the behavior of users on small Wikipedia editions and says AI has empowered a subset that he terms “Wikipedia hijackers.” These users can range widely—from naive teenagers creating pages about their hometowns or their favorite YouTubers to well-meaning Wikipedians who think that by creating articles in minority languages they are in some way “helping” those communities.&lt;/p&gt;
    &lt;p&gt;“The problem with them nowadays is that they are armed with Google Translate,” Trosterud says, adding that this is allowing them to produce much longer and more plausible-looking content than they ever could before: “Earlier they were armed only with dictionaries.”&lt;/p&gt;
    &lt;p&gt;This has effectively industrialized the acts of destruction—which affect vulnerable languages most, since AI translations are typically far less reliable for them. There can be lots of different reasons for this, but a meaningful part of the issue is the relatively small amount of source text that is available online. And sometimes models struggle to identify a language because it is similar to others, or because some, including Greenlandic and most Native American languages, have structures that make them badly suited to the way most machine translation systems work. (Wehr notes that in Greenlandic most words are agglutinative, meaning they are built by attaching prefixes and suffixes to stems. As a result, many words are extremely context specific and can express ideas that in other languages would take a full sentence.)&lt;/p&gt;
    &lt;p&gt;Research produced by Google before a major expansion of Google Translate rolled out three years ago found that translation systems for lower-resourced languages were generally of a lower quality than those for better-resourced ones. Researchers found, for example, that their model would often mistranslate basic nouns across languages, including the names of animals and colors. (In a statement to MIT Technology Review, Google wrote that it is “committed to meeting a high standard of quality for all 249 languages” it supports “by rigorously testing and improving [its] systems, particularly for languages that may have limited public text resources on the web.”)&lt;/p&gt;
    &lt;p&gt;Wikipedia itself offers a built-in editing tool called Content Translate, which allows users to automatically translate articles from one language to another—the idea being that this will save time by preserving the references and fiddly formatting of the originals. But it piggybacks on external machine translation systems, so it’s largely plagued by the same weaknesses as other machine translators—a problem that the Wikimedia Foundation says is hard to solve. It’s up to each edition’s community to decide whether this tool is allowed, and some have decided against it. (Notably, English-language Wikipedia has largely banned its use, claiming that some 95% of articles created using Content Translate failed to meet an acceptable standard without significant additional work.) But it’s at least easy to tell when the program has been used; Content Translate adds a tag on the Wikipedia back end.&lt;/p&gt;
    &lt;p&gt;Other AI programs can be harder to monitor. Still, many Wikipedia editors I spoke with said that once their languages were added to major online translation tools, they noticed a corresponding spike in the frequency with which poor, likely machine-translated pages were created.&lt;/p&gt;
    &lt;p&gt;Some Wikipedians using AI to translate content do occasionally admit that they do not speak the target languages. They may see themselves as providing smaller communities with rough-cut articles that speakers can then fix—essentially following the same model that has worked well for more active Wikipedia editions.&lt;/p&gt;
    &lt;quote&gt;
      &lt;head&gt;Google Translate, for instance, says the Fulfulde word for January means June, while ChatGPT says it’s August or September. The programs also suggest the Fulfulde word for “harvest” means “fever” or “well-being,” among other possibilities.&lt;/head&gt;
    &lt;/quote&gt;
    &lt;p&gt;But once error-filled pages are produced in small languages, there is usually not an army of knowledgeable people who speak those languages standing ready to improve them. There are few readers of these editions, and sometimes not a single regular editor.&lt;/p&gt;
    &lt;p&gt;Yuet Man Lee, a Canadian teacher in his 20s, says that he used a mix of Google Translate and ChatGPT to translate a handful of articles that he had written for the English Wikipedia into Inuktitut, thinking it’d be nice to pitch in and help a smaller Wikipedia community. He says he added a note to one saying that it was only a rough translation. “I did not think that anybody would notice [the article],” he explains. “If you put something out there on the smaller Wikipedias—most of the time nobody does.”&lt;/p&gt;
    &lt;p&gt;But at the same time, he says, he still thought “someone might see it and fix it up”—adding that he had wondered whether the Inuktitut translation that the AI systems generated was grammatically correct. Nobody has touched the article since he created it.&lt;/p&gt;
    &lt;p&gt;Lee, who teaches social sciences in Vancouver and first started editing entries in the English Wikipedia a decade ago, says that users familiar with more active Wikipedias can fall victim to this mindset, which he terms a “bigger-Wikipedia arrogance”: When they try to contribute to smaller Wikipedia editions, they assume that others will come along to fix their mistakes. It can sometimes work. Lee says he had previously contributed several articles to Wikipedia in Tatar, a language spoken by several million people mainly in Russia, and at least one of those was eventually corrected. But the Inuktitut Wikipedia is, by comparison, a “barren wasteland.”&lt;/p&gt;
    &lt;p&gt;He emphasizes that his intentions had been good: He wanted to add more articles to an Indigenous Canadian Wikipedia. “I am now thinking that it may have been a bad idea. I did not consider that I could be contributing to a recursive loop,” he says. “It was about trying to get content out there, out of curiosity and for fun, without properly thinking about the consequences.”&lt;/p&gt;
    &lt;head rend="h3"&gt;“Totally, completely no future”&lt;/head&gt;
    &lt;p&gt;Wikipedia is a project that is driven by wide-eyed optimism. Editing can be a thankless task, involving weeks spent bickering with faceless, pseudonymous people, but devotees put in hours of unpaid labor because of a commitment to a higher cause. It is this commitment that drives many of the regular small-language editors I spoke with. They all feared what would happen if garbage continued to appear on their pages.&lt;/p&gt;
    &lt;p&gt;Abdulkadir Abdulkadir, a 26-year-old agricultural planner who spoke with me over a crackling phone call from a busy roadside in northern Nigeria, said that he spends three hours every day fiddling with entries in his native Fulfulde, a language used mainly by pastoralists and farmers across the Sahel. “But the work is too much,” he said.&lt;/p&gt;
    &lt;p&gt;Abdulkadir sees an urgent need for the Fulfulde Wikipedia to work properly. He has been suggesting it as one of the few online resources for farmers in remote villages, potentially offering information on which seeds or crops might work best for their fields in a language they can understand. If you give them a machine-translated article, Abdulkadir told me, then it could “easily harm them,” as the information will probably not be translated correctly into Fulfulde.&lt;/p&gt;
    &lt;p&gt;Google Translate, for instance, says the Fulfulde word for January means June, while ChatGPT says it’s August or September. The programs also suggest the Fulfulde word for “harvest” means “fever” or “well-being,” among other possibilities.&lt;/p&gt;
    &lt;p&gt;Abdulkadir said he had recently been forced to correct an article about cowpeas, a foundational cash crop across much of Africa, after discovering that it was largely illegible.&lt;/p&gt;
    &lt;p&gt;If someone wants to create pages on the Fulfulde Wikipedia, Abdulkadir said, they should be translated manually. Otherwise, “whoever will read your articles will [not] be able to get even basic knowledge,” he tells these Wikipedians. Nevertheless, he estimates that some 60% of articles are still uncorrected machine translations. Abdulkadir told me that unless something important changes with how AI systems learn and are deployed, then the outlook for Fulfulde looks bleak. “It is going to be terrible, honestly,” he said. “Totally, completely no future.”&lt;/p&gt;
    &lt;p&gt;Across the country from Abdulkadir, Lucy Iwuala contributes to Wikipedia in Igbo, a language spoken by several million people in southeastern Nigeria. “The harm has already been done,” she told me, opening the two most recently created articles. Both had been automatically translated via Wikipedia’s Content Translate and contained so many mistakes that she said it would have given her a headache to continue reading them. “There are some terms that have not even been translated. They are still in English,” she pointed out. She recognized the username that had created the pages as a serial offender. “This one even includes letters that are not used in the Igbo language,” she said.&lt;/p&gt;
    &lt;p&gt;Iwuala began regularly contributing to Wikipedia three years ago out of concern that Igbo was being displaced by English. It is a worry that is common to many who are active on smaller Wikipedia editions. “This is my culture. This is who I am,” she told me. “That is the essence of it all: to ensure that you are not erased.”&lt;/p&gt;
    &lt;p&gt;Iwuala, who now works as a professional translator between English and Igbo, said the users doing the most damage are inexperienced and see AI translations as a way to quickly increase the profile of the Igbo Wikipedia. She often finds herself having to explain at online edit-a-thons she organizes, or over email to various error-prone editors, that the results can be the exact opposite, pushing users away: “You will be discouraged and you will no longer want to visit this place. You will just abandon it and go back to the English Wikipedia.”&lt;/p&gt;
    &lt;p&gt;These fears are echoed by Noah Ha‘alilio Solomon, an assistant professor of Hawaiian language at the University of Hawai‘i. He reports that some 35% of words on some pages in the Hawaiian Wikipedia are incomprehensible. “If this is the Hawaiian that is going to exist online, then it will do more harm than anything else,” he says.&lt;/p&gt;
    &lt;p&gt;Hawaiian, which was teetering on the verge of extinction several decades ago, has been undergoing a recovery effort led by Indigenous activists and academics. Seeing such poor Hawaiian on such a widely used platform as Wikipedia is upsetting to Ha‘alilio Solomon.&lt;/p&gt;
    &lt;p&gt;“It is painful, because it reminds us of all the times that our culture and language has been appropriated,” he says. “We have been fighting tooth and nail in an uphill climb for language revitalization. There is nothing easy about that, and this can add extra impediments. People are going to think that this is an accurate representation of the Hawaiian language.”&lt;/p&gt;
    &lt;p&gt;The consequences of all these Wikipedia errors can quickly become clear. AI translators that have undoubtedly ingested these pages in their training data are now assisting in the production, for instance, of error-strewn AI-generated books aimed at learners of languages as diverse as Inuktitut and Cree, Indigenous languages spoken in Canada, and Manx, a small Celtic language spoken on the Isle of Man. Many of these have been popping up for sale on Amazon. “It was just complete nonsense,” says Richard Compton, a linguist at the University of Quebec in Montreal, of a volume he reviewed that had purported to be an introductory phrasebook for Inuktitut.&lt;/p&gt;
    &lt;p&gt;Rather than making minority languages more accessible, AI is now creating an ever expanding minefield for students and speakers of those languages to navigate. “It is a slap in the face,” Compton says. He worries that younger generations in Canada, hoping to learn languages in communities that have fought uphill battles against discrimination to pass on their heritage, might turn to online tools such as ChatGPT or phrasebooks on Amazon and simply make matters worse. “It is fraud,” he says.&lt;/p&gt;
    &lt;head rend="h3"&gt;A race against time&lt;/head&gt;
    &lt;p&gt;According to UNESCO, a language is declared extinct every two weeks. But whether the Wikimedia Foundation, which runs Wikipedia, has an obligation to the languages used on its platform is an open question. When I spoke to Runa Bhattacharjee, a senior director at the foundation, she said that it was up to the individual communities to make decisions about what content they wanted to exist on their Wikipedia. “Ultimately, the responsibility really lies with the community to see that there is no vandalism or unwanted activity, whether through machine translation or other means,” she said. Usually, Bhattacharjee added, editions were considered for closure only if a specific complaint was raised about them.&lt;/p&gt;
    &lt;p&gt;But if there is no active community, how can an edition be fixed or even have a complaint raised?&lt;/p&gt;
    &lt;p&gt;Bhattacharjee explained that the Wikimedia Foundation sees its role in such cases as about maintaining the Wikipedia platform in case someone comes along to revive it: “It is the space that we provide for them to grow and develop. That is where we are at.”&lt;/p&gt;
    &lt;p&gt;Inari Saami, spoken in a single remote community in northern Finland, is a poster child for how people can take good advantage of Wikipedia. The language was headed toward extinction four decades ago; there were only four children who spoke it. Their parents created the Inari Saami Language Association in a last-ditch bid to keep it going. The efforts worked. There are now several hundred speakers, schools that use Inari Saami as a medium of instruction, and 6,400 Wikipedia articles in the language, each one copy-edited by a fluent speaker.&lt;/p&gt;
    &lt;p&gt;This success highlights how Wikipedia can indeed provide small and determined communities with a unique vehicle to promote their languages’ preservation. “We don’t care about quantity. We care about quality,” says Fabrizio Brecciaroli, a member of the Inari Saami Language Association. “We are planning to use Wikipedia as a repository for the written language. We need to provide tools that can be used by the younger generations. It is important for them to be able to use Inari Saami digitally.”&lt;/p&gt;
    &lt;p&gt;This has been such a success that Wikipedia has been integrated into the curriculum at the Inari Saami–speaking schools, Brecciaroli adds. He fields phone calls from teachers asking him to write up simple pages on topics from tornadoes to Saami folklore. Wikipedia has even offered a way to introduce words into Inari Saami. “We have to make up new words all the time,” Brecciaroli says. “Young people need them to speak about sports, politics, and video games. If they are unsure how to say something, they now check Wikipedia.”&lt;/p&gt;
    &lt;p&gt;Wikipedia is a monumental intellectual experiment. What’s happening with Inari Saami suggests that with maximum care, it can work in smaller languages. “The ultimate goal is to make sure that Inari Saami survives,” Brecciaroli says. “It might be a good thing that there isn’t a Google Translate in Inari Saami.”&lt;/p&gt;
    &lt;p&gt;That may be true—though large language models like ChatGPT can be made to translate phrases into languages that more traditional machine translation tools do not offer. Brecciaroli told me that ChatGPT isn’t great in Inari Saami but that the quality varies significantly depending on what you ask it to do; if you ask it a question in the language, then the answer will be filled with words from Finnish and even words it invents. But if you ask it something in English, Finnish, or Italian and then ask it to reply in Inari Saami, it will perform better.&lt;/p&gt;
    &lt;p&gt;In light of all this, creating as much high-quality content online as can possibly be written becomes a race against time. “ChatGPT only needs a lot of words,” Brecciaroli says. “If we keep putting good material in, then sooner or later, we will get something out. That is the hope.” This is an idea supported by multiple linguists I spoke with—that it may be possible to end the “garbage in, garbage out” cycle. (OpenAI, which operates ChatGPT, did not respond to a request for comment.)&lt;/p&gt;
    &lt;p&gt;Still, the overall problem is likely to grow and grow, since many languages are not as lucky as Inari Saami—and their AI translators will most likely be trained on more and more AI slop. Wehr, unfortunately, seems far less optimistic about the future of his beloved Greenlandic.&lt;/p&gt;
    &lt;p&gt;Since deleting much of the Greenlandic-language Wikipedia, he has spent years trying to recruit speakers to help him revive it. He has appeared in Greenlandic media and made social media appeals. But he hasn’t gotten much of a response; he says it has been demoralizing.&lt;/p&gt;
    &lt;p&gt;“There is nobody in Greenland who is interested in this, or who wants to contribute,” he says. “There is completely no point in it, and that is why it should be closed.”&lt;/p&gt;
    &lt;p&gt;Late last year, he began a process requesting that the Wikipedia Language Committee shut down the Greenlandic-language edition. Months of bitter debate followed between dozens of Wikipedia bureaucrats; some seemed to be surprised that a superficially healthy-seeming edition could be gripped by so many problems.&lt;/p&gt;
    &lt;p&gt;Then, earlier this month, Wehr’s proposal was accepted: Greenlandic Wikipedia is set to be shuttered, and any articles that remain will be moved into the Wikipedia Incubator, where new language editions are tested and built. Among the reasons cited by the Language Committee is the use of AI tools, which have “frequently produced nonsense that could misrepresent the language.”&lt;/p&gt;
    &lt;p&gt;Nevertheless, it may be too late—mistakes in Greenlandic already seem to have become embedded in machine translators. If you prompt either Google Translate or ChatGPT to do something as simple as count to 10 in proper Greenlandic, neither program can deliver.&lt;/p&gt;
    &lt;p&gt;Jacob Judah is an investigative journalist based in London.&lt;/p&gt;
    &lt;head rend="h3"&gt;Deep Dive&lt;/head&gt;
    &lt;head rend="h3"&gt;Artificial intelligence&lt;/head&gt;
    &lt;head rend="h3"&gt;It’s surprisingly easy to stumble into a relationship with an AI chatbot&lt;/head&gt;
    &lt;p&gt;We’re increasingly developing bonds with chatbots. While that’s safe for some, it’s dangerous for others.&lt;/p&gt;
    &lt;head rend="h3"&gt;Therapists are secretly using ChatGPT. Clients are triggered.&lt;/head&gt;
    &lt;p&gt;Some therapists are using AI during therapy sessions. They’re risking their clients’ trust and privacy in the process.&lt;/p&gt;
    &lt;head rend="h3"&gt;OpenAI is huge in India. Its models are steeped in caste bias.&lt;/head&gt;
    &lt;p&gt;India is OpenAI’s second-largest market, but ChatGPT and Sora reproduce caste stereotypes that harm millions of people.&lt;/p&gt;
    &lt;head rend="h3"&gt;AI models are using material from retracted scientific papers&lt;/head&gt;
    &lt;p&gt;Some companies are working to remedy the issue.&lt;/p&gt;
    &lt;head rend="h3"&gt;Stay connected&lt;/head&gt;
    &lt;head rend="h2"&gt;Get the latest updates from&lt;lb/&gt;MIT Technology Review&lt;/head&gt;
    &lt;p&gt;Discover special offers, top stories, upcoming events, and more.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45706518</guid><pubDate>Sat, 25 Oct 2025 19:57:48 +0000</pubDate></item><item><title>California invests in battery energy storage, leaving rolling blackouts behind</title><link>https://www.latimes.com/environment/story/2025-10-17/california-made-it-through-another-summer-without-a-flex-alert</link><description>&lt;doc fingerprint="235081ed63971539"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Share via&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;California hasn’t issued an emergency plea for the public to conserve energy, known as a Flex Alert, since 2022.&lt;/item&gt;
      &lt;item&gt;Experts credit much of the progress to a surge in battery energy storage systems in recent years.&lt;/item&gt;
      &lt;item&gt;Battery storage in California has grown more than 3,000% since 2020.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For decades, rolling blackouts and urgent calls for energy conservation were part of life in California — a reluctant summer ritual almost as reliable as the heat waves that drove them. But the state has undergone a quiet shift in recent years, and the California Independent System Operator hasn’t issued a single one of those emergency pleas, known as Flex Alerts, since 2022.&lt;/p&gt;
    &lt;p&gt;Experts and officials say the Golden State has reached a turning point, reflecting years of investment in making its electrical grid stronger, cleaner and more dependable. Much of that is new battery energy storage, which captures and stores electricity for later use.&lt;/p&gt;
    &lt;p&gt;In fact, batteries have been transformative for California, state officials say. In late afternoon, when the sun stops hitting solar panels and people are home using electricity, batteries now push stored solar energy onto the grid.&lt;/p&gt;
    &lt;p&gt;California has invested heavily in the technology, helping it mature and get cheaper in recent years. Battery storage in the state has grown more than 3,000% in six years — from 500 megawatts in 2020 to more than 15,700 megawatts today.&lt;/p&gt;
    &lt;p&gt;“There is no question that the battery fleet that has grown rapidly since 2020, along with the state’s expanding portfolio of other supply and demand-side resources, has been a real game changer for reliability during summer periods of peak demand,” said Elliot Mainzer, CAISO’s president and chief executive.&lt;/p&gt;
    &lt;p&gt;It was only five years ago that a record-shattering heat wave pushed the grid to its limit and plunged much of the state into darkness. In the wake of that event, California’s energy leaders vowed to take action to make the grid more resilient.&lt;/p&gt;
    &lt;p&gt;Since then, CAISO has overseen a massive build-out of new energy and storage resources, including more than 26,000 megawatts of new capacity overall, which has also helped make the grid more stable, Mainzer said. The state hasn’t seen rolling blackouts since 2020.&lt;/p&gt;
    &lt;p&gt;“Extreme weather events, wildfires and other emergencies can pose reliability challenges for any bulk electric system,” he said. “But the CAISO battery fleet, along with the additional capacity and close coordination with state and regional partners, have provided an indisputable benefit to reliability.”&lt;/p&gt;
    &lt;p&gt;An immense solar-plus-storage power plant in the desert is now pumping out inexpensive clean electricity at full bore.&lt;/p&gt;
    &lt;p&gt;Batteries are now key to California’s climate goals, including its mandate of 100% carbon neutrality by 2045.&lt;/p&gt;
    &lt;p&gt;Already, batteries have enabled the grid to operate with dramatic decreases in the use of planet-warming fossil fuels. Now they’re becoming a more cost-effective and reliable replacement for aging gas-fired power plants, according to Maia Leroy, founder of the California energy consulting firm Lumenergy LLC and co-author of a recent report on the rise of battery storage over gas generation in California.&lt;/p&gt;
    &lt;p&gt;“Historically, Flex Alerts have always come through in summertime when it’s super hot and everyone is cranking their AC,” Leroy said. “But also in the summertime, we’re seeing that gas plants underperform because combustion doesn’t work well with ambient heat. So when we’re able to shift that need from having to use gas plants to something more stable, dispatchable and flexible like battery storage, then we’re able to meet that demand in the summer without having to rely on those underperforming gas plants.”&lt;/p&gt;
    &lt;p&gt;Battery energy storage is not without challenges, however. Lithium-ion batteries — the most common type used for energy storage — typically have about four to six hours of capacity. It’s enough to support the grid during peak hours as the sun sets, but can still leave some gaps to be filled by natural gas.&lt;/p&gt;
    &lt;p&gt;Nikhil Kumar, program director with the energy policy nonprofit GridLab, said the technology already exists for longer-duration batteries, including through different chemistries such as iron-air batteries, which release energy through oxidation, and flow batteries, which store energy in liquid chemicals that flow through a reactor.&lt;/p&gt;
    &lt;p&gt;Those batteries are not yet as mature and can be more expensive and larger than their lithium-ion counterparts, Kumar said. But a recent GridLab report indicates that equation is changing, with the average cost of a new gas plant often on par with four-hour lithium-ion batteries and only slightly less expensive than longer-duration battery technologies.&lt;/p&gt;
    &lt;p&gt;“Batteries are going to get cheaper,” Kumar said. “Gas isn’t.”&lt;/p&gt;
    &lt;p&gt;The Trump administration said it will open 13 million acres of federal lands for coal mining and provide $625 million to recommission or modernize coal-fired power plants.&lt;/p&gt;
    &lt;p&gt;The battery storage shift is occurring as the Trump administration takes steps to stifle solar and other forms of renewable energy in favor of fossil fuels such as oil, gas and coal. At the end of September, the administration announced that it would open 13 million acres of federal lands for coal mining and provide $625 million to recommission or modernize coal-fired powered plants, which officials said would help strengthen the economy, protect jobs and advance American energy.&lt;/p&gt;
    &lt;p&gt;During an hourlong news conference on the initiative, Interior Secretary Doug Burgum described wind and solar energy as intermittent sources that are “literally dependent on the weather” — but neither he nor any other official mentioned the growth of battery storage that has made those sources more reliable and more promising.&lt;/p&gt;
    &lt;p&gt;It’s not a partisan issue. ERCOT, which operates Texas’ electrical grid, has more than 14,000 megawatts of batteries online, a nearly threefold increase from early 2023. California and Texas are constantly trading places as the top state for battery storage.&lt;/p&gt;
    &lt;p&gt;But Trump has made moves to support the production of batteries in the U.S. Currently, about three-quarters of the world’s batteries are made in China, and Trump’s tariffs — including a proposed 100% tariff on China — have been good for at least one Sacramento-based battery manufacturer, Sparkz.&lt;/p&gt;
    &lt;p&gt;“The administration wants critical material manufacturing to happen in the U.S.,” said Sanjiv Malhotra, founder and chief executive. “They basically are very much in favor of domestic manufacturing of batteries.”&lt;/p&gt;
    &lt;p&gt;Sparkz is making lithium-iron batteries that don’t use nickel and cobalt — a composition that has long been an industry darling but that depends on imported metals. Instead, their lithium-iron-phosphate batteries have a supply chain that is entirely based in the U.S., which means they can take advantage of federal tax credits that favor the production of clean energy components made mostly of domestic parts, Malhotra said. The company’s clients include data centers and utilities.&lt;/p&gt;
    &lt;p&gt;Malhotra added that California has done an excellent job “beefing up” the grid’s storage capacity in the last few years. He said batteries are a major reason why the state hasn’t seen a Flex Alert since 2022.&lt;/p&gt;
    &lt;p&gt;“The numbers basically tell the story that it was all because of, essentially, energy storage,” he said.&lt;/p&gt;
    &lt;p&gt;There is still work to do. While the state’s grid has seen improvements, it is more than a century old and was built primarily for gas plants. Experts and officials agree that it needs additional substantial upgrades and reforms to meet current energy demands and goals.&lt;/p&gt;
    &lt;p&gt;Permitting is also a hurdle, as California typically requires lengthy environmental review for new projects. The state, sometimes controversially, is now speeding review, and recently approved a massive solar and battery storage farm, the Darden Clean Energy Project in Fresno County, through a new fast-track permitting program. It will make enough electricity to power 850,000 homes for four hours, according to the California Energy Commission.&lt;/p&gt;
    &lt;p&gt;A plume of material released from the plant contained hydroflouride, a toxic gas, that is now being monitored by Monterey County.&lt;/p&gt;
    &lt;p&gt;Safety remains a considerable concern. In January, a fire tore through one of the world’s largest battery storage facilities in Moss Landing, Monterey County. The facility housed around 100,000 lithium-ion batteries, which are exceptionally dangerous when ignited because they burn extremely hot and cannot be extinguished with water, which can trigger a violent chemical reaction. The blaze emitted dangerous levels of nickel, cobalt and manganese that were measured within miles of the site.&lt;/p&gt;
    &lt;p&gt;“When you’re dealing with large technologies in general, there’s always going to be some kind of danger,” said Leroy, of Lumenergy. “This points to the big need for diversifying the technologies that we use.”&lt;/p&gt;
    &lt;p&gt;Other forms of energy, such as oil and coal, also pose considerable health and safety risks including the emission of air pollution — soot, mercury, nitrogen dioxide and carbon dioxide contributing to climate change.&lt;/p&gt;
    &lt;p&gt;California is in the process of eliminating coal power and expects to be completely coal-free by November. And while natural gas still makes up a large piece of the state’s portfolio, renewables represented nearly 60% of California’s in-state electricity generation in 2024, according to the U.S. Energy Information Administration.&lt;/p&gt;
    &lt;p&gt;The numbers continue to trend upward. In the first six months of this year, CAISO’s grid was powered by 100% clean energy for an average of almost seven hours each day.&lt;/p&gt;
    &lt;p&gt;“We have literally just demonstrated that California is able to run with super clean resources, with backups from natural gas,” said Kumar, of GridLab. “And it works. We don’t have Flex Alerts.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45706527</guid><pubDate>Sat, 25 Oct 2025 19:58:55 +0000</pubDate></item><item><title>ProEnergy repurposes jet engines to power data centers</title><link>https://www.datacenterdynamics.com/en/news/proenergy-offers-repurposed-jet-engines-to-data-cent/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45706534</guid><pubDate>Sat, 25 Oct 2025 19:59:32 +0000</pubDate></item><item><title>Torchcomms: A modern PyTorch communications API</title><link>https://pytorch.org/blog/torchcomms/</link><description>&lt;doc fingerprint="6d0ad4f949951ce4"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Torchcomms is a new experimental, lightweight communication API intended for use with PyTorch Distributed (PTD). In addition to the core API, we are open-sourcing NCCLX, a new backend we developed to scale to over 100,000 GPUs.&lt;/p&gt;
    &lt;p&gt;With our first release of torchcomms, we’re delivering the foundational APIs and backends required for large-scale model training in PyTorch. This initial release focuses on core communication primitives that enable reliable and performant distributed training at scale. Over the next year, we’ll continue to mature the offering—introducing features that make it easier to prototype new collectives, scale seamlessly with built-in fault tolerance, and optimize device-centric communication patterns. Our roadmap is focused on empowering researchers and developers to move faster, test new ideas at scale, and build the next generation of large-scale AI systems.&lt;/p&gt;
    &lt;p&gt;Torchcomms is our first step toward proving out new communication paradigms at scale. To accelerate innovation, we’re developing the API fully in the open, inviting community feedback as it evolves. Because of this open development process, the API is still early and may undergo breaking changes as it matures. Over time, torchcomms will serve as a proving ground for next-generation distributed technologies, with the long-term goal of migrating all PyTorch Distributed functionality onto this new foundation. As torchcomms stabilizes, it will become the backbone of scalable, fault-tolerant, and device-centric distributed training in PyTorch.&lt;/p&gt;
    &lt;head rend="h3"&gt;Project Goals&lt;/head&gt;
    &lt;p&gt;With torchcomms, we’re laying the groundwork for the next generation of distributed communication in PyTorch. Our goal is to build a flexible, extensible foundation that enables developers and researchers to move faster, scale further, and target a wider variety of hardware. Specifically, we’re working toward the following objectives:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Fast Prototyping of Communication Primitives – Machine learning researchers need to experiment rapidly with new communication paradigms. By decoupling communications from PyTorch’s core numeric primitives, torchcomms makes it possible to iterate on communication layers independently—adding new collectives, APIs, or backends without breaking existing functionality. This design also enables out-of-tree backends, allowing researchers and hardware vendors to easily integrate specialized communication stacks tailored to their devices and features.&lt;/item&gt;
      &lt;item&gt;Scaling to 100K+ GPUs – Scaling modern training workloads to hundreds of thousands of GPUs requires rethinking how communication resources are managed. Current approaches, such as lazy initialization and limited concurrency semantics for point-to-point operations, constrain scalability within libraries like NCCL. Torchcomms introduces eager initialization (where backend resources are explicitly managed by the user) and model-specific hints to optimize how communicators, NVLink buffers, and RoCE resources are allocated and shared—paving the way for truly massive distributed jobs.&lt;/item&gt;
      &lt;item&gt;Heterogeneous Hardware Support – Existing collective backends are typically optimized for a single vendor or hardware family. With torchcomms, we’re designing for heterogeneous systems from the ground up—enabling mixed deployments that span multiple hardware generations and vendors within a single training job. This flexibility is critical as the ecosystem evolves beyond homogeneous GPU clusters.&lt;/item&gt;
      &lt;item&gt;Fault Tolerance at Scale – Today’s open-source PyTorch Distributed lacks robust fault-tolerant process groups, which limits the reliability of higher-level libraries like torchft. Torchcomms aims to close that gap by open-sourcing a fault-tolerant backend capable of supporting algorithms such as fault-tolerant HSDP and fault-tolerant Streaming DiLoCo at scale—delivering resilience without compromising performance.&lt;/item&gt;
      &lt;item&gt;One-Sided Communication – One-sided communication (e.g., RDMA-style semantics) is increasingly essential for asynchronous workflows in reinforcement learning, checkpointing, and large language models. Torchcomms will provide first-class support for one-sided communication, enabling efficient, low-overhead message passing and data exchange between distributed processes.&lt;/item&gt;
      &lt;item&gt;Device-Centric Collectives – To achieve ultra-low latency for inference and training, communication and computation must be tightly coupled. Torchcomms is developing device-centric collective APIs, which enable communication metadata and logic to live directly on the device (e.g. the GPU). This includes both direct RDMA operations from the GPU (e.g., IBGDA) and CPU proxy-based designs. These capabilities allow developers to fuse compute and communication operations seamlessly, unlocking new levels of performance.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Why a new API?&lt;/head&gt;
    &lt;p&gt;A common question we hear is: “Why a new API?”&lt;/p&gt;
    &lt;p&gt;With torchcomms, we’re pursuing a set of ambitious goals—introducing capabilities that don’t yet exist in any other communication library today. To move quickly, we need the freedom to iterate in the open and evolve the design without being constrained by existing interfaces. This means that, during its early stages, the API may experience breaking changes as we experiment and refine it in collaboration with the community.&lt;/p&gt;
    &lt;p&gt;The existing c10d APIs in PyTorch Distributed carry significant technical debt, making them difficult to extend or modernize. As the torchcomms API stabilizes, we plan to deprecate the old c10d::Backend interface and adopt torchcomms as the underlying implementation for PyTorch Distributed. This transition will be done gradually and with minimal disruption—most users and models will continue to work as they do today, while automatically benefiting from the performance, scalability, and flexibility of the new backends.&lt;/p&gt;
    &lt;head rend="h2"&gt;Quickstart&lt;/head&gt;
    &lt;p&gt;First, see the Installation instructions for how to install torchcomms.&lt;/p&gt;
    &lt;p&gt;For more documentation, check out: https://meta-pytorch.org/torchcomms/&lt;/p&gt;
    &lt;head rend="h3"&gt;Basic Usage&lt;/head&gt;
    &lt;p&gt;Torchcomms is a lightweight wrapper around the underlying backends and communicators. The core APIs map directly to the backend methods and are designed as a fully object-oriented API.&lt;/p&gt;
    &lt;quote&gt;import torchcomms # Eagerly initialize a communicator using MASTER_PORT/MASTER_ADDR/RANK/WORLD_SIZE environment variables provided by torchrun. # This communicator is bound to a single device. comm = torchcomms.new_comm("ncclx", torch.device("cuda"), name="my_comm") print(f"I am rank {comm.get_rank()} of {comm.get_size()}!") t = torch.full((10, 20), value=comm.rank, dtype=torch.float) # run an all_reduce on the current stream comm.allreduce(t, torchcomms.ReduceOp.SUM, async_op=False) # run an all_reduce on the background stream work = comm.allreduce(t, torchcomms.ReduceOp.SUM, async_op=True) work.wait() # split a communicator into groups of 8 split_groups = torch.arange(comm.get_size()).view(-1, 8).tolist() tp_comm = comm.split(split_groups)&lt;/quote&gt;
    &lt;head rend="h2"&gt;DeviceMesh&lt;/head&gt;
    &lt;p&gt;Torchcomms also supports compatibility with DeviceMesh for compatibility with PyTorch parallelism libraries such as FSDP2.&lt;/p&gt;
    &lt;quote&gt;import torchcomms from torchcomms.device_mesh import init_device_mesh from torch.distributed.fsdp import fully_shard comm = torchcomms.new_comm("ncclx", torch.device("cuda:0"), name="global") mesh = init_device_mesh( mesh_dim_comms=(comm,), mesh_dim_names=("global",), ) fully_shard(model, device_mesh=mesh)&lt;/quote&gt;
    &lt;head rend="h2"&gt;Initial Backends&lt;/head&gt;
    &lt;p&gt;Along with the new torchcomms APIs, we have released several backends for a variety of hardware platforms.&lt;/p&gt;
    &lt;head rend="h3"&gt;NCCLX&lt;/head&gt;
    &lt;p&gt;NCCLX contains the Meta extension to the popular NCCL library. NCCLX is production-tested – it is used for large scale training and inference for large language models (LLMs) such as Llama3 and Llama4. Today, all of Meta’s generative AI services are backed by NCCLX. Some key features of NCCLX include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Scalable initialization&lt;/item&gt;
      &lt;item&gt;Zero-copy and SM-free communication&lt;/item&gt;
      &lt;item&gt;Custom collective algorithms&lt;/item&gt;
      &lt;item&gt;Network traffic load balancing&lt;/item&gt;
      &lt;item&gt;One-sided communication&lt;/item&gt;
      &lt;item&gt;GPU-resident and low latency collectives&lt;/item&gt;
      &lt;item&gt;Fault analyzer and localization&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In parallel with the upstream NCCL, we have developed a separate Custom Transport (CTran) stack to host these Meta in-house optimizations and custom features. CTran contains NVLink, IB/RoCE and TCP transports to support lower-level communication primitives via different hardware routines and build communication algorithms for various communication semantics (e.g., collectives, point-to-point, RMA) over the transports.&lt;/p&gt;
    &lt;p&gt;Both NCCLX and CTran are open sourced today, along with torchcomms. We will discuss more details of NCCLX/CTran in a white paper later this week.&lt;/p&gt;
    &lt;head rend="h3"&gt;NCCL and RCCL&lt;/head&gt;
    &lt;p&gt;In addition to NCCLX, torchcomms also supports upstream NCCL. Current PyTorch Distributed NCCL users can try out torchcomms easily without changing the underlying communication library setup.&lt;/p&gt;
    &lt;p&gt;The AMD RCCL support in the current PyTorch Distributed is through the NCCL process group. As part of torchcomms release, we have also included a native RCCL backend. This allows torchcomms to provide native multi-vendor GPU support from Day 1. It allows different libraries to evolve more independently.&lt;/p&gt;
    &lt;head rend="h3"&gt;Gloo&lt;/head&gt;
    &lt;p&gt;You may know of Gloo as the backend you use when you need to transfer CPU metadata between machines or for tests. That is the main use case but it also has some new advanced features such as infiniBand and one sided operations. We recently also added a new “lazy init” mode that allows Gloo to scale to 100k or more workers.&lt;/p&gt;
    &lt;head rend="h2"&gt;Composability: torchtitan&lt;/head&gt;
    &lt;p&gt;We’ve demonstrated compatibility and correctness of the new torchcomms API by integrating it in with torchtitan. This uses the device mesh integration to provide compatibility with the existing PyTorch technologies, such as FSDP2 and tensor parallelism.&lt;/p&gt;
    &lt;p&gt;Link to torchtitan integration, the integration code will be under path: torchtitan/experiments/torchcomms/.&lt;/p&gt;
    &lt;p&gt;Link to torchtitan loss/performance curves: (with FSDP2)&lt;/p&gt;
    &lt;head rend="h2"&gt;New APIs&lt;/head&gt;
    &lt;head rend="h3"&gt;Collective Semantic Changes&lt;/head&gt;
    &lt;p&gt;We’ve made a number of changes to the existing collectives that were inherited from the existing PyTorch Distributed APIs. These are intended to make the high level semantics better match the underlying device semantics and to improve flexibility.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;All operations are done through object oriented APIs rather than using the global dist.* APIs.&lt;/item&gt;
      &lt;item&gt;Each torchcomm.TorchComm object maps to a single device and communicator.&lt;/item&gt;
      &lt;item&gt;Backends are eagerly initiated and require a device to be passed in at creation time.&lt;/item&gt;
      &lt;item&gt;All operations use the communicator ranks rather than “global” ranks.&lt;/item&gt;
      &lt;item&gt;All operations execute in order they were issued and concurrent operations must be run using the batch API.&lt;/item&gt;
      &lt;item&gt;send/recvs do not execute concurrently unless issued via the batch API.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Window APIs&lt;/head&gt;
    &lt;p&gt;We’re adding support for window APIs to allow for dynamic put/get operations on remote memory. For certain use cases including checkpointing, async operations this can be significantly more performant and easier to express since only one side needs to be involved unlike traditional collectives.&lt;lb/&gt; The window APIs enable users to create a memory buffer—either in GPU or CPU memory—across different ranks. Once created, the buffer is automatically registered and can be accessed via the provided Put and Get APIs, leveraging the underlying RDMA or NVL transport for zero-copy, one-sided communication. Additionally, the window APIs offer an atomic signaling mechanism, further enhancing asynchronous communication capabilities.&lt;/p&gt;
    &lt;p&gt;The window APIs are under active development and still experimental.&lt;/p&gt;
    &lt;head rend="h3"&gt;Transport APIs&lt;/head&gt;
    &lt;p&gt;We’re adding transport APIs that allow for doing point to point operations using the underlying transport directly. This provides a similar API to window APIs but not tied to a collective library. Initially we’re providing support just for RDMA over a dedicated Network which is intended for use in RPC like operations. This is internally supported by the IB backend in CTran.&lt;/p&gt;
    &lt;p&gt;The RdmaTransport provides a write API that allows users to directly write into the remote memory. Users would need to register the memory and exchange its handle between processes to facilitate the write. This is effectively a zero copy data transfer, and can be done for a CPU or GPU memory in a zero copy fashion. These APIs are only transport APIs and do no compute (no reduce, etc).&lt;/p&gt;
    &lt;p&gt;The transport APIs are under active development and are still experimental.&lt;/p&gt;
    &lt;head rend="h3"&gt;Fault Tolerance APIs&lt;/head&gt;
    &lt;p&gt;We’re working on creating a new backend that provides fault tolerant collectives. This new backend is built entirely on the CTran transport and provides failure detection, timeouts, error recovery and safe reconfiguration after errors.&lt;/p&gt;
    &lt;head rend="h2"&gt;Extensibility&lt;/head&gt;
    &lt;head rend="h3"&gt;Extending Backends with New Collectives&lt;/head&gt;
    &lt;p&gt;Torchcomms is designed to support direct access to the underlying backends. This allows for fast prototyping of new APIs before we standardize them and add them to the shared backend interface.&lt;/p&gt;
    &lt;p&gt;Here’s an example of adding a new custom operation:&lt;/p&gt;
    &lt;quote&gt;class TorchCommMyBackend : public TorchCommBackend { public: std::shared_ptr&amp;lt;TorchWork&amp;gt; quantized_all_reduce( at::Tensor&amp;amp; tensor, ReduceOp op, bool async_op) { // your implementation } }; PYBIND11_MODULE(_comms_my_backend, m) { py::class_&amp;lt;TorchCommMyBackend, std::shared_ptr&amp;lt;TorchCommMyBackend&amp;gt;&amp;gt;( m, "TorchCommMyBackend") .def( "quantized_all_reduce", &amp;amp;TorchCommMyBackend::quantized_all_reduce, py::call_guard&amp;lt;py::gil_scoped_release&amp;gt;()); }&lt;/quote&gt;
    &lt;p&gt;To use in your model, it’s as easy as calling&lt;code&gt;unsafe_get_backend()&lt;/code&gt;and calling the new method.&lt;/p&gt;
    &lt;quote&gt;import torchcomms comm = torchcomms.new_comm("my_backend") backend = comm.unsafe_get_backend() backend.quantized_all_reduce(t, ReduceOp.SUM, async_op=False)&lt;/quote&gt;
    &lt;p&gt;Once prototyping is done, we’re happy to upstream new operations into the standard torchcomms API.&lt;/p&gt;
    &lt;head rend="h3"&gt;Writing a new torchcomm Backend&lt;/head&gt;
    &lt;p&gt;One of the key features of torchcomms is that it makes it much easier to write third-party backends. These backends no longer need to be built as part of PyTorch and can be simply installed like any other Python extension using pip.&lt;/p&gt;
    &lt;p&gt;To write a new backend you need to implement the TorchCommBackend interface: https://github.com/meta-pytorch/torchcomms/blob/main/comms/torchcomms/TorchCommBackend.hpp&lt;/p&gt;
    &lt;quote&gt;// MyBackend.hpp class MyBackend : public TorchCommBackend { public: ... }; // MyBackend.cpp namespace { class MyBackendRegistration { public: MyBackendRegistration() { TorchCommFactory::get().register_backend( "my_backend", []() { return std::make_shared&amp;lt;MyBackend&amp;gt;(); }); } }; static MyBackendRegistration registration{}; } // MyBackendPy.cpp PYBIND11_MODULE(_comms_my_backend, m) { py::class_&amp;lt;MyBackend, std::shared_ptr&amp;lt;MyBackend&amp;gt;&amp;gt;(m, "MyBackend"); }&lt;/quote&gt;
    &lt;p&gt;Once you have your Python C extension building you then just need to add some metadata to the setup.py so torchcomms can find it.&lt;/p&gt;
    &lt;quote&gt;setup( name="my_backend", entry_points={ "torchcomms.backends": [ "my_backend = my_backend._comms_my_backend", ] }, )&lt;/quote&gt;
    &lt;p&gt;Then you can use it like any other backend after you &lt;code&gt;pip install&lt;/code&gt;it.&lt;/p&gt;
    &lt;quote&gt;import torchcomms comm = torchcomms.new_comm("my_backend", ...)&lt;/quote&gt;
    &lt;head rend="h1"&gt;Next Steps&lt;/head&gt;
    &lt;p&gt;Torchcomms is a brand new API and is very much under active development. We’d love for you to get involved so please reach out if you’re interested in using it or want to help improve it.&lt;/p&gt;
    &lt;p&gt;We’re actively working on the features described in this blog post and hope to have them stabilized in the near future as well as improving hardware support for more devices.&lt;/p&gt;
    &lt;p&gt;For more documentation check out: https://meta-pytorch.org/torchcomms/&lt;/p&gt;
    &lt;head rend="h2"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;We would like to acknowledge the contributions of many current and former Meta employees who have played a crucial role in developing torchcomms and torchcomms-backends for large-scale training and inference in production. In particular, we would like to extend special thanks to Tristan Rice, Pavan Balaji, Subodh Iyengar, Qiye Tan, Rodrigo De Castro, Sudharssun Subramanian, Junjie Wang, Feng Tian, Saif Hasan, Min Si, Yifan Mao, Dingming Wu, Zhaoyang Han, Blake Matheny, Art Zhu, Denis Boyda, Regina Ren, Jingyi Yang, Bingzhe Liu, Shuqiang Zhang, Mingran Yang, Cen Zhao, Adi Gangidi, Ashmitha Jeevaraj Shetty, Bruce Wu, Ching-Hsiang Chu, Yulun Wang, Srinivas Vaidyanathan, Chris Gottbrath, Davide Italiano, Shashi Gandham, Omar Baldonado, James Hongyi Zeng&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45706545</guid><pubDate>Sat, 25 Oct 2025 20:00:36 +0000</pubDate></item><item><title>Global key-value metadata storage for Scryer Prolog</title><link>https://github.com/jjtolton/environment.pl</link><description>&lt;doc fingerprint="b0d73452e5a10bbc"&gt;
  &lt;main&gt;
    &lt;p&gt;A global environment/context management system for Scryer Prolog providing key-value metadata storage one level of abstraction above the blackboard.&lt;/p&gt;
    &lt;p&gt;This library provides a clean interface for managing global state in Prolog programs using association trees (AVL trees) backed by the blackboard. It offers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Global persistent storage - Changes persist across backtracking&lt;/item&gt;
      &lt;item&gt;Backtrackable local storage - Changes roll back on backtracking&lt;/item&gt;
      &lt;item&gt;Type-safe reified predicates - Use &lt;code&gt;if_/3&lt;/code&gt;for conditional logic without cuts&lt;/item&gt;
      &lt;item&gt;Once-only initialization - Prevent accidental double initialization&lt;/item&gt;
      &lt;item&gt;Key existence checking - Efficiently check for key presence&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;bakage.pl install environment&lt;/code&gt;
    &lt;p&gt;Copy &lt;code&gt;environment.pl&lt;/code&gt; to your project's library directory or ensure it's in your Scryer Prolog load path.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;library(reif)&lt;/code&gt;- Reified predicates for conditional logic&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;library(assoc)&lt;/code&gt;- Association trees (AVL trees)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;library(iso_ext)&lt;/code&gt;- ISO extensions including blackboard predicates&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;?- use_module(library(environment)).

% Set global values (persistent across backtracking)
?- env_set_global(username, 'Alice').
true.

?- env_set_global(counter, 42).
true.

% Retrieve values
?- env_key_val(username, User).
User = 'Alice'.

% Check if key exists (reified)
?- env_check_flag_t(username, T).
T = true.

% Set local value (backtrackable)
?- env_set_local(temp, 'temporary'), env_key_val(temp, V).
V = 'temporary'.

% Initialize once (prevents double initialization)
?- env_set_global_once(config_loaded, true).
true.

?- env_set_global_once(config_loaded, false).
ERROR: runtime_error(env_set_global_once)&lt;/code&gt;
    &lt;p&gt;Retrieve the current global environment as an association tree.&lt;/p&gt;
    &lt;p&gt;Replace the entire global environment (persistent).&lt;/p&gt;
    &lt;p&gt;Replace the entire global environment (backtrackable).&lt;/p&gt;
    &lt;p&gt;Set a key-value pair globally (persistent across backtracking).&lt;/p&gt;
    &lt;p&gt;Set a flag (key with value &lt;code&gt;true&lt;/code&gt;) globally.&lt;/p&gt;
    &lt;p&gt;Set a key-value pair only if it doesn't exist. If it exists with a different value, throws an error.&lt;/p&gt;
    &lt;p&gt;Set a flag only once. Throws error if already set with different value.&lt;/p&gt;
    &lt;p&gt;Set a key-value pair locally (backtrackable).&lt;/p&gt;
    &lt;p&gt;Set a flag locally (backtrackable).&lt;/p&gt;
    &lt;p&gt;Retrieve value for a key. Throws &lt;code&gt;key_error&lt;/code&gt; if key doesn't exist.&lt;/p&gt;
    &lt;code&gt;?- env_set_global(name, 'Bob'), env_key_val(name, N).
N = 'Bob'.&lt;/code&gt;
    &lt;p&gt;Retrieve value for a key, or unify with &lt;code&gt;NotFound&lt;/code&gt; if key doesn't exist.&lt;/p&gt;
    &lt;code&gt;?- env_key_val_notfound(missing_key, V, default).
V = default.&lt;/code&gt;
    &lt;p&gt;Check if a flag exists (deterministic success/failure).&lt;/p&gt;
    &lt;p&gt;Reified version: unifies &lt;code&gt;Truth&lt;/code&gt; with &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;false&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;?- env_set_global_flag(debug),
   env_check_flag_t(debug, T1),
   env_check_flag_t(missing, T2).
T1 = true,
T2 = false.&lt;/code&gt;
    &lt;p&gt;Check if key exists with specific value (deterministic).&lt;/p&gt;
    &lt;p&gt;Reified version of key-value check.&lt;/p&gt;
    &lt;p&gt;Alias for &lt;code&gt;env_check_key_val_t/3&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Assert that a flag exists (throws error if missing).&lt;/p&gt;
    &lt;p&gt;Remove a key from the environment (persistent).&lt;/p&gt;
    &lt;p&gt;Remove a key from the environment (backtrackable).&lt;/p&gt;
    &lt;code&gt;% Initialize configuration once
init_config :-
    env_set_global_once(db_host, 'localhost'),
    env_set_global_once(db_port, 5432),
    env_set_global_flag_once(config_loaded).

% Access configuration
get_db_connection(Host, Port) :-
    env_key_val(db_host, Host),
    env_key_val(db_port, Port).&lt;/code&gt;
    &lt;code&gt;% Enable/disable features
enable_feature(Feature) :-
    env_set_global_flag(Feature).

disable_feature(Feature) :-
    env_remove(Feature).

% Check if feature is enabled
feature_enabled(Feature) :-
    env_check_flag(Feature).

% Conditional execution
maybe_log(Message) :-
    env_check_flag_t(logging_enabled, T),
    if_(T=true,
        format('LOG: ~w~n', [Message]),
        true
       ).&lt;/code&gt;
    &lt;code&gt;% Use local state that backtracks
process_with_context(Data, Result) :-
    env_set_local(current_data, Data),
    process_step_1,
    process_step_2,
    env_key_val(result, Result).&lt;/code&gt;
    &lt;code&gt;% Increment counter
increment_counter(Name) :-
    env_key_val_notfound(Name, Current, 0),
    Next is Current + 1,
    env_set_global(Name, Next).

% Usage
?- increment_counter(requests), increment_counter(requests).
true.

?- env_key_val(requests, Count).
Count = 2.&lt;/code&gt;
    &lt;p&gt;The environment is initialized exactly once using &lt;code&gt;term_expansion/2&lt;/code&gt;. The first time the module is loaded, it creates an empty association tree and stores it in the blackboard under &lt;code&gt;global_context&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;This library extensively uses reified predicates from &lt;code&gt;library(reif)&lt;/code&gt; for conditional logic without cuts. This enables pure, declarative programming with backtracking-friendly conditionals.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;All operations are O(log n) due to the underlying AVL tree implementation&lt;/item&gt;
      &lt;item&gt;Key lookups are efficient even with thousands of entries&lt;/item&gt;
      &lt;item&gt;Reified key existence checking avoids expensive exception handling&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;BSD-2-Clause (compatible with Scryer Prolog standard libraries)&lt;/p&gt;
    &lt;p&gt;Jay&lt;/p&gt;
    &lt;p&gt;0.1.0&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45706601</guid><pubDate>Sat, 25 Oct 2025 20:08:54 +0000</pubDate></item><item><title>In memory of the Christmas Island shrew</title><link>https://news.mongabay.com/2025/10/in-memory-of-the-christmas-island-shrew/</link><description>&lt;doc fingerprint="9773118fc882821f"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Once abundant on Christmas Island, the tiny, five-gram shrew (Crocidura trichura) filled the night forest with its high, thin cry before vanishing into silence.&lt;/item&gt;
      &lt;item&gt;Introduced black rats and their parasites decimated the island’s native mammals, and by 1908 the shrew was thought extinct, its memory confined to museum drawers and field notes.&lt;/item&gt;
      &lt;item&gt;Brief rediscoveries in 1958 and 1984 brought fleeting hope, but the last known individuals died in captivity, and no others have been found despite decades of searching.&lt;/item&gt;
      &lt;item&gt;Its loss, now made official, adds to Australia’s grim record of extinctions—a quiet reminder of fragile lives erased by invasion, neglect, and the noise of human expansion.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It never weighed more than a spoonful of sugar. Five or six grams of life, soft-furred and sharp-nosed, darting among the roots and leaf litter of a tiny island in the Indian Ocean. At night, its voice—a thin, high cry, part bat and part whisper—once filled the forest of Christmas Island. Now the forest is silent. Australia’s only shrew, Crocidura trichura, has been declared extinct.&lt;/p&gt;
    &lt;p&gt;Few knew it lived, fewer still that it was Australian. The shrew was a stranger in a land of pouched mammals, a migrant that arrived tens of thousands of years ago, likely clinging to a raft of vegetation from what is now Indonesia. On this isolated outpost, it built a quiet lineage of survivors. When British naturalists arrived in the 1890s, they found the forest alive with its shrill chatter. “Extremely common,” they wrote. And then, almost at once, it vanished.&lt;/p&gt;
    &lt;p&gt;The black rats came first, stowaways in bales of hay. With them came a parasite, Trypanosoma lewisi, that swept through the island’s naïve mammals like a plague. Within years, both native rats were gone. By 1908, the shrew was presumed lost too. Its name lingered only in museum drawers and in the footnotes of field reports.&lt;/p&gt;
    &lt;p&gt;Yet it was not quite gone. Half a century later, in 1958, two shrews appeared as bulldozers tore into the forest for phosphate mining. They were seen, released, and forgotten. Then, in 1984, came a miracle: a live female, found in a clump of fern by biologists clearing a path. For more than a year, she lived in a terrarium, fed on grasshoppers and care. A few months later, a male was caught. The world briefly held its breath for a reunion that might save a species. But the male, sickly and short-tempered, died within weeks. The female lingered alone until she, too, was gone.&lt;/p&gt;
    &lt;p&gt;No others were ever found. Searches in the following decades brought only silence—the kind of silence that deepens until it becomes its own proof. When scientists dissected hundreds of feral cats on the island, not a trace of shrew remained in their stomachs. The Red List, in its latest revision, made official what many already knew in their hearts: Crocidura trichura was no more.&lt;/p&gt;
    &lt;p&gt;To some, the loss of a creature so small may seem inconsequential. Yet its passing adds one more mark to Australia’s lamentable record—the thirty-ninth mammal species lost since colonization, more than any other country on Earth. The shrew’s absence is a story repeated across islands: an ancient ecosystem undone by the carelessness of arrival, by rats and cats, ants and snakes, by the unthinking traffic of an expanding world.&lt;/p&gt;
    &lt;p&gt;The Christmas Island shrew had survived what many thought impossible. For decades, it persisted unseen—a shadow among roots, defying extinction. It was officially rediscovered, officially lost, and then, improbably, rediscovered again. It endured eighty years of disappearance before the recorders caught up. That endurance was its last act of defiance.&lt;/p&gt;
    &lt;p&gt;In life, it asked for little: a patch of soil, a few beetles, a quiet forest. In death, it leaves questions that are larger than itself. How many other lives flicker out unseen before the world even learns their names? How many others wait somewhere in the darkness, unseen but breathing still?&lt;/p&gt;
    &lt;p&gt;There is always a chance—slim but not zero—that the shrew endures yet, hidden in the damp heart of Christmas Island, trembling but alive. Hope, after all, has a long history of outliving the species it mourns. But the forest is quieter now. And if this really is the end, the last of Australia’s shrews will have gone as it lived—small, secret, and almost entirely unnoticed, save for those who loved it enough to listen for its cry.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45706624</guid><pubDate>Sat, 25 Oct 2025 20:13:55 +0000</pubDate></item><item><title>Load-time relocation of shared libraries (2011)</title><link>https://eli.thegreenplace.net/2011/08/25/load-time-relocation-of-shared-libraries/</link><description>&lt;doc fingerprint="2f8599532e059648"&gt;
  &lt;main&gt;
    &lt;p&gt;This article's aim is to explain how a modern operating system makes it possible to use shared libraries with load-time relocation. It focuses on the Linux OS running on 32-bit x86, but the general principles apply to other OSes and CPUs as well.&lt;/p&gt;
    &lt;p&gt;Note that shared libraries have many names - shared libraries, shared objects, dynamic shared objects (DSOs), dynamically linked libraries (DLLs - if you're coming from a Windows background). For the sake of consistency, I will try to just use the name "shared library" throughout this article.&lt;/p&gt;
    &lt;head rend="h3"&gt;Loading executables&lt;/head&gt;
    &lt;p&gt;Linux, similarly to other OSes with virtual memory support, loads executables to a fixed memory address. If we examine the ELF header of some random executable, we'll see an Entry point address:&lt;/p&gt;
    &lt;code&gt;$ readelf -h /usr/bin/uptime
ELF Header:
  Magic:   7f 45 4c 46 01 01 01 00 00 00 00 00 00 00 00 00
  Class:                             ELF32
  [...] some header fields
  Entry point address:               0x8048470
  [...] some header fields
&lt;/code&gt;
    &lt;p&gt;This is placed by the linker to tell the OS where to start executing the executable's code [1]. And indeed if we then load the executable with GDB and examine the address 0x8048470, we'll see the first instructions of the executable's .text segment there.&lt;/p&gt;
    &lt;p&gt;What this means is that the linker, when linking the executable, can fully resolve all internal symbol references (to functions and data) to fixed and final locations. The linker does some relocations of its own [2], but eventually the output it produces contains no additional relocations.&lt;/p&gt;
    &lt;p&gt;Or does it? Note that I emphasized the word internal in the previous paragraph. As long as the executable needs no shared libraries [3], it needs no relocations. But if it does use shared libraries (as do the vast majority of Linux applications), symbols taken from these shared libraries need to be relocated, because of how shared libraries are loaded.&lt;/p&gt;
    &lt;head rend="h3"&gt;Load-time relocation in action&lt;/head&gt;
    &lt;p&gt;To see the load-time relocation in action, I will use our shared library from a simple driver executable. When running this executable, the OS will load the shared library and relocate it appropriately.&lt;/p&gt;
    &lt;p&gt;Curiously, due to the address space layout randomization feature which is enabled in Linux, relocation is relatively difficult to follow, because every time I run the executable, the libmlreloc.so shared library gets placed in a different virtual memory address [9].&lt;/p&gt;
    &lt;p&gt;This is a rather weak deterrent, however. There is a way to make sense in it all. But first, let's talk about the segments our shared library consists of:&lt;/p&gt;
    &lt;code&gt;$ readelf --segments libmlreloc.so

Elf file type is DYN (Shared object file)
Entry point 0x3b0
There are 6 program headers, starting at offset 52

Program Headers:
  Type           Offset   VirtAddr   PhysAddr   FileSiz MemSiz  Flg Align
  LOAD           0x000000 0x00000000 0x00000000 0x004e8 0x004e8 R E 0x1000
  LOAD           0x000f04 0x00001f04 0x00001f04 0x0010c 0x00114 RW  0x1000
  DYNAMIC        0x000f18 0x00001f18 0x00001f18 0x000d0 0x000d0 RW  0x4
  NOTE           0x0000f4 0x000000f4 0x000000f4 0x00024 0x00024 R   0x4
  GNU_STACK      0x000000 0x00000000 0x00000000 0x00000 0x00000 RW  0x4
  GNU_RELRO      0x000f04 0x00001f04 0x00001f04 0x000fc 0x000fc R   0x1

 Section to Segment mapping:
  Segment Sections...
   00     .note.gnu.build-id .hash .gnu.hash .dynsym .dynstr .gnu.version .gnu.version_r .rel.dyn .rel.plt .init .plt .text .fini .eh_frame
   01     .ctors .dtors .jcr .dynamic .got .got.plt .data .bss
   02     .dynamic
   03     .note.gnu.build-id
   04
   05     .ctors .dtors .jcr .dynamic .got
&lt;/code&gt;
    &lt;p&gt;To follow the myglob symbol, we're interested in the second segment listed here. Note a couple of things:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;In the section to segment mapping in the bottom, segment 01 is said to contain the .data section, which is the home of myglob&lt;/item&gt;
      &lt;item&gt;The VirtAddr column specifies that the second segment starts at 0x1f04 and has size 0x10c, meaning that it extends until 0x2010 and thus contains myglob which is at 0x200C.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Now let's use a nice tool Linux gives us to examine the load-time linking process - the dl_iterate_phdr function, which allows an application to inquire at runtime which shared libraries it has loaded, and more importantly - take a peek at their program headers.&lt;/p&gt;
    &lt;p&gt;So I'm going to write the following code into driver.c:&lt;/p&gt;
    &lt;code&gt;#define _GNU_SOURCE
#include &amp;lt;link.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;


static int header_handler(struct dl_phdr_info* info, size_t size, void* data)
{
    printf("name=%s (%d segments) address=%p\n",
            info-&amp;gt;dlpi_name, info-&amp;gt;dlpi_phnum, (void*)info-&amp;gt;dlpi_addr);
    for (int j = 0; j &amp;lt; info-&amp;gt;dlpi_phnum; j++) {
         printf("\t\t header %2d: address=%10p\n", j,
             (void*) (info-&amp;gt;dlpi_addr + info-&amp;gt;dlpi_phdr[j].p_vaddr));
         printf("\t\t\t type=%u, flags=0x%X\n",
                 info-&amp;gt;dlpi_phdr[j].p_type, info-&amp;gt;dlpi_phdr[j].p_flags);
    }
    printf("\n");
    return 0;
}


extern int ml_func(int, int);


int main(int argc, const char* argv[])
{
    dl_iterate_phdr(header_handler, NULL);

    int t = ml_func(argc, argc);
    return t;
}
&lt;/code&gt;
    &lt;p&gt;header_handler implements the callback for dl_iterate_phdr. It will get called for all libraries and report their names and load addresses, along with all their segments. It also invokes ml_func, which is taken from the libmlreloc.so shared library.&lt;/p&gt;
    &lt;p&gt;To compile and link this driver with our shared library, run:&lt;/p&gt;
    &lt;code&gt;gcc -g -c driver.c -o driver.o
gcc -o driver driver.o -L. -lmlreloc
&lt;/code&gt;
    &lt;p&gt;Running the driver stand-alone we get the information, but for each run the addresses are different. So what I'm going to do is run it under gdb [10], see what it says, and then use gdb to further query the process's memory space:&lt;/p&gt;
    &lt;code&gt; $ gdb -q driver
 Reading symbols from driver...done.
 (gdb) b driver.c:31
 Breakpoint 1 at 0x804869e: file driver.c, line 31.
 (gdb) r
 Starting program: driver
 [...] skipping output
 name=./libmlreloc.so (6 segments) address=0x12e000
                header  0: address=  0x12e000
                        type=1, flags=0x5
                header  1: address=  0x12ff04
                        type=1, flags=0x6
                header  2: address=  0x12ff18
                        type=2, flags=0x6
                header  3: address=  0x12e0f4
                        type=4, flags=0x4
                header  4: address=  0x12e000
                        type=1685382481, flags=0x6
                header  5: address=  0x12ff04
                        type=1685382482, flags=0x4

[...] skipping output
 Breakpoint 1, main (argc=1, argv=0xbffff3d4) at driver.c:31
 31    }
 (gdb)
&lt;/code&gt;
    &lt;p&gt;Since driver reports all the libraries it loads (even implicitly, like libc or the dynamic loader itself), the output is lengthy and I will just focus on the report about libmlreloc.so. Note that the 6 segments are the same segments reported by readelf, but this time relocated into their final memory locations.&lt;/p&gt;
    &lt;p&gt;Let's do some math. The output says libmlreloc.so was placed in virtual address 0x12e000. We're interested in the second segment, which as we've seen in readelf is at ofset 0x1f04. Indeed, we see in the output it was loaded to address 0x12ff04. And since myglob is at offset 0x200c in the file, we'd expect it to now be at address 0x13000c.&lt;/p&gt;
    &lt;p&gt;So, let's ask GDB:&lt;/p&gt;
    &lt;code&gt;(gdb) p &amp;amp;myglob
$1 = (int *) 0x13000c
&lt;/code&gt;
    &lt;p&gt;Excellent! But what about the code of ml_func which refers to myglob? Let's ask GDB again:&lt;/p&gt;
    &lt;code&gt;(gdb) set disassembly-flavor intel
(gdb) disas ml_func
Dump of assembler code for function ml_func:
   0x0012e46c &amp;lt;+0&amp;gt;:   push   ebp
   0x0012e46d &amp;lt;+1&amp;gt;:   mov    ebp,esp
   0x0012e46f &amp;lt;+3&amp;gt;:   mov    eax,ds:0x13000c
   0x0012e474 &amp;lt;+8&amp;gt;:   add    eax,DWORD PTR [ebp+0x8]
   0x0012e477 &amp;lt;+11&amp;gt;:  mov    ds:0x13000c,eax
   0x0012e47c &amp;lt;+16&amp;gt;:  mov    eax,ds:0x13000c
   0x0012e481 &amp;lt;+21&amp;gt;:  add    eax,DWORD PTR [ebp+0xc]
   0x0012e484 &amp;lt;+24&amp;gt;:  pop    ebp
   0x0012e485 &amp;lt;+25&amp;gt;:  ret
End of assembler dump.
&lt;/code&gt;
    &lt;p&gt;As expected, the real address of myglob was placed in all the mov instructions referring to it, just as the relocation entries specified.&lt;/p&gt;
    &lt;head rend="h3"&gt;Relocating function calls&lt;/head&gt;
    &lt;p&gt;So far this article demonstrated relocation of data references - using the global variable myglob as an example. Another thing that needs to be relocated is code references - in other words, function calls. This section is a brief guide on how this gets done. The pace is much faster than in the rest of this article, since I can now assume the reader understands what relocation is all about.&lt;/p&gt;
    &lt;p&gt;Without further ado, let's get to it. I've modified the code of the shared library to be the following:&lt;/p&gt;
    &lt;code&gt;int myglob = 42;

int ml_util_func(int a)
{
    return a + 1;
}

int ml_func(int a, int b)
{
    int c = b + ml_util_func(a);
    myglob += c;
    return b + myglob;
}
&lt;/code&gt;
    &lt;p&gt;ml_util_func was added and it's being used by ml_func. Here's the disassembly of ml_func in the linked shared library:&lt;/p&gt;
    &lt;code&gt;000004a7 &amp;lt;ml_func&amp;gt;:
 4a7:   55                      push   ebp
 4a8:   89 e5                   mov    ebp,esp
 4aa:   83 ec 14                sub    esp,0x14
 4ad:   8b 45 08                mov    eax,DWORD PTR [ebp+0x8]
 4b0:   89 04 24                mov    DWORD PTR [esp],eax
 4b3:   e8 fc ff ff ff          call   4b4 &amp;lt;ml_func+0xd&amp;gt;
 4b8:   03 45 0c                add    eax,DWORD PTR [ebp+0xc]
 4bb:   89 45 fc                mov    DWORD PTR [ebp-0x4],eax
 4be:   a1 00 00 00 00          mov    eax,ds:0x0
 4c3:   03 45 fc                add    eax,DWORD PTR [ebp-0x4]
 4c6:   a3 00 00 00 00          mov    ds:0x0,eax
 4cb:   a1 00 00 00 00          mov    eax,ds:0x0
 4d0:   03 45 0c                add    eax,DWORD PTR [ebp+0xc]
 4d3:   c9                      leave
 4d4:   c3                      ret
&lt;/code&gt;
    &lt;p&gt;What's interesting here is the instruction at address 0x4b3 - it's the call to ml_util_func. Let's dissect it:&lt;/p&gt;
    &lt;p&gt;e8 is the opcode for call. The argument of this call is the offset relative to the next instruction. In the disassembly above, this argument is 0xfffffffc, or simply -4. So the call currently points to itself. This clearly isn't right - but let's not forget about relocation. Here's what the relocation section of the shared library looks like now:&lt;/p&gt;
    &lt;code&gt;$ readelf -r libmlreloc.so

Relocation section '.rel.dyn' at offset 0x324 contains 8 entries:
 Offset     Info    Type            Sym.Value  Sym. Name
00002008  00000008 R_386_RELATIVE
000004b4  00000502 R_386_PC32        0000049c   ml_util_func
000004bf  00000401 R_386_32          0000200c   myglob
000004c7  00000401 R_386_32          0000200c   myglob
000004cc  00000401 R_386_32          0000200c   myglob
[...] skipping stuff
&lt;/code&gt;
    &lt;p&gt;If we compare it to the previous invocation of readelf -r, we'll notice a new entry added for ml_util_func. This entry points at address 0x4b4 which is the argument of the call instruction, and its type is R_386_PC32. This relocation type is more complicated than R_386_32, but not by much.&lt;/p&gt;
    &lt;p&gt;It means the following: take the value at the offset specified in the entry, add the address of the symbol to it, subtract the address of the offset itself, and place it back into the word at the offset. Recall that this relocation is done at load-time, when the final load addresses of the symbol and the relocated offset itself are already known. These final addresses participate in the computation.&lt;/p&gt;
    &lt;p&gt;What does this do? Basically, it's a relative relocation, taking its location into account and thus suitable for arguments of instructions with relative addressing (which the e8 call is). I promise it will become clearer once we get to the real numbers.&lt;/p&gt;
    &lt;p&gt;I'm now going to build the driver code and run it under GDB again, to see this relocation in action. Here's the GDB session, followed by explanations:&lt;/p&gt;
    &lt;code&gt; $ gdb -q driver
 Reading symbols from driver...done.
 (gdb) b driver.c:31
 Breakpoint 1 at 0x804869e: file driver.c, line 31.
 (gdb) r
 Starting program: driver
 [...] skipping output
 name=./libmlreloc.so (6 segments) address=0x12e000
               header  0: address=  0x12e000
                       type=1, flags=0x5
               header  1: address=  0x12ff04
                       type=1, flags=0x6
               header  2: address=  0x12ff18
                       type=2, flags=0x6
               header  3: address=  0x12e0f4
                       type=4, flags=0x4
               header  4: address=  0x12e000
                       type=1685382481, flags=0x6
               header  5: address=  0x12ff04
                       type=1685382482, flags=0x4

[...] skipping output
Breakpoint 1, main (argc=1, argv=0xbffff3d4) at driver.c:31
31    }
(gdb)  set disassembly-flavor intel
(gdb) disas ml_util_func
Dump of assembler code for function ml_util_func:
   0x0012e49c &amp;lt;+0&amp;gt;:   push   ebp
   0x0012e49d &amp;lt;+1&amp;gt;:   mov    ebp,esp
   0x0012e49f &amp;lt;+3&amp;gt;:   mov    eax,DWORD PTR [ebp+0x8]
   0x0012e4a2 &amp;lt;+6&amp;gt;:   add    eax,0x1
   0x0012e4a5 &amp;lt;+9&amp;gt;:   pop    ebp
   0x0012e4a6 &amp;lt;+10&amp;gt;:  ret
End of assembler dump.
(gdb) disas /r ml_func
Dump of assembler code for function ml_func:
   0x0012e4a7 &amp;lt;+0&amp;gt;:    55     push   ebp
   0x0012e4a8 &amp;lt;+1&amp;gt;:    89 e5  mov    ebp,esp
   0x0012e4aa &amp;lt;+3&amp;gt;:    83 ec 14       sub    esp,0x14
   0x0012e4ad &amp;lt;+6&amp;gt;:    8b 45 08       mov    eax,DWORD PTR [ebp+0x8]
   0x0012e4b0 &amp;lt;+9&amp;gt;:    89 04 24       mov    DWORD PTR [esp],eax
   0x0012e4b3 &amp;lt;+12&amp;gt;:   e8 e4 ff ff ff call   0x12e49c &amp;lt;ml_util_func&amp;gt;
   0x0012e4b8 &amp;lt;+17&amp;gt;:   03 45 0c       add    eax,DWORD PTR [ebp+0xc]
   0x0012e4bb &amp;lt;+20&amp;gt;:   89 45 fc       mov    DWORD PTR [ebp-0x4],eax
   0x0012e4be &amp;lt;+23&amp;gt;:   a1 0c 00 13 00 mov    eax,ds:0x13000c
   0x0012e4c3 &amp;lt;+28&amp;gt;:   03 45 fc       add    eax,DWORD PTR [ebp-0x4]
   0x0012e4c6 &amp;lt;+31&amp;gt;:   a3 0c 00 13 00 mov    ds:0x13000c,eax
   0x0012e4cb &amp;lt;+36&amp;gt;:   a1 0c 00 13 00 mov    eax,ds:0x13000c
   0x0012e4d0 &amp;lt;+41&amp;gt;:   03 45 0c       add    eax,DWORD PTR [ebp+0xc]
   0x0012e4d3 &amp;lt;+44&amp;gt;:   c9     leave
   0x0012e4d4 &amp;lt;+45&amp;gt;:   c3     ret
End of assembler dump.
(gdb)
&lt;/code&gt;
    &lt;p&gt;The important parts here are:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;In the printout from driver we see that the first segment (the code segment) of libmlreloc.so has been mapped to 0x12e000 [11]&lt;/item&gt;
      &lt;item&gt;ml_util_func was loaded to address 0x0012e49c&lt;/item&gt;
      &lt;item&gt;The address of the relocated offset is 0x0012e4b4&lt;/item&gt;
      &lt;item&gt;The call in ml_func to ml_util_func was patched to place 0xffffffe4 in the argument (I disassembled ml_func with the /r flag to show raw hex in addition to disassembly), which is interpreted as the correct offset to ml_util_func.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Obviously we're most interested in how (4) was done. Again, it's time for some math. Interpreting the R_386_PC32 relocation entry mentioned above, we have:&lt;/p&gt;
    &lt;p&gt;Take the value at the offset specified in the entry (0xfffffffc), add the address of the symbol to it (0x0012e49c), subtract the address of the offset itself (0x0012e4b4), and place it back into the word at the offset. Everything is done assuming 32-bit 2-s complement, of course. The result is 0xffffffe4, as expected.&lt;/p&gt;
    &lt;head rend="h3"&gt;Extra credit: Why was the call relocation needed?&lt;/head&gt;
    &lt;p&gt;This is a "bonus" section that discusses some peculiarities of the implementation of shared library loading in Linux. If all you wanted was to understand how relocations are done, you can safely skip it.&lt;/p&gt;
    &lt;p&gt;When trying to understand the call relocation of ml_util_func, I must admit I scratched my head for some time. Recall that the argument of call is a relative offset. Surely the offset between the call and ml_util_func itself doesn't change when the library is loaded - they both are in the code segment which gets moved as one whole chunk. So why is the relocation needed at all?&lt;/p&gt;
    &lt;p&gt;Here's a small experiment to try: go back to the code of the shared library, add static to the declaration of ml_util_func. Re-compile and look at the output of readelf -r again.&lt;/p&gt;
    &lt;p&gt;Done? Anyway, I will reveal the outcome - the relocation is gone! Examine the disassembly of ml_func - there's now a correct offset placed as the argument of call - no relocation required. What's going on?&lt;/p&gt;
    &lt;p&gt;When tying global symbol references to their actual definitions, the dynamic loader has some rules about the order in which shared libraries are searched. The user can also influence this order by setting the LD_PRELOAD environment variable.&lt;/p&gt;
    &lt;p&gt;There are too many details to cover here, so if you're really interested you'll have to take a look at the ELF standard, the dynamic loader man page and do some Googling. In short, however, when ml_util_func is global, it may be overridden in the executable or another shared library, so when linking our shared library, the linker can't just assume the offset is known and hard-code it [12]. It makes all references to global symbols relocatable in order to allow the dynamic loader to decide how to resolve them. This is why declaring the function static makes a difference - since it's no longer global or exported, the linker can hard-code its offset in the code.&lt;/p&gt;
    &lt;head rend="h3"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Load-time relocation is one of the methods used in Linux (and other OSes) to resolve internal data and code references in shared libraries when loading them into memory. These days, position independent code (PIC) is a more popular approach, and some modern systems (such as x86-64) no longer support load-time relocation.&lt;/p&gt;
    &lt;p&gt;Still, I decided to write an article on load-time relocation for two reasons. First, load-time relocation has a couple of advantages over PIC on some systems, especially in terms of performance. Second, load-time relocation is IMHO simpler to understand without prior knowledge, which will make PIC easier to explain in the future. (Update 03.11.2011: the article about PIC was published)&lt;/p&gt;
    &lt;p&gt;Regardless of the motivation, I hope this article has helped to shed some light on the magic going behind the scenes of linking and loading shared libraries in a modern OS.&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[1]&lt;/cell&gt;
        &lt;cell&gt;For some more information about this entry point, see the section "Digression â process addresses and entry point" of this article.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[2]&lt;/cell&gt;
        &lt;cell&gt;Link-time relocation happens in the process of combining multiple object files into an executable (or shared library). It involves quite a lot of relocations to resolve symbol references between the object files. Link-time relocation is a more complex topic than load-time relocation, and I won't cover it in this article.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[3]&lt;/cell&gt;
        &lt;cell&gt;This can be made possible by compiling all your libraries into static libraries (with ar combining object files instead gcc -shared), and providing the -static flag to gcc when linking the executable - to avoid linkage with the shared version of libc.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[4]&lt;/cell&gt;
        &lt;cell&gt;ml simply stands for "my library". Also, the code itself is absolutely non-sensical and only used for purposes of demonstration.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[5]&lt;/cell&gt;
        &lt;cell&gt;Also called "dynamic linker". It's a shared object itself (though it can also run as an executable), residing at /lib/ld-linux.so.2 (the last number is the SO version and may be different).&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[6]&lt;/cell&gt;
        &lt;cell&gt;If you're not familiar with how x86 structures its stack frames, this would be a good time to read this article.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[7]&lt;/cell&gt;
        &lt;cell&gt;You can provide the -l flag to objdump to add C source lines into the disassembly, making it clearer what gets compiled to what. I've omitted it here to make the output shorter.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[8]&lt;/cell&gt;
        &lt;cell&gt;I'm looking at the left-hand side of the output of objdump, where the raw memory bytes are. a1 00 00 00 00 means mov to eax with operand 0x0, which is interpreted by the disassembler as ds:0x0.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[9]&lt;/cell&gt;
        &lt;cell&gt;So ldd invoked on the executable will report a different load address for the shared library each time it's run.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[10]&lt;/cell&gt;
        &lt;cell&gt;Experienced readers will probably note that I could ask GDB about i shared to get the load-address of the shared library. However, i shared only mentions the load location of the whole library (or, even more accurately, its entry point), and I was interested in the segments.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[11]&lt;/cell&gt;
        &lt;cell&gt;What, 0x12e000 again? Didn't I just talk about load-address randomization? It turns out the dynamic loader can be manipulated to turn this off, for purposes of debugging. This is exactly what GDB is doing.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[12]&lt;/cell&gt;
        &lt;cell&gt;Unless it's passed the -Bsymbolic flag. Read all about it in the man page of ld.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45706660</guid><pubDate>Sat, 25 Oct 2025 20:19:36 +0000</pubDate></item><item><title>Testing out BLE beacons with BeaconDB</title><link>https://blog.matthewbrunelle.com/testing-out-ble-beacons-with-beacondb/</link><description>&lt;doc fingerprint="ae4260d429ba004c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Testing Out BLE Beacons With beaconDB&lt;/head&gt;
    &lt;head rend="h2"&gt;What on earth is beaconDB?&lt;/head&gt;
    &lt;p&gt;I've been using GrapheneOS for about half a year now. Back in March they added support for network based location.[^0] This means you no longer need to rely on Google's location services. Looking into how the system works sent me down yet another rabbit hole of reading. [1]&lt;/p&gt;
    &lt;p&gt;Anyways, in 2013 Mozilla launched Mozilla Location Service (MLS) as a pilot project to provide location lookup using observations of public cell towers, BLE Beacons and WiFi access points. Sadly, in 2024 Mozilla retired MLS. Thankfully, beaconDB launched to continue the work! [2]&lt;/p&gt;
    &lt;p&gt;I have been hacking away on a project for contributing observations to beaconDB and I wanted some BLE beacons I could use for testing. This experiment sort of spun off from that work.&lt;/p&gt;
    &lt;p&gt;The plan is simple:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Buy some BLE beacons.&lt;/item&gt;
      &lt;item&gt;Get their MAC addresses.&lt;/item&gt;
      &lt;item&gt;Query the beaconDB API to confirm no location is currently associated with the beacons.&lt;/item&gt;
      &lt;item&gt;Place the beacons in my yard. [3]&lt;/item&gt;
      &lt;item&gt;Take my dog on a walk around the block while running NeoStumbler.&lt;/item&gt;
      &lt;item&gt;Re-run the API query to see location estimates.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What on earth are BLE Beacons?&lt;/head&gt;
    &lt;p&gt;I've been writing the phrase BLE beacons a lot without describing what they are. So to disambiguate [4]:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Bluetooth - a wireless communication standard.&lt;/item&gt;
      &lt;item&gt;Bluetooth Low Energy - part of the Bluetooth 4.0 protocol, much lower power consumption, but also reduced transmission rates.&lt;/item&gt;
      &lt;item&gt;BLE beacons - BLE devices that are primarily transmit only.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Stationary BLE beacons are often used to mark locations in places where GPS signals are weak, like inside malls. Also, there is no single BLE beacon standard. Instead we have:&lt;/p&gt;
    &lt;p&gt;iBeacon which was released by Apple in 2013. Apple generally still supports them.&lt;/p&gt;
    &lt;p&gt;In 2014 Google launched the experimental URIBeacon. Then in 2015 Google replaced that with Eddystone. A one point Google was really into the concept of the Physical Web, but thankfully gave up on spamming users with notifications in 2018. This effectively reduced Google's involvement with the standard. Eddystone also powers the Waze beacons that saves me from missing my exit in the Ted Williams Tunnel.&lt;/p&gt;
    &lt;p&gt;AltBeacon was released in 2014 as an open standard. There are also other less used beacon standards out there.&lt;/p&gt;
    &lt;p&gt;Also, since BLE beacons are just BLE devices with extra details attached to the broadcast information, both iPhones and Android devices can scan for any standard. Best of all, most modern beacon devices should support broadcasting multiple beacon types at the same time.&lt;/p&gt;
    &lt;p&gt;In terms of collecting information about all these different types of beacons, Neostumbler uses the Android Beacon Library, which can detect the three main beacon types. Though they want to move away from the library so they can support custom scanning intervals.&lt;/p&gt;
    &lt;head rend="h2"&gt;Which BLE beacons did I choose?&lt;/head&gt;
    &lt;p&gt;When I was surveying the options I saw that many beacons included features like motion detection, lights, buttons, sound, etc. I wanted a stationary beacon with a long battery life, so I tried to avoid extra features if possible to keep the cost down. Additionally there are BLE beacons designed for broadcasting over extra long ranges. However the Bluetooth / WiFi accuracy section of the MLS documentation notes:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Bluetooth and WiFi networks have a fairly limited range. Bluetooth low-energy beacons typically reach just a couple meters and WiFi networks reach up to 100 meters. With obstacles like walls and people in the way, these distances get even lower.&lt;/p&gt;&lt;lb/&gt;...&lt;lb/&gt;This means position estimates based on WiFi networks are usually accurate to 100 meters. If a lot of networks are available in the area, accuracy tends to increase to about 10 or 20 meters. Bluetooth networks tend to be accurate to about 10 meters.&lt;/quote&gt;
    &lt;p&gt;So in my case, I specifically do not want a long range beacon in order to improve location accuracy.&lt;/p&gt;
    &lt;p&gt;In the end I settled on the Feasy FSC-BP104D and bought two of them:&lt;/p&gt;
    &lt;p&gt;There is the FeasyBeacon app which leaves a lot to be desired, but is not totally useless. [5] I powered up the two beacons and changed the following settings:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Set a new PIN.&lt;/item&gt;
      &lt;item&gt;I reduced the broadcast interval time from the default 1300ms to 1000ms. This will increase the batter usage, but allows for more frequent updates.&lt;/item&gt;
      &lt;item&gt;Changed the name of the beacons to something fun.&lt;/item&gt;
      &lt;item&gt;Updated the broadcast URL so that I was not advertising a Feasy store page. Sadly, the character limit was not long enough to broadcast my blogs address. So I chose the beaconDB website instead.&lt;/item&gt;
      &lt;item&gt;Checked for firmware updates.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Then I uninstalled the app, hoping to never have to use it again.&lt;/p&gt;
    &lt;head rend="h2"&gt;Trying out the API and confirming the beacons are not associated with a location&lt;/head&gt;
    &lt;p&gt;beaconDB provides a geolocate endpoint. The old MLS version required an API key, but that is no longer needed:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Instead of using API keys to control access like Mozilla did, beaconDB expects clients to be pre-configured with a reasonable user agent. Ideally this identifies the software the client is using and includes info that can be used to narrow things down in the event a bad configuration or bug causes significant load on the server.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;As a first step I wanted to confirm I could hit the API and get a valid location as a response. So I threw together a quick Python script:&lt;/p&gt;
    &lt;code&gt;import requests  
  
url = "https://api.beaconDB.net/v1/geolocate"  
  
headers = {'User-Agent': 'beaconDB test script, blog.matthewbrunelle.com',} 
  
body = {
    "wifiAccessPoints": [{
        "macAddress": "01:23:45:67:89:ab",
        "signalStrength": -51
    }, {
        "macAddress": "01:23:45:67:89:cd"
    }]
} 
  
response = requests.post(url, json=body, headers=headers)  
  
if response.status_code != 200:  
    print(f"Error: {response.status_code}")  
else:  
    print(response.json())

&lt;/code&gt;
    &lt;p&gt;Note: The example code for the blog post uses the example MAC addresses from the documentation, not real ones.&lt;/p&gt;
    &lt;p&gt;The API is pretty simple and most fields are optional. The main information you need to provide are MAC addresses and the signal strength for the observation. If I input the MAC addresses for my home access points [6], I get a response like:&lt;/p&gt;
    &lt;code&gt;{'location': {'lat': XX.XXXXXX, 'lng': -XX.XXXXXX}, 'accuracy': 132}
&lt;/code&gt;
    &lt;p&gt;Which gives the location of the house directly across the street from me. The accuracy is measured in meters, so the circle with a radius of 132 meters centered on that position does, in fact, contain my apartment. Not bad for locating off a single observation. beaconDB works best when you can query with multiple device observations at once.&lt;/p&gt;
    &lt;p&gt;Next, I wanted to hit the same endpoint, but using my BLE beacons. The app provided the beacons information, but they also had their MAC addresses printed on their side. I changed the body in the script above to:&lt;/p&gt;
    &lt;code&gt;body = {  
    "considerIp": False,  
    "bluetoothBeacons": [{
        "macAddress": "ff:23:45:67:89:ab",
        "age": 2000,
        "name": "beacon",
        "signalStrength": -110
    }],
    "fallbacks": {  sdf10adfasdfasf
        "lacf": False,  
        "ipf": False  
    }  
}
&lt;/code&gt;
    &lt;p&gt;Note that here I made sure to set &lt;code&gt;considerIp&lt;/code&gt; and &lt;code&gt;fallbacks&lt;/code&gt; to false, so that the API purely relies on the BLE beacon. From the docs:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;fallbacks&lt;/code&gt;section allows some control over the more coarse grained position sources. If no exact match can be found, these can be used to return a “404 Not Found” rather than a coarse grained estimate with a large accuracy value.&lt;/quote&gt;
    &lt;p&gt;As expected, I get a 404 back from the API.&lt;/p&gt;
    &lt;head rend="h2"&gt;Collecting observations with Neostumbler and testing the API&lt;/head&gt;
    &lt;p&gt;This part was pretty easy. NeoStumbler is a great app for contributing observations to beaconDB. I started recording and took my dog for a walk around the block. At the end of the walk I uploaded my observations. Then I just needed to wait, but not for too long:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;note that submissions will take at least 5 minutes to become available in the beaconDB&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Except... I was still getting 404s for my BLE beacons.&lt;/p&gt;
    &lt;p&gt;Neostumbler has a mechanism for filtering out moving devices, so the next thing I tried was disabling that. However I was still getting 404s...&lt;/p&gt;
    &lt;head rend="h2"&gt;Directly submitting observations to beaconDB&lt;/head&gt;
    &lt;p&gt;OK, so at this point I do not know if the issue is with Neostumbler submitting my observations, or beaconDB using them. Thankfully, Neostumbler lets you export your observations to csv.&lt;/p&gt;
    &lt;p&gt;So I was able to directly submit an observation using the geosubmit v2 endpoint. The export contains every piece of information you can submit, except for the GPS heading and the beacon name.&lt;/p&gt;
    &lt;code&gt;import requests  
  
url = "https://api.beacondb.net/v2/geosubmit"  
  
headers = {'User-Agent': 'BeaconDB test script, blog.matthewbrunelle.com',}  
  
{"items": [{
    "timestamp": 1405602028568,
    "position": {
        "latitude": -22.7539192,
        "longitude": -43.4371081,
        "accuracy": 10.0,
        "age": 1000,
        "altitude": 100.0,
        "altitudeAccuracy": 50.0,
        #"heading": 45.0,
        "pressure": 1013.25,
        "speed": 3.6,
        "source": "gps"
    },
    "bluetoothBeacons": [
        {
            "macAddress": "ff:23:45:67:89:ab",
            "age": 2000,
            #"name": "beacon",
            "signalStrength": -110
        }
    ],
}]}
  
response = requests.post(url, json=body, headers=headers)  
  
print(f"Status code: {response.status_code}")  
if response.status_code == 200:  
    print(response.json())
&lt;/code&gt;
    &lt;p&gt;Anyways, after running this script I wait again... and still a 404. At this point I realized that I had never run a test of a known good BLE beacon against the API to make sure I get a location back. So I dumped a full month of observations which contained a recent road trip I went on [7] and check some of those MAC addresses. Still nothing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Double checking the beaconDB source and final thoughts&lt;/head&gt;
    &lt;p&gt;So finally, I went to look at the beaconDB source to see what I could find. First I wanted to check if there was a minimum number of observations needed, sort of like the trilateration I learned about in HackerBox 0119 - Geopositioning. A comment from the repository revealed:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;At least two WiFi networks have to been known to accurately determine the position.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;So I tried making the WiFi query I made before, but adding the BLE beacons to see if the accuracy improved... Nothing, the accuracy was the same. As I searched the codebase I realized the problem: beaconDB currently accepts and stores BLE beacons, but does not use them yet for geolocation. So I made an issue.&lt;/p&gt;
    &lt;p&gt;Not all projects end as expected. At the very least, I learned a lot along the way. [8] My initial question was "how does beaconDB use BLE beacons". I should have probably checked if the answer was "it currently doesn't" before I set everything up.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Especially since I am a fan of how the fused location provider in Play Services works. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;There are some pretty graphs of observations over time. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I should note that there are several beacons around me already, so this is maybe not the most useful way to spend my time. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;By mostly looking at the first sentences of pages on Wikipedia. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Also amazingly exodus show no trackers. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I'm currently using two TP-Link EAP670. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Scanning in New Hampshire is interesting compared to MA. I was basically only getting cell tower readings with the occasional WiFi. No BLE beacons. In my neighborhood I get 30-50 WiFi APs at a time. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Most importantly, I was able to write an explanation of what BLE beacons are. Now I don't have to cram that into a future post I am working on. ↩︎&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45706705</guid><pubDate>Sat, 25 Oct 2025 20:26:59 +0000</pubDate></item><item><title>Agent Lightning: Train agents with RL (no code changes needed)</title><link>https://github.com/microsoft/agent-lightning</link><description>&lt;doc fingerprint="a716b050645adcbf"&gt;
  &lt;main&gt;
    &lt;p&gt;The absolute trainer to light up AI agents.&lt;/p&gt;
    &lt;p&gt;Join our Discord community to connect with other users and contributors.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Turn your agent into an optimizable beast with ZERO CODE CHANGE (almost)! 💤&lt;/item&gt;
      &lt;item&gt;Build with ANY agent framework (LangChain, OpenAI Agent SDK, AutoGen, CrewAI, Microsoft Agent Framework...); or even WITHOUT agent framework (Python OpenAI). You name it! 🤖&lt;/item&gt;
      &lt;item&gt;Selectively optimize one or more agents in a multi-agent system. 🎯&lt;/item&gt;
      &lt;item&gt;Embraces Algorithms like Reinforcement Learning, Automatic Prompt Optimization, Supervised Fine-tuning and more. 🤗&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Read more on our documentation website.&lt;/p&gt;
    &lt;code&gt;pip install agentlightning&lt;/code&gt;
    &lt;p&gt;Please refer to our installation guide for more details.&lt;/p&gt;
    &lt;p&gt;To start using Agent-lightning, check out our documentation and examples.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;8/11/2025 Training AI Agents to Write and Self-correct SQL with Reinforcement Learning Medium.&lt;/item&gt;
      &lt;item&gt;8/5/2025 Agent Lightning: Train ANY AI Agents with Reinforcement Learning arXiv paper.&lt;/item&gt;
      &lt;item&gt;7/26/2025 We discovered an approach to train any AI agent with RL, with (almost) zero code changes. Reddit.&lt;/item&gt;
      &lt;item&gt;6/6/2025 Agent Lightning - Microsoft Research Project page.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;DeepWerewolf — A case study of agent RL training for the Chinese Werewolf game built with AgentScope and Agent Lightning.&lt;/item&gt;
      &lt;item&gt;AgentFlow — A modular multi-agent framework that combines planner, executor, verifier, and generator agents with the Flow-GRPO algorithm to tackle long-horizon, sparse-reward tasks.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Agent Lightning keeps the moving parts to a minimum so you can focus on your idea, not the plumbing. Your agent continues to run as usual; you can still use any agent framework you like; you drop in the lightweight &lt;code&gt;agl.emit_xxx()&lt;/code&gt; helper, or let the tracer collect every prompt, tool call, and reward. Those events become structured spans that flow into the LightningStore, a central hub that keeps tasks, resources, and traces in sync.&lt;/p&gt;
    &lt;p&gt;On the other side of the store sits the algorithm you choose, or write yourself. The algorithm reads spans, learns from them, and posts updated resources such as refined prompt templates or new policy weights. The Trainer ties it all together: it streams datasets to runners, ferries resources between the store and the algorithm, and updates the inference engine when improvements land. You can either stop there, or simply let the same loop keep turning.&lt;/p&gt;
    &lt;p&gt;No rewrites, no lock-in, just a clear path from first rollout to steady improvement.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Workflow&lt;/cell&gt;
        &lt;cell role="head"&gt;Status&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CPU Tests&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;GPU Tests&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Examples Integration&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Latest Dependency Compatibility&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Legacy Examples Compatibility&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;If you find Agent Lightning useful in your research or projects, please cite our paper:&lt;/p&gt;
    &lt;code&gt;@misc{luo2025agentlightningtrainai,
      title={Agent Lightning: Train ANY AI Agents with Reinforcement Learning},
      author={Xufang Luo and Yuge Zhang and Zhiyuan He and Zilong Wang and Siyun Zhao and Dongsheng Li and Luna K. Qiu and Yuqing Yang},
      year={2025},
      eprint={2508.03680},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2508.03680},
}&lt;/code&gt;
    &lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.&lt;/p&gt;
    &lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt;
    &lt;p&gt;This project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.&lt;/p&gt;
    &lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark &amp;amp; Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.&lt;/p&gt;
    &lt;p&gt;This project has been evaluated and certified to comply with the Microsoft Responsible AI Standard. The team will continue to monitor and maintain the repository, addressing any severe issues, including potential harms, if they arise.&lt;/p&gt;
    &lt;p&gt;This project is licensed under the MIT License. See the LICENSE file for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45706729</guid><pubDate>Sat, 25 Oct 2025 20:30:25 +0000</pubDate></item><item><title>Honda's ASIMO</title><link>https://www.robotsgottalents.com/post/asimo</link><description>&lt;doc fingerprint="e4048552a6b1ebc0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;HONDA'S ASIMO&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Robots Got Talents&lt;/item&gt;
      &lt;item&gt;Feb 26, 2021&lt;/item&gt;
      &lt;item&gt;5 min read&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;ASIMO which stands for Advanced Step in Innovative Mobility is one of the worlds most famous humanoid robots, which was created by Honda in 2000, and discontinued in 2018. ASIMO was first developed to help people. ASIMO’s height of four feet, three inches (130 centimetres) makes it the perfect size for helping around the house or assisting a person confined to a bed or a wheelchair. ASIMO’s size also allows it to look directly at an adult sitting in a chair or sitting up in bed for easy and natural communication.&lt;/p&gt;
    &lt;head rend="h2"&gt;History of Honda's Robots:&lt;/head&gt;
    &lt;p&gt;Honda began developing humanoid robots in the 1980s, including several prototypes that preceded ASIMO. It was the company's goal to create a walking robot. E0 was the first bipedal (two-legged) model produced as part of the Honda E series, which was an early experimental line of the self-regulating, humanoid walking robot with wireless movements created between 1986 and 1993.&lt;/p&gt;
    &lt;p&gt;Honda's E series:&lt;/p&gt;
    &lt;p&gt;E0 to E6 from the top left corner.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;E0, developed in 1986.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;E1, developed in 1987, was larger than the first and walked at 0.25 km/h. This model and subsequent E-series robots have 12 degrees of freedom: 3 in each groin, 1 in each knee and 2 in each ankle.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;E2, developed in 1989, could travel at 1.2km/h, through the development of "dynamic movement".&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;E3, developed in 1991, travelled at 3km/h, the average speed of a walking human.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;E4, developed in 1991, lengthened the knee to achieve speeds of up to 4.7km/h.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;E5, developed in 1992, was able to walk autonomously, albeit with a very large head.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;E6, developed in 1993, was able to autonomously balance, walk over obstacles, and even climb stairs.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This was followed by the Honda P series of robots produced from 1993 through 1997. In 1993, Honda began developing "Prototype" models ("P" series), attaching the legs to a torso with arms that could perform basic tasks. P2, the second prototype model, created in December 1996, using wireless techniques making it the first self-regulating, two-legged walking robot. P2 weighed 463 pounds with a height of six feet tall. In September 1997, P3 was introduced as the first completely independent bi-pedal humanoid walking robot, standing five feet, four inches tall and weighing 287 pounds. All the research made on the E- and P-series led to the creation of ASIMO.&lt;/p&gt;
    &lt;p&gt;Honda's P series:&lt;/p&gt;
    &lt;p&gt;P1 to P4 from the left to the right.&lt;/p&gt;
    &lt;p&gt;About ASIMO:&lt;/p&gt;
    &lt;p&gt;ASIMO (Advanced Step in Innovative Mobility) is the latest humanoid robot created by Honda in 2000 after the E and P series. ASIMO is currently displayed in the Miraikan museum in Tokyo, Japan. On 8 July 2018, Honda posted the last update of Asimo through their official page stating that it would be ceasing all development and production of Asimo robots in order to focus on more practical honour applications using the technology developed through Asimo's lifespan. The name ASIMO was also chosen in honour of Isaac Asimov, the father of Science fiction.&lt;/p&gt;
    &lt;p&gt;ASIMO stands 130 cm (4 ft 3 in) tall and weighs 54 kg (119 lb). Research conducted by Honda found that the ideal height for a mobility assistant robot was between 120 cm and the height of an average adult, which is conducive to operating doorknobs and light switches.&lt;/p&gt;
    &lt;p&gt;Source: Asimo technical information book&lt;/p&gt;
    &lt;p&gt;ASIMO is powered by a rechargeable 51.8 V lithium-ion battery with an operating time of one hour. Switching from a nickel-metal hydride in 2004 increased the amount of time ASIMO can operate before recharging. ASIMO has a three-dimensional computer processor that was created by Honda and consists of a three stacked-die, a processor, a signal converter and memory. The computer that controls ASIMO's movement is housed in the robot's waist area and can be controlled by a PC, wireless controller, or voice commands.&lt;/p&gt;
    &lt;p&gt;Abilities and Functions:&lt;/p&gt;
    &lt;p&gt;ASIMO has the ability to recognize moving objects, postures, gestures, its surrounding environment, sounds and faces, which enables it to interact with humans. The robot can detect the movements of multiple objects by using visual information captured by two cameras "eyes" in its head and also determine distance and direction. This feature allows ASIMO to follow or face a person when approached. The robot interprets voice commands and human gestures, enabling it to recognize when a handshake is offered or when a person waves or points, and then respond accordingly. ASIMO's ability to distinguish between voices and other sounds allows it to identify its companions. ASIMO is able to respond to its name and recognizes sounds associated with a falling object or collision. This allows the robot to face a person when spoken to or look towards a sound. ASIMO responds to questions by nodding or providing a verbal answer in different languages and can recognize approximately 10 different faces and address them by name.&lt;/p&gt;
    &lt;p&gt;Sensors and Features:&lt;/p&gt;
    &lt;p&gt;There are sensors that assist in autonomous navigation. The two cameras inside the head are used as a visual sensor to detect obstacles. The lower portion of the torso has a ground sensor which comprises one laser sensor and one infrared sensor. The laser sensor is used to detect ground surface. The infrared sensor with automatic shutter adjustment based on brightness is used to detect pairs of floor markings to confirm the navigable paths of the planned map. The pre-loaded map and the detection of floor markings help the robot to precisely identify its present location and continuously adjust its position. There are front and rear ultrasonic sensors to sense the obstacles. The front sensor is located at the lower portion of the torso together with the ground sensor. The rear sensor is located at the bottom of the backpack.&lt;/p&gt;
    &lt;p&gt;More technical details could be found in the official technical book, on ASIMO's Website press here&lt;/p&gt;
    &lt;p&gt;ASIMO's Sapcifications Table:&lt;/p&gt;
    &lt;head rend="h2"&gt;Interesting FAQs about ASIMO:&lt;/head&gt;
    &lt;p&gt;How is ASIMO controlled?&lt;/p&gt;
    &lt;p&gt;ASIMO is controlled by a laptop computer or by a portable computer controller unit through a wireless network system. This permits a more direct and flexible operation. A single operator can easily and fully control. ASIMO’s movements. Can ASIMO also be controlled by voice commands? ASIMO can comprehend and carry out tasks based on simple voice commands that have been preprogrammed into its onboard memory.&lt;/p&gt;
    &lt;p&gt;Can ASIMO recognize people and obstacles?&lt;/p&gt;
    &lt;p&gt;ASIMO utilizes IC Communications technology to recognize people within its vicinity.&lt;/p&gt;
    &lt;p&gt;ASIMO can also independently map its environment using its camera “eyes” and register stationary obstacles. ASIMO can store this data in an onboard map of its environment, then recall this data while walking in order to avoid these obstacles.&lt;/p&gt;
    &lt;p&gt;ASIMO can recognize moving pedestrians in its walking path and stop momentarily until these persons have cleared the robot’s path.&lt;/p&gt;
    &lt;p&gt;How intelligent is ASIMO?&lt;/p&gt;
    &lt;p&gt;ASIMO’s intelligence lies in the technologies with which it is equipped, not in the ability to think or reason like a human.&lt;/p&gt;
    &lt;p&gt;How many motors are used in ASIMO?&lt;/p&gt;
    &lt;p&gt;ASIMO is equipped with 34 separate servo motors.&lt;/p&gt;
    &lt;p&gt;Is ASIMO for sale, cost?&lt;/p&gt;
    &lt;p&gt;Unfortunately, ASIMO is not for sale, but according to different sources it cost from $2,000,000 to $2,500,000 buy ASIMO.&lt;/p&gt;
    &lt;head rend="h2"&gt;ASIMO 20th Anniversary&lt;/head&gt;
    &lt;head rend="h2"&gt;Sources:&lt;/head&gt;
    &lt;p&gt;Links for the sources used in creating this post&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45706744</guid><pubDate>Sat, 25 Oct 2025 20:32:29 +0000</pubDate></item><item><title>"Learn APL" Notes</title><link>https://luksamuk.codes/pages/learn-apl.html</link><description>&lt;doc fingerprint="aa94ba39423d9129"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;"Learn APL" Notes&lt;/head&gt;
    &lt;p&gt;I use this page as reference card when I have any doubts about the APL language.&lt;/p&gt;
    &lt;p&gt;This file follows APL Wiki's APL Tutorial and Further Topics in APL guides, plus occasional extra looks at TryAPL for missing stuff on certain symbols (I made sure it was compatible with GNU APL).&lt;/p&gt;
    &lt;p&gt;I do not guarantee a comprehensive guide to APL here. This is mainly for future consulting.&lt;/p&gt;
    &lt;p&gt;Plus, make sure you are using a monospace font which supports APL characters!&lt;/p&gt;
    &lt;p&gt;Also see the GNU APL Manual.&lt;/p&gt;
    &lt;head rend="h3"&gt;Back to last page&lt;/head&gt;
    &lt;head rend="h2"&gt;Table of Contents&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Getting Started&lt;/item&gt;
      &lt;item&gt;APL Concepts&lt;/item&gt;
      &lt;item&gt;Further Topics in APL&lt;/item&gt;
      &lt;item&gt;Finishing&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Getting Started&lt;/head&gt;
    &lt;head rend="h3"&gt;Startup&lt;/head&gt;
    &lt;p&gt;Let's make sure our file executes. Executing the tangled file will run everything done in the tutorial.&lt;/p&gt;
    &lt;p&gt; Also, for live interaction, use &lt;code&gt;gnu-apl-interactive-send-*&lt;/code&gt;.
&lt;/p&gt;
    &lt;code&gt;#!/usr/bin/apl --id 1010
&lt;/code&gt;
    &lt;p&gt;Oh, and just so you know, use a unicode font which supports this stuff.&lt;/p&gt;
    &lt;head rend="h3"&gt;Simple arithmetic&lt;/head&gt;
    &lt;p&gt; Use &lt;code&gt;⍝&lt;/code&gt; at the beginning of any comment.
&lt;/p&gt;
    &lt;quote&gt;⍝⍝⍝ Getting started ⍝⍝ This is a comment. ⍝⍝ Check the GNU APL keyboard for shortcut hints ⍝⍝ at any time. ⍝ Simple Arithmetic&lt;/quote&gt;
    &lt;head rend="h4"&gt;Arithmetic functions&lt;/head&gt;
    &lt;quote&gt;5+12 18÷3 108÷11 4×7 3.893×7.6&lt;/quote&gt;
    &lt;p&gt; Use &lt;code&gt;-&lt;/code&gt; for subtraction, and &lt;code&gt;¯&lt;/code&gt; for negative signal.
&lt;/p&gt;
    &lt;quote&gt;100-95 8-16&lt;/quote&gt;
    &lt;head rend="h4"&gt;Arithmetic on lists of numbers&lt;/head&gt;
    &lt;quote&gt;3+2 4 11 7 5&lt;/quote&gt;
    &lt;p&gt;Spot the difference on applying a sum to each element and applying a sum on two numbers:&lt;/p&gt;
    &lt;quote&gt;1+2 3 4 1+234&lt;/quote&gt;
    &lt;p&gt;Lists can be on either side of the sign.&lt;/p&gt;
    &lt;quote&gt;6 3 8 1+3 2.5 33.7 12 8÷15 9.8 11.2 17 1.2×1.175&lt;/quote&gt;
    &lt;p&gt;It is possible to perform arithmetic between two lists in a per-element basis, but only if their length matches.&lt;/p&gt;
    &lt;quote&gt;12 3 29 4×1 3 5 2&lt;/quote&gt;
    &lt;head rend="h4"&gt;Order of execution&lt;/head&gt;
    &lt;p&gt;APL runs stuff from right to left, since there are so many functions on the language.&lt;/p&gt;
    &lt;quote&gt;3×3-1&lt;/quote&gt;
    &lt;p&gt;That is because APL groups things from right to left as well.&lt;/p&gt;
    &lt;quote&gt;2 3 1+8÷2 2 2&lt;/quote&gt;
    &lt;p&gt;If you need to make things unambiguous, use parentheses.&lt;/p&gt;
    &lt;quote&gt;(2 3 1+8)÷2 2 2&lt;/quote&gt;
    &lt;p&gt; Remember again the difference between &lt;code&gt;-&lt;/code&gt; and &lt;code&gt;¯&lt;/code&gt;!
&lt;/p&gt;
    &lt;quote&gt;1985 - 1066 ⍝ Difference of two numbers 3 ¯1 ¯7 + ¯4 ¯1 2 ⍝ Sum between two lists with negative numbers 2-3+5 ⍝ This does 3+5, then does 2-8 2 ¯3+5 ⍝ This adds 5 to the number list 2 ¯3&lt;/quote&gt;
    &lt;head rend="h4"&gt;Dual-purpose functions&lt;/head&gt;
    &lt;p&gt;Some functions can be used for more than one purpose.&lt;/p&gt;
    &lt;p&gt;When used in infix notation, ordinary operations have their intended effect:&lt;/p&gt;
    &lt;quote&gt;5+4 1 3 4+3 1 6&lt;/quote&gt;
    &lt;p&gt;You can, however, use the functions in prefix notation, which will change their effect.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;+&lt;/code&gt; appears to do nothing. Its true usage happens for assignment, which
we'll see next.
&lt;/p&gt;
    &lt;quote&gt;+12&lt;/quote&gt;
    &lt;p&gt;&lt;code&gt;-&lt;/code&gt; inverts the signal of al numbers on the list.
&lt;/p&gt;
    &lt;quote&gt;- 3 ¯6 ¯8 4 12 ¯9&lt;/quote&gt;
    &lt;p&gt;&lt;code&gt;÷&lt;/code&gt; takes the reciprocal of all numbers (divides 1 by them).
&lt;/p&gt;
    &lt;quote&gt;÷1 2 4 10 100&lt;/quote&gt;
    &lt;p&gt;&lt;code&gt;×&lt;/code&gt; takes the sign of each number from the list. Yields &lt;code&gt;1&lt;/code&gt; for positive
numbers, &lt;code&gt;¯1&lt;/code&gt; for negative, and &lt;code&gt;0&lt;/code&gt; for zero.
&lt;/p&gt;
    &lt;quote&gt;×8 0 ¯3 ¯7 0 4&lt;/quote&gt;
    &lt;p&gt;There is no definition for postfix operators; that would be a syntax error.&lt;/p&gt;
    &lt;head rend="h4"&gt;Ceiling and floor&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;⌈&lt;/code&gt;rounds a number up;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;⌊&lt;/code&gt;rounds a number down.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To perform accurate rounding, you may want to use one of the following patterns:&lt;/p&gt;
    &lt;quote&gt;⌈120.11 12.32 65.01 13.52 - 0.5 ⌊99.99 12.82 15.39 48.90 + 0.5&lt;/quote&gt;
    &lt;p&gt; When using those operators under an infix form, &lt;code&gt;⌈&lt;/code&gt; selects the greatest
number, while &lt;code&gt;⌊&lt;/code&gt; selects the smallest number.
&lt;/p&gt;
    &lt;quote&gt;2 ⌈ 6 2 ⌊ 6&lt;/quote&gt;
    &lt;p&gt;One can also use these operations to perform comparisions between lists of numbers.&lt;/p&gt;
    &lt;quote&gt;6 8 1 ⌈ 3 5 9 6 8 1 ⌊ 3 5 9&lt;/quote&gt;
    &lt;head rend="h4"&gt;Ending a session&lt;/head&gt;
    &lt;p&gt;If you want to end a session, use&lt;/p&gt;
    &lt;quote&gt;)OFF&lt;/quote&gt;
    &lt;p&gt;This will not be tangled.&lt;/p&gt;
    &lt;head rend="h4"&gt;Exercises&lt;/head&gt;
    &lt;quote&gt;⍝ Exercises&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Q1&lt;p&gt;Enter statements to:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Multiply each of three numbers, &lt;code&gt;3 6 2&lt;/code&gt;by&lt;code&gt;8&lt;/code&gt;and then add&lt;code&gt;4&lt;/code&gt;to the results of the multiplication.&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;4 + 8 × 3 6 2&lt;/quote&gt;&lt;list rend="ul"&gt;&lt;item&gt;Add 15% to each number in the list &lt;code&gt;14 5 78 145&lt;/code&gt;.&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;1.15 × 14 5 78 145&lt;/quote&gt;&lt;list rend="ul"&gt;&lt;item&gt;Add the difference between &lt;code&gt;13&lt;/code&gt;and&lt;code&gt;8&lt;/code&gt;to&lt;code&gt;4 6 12 7&lt;/code&gt;.&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;(13 - 8) + 4 6 12 7 ⍝ Or... 4 6 12 7 + 13 - 8&lt;/quote&gt;&lt;list rend="ul"&gt;&lt;item&gt;Multiply the result of &lt;code&gt;6&lt;/code&gt;times&lt;code&gt;3&lt;/code&gt;by the result of&lt;code&gt;4&lt;/code&gt;times&lt;code&gt;8&lt;/code&gt;and subtract&lt;code&gt;5&lt;/code&gt;from the total.&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;((6 × 3) × (4 × 8)) - 5 ⍝ Or... ¯5+(6×3)×4×8&lt;/quote&gt;&lt;list rend="ul"&gt;&lt;item&gt;Reverse the signs in this list: &lt;code&gt;3 ¯4 ¯12 6&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;- 3 ¯4 ¯12 6&lt;/quote&gt;&lt;list rend="ul"&gt;&lt;item&gt;Compare these lists, selecting the larger number in each comparision: &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;2 7 0 55&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;33 1 10 13&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;2 7 0 55 ⌈ 33 1 10 13&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Multiply each of three numbers, &lt;/item&gt;
      &lt;item&gt;Q2&lt;p&gt;Which of these statements cause error messages? Why?&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Statement &lt;code&gt;a&lt;/code&gt;is a valid multiplication between&lt;code&gt;12&lt;/code&gt;and&lt;code&gt;9&lt;/code&gt;.&lt;/item&gt;&lt;item&gt;Statement &lt;code&gt;b&lt;/code&gt;is a valid sum between&lt;code&gt;3&lt;/code&gt;and&lt;code&gt;¯2&lt;/code&gt;.&lt;/item&gt;&lt;item&gt;Statement &lt;code&gt;c&lt;/code&gt;produces a&lt;code&gt;LENGTH ERROR&lt;/code&gt;because&lt;code&gt;19 0 3 4&lt;/code&gt;and&lt;code&gt;7 2 87&lt;/code&gt;are lists of different lengths.&lt;/item&gt;&lt;item&gt;&lt;code&gt;5 ¯8&lt;/code&gt;is a valid list of two numbers; it may be unintended, though.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Statement &lt;/item&gt;
      &lt;item&gt;Q3&lt;p&gt;You're getting&lt;/p&gt;&lt;code&gt;£200&lt;/code&gt;worth of dollars for yourself and&lt;code&gt;£180&lt;/code&gt;and&lt;code&gt;£230&lt;/code&gt;worth respectively for two friends. Enter a statement which calculates how many dollars each of you will get at&lt;code&gt;1.96&lt;/code&gt;dollars to the pound.&lt;quote&gt;200 180 230×1.96&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Q4&lt;p&gt;Highest recorded temperatures for a week in August were:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;79 84 83 78 74 69 70&lt;/code&gt;(Fahrenheit)&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Enter a statement to convert them into Centigrade. (One method is to subtract 32 degrees and multiply by 5/9.) Suppress decimal places in the result.&lt;/p&gt;&lt;quote&gt;⌊((79 84 83 78 74 69 70-32)×5÷9)+0.5 ⍝ Or... ⌈¯0.5+(5÷9)×79 84 83 78 74 69 70-32&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Q5&lt;p&gt;Enter a statement to find the difference in metres between 1500 metres and a mile. (1 yard = 0.9144m and 1760 yards in a mile)&lt;/p&gt;&lt;quote&gt;¯1500+1760×0.9144&lt;/quote&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Variables&lt;/head&gt;
    &lt;quote&gt;⍝ Variables&lt;/quote&gt;
    &lt;head rend="h4"&gt;Assignments&lt;/head&gt;
    &lt;p&gt; An assignment can be done with a variable name and a &lt;code&gt;←&lt;/code&gt; symbol.
&lt;/p&gt;
    &lt;code&gt;A ← .175
&lt;/code&gt;
    &lt;p&gt; This enables &lt;code&gt;A&lt;/code&gt; to be used in expressions.
&lt;/p&gt;
    &lt;quote&gt;200×A A×30.50 12.25 60.30 15.00 ⌈ A×30.50 12.25 60.30 15.00&lt;/quote&gt;
    &lt;p&gt;&lt;code&gt;C&lt;/code&gt; is the conversion factor for fonverting pounds to kilograms.
&lt;/p&gt;
    &lt;quote&gt;C ← .45359237 17 × C ⍝ Convert 17 lbs into Kg ⌈C×11×14 ⍝ How many Kgs are there in 11 stones, ⍝ then round up&lt;/quote&gt;
    &lt;p&gt;To keep a calculation, we then use variables.&lt;/p&gt;
    &lt;quote&gt;JOE ← ⌈C×11×14&lt;/quote&gt;
    &lt;head rend="h4"&gt;Variable names&lt;/head&gt;
    &lt;p&gt;Valid statements:&lt;/p&gt;
    &lt;quote&gt;AAA ← 4 ab ← 1 C9999 ← 0 Jack_Smith ← 100&lt;/quote&gt;
    &lt;p&gt;Which denotes that APL is case sensitive.&lt;/p&gt;
    &lt;p&gt;Also, APL doesn't have bare words as variable names:&lt;/p&gt;
    &lt;code&gt;JOHN SMITH ← 100
&lt;/code&gt;
    &lt;p&gt;However, using parentheses will create two identical variables with the same value. This happens in both GNU APL and Dyalog.&lt;/p&gt;
    &lt;quote&gt;(JOHN SMITH) ← 100 ⍝ Creates JOHN with value 100 ⍝ and SMITH with value 100&lt;/quote&gt;
    &lt;p&gt;And if you start a variable name with a single number, the number will be printed right after the value, which is assigned to the variable name that follows:&lt;/p&gt;
    &lt;quote&gt;5B ← 12&lt;/quote&gt;
    &lt;head rend="h4"&gt;Assigning lists to variables&lt;/head&gt;
    &lt;quote&gt;PRICE ← 12.45 5.60 5.99 7.75 +VAT ← PRICE × A ⍝ A was assigned earlier&lt;/quote&gt;
    &lt;p&gt; The &lt;code&gt;+&lt;/code&gt; operator, when put before an assignment, forces a declarative
behaviour on the assigned variable – in other words, forces the
variable to be displayed.
&lt;/p&gt;
    &lt;p&gt; Using an unassigned variable causes a &lt;code&gt;VALUE ERROR&lt;/code&gt;.
&lt;/p&gt;
    &lt;head rend="h4"&gt;System commands&lt;/head&gt;
    &lt;p&gt; The &lt;code&gt;)OFF&lt;/code&gt; command has already been presented earlier.
&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;)VARS&lt;/code&gt; lists all variables in the workspace.
&lt;/p&gt;
    &lt;quote&gt;)VARS&lt;/quote&gt;
    &lt;p&gt;&lt;code&gt;)WSID&lt;/code&gt; shows the identity of the current workspace, which defaults to
&lt;code&gt;CLEAR WS&lt;/code&gt;.
&lt;/p&gt;
    &lt;quote&gt;)WSID&lt;/quote&gt;
    &lt;p&gt; This command can also be used to change the identity of the workspace; we change its name to &lt;code&gt;NEW&lt;/code&gt;. The variables in it won't
change.
&lt;/p&gt;
    &lt;quote&gt;)WSID NEW&lt;/quote&gt;
    &lt;p&gt; To remove the variables (and the name), we can use &lt;code&gt;)CLEAR&lt;/code&gt;.
&lt;/p&gt;
    &lt;quote&gt;)CLEAR&lt;/quote&gt;
    &lt;head rend="h4"&gt;Character assignments&lt;/head&gt;
    &lt;p&gt;APL doesn't only deals with numbers, it can also deal with text. Just apply quotes.&lt;/p&gt;
    &lt;quote&gt;A ← 'APL WILL PROCESS TEXT' C ← 'CHARACTERS'&lt;/quote&gt;
    &lt;p&gt; To insert quotes inside the text, use &lt;code&gt;''&lt;/code&gt;.
&lt;/p&gt;
    &lt;code&gt;NAME ← 'WHAT''S IN A NAME? '
&lt;/code&gt;
    &lt;p&gt;Other way to do that is by using double quotes around the characters.&lt;/p&gt;
    &lt;code&gt;NAME ← "WHAT'S IN A NAME? "
&lt;/code&gt;
    &lt;p&gt;Consider the following variables.&lt;/p&gt;
    &lt;quote&gt;N ← 'NET PRICE' QTY ← '230'&lt;/quote&gt;
    &lt;p&gt; Attempting to perform arithmetic on text generates a &lt;code&gt;DOMAIN ERROR&lt;/code&gt;:
&lt;/p&gt;
    &lt;code&gt;N×10
QTY+5
&lt;/code&gt;
    &lt;head rend="h4"&gt;Multiple assignments&lt;/head&gt;
    &lt;p&gt;One can assign one value to multiple variables at the same time:&lt;/p&gt;
    &lt;code&gt;(ZAK YAK) ← 5
&lt;/code&gt;
    &lt;p&gt;Or assign many values to many variables at the same time too:&lt;/p&gt;
    &lt;quote&gt;(YEN MARK BUCK) ← 10 20 30&lt;/quote&gt;
    &lt;head rend="h4"&gt;Displaying variables together&lt;/head&gt;
    &lt;p&gt;This part is straightforward.&lt;/p&gt;
    &lt;quote&gt;N 10 NAME C X ← 18 Y ← 3 1985 X Y NAME X C 'NET PRICE: ' 10&lt;/quote&gt;
    &lt;head rend="h4"&gt;Joining lists&lt;/head&gt;
    &lt;p&gt; When writing &lt;code&gt;X Y&lt;/code&gt;, these values were joined in a list of two
elements. The first element was the number in &lt;code&gt;X&lt;/code&gt;, the second was the
two-element list in &lt;code&gt;Y&lt;/code&gt;.
&lt;/p&gt;
    &lt;p&gt;Let's store this result.&lt;/p&gt;
    &lt;quote&gt;Z ← X Y&lt;/quote&gt;
    &lt;p&gt; Operations done in &lt;code&gt;Z&lt;/code&gt; will not affect &lt;code&gt;X&lt;/code&gt; and &lt;code&gt;Y&lt;/code&gt; (also notice how &lt;code&gt;+10&lt;/code&gt; maps
elegantly into sublists!!!):
&lt;/p&gt;
    &lt;quote&gt;Z ← Z+10&lt;/quote&gt;
    &lt;p&gt;Example with characters.&lt;/p&gt;
    &lt;quote&gt;CNAME ← 'BASIL ' SNAME ← 'BRUSH' NAME ← CNAME SNAME&lt;/quote&gt;
    &lt;p&gt; Notice, though, that &lt;code&gt;NAME&lt;/code&gt; is a list of two elements, each being a list
of characters; this is called a nested variable.
&lt;/p&gt;
    &lt;head rend="h4"&gt;Joining and merging variables&lt;/head&gt;
    &lt;p&gt; The comma (&lt;code&gt;,&lt;/code&gt;) allows APL to catenate lists.
&lt;/p&gt;
    &lt;quote&gt;NAME ← CNAME,SNAME&lt;/quote&gt;
    &lt;p&gt;One can see that the variable indeed became a non-nested list of 11 characters.&lt;/p&gt;
    &lt;quote&gt;⍴NAME&lt;/quote&gt;
    &lt;head rend="h4"&gt;Simple and nested variables&lt;/head&gt;
    &lt;p&gt;Single numbers (separated by spaces) and characters make up lists.&lt;/p&gt;
    &lt;quote&gt;PIERRE ← 1 2 3 4 MIREILLE ← 'FILLE'&lt;/quote&gt;
    &lt;p&gt; Numbers enclosed in parentheses are treated as single items, so now &lt;code&gt;PIERRE&lt;/code&gt; will be a list, containing two lists.
&lt;/p&gt;
    &lt;quote&gt;PIERRE ← (1 2 3) (4 5 6 7)&lt;/quote&gt;
    &lt;p&gt;A list of character lists is easier, just enclose each sublist in quotes (if you were to put it in a single, simple list, you'd put everyone under the same quotes anyway):&lt;/p&gt;
    &lt;quote&gt;FRANCOISE ← 'UNE' 'JEUNE' 'FILLE'&lt;/quote&gt;
    &lt;head rend="h4"&gt;Mixed variables&lt;/head&gt;
    &lt;p&gt;This is not good for arithmetic, but it's useful to store characters and numbers together.&lt;/p&gt;
    &lt;quote&gt;PHONES ← 'BILL' 577332 'FRANK' 886331&lt;/quote&gt;
    &lt;head rend="h4"&gt;Exercises&lt;/head&gt;
    &lt;p&gt;Let's start with a clean workspace.&lt;/p&gt;
    &lt;quote&gt;)CLEAR&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Q1&lt;p&gt;Enter statements which:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Assign the numbers &lt;code&gt;22 2 2007&lt;/code&gt;to three variables called respectively&lt;code&gt;D&lt;/code&gt;,&lt;code&gt;M&lt;/code&gt;and&lt;code&gt;Y&lt;/code&gt;.&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;(D M Y) ← 22 2 2007&lt;/quote&gt;&lt;list rend="ul"&gt;&lt;item&gt;Assign the characters &lt;code&gt;TODAY'S DATE:&lt;/code&gt;to a variable called&lt;code&gt;DATE&lt;/code&gt;.&lt;/item&gt;&lt;/list&gt;&lt;code&gt;DATE ← 'TODAY''S DATE: '&lt;/code&gt;&lt;list rend="ul"&gt;&lt;item&gt;Produce the display: &lt;code&gt;TODAY'S DATE: 22 2 2007&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;DATE D M Y&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Assign the numbers &lt;/item&gt;
      &lt;item&gt;Q2&lt;p&gt;Set up a variable&lt;/p&gt;&lt;code&gt;CONV&lt;/code&gt;which contains a constant for converting pounds to kilos. (1lb = 0.454Kg and 14lb = 1 stone). Use&lt;code&gt;CONV&lt;/code&gt;to convert your weight (to the nearest stone) into kilograms. Reduce the result by 10%, round it down, and display it.&lt;quote&gt;⍝ 1 stone = 14 lbs. ⍝ 1 lb = 0.454 Kg. ⍝ Let's pretend I weight 11.5 stones. CONV ← .454 MYWEIGHT ← ⌊11.5×CONV×14×.9 MYWEIGHT&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Q3&lt;p&gt;The cost prices of four items of stock are £8, 6, 12, 4 respectively. The markup on these items is 100%. Three other items cost respectively £16, 13 and 7. Their markup is 75%. Calculate the fully inclusive price of each item (with VAT at 17%). Display the prices (rounded up) with the caption:&lt;/p&gt;&lt;code&gt;'PRICE+VAT: '&lt;/code&gt;&lt;quote&gt;ITEMS_A ← 2×8 6 12 4 ITEMS_B ← 1.75×16 13 7 ITEMS ← ⌈1.17×ITEMS_A,ITEMS_B 'PRICE+VAT: ' ITEMS&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Q4&lt;code&gt;TEST1&lt;/code&gt;contains a student's exam marks for each of seven subjects (65 72 54 80 67 60 59).&lt;code&gt;TEST2&lt;/code&gt;contains his marks for the same subjects gained at a different test (75 70 60 74 58 61 50). Produce a list consisting of his higher mark for each subject.&lt;quote&gt;TEST1 ← 65 72 54 80 67 60 59 TEST2 ← 75 70 60 74 58 61 50 TEST1 ⌈ TEST2&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Q5&lt;p&gt;Which of the following will produce error messages? Why?&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;The expression &lt;code&gt;RATE ← '3.7×3'&lt;/code&gt;is a valid assignment of a list of characters, though it might be a logic error.&lt;/item&gt;&lt;item&gt;The expression &lt;code&gt;10+10 '←21'&lt;/code&gt;produces a&lt;code&gt;DOMAIN ERROR&lt;/code&gt;, because it tries to sum&lt;code&gt;10&lt;/code&gt;over a list containing the number&lt;code&gt;10&lt;/code&gt;and the list of characters&lt;code&gt;'←21'&lt;/code&gt;, which cannot perform arithmetic operations.&lt;/item&gt;&lt;item&gt;The expression &lt;code&gt;100×RATE&lt;/code&gt;produces a&lt;code&gt;DOMAIN ERROR&lt;/code&gt;, because it tries to multiply by&lt;code&gt;100&lt;/code&gt;over a list containing characters (&lt;code&gt;RATE&lt;/code&gt;), which cannot perform arithmetic operations.&lt;/item&gt;&lt;item&gt;The expression &lt;code&gt;SYMBOLS ← '¯&amp;lt;≤=≥'&lt;/code&gt;is perfectly valid and creates a list of characters. But it might not be supported by some APL implementations (GNU APL supports it).&lt;/item&gt;&lt;item&gt;The expression &lt;code&gt;3+'232'&lt;/code&gt;produces a&lt;code&gt;DOMAIN ERROR&lt;/code&gt;, because it tries to sum&lt;code&gt;3&lt;/code&gt;over a list of characters, which cannot perform arithmetic operations.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;The expression &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Cleanup&lt;/head&gt;
    &lt;p&gt;From now on, we clear the variables and the workspace across chapters.&lt;/p&gt;
    &lt;quote&gt;)CLEAR&lt;/quote&gt;
    &lt;head rend="h3"&gt;Tables&lt;/head&gt;
    &lt;p&gt;We won't be typing a lot of things here, that is insane! Let's see how to generate our tables.&lt;/p&gt;
    &lt;quote&gt;⍝ Tables&lt;/quote&gt;
    &lt;head rend="h4"&gt;The Roll function&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;?&lt;/code&gt; is the Roll function, also called Random or Deal.
&lt;/p&gt;
    &lt;p&gt;This generates numbers on range 1 to 100:&lt;/p&gt;
    &lt;code&gt;? 100
&lt;/code&gt;
    &lt;p&gt; The two-argument form generates a list of &lt;code&gt;n&lt;/code&gt; (left) unique numbers from
1 to &lt;code&gt;m&lt;/code&gt; (right):
&lt;/p&gt;
    &lt;quote&gt;50 ? 100&lt;/quote&gt;
    &lt;p&gt; In fact, it should always be true that &lt;code&gt;n ≤ m&lt;/code&gt;, since the generated
numbers are unique. If not, we'll have a &lt;code&gt;DOMAIN ERROR&lt;/code&gt;.
&lt;/p&gt;
    &lt;p&gt; Both &lt;code&gt;n&lt;/code&gt; and &lt;code&gt;m&lt;/code&gt; can be replaced by variables as well.
&lt;/p&gt;
    &lt;head rend="h4"&gt;The Iota function&lt;/head&gt;
    &lt;p&gt; Iota, or Index, generates a sequence of numbers from 1 to &lt;code&gt;m&lt;/code&gt; in its
one-argument form.
&lt;/p&gt;
    &lt;code&gt;⍳100
&lt;/code&gt;
    &lt;head rend="h4"&gt;Setting up tables&lt;/head&gt;
    &lt;p&gt; When entering tables, we use dyadic for of the rho (&lt;code&gt;⍴&lt;/code&gt;) function, also
called Shape or Reshape. The list before &lt;code&gt;⍴&lt;/code&gt; states the order of the
table; the following elements are its rows, element by element.
&lt;/p&gt;
    &lt;quote&gt;4 3 ⍴ 10 20 30 40 50 60 70 80 90 100 110 120&lt;/quote&gt;
    &lt;p&gt;Let's generate twelve random numbers, then display them in a 4×3 table.&lt;/p&gt;
    &lt;quote&gt;DATA ← 12 ? 100 4 3 ⍴ DATA&lt;/quote&gt;
    &lt;p&gt; If you feed &lt;code&gt;⍴&lt;/code&gt; less numbers than expected, APL just keeps wrapping
these numbers. If you feed more than expected, APL uses just enough
numbers to build the table.
&lt;/p&gt;
    &lt;quote&gt;4 3 ⍴ 1 2 3 4 5&lt;/quote&gt;
    &lt;p&gt;And so follows that supplying one number fills the whole table:&lt;/p&gt;
    &lt;quote&gt;3 5 ⍴ 1&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Extra bit&lt;p&gt;I wonder about identity matrices! Let's take a 3×3 matrix. If we type a&lt;/p&gt;&lt;code&gt;1&lt;/code&gt;, and then a number&lt;code&gt;n&lt;/code&gt;of zeroes (corresponding to the matrix order), then I suppose we can build an identity matrix…&lt;quote&gt;3 3 ⍴ 1 0 0 0&lt;/quote&gt;&lt;p&gt;Indeed! But wait: I don't know how to build functions in APL yet, but I suppose we can take this arbitrary number of zeroes and write them in ⍴-notation too.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Generate a list of &lt;code&gt;n&lt;/code&gt;zeroes;&lt;/item&gt;&lt;item&gt;Catenate a number &lt;code&gt;1&lt;/code&gt;in front of it;&lt;/item&gt;&lt;item&gt;Feed it as filling elements to the second ⍴.&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;4 4 ⍴ 1,(4 ⍴ 0)&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Generate a list of &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Arithmetic on tables&lt;/head&gt;
    &lt;p&gt;Let's begin.&lt;/p&gt;
    &lt;quote&gt;SALES ← 3 3⍴20 13 8 30 43 48 3 50 21 SALES&lt;/quote&gt;
    &lt;p&gt;Performing arithmetic on a table affects every number, just like in a list.&lt;/p&gt;
    &lt;code&gt;SALES×10
&lt;/code&gt;
    &lt;p&gt;Let's set up another table.&lt;/p&gt;
    &lt;quote&gt;PRICES ← 2 3 ⍴ 21 2 12 47 33 1&lt;/quote&gt;
    &lt;p&gt; This operation causes a &lt;code&gt;LENGTH ERROR&lt;/code&gt;:
&lt;/p&gt;
    &lt;quote&gt;SALES×PRICES&lt;/quote&gt;
    &lt;p&gt; This is because &lt;code&gt;SALES&lt;/code&gt; is 3×3 while &lt;code&gt;PRICES&lt;/code&gt; is 2×3. So let's reshape
&lt;code&gt;SALES&lt;/code&gt; into a 3×2 table. This way, both of them will have the same
number of elements.
&lt;/p&gt;
    &lt;quote&gt;SALES ← 3 2⍴SALES&lt;/quote&gt;
    &lt;p&gt;But that still won't do… we're trying to multiply elements of same address here, not make matrix multiplication. Let's try again.&lt;/p&gt;
    &lt;quote&gt;SALES ← 2 3⍴SALES&lt;/quote&gt;
    &lt;p&gt;Ok, now we're good and we can proceed.&lt;/p&gt;
    &lt;quote&gt;TOTAL ← SALES×PRICES SALES-PRICES&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Extra bits&lt;p&gt;Let's build a nice table.&lt;/p&gt;&lt;p&gt;First table:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Build a sequence from &lt;code&gt;1&lt;/code&gt;to&lt;code&gt;25&lt;/code&gt;.&lt;/item&gt;&lt;item&gt;Create a &lt;code&gt;5×5&lt;/code&gt;table with it.&lt;/item&gt;&lt;item&gt;Take the reciprocal of each number.&lt;/item&gt;&lt;item&gt;Multiply each element by &lt;code&gt;10&lt;/code&gt;.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Second table:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Take a sequence from &lt;code&gt;1&lt;/code&gt;to&lt;code&gt;25&lt;/code&gt;.&lt;/item&gt;&lt;item&gt;Add &lt;code&gt;25&lt;/code&gt;to each element.&lt;/item&gt;&lt;item&gt;Create a &lt;code&gt;5×5&lt;/code&gt;table with it.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Final table:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Multiply each element of first table by each element of second table.&lt;/item&gt;&lt;item&gt;Round every number by adding &lt;code&gt;¯.5&lt;/code&gt;to each number and taking their ceiling.&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;TOTAL ← ⌈¯.5+(5 5⍴25+⍳25)×10×÷5 5⍴⍳25&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Build a sequence from &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Catenating tables&lt;/head&gt;
    &lt;p&gt;Catenating tables produce a big table. Each row is catenated like a list. Therefore, catenated tables must have the same number of rows.&lt;/p&gt;
    &lt;quote&gt;SALES,PRICES&lt;/quote&gt;
    &lt;p&gt;Let's test it a little more.&lt;/p&gt;
    &lt;quote&gt;LITTLE ← 2 2⍴1 MEDIUM ← 2 6⍴5 BIG ← LITTLE,MEDIUM&lt;/quote&gt;
    &lt;p&gt; To perform &lt;code&gt;LITTLE+MEDIUM&lt;/code&gt;, we pad &lt;code&gt;LITTLE&lt;/code&gt; with a table of zeroes.
&lt;/p&gt;
    &lt;quote&gt;ZEROES ← 2 4⍴0 LITTLE ← LITTLE,ZEROES LITTLE+MEDIUM&lt;/quote&gt;
    &lt;p&gt; We could also have the zeroes on the other side; let's reset &lt;code&gt;LITTLE&lt;/code&gt;
and do it.
&lt;/p&gt;
    &lt;quote&gt;LITTLE ← 2 2⍴1 LITTLE ← ZEROES,LITTLE LITTLE+MEDIUM&lt;/quote&gt;
    &lt;p&gt;Since there is this kind of ambiguity, that is the reason why APL doesn't do arithmetic on data of unequal size.&lt;/p&gt;
    &lt;head rend="h4"&gt;Selecting elements&lt;/head&gt;
    &lt;p&gt; Let's set up a &lt;code&gt;4×3&lt;/code&gt; table for the next example.
&lt;/p&gt;
    &lt;quote&gt;+TABLE ← 4 3⍴2 12 15 4 11 7 1 16 8 20 19 9&lt;/quote&gt;
    &lt;p&gt; Let's select the &lt;code&gt;9&lt;/code&gt; in the bottom row, rightmost column.
&lt;/p&gt;
    &lt;quote&gt;TABLE[4;3]&lt;/quote&gt;
    &lt;p&gt;We sum the element at Row 1, Column 2 to the element at Row 2, Column 2. Then we put it on Row 3, Column 2:&lt;/p&gt;
    &lt;quote&gt;TABLE[3;2] ← TABLE[1;2] + TABLE[2;2]&lt;/quote&gt;
    &lt;p&gt;We can select more than one element in a row, or even in a column.&lt;/p&gt;
    &lt;quote&gt;TABLE[1;1 2] TABLE[1 2;2]&lt;/quote&gt;
    &lt;p&gt;To select entire rows or columns, omit the other parameter.&lt;/p&gt;
    &lt;quote&gt;TABLE[1;] TABLE[;1]&lt;/quote&gt;
    &lt;p&gt;Let's replace the numbers in column 3 with the sum of numbers in columns 1 and 2.&lt;/p&gt;
    &lt;quote&gt;TABLE[;3] ← TABLE[;1] + TABLE[;2]&lt;/quote&gt;
    &lt;p&gt;Also note that indexing can also be applied on lists.&lt;/p&gt;
    &lt;quote&gt;LIST ← 8 1 90 4 LIST[2]&lt;/quote&gt;
    &lt;head rend="h4"&gt;Dimensions&lt;/head&gt;
    &lt;p&gt;In APL, data has dimensions.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Single numbers have dimension zero.&lt;/item&gt;
      &lt;item&gt;A list has one dimension.&lt;/item&gt;
      &lt;item&gt;The previous tables have two dimensions.&lt;/item&gt;
      &lt;item&gt;Three-dimensional tables/arrays are like cubes, having depth, height and length.&lt;/item&gt;
      &lt;item&gt;It is possible to create arrays of many dimensions in APL.&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;SALES ← 6 4⍴24?50&lt;/quote&gt;
    &lt;p&gt; In &lt;code&gt;SALES&lt;/code&gt;, the salesmen are rows, the products are columns.
If we wanted to represent more than one region – say, three regions
–, we'd need another dimension.
&lt;/p&gt;
    &lt;quote&gt;+SALES ← 3 6 4⍴72?100 SALES[2;5;4] ⍝ Plane 2, Row 5, Column 4 SALES[2;;] ⍝ Plane 2&lt;/quote&gt;
    &lt;head rend="h4"&gt;Enquiring about the size of data&lt;/head&gt;
    &lt;p&gt; While the dyadic usage of &lt;code&gt;⍴&lt;/code&gt; involves creating arrays, the monadic
usage of &lt;code&gt;⍴&lt;/code&gt; allows one to enquire about the size (or shape) of existing
tables, variables, etc.
&lt;/p&gt;
    &lt;quote&gt;⍴SALES&lt;/quote&gt;
    &lt;p&gt;Let's create some data.&lt;/p&gt;
    &lt;quote&gt;TABLE ← 5 3⍴15?20 LIST ← ⍳6 NUM ← 234&lt;/quote&gt;
    &lt;p&gt;Now let's ask about their shape.&lt;/p&gt;
    &lt;quote&gt;⍴TABLE ⍴LIST ⍴NUM&lt;/quote&gt;
    &lt;p&gt; Notice that, since &lt;code&gt;NUM&lt;/code&gt; has no shape (equivalent to a point), APL gives
an empty response.
&lt;/p&gt;
    &lt;p&gt;We don't need variables to do this kind of thing, though. We can apply directly to literals.&lt;/p&gt;
    &lt;quote&gt;⍴12 61 502 1 26 0 11 ⍴'SHAMBOLIOSIS'&lt;/quote&gt;
    &lt;head rend="h4"&gt;Tables of characters&lt;/head&gt;
    &lt;p&gt;This is also straightforward; characters are stored as a list of characters. Let's do some experiments.&lt;/p&gt;
    &lt;quote&gt;⍝ Compare these two. ALF ← 3 5⍴'ABCDE' NUM ← 3 5⍴12345 MYNAME ← 'GORSUCH' ⍴MYNAME 3 7⍴MYNAME 3 14⍴MYNAME 3 18⍴MYNAME MYNAME ← 'GORSUCH ' ⍴MYNAME 3 40⍴MYNAME&lt;/quote&gt;
    &lt;p&gt;Solution for the given example.&lt;/p&gt;
    &lt;quote&gt;4 11⍴'ADAMS CHATER PRENDERGASTLEE '&lt;/quote&gt;
    &lt;head rend="h4"&gt;Mixed tables&lt;/head&gt;
    &lt;p&gt;We can build tables containing characters and numbers, just like the lists.&lt;/p&gt;
    &lt;quote&gt;MIXTURE ← 3 3⍴'A' 1 'B' 'C' 2 'D' 'E' 3 'F'&lt;/quote&gt;
    &lt;head rend="h4"&gt;Nested tables&lt;/head&gt;
    &lt;p&gt;Tables can contain other tables or lists.&lt;/p&gt;
    &lt;quote&gt;NEST ← 2 3⍴(2 2⍴⍳4) (⍳5) 'A NAME' (2 4⍴⍳8) 23 (3 4⍴'NAME') ⍴NEST&lt;/quote&gt;
    &lt;head rend="h4"&gt;Depth&lt;/head&gt;
    &lt;p&gt; The depth (&lt;code&gt;≡&lt;/code&gt;) function shows the degree of nesting in a variable.
&lt;/p&gt;
    &lt;quote&gt;≡45 ⍝ Values have depth 0 ≡1 2 3 ⍝ Lists have depth 1 ≡2 2⍴3 4 5 6 ⍝ Tables too&lt;/quote&gt;
    &lt;p&gt; Now let's check the depth of &lt;code&gt;NEST&lt;/code&gt;:
&lt;/p&gt;
    &lt;quote&gt;≡NEST&lt;/quote&gt;
    &lt;p&gt;When at least one element of a list or table is also a list or table, the depth becomes 2; and so on, as long as you have child list/tables inside child list/tables:&lt;/p&gt;
    &lt;quote&gt;BIG_NEST ← NEST NEST ⍴BIG_NEST ≡BIG_NEST&lt;/quote&gt;
    &lt;p&gt; Since the components of &lt;code&gt;BIG_NEST&lt;/code&gt; already have depth 2, &lt;code&gt;BIG_NEST&lt;/code&gt; adds
one more layer of depth.
&lt;/p&gt;
    &lt;head rend="h4"&gt;Practice&lt;/head&gt;
    &lt;p&gt;Some interesting snippets showcasing the strength of APL: combining functions.&lt;/p&gt;
    &lt;quote&gt;⍝ Playing with sizes of character lists (⍴'ABC','DEF')+⍴'GHI' ⍝ Selecting the first nine numbers in row 1 of a big table TABLE ← 10 10⍴100?100 TABLE[1;⍳9]&lt;/quote&gt;
    &lt;head rend="h4"&gt;Exercises&lt;/head&gt;
    &lt;quote&gt;)CLEAR&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Q1&lt;p&gt;Set up a four-row one-column table called&lt;/p&gt;&lt;code&gt;MILES&lt;/code&gt;containing&lt;code&gt;300 42 25 140&lt;/code&gt;.&lt;quote&gt;MILES ← 4 1⍴300 42 25 140&lt;/quote&gt;&lt;p&gt;And a similarly shaped table called&lt;/p&gt;&lt;code&gt;RATES&lt;/code&gt;containing&lt;code&gt;27.5 15 27.5 27.5&lt;/code&gt;.&lt;quote&gt;RATES ← 4 1⍴27.5 15 27.5 27.5&lt;/quote&gt;&lt;p&gt;Multiply&lt;/p&gt;&lt;code&gt;RATES&lt;/code&gt;by&lt;code&gt;MILES&lt;/code&gt;, then multiply the result by&lt;code&gt;0.01&lt;/code&gt;to produce a table called&lt;code&gt;EXPENSES&lt;/code&gt;.&lt;code&gt;+EXPENSES ← .01×RATES×MILES&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Q2&lt;p&gt;Change the number in column 1 row 3 of&lt;/p&gt;&lt;code&gt;MILES&lt;/code&gt;from&lt;code&gt;25&lt;/code&gt;to&lt;code&gt;250&lt;/code&gt;. Again, multiply&lt;code&gt;RATES&lt;/code&gt;by&lt;code&gt;MILES&lt;/code&gt;and the result by&lt;code&gt;0.01&lt;/code&gt;to give&lt;code&gt;EXPENSES&lt;/code&gt;, then reformat&lt;code&gt;EXPENSES&lt;/code&gt;to produce a one-row four-column table.&lt;quote&gt;MILES[3;1] ← 250 +EXPENSES ← (.01×RATES×MILES)[;1]&lt;/quote&gt;&lt;p&gt;Alternative way to change&lt;/p&gt;&lt;code&gt;EXPENSES&lt;/code&gt;; interesting way to store and immediately use a variable.&lt;quote&gt;+EXPENSES ← 1 4⍴EXPENSES ← .01×RATES×MILES&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Q3&lt;p&gt;Define&lt;/p&gt;&lt;code&gt;X&lt;/code&gt;as a three-row ten-column table containing random numbers, and&lt;code&gt;Y&lt;/code&gt;as a three-row four-column table also containing random numbers. Add&lt;code&gt;X&lt;/code&gt;to&lt;code&gt;Y&lt;/code&gt;, first taking whatever steps you think necessary to enable the operation to take place.&lt;quote&gt;⍝ Defining the tables X ← 3 10⍴30?30 Y ← 3 4⍴30+12?12 ⍝ To sum Y into X, we catenate zeroes to Y, ⍝ extending it. X+Y,3 ((⍴X)[2]-(⍴Y)[2])⍴0&lt;/quote&gt;&lt;p&gt;Since the problem did not specify where to add the columns, here is an alternative which catenates the zeroes to the left of&lt;/p&gt;&lt;code&gt;Y&lt;/code&gt;:&lt;quote&gt;X+(3 ((⍴X)[2]-(⍴Y)[2])⍴0),Y&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Q4&lt;p&gt;Using table&lt;/p&gt;&lt;code&gt;X&lt;/code&gt;, add the first and second rows and replace the third row with the result of the addition.&lt;quote&gt;X[3;] ← X[1;]+X[2;]&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Q5&lt;p&gt;Create a table which [displays&lt;/p&gt;&lt;code&gt;APL ROCKS&lt;/code&gt;in vertical orientation]:&lt;quote&gt;9 1⍴'APL ROCKS'&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Q6&lt;p&gt;What will be the result of each of these&lt;/p&gt;&lt;code&gt;⍴&lt;/code&gt;statements? Predict each result before you press ENTER.&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;⍴'ABC DEF'&lt;/code&gt;&lt;lb/&gt;→&lt;code&gt;7&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;⍴480 0 1.2&lt;/code&gt;&lt;lb/&gt;→&lt;code&gt;3&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;TABLE ← 10 10⍴100⍴1000&lt;/code&gt;&lt;code&gt;⍴TABLE&lt;/code&gt;&lt;lb/&gt;→&lt;code&gt;10 10&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;⍴'R'&lt;/code&gt;&lt;lb/&gt;→ (empty)&lt;/item&gt;&lt;item&gt;&lt;code&gt;⍴'480 0 1.2'&lt;/code&gt;&lt;lb/&gt;→&lt;code&gt;9&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;TABLE ← 2 10 3⍴100⍴100&lt;/code&gt;&lt;code&gt;⍴TABLE&lt;/code&gt;&lt;lb/&gt;→&lt;code&gt;2 10 3&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;NOTE: Recall why&lt;/p&gt;&lt;code&gt;⍴'R'&lt;/code&gt;gives an empty response: a single value is equivalent to a point, which has no size/dimension/shape.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Cleanup&lt;/head&gt;
    &lt;quote&gt;)CLEAR&lt;/quote&gt;
    &lt;head rend="h3"&gt;Writing a function&lt;/head&gt;
    &lt;quote&gt;⍝ Writing a function&lt;/quote&gt;
    &lt;head rend="h4"&gt;Precondition: the Slash operator&lt;/head&gt;
    &lt;p&gt; The Slash (&lt;code&gt;/&lt;/code&gt;) or Reduce operator is not a function; it modifies or
extends the operation of the functions it is used with.
&lt;/p&gt;
    &lt;p&gt;It works as if by putting the operator between the numbers.&lt;/p&gt;
    &lt;quote&gt;+/ 1 6 3 4 ×/ 1 2 3 4&lt;/quote&gt;
    &lt;p&gt;This can be done on a table too, however it will sum in a row basis.&lt;/p&gt;
    &lt;quote&gt;TABLE ← 3 3⍴⍳9 TABLE +/ TABLE&lt;/quote&gt;
    &lt;p&gt;We can, however, apply Reduce twice to obtain the entire sum.&lt;/p&gt;
    &lt;quote&gt;+/+/ TABLE&lt;/quote&gt;
    &lt;p&gt; Useful combination: To select the largest number in a list, use &lt;code&gt;⌈&lt;/code&gt;:
&lt;/p&gt;
    &lt;quote&gt;⌈/ 75 72 78 90 69 77 81 88&lt;/quote&gt;
    &lt;p&gt; The opposite equivalent (&lt;code&gt;⌊&lt;/code&gt;) selects the smallest number:
&lt;/p&gt;
    &lt;quote&gt;⌊/ 75 72 78 90 69 77 81 88&lt;/quote&gt;
    &lt;p&gt; A final example: We take the sum of &lt;code&gt;X&lt;/code&gt; (which is &lt;code&gt;15&lt;/code&gt;) and divide it by
&lt;code&gt;X&lt;/code&gt;'s shape (&lt;code&gt;5&lt;/code&gt;). This yields &lt;code&gt;3&lt;/code&gt;, as expected of calculating the average
of a number.
&lt;/p&gt;
    &lt;code&gt;X ← ⍳5
(+/ X)÷⍴X
&lt;/code&gt;
    &lt;head rend="h4"&gt;User functions&lt;/head&gt;
    &lt;p&gt;Now we'll preserve statements.&lt;/p&gt;
    &lt;p&gt;It seems some APL editors have a built-in editor. For example, one can use the following commands:&lt;/p&gt;
    &lt;quote&gt;)EDIT MYFUNC ⍝ On modern editors )ED MYFUNC ⍝ On Dyalog ∇ ⍝ On older editors, and on GNU APL as well&lt;/quote&gt;
    &lt;p&gt; GNU APL also calls a new buffer when defining a function, under Emacs. We can also send the following region to the interpreter no problem. We just need to type in the function (&lt;code&gt;∇&lt;/code&gt;) operator, which
starts the input mode.
&lt;/p&gt;
    &lt;p&gt; Typing &lt;code&gt;∇&lt;/code&gt; again goes back to calculator mode.
&lt;/p&gt;
    &lt;quote&gt;∇TRY1 'Type some numbers: ' NUM ← ⎕ ⍝ Asks for user input 'Total is: ' (+/ NUM) ∇&lt;/quote&gt;
    &lt;p&gt; In case this function doesn't work when typing, just use &lt;code&gt;∇TRY1&lt;/code&gt; to
change its definition on the editor.
&lt;/p&gt;
    &lt;p&gt; This defines a user function &lt;code&gt;TRY1&lt;/code&gt;, which takes no arguments. The Quad
(&lt;code&gt;⎕&lt;/code&gt;) operator calls in for user input.
&lt;/p&gt;
    &lt;p&gt; You can edit a function such as &lt;code&gt;TRY1&lt;/code&gt; anytime, by typing &lt;code&gt;∇TRY1&lt;/code&gt; on the
REPL; other APL implementations will allow you to use the command
&lt;code&gt;)EDIT TRY1&lt;/code&gt;, for example.
&lt;/p&gt;
    &lt;p&gt;Here is another example:&lt;/p&gt;
    &lt;quote&gt;∇TRY2 'Type some numbers: ' NUM ← ⎕ 'You have entered' (⍴NUM) 'numbers' ∇&lt;/quote&gt;
    &lt;p&gt;And as requested, here is a way to calculate the average of some numbers:&lt;/p&gt;
    &lt;quote&gt;∇AVERAGE 'Type some numbers:' NUM ← ⎕ 'Integer average of these numbers is:' (⌊(+/ NUM)÷⍴NUM) ∇&lt;/quote&gt;
    &lt;p&gt;One more definition.&lt;/p&gt;
    &lt;quote&gt;∇TRY3 'Type some numbers:' NUM ← ⎕ 'You have entered' (⍴NUM) 'numbers' 'The biggest was' (⌈/ NUM) 'The smallest was' (⌊/ NUM) 'Sum of numbers is' (+/ NUM) 'Integer average of numbers is' (⌊(+/ NUM)÷⍴NUM) ∇&lt;/quote&gt;
    &lt;head rend="h4"&gt;Saving a workspace&lt;/head&gt;
    &lt;p&gt;You can check out the user-defined functions in your workspace with this command:&lt;/p&gt;
    &lt;quote&gt;)FNS&lt;/quote&gt;
    &lt;p&gt; There are some extra variables as well (check by using &lt;code&gt;)VARS&lt;/code&gt;), so we
need to erase them:
&lt;/p&gt;
    &lt;quote&gt;)ERASE TABLE X&lt;/quote&gt;
    &lt;p&gt;Now we'll save the current workspace. First let's set the workspace ID to the filename where it should be salved.&lt;/p&gt;
    &lt;p&gt;Notice that we are using Unix notation and the XML extension. This is a requirement for GNU APL.&lt;/p&gt;
    &lt;quote&gt;)WSID ./MyFirstWS.xml&lt;/quote&gt;
    &lt;p&gt;Windows users, using NARS2000, should do something like:&lt;/p&gt;
    &lt;code&gt;)WSID 'c:\foo\MyFirstWS'
&lt;/code&gt;
    &lt;p&gt;Now we use the command to save.&lt;/p&gt;
    &lt;quote&gt;)SAVE&lt;/quote&gt;
    &lt;p&gt;My result was:&lt;/p&gt;
    &lt;quote&gt;2019-08-06 12:56:35 (GMT-3) ./MyFirstWS.xml&lt;/quote&gt;
    &lt;p&gt;Now we can safely clear the workspace.&lt;/p&gt;
    &lt;quote&gt;)CLEAR&lt;/quote&gt;
    &lt;p&gt;To load the workspace again, use the load command with the file name.&lt;/p&gt;
    &lt;quote&gt;)LOAD ./MyFirstWS.xml&lt;/quote&gt;
    &lt;p&gt; NOTE: GNU APL instructs to use &lt;code&gt;)COPY&lt;/code&gt; instead.
&lt;/p&gt;
    &lt;head rend="h4"&gt;User functions with arguments&lt;/head&gt;
    &lt;p&gt;User functions can have no arguments, one argument or two arguments.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Monadic&lt;p&gt;We intent to build a function which averages the numbers in a list. So let's define it.&lt;/p&gt;&lt;code&gt;∇AV X (+/ X)÷⍴X ∇&lt;/code&gt;&lt;p&gt;Now we can use it properly.&lt;/p&gt;&lt;quote&gt;AV 12 7 3 1 AV 3 8 1 4 AV 192 4534 12 0 2 NUM ← ⍳5 AV NUM&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Dyadic&lt;p&gt;A dyadic function should be declared with arguments to its left and its right:&lt;/p&gt;&lt;code&gt;∇A SUM B A+B ∇&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Using function results in other expressions&lt;/head&gt;
    &lt;p&gt; To do so, we need to rewrite the function to enable that. See this rewriting of &lt;code&gt;AV&lt;/code&gt;.
&lt;/p&gt;
    &lt;code&gt;∇R←AV X
  R←(+/ X)÷⍴X
∇
&lt;/code&gt;
    &lt;p&gt;An example of usage:&lt;/p&gt;
    &lt;quote&gt;¯3 + AV 3 8 1 4&lt;/quote&gt;
    &lt;p&gt;The same can be done to dyadic functions.&lt;/p&gt;
    &lt;code&gt;∇R←A SUM B
  R←A+B
∇
&lt;/code&gt;
    &lt;head rend="h4"&gt;Cleanup&lt;/head&gt;
    &lt;quote&gt;)ERASE NUM )SAVE )CLEAR&lt;/quote&gt;
    &lt;head rend="h2"&gt;APL Concepts&lt;/head&gt;
    &lt;head rend="h3"&gt;Overview of the APL System&lt;/head&gt;
    &lt;p&gt;APL is an interpreted language.&lt;/p&gt;
    &lt;p&gt;APL reserves an area in the RAM, which is called a workspace. This is were programs and data reside. Other workspaces can be loaded at will for calculation and processing.&lt;/p&gt;
    &lt;head rend="h4"&gt;Data&lt;/head&gt;
    &lt;p&gt;Data is acquired by typing or from files. All data is held in arrays or scalars.&lt;/p&gt;
    &lt;p&gt;GNU APL supports complex numbers.&lt;/p&gt;
    &lt;p&gt;Formal names will be used from now on.&lt;/p&gt;
    &lt;head rend="h4"&gt;Modes&lt;/head&gt;
    &lt;p&gt;APL uses a modal interpreter. Calculator mode executes statements as entered. Definition mode does not execute immediately, and stores statements as a user-defined function or operator. Function execution mode happens when you run a user-defined function or operator.&lt;/p&gt;
    &lt;head rend="h4"&gt;Built-in functions and operators&lt;/head&gt;
    &lt;p&gt;APL has about 50 built-in functions which can be invoked by a single symbol.&lt;/p&gt;
    &lt;p&gt;Most functions can perform two different opperations depending on whether they're used with one or two arguments.&lt;/p&gt;
    &lt;p&gt;APL also has five built-in operators. Combining an operator with its operands creates a derived function.&lt;/p&gt;
    &lt;head rend="h4"&gt;System functions and variables&lt;/head&gt;
    &lt;p&gt;Part of APL system, yet not part of APL language. Used to extend facilities provided by original APL, they vary from one vendor to another. Could also be tailored to the system which it is running.&lt;/p&gt;
    &lt;p&gt; System functions such as &lt;code&gt;⎕NREAD&lt;/code&gt; and &lt;code&gt;⎕NWRITE&lt;/code&gt; (with names starting with
a Quad &lt;code&gt;⎕&lt;/code&gt;) read and write data from files, and are distinguishable from
the rest by their starting character.
&lt;/p&gt;
    &lt;head rend="h4"&gt;System commands&lt;/head&gt;
    &lt;p&gt; They are also not part of the APL language itself, but are crucial to managing the workspace. They always start with a &lt;code&gt;)&lt;/code&gt;.
&lt;/p&gt;
    &lt;head rend="h4"&gt;User-defined functions and operators&lt;/head&gt;
    &lt;p&gt;Functions or operators which can be written by the user. Consists of APL statements that have a name. Functions are edited through the function editor, which can also be used to tweak a function.&lt;/p&gt;
    &lt;head rend="h4"&gt;Files&lt;/head&gt;
    &lt;p&gt;Files are usually not necessary on APL, given the convenience of workspaces, being only really required when dealing with big projects. When that time comes, APL has facilities for that; and workspaces can be shared between users.&lt;/p&gt;
    &lt;head rend="h4"&gt;Error handling&lt;/head&gt;
    &lt;p&gt;APL provides facilities for error trapping and diagnostics.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Workspace&lt;/head&gt;
    &lt;p&gt;Workspaces are containers for functions and data, and can be saved on disk by using commands.&lt;/p&gt;
    &lt;p&gt;APL also makes it easy to create test data for functions. Since prototyping can be done so quickly, APL is sometimes referred to as a "tool of thought".&lt;/p&gt;
    &lt;head rend="h4"&gt;Functions, operators, classes&lt;/head&gt;
    &lt;p&gt;Functions can take 0, 1 or 2 arguments; arguments to functions are always arrays.&lt;/p&gt;
    &lt;p&gt; Operators look like functions, but takes either one or two operands, which can be functions (e.g. the Each operator &lt;code&gt;¨&lt;/code&gt;). They can also be
defined.
&lt;/p&gt;
    &lt;p&gt;Classes are a collection of functions, operators and data (named properties). Acts as a template to create objects. Classes are supported in Dyalog, but not in GNU APL.&lt;/p&gt;
    &lt;head rend="h4"&gt;Workspace size&lt;/head&gt;
    &lt;p&gt; Some APLS allow changing the size of your workspace with &lt;code&gt;)CLEAR 50MB&lt;/code&gt;,
for example.
&lt;/p&gt;
    &lt;p&gt;To check the amount of free space on your workspace, use the system function Workspace Available:&lt;/p&gt;
    &lt;code&gt;⎕WA
&lt;/code&gt;
    &lt;head rend="h4"&gt;Managing the workspace&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Internal workspace commands&lt;p&gt;These have already been discussed.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;)CLEAR&lt;/code&gt;: Clear workspace. Erases all variables, functions, operators and classes.&lt;/item&gt;&lt;item&gt;&lt;code&gt;)ERASE&lt;/code&gt;: Erases individual classes.&lt;/item&gt;&lt;item&gt;&lt;code&gt;)VARS&lt;/code&gt;: Lists all user-defined variables in the workspace.&lt;/item&gt;&lt;item&gt;&lt;code&gt;)FNS&lt;/code&gt;: Lists all user-defined functions in the workspace.&lt;/item&gt;&lt;item&gt;&lt;code&gt;)OPS&lt;/code&gt;: Lists all user-defined operators in the workspace.&lt;/item&gt;&lt;item&gt;&lt;code&gt;)CLASSES&lt;/code&gt;: Lists all user-defined classes in the workspace. Can be used in Dyalog.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;External workspace commands&lt;p&gt;Some of these have already been discussed.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;)SAVE myWorkspace&lt;/code&gt;saves a workspace to disk. Append&lt;code&gt;.xml&lt;/code&gt;if you're using GNU APL.&lt;/item&gt;&lt;item&gt;&lt;code&gt;)LOAD myWorkspace&lt;/code&gt;loads an entire workspace back into memory; the workspace in memory is overwritten.&lt;/item&gt;&lt;item&gt;&lt;code&gt;)COPY&lt;/code&gt;can be used to copy a function from a workspace in disk, but does not overwrite the current workspace.&lt;/item&gt;&lt;item&gt;&lt;code&gt;)DROP&lt;/code&gt;deletes a workspace on disk.&lt;/item&gt;&lt;item&gt;&lt;code&gt;)LIB&lt;/code&gt;shows the names of the workspaces stored on disk.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Save locations vary due to APL implementations.&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;System variables&lt;/head&gt;
    &lt;p&gt;Here are some useful system variables which you may use.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;⎕WA&lt;/code&gt;: Workspace Available. Number of available bytes for use in workspace.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;⎕PP&lt;/code&gt;: Print Precision. Number of digits displayed in numeric output.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;⎕PW&lt;/code&gt;: Print Width. Max number of characters in each printed line.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;⎕LX&lt;/code&gt;: Latent Expression. This variable contains an expression or user-defined function which is executed when the workspace is loaded; effectively, a setup function for the current workspace. Empty by default.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;⎕IO&lt;/code&gt;: Index Origin. Stores the value where indexes start. GNU APL starts at 1, but can be changed to 0.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;System functions&lt;/head&gt;
    &lt;p&gt;These vary from vendor to vendor, so there is no guarantee that these will work in your APL. For example:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;⎕NL&lt;/code&gt;: Name List. Produces a list of variables, functions, operators or classes.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;⎕EX&lt;/code&gt;: Expunge. Expunges individual APL objects.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;System functions are designed to be used in user-defined commands, whereas system commands are designed for direct usage.&lt;/p&gt;
    &lt;head rend="h3"&gt;Data&lt;/head&gt;
    &lt;quote&gt;⍝⍝⍝ APL Concepts ⍝ Data&lt;/quote&gt;
    &lt;head rend="h4"&gt;Variables&lt;/head&gt;
    &lt;p&gt;Data can be directly quoted…&lt;/p&gt;
    &lt;quote&gt;234.98×3409÷12.4&lt;/quote&gt;
    &lt;p&gt;…or assigned to a name.&lt;/p&gt;
    &lt;quote&gt;VAR ← 183.6&lt;/quote&gt;
    &lt;head rend="h4"&gt;Names&lt;/head&gt;
    &lt;p&gt;APL allows uppercase and lowercase characters, some APLs also allows symbols too.&lt;/p&gt;
    &lt;head rend="h4"&gt;Types of data&lt;/head&gt;
    &lt;p&gt;Data can be numbers, characters or a mixture of those. GNU APL in particular also allows complex numbers; Dyalog allows classes.&lt;/p&gt;
    &lt;head rend="h4"&gt;Size, shape and depth&lt;/head&gt;
    &lt;p&gt;From now on, unless there is something new, only some examples will be typed.&lt;/p&gt;
    &lt;quote&gt;⍝ Scalars (no dimensions) 294 'A' ⍝ Vectors (one dimension -- length) 23 8 0 12 3 'ABC' 28 3 'A' 'BC' ⍝ 2D Matrices (two dimensions -- height and length) ⍝ There is no way to write a matrix literal. 4 4⍴7 45 2 89 16 15 10 21 8 0 13 99 83 19 4 27 4 2⍴'WILSO' 393 'ADAMS' 7183 'CAIRN' 87 'SAMSO' 8467 ⍝ 3D Matrices (three dimensions) 3 3 4⍴36?100&lt;/quote&gt;
    &lt;p&gt;Arrays are data structures of any dimension – obviously, scalars do not apply.&lt;/p&gt;
    &lt;head rend="h4"&gt;Setting up data structures&lt;/head&gt;
    &lt;quote&gt;X1 ← 23 9 144 12 5 0 X2 ← 1 2 'A' 'B' 3 4 2 3⍴23 9 144 12 5 0 NUMS ← 36?100 3 3 4⍴NUMS 6⍴9 ⍝ Nested arrays VAR ← (2 3⍴9) (1 2 3) 'A' 'ABCD' 88 16.1&lt;/quote&gt;
    &lt;head rend="h4"&gt;Data structure versus data value&lt;/head&gt;
    &lt;quote&gt;X ← 1⍴22 Y ← 22 ⍴X ⍝ 1, because X is a vector ⍴Y ⍝ Empty response, because Y is a scalar Z ← 1 5⍴12 5 38 3 6 ⍝ When displayed, Z looks like a vector, ⍴Z ⍝ but is in fact a 1×5 matrix )CLEAR&lt;/quote&gt;
    &lt;head rend="h4"&gt;Empty data structures&lt;/head&gt;
    &lt;p&gt;Useful for some things, for example flor predefined storage areas, where elements can be added.&lt;/p&gt;
    &lt;quote&gt;X ← ⍳0 ⍝ X is a vector of zero elements X ⍝ Printing X gives an empty response ⍴X ⍝ Asking for the shape of X gives a zero&lt;/quote&gt;
    &lt;p&gt;This is fundamentally different than a scalar, which does not have zero elements: a scalar has zero dimensions instead.&lt;/p&gt;
    &lt;code&gt;⍴45
&lt;/code&gt;
    &lt;p&gt;We can also create empty matrices. For example, a matrix of two rows and no columns:&lt;/p&gt;
    &lt;quote&gt;TAB ← 3 0⍴⍳0 TAB ⍴TAB&lt;/quote&gt;
    &lt;head rend="h4"&gt;Dimension ordering&lt;/head&gt;
    &lt;p&gt; General rule when applying an operation to data (e.g. a reduce &lt;code&gt;/&lt;/code&gt;):
&lt;/p&gt;
    &lt;p&gt;Unless specified otherwise, the operation takes place on the last dimension.&lt;/p&gt;
    &lt;p&gt;For example, consider a 3×4 matrix.&lt;/p&gt;
    &lt;quote&gt;X ← 3 4⍴⍳12 +/ X&lt;/quote&gt;
    &lt;p&gt;Applying a reduction to it yields a list of three elements. Each element of the list is the sum of a row. This is because a column is the last dimension of a 2D matrix (3 rows, 4 columns).&lt;/p&gt;
    &lt;p&gt;In other words, since we're performing the reduction on the last dimension (columns), then each result is the sum of all columns belonging to that row.&lt;/p&gt;
    &lt;p&gt; You can change that by using the axis (&lt;code&gt;[]&lt;/code&gt;) operator:
&lt;/p&gt;
    &lt;code&gt;+/[1] X
&lt;/code&gt;
    &lt;p&gt;This carries the reduction on the first axis (rows), therefore the resulting list of four numbers is the sum of each column.&lt;/p&gt;
    &lt;p&gt;Now each result is the sum of all rows belonging to that column.&lt;/p&gt;
    &lt;quote&gt;)CLEAR&lt;/quote&gt;
    &lt;head rend="h4"&gt;Indexing&lt;/head&gt;
    &lt;p&gt;There is something that remains to be discussed. Last section talked about the rows in index 1. This seems to mean that in APL indexes start at 1, but that might not be always true. This is true for GNU APL, to say the least.&lt;/p&gt;
    &lt;p&gt;If you wish to change indexing, just change the Index Origin system variable (this bit is not tangled):&lt;/p&gt;
    &lt;quote&gt;⎕IO ← 0&lt;/quote&gt;
    &lt;p&gt; From here on, we'll consider Index Origin to be &lt;code&gt;1&lt;/code&gt;.
&lt;/p&gt;
    &lt;p&gt; Selecting elements is easy. Just use the brackets (&lt;code&gt;[]&lt;/code&gt;), and separate
variable indexes with &lt;code&gt;;&lt;/code&gt;.
&lt;/p&gt;
    &lt;quote&gt;⍝ Indexing in one dimension X ← 1 45 6 3 9 33 6 0 1 22 X[4] + X[10] ⍝ Indexing in two dimensions TABLE ← 3 3⍴9?100 TABLE[3;2] ⍝ Indexing for more than one dimension ⍝ Indexing in three dimensions DATA ← 4 4 4⍴64?100 DATA[2;1;4] ⍝ Selecting an entire row in tree ways TABLE[1;1 2 3] TABLE[1;⍳3] TABLE[1;] ⍝ Selecting an entire column TABLE[;2] ⍝ Selecting from anonymous data (3 8 4)[1+2] ⍝ Selecting from an anonymous string, based on a variable P ← 2 'ABCDE'[P]&lt;/quote&gt;
    &lt;p&gt;Some useful stuff that has not been discussed yet:&lt;/p&gt;
    &lt;p&gt;Indexing can also be used to rearrange elements on a matrix!&lt;/p&gt;
    &lt;quote&gt;'ABCDE'[4 5 1 4]&lt;/quote&gt;
    &lt;p&gt;We can also do indexing with variables of a higher dimension. This pretty much collects stuff and stores it in the created shape:&lt;/p&gt;
    &lt;quote&gt;'ABCDE'[2 2⍴4 5 1 4]&lt;/quote&gt;
    &lt;p&gt; Indexing can also be done with the squad (&lt;code&gt;⌷&lt;/code&gt;) symbol (notice that this
is different from the quad &lt;code&gt;⎕&lt;/code&gt;, since it is narrower):
&lt;/p&gt;
    &lt;quote&gt;2⌷'ABCD'&lt;/quote&gt;
    &lt;quote&gt;)CLEAR&lt;/quote&gt;
    &lt;head rend="h3"&gt;Built-in functions&lt;/head&gt;
    &lt;p&gt;APL has 50 useful built-in functions in general, and 5 operators to modify and extend how functions work.&lt;/p&gt;
    &lt;quote&gt;⍝ Built-in Functions&lt;/quote&gt;
    &lt;head rend="h4"&gt;Arguments&lt;/head&gt;
    &lt;p&gt;Most functions have two behaviours depending on how you place their arguments. For example:&lt;/p&gt;
    &lt;quote&gt;⌈12.625 ⍝ Ceiling 2⌈8 ⍝ Select greatest number ÷1 2 3 4 5 ⍝ Reciprocal 100÷1 2 3 4 5 ⍝ Divide 100 by each&lt;/quote&gt;
    &lt;head rend="h4"&gt;Execution order&lt;/head&gt;
    &lt;p&gt;Expressions are evaluated from right to left. The results of one function become the argument of the next function.&lt;/p&gt;
    &lt;head rend="h4"&gt;Numbers or text&lt;/head&gt;
    &lt;p&gt; Some functions work on numbers only. Some work on either numbers or text data. Using a function which does not work on a data type yields a &lt;code&gt;DOMAIN ERROR&lt;/code&gt;.
&lt;/p&gt;
    &lt;p&gt; Some functions also work only on a subset of the number domain, such as logical functions (&lt;code&gt;∨&lt;/code&gt;, &lt;code&gt;∧&lt;/code&gt; etc.) Thiis means that they only recognize
the states of TRUTH (&lt;code&gt;1&lt;/code&gt;) and FALSITY (&lt;code&gt;0&lt;/code&gt;).
&lt;/p&gt;
    &lt;head rend="h4"&gt;Shape and size of data&lt;/head&gt;
    &lt;p&gt; Some functions can be used only on data of a certain shape. The following example (not tangled) yields a &lt;code&gt;LENGTH ERROR&lt;/code&gt;, because data on
both sides do not have the same shape:
&lt;/p&gt;
    &lt;quote&gt;29 51 60 27÷3 11&lt;/quote&gt;
    &lt;head rend="h4"&gt;Groups of functions&lt;/head&gt;
    &lt;p&gt;Following there will be some examples of functions, which I'll store in tables as given in the tutorial, for further consulting.&lt;/p&gt;
    &lt;p&gt;Unless there is a new function with non-obvious usage, there will be some examples.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Arithmetic functions&lt;th&gt;Function&lt;/th&gt;&lt;th&gt;Monadic form&lt;/th&gt;&lt;th&gt;Dyadic form&lt;/th&gt;&lt;td&gt;+&lt;/td&gt;&lt;td&gt;Numeric&lt;/td&gt;&lt;td&gt;Add&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;td&gt;Negation&lt;/td&gt;&lt;td&gt;Subtract&lt;/td&gt;&lt;td&gt;×&lt;/td&gt;&lt;td&gt;Sign&lt;/td&gt;&lt;td&gt;Multiply&lt;/td&gt;&lt;td&gt;÷&lt;/td&gt;&lt;td&gt;Reciprocal&lt;/td&gt;&lt;td&gt;Divide&lt;/td&gt;&lt;td&gt;⌈&lt;/td&gt;&lt;td&gt;Ceiling&lt;/td&gt;&lt;td&gt;Biggest&lt;/td&gt;&lt;td&gt;⌊&lt;/td&gt;&lt;td&gt;Floor&lt;/td&gt;&lt;td&gt;Smallest&lt;/td&gt;&lt;td&gt;&amp;amp;vert;&lt;/td&gt;&lt;td&gt;Modulo&lt;/td&gt;&lt;td&gt;Remainder&lt;/td&gt;&lt;/item&gt;
      &lt;item&gt;Algebraic functions&lt;p&gt;Functions for advanced arithmetic.&lt;/p&gt;&lt;th&gt;Function&lt;/th&gt;&lt;th&gt;Monadic form&lt;/th&gt;&lt;th&gt;Dyadic form&lt;/th&gt;&lt;td&gt;⍳&lt;/td&gt;&lt;td&gt;Index generator&lt;/td&gt;&lt;td&gt;?&lt;/td&gt;&lt;td&gt;Random number&lt;/td&gt;&lt;td&gt;Random deal&lt;/td&gt;&lt;td&gt;⋆ or *&lt;/td&gt;&lt;td&gt;'e' to the power&lt;/td&gt;&lt;td&gt;Number to the power&lt;/td&gt;&lt;td&gt;⍟&lt;/td&gt;&lt;td&gt;Log to base 'e'&lt;/td&gt;&lt;td&gt;Log to any base&lt;/td&gt;&lt;td&gt;○&lt;/td&gt;&lt;td&gt;π times&lt;/td&gt;&lt;td&gt;Sine, cosine, etc&lt;/td&gt;&lt;td&gt;!&lt;/td&gt;&lt;td&gt;Factorial&lt;/td&gt;&lt;td&gt;Combinations&lt;/td&gt;&lt;td&gt;⌹&lt;/td&gt;&lt;td&gt;Matrix inversion&lt;/td&gt;&lt;td&gt;Matrix division&lt;/td&gt;&lt;list rend="ul"&gt;&lt;item&gt;Circle operator&lt;p&gt;The circle operator (&lt;/p&gt;&lt;code&gt;○&lt;/code&gt;) does not have an obvious operation on its dyadic form. Here is a table of values of α on the case α ○ ω, taken from TryAPL:&lt;th&gt;α&lt;/th&gt;&lt;th&gt;α ○ ω&lt;/th&gt;&lt;th&gt;α&lt;/th&gt;&lt;th&gt;α ○ ω&lt;/th&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;(1-ω⋆2)⋆0.5&lt;/td&gt;&lt;td&gt;¯1&lt;/td&gt;&lt;td&gt;Arcsin ω&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;Sin ω&lt;/td&gt;&lt;td&gt;¯2&lt;/td&gt;&lt;td&gt;Arccos ω&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;Cos ω&lt;/td&gt;&lt;td&gt;¯3&lt;/td&gt;&lt;td&gt;Arctan ω&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;Tan ω&lt;/td&gt;&lt;td&gt;¯4&lt;/td&gt;&lt;td&gt;(¯1+ω⋆2)⋆0.5&lt;/td&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;(1+ω⋆2)≠0.5&lt;/td&gt;&lt;td&gt;¯5&lt;/td&gt;&lt;td&gt;Arcsinh ω&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;Sinh ω&lt;/td&gt;&lt;td&gt;¯6&lt;/td&gt;&lt;td&gt;Arccosh ω&lt;/td&gt;&lt;td&gt;6&lt;/td&gt;&lt;td&gt;Cosh ω&lt;/td&gt;&lt;td&gt;¯7&lt;/td&gt;&lt;td&gt;Arctanh ω&lt;/td&gt;&lt;td&gt;7&lt;/td&gt;&lt;td&gt;Tanh ω&lt;/td&gt;&lt;td&gt;¯8&lt;/td&gt;&lt;td&gt;-8○ω&lt;/td&gt;&lt;td&gt;8&lt;/td&gt;&lt;td&gt;(¯1+ω⋆2)⋆0.5&lt;/td&gt;&lt;td&gt;¯9&lt;/td&gt;&lt;td&gt;ω&lt;/td&gt;&lt;td&gt;9&lt;/td&gt;&lt;td&gt;Real part of ω&lt;/td&gt;&lt;td&gt;¯10&lt;/td&gt;&lt;td&gt;+ω&lt;/td&gt;&lt;td&gt;10&lt;/td&gt;&lt;td&gt;&amp;amp;vert; ω&lt;/td&gt;&lt;td&gt;¯11&lt;/td&gt;&lt;td&gt;ω ×&lt;/td&gt;&lt;code&gt;0J1&lt;/code&gt;&lt;td&gt;11&lt;/td&gt;&lt;td&gt;Imag part of ω&lt;/td&gt;&lt;td&gt;¯12&lt;/td&gt;&lt;td&gt;⋆ω&lt;/td&gt;&lt;td&gt;12&lt;/td&gt;&lt;td&gt;Phase of ω&lt;/td&gt;&lt;p&gt;Also notice that&lt;/p&gt;&lt;code&gt;0J1&lt;/code&gt;is a complex number of real part&lt;code&gt;0&lt;/code&gt;and imaginary part&lt;code&gt;1&lt;/code&gt;.&lt;/item&gt;&lt;item&gt;Domino operator&lt;p&gt;The Domino operator (&lt;/p&gt;&lt;code&gt;⌹&lt;/code&gt;) generates the inverse of a matrix in its monadic form, and divides a matrix by another in its dyadic form:&lt;quote&gt;MAT ← 2 2⍴⍳4 ⌹MAT 5 6⌹MAT&lt;/quote&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Circle operator&lt;/item&gt;
      &lt;item&gt;Comparative functions&lt;th&gt;Function&lt;/th&gt;&lt;th&gt;Monadic form&lt;/th&gt;&lt;th&gt;Dyadic form&lt;/th&gt;&lt;td&gt;&amp;lt;&lt;/td&gt;&lt;td&gt;Less than&lt;/td&gt;&lt;td&gt;≤&lt;/td&gt;&lt;td&gt;Less than or equal&lt;/td&gt;&lt;td&gt;=&lt;/td&gt;&lt;td&gt;Equal&lt;/td&gt;&lt;td&gt;≥&lt;/td&gt;&lt;td&gt;Greater than or equal&lt;/td&gt;&lt;td&gt;&amp;gt;&lt;/td&gt;&lt;td&gt;Greater than&lt;/td&gt;&lt;td&gt;≠&lt;/td&gt;&lt;td&gt;Not equal&lt;/td&gt;&lt;td&gt;≡&lt;/td&gt;&lt;td&gt;Depth&lt;/td&gt;&lt;td&gt;Match&lt;/td&gt;&lt;td&gt;≢&lt;/td&gt;&lt;td&gt;Tally&lt;/td&gt;&lt;td&gt;Not match&lt;/td&gt;&lt;td&gt;∊&lt;/td&gt;&lt;td&gt;Enlist&lt;/td&gt;&lt;td&gt;Membership&lt;/td&gt;&lt;td&gt;⍳&lt;/td&gt;&lt;td&gt;Iota&lt;/td&gt;&lt;td&gt;Index of&lt;/td&gt;&lt;td&gt;⍷&lt;/td&gt;&lt;td&gt;Find&lt;/td&gt;&lt;p&gt;Here's an interesting use for comparative functions: Suppose we have a table, where some numbers are negative. How can we test which numbers are less than zero in it?&lt;/p&gt;&lt;quote&gt;TABLE ← 3 3⍴25-9?50 TABLE &amp;lt; 0&lt;/quote&gt;&lt;list rend="ul"&gt;&lt;item&gt;Equal underbar&lt;p&gt;The Equal underbar (&lt;/p&gt;&lt;code&gt;≡&lt;/code&gt;) serves two purposes. In its monadic form, it shows the depth of a specific structure.&lt;quote&gt;≡2 2⍴1 (2 3) (4 5 6 7) (8 (9 10) 11)&lt;/quote&gt;&lt;p&gt;In its dyadic form, it attempts to match both parameters to see if they are equal in shape, order and values:&lt;/p&gt;&lt;quote&gt;'t' 'e' 's' 't'≡'test'&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Equal underbar slash&lt;p&gt;The Equal underbar slash (&lt;/p&gt;&lt;code&gt;≢&lt;/code&gt;) does the exact opposite of&lt;code&gt;≡&lt;/code&gt;. In its monadic form, it shows the tally (shallowest depth) of a specific structure:&lt;quote&gt;≢2 2⍴1 (2 3) (4 5 6 7) (8 (9 10) 11)&lt;/quote&gt;&lt;p&gt;In its dyadic form, it checks if both parameters do not match:&lt;/p&gt;&lt;quote&gt;('t' 'e') ('s' 't')≢'test'&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Epsilon&lt;p&gt;The Epsilon (&lt;/p&gt;&lt;code&gt;∊&lt;/code&gt;), in its dyadic form, checks whether the first parameter is enclosed in the second parameter, thus testing for membership:&lt;quote&gt;2∊1 2 3&lt;/quote&gt;&lt;p&gt;The monadic form, however, enlists a certain value. If it is a scalar, it is put into a list; if it is a list, nothing changes; if it is a matrix, rows will be put one after the other to form a single list.&lt;/p&gt;&lt;quote&gt;∊3 3 3⍴⍳27&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Epsilon underbar&lt;p&gt;The Epsilon underbar (&lt;/p&gt;&lt;code&gt;⍷&lt;/code&gt;) is only dyadic, and attempts to find the first argument (which should be a pattern) inside the second argument. The result should be a structure which marks where the occurence starts for each occurence found.&lt;quote&gt;'ana' ⍷ 'banana'&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Iota&lt;p&gt;The Iota (&lt;/p&gt;&lt;code&gt;⍳&lt;/code&gt;) in its monadic form generates a list from&lt;code&gt;0&lt;/code&gt;to&lt;code&gt;n&lt;/code&gt;.&lt;quote&gt;⍳9 3 3⍴⍳9&lt;/quote&gt;&lt;p&gt;In its dyadic form, it attempts to find the second argument inside the first argument. The first match found returns the element index inside the list, matrix, etc.&lt;/p&gt;&lt;quote&gt;X ← 0 0 5 3 X[(0≠0 0 5 3)⍳1] ⍝ Get first non-null element of X&lt;/quote&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Equal underbar&lt;/item&gt;
      &lt;item&gt;Logical functions&lt;p&gt;These functions work only with yielding&lt;/p&gt;&lt;code&gt;0&lt;/code&gt;or&lt;code&gt;1&lt;/code&gt;by default, but they are also used for branching.&lt;p&gt;All functions are dyadic, unless specified otherwise.&lt;/p&gt;&lt;th&gt;Function&lt;/th&gt;&lt;th&gt;Description&lt;/th&gt;&lt;td&gt;~&lt;/td&gt;&lt;td&gt;Not (Monadic)&lt;/td&gt;&lt;td&gt;∨&lt;/td&gt;&lt;td&gt;Or&lt;/td&gt;&lt;td&gt;∧&lt;/td&gt;&lt;td&gt;And&lt;/td&gt;&lt;td&gt;⍱&lt;/td&gt;&lt;td&gt;Nor&lt;/td&gt;&lt;td&gt;⍲&lt;/td&gt;&lt;td&gt;Nand&lt;/td&gt;&lt;quote&gt;~1 0 1 1 0 1∨0 0 1 1 0 1∧0 0 1 1 0 1⍱0 0 1 1 0 1⍲0 0 1&lt;/quote&gt;&lt;p&gt;We can also short-circuit expressions. Should even be useful for comparisions.&lt;/p&gt;&lt;quote&gt;(5 &amp;gt; 4) ∧ 1 &amp;lt; 3&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Manipulative functions&lt;th&gt;Function&lt;/th&gt;&lt;th&gt;Monadic form&lt;/th&gt;&lt;th&gt;Dyadic form&lt;/th&gt;&lt;td&gt;⍴&lt;/td&gt;&lt;td&gt;Shape&lt;/td&gt;&lt;td&gt;Reshape&lt;/td&gt;&lt;td&gt;,&lt;/td&gt;&lt;td&gt;Ravel&lt;/td&gt;&lt;td&gt;Catenate&lt;/td&gt;&lt;td&gt;~&lt;/td&gt;&lt;td&gt;Not&lt;/td&gt;&lt;td&gt;Without&lt;/td&gt;&lt;td&gt;⌽&lt;/td&gt;&lt;td&gt;Reverse&lt;/td&gt;&lt;td&gt;Rotate&lt;/td&gt;&lt;td&gt;⍉&lt;/td&gt;&lt;td&gt;Transpose&lt;/td&gt;&lt;td&gt;Dyadic transpose&lt;/td&gt;&lt;td&gt;↑&lt;/td&gt;&lt;td&gt;Take first&lt;/td&gt;&lt;td&gt;Take&lt;/td&gt;&lt;code&gt;n&lt;/code&gt;&lt;td&gt;↓&lt;/td&gt;&lt;td&gt;Drop&lt;/td&gt;&lt;code&gt;n&lt;/code&gt;&lt;td&gt;⊂&lt;/td&gt;&lt;td&gt;Enclose&lt;/td&gt;&lt;td&gt;Partitioned enclose&lt;/td&gt;&lt;td&gt;⊃&lt;/td&gt;&lt;td&gt;Disclose&lt;/td&gt;&lt;td&gt;Pick&lt;/td&gt;&lt;td&gt;∩&lt;/td&gt;&lt;td&gt;Intersection&lt;/td&gt;&lt;td&gt;∪&lt;/td&gt;&lt;td&gt;Unique&lt;/td&gt;&lt;td&gt;Union&lt;/td&gt;&lt;td&gt;⊢&lt;/td&gt;&lt;td&gt;Identity&lt;/td&gt;&lt;td&gt;Right&lt;/td&gt;&lt;td&gt;⊣&lt;/td&gt;&lt;td&gt;Identity&lt;/td&gt;&lt;td&gt;Left&lt;/td&gt;&lt;list rend="ul"&gt;&lt;item&gt;Comma&lt;p&gt;The Ravel (&lt;/p&gt;&lt;code&gt;,&lt;/code&gt;) operator, in its monadic form, turns a matrix into a list.&lt;quote&gt;X ← 3 3 3⍴⍳27 ⍝ A cube ,X&lt;/quote&gt;&lt;p&gt;However, we can use axis parameters to induce other behaviours.&lt;/p&gt;&lt;quote&gt;,[1 2]X&lt;/quote&gt;&lt;p&gt;The dyadic form catenates two structures. The particular behaviour is determined by shape.&lt;/p&gt;&lt;quote&gt;(3 3⍴⍳9),(3 3⍴9+⍳9)&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Circle Stile&lt;p&gt;The Reverse (&lt;/p&gt;&lt;code&gt;⌽&lt;/code&gt;), in its monadic form, reverses the elements along the last axis.&lt;quote&gt;⌽0 0 5 7&lt;/quote&gt;&lt;p&gt;Its dyadic form performs a rotation on the elements of the second parameter, in the last axis, by the number of elements specified in the second parameter, as if the data were stored in a toroidal shape. Number of rotated elements' sign provides the direction.&lt;/p&gt;&lt;quote&gt;2⌽3 3⍴⍳9 ¯2⌽3 3⍴⍳9&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Transpose&lt;p&gt;The Transpose (&lt;/p&gt;&lt;code&gt;⍉&lt;/code&gt;), in its monadic form, reverses the axes of the given matrix.&lt;quote&gt;⍉3 3⍴⍳9&lt;/quote&gt;&lt;p&gt;In its dyadic form, we can directly instruct which axes are swapped and how:&lt;/p&gt;&lt;quote&gt;2 1 3⍉3 3 3⍴⍳27 ⍝ Swap axes 1 and 2&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Up Arrow&lt;p&gt;The Take function (&lt;/p&gt;&lt;code&gt;↑&lt;/code&gt;), in its monadic form, gets the first element of an array.&lt;quote&gt;↑3 1 2&lt;/quote&gt;&lt;p&gt;In its dyadic form, it takes exactly the number of elements specified at the first parameter, from the second parameter. If the absolute number exceeds the length, the resulting list is zero-filled. If the number is negative, it is taken from last element.&lt;/p&gt;&lt;quote&gt;2↑⌽⍳4 ¯7↑⌽⍳4&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Down Arrow&lt;p&gt;The Drop function (&lt;/p&gt;&lt;code&gt;↓&lt;/code&gt;) has only a dyadic form, and drops the number of elements in the first parameter from the second parameter list. If the number is negative, the drop happens from the end. If the absolute number exceeds the length, an empty response is returned.&lt;/item&gt;&lt;item&gt;Left Shoe&lt;p&gt;The Enclose (&lt;/p&gt;&lt;code&gt;⊂&lt;/code&gt;) function, in its monadic form, encloses the given object into a nested scalar.&lt;quote&gt;⊂2 2⍴⍳4 ⍴⊂2 2⍴⍳4&lt;/quote&gt;&lt;p&gt;In its dyadic form, it does a selective enclosing, returning the enclosed objects:&lt;/p&gt;&lt;quote&gt;0 1 1 0⊂⍳4&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Right Shoe&lt;p&gt;The Disclose (&lt;/p&gt;&lt;code&gt;⊃&lt;/code&gt;) function, in its monadic form, discloses the single elements of an object, zero-filling the missing elements so that all of them belong to a single shape, with the same number of dimensions.&lt;quote&gt;⊃(⍳4) 2 3&lt;/quote&gt;&lt;p&gt;In its dyadic form, it recursively picks up a certain element from a nested structure.&lt;/p&gt;&lt;quote&gt;X ← 4⍴⊂(4 4⍴16?100) ⍝ List of four enclosed 4x4 matrices 2 (2 2)⊃X ⍝ Pick 2nd matrix, then pick element [2;2]&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Right Tack&lt;p&gt;The Right (&lt;/p&gt;&lt;code&gt;⊢&lt;/code&gt;) function does nothing in its monadic form, giving back the untouched data. Its dyadic form, however, selects the left element. It has a particularly useful property of selecting the rightmost element when mapped over a structure:&lt;quote&gt;2 3⊢4 5 ⊢/ 6 7 8 9&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Left Tack&lt;p&gt;The Left (&lt;/p&gt;&lt;code&gt;⊣&lt;/code&gt;) function works much like Right, except that it selects the left element, or the leftmost element on a mapping:&lt;quote&gt;2 3⊣4 5 ⊣/ 6 7 8 9&lt;/quote&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Comma&lt;/item&gt;
      &lt;item&gt;Sorting and coding functions&lt;th&gt;Function&lt;/th&gt;&lt;th&gt;Monadic form&lt;/th&gt;&lt;th&gt;Dyadic form&lt;/th&gt;&lt;td&gt;⍋&lt;/td&gt;&lt;td&gt;Grade up&lt;/td&gt;&lt;td&gt;Collated grade up&lt;/td&gt;&lt;td&gt;⍒&lt;/td&gt;&lt;td&gt;Grade down&lt;/td&gt;&lt;td&gt;Collated grade down&lt;/td&gt;&lt;td&gt;⊥&lt;/td&gt;&lt;td&gt;Decode&lt;/td&gt;&lt;td&gt;⊤&lt;/td&gt;&lt;td&gt;Encode&lt;/td&gt;&lt;list rend="ul"&gt;&lt;item&gt;Grade Up&lt;p&gt;The Grade Up (&lt;/p&gt;&lt;code&gt;⍋&lt;/code&gt;) function, in its monadic form, returns the indexes of elements in ascending order.&lt;quote&gt;LIST ← 10?100 LIST[⍋LIST]&lt;/quote&gt;&lt;p&gt;In its dyadic form, the first parameter is a collating sequence, which enumerates top-priority elements for the ordering. Elements outside of the collation are put in the end of the sequence.&lt;/p&gt;&lt;quote&gt;TEXT ← 'Banana' TEXT['an'⍋TEXT]&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Grade Down&lt;p&gt;The Grade Down (&lt;/p&gt;&lt;code&gt;⍒&lt;/code&gt;) function works just like Grade Up, except that it returns indexes of elements in descending order.&lt;p&gt;On the dyadic form, the collating sequence enumerates elements which shall be ordered from rightmost to leftmost. Elements outside of the collation are put in the beginning of the sequence.&lt;/p&gt;&lt;quote&gt;LIST ← 10?100 TEXT ← 'Banana' LIST[⍒LIST] TEXT['an'⍒TEXT]&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Decode&lt;p&gt;The Decode (&lt;/p&gt;&lt;code&gt;⊥&lt;/code&gt;) function converts a number (expressed as a list) on the second argument to the base shown in the first argument.&lt;quote&gt;2⊥0 0 1 0 1 16⊥2 1 24 60 60⊥2 46 40 ⍝ Time conversion! 2h46m40s into total seconds&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Encode&lt;p&gt;The Encode (&lt;/p&gt;&lt;code&gt;⊤&lt;/code&gt;) function does the opposite of Decode.&lt;quote&gt;2 2 2 2⊤5 7 12 24 60 60⊤10000 ⍝ Mixed radix; convert 10000 seconds to h m s&lt;/quote&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Grade Up&lt;/item&gt;
      &lt;item&gt;Miscellaneous functions and other symbols&lt;th&gt;Function&lt;/th&gt;&lt;th&gt;Meaning&lt;/th&gt;&lt;td&gt;⎕&lt;/td&gt;&lt;td&gt;Numeric input from keyboard (niladic)&lt;/td&gt;&lt;td&gt;⍞&lt;/td&gt;&lt;td&gt;Character input from keyboard (niladic)&lt;/td&gt;&lt;td&gt;◊&lt;/td&gt;&lt;td&gt;Stament separator&lt;/td&gt;&lt;td&gt;⍝&lt;/td&gt;&lt;td&gt;Comment&lt;/td&gt;&lt;td&gt;⍎&lt;/td&gt;&lt;td&gt;Evaluate text as APL expression (monadic)&lt;/td&gt;&lt;td&gt;⍕&lt;/td&gt;&lt;td&gt;Format (monadic/dyadic)&lt;/td&gt;&lt;td&gt;⌷&lt;/td&gt;&lt;td&gt;Index (dyadic)&lt;/td&gt;&lt;td&gt;⍬&lt;/td&gt;&lt;td&gt;Zilde&lt;/td&gt;&lt;list rend="ul"&gt;&lt;item&gt;Diamond&lt;p&gt;The statement separator (&lt;/p&gt;&lt;code&gt;◊&lt;/code&gt;) allows for inputting more than one statement in a single line.&lt;quote&gt;LIST ← 25-(5?50) ◊ (÷LIST)&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Hydrant&lt;p&gt;The Execute operator (&lt;/p&gt;&lt;code&gt;⍎&lt;/code&gt;) evaluates a textual expression as an APL statement.&lt;code&gt;⍎'X ← 10×3 3⍴⍳9 ◊ ÷X'&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Thorn&lt;p&gt;The Format operator (&lt;/p&gt;&lt;code&gt;⍕&lt;/code&gt;) in its monadic form, transforms values into a character list, suited to display onscreen.&lt;quote&gt;⍕1 2 3&lt;/quote&gt;&lt;p&gt;Its dyadic form requires a format list as first argument, containing the field width for each value and its number of decimal places. The second argument is the values. If the field is not wide enough, it gives a&lt;/p&gt;&lt;code&gt;DOMAIN ERROR&lt;/code&gt;.&lt;quote&gt;6 2⍕3.25 3.002 ⍝ 8 2⍕1234 ⍝ Not wide enough&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Squad&lt;p&gt;The Index operator (&lt;/p&gt;&lt;code&gt;⌷&lt;/code&gt;) has only a dyadic form, where one can pick elements at something. It also supports axis parameters.&lt;quote&gt;TABLE ← 3 4⍴⍳12 2 3⌷TABLE 2⌷[1] TABLE 2⌷[2] TABLE&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Zilde&lt;p&gt;The Empty Numeric Vector (&lt;/p&gt;&lt;code&gt;⍬&lt;/code&gt;) is a vector of zero elements.&lt;quote&gt;⍝ These are a match, since they are numeric vectors. ⍬≡⍳0 ⍬≡0⍴0 ⍝ These do not match. ⍬≡0 0⍴0 ⍝ Not a vector ⍬≡'' ⍝ Not numeric&lt;/quote&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Diamond&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;System functions&lt;/head&gt;
    &lt;p&gt;System functions exist to extend the power of APL, improving the usable tasks.&lt;/p&gt;
    &lt;p&gt;See the implementation documentation for that.&lt;/p&gt;
    &lt;head rend="h3"&gt;Built-in operators&lt;/head&gt;
    &lt;quote&gt;⍝ Built-in Operators&lt;/quote&gt;
    &lt;p&gt;Operators are used to specify the way in which one or more functions are applied to data. For example: repeatedly, cumulatively, etc.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Operator&lt;/cell&gt;
        &lt;cell role="head"&gt;Name&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;/&lt;/cell&gt;
        &lt;cell&gt;Slash&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;⌿&lt;/cell&gt;
        &lt;cell&gt;Slash bar&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;\&lt;/cell&gt;
        &lt;cell&gt;Backslash&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;⍀&lt;/cell&gt;
        &lt;cell&gt;Backslash bar&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;.&lt;/cell&gt;
        &lt;cell&gt;Inner product&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;∘.&lt;/cell&gt;
        &lt;cell&gt;Outer product&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;¨&lt;/cell&gt;
        &lt;cell&gt;Each&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;[ ]&lt;/cell&gt;
        &lt;cell&gt;Axis&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;⍨&lt;/cell&gt;
        &lt;cell&gt;Duplicate/Commute&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;∘&lt;/cell&gt;
        &lt;cell&gt;Compose&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h4"&gt;Reduce and scan&lt;/head&gt;
    &lt;p&gt; When used with functions as their operands, Slash and Backslash become Reduce (&lt;code&gt;/&lt;/code&gt;) and Scan (&lt;code&gt;\&lt;/code&gt;), which apply a single function to all elements
of an argument.
&lt;/p&gt;
    &lt;quote&gt;⍝ These two operations are equivalent 22 + 93 + 4.6 + 10 + 3.3 +/22 93 4.6 10 3.3 ⍝ Reduce using plus&lt;/quote&gt;
    &lt;p&gt; In the last example, Reduce interposes the &lt;code&gt;+&lt;/code&gt; between the values on the
vector. Were it replaced by the Scan operator, the same would happen,
but the result would be a vector containing intermediate results; the
last element of such vector would be the last result.
&lt;/p&gt;
    &lt;quote&gt;+\22 93 4.6 10 3.3 ⍝ Scan using plus 22 (22+93) (115+4.6) (119.6+10) (129.6+3.3) ⍝ Equivalent calculation&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reduce First and Scan First&lt;p&gt;Using a Slash bar with a function means using the Reduce First (&lt;/p&gt;&lt;code&gt;⌿&lt;/code&gt;) operator. This will apply a reduction on the first dimension of the data structure:&lt;quote&gt;TABLE ← 3 5⍴15?30 +⌿ TABLE&lt;/quote&gt;&lt;p&gt;Using a Backslash bar with a function means using the Scan First (&lt;/p&gt;&lt;code&gt;⍀&lt;/code&gt;) operator. This does something similar to Scan, but stores each result in a matrix row (first dimension).&lt;quote&gt;+⍀ TABLE&lt;/quote&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Compress and expand&lt;/head&gt;
    &lt;p&gt; When used with one or more numbers, Slash and Backslash become Compression (&lt;code&gt;/&lt;/code&gt;) and Expansion (&lt;code&gt;\&lt;/code&gt;).
&lt;/p&gt;
    &lt;p&gt;Compress selects a part of an object:&lt;/p&gt;
    &lt;quote&gt;1 0 1 1 0 1 / 'ABCDEF'&lt;/quote&gt;
    &lt;p&gt;Expand inserts fill data into objects:&lt;/p&gt;
    &lt;quote&gt;TABLE ← 2 3⍴⍳6 ⍝ Insert new columns (axis 2). ⍝ New columns indicated by zeroes. 1 0 1 0 1\[2]TABLE&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Compress First and Expand First&lt;p&gt;The Compress First (&lt;/p&gt;&lt;code&gt;⌿&lt;/code&gt;) operator, also known as Replicate First, is the dyadic form of the Slash Bar, and can be used in a matrix to remove and duplicate certain rows (first dimension):&lt;quote&gt;TABLE ← 3 4⍴⍳12 1 0 2⌿TABLE ⍝ Remove 2nd row, duplicate 3rd row&lt;/quote&gt;&lt;p&gt;The Expand First (&lt;/p&gt;&lt;code&gt;⍀&lt;/code&gt;) operator is the dyadic version of the Backslash bar, and also works by adding new rows (first dimension) to a matrix.&lt;quote&gt;TABLE ← 3 4⍴⍳12 1 0 1 0 1 0 0⍀TABLE&lt;/quote&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Outer and inner products&lt;/head&gt;
    &lt;p&gt;Product operators distribute the application of a function between each element of one argument and all elements in another; this removes the constraint on applying certain functions to arguments of same shape.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Outer Product&lt;p&gt;The outer product (&lt;/p&gt;&lt;code&gt;∘.&lt;/code&gt;)gives the result of applying the function to all combinations of elements in both arguments:&lt;quote&gt;1 2 3∘.+4 5 6&lt;/quote&gt;&lt;p&gt;The result is a 3×3 matrix, where the first column is the sum between&lt;/p&gt;&lt;code&gt;1&lt;/code&gt;and each of the numbers in the second argument; the second column is the sum between&lt;code&gt;2&lt;/code&gt;and each of the numbers in the second argument; and so on.&lt;p&gt;Another example: a matrix of powers.&lt;/p&gt;&lt;quote&gt;(⍳4)∘.*⍳4&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Inner Product&lt;p&gt;The inner product (&lt;/p&gt;&lt;code&gt;.&lt;/code&gt;) allows two functions to be applied to arguments; operations happen between the last dimension of the left argument, and the first dimension of the right argument; so the two inner dimensions are used.&lt;p&gt;Using this on matrices results in two steps:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Each row of the left argument is applied to each column of the right argument. This uses the rightmost function;&lt;/item&gt;&lt;item&gt;The leftmost function is applied to the result, through a Reduction (&lt;code&gt;/&lt;/code&gt;).&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;X←3 3⍴9?100 Y←3 3⍴9?100 ⍝ 1. Each row of X is multiplied by each column of Y; ⍝ 2. The result is reduced through a sum. X+.×Y&lt;/quote&gt;&lt;p&gt;There are up to 400 possible inner products. Some uses are:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Locating incidences of given character strings within textual data;&lt;/item&gt;&lt;item&gt;Evaluation of polynomials;&lt;/item&gt;&lt;item&gt;Matrix multiplication;&lt;/item&gt;&lt;item&gt;Product of powers;&lt;/item&gt;&lt;item&gt;Etc.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Each&lt;/head&gt;
    &lt;p&gt; The Each operator (&lt;code&gt;¨&lt;/code&gt;) allows applying a certain function (on the left)
to each elements of an array or vector (on the right).
&lt;/p&gt;
    &lt;quote&gt;⍴¨(⍳3)(⍳2)(⍳5) ⍝ Find the length of each vector&lt;/quote&gt;
    &lt;head rend="h4"&gt;Axis&lt;/head&gt;
    &lt;p&gt;Some functions operate in data which has more than one dimension. One can change the axis in which they operate by using the axis operator.&lt;/p&gt;
    &lt;p&gt; By default, APL functions work on the last dimension of your data. The order of dimensions is the one show when you apply &lt;code&gt;⍴&lt;/code&gt; to the data.
&lt;/p&gt;
    &lt;quote&gt;TABLE ← 2 3⍴⍳6 ⍝ A matrix of 2×3 (two dimensions) ⍝ Reduce with + on the second dimension. This gives a ⍝ list of two numbers, each being the sum of numbers ⍝ along the COLUMNS (dimension 2, last one) of each ⍝ row of the matrix. +/TABLE ⍝ This reduction specifies that the sum should occur ⍝ along the ROWS (dimension 1) of a column of the ⍝ matrix, therefore it gives a list of three numbers. +/[1]TABLE&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Functions that accept axis specifications&lt;p&gt;here are some built-in functions and operators that accept specifying axes:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Functions &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;↑&lt;/code&gt;(First, Take)&lt;/item&gt;&lt;item&gt;&lt;code&gt;↓&lt;/code&gt;(Drop)&lt;/item&gt;&lt;item&gt;&lt;code&gt;⊂&lt;/code&gt;(Enclose, Partition)&lt;/item&gt;&lt;item&gt;&lt;code&gt;⊃&lt;/code&gt;(Disclose, Pick)&lt;/item&gt;&lt;item&gt;&lt;code&gt;,&lt;/code&gt;(Ravel, Catenate)&lt;/item&gt;&lt;item&gt;&lt;code&gt;⌽&lt;/code&gt;,&lt;code&gt;⊖&lt;/code&gt;(Reversal, Rotation)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Operators &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;/&lt;/code&gt;(Reduce, Compress)&lt;/item&gt;&lt;item&gt;&lt;code&gt;\&lt;/code&gt;(Scan, Expand)&lt;/item&gt;&lt;item&gt;&lt;code&gt;⌿&lt;/code&gt;(Reduce First, Compress First)&lt;/item&gt;&lt;item&gt;&lt;code&gt;⍀&lt;/code&gt;(Scan First, Compress First)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Functions &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;User-defined Functions&lt;/head&gt;
    &lt;quote&gt;⍝ User-defined functions&lt;/quote&gt;
    &lt;head rend="h4"&gt;Arguments and results&lt;/head&gt;
    &lt;p&gt;Functions can be thought of as external programs which are run. They can be:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Niladic: They have no specified arguments.&lt;/item&gt;
      &lt;item&gt;Monadic: Functions have one argument, passed at its right.&lt;/item&gt;
      &lt;item&gt;Dyadic: Functions have two arguments, the first is passed at its left and the second is passed at its right.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Passing many values as an argument is enclosed into a single vector of arguments.&lt;/p&gt;
    &lt;p&gt;Definining a function that is both monadic and dyadic require testing the first and second arguments to dispatch based on it.&lt;/p&gt;
    &lt;p&gt;If you need to express a result, you will also need to give a name for the result field.&lt;/p&gt;
    &lt;head rend="h4"&gt;User-defined operators&lt;/head&gt;
    &lt;p&gt;Operators must have one or two operands, which are functions; not more nor less, since operators are used to modify the behaviour of functions.&lt;/p&gt;
    &lt;head rend="h4"&gt;Editing functions&lt;/head&gt;
    &lt;p&gt; Some APLs allow you to edit a function by using the &lt;code&gt;)EDIT&lt;/code&gt; command or
the &lt;code&gt;⎕EDIT&lt;/code&gt; system function. This is the case for Dyalog, for example –
however, Dyalog uses the &lt;code&gt;)ED&lt;/code&gt; command instead.
&lt;/p&gt;
    &lt;quote&gt;)ED FUNK&lt;/quote&gt;
    &lt;p&gt; Older APL systems, like GNU APL, allows editing one-line-at-time, using the Del (&lt;code&gt;∇&lt;/code&gt;) editor. However, the &lt;code&gt;gnu-apl-mode&lt;/code&gt; for Emacs replaces
the use of Del by opening a new temporary buffer to edit the function.
&lt;/p&gt;
    &lt;code&gt;∇FUNK
&lt;/code&gt;
    &lt;p&gt; APL uses the concept of workspaces to store functions and values, however one can safely use the Del (&lt;code&gt;∇&lt;/code&gt;) notation to define a certain
function in an APL code file:
&lt;/p&gt;
    &lt;quote&gt;∇FUNK ⍝ Add some code here... ∇&lt;/quote&gt;
    &lt;p&gt;The rest of this text will use the Del editor notation, in a way which it can be executed in a GNU APL script, therefore some things will be different e.g. line numbers will not be used here.&lt;/p&gt;
    &lt;head rend="h4"&gt;The function header&lt;/head&gt;
    &lt;p&gt;When typing the function, one must type a suitable function header, for example:&lt;/p&gt;
    &lt;quote&gt;∇SD X SUM ← +/X AVG ← SUM÷⍴X DIFF ← AVG-X SQDIFF ← DIFF⋆2 SQAVG ← (+/SQDIFF)÷⍴SQDIFF RESULT ← SQAVG⋆0.5 ∇&lt;/quote&gt;
    &lt;p&gt; This function takes a vector called &lt;code&gt;X&lt;/code&gt; and performs some computation
using it.
&lt;/p&gt;
    &lt;quote&gt;SD 12 45 20 68 92 108&lt;/quote&gt;
    &lt;p&gt; The result exists in the global variable &lt;code&gt;RESULT&lt;/code&gt;, created inside the
function.
&lt;/p&gt;
    &lt;p&gt;If we were defining a function with two operators, we would have a header such as:&lt;/p&gt;
    &lt;code&gt;∇X CALC Y
&lt;/code&gt;
    &lt;p&gt; And if we wanted the result to be put in a specific variable, see how we could redefine &lt;code&gt;SD&lt;/code&gt;:
&lt;/p&gt;
    &lt;quote&gt;∇R ← SD X SUM ← +/X AVG ← SUM÷⍴X DIFF ← AVG-X SQDIFF ← DIFF⋆2 SQAVG ← (+/SQDIFF)÷⍴SQDIFF R ← SQAVG⋆0.5 ∇&lt;/quote&gt;
    &lt;p&gt; By doing this, the result of applying &lt;code&gt;SD&lt;/code&gt; to something could be
assigned to a variable; &lt;code&gt;R&lt;/code&gt; itself is not a variable which is visible
outside of &lt;code&gt;SD&lt;/code&gt;, acting as a surrogate for the final result of
execution.
&lt;/p&gt;
    &lt;head rend="h4"&gt;The operator header&lt;/head&gt;
    &lt;p&gt;Operator bodies are defined just like functions'; what changes is the header, which must specify an operator.&lt;/p&gt;
    &lt;p&gt;Here is the header of a monadic operator:&lt;/p&gt;
    &lt;code&gt;∇R ← X (LOP OPERATE) Y
&lt;/code&gt;
    &lt;p&gt;And the header of a dyadic operator:&lt;/p&gt;
    &lt;code&gt;∇R ← X (LOP OPERATE ROP) Y
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;OPERATE&lt;/code&gt;is the operator name;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;R&lt;/code&gt;is the optional return variable;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;X&lt;/code&gt;and&lt;code&gt;Y&lt;/code&gt;are left and right parameters for the operator;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;LOP&lt;/code&gt;is an obligatory left operand, which the operator will change the behaviour of;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ROP&lt;/code&gt;is an optional right operand, which the operator will also change the behaviour of.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Local and global variables&lt;/head&gt;
    &lt;p&gt;One can quote variables in the header to make sure they are local to the function; by not doing so, they will remain global. Also notice that local variables are not shared with variables called inside the function body.&lt;/p&gt;
    &lt;p&gt; So let's fix &lt;code&gt;SD&lt;/code&gt;.
&lt;/p&gt;
    &lt;quote&gt;)CLEAR ⍝ Clear the workspace ∇R ← SD X;SUM;AVG;DIFF;SQDIFF;SQAVG SUM ← +/X AVG ← SUM÷⍴X DIFF ← AVG-X SQDIFF ← DIFF⋆2 SQAVG ← (+/SQDIFF)÷⍴SQDIFF R ← SQAVG⋆0.5 ∇&lt;/quote&gt;
    &lt;p&gt;But the header is so big, that's not good. Let's try making this a little more compact so we have fewer local variables.&lt;/p&gt;
    &lt;quote&gt;∇R ← SD X;SQDIFF SQDIFF ← (X-(+/X)÷⍴X)⋆2 R ← ((+/SQDIFF)÷⍴SQDIFF)⋆0.5 ∇&lt;/quote&gt;
    &lt;head rend="h4"&gt;Branching&lt;/head&gt;
    &lt;p&gt; Inside the body of a function or operator, the symbol Goto (&lt;code&gt;→)&lt;/code&gt; is used
to determine a jump. The symbol should then be followed by some data;
if the data is a scalar, the function jumps to the given line. If it
is a vector, the function jumps to the first element of the vector and
ignores the rest of it.
&lt;/p&gt;
    &lt;p&gt;Here is an example of that in action, with numbering on the body for better understanding.&lt;/p&gt;
    &lt;quote&gt;∇R←TEST X [1] →(X≥0)/4 [2] R←0 [3] →5 [4] R←1 ∇&lt;/quote&gt;
    &lt;p&gt; The function starts by testing whether &lt;code&gt;X&lt;/code&gt; is greater or equal to
zero. If so, the result is &lt;code&gt;1&lt;/code&gt;, therefore the Compress (&lt;code&gt;/&lt;/code&gt;) operator
selects the sole number at the right, which is &lt;code&gt;4&lt;/code&gt;. The &lt;code&gt;→&lt;/code&gt; symbol then
instructs the function to jump to the line – that is, the fourth one.
&lt;/p&gt;
    &lt;p&gt; Line &lt;code&gt;[2]&lt;/code&gt; puts a &lt;code&gt;0&lt;/code&gt; on the result variable. Then line &lt;code&gt;[3]&lt;/code&gt; instructs the
program to make an unconditional jump to the line &lt;code&gt;5&lt;/code&gt;, which does not
exist – thus ending the function.
&lt;/p&gt;
    &lt;p&gt; Line &lt;code&gt;[4]&lt;/code&gt; attributes the number &lt;code&gt;1&lt;/code&gt; to the result variable, and then
exits gracefully, as there are no more jumps.
&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Looping&lt;p&gt;One can also perform loops very easily by using the Goto symbol (&lt;/p&gt;&lt;code&gt;→&lt;/code&gt;). For example, consider the following function.&lt;quote&gt;⍝ Calculate factorial of a scalar N. ⍝ Has a return variable and a local scalar I. ∇R←FACTORIAL N;I →(N≤0)/0 ⍝ 1: If N is lower or eq to 0, end function I←1 ⍝ 2: Initialize iterator to 1 R←1 ⍝ 3: Initialize result to 1 R←R×I ⍝ 4: Let result be the mult. of result and iter →(I=N)/0 ⍝ 5: If iterator is equal to N, end function I←I+1 ⍝ 6: Increment iterator →4 ⍝ 7: Jump to multiplication ∇&lt;/quote&gt;&lt;p&gt;Jumping to&lt;/p&gt;&lt;code&gt;0&lt;/code&gt;will be explained below; it ends the function.&lt;/item&gt;
      &lt;item&gt;Labels&lt;p&gt;It is not necessary to count lines on most modern APLs. We can just use labels. This is also useful when adding lines and whatnot.&lt;/p&gt;&lt;quote&gt;∇R ← TEST X →(X≥0)/GREATEQ R←0 →0 GREATEQ: R←1 ∇&lt;/quote&gt;&lt;p&gt;Here is the factorial function, rewritten using labels:&lt;/p&gt;&lt;quote&gt;∇R←FACTORIAL N;I →(N≤0)/0 (I R)←1 ⍝ Multiple definition at once LOOP: R←R×I →(I=N)/0 I←I+1 →LOOP ∇&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Ending execution of a function&lt;p&gt;A function stops naturally when the last line of its body is executed. However, one can go to a line number which doesn't exist to end the function immediately. For example:&lt;/p&gt;&lt;quote&gt;→(X&amp;lt;1)/0 →0 →7 ⍝ Suppose this line is in a function with six lines&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Structured control keywords&lt;p&gt;Some APLs support structured-control keywords for flow control. This makes APL more readable. (GNU APL, however, does not support them)&lt;/p&gt;&lt;p&gt;Here is a table of keywords. These keywords are not part of the APL ISO, but they are supported in many implementations.&lt;/p&gt;&lt;th&gt;Function&lt;/th&gt;&lt;th&gt;Keyword&lt;/th&gt;&lt;td&gt;Conditional execution&lt;/td&gt;&lt;code&gt;:If&lt;/code&gt;,&lt;code&gt;:ElseIf&lt;/code&gt;,&lt;code&gt;:Else&lt;/code&gt;,&lt;code&gt;:EndIf&lt;/code&gt;&lt;td&gt;For loop&lt;/td&gt;&lt;code&gt;:For&lt;/code&gt;,&lt;code&gt;:EndFor&lt;/code&gt;&lt;td&gt;While loop&lt;/td&gt;&lt;code&gt;:While&lt;/code&gt;,&lt;code&gt;:EndWhile&lt;/code&gt;&lt;td&gt;Repeat loop&lt;/td&gt;&lt;code&gt;:Repeat&lt;/code&gt;,&lt;code&gt;:EndRepeat&lt;/code&gt;&lt;td&gt;Case selection&lt;/td&gt;&lt;code&gt;:Select&lt;/code&gt;,&lt;code&gt;:Case&lt;/code&gt;,&lt;code&gt;:CaseList&lt;/code&gt;,&lt;code&gt;:Else&lt;/code&gt;,&lt;code&gt;:EndSelect&lt;/code&gt;&lt;td&gt;Branch&lt;/td&gt;&lt;code&gt;:GoTo&lt;/code&gt;&lt;td&gt;Terminate function&lt;/td&gt;&lt;code&gt;:Return&lt;/code&gt;(same as&lt;code&gt;→0&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Comments in functions&lt;p&gt;Just use the Lamp (&lt;/p&gt;&lt;code&gt;⍝&lt;/code&gt;) symbol.&lt;/item&gt;
      &lt;item&gt;Ambivalent Functions&lt;p&gt;In APL2, dyadic functions may be used monodically. This happens when the left argument is undefined. This means that its Name Classification (&lt;/p&gt;&lt;code&gt;⎕NC&lt;/code&gt;) is&lt;code&gt;0&lt;/code&gt;. This can be compared:&lt;quote&gt;∇R←A AMBIVALENT B →(0=⎕NC 'A')/MONADIC →DYADIC MONADIC: A←5 DYADIC: R←A+B ∇ 1 AMBIVALENT 2 ⍝ Dyadic usage; yields 3 AMBIVALENT 2 ⍝ Monadic usage; yields 7&lt;/quote&gt;&lt;p&gt;Some APLs like NARS2000 and Dyalog use a particular syntax which distinguishes ambivalent and dyadic functions. See these function headers:&lt;/p&gt;&lt;quote&gt;∇R←A NOMADIC B ⍝ Dyadic ∇ ∇R←{A} NOMADIB B ⍝ Ambivalent ∇&lt;/quote&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Extra: Lambdas&lt;/head&gt;
    &lt;p&gt;GNU APL has limited support for lambda expressions. Those are functions which are defined inline, and can even be named.&lt;/p&gt;
    &lt;p&gt; In lambdas, Alpha (&lt;code&gt;⍺&lt;/code&gt;) is the symbol used for the left argument, and
Omega (&lt;code&gt;⍵&lt;/code&gt;) is the symbol used for the right argument. All lambdas are
one-line functions, enclosed in Curly Brackets (&lt;code&gt;{}&lt;/code&gt;), which can be
monadic or dyadic depending on argument usage, and their single line
always return a value.
&lt;/p&gt;
    &lt;quote&gt;AVERAGE ← {(+/⍵)÷⍴⍵} ⍝ Named lambda 2 {⍺+⍵} 3 ⍝ Unnamed lambda, applied immediately&lt;/quote&gt;
    &lt;p&gt; Here is an example lambda function which finds all the prime numbers below the second argument (&lt;code&gt;⍵&lt;/code&gt;) of the monadic function (ACHARYA and
PEREIRA):
&lt;/p&gt;
    &lt;quote&gt;PRIMES ← {(~⍵∊⍵∘.×⍵)/⍵←1↓⍳⍵} PRIMES 100&lt;/quote&gt;
    &lt;head rend="h3"&gt;Error Handling&lt;/head&gt;
    &lt;quote&gt;⍝ Error handling&lt;/quote&gt;
    &lt;head rend="h4"&gt;Errors in calculator mode&lt;/head&gt;
    &lt;p&gt; APL prints errors when you type a statement containing an error in calculator mode. For example, this yields a &lt;code&gt;DOMAIN ERROR&lt;/code&gt;:
&lt;/p&gt;
    &lt;quote&gt;1 1 0 'a'∨1 1 0 0&lt;/quote&gt;
    &lt;p&gt;To correct an error in calculator mode, simply retype the statement correctly, or use the the implementation's line-editing facilities.&lt;/p&gt;
    &lt;head rend="h4"&gt;Errors in user-defined functions or operators&lt;/head&gt;
    &lt;p&gt;When executing a user-defined function or operator, if an error happens, the execution stops at that point. Modern APLs have a Debug window where you can examine and correct errors in the function or operator.&lt;/p&gt;
    &lt;head rend="h4"&gt;The state indicator&lt;/head&gt;
    &lt;p&gt; When the halted function was called by other function, one can inspect the call stack using the State Indicator. This can be done with the system function &lt;code&gt;)SI&lt;/code&gt; or, in some APLs, by inspecting the variable &lt;code&gt;⎕SI&lt;/code&gt;.
&lt;/p&gt;
    &lt;p&gt;Here is an example taken from implementation APLX (deprecated):&lt;/p&gt;
    &lt;quote&gt;)SI C[2] * B[8] A[5]&lt;/quote&gt;
    &lt;p&gt; In the example above, the problem happened at function &lt;code&gt;C&lt;/code&gt;, at line
&lt;code&gt;2&lt;/code&gt;. This function was called by function &lt;code&gt;B&lt;/code&gt; at line &lt;code&gt;8&lt;/code&gt;, which was then
called by function &lt;code&gt;A&lt;/code&gt; on line &lt;code&gt;5&lt;/code&gt;.
&lt;/p&gt;
    &lt;p&gt; The asterisk means that the execution of line &lt;code&gt;2&lt;/code&gt; of function &lt;code&gt;C&lt;/code&gt; is still
pending. If another function were executed at this point and also
yielded an error, this would happen:
&lt;/p&gt;
    &lt;quote&gt;E[3] * D[6] C[2] * B[8] A[5]&lt;/quote&gt;
    &lt;p&gt; So now function &lt;code&gt;E&lt;/code&gt; at line &lt;code&gt;3&lt;/code&gt; is pendent, and was called from function &lt;code&gt;D&lt;/code&gt;
at line &lt;code&gt;6&lt;/code&gt;.
&lt;/p&gt;
    &lt;p&gt; This top level can be cleared by using the Goto symbol (&lt;code&gt;→&lt;/code&gt;). Another
&lt;code&gt;→&lt;/code&gt;, in this case, would clear the State Indicator completely.
&lt;/p&gt;
    &lt;quote&gt;→ )SI C[2] * B[8] A[5]&lt;/quote&gt;
    &lt;p&gt; There are also system functions to clear the State Indicator. In GNU APL, this can be done with &lt;code&gt;)RESET&lt;/code&gt;.
&lt;/p&gt;
    &lt;head rend="h4"&gt;Action after suspended execution&lt;/head&gt;
    &lt;p&gt; One can resume the suspended execution where it stopped. To do so, just type Goto (&lt;code&gt;→&lt;/code&gt;) followed by the line number.
&lt;/p&gt;
    &lt;quote&gt;→3 ⍝ Suppose execution halted at line 3 of the function&lt;/quote&gt;
    &lt;p&gt;It is not mandatory to continue execution where the function halted. For example, suppose you want to restart at the next line:&lt;/p&gt;
    &lt;code&gt;→4
&lt;/code&gt;
    &lt;p&gt; Another way to do this is by using the niladic system function &lt;code&gt;⎕LC&lt;/code&gt;. This yields a vector containing all current line numbers of
functions in the State Indicator. All we need to do is to jump to the
first number of such vector:
&lt;/p&gt;
    &lt;quote&gt;→⌷LC&lt;/quote&gt;
    &lt;p&gt;Or, if we want to resume at the next line, we can also exploit the vector:&lt;/p&gt;
    &lt;quote&gt;→1+⎕LC&lt;/quote&gt;
    &lt;head rend="h4"&gt;Error trapping and tracing&lt;/head&gt;
    &lt;p&gt;It is possible to specify in advance what to do if an error occurs on execution; APL allows error trapping at runtime.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Dyalog has the keywords &lt;code&gt;:Trap&lt;/code&gt;,&lt;code&gt;:EndTrap&lt;/code&gt;,&lt;code&gt;:Case&lt;/code&gt;and&lt;code&gt;:Else&lt;/code&gt;, and the system variable&lt;code&gt;⎕TRAP&lt;/code&gt;which allows precise control;&lt;/item&gt;
      &lt;item&gt;APL2 has the system variables &lt;code&gt;⎕EA&lt;/code&gt;(Execute Alternate; executes the right argument and, if it fails, executes the left one) and&lt;code&gt;⌷EC&lt;/code&gt;(Execute Controlled; Executes the argument and returns the result, if any. Also returns additional information on errors).&lt;/item&gt;
      &lt;item&gt;APL+Win has the keywords &lt;code&gt;:Try&lt;/code&gt;,&lt;code&gt;:Catch&lt;/code&gt;and&lt;code&gt;:Finally&lt;/code&gt;; and the&lt;code&gt;⎕ELX&lt;/code&gt;system variable executes the argument passed on its right, whenever an error occurs.&lt;/item&gt;
      &lt;item&gt;NARS2000 has &lt;code&gt;⎕ELX&lt;/code&gt;like APL+Win, and&lt;code&gt;⎕EA&lt;/code&gt;and&lt;code&gt;⌷EC&lt;/code&gt;, like APL2.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It seems like GNU APL does not have error trapping facilities.&lt;/p&gt;
    &lt;head rend="h3"&gt;Formatting&lt;/head&gt;
    &lt;quote&gt;⍝ Formatting&lt;/quote&gt;
    &lt;head rend="h4"&gt;The "Format" primitive&lt;/head&gt;
    &lt;p&gt; Useful variable: &lt;code&gt;⎕PP&lt;/code&gt; (Print Precision).
&lt;/p&gt;
    &lt;p&gt;When the left argument is not specified, the data is converted into plain text with no specific format, using only display defaults.&lt;/p&gt;
    &lt;quote&gt;⍕ 0.0000003 3.0123456789&lt;/quote&gt;
    &lt;p&gt;With two arguments, the left argument is always a list of two elements: Field width and number of decimal places.&lt;/p&gt;
    &lt;quote&gt;6 2⍕341.82921&lt;/quote&gt;
    &lt;p&gt;Note that, before the number was truncated, it was rounded.&lt;/p&gt;
    &lt;head rend="h4"&gt;The system function &lt;code&gt;⎕FMT&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt; Some APL implementations (except APL2 and GNU APL) have a &lt;code&gt;⎕FMT&lt;/code&gt; system
function:
&lt;/p&gt;
    &lt;quote&gt;'B K2 G&amp;lt; ZZ9 DOLLARS AND 99 CENTS&amp;gt;' ⎕FMT 8.23 12.86 0 2.52 8 DOLLARS AND 23 CENTS 12 DOLLARS AND 86 CENTS 2 DOLLARS AND 52 CENTS&lt;/quote&gt;
    &lt;head rend="h3"&gt;End of Tutorial&lt;/head&gt;
    &lt;quote&gt;)CLEAR&lt;/quote&gt;
    &lt;head rend="h2"&gt;Further Topics in APL&lt;/head&gt;
    &lt;p&gt;These are very useful topics which I will only take some notes on new things I find interesting. Here is the link to the relevant contents.&lt;/p&gt;
    &lt;p&gt;It is also useful to check the GNU APL Manual&lt;/p&gt;
    &lt;head rend="h3"&gt;Displaying the Shape of an Array&lt;/head&gt;
    &lt;quote&gt;⍝⍝⍝ Further Topics in APL ⍝ Displaying the shape of an array&lt;/quote&gt;
    &lt;p&gt; Most APLS have a &lt;code&gt;DISPLAY&lt;/code&gt; or &lt;code&gt;⎕DISPLAY&lt;/code&gt; system function to draw boxes
around data. GNU APL uses &lt;code&gt;⎕CR&lt;/code&gt; for that. For example:
&lt;/p&gt;
    &lt;quote&gt;8⎕CR 3 4⍴12?50 8⎕CR 1 (⍳2) 3 4 5 8⎕CR 1 'A' (2 3) (2 5⍴'HELLOWORLD')&lt;/quote&gt;
    &lt;p&gt;Results are better seen with GNU FreeFont:&lt;/p&gt;
    &lt;quote&gt;┌→──────────┐ ↓40 26 30 24│ │50 35 31 47│ │43 45 38 11│ └───────────┘ ┌→────────────┐ │1 ┌→──┐ 3 4 5│ │ │1 2│ │ │ └───┘ │ └∊────────────┘ ┌→────────────────┐ │1 A ┌→──┐ ┌→────┐│ │ │2 3│ ↓HELLO││ │ └───┘ │WORLD││ │ └─────┘│ └∊────────────────┘&lt;/quote&gt;
    &lt;p&gt;Meaning of symbols used when drawing boxes:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Sym&lt;/cell&gt;
        &lt;cell role="head"&gt;Placement&lt;/cell&gt;
        &lt;cell role="head"&gt;Meaning&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;Beneath character&lt;/cell&gt;
        &lt;cell&gt;Scalar character&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;→&lt;/cell&gt;
        &lt;cell&gt;Left of top edge&lt;/cell&gt;
        &lt;cell&gt;Vector or higher-rank array&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;~&lt;/cell&gt;
        &lt;cell&gt;Left of bottom edge&lt;/cell&gt;
        &lt;cell&gt;Numeric data&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;+&lt;/cell&gt;
        &lt;cell&gt;Left of bottom edge&lt;/cell&gt;
        &lt;cell&gt;Mixed data&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;⊖&lt;/cell&gt;
        &lt;cell&gt;Left of top edge&lt;/cell&gt;
        &lt;cell&gt;Empty vector or higher-rank array&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;↓&lt;/cell&gt;
        &lt;cell&gt;Left side of box&lt;/cell&gt;
        &lt;cell&gt;Matrix or higher-rank array&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;⌽&lt;/cell&gt;
        &lt;cell&gt;Left side of box&lt;/cell&gt;
        &lt;cell&gt;Empty matrix or higher-rank array&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;∊&lt;/cell&gt;
        &lt;cell&gt;Left of bottom edge&lt;/cell&gt;
        &lt;cell&gt;Nested array&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Array Type and Prototype&lt;/head&gt;
    &lt;quote&gt;⍝ Array type and prototype&lt;/quote&gt;
    &lt;p&gt; Arrays of one or more dimensions of zero length are known as empty array, which can be generated with Reshape (&lt;code&gt;⍴&lt;/code&gt;) or a selection of sorts
(like with Compress, &lt;code&gt;/&lt;/code&gt;). Its type can be numeric, simple character or
nested, depending on how it was created.
&lt;/p&gt;
    &lt;p&gt; Empty arrays are useful for initializing arrays where data will be added in the future, for creating scalars from arrays or as argument to Goto (&lt;code&gt;→&lt;/code&gt;).
&lt;/p&gt;
    &lt;head rend="h4"&gt;Array Type and Prototype&lt;/head&gt;
    &lt;p&gt;Arrays have a type zero for numeric elements, and blank character for character elements.&lt;/p&gt;
    &lt;quote&gt;⍝ Empty numeric vector and empty character vector 8⎕CR ⍳0 ◊ 8⎕CR '' ⍝ Same thing, but using ⍴ 8⎕CR 0⍴676 ◊ 8⎕CR 0⍴'PETER'&lt;/quote&gt;
    &lt;quote&gt;┌⊖┐ │0│ └─┘ ┌⊖┐ │ │ └─┘&lt;/quote&gt;
    &lt;p&gt; Empty numeric vectors can also be created using Zilde (&lt;code&gt;⍬&lt;/code&gt;).
&lt;/p&gt;
    &lt;quote&gt;X←⍬ ⍴X X≡0⍴0 8⎕CR ⍬&lt;/quote&gt;
    &lt;quote&gt;0 1 ┌⊖┐ │0│ └─┘&lt;/quote&gt;
    &lt;head rend="h4"&gt;Prototypes of nested arrays&lt;/head&gt;
    &lt;p&gt;Complex empty arrays can be created by using a nested array to generate the empty array:&lt;/p&gt;
    &lt;quote&gt;⍝ A nested array containing a list of characters ⍝ and a list of numbers; the second statement ⍝ is an empty nested array containing another ⍝ empty array. 8⎕CR 'ABC' (⍳3) ◊ 8⎕CR 0⍴'ABC' (⍳3)&lt;/quote&gt;
    &lt;quote&gt;┌→────────────┐ │┌→──┐ ┌→────┐│ ││ABC│ │1 2 3││ │└───┘ └─────┘│ └∊────────────┘ ┌⊖────┐ │┌→──┐│ ││ ││ │└───┘│ └∊────┘&lt;/quote&gt;
    &lt;p&gt;When the first element is numeric, we end up with a nested array of null elements.&lt;/p&gt;
    &lt;quote&gt;8⎕CR (2 2⍴⍳4) 'ABC' ◊ 8⎕CR 0⍴(2 2⍴⍳4) 'ABC'&lt;/quote&gt;
    &lt;quote&gt;┌→──────────┐ │┌→──┐ ┌→──┐│ │↓1 2│ │ABC││ ││3 4│ └───┘│ │└───┘ │ └∊──────────┘ ┌⊖────┐ │┌→──┐│ │↓0 0││ ││0 0││ │└───┘│ └∊────┘&lt;/quote&gt;
    &lt;p&gt;If the first element is mixed, then we'll have an array filled with zeroes and empty characters.&lt;/p&gt;
    &lt;quote&gt;8⎕CR (2 2⍴1 'K' 2 'J') (⍳4) ◊ 8⎕CR 0⍴(2 2⍴1 'K' 2 'J') (⍳4)&lt;/quote&gt;
    &lt;quote&gt;┌→──────────────┐ │┌→──┐ ┌→──────┐│ │↓1 K│ │1 2 3 4││ ││2 J│ └───────┘│ │└───┘ │ └∊──────────────┘ ┌⊖────┐ │┌→──┐│ │↓0 ││ ││0 ││ │└───┘│ └∊────┘&lt;/quote&gt;
    &lt;p&gt;Therefore, the prototype concept can be used to display the type of an array.&lt;/p&gt;
    &lt;quote&gt;8⎕CR VAR ← (2 2⍴1 'A' 'B' 2) ((⍳2) 7) 'ABC'&lt;/quote&gt;
    &lt;quote&gt;┌→────────────────────┐ │┌→──┐ ┌→──────┐ ┌→──┐│ │↓1 A│ │┌→──┐ 7│ │ABC││ ││B 2│ ││1 2│ │ └───┘│ │└───┘ │└───┘ │ │ │ └∊──────┘ │ └∊∊───────────────────┘&lt;/quote&gt;
    &lt;p&gt; To display the array type, we first enclose (&lt;code&gt;⊂&lt;/code&gt;) the array to make it a
scalar, then we build the empty vector with it (&lt;code&gt;0⍴&lt;/code&gt;). Since building
the empty vector creates an additional level of nesting, we use the
First (&lt;code&gt;↑&lt;/code&gt;) function to remove it:
&lt;/p&gt;
    &lt;quote&gt;8⎕CR ↑0⍴⊂VAR&lt;/quote&gt;
    &lt;quote&gt;┌→────────────────────┐ │┌→──┐ ┌→──────┐ ┌→──┐│ │↓0 │ │┌→──┐ 0│ │ ││ ││ 0│ ││0 0│ │ └───┘│ │└───┘ │└───┘ │ │ │ └∊──────┘ │ └∊∊───────────────────┘&lt;/quote&gt;
    &lt;head rend="h4"&gt;The prototype as a fill element&lt;/head&gt;
    &lt;p&gt; Functions such as Take (&lt;code&gt;↑&lt;/code&gt;), Expand (&lt;code&gt;\&lt;/code&gt;) and Replicate (&lt;code&gt;/&lt;/code&gt;) add elements
to an existing array. A prototype can be used to determine the type
and shape of extra elements.
&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Type of array&lt;/cell&gt;
        &lt;cell role="head"&gt;Fill Element&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Numeric&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Character&lt;/cell&gt;
        &lt;cell&gt;Space&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Nested/Mixed&lt;/cell&gt;
        &lt;cell&gt;Prototype of first element, with&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Numbers/Characters replaced&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;accordingly&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Here are some examples.&lt;/p&gt;
    &lt;quote&gt;8⎕CR 5↑1 2 3 ◊ 8⎕CR 5↑'ABC' ⍝ Numeric and textual vectors of 5 elts 8⎕CR 2↑0⍴⊂VAR ⍝ Vector containing two prototypes 8⎕CR 2↑⊂VAR ⍝ Put VAR's prototype after VAR, in a vector 8⎕CR ¯2↑⊂VAR ⍝ Put VAR's prototype before VAR, in a vector&lt;/quote&gt;
    &lt;quote&gt;┌→────────┐ │1 2 3 0 0│ └─────────┘ ┌→────┐ │ABC │ └─────┘ ┌→──────────────────────────────────────────────┐ │┌→────────────────────┐ ┌→────────────────────┐│ ││┌→──┐ ┌→──────┐ ┌→──┐│ │┌→──┐ ┌→──────┐ ┌→──┐││ ││↓0 │ │┌→──┐ 0│ │ ││ │↓0 │ │┌→──┐ 0│ │ │││ │││ 0│ ││0 0│ │ └───┘│ ││ 0│ ││0 0│ │ └───┘││ ││└───┘ │└───┘ │ │ │└───┘ │└───┘ │ ││ ││ └∊──────┘ │ │ └∊──────┘ ││ │└∊∊───────────────────┘ └∊∊───────────────────┘│ └∊∊∊────────────────────────────────────────────┘ ┌→──────────────────────────────────────────────┐ │┌→────────────────────┐ ┌→────────────────────┐│ ││┌→──┐ ┌→──────┐ ┌→──┐│ │┌→──┐ ┌→──────┐ ┌→──┐││ ││↓1 A│ │┌→──┐ 7│ │ABC││ │↓0 │ │┌→──┐ 0│ │ │││ │││B 2│ ││1 2│ │ └───┘│ ││ 0│ ││0 0│ │ └───┘││ ││└───┘ │└───┘ │ │ │└───┘ │└───┘ │ ││ ││ └∊──────┘ │ │ └∊──────┘ ││ │└∊∊───────────────────┘ └∊∊───────────────────┘│ └∊∊∊────────────────────────────────────────────┘ ┌→──────────────────────────────────────────────┐ │┌→────────────────────┐ ┌→────────────────────┐│ ││┌→──┐ ┌→──────┐ ┌→──┐│ │┌→──┐ ┌→──────┐ ┌→──┐││ ││↓0 │ │┌→──┐ 0│ │ ││ │↓1 A│ │┌→──┐ 7│ │ABC│││ │││ 0│ ││0 0│ │ └───┘│ ││B 2│ ││1 2│ │ └───┘││ ││└───┘ │└───┘ │ │ │└───┘ │└───┘ │ ││ ││ └∊──────┘ │ │ └∊──────┘ ││ │└∊∊───────────────────┘ └∊∊───────────────────┘│ └∊∊∊────────────────────────────────────────────┘&lt;/quote&gt;
    &lt;p&gt;More info: Empty Arrays and Prototypes&lt;/p&gt;
    &lt;head rend="h3"&gt;Vector Notation&lt;/head&gt;
    &lt;p&gt;Nothing new here. Just pay attention to how the vectors are constructed:&lt;/p&gt;
    &lt;quote&gt;8⎕CR 'ABC' 'DEF' 8⎕CR (1 2 3) 'DEF' ⍴1 2 3 'DEF' ⍴1 2 3 'D' 'E' 'F' 8⎕CR ((1 2) (3 4)) 2 3 X←2 2⍴⍳4 Y←'HELLO' 8⎕CR (X Y) ⍝ Variables entered in vector form ⍴X Y&lt;/quote&gt;
    &lt;quote&gt;8⎕CR 'ABC' 'DEF' ┌→──────────┐ │┌→──┐ ┌→──┐│ ││ABC│ │DEF││ │└───┘ └───┘│ └∊──────────┘ 8⎕CR ((1 2 3) 'DEF') ┌→────────────┐ │┌→────┐ ┌→──┐│ ││1 2 3│ │DEF││ │└─────┘ └───┘│ └∊────────────┘ ⍴1 2 3 'DEF' 4 ⍴1 2 3 'D' 'E' 'F' 6 8⎕CR ((1 2) (3 4)) 2 3 ┌→────────────────┐ │┌→──────────┐ 2 3│ ││┌→──┐ ┌→──┐│ │ │││1 2│ │3 4││ │ ││└───┘ └───┘│ │ │└∊──────────┘ │ └∊∊───────────────┘ X←2 2⍴⍳4 Y←'HELLO' 8⎕CR (X Y) ⍝ Variables entered in vector form ┌→────────────┐ │┌→──┐ ┌→────┐│ │↓1 2│ │HELLO││ ││3 4│ └─────┘│ │└───┘ │ └∊────────────┘ ⍴X Y 2&lt;/quote&gt;
    &lt;head rend="h3"&gt;Variables and Indexing&lt;/head&gt;
    &lt;p&gt;Nothing new too.&lt;/p&gt;
    &lt;quote&gt;LIST←12 24 36 48 LIST[2] LIST[1]+LIST[4] ALF←'ABCDEFGHIJKLMNOPQRSTUVWXYZ' ALF[26 1 13 2 9 1] TABLE←10×2 4⍴⍳8 TABLE[1;4] TABLE[1;⍳4]+TABLE[2;⍳4] TABLE[1;]+TABLE[2;] (⍴TABLE[1;2 3])=(⍴1),⍴2 3 ALF[2 2⍴⍳4] ⍴TABLE[1;] ⍝ Rows indexed by scalar, result is vector ⍴TABLE[,1;] ⍝ Rows indexed by vector, result is matrix ⍴TABLE[1 1⍴1;] ⍝ Rows indexed by matrix, result is cube&lt;/quote&gt;
    &lt;head rend="h4"&gt;The Index (&lt;code&gt;⌷&lt;/code&gt;) function&lt;/head&gt;
    &lt;quote&gt;TABLE[1;2]=1 2⌷TABLE 2⌷⍳5 (⊂3 4)⌷⍳5 ⍝ Use a nested scalar for multiple index. TAB←2 5⍴⍳10 8⎕CR TAB 2 3⌷TAB 2 (2 3)⌷TAB ⍝ 2nd element of indexing vec is an enclosed vec ⍝ Nested 2-elts vector for multiple indexes. ⍝ Result is a submatrix of TAB located at ⍝ rows 1 2, columns 2 3. (1 2) (2 3)⌷TAB ⍝ An empty left argument is OK for index when ⍝ a scalar is the right argument. This returns ⍝ the scalar itself. (⍳0)⌷37&lt;/quote&gt;
    &lt;head rend="h3"&gt;Multiple Specification&lt;/head&gt;
    &lt;p&gt;Nothing new here as well.&lt;/p&gt;
    &lt;quote&gt;(A B C)←1 2 3 A ◊ B ◊ C (A B C)←5 A ◊ B ◊ C (A B C)←'HI' 'THERE' 'FOLKS' ⍴A ⍝ See that A received 'HI' only (A B C)←⊂'HI' 'THERE' 'FOLKS' ⍴A ⍝ All three variables received a vec of the three char vecs 8⎕CR A&lt;/quote&gt;
    &lt;head rend="h3"&gt;Selective Specification&lt;/head&gt;
    &lt;p&gt;Some functions in APL can be used to select portions of an array. When associated with assignment, they can be used to assign values to portions of such array.&lt;/p&gt;
    &lt;p&gt;Bracket indexing is the easiest example.&lt;/p&gt;
    &lt;quote&gt;TAB←2 3⍴⍳6 TAB[2;1]←8&lt;/quote&gt;
    &lt;p&gt; Let's assign the first three elements of a vector by using the Take (dyadic &lt;code&gt;↑&lt;/code&gt;) function.
&lt;/p&gt;
    &lt;quote&gt;VEC←⍳5 (3↑VEC)←'ABC' 8⎕CR VEC&lt;/quote&gt;
    &lt;quote&gt;┌→──────┐ │ABC 4 5│ └───────┘&lt;/quote&gt;
    &lt;p&gt; Let's use the Ravel (monadic &lt;code&gt;,&lt;/code&gt;) on a matrix to assign a new vector
value to it:
&lt;/p&gt;
    &lt;quote&gt;MAT←3 4⍴'ABCDEFGHIJKL' (,MAT)←'NEW DATAHERE' ⍝ Ravelled matrix appears as a vector 8⎕CR MAT ⍝ Assignment occurs in matrix itself&lt;/quote&gt;
    &lt;quote&gt;┌→───┐ ↓NEW │ │DATA│ │HERE│ └────┘&lt;/quote&gt;
    &lt;p&gt; Now let's combine Compression (dyadic &lt;code&gt;/&lt;/code&gt;) and Ravel (monadic &lt;code&gt;,&lt;/code&gt;) to
select all A's on the matrix, and replace them by asterisk:
&lt;/p&gt;
    &lt;quote&gt;(('A'=,MAT)/,MAT)←'*' 8⎕CR MAT&lt;/quote&gt;
    &lt;quote&gt;┌→───┐ ↓NEW │ │D*T*│ │HERE│ └────┘&lt;/quote&gt;
    &lt;p&gt; We can also combine Take (dyadic &lt;code&gt;↑&lt;/code&gt;) and Ravel (monadic &lt;code&gt;,&lt;/code&gt;) to replace
elements at the top-left 2×2 submatrix of &lt;code&gt;MAT&lt;/code&gt;:
&lt;/p&gt;
    &lt;quote&gt;(,2 2↑MAT)←'⎕⎕⎕⎕' 8⎕CR MAT&lt;/quote&gt;
    &lt;quote&gt;┌→───┐ ↓⎕⎕W │ │⎕⎕T*│ │HERE│ └────┘&lt;/quote&gt;
    &lt;p&gt; We can also use the Compression (&lt;code&gt;/&lt;/code&gt;) function for selection.
&lt;/p&gt;
    &lt;quote&gt;TABLE←3 4⍴⍳12 8⎕CR TABLE (1 0 1 0/TABLE)←3 2⍴100 8⎕CR TABLE&lt;/quote&gt;
    &lt;quote&gt;┌→─────────┐ ↓1 2 3 4│ │5 6 7 8│ │9 10 11 12│ └──────────┘ ┌→────────────┐ ↓100 2 100 4│ │100 6 100 8│ │100 10 100 12│ └─────────────┘&lt;/quote&gt;
    &lt;p&gt; In the next example, we have a vector &lt;code&gt;X&lt;/code&gt;. We want to replace the first
&lt;code&gt;⍴X&lt;/code&gt; elements of &lt;code&gt;DATA&lt;/code&gt; with the contents of &lt;code&gt;X&lt;/code&gt;.
&lt;/p&gt;
    &lt;quote&gt;DATA←⍳13 X←10×⍳3 8⎕CR DATA ((⍴X)↑DATA)←X 8⎕CR DATA&lt;/quote&gt;
    &lt;quote&gt;┌→────────────────────────────┐ │1 2 3 4 5 6 7 8 9 10 11 12 13│ └─────────────────────────────┘ ┌→───────────────────────────────┐ │10 20 30 4 5 6 7 8 9 10 11 12 13│ └────────────────────────────────┘&lt;/quote&gt;
    &lt;p&gt; Replace the first &lt;code&gt;X+2&lt;/code&gt; elements of &lt;code&gt;Y&lt;/code&gt; with the reverse of a vector
containing numbers &lt;code&gt;1&lt;/code&gt; up to &lt;code&gt;X+2:&lt;/code&gt;
&lt;/p&gt;
    &lt;quote&gt;Y←⍳10 X←3 8⎕CR Y ((2+X)↑Y)←⌽⍳X+2 8⎕CR Y&lt;/quote&gt;
    &lt;quote&gt;┌→───────────────────┐ │1 2 3 4 5 6 7 8 9 10│ └────────────────────┘ ┌→───────────────────┐ │5 4 3 2 1 6 7 8 9 10│ └────────────────────┘&lt;/quote&gt;
    &lt;p&gt; We can use Enlist (monadic &lt;code&gt;∊&lt;/code&gt;) to remove nesting from an array.
&lt;/p&gt;
    &lt;quote&gt;8⎕CR NEST←(2 2⍴⍳4) 'TEXT' (3 1⍴⍳3) (∊NEST)←0 8⎕CR NEST ⍝ Set specific position to number (6⌷∊NEST)←999 8⎕CR NEST ⍝ Set specific position to character vector (text). ⍝ For that, introduce extra nesting to the new text. (7⌷∊NEST)←⊂'TEXT' 8⎕CR NEST&lt;/quote&gt;
    &lt;quote&gt;┌→───────────────┐ │┌→──┐ ┌→───┐ ┌→┐│ │↓1 2│ │TEXT│ ↓1││ ││3 4│ └────┘ │2││ │└───┘ │3││ │ └─┘│ └∊───────────────┘ ┌→──────────────────┐ │┌→──┐ ┌→──────┐ ┌→┐│ │↓0 0│ │0 0 0 0│ ↓0││ ││0 0│ └───────┘ │0││ │└───┘ │0││ │ └─┘│ └∊──────────────────┘ ┌→────────────────────┐ │┌→──┐ ┌→────────┐ ┌→┐│ │↓0 0│ │0 999 0 0│ ↓0││ ││0 0│ └─────────┘ │0││ │└───┘ │0││ │ └─┘│ └∊────────────────────┘ ┌→─────────────────────────┐ │┌→──┐ ┌→─────────────┐ ┌→┐│ │↓0 0│ │0 999 ┌→───┐ 0│ ↓0││ ││0 0│ │ │TEXT│ │ │0││ │└───┘ │ └────┘ │ │0││ │ └∊─────────────┘ └─┘│ └∊∊────────────────────────┘&lt;/quote&gt;
    &lt;p&gt; The function First (monadic &lt;code&gt;↑&lt;/code&gt;) selects the first element of an
array. Here, we shall replace the first 2×2 matrix of &lt;code&gt;NEST&lt;/code&gt; by a
character vector.
&lt;/p&gt;
    &lt;quote&gt;(↑NEST)←'ABC' 8⎕CR NEST&lt;/quote&gt;
    &lt;p&gt;So, the sky is the limit. For more info, see this page.&lt;/p&gt;
    &lt;head rend="h3"&gt;Binding Strengths&lt;/head&gt;
    &lt;p&gt;In general, APL evaluates from right to left. However, some elements can be said to have stronger binding.&lt;/p&gt;
    &lt;p&gt;Here is a descending list of binding strength.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Binding&lt;/cell&gt;
        &lt;cell role="head"&gt;Bound items&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Brackets &lt;code&gt;[]&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Brackets to object to the left&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Specification &lt;code&gt;←&lt;/code&gt; left&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;←&lt;/code&gt; to object on its left&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Right operand&lt;/cell&gt;
        &lt;cell&gt;Dyadic operator to its right operand&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Vector&lt;/cell&gt;
        &lt;cell&gt;Array to array&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Left operand&lt;/cell&gt;
        &lt;cell&gt;Operator to its left operand&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Left argument&lt;/cell&gt;
        &lt;cell&gt;Function to left argument&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Right argument&lt;/cell&gt;
        &lt;cell&gt;Function to right argument&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Specification &lt;code&gt;←&lt;/code&gt; right&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;←&lt;/code&gt; to object on its right&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;And parentheses can override the binding strength hierarchy.&lt;/p&gt;
    &lt;p&gt;For more info, see this page.&lt;/p&gt;
    &lt;head rend="h3"&gt;Pervasive Functions&lt;/head&gt;
    &lt;p&gt;There are Scalar and Mixed functions in APL. Scalar functions have the property of being pervasive, that is, they apply to all levels of nesting on the data.&lt;/p&gt;
    &lt;p&gt;Here are some scalar functions:&lt;/p&gt;
    &lt;quote&gt;+ - × ÷ | ⌈ ⌊ * ⍟ ○ ! ^ ∨ ⍲ ⍱ &amp;lt; ≤ = ≥ &amp;gt; ≠ Monadic ~ Monadic ?&lt;/quote&gt;
    &lt;p&gt;For more info, see this page.&lt;/p&gt;
    &lt;head rend="h3"&gt;OO, Classes and Inheritance&lt;/head&gt;
    &lt;p&gt;GNU APL does not support object orientation, therefore I will not be covering it. However, Dyalog APL does.&lt;/p&gt;
    &lt;p&gt;Object-oriented APL information can be found on this page.&lt;/p&gt;
    &lt;head rend="h2"&gt;Finishing&lt;/head&gt;
    &lt;quote&gt;⍝ Closes the script file. )OFF&lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45706755</guid><pubDate>Sat, 25 Oct 2025 20:34:37 +0000</pubDate></item><item><title>Project Amplify: Powered footwear for running and walking</title><link>https://about.nike.com/en/newsroom/releases/nike-project-amplify-official-images</link><description>&lt;doc fingerprint="d7d28bb7ec6b46bc"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Nike is unveiling Project Amplify: the world’s first powered footwear system for running and walking, designed to help everyday athletes go a little bit faster and farther — all with less effort.&lt;/p&gt;
      &lt;p&gt;Engineered to augment natural lower leg and ankle movement, the Project Amplify system breaks the perception of possibility by providing an unparalleled boost to anyone who wants to move, creating a new future for running, jogging and walking. &lt;/p&gt;
      &lt;p&gt;Built on motion algorithms informed by the Nike Sport Research Lab, the first-generation footwear system is comprised of a lightweight, powerful motor; drive belt; and rechargeable cuff battery that seamlessly integrate with a carbon fiber–plated running shoe that can be worn with or without the robotics system.&lt;/p&gt;
      &lt;p&gt;This makes it easier for everyday athletes to walk or run more often, for longer amounts of time, while having more fun — adding movement to their lives, extending their walking commute, or helping them to enjoy the run for another mile or two. &lt;/p&gt;
      &lt;p&gt;Each application reflects Nike’s unmatched commitment to solving problems for athletes, improving their experience and powering the future of sport. What’s more: Project Amplify represents one of four major technological advances Nike is unveiling this month, joining innovations across Air apparel, advanced cooling, and mind science in demonstrating the depth, breadth and impact of the brand’s commitment to athlete-centered innovation. &lt;/p&gt;
      &lt;p&gt;“Our job is to dream big while keeping athletes at the center,” says Michael Donaghu, VP of Create The Future, Emerging Sport and Innovation. “Project Amplify started with a single question: What if we could find a way to help athletes move faster and farther with less energy and a lot more fun? At its core, Project Amplify is about seamlessly adding a little more power to your stride. The fun comes from realizing you can do more than you thought you could — whatever ‘more’ means to you.”&lt;/p&gt;
      &lt;p&gt;Akin to how electric bikes have made it easier to ride farther and more frequently, revolutionizing urban commuting, Nike is developing Project Amplify to make slower running, jogging and walking easier and more fun, with a focus on athletes running between a 10- and 12-minute mile pace. &lt;/p&gt;
      &lt;p&gt;The first-generation product, created alongside robotics partner Dephy, isn’t designed for competitive, faster runners trying to shave seconds off their time; rather, it’s intended to serve athletes who want to go faster and farther with less effort by giving them more power for everyday movement — in effect, a second set of calf muscles.&lt;/p&gt;
      &lt;p&gt;That approach is backed by insights developed from NSRL testing involving athletes of all abilities and intensities, who have shared that the system feels like it’s part of their body and that it makes walking or running uphill feel like moving on flat ground. For some, wearing Project Amplify helps them go from a 12-minute mile to a 10-minute mile.&lt;/p&gt;
      &lt;p&gt;These learnings are the product of extensive testing over several years, both in outdoor environments and the NSRL. More than 400 athletes have covered over 2.4 million steps, the equivalent of roughly 12,000 laps around the NSRL’s 200-meter track, in more than nine different versions of the hardware — each iteration focused on refining a different element of the system. &lt;/p&gt;
      &lt;p&gt;“Is this new for Nike? Yes and no,” says Donaghu. “It’s obviously a new innovation, but the day Bill Bowerman poured rubber into the family waffle iron was the start of a journey to augment movement and create the future of sport. We’ve always believed movement is medicine, and Project Amplify is the next chapter in that story. It’s a bold leap forward, crossing a new threshold of putting power directly into your stride.”&lt;/p&gt;
      &lt;p&gt;With Project Amplify still in the testing stage, Nike is blending art and science to reach performance readiness and bring the footwear system to a broad consumer launch in the coming years. &lt;/p&gt;
      &lt;p&gt;* If you have a body, you are an athlete.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45706765</guid><pubDate>Sat, 25 Oct 2025 20:35:48 +0000</pubDate></item><item><title>Show HN: Diagram as code tool with draggable customizations</title><link>https://github.com/RohanAdwankar/oxdraw</link><description>&lt;doc fingerprint="2e583e5e3b2d53b2"&gt;
  &lt;main&gt;
    &lt;head class="px-3 py-2"&gt;oxdraw_demo.mov&lt;/head&gt;
    &lt;p&gt;The goal of &lt;code&gt;oxdraw&lt;/code&gt; is to make it easy to create and maintain high-quality diagrams using a declarative and reproducible syntax.
Charts are written in Mermaid syntax, while a web interface allows users to fine-tune positions connector paths, colors, and other styling components. Whenever a diagram is tweaked visually, the structural changes are persisted back to the source file as declarative code so that everything remains deterministic and versionable.
The changes are saved as comments in the mermaid file so it remains compatible with other Mermaid tools.
The repo is composed of the Rust CLI to compile &lt;code&gt;.mmd&lt;/code&gt; files into images and the React based web interface to editing the files.&lt;/p&gt;
    &lt;p&gt;The reason I started this project was I used Mermaid a lot in the past when making architecture diagrams or trying to understand large codebases through having AI tools generate .mmd files to visualize them. However what typically happened was since these diagrams couldn't be edited minutely for example cleaning up joints and chart organization, I would have to move over the diagrams I started to things like Lucidchart. So the big picture goal of this project is to unite the benefits of code generated diagramming like Mermaid with the customizability of diagram software like Lucidchart.&lt;/p&gt;
    &lt;code&gt;cargo install oxdraw&lt;/code&gt;
    &lt;code&gt;oxdraw --input flow.mmd  &lt;/code&gt;
    &lt;code&gt;oxdraw --input flow.mmd --edit&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Flag&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;-i, --input &amp;lt;PATH&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Read a Mermaid source file; pass &lt;code&gt;-&lt;/code&gt; to consume stdin instead.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;-o, --output &amp;lt;PATH&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Write the rendered asset to a specific path; pass &lt;code&gt;-&lt;/code&gt; to stream SVG to stdout. Defaults to &lt;code&gt;&amp;lt;input&amp;gt;.svg&lt;/code&gt; (or &lt;code&gt;&amp;lt;input&amp;gt;.&amp;lt;format&amp;gt;&lt;/code&gt; if an explicit format is chosen) and &lt;code&gt;out.svg&lt;/code&gt; when reading from stdin.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;--png&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Shorthand for &lt;code&gt;--output-format png&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;--scale &amp;lt;FACTOR&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Scale multiplier for PNG rasterization (default &lt;code&gt;10.0&lt;/code&gt;); values must be greater than zero. Ignored for SVG output.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;--edit&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Launch the interactive editor pointing at the supplied diagram instead of emitting an asset once.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;--serve-host &amp;lt;ADDR&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Override the bind address used while &lt;code&gt;--edit&lt;/code&gt; is active (default &lt;code&gt;127.0.0.1&lt;/code&gt;).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;--serve-port &amp;lt;PORT&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Override the HTTP port while &lt;code&gt;--edit&lt;/code&gt; is active (default &lt;code&gt;5151&lt;/code&gt;).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;-b, --background-color &amp;lt;COLOR&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Background fill passed to the renderer (currently SVG only). Applies to both one-off renders and the editor preview.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;-q, --quiet&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Suppress informational stdout such as the success message after rendering to disk.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Control&lt;/cell&gt;
        &lt;cell role="head"&gt;What it does&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Delete selected&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Removes the currently selected node or edge; available via the Delete/Backspace keys as well.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Node Fill/Stroke/Text pickers&lt;/cell&gt;
        &lt;cell&gt;Apply per-node color overrides; double-clicking a node clears its override.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Reset node style&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Remove all color overrides for the selected node.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Edge Color picker&lt;/cell&gt;
        &lt;cell&gt;Override the selected edge stroke color.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Edge Line selector&lt;/cell&gt;
        &lt;cell&gt;Toggle between solid and dashed stroke styles.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Edge Arrow selector&lt;/cell&gt;
        &lt;cell&gt;Choose arrow directions (forward/backward/both/none).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Add control point&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Insert a new draggable waypoint on the selected edge to fine-tune routing.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;Reset edge style&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Drop edge-specific styling and revert to defaults; double-clicking an edge handle also clears its manual path.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Canvas and editor interactions&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Drag nodes to update their stored positions with grid snapping and live alignment guides; Shift+Arrow nudges the selection in grid-sized jumps.&lt;/item&gt;
      &lt;item&gt;Drag edge handles (or the label handle) to reshape routes; double-click an edge to insert a handle and double-click a handle to remove overrides.&lt;/item&gt;
      &lt;item&gt;Drag an entire subgraph container to move all of its member nodes (and any edge overrides) together while maintaining separation from sibling groups.&lt;/item&gt;
      &lt;item&gt;The source panel mirrors the Mermaid file, auto-saves after short idle periods, and surfaces pending/saving/error states alongside the current selection.&lt;/item&gt;
      &lt;item&gt;Status text in the top toolbar signals loading, saving, and the currently edited file path.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head class="px-3 py-2"&gt;path_algo.mov&lt;/head&gt;
    &lt;p&gt;The path drawing algorithm is fun because there is a lot of ambiguity with what optimal behavior could be. Some prefer smooth lines because there is less total line but I prefer strong edges to make the diagram a bit more clear. Some prefer no overlapping lines but I sometimes prefer an overlap rather than letting the lines get super long and string out of the diagram very far. This is an example of using the delete key to remove one relationship and then using the arrow keys to move around one the nodes and seeing how the algorithm recomputes the positioning. There's definitely some improvements to be made to this algorithm so I imagine this will keep getting better :)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45706792</guid><pubDate>Sat, 25 Oct 2025 20:38:58 +0000</pubDate></item><item><title>ARM Memory Tagging: how it improves C/C++ memory safety (2018) [pdf]</title><link>https://llvm.org/devmtg/2018-10/slides/Serebryany-Stepanov-Tsyrklevich-Memory-Tagging-Slides-LLVM-2018.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45706815</guid><pubDate>Sat, 25 Oct 2025 20:42:02 +0000</pubDate></item><item><title>An Update on TinyKVM</title><link>https://fwsgonzo.medium.com/an-update-on-tinykvm-7a38518e57e9</link><description>&lt;doc fingerprint="343ac81d7d099be9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;An update on TinyKVM&lt;/head&gt;
    &lt;p&gt;Hey all. TinyKVM was open-sourced this february and since then I’ve been working on some things that are very much outside of the scope of the original implementation. Originally, it was intended to be for pure computation (and that is very much still possible, and is the default), but makes it hard to use TinyKVM outside of specialized use-cases. So, I’ve relented and implemented limited support for running unmodified executables in TinyKVM. Specifically, run-times like Deno, Python WSGI and similar run-times like Lune.&lt;/p&gt;
    &lt;p&gt;I would like to make a special shout-out to Laurence Rowe who championed KVM server, which has now become almost a de-facto CLI for TinyKVM servers. It’s very much work in progress, but give it a try if you’re interested in these kinds of things.&lt;/p&gt;
    &lt;p&gt;In order to achieve this I picked the very untraditional route of implementing system call emulation, but as poorly as possible. And as few system calls as possible. I think today there is 50 real system calls (gVisor has ~200 for comparison), and all of them will to some degree make shit up (for lack of a better term). The goal is to avoid accessing the (shared) Linux kernel when at all possible, but give sanitized access when permitted and appropriate. To give an example of what I mean by this: The only allowed ioctl operations are setting and getting non-blocking mode (FIONBIO), and reading the number of available bytes (FIONREAD). This minimalist system call API is currently able to run quite a few complex run-times unmodified. Programs are surprisingly good at handling failing system calls, or suspicious return values. If you put a jailer on top it should be good enough for production, but I do still recommend to use TinyKVM in pure compute mode. Something like Jailer + TinyKVM + Deno + per request isolation.&lt;/p&gt;
    &lt;head rend="h3"&gt;Per-Request Isolation&lt;/head&gt;
    &lt;p&gt;Per-request isolation is apparently not that common. I could not find any other production-level support other than in wasmtime (and previously Lucet). But, due to its lack of in-guest JIT support it will not be able to compete with Deno so I will just focus on the positives: It uses a clever lazy MADV_DONTNEED mechanism which delays the cost. You can go test wasmtime’s per-request isolation right now with the hello-wasi-http example.&lt;/p&gt;
    &lt;p&gt;In TinyKVM there are two reset modes, which together forms hybrid per-request isolation that is capable of maintaining a low memory footprint. Together, it makes the fastest per-request isolation that exists right now. It’s main mode will directly rewrite all touched pages in a VM fork back to their original contents and then leave pagetables (and TLBs) intact. This mode has turned out to be the fastest, but as it leaves the memory footprint untouched it can only grow memory usage for forked VMs. Forked VMs are tiny to begin with, but for large page rendering work it may be a concern, hence there’s a second mode triggered by a fork using memory above a limit. The second mode resets the entire VM with pagetables and everything, which happens when it uses working memory above a certain limit or an exception occurs during request handling. It’s not particularly expensive on its own, but if every VM fork would do it all the time the IPIs and coherency chatter would be a bottleneck.&lt;/p&gt;
    &lt;p&gt;So we ran a full Deno page rendering benchmark in TinyKVM and then also the very same (unmodified) benchmark natively. We made GC single-threaded in order to compare equally. It would normally run async in another thread, but you’d still have to pay the cost of doing it. What we found was that TinyKVM generally had lower p90+ latency, while native had better p50.&lt;/p&gt;
    &lt;p&gt;Now this is incredible. Per-request isolation is very very expensive. We are resetting an entire KVM VM every request back to its original state. And we’re doing it very close to native not doing it at all. We’re doing it with unmodified Deno, a big run-time, and with a full page rendering benchmark, a large piece of compute work that builds real memory pressure.&lt;/p&gt;
    &lt;head rend="h3"&gt;A new type of remote procedure call&lt;/head&gt;
    &lt;p&gt;One of the things not on my 2025 bingo card was creating a custom RPC mechanism. And, it’s not that great outside of its specific use-case.&lt;/p&gt;
    &lt;p&gt;I figured that if you loaded two binaries into the same address space, couldn’t you just call a function in the other just fine? Turns out yes, especially if you trap on the far jump (not a real far jump) and then switch a few important registers like the thread-pointer (FSBASE). So, if you have to ABI- or FFI-compatible programs you can essentially freely call functions in the other. Now, this sounds dangerous for sandboxing and kinda useless if you can just use a super-fast IPC like iceoryx2, but.. it turns out that super-fast IPC requires the other end to be always scheduled and crucially also requires that caller to not be adversarial and trample shared memory while you’re reading it. If both of those things are true, then go ahead and use fast IPC. Being able to directly call a remote party without depending on the scheduler it turns out is really really performant. A simple schbench benchmark will tell you all you need to know about what happens when the scheduler is busy. You can go do it on your own machine. It’s commonly a 2-digit number of milliseconds you can expect for p99. So, this new method is in fact the new king of this specific type of RPC. The only remaining part then is how do you deal with sandbox integrity? Turns out you can just not have the remote part mapped in at all, and then either:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Directly resume the remote VM with your caller VMs address space already mapped in. This means that the remote VM is “higher privileged”, sort of.&lt;/item&gt;
      &lt;item&gt;Map in the remote VM just-in-time on the execution page fault, execute the remote function call, unmap it on return (or any exception, timeout). This also means the remote VM is “higher privileged”.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So, what is this then? Are these two programs the same tenant? What does this have to do with per-request isolation?&lt;/p&gt;
    &lt;p&gt;Per-request isolation doesn’t have persistence. The entire request VM gets wiped on every request. It would be great if we could maintain something under certain conditions. So, then either it would have to make an expensive call out to a remote service (ala Binder on Android). Or, we could solve two problems in one: Allow tenants to have a program that is persistent, and give them direct scheduler-free access to it. That is, the persistent program would inform the system which functions are callable, so you can’t just randomly jump to remote memory, but you can jump to any registered address directly, which immediately executes the remote function call. Example:&lt;/p&gt;
    &lt;code&gt;static void my_backend(const char*, const char*)&lt;lb/&gt;{&lt;lb/&gt;   alignas(64) char buffer[256];&lt;lb/&gt;   sys_storage_resume(buffer, sizeof(buffer));&lt;lb/&gt;   const char ctype[] = "text/plain";&lt;lb/&gt;   backend_response(200, ctype, sizeof(ctype)-1,&lt;lb/&gt;       buffer, __builtin_strlen(buffer));&lt;lb/&gt;}&lt;/code&gt;
    &lt;p&gt;Here’s a simple C++ request handler. Instead of jumping directly to a remote VM function, we choose to directly resume the remote VM, as it is running a complex run-time. Deno in fact.&lt;/p&gt;
    &lt;code&gt;while (true) {&lt;lb/&gt;  // Wait for a UInt8Array buffer from C&lt;lb/&gt;  const bufptr = drogon.symbols.wait_for_storage_task_paused();&lt;lb/&gt;  // View it as a Uint8Array of length 256&lt;lb/&gt;  const arrayBuffer = Deno.UnsafePointerView.getArrayBuffer(bufptr, 256);&lt;lb/&gt;  const buffer = new Uint8Array(arrayBuffer);&lt;lb/&gt;&lt;lb/&gt;  const redis_answer = await redisClient.get("test");&lt;lb/&gt;  // Copy redis_answer to buffer&lt;lb/&gt;  const response = "Hello from Deno storage inside TinyKVM, redis answer: " + redis_answer;&lt;lb/&gt;  ...&lt;lb/&gt;}&lt;/code&gt;
    &lt;p&gt;What’s omitted is encoding the answer back into the buffer zero-terminated. But maybe you got the gist of it: The buffer is zero-copy and we write directly into it. The only remaining thing to do after writing to the buffer is to go back to waiting.&lt;/p&gt;
    &lt;p&gt;While everything is zero-copy, you will have to duplicate anything that you want to persist. You can use allocators to allocate for the caller.&lt;/p&gt;
    &lt;p&gt;This feature currently executes safely on the order of 2 microseconds wherever I’ve benchmarked it.&lt;/p&gt;
    &lt;p&gt;Concurrent access to the remote is possible with an idea I’ve had in my head for a while: Create N threads in the remote VM and register them for use by callers. However, for now I am currently using serialized access to the remote VM. It’s also possible to fork it into many copies to avoid serializing access but that only helps you in certain cases like connection pooling to a database. That is of course supported already. If you want a single-source-of-truth then you probably also want to serialize access to the remote.&lt;/p&gt;
    &lt;p&gt;During remote calls the caller VM has to be paused. There’s no way around it, otherwise it can trample memory used by the remote VM and crash it. While zero-copy IPC exists where both can run at the same time, it’s fundamentally a question of trust and integrity. You simply can’t do that with two separate sandboxes talking to each other.&lt;/p&gt;
    &lt;p&gt;Anyway. I hope that was an introduction to the concept, at least. It’s not your everyday feature. It likely won’t solve your problems. I just think it’s a really cool idea. And I do use it, of course. For limited persistence with per-request isolation.&lt;/p&gt;
    &lt;head rend="h3"&gt;VM snapshots&lt;/head&gt;
    &lt;p&gt;The last topic of this post is VM snapshots. A feature that many have asked about for TinyKVM. Wouldn’t it be nice if you could snapshot a VM, transport it somewhere else, and resume it? Well, now you can. The feature is implemented by backing all of physical memory with a single file, and then adding some VM state on top and a user-provided section at the very end. This combines all state into a single file with holes.&lt;/p&gt;
    &lt;p&gt;For reference, a Deno JS hello world instance is 192MiB RSS after initializing the first time. If you save that state into a snapshot and resume it, the file is 135MiB on disk (2.4GiB logical), and RSS is 50MiB after starting with 32 VM forks.&lt;/p&gt;
    &lt;code&gt;$ du -h program/deno/deno.mem&lt;lb/&gt;135M program/deno/deno.mem&lt;/code&gt;
    &lt;p&gt;The startup time is 0.7ms with everything in page cache. Clearing the page cache is not a simple matter as you have to clear any caching on the disk as well. This typically means you’ll need a custom device. I don’t have all the answers right now, but I suspect it will be around 20ms to load the program from disk with everything cold.&lt;/p&gt;
    &lt;p&gt;We’re currently working on recording the actually accessed pages of a request and only preloading those. Combined with a full clear of all relevant caches we hope to see that it loads faster than any other alternatives in this space. Fast cold start is of course a crowded space, but you never know what you will find until you try. Because we will be able to know more or less the exact pages that are going to be used by the next request, we might be able to populate just the right pages and avoid loading pages that aren’t going to be used. Typically Linux will load ranges of pages optimistically based on faults. Avoiding that can save some time. We are also hosting just a single process. It’s just Deno, and nothing else. Of course, requests differ, but they should have many things in common.&lt;/p&gt;
    &lt;p&gt;I think I will end this post here. This is as far as I’ve gotten. Thanks for reading!&lt;/p&gt;
    &lt;p&gt;-gonzo&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45706866</guid><pubDate>Sat, 25 Oct 2025 20:51:16 +0000</pubDate></item><item><title>An Efficient Implementation of Self, a Dynamically-Typed Object-Oriented Langua [pdf]</title><link>https://courses.cs.washington.edu/courses/cse501/15sp/papers/chambers.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45706924</guid><pubDate>Sat, 25 Oct 2025 21:01:02 +0000</pubDate></item><item><title>How programs get run: ELF binaries</title><link>https://lwn.net/Articles/631631/</link><description>&lt;doc fingerprint="aba31895a40737c8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How programs get run: ELF binaries&lt;/head&gt;
    &lt;quote&gt;Benefits for LWN subscribers&lt;p&gt;The primary benefit from subscribing to LWN is helping to keep us publishing, but, beyond that, subscribers get immediate access to all site content and access to a number of extra site features. Please sign up today!&lt;/p&gt;&lt;/quote&gt;
    &lt;p&gt;The previous article in this series described the general mechanisms that the Linux kernel has for executing programs as a result of a user-space call to execve(). However, the particular format handlers described in that article each deferred the process of execution to an inner call to search_binary_handler(). That recursion almost always ends with the invocation of an ELF binary program, which is the subject of this article.&lt;/p&gt;
    &lt;head rend="h4"&gt;The ELF format&lt;/head&gt;
    &lt;p&gt;The ELF (Executable and Linkable Format) format is the main binary format in use on modern Linux systems, and support for it is implemented in the file fs/binfmt_elf.c. It's also a slightly complicated format for the kernel to handle; the main load_elf_binary() function spans over 400 lines, and the ELF support code is more than four times as big as the code that supports the old a.out format.&lt;/p&gt;
    &lt;p&gt;An ELF file for an executable program (rather than a shared library or an object file) must always contain a program header table near the start of the file, after the ELF header; each entry in this table provides information that is needed to run the program.&lt;/p&gt;
    &lt;p&gt;The kernel only really cares about three types of program header entries. The first type is the PT_LOAD segment, which describes areas of the new program's running memory. This includes code and data sections that come from the executable file, together with the size of a BSS section. The BSS will be filled with zeroes (thus only its length needs to be stored in the executable file). The second entry of interest is a PT_INTERP entry, which identifies the run-time linker needed to assemble the complete program; for the time being, we'll assume a statically linked ELF binary and return to dynamic linking later. Finally, the kernel also gets a single bit of information from a PT_GNU_STACK entry, if present, which indicates whether the program's stack should be made executable or not.&lt;/p&gt;
    &lt;p&gt;(This article only focuses on what's needed to load an ELF program, rather than exploring all of the details of the format. The interested reader can find much more information via the references linked from Wikipedia's ELF article or by exploring real binaries with the objdump tool.)&lt;/p&gt;
    &lt;head rend="h4"&gt;Processing ELF binaries&lt;/head&gt;
    &lt;p&gt;Loading an ELF binary is handled by the load_elf_binary() function, which starts by examining the ELF header to check that the file in question does indeed look like a supported ELF format. The handler needs the whole of the ELF program header, whether it is within the first 128 bytes read into buf in linux_binprm or not, so it needs to read it into some scratch space.&lt;/p&gt;
    &lt;p&gt;The code now loops over the program header entries, checking for an interpreter (PT_INTERP) and whether the program's stack should be executable (from the PT_GNU_STACK entry). With this preparation done, the code needs to initialize those attributes of the new program that are not inherited from the old program; the Single UNIX Specification version 3 (SUSv3) exec specification describes most of the required behavior (and table 28-4 of The Linux Programming Interface gives an excellent summary of the attributes involved).&lt;/p&gt;
    &lt;p&gt;The process of setting up the new program starts with a call to flush_old_exec(), which clears up state in the kernel that refers to the previous program. Any other threads of the old program are killed so the new program starts with a single thread, and the signal-handling information for the process is unshared so that it can be safely altered later. Any pending POSIX timers for the old program are cleared, and the location of the executable file for the program (visible at /proc/pid/exe) is updated. The virtual memory mappings for the old program are released, which also kills any pending asynchronous I/O operations and frees any uprobes. Finally, the personality of the process is updated to remove any features that could affect security, as previously recorded in the per_clear field in linux_binprm. The main handler code also calls the SET_PERSONALITY() macro to set the thread flags appropriately for a new 64-bit program.&lt;/p&gt;
    &lt;p&gt;A corresponding call to setup_new_exec() now sets up the kernel's internal state for the new program. This function starts by determining whether the new program can generate a core dump (or have ptrace() attach to it); this is disabled by default for setuid or setgid programs. Dumping is also disabled when the program file isn't readable under the current credentials. A call to __set_task_comm() sets the current task's comm field to the basename of the originally invoked filename; this value is used as a thread name, and is accessible to user space via the PR_GET_NAME and PR_SET_NAME prctl() operations. A call to flush_signal_handlers() sets up the signal handlers for the new program; any signal handler that's not SIG_IGN gets set to the default SIG_DFL value (so any ignored signals are inherited by the new program). Finally, a call to do_close_on_exec() closes all of the old program's file descriptors that have the O_CLOEXEC flag set; other file descriptors will be inherited by the new program.&lt;/p&gt;
    &lt;p&gt;The virtual memory for the new program also needs to be set up. To improve security (by helping protect against stack overflow attacks), the highest address for the stack is typically moved downward by a random offset. An initial call to setup_arg_pages() then sets up the kernel's memory tracking structures, and adjusts for the new location of the stack. The code loops through all of the PT_LOAD segments in the program file and maps them into the process's address space, setting up the new program's memory layout. It then sets up zero-filled pages that correspond to the program's BSS segment. Also, additional special pages — such as the virtual dynamic shared object (vDSO) pages — need to be mapped, which is taken care of by a call to arch_setup_additional_pages(). An empty page may also be mapped at the zero address in the program's address space for backward-compatibility reasons (old SVr4 programs apparently assume that reading from a NULL pointer would return zeros rather than SIGSEGV).&lt;/p&gt;
    &lt;p&gt;Next, the credentials for the new program are set up via a call to install_exec_creds(). This function lets any active Linux Security Module (LSM) know about the change in credentials (through the bprm_committing_creds and bprm_committed_creds LSM hooks), and the inner commit_creds() function performs the assignment.&lt;/p&gt;
    &lt;p&gt;The final preparation for running the new program is to set up the rest of its stack (in its new randomized location), by calling the create_elf_tables() function; this is described in a separate section below.&lt;/p&gt;
    &lt;p&gt;All of the preparation has now been done, and the new program can be launched. An earlier article explained how the kernel's system_call entry point pushes the user-space CPU registers to the kernel stack before entering the main kernel code, and these registers are correspondingly restored when the system call completes. The area of the stack that holds the saved registers is cast to a pt_regs structure, and the saved user-space CPU registers can thus be overwritten with suitable values (zeroes) for the start of the new program. The call to the start_thread() function also sets the saved instruction pointer to the entry point of the program (or the dynamic linker), and the saved stack pointer to the current top of the stack (from the p field in linux_binprm). The zero return code from the handler indicates success, and the execve() syscall returns to user space — but to a completely different user space, where the process's memory has been remapped, and the restored registers have values that start the execution of the new program.&lt;/p&gt;
    &lt;head rend="h4"&gt;Populating the stack: the auxiliary vector, environment and arguments&lt;/head&gt;
    &lt;p&gt;The create_elf_tables() function adds more information to the new program's stack, below the argument and environment information added by the generic code, as two distinct chunks. An initial call to arch_align_stack() rounds down the existing stack position to a 16-byte boundary, and may also further randomize the stack position downward slightly.&lt;/p&gt;
    &lt;p&gt;The first collection of information forms the ELF auxiliary vector, a collection of (id, value) pairs that describe useful information about the program being run and the environment it is running in, communicated from the kernel to user space. To build this vector, the handler code first needs to push onto the stack any information that doesn't fit within a 64-bit value; for x86_64 this is a platform capability description (the string "x86_64") and 16 bytes of random data (to help seed user-space random number generators).&lt;/p&gt;
    &lt;p&gt;Next, the code assembles the (id, value) pairs for the auxiliary vector in the saved_auxv space within the mm_struct. An LWN article from Michael Kerrisk describes the contents of this vector, so here we just mention a few interesting entries:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The (architecture-specific) first entry in the vector is the AT_SYSINFO_EHDR value for x86_64; this indicates the location of the vDSO page, as referenced in an earlier article.&lt;/item&gt;
      &lt;item&gt;The AT_PLATFORM value is the location of the "x86_64" platform capability description pushed earlier.&lt;/item&gt;
      &lt;item&gt;The AT_RANDOM value is the location of the random data pushed earlier.&lt;/item&gt;
      &lt;item&gt;The AT_EXECFN value holds the location of the program filename that was pushed as the very first thing on the stack (and whose location was stored in the exec field of linux_binprm), above the arguments and environment values.&lt;/item&gt;
      &lt;item&gt;The AT_ENTRY value holds the entry point for the text segment, i.e. where program execution should start.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Once this auxiliary vector is created, the code now assembles the rest of the new program's stack. The required space is calculated, and then the entries are inserted from low addresses to higher ones:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The argc argument count is inserted first.&lt;/item&gt;
      &lt;item&gt;An array of argument pointers is inserted next, ending with a NULL pointer. This is where main()'s argv will eventually point.&lt;/item&gt;
      &lt;item&gt;An array of environment pointers is inserted next, ending with a NULL pointer. This is where environ will point.&lt;/item&gt;
      &lt;item&gt;The auxiliary vector is put at the highest address, just below the additional values it references.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Taken together, the top of the new program's address space will have contents like the following example (this page has a similar example):&lt;/p&gt;
    &lt;quote&gt;------------------------------------------------------------- 0x7fff6c845000 0x7fff6c844ff8: 0x0000000000000000 _ 4fec: './stackdump\0' &amp;lt;------+ env / 4fe2: 'ENVVAR2=2\0' | &amp;lt;----+ \_ 4fd8: 'ENVVAR1=1\0' | &amp;lt;---+ | / 4fd4: 'two\0' | | | &amp;lt;----+ args | 4fd0: 'one\0' | | | &amp;lt;---+ | \_ 4fcb: 'zero\0' | | | &amp;lt;--+ | | 3020: random gap padded to 16B boundary | | | | | | - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -| | | | | | 3019: 'x86_64\0' &amp;lt;-+ | | | | | | auxv 3009: random data: ed99b6...2adcc7 | &amp;lt;-+ | | | | | | data 3000: zero padding to align stack | | | | | | | | . . . . . . . . . . . . . . . . . . . . . . . . . . .|. .|. .| | | | | | 2ff0: AT_NULL(0)=0 | | | | | | | | 2fe0: AT_PLATFORM(15)=0x7fff6c843019 --+ | | | | | | | 2fd0: AT_EXECFN(31)=0x7fff6c844fec ------|---+ | | | | | 2fc0: AT_RANDOM(25)=0x7fff6c843009 ------+ | | | | | ELF 2fb0: AT_SECURE(23)=0 | | | | | auxiliary 2fa0: AT_EGID(14)=1000 | | | | | vector: 2f90: AT_GID(13)=1000 | | | | | (id,val) 2f80: AT_EUID(12)=1000 | | | | | pairs 2f70: AT_UID(11)=1000 | | | | | 2f60: AT_ENTRY(9)=0x4010c0 | | | | | 2f50: AT_FLAGS(8)=0 | | | | | 2f40: AT_BASE(7)=0x7ff6c1122000 | | | | | 2f30: AT_PHNUM(5)=9 | | | | | 2f20: AT_PHENT(4)=56 | | | | | 2f10: AT_PHDR(3)=0x400040 | | | | | 2f00: AT_CLKTCK(17)=100 | | | | | 2ef0: AT_PAGESZ(6)=4096 | | | | | 2ee0: AT_HWCAP(16)=0xbfebfbff | | | | | 2ed0: AT_SYSINFO_EHDR(33)=0x7fff6c86b000 | | | | | . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . | | | | | 2ec8: environ[2]=(nil) | | | | | 2ec0: environ[1]=0x7fff6c844fe2 ------------------|-+ | | | 2eb8: environ[0]=0x7fff6c844fd8 ------------------+ | | | 2eb0: argv[3]=(nil) | | | 2ea8: argv[2]=0x7fff6c844fd4 ---------------------------|-|-+ 2ea0: argv[1]=0x7fff6c844fd0 ---------------------------|-+ 2e98: argv[0]=0x7fff6c844fcb ---------------------------+ 0x7fff6c842e90: argc=3&lt;/quote&gt;
    &lt;p&gt;Note that although there are two randomizations in the stack layout (the position of the top of memory and the size of the gap between the argument values and the auxiliary vector), the newly running program can still figure out where all of the information on the stack is. The SP register tells the program where the top of the stack is (i.e. the lowest address), and the command-line arguments are arranged upwards in memory from there, with a NULL pointer to mark where they end. The environment values are found next, again with a NULL pointer to terminate, and the auxiliary vector is found at the next consecutive addresses, closing with an AT_NULL ID. The values found within all of this information give the addresses of the argument strings, environment strings, and auxiliary data values, so no explicit information about the size of the random gap is needed.&lt;/p&gt;
    &lt;head rend="h4"&gt;Dynamically linked programs&lt;/head&gt;
    &lt;p&gt;So far we've assumed the program being executed is statically linked and skipped over steps that would be triggered by the presence of a PT_INTERP entry in the ELF program header. However, most programs are dynamically linked, meaning that required shared libraries have to be located and linked at run-time. This is performed by the runtime linker (typically something like /lib64/ld-linux-x86-64.so.2), and the identity of this linker is specified by the PT_INTERP program header entry.&lt;/p&gt;
    &lt;p&gt;To cope with a runtime linker, the ELF handler first reads the ELF interpreter file name into scratch space, then opens the executable file with open_exec(). The first 128 bytes of the file are read into the bprm-&amp;gt;buf scratch area, replacing the contents of the original program file and allowing access to the ELF header of the interpreter program — which must therefore be an ELF binary itself, rather than any other format.&lt;/p&gt;
    &lt;p&gt;After the program code has been loaded into memory as described previously, the ELF handler also loads the ELF interpreter program into memory with load_elf_interp(). This process is similar to the process of loading the original program: the code checks the format information in the ELF header, reads in the ELF program header, maps all of the PT_LOAD segments from the file into the new program's memory, and leaves room for the interpreter's BSS segment.&lt;/p&gt;
    &lt;p&gt;The execution start address for the program is also set to be the entry point of the interpreter, rather than that of the program itself. When the execve() system call completes, execution then begins with the ELF interpreter, which takes care of satisfying the linkage requirements of the program from user space — finding and loading the shared libraries that the program depends on, and resolving the program's undefined symbols to the correct definitions in those libraries. Once this linkage process is done (which relies on a much deeper understanding of the ELF format than the kernel has), the interpreter can start the execution of the new program itself, at the address previously recorded in the AT_ENTRY auxiliary value.&lt;/p&gt;
    &lt;head rend="h4"&gt;Compatibility with other architectures&lt;/head&gt;
    &lt;p&gt;As described previously, a modern 64-bit (x86_64) Linux system can also support running 32-bit binaries of two types: normal 32-bit binaries (x86_32), and x32 ABI programs (which can make use of additional x86_64 registers). So how does the kernel support these binaries?&lt;/p&gt;
    &lt;p&gt;The key file that provides support for these formats is compat_binfmt_elf.c, which is included in the kernel when the CONFIG_COMPAT_BINFMT_ELF config option is set. This file didn't appear in our earlier list of places that register binary handlers, because the file contains almost no code of its own. Instead, it includes the main binfmt_elf.c ELF handler code (using #include), and uses the preprocessor to redirect various internal functions and values to 32-bit compatibility versions. Other than these changes, the format handler therefore behaves the same as the normal ELF handler described above.&lt;/p&gt;
    &lt;p&gt;One set of changes uses 32-bit versions of the structures describing the layout of the ELF file; similarly, the appropriate constant values for 32-bit binaries are used, which ensures that the compatibility handler only claims support for the relevant ELF binary types. In particular, the elf_check_arch() call is replaced with a compat_elf_check_arch() version that checks for either x86_32 or (if configured) x32.&lt;/p&gt;
    &lt;p&gt;The preprocessor changes also redirect some of the inner functionality of the ELF handler code. The invocation of the SET_PERSONALITY() macro is redirected to set_personality_ia32() so that the relevant thread flags for the 32-bit architecture are set and, similarly, the arch_setup_additional_pages() function is replaced with a version that sets up a 32-bit vDSO. More significantly, the start_thread() function is replaced with compat_start_thread(), which maps to start_thread_ia32(). This alters the arguments to the inner start_thread_common() function so that the saved segment registers are initialized differently than for x86_64 binaries (and the ELF_PLAT_INIT() macro is also adjusted to match).&lt;/p&gt;
    &lt;head rend="h4"&gt;Epilogue&lt;/head&gt;
    &lt;p&gt;Every program that runs on a Linux system passes through the portal of execve(); as such it's a key piece of kernel functionality that's worth understanding in detail. Although the kernel natively supports script and other machine-code format programs, program execution on a modern Linux system eventually involves running an ELF binary. ELF is a complicated format, but fortunately the kernel can ignore most of that complexity — it only needs to understand just enough ELF to load segments into memory, and to invoke a user space run-time linker program to finish the job of assembling a complete running program.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Index entries for this article&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Kernel&lt;/cell&gt;
        &lt;cell&gt;exec()&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;GuestArticles&lt;/cell&gt;
        &lt;cell&gt;Drysdale, David&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt; Posted Feb 5, 2015 19:24 UTC (Thu) by Tara_Li (guest, #26706) [Link] (4 responses) http://www.muppetlabs.com/~breadbox/software/tiny/teensy.... The creation of a 45 byte ELF executable - admitted, all it does is return 42, but it *does* execute. Posted Feb 6, 2015 2:14 UTC (Fri) by vonbrand (subscriber, #4458) [Link] That one contains a nice discussion of checks that aren't made when launching an executable... any possible screwups by not checking? Posted Feb 6, 2015 13:34 UTC (Fri) by jzbiciak (guest, #5246) [Link] That was a fun read. :-) Posted Feb 7, 2015 14:05 UTC (Sat) by felixfix (subscriber, #242) [Link] (1 responses) Posted Feb 16, 2015 16:04 UTC (Mon) by bokr (guest, #58369) [Link] http://en.wikipedia.org/wiki/LGP-30 Likewise, the RPC-4000 was manufactured by Librascope, Posted Feb 7, 2015 4:01 UTC (Sat) by felixfix (subscriber, #242) [Link] (2 responses) Then I learned machine language for it, and delighted in knowing that 11 was add, 12 was subtract, while 21 was add immediate and 22 was subtract immediate (just reaching; those may not be correct!). My teacher and I began a contest to see who could get the most interesting program on a single 80 column card. I think he gave up when I got 120 digits of instruction with various nefarious overlaps. The program printed out THIMK over and over on the console typewriter. One sense switch would bypass a delay loop; a second halted the program. It couldn't print THINK because that M was the halt instruction. I think I learned for more about useful programming in that summer than any class since. Posted Feb 7, 2015 13:18 UTC (Sat) by vonbrand (subscriber, #4458) [Link] I remember the IBM 1620 had no proper FORTRAN II, but some cut-down dialect called PDQ FORTRAN. Posted Sep 8, 2018 2:23 UTC (Sat) by Since1969 (guest, #127103) [Link] 1* were the immediate instructions; 2* were the "storage-to-storage" ones. My first program was computing Hero's Formula using "FORTRAN with Format". Later we got Load and Go FORTRAN, which saved a lot of trees. But after a few FORTRAN programs, I learned SPS (assembler). One of the coolest tricks was coding loops of different lengths which produced tones in various pitches in a nearby FM radio. Great machine. Posted Feb 8, 2015 18:50 UTC (Sun) by kleptog (subscriber, #1183) [Link] Posted Feb 12, 2015 16:52 UTC (Thu) by nye (subscriber, #51576) [Link] (1 responses) I have an instinctive reaction that this sort of behaviour should have to be explicitly enabled via sysctl or something - it seems to violate the principle of least astonishment in a way that could have surprising implications, including security ones. Am I way off base here? Certainly I am working from a position of abject ignorance. Posted Feb 12, 2015 17:20 UTC (Thu) by drysdale (guest, #95971) [Link] Posted Feb 16, 2015 17:26 UTC (Mon) by nix (subscriber, #2304) [Link] &lt;head&gt;How programs get run: ELF binaries&lt;/head&gt;&lt;head&gt;How programs get run: ELF binaries&lt;/head&gt;&lt;head&gt;How programs get run: ELF binaries&lt;/head&gt;&lt;head/&gt; There's also The Story of Mel. &lt;head&gt;How programs get run: ELF binaries&lt;/head&gt;&lt;head&gt;LGP-30&lt;/head&gt;&lt;lb/&gt; deserves more credit than "The Story of Mel" gives.&lt;lb/&gt; which had become a division of General Precision by then, IIRC.&lt;lb/&gt; (I started work at Librascope Sept '59, and those were the&lt;lb/&gt; computers I cut my teeth on. It's been interesting -- and still is ;-)&lt;head&gt;How programs get run: ELF binaries&lt;/head&gt;&lt;head&gt;How programs get run: ELF binaries&lt;/head&gt;&lt;head&gt;How programs get run: ELF binaries&lt;/head&gt;&lt;head&gt;How programs get run: ELF binaries&lt;/head&gt;&lt;head&gt;How programs get run: ELF binaries&lt;/head&gt;&lt;lb/&gt; &amp;gt;space for backward-compatibility reasons (old SVr4 programs apparently assume&lt;lb/&gt; &amp;gt;that reading from a NULL pointer would return zeros rather than SIGSEGV).&lt;head/&gt; That behaviour does need to be explicitly enabled via the personality() syscall; of the pre-defined personality values, only PER_SRV4 and PER_UW7 set the MMAP_PAGE_ZERO bit that controls this behaviour. (The bit is also explicitly cleared when running a setuid/setgid binary.) &lt;head&gt;How programs get run: ELF binaries&lt;/head&gt;&lt;head&gt;How programs get run: ELF binaries&lt;/head&gt;&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45706938</guid><pubDate>Sat, 25 Oct 2025 21:03:39 +0000</pubDate></item></channel></rss>