<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 03 Feb 2026 14:37:59 +0000</lastBuildDate><item><title>Todd C. Miller – Sudo maintainer for over 30 years</title><link>https://www.millert.dev/</link><description>&lt;doc fingerprint="de40511530d7032a"&gt;
  &lt;main&gt;
    &lt;p&gt;Note: this page tends be neglected and is only updated occasionally. The links to the left are where the useful bits are hiding.&lt;/p&gt;
    &lt;p&gt;For the past 30+ years I’ve been the maintainer of sudo. I’m currently in search of a sponsor to fund continued sudo maintenance and development. If you or your organization is interested in sponsoring sudo, please let me know.&lt;/p&gt;
    &lt;p&gt;I also work on OpenBSD, though my I’m not as active there as I once was.&lt;/p&gt;
    &lt;p&gt;In the past, I’ve made large contributions to ISC cron, among other projects.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46858577</guid><pubDate>Mon, 02 Feb 2026 17:25:26 +0000</pubDate></item><item><title>Zig Libc</title><link>https://ziglang.org/devlog/2026/#2026-01-31</link><description>&lt;doc fingerprint="bc01b08d8cb63a11"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Devlog&lt;/head&gt;
    &lt;p&gt;This page contains a curated list of recent changes to main branch Zig.&lt;/p&gt;
    &lt;p&gt;Also available as an RSS feed.&lt;/p&gt;
    &lt;p&gt;This page contains entries for the year 2026. Other years are available in the Devlog archive page.&lt;/p&gt;
    &lt;head rend="h1"&gt;zig libc&lt;/head&gt;
    &lt;p&gt;Author: Andrew Kelley&lt;/p&gt;
    &lt;p&gt;Over the past month or so, several enterprising contributors have taken an interest in the zig libc subproject. The idea here is to incrementally delete redundant code, by providing libc functions as Zig standard library wrappers rather than as vendored C source files. In many cases, these functions are one-to-one mappings, such as &lt;code&gt;memcpy&lt;/code&gt; or &lt;code&gt;atan2&lt;/code&gt;, or trivially wrap a generic function, like &lt;code&gt;strnlen&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;fn strnlen(str: [*:0]const c_char, max: usize) callconv(.c) usize {
    return std.mem.findScalar(u8, @ptrCast(str[0..max]), 0) orelse max;
}
&lt;/code&gt;
    &lt;p&gt;So far, roughly 250 C source files have been deleted from the Zig repository, with 2032 remaining.&lt;/p&gt;
    &lt;p&gt;With each function that makes the transition, Zig gains independence from third party projects and from the C programming language, compilation speed improves, Zigâs installation size is simplified and reduced, and user applications which statically link libc enjoy reduced binary size.&lt;/p&gt;
    &lt;p&gt;Additionally, a recent enhancement now makes zig libc share the Zig Compilation Unit with other Zig code rather than being a separate static archive, linked together later. This is one of the advantages of Zig having an integrated compiler and linker. When the exported libc functions share the ZCU, redundant code is eliminated because functions can be optimized together. Itâs kind of like enabling LTO (Link-Time Optimization) across the libc boundary, except itâs done properly in the frontend instead of too late, in the linker.&lt;/p&gt;
    &lt;p&gt;Furthermore, when this work is combined with the recent std.Io changes, there is potential for users to seamlessly control how libc performs I/O - for example forcing all calls to &lt;code&gt;read&lt;/code&gt; and &lt;code&gt;write&lt;/code&gt; to participate in an io_uring event loop, even though that code was not written with such use case in mind. Or, resource leak detection could be enabled for third-party C code. For now this is only a vaporware idea which has not been experimented with, but the idea intrigues me.&lt;/p&gt;
    &lt;p&gt;Big thanks to Szabolcs Nagy for libc-test. This project has been a huge help in making sure that we donât regress any math functions.&lt;/p&gt;
    &lt;p&gt;As a reminder to our users, now that Zig is transitioning to being the static libc provider, if you encounter issues with the musl, mingw-w64, or wasi-libc libc functionality provided by Zig, please file bug reports in Zig first so we donât annoy maintainers for bugs that are in Zig, and no longer vendored by independent libc implementation projects.&lt;/p&gt;
    &lt;p&gt;Abolish ICE.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46858622</guid><pubDate>Mon, 02 Feb 2026 17:28:19 +0000</pubDate></item><item><title>Linux From Scratch ends SysVinit support</title><link>https://lists.linuxfromscratch.org/sympa/arc/lfs-announce/2026-02/msg00000.html</link><description>&lt;doc fingerprint="5939ec2fb1976402"&gt;
  &lt;main&gt;
    &lt;p&gt;Subject: Linux From Scratch Announcements&lt;/p&gt;
    &lt;p&gt;This button tries to protect the mailing list archives against address harvesting by a spammer.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46858829</guid><pubDate>Mon, 02 Feb 2026 17:45:27 +0000</pubDate></item><item><title>The Codex App</title><link>https://openai.com/index/introducing-the-codex-app/</link><description>&lt;doc fingerprint="b6466c5fc48cac9c"&gt;
  &lt;main&gt;
    &lt;p&gt;Today, we’re introducing the Codex app for macOS—a powerful new interface designed to effortlessly manage multiple agents at once, run work in parallel, and collaborate with agents over long-running tasks.&lt;/p&gt;
    &lt;p&gt;We're also excited to show more people what's now possible with Codex. For a limited time we're including Codex with ChatGPT Free and Go, and we're doubling the rate limits on Plus, Pro, Business, Enterprise, and Edu plans. Those higher limits apply everywhere you use Codex—in the app, from the CLI, in your IDE, and in the cloud.&lt;/p&gt;
    &lt;p&gt;The Codex app changes how software gets built and who can build it—from pairing with a single coding agent on targeted edits to supervising coordinated teams of agents across the full lifecycle of designing, building, shipping, and maintaining software.&lt;/p&gt;
    &lt;p&gt;Since we launched Codex in April 2025, the way developers work with agents has fundamentally changed. Models are now capable of handling complex, long-running tasks end to end and developers are now orchestrating multiple agents across projects: delegating work, running tasks in parallel, and trusting agents to take on substantial projects that can span hours, days, or weeks. The core challenge has shifted from what agents can do to how people can direct, supervise, and collaborate with them at scale—existing IDEs and terminal-based tools are not built to support this way of working.&lt;/p&gt;
    &lt;p&gt;This new way of building coupled with new model capabilities demands a different kind of tool, which is why we are introducing the Codex desktop app, a command center for agents.&lt;/p&gt;
    &lt;p&gt;The Codex app provides a focused space for multi-tasking with agents. Agents run in separate threads organized by projects, so you can seamlessly switch between tasks without losing context. The app lets you review the agent’s changes in the thread, comment on the diff, and even open it in your editor to make manual changes.&lt;/p&gt;
    &lt;p&gt;It also includes built-in support for worktrees, so multiple agents can work on the same repo without conflicts. Each agent works on an isolated copy of your code, allowing you to explore different paths without needing to track how they impact your codebase. As an agent works, you can check out changes locally or let it continue making progress without touching your local git state.&lt;/p&gt;
    &lt;p&gt;The app picks up your session history and configuration from the Codex CLI and IDE extension, so you can immediately start using it with your existing projects.&lt;/p&gt;
    &lt;p&gt;Codex is evolving from an agent that writes code into one that uses code to get work done on your computer. With skills(opens in a new window), you can easily extend Codex beyond code generation to tasks that require gathering and synthesizing information, problem-solving, writing, and more.&lt;/p&gt;
    &lt;p&gt;Skills bundle instructions, resources, and scripts so Codex can reliably connect to tools, run workflows, and complete tasks according to your team’s preferences. The Codex app includes a dedicated interface to create and manage skills. You can explicitly ask Codex to use specific skills, or let it automatically use them based on the task at hand.&lt;/p&gt;
    &lt;p&gt;We asked Codex to make a racing game, complete with different racers, eight maps, and even items players could use with the space bar. Using an image generation skill(opens in a new window) (powered by GPT Image) and a web game development skill(opens in a new window), Codex built the game by working independently using more than 7 million tokens with just one initial user prompt. It took on the roles of designer, game developer, and QA tester to validate its work by actually playing the game.&lt;/p&gt;
    &lt;p&gt;We’ve included the game, as well as the prompt and skills used to create it, below. You can also try out earlier iterations to see how Codex improved it as it worked for longer.&lt;/p&gt;
    &lt;p&gt;At OpenAI, we’ve built hundreds of skills internally to help multiple teams confidently delegate work to Codex that would otherwise be hard to define consistently—from running evals and babysitting training runs to drafting documentation and reporting on growth experiments.&lt;/p&gt;
    &lt;p&gt;The Codex app includes a library of skills for tools and workflows that have become popular at OpenAI, with a few highlighted below. You can find the full list in the open source repo(opens in a new window).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Implement designs: Fetch design context, assets, and screenshots from Figma(opens in a new window) and translate them into production-ready UI code with 1:1 visual parity.&lt;/item&gt;
      &lt;item&gt;Manage projects: Triage bugs, track releases, manage team workload, and more in Linear(opens in a new window) to keep projects moving.&lt;/item&gt;
      &lt;item&gt;Deploy to the cloud: Have Codex deploy your web app creations to popular cloud hosts like Cloudflare(opens in a new window), Netlify(opens in a new window), Render(opens in a new window), and Vercel(opens in a new window).&lt;/item&gt;
      &lt;item&gt;Generate images: Use the image generation skill(opens in a new window) powered by GPT Image to create and edit images to use in websites, UI mockups, product visuals, and game assets.&lt;/item&gt;
      &lt;item&gt;Build with OpenAI APIs: Reference up-to-date documentation(opens in a new window) when building with OpenAI APIs.&lt;/item&gt;
      &lt;item&gt;Create documents: A set of skills for reading, creating, and editing PDF(opens in a new window), spreadsheet(opens in a new window), and docx(opens in a new window) files with professional formatting and layouts.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When you create a new skill in the app, Codex can use it wherever you work: in the app, CLI or in your IDE extension. You can also check skills into your repository to make them available to your entire team. Read more about sharing skills using team config here(opens in a new window).&lt;/p&gt;
    &lt;p&gt;With the Codex app, you can also set up Automations that let Codex work in the background on an automatic schedule. Automations combine instructions with optional skills, running on a schedule you define. When an Automation finishes, the results land in a review queue so you can jump back in and continue working if needed.&lt;/p&gt;
    &lt;p&gt;At OpenAI, we’ve been using Automations to handle the repetitive but important tasks, like daily issue triage, finding and summarizing CI failures, generating daily release briefs, checking for bugs, and more.&lt;/p&gt;
    &lt;p&gt;Developers have different preferences in how they work with an agent. Some want a blunt, execution-focused partner; others prefer more communicative, engaging interactions. Codex now lets developers choose between two personalities—a terse, pragmatic style and a more conversational, empathetic one, without any change in capabilities, to fit the approach you like the most. Just use the /personality command in the app, CLI, and IDE extension.&lt;/p&gt;
    &lt;p&gt;Learn more about how to set up and use the Codex app in the docs(opens in a new window).&lt;/p&gt;
    &lt;p&gt;We’re integrating security by design across the entire Codex agent stack. The Codex app uses native, open-source(opens in a new window) and configurable system-level sandboxing just like in the Codex CLI. By default, Codex agents are limited to editing files in the folder or branch where they’re working and using cached web search, then asking for permission to run commands that require elevated permissions like network access. You can configure rules(opens in a new window) for your project or team that allows certain commands to automatically run with elevated permissions.&lt;/p&gt;
    &lt;p&gt;The Codex app is available starting today on macOS. Anyone with a ChatGPT Plus, Pro, Business, Enterprise or Edu subscription can use Codex across the CLI, web, IDE-extension and app with their ChatGPT login. Usage is included in ChatGPT subscriptions, with the option to purchase additional credits if needed.&lt;/p&gt;
    &lt;p&gt;For a limited time, Codex will also be available to ChatGPT Free and Go users to help build more with agents. We’re also doubling rate limits for existing Codex users across all paid plans during this period.&lt;/p&gt;
    &lt;p&gt;Enterprises and developers increasingly rely on Codex for end-to-end development. Since the launch of GPT‑5.2-Codex in mid-December, overall Codex usage has doubled, and in the past month, more than a million developers have used Codex. We’ll continue to expand where and how developers can use Codex, including making the app available on Windows, pushing the frontier of model capabilities, and rolling out faster inference.&lt;/p&gt;
    &lt;p&gt;Within the app, we’ll keep refining multi-agent workflows based on real-world feedback, making it easier to manage parallel work and move between agents without losing context. We’re also building out Automations with support for cloud-based triggers, so Codex can run continuously in the background—not just when your computer is open.&lt;/p&gt;
    &lt;p&gt;Codex is built on a simple premise: everything is controlled by code. The better an agent is at reasoning about and producing code, the more capable it becomes across all forms of technical and knowledge work. Yet a key challenge today is the gap between what frontier models are capable of and how easily people can use them in practice. Codex is designed to close that gap by making it easier to direct, supervise, and apply the full intelligence of our models to real work. We’ve focused on making Codex the best coding agent, which has also laid the foundation for it to become a strong agent for a broad range of knowledge work tasks that extend beyond writing code. We’re excited to see what you build with Codex!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46859054</guid><pubDate>Mon, 02 Feb 2026 18:02:48 +0000</pubDate></item><item><title>Anki ownership transferred to AnkiHub</title><link>https://forums.ankiweb.net/t/ankis-growing-up/68610</link><description>&lt;doc fingerprint="be5a7113f11cafe8"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Hi everyone,&lt;/p&gt;
      &lt;p&gt;We initially reached out to @dae to explore collaborating more closely on improving Anki. We were both humbled and shocked when he asked if we’d be willing to step into a much larger leadership role than we expected.&lt;/p&gt;
      &lt;p&gt;At this point, we’re mostly excited…and also feeling a healthy amount of terror. This is a big responsibility. It will push us to grow as individuals, as a team, and as a community, and we don’t take that lightly.&lt;/p&gt;
      &lt;p&gt;We’re grateful for the trust Damien and others have placed in us. And we also know that trust has to be earned, especially from people who don’t know us yet.&lt;/p&gt;
      &lt;head rend="h3"&gt;What We Believe&lt;/head&gt;
      &lt;p&gt;We believe Anki is almost sacred, something bigger than any one person or organization. In an important sense, it belongs to the community.&lt;/p&gt;
      &lt;p&gt;This article highlights the principles Damien built Anki on; principles we deeply share, such as respect for user agency, refusal of manipulative design patterns, and an emphasis on the craft of building genuinely useful tools that aren’t merely engaging. Anki has never tried to maximize “engagement” by exploiting psychological vulnerabilities purely for profit. Anki gives your time back to you, and that is an exceptional rarity in this world that we want to preserve.&lt;/p&gt;
      &lt;p&gt;As an organization built by students, for students, our mission is to continue embodying these principles. We are accountable only to you, our users, not external investors, and we plan to keep it that way.&lt;/p&gt;
      &lt;head rend="h3"&gt;What We Don’t Know Yet&lt;/head&gt;
      &lt;p&gt;We can’t answer every question right away, as there are many unknowns since much hasn’t been decided yet. But we are sharing everything we can now because the community is important to us. We encourage you all to share your thoughts and questions – we’re all in this together!&lt;/p&gt;
      &lt;p&gt;We’re still working through the details on things like:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Governance and decision-making: How decisions are made, who has final say, and how the community is heard&lt;/item&gt;
        &lt;item&gt;Roadmap and priorities: What gets built when and how to balance competing needs&lt;/item&gt;
        &lt;item&gt;The transition itself: How to bring in more support without disrupting what already works&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Anki has shown how powerful community collaboration can be when it’s genuinely a group effort, and that’s a tradition we are honored to continue.&lt;/p&gt;
      &lt;p&gt;We’re currently talking to David Allison, a long-time core contributor to AnkiDroid, about working together on exactly these questions. His experience with AnkiDroid’s collaborative development is invaluable, and we’re grateful he’s willing to help us get this right. We’re incredibly excited to have him join us full-time to help propel Anki into the future.&lt;/p&gt;
      &lt;head rend="h3"&gt;What We’re Aiming For&lt;/head&gt;
      &lt;p&gt;UI/UX improvements. We’re bringing professional design expertise on board to make it more approachable without sacrificing Anki’s power. We believe that principled design will bring meaningful quality of life improvements to power users and novices alike.&lt;/p&gt;
      &lt;p&gt;Addressing the bus factor. The ecosystem shouldn’t be in jeopardy if any one person disappears. We want to build software that lives beyond any single contributor.&lt;/p&gt;
      &lt;p&gt;Supporting more than just med students. AnkiHub grew out of the medical education community, but Anki serves learners from all walks of life, and we want to support everyone to achieve their learning goals.&lt;/p&gt;
      &lt;p&gt;A more robust add-on ecosystem. We’d love to build tools that empower non-technical users to customize Anki for their needs, and we’re exploring add-ons that work everywhere, including mobile.&lt;/p&gt;
      &lt;head rend="h3"&gt;How We’ll Work&lt;/head&gt;
      &lt;p&gt;We want to provide transparency into the decision-making process, taking inspiration from proven models to:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Give the community clarity on how to be heard and give feedback&lt;/item&gt;
        &lt;item&gt;Make it clear how decisions are made and why&lt;/item&gt;
        &lt;item&gt;Set realistic expectations&lt;/item&gt;
        &lt;item&gt;Define roles and responsibilities so things don’t fall through the cracks&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;We want to bring everyone in the global Anki community together into a closer collaboration focused on building the best learning tools possible. Today, these groups often work in silos; a more unified process will help everyone move Anki forward together.&lt;/p&gt;
      &lt;head rend="h3"&gt;Sustainability&lt;/head&gt;
      &lt;p&gt;Some practical reassurances:&lt;/p&gt;
      &lt;p&gt;Sustainability, affordability, and accessibility. We’re committed to a sustainable business model that keeps Anki accessible and prioritizes user needs above profits. If anything ever needs to change, we’ll be transparent about why.&lt;/p&gt;
      &lt;p&gt; No enshittification. We’ve seen what happens when VC-backed companies acquire beloved tools. That’s not what this is. There are no investors involved, and we’re not here to extract value from something the community built together. Building in the right safeguards and processes to handle pressure without stifling necessary improvements is something we’re actively considering.&lt;/p&gt;
      &lt;p&gt;We’re grateful to Damien et all for their trust and support, and grateful to all of you for the passion that makes this community so special.&lt;/p&gt;
      &lt;p&gt;We welcome your questions, concerns, and feedback.&lt;/p&gt;
      &lt;p&gt; – The AnkiHub Team&lt;/p&gt;
      &lt;head rend="h1"&gt;FAQs&lt;/head&gt;
      &lt;head rend="h2"&gt;What is AnkiHub?&lt;/head&gt;
      &lt;p&gt;AnkiHub is a small education technology company founded by two long-time Anki nerds: Nick, a resident physician known as The AnKing, and Andrew Sanchez, a research software engineer. AnkiHub grew out of years of obsessive Anki use and firsthand experience with both its power and its limitations.&lt;/p&gt;
      &lt;p&gt;AnkiHub began as a way to collaborate on Anki decks (such as the AnKing Step Deck for medical students) and has since evolved into a broader effort to improve the Anki ecosystem by building tools that help more people benefit from Anki.&lt;/p&gt;
      &lt;head rend="h2"&gt;Will Anki remain open source?&lt;/head&gt;
      &lt;p&gt;Absolutely. Anki’s core code will remain open source, guided by the same principles that have guided the project from the beginning.&lt;/p&gt;
      &lt;head rend="h2"&gt;Are there any changes planned to Anki’s pricing?&lt;/head&gt;
      &lt;p&gt;No. We are committed to fair pricing that supports users rather than exploiting them. Both Anki and AnkiHub are already profitable. Any future decisions will be made with community benefit, user value, and long-term project health in mind.&lt;/p&gt;
      &lt;head rend="h2"&gt;Is Anki in financial trouble?&lt;/head&gt;
      &lt;p&gt;No. The transition is driven by the goal of helping Anki reach its full potential, not by financial issues. Our goal is to build a resilient structure and accelerate development.&lt;/p&gt;
      &lt;head rend="h2"&gt;What is the timeline?&lt;/head&gt;
      &lt;p&gt;Our intention is to build confidence and earn trust while making gradual changes. The transition will be transparent, with clear communication throughout.&lt;/p&gt;
      &lt;head rend="h2"&gt;What happens to volunteer contributors and community developers?&lt;/head&gt;
      &lt;p&gt;Volunteer contributors will always be essential to Anki. Our goal is to make it easier to collaborate meaningfully.&lt;/p&gt;
      &lt;head rend="h2"&gt;Will the mobile apps change or be removed from the app stores?&lt;/head&gt;
      &lt;p&gt;The mobile apps will continue to be maintained and supported. Additional development capacity should help with faster updates, better testing, and more consistent improvements across platforms over time.&lt;/p&gt;
      &lt;head rend="h2"&gt;How much influence will investors or external partners have on Anki after the transition?&lt;/head&gt;
      &lt;p&gt;None. Both Anki and AnkiHub are entirely self-funded. There are no outside investors dictating product decisions, growth targets, or monetization strategy.&lt;/p&gt;
      &lt;head rend="h2"&gt;What will happen with AnkiHub?&lt;/head&gt;
      &lt;p&gt;AnkiHub will continue to operate as usual, but now our teams are working together to improve both solutions. The only change you should notice is that, over time, everything becomes much easier to use.&lt;/p&gt;
      &lt;p&gt;We’ll share more updates as they happen in the future.&lt;/p&gt;
      &lt;head rend="h2"&gt;What will happen with the current AnkiHub subscriptions?&lt;/head&gt;
      &lt;p&gt;AnkiHub subscriptions enhance Anki with collaborative features, shared deck syncing, and LLM-based features and that isn’t changing at this time.&lt;/p&gt;
      &lt;head rend="h2"&gt;What will happen with AnkiDroid?&lt;/head&gt;
      &lt;p&gt;AnkiDroid will remain an open-source, self-governed project. There are no plans or agreements regarding AnkiDroid.&lt;/p&gt;
      &lt;head rend="h2"&gt;How will decisions be made and communicated?&lt;/head&gt;
      &lt;p&gt;Anki is open-source, and we will build on and improve its current decision-making processes. We will work in public whenever possible and seek consensus from core contributors. Significant decisions, choices, and their outcomes will be documented on GitHub or in the source code. When a change materially affects users or developers, the reasoning behind it and its impact will be communicated publicly. In the coming weeks, we will work on defining a more formal governance model to set clear expectations.&lt;/p&gt;
      &lt;head rend="h2"&gt;Will there be a public governance model, advisory board, or other accountability structure?&lt;/head&gt;
      &lt;p&gt;We’re exploring what makes sense here, and we don’t want to rush it.&lt;/p&gt;
      &lt;p&gt;Historically, Anki has relied more on trust and stewardship than on formal governance. We want to preserve that spirit while improving transparency. Our goal is to establish a governance structure that supports the community and improves clarity and accountability without burdensome bureaucracy.&lt;/p&gt;
      &lt;head rend="h2"&gt;How will the transition affect add-ons and their developers?&lt;/head&gt;
      &lt;p&gt;Add-ons are a critical part of the ecosystem.&lt;/p&gt;
      &lt;p&gt;Our intent is to make life easier for add-on developers: clearer APIs, better documentation, fewer breaking changes, and more predictable release cycles. The goal is not to lock down or restrict the add-on space, but rather to enhance it.&lt;/p&gt;
      &lt;head rend="h2"&gt;What new resources will Anki gain through this transition?&lt;/head&gt;
      &lt;p&gt;The biggest change is bandwidth by enabling more people to work on Anki without everything being bottlenecked through a single person. This will take time, but will eventually translate into more engineering, design, and support capacity.&lt;/p&gt;
      &lt;head rend="h2"&gt;What steps will be taken to make Anki more accessible, stable, and beginner-friendly?&lt;/head&gt;
      &lt;p&gt;There is a lot of low-hanging fruit that we plan to tackle: improving onboarding for new users, polishing rough edges, and addressing long-standing usability issues. These are exactly the kinds of improvements that have been difficult to tackle under constant time pressure, and we’re excited to invest in them.&lt;/p&gt;
      &lt;head rend="h2"&gt;Will community feedback still meaningfully influence the project’s direction?&lt;/head&gt;
      &lt;p&gt;Yes. Anki exists because of its community: users, contributors, add-on developers, translators, and educators. Feedback won’t always translate into immediate changes, but it will always be heard, considered, and respected.&lt;/p&gt;
      &lt;head rend="h2"&gt;How will trust be built with users who are skeptical or anxious about the change?&lt;/head&gt;
      &lt;p&gt;Trust isn’t something you demand; it’s something you earn over time. We intend to build trust through consistent actions: honoring commitments, avoiding surprises, communicating clearly, and demonstrating that Anki’s values haven’t changed. We hope our past actions will give you some peace of mind, but we also understand the skepticism, and we’re prepared to meet it with patience and transparency.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46861313</guid><pubDate>Mon, 02 Feb 2026 20:48:55 +0000</pubDate></item><item><title>GitHub experience various partial-outages/degradations</title><link>https://www.githubstatus.com?todayis=2026-02-02</link><description>&lt;doc fingerprint="181783f747bb49e6"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt; Resolved - This incident has been resolved. Thank you for your patience and understanding as we addressed this issue. A detailed root cause analysis will be shared as soon as it is available. &lt;lb/&gt; Feb 3, 00:56 UTC &lt;/p&gt;
      &lt;p&gt; Update - Actions is operating normally. &lt;lb/&gt; Feb 3, 00:56 UTC &lt;/p&gt;
      &lt;p&gt; Update - Based on our telemetry, most customers should see full recovery from failing GitHub Actions jobs on hosted runners.&lt;lb/&gt;We are monitoring closely to confirm complete recovery.&lt;lb/&gt;Other GitHub features that rely on GitHub Actions (for example, Copilot Coding Agent and Dependabot) should also see recovery. &lt;lb/&gt; Feb 2, 23:50 UTC &lt;/p&gt;
      &lt;p&gt; Update - Actions is experiencing degraded performance. We are continuing to investigate. &lt;lb/&gt; Feb 2, 23:43 UTC &lt;/p&gt;
      &lt;p&gt; Update - Copilot is operating normally. &lt;lb/&gt; Feb 2, 23:42 UTC &lt;/p&gt;
      &lt;p&gt; Update - Pages is operating normally. &lt;lb/&gt; Feb 2, 23:31 UTC &lt;/p&gt;
      &lt;p&gt; Update - Our upstream provider has applied a mitigation to address queuing and job failures on hosted runners.&lt;lb/&gt;Telemetry shows improvement, and we are monitoring closely for full recovery. &lt;lb/&gt; Feb 2, 22:53 UTC &lt;/p&gt;
      &lt;p&gt; Update - We continue to investigate failures impacting GitHub Actions hosted-runner jobs.&lt;lb/&gt;We're waiting on our upstream provider to apply the identified mitigations, and we're preparing to resume job processing as safely as possible. &lt;lb/&gt; Feb 2, 22:10 UTC &lt;/p&gt;
      &lt;p&gt; Update - Copilot is experiencing degraded performance. We are continuing to investigate. &lt;lb/&gt; Feb 2, 21:27 UTC &lt;/p&gt;
      &lt;p&gt; Update - We continue to investigate failures impacting GitHub Actions hosted-runner jobs.&lt;lb/&gt;We have identified the root cause and are working with our upstream provider to mitigate.&lt;lb/&gt;This is also impacting GitHub features that rely on GitHub Actions (for example, Copilot Coding Agent and Dependabot). &lt;lb/&gt; Feb 2, 21:13 UTC &lt;/p&gt;
      &lt;p&gt; Update - The team continues to investigate issues causing GitHub Actions jobs on hosted runners to remain queued for extended periods, with a percentage of jobs failing. We will continue to provide updates as we make progress toward mitigation.&lt;lb/&gt; Feb 2, 20:27 UTC &lt;/p&gt;
      &lt;p&gt; Update - Pages is experiencing degraded performance. We are continuing to investigate. &lt;lb/&gt; Feb 2, 19:48 UTC &lt;/p&gt;
      &lt;p&gt; Update - The team continues to investigate issues causing GitHub Actions jobs on hosted runners to remain queued for extended periods, with a percentage of jobs failing. We will continue to provide updates as we make progress toward mitigation. &lt;lb/&gt; Feb 2, 19:44 UTC &lt;/p&gt;
      &lt;p&gt; Update - Actions is experiencing degraded availability. We are continuing to investigate. &lt;lb/&gt; Feb 2, 19:43 UTC &lt;/p&gt;
      &lt;p&gt; Update - GitHub Actions hosted runners are experiencing high wait times across all labels. Self-hosted runners are not impacted. &lt;lb/&gt; Feb 2, 19:07 UTC &lt;/p&gt;
      &lt;p&gt; Investigating - We are investigating reports of degraded performance for Actions &lt;lb/&gt; Feb 2, 19:03 UTC &lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46861842</guid><pubDate>Mon, 02 Feb 2026 21:28:16 +0000</pubDate></item><item><title>xAI joins SpaceX</title><link>https://www.spacex.com/updates#xai-joins-spacex</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46862170</guid><pubDate>Mon, 02 Feb 2026 21:51:22 +0000</pubDate></item><item><title>The TSA's New $45 Fee to Fly Without ID Is Illegal</title><link>https://www.frommers.com/tips/airfare/the-tsa-new-45-fee-to-fly-without-id-is-illegal-says-regulatory-expert/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46863162</guid><pubDate>Mon, 02 Feb 2026 22:48:10 +0000</pubDate></item><item><title>How does misalignment scale with model intelligence and task complexity?</title><link>https://alignment.anthropic.com/2026/hot-mess-of-ai/</link><description>&lt;doc fingerprint="a94bb3bd24c2cd2e"&gt;
  &lt;main&gt;
    &lt;p&gt;Research done as part of the first Anthropic Fellows Program during Summer 2025.&lt;/p&gt;
    &lt;p&gt;When AI systems fail, will they fail by systematically pursuing the wrong goals, or by being a hot mess? We decompose the errors of frontier reasoning models into bias (systematic) and variance (incoherent) components and find that, as tasks get harder and reasoning gets longer, model failures become increasingly dominated by incoherence rather than systematic misalignment. This suggests that future AI failures may look more like industrial accidents than coherent pursuit of a goal we did not train them to pursue.&lt;/p&gt;
    &lt;p&gt;As AI becomes more capable, we entrust it with increasingly consequential tasks. This makes understanding how these systems might fail even more critical for safety. A central concern in AI alignment is that superintelligent systems might coherently pursue misaligned goals: the classic paperclip maximizer scenario. But there's another possibility: AI might fail not through systematic misalignment, but through incoherence—unpredictable, self-undermining behavior that doesn't optimize for any consistent objective. That is, AI might fail in the same way that humans often fail, by being a hot mess.&lt;/p&gt;
    &lt;p&gt;This paper builds on the hot mess theory of misalignment (Sohl-Dickstein, 2023), which surveyed experts to rank various entities (including humans, animals, machine learning models, and organizations) by intelligence and coherence independently. It found that smarter entities are subjectively judged to behave less coherently. We take this hypothesis from survey data to empirical measurement across frontier AI systems, asking: As models become more intelligent and tackle harder tasks, do their failures look more like systematic misalignment, or more like a hot mess?&lt;/p&gt;
    &lt;p&gt;To quantify incoherence we decompose AI errors using the classic bias-variance framework:&lt;/p&gt;
    &lt;p&gt;We define incoherence as the fraction of error attributable to variance:&lt;/p&gt;
    &lt;p&gt;An incoherence of 0 means all errors are systematic (classic misalignment risk). An incoherence of 1 means all errors are random (the hot mess scenario). Crucially, this metric is independent of overall performance: a model can improve while becoming more or less coherent.&lt;/p&gt;
    &lt;p&gt;We evaluated frontier&lt;/p&gt;
    &lt;p&gt;Across all tasks and models, the longer models spend reasoning and taking actions, the more incoherent they become. This holds whether we measure reasoning tokens, agent actions, or optimizer steps.&lt;/p&gt;
    &lt;p&gt;How does incoherence change with model scale? The answer depends on task difficulty:&lt;/p&gt;
    &lt;p&gt;This suggests that scaling alone won't eliminate incoherence. As more capable models tackle harder problems, variance-dominated failures persist or worsen.&lt;/p&gt;
    &lt;p&gt;We find that when models spontaneously reason longer on a problem (compared to their median), incoherence spikes dramatically. Meanwhile, deliberately increasing reasoning budgets through API settings provides only modest coherence improvements. The natural variation dominates.&lt;/p&gt;
    &lt;p&gt;Aggregating multiple samples reduces variance (as expected from theory), providing a path to more coherent behavior, though this may be impractical for real-world agentic tasks where actions are irreversible.&lt;/p&gt;
    &lt;p&gt;A key conceptual point: LLMs are dynamical systems, not optimizers. When a language model generates text or takes actions, it traces trajectories through a high-dimensional state space. It has to be trained to act as an optimizer, and trained to align with human intent. It's unclear which of these properties will be more robust as we scale.&lt;/p&gt;
    &lt;p&gt;Constraining a generic dynamical system to act as a coherent optimizer is extremely difficult. Often the number of constraints required for monotonic progress toward a goal grows exponentially with the dimensionality of the state space. We shouldn't expect AI to act as coherent optimizers without considerable effort, and this difficulty doesn't automatically decrease with scale.&lt;/p&gt;
    &lt;p&gt;To probe this directly, we designed a controlled experiment: train transformers to explicitly emulate an optimizer. We generate training data from steepest descent on a quadratic loss function, then train models of varying sizes to predict the next optimization step given the current state (essentially: training a "mesa-optimizer").&lt;/p&gt;
    &lt;p&gt;The results are interesting:&lt;/p&gt;
    &lt;p&gt;Our results are evidence that future AI failures may look more like industrial accidents than coherent pursuit of goals that were not trained for. (Think: the AI intends to run the nuclear power plant, but gets distracted reading French poetry, and there is a meltdown.) However, coherent pursuit of poorly chosen goals that we trained for remains a problem. Specifically:&lt;/p&gt;
    &lt;p&gt;We use the bias-variance decomposition to systematically study how AI incoherence scales with model intelligence and task complexity. The evidence suggests that as AI tackles harder problems requiring more reasoning and action, its failures tend to become increasingly dominated by variance rather than bias. This doesn't eliminate AI risk—but it changes what that risk looks like, particularly for problems that are currently hardest for models, and should inform how we prioritize alignment research.&lt;/p&gt;
    &lt;p&gt;We thank Andrew Saxe, Brian Cheung, Kit Frasier-Taliente, Igor Shilov, Stewart Slocum, Aidan Ewart, David Duvenaud, and Tom Adamczewski for extremely helpful discussions on topics and results in this paper.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46864498</guid><pubDate>Tue, 03 Feb 2026 00:28:06 +0000</pubDate></item><item><title>Banning lead in gas worked. The proof is in our hair</title><link>https://attheu.utah.edu/health-medicine/banning-lead-in-gas-worked-the-proof-is-in-our-hair/</link><description>&lt;doc fingerprint="7ef43095fbe01e94"&gt;
  &lt;main&gt;
    &lt;p&gt;Prior to the establishment of the Environmental Protection Agency in 1970, Americans lived in communities awash with lead from industrial sources, paint, water supply pipes and, most significantly, tailpipe emissions. A dangerous neurotoxin that accumulates in human tissues and is linked to developmental deficits in children, environmental lead levels have come way down in the years since, and so have human exposures.&lt;/p&gt;
    &lt;p&gt;The proof is in your hair.&lt;/p&gt;
    &lt;p&gt;An analysis of hair samples conducted by University of Utah scientists shows precipitous reductions in lead levels since 1916.&lt;/p&gt;
    &lt;p&gt;“We were able to show through our hair samples what the lead concentrations are before and after the establishment of regulations by the EPA,” said demographer Ken Smith, a distinguished professor emeritus of family and consumer studies. “We have hair samples spanning about 100 years. And back when the regulations were absent, the lead levels were about 100 times higher than they are after the regulations.”&lt;/p&gt;
    &lt;head rend="h4"&gt;A useful element with a dark side&lt;/head&gt;
    &lt;p&gt;The findings, which appear in PNAS, underscore the vital role of environmental regulations in protecting public health. The study notes lead rules are now being weakened by the Trump administration in a wide-ranging move to ease environmental protections.&lt;/p&gt;
    &lt;p&gt;“We should not forget the lessons of history. And the lesson is those regulations have been very important,” said co-author Thure Cerling, a distinguished professor of both geology and biology. “Sometimes they seem onerous and mean that industry can’t do exactly what they’d like to do when they want to do it or as quickly as they want to do it. But it’s had really, really positive effects.”&lt;/p&gt;
    &lt;p&gt;Lead is the heaviest of heavy metals that, like mercury and arsenic, accumulate in living tissue and are toxic at even low levels. Yet lead holds very useful properties, great for fashioning into pipes and as a chemical additive. Lead was added to paint to improve durability, speed up drying, and produce vibrant colors with greater coverage. Lead also improved the performance of automobile engines by preventing pistons from “knocking.”&lt;/p&gt;
    &lt;p&gt;By the 1970s, its toxicity became well established, and EPA regulations began phasing it out of paint, pipes, gasoline and other consumer products.&lt;/p&gt;
    &lt;head rend="h4"&gt;How Utahns’ affection for family history advances science&lt;/head&gt;
    &lt;p&gt;To document whether these steps were helping reduce lead exposure in people, Smith joined with geologist Diego Fernandez and Cerling, who had developed techniques to discern where animals have lived and what they eat based on chemical analysis of hair and teeth.&lt;/p&gt;
    &lt;p&gt;The lead research is built on a previous study funded by the university’s Center on Aging and the National Institutes of Health that had recruited Utahns who consented to provide blood samples and family health histories.&lt;/p&gt;
    &lt;p&gt;For the new study, the researchers asked members of that cohort to provide hair samples, both contemporary and from when they were young. These people obliged, and some were able to find ancestors’ hair preserved in family scrapbooks dating as far back as a century. In all, the team acquired hair samples from 48 individuals in this manner, offering a robust window into lead levels along Utah’s populous Wasatch Front, which historically experienced heavy lead emissions from industrial sources.&lt;/p&gt;
    &lt;p&gt;“The Utah part of this is so interesting because of the way people keep track of their family history. I don’t know that you could do this in New York or Florida,” said Smith, who directed the U’s Pedigree and Population Program at the Huntsman Cancer Center while these studies were conducted.&lt;/p&gt;
    &lt;p&gt;This region supported a vibrant smelting industry through most of the 20th century, centered in the cities of Midvale and Murray. Most of Utah’s smelters were shuttered by the 1970s, around the same time the EPA clamped down on the use of lead in consumer products.&lt;/p&gt;
    &lt;p&gt;The research team ran the hair samples through mass spectrometry equipment at the facility directed by Fernandez.&lt;/p&gt;
    &lt;p&gt;“The surface of the hair is special. We can tell that some elements get concentrated and accumulated on the surface. Lead is one of those. That makes it easier because lead is not lost over time,” said Fernandez, a research professor in the Department of Geology &amp;amp; Geophysics. “Because mass spectrometry is very sensitive, we can do it with one hair strand, though we cannot tell where the lead is in the hair. It’s probably on the surface mostly, but it could also be coming from the blood if that hair was synthesized when there was high lead in the blood.”&lt;/p&gt;
    &lt;p&gt;Blood would provide a better exposure assessment, but hair is far easier to collect and preserve, and more importantly, it offers clues to long-ago exposures for a person who has grown up or even deceased.&lt;/p&gt;
    &lt;p&gt;“It doesn’t really record that internal blood concentration that your brain is seeing, but it tells you about that overall environmental exposure,” Cerling said. “One of the things that we found is that hair records that original value, but then the longer the hair has been exposed to the environment, the higher the lead concentrations are.”&lt;/p&gt;
    &lt;p&gt;The team’s findings regarding lead in hair run parallel to the reductions of lead in gasoline following the EPA’s establishment by President Richard Nixon.&lt;/p&gt;
    &lt;p&gt;Prior to 1970, for example, gasolines contained about 2 grams of lead per gallon. That might not sound like much, but considering the billions of gallons of fuel American automobiles burn each year, it adds up to nearly 2 pounds of lead released into the environment per person a year.&lt;/p&gt;
    &lt;p&gt;‘It’s an enormous amount of lead that’s being put into the environment and quite locally,” Cerling said. “It’s just coming out of the tailpipe, goes up in the air and then it comes down. It’s in the air for a number of days, especially during the inversions that we have and it absorbs into your hair, you breathe it and it goes into your lungs.”&lt;/p&gt;
    &lt;p&gt;But after the 1970s, even as gasoline consumption escalated in the United States, the concentrations of lead in the hair samples plummeted, from as high as 100 parts per million (ppm) to 10 ppm by 1990. In 2024, the level was less than 1 ppm.&lt;/p&gt;
    &lt;p&gt;The study, titled “Lead in archived hair documents decline in human lead (Pb) exposure since establishment of the US Environmental Protection Agency,” was published Feb. 2 in PNAS, or Proceedings of the National Academy of Sciences. Support came from the Huntsman Cancer Foundation and the National Cancer Institute through a grant to the Utah Population Database and the University of Utah.&lt;/p&gt;
    &lt;head rend="h3"&gt;MEDIA &amp;amp; PR CONTACTS&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Brian Maffly Science writer, University of Utah Communications&lt;lb/&gt;801-573-2382 brian.maffly@utah.edu&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46865275</guid><pubDate>Tue, 03 Feb 2026 01:52:21 +0000</pubDate></item><item><title>Floppinux – An Embedded Linux on a Single Floppy, 2025 Edition</title><link>https://krzysztofjankowski.com/floppinux/floppinux-2025.html</link><description>&lt;doc fingerprint="1719381e65a62ba8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;FLOPPINUX&lt;/head&gt;
    &lt;head rend="h2"&gt;An Embedded ð§Linux on a Single ð¾Floppy&lt;/head&gt;
    &lt;head rend="h2"&gt;2025 Edition (v0.3.1)&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;FLOPPINUX was released in 2021. After four years people find it helpful. Because of that I decided to revisit FLOPPINUX in 2025 and make updated tutorial. This brings bunch of updates like latest kernel and persistent storage.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;Table of Contents&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Main Project Goals&lt;/item&gt;
      &lt;item&gt;Linux Kernel&lt;/item&gt;
      &lt;item&gt;64-bit Base OS&lt;/item&gt;
      &lt;item&gt;Working Directory&lt;/item&gt;
      &lt;item&gt;System Requirements&lt;/item&gt;
      &lt;item&gt;Kernel&lt;/item&gt;
      &lt;item&gt;Toolset&lt;/item&gt;
      &lt;item&gt;Filesystem&lt;/item&gt;
      &lt;item&gt;Boot Image&lt;/item&gt;
      &lt;item&gt;Floppy Disk&lt;/item&gt;
      &lt;item&gt;Summary&lt;/item&gt;
      &lt;item&gt;Download&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Main Project Goals&lt;/head&gt;
    &lt;p&gt;Think of this as Linux From Scratch but for making single floppy distribution.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;It is meant to be a full workshop (tutorial) that you can follow easily and modify it to your needs. It is a learning exercise. Some base Linux knowledge is needed.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The final distribution is very simple and consists only of minimum of tools and hardware support. As a user you will be able to boot any PC with a floppy drive to a Linux terminal, edit files, and create simple scripts. There is 264KB of space left for your newly created files.&lt;/p&gt;
    &lt;head rend="h3"&gt;Core features:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fully working distribution booting from the single floppy&lt;/item&gt;
      &lt;item&gt;Latest* Linux kernel&lt;/item&gt;
      &lt;item&gt;Supporting all 32-bit x86 CPUs since Intel 486DX&lt;/item&gt;
      &lt;item&gt;Have a working text editor (Vi) and basic file manipulation commands (move, rename, delete, etc.)&lt;/item&gt;
      &lt;item&gt;Support for simple scripting&lt;/item&gt;
      &lt;item&gt;Persistent storage on the floppy to actualy save files (264KB)&lt;/item&gt;
      &lt;item&gt;Works on real hardware and emulation&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Minimum Hardware Requirements:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Intel 486DX 33MHz&lt;/item&gt;
      &lt;item&gt;20MB RAM&lt;/item&gt;
      &lt;item&gt;Internal floppy disk&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Linux Kernel&lt;/head&gt;
    &lt;p&gt;The Linux kernel drops i486 support in 6.15 (released May 2025), so 6.14 (released March 2025) is the latest version with full compatibility.&lt;/p&gt;
    &lt;head rend="h2"&gt;64-bit Base OS&lt;/head&gt;
    &lt;p&gt;This time I will do everything on Omarchy Linux. It is 64-bit operating system based on Arch Linux. Instructions should work on all POSIX systems. Only difference is getting needed packages.&lt;/p&gt;
    &lt;head rend="h2"&gt;Working Directory&lt;/head&gt;
    &lt;p&gt;Create directory where you will keep all the files.&lt;/p&gt;
    &lt;code&gt;mkdir ~/my-linux-distro/
BASE=~/my-linux-distro/
cd $BASE&lt;/code&gt;
    &lt;head rend="h2"&gt;Host OS Requirements&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;You need supporting software to build things. This exact list may vary depending on the system you have.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Install needed software/libs. On Arch/Omarchy 3.1:&lt;/p&gt;
    &lt;code&gt;sudo pacman -S ncurses bc flex bison syslinux cpio&lt;/code&gt;
    &lt;p&gt;Cross-compiler:&lt;/p&gt;
    &lt;code&gt;wget https://musl.cc/i486-linux-musl-cross.tgz
tar xvf i486-linux-musl-cross.tgz
rm i486-linux-musl-cross.tgz&lt;/code&gt;
    &lt;head rend="h3"&gt;Emulation&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;86Box is also good but slower. Bochs is the best but for debugging, not needed here.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;For emulation I will be using qemu.&lt;/p&gt;
    &lt;code&gt;sudo pacman -S qemu-full&lt;/code&gt;
    &lt;head rend="h2"&gt;Kernel&lt;/head&gt;
    &lt;p&gt;Get the sources for the latest compatible kernel 6.14.11:&lt;/p&gt;
    &lt;code&gt;git clone --depth=1 --branch v6.14.11 https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git
cd linux&lt;/code&gt;
    &lt;p&gt;Now, that you have them in linux/ directory lets configure and build our custom kernel. First create tiniest base configuration:&lt;/p&gt;
    &lt;code&gt;make ARCH=x86 tinyconfig&lt;/code&gt;
    &lt;quote&gt;
      &lt;p&gt;This is a bootstrap with absolute minimum features. Just enough to boot the system. We want a little bit more.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Add additonal config settings on top of it:&lt;/p&gt;
    &lt;code&gt;make ARCH=x86 menuconfig&lt;/code&gt;
    &lt;p&gt;Important: Do not uncheck anything in options unless specified so. Some of those options are important. You can uncheck but on your own risk.&lt;/p&gt;
    &lt;p&gt;From menus choose those options:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;General Setup &lt;list rend="ul"&gt;&lt;item&gt;Configure standard kernel features (expert users) &lt;list rend="ul"&gt;&lt;item&gt;Enable support for printk&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Initial RAM filesystem and RAM disk (initramfs/initrd) &lt;list rend="ul"&gt;&lt;item&gt;Support initial ramdisk/ramfs compressed using XZ and uncheck everything else&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Configure standard kernel features (expert users) &lt;/item&gt;
      &lt;item&gt;Processor type and features &lt;list rend="ul"&gt;&lt;item&gt;x86 CPU resources control support&lt;/item&gt;&lt;item&gt;Processor family &lt;list rend="ul"&gt;&lt;item&gt;486DX&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Enable the block layer&lt;/item&gt;
      &lt;item&gt;Executable file formats &lt;list rend="ul"&gt;&lt;item&gt;Kernel support for ELF binaries&lt;/item&gt;&lt;item&gt;Kernel support for scripts starting with #!&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Device Drivers &lt;list rend="ul"&gt;&lt;item&gt;Block devices &lt;list rend="ul"&gt;&lt;item&gt;Normal floppydisk support&lt;/item&gt;&lt;item&gt;RAM block device support &lt;list rend="ul"&gt;&lt;item&gt;Default number of RAM disk: 1&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Character devices &lt;list rend="ul"&gt;&lt;item&gt;Enable TTY&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Block devices &lt;/item&gt;
      &lt;item&gt;File systems &lt;list rend="ul"&gt;&lt;item&gt;DOS/FAT/EXFAT/NT Filesystems &lt;list rend="ul"&gt;&lt;item&gt;MSDOS fs support&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Pseudo filesystems &lt;list rend="ul"&gt;&lt;item&gt;/proc file system support&lt;/item&gt;&lt;item&gt;sysfs file system support&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Native language support &lt;list rend="ul"&gt;&lt;item&gt;Codepage 437&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;DOS/FAT/EXFAT/NT Filesystems &lt;/item&gt;
      &lt;item&gt;Library routines &lt;list rend="ul"&gt;&lt;item&gt;XZ decompression and uncheck everything under it&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Exit configuration (yes, save settings to .config).&lt;/p&gt;
    &lt;p&gt;Time for compiling!&lt;/p&gt;
    &lt;head rend="h3"&gt;Compile Kernel&lt;/head&gt;
    &lt;code&gt;make ARCH=x86 bzImage -j$(nproc)&lt;/code&gt;
    &lt;p&gt;This will take a while depending on the speed of your CPU. In the end the kernel will be created in arch/x86/boot/ as bzImage file.&lt;/p&gt;
    &lt;p&gt;Move kernel to our main directory and go back to it:&lt;/p&gt;
    &lt;code&gt;mv arch/x86/boot/bzImage ../
cd ..&lt;/code&gt;
    &lt;head rend="h2"&gt;Toolset&lt;/head&gt;
    &lt;p&gt;Without tools kernel will just boot and you will not be able to do anything. One of the most popular lightweight tools is BusyBox. It replaces the standard GNU utilities with way smaller but still functional alternatives, perfect for embedded needs.&lt;/p&gt;
    &lt;p&gt;Get the 1.36.1 version from busybox.net or Github mirror. Download the file, extract it, and change directory:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Remember to be in the working directory.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;code&gt;wget https://github.com/mirror/busybox/archive/refs/tags/1_36_1.tar.gz
tar xzvf 1_36_1.tar.gz
rm 1_36_1.tar.gz
cd busybox-1_36_1/&lt;/code&gt;
    &lt;p&gt;As with kernel you need to create starting configuration:&lt;/p&gt;
    &lt;code&gt;make ARCH=x86 allnoconfig&lt;/code&gt;
    &lt;quote&gt;
      &lt;p&gt;You may skip this following fix if you are building on Debian/Fedora&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Fix for Arch Linux based distributions:&lt;/p&gt;
    &lt;code&gt;sed -i 's/main() {}/int main() {}/' scripts/kconfig/lxdialog/check-lxdialog.sh&lt;/code&gt;
    &lt;quote&gt;
      &lt;p&gt;Now the fun part. You need to choose what tools you want. Each menu entry will show how much more KB will be taken if you choose it. So choose it wisely :) For the first time use my selection.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Run the configurator:&lt;/p&gt;
    &lt;code&gt;make ARCH=x86 menuconfig&lt;/code&gt;
    &lt;p&gt;Choose the following options. Remember to do not uncheck anything if not stated here.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Settings &lt;list rend="ul"&gt;&lt;item&gt;Support files &lt;list rend="ul"&gt;&lt;item&gt;2GB&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Build static binary (no shared libs)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Support files &lt;/item&gt;
      &lt;item&gt;Coreutils &lt;list rend="ul"&gt;&lt;item&gt;cat&lt;/item&gt;&lt;item&gt;cp&lt;/item&gt;&lt;item&gt;df&lt;/item&gt;&lt;item&gt;echo&lt;/item&gt;&lt;item&gt;ls&lt;/item&gt;&lt;item&gt;mkdir&lt;/item&gt;&lt;item&gt;mv&lt;/item&gt;&lt;item&gt;rm&lt;/item&gt;&lt;item&gt;sync&lt;/item&gt;&lt;item&gt;test &lt;list rend="ul"&gt;&lt;item&gt;test as [&lt;/item&gt;&lt;item&gt;test as [[&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Console Utilities &lt;list rend="ul"&gt;&lt;item&gt;clear&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Editors &lt;list rend="ul"&gt;&lt;item&gt;vi&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Init Utilities &lt;list rend="ul"&gt;&lt;item&gt;init &lt;list rend="ul"&gt;&lt;item&gt;uncheck everything else (inside init: keep [*] only on init in this page)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;init &lt;/item&gt;
      &lt;item&gt;Linux System Utilities &lt;list rend="ul"&gt;&lt;item&gt;mdev&lt;/item&gt;&lt;item&gt;mount &lt;list rend="ul"&gt;&lt;item&gt;Support lots of -o flags&lt;/item&gt;&lt;item&gt;uncheck evrything else&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;umount&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Miscellaneous Utilities &lt;list rend="ul"&gt;&lt;item&gt;uncheck readahead&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Shells &lt;list rend="ul"&gt;&lt;item&gt;Choose alias as (ash)&lt;/item&gt;&lt;item&gt;ash&lt;/item&gt;&lt;item&gt;Optimize for size instead of speed&lt;/item&gt;&lt;item&gt;Alias support&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Now exit with save config.&lt;/p&gt;
    &lt;head rend="h3"&gt;Cross Compiler Setup&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Our target system needs to be 32-bit. To compile it on 64-bit system we need a cross compiler. You can setup this by hand in the menuconfig or just copy and paste those four lines.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Setup paths:&lt;/p&gt;
    &lt;code&gt;sed -i "s|.*CONFIG_CROSS_COMPILER_PREFIX.*|CONFIG_CROSS_COMPILER_PREFIX=\"${BASE}/i486-linux-musl-cross/bin/i486-linux-musl-\"|" .config

sed -i "s|.*CONFIG_SYSROOT.*|CONFIG_SYSROOT=\"${BASE}/i486-linux-musl-cross\"|" .config

sed -i "s|.*CONFIG_EXTRA_CFLAGS.*|CONFIG_EXTRA_CFLAGS=-I$BASE/i486-linux-musl-cross/include|" .config

sed -i "s|.*CONFIG_EXTRA_LDFLAGS.*|CONFIG_EXTRA_LDFLAGS=-L$BASE/i486-linux-musl-cross/lib|" .config&lt;/code&gt;
    &lt;head rend="h3"&gt;Compile BusyBox&lt;/head&gt;
    &lt;p&gt;Build tools and create base filesystem (âinstallâ). It will ask for options, just press enter for default for all of them.&lt;/p&gt;
    &lt;code&gt;make ARCH=x86 -j$(nproc) &amp;amp;&amp;amp; make ARCH=x86 install&lt;/code&gt;
    &lt;p&gt;This will create a filesystem with all the files at **_install/**. Move it to our main directory. I like to rename it to.&lt;/p&gt;
    &lt;p&gt;Lastly to to that new directory.&lt;/p&gt;
    &lt;code&gt;mv _install ../filesystem
cd ../filesystem&lt;/code&gt;
    &lt;head rend="h2"&gt;Filesystem&lt;/head&gt;
    &lt;p&gt;You got kernel and basic tools but the system still needs some additional directory structure.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;This created minimum viable directory structure for satisfying the basic requirements of a Linux system.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Remember to be in the filesystem/ directory.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;code&gt;mkdir -pv {dev,proc,etc/init.d,sys,tmp,home}
sudo mknod dev/console c 5 1
sudo mknod dev/null c 1 3&lt;/code&gt;
    &lt;p&gt;Next step is to add minimum configuration files. First one is a welcome message that will be shown after booting.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Here is the first real opportunity to go wild and make this your own signature.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;code&gt;cat &amp;gt;&amp;gt; welcome &amp;lt;&amp;lt; EOF
Your welome message or ASCII art.
EOF&lt;/code&gt;
    &lt;p&gt;Or download my welcome file.&lt;/p&gt;
    &lt;code&gt;wget https://krzysztofjankowski.com/floppinux/downloads/0.3.1/welcome&lt;/code&gt;
    &lt;p&gt;It looks like that:&lt;/p&gt;
    &lt;code&gt;$ cat welcome

                _________________
               /_/ FLOPPINUX  /_/;
              / ' boot disk  ' //
             / '------------' //
            /   .--------.   //
           /   /         /  //
          .___/_________/__//   1440KiB
          '===\_________\=='   3.5"

_______FLOPPINUX_V_0.3.1 __________________________________
_______AN_EMBEDDED_SINGLE_FLOPPY_LINUX_DISTRIBUTION _______
_______BY_KRZYSZTOF_KRYSTIAN_JANKOWSKI ____________________
_______2025.12 ____________________________________________&lt;/code&gt;
    &lt;quote&gt;
      &lt;p&gt;Back to serious stuff. Inittab tells the system what to do in critical states like starting, exiting and restarting. It points to the initialization script rc that is the first thing that our OS will run before dropping into the shell.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Create an inittab file:&lt;/p&gt;
    &lt;code&gt;cat &amp;gt;&amp;gt; etc/inittab &amp;lt;&amp;lt; EOF
::sysinit:/etc/init.d/rc
::askfirst:/bin/sh
::restart:/sbin/init
::ctrlaltdel:/sbin/reboot
::shutdown:/bin/umount -a -r
EOF&lt;/code&gt;
    &lt;p&gt;And the init rc script:&lt;/p&gt;
    &lt;code&gt;cat &amp;gt;&amp;gt; etc/init.d/rc &amp;lt;&amp;lt; EOF
#!/bin/sh
mount -t proc none /proc
mount -t sysfs none /sys
mdev -s
ln -s /proc/mounts /etc/mtab
mkdir -p /mnt /home
mount -t msdos -o rw /dev/fd0 /mnt
mkdir -p /mnt/data
mount --bind /mnt/data /home
clear
cat welcome
cd /home
/bin/sh
EOF&lt;/code&gt;
    &lt;p&gt;Make the script executable and owner of all files to root:&lt;/p&gt;
    &lt;code&gt;chmod +x etc/init.d/rc
sudo chown -R root:root .&lt;/code&gt;
    &lt;p&gt;Compress this directory into one file. Then go back to working directory.&lt;/p&gt;
    &lt;code&gt;find . | cpio -H newc -o | xz --check=crc32 --lzma2=dict=512KiB -e &amp;gt; ../rootfs.cpio.xz
cd ..&lt;/code&gt;
    &lt;p&gt;Create booting configuration.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Another place to tweak parameters for your variant. Text after SAY is what will be displayed on the screen as first, usualy a name of the OS.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;The tsc=unstable is useful on some (real) computers to get rid of randomly shown warnings about Time Stamp Counter.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Remember to be in the working directory.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;code&gt;cat &amp;gt;&amp;gt; syslinux.cfg &amp;lt;&amp;lt; EOF
DEFAULT floppinux
LABEL floppinux
SAY [ BOOTING FLOPPINUX VERSION 0.3.1 ]
KERNEL bzImage
INITRD rootfs.cpio.xz
APPEND root=/dev/ram rdinit=/etc/init.d/rc console=tty0 tsc=unstable
EOF&lt;/code&gt;
    &lt;p&gt;Make it executable:&lt;/p&gt;
    &lt;code&gt;chmod +x syslinux.cfg&lt;/code&gt;
    &lt;p&gt;Create sample file&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;To make the system a little bit more user friendly I like to have a sample file that user will be able to read and edit. You can put anything you want in it. A simple help would be also a good idea to include.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;code&gt;cat &amp;gt;&amp;gt; hello.txt &amp;lt;&amp;lt; EOF
Hello, FLOPPINUX user!
EOF&lt;/code&gt;
    &lt;p&gt;Filesystem is ready. Final step is to put this all on a floppy!&lt;/p&gt;
    &lt;head rend="h2"&gt;Boot Image&lt;/head&gt;
    &lt;p&gt;First we need an empty file in exact size of a floppy disk. Then format and make it bootable.&lt;/p&gt;
    &lt;p&gt;Create empty floppy image:&lt;/p&gt;
    &lt;code&gt;dd if=/dev/zero of=floppinux.img bs=1k count=1440&lt;/code&gt;
    &lt;p&gt;Format it and create bootloader:&lt;/p&gt;
    &lt;code&gt;mkdosfs -n FLOPPINUX floppinux.img
syslinux --install floppinux.img&lt;/code&gt;
    &lt;p&gt;Mount it and copy syslinux, kernel, and filesystem onto it:&lt;/p&gt;
    &lt;code&gt;sudo mount -o loop floppinux.img /mnt
sudo mkdir /mnt/data
sudo cp hello.txt /mnt/data/
sudo cp bzImage /mnt
sudo cp rootfs.cpio.xz /mnt
sudo cp syslinux.cfg /mnt
sudo umount /mnt&lt;/code&gt;
    &lt;p&gt;Done!&lt;/p&gt;
    &lt;head rend="h3"&gt;Test in emulator&lt;/head&gt;
    &lt;p&gt;Itâs good to test before wasting time for the real floppy to burn.&lt;/p&gt;
    &lt;p&gt;Boot the new OS in qemu:&lt;/p&gt;
    &lt;code&gt;qemu-system-i386 -fda floppinux.img -m 20M -cpu 486&lt;/code&gt;
    &lt;p&gt;If it worked that means You have successfully created your own distribution! Congratulations!&lt;/p&gt;
    &lt;p&gt;The floppinux.img image is ready to burn onto a floppy and boot on real hardware!&lt;/p&gt;
    &lt;head rend="h2"&gt;Floppy Disk&lt;/head&gt;
    &lt;head rend="h3"&gt;&amp;lt;!&amp;gt; Important &amp;lt;!&amp;gt;&lt;/head&gt;
    &lt;p&gt;Change XXX to floppy drive name in your system. In my case it is sdb. Choosing wrongly will NUKE YOUR PARTITION and REMOVE all of your files! Think twice. Or use some GUI application for that.&lt;/p&gt;
    &lt;code&gt;sudo dd if=floppinux.img of=/dev/XXX bs=512 conv=notrunc,sync,fsync oflag=direct status=progress&lt;/code&gt;
    &lt;p&gt;After 5 minutes I got freshly burned floppy.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;FLOPPINUX: 0.3.1 (December 2025)&lt;/item&gt;
      &lt;item&gt;Linux Kernel: 6.14.11&lt;/item&gt;
      &lt;item&gt;Busybox: 1.36.1&lt;/item&gt;
      &lt;item&gt;Image size: 1440KiB / 1.44MiB&lt;/item&gt;
      &lt;item&gt;Kernel size: 881KiB (bzImage)&lt;/item&gt;
      &lt;item&gt;Tools: 137KiB (rootfs.cpio.xz)&lt;/item&gt;
      &lt;item&gt;Free space left (df -h): 253KiB&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;System Tools&lt;/head&gt;
    &lt;head rend="h4"&gt;File &amp;amp; Directory Manipulation&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;cat&lt;/code&gt;- display file contents&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;cp&lt;/code&gt;- copy files and directories&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;mv&lt;/code&gt;- move/rename files and directories&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rm&lt;/code&gt;- remove files and directories&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ls&lt;/code&gt;- list directory contents&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;mkdir&lt;/code&gt;- creates directory&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;System Information &amp;amp; Management&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;df -h&lt;/code&gt;- display filesystem disk space usage&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;sync&lt;/code&gt;- force write of buffered data to disk - use this after any changes to the floppy filesystem&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;mount&lt;/code&gt;- mount filesystems&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;umount&lt;/code&gt;- unmount filesystems&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Text Processing &amp;amp; Output&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;echo&lt;/code&gt;- display text output&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;more&lt;/code&gt;- page through text output&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Utilities&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;clear&lt;/code&gt;- clear terminal screen&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;test&lt;/code&gt;- evaluate conditional expressions&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Applications&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;vi&lt;/code&gt;- text editor&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46866544</guid><pubDate>Tue, 03 Feb 2026 04:33:25 +0000</pubDate></item><item><title>Show HN: Minikv – Distributed key-value and object store in Rust (Raft, S3 API)</title><link>https://github.com/whispem/minikv</link><description>&lt;doc fingerprint="ee59d01e2ff04f9b"&gt;
  &lt;main&gt;
    &lt;p&gt;A distributed, multi-tenant key-value &amp;amp; object store written in Rust&lt;/p&gt;
    &lt;p&gt;minikv provides strong consistency (Raft + 2PC), durability (WAL), and production-grade observability, security, and multi-tenancy — all in a modern Rust codebase.&lt;/p&gt;
    &lt;p&gt;Built in public as a learning-by-doing project — now evolved into a complete, reference implementation of distributed systems in Rust.&lt;/p&gt;
    &lt;p&gt;minikv v0.8.0 brings enterprise-grade features for distributed deployments:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cross-datacenter replication: Async replication with multiple conflict resolution strategies (LWW, Vector Clocks)&lt;/item&gt;
      &lt;item&gt;Change Data Capture (CDC): Real-time event streaming to Webhook, Kafka, or file sinks&lt;/item&gt;
      &lt;item&gt;Admin Web UI: Embedded dashboard for cluster monitoring and management&lt;/item&gt;
      &lt;item&gt;Backup &amp;amp; Restore: Full and incremental backups with encryption support&lt;/item&gt;
      &lt;item&gt;Plugin system: Extensible architecture for custom storage, auth, and hooks&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Previous highlights (v0.7.0): secondary indexes, multi-key transactions, batch import/export, durable S3 backend.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;What is minikv?&lt;/item&gt;
      &lt;item&gt;Tech Stack&lt;/item&gt;
      &lt;item&gt;Quick Start&lt;/item&gt;
      &lt;item&gt;Architecture&lt;/item&gt;
      &lt;item&gt;Performance&lt;/item&gt;
      &lt;item&gt;Features&lt;/item&gt;
      &lt;item&gt;Roadmap&lt;/item&gt;
      &lt;item&gt;Story&lt;/item&gt;
      &lt;item&gt;Documentation&lt;/item&gt;
      &lt;item&gt;Development&lt;/item&gt;
      &lt;item&gt;Contributing&lt;/item&gt;
      &lt;item&gt;Contact&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;minikv is a distributed key-value store written in Rust, designed for simplicity, speed, and reliability.&lt;/p&gt;
    &lt;p&gt;Who is this for ?&lt;lb/&gt; minikv is for engineers learning distributed systems, teams experimenting with Rust-based infrastructure, and anyone curious about consensus, durability, and system trade-offs.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Clustered : Raft consensus and 2PC for transactional writes&lt;/item&gt;
      &lt;item&gt;Virtual Sharding : 256 vshards for elastic scaling &amp;amp; balancing&lt;/item&gt;
      &lt;item&gt;WAL : Write-ahead log for durability&lt;/item&gt;
      &lt;item&gt;gRPC for node communication, HTTP REST &amp;amp; S3 API for clients&lt;/item&gt;
      &lt;item&gt;Bloom filters, snapshots, watch/subscribe for performance &amp;amp; reactivity&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Rust – core logic&lt;/item&gt;
      &lt;item&gt;Shell – orchestration/automation&lt;/item&gt;
      &lt;item&gt;JavaScript – benchmarks, tools&lt;/item&gt;
      &lt;item&gt;Makefile – build flows&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;git clone https://github.com/whispem/minikv.git
cd minikv
cargo build --release

# Start a node
cargo run -- --config config.example.toml

# API examples
curl localhost:8080/health/ready   # readiness
curl localhost:8080/metrics        # Prometheus metrics
curl localhost:8080/admin/status   # admin dashboard

# Create API key (admin)
curl -X POST http://localhost:8080/admin/keys -d '{"role":"ReadWrite","tenant_id":"acme"}'

# S3 (demo)
curl -X PUT localhost:8080/s3/mybucket/mykey -d 'hello minikv!'
curl localhost:8080/s3/mybucket/mykey&lt;/code&gt;
    &lt;p&gt;For cluster setup and advanced options, see the documentation.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Raft: consensus and leader election&lt;/item&gt;
      &lt;item&gt;2PC: atomic distributed/batch writes&lt;/item&gt;
      &lt;item&gt;Virtual Shards: scale and rebalance across 256 partitions&lt;/item&gt;
      &lt;item&gt;Pluggable Storage: in-memory, RocksDB, Sled&lt;/item&gt;
      &lt;item&gt;Admin API: HTTP endpoints for status, metrics and config&lt;/item&gt;
      &lt;item&gt;Config: via environment, file or CLI flags&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Write throughput : over 50,000 operations/sec (single node, in-memory)&lt;/item&gt;
      &lt;item&gt;Sub-millisecond read latency&lt;/item&gt;
      &lt;item&gt;Cluster tested (3–5 nodes, commodity VMs)&lt;/item&gt;
      &lt;item&gt;Built-in Prometheus metrics&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Raft consensus (multi-node, strong consistency)&lt;/item&gt;
      &lt;item&gt;Two-phase commit (2PC) for atomic multi-key transactions&lt;/item&gt;
      &lt;item&gt;256 virtual shards for cluster scaling and rebalancing&lt;/item&gt;
      &lt;item&gt;Write-ahead log (WAL) for durability&lt;/item&gt;
      &lt;item&gt;Auto-rebalancing, graceful leader failover, hot-join and node removal&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Time-To-Live keys (TTL)&lt;/item&gt;
      &lt;item&gt;LZ4 compression (configurable)&lt;/item&gt;
      &lt;item&gt;Bloom filters and index snapshots&lt;/item&gt;
      &lt;item&gt;Pluggable and persistent storage: in-memory, RocksDB, Sled&lt;/item&gt;
      &lt;item&gt;Batch &amp;amp; range operations, prefix queries&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;HTTP REST (CRUD, batch, range, admin)&lt;/item&gt;
      &lt;item&gt;S3-compatible API (with TTL extensions)&lt;/item&gt;
      &lt;item&gt;gRPC (internal)&lt;/item&gt;
      &lt;item&gt;WebSocket and SSE endpoints for real-time watch/subscribe events&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;API keys (Argon2) and JWT authentication&lt;/item&gt;
      &lt;item&gt;Role-based access control (RBAC) and audit logging&lt;/item&gt;
      &lt;item&gt;Multi-tenant isolation&lt;/item&gt;
      &lt;item&gt;AES-256-GCM encryption at rest&lt;/item&gt;
      &lt;item&gt;Per-tenant quotas (storage, requests, rate limits)&lt;/item&gt;
      &lt;item&gt;TLS (HTTP &amp;amp; gRPC)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Admin dashboard&lt;/item&gt;
      &lt;item&gt;Prometheus metrics (counters, histograms)&lt;/item&gt;
      &lt;item&gt;Request and endpoint statistics&lt;/item&gt;
      &lt;item&gt;Structured logging and tracing spans&lt;/item&gt;
      &lt;item&gt;Kubernetes health probes&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Memory-safe Rust&lt;/item&gt;
      &lt;item&gt;Test suite, automated CI&lt;/item&gt;
      &lt;item&gt;Documentation and sample config&lt;/item&gt;
      &lt;item&gt;Single static binary&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cross-datacenter replication&lt;/item&gt;
      &lt;item&gt;Change Data Capture (CDC)&lt;/item&gt;
      &lt;item&gt;Admin Web UI&lt;/item&gt;
      &lt;item&gt;Backup &amp;amp; Restore&lt;/item&gt;
      &lt;item&gt;Plugin system&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Secondary indexes&lt;/item&gt;
      &lt;item&gt;Multi-key transactions&lt;/item&gt;
      &lt;item&gt;Durable S3-backed object store&lt;/item&gt;
      &lt;item&gt;Batch import/export&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Kubernetes Operator&lt;/item&gt;
      &lt;item&gt;GraphQL API&lt;/item&gt;
      &lt;item&gt;Time-series optimizations&lt;/item&gt;
      &lt;item&gt;Geo-partitioning&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;minikv started as a 24-hour challenge by a Rust learner (82 days into the language!). It now serves as both a playground and a reference for distributed systems, demonstrating curiosity, learning-by-doing, and robust engineering.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Example config : &lt;code&gt;config.example.toml&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Cluster, API, usage : see &lt;code&gt;docs/&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Certificate generation : &lt;code&gt;certs/README.md&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;cargo test           # Run all tests
cargo clippy --fix   # Lint and fix
cargo fmt            # Format code&lt;/code&gt;
    &lt;p&gt;Continuous Integration runs on push &amp;amp; PR via &lt;code&gt;.github/workflows/ci.yml&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Issues and PRs welcome! See CONTRIBUTING.md.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GitHub: whispem/minikv&lt;/item&gt;
      &lt;item&gt;Email: via GitHub profile&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46867947</guid><pubDate>Tue, 03 Feb 2026 08:00:19 +0000</pubDate></item><item><title>LNAI – Define AI coding tool configs once, sync to Claude, Cursor, Codex, etc.</title><link>https://github.com/KrystianJonca/lnai</link><description>&lt;doc fingerprint="12953a5fcfbbaedc"&gt;
  &lt;main&gt;
    &lt;p&gt;Stop maintaining separate config files for every AI coding tool. Define once in &lt;code&gt;.ai/&lt;/code&gt;, sync everywhere.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;One source of truth — Write your project rules, MCP servers, and permissions once&lt;/item&gt;
      &lt;item&gt;Works with your tools — Syncs to native formats each tool actually reads&lt;/item&gt;
      &lt;item&gt;Stay in sync — Update &lt;code&gt;.ai/&lt;/code&gt;and run&lt;code&gt;lnai sync&lt;/code&gt;to propagate changes instantly&lt;/item&gt;
      &lt;item&gt;Automatic cleanup — Orphaned files are removed when configs change&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Tool&lt;/cell&gt;
        &lt;cell role="head"&gt;Config Generated&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Claude Code&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;.claude/&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Codex&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;.codex/&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Cursor&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;.cursor/&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Gemini CLI&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;.gemini/&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;GitHub Copilot&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;.github/copilot-instructions.md&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;OpenCode&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;.opencode/&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Windsurf&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;.windsurf/&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;npm install -g lnai

lnai init      # Create .ai/ configuration
lnai validate  # Check for errors
lnai sync      # Export to native tool configs&lt;/code&gt;
    &lt;p&gt;Full guides and configuration reference at lnai.sh&lt;/p&gt;
    &lt;p&gt;MIT&lt;/p&gt;
    &lt;p&gt;If you find LNAI helpful, please star us on GitHub!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46868318</guid><pubDate>Tue, 03 Feb 2026 08:45:57 +0000</pubDate></item><item><title>Show HN: Safe-now.live – Ultra-light emergency info site (&lt;10KB)</title><link>https://safe-now.live</link><description>&lt;doc fingerprint="ca634b944ef574a1"&gt;
  &lt;main&gt;&lt;head rend="h2"&gt;⚠ Active Disasters &amp;amp; Declarations (FEMA | EC)&lt;/head&gt;🇺🇸 USA: ❄ SEVERE WINTER STORM (WV) | ❄ SEVERE WINTER STORM (NC) | ❄ SEVERE WINTER STORM (IN) | ❄ SEVERE WINTER STORM (KY) | ❄ SEVERE WINTER STORM (TN) | ❄ SEVERE WINTER STORM (AR)&lt;head rend="h2"&gt;📍 Find Local Info&lt;/head&gt;&lt;p&gt;United States: AL AK AZ AR CA CO CT DE DC FL GA HI ID IL IN IA KS KY LA ME MD MA MI MN MS MO MT NE NV NH NJ NM NY NC ND OH OK OR PA PR RI SC SD TN TX UT VT VA WA WV WI WY | VI AS GU MP&lt;/p&gt;&lt;p&gt;Canada: AB BC MB NB NL NS NT NU ON PE QC SK YT&lt;/p&gt;&lt;p&gt;International: UK/EU 112 | AU 000 | NZ 111 | JP 110/119 | MX 911 | BR 190&lt;/p&gt;&lt;head rend="h2"&gt;🆘 Quick Reference&lt;/head&gt;Earthquake: Drop, Cover, Hold On&lt;p&gt;Tornado: Lowest floor, interior room&lt;/p&gt;&lt;p&gt;Flood: Higher ground - Turn around, don't drown&lt;/p&gt;&lt;p&gt;Fire: Get out, stay out, call 911&lt;/p&gt;&lt;p&gt;Gas leak: Leave immediately, don't use electronics&lt;/p&gt;&lt;p&gt;Chemical: Move upwind, shelter in place&lt;/p&gt;&lt;p&gt;Active threat: Run, Hide, Fight&lt;/p&gt;&lt;p&gt;CO alarm: Get outside, call 911, don't re-enter&lt;/p&gt;&lt;p&gt;Flood water: Turn off electricity at breaker before contact&lt;/p&gt;&lt;p&gt;Lightning: Get inside; avoid trees, water, metal; crouch if stuck outside&lt;/p&gt;&lt;p&gt;Tsunami: Move inland and uphill immediately; don't wait&lt;/p&gt;&lt;p&gt;Power out: Fridge safe 4hrs, freezer 48hrs if closed&lt;/p&gt;&lt;p&gt;Heat stroke: Cool rapidly with water/ice; call 911; confusion is danger sign&lt;/p&gt;&lt;p&gt;Hypothermia: Remove wet clothes; warm gradually; hot drinks if conscious&lt;/p&gt;&lt;p&gt;Civil unrest: Avoid crowds; get indoors; don't engage; document if safe&lt;/p&gt;&lt;head rend="h2"&gt;🎒 Emergency Kit&lt;/head&gt;- Water/Food: Water: 1 gal/4L per person per day; Water purification tablets; Non-perishable food&lt;p&gt;- Medical: First aid kit; Prescription medications; Infant/special needs items; N95 masks&lt;/p&gt;&lt;p&gt;- Tools/Comms: Flashlight + batteries; Battery/crank radio; Whistle; Phone + charger; Wrench (utilities)&lt;/p&gt;&lt;p&gt;- Docs/Money: Cash in small bills; Copies: IDs, insurance, bank; Emergency contacts; Local maps&lt;/p&gt;&lt;p&gt;- Shelter/Clothing: Emergency blanket; Change of clothes; Sturdy shoes; Rain gear&lt;/p&gt;&lt;p&gt;- Sanitation: Moist towelettes; Garbage bags + ties; Bleach; Personal hygiene items&lt;/p&gt;&lt;p&gt;Source: Ready.gov / GetPrepared.gc.ca&lt;/p&gt;&lt;head rend="h2"&gt;🏠 Home Prep&lt;/head&gt;- Know: 2 evacuation routes; Family communication plan; Utility shutoffs (gas, water, electric); Nearest shelters; How to receive alerts&lt;p&gt;- Safety: Test smoke/CO detectors monthly; Secure water heater + heavy furniture; Fire extinguisher accessible; Know shelter-in-place location&lt;/p&gt;&lt;p&gt;- Power Outage: Generator: OUTSIDE ONLY; Keep 20ft/6m from openings (CO risk)&lt;/p&gt;&lt;p&gt;- Pets: ID tags + microchip; Carrier/leash; Food/water; Medications; Vaccination records&lt;/p&gt;&lt;p&gt;- Children: Comfort item; ID bracelet; Emergency contact card; Age-appropriate instructions&lt;/p&gt;&lt;head rend="h2"&gt;💰 Financial Help&lt;/head&gt;Disaster Aid: FEMA (housing, repairs, personal property) | SBA Loans (low-interest loans)&lt;p&gt;Benefits: 211 connects to local aid | Benefits.gov finder | SNAP/Food stamps&lt;/p&gt;&lt;p&gt;Tip: Document damage with photos BEFORE cleanup; keep all receipts&lt;/p&gt;&lt;head rend="h2"&gt;🔄 Recovery&lt;/head&gt;Before entering: Wait for official all-clear; check for gas smell, structural damage&lt;p&gt;Inside: No electricity if flooding; photograph everything; wear N95 + gloves&lt;/p&gt;&lt;p&gt;Food safety: Discard if power out 4+ hrs (fridge) or thawed (freezer); when in doubt, throw it out&lt;/p&gt;&lt;p&gt;Mold: Appears within 24-48 hrs; dry everything; clean with water/detergent; consider N95&lt;/p&gt;&lt;p&gt;Avoid: Contractor scams (get multiple bids, check licenses); price gouging (report to AG)&lt;/p&gt;&lt;head rend="h2"&gt;📚 Resources&lt;/head&gt;Guides: Emergency Guide | First Aid | Shelter &amp;amp; Safety&lt;p&gt;USA: FEMA 1-800-621-3362 (no immigration check) | Shelters 1-800-733-2767 | 211 Food/housing/utilities | Power Outages&lt;/p&gt;&lt;p&gt;Crisis Lines: Veterans 988 press 1 | DV Hotline 1-800-799-7233 | SAMHSA 1-800-662-4357&lt;/p&gt;&lt;p&gt;Canada: GetPrepared.gc.ca | Red Cross Canada | Weather Alerts&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46868479</guid><pubDate>Tue, 03 Feb 2026 09:06:04 +0000</pubDate></item><item><title>What's up with all those equals signs anyway?</title><link>https://lars.ingebrigtsen.no/2026/02/02/whats-up-with-all-those-equals-signs-anyway/</link><description>&lt;doc fingerprint="6ff2d15d65fe3faf"&gt;
  &lt;main&gt;
    &lt;p&gt;For some reason or other, people have been posting a lot of excerpts from old emails on Twitter over the last few days. The most vital question everybody’s asking themselves is: What’s up with all those equals signs?!&lt;/p&gt;
    &lt;p&gt;And that’s something I’m somewhat of an expert on. I mean, having written mail readers and stuff; not because I’ve been to Caribbean islands.&lt;/p&gt;
    &lt;p&gt;I’ve seen people confidently claim that it’s a code, or that it’s an artefact of scanning and then using OCR, but it’s neither — it’s just that whoever converted these emails to a readable format were morons.&lt;/p&gt;
    &lt;p&gt;What’s that you say? “Converted?! Surely emails are just text!!” Well, if you lived in the stone age (i.e., the 80s), they mostly were, but then people invented things like “long lines” and “rock döts”, and computers had to “encode” the mail before sending.&lt;/p&gt;
    &lt;p&gt;The artefact we see here is from something called “quoted printable”, or as we used to call it when it was introduced: “Quoted unreadable”.&lt;/p&gt;
    &lt;p&gt;To take the first line. Whoever wrote this, typed in the following in their mail reader:&lt;/p&gt;
    &lt;quote&gt;we talked about designing a pig with different non- cloven hoofs in order to make kosher bacon&lt;/quote&gt;
    &lt;p&gt;We see that that’s quite a long line. Mail servers don’t like that, so mail software will break it into two lines, like so:&lt;/p&gt;
    &lt;quote&gt;we talked about designing a pig with different non- = cloven hoofs in order to make kosher bacon&lt;/quote&gt;
    &lt;p&gt;See? There’s that equals sign! Yes, the equals sign is used to say “this should really be one single line, but I’ve broken it in two so that the mail server doesn’t get mad at me”.&lt;/p&gt;
    &lt;p&gt;The formal definition here is important, though, so I have to be a bit technical here: To say “this is a continuation line”, you insert an equals sign, then a carriage return, and then a line feed.&lt;/p&gt;
    &lt;p&gt;Or,&lt;/p&gt;
    &lt;quote&gt;=CRLF&lt;/quote&gt;
    &lt;p&gt;Three characters in total, i.e., :&lt;/p&gt;
    &lt;quote&gt;... non- =CRLF cloven hoofs...&lt;/quote&gt;
    &lt;p&gt;When displaying this, we remove all these three characters, and end up&lt;lb/&gt; with:&lt;/p&gt;
    &lt;quote&gt;... non- cloven hoofs...&lt;/quote&gt;
    &lt;p&gt;So what’s happened here? Well, whoever collected these emails first converted from CRLF (also known as the “Windows” line ending coding, but it’s the standard line ending in the SMTP standard) to “NL” (i.e., “Unix” line ending coding). This is pretty normal if you want to deal with email. But you then have one byte fewer:&lt;/p&gt;
    &lt;quote&gt;... non- =NL cloven hoofs...&lt;/quote&gt;
    &lt;p&gt;If your algorithm to decode this is, stupidly, “find equals signs at the end of the line, and then delete two characters, and then finally the equals sign”, you should end up with:&lt;/p&gt;
    &lt;quote&gt;... non- loven hoofs...&lt;/quote&gt;
    &lt;p&gt;I.e., you lose the “c”. That’s almost what happened here, but not quite: Why does the equals sign still remain?&lt;/p&gt;
    &lt;p&gt;This StackOverflow post from 14 years ago explains the phenomenon, sort of:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Obviously the client notices that = is not followed by a proper CR LF sequence, so it assumes that it is not a soft line break, but a character encoded in two hex digits, therefore it reads the next two bytes. It should notice that the next two bytes are not valid hex digits, so its behavior is wrong too, but we have to admit that at that point it does not have a chance to display something useful. They opted for the garbage in, garbage out approach.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That is, equals signs are also used for something else besides wrapping long lines, and that’s what we see later in the post:&lt;/p&gt;
    &lt;quote&gt;=C2 please note&lt;/quote&gt;
    &lt;p&gt;If the equals sign is not at the end of a line, it’s used to encode “funny characters”, like what you use with “rock döts”. =C2 is 194, which is a first character in a UTF-8 sequence, and the following char is most likely a =A0: =C2=A0 is “non-breakable space”, which is something people often use to indent text (and the “please note” is indented) and you see =A0 in many other places in these emails.&lt;/p&gt;
    &lt;p&gt;My guess is that whoever did this part just did a search-replace for =C2 and/or =A0 instead of using a proper decoder, but other explanations are certainly possible. Any ideas?&lt;/p&gt;
    &lt;p&gt;Anyway, that’s what’s up with those equals signs: 1) “it’s technical”, and 2) “it’s a combination of buggy continuation line decoding and buggy non-ASCII decoding”, and 3) “whoever processed these mails are incompetent”. I don’t think 2) should be very surprising at this point, do you?&lt;/p&gt;
    &lt;p&gt;(Edit a bit later: To nitpick a bit here: When the standard was written, people mostly envisioned that the quoted-printable content transport encoding would be unwound upon reception (note “transport”), and that you’d end up with “clean text” on disk after reception. This didn’t really happen, so all “real” implementations do the right thing with single-character (i.e., “unencoded”) newlines. For instance:&lt;/p&gt;
    &lt;quote&gt;(quoted-printable-decode-string "he=\nllo") =&amp;gt; "hello"&lt;/quote&gt;
    &lt;p&gt;Which leads me to assume that they reused an algo that was usually run in an SMTP server context to do the line unfolding — in that context, you can safely assume that the line ending is a CRLF. And by chance, this algo also works fine if you’re working with a Windows-based file, but fails for a Unix-based file.)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46868759</guid><pubDate>Tue, 03 Feb 2026 09:37:40 +0000</pubDate></item><item><title>Emerge Career (YC S22) is hiring a product designer</title><link>https://www.ycombinator.com/companies/emerge-career/jobs/omqT34S-founding-product-designer</link><description>&lt;doc fingerprint="3d88781899c444b5"&gt;
  &lt;main&gt;
    &lt;p&gt;All-in-one re-entry &amp;amp; workforce development training platform&lt;/p&gt;
    &lt;p&gt;Emerge Career’s mission is to break the cycle of poverty and incarceration. We’re not just building software; we’re creating pathways to real second chances. Through an all-in-one platform deeply embedded within the criminal justice system, we recruit, train, and place justice-impacted individuals into life-changing careers.&lt;/p&gt;
    &lt;p&gt;Our vision is to become the country’s unified workforce development system, replacing disconnected brick-and-mortar job centers with one integrated, tech-powered solution that meets low-income individuals exactly where they are. Today, the federal government spends billions annually on education and training programs, yet only about 70% of participants graduate, just 38.6% secure training-related employment, and average first-year earnings hover around $34,708.&lt;/p&gt;
    &lt;p&gt;By contrast, our seven-person team has already outperformed the job centers in two entire states (Vermont and South Dakota) in just the past year. With an 89% graduation rate and 92% of graduates securing training-related employment, our alumni aren’t just getting jobs—they’re launching new lives with average first-year earnings of $77,352. The results speak for themselves, and we’re just getting started.&lt;/p&gt;
    &lt;p&gt;Before Emerge, our founders Zo and Gabe co-founded Ameelio, an award-winning tech nonprofit that is dismantling the prison communication duopoly. Backed by tech luminaries like Reid Hoffman, Vinod Khosla, and Jack Dorsey, and by major criminal-justice philanthropies such as Arnold Ventures and the Mellon Foundation, Ameelio became a recognized leader in the space. Because of this experience both Zo and Gabe understood what it took to create change from within the system. After serving over 1M people impacted by incarceration, they witnessed firsthand the gap in second-chance opportunities and the chronic unemployment plaguing those impacted by the justice system. Emerge Career is committed to solving this issue.&lt;/p&gt;
    &lt;p&gt;Our students are at the heart of our work. Their journeys have captured national attention on CBS, NBC, and in The Boston Globe, and our programs now serve entire states and cities. And we’re not doing it alone: our vision has attracted support from Alexis Ohanian (776), Michael Seibel, Y Combinator, the Opportunity Fund, and public figures like Diana Taurasi, Deandre Ayton, and Marshawn Lynch. All of us believe that, with the right mix of technology and hands-on practice, we can redefine workforce development and deliver true second chances at scale.&lt;/p&gt;
    &lt;p&gt;Emerge Career was designed to tackle two systemic issues: recidivism, fueled by post-incarceration unemployment and poverty, and labor shortages in key industries. Over 60% of formerly incarcerated people remain unemployed a year after incarceration, seeking work but not finding it. The reality is shocking, workforce development programs are severely limited inside prison, with only one-third of incarcerated people ever participating. To worsen, the available prison jobs offer meager wages, often less than $1 per hour, and often do not equip individuals with the skills for long-term stable employment.&lt;/p&gt;
    &lt;p&gt;We call this a Founding Design Engineer role, even three years in and with multiple contracts under our belt, for two reasons. First, you'll be our very first engineer, joining our co-founder, who's built the entire platform solo to date. Second, our growth is now outpacing our systems, and we can't keep up on maintenance alone. We're at a critical juncture: we can either hire someone to simply care for what exists, or we can bring on a talent who believes that, with the right blend of technology and hands-on practice, we can unify the workforce-development system and deliver second chances at true scale. We hope that can be you.&lt;/p&gt;
    &lt;p&gt;This is not a traditional engineering job. You'll build features in React and TypeScript, but your real job is helping students finish. That means understanding the human problem first: why do people disengage? What makes someone choose to keep going when the payoff is months away? You'll answer those questions through direct conversations, usability research, and watching how people actually use what you build. Then you'll prototype fast, ship real software, and measure whether it worked. Some days that looks like code. Other days it looks like a phone call, a support ticket, or a whiteboard session figuring out how to turn a one-off fix into a system that scales.&lt;/p&gt;
    &lt;p&gt;This role blends engineering, product, design, and program operations. We're looking for someone who believes good design can inspire a person to invest in their own future, and who wants to prove it, week after week, by shipping work that measurably helps students succeed. If you want to be close to users, own outcomes end to end, and build something that actually matters, you'll thrive here.&lt;/p&gt;
    &lt;p&gt;You design by building. You don't hand off mockups and wait. You open Cursor, Claude Code, or whatever gets you closest to a real, testable thing fastest. You might already be shipping code in production — or you're itching to. You believe the fastest path to a great design is putting something real in front of a real user and watching what happens.&lt;/p&gt;
    &lt;p&gt;You are relentlessly scrappy. You prototype in hours, not weeks. You'd rather test an ugly thing that teaches you something than polish a beautiful thing nobody's used yet. You know that at this stage, speed of learning is the only thing that matters. Fidelity comes later. Signal comes first.&lt;/p&gt;
    &lt;p&gt;You refuse to be blocked. When engineering bandwidth isn't there, you don't sit around. You figure it out — a Figma prototype, a coded prototype, a quick hack in the codebase. You treat "waiting for a developer" as a personal failure. You find a way or you make one.&lt;/p&gt;
    &lt;p&gt;You think in outcomes, not outputs. You don't measure your work in screens delivered. You measure it in whether students finished, whether they came back, whether the thing you shipped actually moved a number that matters. You're obsessed with the gap between what you designed and what actually happened.&lt;/p&gt;
    &lt;p&gt;You talk to users constantly. Not in scheduled quarterly research sprints — in real conversations, every week. You build relationships with students. You know their names, their blockers, their moments of doubt. Your best design ideas come from a 10-minute phone call, not a brainstorm.&lt;/p&gt;
    &lt;p&gt;You have strong taste but low ego. You have opinions about what good looks like and you'll fight for them. But when the data says you're wrong, you move on fast. You don't fall in love with your work. You fall in love with the problem.&lt;/p&gt;
    &lt;p&gt;You believe everyone deserves a second chance. You treat everyone with dignity. You know how to meet people exactly where they are — with empathy and compassion — helping create a space where everyone feels seen and valued, regardless of their background.&lt;/p&gt;
    &lt;p&gt;You work hard. You show up early, stay late, and do what needs to get done — no ego, no excuses. This isn't a 9-to-5. The team puts in 10+ hour days because we care about the mission and each other. If that sounds miserable, this isn't for you. If it sounds exciting, you'll fit right in.&lt;/p&gt;
    &lt;p&gt;Talking to students — a lot. Your week starts and ends with users. You'll build real relationships with students, not just run usability sessions. You'll understand why someone almost quit, what message made them log back in, what screen confused them at 11pm. These conversations are your primary design tool.&lt;/p&gt;
    &lt;p&gt;Prototyping at the speed of conversation. You hear a problem on a call Tuesday. By Wednesday you have something testable — a coded prototype, a functional hack, a Figma flow wired to real data. By Thursday a student is using it. By Friday you know if it worked. That's the cycle. Repeat.&lt;/p&gt;
    &lt;p&gt;Shipping real product, not just designs. You'll work in our React and TypeScript codebase — or use AI tools like Cursor and Claude Code to get there. The goal isn't to become a full-time engineer. The goal is to never let "it hasn't been built yet" slow down learning. Some of what you build will go straight to production. Some will be throwaway prototypes. You'll know the difference.&lt;/p&gt;
    &lt;p&gt;Designing the moments that keep students going. The hardest design problem here isn't layout or typography. It's commitment. Students are betting months of effort on a future they have to imagine. You'll study where they disengage, what triggers doubt, and what reignites momentum. Then you'll design the moments — an interface, a message, a milestone — that help someone choose to keep going. How do you make a better life in three months feel worth the sacrifice today? You'll own that problem.&lt;/p&gt;
    &lt;p&gt;Measuring what matters. Polished decks don't matter here. You'll define success metrics for what you ship, track whether completion rates moved, whether more students hit the next milestone, whether the intervention you designed actually intervened. You'll close the loop between design and outcome every time.&lt;/p&gt;
    &lt;p&gt;Working across the entire stack of the student experience. Some days that looks like interface design. Other days it looks like rethinking a Customer.io campaign, redesigning an onboarding flow, or sitting with the ops team to understand why students in one facility disengage faster than another. You go where the problem is.&lt;/p&gt;
    &lt;p&gt;Documenting your work clearly. Our work spans months and involves multiple teams. You'll create visibility when a change impacts operations and help others understand how features affect training and service delivery. Precision matters.&lt;/p&gt;
    &lt;p&gt;Start Date: ASAP&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46869901</guid><pubDate>Tue, 03 Feb 2026 12:00:23 +0000</pubDate></item><item><title>KDE's new Plasma Login Manager is tightly bound to systemd</title><link>https://forums.FreeBSD.org/threads/kde-plasma-login-manager-wont-support-systemd-free-linux-or-bsd-systems.101393/</link><description>&lt;doc fingerprint="bf42bad59b87f39c"&gt;
  &lt;main&gt;
    &lt;p&gt;KDE's new Plasma Login Manager is tightly bound to systemd, making it unusable on systemd-free Linux distributions and BSD systems.&lt;lb/&gt;KDE’s upcoming Plasma Login Manager will make its first official appearance in Plasma 6.6 (scheduled for release on February 17), explicitly designed as a successor to the long-standing SDDM, which has been used by KDE Plasma for years.&lt;lb/&gt;KDE developers have framed it as deeply integrated into the Plasma stack itself, with the goal of modernizing the login process by aligning it more closely with how Plasma sessions are actually started and managed, reducing historical complexity and duplicated logic that accumulated around SDDM.&lt;lb/&gt;However, it does come with a few limitations, ones that users of systemd-free Linux distributions or BSD systems likely won’t appreciate. Here’s what it’s all about.&lt;lb/&gt;PLM is strictly systemd-native, relying on systemd-logind and systemd user services for session lifecycle management, permissions, and seat handling. These are hard dependencies, not optional features, and they form the foundation of the new login manager.&lt;lb/&gt;Because of this, systemd-free Linux distributions cannot use Plasma Login Manager, and the same applies to all BSD operating systems, which lack systemd entirely and have no compatible substitute for the APIs PLM depends on. As one of the KDE developers commented on Reddit:&lt;lb/&gt;In other words, for those users, the situation remains unchanged. On their systems, Plasma will continue to rely on SDDM or other platform-specific startup mechanisms, with no indication from KDE that PLM will be made portable beyond systemd environments.&lt;/p&gt;
    &lt;p&gt;KDE’s upcoming Plasma Login Manager will make its first official appearance in Plasma 6.6 (scheduled for release on February 17), explicitly designed as a successor to the long-standing SDDM, which has been used by KDE Plasma for years.&lt;/p&gt;
    &lt;p&gt;KDE developers have framed it as deeply integrated into the Plasma stack itself, with the goal of modernizing the login process by aligning it more closely with how Plasma sessions are actually started and managed, reducing historical complexity and duplicated logic that accumulated around SDDM.&lt;/p&gt;
    &lt;p&gt;However, it does come with a few limitations, ones that users of systemd-free Linux distributions or BSD systems likely won’t appreciate. Here’s what it’s all about.&lt;/p&gt;
    &lt;p&gt;PLM is strictly systemd-native, relying on systemd-logind and systemd user services for session lifecycle management, permissions, and seat handling. These are hard dependencies, not optional features, and they form the foundation of the new login manager.&lt;/p&gt;
    &lt;p&gt;Because of this, systemd-free Linux distributions cannot use Plasma Login Manager, and the same applies to all BSD operating systems, which lack systemd entirely and have no compatible substitute for the APIs PLM depends on. As one of the KDE developers commented on Reddit:&lt;/p&gt;
    &lt;quote&gt;To avoid any confusion, it’s important to emphasize that the lack of PLM support on systemd-free Linux distributions or BSD systems does not mean you can’t use the KDE Plasma desktop environment there. Plasma itself remains fully usable on those platforms.“At the end of the day, we don’t ideally want to cut support for the BSDs and other niche distros, but we also don’t want to hold back on making the best experience possible for the majority user base.”&lt;/quote&gt;
    &lt;p&gt;In other words, for those users, the situation remains unchanged. On their systems, Plasma will continue to rely on SDDM or other platform-specific startup mechanisms, with no indication from KDE that PLM will be made portable beyond systemd environments.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46870751</guid><pubDate>Tue, 03 Feb 2026 13:32:06 +0000</pubDate></item><item><title>Decentralizing My Smartphone with Single Purpose Devices</title><link>https://ambertherambler.bearblog.dev/decentralizing-my-smartphone-with-single-purpose-devices/</link><description>&lt;doc fingerprint="3d08377c29ff1289"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Decentralizing My Smartphone With Single Purpose Devices&lt;/head&gt;
    &lt;p&gt;Lately, I’ve become nostalgic for the days before smartphones, when the internet was a place we went to deliberately, and not a place that lived on all of our devices, beckoning to us with a constant stream of notifications, and our own fears of missing out.&lt;/p&gt;
    &lt;p&gt;For me (and many people who grew up before the 2000s), the internet used to be a place only accessible via a CRT screen connected to a large box in my childhood bedroom. It required a ritual each time to get on, and getting connected to the internet ironically required disconnecting from our phones. We had cell phones, sure, but this was before unlimited calling and texting. Because of this, time spent in the virtual world was short, and it only took place when someone in the house wasn’t expecting a call or didn’t need to use the phone. Loading webpages was slow and tedious, so you had to be deliberate with your time spent online. Nowadays, the glowing rectangles in our pockets keep us chronically online; always connected. It seems impossible to escape from the internet. It's everywhere.&lt;/p&gt;
    &lt;p&gt;The lines between the digital world and the real world have completely blurred. Almost everything we could want or need to do day to day can be done from our smartphones, from listening to music and keeping up with the news, to finding directions and getting groceries. Smartphones have without a doubt made our lives more convenient, and they save us hours upon hours of time every day…which would be great, if we didn’t end up wasting all of that time we saved working when we’re off the clock, or endlessly scrolling through mindless brain rot. As much as I love the modern conveniences my smartphone provides, I can’t help but feel suffocated by the constant influx of information, and the pressure to always be available at a moment’s notice.&lt;/p&gt;
    &lt;p&gt;Over the last few days, I’ve taken steps to decentralize my smartphone, and find alternative ways of fulfilling the tasks I’ve come to rely on it for. It’s my hope that in doing so, I can reclaim some of the time and attention it has taken from me, and put it to better use. This isn’t the first time I’ve done this. It isn’t my intention to swear off of technology forever and become a recluse. That said, I think there is value in taking a digital detox now and then, stepping away from time to time to reevaluate what is working for us, and what, if anything, is getting in the way of us living our lives with greater purpose.&lt;/p&gt;
    &lt;p&gt;Below is a photo of some of the Single Purpose Devices I have been using more so that I can use my smartphone less.&lt;/p&gt;
    &lt;p&gt;I think I will write blog posts detailing each of these things more in depth, but for now, they are as follows: (from left) Magnavox Portable DVD player, Fujifilm X100V Digital Camera, Sony Walkman CD player, iPod (4th Gen Monochrome), AlphaSmart Neo, Physical Books, Typewriter (Royal Arrow), Pen/Paper Journaling, Standalone Calculator, Nintendo Switch&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46871169</guid><pubDate>Tue, 03 Feb 2026 14:09:10 +0000</pubDate></item><item><title>Agent Skills</title><link>https://agentskills.io/home</link><description>&lt;doc fingerprint="8f77afff0b4fb448"&gt;
  &lt;main&gt;&lt;head rend="h2"&gt;Why Agent Skills?&lt;/head&gt;Agents are increasingly capable, but often don’t have the context they need to do real work reliably. Skills solve this by giving agents access to procedural knowledge and company-, team-, and user-specific context they can load on demand. Agents with access to a set of skills can extend their capabilities based on the task they’re working on. For skill authors: Build capabilities once and deploy them across multiple agent products. For compatible agents: Support for skills lets end users give agents new capabilities out of the box. For teams and enterprises: Capture organizational knowledge in portable, version-controlled packages.&lt;head rend="h2"&gt;What can Agent Skills enable?&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Domain expertise: Package specialized knowledge into reusable instructions, from legal review processes to data analysis pipelines.&lt;/item&gt;&lt;item&gt;New capabilities: Give agents new capabilities (e.g. creating presentations, building MCP servers, analyzing datasets).&lt;/item&gt;&lt;item&gt;Repeatable workflows: Turn multi-step tasks into consistent and auditable workflows.&lt;/item&gt;&lt;item&gt;Interoperability: Reuse the same skill across different skills-compatible agent products.&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46871173</guid><pubDate>Tue, 03 Feb 2026 14:09:54 +0000</pubDate></item><item><title>Ask HN: Is there anyone here who still uses slide rules?</title><link>https://news.ycombinator.com/item?id=46871179</link><description>&lt;doc fingerprint="3f7c9216fbaef8b9"&gt;
  &lt;main&gt;
    &lt;p&gt;I do not use, and have never used, a slide rule. My grandfather was an aeronautical engineering / materials scientist for McDonnell Aircraft, and did a lot of foundational work on heat shields for early space flight (or so I am told). He was eventually named a McDonnell Douglas Fellow, back when there were fewer than 15 Fellows - the company, at the time, took out a full-page ad in Aerospace Magazine announcing it.&lt;/p&gt;
    &lt;p&gt;I have his slide rule, that he used for ages. It's a mystery in a box to me - I have not the foggiest clue how it is used - but I cherish it.&lt;/p&gt;
    &lt;p&gt;&amp;gt; I have not the foggiest clue how it is used - but I cherish it.&lt;/p&gt;
    &lt;p&gt;It's easier and more straightforward than you might expect. I encourage you to learn to use his slide rule, in large part because you might find it fun, but also to honor your grandfather's legacy.&lt;/p&gt;
    &lt;p&gt;When I was in high school, (early 1990s,) there was a giant one mounted above the blackboard. It was clearly used for instruction in the past, but it looked so cool that no one wanted to remove it.&lt;/p&gt;
    &lt;p&gt;Every once in awhile a teacher would spend about 10-15 minutes showing how to use it. Everyone would "oooh" and "awww" and then we would all laugh about how we didn't need to use them now that we all had calculators in our pocket that were more powerful than the computers that put people on the moon.&lt;/p&gt;
    &lt;p&gt;It's always nice to learn about the past so we can appreciate what we have now.&lt;/p&gt;
    &lt;p&gt;Although slide rules are a "dead skill," Aviators typically learn to use something called an E6B Flight Computer, which works on the same principle as a round slide rule.&lt;/p&gt;
    &lt;p&gt;Now that's a properly dead skill, surely. I have my dad's one somewhere, and know roughly how it works, but I've not touched it this century.&lt;/p&gt;
    &lt;p&gt;I also have one of these: https://archive.org/details/spencersdecimalr0000unse ; I believe they were popular around the time of the UK converting to decimal currency, to save people having to do the transitional arithmetic. Had a bunch of other tables in. A physical LUT.&lt;/p&gt;
    &lt;p&gt;I wonder if there's anyone with abacus skills here. I hear that held out against calculators a lot longer, for shopkeeper uses.&lt;/p&gt;
    &lt;p&gt;I have two or three that I inherited from my dad. I've never learned to use them because I haven't thought of something I'd use them for. The one thing I could think of is quickly doing fractional math while woodworking (what width will I have if I rip this 7.5" board into 4 pieces?) but in reality I just don't actually do that much math while woodworking.&lt;/p&gt;
    &lt;p&gt;Knew a mechanical engineer at a place where I interned. Asked him about it and he joked that he didn't trust those transistors before explaining that it's just muscle memory to him and while a calculator would be faster he'd still earn the same per hour. Apparently I was the first to ask him in over a decade as everyone had moved on to do stuff in software and no one was pushing him to use a calculator anymore. Interns didn't inquire because they thought it must be some esoteric/religious practice. Last I heard he was still working there, management asked him to stay on past retirement age for his invaluable skillset. While its probably some other skill I just like to imagine the suits in a meeting where they decided to keep him on for this particular "skill" that no one else in the company had anymore.&lt;/p&gt;
    &lt;p&gt;I have one in my flight bag! No hate here, I think it's sensible to have a highly reliable, highly available backup to whatever digital equipment we need to rely on.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46871179</guid><pubDate>Tue, 03 Feb 2026 14:10:21 +0000</pubDate></item></channel></rss>