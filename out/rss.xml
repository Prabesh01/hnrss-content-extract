<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 24 Oct 2025 06:46:09 +0000</lastBuildDate><item><title>I spent a year making an ASN.1 compiler in D</title><link>https://bradley.chatha.dev/blog/dlang-propaganda/asn1-compiler-in-d/</link><description>&lt;doc fingerprint="1620d077aea51bd4"&gt;
  &lt;main&gt;&lt;p&gt;Published: 2025/10/23 | Updated: 2025/10/23&lt;/p&gt;&lt;p&gt;… and it’s still nowhere near complete.&lt;/p&gt;&lt;p&gt;In this post I’ll just rambling about ASN.1; parts of the compiler implementation, and some of the tool’s output rather than the tool itself as its still too WIP to really advertise on its own yet.&lt;/p&gt;&lt;p&gt;This post is unstructured, so you can just pick somewhere random and start reading from there with no/minimal context lost.&lt;/p&gt;&lt;p&gt;Note: the name of the tool is dasn1.&lt;/p&gt;&lt;p&gt;I’m currently writing Juptune - a toy async I/O framework that attempts to implement as much of its stack as possible in pure D.&lt;/p&gt;&lt;p&gt;I’m really interested in writing an implementation of TLS, which means I need to be able to handle x.509 certificates (i.e. TLS/SSL certs), which means I need to be able to handle their underlying data encoding: ASN.1’s DER encoding.&lt;/p&gt;&lt;p&gt;So basically I just wanted to do this for fun at the end of the day, nothing much deeper than that. I’ve never written or worked on a proper compiler project before that wasn’t toy-sized so I saw a ton of growth potential… the main thing that’s grown however is the mental scar ASN.1’s left on me.&lt;/p&gt;&lt;p&gt;I’ve succesfully generated code that can parse a couple of x.509 certificates I’ve thrown at it, and I’ve started work on an almost-D-native (excluding crypto primitives) implementation of TLS 1.3.&lt;/p&gt;&lt;p&gt;I’m constantly amazed about how much of modern life relies on these ancient, overly complicated specs from the 90s. ASN.1 is used everywhere in some form or another and yet I bet you’ve never even heard of it before, just have a look on wikipedia.&lt;/p&gt;&lt;p&gt;ASN.1 is the result of a bunch of graybeards from the late 80s+ trying to design an overengineered data specification language. In other words, it’s protobuf on steroids.&lt;/p&gt;&lt;p&gt;There’s two parts of ASN.1: There’s the ASN.1 notation (defined by x.680, x.681, x.682, and x.683), and then there’s the various encodings (BER, CER, DER, PER, XER, JER…). In this post I’ll mainly be focusing on the notation + DER.&lt;/p&gt;&lt;p&gt;Similarly to protobuf you use the notation to define a structured way to represent data, and then use tooling that can generate encoders/decoders for a specific encoding, in a specific programming language.&lt;/p&gt;&lt;p&gt;Here’s a choice snippet of the ASN.1 notation for RFC 5280 (which defines what’s commonly known as TLS certificates):&lt;/p&gt;&lt;p&gt;Encoding wise here’s a quick of some of the more well known ones:&lt;/p&gt;&lt;p&gt;Did I ever mention that ASN.1 is complicated? On the one hand the sheer amount of possible encodings is daunting, but on the other hand it shows a certain flexbility that ASN.1 provides - you could even invent your own domain-specific encoding if needed.&lt;/p&gt;&lt;p&gt;Loosely speaking you can define ASN.1’s notation as being the “base” notation defined in x.680, with the sometimes-optional addon specifications defined in x.681, x.682, x.683.&lt;/p&gt;&lt;p&gt;These specifications are also written in academicese so for mere uneducated mortals such as myself, simply trying to read and understand what the specifications are saying in the first place is already a large hurdle. I think I’ve started to get the hang of it though.&lt;/p&gt;&lt;p&gt;Fortunately for my use case of handling x.509 certificates, there’s no hard requirement for anything beyond x.680 and so x.680 is the only spec I’ve attempted to implement so far (outside of x.690 which describes how BER/CER/DER works - which is actually a joy to read compared to the x.68x specs).&lt;/p&gt;&lt;p&gt;x.680 isn’t the worst thing in the world to implement, it’s just the fact that there’s a lot more to it than you’d think from a quick glance at a code example, as well as some relatively annoying “transformation” (semantic) rules you have to acccount for.&lt;/p&gt;&lt;p&gt;Generally though I’d say the really difficult parts seem to come from its extensions.&lt;/p&gt;&lt;p&gt;One of the more annoying parts of implementing a parser for ASN.1’s notation is that x.680 has been revised several times over the years, which includes the deprecation + removal of certain features.&lt;/p&gt;&lt;p&gt;And so some other specifications you read through will either:&lt;/p&gt;&lt;p&gt;Meaning that if you want to write a compiler for ASN.1 for a specific use case, but want it to also be an implementation of the more modern specs… then you’ll have to partially implement/hack around some of the older stuff that’s no longer defined in the up to date spec documentation.&lt;/p&gt;&lt;p&gt;An example would be the &lt;code&gt;ANY DEFINED BY&lt;/code&gt; syntax, which I have a separate section on.&lt;/p&gt;&lt;p&gt;This is essentially the academic equivalent of an Elder Scroll - you will go insane attempting to read let alone mentally parse this damn thing.&lt;/p&gt;&lt;p&gt;x.681 describes the Information Class Object system. I’d love to talk to you more about it more in depth but I haven’t put in enough effort to confidently state much about how it works.&lt;/p&gt;&lt;p&gt;One of the few parts I sort of understand and can talk about is that x.681 has a really cool feature where Information Classes can be given a custom initialisation syntax:&lt;/p&gt;&lt;p&gt;I’d absolutely love to attempt to implement x.681 for the challenge of this feature alone, however I only have so much energy (and sanity), so it’ll likely be a while until I even properly consider it.&lt;/p&gt;&lt;p&gt;x.682 describes the Table Constraint feature. I’m going to be honest I don’t understand a single thing about this feature - I took one look at the specification and was like “absolutely not”.&lt;/p&gt;&lt;p&gt;x.683 describes the ability to create templated (sorry, “parameterised”) types. Similar to the other ASN.1 extensions I haven’t looked much into this feature, but it appears to be a lot simpler to implement than the others.&lt;/p&gt;&lt;p&gt;In essence, one of the things you can do is this:&lt;/p&gt;&lt;p&gt;It supports values as well as types within its template parameters (similarly to D!) so there’s a few cool things you can do with it I guess.&lt;/p&gt;&lt;p&gt;Despite the many, many, many pains of this god forsaken technology, it’s actually really interesting and powerful at the same time.&lt;/p&gt;&lt;p&gt;ASN.1’s notation contains a pretty neat feature where you can add special constraints onto types + fields. So rather than having a stray “ProtcolPacket.field1.field2.xyz MUST be between 0 and 2” that’s super easy to miss, you can instead describe this constraint within ASN.1 itself which (good) tooling will then take into account for you.&lt;/p&gt;&lt;p&gt;Here’s some examples of the simpler constraints available:&lt;/p&gt;&lt;p&gt;There’s a few more constraints available but… they’re mostly pretty complex ones that I don’t want to have to think about.&lt;/p&gt;&lt;p&gt;It’s really cool to see that ASN.1 has a feature like this though, considering the only other langauge I’ve personally encountered that has a similar feature is Ada.&lt;/p&gt;&lt;p&gt;ASN.1 generally uses the &lt;code&gt;OBJECT IDENTIFIER&lt;/code&gt; type in order to, well, identify specific things, e.g. extensions found within x.509 certificates.&lt;/p&gt;&lt;p&gt;&lt;code&gt;OBJECT IDENTIFIER&lt;/code&gt;s are also used to provide versions to modules, for example:&lt;/p&gt;&lt;p&gt;Everything between the curly brackets is an OBJECT IDENTIFIER for this exact module - technically no other ASN.1 module in existance should ever use this specific OBJECT IDENTIFIER. The optional labels (e.g. &lt;code&gt;iso&lt;/code&gt;) have no meaning beyond aiding human comprehension, it’s the values (e.g. &lt;code&gt;(0)&lt;/code&gt;) that are actually used to create the identifier.&lt;/p&gt;&lt;p&gt;As a great example of this versioning system, it just so happens that this specific module has a more modern version that has this specific OBJECT IDENTIFIER instead:&lt;/p&gt;&lt;p&gt;This updated version doesn’t change how data is encoded to/from DER but instead it simply uses more modern syntax and features.&lt;/p&gt;&lt;p&gt;This is important because older specifications will be using &lt;code&gt;PKIX1Implicit88&lt;/code&gt; whereas newer ones will likely be using &lt;code&gt;PKIX1Implicit-2009&lt;/code&gt; instead, and so there needs to be a more clear-cut way to distinguish between these two versions of the &lt;code&gt;PKIX1Implicit&lt;/code&gt; module other than going by its name - and this is where OBJECT IDENTIFIERS come in handy.&lt;/p&gt;&lt;p&gt;When importing modules within ASN.1 notation you can (and should) specify an OBJECT IDENTIFIER as well:&lt;/p&gt;&lt;p&gt;Maybe I’m just a nerd, but I find this to almost be a thing of beauty with how simple yet effective it is.&lt;/p&gt;&lt;p&gt;D has several quality of life features that makes it surprisingly easy to generate code for - features that would definitely make the compiler more annoying to work with when targeting other languages.&lt;/p&gt;&lt;p&gt;These features on their own aren’t exactly rare to see, but the specific combination is what makes everything work together so well.&lt;/p&gt;&lt;p&gt;&lt;code&gt;static import&lt;/code&gt; in D means “import this module, but ONLY allow it to be used via its fully qualified name”:&lt;/p&gt;&lt;p&gt;You can even override the module name, as strange as that sounds!&lt;/p&gt;&lt;p&gt;This feature is a godsend for preserving the original names of ASN.1 types. For example, Juptune provides an error type called &lt;code&gt;Result&lt;/code&gt; which comes from the &lt;code&gt;juptune.core.util.result&lt;/code&gt; module.&lt;/p&gt;&lt;p&gt;Without static imports I’d have to be careful of ASN.1 code that defines a &lt;code&gt;Result&lt;/code&gt; type as it’d otherwise come into conflict with Juptune’s own &lt;code&gt;Result&lt;/code&gt; type.&lt;/p&gt;&lt;p&gt;However, with static imports, I can basically just generate code that looks like this:&lt;/p&gt;&lt;p&gt;Completely removing the need of me having to worry about symbol name conflicts.&lt;/p&gt;&lt;p&gt;On a similar vein D allows you to specify that instead of looking up a symbol from any available symbol table (e.g. local vars; non-static imports, etc.) it should instead perform a lookup using the current module’s top-level symbols.&lt;/p&gt;&lt;p&gt;For example:&lt;/p&gt;&lt;p&gt;The leading &lt;code&gt;.&lt;/code&gt; in &lt;code&gt;.Type1&lt;/code&gt; is what causes the module-local lookup.&lt;/p&gt;&lt;p&gt;Essentially, this feature compliments the static import feature to help make it much harder for ASN.1 types to accidentally refer to the wrong symbol when converted into D code.&lt;/p&gt;&lt;p&gt;In short: this feature allowed me to be really really lazy with certain parts of the compiler :D&lt;/p&gt;&lt;p&gt;As the name suggests, &lt;code&gt;typeof()&lt;/code&gt; allows you to retrieve the type of any particular symbol you pass into it - this is great when dealing with code generation since sometimes it can be kind of annoying to structure your code in a way where you can easily preserve the type name of some symbol you’re working with.&lt;/p&gt;&lt;p&gt;In other words “this let’s me write bad code and make it still work”.&lt;/p&gt;&lt;p&gt;First example is around how some getters and setters for SEQEUENCE fields are generated. Instead of doing the correct thing and preserving the type name for each field, I got lazy and just used &lt;code&gt;typeof(_field)&lt;/code&gt;:&lt;/p&gt;&lt;p&gt;The second example is around error messages. Instead of needing to keep track of the current type’s name when generating error messages… I could just use &lt;code&gt;typeof(this)&lt;/code&gt; to get the type instead:&lt;/p&gt;&lt;p&gt;What’s even better is that because the entire string is composed of compile-time constants, it doesn’t actually require an allocation + concat at runtime since the compiler will constant fold it for you. This allows &lt;code&gt;fromDecoding&lt;/code&gt; to still be marked as &lt;code&gt;@nogc&lt;/code&gt;!&lt;/p&gt;&lt;p&gt;Generating a parameter list and don’t want to have to care about whether there’s an extra comma or not?&lt;/p&gt;&lt;p&gt;Enum options?&lt;/p&gt;&lt;p&gt;Array values?&lt;/p&gt;&lt;p&gt;D’s got your back! (Except for specifying multiple modules in a single import statement, then for some reason you’re not allowed, but shh about that).&lt;/p&gt;&lt;p&gt;For a while a lot of the types being generated (and some of the core decoding types) didn’t have a &lt;code&gt;toString&lt;/code&gt; implementation. This’d normally mean that I couldn’t just use &lt;code&gt;.toString&lt;/code&gt; willy-nilly but instead the compiler would need knowledge about which types had a &lt;code&gt;toString&lt;/code&gt; or not.&lt;/p&gt;&lt;p&gt;However, as is the common theme now D allows us to be very lazy - instead of keeping track of this ourselves in dasn1, we can instead just generate code where it’s the D compiler’s concern instead of our’s:&lt;/p&gt;&lt;p&gt;Job sorted (and future proofed!).&lt;/p&gt;&lt;p&gt;You could definitely utilise D’s metaprogramming for more complicated stuff, but it’s also good for silly little things like this.&lt;/p&gt;&lt;p&gt;Naturally I’ve tried to use whatever D features that I could in order to implement dasn1, so I thought I’d pick a few parts of the code that rely on D’s features quite heavily as a small showcase.&lt;/p&gt;&lt;p&gt;Mixin templates are a fairly quirky feature of D - it allows you to define a normal template (essentially a compile-time collection of symbols) and then copy-paste them wherever you like, whether that’s inside a class, struct, the top-level module etc.&lt;/p&gt;&lt;p&gt;Since the ASN.1 grammar only had a handful of node “types”, I decided to use mixin templates to model each specific “type”:&lt;/p&gt;&lt;p&gt;I probably could’ve gotten away with just using templated base classes instead, but there’s a few differences that actually make that kind of annoying. Namely it’d create some bloated symbol names which would make reading compiler errors even more painful than it already ended up being.&lt;/p&gt;&lt;p&gt;Let’s look at one of the AST nodes again:&lt;/p&gt;&lt;p&gt;This is a node that contains several other nodes. &lt;code&gt;Container&lt;/code&gt; itself supports an unbounded amount of node types it can store, since D supports variadic template parameters. You may be asking what the API for this even looks like, and I’ll be glad to show you a quick snippet:&lt;/p&gt;&lt;p&gt;Let’s have a look at a &lt;code&gt;OneOf&lt;/code&gt; node instead now:&lt;/p&gt;&lt;p&gt;This node has a similar template-based API for most of its operations:&lt;/p&gt;&lt;p&gt;However the main feature of the &lt;code&gt;OneOf&lt;/code&gt; node is its &lt;code&gt;match&lt;/code&gt; function. This function requires the user to pass in a handler function for each possible node type that the &lt;code&gt;OneOf&lt;/code&gt; can store, and this requirement is enforced at compile-time so that changes to the node type list will immediately require all appropriate &lt;code&gt;match&lt;/code&gt; functions to be updated (i.e. no silent breakage).&lt;/p&gt;&lt;p&gt;This is surprisingly easy to implement with D due to its first-class metaprogramming features, I’ll try my best to be brief with how this all works:&lt;/p&gt;&lt;p&gt;In essence:&lt;/p&gt;&lt;code&gt;NodeTypes...&lt;/code&gt; is the template parameter containing a compile-time tuple of all possible types that this &lt;code&gt;OneOf&lt;/code&gt; can store.&lt;code&gt;oneOfHandlerFuncTuple&lt;/code&gt; is a template that generates a new compile-time tuple, where each &lt;code&gt;NodeTypes&lt;/code&gt; is mapped into a function pointer type.&lt;code&gt;match&lt;/code&gt; uses the result of &lt;code&gt;oneOfHandlerFuncTuple&lt;/code&gt; as its main parameter. Since this is a compile-time tuple of types it automagically gets expanded into multiple parameters under the hood.&lt;code&gt;static foreach&lt;/code&gt; within &lt;code&gt;match&lt;/code&gt;’s body allows us to iterate over a compile-time collection (in this case, &lt;code&gt;NodeTypes&lt;/code&gt;) and duplicate the foreach’s body for each item. In this case, so we can make a &lt;code&gt;case&lt;/code&gt; statement per item in &lt;code&gt;NodeTypes&lt;/code&gt;.&lt;p&gt;So:&lt;/p&gt;&lt;code&gt;NodeTypes...&lt;/code&gt; is &lt;code&gt;(Node1, Node2)&lt;/code&gt;.&lt;code&gt;oneOfHandlerFuncTuple&lt;/code&gt; results in &lt;code&gt;(Result delegate(Node1), Result delegate(Node2))&lt;/code&gt;&lt;code&gt;match&lt;/code&gt;’s parameters expand into &lt;code&gt;match(scope delegate(Node1) handler_0, scope delegate(Node2) handler_1)&lt;/code&gt;&lt;p&gt;Which means that we could use this example match function like so:&lt;/p&gt;&lt;p&gt;I know that’s a lot to take in especially since I have to be briefer than usual, but TL;DR D makes the hard stuff easy while still being relatively easy on the eyes. I would make a snarky comparison with C++ but literally no one expects C++ metaprogramming to be readable at this point.&lt;/p&gt;&lt;p&gt;10 years ago (October 2015) D’s standard library was given an experimental package called &lt;code&gt;std.experimental.allocator&lt;/code&gt;. It has a pretty neat but kind of janky way of composing a bunch of allocation building blocks together, in order to “easily” make custom allocators.&lt;/p&gt;&lt;p&gt;I use it for the ASN.1 stuff since it makes it easy to construct and dispose classes within &lt;code&gt;@nogc&lt;/code&gt; code, and it looks kind of cool to boot:&lt;/p&gt;&lt;p&gt;The issue is this package is still experimental 10 years later and I wouldn’t be surprised if it gets removed sooner or later, especially with the Phobos v2 work that’ll hopefully exist in some form before I retire (I’m 26).&lt;/p&gt;&lt;p&gt;:D The sign of someone who loves this damn language is that they can’t help but provide some level of historical snark. I have no further comments, I just miss the days I had hope for D’s future xD&lt;/p&gt;&lt;p&gt;Situation: I need to store IR nodes using a base class rather than a specific concrete implementation class, but I’d still like to limit the potential options without having to go down the SumType route.&lt;/p&gt;&lt;p&gt;Solution: This short but sweet struct (note: this is a different &lt;code&gt;OneOf&lt;/code&gt; struct for IR purposes, not AST purposes).&lt;/p&gt;&lt;p&gt;We can initialise this struct like so:&lt;/p&gt;&lt;p&gt;Now the fun part comes from this weird &lt;code&gt;alias ir this;&lt;/code&gt; line. Normally when working with a wrapper struct like this you’d have do something like:&lt;/p&gt;&lt;p&gt;With &lt;code&gt;alias ir this;&lt;/code&gt; anytime we try to perform an operation (e.g. casting; function calls, etc.) that the &lt;code&gt;OneOf&lt;/code&gt; struct itself does not support, the compiler will instead try to use it on the &lt;code&gt;OneOf.ir&lt;/code&gt; field instead:&lt;/p&gt;&lt;p&gt;It’s a very weird, niche feature which might even get removed or at least deprecated in the future, but it allows for some mild syntax cleanup as shown above.&lt;/p&gt;&lt;p&gt;Some of the IR types try to strictly limit the way that user code can query and interact with their data, mainly to help prevent potential memory corruption… at least that was my original, flawed reasoning.&lt;/p&gt;&lt;p&gt;This can be awkward when writing unittests, as sometimes you just need to query a very particular part of a type’s data without having to go through all of its hurdles.&lt;/p&gt;&lt;p&gt;And so by simply slapping &lt;code&gt;version(unittest)&lt;/code&gt; onto a funciton definition, you now have an escape hatch that won’t make its way out into real code:&lt;/p&gt;&lt;p&gt;There’s a few examples of this within the codebase. Sometimes unittests are for the most part identical except:&lt;/p&gt;&lt;p&gt;It’s one of those things where you kind of just have to use it and do it before you “get it”, so I apologise for the really poor explanation, but this is essentially something you can do with templates.&lt;/p&gt;&lt;p&gt;Here’s one of the templated “test harnesses” I used - this one in particular is for testing the AST -&amp;gt; IR converter functions.&lt;/p&gt;&lt;p&gt;It can be used like so:&lt;/p&gt;&lt;p&gt;One main issue, especially for the larger tests, is that specifying &lt;code&gt;Harness.T&lt;/code&gt; (and more minorly &lt;code&gt;Harness.run&lt;/code&gt;) can start to make the code look chunky and a bit harder to read.&lt;/p&gt;&lt;p&gt;So by using the magical &lt;code&gt;with()&lt;/code&gt; statement, instead of writing &lt;code&gt;Harness.run&lt;/code&gt; and &lt;code&gt;Harness.T&lt;/code&gt;, we can just write &lt;code&gt;run&lt;/code&gt; and &lt;code&gt;T&lt;/code&gt; and the compiler will know how to lookup these otherwise missing/undefined symbols:&lt;/p&gt;&lt;p&gt;Again this is one of those things that on paper sounds really stupid (and impossible to easily describe), but grows on you really fast when you give it a try.&lt;/p&gt;&lt;p&gt;While ASN.1’s basic syntax looks pretty easy from an initial glance, that illusion shatters once you start getting into it more deeply.&lt;/p&gt;&lt;p&gt;ASN.1 has various separate value forms that start with a left bracket (&lt;code&gt;{&lt;/code&gt;), a lot of these forms are ambiguous due to a variety of factors and can only be distinguished with semantic context.&lt;/p&gt;&lt;p&gt;Given that dans1 has a clean split between syntax and semantic analysis, “this does not spark joy” as the kids would say.&lt;/p&gt;&lt;p&gt;I’ll let this comment from the parser code explain itself:&lt;/p&gt;&lt;p&gt;:D Fun times.&lt;/p&gt;&lt;p&gt;Example: I can’t even remember the exact conditions, but I remember having to debug some generated decoder code since it was failing to decode a specific field. It turned out that this field was under certain “exact conditions” that meant its tag was supposed to be treated as &lt;code&gt;EXPLICIT&lt;/code&gt; instead of the module-default &lt;code&gt;IMPLICIT&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;I still have no idea where in the spec this behaviour gets mentioned and so I basically had to wing a fix and hope it works going forward.&lt;/p&gt;&lt;p&gt;More generally this feeling and scenario has happened quite a few times - the information is scattered (sometimes across different specs) and is hard to keep track of.&lt;/p&gt;&lt;p&gt;Another example is around module versions. The spec makes absolutely zero mention (that I can see) on how to version modules for non ISO/ITU purposes, and I would greatly appreciate if anyone could help me find this information.&lt;/p&gt;&lt;p&gt;I’d be amazed if there’s a 100% spec compliant implementation out there, even commercially.&lt;/p&gt;&lt;code&gt;UTF8String (SIZE ("yagababa"))&lt;/code&gt; doesn’t make sense.&lt;code&gt;myInt INTEGER (1) ::= 2&lt;/code&gt; needs to trigger an error.&lt;p&gt;It’s tedious and not very fun, but there’s no real way around it.&lt;/p&gt;&lt;p&gt;For a newbie to compiler programming like me I also found it really hard to deal with useful error messages. I ended up running the checks twice: one time to see if there’s even an error at all, and the second time to build up the error string. This is mainly complicated by the existance of UNION and (especially) INTERSECTION constraints.&lt;/p&gt;&lt;p&gt;I foolishly made the mistake of believing that once I converted the generic AST nodes into the more specific IR nodes that I wouldn’t have to make any major changes to the underlying data (beyond setting up things like symbol tables).&lt;/p&gt;&lt;p&gt;:D Unfortunately that wonderfully naive thought was quickly crushed as ASN.1 requires the semantic stage to perform certain transformations, certain transformations (e.g. &lt;code&gt;AUTOMATIC TAGS&lt;/code&gt;) that ended up/are going to be really annoying due to the way I’ve structured the code.&lt;/p&gt;&lt;p&gt;But that’s future Brad’s problem.&lt;/p&gt;&lt;p&gt;I am extremely thankful that x.509 is an old enough specification that the ASN.1 notation only uses the older syntax of x.680.&lt;/p&gt;&lt;p&gt;The alternative is that you’d need an implementation of the x.681, x.682, and x.683 specs to use any of the newer stuff - this is absolutely non-trivial to implement, and I imagine this is one of the many reasons ASN.1 hasn’t ever really taken off outside of historical and commercialised spaces.&lt;/p&gt;&lt;p&gt;There is one exception to the above however and that is &lt;code&gt;ANY DEFINED BY&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;It’d basically be used to define a type who’s contents could be any other type conditioned by some other field:&lt;/p&gt;&lt;p&gt;You then have to piece together what identifier matches which type. Dasn1 doesn’t actually implement &lt;code&gt;ANY DEFINED BY&lt;/code&gt; as-is since even by the 2003 revision it was deprecated.&lt;/p&gt;&lt;p&gt;Instead, for better or for worse, dasn1 has a hacked together intrinsic called &lt;code&gt;Dasn1-Any&lt;/code&gt;:&lt;/p&gt;&lt;p&gt;This essentially gets lowered down into the decoding code for &lt;code&gt;OCTET STRING&lt;/code&gt; but without any sort of tag validation enabled. Unfortunately until/unless I want to implement Information Object Classes, I’m then stuck with having to manually call into the decoding code when I want to turn &lt;code&gt;Dans1-Any&lt;/code&gt; fields into their actual types.&lt;/p&gt;&lt;p&gt;This is more of a personal one.&lt;/p&gt;&lt;p&gt;Between the various different aspects of the ASN.1 compiler, the x.68x specs, the x.690 spec, and all of the other projects building off of this ASN.1 work (x.509 certificate handling, TLS 1.3) I started to feel like a stranger in my own codebase, even just a week after I had last touched it.&lt;/p&gt;&lt;p&gt;It’ll definitely be interesting making future improvements/changes as my at-hand knowledge is constantly dwindling.&lt;/p&gt;&lt;p&gt;From having to write 20,000 different node visitors for various reasons; to hand-rolling a syntax parser for a boring, drawn out grammar; to needing to write code that looks 95% the same as the last but that last 5% of difference ranges from drudge to mentally taxing, repeated 9000 times.&lt;/p&gt;&lt;p&gt;I think I can finally say I have some proper compiler experience under my belt ;(&lt;/p&gt;&lt;p&gt;But lord knows that each and every milestone has been so extremely rewarding (as long as I try not to think about the fact that almost no one will be using this code).&lt;/p&gt;&lt;p&gt;p.s. Don’t try to make a template-based parser combinator for the entire grammar of a language you don’t personally control unless you want to see symbol names that are 10Mb+ long and explode the binary size by over 100Mb. Don’t ask me how I know.&lt;/p&gt;&lt;p&gt;(I even hard crashed the D compiler I use once, since I guess the error message was literally too long. That endlessly scrolling console…)&lt;/p&gt;&lt;p&gt;A probably wasted year of my life later and there’s still an insane amount of work left on everything relating to this project (and Juptune) in general, but I think it’s making me a better programmer. Maybe.&lt;/p&gt;&lt;p&gt;The dream is that one day I can put “made an ASN.1 compiler + x.509 certificate handler + TLS 1.3 implementation” on my CV and still get told “sorry, you’re a good match except you don’t have 6 months of production experience in Ansible, we can’t hire you” by a recruiter. God I love this industry.&lt;/p&gt;&lt;p&gt;Don’t do ASN.1 kids, you’ll never be the same.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45681200</guid><pubDate>Thu, 23 Oct 2025 12:47:41 +0000</pubDate></item><item><title>Antislop: A framework for eliminating repetitive patterns in language models</title><link>https://arxiv.org/abs/2510.15061</link><description>&lt;doc fingerprint="3c1c3503d5f3928b"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Machine Learning&lt;/head&gt;&lt;p&gt; [Submitted on 16 Oct 2025 (v1), last revised 21 Oct 2025 (this version, v2)]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Antislop: A Comprehensive Framework for Identifying and Eliminating Repetitive Patterns in Language Models&lt;/head&gt;View PDF&lt;quote&gt;Abstract:Widespread LLM adoption has introduced characteristic repetitive phraseology, termed "slop," which degrades output quality and makes AI-generated text immediately recognizable. We present Antislop, a comprehensive framework providing tools to both detect and eliminate these overused patterns. Our approach combines three innovations: (1) The Antislop Sampler, which uses backtracking to suppress unwanted strings at inference time without destroying vocabulary; (2) An automated pipeline that profiles model-specific slop against human baselines and generates training data; (3) Final Token Preference Optimization (FTPO), a novel fine-tuning method that operates on individual tokens, surgically adjusting logits wherever a banned pattern has appeared in an inference trace. We demonstrate that some slop patterns appear over 1,000x more frequently in LLM output than human text. The Antislop Sampler successfully suppresses 8,000+ patterns while maintaining quality, whereas token banning becomes unusable at just 2,000. Most importantly, FTPO achieves 90% slop reduction while maintaining or improving performance in cross-domain evals including GSM8K, MMLU, and creative writing tasks. In contrast, DPO suffers significant degradation in writing quality and lexical diversity despite achieving weaker suppression. We release all code and results under MIT license: this https URL.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Samuel Paech [view email]&lt;p&gt;[v1] Thu, 16 Oct 2025 18:22:22 UTC (536 KB)&lt;/p&gt;&lt;p&gt;[v2] Tue, 21 Oct 2025 21:42:07 UTC (536 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;p&gt; IArxiv Recommender (What is IArxiv?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45683897</guid><pubDate>Thu, 23 Oct 2025 16:36:05 +0000</pubDate></item><item><title>Claude Memory</title><link>https://www.anthropic.com/news/memory</link><description>&lt;doc fingerprint="777befbbffb2c0ea"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Bringing memory to Claude&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Update&lt;p&gt;Expanding to Pro and Max plans&lt;/p&gt;&lt;p&gt;Oct 23, 2025&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Whether you’re iterating on a strategy proposal, debugging an issue, or managing multiple projects, Claude picks up right where you left off. Like Team and Enterprise users, you get project-scoped memory (each project has its own separate memory), full control to view and edit what Claude remembers, and incognito chat for conversations that don’t save to memory.&lt;/p&gt;
    &lt;p&gt;Before this rollout, we ran extensive safety testing across sensitive wellbeing-related topics and edge cases—including whether memory could reinforce harmful patterns in conversations, lead to over-accommodation, and enable attempts to bypass our safeguards. Through this testing, we identified areas where Claude's responses needed refinement and made targeted adjustments to how memory functions. These iterations helped us build and improve the memory feature in a way that allows Claude to provide helpful and safe responses to users.&lt;/p&gt;
    &lt;p&gt;To get started, enable memory in Settings.&lt;/p&gt;
    &lt;p&gt;Today, we’re introducing memory to the Claude app, where Claude remembers you and your team’s projects and preferences, eliminating the need to re-explain context and keeping complex work moving forward.&lt;/p&gt;
    &lt;p&gt;Memory is fully optional, with granular user controls that help you manage what Claude remembers. We’re also introducing Incognito chats that don’t appear in your conversation history or save to memory.&lt;/p&gt;
    &lt;p&gt;Memory is rolling out to Team and Enterprise plan users starting today. Enterprise admins can choose whether to disable memory for their organization at any time. Incognito chat is available to all Claude users.&lt;/p&gt;
    &lt;head rend="h2"&gt;Memory built for work&lt;/head&gt;
    &lt;p&gt;With memory, Claude focuses on learning your professional context and work patterns to maximize productivity. It remembers your team’s processes, client needs, project details, and priorities. Sales teams keep client context across deals, product teams maintain specifications across sprints, and executives track initiatives without constantly rebuilding context.&lt;/p&gt;
    &lt;p&gt;If you use projects, Claude creates a separate memory for each project. This ensures that your product launch planning stays separate from client work, and confidential discussions remain separate from general operations. These project boundaries help you and your teams manage complex, concurrent initiatives without mixing unrelated details, serving as a safety guardrail that keeps sensitive conversations contained.&lt;/p&gt;
    &lt;p&gt;Claude uses a memory summary to capture all its memories in one place for you to view and edit. In your settings, you can see exactly what Claude remembers from your conversations, and update the summary at any time by chatting with Claude. Based on what you tell Claude to focus on or to ignore, Claude will adjust the memories it references.&lt;/p&gt;
    &lt;head rend="h2"&gt;Incognito chat&lt;/head&gt;
    &lt;p&gt;Sometimes you need Claude’s help without using or adding to memory. Incognito chat gives you a clean slate for conversations that you don’t want to preserve in memory. It is perfect for sensitive brainstorming, confidential strategy discussions, or when you simply want a fresh conversation without context from previous chats. Your regular memory and conversation history remain untouched. If you’re using memory on a Team or Enterprise plan, your standard data retention settings apply.&lt;/p&gt;
    &lt;head rend="h2"&gt;Starting with teams at work&lt;/head&gt;
    &lt;p&gt;Memory introduces new safety considerations and we've designed the feature to be useful in work settings, while avoiding sensitive conversations and topics. We're also taking a thoughtful phased approach to ensure these powerful capabilities are deployed responsibly, and will continue to evaluate and test how memory works across the different ways people use Claude before expanding availability.&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting started&lt;/head&gt;
    &lt;p&gt;To see memory in action, enable the feature in Settings, and let Claude generate memory with your past chats at initial set-up. Ask Claude questions like “what were we working on last week?” to see what Claude remembers across your existing chats and connected tools. If you would like to bring your memory details over from a different AI tool or export your memory from Claude for backup or migration, you can follow these instructions.&lt;/p&gt;
    &lt;p&gt;Great work builds over time. With memory, each conversation with Claude improves the next.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45684134</guid><pubDate>Thu, 23 Oct 2025 16:56:07 +0000</pubDate></item><item><title>OpenAI acquires Sky.app</title><link>https://openai.com/index/openai-acquires-software-applications-incorporated</link><description>&lt;doc fingerprint="313411143f63e33e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;OpenAI acquires Software Applications Incorporated, maker of Sky&lt;/head&gt;
    &lt;p&gt;Enhancing how people use AI on their computers.&lt;/p&gt;
    &lt;p&gt;AI progress isn’t only about advancing intelligence—it’s about unlocking it through interfaces that understand context, adapt to your intent, and work seamlessly. That’s why we’re excited to share that OpenAI has acquired Software Applications Incorporated, makers of Sky.&lt;/p&gt;
    &lt;p&gt;Sky is a powerful natural language interface for the Mac. With Sky, AI works alongside you, whether you’re writing, planning, coding, or managing your day. Sky understands what’s on your screen and can take action using your apps.&lt;/p&gt;
    &lt;p&gt;We will bring Sky’s deep macOS integration and product craft into ChatGPT, and all members of the team will join OpenAI.&lt;/p&gt;
    &lt;p&gt;“We’re building a future where ChatGPT doesn’t just respond to your prompts, it helps you get things done. Sky’s deep integration with the Mac accelerates our vision of bringing AI directly into the tools people use every day.” —Nick Turley, VP &amp;amp; Head of ChatGPT&lt;/p&gt;
    &lt;p&gt;“We’ve always wanted computers to be more empowering, customizable, and intuitive. With LLMs, we can finally put the pieces together. That’s why we built Sky, an AI experience that floats over your desktop to help you think and create. We’re thrilled to join OpenAI to bring that vision to hundreds of millions of people.” —Ari Weinstein, Co-Founder and CEO, Software Applications Incorporated&lt;/p&gt;
    &lt;p&gt;Stay tuned for more updates as we get to work integrating Sky’s capabilities.&lt;/p&gt;
    &lt;p&gt;Disclosure: An investment fund associated with Sam Altman held a passive investment in Software Applications Incorporated. This acquisition was led by Nick Turley and Fidji Simo and approved by the independent Transaction and Audit Committees of OpenAI’s board of directors.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45684236</guid><pubDate>Thu, 23 Oct 2025 17:04:17 +0000</pubDate></item><item><title>Can “second life” EV batteries work as grid-scale energy storage?</title><link>https://www.volts.wtf/p/can-second-life-ev-batteries-work</link><description>&lt;doc fingerprint="677ad37521942734"&gt;
  &lt;main&gt;
    &lt;p&gt;Redwood Materials has long dominated EV battery recycling, but what if they could drain every last drop of energy from those batteries before recycling them? I talk with the company’s CTO, Colin Campbell, about Redwood Energy, a new division doing just that by deploying used batteries as grid-scale storage at a massive scale. This isn’t just a side project; it’s a plan to turn a massive wave of incoming used batteries into a key resource for the grid.&lt;/p&gt;
    &lt;p&gt;(PDF transcript)&lt;lb/&gt;(Active transcript)&lt;/p&gt;
    &lt;head rend="h4"&gt;Text transcript:&lt;/head&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Hi everybody, this is Volts for October 22, 2025, “Can ‘second life’ EV batteries work as grid-scale energy storage?” I’m your host, David Roberts. Redwood Materials started recycling lithium-ion batteries before it was cool, before it was profitable, and before there were very many lithium-ion batteries to speak of. In the five years since, it has grown and scaled to capture the overwhelming majority of the booming automotive-battery recycling market in North America.&lt;/p&gt;
    &lt;p&gt;Earlier this year, it spun off a new division called Redwood Energy. The idea is simple: it is going to hook the EV batteries it receives up to large arrays that serve as grid-scale energy storage. That way, it can drain every last bit of useful life out of them before it recycles them.&lt;/p&gt;
    &lt;p&gt;So-called “second life” batteries have been discussed for many, many years, but this is the first time they have been deployed at appreciable scale. Redwood has built an off-grid facility where 20 megawatts of solar panels are powering 63 megawatt-hours of second life batteries that feed into two one-megawatt data centers.&lt;/p&gt;
    &lt;p&gt;Today, I am going to chat with the company’s CTO, Colin Campbell, about why Redwood hatched this initiative, how the costs of second life storage compare with the rest of the storage market, and how big he thinks this side of the business could ultimately get.&lt;/p&gt;
    &lt;p&gt;All right then, with no further ado, Colin Campbell, welcome to Volts. Thank you so much for coming.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;David, thanks so much for having me. Pleasure to be here with you.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Before we jump in, let’s back up a little bit — I should have probably mentioned in the intro you are, in certain circles, semi-famous. Colin Campbell worked at Tesla for many, many years — 17 years — one of their lead engineers. So a big role in designing and growing Tesla. So maybe you could just say briefly what it is that pulled you over to this side of things?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yeah, I was really excited when I joined Redwood to take some of the same philosophies and approaches and really, how should we say it, sort of the ethical impetus that brought me to Tesla and to deploy it in another part of the world. So instead of in consumer devices, cars, in industrial and industry, in things like the metals markets, novel material manufacturing at scale in the US. These are things that I think we all feel have withered a little bit over the last 20, 30 years in the US, and there’s a tremendous opportunity to apply some of the same lessons that we used at Tesla to those industries.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Was it 2019 that Redwood got underway?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yes, that’s right.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;And when Redwood started, there were not that many EV batteries around. So you guys have been recycling all kinds. Basically just taking all lithium-ion batteries. Is that right?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yeah. If you’ve got a lithium-ion battery, we will recycle it for you. So we’ll take your AirPods, your toothbrush, we’ll take that laptop, cell phone, all the way up to EVs.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;When did automotive batteries become the majority of your input by volume?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;That is a good question.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Was it recent or was that early on?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;I would say the transition to EV batteries dominating what we received, it’s been in the last year or 18 months.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;So the front edge of a very large wave of batteries has begun to arrive?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yeah, the wave is out there, it’s coming. The waters have finally started to arrive at the beach here.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;So then comes this idea — and I have to think that someone at Redwood has had this idea in the back of their minds for a while — this idea of you’re getting all these batteries and then you’re just sucking the life out of them before you recycle them. It seems quite logical, but it raises all kinds of questions. So the very first question, I think the most important, because people have been discussing second life batteries for a long time, and always the barrier that keeps people away from it is batteries are very heterogeneous.&lt;/p&gt;
    &lt;p&gt;They come in. There are lots of different chemistries, there are lots of different wear and tear, states of wear and tear, how much life they have in them. You just get a huge variety of batteries. Making all those batteries work together has been the trick. And so when I heard this announcement from Redwood, I was like, “Oh my God, how’d they solve that problem?” And I went and looked and all it says on the site is, “Hey, we solved that problem.” So I’m very curious. Like, I thought that was an extremely difficult problem, but apparently you just hook all these different batteries up to this little box, this little box that you’re calling the universal translator, and voila, they all work together. So can you tell us a little bit about how you did that?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Simple as that. Yes. No, you’re absolutely right. And the idea of a second life battery in a second life energy storage system has been out there for a long time. I think you nailed one piece of it, which was that we weren’t really seeing those batteries come back for, originally, recycling, and now for second life in appreciable volume until really recently. We know it’s inevitable that they’ll come back, but it just hadn’t started to happen yet. And the other thing that’s made this practical — and more than practical, a good business for us — is a couple of realizations we had.&lt;/p&gt;
    &lt;p&gt;So one is that electric vehicle batteries are incredibly robust, and grid-scale energy storage is a relatively pastoral life for those batteries — it’s really like putting the old horse out to pasture. So what that means is you don’t have to do much to them. They’re mechanically made for salt spray and vibration and being underwater, and they’re electrically made for fast charging, for merging onto the freeway, for high performance.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;They’re very high-end.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yes, exactly.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;I don’t know that people understand, one, how high end they are, or two, how big they are — capacity-wise, they’re huge. And then there’s three, sort of how big they are physically. I mean, one of the things that sort of haunted me as I was reading about this, and this is for years, when I think automotive battery, my brain wants to think about the size and shape of the normal —&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;12-volt lead-acid guy.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;12-volt battery, that square. And I was like, “Oh, those little square boxes. Well, those will be easy to stack.” But of course, an actual EV battery is this big, unwieldy, odd-shaped thing that is also heavy. You have to carry them around with forklifts.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yep. So because they’re so awkward and big, if you’re going to repurpose them and have a profitable business doing that, you really can’t spend a bunch of labor on it. So the important thing for us was, don’t disassemble it, don’t mess with it, really use it as it is.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;That’s key here. You’re not getting at the cells, you’re not tearing it down and using the cells, you’re just — it’s just the battery itself. You’re just plugging the battery itself, laying it on the ground and plugging it in.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yeah, there’s a little bit more magic to that, but that’s the core of it — do as little as possible, make it really, really simple to keep it cheap and resilient and flexible for the, what you said, the wide variety of packs that we get.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;And we should say another barrier to making this business work was the incredible logistics involved in gathering batteries, which, of course, you guys are already doing.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yeah, it’s an underappreciated challenge of the recycling business, which is just gathering all the batteries. It’s an incredibly diverse and heterogeneous set of companies, set of individuals, set of utilities, and municipal agencies that collect them. And our commercial team has just crushed it, really, in making it so that all those batteries come to us.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;What’s the percentage now?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;It’s north of 70 or 80%.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;So is that 80% of the batteries that get recycled or do you think it’s 80% of all lithium-ion car batteries?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;It is of the lithium-ion batteries. So more than just car batteries that get recycled in the US.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;So you’re the bulk of the recycling business. But you didn’t actually answer the core of the question, which is — I mean, I’m sure the actual answer is some sort of software gobbledygook that I wouldn’t understand — but what is it that made it possible for you, you guys, to figure this software out when other people have failed?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yeah. So there are two parts, like we said: One is this mechanical simplicity and the other is what you referred to earlier, this box that we’re calling a universal translator. So what is that? That is something that our really strong in-house power electronics team built. It is a way to make sure every one of these unique snowflakes of a pack gets individual care and feeding. So it’s a way to control the voltage, control the power for each pack, depending on its own unique state of health, its own unique state of charge. Also to talk the language of any pack.&lt;/p&gt;
    &lt;p&gt;So if you’ve got 50 different pack manufacturers, they all talk 50 different languages, the content is kind of similar —&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;I was curious about that, are you sort of able to generalize at all or are you really sort of having, “Well, here’s NMC language. We got to program that in.” Is there any sort of commonality among batteries or is it really just bespoke, you got to program every single individual one in there?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;It’s pretty bespoke. The content is the same. All battery packs want to talk about is cell voltages, cell temperatures, and pack currents. But the languages are pretty different.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Interesting.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;So that’s been a real effort and a real successful effort by our software team to abstract that away and make it so that at the high level we just have a battery.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;So I’m curious just how agnostic it is. Can you say with confidence that any EV battery on the market, if you wear it out in your car, you can plug it into this thing? Is that categorical?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;It’s never, never 100%. But we’ve put a lot of effort into making sure we’re in the high 90s. So this universal translator that we built, it’s ready for battery packs anywhere from 200 to 900 volts, for example. So we know more modern cars are higher voltage, semi trucks are higher voltage, Cybertrucks are higher voltage. And then also we’re agnostic to chemistry, so LFP, high nickel, we can take it all.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;That is just wild. So congrats to your software team. It actually raises the question, which is, I’m wondering, like, how modular is this? It seems like the box, the software is the key thing. So if I, for whatever reason, had one of these boxes and I’m like, I don’t know, I run an automotive garage or something and I just happen to have three or four spare EV batteries in my backyard, could I hook them together and treat them like one battery, just using this thing? Like how, how small can it get, I guess is the question?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yeah, you hypothetically could. I’d never thought about it, to be honest. But there’s no reason you couldn’t make a 200 kilowatt-hour site using this same piece of technology.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;So it’ll scale down as far as you would ever want?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;It will. I’ll say that’s not the question we most commonly get. Usually people want to know how big can you go and how fast can you go?&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Yeah, yeah, yeah, well, we’ll get there. But you know, I love me some distributed energy, so I’d love to think about who could do this on site, basically. So you get the batteries and you assess them presumably to see if they’re suitable for this. Sort of like, what’s the criteria and how many batteries make it through?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yeah, the assessment, I think it’s less of an intense torture test than most people imagine. And the reason for that is you don’t need that much cycle life out of a used battery in order for it to make economic sense to put it into service. So you don’t really need perfect understanding of its state of health. You just need to know it’s good enough. And so that’s something — we’ve built some specialized hardware to do that. It’s less than a minute per battery.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Oh, so you get it, you plug it in, you get a thumbs-up or thumbs-down.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Red light, green light.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;And how many batteries get sort of rejected versus accepted, do you know?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;We do know. I’ll have to say we’re constitutionally sort of incapable of rejecting things. So first pass, it’s high 90s that we’re accepting.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Ah, so most batteries then will have some juice left.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Most batteries are good enough, and that doesn’t mean they’re great, but they’re really good enough to deploy. And then we’re always looking at that fraction that got rejected and just saying, “How can we squeeze a little bit more utility out of those?”&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Maybe this comparison you don’t have in the top of your head, but relatively speaking, for a given battery, say an NMC battery, what is the value of this remaining capacity you’re getting out of them versus the value of the metals that you recover out of them?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yeah, well, obviously it varies and we’re learning, but equal to or greater and maybe several times greater.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Oh, interesting. So this is not a marginal bit of value creation. Then you’re getting, you’re 2x-ing the value you get out of these batteries by doing this?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Something like that. Which is like, “Oh my goodness, look at this utility that we were rushing into the recycler. Let’s go and take a detour and capture it.”&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Right, right. So tell me just a little bit about, from an engineering perspective, how you design a system when you know that these batteries, let’s say relative to a typical grid-scale battery installation, you’re going to be mucking with these a lot more. You’re going to be adding them and removing them more frequently than a typical battery installation. How do you design around that to try to keep that cost — because I’ll just say up front, like when I first heard about this, and I’m sure a lot of people say this, like my first thought is just like, “That just sounds like a lot of logistics, like a lot of people, a lot of forklifts, a lot of space, just a lot of logistics.”&lt;/p&gt;
    &lt;p&gt;So it must be clear to you that you’re getting more value out of it than the logistics. But how are you trying to minimize the logistics of being this active — taking things in and out?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yeah, well, the short answer, and maybe not that helpful, is you design for it. So you know that you’re going to have to swap packs more often than in a brand new energy storage site with new cells. And so you provision for that in your design. So, yeah, there’s some small amount of forklift traffic. You make sure it’s really simple to access packs, that it’s really simple for an operator to connect and disconnect packs, to lift them, to move them. And I think one piece of this that is related to that is that these sites are slightly lower energy density than maybe a brand new purpose-built energy storage site. And that really eases service.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;How do you mean? Like, what do you mean safety-wise?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;No, no, just in terms of the megawatt-hours per acre. They’re a little more spread out, and part of that is service and planning for service.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;So you just have to literally physically lay them on the ground. You have to space them out enough that you can get to them, basically?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yeah, it’s actually — I think of it less as a requirement of second life energy storage and it’s more one about like what is the value of a really dense energy storage site? For some sites it’s really important: if you’re in a city, if you’re close to some infrastructure where land is expensive, it’s really important. But in many, many sites it’s less important and you would actually get a lower cost dollars per kilowatt-hour installed with less energy density. And that was one important realization.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Because of lower labor costs, because of easier — it’s just easier to use, easier to update.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Just simpler. The closer you pack cells together, the more careful you have to be because they do contain energy.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Well, let’s talk about safety then. Because I was going to get to that later, but I’m assuming that, like, because these are spaced out so widely and they’re just sort of individually attached, it’s kind of difficult for me to imagine any sort of large-scale fire or any danger really. Is there safety? What is the, what are the safety considerations here?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;So top of the list for us, of course, designing this thing is safety. And our guiding light has always been passive safety. So if you do have a fire for whatever reason, that it stops on its own, that no fire response is needed, no sprinklers are needed, you’re absolutely welcome to. We encourage people to do that, but it’s not necessary. So it’s a passive feature of the system.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;So this individual battery that’s hooked up could theoretically catch on fire, burn up, and be done — and that’s it. And who cares, basically.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;That’s exactly right.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Has that happened? Have you had any thermal runaways yet? I’m always curious what the actual percentage of that happening is.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;No, we haven’t. It’s really rare. I mean, it’s impactful and it’s important when it does. And I think Moss Landing in particular really sticks in everyone’s imagination.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;It really does. That’s why I have to ask this question anytime I talk to a battery company.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yeah. And that’s real. That was a real — that was a bad outcome. But we are designed to avoid anything like that.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;How long have you had enough batteries come through yet that you’re able to generalize about kind of what you’re getting out of them? Like, what is the average lifespan of one of these?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yeah, we really don’t know, to be frank. But what we do know is that it’s long enough to be a good business, that if we deploy them for a year, for 500 cycles, something like that, that makes sense. And we know that that’s well within reach.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;But presumably this little box is recording lots of information about these. So you are gathering tons of data, presumably tons of data about the performance of these used batteries?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yeah, absolutely. I think we’re going to be the clearinghouse for what actually happens at the end of life for EV packs. But it takes a long time. They’re pretty robust. So even after you have rightfully retired one from your car for being slow and having a short range, there are many, many, many years of capacity remaining at that thing.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;80% is like the typical industry — that’s where you sort of cut off the EV battery usefulness. When it gets down to 80%?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yeah, that’s a norm. Depends on the customer. It’s really their choice.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Sure, but 80% is a lot.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Exactly.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;You sort of already answered this, but I’ll ask it anyway: So right now you’re going to places where land is not at a particular premium. And so there’s no real reason not to spread out, as you say. You might even get a little better unit economics spreading out more. I wonder, do you expect all future second life grid-scale storage to be in places where land is not a premium? Because what I’m wondering is, are there engineering ways to get them closer together? Could you ever figure out how to stack them? Like, they are very spread out.&lt;/p&gt;
    &lt;p&gt;And like the first thing that came to mind was, if this becomes really valuable and really common, somebody is going to figure out how to squish them closer together. Is that something you think about at all?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;We do think about it and we in fact have already done it. So our architecture is flexible, so we really work with our customer to understand the value of density to them. And if it’s high, then we can provide a much denser product.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;You can do it. Is there stacking? Can you stack them at all? Go vertical at all? Because this is the thing, they just spread out horizontally. And I can’t help thinking, if you could just go up a couple of stories, you could fit so much more.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yeah. There are a bunch of different ways to do it, and it just starts to get a little more complicated. You’ve got to build the tower for them to live in and figure out how to get them in and out. It’s all possible. It all makes sense in certain circumstances, but not all. So we work with the people who are buying these to figure out what makes sense.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Is the idea here that you will be the developer and the owner of the battery in all cases, or are you selling, will someone else own and operate them? What’s the business model exactly?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;I mean, this industry, there’s probably every business model under the sun available, and we’re open to pretty much all of them. The one thing that is important to us is that we recycle the packs. That’s part of our mission. It’s part of what we think is important to do in North America, and we intend to do that.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;But that sort of suggests that the model that makes the most sense is for you to just be sort of having them and owning them and running them the whole time. Or is the idea that you could ship a bunch of these to a separate site, they set up one of these, and then they ship them back to your facility when they’re done with them, but they own them while they’re in the battery?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;There’s — I’m not trying to be cute — you could imagine a million different ways to structure that sort of contractual relationship. And in the end, the batteries, we still would like to receive them for recycling.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;I guess it’s more like the physics or logistics of it. I’m sort of wondering about. Because doing this right next to the plant where they’re recycled makes just a ton of sense. Obviously, there’s very little logistics, but once you have one of these set up in a spot that is remote from the recycling facility, then the fact that packs are coming in and out frequently becomes a little bit more of an issue. Because then you have a sort of a supply chain between you and a remote facility. That doesn’t daunt you at all?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;You have to think about it. But this is not like rail cars and rail cars of packs going back and forth, even from a giant energy storage site. It’s like a few. And at the beginning, while we are really pioneering this and doing it for the first time — I think it makes total sense for us to do it ourselves. And we will. But I don’t think that’s necessary long term.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;So one of the claims your CEO J. B. Straubel makes in his sort of introductory video is that this is going to be cheaper than grid-scale storage with new lithium-ion batteries. And I guess the calculation there is — on one hand, your business model works as is. So you have the batteries from the perspective of this new division basically for free. Like they’re already there. You’re already gathering them. So in a sense, even if they’re lower quality than new batteries, they’re just sitting there. So, in a sense they’re cheaper that way.&lt;/p&gt;
    &lt;p&gt;But on the other hand, you have all this logistics, you have all these forklifts and trucks and setting up and the space and site and everything else. So I’m just wondering how the costs balance out. Is there an easy comparison between a new second life battery and a brand new battery? Like a cost comparison?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yeah, I think as you pointed out, the cost of energy is low compared to a brand new battery because it’s degraded, it’s been out in the world, it’s not a fresh battery. The balance of system, we’re actually making really important strides there too. So the power electronics, the mechanical assembly, there’s a lot of cost in these sites around what people call the EPC cost — engineering, procurement, construction — civil works, getting the batteries plugged in, wiring the whole thing up. And we spent and are spending a lot of time optimizing sort of the rest of the cost stack.&lt;/p&gt;
    &lt;p&gt;So not just leaning on the fact that our energy is relatively low cost because it is second life energy, but really pushing hard on power electronics. We have that whole team in-house. Push down the dollars per watt of power electronics, make it a really, really simple, really, really robust thing to deploy. And that’s underappreciated about what we’re up to — it’s not just that the batteries are cheaper, the whole system is simpler.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Well, that’s, I mean, it’s the whole system that first jumped up when I started reading about this. Like obviously that’s where, like, you found an incredibly cheap source of batteries, i.e. a big pile of batteries you already had in your backyard. But like, it’s all, all the costs are the logistics and the balance of system stuff. So you think you have running room there to bring those costs down substantially?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Absolutely.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;But you can claim that you are beating a new lithium-ion grid-scale battery storage system on the sort of per kilowatt-hour basis already?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yes, we can, and that’s installed over life. So there’s a little bit of pack replacement that has to happen.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Do you have a number? What are you pitching to people when you’re trying to sell this?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;I do have a number, but it’s enough to make it a really good, great business, I think, is what I will say here.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Okay, but like, sort of legendarily, a new lithium-ion battery grid-scale storage — they sort of will do four hours, some of them will do eight hours. Some people now are pushing the economics because batteries are getting cheaper. They’re pushing the economics out to maybe 12 hours at the outer edge. If your unit costs are that much cheaper, how — what kind of durations do you think you can get given your cheaper system?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;You’ve actually nailed it there. So because energy is cheaper, the balance of plant, which we are making great progress on, like power electronics, the cost of power starts to become more important. And so we have a real advantage for eight-hour and beyond energy storage. We can play and compete and win at 2-hour and 4-hour on total installed cost over life. But it starts to look really compelling at the longer durations.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Oh, interesting. Can you do 24 hours? The Holy Grail. Could you make something baseload out of this?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Absolutely. The original modeling that we did for this was around a 24-hour system. Turning renewables into baseload. Looks really good.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;I’ve been told by many very confident-sounding people, Colin, that that’s impossible. So you say you did it. So do you envision the next plant you build and the next one after that — do you envision hooking these up to the grid and having them sort of make money off providing services to the grid, arbitrage, frequency, et cetera, et cetera? Or do you primarily envision doing what you’ve done with this first installation, which is going off-grid? You got solar panels, you got batteries, you got data centers. It’s all hooked up together, it’s all self-contained and running on its own, and does not need one of these very difficult-to-get grid connections.&lt;/p&gt;
    &lt;p&gt;Which model do you think is going to dominate?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;We are going to do all of the above. We can and we are doing sites for grid services. Just plug a battery into the grid and help support the grid by participating in the market. We have other “microgrids.” They’re not so micro anymore. They’re many, many, many megawatts.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Go ahead and brag. This one you built? Yeah, it’s Nevada. I forget — it’s the biggest microgrid in America? You are claiming North America.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;It’s the largest microgrid in North America and it’s the largest second-energy storage site in the world. So that’s like you said at the top, it’s a 12-megawatt AC, 63-megawatt-hour grid supporting about 2 or 3 megawatts of data centers and run by solar. So all the energy comes from another 12 megawatts of solar.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;And the grid does not touch it. There’s no transmission grid connection at all?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;That’s exactly right.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;What a beautiful thing. I’ve also been confidently told that those things don’t work economically. Exciting that it is working. And you’ve probably answered this already. But in terms of grid services, you hook one of these things up to the grid, there’s nothing that new batteries can do that these batteries can’t do, right? In terms of frequency regulation and all this kind of stuff. Grid forming, whatever. The kind of things that the batteries and inverters can do.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Virtual inertia, all of that. I mean, one of the things that is very topical right now is the data center market, of course, like a giant increase in the demand for power.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Indeed.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;And there’s just this beautiful symbiosis between energy storage and data centers. Sort of no matter what your primary source of power is. So much of it is the, there’s already huge racks of batteries and uninterruptible power supplies inside the data center. Already these big diesel generators. We can make both of those things obsolete.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;So you now have two little data centers running. I mean, the data center company technology that you’re using at this site is also pretty interesting on its own merits. But they’re building basically what they call modular data centers. And I’ve been wondering when someone’s going to do this because everybody, it’s kind of the same arc nuclear went on at first. Everybody’s like economies of scale. Economies of scale. Bigger, bigger, bigger, bigger, bigger, big, big, big. And you’re getting these data centers now that are like small cities, like gigawatt-plus data centers. And I have part of this podcast premise to hunt great faith in modularity and repeatability and manufacturability competing against those economies of scale.&lt;/p&gt;
    &lt;p&gt;So this company is making data centers at this site in Nevada, is making these basically like containerized, modularized data centers. Like a 1-megawatt data center with all the power, electronics, cooling, etc., contained in the box, basically.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;That’s our partner Crusoe, we love them, they’re super smart and they’re doing exactly what you’re talking about, which is: how do we drive down the cost of a data center? We mass-manufacture it.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Mass manufacture and distribute so it’ll be distributed just like everything else. And then you can wedge a little bit of data centering here and a little bit of data centering there rather than having to look for a mega site. But anyway, that’s probably a whole separate pod on its own. But yeah, but again, so there’s — so you could, in terms of building these sort of like off-grid, self-contained solar plus battery plus use — whoever’s in that use, that could be any manufacturing, be a factory, be anything?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Could be anyone who needs power. So data center is obviously top of the list right now. You can go set up a data center quite quickly and run it off solar and storage while you wait for your grid interconnection. If you’re planning to put a natural gas turbine, while you wait for that turbine to show up, those are actually — can be at the power levels we’re talking about, they can take a long time.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Yes.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;So we can help sort of blaze the trail. And then there’s really a tremendous amount of utility and, like I said, symbiosis between data centers and energy storage.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Well, just speed too, right? Like the top — you know this — the top thing hyperscalers are saying, the top thing data centers want is speed to market. They hardly care about the cost, they just want to get hooked up, time to power. And I’m guessing, tell me if I’m wrong, but I’m guessing you can build one of these things, a solar field and a battery field attached to a manufacturing facility, faster than any large-scale centralized power plant. Is that —&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;That is turning out to be true.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;How fast? Do you have a number yet? You’ve only built one.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;I mean it obviously depends so much on scale, but 12 months, 18 months.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;How long did it take to build the one you built?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;I mean, the one we built from empty dirt pad to fully commissioned was like four months.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;What?! A four-month timeline for a fully operational 24/7 power supply.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;This is where the simplicity of install is so important.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Yeah, so again, you’re pushing away at that, the balance of system, the speed, etc. But again, already four months is just wildly faster than anything else available. Have you learned anything — I mean, this thing, this one you’ve got running has only been running for two, three months. It’s relatively new, so I’m sure there’s lots more to learn. But have you learned anything about the performance of these things in the field? Like, are you getting data that is updating any of your priors? Is anything surprising you about what’s actually happening out there?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;So far, no surprises. So we’re confirming a lot of the things that we had modeled out. We have a really excellent physics-based modeling team. So I’ll give you one example. A lot of EV batteries are liquid cooled. So if you are driving around in your electric car, your cells are cooled by fluid that runs through a radiator. And we don’t use that system because of the complexity that’s associated with pumps and pipes and fluids and all of those things. And we now know for a fact that that is absolutely fine in the middle of the desert in the summer.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;So most of the overheating probably comes from being contained in a hot car over hot pavement. In that environment, they just won’t overheat if you’re sitting them out in the open.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;It’s really about the rate that we are pushing power into them.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Oh, I see.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;So if we’re discharging, say at the fastest, over two hours, that’s pretty chill for a battery compared to showing up at a supercharger and trying to fill it in 20 minutes.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Again, this is out to pasture again. These are old horses that are being treated gently.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;So it’s working exactly as we expected it to.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;And you’re not worried at all that in the fullness of time, because batteries, new batteries are legendarily rapidly falling in cost, you’re not worried at all that at some point that process is going to undercut your economics. Do you think you’re going to stay ahead of that?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yeah, well, I think a used battery is always going to be cheaper than a new one. I’m pretty confident in that. And the other piece of it is what I talked about a little bit earlier. We’re not sitting still on the non-battery parts. So we’re really, we have a great team, power electronics, mechanical engineering, software, all of that pushing down the cost of all the things that aren’t the battery.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Is there a future where you include other kinds of non-automotive batteries in this system? Like, is there another kind of battery that has enough juice in it to make it worth the squeeze?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;I think so. I mean, we’re pretty agnostic to battery type. So it really comes down to sort of acquisition cost, in the end.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;I’m just sort of assuming that like a toothbrush battery is just not going to be worth getting the human to walk out there and plug it in.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Let me backpedal. I don’t think ever that you’ll see like a matrix-like field of AirPods or toothbrushes.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;So what’s the general cutoff? Like a weed whacker battery, like how big before...?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;I don’t know, but I bet somewhere in the like 10 to 14 kilowatt-hour range, somewhere in there it’ll start to make sense. So maybe light hybrids, but not weed whackers.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;And not toothbrushes. So in terms of the logistics of gathering the batteries, I’m assuming that’s all already up and running. That’s what you’ve been doing for the last few years. Is your ability to do this with the batteries going to change that side of things — how you gather them? I know there’s some sort of partnership with GM, it’s a little vague on the website, exactly what that consists of. What is that?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Well, I think we’ve really put more effort into exactly those kinds of partnerships with automakers who sometimes have the packs at their end of life and need a place to send them.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Do they, though? Why would they, like, why would GM end up with used GM batteries?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Well, sometimes. So some, some packs —&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;I’m so curious, what happens to a battery — like if my battery runs out, I go to a — I don’t know, a mechanic or whatever and get a new one. I have no idea what happens to it. Tell us just a little bit about what that looks like?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Everything under the sun happens to it. So if it’s a dealer, then that’s one, like, pretty consistent path. If it’s a shop, your local EV service shop, it’s actually been a challenge for them. And it’s one thing that, well before this energy storage business started, that we’ve been working hard to make as easy as possible. So we actually have sort of a — I don’t know what you want to call it, like a reverse Amazon — to make it super easy to send big batteries like this to us to figure out what they’re worth and get them on their way.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;So they mail them to you, basically, they ship them to you.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yes.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Interesting. And that — I don’t know, that just seems so expensive when I think about it. Again, so much logistics. It’s amazing how much logistics is involved in your business model.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Logistics is a real thing. It’s also remarkable how efficient it is to move mass around. Transportation costs for a battery are not a giant piece of the concern. It’s really the complexity of just like there’s a million places these end up — junkyards, people’s houses, dealerships, everything you can imagine.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;What is the GM partnership, the newer GM partnership? It caught my eye, and the reason I ask about it is because I thought it would just be them getting you their old batteries. But it also says something in the press release about them maybe sending you new batteries also to be included in these power plants. So I was wondering about that — if there would ever be any reason for new batteries to wander into this milieu.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yeah, well, maybe a couple things. GM’s been tremendously collaborative with us as we embark on the second life project. And we appreciate that. It’s very helpful to have their support as we do it. And then not specific to GM, but you do have to ask yourself the question “Why do these batteries have to be used?” And if we can do a good enough job on the balance of system costs, then they don’t. That’s not our focus right now, but it’s something that definitely is on my mind.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Interesting. So theoretically, you could end up being just a very competitive grid storage company that is agnostic to the source of batteries?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Could be.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Someday, maybe.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;The thing that we’re getting good at right now, and it’s still — it’s still early days, I want to emphasize that for us — is being uniquely capable of integrating all of these zillion different battery types. So this, like, heterogeneity is something that we’re really good at.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Which raises a question I’ve had about Redwood forever. Recycling really forever. Now that you are big enough to sort of throw your weight around a little bit, you’re a big player in this market. Have you initiated any kind of talks with battery designers and manufacturers about trying to get batteries to be designed more for recyclability on the front end? And now that I think about it too, that would probably — like, the more sort of uniform they get and the easier to recycle it gets, I feel like that would also have the effect of making them easier to do this with, to integrate into these things with. Are you at all trying to influence the design of batteries on the front end?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;That’s a great question. And I confronted that a little bit in my prior life where I was designing EV battery packs.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;I think Tesla’s actually famous for designing batteries that are very not that. They’re very integrated into the car. They’re very — not particularly recyclable.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;I’ll say a couple things about that. One is, when you’re doing things the way that we need to do them to make an impact in the world at industrial scale, having packs be disassembled by hand or even with automation, the sort of design for recyclability, that’s pretty expensive. And so I think the recycling processes that win are going to be something that is at least philosophically like backing up a truck full of packs and like dumping them into a machine.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Are you physically disassembling all the batteries now? Before you recycle them in the recycling process.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Right now I try not to. I try to send them into energy storage.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;You hire people to do that.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;But no, our processes don’t require a great deal of disassembly because every pack is different, and I think every pack is rightfully different in order to make a great car or a great truck or whatever it is, it’s hard to make those things.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;So you think standardization is going to happen on the recycling end, not on the design end, basically?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;I think so. And I think the processes for separating out all of the metals that are contained in a pack are going to work fine, regardless of how the pack was built.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Yeah, yeah, I need to do another pod just on the recycling stuff. By way of wrapping up, let’s look out a little bit into the future. When I brought this up online, a lot of people’s first reaction was, “Well, that seems like kind of a boutique distraction from the core business that Redwood’s in.” And the more I looked into it, I was like, “Well, there’s like two gazillion batteries on the way to recycling.” Again, we’re just at the front end of this. They’re just sort of trickling in now, I guess you’d say, in what is going to become a flood.&lt;/p&gt;
    &lt;p&gt;So you could see this growing and expanding quite a bit. I just wonder how you see this division relative to the recycling division. I mean, you sort of touched on this earlier. Do you think this will be, in the fullness of time, a comparably sized part of the business or even bigger than the recycling part?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Absolutely. There’s plenty of batteries out there in the world that are going to need to be reused. Like you — you hit on it. It’s like, what is North American EV pack production per year today? It’s 100 gigawatt-hours, 150 gigawatt-hours per year. And then the entire storage, I think, deployed last year in the US was — was half of that. So, the EV market is, for the moment, quite big compared to the storage market. They’re both growing, but —&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;EVs are growing faster. I mean, I’m assuming EVs are always going to dwarf stationary storage.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Storage is catching up. I think it’s about a quarter of the cells in the US that go into storage.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Really? That’s bigger than I would have guessed.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;But the point is there’s plenty of used packs. We know that it’s inevitable they’re going to come back. So that’s to the like, is it a boutique distraction? No, I think it’s a real durable business. And to the question, is it a distraction? We are still quite committed to the metals business. I think that’s still so exciting and so important to bring back to North America.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;And this does seem like, to me at least, this seems just to fit right in. Like in a sense, it’s almost like a version of recycling. You’re sort of recycling power. You’re recycling the power before you recycle the metals.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;I was trying to think about how to say this.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;But in the same way, you’re preventing new stuff from having to be made. I mean, in a sense, in both cases, you’re preventing the necessity for new stuff.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yeah, I mean, the need for new stuff is gigantic. And so in order to fuel a complete electrification of the economy, there’s still a lot of new stuff we’re going to need, but we can in the short term blunt that a little bit and make it cheaper by extracting really every last drop of utility, whether it be energy storage capacity, whether it be the metals out of old things. And then if you fast forward 100 years, like it’ll all be circular.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;So this is, especially in these depressing current times. These are among, among the places I go, my happy places is thinking about this 100-year time horizon and total circularity. And it’s interesting to think how this fits into that picture, basically. You can imagine a world of full circularity vis-à-vis metals, right, where we no longer are having to dig up any new metals, basically. We’ve reached a steady state. We’re perfectly recycling all the metals that come through.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;You can. The thing I want to emphasize is that that also just makes economic sense. It is a cheaper way to provide nickel and lithium in addition to being sort of lower carbon and all of the other things that circularity provides.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Yes. Less grim labor implications, all that kind of stuff as well. But I was sort of thinking about how this fits into that. Like if you’re getting all the world’s batteries and recycling them and you’re sucking all this capacity out of them before you recycle them, you’re also like, that’s a big, potentially a big chunk of the energy storage we need. I don’t know if anybody’s tried to do this kind of math, like 20 years out or whatever, 50 years out. Like what, what sort of — like how much of the stationary storage market in the US do you think could ultimately be served by second life batteries?&lt;/p&gt;
    &lt;p&gt;This is all napkin math, of course.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;It’s a good question. So today we can serve like 10, 15% of the market.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Really? Already with the batteries you’re receiving today?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yeah, so we’re receiving something like 5 gigawatt-hours a year. And I think the US put 50 into service this year.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;5 gigawatt-hours a year. And this plant you built, we should say, this off-grid plant, it’s like 63, not, it’s not even 100 megawatt-hours. So to really scale this up to start matching the input, that’s just going to be a lot of land, isn’t it? You’re not worried at all about the land?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;I mean, this is like, this is a version of “Am I worried about the land use of solar?” And no, turns out you get a lot of, a lot of energy density coming from the sun. A lot of power density, sorry. And if you look at the size of — we can even look at our pilot plant in Nevada. If you look at the size of the battery compared to the size of the solar array, it’s 1/10 the size.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;1/10?!&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;So, and that’s, we could do better. We could do 1/20 or 1/30 if we wanted to.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Ah, so you can shrink down the size of the battery thing. Can’t really shrink down the size of the solar.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yeah, exactly. So, it’s not that big.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;So for the off-grid applications, it would be the generation. That would be the land, the real land issue, not so much the batteries. What’s next? We pull our view out from 100 years out to say five. What’s next? What’s the next plant? Do you imagine being sort of the owner and developer of the next few of these as you kind of prove them out and show they can work?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;What’s next is much bigger projects. So we have several of those lined up already in the 5 to 10 and bigger x the one we put in Nevada. So substantially bigger than our pilot site in Nevada. And so we’re really focused on executing those and delivering those.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;And are those in Nevada?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;They’re all over the country.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Really? I think of the vast west desert as where you find these big swaths of cheap land. Are you building — you have your eye on the east coast, the northeast, congested areas too?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;We have projects — I’m sort of like doing the Rolodex in my head here — not quite everywhere in the country, but not just in the desert west, to your point.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Interesting. And I’m sure some of this is confidential, but for the projects in your pipeline, are they all off-grid, attached to solar in some sort of manufacturing facility, or are some of them going to be grid-connected?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Some of them will be grid connected. Like if you can imagine a place where somebody has put a utility-scale battery, we have a project like that. We have grid-connected grid arbitrage. We have behind the meter, front of the meter. We have paired with manufacturing, paired with renewables.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Any energy storage plays, basically.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Exactly. Same energy storage as any other kind.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;As I think about the logistics, new things keep coming to mind. But in terms of your battery gathering, how many sites do you have where you’re gathering batteries? Because wherever you build one of these, you are establishing basically an ongoing relationship to some source of these batteries, right? A supply chain. You’re going to have to have batteries continually shipped between where they’re gathered and where you have this plant. How many of those battery gathering sites are there?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;As this becomes a national project for us, we need sort of regional warehousing.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Is it all in the one Nevada plant at this point?&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;It’s not. We also have a big site that we’re developing and actually just opened our first recycling plant there in South Carolina. So that’s a strategic spot for us on the east coast, near a port, near a lot of industry. And that’s another logical place for us to inventory this stuff. But I imagine, in the fullness of time, we will put them where it makes sense to support these customers.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;I just keep trying to wrap my head around the shift that you are about to undergo. Like right now you say you got 5 gigawatt-hours a year of batteries incoming.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Gigawatt-hours.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Yep, gigawatt-hours, sorry. I’m assuming that the line is going up and to the right.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yes, it is.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;How fast per year? Like, what’s next year? How steep is that line? I mean, I’m assuming it’s just going to get real steep relatively soon. But I don’t know if you’ve actually charted it out and plotted it out.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yeah, it’s a little hard to predict, but we’ve seen 50% year-on-year growth at the beginning of this wave. And you can look back at the beginning of EV manufacturing in 2012 in volume. What was the ramp rate? And we’re going to see something like that.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Interesting. So we’re going to go from like 5, 10. Like having 100 GWh of batteries coming through is not crazy. Not out of the...&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Yeah, I mean, you can almost just predict it. We’re making 100 gigawatt-hours today, so in 10 years we’ll be seeing those come back ready for second life.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;And so then I just, at that level of volume, getting more power out of them will in no way be a small thing. I think this is what J. B. Straubel was kind of trying to get at in his big talk — this may look like a side thing today, but it’s going to be enormously important. If you’ve got 100 gigawatt-hours coming through, that’s a lot of power to just be throwing away. So it’s just going to be a lot more significant in five years.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;It really will. So we are laying the groundwork for this. This team knows how to build things at scale. We have done it before. The business and the power electronics, the mechanical bits that we’re designing for energy storage, they’re all designed for mass manufacture, for simple assembly in the field. Because we know that this is coming — tens and hundreds of gigawatts.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Well, I love to see someone getting ahead of the puck. As I look around these days at US politics, it’s nice to see someone anticipating what’s going to happen and getting ready before it happens. Just a beautiful thing to witness.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;Thank you. We’re having fun. We love finding something valuable that hasn’t been extracted and going after it. And this is just another example of it.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Yeah, it’s just a bunch of puzzles. I mean, all this second life stuff is just an enormous logistical puzzle to solve. And solving puzzles is fun.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;We really enjoy it.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Colin, thanks so much for coming on and talking us through this. Really interesting. I think it’s a lot bigger of a deal than it sort of appears on the surface. So it was fun to — fun to dig in a little bit with you. Thanks for coming on.&lt;/p&gt;
    &lt;p&gt;Colin Campbell&lt;/p&gt;
    &lt;p&gt;So fun to be here. Great questions. Really enjoyed it.&lt;/p&gt;
    &lt;p&gt;David Roberts&lt;/p&gt;
    &lt;p&gt;Thank you for listening to Volts. It takes a village to make this podcast work. Shout out, especially, to my super producer, Kyle McDonald, who makes me and my guests sound smart every week. And it is all supported entirely by listeners like you. So, if you value conversations like this, please consider joining our community of paid subscribers at volts.wtf. Or, leaving a nice review, or telling a friend about Volts. Or all three. Thanks so much, and I’ll see you next time.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45685007</guid><pubDate>Thu, 23 Oct 2025 18:15:45 +0000</pubDate></item><item><title>Zram Performance Analysis</title><link>https://notes.xeome.dev/notes/Zram</link><description>&lt;doc fingerprint="f2e918dba5296b1d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Zram Performance Analysis&lt;/head&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Zram is a kernel module that utilizes a compressed virtual memory block device allowing for efficient memory management. In this document we will analyze the performance of various compression algorithms used in Zram and their impact on the system. We will also discuss the effects of different page-cluster values on the system’s latencies and throughput.&lt;/p&gt;
    &lt;head rend="h2"&gt;Compression Algorithm Comparison&lt;/head&gt;
    &lt;p&gt;The following table compares the performance of different compression algorithms used in Zram, in terms of compression time, data size, compressed size, total size, and compression ratio.&lt;/p&gt;
    &lt;p&gt;Data from Linux Reviews:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;Algorithm&lt;/cell&gt;
        &lt;cell role="head"&gt;Cp time&lt;/cell&gt;
        &lt;cell role="head"&gt;Data&lt;/cell&gt;
        &lt;cell role="head"&gt;Compressed&lt;/cell&gt;
        &lt;cell role="head"&gt;Total&lt;/cell&gt;
        &lt;cell role="head"&gt;Ratio&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;lzo&lt;/cell&gt;
        &lt;cell&gt;4.571s&lt;/cell&gt;
        &lt;cell&gt;1.1G&lt;/cell&gt;
        &lt;cell&gt;387.8M&lt;/cell&gt;
        &lt;cell&gt;409.8M&lt;/cell&gt;
        &lt;cell&gt;2.689&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;lzo-rle&lt;/cell&gt;
        &lt;cell&gt;4.471s&lt;/cell&gt;
        &lt;cell&gt;1.1G&lt;/cell&gt;
        &lt;cell&gt;388M&lt;/cell&gt;
        &lt;cell&gt;410M&lt;/cell&gt;
        &lt;cell&gt;2.682&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;lz4&lt;/cell&gt;
        &lt;cell&gt;4.467s&lt;/cell&gt;
        &lt;cell&gt;1.1G&lt;/cell&gt;
        &lt;cell&gt;403.4M&lt;/cell&gt;
        &lt;cell&gt;426.4M&lt;/cell&gt;
        &lt;cell&gt;2.582&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;lz4hc&lt;/cell&gt;
        &lt;cell&gt;14.584s&lt;/cell&gt;
        &lt;cell&gt;1.1G&lt;/cell&gt;
        &lt;cell&gt;362.8M&lt;/cell&gt;
        &lt;cell&gt;383.2M&lt;/cell&gt;
        &lt;cell&gt;2.872&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;842&lt;/cell&gt;
        &lt;cell&gt;22.574s&lt;/cell&gt;
        &lt;cell&gt;1.1G&lt;/cell&gt;
        &lt;cell&gt;538.6M&lt;/cell&gt;
        &lt;cell&gt;570.5M&lt;/cell&gt;
        &lt;cell&gt;1.929&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;zstd&lt;/cell&gt;
        &lt;cell&gt;7.897s&lt;/cell&gt;
        &lt;cell&gt;1.1G&lt;/cell&gt;
        &lt;cell&gt;285.3M&lt;/cell&gt;
        &lt;cell&gt;298.8M&lt;/cell&gt;
        &lt;cell&gt;3.961&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Data from u/VenditatioDelendaEst:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="7"&gt;
        &lt;cell role="head"&gt;algo&lt;/cell&gt;
        &lt;cell role="head"&gt;page-cluster&lt;/cell&gt;
        &lt;cell role="head"&gt;MiB/s&lt;/cell&gt;
        &lt;cell role="head"&gt;IOPS&lt;/cell&gt;
        &lt;cell role="head"&gt;Mean Latency (ns)&lt;/cell&gt;
        &lt;cell role="head"&gt;99% Latency (ns)&lt;/cell&gt;
        &lt;cell role="head"&gt;comp_ratio&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;lzo&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;5821&lt;/cell&gt;
        &lt;cell&gt;1490274&lt;/cell&gt;
        &lt;cell&gt;2428&lt;/cell&gt;
        &lt;cell&gt;7456&lt;/cell&gt;
        &lt;cell&gt;2.77&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;lzo&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;6668&lt;/cell&gt;
        &lt;cell&gt;853514&lt;/cell&gt;
        &lt;cell&gt;4436&lt;/cell&gt;
        &lt;cell&gt;11968&lt;/cell&gt;
        &lt;cell&gt;2.77&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;lzo&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;7193&lt;/cell&gt;
        &lt;cell&gt;460352&lt;/cell&gt;
        &lt;cell&gt;8438&lt;/cell&gt;
        &lt;cell&gt;21120&lt;/cell&gt;
        &lt;cell&gt;2.77&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;lzo&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;7496&lt;/cell&gt;
        &lt;cell&gt;239875&lt;/cell&gt;
        &lt;cell&gt;16426&lt;/cell&gt;
        &lt;cell&gt;39168&lt;/cell&gt;
        &lt;cell&gt;2.77&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;lzo-rle&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;6264&lt;/cell&gt;
        &lt;cell&gt;1603776&lt;/cell&gt;
        &lt;cell&gt;2235&lt;/cell&gt;
        &lt;cell&gt;6304&lt;/cell&gt;
        &lt;cell&gt;2.74&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;lzo-rle&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;7270&lt;/cell&gt;
        &lt;cell&gt;930642&lt;/cell&gt;
        &lt;cell&gt;4045&lt;/cell&gt;
        &lt;cell&gt;10560&lt;/cell&gt;
        &lt;cell&gt;2.74&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;lzo-rle&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;7832&lt;/cell&gt;
        &lt;cell&gt;501248&lt;/cell&gt;
        &lt;cell&gt;7710&lt;/cell&gt;
        &lt;cell&gt;19584&lt;/cell&gt;
        &lt;cell&gt;2.74&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;lzo-rle&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;8248&lt;/cell&gt;
        &lt;cell&gt;263963&lt;/cell&gt;
        &lt;cell&gt;14897&lt;/cell&gt;
        &lt;cell&gt;37120&lt;/cell&gt;
        &lt;cell&gt;2.74&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;lz4&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;7943&lt;/cell&gt;
        &lt;cell&gt;2033515&lt;/cell&gt;
        &lt;cell&gt;1708&lt;/cell&gt;
        &lt;cell&gt;3600&lt;/cell&gt;
        &lt;cell&gt;2.63&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;lz4&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;9628&lt;/cell&gt;
        &lt;cell&gt;1232494&lt;/cell&gt;
        &lt;cell&gt;2990&lt;/cell&gt;
        &lt;cell&gt;6304&lt;/cell&gt;
        &lt;cell&gt;2.63&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;lz4&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;10756&lt;/cell&gt;
        &lt;cell&gt;688430&lt;/cell&gt;
        &lt;cell&gt;5560&lt;/cell&gt;
        &lt;cell&gt;11456&lt;/cell&gt;
        &lt;cell&gt;2.63&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;lz4&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;11434&lt;/cell&gt;
        &lt;cell&gt;365893&lt;/cell&gt;
        &lt;cell&gt;10674&lt;/cell&gt;
        &lt;cell&gt;21376&lt;/cell&gt;
        &lt;cell&gt;2.63&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;zstd&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;2612&lt;/cell&gt;
        &lt;cell&gt;668715&lt;/cell&gt;
        &lt;cell&gt;5714&lt;/cell&gt;
        &lt;cell&gt;13120&lt;/cell&gt;
        &lt;cell&gt;3.37&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;zstd&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;2816&lt;/cell&gt;
        &lt;cell&gt;360533&lt;/cell&gt;
        &lt;cell&gt;10847&lt;/cell&gt;
        &lt;cell&gt;24960&lt;/cell&gt;
        &lt;cell&gt;3.37&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;zstd&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;2931&lt;/cell&gt;
        &lt;cell&gt;187608&lt;/cell&gt;
        &lt;cell&gt;21073&lt;/cell&gt;
        &lt;cell&gt;48896&lt;/cell&gt;
        &lt;cell&gt;3.37&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;zstd&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;3005&lt;/cell&gt;
        &lt;cell&gt;96181&lt;/cell&gt;
        &lt;cell&gt;41343&lt;/cell&gt;
        &lt;cell&gt;95744&lt;/cell&gt;
        &lt;cell&gt;3.37&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Data from my raspberry pi 4, 2gb model:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="7"&gt;
        &lt;cell role="head"&gt;algo&lt;/cell&gt;
        &lt;cell role="head"&gt;page-cluster&lt;/cell&gt;
        &lt;cell role="head"&gt;MiB/s&lt;/cell&gt;
        &lt;cell role="head"&gt;IOPS&lt;/cell&gt;
        &lt;cell role="head"&gt;Mean Latency (ns)&lt;/cell&gt;
        &lt;cell role="head"&gt;99% Latency (ns)&lt;/cell&gt;
        &lt;cell role="head"&gt;comp_ratio&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;lzo&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;1275.19&lt;/cell&gt;
        &lt;cell&gt;326448.93&lt;/cell&gt;
        &lt;cell&gt;9965.14&lt;/cell&gt;
        &lt;cell&gt;18816.00&lt;/cell&gt;
        &lt;cell&gt;1.62&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;lzo&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1892.08&lt;/cell&gt;
        &lt;cell&gt;242186.68&lt;/cell&gt;
        &lt;cell&gt;14178.77&lt;/cell&gt;
        &lt;cell&gt;31104.00&lt;/cell&gt;
        &lt;cell&gt;1.62&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;lzo&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;2451.65&lt;/cell&gt;
        &lt;cell&gt;156905.52&lt;/cell&gt;
        &lt;cell&gt;23083.55&lt;/cell&gt;
        &lt;cell&gt;56064.00&lt;/cell&gt;
        &lt;cell&gt;1.62&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;lzo&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;2786.33&lt;/cell&gt;
        &lt;cell&gt;89162.46&lt;/cell&gt;
        &lt;cell&gt;42224.49&lt;/cell&gt;
        &lt;cell&gt;107008.00&lt;/cell&gt;
        &lt;cell&gt;1.62&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;lzo-rle&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;1271.53&lt;/cell&gt;
        &lt;cell&gt;325511.42&lt;/cell&gt;
        &lt;cell&gt;9997.72&lt;/cell&gt;
        &lt;cell&gt;20096.00&lt;/cell&gt;
        &lt;cell&gt;1.62&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;lzo-rle&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1842.69&lt;/cell&gt;
        &lt;cell&gt;235863.95&lt;/cell&gt;
        &lt;cell&gt;14627.23&lt;/cell&gt;
        &lt;cell&gt;34048.00&lt;/cell&gt;
        &lt;cell&gt;1.62&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;lzo-rle&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;2404.35&lt;/cell&gt;
        &lt;cell&gt;153878.65&lt;/cell&gt;
        &lt;cell&gt;23592.19&lt;/cell&gt;
        &lt;cell&gt;60160.00&lt;/cell&gt;
        &lt;cell&gt;1.62&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;lzo-rle&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;2766.61&lt;/cell&gt;
        &lt;cell&gt;88531.46&lt;/cell&gt;
        &lt;cell&gt;42579.14&lt;/cell&gt;
        &lt;cell&gt;114176.00&lt;/cell&gt;
        &lt;cell&gt;1.62&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;lz4&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;1329.87&lt;/cell&gt;
        &lt;cell&gt;340447.83&lt;/cell&gt;
        &lt;cell&gt;9421.35&lt;/cell&gt;
        &lt;cell&gt;15936.00&lt;/cell&gt;
        &lt;cell&gt;1.59&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;lz4&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;2004.43&lt;/cell&gt;
        &lt;cell&gt;256567.19&lt;/cell&gt;
        &lt;cell&gt;13238.78&lt;/cell&gt;
        &lt;cell&gt;25216.00&lt;/cell&gt;
        &lt;cell&gt;1.59&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;lz4&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;2687.75&lt;/cell&gt;
        &lt;cell&gt;172015.93&lt;/cell&gt;
        &lt;cell&gt;20807.00&lt;/cell&gt;
        &lt;cell&gt;43264.00&lt;/cell&gt;
        &lt;cell&gt;1.59&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;lz4&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;3157.29&lt;/cell&gt;
        &lt;cell&gt;101033.42&lt;/cell&gt;
        &lt;cell&gt;36901.36&lt;/cell&gt;
        &lt;cell&gt;80384.00&lt;/cell&gt;
        &lt;cell&gt;1.59&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;zstd&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;818.88&lt;/cell&gt;
        &lt;cell&gt;209633.97&lt;/cell&gt;
        &lt;cell&gt;16672.13&lt;/cell&gt;
        &lt;cell&gt;38656.00&lt;/cell&gt;
        &lt;cell&gt;1.97&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;zstd&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1069.07&lt;/cell&gt;
        &lt;cell&gt;136840.50&lt;/cell&gt;
        &lt;cell&gt;26777.05&lt;/cell&gt;
        &lt;cell&gt;69120.00&lt;/cell&gt;
        &lt;cell&gt;1.97&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;zstd&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;1286.17&lt;/cell&gt;
        &lt;cell&gt;82314.84&lt;/cell&gt;
        &lt;cell&gt;46059.39&lt;/cell&gt;
        &lt;cell&gt;127488.00&lt;/cell&gt;
        &lt;cell&gt;1.97&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;zstd&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;1427.75&lt;/cell&gt;
        &lt;cell&gt;45688.14&lt;/cell&gt;
        &lt;cell&gt;84876.56&lt;/cell&gt;
        &lt;cell&gt;246784.00&lt;/cell&gt;
        &lt;cell&gt;1.97&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The table presents the performance metrics of different compression algorithms, including LZO, LZO-RLE, LZ4, and ZSTD. The metrics include throughput, compression ratio, and latency, which are important factors to consider for selecting the optimal compression algorithm. We used a weighted sum to evaluate the performance of each algorithm and page cluster combination, with weights of 0.4 for latency, 0.4 for compression ratio, and 0.2 for throughput. The results show that LZ4 with page cluster 0 achieved the highest weighted sum, indicating that it is the optimal choice for this dataset. Overall, this evaluation provides valuable insights for selecting the most suitable compression algorithm for data storage and processing, balancing between compression ratio, throughput, and latency.&lt;/p&gt;
    &lt;p&gt;Code used to calculate weighed sums:&lt;/p&gt;
    &lt;p&gt;Data from me:&lt;/p&gt;
    &lt;p&gt;Compiling memory intensive code (vtm ). Test was done on raspberry pi 4b, 2gb ram.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;algo&lt;/cell&gt;
        &lt;cell role="head"&gt;time&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;lz4&lt;/cell&gt;
        &lt;cell&gt;433.63s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;zstd&lt;/cell&gt;
        &lt;cell&gt;459.34s&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Page-cluster Values and Latency&lt;/head&gt;
    &lt;p&gt;The page-cluster value controls the number of pages that are read in from swap in a single attempt, similar to the page cache readahead. The consecutive pages are not based on virtual or physical addresses, but consecutive on swap space, meaning they were swapped out together.&lt;/p&gt;
    &lt;p&gt;The page-cluster value is a logarithmic value. Setting it to zero means one page, setting it to one means two pages, setting it to two means four pages, etc. A value of zero disables swap readahead completely.&lt;/p&gt;
    &lt;p&gt;The default value is 3 (8 pages at a time). However, tuning this value to a different value may provide small benefits if the workload is swap-intensive. Lower values mean lower latencies for initial faults, but at the same time, extra faults and I/O delays for following faults if they would have been part of that consecutive pages readahead would have brought in.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;In the analysis of Zram performance, it was determined that the zstd algorithm provides the highest compression ratio while still maintaining acceptable speeds. The high compression ratio allows more of the working set to fit in uncompressed memory, reducing the need for swap and ultimately improving performance.&lt;/p&gt;
    &lt;p&gt;For daily use (non latency sensitive), it is recommended to use zstd with &lt;code&gt;page-cluster=0&lt;/code&gt; as the majority of swapped data is likely stale (old browser tabs). However, systems that require constant swapping may benefit from using the lz4 algorithm due to its higher throughput and lower latency.&lt;/p&gt;
    &lt;p&gt;It is important to note that the decompression of zstd is slow and results in a lack of throughput gain from readahead. Therefore, &lt;code&gt;page-cluster=0&lt;/code&gt; should be used for zstd. This is the default setting on ChromeOS and seems to be standard practice on Android.&lt;/p&gt;
    &lt;p&gt;The default &lt;code&gt;page-cluster&lt;/code&gt; value is set to 3, which is better suited for physical swap. This value dates back to 2005, when the kernel switched to git, and may have been used in a time before the widespread use of SSDs. It is recommended to consider the specific requirements of the system and workload when configuring Zram.&lt;/p&gt;
    &lt;head rend="h1"&gt;Sources and See Also&lt;/head&gt;
    &lt;p&gt;https://docs.kernel.org/admin-guide/sysctl/vm.html&lt;/p&gt;
    &lt;p&gt;https://www.reddit.com/r/Fedora/comments/mzun99/new_zram_tuning_benchmarks/&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45686280</guid><pubDate>Thu, 23 Oct 2025 19:58:12 +0000</pubDate></item><item><title>Date bug in Rust-based coreutils affects Ubuntu 25.10 automatic updates</title><link>https://lwn.net/Articles/1043103/</link><description>&lt;doc fingerprint="756159579c2627f8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Date bug affects Ubuntu 25.10 automatic updates&lt;/head&gt;
    &lt;p&gt;The Ubuntu Project has announced that a bug in the Rust-based uutils version of the date command shipped with Ubuntu 25.10 broke automatic updates:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Some Ubuntu 25.10 systems have been unable to automatically check for available software updates. Affected machines include cloud deployments, container images, Ubuntu Desktop and Ubuntu Server installs.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The announcement includes remediation instructions for those affected by the bug. Systems with the rust-coreutils package version 0.2.2-0ubuntu2 or earlier have the bug, it is fixed in 0.2.2-0ubuntu2.1 or later. It does not impact manual updates using the apt command or other utilities.&lt;/p&gt;
    &lt;p&gt;Ubuntu embarked on a project to "oxidize" the distribution by switching to uutils and sudo-rs for the 25.10 release, and to see if the Rust-based utilities would be suitable for the long-term-release slated for next April. LWN covered that project in March.&lt;/p&gt;
    &lt;p&gt; Posted Oct 23, 2025 20:52 UTC (Thu) by dskoll (subscriber, #1630) [Link] (5 responses) ... will be called Grateful Guinea-Pig But seriously. Rewriting C utilities that have been battle-tested for decades in Rust might be a good idea in the long term, but anyone could have predicted short-term hiccups. Posted Oct 23, 2025 21:38 UTC (Thu) by geofft (subscriber, #59789) [Link] (2 responses) Posted Oct 23, 2025 22:21 UTC (Thu) by dskoll (subscriber, #1630) [Link] (1 responses) I don't have anything against Rust (nor against C), but I do think it's unfortunate that the Rust utilities are licensed under the MIT license rather than the GPL. But that's a whole other debate... Posted Oct 23, 2025 23:57 UTC (Thu) by dralley (subscriber, #143766) [Link] Posted Oct 24, 2025 1:45 UTC (Fri) by welinder (guest, #4699) [Link] And it's humbling to see that a silly little bug deep in date can silently break unattended security updates! Posted Oct 24, 2025 6:30 UTC (Fri) by eru (subscriber, #2753) [Link] I fail to see why it would be a good idea even in the long term. These utilities are done, the specifications do not change, or change very little. The only valid reason might be a future situation, where support for the C language starts disappearing, which is totally a fantasy scenario. C is too entrenched for that to happen within the expected lifetime of our technical civilisation. Posted Oct 23, 2025 21:12 UTC (Thu) by pixelbeat (guest, #7440) [Link] (3 responses) Then there are fundamental issues with SIGPIPE handling in all the uutils https://github.com/uutils/coreutils/issues/8919 Also there are questionable interface changes being added like 12 ways to get a sha3 https://github.com/uutils/coreutils/issues/8984 I wish them well, but this needs to be carefully managed. Posted Oct 23, 2025 23:26 UTC (Thu) by csigler (subscriber, #1224) [Link] I cannot possibly (imaginarily) upvote this comment enough. For those familiar with the 1976 movie "Network": "You have meddled with the primal forces of Unix, and _you_will_atone_!!!" Clemmitt Posted Oct 24, 2025 4:04 UTC (Fri) by Keith.S.Thompson (subscriber, #133709) [Link] (1 responses) I wonder whether that was a deliberate decision. ("true" and "false" are bash builtins, so the commands under /usr/bin probably aren't used very often.) Posted Oct 24, 2025 6:05 UTC (Fri) by mb (subscriber, #50428) [Link] Posted Oct 23, 2025 21:35 UTC (Thu) by JMB (guest, #74439) [Link] And concerning servers ... in most cases even extreme security relevant problems At least the problem shows that it is not fuitile to have tested the new Rust code ... Posted Oct 23, 2025 22:00 UTC (Thu) by geofft (subscriber, #59789) [Link] Looks like this was originally reported in https://pad.lv/2127970 on October 16, exactly one week ago and also exactly one week after Ubuntu 25.10's release. The reporter originally mentioned the bug in the context of a homegrown backup script that was failing silently, and they got the fix into the proposed stable update repository yesterday, with an (understandable) argument about why it wasn't same-day levels of urgent. This morning, someone pointed out that it breaks unattended-upgrades. It seems to me that it was only at this point that it was tracked as a security issue, and the package is now available in both the (prod) stable updates repository and the more minimal security updates repository. The actual bug itself is simply that support for `date -r &amp;lt;file&amp;gt;` wasn't implemented. The issue https://github.com/uutils/coreutils/issues/8621 and the pull request implementing support https://github.com/uutils/coreutils/pull/8630 were both filed on the same day, September 12 of this year, and it was reviewed and merged into main two days later. This, understandably, postdates whichever release Ubuntu snapshotted. I think I am mostly surprised that the command silently accepted -r and did nothing, and indeed from the actual diff (https://github.com/uutils/coreutils/commit/88a7fa7adfa048...) it's pretty clear that the argument parser had support for it but it wasn't wired up to do anything. If the command had instead returned an argument parsing error, I think this would have been caught a lot quicker. It does seem a little bit odd that whoever implemented this in the argument parser didn't at least add an "if -r, throw 'todo'" case. But it's also interesting that this was not statically caught. The Rust compiler is pretty good at warning and complaining about unused variables. (To be fair, most C compilers and many other languages are too, though anecdotally these warnings seem less noisy in Rust and I've seen more codebases in Rust where this is a hard failure than C codebases using -Werror. Also, Rust has #[must_use], if you want to be thorough.) However, there wasn't actually an unused variable here; you can see that you get the value out of the parsed-arguments object by asking for the value of the flag. I wonder if it's worth thinking about an argument-parsing API in Rust that would raise an unused-variable warning at compile time if a parsed command-line flag or argument is never used in the code. It might also be possible to do this with the existing parser with a sufficiently clever linter. Either way, the lack of compile-time detection of this bug feels at odds with the philosophy of a Rust rewrite of coreutils, i.e., that there's merit in having tools do the checking instead of trusting and expecting people to write perfect code. I also think it would be very much worth it for Ubuntu and the uutils developers to manually do an audit for all arguments that are parsed in an argument parser but not actually implemented. If this pattern happened once, it likely isn't the only case. &lt;head&gt;The next Ubuntu release...&lt;/head&gt;&lt;head&gt;The next Ubuntu release...&lt;/head&gt;&lt;head&gt;The next Ubuntu release...&lt;/head&gt;&lt;head&gt;The next Ubuntu release...&lt;/head&gt;&lt;head&gt;The next Ubuntu release...&lt;/head&gt;&lt;head&gt;Don't fix what aint broke&lt;/head&gt;&lt;quote&gt; Rewriting C utilities that have been battle-tested for decades in Rust might be a good idea in the long term, &lt;/quote&gt;&lt;head&gt;uutils is doing well, but needs to be carefully managed&lt;/head&gt;&lt;head&gt;uutils is doing well, but needs to be carefully managed&lt;/head&gt;&lt;head&gt;uutils is doing well, but needs to be carefully managed&lt;/head&gt;&lt;head&gt;uutils is doing well, but needs to be carefully managed&lt;/head&gt;&lt;head&gt;No problems for oldschool Linux users ...&lt;/head&gt;&lt;lb/&gt; For Smartphone Junkies that may be true (due to fear of missing out),&lt;lb/&gt; but for experts there is no need to get even security fixes in less than a week.&lt;lb/&gt; are not fixed due to other priorities anyway ... form frozen zone ... to ice age.&lt;lb/&gt; but still wondering if concerning all bugs Rust really have a positive benefit&lt;lb/&gt; for experienced coders ... seems more a hype than something which can be prooved.&lt;head&gt;uutils date bug timeline and root cause&lt;/head&gt;&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45686919</guid><pubDate>Thu, 23 Oct 2025 20:49:08 +0000</pubDate></item><item><title>FocusTube: A Chrome extension that hides YouTube Shorts</title><link>https://github.com/CaptainYouz/FocusTube</link><description>&lt;doc fingerprint="1c5893e0d09c161a"&gt;
  &lt;main&gt;
    &lt;p&gt;TL;DR: We only have one life. Let's stop wasting it on YouTube shorts.&lt;/p&gt;
    &lt;p&gt;A chrome extension that removes the short block of the YouTube homepage and reduces the thumbnail size.&lt;/p&gt;
    &lt;p&gt;https://developer.chrome.com/docs/extensions/get-started/tutorial/hello-world#load-unpacked&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45687227</guid><pubDate>Thu, 23 Oct 2025 21:11:14 +0000</pubDate></item><item><title>When is it better to think without words?</title><link>https://www.henrikkarlsson.xyz/p/wordless-thought</link><description>&lt;doc fingerprint="7519513caab092d0"&gt;
  &lt;main&gt;
    &lt;head rend="h6"&gt;Portrait of a Man with Glasses I, Francis Bacon, 1963&lt;/head&gt;
    &lt;p&gt;This essay can be read as a complement to last year’s “How to think in writing.”&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Thoughts die the moment they are embodied in words.&lt;/p&gt;&lt;lb/&gt;—Schopenhauer&lt;/quote&gt;
    &lt;head rend="h4"&gt;1.&lt;/head&gt;
    &lt;p&gt;In the 1940s, when the French mathematician Jacques Hadamard asked good mathematicians how they came up with solutions to hard problems, they nearly universally answered that they didn’t think in words; neither did they think in images or equations. Rather, what passed through the mathematicians as they struggled with problems were such things as vibrations in their hands, nonsense words in their ears, or blurry shapes in their heads.1&lt;/p&gt;
    &lt;p&gt;Hadamard, who had the same types of experiences, wrote in The Psychology of Invention in the Mathematical Field that this mode of thinking was distinct from daydreaming, and that most people, though they often think wordlessly, have never experienced the kind of processing that the mathematicians did.&lt;/p&gt;
    &lt;p&gt;When I read this, in December 2024, all sorts of questions arose in me. First of all, what does it even mean? Do they not think in words and equations at all? And secondly, how do I square this with my personal experience, which is that whenever I write what I think about a subject, it always turns out that my thoughts do not hold up on paper? No matter how confident I am in my thoughts, they reveal themselves on the page as little but logical holes, contradictions, and non sequiturs.&lt;/p&gt;
    &lt;p&gt;I recognize myself when Paul Graham writes:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The reason I’ve spent so long establishing [that writing helps you refine your thinking] is that it leads to another [point] that many people will find shocking. If writing down your ideas always makes them more precise and more complete, then no one who hasn’t written about a topic has fully formed ideas about it. And someone who never writes has no fully formed ideas about anything nontrivial.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;How come Hadamard’s colleagues are able to have productive thoughts, working in their heads, without words, sometimes, for days on end?&lt;/p&gt;
    &lt;head rend="h2"&gt;Tense subconscious processing&lt;/head&gt;
    &lt;p&gt;Hadamard’s book is most famous for its detailed discussion of what Henri Poincaré called the “sudden illumination”—the moment when the solution to a problem emerges “in the shower” unexpectedly after a long period of unconscious incubation.&lt;/p&gt;
    &lt;p&gt;The hypothesis here is that if you work hard on a problem, you soak your subconscious with it. Wrestling with a problem helps you build a mental model of what you know and what you don’t—providing the subconscious with building blocks to work with. (You can’t have genuine intuition and inspiration in areas where you lack knowledge.) Then, once you drop the problem from conscious thought and go take care of the dishes or something, the subconscious begins a silent and parallelized search, trying many, many alternatives (in a somewhat random fashion), until something snaps in place. When this happens, the solution bubbles back up to the conscious mind, as if out of nowhere, making you freeze mid-motion with a stack of dirty plates in your hands.&lt;/p&gt;
    &lt;p&gt;This is a very useful thing to know about the mind, because it means you can steer your subconscious towards the particular problems you want it to work on. By priming yourself with important problems before doing the dishes or going for walks or sleeping, you make sure your mental resources are used on what matters for you, instead of, for example, the open loops in a Netflix series you watched before bed. It is free labor.&lt;/p&gt;
    &lt;p&gt;But—this is not what Hadamard is talking about when he describes the wordless thought of the mathematicians and researchers he has surveyed. Instead, what they seem to be doing is something similar to this subconscious, parallelized search, except they do it in a “tensely” focused way.&lt;/p&gt;
    &lt;p&gt;The impression I get is that Hadamard loads a question into his mind (either in a non-verbal way, or by reading a mathematical problem that has been written by himself or someone else), and then he holds the problem effortfully centered in his mind. Effortfully, but wordlessly, and without clear visualizations. Describing the mental image that filled his mind while working on a problem concerning infinite series for his thesis, Hadamard writes that his mind was occupied by an image of a ribbon which was thicker in certain places (corresponding to possibly important terms). He also saw something that looked like equations, but as if seen from a distance, without glasses on: he was unable to make out what they said.&lt;/p&gt;
    &lt;p&gt;I’m not sure what is going on here. But here’s a speculation. As I understand it, when one part of our brain is working, it often inhibits another—if you put words to distressing feelings, for example, the language-oriented parts of your brain inhibit the amygdala, which reduces the emotional distress. Similarly, when you are focused on a task at hand, the executive control network of your brain will tend to inhibit the default mode network which is responsible for mind wandering. (This might explain why illuminations tend to occur mainly in the shower, when the executive control networks downregulate and the mind is allowed to wander.)&lt;/p&gt;
    &lt;p&gt;Here’s my speculation: perhaps Hadamard and the other great mathematicians are able to enter into a modality of thought where they are able to keep both the default mode network and the executive control network on at the same time. Perhaps this allows them to do a sort of subconscious, in-the-shower-type processing, while still maintaining enough conscious focus to ensure the thoughts don’t drift away from the problem and its constraints.&lt;/p&gt;
    &lt;p&gt;When I look into this, I notice that there is research indicating that when doing certain types of creative work, the default mode network and the executive control network are, indeed, active at the same time, which they usually aren’t. Individuals who are experienced in a creative field seem to have the capacity to keep the default mode network turned on, allowing them to generate many permutations of ideas, while steering it with the executive control network, ensuring their parallelized mindwandering is constrained by the facts of the problem. I suspect we are all capable of this to some extent, but doing it to the extent Hadamard’s subjects did is akin to a ballerina spinning on her toes: a mental posture that requires serious practice to develop the necessary muscles and coordination.&lt;/p&gt;
    &lt;p&gt;I’m not well-versed in neuroscience enough to know if I’m interpreting this right; I’m just speculating.&lt;/p&gt;
    &lt;p&gt;But what we do know is that Hadamard, as he worked, would pace up and down his room with what “witnesses to [his] daily life and work” called his “inside” look. (Others, like Poincaré and Helmholtz, seem to have sat at their desks, staring into nowhere.) And this type of deep, consciously-blurry concentration could go on for a long time: Hadamard mentions that he only stopped walking if he needed to write down a proof (reluctantly). An acquaintance writes that a friend of his shared an office with one of the best now living physicists; this physicist’s work habit was to come into the office in the morning and then stare into the wall for 8 hours before going home. Imagine holding a productive thought for that long without writing any steps down and, presumably, without even compressing things into words inside your head!&lt;/p&gt;
    &lt;head rend="h2"&gt;The interplay between writing and non-linguistic thinking&lt;/head&gt;
    &lt;p&gt;Hadamard writes that he sometimes used algebraic signs when dealing with easy calculations, but adds that, “whenever the matter looks more difficult, they become too heavy a baggage for me.”&lt;/p&gt;
    &lt;p&gt;Why are words too heavy?&lt;/p&gt;
    &lt;p&gt;Reasoning from my experience, I suspect it is because words are laborious. When we put words to a thought, we have to compress something that is like a web in our mind, filled with connections and associations going in all directions, turning that web into a sequential string of words; we have to compress what is high-dimensional into something low-dimensional. This has all sorts of advantages, which I will return to, but the point I want to emphasize here is that compression is effortful. It takes intense concentration to find the right words (rather than the sloppy ones that first come to mind), and then to put them in the proper order. As James Joyce said to his friend when he was asked why he looked so gloomy, “I’ve only written seven words today…” “But why then are you in despair—seven words is a lot for you!” “I don’t know in which order to put them…”&lt;/p&gt;
    &lt;p&gt;If we can avoid the compression step, and do the manipulations directly in the high-dimensional, non-linguistic, conceptual space, we can move much faster.2&lt;/p&gt;
    &lt;p&gt;But this is a big if. Most people, myself included, have too weak mental models to do this kind of processing for complex problems, and so, our thoughts are riddled with contradictions and holes that we often don’t notice unless we try to write them down. We can move faster in wordless thought, but we’re moving at random. If, however, you have deep expertise in an area, like the mathematicians, it is possible to let go of the language compression and do a much faster search. M, who started his career as a physicist, tells me that when he was 13 and read that Einstein thought without words, he felt disappointed since his mind didn’t work like that; then, “a decade and many thousands of hours of mathematics and physics later,” he reread the passage and recognized himself almost completely. I guess this was because the labor of learning mathematics, done largely through reading and writing his way through complex ideas and problems, had given him deep enough mental models to make words somewhat superfluous.&lt;/p&gt;
    &lt;p&gt;But even then, as Hadamard notes, writing is a necessary step of the process. The insights arrived at wordlessly need to be submitted to the rigor of mathematical notation and logic, to test their validity. It is a sort of feedback mechanism: unless the intuition holds up on the page, it is a false intuition.&lt;/p&gt;
    &lt;p&gt;The written results also work as relay results. By writing something down and making sure it is solid, we can offload that thought from working memory and instead use it as a building block for the next step of the thought. Or, to use a metaphor by the mathematician William Hamilton, deep thinking is like building a tunnel through a sandbank:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In this operation, it is impossible to succeed unless every foot, nay, almost every inch in our progress be secured by an arch of masonry before we attempt the excavation of another. Now, language is to the mind precisely what the arch is to the tunnel. The power of thinking and the power of excavation are not dependent on the words in the one case, on the mason-work in the other; but without these subsidiaries, neither process could be carried on beyond its rudimentary commencement.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;So writing—and reading, seriously, the writings of others—is a way to collect stepping stones: ideas that have been stabilized enough that they can carry us as we walk deeper into the thought space.&lt;/p&gt;
    &lt;p&gt;But this stabilization of meaning can go wrong, too, if we stabilize ideas that aren’t ready to be stabilized yet. When writing, there are all sorts of details that need to be specified for our paragraphs to make sense, and if we don’t know what should go into a sentence, it is all too easy to fill in the uncertain parts with guesses. At least my brain has the most miraculous autocomplete function and supplies me with credible endings to any sentence I start—often credible nonsense. But when the nonsense is there on the page, next to thoughts I’ve settled through hard work, it looks respectable! It often takes considerable work to realize I’ve fooled myself.&lt;/p&gt;
    &lt;p&gt;This was another reason Hadamard’s subjects gave for why they were reluctant to use words: they were afraid of the false precision writing forces onto thinking. They were afraid of premature precision and the confusion it breeds. By thinking in blurry images, or tensions of the hands, or sounds, they could keep their thoughts accurately vague in the areas where there was still uncertainty. They wrote down on paper, as settled, only mostly what was actually known. If you are disciplined, you can write in such a way that you avoid false precision.&lt;/p&gt;
    &lt;p&gt;To sum up: the relationship between verbal thinking and deep wordless concentration is complex.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Non-verbal, blurry thinking is faster and can search in a broader way, but it is more error-prone than verbal thought.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Good writing tends to come from an attempt to capture in words something you understand wordlessly, rather than moving ideas around on the page; but, paradoxically, a generative subconscious is usually one that has been trained by writing and deep reading, which provides the subconscious with relay results and other mental structures necessary for deep thought.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Writing forces precision, which can fool us into locking in details we have no reason to lock in, but written notes (or drawings) are a necessary aid when thinking long chains of thoughts.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Over the last nine months, as I’ve been thinking about this topic, I’ve become more mindful about when words hinder and when they help. I notice that I spend more time in wordless thoughts than I used to. But I’m also more deliberate about using writing to structure my brain so it feeds me better thoughts.&lt;/p&gt;
    &lt;p&gt;As always, a big thank you to the paying subscribers who fund the work on the public essays. I couldn’t do this without you! I also want to thank Johanna Karlsson and Michael Nielsen for discussion about the topic. Esha Rana helped me with the final edit.&lt;/p&gt;
    &lt;p&gt;I can think of examples of mathematicians and physicist for whom this is not true. The first one who comes to mind is Richard Feynman, who said in an interview:&lt;/p&gt;
    &lt;head rend="h5"&gt;Feynman:&lt;/head&gt;
    &lt;p&gt;I actually did the work on the paper.&lt;/p&gt;
    &lt;head rend="h5"&gt;Weiner:&lt;/head&gt;
    &lt;p&gt;That s right. It wasn’t a record of what you had done but it is the work.&lt;/p&gt;
    &lt;head rend="h5"&gt;Feynman:&lt;/head&gt;
    &lt;p&gt;It’s the doing it — it’s the scrap paper.&lt;/p&gt;
    &lt;head rend="h5"&gt;Weiner:&lt;/head&gt;
    &lt;p&gt;Well, the work was done in your head but the record of it is still here.&lt;/p&gt;
    &lt;head rend="h5"&gt;Feynman:&lt;/head&gt;
    &lt;p&gt;No, it’s not a record, not really, it’s working. You have to work on paper and this is the paper. OK?&lt;/p&gt;
    &lt;p&gt;A more technical way of saying this is that our (non-verbal) thoughts seem to behave as vectors; when a cluster of neurons fire together, that pattern is like an address pointing toward a point in a high dimensional space. But when we convert our thoughts to words, we convert that vector into a scalar. I’m not sure if this is true, but here is a paper laying out the argument for why it might be.&lt;/p&gt;
    &lt;p&gt;The discussion of vectors and dimension reduction also has an interesting parallel to an ongoing discussion in AI research. When a large language model calculates what to output, the “thinking” happens in high dimensional space where vectors are passed from layer to layer. At the final layer, that high dimensional representation is collapsed into a token—the written output. When this happens, enormous amounts of information is lost: the residual stream contains over a thousand times more information than gets encoded into the token! That lends some support to the idea that non-verbal (partly unconscious) thinking might be more information rich in humans, too.&lt;/p&gt;
    &lt;p&gt;In reasoning models, where the LLM is encouraged to think for longer, what happens is that this written output—this collapsed thought—is fed back into the model as input, so it can keep thinking about it. It is as if a person were to lose all of their memories and thoughts every few seconds and could only rely on whatever conclusions they had written on a slip of paper; this seems, potentially, like a limited way of thinking. To come around this problem—if it is a problem—one idea that is being explored is to feed the entire vector back into the model as a chain of thought, instead of the tokens on the scratch pad. This would be something like letting the models think in a non-verbal mental space, akin to what Hadamard described—thinking in the latent space, rather than on the scratch pad.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45687441</guid><pubDate>Thu, 23 Oct 2025 21:26:57 +0000</pubDate></item><item><title>/dev/null is an ACID compliant database</title><link>https://jyu.dev/blog/why-dev-null-is-an-acid-compliant-database/</link><description>&lt;doc fingerprint="8812dd1940f64a11"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Atomicity&lt;/head&gt;
    &lt;p&gt;Operations are "all or nothing."&lt;/p&gt;
    &lt;p&gt;Anything you write to &lt;code&gt;/dev/null&lt;/code&gt; disappears entirely. There's no partial write problem: it’s either written (and discarded) or not written at all. ✅&lt;/p&gt;
    &lt;head rend="h2"&gt;Consistency&lt;/head&gt;
    &lt;p&gt;The system transitions from one valid state to another.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;/dev/null&lt;/code&gt; always stays in a consistent state (empty). No matter what you write, the invariant "file contains nothing" always holds. ✅&lt;/p&gt;
    &lt;head rend="h2"&gt;Isolation&lt;/head&gt;
    &lt;p&gt;Concurrent transactions don’t interfere with each other.&lt;/p&gt;
    &lt;p&gt;Multiple processes can write to &lt;code&gt;/dev/null&lt;/code&gt; at the same time, and their outputs never conflict, because nothing is ever stored. ✅&lt;/p&gt;
    &lt;head rend="h2"&gt;Durability&lt;/head&gt;
    &lt;p&gt;Once a transaction is committed, it remains so, even after crashes.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;/dev/null&lt;/code&gt; "durably" commits your data into nothingness. After a crash or reboot, it still contains exactly what it always has: nothing. ✅&lt;/p&gt;
    &lt;p&gt;There is only 1 small problem though, it only comes with 0b of free storage. For more space, you will have to contact entreprise sales, which is actually just me!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45687458</guid><pubDate>Thu, 23 Oct 2025 21:28:02 +0000</pubDate></item><item><title>How memory maps (mmap) deliver faster file access in Go</title><link>https://info.varnish-software.com/blog/how-memory-maps-mmap-deliver-25x-faster-file-access-in-go</link><description>&lt;doc fingerprint="f2fbd59d36b2b0c8"&gt;
  &lt;main&gt;
    &lt;p&gt;One of the slowest things you can do in an application is making system calls. They're slow because you do have to enter the kernel, which is quite expensive. What should you do when you need to do a lot of disk I/O but you care about performance? One solution is to use memory maps.&lt;lb/&gt;Memory maps are a modern Unix mechanism where you can take a file and make it part of the virtual memory. In Unix context, modern means that it was introduced in the 1980s or later. You have a file, containing data, you mmap it and you'll get a pointer to where this resides. Now, instead of seeking and reading, you just read from this pointer, adjusting the offset to get to the right data.&lt;/p&gt;
    &lt;head rend="h2"&gt;Performance&lt;/head&gt;
    &lt;p&gt;To show what kind of performance you can get using memory maps, I've written a little Go library that allows you to read from a file using a memory map or a ReaderAt. ReaderAt will do a pread(), which is a seek/read combo, while mmap will just read from the memory map.&lt;/p&gt;
    &lt;p&gt;This almost feels like magic. Initially, when we launched Varnish Cache back in 2006, this was one of the features that made Varnish Cache very fast when delivering content. Varnish Cache would use memory maps to deliver content at blistering speeds.&lt;lb/&gt;Also, since you can operate with pointers into memory that is allocated by the memory map, you'll reduce memory pressure as well as raw latency.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Downside of Memory Maps&lt;/head&gt;
    &lt;p&gt;The downside of memory maps is that you really can't write to the memory map. The reason is due to the way virtual memory works. When you're writing to a part of virtual memory that isn't mapped into physical memory, the CPU will generate a page fault. On a modern computer, the CPU is responsible for tracking what virtual memory pages are mapped onto what physical memory. Since you're writing to a page that isn't mapped, the CPU needs help.&lt;lb/&gt;So, when the page fault occurs, the OS will 1) allocate a new memory page, 2) read the contents of the file at the correct offset, 3) write this to the new memory page. Then control is returned to the application. The application will now overwrite the virtual memory page with new data.&lt;lb/&gt;Can we stop and appreciate how extremely inefficient this is? I think it is fairly safe to say that writing through a memory map is never a good idea when considering performance. At least if there is any risk, the file isn't mapped up in physical memory.&lt;lb/&gt;Let me illustrate this with a few more benchmarks.&lt;/p&gt;
    &lt;p&gt;As you can see, whether or not the pages are in cache is crucial for performance. WriterAt, which uses the pwrite call, is a much more predictable bet.&lt;lb/&gt;Still, writing through memory maps, was what Varnish Cache did initially. It somehow got away with it, but mostly because the competition was pretty bad.&lt;lb/&gt;This is why Varnish Cache got the malloc backend and why Varnish Enterprise got the various Massive Storage Engines. The malloc backend resolved the problem by just allocating system memory through the malloc system call, and the Massive Storage Engine uses io_uring, which is so new that support for it is still somewhat limited.&lt;/p&gt;
    &lt;head rend="h2"&gt;Using Memory Maps to Solve Real-world Performance Problems&lt;/head&gt;
    &lt;p&gt;The last couple of weeks I've been working on an HTTP-backed filesystem. This is part of our AI Storage Acceleration solution, geared towards high performance computing environments. In this filesystem we needed a way to transfer folder data over HTTP. A folder is really just a listing of files, symbolic links and directories. The naive approach would be just to use JSON encoding, but JSON is notorious for being slow.&lt;lb/&gt;Our priority is performance. We made a benchmarking suite, comparing various databases with each other. CDB was overall the fastest. Looking at the numbers, we'd still see that CDB would spend something like 1200ns on a database lookup that was entirely in the page cache. This seems very slow to me. After all, everything should be in memory and spending 1200ns reading memory sounds at least 100x too slow. I started looking into the CDB implementation I was using. It was the above ReaderAt implementation. So, most of the time is likely spent waiting for the operating system.&lt;lb/&gt;Some hours later, I was able to replace the seek/read with a memory map. This resulted in a 25x improvement in performance. Again, it feels like magic. Unlike the original file stevedore in Varnish Cache, this performance improvement has no downside.&lt;lb/&gt;Benchmarks: https://github.com/perbu/mmaps-in-go &lt;lb/&gt;CDB64 files with memory maps: https://github.com/perbu/cdb &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45687796</guid><pubDate>Thu, 23 Oct 2025 21:56:07 +0000</pubDate></item><item><title>Apple loses UK App Store monopoly case, penalty might near $2B</title><link>https://9to5mac.com/2025/10/23/apple-loses-uk-app-store-monopoly-case-penalty-might-near-2-billion/</link><description>&lt;doc fingerprint="a6ccef2653173374"&gt;
  &lt;main&gt;
    &lt;p&gt;A landmark case in the UK concerning Apple’s App Store practices has just been decided, with a London tribunal ruling against the company in a move that could cost Apple up to $2 billion.&lt;/p&gt;
    &lt;head rend="h2"&gt;London tribunal rules that Apple overcharged app developers for years with unfair commissions&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Apple abused its dominant position by charging app developers unfair commissions, a London tribunal ruled on Thursday, in a blow which could leave the U.S. tech company on the hook for hundreds of millions of pounds in damages.&lt;/p&gt;
      &lt;p&gt;The Competition Appeal Tribunal (CAT) ruled against Apple after a trial of the lawsuit, which was brought on behalf of millions of iPhone and iPad users in the United Kingdom.&lt;/p&gt;
      &lt;p&gt;The CAT ruled that Apple had abused its dominant position from October 2015 until the end of 2020 by shutting out competition in the app distribution market and by “charging excessive and unfair prices” as commission to developers. […]&lt;/p&gt;
      &lt;p&gt;The case had been valued at around 1.5 billion pounds ($2 billion) by those who brought it. A hearing next month will decide how damages are calculated and Apple’s application for permission to appeal.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Apple has already said it will appeal the ruling, which the company said “takes a flawed view of the thriving and competitive app economy”.&lt;/p&gt;
    &lt;p&gt;The estimated $2 billion in damages that might be enforced is expected to combine several different factors.&lt;/p&gt;
    &lt;p&gt;Per Reuters:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;“developers were overcharged by the difference between a 17.5% commission for app purchases and the commission Apple charged, which Kent’s lawyers said was usually 30%.”&lt;/item&gt;
      &lt;item&gt;“The CAT also ruled that app developers passed on 50% of the overcharge to consumers.”&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We will keep you posted on any further developments with the case, including Apple’s appeal and the actual damages when they are calculated next month.&lt;/p&gt;
    &lt;p&gt;For previous coverage of this lawsuit, here’s the original 2023 news story.&lt;/p&gt;
    &lt;p&gt;What are your takeaways from the ruling against Apple for its App Store practices in the UK? Let us know in the comments.&lt;/p&gt;
    &lt;head rend="h3"&gt;Best iPhone accessories&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AirPods Pro 3&lt;/item&gt;
      &lt;item&gt;AirTag 4-pack (now only $65, down from $99)&lt;/item&gt;
      &lt;item&gt;MagSafe Car Mount for iPhone&lt;/item&gt;
      &lt;item&gt;10-year AirTag battery case 2-pack&lt;/item&gt;
      &lt;item&gt;100W USB-C fast charging power adapter&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;FTC: We use income earning auto affiliate links. More.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45688006</guid><pubDate>Thu, 23 Oct 2025 22:11:23 +0000</pubDate></item><item><title>Automating Algorithm Discovery: A Case Study in MoE Load Balancing</title><link>https://adrs-ucb.notion.site/moe-load-balancing</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=45688236</guid><pubDate>Thu, 23 Oct 2025 22:35:22 +0000</pubDate></item><item><title>Introduction to the concept of likelihood and its applications (2018)</title><link>https://journals.sagepub.com/doi/10.1177/2515245917744314</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45688443</guid><pubDate>Thu, 23 Oct 2025 22:52:15 +0000</pubDate></item><item><title>React Flow, open source libraries for node-based UIs with React or Svelte</title><link>https://github.com/xyflow/xyflow</link><description>&lt;doc fingerprint="ce0797600b4bffda"&gt;
  &lt;main&gt;
    &lt;p&gt;Powerful open source libraries for building node-based UIs with React or Svelte. Ready out-of-the-box and infinitely customizable.&lt;/p&gt;
    &lt;p&gt;The xyflow repository is the home of four packages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;React Flow 12 &lt;code&gt;@xyflow/react&lt;/code&gt;packages/react&lt;/item&gt;
      &lt;item&gt;React Flow 11 &lt;code&gt;reactflow&lt;/code&gt;v11 branch&lt;/item&gt;
      &lt;item&gt;Svelte Flow &lt;code&gt;@xyflow/svelte&lt;/code&gt;packages/svelte&lt;/item&gt;
      &lt;item&gt;Shared helper library &lt;code&gt;@xyflow/system&lt;/code&gt;packages/system&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Are you using React Flow or Svelte Flow for a personal project? Great! No sponsorship needed, you can support us by reporting any bugs you find, sending us screenshots of your projects, and starring us on Github 🌟&lt;/p&gt;
    &lt;p&gt;Are you using React Flow or Svelte Flow at your organization and making money from it? Awesome! We rely on your support to keep our libraries developed and maintained under an MIT License, just how we like it. For React Flow you can do that on the React Flow Pro website and for both of our libraries you can do it through Github Sponsors.&lt;/p&gt;
    &lt;p&gt;The best way to get started is to check out the React Flow or Svelte Flow learn section. However if you want to get a sneak peek of how to install and use the libraries you can see it here:&lt;/p&gt;
    &lt;head&gt;React Flow basic usage&lt;/head&gt;
    &lt;code&gt;npm install @xyflow/react&lt;/code&gt;
    &lt;code&gt;import { useCallback } from 'react';
import {
ReactFlow,
MiniMap,
Controls,
Background,
useNodesState,
useEdgesState,
addEdge,
} from '@xyflow/react';

import '@xyflow/react/dist/style.css';

const initialNodes = [
{ id: '1', position: { x: 0, y: 0 }, data: { label: '1' } },
{ id: '2', position: { x: 0, y: 100 }, data: { label: '2' } },
];

const initialEdges = [{ id: 'e1-2', source: '1', target: '2' }];

function Flow() {
const [nodes, setNodes, onNodesChange] = useNodesState(initialNodes);
const [edges, setEdges, onEdgesChange] = useEdgesState(initialEdges);

const onConnect = useCallback((params) =&amp;gt; setEdges((eds) =&amp;gt; addEdge(params, eds)), [setEdges]);

return (
  &amp;lt;ReactFlow
    nodes={nodes}
    edges={edges}
    onNodesChange={onNodesChange}
    onEdgesChange={onEdgesChange}
    onConnect={onConnect}
  &amp;gt;
    &amp;lt;MiniMap /&amp;gt;
    &amp;lt;Controls /&amp;gt;
    &amp;lt;Background /&amp;gt;
  &amp;lt;/ReactFlow&amp;gt;
);
}

export default Flow;&lt;/code&gt;
    &lt;head&gt;Svelte Flow basic usage&lt;/head&gt;
    &lt;code&gt;npm install @xyflow/svelte&lt;/code&gt;
    &lt;code&gt;&amp;lt;script lang="ts"&amp;gt;
import { writable } from 'svelte/store';
import {
  SvelteFlow,
  Controls,
  Background,
  BackgroundVariant,
  MiniMap,
} from '@xyflow/svelte';

import '@xyflow/svelte/dist/style.css'

const nodes = writable([
  {
    id: '1',
    type: 'input',
    data: { label: 'Input Node' },
    position: { x: 0, y: 0 }
  },
  {
    id: '2',
    type: 'custom',
    data: { label: 'Node' },
    position: { x: 0, y: 150 }
  }
]);

const edges = writable([
  {
    id: '1-2',
    type: 'default',
    source: '1',
    target: '2',
    label: 'Edge Text'
  }
]);
&amp;lt;/script&amp;gt;

&amp;lt;SvelteFlow
{nodes}
{edges}
fitView
on:nodeclick={(event) =&amp;gt; console.log('on node click', event)}
&amp;gt;
&amp;lt;Controls /&amp;gt;
&amp;lt;Background variant={BackgroundVariant.Dots} /&amp;gt;
&amp;lt;MiniMap /&amp;gt;
&amp;lt;/SvelteFlow&amp;gt;&lt;/code&gt;
    &lt;p&gt;For releasing packages we are using changesets in combination with the changeset Github action. The rough idea is:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;create PRs for new features, updates and fixes (with a changeset if relevant for changelog)&lt;/item&gt;
      &lt;item&gt;merge into main&lt;/item&gt;
      &lt;item&gt;changset creates a PR that bumps all packages based on the changesets&lt;/item&gt;
      &lt;item&gt;merge changeset PR if you want to release to Github and npm&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Built by xyflow&lt;/head&gt;
    &lt;p&gt;React Flow and Svelte Flow are maintained by the xyflow team. If you need help or want to talk to us about a collaboration, reach out through our contact form or by joining our Discord Server.&lt;/p&gt;
    &lt;p&gt;React Flow and Svelte Flow are MIT licensed.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45688836</guid><pubDate>Thu, 23 Oct 2025 23:33:28 +0000</pubDate></item><item><title>Counter-Strike's player economy is in a multi-billion dollar freefall</title><link>https://www.polygon.com/counter-strike-cs-player-economy-multi-billion-dollar-freefall/</link><description>&lt;doc fingerprint="b660f151878bcf98"&gt;
  &lt;main&gt;
    &lt;p&gt;Counter-Strike has long been known for two things: tight tactical FPS gameplay and a thriving player marketplace effectively valued at literal billions of dollars. Now, thanks to a recent update from Valve, the latter is in a downward spiral, having lost 25% of its value — or $1.75 billion — overnight.&lt;/p&gt;
    &lt;p&gt;First, some context. Counter-Strike is a free-to-play multiplayer shooter. As with most other F2P games, it generates revenue from selling cosmetics. They arrive in lootbox-like Cases, which are opened by Keys purchased with real-world currency. They can also be obtained through trading with other players and purchasing from Steam Community Market. Beyond Steam, unofficial third-party marketplaces for CS cosmetics have also popped up as channels for buying and selling items.&lt;/p&gt;
    &lt;p&gt;Because items are obtained at random through opening Cases, rarer items fetch the highest value on the open marketplaces. Items of lower-rarity tiers can also be traded in at volume for an item of a higher tier via trade up contracts. Previously, Knives and Gloves could not be obtained through trade up contracts, exponentially increasing their value as highly sought-after items. Prior to the most recent update, some Knives, like a Doppler Ruby Butterfly Knife, could fetch around $20,000 on third-party storefronts like CSFloat.&lt;/p&gt;
    &lt;p&gt;Following Valve's Oct. 22 update to Counter-Strike, the second-highest-tier, Covert (Red), can now be traded up and turned into Knives and Gloves. Essentially, this means that a previously extremely rare and highly sought-after cosmetic is going to be much more obtainable for those who increasingly want it, reducing the value of Knives and Gloves on the open marketplace.&lt;/p&gt;
    &lt;p&gt;And this is where the market descends into a freefall. Now, that Butterfly Knife mentioned above? It's going for around $12,000, as people are essentially dumping their stock, with 15 sold over the past 16 hours at the time of this writing.&lt;/p&gt;
    &lt;p&gt;Bloomberg reported the market for Counter-Strike cosmetic items dropped 25% overnight from Wednesday evening into Thursday morning. It's lost about $1.84 billion in value, according to Pricempire, which tracks and analyses the market for CS items. "This completely changes the supply of Counter-Strike’s most sought-after and expensive tier of items," Pricempire marketing manager Ethan MacDonald told Bloomberg.&lt;/p&gt;
    &lt;p&gt;As sellers attempt to recoup their investments, similar fire sales like the one happening at CSFloat are occurring at other sites. One such site, Skin Port, even put us in a waiting room to access it; traffic was overwhelming its servers.&lt;/p&gt;
    &lt;p&gt;Just like how NFT or cryptocurrency values can drastically shift, Counter-Strike item traders are seeing their stock rapidly change in value, and not for the best. While some items of lower-rarity tiers have gone up in value, and Reds might see a bump now that they can be traded up into Knives and Gloves, that can't make up for the sudden drop at the top of the cosmetics market.&lt;/p&gt;
    &lt;p&gt;We'll have to wait and see if the market levels out or if it continues to crash. Plenty of players and CS traders must be eagerly awaiting more news: As of this writing, Pricempire's servers had crashed.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45689241</guid><pubDate>Fri, 24 Oct 2025 00:24:11 +0000</pubDate></item><item><title>Computer science courses that don't exist, but should (2015)</title><link>https://prog21.dadgum.com/210.html</link><description>&lt;doc fingerprint="b44d70d748170ab9"&gt;
  &lt;main&gt;
    &lt;p&gt;Discover how to create and use variables that aren't inside of an object hierarchy. Learn about "functions," which are like methods but more generally useful. Prerequisite: Any course that used the term "abstract base class."&lt;/p&gt;
    &lt;p&gt;CSCI 3300: Classical Software Studies&lt;lb/&gt; Discuss and dissect historically significant products, including VisiCalc, AppleWorks, Robot Odyssey, Zork, and MacPaint. Emphases are on user interface and creativity fostered by hardware limitations.&lt;/p&gt;
    &lt;p&gt;CSCI 4020: Writing Fast Code in Slow Languages&lt;lb/&gt; Analyze performance at a high level, writing interpreted Python that matches or beats typical C++ code while being less fragile and more fun to work with.&lt;/p&gt;
    &lt;p&gt;CSCI 2170: User Experience of Command Line Tools&lt;lb/&gt; An introduction to UX principles as applied to command line programs designed as class projects. Core focus is on output relevance, readability, and minimization. UNIX "ls" tool is a case study in excessive command line switches.&lt;/p&gt;
    &lt;p&gt;PSYC 4410: Obsessions of the Programmer Mind&lt;lb/&gt; Identify and understand tangential topics that software developers frequently fixate on: code formatting, taxonomy, type systems, splitting projects into too many files. Includes detailed study of knee-jerk criticism when exposed to unfamiliar systems.&lt;/p&gt;
    &lt;p&gt;permalink September 10, 2015&lt;/p&gt;
    &lt;p&gt;I'm James Hague, a recovering programmer who has been designing video games since the 1980s. Programming Without Being Obsessed With Programming and Organizational Skills Beat Algorithmic Wizardry are good starting points. For the older stuff, try the 2012 Retrospective.&lt;/p&gt;
    &lt;p&gt;Where are the comments?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45690045</guid><pubDate>Fri, 24 Oct 2025 02:22:07 +0000</pubDate></item><item><title>Fast-DLLM: Training-Free Acceleration of Diffusion LLM</title><link>https://arxiv.org/abs/2505.22618</link><description>&lt;doc fingerprint="6c9c362a57f5d2ca"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Computation and Language&lt;/head&gt;&lt;p&gt; [Submitted on 28 May 2025 (v1), last revised 3 Jul 2025 (this version, v3)]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Fast-dLLM: Training-free Acceleration of Diffusion LLM by Enabling KV Cache and Parallel Decoding&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:Diffusion-based large language models (Diffusion LLMs) have shown promise for non-autoregressive text generation with parallel decoding capabilities. However, the practical inference speed of open-sourced Diffusion LLMs often lags behind autoregressive models due to the lack of Key-Value (KV) Cache and quality degradation when decoding multiple tokens simultaneously. To bridge this gap, we introduce a novel block-wise approximate KV Cache mechanism tailored for bidirectional diffusion models, enabling cache reuse with negligible performance drop. Additionally, we identify the root cause of generation quality degradation in parallel decoding as the disruption of token dependencies under the conditional independence assumption. To address this, we propose a confidence-aware parallel decoding strategy that selectively decodes tokens exceeding a confidence threshold, mitigating dependency violations and maintaining generation quality. Experimental results on LLaDA and Dream models across multiple LLM benchmarks demonstrate up to \textbf{27.6$\times$ throughput} improvement with minimal accuracy loss, closing the performance gap with autoregressive models and paving the way for practical deployment of Diffusion LLMs.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Chengyue Wu [view email]&lt;p&gt;[v1] Wed, 28 May 2025 17:39:15 UTC (272 KB)&lt;/p&gt;&lt;p&gt;[v2] Wed, 2 Jul 2025 05:11:54 UTC (502 KB)&lt;/p&gt;&lt;p&gt;[v3] Thu, 3 Jul 2025 04:51:05 UTC (541 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45690219</guid><pubDate>Fri, 24 Oct 2025 02:50:50 +0000</pubDate></item><item><title>Roc Camera</title><link>https://roc.camera/</link><description>&lt;doc fingerprint="99e41a343b35502d"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Photography used to have magic&lt;/head&gt;
    &lt;head rend="h2"&gt;Photographyusedtohavemagic&lt;/head&gt;
    &lt;p&gt;There was a time when cameras captured magic. A photo wasn't just an image; it was a snapshot of life. People lined up, waited their turn, and treasured the results. Photos told stories, a reflection of reality, a physical artifact of our lives.&lt;/p&gt;
    &lt;head rend="h2"&gt;AI has blurred the line&lt;/head&gt;
    &lt;head rend="h2"&gt;AIhasblurredtheline&lt;/head&gt;
    &lt;p&gt;In the past two decades, we've seen an explosion in the way we take, share, and create images. Smartphones and social media has capturing and sharing images easier. Generative AI has made it possible to create any image we can imagine.&lt;/p&gt;
    &lt;head rend="h2"&gt;Lost sight of what is real&lt;/head&gt;
    &lt;head rend="h2"&gt;Lostsightofwhatisreal&lt;/head&gt;
    &lt;p&gt;We've started to lose sight of what is real in an endless sea of copies, AI-generated noise, and altered realities. We're losing our ability to find our bearings in the digital world.&lt;/p&gt;
    &lt;head rend="h2"&gt;It's time for Roc Camera&lt;/head&gt;
    &lt;head rend="h2"&gt;It'stimeforRocCamera&lt;/head&gt;
    &lt;p&gt;By combining sensors, an on-device zero-knowledge proofs, and a tamper-proof environment for attesting sensor data, We've built Roc Camera to capture verifiably real moments.&lt;/p&gt;
    &lt;head rend="h3"&gt;Camera Components:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;â¢ 4-inch IPS LCD Screen 720x720 with Capacitive Touch&lt;/item&gt;
      &lt;item&gt;â¢ 16MP Sony IMX519 CMOS with 122Â° FOV lens&lt;/item&gt;
      &lt;item&gt;â¢ Raspberry Pi 4 4GB RAM ARM Cortex-A72 1.5 Ghz&lt;/item&gt;
      &lt;item&gt;â¢ LiPo 4000mAh Battery&lt;/item&gt;
      &lt;item&gt;â¢ Uninterruptible Power Supply Board&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Capture&lt;/head&gt;
    &lt;p&gt;Capture a photo that only this Camera can uniquely take&lt;/p&gt;
    &lt;head rend="h3"&gt;Prove&lt;/head&gt;
    &lt;p&gt;Creates a Zero Knowledge (ZK) Proof of the camera sensor data and other metadatas&lt;/p&gt;
    &lt;head rend="h3"&gt;Verify&lt;/head&gt;
    &lt;p&gt;Verify that the photo is real by checking the ZK proof via the Roc Photo SDK&lt;/p&gt;
    &lt;head rend="h2"&gt; Capture &lt;lb/&gt;verifiably&lt;lb/&gt; real&lt;lb/&gt; moments &lt;/head&gt;
    &lt;p&gt;Accepting orders now â Batch 2&lt;/p&gt;
    &lt;p&gt;Ships in 2~3 weeks&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45690251</guid><pubDate>Fri, 24 Oct 2025 02:54:29 +0000</pubDate></item><item><title>JupyterGIS breaks through to the next level</title><link>https://eo4society.esa.int/2025/10/16/jupytergis-breaks-through-to-the-next-level/</link><description>&lt;doc fingerprint="1e3f8f51d82fedc0"&gt;
  &lt;main&gt;
    &lt;p&gt;Launched in June 2024, JupyterGIS was introduced as a collaborative, web-based GIS environment built on the JupyterLab framework. Its objective is to bring QGIS-inspired workflows into the browser, enabling real-time collaborative editing, seamless integration with notebooks, and support for core geospatial data formats.&lt;/p&gt;
    &lt;p&gt;When it was first announced earlier this year, JupyterGIS already delivered:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Real-time collaborative editing (Google Docs-style)&lt;/item&gt;
      &lt;item&gt;Visualisation of raster &amp;amp; vector data&lt;/item&gt;
      &lt;item&gt;Symbology editing and spatio-temporal animations&lt;/item&gt;
      &lt;item&gt;Programmatic map control via a Python API.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Thanks to contributions from the community and support from partner organizations, JupyterGIS has advanced significantly and now offers an expanded range of features for analysis, visualization, and collaboration.&lt;/p&gt;
    &lt;p&gt;Enhanced vector tile capabilities&lt;/p&gt;
    &lt;p&gt;Support for vector tiles has been strengthened, including full compatibility with the pmtiles format.&lt;/p&gt;
    &lt;p&gt;Other key updates include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;An identify tool that inspects vector tiles to display features and associated properties.&lt;/item&gt;
      &lt;item&gt;A symbology panel that applies graduated, categorized, and canonical symbology to vector tile layers.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These improvements enhance the interpretability and styling of geospatial datasets directly in the browser.&lt;/p&gt;
    &lt;p&gt;A new processing toolbox&lt;/p&gt;
    &lt;p&gt;One of the most significant updates is a new browser-based processing toolbox powered by a WebAssembly (WASM) build of the Geospatial Data Abstraction Library (GDAL).&lt;/p&gt;
    &lt;p&gt;Available tools include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Buffer: computes a buffer around geometries of a vector dataset.&lt;/item&gt;
      &lt;item&gt;Convex Hull: calculates the convex hull for each feature of an input layer.&lt;/item&gt;
      &lt;item&gt;Dissolve: combines features of vector layers into new features&lt;/item&gt;
      &lt;item&gt;Bounding Boxes: calculates the bounding box for each feature in an input layer.&lt;/item&gt;
      &lt;item&gt;Centroid: creates a new layer with the centroids of the geometries of an input layer.&lt;/item&gt;
      &lt;item&gt;Concave Hull: computes the concave hull for each feature of an input point layer.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This toolbox has been designed for extensibility, with a JSON schema that allows additional GDAL operations to be integrated in a straightforward manner.&lt;/p&gt;
    &lt;p&gt;Symbology enhancements&lt;/p&gt;
    &lt;p&gt;Visualization of geospatial data has become more flexible and expressive through several enhancements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Viridis is now the default colormap, providing perceptually uniform visualization.&lt;/item&gt;
      &lt;item&gt;Multiband symbology is now available for GeoTIFFs.&lt;/item&gt;
      &lt;item&gt;Canonical symbology defined in GeoJSON files can be applied automatically.&lt;/item&gt;
      &lt;item&gt;Colormaps can now be reversed, allowing greater flexibility for data interpretation and visualization.&lt;/item&gt;
      &lt;item&gt;In the case of point layers, color and marker size can be styled independently, and bound to different data.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Integration with SpatioTemporal Asset Catalogs (STAC)&lt;/p&gt;
    &lt;p&gt;A SpatioTemporal Asset Catalog (STAC) browser is now embedded into JupyterGIS, streamlining access to different data collections. Users can select specific platforms and sensors, choose data products and processing levels, and set temporal and spatial constraints.&lt;/p&gt;
    &lt;p&gt;It is now possible to search across multiple datasets simultaneously. Users can click on any result to add it directly as a layer to their JupyterGIS project. This creates a seamless workflow from data discovery to visualization, making it easier for researchers and analysts to find and integrate relevant satellite imagery and geospatial datasets into their Jupyter notebooks.&lt;/p&gt;
    &lt;p&gt;Currently, the STAC Browser only supports the Geodes STAC API but support for all STAC catalogs is under way.&lt;/p&gt;
    &lt;p&gt;Support for more data types&lt;/p&gt;
    &lt;p&gt;The range of supported geospatial data formats is now broadened with GeoParquet and PMTiles, enabling efficient columnar storage and fast analytical queries for GeoParquet, and highly compact, streaming-friendly vector tile delivery for PMTiles.&lt;/p&gt;
    &lt;p&gt;User experience and interface improvements&lt;/p&gt;
    &lt;p&gt;The interface has been refined for a smoother workflow:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Integrated control panels (layer list, filters, layer properties, etc.), reducing back and forth between the JupyterLab side-panels and the JupyterGIS UI. It also improves the “single document” scenario, allowing it to interact with JupyterGIS controls when opening a GIS document from the classic Jupyter Notebook UI.&lt;/item&gt;
      &lt;item&gt;An improved toolbar design, with cleaner icons and better usability.&lt;/item&gt;
      &lt;item&gt;A new feature to center the map on your current location.&lt;/item&gt;
      &lt;item&gt;Map annotations now link to the map: clicking an annotation automatically re-centers and zooms to the location.&lt;/item&gt;
      &lt;item&gt;Full-screen mode support.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Legends for vector layers&lt;/p&gt;
    &lt;p&gt;JupyterGIS now automatically generates legends for vector layers, ensuring consistent interpretation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Legends are dynamically updated to reflect current symbology.&lt;/item&gt;
      &lt;item&gt;Customizations such as reversed colormaps are preserved.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;JupyterGIS tiler extension&lt;/p&gt;
    &lt;p&gt;An extension for JupyterGIS enables the creation of JupyterGIS layers from xarray variables in Jupyter kernels, with support for lazy evaluation, bridging geospatial workflows with powerful array-based computation.&lt;/p&gt;
    &lt;p&gt;The package, called JupyterGIS-tiler, is available in GitHub here and can be installed from PyPI with pip install jupytergis-tiler.&lt;/p&gt;
    &lt;p&gt;Looking ahead&lt;/p&gt;
    &lt;p&gt;Development will continue to expand JupyterGIS in several directions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Extension of the GDAL-based processing toolbox.&lt;/item&gt;
      &lt;item&gt;Deeper integration with QGIS and a richer Python API for automation.&lt;/item&gt;
      &lt;item&gt;A Story Maps Editor and Viewer to enable interactive communication of geospatial information through text, imagery, and maps.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In the meantime, feel free to try JupyterGIS directly in your browser with JupyterLite, no installation required.&lt;/p&gt;
    &lt;p&gt;Opportunities for engagement also include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Checking out documentation for tutorials and the Python API.&lt;/item&gt;
      &lt;item&gt;Discussions via the GeoJupyter Zulip channel or the bi-weekly GeoJupyter hackathon.&lt;/item&gt;
      &lt;item&gt;Contributions to the development repository.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The JupyterGIS community continues to grow, and active participation from researchers, developers, and educators worldwide is encouraged.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45690679</guid><pubDate>Fri, 24 Oct 2025 04:13:01 +0000</pubDate></item></channel></rss>