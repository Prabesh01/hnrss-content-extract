<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 28 Jan 2026 20:53:21 +0000</lastBuildDate><item><title>Hypercubic (YC F25) Is Hiring a Founding SWE and COBOL Engineer</title><link>https://www.ycombinator.com/companies/hypercubic/jobs</link><description>&lt;doc fingerprint="3564976ca045d865"&gt;
  &lt;main&gt;
    &lt;p&gt;AI to maintain and modernize COBOL.&lt;/p&gt;
    &lt;p&gt;Hypercubic is an AI-native maintenance and modernization platform for COBOL and mainframes.&lt;/p&gt;
    &lt;p&gt;We help enterprises understand and preserve their mission-critical legacy systems. About 70% of the Fortune 500 companies still rely on them to run their core business applications in banking, insurance, telecom, airlines, retail, and more.&lt;/p&gt;
    &lt;p&gt;These systems, originally built in the 1960s‚Äì90s, still power trillions in global infrastructure today but have become increasingly opaque as original developers retire or leave the workforce.&lt;/p&gt;
    &lt;p&gt;We're laying the foundation to autonomously maintain and modernize these legacy systems to future-proof the backbone of the global economy.&lt;/p&gt;
    &lt;p&gt;Learn more at hypercubic.ai&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46784491</guid><pubDate>Tue, 27 Jan 2026 18:50:50 +0000</pubDate></item><item><title>A verification layer for browser agents: Amazon case study</title><link>https://sentienceapi.com/blog/verification-layer-amazon-case-study</link><description>&lt;doc fingerprint="3f4442764a60997b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A verification layer for browser agents: Amazon case study&lt;/head&gt;
    &lt;p&gt;How structured snapshots + Jest-style assertions make small local models reliable.&lt;/p&gt;
    &lt;p&gt;This post is a technical report on four runs of the same Amazon shopping flow. The purpose is to isolate one claim: reliability comes from verification, not from giving the model more pixels or more parameters.&lt;/p&gt;
    &lt;p&gt;Sentience is used here as a verification layer: each step is gated by explicit assertions over structured snapshots. This makes it feasible to use small local models as executors, while reserving larger models for planning (reasoning) when needed. No vision models are required for the core loop in the local runs discussed below.&lt;/p&gt;
    &lt;head rend="h2"&gt;Key findings&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Finding&lt;/cell&gt;
        &lt;cell role="head"&gt;Evidence (from logs / report)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;A fully autonomous run can complete with local models when verification gates every step.&lt;/cell&gt;
        &lt;cell&gt;Demo 3 re-run: &lt;code&gt;Steps passed: 7/7&lt;/code&gt; and &lt;code&gt;success: True&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Token efficiency can be engineered by interface design (structure + filtering), not by model choice.&lt;/cell&gt;
        &lt;cell&gt;Demo 0 report: estimated ~35,000 ‚Üí 19,956 tokens (~43% reduction)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Verification &amp;gt; intelligence is the practical lesson.&lt;/cell&gt;
        &lt;cell&gt;Planner drift is surfaced as explicit FAIL/mismatch rather than silent progress&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Key datapoints:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Metric&lt;/cell&gt;
        &lt;cell role="head"&gt;Demo 0 (cloud baseline)&lt;/cell&gt;
        &lt;cell role="head"&gt;Demo 3 (local autonomy)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Success&lt;/cell&gt;
        &lt;cell&gt;1/1 run&lt;/cell&gt;
        &lt;cell&gt;7/7 steps (re-run)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Duration&lt;/cell&gt;
        &lt;cell&gt;~60,000ms&lt;/cell&gt;
        &lt;cell&gt;405,740ms&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Tokens&lt;/cell&gt;
        &lt;cell&gt;19,956 (after filtering)&lt;/cell&gt;
        &lt;cell&gt;11,114&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Task (constant across runs): Amazon ‚Üí Search ‚Äúthinkpad‚Äù ‚Üí Click first product ‚Üí Add to cart ‚Üí Proceed to checkout&lt;/p&gt;
    &lt;head rend="h2"&gt;First principles: structure &amp;gt; pixels&lt;/head&gt;
    &lt;p&gt;Screenshot-based agents use pixels as the control plane. That often fails in predictable ways: ambiguous click targets, undetected navigation failures, and ‚Äúprogress‚Äù without state change.&lt;/p&gt;
    &lt;p&gt;The alternative is to treat the page as a structured snapshot (roles, text, geometry, and a small amount of salience) and then require explicit pass/fail verification after each action. This is the ‚ÄúJest for agents‚Äù idea: a step does not succeed because the model says it did; it succeeds because an assertion over browser state passes.&lt;/p&gt;
    &lt;head rend="h2"&gt;The ‚Äúimpossible benchmark‚Äù&lt;/head&gt;
    &lt;p&gt;The target configuration is a strong planner paired with a small, local executor, still achieving reliable end-to-end behavior. Concretely: DeepSeek-R1 (planner) + a ~3B-class local executor, with Sentience providing verification gates between steps.&lt;/p&gt;
    &lt;p&gt;Note on attribution: the run logs included in this post report outcomes (duration/tokens/steps) but do not consistently print model identifiers. Where specific model names are mentioned below, they are explicitly labeled as run configuration.&lt;/p&gt;
    &lt;p&gt;Why this is a useful benchmark:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The executor is intentionally ‚Äúdumb‚Äù: it only needs to choose DOM actions (CLICK/TYPE) against a compact representation.&lt;/item&gt;
      &lt;item&gt;Reliability comes from the verification layer: each action is followed by snapshot + assertions that gate success and drive bounded retries.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In other words, the point is not that small models are magically capable; it‚Äôs that verification makes capability usable.&lt;/p&gt;
    &lt;head rend="h2"&gt;Setup and dependencies&lt;/head&gt;
    &lt;p&gt;These demos use the Sentience Python SDK, Playwright for browser control, and local LLMs for planning/execution. The minimal install sequence is straight from the SDK README:&lt;/p&gt;
    &lt;code&gt;# Install from PyPI
pip install sentienceapi

# Install Playwright browsers (required)
playwright install chromium

# For local LLMs (optional)
pip install transformers torch  # For local LLMs&lt;/code&gt;
    &lt;p&gt;Video artifacts are generated from screenshots; if &lt;code&gt;ffmpeg&lt;/code&gt; is available, the run assembles a short summary clip (the logs show creation even when &lt;code&gt;ffmpeg&lt;/code&gt; errors occur in some runs).&lt;/p&gt;
    &lt;head rend="h2"&gt;Architecture: the 3-model stack (planner, executor, verifier)&lt;/head&gt;
    &lt;p&gt;Sentience separates planning from execution, and inserts verification in the middle:&lt;/p&gt;
    &lt;code&gt;Planner LLM ‚Üí JSON Plan (steps + required verification)
          ‚Üì
     AgentRuntime
(snapshot + verify + trace)
          ‚Üì
   Executor LLM (CLICK/TYPE)
          ‚Üì
 AsyncSentienceBrowser + Extension
          ‚Üì
Trace pipeline ‚Üí Sentience Studio&lt;/code&gt;
    &lt;p&gt;The key is the runtime: every action is wrapped in a snapshot + verification cycle that produces pass/fail evidence. Verification is inline runtime gating (it determines whether the step succeeds), not post-hoc analysis.&lt;/p&gt;
    &lt;p&gt;Clarifying terms used below:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Planner (reasoning): produces a structured plan (steps + required verifications).&lt;/item&gt;
      &lt;item&gt;Executor (action): selects concrete DOM actions (CLICK/TYPE) against the current snapshot.&lt;/item&gt;
      &lt;item&gt;Verifier (assertions): evaluates explicit assertions over snapshots and gates step/task success (with deterministic overrides when intent is unambiguous).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Amazon shopping flow snapshot diff status between 2 steps (shows whether the LLM action succeeded)&lt;/p&gt;
    &lt;p&gt;Amazon shopping flow snapshot heatmap by importance of top elements&lt;/p&gt;
    &lt;head rend="h2"&gt;The verification layer (SDK code you can copy)&lt;/head&gt;
    &lt;p&gt;At the runtime level, assertions are first-class, recorded as events, and can gate success. From &lt;code&gt;AgentRuntime.assert_()&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;def assert_(
  self,
  predicate: Predicate,
  label: str,
  required: bool = False,
) -&amp;gt; bool:
  """
  Evaluate an assertion against current snapshot state.

  The assertion result is:
  1. Accumulated for inclusion in step_end.data.verify.signals.assertions
  2. Emitted as a dedicated 'verification' event for Studio timeline
  """
  outcome = predicate(self._ctx())
  self._record_outcome(
      outcome=outcome,
      label=label,
      required=required,
      kind="assert",
      record_in_step=True,
  )
  if required and not outcome.passed:
      self._persist_failure_artifacts(reason=f"assert_failed:{label}")
  return outcome.passed&lt;/code&gt;
    &lt;p&gt;To support async UI, the runtime exposes fluent retry logic:&lt;/p&gt;
    &lt;code&gt;def check(self, predicate: Predicate, label: str, required: bool = False) -&amp;gt; AssertionHandle:
  """
  Create an AssertionHandle for fluent .once() / .eventually() usage.

  This does NOT evaluate the predicate immediately.
  """
  return AssertionHandle(runtime=self, predicate=predicate, label=label, required=required)&lt;/code&gt;
    &lt;p&gt;Predicates are explicit, composable, and operate over semantic snapshots. For example:&lt;/p&gt;
    &lt;code&gt;def url_contains(substring: str) -&amp;gt; Predicate:
  def _pred(ctx: AssertContext) -&amp;gt; AssertOutcome:
      url = ctx.url or ""
      ok = substring in url
      return AssertOutcome(
          passed=ok,
          reason="" if ok else f"url does not contain: {substring}",
          details={"substring": substring, "url": url[:200]},
      )
  return _pred&lt;/code&gt;
    &lt;code&gt;def exists(selector: str) -&amp;gt; Predicate:
  def _pred(ctx: AssertContext) -&amp;gt; AssertOutcome:
      snap = ctx.snapshot
      if snap is None:
          return AssertOutcome(
              passed=False,
              reason="no snapshot available",
              details={"selector": selector, "reason_code": "no_snapshot"},
          )
      from .query import query
      matches = query(snap, selector)
      ok = len(matches) &amp;gt; 0
      return AssertOutcome(
          passed=ok,
          reason="" if ok else f"no elements matched selector: {selector}",
          details={
              "selector": selector,
              "matched": len(matches),
              "reason_code": "ok" if ok else "no_match",
          },
      )
  return _pred&lt;/code&gt;
    &lt;p&gt;This is why the system behaves like a test harness: assertions are deterministic, and failures produce artifacts instead of silent drift.&lt;/p&gt;
    &lt;head rend="h2"&gt;A tiny comparison table (control plane and failure mode)&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Approach&lt;/cell&gt;
        &lt;cell role="head"&gt;Control Plane&lt;/cell&gt;
        &lt;cell role="head"&gt;Failure Mode&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Vision agents&lt;/cell&gt;
        &lt;cell&gt;Screenshots&lt;/cell&gt;
        &lt;cell&gt;Silent retries&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Raw DOM&lt;/cell&gt;
        &lt;cell&gt;HTML text&lt;/cell&gt;
        &lt;cell&gt;Hallucinated selectors&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Sentience&lt;/cell&gt;
        &lt;cell&gt;Structured snapshot + assertions&lt;/cell&gt;
        &lt;cell&gt;Explicit FAIL with artifacts&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Token efficiency is not a side effect here. The structure-first snapshot plus role filtering reduced prompt volume by ~43% in the cloud LLM baseline (Demo 0), while keeping the same deterministic verification loop.&lt;/p&gt;
    &lt;head rend="h2"&gt;The four demos (same task, different autonomy)&lt;/head&gt;
    &lt;head rend="h3"&gt;Demo 3 ‚Äî Local autonomy (planner + executor) with verification gates&lt;/head&gt;
    &lt;head rend="h4"&gt;See Code&lt;/head&gt;
    &lt;p&gt;Inputs&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Planner (reasoning): DeepSeek-R1 family (run configuration; see note above)&lt;/item&gt;
      &lt;item&gt;Executor (action): local Qwen family (run configuration; the ‚Äúimpossible benchmark‚Äù target is ~3B-class)&lt;/item&gt;
      &lt;item&gt;Verifier (assertions): Sentience runtime gates (structured snapshots + explicit assertions + deterministic overrides)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Verification&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Each step is gated by explicit assertions over snapshots (URL predicates, element existence, etc.)&lt;/item&gt;
      &lt;item&gt;Deterministic overrides are applied when intent is unambiguous (e.g., drawer dismissal)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Outcome The re-run completed end-to-end:&lt;/p&gt;
    &lt;code&gt;=== Run Summary ===
success: True
duration_ms: 405740
tokens_total: 11114
Steps passed: 7/7&lt;/code&gt;
    &lt;p&gt;The practical point is not that the executor ‚Äúunderstands Amazon.‚Äù It selects actions inside a loop that proves outcomes (via assertions) and forces the correct branch when intent is unambiguous (via deterministic overrides).&lt;/p&gt;
    &lt;p&gt;Demo 3 is the latest result in this case study - the one we care about most (local autonomy with verification). To give the full context, the next sections go back to the earliest baseline (Demo 0) and then walk forward through Demo 1 and Demo 2, showing the evolution: how structure-first snapshots, verification gates, and element filtering made the system cheaper and more reliable before we reached full autonomy.&lt;/p&gt;
    &lt;head rend="h3"&gt;Demo 0 ‚Äî Cloud LLM + Sentience SDK (structured JSON)&lt;/head&gt;
    &lt;head rend="h4"&gt;See Code&lt;/head&gt;
    &lt;p&gt;Earlier baseline (Dec 2025 report). This run used a cloud model (GLM-4.6) with Sentience‚Äôs structured snapshot pipeline. The key contribution was reducing the problem to structured elements and gating each step with verification.&lt;/p&gt;
    &lt;p&gt;Token reduction from element filtering (as reported):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Metric&lt;/cell&gt;
        &lt;cell role="head"&gt;Before&lt;/cell&gt;
        &lt;cell role="head"&gt;After&lt;/cell&gt;
        &lt;cell role="head"&gt;Reduction&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Prompt tokens (estimated)&lt;/cell&gt;
        &lt;cell&gt;~35,000&lt;/cell&gt;
        &lt;cell&gt;19,956&lt;/cell&gt;
        &lt;cell&gt;~43%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Demo 1 ‚Äî Human steps + Local Qwen 2.5-3B executor&lt;/head&gt;
    &lt;head rend="h4"&gt;See Code&lt;/head&gt;
    &lt;p&gt;Inputs&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Planner: human-authored steps&lt;/item&gt;
      &lt;item&gt;Executor: Local Qwen 2.5-3B (run configuration)&lt;/item&gt;
      &lt;item&gt;Verifier: Sentience assertions&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Outcome This isolates the verification layer and structured snapshot format with a small local executor.&lt;/p&gt;
    &lt;head rend="h3"&gt;Demo 2 ‚Äî Local Qwen 2.5-7B planner + Qwen 2.5-3B executor (autonomous)&lt;/head&gt;
    &lt;head rend="h4"&gt;See Code&lt;/head&gt;
    &lt;p&gt;Inputs&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Planner: Local Qwen 2.5-7B (run configuration)&lt;/item&gt;
      &lt;item&gt;Executor: Qwen 2.5-3B (run configuration)&lt;/item&gt;
      &lt;item&gt;Verifier: Sentience assertions + overrides&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Verification When the planner‚Äôs verification target becomes brittle under UI ambiguity, the runtime surfaces the mismatch via explicit verification failures (rather than silently proceeding).&lt;/p&gt;
    &lt;p&gt;Context: cross-demo outcome summary. The table below is a compact comparison of the four demos (cloud baseline ‚Üí human-plan control ‚Üí autonomous planning ‚Üí local autonomy), highlighting duration, token usage, and step completion.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Demo&lt;/cell&gt;
        &lt;cell role="head"&gt;Planner / Executor&lt;/cell&gt;
        &lt;cell role="head"&gt;Duration&lt;/cell&gt;
        &lt;cell role="head"&gt;Tokens&lt;/cell&gt;
        &lt;cell role="head"&gt;Steps&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;Cloud LLM (run config) + Sentience SDK&lt;/cell&gt;
        &lt;cell&gt;~60,000ms&lt;/cell&gt;
        &lt;cell&gt;19,956&lt;/cell&gt;
        &lt;cell&gt;1/1 run&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Human plan + Local Qwen 2.5-3B (run config)&lt;/cell&gt;
        &lt;cell&gt;207,569ms&lt;/cell&gt;
        &lt;cell&gt;5,555&lt;/cell&gt;
        &lt;cell&gt;9/9 steps&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;Local Qwen 2.5-7B + Qwen 2.5-3B (run config)&lt;/cell&gt;
        &lt;cell&gt;435,446ms&lt;/cell&gt;
        &lt;cell&gt;13,128&lt;/cell&gt;
        &lt;cell&gt;7/8 steps&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;DeepSeek-R1 family + local Qwen family (run config)&lt;/cell&gt;
        &lt;cell&gt;Run A: 496,863ms / Run B: 405,740ms&lt;/cell&gt;
        &lt;cell&gt;12,922 / 11,114&lt;/cell&gt;
        &lt;cell&gt;7/8 ‚Üí 7/7 steps&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;What the logs show (concrete evidence)&lt;/head&gt;
    &lt;head rend="h3"&gt;Deterministic overrides (first product)&lt;/head&gt;
    &lt;p&gt;The executor can be overruled when the runtime has a safer deterministic choice:&lt;/p&gt;
    &lt;code&gt;[fallback] first_product_link preselect -&amp;gt; CLICK(1022)
Executor decision: {"action": "click", "id": 884, "raw": "CLICK(884)"}
[override] first_product_link -&amp;gt; CLICK(1022)&lt;/code&gt;
    &lt;p&gt;This is not a model preference. It is an explicit guardrail that preserves the ‚Äúfirst result‚Äù intent.&lt;/p&gt;
    &lt;head rend="h3"&gt;Drawer handling (add-on upsell)&lt;/head&gt;
    &lt;p&gt;When Amazon opens the add-on drawer, the runtime dismisses it deterministically:&lt;/p&gt;
    &lt;code&gt;[fallback] add_to_cart drawer detected -&amp;gt; CLICK(6926)
Executor decision: {"action": "click", "id": 1214, "raw": "CLICK(1214)"}
[override] add_to_cart -&amp;gt; CLICK(6926)&lt;/code&gt;
    &lt;p&gt;Result:&lt;/p&gt;
    &lt;code&gt;result: PASS | add_to_cart_verified_after_drawer&lt;/code&gt;
    &lt;head rend="h3"&gt;Planner drift (brittle selector)&lt;/head&gt;
    &lt;p&gt;In the autonomous planner run, the verification target briefly drifted into a brittle selector; the runtime still enforces pass/fail deterministically, which is why the mismatch is surfaced rather than glossed over:&lt;/p&gt;
    &lt;code&gt;"intent": "checkout_button",
"verify": [
{
  "predicate": "exists",
  "args": [
    "data-test-id=nav-x-site-nav-button-checkout"
  ]
}
]&lt;/code&gt;
    &lt;p&gt;The system caught the mismatch with assertions, but it highlights why verification must be strong before model scale pays off.&lt;/p&gt;
    &lt;head rend="h2"&gt;Run summaries (from logs)&lt;/head&gt;
    &lt;p&gt;Demo 0 (Cloud LLM + Sentience SDK; report excerpt):&lt;/p&gt;
    &lt;code&gt;success: True
duration_ms: ~60000
tokens_total: 19956
notes: token reduction ~43% (estimated ~35,000 ‚Üí 19,956) via element filtering&lt;/code&gt;
    &lt;p&gt;Demo 1 (Human steps + Qwen 2.5-3B executor):&lt;/p&gt;
    &lt;code&gt;=== Run Summary ===
success: True
duration_ms: 207569
tokens_total: 5555
Steps passed: 9/9&lt;/code&gt;
    &lt;p&gt;Demo 2 (Qwen 2.5-7B planner + Qwen 2.5-3B executor):&lt;/p&gt;
    &lt;code&gt;=== Run Summary ===
success: True
duration_ms: 435446
tokens_total: 13128
Steps passed: 7/8&lt;/code&gt;
    &lt;p&gt;Demo 3 Run A (DeepSeek-R1-Distill-Qwen-14B planner + Qwen 2.5-7B executor): (Model identifiers are run configuration; the excerpted logs primarily report outcome metrics.)&lt;/p&gt;
    &lt;code&gt;=== Run Summary ===
success: True
duration_ms: 496863
tokens_total: 12922
Steps passed: 7/8&lt;/code&gt;
    &lt;p&gt;Demo 3 Re-run:&lt;/p&gt;
    &lt;code&gt;=== Run Summary ===
success: True
duration_ms: 405740
tokens_total: 11114
Steps passed: 7/7&lt;/code&gt;
    &lt;p&gt;The run also emits a trace upload confirmation:&lt;/p&gt;
    &lt;code&gt;‚úÖ [Sentience] Trace uploaded successfully&lt;/code&gt;
    &lt;p&gt;Some runs use MLX backends (Apple Silicon). MLX does not expose token usage metrics, so token totals can be directional; plan stability and retry counts are the more reliable signal in those cases.&lt;/p&gt;
    &lt;head rend="h2"&gt;Observability and artifacts&lt;/head&gt;
    &lt;p&gt;Each step produces structured traces, snapshots, and artifacts. The run automatically creates a video summary from screenshots:&lt;/p&gt;
    &lt;code&gt;Creating video from screenshots in .../screenshots/20260120_115426...
Found 7 screenshots
...
‚úÖ Video created: .../demo.mp4
‚úÖ [Sentience] Trace uploaded successfully&lt;/code&gt;
    &lt;p&gt;These traces power Sentience Studio: diff_status, evidence, and a timeline of verification events that explain why a step passed or failed.&lt;/p&gt;
    &lt;p&gt;See the screenshot below for a step with failed assertion due to URL not being changed after a click event:&lt;/p&gt;
    &lt;p&gt;Sentience Studio provides a time line to walk through traces for each run, making it easy to debug and understand agent behavior.&lt;/p&gt;
    &lt;head rend="h2"&gt;Takeaways (first principles)&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Verification &amp;gt; intelligence for reliability. A modest model operating inside strict, deterministic tests will beat a stronger model operating without tests, because failures are detected and bounded.&lt;/item&gt;
      &lt;item&gt;Vision is a fallback, not the control plane. Structure-first snapshots and assertions carry the flow; vision is used when necessary, not by default.&lt;/item&gt;
      &lt;item&gt;Structure + verification makes small models viable. The executor is constrained to checkable actions; retries are bounded; failures produce artifacts.&lt;/item&gt;
      &lt;item&gt;Local models become a rational default. Lower token usage enables better economics and improves privacy/deployment control.&lt;/item&gt;
      &lt;item&gt;Larger planners help after verification is in place. They reduce plan drift and replan churn; they do not replace verification.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In Sentience, ‚Äúverification‚Äù means explicit assertions over structured snapshots, with deterministic overrides when intent is unambiguous.&lt;/p&gt;
    &lt;p&gt;This is the Sentience approach: treat the browser as structured data, assert outcomes explicitly, and keep vision as a fallback. The result is a deterministic core that makes local LLMs practical without sacrificing reliability.&lt;/p&gt;
    &lt;p&gt;This approach is designed for teams that care about cost, data privacy/compliance, reproducibility, and debuggability - not for demo-only agents.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46790127</guid><pubDate>Wed, 28 Jan 2026 02:08:14 +0000</pubDate></item><item><title>Rust at Scale: An Added Layer of Security for WhatsApp</title><link>https://engineering.fb.com/2026/01/27/security/rust-at-scale-security-whatsapp/</link><description>&lt;doc fingerprint="8e10dda3ac31549d"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;WhatsApp has adopted and rolled out a new layer of security for users ‚Äì built with Rust ‚Äì as part of its effort to harden defenses against malware threats.&lt;/item&gt;
      &lt;item&gt;WhatsApp‚Äôs experience creating and distributing our media consistency library in Rust to billions of devices and browsers proves Rust is production ready at a global scale.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Our Media Handling Strategy&lt;/head&gt;
    &lt;p&gt;WhatsApp provides default end-to-end encryption for over 3 billion people to message securely each and every day. Online security is an adversarial space, and to continue ensuring users can keep messaging securely, we‚Äôre constantly adapting and evolving our strategy against cyber-security threats ‚Äì all while supporting the WhatsApp infrastructure to help people connect.&lt;/p&gt;
    &lt;p&gt;For example, WhatsApp, like many other applications, allows users to share media and other types of documents. WhatsApp helps protect users by warning about dangerous attachments like APKs, yet rare and sophisticated malware could be hidden within a seemingly benign file like an image or video. These maliciously crafted files might target unpatched vulnerabilities in the operating system, libraries distributed by the operating system, or the application itself.&lt;/p&gt;
    &lt;p&gt;To help protect against such potential threads, WhatsApp is increasingly using the Rust programming language, including in our media sharing functionality. Rust is a memory safe language offering numerous security benefits. We believe that this is the largest rollout globally of any library written in Rust.&lt;/p&gt;
    &lt;p&gt;To help explain why and how we rolled this out, we should first look back at a key OS-level vulnerability that sent an important signal to WhatsApp around hardening media-sharing defenses.&lt;/p&gt;
    &lt;head rend="h2"&gt;2015 Android Vulnerability: A Wake-up Call for Media File Protections&lt;/head&gt;
    &lt;p&gt;In 2015, Android devices, and the applications that ran on them, became vulnerable to the ‚ÄúStagefright‚Äù vulnerability. The bug lay in the processing of media files by operating system-provided libraries, so WhatsApp and other applications could not patch the underlying vulnerability. Because it could often take months for people to update to the latest version of their software, we set out to find solutions that would keep WhatsApp users safe, even in the event of an operating system vulnerability.&lt;/p&gt;
    &lt;p&gt;At that time, we realized that a cross-platform C++ library already developed by WhatsApp to send and consistently format MP4 files (called ‚Äúwamedia‚Äù) could be modified to detect files which do not adhere to the MP4 standard and might trigger bugs in a vulnerable OS library on the receiver side ‚Äì hence putting a target‚Äôs security at risk. We rolled out this check and were able to protect WhatsApp users from the Stagefright vulnerability much more rapidly than by depending on users to update the OS itself.&lt;/p&gt;
    &lt;p&gt;But because media checks run automatically on download and process untrusted inputs, we identified early on that wamedia was a prime candidate for using a memory safe language.&lt;/p&gt;
    &lt;head rend="h2"&gt;Our Solution: Rust at Scale&lt;/head&gt;
    &lt;p&gt;Rather than an incremental rewrite, we developed the Rust version of wamedia in parallel with the original C++ version. We used differential fuzzing and extensive integration and unit tests to ensure compatibility between the two implementations.&lt;/p&gt;
    &lt;p&gt;Two major hurdles were the initial binary size increase due to bringing in the Rust standard library and the build system support required for the diverse platforms supported by WhatsApp. WhatsApp made a long-term bet to build that support. In the end, we replaced 160,000 lines of C++ (excluding tests) with 90,000 lines of Rust (including tests). The Rust version showed performance and runtime memory usage advantages over the C++. Given this success, Rust was fully rolled out to all WhatsApp users and many platforms: Android, iOS, Mac, Web, Wearables, and more. With this positive evidence in hand, memory safe languages will play an ever increasing part in WhatsApp‚Äôs overall approach to application and user security.&lt;/p&gt;
    &lt;p&gt;Over time, we‚Äôve added more checks for non-conformant structures within certain file types to help protect downstream libraries from parser differential exploit attempts. Additionally, we check higher risk file types, even if structurally conformant, for risk indicators. For instance, PDFs are often a vehicle for malware, and more specifically, the presence of embedded files and scripting elements within a PDF further raise risks. We also detect when one file type masquerades as another, through a spoofed extension or MIME type. Finally, we uniformly flag known dangerous file types, such as executables or applications, for special handling in the application UX. Altogether, we call this ensemble of checks ‚ÄúKaleidoscope.‚Äù This system protects people on WhatsApp from potentially malicious unofficial clients and attachments. Although format checks will not stop every attack, this layer of defense helps mitigate many of them.&lt;/p&gt;
    &lt;p&gt;Each month, these libraries are distributed to billions of phones, laptops, desktops, watches, and browsers running on multiple operating systems for people on WhatsApp, Messenger, and Instagram. This is the largest ever deployment of Rust code to a diverse set of end-user platforms and products that we are aware of. Our experience speaks to the production-readiness and unique value proposition of Rust on the client-side.&lt;/p&gt;
    &lt;head rend="h2"&gt;How Rust Fits In To WhatsApp‚Äôs Approach to App Security&lt;/head&gt;
    &lt;p&gt;This is just one example of WhatsApp‚Äôs many investments in security. It‚Äôs why we built default end-to-end encryption for personal messages and calls, offer end-to-end encrypted backups, and use key transparency technology to verify a secure connection, provide additional calling protections, and more.&lt;/p&gt;
    &lt;p&gt;WhatsApp has a strong track record of being loud when we find issues and working to hold bad actors accountable. For example, WhatsApp reports CVEs for important issues we find in our applications, even if we do not find evidence of exploitation. We do this to give people on WhatsApp the best chance of protecting themselves by seeing a security advisory and updating quickly.&lt;/p&gt;
    &lt;p&gt;To ensure application security, we first must identify and quantify the sources of risk. We do this through internal and external audits like NCC Group‚Äôs public assessment of WhatsApp‚Äôs end-to-end encrypted backups, fuzzing, static analysis, supply chain management, and automated attack surface analysis. We also recently expanded our Bug Bounty program to introduce the WhatsApp Research Proxy ‚Äì a tool that makes research into WhatsApp‚Äôs network protocol more effective.&lt;/p&gt;
    &lt;p&gt;Next, we reduce the identified risk. Like many others in the industry, we found that the majority of the high severity vulnerabilities we published were due to memory safety issues in code written in the C and C++ programming languages. To combat this we invest in three parallel strategies:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Design the product to minimize unnecessary attack surface exposure.&lt;/item&gt;
      &lt;item&gt;Invest in security assurance for the remaining C and C++ code.&lt;/item&gt;
      &lt;item&gt;Default the choice of memory safe languages, and not C and C++, for new code.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;WhatsApp has added protections like CFI, hardened memory allocators, safer buffer handling APIs, and more. C and C++ developers have specialized security training, development guidelines, and automated security analysis on their changes. We also have strict SLAs for fixing issues uncovered by the risk identification process.&lt;/p&gt;
    &lt;head rend="h2"&gt;Accelerating Rust Adoption to Enhance Security&lt;/head&gt;
    &lt;p&gt;Rust enabled WhatsApp‚Äôs security team to develop a secure, high performance, cross-platform library to ensure media shared on the platform is consistent and safe across devices. This is an important step forward in adding additional security behind the scenes for users and part of our ongoing defense-in-depth approach. Security teams at WhatsApp and Meta are highlighting opportunities for high impact adoption of Rust to interested teams, and we anticipate accelerating adoption of Rust over the coming years.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46791742</guid><pubDate>Wed, 28 Jan 2026 06:21:07 +0000</pubDate></item><item><title>Virtual Boy on TV with Intelligent Systems Video Boy</title><link>https://hcs64.com/video-boy-vue/</link><description>&lt;doc fingerprint="2d351f13193782d2"&gt;
  &lt;main&gt;
    &lt;p&gt;The Video Boy plays Nintendo Virtual Boy games on a TV or monitor. As with many of Nintendo's development tools, it was made by Intelligent Systems. These were used to record video or screenshots; it's said that this particular unit was used by the venerable Nintendo Power.&lt;/p&gt;
    &lt;p&gt;Contents:&lt;/p&gt;
    &lt;p&gt;The Virtual Boy inputs are on the top and front of the unit. From left to right: cartridge slot, link cable port, and controller port. There's also a red power LED. A cartridge goes in with the label facing down; it plugs directly into a Virtual Boy main board.&lt;/p&gt;
    &lt;p&gt;Note that the name shown here is "Video Adapter VUE". "Video Boy" appears nowhere on this device, but it is found in the instructions as "VIDEO-BOY (VUE)" and on the Intelligent Systems site as √£√£√£¬™√£√£¬º√£¬§ or videoboy.html.&lt;/p&gt;
    &lt;p&gt;The AV multi-out is PAL, which is 50 FPS like the Virtual Boy; this avoids a more complicated and lossy scan conversion to ~60 FPS NTSC.&lt;/p&gt;
    &lt;p&gt;The unit came with a DB9 to 3xRCA cable for the RGB OUT; I haven't tested it, lacking a monitor that takes raw RGB. The SCANNER port connects to a development headset; I don't have one.&lt;/p&gt;
    &lt;p&gt;This row of switches, SW1, is exposed on the bottom of the unit. The initial setting was: 1 off, 2 on, 3 on, 4 on, 5 off, 6 off, 7 off, 8 on.&lt;/p&gt;
    &lt;p&gt;7 and 8 control which display is shown: 8 controls the left, rendered in Virtual Boy red, 7 is the right, rendered in green. With both 7 and 8 on, left and right are combined, this was intended as anaglyph 3D. See the video output below.&lt;/p&gt;
    &lt;p&gt;Switching 5 on prevents anything from working. I didn't notice any effect from switching the others.&lt;/p&gt;
    &lt;p&gt;There's an image of the instructions which describes the switches, unfortunately it's low resolution. I think it says "don't use" for 5 and 6, and 1-4 are for setting some integer, "1=MSB, 4=LSB, ON=0, OFF=1".&lt;/p&gt;
    &lt;p&gt;There are nearby unpopulated jumper pads, and a set of pads marked "CL" which seem to be cut traces. This may have been hardwired when the switch wasn't installed.&lt;/p&gt;
    &lt;p&gt;The top label says "√£√£√£¬∏√£¬ß√• 12√•¬∑", approximately "Project No. 12".&lt;/p&gt;
    &lt;p&gt;The bottom label says "VUE TV MONITOR", identifying the board inside. "Ver. C" indicates the third or fourth version, and "+√¶¬π√© " is "plus retrofit", perhaps indicating the various jumper wire patches. "MAI-VUE-X8" identifies the internal Virtual Boy main board.&lt;/p&gt;
    &lt;p&gt;The monitor board (left) has a Virtual Boy main board mounted on top of it (center top between the metal braces). The right side of the case is taken up by the power supply.&lt;/p&gt;
    &lt;p&gt;The Virtual Boy generates an image by sweeping a column of light horizontally. To convert this to the rows of a PAL TV signal, at least one frame must be buffered and rotated; the monitor board performs this conversion.&lt;/p&gt;
    &lt;p&gt;Note that the monitor board has unpopulated connector pads on the left (CN1, label not visible) and lower right (CN2). I think this same board can be configured to go into a VUE-DEBUGGER development unit (see PAL monitor), CN1 would be where it plugs into the debugger bus.&lt;/p&gt;
    &lt;p&gt;The main board is the heart of a Virtual Boy. This seems to be an early or development board, MAI-VUE-X8, (c) 1994. (A production board is VUE-MAI-01, (c) 1995.)&lt;/p&gt;
    &lt;p&gt;For info on Virtual Boy hardware:&lt;/p&gt;
    &lt;p&gt;Under the MAI-VUE-X8 board there are a few stray ICs and the ribbon cables that carry video to the monitor board (left and right). The board name was hiding under here: "VUE TV MONITOR(C)", which matches "Ver. C" on the label.&lt;/p&gt;
    &lt;p&gt;The workhorses are these two big Xilinx XC3064-70 FPGAs, which get their configuration from the 1765DPC PROMs between them. Perhaps one stores input while the other scans output.&lt;/p&gt;
    &lt;p&gt;The big NEC chip on the left (D27C1024A-15) is a 1Mbit EPROM, with an Intelligent Systems metal sticker to prevent UV erasure. I guess that at least one of the FPGAs is configured as a DSP, running a program from the EPROM.&lt;/p&gt;
    &lt;p&gt;There are eight 32KB SRAMs across the board, numbered in two groups: U12 &amp;amp; U13 (64KB), and U17-U22 (192KB). The 64KB might be DSP work RAM. 192KB would exactly fit two 384x256 frames with 8 bits per pixel (384x256 is the size of the Virtual Boy framebuffer, though only the top 224 rows are used). Virtual Boy graphics are only 2 bits per pixel, but each of the three non-black brightness levels can be configured by an independent 8 bit register, so 8 bits per pixel is plausible. This could be a double buffer (one taking input while the other scans output), or it could be one buffer per eye, or a double buffer for each eye at only 4 bits per pixel.&lt;/p&gt;
    &lt;p&gt;The oscillator Y1 (left, below the EPROM) seems to be associated with a VCLK test point, probably Video Clock; it's labeled D177J4, which suggests the 17.734475 MHz PAL color subcarrier. There's an unpopulated space for a second oscillator, Y2, and support components; it's grouped with the SCLK test point, maybe the Servo Clock. This may have be used when the board was configured to plug into the VUE-DEBUGGER.&lt;/p&gt;
    &lt;p&gt;Output is produced here by two MB40778 8-bit DACs (bottom center), an S-RGB video encoder (center right), and numerous discrete components. On the left are the output connectors: CN10 at top is RGB, CN8 at bottom is AV multi-out. I guess that each DAC handles one channel, connected to the red and green inputs of the S-RGB.&lt;/p&gt;
    &lt;p&gt;There are three jumpers on the bottom, and one that goes to (and through) the Virtual Boy board, strategically glued. Version C might have still needed a few fixes, or maybe these are used to retrofit a particular MAI-VUE board, or they could be specific to the standalone Video Boy configuration.&lt;/p&gt;
    &lt;p&gt;These images of Virtual Boy Wario Land come through an Elgato dongle, deinterlaced with ffmpeg filter yadif=send_field.&lt;/p&gt;
    &lt;p&gt;The composite video output is a bit blurry. DIP switches 7 and 8 control how the two Virtual Boy displays are combined: 8 enables the left display in red, 7 the right in green, and they can be combined (center).&lt;/p&gt;
    &lt;p&gt;Here's the stereo effect in action, note how the colors separate on the backswing.&lt;/p&gt;
    &lt;p&gt;S-Video has nice crisp pixels, thanks to a higher luma resolution than composite. The Elgato isn't picking up chroma for some reason; this may be a flaw in the multi-out to S-Video cable I'm using, or the VUE Monitor may not output a color PAL S-Video signal. I use the brighter "green" output on the right when I occasionally stream Virtual Boy games.&lt;/p&gt;
    &lt;p&gt;Intelligent Systems had a √Ø¬º¬∂√Ø¬º¬µ√Ø¬º¬•√Ø¬º√Ø¬º¬§√Ø¬º¬•√Ø¬º¬¢√Ø¬º¬µ√Ø¬º¬ß√Ø¬º¬ß√Ø¬º¬•√Ø¬º¬≤√£¬∑√£¬™√£¬º√£¬∫√£¬Æ√£√¶¬°√• site, with a section on the √£√£√£¬™√£√£¬º√£¬§ (Video Boy) VUE and a connection diagram.&lt;/p&gt;
    &lt;p&gt;Here's the text of the Video Boy page, based on Google Translate:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Simply connect a TV monitor that has PAL video input or RGB input to the Video Boy VUE, and a simulated stereoscopic Virtual Boy image will be displayed. By playing the Virtual Boy game cartridge on the Video Boy VUE, you can display the left-eye image and the right-eye image on the TV monitor in red and green, respectively. It is also possible to select and display an image for the left eye only or an image for the right eye only.&lt;/p&gt;
      &lt;p&gt;Since the same screen can be checked by multiple people, it is very useful during demonstrations, specification meetings, debugging, etc.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I think the PAL√§¬ª√¶¬ß√£¬¢√£√£¬ø√•¬∫√•√£√£¬º√£VUE (PAL monitor output board) was the same VUE TV Monitor board that's used in the Video Boy, configured as an expansion board for the VUE-DEBUGGER development unit. The notes on that page are similar to the Video Boy, with these two added points:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;You can record your debugging work on video. This makes it easier to reproduce and check bugs that occur only occasionally, and improves debugging efficiency.&lt;/p&gt;
      &lt;p&gt;The need for programmers to look into the scanner during development is drastically reduced, reducing the strain on the eyes of the developer and improving work efficiency.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;lettuce, a developer who had worked with the Video Boy, has a page with an image of the instructions, along with a longer post about working with the Virtual Boy.&lt;/p&gt;
    &lt;p&gt;Initially published 2021-05-14.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46792572</guid><pubDate>Wed, 28 Jan 2026 08:32:50 +0000</pubDate></item><item><title>Show HN: The HN Arcade</title><link>https://andrewgy8.github.io/hnarcade/</link><description>&lt;doc fingerprint="35d1c25da4e5eef"&gt;
  &lt;main&gt;
    &lt;p&gt;Skip to main content HN Arcade Games Tags How It Works GitHub HN Arcade Discover games from Hacker News Browse Games Submit a Game&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46793693</guid><pubDate>Wed, 28 Jan 2026 10:50:32 +0000</pubDate></item><item><title>Kyber (YC W23) Is Hiring a Staff Engineer</title><link>https://www.ycombinator.com/companies/kyber/jobs/GPJkv5v-staff-engineer-tech-lead</link><description>&lt;doc fingerprint="f15442ba0e572026"&gt;
  &lt;main&gt;
    &lt;p&gt;Instantly draft, review, and send complex regulatory notices.&lt;/p&gt;
    &lt;p&gt;At Kyber, we're building the next-generation document platform for enterprises. Today, our AI-native solution transforms regulatory document workflows, enabling insurance claims organizations to consolidate 80% of their templates, spend 65% less time drafting, and compress overall communication cycle times by 5x. Our vision is for every enterprise to seamlessly leverage AI templates to generate every document.&lt;/p&gt;
    &lt;p&gt;Over the past 18 months, we‚Äôve:&lt;/p&gt;
    &lt;p&gt;Kyber is backed by top Silicon Valley VCs, including Y Combinator and Fellows Fund.&lt;/p&gt;
    &lt;p&gt;We're seeking a Staff Engineer with a clear line of sight to CTO. This role is ideal for someone who is already operating as a 10x engineer, thrives in early stage environments, and is excited to design and scale mission-critical AI systems from first principles.&lt;/p&gt;
    &lt;p&gt;Responsibilities:&lt;/p&gt;
    &lt;p&gt;What We‚Äôre Looking For in You:&lt;/p&gt;
    &lt;p&gt;Join us in building and scaling a game-changing enterprise product powered by state-of-the-art AI. At Kyber, your contributions will directly impact how businesses handle some of their most critical workflows and customer interactions.&lt;/p&gt;
    &lt;p&gt;If you‚Äôre obsessed with building, AI, and transforming enterprise workflows, we‚Äôd love to hear from you!&lt;/p&gt;
    &lt;p&gt;We want to hear from extraordinary individuals who are ready to shape the future of enterprise documents. To stand out, ask someone you‚Äôve worked with to send your resume or LinkedIn profile, along with a brief 2-3 sentence endorsement, directly to arvind [at] askkyber.com.&lt;/p&gt;
    &lt;p&gt;Referrals matter. They help us understand the impact you‚Äôve already had and the kind of teammate you‚Äôll be. A strong referee can elevate your application, so choose someone who knows your skills and character well.&lt;/p&gt;
    &lt;p&gt;Apply today and help us bring enterprise documents into the AI-native age.&lt;/p&gt;
    &lt;p&gt;With Kyber, companies operating in regulated industries can quickly draft, review, and send complex regulatory notices. For example, when Branch Insurance's claims team has to settle a claim, instead of spending hours piecing together evidence to draft a complex notice, they can simply upload the details of the claim to Kyber, auto-generate multiple best in-class drafts, easily assign reviewers, collaborate on notices in real-time, and then send the letter to the individual the notice is for. Kyber not only saves these teams time, it also improves overall quality, accountability, and traceability.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46794231</guid><pubDate>Wed, 28 Jan 2026 12:00:08 +0000</pubDate></item><item><title>Show HN: SHDL ‚Äì A minimal hardware description language built from logic gates</title><link>https://github.com/rafa-rrayes/SHDL</link><description>&lt;doc fingerprint="1819c58a0a77a90"&gt;
  &lt;main&gt;
    &lt;p&gt;A lightweight hardware description language and Python driver for digital circuit simulation using exclusively logic gates! SHDL provides an intuitive syntax for defining digital circuits and a clean Python API for interacting with them (PySHDL).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üöÄ Simple Syntax - Easy-to-learn hardware description language&lt;/item&gt;
      &lt;item&gt;üêç Python Integration - Seamless Python API for circuit simulation&lt;/item&gt;
      &lt;item&gt;‚ö° C Backend - Compiles to optimized C code for fast simulation and portability&lt;/item&gt;
      &lt;item&gt;üîß Command Line Tools - Built-in compiler and utilities&lt;/item&gt;
      &lt;item&gt;üì¶ Component Reuse - Import and compose reusable circuit components&lt;/item&gt;
      &lt;item&gt;üî¢ Constants Support - Use named constants for parameterizable designs&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We recommend using &lt;code&gt;uv&lt;/code&gt; for using PySHDL. If you don't have it installed, you can install it via pip:&lt;/p&gt;
    &lt;code&gt;pip install PySHDL&lt;/code&gt;
    &lt;p&gt;Create a file &lt;code&gt;fullAdder.shdl&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;component FullAdder(A, B, Cin) -&amp;gt; (Sum, Cout) {

    x1: XOR; a1: AND;
    x2: XOR; a2: AND;
    o1: OR;

    connect {
        A -&amp;gt; x1.A; B -&amp;gt; x1.B;
        A -&amp;gt; a1.A; B -&amp;gt; a1.B;

        x1.O -&amp;gt; x2.A; Cin -&amp;gt; x2.B;
        x1.O -&amp;gt; a2.A; Cin -&amp;gt; a2.B;
        a1.O -&amp;gt; o1.A; a2.O -&amp;gt; o1.B;

        x2.O -&amp;gt; Sum; o1.O -&amp;gt; Cout;
    }
}
&lt;/code&gt;
    &lt;code&gt;from SHDL import Circuit

# Load and compile the circuit
with Circuit("fullAdder.shdl") as c:
    # Set input values
    c.poke("A", 1)
    c.poke("B", 1)
    c.poke("Cin", 1)
    # Run simulation
    c.step(10)
    # Read output
    result = c.peek("Sum")
print(f"Result: {result}")  # Output: Result: 60&lt;/code&gt;
    &lt;code&gt;# Compile SHDL to C
shdlc adder.shdl -o adder.c

# Compile and build executable
shdlc adder.shdl --optimize 3&lt;/code&gt;
    &lt;code&gt;shdlc [options] &amp;lt;input.shdl&amp;gt;

Options:
  -o, --output FILE       Output C file (default: &amp;lt;input&amp;gt;.c)
  -I, --include DIR       Add directory to component search path
  -c, --compile-only      Generate C code only, do not compile to binary
  -O, --optimize LEVEL    GCC optimization level 0-3 (default: 3)
&lt;/code&gt;
    &lt;code&gt;Circuit(shdl_file, search_paths=None)&lt;/code&gt;
    &lt;p&gt;Create a new circuit instance from a SHDL file.&lt;/p&gt;
    &lt;p&gt;Methods:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;poke(port_name, value)&lt;/code&gt;- Set an input port value&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;peek(port_name)&lt;/code&gt;- Read an output port value&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;step(cycles)&lt;/code&gt;- Advance simulation by N cycles&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;reset()&lt;/code&gt;- Reset circuit to initial state&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See the &lt;code&gt;examples/&lt;/code&gt; directory for more complete examples:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;interacting.py&lt;/code&gt;- Basic circuit interaction&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;SHDL_components/&lt;/code&gt;- Reusable component library&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For comprehensive documentation, visit our Documentation Site.&lt;/p&gt;
    &lt;p&gt;GitHub repository: rafa-rrayes/SHDL&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Python &amp;gt;= 3.10&lt;/item&gt;
      &lt;item&gt;GCC or compatible C compiler (for circuit compilation)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;SHDL is still early-stage, and real-world feedback is incredibly valuable. If you try the library‚Äîwhether for a small experiment, a class assignment, or a personal project‚ÄîI would love to hear how it went.&lt;/p&gt;
    &lt;p&gt;Please consider sharing: ‚Ä¢ What worked well ‚Ä¢ What felt confusing or missing ‚Ä¢ Any bugs you hit ‚Ä¢ Feature ideas ‚Ä¢ Example circuits you built&lt;/p&gt;
    &lt;p&gt;You can give feedback in any of the following ways: ‚Ä¢ Open an Issue: üëâ https://github.com/rafa-rrayes/SHDL/issues ‚Ä¢ Start a Discussion: üëâ https://github.com/rafa-rrayes/SHDL/discussions ‚Ä¢ Submit a Pull Request: Improvements, examples, docs, and tests are all welcome. ‚Ä¢ Send me a message! üëâ rafa@rayes.com.br is my email.&lt;/p&gt;
    &lt;p&gt;Even a short comment like ‚ÄúTried it ‚Äî worked for me‚Äù helps guide development. Thank you for trying SHDL!&lt;/p&gt;
    &lt;p&gt;Rafa Rayes&lt;lb/&gt; Email: rafa@rayes.com.br GitHub: rafa-rrayes&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46794281</guid><pubDate>Wed, 28 Jan 2026 12:06:18 +0000</pubDate></item><item><title>Show HN: I built a small browser engine from scratch in C++</title><link>https://github.com/beginner-jhj/mini_browser</link><description>&lt;doc fingerprint="7c05a3807cd2fad"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Built a small browser engine in C++ to understand how browsers render HTML to the screen.&lt;/item&gt;
      &lt;item&gt;Implemented core structures: HTML/CSS parsing, layout calculation, and rendering from scratch.&lt;/item&gt;
      &lt;item&gt;This is a learning-focused project, not a production browser.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Hello, I'm a korean high school senior (Grade 12) planning to major in Computer Science.&lt;/p&gt;
    &lt;p&gt;I wanted to understand not just how to use technology, but how it works internally. I've built several websites with HTML, CSS, and JavaScript, but I never really understood how the browser executing this code actually works.&lt;/p&gt;
    &lt;p&gt;"How does a browser render HTML to the screen?"&lt;/p&gt;
    &lt;p&gt;To answer this question, I spent about 8 weeks building a browser engine from scratch.&lt;/p&gt;
    &lt;p&gt;C++ was entirely new to me, and I struggled with countless bugs, but I eventually completed a small browser that can parse HTML, apply CSS, and render images. While not perfect, it was sufficient to understand the core principles of how browsers work.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Key Features&lt;/item&gt;
      &lt;item&gt;Tech Stack&lt;/item&gt;
      &lt;item&gt;Build &amp;amp; Run&lt;/item&gt;
      &lt;item&gt;Architecture&lt;/item&gt;
      &lt;item&gt;Project Structure&lt;/item&gt;
      &lt;item&gt;Supported CSS Properties&lt;/item&gt;
      &lt;item&gt;Challenges &amp;amp; Solutions&lt;/item&gt;
      &lt;item&gt;What I Learned&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This browser supports the following features:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;HTML Parsing: Tokenization, DOM tree construction, automatic error correction&lt;/item&gt;
      &lt;item&gt;CSS Rendering: Selector matching, style inheritance, Cascade application&lt;/item&gt;
      &lt;item&gt;Layout: Block/Inline layouts, Position property support&lt;/item&gt;
      &lt;item&gt;Images: Local/network/Data URL support, asynchronous loading, caching&lt;/item&gt;
      &lt;item&gt;Navigation: Link clicking, event bubbling, history (back/forward)&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;Details&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Language&lt;/cell&gt;
        &lt;cell&gt;C++17&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;GUI Framework&lt;/cell&gt;
        &lt;cell&gt;Qt6 (Core, Gui, Network)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Build System&lt;/cell&gt;
        &lt;cell&gt;CMake 3.16+&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Rendering&lt;/cell&gt;
        &lt;cell&gt;Qt Graphics View Framework&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;macOS, Linux, or Windows (MSVC support)&lt;/item&gt;
      &lt;item&gt;CMake 3.16+&lt;/item&gt;
      &lt;item&gt;Qt6 installed (development libraries)&lt;/item&gt;
      &lt;item&gt;C++17-compatible compiler&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Install Qt6 on macOS (using Homebrew):&lt;/p&gt;
    &lt;code&gt;brew install qt6&lt;/code&gt;
    &lt;p&gt;Linux (Ubuntu/Debian):&lt;/p&gt;
    &lt;code&gt;sudo apt-get install qt6-base-dev cmake build-essential&lt;/code&gt;
    &lt;code&gt;# 1. Navigate to project directory
cd /path/to/small_browser

# 2. Create and enter build directory
mkdir -p build &amp;amp;&amp;amp; cd build

# 3. Configure with CMake
cmake ..

# 4. Build
make

# After build completes, executable: ./browser&lt;/code&gt;
    &lt;code&gt;# From build directory
./browser

# Or with full path
./build/browser&lt;/code&gt;
    &lt;p&gt;The GUI window will appear. You can test rendering by opening HTML files from the test_html_files directory.&lt;/p&gt;
    &lt;code&gt;# From build directory
cd test
ctest&lt;/code&gt;
    &lt;p&gt;Real browsers follow a 5-stage pipeline to render HTML to screen:&lt;/p&gt;
    &lt;p&gt;This project implements this pipeline as follows:&lt;/p&gt;
    &lt;p&gt;Goal: Convert HTML string into tokens&lt;/p&gt;
    &lt;p&gt;The first step breaks down HTML text into small units (tokens) that the parser can understand.&lt;/p&gt;
    &lt;p&gt;Core Struct:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;TOKEN&lt;/code&gt;(include/html/token.h)&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;TOKEN_TYPE&lt;/code&gt;: START_TAG, END_TAG, TEXT&lt;/item&gt;&lt;item&gt;&lt;code&gt;value&lt;/code&gt;: tag name or text content&lt;/item&gt;&lt;item&gt;&lt;code&gt;attributes&lt;/code&gt;: tag attributes (key-value map)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Implementation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;HTML_TOKENIZER&lt;/code&gt;(include/html/html_tokenizer.h, src/html/html_tokenizer.cpp)&lt;list rend="ul"&gt;&lt;item&gt;Role: Parse HTML string and convert to TOKEN vector&lt;/item&gt;&lt;item&gt;Key method: &lt;code&gt;tokenize()&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;Input: &amp;lt;div class="container"&amp;gt;Hello&amp;lt;/div&amp;gt;
Output: 
  - TOKEN{START_TAG, "div", {"class": "container"}}
  - TOKEN{TEXT, "Hello"}
  - TOKEN{END_TAG, "div"}
&lt;/code&gt;
    &lt;p&gt;Goal: Create DOM tree from tokens&lt;/p&gt;
    &lt;p&gt;Organize tokens into a hierarchical tree structure (DOM Tree).&lt;/p&gt;
    &lt;p&gt;Core Classes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;NODE&lt;/code&gt;(include/html/node.h, src/html/node.cpp)&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;NODE_TYPE&lt;/code&gt;: ELEMENT, TEXT&lt;/item&gt;&lt;item&gt;Properties: &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;m_tag_name&lt;/code&gt;: element's tag name (e.g., "div", "p")&lt;/item&gt;&lt;item&gt;&lt;code&gt;m_text&lt;/code&gt;: text node content&lt;/item&gt;&lt;item&gt;&lt;code&gt;m_children&lt;/code&gt;: child nodes&lt;/item&gt;&lt;item&gt;&lt;code&gt;m_attributes&lt;/code&gt;: attribute map (id, class, src, etc.)&lt;/item&gt;&lt;item&gt;&lt;code&gt;m_parent&lt;/code&gt;: parent node&lt;/item&gt;&lt;item&gt;&lt;code&gt;m_computed_style&lt;/code&gt;: calculated style information&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;HTML_PARSER&lt;/code&gt;(include/html/html_parser.h, src/html/html_parser.cpp)&lt;list rend="ul"&gt;&lt;item&gt;Role: Parse token stream and build DOM tree&lt;/item&gt;&lt;item&gt;Key method: &lt;code&gt;parse()&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Memory Structure:&lt;/p&gt;
    &lt;code&gt;root NODE
‚îú‚îÄ‚îÄ NODE (tag: html)
‚îÇ   ‚îú‚îÄ‚îÄ NODE (tag: head)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ NODE (tag: title)
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ NODE (text: "My Page")
‚îÇ   ‚îî‚îÄ‚îÄ NODE (tag: body)
‚îÇ       ‚îú‚îÄ‚îÄ NODE (tag: div, attributes: {class: "container"})
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ NODE (text: "Hello World")
‚îÇ       ‚îî‚îÄ‚îÄ NODE (tag: img, attributes: {src: "image.png"})
&lt;/code&gt;
    &lt;p&gt;Goal: Parse CSS rules and apply styles to each node&lt;/p&gt;
    &lt;p&gt;Parse CSS file to extract style rules, then calculate final styles for each DOM node following CSS Cascade rules.&lt;/p&gt;
    &lt;p&gt;Core Structures/Classes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;CSS_RULE&lt;/code&gt;(include/css/css_rule.h)&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;selector&lt;/code&gt;: CSS selector (e.g., ".container", "#redBtn")&lt;/item&gt;&lt;item&gt;&lt;code&gt;properties&lt;/code&gt;: style properties (color, font-size, width, etc.)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;COMPUTED_STYLE&lt;/code&gt;(include/css/computed_style.h)&lt;list rend="ul"&gt;&lt;item&gt;Final style applied to each node&lt;/item&gt;&lt;item&gt;Property examples: &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;color&lt;/code&gt;: text color&lt;/item&gt;&lt;item&gt;&lt;code&gt;font_size&lt;/code&gt;: font size&lt;/item&gt;&lt;item&gt;&lt;code&gt;font_weight&lt;/code&gt;: font weight&lt;/item&gt;&lt;item&gt;&lt;code&gt;display&lt;/code&gt;: BLOCK, INLINE, NONE&lt;/item&gt;&lt;item&gt;&lt;code&gt;margin_top/bottom/left/right&lt;/code&gt;: margin values&lt;/item&gt;&lt;item&gt;&lt;code&gt;padding_top/bottom/left/right&lt;/code&gt;: padding values&lt;/item&gt;&lt;item&gt;&lt;code&gt;background_color&lt;/code&gt;: background color&lt;/item&gt;&lt;item&gt;&lt;code&gt;position&lt;/code&gt;: Static, Relative, Absolute, Fixed&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;CSS_PARSER&lt;/code&gt;(include/css/css_parser.h, src/css/css_parser.cpp)&lt;list rend="ul"&gt;&lt;item&gt;CSS rule parsing&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;CSSOM&lt;/code&gt;(include/css/cssom.h, src/css/cssom.cpp)&lt;list rend="ul"&gt;&lt;item&gt;CSS Object Model management&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;apply_style()&lt;/code&gt;(include/css/apply_style.h, src/css/apply_style.cpp)&lt;list rend="ul"&gt;&lt;item&gt;Apply CSS rules to DOM nodes&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Style Calculation Process:&lt;/p&gt;
    &lt;code&gt;1. Parse CSS rules ‚Üí store as CSS_RULE
2. For each NODE:
   - Find matching selectors
   - Calculate specificity (I simplified this)
   - Apply Cascade rules
   - Create COMPUTED_STYLE
&lt;/code&gt;
    &lt;p&gt;Goal: Calculate position and size of each element&lt;/p&gt;
    &lt;p&gt;Based on styled nodes, calculate each element's position (x, y) and dimensions (width, height) on screen.&lt;/p&gt;
    &lt;p&gt;Core Structs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;LAYOUT_BOX&lt;/code&gt;(include/css/layout_tree.h)&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;node&lt;/code&gt;: corresponding DOM node&lt;/item&gt;&lt;item&gt;&lt;code&gt;style&lt;/code&gt;: applied COMPUTED_STYLE&lt;/item&gt;&lt;item&gt;&lt;code&gt;x, y&lt;/code&gt;: position&lt;/item&gt;&lt;item&gt;&lt;code&gt;width, height&lt;/code&gt;: dimensions&lt;/item&gt;&lt;item&gt;&lt;code&gt;children&lt;/code&gt;: child LAYOUT_BOX elements&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;LINE_STATE&lt;/code&gt;(include/css/layout_tree.h)&lt;list rend="ul"&gt;&lt;item&gt;Track current state during inline layout calculation&lt;/item&gt;&lt;item&gt;&lt;code&gt;current_x, current_y&lt;/code&gt;: current position&lt;/item&gt;&lt;item&gt;&lt;code&gt;line_height&lt;/code&gt;: current line height&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Helper Functions (include/css/layout_tree.h, src/css/layout_tree.cpp)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Role: Generate LAYOUT_BOX tree from DOM nodes&lt;/item&gt;
      &lt;item&gt;Key functions: &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;layout_block_element()&lt;/code&gt;: calculate block layout&lt;/item&gt;&lt;item&gt;&lt;code&gt;layout_inline_element()&lt;/code&gt;: calculate inline layout&lt;/item&gt;&lt;item&gt;&lt;code&gt;layout_text_element()&lt;/code&gt;: calculate text node size&lt;/item&gt;&lt;item&gt;&lt;code&gt;layout_image_element()&lt;/code&gt;: calculate image element layout&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Layout Algorithm:&lt;/p&gt;
    &lt;code&gt;BLOCK elements:
  - Use full width
  - Children arranged vertically
  
INLINE elements:
  - Arranged horizontally
  - Flow like text
  
Margin/Padding handling:
  - total_width = margin_left + border + padding + content + padding + border + margin_right
&lt;/code&gt;
    &lt;p&gt;Goal: Draw calculated layout on screen&lt;/p&gt;
    &lt;p&gt;Traverse LAYOUT_BOX tree and render each element graphically.&lt;/p&gt;
    &lt;p&gt;Core Classes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;Renderer&lt;/code&gt;(include/gui/renderer.h, src/gui/renderer.cpp)&lt;list rend="ul"&gt;&lt;item&gt;Role: Draw layout boxes to Qt Graphics&lt;/item&gt;&lt;item&gt;Key methods: &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;paint_layout()&lt;/code&gt;: render entire layout box tree&lt;/item&gt;&lt;item&gt;&lt;code&gt;draw_element_box()&lt;/code&gt;: draw element box (background, border)&lt;/item&gt;&lt;item&gt;&lt;code&gt;draw_text_node()&lt;/code&gt;: render text&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Uses Qt's &lt;code&gt;QPainter&lt;/code&gt;to draw on screen&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Rendering Order:&lt;/p&gt;
    &lt;code&gt;1. Fill background color
2. Draw borders
3. Handle padding area
4. Render text
5. Render images (using cached images)
6. Traverse child elements
&lt;/code&gt;
    &lt;code&gt;HTML String
    ‚Üì
[HTML_TOKENIZER] - Tokenization
    ‚Üì TOKEN vector
[HTML_PARSER] - DOM Construction
    ‚Üì NODE tree
[CSS_PARSER + CSSOM + apply_style()] - Style Calculation
    ‚Üì NODE + COMPUTED_STYLE
[Helper Functions] - Layout
    ‚Üì LAYOUT_BOX tree
[RENDERER] - Painting
    ‚Üì
Screen Output
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;IMAGE_CACHE_MANAGER (include/gui/image_cache_manager.h)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Cache downloaded images to prevent duplicate loads&lt;/item&gt;
          &lt;item&gt;Store QPixmap&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;MAIN_WINDOW (include/gui/main_window.h, src/gui/main_window.cpp)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Qt main window&lt;/item&gt;
          &lt;item&gt;Provide user interface&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;include/
  ‚îú‚îÄ‚îÄ html/           # HTML parsing (token.h, node.h, html_tokenizer.h, html_parser.h)
  ‚îú‚îÄ‚îÄ css/            # CSS parsing &amp;amp; layout (computed_style.h, css_parser.h, layout_tree.h, etc.)
  ‚îî‚îÄ‚îÄ gui/            # Rendering &amp;amp; UI (renderer.h, main_window.h, etc.)

src/
  ‚îú‚îÄ‚îÄ html/           # HTML parsing implementation
  ‚îú‚îÄ‚îÄ css/            # CSS &amp;amp; layout implementation
  ‚îî‚îÄ‚îÄ gui/            # Rendering implementation
&lt;/code&gt;
    &lt;p&gt;This browser supports the following CSS properties. All property parsing is defined in the &lt;code&gt;COMPUTED_STYLE&lt;/code&gt; struct in include/css/computed_style.h, with implementation in src/css/computed_style.cpp.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Property&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Possible Values&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;color&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Text color&lt;/cell&gt;
        &lt;cell&gt;Color name, hex (#RRGGBB)&lt;/cell&gt;
        &lt;cell&gt;black&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;font-size&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Font size&lt;/cell&gt;
        &lt;cell&gt;Number + px (e.g., 16px)&lt;/cell&gt;
        &lt;cell&gt;16px&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;font-weight&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Font weight&lt;/cell&gt;
        &lt;cell&gt;normal, bold, 100-900&lt;/cell&gt;
        &lt;cell&gt;normal&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;font-style&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Font style&lt;/cell&gt;
        &lt;cell&gt;normal, italic&lt;/cell&gt;
        &lt;cell&gt;normal&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;font-family&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Font name&lt;/cell&gt;
        &lt;cell&gt;Font name&lt;/cell&gt;
        &lt;cell&gt;Arial&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;line-height&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Line height&lt;/cell&gt;
        &lt;cell&gt;Number (multiplier)&lt;/cell&gt;
        &lt;cell&gt;font-size * 1.5&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Property&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Possible Values&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;background-color&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Background color&lt;/cell&gt;
        &lt;cell&gt;Color name, hex (#RRGGBB)&lt;/cell&gt;
        &lt;cell&gt;transparent&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Property&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Possible Values&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;width&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Element width&lt;/cell&gt;
        &lt;cell&gt;Number + px, auto&lt;/cell&gt;
        &lt;cell&gt;auto (-1)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;height&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Element height&lt;/cell&gt;
        &lt;cell&gt;Number + px, auto&lt;/cell&gt;
        &lt;cell&gt;auto (-1)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;box-sizing&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Box sizing method&lt;/cell&gt;
        &lt;cell&gt;content-box, border-box&lt;/cell&gt;
        &lt;cell&gt;content-box&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Property&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Possible Values&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;margin-top&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Top margin&lt;/cell&gt;
        &lt;cell&gt;Number + px&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;margin-right&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Right margin&lt;/cell&gt;
        &lt;cell&gt;Number + px&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;margin-bottom&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Bottom margin&lt;/cell&gt;
        &lt;cell&gt;Number + px&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;margin-left&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Left margin&lt;/cell&gt;
        &lt;cell&gt;Number + px&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;margin&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Margin shorthand&lt;/cell&gt;
        &lt;cell&gt;1-4 values&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;padding-top&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Top padding&lt;/cell&gt;
        &lt;cell&gt;Number + px&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;padding-right&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Right padding&lt;/cell&gt;
        &lt;cell&gt;Number + px&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;padding-bottom&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Bottom padding&lt;/cell&gt;
        &lt;cell&gt;Number + px&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;padding-left&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Left padding&lt;/cell&gt;
        &lt;cell&gt;Number + px&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;padding&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Padding shorthand&lt;/cell&gt;
        &lt;cell&gt;1-4 values&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Shorthand Examples:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;margin: 10px;&lt;/code&gt;‚Üí 10px on all sides&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;margin: 10px 20px;&lt;/code&gt;‚Üí 10px top/bottom, 20px left/right&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;margin: 10px 20px 30px;&lt;/code&gt;‚Üí 10px top, 20px left/right, 30px bottom&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;margin: 10px 20px 30px 40px;&lt;/code&gt;‚Üí 10px top, 20px right, 30px bottom, 40px left&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Property&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Possible Values&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;border-width&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Border width&lt;/cell&gt;
        &lt;cell&gt;Number + px&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;border-color&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Border color&lt;/cell&gt;
        &lt;cell&gt;Color name, hex (#RRGGBB)&lt;/cell&gt;
        &lt;cell&gt;black&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;border-style&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Border style&lt;/cell&gt;
        &lt;cell&gt;solid, dashed, dotted, etc.&lt;/cell&gt;
        &lt;cell&gt;solid&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;border&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Border shorthand&lt;/cell&gt;
        &lt;cell&gt;width color style&lt;/cell&gt;
        &lt;cell&gt;0 black solid&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Property&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Possible Values&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;display&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Display type&lt;/cell&gt;
        &lt;cell&gt;block, inline, none&lt;/cell&gt;
        &lt;cell&gt;inline&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;position&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Position type&lt;/cell&gt;
        &lt;cell&gt;static, relative, absolute, fixed&lt;/cell&gt;
        &lt;cell&gt;static&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;top&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Top position (relative, absolute, fixed)&lt;/cell&gt;
        &lt;cell&gt;Number + px&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;right&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Right position (relative, absolute, fixed)&lt;/cell&gt;
        &lt;cell&gt;Number + px&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;bottom&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Bottom position (relative, absolute, fixed)&lt;/cell&gt;
        &lt;cell&gt;Number + px&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;left&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Left position (relative, absolute, fixed)&lt;/cell&gt;
        &lt;cell&gt;Number + px&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Property&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Possible Values&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;text-align&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Text alignment&lt;/cell&gt;
        &lt;cell&gt;left, center, right, justify&lt;/cell&gt;
        &lt;cell&gt;left&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;text-decoration&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Text decoration&lt;/cell&gt;
        &lt;cell&gt;none, underline, line-through, overline&lt;/cell&gt;
        &lt;cell&gt;none&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Property&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Possible Values&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;opacity&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Opacity&lt;/cell&gt;
        &lt;cell&gt;0 - 1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;visibility&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Element visibility&lt;/cell&gt;
        &lt;cell&gt;visible, hidden (true/false)&lt;/cell&gt;
        &lt;cell&gt;visible&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Property Parsing &amp;amp; Setting (src/css/computed_style.cpp):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;init_setters()&lt;/code&gt;: Register setter functions for all CSS properties&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;parse_color()&lt;/code&gt;: Parse color values (hex, named colors)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;parse_font_size()&lt;/code&gt;: Parse font size&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;parse_string_to_float()&lt;/code&gt;: Parse numeric values&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;parse_display_type()&lt;/code&gt;: Parse display values&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;parse_text_align()&lt;/code&gt;: Parse text-align values&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;parse_box_sizing()&lt;/code&gt;: Parse box-sizing values&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;parse_text_decoration()&lt;/code&gt;: Parse text-decoration values&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;parse_position_type()&lt;/code&gt;: Parse position values&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;parse_spacing_shorthand()&lt;/code&gt;: Parse margin/padding shorthand&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Style Inheritance (src/css/computed_style.cpp):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;inherit_color()&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;inherit_font_size()&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;inherit_font_weight()&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;inherit_font_style()&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;inherit_font_family()&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;inherit_line_height()&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;inherit_text_align()&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;inherit_visibility()&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;inherit_text_decoration()&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I was new to C++, and unexpected problems and bugs appeared continuously from start to finish. While some issues remain unresolved, I'll share the 3 most difficult challenges and how I overcame them.&lt;/p&gt;
    &lt;p&gt;The Challenge:&lt;/p&gt;
    &lt;p&gt;Writing parsers required managing many different states. HTML parsing needed to handle start tags, end tags, text, comments‚Äîso many cases. I had no idea how to even start.&lt;/p&gt;
    &lt;p&gt;The Solution:&lt;/p&gt;
    &lt;p&gt;I read two key articles to understand parser fundamentals:&lt;/p&gt;
    &lt;p&gt;After understanding the basic principles, I wrote a few simple parsers myself. Once comfortable with how parsers work, I could independently write the complete CSS parsing logic.&lt;/p&gt;
    &lt;p&gt;The Challenge:&lt;/p&gt;
    &lt;p&gt;Rendering required managing even more states than parsing. &lt;code&gt;LINE_STATE&lt;/code&gt;, &lt;code&gt;LAYOUT_BOX&lt;/code&gt;‚Äîcomplex state tracking. I had to implement recursion, which I wasn't familiar with. Plus, I needed to handle different element types (boxes, inline, text) separately.&lt;/p&gt;
    &lt;p&gt;The Solution:&lt;/p&gt;
    &lt;p&gt;I used Claude AI extensively to understand rendering logic and reviewed the generated code carefully. Rather than using AI code directly, I reviewed it thoroughly and asked questions to understand the underlying principles. After becoming comfortable with rendering logic, I could modify the codebase and fix bugs, which proved I truly understood it.&lt;/p&gt;
    &lt;p&gt;The Challenge:&lt;/p&gt;
    &lt;p&gt;Fetching HTTP/HTTPS images from external servers was the most complex part. I couldn't stop layout calculation while downloading images, so I needed to understand asynchronous processing. While I theoretically understood image caching and reflowing, implementation required considering so many details.&lt;/p&gt;
    &lt;p&gt;The Solution:&lt;/p&gt;
    &lt;p&gt;I invested 3-5 hours designing a solid, robust image caching/reflowing system. With proper architecture in place, implementation became much easier. Through this process, I clearly understood the difference between multithreading async and non-blocking I/O async.&lt;/p&gt;
    &lt;p&gt;Overcoming these three challenges taught me more than just technical skills‚Äîit taught me how to approach problems and the importance of design. While not perfect, this is the project's greatest value.&lt;/p&gt;
    &lt;p&gt;Through this project, I gained hands-on understanding of how real browsers work. Beyond the concept of "browsers render HTML," I now understand how tokenization, layout calculation, and final rendering stages interact. This will help me predict browser behavior and optimize performance in future web development.&lt;/p&gt;
    &lt;p&gt;But the most valuable lessons transcended this specific project:&lt;/p&gt;
    &lt;p&gt;1. Systematic Debugging&lt;/p&gt;
    &lt;p&gt;When facing endless bugs, I learned not to randomly fix code but to form hypotheses and test them. Through proper logging, I tracked program state and systematically identified where problems occurred. This debugging discipline will serve me across all programming languages.&lt;/p&gt;
    &lt;p&gt;2. Persistence &amp;amp; Grit&lt;/p&gt;
    &lt;p&gt;Many times I wanted to give up when problems remained unsolved for days. But by breaking problems into pieces and accumulating small progress, I eventually overcame them. I realized this persistence is essential for success in any field.&lt;/p&gt;
    &lt;p&gt;3. The Value of Pragmatism&lt;/p&gt;
    &lt;p&gt;Perfect software doesn't exist. This browser still lacks support for many CSS properties and HTML elements, and has various bugs. But I learned that shipping imperfect but working software beats chasing ideal perfection. This pragmatism is crucial in the real software industry.&lt;/p&gt;
    &lt;p&gt;4. The Power of "Why?"&lt;/p&gt;
    &lt;p&gt;When receiving code from AI or tutorials, I didn't just check if it worked. I constantly asked "Why does this work?", "Is this part really necessary?", "Are there alternative approaches?" This curiosity and deep exploration led to understanding principles, not just surface-level learning.&lt;/p&gt;
    &lt;p&gt;The greatest achievement of this project isn't the completed browser.&lt;/p&gt;
    &lt;p&gt;It's developing problem-solving ability.&lt;/p&gt;
    &lt;p&gt;Systematic debugging, persistent effort, "completion over perfection" pragmatism, and the habit of always asking "Why?"&lt;/p&gt;
    &lt;p&gt;These will help me tackle every problem I face ahead.&lt;/p&gt;
    &lt;p&gt;Honestly, experienced developers might complete this more elegantly,&lt;/p&gt;
    &lt;p&gt;but to a student new to C++, it seemed nearly impossible.&lt;/p&gt;
    &lt;p&gt;Yet I still took on the challenge. Why?&lt;/p&gt;
    &lt;p&gt;It was simple:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I was curious&lt;/item&gt;
      &lt;item&gt;It looked fun&lt;/item&gt;
      &lt;item&gt;I thought I could do it&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So I created a folder, opened an editor, and started coding.&lt;/p&gt;
    &lt;code&gt;mkdir mini_browser
cd mini_browser
# Let's go&lt;/code&gt;
    &lt;p&gt;There were many difficulties. 5-hour debugging sessions. 3-day unsolved bugs.&lt;/p&gt;
    &lt;p&gt;But 8 weeks later, I have a working browser.&lt;/p&gt;
    &lt;p&gt;Are you facing something that seems impossible right now?&lt;/p&gt;
    &lt;p&gt;Just start.&lt;/p&gt;
    &lt;p&gt;Imperfect is okay. Slow is okay. Stuck is okay.&lt;/p&gt;
    &lt;p&gt;Without starting, it stays impossible forever. With starting, it becomes possible.&lt;/p&gt;
    &lt;p&gt;Thank you for reading this long journey. üöÄ&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46795540</guid><pubDate>Wed, 28 Jan 2026 14:03:28 +0000</pubDate></item><item><title>When Every Network is 192.168.1.x</title><link>https://netrinos.com/blog/conflicting-subnets</link><description>&lt;doc fingerprint="77317213f833b2c8"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;The Problem&lt;/head&gt;
    &lt;p&gt;If you manage devices at multiple customer sites, you already know this problem. Every consumer router and ISP modem ships with the same default subnet. The specific range varies by manufacturer (192.168.1.0/24, 192.168.0.0/24, 10.0.0.0/24), but the result is the same: every site ends up on one of the same few subnets.&lt;/p&gt;
    &lt;p&gt;Security integrators, MSPs, AV installers, home automation companies. Anyone who deploys equipment at residential sites encounters this immediately. The NVR at one customer's home is 192.168.1.100. The NVR at the next customer's home is also on 192.168.1.x. And the one after that.&lt;/p&gt;
    &lt;p&gt;One remote site isn't a problem. Set up a VPN gateway, add a route for 192.168.1.0/24, and traffic flows to the right place. Two sites with different subnets, still fine. But the moment two sites share the same address range, you have an ambiguity that IP routing cannot resolve.&lt;/p&gt;
    &lt;p&gt;A packet destined for 192.168.1.100 has two valid destinations. The routing table accepts one entry per prefix. One site works. The other is unreachable.&lt;/p&gt;
    &lt;p&gt;At 50 or 300 sites, the problem is absurd. You can't maintain unique subnet assignments across networks you don't control. You didn't configure these routers. You don't have admin access to most of them. And re-addressing a customer's home network to avoid conflicts with your other customers isn't realistic.&lt;/p&gt;
    &lt;p&gt;There's a second problem. The devices you need to reach, cameras, NVRs, NAS units, etc., are embedded systems with fixed firmware. There's no SSH, no package manager, no way to install a WireGuard client. You need to reach them, but they can't participate in any overlay network directly.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Traditional Approaches Fail&lt;/head&gt;
    &lt;head rend="h3"&gt;Port forwarding&lt;/head&gt;
    &lt;p&gt;The most common workaround. Open ports on the customer's ISP modem and map external ports to internal devices. This works until the ISP replaces or resets the modem. When that happens, the port forwarding configuration is gone. You're dispatching a technician.&lt;/p&gt;
    &lt;p&gt;Port forwarding also breaks multi-port protocols. RTSP, the protocol used by most IP cameras for video streaming, uses TCP (typically port 554) as a control channel, but delivers the actual video over RTP on separate UDP ports. These ports are dynamically negotiated during session setup, and they span a wide range. Port-forward TCP 554 and the RTSP handshake succeeds, but the RTP media arrives on UDP ports that aren't forwarded. The control session connects. The video never arrives.&lt;/p&gt;
    &lt;p&gt;And that assumes a single NAT. Many sites have a security firewall behind the ISP modem, or a cellular modem in front of it. Double or triple NAT means configuring port forwarding on two or three devices in series, any of which can be reset or replaced independently. If the ISP uses CGNAT, the outermost NAT is on the ISP's infrastructure and you have no options.&lt;/p&gt;
    &lt;head rend="h3"&gt;Subnet routing&lt;/head&gt;
    &lt;p&gt;Route all of 192.168.1.0/24 through a VPN node at the remote site. This works for exactly one site. The routing table accepts one next-hop per destination prefix. When two sites share the same range, you can route to one or the other, not both.&lt;/p&gt;
    &lt;head rend="h3"&gt;Re-addressing&lt;/head&gt;
    &lt;p&gt;Assign each customer a unique subnet so addresses don't overlap. This is the theoretically correct answer. It's also operationally impossible at scale. You don't own these networks. The customer's ISP modem manages DHCP. Their phones, laptops, and smart speakers expect the existing configuration. Re-addressing 300 customer networks and maintaining a master subnet allocation is not a real solution.&lt;/p&gt;
    &lt;head rend="h2"&gt;Overlay Addressing with 1:1 NAT&lt;/head&gt;
    &lt;p&gt;The approach that works is to stop trying to route to local addresses entirely. Instead, assign each remote device a globally unique IP in a separate address space (an overlay network) and translate between the overlay address and the local address at each site.&lt;/p&gt;
    &lt;p&gt;You place a device on the customer's LAN: a Raspberry Pi, a spare PC, any Linux box. This device connects to your mesh network via WireGuard. It also has a connection to the local network where the target devices sit.&lt;/p&gt;
    &lt;p&gt;For each device you want to reach, you assign an address from the overlay range. RFC 6598 reserves 100.64.0.0/10 for Carrier-Grade NAT, providing roughly 4 million addresses. This range is almost never used on customer LANs, so it won't collide with existing devices. And because the overlay addresses only exist inside WireGuard tunnels, they never appear as raw IP on the internet, so there's no conflict with ISPs that use CGNAT on the WAN side. Each camera, NVR, or NAS gets a unique address in this space, regardless of its local IP.&lt;/p&gt;
    &lt;p&gt;The gateway device performs 1:1 NAT. Traffic arriving for 100.97.14.3 is destination-translated to 192.168.1.100, and the source is masqueraded to the gateway's own LAN address. The local device sees a packet from a neighbor on its own subnet and responds normally. Connection tracking reverses both translations on the return path. A single gateway holds multiple overlay addresses, one per device behind it, so each camera, NVR, or panel gets its own IP and DNS name on the mesh.&lt;/p&gt;
    &lt;p&gt;The local device has no awareness of this. It receives packets from a local IP (the gateway's LAN interface) and responds normally. No software, no configuration changes, nothing installed on the endpoint.&lt;/p&gt;
    &lt;p&gt;The local IP address becomes an implementation detail. Only the NAT rule on the gateway cares that the NVR is at 192.168.1.100. Everything else on the overlay network knows it by its unique address. Site A's NVR is 100.97.14.3. Site B's NVR is 100.82.44.9. Even the monitoring station itself can be on 192.168.1.x. It doesn't matter. The conflict is gone.&lt;/p&gt;
    &lt;p&gt;The NAT itself is trivial. Anyone can write an nftables rule. The hard part is automating it across hundreds of sites: key generation, peer distribution, NAT rule management, DNS assignment, health monitoring, roaming technicians who need access from the field, all without manual intervention. Each device requires a WireGuard peer, a DNAT rule, and a DNS record. At 10 devices per site across 300 sites, that's 3,000 sets of configuration to generate, deploy, and keep in sync.&lt;/p&gt;
    &lt;head rend="h2"&gt;In Production&lt;/head&gt;
    &lt;p&gt;A security integrator managing residential camera systems operates approximately 300 customer sites with over 3,000 cameras, NVRs, etc. Every site has a standard ISP modem handing out addresses in 192.168.1.0/24.&lt;/p&gt;
    &lt;p&gt;Before: open ports on every ISP modem. Cameras, many running firmware with known vulnerabilities, exposing port 80 directly to the internet. When the ISP replaced or reset a modem, all port forwarding configuration was lost. A technician was dispatched to reconfigure it.&lt;/p&gt;
    &lt;p&gt;After: a gateway device at each site connects to the monitoring station through an encrypted WireGuard mesh. Each camera has a unique overlay address. The monitoring station accesses any camera by its overlay IP or DNS name.&lt;/p&gt;
    &lt;p&gt;The security posture changed. Cameras that were previously exposed to the internet, reachable by anyone with a port scanner, are now invisible. No open ports on customer equipment. All traffic encrypted end-to-end inside WireGuard tunnels. The attack surface went from 3,000 devices on the public internet to zero.&lt;/p&gt;
    &lt;p&gt;Operationally, truck rolls for connectivity issues stopped. The ISP can swap the modem, change the customer's public IP, or reset the device to factory defaults. The gateway reconnects automatically, and the overlay addresses don't change. Sites with dual-WAN failover just work: the gateway uses whichever uplink is available. A technician in the field connects to the mesh and accesses any camera by its DNS name, from any location, without VPN credentials per site or firewall rules to maintain.&lt;/p&gt;
    &lt;p&gt;Adding a new site means dropping a gateway on the customer's LAN. It picks up a DHCP address and calls home. Register the devices from your dashboard, and they're immediately reachable. This deployment has been running in production for over two years.&lt;/p&gt;
    &lt;head rend="h2"&gt;Clarifications&lt;/head&gt;
    &lt;p&gt;Not a full mesh. Customer gateways don't know about each other. A gateway at Site A has no awareness of Site B. Only the monitoring station and technicians assigned to the sites can reach its devices. Access control enforces this: each participant on the mesh sees only what they should. This is the correct topology for managing customer equipment, not a limitation.&lt;/p&gt;
    &lt;p&gt;NAT is still NAT. DNAT with masquerade passes all ports and protocols, so multi-port protocols like RTSP should work: the dynamically negotiated RTP ports pass through without explicit forwarding rules. Protocols that embed IP addresses in their payload (RTSP includes the device's local IP in SDP) or use IP-based authentication may need testing.&lt;/p&gt;
    &lt;p&gt;Requires a foothold device. You need a device on the remote LAN to run the VPN and NAT. At scale, a dedicated Linux device makes sense: a Raspberry Pi, a small appliance, a spare PC. But the same virtual device capability works from any Netrinos client on Windows, macOS, or Linux. Either way, if there's nothing you can control at the target site, this approach doesn't help.&lt;/p&gt;
    &lt;p&gt;Address space. The overlay uses the 100.64.0.0/10 CGNAT range (RFC 6598). This range is not for use on customer LANs, so collisions with local devices are unlikely. Overlay addresses are encapsulated inside WireGuard tunnels and never appear on the public internet, so ISP-level CGNAT will not conflict.&lt;/p&gt;
    &lt;head rend="h2"&gt;Under the Hood&lt;/head&gt;
    &lt;p&gt;Netrinos is a configuration manager built on industry-standard tools: WireGuard for tunnels, nftables on Linux, PF on macOS, WFP on Windows. These are popular, trusted, proven components. None of them can solve the conflicting subnet problem on their own. The orchestration is what makes it work, generating the right configuration across hundreds of devices and keeping it in sync.&lt;/p&gt;
    &lt;p&gt;The implementation uses three components, all generated from a single device registration.&lt;/p&gt;
    &lt;p&gt;A WireGuard peer, auto-generated for each virtual device:&lt;/p&gt;
    &lt;code&gt;[Peer]
PublicKey = &amp;lt;generated-per-device&amp;gt;
AllowedIPs = 100.97.14.3/32&lt;/code&gt;
    &lt;p&gt;A DNAT rule and masquerade (nftables on Linux):&lt;/p&gt;
    &lt;code&gt;# Translate destination to local device
ip daddr 100.97.14.3 dnat to 192.168.1.100

# Masquerade tunnel traffic going to LAN
iifname "wg0" oifname != "wg0" masquerade&lt;/code&gt;
    &lt;p&gt;A DNS record mapping a human-readable name to the overlay address:&lt;/p&gt;
    &lt;code&gt;lobby-cam.downtown.myco.2ho.ca  √¢  100.97.14.3&lt;/code&gt;
    &lt;p&gt;Register a device ("192.168.1.100 on this site's LAN, call it lobby-cam"), and all three are generated and deployed. No manual WireGuard configuration, no hand-written firewall rules, no DNS zone editing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Closing&lt;/head&gt;
    &lt;p&gt;Every service company managing devices at customer sites runs into this: the networks they need to reach all look identical. Overlay addressing with 1:1 NAT solves it. The local IP becomes an implementation detail, and the devices you need to reach get unique addresses that the rest of the network can route to without ambiguity.&lt;/p&gt;
    &lt;p&gt;The components are standard: WireGuard, nftables, DNS. The hard part is orchestrating them across hundreds of sites, keeping keys rotated, NAT rules consistent, and DNS records in sync, without manual intervention. That's the problem worth solving.&lt;/p&gt;
    &lt;p&gt;This is how Netrinos Virtual Devices work. The software runs on Windows, macOS, and Linux, with a 14-day free trial.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46795582</guid><pubDate>Wed, 28 Jan 2026 14:06:39 +0000</pubDate></item><item><title>Microsoft forced me to switch to Linux</title><link>https://www.himthe.dev/blog/microsoft-to-linux</link><description>&lt;doc fingerprint="3c17b9573b05fcde"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;From Microsoft to Microslop to Linux: Why I Made the Switch&lt;/head&gt;
    &lt;p&gt;January 26, 2026&lt;/p&gt;
    &lt;head rend="h2"&gt;What's better than a devil you don't know?&lt;lb/&gt;The devil you do.&lt;/head&gt;
    &lt;p&gt;I've used Windows for as long as I've been alive. At 6 years old, my first computer was a Windows 98 machine, with an Athlon XP 1900+ (Palomino core) and a GeForce 440 MX, blessed with a generous 256 megabytes of RAM.&lt;/p&gt;
    &lt;p&gt;Looking back, I kinda got scammed with that graphics card, but what could I do? I was a silly kid. (The missing shader support came back to bite me in the ass)&lt;/p&gt;
    &lt;p&gt;Also, is it weird that I still remember the specs of my first computer, 22 years later?&lt;/p&gt;
    &lt;p&gt;Anyway, Windows has been familiar and comfortable. I knew all the workarounds and how to extract maximum efficiency from it.&lt;/p&gt;
    &lt;p&gt;I was a happy user, for over 20 years, and Windows has been my go-to for everything computer-related.&lt;/p&gt;
    &lt;p&gt;Even after becoming a software developer and using a macbook, I'd still find myself reaching for Windows at times.&lt;/p&gt;
    &lt;p&gt;That is, until Microsoft decided to turn it into something completely unrecognizable and unusable.&lt;/p&gt;
    &lt;head rend="h2"&gt;It all came crashing down&lt;/head&gt;
    &lt;p&gt;I think it started with the Windows 10 full-screen ads.&lt;/p&gt;
    &lt;p&gt;You know, those friendly suggestions telling you to try OneDrive or to "use the recommended browser settings" (reads as "please try Edge and OneDrive, we're desperate").&lt;/p&gt;
    &lt;p&gt;Actually, scratch that, I think it really started with the non-consensual updates:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Oh you're doing work? That's so cute... we're gonna close whatever apps you had open, because we're updating now. We own your computer.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;You had unsaved work? Too bad, it's gone, get bent.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;At first I ignored it, and carried on as normal. Sure, I'd get mad from time to time and I'd complain.&lt;/p&gt;
    &lt;p&gt;But hey, nothing beats the convenience of being able to have all of your applications in one place&lt;/p&gt;
    &lt;head rend="h4"&gt;Right? Right?&lt;/head&gt;
    &lt;p&gt;My breaking point came with the 24H2 update. It installed on my system without my consent, like any other major update. I knew there were problems with it, people were already complaining on Reddit, so I just postponed it, and kept postponing it.&lt;/p&gt;
    &lt;p&gt;All it took was for me to leave my computer on and unattended for a while, and BOOM, just like that - the major OS update that nobody wanted, it was on my computer.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Chrome Seizure Incident&lt;/head&gt;
    &lt;p&gt;As soon as 24H2 landed on my machine, I encountered a bug so bizarre I thought I was losing my marbles.&lt;lb/&gt; If Chrome was positioned under any other window, it would start having what I can only describe as a visual seizure.&lt;lb/&gt; Here's Ableton Live with Chrome (Reddit) under it:&lt;/p&gt;
    &lt;p&gt;Worse, there was a decent chance this would trigger a full system lock, leaving me smashing my desk in impotent rage. I shit you not.&lt;/p&gt;
    &lt;p&gt;I tried to rollback. The rollback failed with an error. I reinstalled Windows. The bug persisted.&lt;lb/&gt; Like digital herpes, I just couldn't get rid of it.&lt;lb/&gt; The solution? Installing an Insider build. Yes, the solution to Microsoft's broken stable release was to use their unstable release.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;For the Windows Defenders (see what I did there?), I tried uninstalling the display drivers with DDU, and testing other versions. It didn't help.&lt;/p&gt;
      &lt;p&gt;Either I stayed forever on the older build, or I'd have to deal with this. And don't tell me to forever disable updates, I'll completely lose it.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;The Sequel I Never Wanted&lt;/head&gt;
    &lt;p&gt;The Insider build worked...sort of. But now I had a new bug: Chrome would randomly lock up for about 30 seconds when a video was playing. My options were to wait it out or press Ctrl+Alt+Delete and Esc to force my way back to a working browser. After some digging, I discovered this was caused by an NVIDIA-Microsoft driver incompatibility.&lt;/p&gt;
    &lt;p&gt;Links here:&lt;/p&gt;
    &lt;p&gt;I've found out that the flickers and the chrome lock-up issues are likely caused by the Multiplane Overlay (MPO) pipeline. Microsoft blamed NVIDIA for not correctly implementing it in their drivers. NVIDIA blamed Microsoft. What's clear is that if you were facing this issue, you were essentially screwed because these 2 companies would just pass the hot potato to each other.&lt;/p&gt;
    &lt;p&gt;I should mention that this bug persisted even after I went off the Insider build and on 25H2. And when I posted on r/Microsoft, they just deleted it.&lt;/p&gt;
    &lt;p&gt;The latest and greatest OS surely cannot be broken beyond repair, surely I'm using my PC wrong.&lt;/p&gt;
    &lt;p&gt;So there I was, finally grasping the reality of what you're up against, as a Windows user:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Random bugs that break basic functionality&lt;/item&gt;
      &lt;item&gt;Updates that install without permission and brick my system&lt;/item&gt;
      &lt;item&gt;Copilot and OneDrive ads appearing in every corner of the OS&lt;/item&gt;
      &lt;item&gt;Copilot buttons everywhere, coming for every application&lt;/item&gt;
      &lt;item&gt;Can't even make a local account without hacking the setup with Rufus (they even removed the terminal workaround)&lt;/item&gt;
      &lt;item&gt;Zero actionable fixes or even an aknowledgment of their fuckups&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;People often say Linux is "too much work.".&lt;/p&gt;
    &lt;p&gt;And I agree. They're completely justified to complain. There's the documentation page diving, the forums, the reddit threads. And, most importantly, you have to basically rewire your brain and stop expecting it to behave like Windows used to.&lt;/p&gt;
    &lt;p&gt;But I looked at the list above and realized: Windows is now also too much work.&lt;lb/&gt; And the difference with Windows is that you're going to do all that work while actively fighting your computer only for it to be undone when the next surprise update comes and ruins everything.&lt;/p&gt;
    &lt;p&gt;You might be thinking "just disable updates, man" or "just install LTSC", or "just run some random debloat script off of GitHub". Why? Why would I jump through all these hoops? I'd rather put in the effort for an OS that knows what consent is and respects me as a user.&lt;/p&gt;
    &lt;head rend="h2"&gt;Could the grass actually be greener on the other side?&lt;/head&gt;
    &lt;p&gt;To set the stage: I'm a software developer and a musician.&lt;/p&gt;
    &lt;p&gt;As you can imagine, I was legitimately worried about app support on Linux, and how it would distrupt my workflow.&lt;/p&gt;
    &lt;p&gt;But after Chrome crashing for the 10000th time, I said "enough is enough", and decided to go big. I installed CachyOS, a performance-focused Arch-based distribution, on my main machine (9800X3D, RTX 5080).&lt;/p&gt;
    &lt;p&gt;It wasn't a painless process. In fact, sleep mode was broken from the start, and my system would fail to detect the monitor after waking up.&lt;/p&gt;
    &lt;p&gt;What's more, Ableton Live does not have a native Linux build, only Windows and macOS. So I couldn't use it anymore, at least not without fucking around with Wine (which doesn't fully support it), or without keeping a Windows VM and taking an L on audio latency.&lt;/p&gt;
    &lt;p&gt;But unlike Windows, on CachyOS I could actually fix my NVIDIA woes by following this thread on their forum.&lt;/p&gt;
    &lt;p&gt;All I had to do was add the NVIDIA modules to mkinitcpio. One config change, a command to rebuild the initramfs, and problem solved.&lt;/p&gt;
    &lt;p&gt;I also found a good native alternative to Ableton Live - Bitwig Studio, which bothered to release a native Linux Build.&lt;/p&gt;
    &lt;p&gt;Thanks to the constant progress that was made with Pipewire, I'm getting audio latency on par with Mac OS, and lower than Windows. And my workflow didn't even change that much, since Bitwig is made by ex-Ableton developers that seem to give a shit.&lt;/p&gt;
    &lt;p&gt;As for my development tools, on Windows you already accept the fact that you WILL use WSL or docker, so realistically I just cut the broken middleman.&lt;/p&gt;
    &lt;p&gt;Now compare that to the Windows fuckery above.&lt;/p&gt;
    &lt;head rend="h2"&gt;What You're Signing Up For&lt;/head&gt;
    &lt;p&gt;If 3 years ago you would have told me that Microsoft would singlehandedly sabotage their own OS, doing more Linux marketing than the most neckbearded Linux fanboy (or the most femboy Thinkpad enjoyer), I'd have laughed in your face, called you delusional, and then hurled some more insults your way.&lt;/p&gt;
    &lt;p&gt;Yet here we are, I've been dual-booting CachyOS for over a year, and in the last month I've been using it exclusively.&lt;/p&gt;
    &lt;p&gt;So what is the actual state of Linux in 2026, from my honest perspective?&lt;/p&gt;
    &lt;head rend="h5"&gt;Web Browsing&lt;/head&gt;
    &lt;p&gt;All major browsers (Chrome, Firefox, Edge, Brave) have native Linux builds. Full support. No compromises.&lt;lb/&gt; Video playback works flawlessly, with hardware acceleration even. On AMD, on NVidia and yes, on Intel too.&lt;/p&gt;
    &lt;head rend="h5"&gt;Software Development&lt;/head&gt;
    &lt;p&gt;Linux is the preferred platform for development.&lt;/p&gt;
    &lt;p&gt;Better terminal support, native package managers, Docker runs natively without the WSL overhead, and your production servers are probably running Linux anyway.&lt;/p&gt;
    &lt;p&gt;Hell, even Microsoft has their own Linux distro, Azure Linux (Formerly CBL-Mariner).&lt;/p&gt;
    &lt;head rend="h5"&gt;Content Creation&lt;/head&gt;
    &lt;p&gt;This is where people assume Linux falls short. And they're right, but not completely:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Adobe Suite: Runs via Winboat. Far from perfect (no video acceleration, laggy at times), but functional&lt;/item&gt;
      &lt;item&gt;DaVinci Resolve: Native Linux app. Professional-grade video editing, free tier available&lt;/item&gt;
      &lt;item&gt;Kdenlive: Native Linux app, completely free and open source&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h5"&gt;Music Production&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Bitwig Studio: Incredible DAW that runs natively on Linux&lt;/item&gt;
      &lt;item&gt;Ardour: Native, free, open-source DAW&lt;/item&gt;
      &lt;item&gt;Audio latency: Thanks to PipeWire, Linux audio latency is actually lower than Windows&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h5"&gt;Gaming&lt;/head&gt;
    &lt;p&gt;Here's where things get interesting. The perception is that gaming on Linux is a compromise. In 2026, that's increasingly untrue:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Proton/Wine: Pretty much all games without kernel-level anti-cheat work out of the box through Steam's Proton compatibility layer&lt;/item&gt;
      &lt;item&gt;Performance: For AMD GPUs, gaming performance is on par with Windows, on average&lt;/item&gt;
      &lt;item&gt;NVIDIA: There was a 10-30% performance penalty on Intel/NVIDIA GPU setups, but recent Vulkan extensions are taking care of that.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;NVIDIA has released beta drivers making use of these improvements, and once Wine/DXVK/Proton are updated to make use of the extensions, the performance delta should be essentially gone&lt;/p&gt;
    &lt;p&gt;The only real limitation is that some games with anti-cheat like Valorant, Call of Duty or League of Legends won't run. But honestly I think not being able to launch League of Legends is actually a feature - one final reason to install Linux.&lt;/p&gt;
    &lt;p&gt;It's not all bad, though. Arc Raiders makes use of Easy Anti-Cheat, yet runs flawlessly. In fact, I've been playing it like a madman. It goes to show that if the developers want to, it's possible.&lt;/p&gt;
    &lt;head rend="h5"&gt;3D Modeling&lt;/head&gt;
    &lt;p&gt;Still falls short compared to Windows and Mac OS (Autodesk, I'm looking at you).&lt;/p&gt;
    &lt;p&gt;The silver lining is that Blender has a native build. So if it's your main application, you're good to go.&lt;/p&gt;
    &lt;head rend="h5"&gt;General Usage&lt;/head&gt;
    &lt;p&gt;Basic operations are so much faster on Linux. Opening directories, launching applications, system responsiveness. It's like your computer took a line of coke, and is now ready to work.&lt;/p&gt;
    &lt;p&gt;No more waiting for the Start menu to decide it wants to open. No more File Explorer hanging when you need it the most.&lt;/p&gt;
    &lt;p&gt;Since we're on the topic of Linux improvements, I want to address the elephant in the room - people who keep saying "I want to switch", but keep moving the goalposts:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"I'll switch when Linux supports X."&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Linux supports X.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;"Okay, but what about Y?"&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Linux supports Y.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;"Well, Z is still missing..."&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;If you're always finding the next reason not to switch, you're not looking for solutions, you're looking for excuses to stay complacent.&lt;/p&gt;
    &lt;p&gt;I was that person, so I would know.&lt;/p&gt;
    &lt;p&gt;At the same time, I want to take it down a notch and say that there are still plenty of use cases (Especially creative work, and like stated previously, 3D modelling and also Game Dev) where it simply doesn't make sense to switch.&lt;/p&gt;
    &lt;p&gt;So if you're in that scenario, don't feel pressured, just wait for things to improve.&lt;/p&gt;
    &lt;p&gt;And if you don't plan on ever switching, more power to you.&lt;/p&gt;
    &lt;p&gt;I'm not here to judge, just here to vent my Microsoft frustrations.&lt;/p&gt;
    &lt;p&gt;And I didn't really want to switch either, because who wants to re-learn how their computer should be operated from scratch? What I really wanted was for Windows to work, but Microsoft didn't.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Windows Retrospective&lt;/head&gt;
    &lt;p&gt;While I'm enjoying my new Linux setup, Windows 11 is having a miserable year, and we're only a month in!&lt;/p&gt;
    &lt;p&gt;According to Windows Latest, there were over 20 major update problems in 2025 alone, and 2026 is starting off strong, with the January update causing black screens and Outlook crashes.&lt;/p&gt;
    &lt;p&gt;Here's a quick 2025 Spotify Wrapped of the bugs Windows users dealt with:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;USB audio devices randomly stopped working&lt;/item&gt;
      &lt;item&gt;Webcams failed to be detected&lt;/item&gt;
      &lt;item&gt;BitLocker settings became inaccessible&lt;/item&gt;
      &lt;item&gt;Adobe Premiere Pro couldn't drag clips on the timeline&lt;/item&gt;
      &lt;item&gt;Cursor constantly spinning for no reason&lt;/item&gt;
      &lt;item&gt;Remote Desktop sessions randomly disconnecting&lt;/item&gt;
      &lt;item&gt;The Copilot app accidentally getting deleted (okay, this is actually a good change for once)&lt;/item&gt;
      &lt;item&gt;Blue screens of death in mandatory security updates&lt;/item&gt;
      &lt;item&gt;Windows Hello face recognition broken&lt;/item&gt;
      &lt;item&gt;File Explorer becoming unresponsive&lt;/item&gt;
      &lt;item&gt;FPS drops and system reboots while gaming&lt;/item&gt;
      &lt;item&gt;Task Manager spawning infinite copies of itself&lt;/item&gt;
      &lt;item&gt;Dark mode breaking with white flashes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And the company's response? Crickets. They're busy boasting that 30% of their code is currently being written by AI. Don't worry, Microsoft, we can definitely tell.&lt;/p&gt;
    &lt;p&gt;For the remainder of 2026, Microsoft is cooking up a big one: replacing more and more native apps with React Native. But don't let the name fool you, there's nothing "native" about it. These are projects designed to be easily ported across any machine and architecture, because underneath it all, it's just JavaScript.&lt;/p&gt;
    &lt;p&gt;And each one spawns its own Chromium process, gobbling up your RAM so you can enjoy the privilege of opening the Settings app.&lt;/p&gt;
    &lt;p&gt;I could maybe understand this for a weather widget. But when it's coming for core system apps, it's LAZY!&lt;/p&gt;
    &lt;p&gt;I'm gonna go full conspiracy nut here, but I bet it's because the LLM understands JavaScript better, and Microsoft can't be asked to pay actual humans to write proper native code.&lt;/p&gt;
    &lt;p&gt;Meanwhile, entire governments are abandoning Windows for Linux, the term "Microslop" is trending on social media, and Windows 11's reputation is at its lowest point ever.&lt;/p&gt;
    &lt;head rend="h2"&gt;Not Because I Wanted To, But Because Microsoft Forced My Hand&lt;/head&gt;
    &lt;p&gt;So here I am. Fully switched to Linux.&lt;/p&gt;
    &lt;p&gt;Not because I'm some open-source idealist or command-line warrior (I'm just some guy), but because Microsoft turned into Microslop.&lt;/p&gt;
    &lt;p&gt;Recently, Microsoft CEO Satya Nadella wrote a blog post asking people to stop calling AI-generated content "slop" and to think of AI as "bicycles for the mind."&lt;/p&gt;
    &lt;p&gt;Well, Mr Satya, I have a couple of bicycles that will blow your mind:&lt;/p&gt;
    &lt;p&gt;You are the biggest Linux evangelist there ever was, you single-handedly convinced countless people to ditch your buggy, ad-ridden, bloated, slop-infested mess of an OS.&lt;/p&gt;
    &lt;p&gt;And worst of all, you're like a pit bull that has lock-jawed onto OpenAI's ballsack, and you're not letting go, no matter how much we tell you to.&lt;/p&gt;
    &lt;p&gt;So we're calling slop for what it is: disgusting slop.&lt;/p&gt;
    &lt;p&gt;You're chasing profit like your life depends on it, yet you've completely forgotten the very thing that generates profit: user satisfaction.&lt;/p&gt;
    &lt;p&gt;Now you're stuck in a circlejerk of fake value in a fake bubble, and OpenAI's hand is so far up your ass they're playing shadow puppets with your tonsils.&lt;/p&gt;
    &lt;p&gt;The time to switch is now. The tools are ready. The only question is: are you?&lt;/p&gt;
    &lt;p&gt;Satya came down from his cloud in the sky,&lt;/p&gt;
    &lt;p&gt;With Copilot dreams and a gleam in his eye,&lt;/p&gt;
    &lt;p&gt;He sprinkled AI on each app, every field,&lt;/p&gt;
    &lt;p&gt;Till users cried "Fuck!", and the slop was revealed.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46795864</guid><pubDate>Wed, 28 Jan 2026 14:28:21 +0000</pubDate></item><item><title>Airfoil (2024)</title><link>https://ciechanow.ski/airfoil/</link><description>&lt;doc fingerprint="b77d1a2b09aeb189"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Airfoil&lt;/head&gt;
    &lt;p&gt;The dream of soaring in the sky like a bird has captivated the human mind for ages. Although many failed, some eventually succeeded in achieving that goal. These days we take air transportation for granted, but the physics of flight can still be puzzling.&lt;/p&gt;
    &lt;p&gt;In this article we‚Äôll investigate what makes airplanes fly by looking at the forces generated by the flow of air around the aircraft‚Äôs wings. More specifically, we‚Äôll focus on the cross section of those wings to reveal the shape of an airfoil √¢ you can see it presented in yellow below:&lt;/p&gt;
    &lt;p&gt;We‚Äôll find out how the shape and the orientation of the airfoil helps airplanes remain airborne. We‚Äôll also learn about the behavior and properties of air and other flowing matter. In the demonstration below, you can see a fluid flowing around a gray cube. Using the slider to change just one property of this substance, we can end up with vastly different effects on the liveliness of that flow:&lt;/p&gt;
    &lt;p&gt;Over the course of this blog post we‚Äôll build some intuitions for why these different effects happen to airfoils and other objects placed in flowing air. We‚Äôll start this journey by looking at some of the methods we can use to visualize the motion of the air.&lt;/p&gt;
    &lt;head rend="h1"&gt;Visualizing Flow&lt;/head&gt;
    &lt;p&gt;If you‚Äôve ever been outside in a grassy area on a windy fall day, you may have witnessed something similar to the little scene seen below. The slider lets you control the speed of time to observe in detail how the falling leaves and the bending blades of grass are visibly affected by the wind sweeping through this area:&lt;/p&gt;
    &lt;p&gt;We intuitively understand that it‚Äôs the flowing air that pushes the vegetation around, but note that we only observe the effects that the wind has on other objects √¢ we can‚Äôt see the motion of the air itself. I could show you a similarly windy scene without the grass and leaves, and I could try to convince you that there is something going on there, but that completely empty demonstration wouldn‚Äôt be very gratifying.&lt;/p&gt;
    &lt;p&gt;Since the air‚Äôs transparency prevents us from tracking its movement directly, we have to come up with some other ways that can help us see its motion. Thankfully, the little outdoor scene already provides us with some ideas.&lt;/p&gt;
    &lt;p&gt;Notice that as the wind hits a blade of grass, that blade naturally bends in the direction of the blowing gust, and the faster that gust, the stronger the bending. A√Ç single blade indicates the direction and speed of the flow of air in that area.&lt;/p&gt;
    &lt;p&gt;In the next demonstration we‚Äôre looking at the same grassy field from above. When seen from this perspective, all the blades form short lines that are locally aligned with the wind. The more leaned over a blade of grass is, the longer the line it forms. We can mimic this behavior with a collection of small arrows placed all over the area, as seen on the right side:&lt;/p&gt;
    &lt;p&gt;Each arrow represents the direction and the speed of the flow of air at that location √¢ the longer the arrow, the faster the flow. In these windy conditions the flow varies from place to place and it also changes over time, which we can clearly see in the motion of the arrows.&lt;/p&gt;
    &lt;p&gt;Note that we have some flexibility in how the speed of wind corresponds to the length of an arrow. I adjusted the lengths of the arrows to prevent them from visually overlapping, but I also made sure to maintain their relative lengths √¢ if one arrow is twice as long as the other, then the flow at that location is also twice as fast.&lt;/p&gt;
    &lt;p&gt;For visual clarity I‚Äôm also not packing the arrows as densely as the blades of grass are placed, but it‚Äôs important to note that every point in the flow has its own velocity which contributes to the complete velocity field present in this area. If we wanted to, we could draw a velocity arrow at any of the seemingly empty spots on the right side.&lt;/p&gt;
    &lt;p&gt;The arrows are convenient, but the grassy scene also has another aid for visualizing flows. Many light objects like leaves, flower petals, dust, or smoke are very easily influenced by the motion of the surrounding air. They quickly change their velocity to match the flow of the wind. We can replicate the behavior of these light objects with little markers that are pushed around by that flow. You can see them on the right side:&lt;/p&gt;
    &lt;p&gt;These little markers also show us the motion of the air. Each marker represents an object so small and light that it instantly picks up the speed of the surrounding airflow. We‚Äôd have a hard time seeing these miniscule specks at their actual sizes, so I‚Äôm drawing the markers as visible dots.&lt;/p&gt;
    &lt;p&gt;In fact, the motion of each marker is equivalent to the motion of the parcel of air right around it. If you slow down time, you‚Äôll be able to see how each marker just moves in the direction of the arrows underneath it. I also made each marker leave a little ghost trail behind it √¢ this lets us track the path the air, as represented by the marker, took on the way to its current position.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs pause for a second to emphasize what the grass-like arrows and leaf-like markers represent √¢√Ç they both show the velocity of the flow of air, but in slightly different ways. An arrow is attached to its fixed point in space, so it represents the current direction and speed of the flow at that location. The whole collection of arrows lets us easily see what the entire flow is doing at the moment.&lt;/p&gt;
    &lt;p&gt;On the other hand, the little markers are actively following the flow, letting us see how the air is actually moving through space, with the ghosty trails giving us some historical overview of where this parcel of air has come from.&lt;/p&gt;
    &lt;p&gt;The two methods we‚Äôve seen so far are very versatile, but sometimes we don‚Äôt care about the local direction of the flow, only its speed √¢ in the middle of this grassy field one might get cold from a fast blowing wind regardless of the direction from which that wind is coming. This brings us the third way of visualizing flow:&lt;/p&gt;
    &lt;p&gt;In this method we show the speed of the airflow using colors of varying brightness √¢ the faster the wind, the brighter the color. You can see the whole spectrum of colors in the scale below the plot.&lt;/p&gt;
    &lt;p&gt;This method shows the speed of the flow at all locations giving us a more fine-grained insight into the motion of air at the cost of the directional information. To help with that I‚Äôll sometimes overlay the regular arrows on top to let us know where the flow is going as well.&lt;/p&gt;
    &lt;p&gt;You may have noticed that all these methods present a flat, two dimensional view of the flow. It‚Äôs based on the assumption that the wind in our little scene doesn‚Äôt change with elevation, and that it also doesn‚Äôt blow towards or away from the ground.&lt;/p&gt;
    &lt;p&gt;In reality, the air velocity could vary in all three dimensions, and that air could also flow upwards or downwards. Thankfully, the air flows we‚Äôll consider in this article will be two dimensional and the simple flat drawings will suffice.&lt;/p&gt;
    &lt;p&gt;Before we finish this section, let me bring up visualization of a simple airflow, but this time I‚Äôll give you some control over its direction, which you can change using the second slider. The first one once more controls the speed of time:&lt;/p&gt;
    &lt;p&gt;Don‚Äôt be misled by the frozen arrows, the wind is actually blowing there. Remember that the arrows represent the local velocity of the flow of air, so while the velocity doesn‚Äôt change, the position of each packet of air does. You can see those changes by tracking the markers moving around with the flow. This demonstration represents a steady flow, which means that its properties don‚Äôt change over time.&lt;/p&gt;
    &lt;p&gt;So far we‚Äôve been exploring the notion of airflow‚Äôs velocity on a more intuitive level, with a general understanding that‚Äôs it‚Äôs ‚Äúthe air‚Äù moving around in some direction and at some speed. I illustrated that concept using simple arrows√¢, markers√Ç √¢¬¢, and varying colors, but we‚Äôre now ready to investigate the details hiding behind those straightforward graphical representations.&lt;/p&gt;
    &lt;p&gt;To do that, we have to look at individual particles of air. Although I briefly discussed the particle nature of air before, this time around we‚Äôre going to take a closer look at the motion of these molecules, and what it means for airflow as a whole.&lt;/p&gt;
    &lt;head rend="h1"&gt;Velocity&lt;/head&gt;
    &lt;p&gt;Let‚Äôs take a look at the air particles in a small, marked out volume of space seen in the demonstration below √¢ you can drag the cube around to change the viewing angle. The slider controls the speed of time:&lt;/p&gt;
    &lt;p&gt;You‚Äôre witnessing the motion of over twelve thousand air particles. It may seem like a lot, but this cube is extremely tiny, its sides are only 80 nanometers long. To put this in perspective using more familiar sizes, if that cube‚Äôs side measured just 1 inch1 centimeter, it would contain around 410 quintillion, or 4.1√É102025 quintillion, or 2.5√É1019 particles.&lt;/p&gt;
    &lt;p&gt;The particles are zipping around in random directions, constantly entering and leaving this region. However, despite all this motion what you‚Äôre seeing here is a simulation of still air.&lt;/p&gt;
    &lt;p&gt;To understand how all this movement ends up creating still conditions, we first have to look at the velocity of each particle √¢ I‚Äôll visualize it with a small arrow in the direction of motion. To make things a easier to see, I‚Äôll also highlight a few of the particles while fading out the rest of them:&lt;/p&gt;
    &lt;p&gt;The length of an arrow is proportional to the speed of a particle, so when you freeze the time you should be able to see how some particles are slower and some are faster. This speed variation follows a certain distribution that‚Äôs related to temperature √¢ the warmer the air, the faster the motion of its particles.&lt;/p&gt;
    &lt;p&gt;At room temperature the average speed of a particle in air is an astonishing 1030√Ç mph1650√Ç km/h, which is many times higher than even the most severe hurricanes. Given the size of the cube, this means that even at the fastest speed of simulation everything happens 11 billion times slower than in real life.&lt;/p&gt;
    &lt;p&gt;If you paid close attention, you may have also noticed that sometimes the particles randomly change direction and speed of their motion √¢ this happens when molecules collide. Each particle experiences roughly ten billion collisions per second. We‚Äôll get back to these interactions later on, but for now let‚Äôs try to figure out how all this turmoil creates still air.&lt;/p&gt;
    &lt;p&gt;Having just seen the small velocity arrows of individual particles, let‚Äôs calculate the average velocity of a group of three particles, using the process shown below. We first take the velocity arrows from each particle and place them head to toe, one after another. Then we connect the start of the first arrow with the end of the last arrow to create the sum of all velocities. Finally, we divide, or scale down, the length of this sum by the number of particles to get the average velocity:&lt;/p&gt;
    &lt;p&gt;In the next demonstration we‚Äôre repeating this whole procedure by tallying up all the particles inside the red box. You can change the size of that region with the second slider. The large arrow in the middle shows the average velocity of particles in the box. To make that central arrow visible, I‚Äôm making it much larger than the tiny arrows tied to particles:&lt;/p&gt;
    &lt;p&gt;The counter in the bottom part of the demonstration tracks the current number of particles in the red cube. That value fluctuates as the molecules enter and leave that region. While aggregating over a small number of particles creates a very noisy readout, it doesn‚Äôt take that many particles to get a much steadier measure.&lt;/p&gt;
    &lt;p&gt;Recall that the scale of the large central arrow is much larger than the scale of individual tiny arrows attached to each particle. Despite that increase in size, the arrow practically disappears when we average out a larger number of particles and we can clearly see that the average velocity of particles is more or less zero even in this extremely small volume.&lt;/p&gt;
    &lt;p&gt;In still conditions, all these motions in different directions average out to nothing. As some particles enter the area from a random direction, the others also leave it in a random way. The bulk of air doesn‚Äôt really go anywhere and the particles just meander in a random fashion.&lt;/p&gt;
    &lt;p&gt;An imperfect, but convenient analogy is to imagine a swarm of bees flying in the air. While all the individual insects are actively roaming around at different speeds, the group as a whole may steadily stay in one place.&lt;/p&gt;
    &lt;p&gt;All these experiments form the key to understanding what happens when wind sweeps through an area. In the demonstration below, we‚Äôre once again watching a small volume of space, but this time you can control the speed of the blowing wind:&lt;/p&gt;
    &lt;p&gt;Notice the mphkm/h speedometer in the bottom of the demonstration. This is not a mistake √¢√Ç even with hurricane-level wind speeds it‚Äôs very hard to see any difference in the motion of the particles. Perhaps you‚Äôve managed to see the tiniest shifts in the small particle arrows as you drag the second slider around with time paused, but it‚Äôs difficult to even perceive from which direction the wind is blowing.&lt;/p&gt;
    &lt;p&gt;However, when we use the procedure of averaging the velocity of all the particles, we can reveal the motion of their group in the box of a given size, at a specific speed of the flow:&lt;/p&gt;
    &lt;p&gt;Because the motion of each individual particle is so disordered, we have to look at many of them at once to discern any universal characteristics. And when we do just that, from all the chaos emerges order.&lt;/p&gt;
    &lt;p&gt;It‚Äôs important to note that with this approach we‚Äôre tracking the velocity of the flow within the same region of space outlined by the red box √¢ the molecules keep entering and leaving this area as the flow moves and the arrow in the middle shows the average velocity of the air‚Äôs particles in that area.&lt;/p&gt;
    &lt;p&gt;This is exactly what the grass-like arrows we‚Äôve played with in the previous section represent √¢ each one shows the average velocity of air particles in that local region of space. The big arrow we just saw in the middle of the swarm in the averaging red box is equivalent to each of the arrows seen below:&lt;/p&gt;
    &lt;p&gt;Naturally, the averaging box needs to be large enough to avoid the jitteriness related to aggregation of too few particles, but at any scale that we could care about the noisy readout completely disappears.&lt;/p&gt;
    &lt;p&gt;The average motion of particles is very different than the motion of each individual molecule. Even in very fast flows, many of the molecules move in the opposite direction than what the arrow indicates, but if we tally up all the particle motion, the air as a whole does make forward progress in the direction of velocity.&lt;/p&gt;
    &lt;p&gt;Up to this point, we‚Äôve mostly looked at the flow of air by looking at wind and the way it moves through space, but what we consider a motion of air is relative. Let‚Äôs see how, by merely changing the point of view, we can create a motion of air in otherwise windless conditions.&lt;/p&gt;
    &lt;head rend="h1"&gt;Relative Velocity&lt;/head&gt;
    &lt;p&gt;Let‚Äôs zoom away from the world of microscopic particles to look at the motion of larger bodies. In the demonstration below, you can see two different views of the same car driving in the left direction. In the top part, the camera stays firmly on the ground, but in the bottom part, the camera tracks the motion of the vehicle. If needed, you can restart the scene with the button in the bottom left corner or tweak the speed of time with the slider:&lt;/p&gt;
    &lt;p&gt;These two views show the exact same scene √¢ we‚Äôre just changing what the camera is focusing on. As seen in the top part, from the perspective of the static camera, it‚Äôs only the car that has some velocity in the left direction.&lt;/p&gt;
    &lt;p&gt;On the other hand, from the perspective of the camera focused on the vehicle, the car doesn‚Äôt move, but everything else does. The poles and road markings all move to the right with a speed equal to that of the car. This shouldn‚Äôt come as a surprise from daily experience in any form of transportation √¢ when you‚Äôre sitting in a moving vehicle, static things in the surrounding environment seem to move towards and past you.&lt;/p&gt;
    &lt;p&gt;The very same rules apply to any region of air √¢ I‚Äôve outlined some of them with dashed boxes up in the sky. For the observer on the ground that air is still, but from the car‚Äôs perspective, that air is moving.&lt;/p&gt;
    &lt;p&gt;With that in mind, let‚Äôs see the same scene, but this time I‚Äôll add the familiar small arrows showing the air‚Äôs velocity as ‚Äúseen‚Äù by the camera:&lt;/p&gt;
    &lt;p&gt;From the point of view of the car, as seen in the bottom view, the air is moving to the right, as if there was some wind blowing right at the vehicle. You‚Äôve probably felt this many times by sticking your hand out the window √¢ it feels no different than if you were standing still on the ground with the wind hitting your fingers.&lt;/p&gt;
    &lt;p&gt;In fact, there is absolutely no difference between ‚Äúregular‚Äù wind and wind experienced by the car or your hand sticking out the window √¢ both are simply a motion of air relative to some object. This means that we can use our arrows to represent any motion of air, as long as we note what that motion is relative to.&lt;/p&gt;
    &lt;p&gt;You may have also noticed that the moving car affects the motion of air in its vicinity. Let me bring up the previous demonstration one more time:&lt;/p&gt;
    &lt;p&gt;In the top view, we can see how the front of the vehicle pushes the air forward, and how the air ‚Äúbends‚Äù and speeds up around the shape of the car to roughly follow its shape, only to end up circling right behind the machine.&lt;/p&gt;
    &lt;p&gt;The same effects are seen in the bottom view √¢ they‚Äôre just experienced differently. For example, the air right in front of the car slows down, while the air on top moves even faster than the rest of the undisturbed, distant air.&lt;/p&gt;
    &lt;p&gt;We‚Äôll soon explore why the air behaves this way when flowing around an object, but for now let‚Äôs raise above the ground to see the motion of an airplane flying in the sky. We‚Äôll use the familiar setup of a camera kept steady relative the ground, as seen in the top part, and a camera that follows the airplane, seen in the bottom part:&lt;/p&gt;
    &lt;p&gt;Before we continue, notice that it‚Äôs getting a little hard to pay close attention to what happens to the moving objects in the ground-fixed camera view √¢ the bodies quickly leave the field of view of the demonstrations. For the rest of this article I‚Äôll stick to the camera style seen in the bottom part of the demonstration √¢ this will let us directly track the interaction between the object and the air that flows around that object.&lt;/p&gt;
    &lt;p&gt;From the point of view of the airplane, it also experiences a flow of incoming air as seen by the air ‚Äúboxes‚Äù approaching the plane, which is very similar to the car example. What‚Äôs completely different from the car example is the fact that the airplane somehow stays suspended in the air, despite gravity pulling it down towards the ground. This means that there must be some other force acting on it to prevent the plane from falling from the sky.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs compare these two vehicles by looking at the basic forces affecting their motion, starting with the diagram of forces acting on the car:&lt;/p&gt;
    &lt;p&gt;The down-pulling gravity force is counteracted by the reaction forces from the ground √¢ they act through the car‚Äôs tires to prevent the car from sinking. The air drag and other forms of resistance push the car back, but the car‚Äôs tires powered by the engine keep propelling the car forward.&lt;/p&gt;
    &lt;p&gt;In my previous article I presented a more elaborate description of the interplay between forces and objects, but to briefly recap here, if forces acting on an object are balanced, then that object will maintain its current velocity.&lt;/p&gt;
    &lt;p&gt;All forces on the car are balanced and the vehicle moves forward with constant speed, and it doesn‚Äôt move at all in the up or down direction √¢ the object‚Äôs velocity is indeed constant.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs draw a similar diagram of forces for the flying plane:&lt;/p&gt;
    &lt;p&gt;We still have the air drag that pushes the vehicle back, and the plane‚Äôs propeller powered by the engine keeps pushing it forward. As a result the plane moves forward with constant speed.&lt;/p&gt;
    &lt;p&gt;We also have the down-pulling gravity. This time, however, that gravity is not countered by the reaction forces from the ground, but instead it‚Äôs balanced by lift, a force that pushes the plane up. When gravity and lift are equalized, the plane doesn‚Äôt move up or down either.&lt;/p&gt;
    &lt;p&gt;Airplanes create most of their lift with wings, which are carefully designed to generate that force. While length, area, and the overall geometry of the wings are very important, in this article we‚Äôll focus on the shape of the cross-section of a wing which I highlighted below in yellow:&lt;/p&gt;
    &lt;p&gt;This is an airfoil, the protagonist of this article. This airfoil has a smooth, rounded front and a sharp trailing edge. Let‚Äôs take a closer look at the flow of air around this airfoil using the grass-like arrows that show the velocity of air at that location:&lt;/p&gt;
    &lt;p&gt;These arrows paint an interesting picture, but in the demonstration below I‚Äôve also added the little leaf-like markers that track the motion of air parcels in the flow. I√Ç steadily release a whole line of them from the left side, but you can also clicktap anywhere in the flow to drop a marker at that location. You can do this in any demonstration that has a little hand symbol in the bottom right corner:&lt;/p&gt;
    &lt;p&gt;The markers show that the flow splits ahead of the airfoil, then it gently changes direction to glide above and below the shape. Moreover, the markers right in front of the airfoil gradually slow down and lag behind their neighbors. The air somehow senses the presence of the body.&lt;/p&gt;
    &lt;p&gt;It may be hard to see, but the top and bottom sections of this airfoil aren‚Äôt symmetric. This asymmetric design is very important, but right now it will needlessly complicate our discussion on how the flow around this shape arises.&lt;/p&gt;
    &lt;p&gt;To simplify things a little, let‚Äôs use a less complicated shape of a symmetric airfoil √¢ you can see it in the demonstration below. I overlay the previous asymmetric shape with a dashed outline to show the difference between the two:&lt;/p&gt;
    &lt;p&gt;The motion of air around this airfoil is very similar √¢ the flow changes its direction and speed when it passes around an object. Until now we‚Äôve simply been observing that the flow changes to adapt to the shape of the body, but it‚Äôs finally time to understand why it happens. To explain that behavior we need to go back to the world of air particles to discuss the concept of pressure.&lt;/p&gt;
    &lt;head rend="h1"&gt;Pressure&lt;/head&gt;
    &lt;p&gt;As we‚Äôve discussed, even in the seemingly steady conditions the particles of air are zipping around at high speeds colliding with each other at an incredible rate. The surface of any object placed in the air will also experience these bounces.&lt;/p&gt;
    &lt;p&gt;In the demonstration below, you can see air particles bombarding a small box. Every time a collision happens I briefly mark it with a dark spot on the surface of that cube:&lt;/p&gt;
    &lt;p&gt;To understand the implications of these collisions, let‚Äôs first take a look at objects with more ordinary sizes. In the demonstration below, tennis balls are hitting a large cardboard box from the left and right side. By dragging the slider you can change the intensity of both streams of balls:&lt;/p&gt;
    &lt;p&gt;When a tennis ball hits the box, the collision imparts some force on it, causing the box to move. However, in this simulation the collisions from all the balls on each side balance each other out, so the box doesn‚Äôt make any consistent progress in either direction.&lt;/p&gt;
    &lt;p&gt;In real air, the situation is similar, but at vastly different scales. The mass of each particle constituting air is absolutely miniscule, so the impact of an individual collision on any object of meaningful size is completely imperceptible.&lt;/p&gt;
    &lt;p&gt;Moreover, each air particle hitting an object has a different speed, and it strikes the surface of that object at a different angle √¢ some hit the object straight on, but some barely graze it. Due to the enormous number of these collisions happening at every instant of time, all these variations average out, and even a small section of surface of any body experiences uniform bombardment.&lt;/p&gt;
    &lt;p&gt;In aggregate, we say that the air exerts pressure on any object present in that air. The magnitude of this pressure depends on the intensity of these collisions across an area.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs see how this pressure manifests on our tiny cube. In the demonstration below, you can use the second slider to control the number of air molecules present in this volume:&lt;/p&gt;
    &lt;p&gt;The black arrows you see on the sides of the cube symbolize the magnitude of pressure on these walls. As we uniformly increase the number of particles in this volume, the intensity of collisions, and thus the pressure, also increases. Because the collisions happen at more or less the same rate on every side of the box, the net balance of forces is also maintained and the cube doesn‚Äôt move, regardless of how big or small the overall pressure is.&lt;/p&gt;
    &lt;p&gt;This is exactly what happens in the Earth‚Äôs atmosphere √¢ everything is constantly squeezed by relatively high pressure caused by the barrage of countless air particles. That pressure is typically balanced either by an object‚Äôs material, which resists compression like a spring, or by the air itself that fills the insides of the object. When that inner air is removed, the seemingly innocuous atmospheric pressure reveals its might.&lt;/p&gt;
    &lt;p&gt;The underlying particle nature also shows us that pressure is never negative. Without any particle collisions, we reach the lowest possible pressure of zero. Beyond that, any impacts on the surface of an object create some amount of positive pressure.&lt;/p&gt;
    &lt;p&gt;In the demonstrations we‚Äôve seen so far, the balanced number of collisions on each wall was very important for keeping the objects steady. Unsurprisingly, more interesting things happen when this harmony isn‚Äôt maintained. Let‚Äôs first investigate this scenario using the tennis balls. In the demonstration below, the slider controls if it‚Äôs the left side or the right side that‚Äôs shooting more balls:&lt;/p&gt;
    &lt;p&gt;As you can see, if one of the sides has a higher number of collisions, the forces acting on the box are no longer balanced and the box starts to move.&lt;/p&gt;
    &lt;p&gt;The very same situation happens in air, which you can witness in the simulation below. Notice that the volume in which the tiny cube exists has more particles on one side than the other. Observe what happens to cube once you let the time run using the slider:&lt;/p&gt;
    &lt;p&gt;The higher number of particle collisions on one side of the cube creates higher pressure forces on that wall. The uneven forces end up pushing the block to the side. In this demonstration, the pressure re-balances after a while and the cube stops moving.&lt;/p&gt;
    &lt;p&gt;Intuitively, the air exerts an imbalanced net force on the cube only when different parts of that object experience different pressure √¢ it‚Äôs the spatial variation in pressure that creates an acting net force. When the difference in pressure between any two points increases, the net force acting on the object also grows.&lt;/p&gt;
    &lt;p&gt;It‚Äôs easy to see that a larger number of collisions on the left side of an object would start to exert a net force pushing that object to the right, but, perhaps surprisingly, the same rules apply to any chunk of air itself.&lt;/p&gt;
    &lt;p&gt;In the demonstration below, I once again made one half of the test volume contain more particles than the other half. As you unpause the demonstration, observe the average velocity of molecules in the marked out section of air:&lt;/p&gt;
    &lt;p&gt;The particles on the more occupied side can easily travel to the less crowded side, because there are fewer particles there to collide with and bounce back from. Additionally, each particle in the less populated section is more likely to hit a particle in the more populated section, which will typically cause that particle from the desolate side to bounce back where it came from.&lt;/p&gt;
    &lt;p&gt;The particles end up, on average, traveling from the area of high pressure to the area of lower pressure. Even though we don‚Äôt have any clean borders between different sections, we can still see the bulk of particles getting accelerated towards the less dense section.&lt;/p&gt;
    &lt;p&gt;Once again, the initial pressure differences in the test volume dissipate after a while. On their own, these freely suspended pressure variations quickly disappear, but we will soon see how, with the aid of airflow, these areas of different pressure can be sustained indefinitely.&lt;/p&gt;
    &lt;p&gt;In the examples we‚Äôve been playing with, the notion of increased pressure came from an increased number of collisions, which in turn came from an increased number of particles in the area. This shows that, all other things being equal, pressure is tied to the local density of the air, which was very easy to perceive in an increased concentration of molecules.&lt;/p&gt;
    &lt;p&gt;However, the pressure can also grow due to increased average speed of the particles, which in turn comes with increased temperature. As particles get faster, each collision gets more impactful and it pushes on an object or other particles a bit harder, causing the overall pressure to also increase. In the demonstration below, we can simulate this with tennis balls hitting the cardboard box at the same rate, but with different speeds, which you can control with the slider:&lt;/p&gt;
    &lt;p&gt;As we make the balls on one side of the box faster, their impacts also become stronger and the package starts moving to the right, even though the number of collisions per second is equal on both sides.&lt;/p&gt;
    &lt;p&gt;The important point from these discussions is that air pressure exerts force on everything inside it, be it a solid object or any parcel of air. It‚Äôs a little unintuitive that the air itself both exerts the pressure and it also ‚Äúfeels‚Äù the pressure, but it‚Äôs all just a consequence of very rapid motions of particles and the collisions between them happening at an enormous rate.&lt;/p&gt;
    &lt;p&gt;Recall that even in small volumes of air there are billions of billions of particles, and each particle experiences roughly ten billion collisions per second. What we‚Äôve simulated at a micro scale and in slow motion as countable, individual interactions, very quickly smooths out into a uniform and uninterrupted notion of force-exerting pressure.&lt;/p&gt;
    &lt;p&gt;This fact lets us abandon the molecules and their collisions yet again. It‚Äôs not a big loss, since counting the number and intensity of collisions was never convenient in the first place, but we can now investigate some other ways of visualizing pressure in a region of air.&lt;/p&gt;
    &lt;head rend="h1"&gt;Visualizing Pressure&lt;/head&gt;
    &lt;p&gt;As we‚Äôve seen in the particle simulations, pressure can vary from place to place. One of the most convenient ways to express this variation is to use colors of different intensities. Let‚Äôs see how that simple approach could work here. In the demonstration below, the dashed circles represent regions of high and low pressure √¢ you can drag them around to change their position:&lt;/p&gt;
    &lt;p&gt;This map of pressure is colored with varying shades of red as indicated by the scale below √¢ the redder the color, the higher the pressure. The small triangle √¢¬º in the middle of the scale indicates the location of the base, static pressure present in the atmosphere.&lt;/p&gt;
    &lt;p&gt;In this simulation we have complete control over where the different locations of lower and higher pressure are. To make things more interesting, each draggable pressure circle has a different strength and range. You can infer this variation from color changes around these points.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs put an airfoil in this area to see how it‚Äôs affected by the pressure of the surrounding air. The arrows seen below symbolize the force that pressure exerts on the surface of the airfoil at that location. They‚Äôre the exact same arrows that we‚Äôve seen acting on the walls of the tiny yellow cube, here we just see them at a larger scale:&lt;/p&gt;
    &lt;p&gt;As you move around the locations of lower and higher pressure, the forces acting on the surface of the airfoil also change, matching what we‚Äôve seen with little cubes bombarded by air particles. The static pressure always exerts some base load, but in the areas of higher pressure the surface forces are higher, and in the areas of lower pressure the surface forces are lower than these base forces.&lt;/p&gt;
    &lt;p&gt;Note that you can also move the pressure circles into the airfoil, but it only serves as a convenience to let you customize the shape of the air pressure field around that body √¢ we don‚Äôt particularly care about the pressure inside the solid itself.&lt;/p&gt;
    &lt;p&gt;When we tally up all the pressure forces acting on each piece of the airfoil‚Äôs surface, we end up with the net force acting on that object. In the demonstration below, I‚Äôm showing it with the big arrow at the center of the airfoil:&lt;/p&gt;
    &lt;p&gt;By changing the distribution of pressure around the airfoil, we can affect the total force that this object feels.&lt;/p&gt;
    &lt;p&gt;The reddish plots we‚Äôve been looking at are correct, but a little inconvenient. Recall that final net force on the object depends only on the differences of pressure √¢ when we uniformly increased the number of collisions on the walls of the tiny cube, it steadily remained in place.&lt;/p&gt;
    &lt;p&gt;This means that the static background pressure doesn‚Äôt matter for the cumulative forces acting on an object. It‚Äôs only the differences relative to that static pressure that affect the overall balance. This lets us overhaul our visual representation of pressure √¢ we can use no color where the pressure has the static value, use blue color when the pressure is lower than the static pressure, and use red color when the pressure is higher than the static pressure:&lt;/p&gt;
    &lt;p&gt;This is the exact same distribution of pressure that we‚Äôve just seen. All the pressure demos in this section are connected, and here we simply changed the reference point against which we present the pressure variation.&lt;/p&gt;
    &lt;p&gt;If we then throw in the airfoil back into the mix we can now also adjust the arrows representing the forces that the pressure exerts on the surface of that object:&lt;/p&gt;
    &lt;p&gt;The areas of higher pressure still seem to push on the surface of the airfoil, but the areas of lower pressure now seem to pull it. However, I need to emphasize once more that pressure always pushes on the object, and we can only talk about a pulling force when we discard that uniform, pushing contribution coming from the static pressure. In those ‚Äúpulling‚Äù areas the pressure is still pushing, it just pushes less intensely.&lt;/p&gt;
    &lt;p&gt;I will also use the convenient terms of positive and negative pressure, but remember that this refers to their difference from the static pressure. The phrase ‚Äúpressure lower than static pressure‚Äù is a mouthful, so the expression ‚Äúnegative pressure‚Äù is very handy, even when it hides the fact that pressure is always positive.&lt;/p&gt;
    &lt;p&gt;While the color variations used here show the true nature of the smoothly varying pressure changes, they make it a little hard to see how quickly those changes happen. To fix this, I‚Äôll also draw the contour lines that join the locations of the same pressure √¢ they‚Äôre very similar to lines of the same altitude you may have seen on maps:&lt;/p&gt;
    &lt;p&gt;Every point on one of those contour lines has the same value of pressure, and each subsequent line is drawn at the same increment of pressure √¢ you can see this in the scale placed below the plot. This means that the closer the lines are together, the more quickly the pressure changes in that area.&lt;/p&gt;
    &lt;p&gt;The mathematical concept that describes the direction and rapidness of these changes is known as a gradient. Informally, gradient describes how some property changes from one point to another, and, thankfully, this notion tracks closely with how this word is used in graphic design to describe smooth color changes. Wherever you see a color gradient , this also implies that there is a pressure gradient √¢ the pressure changes from place to place.&lt;/p&gt;
    &lt;p&gt;This spatial variation is particularly important for the motion of air. Recall that the air pressure differences don‚Äôt just exert forces on solid objects, but also on the air itself √¢ any small parcel of air is subject to the same whims of pressure forces.&lt;/p&gt;
    &lt;p&gt;Those spatial variations in pressure end up pushing the air around, changing its velocity. Let‚Äôs see this in action using the little leaf-like markers that are moved around by pressure differences. In the demonstration below, I‚Äôm steadily releasing the markers from the left side √¢√Ç notice how their trajectory changes when you modify the pressure field:&lt;/p&gt;
    &lt;p&gt;You may still find it a little difficult to grasp how pressure differences affect the motion of a parcel of air. Luckily, we can draw parallels between the contour lines of pressure seen on these pressure maps and the contour lines of elevation seen on traditional maps. This lets us build a little pressure-landscape analogy.&lt;/p&gt;
    &lt;p&gt;In the demonstration below, the very same distribution of pressure is expressed as a mountainy landscape. Positive pressure lifts the ground above the base level and negative pressure depresses it below the base level. A parcel of air moves like a marble that loses speed when climbing uphill and accelerates when rolling downhill. You can drag the demo around to change the viewing angle:&lt;/p&gt;
    &lt;p&gt;Notice that when the pressure changes more rapidly and the contour lines are closer, the steepness of the corresponding hill or valley also increases, and so do the forces acting on a parcel of air. If the pressure is increasing by a large amount, it may even make the marker go back. This landscape analogy also shows that the static pressure doesn‚Äôt matter for the motion of air parcels, as any changes in static pressure would just lift all the areas by the same amount without changing their steepness.&lt;/p&gt;
    &lt;p&gt;When watching these air parcels move around, you may have noticed that things were a little bit off. For example, it‚Äôs possible for air parcels coming from different directions to arrive at the same location, and then continue to travel in different directions. You can see an example of that on the left side of the demonstration below, with the slider letting you scrub back and forth in time:&lt;/p&gt;
    &lt;p&gt;Recall that the markers always follow the local velocity of air, so the motion seen in the left part implies that the air at the location of the meetup of the two markers has two different velocities at the same time, which is not realistic.&lt;/p&gt;
    &lt;p&gt;It‚Äôs worth pointing out that the situation seen on right side, where one marker merely intersects the historical path of the other, can be realistic, as long as we‚Äôre dealing with an unsteady flow, where the velocity of the air at the crossing location has changed since the first marker was there. For steady conditions in which no changes occur over time, the scenario seen on the right is also not physically correct.&lt;/p&gt;
    &lt;p&gt;We‚Äôll look at some unsteady flows later in the article, but for now we‚Äôre interested in steady conditions so the crossing paths of our markers indicate implausible velocities. Even more dubious result happen when we simulate the motion of these markers with an airfoil present in the flow:&lt;/p&gt;
    &lt;p&gt;For most distributions of pressure, the air markers will flow right through the body. This is clearly wrong! The demonstrations we‚Äôve seen so far correctly represent what would happen to individual air parcels and bodies placed in these pressure fields, but those pressure fields themselves were completely made up and didn‚Äôt correspond to any physical reality. Our mistake was that we completely ignored any interactions between the pressure of the air and the motion of that air.&lt;/p&gt;
    &lt;p&gt;The flow of air, the pressure of air, and the shape of the objects placed in that air are all tied together √¢ for a given incoming flow speed and the shape of the object, we can‚Äôt just arbitrarily arrange the pressure field like we did in our artificial demonstrations. Instead, that pressure field will arise on its own.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs see a real distribution of pressure around this airfoil and witness how it affects the motion of air parcels around it:&lt;/p&gt;
    &lt;p&gt;The behavior of air parcels now matches our intuitive expectations √¢ the markers don‚Äôt go through the body, and in these steady conditions they also don‚Äôt cross paths.&lt;/p&gt;
    &lt;p&gt;We‚Äôre now one step closer to understanding how the flow of air takes its shape to move around an airfoil √¢ it‚Äôs the pressure differences that cause the flow to change its direction and speed.&lt;/p&gt;
    &lt;p&gt;The pressure field we‚Äôve just seen clearly works √¢ regions of lower and higher pressure guide the air around the airfoil. However, it‚Äôs still unclear how these areas emerged in the first place. Let‚Äôs try to follow nature‚Äôs path to see how this pressure distribution is created and sustained in a flow.&lt;/p&gt;
    &lt;head rend="h1"&gt;Airfoil Flow&lt;/head&gt;
    &lt;p&gt;Before we start building the correct pressure field from scratch, let‚Äôs first establish two guiding principles that the flow around any object has to follow.&lt;/p&gt;
    &lt;p&gt;Firstly, the air can‚Äôt penetrate solid walls. A valid pressure field should either completely stop the flow at the surface of the object, or redirect that flow to make it travel in the direction perpendicular to the walls. This means that the markers that we track can never get inside the object.&lt;/p&gt;
    &lt;p&gt;Secondly, we also have the restrictions on the relative motion of the markers. For now we‚Äôll only be interested in steady conditions, which means that the markers can‚Äôt cross their paths √¢ we expect the ghostly historical trails to never intersect.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs first focus on the pressure field in front of the airfoil. In the demonstration below, I created an artificial pressure field in that frontal region, you can control it using the slider:&lt;/p&gt;
    &lt;p&gt;It should quickly become clear that to prevent the approaching air from getting into the object, the pressure in the frontal region has to be positive, so that it pushes the incoming air away.&lt;/p&gt;
    &lt;p&gt;If that positive pressure in front is too low the air can still erroneously flow through the object. If that pressure is too high, the air parcels arriving at the airfoil will turn back and incorrectly cross paths with the incoming air. When the pressure is just right, the air parcels don‚Äôt go through the wall, and, at least in front of the object, they also don‚Äôt cross their paths.&lt;/p&gt;
    &lt;p&gt;The faster the incoming flow, the higher the pushing force required to slow down and redirect the incoming air. In the demonstration below, you can also control the speed of that incoming air using the second slider:&lt;/p&gt;
    &lt;p&gt;While for slow flows, only a small amount of positive pressure is enough to stop the incoming air, for fast flows, the pressure in front of the airfoil has to become much higher.&lt;/p&gt;
    &lt;p&gt;The pressure needed to stop air at a given velocity is known as stagnation pressure and it‚Äôs proportional to the square of that velocity √¢ twice as high speed requires four times larger pressure. Naturally, when there is no flow, no pressure is required as the air no longer tries to flow through the object.&lt;/p&gt;
    &lt;p&gt;In the previous two demonstrations, we manually adjusted the pressure to get the correct result, but in nature this process happens on its own √¢ it‚Äôs the flow itself that creates this region of increased pressure in front of the object.&lt;/p&gt;
    &lt;p&gt;As the incoming parcels of air arrive at the surface of the airfoil, they can‚Äôt continue going forward, but air parcels from further up ahead continuously want to keep flowing into this region. This compresses the air close to the object, which causes the pressure in front to increase, which then helps to slow down the incoming flow.&lt;/p&gt;
    &lt;p&gt;This mechanism is self-balancing √¢ if the pressure is too low to push away the incoming air parcels, the air parcels will compact the existing air more, causing an increase in pressure. If the pressure is too high, it will easily push the incoming air away, which relieves the frontal area, causing the pressure to decrease. Any fluctuations quickly settle to an equilibrium that balances the pressure in the entire frontal region.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs look at the distribution of the positive frontal pressure once more:&lt;/p&gt;
    &lt;p&gt;Notice that the positive pressure isn‚Äôt limited to just the close vicinity of the airfoil, but it spreads out much further ahead to gradually reach the value of the static pressure, far away from the airfoil itself.&lt;/p&gt;
    &lt;p&gt;All in all, we have a large area of increasing pressure that starts far away from the body and ends at its surface. Those pressure differences create a pressure ‚Äúhill‚Äù that not only gradually slows the incoming air down, but it also redirects that air to flow around the object.&lt;/p&gt;
    &lt;p&gt;It seems that with our frontal pressure field we‚Äôve easily completed our goal of preventing the air from flowing through the walls of the body. However, our second guideline of non-crossing marker paths is still not fulfilled √¢ this condition is broken above and below the airfoil.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs first try to rectify this manually. In the demonstration below, you can control the pressure in these two regions using the slider:&lt;/p&gt;
    &lt;p&gt;While positive values of pressure in those zones make the problem worse, negative values get us much closer to the expected behavior √¢ in the top and bottom areas the markers no longer veer off into different directions. However, that pressure can‚Äôt be too low, otherwise it will pull the markers back into the body.&lt;/p&gt;
    &lt;p&gt;In real flow, these regions of lower pressure arise on their own, but the explanation for this phenomenon is a little less straightforward than what I‚Äôve described for the area of positive pressure in the frontal region. We can get some, albeit a bit hand-wavy, understanding by observing what happens to the air markers when those negative regions are missing.&lt;/p&gt;
    &lt;p&gt;In that scenario, the incoming air parcels no longer reach those areas above and below the airfoil, causing some local depletion of air that has since left those zones. This decreases the pressure in those regions, and that lower pressure attracts the surrounding air to flow into those less occupied spaces.&lt;/p&gt;
    &lt;p&gt;If that lower pressure is too negative, more air will come in and the pressure will rise. If the pressure is not negative enough, those region will get depleted again. Once again, it‚Äôs the flow itself that creates the balancing system √¢ without the flow no pressure differences would arise.&lt;/p&gt;
    &lt;p&gt;As we‚Äôll see later on, in more extreme scenarios that negative pressure can alter the flow more dramatically, and the regions of ‚Äúmissing‚Äù air get filled through other means, but for now let‚Äôs close things up by tweaking the pressure in the rear part of the airfoil:&lt;/p&gt;
    &lt;p&gt;Some amount of positive pressure in the rear prevents the air parcels from smashing into each other after leaving the airfoil. Intuitively, this pressure arises naturally from the flow, because as the air slides off from the ends of the top and bottom sides, it all arrives into the same region, creating some compression.&lt;/p&gt;
    &lt;p&gt;If that compressive pressure in the rear is too low, more air will manage to get in, which will further increase the pressure. If that pressure is too high, it will push the incoming air away, which depletes the area and the pressure decreases. The system balances itself yet again.&lt;/p&gt;
    &lt;p&gt;The quite informal description of these balances that I‚Äôve presented can be formalized mathematically using the Navier√¢Stokes equations. These equations describe the motion of liquids and gasses, collectively known as fluids, subject to various forces like gravity, or, most importantly for us, pressure.&lt;/p&gt;
    &lt;p&gt;Navier√¢Stokes equations are notoriously difficult to solve analytically, but a lot of insight about the behavior of fluids can be gained with computer simulations with various degrees of complexity.&lt;/p&gt;
    &lt;p&gt;In this article, I‚Äôm also employing simulations to investigate the flow of air around objects. However, the computer models used here are quite simplified and they don‚Äôt reflect the full richness of physics involved in the motion of air. These slow-motion demonstrations are intended to present the broad strokes of the delicate interaction between the air and the airfoil, but I would advise against relying on them when building an airworthy airplane.&lt;/p&gt;
    &lt;p&gt;With all of these caveats in place, let‚Äôs get back to the pressure distribution around a symmetric airfoil. We‚Äôre done recreating the nature-made pressure field, but there is one small aspect that we haven‚Äôt yet accounted for.&lt;/p&gt;
    &lt;p&gt;For our experiments, I kept the pressure steady in time so that we could focus on its general outlines. In practice, a pressure field imposed by a fast flow around any object will experience some degree of instability, which you can see in the demonstration below. You can once more drop the markers at any location to track the flow in the area:&lt;/p&gt;
    &lt;p&gt;As the pressure builds up on one side, it redirects the flow, which changes the pressure again. The pressure ends up oscillating back and forth like a swing. The pressure distribution and the flow direction are once again at the mercy of their mutual balance, one affecting the other. We‚Äôll soon see some other examples of these unstable behaviors.&lt;/p&gt;
    &lt;p&gt;As we‚Äôve just seen, the variation in pressure doesn‚Äôt just happen in the close vicinity of the airfoil, but it stretches quite far away from the body itself. This means that the velocity of the flow is also affected quite far away from the shape.&lt;/p&gt;
    &lt;p&gt;However, when it comes to the forces exerted on the airfoil, it‚Äôs only the pressure right at the surface of the airfoil that matters. Let‚Äôs bring back the two tools we‚Äôve used before: surface arrows that show how the air pushes or ‚Äúpulls‚Äù on the airfoil, and the net force arrow that tallies up the net results of these forces:&lt;/p&gt;
    &lt;p&gt;As the pressure field fluctuates, the resulting net force also moves around. Let‚Äôs decompose this force into two different components, one perpendicular to the flow, and one parallel to it:&lt;/p&gt;
    &lt;p&gt;The force acting in the direction perpendicular to the flow is known as lift, and the one acting in the direction of the flow is known as pressure drag, or form drag. As the name implies, this component of drag is created by the distribution of pressure around the shape.&lt;/p&gt;
    &lt;p&gt;For this airfoil, the pressure drag is very tiny. While airfoils are specifically designed to minimize the overall drag, most of that force hindering their motion comes from another source √¢ we‚Äôll discuss it soon enough.&lt;/p&gt;
    &lt;p&gt;Notice that as this flow fluctuates, the lift force jumps around, but averaged over time the upward and downward swings of that force end up balancing each other. This airfoil in this configuration doesn‚Äôt generate any continuous lift.&lt;/p&gt;
    &lt;p&gt;This shouldn‚Äôt come as a surprise since this situation is completely symmetric, so the pressure forces on the upper and lower sides of the airfoil are, on average, completely balanced. However, there is an easy way to disturb that symmetry. In the demonstration below, we‚Äôre once again meeting the plain, symmetric airfoil, but this time we can gently tilt it using the slider:&lt;/p&gt;
    &lt;p&gt;The slider controls the so-called angle of attack, which is spanned between some reference line on the body, like the one joining the front and back, and the direction of the incoming flow. I‚Äôm showing this angle right in the middle of the airfoil.&lt;/p&gt;
    &lt;p&gt;As we change the angle of attack, the shape that the airflow ‚Äúsees‚Äù is no longer symmetrical relative to the incoming direction of that flow. The velocity and pressure fields adapt in their mutual push and pull to form a new, asymmetric distribution. Notice that the stagnation point of high pressure has moved around, and the little markers that indicate the motion of air now travel on very different paths below and above and below the airfoil.&lt;/p&gt;
    &lt;p&gt;If we then put the pressure arrows back in, we can tally them all up to get the resulting lift and pressure drag. When compared to the previous simulation, I‚Äôm scaling down all the arrows to make them fit in the bounds of the demonstration:&lt;/p&gt;
    &lt;p&gt;When this symmetric airfoil is tilted up, the asymmetric pressure distribution generates a lift force that pushes the object up. Conversely, for a downward tilted airfoil, the pressure forces push the airfoil down.&lt;/p&gt;
    &lt;p&gt;Naturally, we‚Äôre typically interested in upward-pointing forces, and when the lift generated by the wings is equal to the weight of the plane, the plane will stay in the air without raising or falling to the ground √¢ we‚Äôre finally flying.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs plot the dependence between the lifting force and the angle of attack of an airfoil √¢ you can see it in the right side of the demonstration below. Note that this plot presents time-averaged and settled values, so you may have to wait a little for the flow to normalize and the lift to start oscillating around the expected value:&lt;/p&gt;
    &lt;p&gt;Clearly, as the angle of attack increases, so does the generated lift. The same thing happens on the other end of the spectrum, where a more negative angle of attack creates more negative lift. Note that for this symmetric airfoil the positive and negative sides of the diagram are just mirror images of each other, so let‚Äôs focus only on positive angles of attack.&lt;/p&gt;
    &lt;p&gt;One could naively hope that we could keep increasing the angle of attack to generate more and more lift. Let‚Äôs see what happens in practice:&lt;/p&gt;
    &lt;p&gt;Initially, the lift force indeed keeps increasing with the angle of attack, but at some point it plateaus. Once that critical angle of attack is surpassed, the lift force starts to fall after the flow fully develops.&lt;/p&gt;
    &lt;p&gt;What we‚Äôre witnessing here is known as a stall. The onset of a stall imposes limits on how much lift the wings of an airplane can generate from merely increasing the angle of attack.&lt;/p&gt;
    &lt;p&gt;Notice that when the stall happens, the pressure distribution on the upper part of the airfoil becomes very erratic √¢ it‚Äôs not only the surface pressure arrows that are changing rapidly, but the whole pressure field in that area is very disturbed.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs bring in the velocity arrows and markers to get a better feel on what‚Äôs going on in that region:&lt;/p&gt;
    &lt;p&gt;At high angles of attack, the flow above the upper part of the airfoil becomes very complicated. If you clicktap in that region to drop a few markers, you‚Äôll notice that the air is trapped in various swirling eddies that are eventually shed to fly away with rest of the flow.&lt;/p&gt;
    &lt;p&gt;We‚Äôre witnessing flow separation, where the main part of the flow detaches from the surface and doesn‚Äôt follow its shape anymore. The interactions in the complicated flow right above the airfoil affect the pressure field, which then decreases lift.&lt;/p&gt;
    &lt;p&gt;There is a lot going on there, but to understand how these effects arise we have to talk about a property that affects the flow of every fluid: viscosity.&lt;/p&gt;
    &lt;head rend="h1"&gt;Viscosity&lt;/head&gt;
    &lt;p&gt;You might have heard the term viscosity used to describe ‚Äúthickness‚Äù of different liquids, with a classic example that contrasts the slowness of the flow of honey to the rapidness of the flow of water.&lt;/p&gt;
    &lt;p&gt;Viscosity is also a property of gasses like air, but before I describe this concept more formally, we‚Äôll first build an intuitive understanding of what viscosity is and what it does to the flow of different fluids.&lt;/p&gt;
    &lt;p&gt;In the demonstration below, the fluid flows in from the left side, but note that the flow in the top half is faster than the flow in the bottom half, which is reflected by the different lengths of the arrows. Dragging the slider to the left decreases the viscosity of the fluid, and dragging the slider to the right increases viscosity:&lt;/p&gt;
    &lt;p&gt;While we can see some changes to the arrows as we move the slider around, you probably agree that, for this flow, the arrow-based visualization isn‚Äôt very rewarding. Let‚Äôs add the color-based visualization of speed distribution in this flow:&lt;/p&gt;
    &lt;p&gt;We can now see how viscosity blends the speed variation between different sections of the fluid. For highly viscous fluids, this mixing behavior spreads very easily and the initially distinct velocities of the two layers average out quite rapidly.&lt;/p&gt;
    &lt;p&gt;At lower viscosity these two layers with different speeds remain quite separated. If you make the viscosity low enough, you may even notice that, after a while, the flow develops some interesting wave-like phenomena √¢ we‚Äôll get back to these soon.&lt;/p&gt;
    &lt;p&gt;All this mixing behavior may remind you of a diffusion process, where some quantity, like temperature or concentration, evens out over time. Let‚Äôs see some basic diffusion in action. In the simulation below, I filled half of the bottle with with red-dyed water, while the other half is filled with blue-dyed water. The slider lets you control the speed of time:&lt;/p&gt;
    &lt;p&gt;As time passes, the sharp difference between the two layer blends more and more to eventually completely disappear. Clearly, there is some similarity between the diffusion of differently colored dyes and the averaging of velocity that we‚Äôve seen in the earlier example.&lt;/p&gt;
    &lt;p&gt;In our flow demonstrations, viscosity seemed to have controlled the diffusion of velocity. To define it more precisely, viscosity controls the diffusion of momentum, which is a product of velocity and mass. The simplified fluids we‚Äôre looking at have more or less constant density, so each equally-sized parcel of those fluids has the same mass. Therefore, if it makes things easier for you, wherever you see the word momentum you can think of velocity, but in more complex scenarios these differences can matter.&lt;/p&gt;
    &lt;p&gt;Let me bring in the previous flow simulation one more time:&lt;/p&gt;
    &lt;p&gt;You‚Äôve probably noticed that, as the flow moves to the right, the size of this blended region increases. When the regions of fluid with different momentums meet for the first time, they barely have any time to average out, and the blending is minimal. As time passes, these regions of fluid get to average out more, similarly to how two different layers of dyed water mix more over time.&lt;/p&gt;
    &lt;p&gt;However, as time is passing, these parcels also keep moving, and that stronger blending happens further to the right. The downstream regions had more time to mix and average out, so the visible thickness of the blended region on the right side is also larger.&lt;/p&gt;
    &lt;p&gt;With higher viscosity, the size of blended region grows much more quickly, which lets us be more precise about our working definition √¢ viscosity controls the rate of the diffusion of momentum.&lt;/p&gt;
    &lt;p&gt;So far we‚Äôve only observed flows with nicely separated horizontal layers, but viscosity averages momentum between any two regions of fluids. In the demonstration below, you can witness how viscosity affects a swirly motion of fluid in a vortex:&lt;/p&gt;
    &lt;p&gt;Notice that with high viscosity any differences in velocity are very quickly diluted out into nothing, but with low viscosity the revolving motion can survive for quite a while.&lt;/p&gt;
    &lt;p&gt;Viscosity has a damping or smoothing effect that makes it much harder to sustain any large variation in a velocity field. Let‚Äôs see how this affects the motion of objects in fluids of various viscosity. In the demonstration below, we‚Äôre tracking a velocity field close to a very thin plate put directly in the stream of an incoming fluid of adjustable viscosity:&lt;/p&gt;
    &lt;p&gt;With high viscosity, there is a large region of slow down around the plate that regains its speed fairly quickly behind the object. At lower viscosity that surrounding region is much smaller, but it extends much further behind the plate. For very low viscosity we‚Äôre once again seeing some more unusual behavior that we‚Äôll get back to in a minute.&lt;/p&gt;
    &lt;p&gt;From the dark colors we can easily see that right by the surface of the plate the fluid doesn‚Äôt move at all √¢ it sticks to that surface. This velocity difference between the halted flow at the wall and the moving outer flow gets smoothed out over time by viscosity, similar to how it blended in the flow between two different layers of fluid.&lt;/p&gt;
    &lt;p&gt;As before, with higher viscosity, the velocity averaging process becomes more rapid, and the blended region becomes more widespread. This averaging effect doesn‚Äôt just alter the velocity of fluid, but it also affects the plate. In some sense, the viscosity also wants to make the velocity of the surface of the plate to be more like the velocity of the surrounding flow.&lt;/p&gt;
    &lt;p&gt;The viscosity makes the flow want to pull the plate with it, which creates a shearing force that tries to slide the surface of this object away. The net effect is that that viscosity creates additional drag known as skin friction drag that wants to slow down any object moving in it.&lt;/p&gt;
    &lt;p&gt;All of these effects underline why highly viscous fluids are ‚Äúthick‚Äù. Viscosity not only quickly averages any local differences in velocity, which prevents those fluids from flowing easily, but it also represses motion of objects in those fluids √¢ you‚Äôve likely experienced the difficulty of moving a spoon through a jar of honey.&lt;/p&gt;
    &lt;p&gt;The flow of any fluid exhibits tiny, random disturbances. In fluids with high viscosity, these variations are very quickly dispersed, so their motion is rarely erratic. Fluids with low viscosity aren‚Äôt as effective at damping motion, and these disturbances can grow to create oscillatory patterns. We‚Äôve seen glimpses of them in the previous simulations, but here is another example:&lt;/p&gt;
    &lt;p&gt;At lower viscosity the flow becomes quite wave-y. Those instabilities happen at the border of regions of fluid with different velocities, like where the slow wake behind a plate is in contact with the fast external flow. In those regions, any tiny random intrusion of slower flow into the faster flow can get magnified and rolled over like a wave.&lt;/p&gt;
    &lt;p&gt;In our discussion of the motion of air around an airfoil, we‚Äôve seen how the flow, the pressure field, and the shape of the body have effects on each other. These influences can be quite dynamic in nature, with distributions of velocity and pressure swinging back and forth in a never-ending fight for dominance.&lt;/p&gt;
    &lt;p&gt;In the demonstration below, we can see a more dramatic example of these battles, where, depending on the viscosity, the flow around a gray cube can take many different forms:&lt;/p&gt;
    &lt;p&gt;With very high viscosity, the flow is completely stable, but as viscosity decreases, it starts to regularly oscillate from side to side, shedding vortices in the process. At very low viscosity, the motion becomes even more erratic.&lt;/p&gt;
    &lt;p&gt;While I can‚Äôt easily simulate it here, with further decrease in viscosity, the flow can develop full featured turbulence in which highly irregular and chaotic mixing motions occur at different scales. Turbulent flow stands in contrast to laminar flow, in which neighboring areas of fluid move in an orderly way past each other without any varying fluctuations.&lt;/p&gt;
    &lt;p&gt;Although we‚Äôve put most of our focus on viscosity, which is often denoted with the Greek letter √é¬º, the general behavior of the flow also depends on its velocity u, density √è, and the size L of the body or container involved in the flow. These parameters are tied together by the Reynolds number Re:&lt;/p&gt;
    &lt;p&gt;Flows with the same Reynolds numbers exhibit similar behavior, which means that if we make the obstacle size L twice as large and we halve the speed of the flow u, the Reynolds number won‚Äôt change and neither will the characteristics of the flow √¢ it will exhibit the same smooth or oscillatory motion.&lt;/p&gt;
    &lt;p&gt;The Reynolds number also ‚Äúpredicts‚Äù the onset of turbulence. When we increase the speed of the flow u, or decrease the viscosity √é¬º, the Reynolds number rises. When it reaches a high enough value, turbulence is likely to occur.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs quantify the difference in viscosity between different fluids. The precise values aren‚Äôt that important to us, but to briefly be a bit more formal, viscosity is expressed in units of pascal-seconds, or Pa√Ç¬∑s. To let us use more manageable numbers, the following table uses millipascal-seconds, or mPa√Ç¬∑s:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;honey&lt;/cell&gt;
        &lt;cell&gt;~10000 mPa¬∑s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;olive oil&lt;/cell&gt;
        &lt;cell&gt;~100 mPa¬∑s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;water&lt;/cell&gt;
        &lt;cell&gt;1.0 mPa¬∑s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;air&lt;/cell&gt;
        &lt;cell&gt;0.018 mPa¬∑s&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;These values are measured at 68 √Ç¬∞F20 √Ç¬∞C, but many fluids like oil get much less viscous with increased temperature. As expected, honey is significantly more viscous than water. Compared to water, the viscosity of air is around 50 times less still, but even a very low viscosity has effects on flow and its interaction with solid walls.&lt;/p&gt;
    &lt;p&gt;To understand how viscosity arises in gasses like air, we have to once more get back to the world of particles. So far we‚Äôve been watching them from a distance, with individual collisions barely perceptible in the moving swarm. This time we‚Äôre going take a closer look at these interactions.&lt;/p&gt;
    &lt;p&gt;In the demonstration below, you can experience a simplified simulation of two molecules colliding in space. Each molecule represents nitrogen or oxygen √¢ these two elements constitute the vast majority of air, and, in normal conditions, each one consists of two atoms.&lt;/p&gt;
    &lt;p&gt;You can drag the orange particle around, and once you let go I‚Äôll automatically aim it so that it hits the blue particle. The speed of the orange molecule is four times larger than the speed of the blue one:&lt;/p&gt;
    &lt;p&gt;Notice that after the collision, it‚Äôs the orange molecule that‚Äôs slow, and it‚Äôs the blue one that‚Äôs fast. In this demonstration the two particles have the same mass and they collide straight on, so they simply end up trading velocities.&lt;/p&gt;
    &lt;p&gt;More generally, particles of different masses that strike each other at different angles will exchange some amount of momentum. Recall that the heavier the particle, or the faster it moves, the higher its momentum.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs see how this behavior ends up affecting the average velocities of larger quantities of molecules. In the paused demonstration below, air molecules are grouped into two different parts. The air in the blue region has higher velocity than the air in the red region, which you can see in the black arrows showing the average velocity in those regions. Notice what happens to these averages as you let time flow by dragging the slider:&lt;/p&gt;
    &lt;p&gt;At the very beginning, the average velocities in these two sections are visibly different, but they quickly even out when fast particles from the blue region flow into the slower red region, and the slower particles from the red region move into the faster blue region, balancing the initial velocity differences.&lt;/p&gt;
    &lt;p&gt;Moreover, some of the faster particles collide with slower particles in the red region and some of the slower particles collide with faster particles from above. The faster particles lose some of their higher momentum, while the slower particles gain some of the momentum. All of these effects ‚Äúdilute‚Äù some of those average velocity differences between the two regions.&lt;/p&gt;
    &lt;p&gt;You may also remember that when we observed a flow of fluid around a flat plate, that fluid wasn‚Äôt moving at all right on the surface of that plate, because it was stuck to it. Let‚Äôs see how this behavior may arise on a microscopic scale.&lt;/p&gt;
    &lt;p&gt;In the demonstration below, we‚Äôre watching the familiar air particles right next to the surface of an object. To make tracking easier, I‚Äôm highlighting some of the particles in the vicinity of this surface:&lt;/p&gt;
    &lt;p&gt;When seen at a very large magnification, this surface, like almost all surfaces, isn‚Äôt perfectly smooth and has various peaks and valleys. The particles hitting these irregularities get bounced in more or less random directions. Some of the unlucky molecules can even get stuck for a while in these local crevices.&lt;/p&gt;
    &lt;p&gt;Close to the surface, the random collisions with peaks and valleys prevent the particles from making bulk progress in any direction. The average velocity of the air flow by the wall is more or less zero. Some molecular interactions between the particles and the surface can also prevent the fluid from moving.&lt;/p&gt;
    &lt;p&gt;This sticking behavior is known as the no√¢slip condition and it holds true for most typical flows of fluids that we experience day to day. It‚Äôs only in extreme conditions of very rarified gasses in the upper parts of the atmosphere or flows in microscopic capillaries that can break this assumption.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs leave the world of particles behind for the last time and see how these two effects play an important role of influencing the airflow close to the surface of any object.&lt;/p&gt;
    &lt;head rend="h1"&gt;Boundary Layer&lt;/head&gt;
    &lt;p&gt;Let‚Äôs take another look at a thin plate placed in the stream of incoming fluid:&lt;/p&gt;
    &lt;p&gt;From this broader perspective, it‚Äôs hard to see how the flow interacts with the surface of that plate, because the effects of viscosity are limited to the region close to that surface. Let‚Äôs focus our attention on the small area that I‚Äôve outlined with a dashed line, right in the top part of the plate. Here it is zoomed up close:&lt;/p&gt;
    &lt;p&gt;We can once more see that, due to the no-slip condition, the velocity is zero at the wall, and then it grows to meet the velocity of the flow further away from the surface itself. What we‚Äôre seeing here is known as the boundary layer, which spans the region between the surface of the object and the ‚Äúouter‚Äù flow, which is mostly unaffected by the presence of the object.&lt;/p&gt;
    &lt;p&gt;Because the velocity in the boundary layer smoothly approaches the speed of the outer flow, it doesn‚Äôt have a well-defined end point. One of the choices is to agree that the boundary layer ends where the speed reaches 99% of the speed of the surrounding flow far away from the solid surface. Let me visualize this boundary in the flow using a dashed line:&lt;/p&gt;
    &lt;p&gt;As we move with the flow along the distance of the plate, the viscosity keeps averaging out the velocity differences, making the boundary layer thicker √¢ this is similar to what we‚Äôve seen at larger scales with highly viscous flows around objects.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs quantify the distribution of speed in the boundary layer a little more precisely. In the demonstration below, I put the velocity arrows back in. I then connected the ends of these arrows with a thin line to show a profile of velocity at that location along the surface:&lt;/p&gt;
    &lt;p&gt;Notice that, initially, the velocity close to the wall increases almost linearly, but then it smoothly tapers to reach the speed of the external flow. The velocity profile close to the surface has a certain steepness, which I‚Äôm showing with the white dotted line. This line determines the amount of skin friction drag at that spot √¢ the closer to the surface, or more horizontal, the line is, the higher the skin drag.&lt;/p&gt;
    &lt;p&gt;As the differences in velocity become less severe, the force with which viscosity wants to drag the surface with the flow also decreases. In the conditions present in the demonstration, the skin friction drag decreases over distance.&lt;/p&gt;
    &lt;p&gt;At this point you hopefully have an intuitive grasp of how viscosity affects the flow close to the surface of the object. From our earlier discussion, you may also remember that pressure differences also affect how the flow behaves, with parcels of air slowing down when climbing the hill of increasing pressure and accelerating on the downhill of the decreasing pressure.&lt;/p&gt;
    &lt;p&gt;In the boundary layer flows we played with, the pressure distribution was more or less constant in the investigated region. Let‚Äôs see how the flow changes when we vary that pressure.&lt;/p&gt;
    &lt;p&gt;In the top part of the demonstration below we see the exact same view of velocity we‚Äôve experimented with so far. In the bottom part of the demonstration below you can see the pressure distribution in the boundary layer, which you can change using the slider below.&lt;/p&gt;
    &lt;p&gt;If the pressure decreases in the direction of the flow in the boundary layer, we say that the pressure gradient is favorable. Favorable pressure gradient accelerates the air, and the boundary layer doesn‚Äôt grow as quickly, since the slowdown caused by viscosity is opposed by that acceleration.&lt;/p&gt;
    &lt;p&gt;When the pressure increases in the direction of the flow, we say that the pressure gradient is adverse. Adverse pressure gradient pushes against the direction of motion of the air. Far away from the surface, the air has enough momentum that the adverse pressure merely slows the flow down. However, close to the surface, the flow in the boundary layer was slow in the first place, so a pushing adverse pressure gradient may even reverse the direction of the flow.&lt;/p&gt;
    &lt;p&gt;When the flow in the boundary layer gets reversed, we say that the boundary layer separates. This region of reversed flow can form a sort of wedge that can lift the rest of the flow away from the surface.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs take a step back from the subtleties of boundary layers to see how what we‚Äôve learned corresponds to behavior of a flow around an airfoil. Let me once more bring up the demonstration that brought us here in the first place:&lt;/p&gt;
    &lt;p&gt;As we move across the surface of the airfoil, the high pressure at the stagnation point up front gradually decreases to reach minimum close to the ‚Äúpeak‚Äù of that curved surface. Across this transition the pressure gradient is favorable, and that distribution works in our favor √¢ the boundary layer stays nicely attached to the surface.&lt;/p&gt;
    &lt;p&gt;However, as the air reaches the valley of the lowest pressure, it then has to start climbing back up to reach the slightly positive pressure in the rear of the airfoil. For small values of the angle of attack, the pressure pit from which the air has to climb out is not very deep and the adverse pressure gradient isn‚Äôt very strong, so the boundary layer remains attached.&lt;/p&gt;
    &lt;p&gt;As we increase the angle of attack of the airfoil, the pressure on top becomes lower and lower. For even higher angles, the adverse pressure gradient becomes so strong that it eventually reverses the flow in the boundary layer, creating separation. Let‚Äôs look at this region up close to see how the arrows of velocity in the separated region point in the other direction:&lt;/p&gt;
    &lt;p&gt;If you clicktap to add markers in the bottom right corner of the simulation you‚Äôll notice that many of them move against the bulk of the flow √¢ the boundary layer and the flow have separated.&lt;/p&gt;
    &lt;p&gt;We‚Äôll get back to looking at airfoils soon enough, but we still have a few things to wrap up in the world of boundary layers.&lt;/p&gt;
    &lt;p&gt;The boundary layers we‚Äôve looked at so far were laminar √¢ the layers of fluid with different velocities flowed in an orderly way on top of each other. However, at higher flow speeds and over larger distances, or at high Reynolds numbers, the flow in the boundary layer transitions to a turbulent flow:&lt;/p&gt;
    &lt;p&gt;Be aware that what you‚Äôre seeing here is a very simplified simulation of a turbulent boundary layer. Turbulence is inherently three dimensional and it contains various evolving structures of different sizes that are extremely computationally expensive to evaluate in detail. Thankfully, you can find many videos of computer simulations and real flows showing turbulent boundary layers.&lt;/p&gt;
    &lt;p&gt;While the laminar boundary layers we‚Äôve seen in the past exhibited very organized flows, the turbulent one is very chaotic, with large and small swirls causing the flow to mix very rapidly. The transition from laminar to turbulent boundary layer happens spontaneously, but for a given flow speed, the location of the transition depends on surface roughness, steadiness of the flow outside of the boundary layer, and presence of pressure gradients.&lt;/p&gt;
    &lt;p&gt;At any given moment, the velocity profile in the turbulent boundary layer is very unsteady, but it can be averaged over time to get the mean distribution of speed. Let‚Äôs compare the time-averaged profiles of the laminar and turbulent boundary layers:&lt;/p&gt;
    &lt;p&gt;In the dynamic simulation of the turbulent boundary layer, we saw how the slower flow close to the surface rapidly mixed with the upper regions of the flow. This slows down those faster sections, and we need to go farther away from the surface for these sluggish intrusions to stop affecting the flow. For this reason, the turbulent boundary layer is thicker and grows faster than a laminar boundary layer.&lt;/p&gt;
    &lt;p&gt;On the other hand, the strong turbulent mixing causes the fast external flow to get close to the body, so the overall velocity profile by the surface increases much more quickly in the turbulent case as opposed to laminar case √¢ I‚Äôm showing that with white dotted lines.&lt;/p&gt;
    &lt;p&gt;Recall that the more horizontal the velocity profile at the surface of the object, the bigger the skin friction drag √¢ a turbulent boundary layer has higher skin friction drag than a laminar layer. Despite the cost of increased friction drag, a turbulent boundary layer is often beneficial.&lt;/p&gt;
    &lt;p&gt;Because of that higher velocity closer to the surface, a turbulent boundary layer is more resistant to adverse pressure gradients and it can stay attached to the surface of an object for longer distances.&lt;/p&gt;
    &lt;p&gt;For some objects like golf balls, which purposefully make their boundary layer turbulent by roughing up the surface with little dimples, the delayed separation also decreases the pressure drag caused by uneven pressure distribution. That reduction more than compensates for the increased skin friction drag, making the dimply golf balls fly farther than equivalent smooth balls.&lt;/p&gt;
    &lt;p&gt;For airfoils, a turbulent boundary layer delays separation of the flow, which can help prevent stall at higher angles of attack, but at normal cruising conditions the increased skin friction becomes an important drawback. For many aerodynamic shapes in typical conditions, the skin friction drag is the primary contributor to the total drag that these objects experience.&lt;/p&gt;
    &lt;p&gt;As we‚Äôve seen, by increasing the angle of attack on an airfoil, the lift force grows up to a certain limit, at which the boundary layer separates over most of the upper surface. By staying under this limit, a symmetric airfoil can safely generate lift force.&lt;/p&gt;
    &lt;p&gt;However, when it comes to angle of attack and lift, the shape of an airfoil isn‚Äôt particularly unique in its lift-creation capabilities. Most simple elongated shapes generate lift when put in a flow at an angle of attack. In the demonstration below, you can tilt a flat plate and see the forces exerted by the pressure field around it:&lt;/p&gt;
    &lt;p&gt;You may be surprised to see that, at small angles of attack, this flat plate also generates lift. An airfoil-like shape is not a requirement for lift generation. After all, paper airplanes with their flat wings can fly just fine. Lift is just an outcome of the pressure distribution created and sustained by the flow.&lt;/p&gt;
    &lt;p&gt;Although it doesn‚Äôt take a sophisticated shape to generate lift at an angle of attack, a well-designed airfoil can often create more lift and with lower drag. In the last section of this article, we‚Äôll explore how other variations to the shape of an airfoil can affect its characteristics.&lt;/p&gt;
    &lt;head rend="h1"&gt;Airfoil Shapes&lt;/head&gt;
    &lt;p&gt;Let‚Äôs go back to the simple symmetric airfoil we‚Äôve been playing with thus far. This time, however, we‚Äôre able to control its thickness using the slider:&lt;/p&gt;
    &lt;p&gt;Notice that as we increase the thickness of the airfoil, the pressure on the top and bottom sections of the shape becomes more negative. For this symmetric airfoil at 0√Ç¬∞ angle of attack the thickness doesn‚Äôt change much other than increasing the pressure drag.&lt;/p&gt;
    &lt;p&gt;However, if we break the symmetry of the shape, we can use thickness-dependence to make one side of the airfoil have a higher negative pressure than the other. In the demonstration below, you can control the ‚Äúthickness‚Äù of the upper surface of the airfoil using the slider:&lt;/p&gt;
    &lt;p&gt;Notice that an asymmetric shape creates an asymmetric pressure distribution, which ends up creating lift without any changes to angle of attack. With some slight tweaking of this shape we finally recreated the asymmetric shape we first saw on the airplane in the early sections of this article.&lt;/p&gt;
    &lt;p&gt;Naturally, when combined with an increasing angle of attack, this airfoil will generate even more lift until it eventually reaches stalling conditions:&lt;/p&gt;
    &lt;p&gt;While symmetric airfoils are sometimes used in acrobatic airplanes, which often find themselves flying upside down, most typical planes use an asymmetric airfoil shape.&lt;/p&gt;
    &lt;p&gt;The underlying mechanism of lift generation by changing the angle of attack or by shaping the object differently is ultimately the same √¢ we‚Äôre changing the placement and orientation of the surface of the body relative to the incoming flow. The flow reacts by changing the velocity and pressure distribution, and the resulting pressure field creates the forces on that object.&lt;/p&gt;
    &lt;p&gt;This all means that we have a lot of flexibility in how an airfoil is shaped, as long as the resulting pressure distribution fulfills the design goals of achieving a certain amount of lift while minimizing drag.&lt;/p&gt;
    &lt;p&gt;For example, in some applications it‚Äôs important to minimize the skin friction drag caused by a turbulent boundary layer. Some laminar flow airfoils achieve this by shaping the airfoil to move the ‚Äúpit‚Äù of negative pressure further to the back of the airfoil:&lt;/p&gt;
    &lt;p&gt;The favorable pressure gradient between the front and the lowest pressure point extends over a longer distance across the surface of this airfoil, which, at least in principle, helps to keep the boundary layer laminar to keep the skin friction low.&lt;/p&gt;
    &lt;p&gt;Notice that even this unusual airfoil had a rounded front and a sharp back. The roundness of the front helps the air smoothly flow around this area at different angles of attack, and the sharp back reduces the pressure drag by avoiding the separation of the flow.&lt;/p&gt;
    &lt;p&gt;The velocity of the flow around the airfoil is also a contributing factor to the design of the shape. Let‚Äôs look at the speed distribution in the flow around a simple asymmetric airfoil using the varying colors and markers:&lt;/p&gt;
    &lt;p&gt;The flow above the airfoil is faster than the incoming flow as indicated by brighter colors. The markers that start in the same line don‚Äôt end up sliding off the airfoil in the same formation √¢ the ones on top are further ahead. This is particularly visible for larger values of the angles of attack.&lt;/p&gt;
    &lt;p&gt;This acceleration in the upper part becomes another point of consideration for airfoil design. While commercial airliners don‚Äôt fly faster than the speed of sound, the accelerated flow in the top part of an airfoil can break that barrier. This creates a shockwave that can sometimes be seen in flight. Modern airliners use supercritical airfoils that are designed to reduce these drag-causing shockwaves by carefully controlling the speed of the flow around the wing.&lt;/p&gt;
    &lt;p&gt;Planes designed to fly above the speed of sound use supersonic airfoils that are quite different from the shapes we‚Äôve seen. These airfoils have a thin profile and their front edge is sharp and not rounded. Supersonic flows of air are more complicated than what we‚Äôve explored in this article, as variations in density and temperature become an important component of the behavior of the flow.&lt;/p&gt;
    &lt;p&gt;Many of the airfoils used today are designed specifically for the plane they‚Äôll be used in. Moreover, that cross-sectional shape may change across the length of the wing. Real airplanes are three dimensional and the overall shape of the wings also significantly affects the lift and drag of an airplane, but ultimately all the resulting forces are an outcome of interactions between the flow and the body.&lt;/p&gt;
    &lt;head rend="h1"&gt;Further Reading and Watching&lt;/head&gt;
    &lt;p&gt;John Anderson‚Äôs Fundamentals of Aerodynamics is a very well-written textbook on aerodynamics. Over the course of over a thousand pages, the author presents a classic exposition of the motion of fluids and their interactions with bodies put in those flows.&lt;/p&gt;
    &lt;p&gt;Understanding Aerodynamics by Doug McLean is a great textbook that takes a different approach of explaining aerodynamic phenomena using physical reasoning. For me, the crowning achievement of the publication is showing that many popular explanations of the origins of lift are either incorrect or they‚Äôre based on merely mathematically convenient theorems. The author‚Äôs video lecture gives an overview of some of these misconceptions.&lt;/p&gt;
    &lt;p&gt;In this article, I‚Äôm using computational fluid dynamics to simulate the flow of air around different objects. For an approachable introduction to these methods I enjoyed Tony Saad‚Äôs series of lectures on the topic. For an alternative, and slightly more rigorous approach, Lorena Barba created 12 steps to Navier-Stokes. That website is also accompanied by video lectures.&lt;/p&gt;
    &lt;p&gt;Finally, YouTuber braintruffle created a series of beautiful videos that start with the behavior of fluids on a quantum scale and build up increasingly abstract models that can be used in more practical applications. The videos are packed with interesting takes on fluid mechanics, and they‚Äôre worth watching for their visuals alone.&lt;/p&gt;
    &lt;head rend="h1"&gt;Final Words&lt;/head&gt;
    &lt;p&gt;If you were to sit on a flying airplane and look out the window to glance at its wings, you‚Äôd often have a hard time seeing anything going on. However, in that crisp clearness of air whose invisible flow sustains the varied pressure field, lies the hidden source of lift that overcomes the might of gravity to keep the plane safely above the ground.&lt;/p&gt;
    &lt;p&gt;Since the first human flight, we‚Äôve now mastered the art of soaring in the skies by bending the flow of air to our will, using physical quantities like pressure and velocity to help shape our designs. These tangible concepts are ultimately just a manifestation of motions and collisions of billions of inanimate air particles that somehow conspire to assemble the forces we need.&lt;/p&gt;
    &lt;p&gt;I hope this deeper, technical exploration of airfoils hasn‚Äôt diminished your appreciation of the greatness of flight. Perhaps paradoxically, by seeing how all the pieces fit together, you‚Äôll find the whole thing even more magical.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46795908</guid><pubDate>Wed, 28 Jan 2026 14:32:30 +0000</pubDate></item><item><title>Show HN: Config manager for Claude Code (and others) ‚Äì rules, MCPs, permissions</title><link>https://github.com/regression-io/coder-config</link><description>&lt;doc fingerprint="3e35c65f95a7a87e"&gt;
  &lt;main&gt;
    &lt;p&gt;A configuration manager for AI coding tools. Works with Claude Code, Gemini CLI, Codex CLI, and Antigravity.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Migration note: This package was renamed from&lt;/p&gt;&lt;code&gt;@regression-io/claude-config&lt;/code&gt;to&lt;code&gt;coder-config&lt;/code&gt;. The&lt;code&gt;claude-config&lt;/code&gt;command still works as an alias.&lt;/quote&gt;
    &lt;p&gt;AI coding assistants are powerful, but managing their configuration across projects is tedious. Each tool has its own config format. MCP servers need to be set up per-project. Context gets lost between sessions. Working across multiple repos means re-explaining relationships every time.&lt;/p&gt;
    &lt;p&gt;Workstreams Group related repos together. When a workstream is active, Claude automatically knows which directories it can access and receives your custom context. Useful for microservices, monorepos, or any multi-repo workflow where projects relate to each other.&lt;/p&gt;
    &lt;p&gt;Unified MCP Registry Define your MCP servers once in a global registry. Enable them per-project with a toggle. Configuration inherits from global ‚Üí workspace ‚Üí project, so common tools are always available while project-specific ones stay scoped.&lt;/p&gt;
    &lt;p&gt;Hierarchical Rules Rules cascade from &lt;code&gt;~/.claude/rules/&lt;/code&gt; down to project-specific rules. Global conventions apply everywhere; project-specific instructions stay local.&lt;/p&gt;
    &lt;p&gt;Persistent Memory Store preferences, corrections, and patterns that persist across sessions. When you tell Claude "always use our logger instead of console.log," it remembers ‚Äî not just for this session, but permanently.&lt;/p&gt;
    &lt;p&gt;Plugin System Install LSP servers, MCP tools, and custom commands from plugin marketplaces. Plugins can be scoped globally or per-project.&lt;/p&gt;
    &lt;p&gt;Multi-Tool Output Write one config, generate outputs for Claude Code (&lt;code&gt;.mcp.json&lt;/code&gt;), Gemini CLI (&lt;code&gt;settings.json&lt;/code&gt;), Codex CLI (&lt;code&gt;config.toml&lt;/code&gt;), and Antigravity. Switch tools without reconfiguring.&lt;/p&gt;
    &lt;p&gt;Web UI Visual interface for managing everything above. File explorer for &lt;code&gt;.claude&lt;/code&gt; folders, MCP toggles, memory editor, workstream management. Runs locally on port 3333.&lt;/p&gt;
    &lt;code&gt;npm install -g coder-config&lt;/code&gt;
    &lt;p&gt;Requires Node.js 18+.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Migrating from @regression-io/claude-config?&lt;/p&gt;npm uninstall -g @regression-io/claude-config npm install -g coder-config&lt;p&gt;Your settings in&lt;/p&gt;&lt;code&gt;~/.claude-config/&lt;/code&gt;are preserved automatically.&lt;/quote&gt;
    &lt;code&gt;# 1. Install
npm install -g coder-config

# 2. Set up auto-start (recommended)
coder-config ui install

# 3. Open the UI
open http://localhost:3333&lt;/code&gt;
    &lt;p&gt;The server starts automatically on login. Install as a PWA from your browser for app-like access.&lt;/p&gt;
    &lt;code&gt;coder-config update
# Then restart: coder-config ui stop &amp;amp;&amp;amp; coder-config ui&lt;/code&gt;
    &lt;code&gt;# Initialize a project
coder-config init

# Add MCPs to your project
coder-config add postgres github

# Generate .mcp.json for Claude Code
coder-config apply&lt;/code&gt;
    &lt;p&gt;Both &lt;code&gt;coder-config&lt;/code&gt; and &lt;code&gt;claude-config&lt;/code&gt; work identically.&lt;/p&gt;
    &lt;code&gt;coder-config init                        # Initialize project
coder-config apply                       # Generate .mcp.json from config
coder-config show                        # Show current project config
coder-config list                        # List available MCPs (‚úì = active)
coder-config add &amp;lt;mcp&amp;gt; [mcp...]          # Add MCP(s) to project
coder-config remove &amp;lt;mcp&amp;gt; [mcp...]       # Remove MCP(s) from project&lt;/code&gt;
    &lt;code&gt;coder-config memory                         # Show memory status
coder-config memory init                    # Initialize project memory
coder-config memory add &amp;lt;type&amp;gt; "&amp;lt;content&amp;gt;"  # Add entry
coder-config memory search &amp;lt;query&amp;gt;          # Search all memory

# Types: preference, correction, fact (global)
#        context, pattern, decision, issue, history (project)&lt;/code&gt;
    &lt;code&gt;coder-config env                    # List environment variables
coder-config env set &amp;lt;KEY&amp;gt; &amp;lt;value&amp;gt;  # Set variable in .claude/.env
coder-config env unset &amp;lt;KEY&amp;gt;        # Remove variable&lt;/code&gt;
    &lt;code&gt;coder-config project                      # List registered projects
coder-config project add [path]           # Add project (defaults to cwd)
coder-config project add [path] --name X  # Add with custom display name
coder-config project remove &amp;lt;name|path&amp;gt;   # Remove from registry&lt;/code&gt;
    &lt;code&gt;coder-config workstream                   # List all workstreams
coder-config workstream create "Name"     # Create new workstream
coder-config workstream delete &amp;lt;name&amp;gt;     # Delete workstream
coder-config workstream use &amp;lt;name&amp;gt;        # Activate workstream (this terminal)
coder-config workstream active            # Show current active workstream
coder-config workstream deactivate        # Deactivate workstream (this terminal)
coder-config workstream add &amp;lt;ws&amp;gt; &amp;lt;path&amp;gt;   # Add project to workstream
coder-config workstream remove &amp;lt;ws&amp;gt; &amp;lt;path&amp;gt;  # Remove project from workstream
coder-config workstream inject [--silent] # Output restriction + context (for hooks)
coder-config workstream detect [path]     # Detect workstream for directory
coder-config workstream check-path &amp;lt;path&amp;gt; # Check if path is within workstream (exit 0/1)
coder-config workstream install-hook      # Install hook for Claude Code
coder-config workstream install-hook --gemini  # Install hook for Gemini CLI
coder-config workstream install-hook --codex   # Install hook for Codex CLI
coder-config workstream install-hook --all     # Install hooks for all supported tools

# Folder auto-activation
coder-config workstream add-trigger &amp;lt;ws&amp;gt; &amp;lt;folder&amp;gt;  # Add trigger folder
coder-config workstream remove-trigger &amp;lt;ws&amp;gt; &amp;lt;folder&amp;gt;  # Remove trigger folder
coder-config workstream auto-activate &amp;lt;ws&amp;gt; [on|off|default]  # Set auto-activate
coder-config workstream check-folder [path] [--json]  # Check folder for matches
coder-config workstream install-cd-hook    # Install cd hook for shell
coder-config workstream uninstall-cd-hook  # Remove cd hook
coder-config workstream cd-hook-status     # Check cd hook status&lt;/code&gt;
    &lt;p&gt;Per-terminal isolation: With shell integration, each terminal can have its own active workstream:&lt;/p&gt;
    &lt;code&gt;# Terminal 1
coder-config workstream use project-a

# Terminal 2
coder-config workstream use project-b&lt;/code&gt;
    &lt;p&gt;When active, the AI receives a restriction telling it to only work within the workstream's directories.&lt;/p&gt;
    &lt;p&gt;Multi-tool support: Workstreams work with Claude Code, Gemini CLI, and Codex CLI. Install hooks for your preferred tool(s):&lt;/p&gt;
    &lt;code&gt;# For Claude Code only
coder-config workstream install-hook

# For Gemini CLI only
coder-config workstream install-hook --gemini

# For Codex CLI only
coder-config workstream install-hook --codex

# For all supported tools
coder-config workstream install-hook --all&lt;/code&gt;
    &lt;p&gt;Folder auto-activation: Automatically activate workstreams when you cd into matching directories:&lt;/p&gt;
    &lt;code&gt;# Install the cd hook (adds function to ~/.zshrc or ~/.bashrc)
coder-config workstream install-cd-hook

# Now when you cd into a project folder:
cd ~/projects/my-app  # Auto-activates matching workstream
# Output: üìÇ Workstream: My App

# If multiple workstreams match, you'll be prompted:
cd ~/projects
# Output: Multiple workstreams match this folder:
#   1) Frontend
#   2) Backend
#   0) Skip
# Choose [0-2]:&lt;/code&gt;
    &lt;p&gt;Trigger folders: Besides project paths, you can add extra trigger folders:&lt;/p&gt;
    &lt;code&gt;coder-config workstream add-trigger "My Work" ~/projects
coder-config workstream remove-trigger "My Work" ~/projects&lt;/code&gt;
    &lt;p&gt;Auto-activate setting: Control per-workstream or globally:&lt;/p&gt;
    &lt;code&gt;coder-config workstream auto-activate "My Work" on      # Always auto-activate
coder-config workstream auto-activate "My Work" off     # Never auto-activate
coder-config workstream auto-activate "My Work" default # Use global setting&lt;/code&gt;
    &lt;code&gt;coder-config registry                       # List MCPs in global registry
coder-config registry add &amp;lt;name&amp;gt; '&amp;lt;json&amp;gt;'   # Add MCP to global registry
coder-config registry remove &amp;lt;name&amp;gt;         # Remove MCP from registry&lt;/code&gt;
    &lt;code&gt;coder-config update             # Check npm and install updates if available
coder-config update --check     # Check for updates without installing
coder-config update /path/src   # Update from local development source&lt;/code&gt;
    &lt;p&gt;The UI checks for updates automatically and auto-updates when enabled in Preferences. After server updates, the UI auto-refreshes to load the new version.&lt;/p&gt;
    &lt;code&gt;coder-config ui                    # Start UI on port 3333
coder-config ui --port 8080        # Custom port
coder-config ui /path/to/project   # Specific project directory
coder-config ui --foreground       # Run in foreground (blocking)
coder-config ui status             # Check if daemon is running
coder-config ui stop               # Stop the daemon

# Auto-start on login (macOS)
coder-config ui install            # Install LaunchAgent for auto-start
coder-config ui uninstall          # Remove auto-start&lt;/code&gt;
    &lt;p&gt;Daemon Mode: By default, &lt;code&gt;coder-config ui&lt;/code&gt; runs as a background daemon.
The UI runs from your home directory and persists across terminal sessions.
Switch between registered projects using the dropdown in the header.&lt;/p&gt;
    &lt;p&gt;PWA / Auto-Start: Install the UI as a PWA in your browser, then run &lt;code&gt;coder-config ui install&lt;/code&gt;
to have the server start automatically on login. Your PWA will always connect instantly.&lt;/p&gt;
    &lt;p&gt;For full functionality, add to &lt;code&gt;~/.zshrc&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;source /path/to/coder-config/shell/claude-config.zsh&lt;/code&gt;
    &lt;p&gt;This enables:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Per-terminal workstreams - &lt;code&gt;workstream use&lt;/code&gt;activates for current terminal only&lt;/item&gt;
      &lt;item&gt;Auto-generates &lt;code&gt;.mcp.json&lt;/code&gt;when entering a project with&lt;code&gt;.claude/mcps.json&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Tab completion for all commands&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Settings merge from global to project to sub-project:&lt;/p&gt;
    &lt;code&gt;~/.claude/mcps.json                    # Global - applies everywhere
~/projects/.claude/mcps.json           # Workspace - applies to projects here
~/projects/my-app/.claude/             # Project - specific to this project
~/projects/my-app/server/.claude/      # Sub-project - inherits from parent
&lt;/code&gt;
    &lt;p&gt;Sub-projects are automatically detected (folders with &lt;code&gt;.git&lt;/code&gt;), or you can manually link any folder using "Add Sub-project" in the Web UI.&lt;/p&gt;
    &lt;p&gt;After &lt;code&gt;coder-config init&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;your-project/
‚îú‚îÄ‚îÄ .claude/
‚îÇ   ‚îú‚îÄ‚îÄ mcps.json       # MCP configuration
‚îÇ   ‚îú‚îÄ‚îÄ settings.json   # Claude Code settings
‚îÇ   ‚îú‚îÄ‚îÄ rules/          # Project rules (*.md)
‚îÇ   ‚îî‚îÄ‚îÄ commands/       # Custom commands (*.md)
‚îî‚îÄ‚îÄ .mcp.json           # Generated - Claude Code reads this
&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;.claude/mcps.json&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;{
  "mcpServers": {
    "filesystem": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/path"]
    },
    "github": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-github"],
      "env": {
        "GITHUB_TOKEN": "${GITHUB_TOKEN}"
      }
    }
  }
}&lt;/code&gt;
    &lt;p&gt;Environment variables use &lt;code&gt;${VAR}&lt;/code&gt; syntax and load from &lt;code&gt;.claude/.env&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Persistent memory for Claude Code sessions.&lt;/p&gt;
    &lt;p&gt;Global (&lt;code&gt;~/.claude/memory/&lt;/code&gt;)&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;File&lt;/cell&gt;
        &lt;cell role="head"&gt;Purpose&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;preferences.md&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;User preferences and style&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;corrections.md&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Mistakes to avoid&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;facts.md&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Environment facts&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Project (&lt;code&gt;&amp;lt;project&amp;gt;/.claude/memory/&lt;/code&gt;)&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;File&lt;/cell&gt;
        &lt;cell role="head"&gt;Purpose&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;context.md&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Project overview&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;patterns.md&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Code patterns&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;decisions.md&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Architecture decisions&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;issues.md&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Known issues&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;history.md&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Session history&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Manage via Web UI or edit files directly.&lt;/p&gt;
    &lt;p&gt;Save context from a Claude Code session and restore it on the next session start.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Save context - Use &lt;code&gt;/flush&lt;/code&gt;in Claude Code to write a context summary&lt;/item&gt;
      &lt;item&gt;Auto-restore - The &lt;code&gt;session-start&lt;/code&gt;hook injects saved context into your next session&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Context is stored per-project in &lt;code&gt;.claude/session-context.md&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;From the UI: Go to System &amp;gt; Sessions and click "Install All"&lt;/p&gt;
    &lt;p&gt;From the CLI:&lt;/p&gt;
    &lt;code&gt;coder-config session install&lt;/code&gt;
    &lt;p&gt;This installs the SessionStart hook and the &lt;code&gt;/flush&lt;/code&gt; command.&lt;/p&gt;
    &lt;code&gt;coder-config session           # Show session status
coder-config session install   # Install hooks and /flush command
coder-config session clear     # Clear saved context&lt;/code&gt;
    &lt;p&gt;Session context is stored in each project at &lt;code&gt;.claude/session-context.md&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Workstreams are context sets for multi-project workflows. They group related projects and inject context rules into every Claude session.&lt;/p&gt;
    &lt;p&gt;When working on complex features that span multiple repos (e.g., REST API + UI + shared library), you need Claude to understand the broader context. Workstreams solve this by:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Grouping related projects together&lt;/item&gt;
      &lt;item&gt;Defining rules specific to that workflow&lt;/item&gt;
      &lt;item&gt;Automatically injecting those rules into every Claude session&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Create a workstream for user authentication feature
coder-config workstream create "User Auth"

# Add related projects
coder-config workstream add "User Auth" ~/projects/api
coder-config workstream add "User Auth" ~/projects/ui
coder-config workstream add "User Auth" ~/projects/shared

# Activate it
coder-config workstream use "User Auth"&lt;/code&gt;
    &lt;p&gt;Then in the Web UI, edit the workstream to add rules like:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Focus on user authentication flow. Use JWT tokens. React Query for state management. PostgreSQL for persistence.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;For rules to be injected automatically, install the pre-prompt hook:&lt;/p&gt;
    &lt;p&gt;Option 1: One-click install (recommended)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Open Web UI ‚Üí Workstreams ‚Üí Click "Install Hook Automatically"&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Option 2: Manual&lt;/p&gt;
    &lt;code&gt;# Add to ~/.claude/hooks/pre-prompt.sh
coder-config workstream inject --silent&lt;/code&gt;
    &lt;p&gt;Once installed, your active workstream's rules are prepended to every Claude session.&lt;/p&gt;
    &lt;p&gt;Coder-config can track which files you work on and suggest workstreams based on patterns:&lt;/p&gt;
    &lt;p&gt;How it works:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;A post-response hook logs file paths accessed during Claude sessions&lt;/item&gt;
      &lt;item&gt;Co-activity patterns are detected (projects frequently worked on together)&lt;/item&gt;
      &lt;item&gt;Workstream suggestions appear in the UI based on these patterns&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Setup (optional):&lt;/p&gt;
    &lt;code&gt;# Install the activity tracking hook
# Add to ~/.claude/hooks/post-response.sh:
source /path/to/coder-config/hooks/activity-track.sh&lt;/code&gt;
    &lt;p&gt;In the Web UI:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Activity Insights panel shows sessions, files tracked, and active projects&lt;/item&gt;
      &lt;item&gt;Suggested Workstreams appear when patterns are detected&lt;/item&gt;
      &lt;item&gt;Click "Create" to open pre-filled dialog (tweak projects as needed)&lt;/item&gt;
      &lt;item&gt;Click "X" to dismiss suggestions you don't want&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Feature&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Project Explorer&lt;/cell&gt;
        &lt;cell&gt;Browse and edit &lt;code&gt;.claude/&lt;/code&gt; folders across your project hierarchy&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Claude Code Settings&lt;/cell&gt;
        &lt;cell&gt;Visual editor for permissions, model, hooks, and behavior&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Gemini CLI Settings&lt;/cell&gt;
        &lt;cell&gt;Configure model, display options, and sandbox mode&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Codex CLI Settings&lt;/cell&gt;
        &lt;cell&gt;Configure model, security, MCP servers, and features&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Antigravity Settings&lt;/cell&gt;
        &lt;cell&gt;Configure security policies, browser allowlist, and agent mode&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;MCP Registry&lt;/cell&gt;
        &lt;cell&gt;Search GitHub/npm, add and configure MCP servers&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Plugins&lt;/cell&gt;
        &lt;cell&gt;Browse marketplaces, install plugins with scope control&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Memory&lt;/cell&gt;
        &lt;cell&gt;Manage preferences, corrections, patterns, and decisions&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Workstreams&lt;/cell&gt;
        &lt;cell&gt;Group related projects with shared context rules&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Additional features: project/workstream switchers in header, sub-project detection, dark mode, auto-updates.&lt;/p&gt;
    &lt;p&gt;Claude Code plugins extend functionality with LSP servers, MCP servers, commands, and always-on guidance. Plugins replace templates - instead of static files that can become stale, plugins are always active and update automatically.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Aspect&lt;/cell&gt;
        &lt;cell role="head"&gt;Plugins&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Delivery&lt;/cell&gt;
        &lt;cell&gt;Enable plugin once&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Updates&lt;/cell&gt;
        &lt;cell&gt;Auto-refresh from marketplace&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Freshness&lt;/cell&gt;
        &lt;cell&gt;Always current&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Scope&lt;/cell&gt;
        &lt;cell&gt;Global, project, or local&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Discovery&lt;/cell&gt;
        &lt;cell&gt;Browse marketplaces&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;From CLI:&lt;/p&gt;
    &lt;code&gt;# Add the coder-config plugins marketplace
claude plugin marketplace add regression-io/claude-config-plugins

# Install framework-specific plugins
claude plugin install fastapi-support@claude-config-plugins
claude plugin install react-typescript@claude-config-plugins
claude plugin install python-support@claude-config-plugins&lt;/code&gt;
    &lt;p&gt;From Web UI:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Open Project Explorer&lt;/item&gt;
      &lt;item&gt;Click the + menu on any project folder&lt;/item&gt;
      &lt;item&gt;Select Install Plugins&lt;/item&gt;
      &lt;item&gt;Toggle plugins on/off with scope selection (Project/Global/Local)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Plugins page shows all available plugins:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Filter by marketplace, category, source type (Anthropic/Community), installed status&lt;/item&gt;
      &lt;item&gt;Search by name or description&lt;/item&gt;
      &lt;item&gt;View plugin details (LSP/MCP/Commands included)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Plugins come from marketplaces (Git repositories):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;claude-plugins-official - Anthropic's official plugins&lt;/item&gt;
      &lt;item&gt;regression-io/claude-config-plugins - Framework and language plugins&lt;/item&gt;
      &lt;item&gt;Add community marketplaces via "Manage Marketplaces" in the filter dropdown&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Supported marketplace formats:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;owner/repo&lt;/code&gt;‚Äî GitHub shorthand&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;https://github.com/owner/repo&lt;/code&gt;‚Äî Full URL&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/local/path&lt;/code&gt;‚Äî Local directory&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Web UI provides a visual editor for &lt;code&gt;~/.claude/settings.json&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;Configure what Claude Code can do automatically:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Allow - Tools that run without asking&lt;/item&gt;
      &lt;item&gt;Ask - Tools that require confirmation&lt;/item&gt;
      &lt;item&gt;Deny - Tools that are blocked&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Pattern examples:&lt;/p&gt;
    &lt;code&gt;Bash(npm run build)      # Specific command
Bash(npm:*)              # Prefix match (npm anything)
Read(**)                 # All file reads
Edit(src/**)             # Edit files in src/
mcp__github__*           # All GitHub MCP tools
&lt;/code&gt;
    &lt;p&gt;Choose your preferred Claude model (Sonnet 4, Opus 4.5, etc.)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Auto-accept edits&lt;/item&gt;
      &lt;item&gt;Verbose mode&lt;/item&gt;
      &lt;item&gt;Enable/disable MCP servers&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Web UI provides a visual editor for &lt;code&gt;~/.gemini/settings.json&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;Choose Gemini model (2.5 Pro, 2.5 Flash, etc.) and enable preview features.&lt;/p&gt;
    &lt;p&gt;Configure theme, token count display, diff view, and streaming.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Vim keybindings&lt;/item&gt;
      &lt;item&gt;Auto-save&lt;/item&gt;
      &lt;item&gt;Check for updates&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Control command execution safety (enabled/disabled).&lt;/p&gt;
    &lt;p&gt;The Web UI provides a visual editor for &lt;code&gt;~/.codex/config.toml&lt;/code&gt;:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Model - Select GPT-5.2 Codex, GPT-5, o3-mini, etc.&lt;/item&gt;
      &lt;item&gt;Reasoning Effort - Control thoroughness (minimal to xhigh)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Approval Policy - When to ask for command approval (on-request, untrusted, on-failure, never)&lt;/item&gt;
      &lt;item&gt;Sandbox Mode - Filesystem access level (read-only, workspace-write, full-access)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Configure MCP servers for Codex CLI with the same format as other tools.&lt;/p&gt;
    &lt;p&gt;Toggle feature flags like shell snapshots and web search.&lt;/p&gt;
    &lt;p&gt;Configure TUI animations, notifications, and session history persistence.&lt;/p&gt;
    &lt;p&gt;For full configuration options, see Codex CLI docs.&lt;/p&gt;
    &lt;p&gt;The Web UI provides a visual editor for &lt;code&gt;~/.gemini/antigravity/settings.json&lt;/code&gt;:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Policy&lt;/cell&gt;
        &lt;cell role="head"&gt;Options&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Terminal Execution&lt;/cell&gt;
        &lt;cell&gt;Off, Auto, Turbo&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Code Review&lt;/cell&gt;
        &lt;cell&gt;Enabled, Disabled&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;JS Execution&lt;/cell&gt;
        &lt;cell&gt;Sandboxed, Direct&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Configure MCP servers for Antigravity. Note: Antigravity does NOT support &lt;code&gt;${VAR}&lt;/code&gt; interpolation - variables are resolved to actual values.&lt;/p&gt;
    &lt;p&gt;Control which URLs Antigravity can access during sessions.&lt;/p&gt;
    &lt;p&gt;Configure autonomous multi-step operations, iteration limits, and confirmation requirements.&lt;/p&gt;
    &lt;p&gt;User settings stored in &lt;code&gt;~/.claude-config/config.json&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;{
  "toolsDir": "~/mcp-tools",
  "registryPath": "~/.claude/registry.json",
  "ui": {
    "port": 3333,
    "openBrowser": true
  }
}&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Key&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;toolsDir&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Directory for local MCP tools&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;registryPath&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Path to custom MCP registry&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;ui.port&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Default port for web UI&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;ui.openBrowser&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Auto-open browser on &lt;code&gt;coder-config ui&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;quote&gt;
      &lt;p&gt;Note: Ralph Loops is an experimental feature, disabled by default. Enable it in the Web UI under Preferences &amp;gt; Experimental Features.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Ralph Loops enable autonomous development - Claude Code runs continuously until a task is completed.&lt;/p&gt;
    &lt;code&gt;coder-config loop                           # List all loops
coder-config loop create "Task description" # Create new loop
coder-config loop create "Task" --workstream &amp;lt;name&amp;gt;  # Create loop in workstream context
coder-config loop start &amp;lt;id&amp;gt;                # Start/resume a loop
coder-config loop pause &amp;lt;id&amp;gt;                # Pause loop at next safe point
coder-config loop resume &amp;lt;id&amp;gt;               # Resume paused loop
coder-config loop cancel &amp;lt;id&amp;gt;               # Cancel loop
coder-config loop delete &amp;lt;id&amp;gt;               # Delete loop and its data
coder-config loop approve &amp;lt;id&amp;gt;              # Approve plan (when in plan phase)
coder-config loop complete &amp;lt;id&amp;gt;             # Mark loop as complete
coder-config loop status [id]               # Show status (active loop if no id)
coder-config loop active                    # Show current active loop
coder-config loop history                   # Show completed loops
coder-config loop config                    # Show loop configuration
coder-config loop config --max-iterations 50    # Set max iterations
coder-config loop config --auto-approve-plan    # Skip manual plan approval&lt;/code&gt;
    &lt;p&gt;Three-Phase Workflow:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Clarify - Claude asks questions to understand requirements&lt;/item&gt;
      &lt;item&gt;Plan - Claude creates an implementation plan (requires approval)&lt;/item&gt;
      &lt;item&gt;Execute - Claude implements the plan until complete&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Running a loop:&lt;/p&gt;
    &lt;code&gt;export CODER_LOOP_ID=&amp;lt;id&amp;gt;
claude --continue "Your task description"&lt;/code&gt;
    &lt;p&gt;Safety mechanisms:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Iteration limits (default: 50)&lt;/item&gt;
      &lt;item&gt;Phase gates (manual plan approval)&lt;/item&gt;
      &lt;item&gt;Graceful pause on limit exceeded&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Node.js 18+&lt;/item&gt;
      &lt;item&gt;Build tools (for newer Node.js versions without prebuilt binaries): &lt;list rend="ul"&gt;&lt;item&gt;macOS: Xcode Command Line Tools (&lt;code&gt;xcode-select --install&lt;/code&gt;)&lt;/item&gt;&lt;item&gt;Linux: &lt;code&gt;build-essential&lt;/code&gt;package&lt;/item&gt;&lt;item&gt;Windows: Visual Studio Build Tools&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;macOS: Xcode Command Line Tools (&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;git clone https://github.com/regression-io/coder-config.git
cd coder-config
npm install
npm run build
npm start&lt;/code&gt;
    &lt;p&gt;MIT&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46796825</guid><pubDate>Wed, 28 Jan 2026 15:44:24 +0000</pubDate></item><item><title>Oban, the job processing framework from Elixir, has come to Python</title><link>https://www.dimamik.com/posts/oban_py/</link><description>&lt;doc fingerprint="2e18825df1a004c7"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Setting the Stage&lt;/head&gt;
    &lt;p&gt;I‚Äôve used Oban in Elixir for almost as long as I‚Äôve been writing software in Elixir, and it has always been an essential tool for processing jobs. I always knew Oban was cool, but I never dug deeper. This article is a collection of my notes and observations on how the Python implementation of Oban works and what I‚Äôve learned while exploring its codebase. I‚Äôll also try to compare it with the Elixir version and talk about concurrency in general.&lt;/p&gt;
    &lt;head rend="h2"&gt;Surface Level&lt;/head&gt;
    &lt;p&gt;Oban allows you to insert and process jobs using only your database. You can insert the job to send a confirmation email in the same database transaction where you create the user. If one thing fails, everything is rolled back.&lt;/p&gt;
    &lt;p&gt;Additionally, like most job processing frameworks, Oban has queues with local and global queue limits. But unlike others, it stores your completed jobs and can even keep their results if needed. It has built-in cron scheduling and many more features to control how your jobs are processed.&lt;/p&gt;
    &lt;p&gt;Oban comes in two versions - Open Source Oban-py and commercial Oban-py-pro.&lt;/p&gt;
    &lt;p&gt;OSS Oban has a few limitations, which are automatically lifted in the Pro version:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Single-threaded asyncio execution - concurrent but not truly parallel, so CPU-bound jobs block the event loop.&lt;/item&gt;
      &lt;item&gt;No bulk inserts - each job is inserted individually.&lt;/item&gt;
      &lt;item&gt;No bulk acknowledgements - each job completion is persisted individually.&lt;/item&gt;
      &lt;item&gt;Inaccurate rescues - jobs that are long-running might get rescued even if the producer is still alive. Pro version uses smarter heartbeats to track producer liveness.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In addition, Oban-py-pro comes with a few extra features you‚Äôd configure separately, like workflows, relay, unique jobs, and smart concurrency.&lt;/p&gt;
    &lt;p&gt;OSS Oban-py is a great start for your hobby project, or if you‚Äôd want to evaluate Oban philosophy itself, but for any bigger scale - I‚Äôd go with Oban Pro. The pricing seems very compelling, considering the amount of work put into making the above features work.&lt;/p&gt;
    &lt;p&gt;I obviously can‚Äôt walk you through the Pro version features, but let‚Äôs start with the basics. How Oban Py works under the hood, from the job insertion until the job execution. Stay tuned.&lt;/p&gt;
    &lt;head rend="h2"&gt;Going Deeper - Job Processing Path&lt;/head&gt;
    &lt;p&gt;Let‚Äôs get straight to it. You insert your job:&lt;/p&gt;
    &lt;code&gt;from oban import job

@job(queue="default")
async def send_email(to: str, subject: str, body: str):
    # Simple and clean, but no access to job context
    await smtp.send(to, subject, body)

await send_email.enqueue("[email¬†protected]", "Hello", "World")
&lt;/code&gt;
    &lt;p&gt;After the insertion, the job lands in the &lt;code&gt;oban_jobs&lt;/code&gt; database table with &lt;code&gt;state = 'available'&lt;/code&gt;. Oban fires off a PostgreSQL &lt;code&gt;NOTIFY&lt;/code&gt; on the &lt;code&gt;insert&lt;/code&gt; channel:&lt;/p&gt;
    &lt;code&gt;# oban.py:414-419
# Single inserts go through bulk insert path
result = await self._query.insert_jobs(jobs)
queues = {job.queue for job in result if job.state == "available"}
await self._notifier.notify("insert", [{"queue": queue} for queue in queues])
&lt;/code&gt;
    &lt;p&gt;Every Oban node listening on that channel receives the notification. The Stager on each node gets woken up, but each Stager only cares about queues it‚Äôs actually running. Be aware that each node decides which queues it runs, so if the current node runs this queue, the producer is notified:&lt;/p&gt;
    &lt;code&gt;# _stager.py:95-99
async def _on_notification(self, channel: str, payload: dict) -&amp;gt; None:
    queue = payload["queue"]

    if queue in self._producers:
        self._producers[queue].notify()
&lt;/code&gt;
    &lt;p&gt;That &lt;code&gt;notify()&lt;/code&gt; call sets an &lt;code&gt;asyncio.Event&lt;/code&gt;, breaking the Producer out of its wait loop, so it can dispatch the jobs to the workers:&lt;/p&gt;
    &lt;code&gt;# _producer.py:244-262
async def _loop(self) -&amp;gt; None:
    while True:
        try:
            # &amp;lt;--- This is where the event is received ---&amp;gt;
            await asyncio.wait_for(self._notified.wait(), timeout=1.0)
        except asyncio.TimeoutError:
            continue
        except asyncio.CancelledError:
            break

        # &amp;lt;--- Reset the event so it can be triggered for the next batch ---&amp;gt;
        self._notified.clear()

        try:
            # &amp;lt;--- A little debounce to potentially process multiple jobs at once ---&amp;gt;
            await self._debounce()
            # &amp;lt;--- Dispatch (Produce) the jobs from the database to the workers ---&amp;gt;
            await self._produce()
        except asyncio.CancelledError:
            break
        except Exception:
            logger.exception("Error in producer for queue %s", self._queue)
&lt;/code&gt;
    &lt;p&gt;Before fetching the jobs, the producer persists all pre-existing job completions (acks) to the database to make sure queue limits are respected. Next, it fetches new jobs, transitioning their state to executing at the same time. A slightly more complex version of this SQL is used:&lt;/p&gt;
    &lt;code&gt;-- fetch_jobs.sql (simplified)
WITH locked_jobs AS (
  SELECT priority, scheduled_at, id
  FROM
  oban_jobs
  WHERE state = 'available' AND queue = %(queue)s
  ORDER BY priority ASC, scheduled_at ASC, id ASC
  LIMIT %(demand)s
  FOR UPDATE SKIP LOCKED
)
UPDATE oban_jobs oj
SET
  attempt = oj.attempt + 1,
  attempted_at = timezone('UTC', now()),
  attempted_by = %(attempted_by)s,
  state = 'executing'
FROM locked_jobs
WHERE oj.id = locked_jobs.id
&lt;/code&gt;
    &lt;p&gt;And this is the first really cool part.&lt;/p&gt;
    &lt;p&gt;Segue to FOR UPDATE SKIP LOCKED.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;FOR UPDATE&lt;/code&gt;- Locks the selected rows so no other transaction can modify them until this transaction completes. This prevents two producers from grabbing the same job.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;SKIP LOCKED&lt;/code&gt;- If a row is already locked by another transaction, skip it instead of waiting. This is crucial for concurrency.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Why this matters for job queues: Imagine two producer instances (A and B) trying to fetch jobs simultaneously:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Without SKIP LOCKED&lt;/cell&gt;
        &lt;cell role="head"&gt;With SKIP LOCKED&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;A locks job #1&lt;/cell&gt;
        &lt;cell&gt;A locks job #1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;B waits for job #1 to unlock&lt;/cell&gt;
        &lt;cell&gt;B skips job #1, takes job #2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Slow, sequential processing&lt;/cell&gt;
        &lt;cell&gt;Fast, parallel processing&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Back in Python, we know that the jobs we just fetched should be processed immediately. When we fetched the job, we already transitioned its state and respected the queue demand.&lt;/p&gt;
    &lt;p&gt;Each job gets dispatched as an async task:&lt;/p&gt;
    &lt;code&gt;jobs = await self._get_jobs()
for job in jobs:
    task = self._dispatcher.dispatch(self, job)
    task.add_done_callback(
        lambda _, job_id=job.id: self._on_job_complete(job_id)
    )

    self._running_jobs[job.id] = (job, task)
&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;add_done_callback&lt;/code&gt; ensures that independent of success or failure, we can attach a callback to handle job completion.&lt;/p&gt;
    &lt;p&gt;The dispatcher controls how exactly the job is run. For the non-pro Oban version, it just uses &lt;code&gt;asyncio.create_task&lt;/code&gt; to run the job in the event loop:&lt;/p&gt;
    &lt;code&gt;# _producer.py:69-71
class LocalDispatcher:
    def dispatch(self, producer: Producer, job: Job) -&amp;gt; asyncio.Task:
        return asyncio.create_task(producer._execute(job))
&lt;/code&gt;
    &lt;p&gt;For pro version, local asyncio dispatcher is automatically replaced with a pool of processes, so you don‚Äôt need to do anything to have true parallelism across multiple cores.&lt;/p&gt;
    &lt;p&gt;After the job is dispatched, the Executor takes over. It resolves your worker class from the string name, runs it, and pattern-matches the result:&lt;/p&gt;
    &lt;code&gt;# _executor.py:73-83
async def _process(self) -&amp;gt; None:
  self.worker = resolve_worker(self.job.worker)()
  self.result = await self.worker.process(self.job)
&lt;/code&gt;
    &lt;code&gt;# _executor.py:95-133
match result:
    case Exception() as error:
        # Retry or discard based on attempt count
    case Cancel(reason=reason):
        # Mark cancelled
    case Snooze(seconds=seconds):
        # Reschedule with decremented attempt
    case _:
        # Completed successfully
&lt;/code&gt;
    &lt;p&gt;And that‚Äôs the second cool part! You see how similar it is to Elixir‚Äôs pattern matching? I love how it‚Äôs implemented!&lt;/p&gt;
    &lt;p&gt;When execution finishes, the result gets queued for acknowledgement:&lt;/p&gt;
    &lt;code&gt;# _producer.py:315
self._pending_acks.append(executor.action)
&lt;/code&gt;
    &lt;p&gt;The completion callback notifies the Producer to wake up again-fetch more jobs, and batch-ack the finished ones in a single query.&lt;/p&gt;
    &lt;p&gt;That‚Äôs the hot path: &lt;code&gt;Insert ‚Üí Notify ‚Üí Fetch (with locking) ‚Üí Execute ‚Üí Ack.&lt;/code&gt; Five hops from your code to completion. What about the background processes? What about errors and retries? What about periodic jobs, cron, and all these other pieces? Stay tuned.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Undercurrents - Background Processes&lt;/head&gt;
    &lt;p&gt;Oban runs several background loops that keep the system healthy.&lt;/p&gt;
    &lt;head rend="h3"&gt;Leader Election&lt;/head&gt;
    &lt;p&gt;In a cluster, you don‚Äôt want every node pruning jobs or rescuing orphans. Oban elects a single leader:&lt;/p&gt;
    &lt;code&gt;# _leader.py:107-113
async def _election(self) -&amp;gt; None:
    self._is_leader = await self._query.attempt_leadership(
        self._name, self._node, int(self._interval), self._is_leader
    )
&lt;/code&gt;
    &lt;code&gt;-- Cleanup expired leaders first
DELETE FROM
  oban_leaders
WHERE
  expires_at &amp;lt; timezone('UTC', now())
&lt;/code&gt;
    &lt;code&gt;-- If current node is a leader, it re-elects itself
INSERT INTO oban_leaders (name, node, elected_at, expires_at)
VALUES (
  %(name)s,
  %(node)s,
  timezone('UTC', now()),
  timezone('UTC', now()) + interval '%(ttl)s seconds'
)
ON CONFLICT (name) DO UPDATE SET
  -- Only update if we're the same node (i.e. current leader re-electing itself).
  -- Other nodes can't overwrite an active leader's lease.
  expires_at = EXCLUDED.expires_at
WHERE
  oban_leaders.node = EXCLUDED.node
RETURNING node
&lt;/code&gt;
    &lt;code&gt;-- Try to insert as a new leader if no leader exists
INSERT INTO oban_leaders (
  name, node, elected_at, expires_at
) VALUES (
  %(name)s,
  %(node)s,
  timezone('UTC', now()),
  timezone('UTC', now()) + interval '%(ttl)s seconds'
)
ON CONFLICT (name) DO NOTHING
RETURNING node
&lt;/code&gt;
    &lt;p&gt;The leader refreshes twice as often to hold onto the role:&lt;/p&gt;
    &lt;code&gt;# _leader.py:101-105
# Sleep for half interval if leader (to boost their refresh interval and allow them to
# retain leadership), full interval otherwise
sleep_duration = self._interval / 2 if self._is_leader else self._interval
&lt;/code&gt;
    &lt;p&gt;When a node shuts down cleanly, it resigns and notifies the cluster:&lt;/p&gt;
    &lt;code&gt;# _leader.py:83-87
if self._is_leader:
    payload = {"action": "resign", "node": self._node, "name": self._name}

    await self._notifier.notify("leader", payload)
    await self._query.resign_leader(self._name, self._node)
&lt;/code&gt;
    &lt;p&gt;And that‚Äôs the third cool part! Leader election is delegated entirely to PostgreSQL. Oban uses &lt;code&gt;INSERT ... ON CONFLICT&lt;/code&gt; with a TTL-based lease - no Raft, no consensus protocol, no external coordination service. If the leader dies, its lease expires and the next node to run the election query takes over. Simple, effective, and zero additional infrastructure.&lt;/p&gt;
    &lt;head rend="h3"&gt;Lifeline: Rescuing Orphaned Jobs&lt;/head&gt;
    &lt;p&gt;Workers crash. Containers get killed. When that happens, jobs can get stuck executing indefinitely. The Lifeline process (leader-only) rescues them:&lt;/p&gt;
    &lt;code&gt;# _lifeline.py:73-77
async def _rescue(self) -&amp;gt; None:
    if not self._leader.is_leader:
        return

    await use_ext("lifeline.rescue", _rescue, self._query, self._rescue_after)
&lt;/code&gt;
    &lt;p&gt;Oban-py rescue mechanics are purely time-based - any job in &lt;code&gt;executing&lt;/code&gt; state longer than &lt;code&gt;rescue_after&lt;/code&gt; (default: 5 minutes) gets moved back. Unlike the Oban Pro version, it doesn‚Äôt check whether the producer that owns the job is still alive. This means legitimately long-running jobs could be rescued and executed a second time.&lt;/p&gt;
    &lt;p&gt;The takeaway is that you should set &lt;code&gt;rescue_after&lt;/code&gt; higher than your longest expected job duration, and design workers to be idempotent.&lt;/p&gt;
    &lt;p&gt;The SQL itself is straightforward - jobs stuck executing get moved back to available or discarded if they‚Äôve exhausted retries:&lt;/p&gt;
    &lt;code&gt;-- rescue_jobs.sql (simplified)
UPDATE oban_jobs
SET
  state = CASE
    WHEN attempt &amp;gt;= max_attempts THEN 'discarded'
    ELSE 'available'
  END,
  meta = CASE
    WHEN attempt &amp;gt;= max_attempts THEN meta
    ELSE meta || jsonb_build_object('rescued', coalesce((meta-&amp;gt;&amp;gt;'rescued')::int, 0) + 1)
  END
WHERE
  state = 'executing'
  AND attempted_at &amp;lt; timezone('UTC', now()) - make_interval(secs =&amp;gt; %(rescue_after)s)
&lt;/code&gt;
    &lt;p&gt;The rescued counter in meta lets you track how often jobs needed saving.&lt;/p&gt;
    &lt;head rend="h3"&gt;Pruner: Cleaning Up Old Jobs&lt;/head&gt;
    &lt;p&gt;Without pruning, your oban_jobs table grows forever. The Pruner (also leader-only) deletes terminal jobs older than max_age (default: 1 day):&lt;/p&gt;
    &lt;code&gt;-- prune_jobs.sql
WITH jobs_to_delete AS (
SELECT id FROM oban_jobs
WHERE
(state = 'completed' AND completed_at &amp;lt;= timezone('UTC', now()) - make_interval(secs =&amp;gt; %(max_age)s)) OR
(state = 'cancelled' AND cancelled_at &amp;lt;= timezone('UTC', now()) - make_interval(secs =&amp;gt; %(max_age)s)) OR
(state = 'discarded' AND discarded_at &amp;lt;= timezone('UTC', now()) - make_interval(secs =&amp;gt; %(max_age)s))
ORDER BY id ASC
LIMIT %(limit)s
)
DELETE FROM oban_jobs WHERE id IN (SELECT id FROM jobs_to_delete)
&lt;/code&gt;
    &lt;p&gt;The LIMIT prevents long-running deletes from blocking other operations.&lt;/p&gt;
    &lt;head rend="h3"&gt;Retry &amp;amp; Backoff Mechanics&lt;/head&gt;
    &lt;p&gt;When a job raises an exception, the Executor decides its fate:&lt;/p&gt;
    &lt;code&gt;# _executor.py:96-109
match result:
    case Exception() as error:
        if self.job.attempt &amp;gt;= self.job.max_attempts:
            self.action = AckAction(
                job=self.job,
                state="discarded",
                error=self._format_error(error),
            )
        else:
            self.action = AckAction(
                job=self.job,
                state="retryable",
                error=self._format_error(error),
                schedule_in=self._retry_backoff(),
            )
&lt;/code&gt;
    &lt;p&gt;Simple rule: under &lt;code&gt;max_attempts&lt;/code&gt; - retry, otherwise - discard.&lt;/p&gt;
    &lt;p&gt;The default backoff uses jittery-clamped exponential growth with randomness to prevent thundering herds:&lt;/p&gt;
    &lt;code&gt;# _backoff.py:66-87
def jittery_clamped(attempt: int, max_attempts: int, *, clamped_max: int = 20) -&amp;gt; int:
    if max_attempts &amp;lt;= clamped_max:
        clamped_attempt = attempt
    else:
        clamped_attempt = round(attempt / max_attempts * clamped_max)

    time = exponential(clamped_attempt, mult=1, max_pow=100, min_pad=15)

    return jitter(time, mode="inc")
&lt;/code&gt;
    &lt;p&gt;And that‚Äôs the fourth cool thing! Backoff includes jitter to prevent thundering herds - without it, all failed jobs from the same batch would retry at the exact same moment, spiking load all over again.&lt;/p&gt;
    &lt;p&gt;The formula: 15 + 2^attempt seconds, with up to 10% added jitter. Attempt 1 waits ~17s. Attempt 5 waits ~47s. Attempt 10 waits ~1039s (~17 minutes).&lt;/p&gt;
    &lt;p&gt;The clamping handles jobs with high &lt;code&gt;max_attempts&lt;/code&gt; - if you set &lt;code&gt;max_attempts=100&lt;/code&gt;, it scales the attempt number down proportionally so you don‚Äôt wait years between retries.&lt;/p&gt;
    &lt;p&gt;Workers can override this with custom backoff:&lt;/p&gt;
    &lt;code&gt;@worker(queue="default")
class MyWorker:
    async def process(self, job: Job):
        ...

    def backoff(self, job: Job) -&amp;gt; int:
        # Linear backoff: 60s, 120s, 180s...
        return job.attempt * 60
&lt;/code&gt;
    &lt;head rend="h2"&gt;Surfacing - Takeaways&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PostgreSQL does the heavy lifting. &lt;code&gt;FOR UPDATE SKIP LOCKED&lt;/code&gt;for concurrent job fetching,&lt;code&gt;LISTEN/NOTIFY&lt;/code&gt;for real-time signaling,&lt;code&gt;ON CONFLICT&lt;/code&gt;for leader election - the database isn‚Äôt just storage, it‚Äôs the coordination layer. There‚Äôs no Redis, no ZooKeeper, no external broker. One less thing to operate.&lt;/item&gt;
      &lt;item&gt;Oban-py is concurrent, but not parallel. Async IO allows multiple jobs to be in-flight, but the event loop is single-threaded. For I/O-bound workloads, this is fine. For CPU-bound tasks, consider using the Pro version with a process pool.&lt;/item&gt;
      &lt;item&gt;Leader election is simple and effective. No consensus protocol, no Raft - just an &lt;code&gt;INSERT ... ON CONFLICT&lt;/code&gt;with a TTL. The leader refreshes at 2x the normal rate to hold the lease. If it dies, the lease expires and another node takes over. Good enough for pruning and rescuing.&lt;/item&gt;
      &lt;item&gt;The codebase is a pleasure to read. Clear naming, consistent patterns, and well-separated concerns - exploring it felt more like reading a well-written book than understanding a library.&lt;/item&gt;
      &lt;item&gt;OSS gets you far, Pro fills the gaps. Bulk operations, smarter rescues, and true parallelism are all Pro-only - but for what you get, Pro license feels like a great deal.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Overall, Oban.py is a clean and well-structured port. If you‚Äôre coming from Elixir and miss Oban, or if you‚Äôre in Python and want a database-backed job queue that doesn‚Äôt require external infrastructure beyond PostgreSQL - it‚Äôs worth looking at.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46797594</guid><pubDate>Wed, 28 Jan 2026 16:32:00 +0000</pubDate></item><item><title>Spinning around: Please don't ‚Äì Common problems with spin locks</title><link>https://www.siliceum.com/en/blog/post/spinning-around/</link><description>&lt;doc fingerprint="3e1474539c305098"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Intro&lt;/head&gt;
    &lt;p&gt;This is the 3rd project in less than a year where I√¢ve seen issues with spin-loops. I√¢ve been dealing with spinning threads for many years now, and I won√¢t lie: over the years I√¢ve been both on the offender and victim side.&lt;lb/&gt; I√¢m getting tired of seeing the same issues again and again, which usually makes for a good reason to write a blog post so that, hopefully, people will read it and stop making the same mistakes others did.&lt;/p&gt;
    &lt;p&gt;Actually, many others have written about this, covering various issues related to spin locks 1 2 3 4 5 6. But I guess there√¢s never enough material on those subjects. Some are about speed, others about fairness, a few about priority inversion, NUMA, and sometimes even about actually broken code.&lt;lb/&gt; If this list hasn√¢t convinced you that things do spin out of control when using spin-locks, and that you should use OS primitives instead, keep reading. I√¢ll cover what you should not do when implementing your own spin-lock. Notice I said what you should NOT do, because, again, you should probably not use a spin-lock at all these days.&lt;lb/&gt; And if you do√¢¬¶ make sure you really, REALLY, REALLY know what you√¢re doing (spoiler: it will always come back to bite you when you least expect it).&lt;/p&gt;
    &lt;p&gt;Note this is a story about spin loops in general, not about locking algorithms for which there are many 5.&lt;/p&gt;
    &lt;head rend="h1"&gt;The broken spin-lock&lt;/head&gt;
    &lt;p&gt;Let√¢s start with the basics, you want to implement your own spinlock.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;√∞¬§¬™ √¢It√¢s easy! You simply have a boolean, a&lt;/p&gt;&lt;code&gt;lock&lt;/code&gt;and an&lt;code&gt;unlock&lt;/code&gt;function.√¢&lt;/quote&gt;
    &lt;p&gt;Right√¢¬¶&lt;/p&gt;
    &lt;p&gt;For demonstration purposes, we are using &lt;code&gt;int&lt;/code&gt; instead of &lt;code&gt;bool&lt;/code&gt; as you might have something more complicated to do with it, such as storing metadata (for example: the thread ID). There are also quite a few pieces of code around that do not implement a spin-lock per se, but mutate some other content such as pointers.&lt;/p&gt;
    &lt;code&gt;class BrokenSpinLock
{
    // Using int32_t instead of bool on purpose, don't mind it.
    int32_t isLocked = 0;
public:
    void lock()
    {
        while (isLocked != 0) // (1)
        {
            // Loop again until not locked anymore
        }
                            // (2)
        isLocked = 1;       // (3)
    }                       // (4)

    void unlock()
    {
        isLocked = 0;
    }
};&lt;/code&gt;
    &lt;p&gt;Those who have dealt with multi-threading before will immediately spot the issue. The code is not thread-safe as, if multiple threads attempt to use this lock, we could read invalid values of &lt;code&gt;isLocked&lt;/code&gt; (in theory, and on a CPU where tearing could happen on its word size).
Worse, even if this could not happen, a wild race-condition could appear.&lt;lb/&gt; Consider the following example where two threads would call &lt;code&gt;lock&lt;/code&gt; at the exact same time:&lt;/p&gt;
    &lt;code&gt;(1) ThreadA: Sees `isLocked == 0` | ThreadB: Sees `isLocked == 0` 
(2) ThreadA: Leaves the loop      | ThreadB: Leaves the loop       
(3) ThreadA: Writes 1 to isLocked | ThreadB: Writes 1 to isLocked &lt;/code&gt;
    &lt;p&gt;Now we have two threads who think they have successfully acquired the lock!&lt;/p&gt;
    &lt;p&gt;Some may also have heard about this shiny little thing called &lt;code&gt;atomic&lt;/code&gt; variables/operations.&lt;lb/&gt; To oversimplify: atomic operations guarantee that other threads cannot observe a partial/intermediate state of the operation and thus race-conditions can not occur (on those specific operations and memory).&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;√∞¬° While named after the Greek&lt;/p&gt;&lt;code&gt;atomos&lt;/code&gt;that means √¢that which cannot be divided√¢,&lt;code&gt;atomic&lt;/code&gt;operations might as well be as dangerous and difficult to use as nuclear energy.&lt;/quote&gt;
    &lt;p&gt;Let√¢s replace &lt;code&gt;isLocked&lt;/code&gt; by an atomic version: &lt;code&gt;std::atomic&amp;lt;int&amp;gt;&lt;/code&gt;. Though our code does not suffer from a race-condition on the data itself, we still do not know if the thread that sets &lt;code&gt;isLocked&lt;/code&gt; to &lt;code&gt;1&lt;/code&gt; is the one that now owns the lock. But we can now do an &lt;code&gt;exchange&lt;/code&gt; operation atomically, which solves our little problem!&lt;/p&gt;
    &lt;p&gt;Instead of first checking if the lock is locked, then writing, we actually write our value and get the previous value, in a single atomic operation! If the previous value was &lt;code&gt;0&lt;/code&gt;, then it means we√¢re the one who actually did the locking. Otherwise we will see a &lt;code&gt;1&lt;/code&gt;, meaning the lock was already held either before we tried, or because another thread√¢s exchange completed before ours.&lt;/p&gt;
    &lt;code&gt;void lock()
{
    while (isLocked.exchange(1) != 0) {}
}&lt;/code&gt;
    &lt;p&gt;Let√¢s replay the scenario. Even if both threads execute the exchange simultaneously, atomicity guarantees one will finish before the other, for example Thread B√¢s:&lt;/p&gt;
    &lt;code&gt;ThreadA: `isLocked.exchange(1)` | ThreadB: `isLocked.exchange(1)` 
ThreadA: Writes 1, sees 1       | ThreadB: Writes 1, sees 0       
ThreadA: Writes 1, sees 1       | ThreadB: Now owns the lock!
ThreadA: ...                    | ThreadB: ... 
ThreadA: ...                    | ThreadB: `unlock()`, writes 0 
ThreadA: Writes 1, sees 0       | ThreadB: ... 
ThreadA: Now owns the lock!     | ThreadB: ... &lt;/code&gt;
    &lt;p&gt;Good, we now have a working spin-lock, but we still have a long way to go.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;√∞¬° In the CPU lingua, a memory read/write is called a memory load/store&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h1"&gt;The spin-lock that burned CPUs&lt;/head&gt;
    &lt;p&gt;You may have realized that our spin-lock will√¢¬¶ spin doing nothing, the loop is empty.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;√∞¬§¬™ √¢Great, it√¢ll attempt to take ownership faster√¢&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Well, that√¢s only true if you want to burn your CPU. Since the CPU has no way of knowing that you are waiting and not doing any meaningful work, it might stay at a high frequency. Modern CPUs can change the frequency of the cores to save energy, and effectively also lower the CPU core temperature. This is clearly not desirable behavior, especially on mobile/embedded devices.&lt;/p&gt;
    &lt;p&gt;Not convinced or do not care about the planet? (shame on you!) Then at least think about your users√¢ power bill. Still not convinced? What if I told you this can actually be slower than doing something in the loop?&lt;lb/&gt; Imagine that a lot of threads are attempting to lock your spin-lock. Only one can win. But worse, due to its nature you always do memory writes, which need to be synchronized between the different cores of your CPU!&lt;/p&gt;
    &lt;p&gt;From Intel√¢s Optimization Reference Manual 3 11.4.2:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;On a modern microprocessor with a superscalar speculative execution engine, a loop like this results in the issue of multiple simultaneous read requests from the spinning thread. These requests usually execute out-of-order with each read request being allocated a buffer resource. On detection of a write by a worker thread to a load that is in progress, the processor must guarantee no violations of memory order occur. The necessity of maintaining the order of outstanding memory operations inevitably costs the processor a severe penalty that impacts all threads.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;And the issue will keep getting bigger with recent CPUs that have many cores and sometimes NUMA memory.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;This penalty occurs on the Intel Core Solo and Intel Core Duo processors. However, the penalty on these processors is small compared with penalties suffered on the Intel Xeon processors. There the performance penalty for exiting the loop is about 25 times more severe.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;If you still need some convincing√¢¬¶ this is even worse if you enable SMT (hyperthreading):&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;On a processor supporting Intel HT Technology, spin-wait loops can consume a significant portion of the execution bandwidth of the processor. One logical processor executing a spin-wait loop can severely impact the performance of the other logical processor.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Now that I hopefully have your attention, here√¢s how to &lt;del&gt;solve&lt;/del&gt; mitigate the issue:&lt;lb/&gt; The best way to avoid √¢bothering√¢ your neighbours is to &lt;del&gt;avoid spin loops&lt;/del&gt; tell the CPU you are waiting to be notified of a memory change/doing a spinloop! On x86 CPUs, this is done with the &lt;code&gt;PAUSE&lt;/code&gt; instruction. It was designed exactly for this use-case!&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;The penalty of exiting from a spin-wait loop can be avoided by inserting a&lt;/p&gt;&lt;code&gt;PAUSE&lt;/code&gt;instruction in the loop. In spite of the name, the&lt;code&gt;PAUSE&lt;/code&gt;instruction improves performance by introducing a slight delay in the loop and effectively causing the memory read requests to be issued at a rate that allows immediate detection of any store to the synchronization variable. This prevents the occurrence of a long delay due to memory order violation.&lt;/quote&gt;
    &lt;p&gt;You can modify the code to use this instruction with compiler intrinsics:&lt;/p&gt;
    &lt;code&gt;void cpu_pause()
{
#if defined(__i386__) || defined(__x86_64__) || defined(_M_IX86) || defined(_M_X64)
    _mm_pause();
#elif defined(__arm__) || defined(__aarch64__) || defined(_M_ARM) || defined(_M_ARM64) || defined(_M_ARM64EC)
    __yield();
#else
    #error "unknown instruction set"
#endif
}

void lock()
{
    while (isLocked.exchange(1) != 0)
    {
        cpu_pause();
    }
}&lt;/code&gt;
    &lt;head rend="h1"&gt;The spin-lock that didn√¢t wait enough&lt;/head&gt;
    &lt;p&gt;As already mentioned, the penalty of synchronizing data between CPU cores is getting more expensive as new CPUs get more cores, get multiple core complexes or NUMA architectures. Resolving conflicts (multiple cores trying to do atomic stores) thus needs to be mitigated in some way. A traditional approach is to use a backoff strategy that increases the number of &lt;code&gt;PAUSE&lt;/code&gt; instructions for each attempt at locking.&lt;/p&gt;
    &lt;p&gt;The one you will find most (recommended by the Intel Optimization Manual, 2.7.4), is the exponential backoff:&lt;/p&gt;
    &lt;code&gt;void lock()
{
    const int maxPauses = 64; // MAX_BACKOFF
    int nbPauses = 1;
    while (isLocked.exchange(1) != 0)
    {
        for (int i = 0; i&amp;lt;nbPauses; i++)
            cpu_pause();
        // Multiply the number of pauses by 2 until we reach the max backoff count.
        nbPauses = nbPauses &amp;lt; maxPauses ? nbPauses * 2 : nbPauses;
    }
}&lt;/code&gt;
    &lt;p&gt;As mentioned by Intel:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;The number of&lt;/p&gt;&lt;code&gt;PAUSE&lt;/code&gt;instructions are increased by a factor of 2 until some&lt;code&gt;MAX_BACKOFF&lt;/code&gt;is reached which is subject to tuning.&lt;/quote&gt;
    &lt;p&gt;We also mix it with a bit of randomness by using &lt;code&gt;rdtsc&lt;/code&gt;, and let√¢s refactor the yielding part into a structure that can be easily swapped:&lt;/p&gt;
    &lt;code&gt;struct Yielder
{
    static const int maxPauses = 64; // MAX_BACKOFF
    int nbPauses = 1;
    void do_yield()
    {
        // jitter is in the range of [0;nbPauses-1].
        // We can use bitwise AND since nbPauses is a power of 2.
        const int jitter = static_cast&amp;lt;int&amp;gt;(__rdtsc() &amp;amp; (nbPauses - 1));
        // So subtracting we get a value between [1;nbPauses]
        const int nbPausesThisLoop = nbPauses - jitter;
        for (int i = 0; i &amp;lt; nbPausesThisLoop; i++) 
            cpu_pause();
        // Multiply the number of pauses by 2 until we reach the max backoff count.
        nbPauses = nbPauses &amp;lt; maxPauses ? nbPauses * 2 : nbPauses;
    }
}

void lock()
{
    Yielder yielder;
    while (isLocked.exchange(1) != 0)
    {
        yielder.do_yield();
    }
}&lt;/code&gt;
    &lt;head rend="h1"&gt;The spin-lock that waited too long&lt;/head&gt;
    &lt;p&gt;Remember the comment above about &lt;code&gt;MAX_BACKOFF&lt;/code&gt; being subject to tuning?
Well you√¢d better make sure to tune it for the exact CPU you√¢ll be working on.&lt;lb/&gt; Let√¢s have a look at the following table listing the measured7 duration of &lt;code&gt;PAUSE&lt;/code&gt; in cycles:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="18"&gt;
        &lt;cell role="head"&gt;Sandy Bridge&lt;/cell&gt;
        &lt;cell role="head"&gt;Ivy Bridge&lt;/cell&gt;
        &lt;cell role="head"&gt;Haswell&lt;/cell&gt;
        &lt;cell role="head"&gt;Broadwell&lt;/cell&gt;
        &lt;cell role="head"&gt;Skylake&lt;/cell&gt;
        &lt;cell role="head"&gt;Kaby Lake&lt;/cell&gt;
        &lt;cell role="head"&gt;Coffee Lake&lt;/cell&gt;
        &lt;cell role="head"&gt;Cannon Lake&lt;/cell&gt;
        &lt;cell role="head"&gt;Cascade Lake&lt;/cell&gt;
        &lt;cell role="head"&gt;Ice Lake&lt;/cell&gt;
        &lt;cell role="head"&gt;Rocket Lake&lt;/cell&gt;
        &lt;cell role="head"&gt;Alder Lake-P&lt;/cell&gt;
        &lt;cell role="head"&gt;Tremont&lt;/cell&gt;
        &lt;cell role="head"&gt;Alder Lake-E&lt;/cell&gt;
        &lt;cell role="head"&gt;AMD Zen+&lt;/cell&gt;
        &lt;cell role="head"&gt;AMD Zen2&lt;/cell&gt;
        &lt;cell role="head"&gt;AMD Zen3&lt;/cell&gt;
        &lt;cell role="head"&gt;AMD Zen4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;11.00&lt;/cell&gt;
        &lt;cell&gt;10.00&lt;/cell&gt;
        &lt;cell&gt;9.00&lt;/cell&gt;
        &lt;cell&gt;9.00&lt;/cell&gt;
        &lt;cell&gt;140.00&lt;/cell&gt;
        &lt;cell&gt;140.00&lt;/cell&gt;
        &lt;cell&gt;152.50&lt;/cell&gt;
        &lt;cell&gt;157.00&lt;/cell&gt;
        &lt;cell&gt;40.00&lt;/cell&gt;
        &lt;cell&gt;138.20&lt;/cell&gt;
        &lt;cell&gt;138.20&lt;/cell&gt;
        &lt;cell&gt;160.17&lt;/cell&gt;
        &lt;cell&gt;176.00&lt;/cell&gt;
        &lt;cell&gt;61.80&lt;/cell&gt;
        &lt;cell&gt;3.00&lt;/cell&gt;
        &lt;cell&gt;65.00&lt;/cell&gt;
        &lt;cell&gt;65.00&lt;/cell&gt;
        &lt;cell&gt;65.00&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;And that√¢s where the issue lies. Depending on the architecture, you may get more than 10x changes in cycles per &lt;code&gt;PAUSE&lt;/code&gt;.&lt;lb/&gt; Old CPUs tended to have small &lt;code&gt;PAUSE&lt;/code&gt; duration of ~10 cycles on Intel, ~3 on AMD, where new architectures have a duration of 100-160 cycles on Intel, and ~60 cycles on AMD.
And this might get worse in the future!&lt;/p&gt;
    &lt;p&gt;This actually is also now part of the latest Intel Optimization Reference Manual 3 2.7.4:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;The latency of the&lt;/p&gt;&lt;code&gt;PAUSE&lt;/code&gt;instruction in prior generation microarchitectures is about 10 cycles, whereas in Skylake Client microarchitecture it has been extended to as many as 140 cycles.&lt;/quote&gt;
    &lt;p&gt;How to fix this, you ask? I√¢ll defer to Intel√¢s advice again and limit the duration of the &lt;code&gt;PAUSE&lt;/code&gt; loop using CPU cycles instead of a counter:&lt;/p&gt;
    &lt;code&gt;static inline bool before(uint64_t a, uint64_t b)
{
    return ((int64_t)b - (int64_t)a) &amp;gt; 0;
}
void pollDelay(uint32_t clocks)
{
    uint64_t endTime = _rdtsc()+ clocks;
    for (; before(_rdtsc(), endTime); )
        cpu_pause();
}&lt;/code&gt;
    &lt;quote&gt;&lt;p&gt;As the&lt;/p&gt;&lt;code&gt;PAUSE&lt;/code&gt;latency has been increased significantly, workloads that are sensitive to&lt;code&gt;PAUSE&lt;/code&gt;latency will suffer some performance loss.&lt;lb/&gt;[√¢¬¶]&lt;lb/&gt;Notice that in the Skylake Client microarchitecture the&lt;code&gt;RDTSC&lt;/code&gt;instruction counts at the machine√¢s guaranteed P1 frequency independently of the current processor clock (see the INVARIANT TSC property), and therefore, when running in Intel√Ç¬Æ Turbo-Boost-enabled mode, the delay will remain constant, but the number of instructions that could have been executed will change.&lt;/quote&gt;
    &lt;p&gt;Let√¢s implement this:&lt;/p&gt;
    &lt;code&gt;struct Yielder
{
    static const int maxPauses = 64; // MAX_BACKOFF
    int nbPauses = 1;
    
    const int maxCycles = /*Some value*/;
    
    void do_yield()
    {
        uint64_t beginTSC = __rdtsc();
        uint64_t endTSC = beginTSC + maxCycles; // Max duration of the yield
        // jitter is in the range of [0;nbPauses-1].
        // We can use bitwise AND since nbPauses is a power of 2.
        const int jitter = static_cast&amp;lt;int&amp;gt;(beginTSC &amp;amp; (nbPauses - 1));
        // So subtracting we get a value between [1;nbPauses]
        const int nbPausesThisLoop = nbPauses - jitter;
        for (int i = 0; i &amp;lt; nbPausesThisLoop &amp;amp;&amp;amp; before(__rdtsc(), endTSC); i++) 
            cpu_pause();
        // Multiply the number of pauses by 2 until we reach the max backoff count.
        nbPauses = nbPauses &amp;lt; maxPauses ? nbPauses * 2 : nbPauses;
    }
}

void lock()
{
    Yielder yield;
    while (isLocked.exchange(1) != 0)
    {
        yield.do_yield();
    }
}&lt;/code&gt;
    &lt;p&gt;This method has two main advantages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We define the max duration of a &lt;code&gt;PAUSE&lt;/code&gt;loop in terms of&lt;code&gt;TSC&lt;/code&gt;cycles, which is (on most modern CPUs) independent of the actual frequency of the core or duration of&lt;code&gt;PAUSE&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;If the operating system happens to preempt our thread in the middle of the loop, it will stop yielding after being rescheduled if maximum duration has been exceeded. Otherwise we could call &lt;code&gt;PAUSE&lt;/code&gt;more than necessary on a thread wakeup.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You√¢ll notice that we kept the exponential backoff as a plain counter. This is to avoid having to compute the duration of a single &lt;code&gt;PAUSE&lt;/code&gt; (this would require getting rid of the jitter).
However, we still need to choose a value for &lt;code&gt;maxCycles&lt;/code&gt;. This again is purely empirical and needs tuning, but one may assume the duration of a context switch is about 3√Ç¬µs. Depending on the system and actual switch this can be more or be less. But it should be in the same order of magnitude.
We can then estimate the TSC cycles/√Ç¬µs conversion to be ~3200cycles/√Ç¬µs  for a 3.2Ghz clock. Another common frequency for the TSC is 2.5GHz.
While obviously incorrect, this is a good guesstimate for a default value on PC. At worst, you√¢ll most likely get a 2x difference with the real value, which is way better than the x10 you could get with the varying &lt;code&gt;PAUSE&lt;/code&gt; durations!&lt;/p&gt;
    &lt;p&gt;I did however mention this is a default value, and the best thing to do is to retrieve the real value, either from the OS or by measuring it. Sadly TSC calibration is not officially exposed by Linux/Windows, so the best way is to measure the TSC against the system high resolution clock. Ideally this should be done asynchronously (don√¢t do it on your application main thread at boot, please).&lt;/p&gt;
    &lt;code&gt;// Please, do this asynchronously and not during your main thread init
// Otherwise you will make your application boot longer for nothing!
// Note there are more accurate ways to do this, but we do not need a very high precision nor accuracy.
// You may also split this function in two and do some meaningful amount of work instead of sleeping.
uint64_t MeasureCyclesPerUs()
{
    const auto clockBefore = std::chrono::high_resolution_clock::now();
    const uint64_t cyclesBefore = __rdtsc();
    std::this_thread::sleep_for(std::chrono::microseconds{10});
    const auto clockAfter = std::chrono::high_resolution_clock::now();
    const uint64_t cyclesAfter = __rdtsc();
    const auto clockDelta = clockAfter - clockBefore;
    const uint64_t cyclesDelta = cyclesAfter - cyclesBefore;
    const uint64_t cyclesPerUs = (1000 * cyclesDelta) / std::chrono::nanoseconds(clockDelta).count();
    return cyclesPerUs;
}&lt;/code&gt;
    &lt;quote&gt;&lt;p&gt;√∞¬° Windows actually √¢exposes√¢ this value as&lt;/p&gt;&lt;code&gt;CyclesPerYield&lt;/code&gt;in the kernel shared data at offset&lt;code&gt;0x2D6&lt;/code&gt;. This is used internally by synchronization primitives to determine how many&lt;code&gt;PAUSE&lt;/code&gt;instructions it should issue. However I wouldn√¢t recommend using those internals unless your code sanitizes the value.&lt;/quote&gt;
    &lt;head rend="h1"&gt;The spin-lock that used too many barriers&lt;/head&gt;
    &lt;p&gt;We only briefly touched the topic of &lt;code&gt;atomics&lt;/code&gt;. All atomic operations actually take an optional parameter which is the memory order.
I don√¢t want to spend too much time on this as entire talks are dedicated to it, and it√¢s not an easy topic.&lt;/p&gt;
    &lt;p&gt;However do know this: not providing the parameter is equivalent to using &lt;code&gt;std::memory_order_seq_cst&lt;/code&gt; (sequentially consistent) which enforces the most restrictions. On some platforms this may even flush your cache via memory barriers!
Our previous example can actually be re-written using acquire/release semantics:&lt;/p&gt;
    &lt;code&gt;void lock()
{
    Yielder yield;
    while (isLocked.exchange(1, std::memory_order_acquire) != 0)
    {
        yield.do_yield();
    }
}

void unlock()
{
    isLocked.store(0, std::memory_order_release);
}&lt;/code&gt;
    &lt;p&gt;On my x64 machine and exponential backoff:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Lock Type&lt;/cell&gt;
        &lt;cell role="head"&gt;Uncontended (ops/s)&lt;/cell&gt;
        &lt;cell role="head"&gt;Contended (ops/s)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;ExpBackoff+SeqCst&lt;/cell&gt;
        &lt;cell&gt;313M&lt;/cell&gt;
        &lt;cell&gt;55.3M&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;ExpBackoff+AcqRel&lt;/cell&gt;
        &lt;cell&gt;612M&lt;/cell&gt;
        &lt;cell&gt;58.7M&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;ExpBackoff+Acquire&lt;/cell&gt;
        &lt;cell&gt;652M&lt;/cell&gt;
        &lt;cell&gt;65.3M&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;You may have a look at the various assemblies generated on this compiler explorer example https://godbolt.org/z/GjEEWPsj8.&lt;/p&gt;
    &lt;head rend="h1"&gt;The spin-lock that saturated the load ports&lt;/head&gt;
    &lt;p&gt;A spin-lock should be fast, otherwise you would just use your average system lock. While we mitigated the inter-core synchronization with the jitter and exponential backoff, there are ways to reduce the cache coherency 8 traffic under contention. This has been mentioned by many in the past 9 10 11 but it doesn√¢t hurt to remind it again. Instead of looping over a Test-And-Set (aka Compare-And-Swap) operation, prefer using both Test and Test-And-Set operations! It also applies to our Load-And-Test (aka Exchange) operation.&lt;/p&gt;
    &lt;p&gt;So instead of:&lt;/p&gt;
    &lt;code&gt;void lock()
{
    Yielder yield;
    while (isLocked.exchange(1, std::memory_order_acquire) != 0)
    {
        yield.do_yield();
    }
}&lt;/code&gt;
    &lt;p&gt;Do:&lt;/p&gt;
    &lt;code&gt;void lock()
{
    Yielder yield;
    // Actually start by an exchange, we assume the lock is not already taken
    // This is because the main use case of a spinlock is when there's no contention!
    while (isLocked.exchange(1, std::memory_order_acquire) != 0)
    {
        // To avoid locking the cache line with a write access, always only read before attempting the writes
        do {
            yield.do_yield(); // Yield while we fail to obtain the lock.
        } while (isLocked.load(std::memory_order_relaxed) != 0);
    }
}&lt;/code&gt;
    &lt;head rend="h1"&gt;The spin-lock that didn√¢t handle priority inversion&lt;/head&gt;
    &lt;p&gt;Priority inversion is one of the worst things that could (and will) happen with a spinlock. And it impacts most severely the platforms that need them the most! (Embedded, real-time OSes, √¢¬¶) Let√¢s have a look at the issue:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;A low-priority thread acquires your spinlock&lt;/item&gt;
      &lt;item&gt;A high-priority thread tries to acquire the lock and starts spinning&lt;/item&gt;
      &lt;item&gt;The OS scheduler preempts the low-priority thread to run another thread with medium/high priority (anything higher than √¢low√¢)&lt;/item&gt;
      &lt;item&gt;There are no cores left to run the low priority thread as they are all used by higher priority threads.&lt;/item&gt;
      &lt;item&gt;The high-priority thread burns CPU cycles spinning forever.&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;&lt;p&gt;√∞¬§¬™ √¢Let√¢s use&lt;/p&gt;&lt;code&gt;std::this_thread::yield()&lt;/code&gt;?√¢&lt;/quote&gt;
    &lt;p&gt;Meh, did you test it on multiple systems? I√¢ll play along and give it a try.&lt;/p&gt;
    &lt;code&gt;struct Yielder
{
    void do_yield_expo_and_jitter()
    {
        // Same as before, exponential backoff and jitter
    }

    void do_yield()
    {
        do_yield_expo_and_jitter();
        if (nbPauses &amp;gt;= maxPauses)
        {
            std::this_thread::yield(); // Yield thread back to the OS
            nbPauses = 1;
        }
    }
}&lt;/code&gt;
    &lt;p&gt;Now when we reach the maximum number of iterations, we make the thread yield its quantum to the operating system (&lt;code&gt;SwitchToThread&lt;/code&gt; on Windows, &lt;code&gt;sched_yield&lt;/code&gt; on Linux) so that another thread may be scheduled.
While in practice this may, sometimes, solve the issue as the OS is now free to schedule other threads including the low priority one, this is not mandatory!
Some implementations may end up just rescheduling the thread that just yielded since it√¢s of higher priority.&lt;/p&gt;
    &lt;p&gt;You may have also seen implementations that use &lt;code&gt;Sleep(0)&lt;/code&gt; on Windows. This is better than &lt;code&gt;SwitchToThread&lt;/code&gt; (which can only yield to a thread ready to run on the current core, per the docs12. Same for normal Linux schedulers13). However this used to14 only yield to threads of same or higher priorities, and still does on the real-time version of the OS! For example on an embedded device, or a console.
The only way to schedule any thread on real-time kernels, be it Windows or Linux, is to sleep for a non-zero duration√¢¬¶ which we obviously would like to avoid!&lt;/p&gt;
    &lt;p&gt;So the solution that the DotNet runtime team came up with is to start with &lt;code&gt;SwitchToThread&lt;/code&gt;, then &lt;code&gt;Sleep(0)&lt;/code&gt; then &lt;code&gt;Sleep(1)&lt;/code&gt;!&lt;/p&gt;
    &lt;code&gt;// We prefer to call Thread.Yield first, triggering a SwitchToThread. This
// unfortunately doesn't consider all runnable threads on all OS SKUs. In
// some cases, it may only consult the runnable threads whose ideal processor
// is the one currently executing code. Thus we occasionally issue a call to
// Sleep(0), which considers all runnable threads at equal priority. Even this
// is insufficient since we may be spin waiting for lower priority threads to
// execute; we therefore must call Sleep(1) once in a while too, which considers
// all runnable threads, regardless of ideal processor and priority, but may
// remove the thread from the scheduler's queue for 10+ms, if the system is
// configured to use the (default) coarse-grained system timer.&lt;/code&gt;
    &lt;head rend="h1"&gt;The spin-locks that woke something unrelated&lt;/head&gt;
    &lt;p&gt;So we dealt with the priority inversion at the cost of potential sleeps.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;√∞¬§¬™ √¢Ship it!√¢&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Please god no√¢¬¶ Yes, you (most likely) avoid the worst case scenario (the livelock), but really, is it fine?&lt;/p&gt;
    &lt;p&gt;Let√¢s stop for a second here and assume we never did more than yield.&lt;/p&gt;
    &lt;p&gt;As you may have already guessed, a livelock is only half the story (this is starting to be a recurring pattern, isn√¢t it?). The fact is, the issue could happen even if all your threads have the same priority! (Yes, I saw you coming asking for an easy fix by removing priorities.) Consider the following scenario:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;4 cores machine&lt;/item&gt;
      &lt;item&gt;4 high priority threads: A, B, C, D (your thread pool)&lt;/item&gt;
      &lt;item&gt;4 other high priority threads: X, Y, W, Z (controlled by a 3rd party, those suck. Please library writers, don√¢t spawn threads on your own, thank you!).&lt;/item&gt;
      &lt;item&gt;Thread A acquires the lock&lt;/item&gt;
      &lt;item&gt;Threads B, C, D spin, trying to acquire it.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;At this point, we have the following:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Core 0&lt;/cell&gt;
        &lt;cell role="head"&gt;Core 1&lt;/cell&gt;
        &lt;cell role="head"&gt;Core 2&lt;/cell&gt;
        &lt;cell role="head"&gt;Core 3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Thread A&lt;/cell&gt;
        &lt;cell&gt;Thread B&lt;/cell&gt;
        &lt;cell&gt;Thread C&lt;/cell&gt;
        &lt;cell&gt;Thread D&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Thread X gets scheduled (A somehow released its quantum, still holds the lock)&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Core 0&lt;/cell&gt;
        &lt;cell role="head"&gt;Core 1&lt;/cell&gt;
        &lt;cell role="head"&gt;Core 2&lt;/cell&gt;
        &lt;cell role="head"&gt;Core 3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Thread X&lt;/cell&gt;
        &lt;cell&gt;Thread B&lt;/cell&gt;
        &lt;cell&gt;Thread C&lt;/cell&gt;
        &lt;cell&gt;Thread D&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Thread B yields, Y is scheduled&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Core 0&lt;/cell&gt;
        &lt;cell role="head"&gt;Core 1&lt;/cell&gt;
        &lt;cell role="head"&gt;Core 2&lt;/cell&gt;
        &lt;cell role="head"&gt;Core 3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Thread X&lt;/cell&gt;
        &lt;cell&gt;Thread Y&lt;/cell&gt;
        &lt;cell&gt;Thread C&lt;/cell&gt;
        &lt;cell&gt;Thread D&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Thread Y yields, B is scheduled again, C and D yield to W and Z&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Core 0&lt;/cell&gt;
        &lt;cell role="head"&gt;Core 1&lt;/cell&gt;
        &lt;cell role="head"&gt;Core 2&lt;/cell&gt;
        &lt;cell role="head"&gt;Core 3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Thread X&lt;/cell&gt;
        &lt;cell&gt;Thread B&lt;/cell&gt;
        &lt;cell&gt;Thread W&lt;/cell&gt;
        &lt;cell&gt;Thread Z&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;I could continue this for a long time. Even though thread A might get scheduled again, it might not! This depends on your scheduler√¢s internals. Especially since yielding may yield only to the ready threads of the current core12 13. At the time of writing this article, this actually is a known issue with Address Sanitizer!&lt;/p&gt;
    &lt;p&gt;Oh, and even if it did get scheduled, you probably lost a lot of time switching from one thread to the other, this is your typical lock convoy15 and is what Linus Torvalds more or less hints here4 16 13:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;And no, adding random √¢&lt;/p&gt;&lt;code&gt;sched_yield()&lt;/code&gt;√¢ calls while you√¢re spinning on the spinlock will not really help. It will easily result in scheduling storms while people are yielding to all the wrong processes.&lt;/quote&gt;
    &lt;p&gt;So no, simply using the same priority for all threads or sleeping is not fine. Let√¢s see what we can do about it.&lt;/p&gt;
    &lt;head rend="h1"&gt;The spin-lock that spoke to the OS&lt;/head&gt;
    &lt;p&gt;The real problem, when you spin in a loop, is that you expect things to go fast so that your thread may continue.&lt;lb/&gt; But by yielding this way you defeat a lot of the kernel heuristics. It has no way to know what you actually meant, and may schedule anything (or nothing) but threads from your process. Worse, it may degrade your thread priority, move it to lower frequency cores, and you lose any kind of priority boost when waking up due to the lock being released√¢¬¶&lt;lb/&gt; That√¢s clearly not what we want. If only there was a way to communicate our intent to the OS√¢¬¶&lt;/p&gt;
    &lt;p&gt;Well that√¢s exactly what Linux did when introducing the futex API! Since we√¢re waiting in a loop for a value to change, just notify the OS about it and let it handle things from there. Windows also implements this with the &lt;code&gt;WaitOnAddress&lt;/code&gt; API, which we√¢ll be demonstrating here:&lt;/p&gt;
    &lt;code&gt;void do_yield(int32_t* address, int32_t comparisonValue, uint32_t timeoutMs)
{
    do_yield_expo_and_jitter();
    if (nbPauses &amp;gt;= maxPauses)
    {
        // The thread will stay asleep while the value at the given address doesn't change and `WakeByAddressSingle`/`WakeByAddressAll` isn't called.
        // We might have a spurious wakeup though, so the value needs to be checked afterward, which we already do since we spin.
        WaitOnAddress(address, &amp;amp;comparisonValue, sizeof(comparisonValue), timeoutMs);
        nbPauses = 1;
    }
}
void lock()
{
    Yielder yield;
    while (isLocked.exchange(1, std::memory_order_acquire) != 0)
    {
        do {
            yield.do_yield(&amp;amp;isLocked, 1 /*while locked*/ , 1 /*ms*/);
        } while (isLocked.load(std::memory_order_relaxed) != 0);
    }
}
void unlock()
{
    isLocked = 0;
    WakeByAddressSingle(&amp;amp;isLocked); // Notify a potential thread waiting, if any.
}&lt;/code&gt;
    &lt;p&gt;Windows√¢ &lt;code&gt;WaitOnAddress&lt;/code&gt; internally does a single iteration before issuing the system call, but Linux√¢s futex API is a direct syscall. That√¢s why we call &lt;code&gt;WaitOnAddress&lt;/code&gt; only after spinning a bit.&lt;lb/&gt; This lets us have a similar spinning strategy on all platforms, which ensures a more consistent behavior.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;√∞¬° You may notice that we always end up calling&lt;/p&gt;&lt;code&gt;WakeByAddressSingle&lt;/code&gt;even if there√¢s no other thread waiting. While not that slow on Windows, this is slow on Linux since it will do a syscall. To avoid that one would usually store some state such as the number of waiting (parked) threads.&lt;/quote&gt;
    &lt;quote&gt;&lt;p&gt;√∞¬§¬™ √¢Wait! Wasn√¢t&lt;/p&gt;&lt;code&gt;std::atomic_wait&lt;/code&gt;added to the standard recently?√¢&lt;/quote&gt;
    &lt;p&gt;Yes! And this is what one should have used if implementers did the right thing from the get-go (and more importantly did the same thing for each implementation), but this was not the case√¢¬¶17&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;libc++&lt;/code&gt;(clang) used to do exponential backoff with thread yields before&lt;code&gt;futex&lt;/code&gt;. At least it got fixed in January 2025 but it still does exponential backoff.&lt;/item&gt;
      &lt;item&gt;MSVC STL does the right thing√¢¬¢ imho and goes almost straight to the OS since the first implementation. Good job!&lt;/item&gt;
      &lt;item&gt;So does &lt;code&gt;libstdc++&lt;/code&gt;(GCC)!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So if you use it, you may get a built-in exponential backoff, or not. Both implementations actually make sense from an implementer√¢s point of view (Do you expect &lt;code&gt;std::atomic_wait&lt;/code&gt; users to use it with their own backoff strategies? Or directly as condition variables?), but this difference ends up being problematic since the code behaves differently between implementations.&lt;lb/&gt; In the end, as usual with the &lt;code&gt;std&lt;/code&gt; library, you√¢re better off using the OS primitives directly if you want portable behaviour that you control.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;As mentioned, Windows√¢&lt;/p&gt;&lt;code&gt;WaitOnAddress&lt;/code&gt;will do a single spin before doing a syscall. The duration of&lt;code&gt;PAUSE&lt;/code&gt;is computed on process start by the loader in&lt;code&gt;LdrpInitializeProcess&lt;/code&gt;and stored in&lt;code&gt;ntdll.dll!RtlpWaitOnAddressSpinCycleCount&lt;/code&gt;.&lt;/quote&gt;
    &lt;head rend="h1"&gt;The spin-lock that was unfair&lt;/head&gt;
    &lt;p&gt;An issue with some lock algorithms is that they may be unfair: this is what happens when under contention a thread may never actually grab the ownership of the lock if other threads are faster.&lt;lb/&gt; This time I√¢ll simply give a warning and ask you to trust me as this article is starting to be lengthy. You may have encountered some √¢ticket√¢ locks that attempt to enhance the fairness of the lock. While it may look good on paper, it√¢s actually not so good in practice.&lt;/p&gt;
    &lt;p&gt;Not only is it slower due to its complexity, but as mentioned before only the OS really knows what√¢s good for scheduling. And if you want to use a &lt;code&gt;futex&lt;/code&gt;-like API you end up having to wake up all potential waiters instead of just the one you want. So please, rely on the OS primitives for fairness instead. (Even if we didn√¢t have those primitives, a random+exponential backoff may perform better than a ticket lock anyway!)&lt;/p&gt;
    &lt;head rend="h1"&gt;The spin-locks that were falsely sharing&lt;/head&gt;
    &lt;p&gt;Here comes another tidbit of CPU architecture: even if you write to different variables, they may share the same cacheline! And this is really bad for performance when you do atomic operations on the same cacheline, even if the addresses are different. To fix this issue, you may enforce alignment of your variables or use padding in a &lt;code&gt;struct&lt;/code&gt;. False sharing is also known as destructive interference, which led to the standard√¢s &lt;code&gt;std::hardware_destructive_interference_size&lt;/code&gt; value!&lt;/p&gt;
    &lt;code&gt;alignas(std::hardware_destructive_interference_size) MyLock lock1;
alignas(std::hardware_destructive_interference_size) MyLock lock2;&lt;/code&gt;
    &lt;p&gt;This is however not a silver bullet!&lt;lb/&gt; While you will avoid false sharing, you may also fill your TLB and L1 cache faster which may lead to more cache thrashing.&lt;/p&gt;
    &lt;p&gt;You may even encounter cache bank conflicts. Cache bank conflicts only exist on some CPUs, but don√¢t trust manufacturers to avoid them. From 3.6.1.3 of the Intel Optimization Reference Manual:&lt;/p&gt;
    &lt;quote&gt;
      &lt;item&gt;√¢In the Sandy Bridge microarchitecture, the internal organization of the L1D cache may manifest [√¢¬¶]√¢&lt;/item&gt;
      &lt;item&gt;√¢The L1D cache bank conflict issue does not apply to Haswell microarchitecture.√¢&lt;/item&gt;
      &lt;item&gt;√¢In the Golden Cove microarchitecture, bank conflicts often happen when multiple loads access [√¢¬¶]√¢&lt;/item&gt;
      &lt;p&gt;√∞¬° So this was once an issue, then fixed, then it came back in another form.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;These are thankfully mitigated thanks to the random+exponential backoff, but are getting worse (this pattern of √¢yes, but√¢ should really annoy you by now, that√¢s the whole point of this article).&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Whenever possible, avoid reading the same memory location within a tight loop or using multiple load operations.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;And the only way to really fix that is to√¢¬¶ actually park the thread by calling an OS primitive such as a futex! You should also avoid doing multiple loads per loop, as recommended previously.&lt;/p&gt;
    &lt;head rend="h1"&gt;What about specialized instructions?&lt;/head&gt;
    &lt;quote&gt;&lt;p&gt;√∞¬§¬™ √¢I√¢ve read about&lt;/p&gt;&lt;code&gt;MWAIT&lt;/code&gt;and&lt;code&gt;TPAUSE&lt;/code&gt;.√¢&lt;/quote&gt;
    &lt;p&gt;And you should probably have read further as those are privileged instructions! But yes they do have the same look as a futex wait/wake, which is very tempting. And, to be fair, AMD does offer a userland alternative which is &lt;code&gt;monitorx&lt;/code&gt; and &lt;code&gt;mwaitx&lt;/code&gt; that we can use!&lt;/p&gt;
    &lt;p&gt;One advantage of &lt;code&gt;mwaitx&lt;/code&gt; is that you can tell the CPU to wait for a given TSC count instead of having to loop! So it can be used to replace the &lt;code&gt;_mm_pause&lt;/code&gt; loop when supported, and that√¢s actually what Windows√¢ locking primitives such as &lt;code&gt;WaitOnAddress&lt;/code&gt; or &lt;code&gt;AcquireSRWLockExclusive&lt;/code&gt; do internally!
Not only is the √¢API√¢ easier (you provide a timestamp for the wakeup date) but it can save power! 18 19&lt;lb/&gt; Just do not use it for long periods since you are still delaying potential work from other threads by not explicitly yielding to the OS.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;√∞¬°&lt;/p&gt;&lt;code&gt;mwaitx&lt;/code&gt;can spuriously wake up, but this is fine for our usage since we√¢ll just spin and try again!&lt;/quote&gt;
    &lt;head rend="h1"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;You√¢ll notice I barely mentioned ARM, that√¢s because I do not have enough experience with this architecture to give any advice other than you should use the proper memory ordering for decent performance.&lt;/p&gt;
    &lt;p&gt;If you read this far, I√¢ll say it again: in most (and pretty much all) cases you should not even need to worry about the performance of your locks. The best lock is the one you don√¢t use.&lt;/p&gt;
    &lt;p&gt;Again, from Linus: 4&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Because you should never ever think that you√¢re clever enough to write your own locking routines.. Because the likelihood is that you aren√¢t (and by that √¢you√¢ I very much include myself - we√¢ve tweaked all the in-kernel locking over decades, and gone through the simple test-and-set to ticket locks to cacheline-efficient queuing locks, and even people who know what they are doing tend to get it wrong several times).&lt;/p&gt;
      &lt;p&gt;There√¢s a reason why you can find decades of academic papers on locking. Really. It√¢s hard.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;But if you do, even after all those warnings, at least make sure you follow best practices and especially the pre-requisites for a spinlock to be efficient:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;There is low contention&lt;/item&gt;
      &lt;item&gt;The critical section (work done under the lock) is very small. (Consider that √¢small√¢ varies with the number of threads competing for the lock√¢¬¶)&lt;/item&gt;
      &lt;item&gt;Notify your OS about what you√¢re doing (&lt;code&gt;futex&lt;/code&gt;,&lt;code&gt;WaitOnAddress&lt;/code&gt;, √¢¬¶)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Bonus!&lt;/head&gt;
    &lt;p&gt;List of projects/libraries that do (or did) it wrong and that I happened to stumble upon:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;RPMalloc: the one that led to this rant, we had a dependency using it on console, and it caused livelocks. It only loops with a single CPU yield. Bad for perf, impossible (read: will break) to use on embedded platforms with a realtime scheduler.&lt;/item&gt;
      &lt;item&gt;OpenBSD√¢s libc goes straight to an OS thread &lt;code&gt;yield&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Glibc goes straight to &lt;code&gt;futex&lt;/code&gt;by default&lt;list rend="ul"&gt;&lt;item&gt;default mutex is the √¢simple√¢ one and only checks value once before going straight to the OS&lt;/item&gt;&lt;item&gt;&lt;code&gt;PTHREAD_MUTEX_ADAPTIVE_NP&lt;/code&gt;is mostly good! The number of spins is fixed by default but can be tweaked using the tunable&lt;code&gt;glibc.pthread.mutex_spin_count&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Intel TBB: &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;tbb::spinlock&lt;/code&gt;: simple backoff with 16 yields&lt;/item&gt;&lt;item&gt;&lt;code&gt;tbb::mutex&lt;/code&gt;: Pure&lt;code&gt;_mm_pause&lt;/code&gt;backoff with fixed count, then thread yield backoff, then uses a futex wait on linux, or plain semaphore on other platforms&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Webkit: &lt;list rend="ul"&gt;&lt;item&gt;OS Thread yield (&lt;code&gt;SwitchToThread&lt;/code&gt;/&lt;code&gt;sched_yield&lt;/code&gt;) on CAS failure&lt;/item&gt;&lt;item&gt;Hardcoded spincount&lt;/item&gt;&lt;item&gt;Duplicated here&lt;/item&gt;&lt;item&gt;Same thing here&lt;/item&gt;&lt;item&gt;Even though they have benchmarks (both for speed and fairness)!&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;OS Thread yield (&lt;/item&gt;
      &lt;item&gt;AddressSanitizer (ASAN) &lt;list rend="ul"&gt;&lt;item&gt;The Issue =&amp;gt; can livelock with a realtime scheduler&lt;/item&gt;&lt;item&gt;The Implementation&lt;/item&gt;&lt;item&gt;Yield is done by sched_yield on linux and &lt;code&gt;Sleep(0)&lt;/code&gt;on Windows&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;DotNet runtime still uses &lt;code&gt;Sleep&lt;/code&gt;instead of WaitOnAddress&lt;/item&gt;
      &lt;item&gt;And so many others√¢¬¶&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Footnotes&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Measuring Mutexes, Spinlocks and how Bad the Linux Scheduler Really Is - Malte Skarupke √¢¬©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Spinlocks Considered Harmful - matklad √¢¬©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Intel√Ç¬Æ 64 and IA-32 Architectures Optimization Reference Manual √¢¬© √¢¬©2 √¢¬©3&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Linus Torvalds on spinlocks (1) - Real World Technologies Forum √¢¬© √¢¬©2 √¢¬©3&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lock√¢Unlock: Is That All? A Pragmatic Analysis of Locking in Software Systems - Rachid Guerraoui, Hugo Guiroux, Renaud Lachaize, Vivien Qu√É¬©ma, Vasileios Trigonakis. ACM Transactions on Computer Systems, 2019, pp.1-149. √¢¬© √¢¬©2&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Spin Locks Considered Harmful, and How to Write Them When We Must - Intel (via The Wayback Machine) √¢¬©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Cache coherency primer - Fabian Giesen √¢¬©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;AMD Ryzen Processor Software Optimization (GDC 2024) - Ken Mitchell √¢¬©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;AMD RYZEN√¢¬¢ Cpu Optimization (GDC 2018) - Ken Mitchell &amp;amp; Elliot Kim √¢¬©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Correctly implementing a spinlock in C++ - Erik Rigtorp √¢¬©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;SwitchToThread docs - Microsoft √¢¬© √¢¬©2&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Linus Torvalds on spinlocks (3) - Real World Technologies Forum √¢¬© √¢¬©2 √¢¬©3&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sleeping vs. Yielding - Ken Henderson √¢¬©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;A Complete Guide to Lock Convoys - Dave Kilian √¢¬©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Linus Torvalds on spinlocks (2) - Real World Technologies Forum √¢¬©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Implementing atomic wait and notify - Blat Blatnik √¢¬©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;SpecialK√¢s commit automating&lt;/p&gt;&lt;code&gt;mwaitx&lt;/code&gt;√¢s usage - Andon M. Coleman √¢¬©&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;An Analysis of User-space Idle State Instructions on x86 Processors - Malte-Christian Kuns, Hannes Tr√É¬∂pgen, Robert Sch√É¬∂ne. ICPE √¢25: Proceedings of the 16th ACM/SPEC International Conference on Performance Engineering, 2025, pp.232-239. √¢¬©&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46797868</guid><pubDate>Wed, 28 Jan 2026 16:48:59 +0000</pubDate></item><item><title>Mousefood ‚Äì Build embedded terminal UIs for microcontrollers</title><link>https://github.com/ratatui/mousefood</link><description>&lt;doc fingerprint="8687611f4686e2e8"&gt;
  &lt;main&gt;
    &lt;p&gt;Mousefood - a no-std embedded-graphics backend for Ratatui!&lt;/p&gt;
    &lt;p&gt;Add mousefood as a dependency:&lt;/p&gt;
    &lt;code&gt;cargo add mousefood&lt;/code&gt;
    &lt;p&gt;Exemplary setup:&lt;/p&gt;
    &lt;code&gt;use mousefood::embedded_graphics::{mock_display::MockDisplay, pixelcolor::Rgb888};
use mousefood::prelude::*;
use ratatui::widgets::{Block, Paragraph};
use ratatui::{Frame, Terminal};

fn main() -&amp;gt; Result&amp;lt;(), Box&amp;lt;dyn std::error::Error&amp;gt;&amp;gt; {
    // replace this with your display driver
    // e.g. ILI9341, ST7735, SSD1306, etc.
    let mut display = MockDisplay::&amp;lt;Rgb888&amp;gt;::new();

    let backend = EmbeddedBackend::new(&amp;amp;mut display, EmbeddedBackendConfig::default());
    let mut terminal = Terminal::new(backend)?;

    terminal.draw(draw)?;
    Ok(())
}

fn draw(frame: &amp;amp;mut Frame) {
    let block = Block::bordered().title("Mousefood");
    let paragraph = Paragraph::new("Hello from Mousefood!").block(block);
    frame.render_widget(paragraph, frame.area());
}&lt;/code&gt;
    &lt;p&gt;Embedded-graphics includes bitmap fonts that have a very limited set of characters to save space (ASCII, ISO 8859 or JIS X0201). This makes it impossible to draw most of Ratatui's widgets, which heavily use box-drawing glyphs, Braille, and other special characters.&lt;/p&gt;
    &lt;p&gt;Mousefood by default uses &lt;code&gt;embedded-graphics-unicodefonts&lt;/code&gt;,
which provides embedded-graphics fonts with a much larger set of characters.&lt;/p&gt;
    &lt;p&gt;In order to save space and speed up rendering, the &lt;code&gt;fonts&lt;/code&gt; feature can be disabled by turning off the default crate features.
&lt;code&gt;ibm437&lt;/code&gt; is a good alternative that includes
some drawing characters, but is not as large as embedded-graphics-unicodefonts.&lt;/p&gt;
    &lt;p&gt;Bold and italic modifiers are supported, but this requires providing fonts through &lt;code&gt;EmbeddedBackendConfig&lt;/code&gt;.
If only regular font is provided, it serves as a fallback.
All fonts must be of the same size.&lt;/p&gt;
    &lt;code&gt;use mousefood::embedded_graphics::{mock_display::MockDisplay, pixelcolor::Rgb888};
use mousefood::{EmbeddedBackend, EmbeddedBackendConfig, fonts};
use ratatui::Terminal;

fn main() -&amp;gt; Result&amp;lt;(), Box&amp;lt;dyn std::error::Error&amp;gt;&amp;gt; {
    let mut display = MockDisplay::&amp;lt;Rgb888&amp;gt;::new();
    let config = EmbeddedBackendConfig {
        font_regular: fonts::MONO_6X13,
        font_bold: Some(fonts::MONO_6X13_BOLD),
        font_italic: Some(fonts::MONO_6X13_ITALIC),
        ..Default::default()
    };
    let backend = EmbeddedBackend::new(&amp;amp;mut display, config);
    let _terminal = Terminal::new(backend)?;
    Ok(())
}&lt;/code&gt;
    &lt;p&gt;Colors can be remapped using &lt;code&gt;color_theme&lt;/code&gt; on &lt;code&gt;EmbeddedBackendConfig&lt;/code&gt;.
By default the ANSI palette is used.&lt;/p&gt;
    &lt;code&gt;use mousefood::{ColorTheme, EmbeddedBackend, EmbeddedBackendConfig};
use mousefood::embedded_graphics::{mock_display::MockDisplay, pixelcolor::Rgb888};

fn main() -&amp;gt; Result&amp;lt;(), Box&amp;lt;dyn std::error::Error&amp;gt;&amp;gt; {
    let mut display = MockDisplay::&amp;lt;Rgb888&amp;gt;::new();
    let theme = ColorTheme {
        background: Rgb888::new(5, 5, 5),
        foreground: Rgb888::new(240, 240, 240),
        yellow: Rgb888::new(255, 200, 0),
        ..ColorTheme::ansi()
    };

    let config = EmbeddedBackendConfig {
        color_theme: theme,
        ..Default::default()
    };
    let backend = EmbeddedBackend::new(&amp;amp;mut display, config);
    Ok(())
}&lt;/code&gt;
    &lt;p&gt;Mousefood includes popular color themes that can be used directly:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;ColorTheme::ansi()&lt;/code&gt;- Standard ANSI colors (default)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ColorTheme::tokyo_night()&lt;/code&gt;- Tokyo Night dark theme with blue/purple tones&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Mousefood can be run in a simulator using embedded-graphics-simulator crate.&lt;/p&gt;
    &lt;p&gt;Run simulator example:&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/ratatui/mousefood.git
cd mousefood/examples/simulator
cargo run&lt;/code&gt;
    &lt;p&gt;For more details, view the simulator example.&lt;/p&gt;
    &lt;p&gt;Support for EPD (e-ink displays) produced by WeAct Studio (&lt;code&gt;weact-studio-epd&lt;/code&gt; driver) can be enabled using &lt;code&gt;epd-weact&lt;/code&gt; feature.&lt;/p&gt;
    &lt;p&gt;This driver requires some additional configuration. Follow the &lt;code&gt;weact-studio-epd&lt;/code&gt;
crate docs and apply the same &lt;code&gt;flush_callback&lt;/code&gt; pattern used in the Waveshare example below.&lt;/p&gt;
    &lt;head&gt;Setup example&lt;/head&gt;
    &lt;code&gt;use mousefood::prelude::*;
use weact_studio_epd::graphics::Display290BlackWhite;
use weact_studio_epd::WeActStudio290BlackWhiteDriver;

fn main() -&amp;gt; Result&amp;lt;(), Box&amp;lt;dyn std::error::Error&amp;gt;&amp;gt; {
    // Configure SPI + GPIO + delay provider for your board.
    // let (spi_interface, busy, rst, delay) = ...;

    let mut driver = WeActStudio290BlackWhiteDriver::new(spi_interface, busy, rst, delay);
    let mut display = Display290BlackWhite::new();

    driver.init()?;

    let config = EmbeddedBackendConfig {
        flush_callback: Box::new(move |d| {
            driver.full_update(d).expect("epd update failed");
        }),
        ..Default::default()
    };

    let backend = EmbeddedBackend::new(&amp;amp;mut display, config);
    let _terminal = Terminal::new(backend)?;
    Ok(())
}&lt;/code&gt;
    &lt;p&gt;Support for EPD (e-ink displays) produced by Waveshare Electronics (&lt;code&gt;epd-waveshare&lt;/code&gt; driver) can be enabled using &lt;code&gt;epd-waveshare&lt;/code&gt; feature.&lt;/p&gt;
    &lt;head&gt;Setup example&lt;/head&gt;
    &lt;code&gt;use mousefood::prelude::*;
use epd_waveshare::{epd2in9_v2::*, prelude::*};

fn main() -&amp;gt; Result&amp;lt;(), Box&amp;lt;dyn std::error::Error&amp;gt;&amp;gt; {
    // Configure SPI + GPIO + delay provider for your board.
    // let (mut spi_device, busy, dc, rst, mut delay) = ...;

    let mut epd = Epd2in9::new(&amp;amp;mut spi_device, busy, dc, rst, &amp;amp;mut delay, None)?;
    let mut display = Display2in9::default();

    let config = EmbeddedBackendConfig {
        flush_callback: Box::new(move |d| {
            epd.update_and_display_frame(&amp;amp;mut spi_device, d.buffer(), &amp;amp;mut delay)
                .expect("epd update failed");
        }),
        ..Default::default()
    };

    let backend = EmbeddedBackend::new(&amp;amp;mut display, config);
    let _terminal = Terminal::new(backend)?;
    Ok(())
}&lt;/code&gt;
    &lt;p&gt;See the full embedded example at &lt;code&gt;examples/epd-waveshare-demo&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Flash memory on most embedded devices is very limited. Additionally, to achieve high frame rate when using the &lt;code&gt;fonts&lt;/code&gt; feature,
it is recommended to use &lt;code&gt;opt-level = 3&lt;/code&gt;,
which can make the resulting binary even larger.&lt;/p&gt;
    &lt;p&gt;Mousefood is hardware-agnostic. Successfully tested on:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ESP32 (Xtensa)&lt;/item&gt;
      &lt;item&gt;ESP32-C6 (RISC-V)&lt;/item&gt;
      &lt;item&gt;STM32&lt;/item&gt;
      &lt;item&gt;RP2040&lt;/item&gt;
      &lt;item&gt;RP2350&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Full API docs are available on docs.rs.&lt;/p&gt;
    &lt;p&gt;All contributions are welcome!&lt;/p&gt;
    &lt;p&gt;Before opening a pull request, please read the contributing guidelines.&lt;/p&gt;
    &lt;p&gt;Here are some projects built using Mousefood:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tuitar - A portable guitar training tool.&lt;/item&gt;
      &lt;item&gt;Mnyaoo32 - An eccentric way to consume IRC messages using ESP32.&lt;/item&gt;
      &lt;item&gt;Phone-OS - A modern phone OS for ESP32 CYD.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Send a pull request to add your project here!&lt;/p&gt;
    &lt;p&gt;Mousefood is dual-licensed under Apache 2.0 and MIT terms.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46798402</guid><pubDate>Wed, 28 Jan 2026 17:20:31 +0000</pubDate></item><item><title>Computer History Museum Launches Digital Portal to Its Collection</title><link>https://computerhistory.org/press-releases/computer-history-museum-launches-digital-portal-to-its-vast-collection/</link><description>&lt;doc fingerprint="bdf8b7dc9943ebbd"&gt;
  &lt;main&gt;
    &lt;p&gt;Gordon and Betty Moore Foundation Funded OpenCHM to Digitize One-of-a-Kind Archive&lt;/p&gt;
    &lt;p&gt;MOUNTAIN VIEW, Calif. ‚Äì January 21, 2026 ‚Äì The Computer History Museum (CHM), a leader in decoding technology‚Äîits computing past, digital present, and future impact on humanity‚Äîannounced the launch of OpenCHM, a new digital portal providing global access to its unparalleled collection.&lt;/p&gt;
    &lt;p&gt;‚ÄúOpenCHM is designed to inspire discovery, spark curiosity, and make the stories of the digital age more accessible to everyone, everywhere,‚Äù said CHM President and CEO Marc Etkind. ‚ÄúWe‚Äôre unlocking the collection for new audiences to explore.‚Äù&lt;/p&gt;
    &lt;p&gt;OpenCHM is funded by the Gordon and Betty Moore Foundation and other generous donors, and this launch represents a major milestone in CHM's multi-year digitization initiative. Designed in collaboration with KeepThinking, the portal is powered by their innovative Qi collection management system.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe were excited by the prospect of CHM opening up their unique collections to broader audiences, from scholars and teachers to students and the public. The balance of the engaging, curated narratives by CHM‚Äôs own historians and field experts along with the tools and capabilities to explore one‚Äôs own interests makes the platform truly compelling. The Moore Foundation also values the OpenCHM team's commitment to thoughtful design and documentation, which we hope will inspire and enable other organizations to share their collections more openly.‚Äù‚ÄîJanet Coffey, Program Director, Science, Gordon and Betty Moore Foundation&lt;/p&gt;
    &lt;p&gt;The OpenCHM platform expands worldwide access to CHM‚Äôs vast collection through a digital portal, and ongoing digitization regularly adds more historical materials. Along with the collection, the portal introduces new digital storytelling and discovery tools designed to bring the history of the technology revolution to life for both experts and general audiences.&lt;/p&gt;
    &lt;p&gt;OpenCHM features include:&lt;/p&gt;
    &lt;p&gt;OpenCHM advances CHM‚Äôs mission to preserve and interpret the history of technology while making it broadly accessible as a public resource.&lt;/p&gt;
    &lt;p&gt;About CHM &lt;lb/&gt; The Computer History Museum (CHM) is the leading museum decoding computing‚Äôs ongoing impact on our world. We are uniquely positioned to cull the key lessons of the past and‚Äîthrough our research, exhibits, events, and incomparable collection of computing artifacts‚Äîcreate informed digital citizens empowered to make the choices that will shape a better future. &lt;/p&gt;
    &lt;p&gt;Press contact: Carina Sweet, [email protected], 650.810.1059&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46798994</guid><pubDate>Wed, 28 Jan 2026 17:54:54 +0000</pubDate></item><item><title>LM Studio 0.4.0</title><link>https://lmstudio.ai/blog/0.4.0</link><description>&lt;doc fingerprint="2e5b9d5b3934d4fa"&gt;
  &lt;main&gt;&lt;p&gt;Introducing LM Studio 0.4.0&lt;/p&gt;&lt;p&gt;Today we are thrilled to share LM Studio 0.4.0, the next generation of LM Studio.&lt;/p&gt;&lt;p&gt;This release introduces parallel requests with continuous batching for high throughput serving, all-new non-GUI deployment option, new stateful REST API, and a refreshed user interface.&lt;/p&gt;&lt;p&gt;LM Studio 0.4.0 highlights include:&lt;/p&gt;&lt;code&gt;/v1/chat&lt;/code&gt; that allows using local MCPs.&lt;p&gt;Read on for more details!&lt;/p&gt;&lt;p&gt;Today we're introducing &lt;code&gt;llmster&lt;/code&gt;: it's the core of the LM Studio desktop app, but packaged to be server-native, without reliance on the GUI. We've rearchitected our software to separate the GUI from the core functionality, allowing &lt;code&gt;llmster&lt;/code&gt; to run as a standalone daemon.&lt;/p&gt;&lt;p&gt;This means &lt;code&gt;llmster&lt;/code&gt; can be run completely independently of the app and deployed anywhere: Linux boxes, cloud servers, your GPU rig, or even Google Colabs. It can of course still be run on your local machine without the GUI, for those who prefer terminal-based workflows.&lt;/p&gt;&lt;code&gt;llmster&lt;/code&gt;&lt;p&gt;Linux / Mac&lt;/p&gt;&lt;quote&gt;&lt;code&gt;curl -fsSL https://lmstudio.ai/install.sh | bash&lt;/code&gt;&lt;/quote&gt;&lt;p&gt;Windows&lt;/p&gt;&lt;quote&gt;&lt;code&gt;irm https://lmstudio.ai/install.ps1 | iex&lt;/code&gt;&lt;/quote&gt;&lt;code&gt;llmster&lt;/code&gt;&lt;code&gt;lms daemon up&lt;/code&gt;&lt;code&gt;lms get &amp;lt;model&amp;gt;&lt;/code&gt;&lt;code&gt;lms server start&lt;/code&gt;&lt;code&gt;lms chat&lt;/code&gt;&lt;code&gt;lms runtime update llama.cpp&lt;/code&gt; (and &lt;code&gt;lms runtime update mlx&lt;/code&gt; on macOS)&lt;p&gt;Alongside LM Studio 0.4.0, our llama.cpp engine is graduating to version 2.0.0. With it we're introducing support for concurrent inference requests to the same model.&lt;/p&gt;&lt;p&gt;Run parallel requests in the app with Split View&lt;/p&gt;&lt;p&gt;You will find 2 new load options in the model loader dialog:&lt;/p&gt;&lt;p&gt;Max Concurrent Predictions: sets the maximum number of concurrent requests that can be processed by the model. Requests beyond this limit will be queued.&lt;/p&gt;&lt;p&gt;Unified KV Cache: when enabled, preallocated resources will not be hard-partitioned per concurrent request, allowing varying request sizes per request. This is enabled by default.&lt;/p&gt;&lt;p&gt;Parallel requests work thanks to llama.cpp's open-source continuous batching implementation, adopted in LM Studio's llm-engine. This capability has not yet made it into our MLX engine, but it is actively in the works and will land soon.&lt;/p&gt;&lt;p&gt;We have refreshed LM Studio's user interface from the ground up for a more consistent and pleasant experience.&lt;/p&gt;&lt;p&gt;Export your chats&lt;/p&gt;&lt;p&gt;You can now export your chats to PDF, markdown, or plain text. Click the ‚Ä¢‚Ä¢‚Ä¢ menu on a chat and head to "Export" for all available options.&lt;/p&gt;&lt;p&gt;You can now open multiple chat sessions side by side using Split View. Click the new Split View icon in the top right corner of the chat window to open a new chat pane.&lt;/p&gt;&lt;p&gt;Developer Mode is a new setting that exposes advanced options in the app. You can enable it from Settings &amp;gt; Developer. Once enabled, it'll reveal all advanced options across the app, including in the model loader dialog and sidebars.&lt;/p&gt;&lt;p&gt;Head over to the Developer tab to see the new in-app documentation. It covers the new REST API, CLI commands, and advanced configuration options.&lt;/p&gt;&lt;p&gt;New CLI experience&lt;/p&gt;&lt;code&gt;lms chat&lt;/code&gt;&lt;p&gt;With LM Studio 0.4.0, we're introducing a brand-new CLI experience centered around the &lt;code&gt;lms chat&lt;/code&gt; command. This command opens an interactive chat session directly in your terminal, allowing you to chat with your models and download new ones.&lt;/p&gt;&lt;p&gt;Run &lt;code&gt;lms chat --help&lt;/code&gt; to see all available options.&lt;/p&gt;&lt;code&gt;/v1/chat&lt;/code&gt;&lt;code&gt;/v1/chat&lt;/code&gt; endpoint&lt;p&gt;&lt;code&gt;/v1/chat&lt;/code&gt; is a new first-party REST endpoint for chatting with local models from your apps.&lt;/p&gt;&lt;p&gt;Unlike typical "stateless" chat APIs, &lt;code&gt;/v1/chat&lt;/code&gt; is stateful: you can start a conversation, get back a &lt;code&gt;response_id&lt;/code&gt;, and then continue it by passing &lt;code&gt;previous_response_id&lt;/code&gt; on your next request. This keeps requests small and makes it easy to build multi-step workflows on top of LM Studio.&lt;/p&gt;&lt;p&gt;Responses also include detailed stats (tokens in/out, speed, time to first token), so you can track performance and tune load/inference settings.&lt;/p&gt;&lt;p&gt;And when you need tools, &lt;code&gt;/v1/chat&lt;/code&gt; can also enable your locally configured MCPs - gated by permission keys.&lt;/p&gt;&lt;p&gt;To allow you to control which client accesses your LM Studio server, we've introduced permission keys. You can generate and manage permission keys from the Settings &amp;gt; Server tab in the app.&lt;/p&gt;&lt;p&gt;Please let us know how you like it! We'd love to hear your feedback.&lt;/p&gt;&lt;p&gt;Special thanks to the 0.4.0 beta group. Your feedback and bug reports have been invaluable &amp;lt;3.&lt;/p&gt;&lt;p&gt;Below is the full list of release notes items.&lt;/p&gt;&lt;quote&gt;&lt;code&gt;### LM Studio 0.4.0 - Release Notes Welcome to LM Studio 0.4.0 üëæ! - We're excited to introduce the next generation of LM Studio. - New features include: - `llmster`: the LM Studio Daemon for headless deployments w/o GUI on servers or cloud instances - Parallel inference requests (instead of queued) for high throughput use cases - New stateful REST API with local MCP server support - `POST /v1/chat` - A completely revamped UI experience ‚ú® **Build 17** - MCPs will now only be loaded when needed, instead of at app startup - Fixed a bug where some fields in app settings could get reset after update **Build 16** - New icons and placements for Discover, My Models buttons - Fixed a bug where generators wouldn't show in the top bar model picker when selected - Fixed a bug which prevented additional quantizations from being downloaded for staff pick models that were already downloaded - Fixed a bug where `lms import` will sometimes not work properly if llmster (daemon) is also installed - Fixed a bug in `/api/v1/chat` that caused server errors when inputs were empty or `top_k` exceeded 500 - Fixed a bug where `lms ls` and `lms load` sometimes would fail after waking up the LM Studio service - Fixed a bug where sometimes token counting would not work properly for gpt-oss models **Build 15** - Introduce Parallel Requests with Continuous Batching üöÄ - When loading a model, you can now select n_parallel to allow multiple requests to be processed in parallel. - When enabled, instead of queuing requests one by one, the model will process up to N requests simultaneously. - By default, parallel slots are set to 4 (with unified KV set to true, which should result in no additional memory overhead). - This is supported for LM Studio's llama.cpp engine, with MLX coming later. - Introducing Split View in Chat: view two chats side by side. - Drag and drop chat tabs to either half of the window to split the view. - Close one side of the split view with the 'x' button in the top right of each pane. - Introducing üîß Developer Mode: a simplification of the previous Developer/Power User/User 3 mode switch. - Developer Mode combines the previous Developer and Power User modes into a single mode with all advanced features enabled. - You can turn on Developer Mode in Settings &amp;gt; Developer. - New setting: enforce allowing only one new empty chat at a time (default: enabled) - Change in Settings &amp;gt; Chat - New üî≠ Model Search experience - Access via the üîç button on the top right or by pressing Cmd/Ctrl + Shift + M - Model format filter preferences persist between app restarts - Modal is resizable and remembers its size between app restarts - Limit number of open tabs to 1 per pane. Support showing 2 side-by-side chat tabs. - Selecting a new chat replaces the current tab in that pane. - Add button to create a new chat in the sidebar - Pressing Cmd/Ctrl + L while the model picker is open will dismiss it - On narrow window size show right hand sidebar as an ephemeral overlay - Support for the LFM2 tool call format - CLI now uses commit hash for versioning instead of semantic version numbers - Updates to UI details in hardware settings - Fixed a bug where moving large number of conversations would sometimes only move part of them - Fixed a bug where `lms ls` sometimes would show incomplete list of models on startup - Fixed a bug in deleting tool confirmation preferences in settings - Fixed a UI bug in app onboarding - Fixed a visual bug in Models Table selected row affecting the Architecture and Format columns - Fixed a bug where undoing pasted content in chat input would not work as expected - Fixed a bug where a leading decimal in a numeric input would parse as a 0 - Fixed a bug rendering multiple images in a conversation message - Fixed a bug where a documentation sidebar section would sometimes get stuck in expanded state - Fixed a bug where chat names would sometimes be empty - Fixed a visual bug in rendering keyboard shortcuts on Windows and Linux - Fixed a bug where model loader would sometimes close due to mouse move shortly after opening - Fixed a bug rendering titles in preset conflict resolver dialog - Fixed a bug where reloading with new load parameters would not apply next time the same model is used for a chat - Fixed a bug where the model loading will get stuck if the cpu moe slider is maxed out - Fixed a bug where exporting chats with very large images to PDF would fail - Fixed a responsive UI overlap bug in the app header - [Windows] Fixed a bug where the default embedding model will not be available after in-app update - Adds download, copy, and reveal in working directory buttons to generated images in chat **Build 14** - (Build 14 was skipped) **Build 13** - App setting to control primary navigation position: 'top' or 'left' - [Mac] New tray menu icon üëæ (experimental, might change) - `/api/v1` endpoints and `/v1/responses` API now return better formatted errors - Significantly reduce the size of the app update asset **Build 12** - Bugfix: New chats to be created with the same model as the previously focused chat - Bring back gear button to change load parameters for currently loaded model - Bring back context fullness indicator and current input token counter - New in My Models: right-click on tab header to choose which columns to show/hide - New in My Models: Capabilities and Format columns - Fixed a flicker in model picker floating panel upon first open - P.S. you can open the model picker from anywhere in the app with Cmd/Ctrl + L - Fixed focus + Enter on Eject button not working inside model picker - Updated chat terminal and messages colors and style - Fixed dragging and dropping chats/folders in the sidebar **Build 11** - ‚ú®üëæ Completely revamped UI - this is a work in progress, give us feedback! - [CLI] New `lms chat` experience! - Support slash commands, thinking highlighting and pasting larger content - Slash commands available: /model, /download, /system-prompt, /help and /exit - [CLI] New: `lms runtime survey` to print info about available GPUs! - FunctionGemma support - Added a slider to control n_cpu_moe - New REST API endpoint: `api/v1/models/unload` to unload models - Breaking change: in `api/v1/models/load` endpoint response, introduced in this beta, `model_instance_id` has been renamed to `instance_id`. - Display live processing status for each loaded LLM on the Developer page - Prompt processing progress percentage ‚Üí token generation count - Improved PDF rendering quality for tool requests and responses - Significantly increased the reliability and speed of deleting multiple chats at once - Updated style of chat message generation info - Updated layout of Hardware settings page and other settings rows - Fixed a bug where sometimes models are indexed before all files are downloaded - Fixed a bug where exporting larger PDFs would sometimes fail - Fixed a bug where pressing the chat clear hotkey multiple times would open multiple confirmation dialogs - Fixed a bug where pressing the chat clear hotkey would sometimes duplicate the chat - Fixed a bug where pressing the duplicate hotkey on the release notes would create a glitched chat tab - Fixed a bug where `lms help` would not work - Fixed a bug where deleting models or canceling downloads would leave behind empty folders - Fixed a styling bug in the GPU section on the Hardware page - [MLX] Fixed a bug where the bf16 model format was not recognized as a valid quantization **Build 10** - (Build 10 was skipped) **Build 9** - (Build 9 was skipped) **Build 8** - Fixed a bug where the default system prompt was still sent to the model even after the system prompt field was cleared. - Fixed a bug where exported chats did not include the correct system prompt. - Fixed a bug where the token count was incorrect when a default system prompt existed but the system prompt field was cleared. - Fix a bug where sometimes the tool call results are not being added to the context correctly - Fix chat clearing with hotkey (Cmd/Ctrl + Shift + Option/Alt + D) would clear wrong chat - Fix a bug where Ctrl/Cmd + N would sometimes create two new chats - Updated style for Integrations panel and select - Fixed cURL copy button for embedding models displaying additional incorrect requests - Fix "ghost chats" caused by moving conversations/deleting conversations **Build 7** - Fix jinja prompt formatting bug for some models where EOS tokens were not being included properly - Bring back release notes viewer for Runtime available update - Prevent tooltip from staying open when hovering tooltip content - Fix a bug in deleting multiple chats at once - Minor fix to overlapping labels in model loader - Support for EssentialAI's rnj-1 model **Build 6** - Fixed a bug where Qwen3-Next user messages would not appear in formatted prompts properly **Build 5** - Fixed a bug where quickly deleting multiple conversations will sometimes soft-lock the app - Fixed another bug that prevented the last remaining open tab from being closed **Build 4** - Fixed a bug where the last remaining open tab sometimes could not be closed - Fixed a bug where `lms log stream` would exit immediately - Fixed a bug where the server port would get printed as [object Object] - Image validation checks in `v1/chat` and `v1/responses` REST API now run without model loading - Fixed a bug where images without extensions were not classified correctly - Fix bug in move-to-trash onboarding dialog radio selection where some parts of the label were not clickable - Fix several clickable areas bugs in Settings windows buttons - Fixed a bug where certain settings may get adjusted unexpectedly when using llmster (for example, the JIT model loading may become disabled) - New and improved Runtime page style and structure - Fixes a bug where guardrail settings were not showing up in User UI mode - Fixed a bug where `lms log stream` would exit immediately **Build 3** - Introducing 'llmster': the LM Studio Daemon! - True headless, no GUI version of the process that powers LM Studio - Run it on servers, cloud instances, or any machine without a graphical interface - Load models on CPU/GPU and serve them, use via `lms` CLI or our APIs - To install: - Linux/Mac: `curl -fsSL https://lmstudio.ai/install.sh | bash` - Windows: `irm https://lmstudio.ai/install.ps1 | iex` - Support for MistralAI Ministral models (3B, 8B, 13B) - Improved `lms` output and help messages style. Run `lms --help` to explore! - Get llama.cpp level logs with `lms log stream -s runtime` in the terminal - `lms get` interactive mode now shows the latest model catalog options - New and improved style for Downloads panel - New and improved style for App Settings - We're trying something out: Model search now in its own tab - still iterating on the UI for this page, please give us feedback! **Build 2** - Show release notes in a dedicated tab after app updates - Add support to display images in exported PDFs and exported markdown files - Quick Docs is now Developer Docs, with refreshed documentation and direct access from the welcome page. - Allow creating permission tokens without allowed MCP permissions - Fixed a bug where sometimes images created by MCPs are not showing up - Fixed a bug where sometimes the plugin chips not working - Fixed a bug where the "thinking" blocks will sometimes expand erroneously - Fixed a bug where certain tabs would not open correctly - Fixed a bug where sometimes the model list would not load - Fixed a bug where in-app docs article titles would sometimes wiggle on scroll - Fixed a visual bug in Preset 'resolve conflicts' modal - Fixed a bug where sometimes Download button would continue showing for an already downloaded model - Fixed a bug where chat sidebar buttons wouldn't be visible on narrow screens - Display model indexing errors as buttons rather than hints **Build 1** - Welcome to the 0.4.0 Beta!&lt;/code&gt;&lt;/quote&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46799477</guid><pubDate>Wed, 28 Jan 2026 18:23:14 +0000</pubDate></item><item><title>Allowlisting some Bash commands is often the same as allowlisting all</title><link>https://www.joinformal.com/blog/allowlisting-some-bash-commands-is-often-the-same-as-allowlisting-all-with-claude-code/</link><description>&lt;doc fingerprint="d7a81fdc2bb54aeb"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
        &lt;p&gt;At Formal , we are heavy users of agentic coding tools for software development, and we‚Äôre trying to continue performing local development with these tools on our (admittedly beefy) laptops for as long as possible. One example is Claude Code. These tools feel particularly magical when verification loops are as fast as possible.&lt;/p&gt;
        &lt;p&gt;Having to explicitly approve every file edit Claude Code makes is time intensive ‚Äî and so is having to explicitly approve every command Claude Code wants to run to get feedback on that code change before we review it ourselves. Some examples include running go build, go test, restarting a docker container, and running our linter!&lt;/p&gt;
        &lt;p&gt;Claude Code supports allowlisting Bash commands as well as file edits to your directory without requiring approvals, which can dramatically speed up development. What if, however, we do not want Claude Code to be able to run certain commands on our laptops? Enabling file edits and particular Bash commands often used in software development often enables Claude Code to run any command!&lt;/p&gt;
        &lt;p&gt;We use TypeScript and Go, so the examples in this post will be specific to those languages.&lt;/p&gt;
        &lt;p&gt;We‚Äôre defining ‚Äúable‚Äù as ‚Äúcould Claude Code perform these actions,‚Äù irrespective of the probability that Claude would output text that would cause Claude Code to perform these actions.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;go test&lt;/head&gt;
        &lt;p&gt;What‚Äôs the worst a unit test could do? Well, a unit test could execute arbitrary bash scripts.&lt;/p&gt;
        &lt;p&gt;If you allowlist running go test and editing files without approval,&lt;lb/&gt; Claude Code could run any other command without approval via the following flow:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Edit a test file to use exec.Command&lt;/item&gt;
          &lt;item&gt;Run go test&lt;/item&gt;
        &lt;/list&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;go generate&lt;/head&gt;
        &lt;p&gt;Okay, that makes sense ‚Äî go test is effectively running arbitrary code. What about making sure our code builds? Well, a prerequisite for building is code generation.&lt;/p&gt;
        &lt;p&gt;We do have some go generate directives, however, and running go generate as part of your build pipeline allows arbitrary code execution if the coding agent can edit files that will be used by go generate.&lt;/p&gt;
        &lt;p&gt;Running go generate produces&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;go build*&lt;/head&gt;
        &lt;p&gt;Okay, so let‚Äôs not run go generate without manual review. What about making sure your edited code builds correctly? Well, Claude Code can run formal ls via go build too if Claude Code can specify arguments after go build! go help build shows that there is a -toolexec argument:&lt;/p&gt;
        &lt;p&gt;Running go build -toolexec ‚Äòformal ls‚Äô produces&lt;/p&gt;
        &lt;p&gt;It seems like our Formal Desktop fails to connect to the desktop agent when trying&lt;lb/&gt; to be run by go build! Good thing we won‚Äôt be supporting that kind of functionality&lt;lb/&gt; soon.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;eslint&lt;/head&gt;
        &lt;p&gt;What about just running our eslint linter? Eslint supports JavaScript files as configs, so Claude Code could add an execSync in an eslint.config.js.&lt;/p&gt;
        &lt;p&gt;Sure enough, eslint tries to run formal ls on startup:&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;make or pnpm run&lt;/head&gt;
        &lt;p&gt;However, allowlisting any pnpm run command could enable Claude Code to run any command solely by editing the package.json‚Äôs scripts config, no understanding of custom eslint rules required! Allowlisting a make command would allow executing any command as well for similar reasons.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;Claude Code May Be Able to Run Any Command&lt;/head&gt;
        &lt;p&gt;If using file watchers like next dev ‚Äìturbopack or jest with watchman, Claude Code could still execute any command without Bash being allowlisted! We perform frontend development using next dev ‚Äìturbopack, which spins up a Next.js server with automatic building and hot reloading when a file is edited. Adding the following code in any API route will have this command be executed at startup when the file is saved:&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;docker&lt;/head&gt;
        &lt;p&gt;What about rebuilding docker containers? Since Docker is a tool for executing code, being able to run docker commands enables Claude Code to run any command in a container.&lt;/p&gt;
        &lt;p&gt;To interact with the host, Claude Code could mount the host filesystem and run in privileged mode. In fact, the docker daemon by default runs with root, so being able to run docker commands may enable Claude Code to run commands as root as well against the host filesystem:&lt;/p&gt;
        &lt;quote/&gt;
        &lt;p&gt;Hardcoded docker commands don‚Äôt fare much better: you can configure mounts and privileged settings by editing the Docker Compose file, and run privileged commands that interact with the host through theUSER and RUN instructions in Dockerfiles.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;Allowlisting Bash Commands Is a Fraught Exercise&lt;/head&gt;
        &lt;p&gt;The combination of running developer tools against your codebase and editing your codebase often allows running any code. Development software is designed to execute developer-provided code, and malicious code provided by a malicious developer was not part of the threat model (if this kind of software had a threat model to begin with!). A lot of tools have some method of running arbitrary code as a configuration feature, not a bug.&lt;/p&gt;
        &lt;p&gt;The challenges of allowlisting only some commands but not others is not specific to Claude Code or Cursor: a lot of Unix binaries were not designed to isolate user privileges, and similarly our developer tools for executing code were not designed as if a malicious developer was able to run them.&lt;/p&gt;
        &lt;p&gt;In fact, even find supports a -exec argument that allows for arbitrary code execution.&lt;/p&gt;
        &lt;p&gt;This might be part of the reason why the Claude Code npm source has a ‚ÄúGlob‚Äù tool with the following prompt:&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;But Does Command Allowlisting Make Running Unwanted Commands Less Likely?&lt;/head&gt;
        &lt;p&gt;Sure, Claude Code could perform all of these convoluted code edits or command arguments, but would Claude Code be less likely to emit these kinds of commands and changes than a more conventional Bash command?&lt;/p&gt;
        &lt;p&gt;Intuitively, we expect this to be true: we would expect that Claude Code would emit a Bash:(curl) tool call more often than a Bash:(go build -toolexec ‚Äòcurl‚Äô) call. We have not found a great way, however, to precisely quantify that reduction likelihood.&lt;/p&gt;
        &lt;p&gt;Should we worry more about allowlisting make and pnpm run than go build with file edits?&lt;/p&gt;
        &lt;p&gt;In addition, active attempts at prompt injection to the inputs we are providing to Claude Code may significantly change our likelihood estimates. Still, viewing Claude Code as unhindered at the model and prompt level from emitting any kind of command is a simplifying assumption: the model providers are working on model alignment.&lt;/p&gt;
        &lt;p&gt;Still, the definition of implicit ‚Äúwanted‚Äù and ‚Äúunwanted‚Äù commands from a prompt is remarkably squishy. In our experience, we have seen Claude Code attempt to run psql and AWS CLI commands. At first blush, this may seem alarming ‚Äî but it depends on what resource these&lt;lb/&gt; commands are run against! There are likely many Claude Code users who want it to run psql and AWS CLI.&lt;/p&gt;
        &lt;p&gt;In addition, we have a containerized test Postgres database in our compose stack, and running psql commands on that database is an expected part of our test and development workflow. Determining the risk profile of the same psql or AWS CLI command based on the resource we are interacting with can be tricky for agentic coding tools (and for humans too)!&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;An Alternative Form of Permissions Restriction: Sandboxing!&lt;/head&gt;
        &lt;p&gt;Running these tools on a different host means that these agentic tools are limited by the permissions of the host irrespective of what commands they run. We do still want to run these agentic tools on a privileged host, so we‚Äôre thrilled to see that Cursor, Claude Code, and Codex have all been releasing sandboxing tools! For OS X users, a lot of these sandboxes are using sandbox-exec under the hood. This is the same technique Chromium uses despite macOS considering it deprecated since 2017.&lt;/p&gt;
        &lt;p&gt;In addition, we recommend sandboxing those watchman processes as well.&lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46800451</guid><pubDate>Wed, 28 Jan 2026 19:37:11 +0000</pubDate></item><item><title>Native Instruments enters into insolvency proceedings</title><link>https://www.engadget.com/audio/native-instruments-enters-into-insolvency-proceedings-leaving-its-future-uncertain-183206826.html</link><description>&lt;doc fingerprint="d504409dd0bab9d5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Native Instruments enters into insolvency proceedings, leaving its future uncertain&lt;/head&gt;
    &lt;head rend="h2"&gt;An administrator has been appointed to restructure the company and potentially sell off assets.&lt;/head&gt;
    &lt;p&gt;Music hardware and software manufacturer Native Instruments has entered into preliminary insolvency proceedings, according to a report by Create Digital Music. This is the company behind iconic software like Massive, Traktor and Kontakt and hardware like Maschine+. Native Instruments also owns the brands iZotope, Brainworx and Plugin Alliance.&lt;/p&gt;
    &lt;p&gt;We don't have many specifics as to what this entails and what the future of the company will look like. We do know that an administrator has been appointed to handle restructuring and, potentially, to sell off existing assets. Native Instruments employs hundreds of people and their fates also remain uncertain.&lt;/p&gt;
    &lt;p&gt;A private equity firm called Francisco Partners owns a majority stake in the company. It also owns majority stakes in entities like GoodRX and Verifone, among others. This isn't the first time Native Instruments has been forced into major restructuring. The company experienced plenty of layoffs and uncertainty between 2019 and 2020 before being purchased by private equity.&lt;/p&gt;
    &lt;p&gt;Again, we have no idea how this will shake out. It's possible that new investors will jump on board and it goes back to business as usual. It's also possible everything will be scrapped for parts and sold to the highest bidder.&lt;/p&gt;
    &lt;p&gt;We do know that subsidiary Plugin Alliance seems to be unaffected. It issued a statement on Facebook saying that it isn't involved with the proceedings and that operations will continue as normal. This means new plugins will be released, along with updates for current software.&lt;/p&gt;
    &lt;p&gt;Everything else is still up in the air. This is troubling for those who have heavily invested in the company's ecosystem of products. I'm one of them. Any hope I had for a hardware refresh of the Maschine+ just went out the window.&lt;/p&gt;
    &lt;p&gt;If the company's robust line of software goes up for sale, Akai is likely the best bet. It has already begun incorporating Native Instruments software into MPC machines.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46800645</guid><pubDate>Wed, 28 Jan 2026 19:51:05 +0000</pubDate></item><item><title>Native Linux VST plugin directory</title><link>https://linuxmusic.rocks</link><description>&lt;doc fingerprint="ca2eb295dcc9645c"&gt;
  &lt;main&gt;
    &lt;p&gt;Search&lt;/p&gt;
    &lt;p&gt;Categories&lt;/p&gt;
    &lt;p&gt;Category id: --------- All --- Effects ------ Distortion --------- Bitcrusher --------- Saturation ------ Dynamics --------- Compressor --------- De-esser --------- Gate --------- Limiters --------- Transient Designer ------ EQ ------ Emulations --------- Amp simulation --------- Cabinet simulation --------- Console Buss Emulation ------ Filter ------ Meter/Analyser ------ Modulation --------- Chorus --------- Flanger --------- Phaser --------- Pitch/Frequency shifter --------- Tremolo ------ Multieffect ------ Time/Space --------- Delay --------- Reverb --------- Stereo widening ------ Tool --------- Dither --------- Tone/Noise Generator/FX --- Instrument ------ Drums ------ Sampler/Trigger ------ Synth ------ Vocoder --- Midi --- Other ------ Bundle ------ Software --------- DAW --------- Utils&lt;/p&gt;
    &lt;p&gt;Format: VST2 VST3 LV2 CLAP DAW DSSI JACK LADSPA standalone&lt;/p&gt;
    &lt;p&gt;Free: Unknown Yes No&lt;/p&gt;
    &lt;p&gt;Tabular view:&lt;/p&gt;
    &lt;p&gt;Order by: Updated Neweset Name&lt;/p&gt;
    &lt;p&gt;Show untested:&lt;/p&gt;
    &lt;p&gt;Filter&lt;/p&gt;
    &lt;p&gt;True iron&lt;/p&gt;
    &lt;p&gt;Saturation by Kazrog&lt;/p&gt;
    &lt;p&gt;True dynamics&lt;/p&gt;
    &lt;p&gt;Compressor by Kazrog&lt;/p&gt;
    &lt;p&gt;True 252&lt;/p&gt;
    &lt;p&gt;EQ by Kazrog&lt;/p&gt;
    &lt;p&gt;Synth Warmer&lt;/p&gt;
    &lt;p&gt;Distortion by Kazrog&lt;/p&gt;
    &lt;p&gt;Retro Sta-Level&lt;/p&gt;
    &lt;p&gt;MHB Green&lt;/p&gt;
    &lt;p&gt;KClip Zero&lt;/p&gt;
    &lt;p&gt;Limiters by Kazrog&lt;/p&gt;
    &lt;p&gt;KClip 3&lt;/p&gt;
    &lt;p&gt;Avalon VT-747SP&lt;/p&gt;
    &lt;p&gt;Console Buss Emulation by Kazrog&lt;/p&gt;
    &lt;p&gt;Airline V15&lt;/p&gt;
    &lt;p&gt;Amp simulation by Kazrog&lt;/p&gt;
    &lt;p&gt;AmpCraft - 1992&lt;/p&gt;
    &lt;p&gt;Avalon EQ Bundle&lt;/p&gt;
    &lt;p&gt;Trailbender&lt;/p&gt;
    &lt;p&gt;Delay by Signal Perspective&lt;/p&gt;
    &lt;p&gt;Pyrite&lt;/p&gt;
    &lt;p&gt;Distortion by Signal Perspective&lt;/p&gt;
    &lt;p&gt;Grindbox Mk2&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46800737</guid><pubDate>Wed, 28 Jan 2026 19:59:04 +0000</pubDate></item></channel></rss>