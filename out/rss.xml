<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 08 Oct 2025 15:38:39 +0000</lastBuildDate><item><title>Nobel Prize in Physics 2025</title><link>https://www.nobelprize.org/prizes/physics/2025/popular-information/</link><description>&lt;doc fingerprint="715db15f2195d5ea"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Popular information&lt;/head&gt;
    &lt;p&gt;Popular science background: Quantum properties on a human scale (pdf)&lt;lb/&gt;Populärvetenskaplig information: Kvantegenskaper på mänsklig skala (pdf)&lt;/p&gt;
    &lt;head rend="h2"&gt;Quantum properties on a human scale&lt;/head&gt;
    &lt;p&gt;The Nobel Prize laureates in physics for 2025, John Clarke, Michel H. Devoret and John M. Martinis, used a series of experiments to demonstrate that the bizarre properties of the quantum world can be made concrete in a system big enough to be held in the hand. Their superconducting electrical system could tunnel from one state to another, as if it were passing straight through a wall. They also showed that the system absorbed and emitted energy in doses of specific sizes, just as predicted by quantum mechanics.&lt;/p&gt;
    &lt;head rend="h3"&gt;A series of groundbreaking experiments&lt;/head&gt;
    &lt;p&gt;Quantum mechanics describes properties that are significant on a scale that involves single particles. In quantum physics, these phenomena are called microscopic, even when they are much smaller than can be seen using an optical microscope. This contrasts with macroscopic phenomena, which consist of a large number of particles. For example, an everyday ball is built up of an astronomical amount of molecules and displays no quantum mechanical effects. We know that the ball will bounce back every time it is thrown at a wall. A single particle, however, will sometimes pass straight through an equivalent barrier in its microscopic world and appear on the other side. This quantum mechanical phenomenon is called tunnelling.&lt;/p&gt;
    &lt;p&gt;This year’s Nobel Prize in Physics recognises experiments that demonstrated how quantum tunnelling can be observed on a macroscopic scale, involving many particles. In 1984 and 1985, John Clarke, Michel Devoret and John Martinis conducted a series of experiments at the University of California, Berkeley. They built an electrical circuit with two superconductors, components that can conduct a current without any electrical resistance. They separated these with a thin layer of material that did not conduct any current at all. In this experiment, they showed that they could control and investigate a phenomenon in which all the charged particles in the superconductor behave in unison, as if they are a single particle that fills the entire circuit.&lt;/p&gt;
    &lt;p&gt;This particle-like system is trapped in a state in which current flows without any voltage – a state from which it does not have enough energy to escape. In the experiment, the system shows its quantum character by using tunnelling to escape the zero-voltage state, generating an electrical voltage. The laureates were also able to show that the system is quantised, which means it only absorbs or emits energy in specific amounts.&lt;/p&gt;
    &lt;head rend="h3"&gt;Tunnels and crossings&lt;/head&gt;
    &lt;p&gt;To help them, the laureates had concepts and experimental tools that had been developed over decades. Together with the theory of relativity, quantum physics is the foundation of what has come to be called modern physics, and researchers have spent the last century exploring what it entails.&lt;/p&gt;
    &lt;p&gt;Individual particles’ ability to tunnel is well known. In 1928, the physicist George Gamow realised that tunnelling is the reason why some heavy atomic nuclei tend to decay in a particular manner. The interaction between the forces in the nucleus creates a barrier around it, holding in the particles it contains. However, despite this, a small piece of the atomic nucleus can sometimes split off, move outside the barrier and escape – leaving behind a nucleus that has been transformed into another element. Without tunnelling, this type of nuclear decay could not occur.&lt;/p&gt;
    &lt;p&gt;Tunnelling is a quantum mechanical process, which entails that chance plays a role. Some types of atomic nuclei have a tall, wide barrier, so it can take a long while for a piece of the nucleus to appear outside it, while other types decay more easily. If we only look at a single atom, we cannot predict when this will happen, but by watching the decay of a large number of nuclei of the same type, we can measure an expected time before tunnelling occurs. The most common way of describing this is through the concept of half-life, which is how long it takes for half the nuclei in a sample to decay.&lt;/p&gt;
    &lt;p&gt;Physicists were quick to wonder whether it would be possible to investigate a type of tunnelling that involves more than one particle at a time. One approach to new types of experiments originated in a phenomenon that arises when some materials get extremely cold.&lt;/p&gt;
    &lt;p&gt;In an ordinary conductive material, current flows because there are electrons that are free to move through the entire material. In some materials, the individual electrons that push their way through the conductor may become organised, forming a synchronised dance that flows without any resistance. The material has become a superconductor and the electrons are joined together as pairs. These are called Cooper pairs, after Leon Cooper who, along with John Bardeen and Robert Schrieffer, provided a detailed description of how superconductors work (Nobel Prize in Physics 1972).&lt;/p&gt;
    &lt;p&gt;Cooper pairs behave completely differently to ordinary electrons. Electrons have a great deal of integrity and like to stay at a distance from each other – two electrons cannot be in the same place if they have the same properties. We can see this in an atom, for example, where the electrons divide themselves into different energy levels, called shells. However, when the electrons in a superconductor join up as pairs, they lose a bit of their individuality; while two separate electrons are always distinct, two Cooper pairs can be exactly the same. This means the Cooper pairs in a superconductor can be described as a single unit, one quantum mechanical system. In the language of quantum mechanics, they are then described as a single wave function. This wave function describes the probability of observing the system in a given state and with given properties.&lt;/p&gt;
    &lt;p&gt;If two superconductors are joined together with a thin insulating barrier between them, it creates a Josephson junction. This component is named after Brian Josephson, who performed quantum mechanical calculations for the junction. He discovered that interesting phenomena arise when the wave functions on each side of the junction are considered (Nobel Prize in Physics 1973). The Josephson junction rapidly found areas of application, including in precise measurements of fundamental physical constants and magnetic fields.&lt;/p&gt;
    &lt;p&gt;The construction also provided tools for exploring the fundamentals of quantum physics in a new way. One person who did so was Anthony Leggett (Nobel Prize in Physics 2003), whose theoretical work on macroscopic quantum tunnelling at a Josephson junction inspired new types of experiments.&lt;/p&gt;
    &lt;head rend="h3"&gt;The research group starts its work&lt;/head&gt;
    &lt;p&gt;These subjects were a perfect match for John Clarke’s research interests. He was a professor at the University of California, Berkeley, in the US, where he had moved after completing his doctoral degree at the University of Cambridge, UK, in 1968. At UC Berkeley he built up his research group and specialised in exploring a range of phenomena using superconductors and the Josephson junction.&lt;/p&gt;
    &lt;p&gt;By the mid-1980s, Michel Devoret had joined John Clarke’s research group as a postdoc, after receiving his doctorate in Paris. This group also included the doctoral student John Martinis. Together, they took on the challenge of demonstrating macroscopic quantum tunnelling. Vast amounts of care and precision were necessary to screen the experimental setup from all the interference that could affect it. They succeeded in refining and measuring all the properties of their electrical circuit, allowing them to understand it in detail.&lt;/p&gt;
    &lt;p&gt;To measure the quantum phenomena, they fed a weak current into the Josephson junction and measured the voltage, which is related to the electrical resistance in the circuit. The voltage over the Josephson junction was initially zero, as expected. This is because the wave function for the system is enclosed in a state that does not allow a voltage to arise. Then they studied how long it took for the system to tunnel out of this state, causing a voltage. Because quantum mechanics entails an element of chance, they took numerous measurements and plotted their results as graphs, from which they could read the duration of the zero-voltage state. This is similar to how measurements of the half-lives of atomic nuclei are based on statistics of numerous instances of decay.&lt;/p&gt;
    &lt;p&gt;The tunnelling demonstrates how the experimental setup’s Cooper pairs, in their synchronised dance, behave like a single giant particle. The researchers obtained further confirmation of this when they saw that the system had quantised energy levels. Quantum mechanics was named after the observation that the energy in microscopic processes is divided into separate packages, quanta. The laureates introduced microwaves of varying wavelengths into the zero-voltage state. Some of these were absorbed, and the system then moved to a higher energy level. This showed that the zero-voltage state had a shorter duration when the system contained more energy – which is exactly what quantum mechanics predicts. A microscopic particle shut behind a barrier functions in the same way.&lt;/p&gt;
    &lt;head rend="h3"&gt;Practical and theoretical benefit&lt;/head&gt;
    &lt;p&gt;This experiment has consequences for the understanding of quantum mechanics. Other types of quantum mechanical effects that are demonstrated on the macroscopic scale are composed of many tiny individual pieces and their separate quantum properties. The microscopic components are then combined to cause macroscopic phenomena such as lasers, superconductors and superfluid liquids. However, this experiment instead created a macroscopic effect – a measurable voltage – from a state that is in itself macroscopic, in the form of a common wave function for vast numbers of particles.&lt;/p&gt;
    &lt;p&gt;Theorists like Anthony Leggett have compared the laureates’ macroscopic quantum system with Erwin Schrödinger’s famous thought experiment featuring a cat in a box, where the cat would be both alive and dead if we did not look inside. (Erwin Schrödinger received the Nobel Prize in Physics 1933.) The intention of his thought experiment was to show the absurdity of this situation, because the special properties of quantum mechanics are often erased at a macroscopic scale. The quantum properties of an entire cat cannot be demonstrated in a laboratory experiment.&lt;/p&gt;
    &lt;p&gt;However, Legget has argued that the series of experiments conducted by John Clarke, Michel Devoret and John Martinis showed that there are phenomena that involve vast numbers of particles which together behave just as quantum mechanics predicts. The macroscopic system that consists of many Cooper pairs is still many orders of magnitude smaller than a kitten – but because the experiment measures the quantum mechanical properties that apply to the system as a whole, for a quantum physicist it is fairly similar to Schrödinger’s imaginary cat.&lt;/p&gt;
    &lt;p&gt;This type of macroscopic quantum state offers new potential for experiments using the phenomena that govern the microscopic world of particles. It can be regarded as a form of artificial atom on a large scale – an atom with cables and sockets that can be connected into new test set-ups or utilised in new quantum technology. For example, artificial atoms are used to simulate other quantum systems and aid in understanding them.&lt;/p&gt;
    &lt;p&gt;Another example is the quantum computer experiment subsequently performed by Martinis, in which he utilised exactly the energy quantisation that he and the other two laureates had demonstrated. He used a circuit with quantised states as information-bearing units – a quantum bit. The lowest energy state and the first step upward functioned as zero and one, respectively. Superconducting circuits are one of the techniques being explored in attempts to construct a future quantum computer.&lt;/p&gt;
    &lt;p&gt;This year’s laureates have thus contributed to both practical benefit in physics laboratories and to providing new information for the theoretical understanding of our physical world.&lt;/p&gt;
    &lt;head rend="h3"&gt;Further reading&lt;/head&gt;
    &lt;p&gt;Additional information on this year’s prizes, including a scientific background in English, is available on the website of the Royal Swedish Academy of Sciences, www.kva.se, and at www.nobelprize.org, where you can watch video from the press conferences, the Nobel Prize lectures and more. Information on exhibitions and activities related to the Nobel Prizes and the prize in economic sciences is available at www.nobelprizemuseum.se.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Royal Swedish Academy of Sciences has decided to award the Nobel Prize in Physics 2025 to&lt;/head&gt;
    &lt;p&gt;JOHN CLARKE&lt;lb/&gt;Born 1942 in Cambridge, UK. PhD 1968 from University of Cambridge, UK. Professor at University of California, Berkeley, USA.&lt;/p&gt;
    &lt;p&gt;MICHEL H. DEVORET&lt;lb/&gt;Born 1953 in Paris, France. PhD 1982 from Paris-Sud University, France. Professor at Yale University, New Haven, CT and University of California, Santa Barbara, USA.&lt;/p&gt;
    &lt;p&gt;JOHN M. MARTINIS&lt;lb/&gt;Born 1958. PhD 1987 from University of Californa, Berkeley, USA. Professor at University of California, Santa Barbara, USA.&lt;/p&gt;
    &lt;p&gt;“for the discovery of macroscopic quantum mechanical tunnelling and energy quantisation in an electric circuit”&lt;/p&gt;
    &lt;p&gt;Science Editors: Ulf Danielsson, Göran Johansson and Eva Lindroth, the Nobel Committee for Physics&lt;lb/&gt;Text: Anna Davour&lt;lb/&gt;Translation: Clare Barnes&lt;lb/&gt;Illustrations: Johan Jarnestad&lt;lb/&gt;Editor: Sara Gustavsson&lt;lb/&gt;© The Royal Swedish Academy of Sciences&lt;/p&gt;
    &lt;head rend="h3"&gt;Nobel Prize announcements 2025&lt;/head&gt;
    &lt;p&gt;Don't miss the Nobel Prize announcements 6–13 October. All announcements are streamed live here on nobelprize.org.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45501189</guid><pubDate>Tue, 07 Oct 2025 09:50:49 +0000</pubDate></item><item><title>Qualcomm to acquire Arduino</title><link>https://www.qualcomm.com/news/releases/2025/10/qualcomm-to-acquire-arduino-accelerating-developers--access-to-i</link><description>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45502541</guid><pubDate>Tue, 07 Oct 2025 13:00:08 +0000</pubDate></item><item><title>Vibe engineering</title><link>https://simonwillison.net/2025/Oct/7/vibe-engineering/</link><description>&lt;doc fingerprint="a3d0c07761f5138d"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Vibe engineering&lt;/head&gt;
    &lt;p&gt;7th October 2025&lt;/p&gt;
    &lt;p&gt;I feel like vibe coding is pretty well established now as covering the fast, loose and irresponsible way of building software with AI—entirely prompt-driven, and with no attention paid to how the code actually works. This leaves us with a terminology gap: what should we call the other end of the spectrum, where seasoned professionals accelerate their work with LLMs while staying proudly and confidently accountable for the software they produce?&lt;/p&gt;
    &lt;p&gt;I propose we call this vibe engineering, with my tongue only partially in my cheek.&lt;/p&gt;
    &lt;p&gt;One of the lesser spoken truths of working productively with LLMs as a software engineer on non-toy-projects is that it’s difficult. There’s a lot of depth to understanding how to use the tools, there are plenty of traps to avoid, and the pace at which they can churn out working code raises the bar for what the human participant can and should be contributing.&lt;/p&gt;
    &lt;p&gt;The rise of coding agents—tools like Claude Code (released February 2025), OpenAI’s Codex CLI (April) and Gemini CLI (June) that can iterate on code, actively testing and modifying it until it achieves a specified goal, has dramatically increased the usefulness of LLMs for real-world coding problems.&lt;/p&gt;
    &lt;p&gt;I’m increasingly hearing from experienced, credible software engineers who are running multiple copies of agents at once, tackling several problems in parallel and expanding the scope of what they can take on. I was skeptical of this at first but I’ve started running multiple agents myself now and it’s surprisingly effective, if mentally exhausting!&lt;/p&gt;
    &lt;p&gt;This feels very different from classic vibe coding, where I outsource a simple, low-stakes task to an LLM and accept the result if it appears to work. Most of my tools.simonwillison.net collection (previously) were built like that. Iterating with coding agents to produce production-quality code that I’m confident I can maintain in the future feels like a different process entirely.&lt;/p&gt;
    &lt;p&gt;It’s also become clear to me that LLMs actively reward existing top tier software engineering practices:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Automated testing. If your project has a robust, comprehensive and stable test suite agentic coding tools can fly with it. Without tests? Your agent might claim something works without having actually tested it at all, plus any new change could break an unrelated feature without you realizing it. Test-first development is particularly effective with agents that can iterate in a loop.&lt;/item&gt;
      &lt;item&gt;Planning in advance. Sitting down to hack something together goes much better if you start with a high level plan. Working with an agent makes this even more important—you can iterate on the plan first, then hand it off to the agent to write the code.&lt;/item&gt;
      &lt;item&gt;Comprehensive documentation. Just like human programmers, an LLM can only keep a subset of the codebase in its context at once. Being able to feed in relevant documentation lets it use APIs from other areas without reading the code first. Write good documentation first and the model may be able to build the matching implementation from that input alone.&lt;/item&gt;
      &lt;item&gt;Good version control habits. Being able to undo mistakes and understand when and how something was changed is even more important when a coding agent might have made the changes. LLMs are also fiercely competent at Git—they can navigate the history themselves to track down the origin of bugs, and they’re better than most developers at using git bisect. Use that to your advantage.&lt;/item&gt;
      &lt;item&gt;Having effective automation in place. Continuous integration, automated formatting and linting, continuous deployment to a preview environment—all things that agentic coding tools can benefit from too. LLMs make writing quick automation scripts easier as well, which can help them then repeat tasks accurately and consistently next time.&lt;/item&gt;
      &lt;item&gt;A culture of code review. This one explains itself. If you’re fast and productive at code review you’re going to have a much better time working with LLMs than if you’d rather write code yourself than review the same thing written by someone (or something) else.&lt;/item&gt;
      &lt;item&gt;A very weird form of management. Getting good results out of a coding agent feels uncomfortably close to getting good results out of a human collaborator. You need to provide clear instructions, ensure they have the necessary context and provide actionable feedback on what they produce. It’s a lot easier than working with actual people because you don’t have to worry about offending or discouraging them—but any existing management experience you have will prove surprisingly useful.&lt;/item&gt;
      &lt;item&gt;Really good manual QA (quality assurance). Beyond automated tests, you need to be really good at manually testing software, including predicting and digging into edge-cases.&lt;/item&gt;
      &lt;item&gt;Strong research skills. There are dozens of ways to solve any given coding problem. Figuring out the best options and proving an approach has always been important, and remains a blocker on unleashing an agent to write the actual code.&lt;/item&gt;
      &lt;item&gt;The ability to ship to a preview environment. If an agent builds a feature, having a way to safely preview that feature (without deploying it straight to production) makes reviews much more productive and greatly reduces the risk of shipping something broken.&lt;/item&gt;
      &lt;item&gt;An instinct for what can be outsourced to AI and what you need to manually handle yourself. This is constantly evolving as the models and tools become more effective. A big part of working effectively with LLMs is maintaining a strong intuition for when they can best be applied.&lt;/item&gt;
      &lt;item&gt;An updated sense of estimation. Estimating how long a project will take has always been one of the hardest but most important parts of being a senior engineer, especially in organizations where budget and strategy decisions are made based on those estimates. AI-assisted coding makes this even harder—things that used to take a long time are much faster, but estimations now depend on new factors which we’re all still trying to figure out.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you’re going to really exploit the capabilities of these new tools, you need to be operating at the top of your game. You’re not just responsible for writing the code—you’re researching approaches, deciding on high-level architecture, writing specifications, defining success criteria, designing agentic loops, planning QA, managing a growing army of weird digital interns who will absolutely cheat if you give them a chance, and spending so much time on code review.&lt;/p&gt;
    &lt;p&gt;Almost all of these are characteristics of senior software engineers already!&lt;/p&gt;
    &lt;p&gt;AI tools amplify existing expertise. The more skills and experience you have as a software engineer the faster and better the results you can get from working with LLMs and coding agents.&lt;/p&gt;
    &lt;head rend="h4"&gt;“Vibe engineering”, really?&lt;/head&gt;
    &lt;p&gt;Is this a stupid name? Yeah, probably. “Vibes” as a concept in AI feels a little tired at this point. “Vibe coding” itself is used by a lot of developers in a dismissive way. I’m ready to reclaim vibes for something more constructive.&lt;/p&gt;
    &lt;p&gt;I’ve never really liked the artificial distinction between “coders” and “engineers”—that’s always smelled to me a bit like gatekeeping. But in this case a bit of gatekeeping is exactly what we need!&lt;/p&gt;
    &lt;p&gt;Vibe engineering establishes a clear distinction from vibe coding. It signals that this is a different, harder and more sophisticated way of working with AI tools to build production software.&lt;/p&gt;
    &lt;p&gt;I like that this is cheeky and likely to be controversial. This whole space is still absurd in all sorts of different ways. We shouldn’t take ourselves too seriously while we figure out the most productive ways to apply these new tools.&lt;/p&gt;
    &lt;p&gt;I’ve tried in the past to get terms like AI-assisted programming to stick, with approximately zero success. May as well try rubbing some vibes on it and see what happens.&lt;/p&gt;
    &lt;p&gt;I also really like the clear mismatch between “vibes” and “engineering”. It makes the combined term self-contradictory in a way that I find mischievous and (hopefully) sticky.&lt;/p&gt;
    &lt;head rend="h2"&gt;More recent articles&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;OpenAI DevDay 2025 live blog - 6th October 2025&lt;/item&gt;
      &lt;item&gt;Embracing the parallel coding agent lifestyle - 5th October 2025&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45503867</guid><pubDate>Tue, 07 Oct 2025 14:55:14 +0000</pubDate></item><item><title>IKEA Catalogs 1951-2021</title><link>https://ikeamuseum.com/en/explore/ikea-catalogue/</link><description>&lt;doc fingerprint="71c3125f48ed4455"&gt;
  &lt;main&gt;
    &lt;p&gt;Good question! We know that a lot of people are curious about what the IKEA catalogue has looked like through the ages. The catalogue has always reflected the age and its views on interior design and everyday living, especially in Sweden, but in recent decades also internationally. The catalogue was in print for 70 years, and by digitising all the catalogues we could make them available to everybody. Making the story of IKEA available to as many people as possible is our main task at IKEA Museum. So we hope that the catalogues will bring some joy and nostalgia, and maybe even a few surprises.&lt;/p&gt;
    &lt;head rend="h1"&gt;IKEA catalogue&lt;/head&gt;
    &lt;p&gt;For over 70 years, the IKEA catalogue was produced in Ãlmhult, constantly growing in number, scope and distribution. From the 1950s when Ingvar Kamprad wrote most of the texts himself, via the poppy, somewhat radical 1970s and all the way into the scaled-down 2000s â the IKEA catalogue always captured the spirit of the time. The 2021 IKEA catalogue was the very last one printed on paper.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;1950s&lt;/item&gt;
      &lt;item&gt;1960s&lt;/item&gt;
      &lt;item&gt;1970s&lt;/item&gt;
      &lt;item&gt;1980s&lt;/item&gt;
      &lt;item&gt;1990s&lt;/item&gt;
      &lt;item&gt;2000s&lt;/item&gt;
      &lt;item&gt;2010s&lt;/item&gt;
      &lt;item&gt;2020s&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Just like the perception of the home, the catalogue has changed dramatically since 1951, when it was first published. Look in the older catalogues and youâll be amazed at what you find. In fact, youâll probably even have a giggle or two. In the 1950s and 1960s, there are rarely any people in the pictures, and never any children. But in the 1970s there are children playing all over the home, you can see adults smoking and even the occasional political poster on the wall. Browse on to the 1980s IKEA catalogues and the trends have changed again, with shiny fabrics and other fancy materials. In the 1990s homes become more scaled-down and clearly inspired by a Scandinavian tradition. In this way, the IKEA catalogues are a kind of time capsule for you to travel in. And who knows? When we look back at the most recent catalogues in 10 or 20 yearsâ time, weâll probably shake our heads and give a sigh.&lt;/p&gt;
    &lt;p&gt;IKEA Museum decided to start with the Swedish catalogue as it has been around the longest. In the future, we hope to be able to digitise catalogues from more countries in more languages.&lt;/p&gt;
    &lt;p&gt;No. The IKEA catalogue has always only shown a selection of whatâs available in the stores. The catalogues from the 1970s and onwards show around 30â50 per cent of the entire range. The products that are not featured are generally smaller ones in textiles, decorations and lighting. Temporary collections are rarely included either. But the farther back you go, the higher a percentage of the range can be found in the catalogue.&lt;/p&gt;
    &lt;p&gt;Yes, but the older a product is, the harder it may be to find information about it. If you have a specific question about a product, weâre happy to help you out if we can. But 70 years is a long time, so we canât promise anything. While youâre waiting for our response you can always browse through the catalogues â the product texts that are there are quite detailed. You can search in the catalogues by product name and product type. There are also various stories about different products on our site, and more are constantly being added.&lt;lb/&gt; Browse through stories about IKEA products from 7 decades. &lt;/p&gt;
    &lt;p&gt;IKEA was founded in the 1940s, so why are you showing no catalogues from before 1951?&lt;lb/&gt; The first catalogue did not come out until 1951. Before that, IKEA was a mail order company that didnât sell furniture, but pens, clocks, electric razors, wallets and bags. At that time, the range was only presented in a small mail order brochure called ikÃ©a-nytt (literally ikÃ©a news). Sometimes it was distributed as a supplement in farming paper Jordbrukarnas FÃ¶reningsblad, which reached hundreds of thousands of people in the Swedish countryside. From autumn 1948 Ingvar Kamprad started including furniture in the range, and things quickly grew from there. In the 1950 ikÃ©a-nytt, as many as six of the 18 pages featured furniture. And when you look at the 1951 catalogue, youâll see that there are no more pens and wallets. Ingvar Kamprad was now truly focusing on home furnishing, and shelving the rest.&lt;lb/&gt; Browse through all issues of ikÃ©a-nytt.&lt;/p&gt;
    &lt;p&gt;Not really. We do have a few copies of each yearâs IKEA catalogue in our archives, which weâre saving for posterity. They should be handled as little as possible to keep them in good condition, so weâve made the catalogues available digitally, both online and on monitors at IKEA Museum. You can browse through those as much as you like!&lt;/p&gt;
    &lt;p&gt;Yes you can. The easiest way to share the catalogues is to click on the arrow at the bottom left corner for each catalogue, or in the left-hand menu once youâve started browsing through. This will copy a link which you can share on a website or social media. If you would like to download and publish on your own digital platform, you can share a maximum of three complete digital catalogues. Donât forget to state the copyright details, “Â© Inter IKEA Systems B.V.”, the catalogue year, and the link /en/explore/ikea-catalogue/ so that anyone interested can find out more. You may not publish the digital catalogues for commercial purposes.&lt;/p&gt;
    &lt;p&gt;Absolutely! You can share up to 30 images from the catalogues on your own digital platform, such as a blog, on Instagram or similar (as long as itâs not for commercial purposes). Donât forget to state the copyright details, “Â© Inter IKEA Systems B.V.”, the catalogue year, and the link /en/explore/ikea-catalogue/ so that anyone interested can find out more.&lt;/p&gt;
    &lt;p&gt;Yes! You can find all press material, including images, information about current exhibitions and much more, in the IKEA Museum press room.&lt;/p&gt;
    &lt;p&gt;At the moment we have a good amount of catalogues in all languages at the museum, and do not need any more. Having said that, please contact us anyway if youâve been collecting catalogues for several decades, or if you have any other material you think might be of interest to IKEA Museum.&lt;/p&gt;
    &lt;p&gt;Unfortunately not. We sometimes wish we did, as we handle quite a lot of old products that may need putting together and taking apart.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45504470</guid><pubDate>Tue, 07 Oct 2025 15:35:48 +0000</pubDate></item><item><title>Show HN: Timelinize – Privately organize your own data from everywhere, locally</title><link>https://timelinize.com</link><description>&lt;doc fingerprint="e64842e6eda1dcc1"&gt;
  &lt;main&gt;
    &lt;p&gt;Timelinize ("time-lynn-eyes") is an open source personal archival suite, designed for modern family history. It organizes all your data onto a single, unified timeline on your own computer.&lt;/p&gt;
    &lt;p&gt;Photos, videos, text messages, locations, chats, social media, and more. Timelinize unifies it all.&lt;/p&gt;
    &lt;p&gt;By adding all your data, Timelinize documents your family's life with more detail and privacy, and gives you a more complete view of your story, than standard photo library and journaling apps.&lt;/p&gt;
    &lt;p&gt;Most apps store your data "in the cloud" and out of your control. What if you lost access to your Google/Apple/Facebook accounts, or your phone? By bringing that data home to your own computer, Timelinize preserves a richer story than any one app or service can do alone.&lt;/p&gt;
    &lt;p&gt;Timelinize isn't a replacement for the apps and services you already use, so you don't need to disrupt your way of life. Instead, it "sits behind" what you already use to become the permanent private archive of your working copy from:&lt;/p&gt;
    &lt;p&gt;With several projections for your data, it's easy to keep moments alive that would otherwise be forgotten, rotting on a hard drive in your closet... or in a bigcorp's cloud.&lt;/p&gt;
    &lt;p&gt;The timeline view semantically groups all your data into a single linear layout. Easily see what occurred on a specific day in the order it happened.&lt;/p&gt;
    &lt;p&gt;Visualize your data on a huge, beautiful map of the world that plots points when and where they happened, even for data that doesn't have coordinates (like text messages and emails).&lt;/p&gt;
    &lt;p&gt;Follow connections with people across all kinds of chats and messages. Combine conversations with people across platforms into one view.&lt;/p&gt;
    &lt;p&gt;Browse through a rich display of photos and videos from photo libraries, messages sent and received, and other sources.&lt;/p&gt;
    &lt;p&gt;Add millions of data points to your timeline in a matter of minutes. You get full control over background jobs like imports, thumbnails, and embeddings.&lt;/p&gt;
    &lt;p&gt;Timelinize supports playing "live photos" (or "motion photos") for photos taken on Apple, Google, and Samsung devices.&lt;/p&gt;
    &lt;p&gt;Timelinize specializes in combining data from multiple sets and sources. It can identify people and other entities across data sources by their attributes. If a person or contact appears in multiple data sets, it will automatically merge them if possible. If not, you can easily merge entities with the click of a button.&lt;/p&gt;
    &lt;p&gt;Because Timelinize is entity-aware, it can project data points onto a map even without coordinate data. If a geolocated point is known for an entity around the same time of others of that entity's data points, it will appear on the map.&lt;/p&gt;
    &lt;p&gt;Customize the map to change its theme, layers, and even make it 3D.&lt;/p&gt;
    &lt;p&gt;The heatmap shows where your data is concentrated. It smoothly blends as you zoom in and out.&lt;/p&gt;
    &lt;p&gt;Customize what defines a duplicate item, and how to handle that, with a fine degree of control—perfect for merging separate, disparate data sets.&lt;/p&gt;
    &lt;p&gt;An implicit conversation is discovered when a data source links items and entities with a "sent to" relation. You can easily view conversations between entities across modalities in a single scroll: chats, emails, messages, texts, and more.&lt;/p&gt;
    &lt;p&gt;Since I need this to function well for my own family, I have tried to give special attention to less-visible aspects of this application, such as:&lt;/p&gt;
    &lt;p&gt;Timelinize deduplicates, denoises, clusters, and simplifies location data for optimal preservation, with an algorithm that subjectively performs better than Google Maps Timeline.&lt;/p&gt;
    &lt;p&gt;For nerds like me: you can use Timelinize through its CLI, which mirrors all the functions of the HTTP API used by the frontend.&lt;/p&gt;
    &lt;p&gt;Search for pictures and messages by describing them, or find similar items to what you're viewing.&lt;/p&gt;
    &lt;p&gt;All items are stored verbatim, then thumbnails are generated for all images and video media, which are stored separately. Your original data is not modified.&lt;/p&gt;
    &lt;p&gt;The database schema has been meticulously designed and refined to be as adaptable as possible.&lt;/p&gt;
    &lt;p&gt;Timelinize will continue to develop and evolve. In the future, I anticipate the following capabilities:&lt;/p&gt;
    &lt;p&gt;Annotate your timeline, write rich stories with live embeddings from your timeline data, or make physical media like photo books (but with more than just photos!).&lt;/p&gt;
    &lt;p&gt;Add context to your timeline with additional public timelines which have weather, local/regional news, and global events.&lt;/p&gt;
    &lt;p&gt;Securely and privately share parts of your timeline with trusted friends and family members, directly from your computer to theirs.&lt;/p&gt;
    &lt;p&gt;Right now, Timelinize sits "behind" the apps and platforms you already use. But in the future, you could sync data directly to your timeline as it is originated.&lt;/p&gt;
    &lt;p&gt;Collect your data from various sources. Import it with a few clicks. Within minutes, explore millions of your data points in several intuitive ways.&lt;/p&gt;
    &lt;p&gt;Imported data is copied into your timeline folder, ensuring long-term stability and integrity. Timelines are portable—you can copy them or move them to other devices and computers.&lt;/p&gt;
    &lt;p&gt;Your timeline is simply a folder on disk containing a SQLite database alongside your data files. You can freely explore it with other tooling, so you're not locked into Timelinize.&lt;/p&gt;
    &lt;p&gt;Unlike writing a journal, you don't have to take extra time to create content. You're already making the data your timeline can display! And it doesn't replace your current workflow or apps.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45504973</guid><pubDate>Tue, 07 Oct 2025 16:10:22 +0000</pubDate></item><item><title>Seeing like a software company</title><link>https://www.seangoedecke.com/seeing-like-a-software-company/</link><description>&lt;doc fingerprint="2615d9142c2d05e0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Seeing like a software company&lt;/head&gt;
    &lt;p&gt;The big idea of James C. Scott’s Seeing Like A State can be expressed in three points:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Modern organizations exert control by maximising “legibility”: by altering the system so that all parts of it can be measured, reported on, and so on.&lt;/item&gt;
      &lt;item&gt;However, these organizations are dependent on a huge amount of “illegible” work: work that cannot be tracked or planned for, but is nonetheless essential.&lt;/item&gt;
      &lt;item&gt;Increasing legibility thus often actually lowers efficiency - but the other benefits are high enough that organizations are typically willing to do so regardless.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By “legible”, I mean work that is predictable, well-estimated, has a paper trail, and doesn’t depend on any contingent factors (like the availability of specific people). Quarterly planning, OKRs, and Jira all exist to make work legible. Illegible work is everything else: asking for and giving favors, using tacit knowledge that isn’t or can’t be written down, fitting in unscheduled changes, and drawing on interpersonal relationships. As I’ll argue, tech companies need to support both of these kinds of work.&lt;/p&gt;
    &lt;p&gt;Thinking in terms of legibility and illegibility explains so many of the things that are confusing about large software companies. It explains why companies do many things that seem obviously counter-productive, why the rules in practice are so often out of sync with the rules as written, and why companies are surprisingly willing to tolerate rule-breaking in some contexts.&lt;/p&gt;
    &lt;head rend="h3"&gt;Seeing like a state&lt;/head&gt;
    &lt;p&gt;James C. Scott was writing about the “high modernist” movement in governance that produced (among other things) the tidy German forests of the 19th century1. In order to produce wood at scale, the German state demanded legibility: forests that an inspector could visit to tally up the amount of healthy trees. That means that you must be able to walk through the forest - i.e. the underbrush must be controlled - and the trees ought to be ideally laid out in neat rows of a single type.&lt;/p&gt;
    &lt;p&gt;Proponents of legibility often describe their processes as “efficiency measures” or ways to “avoid waste”. But overall, the new “efficient” forests were in fact far less efficient than the old, illegible forests. They produced less wood per year and required more effort to fight disease, because the underbrush proved surprisingly load-bearing to the health of the soil, and the variety of species turned out to have been an asset. The new homogeneous forests could be wiped out by a single parasite or disease in a way that the older, more varied forests could not.&lt;/p&gt;
    &lt;p&gt;However, the advantages of legibility are enormous. Once you know exactly how many trees you have, you can plan ahead, make large trade deals, avoid graft, and so on. To me, this is the most interesting point Scott makes. Large organizations did genuinely think that more legibility would necessarily increase efficiency2. But even when it became clear that that was false, those organizations continued pushing for legibility anyway, because the other advantages were too powerful.&lt;/p&gt;
    &lt;head rend="h3"&gt;Seeing like a software company&lt;/head&gt;
    &lt;p&gt;It’s the same way in software companies. It’s almost a truism among software engineers that a single engineer can be more efficient alone than they can by working as part of a team. That’s why there are so many anecdotes about engineers taking leave to finally get some work done, or about productive work being done on nights and weekends.&lt;/p&gt;
    &lt;p&gt;Likewise, it should be obvious to any practicing engineer that engineer-driven work goes far more swiftly than work that is mandated from above. Engineer-driven work doesn’t need to be translated into something that makes sense, doesn’t need to be actively communicated in all directions, and can in general just be done in the most straightforward and efficient way.&lt;/p&gt;
    &lt;p&gt;This is why tiny software companies are often much better than large software companies at delivering software: it doesn’t matter that the large company is throwing ten times the number of engineers at the problem if the small company is twenty times more efficient3.&lt;/p&gt;
    &lt;p&gt;Why don’t large companies react to this by doing away with all of their processes? Are they stupid? No. The processes that slow engineers down are the same processes that make their work legible to the rest of the company. And that legibility (in dollar terms) is more valuable than being able to produce software more efficiently.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why legibility is valuable to tech companies&lt;/head&gt;
    &lt;p&gt;What does legibility mean to a tech company, in practice? It means:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The head of a department knows, to the engineer, all the projects the department is currently working on&lt;/item&gt;
      &lt;item&gt;That head also knows (or can request) a comprehensive list of all the projects the department has shipped in the last quarter&lt;/item&gt;
      &lt;item&gt;That head has the ability to plan work at least one quarter ahead (ideally longer)&lt;/item&gt;
      &lt;item&gt;That head can, in an emergency, direct the entire resources of the department at immediate work&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note that “shipping high quality software” or “making customers happy” or even “making money” is not on this list. Those are all things tech companies want to do, but they’re not legibility.&lt;/p&gt;
    &lt;p&gt;Our small-but-efficient software company meets only one of these criteria: the ability to pivot to some immediate problem that needs solving. The other information is all locked up in various engineers’ heads, who may or may not remember what they did two months ago (and who certainly won’t be willing to commit to work two months from now). That’s not necessarily a problem, so long as everyone’s on the same page about what needs doing and the product is continuing to improve.&lt;/p&gt;
    &lt;p&gt;A typical large software company meets almost all of these criteria - I say almost, because in some companies or departments the ability to direct immediate work has atrophied (more on that later). But aside from that, large companies are usually very good at cataloguing what is being worked on, remembering what’s been shipped in the past, and planning work in the medium-to-long-term.&lt;/p&gt;
    &lt;p&gt;Why are these capabilities so valuable to a large software company, when small software companies can do without them? This is leaving my area of expertise somewhat, but I’m pretty sure the main answer is large enterprise deals. Making deals with large enterprise customers is fantastically profitable. Any sufficiently large SaaS will thus pivot from small customers to enterprise customers, if it can4. But enterprise deals (a) can take many, many months to set up, and (b) require making long-term feature commitments. An illegible company is not configured to be able to stick with a boring enterprise deal for many months, constantly answering questions and delivering features. Large enterprise customers simply won’t trust a small software company to deliver the things they need over the next year or two.&lt;/p&gt;
    &lt;p&gt;Customers like this typically value legibility very highly, and so demand that their vendors also be legible. In fact, highly legible organizations struggle to communicate at all with organizations that are less legible (and vice versa). They don’t have access to the right bona fides, they don’t talk the same language, and so on. This puts real pressure on growing tech companies to become more legible, even if it hurts their ability to deliver software.&lt;/p&gt;
    &lt;head rend="h3"&gt;Legible assumptions&lt;/head&gt;
    &lt;p&gt;In the pursuit of legibility, large tech companies make simplifying assumptions about the nature of tech work. For instance, they assume:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Any engineers with the same job title perform roughly the same.&lt;/item&gt;
      &lt;item&gt;Engineers can be shuffled and reorganized without substantial loss of productivity.&lt;/item&gt;
      &lt;item&gt;A team will maintain the same level of productivity over time, if it has the same number of engineers.&lt;/item&gt;
      &lt;item&gt;Projects can be estimated ahead of time, albeit with some margin for error. The more time spent estimating a project, the more accurate the estimate will become.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Of course, all of these are false. Within the same job title, there is significant variance in engineering ability. Engineers have different skillsets and interests, and will work much more productively on projects that are a good fit for them. Because of this, the productivity of a team has a weak relationship to the number of engineers on the team.&lt;/p&gt;
    &lt;p&gt;Project estimates are largely fantasy. More accurately, they’re performative: the initial estimate determines the kind of engineering work that gets done to deliver by that estimate, not the other way around. For this reason, breaking down a project into parts and estimating each part often delivers a less accurate estimate, because it makes it harder for engineers to align with the overall ship date.&lt;/p&gt;
    &lt;p&gt;However, these assumptions are true enough for their purpose, which is to provide legibility to the executives in charge of the company. Whether the project estimate is accurate or not, it can be used to plan and to communicate with other large organizations (who are themselves typically aware that these estimates ought not to be taken completely seriously).&lt;/p&gt;
    &lt;head rend="h3"&gt;Temporary sanctioned zones of illegibility&lt;/head&gt;
    &lt;p&gt;I mentioned above that large companies sometimes lose the ability to prioritize immediate work. This is because the processes that make work legible also impose a serious delay. Consider the steps that a hypothetical large company might take before beginning to write code on a problem:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Somebody has a product idea.&lt;/item&gt;
      &lt;item&gt;They take that idea to the Product org, where it goes into the “planning” stage. Meetings are had about the idea.&lt;/item&gt;
      &lt;item&gt;Once the Product org formally decide they want to do it, the idea then passes to the Engineering org: into the hands of some council of engineering architects, who are tasked with the initial technical review. They figure out how it fits into the general engineering priorities and give it a very rough time estimate.&lt;/item&gt;
      &lt;item&gt;The VPs and senior managers in the engineering org then negotiate which team will own the work. Often this is a semi-technical, semi-organizational decision (because which service the work should fall into is at least partly a technical question).&lt;/item&gt;
      &lt;item&gt;Finally the work lands on the team. It enters the team planning backlog, where the team technical lead breaks it out into smaller pieces of work.&lt;/item&gt;
      &lt;item&gt;Those smaller pieces of work enter the team ticket backlog, and are estimated in the team’s weekly planning meeting.&lt;/item&gt;
      &lt;item&gt;Finally some of those pieces of work make it into the next sprint, and are picked up by an engineer who can actually do it.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I’m leaving out many crucial parts of this process: the updates on each ticket, which then roll up to higher levels of management, legal and design review, which can themselves take weeks, and then the final steps involved in shipping the change to customers. All of this makes the work very legible, but none of this is compatible with work that has to be done right now. What do you do when there’s a sudden, urgent technical problem - maybe you’re about to overflow your &lt;code&gt;int&lt;/code&gt; ID column on the users table, or some very large customer is experiencing a show-stopping bug?5&lt;/p&gt;
    &lt;p&gt;To solve this kind of problem, tech companies often reserve the right to create temporary zones where illegible work is allowed. Sometimes these are called “virtual teams”, or “strike teams” (or even the colourful name “tiger teams”). They are composed of hand-picked engineers who are trusted by the organization. Often there is no manager assigned at all, but instead some very senior engineer who’s tasked with running the project. These teams are given a loose mandate - like “stop the database from falling over every few days” - and allowed to do basically whatever it takes to get it done.&lt;/p&gt;
    &lt;p&gt;This is a smart compromise between complete illegibility, which as I discussed above would make the company unable to make deals with its richest customers, and complete legibility, which would force even urgent company-killing issues to go through the entire laborious process of scoping, planning and estimating.&lt;/p&gt;
    &lt;p&gt;Even when siloed to a temporary team, sanctioned illegibility still coexists awkwardly with the rest of the organization. Engineers outside the team don’t like seeing other engineers given the freedom to work without the burden of process: either because they’re jealous, or because they’re believers in process and think that such work is unacceptably dangerous. Managers also don’t like extending that level of trust. That’s why sanctioned efforts like this are almost always temporary. The majority of the illegible work that occurs in large organizations is still unsanctioned.&lt;/p&gt;
    &lt;head rend="h3"&gt;Permanent zones of unsanctioned illegibility&lt;/head&gt;
    &lt;p&gt;If you’re an engineer on team A, and you need team B to do some kind of work for you, the formal way to do this is to create an issue in their “planning” backlog and wait for it to go through the entire twelve-step process before it finally makes its way into one of their sprints, where hopefully somebody will pick it up and do it. This can take weeks to months. When what you want is a one-line change, it’s incredibly frustrating to watch your requested work item go through all these steps - each one of which takes many times longer than it would take to simply do the work.&lt;/p&gt;
    &lt;p&gt;The official way around this problem is that team A should anticipate in their planning process that team B will need to do this work, so that piece for team B can enter their backlog at the same time as it enters team A’s backlog. That way (in theory) they should be complete at around the same time6. Any practicing software engineer knows how ridiculous this idea is. You can never anticipate every change that has to be made months before you start writing code.&lt;/p&gt;
    &lt;p&gt;The actual way around this problem is illegible backchannels. An engineer on team A reaches out to an engineer on team B asking “hey, can you make this one-line change for me”. That engineer on team B then does it immediately, maybe creating a ticket, maybe not. Then it’s done! This works great, but it’s illegible because the company can’t expect it or plan for it - it relies on the interpersonal relationships between engineers on different teams, which are very difficult to quantify. If you’re a well-liked engineer, your ability to pull on these backchannels is significantly greater than if you’re brand-new or have a bad reputation. But how well-liked you are is not something companies can officially use when they’re planning projects.&lt;/p&gt;
    &lt;p&gt;Backchannels are a constant presence at all levels of the company. As well as engineer-engineer cross-team backchannels, there are backchannels inside teams, between managers, product managers, and so on. Often when a question is asked formally in a public space, it’s already been rehearsed and workshopped privately with the person who’s answering the question. None of this is or can be documented as part of the formal processes of the company, but it’s load-bearing nonetheless. Many formal processes simply cannot function without the consensus mechanisms or safety valves offered by backchannels.&lt;/p&gt;
    &lt;p&gt;Sometimes backchannels can go badly. Earlier this year I wrote Protecting your time from predators in large tech companies about how some people use backchannels to benefit themselves at the expense of the naive engineers they’re requesting work from. And it never feels good when you get the sense that everyone in a meeting has privately discussed the topic ahead of time except for you. For these reasons, some people think that backchannels themselves are a bad thing, and that all communication should go via formal, legible channels.&lt;/p&gt;
    &lt;head rend="h3"&gt;Sociopaths, clueless, and losers&lt;/head&gt;
    &lt;p&gt;There’s another text which has been as influential to many as Seeing Like A State. This one isn’t a book, but a blog post: The Gervais Principle by Venkatesh Rao. Rao divides organizations into three groups. At the top are the “sociopaths”, who cynically use organizational rules for their own benefit. In middle management are the “clueless”, who are bought into the formal rules of the organization and don’t realise that there’s a deeper game being played above their heads. Below them are the “losers”, who realise there’s a game being played but don’t want to play it. The name “losers” is not a value judgement - I think it’s meant to affectionately pick out people like the leads in Clerks, who are too authentic to get involved in the corporate game.&lt;/p&gt;
    &lt;p&gt;I don’t agree with everything in The Gervais Principle, though I think it’s worth a read (if you’re interested in this stuff, you should also read the excellent Moral Mazes). But the categories here can be very naturally read in terms of legibility. Both sociopaths and losers are engaged with the illegible world of the organization. Sociopaths use this world to climb the ladder, while losers use it to carve out a cosy low-effort niche for themselves.&lt;/p&gt;
    &lt;p&gt;The “clueless” are only engaged with legible processes. They’re the people who, when they want to get promoted, go and look up the formal job ladder and make a plan for how they can exemplify each of the values at the next level. They’re concerned with doing everything by the book. When they’re forced into an encounter with the illegible world, their reaction is to shake their heads and start drafting updates to the legible process that can accommodate some pale approximation of the more-efficient illegible process.&lt;/p&gt;
    &lt;p&gt;I think it’s far too cynical to call these people clueless. Legible process is still very important - after all, it’s the large part of what the organization does. Improving formal processes is still very high-leverage work, even if formal processes can’t ever describe the entirety of how an organization operates. People who are invested in legibility have real value to any tech company.&lt;/p&gt;
    &lt;p&gt;However, thinking about people in Rao’s categories - people who exploit illegibility, people who find it distasteful, and people who use it casually - can be illuminating. Many frequent areas of conflict in software companies stem from the friction between these groups of people.&lt;/p&gt;
    &lt;head rend="h3"&gt;Final thoughts&lt;/head&gt;
    &lt;p&gt;I write a lot about recognizing and using illegibility in tech companies:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Breaking the (formal, legible) rules is sometimes the right thing to do&lt;/item&gt;
      &lt;item&gt;Beware of savvy product managers (and others) exploiting illegible channels to chisel work out of naive engineers&lt;/item&gt;
      &lt;item&gt;Competent engineers should work on “side bets” that are outside the normal planning process&lt;/item&gt;
      &lt;item&gt;Getting promoted to Staff and above has very little to do with the formal job ladder&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In general, advice about illegible processes is what I call “dangerous advice”. It’s dangerous because if you make it legible - for instance, if you announce publicly that you’re getting a piece of work done through backchannels instead of the formal process - you will be punished by the organization even if your management chain wanted you to do it. You can’t speak too loudly about it. It has to stay illegible.&lt;/p&gt;
    &lt;p&gt;I get a lot of negative feedback on these posts from people who say that you should never sidestep the formal process. According to them, if it needs changing, you should change the process instead of going around it. In other words, everything that goes on in a tech company should be legible, and illegible processes should be stamped out and converted to legible ones.&lt;/p&gt;
    &lt;p&gt;I think this view is naive. All organizations - tech companies, social clubs, governments - have both a legible and an illegible side. The legible side is important, past a certain size. It lets the organization do things that would otherwise be impossible: long-term planning, coordination with other very large organizations, and so on. But the illegible side is just as important. It allows for high-efficiency work, offers a release valve for processes that don’t fit the current circumstances, and fills the natural human desire for gossip and soft consensus.&lt;/p&gt;
    &lt;p&gt;edit: this got some comments on Hacker News. Some commenters agree with everything except the idea that large enterprise deals are the primary driver for legibility - they think it’s communication at scale, or being able to target market share, or internal control.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;This is the first example Scott gives, but I promise I did read the whole book. Other examples: the construction of Brasília, Operation Vijiji in Tanzania, and the Soviet attempt to replace individual peasant farms with state-run collectives.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;This is a very common false belief today among software engineers.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;I don’t think small companies just work harder; plenty of people at large companies work very hard. I also don’t think that small companies just have better engineers - what advantage they have in enthusiasm is often outweighed by the fact that they can’t afford to pay as well.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;I was at Zendesk during the height of its pivot.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Ironically, the most urgent types of problem typically can be solved via a normal “incident” process - but this itself is usually a zone where the rules are relaxed a bit in order to resolve the incident as quickly as possible. Anyway, here I’m not talking about incidents but about projects that will take a couple of weeks to resolve.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The other, healthier official way is to allow teams to make small changes to other teams’ services themselves. But this only goes so far - the other team will always be the gatekeepers for changes like this, and are always in a position to slow down the change by days or weeks.&lt;/p&gt;↩&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you liked this post, consider subscribing to email updates about my new posts, or sharing it on Hacker News.&lt;/p&gt;
    &lt;p&gt;September 3, 2025 │ Tags: tech companies&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45505539</guid><pubDate>Tue, 07 Oct 2025 16:49:09 +0000</pubDate></item><item><title>Gemini 2.5 Computer Use model</title><link>https://blog.google/technology/google-deepmind/gemini-computer-use-model/</link><description>&lt;doc fingerprint="b97269db1c538405"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing the Gemini 2.5 Computer Use model&lt;/head&gt;
    &lt;p&gt;Earlier this year, we mentioned that we're bringing computer use capabilities to developers via the Gemini API. Today, we are releasing the Gemini 2.5 Computer Use model, our new specialized model built on Gemini 2.5 Pro’s visual understanding and reasoning capabilities that powers agents capable of interacting with user interfaces (UIs). It outperforms leading alternatives on multiple web and mobile control benchmarks, all with lower latency. Developers can access these capabilities via the Gemini API in Google AI Studio and Vertex AI.&lt;/p&gt;
    &lt;p&gt;While AI models can interface with software through structured APIs, many digital tasks still require direct interaction with graphical user interfaces, for example, filling and submitting forms. To complete these tasks, agents must navigate web pages and applications just as humans do: by clicking, typing and scrolling. The ability to natively fill out forms, manipulate interactive elements like dropdowns and filters, and operate behind logins is a crucial next step in building powerful, general-purpose agents.&lt;/p&gt;
    &lt;head rend="h2"&gt;How it works&lt;/head&gt;
    &lt;p&gt;The model’s core capabilities are exposed through the new `computer_use` tool in the Gemini API and should be operated within a loop. Inputs to the tool are the user request, screenshot of the environment, and a history of recent actions. The input can also specify whether to exclude functions from the full list of supported UI actions or specify additional custom functions to include.&lt;/p&gt;
    &lt;p&gt;Gemini 2.5 Computer Use Model flow&lt;/p&gt;
    &lt;p&gt;The model then analyzes these inputs and generates a response, typically a function call representing one of the UI actions such as clicking or typing. This response may also contain a request for an end user confirmation, which is required for certain actions such as making a purchase. The client-side code then executes the received action.&lt;/p&gt;
    &lt;p&gt;After the action is executed, a new screenshot of the GUI and the current URL are sent back to the Computer Use model as a function response restarting the loop. This iterative process continues until the task is complete, an error occurs or the interaction is terminated by a safety response or user decision.&lt;/p&gt;
    &lt;p&gt;The Gemini 2.5 Computer Use model is primarily optimized for web browsers, but also demonstrates strong promise for mobile UI control tasks. It is not yet optimized for desktop OS-level control.&lt;/p&gt;
    &lt;p&gt;Check out a few demos below to see the model in action (shown here at 3X speed).&lt;/p&gt;
    &lt;p&gt;Prompt: “From https://tinyurl.com/pet-care-signup, get all details for any pet with a California residency and add them as a guest in my spa CRM at https://pet-luxe-spa.web.app/. Then, set up a follow up visit appointment with the specialist Anima Lavar for October 10th anytime after 8am. The reason for the visit is the same as their requested treatment.”&lt;/p&gt;
    &lt;p&gt;Prompt: “My art club brainstormed tasks ahead of our fair. The board is chaotic and I need your help organizing the tasks into some categories I created. Go to sticky-note-jam.web.app and ensure notes are clearly in the right sections. Drag them there if not.”&lt;/p&gt;
    &lt;head rend="h2"&gt;How it performs&lt;/head&gt;
    &lt;p&gt;The Gemini 2.5 Computer Use model demonstrates strong performance on multiple web and mobile control benchmarks. The table below includes results from self-reported numbers, evaluations run by Browserbase and evaluations we ran ourselves. Evaluation details are available in the Gemini 2.5 Computer Use evaluation info and in Browserbase’s blog post. Unless otherwise indicated, scores shown are for computer use tools exposed via API.&lt;/p&gt;
    &lt;p&gt;Gemini 2.5 Computer Use outperforms leading alternatives on multiple benchmarks&lt;/p&gt;
    &lt;p&gt;The model offers leading quality for browser control at the lowest latency, as measured by performance on the Browserbase harness for Online-Mind2Web.&lt;/p&gt;
    &lt;p&gt;Gemini 2.5 Computer Use delivers high accuracy while maintaining low latency&lt;/p&gt;
    &lt;head rend="h2"&gt;How we approached safety&lt;/head&gt;
    &lt;p&gt;We believe that the only way to build agents that will benefit everyone is to be responsible from the start. AI agents that control computers introduce unique risks, including intentional misuse by users, unexpected model behavior, and prompt injections and scams in the web environment. Thus, it is critical to implement safety guardrails with care.&lt;/p&gt;
    &lt;p&gt;We have trained safety features directly into the model to address these three key risks (described in the Gemini 2.5 Computer Use System Card).&lt;/p&gt;
    &lt;p&gt;Further, we also provide developers with safety controls, which empower developers to prevent the model from auto-completing potentially high-risk or harmful actions. Examples of these actions include harming a system's integrity, compromising security, bypassing CAPTCHAs, or controlling medical devices. The controls:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Per-step safety service: An out-of-model, inference-time safety service that assesses each action the model proposes before it’s executed.&lt;/item&gt;
      &lt;item&gt;System instructions: Developers can further specify that the agent either refuses or asks for user confirmation before it takes specific kinds of high-stakes actions. (Example in documentation).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Additional recommendations for developers on safety measures and best practices can be found in our documentation. While these safeguards are designed to reduce risk, we urge all developers to thoroughly test their systems before launch.&lt;/p&gt;
    &lt;head rend="h2"&gt;How early testers have used it&lt;/head&gt;
    &lt;p&gt;Google teams have already deployed the model to production for use cases including UI testing, which can make software development signficantly faster. Versions of this model have also been powering Project Mariner, the Firebase Testing Agent, and some agentic capabilities in AI Mode in Search.&lt;/p&gt;
    &lt;p&gt;Users from our early access program have also been testing the model to power personal assistants, workflow automation, and UI testing, and have seen strong results. In their own words:&lt;/p&gt;
    &lt;head rend="h2"&gt;How to get started&lt;/head&gt;
    &lt;p&gt;Starting today, the model is available in public preview, accessible via the Gemini API on Google AI Studio and Vertex AI.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Try it now: In a demo environment hosted by Browserbase.&lt;/item&gt;
      &lt;item&gt;Start building: Dive into our reference and documentation (see Vertex AI docs for enterprise use) to learn how to build your own agent loop locally with Playwright or in a cloud VM with Browserbase.&lt;/item&gt;
      &lt;item&gt;Join the community: We’re excited to see what you build. Share feedback and help guide our roadmap in our Developer Forum.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45507936</guid><pubDate>Tue, 07 Oct 2025 19:49:11 +0000</pubDate></item><item><title>Study of 1M-year-old skull points to earlier origins of modern humans</title><link>https://www.theguardian.com/science/2025/sep/25/study-of-1m-year-old-skull-points-to-earlier-origins-of-modern-humans</link><description>&lt;doc fingerprint="f65511fdb8b11bbe"&gt;
  &lt;main&gt;
    &lt;p&gt;A million-year-old human skull suggests that the origins of modern humans may reach back far deeper in time than previously thought and raises the possibility that Homo sapiens first emerged outside of Africa.&lt;/p&gt;
    &lt;p&gt;Leading scientists reached this conclusion after reanalysis of a skull known as Yunxian 2 discovered in China and previously classified as belonging to a member of the primitive human species Homo erectus.&lt;/p&gt;
    &lt;p&gt;After applying sophisticated reconstruction techniques to the skull, scientists believe that it may instead belong to a group called Homo longi (dragon man), closely linked to the elusive Denisovans who lived alongside our own ancestors.&lt;/p&gt;
    &lt;p&gt;This repositioning would make the fossil the closest on record to the split between modern humans and our closest relatives, the Neanderthals and Denisovans, and would radically revise understanding of the last 1m years of human evolution.&lt;/p&gt;
    &lt;p&gt;Prof Chris Stringer, an anthropologist and research leader in human evolution at the Natural History Museum in London, said: “This changes a lot of thinking because it suggests that by 1m years ago our ancestors had already split into distinct groups, pointing to a much earlier and more complex human evolutionary split than previously believed. It more or less doubles the time of origin of Homo sapiens.”&lt;/p&gt;
    &lt;p&gt;The skull was first unearthed in Hubei province in 1990, badly crushed and difficult to interpret. Based on its age and some broad-brush traits, it was assigned as Homo erectus, a group that is thought to have contained direct ancestors of modern humans.&lt;/p&gt;
    &lt;p&gt;The latest work used advanced CT imaging, high-resolution surface scanning and sophisticated digital techniques to produce a virtual reconstruction of the skull. The skull’s large, squat brain case and jutting lower jaw are reminiscent of Homo erectus. But the overall shape and size of the brain case and teeth appear to place it much closer to Homo longi, a species that scientists have recently argued should incorporate the Denisovans.&lt;/p&gt;
    &lt;p&gt;This would push the split between our own ancestors, Neanderthals and Homo longi back by at least 400,000 years and, according to Springer, raises the possibility that our common ancestor – and potentially the first Homo sapiens – lived in western Asia rather than Africa.&lt;/p&gt;
    &lt;p&gt;“This fossil is the closest we’ve got to the ancestor of all those groups,” Stringer said.&lt;/p&gt;
    &lt;p&gt;A computational analysis of a wider selection of fossils suggests that in the last 800,000 years, large-brained humans evolved along just five major branches: Asian erectus, heidelbergensis, sapiens, Neanderthals and Homo longi (including the Denisovans).&lt;/p&gt;
    &lt;p&gt;“We feel that this study is a landmark step towards resolving the ‘muddle in the middle’ [the confusing array of human fossils from between 1m and 300,000 years ago] that has preoccupied palaeoanthropologists for decades,” Stringer said.&lt;/p&gt;
    &lt;p&gt;The findings run counter to some recent analyses based on genetic comparisons of living humans and ancient DNA, meaning the conclusions are likely to be contentious.&lt;/p&gt;
    &lt;p&gt;Dr Frido Welker, an associate professor in human evolution at the University of Copenhagen, who was not involved in the research, said: “It’s exciting to have a digital reconstruction of this important cranium available. If confirmed by additional fossils and genetic evidence, the divergence dating would be surprising indeed. Alternatively, molecular data from the specimen itself could provide insights confirming or disproving the authors’ morphological hypothesis.”&lt;/p&gt;
    &lt;p&gt;The findings are published in the journal Science.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45510582</guid><pubDate>Wed, 08 Oct 2025 00:17:21 +0000</pubDate></item><item><title>Show HN: Oh Yah – Routine management app I built for my sons</title><link>https://ohyahapp.com</link><description>&lt;doc fingerprint="3c11f5fd244164e3"&gt;
  &lt;main&gt;
    &lt;p&gt;Each task has a dedicated timer in a distraction-free environment. Navigation is disabled during focus time to maintain attention and encourage task completion.&lt;/p&gt;
    &lt;p&gt;Kids can submit photo evidence of completed tasks, building accountability whilst giving parents peace of mind about task completion.&lt;/p&gt;
    &lt;p&gt;Ordered tasks provide structure and sequence, whilst unordered tasks offer flexibility. Clear priorities help kids understand what needs to be done when.&lt;/p&gt;
    &lt;p&gt;Parents review individual tasks but award stars for the complete schedule. Auto-approval with full stars occurs after 24 hours if all tasks are submitted and no manual award is given.&lt;/p&gt;
    &lt;p&gt;Manage up to 8 child profiles with individual schedules and tasks. Perfect for families with multiple children.&lt;/p&gt;
    &lt;p&gt;Clean interface with simple navigation. Kids tap their profile and start immediately - no complex menus or overwhelming choices.&lt;/p&gt;
    &lt;p&gt;Oh Yah! is for families who need routine management that works with their child's unique needs — not generic productivity apps that overwhelm.&lt;/p&gt;
    &lt;p&gt;Child taps their profile and sees today's tasks in a consistent order set by parents.&lt;/p&gt;
    &lt;p&gt;Each task opens in a focused timer modal with no distractions or navigation.&lt;/p&gt;
    &lt;p&gt;Take a photo as proof and submit the completed task for parent review.&lt;/p&gt;
    &lt;p&gt;Parents review tasks and award stars based on quality. Unreviewed tasks auto-approve after 24 hours, keeping parents accountable.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45513459</guid><pubDate>Wed, 08 Oct 2025 08:15:49 +0000</pubDate></item><item><title>Synology reverses policy banning third-party HDDs after sales allegedly plummet</title><link>https://www.guru3d.com/story/synology-reverses-policy-banning-thirdparty-hdds-after-nas-sales-plummet/</link><description>&lt;doc fingerprint="7da303bb4dfe4cfc"&gt;
  &lt;main&gt;
    &lt;p&gt;Now, with the release of DSM 7.3, Synology has quietly walked the policy back. Third-party hard drives and 2.5-inch SATA SSDs can once again be used without triggering warning messages or reduced functionality. Drives from Seagate, WD, and others will work exactly as they did before—complete with full monitoring, alerts, and storage features.&lt;/p&gt;
    &lt;p&gt;For users, this means more choice and lower costs when building or upgrading a NAS. For Synology, it’s a much-needed course correction after months of backlash. While the company hasn’t publicly admitted fault, it’s clear that sales pressure and community outrage played a major role in reversing the decision.&lt;/p&gt;
    &lt;p&gt;Critics say the entire episode has damaged Synology’s reputation. The company seemed to believe that after QNAP’s well-known ransomware troubles, it could tighten control of the market without losing customers. Instead, the plan backfired—hard. Many loyal users have since turned to alternative brands or expressed hesitation about buying another Synology product.&lt;/p&gt;
    &lt;p&gt;Still, the return of open drive support is good news for anyone running a Synology NAS. It restores the flexibility that made the brand so popular in the first place. Whether this move is enough to win back frustrated users remains to be seen, but for now, DSM 7.3 brings a welcome dose of freedom back to the platform.&lt;/p&gt;
    &lt;p&gt;Source: Synology / nascompares&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45513485</guid><pubDate>Wed, 08 Oct 2025 08:19:36 +0000</pubDate></item><item><title>Nobel Prize in Chemistry 2025</title><link>https://www.nobelprize.org/prizes/chemistry/2025/popular-information/</link><description>&lt;doc fingerprint="37d0923c8f250160"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Popular information&lt;/head&gt;
    &lt;p&gt;Popular science background: They have created new rooms for chemistry (pdf)&lt;lb/&gt;Populärvetenskaplig information: De har skapat nya rum för kemi (pdf)&lt;/p&gt;
    &lt;head rend="h2"&gt;They have created new rooms for chemistry&lt;/head&gt;
    &lt;p&gt;Susumu Kitagawa, Richard Robson and Omar M. Yaghi are awarded the Nobel Prize in Chemistry 2025 for the development of a new type of molecular architecture. The constructions they created – metal–organic frameworks – contain large cavities in which molecules can flow in and out. Researchers have used them to harvest water from desert air, extract pollutants from water, capture carbon dioxide and store hydrogen.&lt;/p&gt;
    &lt;p&gt;An attractive and very spacious studio apartment, specifically designed for your life as a water molecule – this is how an estate agent might describe one of all the metal–organic frameworks that laboratories around the world have developed in recent decades. Other constructions of this type are tailormade for capturing carbon dioxide, separating PFAS from water, delivering pharmaceuticals in the body or managing extremely toxic gases. Some can trap the ethylene gas from fruit – so they ripen more slowly – or encapsulate enzymes that break down traces of antibiotics in the environment.&lt;/p&gt;
    &lt;p&gt;Simply stated, metal–organic frameworks are exceptionally useful. Susumu Kitagawa, Richard Robson and Omar Yaghi are awarded the Nobel Prize in Chemistry 2025 because they created the first metal–organic frameworks (MOF) and demonstrated their potential. Thanks to the laureates’ work, chemists have been able to design tens of thousands of different MOFs, facilitating new chemical wonders.&lt;/p&gt;
    &lt;p&gt;As so often in the sciences, the story of the Nobel Prize in Chemistry 2025 begins with someone who thought outside the box. This time, inspiration came during preparations for a classic chemistry lesson, in which the students were to build molecules from rods and balls.&lt;/p&gt;
    &lt;head rend="h3"&gt;A simple wooden model of a molecule generates an idea&lt;/head&gt;
    &lt;p&gt;It was 1974. Richard Robson, who was teaching at the University of Melbourne, Australia, had been tasked with turning wooden balls into models of atoms, so students could create molecular structures. For this to work, he needed the university’s workshop to drill holes in them, so that wooden rods – the chemical bonds – could be attached to the atoms. However, the holes could not be randomly placed. Each atom – such as carbon, nitrogen or chlorine – forms chemical bonds in a specific way. Robson needed to mark out where the holes should be drilled.&lt;/p&gt;
    &lt;p&gt;When the workshop returned the wooden balls, he tested building some molecules. This was when he had a moment of insight: there was a vast amount of information baked into the holes’ positioning. The model molecules automatically had the correct form and structure, because of where the holes were situated. This insight led to his next idea: what would happen if he utilised the atoms’ inherent properties to link together different types of molecules, rather than individual atoms? Could he design new types of molecular constructions?&lt;/p&gt;
    &lt;head rend="h3"&gt;Robson builds innovative chemical creations&lt;/head&gt;
    &lt;p&gt;Every year, when Robson brought out the wooden models to teach new students, the same idea occurred to him. However, more than a decade passed before he decided to test it out. He started with a very simple model, inspired by the structure of a diamond, in which each carbon atom bonds to four others, forming a tiny pyramid (figure 2). Robson’s aim was to build a similar structure, but his would be based on positively charged copper ions, Cu+. Like carbon, they prefer to have four other atoms around them.&lt;/p&gt;
    &lt;p&gt;He combined the copper ions with a molecule that has four arms: 4′,4″,4”’,4””-tetracyanotetraphenylmethane. There’s no need to remember its complicated name, but it is important that the molecule at the end of each arm had a chemical group, nitrile, that was attracted to the positively charged copper ions (figure 2).&lt;/p&gt;
    &lt;p&gt;At that time, most chemists would have assumed that combining copper ions with the four-armed molecules would result in a bird’s nest of ions and molecules. But things went Robson’s way. As he had predicted, the ions and molecules inherent attraction to each other mattered, so they organised themselves into a large molecular construction. Just like carbon atoms in a diamond, they formed a regular crystalline structure. However, unlike diamond – which is a compact material – this crystal contained a vast number of large cavities (figure 2).&lt;/p&gt;
    &lt;p&gt;In 1989, Robson presented his innovative chemical creation in the Journal of the American Chemical Society. In his article, he speculates about the future and suggests that this could offer a new way to construct materials. These, he writes, could be given never previously seen properties, potentially beneficial ones.&lt;/p&gt;
    &lt;p&gt;As it turned out, he had foreseen the future.&lt;/p&gt;
    &lt;head rend="h3"&gt;Robson brings about a pioneering spirit in chemistry&lt;/head&gt;
    &lt;p&gt;As soon as the year after his pioneering work was published, Robson presented several new types of molecular constructions with cavities that were filled with various substances. He used one of them to exchange ions. He submerged the ion-filled construction in a fluid that contained a different type of ion. The result was that the ions changed places, demonstrating that substances could flow in and out of the construction.&lt;/p&gt;
    &lt;p&gt;In his experiments, Robson showed that rational design can be utilised for building crystals with spacious interiors that are optimised for specific chemicals. He suggested that this new form of molecular construction – when correctly designed – could be used to catalyse chemical reactions, for example.&lt;/p&gt;
    &lt;p&gt;However, Robson’s constructions were quite rickety and tended to fall apart. Many chemists thought they were useless, but some could see that he was onto something and, for them, his ideas about the future awakened a pioneering spirit. Those who would come to lay a stable foundation for his visions were Susumu Kitagawa and Omar Yaghi. Between 1992 and 2003 they made – separately – a series of groundbreaking discoveries. We will begin in the 1990s, with Kitagawa, who was working at Kindai University, Japan.&lt;/p&gt;
    &lt;head rend="h3"&gt;Kitagawa’s motto: even useless things can become useful&lt;/head&gt;
    &lt;p&gt;Throughout his research career, Susumu Kitagawa has followed an important principle: to try to see “the usefulness of useless.” As a young student, he read a book by the Nobel Prize laureate Hideki Yukawa. In it, Yukawa refers to an ancient Chinese philosopher, Zhuangzi, who says that we must question what we believe to be useful. Even if something does not bring immediate benefit, it may still turn out to be valuable.&lt;/p&gt;
    &lt;p&gt;Accordingly, when Kitagawa began to investigate the potential for creating porous molecular structures, he did not believe they had to have a specific purpose. When he presented his first molecular construction in 1992, it was indeed not particularly useful: a two-dimensional material with cavities in which acetone molecules could hide. However, it had resulted from a new way of thinking about the art of building with molecules. Like Robson, he used copper ions as cornerstones that were linked together by larger molecules.&lt;/p&gt;
    &lt;p&gt;Kitagawa wanted to continue experimenting with this new construction technology, but when he applied for grants, research funders did not think there was any particular point to his ambitions. The materials he created were unstable and had no purpose, so many of his proposals were rejected.&lt;/p&gt;
    &lt;p&gt;However, he did not give up and in 1997 he had his first major breakthrough. Using cobalt, nickel or zinc ions and a molecule called 4,4′-bipyridine, his research group created three-dimensional metal–organic frameworks that were intersected by open channels (figure 3). When they dried one of these materials – emptying it of water – it was stable and the spaces could even be filled with gases. The material could absorb and release methane, nitrogen and oxygen, without changing shape.&lt;/p&gt;
    &lt;head rend="h3"&gt;Kitagawa sees the uniqueness of his creations&lt;/head&gt;
    &lt;p&gt;Kitagawa’s constructions were both stable and had a function, but research funders were still unable to see their charm. One reason was that chemists already had zeolites, stable and porous materials, which they could build from silicon dioxide. These can absorb gases, so why would anyone develop a similar material that did not work as well?&lt;/p&gt;
    &lt;p&gt;Susumu Kitagawa understood that if he were to receive any major grants, he had to define what made metal–organic frameworks unique. So, in 1998, he described his vision in the Bulletin of the Chemical Society of Japan. He presented several advantages with MOFs. For example, they can be created from many types of molecules, so there is enormous potential for integrating different functions. Also – and this is important – he realised that MOFs can form soft materials. Unlike zeolites, which are usually hard materials, MOFs contain flexible molecular building blocks (figure 4) that can create a pliant material.&lt;/p&gt;
    &lt;p&gt;After this, all he had to do was to put his ideas into practice. Kitagawa, along with other researchers, started developing flexible MOFs. While they work on this, we will move our focus to the US, where Omar Yaghi was also occupied with taking molecular architecture to new heights.&lt;/p&gt;
    &lt;head rend="h3"&gt;A secret library visit opens Yaghi’s eyes to chemistry&lt;/head&gt;
    &lt;p&gt;Studying chemistry was not an obvious choice for Omar Yaghi. He and his many siblings were raised in a single room in Amman, Jordan, with no electricity or running water. School was a refuge from his otherwise challenging life. One day, when he was ten years old, he sneaked into the school library, which was usually locked, and picked a book at random from the shelf. On opening it, his eyes were drawn to unintelligible but captivating pictures – his first encounter with molecular structures.&lt;/p&gt;
    &lt;p&gt;At the age of 15 – and on his father’s stern instruction – Yaghi moved to the US to study. He was attracted by chemistry and eventually by the art of designing new materials, but found the traditional way of building new molecules too unpredictable. Normally, chemists combine substances that are to react with each other in a container. Then, to start the chemical reaction, they heat the container. The desired molecule forms, but is also often accompanied by a range of contaminating side products.&lt;/p&gt;
    &lt;p&gt;In 1992, when Yaghi started his first position as research group leader, at Arizona State University, he wanted to find more controlled ways in which to create materials. His aim was to use rational design to connect different chemical constituents, like pieces of Lego, to make large crystals. This turned out to be challenging, but they finally succeeded when the research group started combining metal ions with organic molecules. In 1995, Yaghi published the structure of two different two-dimensional materials; these were like nets and were held together by copper or cobalt. The latter could host guest molecules in its spaces and, when these were fully occupied, it was so stable that it could be heated to 350°C without collapsing. Yaghi describes this material in an article in Nature where he coins the name “metal–organic framework;” this term is now used to describe extended and ordered molecular structures that potentially contain cavities, and are built from metals and organic (carbon-based) molecules.&lt;/p&gt;
    &lt;head rend="h3"&gt;Just a few grams of Yaghi’s framework can contain a football pitch&lt;/head&gt;
    &lt;p&gt;Yaghi established the next milestone in the development of metal–organic frameworks in 1999, when he presented MOF-5 to the world. This material has become a classic in the field. It is an exceptionally spacious and stable molecular construction. Even when empty, it can be heated to 300°C without collapsing.&lt;/p&gt;
    &lt;p&gt;However, what caused many researchers to raise their eyebrows was the enormous area hiding inside the material’s cubic spaces. A couple of grams of MOF-5 holds an area as big as a football pitch, which means it can absorb much more gas than a zeolite could (figure 5).&lt;/p&gt;
    &lt;p&gt;Speaking of the differences between zeolites and MOFs, it took just a few years for researchers to succeed in developing soft MOFs. One of those who was able to present a flexible material was Susumu Kitagawa himself. When his material was filled with water or methane, it changed shape, and when it was emptied, it returned to its original form. The material behaved somewhat like a lung that can breathe gas in and out, changeable but stable.&lt;/p&gt;
    &lt;head rend="h3"&gt;Yaghi’s research group conjures drinking water from desert air&lt;/head&gt;
    &lt;p&gt;Omar Yaghi laid the final bricks in the foundation of metal–organic frameworks in 2002 and 2003. In two articles, in Science and Nature, he shows that it is possible to modify and change MOFs in a rational manner, giving them different properties. One thing he did was to produce 16 variants of MOF-5, with cavities that were both larger and smaller than those in the original material (figure 6). One variant could store huge volumes of methane gas, which Yaghi suggested could be used in RNG-fuelled vehicles.&lt;/p&gt;
    &lt;p&gt;Subsequently, metal–organic frameworks have taken the world by storm. Researchers have developed a molecular kit with a wide range of different pieces that can be used to create new MOFs. These have different shapes and characters, providing incredible potential for the rational – or AI-based – design of MOFs for different purposes. Figure 7 provides examples of how MOFs can be utilised. For instance, Yaghi’s research group has harvested water from the desert air of Arizona. During the night, their MOF material captured water vapour from the air. When dawn came and the sun heated the material, they were able to collect the water.&lt;/p&gt;
    &lt;head rend="h3"&gt;MOF materials that capture carbon dioxide and toxic gases&lt;/head&gt;
    &lt;p&gt;Researchers have created numerous different and functional MOFs. So far, in most cases, the materials have only been used on a small scale. To harness the benefits of MOF materials for humanity, many companies are now investing in their mass production and commercialisation. Some have succeeded. For example, the electronics industry can now use MOF materials to contain some of the toxic gases required to produce semiconductors. Another MOF can instead break down harmful gases, including some that can be used as chemical weapons. Numerous companies are also testing materials that can capture carbon dioxide from factories and power stations, to reduce greenhouse gas emissions.&lt;/p&gt;
    &lt;p&gt;Some researchers believe that metal–organic frameworks have such huge potential that they will be the material of the twenty-first century. Time will tell, but through the development of metal–organic frameworks, Susumu Kitagawa, Richard Robson and Omar Yaghi have provided chemists with new opportunities for solving some of the challenges we face. They have thus – as Alfred Nobel’s will states – brought the greatest benefit to humankind.&lt;/p&gt;
    &lt;head rend="h2"&gt;Further reading&lt;/head&gt;
    &lt;p&gt;Additional information on this year’s prizes, including a scientific background in English, is available on the website of the Royal Swedish Academy of Sciences, www.kva.se, and at www.nobelprize.org, where you can watch video from the press conferences, the Nobel Prize lectures and more. Information on exhibitions and activities related to the Nobel Prizes and the prize in economic sciences is available at www.nobelprizemuseum.se.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Royal Swedish Academy of Sciences has decided to award the Nobel Prize in Chemistry 2025 to&lt;/head&gt;
    &lt;p&gt;SUSUMU KITAGAWA&lt;lb/&gt;Born 1951 in Kyoto, Japan. PhD 1979 from Kyoto University, Japan. Professor at Kyoto University, Japan.&lt;/p&gt;
    &lt;p&gt;RICHARD ROBSON&lt;lb/&gt;Born 1937 in Glusburn, UK. PhD 1962 from University of Oxford, UK. Professor at University of Melbourne, Australia.&lt;/p&gt;
    &lt;p&gt;OMAR M. YAGHI&lt;lb/&gt;Born 1965 in Amman, Jordan. PhD 1990 from University of Illinois Urbana-Champaign, USA. Professor at University of California, Berkeley, USA.&lt;/p&gt;
    &lt;p&gt;“for the development of metal–organic frameworks”&lt;/p&gt;
    &lt;p&gt;Science Editors: Peter Brzezinski, Heiner Linke, Olof Ramström and Xiaodong Zou, the Nobel Committee for Chemistry&lt;lb/&gt;Text: Ann Fernholm&lt;lb/&gt;Translation: Clare Barnes&lt;lb/&gt;Illustrations: Johan Jarnestad&lt;lb/&gt;Editor: Alicia Hegner&lt;lb/&gt;© The Royal Swedish Academy of Sciences&lt;/p&gt;
    &lt;head rend="h3"&gt;Nobel Prize announcements 2025&lt;/head&gt;
    &lt;p&gt;Don't miss the Nobel Prize announcements 6–13 October. All announcements are streamed live here on nobelprize.org.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45514164</guid><pubDate>Wed, 08 Oct 2025 09:49:36 +0000</pubDate></item><item><title>Legal Contracts Built for AI Agents</title><link>https://paid.ai/blog/ai-agents/paid-gitlaw-introducing-legal-contracts-built-for-ai-agents</link><description>&lt;doc fingerprint="3d14491969fbea31"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Insights straight to your inbox&lt;/head&gt;
    &lt;p&gt;Join 10,000+ subscribers getting the latest insights on AI monetization.&lt;/p&gt;
    &lt;p&gt;We've partnered with GitLaw to launch something that should have existed from day one: a Master Services Agreement specifically designed for AI agents.&lt;/p&gt;
    &lt;p&gt;Not because we love legal documents (we don’t), but because the contracts most agent companies are using create problems they don't see until something breaks.&lt;/p&gt;
    &lt;p&gt;Most AI agent companies are still using SaaS contracts which makes no sense.&lt;/p&gt;
    &lt;p&gt;Your software isn't just sitting there helping someone fill out a form. It's booking meetings, writing code, making decisions. When something goes wrong, who's liable?&lt;/p&gt;
    &lt;p&gt;Standard contracts don't answer that question. They assume software waits for human instructions. Click button, thing happens, done.&lt;/p&gt;
    &lt;p&gt;But your agent operates differently. It decides which prospects to contact. It writes outreach messages. It follows up based on response patterns. It learns from interactions and adjusts behavior over time.&lt;/p&gt;
    &lt;p&gt;Those are autonomous actions. And when your agent does something unexpected, the gap between what your contract says and what your product does creates legal exposure you can't price for.&lt;/p&gt;
    &lt;p&gt;Your workflow agent doesn't suggest next steps. It executes them. Sends emails. Updates records. Moves data between systems. No human clicking approve at every stage.&lt;/p&gt;
    &lt;p&gt;Traditional software processes tasks one at a time when asked. Agents run 24/7, making hundreds of micro-decisions. Remember the Ford dealership chatbot that hallucinated a free truck offer? That's what happens when autonomous systems operate under contracts written for passive tools.&lt;/p&gt;
    &lt;p&gt;Static software behaves the same way every deployment. Agents learn from context, adjust to patterns, change behavior based on accumulated data. The system you shipped six months ago operates differently today.&lt;/p&gt;
    &lt;p&gt;Your SaaS contract wasn't built for any of this.&lt;/p&gt;
    &lt;p&gt;Working with Nick and the GitLaw team, we identified the contract gaps that create the most exposure for agent companies. The new MSA addresses three critical areas:&lt;/p&gt;
    &lt;p&gt;The contract establishes that your agent functions as a sophisticated tool, not an autonomous employee. When a customer's agent books 500 meetings with the wrong prospect list, the answer to "who approved that?" cannot be "the AI decided."&lt;/p&gt;
    &lt;p&gt;It has to be "the customer deployed the agent with these parameters and maintained oversight responsibility."&lt;/p&gt;
    &lt;p&gt;The MSA includes explicit language in Section 1.2 that protects you from liability for autonomous decisions while clarifying customer responsibility.&lt;/p&gt;
    &lt;p&gt;AI agents hallucinate. They produce confident outputs that turn out wrong. The MSA includes explicit disclaimers that agent outputs require human verification before material business decisions.&lt;/p&gt;
    &lt;p&gt;It also includes damage caps appropriate for unpredictable systems. Typically 12 months of fees with exclusions for indirect losses. Not being difficult. Acknowledging you can't predict every edge case in software that learns and adapts.&lt;/p&gt;
    &lt;p&gt;Section 7 covers liability limitations with AI-specific disclaimers about output accuracy in Section 4.1.&lt;/p&gt;
    &lt;p&gt;This kills more deals than any other contract issue. Your agent ingests customer data and generates outputs. You might want to use those interactions to improve your models.&lt;/p&gt;
    &lt;p&gt;Customers panic when they hear that. They imagine their proprietary data training models that help competitors.&lt;/p&gt;
    &lt;p&gt;The MSA establishes that customers own their data and any agent outputs. Then it provides separate, customizable language about using de-identified, aggregated data for training purposes. With clear opt-out options.&lt;/p&gt;
    &lt;p&gt;Most customers accept training use when it's explained clearly. Trying to slip it in through vague language destroys trust.&lt;/p&gt;
    &lt;p&gt;Section 2.1 covers ownership with customizable training permissions in the cover page variables.&lt;/p&gt;
    &lt;p&gt;At Paid, we solve billing and cost tracking for AI agents. But we kept hearing the same problem before companies even got to pricing.&lt;/p&gt;
    &lt;p&gt;Founders would tell us they couldn't figure out how to charge for agents. Then we'd look at their contracts. They were trying to price outcome-based work using terms written for seat-based software.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;"Most AI agent companies are still using SaaS contract language which makes no sense. Your software isn't just sitting there helping someone fill out a form. It's booking meetings, writing code, making decisions. When something goes wrong, who's liable? The standard contracts don't answer that. We kept hearing this from founders, so when GitLaw said they were building an agent-specific MSA, we jumped in. Builders need legal frameworks that match what their agents actually do".&lt;/p&gt;&lt;lb/&gt;Manny Medina, Paid CEO&lt;/quote&gt;
    &lt;p&gt;You can't bill for outcomes if your contract only covers usage. You can't price based on value delivered if your liability framework assumes predictable, passive behavior. You can't protect your margins when the legal foundation doesn't match what your product does.&lt;/p&gt;
    &lt;p&gt;The contract shapes everything that comes after. Get it wrong and your entire business model sits on shaky ground.&lt;/p&gt;
    &lt;p&gt;The MSA is open source and free to use. You can access it directly in the GitLaw Community or ask the GitLaw AI Agent to generate a customized version for your specific needs.&lt;/p&gt;
    &lt;p&gt;Because the law around AI agents is evolving rapidly, treat this as a starting point, not a substitute for legal advice. Work with a commercial lawyer to customize it for your situation.&lt;/p&gt;
    &lt;p&gt;The template uses CommonPaper's Software Licensing Agreement and AI Addendum as a foundation, adapted for the unique characteristics of AI agents.&lt;/p&gt;
    &lt;p&gt;Nick and the GitLaw team built this based on patterns from reviewing hundreds of agent contracts. We contributed our research from working with dozens of agent companies on monetization challenges.&lt;/p&gt;
    &lt;p&gt;Together, we're building the infrastructure the agent economy needs. Legal frameworks that match how agents actually work. Billing systems that align pricing with value delivery. Cost tracking that protects margins.&lt;/p&gt;
    &lt;p&gt;Because agents aren't just another SaaS feature. They're a fundamentally different product category that needs different infrastructure.&lt;/p&gt;
    &lt;p&gt;Legal frameworks always lag behind technology. Right now that lag creates real risk for anyone building agents.&lt;/p&gt;
    &lt;p&gt;You can ignore it and hope nothing breaks. Or you can use contracts built for what agents actually do, not what software did ten years ago.&lt;/p&gt;
    &lt;p&gt;Most founders choose hope. The ones who survive choose better infrastructure - and you'll soon find these MSAs baked into Paid's offering too.&lt;/p&gt;
    &lt;p&gt;→ Read the announcement on GitLaw&lt;/p&gt;
    &lt;p&gt;→ Listen to our conversation with Nick about building legal infrastructure for the agent economy.&lt;/p&gt;
    &lt;p&gt;Join 10,000+ subscribers getting the latest insights on AI monetization.&lt;/p&gt;
    &lt;p&gt;Price smarter. Protect margins. Grow revenue.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45515640</guid><pubDate>Wed, 08 Oct 2025 12:55:01 +0000</pubDate></item><item><title>The email they shouldn't have read</title><link>https://it-notes.dragas.net/2025/10/08/the-email-they-shouldnt-have-read/</link><description>&lt;doc fingerprint="764a911c87a67cf9"&gt;
  &lt;main&gt;
    &lt;p&gt;Author's Note: Before we begin, an important clarification. What follows is a horror story based on real events from my career. However, to protect the privacy of the people and companies involved, I have deliberately mixed things up: technologies, contexts, and specific details have been modified or merged with other experiences. I therefore invite you to read this story not as a strict chronicle of a single event, but as an archetype of a widespread problem in the IT world: vendor lock-in and predatory business practices. Any attempt to identify the specific company or software described would lead to an incorrect conclusion.&lt;/p&gt;
    &lt;p&gt;When the phone rang, I was in a meeting - so I didnât answer. But I recognized the number and sent a quick message:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"Iâm with a client right now. If itâs not urgent, please send me an email - otherwise Iâll call you ASAP".&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The reply, via SMS, left me speechless:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"Thatâs exactly the problem. I canât send you an email. Call me as soon as you can".&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;From that moment on, my perception of a certain kind of world changed forever.&lt;/p&gt;
    &lt;p&gt;A few years earlier, a major public institution - letâs call it Agency A - was still running an ancient Exchange mail server. It hadnât received security updates for ages, the anti-spam was completely ineffective, and the new regulations were clear: embrace Open Source solutions whenever possible.&lt;/p&gt;
    &lt;p&gt;They had already received a proposal - expensive but, when compared to similar offers made to other organizations, apparently reasonable â for a managed service hosted by an external provider and based on an open source mail stack. The company offered a managed version with its own proprietary additions and enterprise support.&lt;/p&gt;
    &lt;p&gt;The catch? While such pricing had become almost "normal" in the market, it was still wildly inflated considering what was actually being delivered. Agency A already had solid infrastructure - reputable IP classes, redundant datacenters, everything running smoothly. We had built and maintained that environment for years, and it was still performing perfectly.&lt;/p&gt;
    &lt;p&gt;The request was simple: âEvaluate this solution, and if itâs suitable, weâll migrate.â. About 500 active mailboxes, roughly the same number of aliases. Manageable, but far from trivial.&lt;/p&gt;
    &lt;p&gt;So I started experimenting. I had heard of that stack before but never used it directly. I deployed it in some non-critical environments - ours, and a few test clients who agreed to try it at a discounted rate. Everything worked flawlessly for almost a year. I began to appreciate its design and flexibility. Confident, I told Agency A we could proceed with a pilot migration.&lt;/p&gt;
    &lt;p&gt;We built a new server, deployed the stack, and assigned a few secondary domains for early adopters. The feedback was great - so good that users started pushing for a full migration.&lt;lb/&gt; The IT team planned carefully: created accounts and aliases, migrated selected mailboxes, and kept the old Exchange server online (hidden, for legacy access).&lt;/p&gt;
    &lt;p&gt;The morning after the MX switch I was tense, waiting for trouble - but it never came. A couple of small questions, nothing serious. The internal team handled everything perfectly. It was a success.&lt;/p&gt;
    &lt;p&gt;Word spread quickly.&lt;/p&gt;
    &lt;p&gt;Agency B - smaller, but in some ways more influential - contacted me. They were customers of the same managed-service company that had pitched to Agency A. Once they saw the potential savings (at less than a tenth of the annual cost), the stability, and the freedom of keeping their data on their own servers, they became very interested. Their contract, however, was a five-year deal with automatic renewal - two years left. The legal office said the notice period was six months, so there was time.&lt;/p&gt;
    &lt;p&gt;They wanted to prepare silently. Their supplier was known for aggressive commercial behavior and often retaliated when customers tried to leave. So we built everything quietly - users, aliases, test setups - and froze the system, waiting for the official termination notice.&lt;/p&gt;
    &lt;p&gt;That day finally came. The notice was sent, about eight months before expiration. Migration would begin upon confirmation of receipt - or the following month at the latest.&lt;/p&gt;
    &lt;p&gt;Meanwhile, I learned that Agency C - another institution - was also planning to leave the same provider. They wanted to keep the same software stack for consistency, so I told them about our experience. They asked for a quote, which I prepared (without mentioning Agency B, of course). My margin would have been small, but the project made sense: it was about owning your data, not making money.&lt;/p&gt;
    &lt;p&gt;Everything seemed to move smoothly - until that SMS.&lt;/p&gt;
    &lt;p&gt;I called back immediately.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;"Thereâs been a problem with the termination" said the IT manager of Agency B.&lt;/p&gt;&lt;lb/&gt;"Somehow they found out what we were doing. There are hidden clauses we didnât know about, and now we canât leave - at least not for another five years. They know everything. Even your quote.".&lt;/quote&gt;
    &lt;p&gt;I was stunned. How could they possibly know?&lt;/p&gt;
    &lt;p&gt;Minutes later, my phone rang again - Agency C this time.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"Forget the proposal", they said. "They called us. Threatened us, actually. They even mentioned your name and said they might take legal action against you for unfair competition - claiming theyâre the only âauthorizedâ installers of that software. Which is absurd, of course. Itâs open source. But our director doesnât want trouble.".&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Sometimes, when public money is involved, people prefer avoiding troubles over doing whatâs right.&lt;/p&gt;
    &lt;p&gt;Something didnât add up.&lt;lb/&gt; Then someone at Agency C noticed a clue: a former interim IT manager still had an email client connected via token authentication - with access to all messages. And that person had signed the original contract with the provider years before. Informally questioned, he admitted contacting them "to warn them" but claimed it was harmless. He never mentioned me - supposedly.&lt;/p&gt;
    &lt;p&gt;That still didnât explain how they knew about Agency Bâs internal steps. To test a theory, we set a trap: I asked a friend abroad to send Agency B a fake quote, from a company outside the EU.&lt;lb/&gt; The following Monday, the provider called Agency B and said, "We advise against working with non-EU companies - compliance can get tricky.".&lt;/p&gt;
    &lt;p&gt;That strongly suggested it: it looked as if they might have been reading the emails.&lt;/p&gt;
    &lt;p&gt;The IT manager exploded and confronted them. The response was chilling:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"Iâm not saying we do - but we could. Itâs in the contract. You should read the fine print, especially the unilateral amendment from two years ago.".&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That amendment, quietly accepted, included horrifying clauses:&lt;lb/&gt; - notice period extended from 6 to 12 months&lt;lb/&gt; - formerly free services could become paid at the providerâs discretion&lt;lb/&gt; - and, "for security reasons", they could disable any access other than the webmail - which they promptly did.&lt;/p&gt;
    &lt;p&gt;All of this happened before the GDPR era, when certain practices could still slip through.&lt;/p&gt;
    &lt;p&gt;I tried to contact the companyâs owner directly - no reply. Calls, emails, nothing. Their support lines were "not authorized to forward requests". I wanted to confront them about the ânot accreditedâ nonsense and the so-called unfair competition. But bullies never like a fair conversation.&lt;/p&gt;
    &lt;p&gt;I urged Agency B and C to investigate - not only legally, but ethically.&lt;lb/&gt; They were horrified, yes - but in the end, nothing changed.&lt;lb/&gt; Worse: the provider, invoking that same contract amendment, made previously free features paid ones, increasing their costs by another 30%.&lt;lb/&gt; Management wasnât outraged by the abuse - just by the extra expense, "hard to justify in the budget".&lt;/p&gt;
    &lt;p&gt;Years later, those directors were gone. The technical staff remained - older, wiser, and determined not to repeat the mistake. They eventually switched providers, though to something "safer", not necessarily better.&lt;/p&gt;
    &lt;p&gt;I couldnât solve that problem. The battle had to come from them, and I would have supported them all the way - not for profit, but for principle.&lt;lb/&gt; Because when a company that claims to âsupport open sourceâ behaves like that, we all lose.&lt;lb/&gt; We all get labeled the same way.&lt;/p&gt;
    &lt;p&gt;And thatâs the real horror of the story - not the software, but what people do with it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45515657</guid><pubDate>Wed, 08 Oct 2025 12:56:54 +0000</pubDate></item><item><title>The weaponization of travel blacklists</title><link>https://papersplease.org/wp/2025/10/06/the-weaponization-of-travel-blacklists/</link><description>&lt;doc fingerprint="7712fb12443571b9"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;The weaponization of travel blacklists&lt;/head&gt;&lt;p&gt;Coming just hours before the partial shutdown of Federal government operations, this hearing was sparsely attended, even by members of the committee, and got little press attention. The hearing opened with the Chair and Ranking Minority Member of the committee talking over each other at length.&lt;/p&gt;&lt;p&gt;Much of the argument between Senators and the questioning of witnesses focused not on the general problems of the Quiet Skies traveler surveillance program program or government travel blacklists (referred to euphemistically as “watchlists” throughout the hearing) but on whether these programs have been weaponized to a greater extent under Democratic or Republican administrations.&lt;/p&gt;&lt;p&gt;But if we — and, we hope, members of Congress — can look past the partisan polemics, the testimony and documents introduced into the record of this hearing provide important guidance on what can and should be done to protect all travelers — regardless of our party affiliation (if any), ethnicity, religious beliefs, or political opinions — against the weaponization of travel blacklists by whatever government is in power.&lt;/p&gt;&lt;p&gt;The Quiet Skies [sic] program assigned officers from the Federal Air Marshals Service (one of the police agencies within the Transportation Security Administration) to accompany and surveil pre-selected airline passengers on flights and in airports.&lt;/p&gt;&lt;p&gt;Quiet Skies is just one of many travel surveillance and blacklisting programs. According to another report by the same Senate committee last yea (under a chair from the opposite side of the aisle), “There are at least 22 different mechanisms that might lead Americans to receive additional screening at airports and other ports of entry or be denied the ability to travel.”&lt;/p&gt;&lt;p&gt;According to precious whistleblower reports and documents obtained by the Senate HSGAC Committee and entered into the record of the hearing last week, Quite Skies targets were selected by a ruleset that incorporated other US government blacklists and watchlists as well as profile-based rules that factored in ethnicity and countries previously visited.&lt;/p&gt;Targets of blacklisting and watchlisting have ranged from people selected based on having used a credit card at a Washington-area airport on or around January 6, 2021, to critics of Israel’s military actions in Gaza, among other activities protected by the First Amendment.&lt;p&gt;The Quiet Skies program was ended in June 2025 by the Secretary of Homeland Security, Kristi Noehm. The same day as the Senate hearing on Quiet Skies last week, the TSA announced that Secretary Noehm was firing five senior TSA officials associated with the Quite Skies program, including the TSA’s executive assistant administrator for operations support and the deputy assistant administrator for intelligence and analysis.&lt;/p&gt;&lt;p&gt;News reports, presumably based on DHS statements, described Quiet Skies as a “Biden-era” program even though its largest expansion came in 2018 during the first Trump administration. And according to the TSA’s press release last week:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;The TSA administrator has legal authority to prevent an individual from boarding an aircraft, task Federal Air Marshals with surveilling an individual, or place them on a watchlist, but it is only intended to be used to track and prevent dangerous criminals and terrorists from carrying out attacks on Americans.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;We question whether the TSA Administrator has the authority to prevent someone from traveling by common carrier without getting an order from a judge. And the TSA and DHS have consistently asserted authority and exercised power — legally or not — to blacklist and surveil travelers without needing any suspicion of criminality.&lt;/p&gt;&lt;p&gt;The bipartisanship of violations of the right to travel through blacklisting and watchlisting was brought out in the response of Mr. Abed Ayoub, Executive Director of the American-Arab Anti-Discrimination Committee (ADC) to one of the Senators’ questions about the weaponization of watchlists and blacklists against disfavored groups and individuals:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;That’s not a partisan problem. That’s a due process problem. When the government can quietly tag one group, it can quietly tag any group, left, right, neither, just depending on who holds power. The answer is the same for all of us: end the watchlists….&lt;/p&gt;&lt;p&gt;Quiet Skies captures only part of the story. It’s a window into a faulty surveillance architecture. The watchlist isn’t about who you vote for. It’s about whether the government has to prove its case when it takes away your rights….&lt;/p&gt;&lt;p&gt;Our community, for the past quarter of a century, we’re… targeted by all the administrations, so we can tell you the experience under Republican and Democratic administrations.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Further guidance about what Congress can and should do was provided by another of the witnesses, Mr. Jim Harper, a Senior Nonresident Fellow of the American Enterprise Institute:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;We intuitively feel we have the right to travel, and there are cases from the Supreme Court that say you have a right to travel: You can move from one state to another and they can’t deny you Welfare benefits when you get there.&lt;/p&gt;&lt;p&gt;There are other cases: A man in San Francisco wanted to fly to Washington, DC, to meet with his Representative, and the 9th Circuit Court of Appeals said that you don’t have a right to travel on your preferred mode of transportation. They said, no, you can take the train, you can drive, if you want to go to Washington, DC.&lt;/p&gt;&lt;p&gt;A clear right to travel — Americans believe they have it, but the courts haven’t accorded it to them — would give them a position when they went to court.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Court cases challenging the no-fly list (ongoing since 2013, and now on remand following a unanimous favorable Supreme Court decision in 2024) and other travel blacklists and watchlists (ongoing since 2018) have been dragged out for years by the government. The government continues to claim that “merely” being delayed for a few hours or days isn’t sufficiently harmful to a traveler’s rights to provide a basis for a lawsuit.&lt;/p&gt;&lt;p&gt;The Freedom to Travel Act that was introduced in 2021 in the House of Representatives would provide both an explicit statutory right to travel by common carrier and a cause of action for violations of that right by government agencies, carriers, or other entities.&lt;/p&gt;&lt;p&gt;We hope Senators and Representatives moved to act on the issues raised in last week’s hearing on the TSA will re-introduce and co-sponsor the Freedom to Travel Act in this session of Congress, hold committee hearings on it, and incorporate it into appropriate omnibus legislation that has a better chance of passage than a standalone bill.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45515783</guid><pubDate>Wed, 08 Oct 2025 13:10:19 +0000</pubDate></item><item><title>We found a bug in Go's ARM64 compiler</title><link>https://blog.cloudflare.com/how-we-found-a-bug-in-gos-arm64-compiler/</link><description>&lt;doc fingerprint="3b06c011ce263a54"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Every second, 84 million HTTP requests are hitting Cloudflare across our fleet of data centers in 330 cities. It means that even the rarest of bugs can show up frequently. In fact, it was our scale that recently led us to discover a bug in Go's arm64 compiler which causes a race condition in the generated code.&lt;/p&gt;
      &lt;p&gt;This post breaks down how we first encountered the bug, investigated it, and ultimately drove to the root cause.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;Investigating a strange panic&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;We run a service in our network which configures the kernel to handle traffic for some products like Magic Transit and Magic WAN. Our monitoring watches this closely, and it started to observe very sporadic panics on arm64 machines.&lt;/p&gt;
      &lt;p&gt;We first saw one with a fatal error stating that traceback did not unwind completely. That error suggests that invariants were violated when traversing the stack, likely because of stack corruption. After a brief investigation we decided that it was probably rare stack memory corruption. This was a largely idle control plane service where unplanned restarts have negligible impact, and so we felt that following up was not a priority unless it kept happening.&lt;/p&gt;
      &lt;p&gt;And then it kept happening.Â &lt;/p&gt;
      &lt;p&gt;When we first saw this bug we saw that the fatal errors correlated with recovered panics. These were caused by some old code which used panic/recover as error handling.Â &lt;/p&gt;
      &lt;p&gt;At this point, our theory was:Â &lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;All of the fatal panics happen within stack unwinding.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;We correlated an increased volume of recovered panics with these fatal panics.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Recovering a panic unwinds goroutine stacks to call deferred functions.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;A related Go issue (#73259) reported an arm64 stack unwinding crash.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Letâs stop using panic/recover for error handling and wait out the upstream fix?&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;So we did that and watched as fatal panics stopped occurring as the release rolled out. Fatal panics gone, our theoretical mitigation seemed to work, and this was no longer our problem. We subscribed to the upstream issue so we could update when it was resolved and put it out of our minds.&lt;/p&gt;
      &lt;p&gt;But, this turned out to be a much stranger bug than expected. Putting it out of our minds was premature as the same class of fatal panics came back at a much higher rate. A month later, we were seeing up to 30 daily fatal panics with no real discernible cause; while that might account for only one machine a day in less than 10% of our data centers, we found it concerning that we didnât understand the cause. The first thing we checked was the number of recovered panics, to match our previous pattern, but there were none. More interestingly, we could not correlate this increased rate of fatal panics with anything. A release? Infrastructure changes? The position of Mars? &lt;/p&gt;
      &lt;p&gt;At this point we felt like we needed to dive deeper to better understand the root cause. Pattern matching and hoping was clearly insufficient.Â &lt;/p&gt;
      &lt;p&gt;We saw two classes of this bug -- a crash while accessing invalid memory and an explicitly checked fatal error.Â &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;goroutine 153 gp=0x4000105340 m=324 mp=0x400639ea08 [GC worker (active)]:
/usr/local/go/src/runtime/asm_arm64.s:244 +0x6c fp=0x7ff97fffe870 sp=0x7ff97fffe860 pc=0x55558d4098fc
runtime.systemstack(0x0)
       /usr/local/go/src/runtime/mgc.go:1508 +0x68 fp=0x7ff97fffe860 sp=0x7ff97fffe810 pc=0x55558d3a9408
runtime.gcBgMarkWorker.func2()
       /usr/local/go/src/runtime/mgcmark.go:1102
runtime.gcDrainMarkWorkerIdle(...)
       /usr/local/go/src/runtime/mgcmark.go:1188 +0x434 fp=0x7ff97fffe810 sp=0x7ff97fffe7a0 pc=0x55558d3ad514
runtime.gcDrain(0x400005bc50, 0x7)
       /usr/local/go/src/runtime/mgcmark.go:212 +0x1c8 fp=0x7ff97fffe7a0 sp=0x7ff97fffe6f0 pc=0x55558d3ab248
runtime.markroot(0x400005bc50, 0x17e6, 0x1)
       /usr/local/go/src/runtime/mgcmark.go:238 +0xa8 fp=0x7ff97fffe6f0 sp=0x7ff97fffe6a0 pc=0x55558d3ab578
runtime.markroot.func1()
       /usr/local/go/src/runtime/mgcmark.go:887 +0x290 fp=0x7ff97fffe6a0 sp=0x7ff97fffe560 pc=0x55558d3acaa0
runtime.scanstack(0x4014494380, 0x400005bc50)
       /usr/local/go/src/runtime/traceback.go:447 +0x2ac fp=0x7ff97fffe560 sp=0x7ff97fffe4d0 pc=0x55558d3eeb7c
runtime.(*unwinder).next(0x7ff97fffe5b0?)
       /usr/local/go/src/runtime/traceback.go:566 +0x110 fp=0x7ff97fffe4d0 sp=0x7ff97fffe490 pc=0x55558d3eed40
runtime.(*unwinder).finishInternal(0x7ff97fffe4f8?)
       /usr/local/go/src/runtime/panic.go:1073 +0x38 fp=0x7ff97fffe490 sp=0x7ff97fffe460 pc=0x55558d403388
runtime.throw({0x55558de6aa27?, 0x7ff97fffe638?})
runtime stack:
fatal error: traceback did not unwind completely
       stack=[0x4015d6a000-0x4015d8a000
runtime: g8221077: frame.sp=0x4015d784c0 top=0x4015d89fd0&lt;/code&gt;
      &lt;/quote&gt;
      &lt;quote&gt;
        &lt;code&gt;goroutine 187 gp=0x40003aea80 m=13 mp=0x40003ca008 [GC worker (active)]:
       /usr/local/go/src/runtime/asm_arm64.s:244 +0x6c fp=0x7fff2afde870 sp=0x7fff2afde860 pc=0x55557e2d98fc
runtime.systemstack(0x0)
       /usr/local/go/src/runtime/mgc.go:1489 +0x94 fp=0x7fff2afde860 sp=0x7fff2afde810 pc=0x55557e279434
runtime.gcBgMarkWorker.func2()
       /usr/local/go/src/runtime/mgcmark.go:1112
runtime.gcDrainMarkWorkerDedicated(...)
       /usr/local/go/src/runtime/mgcmark.go:1188 +0x434 fp=0x7fff2afde810 sp=0x7fff2afde7a0 pc=0x55557e27d514
runtime.gcDrain(0x4000059750, 0x3)
       /usr/local/go/src/runtime/mgcmark.go:212 +0x1c8 fp=0x7fff2afde7a0 sp=0x7fff2afde6f0 pc=0x55557e27b248
runtime.markroot(0x4000059750, 0xb8, 0x1)
       /usr/local/go/src/runtime/mgcmark.go:238 +0xa8 fp=0x7fff2afde6f0 sp=0x7fff2afde6a0 pc=0x55557e27b578
runtime.markroot.func1()
       /usr/local/go/src/runtime/mgcmark.go:887 +0x290 fp=0x7fff2afde6a0 sp=0x7fff2afde560 pc=0x55557e27caa0
runtime.scanstack(0x40042cc000, 0x4000059750)
       /usr/local/go/src/runtime/traceback.go:458 +0x188 fp=0x7fff2afde560 sp=0x7fff2afde4d0 pc=0x55557e2bea58
runtime.(*unwinder).next(0x7fff2afde5b0)
goroutine 0 gp=0x40003af880 m=13 mp=0x40003ca008 [idle]:
PC=0x55557e2bea58 m=13 sigcode=1 addr=0x118
SIGSEGV: segmentation violation&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;Now we could observe some clear patterns. Both errors occur when unwinding the stack in &lt;code&gt;(*unwinder).next&lt;/code&gt;. In one case we saw an intentional fatal error as the runtime identified that unwinding could not complete and the stack was in a bad state. In the other case there was a direct memory access error that happened while trying to unwind the stack. The segfault was discussed in the GitHub issue and a Go engineer identified it as dereference of a go scheduler struct, m, when unwinding.Â   &lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;A review of Go scheduler structs&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Go uses a lightweight userspace scheduler to manage concurrency. Many goroutines are scheduled on a smaller number of kernel threads â this is often referred to as M:N scheduling. Any individual goroutine can be scheduled on any kernel thread. The scheduler has three core types â &lt;code&gt;g&lt;/code&gt;Â  (the goroutine), &lt;code&gt;m&lt;/code&gt; (the kernel thread, or âmachineâ), and &lt;code&gt;p&lt;/code&gt; (the physical execution context, orÂ  âprocessorâ). For a goroutine to be scheduled a free &lt;code&gt;m&lt;/code&gt; must acquire a free &lt;code&gt;p&lt;/code&gt;, which will execute a g. Each &lt;code&gt;g&lt;/code&gt; contains a field for its m if it is currently running, otherwise it will be nil. This is all the context needed for this post but the go runtime docs explore this more comprehensively.Â &lt;/p&gt;
      &lt;p&gt;At this point we can start to make inferences on whatâs happening: the program crashes because we try to unwind a goroutine stack which is invalid. In the first backtrace, if a return address is null, we call &lt;code&gt;finishInternal&lt;/code&gt; and abort because the stack was not fully unwound. The segmentation fault case in the second backtrace is a bit more interesting: if instead the return address is non-zero but not a function then the unwinder code assumes that the goroutine is currently running. It'll then dereference m and fault by accessing &lt;code&gt;m.incgo&lt;/code&gt; (the offset of &lt;code&gt;incgo&lt;/code&gt; into &lt;code&gt;struct m&lt;/code&gt; is 0x118, the faulting memory access). &lt;/p&gt;
      &lt;p&gt;What, then, is causing this corruption? The traces were difficult to get anything useful from â our service has hundreds if not thousands of active goroutines. It was fairly clear from the beginning that the panic was remote from the actual bug. The crashes were all observed while unwinding the stack and if this were an issue any time the stack was unwound on arm64 we would be seeing it in many more services. We felt pretty confident that the stack unwinding was happening correctly but on an invalid stack.Â &lt;/p&gt;
      &lt;p&gt;Our investigation stalled for a while at this point â making guesses, testing guesses, trying to infer if the panic rate went up or down, or if nothing changed. There was a known issue on Goâs GitHub issue tracker which matched our symptoms almost exactly, but what they discussed was mostly what we already knew. At some point when looking through the linked stack traces we realized that their crash referenced an old version of a library that we were also using â Go Netlink.&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;goroutine 1267 gp=0x4002a8ea80 m=nil [runnable (scan)]:
runtime.asyncPreempt2()
        /usr/local/go/src/runtime/preempt.go:308 +0x3c fp=0x4004cec4c0 sp=0x4004cec4a0 pc=0x46353c
runtime.asyncPreempt()
        /usr/local/go/src/runtime/preempt_arm64.s:47 +0x9c fp=0x4004cec6b0 sp=0x4004cec4c0 pc=0x4a6a8c
github.com/vishvananda/netlink/nl.(*NetlinkSocket).Receive(0x14360300000000?)
        /go/pkg/mod/github.com/!data!dog/[email protected]/nl/nl_linux.go:803 +0x130 fp=0x4004cfc710 sp=0x4004cec6c0 pc=0xf95de0
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;We spot-checked a few stack traces and confirmed the presence of this Netlink library. Querying our logs showed that not only did we share a library â every single segmentation fault we observed had happened while preempting &lt;code&gt;NetlinkSocket.Receive&lt;/code&gt;.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Whatâs (async) preemption?&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;In the prehistoric era of Go (&amp;lt;=1.13) the runtime was cooperatively scheduled. A goroutine would run until it decided it was ready to yield to the scheduler â usually due to explicit calls to &lt;code&gt;runtime.Gosched()&lt;/code&gt; or injected yield points at function calls/IO operations. Since Go 1.14 the runtime instead does async preemption. The Go runtime has a thread &lt;code&gt;sysmon&lt;/code&gt; which tracks the runtime of goroutines and will preempt any that run for longer than 10ms (at time of writing). It does this by sending &lt;code&gt;SIGURG&lt;/code&gt; to the OS thread and in the signal handler will modify the program counter and stack to mimic a call to &lt;code&gt;asyncPreempt&lt;/code&gt;.&lt;/p&gt;
      &lt;p&gt;At this point we had two broad theories:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;
          &lt;p&gt;This is a Go Netlink bug â likely due to &lt;code&gt;unsafe.Pointer&lt;/code&gt; usage which invoked undefined behavior but is only actually broken on arm64&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;This is a Go runtime bug and we're only triggering it in &lt;code&gt;NetlinkSocket.Receive&lt;/code&gt; for some reason&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;After finding the same bug publicly reported upstream, we were feeling confident this was caused by a Go runtime bug. However, upon seeing that both issues implicated the same function, we felt more skeptical â notably the Go Netlink library uses unsafe.Pointer so memory corruption was a plausible explanation even if we didn't understand why.&lt;/p&gt;
      &lt;p&gt;After an unsuccessful code audit we had hit a wall. The crashes were rare and remote from the root cause. Maybe these crashes were caused by a runtime bug, maybe they were caused by a Go Netlink bug. It seemed clear that there was something wrong with this area of the code, but code auditing wasnât going anywhere. &lt;/p&gt;
      &lt;p&gt;At this point we had a fairly good understanding of what was crashing but very little understanding of why it was happening. It was clear that the root cause of the stack unwinder crashing was remote from the actual crash, and that it had to do with &lt;code&gt;(*NetlinkSocket).Receive&lt;/code&gt;, but why? We were able to capture a coredump of a production crash and view it in a debugger. The backtrace confirmed what we already knew â that there was a segmentation fault when unwinding a stack. The crux of the issue revealed itself when we looked at the goroutine which had been preempted while calling &lt;code&gt;(*NetlinkSocket).Receive&lt;/code&gt;.Â     &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;(dlv) bt
0  0x0000555577579dec in runtime.asyncPreempt2
   at /usr/local/go/src/runtime/preempt.go:306
1  0x00005555775bc94c in runtime.asyncPreempt
   at /usr/local/go/src/runtime/preempt_arm64.s:47
2  0x0000555577cb2880 in github.com/vishvananda/netlink/nl.(*NetlinkSocket).Receive
   at
/vendor/github.com/vishvananda/netlink/nl/nl_linux.go:779
3  0x0000555577cb19a8 in github.com/vishvananda/netlink/nl.(*NetlinkRequest).Execute
   at 
/vendor/github.com/vishvananda/netlink/nl/nl_linux.go:532
4  0x0000555577551124 in runtime.heapSetType
   at /usr/local/go/src/runtime/mbitmap.go:714
5  0x0000555577551124 in runtime.heapSetType
   at /usr/local/go/src/runtime/mbitmap.go:714
...
(dlv) disass -a 0x555577cb2878 0x555577cb2888
TEXT github.com/vishvananda/netlink/nl.(*NetlinkSocket).Receive(SB) /vendor/github.com/vishvananda/netlink/nl/nl_linux.go
        nl_linux.go:779 0x555577cb2878  fdfb7fa9        LDP -8(RSP), (R29, R30)
        nl_linux.go:779 0x555577cb287c  ff430191        ADD $80, RSP, RSP
        nl_linux.go:779 0x555577cb2880  ff434091        ADD $(16&amp;lt;&amp;lt;12), RSP, RSP
        nl_linux.go:779 0x555577cb2884  c0035fd6        RET
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;The goroutine was paused between two opcodes in the function epilogue. Since the process of unwinding a stack relies on the stack frame being in a consistent state, it felt immediately suspicious that we preempted in the middle of adjusting the stack pointer. The goroutine had been paused at 0x555577cb2880, between&lt;code&gt; ADD $80, RSP, RSP and ADD $(16&amp;lt;&amp;lt;12), RSP, RSP&lt;/code&gt;.Â &lt;/p&gt;
      &lt;p&gt;We queried the service logs to confirm our theory. This wasnât isolated â the majority of stack traces showed that this same opcode was preempted. This was no longer a weird production crash we couldnât reproduce. A crash happened when the Go runtime preempted between these two stack pointer adjustments. We had our smoking gun.Â &lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;Building a minimal reproducer&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;At this point we felt pretty confident that this was actually just a runtime bug and it should be reproducible in an isolated environment without any dependencies. The theory at this point was:&lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;Stack unwinding is triggered by garbage collection&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Async preemption between a split stack pointer adjustment causes a crash&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;What if we make a function which splits the adjustment and then call it in a loop?&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;quote&gt;
        &lt;code&gt;package main

import (
	"runtime"
)

//go:noinline
func big_stack(val int) int {
	var big_buffer = make([]byte, 1 &amp;lt;&amp;lt; 16)

	sum := 0
	// prevent the compiler from optimizing out the stack
	for i := 0; i &amp;lt; (1&amp;lt;&amp;lt;16); i++ {
		big_buffer[i] = byte(val)
	}
	for i := 0; i &amp;lt; (1&amp;lt;&amp;lt;16); i++ {
		sum ^= int(big_buffer[i])
	}
	return sum
}

func main() {
	go func() {
		for {
			runtime.GC()
		}
	}()
	for {
		_ = big_stack(1000)
	}
}
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;This function ends up with a stack frame slightly larger than can be represented in 16 bits, and so on arm64 the Go compiler will split the stack pointer adjustment into two opcodes. If the runtime preempts between these opcodes then the stack unwinder will read an invalid stack pointer and crash.Â &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;; epilogue for main.big_stack
ADD $8, RSP, R29
ADD $(16&amp;lt;&amp;lt;12), R29, R29
ADD $16, RSP, RSP
; preemption is problematic between these opcodes
ADD $(16&amp;lt;&amp;lt;12), RSP, RSP
RET
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;After running this for a few minutes the program panicked as expected!&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;SIGSEGV: segmentation violation
PC=0x60598 m=8 sigcode=1 addr=0x118

goroutine 0 gp=0x400019c540 m=8 mp=0x4000198708 [idle]:
runtime.(*unwinder).next(0x400030fd10)
        /home/thea/sdk/go1.23.4/src/runtime/traceback.go:458 +0x188 fp=0x400030fcc0 sp=0x400030fc30 pc=0x60598
runtime.scanstack(0x40000021c0, 0x400002f750)
        /home/thea/sdk/go1.23.4/src/runtime/mgcmark.go:887 +0x290 

[...]

goroutine 1 gp=0x40000021c0 m=nil [runnable (scan)]:
runtime.asyncPreempt2()
        /home/thea/sdk/go1.23.4/src/runtime/preempt.go:308 +0x3c fp=0x40003bfcf0 sp=0x40003bfcd0 pc=0x400cc
runtime.asyncPreempt()
        /home/thea/sdk/go1.23.4/src/runtime/preempt_arm64.s:47 +0x9c fp=0x40003bfee0 sp=0x40003bfcf0 pc=0x75aec
main.big_stack(0x40003cff38?)
        /home/thea/dev/stack_corruption_reproducer/main.go:29 +0x94 fp=0x40003cff00 sp=0x40003bfef0 pc=0x77c04
Segmentation fault (core dumped)

real    1m29.165s
user    4m4.987s
sys     0m43.212s&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;A reproducible crash with standard library only? This felt like conclusive evidence that our problem was a runtime bug.&lt;/p&gt;
      &lt;p&gt;This was an extremely particular reproducer! Even now with a good understanding of the bug and its fix, some of the behavior is still puzzling. It's a one-instruction race condition, so itâs unsurprising that small changes could have large impact. For example, this reproducer was originally written and tested on Go 1.23.4, but did not crash when compiled with 1.23.9 (the version in production), even though we could objdump the binary and see the split ADD still present! We donât have a definite explanation for this behavior â even with the bug present there remain a few unknown variables which affect the likelihood of hitting the race condition.Â &lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;A single-instruction race condition window&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;arm64 is a fixed-length 4-byte instruction set architecture. This has a lot of implications on codegen but most relevant to this bug is the fact that immediate length is limited. &lt;code&gt;add&lt;/code&gt; gets a 12-bit immediate, &lt;code&gt;mov&lt;/code&gt; gets a 16-bit immediate, etc. How does the architecture handle this when the operands don't fit? It depends â &lt;code&gt;ADD&lt;/code&gt; in particular reserves a bit for "shift left by 12" so any 24 bit addition can be decomposed into two opcodes. Other instructions are decomposed similarly, or just require loading an immediate into a register first.Â &lt;/p&gt;
      &lt;p&gt;The very last step of the Go compiler before emitting machine code involves transforming the program into &lt;code&gt;obj.Prog&lt;/code&gt; structs. It's a very low level intermediate representation (IR) that mostly serves to be translated into machine code.Â &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;//https://github.com/golang/go/blob/fa2bb342d7b0024440d996c2d6d6778b7a5e0247/src/cmd/internal/obj/arm64/obj7.go#L856

// Pop stack frame.
// ADD $framesize, RSP, RSP
p = obj.Appendp(p, c.newprog)
p.As = AADD
p.From.Type = obj.TYPE_CONST
p.From.Offset = int64(c.autosize)
p.To.Type = obj.TYPE_REG
p.To.Reg = REGSP
p.Spadj = -c.autosize
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;Notably, this IR is not aware of immediate length limitations. Instead, this happens in asm7.go when Go's internal intermediate representation is translated into arm64 machine code. The assembler will classify an immediate in conclass based on bit size and then use that when emitting instructions â extra if needed.&lt;/p&gt;
      &lt;p&gt;The Go assembler uses a combination of (&lt;code&gt;mov, add&lt;/code&gt;) opcodes for some adds that fit in 16-bit immediates, and prefers (&lt;code&gt;add, add + lsl 12&lt;/code&gt;) opcodes for 16-bit+ immediates.Â   &lt;/p&gt;
      &lt;p&gt;Compare a stack of (slightly larger than) &lt;code&gt;1&amp;lt;&amp;lt;15&lt;/code&gt;:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;; //go:noinline
; func big_stack() byte {
; 	var big_stack = make([]byte, 1&amp;lt;&amp;lt;15)
; 	return big_stack[0]
; }
MOVD $32776, R27
ADD R27, RSP, R29
MOVD $32784, R27
ADD R27, RSP, RSP
RET
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;With a stack of &lt;code&gt;1&amp;lt;&amp;lt;16&lt;/code&gt;:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;; //go:noinline
; func big_stack() byte {
; 	var big_stack = make([]byte, 1&amp;lt;&amp;lt;16)
; 	return big_stack[0]
; } 
ADD $8, RSP, R29
ADD $(16&amp;lt;&amp;lt;12), R29, R29
ADD $16, RSP, RSP
ADD $(16&amp;lt;&amp;lt;12), RSP, RSP
RET
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;In the larger stack case, there is a point between &lt;code&gt;ADD x, RSP, RSP&lt;/code&gt; opcodes where the stack pointer is not pointing to the tip of a stack frame. We thought at first that this was a matter of memory corruption â that in handling async preemption the runtime would push a function call on the stack and corrupt the middle of the stack. However, this goroutine is already in the function epilogue â any data we corrupt is actively in the process of being thrown away. What's the issue then?  &lt;/p&gt;
      &lt;p&gt;The Go runtime often needs to unwind the stack, which means walking backwards through the chain of function calls. For example: garbage collection uses it to find live references on the stack, panicking relies on it to evaluate &lt;code&gt;defer&lt;/code&gt; functions, and generating stack traces needs to print the call stack. For this to work the stack pointer must be accurate during unwinding because of how golang dereferences sp to determine the calling function. If the stack pointer is partially modified, the unwinder will look for the calling function in the middle of the stack. The underlying data is meaningless when interpreted as directions to a parent stack frame and then the runtime will likely crash.Â &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;//https://github.com/golang/go/blob/66536242fce34787230c42078a7bbd373ef8dcb0/src/runtime/traceback.go#L373

if innermost &amp;amp;&amp;amp; frame.sp &amp;lt; frame.fp || frame.lr == 0 {
    lrPtr = frame.sp
    frame.lr = *(*uintptr)(unsafe.Pointer(lrPtr))
}
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;When async preemption happens it will push a function call onto the stack but the parent stack frame is no longer correct because sp was only partially adjusted when the preemption happened. The crash flow looks something like this: &lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;Async preemption happens between the two opcodes that &lt;code&gt;add x, rsp&lt;/code&gt; expands to&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Garbage collection triggers stack unwinding (to check for heap object liveness)&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;The unwinder starts traversing the stack of the problematic goroutine and correctly unwinds up to the problematic function&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;The unwinder dereferences &lt;code&gt;sp&lt;/code&gt; to determine the parent function&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Almost certainly the data behind &lt;code&gt;sp&lt;/code&gt; is not a function&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Crash&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;We saw earlier a faulting stack trace which ended in &lt;code&gt;(*NetlinkSocket).Receive&lt;/code&gt; â in this case stack unwinding faulted while it was trying to determine the parent frame.Â    &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;goroutine 90 gp=0x40042cc000 m=nil [preempted (scan)]:
runtime.asyncPreempt2()
/usr/local/go/src/runtime/preempt.go:306 +0x2c fp=0x40060a25d0 sp=0x40060a25b0 pc=0x55557e299dec
runtime.asyncPreempt()
/usr/local/go/src/runtime/preempt_arm64.s:47 +0x9c fp=0x40060a27c0 sp=0x40060a25d0 pc=0x55557e2dc94c
github.com/vishvananda/netlink/nl.(*NetlinkSocket).Receive(0xff48ce6e060b2848?)
/vendor/github.com/vishvananda/netlink/nl/nl_linux.go:779 +0x130 fp=0x40060b2820 sp=0x40060a27d0 pc=0x55557e9d2880
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;Once we discovered the root cause we reported it with a reproducer and the bug was quickly fixed. This bug is fixed in go1.23.12, go1.24.6, and go1.25.0. Previously, the go compiler emitted a single &lt;code&gt;add x, rsp&lt;/code&gt; instruction and relied on the assembler to split immediates into multiple opcodes as necessary. After this change, stacks larger than 1&amp;lt;&amp;lt;12 will build the offset in a temporary register and then add that to &lt;code&gt;rsp&lt;/code&gt; in a single, indivisible opcode. A goroutine can be preempted before or after the stack pointer modification, but never during. This means that the stack pointer is always valid and there is no race condition.&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;LDP -8(RSP), (R29, R30)
MOVD $32, R27
MOVK $(1&amp;lt;&amp;lt;16), R27
ADD R27, RSP, RSP
RET&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;This was a very fun problem to debug. We donât often see bugs where you can accurately blame the compiler. Debugging it took weeks and we had to learn about areas of the Go runtime that people donât usually need to think about. Itâs a nice example of a rare race condition, the sort of bug that can only really be quantified at a large scale.&lt;/p&gt;
      &lt;p&gt;Weâre always looking for people who enjoy this kind of detective work. Our engineering teams are hiring. &lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45516000</guid><pubDate>Wed, 08 Oct 2025 13:33:15 +0000</pubDate></item><item><title>Show HN: CodingFox – Open-Source AI Code Review Tool That Works Like Magic</title><link>https://github.com/furudo-erika/codingfox</link><description>&lt;doc fingerprint="8f06b01d89b48b82"&gt;
  &lt;main&gt;
    &lt;code&gt;                                        ████                                
                                    ████▒▒██                                
                                  ████  ▒▒██                                
                                ██▒▒  ▒▒▒▒▒▒██                              
                              ██▒▒██        ██                              
  ████                      ██▒▒██          ██                              
██▒▒▒▒██████                ██▒▒██      ▒▒  ████                            
██▒▒▒▒██    ████      ██████▒▒▒▒▒▒██    ▒▒▒▒██████████████                  
██▒▒    ████▒▒▒▒██████▒▒▒▒▒▒▒▒▒▒▒▒▒▒██▒▒▒▒▒▒██▒▒▒▒▒▒▒▒▒▒▒▒████              
██▒▒▒▒      ██▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒██▒▒██▒▒▒▒▒▒▒▒▒▒▒▒▒▒██            
  ██▒▒      ██▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒██▒▒██▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒████        
  ██        ██▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒██▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒██      
  ██▒▒    ██▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒████▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒██    
  ██▒▒▒▒  ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒  ██▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒██    
    ██▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒    ██▒▒▒▒▒▒▒▒▒▒████▒▒▒▒▒▒▒▒██  
    ████▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒██      ██▒▒▒▒▒▒████▒▒▒▒▒▒▒▒▒▒▒▒██  
    ██▒▒██▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒██        ██▒▒▒▒██▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒██  
      ██▒▒██▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒██        ██████▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒██  
      ██▒▒██▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒██      ██▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒██
        ████  ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒    ██▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒██
          ██    ▒▒██████▒▒▒▒▒▒▒▒▒▒▒▒▒▒    ██▒▒  ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒██
          ██            ████▒▒▒▒▒▒▒▒▒▒    ██  ▒▒  ▒▒        ▒▒▒▒▒▒▒▒▒▒▒▒██  
            ██                      ██  ████  ▒▒          ▒▒▒▒▒▒▒▒▒▒▒▒▒▒██  
              ██                      ██▒▒██              ▒▒  ▒▒▒▒▒▒▒▒▒▒██  
                ██████████████████████▒▒▒▒██                    ▒▒▒▒▒▒██    
                      ██▒▒      ██▒▒▒▒▒▒▒▒██                    ▒▒▒▒██      
                      ██▒▒▒▒  ██▒▒▒▒▒▒▒▒████                  ▒▒▒▒██        
                      ██▒▒▒▒▒▒██▒▒▒▒▒▒██  ██                    ██          
                        ██████▒▒▒▒▒▒██    ██                ████            
                              ██████      ██          ██████                
                                            ██    ████                      
                                            ██████                                   

                        CodingFox - Your AI Code Review Partner
                        Stop shipping bugs. Start shipping excellence.
&lt;/code&gt;
    &lt;p&gt;CodingFox is an intelligent AI-powered code review assistant that revolutionizes your pull request workflow. Using advanced language models (GPT-3.5 Turbo and GPT-4), CodingFox provides instant, contextual code reviews that catch bugs, improve code quality, and accelerate your development cycle.&lt;/p&gt;
    &lt;code&gt;    ╔═══════════════════════════════════════════╗
    ║   🦊 CodingFox AI Code Reviews            ║
    ║   ─────────────────────────────          ║
    ║   ✓ Instant PR Analysis                  ║
    ║   ✓ Line-by-Line Suggestions             ║
    ║   ✓ Bug Detection &amp;amp; Prevention           ║
    ║   ✓ Code Quality Enhancement             ║
    ╚═══════════════════════════════════════════╝
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;⚡ Lightning-Fast Reviews: Get comprehensive code reviews in seconds, not hours&lt;/item&gt;
      &lt;item&gt;🎯 Context-Aware Analysis: Understands your codebase and provides relevant suggestions&lt;/item&gt;
      &lt;item&gt;🛡️ Bug Prevention: Catches potential issues before they reach production&lt;/item&gt;
      &lt;item&gt;💡 Smart Suggestions: Offers actionable improvements, not just criticism&lt;/item&gt;
      &lt;item&gt;🔄 Continuous Learning: Improves with every review based on your feedback&lt;/item&gt;
      &lt;item&gt;💰 Cost-Effective: Reduce review time by 60% while improving code quality&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Automated PR Summaries: Generate comprehensive summaries and release notes&lt;/item&gt;
      &lt;item&gt;Line-by-Line Review: Detailed suggestions for every code change&lt;/item&gt;
      &lt;item&gt;Pattern Recognition: Identifies anti-patterns and suggests best practices&lt;/item&gt;
      &lt;item&gt;Security Analysis: Flags potential security vulnerabilities&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Incremental Reviews: Reviews each commit individually for better context&lt;/item&gt;
      &lt;item&gt;Selective Analysis: Skips trivial changes to focus on what matters&lt;/item&gt;
      &lt;item&gt;Multi-Model Support: Uses lightweight models for summaries, powerful ones for reviews&lt;/item&gt;
      &lt;item&gt;Custom Prompts: Tailor review focus to your team's needs&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Chat with CodingFox: Ask questions about specific code sections&lt;/item&gt;
      &lt;item&gt;Test Generation: Request test cases for your changes&lt;/item&gt;
      &lt;item&gt;Code Simplification: Get suggestions for reducing complexity&lt;/item&gt;
      &lt;item&gt;Documentation Helper: Generate or improve code documentation&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Get CodingFox running in your repository in under 5 minutes!&lt;/p&gt;
    &lt;p&gt;Before you begin, ensure you have:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A GitHub repository where you want to add CodingFox&lt;/item&gt;
      &lt;item&gt;Admin access to the repository (to add secrets)&lt;/item&gt;
      &lt;item&gt;An OpenAI account (free tier works to start)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Sign up for OpenAI (if you haven't already):&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Go to OpenAI Platform&lt;/item&gt;
          &lt;item&gt;Create your account&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Generate an API Key:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Navigate to API Keys page&lt;/item&gt;
          &lt;item&gt;Click "Create new secret key"&lt;/item&gt;
          &lt;item&gt;Give it a name (e.g., "CodingFox")&lt;/item&gt;
          &lt;item&gt;Copy the key immediately (you won't see it again!)&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Add Credits (for new accounts):&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Go to Billing&lt;/item&gt;
          &lt;item&gt;Add at least $5 to get started (this will last for hundreds of PR reviews)&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Navigate to your GitHub repository&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Go to Settings:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Click on the Settings tab in your repository&lt;/item&gt;
          &lt;item&gt;Scroll down to Security section in the left sidebar&lt;/item&gt;
          &lt;item&gt;Click on Secrets and variables → Actions&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Add New Secret:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Click "New repository secret" button&lt;/item&gt;
          &lt;item&gt;Name: &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Value: Paste your OpenAI API key&lt;/item&gt;
          &lt;item&gt;Click "Add secret"&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Create the workflow directory in your repository:&lt;/p&gt;
        &lt;quote&gt;mkdir -p .github/workflows&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Create the workflow file:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Create a new file: &lt;code&gt;.github/workflows/codingfox-review.yml&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Copy and paste this configuration:&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;Create a new file: &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;name: CodingFox AI Review

# Permissions needed for the action to work
permissions:
  contents: read
  pull-requests: write

# Trigger on pull requests and PR comments
on:
  pull_request:
    types: [opened, synchronize, reopened]
  pull_request_review_comment:
    types: [created]

# Prevent multiple reviews at the same time
concurrency:
  group:
    ${{ github.repository }}-${{ github.event.number || github.head_ref ||
    github.sha }}-${{ github.workflow }}-${{ github.event_name ==
    'pull_request_review_comment' &amp;amp;&amp;amp; 'pr_comment' || 'pr' }}
  cancel-in-progress: ${{ github.event_name != 'pull_request_review_comment' }}

jobs:
  review:
    runs-on: ubuntu-latest
    steps:
      - uses: codingfox/ai-pr-reviewer@latest
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        with:
          debug: false
          review_simple_changes: false
          review_comment_lgtm: false&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Commit and push the workflow file: &lt;code&gt;git add .github/workflows/codingfox-review.yml git commit -m "Add CodingFox AI code review" git push&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Create a test pull request:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Make any small change in your repository&lt;/item&gt;
          &lt;item&gt;Create a new branch: &lt;code&gt;git checkout -b test-codingfox&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Make a change and commit&lt;/item&gt;
          &lt;item&gt;Push and create a pull request&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Watch CodingFox in action:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Within 30-60 seconds, CodingFox will comment on your PR&lt;/item&gt;
          &lt;item&gt;You'll see a summary, code review comments, and release notes&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Interact with CodingFox:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Try commenting &lt;code&gt;@codingfox help me write tests for this function&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;CodingFox will respond with helpful suggestions&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;Try commenting &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For more thorough and accurate reviews, upgrade to GPT-4:&lt;/p&gt;
    &lt;code&gt;- uses: codingfox/ai-pr-reviewer@latest
  env:
    GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
    OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
  with:
    openai_heavy_model: gpt-4  # Better for code reviews
    openai_light_model: gpt-3.5-turbo  # Keep for summaries&lt;/code&gt;
    &lt;code&gt;with:
  review_simple_changes: true  # Review even minor changes
  review_comment_lgtm: true     # Comment even when code looks good
  max_review_comments: 50       # Increase comment limit&lt;/code&gt;
    &lt;code&gt;with:
  path_filters: |
    src/**
    !test/**
    !docs/**
    !*.md&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Issue&lt;/cell&gt;
        &lt;cell role="head"&gt;Solution&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CodingFox not commenting&lt;/cell&gt;
        &lt;cell&gt;Check Actions tab for errors, verify OPENAI_API_KEY is set&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;"Rate limit exceeded"&lt;/cell&gt;
        &lt;cell&gt;Add credits to OpenAI account or reduce &lt;code&gt;openai_concurrency_limit&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Reviews too verbose&lt;/cell&gt;
        &lt;cell&gt;Set &lt;code&gt;review_simple_changes: false&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Missing some files&lt;/cell&gt;
        &lt;cell&gt;Check &lt;code&gt;path_filters&lt;/code&gt; and &lt;code&gt;max_files&lt;/code&gt; settings&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Timeout errors&lt;/cell&gt;
        &lt;cell&gt;Increase &lt;code&gt;openai_timeout_ms&lt;/code&gt; (default: 360000)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Start with GPT-3.5: It's very cost-effective for initial testing&lt;/item&gt;
      &lt;item&gt;Use path filters: Focus on important directories like &lt;code&gt;src/&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Customize prompts: Tailor reviews to your team's standards&lt;/item&gt;
      &lt;item&gt;Monitor costs: Check OpenAI usage dashboard regularly&lt;/item&gt;
      &lt;item&gt;Iterate on feedback: Adjust settings based on team preferences&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Once installed, CodingFox will:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;✅ Automatically review every new pull request&lt;/item&gt;
      &lt;item&gt;✅ Generate PR summaries and release notes&lt;/item&gt;
      &lt;item&gt;✅ Provide line-by-line code suggestions&lt;/item&gt;
      &lt;item&gt;✅ Respond to your questions and requests&lt;/item&gt;
      &lt;item&gt;✅ Learn from your codebase patterns&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Simply create a pull request and CodingFox will automatically:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Generate a comprehensive PR summary&lt;/item&gt;
      &lt;item&gt;Review code changes line-by-line&lt;/item&gt;
      &lt;item&gt;Suggest improvements and catch issues&lt;/item&gt;
      &lt;item&gt;Create release notes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Tag &lt;code&gt;@codingfox&lt;/code&gt; in any PR comment:&lt;/p&gt;
    &lt;code&gt;@codingfox Can you suggest test cases for this function?
&lt;/code&gt;
    &lt;code&gt;@codingfox How can I improve the performance of this loop?
&lt;/code&gt;
    &lt;code&gt;@codingfox Is there a better design pattern for this implementation?
&lt;/code&gt;
    &lt;p&gt;Add to PR description to skip review:&lt;/p&gt;
    &lt;code&gt;@codingfox: ignore
&lt;/code&gt;
    &lt;code&gt;with:
  # For comprehensive reviews (recommended: gpt-4)
  openai_heavy_model: gpt-4
  
  # For summaries and simple tasks
  openai_light_model: gpt-3.5-turbo
  
  # Temperature for AI responses (0-1)
  openai_temperature: 0.2&lt;/code&gt;
    &lt;code&gt;with:
  # Review even simple changes like typos
  review_simple_changes: false
  
  # Continue reviewing when changes look good
  review_comment_lgtm: false
  
  # Maximum review comments per PR
  max_review_comments: 30
  
  # Enable debug logging
  debug: true&lt;/code&gt;
    &lt;p&gt;Customize CodingFox's personality and focus:&lt;/p&gt;
    &lt;code&gt;with:
  system_message: |
    You are @codingfox, an expert code reviewer focused on:
    - Security best practices
    - Performance optimization
    - Clean code principles
    - Test coverage
    
    Be constructive, specific, and friendly in your feedback.
  
  summarize_prompt: |
    Provide a concise summary focusing on:
    - Main changes and their purpose
    - Potential impact on the system
    - Areas requiring special attention&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Model&lt;/cell&gt;
        &lt;cell role="head"&gt;Use Case&lt;/cell&gt;
        &lt;cell role="head"&gt;Estimated Cost&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;GPT-3.5 Turbo&lt;/cell&gt;
        &lt;cell&gt;Summaries&lt;/cell&gt;
        &lt;cell&gt;~$0.002 per PR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;GPT-4&lt;/cell&gt;
        &lt;cell&gt;Full Review&lt;/cell&gt;
        &lt;cell&gt;~$0.10-0.50 per PR&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Typical Usage: A 20-developer team reviewing 50 PRs/day costs approximately $20-30/day with GPT-4.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Data Processing: Code is sent to OpenAI's API for analysis&lt;/item&gt;
      &lt;item&gt;Data Retention: OpenAI API has strict data usage policies&lt;/item&gt;
      &lt;item&gt;Compliance: Review with your security team for sensitive repositories&lt;/item&gt;
      &lt;item&gt;Self-Hosting: Contact us for on-premise deployment options&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Node.js 17+&lt;/item&gt;
      &lt;item&gt;npm or yarn&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Install dependencies
npm install

# Build and package
npm run build &amp;amp;&amp;amp; npm run package

# Run tests
npm test&lt;/code&gt;
    &lt;p&gt;We welcome contributions! Please see our Contributing Guide for details.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Feature&lt;/cell&gt;
        &lt;cell role="head"&gt;CodingFox&lt;/cell&gt;
        &lt;cell role="head"&gt;Traditional Reviews&lt;/cell&gt;
        &lt;cell role="head"&gt;Other AI Tools&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Review Speed&lt;/cell&gt;
        &lt;cell&gt;⚡ Instant&lt;/cell&gt;
        &lt;cell&gt;🐌 Hours/Days&lt;/cell&gt;
        &lt;cell&gt;⚡ Instant&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Context Understanding&lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Consistency&lt;/cell&gt;
        &lt;cell&gt;✅ 100%&lt;/cell&gt;
        &lt;cell&gt;❌ Variable&lt;/cell&gt;
        &lt;cell&gt;✅ 100%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Availability&lt;/cell&gt;
        &lt;cell&gt;✅ 24/7&lt;/cell&gt;
        &lt;cell&gt;❌ Business Hours&lt;/cell&gt;
        &lt;cell&gt;✅ 24/7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Learning Curve&lt;/cell&gt;
        &lt;cell&gt;✅ None&lt;/cell&gt;
        &lt;cell&gt;❌ Team Dependent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Customization&lt;/cell&gt;
        &lt;cell&gt;✅ Extensive&lt;/cell&gt;
        &lt;cell&gt;✅ Full&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Cost&lt;/cell&gt;
        &lt;cell&gt;💰 Low&lt;/cell&gt;
        &lt;cell&gt;💰💰💰 High&lt;/cell&gt;
        &lt;cell&gt;💰💰 Medium&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;quote&gt;
      &lt;p&gt;"CodingFox reduced our PR review time by 65% while catching 40% more bugs before production." - Tech Lead, Fortune 500&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;"The contextual suggestions are incredible. It's like having a senior developer review every line of code." - Startup CTO&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;"We save $50k+ annually on review time alone. CodingFox pays for itself in days." - Engineering Manager&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;MIT License - see LICENSE file for details.&lt;/p&gt;
    &lt;code&gt;    /\_/\  
   ( ^.^ )  Made with ❤️ by CodingFox Team
    (")_(")  Happy Coding! 🦊
&lt;/code&gt;
    &lt;p&gt;CodingFox - Elevating Code Quality, One Review at a Time&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45516402</guid><pubDate>Wed, 08 Oct 2025 14:11:30 +0000</pubDate></item><item><title>How To Start Bug Bounties (2021)</title><link>https://ozguralp.medium.com/how-to-start-bug-bounties-101-how-to-make-a-million-in-4-years-e15ee62d6f4</link><description>&lt;doc fingerprint="c618e257093157bd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How to Start Bug Bounties 101 &amp;amp; How to Make a Million in 4 Years&lt;/head&gt;
    &lt;p&gt;I got lots of questions and requests especially from new beginners to the area, so wanted to prepare a blog post regarding how to start at bug hunting and how to be successful.&lt;/p&gt;
    &lt;p&gt;Firstly, I want to say as there is no only true way exist to became successful in any area including this one. Every person has their own personality, characteristics, speciality and qualifications so this criteria could differ from one to another. I am only telling my story and mental methodology here, which directed me to earn $1 million through 4 years.&lt;/p&gt;
    &lt;head rend="h3"&gt;How (not) to start at first place?&lt;/head&gt;
    &lt;p&gt;If you are a person who is consistently asking other people about how to become successful in bug bounty sector or being mentor to them, I can surely tell you that as this is not the right way. Nobody has a simple formula to become successful in any area. So first thing to do in here could be stopping to ask people generic “how to” questions. Instead of it; you can do your homework, do some research about the area and find out your way yourself which will really help you later in terms of gaining bug hunting mindset.&lt;/p&gt;
    &lt;p&gt;When I was lecturing “Cyber Security 101” class at the Istanbul Bilgi University for 4 years, my first slide of the presentation for the first term was this one:&lt;/p&gt;
    &lt;p&gt;This concept could be expanded &amp;amp; adapted to any area. In terms of bug hunting:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;“Learning how to use Google” is super essential. I use nearly 50-100 times per day for the last 4 years of my time. If you know how to use if efficiently, you can find what you are looking for faster and smarter. If you want to know how to use it efficiently, you can start Googling about it.&lt;/item&gt;
      &lt;item&gt;If your native language is not English, then learning it is super essential as using Google. The most international accepted language for 2021 is English and nearly all resources can be found within it.&lt;/item&gt;
      &lt;item&gt;I mentioned Turkish (as native language) on my original slide because knowing your native language is an important thing to become successful in any area. If you cannot know your native language well at first place, then you cannot use/learn/know other languages well too. In addition to that, we are using our language as a gateway to the outer world. Applying it to bug hunting: To understand what you are reading/researching, to speak with other people on same interests, to write a good report, to make a discussion with the report reviewer/triager; you need to know your native language + English good. There is a concept exist as Sapir–Whorf hypothesis regarding to the subject as: “a principle suggesting that the structure of a language affects its speakers’ worldview or cognition, and thus people’s perceptions are relative to their spoken language.”. which I highly believe as it is really effecting our perspective of lives including our approaches to any subject. So knowing your language better + an extra language might bring a new different point of view to the human being. (If you are into the topic, I also can recommend the 2016 Sci-Fi movie Arrival which had a different unique approach to this hypothesis.)&lt;/item&gt;
      &lt;item&gt;“Finding your own area/speciality” is actually important on the long run to become expertise and unique in the industry. As a real world example, Tommy tells it all the time as he made nearly all of his bug bounty payouts from a single vulnerability category, SSRF, which is a good proof to what some focused working can put into your wallet.&lt;/item&gt;
      &lt;item&gt;“Technical knowledge &amp;amp; experience” is all you can put into this area. Comparing to the other working concepts/practices (such as winemaking, having nearly 1000 years of history and experience), bug hunting (as well as nearly all IT topics) is still a new topic which changes everyday. So adding some value to it is easy comparing to other disciplines.&lt;/item&gt;
      &lt;item&gt;I am not going to talk in details about “Keeping up-to date” in here, because as it is obvious that information technologies are updated every day and without having that, your bugs could be out-of-date :)&lt;/item&gt;
      &lt;item&gt;In terms of bug hunting, “Expanding your network/social skills” is not too important comparing to the prior items, however having those still can bring you new opportunities. Human beings are known as social living creatures from beginning and working as a community always brings positive developments.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;How to become successful?&lt;/head&gt;
    &lt;p&gt;From both my experience and observations of other bug hunters’ career paths/resumes; I can say that if you have a penetration test/offensive security research experience on your back then it is easier to getting adapted on bug hunting discipline. But as I said, there is no point of generalizing and I do personally know lots of successful bug hunters even if they didn’t go into the university at all or yet. So this really depends on the person. You could become successful when you are at your 14 or could fail even after you have your PhD in Computer Sciences.&lt;/p&gt;
    &lt;p&gt;Firstly, definition of “being success” in here is really important and it also depends from person to person too. Most of the times, success is came down to the salary/payout/money; however I can say that there are more success items exist in bug bounty hunting comparing to the regular day job. From my point of view, I am choosing bug hunting over regular working due to those earnings of successes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Being own your boss: If you have a really good self-discipline and really do not like illogical duties coming from your superior, than this is definitely it for you. This is the uttermost thing that I love about bug hunting. You are your own boss.&lt;/item&gt;
      &lt;item&gt;Performance basis payouts: If you are eager of earning more money, instead of changing your job, you can work for extra bucks over the night :)&lt;/item&gt;
      &lt;item&gt;Flexible working: Most of the new IT jobs has this as a benefit but still taking a day or month off without asking to anyone for approval is still awesome.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So without having the same salary on a daily job, I would still prefer hunting as those advantages. Having those is a success for me rather than huge payouts :) To sum up; for becoming successful, a person needs to define their own success criteria at first.&lt;/p&gt;
    &lt;head rend="h3"&gt;Ok, my success criteria is 🤑. So how to make a million?&lt;/head&gt;
    &lt;p&gt;Now as a starting point, it differs within various experience levels:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If you are starting without any IT experience, then this is the toughest one to achieve. For becoming successful in this area, one should really know the basics of the IT such as networks, hosts, software, protocols etc. basically everything. Without knowing them, finding vulnerabilities would be really hard. I could suggest to understand those technologies at first; e.g. installing a web service, creating a DNS server, learning a programming language etc. then afterwards focusing on security field.&lt;/item&gt;
      &lt;item&gt;If you are starting with IT experience but without a pentest experience; then this is still hard for you but not the toughest. The main thing in here is actually learning about security principles. Why do we need security? What are we trying to protect? Who are protecting from? How can we protect that? What could be entry points? What are the attack types? If you can start answering those questions on all case by case, then the basics of the offensive security could be start shaping on you.&lt;/item&gt;
      &lt;item&gt;If you are coming from pentest experience like me; I can say that bug hunting discipline is really different than pentest and a little bit hard to getting used to. Instead of the pentest projects (finding every vulnerability including all levels), you need to focus nearly to find exploitable vulnerabilities rather than theoretical ones. I remember as we were reporting SQLi’s on the pentest projects within having errors as &lt;code&gt;'&lt;/code&gt;characters or reporting&lt;code&gt;&amp;lt;&amp;gt;&lt;/code&gt;escapes on the responses of the HTML’s without trying to actually dump an information from DB or bypassing WAF for a successful XSS attack. So this is the time that you need to focus on finding actual vulnerabilities within real world scenarios &amp;amp; impacts.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I personally prefer and suggest to start into bug hunting after learning the security concepts + having online trainings. You can still find vulnerabilities without having extreme technical skills but most of the times they would happen within temporary lucky findings/reports which could make you struggle in the future.&lt;/p&gt;
    &lt;p&gt;After starting actively bug hunting, this is my mental applied methodology for both short/long term:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Being consistent: Especially for the first years, consistency is really important. Some days while you are getting some valid reports, some days you will get nothing. So within consistency you will increase your chances to find valid reports per day/week.&lt;/item&gt;
      &lt;item&gt;Goals &amp;amp; motivation: Demotivation is really common especially at the first days/months of hunting. I personally felt like thousands of times demotivated when cannot find any bugs during the day. What I found as a solution is focusing of the both short/long term realistic goals instead of daily wins. The important thing in here is actually what you achieve per average. Setting weekly/monthly/yearly achievable goals and actually achieving them is really good for intrinsic satisfaction.&lt;/item&gt;
      &lt;item&gt;Variety in bugs: If you are focused only on XSS bugs, then you can only report XSS bugs. :) especially for the beginners, having different set of categories testing is really important. For my first year on hunting; I can say that I looked and reported for all kind of bugs. Within this, you will start to have more valid reports comparing to the lesser diversified testing which will reduce the stress both in terms of payouts &amp;amp; fear of not finding anything.&lt;/item&gt;
      &lt;item&gt;Focusing on some categories: As the prior Tommy &amp;amp; SSRF example, especially after some time; focusing on some categories and increasing the technical knowledge about them &amp;amp; being expertise on them will really create difference in the industry. Especially after my 2nd year at the hunting, I started focusing on some of the categories that I love such as Authorization/Authentication. Read everything about them. Apply everything you learn about them in the real world. Manually analyze every request and response. In some step, you will catch those special ones unique to you!&lt;/item&gt;
      &lt;item&gt;Learn platforms/mentality: Every bug bounty platform, target, program, triager etc. has a huge difference of approaches comparing to others. For last 4.5 years (All of my bug hunting journey), I mostly worked (80–85%) on a single platform which bringed me succeed. While I was testing mostly new systems/targets per week on my first years; especially for the last 2 years, I started testing my old targets again per 6 months which I earned most of my payouts. On this period, I found out that application owners creates lots of different vulnerabilities while patching the reported ones which are overlooked most of the times. Also testing/getting used to same technologies will collect more deep/technical information regarding those which makes it possible to report more complex and unhidden bugs. So while testing different applications/targets extends &amp;amp; diversifies your knowledge, testing the same ones from time to time provides new discoveries that goes unnoticed.&lt;/item&gt;
      &lt;item&gt;Have your own mental methodology: Every successful bug hunter I met has a unique approach of testing, which is shaped after some time. So find the methodologies that suits best for you and improve them on your way.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Last thoughts&lt;/head&gt;
    &lt;p&gt;As I said on the prolog section of the post: “There is no only true way exist to became successful in any area.”. Every human being has their own journey. We will always use others’ experiences for self-development as on the history, however will also determine our self-journeys within individual efforts and diligence.&lt;/p&gt;
    &lt;p&gt;Stay safe and be luck on your side :)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45516556</guid><pubDate>Wed, 08 Oct 2025 14:25:19 +0000</pubDate></item><item><title>Show HN: Recall: Give Claude perfect memory with Redis-backed persistent context</title><link>https://www.npmjs.com/package/@joseairosa/recall</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45516584</guid><pubDate>Wed, 08 Oct 2025 14:28:06 +0000</pubDate></item><item><title>After 2 decades of tinkering, MAME cracks the Hyper Neo Geo 64</title><link>https://www.readonlymemo.com/mame-hyper-neo-geo-support-sound-emulation/</link><description>&lt;doc fingerprint="372e9953cb024b11"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;After 2 decades of tinkering, MAME finally cracks the Hyper Neo Geo 64&lt;/head&gt;
    &lt;p&gt;How MAME devs finally got sound working for the 3D arcade system. Plus: PC Engine LaserActive support gets fast-tracked.&lt;/p&gt;
    &lt;p&gt;Let me test out a theory here: If you're into emulation, you're into older video games, ergo you're into old stuff of all kinds. That means you, savvy, good-taste-having reader, will love this spread of photos I took in Tokyo last week at the National Film Archive of Japan, which has a small but lovely set of exhibits from the history of Japanese film. Since you like playing Super Nintendo games this is absolutely your shit, right? Right??&lt;/p&gt;
    &lt;p&gt;Okay, I'll throw in a pic of some games to sweeten the deal.&lt;/p&gt;
    &lt;p&gt;This issue is coming a week late as I was off to Japan last week for my first-ever visit to the Tokyo Game Show, and too busy working (and working at eating sushi) to squeeze in a newsletter. And it's coming late in the day Sunday — apologies! But patience pays off!!&lt;/p&gt;
    &lt;p&gt;This issue's main story has been cookin' for a minute: last month the news landed that MAME had finally properly cracked Hyper Neo Geo 64 support, but the celebration was a little bit premature. The arcade system was playable in MAME, yes, but sound was in really shoddy shape — it wasn't yet a particularly good experience.&lt;/p&gt;
    &lt;p&gt;Over the last month or so that's been changing, and changing fast, with frequent improvements checked in by a pair of regular MAME contributors. So now is the time to talk about it, and soon (with the very next MAME release!) it will be time to actually play it. Considering there are only seven Hyper Neo Geo 64 games, well, that's a week's worth of evenings sorted.&lt;/p&gt;
    &lt;p&gt;As with every trip to Tokyo I took a few hours to stop by Akihabara this time, but its pull has certainly lessened over the years as retro prices have skyrocketed from where they were a decade ago and the selection has gotten thinner and thinner. Still, browsing the stores is a fun time and there are great finds to be found as long as you're not looking for anything too in-demand. I picked up one game: Kamiwaza, a PS2 "stealth" game where you play as a thief in feudal Japan stealing hella stuff.&lt;/p&gt;
    &lt;p&gt;As you might guess, it's more silly than stealthy.&lt;/p&gt;
    &lt;p&gt;Shout out to my shopping partner in crime, Paradise Killer's Oli Clarke Smith, for the recommendation. I've got a feature on the way in the coming weeks over at PC Gamer based on some of the games we picked up and how they speak to the "identity" of particular retro consoles. I'm hoping it'll be a fun read!&lt;/p&gt;
    &lt;p&gt;For now, let's hop into MAME; then stick around for an update on Pioneer LaserActive emulation!&lt;/p&gt;
    &lt;head rend="h2"&gt;The Big Two&lt;/head&gt;
    &lt;head rend="h3"&gt;1. The Hyper Neo Geo comes to MAME: Now with working sound!&lt;/head&gt;
    &lt;p&gt;21 years ago, David "MameHaze" Haywood started looking into what it would take to add support for the Hyper Neo Geo 64 arcade system — then just five years past the end of its short lifespan — to MAME. "When I started looking at the system back in 2004 MAME didn't really do much 3D stuff at all, even things like the MIPS (main CPU) core were in a much rougher shape, there were no dumps of the I/O MCU at all (happened only a few years ago) and the PC I had at the time barely had enough memory to load and decode even the 2D graphics," he says.&lt;/p&gt;
    &lt;p&gt;"It was also pre-YouTube, and even in the early days of YouTube you didn't really get much in the way of good reference material. Kinda crazy to think that a lot of people who are probably interested in the emulation of the platform now as younger adults weren't even born when emulation work first started on it!"&lt;/p&gt;
    &lt;p&gt;A few weeks ago, two decades after he started looking into the system, Haywood finally promoted it to "working" status in MAME. But that move was a bit of a formality, or a bit sneaky, depending on how you look at it. Though the promotion got some buzz, it wasn't truly finished: proper sound emulation was still missing. Haywood actually hadn't worked on the core since 2023, and decided, well, people had been playing the games for long enough without sound, he might as well slap the "working" label on. It turned out to be the final push other MAME contributors needed to take a crack at tuning up the sound.&lt;/p&gt;
    &lt;p&gt;What's the Hyper Neo Geo's whole deal, anyway? Well, it makes some sense that the system would be more a curiosity for younger folks to discover than an object of intense nostalgia like some of MAME's more high-profile cores or the original Neo Geo; it was only active in arcades for two years from 1997 to 1999 during the awkward transitional period to 3D, with just seven games released for it:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Road's Edge&lt;/item&gt;
      &lt;item&gt;Samurai Shodown 64&lt;/item&gt;
      &lt;item&gt;Xtreme Rally&lt;/item&gt;
      &lt;item&gt;Beat Busters: Second Nightmare&lt;/item&gt;
      &lt;item&gt;Samurai Shodown 64: Warriors Rage&lt;/item&gt;
      &lt;item&gt;Fatal Fury: Wild Ambition&lt;/item&gt;
      &lt;item&gt;Buriki One&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here's a nice write-up of the system from Nicole Express that delves into the hardware:&lt;/p&gt;
    &lt;p&gt;None of these games have the Bloodborne-style pull to individually inspire interest in emulation, but the MAME team's all-consuming drive to reverse-engineer and archive every arcade system in existence kept it on the radar. Haywood's initial investigation into it predated even MAME's high profile support of Capcom's CPS3 boards, for instance, but once that platform was decrypted support was added quite quickly because hell yeah people wanted to play Street Fighter III. By comparison, "Hyper64 has been a 21 year on-and-off slog," he says.&lt;/p&gt;
    &lt;p&gt;It's a perfect representation one of the eternal frustrations of emulation development: People often ask why no one's working on something when they actually are. Just invisibly.&lt;/p&gt;
    &lt;quote&gt;"The sheer number of times I picked up the Hyper64 driver and pumped weeks of work in it only to not be able to make any progress at all was frustrating at the best of times. Just trying to gain an understanding of it all, but ending up not making any headway at all. That's something I don't think people really appreciate when it comes to emulation, the amount of time that you have to put in which often yields no positive results at all, where all you can really conclude is it doesn't work the way you were hoping it would work."&lt;/quote&gt;
    &lt;p&gt;A few years ago, Haywood finally made substantial progress: Someone dumped the I/O microcontroller, and he was able to write a CPU core to emulate it. "The inputs finally started working in a bunch of the games, which allowed me to explore them further and make video improvements," he said.&lt;/p&gt;
    &lt;p&gt;"Other components improving in MAME over the years has really helped too. When I started MAME didn't have a CPU core for the V53 either (which is a V33 CPU with variolus peripherals) and is the CPU driving the sound DSP. At some point in MAME's history the V53 support got fleshed out (for other systems) which has really come in handy now, as proper sound emulation requires that to be running properly."&lt;/p&gt;
    &lt;p&gt;When Haywood marked the platform as working, it caught the attention of another longtime MAME contributor: R. Belmont. For the last month or so, Belmont, as well as two other devs, Happy and O. Galibert, have been chipping away at making the games sound like they're supposed to.&lt;/p&gt;
    &lt;p&gt;"Haze marking them working did provide a push, and Happy had done a detailed disassembly of the sound CPU program which was quite useful," Belmont recently posted on Reddit. Belmont and Galibert have both been working on synthesizer support in MAME, and the Hyper Neo Geo 64's sound chip happens to be used it one, providing them with some convenient overlap in interest/speciality.&lt;/p&gt;
    &lt;p&gt;The current MAME release, 0.281, includes a series of rapid-fire improvements as documented by Belmont in a few videos on YouTube:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"Very early work in progress on better audio for the Hyper Neo Geo 64 system. There is a loooong way to go, this is just some very basic fixes so far."&lt;/item&gt;
      &lt;item&gt;"Since the first video we've got the basic sample starts and stops working the actual correct way they're supposed to and added a preliminary support for volume envelopes, which also helps the audio balance. Still a lot of work to go though."&lt;/item&gt;
      &lt;item&gt;"More progress today! I figured out how the volume envelopes really work, and that made Buriki One's intro mostly awesome."&lt;/item&gt;
      &lt;item&gt;"Barring any last minute adjustments, this is what HNG64 audio will sound like in MAME 0.281. Since the last video, the per-voice low pass filter was added, which cleans up some of the high frequency 'hash' audible previously and makes the sound a bit cleaner."&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It was a ton of progress for a month, taking Hyper Neo Geo 64 sound support from messy and inaccurate to, at least, broadly playable without assaulting your ears. But the real refinements have been coming in just the last few days since 0.281's release in late September.&lt;/p&gt;
    &lt;p&gt;But the next build is gonna be the big one. October's upcoming MAME 0.282 release will notably fix up the audio issues in one of the the trickiest games, Xtreme Rally, while really polishing up the rest. Here's what Belmont's noted in update notes for 0.282 so far:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"Olivier Galibert figured out how they squeezed 12 bits of dynamic range into 8 bits (presumably this is the format from Roger Linn's original MPC60 design) and replaced the biquad low-pass filter with a more likely Chamberlin one that fits the parameters better. Also there were some improvements to the filter envelope. All this results in much clearer and higher-fidelity sound."&lt;/item&gt;
      &lt;item&gt;"This time we've figured out how looping samples actually work, fixed the final mixdown to not introduce any distortion, and fixed the filter envelope. The result? A dramatic improvement to Beast Busters Second Nightmare's intro."&lt;/item&gt;
      &lt;item&gt;"So the previous fixes seem to have solved Samurai Shodown 64 and SS64 2, but Xtreme Rally (aka Off Beat Racer) was still extremely broken. The engine sound barely worked, sounds were missing, and some sounds would stick looping forever. This time the problem wasn't actually in the sound emulation itself; Xtreme Rally has unique code among the 7 HNG64 games that tries to push sound commands to the sound CPU as quickly as possible. This resulted in as many as 2/3rds of the commands getting dropped on the floor. I have fixed that issue so that all of the commands make it, and Xtreme Rally now sounds great."&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Since Belmont made that post he dialed in a few more improvements where the wrong sounds were playing in certain instances in the game. Here's a video from Haywood showing off the vastly improved audio (though he notes "some graphical issues, such as the fog in the tunnel still need addressing eventually.")&lt;/p&gt;
    &lt;p&gt;Once MAME 0.282 releases, the Hyper Neo Geo 64 will well and truly be worthy of the "working" label. Turns out it just needed that last little push.&lt;/p&gt;
    &lt;p&gt;In a perfect encapsulation of how these sorts of collaborative projects come together, Galibert noted on Reddit that despite their contributions to the core stemming from an interest in emulating synthesizers, "amusingly, the synth itself (MPC3000) is not working at all yet." Some parts of the synthesizer remain undumped and undocumented, just as parts of the Hyper Neo Geo once were; sometimes while you're waiting for all the pieces to fall into place, it turns out one of the pieces you do have happens to fit into another puzzle entirely.&lt;/p&gt;
    &lt;p&gt;"It's just been a long slow process," Haywood said. "Things have inched forward a little bit over the years, and the surrounding code in MAME has become better / more capable, allowing for more progress to be made, step by step."&lt;/p&gt;
    &lt;head rend="h3"&gt;2. Can't stop Pioneering: NEC support and big LaserActive performance improvements arrive in the latest Ares nightlies&lt;/head&gt;
    &lt;p&gt;Often I end a big story, like the August issue's deep dive into the 16 years it took to emulate the Pioneer LaserActive, with the door open to a follow-up many months or years down the road. In this story, our hero — emudev Nemesis — finished work on one of two modules for the Laserdisc-based gaming console, making it possible to play Sega's Mega LD games via emulation for the first time.&lt;/p&gt;
    &lt;p&gt;As of publication time, Nemesis was juuuust starting to take a look at the work required to do the same for the other "pak" players could slot into the LaserActive to play NEC PC Engine games, but who knew how long that would take?&lt;/p&gt;
    &lt;p&gt;Maybe we'd come back to it before the end of 2026, or maybe next year, or maybe in half a deca-&lt;/p&gt;
    &lt;p&gt;Oh. He already did it.&lt;/p&gt;
    &lt;p&gt;"NEC LDROM2 support is functioning on nightly builds of the v147 prerelease, and will be included in the next official Ares release," Nemesis recently wrote on his website. It took less than three weeks. While you can grab the nightly build anytime, when the next stable build of Ares releases, it'll be all official-like.&lt;/p&gt;
    &lt;p&gt;Considering the bulky size of the LaserActive game rips — they can take up dozens of gigabytes — some performance optimizations Nemesis has implemented in the last few days are almost as exciting as the second console support. Because now you should be able to run the images off a decent HDD without performance issues. Here's the breakdown on Github:&lt;/p&gt;
    &lt;quote&gt;"This change brings speed enhancements to LaserActive games. The linear resampling coefficient precalculation reduces overall CPU overhead by approximately 30%, making slower CPUs much more likely to achieve full framerate. Additionally, frame prefetch using a background thread makes games much more tolerant of IO latency, making it possible to play games back from platter drives over SATA3.&lt;lb/&gt;This should be sufficient to make emulation performance acceptable on 95%+ of systems, and I don't have any further optimizations planned at this stage."&lt;/quote&gt;
    &lt;p&gt;So then — LaserActive support is more or less feature complete. What can you play? What should you play? Seeing as the system's deader than dead and nobody's likely to be playing copyright cop, the Laserdisc rips are being freely uploaded and shared here. Not every game is available yet, but here's where you should probably start:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Vajra and Vajra 2 - A pair of LaserActive-exclusive rail shooters by Data West&lt;/item&gt;
      &lt;item&gt;Triad Stone - An FMV game in the Dragon's Lair game&lt;/item&gt;
      &lt;item&gt;J.B. Harold - Blue Chicago Blues - As described by Nemesis, an "FMV murder mystery detective game, with a surprising amount of freedom. You have control over where to go, what actions to take, and what questions to ask. This title came on a double-sided CLV disc, giving it four times the video content of a typical single-sided CAV LaserActive title. The game also used separate video streams per field, to squeeze a whopping 4 hours of footage into one disc."&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are a couple other cool games and curiosities on the system, including more rail shooters, some prototypes of Myst, and a German TV movie that lets you swap between different perspectives — but the above should give you a taste for that sweet sweet (or fuzzy, fuzzy) '90s laser gaming.&lt;/p&gt;
    &lt;head rend="h2"&gt;Patching In&lt;/head&gt;
    &lt;p&gt;MiSTer's Taito F2 core pulls off a Hat Trick – Taito's 1990 game Football Champ, aka Hat Trick Hero, is now playable on the MiSTer's arcade core, as is the baseball game Ah Eikou no Koshien. The latter's surprisingly expressive for its era and looks like a lot more fun than I expect from '90s baseball games.&lt;/p&gt;
    &lt;p&gt;MiSTer's CDi core once again threatens you by functioning – In the latest unstable nightly build of the CDi core, developer Andre Zeps has committed several crimes of CDi improvement, including: "Fix dual SDRAM mode," "Add support for chroma subcarrier for clean composite video from external RGB converters," and "- Add bob deinterlacing to ascal." Go on then, but don't blame me if you start bleeding from every orifice while playing Wind of Gamelon.&lt;/p&gt;
    &lt;head rend="h2"&gt;Core Report&lt;/head&gt;
    &lt;p&gt;Windows builds of RPCS3 are back in business – Due to a compiler issue, RPCS3's latest builds haven't been available on Windows since back in June, but they're back and working again now. Meanwhile, contributor Whatcookie has created a surprisingly detailed breakdown of how hard it is to do nothing, efficiently.&lt;/p&gt;
    &lt;p&gt;Eden is off the Play Store, for now – Well, so much for that. After launching on Android a few weeks ago, the Switch emulator has been taken down, though you can still find builds, including for Android, on the Github. Aren't DMCA takedowns lovely?&lt;/p&gt;
    &lt;p&gt;Speedrunning-focused emulator BizHawk gets hexed – But in a good way! The source port DSDA-Doom has been integrated into BizHawk, supporting Doom, Heretic and Hexen. It also now has an integrated DOSBox-X core, as well as Opera, for the 3DO.&lt;/p&gt;
    &lt;p&gt;ShadPS4 gets more Unreal – The latest build of ShadPS4 marks a significant milestone: some Unreal Engine games for the console are now playable, and even more are bootable. Look at all these games that work!&lt;/p&gt;
    &lt;head rend="h2"&gt;Translation Station&lt;/head&gt;
    &lt;p&gt;Tis the season for brains... Dead of the Brain (2) – It's spooky season, which means the crew behind the translation of PC-98 adventure game Dead of the Brain is back with the sequel two years after the first! "Like the original game, this is also a point-and-click adventure involving zombies, but this time the gameplay is much simpler, but there's still a degree of brute force required," translation crew WINE says. Playing this one might be a bit tedious, but the art is :chefskiss:&lt;/p&gt;
    &lt;p&gt;Virtual-On, on PS3 – The PS3 re-release of this mecha game had English dialogue etc., but its UI was in Japanese. This translation patch changes that.&lt;/p&gt;
    &lt;p&gt;Wizardy VI, on Saturn – There are at least nine platforms you can play Wizardry: Bane of the Cosmic Forge on, from the 1990 DOS original to the Amiga and FM Towns and modern ports, but the Japanese-only Saturn port is unique, incorporating features from Wizardry 7, and now playable with the original English script. This version has "more spells, more traps, and more skills (though most of the extra skills do nothing in 6, unfortunately), and the art style too is very reminiscent of 7 ... it’s also got a much easier early game, which a lot of new players have notoriously struggled with when playing the other versions," hacker and fan Remisse told Sega Saturn Shiro.&lt;/p&gt;
    &lt;p&gt;Undercover Cops play board games on the GB – Prolific translation group Stardust Crusaders is back with a Game Boy board/card game based on the arcade game. I'm not gonna say it's one of Irem's all-timers (find me playing Ninja Baseball Bat Man instead), but it's cute!&lt;/p&gt;
    &lt;head rend="h2"&gt;Good pixels&lt;/head&gt;
    &lt;p&gt;It's early October which means it's basically Halloween, right? Here's a load of screenshots from the first couple hours of Dead of the Brain 2. 👻&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45516968</guid><pubDate>Wed, 08 Oct 2025 15:01:38 +0000</pubDate></item><item><title>A deep dive into the RSS feed reader landscape</title><link>https://lighthouseapp.io/blog/feed-reader-deep-dive</link><description>&lt;doc fingerprint="be149c54c0323cec"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A deep dive into the rss feed reader landscape&lt;/head&gt;
    &lt;p&gt;RSS feeds and, in one form or another, feed readers, have existed for more than 20 years. Their main purpose is enabling their users to consume content from various sources in one place. And especially in recent years, also helping users deal with content overload.&lt;/p&gt;
    &lt;p&gt;Back then there were only a handful of relevant products. Today it's different, there are products for many different situations and use-cases. When first getting into RSS and feed readers, it can be difficult to find out which of this wide range of products are the right ones to use.&lt;/p&gt;
    &lt;p&gt;This article describes the landscape so you can find out which product fits best for your use-case.&lt;/p&gt;
    &lt;p&gt;Side-note: I'm using RSS as a synonym for all web feed standards (Atom, JSON Feed)&lt;/p&gt;
    &lt;head rend="h2"&gt;Classification&lt;/head&gt;
    &lt;p&gt;I attempted a classification of feed readers based on 2 axes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Deployment model: local (phone or PC), browser extension, self-hosted, hosted&lt;/item&gt;
      &lt;item&gt;Business model: free, one-time payment, SAAS&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The deployment model is based on where data is stored and feed fetching happens. Some products have a web app and mobile apps, but feed fetching happens on the server. In this case it's classified as &lt;code&gt;hosted&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The business model categorization is based on the cheapest option that gives access to the full feature set of the product. A self-hostable product with a hosted option is categorized into &lt;code&gt;free&lt;/code&gt;. A freemium SAAS product is categorized as &lt;code&gt;paid (SAAS)&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;And here the image in table format, for easily clickable links:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Pricing&lt;/cell&gt;
        &lt;cell role="head"&gt;On-device (phone or PC)&lt;/cell&gt;
        &lt;cell role="head"&gt;Browser extension&lt;/cell&gt;
        &lt;cell role="head"&gt;Self-hosted&lt;/cell&gt;
        &lt;cell role="head"&gt;Hosted&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Free&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Paid (one-time)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Paid (SAAS)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Hosting models&lt;/head&gt;
    &lt;head rend="h3"&gt;Browser extension&lt;/head&gt;
    &lt;p&gt;Feed readers deployed as browser extensions can be installed through the respective stores of the browsers, usually either the Chrome Web Store or the Firefox Add-ons.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Setup and maintenance: Setup typically only requires installing the extension, not even an account is needed. There is no maintenance required beyond the occasional update, which usually happens automatically.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data control and storage: Data is stored locally, with browser storage functionality (local storage or IndexedDB). How much data can be stored depends on the storage of the device. Browser extensions can only store as much data as the browser allows itself to use. But for most users this is easily enough.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Feed fetching: Feeds are fetched on the device itself. Because the extension only runs if the browser runs, feeds are only fetched if the browser is open. This can lead to missed posts, depending on the publishing frequency of the feed and how often the browser is active.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Availability: Since all data is stored on the device, by default it's available only on the device where the extension is installed. If users enable it, the extension supports it, and the user is signed in, browsers can sync data to other devices that have the extension. Storing all data on the device also means that it is accessible offline.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Functionality: Extensions can integrate deeply with the browser, and offer features like automatic feed finding of visited websites. Extensions can also provide a comprehensive feature set. Their only limitations are more compute-intensive features (e.g. requiring machine learning), or features that require special infrastructure to run (e.g. emails).&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Products (free)&lt;/head&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell role="head"&gt;Free&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (one-time)&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (SAAS)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;In this category I only found one product. Smart-RSS was another one, but was discontinued in February.&lt;/p&gt;
    &lt;head rend="h3"&gt;On-device&lt;/head&gt;
    &lt;p&gt;On-device products are separate applications and installed on the device you want to use them. Either on your iOS or Android phone or tablet, or on your Windows, Mac, or Linux computer. They fetch feeds and store data on that device.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Setup and maintenance: In general setup is done by installing the application. Some products may require an account, but that is not the norm. Maintenance is similar to browser extensions, the occasional updates. Some applications require manual update installations, others do that automatically.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data control and storage: Data is stored locally on the device, which gives total control over the data. The maximum amount of feeds and articles stored only depend on the available storage of the device.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Feed fetching: Feeds are fetched on the device. For that to happen the application must be running. Some products may implement a background fetching service, in that case only the device must be turned on. Similar to browser extensions, this limitation may lead to missed posts.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Availability: Typically the data of on-device feed readers are only available on the device where it's installed. Data sync would need to be done manually or via operating system specific mechanisms (e.g. iCloud), which not all products support. Since data is stored on the device, it's also available offline.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Functionality: On-device products can use the full computing power of the device. Combined with the comparatively small storage requirements of one user, it means that some features can be significantly faster than other categories. The exact features depend on the application, and mobile apps are typically less powerful than desktop apps. Limitations are only features that require multiple users (e.g. recommendations) or specific infrastructure (e.g. newsletter subscriptions).&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Products&lt;/head&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell role="head"&gt;Free&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (one-time)&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (SAAS)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Self-hosted&lt;/head&gt;
    &lt;p&gt;Self-hosted products all fall into the open-source and free category. They are designed to be installed on a server to run continuously, though it is possible to install them on a PC as well. They fetch feeds and store data on the server, and make it available through a web interface.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Setup and maintenance: Setup requires a server, installing the application, and depending on how it should be accessible, possibly also domain and reverse proxy setup. This needs significantly more technical knowledge than the other options, but with ChatGPT (or others) it should be possible also for fairly non-technical people. This setup is generally more complex with more failure points than the other options, but with a correct setup failures happen rarely, if at all.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data control and storage: The application stores data on the server it runs on. Since users control their server, they also have total control over the data stored on it. Applications typically use well-established databases, which allows users to inspect and change data with common tools. The amount of data that can be stored is only limited by the available storage on the server. Most servers start at 20 GB, which is enough for most feed reading use-cases. Often, storage can be dynamically extended if more space is needed.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Feed fetching: Feeds are fetched on the server. Since it runs continuously, there is no break in feed fetching, and even high frequency feeds are no problem.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Availability: The application and all its data is accessible from any device with a web browser by navigating to the server's URL. Data is stored on the server, therefore automatically synced between all devices that use it, but also require internet access.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Functionality: On average self-hosted products have a wider feature set than browser extension or on-device feed readers. There is no theoretical limit on the feature set, but typically they keep the infrastructure as simple as possible, to keep setup and maintenance straightforward. This makes them slightly less powerful than hosted alternatives.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Products&lt;/head&gt;
    &lt;p&gt;Self-hosted products are all open-source and free. The only costs are for the server, and the cheapest VPS plans start at ~2$/month.&lt;/p&gt;
    &lt;head rend="h3"&gt;Hosted&lt;/head&gt;
    &lt;p&gt;Hosted feed readers are managed services. It's required to create an account to get access to them. All of them are paid SAAS products, and most offer a free plan.&lt;/p&gt;
    &lt;p&gt;On average they have the most polished user experience and most comprehensive feature sets, since they're backed by companies that invest in continuous development.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Setup and maintenance: Beyond creating an account, no setup is required. The same for maintenance. Service providers make sure the products work as intended, and deal with everything required to keep the service running, including infrastructure setup, monitoring, backups, etc.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data control and storage: Since data is stored on the servers and databases of the company running the product, users don't have direct control. But through laws like GDPR users have the right to export all their data, or request deletion. Storage is essentially unlimited, though most products have limits to avoid abuse. These limits are mentioned on their pricing page.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Feed fetching: Similar to self-hosted products, feeds are fetched on the server, which runs continuously and ensures that even high-frequency feeds don't pose a problem. The fetching interval is usually dynamic, based on the popularity of a feed and the publishing frequency.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Availability: Hosted products are primarily available as web application, and some offer native apps as well. Since data is stored on the server, it's natively synced between devices. Some hosted feed readers also offer offline support.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Functionality: Hosted feed readers serve many customers at the same time, which makes it necessary to have more complex infrastructure setups. This also enables features that other types of products cannot do, like email receiving, recommendations, or historic feed contents. Consequently hosted options are generally more powerful than other categories, though the specific feature set depends on the product.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Products&lt;/head&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell role="head"&gt;Free&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (one-time)&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (SAAS)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;All hosted products are SAAS products and charge monthly. &lt;code&gt;Folo&lt;/code&gt; is an outlier, they currently don't have any paid features, but the terms of service indicate that this will come in the future. At that point it will join the others in the &lt;code&gt;Paid (SAAS)&lt;/code&gt; category.&lt;/p&gt;
    &lt;head rend="h2"&gt;App support and offline access for products that don't offer it natively&lt;/head&gt;
    &lt;p&gt;Many of the self-hosted or hosted products don't provide apps or offline access by themselves. However, with the right setup, it's still possible to access the articles offline.&lt;/p&gt;
    &lt;p&gt;Most of these products provide APIs. This can be a proprietary API, or an API based on the old Google Reader API.&lt;/p&gt;
    &lt;p&gt;Mobile apps, for example ReadKit or Fiery Feeds, can not only subscribe to feeds, but also connect to other products through their APIs. They download contents, store them locally, and sync changes back to the connected products.&lt;/p&gt;
    &lt;p&gt;These apps make it possible to use a native mobile app for products that don't provide an app themselves, and get offline access at the same time.&lt;/p&gt;
    &lt;p&gt;FreshRSS, for example, has a list of native apps that support it.&lt;/p&gt;
    &lt;head rend="h2"&gt;A note on newsletters&lt;/head&gt;
    &lt;p&gt;Newsletters are a growing mechanism for delivering (blog) content. Some, but not all, hosted feed readers support newsletters out of the box. But on-device products can't do that at all because of their infrastructure limitations.&lt;/p&gt;
    &lt;p&gt;Even if a feed reader doesn't support newsletters by itself, it's still possible to get newsletters into the feed reader, through services that convert newsletters into RSS feeds.&lt;/p&gt;
    &lt;p&gt;These services generate an email address and give you a corresponding feed URL. Emails to the generated address are added to the feed as new entry. So after signing up to the newsletter and adding the feed URL, the newsletter is added to the feed reader even without native email support.&lt;/p&gt;
    &lt;p&gt;Services that do this are Kill the Newsletter and the Lighthouse Newsletter to RSS tool. Both are free.&lt;/p&gt;
    &lt;head rend="h2"&gt;Products&lt;/head&gt;
    &lt;p&gt;The descriptions highlight the defining and unique aspects of the products, for the full feature list please go to their respective websites. Where available I used the screenshots for their websites, to represent the products as best as possible (test account screenshots wouldn't be as good).&lt;/p&gt;
    &lt;head rend="h3"&gt;NetNewsWire (on-device, free)&lt;/head&gt;
    &lt;p&gt;NetNewsWire is a free, on-device feed reader for Mac and iOS. By default it stores data on the device itself, but can sync via iCloud and using other products as storage. And it provides a Safari extension for easy feed-adding. Notably, it supports AppleScript, which makes it possible to automate certain workflows.&lt;/p&gt;
    &lt;head rend="h3"&gt;Fiery Feeds (on device, paid SAAS)&lt;/head&gt;
    &lt;p&gt;Fiery feeds is a Mac and iOS app. The download is free, and to get the premium features it costs ~15$/year (varies by region). By default it stores data on the device itself, but can sync via iCloud and using the API of other products (e.g. FreshRSS). The main distinguishing features are the customization options of the app, like custom themes.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reeder (on-device, SAAS)&lt;/head&gt;
    &lt;p&gt;The current version of Reeder is a Mac and iOS app. The download is free, and to get the premium features it costs ~10$/year. The previous version of Reeder, now called Reeder Classic, is still available as one-time purchase. It also stores data on-device, and can sync via iCloud.&lt;/p&gt;
    &lt;p&gt;The main distinguishing feature is the unified timeline, which includes RSS, podcasts, social media, and more.&lt;/p&gt;
    &lt;head rend="h3"&gt;FreshRSS (self-hosted, free)&lt;/head&gt;
    &lt;p&gt;FreshRSS is a self-hosted feed reader and once set up, it's available as a web app. It is quite powerful, and in addition to normal feed subscriptions offers WebSub as well. It's possible to customize it with themes and extensions, and it's translated into more than 15 languages.&lt;/p&gt;
    &lt;p&gt;Together with Miniflux they're the most-recommended self-hosted options.&lt;/p&gt;
    &lt;head rend="h3"&gt;Miniflux&lt;/head&gt;
    &lt;p&gt;Miniflux is a self-hosted feed reader as well, and available as web app after setup. It's focus is on staying simple and fast instead of adding fancy features. It also offers a hosted version, which is 15$/year and has a 15 day trial period.&lt;/p&gt;
    &lt;p&gt;Together with FreshRSS they're the most-recommended self-hosted options.&lt;/p&gt;
    &lt;head rend="h3"&gt;Folo (hosted, free)&lt;/head&gt;
    &lt;p&gt;Folo is a relatively new product developed by the creators of RSS Hub. It's a free hosted feed reader, with apps available for every major platform. Their terms of service suggest that at some point they will charge a monthly fee for some premium features, but at the time of writing there were no paid features.&lt;/p&gt;
    &lt;p&gt;Folo is also open-source and therefore theoretically self-hostable, but I haven't found documentation for it.&lt;/p&gt;
    &lt;p&gt;It has a huge feature set, including newsletter support, transforming websites into feeds, AI summaries, and much more.&lt;/p&gt;
    &lt;head rend="h3"&gt;Feedly (hosted, SAAS)&lt;/head&gt;
    &lt;p&gt;Feedly is the most widely-known product and has the most users of all feed readers. It has a comprehensive features set, and offers a free plan as well. For the past couple of years, it seems that Feedly has focused more on AI features and enterprise customers, but their core product remains solid.&lt;/p&gt;
    &lt;head rend="h3"&gt;Inoreader&lt;/head&gt;
    &lt;p&gt;Inoreader is the second most widely-known product, after Feedly. It too offers a free plan. Their feature list is impressive, with social media support for subscriptions, automation and AI features, public API and integrations. And of course much more.&lt;/p&gt;
    &lt;p&gt;What stands out on Reddit are complaints about price hikes. Though Inoreader probably has tens or hundreds of thousands of users who don't have issues and think the product is great.&lt;/p&gt;
    &lt;head rend="h3"&gt;Readwise Reader&lt;/head&gt;
    &lt;p&gt;Readwise Reader is a relatively new product, from the creators of the original Readwise. It's a great feed reader, though were it really shines is the reading experience. They also have reading views for PDFs, eBooks, and more.&lt;/p&gt;
    &lt;p&gt;The website mentions that it's in beta, but it has been in beta for years now and at this point is a stable product, and has been for awhile.&lt;/p&gt;
    &lt;head rend="h3"&gt;Tiny Tiny RSS&lt;/head&gt;
    &lt;p&gt;Tiny Tiny RSS deserves an honorable mention in this list. It was, and still is, used by many, and has been for a long time, and was often recommended on the RSS subreddit.&lt;/p&gt;
    &lt;p&gt;On October 3rd the maintainer announced that he's going to stop working on it, and will remove all infrastructure on November 1st. Forks of the project with other maintainers may pop up, but at the moment it's too soon to tell what the future of Tiny Tiny RSS will be.&lt;/p&gt;
    &lt;head rend="h3"&gt;Lighthouse&lt;/head&gt;
    &lt;p&gt;Lighthouse is also a relatively new product. It's in beta, which refers to the fact that it doesn't yet have all features necessary to fulfill its vision, which goes beyond simple feed reading.&lt;/p&gt;
    &lt;p&gt;The main differentiator is that it focuses on articles over feeds, and has a separate view for curating articles (the inbox). It's focused on finding high-value content.&lt;/p&gt;
    &lt;head rend="h2"&gt;Similar product categories&lt;/head&gt;
    &lt;p&gt;Feed readers are powerful products, which require manual setup to make them work well. Subscribing to feeds is mandatory, adding tags, filtered views, and rules can make them work even better. But for some use-cases, other product categories are simpler and might work better.&lt;/p&gt;
    &lt;head rend="h3"&gt;News aggregators&lt;/head&gt;
    &lt;p&gt;News aggregators automatically collect and curate news from a large variety of sources. They usually provide some customization options, but focus on news and don't allow arbitrary feed subscriptions like feed readers do.&lt;/p&gt;
    &lt;p&gt;They focus on providing an overview of the most relevant news stories.&lt;/p&gt;
    &lt;p&gt;Examples are Kagi News, Ground News, and SmartNews.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reading lists&lt;/head&gt;
    &lt;p&gt;Reading lists, also called read-it-later apps, are for saving and organizing links you found somewhere on the web. Many feed readers can do the same, but reading lists are optimized for that purpose.&lt;/p&gt;
    &lt;p&gt;Examples are Instapaper and Matter. Karakeep is a self-hosted option.&lt;/p&gt;
    &lt;head rend="h2"&gt;How to choose&lt;/head&gt;
    &lt;p&gt;For most people, going with one of the hosted products is the best option. They're generally the most polished and most powerful products, owing to the fact that they have companies behind them with full-time engineers. They generally also offer a free plan, so if you stay within the limits of those, they will even be free to use.&lt;/p&gt;
    &lt;p&gt;For more specific requirements, products of the other categories can work better. They have different characteristics, and can work better in some situations. For example, if you want total control over your data, self-hosted options are the way to go.&lt;/p&gt;
    &lt;p&gt;It's probably easiest to first decide on the category, and then check out multiple products, or maybe even try them out. Virtually all products support OPML import and export, so moving feed subscriptions from one product to the next is almost zero effort.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45517134</guid><pubDate>Wed, 08 Oct 2025 15:17:36 +0000</pubDate></item></channel></rss>