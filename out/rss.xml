<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sun, 21 Sep 2025 09:08:49 +0000</lastBuildDate><item><title>Lidar, optical distance and time of flight sensors</title><link>https://ams-osram.com/innovation/technology/depth-and-3d-sensing/lidar-optical-distance-and-time-of-flight-sensors</link><description>&lt;doc fingerprint="31a6f09c03f2415b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;LIDAR, optical distance &amp;amp; time of flight sensors&lt;/head&gt;
    &lt;p&gt;Fully integrated dToF modules and iToF VCSEL illuminators for short range applications. Laser sources for long range LIDAR systems.&lt;/p&gt;
    &lt;head rend="h2"&gt;Optical distance sensors&lt;/head&gt;
    &lt;p&gt;A range of approaches exist to directly measure distance as the length of the reflected optical path from laser, to a target where it is reflected, and back to a sensor. These are commonly known by various names, including LIDAR and time of flight sensors, although there is actually overlap in principles between them. &lt;lb/&gt; The main system types are summarized in the table below. They are principally defined by the following key parameters: &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Optical distance measurement principle: This is the method by which optical depth in the z dimension is measured. Main approaches are indirect Time of Flight (iToF), direct Time of Flight (dToF), and Frequency Modulated Continuous Wave (FMCW).&lt;/item&gt;
      &lt;item&gt;Scanning architecture: This is how the system measures multiple depth points across the x and y dimensions to create a 3D depth map. Main approaches here are either a single emitter with a sensor array, emitter array plus sensor array, and scanning mirror systems with only a single source/detector.&lt;/item&gt;
      &lt;item&gt;Optical aperture/power: There is a trade-off between optical power and aperture size, and achievable range. There are two key categories: Compact, low power short range systems, for example integrated modules with wafer level optics for consumer electronics; and larger longer-range systems built using discrete components, more powerful sources and larger aperture bulk optics.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;&lt;lb/&gt; All typically operate in the infrared spectrum. This enables interference from ambient light to be minimized by using a matching infrared bandpass filter at the receiver, and for the system to appear largely invisible to users. &lt;/p&gt;
    &lt;head rend="h2"&gt;Optical distance measurement principles&lt;/head&gt;
    &lt;head rend="h2"&gt;Direct Time of Flight (dToF)&lt;/head&gt;
    &lt;p&gt;The laser source is pulsed, and the time taken for each pulses to reflect and return to the sensor is measured. This time is then converted to distance using the speed of light. dToF systems enable robust and low power distance measurements. However, the receiver is typically implemented with a Single Photon Avalanche detector and timing circuit. Practical limits to the size of array that can be achieved for this limits the resolution for solid state systems to typically &amp;lt;100 depth points.&lt;/p&gt;
    &lt;head rend="h2"&gt;Indirect Time of Flight (iToF)&lt;/head&gt;
    &lt;p&gt;The laser source is amplitude modulated. The phase difference between the transmitted light, and the light reflected to the sensor, is measured. This phase difference is converted to time, and then to distance using the speed of light. The receiver can be implemented as part of a specialized image sensor, enabling high resolutions with no moving parts. However, iToF is vulnerable to crosstalk and multipath interference, making it less robust than dToF systems. It is typically only used in short range, high resolution, systems.&lt;/p&gt;
    &lt;head rend="h2"&gt;Frequency Modulated Continuous Wave (FMCW)&lt;/head&gt;
    &lt;p&gt;The laser source is CW and frequency modulated with a sawtooth waveform (‚ÄúChirp‚Äù). The reflected signal is optically mixed with a reference from the source. The resulting signal then contains a ‚Äúbeat‚Äù frequency corresponding to distance, that is extracted by spectral analysis. FMCW has robustness and performance advantages compared to dToF, including long range, low emitter power, high immunity to ambient light and the ability to directly measure radial velocity. However, for reasons of optical complexity, it is typically only deployed for more specialist systems at present.&lt;/p&gt;
    &lt;head rend="h2"&gt;Scanning architectures&lt;/head&gt;
    &lt;head rend="h2"&gt;Single emitter + detector array&lt;/head&gt;
    &lt;p&gt;The most common approach for solid state iToF and dToF systems uses a single flood illuminator, and a detector array. In the case of short range modules the emitter is a VCSEL with diffuser optics to achieve the required field of view, and matching imaging optics on the detector. Longer range ‚Äúflash LIDAR‚Äù systems use the dToF approach with a higher power VCSEL array or Edge Emitting laser source, plus larger apertures on each side.&lt;/p&gt;
    &lt;head rend="h2"&gt;Emitter array + detector array&lt;/head&gt;
    &lt;p&gt;The performance of dToF / flash LIDAR systems is limited by several practical factors. In order to remain eye safe, there is a limit to the maximum optical power that can be transmitted, and this impacts range. Furthermore, a time detection circuit is required for each depth point, limiting the practically achievable resolution. True Solid State (TSS) Lidar systems address these issues by sequentially illuminating different parts of the scene using a pixelated emitter array. This allows the available optical power to be more focused for each pulse, and allows pixel TDCs to be shared. However, it comes at the expense of additional transmit complexity.&lt;/p&gt;
    &lt;head rend="h2"&gt;Scanning mirrors&lt;/head&gt;
    &lt;p&gt;The longest-range LIDAR systems use a single source and detector, and scan it across the scene. This approach enables range to be optimized by use of a focused source and high fidelity time detection. In addition, with just a single channel, the more complex but high performance approach of FMCW can also be deployed. Various scanning configurations are possible, including two dimensional scanning with a MEMs mirror, and one dimensional scanning using a rotating polygon mirror.&lt;/p&gt;
    &lt;head rend="h2"&gt;Direct Time of Flight sensor modules&lt;/head&gt;
    &lt;p&gt;ams OSRAM offers fully integrated direct Time of Flight sensor modules. These compact and low power devices integrate a 940nm VCSEL (laser), a SPAD (Single Photon Avalanche Photodiode) pixel array, Time-to-Digital Converters (TDCs), and all the necessary signal processing to give a direct readout of distance over I2C. &lt;lb/&gt; Single and multi zone devices up to 8x8 are available in package sizes down to 2.2x3.6x1.0mm, with operating ranges and field of view up to 5m and 63 degrees. &lt;lb/&gt; Applications include autofocus for cameras and projectors, obstacle detection for robotics and drones, low power wakeup for camera systems, touchless controls and hand gesture sensing. &lt;lb/&gt; For more Information, see our white paper: understanding time of flight sensing. &lt;/p&gt;
    &lt;head rend="h2"&gt;VCSELs and VCSEL Modules for Indirect Time of Flight sensing&lt;/head&gt;
    &lt;p&gt;ams OSRAM offers a wide range of infrared VCSELs and VCSEL modules at 850nm and 940nm for iToF systems. For example, our&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;BIDOS‚Ñ¢ P2433 VCSEL modules deliver up to 6.5W in a 2.4 x 3.3 x 1.2 mm package with integrated photodiode and fields of view of 60¬∞x45¬∞ and 72¬∞x58¬∞.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;&lt;lb/&gt; Full iToF system reference designs are available from our partners:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;KEA Time of Flight Camera Development Kit from Chronoptics (pictured) features our BIDOS VCSEL illuminators at 940nm, and comprises a complete solution to accelerate and simplify the integration of 3D depth sensing into products.&lt;/item&gt;
      &lt;item&gt;Melexis EVK75027 iToF evaluation kit features our automotive qualified TARA-2000-AUT-SAFE VCSEL illuminator. It demonstrates a complete VGA depth camera system for in cabin monitoring and gesture sensing. Further details of the eye safe illumination system implementation can be found in this white paper.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;VCSELs and EELs for long range LIDAR&lt;/head&gt;
    &lt;p&gt;ams OSRAM offers both VCSEL and edge emitting Lasers (EEL) for use in pulsed operation mode in LIDAR systems. Both types of lasers are provided in different configurations, like VCSEL arrays or single to multichannel edge emitting lasers, as well as several power levels for a variety of system and optical design approaches. Thanks to our proprietary wavelength stabilization technology for edge emitting lasers, these emitters now provide a low temperature-dependent wavelength shift on a similar level as VCSEL. &lt;lb/&gt; Our products include: &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;SPL S4L90A_3 The flagship of ams OSRAM‚Äôs LiDAR portfolio: 4 Channel SMT Laser in QFN package, wavelength stabilized, 905 nm, 220 ¬µm, AEC-Q102&lt;/item&gt;
      &lt;item&gt;SPL S1L90A_3 1 Channel SMT laser in QFN package, 905 nm, 125 W 220 ¬µm&lt;/item&gt;
      &lt;item&gt;SPL DP90_3 Nanostack pulsed laser diode, 905 nm, 65W, 110 ¬µm, AEC-Q102&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45292915</guid><pubDate>Thu, 18 Sep 2025 18:05:58 +0000</pubDate></item><item><title>MapSCII ‚Äì World map in terminal</title><link>https://github.com/rastapasta/mapscii</link><description>&lt;doc fingerprint="ecc3b87ab9807886"&gt;
  &lt;main&gt;
    &lt;p&gt;A node.js based Vector Tile to Braille and ASCII renderer for xterm-compatible terminals.&lt;/p&gt;
    &lt;code&gt;$ telnet mapscii.me&lt;/code&gt;
    &lt;p&gt;If you're on Windows, use the open source telnet client PuTTY to connect.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Use your mouse to drag and zoom in and out!&lt;/item&gt;
      &lt;item&gt;Discover Point-of-Interests around any given location&lt;/item&gt;
      &lt;item&gt;Highly customizable layer styling with Mapbox Styles support&lt;/item&gt;
      &lt;item&gt;Connect to any public or private vector tile server&lt;/item&gt;
      &lt;item&gt;Or just use the supplied and optimized OSM2VectorTiles based one&lt;/item&gt;
      &lt;item&gt;Work offline and discover local VectorTile/MBTiles&lt;/item&gt;
      &lt;item&gt;Compatible with most Linux and OSX terminals&lt;/item&gt;
      &lt;item&gt;Highly optimized algorithms for a smooth experience&lt;/item&gt;
      &lt;item&gt;100% pure JavaScript! üòé&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With a modern node installation available, just start it with&lt;/p&gt;
    &lt;code&gt;npx mapscii
&lt;/code&gt;
    &lt;p&gt;If you haven't already got Node.js &amp;gt;= version 10, then go get it.&lt;/p&gt;
    &lt;code&gt;npm install -g mapscii
&lt;/code&gt;
    &lt;p&gt;If you're on OSX, or get an error about file permissions, you may need to do &lt;code&gt;sudo npm install -g mapscii&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;In any of the supported Linux distros:&lt;/p&gt;
    &lt;code&gt;sudo snap install mapscii
&lt;/code&gt;
    &lt;p&gt;(This snap is maintained by @nathanhaines)&lt;/p&gt;
    &lt;p&gt;This is pretty simple too.&lt;/p&gt;
    &lt;code&gt;mapscii
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Arrows up, down, left, right to scroll around&lt;/item&gt;
      &lt;item&gt;Press a or z to zoom in and out&lt;/item&gt;
      &lt;item&gt;Press c to switch to block character mode&lt;/item&gt;
      &lt;item&gt;Press q to quit&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If your terminal supports mouse events you can drag the map and use your scroll wheel to zoom in and out.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;x256&lt;/code&gt;for converting RGB values to closest xterm-256 color code&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;term-mouse&lt;/code&gt;for mouse handling&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;keypress&lt;/code&gt;for input handling&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;string-width&lt;/code&gt;to determine visual string lengths&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;vector-tile&lt;/code&gt;for VectorTile parsing&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;pbf&lt;/code&gt;for Protobuf decoding&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;mbtiles&lt;/code&gt;for MBTiles parsing&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;earcut&lt;/code&gt;for polygon triangulation&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rbush&lt;/code&gt;for 2D spatial indexing of geo and label data&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;bresenham&lt;/code&gt;for line point calculations&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;simplify-js&lt;/code&gt;for polyline simplifications&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;node-fetch&lt;/code&gt;for HTTP requests&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;env-paths&lt;/code&gt;to determine where to persist downloaded tiles&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;MapSCII&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;GeoJSON support via geojson-vt&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;CLI support&lt;/p&gt;
            &lt;list rend="ul"&gt;
              &lt;item&gt;[-] startup parameters &lt;list rend="ul"&gt;&lt;item&gt;TileSource&lt;/item&gt;&lt;item&gt;Style&lt;/item&gt;&lt;item&gt;center position&lt;/item&gt;&lt;item&gt;zoom&lt;/item&gt;&lt;item&gt;demo mode?&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
          &lt;item&gt;[-] startup parameters &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;mouse control&lt;/p&gt;
            &lt;list rend="ul"&gt;
              &lt;item&gt;hover POIs/labels&lt;/item&gt;
              &lt;item&gt;hover maybe even polygons/-lines?&lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Styler&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;respect zoom based style ranges&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Renderer&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;TileSource&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;implement single vector-tile handling&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;lukasmartinelli &amp;amp; manuelroth for all their work on OSM2VectorTiles (global vector tiles from OSM Planet)&lt;/item&gt;
      &lt;item&gt;mourner for all his work on mindblowing GIS algorithms (like the used earcut, rbush, simplify-js, ..)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;OpenStreetMap is open data, licensed under the Open Data Commons Open Database License (ODbL) by the OpenStreetMap Foundation (OSMF).&lt;/p&gt;
    &lt;p&gt;You are free to copy, distribute, transmit and adapt our data, as long as you credit OpenStreetMap and its contributors. If you alter or build upon our data, you may distribute the result only under the same licence. The full legal code explains your rights and responsibilities.&lt;/p&gt;
    &lt;p&gt;The cartography in our map tiles, and our documentation, are licenced under the Creative Commons Attribution-ShareAlike 2.0 licence (CC BY-SA).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45293012</guid><pubDate>Thu, 18 Sep 2025 18:12:58 +0000</pubDate></item><item><title>PYREX vs. pyrex: What's the difference?</title><link>https://www.corning.com/worldwide/en/products/life-sciences/resources/stories/in-the-field/pyrex-vs-pyrex-whats-the-difference.html</link><description>&lt;doc fingerprint="bc309c5290c9256b"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;head rend="h2"&gt;PYREX vs pyrex Construction Differences&lt;/head&gt;
      &lt;p&gt;Corning used borosilicate to produce all Pyrex products. However, the company that purchased the cookware products switched to soda-lime glass, adopting the name pyrex (spelled with all lowercase letters).&lt;/p&gt;
      &lt;p&gt;Corning continued to make its lab tools with borosilicate, dubbing these products to be PYREX (spelled with all uppercase letters). Borosilicate glassware can sustain the large, sudden temperature changes that frequently occur in labs without shattering. These products are also less likely to react to chemicals.&lt;/p&gt;
      &lt;p&gt;Corning sold the consumer products or cookware business in 1998. The new owner, known as Borden at the time, later rebranding to World Kitchen in 2000, recognized that the cookware didn't need to be quite as strong, and ‚Äî to make it accessible to the average customer ‚Äî it needed to be more affordable. With this in mind, they switched the cookware to soda-lime glass, a less expensive component. Soda-lime glass, now called pyrex, isn't as resistant to thermal shock, but it is durable enough for everyday cooking.&lt;/p&gt;
      &lt;head rend="h2"&gt;Benefits of PYREX Labware&lt;/head&gt;
      &lt;p&gt;PYREX labware is designed to meet the rigorous demands of scientific experimentation. In fact, these scientific glassware products were integral in developing penicillin during World War II and the polio vaccine during the 1950s.&lt;/p&gt;
      &lt;p&gt;Corning laboratory glassware products have long been manufactured to meet the quality and reliability standards created by the American Society for Testing and Materials (ASTM). Corning advanced its quality control for accuracy and precision further by testing its volumetric glassware in an ISO/IEC 17025 accredited laboratory.&lt;/p&gt;
      &lt;p&gt;PYREX glass is well-suited for lab work because Corning uses borosilicate to produce beakers, flasks, test tubes, and other lab glassware. PYREX lab glassware made with borosilicate can withstand harsh, corrosive chemicals, handle extremely low and high temperatures, and it can survive rapid temperature changes without sustaining damage. PYREX beakers, Erlenmeyer flasks, and round- and flat-bottom boiling flasks can be repeatedly heated up to 230¬∫C. PYREX volumetric laboratory ware can be brought to 150¬∫C. Overall, PYREX laboratory glassware has a temperature shock limit ‚Äî or allowable difference between the temperature of the glass and any medium in contact with the glass (air, liquid, or solid) ‚Äî of 160¬∫C.&lt;/p&gt;
      &lt;p&gt;Always check laboratory glassware for any cracks, scratches, chips, or hazing ‚Äî these damages can cause the product to break while in use. If properly cleaned and not damaged, PYREX laboratory glassware is reusable.&lt;/p&gt;
      &lt;head rend="h2"&gt;Unique Cleaning Procedures for PYREX Lab Glassware&lt;/head&gt;
      &lt;p&gt;Despite being made of a strong, durable material, PYREX lab glassware requires specific care and maintenance. Ignoring the specific cleaning differences of PYREX labware can undermine the glassware's integrity and stability. If handled improperly, these products could shatter when exposed to high temperatures.&lt;/p&gt;
      &lt;p&gt;Always clean PYREX products with a non-abrasive glassware detergent either by hand or in a dishwasher. Do not exceed temperatures above 110¬∞C during the cleaning process. Do not use abrasive brushes or scrubbing pads that can scratch the glass or its coating. In addition, limit exposure to any aldehydes, ketones, chlorinated solvents, or concentrated acids, because they can damage the glassware.&lt;/p&gt;
      &lt;p&gt;For over 100 years, Corning has been a trailblazer in creating innovative glassware products that can reliably and repeatedly meet users' needs. These products have accelerated scientific discoveries and enhanced human health.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45310995</guid><pubDate>Sat, 20 Sep 2025 06:37:01 +0000</pubDate></item><item><title>Writing a competitive BZip2 encoder in Ada from scratch in a few days ‚Äì part 3</title><link>https://gautiersblog.blogspot.com/2025/09/writing-competitive-bzip2-encoder-in.html</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=45312202</guid><pubDate>Sat, 20 Sep 2025 10:55:53 +0000</pubDate></item><item><title>FLX1s phone is launched</title><link>https://furilabs.com/flx1s-is-launched/</link><description>&lt;doc fingerprint="dfe351495ea32377"&gt;
  &lt;main&gt;
    &lt;p&gt;It is with great excitement that we can now release the FLX1s. Pre-sales are open and the phone is in production which is due to complete end of October 2025. Following that we can start shipping. Existing orders will be opted into the FLX1s or refunded.&lt;lb/&gt;To all our amazing FLX1 owners and those waiting patiently for their order, you have been the most wonderful and supportive community that we could ever have imagined.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;Thank-you from the FuriLabs Team.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45312326</guid><pubDate>Sat, 20 Sep 2025 11:20:04 +0000</pubDate></item><item><title>Images over DNS</title><link>https://dgl.cx/2025/09/images-over-dns</link><description>&lt;doc fingerprint="fec80dd7a0729493"&gt;
  &lt;main&gt;
    &lt;p&gt;What's the limit of what can be in a TXT record?&lt;/p&gt;
    &lt;p&gt;Some places say 255 bytes. They are wrong. Within a TXT record there are multiple character-strings (RFC 1035 section 3.3.14) and those are limited in length (because a single byte is used for their length), however there can be many of them.&lt;/p&gt;
    &lt;p&gt;The actual limit is limited by the size of the DNS payload, which for UDP is these days around 1232 bytes. That is obviously quite low. However if we use TCP, which doesn't require anything special, other than the normal fallback to TCP that DNS does, then we can serve up to 64KB.&lt;/p&gt;
    &lt;p&gt;I set out to demonstrate exactly that, by using Google Public DNS's JSON API and then serving large TXT responses over TCP, from a custom server.&lt;/p&gt;
    &lt;p&gt;This mostly just works, the main issue is not with the length, but with binary data, because JSON isn't really designed to handle binary data. Therefore there is some slightly custom JSON parsing. Using raw binary data in a TXT record avoids the overhead of Base64 or another encoding, meaning more data can be packed in.&lt;/p&gt;
    &lt;p&gt;üëâ See it in action. For more read the comments in image.html.&lt;/p&gt;
    &lt;head rend="h2"&gt;Non-browser&lt;/head&gt;
    &lt;p&gt;It is possible to query this via dig. Although turning it back into binary output is a bit tricky, as the presentation form of DNS responses is escaped for output.&lt;/p&gt;
    &lt;p&gt;You can retrieve the data with dig and a little Perl to unescape and combine the character sequences:&lt;/p&gt;
    &lt;code&gt;$ dig +short dog.log.battery.st TXT | perl -pe'chomp; s/" "//g; s/^"//; s/"$//; s/\\(\d{3})/chr $1/eg; s/\\([\\"])/$1/g' &amp;gt; dog.avif
$ sha256sum dog.avif
7058fbd20ef2af84d5efb0ae7d91f87ce7a912380636c468b32f2c759cbb9130  dog.avif
&lt;/code&gt;
    &lt;p&gt;(This is actually just a modified version of the Perl one liner from my Wikipedia over DNS from 2008, nothing changes.)&lt;/p&gt;
    &lt;p&gt;Because the web version uses Google's JSON resolver we know it doesn't have problems querying very large TXT records, however your local recursor may not support this. If it doesn't work you can add &lt;code&gt;@dns.google&lt;/code&gt; to the dig command
line to send the query to Google's Public DNS servers (or any other open
recursor, &lt;code&gt;@9.9.9.9&lt;/code&gt; seems to work too).&lt;/p&gt;
    &lt;head rend="h2"&gt;Why?&lt;/head&gt;
    &lt;p&gt;I thought it was a cute hack when I realised it was possible.&lt;/p&gt;
    &lt;p&gt;For those interested in security there is a consideration here, attackers have long tunnelled over DNS, but tunnelling large payloads to a browser is potentially something new. Because Google Public DNS has a certificate that includes &lt;code&gt;8.8.8.8&lt;/code&gt; and so on, HTTPS
traffic can go directly from a browser without a DNS lookup. This may be
unexpected in environments that use DNS filtering. This is something that will
become more common once Lets Encrypt fully rolls out IP address
certificates,
the difference here is piggybacking on an existing IP address certificate.&lt;/p&gt;
    &lt;p&gt;This deliberately uses a low TTL (10 seconds) to avoid filling DNS recursor's caches with useless content. It would be possible to increase this and therefore get caching from the recursors, a bit like a free distributed CDN (although I suspect if someone actually did this they would adaptively limit TTLs, if something like that isn't already done).&lt;/p&gt;
    &lt;head rend="h2"&gt;Server side&lt;/head&gt;
    &lt;p&gt;The server is a custom Go DNS server. To be honest it was written by ChatGPT because it's not that clever, the idea is what matters. (Although ChatGPT did get some details like truncation wrong so I fixed the code myself.)&lt;/p&gt;
    &lt;p&gt;All the code is here. AI was only used for the server component, this blog post and the client HTML code is my own work.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45312515</guid><pubDate>Sat, 20 Sep 2025 11:50:15 +0000</pubDate></item><item><title>Vapor chamber tech keeps iPhone 17 Pro cool</title><link>https://spectrum.ieee.org/iphone-17-pro-vapor-chamber</link><description>&lt;doc fingerprint="9533a64f32e316ed"&gt;
  &lt;main&gt;
    &lt;p&gt;On 9 September, Apple introduced its newest lineup, including the iPhone 17 series. Much of the attention went to a new ultrathin model and a bright orange color option (a shade not dissimilar to that of the IEEE Spectrum logo). The new smartphones will also ship with the latest operating system and its ‚ÄúLiquid Glass‚Äù software design‚Äîbut the liquid in these phones goes beyond software.&lt;/p&gt;
    &lt;p&gt;The iPhone 17 Pro and iPhone 17 Pro Max contain thin, hermetically sealed chambers with a drop of water inside that cycles between liquid and gas to help dissipate heat. Known as vapor chambers, the cooling system is becoming more common in smartphones built for sustained high performance. Some high-end Samsung Galaxy and Google Pixel models, among others, have introduced vapor-chamber cooling in the past few years. Now, Apple is following their lead.&lt;/p&gt;
    &lt;p&gt;‚ÄúCooling of smaller portables like phones must focus on spreading heat as widely as possible to the surface of the device, with particular attention to heat-generating components, like the chip,‚Äù says Kenneth Goodson, a professor of mechanical engineering at Stanford who specializes in heat transfer and energy conversion. To cool down those hot spots, the industry seems to be moving toward vapor chambers and other phase-change technology.&lt;/p&gt;
    &lt;head rend="h2"&gt;How vapor chambers keep phones cool&lt;/head&gt;
    &lt;p&gt;The standard approach to cooling smartphones uses a solid, highly conductive plate made from a material like copper to spread heat. This approach relies on having a surface where heat can spread. Sometimes, fins are added to extend that surface, but this can lead to a thicker device. Most companies, however, are intent on making thinner and thinner phones.&lt;/p&gt;
    &lt;p&gt;Phase-change technology‚Äîwhich has been used in laptops for decades, Goodson notes‚Äîachieves the same goal more effectively with fluid that boils and condenses to dissipate heat. These two-phase solutions include vapor chambers, like those used in the new iPhone, as well as narrow, fingerlike structures called heat pipes.&lt;/p&gt;
    &lt;p&gt;Phones have limited volume to work with, and ‚Äúperformance per volume is critical,‚Äù says Victor Chiriac, the CEO and cofounder of Global Cooling Technology Group, based in Phoenix. Thin and wide vapor chambers have a high heat-removal capacity and offer an effective solution. The cycle between liquid and vapor is ‚Äúa powerful mechanism for absorbing heat,‚Äù he says.&lt;/p&gt;
    &lt;p&gt;Apple‚Äôs vapor chamber efficiently spreads heat across the phone‚Äôs body.Apple&lt;/p&gt;
    &lt;p&gt;In Apple‚Äôs version, a small amount of deionized water is sealed in the chamber. The water evaporates when near heat sources, then condenses back into a liquid when the heat dissipates into the phone‚Äôs surrounding aluminum body. Water is often used in vapor chambers, though sometimes other materials are mixed in to prevent it from freezing and cracking the seal, Chiriac says.&lt;/p&gt;
    &lt;head rend="h2"&gt;Vapor-chamber manufacturing faces challenges&lt;/head&gt;
    &lt;p&gt;As Apple, Samsung, and others push the boundaries of how thin phones can get, manufacturing vapor chambers may become a challenge. While solid materials can easily be shaved down, these chambers need to have enough space for coolant to travel through channels. The chambers have to be perfectly sealed in order to work properly, and ‚Äúthe thinner you make it, the less space you have for that secret sauce to do its thing,‚Äù Chiriac says.&lt;/p&gt;
    &lt;p&gt;It comes down to physics: ‚ÄúA big challenge in small devices like phones is that as you scale down the thickness of a vapor chamber, the fluid physics aggressively scale back their performance relative to copper and other solid heat conductors,‚Äù Goodson explains. (This is a problem that researchers, including his students, are working to address with new microstructures.) Plus, vapor chambers tend to be expensive to manufacture.&lt;/p&gt;
    &lt;p&gt;Still, Apple and other companies have decided to invest in this technology for their most powerful phone models. Goodson suspects part of that decision is to leverage the ‚Äúwow‚Äù factor. But, he says, ‚Äúwith time this approach will likely become an industry standard.‚Äù&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;All-Silicon ‚ÄúFan-on-a-Chip‚Äù Keeps Thin Devices Cool ‚Ä∫&lt;/item&gt;
      &lt;item&gt;Superslim Liquid Loop Will Keep Future Smartphones Cool ‚Ä∫&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Gwendolyn Rak is an assistant editor at IEEE Spectrum covering consumer electronics and careers. She holds a master‚Äôs degree in science journalism from New York University and a bachelor‚Äôs degree in astrophysics and history from Swarthmore College.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45313415</guid><pubDate>Sat, 20 Sep 2025 13:50:58 +0000</pubDate></item><item><title>Ultrasonic Chef's Knife</title><link>https://seattleultrasonics.com/</link><description>&lt;doc fingerprint="c4ae7ddc24d05992"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;head rend="h2"&gt;The World's First&lt;/head&gt;&lt;lb/&gt;Ultrasonic Chef's Knife&lt;lb/&gt;For Home Cooks&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;head rend="h2"&gt;Switch on the ultrasonics and feel the blade glide effortlessly through food. Clean cuts, minimal force, less sticking.&lt;/head&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Regular price $399.00 &lt;/p&gt;
    &lt;p&gt; Regular price &lt;del class="price-item price-item--regular" data-product-id="7320581177440" rend="overstrike"&gt; $399.00 &lt;/del&gt; Sale price $399.00 &lt;/p&gt;
    &lt;p&gt;Pre-Order now for estimated shipping by January, 2026 (Batch 1). Cancel anytime before your order ships. What is a Pre-Order?&lt;/p&gt;
    &lt;p&gt;Regular price $499.00 &lt;/p&gt;
    &lt;p&gt; Regular price &lt;del class="price-item price-item--regular" data-product-id="7497201942624" rend="overstrike"&gt; $548.00 &lt;/del&gt; Sale price $499.00 &lt;/p&gt;
    &lt;p&gt;Pre-Order now for estimated shipping by January 2026 (Batch 1). Cancel anytime before your order ships. What is a Pre-Order?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45314592</guid><pubDate>Sat, 20 Sep 2025 16:12:56 +0000</pubDate></item><item><title>Designing NotebookLM</title><link>https://jasonspielman.com/notebooklm</link><description>&lt;doc fingerprint="bf50da1b9d312eaa"&gt;
  &lt;main&gt;
    &lt;p&gt;User Journey √¢¬¢ Annotated Overview&lt;/p&gt;
    &lt;p&gt;Home&lt;/p&gt;
    &lt;p&gt;Next&lt;/p&gt;
    &lt;p&gt;Jason Spielman&lt;/p&gt;
    &lt;p&gt;Design Lead&lt;/p&gt;
    &lt;p&gt;UX + Identity&lt;/p&gt;
    &lt;p&gt;2024&lt;/p&gt;
    &lt;p&gt;I led design for NotebookLM, shaping the product√¢s core user experience, brand identity, and visual system from experiment to launch.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;This remains one of my proudest projects, and I√¢m incredibly grateful for the opportunity to design something entirely new from the ground up. It was a chance to explore fresh paradigms, invent new patterns, and bring a product to life that hadn√¢t existed before. None of it would√¢ve been possible without the tight-knit, cross-functional team I was fortunate to collaborate with.&lt;/p&gt;
    &lt;p&gt;Podcast √¢¬¢ Sequoia&lt;/p&gt;
    &lt;p&gt;Raiza and I discuss the journey building NotebookLM.&lt;/p&gt;
    &lt;p&gt;NotebookLM √¢¬¢ Winner!&lt;/p&gt;
    &lt;p&gt;Recognized as one of TIME√¢s Best Inventions of 2024.&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Architecture&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;3 Panel&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Visual Assets&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Architecture&lt;/p&gt;
    &lt;p&gt;UI Evolution&lt;/p&gt;
    &lt;p&gt;Early Prototype&lt;/p&gt;
    &lt;p&gt;This is what the UI looked like when I first joined the early project.&lt;/p&gt;
    &lt;p&gt;Notes driven UI&lt;/p&gt;
    &lt;p&gt;Exploratory chat UI introduced as an overlay on the note canvas.&lt;/p&gt;
    &lt;p&gt;3-Panel Structure&lt;/p&gt;
    &lt;p&gt;Synthesizes learnings into a scalable and adaptive layout.&lt;/p&gt;
    &lt;p&gt;One of the core problems we set out to solve with NotebookLM was √¢tab overwhelm√¢ the scattered, fractured experience of jumping between tools while trying to synthesize ideas. We wanted to create a space where every part of the creation journey could happen in one place.&lt;/p&gt;
    &lt;p&gt;√¢ Inputs&lt;/p&gt;
    &lt;p&gt;Outputs √¢&lt;/p&gt;
    &lt;p&gt;Chat&lt;/p&gt;
    &lt;p&gt;√¢¬¢ Citations&lt;/p&gt;
    &lt;p&gt;Creation&lt;/p&gt;
    &lt;p&gt;√¢¬¢ Multiple entry points&lt;/p&gt;
    &lt;p&gt;This visual shows how the core building blocks came together.&lt;/p&gt;
    &lt;p&gt;The structure you see now may seem obvious but it took After what felt like 1000 iterations to get there. Trying to put these blocks together in a way that allowed for a clear mental model and digstible UI. These early sketches are from a plane. I ran out of paper and ultimately found the final solution when drawing on a napkin.&lt;/p&gt;
    &lt;p&gt;The mental model of NotebookLM was built around the creation journey: starting with inputs, moving through conversation, and ending with outputs. Users bring in their sources (documents, notes, references), then interact with them through chat by asking questions, clarifying, and synthesizing before transforming those insights into structured outputs like notes, study guides, and Audio Overviews.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;By grounding the design in this linear but flexible flow (Inputs √¢ Chat √¢ Outputs) we gave users a clear sense of place within the product while keeping the complexity of new AI interactions digestible and intuitive.&lt;/p&gt;
    &lt;p&gt;It√¢s rare to find a product that brings reading, writing, and creation together in a truly integrated way largely because juggling all three can be overwhelming. But with AI reducing friction, the opportunity emerged to design a space where every part of the creative process could coexist.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;To make that possible, I designed a responsive panel system that adapts to the user√¢s needs, scaling fluidly while preserving quick access to key elements like sources and notes, even at the smallest sizes.&lt;/p&gt;
    &lt;p&gt;The default layout, offering a balanced view of sources, chat, and notes.&lt;/p&gt;
    &lt;p&gt;Optimized for referencing sources and generating responses with citations.&lt;/p&gt;
    &lt;p&gt;A popular request, designed for users focused on drafting and iteration.&lt;/p&gt;
    &lt;p&gt;Ideal for composing while keeping source material in view.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;To optimize spatial utility, I created a set of responsive panels that scale based on user needs, retaining essential icons for sources and notes even at minimal widths.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;Scalability was a core principle. While the content within these panels can shift and evolve, the underlying system is built to support growth, accommodating new tools, modes, and workflows without breaking the structure.&lt;/p&gt;
    &lt;p&gt;Source Panel&lt;/p&gt;
    &lt;p&gt;Studio Panel&lt;/p&gt;
    &lt;p&gt;See how the team has continued to scale this system with the newest launch of flashcards, quizzes, professional reports.&lt;/p&gt;
    &lt;p&gt;Chat Panel&lt;/p&gt;
    &lt;p&gt;Here√¢s what that looks like:&lt;/p&gt;
    &lt;p&gt;User Journey √¢¬¢ Annotated Overview&lt;/p&gt;
    &lt;p&gt;Read the full story&lt;/p&gt;
    &lt;p&gt;Defining the brand identity was a fast-paced effort, made possible by close collaboration with Google Labs and the central brand team. Shoutout Feel Hwang, Nick Mcginnis, Jennifer Leartanasan and team.&lt;/p&gt;
    &lt;p&gt;Jason Spielman&lt;/p&gt;
    &lt;p&gt;Linkedin √¢&lt;/p&gt;
    &lt;p&gt;Jason Spielman&lt;/p&gt;
    &lt;p&gt;Linkedin √¢&lt;/p&gt;
    &lt;p&gt;Home&lt;/p&gt;
    &lt;p&gt;Next&lt;/p&gt;
    &lt;p&gt;Jason Spielman&lt;/p&gt;
    &lt;p&gt;Design Lead&lt;/p&gt;
    &lt;p&gt;UX + Identity&lt;/p&gt;
    &lt;p&gt;2024&lt;/p&gt;
    &lt;p&gt;I led design for NotebookLM, shaping the product√¢s core user experience, brand identity, and visual system from experiment to launch.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;This remains one of my proudest projects, and I√¢m incredibly grateful for the opportunity to design something entirely new from the ground up. It was a chance to explore fresh paradigms, invent new patterns, and bring a product to life that hadn√¢t existed before. None of it would√¢ve been possible without the tight-knit, cross-functional team I was fortunate to collaborate with.&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Architecture&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;3 Panel&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Brand Identity&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Visual Assets&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Takeaways&lt;/p&gt;
    &lt;p&gt;Architecture&lt;/p&gt;
    &lt;p&gt;UI Evolution&lt;/p&gt;
    &lt;p&gt;Early Prototype&lt;/p&gt;
    &lt;p&gt;This is what the UI looked like when I first joined the early project.&lt;/p&gt;
    &lt;p&gt;Notes driven UI&lt;/p&gt;
    &lt;p&gt;Exploratory chat UI introduced as an overlay on the note canvas.&lt;/p&gt;
    &lt;p&gt;3-Panel Structure&lt;/p&gt;
    &lt;p&gt;Synthesizes learnings into a scalable and adaptive layout.&lt;/p&gt;
    &lt;p&gt;One of the core problems we set out to solve with NotebookLM was √¢tab overwhelm√¢ the scattered, fractured experience of jumping between tools while trying to synthesize ideas. We wanted to create a space where every part of the creation journey could happen in one place.&lt;/p&gt;
    &lt;p&gt;√¢ Inputs&lt;/p&gt;
    &lt;p&gt;Outputs √¢&lt;/p&gt;
    &lt;p&gt;Chat&lt;/p&gt;
    &lt;p&gt;√¢¬¢ Citations&lt;/p&gt;
    &lt;p&gt;Creation&lt;/p&gt;
    &lt;p&gt;√¢¬¢ Multiple entry points&lt;/p&gt;
    &lt;p&gt;This visual shows how the core building blocks came together.&lt;/p&gt;
    &lt;p&gt;The structure you see now may seem obvious but it took After what felt like 1000 iterations to get there. Trying to put these blocks together in a way that allowed for a clear mental model and digstible UI. These early sketches are from a plane. I ran out of paper and ultimately found the final solution when drawing on a napkin.&lt;/p&gt;
    &lt;p&gt;The mental model of NotebookLM was built around the creation journey: starting with inputs, moving through conversation, and ending with outputs. Users bring in their sources (documents, notes, references), then interact with them through chat by asking questions, clarifying, and synthesizing before transforming those insights into structured outputs like notes, study guides, and Audio Overviews.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;By grounding the design in this linear but flexible flow (Inputs √¢ Chat √¢ Outputs) we gave users a clear sense of place within the product while keeping the complexity of new AI interactions digestible and intuitive.&lt;/p&gt;
    &lt;p&gt;It√¢s rare to find a product that brings reading, writing, and creation together in a truly integrated way largely because juggling all three can be overwhelming. But with AI reducing friction, the opportunity emerged to design a space where every part of the creative process could coexist.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;To make that possible, I designed a responsive panel system that adapts to the user√¢s needs, scaling fluidly while preserving quick access to key elements like sources and notes, even at the smallest sizes.&lt;/p&gt;
    &lt;p&gt;Standard&lt;/p&gt;
    &lt;p&gt;The default layout, offering a balanced view of sources, chat, and notes.&lt;/p&gt;
    &lt;p&gt;Reading + Chat&lt;/p&gt;
    &lt;p&gt;Optimized for referencing sources and generating responses with citations.&lt;/p&gt;
    &lt;p&gt;To optimize spatial utility, I created a set of responsive panels that scale based on user needs, retaining essential icons for sources and notes even at minimal widths.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;Scalability was a core principle. While the content within these panels can shift and evolve, the underlying system is built to support growth, accommodating new tools, modes, and workflows without breaking the structure.&lt;/p&gt;
    &lt;p&gt;Source Panel&lt;/p&gt;
    &lt;p&gt;Studio Panel&lt;/p&gt;
    &lt;p&gt;See how the team has continued to scale this system with the newest launch of flashcards, quizzes, professional reports.&lt;/p&gt;
    &lt;p&gt;Chat Panel&lt;/p&gt;
    &lt;p&gt;Here√¢s what that looks like:&lt;/p&gt;
    &lt;p&gt;User Journey √¢¬¢ Annotated Overview&lt;/p&gt;
    &lt;p&gt;Read the full story&lt;/p&gt;
    &lt;p&gt;Defining the brand identity was a fast-paced effort, made possible by close collaboration with Google Labs and the central brand team. Shoutout Feel Hwang, Nick Mcginnis, Jennifer Leartanasan and team.&lt;/p&gt;
    &lt;p&gt;Jason Spielman&lt;/p&gt;
    &lt;p&gt;Linkedin √¢&lt;/p&gt;
    &lt;p&gt;Wanda Wingleton&lt;/p&gt;
    &lt;p&gt;Linkedin √¢&lt;/p&gt;
    &lt;p&gt;Home&lt;/p&gt;
    &lt;p&gt;Next&lt;/p&gt;
    &lt;p&gt;Jason Spielman&lt;/p&gt;
    &lt;p&gt;Design Lead&lt;/p&gt;
    &lt;p&gt;UX + Identity&lt;/p&gt;
    &lt;p&gt;2024&lt;/p&gt;
    &lt;p&gt;I led design for NotebookLM, shaping the product√¢s core user experience, brand identity, and visual system from experiment to launch.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;This remains one of my proudest projects, and I√¢m incredibly grateful for the opportunity to design something entirely new from the ground up. It was a chance to explore fresh paradigms, invent new patterns, and bring a product to life that hadn√¢t existed before. None of it would√¢ve been possible without the tight-knit, cross-functional team I was fortunate to collaborate with.&lt;/p&gt;
    &lt;p&gt;Podcast √¢¬¢ Seqouia Training Data&lt;/p&gt;
    &lt;p&gt;Raiza and I discuss the journey building NotebookLM.&lt;/p&gt;
    &lt;p&gt;NotebookLM √¢¬¢ Winner!&lt;/p&gt;
    &lt;p&gt;Recognized as one of TIME√¢s Best Inventions of 2024.&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Architecture&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;3 Panel&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Brand Identity&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Visual Assets&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Takeaways&lt;/p&gt;
    &lt;p&gt;Architecture&lt;/p&gt;
    &lt;p&gt;Design Evolution&lt;/p&gt;
    &lt;p&gt;Early Prototype&lt;/p&gt;
    &lt;p&gt;This is what the UI looked like when I first joined the early project.&lt;/p&gt;
    &lt;p&gt;Notes driven UI&lt;/p&gt;
    &lt;p&gt;Exploratory chat UI introduced as an overlay on the note canvas.&lt;/p&gt;
    &lt;p&gt;3-Panel Structure&lt;/p&gt;
    &lt;p&gt;Synthesizes learnings into a scalable and adaptive layout.&lt;/p&gt;
    &lt;p&gt;One of the core problems we set out to solve with NotebookLM was √¢tab overwhelm√¢ the scattered, fractured experience of jumping between tools while trying to synthesize ideas. We wanted to create a space where every part of the creation journey could happen in one place.&lt;/p&gt;
    &lt;p&gt;√¢ Inputs&lt;/p&gt;
    &lt;p&gt;Outputs √¢&lt;/p&gt;
    &lt;p&gt;Chat&lt;/p&gt;
    &lt;p&gt;√¢¬¢ Citations&lt;/p&gt;
    &lt;p&gt;Creation&lt;/p&gt;
    &lt;p&gt;√¢¬¢ Multiple entry points&lt;/p&gt;
    &lt;p&gt;This visual shows how the core building blocks came together.&lt;/p&gt;
    &lt;p&gt;The structure you see now may look obvious but it took what felt like a thousand iterations to get there. I was trying to arrange these blocks in a way that supported a clear mental model and a UI that felt intuitive and digestible.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;These sketches were done on a plane. I ran out of paper and ended up sketching the final solution across a few napkins.&lt;/p&gt;
    &lt;p&gt;The mental model of NotebookLM was built around the creation journey: starting with inputs, moving through conversation, and ending with outputs. Users bring in their sources (documents, notes, references), then interact with them through chat by asking questions, clarifying, and synthesizing before transforming those insights into structured outputs like notes, study guides, and Audio Overviews.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;By grounding the design in this linear but flexible flow (Inputs √¢ Chat √¢ Outputs) we gave users a clear sense of place within the product while keeping the complexity of new AI interactions digestible and intuitive.&lt;/p&gt;
    &lt;p&gt;It√¢s rare to find a product that brings reading, writing, and creation together in a truly integrated way largely because juggling all three can be overwhelming. But with AI reducing friction, the opportunity emerged to design a space where every part of the creative process could coexist.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;To make that possible, I designed a responsive panel system that adapts to the user√¢s needs, scaling fluidly while preserving quick access to key elements like sources and notes, even at the smallest sizes.&lt;/p&gt;
    &lt;p&gt;Standard&lt;/p&gt;
    &lt;p&gt;The default layout, offering a balanced view of sources, chat, and notes.&lt;/p&gt;
    &lt;p&gt;Reading + Chat&lt;/p&gt;
    &lt;p&gt;Optimized for referencing sources and generating responses with citations.&lt;/p&gt;
    &lt;p&gt;Chat + Writing&lt;/p&gt;
    &lt;p&gt;A popular request, designed for users focused on drafting and iteration.&lt;/p&gt;
    &lt;p&gt;Reading + Writing&lt;/p&gt;
    &lt;p&gt;Ideal for composing while keeping source material in view.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;To optimize spatial utility, I created a set of responsive panels that scale based on user needs, retaining essential icons for sources and notes even at minimal widths.&lt;/p&gt;
    &lt;p&gt;√Ç&lt;/p&gt;
    &lt;p&gt;Scalability was a core principle. While the content within these panels can shift and evolve, the underlying system is built to support growth, accommodating new tools, modes, and workflows without breaking the structure.&lt;/p&gt;
    &lt;p&gt;Source Panel&lt;/p&gt;
    &lt;p&gt;Studio Panel&lt;/p&gt;
    &lt;p&gt;See how the team has continued to scale this system with the newest launch of flashcards, quizzes, professional reports.&lt;/p&gt;
    &lt;p&gt;Chat Panel&lt;/p&gt;
    &lt;p&gt;Here√¢s what that looks like:&lt;/p&gt;
    &lt;p&gt;Read the full story&lt;/p&gt;
    &lt;p&gt;Defining the brand identity was a fast-paced effort, made possible by close collaboration with Google Labs and the central brand team. Shoutout Feel Hwang, Nick Mcginnis, Jennifer Leartanasan and team.&lt;/p&gt;
    &lt;p&gt;Jason Spielman&lt;/p&gt;
    &lt;p&gt;Linkedin √¢&lt;/p&gt;
    &lt;p&gt;Jason Spielman&lt;/p&gt;
    &lt;p&gt;Linkedin √¢&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45315312</guid><pubDate>Sat, 20 Sep 2025 17:25:58 +0000</pubDate></item><item><title>A revolution in English bell ringing</title><link>https://harpers.org/archive/2025/10/a-change-of-tune-veronique-greenwood-bell-ringing/</link><description>&lt;doc fingerprint="f108bd6b5cc6fc83"&gt;
  &lt;main&gt;
    &lt;p&gt;October 2025 Issue [Annotation] A Change of Tune Download PDF Adjust Share A revolution in English bell ringing by Veronique Greenwood, Veronique Greenwood is a writer and bell ringer who lives in England. Tags Bell ringing England Adjust Share&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45316744</guid><pubDate>Sat, 20 Sep 2025 19:51:36 +0000</pubDate></item><item><title>A brief history of threads and threading</title><link>https://eclecticlight.co/2025/09/20/a-brief-history-of-threads-and-threading/</link><description>&lt;doc fingerprint="66748c770736d00a"&gt;
  &lt;main&gt;
    &lt;p&gt;The original 128K Mac from 1984 came with a single Motorola 68000 processor running at 8 MHz that could only run one app at a time. Yet today‚Äôs Macs come with multiple CPU cores that can comfortably run several substantial apps simultaneously, while running a Time Machine backup and other tasks in the background. This brief history outlines the journey between them.&lt;/p&gt;
    &lt;p&gt;A processor with a single core and no support for multi-tasking runs one sequence of instructions at a time. When those call for an operating system function to be performed, the running app is interrupted to hand control over to the system, and once that has completed, control is passed back to the app. That‚Äôs what the first Macs did until Andy Hertzfeld wrote Switcher, released by Apple in April 1985. This allowed the user to switch between running more than one app, but was still limited to running just one of them at a time.&lt;/p&gt;
    &lt;head rend="h4"&gt;Multitasking&lt;/head&gt;
    &lt;p&gt;Over the next couple of years, some third-party utilities were produced to go further than Switcher, but it wasn‚Äôt until 1987 that MultiFinder replaced Switcher, and was integrated into System 7 in 1991. Developed by Erich Ringewald and Phil Goldman, this brought cooperative multitasking, which was to become the mainstay of classic Mac OS.&lt;/p&gt;
    &lt;p&gt;In computers with a single processor core, multitasking is a way of cheating to give the impression that the processor is doing several things at once, when in fact all it‚Äôs doing is switching rapidly between two or more different programs. There are two fundamental models for doing that:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;cooperative multitasking, in which individual tasks yield to give others processing time;&lt;/item&gt;
      &lt;item&gt;preemptive multitasking, in which a scheduler switches between tasks at regular intervals.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When a processor switches from one task to the next, the current task state must be saved so it can be resumed later. Once that‚Äôs complete, the next task is loaded to complete the context switch. That incurs overhead, both in terms of processing and in memory storage, which are less when switching between lightweight tasks. Different strategies have been adopted to determine the optimum size of tasks and overhead imposed by context switching, and terminology differs between them, variously using words such as processes, threads and even fibres, which can prove thoroughly confusing.&lt;/p&gt;
    &lt;p&gt;Classic Mac OS thus has a Process Manager that launches apps in cooperative multitasking. This works well much of the time, but lets badly behaved tasks hog the processor and block other tasks from getting their fair share. It‚Äôs greatly aided by the main event loop at the heart of Mac apps that waits for control input to direct the app to perform work for the user. But when an app charges off to spend many seconds tackling a demanding task without polling its main event loop, that app could lock the user out for what seems like an age.&lt;/p&gt;
    &lt;p&gt;In February 1988 Apple released the first Unix for Macintosh, A/UX, which came with preemptive multitasking. That was added to Mac OS in 1996 in System 7.5.3, in Multiprocessing Services, and further enhanced in Mac OS 8.6 three years later. Cooperative multitasking was also supported by the Thread Manager.&lt;/p&gt;
    &lt;head rend="h4"&gt;Threads&lt;/head&gt;
    &lt;p&gt;In 2000 Apple‚Äôs hardware and software changed radically. Its first Macs with dual processors came in PowerPC 7400 (G4) chips in Power Mac G4 desktop systems, and Mac OS X brought several types of thread that could be used to manage processing on multiple processors or CPU cores, together with preemptive multitasking. Thread types include low-level Mach threads, higher-level POSIX threads or Pthreads that replaced Multiprocessing Services, Java Threads, Cocoa‚Äôs NSThreads, and cooperatively scheduled threads using the Carbon Thread Manager. The following diagram summarises Apple‚Äôs current terminology.&lt;/p&gt;
    &lt;p&gt;In most cases, we‚Äôre considering applications with a GUI, normally run from a bundle structure. These can in turn run their own code, such as privileged helper apps used to perform work that requires elevated privileges. In recent years, there has been a proliferation of additional executable code associated with many apps.&lt;/p&gt;
    &lt;p&gt;When that app is run, there‚Äôs a single runtime instance created from its single executable code, and given its own virtual memory and access to system resources that it needs. This is a process, and listed as such in Activity Monitor, for example.&lt;/p&gt;
    &lt;p&gt;Each process has a main thread, a single flow of code execution, and may create additional threads, perhaps to run in the background. Threads don‚Äôt get their own virtual memory, but share that allocated to the process, although they have their own stack. On Apple silicon Macs they‚Äôre easy to tell apart as they can only run on a single core, although they may be moved between cores, sometimes rapidly.&lt;/p&gt;
    &lt;p&gt;Within each thread are individual tasks, each a quantity of work to be performed. These can be brief sections of code and are more interdependent than threads. They‚Äôre often divided into synchronous and asynchronous tasks, depending on whether they need to be run as part of a strict sequence.&lt;/p&gt;
    &lt;p&gt;In 2005 the Power Mac G5 was the first Mac to use dual-core PowerPC G5 processors, then the iMac 17-inch of the following year used Apple‚Äôs first Intel Core Duo processor with two cores.&lt;/p&gt;
    &lt;head rend="h4"&gt;Grand Central Dispatch&lt;/head&gt;
    &lt;p&gt;In 2009 Mac OS X 10.6 Snow Leopard introduced a new dispatcher, named Grand Central Dispatch (GCD) after Grand Central Terminal in New York City, and that was enhanced in macOS Sierra a decade later. More recently it has been referred to simply as Dispatch.&lt;/p&gt;
    &lt;p&gt;At its heart, GCD is a dispatcher managing queues of tasks, activating those that need most to be run, and leaving the less pressing to wait a bit longer. It has its own queues, as well as those assembled by apps. Some are run as simple queues with a first in first out rule, others using sophisticated heuristics to determine relative priorities. There‚Äôs a detailed account of GCD internals in Jonathan Levin‚Äôs book *OS Internals volume 1, and Apple‚Äôs current developer documentation is here.&lt;/p&gt;
    &lt;p&gt;GCD was introduced for Macs with multiple identical cores, to support their symmetric multiprocessing (SMP), and with the release of the first Apple silicon Macs in November 2020 it has managed queues of threads to be dispatched for execution on two CPU core types, Performance and Efficiency. Core allocation is now managed according to the Quality of Service (QoS) assigned to each thread. When used on SMP processors with no contention for core availability, QoS has limited effects on thread performance, but performance on P and E cores may differ by a factor of 10.&lt;/p&gt;
    &lt;p&gt;Over the last 41 years, macOS has gained thorough support for getting the best performance from multiple tasks, threads, and processes in chips that contain up to 32 CPU cores of two types ‚Äì a far cry from that single 68000 processor.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45317526</guid><pubDate>Sat, 20 Sep 2025 21:04:38 +0000</pubDate></item><item><title>$2 WeAct Display FS adds a 0.96-inch USB information display to your computer</title><link>https://www.cnx-software.com/2025/09/18/2-weact-display-fs-adds-a-0-96-inch-usb-information-display-to-your-computer/</link><description>&lt;doc fingerprint="aa305d1c39dee0f3"&gt;
  &lt;main&gt;
    &lt;p&gt;WeAct Display FS is an inexpensive 0.96-inch USB display dongle designed to add an information display or a tiny secondary display to your computer or SBC.&lt;/p&gt;
    &lt;p&gt;We‚Äôve seen this type of information display with products such as the Turing Smart Screen, a larger 3.5-inch color display, or small OLEDs integrated into cases such as the Pironman 5 Max to disable text. The WeAct Display FS V1 may be tiny, but it‚Äôs also a full-color 160√ó80 resolution display that can be customized with software provided by WeAct.&lt;/p&gt;
    &lt;p&gt;WeAct Display FS V1 specifications:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Display ‚Äì 0.96-inch RGB565 display with 160√ó80 resolution&lt;/item&gt;
      &lt;item&gt;Host interface ‚Äì ‚ÄúReversible‚Äù USB 2.0 Type-A Full Speed (FS) port showing as a CDC device&lt;/item&gt;
      &lt;item&gt;Dimensions ‚Äì 43 x 14.5 mm&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Since you wouldn‚Äôt want to get a display only for it to face the wrong direction, for instance, the desk or the wall, the company made the USB-A port reversible, and the user only needs to install one of the two provided pads on the unused side of the port to avoid short circuits.&lt;/p&gt;
    &lt;p&gt;WeAct provides two programs for it. The first one is the WeAct Studio System Monitor based on a fork of Matthieu Houdebine‚Äôs Turing Smart Screen Python project. This allows users to create UIs/themes with text, images, weather, and other features‚Ä¶ WeAct says the little device only works on Windows, but the open-source project is supposed to also work on macOS, Linux (including Raspberry Pi OS), and essentially any operating system with support for Python 3.9+.&lt;/p&gt;
    &lt;p&gt;The second program is called WeAct Studio Screen Projection, and as I understand it, it emulates an actual display, so you could move any window/program to the USB display. I‚Äôm just not sure how a desktop OS like Windows will handle a tiny 160√ó80 ‚Äúmonitor‚Äù‚Ä¶ I suppose it could be used to play a full-screen YouTube video or display photos for whatever reason. That one only works on Windows, and there‚Äôs no source code.&lt;/p&gt;
    &lt;p&gt;You‚Äôll find the WeAct Display FS V1 (0.96-inch) on AliExpress for about $2 plus shipping, but while looking for information, I also noticed a 3.5-inch variant with 480√ó320 resolution for about $11.&lt;/p&gt;
    &lt;p&gt;Jean-Luc started CNX Software in 2010 as a part-time endeavor, before quitting his job as a software engineering manager, and starting to write daily news, and reviews full time later in 2011.&lt;/p&gt;
    &lt;p&gt;Support CNX Software! Donate via cryptocurrencies, become a Patron on Patreon, or purchase goods on Amazon or Aliexpress. We also use affiliate links in articles to earn commissions if you make a purchase after clicking on those links.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45317527</guid><pubDate>Sat, 20 Sep 2025 21:04:47 +0000</pubDate></item><item><title>In defence of swap: common misconceptions (2018)</title><link>https://chrisdown.name/2018/01/02/in-defence-of-swap.html</link><description>&lt;doc fingerprint="be79d81b38a2af88"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;In defence of swap: common misconceptions&lt;/head&gt;
    &lt;p&gt;This post is also available in Japanese, Chinese, and Russian.&lt;/p&gt;
    &lt;p&gt;tl;dr:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Having swap is a reasonably important part of a well functioning system. Without it, sane memory management becomes harder to achieve.&lt;/item&gt;
      &lt;item&gt;Swap is not generally about getting emergency memory, it's about making memory reclamation egalitarian and efficient. In fact, using it as "emergency memory" is generally actively harmful.&lt;/item&gt;
      &lt;item&gt;Disabling swap does not prevent disk I/O from becoming a problem under memory contention. Instead, it simply shifts the disk I/O thrashing from anonymous pages to file pages. Not only may this be less efficient, as we have a smaller pool of pages to select from for reclaim, but it may also contribute to getting into this high contention state in the first place.&lt;/item&gt;
      &lt;item&gt;The swapper on kernels before 4.0 has a lot of pitfalls, and has contributed to a lot of people's negative perceptions of swap due to its overeagerness to swap out pages. On kernels &amp;gt;4.0, the situation is significantly better.&lt;/item&gt;
      &lt;item&gt;On SSDs, swapping out anonymous pages and reclaiming file pages are essentially equivalent in terms of performance and latency. On older spinning disks, swap reads are slower due to random reads, so a lower &lt;code&gt;vm.swappiness&lt;/code&gt;setting makes sense there (read on for more about&lt;code&gt;vm.swappiness&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Disabling swap doesn't prevent pathological behaviour at near-OOM, although it's true that having swap may prolong it. Whether the global OOM killer is invoked with or without swap, or was invoked sooner or later, the result is the same: you are left with a system in an unpredictable state. Having no swap doesn't avoid this.&lt;/item&gt;
      &lt;item&gt;You can achieve better swap behaviour under memory pressure and prevent thrashing by utilising &lt;code&gt;memory.low&lt;/code&gt;and friends in cgroup v2.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As part of my work improving kernel memory management and cgroup v2, I've been talking to a lot of engineers about attitudes towards memory, especially around application behaviour under pressure and operating system heuristics used under the hood for memory management.&lt;/p&gt;
    &lt;p&gt;A repeated topic in these discussions has been swap. Swap is a hotly contested and poorly understood topic, even by those who have been working with Linux for many years. Many see it as useless or actively harmful: a relic of a time where memory was scarce, and disks were a necessary evil to provide much-needed space for paging. This is a statement that I still see being batted around with relative frequency in recent years, and I've had many discussions with colleagues, friends, and industry peers to help them understand why swap is still a useful concept on modern computers with significantly more physical memory available than in the past.&lt;/p&gt;
    &lt;p&gt;There's also a lot of misunderstanding about the purpose of swap ‚Äì many people just see it as a kind of "slow extra memory" for use in emergencies, but don't understand how it can contribute during normal load to the healthy operation of an operating system as a whole.&lt;/p&gt;
    &lt;p&gt;Many of us have heard most of the usual tropes about memory: "Linux uses too much memory", "swap should be double your physical memory size", and the like. While these are either trivial to dispel, or discussion around them has become more nuanced in recent years, the myth of "useless" swap is much more grounded in heuristics and arcana rather than something that can be explained by simple analogy, and requires somewhat more understanding of memory management to reason about.&lt;/p&gt;
    &lt;p&gt;This post is mostly aimed at those who administer Linux systems and are interested in hearing the counterpoints to running with undersized/no swap or running with &lt;code&gt;vm.swappiness&lt;/code&gt; set to 0.&lt;/p&gt;
    &lt;head rend="h2"&gt;Background&lt;/head&gt;
    &lt;p&gt;It's hard to talk about why having swap and swapping out pages are good things in normal operation without a shared understanding of some of the basic underlying mechanisms at play in Linux memory management, so let's make sure we're on the same page.&lt;/p&gt;
    &lt;head rend="h3"&gt;Types of memory&lt;/head&gt;
    &lt;p&gt;There are many different types of memory in Linux, and each type has its own properties. Understanding the nuances of these is key to understanding why swap is important.&lt;/p&gt;
    &lt;p&gt;For example, there are pages ("blocks" of memory, typically 4k) responsible for holding the code for each process being run on your computer. There are also pages responsible for caching data and metadata related to files accessed by those programs in order to speed up future access. These are part of the page cache, and I will refer to them as file memory.&lt;/p&gt;
    &lt;p&gt;There are also pages which are responsible for the memory allocations made inside that code, for example, when new memory that has been allocated with &lt;code&gt;malloc&lt;/code&gt; is written to, or when using &lt;code&gt;mmap&lt;/code&gt;'s &lt;code&gt;MAP_ANONYMOUS&lt;/code&gt; flag. These are "anonymous" pages ‚Äì so called because they are not backed by anything ‚Äì and I will refer to them as anon memory.&lt;/p&gt;
    &lt;p&gt;There are other types of memory too ‚Äì shared memory, slab memory, kernel stack memory, buffers, and the like ‚Äì but anonymous memory and file memory are the most well known and easy to understand ones, so I will use these in my examples, although they apply equally to these types too.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reclaimable/unreclaimable memory&lt;/head&gt;
    &lt;p&gt;One of the most fundamental questions when thinking about a particular type of memory is whether it is able to be reclaimed or not. "Reclaim" here means that the system can, without losing data, purge pages of that type from physical memory.&lt;/p&gt;
    &lt;p&gt;For some page types, this is typically fairly trivial. For example, in the case of clean (unmodified) page cache memory, we're simply caching something that we have on disk for performance, so we can drop the page without having to do any special operations.&lt;/p&gt;
    &lt;p&gt;For some page types, this is possible, but not trivial. For example, in the case of dirty (modified) page cache memory, we can't just drop the page, because the disk doesn't have our modifications yet. As such we either need to deny reclamation or first get our changes back to disk before we can drop this memory.&lt;/p&gt;
    &lt;p&gt;For some page types, this is not possible. For example, in the case of the anonymous pages mentioned previously, they only exist in memory and in no other backing store, so they have to be kept there.&lt;/p&gt;
    &lt;head rend="h2"&gt;On the nature of swap&lt;/head&gt;
    &lt;p&gt;If you look for descriptions of the purpose of swap on Linux, you'll inevitably find many people talking about it as if it is merely an extension of the physical RAM for use in emergencies. For example, here is a random post I got as one of the top results from typing "what is swap" in Google:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Swap is essentially emergency memory; a space set aside for times when your system temporarily needs more physical memory than you have available in RAM. It's considered "bad" in the sense that it's slow and inefficient, and if your system constantly needs to use swap then it obviously doesn't have enough memory. [‚Ä¶] If you have enough RAM to handle all of your needs, and don't expect to ever max it out, then you should be perfectly safe running without a swap space.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;To be clear, I don't blame the poster of this comment at all for the content of their post ‚Äì this is accepted as "common knowledge" by a lot of Linux sysadmins and is probably one of the most likely things that you will hear from one if you ask them to talk about swap. It is unfortunately also, however, a misunderstanding of the purpose and use of swap, especially on modern systems.&lt;/p&gt;
    &lt;p&gt;Above, I talked about reclamation for anonymous pages being "not possible", as anonymous pages by their nature have no backing store to fall back to when being purged from memory ‚Äì as such, their reclamation would result in complete data loss for those pages. What if we could create such a store for these pages, though?&lt;/p&gt;
    &lt;p&gt;Well, this is precisely what swap is for. Swap is a storage area for these seemingly "unreclaimable" pages that allows us to page them out to a storage device on demand. This means that they can now be considered as equally eligible for reclaim as their more trivially reclaimable friends, like clean file pages, allowing more efficient use of available physical memory.&lt;/p&gt;
    &lt;p&gt;Swap is primarily a mechanism for equality of reclamation, not for emergency "extra memory". Swap is not what makes your application slow ‚Äì entering overall memory contention is what makes your application slow.&lt;/p&gt;
    &lt;p&gt;So in what situations under this "equality of reclamation" scenario would we legitimately choose to reclaim anonymous pages? Here are, abstractly, some not uncommon scenarios:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;During initialisation, a long-running program may allocate and use many pages. These pages may also be used as part of shutdown/cleanup, but are not needed once the program is "started" (in an application-specific sense). This is fairly common for daemons which have significant dependencies to initialise.&lt;/item&gt;
      &lt;item&gt;During the program's normal operation, we may allocate memory which is only used rarely. It may make more sense for overall system performance to require a major fault to page these in from disk on demand, instead using the memory for something else that's more important.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Examining what happens with/without swap&lt;/head&gt;
    &lt;p&gt;Let's look at typical situations, and how they perform with and without swap present. I talk about metrics around "memory contention" in my talk on cgroup v2.&lt;/p&gt;
    &lt;head rend="h3"&gt;Under no/low memory contention&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;With swap: We can choose to swap out rarely-used anonymous memory that may only be used during a small part of the process lifecycle, allowing us to use this memory to improve cache hit rate, or do other optimisations.&lt;/item&gt;
      &lt;item&gt;Without swap: We cannot swap out rarely-used anonymous memory, as it's locked in memory. While this may not immediately present as a problem, on some workloads this may represent a non-trivial drop in performance due to stale, anonymous pages taking space away from more important use.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Under moderate/high memory contention&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;With swap: All memory types have an equal possibility of being reclaimed. This means we have a better chance to be able to reclaim pages successfully ‚Äì that is, we can reclaim pages that are not quickly faulted back in again (thrashing).&lt;/item&gt;
      &lt;item&gt;Without swap: Anonymous pages are locked into memory as they have nowhere to go. The chance of successful long-term page reclamation is lower, as we have only some types of memory eligible to be reclaimed at all. The risk of page thrashing is higher. The casual reader might think that this would still be better as it might avoid having to do disk I/O, but this isn't true ‚Äì we simply transfer the disk I/O of swapping to dropping hot page caches and dropping code segments we need soon.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Under temporary spikes in memory usage&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;With swap: We're more resilient to temporary spikes, but in cases of severe memory starvation, the period from memory thrashing beginning to the OOM killer may be prolonged. We have more visibility into the instigators of memory pressure and can act on them more reasonably, and can perform a controlled intervention.&lt;/item&gt;
      &lt;item&gt;Without swap: The OOM killer is triggered more quickly as anonymous pages are locked into memory and cannot be reclaimed. We're more likely to thrash on memory, but the time between thrashing and OOMing is reduced. Depending on your application, this may be better or worse. For example, a queue-based application may desire this quick transfer from thrashing to killing. That said, this is still too late to be really useful ‚Äì the OOM killer is only invoked at moments of severe starvation, and relying on this method for such behaviour would be better replaced with more opportunistic killing of processes as memory contention is reached in the first place.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Okay, so I want system swap, but how can I tune it for individual applications?&lt;/head&gt;
    &lt;p&gt;You didn't think you'd get through this entire post without me plugging cgroup v2, did you? ;-)&lt;/p&gt;
    &lt;p&gt;Obviously, it's hard for a generic heuristic algorithm to be right all the time, so it's important for you to be able to give guidance to the kernel. Historically the only tuning you could do was at the system level, using &lt;code&gt;vm.swappiness&lt;/code&gt;. This has two problems: &lt;code&gt;vm.swappiness&lt;/code&gt; is incredibly hard to reason about because it only feeds in as a small part of a larger heuristic system, and it also is system-wide instead of being granular to a smaller set of processes.&lt;/p&gt;
    &lt;p&gt;You can also use &lt;code&gt;mlock&lt;/code&gt; to lock pages into memory, but this requires either modifying program code, fun with &lt;code&gt;LD_PRELOAD&lt;/code&gt;, or doing horrible things with a debugger at runtime. In VM-based languages this also doesn't work very well, since you generally have no control over allocation and end up having to &lt;code&gt;mlockall&lt;/code&gt;, which has no precision towards the pages you actually care about.&lt;/p&gt;
    &lt;p&gt;cgroup v2 has a tunable per-cgroup in the form of &lt;code&gt;memory.low&lt;/code&gt;, which allows us to tell the kernel to prefer other applications for reclaim below a certain threshold of memory used. This allows us to not prevent the kernel from swapping out parts of our application, but prefer to reclaim from other applications under memory contention. Under normal conditions, the kernel's swap logic is generally pretty good, and allowing it to swap out pages opportunistically generally increases system performance. Swap thrash under heavy memory contention is not ideal, but it's more a property of simply running out of memory entirely than a problem with the swapper. In these situations, you typically want to fail fast by self-killing non-critical processes when memory pressure starts to build up.&lt;/p&gt;
    &lt;p&gt;You can not simply rely on the OOM killer for this. The OOM killer is only invoked in situations of dire failure when we've already entered a state where the system is severely unhealthy and may well have been so for a while. You need to opportunistically handle the situation yourself before ever thinking about the OOM killer.&lt;/p&gt;
    &lt;p&gt;Determination of memory pressure is somewhat difficult using traditional Linux memory counters, though. We have some things which seem somewhat related, but are merely tangential ‚Äì memory usage, page scans, etc ‚Äì and from these metrics alone it's very hard to tell an efficient memory configuration from one that's trending towards memory contention. There is a group of us at Facebook, spearheaded by Johannes, working on developing new metrics that expose memory pressure more easily that should help with this in future. If you're interested in hearing more about this, I go into detail about one metric being considered in my talk on cgroup v2.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tuning&lt;/head&gt;
    &lt;head rend="h3"&gt;How much swap do I need, then?&lt;/head&gt;
    &lt;p&gt;In general, the minimum amount of swap space required for optimal memory management depends on the number of anonymous pages pinned into memory that are rarely reaccessed by an application, and the value of reclaiming those anonymous pages. The latter is mostly a question of which pages are no longer purged to make way for these infrequently accessed anonymous pages.&lt;/p&gt;
    &lt;p&gt;If you have a bunch of disk space and a recent (4.0+) kernel, more swap is almost always better than less. In older kernels &lt;code&gt;kswapd&lt;/code&gt;, one of the kernel processes responsible for managing swap, was historically very overeager to swap out memory aggressively the more swap you had. In recent times, swapping behaviour when a large amount of swap space is available has been significantly improved. If you're running kernel 4.0+, having a larger swap on a modern kernel should not result in overzealous swapping. As such, if you have the space, having a swap size of a few GB keeps your options open on modern kernels.&lt;/p&gt;
    &lt;p&gt;If you're more constrained with disk space, then the answer really depends on the tradeoffs you have to make, and the nature of the environment. Ideally you should have enough swap to make your system operate optimally at normal and peak (memory) load. What I'd recommend is setting up a few testing systems with 2-3GB of swap or more, and monitoring what happens over the course of a week or so under varying (memory) load conditions. As long as you haven't encountered severe memory starvation during that week ‚Äì in which case the test will not have been very useful ‚Äì you will probably end up with some number of MB of swap occupied. As such, it's probably worth having at least that much swap available, in addition to a little buffer for changing workloads. &lt;code&gt;atop&lt;/code&gt; in logging mode can also show you which applications are having their pages swapped out in the &lt;code&gt;SWAPSZ&lt;/code&gt; column, so if you don't already use it on your servers to log historic server state you probably want to set it up on these test machines with logging mode as part of this experiment. This also tells you when your application started swapping out pages, which you can tie to log events or other key data.&lt;/p&gt;
    &lt;p&gt;Another thing worth considering is the nature of the swap medium. Swap reads tend to be highly random, since we can't reliably predict which pages will be refaulted and when. On an SSD this doesn't matter much, but on spinning disks, random I/O is extremely expensive since it requires physical movement to achieve. On the other hand, refaulting of file pages is likely less random, since files related to the operation of a single application at runtime tend to be less fragmented. This might mean that on a spinning disk you may want to bias more towards reclaiming file pages instead of swapping out anonymous pages, but again, you need to test and evaluate how this balances out for your workload.&lt;/p&gt;
    &lt;p&gt;For laptop/desktop users who want to hibernate to swap, this also needs to be taken into account ‚Äì in this case your swap file should be at least your physical RAM size.&lt;/p&gt;
    &lt;head rend="h3"&gt;What should my swappiness setting be?&lt;/head&gt;
    &lt;p&gt;First, it's important to understand what &lt;code&gt;vm.swappiness&lt;/code&gt; does. &lt;code&gt;vm.swappiness&lt;/code&gt; is a sysctl that biases memory reclaim either towards reclamation of anonymous pages, or towards file pages. It does this using two different attributes: &lt;code&gt;file_prio&lt;/code&gt; (our willingness to reclaim file pages) and &lt;code&gt;anon_prio&lt;/code&gt; (our willingness to reclaim anonymous pages). &lt;code&gt;vm.swappiness&lt;/code&gt; plays into this, as it becomes the default value for &lt;code&gt;anon_prio&lt;/code&gt;, and it also is subtracted from the default value of 200 for &lt;code&gt;file_prio&lt;/code&gt;, which means for a value of &lt;code&gt;vm.swappiness = 50&lt;/code&gt;, the outcome is that &lt;code&gt;anon_prio&lt;/code&gt; is 50, and &lt;code&gt;file_prio&lt;/code&gt; is 150 (the exact numbers don't matter as much as their relative weight compared to the other).&lt;/p&gt;
    &lt;p&gt;This means that, in general, vm.swappiness is simply a ratio of how costly reclaiming and refaulting anonymous memory is compared to file memory for your hardware and workload. The lower the value, the more you tell the kernel that infrequently accessed anonymous pages are expensive to swap out and in on your hardware. The higher the value, the more you tell the kernel that the cost of swapping anonymous pages and file pages is similar on your hardware. The memory management subsystem will still try to mostly decide whether it swaps file or anonymous pages based on how hot the memory is, but swappiness tips the cost calculation either more towards swapping or more towards dropping filesystem caches when it could go either way. On SSDs these are basically as expensive as each other, so setting &lt;code&gt;vm.swappiness = 100&lt;/code&gt; (full equality) may work well. On spinning disks, swapping may be significantly more expensive since swapping in general requires random reads, so you may want to bias more towards a lower value.&lt;/p&gt;
    &lt;p&gt;The reality is that most people don't really have a feeling about which their hardware demands, so it's non-trivial to tune this value based on instinct alone ‚Äì this is something that you need to test using different values. You can also spend time evaluating the memory composition of your system and core applications and their behaviour under mild memory reclamation.&lt;/p&gt;
    &lt;p&gt;When talking about &lt;code&gt;vm.swappiness&lt;/code&gt;, an extremely important change to consider from recent(ish) times is this change to vmscan by Satoru Moriya in 2012, which changes the way that &lt;code&gt;vm.swappiness = 0&lt;/code&gt; is handled quite significantly.&lt;/p&gt;
    &lt;p&gt;Essentially, the patch makes it so that we are extremely biased against scanning (and thus reclaiming) any anonymous pages at all with &lt;code&gt;vm.swappiness = 0&lt;/code&gt;, unless we are already encountering severe memory contention. As mentioned previously in this post, that's generally not what you want, since this prevents equality of reclamation prior to extreme memory pressure occurring, which may actually lead to this extreme memory pressure in the first place. &lt;code&gt;vm.swappiness = 1&lt;/code&gt; is the lowest you can go without invoking the special casing for anonymous page scanning implemented in that patch.&lt;/p&gt;
    &lt;p&gt;The kernel default here is &lt;code&gt;vm.swappiness = 60&lt;/code&gt;. This value is generally not too bad for most workloads, but it's hard to have a general default that suits all workloads. As such, a valuable extension to the tuning mentioned in the "how much swap do I need" section above would be to test these systems with differing values for vm.swappiness, and monitor your application and system metrics under heavy (memory) load. Some time in the near future, once we have a decent implementation of refault detection in the kernel, you'll also be able to determine this somewhat workload-agnostically by looking at cgroup v2's page refaulting metrics.&lt;/p&gt;
    &lt;head rend="h3"&gt;Update as of 2019-07: memory pressure metrics in kernel 4.20+&lt;/head&gt;
    &lt;p&gt;The refault metrics mentioned as in development earlier are now in the kernel from 4.20 onwards and can be enabled with &lt;code&gt;CONFIG_PSI=y&lt;/code&gt;. See my talk at SREcon at around the 25:05 mark:&lt;/p&gt;
    &lt;head rend="h2"&gt;In conclusion&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Swap is a useful tool to allow equality of reclamation of memory pages, but its purpose is frequently misunderstood, leading to its negative perception across the industry. If you use swap in the spirit intended, though ‚Äì as a method of increasing equality of reclamation ‚Äì you'll find that it's a useful tool instead of a hindrance.&lt;/item&gt;
      &lt;item&gt;Disabling swap does not prevent disk I/O from becoming a problem under memory contention, it simply shifts the disk I/O thrashing from anonymous pages to file pages. Not only may this be less efficient, as we have a smaller pool of pages to select from for reclaim, but it may also contribute to getting into this high contention state in the first place.&lt;/item&gt;
      &lt;item&gt;Swap can make a system slower to OOM kill, since it provides another, slower source of memory to thrash on in out of memory situations ‚Äì the OOM killer is only used by the kernel as a last resort, after things have already become monumentally screwed. The solutions here depend on your system: &lt;list rend="ul"&gt;&lt;item&gt;You can opportunistically change the system workload depending on cgroup-local or global memory pressure. This prevents getting into these situations in the first place, but solid memory pressure metrics are lacking throughout the history of Unix. Hopefully this should be better soon with the addition of refault detection.&lt;/item&gt;&lt;item&gt;You can bias reclaiming (and thus swapping) away from certain processes per-cgroup using &lt;code&gt;memory.low&lt;/code&gt;, allowing you to protect critical daemons without disabling swap entirely.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Many thanks to Rahul, Tejun, and Johannes for their extensive suggestions and feedback on this post.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45318798</guid><pubDate>Sun, 21 Sep 2025 00:06:38 +0000</pubDate></item><item><title>The bloat of edge-case first libraries</title><link>https://43081j.com/2025/09/bloat-of-edge-case-libraries</link><description>&lt;doc fingerprint="6e55d2411b082c98"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The bloat of edge-case first libraries&lt;/head&gt;
    &lt;p&gt;This is just some of what I‚Äôve been pondering recently - particularly in terms of how we ended up with such overly-granular dependency trees.&lt;/p&gt;
    &lt;p&gt;I think we‚Äôve ended up with many libraries in our ecosystem which are edge-case-first, the opposite to what I‚Äôd expect. I‚Äôll give a few examples and some thoughts around this, mostly in the hope we can start to trim some of it away.&lt;/p&gt;
    &lt;head rend="h1"&gt;The problem&lt;/head&gt;
    &lt;p&gt;I believe a lot of the questionably small libraries hiding in our deep dependency trees are a result of over-engineering for inputs and edge cases we‚Äôve probably never seen.&lt;/p&gt;
    &lt;p&gt;For example, say we‚Äôre building a &lt;code&gt;clamp&lt;/code&gt; function:&lt;/p&gt;
    &lt;code&gt;export function clamp(value: number, min: number, max: number): number {
  return Math.min(Math.max(value, min), max);
}
&lt;/code&gt;
    &lt;p&gt;Pretty simple!&lt;/p&gt;
    &lt;p&gt;What if someone passes nonsensical ranges? Let‚Äôs handle that.&lt;/p&gt;
    &lt;code&gt;export function clamp(value: number, min: number, max: number): number {
  if (min &amp;gt; max) {
    throw new Error('min must be less than or equal to max');
  }
  return Math.min(Math.max(value, min), max);
}
&lt;/code&gt;
    &lt;p&gt;This is probably as far as I‚Äôd go. But let‚Äôs over-engineer - what if someone passes a number-like string?&lt;/p&gt;
    &lt;code&gt;export function clamp(value: number | string, min: number | string, max: number | string): number {
  if (typeof value === 'string' &amp;amp;&amp;amp; Number.isNaN(Number(value))) {
    throw new Error('value must be a number or a number-like string');
  }
  if (typeof min === 'string' &amp;amp;&amp;amp; Number.isNaN(Number(min))) {
    throw new Error('min must be a number or a number-like string');
  }
  if (typeof max === 'string' &amp;amp;&amp;amp; Number.isNaN(Number(max))) {
    throw new Error('max must be a number or a number-like string');
  }
  if (Number(min) &amp;gt; Number(max)) {
    throw new Error('min must be less than or equal to max');
  }
  return Math.min(Math.max(value, min), max);
}
&lt;/code&gt;
    &lt;p&gt;At this point, it seems clear to me we‚Äôve just poorly designed our function. It solely exists to clamp numbers, so why would we accept strings?&lt;/p&gt;
    &lt;p&gt;But hey, let‚Äôs go further! What if other libraries also want to accept such loose inputs? Let‚Äôs extract this into a separate library:&lt;/p&gt;
    &lt;code&gt;import isNumber from 'is-number';

export function clamp(value: number | string, min: number | string, max: number | string): number {
  if (!isNumber(value)) {
    throw new Error('value must be a number or a number-like string');
  }
  if (!isNumber(min)) {
    throw new Error('min must be a number or a number-like string');
  }
  if (!isNumber(max)) {
    throw new Error('max must be a number or a number-like string');
  }
  if (Number(min) &amp;gt; Number(max)) {
    throw new Error('min must be less than or equal to max');
  }
  return Math.min(Math.max(value, min), max);
}
&lt;/code&gt;
    &lt;p&gt;Whoops! We‚Äôve just created the infamous &lt;code&gt;is-number&lt;/code&gt; library!&lt;/p&gt;
    &lt;head rend="h1"&gt;How it should be&lt;/head&gt;
    &lt;p&gt;This, in my opinion, is poor technical design we‚Äôve all ended up dealing with over the years. Carrying the baggage of these overly-granular libraries that exist to handle edge cases we‚Äôve probably never encountered.&lt;/p&gt;
    &lt;p&gt;I think it should have been:&lt;/p&gt;
    &lt;code&gt;export function clamp(value: number, min: number, max: number): number {
  return Math.min(Math.max(value, min), max);
}
&lt;/code&gt;
    &lt;p&gt;Maybe with some &lt;code&gt;min &amp;lt;= max&lt;/code&gt; validation, but even that is debatable. At this point, you may as well inline the &lt;code&gt;Math.min(Math.max(...))&lt;/code&gt; expression instead of using a dependency.&lt;/p&gt;
    &lt;p&gt;We should be able to define our functions to accept the inputs they are designed for, and not try to handle every possible edge case.&lt;/p&gt;
    &lt;p&gt;There are two things at play here:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Data types&lt;/item&gt;
      &lt;item&gt;Values&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A well designed library would assume the right data types have been passed in, but may validate that the values make sense (e.g. &lt;code&gt;min&lt;/code&gt; is less than or equal to &lt;code&gt;max&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;These over-engineered libraries have decided to implement both at runtime - essentially run-time type checking and value validation. One could argue that this is just a result of building in the pre-TypeScript era, but that still doesn‚Äôt justify the overly specific value validation (e.g. the real &lt;code&gt;is-number&lt;/code&gt; also checks that it is finite).&lt;/p&gt;
    &lt;head rend="h1"&gt;What we shouldn‚Äôt do&lt;/head&gt;
    &lt;p&gt;We shouldn‚Äôt build edge-case-first libraries, i.e. those which solve for edge cases we have yet to encounter or are unlikely to ever encounter.&lt;/p&gt;
    &lt;head rend="h2"&gt;Example: &lt;code&gt;is-arrayish&lt;/code&gt; (76M downloads/week)&lt;/head&gt;
    &lt;p&gt;The &lt;code&gt;is-arrayish&lt;/code&gt; library determines if a value is an &lt;code&gt;Array&lt;/code&gt; or behaves like one.&lt;/p&gt;
    &lt;p&gt;There will be some edge cases where this matters a lot, where we want to accept something we can index into but don‚Äôt care if it is a real &lt;code&gt;Array&lt;/code&gt; or not.&lt;/p&gt;
    &lt;p&gt;However, the common use case clearly will not be that and we could‚Äôve just used &lt;code&gt;Array.isArray()&lt;/code&gt; all along.&lt;/p&gt;
    &lt;head rend="h2"&gt;Example: &lt;code&gt;is-number&lt;/code&gt; (90M downloads/week)&lt;/head&gt;
    &lt;p&gt;The &lt;code&gt;is-number&lt;/code&gt; library determines if a value is a positive, finite number or number-like string (maybe we should name it &lt;code&gt;is-positive-finite-number&lt;/code&gt; to be more accurate).&lt;/p&gt;
    &lt;p&gt;Again, there will be edge cases where we want to deal with number-like strings or we want to validate that a number is within a range (e.g. finite).&lt;/p&gt;
    &lt;p&gt;The common use case will not be this. The common use case will be that we want to check &lt;code&gt;typeof n === 'number'&lt;/code&gt; and be done with it.&lt;/p&gt;
    &lt;p&gt;For those edge cases where we want to additionally validate what kind of number it is, we could use a library (but one which exists for the validation, not for the type check).&lt;/p&gt;
    &lt;head rend="h2"&gt;Example: &lt;code&gt;pascalcase&lt;/code&gt; (9.7M downloads/week)&lt;/head&gt;
    &lt;p&gt;The &lt;code&gt;pascalcase&lt;/code&gt; library transforms text to PascalCase.&lt;/p&gt;
    &lt;p&gt;It has 1 dependency (&lt;code&gt;camelcase&lt;/code&gt;) and accepts a variety of input types:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;strings&lt;/item&gt;
      &lt;item&gt;null&lt;/item&gt;
      &lt;item&gt;undefined&lt;/item&gt;
      &lt;item&gt;arrays of strings&lt;/item&gt;
      &lt;item&gt;functions&lt;/item&gt;
      &lt;item&gt;arbitrary objects with &lt;code&gt;toString&lt;/code&gt;methods&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In reality, almost every user will be passing a &lt;code&gt;string&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;Example: &lt;code&gt;is-regexp&lt;/code&gt; (10M downloads/week)&lt;/head&gt;
    &lt;p&gt;The &lt;code&gt;is-regexp&lt;/code&gt; library checks if a value is a &lt;code&gt;RegExp&lt;/code&gt; object, and supports cross-realm values.&lt;/p&gt;
    &lt;p&gt;In reality, almost every user will be passing a &lt;code&gt;RegExp&lt;/code&gt; object, and not one from another realm.&lt;/p&gt;
    &lt;p&gt;For context, cross-realm values can happen when you retrieve a value from an &lt;code&gt;iframe&lt;/code&gt; or VM for example:&lt;/p&gt;
    &lt;code&gt;const iframe = document.createElement('iframe');
iframe.contentWindow.RegExp === RegExp; // false

const iframeRegex = iframe.contentWindow.someRegexp;

iframeRegex instanceof RegExp; // false
isRegex(iframeRegex); // true
&lt;/code&gt;
    &lt;p&gt;This is indeed useful, and I do support this myself in chai (which I maintain). However, this is an edge case most libraries don‚Äôt need to care about.&lt;/p&gt;
    &lt;head rend="h1"&gt;What we should do&lt;/head&gt;
    &lt;p&gt;We should build libraries which solve the common use case and make assumptions about the input types they will be given.&lt;/p&gt;
    &lt;head rend="h2"&gt;Example: scule (1.8M downloads/week)&lt;/head&gt;
    &lt;p&gt;scule is a library for transforming casing of text (e.g. camel case, etc).&lt;/p&gt;
    &lt;p&gt;It only accepts inputs it is designed for (strings and arrays of strings) and has zero dependencies.&lt;/p&gt;
    &lt;p&gt;In most of the functions it exports, it assumes valid input data types.&lt;/p&gt;
    &lt;head rend="h2"&gt;Example: dlv (14.9M downloads/week)&lt;/head&gt;
    &lt;p&gt;dlv is a library for deep property access.&lt;/p&gt;
    &lt;p&gt;It only accepts strings and arrays of strings as the path to access, and assumes this (i.e. does no validation).&lt;/p&gt;
    &lt;head rend="h1"&gt;Validation is important&lt;/head&gt;
    &lt;p&gt;Validation is important, and I want to be clear that I‚Äôm not saying we should stop validating our data.&lt;/p&gt;
    &lt;p&gt;However, we should usually be validating the data in the project that owns it (e.g. at the app level), and not in every library that later consumes it as input.&lt;/p&gt;
    &lt;p&gt;Deep dependencies applying validation like this actually shift the burden from where it belongs (at data boundaries) to deep in the dependency tree.&lt;/p&gt;
    &lt;p&gt;Often at this point, it is invisible to the consumer of the library.&lt;/p&gt;
    &lt;p&gt;How many people are passing values into &lt;code&gt;is-number&lt;/code&gt; (via other libraries), not realising it will prevent them from using negative numbers and &lt;code&gt;Infinity&lt;/code&gt;?&lt;/p&gt;
    &lt;head rend="h1"&gt;A note on overly-granular libraries&lt;/head&gt;
    &lt;p&gt;This post isn‚Äôt about overly-granular libraries in general, but I‚Äôd like to briefly mention them for visibility.&lt;/p&gt;
    &lt;p&gt;An overly-granular library is one where someone took a useful library and split it up into an almost atomic-level of granularity.&lt;/p&gt;
    &lt;p&gt;Some examples:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;shebang-regex&lt;/code&gt;- 2LOC, does the same as&lt;code&gt;startsWith('#!')&lt;/code&gt;, 86M downloads/week&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;is-whitespace&lt;/code&gt;- 7LOC, checks if a string is only whitespace, 1M downloads/week&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;is-npm&lt;/code&gt;- 8LOC, checks&lt;code&gt;npm_config_user_agent&lt;/code&gt;or&lt;code&gt;npm_package_json&lt;/code&gt;are set, 7M downloads/week&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is a personal preference some maintainers clearly prefer. The thought seems to be that by having atomic libraries, you can easily build your next library mostly from the existing building blocks you have.&lt;/p&gt;
    &lt;p&gt;I don‚Äôt really agree with this and think downloading a package for &lt;code&gt;#!&lt;/code&gt; 86 million times a week is a bit much.&lt;/p&gt;
    &lt;head rend="h1"&gt;What can be done about this?&lt;/head&gt;
    &lt;p&gt;The e18e community is already tackling a lot of this by contributing performance improvements across the ecosystem, including removing and replacing dependencies with more modern, performant ones.&lt;/p&gt;
    &lt;p&gt;Through these efforts, there‚Äôs already a useful list of replacements and an ESLint plugin.&lt;/p&gt;
    &lt;head rend="h2"&gt;As a maintainer&lt;/head&gt;
    &lt;p&gt;If you‚Äôre maintaining a library, it would be worth reviewing your dependencies to see if:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Any are replaceable by native functionality these days (e.g. &lt;code&gt;Array.isArray&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Any are replaceable by smaller, less granular and/or more performant alternatives (e.g. &lt;code&gt;scule&lt;/code&gt;instead of&lt;code&gt;pascalcase&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Any are redundant if you make more assumptions about input types&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Tools like npmgraph can help you visualise your dependency tree to make this task easier.&lt;/p&gt;
    &lt;p&gt;Also, being stricter around input types will allow you to reduce a lot of code and dependencies.&lt;/p&gt;
    &lt;p&gt;If you can assume the data being passed in is the correct type, you can leave validation up to the consumer.&lt;/p&gt;
    &lt;head rend="h2"&gt;As a user&lt;/head&gt;
    &lt;p&gt;Keep a close eye on your dependencies (both deep and direct), and what alternatives are available to your direct dependencies.&lt;/p&gt;
    &lt;p&gt;Often, it is easy to stick with a dependency from long ago and forget to re-visit it one day in case there is a better way. Many of these packages are possible natively, or have more modern alternatives.&lt;/p&gt;
    &lt;p&gt;Useful tools:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;npmgraph for visualising your dependency tree&lt;/item&gt;
      &lt;item&gt;node-modules.dev for visualising your dependencies and lots of useful meta data&lt;/item&gt;
      &lt;item&gt;Dependabot for keeping your dependencies up to date&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;On the topic of data, it is also worth ensuring validation happens at data boundaries rather than being delegated to various dependencies. Try to validate the type and value up front, before passing into dependencies.&lt;/p&gt;
    &lt;head rend="h1"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Most of these libraries exist to handle edge cases that do certainly exist. However, we are all paying the cost of that rather than only those who need to support those edge cases.&lt;/p&gt;
    &lt;p&gt;This is the wrong way around. Libraries should implement the main use case, and alternatives (or plugins) can exist to provide the edge cases the minority needs.&lt;/p&gt;
    &lt;p&gt;We should all be more aware of what is in our dependency tree, and should push for more concise, lighter libraries.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45319399</guid><pubDate>Sun, 21 Sep 2025 02:09:43 +0000</pubDate></item><item><title>Amazon to end commingling after years of complaints from brands and sellers</title><link>https://www.modernretail.co/operations/amazon-to-end-commingling-program-after-years-of-complaints-from-brands-and-sellers/</link><description>&lt;doc fingerprint="c70b858da962fde"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Amazon to end commingling program after years of complaints from brands and sellers&lt;/head&gt;
    &lt;p&gt;Amazon revealed at its annual Accelerate seller conference in Seattle that it is shutting down its long-running ‚Äúcommingling‚Äù program ‚Äî a move that drew louder applause from sellers than any other update of the morning.&lt;/p&gt;
    &lt;p&gt;The decision marks the end of a controversial practice in which Amazon pooled identical items from different sellers under one barcode. The system, intended to speed deliveries and save warehouse space, had also allowed counterfeit or expired goods to be mixed in with authentic ones, according to The Wall Street Journal. For years, brands complained that commingling made it difficult to trace problems back to specific sellers and left their reputations vulnerable when customers received knockoffs. In 2013, Johnson &amp;amp; Johnson temporarily pulled many of its consumer products from Amazon, arguing the retailer wasn‚Äôt doing enough to curb third-party sales of damaged or expired goods.&lt;/p&gt;
    &lt;p&gt;By ending commingling, Amazon is signaling a stronger commitment to protecting brands on its marketplace, while further distancing itself from resellers. The announcement underscores the company‚Äôs ongoing strategy to prioritize trusted brand relationships ‚Äî evident in moves like its revived wholesale partnership with Nike ‚Äî while responding to mounting seller and consumer frustration over counterfeit risks.&lt;/p&gt;
    &lt;p&gt;During Wednesday‚Äôs presentation in Seattle, Amazon executives said the economics of commingling no longer worked. With the company‚Äôs logistics network now capable of storing products closer to customers, the speed advantage of pooled inventory has diminished. At the same time, Amazon estimated brand owners spent $600 million in the past year alone through re-stickering products, the process of placing new labels or barcodes over existing ones on products.&lt;/p&gt;
    &lt;p&gt;‚ÄúMost products can now achieve the fast shipping speeds customers love without commingling,‚Äù Nadya Dhalla, director of Supply Chain by Amazon, said from the stage. ‚ÄúBy ending commingling, these resources can now be reinvested in growing your business.‚Äù&lt;/p&gt;
    &lt;p&gt;Ben Donovan, insights lead at Marketplace Pulse, said the announcement was ‚Äúone of the more significant‚Äù steps Amazon has taken in years to support brands. ‚ÄúIt signals a continued shift away from resellers towards brand owners,‚Äù Donovan said. ‚ÄúIt is certainly becoming a tougher environment for resellers on Amazon.‚Äù&lt;/p&gt;
    &lt;p&gt;The decision aligns with Amazon‚Äôs recent emphasis on direct partnerships with household names. In May, Amazon resumed working with Nike to source products directly, ending years of separation after Nike pulled out in 2019. That move restricted the ability of independent resellers to list certain Nike items on Amazon, Modern Retail reported at the time. And industry analysts saw it as part of a broader effort by the e-commerce giant to court major brands while tightening oversight of who can sell their goods.&lt;/p&gt;
    &lt;p&gt;The end of commingling coincided with Amazon‚Äôs heavy promotion of a new AI-powered seller assistant described as ‚Äúagentic.‚Äù Amazon touted its new seller assistant several times over the course of the 90-minute presentation. Amazon pitched the tool as able to resolve support tickets, optimize storage to help avoid fees and recommend operational improvements across a seller‚Äôs business. Yet despite the fanfare around AI, it was the decision to sunset commingling ‚Äî a little-known policy to most consumers ‚Äî that seemed to resonate most with sellers.&lt;/p&gt;
    &lt;p&gt;Amazon said commingling will be phased out across its supply chain later this year.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45319463</guid><pubDate>Sun, 21 Sep 2025 02:23:59 +0000</pubDate></item><item><title>iFixit iPhone Air teardown</title><link>https://www.ifixit.com/News/113171/iphone-air-teardown</link><description>&lt;doc fingerprint="b569c1074bc717dd"&gt;
  &lt;main&gt;
    &lt;p&gt;To be honest, we were holding our breath for the iPhone Air. Thinner usually means flimsier, harder to fix, and more glued-down parts. But the iPhone Air proves otherwise. Apple has somehow built its thinnest iPhone ever without tanking repairability.&lt;/p&gt;
    &lt;p&gt;Just a few months ago, Samsung‚Äôs Galaxy S25 Edge pulled off a similar trick in an ultra-thin package. How‚Äôd they do it? And how‚Äôd Apple follow suit?&lt;/p&gt;
    &lt;p&gt;The secret: Thinner can actually be more repairable, with clever design.&lt;/p&gt;
    &lt;head rend="h2"&gt;Clever Use of Space&lt;/head&gt;
    &lt;p&gt;Apple made one huge design shift in the Air, which they teased in their keynote and we confirmed with our Lumafield Neptune CT scanner: The middle of this phone is basically just a battery with a frame around it. Apple popped the logic board up above the battery, a large part of how their design got thinner without compromising repair.&lt;/p&gt;
    &lt;p&gt;When we score repairability, 80% of our score is determined by the ease of replacing the parts that are most important and most likely to break. To figure this out, we build a model of the repair process. What‚Äôs the path you have to take to get to the battery, or to the screen? We call this the ‚Äúdisassembly tree.‚Äù The ideal (if unlikely) disassembly tree is flat. No parts in the way of other parts.&lt;/p&gt;
    &lt;p&gt;A thin device often means, advantageously, a flat disassembly tree. Stacked parts are thicker than parts side-by-side. Our friends over at Framework have been saying this for a long time: It‚Äôs totally possible to make a thin and light device that‚Äôs also built for repair. The Framework Laptop has done this from the start, with nearly all major components accessible when you remove the cover.&lt;/p&gt;
    &lt;p&gt;And that‚Äôs exactly what we‚Äôre seeing in the Air. The logic board shift freed up room for the battery and helped the phone stay thin without cramming parts on top of each other. It also conveniently puts less stress on the board if the phone flexes in your pocket. It‚Äôs a smart workaround for the ‚Äúbendgate‚Äù problems that haunted earlier slim iPhone designs. Not that the Air‚Äôs really going to be bending much, as Zack‚Äôs test at Jerry Rig Everything suggests.&lt;/p&gt;
    &lt;p&gt;(By the way, did you see we‚Äôre teaming up with Zack to bring you a toolkit that‚Äôs made for on-the-go repairs and durability testing?)&lt;/p&gt;
    &lt;p&gt;The Air trims a few extras compared to the Plus line it succeeds, losing the lower speaker and a rear camera. Like the 16e, it‚Äôs got just a single rear camera.&lt;/p&gt;
    &lt;p&gt;Inside, though, it packs the upgraded C1X modem, a new N1 WiFi chip, and the A19 Pro system-on-chip, all tucked into the logic board sandwich. It‚Äôs a lean, efficient setup that makes the most of limited space. This reduced complexity also contributes to quicker disassembly‚Äîfewer features, fewer parts, and fewer points of failure.&lt;/p&gt;
    &lt;head rend="h2"&gt;Battery Life? Eh. Battery Swaps? No Big Deal&lt;/head&gt;
    &lt;p&gt;There‚Äôs been a lot of buzz about battery life on this phone. Apple said ‚Äúall-day battery life,‚Äù and tech reviewers of the world, noting the lack of watt-hour specificity and immediate announcement of an add-on battery pack, said, ‚Äúreally now?‚Äù At 12.26 Wh, this battery is certainly smaller than recent iPhones (closest comparison being the 13 Pro‚Äôs 11.97 Wh), and that raises questions about longevity. More charging cycles usually means faster wear. Still, Apple‚Äôs efficiency tricks give it solid runtime, at least for now.&lt;/p&gt;
    &lt;p&gt;But no battery lasts forever, so how difficult will swaps be? We‚Äôre relieved to see that the Air has all the greatest hits of the last few iPhone battery designs.&lt;/p&gt;
    &lt;p&gt;The Air‚Äôs battery is easy to find and accessible through the back glass thanks to Apple‚Äôs dual entry design. Even better, it‚Äôs a metal-encased battery. This thin layer of armor makes it more bend resistant and safer to replace. Even better than that, it‚Äôs mounted with electrically debonding adhesive strips. Hook them up to a power source and the battery lifts right out, no dangerous prying required. We used our FixHub Portable Power Station for an easy 12 V, and each strip freed after about 70 seconds.&lt;/p&gt;
    &lt;p&gt;Even though it‚Äôs comparably a small battery, its heft accounts for 28% of the phone‚Äôs total weight, more than any other component.&lt;/p&gt;
    &lt;p&gt;And in a fun twist, we‚Äôve confirmed that it‚Äôs the exact same cell found in Apple‚Äôs MagSafe battery pack. You can swap between them and the phone still boots up just fine. Like a rear-mounted spare tire on an SUV, an iPhone Air with a MagSafe battery pack is ready for an on-the-go swap, if you will. Granted it‚Äôll take a bit more than a tire iron to make it happen.&lt;/p&gt;
    &lt;head rend="h2"&gt;Modular Port, but How About Parts to Back It Up?&lt;/head&gt;
    &lt;p&gt;How about other likely-to-fail parts? USB-C ports are among the most common failure points in modern phones. Ports tend to collect moisture, which can cause corrosion, and no one is immune to pocket lint. Not to mention the standard port problems caused by mechanical wear and tear.&lt;/p&gt;
    &lt;p&gt;Now, to be clear, if your phone stops charging consistently, you shouldn‚Äôt jump straight to replacing the port. Every time you stick a charge cable into the port, you‚Äôre jamming pocket lint against the back. Give your charge port a cleanout before you replace it.&lt;/p&gt;
    &lt;head rend="h3"&gt;How to Clean the Ports on your Electronic Device&lt;/head&gt;
    &lt;p&gt;Use this guide to clean the ports on your‚Ä¶&lt;/p&gt;
    &lt;p&gt;But when you do need to replace an Air charging port, you‚Äôll be glad to know it‚Äôs decently modular, following the trend of the last few iPhone models. It‚Äôs a tedious process, with delicate flex cables, adhesive, and hard-to-reach screws, but it‚Äôs still feasible.&lt;/p&gt;
    &lt;p&gt;Interestingly, the modularity of the USB-C port doesn‚Äôt seem to be a serviceability choice. Apple won‚Äôt do USB-C repairs in-house and they don‚Äôt sell replacement ports for iPhones. Of course that won‚Äôt stop us from selling the parts as soon as we can get them‚Äîand regardless of intent, this modularity is nice to have.&lt;/p&gt;
    &lt;p&gt;Third-party parts manufacturers may take a bit to catch up, since this is a brand new architecture for the housing of the USB port. Apple reportedly used 3D printing to shrink the housing to fit the slim frame of the 6.5mm iPhone Air.&lt;/p&gt;
    &lt;p&gt;Apple says this process reduced material usage by 33% compared to conventional forging processes. Granted, the USB-C port is already tiny. But this isn‚Äôt the only place they‚Äôre using it: The Apple Watch Ultra 3 uses the same titanium-printing process in its case.&lt;/p&gt;
    &lt;p&gt;We took a close look at the titanium material in the USB-C port, with our Evident DSX2000 microscope.&lt;/p&gt;
    &lt;p&gt;What we saw was fascinating: these regular bubble-like structures.&lt;/p&gt;
    &lt;p&gt;We tapped in some friends in the additive manufacturing industry, who said it wasn‚Äôt quite like any metal 3D printing they‚Äôd seen before. Their best guess is that Apple‚Äôs using a binder or aerosol jet process in addition to some after-printing machining. This aligns with a binder jetting patent Apple inherited back in 2015 when they acquired Metaio. Whatever the exact process, the result is some truly impressive titanium manipulation.&lt;/p&gt;
    &lt;p&gt;(If you‚Äôre a metal 3D printing expert and want to give us your thoughts in the comments, we‚Äôd love to hear from you!)&lt;/p&gt;
    &lt;head rend="h2"&gt;How Strong Is Thin?&lt;/head&gt;
    &lt;p&gt;Titanium may have retired from the rest of the iPhone line (possibly for geopolitical more than technical reasons) but it‚Äôs back as the backbone of this slim smartphone. This tough metal is a good choice, but it‚Äôs only as strong as its weak points. Our empty-frame bend test snapped the Air at its plastic antenna passthroughs‚Äîa necessity if you want your phone to phone properly. CT scans make it clear: Apple reinforced the center section, but the top and bottom remain vulnerable.&lt;/p&gt;
    &lt;p&gt;Of course, the center is where the phone is most likely to bend, and so far testing hasn‚Äôt given any indication of undue flexibility. Will that design affect the durability of the phone? We doubt we‚Äôll see instances of Airs snapping at the ends, but only time will tell.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Verdict: A 7 out of 10 Repairability Score&lt;/head&gt;
    &lt;p&gt;At 6.5 mm, the Air is a hair thinner than Samsung‚Äôs Galaxy S25 Edge, yet it manages to keep modular parts and early battery access. Apple‚Äôs dual entry design makes battery swaps simple and keeps the fancy OLED out of harm‚Äôs way. Electrically debonding adhesive makes battery replacements a lot more consistent than traditional or stretch-release adhesive, and most other major components are simple to access and remove. Apple also kept their best-in-class clipped- and screwed-in screen and back glass architecture, enabling quick reassembly without requiring special adhesive.&lt;/p&gt;
    &lt;p&gt;Combined with Apple‚Äôs continued commitment to day-one repair manuals, the iPhone Air earns a provisional 7 out of 10 repairability score. (We‚Äôre waiting on Apple to make good on their parts availability commitment as well as final results on our parts pairing tests. Their recent track record‚Äôs pretty good, though.)&lt;/p&gt;
    &lt;p&gt;Apple has proved that thin doesn‚Äôt have to mean unfixable. The iPhone Air is slimmer than any iPhone before it, but its layout and design tradeoffs make repairs more approachable, not less. It still has limits, but the design shows that good engineering can make even the slimmest devices last longer in the real world. Successful field test for your new foldable, Apple. We‚Äôre onto you!&lt;/p&gt;
    &lt;p&gt;More Apple 2025 lineup teardowns coming soon. Bonus round: Can TechWoven handle‚Ä¶ hot sauce?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45319690</guid><pubDate>Sun, 21 Sep 2025 03:09:47 +0000</pubDate></item><item><title>Spectral Labs releases SGS-1: the first generative model for structured CAD</title><link>https://www.spectrallabs.ai/research/SGS-1</link><description>&lt;doc fingerprint="a55b8b523846d2a2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing SGS-1&lt;/head&gt;
    &lt;p&gt;Spectral Labs releases SGS-1: the first generative model for structured CAD.&lt;/p&gt;
    &lt;p&gt;Today we are announcing SGS-1, a foundation model that can generate fully manufacturable and parametric 3D geometry. You can try a research preview of SGS-1 here.&lt;/p&gt;
    &lt;p&gt;Given an image or a 3D mesh, SGS-1 can generate CAD B-Rep parts in STEP format. Unlike all other existing generative models, SGS-1 outputs are accurate and can be edited easily in traditional CAD software.&lt;/p&gt;
    &lt;p&gt;Overview of SGS-1 - users can provide an image or ‚Äúdumb‚Äù 3D file, and get back a parametric B-Rep file that can be easily edited to match specific dimensions&lt;/p&gt;
    &lt;p&gt;SGS-1 shows strong general results, producing much more complex and diverse CAD shapes than existing methods.&lt;/p&gt;
    &lt;p&gt;Illustrative results from SGS-1&lt;/p&gt;
    &lt;p&gt;SGS-1 can be used for real-world engineering tasks. In the below example, SGS-1 is used to design a bracket for a roller assembly from partial context and a text description (additional details below in Generating Parametric Geometry in Assembly Context section).&lt;/p&gt;
    &lt;head rend="h2"&gt;Results and comparing SGS-1 to prior models&lt;/head&gt;
    &lt;p&gt;We compare SGS-1 to SOTA multimodal reasoning LLMs and open-source image-to-CAD models: GPT-5 thinking, a large reasoning model by OpenAI that can produce CadQuery code to represent parametric geometry, and HoLa, a 205M parameter latent diffusion model with 181M parameter VAE that generate B-Rep geometry conditioned on a single input image. We develop a benchmark set of 75 images depicting medium to high complexity parametric geometry, sourced from CAD image renders of various styles, engineering sketches, and images generated by generative AI models. Model performance is evaluated by successful/failed creation of a single valid watertight solid that is an accurate representation of the input image using distance metrics (Success Ratio).&lt;/p&gt;
    &lt;p&gt;Quantitative evaluations&lt;/p&gt;
    &lt;p&gt;We run each model 10 times and show scores for all 10 runs, as well as for the best output of the 10. Although GPT-5 and HoLa BRep can attain non-zero performance on the easiest images, SGS-1 is the best performing model with at least one success for all but the most complex objects.&lt;/p&gt;
    &lt;p&gt;Outputs from the SOTA large reasoning model (GPT-5) demonstrate a clear lack of spatial understanding, producing outputs that are unusable or too simple to actually be useful. We use both SGS-1 and GPT-5 to generate the parametric geometry for the rail mount from the input image, in order to produce the desired target complete assembly.&lt;/p&gt;
    &lt;p&gt;SGS-1 accurately represents the geometry and can be plugged into an assembly context, while the output from the large reasoning model is missing core spatial features.&lt;/p&gt;
    &lt;head rend="h2"&gt;Generating Parametric Geometry in Assembly Context&lt;/head&gt;
    &lt;p&gt;With SGS-1, you can create new parametric geometry within your current assembly context. In this example, SGS-1 takes in a partial CAD assembly and a text description/image of a bracket, and produces a 3D design for a bracket that is feasible for the context.&lt;/p&gt;
    &lt;p&gt;First, render the partial assembly and come up with a text description of the parts you want to add. Next, run it through SGS-1, which will output a parametric B-Rep in the form of a downloadable STEP fileFinally, import the STEP file into your partial assembly and adjust dimensions until the part fits correctly into the assembly&lt;/p&gt;
    &lt;p&gt;SGS-1 is capable of generating diverse designs for tasks like this - several bracket designs created by SGS-1 are shown below:&lt;/p&gt;
    &lt;head rend="h2"&gt;Converting Sketches and Engineering Drawings to B-Rep&lt;/head&gt;
    &lt;p&gt;SGS-1 can be used to convert simple freehand sketches and engineering drawings into geometry that you can work in in your CAD editor. In this example, we run sketches and drawings through SGS-1 to create parametric geometry.&lt;/p&gt;
    &lt;p&gt;Use SGS-1 to transform sketches and drawings into 3D CAD files&lt;/p&gt;
    &lt;p&gt;This works well on simple hand sketches, enabling powerful design workflows.&lt;/p&gt;
    &lt;p&gt;This also works on structured engineering drawings.&lt;/p&gt;
    &lt;head rend="h2"&gt;Automating Reverse Engineering and STL to STEP File Conversion&lt;/head&gt;
    &lt;p&gt;SGS-1 can be used to convert scans and standalone STL or other mesh files to parametric STEP files without any human input, automating reverse engineering of many shapes.&lt;/p&gt;
    &lt;p&gt;Use SGS-1 to convert dumb 3D representations to parametric geometry&lt;/p&gt;
    &lt;head rend="h2"&gt;Limitations&lt;/head&gt;
    &lt;p&gt;SGS-1 is designed to generate parametric 3D geometry for engineering use cases, and struggles when tasked with generating creative assets and organic shapes with complex curvature. In addition, SGS-1 has a limited 3D resolution and struggles with generating very thin structures. Finally, SGS-1 cannot create full assemblies in one shot. We plan to address these limitations with our next model generation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Next Steps&lt;/head&gt;
    &lt;p&gt;SGS-1 represents a significant step forward for foundation models that can generate 3D geometry for engineering tasks. We plan to continue pushing forward the frontier, by training models that can engineer physical systems of increasing complexity. The next generation of models will be natively multimodal, support larger and more complex spatial context, and will be capable of performing more advanced physical reasoning through longer range planning. As we continue to scale up these models, we are excited about scaling up reinforcement learning using physical simulation feedback, which will unlock new physical reasoning capabilities for our models.&lt;/p&gt;
    &lt;p&gt;If you are interested in deploying SGS-1 or collaborating on research, please contact us through this form.&lt;/p&gt;
    &lt;p&gt;We are also hiring! Our team is composed of top AI researchers and engineers with previous experience at institutions such as Autodesk Research, Samsung Research, CMU, and Meta. If you're interested in our work and mission, please get in touch.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45319876</guid><pubDate>Sun, 21 Sep 2025 03:46:07 +0000</pubDate></item><item><title>Representing Heterogeneous Data (2023)</title><link>https://journal.stuffwithstuff.com/2023/08/04/representing-heterogeneous-data/</link><description>&lt;doc fingerprint="5450dc984f900a15"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Representing Heterogeneous Data&lt;/head&gt;‚Üê ‚Üí&lt;head rend="h4"&gt;August 04, 2023&lt;/head&gt;&lt;p&gt;As I mentioned in the last post, I‚Äôm working on taking my little videogame scripting language and turning it into a statically typed one. As much as possible, I‚Äôm trying to make the language simple and familiar. But sometimes those goals are in opposition and the most familiar solution to a problem is kind of a mess.&lt;/p&gt;&lt;p&gt;So, I‚Äôm also exploring novel approaches and delving deeper into programming language history to scavenge forgotten ideas.&lt;/p&gt;&lt;head rend="h2"&gt;The heterogeneous data problem&lt;/head&gt;&lt;p&gt;One problem every language has to solve is giving users a way to represent heterogeneous data. By that, I mean:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;Data that might or might not be present. Imagine you have a record for storing a street address:&lt;/p&gt;&lt;code&gt;rec Address var number Int var street String var apartmentNumber Int var city String var zipCode Int var state String end&lt;/code&gt;&lt;p&gt;But some addresses don‚Äôt have apartment numbers. How do you store the apartment number when an address has one but also support its absence?&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Data that might be in one of several different forms. You‚Äôre making a game where a hero can wield weapons. Melee weapons like swords have a single number for how much damage they do. Ranged weapons like crossbows have a pair of numbers for the minimum and maximum range they can reach. How do different kinds of weapons have different fields?&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;These are two sides of the exact same coin. You can treat optional data as data that can be in one of two forms: present with an associated value or absent with no value attached. Functional languages with an option or maybe type do exactly that: The language directly supports data that can have one of multiple forms, and they model absent data using that.&lt;/p&gt;&lt;p&gt;Conversely, you could model data being in one of several different forms by having separate fields for all possible forms it could be in. At any point in time, only one of the fields has a value and the others are all absent. If you‚Äôve ever found yourself building a struct or class and writing a comment that says ‚ÄúIf this field is blah then this other field will be null.‚Äù then you‚Äôve taken this path (and probably felt a little gross doing it).&lt;/p&gt;&lt;head rend="h2"&gt;What other languages do&lt;/head&gt;&lt;p&gt;I don‚Äôt know if broad language tours are your thing, but so much of my job working on Dart involves researching how other languages solve a problem that I can‚Äôt help myself anymore.&lt;/p&gt;&lt;p&gt;There are a handful of solutions to the problem. I‚Äôll just throw out the ones I know:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;Null. The most famously maligned approach is to allow any reference variable to potentially refer to ‚Äúnull‚Äù, ‚Äúnil‚Äù, or nothing. This means every reference type can directly also represent an absent value. Of course, the problem is that many data fields aren‚Äôt heterogeneous and should always be present. If you make every single reference nullable, you‚Äôve lost the ability to distinguish ones that can be absent from ones that really shouldn‚Äôt be.&lt;/p&gt;&lt;p&gt;This is why many newer statically typed languages either don‚Äôt support null at all (Rust and most other statically typed functional languages) or support non-nullable types (Dart, Kotlin, and TypeScript).&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Variant types. A ‚Äúvariant‚Äù type is a type that can hold a value of one of multiple different types. You can think of nullable references as a limited variant type that can hold either a value of one specific type or the special&lt;/p&gt;&lt;code&gt;null&lt;/code&gt;value but that‚Äôs it. Some languages have looser variants that let you store values of any type in the same variable.&lt;/item&gt;&lt;item&gt;&lt;p&gt;Untagged unions. C lets you define a data structure whose fields all share overlapping memory. If you have a few different pieces of data that are disjoint‚Äîyou should only ever have one of them and not the others‚Äîthen this avoids the memory overhead of storing them all separately.&lt;/p&gt;&lt;p&gt;However, in C, the language itself doesn‚Äôt keep track of which piece of data you have in the union. It will freely let you write one field and then read out another and it will happily just reinterpret the bits in memory as that other type. Efficient, yes. Safe? No.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Sum types. Functional languages going all the way back to ML have a feature also sometimes confusingly called ‚Äúunions‚Äù that is fairly different. Again, you have an object that can store one of a few different kinds of data. But the language also stores a tag in there so that it knows at runtime which piece of data you have. (This is why they‚Äôre also called ‚Äútagged unions‚Äù or ‚Äúdiscriminated unions‚Äù.)&lt;/p&gt;&lt;p&gt;The language uses pattern matching to cleverly prevent you from accessing the data as the wrong type.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Subtyping. The object-oriented dual to sum types is subtyping: either inheritance or interface implementation. In an object-oriented language, we could model our weapon example like:&lt;/p&gt;&lt;code&gt;interface class Weapon {} class MeleeWeapon implements Weapon { int damage; MeleeWeapon(this.damage); } class RangedWeapon implements Weapon { int minRange; int maxRange; RangedWeapon(this.minRange, this.maxRange); }&lt;/code&gt;&lt;p&gt;Code that wants to work with weapons generally uses the&lt;/p&gt;&lt;code&gt;Weapon&lt;/code&gt;supertype. The two subtypes for melee and ranged weapons each store the fields they need. If you want to go all the way to an object-oriented style, these fields would be private and then you‚Äôd have abstract methods in&lt;code&gt;Weapon&lt;/code&gt;that are overridden in the subclasses to use them.&lt;p&gt;It‚Äôs a complex, heavyweight approach, but a powerful and flexible one.&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;There may be a couple of other weirder language features you can use to model varied data, but I think these are the big ones. Languages tend to pick and choose from this list:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;Dynamically typed languages essentially treat all variables as variant types. And all the ones I know also go ahead and allow null too. If you‚Äôre not going to have any static checking anyway, you may as well be maximally permissive, I guess.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Statically typed functional languages lean really hard on sum types.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Object-oriented languages obviously primarily use subtyping, though most also have nullable reference types.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;C makes pointer types nullable and supports untagged unions. It doesn‚Äôt have (checked) variants or subtyping, but it can approximate both by allowing pointers to be cast to different types. C++ takes everything C has and also explicitly supports subtyping.&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Newer, bigger multi-paradigm languages like C# and Swift tend to take just about all of the approaches.&lt;/p&gt;&lt;head rend="h2"&gt;Whither for my little language?&lt;/head&gt;&lt;p&gt;OK, so what‚Äôs the right approach for my aspirationally simple and elegant statically typed game scripting language?&lt;/p&gt;&lt;p&gt;I quite like object-oriented programming in general, but subtyping adds a lot of complexity to a static type system, so my current plan is to not have subtyping in the language at all. That rules out that approach.&lt;/p&gt;&lt;p&gt;My goal is for the language to be fairly high level and expressive. It‚Äôs supposed to be a language that makes making games fun, not necessarily a high-performance machine for engineering giant AAA games. I want you to have a good time tinkering on pixelly 2D games, not write the next Unreal Engine in it. To that end, the language is garbage-collected. That means memory safety, which rules out untagged unions.&lt;/p&gt;&lt;p&gt;Back when this language was dynamically typed, it had &lt;code&gt;nil&lt;/code&gt;, so that‚Äôs an
obvious approach. But I‚Äôve spent, like, way too much of my time
rooting out nullable references from Dart and the last thing I want
to do with my hobby project is to go back to square one.&lt;/p&gt;&lt;p&gt;That basically just leaves sum types and variant types. Given that my language is statically typed and not object-oriented, sum types are the obvious approach. Everyone who uses sum types loves them, myself included. Algebraic datatypes are just cool.&lt;/p&gt;&lt;p&gt;And, in fact, I went ahead and implemented a protype of sum types and pattern matching and destructuring in my language. It worked. It was‚Ä¶ just OK. To explain why requires a little context&lt;/p&gt;&lt;head rend="h2"&gt;An imperative, procedural language&lt;/head&gt;&lt;p&gt;My language is unabashedly imperative. I like imperative programming, especially for scripting little games. Games are giant balls of mutable state. I‚Äôve watched my kids and many others learn to program, and imperatively modifying stuff seems to be a natural way to think about defining a process.&lt;/p&gt;&lt;p&gt;When you read a recipe for cake, you don‚Äôt see steps like: ‚ÄúProduce a new bowl of batter which is the previous bowl of batter and 2 cups of sugar.‚Äù It just says ‚ÄúAdd 2 cups of sugar to the bowl.‚Äù&lt;/p&gt;&lt;p&gt;Now, I know all of the problems with mutation of state and imperative code when programming in the large. I get it. But this is supposed to be a fun little language for fun little games and, to me, imperative programming fits that to a tee.&lt;/p&gt;&lt;p&gt;The basic vibe I have for the language is similar to Pascal, C, or BASIC: In other words, a classic procedural language. Structures and functions. It looks like this:&lt;/p&gt;&lt;code&gt;rec MeleeWeapon
  var damage Int
end

def attack(weapon MeleeWeapon, monster Monster, distance Int)
  if distance &amp;gt; 1 then
    print("You are out of range.")
    return
  end

  var damage = rollDice(weapon.damage)
  if monster.health &amp;lt;= damage then
    print("You kill the monster!")
    monster.health = 0
  else
    print("You wound the monster.")
    monster.health = monster.health - damage
  end
end
&lt;/code&gt;&lt;p&gt;What‚Äôs cool about simple procedural code is that even though I have no idea what language you know and you certainly have never programmed in this one, I‚Äôm still pretty confident that you understand this code.&lt;/p&gt;&lt;head rend="h2"&gt;With sum types&lt;/head&gt;&lt;p&gt;Let‚Äôs see how it looks with something like sum types:&lt;/p&gt;&lt;code&gt;rec Weapon
case MeleeWeapon
  var damage Int
case RangedWeapon
  var minRange Int
  var maxRange Int
end

def attack(weapon Weapon, monster Monster, distance Int)
  var isInRange = match weapon
  case MeleeWeapon(damage) then distance == 1
  case RangedWeapon(min, max) then distance &amp;gt;= min and distance &amp;lt;= max
  end

  if !isInRange then
    print("You are out of range.")
    return
  end

  var damage = match weapon
  case MeleeWeapon(damage) then rollDice(damage)
  case RangedWeapon(min, max) then max - min
  end

  if monster.health &amp;lt;= damage then
    print("You kill the monster!")
    monster.health = 0
  else
    print("You wound the monster.")
    monster.health = monster.health - damage
  end
end
&lt;/code&gt;&lt;p&gt;The sort of weird &lt;code&gt;rec&lt;/code&gt; syntax is defining a sum type, &lt;code&gt;Weapon&lt;/code&gt;, with type
constructors &lt;code&gt;MeleeWeapon&lt;/code&gt; and &lt;code&gt;RangedWeapon&lt;/code&gt;. I‚Äôm still noodling on the syntax.&lt;/p&gt;&lt;p&gt;Now, the code here works. And it‚Äôs safe. The compiler and the structure of the pattern matching code itself prevent you from accessing the wrong fields from a weapon of a different kind. That‚Äôs cool.&lt;/p&gt;&lt;p&gt;But it‚Äôs so much weirder than the previous code. In a procedural language, the idiomatic way to access fields on records is simply &lt;code&gt;record.field&lt;/code&gt;. That syntax
is in almost every programming language all the way back to Algol. But once you
hop over to sum types, you lose that syntax entirely and have to instead sort of
‚Äúinvert‚Äù the code and use pattern matching and destructuring.&lt;/p&gt;&lt;p&gt;I do love pattern matching and destructuring‚ÄîI just spent the past year of my life adding it to Dart. But for this language, I‚Äôm pushing really hard on simplicity. If possible, I don‚Äôt want two different ways to access state on a value, depending on whether the field is case-specific or not.&lt;/p&gt;&lt;p&gt;More to the point, there‚Äôs no graceful way to handle mutable sum type fields using pattern matching. SML eschews mutability in general and then works around it by allowing you to define explicit mutable ref types. But that‚Äôs definitely not how my language rolls.&lt;/p&gt;&lt;head rend="h2"&gt;Variant records&lt;/head&gt;&lt;p&gt;There is one other approach to heterogeneous data that I found that I didn‚Äôt put in the list up there because, as far as I can tell, it‚Äôs basically a dead end in the evolutionary history of programming languages.&lt;/p&gt;&lt;p&gt;Some versions of Pascal have a thing called ‚Äúvariant records‚Äù. A record in Pascal is your basic ‚Äúcollection of fields‚Äù struct type. A variant record says that some of those fields are only accessible when the record is one of a few different enumerated states.&lt;/p&gt;&lt;p&gt;In C, it‚Äôs common to wrap an untagged union in a struct along with a tag enum indicating which branch of the union is active:&lt;/p&gt;&lt;code&gt;typedef enum {
  WEAPON_MELEE,
  WEAPON_RANGED
} WeaponType;

typedef struct {
  WeaponType type;
  union {
    struct {
      int damage;
    } melee;
    
    struct {
      int minRange;
      int maxRange;
    } ranged;
  } as;
} Weapon;
&lt;/code&gt;&lt;p&gt;Using it looks something like:&lt;/p&gt;&lt;code&gt;Weapon weapon;
weapon.type = WEAPON_MELEE;
weapon.as.melee.damage = 6;
&lt;/code&gt;&lt;p&gt;A variant record in Pascal (as I understand it from the half dozen ancient slideshows I‚Äôve been able to find about it) essentially models that pattern directly.&lt;/p&gt;&lt;p&gt;The cool thing about this feature is that the variant-specific fields are accessed using the same familiar field access syntax used everywhere else. That also means variant-specific fields can be mutable.&lt;/p&gt;&lt;p&gt;Of course, the not cool thing about using that same field syntax is that there‚Äôs nothing preventing you from accessing the wrong variant field:&lt;/p&gt;&lt;code&gt;Weapon weapon;
weapon.type = WEAPON_MELEE;
weapon.as.melee.damage = 6;

printf("Min range %d\n", weapon.as.ranged.minRange); // Oops.
&lt;/code&gt;&lt;p&gt;There is a type tag, but the language doesn‚Äôt know and doesn‚Äôt check it. This is definitely true in C and I think true in Pascal. (It‚Äôs always hard to talk about Pascal definitively because there‚Äôs no ‚ÄúPascal‚Äù, just a huge family of loosely-related Pascal-ish languages.)&lt;/p&gt;&lt;p&gt;In a memory safe language like mine, I definitely don‚Äôt want users to be able to reinterpret memory. But that‚Äôs a solvable problem.&lt;/p&gt;&lt;head rend="h2"&gt;Record cases&lt;/head&gt;&lt;p&gt;Which, finally, brings us to the feature I designed for my language. It‚Äôs very close to variant records in Pascal. The type declaration looks just like the sum type example:&lt;/p&gt;&lt;code&gt;rec Weapon
case MeleeWeapon
  var damage Int
case RangedWeapon
  var minRange Int
  var maxRange Int
end
&lt;/code&gt;&lt;p&gt;The difference is that you don‚Äôt need to rely on pattern matching to access the variant fields. They‚Äôre just fields:&lt;/p&gt;&lt;code&gt;def attack(weapon Weapon, monster Monster, distance Int)
  if weapon is MeleeWeapon and distance &amp;gt; 1 or
      distance &amp;lt; weapon.minRange or
      distance &amp;gt; weapon.maxRange then
    print("You are out of range.")
    return
  end

  var damage = if weapon is MeleeWeapon then
    rollDice(weapon.damage)
  else
    weapon.maxRange - weapon.minRange
  end

  if monster.health &amp;lt;= damage then
    print("You kill the monster!")
    monster.health = 0
  else
    print("You wound the monster.")
    monster.health = monster.health - damage
  end
end
&lt;/code&gt;&lt;p&gt;Of course, you lose the compile-time safety that pattern matching gives you where you can‚Äôt access fields of the wrong type. But we don‚Äôt need to go all the way to C‚Äôs level of unsafety. Instead, when you access a case-specific field on a record, if the record‚Äôs type tag is set to a different case, the access throws a runtime error. This preserves memory safety.&lt;/p&gt;&lt;p&gt;This is a real trade-off. The feature I have here provides strictly less static safety than using sum types. There is a slight performance cost to checking the type tag when accessing case-specific fields. In return, you get simpler, more familiar syntax for working with case-specific fields, including mutable ones.&lt;/p&gt;&lt;p&gt;Also, it allows a single record to have a mixture of shared and case-specific fields:&lt;/p&gt;&lt;code&gt;rec Weapon
  var name String
  var bonus Int
case MeleeWeapon
  var damage Int
case RangedWeapon
  var minRange Int
  var maxRange Int
end
&lt;/code&gt;&lt;p&gt;Here, &lt;code&gt;name&lt;/code&gt; and &lt;code&gt;bonus&lt;/code&gt; can be accessed on all &lt;code&gt;Weapon&lt;/code&gt; instances, but the
other fields are case specific. It sort of combines product and sum types into a
single construct. I‚Äôve found this to be really handy in practice.&lt;/p&gt;&lt;p&gt;I haven‚Äôt decided if I‚Äôm totally sold on this feature yet. But in the (admittedly small) amount of example code I‚Äôve written using it so far, it seems to feel pretty nice. For a small game scripting language, I think it may strike a decent balance between static safety and simplicity.&lt;/p&gt;&lt;head rend="h2"&gt;Update: What about flow typing?&lt;/head&gt;&lt;p&gt;When I first posted this, the most common reply was why not do some sort of flow typing? In code like:&lt;/p&gt;&lt;code&gt;def attack(weapon Weapon, monster Monster, distance Int)
  if weapon is RangedWeapon and
        (distance &amp;lt; weapon.minRange or distance &amp;gt; weapon.maxRange) or
      distance &amp;gt; 1 then
    print("You are out of range.")
    return
  end

  # ...
end
&lt;/code&gt;&lt;p&gt;The compiler could do control flow analysis to determine that the &lt;code&gt;.minRange&lt;/code&gt;
and &lt;code&gt;.maxRange&lt;/code&gt; calls are guarded by an &lt;code&gt;is RangedWeapon&lt;/code&gt; and thus allow them.
But if you don‚Äôt guard the code with that kind of check, you‚Äôd get an error:&lt;/p&gt;&lt;code&gt;def attack(weapon Weapon, monster Monster, distance Int)
  if distance &amp;lt; weapon.minRange or # Error! Can't access .minRange here.
     distance &amp;gt; weapon.maxRange then
    print("You are out of range.")
    return
  end

  # ...
end
&lt;/code&gt;&lt;p&gt;This is definitely a thing you can do! TypeScript, Kotlin, Flow, Dart, and others all support it. The general technique is called ‚Äúcontrol flow analysis‚Äù and the specific feature is called ‚Äúflow typing‚Äù, ‚Äúsmart casts‚Äù, or ‚Äútype promotion‚Äù depending on which language.&lt;/p&gt;&lt;p&gt;Is it a good fit for my language? I do like that it makes imperative code ‚Äújust work‚Äù while being safe. But that ‚Äújust‚Äù is doing a lot of heavy lifting. We do this analysis in Dart and it is fantastically complex. Proving that a certain piece of code can only be reached by going through some other piece of code first gets hard quickly in the presence of loops and closures. It seems like every release of Dart, we ship more extensions to flow analysis because users keep expecting it to be smarter and smarter.&lt;/p&gt;&lt;p&gt;Also, it isn‚Äôt sound in many cases that users expect to work. Once the variable that you‚Äôre type testing can escape the current function, the compiler generally can‚Äôt prove that it won‚Äôt be mutated between when you test its type and when you use it as the more precise type later.&lt;/p&gt;&lt;p&gt;Overall, my feeling is that it works out pretty well for Dart, but it‚Äôs a large sort of messy feature that feels a little too magical. A goal with my hobby language is that you should be able to have the whole language loaded into your head and rarely be surprised by what it does. Flow analysis in Dart still fairly often surprises me and I literally work on the language full-time.&lt;/p&gt;&lt;p&gt;There‚Äôs also the question of what you promote the tested variable to. In my language as it currently stands, there is no subtyping. &lt;code&gt;MeleeWeapon&lt;/code&gt; isn‚Äôt a
subtype of &lt;code&gt;Weapon&lt;/code&gt;, it‚Äôs a case constructor. The &lt;code&gt;weapon is MeleeWeapon&lt;/code&gt; syntax
looks like a type test, but it‚Äôs really more like an enum case check.&lt;/p&gt;&lt;p&gt;So after that test, what type would &lt;code&gt;weapon&lt;/code&gt; have? It would still have to be
&lt;code&gt;Weapon&lt;/code&gt;. I guess I could make this work by not promoting the type but by
having the type checker track an extra ‚Äúknown case‚Äù property for each static
type and then use that. That might work. But even with that, I worry that it
would quickly become annoying. Let‚Äôs say you refactor the above code to:&lt;/p&gt;&lt;code&gt;def attack(weapon Weapon, monster Monster, distance Int)
  if weapon is RangedWeapon and checkRange(weapon, distance) or
      distance &amp;gt; 1 then
    print("You are out of range.")
    return
  end

  # ...
end

def checkRange(weapon Weapon, distance Int) Bool
  distance &amp;lt; weapon.minRange or distance &amp;gt; weapon.maxRange
end
&lt;/code&gt;&lt;p&gt;That no longer works. Inside &lt;code&gt;checkRange()&lt;/code&gt; the compiles has lost track that
&lt;code&gt;weapon&lt;/code&gt; is always a &lt;code&gt;RangedWeapon&lt;/code&gt;. You could come up with a way to annotate
that, but now we‚Äôre back to subtyping and all the complexity it involves.&lt;/p&gt;&lt;p&gt;So, overall, yes, subtyping and flow analysis is a thing that could work here, but I‚Äôm trying to avoid it because I feel like it‚Äôs a bigger lump of complexity than I want to take on.&lt;/p&gt;&lt;p&gt;I‚Äôd be more inclined to do sum types and destructuring, even though it feels a little weird in an imperative language, then do this kind of complex control flow analysis.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45320230</guid><pubDate>Sun, 21 Sep 2025 05:13:35 +0000</pubDate></item><item><title>Vibe Coding Cleanup as a Service</title><link>https://donado.co/en/articles/2025-09-16-vibe-coding-cleanup-as-a-service/</link><description>&lt;doc fingerprint="3551835589a784cd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Vibe Coding Cleanup as a Service&lt;/head&gt;
    &lt;p&gt;A new service category is quietly emerging in tech: Vibe Coding cleanup. What started as LinkedIn jokes about ‚Äúfixing AI messes‚Äù has become a real business opportunity. The harsh reality nobody wants to admit: most AI-generated code is production-unready, and companies are desperately hiring specialists to fix it before their technical debt spirals out of control.&lt;/p&gt;
    &lt;head rend="h2"&gt;The vibe coding explosion&lt;/head&gt;
    &lt;p&gt;When Andrej Karpathy coined ‚Äúvibe coding‚Äù in early 2025, he perfectly captured how developers now work: chatting with AI to generate entire functions instead of writing them. The approach promises 10x productivity gains through natural language programming. GitHub reports that 92% of developers now use AI coding tools, with Copilot alone generating billions of lines of code monthly.&lt;/p&gt;
    &lt;p&gt;But there‚Äôs a problem nobody talks about at conferences. GitClear‚Äôs analysis of 150 million lines of code reveals AI assistance correlates with 41% more code churn - code that gets reverted or rewritten within two weeks. Stanford researchers found that developers using AI assistants produce significantly less secure code while believing it‚Äôs more secure. The tools amplify bad practices: no input validation, outdated dependencies, and architectural decisions that make senior engineers weep.&lt;/p&gt;
    &lt;head rend="h2"&gt;The cleanup economy is real&lt;/head&gt;
    &lt;p&gt;404 Media‚Äôs investigation reveals developers are building entire careers around fixing AI-generated code. Hamid Siddiqi manages 15-20 cleanup projects simultaneously, charging premium rates to untangle what he calls ‚ÄúAI spaghetti‚Äù - inconsistent interfaces, redundant functions, and business logic that makes no sense. Software consultancy Ulam Labs now advertises ‚ÄúVibe Coding cleanup‚Äù as a core service.&lt;/p&gt;
    &lt;p&gt;The demand is so high that VibeCodeFixers.com launched as a dedicated marketplace. Within weeks, 300 specialists signed up and dozens of projects were matched. Founder Swatantra Sohni describes a typical client: ‚ÄúThey burned through $5,000 in OpenAI credits, have a half-working prototype they‚Äôre emotionally attached to, and need it production-ready yesterday.‚Äù The Pragmatic Engineer reports similar patterns across Silicon Valley startups.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why AI code fails at scale&lt;/head&gt;
    &lt;p&gt;The fundamental issue isn‚Äôt that AI writes bad code - it‚Äôs that it writes locally optimized code without understanding system context. Stack Overflow‚Äôs analysis shows AI excels at small, isolated tasks but fails at architectural decisions. Every prompt creates technical debt: inconsistent patterns, duplicated logic, and security holes that automated scanners miss.&lt;/p&gt;
    &lt;p&gt;Computer Weekly reports that 40% of AI-generated code contains security vulnerabilities. The tools leak secrets into code, suggest deprecated libraries, and create race conditions that only appear under load. Worse, developers often don‚Äôt understand the generated code well enough to spot these issues. Martin Fowler warns this creates ‚Äúcompetency debt‚Äù - teams lose the ability to maintain their own systems.&lt;/p&gt;
    &lt;head rend="h2"&gt;The market opportunity&lt;/head&gt;
    &lt;p&gt;The Vibe Coding cleanup market is growing rapidly, though exact numbers are hard to pin down. What we know: Gartner predicts 75% of enterprise software engineers will use AI code assistants by 2028. If even a fraction of those projects need cleanup - and current data suggests most will - we‚Äôre looking at a massive emerging market.&lt;/p&gt;
    &lt;p&gt;The economics are compelling. Startups save weeks getting to MVP with Vibe Coding, then spend comparable time and budget on cleanup. But that‚Äôs still faster than traditional development. The specialists who can efficiently refactor AI messes command $200-400/hour rates. Some are building productized services: fixed-price cleanup packages, AI code audits, and ‚Äúvibe-to-production‚Äù pipelines.&lt;/p&gt;
    &lt;p&gt;ThoughtWorks reports 60% of their AI-assisted projects require significant refactoring before production. Multiple consultancies are now hiring specifically for ‚ÄúAI code remediation‚Äù roles. The market is real, growing, and largely untapped.&lt;/p&gt;
    &lt;head rend="h2"&gt;What this means for engineering&lt;/head&gt;
    &lt;p&gt;We‚Äôre witnessing a fundamental shift in how software gets built. AI handles the initial implementation, humans handle architecture, testing, and cleanup. It‚Äôs not the future we expected, but it‚Äôs the one we‚Äôre getting.&lt;/p&gt;
    &lt;p&gt;Gergely Orosz argues AI tools are ‚Äúexpensive junior engineers‚Äù - they write lots of code quickly but need constant supervision. The difference is that AI juniors never become seniors. They‚Äôll always need cleanup specialists.&lt;/p&gt;
    &lt;p&gt;This creates interesting career paths. Junior developers who master Vibe Coding cleanup can command senior salaries within two years. Senior engineers who understand both AI capabilities and limitations become invaluable. Companies that build robust cleanup processes gain competitive advantage.&lt;/p&gt;
    &lt;head rend="h2"&gt;Our stance&lt;/head&gt;
    &lt;p&gt;At Donado Labs, we‚Äôve cleaned up enough vibe-coded disasters to recognize the pattern. AI acceleration works, but only with professional cleanup built into the process. We use AI for prototyping and routine tasks, but architecture and critical logic remain human-written. Our ‚ÄúVibe to Production‚Äù service takes AI prototypes and makes them enterprise-ready: proper testing, security hardening, and documentation that won‚Äôt make your successor cry.&lt;/p&gt;
    &lt;p&gt;The companies succeeding with AI coding aren‚Äôt the ones using it most - they‚Äôre the ones using it smartly. They prototype with AI, then invest in cleanup before technical debt compounds. They treat Vibe Coding like any other tool: powerful but dangerous without expertise.&lt;/p&gt;
    &lt;p&gt;Next time someone claims AI will replace programmers, ask them who‚Äôs going to clean up the code. That‚Äôs where the real opportunity lies.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45320431</guid><pubDate>Sun, 21 Sep 2025 06:01:49 +0000</pubDate></item><item><title>Universities should be more than toll gates</title><link>https://www.waliddib.com/posts/universities-should-be-more-than-toll-gates/</link><description>&lt;doc fingerprint="33709953a8a5063c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Universities should be more than toll gates&lt;/head&gt;
    &lt;p&gt;If you studied university in many parts of the Middle East, try asking yourself or any of your friends what their favorite part of university was, and a lot of them will say the dorm life, late-night conversations, or the campus freedom. Very few will tell you their favorite part was what they learned in class.&lt;/p&gt;
    &lt;p&gt;A few days ago, I was lazily browsing Hacker News when I came across a provocative blog post titled ‚ÄúMath is Erotic.‚Äù Without going into too much detail about the contents of the post itself ‚Äî which, for reference, has very little erotica ‚Äî the part that really caught my attention was below:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The function universities have long played is less one of educating than of credentialing.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I studied Environmental Engineering in Jordan, and more than 10 years after graduating, the above resonates on a profound level with me. I assume a lot of people from the Arab world and South Asia would relate to this, too.&lt;/p&gt;
    &lt;p&gt;At the risk of sounding like yet another entrepreneur talking smack about university education, hear me out: the German Jordanian University, where I studied, was a conveyor belt clattering along slowly to secure jobs abroad for young Jordanians. As the name implies, engineering students were meant to spend 4 years in Jordan, and another mandatory year in Germany. It started as a joint project in 2005 between the governments of Jordan and Germany.&lt;/p&gt;
    &lt;p&gt;This university, mind you, is allegedly one of the best in Jordan. I had some of the highest grades in my class, but this came at the expense of learning very little about my actual courses. Getting good grades exclusively depended on your rote memorization skills the night before an exam. Not only do I remember nothing from what I studied1, I detested every minute of every subject I took there. Passing subjects was significantly more important than understanding them.&lt;/p&gt;
    &lt;p&gt;A typical Jordanian engineering student needs to serve an engineering sentence of 5 years, compared to 4 years of education in the US or 3 in England. Jordanian universities follow an archaic credit-hour system where at least a semester‚Äôs worth of useless subjects are crammed into your schedule. For example, everyone I know had to study ‚ÄúMilitary Science,‚Äù a semester-long 3-credit course with very little use outside of esoteric trivia about army hierarchy.&lt;/p&gt;
    &lt;p&gt;If you‚Äôre assuming that I‚Äôm implying that the system trades your time and money for empty credit hours, then you can collect your prize at the door. 21% of Jordanians are unemployed. That‚Äôs far above the global average of 4.9%. I‚Äôm sure the Ministry of Higher Education knows exactly what they‚Äôre doing, but from where I‚Äôm standing it looks like the plan is to keep people out of the workforce for as long as possible.&lt;/p&gt;
    &lt;p&gt;This is not to say that this specific university was not worth students‚Äô money. Many of my peers secured jobs in Germany right after graduating. These people did their time and earned their credentials. The question remains, though: is this because of what they learned at university or because of being part of the German-Jordanian labor conveyor belt?&lt;/p&gt;
    &lt;p&gt;This isn‚Äôt a complaint, it‚Äôs an obituary for the education I could‚Äôve had. My first jolt of confusion about university lectures was in 2012, during my foreign exchange year in Germany. I was in a classroom full of Environmental Engineering students who were there because they wanted to be there. I, on the other hand, was there because my dad thought engineering would be good for me. When I saw the passion with which the professor discussed fluid mechanics, and the students peppered him with genuine questions, I realized something simple but profound: people can actually be passionate about what they study, if it‚Äôs taught well and if they truly care about the subject.&lt;/p&gt;
    &lt;p&gt;Years later, I rediscovered what I really loved: learning for its own sake. In 2024, I came across the CS50 YouTube channel, which is Harvard University‚Äôs introduction to the intellectual enterprises of computer science and the art of programming. Even if I had no intention to learn anything about computer science, or C programming, I couldn‚Äôt stop watching it. The thought of being entertained by learning was so alien to me and yet there I was, binge-watching lectures on algorithms, memory, and bytecode.&lt;/p&gt;
    &lt;p&gt;Last month I spent 30 hours diving into Arduinos and following tutorials with a breadboard on my desk. Before that, I spent 8 months in Godot making small games. When I found out about Cursor, I coded a Pocket clone after the original app shut down. I even built a TikTok scraping API just because I could. None of this was for money. Not one single project.&lt;/p&gt;
    &lt;p&gt;But all of this learning came with its own kind of weight. The more I dabbled, the more I realized how much there was to learn. Each new subject made me feel both excited and lost. I would forget one topic as soon as I picked up the next, and the disparity between everything I explored left me frustrated. It was a strange sadness. The deeper I went, the further behind I felt.&lt;/p&gt;
    &lt;p&gt;Absolute joy turned into anger, and anger into resentment, as I wondered how different my life might have been if I‚Äôd been taught subjects I actually cared about by professors who cared too. Then I caught myself, realizing I was being melodramatic about a decade-old grievance.&lt;/p&gt;
    &lt;p&gt;I recently started to see learning a bit differently. I don‚Äôt need to feel guilty about learning with no end goal or finish line. My learning process is suboptimal at best, and I don‚Äôt have an Obsidian or Notion ‚ÄúSecond Brain‚Äù.&lt;/p&gt;
    &lt;p&gt;Forgetting is fine. Losing track is fine. Nobody beats themselves up because they can‚Äôt recite scripts and scenes of their favorite movie or video game, so why should I remember exactly how layers work in Godot?&lt;/p&gt;
    &lt;p&gt;What matters is that I keep finding new things to chase, new rabbit holes to fall into. The act of learning itself is such a rush, even if I find another shinier subject halfway through. I now have a new plan: acquire the financial freedom my little family needs to design my own syllabus and spend the rest of my life learning on my own terms.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;To be fair, I only worked as an engineer for a bit more than a year between 2014 and 2016. ‚Ü©Ô∏é&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45320759</guid><pubDate>Sun, 21 Sep 2025 07:19:59 +0000</pubDate></item></channel></rss>