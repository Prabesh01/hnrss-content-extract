<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 03 Jan 2026 06:16:45 +0000</lastBuildDate><item><title>Ask HN: Who is hiring? (January 2026)</title><link>https://news.ycombinator.com/item?id=46466074</link><description>&lt;doc fingerprint="3741985a3402e664"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Please state the location and include REMOTE for remote work, REMOTE (US) or similar if the country is restricted, and ONSITE when remote work is &lt;/p&gt;not&lt;p&gt; an option.&lt;/p&gt;&lt;p&gt;Please only post if you personally are part of the hiring company—no recruiting firms or job boards. One post per company. If it isn't a household name, explain what your company does.&lt;/p&gt;&lt;p&gt;Please only post if you are actively filling a position and are committed to responding to applicants.&lt;/p&gt;&lt;p&gt;Commenters: please don't reply to job posts to complain about something. It's off topic here.&lt;/p&gt;&lt;p&gt;Readers: please only email if you are personally interested in the job.&lt;/p&gt;&lt;p&gt;Searchers: try https://dheerajck.github.io/hnwhoishiring/, http://nchelluri.github.io/hnjobs/, https://hnresumetojobs.com, https://hnhired.fly.dev, https://kennytilton.github.io/whoishiring/, https://hnjobs.emilburzo.com, or this (unofficial) Chrome extension: https://chromewebstore.google.com/detail/hn-hiring-pro/mpfal....&lt;/p&gt;&lt;p&gt;Don't miss this other fine thread: Who wants to be hired? https://news.ycombinator.com/item?id=46466073&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46466074</guid><pubDate>Fri, 02 Jan 2026 16:00:42 +0000</pubDate></item><item><title>Punkt. Unveils MC03 Smartphone</title><link>https://www.punkt.ch/blogs/news/punkt-unveils-mc03</link><description>&lt;doc fingerprint="bc993addacb595dc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Punkt. unveils MC03, latest version of its unique smartphone offering giving users full control over personal data and usage.&lt;/head&gt;
    &lt;p&gt;Made in Europe, the MC03 has an updated and more sustainable design and evolved features, with security and privacy at its heart.&lt;/p&gt;
    &lt;p&gt;2 January 2026, Lugano, Switzerland / CES, Las Vegas. Punkt. , the Swiss-based pioneer of beautifully designed, minimalist smartphones that give users privacy without friction, will be present at CES with its latest model, the MC03. This unique device, powered by AphyOS and housed within a German-built precision handset, follows through on Punkt.’s well known commitment to intentional tech use and data ownership.&lt;/p&gt;
    &lt;p&gt;Like its forerunner, the MC02, the new model is a subscription-based smartphone that offers users the tools and apps that are most important to them in an environment where they control access to their data and usage.&lt;/p&gt;
    &lt;p&gt;Using the Punkt. MC03, users can put privacy first with two defined repositories for depositing data. The first is named Vault, a protected enclave containing only trusted, Punkt.-approved apps and offering maximum privacy by default with a calm, design-focused user interface. The second, termed Wild Web, provides the freedom to install any app, but with strict, visible safeguards that allow easy privacy controls and can prevent data triangulation and unauthorized data flows.&lt;/p&gt;
    &lt;p&gt;“Privacy is being sought by people more than ever before, particularly as we enter the age of AI,” said Petter Neby, Founder and CEO at Punkt. “They are stressed and overwhelmed by the determination of Big Tech to track and monetise their every online movement. Punkt. offers them a solution – a modern, premium device without the need to compromise on their privacy.”&lt;/p&gt;
    &lt;p&gt;The MC03 features a new look and feel to its operating system allowing users to stay laser-focused on getting the best experience. AphyOS cuts out tracking and profiling technology, bloatware, hidden apps and unwieldy background services. It eliminates spying and runs hardened code to block attacks, assisted by a bank-grade Secure Element.&lt;/p&gt;
    &lt;p&gt;With the MC03, Punkt. is building a secure smartphone ecosystem where privacy is not an add-on, but the default. Supported by trusted partners such as Threema and, new for MC03, Proton, these services feature in the device’s Vault space.&lt;/p&gt;
    &lt;p&gt;Trusted services including Proton Mail, Proton Calendar, Proton Drive, Proton VPN and Proton Pass are available in an environment designed to minimize data exposure and tracking.&lt;/p&gt;
    &lt;p&gt;Punkt. and Proton are ideal partners, both leading within the Swiss Tech movement (with Swiss Tech you pay to retain your data, with Big Tech you pay with your data), operating independently and built around the principle that users, not platforms, control their own data.&lt;/p&gt;
    &lt;p&gt;Andy Yen, Founder and CEO of Proton said, “People deserve choice. Choice over the phone they use, the software they rely on and who they share their data with. By working with likeminded companies like Punkt., we can give users more ways to regain control of their privacy.”&lt;/p&gt;
    &lt;head rend="h3"&gt;Among other features of the MC03:&lt;/head&gt;
    &lt;p&gt;The App Hub&lt;/p&gt;
    &lt;p&gt;Two app stores are available:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A curated privacy-friendly store vetted by AphyOS and Punkt.&lt;/item&gt;
      &lt;item&gt;Access to all widely available apps, activated only when chosen by the user.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Premium Hardware&lt;/p&gt;
    &lt;p&gt;Manufactured at the Gigaset facility in Germany, the device delivers cutting-edge engineering for quality, security, repairability and sustainability, including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;120Hz OLED HDR display&lt;/item&gt;
      &lt;item&gt;Removable 5200mAh battery&lt;/item&gt;
      &lt;item&gt;IP68 water and dust resistance&lt;/item&gt;
      &lt;item&gt;64MP main camera&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Digital Nomad&lt;/p&gt;
    &lt;p&gt;The MC03 retains its built-in VPN, Digital Nomad, protecting connectivity and privacy wherever users are.&lt;/p&gt;
    &lt;p&gt;Ledger&lt;/p&gt;
    &lt;p&gt;Users control app-specific privacy, from full access to full restriction. Ledger also includes a Carbon Reduction feature, giving insights into the energy impact of installed apps and control over background activity.&lt;/p&gt;
    &lt;p&gt;“The MC03 builds on the success of the MC02 in privacy, control and security,” continued Petter Neby. “It delivers modern features with simplicity and minimal distraction.”&lt;/p&gt;
    &lt;p&gt;The Punkt. MC03 is priced at CHF / $ / €699.&lt;/p&gt;
    &lt;p&gt;If you don’t pay for a product, you are the product. With MC03, you pay to retain your data rather than paying with it.&lt;/p&gt;
    &lt;p&gt;A 12-month subscription to AphyOS from Apostrophy is included. After that, continuation requires a paid subscription:&lt;/p&gt;
    &lt;p&gt;Monthly at CHF / $ / €9.99&lt;/p&gt;
    &lt;p&gt;Subscription bundles are available, including a 3-year subscription at 45% discount and a 5-year subscription at 60% discount.&lt;/p&gt;
    &lt;p&gt;The MC03 is available to pre-order now, with deliveries in Europe at the end of January and North America from Spring 2026.&lt;/p&gt;
    &lt;p&gt;Images available for download here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46466364</guid><pubDate>Fri, 02 Jan 2026 16:23:34 +0000</pubDate></item><item><title>The rsync algorithm (1996) [pdf]</title><link>https://www.andrew.cmu.edu/course/15-749/READINGS/required/cas/tridgell96.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46466734</guid><pubDate>Fri, 02 Jan 2026 16:56:19 +0000</pubDate></item><item><title>Clicks Communicator</title><link>https://www.clicksphone.com/en/communicator</link><description>&lt;doc fingerprint="7244f1c192d733e8"&gt;
  &lt;main&gt;
    &lt;p&gt;Yes! Absolutely. Communicator is a fully standalone smartphone that runs Android 16, with all the apps, 5G connectivity and Wi-fi. We think many people will use this as their primary phone while others will use it as a complement to a flagship iPhone, Galaxy, Pixel, etc.&lt;/p&gt;
    &lt;p&gt;Weâre on track to ship Clicks Communicator orders later this year. Shipping timelines will be confirmed once manufacturing enters its final stage. Early customers will receive priority fulfillment. Follow along at @ClicksKeys on Instagram and www.Clicks.tech&lt;/p&gt;
    &lt;p&gt;Communicator will support 5G, 4GLTE, 3G/2G global bands and be sold unlocked. &lt;lb/&gt;5G NR: n41, n77, n78, n1, n2, n3, n5, n7, n8, n12, n13, n14, n20, n25, n26, n28, n38, n40, n41, n48, n66, n71, n77, n78&lt;lb/&gt;5G NR (4Ã4 MIMO): n1, n2, n3, n7, n25, n38, n40, n41, n48, n66, n77, n78LTE (4G):&lt;lb/&gt;FDD: B1, B2, B3, B4, B5, B7, B8, B12, B13, B14, B17, B18, B19, B20, B25, B26, B28, B66, B71&lt;lb/&gt;TDD: B34, B38, B39, B40, B41, B42, B483G / 2G:&lt;lb/&gt;WCDMA: B1, B2, B4, B5, B6, B8, B9, B19&lt;lb/&gt;GSM: B2, B3, B5, B8&lt;/p&gt;
    &lt;p&gt;Communicator will be sold unlocked, supporting a number of the most popular 5G, 4GLTE, 3G/2G global bands. We will evaluate carrier certification as we approach availability.&lt;/p&gt;
    &lt;p&gt;As a real keyboard with the QWERTY layout, Communicator supports languages that use the Latin alphabet: English, Spanish, Portuguese, Italian, Danish, Norwegian, Swedish, Finnish, Dutch, Japanese, Estonian, Faroese, Latvian, Lithuanian, Maltese, Polish, Romanian, Russian, Slovak, Turkish.&lt;/p&gt;
    &lt;p&gt;At this stage of development itâs too early to project battery life. Battery life has been a core design priority from day one. Thatâs why weâre combining a 4,000 mAh silicon-carbon battery with a 4.03â AMOLED display and a modern 4-nanometer SoC that will work together to deliver an efficient power management experience.&lt;/p&gt;
    &lt;p&gt;Communicator will run Android 16. Weâre comfortable committing to 2 years of Android updates and 5 years of security updates.&lt;/p&gt;
    &lt;p&gt;Communicator uses a modern 4-nanometer, 5G IoT SoC platform from MediaTek&lt;/p&gt;
    &lt;p&gt;Communicator packs a 4.03â AMOLED display with a 1080 x 1200 resolution&lt;/p&gt;
    &lt;p&gt;Main (rear facing) camera: 50MP, autofocus with optical image stabilization&lt;lb/&gt;Front facing camera: 24MP fixed focus&lt;/p&gt;
    &lt;p&gt;The reservation program allows you to reserve a Clicks Communicator prior to general availability. By placing a reservation, you secure priority access to purchase a Clicks Communicator when ordering opens. There are two options available: a Reservation Deposit of $199 USD (applied toward the final purchase price at checkout) or a Full Reservation of $399 USD (Early Bird Price), which represents payment of the full purchase price in advance. When ordering opens ahead of shipment, reservation holders will be invited to configure and complete their Communicator order. Please see the full Terms of Reservation for details on our reservation program.&lt;/p&gt;
    &lt;p&gt;Yes. You may cancel at any time before your reservation converts into an order for a full refund.&lt;/p&gt;
    &lt;p&gt;Reservation holders will be invited to configure their Communicator closer to our first production run. Stay tuned for updates!&lt;/p&gt;
    &lt;p&gt;Voice over internet calling (like WhatsApp, Telegram, Facebook) will carry over from your primary phone. If you want to make and receive traditional phone calls over cellular networks, a second SIM/phone number will be required.&lt;/p&gt;
    &lt;p&gt;Yes! Communicator will support both a physical (nano) SIM card and eSIM. The nano-SIM slot is found beneath the back cover.&lt;/p&gt;
    &lt;p&gt;The limited warranty runs for a period of one year from the date of delivery.&lt;/p&gt;
    &lt;p&gt;Closer to availability we will contact customers who have purchased reservations to configure your Communicator (colors, covers, etc.). You will be asked to confirm your shipping address at that time.&lt;/p&gt;
    &lt;p&gt;Weâre focused on shipping Communicator with QWERTY at this time. QWERTY will support a broad range of latin character based language. We will monitor interest in other keyboard layouts.&lt;/p&gt;
    &lt;p&gt;We currently ship to the United States, Canada, Mexico, Costa Rica, Guatemala, the United Arab Emirates, Saudi Arabia, Qatar, Bahrain, Kuwait, Jordan, Oman, Turkey, Egypt, Australia, New Zealand, Paraguay, and across Europe, including the United Kingdom, Germany, France, Italy, the Netherlands, Spain, Switzerland, Poland, Belgium, the Czech Republic, Austria, Sweden, Greece, Ireland, Croatia, Portugal, Denmark, Slovenia, Luxembourg, Slovakia, Finland, Lithuania, Montenegro, Guernsey, Gibraltar, Bosnia and Herzegovina, Iceland, the Isle of Man, Kosovo, and Hungary.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46467057</guid><pubDate>Fri, 02 Jan 2026 17:22:04 +0000</pubDate></item><item><title>Accounting for Computer Scientists (2011)</title><link>https://martin.kleppmann.com/2011/03/07/accounting-for-computer-scientists.html</link><description>&lt;doc fingerprint="2d25d1458425395d"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;head rend="h1"&gt;Accounting for Computer Scientists&lt;/head&gt;
      &lt;p&gt;Published by Martin Kleppmann on 07 Mar 2011.&lt;/p&gt;
      &lt;p&gt;Every educated person really ought to have a basic understanding of accounting. Just like maths, science, programming, music, literature, history, etc., itâs one of those things which helps you make sense of the world. Although dealing with money is not much fun, itâs an unavoidable part of life, so you might as well take a few minutes to understand it.&lt;/p&gt;
      &lt;p&gt;Sadly, in my opinion, most accountants do a terrible job of explaining their work in an accessible way; itâs a field full of jargon, acronyms and weird historical legacies. Even âBookkeeping for Dummiesâ makes my head spin. Surely this stuff canât be that difficult?&lt;/p&gt;
      &lt;p&gt;(We computing people are probably guilty of the same offence of bad explanations and jargon. The problem is, once you have become intimately familiar with a field, itâs very hard to imagine how you thought about things before you understood it.)&lt;/p&gt;
      &lt;p&gt;Eventually I figured it out: basic accounting is just graph theory. The traditional ways of representing financial information hide that structure astonishingly well, but once I had figured out that it was just a graph, it suddenly all made sense.&lt;/p&gt;
      &lt;p&gt;Iâm a computer scientist, and I think of stuff in graphs all the time. If only someone had explained it like that in the first place! It would have saved me so much confusion. So I want to try to fix that. If you like graphs, then by the time you reach the end of this article, you should know everything you need in order to understand the financial statements for a small company/startup (and even calculate them yourself, in a spreadsheet or programming language of your choice).&lt;/p&gt;
      &lt;p&gt;Itâs really not that hard. Letâs go!&lt;/p&gt;
      &lt;p&gt;Accounts = Nodes, Transactions = Edges&lt;/p&gt;
      &lt;p&gt;Say you go to the bagel shop and buy a Super Club bagel for $5 on the company credit card. You also visit some random Silicon Valley startup and buy one of their surplus Aeron chairs, second hand, for $500 (by writing a cheque from the company account). Those are two transactions. Each transaction is an edge in our graph, and the edge is labelled with the amount.&lt;/p&gt;
      &lt;p&gt;An edge always goes from one node to another. What are those nodes? Well, you can define them as you like (although there are some conventions). For now, letâs say:&lt;/p&gt;
      &lt;p&gt;Letâs add some more details. You pay the $5 credit card bill from the company account. And where did the money in the company account come from in the first place? Ah, I see, you put in $5,000 of your savings to start the company. Ok, now the graph looks like this:&lt;/p&gt;
      &lt;p&gt;Hopefully pretty self-explanatory so far. Money flows in the direction of the arrows.&lt;/p&gt;
      &lt;p&gt;Hungry once again, you go to the taqueria and buy a Super Burrito for $8 on the credit card. Now we could create another node for the taqueria, but this is starting to get messy â we donât really care how much money we spent on bagels vs. how much on burritos. Letâs just lump them together as âfoodâ. Also, âRandom startupâ is a bit unhelpful â Iâve already forgotten what those $500 were for. Letâs call it âfurnitureâ instead.&lt;/p&gt;
      &lt;p&gt;See, thatâs perfectly fine. We can have nodes which represent actual bank accounts or cards, others which represent people or companies, and others again which represent abstract categories like âfoodâ or âfurnitureâ. Just throw it all into the same graph.&lt;/p&gt;
      &lt;p&gt;Note also that you can have several edges between the same pair of nodes. You can keep track of the individual edges, or you can simply add them up. (Using the credit card, you spent a total of $13 on food.)&lt;/p&gt;
      &lt;p&gt;Accounts have balances&lt;/p&gt;
      &lt;p&gt;Every node in this graph is an account in accountant-speak (whether or not it is held by a bank), and every account has a balance. The balance is a single number for each account, and it is determined completely by the transactions in and out of the account:&lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;At the beginning of time, the value at each node is zero.&lt;/item&gt;
        &lt;item&gt;At each node, for each incoming edge, add the edgeâs label to the nodeâs value; for each outgoing edge, subtract the edgeâs label from the value.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;After youâve processed all the edges, the value at each node is that accountâs balance. Our graph now looks like this:&lt;/p&gt;
      &lt;p&gt;Note that the account balances have two nice properties:&lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;Because every transaction appears twice â once positive and once negative â the sum of all account balances is always zero.&lt;/item&gt;
        &lt;item&gt;If you partition the set of nodes into any two disjoint sets, and add up all of the balances in each set, then the sum for the one set is always the negative sum of the other set (because, after all, they have to add up to zero).&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;These properties are useful for sanity-checking your numbers; if they are violated, âur doin it wrongâ. (This is what accountants mean when they talk about âbalancing the booksâ.)&lt;/p&gt;
      &lt;p&gt;Doing business&lt;/p&gt;
      &lt;p&gt;Strengthened by a bagel and a burrito, you go out and talk to some potential customers. And hey, they love your product! It has a price tag of $5,000, and you sell it to two big enterprise customers. One pays you right away (good stuff!); the other gives you $2,500 up front, but insists that before they pay the rest, you need to implement that additional feature you foolishly promised.&lt;/p&gt;
      &lt;p&gt;So you received $5,000 + $2,500 in cash from your customers, wired straight the company bank account. Letâs add that to the graph:&lt;/p&gt;
      &lt;p&gt;But thatâs not quite right. The price was $5,000 for each customer, and now it looks like you charged two different prices. How do we represent our arrangement with customer 2?&lt;/p&gt;
      &lt;p&gt;The solution is to deconstruct the deal into two separate transactions: the sale (in which the buyer agrees to buy, but no actual money changes hands) and the payment (when the cash actually hits your bank account). We can draw it like this:&lt;/p&gt;
      &lt;p&gt;See what Iâve done here? Iâve just made up a new node, generically called it âsalesâ, and added the actual $5,000 sales as a transaction from this âsalesâ account to the customer accounts. Adding this extra node hasnât changed your bank balance.&lt;/p&gt;
      &lt;p&gt;This makes sense when you think about the intuitive meaning of the balances. The balance of each customerâs account is the amount they owe you: customer 1 has fully paid up (their incoming and outgoing transactions add up to the same), so their balance is zero; customer 2 has contractually agreed to give you $5,000, but has so far only given you half of that, so their balance is $2,500.&lt;/p&gt;
      &lt;p&gt;And the balance on the sales account is the value of stuff youâve sold. Or rather, the negative value. That looks a bit weirdâ¦ but Iâll come back to that later. (BTW, if you wanted to separately track sales for different customers or different products, no problem â just add whatever nodes make sense for you. Just make sure that every transaction appears only once as an edge, otherwise youâre making stuff up!)&lt;/p&gt;
      &lt;p&gt;Finishing off the example&lt;/p&gt;
      &lt;p&gt;To round it off, let me add some more events to the story (= some more edges to the graph).&lt;/p&gt;
      &lt;p&gt;Not only have you made some sales, but now you also receive a $20,000 investment from Y Combinator â congratulations! You and your co-founder can now afford to pay yourselves a salary. You take $8,000 out of the company account.&lt;/p&gt;
      &lt;p&gt;Then you get set up with a company accountant, and they talk lots of jargon at you. For some strange reason they are obsessed with correctly accounting for your office chair; they want it to depreciate over four years, i.e. its value is gradually reduced to zero over the course of that time. Fair enough, you say (even though you couldnât care less what your chair will be worth in four yearsâ time â surely by that time youâll be the next Google or Facebook, and youâll have other things to worry about than chairs).&lt;/p&gt;
      &lt;p&gt;The resulting graph now looks like this:&lt;/p&gt;
      &lt;p&gt;Note how I have represented the transactions:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;
          &lt;p&gt;I have lumped together your founder investment with that of Y Combinator, under the heading of âcapitalâ. Put simply, this is money you got into the company by selling your companyâs shares, rather than by selling a product or service to a customer. As usual, you can split founders and YC into separate accounts if you feel like it.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Iâve represented payroll (salaries) as just money straight out of the bank account. In reality itâs a bit more complicated due to taxes, healthcare, benefits, etc. but the principles stay the same. Itâs just more nodes and edges in the graph.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;I made depreciation for one year (one quarter of $500 = $125) go away from the âfurnitureâ account. Intuitively, this means that the balance of the âfurnitureâ account is the value that your furniture still has now. Each year, you add another $125 edge from âfurnitureâ to âdepreciationâ, until after four years, the balance of âfurnitureâ drops to zero (assuming you havenât bought any more chairs in the meantime, in your quest for world domination).&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;The profit and loss statement&lt;/p&gt;
      &lt;p&gt;At this point, if youâre getting weary, I donât blame you. But the good news: weâve finished building our graph! Now I will show you how this graph representation maps to two standard financial statements most commonly used in managing a company: the profit and loss statement (âP&amp;amp;Lâ), and the balance sheet. This is useful, because as a startup founder youâll sooner or later have to discuss these documents with your investors/advisors, and so you might as well learn what the hell they mean.&lt;/p&gt;
      &lt;p&gt;In order to produce these statements, I need to get out the crayons. Here is the same graph as before, with the nodes coloured in:&lt;/p&gt;
      &lt;p&gt;Explaining the colours (putting the accounting terminology in brackets, since youâre likely to encounter these words):&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Green for stuff that you have (âassetsâ), e.g. money in the bank, or things which you bought and you could sell again, such as furniture. Also green for people/companies who owe you money (âdebtorsâ, such as Customer 2), and people/companies to whom you owe money (âliabilitiesâ/âcreditorsâ, such as your upcoming credit card bill for that burrito).&lt;/item&gt;
        &lt;item&gt;Blue for sales of your product/service (ârevenueâ) and money you spent that youâre not going to get back (âexpensesâ/âoverheadsâ). The office chair is green, because you could sell it again if you wanted to, but the bagel is blue, because once youâve bought (and eaten) the bagel, thatâs it â no going back.&lt;/item&gt;
        &lt;item&gt;Pink for money from investors (or yourself) that you got by selling shares (âcapitalâ). (If you get a bank loan, thatâs green, not pink, because you owe the bank to pay it back.)&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Every one of your nodes should fall into exactly one of these categories. If not, something has gone wrong, or you have discovered some bit of the accounting world that I donât yet know about.&lt;/p&gt;
      &lt;p&gt;With these colours set, the profit and loss statement is simply a list of all the blue nodes, and the profit or loss of the company is the sum of all of the blue nodesâ balances. The way weâve calculated things, a negative value is a profit, and a positive value is a loss. Thatâs confusing, so you typically flip the sign when reporting the number (so that a profit is positive).&lt;/p&gt;
      &lt;p&gt;Written in the standard way, our P&amp;amp;L looks like this:&lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell rowspan="2" style="font-variant: small-caps;" role="head"&gt;Revenue&lt;/cell&gt;
          &lt;cell style="border-bottom: 1px solid #888;"&gt;Sales&lt;/cell&gt;
          &lt;cell style="border-bottom: 1px solid #888; text-align: right;"&gt;$10,000&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell style="border-bottom: 1px solid #888;" role="head"&gt;Total revenue&lt;/cell&gt;
          &lt;cell style="border-bottom: 1px solid #888; text-align: right;" role="head"&gt;$10,000&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row style="margin-top: 1em"&gt;
          &lt;cell rowspan="4" style="font-variant: small-caps;" role="head"&gt;Expenses&lt;/cell&gt;
          &lt;cell&gt;Payroll&lt;/cell&gt;
          &lt;cell style="text-align: right;"&gt;$8,000&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Depreciation&lt;/cell&gt;
          &lt;cell style="text-align: right;"&gt;$125&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell style="border-bottom: 1px solid #888;"&gt;Food&lt;/cell&gt;
          &lt;cell style="border-bottom: 1px solid #888; text-align: right;"&gt;$13&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell style="border-bottom: 1px solid #888;" role="head"&gt;Total expenses&lt;/cell&gt;
          &lt;cell style="border-bottom: 1px solid #888; text-align: right;" role="head"&gt;$8,138&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row style="margin-top: 1em"&gt;
          &lt;cell style="padding-top: 1em; font-variant: small-caps;" role="head"&gt;Total&lt;/cell&gt;
          &lt;cell style="border-bottom: 1px solid #888; font-weight: bold;" role="head"&gt;Profit/Loss&lt;/cell&gt;
          &lt;cell style="border-bottom: 1px solid #888; font-weight: bold; text-align: right;" role="head"&gt;$1,862&lt;/cell&gt;
          &lt;cell&gt;(= total revenue - total expenses)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;p&gt;The meaning is fairly intuitive. You sold $10,000 worth of stuff, and spent only $8,138 in the process, so you made $1,862 profit.&lt;/p&gt;
      &lt;p&gt;The profit and loss statement is calculated over a period of time (usually a month, a quarter or a year), and itâs often interesting to compare two different periods. To calculate it for a period, filter your transactions to only include those which occurred within that period, and add up the account balances for just those transactions.&lt;/p&gt;
      &lt;p&gt;One thing to watch out for: profit doesnât say anything about your bank account. The bank account is a green node, but weâre only looking at blue nodes here. In this example, you ended up with $23,995 in the bank, even though investors put in $25,000: you made a profit, yet still have less money in the bank than you did before, because Customer 2 hasnât yet fully paid. Thatâs why itâs possible for a company to be profitable but still run out of money!&lt;/p&gt;
      &lt;p&gt;The Balance Sheet&lt;/p&gt;
      &lt;p&gt;The balance sheet is a bit less intuitive than the P&amp;amp;L, but itâs quite a powerful document. It summarises what the company currently has and doesnât have, and why.&lt;/p&gt;
      &lt;p&gt;Remember what I said earlier about partitioning the nodes into two disjoint sets, and their summed balances adding to zero? Thatâs exactly what happens on the balance sheet. We take all of the nodes in the graph; on the one side we consider all of the green nodes, and on the other side all the blue and pink nodes. The sum of all of the blue and pink nodesâ balances is minus the sum of all of the green nodesâ balances.&lt;/p&gt;
      &lt;p&gt;Now, by convention, accountants flip the sign on all of the blue and pink nodesâ balances, which means that the two sums end up being equal. And thatâs why itâs called a balance sheet.&lt;/p&gt;
      &lt;p&gt;In our example, it looks like this:&lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell rowspan="4" style="font-variant: small-caps;" role="head"&gt;Assets&lt;/cell&gt;
          &lt;cell&gt;Bank account&lt;/cell&gt;
          &lt;cell style="text-align: right;"&gt;$23,995&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Debtors&lt;/cell&gt;
          &lt;cell style="text-align: right;"&gt;$2,500&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell style="border-bottom: 1px solid #888;"&gt;Furniture&lt;/cell&gt;
          &lt;cell style="border-bottom: 1px solid #888; text-align: right;"&gt;$375&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell style="border-bottom: 1px solid #888;" role="head"&gt;Total assets&lt;/cell&gt;
          &lt;cell style="border-bottom: 1px solid #888; text-align: right;" role="head"&gt;$26,870&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row style="margin-top: 1em"&gt;
          &lt;cell rowspan="2" style="font-variant: small-caps;" role="head"&gt;Liabilities&lt;/cell&gt;
          &lt;cell style="border-bottom: 1px solid #888;"&gt;Credit card&lt;/cell&gt;
          &lt;cell style="border-bottom: 1px solid #888; text-align: right;"&gt;$8&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell style="border-bottom: 1px solid #888;" role="head"&gt;Total liabilities&lt;/cell&gt;
          &lt;cell style="border-bottom: 1px solid #888; text-align: right;" role="head"&gt;$8&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell colspan="2" style="border-bottom: 1px solid #888; font-weight: bold;" role="head"&gt;Total assets less total liabilities&lt;/cell&gt;
          &lt;cell style="border-bottom: 1px solid #888; font-weight: bold; text-align: right;" role="head"&gt;$26,862&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row style="margin-top: 1em"&gt;
          &lt;cell rowspan="3" style="padding-top: 1em; font-variant: small-caps;" role="head"&gt;Equity&lt;/cell&gt;
          &lt;cell&gt;Profit/Loss&lt;/cell&gt;
          &lt;cell style="text-align: right;"&gt;$1,862&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell style="border-bottom: 1px solid #888;"&gt;Capital&lt;/cell&gt;
          &lt;cell style="border-bottom: 1px solid #888; text-align: right;"&gt;$25,000&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell style="border-bottom: 1px solid #888; font-weight: bold;" role="head"&gt;Total equity&lt;/cell&gt;
          &lt;cell style="border-bottom: 1px solid #888; font-weight: bold; text-align: right;" role="head"&gt;$26,862&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;p&gt;The top block (assets and liabilities) corresponds to the green nodes in the graph, whilst the bottom block contains the pink node (capital) and the sum of all of the blue nodes. We already showed all of the detail for the blue nodes on the Profit and Loss statement above; on the balance sheet we can sum them all up to a single number.&lt;/p&gt;
      &lt;p&gt;Some more sign-flipping has occurred here: Iâve written liabilities, equity and P&amp;amp;L with their signs flipped (which usually, but not always, has the effect of making the numbers positive). That doesnât change anything fundamental about the graph structure, it just puts things into the conventional schema.&lt;/p&gt;
      &lt;p&gt;So how can you interpret the balance sheet? There are various things you can read from it. You can see how much money is in the bank, and how much of that money has already been promised to other people (liabilities). You can see how much of the money in the bank came from investors, vs. how much came from sales. And it shows how much money is due to come in soon, from sales that have closed but havenât yet been fully paid.&lt;/p&gt;
      &lt;p&gt;The total of the balance sheet is a lower bound on the value of your company. Itâs a very pessimistic figure â it assumes that your team, your technology, your brand etc. are all worth precisely nothing; if your company raises money from investors, your valuation will be much higher than the balance sheet figure, since that valuation includes the value of team, technology, brand etc in the form of a wild guess. In established companies you can find âintangible assetsâ on the balance sheet, but since they are very hard to value, I suspect itâs not worth bothering with unless you know what you are doing.&lt;/p&gt;
      &lt;p&gt;Thatâs the end of our whirlwind tour through the world of accounting. If youâre a real accountant reading this, please forgive my simplifications; if you spot any mistakes, please let me know. For everyone else, I hope this has been useful. To find out when I write something new, please follow me on Twitter.&lt;/p&gt;
      &lt;div&gt;
        &lt;p&gt;If you found this post useful, please support me on Patreon so that I can write more like it!&lt;/p&gt;
        &lt;p&gt; To get notified when I write something new, follow me on Bluesky or Mastodon, or enter your email address: &lt;/p&gt;
        &lt;p&gt; I won't give your address to anyone else, won't send you any spam, and you can unsubscribe at any time. &lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46467651</guid><pubDate>Fri, 02 Jan 2026 18:16:07 +0000</pubDate></item><item><title>Fighting Fire with Fire: Scalable Oral Exams</title><link>https://www.behind-the-enemy-lines.com/2025/12/fighting-fire-with-fire-scalable-oral.html</link><description>&lt;doc fingerprint="2c4be0012943dea6"&gt;
  &lt;main&gt;
    &lt;p&gt;It all started with cold calling.&lt;/p&gt;
    &lt;p&gt;In our new "AI/ML Product Management" class (co-taught with Konstantinos Rizakos), the "pre-case" submissions (short assignments meant to prepare students for class discussion) were looking suspiciously good. Not "strong student" good. More like "this reads like a McKinsey memo that went through three rounds of editing," good.&lt;/p&gt;
    &lt;p&gt;So we started cold calling students randomly during class.&lt;/p&gt;
    &lt;p&gt;The result was... illuminating. Many students who had submitted thoughtful, well-structured work could not explain basic choices in their own submission after two follow-up questions. Some could not participate at all. This gap was too consistent to blame on nerves or bad luck. If you cannot defend your own work live, then the written artifact is not measuring what you think it is measuring.&lt;/p&gt;
    &lt;p&gt;Brian Jabarian has been doing interesting work on this problem, having shown that AI is actually better than humans at conducting job interviews. Why? Humans get tired, have biases, and are less consistent at following a script. His results both inspired us and gave us the confidence to try something that would have sounded absurd two years ago: running the final exam with a Voice AI agent.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why oral exams? And why now?&lt;/head&gt;
    &lt;p&gt;The core problem is simple: students have immediate access to LLMs that can handle most exam questions we traditionally use for assessment. The old equilibrium, where take-home work could reliably measure understanding, is dead. Gone. Kaput.&lt;/p&gt;
    &lt;p&gt;We can go pen and paper in the classroom. We did that as well for the midterm.&lt;/p&gt;
    &lt;p&gt;Oral exams are another natural response. They force real-time reasoning, application to novel prompts, and defense of actual decisions. The problem? Oral exams are a logistical nightmare. You cannot run them for a large class without turning the final exam period into a month-long hostage situation.&lt;/p&gt;
    &lt;p&gt;Unless you cheat.&lt;/p&gt;
    &lt;head rend="h2"&gt;Enter the Voice Agent&lt;/head&gt;
    &lt;p&gt;We used ElevenLabs Conversational AI to build the examiner. The platform bundles the messy parts (speech-to-text, text-to-speech, turn-taking, interruption handling, …) into something usable. And here is the thing that surprised me: a basic version for a low-stakes setting (e.g., an assignment) can be up and running in literally minutes. Minutes. Just write a prompt describing what the agent should ask the student, and you are done.&lt;/p&gt;
    &lt;p&gt;Two features mattered a lot for our setup:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Dynamic variables: pass the student's name, project details, and other per-student context into the conversation as parameters&lt;/item&gt;
      &lt;item&gt;Workflows: build a structured flow with sub-agents instead of a single "chatty" agent trying to do everything&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What the exam looked like&lt;/head&gt;
    &lt;p&gt;We ran a two-part oral exam.&lt;/p&gt;
    &lt;p&gt;Part 1: "Talk me through your project." The agent asks about the student's capstone project: goals, data, modeling choices, evaluation, failure modes. This is where the "LLM did my homework" strategy dies. You can paste an assignment into ChatGPT. It is much harder to improvise consistent answers about specific decisions when someone is drilling into details.&lt;/p&gt;
    &lt;p&gt;Part 2: "Now do a case." The agent picks one of the cases we discussed in class and asks questions spanning the topics we covered: basically testing whether students absorbed the material or just showed up.&lt;/p&gt;
    &lt;p&gt;To handle this structure, we split the exam into sub-agents in a workflow:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Authentication agent: Asks for the student's ID and refuses to proceed without a valid one. (In a more productized version, we would integrate with NYU SSO instead of checking against a list.)&lt;/item&gt;
      &lt;item&gt;Project discussion agent: Gets project context injected via parameters. The prompt includes details of each project so the agent can ask informed questions. The next step is obvious: connect retrieval over the student's submitted slides and reports so the agent can quote and probe precisely.&lt;/item&gt;
      &lt;item&gt;Case discussion agent: Selects a case and runs structured questioning. Again, RAG would help with richer case details.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This "many small agents" approach is not just aesthetic. It prevents the system from drifting into unbounded conversation, and it makes debugging possible.&lt;lb/&gt;If you want to try: Link to try the voice agent (use Konstantinos as the name and kr888 as the net id to authenticate; the project was a "LinkedIn Recruiter, an agent that scans profiles and automatically sends personalized DMs to candidates on behalf of a recruiter. It engages in the first 3 turns of chat to answer basic questions (salary, location) before handing off to a human.")&lt;/p&gt;
    &lt;head rend="h2"&gt;By the Numbers&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;36 students examined over 9 days&lt;/item&gt;
      &lt;item&gt;25 minutes average (range: 9–64)&lt;/item&gt;
      &lt;item&gt;65 messages per conversation on average&lt;/item&gt;
      &lt;item&gt;0.42 USD per student (15 USD total)&lt;/item&gt;
      &lt;item&gt;89% of LLM grades within 1 point&lt;/item&gt;
      &lt;item&gt;Shortest exam (9 min) → highest score (19/20)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The economics&lt;/head&gt;
    &lt;p&gt;Let's talk money.&lt;/p&gt;
    &lt;p&gt;Total cost for 36 students: 15 USD.&lt;/p&gt;
    &lt;p&gt;That's 8 USD for Claude (the chair and heaviest grader), 2 USD for Gemini, 0.30 USD for OpenAI, and roughly 5 USD for ElevenLabs voice minutes. Forty-two cents per student.&lt;/p&gt;
    &lt;p&gt;The alternative? 36 students × 25-minute exam × 2 graders = 30 hours of human time. At TA rates (~25/hour), that's 750. At faculty rates, it's "we don't do oral exams because they don't scale."&lt;/p&gt;
    &lt;p&gt;For 15 dollars, we got: real-time oral examination, a three-model grading council with deliberation, structured feedback with verbatim quotes, a complete audit trail, and—as you'll see—a diagnosis of our own teaching gaps.&lt;/p&gt;
    &lt;p&gt;The unit economics in terms of cost work. We will see next that the real benefit is in the value that is delivered, not in the 50x cost savings.&lt;/p&gt;
    &lt;head rend="h2"&gt;What broke (and how we fixed it)&lt;/head&gt;
    &lt;p&gt;The first version had problems. Here is what we learned.&lt;/p&gt;
    &lt;head rend="h3"&gt;1) The voice was intimidating&lt;/head&gt;
    &lt;p&gt;A few students complained that the agent sounded severe. We had cloned Foster Provost's voice because, frankly, his clone was much more accurate than the clones of our own voices. But the students found it... intense. Here is an email from a student:&lt;/p&gt;
    &lt;quote&gt;I had prepared thoroughly and felt confident in my understanding of the material, but the intensity of the interviewer's voice during the exam unexpectedly heightened my anxiety and affected my performance. The experience was more triggering than I anticipated, which made it difficult to fully demonstrate my knowledge. Throughout the course, I have actively participated and engaged with the material, and I had hoped to better demonstrate my knowledge in this interview.&lt;/quote&gt;
    &lt;p&gt;And here is another:&lt;/p&gt;
    &lt;quote&gt;Just got done with my oral exam. [...] I honestly didn't feel comfortable with it at all. The voice you picked was so condescending that it actually dropped my confidence. [...] I don't know why but the agent was shouting at me.&lt;/quote&gt;
    &lt;p&gt;Fix: We are split on that. We love FakeFoster. But next time we will A/B test, and we will try to test other voices. At the end of the day, we want to optimize for comprehension, not charisma. ElevenLabs has guidance on voice and personality tuning: they treat this as a product design problem, and probably a good idea.&lt;/p&gt;
    &lt;head rend="h3"&gt;2) The agent stacked questions&lt;/head&gt;
    &lt;p&gt;This was the biggest real issue. The agent would ask something like: "Explain your metric choice, and also tell me what baselines you tried, and why you did not use X, and what you would do next."&lt;/p&gt;
    &lt;p&gt;That is not one question. That is four questions wearing a trench coat. The cognitive load for an oral exam is already high. Stacking questions makes it brutal.&lt;/p&gt;
    &lt;p&gt;Fix: Hard rule in the prompt: one question at a time. If you want multi-part probing, chain it across turns. For grading the exam, we included an "interference protocol": students received full credit if they had questions stacked like that and answered only some of them.&lt;/p&gt;
    &lt;head rend="h3"&gt;3) Clarifications became moving targets&lt;/head&gt;
    &lt;p&gt;Student: "Can you repeat the question?"&lt;lb/&gt; Agent: paraphrases the question in a subtly different way&lt;/p&gt;
    &lt;p&gt;Now the student is solving a different problem than the one they were asked. Very frustrating.&lt;/p&gt;
    &lt;p&gt;Fix: Explicit instruction in the prompt: repeat verbatim when asked to repeat. No paraphrasing. Same words.&lt;/p&gt;
    &lt;head rend="h3"&gt;4) The agent did not let students think&lt;/head&gt;
    &lt;p&gt;Humans rush to fill silence. Agents do too. Students would pause to think, and the agent would jump in with follow-up probes or worse: interpret the silence as confusion and move on.&lt;/p&gt;
    &lt;p&gt;Fix: Tell the agent to allow think-time without probing aggressively. It made the exam feel less like an interrogation. We also increased the time-out before the agent asks "Are you there?" from 5 to 10 seconds.&lt;/p&gt;
    &lt;head rend="h3"&gt;5) Lack of randomization&lt;/head&gt;
    &lt;p&gt;We asked the agent to "randomly select" a case study. It did not.&lt;/p&gt;
    &lt;p&gt;From December 12–18, when Zillow was in the case list, the agent picked Zillow 88% of the time. After we removed Zillow from the prompt on December 18, the agent immediately latched onto Predictive Policing—picking it for 16 out of 21 exams on December 19 alone.&lt;/p&gt;
    &lt;p&gt;LLMs are not random. They have implicit preferences and ordering biases. Asking an LLM to "pick randomly" is like asking a human to "think of a number between 1 and 10"—you're going to get a lot of 7s.&lt;/p&gt;
    &lt;p&gt;Fix: Pass an explicit random number as a parameter and map it to cases deterministically. Do the randomization in code, not in the prompt.&lt;/p&gt;
    &lt;head rend="h2"&gt;Grading: the council deliberation actually worked&lt;/head&gt;
    &lt;p&gt;OK, so here is where things got interesting.&lt;/p&gt;
    &lt;p&gt;We graded using a "council of LLMs" approach, an idea we borrowed from Andrej Karpathy. Three models (Claude, Gemini, ChatGPT) assessed each transcript independently. Then they saw each other's assessments and revised. Finally, the chair (Claude) synthesized the final grade with evidence.&lt;/p&gt;
    &lt;p&gt;Round 1 was a mess. When the models graded independently, agreement was poor: 0% of grades matched exactly, and only 23% were within 2 points. The average maximum disagreement was nearly 4 points on a 20-point scale.&lt;/p&gt;
    &lt;p&gt;And here's the kicker: Gemini was a softie: It averaged 17/20. Claude averaged 13.4/20. That's a 3.6-point gap—the difference between a B+ and a B-.&lt;/p&gt;
    &lt;p&gt;Meanwhile, Claude and OpenAI were already aligned: 70% of their grades were within 1 point of each other in Round 1.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Model&lt;/cell&gt;
        &lt;cell role="head"&gt;Round 1 Mean&lt;/cell&gt;
        &lt;cell role="head"&gt;Round 2 Mean&lt;/cell&gt;
        &lt;cell role="head"&gt;Change&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Claude&lt;/cell&gt;
        &lt;cell&gt;13.4/20&lt;/cell&gt;
        &lt;cell&gt;13.9/20&lt;/cell&gt;
        &lt;cell&gt;+0.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;OpenAI&lt;/cell&gt;
        &lt;cell&gt;14.0/20&lt;/cell&gt;
        &lt;cell&gt;14.0/20&lt;/cell&gt;
        &lt;cell&gt;+0.0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Gemini&lt;/cell&gt;
        &lt;cell&gt;17.0/20&lt;/cell&gt;
        &lt;cell&gt;15.0/20&lt;/cell&gt;
        &lt;cell&gt;-2.0&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Then came consultation. After each model saw the others' assessments and evidence, agreement improved dramatically:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Metric&lt;/cell&gt;
        &lt;cell role="head"&gt;Round 1&lt;/cell&gt;
        &lt;cell role="head"&gt;Round 2&lt;/cell&gt;
        &lt;cell role="head"&gt;Improvement&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Perfect agreement&lt;/cell&gt;
        &lt;cell&gt;0%&lt;/cell&gt;
        &lt;cell&gt;21%&lt;/cell&gt;
        &lt;cell&gt;+21 pp&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Within 1 point&lt;/cell&gt;
        &lt;cell&gt;0%&lt;/cell&gt;
        &lt;cell&gt;62%&lt;/cell&gt;
        &lt;cell&gt;+62 pp&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Within 2 points&lt;/cell&gt;
        &lt;cell&gt;23%&lt;/cell&gt;
        &lt;cell&gt;85%&lt;/cell&gt;
        &lt;cell&gt;+62 pp&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Mean max difference&lt;/cell&gt;
        &lt;cell&gt;3.93 pts&lt;/cell&gt;
        &lt;cell&gt;1.41 pts&lt;/cell&gt;
        &lt;cell&gt;-2.52 pts&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Gemini lowered its grades by an average of 2 points after seeing Claude's and OpenAI's more rigorous assessments. It couldn't justify giving 17s when Claude was pointing to specific gaps in the experimentation discussion.&lt;/p&gt;
    &lt;p&gt;But here's what's interesting: the disagreement wasn't random. Problem Framing and Metrics had 100% agreement within 1 point. Experimentation? Only 57%.&lt;/p&gt;
    &lt;p&gt;Why? When students give clear, specific answers, graders agree. When students give vague hand-wavy answers, graders (human or AI) disagree on how much partial credit to give. The low agreement on experimentation reflects genuine ambiguity in student responses, not grader noise.&lt;/p&gt;
    &lt;p&gt;The grading was stricter than my own default. That's not a bug. Students will be evaluated outside the university, and the world is not known for grade inflation. (Just in case you are wondering, I graded all exams myself and I asked the TA to also grade the exams; we mostly agreed with the LLM grades, and I aligned mostly with the softie Gemini. However, when examining the cases when my grades disagreed with the council, I found that the council was more consistent across students and I often thought that the council graded more strictly but more fairly.)&lt;/p&gt;
    &lt;p&gt;The feedback was better than any human would produce. The system generated structured "strengths / weaknesses / actions" summaries with verbatim quotes from the transcript. Sample feedback from the highest scorer:&lt;/p&gt;
    &lt;quote&gt;"Your understanding of metric trade-offs and Goodhart's Law risks was exceptional—the hot tub example perfectly illustrated how optimizing for one metric can corrupt another."&lt;/quote&gt;
    &lt;p&gt;Sample from a B- student:&lt;/p&gt;
    &lt;quote&gt;"Practice articulating complete A/B testing designs: state a hypothesis, define randomization unit, specify guardrail metrics, and establish decision criteria for shipping or rolling back."&lt;/quote&gt;
    &lt;p&gt;Specific. Actionable. Tied to evidence. No human grader has the time to generate that for every student.&lt;/p&gt;
    &lt;head rend="h2"&gt;It diagnosed our teaching gaps&lt;/head&gt;
    &lt;p&gt;Ha! This one stung.&lt;/p&gt;
    &lt;p&gt;When we analyzed performance by topic, one bar stuck out like a sore thumb: Experimentation. Mean score: 1.94 out of 4. Compare that to Problem Framing at 3.39.&lt;/p&gt;
    &lt;p&gt;The breakdown was brutal:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;3 students (8%) scored 0—couldn't discuss it at all&lt;/item&gt;
      &lt;item&gt;7 students (19%) scored 1—superficial understanding&lt;/item&gt;
      &lt;item&gt;15 students (42%) scored 2—basic understanding&lt;/item&gt;
      &lt;item&gt;0 students scored 4—no one demonstrated mastery&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We had rushed through A/B testing methodology in class. The external grader made it impossible to ignore.&lt;/p&gt;
    &lt;p&gt;The grading output became a mirror reflecting our own weaknesses as instructors. Ooof.&lt;/p&gt;
    &lt;head rend="h3"&gt;Duration ≠ Quality&lt;/head&gt;
    &lt;p&gt;One finding I found strangely fascinating: exam duration had zero correlation with score (r = -0.03). The shortest exam—9 minutes—got the highest score (19/20). The longest—64 minutes—scored 12/20.&lt;/p&gt;
    &lt;p&gt;Taking longer doesn't mean you know more. If anything, it signals struggling to articulate. Confidence is efficient.&lt;/p&gt;
    &lt;head rend="h2"&gt;Anti-cheating (or: trust but verify)&lt;/head&gt;
    &lt;p&gt;We asked students to record themselves while taking the exam (webcam + audio). This discourages blatantly outsourcing the conversation, having multiple people in the room, or having an LLM in voice mode whispering answers. It also gives us a backup record in case something goes really badly.&lt;/p&gt;
    &lt;p&gt;And here is an underrated benefit of this whole setup: the exam is powered by guidelines, not by secret questions. We can publish exactly how the exam works—the structure, the skills being tested, the types of questions. No surprises. The LLM will pick the specific questions live, and the student will have to handle them.&lt;/p&gt;
    &lt;p&gt;This reduces anxiety and pushes students toward actual preparation instead of guessing what the instructor "wants." And it eliminates the leaked-exam problem entirely. Practice all you want—it will only make you better prepared.&lt;/p&gt;
    &lt;head rend="h2"&gt;What the students said&lt;/head&gt;
    &lt;p&gt;We surveyed students before releasing grades to capture their experience. Some of the results:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Only 13% preferred the AI oral format. 57% wanted traditional written exams. 83% found it more stressful.&lt;/item&gt;
      &lt;item&gt;But here's the thing: 70% agreed it tested their actual understanding: the highest-rated item. They accepted the assessment but not the delivery.&lt;/item&gt;
      &lt;item&gt;At the same time, they almost universally liked the flexibility of taking the exam at their own place and time. Yes, many of them would have also preferred a take-home exam instead of the oral exam, but this format is dead now.&lt;/item&gt;
      &lt;item&gt;83% of students found the oral exam framework more stressful than a written exam.&lt;/item&gt;
      &lt;item&gt;The fix is clear: one question at a time, slower pacing, calmer tone. The concept works. The execution needs iteration.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Try it yourself&lt;/head&gt;
    &lt;p&gt;If you want to experiment with this approach, here are some resources:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Prompt for the voice agent&lt;/item&gt;
      &lt;item&gt;Prompt for the grading council&lt;/item&gt;
      &lt;item&gt;Link to try the voice agent (use Konstantinos as the name and kr888 as the net id to authenticate; the project was a "LinkedIn Recruiter, an agent that scans profiles and automatically sends personalized DMs to candidates on behalf of a recruiter. It engages in the first 3 turns of chat to answer basic questions (salary, location) before handing off to a human.")&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What I would change next time&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Slower pacing and a calmer voice: We love you FakeFoster, but GenZ is not ready for you. Perhaps we will deploy FakePanos next time. Too bad ElevenLabs hasn't perfected thick accents yet to deliver a real Panos experience.&lt;/item&gt;
      &lt;item&gt;RAG over student artifacts (slides, reports, notebooks). ElevenLabs supports this directly. If the agent can quote the student's own submission, the exam becomes much harder to game and much more diagnostically useful.&lt;/item&gt;
      &lt;item&gt;Better case randomization with explicit seeding and tracking. Randomness that "feels random" is not enough. Pass explicit parameters.&lt;/item&gt;
      &lt;item&gt;Audit triggers in grading. If the LLM committee disagrees beyond a threshold, flag for human review. The point of a committee is not to pretend the result is always certain; it is to surface uncertainty.&lt;/item&gt;
      &lt;item&gt;Accessibility defaults. Offer practice runs, allow extra time, and provide alternatives when voice interaction creates unnecessary barriers.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The bigger point&lt;/head&gt;
    &lt;p&gt;Take-home exams are dead. Reverting to pen-and-paper exams in the classroom feels like a regression. In our case, we wanted to check that the students who worked in the team projects actually contributed and understood what they submitted; we would not be able to do that with pen-and-paper exams in the classroom.&lt;/p&gt;
    &lt;p&gt;We need assessments that evolve towards formats that reward understanding, decision-making, and real-time reasoning. Oral exams used to be standard until they could not scale. Now, AI is making them scalable again.&lt;/p&gt;
    &lt;p&gt;And here is the delicious part: you can give the whole setup to the students and let them prepare for the exam by practicing it multiple times. Unlike traditional exams, where leaked questions are a disaster, here the questions are generated fresh each time. The more you practice, the better you get. That is... actually how learning is supposed to work.&lt;/p&gt;
    &lt;p&gt;Fight fire with fire.&lt;/p&gt;
    &lt;p&gt;Thanks to Brian Jabarian for the inspiration and for giving us confidence that these interviews will work, Foster Provost for lending his voice to create the FakeFoster agent (sorry, students found you intimidating!), and Andrej Karpathy for the council-of-LLMs idea.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46467677</guid><pubDate>Fri, 02 Jan 2026 18:18:47 +0000</pubDate></item><item><title>TinyTinyTPU: 2×2 systolic-array TPU-style matrix-multiply unit deployed on FPGA</title><link>https://github.com/Alanma23/tinytinyTPU-co</link><description>&lt;doc fingerprint="b851bc757007c0b2"&gt;
  &lt;main&gt;
    &lt;p&gt;A minimal 2×2 systolic-array TPU-style matrix-multiply unit, implemented in SystemVerilog and deployed on FPGA.&lt;/p&gt;
    &lt;p&gt;This project implements a complete TPU architecture including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2×2 systolic array (4 processing elements)&lt;/item&gt;
      &lt;item&gt;Full post-MAC pipeline (accumulator, activation, normalization, quantization)&lt;/item&gt;
      &lt;item&gt;UART-based host interface&lt;/item&gt;
      &lt;item&gt;Multi-layer MLP inference capability&lt;/item&gt;
      &lt;item&gt;FPGA deployment on Basys3 (Xilinx Artix-7)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Resource Usage (Basys3 XC7A35T):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;LUTs: ~1,000 (5% utilization)&lt;/item&gt;
      &lt;item&gt;Flip-Flops: ~1,000 (3% utilization)&lt;/item&gt;
      &lt;item&gt;DSP48E1: 8 slices&lt;/item&gt;
      &lt;item&gt;BRAM: ~10-15 blocks&lt;/item&gt;
      &lt;item&gt;Estimated Gate Count: ~25,000 gates&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Project Overview&lt;/item&gt;
      &lt;item&gt;Quick Start&lt;/item&gt;
      &lt;item&gt;Simulation &amp;amp; Testing&lt;/item&gt;
      &lt;item&gt;FPGA Build &amp;amp; Deployment&lt;/item&gt;
      &lt;item&gt;Running Inference&lt;/item&gt;
      &lt;item&gt;Project Structure&lt;/item&gt;
      &lt;item&gt;Architecture Details&lt;/item&gt;
      &lt;item&gt;Open Source Tooling (Yosys/nextpnr)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;TinyTinyTPU is an educational implementation of Google's TPU architecture, scaled down to a 2×2 systolic array. It demonstrates:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Systolic Array Architecture: Data flows horizontally (activations) and vertically (partial sums)&lt;/item&gt;
      &lt;item&gt;Diagonal Wavefront Weight Loading: Staggered weight capture for proper systolic timing&lt;/item&gt;
      &lt;item&gt;Full MLP Pipeline: Weight FIFO → MMU → Accumulator → Activation → Normalization → Quantization&lt;/item&gt;
      &lt;item&gt;Multi-Layer Inference: Supports sequential layer processing with double-buffered activations&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is a minimal, educational-scale TPU designed for:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Learning TPU architecture principles&lt;/item&gt;
      &lt;item&gt;Understanding systolic array dataflow&lt;/item&gt;
      &lt;item&gt;FPGA prototyping and experimentation&lt;/item&gt;
      &lt;item&gt;Small-scale ML inference (2×2 matrices)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For production workloads, scale up the array size (e.g., 256×256 like Google TPU v1).&lt;/p&gt;
    &lt;p&gt;For Simulation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Verilator 5.022 or later&lt;/item&gt;
      &lt;item&gt;Python 3.8+&lt;/item&gt;
      &lt;item&gt;cocotb&lt;/item&gt;
      &lt;item&gt;GTKWave or Surfer (for waveform viewing)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For FPGA Build:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Xilinx Vivado 2020.1 or later (for Basys3)&lt;/item&gt;
      &lt;item&gt;OR Yosys + nextpnr (open source alternative, see Open Source Tooling)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For Running Inference:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Basys3 FPGA board&lt;/item&gt;
      &lt;item&gt;USB cable for programming&lt;/item&gt;
      &lt;item&gt;Python 3.8+ with pyserial&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Clone the repository
git clone &amp;lt;repository-url&amp;gt;
cd tinytinyTPU-co

# Set up simulation environment
cd sim
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt&lt;/code&gt;
    &lt;p&gt;All simulation commands must be run from the &lt;code&gt;sim/&lt;/code&gt; directory:&lt;/p&gt;
    &lt;code&gt;cd sim

# Run all tests
make test

# Run all tests with waveform generation
make test WAVES=1

# Run specific module tests
make test_pe
make test_mmu
make test_mlp
make test_uart
make test_tpu_system

# Run with waveforms
make test_pe WAVES=1&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Test File&lt;/cell&gt;
        &lt;cell role="head"&gt;Module&lt;/cell&gt;
        &lt;cell role="head"&gt;Coverage&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;test_pe.py&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Processing Element&lt;/cell&gt;
        &lt;cell&gt;Reset, MAC operations, weight capture&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;test_mmu.py&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;2×2 Systolic Array&lt;/cell&gt;
        &lt;cell&gt;Weight loading, matrix multiply&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;test_weight_fifo.py&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Weight FIFO&lt;/cell&gt;
        &lt;cell&gt;Push/pop, wraparound&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;test_dual_weight_fifo.py&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Dual Weight FIFO&lt;/cell&gt;
        &lt;cell&gt;Column independence, skew timing&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;test_accumulator.py&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Accumulator&lt;/cell&gt;
        &lt;cell&gt;Alignment, buffering, accumulate/overwrite modes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;test_activation_func.py&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Activation Function&lt;/cell&gt;
        &lt;cell&gt;ReLU positive/negative/zero cases&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;test_normalizer.py&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Normalizer&lt;/cell&gt;
        &lt;cell&gt;Gain, bias, shift operations&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;test_activation_pipeline.py&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Activation Pipeline&lt;/cell&gt;
        &lt;cell&gt;Full pipeline, saturation handling&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;test_mlp_integration.py&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;MLP Top&lt;/cell&gt;
        &lt;cell&gt;Multi-layer MLP inference&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;test_uart_controller.py&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;UART Controller&lt;/cell&gt;
        &lt;cell&gt;Command parsing, response generation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;test_tpu_system.py&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;TPU Top&lt;/cell&gt;
        &lt;cell&gt;End-to-end system integration&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;# List available waveforms
make waves

# Open specific waveform
make waves MODULE=pe
make waves MODULE=mmu
make waves MODULE=mlp_top&lt;/code&gt;
    &lt;p&gt;Basys3 Pinout:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;UART RX (B18): Receives commands from PC&lt;/item&gt;
      &lt;item&gt;UART TX (A18): Sends responses to PC&lt;/item&gt;
      &lt;item&gt;Clock: 100 MHz (onboard oscillator)&lt;/item&gt;
      &lt;item&gt;Reset: Center button (BTNC, U18)&lt;/item&gt;
      &lt;item&gt;LEDs: Status display (see &lt;code&gt;fpga/README.md&lt;/code&gt;for LED modes)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;UART Settings:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Baud Rate: 115200&lt;/item&gt;
      &lt;item&gt;Data Bits: 8&lt;/item&gt;
      &lt;item&gt;Parity: None&lt;/item&gt;
      &lt;item&gt;Stop Bits: 1&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The project includes a Python driver for communicating with the FPGA:&lt;/p&gt;
    &lt;code&gt;cd host

# Basic inference demo
python3 inference_demo.py

# Gesture recognition demo (requires trained model)
python3 gesture_demo.py

# Interactive test
python3 test_tpu_driver.py&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;inference_demo.py&lt;/code&gt; script demonstrates:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Loading weights into the TPU&lt;/item&gt;
      &lt;item&gt;Loading input activations&lt;/item&gt;
      &lt;item&gt;Executing inference&lt;/item&gt;
      &lt;item&gt;Reading results&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example Usage:&lt;/p&gt;
    &lt;code&gt;from tpu_driver import TPUDriver

# Connect to FPGA (adjust port as needed)
tpu = TPUDriver('/dev/ttyUSB0')  # Linux
# tpu = TPUDriver('COM3')         # Windows

# Load 2×2 weight matrix
weights = [[1, 2], [3, 4]]
tpu.write_weights(weights)

# Load 2×2 activation matrix
activations = [[5, 6], [7, 8]]
tpu.write_activations(activations)

# Execute inference
tpu.execute()

# Read results
result = tpu.read_result()
print(f"Result: {result}")&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;gesture_demo.py&lt;/code&gt; script implements a simple gesture classifier:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Trains a 2-layer MLP on mouse movement data&lt;/item&gt;
      &lt;item&gt;Classifies gestures as "Horizontal" or "Vertical"&lt;/item&gt;
      &lt;item&gt;Real-time inference on FPGA&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Running the Demo:&lt;/p&gt;
    &lt;code&gt;cd host
python3 gesture_demo.py&lt;/code&gt;
    &lt;p&gt;Model Training:&lt;/p&gt;
    &lt;code&gt;cd model
python3 train.py
# Generates: gesture_model.json&lt;/code&gt;
    &lt;p&gt;The TPU uses a simple byte-based UART protocol:&lt;/p&gt;
    &lt;p&gt;Commands:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;0x01&lt;/code&gt;: Write Weight (4 bytes: W00, W01, W10, W11)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;0x02&lt;/code&gt;: Write Activation (4 bytes: A00, A01, A10, A11)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;0x03&lt;/code&gt;: Execute (start inference)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;0x04&lt;/code&gt;: Read Result (returns 4 bytes: acc0[31:0])&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;0x05&lt;/code&gt;: Read Result Column 1 (returns 4 bytes: acc1[31:0])&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;0x06&lt;/code&gt;: Read Status (returns 1 byte: state[3:0] | cycle_cnt[3:0])&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See &lt;code&gt;host/tpu_driver.py&lt;/code&gt; for full protocol implementation.&lt;/p&gt;
    &lt;code&gt;tinytinyTPU-co/
├── rtl/                          # SystemVerilog RTL source files
│   ├── pe.sv                     # Processing Element (MAC unit)
│   ├── mmu.sv                    # 2×2 Matrix Multiply Unit (systolic array)
│   ├── weight_fifo.sv            # Single-column weight FIFO
│   ├── dual_weight_fifo.sv       # Dual-column weight FIFO with skew
│   ├── accumulator.sv            # Top-level accumulator
│   ├── accumulator_align.sv      # Column alignment logic
│   ├── accumulator_mem.sv        # Double-buffered accumulator memory
│   ├── activation_func.sv        # ReLU/ReLU6 activation
│   ├── normalizer.sv             # Gain/bias/shift normalization
│   ├── loss_block.sv             # L1 loss computation
│   ├── activation_pipeline.sv    # Full post-accumulator pipeline
│   ├── unified_buffer.sv          # Ready/valid output FIFO
│   ├── mlp_top.sv                # Top-level MLP integration
│   ├── tpu_bridge.sv              # UART-to-MLP bridge
│   ├── uart_controller.sv         # UART command processor
│   ├── uart_rx.sv                # UART receiver
│   ├── uart_tx.sv                # UART transmitter
│   └── tpu_top.sv                # Complete TPU system
│
├── sim/                          # Simulation environment
│   ├── Makefile                  # Build and test automation
│   ├── requirements.txt          # Python dependencies
│   ├── tests/                    # cocotb Python testbenches
│   │   ├── test_pe.py
│   │   ├── test_mmu.py
│   │   ├── test_weight_fifo.py
│   │   ├── test_dual_weight_fifo.py
│   │   ├── test_accumulator.py
│   │   ├── test_activation_func.py
│   │   ├── test_normalizer.py
│   │   ├── test_activation_pipeline.py
│   │   ├── test_mlp_integration.py
│   │   ├── test_uart_controller.py
│   │   └── test_tpu_system.py
│   └── waves/                    # Generated VCD waveforms
│
├── fpga/                         # FPGA deployment files
│   ├── basys3_top.sv             # Top-level FPGA wrapper
│   ├── basys3.xdc                # Pin constraints
│   ├── build_vivado.tcl          # Automated build script
│   ├── basys3_top.bit            # Generated bitstream
│   └── README.md                 # FPGA-specific documentation
│
├── host/                         # Python host interface
│   ├── tpu_driver.py             # TPU communication driver
│   ├── tpu_compiler.py           # Model compilation utilities
│   ├── inference_demo.py          # Basic inference demo
│   ├── gesture_demo.py           # Gesture recognition demo
│   └── test_tpu_driver.py        # Driver unit tests
│
├── model/                        # ML model training
│   ├── train.py                  # Model training script
│   └── gesture_model.json        # Trained model (JSON format)
│
└── README.md                     # This file
&lt;/code&gt;
    &lt;code&gt;PE00 -&amp;gt; PE01    Activations flow horizontally (right)
  |       |     
PE10 -&amp;gt; PE11    Partial sums flow vertically (down)
  |       |
acc0    acc1    Outputs to accumulator
&lt;/code&gt;
    &lt;p&gt;Weight Loading (Diagonal Wavefront):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cycle 0: W10 → col0, no capture&lt;/item&gt;
      &lt;item&gt;Cycle 1: W00 → col0 (capture), W11 → col1 (no capture)&lt;/item&gt;
      &lt;item&gt;Cycle 2: W01 → col1 (capture)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Activation Flow:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Row 0: A00 → PE00 → PE01&lt;/item&gt;
      &lt;item&gt;Row 1: A10 → PE10 → PE11 (with 1-cycle skew)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Weight FIFO: Stores weights, outputs with column skew&lt;/item&gt;
      &lt;item&gt;MMU (Systolic Array): Matrix multiply-accumulate&lt;/item&gt;
      &lt;item&gt;Accumulator: Aligns columns, double-buffered storage&lt;/item&gt;
      &lt;item&gt;Activation Pipeline: &lt;list rend="ul"&gt;&lt;item&gt;Activation function (ReLU/ReLU6)&lt;/item&gt;&lt;item&gt;Normalization (gain × bias + shift)&lt;/item&gt;&lt;item&gt;Quantization (int8 with saturation)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Unified Buffer: Output FIFO with ready/valid handshaking&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The MLP controller manages sequential layer processing:&lt;/p&gt;
    &lt;code&gt;State Machine:
IDLE → LOAD_WEIGHT → LOAD_ACT → COMPUTE → DRAIN → TRANSFER → NEXT_LAYER → WAIT_WEIGHTS → ...
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Double Buffering: Activations ping-pong between buffers for layer-to-layer transfer&lt;/item&gt;
      &lt;item&gt;Weight Loading: Weights loaded per layer via UART&lt;/item&gt;
      &lt;item&gt;Pipeline Overlap: While layer N drains, layer N+1 weights can be loaded&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;While Vivado is the standard toolchain for Xilinx FPGAs, open-source alternatives exist:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Yosys: Synthesis (RTL → netlist)&lt;/item&gt;
      &lt;item&gt;nextpnr: Place &amp;amp; Route (netlist → bitstream)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Installation (Ubuntu/Debian):&lt;/p&gt;
    &lt;code&gt;# Install Yosys
sudo apt-get install yosys

# Install nextpnr (for Xilinx 7-series)
# Requires building from source - see nextpnr documentation
git clone https://github.com/YosysHQ/nextpnr.git
cd nextpnr
cmake . -DARCH=xilinx
make -j$(nproc)
sudo make install&lt;/code&gt;
    &lt;p&gt;Installation (macOS):&lt;/p&gt;
    &lt;code&gt;brew install yosys
# nextpnr requires manual build&lt;/code&gt;
    &lt;p&gt;Step 1: Synthesis (Yosys)&lt;/p&gt;
    &lt;code&gt;cd fpga

# Create synthesis script
cat &amp;gt; synth.ys &amp;lt;&amp;lt; 'EOF'
# Read RTL files
read_verilog -sv ../rtl/pe.sv
read_verilog -sv ../rtl/mmu.sv
read_verilog -sv ../rtl/weight_fifo.sv
read_verilog -sv ../rtl/dual_weight_fifo.sv
read_verilog -sv ../rtl/accumulator_align.sv
read_verilog -sv ../rtl/accumulator_mem.sv
read_verilog -sv ../rtl/accumulator.sv
read_verilog -sv ../rtl/activation_func.sv
read_verilog -sv ../rtl/normalizer.sv
read_verilog -sv ../rtl/loss_block.sv
read_verilog -sv ../rtl/activation_pipeline.sv
read_verilog -sv ../rtl/unified_buffer.sv
read_verilog -sv ../rtl/mlp_top.sv
read_verilog -sv ../rtl/uart_rx.sv
read_verilog -sv ../rtl/uart_tx.sv
read_verilog -sv ../rtl/uart_controller.sv
read_verilog -sv ../rtl/tpu_bridge.sv
read_verilog -sv ../rtl/tpu_top.sv
read_verilog -sv basys3_top.sv

# Set top module
hierarchy -top basys3_top

# Synthesize
synth_xilinx -top basys3_top -family xc7

# Write netlist
write_verilog basys3_top_synth.v
write_json basys3_top.json
EOF

# Run synthesis
yosys synth.ys&lt;/code&gt;
    &lt;p&gt;Step 2: Place &amp;amp; Route (nextpnr)&lt;/p&gt;
    &lt;code&gt;# Generate bitstream
nextpnr-xilinx \
    --xdc basys3.xdc \
    --json basys3_top.json \
    --write basys3_top_routed.json \
    --fasm basys3_top.fasm

# Generate bitstream (requires Xilinx tools or open-source fasm2bit)
# Note: fasm2bit conversion may require Xilinx tools or open-source alternatives&lt;/code&gt;
    &lt;p&gt;The project includes a TCL script for automated Vivado builds:&lt;/p&gt;
    &lt;code&gt;cd fpga

# Build bitstream (synthesis + implementation + bitgen)
vivado -mode batch -source build_vivado.tcl

# Expected build time: 5-10 minutes
# Output: basys3_top.bit&lt;/code&gt;
    &lt;p&gt;Build Script Details:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Creates Vivado project: &lt;code&gt;vivado_project/tinytinyTPU_basys3&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Synthesizes all RTL files from &lt;code&gt;../rtl/&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Implements design with timing constraints&lt;/item&gt;
      &lt;item&gt;Generates bitstream: &lt;code&gt;basys3_top.bit&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Creates reports: utilization, timing, DRC&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Resource Utilization (Post-Implementation):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check &lt;code&gt;vivado_project/tinytinyTPU_basys3.runs/impl_1/utilization_post_impl.rpt&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Check &lt;code&gt;vivado_project/tinytinyTPU_basys3.runs/impl_1/timing_summary_post_impl.rpt&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Via Vivado Hardware Manager (GUI):&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Connect Basys3 board via USB&lt;/item&gt;
      &lt;item&gt;Open Vivado&lt;/item&gt;
      &lt;item&gt;Open Hardware Manager&lt;/item&gt;
      &lt;item&gt;Auto-connect to target&lt;/item&gt;
      &lt;item&gt;Program with &lt;code&gt;basys3_top.bit&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Via Command Line:&lt;/p&gt;
    &lt;code&gt;vivado -mode tcl
open_hw_manager
connect_hw_server
open_hw_target
set_property PROGRAM.FILE {basys3_top.bit} [get_hw_devices xc7a35t_0]
program_hw_devices [get_hw_devices xc7a35t_0]&lt;/code&gt;
    &lt;p&gt;Via OpenOCD (Alternative):&lt;/p&gt;
    &lt;code&gt;# If using OpenOCD with Digilent cable
openocd -f interface/ftdi/digilent_jtag_hs3.cfg -f target/xc7a35t.cfg
# Then use GDB or other tools to program&lt;/code&gt;
    &lt;p&gt;Current Status:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Yosys synthesis works well for most SystemVerilog constructs&lt;/item&gt;
      &lt;item&gt;nextpnr supports Xilinx 7-series but may have timing/routing challenges&lt;/item&gt;
      &lt;item&gt;Bitstream generation (fasm2bit) may require Xilinx tools or open-source alternatives&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Recommendations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;For development: Use Vivado for reliable builds&lt;/item&gt;
      &lt;item&gt;For open-source exploration: Use Yosys for synthesis, verify with Vivado&lt;/item&gt;
      &lt;item&gt;For production: Stick with Vivado until open-source toolchain matures&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Future Work:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Create automated Yosys/nextpnr build script&lt;/item&gt;
      &lt;item&gt;Document fasm2bit conversion process&lt;/item&gt;
      &lt;item&gt;Benchmark open-source vs. Vivado results&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Verilator Errors:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Ensure Verilator 5.022+ is installed&lt;/item&gt;
      &lt;item&gt;Check SystemVerilog syntax (use &lt;code&gt;make lint&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Test Failures:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Run with &lt;code&gt;WAVES=1&lt;/code&gt;to generate waveforms for debugging&lt;/item&gt;
      &lt;item&gt;Check &lt;code&gt;sim/test_output.log&lt;/code&gt;for detailed error messages&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Synthesis Errors:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check RTL files are in &lt;code&gt;rtl/&lt;/code&gt;directory&lt;/item&gt;
      &lt;item&gt;Verify SystemVerilog syntax (Vivado may be stricter than Verilator)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Timing Violations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check &lt;code&gt;timing_summary_post_impl.rpt&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;May need to add pipeline stages or reduce clock frequency&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Place &amp;amp; Route Failures:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check utilization reports&lt;/item&gt;
      &lt;item&gt;Verify constraints in &lt;code&gt;basys3.xdc&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;UART Not Working:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Verify COM port: &lt;code&gt;ls /dev/ttyUSB*&lt;/code&gt;(Linux) or Device Manager (Windows)&lt;/item&gt;
      &lt;item&gt;Check baud rate: 115200&lt;/item&gt;
      &lt;item&gt;Verify TX/RX pins in constraints file&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;LEDs Not Responding:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check bitstream programmed correctly&lt;/item&gt;
      &lt;item&gt;Verify reset button (center button)&lt;/item&gt;
      &lt;item&gt;Check switch settings for LED modes (see &lt;code&gt;fpga/README.md&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Contributions welcome! Areas for improvement:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Additional test coverage&lt;/item&gt;
      &lt;item&gt;Performance optimizations&lt;/item&gt;
      &lt;item&gt;Documentation improvements&lt;/item&gt;
      &lt;item&gt;Open-source toolchain support&lt;/item&gt;
      &lt;item&gt;Larger array sizes&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Inspired by Google's TPU architecture (thank you Cliff and Richard for your time!)&lt;/item&gt;
      &lt;item&gt;The boys from the TinyTPU team!!&lt;/item&gt;
      &lt;item&gt;Edmund and the Yosys / Symbiotic EDA crew&lt;/item&gt;
      &lt;item&gt;Stanford FAF for the support, funding, and community!&lt;/item&gt;
      &lt;item&gt;Princeton ECE Dept for the Basys 3 to play around with :)&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46468237</guid><pubDate>Fri, 02 Jan 2026 19:13:24 +0000</pubDate></item><item><title>Unix v4 (1973) – Live Terminal</title><link>https://unixv4.dev/</link><description>&lt;doc fingerprint="a12d4d59e947678b"&gt;
  &lt;main&gt;&lt;p&gt;PDP-11/45&lt;/p&gt;&lt;p&gt;Released November 1973 - the first UNIX written in C, making it portable across hardware platforms.&lt;/p&gt;&lt;p&gt;This is the only known copy, recovered in 2025 from a magnetic tape discovered at the University of Utah after 52 years.&lt;/p&gt;&lt;p&gt;Running on an emulated PDP-11/45 minicomputer, the same hardware used at Bell Labs.&lt;/p&gt;&lt;p&gt;Sources: squoze.net | tape recovery story&lt;/p&gt;&lt;p&gt;ð Feedback &amp;amp; Contact: Check out our guestbook below, or send private feedback to [email protected]&lt;/p&gt;&lt;p&gt; â¢ Backspace doesn't work!&lt;lb/&gt; Press &lt;code&gt;#&lt;/code&gt; to delete char, &lt;code&gt;@&lt;/code&gt; for line&lt;lb/&gt; â¢ Use &lt;code&gt;chdir&lt;/code&gt; not &lt;code&gt;cd&lt;/code&gt;&lt;lb/&gt; â¢ No &lt;code&gt;man&lt;/code&gt; pages (that's v5+)&lt;lb/&gt; â¢ Sessions are temporary (10min timeout if left idle) and ephemeral (state is not saved between sessions and reset on page reload)&lt;lb/&gt; â¢ Authentic 1973 behavior - expect quirks! &lt;/p&gt;&lt;p&gt;Directories:&lt;/p&gt;&lt;code&gt;/demo&lt;/code&gt; - C programs to compile&lt;code&gt;/usr/games&lt;/code&gt; - Vintage games&lt;code&gt;/usr/source&lt;/code&gt; - Unix kernel source&lt;code&gt;/bin&lt;/code&gt; - Available commands&lt;p&gt;Quick Start:&lt;/p&gt;&lt;code&gt;
                    chdir /demo&lt;lb/&gt;
                    cc hello.c&lt;lb/&gt;
                    ./a.out
                &lt;/code&gt;
            &lt;p&gt;Pre-installed in &lt;code&gt;/demo&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;hello.c&lt;/code&gt; - Hello World&lt;code&gt;primes.c&lt;/code&gt; - Prime finder&lt;code&gt;guess.c&lt;/code&gt; - Number guessing game&lt;code&gt;fib.c&lt;/code&gt; - Fibonacci sequence&lt;p&gt;Share your thoughts about UNIX v4 and this site! Your feedback is valuable and helps us improve the experience.&lt;/p&gt;&lt;p&gt;The UNIX v4 software and disk image are licensed under the Caldera Ancient UNIX License.&lt;/p&gt;&lt;p&gt; Copyright Â© Caldera International Inc. 2001-2002. All rights reserved.&lt;lb/&gt; This product includes software developed or owned by Caldera International, Inc.&lt;lb/&gt; UNIX v4 is provided for educational and historical purposes. No warranty. Use at your own risk. &lt;/p&gt;&lt;p&gt;UNIX is a registered trademark of The Open Group in the US and other countries.&lt;/p&gt;&lt;p&gt;This website is not affiliated with or endorsed by Bell Labs, AT&amp;amp;T, The Open Group, or any other trademark holders.&lt;/p&gt;&lt;p&gt;The website design, user interface, and integration platform are original works created by:&lt;/p&gt;&lt;p&gt;Copyright Â© 2025 Squiz Software Pty Ltd - All Rights Reserved&lt;/p&gt;&lt;p&gt;This includes the visual design, theming, web interface, and custom demo programs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46468283</guid><pubDate>Fri, 02 Jan 2026 19:18:36 +0000</pubDate></item><item><title>Jank Lang Hit Alpha</title><link>https://github.com/jank-lang/jank</link><description>&lt;doc fingerprint="9d9d3879498c19d0"&gt;
  &lt;main&gt;
    &lt;p&gt;Most simply, jank is a Clojure dialect on LLVM with C++ interop. Less simply, jank is a general-purpose programming language which embraces the interactive, functional, value-oriented nature of Clojure and the desire for the native runtime and performance of C++. jank aims to be strongly compatible with Clojure. While Clojure's default host is the JVM and its interop is with Java, jank's host is LLVM and its interop is with C++.&lt;/p&gt;
    &lt;p&gt;jank is currently in alpha! Look here for details.&lt;/p&gt;
    &lt;p&gt;Read the jank book.&lt;/p&gt;
    &lt;code&gt;; Comments begin with a ;
(println "meow") ; =&amp;gt; nil

; All built-in data structures are persistent and immutable.
(def george {:name "George Clooney"}) ; =&amp;gt; #'user/george

; Though all data is immutable by default, side effects are adhoc.
(defn say-hi [who]
  (println (str "Hi " (:name who) "!"))
  (assoc who :greeted? true))

; Doesn't change george.
(say-hi george) ; =&amp;gt; {:name "George Clooney"
                ;     :greeted? true}

; Many core functions for working with immutable data.
(apply + (distinct [12 8 12 16 8 6])) ; =&amp;gt; 42

; Interop with C++ can happen *seamlessly*.
(defn sleep [ms]
  (let [duration (cpp/std.chrono.milliseconds ms)]
    (cpp/std.this_thread.sleep_for duration)))&lt;/code&gt;
    &lt;p&gt;If you'd like your name, company, or logo here, you can sponsor this project for at least $25/m.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46468517</guid><pubDate>Fri, 02 Jan 2026 19:39:38 +0000</pubDate></item><item><title>Publish on your own site, syndicate elsewhere</title><link>https://indieweb.org/POSSE#</link><description>&lt;doc fingerprint="385cdb519a5f2b83"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;POSSE&lt;/head&gt;
    &lt;p&gt;POSSE is an abbreviation for Publish (on your) Own Site, Syndicate Elsewhere, the practice of posting content on your own site first, then publishing copies or sharing links to third parties (like social media silos) with original post links to provide viewers a path to directly interacting with your content.&lt;/p&gt;
    &lt;p&gt;▶️ watch Zach’s 1min* video intro to POSSE&lt;/p&gt;
    &lt;head rend="h2"&gt;Why&lt;/head&gt;
    &lt;p&gt;Let your friends read your posts, their way. POSSE lets your friends keep using whatever they use to read your stuff (e.g. social media silos like Instagram, Tumblr, Twitter, Neocities, etc.).&lt;/p&gt;
    &lt;p&gt;Stay in touch with friends now, not some theoretical future. POSSE is about staying in touch with current friends now, rather than the potential of staying in touch with friends in the future.&lt;/p&gt;
    &lt;p&gt;Friends are more important than federation. By focusing on relationships that matter to people rather than architectural ideals, from a human perspective, POSSE is more important than federation. Additionally, if federated approaches take a POSSE approach first, they will likely get better adoption (everyone wants to stay in touch with their friends), and thereby more rapidly approach that federated future.&lt;/p&gt;
    &lt;p&gt;POSSE is beyond blogging. It's a key part of why and how the IndieWeb movement is different from just "everyone blog on their own site", and also different from "everyone just install and run (YourFavoriteSocialSoftware)" etc. monoculture solutions.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why In General&lt;/head&gt;
    &lt;p&gt;POSSE is considered a robust and preferable syndication model for the following reasons:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reduce 3rd party dependence. By posting directly to your own site, you're not dependent on 3rd Party services to do so -- if you can access your site, you can publish your content. On the contrary with PESOS, when the 3rd party site is down, you are unable to add content.&lt;/item&gt;
      &lt;item&gt;Ownership. By posting first on your own site, you create a direct ownership chain that can be traced back to you without any intervening 3rd party services (silos) TOS's getting in the way (which is a vulnerability of PESOS).&lt;/item&gt;
      &lt;item&gt;Own canonical URLs to your content. Canonical URLs to your content are on your domain.&lt;/item&gt;
      &lt;item&gt;Copies can cite the original. By posting content first to your own site (and thus creating a permalink for it), copies that you post on 3rd Party services can link or cite the original on your site (see syndication_formats and POSSE Notes to Twitter)&lt;/item&gt;
      &lt;item&gt;Better search. Searching public content on your own domain (with any web search engine of your choice) works better than depending on silos exclusively to search your posts (e.g. Twitter for a while only showed recent tweets in search results. Facebook still has very poor search results).&lt;/item&gt;
      &lt;item&gt;backfeed can be used to pull in (reverse syndicate) responses from other services&lt;/item&gt;
      &lt;item&gt;allows taking advantage of other services' social layers and aggregation features while storing the canonical copy of your content on your own site&lt;/item&gt;
      &lt;item&gt;...&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Why Link To Your Original&lt;/head&gt;
    &lt;p&gt;Common POSSE practice is to link from POSSE copies to your original, using a permashortlink. Here are a few reasons why:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Discovery of your original content. discovery of your original content from the copies on 3rd party services is enabled by the permashortlinks to your originals posted on said services&lt;/item&gt;
      &lt;item&gt;Subvert spammers who copy your posts. When spammers (e.g. @sin3rss) mindlessly copy from your POSSE copies and repost, they also copy the link back to the original, and thus provide more distribution for people to find and view your original post. "2011-01-09 internet aikido" of a sort.&lt;/item&gt;
      &lt;item&gt;Better ranking for your original posts. If/when your POSSE copies are themselves copied by others and (re)posted elsewhere (e.g. manual retweets, RSS bots etc.), when the copies link to your original posts, search engines figure that out by following those links back to the original and ranking it higher.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;How to&lt;/head&gt;
    &lt;head rend="h3"&gt;How to implement&lt;/head&gt;
    &lt;p&gt;This section is for web developers implementing POSSE.&lt;/p&gt;
    &lt;head rend="h4"&gt;In General&lt;/head&gt;
    &lt;p&gt;In general, when your content posting software posts something, it should also post a copy to the silo destinations of your choice, with an original post link (e.g. permashortlink or permashortcitation) back to your original.&lt;/p&gt;
    &lt;p&gt;The details of how to do so vary per destination. See the silo-specific sections below.&lt;/p&gt;
    &lt;p&gt;Once you have posted the copy to the silo, you should:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;link to the syndicated copy from the original in a posts-elsewhere section on your post.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;User Interface&lt;/head&gt;
    &lt;p&gt;The best user interface (UI) is automatic, dependable, and invisible. If you can implement POSSEing in a way that always does exactly what you want, predictably, then no explicit UI is needed.&lt;/p&gt;
    &lt;head rend="h5"&gt;Preview&lt;/head&gt;
    &lt;p&gt;One way to provide more predictability and inspire confidence is to show what will be POSSEd (within the limitations of the destination) as a preview before publishing&lt;/p&gt;
    &lt;p&gt;(needs screenshot)&lt;/p&gt;
    &lt;p&gt;Twitter is perhaps the most popular POSSE destination and a good place to start.&lt;/p&gt;
    &lt;p&gt;If you can start posting notes (tweets) to your own site and POSSEing to Twitter, instead of posting directly to Twitter, you have taken a big step towards owning your data.&lt;/p&gt;
    &lt;p&gt;Details:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;API Access - posting new tweets works nicely due to permanent API tokens, and the return value contains a URL to the posted &lt;list rend="ul"&gt;&lt;item&gt;As of 2022-11, Twitter is rejecting new API access for applications used to POSSE/backfeed on the grounds that they may violate twitter’s rules and/or policies — Barnaby Walters&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Supports very complete web action endpoints, so semi-manual posting is easy to implement &lt;list rend="ul"&gt;&lt;item&gt;What are these endpoints? Is this still the case in 2022? — Barnaby Walters&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See POSSE to Twitter for details on how to POSSE both notes and articles (blog posts) to Twitter.&lt;/p&gt;
    &lt;p&gt;There are two options for POSSEing to Facebook currently:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Manually crosspost&lt;/item&gt;
      &lt;item&gt;Semi-automatically with the Bridgy browser extension for Facebook&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Medium&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You can create posts via the posts API&lt;/item&gt;
      &lt;item&gt;Medium also supports manual POSSE via the Import Post function, which preserves rel-canonical links to the original URL&lt;/item&gt;
      &lt;item&gt;Shane Becker and Ben Werdmüller manually POSSE to Medium&lt;/item&gt;
      &lt;item&gt;Chris Aldrich uses the WordPress Medium Plugin to POSSE to Medium. They also support bulk migration (aka mass POSSE) for porting across lots of posts after which posts can be POSSEd by means of their plugin.&lt;/item&gt;
      &lt;item&gt;Aaron Gustafson Wrote a Jekyll plugin to POSSE to Medium.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;WordPress&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;How does veganstraightedge.com do it? (all his articles are manually POSSEd to WordPress.com)&lt;/item&gt;
      &lt;item&gt;Chris Aldrich uses a WordPress plugin WordPress Crosspost to POSSE from a self-hosted WordPress install to WordPress.com.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Plain Text Notes&lt;/head&gt;
    &lt;p&gt;Some destinations (e.g. SMS or push notifications) may require a pure plain text representation.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;h-entry_to_text is a method of generating a plain text representation from an arbitrary h-entry&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Software&lt;/head&gt;
    &lt;p&gt;Software and libraries to implement POSSE:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PHP &lt;list rend="ul"&gt;&lt;item&gt;The POSSE namespace in php-helpers (might be moved to a separate package) contains various truncation, preparation and syndication functions including HTML =&amp;gt; plaintext µblog syntax converter&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Python &lt;list rend="ul"&gt;&lt;item&gt;SiloRider is a command-line tool, implemented in Python, that lets you implement POSSE to various services (Twitter and Mastodon as of 2018-08-01).&lt;/item&gt;&lt;item&gt;Feed2Toot is another command-line python tool that parses any number of RSS feeds and posts their content on ActivityPub based services (tested with: Mastodon, Pleroma). Contains some neat bells and whistles like advanced post filtering, numerous options for feed parsing and toot formatting.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Docker &lt;list rend="ul"&gt;&lt;item&gt;POSSE Party: self-hosted software for POSSE&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Services&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Bridgy Publish is POSSE-as-a-service. It supports Twitter, Flickr, GitHub and Mastodon. You can use it interactively or programmatically via webmention.&lt;/item&gt;
      &lt;item&gt;Mugged Tweets - will POSSE a note to a mug (may require first POSSEing to Twitter)&lt;/item&gt;
      &lt;item&gt;IFTTT allows automatically reposting content with an RSS or Atom feed to a number of silos incuding Twitter, Tumblr, and Facebook&lt;/item&gt;
      &lt;item&gt;EchoFeed&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Publishing Flows&lt;/head&gt;
    &lt;p&gt;There's at least two ways to implement a POSSE content posting flow:&lt;/p&gt;
    &lt;head rend="h5"&gt;Client to site to silo&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The user writes a piece of content using a publishing client &lt;list rend="ul"&gt;&lt;item&gt;Optional: client provides UI for selecting which 3rd party services to push to if it knows about them, with optional customizations for per service&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Having finished the content, the user publishes content to their server (optionally: with metadata of which 3rd party services and any customizations thereof) &lt;list rend="ul"&gt;&lt;item&gt;Optional: client can generate a permalink knowing the state of the server, and publish to that permalink&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;The server publishes the content, generates a permalink and summary (and/or customized content suited to 3rd party services) if necessary&lt;/item&gt;
      &lt;item&gt;The server posts copies with permalinks to 3rd party services&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Advantages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;User only has to interact with one site over the internet, their own&lt;/item&gt;
      &lt;item&gt;Syndication can be done fully automatically by the server&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Disadvantages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;any?&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h5"&gt;Client to site and silo&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The user writes a piece of content using a publishing client&lt;/item&gt;
      &lt;item&gt;Having finished the content, the user publishes it to their server&lt;/item&gt;
      &lt;item&gt;The client queries the server for the URL of the content it just pushed&lt;/item&gt;
      &lt;item&gt;The publishing client presents the user with an interface for selecting: &lt;list rend="ul"&gt;&lt;item&gt;Which 3rd party services to publish to&lt;/item&gt;&lt;item&gt;The exact content published to the services, pre-filled with a summary based on the produced content&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;The user selects the services and submits the form&lt;/item&gt;
      &lt;item&gt;The publishing client posts the content summaries out to the 3rd party services&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Advantages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;More user control over timing and editing of copies of content to 3rd party services&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Disadvantages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Syndication requires a manual step each time&lt;/item&gt;
      &lt;item&gt;Dependent on client connectivity directly to 3rd party services (problematic in flakey mobile situations, or when client is publishing using domain-censored internet access).&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;IndieWeb Examples&lt;/head&gt;
    &lt;p&gt;The following IndieWebCamp participants' sites support a POSSE architecture. If you have an implementation, add it, make screenshots or a screencast or blog about it and post the details/link here. In date order (earliest first) :&lt;/p&gt;
    &lt;head rend="h3"&gt;Tantek&lt;/head&gt;
    &lt;p&gt;Tantek.com as of 2010-01-01[1] (2010-01-26 Twitter syndication started[2] and caught up[3][4]). Tantek Çelik implemented POSSE in Falcon on tantek.com.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;all self-hosted posts are openly with PuSH v0.4 + h-feed and Atom real-time syndicated with a PubsubHubbub hub to StatusNet, other subscribers etc. (also to Google Buzz til it shutdown)&lt;/item&gt;
      &lt;item&gt;note (and article titles), reply, RSVP posts are snowflake copied by the personal site server to Twitter with permashortlink citation links/references (see Whistle for details) back to the original. Copies of notes to Twitter are also automatically recopied from there to Facebook.&lt;/item&gt;
      &lt;item&gt;likes of tweets are "copied" (more like propagated) to Twitter using Bridgy publish&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Barnaby Walters&lt;/head&gt;
    &lt;p&gt;Waterpigs.co.uk as of 2012-03-12. Barnaby Walters implemented POSSE over at waterpigs.co.uk&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;as of 2012-09-25 all collections (notes, articles, activity) are PuSH-subscribable feeds.&lt;/item&gt;
      &lt;item&gt;Using the Client to Server to 3rd Parties flow --Waterpigs.co.uk 06:08, 25 September 2012 (PDT)&lt;/item&gt;
      &lt;item&gt;Syndicating to Twitter + Facebook&lt;/item&gt;
      &lt;item&gt;As of 2014-06-19 Taproot can now optionally post additional POSSE tweets when updating a note or article — example of updated note and POSSE tweet for the update. Note that Bridgy successfully backfeeds silo interactions from the update tweet as well as the original POSSE tweet&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Brennan Novak&lt;/head&gt;
    &lt;p&gt;brennannovak.com as of 2012-07-01[5][6]. Brennan Novak implemented POSSE on his site brennannovak.com with copies posted to Twitter and Facebook&lt;/p&gt;
    &lt;head rend="h3"&gt;Aaron Parecki&lt;/head&gt;
    &lt;p&gt;aaronparecki.com as of 2012-08-19[7][8]. Aaron Parecki implemented POSSE on his site aaronparecki.com with copies posted to Twitter containing permashortlinks back to originals on his own site.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;as of 2012-08-19 all collections (notes, articles, replies) are PuSH-subscribable feeds.&lt;/item&gt;
      &lt;item&gt;Posting UI as of 2012-09-09: http://aaronparecki.com/2012/253/note/3&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Sandeep Shetty&lt;/head&gt;
    &lt;p&gt;User:Sandeep.io First post POSSE'd on 2012-11-05. I primarily syndicate to Twitter using a very lo-fi solution of adding silo (Facebook, Twiiter, Google+) provided share links to each post that I can manually click to prefill content, edit and post. I've avoided API integration because of the extensive experience I've had using Facebook API and dealing with it's random changes. "Integration" has high costs sometimes so I keep it as simple as possible.&lt;/p&gt;
    &lt;head rend="h3"&gt;Ben Werdmuller&lt;/head&gt;
    &lt;p&gt;werd.io as of 2013-05-31 [9]. Ben Werdmuller implemented POSSE in his idno platform via plugins. New content has an associated Activity Streams object type; POSSE plugins listen for post events associated with those object types and syndicate appropriately.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Notes and articles are syndicated to Twitter and Facebook&lt;/item&gt;
      &lt;item&gt;Images are syndicated to Facebook, Flickr and Twitter&lt;/item&gt;
      &lt;item&gt;Places are syndicated to Foursquare&lt;/item&gt;
      &lt;item&gt;More plugins are very easily possible; the Foursquare plugin took about an hour to build&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Shane Becker&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Shane Becker using Dark Matter on veganstraightedge.com (since 2013-07-17[10]) with automatic rel-syndication markup on manual POSSEing:&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Glenn Jones&lt;/head&gt;
    &lt;p&gt;glennjones.net as of 2014-01-14 Glenn Jones The blog implemented POSSE using a new version of transmat.io system. New content added to transmat is associated with objects types. A POSSE twitter plugins listens for post events syndicating content. At moment only notes are syndicated.&lt;/p&gt;
    &lt;head rend="h3"&gt;Jeremy Keith&lt;/head&gt;
    &lt;p&gt;adactio.com as of 2014-05-27 Jeremy Keith has implemented POSSE using his own custom CMS.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Notes have been POSSEd since he first started posting them on his own site, on 2014-05-27 (Note POSSE copy may say 2014-05-26 presumably because of timezone differences, Jeremy's is in BST, while a PDT viewer sees datetime adjusted accordingly). See also related blog post 2014-06-01.&lt;/item&gt;
      &lt;item&gt;Photos have been POSSEd to Twitter since he first started posting them on his own site on 2014-07-05 and to Flickr since 2014-07-08. Examples: &lt;list rend="ul"&gt;&lt;item&gt;http://adactio.com/notes/6978/&lt;/item&gt;&lt;item&gt;http://adactio.com/notes/7021 - first photo POSSEd to both Twitter and Flickr:&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Shane Hudson&lt;/head&gt;
    &lt;p&gt;shanehudson.net as of 2014-09-19 Shane Hudson has implemented POSSE to Twitter for Craft CMS.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Previously working on Wordpress but he was not keen on the UX.&lt;/item&gt;
      &lt;item&gt;Has reply contexts working but has to manually copy the ID.&lt;/item&gt;
      &lt;item&gt;Not yet POSSEing photos but plans to.&lt;/item&gt;
      &lt;item&gt;Currently he has to manually copy the tweet from the main text box to a 140 character limit tweet text box. He plans to make that automatic.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p/&gt;
    &lt;head rend="h3"&gt;Ravi Sagar&lt;/head&gt;
    &lt;p&gt;http://www.ravisagar.in/blog/implementing-posse-my-site Implementing POSSE on my site as of 2018-02-21.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The new blogs and notes are posted on Drupal&lt;/item&gt;
      &lt;item&gt;http://www.ravisagar.in/rss-social.xml RSS Feed is generated for the blogs and notes tagged with "Share" keyword&lt;/item&gt;
      &lt;item&gt;Using Rebrandly to create shortlinks for the RSS Feed&lt;/item&gt;
      &lt;item&gt;Using Zapier to share the newly created rebrandly links to Twitter and Linkedin&lt;/item&gt;
    &lt;/list&gt;
    &lt;p/&gt;
    &lt;head rend="h3"&gt;Ludovic Chabant&lt;/head&gt;
    &lt;p&gt;ludovic.chabant.com as of 2018-07-30 Ludovic Chabant has implement POSSE to Twitter and Mastodon from PieCrust CMS, using SiloRider&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;SiloRider is CMS independent -- it only relies on Microformats found in the published markup.&lt;/item&gt;
      &lt;item&gt;New articles are posted as title and link.&lt;/item&gt;
      &lt;item&gt;New microblogging updates are mostly copied verbatim (if the fit the external service's character limits), and support photo posts, including multi-photo posts.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p/&gt;
    &lt;head rend="h3"&gt;Adam Dawkins&lt;/head&gt;
    &lt;p&gt;adamdawkins.uk as of 2019-01-16 Adam Dawkins has implemented POSSE using his own custom CMS.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Notes have been POSSEd since he first started posting them on his own site, on 2019-01-16&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Examples&lt;/head&gt;
    &lt;head rend="h3"&gt;Shaun Ewing&lt;/head&gt;
    &lt;p&gt;shaun.net as of 2020-01-16 Shaun Ewing has implemented POSSE using Jekyll, and custom APIs.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;More information https://shaun.net/notes/taking-back-control-of-my-content/&lt;/item&gt;
      &lt;item&gt;Syndication is still manual, and I'm still working on Level 3/4 "IndieMark" items such as WebMentions, etc.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;capjamesg&lt;/head&gt;
    &lt;p&gt;capjamesg has been syndicating his notes from his own site to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Twitter using brid.gy&lt;/item&gt;
      &lt;item&gt;micro.blog using micro.blog's feed polling system&lt;/item&gt;
      &lt;item&gt;The fediverse using fed.brid.gy&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This syndication happens automatically whenever James posts a note using his Micropub client or his Microsub feed reader.&lt;/p&gt;
    &lt;head rend="h3"&gt;... add more here ...&lt;/head&gt;
    &lt;p&gt;... Add a link to your POSSE–enabled site and the date you started syndicating copies of your content out to 3rd party social sharing/publishing services.&lt;/p&gt;
    &lt;head rend="h3"&gt;Partial POSSE sites&lt;/head&gt;
    &lt;p&gt;Sites which only POSSE some of their content, and still post directly to the same silo they POSSE to.&lt;/p&gt;
    &lt;p&gt;Other partial POSSE sites:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;User:Hupili.net implements a partial POSSE with the following setups: &lt;list rend="ul"&gt;&lt;item&gt;SNSAPI is a lightweight middleware to unify the data structure and interfaces of different social networking services. It gives the scripting flexibility for developer users to manipulate social silos.&lt;/item&gt;&lt;item&gt;SNSRouter is a web UI built upon SNSAPI where one can read an aggregated timeline from different sites, mass forward messages, and update statuses on all channels.&lt;/item&gt;&lt;item&gt;As is said in one of the description paragraph above, this model is not truly POSSE. One can not (hardly) distinguish original/ syndicated status. I'm planning to put a page with permlink on my site upon each status update and then use SNSAPI to syndicate to other silos.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Other Approaches&lt;/head&gt;
    &lt;head rend="h3"&gt;COPE&lt;/head&gt;
    &lt;p&gt;COPE is short for Create Once, Publish Everywhere (COPE), which explicitly lacks a first "Publish Once" step, and thus is more about duplicating the content across various destinations.&lt;/p&gt;
    &lt;p&gt;Without a first "Publish Once" step on a site you "Own", and thus lacking original post permalinks, the COPE strategy fails to actually draw people to any one canonical place to read/view your stuff, and thus all it does is grow (likely) disjoint audiences across other people’s sites.&lt;/p&gt;
    &lt;p&gt;Articles:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2009-10-13 COPE: Create Once, Publish Everywhere by Daniel Jacobson, Director of Application Development for NPR. (Original https://www.programmableweb.com/news/cope-create-once-publish-everywhere/2009/10/13 offline due to site-death of programmableweb.com in 2022)&lt;/item&gt;
      &lt;item&gt;2019-10-28 Create Once, Publish Everywhere With WordPress by Leonardo Losovitz in Smashing Magazine&lt;/item&gt;
      &lt;item&gt;2019 WordCamp Taipei talk: Create Once, Publish Everywhere video on WordPress.tv&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;POSE&lt;/head&gt;
    &lt;p&gt;POSE, Publish Once Syndicate Everywhere, was a broader predecessor of POSSE that also included publishing once on one particular silo, and then syndicating out to other silos.&lt;/p&gt;
    &lt;head rend="h3"&gt;PESOS&lt;/head&gt;
    &lt;p&gt;A similar but opposite approach is PESOS where content is posted first to 3rd party services and then copied/syndicated into a personal site.&lt;/p&gt;
    &lt;p&gt;If exact copies of content are posted on both a personal site and 3rd party services, there's no way to tell (short of comparing possibly non-existent sub-second accurate published dates) whether a site is using POSSE or PESOS. Sites can provably support POSSE by including perma(short)links in syndicated copies that link/reference back to published originals.&lt;/p&gt;
    &lt;head rend="h3"&gt;PESETAS&lt;/head&gt;
    &lt;p&gt;PESETAS is like PESOS but copying/syndicating everything to a particular silo (without any involvement of a personal site).&lt;/p&gt;
    &lt;p&gt;For example, most silos support cross-posting to Twitter, thus you could connect everything to your Twitter account and always (auto-)cross-post there to keep a copy.&lt;/p&gt;
    &lt;p&gt;E.g. Tumblr has a UI for cross-posting to Twitter. See Webapps StackExchange post for documentation and screenshots of UI.&lt;/p&gt;
    &lt;p&gt;Tumblr is a better PESETAS destination however, since it is well established, allows for a wider variety of content, and allows more text, and links to URLs directly instead of linkwrapping them like Twitter does.&lt;/p&gt;
    &lt;p/&gt;
    &lt;head rend="h2"&gt;Brainstorming&lt;/head&gt;
    &lt;head rend="h3"&gt;CRUD&lt;/head&gt;
    &lt;p&gt;All of the above, and to date (2013-222), POSSE has solely described syndicating the Creation of content on your site (publishing) to other sites. This model has been quite successful and perhaps may be sufficient.&lt;/p&gt;
    &lt;p&gt;However, it is worth exploring the potential utility of a full CRUD protocol for POSSE.&lt;/p&gt;
    &lt;head rend="h3"&gt;Create&lt;/head&gt;
    &lt;p&gt;Create is the POSSE default. You create content on your site, you POSSE your creates to other sites. All of this is described above, and in silo-specific details on silo pages.&lt;/p&gt;
    &lt;head rend="h3"&gt;Read&lt;/head&gt;
    &lt;p&gt;Read as a verb is interesting when applied to POSSE.&lt;/p&gt;
    &lt;p&gt;At a minimum, it's useful to implement storing links to syndicated copies of your content to provide for the future possibility of reading from downstream POSSE copies.&lt;/p&gt;
    &lt;p&gt;See:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;u-syndication for how to markup links to syndicated copies of your content&lt;/item&gt;
      &lt;item&gt;syndication-link-use-cases for why to do so&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Actual direct uses of Reading from downstream POSSE copies:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;reverse-syndication / backfeed of activity around the POSSE copy onto your original:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In addition, keeping a u-syndication link to the POSSE copy enables deleting it to perform an Update or a Delete action, as described in the following sections.&lt;/p&gt;
    &lt;head rend="h3"&gt;Update&lt;/head&gt;
    &lt;p&gt;If a POSSE destination allows updates/edits, then when you edit your post, you could propagate that update to the downstream POSSE copy as well.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;E.g. Facebook allows editing the text of a post (including any links in the text), person tags, but not the image of a photo post&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If the destination disallows updates/edits, like Twitter, it is still possible to virtually POSSE updates by deleting the POSSE tweet and reposting, i.e.:&lt;/p&gt;
    &lt;p&gt;Consider only POSSEing updates to Twitter:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;if no one has replied to it yet (otherwise you'd break a threaded conversation on Twitter)&lt;/item&gt;
      &lt;item&gt;if your changes would be shown in the truncated copy on Twitter (i.e. if your changes are past the 140 (more like 120) character horizon, no point in churning the Twitter copy).&lt;/item&gt;
      &lt;item&gt;within a very short time window, maybe like 2-5 minutes, because otherwise the update will be seen as a duplicate to people who are reading you on Twitter.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All of these concerns are regarding the experience that you provide to your friends reading your tweets on Twitter, which of course should be the whole (design) reason you're bothering to POSSE to Twitter in the first place.&lt;/p&gt;
    &lt;p&gt;For details, see silo-specific POSSE sections:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Facebook: POSSE to Facebook (to-do: needs details re: edit text ok, but no photo editing, photo posts need delete/repost to simulate POSSE update)&lt;/item&gt;
      &lt;item&gt;Flickr: (UI supports manually updating the image of a photo post, but is that available in the API? and if so, file a Bridgy Publish feature request GitHub issue to support POSSE Update to Flickr (including the image of a photo post)&lt;/item&gt;
      &lt;item&gt;Twitter: POSSE to Twitter (to-do: copy the above delete/repost strategy to there)&lt;/item&gt;
      &lt;item&gt;...&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Delete&lt;/head&gt;
    &lt;p&gt;Deletes seem fairly straightforward to POSSE, especially to services which themselves propagate deletes to clients.&lt;/p&gt;
    &lt;p&gt;E.g. one can delete a note on Twitter at any point.&lt;/p&gt;
    &lt;p&gt;Similar to updates, consider:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;if there are already replies to a POSSE copy (or activity like favorites/retweets), consider keeping it to keep conversation threading (and others' favorites/retweets).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;However, if you really feel like deleting the content from your site and POSSE copies (e.g. on Twitter), go ahead and do so.&lt;/p&gt;
    &lt;p&gt;Perhaps this is an opportunity for the UI for the deletion of a post to check to see if there's been any activity (replies, favorites, retweets) on the POSSE copy before performing the delete. One possible implementation could involve the UI informing the user of this activity (or lack of it) and reconfirming the delete request on a per-service basis.&lt;/p&gt;
    &lt;p/&gt;
    &lt;head rend="h4"&gt;IndieWeb Examples&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Grant Richmond supports POSSE deletes on twitter as of 2018-10-10, by checking if a post on his site has been unpublished / deleted and sending the appropriate api request for likes, reposts and notes.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;FAQ&lt;/head&gt;
    &lt;head rend="h3"&gt;Worry about search engines and duplicates&lt;/head&gt;
    &lt;p&gt;Q: Do we need to worry about search engines penalizing apparently duplicate posts?&lt;/p&gt;
    &lt;p&gt;A: That's why the POSSE copies SHOULD always link back to the originals. So that search engines can infer that the copies are just copies. Ideally POSSE copies on silos should use rel-canonical to link back to the originals, but even without explicit rel-canonical, the explicit link back to the original is a strong hint that it is an original.&lt;/p&gt;
    &lt;p&gt;This is also an advantage of POSSE over PESOS. With PESOS - there's no way to tell what's the original and what's the copy - so they do look like duplicates.&lt;/p&gt;
    &lt;head rend="h3"&gt;POSSE-post-discovery and backlinks&lt;/head&gt;
    &lt;p&gt;Q: Brid.gy can use posse-post-discovery to find the relationship between a syndicated post and the original when there is not explicit link. Does this mean I should stop adding backlinks to syndicated copies?&lt;/p&gt;
    &lt;p&gt;A: POSSEing without a backlink is considered a last resort, and has some costs associated with it. See posse-post-discovery#Tradeoffs for more details.&lt;/p&gt;
    &lt;head rend="h3"&gt;POSSE or Send Webmentions First&lt;/head&gt;
    &lt;p&gt;In short, POSSE first, then send webmentions.&lt;/p&gt;
    &lt;p&gt;See: Webmention FAQ: POSSE or Send Webmentions First for details and reasoning.&lt;/p&gt;
    &lt;head rend="h2"&gt;Background&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2010-05-26 POSSE first described online as a concept in Tantek Celik on DiSo 2.0: Down to Brass Tacks(archived monkinetic original) : &lt;p&gt;Publish on your own site, own your URLs, your permalinks, and&lt;/p&gt;&lt;lb/&gt;Syndicate out to other sites. Your text updates to Twitter, your checkins to Foursquare, your photos to Flickr etc.&lt;/item&gt;
      &lt;item&gt;2010-10-06 POSSE+backfeed conceptual architecture (predating the terms) &lt;lb/&gt;Note the arrows to/from the "Personal site" in the middle. Arrows outward are conceptually illustrating POSSE, while those returning, backfeed.&lt;lb/&gt;See 2011-01-10 post relating/expanding on it: On Owning Your Data: Follow-up to @Zeldman and the #indieweb&lt;/item&gt;
      &lt;item&gt;2011-06-25 IndieWebCamp 2011 session: "Publish Then Syndicate and Replicate" further explored POSSE conceptually.&lt;/item&gt;
      &lt;item&gt;2012-06-21 POSSE term defined: http://tantek.com/2012/173/t1/posse-core-indieweb-approach&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Related conceptually:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;sometime before 2014-06-21[11]: POSE (Publish Once Syndicate Everywhere) term defined at some point prior to POSSE. Conceptually it was looser than POSSE, as "once" could be interpreted as on a silo rather than your "own site", which POSSE (and the conceptual predecessors) made explicit.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Articles&lt;/head&gt;
    &lt;p&gt;Articles and blog posts about POSSE, especially implementing it:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Hipster :&lt;/item&gt;
      &lt;item&gt;An audience/context-conscious POSSE syndication plugin for WordPress&lt;/item&gt;
      &lt;item&gt; Ars Technica) How Google’s AMP project speeds up the Web—by sandblasting HTML (&lt;p&gt;[…] this nudges publishers toward an idea that's big in the IndieWeb movement: Publish (on your) Own Site, Syndicate Elsewhere (or POSSE for short).&lt;/p&gt;&lt;p&gt;The idea is to own the canonical copy of the content on your own site but then to send that content everywhere you can. Or rather, everywhere you want to reach your readers. Facebook Instant Article? Sure, hook up the RSS feed. Apple News? Send the feed over there, too. AMP? Sure, generate an AMP page. No need to stop there—tap the new Medium API and half a dozen others as well.&lt;/p&gt;&lt;p&gt;Reading is a fragmented experience. Some people will love reading on the Web, some via RSS in their favorite reader, some in Facebook Instant Articles, some via AMP pages on Twitter, some via Lynx in their terminal running on a restored TRS-80 (seriously, it can be done. See below). The beauty of the POSSE approach is that you can reach them all from a single, canonical source.&lt;/p&gt;&lt;p&gt;[…]&lt;/p&gt;&lt;p&gt;For the Web's sake, let's hope Google sticks with AMP long enough to convince publishers that the real future is speeding up their own pages and embracing a POSSE-style approach.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;2018-07-31 : Stepping back from POSSE (archived)&lt;/item&gt;
      &lt;item&gt;2023-10-23 : The poster’s guide to the internet of the future (archived) &lt;list rend="ul"&gt;&lt;item&gt;Mentions POSSE by name, micro.blog, Bridgy, and links to this page&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;2024-09-27 : POSSE: Reclaiming social media in a fragmented world&lt;/item&gt;
      &lt;item&gt;...&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;POSSE as methodology for non-web scenarios&lt;/head&gt;
    &lt;head rend="h3"&gt;POSSE git repositories&lt;/head&gt;
    &lt;p&gt;As discussed #indieweb it is also possible POSSE your git repositories to git "silos", such as GitHub or GitLab. An easy way of doing this was described by Christian Weiske at [12].&lt;/p&gt;
    &lt;p/&gt;
    &lt;head rend="h2"&gt;Sessions&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2011: Publish Then Syndicate and Replicate&lt;/item&gt;
      &lt;item&gt;2013/Secure Cross-Posting&lt;/item&gt;
      &lt;item&gt;2014/SF/possepatterns&lt;/item&gt;
      &lt;item&gt;2016/Brighton/howposse&lt;/item&gt;
      &lt;item&gt;2016/StaticPOSSE&lt;/item&gt;
      &lt;item&gt;2016/Dusseldorf/syndication&lt;/item&gt;
      &lt;item&gt;2017/Berlin/possepesos&lt;/item&gt;
      &lt;item&gt;2019/Amsterdam/syndication&lt;/item&gt;
      &lt;item&gt;2019/NYC/syndication&lt;/item&gt;
      &lt;item&gt;2019/Düsseldorf/syndicate&lt;/item&gt;
      &lt;item&gt;2024/Brighton/posse&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;See Also&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;POSSE reply&lt;/item&gt;
      &lt;item&gt;PESOS&lt;/item&gt;
      &lt;item&gt;PESETAS&lt;/item&gt;
      &lt;item&gt;why&lt;/item&gt;
      &lt;item&gt;original post link&lt;/item&gt;
      &lt;item&gt;microsyntax for POSSEing to plain text destinations&lt;/item&gt;
      &lt;item&gt;rel-canonical&lt;/item&gt;
      &lt;item&gt;Documentation on syndication formats&lt;/item&gt;
      &lt;item&gt;posts-elsewhere&lt;/item&gt;
      &lt;item&gt;2017-11-09 Nicolas Hoizey: Medium is only an edge server of your POSSE CDN, your own blog is the origin&lt;/item&gt;
      &lt;item&gt;2018-03-24 Hacker News comment thread: https://news.ycombinator.com/item?id=16663850&lt;/item&gt;
      &lt;item&gt;HN ibid: "Why won't a link on these platforms suffice since they have their "cards"?"&lt;/item&gt;
      &lt;item&gt;HN ibid: "This is an interesting thing, but too complicated and over-broad for the mere-mortal." &amp;lt;-- page introduction needs simplifying, simpler instructions to setup POSSE, acknowledge where POSSE usability is in the Generations spectrum&lt;/item&gt;
      &lt;item&gt;HN ibid: "Facebook is just a glorified RSS feed with centralized discover ability." &amp;lt;-- debunk with comparing Facebook#Features (and Twitter#Features) vs RSS plumbing feature set. A visual diagram/table comparison might help.&lt;/item&gt;
      &lt;item&gt;HN ibid: "This really is not possible with RSS at all, especially since the silos don’t want to support RSS in any meaningful way." &amp;lt;-- perhaps add a whole subsection in "Why" explaining why RSS is insufficient compared to POSSE.&lt;/item&gt;
      &lt;item&gt;2021-11-07 Hacker News comment thread: https://news.ycombinator.com/item?id=29115696&lt;/item&gt;
      &lt;item&gt;Recommend non-realtime POSSE to Twitter and other social media due to their active use as part of the surveillance apparatus of local and national law enforcement: https://theintercept.com/2020/07/09/twitter-dataminr-police-spy-surveillance-black-lives-matter-protests/&lt;/item&gt;
      &lt;item&gt;Jetpack 8.9 adds Social Previews which allows one to preview how your posts will appear on Facebook, Twitter, and Google search results before you hit the publish button!&lt;/item&gt;
      &lt;item&gt;Consider a deliberate ethical use of POSSEing, e.g. see Code of Ethics for an example set of explicit self-stated “Rules of engagement”&lt;/item&gt;
      &lt;item&gt;“Pluralistic is my mutli-channel publishing effort – a project to push the limits of POSSE (post own site, share everywhere)” Pluralistic: 05 May 2021&lt;/item&gt;
      &lt;item&gt;Cory Doctorow explains how he uses POSSE. This Week in Google (time offset 474s): https://www.youtube.com/watch?v=qyU2cZLFsik&amp;amp;t=474s &lt;p&gt;I try not to get locked into anyone else’s walled garden. I … pursue this publishing strategy they call POSSE, post own site syndicate everywhere …&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;articles: 2018-02-06 Dries Buytaert To PESOS or to POSSE? and 2018-02-16 Dries Buytaert My POSSE plan for evolving my site&lt;/item&gt;
      &lt;item&gt;https://twitter.com/SaraSoueidan/status/1539870410317221888 &lt;list rend="ul"&gt;&lt;item&gt;"What Matthias said.&lt;lb/&gt;Write on your own blogs, syndicate elsewhere.&lt;lb/&gt;Own your content! There's nothing like it." @SaraSoueidan June 23, 2022&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;"What Matthias said.&lt;/item&gt;
      &lt;item&gt;Brainstorm: Tantek Çelik: POSSE advantages are largely distribution (immediately) and discovery (over time). if neither of those two are happening, then it's not worth keeping it around. Date-time-proof-of-posting can be solved by sending your original post (or a POSSE/tweet copy) to the Internet Archive and does not require keeping the POSSE/tweet copy.&lt;/item&gt;
      &lt;item&gt;https://andy-bell.co.uk/how-im-dealing-with-twitter-in-a-hands-off-manner/&lt;/item&gt;
      &lt;item&gt;Why: 2023-07-13 Jeremy Keith: The syndicate &lt;p&gt;We’ll see how long it lasts. We’ll see how long any of them last. Today’s social media darlings are tomorrow’s Friendster and MySpace.&lt;/p&gt;&lt;p&gt;When the current crop of services wither and die, my own website will still remain in full bloom.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;https://mastodon.social/@davidpierce/111284796654263440 &lt;list rend="ul"&gt;&lt;item&gt;"For the last six months or so I've been obsessed with POSSE, a decade-old idea about how to mix the best of blogging and social media. For a story and for The Vergecast, I tried to figure out how POSSE could work — and why it might not https://www.theverge.com/2023/10/23/23928550/posse-posting-activitypub-standard-twitter-tumblr-mastodon" @davidpierce October 23, 2023&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;to-do: draw an updated diagram without Twitter (replace with Bluesky), and to Fediverse via BridgyFed with a line that ends in "Y" with 📤 📥 on the ends&lt;/item&gt;
      &lt;item&gt;update any references / instructions to POSSE to Twitter to note historical importance and current lack of automated support&lt;/item&gt;
      &lt;item&gt;to-do: add a http://micro.blog section to the "How to" section; make sure to link to micro.blog&lt;/item&gt;
      &lt;item&gt;Why: 2024-02-24 Pluralistic: Vice surrenders &lt;p&gt;This is the moment for POSSE (Post Own Site, Share Everywhere), a strategy that sees social media as a strategy for bringing readers to channels that you control&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;Curation is the last best hope of intelligent discourse.&lt;/item&gt;
      &lt;item&gt;https://hachyderm.io/@pluralistic@mamot.fr/111987590552793552&lt;/item&gt;
      &lt;item&gt;^ actual permalink: https://mamot.fr/@pluralistic/111987590098901216 &lt;list rend="ul"&gt;&lt;item&gt;"If there was ever a moment when the obvious, catastrophic, imminent risk of trusting Big Tech intermediaries to sit between you and your customers or audience, it was now. This is *not* the moment to be "social first." This is the moment for POSSE (Post Own Site, Share Everywhere), a strategy that sees social media as a strategy for bringing readers to channels that *you* control:https://pluralistic.net/2022/02/19/now-we-are-two/#two-much-posse14/" @pluralistic February 24, 2024&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;2024-03-09 Molly White: POSSE &lt;p&gt;I just finally deployed something I've been working on for a few weeks now: a feed of my writing, posting, reading, and other various activity that lives on my website at https://www.mollywhite.net/feed&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;Why: to have another way to search your stuff, since sometimes (often? usually now?) large web web search engines like Google or even DDG are very poor at site-specific searching (e.g. site:http://tantek.com), whereas social media silos like Twitter are very good at profile-specific searches (e.g. from:t).&lt;/item&gt;
      &lt;item&gt;IndieWeb Example: 2024-03-09 Molly White deployed automatic POSSE to Twitter/Mastodon/Bluesky: POSSE&lt;/item&gt;
      &lt;item&gt;https://mastodon.social/@flokosiol/112438679946887082 &lt;quote/&gt;with embedded photo of Laura presenting a text slide on a stage:&lt;p&gt;"Starting day 2 of #btconf with Laura Kalbag and some #indieweb vibes." @flokosiol May 14, 2024&lt;/p&gt;&lt;quote/&gt;— a rephrasing of POSSE.&lt;p&gt;Social media etiquette:&lt;/p&gt;&lt;p&gt;Post to your own site first, then mirror those posts to third-party platforms.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;2024-09-27 Molly White: POSSE: Reclaiming social media in a fragmented world&lt;/item&gt;
      &lt;item&gt;don't POSSE to X, says Richard MacManus https://cybercultural.com/p/web-values/&lt;/item&gt;
      &lt;item&gt;Molly White talks POSSE and more at SXSW 2025 2025-03-09&lt;/item&gt;
      &lt;item&gt;https://changelog.com/friends/85#t=6099&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46468600</guid><pubDate>Fri, 02 Jan 2026 19:48:25 +0000</pubDate></item><item><title>Daft Punk Easter Egg in the BPM Tempo of Harder, Better, Faster, Stronger?</title><link>https://www.madebywindmill.com/tempi/blog/hbfs-bpm/</link><description>&lt;doc fingerprint="e65c8135899088b4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Was Daft Punk Having a Laugh When They Chose the Tempo of Harder, Better, Faster, Stronger?&lt;/head&gt;
    &lt;p&gt;Google "harder better faster stronger bpm" and Google’s “AI Overview” will tell you:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Daft Punk’s “Harder, Better, Faster, Stronger” generally sits around 123 BPM (Beats Per Minute), though some analyses find it slightly higher (like 123.48 BPM) or list different BPMs in remixes/workouts, with exact figures varying slightly by source and version.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Spotify’s metadata database, SongBPM, and most other online BPM databases list it at exactly 123.&lt;/p&gt;
    &lt;p&gt;But I think our helmet-clad robot friends might have been making a little joke that we’ve apparently all missed. The BPM of Harder, Better, Faster, Stronger is actually 123.45.&lt;/p&gt;
    &lt;p&gt;How do I know this? It so happens that for over 10 years I’ve written an app called Tempi that shows the music BPM in real time, so I know a little bit about the science and algorithms behind music tempo detection.&lt;/p&gt;
    &lt;p&gt;Most tempo detection software works basically the same way:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A specialized algorithm called the Fast Fourier Transform (FFT) collects overlapping energy levels at different frequency bands.&lt;/item&gt;
      &lt;item&gt;Those levels are refined into well-defined peaks that represent rhythmic events in the track.&lt;/item&gt;
      &lt;item&gt;Another algorithm (autocorrelation) looks for patterns, or more accurately periodicity, in those peaks.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But these patterns are tricky because there’s all kinds of noise, performance inaccuracies, and rhythmic harmonics throwing things off. All that is to say, a) it’s complicated and b) it’s not perfectly accurate.&lt;/p&gt;
    &lt;p&gt;When I make changes to my own system of course I need some way to know if it’s getting better or worse, so I have a test library of hundreds of song snippets that I score it against. One of these songs is Daft Punk’s HBFS, and early on I noticed something strange about that track.&lt;/p&gt;
    &lt;p&gt;Almost all electronic music is synced to a sequencer and so obviously is going to have a very steady tempo. But while the vast majority of electronic music tracks I test have an “integral” tempo – meaning their tempo is exactly some round number like 95, and not a fraction like 95.2 – my software always finds the BPM of HBFS to be somewhere between 123 and 124, but not exactly either. For years I’ve chalked this up to inconsistencies with my system and didn’t think much of it. But lately I’ve made improvements to the system so that it’s much more accurate and it now tells me the BPM of HBFS is 123.4.&lt;/p&gt;
    &lt;p&gt;And that got me thinking, “Hmm. Did these guys pick that tempo because they have a sense of humor? And if so, how far would they take it?”&lt;/p&gt;
    &lt;p&gt;To get to the bottom of this I needed to establish what the BPM of HBFS really is.&lt;/p&gt;
    &lt;head rend="h3"&gt;And that’s actually pretty easy to do…&lt;/head&gt;
    &lt;p&gt;Here’s a Venn diagram showing the overlap between human and computer capabilities in the digital realm:&lt;/p&gt;
    &lt;p&gt;Computers can do almost all “computer-y” things (i.e. things that can be entirely done on a computer) MUCH better, faster, (and stronger?) than humans. But for the time being there remain a few things that humans can do very easily which computers find difficult. Along with counting traffic lights and crosswalks, one of those things is finding the exact BPM of a song. Not an estimate like most software does, but the exact value with extreme precision across the entire song. Anyone with a basic sense of rhythm and an audio app can do this.&lt;/p&gt;
    &lt;p&gt;Here’s how:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Open the song in an audio app like Logic, Audition, Ableton, Reaper, ProTools, etc.&lt;/item&gt;
      &lt;item&gt;Zoom in on the waveform a little bit so you can see the shape of the beats.&lt;/item&gt;
      &lt;item&gt;Find the first obvious beat – meaning it has a well-defined waveform peak – and the last obvious beat. Let’s call these “bookend” beats.&lt;/item&gt;
      &lt;item&gt;Measure the exact duration in seconds between the bookend beats.&lt;/item&gt;
      &lt;item&gt;Play the song and count all the beats starting at the first bookend beat and ending at the last bookend beat. (If you have an old school calculator, an easy way to do this is type “1+1=” and then just keep tapping “=” to add 1 on each beat.)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Then to get the exact tempo of the track, averaged throughout the entire thing, use this formula:&lt;/p&gt;
    &lt;code&gt;bpm = 60 * (number_of_beats - 1) / duration&lt;/code&gt;
    &lt;p&gt;Computers have a rough time of this because they don’t really know how to “keep a beat”, and the algorithms that can find the beat do a lot better when they already know the estimated BPM, which is obviously a chicken/egg problem.&lt;/p&gt;
    &lt;p&gt;For the first bookend beat in HBFS I used the first beat after the “whooshing” intro, at around 5.58s. The last bookend beat I used the last “work” at about the 3:41.85 mark. (“Never” and “Over” aren’t good candidates because you can’t see their waveform peaks.)&lt;/p&gt;
    &lt;p&gt;That gives exactly 446 beats or 445 intervals.&lt;/p&gt;
    &lt;p&gt;I tried this with two different copies of HBFS. The Discovery CD rip I have of the song has a duration between the bookend beats of 216.276, so:&lt;/p&gt;
    &lt;code&gt;bpm = 60 * 445 / 216.276 = 123.4499403556&lt;/code&gt;
    &lt;p&gt;The “YouTube official audio” track I tested has a duration of 216.282, so:&lt;/p&gt;
    &lt;code&gt;bpm = 60 * 445 / 216.282 = 123.4533651445&lt;/code&gt;
    &lt;p&gt;The original Discovery CD version has obviously undergone less processing over time than the YouTube version so I tend to think it’s more representative, and it’s very close to 123.45 – only a 0.00005964 difference! But even the more modern YouTube version closely rounds to 123.45.&lt;/p&gt;
    &lt;p&gt;So hopefully I’ve put this fact to rest:&lt;/p&gt;
    &lt;p&gt;The BPM of Harder, Better, Faster, Stronger is 123.45.&lt;/p&gt;
    &lt;head rend="h2"&gt;But…was it intentional?&lt;/head&gt;
    &lt;p&gt;The year is 1999 or 2000. Would the gear Daft Punk uses even support fractional BPMs? And if so out to how many decimal places?&lt;/p&gt;
    &lt;p&gt;From their 2001 interview with Remix Magazine (archive.org) we know that Bangalter says:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Our sequencing is done either on an E-mu SP-1200, an Akai MPC, or a PC with Logic Audio software. We do not work on things in just one way.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;And from later interviews we know the Akai MPC was specifically an MPC-3000. (Oh, and that’s Emagic’s Logic, not Apple’s. Apple didn’t acquire Emagic until 2002.)&lt;/p&gt;
    &lt;p&gt;Did the E-mu support fractional BPMs? Yes, but only to 1 decimal place:&lt;/p&gt;
    &lt;p&gt;The Akai MPC-3000? Yep, also to 1 decimal place:&lt;/p&gt;
    &lt;p&gt;What about Emagic’s Logic?&lt;/p&gt;
    &lt;p&gt;Oooh, look at that. Logic supported BPMs to *4* decimal places.&lt;/p&gt;
    &lt;p&gt;But while we know those three sequencers were used on the Discovery album, I’m not sure anyone else knows which one was specifically used on HBFS. I’ve searched and searched and it seems this detail has just never been revealed.&lt;/p&gt;
    &lt;p&gt;And to confuse matters more, in a 2013 interview with Time Magazine, Bangalter says:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;So we’ve never actually made music with computers! [laughs] Neither Homework nor Discovery nor even Human After All were made with computers.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Was he contradicting himself from 12 years before? Or did he forget? Or maybe it’s a terminology thing?&lt;/p&gt;
    &lt;p&gt;That the CD version is so close to exactly 123.45 makes me think this was intentional. And if it was? Well played, robots. You managed to leave a little Easter egg hiding in plain sight for 25 years.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46469577</guid><pubDate>Fri, 02 Jan 2026 21:27:44 +0000</pubDate></item><item><title>Linux kernel security work</title><link>http://www.kroah.com/log/blog/2026/01/02/linux-kernel-security-work/</link><description>&lt;doc fingerprint="1632919690e4360c"&gt;
  &lt;main&gt;
    &lt;p&gt;Lots of the CVE world seems to focus on “security bugs” but I’ve found that it is not all that well known exactly how the Linux kernel security process works. I gave a talk about this back in 2023 and at other conferences since then, attempting to explain how it works, but I also thought it would be good to explain this all in writing as it is required to know this when trying to understand how the Linux kernel CNA issues CVEs.&lt;/p&gt;
    &lt;p&gt;This is a post in the series about the Linux kernel CVE release process:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Linux kernel versions, how the Linux kernel releases are numbered.&lt;/item&gt;
      &lt;item&gt;Tracking kernel commits across branches, how to keep track of Linux kernel commits as they move from the main release branch into the different stable releases in an automated way.&lt;/item&gt;
      &lt;item&gt;Linux kernel security work (this post), how the Linux kernel security team works to fix reported security bugs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;tl;dr&lt;/head&gt;
    &lt;p&gt;Summary up front for those not wanting to read a wall of text:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Linux kernel security team work to fix reported issues as quickly as possible and get the fixes merged to public trees, and do not do any announcements anywhere.&lt;/item&gt;
      &lt;item&gt;The Linux kernel security team and the CVE team are different groups of people, all of whom do this work on their own recognition, not associated with any company.&lt;/item&gt;
      &lt;item&gt;Only send plain text emails to the kernel security team.&lt;/item&gt;
      &lt;item&gt;Do not email the kernel security team and expect to get a CVE assigned.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Reactive, not proactive, security work&lt;/head&gt;
    &lt;p&gt;The Linux kernel security team is group of Linux kernel developers who are responsible for triaging potential security bugs that are reported to them, and get them fixed as soon as possible. They do this work as “reactive” for security issues, independent of the great “proactive” kernel security work that the Kernel Self-protection project has been doing for the past 10+ years.&lt;/p&gt;
    &lt;head rend="h1"&gt;Kernel security team&lt;/head&gt;
    &lt;p&gt;As can be seen in the in-kernel documentation to contact the security team, just email the address in that document the potential issue that you have found, without using HTML or any binary attachments, and the developers there will take the report and usually ask questions and work to resolve the issue if it turns out to actually be a real security issue. Many issues reported are not, and so the reporter is told to send their bug report to the respective mailing list and work on it with the developers there, in public.&lt;/p&gt;
    &lt;p&gt;When reporting a bug, just send a simple, plain text email to the security alias. Do not send an email that contains a binary attachment as opening unsolicited binary files is not anything anyone should be doing. Also do not use markdown formatting, just plain text. Also, no encryption is needed, as it will not work due to the email alias handling (i.e. one address to many individuals.) If you are forced to use encryption to report security problems, please reconsider this policy as it feels counterproductive (UK government, this means you…)&lt;/p&gt;
    &lt;p&gt;The members of the security team contain a handful of core kernel developers that have experience dealing with security bugs, and represent different major subsystems of the kernel. They do this work as individuals, and specifically can NOT tell their employer, or anyone else, anything that is discussed on the security alias before it is resolved. This arrangement has allowed the kernel security team to remain independent and continue to operate across the different governments that the members operate in, and it looks to become the normal way project security teams work with the advent of the European Union’s new CRA law coming into affect which places requirements on response time of companies that receive notice of potential security issues in their projects.&lt;/p&gt;
    &lt;head rend="h2"&gt;How the fix happens&lt;/head&gt;
    &lt;p&gt;The way the security team works is when a bug is reported, if the members do not have experience in that specific subsystem, they drag the maintainers of that subsystem into the email chain, and work to get the bug resolved. If a subsystem has a continued number of bugs reported over time, the maintainer can be “asked” if they wish to join the alias to help remove the additional “hop” of bug triage happening. This is what has caused the alias members to naturally grow over time to end up representing the major portions of the kernel with the most issues.&lt;/p&gt;
    &lt;p&gt;Ideally the bug reporter also provides a working fix for the issue, allowing them to get the proper credit for the fix but of course that does not always happen. If no fix is provided, the developers involve work to resolve the bug as soon as they can, and when they agree it is resolved, get it merged into the main kernel branch and the stable kernel releases as soon as possible.&lt;/p&gt;
    &lt;head rend="h2"&gt;No embargoes&lt;/head&gt;
    &lt;p&gt;As the documentation states, no embargoes longer than 7 days are allowed, once a working fix is made, as there’s no real reason to hold off on getting a fix merged at that time. Only very few changes ever have any embargo at all, as it’s more bother than it is worth.&lt;/p&gt;
    &lt;p&gt;Once the bug is fixed in the kernel trees, the developer’s work is finished, and it is up to the reporter if they wish to “announce” a bugfix or not. The kernel security team on their own do not do any reporting or external communication at all. Only later, if the fix is warranted to justify a CVE being assigned, is the commit announced as a security fix, but that work is done by the kernel CVE team, NOT the kernel security team.&lt;/p&gt;
    &lt;p&gt;More about how the kernel CVE team works in a later post in this series…&lt;/p&gt;
    &lt;head rend="h1"&gt;A bug is a bug is a bug&lt;/head&gt;
    &lt;p&gt;This “do not announce anything” policy has been present in the kernel security team since the very beginning, and as you can imagine, has caused much “disagreement” by those outside of the kernel community. This came up soon after the kernel security team was established in a 2008 email thread with Linus:&lt;/p&gt;
    &lt;code&gt;  On Wed, 16 Jul 2008, pageexec@freemail.hu wrote:
  &amp;gt;
  &amp;gt; you should check out the last few -stable releases then and see how
  &amp;gt; the announcement doesn't ever mention the word 'security' while fixing
  &amp;gt; security bugs

  Umm. What part of "they are just normal bugs" did you have issues with?
  I expressly told you that security bugs should not be marked as such,
  because bugs are bugs.

  &amp;gt; in other words, it's all the more reason to have the commit say it's
  &amp;gt; fixing a security issue.

  No.

  &amp;gt; &amp;gt; I'm just saying that why mark things, when the marking have no meaning?
  &amp;gt; &amp;gt; People who believe in them are just _wrong_.
  &amp;gt;
  &amp;gt; what is wrong in particular?

  You have two cases:

  - people think the marking is somehow trustworthy.

    People are WRONG, and are misled by the partial markings, thinking that
    unmarked bugfixes are "less important". They aren't.

  - People don't think it matters

    People are right, and the marking is pointless.
    In either case it's just stupid to mark them. I don't want to do it,
    because I don't want to perpetuate the myth of "security fixes" as a
    separate thing from "plain regular bug fixes".

    They're all fixes. They're all important. As are new features, for that
    matter.

  &amp;gt; when you know that you're about to commit a patch that fixes a security
  &amp;gt; bug, why is it wrong to say so in the commit?

  It's pointless and wrong because it makes people think that other bugs
  aren't potential security fixes.

  What was unclear about that?

  Linus
&lt;/code&gt;
    &lt;p&gt;The whole email thread is worth reading.&lt;/p&gt;
    &lt;head rend="h2"&gt;No one knows how you use open source&lt;/head&gt;
    &lt;p&gt;The primary reason why the kernel does not do any security announcements is that almost any bugfix at the level of an operating system kernel can be a “security issue” given the issues involved (memory leaks, denial of service, information leaks, etc.) Also, given that Linux is open source, the developers involved in fixing problems do NOT know how Linux is being used. A simple bugfix for a minor thing for one user could be a major system vulnerability fix for a different user, all depending on how Linux is being used. Ben Hawkes said it best in a wonderful essay about “What is a good Linux kernel bug”:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;âIt’s hard to capture the fact that a bug can be super serious in one type of deployment, somewhat important in another, or no big deal at all – and that the bug can be all of this at the same time. Vulnerability remediation is hard.â â Ben Hawkes&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Always remember, kernel developers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;do not know your use case.&lt;/item&gt;
      &lt;item&gt;do not know what code you use.&lt;/item&gt;
      &lt;item&gt;do not want to know any of this.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So, overall, the kernel security bug policy can be boiled down to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fix known bugs as soon as possible.&lt;/item&gt;
      &lt;item&gt;Get releases out to users as quickly as possible.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For those that are always worried “what if a bugfix causes problems”, they should remember that a fix for a known bug is better than the potential of a fix causing a future problem as future problems, when found, will be fixed then. You never want to have “known bugfixes” not resolved on your system at any time. So much so that recent laws will soon be preventing you that being allowed for many countries.&lt;/p&gt;
    &lt;head rend="h2"&gt;Hardware security issues&lt;/head&gt;
    &lt;p&gt;As history has shown us with Spectre and Meltdown, this “no embargo” policy does not always work well when working with problems that cross operating systems and hardware platforms, possibly requiring firmware or microcode updates. Because of this, the kernel developers have been forced to come up with a “Hardware Security policy” to handle these types of issues.&lt;/p&gt;
    &lt;p&gt;This different workflow involves the creation of a special encrypted and restricted email list containing just the needed kernel and hardware developers that are required to get the problem solved. With this process, embargoes are grumpily tolerated for now. Many different hardware bugs have been resolved in Linux over the years through this process, but as a participant in some of these efforts, it is clunky, awkward, and often times extremely slow. The kernel developers involved really do not like this process, and hopefully this will be phased out over time as many hardware issues have been resolved in the past year without having to get this special process involved at all.&lt;/p&gt;
    &lt;p&gt;Also, due to the CRA timelines, long embargo times will probably not even be possible for hardware companies to handle. How that is going to interact with microcode and firmware updates in the next few years is going to be an “interesting” thing to watch evolve.&lt;/p&gt;
    &lt;head rend="h1"&gt;How this all started&lt;/head&gt;
    &lt;p&gt;Way back in 2005, there was not any “official” way to contact anyone about kernel security bugs. It was just an ad-hock group of people that developers “knew” they could email problems to. That obviously did not really scale, and was not helpful for anyone who did not know how the kernel developers worked. This came to a head in 2005 with this email from Steve Bergman:&lt;/p&gt;
    &lt;code&gt;From: Steve Bergman &amp;lt;steve@rueb.com&amp;gt;
To: linux-kernel@vger.kernel.org
Subject: Proper procedure for reporting possible security vulnerabilities?
Date: Mon, 10 Jan 2005 10:46:57 -0600

There seems to be some confusion in certain quarters as to the proper
procedure for reporting possible kernel security issues.

REPORTING-BUGS says send bug reports to the maintainer of that area of
the kernel. However, what about areas for which a maintainer is not
listed? (e.g. VM) It seems that some take that to mean send it
directly to Linus and if you don't hear something back quickly, release
an exploit to the wild.

So what is the preferred procedure and is it documented somewhere?
Should it be made more prominent?

Thanks for any information,
Steve Bergman
&lt;/code&gt;
    &lt;p&gt;That naturally kicked off a bit of discussion, so 36 emails later, the idea of a central email alias that could handle reported security issues was decided on and a few months later, was written up by Chris Wright:&lt;/p&gt;
    &lt;code&gt;From: Chris Wright &amp;lt;chrisw@osdl.org&amp;gt;
To: torvalds@osdl.org
Cc: akpm@osdl.org, alan@lxorguk.ukuu.org.uk,
    marcelo.tosatti@cyclades.com, linux-kernel@vger.kernel.org
Subject: [PATCH] Security contact info
Date: Wed, 9 Mar 2005 01:05:50 -0800

Add security contact info and relevant documentation.

Signed-off-by: Chris Wright &amp;lt;chrisw@osdl.org&amp;gt;

 MAINTAINERS                |    5 +++++
 REPORTING-BUGS             |    4 ++++
 Documentation/SecurityBugs |   38 ++++++++++++++++++++++++++++++++++++++
 3 files changed, 47 insertions(+)
&lt;/code&gt;
    &lt;head rend="h1"&gt;No security announcements&lt;/head&gt;
    &lt;p&gt;As stated earlier, the kernel security team does not do any sort of announcements at all, or any public statements anywhere. They are also not responsible for assigning CVE ids to any kernel bugfixes, that is a different team’s responsibility that happens after kernel bugfixes are in public kernel releases, and almost never before.&lt;/p&gt;
    &lt;p&gt;Because they do not do any announcements, there is also no “early announcement” list, despite many companies constantly asking to “join the security pre-announcement security list” requests we get.&lt;/p&gt;
    &lt;p&gt;The primary reason there is no pre-announcement list is overall they should always be considered public and contain leaks. Otherwise, why would your government allow them to exist? Unless the list is for a project that is not really used by anyone…&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46469623</guid><pubDate>Fri, 02 Jan 2026 21:31:34 +0000</pubDate></item><item><title>Microsoft kills official way to activate Windows 11/10 without internet</title><link>https://www.neowin.net/news/report-microsoft-quietly-kills-official-way-to-activate-windows-1110-without-internet/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46471081</guid><pubDate>Sat, 03 Jan 2026 00:01:53 +0000</pubDate></item><item><title>Show HN: Website that plays the lottery every second</title><link>https://lotteryeverysecond.lffl.me/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46471171</guid><pubDate>Sat, 03 Jan 2026 00:12:55 +0000</pubDate></item><item><title>2026 will be my year of the Linux desktop</title><link>https://xeiaso.net/notes/2026/year-linux-desktop/</link><description>&lt;doc fingerprint="4e7e82b81462420f"&gt;
  &lt;main&gt;
    &lt;p&gt;Making sure you're not a bot! Loading... Please wait a moment while we ensure the security of your connection.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46471199</guid><pubDate>Sat, 03 Jan 2026 00:15:47 +0000</pubDate></item><item><title>Proving Liveness with TLA</title><link>https://roscidus.com/blog/blog/2026/01/01/tla-liveness/</link><description>&lt;doc fingerprint="2c21588617a01b99"&gt;
  &lt;main&gt;
    &lt;p&gt;The TLA Toolbox now has support for proving liveness properties (i.e. that something will eventually happen). I try it out on the Xen vchan protocol.&lt;/p&gt;
    &lt;p&gt;Table of Contents&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Background&lt;/item&gt;
      &lt;item&gt;A simple channel specification&lt;/item&gt;
      &lt;item&gt;Temporal logic&lt;/item&gt;
      &lt;item&gt;Proving liveness (simple case)&lt;/item&gt;
      &lt;item&gt;Multi-step liveness&lt;/item&gt;
      &lt;item&gt;The real protocol&lt;/item&gt;
      &lt;item&gt;Work-arounds for bugs&lt;/item&gt;
      &lt;item&gt;Conclusions&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Background&lt;/head&gt;
    &lt;p&gt;The vchan protocol is used for efficient communication between Xen virtual machines. In 2018, I made a TLA+ specification of vchan: I created a specification of the protocol from the C code, used the model checker (TLC) to test that the protocol worked on small models, and wrote a machine-verified proof of &lt;code&gt;Integrity&lt;/code&gt; (that the data received always matched what was sent).
I also outlined a proof of &lt;code&gt;Availability&lt;/code&gt; (that data sent will eventually arrive, rather than the system deadlocking or going around in circles). But:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Disappointingly, we can't actually prove&lt;/p&gt;&lt;code&gt;Availability&lt;/code&gt;using TLAPS, because currently it understands very little temporal logic&lt;/quote&gt;
    &lt;p&gt;However, newer versions of TLAPS (the TLA Proof System) have added proper support for temporal logic, so I decided to take another look. In this post, I'll start with a simple example of proving a liveness property, and then look at the real protocol. If you're not familiar with TLA, you might want to read the earlier post first, though I'll briefly introduce concepts as we meet them here.&lt;/p&gt;
    &lt;head rend="h2"&gt;A simple channel specification&lt;/head&gt;
    &lt;p&gt;We'll start with a simple model of a one-way channel. There is a sender and a receiver, and they have access to a shared buffer of size &lt;code&gt;BufferSize&lt;/code&gt;
(which is a non-zero natural number):&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The model just keeps track of the total number of bytes sent and received (not the actual data):&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The amount of data currently in the buffer (&lt;code&gt;BufferUsed&lt;/code&gt;) is the difference between these counters,
and the free space (&lt;code&gt;BufferFree&lt;/code&gt;) is the difference between that and the total buffer size:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The property we are interested in (&lt;code&gt;Liveness&lt;/code&gt;) is that data sent eventually arrives:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Specification in terms of actions&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;Liveness&lt;/code&gt; is the property we want, but we also need to say how we plan to achieve this.
In TLA, this is done by describing the initial state and the actions that can be performed
at each step.&lt;/p&gt;
    &lt;p&gt;Initially, no bytes have been sent or received:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;An action only looks at a single atomic step of the algorithm, and relates the values of the variables at the start of the step (e.g. &lt;code&gt;Sent&lt;/code&gt;) to their values at the end (written primed, e.g. &lt;code&gt;Sent'&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;Send&lt;/code&gt; action is true when the sender increases &lt;code&gt;Sent&lt;/code&gt;
(by some amount &lt;code&gt;n&lt;/code&gt;, limited by the free space in the buffer):&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The &lt;code&gt;Recv&lt;/code&gt; action is true when the receiver reads all of the data currently in the buffer:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Every action of our system is either a &lt;code&gt;Send&lt;/code&gt; or a &lt;code&gt;Recv&lt;/code&gt;:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Finally, &lt;code&gt;Spec&lt;/code&gt; describes the behaviours of the whole system in these terms:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Invariants&lt;/head&gt;
    &lt;p&gt;It's always useful to prove some basic invariants about the system (in particular, the types of the variables):&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Before trying to prove anything, it's good to use the model checker (TLC) to test it first. You'll need to put some limits on the number of bytes sent and checked in the model, so it isn't a full proof, but it's likely to spot most problems. In this example, it passes easily.&lt;/p&gt;
    &lt;p&gt;The general idea for proving things in TLA is to get away from temporal logic as quickly as possible and do most of the proof with simple actions. The following pattern should work for proving any invariant:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;This says that &lt;code&gt;Spec&lt;/code&gt; implies that &lt;code&gt;I&lt;/code&gt; is always true because:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;I&lt;/code&gt;is true initially.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Next&lt;/code&gt;steps preserve&lt;code&gt;I&lt;/code&gt;(and so does leaving&lt;code&gt;vars&lt;/code&gt;unchanged).&lt;/item&gt;
      &lt;item&gt;Therefore &lt;code&gt;Spec&lt;/code&gt;ensures&lt;code&gt;I&lt;/code&gt;will always be true.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: The &lt;code&gt;&amp;lt;1&amp;gt;&lt;/code&gt; at the start of each step is the indentation level,
which for some reason TLAPS can't work out by itself.&lt;/p&gt;
    &lt;p&gt;The final &lt;code&gt;QED BY PTL&lt;/code&gt; ("by Propositional Temporal Logic") is the only step that uses temporal logic.
Everything else is just regular logic.&lt;/p&gt;
    &lt;p&gt;Now all we need to do is prove that the &lt;code&gt;Next&lt;/code&gt; action preserves &lt;code&gt;I&lt;/code&gt;, which is straight-forward:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5 6&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;So for proving invariants like &lt;code&gt;I&lt;/code&gt; we can mostly ignore temporal logic.
By for proving liveness, we'll need to understand more about it...&lt;/p&gt;
    &lt;head rend="h2"&gt;Temporal logic&lt;/head&gt;
    &lt;p&gt;Temporal logic is a type of modal logic. In a modal logic we imagine there are many worlds, and we are in one of them. Ordinary mathematical statements refer to our world, so e.g. &lt;code&gt;Sent = 4&lt;/code&gt; refers to the value of &lt;code&gt;Sent&lt;/code&gt; in our world.
However, by using the modal operators, you can refer to other worlds.
For example, &lt;code&gt;[](Sent = 4)&lt;/code&gt; means that &lt;code&gt;Sent = 4&lt;/code&gt; is true in all worlds "reachable" from the current one.&lt;/p&gt;
    &lt;p&gt;In TLA, each world corresponds to a moment in time, and current and future times are reachable. So &lt;code&gt;[]X&lt;/code&gt; means "X will always be true".
&lt;code&gt;&amp;lt;&amp;gt;X&lt;/code&gt; means "X will eventually be true".
For example:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;[](Sent = 4)&lt;/code&gt;means that&lt;code&gt;Sent = 4&lt;/code&gt;is true now and always will be.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;&amp;lt;&amp;gt;(Sent = 4)&lt;/code&gt;means that&lt;code&gt;Sent = 4&lt;/code&gt;is either true now or will be true at some point in the future.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Modal operators nest, so you can say things like &lt;code&gt;&amp;lt;&amp;gt;[](Sent = 4)&lt;/code&gt;
(eventually &lt;code&gt;Sent&lt;/code&gt; will equal 4 and will remain so from then onwards),
or &lt;code&gt;[](F =&amp;gt; &amp;lt;&amp;gt;G)&lt;/code&gt; (&lt;code&gt;F&lt;/code&gt; always leads to &lt;code&gt;G&lt;/code&gt;, which can also be written as &lt;code&gt;F ~&amp;gt; G&lt;/code&gt;).&lt;/p&gt;
    &lt;head rend="h3"&gt;Proving temporal claims with TLAPS&lt;/head&gt;
    &lt;p&gt;In the proof of &lt;code&gt;Spec =&amp;gt; []I&lt;/code&gt; above, only one step required temporal logic (&lt;code&gt;BY PTL&lt;/code&gt;).
Having few such steps is good because these steps can be tricky.&lt;/p&gt;
    &lt;p&gt;The main problem is that TLA propositions are written in First Order Modal Logic, but TLAPS doesn't have any solvers that understand this! Instead, it has a number of solvers that understand regular non-modal logic, plus the &lt;code&gt;PTL&lt;/code&gt; decision procedure that handles modal logic but not much else.&lt;/p&gt;
    &lt;p&gt;For example, consider this apparently simple claim:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;1
&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;This says that if &lt;code&gt;Sent&lt;/code&gt; is always equal to 4 then it is currently greater than 0.
TLAPS can't prove this in a single step:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The regular solvers don't understand the &lt;code&gt;[]&lt;/code&gt;bit.&lt;/item&gt;
      &lt;item&gt;The PTL procedure doesn't understand numbers.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Coalescing for Reasoning in First-Order Modal Logics explains in detail what's going on, but my rough understanding is that TLAPS replaces things a solver won't understand with new fresh variables.&lt;/p&gt;
    &lt;p&gt;For example, &lt;code&gt;[](Sent = 4) =&amp;gt; Sent &amp;gt; 0&lt;/code&gt; is received by the solver as something like:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;Blob1 =&amp;gt; Sent &amp;gt; 0&lt;/code&gt;(for a regular solver), or&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;[]Blob2 =&amp;gt; Blob3&lt;/code&gt;(for PTL)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Instead, you have to break it down into separate steps:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;In the second step, the PTL solver will receive something like this, which it can prove:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Annoyingly, TLAPS doesn't have an easy way to show you what it replaced in this way. If it did, I think it would be much easier to learn how to use it. You can use &lt;code&gt;tlapm spec.tla --debug tempfiles&lt;/code&gt; and look at the files generated for each
solver backend, but they're quite hard to read.&lt;/p&gt;
    &lt;head rend="h3"&gt;Generalising&lt;/head&gt;
    &lt;p&gt;Things that can be proved without assumptions specific to the current time are always true. In the above example, &lt;code&gt;PTL&lt;/code&gt; converted &lt;code&gt;Blob2 =&amp;gt; Blob3&lt;/code&gt; from the regular solver
to &lt;code&gt;[](Blob2 =&amp;gt; Blob3)&lt;/code&gt;.
This was only possible because the proof of &lt;code&gt;Blob2 =&amp;gt; Blob3&lt;/code&gt; didn't depend on the current world/time.&lt;/p&gt;
    &lt;p&gt;For example:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;We're trying to prove that if &lt;code&gt;Sent&lt;/code&gt; is always 4 then it's always greater than 0.
The problem is that we proved &lt;code&gt;Sent = 4 =&amp;gt; Sent &amp;gt; 0&lt;/code&gt; in a context that assumed &lt;code&gt;Spec&lt;/code&gt;,
so TLAPS won't let us generalise it (even though it looks identical to what we proved before,
and didn't actually use anything from &lt;code&gt;Spec&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;When &lt;code&gt;PTL&lt;/code&gt; fails, the &lt;code&gt;Interesting Obligations&lt;/code&gt; view shows e.g.&lt;/p&gt;
    &lt;code&gt;ASSUME ...
       Sent = 4 =&amp;gt; Sent &amp;gt; 0 (* non-[] *),
       PTL 
PROVE  [](Sent = 4) =&amp;gt; [](Sent &amp;gt; 0)
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;(* non-[] *)&lt;/code&gt; indicates that this can't be generalised to all times; we only know it's true now.&lt;/p&gt;
    &lt;p&gt;Instead, we can do:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5 6 7&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Doing the &lt;code&gt;Sent = 4 =&amp;gt; Sent &amp;gt; 0&lt;/code&gt; step before introducing &lt;code&gt;Spec&lt;/code&gt; as an assumption allowed it to be generalised.
We could also have proved it as a separate lemma.&lt;/p&gt;
    &lt;p&gt;Here's an example where we make use of a &lt;code&gt;non-[]&lt;/code&gt; assumption:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;If &lt;code&gt;Spec&lt;/code&gt; is true (we're at the start of the algorithm) then &lt;code&gt;Sent = 0&lt;/code&gt;.
We can't generalise to saying that &lt;code&gt;Sent&lt;/code&gt; is always 0,
but we can still use it to prove that &lt;code&gt;Sent&lt;/code&gt; is (trivially) eventually zero.
But having &lt;code&gt;non-[]&lt;/code&gt; assumptions usually indicates that something has gone wrong.&lt;/p&gt;
    &lt;p&gt;Some assumptions are safe to have in the context however. You can assume constants (e.g &lt;code&gt;NEW n \in Nat&lt;/code&gt;), and also things that will always be true (e.g. &lt;code&gt;[]I&lt;/code&gt;).
This is fine:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Hiding definitions&lt;/head&gt;
    &lt;p&gt;Here's a simplified version of a problem I had:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5 6 7 8 9&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;As usual, the regular solvers can't handle the &lt;code&gt;[]&lt;/code&gt; and &lt;code&gt;PTL&lt;/code&gt; can't handle the numbers or the for-all.
We could create a function (&lt;code&gt;F&lt;/code&gt;) for the temporal formula and then hide its definition:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5 6 7 8&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;However, due to a bug in TLAPS, this is unreliable. Often a proof fails, then you rename things a bit and it passes, then you rename them back and it continues to pass! I reported this at https://github.com/tlaplus/tlapm/issues/247. Here's a screenshot of an extreme case, where TLAPS is failing to prove a conclusion that matches an assumption character for character!&lt;/p&gt;
    &lt;p&gt;Until that's fixed, I found that the following pattern works well as a work-around:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5 6 7 8 9 10 11 12&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Even when this bug is fixed, I think it would be really nice if you could say e.g. &lt;code&gt;BY L1(m+1)&lt;/code&gt; to explicitly use &lt;code&gt;L1&lt;/code&gt; with a particular value of &lt;code&gt;n&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;Proving liveness (simple case)&lt;/head&gt;
    &lt;p&gt;OK, let's use some temporal logic to prove &lt;code&gt;Liveness&lt;/code&gt;:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;One way to prove &lt;code&gt;A ~&amp;gt; B&lt;/code&gt; (&lt;code&gt;A&lt;/code&gt; always eventually leads to &lt;code&gt;B&lt;/code&gt;)
is from an action &lt;code&gt;A =&amp;gt; B'&lt;/code&gt; (&lt;code&gt;A&lt;/code&gt; leads to &lt;code&gt;B&lt;/code&gt; in one step), plus a few side conditions.
We'll do that here because we conveniently have a &lt;code&gt;Recv&lt;/code&gt; action that immediately gets us to our goal.
To prove &lt;code&gt;A ~&amp;gt; B&lt;/code&gt; a generally-useful pattern is:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5 6 7&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;If we're at &lt;code&gt;A&lt;/code&gt;and perform our useful action&lt;code&gt;Recv&lt;/code&gt;then afterwards we'll be at&lt;code&gt;B&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;When we're at &lt;code&gt;A&lt;/code&gt;we can perform the useful action.&lt;/item&gt;
      &lt;item&gt;If the useful action is continually possible then eventually it will happen.&lt;/item&gt;
      &lt;item&gt;If we're at &lt;code&gt;A&lt;/code&gt;and perform any action&lt;code&gt;Next&lt;/code&gt;, we'll either stay at&lt;code&gt;A&lt;/code&gt;or get to&lt;code&gt;B&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;The system always performs &lt;code&gt;Next&lt;/code&gt;steps.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Some examples of why these are necessary to prove &lt;code&gt;Liveness&lt;/code&gt;:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Without 2: &lt;code&gt;Recv&lt;/code&gt;requires at least 2 bytes in the buffer; sending a single byte fails.&lt;/item&gt;
      &lt;item&gt;Without 3: someone else has to perform &lt;code&gt;Recv&lt;/code&gt;and we can't be sure they'll actually do it.&lt;/item&gt;
      &lt;item&gt;Without 4: the sender can &lt;code&gt;Send&lt;/code&gt;some data and then&lt;code&gt;Retract&lt;/code&gt;it before it is read.&lt;/item&gt;
      &lt;item&gt;Without 5: 4 wouldn't be useful.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;(3) and (5) come directly from the definition of &lt;code&gt;Spec&lt;/code&gt;.
We need to write proofs for the others, but they're all non-temporal proofs and fairly simple.
The only slightly tricky one is proving &lt;code&gt;ENABLED&lt;/code&gt;:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The magic &lt;code&gt;ExpandENABLED&lt;/code&gt; causes the definition of &lt;code&gt;ENABLED&lt;/code&gt; to be expanded in the version given to the solver.
This is only useful if the solver also has access to the definitions of all the actions used;
&lt;code&gt;AutoUSE&lt;/code&gt;provides them automatically so you don't have to list them manually.&lt;/p&gt;
    &lt;p&gt;However, the solver has to work quite hard to prove this and I found it times out on more realistic examples. The following trick is more generally useful:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5 6 7 8 9&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;Recv&lt;/code&gt;always modifies&lt;code&gt;vars&lt;/code&gt;, so&lt;code&gt;&amp;lt;&amp;lt;Recv&amp;gt;&amp;gt;_vars&lt;/code&gt;is the same as&lt;code&gt;Recv&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Therefore, &lt;code&gt;ENABLED &amp;lt;&amp;lt;Recv&amp;gt;&amp;gt;_vars&lt;/code&gt;is the same as&lt;code&gt;ENABLED Recv&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Therefore, we just need to prove &lt;code&gt;ENABLED Recv&lt;/code&gt;, which is easier for the solver.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The above uses the magic &lt;code&gt;BY ENABLEDaxioms&lt;/code&gt;.
This doesn't seem to be documented; I just found it in one of the examples.
It's really fussy about the syntax used.
e.g. it works if you ask to prove it in both directions with &lt;code&gt;&amp;lt;=&amp;gt;&lt;/code&gt;,
but if you ask for e.g. just &lt;code&gt;=&amp;gt;&lt;/code&gt; then it fails!
Also, it requires &lt;code&gt;&amp;lt;&amp;lt;Recv&amp;gt;&amp;gt;_vars &amp;lt;=&amp;gt; Recv&lt;/code&gt; rather than &lt;code&gt;&amp;lt;&amp;lt;Recv&amp;gt;&amp;gt;_vars = Recv&lt;/code&gt;,
though you can prove the first from the second.
The ENABLEDaxioms_test.tla test file is useful for getting the syntax right.&lt;/p&gt;
    &lt;p&gt;See example.tla for the full proof.&lt;/p&gt;
    &lt;head rend="h2"&gt;Multi-step liveness&lt;/head&gt;
    &lt;p&gt;The above proof was easy because the &lt;code&gt;Recv&lt;/code&gt; step gets us to our goal immediately.
It's more complicated if we only say that each &lt;code&gt;Recv&lt;/code&gt; step reads some of the buffer:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The trick is to define a distance metric:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;1
&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;&lt;code&gt;Dist(n, i)&lt;/code&gt; says we are within &lt;code&gt;i&lt;/code&gt; bytes of having received the first &lt;code&gt;n&lt;/code&gt; bytes.
Then a simple inductive argument will do:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5 6 7 8 9&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Here, &lt;code&gt;R(i)&lt;/code&gt; says that the algorithm works if we start at most &lt;code&gt;i&lt;/code&gt; bytes away from our goal.
&lt;code&gt;R(0)&lt;/code&gt; is obviously true, and we show that &lt;code&gt;R(i) =&amp;gt; R(i+1)&lt;/code&gt;.
By induction, &lt;code&gt;R&lt;/code&gt; is true for any distance.
Notice again the use of &lt;code&gt;HIDE&lt;/code&gt; to avoid confusing the solvers with temporal logic.&lt;/p&gt;
    &lt;p&gt;Then we just need to show &lt;code&gt;Progress&lt;/code&gt;: we eventually get closer to our goal (&lt;code&gt;Dist(n, i+1) ~&amp;gt; Dist(n, i)&lt;/code&gt;).
That can be proved from &lt;code&gt;Recv&lt;/code&gt; in a similar way to before. See example.tla for the full proof.&lt;/p&gt;
    &lt;head rend="h2"&gt;The real protocol&lt;/head&gt;
    &lt;p&gt;I've now updated vchan.tla to prove liveness for the real system. It was more complicated than the example above (because it also looks at the data being sent, has many steps, models sending interrupts, etc), but the basic approach is the same.&lt;/p&gt;
    &lt;p&gt;Note: In the real system, &lt;code&gt;Sent&lt;/code&gt; and &lt;code&gt;Got&lt;/code&gt; are the actual messages, so the
property talks about their lengths. &lt;code&gt;Sent&lt;/code&gt; is what the sending application has
asked the vchan library to transmit (even if it hasn't been written to the shared
buffer yet), and &lt;code&gt;Got&lt;/code&gt; is what the receiving application has received from its
vchan library.&lt;/p&gt;
    &lt;p&gt;Ideally, we'd like to prove something like this:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;However, that doesn't work because the sender (and receiver) can decide to shut down the connection at any moment. If the sender closes the connection before transmitting all the data then obviously it might not be received. So it's actually defined like this:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5 6 7 8 9 10 11&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Note: &lt;code&gt;SenderLive&lt;/code&gt; and &lt;code&gt;ReceiverLive&lt;/code&gt; are badly named.
&lt;code&gt;SenderLive = FALSE&lt;/code&gt; means that the sender has written all data successfully and there is nothing more to come.
&lt;code&gt;ReceiverLive = FALSE&lt;/code&gt; means that the receiver has decided to terminate the connection early,
and probably indicates an error (think &lt;code&gt;EPIPE&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;Although TLAPS couldn't prove liveness properties back in 2018, I had got most of the way there:&lt;/p&gt;
    &lt;p&gt;I'd defined &lt;code&gt;ReadLimit&lt;/code&gt; as:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The number of bytes that the receiver will eventually get without further action from the sender (assuming the receiver doesn't decide to close the connection).&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;and likewise &lt;code&gt;WriteLimit&lt;/code&gt; as:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The number of bytes that the sender will eventually send without further action from the other processes or the client application, assuming the connection isn't closed by either end.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I'd proved some useful invariants about them. For example:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5 6 7 8 9 10 11 12 13 14&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;If &lt;code&gt;ReadLimit&lt;/code&gt; and &lt;code&gt;WriteLimit&lt;/code&gt; accurately predict what will happen then these properties
are good evidence that the protocol works:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;WriteLimit&lt;/code&gt;predicts that the sender will be able to fill the buffer initially.&lt;/item&gt;
      &lt;item&gt;If the receiver doesn't read it then the buffer will become full and the sender will block, at which point &lt;code&gt;ReadAllIfSenderBlocked&lt;/code&gt;predicts all the data will be read.&lt;/item&gt;
      &lt;item&gt;If the receiver runs out of data then it will then eventually block, at which point, &lt;code&gt;WriteAllIfReceiverBlocked&lt;/code&gt;predicts more data can be written.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I'd used TLC to check that both predictions were correct (on small models), but I hadn't been able to prove them with the old version of TLAPS.&lt;/p&gt;
    &lt;head rend="h3"&gt;Proving ReadLimit&lt;/head&gt;
    &lt;p&gt;The actual proof followed the same outline as the example above. The main extra bit was showing that if we haven't yet read up to the &lt;code&gt;ReadLimit&lt;/code&gt;
then the receiver process would eventually reach the code that did the read,
and with the belief that there was at least one byte available.
Mixing &lt;code&gt;BY PTL&lt;/code&gt; and regular solvers was particularly annoying here and required stating
lots of obvious facts like &lt;code&gt;PC \in {"recv_got_len"} =&amp;gt; PC = "recv_got_len"&lt;/code&gt; because &lt;code&gt;PTL&lt;/code&gt;
doesn't understand sets, etc.&lt;/p&gt;
    &lt;p&gt;It seems a bit strange to have to prove that each line of code leads to the next. That's something you can mostly just assume when writing software, but in TLA you need to be explicit. The only interesting bits were the usual things about showing code terminates:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;For loops, show that they will make progress each iteration.&lt;/item&gt;
      &lt;item&gt;Show the code doesn't crash (e.g. no buffer overflow).&lt;/item&gt;
      &lt;item&gt;Show that any explicit &lt;code&gt;await&lt;/code&gt;will eventually resume.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To help with the proofs I defined &lt;code&gt;RSpec&lt;/code&gt; as a variant of &lt;code&gt;Spec&lt;/code&gt;:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Instead of being true only at the start (like &lt;code&gt;Spec&lt;/code&gt;, which uses &lt;code&gt;Init&lt;/code&gt;),
this only requires our invariant (&lt;code&gt;[]I&lt;/code&gt;) to be true.
Things proved using &lt;code&gt;RSpec&lt;/code&gt; are therefore true from any point in the protocol,
which lets them be reused in other proofs.&lt;/p&gt;
    &lt;p&gt;I was able to show that &lt;code&gt;ReadLimit&lt;/code&gt;'s prediction will come true:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;and from that, rather magically:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5 6 7 8 9 10 11&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;That eliminates all mention of &lt;code&gt;ReadLimit&lt;/code&gt;, and expresses the property in terms meaningful to the sender.&lt;/p&gt;
    &lt;head rend="h3"&gt;Proving Availability&lt;/head&gt;
    &lt;p&gt;I was expecting to have to prove &lt;code&gt;WriteLimit&lt;/code&gt; was correct too.
But it turned out I didn't.
&lt;code&gt;Availability&lt;/code&gt; only said that the receiver would receive data that had been transmitted;
it never claimed that the sending process would succeed in doing that!
It's right there in the comment even:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5 6&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Well, this is pretty bad. The point of proofs is that instead of having to check hundreds of lines of C, or dozens of lines of TLA actions, we only have to check that the definition of &lt;code&gt;Availability&lt;/code&gt; is what we want.
My definition of &lt;code&gt;Availability&lt;/code&gt; is still true if the sender blocks forever waiting for more space in the buffer.
In fact, if I change the definition of the sender process so that
the application asking for data to be sent is the only possible action,
then TLC reports that &lt;code&gt;Availability&lt;/code&gt; still holds (which is true).
The original blog post appeared on Reddit, Hacker News and Lobsters,
and nobody else seems to have spotted this either.&lt;/p&gt;
    &lt;p&gt;Though in fairness to my past self, I did mention checking an earlier version of &lt;code&gt;Availability&lt;/code&gt;
that did require that it works end-to-end (but didn't make any claims about what happens on shutdown),
and I had also tested &lt;code&gt;WriteLimit&lt;/code&gt;, so I'm not really worried that the system doesn't work.&lt;/p&gt;
    &lt;p&gt;And so, having learnt how to do liveness proofs, which was my real goal, I decided to stop here.&lt;/p&gt;
    &lt;head rend="h3"&gt;Proving WriteLimit&lt;/head&gt;
    &lt;p&gt;But proof assistants are addictive, and I found myself continuing anyway. The proof of the correctness of &lt;code&gt;WriteLimit&lt;/code&gt; was very similar to the one for &lt;code&gt;ReadLimit&lt;/code&gt; and I got it done much faster
now I knew more about how to do these proofs.&lt;/p&gt;
    &lt;p&gt;However, I also wanted to fix &lt;code&gt;Availability&lt;/code&gt; to something useful and updated it to this:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5 6 7 8 9 10 11&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;(&lt;code&gt;msg&lt;/code&gt; is the data yet to be transmitted)&lt;/p&gt;
    &lt;p&gt;That required strengthening some of the existing proofs to talk about clean shutdowns, not just the connection never being closed, but it was fairly straight-forward.&lt;/p&gt;
    &lt;head rend="h3"&gt;End-to-end liveness&lt;/head&gt;
    &lt;p&gt;I used the &lt;code&gt;ReadLimit&lt;/code&gt; and &lt;code&gt;WriteLimit&lt;/code&gt; lemmas to prove some things about the system as a whole, e.g.&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;and was then finally able to prove my improved version of &lt;code&gt;Availability&lt;/code&gt;:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;1
&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;See vchan.tla for the final version with the proofs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Work-arounds for bugs&lt;/head&gt;
    &lt;p&gt;The biggest problem I had was the bug when mixing forall and temporal formulas, until I found the work-around above. Here are some other problems I hit and their solutions:&lt;/p&gt;
    &lt;head rend="h3"&gt;SUFFICES doesn't always generalise&lt;/head&gt;
    &lt;p&gt;This doesn't work:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5 6&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Even though the &lt;code&gt;SUFFICES&lt;/code&gt; used &lt;code&gt;BY DEF Foo&lt;/code&gt;, &lt;code&gt;Foo&lt;/code&gt; still counts as a time-specific assumption.
A work-around is to &lt;code&gt;ASSUME []Foo&lt;/code&gt; and then assert &lt;code&gt;Foo&lt;/code&gt; in a separate step:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5 6 7&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;CASE with a temporal goal&lt;/head&gt;
    &lt;p&gt;This doesn't work:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;It fails to parse, with &lt;code&gt;Non-constant CASE for temporal goal&lt;/code&gt;.
However, if you replace &lt;code&gt;CASE&lt;/code&gt; with the expanded form then it works:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;PTL and primes&lt;/head&gt;
    &lt;p&gt;This doesn't work:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;A work-around:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Syntax matters&lt;/head&gt;
    &lt;p&gt;Things you might expect to be the same after parsing are treated differently. This fails:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;But this passes:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;quote&gt;1 2 3 4 5&lt;/quote&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Other bugs&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;If keyboard short-cuts stop working, move the focus out of the window and back in again. Sometimes some keys stop working (e.g. Delete) while others continue (e.g. Backspace).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;If the toolbox GUI fails to launch the prover due to&lt;/p&gt;&lt;code&gt;NullPointerException&lt;/code&gt;, try closing the specification and reopening it.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The solver doesn't actually tell you if everything passed; you have to look in the scrollbar for little red regions. If a theorem is folded in the editor, the top-level bit will still show as red if any sub-step fails, but it will NOT appear in the scrollbar! Either expand everything and check by eye, or run&lt;/p&gt;&lt;code&gt;tlapm&lt;/code&gt;from the command-line as a final check. Note that the bright green&lt;code&gt;Spec Status&lt;/code&gt;indicator in the status bar only means that parsing the spec succeeded, not that the proof-checking passed.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Conclusions&lt;/head&gt;
    &lt;p&gt;Checking the specification with TLC was quick and easy and immediately found the shutdown bug. Actually proving the specification correct using TLAPS was much more difficult, took way longer, and didn't uncovered any additional bugs. It did reveal a mistake in my definition of &lt;code&gt;Availability&lt;/code&gt;, but there are surely quicker ways of finding that.
So, in terms of value for time spent, I guess it's only worth it for very high-value code
(or if, like me, you just like proving stuff for fun).&lt;/p&gt;
    &lt;p&gt;However, I think it's good to know how to verify things, even if you don't usually do it. It has certainly made me think more carefully about exactly what you need to check to verify liveness.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46471699</guid><pubDate>Sat, 03 Jan 2026 01:15:54 +0000</pubDate></item><item><title>A Basic Just-In-Time Compiler (2015)</title><link>https://nullprogram.com/blog/2015/03/19/</link><description>&lt;doc fingerprint="2e629a9dea369a89"&gt;
  &lt;main&gt;
    &lt;p&gt; nullprogram.com/blog/2015/03/19/ &lt;/p&gt;
    &lt;p&gt; (The author is currently open to employment opportunities in the United States.) &lt;/p&gt;
    &lt;p&gt;This article was discussed on Hacker News and on reddit.&lt;/p&gt;
    &lt;p&gt;Monday’s /r/dailyprogrammer challenge was to write a program to read a recurrence relation definition and, through interpretation, iterate it to some number of terms. It’s given an initial term (&lt;code&gt;u(0)&lt;/code&gt;) and a sequence of operations, &lt;code&gt;f&lt;/code&gt;, to apply to the previous
term (&lt;code&gt;u(n + 1) = f(u(n))&lt;/code&gt;) to compute the next term. Since it’s an
easy challenge, the operations are limited to addition, subtraction,
multiplication, and division, with one operand each.&lt;/p&gt;
    &lt;p&gt;For example, the relation &lt;code&gt;u(n + 1) = (u(n) + 2) * 3 - 5&lt;/code&gt; would be
input as &lt;code&gt;+2 *3 -5&lt;/code&gt;. If &lt;code&gt;u(0) = 0&lt;/code&gt; then,&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;u(1) = 1&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;u(2) = 4&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;u(3) = 13&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;u(4) = 40&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;u(5) = 121&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;…&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Rather than write an interpreter to apply the sequence of operations, for my submission (mirror) I took the opportunity to write a simple x86-64 Just-In-Time (JIT) compiler. So rather than stepping through the operations one by one, my program converts the operations into native machine code and lets the hardware do the work directly. In this article I’ll go through how it works and how I did it.&lt;/p&gt;
    &lt;p&gt;Update: The follow-up challenge uses Reverse Polish notation to allow for more complicated expressions. I wrote another JIT compiler for my submission (mirror).&lt;/p&gt;
    &lt;head rend="h3"&gt;Allocating Executable Memory&lt;/head&gt;
    &lt;p&gt;Modern operating systems have page-granularity protections for different parts of process memory: read, write, and execute. Code can only be executed from memory with the execute bit set on its page, memory can only be changed when its write bit is set, and some pages aren’t allowed to be read. In a running process, the pages holding program code and loaded libraries will have their write bit cleared and execute bit set. Most of the other pages will have their execute bit cleared and their write bit set.&lt;/p&gt;
    &lt;p&gt;The reason for this is twofold. First, it significantly increases the security of the system. If untrusted input was read into executable memory, an attacker could input machine code (shellcode) into the buffer, then exploit a flaw in the program to cause control flow to jump to and execute that code. If the attacker is only able to write code to non-executable memory, this attack becomes a lot harder. The attacker has to rely on code already loaded into executable pages (return-oriented programming).&lt;/p&gt;
    &lt;p&gt;Second, it catches program bugs sooner and reduces their impact, so there’s less chance for a flawed program to accidentally corrupt user data. Accessing memory in an invalid way will causes a segmentation fault, usually leading to program termination. For example, &lt;code&gt;NULL&lt;/code&gt;
points to a special page with read, write, and execute disabled.&lt;/p&gt;
    &lt;head rend="h4"&gt;An Instruction Buffer&lt;/head&gt;
    &lt;p&gt;Memory returned by &lt;code&gt;malloc()&lt;/code&gt; and friends will be writable and
readable, but non-executable. If the JIT compiler allocates memory
through &lt;code&gt;malloc()&lt;/code&gt;, fills it with machine instructions, and jumps to
it without doing any additional work, there will be a segmentation
fault. So some different memory allocation calls will be made instead,
with the details hidden behind an &lt;code&gt;asmbuf&lt;/code&gt; struct.&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;#define PAGE_SIZE 4096

struct asmbuf {
    uint8_t code[PAGE_SIZE - sizeof(uint64_t)];
    uint64_t count;
};
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;To keep things simple here, I’m just assuming the page size is 4kB. In a real program, we’d use &lt;code&gt;sysconf(_SC_PAGESIZE)&lt;/code&gt; to discover the page
size at run time. On x86-64, pages may be 4kB, 2MB, or 1GB, but this
program will work correctly as-is regardless.&lt;/p&gt;
    &lt;p&gt;Instead of &lt;code&gt;malloc()&lt;/code&gt;, the compiler allocates memory as an anonymous
memory map (&lt;code&gt;mmap()&lt;/code&gt;). It’s anonymous because it’s not backed by a
file.&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;struct asmbuf *
asmbuf_create(void)
{
    int prot = PROT_READ | PROT_WRITE;
    int flags = MAP_ANONYMOUS | MAP_PRIVATE;
    return mmap(NULL, PAGE_SIZE, prot, flags, -1, 0);
}
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Windows doesn’t have POSIX &lt;code&gt;mmap()&lt;/code&gt;, so on that platform we use
&lt;code&gt;VirtualAlloc()&lt;/code&gt; instead. Here’s the equivalent in Win32.&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;struct asmbuf *
asmbuf_create(void)
{
    DWORD type = MEM_RESERVE | MEM_COMMIT;
    return VirtualAlloc(NULL, PAGE_SIZE, type, PAGE_READWRITE);
}
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Anyone reading closely should notice that I haven’t actually requested that the memory be executable, which is, like, the whole point of all this! This was intentional. Some operating systems employ a security feature called W^X: “write xor execute.” That is, memory is either writable or executable, but never both at the same time. This makes the shellcode attack I described before even harder. For well-behaved JIT compilers it means memory protections need to be adjusted after code generation and before execution.&lt;/p&gt;
    &lt;p&gt;The POSIX &lt;code&gt;mprotect()&lt;/code&gt; function is used to change memory protections.&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;void
asmbuf_finalize(struct asmbuf *buf)
{
    mprotect(buf, sizeof(*buf), PROT_READ | PROT_EXEC);
}
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Or on Win32 (that last parameter is not allowed to be &lt;code&gt;NULL&lt;/code&gt;),&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;void
asmbuf_finalize(struct asmbuf *buf)
{
    DWORD old;
    VirtualProtect(buf, sizeof(*buf), PAGE_EXECUTE_READ, &amp;amp;old);
}
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Finally, instead of &lt;code&gt;free()&lt;/code&gt; it gets unmapped.&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;void
asmbuf_free(struct asmbuf *buf)
{
    munmap(buf, PAGE_SIZE);
}
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;And on Win32,&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;void
asmbuf_free(struct asmbuf *buf)
{
    VirtualFree(buf, 0, MEM_RELEASE);
}
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;I won’t list the definitions here, but there are two “methods” for inserting instructions and immediate values into the buffer. This will be raw machine code, so the caller will be acting a bit like an assembler.&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;asmbuf_ins(struct asmbuf *, int size, uint64_t ins);
asmbuf_immediate(struct asmbuf *, int size, const void *value);
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;head rend="h3"&gt;Calling Conventions&lt;/head&gt;
    &lt;p&gt;We’re only going to be concerned with three of x86-64’s many registers: &lt;code&gt;rdi&lt;/code&gt;, &lt;code&gt;rax&lt;/code&gt;, and &lt;code&gt;rdx&lt;/code&gt;. These are 64-bit (&lt;code&gt;r&lt;/code&gt;) extensions
of the original 16-bit 8086 registers. The sequence of
operations will be compiled into a function that we’ll be able to call
from C like a normal function. Here’s what it’s prototype will look
like. It takes a signed 64-bit integer and returns a signed 64-bit
integer.&lt;/p&gt;
    &lt;p&gt;The System V AMD64 ABI calling convention says that the first integer/pointer function argument is passed in the &lt;code&gt;rdi&lt;/code&gt; register.
When our JIT compiled program gets control, that’s where its input
will be waiting. According to the ABI, the C program will be expecting
the result to be in &lt;code&gt;rax&lt;/code&gt; when control is returned. If our recurrence
relation is merely the identity function (it has no operations), the
only thing it will do is copy &lt;code&gt;rdi&lt;/code&gt; to &lt;code&gt;rax&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;There’s a catch, though. You might think all the mucky platform-dependent stuff was encapsulated in &lt;code&gt;asmbuf&lt;/code&gt;. Not quite. As
usual, Windows is the oddball and has its own unique calling
convention. For our purposes here, the only difference is that the
first argument comes in &lt;code&gt;rcx&lt;/code&gt; rather than &lt;code&gt;rdi&lt;/code&gt;. Fortunately this only
affects the very first instruction and the rest of the assembly
remains the same.&lt;/p&gt;
    &lt;p&gt;The very last thing it will do, assuming the result is in &lt;code&gt;rax&lt;/code&gt;, is
return to the caller.&lt;/p&gt;
    &lt;p&gt;So we know the assembly, but what do we pass to &lt;code&gt;asmbuf_ins()&lt;/code&gt;? This
is where we get our hands dirty.&lt;/p&gt;
    &lt;head rend="h4"&gt;Finding the Code&lt;/head&gt;
    &lt;p&gt;If you want to do this the Right Way, you go download the x86-64 documentation, look up the instructions we’re using, and manually work out the bytes we need and how the operands fit into it. You know, like they used to do out of necessity back in the 60’s.&lt;/p&gt;
    &lt;p&gt;Fortunately there’s a much easier way. We’ll have an actual assembler do it and just copy what it does. Put both of the instructions above in a file &lt;code&gt;peek.s&lt;/code&gt; and hand it to &lt;code&gt;nasm&lt;/code&gt;. It will produce a raw binary
with the machine code, which we’ll disassemble with &lt;code&gt;nidsasm&lt;/code&gt; (the
NASM disassembler).&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;$ nasm peek.s
$ ndisasm -b64 peek
00000000  4889F8            mov rax,rdi
00000003  C3                ret
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;That’s straightforward. The first instruction is 3 bytes and the return is 1 byte.&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;asmbuf_ins(buf, 3, 0x4889f8);  // mov   rax, rdi
// ... generate code ...
asmbuf_ins(buf, 1, 0xc3);      // ret
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;For each operation, we’ll set it up so the operand will already be loaded into &lt;code&gt;rdi&lt;/code&gt; regardless of the operator, similar to how the
argument was passed in the first place. A smarter compiler would embed
the immediate in the operator’s instruction if it’s small (32-bits or
fewer), but I’m keeping it simple. To sneakily capture the “template”
for this instruction I’m going to use &lt;code&gt;0x0123456789abcdef&lt;/code&gt; as the
operand.&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;mov   rdi, 0x0123456789abcdef
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Which disassembled with &lt;code&gt;ndisasm&lt;/code&gt; is,&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;00000000  48BFEFCDAB896745  mov rdi,0x123456789abcdef
         -2301
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Notice the operand listed little endian immediately after the instruction. That’s also easy!&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;long operand;
scanf("%ld", &amp;amp;operand);
asmbuf_ins(buf, 2, 0x48bf);         // mov   rdi, operand
asmbuf_immediate(buf, 8, &amp;amp;operand);
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Apply the same discovery process individually for each operator you want to support, accumulating the result in &lt;code&gt;rax&lt;/code&gt; for each.&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;switch (operator) {
    case '+':
        asmbuf_ins(buf, 3, 0x4801f8);   // add   rax, rdi
        break;
    case '-':
        asmbuf_ins(buf, 3, 0x4829f8);   // sub   rax, rdi
        break;
    case '*':
        asmbuf_ins(buf, 4, 0x480fafc7); // imul  rax, rdi
        break;
    case '/':
        asmbuf_ins(buf, 3, 0x4831d2);   // xor   rdx, rdx
        asmbuf_ins(buf, 3, 0x48f7ff);   // idiv  rdi
        break;
}
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;As an exercise, try adding support for modulus operator (&lt;code&gt;%&lt;/code&gt;), XOR
(&lt;code&gt;^&lt;/code&gt;), and bit shifts (&lt;code&gt;&amp;lt;&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;). With the addition of these
operators, you could define a decent PRNG as a recurrence relation. It
will also eliminate the closed form solution to this problem so
that we actually have a reason to do all this! Or, alternatively,
switch it all to floating point.&lt;/p&gt;
    &lt;head rend="h3"&gt;Calling the Generated Code&lt;/head&gt;
    &lt;p&gt;Once we’re all done generating code, finalize the buffer to make it executable, cast it to a function pointer, and call it. (I cast it as a &lt;code&gt;void *&lt;/code&gt; just to avoid repeating myself, since that will implicitly
cast to the correct function pointer prototype.)&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;asmbuf_finalize(buf);
long (*recurrence)(long) = (void *)buf-&amp;gt;code;
// ...
x[n + 1] = recurrence(x[n]);
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;That’s pretty cool if you ask me! Now this was an extremely simplified situation. There’s no branching, no intermediate values, no function calls, and I didn’t even touch the stack (push, pop). The recurrence relation definition in this challenge is practically an assembly language itself, so after the initial setup it’s a 1:1 translation.&lt;/p&gt;
    &lt;p&gt;I’d like to build a JIT compiler more advanced than this in the future. I just need to find a suitable problem that’s more complicated than this one, warrants having a JIT compiler, but is still simple enough that I could, on some level, justify not using LLVM.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46471712</guid><pubDate>Sat, 03 Jan 2026 01:18:07 +0000</pubDate></item><item><title>Einstein Probe detects an X-ray flare from nearby star</title><link>https://phys.org/news/2025-12-einstein-probe-ray-flare-nearby.html</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46471784</guid><pubDate>Sat, 03 Jan 2026 01:29:09 +0000</pubDate></item><item><title>Adventure 751 (1980)</title><link>https://bluerenga.blog/2026/01/01/adventure-751-1980/</link><description>&lt;doc fingerprint="351c59d775a584fd"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;COME WITH ME TO COLOSSAL CAVE. WHERE MAGIC ABOUNDS AND TREASURES ARE FOUND. BID YOUR FINGERS FOLLOW YOUR COMMANDS AND I WILL BE YOUR EYES AND HANDS. YET BEWARE THE FIERY DRAGON, FOR HE KNOWS NOT WHETHER YOU ARE WIZARD OR SIMPLE CHARLATAN!&lt;/p&gt;
      &lt;p&gt;HOW BEST TO CONQUER COLOSSAL CAVE? WITH DARING AND SKILL … OH CLEVER KNAVE!&lt;/p&gt;
      &lt;p&gt;— Early 80s Adventure poster, from the CompuServe Incorporated Information Service Division&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Adventure 751 has been, by my reckoning, the most sought-after variation of Crowther/Woods Adventure. It was generally available on the online portal CompuServe from nearly the beginning of the service and it disappeared when they shut down their games in the 90s. Arthur O’Dwyer started a web page in 2012 (with semi-regular updates!) dedicated to hunting down a copy.&lt;/p&gt;
    &lt;p&gt;To finish off a wild 2025 in game preservation, Arthur O’Dwyer announced the game has been found (by LanHawk, a regular amongst the comments here) and is playable.&lt;/p&gt;
    &lt;p&gt;In 1958, the Electrical Engineering Department of the University of Arizona in Tucson received a donation of equipment in order to form an Analog Computer Laboratory. Analog computers deal with full electrical signals rather than 0s and 1s (think music on record vs. on computer). These could do particular computations (like differential equations) faster than digital devices of the time.&lt;/p&gt;
    &lt;p&gt;The University of Arizona’s lab was more cobbled-together than the for-sale-new device depicted above, as they made “two small but flexible computers complete with homemade removable patchboards” to start with but quite quickly changed mission to be a hybrid laboratory. By hybrid, I don’t mean just having digital and analog computers side-by-side, but trying to make computers that use both digital and analog components. Their name officially became The University of Arizona Analog/Hybrid Computer Laboratory. Designs included the “ASTRAC I”, a “iterative differential analyzer”, “APE 1”, a “teaching aid in statistics” that followed a similar design, and an “ASTRAC II” which was now “solid state” and “ultra-fast” and was supported by both the Air Force and NASA.&lt;/p&gt;
    &lt;p&gt;(Warning: My next three paragraphs consolidate three different accounts which differ somewhat.)&lt;/p&gt;
    &lt;p&gt;Three of the students in the 1969-1970 school year were Alexander B. Trevor, John Goltz and Jeff Wilkins. The trio were discussing the possibility of starting a time-sharing company. This was a little late to the game; Dartmouth with General Electric had developed the concept in the early 60s (where a large computer could have its time split into many parts allowing for multiple computers connected; including remote connections Dartmouth had thousands) and by the time Trevor, Goltz, and Wilkins came to the idea there were other companies like Tymshare and National CSS involved.&lt;/p&gt;
    &lt;p&gt;Jeff Wilkins’s father-in-law, Harry Gard, Sr., was a co-founder of Golden United Life Insurance; at the time the insurance company was still getting their computing via other companies, but Gard was keen on Golden United having a computer of their own. The original intent was to buy a mini-computer like the PDP-15 but Goltz (who was working with Wilkins and doing the purchase through DEC) got a call that he could have a KA-10 for just “a little more” (one of the PDP-10s, a full mainframe rather than minicomputer). While Goltz was an engineer and not a salesperson, John Goltz managed to persuade the board of Golden United to part with the money for the upgrade. This enabled the computer to more feasibly do time-sharing with many customers.&lt;/p&gt;
    &lt;p&gt;After graduating Wilkins moved to Columbus (followed by Goltz; Trevor was drafted to the Army so didn’t join them until ’71) to be at Golden United’s new spin-off, CompuServe; Wilkins at the age of 27 became President. Their first developed product was LIDIS (Life Insurance Data Information System); there were plenty of life insurance companies in Columbus to sell to.&lt;/p&gt;
    &lt;p&gt;The company had rapid success; by 1973 they moved to a new building, and by 1974 had not one but seven mainframes “and were using them not only to support a thriving time sharing business, but also to heat our office buildings.” CompuServe stayed with corporate clients, although Wilkins was alert to trends in personal computers; he hired his brother-in-law to track computer magazine news, given the fact most of the operations done by time-sharing could be done more easily with PCs.&lt;/p&gt;
    &lt;p&gt;One of those personal computers was the TRS-80, launching in 1977 as part of the “Trinity” with the Commodore PET and Apple II from the same year. The TRS-80 was sold through Radio Shack stores that were already well-established across the nation, but it was still difficult to move product when the concept of a personal computer was only a vague notion to many buyers. A Radio Shack manager in Columbus named Bill Louden bought one of the early models (serial model 10) as Radio Shack refused to give out demo units; his purchase became the only demo available in the Midwest and people wanting to experience a TRS-80 went specifically to Columbus, driving and even flying in.&lt;/p&gt;
    &lt;p&gt;Simultaneous to this, Wilkins was watching the new market for “modems” which connected personal computers to networks via the phone. He also had computers sitting idle by night (as businesses using them were running them during the day); since he already had the resources, it would be a straightforward matter to have a new commercial-facing venture.&lt;/p&gt;
    &lt;p&gt;Wilkins thus laid out in 1978 an idea for a new product based on European Videotex services. Videotex is its own rabbit hole that I’m not going to touch on much here; starting in the mid-70s there were experiments with turning televisions into networked services.&lt;/p&gt;
    &lt;p&gt;The important point here is that the “television as an appliance” thought process was being applied to make “computer as an appliance” and this would help interest computing to the masses. Wilkins launched a new service MicroNET (“to get microcomputer owners’ attention and suggest the power of the computer network”) and tapped the previously mentioned Midwest Computer Club for a “beta-test”.&lt;/p&gt;
    &lt;p&gt;The test service was launched for free; Bill Louden called it “a hacker’s dream” and a good way to sell modems (110 and 300 baud). Quoting Bill:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We had access to many of the DEC-10’s features, storage, and better processing power, but of most significance we had started using two programs: One was a store-and-forward messaging system, called Infoplex, which allowed us to share text message files with one another even if we were not online at the same time. The other was a modified version of a program that allowed a user to send a live one-line text message to the CompuServe system operator. Our version, modified by Russ Ranshaw of CompuServe, allowed us to send one-line live messages to each other if we saw one another online. We called it the SEND program.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It had all the regular offerings later associated with CompuServe, including games. Both Star Trek and Adventure were available (this is before Microsoft Adventure came out, so it was the original mainframe version). Eventually in the early 1979 a price structure was added: $9 startup, prime time use $12 per hour, non-prime time use $5 per hour, 300 baud more expensive as a “premium” service. Q2 revenues in 1979 were $4.2 million; this was almost a rounding error in the scheme of the business as a whole, but of course personal computers were about to hit the time-sharing companies with fatal blows.&lt;/p&gt;
    &lt;p&gt;A competitor, The Source, was launched in 1979 but “from scratch” by the entrepreneur William F. von Meister (that is, not piggybacking off an existing time-sharing business). Their main relevance to the story here is not only did they have games (the usual like Star Trek) they also tapped Dartmouth College to work on new games. (Remember these are being developed for mainframes or minicomputers, so we’re not talking about typical personal computer programmers! Hence work being drawn from colleges with access.)&lt;/p&gt;
    &lt;p&gt;I don’t have an official notice of solicitation — it may even have come via word of mouth — but CompuServe also must have had contact with mainframe/minicomputer sites in order to get their own games. A 1984 games catalog lists House of Banshi, which is simply Dungeon/Zork (“CompuServe’s rendition of the original game of ZORK.”) Dor Sageth from the catalog is another famous “lost game” which started life on an institutional computer (mentioned by Jason Scott back in 2011). Listed on page 2 is both “Original Adventure” (as the service launched with) and “New Adventure”.&lt;/p&gt;
    &lt;p&gt;In 1977, David Long went to the University of Chicago to work as a computer operator. The college had just bought two of the newest computers from DEC, the PDP-20. One was for general use by the college and the other was for specifically the Graduate School of Business; Long “tended to work 50-60 hours a week on GSB stuff”. 1977 was also the year the “standard” Crowther/Woods Adventure was finalized, and David Long was able to get a copy direct from the author:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Don was kind enough to transmit the source program to the present author in mid-1977.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;As he notes, given his work schedule, and the time he spent with GSB affairs, “no one cared if I spent another 10-20 hours on Adventure”. He finished “Adventure 501” by November 1978:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;You are inside a building, a well house for a large spring. Off to one side is a small pantry.&lt;/p&gt;
      &lt;p&gt;There is a shiny brass lamp nearby.&lt;/p&gt;
      &lt;p&gt;There is a leather sack here.&lt;/p&gt;
      &lt;p&gt;Taped to the wall is a faded poster.&lt;/p&gt;
      &lt;p&gt;READ POSTER&lt;/p&gt;
      &lt;p&gt;The poster has a picture of a thin man with a long white beard. He is wearing a high pointed cap embroidered with strange symbols, and he is pointing a finger at you. Below the picture are the words: “I want you!–To report all good ideas for extensions to this game to me without delay. Remember: ask not what ADVENTURE can do to you; ask what you can do for ADVENTURE.”&lt;/p&gt;
      &lt;p&gt;“A public service of the John Dillinger Died for You Society.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;A safe is hiding behind the poster. Found treasures get dropped in the safe rather than on the ground.&lt;/p&gt;
    &lt;p&gt;I’ve played Adventure 501 before; a version had been available for some time (with the mysterious addition of a spider, which isn’t Long’s). The archive LanHawk extracted also includes the authentic ’78 version of Adventure 501, so I was able to cross-check with what I already played.&lt;/p&gt;
    &lt;p&gt;Further expansions eventually led to a “version 6” in January of 1980, including a new area as well as an “improved syntax parser”. (More on the parser later.) An in game “billboard” gives version updates:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;( 19-Jan-1980 ) Congratulations to Robert Silverman, the first adventurer to set foot in the Courtyard of Aldor’s Castle.&lt;/p&gt;
      &lt;p&gt;( 25-Feb-1980 ) Adventurers may now enter the Castle Keep, although construction continues within. Some scoring bugs have been fixed.&lt;/p&gt;
      &lt;p&gt;Who will be first to discover the secret of the black bird?&lt;/p&gt;
      &lt;p&gt;( 3-Mar-1980 ) There is a slight bug on the perfume. For full score, you must drop it somewhere, look, and take it again.&lt;/p&gt;
      &lt;p&gt;( 7-Mar-1980 ) 6.04 is released. Expansion of the castle continues — it is far from complete. Several unique new features and puzzles have recently been designed and are now being implemented.&lt;/p&gt;
      &lt;p&gt;The format of most hints has been altered. I hope you agree that the new hints are more in keeping with the flavor of the game.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The game I’m referring to as “Adventure 751” seems to have been entirely wrapped up by the end of the school year. Sometime before the end of the calendar year Long sold the game to CompuServe for “a thousand dollars”. (As they used the PDP-10/20 like Long did, no conversion work was needed and they could run the executable without compilation.) Long seems to have been somewhat protective of his source code so distribution past that point was relatively minimal, although he did give source copies of both 501 and 751 to the Illinois Institute of Technology. (See, comparatively: Woods and his regret freely sending out Adventure 350 to anyone who asked, making it so that when he wrote “v2.0” he was much more careful who had access.)&lt;/p&gt;
    &lt;p&gt;The parser is “improved” over both Adventure 350 and Adventure 501. There is some sense of trying to “outdo Zork”. (See relatedly: Warp bragging about its own system, and Synapse Software calling their system BTZ or “Better Than Zork”.) Quoting Long:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;…Dungeon (Zork) and Adventure-6 were developed almost completely independently. The advanced parser, the object containment facility, and virtually all the game puzzles were designed and implemented prior to our receiving any version of Dungeon. With all due modesty (none), I will point out that Adventure’s containment facility is at least as powerful as Dungeon’s, if not more so, since Adventure’s facility permits searching for contained objects in open containers down to any desired level of containment. Further, the parser permits a few constructs not currently permitted in Dungeon (at least in the version we have at U.C.), such as permitting any number of objects (up to some limits imposed by compiled array sizes) to be specified following transitive verbs. In addition, Adventure’s parser can handle multiple verb constructs such as “GET AND THROW AXE” properly. Finally, Adventure’s parser is slightly better about doing the right things with the various applications of the group words “ALL” and “TREASURES”. A planned enhancement for Release 7 will permit such constructs as “PUSH ALL OF THE BUTTONS” or “TAKE BOTH SACKS”, etc.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;GET AND THROW AXE is uncommon even in modern parsers. Trying to GET AND THROW BREAD in Savoir-Faire (2002) gets the response “You can’t see any such thing.”&lt;/p&gt;
    &lt;p&gt;Dennis Donovan (of CompuServe) made a map in November of 1980 which Arthur O’Dwyer scanned in high resolution with some image cleanup by James Lindell Dean, so I’m going to use it to illustrate the journey.&lt;/p&gt;
    &lt;p&gt;Arthur tested the build with a walkthrough that has been around for a while to confirm this is indeed the “real” Adventure 751; I’m going to play it normally. I am re-mapping the 501 content although I am allowing myself to look at my old posts if I need to; you can also squint at a blurry version of my 501 map where the blue rooms are extensions to Adventure 350.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;You are standing at the end of a road before a small brick building. Around you is a forest. A small stream flows out of the building and down a gully.&lt;/p&gt;
      &lt;p&gt;GO EAST&lt;/p&gt;
      &lt;p&gt;You’re in a flat circular clearing surrounded by dense forest. Not far away is a helicopter. Its engine is idling slowly. Several jac-booted Orcs are standing guard around the aircraft.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Going east normally enters the building. Unexpected! Trying to enter gets a message about needing a flight pass.&lt;/p&gt;
    &lt;p&gt;The building is still there, but you need to use the command IN to enter, and then can go IN again to get in farther.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;You are inside a building, a well house for a large spring. Off to one side is a small storeroom.&lt;/p&gt;&lt;lb/&gt;There is a shiny brass lamp nearby.&lt;lb/&gt;There is a leather sack here.&lt;p&gt;Taped to the wall is a faded poster.&lt;/p&gt;&lt;lb/&gt;There is a small matchbox here.&lt;p&gt;IN&lt;/p&gt;&lt;p&gt;You’re in the caretaker’s storeroom.&lt;/p&gt;&lt;lb/&gt;A yellow pill-shaped tablet, as large as a doughnut, lies nearby.&lt;lb/&gt;There are some keys on the ground here.&lt;lb/&gt;There is food here.&lt;lb/&gt;There is a bottle of water here.&lt;/quote&gt;
    &lt;p&gt;Helpfully, the leather sack works as a container; keep in mind this is not a two-word parser so to operate it you need to use PUT X IN SACK. In fact, it works with multiple items at once. That is…&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;PUT TABLET AND KEYS AND FOOD AND BOTTLE IN SACK&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;…will take care of scooping up all four.&lt;/p&gt;
    &lt;p&gt;Other than the helicopter pad being different, and a slightly different building layout, there’s a new object at the grate that goes into the cave:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;You are in a 20-foot depression floored with bare dirt. Set into the dirt is a strong steel grate mounted in concrete. A dry streambed leads into the depression.&lt;/p&gt;&lt;lb/&gt;There is a large cloth bag lying nearby.&lt;lb/&gt;The grate is locked.&lt;/quote&gt;
    &lt;p&gt;The cloth bag is full of grey powder and if you EMPTY BAG it will scatter all over the place and you won’t be able to pick it up again: “Grey powder has been strewn all about.” I assume this is a softlock, simply from checking what’s inside the bag. (Crowther/Woods really was polite when it came to softlocks. It had the vase breaking when you dropped it, ruining a treasure, but the structure of the game was such that getting all the treasures was an aspirational goal rather than a requirement for having a satisfying playthrough. The various extensions, including the one from Woods himself, often were not so careful. You could eat the food early in Crowther/Woods rather than give it to the appropriate creature, but there’s a built in expectation that EAT FOOD is going to remove it from the object list; just checking what’s inside a container doesn’t suggest such a drastic change.)&lt;/p&gt;
    &lt;p&gt;I’m not going to go underground at all during this session but rather stay outside. The forest, rather than being a method to steer the player back to the caves, includes a “billboard” (as seen earlier, also in the image above) and a castle in the distance.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;You are in open forest, with a deep valley to one side. Not far off is a large billboard.&lt;/p&gt;
      &lt;p&gt;GO NORTH&lt;/p&gt;
      &lt;p&gt;You are standing behind a large billboard on a ridge above a deep valley. To the north, the forest gives way to dense swamp and then to open flatlands. Far beyond, the land rises sharply towards the impassible Misty Mountains. Nestled at the base of a distant cliff are the stone turrets of a tall white castle.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The outdoors keeps going. At least some of this area I recognize from 501, although it goes a little farther than that game did.&lt;/p&gt;
    &lt;p&gt;Going west of the building leads to a “dense forest” with some mushrooms…&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;You are in dense forest, with a hill to one side. The trees appear to thin out towards the north and east.&lt;/p&gt;&lt;lb/&gt;There are some oddly-colored mushrooms here.&lt;p&gt;GO WEST&lt;/p&gt;&lt;p&gt;You are at the high point of a wide grassy knoll, partially surrounded by dense forest. The land rises to the south and east, and drops off sharply to the north and west. The air smells of sea water.&lt;/p&gt;&lt;/quote&gt;
    &lt;p&gt;…and a sandy beach. The beach includes a “large wooden box” (the box is empty) where you can go up to find an Ocean Vista with some flowers, the first treasure I’ve found.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;You’re on sandy beach.&lt;/p&gt;&lt;lb/&gt;A large wooden box has washed up on the shore.&lt;p&gt;GO NORTH&lt;/p&gt;&lt;p&gt;You are at a jumble of large broken rocks and blackened shoals.&lt;/p&gt;&lt;lb/&gt;A gentle path leads up to the top of the nearby cliffs. A narrow treacherous path disappears among the rocks at the foot of the cliff.&lt;p&gt;GO UP&lt;/p&gt;&lt;p&gt;You are on a high cliff overlooking the sea. Far below the rolling breakers smash into a jumble of blackened shoals. The thunder of the surf is deafening.&lt;/p&gt;&lt;lb/&gt;There are some beautiful flowers here!&lt;/quote&gt;
    &lt;p&gt;The “blackened shoals” are incidentally a University of Chicago in-joke created by a friend of Long’s (Eric Weber); it refers to the professors Black and Scholes who made a famous mathematical model for financial markets. There’s an entire hour-long documentary called Trillion Dollar Bet about it (“this solved the ancient problem of risk and return in the stock market”); it is blamed for more than one market crash, including Black Monday from 1987.&lt;/p&gt;
    &lt;p&gt;This is also the location I remembered something very cruel from Adventure 501 that carries over here. Original Crowther/Woods had a limited number of “random” exits that could sometimes go somewhere else (north goes to a different forest than the normal exit, for instance); other authors basing their games off Adventure sometimes ran with this (even affecting home games, like in Phantom’s Revenge). Going north from the shoals will sometimes go to the cliff already seen, and sometimes it will go to a new room altogether. Back when I played 501 I only found the new room by referring to the CompuServe map!&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;You’re at blackened shoals.&lt;/p&gt;&lt;p&gt;GO NORTH&lt;/p&gt;&lt;p&gt;You are at Thunder Hole, a funnel shaped cavern opening onto the sea. The noise of the surf pounding against the outer rocks of the cave is amplified by the peculiar shape of the cave, causing a thunder-like booming sound to reverberate throughout the cave. Outside, a narrow path leads south towards some large rocks.&lt;/p&gt;&lt;p&gt;GO EAST&lt;/p&gt;&lt;p&gt;You are in a dimly lit passage behind Thunder Hole. Etched into the rock wall are the ominous words:&lt;/p&gt;&lt;p&gt;You are approaching the River Styx.&lt;/p&gt;&lt;lb/&gt;Lasciate Ogni Speranza Voi Ch’Entrate.&lt;p&gt;A hideous black dog bares his teeth and growls at your approach.&lt;/p&gt;&lt;/quote&gt;
    &lt;p&gt;I do not remember the method for getting by the dog. I assume I need to go underground first. (I’m pretty sure all of this is 501 territory, though.)&lt;/p&gt;
    &lt;p&gt;If instead of heading west to the beach you head north from the mushrooms/grassy knoll, you arrive at some “salt flats”.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;You’re on grassy knoll.&lt;/p&gt;&lt;p&gt;A tiny little man dressed all in green runs straight at you, shouts “Phuce!”, aims a kick squarely at your kneecap, misses, and disappears into the forest.&lt;/p&gt;&lt;p&gt;GO NORTH&lt;/p&gt;&lt;p&gt;You are at the edge of a trackless salt marsh. Tall reeds obscure the view. In the mud is the partial word “-RO–O”. The missing letters have been washed away by the tide.&lt;/p&gt;&lt;lb/&gt;A wooden pole has been stuck in the mud here.&lt;/quote&gt;
    &lt;p&gt;I’m not sure what the tiny man is about, yet. Saying phuce gets the response “nothing happens.”&lt;/p&gt;
    &lt;p&gt;The salt flats are a maze that lead up to a swamp which is just a continuation of the maze.&lt;/p&gt;
    &lt;p&gt;Notice there’s a.) two “dead end” rooms which aren’t really dead ends and b.) one “death exit” from one of the swamp rooms which just kills you for going a particular direction (“You’ve wandered into a quicksand pit and drowned.”). Neither of these are polite and neither of these are used in Crowther/Woods (you could die walking in the dark by falling in a pit, but this was well-telegraphed by the game).&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;You are at the edge of an open area of wet sand. The dense foliage appears to grow thinner towards the northeast. A small sign stuck in the muck reads: “Site of Proposed Municipal Parking Lot — D.M. Witt, Contractor.”&lt;/p&gt;&lt;lb/&gt;Foul smelling gasses bubble up through the wet sand.&lt;/quote&gt;
    &lt;p&gt;This room has multiple death-exits, which is obnoxious given the restore-a-save procedure (where you need to decline resurrection, leave the game, restart the game, decline instructions, RESUME to load as save, confirm you are loading a save game, and then finally type what you named the save). I think this is all a dead end although I haven’t checked every exit as of yet (see: obnoxious restore-a-save procedure).&lt;/p&gt;
    &lt;p&gt;I believe from here I’ll need to plunge underground, so this seems like a good place to pause for now since I know that’s going to open things wide up. Happy 2026!&lt;/p&gt;
    &lt;p&gt;(If you still haven’t read it, be sure to check out Arthur O’Dwyer’s post; he is planning a follow-up which hacks a bit more at the data. Also thanks to Ethan Johnson for some source assistance.)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46472230</guid><pubDate>Sat, 03 Jan 2026 02:38:06 +0000</pubDate></item><item><title>IQuest-Coder: A new open-source code model beats Claude Sonnet 4.5 and GPT 5.1 [pdf]</title><link>https://github.com/IQuestLab/IQuest-Coder-V1/blob/main/papers/IQuest_Coder_Technical_Report.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46472667</guid><pubDate>Sat, 03 Jan 2026 04:01:03 +0000</pubDate></item></channel></rss>