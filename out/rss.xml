<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 27 Dec 2025 17:38:00 +0000</lastBuildDate><item><title>How uv got so fast</title><link>https://nesbitt.io/2025/12/26/how-uv-got-so-fast.html</link><description>&lt;doc fingerprint="a778f61f8d52f750"&gt;
  &lt;main&gt;
    &lt;p&gt;uv installs packages faster than pip by an order of magnitude. The usual explanation is ‚Äúit‚Äôs written in Rust.‚Äù That‚Äôs true, but it doesn‚Äôt explain much. Plenty of tools are written in Rust without being notably fast. The interesting question is what design decisions made the difference.&lt;/p&gt;
    &lt;p&gt;Charlie Marsh‚Äôs Jane Street talk and a Xebia engineering deep-dive cover the technical details well. The interesting parts are the design decisions: standards that enable fast paths, things uv drops that pip supports, and optimizations that don‚Äôt require Rust at all.&lt;/p&gt;
    &lt;head rend="h2"&gt;The standards that made uv possible&lt;/head&gt;
    &lt;p&gt;pip‚Äôs slowness isn‚Äôt a failure of implementation. For years, Python packaging required executing code to find out what a package needed.&lt;/p&gt;
    &lt;p&gt;The problem was setup.py. You couldn‚Äôt know a package‚Äôs dependencies without running its setup script. But you couldn‚Äôt run its setup script without installing its build dependencies. PEP 518 in 2016 called this out explicitly: ‚ÄúYou can‚Äôt execute a setup.py file without knowing its dependencies, but currently there is no standard way to know what those dependencies are in an automated fashion without executing the setup.py file.‚Äù&lt;/p&gt;
    &lt;p&gt;This chicken-and-egg problem forced pip to download packages, execute untrusted code, fail, install missing build tools, and try again. Every install was potentially a cascade of subprocess spawns and arbitrary code execution. Installing a source distribution was essentially &lt;code&gt;curl | bash&lt;/code&gt; with extra steps.&lt;/p&gt;
    &lt;p&gt;The fix came in stages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PEP 518 (2016) created pyproject.toml, giving packages a place to declare build dependencies without code execution. The TOML format was borrowed from Rust‚Äôs Cargo, which makes a Rust tool returning to fix Python packaging feel less like coincidence.&lt;/item&gt;
      &lt;item&gt;PEP 517 (2017) separated build frontends from backends, so pip didn‚Äôt need to understand setuptools internals.&lt;/item&gt;
      &lt;item&gt;PEP 621 (2020) standardized the &lt;code&gt;[project]&lt;/code&gt;table, so dependencies could be read by parsing TOML rather than running Python.&lt;/item&gt;
      &lt;item&gt;PEP 658 (2022) put package metadata directly in the Simple Repository API, so resolvers could fetch dependency information without downloading wheels at all.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;PEP 658 went live on PyPI in May 2023. uv launched in February 2024. uv could be fast because the ecosystem finally had the infrastructure to support it. A tool like uv couldn‚Äôt have shipped in 2020. The standards weren‚Äôt there yet.&lt;/p&gt;
    &lt;p&gt;Other ecosystems figured this out earlier. Cargo has had static metadata from the start. npm‚Äôs package.json is declarative. Python‚Äôs packaging standards finally bring it to parity.&lt;/p&gt;
    &lt;head rend="h2"&gt;What uv drops&lt;/head&gt;
    &lt;p&gt;Speed comes from elimination. Every code path you don‚Äôt have is a code path you don‚Äôt wait for.&lt;/p&gt;
    &lt;p&gt;uv‚Äôs compatibility documentation is a list of things it doesn‚Äôt do:&lt;/p&gt;
    &lt;p&gt;No .egg support. Eggs were the pre-wheel binary format. pip still handles them; uv doesn‚Äôt even try. The format has been obsolete for over a decade.&lt;/p&gt;
    &lt;p&gt;No pip.conf. uv ignores pip‚Äôs configuration files entirely. No parsing, no environment variable lookups, no inheritance from system-wide and per-user locations.&lt;/p&gt;
    &lt;p&gt;No bytecode compilation by default. pip compiles .py files to .pyc during installation. uv skips this step, shaving time off every install. You can opt in if you want it.&lt;/p&gt;
    &lt;p&gt;Virtual environments required. pip lets you install into system Python by default. uv inverts this, refusing to touch system Python without explicit flags. This removes a whole category of permission checks and safety code.&lt;/p&gt;
    &lt;p&gt;Stricter spec enforcement. pip accepts malformed packages that technically violate packaging specs. uv rejects them. Less tolerance means less fallback logic.&lt;/p&gt;
    &lt;p&gt;Ignoring requires-python upper bounds. When a package says it requires &lt;code&gt;python&amp;lt;4.0&lt;/code&gt;, uv ignores the upper bound and only checks the lower. This reduces resolver backtracking dramatically since upper bounds are almost always wrong. Packages declare &lt;code&gt;python&amp;lt;4.0&lt;/code&gt; because they haven‚Äôt tested on Python 4, not because they‚Äôll actually break. The constraint is defensive, not predictive.&lt;/p&gt;
    &lt;p&gt;First-index wins by default. When multiple package indexes are configured, pip checks all of them. uv picks from the first index that has the package, stopping there. This prevents dependency confusion attacks and avoids extra network requests.&lt;/p&gt;
    &lt;p&gt;Each of these is a code path pip has to execute and uv doesn‚Äôt.&lt;/p&gt;
    &lt;head rend="h2"&gt;Optimizations that don‚Äôt need Rust&lt;/head&gt;
    &lt;p&gt;Some of uv‚Äôs speed comes from Rust. But not as much as you‚Äôd think. Several key optimizations could be implemented in pip today:&lt;/p&gt;
    &lt;p&gt;HTTP range requests for metadata. Wheel files are zip archives, and zip archives put their file listing at the end. uv tries PEP 658 metadata first, falls back to HTTP range requests for the zip central directory, then full wheel download, then building from source. Each step is slower and riskier. The design makes the fast path cover 99% of cases. None of this requires Rust.&lt;/p&gt;
    &lt;p&gt;Parallel downloads. pip downloads packages one at a time. uv downloads many at once. Any language can do this.&lt;/p&gt;
    &lt;p&gt;Global cache with hardlinks. pip copies packages into each virtual environment. uv keeps one copy globally and uses hardlinks (or copy-on-write on filesystems that support it). Installing the same package into ten venvs takes the same disk space as one. Any language with filesystem access can do this.&lt;/p&gt;
    &lt;p&gt;Python-free resolution. pip needs Python running to do anything, and invokes build backends as subprocesses to get metadata from legacy packages. uv parses TOML and wheel metadata natively, only spawning Python when it hits a setup.py-only package that has no other option.&lt;/p&gt;
    &lt;p&gt;PubGrub resolver. uv uses the PubGrub algorithm, originally from Dart‚Äôs pub package manager. Both pip and PubGrub use backtracking, but PubGrub applies conflict-driven clause learning from SAT solvers: when it hits a dead end, it analyzes why and skips similar dead ends later. This makes it faster on complex dependency graphs and better at explaining failures. pip could adopt PubGrub without rewriting in Rust.&lt;/p&gt;
    &lt;head rend="h2"&gt;Where Rust actually matters&lt;/head&gt;
    &lt;p&gt;Some optimizations do require Rust:&lt;/p&gt;
    &lt;p&gt;Zero-copy deserialization. uv uses rkyv to deserialize cached data without copying it. The data format is the in-memory format. Libraries like FlatBuffers achieve this in other languages, but rkyv integrates tightly with Rust‚Äôs type system.1&lt;/p&gt;
    &lt;p&gt;Thread-level parallelism. Python‚Äôs GIL forces parallel work into separate processes, with IPC overhead and data copying. Rust can parallelize across threads natively, sharing memory without serialization boundaries. This matters most for resolution, where the solver explores many version combinations.1&lt;/p&gt;
    &lt;p&gt;No interpreter startup. Every time pip spawns a subprocess, it pays Python‚Äôs startup cost. uv is a single static binary with no runtime to initialize.&lt;/p&gt;
    &lt;p&gt;Compact version representation. uv packs versions into u64 integers where possible, making comparison and hashing fast. Over 90% of versions fit in one u64. This is micro-optimization that compounds across millions of comparisons.&lt;/p&gt;
    &lt;p&gt;These are real advantages. But they‚Äôre smaller than the architectural wins from dropping legacy support and exploiting modern standards.&lt;/p&gt;
    &lt;head rend="h2"&gt;Design over language&lt;/head&gt;
    &lt;p&gt;uv is fast because of what it doesn‚Äôt do, not because of what language it‚Äôs written in. The standards work of PEP 518, 517, 621, and 658 made fast package management possible. Dropping eggs, pip.conf, and permissive parsing made it achievable. Rust makes it a bit faster still.&lt;/p&gt;
    &lt;p&gt;pip could implement parallel downloads, global caching, and metadata-only resolution tomorrow. It doesn‚Äôt, largely because backwards compatibility with fifteen years of edge cases takes precedence. But it means pip will always be slower than a tool that starts fresh with modern assumptions.&lt;/p&gt;
    &lt;p&gt;Other package managers could learn from this: static metadata, no code execution to discover dependencies, and the ability to resolve everything upfront before downloading. Cargo and npm have operated this way for years. If your ecosystem requires running arbitrary code to find out what a package needs, you‚Äôve already lost.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46393992</guid><pubDate>Fri, 26 Dec 2025 17:13:07 +0000</pubDate></item><item><title>Always bet on text (2014)</title><link>https://graydon2.dreamwidth.org/193447.html</link><description>&lt;doc fingerprint="767cce1f3dd3c327"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Captcha Check&lt;/head&gt;
    &lt;p&gt;Hello, you've been (semi-randomly) selected to take a CAPTCHA to validate your requests. Please complete it below and hit the button!&lt;/p&gt;
    &lt;p&gt;Hello, you've been (semi-randomly) selected to take a CAPTCHA to validate your requests. Please complete it below and hit the button!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46397379</guid><pubDate>Fri, 26 Dec 2025 23:09:40 +0000</pubDate></item><item><title>Exe.dev</title><link>https://exe.dev/</link><description>&lt;doc fingerprint="5649e739e2d32d86"&gt;
  &lt;main&gt;
    &lt;p&gt;Login ssh exe.dev _ The disk persists. You have sudo.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46397609</guid><pubDate>Fri, 26 Dec 2025 23:42:46 +0000</pubDate></item><item><title>Publishing your work increases your luck</title><link>https://github.com/readme/guides/publishing-your-work</link><description>&lt;doc fingerprint="284a195f3fe6261d"&gt;
  &lt;main&gt;
    &lt;p&gt;No matter how hard you work, it still takes a little bit of luck for something to hit. That can be discouraging, since luck feels like a force outside our control. But the good news is that we can increase our chances of encountering good luck. That may sound like magic, but it‚Äôs not supernatural. The trick is to increase the number of opportunities we have for good fortune to find us. The simple act of publishing your work is one of the best ways to invite a little more luck into your life.&lt;/p&gt;
    &lt;p&gt;Before we get into the ‚Äúhow,‚Äù it‚Äôs important to get on the same page about the ‚Äúwhat.‚Äù What are we talking about when we say ‚Äúluck?‚Äù There are a lot of definitions that could apply, but let‚Äôs stick with a simple one: Luck is when something unexpected and good happens to you. Unexpected and good. Who doesn‚Äôt want to increase the odds of something unexpected and good?&lt;/p&gt;
    &lt;p&gt;In our world, luck can include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Having your OSS library take off&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Being invited to speak at a conference&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Landing a new job&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Getting a new consulting client&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Being invited onto a podcast&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Making new friends in your community&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;None of these things are totally in your control, which can at times feel frustrating.&lt;/p&gt;
    &lt;p&gt;How can we increase the odds of finding luck? By being a person who works in public. By doing work and being public about it, you build a reputation for yourself. You build a track record. You build a public body of work that speaks on your behalf better than any resume ever could.&lt;/p&gt;
    &lt;p&gt;The goal is not to become famous, the goal is to increase the chances of luck finding us. For me, one of the most helpful ways to think about this has always been the concept of the ‚ÄúLuck Surface Area,‚Äù described in an old post by Jason Roberts. He wrote (and note, the emphasis is mine):&lt;/p&gt;
    &lt;p&gt;"The amount of serendipity that will occur in your life, your Luck Surface Area, is directly proportional to the degree to which you do something you‚Äôre passionate about combined with the total number of people to whom this is effectively communicated."&lt;/p&gt;
    &lt;p&gt;Going further, he codifies it into a formula where:&lt;/p&gt;
    &lt;code&gt;Luck = [Doing Things] * [Telling People]&lt;/code&gt;
    &lt;p&gt;The more things you do multiplied by the more people you tell, the larger your Luck Surface Area becomes. The larger your Luck Surface Area, the more likely you are to catch luck as it flows by.&lt;/p&gt;
    &lt;head rend="h3"&gt;Source: Jason Roberts&lt;/head&gt;
    &lt;head rend="h2"&gt;Doing the work&lt;/head&gt;
    &lt;p&gt;Before you can publish your work, you have to actually do the work. The good news for you is that by even reading this Guide on The ReadME Project, you‚Äôve probably already self-selected into a group of people for whom ‚Äúdoing things‚Äù comes somewhat naturally. You‚Äôre a developer, a designer, a creator, an author, or something else entirely. Whatever moniker you want to give yourself, you‚Äôre built to do things, and that‚Äôs the important part.&lt;/p&gt;
    &lt;p&gt;If that doesn‚Äôt ring true for you, you may fall into one of two groups:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;You actually are doing things, you‚Äôve just trained yourself to think that anything you do isn‚Äôt worth sharing.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;You want to be doing things, but you can‚Äôt bring yourself to get started.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you‚Äôre in the first group, you may need to step back and reframe the work you‚Äôre already doing. This is a common blind spot for people who are executing at a high level! They‚Äôve forgotten just how much they know. They think that they‚Äôre not doing anything interesting because they assume that everyone knows as much as they do. This effect is only exacerbated when everyone in your immediate vicinity is at a similar‚Äîor higher‚Äîskill level. As you become more of an expert, your quality bar gets higher and higher and you forget that everything you know is not known by everyone.&lt;/p&gt;
    &lt;p&gt;If you‚Äôre in this group I want to give you a challenge: Watch the communities where you hang out and see what people are sharing and what gets noticed. Is it something you could have done? Is it something you‚Äôve already done? At its worst this could lead you in the direction of becoming bitter, critical, and thinking that you‚Äôre smarter than everyone. To that I say ‚Äúresist!‚Äù There is no life there. My encouragement to you is to view that as objective evidence that people want to know all of the things that you already know! There is a huge opportunity for you, should you decide to start sharing your work.&lt;/p&gt;
    &lt;p&gt;If you‚Äôre in the second group, you just need to start. Start anywhere, start on anything, start something. You‚Äôll never come up with the perfect idea for an OSS library, a business, a podcast, or an article by just thinking about it. Start on something, today. It won‚Äôt be the perfect version of the thing you have in your head, but you‚Äôll be in motion. Motion begets motion, progress begets progress. Pick the smallest thing you can do and get started.&lt;/p&gt;
    &lt;p&gt;Doing the work is the most important part. It‚Äôs the nucleus around which everything else revolves. What that ‚Äúwork‚Äù looks like, though, is entirely up to you! That‚Äôs the fun part. It can take any form and be in any domain. Wherever your curiosity or expertise draw you, dive into that.&lt;/p&gt;
    &lt;p&gt;Projects outside of work are a good place to dive into your curiosity.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;If you want to make a thermal receipt printer that prints GitHub issues, you should.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;If you want to turn a prefabricated shed into an office, go for it.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;If you want to go all in on an SVG drawing tool, do it.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;If you want to write tens of thousands of words about the infrastructure of modern money, that‚Äôs a newsletter.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Your curiosity will naturally pull you in certain directions, so don‚Äôt be afraid to go super deep into a topic that you‚Äôre interested in. When a person is truly interested in the thing they‚Äôre writing or talking about, their excitement is contagious. Whatever you‚Äôre excited about, be excited about it publicly. Whatever you‚Äôre curious about, be curious about it publicly. People will want to follow along and you‚Äôll inspire people along the way.&lt;/p&gt;
    &lt;p&gt;Projects at work can be a good place to dive into your expertise.&lt;/p&gt;
    &lt;p&gt;It's likely you're constantly solving problems and learning interesting things at your job. This is a great opportunity to take what you‚Äôre already doing and repurpose it for the benefit of others. You can turn those learnings into blog posts, conference talks, meetups, podcasts, or open source projects.&lt;/p&gt;
    &lt;p&gt;Of course not everything you do at work is shareable. If the specifics aren‚Äôt shareable, the concepts, lessons, and takeaways likely are. While you‚Äôre working, keep a scratch pad open and jot down any problems you come across, interesting patterns you see, or things you found confusing. Do this for a month and you‚Äôll have more things to share than you know what to do with!&lt;/p&gt;
    &lt;p&gt;You‚Äôve done the work, now it's time to tell people.&lt;/p&gt;
    &lt;head rend="h2"&gt;Hitting the publish button&lt;/head&gt;
    &lt;p&gt;This part of the formula can be harder for most of us. Most of us really enjoy the building aspect but start to get a little shy when it comes to telling people about the stuff we‚Äôve built. That could be for any number of reasons: fear, embarrassment, self-preservation, or an aversion to being perceived as hawking your wares.&lt;/p&gt;
    &lt;p&gt;It‚Äôs a valuable exercise to investigate whether or not you resonate with any of those reasons. Are you afraid people are going to make fun of what you built? Are you embarrassed that it isn‚Äôt up to your own (admittedly high) standards? Are you waiting for some elusive perfect moment? Do you have an aversion to ‚Äúmarketing‚Äù and don‚Äôt want to become the thing you hate? Whatever it is for you, I encourage you to really dig into it and see if that fear is worth keeping around.&lt;/p&gt;
    &lt;p&gt;Sharing things you‚Äôre learning or making is not prideful. People are drawn to other people in motion. People want to follow along, people want to learn things, people want to be a part of your journey. It‚Äôs not bragging to say, ‚ÄúI‚Äôve made a thing and I think it‚Äôs cool!‚Äù Bringing people along is a good thing for everyone. By publishing your work you‚Äôre helping people learn. You‚Äôre inspiring others to create.&lt;/p&gt;
    &lt;p&gt;You can ‚Äúpublish‚Äù anywhere. For me that‚Äôs mostly Twitter because that‚Äôs where most of my peers hang out. It doesn‚Äôt have to be Twitter for you. It could be GitHub, a newsletter, a podcast, forums, your blog, YouTube, or something completely different that‚Äôs not even on my radar. Anywhere that‚Äôs not your hard drive counts!&lt;/p&gt;
    &lt;p&gt;Publishing is a skill, it‚Äôs something you can learn. You‚Äôll need to build your publishing skill just like you built every other skill you have.&lt;/p&gt;
    &lt;p&gt;Don‚Äôt be afraid to publish along the way. You don‚Äôt have to wait until you‚Äôre done to drop a perfect, finished artifact from the sky (in fact, you may use that as an excuse to never publish). People like stories, so use that to your benefit. Share the wins, the losses, and the thought processes. Bring us along! If you haven‚Äôt been in the habit of sharing your work, it‚Äôs going to feel weird when you start. That‚Äôs normal! Keep going, you get used to it.&lt;/p&gt;
    &lt;p&gt;You‚Äôve done the work. You‚Äôve hit the publish button. You‚Äôve done your part!&lt;/p&gt;
    &lt;head rend="h2"&gt;Capturing the luck&lt;/head&gt;
    &lt;p&gt;You‚Äôve increased the odds that good, unexpected things will come your way. The exact form is hard to predict, but here are a few potential outcomes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;People start to know you as the person that talks about X, Y, and Z.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;You start to get emails from people saying that they read your stuff and liked it.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;You get a DM about a job you might be interested in.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;People ask you if you‚Äôre taking on new clients.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Someone you‚Äôve never met or interacted with will mention you as being an expert in your area.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;A meetup asks you to come talk about the things you‚Äôve been sharing.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;You become friends with other people in your industry.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Your OSS library starts gaining mindshare.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is not a random list of made-up examples, it‚Äôs a list of things that have literally happened to me once I got over my fears and started sharing my work. I had been doing the work all along, but was too afraid to publish. Once I overcame that fear, my Luck Surface Area expanded and good, unexpected things started happening.&lt;/p&gt;
    &lt;p&gt;The formula is simple.&lt;/p&gt;
    &lt;p&gt;Do the work. Don‚Äôt be afraid to dive deep into your curiosity and your expertise. We need more people that are intensely curious. We need more people with deep expertise.&lt;/p&gt;
    &lt;p&gt;Tell people. Press publish, bring us along, share the journey. Tell us what you‚Äôve learned, what you‚Äôve built, or what you‚Äôre excited about.&lt;/p&gt;
    &lt;p&gt;The formula may be simple, but I‚Äôll admit it‚Äôs not always easy. It‚Äôs scary to put yourself out there. It‚Äôs hard to open yourself up to criticism. People online can be mean. But for every snarky comment, there are ten times as many people quietly following along and admiring not only your work, but your bravery to put it out publicly. And at some point, one of those people quietly following along will reach out with a life-changing opportunity and you‚Äôll think, ‚ÄúWow, that was lucky.‚Äù&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46397991</guid><pubDate>Sat, 27 Dec 2025 00:43:04 +0000</pubDate></item><item><title>QNX Self-Hosted Developer Desktop</title><link>https://devblog.qnx.com/qnx-self-hosted-developer-desktop-initial-release/</link><description>&lt;doc fingerprint="38a649794034b286"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;QNX Self-Hosted Developer Desktop -- Initial Release&lt;/head&gt;
    &lt;p&gt;Try out the initial release of the QNX Developer Desktop -- a self-hosted development environment for QNX. No more cross-compilation!&lt;/p&gt;
    &lt;p&gt;The team and I are beyond excited to share what we've been cooking up over the last little while: a full desktop environment running on QNX 8.0, with support for self-hosted compilation! This environment both makes it easier for newly-minted QNX developers to get started with building for QNX, but it also vastly simplifies the process of porting Linux applications and libraries to QNX 8.0.&lt;/p&gt;
    &lt;p&gt;This self-hosted target environment is pre-loaded with many of the ports you'll find on the QNX Open-source Dashboard. (The portal currently includes over 1,400 ports across various targets, QNX versions, and architectures, of which more than 600 are unique ports!)&lt;/p&gt;
    &lt;p&gt;In this initial release, you can grab a copy of the QEMU image and give it a try for yourself. There's still so much more to add, but it's in a great place today for this first release. The team is really passionate about this one, and we're eagerly looking forward to your feedback!&lt;/p&gt;
    &lt;head rend="h1"&gt;What's Included&lt;/head&gt;
    &lt;p&gt;For the initial release of Desktop, we tried to cover all the basics: windowing, terminal, IDEs, browser, file management, and samples. To that end, here's what makes up the QNX Developer Desktop:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A customizable XFCE desktop environment running on Wayland&lt;/item&gt;
      &lt;item&gt;The tools you need to compile and/or run your code (&lt;code&gt;clang&lt;/code&gt;, gcc,&lt;code&gt;clang++&lt;/code&gt;, Python,&lt;code&gt;make&lt;/code&gt;,&lt;code&gt;cmake&lt;/code&gt;,&lt;code&gt;git&lt;/code&gt;, etc)&lt;/item&gt;
      &lt;item&gt;A web browser (can you join the QNX Discord from the QNX Desktop? üèÖüëÄ)&lt;/item&gt;
      &lt;item&gt;Ports of popular IDEs/editors, like Geany, Emacs, Neovim, and vim&lt;/item&gt;
      &lt;item&gt;Thunar, for file management&lt;/item&gt;
      &lt;item&gt;Preloaded samples, like Hello World in C, C++, and Python, and GTK demos OpenGL ES demos&lt;/item&gt;
      &lt;item&gt;... and of course, a terminal.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;System Requirements&lt;/head&gt;
    &lt;p&gt;This environment runs as a virtual machine, using QEMU on Ubuntu. To try the image, you'll need:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Ubuntu 22.04 or 24.04&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Try It Yourself&lt;/head&gt;
    &lt;p&gt;(Keep in mind this is the first release, so it takes a minute to get started and it's a bit rough around the edges.)&lt;/p&gt;
    &lt;p&gt;With a free QNX license, you can find this release in QNX Software Center. On the Available tab of the Manage Installation pane, search for "quick start" and install the "QNX SDP 8.0 Quick Start Target Image for QEMU".&lt;/p&gt;
    &lt;p&gt;You'll find the image in your QNX installation directory, usually &lt;code&gt;~/qnx800/images&lt;/code&gt; by default. Follow the &lt;code&gt;README.md&lt;/code&gt; file in the &lt;code&gt;qemu&lt;/code&gt; directory to extract &amp;amp; combine the multiple QNX packages downloaded under the hood.&lt;/p&gt;
    &lt;p&gt;Next, follow the PDF instructions found in the new &lt;code&gt;./qemu_qsti/docs/&lt;/code&gt; directory to install the required dependencies and boot up.&lt;/p&gt;
    &lt;head rend="h1"&gt;What's Next&lt;/head&gt;
    &lt;p&gt;This is just the very first release! Over the next few months and beyond, we'll drop more updates of Desktop. You can look forward to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;QEMU images for Windows &amp;amp; macOS, and native images for x86&lt;/item&gt;
      &lt;item&gt;A native Desktop image on Raspberry Pi&lt;/item&gt;
      &lt;item&gt;Enhanced documentation&lt;/item&gt;
      &lt;item&gt;Features to help use this self-hosted environment in CI jobs&lt;/item&gt;
      &lt;item&gt;More samples &amp;amp; stability&lt;/item&gt;
      &lt;item&gt;... and more! Have suggestions? Let us know.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Get Help and Share Feedback&lt;/head&gt;
    &lt;p&gt;Lastly, if you want some help with your QNX journey, you can find the QNX team and community:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;in Discord here: discord.gg/Jj4EkkrFTT&lt;/item&gt;
      &lt;item&gt;on Reddit at: reddit.com/r/qnx&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46398201</guid><pubDate>Sat, 27 Dec 2025 01:16:53 +0000</pubDate></item><item><title>More dynamic cronjobs</title><link>https://george.mand.is/2025/09/more-dynamic-cronjobs/</link><description>&lt;doc fingerprint="29aaa31a29a63e9c"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;More dynamic cronjobs&lt;/head&gt;&lt;p&gt;‚Ä¢ ~600 words ‚Ä¢ 3 minute read&lt;/p&gt;&lt;p&gt;I remember learning about cronjobs in the early 2000s. I could tell the computer to go do something, on a recurring basis, forever, even when I wasn't there. They felt like magic!&lt;/p&gt;&lt;p&gt;We didn't have Crontab.guru or AI to ask for figuring out some of the more complex specifications. Just the man pages and good old-fashioned trial and error‚Äîmostly error in my case.&lt;/p&gt;&lt;p&gt;But while you could do fun, complex specifications of recurring intervals, you couldn't quite specify something quite as dynamic as "run this script every Tuesday at 7am unless it's the last Tuesday of the month..."&lt;/p&gt;&lt;p&gt;Or at least, you couldn't strictly through the crontab specification syntax. But I had a recent, mildly embarrassing epiphany that it's not hard at all to add arbitrary checks to your crontab to account for more complex and dynamic scenarios.&lt;/p&gt;&lt;p&gt;Want to run a script every Tuesday of the month at 7am except for the last Tuesday? That's easy‚Äîset up your crontab to run every Tuesday at 7am, but add a little check to make sure the next week is still part of the same month:&lt;/p&gt;&lt;code&gt;0 7 * * Tue [ "$(date -v+7d '+%m')" = "$(date '+%m')" ] &amp;amp;&amp;amp; /path/to/your_command
&lt;/code&gt;&lt;p&gt;If it's not part of the same month, that means we're on the last Tuesday for the month and the script won't run.&lt;/p&gt;&lt;p&gt;Note: The &lt;code&gt;-v&lt;/code&gt; flag is for the macOS/BSD flavors of &lt;code&gt;date&lt;/code&gt;. On Linux you'd want to use &lt;code&gt;-d +7 days&lt;/code&gt; instead.&lt;/p&gt;&lt;p&gt;This really has nothing to do with cronjobs at all and everything to do with the POSIX "test" command which is the thing we're using with those square brackets. I'm used to seeing and utilizing them in shell scripts, but for whatever reason I never thought to reach for that tool here in the crontab.&lt;/p&gt;&lt;p&gt;You could just as easily rewrite it like this, skipping the bracket shorthand, which is probably easier to read:&lt;/p&gt;&lt;code&gt;0 7 * * Tue test "$(date -v+7d '+%m')" = "$(date '+%m')" &amp;amp;&amp;amp; /path/to/your_command
&lt;/code&gt;&lt;p&gt;It never crossed my mind until recently to add slightly more complex checks at the crontab level.&lt;/p&gt;&lt;head rend="h3"&gt;Other clever cronjob things you can do:&lt;/head&gt;&lt;head rend="h4"&gt;Holiday-only cronjobs&lt;/head&gt;&lt;p&gt;Maybe fetch a list of all the US Holidays for a given year and store them in a handy &lt;code&gt;HOLIDAYS.txt&lt;/code&gt; file somewhere:&lt;/p&gt;&lt;code&gt;curl -s https://date.nager.at/api/v3/PublicHolidays/2025/US | jq -r '.[].date' &amp;gt; HOLIDAYS.txt
&lt;/code&gt;&lt;p&gt;Now you can update your cronjob to run every Tuesday at 7am except on Holidays:&lt;/p&gt;&lt;code&gt;0 7 * * Tue ! grep -qx "$(date +%F)" HOLIDAYS.txt &amp;amp;&amp;amp; /path/to/your_command
&lt;/code&gt;&lt;p&gt;Or inversely, maybe run a holiday-only script that checks once a day&lt;/p&gt;&lt;code&gt;@daily grep -qx "$(date +%F)" HOLIDAYS.txt &amp;amp;&amp;amp; /path/to/your_special_holiday_command
&lt;/code&gt;&lt;head rend="h4"&gt;Only run on sunny days&lt;/head&gt;&lt;p&gt;The National Weather Service makes all kinds of fun data available (if you can find it...). How about a script that runs every hour, but only when the weather is clear?&lt;/p&gt;&lt;code&gt;@hourly curl -s "https://api.weather.gov/gridpoints/TOP/32,81/forecast/hourly" | jq -r '.properties.periods[0].shortForecast' | grep -qi clear &amp;amp;&amp;amp; /path/to/your_command
&lt;/code&gt;&lt;p&gt;Or maybe when the weather is cloudy?&lt;/p&gt;&lt;code&gt;@hourly curl -s "https://api.weather.gov/gridpoints/TOP/32,81/forecast/hourly" | jq -r '.properties.periods[0].shortForecast' | grep -qi cloudy &amp;amp;&amp;amp; /path/to/your_command
&lt;/code&gt;&lt;head rend="h4"&gt;Only run when there's something newsworthy&lt;/head&gt;&lt;p&gt;Or maybe we get in line with every-other-startup I'm aware of and throw AI at the problem, only running our script when the LLM gods have decided there is something newsworthy:&lt;/p&gt;&lt;code&gt;@hourly curl -s "https://news.google.com/rss?hl=en-US&amp;amp;gl=US&amp;amp;ceid=US:en" | llm --system "Reply strictly 'yes' or 'no'. Does anything in the news today suggest it is a good reason to run a script that I only want to send when the world is on fire and crazy and terrible things are happening?"  | tr -d '[:space:]' | tr '[:upper:]' '[:lower:]' | grep -qx yes &amp;amp;&amp;amp; /path/to/oh_no
&lt;/code&gt;--&lt;p&gt;Published on Sunday, September 21st 2025. Read this post as Markdown or plain-text.&lt;/p&gt;&lt;p&gt;If you enjoyed reading this consider signing-up for my newsletter, sharing it on Hacker News or hiring me.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46399576</guid><pubDate>Sat, 27 Dec 2025 06:10:42 +0000</pubDate></item><item><title>Verdichtung</title><link>https://alexeygy.github.io/blog/verdichtung/</link><description>&lt;doc fingerprint="ba60107f19a937ff"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;2025-12-26 - Verdichtung&lt;/head&gt;
    &lt;p&gt;Verdichtung is German word that loosely means "densification". It represents an alternative to urban sprawl‚Å∞ that is prevalent in US cities and has been the dominant strategy for Zurich's expansion.&lt;/p&gt;
    &lt;p&gt;What it means is that even though there would theoretically be new space available on the outskirts, the city, or canton, instead of dedicating it to new construction it prefers¬π to repurpose existing buildings by increasing the number of floors or by reducing the distance between buildings.&lt;/p&gt;
    &lt;p&gt;I am actually currently living in such a building created from Verdichtung where before this was partially a parking lot and partially an annex of another building. Looking at historical maps, there are many such occurences&lt;/p&gt;
    &lt;p&gt;Two Google Earth images of Schlieren from 2009 and 2024 showing the practicalities of verdichtung. Look out for the central area turning multiple smaller housing blocks into a larger one and eliminating "wasted space".&lt;/p&gt;
    &lt;p&gt;But top-down maps only tell half the story as they often look directly from above, Verdichtung also often means an increase in height. This does create more living space overall but it also creates some weird apartments that feel way too close together and that often can only serve people that do not &lt;del&gt;are financially unable to&lt;/del&gt; have any demands for either sunlight, privacy, or quietness. For example, a parking lot not far away was repurposed into a hotel-like complex where balconies made out of pure concrete are facing each other.&lt;/p&gt;
    &lt;p&gt;Example sketch (not real but pretty much 1:1 of an apartment complex built close to where I live in 2025) of what Verdichtung looks like in practice. There was a parking lot before here, now we have balconies made out of pure concrete facing each other with no sunlight, privacy, or coziness. The prices are sure high though!&lt;/p&gt;
    &lt;head rend="h2"&gt;Effect on ownership?&lt;/head&gt;
    &lt;p&gt;Ownership in Zurich has undergone a quiet shift in the last years; where private individuals held 41% of the stock in 2010, they now account for barely 31% in 2024 (data from stadt-zuerich.ch). While this generally follows the trend of Switzerland simply having the lowest home ownership in Europe (link), it could be empirically argued that Verdichtung has played a role in this shift as demolishing and building denser is highly complex and expensive, something which would be nearly impossible to do by a private individual, especially so since your neighbors can essentially complain and delay the project for a while. Compare that to you just buying a new plot of land with reasonably well defined rules and building there or just renovating an existing building and it is night and day.&lt;/p&gt;
    &lt;p&gt;Hence projects doing Verdichtung generally lead to four ownership scenarios for land that might have been previously owned by individuals:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;A private company does the project and rents out the flats generating very good stable and predictable revenue per m2.&lt;/item&gt;
      &lt;item&gt;A Genossenschaft (cooperative) or a pension fund does 1.&lt;/item&gt;
      &lt;item&gt;A private company does the project and sells the flats to individuals (less often than 1., companies tend to love the stable income of renting out).&lt;/item&gt;
      &lt;item&gt;The city does the project and rents out the flats, often dedicating a percentage of the flats to social housing.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: Neither cooperatives nor the city typically sell flats. Mostly because it's a massive effort for them to acquire the property, and they really love recurring revenue and absolutely would hate to deal with short-term income as they are generally non-profit institutions.&lt;/p&gt;
    &lt;p&gt;Looking at the above, we see that in most scenarios, Verdichtung leads to a shift from private ownership to either private companies or cooperatives and private individuals renting out.&lt;/p&gt;
    &lt;head rend="h2"&gt;Zurich's ups and downs&lt;/head&gt;
    &lt;p&gt;Zurich has a weird history when it comes to its urban population where its population peaked in the 1970s (at ~422,000), then dropped due to a push for suburbanization and only recently reached the same level again. This is pretty different from many other urban centers as urbanization has been rampant in Europe in the last decades and has been influenced by various factors like the different tax rates across the canton.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; The population of ZRH over time, rough estimate, source: Federal Statistical Office of Switzerland.&lt;/p&gt;
    &lt;head rend="h2"&gt;Any alternatives?&lt;/head&gt;
    &lt;p&gt;Short-term, this seems like much less nice than living in a suburban area but long-term this is much more sustainable. Has it been able to meet demands? No. Zurich's buying market is one of the worst in the world according to the UBS Bubble Index (ranked #3 globally in 2024) having very high prices and some risk of a market correction. Are there many alternatives? No. Not really as free areas are sparse and the city is sandwiched between the lake, the Uetliberg and Z√ºriberg hills, and an airport that is just 10 km away from the city. The reality of the housing market reflects this sharply as prices drop steeply as soon as you hop over a ridge or float down the Limmat.&lt;/p&gt;
    &lt;p&gt;Verdichtung, however does have some upsides. Commute times within the city often are within the magical boundary of 15 minutes (see &lt;code&gt;15 minute city&lt;/code&gt;) and, due to the short distances and okayish infrastructure, allow for using a bicycle¬≤.&lt;/p&gt;
    &lt;head rend="h2"&gt;Wrap-up&lt;/head&gt;
    &lt;p&gt;Verdichtung is the price we pay for not having suburbs but we at least get great infrastructure at a reasonable cost. You could say it's Swiss efficiency applied to the housing problem.&lt;/p&gt;
    &lt;head rend="h2"&gt;Footnotes&lt;/head&gt;
    &lt;p&gt;‚Å∞ Zersiedlung is the Swiss-German term for urban sprawl.&lt;/p&gt;
    &lt;p&gt;¬π If we look under the hood, this preference is a mandate based on the federal-level Raumplanungsgesetz (RPG) linked here. Which says that development has to be done inwards while considering an adequate "quality of housing". Interestingly, and, if you're familiar with Swiss law unsurprisingly, the formulation is extremely vague as it also mandates decentralization, environmental protection, and integration of foreigners so ultimately it's kind of a catch-all that can be used to justify almost anything ü§∑‚ôÇÔ∏è and is one of those things that only works in Switzerland where checks and balances are abundant and abuse is relatively rare.&lt;/p&gt;
    &lt;p&gt;¬≤ At least when you're OK that your bicycle lane can randomly stop at a narrow point or street corner that is not wide enough and then continue when the road widens. Example below:&lt;/p&gt;
    &lt;p&gt;The popular YouTube channel &lt;code&gt;Not Just Bikes&lt;/code&gt; released a comprehensive video about ZRH if you're interested in more.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46400242</guid><pubDate>Sat, 27 Dec 2025 08:42:45 +0000</pubDate></item><item><title>Show HN: Ez FFmpeg ‚Äì Video editing in plain English</title><link>http://npmjs.com/package/ezff</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46400251</guid><pubDate>Sat, 27 Dec 2025 08:45:46 +0000</pubDate></item><item><title>Splice a Fibre</title><link>https://react-networks-lib.rackout.net/fibre</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46401190</guid><pubDate>Sat, 27 Dec 2025 11:57:17 +0000</pubDate></item><item><title>Apple releases open-source model that instantly turns 2D photos into 3D views</title><link>https://github.com/apple/ml-sharp</link><description>&lt;doc fingerprint="3783a21824b9c2d6"&gt;
  &lt;main&gt;
    &lt;p&gt;This software project accompanies the research paper: Sharp Monocular View Synthesis in Less Than a Second by Lars Mescheder, Wei Dong, Shiwei Li, Xuyang Bai, Marcel Santos, Peiyun Hu, Bruno Lecouat, Mingmin Zhen, Ama√´l Delaunoy, Tian Fang, Yanghai Tsin, Stephan Richter and Vladlen Koltun.&lt;/p&gt;
    &lt;p&gt;We present SHARP, an approach to photorealistic view synthesis from a single image. Given a single photograph, SHARP regresses the parameters of a 3D Gaussian representation of the depicted scene. This is done in less than a second on a standard GPU via a single feedforward pass through a neural network. The 3D Gaussian representation produced by SHARP can then be rendered in real time, yielding high-resolution photorealistic images for nearby views. The representation is metric, with absolute scale, supporting metric camera movements. Experimental results demonstrate that SHARP delivers robust zero-shot generalization across datasets. It sets a new state of the art on multiple datasets, reducing LPIPS by 25‚Äì34% and DISTS by 21‚Äì43% versus the best prior model, while lowering the synthesis time by three orders of magnitude.&lt;/p&gt;
    &lt;p&gt;We recommend to first create a python environment:&lt;/p&gt;
    &lt;code&gt;conda create -n sharp python=3.13
&lt;/code&gt;
    &lt;p&gt;Afterwards, you can install the project using&lt;/p&gt;
    &lt;code&gt;pip install -r requirements.txt
&lt;/code&gt;
    &lt;p&gt;To test the installation, run&lt;/p&gt;
    &lt;code&gt;sharp --help
&lt;/code&gt;
    &lt;p&gt;To run prediction:&lt;/p&gt;
    &lt;code&gt;sharp predict -i /path/to/input/images -o /path/to/output/gaussians
&lt;/code&gt;
    &lt;p&gt;The model checkpoint will be downloaded automatically on first run and cached locally at &lt;code&gt;~/.cache/torch/hub/checkpoints/&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Alternatively, you can download the model directly:&lt;/p&gt;
    &lt;code&gt;wget https://ml-site.cdn-apple.com/models/sharp/sharp_2572gikvuh.pt
&lt;/code&gt;
    &lt;p&gt;To use a manually downloaded checkpoint, specify it with the &lt;code&gt;-c&lt;/code&gt; flag:&lt;/p&gt;
    &lt;code&gt;sharp predict -i /path/to/input/images -o /path/to/output/gaussians -c sharp_2572gikvuh.pt
&lt;/code&gt;
    &lt;p&gt;The results will be 3D gaussian splats (3DGS) in the output folder. The 3DGS &lt;code&gt;.ply&lt;/code&gt; files are compatible to various public 3DGS renderers. We follow the OpenCV coordinate convention (x right, y down, z forward). The 3DGS scene center is roughly at (0, 0, +z). When dealing with 3rdparty renderers, please scale and rotate to re-center the scene accordingly.&lt;/p&gt;
    &lt;p&gt;Additionally you can render videos with a camera trajectory. While the gaussians prediction works for all CPU, CUDA, and MPS, rendering videos via the &lt;code&gt;--render&lt;/code&gt; option currently requires a CUDA GPU. The gsplat renderer takes a while to initialize at the first launch.&lt;/p&gt;
    &lt;code&gt;sharp predict -i /path/to/input/images -o /path/to/output/gaussians --render

# Or from the intermediate gaussians:
sharp render -i /path/to/output/gaussians -o /path/to/output/renderings
&lt;/code&gt;
    &lt;p&gt;Please refer to the paper for both quantitative and qualitative evaluations. Additionally, please check out this qualitative examples page containing several video comparisons against related work.&lt;/p&gt;
    &lt;p&gt;If you find our work useful, please cite the following paper:&lt;/p&gt;
    &lt;code&gt;@inproceedings{Sharp2025:arxiv,
  title      = {Sharp Monocular View Synthesis in Less Than a Second},
  author     = {Lars Mescheder and Wei Dong and Shiwei Li and Xuyang Bai and Marcel Santos and Peiyun Hu and Bruno Lecouat and Mingmin Zhen and Ama\"{e}l Delaunoy and Tian Fang and Yanghai Tsin and Stephan R. Richter and Vladlen Koltun},
  journal    = {arXiv preprint arXiv:2512.10685},
  year       = {2025},
  url        = {https://arxiv.org/abs/2512.10685},
}&lt;/code&gt;
    &lt;p&gt;Our codebase is built using multiple opensource contributions, please see ACKNOWLEDGEMENTS for more details.&lt;/p&gt;
    &lt;p&gt;Please check out the repository LICENSE before using the provided code and LICENSE_MODEL for the released models.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46401539</guid><pubDate>Sat, 27 Dec 2025 12:58:12 +0000</pubDate></item><item><title>Floor796</title><link>https://floor796.com/</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46401612</guid><pubDate>Sat, 27 Dec 2025 13:13:00 +0000</pubDate></item><item><title>NMH BASIC</title><link>https://t3x.org/nmhbasic/index.html</link><description>&lt;doc fingerprint="b738281b4ea5b2d8"&gt;
  &lt;main&gt;
    &lt;p&gt;Download: nmhbas23c.zip (version 1.2, 74KB) | nmhbas25c.zip (version 2.1, 90KB) | man page&lt;/p&gt;
    &lt;p&gt;This is a small BASIC interpreter that I wrote in the early 1990s. For some reason I think it is one of the coolest programs I have ever written. Maybe because it is just a bit under 5K bytes large and still does something useful. Maybe it is just nostalgia.&lt;/p&gt;
    &lt;p&gt;One of the more interesting programs I have written in NMH BASIC is a variant of the well-known mine sweeper game that runs in text mode. Not just text mode, actually, but (tele)typewriter mode, as it reprints the playing field after every move.&lt;/p&gt;
    &lt;p&gt;The screenshots use Viacheslav Slavinsky's excellent GlassTTY font, a TrueType font that perfectly resembles the one used in the DEC VT-220 terminal. The same font, at bigger magnification, is used in the NMH BASIC logo.&lt;/p&gt;
    &lt;p&gt;What is maybe interesting about the mine sweeper clone is that it uses a stackless floodfill algorithm that stores its state in the playing field itself and needs no dynamic memory at all. I have recently described it in the paper A Stackless Floodfill Automaton (PDF, 34KB). A demo showing an animation of the algorithm is included in the NMH BASIC package.&lt;/p&gt;
    &lt;p&gt;There are other programs in the package, most of them rather simple, like an implementation of the Hangman game, the (rather pointless) Nim game, a banner printer, a random number generator, etc. NMH BASIC does not have a RNG, so a 15-bit linear feedback shift register is implemented in BASIC to generate pseudo-random numbers.&lt;/p&gt;
    &lt;p&gt;The first program I have ever written in NMH BASIC was the inevitable prime number sieve. I have no idea how often I have loaded and run it in the past decades - until the Floodfill demo became my new favorite. Here is the code of my first NMH BASIC program (the backslash is the division remainder operator):&lt;/p&gt;
    &lt;quote&gt;10 REM 'PRINT PRIME NUMBERS' 20 REM 'M = NUMBER OF PRIMES TO PRINT' 100 LET M = 1000 105 DIM Z(M) 110 LET Z(0) = 2 : LET T = 1 : LET P = 1 115 PRINT 2, 120 IF T &amp;gt;= M GOTO 200 130 LET P = P+2 : LET O = 1 140 FOR I = 0 TO T-1 150 IF P\Z(I) = 0 LET O = 0 : LET I = T 160 NEXT 170 IF O = 0 GOTO 120 180 LET Z(T) = P : LET T = T+1 185 PRINT P, 190 GOTO 120 200 END&lt;/quote&gt;
    &lt;p&gt;I wrote the first version of NMH BASIC in 1994, recycling some parts that I had written in the years 1991..1993. The first version that I wrote in 1994 was a prototype in BASYL-II which I then translated, function by function, to 8086 assembly language. The resulting executable had a size of about 4700bytes and because the token representation that the interpreter uses internally is quite efficient, you could do interesting things with NMH BASIC in as little as 12Kbytes of memory. I had named the interpreter 12K-BASIC initially, but soon learned that others had had that idea before me.&lt;/p&gt;
    &lt;p&gt;Of course in 1994 memory was already measured in megabytes, so you might say that writing a tiny BASIC interpreter was kind of pointless at that time. It depends I would say; it is better than getting drunk in a bar, and now, almost 30 years later, I still enjoy playing with this little program. So much, in fact, that I decided to translate the original code to T3X/0, so that I can play with it on Unix without having to use an emulator.&lt;/p&gt;
    &lt;p&gt;All the above versions are included in the package: the original BASYL-II version, the assembly language version, and the new T3X version. You can recompile the T3X version with T3X/0 and the 8086 assembly language version with TASM or MASM. You need to create a COM file or it will not run. A precompiled COM file and Tcode machine executable (as well as a Tcode machine for Unix) are also included in the package.&lt;/p&gt;
    &lt;p&gt;There is also a simplified version of the interpreter that runs under CP/M. A COM file for CP/M (BASICS.COM) is also included in the archive. The CP/M version currently needs 32K bytes of TPA to run.&lt;/p&gt;
    &lt;p&gt;The NMH BASIC language contains some interesting (IMHO) hacks to make its implementation simpler.&lt;/p&gt;
    &lt;p&gt;All variables have either single-character names or names consisting of a character and a digit, like A0, B2, Z9, etc. The expressions A and A0 and A(0) all refer to the same variable. If you do not use A0..A9, you can use A as a 10-slot array A(0) .. A(9). Or you can use A5 in the place of A(5) if you are refering to a fixed slot.&lt;/p&gt;
    &lt;p&gt;It is getting even weirder. A(10) is the same as B or B0 or B(0). A(22) is equal to C2 or C(2) and, finally, A(259) would be equal to Z(9). So, for instance, if you do not use any Z's, you can use Y as a 20-slot array. In this case the command &lt;code&gt;DIM¬†Y(20)&lt;/code&gt; is really
a null-operation. It merely serves as a reminder that Y is a 20-slot
array (and Z should not be used).
&lt;/p&gt;
    &lt;p&gt;You could also use Y as a 50-alot array by dimensioning it with &lt;code&gt;DIM¬†Y(50)&lt;/code&gt;. In this case the elements of Z will still be used, but
40 additional slots will be allocated to integer variable storage,
so Z becomes a 40-slot array and Y a 50-slot array. It probably
goes without saying that most programs either use single-character
variables as 10-slot arrays or dimension Z, if a larger array is
needed.
&lt;/p&gt;
    &lt;p&gt;This also means that &lt;code&gt;DIM¬†Y(50)&lt;/code&gt; and &lt;code&gt;DIM¬†Z(50)&lt;/code&gt; in the same program
would just allocate 50 integer slots to Z and the last 40 slots of Y would
overlap with the slots of Z. Having multiple large arrays in the
same NMH¬†BASIC program requires some hacking, like using Z(0)..Z(99)
for one array and Z(100)..Z(199) for the other.
&lt;/p&gt;
    &lt;p&gt;Note the definition of "large" above. NMH BASIC uses 12Kbytes of memory in total: for integer variables, string variables, program memory, stacks, and the machine code of the interpreter itself! You could probably write a version of this interpreter that would run on a CP/M machine with as little as 16K bytes of transient program area (but I have never done so).&lt;/p&gt;
    &lt;p&gt;The interpreter performs I/O on "units", where each unit is assigned a file or device when the interpreter is started. NMH BASIC programs cannot open or close any files. They can only redirect input and output to the assigned units. I/O is sequential, i.e. each unit is like a tape drive. The following program prints the data stored on unit #5:&lt;/p&gt;
    &lt;quote&gt;100 LET X = IOCTL(5, 100) : INPUT #5 110 INPUT A$ : IF ASC(A$) = 255 INPUT #0 : END 120 PRINT A$ : GOTO 110&lt;/quote&gt;
    &lt;p&gt;The statement &lt;code&gt;INPUT¬†#5&lt;/code&gt; redirects input to unit #5, so from that point
on all INPUT statements will read from that unit. (Analogously,
&lt;code&gt;PRINT¬†#5&lt;/code&gt; would redirect output to unit #5.) When a string read from
a unit contains the value 255 in its first slot, there is no more
input available from the current input unit. &lt;code&gt;INPUT¬†#0&lt;/code&gt; connects input
back to the keyboard. Note that &lt;code&gt;PRINT¬†#1&lt;/code&gt; would connect output back
to the screen.
&lt;/p&gt;
    &lt;p&gt;There is an IOCTL function that can perform several "services" on a unit, like rewinding it, appending to it (moving the read/write pointer to the end of the unit), or truncating it (or writing an EOF marker on a tape). The IOCTL call in the above example rewinds the unit.&lt;/p&gt;
    &lt;p&gt;The maximum length of a line or string is 64 bytes. Reading anything longer, either via INPUT or by entering it at the interpreter prompt, will result in an error. The CR,LF characters that separate lines are not counted.&lt;/p&gt;
    &lt;p&gt;I have forgotten how other BASIC dialects handle this, but I suspect that NMH BASIC is the odd one out here: in an IF statement the entire rest of the line is executed conditionally. For example&lt;/p&gt;
    &lt;quote&gt;IF 1 = 1 PRINT 'FOO' : PRINT 'BAR'&lt;/quote&gt;
    &lt;p&gt;would print both FOO and BAR. There is no THEN or ELSE keyword. The first keyword after the condition of IF starts the conditional part of the IF statement. When the condition in IF is false, the interpreter advances to the next line. An alternative branch is implemented with jump around jumps using GOTO:&lt;/p&gt;
    &lt;quote&gt;100 IF condition GOTO 130 110 alternative statements 120 GOTO 140 130 consequent statements 140 REM&lt;/quote&gt;
    &lt;p&gt;Or, if the condition and statements are short:&lt;/p&gt;
    &lt;quote&gt;100 IF condition statements 110 IF # condition statements&lt;/quote&gt;
    &lt;p&gt;The # operator implements the logical NOT. It had high precedence in NMH BASIC up to version 1.2, but has very low precedence in NMH BASIC II. Interestingly, this change did not affect any programs in the archive. There is a logical AND, but not a logical OR in IF. If there are multiple conditions separated by commas then the conditional statements will only execute, if all conditions are true. For example, the statement&lt;/p&gt;
    &lt;quote&gt;IF 0 &amp;lt; C, C &amp;lt; 11 STOP&lt;/quote&gt;
    &lt;p&gt;will stop program execution, if C is in the range 1..10. To implement a logical OR, multiple IF statemements with the same conditional part (or jumps around jumps) have to be used.&lt;/p&gt;
    &lt;p&gt;NMH BASIC 1.x listed programs with blanks between all adjacent tokens. NMH BASIC II uses a more compact representation. Either way is merely a characteristic of the LIST routine, though. You can enter a program as&lt;/p&gt;
    &lt;quote&gt;FOR I=1TO10:PRINT A(I):NEXT&lt;/quote&gt;
    &lt;p&gt;but the LIST command will print it as&lt;/p&gt;
    &lt;quote&gt;FOR I = 1 TO 10 : PRINT A ( I ) : NEXT&lt;/quote&gt;
    &lt;p&gt;in NMH BASIC and as&lt;/p&gt;
    &lt;quote&gt;FOR I = 1 TO 10 : PRINT A(I) : NEXT&lt;/quote&gt;
    &lt;p&gt;in NMH BASIC II.&lt;/p&gt;
    &lt;p&gt;This has the weird side effect that sometimes you can SAVE a program but cannot LOAD it later, because some lines will be shorter than 64 characters when you enter them, but LIST (and hence SAVE) will blow them up to a bigger size.&lt;/p&gt;
    &lt;p&gt;This is mostly a problem in NMH BASIC 1.x, which inserts blanks between all tokens. For example:&lt;/p&gt;
    &lt;quote&gt;100 IF ASC(MID$(A$, I, 1)) = ASC('X') LET X = X+1 : GOTO 120 ----+----1----+----2----+----3----+----4----+----5----+----6---| 100 IF ASC( MID$( A$ , I , 1 ) ) = ASC( 'X' ) LET X = X + 1 : GOTO 120&lt;/quote&gt;
    &lt;p&gt;There is no workaround. When a program cannot be loaded, the only remedy is to edit it with a text editor and fix it, either by removing unnecessary blanks or, even better, by splitting the offending line. E.g.:&lt;/p&gt;
    &lt;quote&gt;100 LET C = ASC( MID$( A$ , I , 1 ) ) 105 IF C = ASC( 'X' ) LET X = X + 1 : GOTO 120&lt;/quote&gt;
    &lt;p&gt;Finally, it is a good idea to keep NMH BASIC programs in DOS text format with CR/LF line separators, even on Unix systems, because otherwise the DOS version of the interpreter will refuse to load them.&lt;/p&gt;
    &lt;p&gt;In December 2024 I changed a few things and pubished a new version of NMH BASIC, which I called, for lack of imagination, NMH BASIC II. The new version changes the precedence of the # (logical NOT) operator from highest to lowest (this was a mistake in the original version!) and uses a more compact and more comprehensible LIST format, which is also used for saving programs. Because some code was simplified in the interpreter at the same time, the new version is one byte smaller than the original version.&lt;/p&gt;
    &lt;p&gt;Download: nmhbas3_30.zip (version 3.0, 105KB) | man page&lt;/p&gt;
    &lt;p&gt;Version 3.x of NMH BASIC is an in-progress version that differs from the previous versions in a few points that are described in detail in the manual. Most prominently, the CMPS ("compare strings") function has been replaced with string comparison operators, so, for example,&lt;/p&gt;
    &lt;quote&gt;IF CMPS(A$, 'FOO') = 0 PRINT 'YEP'&lt;/quote&gt;
    &lt;p&gt;would now be written as&lt;/p&gt;
    &lt;quote&gt;IF A$ = 'FOO' PRINT 'YEP'&lt;/quote&gt;
    &lt;p&gt;Then, NMH BASIC III supports baudot-encoded units. This means that any unit connected to the interpreter can be written to and read from using five-channel baudot-encoding (CCITT-2, US-TTY). So the interpreter can, in theory, save and load programs to/from five-hole paper tape.&lt;/p&gt;
    &lt;p&gt;The T3X/0 version of the interpreter is currently fully working. There also is a more efficient Z80 version written in assembly language, which is work in slow progress. It currently runs all the example programs, but lacks baudot-encoded units and may still have a few bugs. An 8086 version written in assembly language may appear later.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46401938</guid><pubDate>Sat, 27 Dec 2025 14:05:44 +0000</pubDate></item><item><title>We Automated Federal Retirements</title><link>https://ndstudio.gov/posts/automating-federal-retirements</link><description>&lt;doc fingerprint="6f289b1e21b2cd99"&gt;
  &lt;main&gt;
    &lt;p&gt;Imagine retiring after a lifetime of public service ‚Äî as a veteran, air traffic controller, or first responder ‚Äî only to wait six months in financial limbo because a decades-old government process can't handle your application.&lt;/p&gt;
    &lt;p&gt;That was the reality for thousands of federal retirees every year since the 60's, having to apply for retirement within a paper-based, broken system plagued by delays and inefficiency.&lt;/p&gt;
    &lt;p&gt;If you had told us we‚Äôd relocate our lives to move to D.C. to fix this, we‚Äôd have called it ridiculous.&lt;/p&gt;
    &lt;p&gt;Yat had just left a decade-long run at Airbnb, helping to build it from scrappy startup to public company; likewise, Dennis also came from startups in manufacturing and AI. Government work simply wasn‚Äôt in the life plan.&lt;/p&gt;
    &lt;p&gt;Yet in under a year, our team of two has transformed this outdated paper process into a modern, digital workflow. The new system is on track to handle 100,000 digital applications by the end of the year, many of which will experience significantly reduced processing time.&lt;/p&gt;
    &lt;p&gt;We share our experience in this blog post in hopes that what started as a mission to give retirees the transition they deserve can turn into something bigger: a proven playbook for modernizing outdated government systems. The same systematic problems we encountered are not unique to retirement, and our approach to them can hopefully be applied to streamlining other outdated areas where citizens interface with their government ‚Äî from applying for benefits, to filing taxes.&lt;/p&gt;
    &lt;p&gt;We're proud to have cut through some bureaucracy and make an impact here, and we‚Äôre excited for what's possible when talented builders turn their skills to public service.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Makes Retirements So Complicated?&lt;/head&gt;
    &lt;p&gt;Before we arrived, when a federal employee retired, they began by preparing a thick stack of forms to submit to their HR department. Processing this case would involve multiple government parties further assembling and verifying information from additional records. Their HR office, their payroll providers, and OPM each needed to individually review every piece of paper for consistency and accuracy.&lt;/p&gt;
    &lt;p&gt;This process can take over six months. During this time, retirees receive only partial payments ‚Äî sometimes enough to get by, but less than their full annuity.&lt;/p&gt;
    &lt;p&gt;It evolved this way over time: new retirement laws had to be supported, checks were added to reduce error rates on paper forms, and digital systems were added piecemeal but never integrated.&lt;/p&gt;
    &lt;p&gt;The result was significant inefficiency. For OPM, this even meant physically pulling historic records about retirees from an underground mine in Pennsylvania, where millions of paper records are stored in vast rows of file cabinets.&lt;/p&gt;
    &lt;p&gt;These challenges hadn't gone unnoticed. In fact, OPM had launched no fewer than three separate modernization initiatives in the 1980s, '90s, and '00s, pouring an estimated $130 million of taxpayer money to try to move this process off of paper. Every single initiative failed.&lt;/p&gt;
    &lt;p&gt;A 2014 Washington Post investigation captured the issues in vivid detail, but that article could just as easily have been written in early 2025. Despite over a decade passing, progress remained glacial, and nothing had seemingly changed.&lt;/p&gt;
    &lt;p&gt;This was the broken system we walked into earlier this year.&lt;/p&gt;
    &lt;p&gt;At the time, we knew only about the crippling inefficiencies of the paper system, not the string of failed efforts that had come before. So perhaps emboldened by sheer naivet√©, we set out to do what our predecessors couldn‚Äôt: actually modernize federal retirement processing and deliver something that could finally last.&lt;/p&gt;
    &lt;head rend="h2"&gt;Digitization and retire.opm.gov&lt;/head&gt;
    &lt;p&gt;Our first priority was bringing the whole system online, immediately.&lt;/p&gt;
    &lt;p&gt;Speed was of the essence in order to stop the bleeding. We issued a public memo for a government-wide cutoff of new paper into The Mine. In order to support this, the digital replacement had to be ready within a month.&lt;/p&gt;
    &lt;p&gt;OPM‚Äôs last attempt at modernization had kicked off the Online Retirement Application (ORA), which set out to serve as a digital version of paper-based retirement applications. However, despite starting in 2018 and millions of dollars per year in investment, the platform was still not fully functional. It looked and performed like a website from the 1990s, and key features that were needed for real usage were still missing.&lt;/p&gt;
    &lt;p&gt;We initially tried to embed ourselves alongside the OPM development team to accelerate its completion. There were certain retirement types that were critical but not yet supported, and there was no ability for applicants to upload supporting documentation PDFs larger than 5MB.&lt;/p&gt;
    &lt;p&gt;What should have been simple ended up near impossible: once again, OPM had bet this modernization effort on a flawed technical direction from the outset. They had committed to building all of this on Microsoft PowerApps, a ‚Äúno-code‚Äù tool meant for building simple web apps, not a professional development platform. For all the complexities required to truly move retirements off of paper, this would be like giving a construction crew Lego bricks to build a 100-story skyscraper.&lt;/p&gt;
    &lt;p&gt;When we met with the developers in Macon, Georgia, OPM's engineering hub, they told us the PowerApps experience was so unfriendly that even they were afraid to make changes. Unless they‚Äôve been specifically trained with PowerApps, most software developers would find it extremely unintuitive to build with, making it hard to apply classic coding skills or iterate quickly.&lt;/p&gt;
    &lt;p&gt;After several more weeks with little progress and only a few weeks left until launch, we called an emergency meeting.&lt;/p&gt;
    &lt;p&gt;We could either continue wrestling with the PowerApps approach with no clear path to success, or pull a Hail Mary of rebuilding the whole system in a modern way. It would be a herculean effort, but it was the only option that gave us a real shot at delivering. The resulting payoff would be the speed, flexibility, and modern capabilities that we knew were possible.&lt;/p&gt;
    &lt;p&gt;Scrapping a seven year effort in favor of a weeks-long rebuild wasn't a decision we took lightly. With a high-profile, government-wide rollout already announced, intense public scrutiny, and OPM's painful history of failed attempts, the idea must have sounded insane to many. Yet, it was somehow the most reasonable path forward.&lt;/p&gt;
    &lt;p&gt;We were up until 3AM that night detailing next steps. We made a plan for what to do, who to talk to, and how to divide the work. By the next morning, we were off to the races.&lt;/p&gt;
    &lt;head rend="h2"&gt;A New Technical Direction&lt;/head&gt;
    &lt;p&gt;The approach we set for OPM was to stand up a digital platform that could connect every source of retirement information, and serve a modern experience to every user in the process. We leveraged industry standard web technologies, while integrating with some of OPM‚Äôs existing expertise to prioritize easy adoption and longevity. Beyond just enabling our immediate team to move fast, we needed to set a foundation for years to come beyond our direct involvement. The technologies we chose were broadly adopted by the developer community, well documented, and battle-tested.&lt;/p&gt;
    &lt;p&gt;This would usually be the part of a technical blog where we would brag about fancy frameworks or proudly show off a unique architecture design. The reality is we simply stuck to solid fundamentals: understand your query patterns, make sure tables are properly indexed, write efficient joins, and execute things in batch - and when the time calls for it, move long-running processes off the main application and onto asynchronous workers (we used Azure Functions).&lt;/p&gt;
    &lt;p&gt;An additionally unique aspect of government was that it can be challenging to get third party vendor tooling. As a result, we often built much of our own tooling from scratch, including our own roles based permissioning system and a feature flagging system.&lt;/p&gt;
    &lt;p&gt;All of this was developed in the ensuing weeks towards launch. After a blur of late nights, last minute bug fixes, and constant communication with the OPM team, we finally got it done.&lt;/p&gt;
    &lt;p&gt;On June 2, 2025, retire.opm.gov went live. By August 4th, almost every agency in the federal government was using the new Online Retirement Application, ending all paper submissions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Designing A Better Experience&lt;/head&gt;
    &lt;p&gt;With the system online, there were still many improvements to be made. Like taxes, applying for retirement was still an incredibly confusing process. Working closely with talented designers and the Retirement Services team at OPM, we set out to reinvent the user experience from end-to-end.&lt;/p&gt;
    &lt;p&gt;During the day we‚Äôd collaborate closely with Retirement Services to synthesize feedback from users all across the government. At night, we‚Äôd lock in and address every last issue and complaint.&lt;/p&gt;
    &lt;p&gt;Impactful features came out of this: the new Online Retirement Application now incorporates a live annuity estimator so users can see how their choices for benefits and elections impact their annuity in real-time as they fill out their application, instead of finding out months later as they receive their first check.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Promise Of ‚ÄúInstant‚Äù Retirement&lt;/head&gt;
    &lt;p&gt;Even though retirees and agencies now work on a modern digital foundation, the delays and redundant steps have not yet been fully eliminated. Retirees still wait longer than necessary for their full paycheck.&lt;/p&gt;
    &lt;p&gt;Fortunately, we stumbled on a critical clue. While poring over old documentation, we discovered that OPM actually had data warehouses that stored historic information about every federal employee. Apparently, these warehouses were created as part of a modernization effort in 2007, and HR and payroll offices all across government have supposedly been regularly reporting into it.&lt;/p&gt;
    &lt;p&gt;For some reason however, this was not well known at OPM, and those that knew about it didn‚Äôt know what data it held, nor considered how it could be used to simplify retirement processing. Not many had seen the data, and administrators were initially resistant to sharing access.&lt;/p&gt;
    &lt;p&gt;From a software perspective, this was the holy grail: a single source of truth that held all the information that the manual redundant steps were meant to review. Because the information was regularly reported by HR and payroll, by the time an employee retired, OPM should already have everything needed to process the retirement, without anyone re-entering or re-verifying information.&lt;/p&gt;
    &lt;p&gt;We needed to see this data for ourselves. After weeks of navigating through a jungle of bureaucratic red-tape, what we finally uncovered was eye-opening: the data was far richer and higher-quality than anyone had anticipated. All along, OPM had actually been sitting on top of a digital version of their underground Mine. It had just been forgotten and buried over time.&lt;/p&gt;
    &lt;p&gt;The hypothesis was clear: if we could successfully incorporate this high-quality data into the new digital workflow ‚Äî and prove its reliability to every stakeholder along the way ‚Äî we could eliminate the time-consuming manual checks entirely.&lt;/p&gt;
    &lt;p&gt;Operations gave us 500 recently processed applications to test with, and we queried the data out of the databases into the official annuity calculator. Result: Every non-complex case matched down to the penny. This proved that the buried digital mine was accurate enough to pay retirees their exact amount on day one.&lt;/p&gt;
    &lt;p&gt;Around the agency, people were excited, but still tentative: What about missing fields? What about the messy edge cases?&lt;/p&gt;
    &lt;p&gt;Our solution was through product design. The ‚ÄúInstant‚Äù experience would be a ‚Äúshow but verify‚Äù type of experience. Retirees see their application pre-filled from OPM's data, then get the opportunity to make corrections. If the data looks correct and they don't make elections that complicate the case, the application qualifies as "Instant".&lt;/p&gt;
    &lt;p&gt;We launched this offering in the new Online Retirement Application (ORA), where thousands of cases now qualify for ‚ÄúInstant‚Äù processing.&lt;/p&gt;
    &lt;p&gt;Last month, we returned to the Mine to pilot these with the team using real retirements. Deep underground, next to the old stacks of paper, the team triggered their first ever ‚Äúinstantly adjudicated‚Äù application. The experiment‚Äôs success proved what we had hoped: OPM‚Äôs existing data could reliably process Instant cases without manual work.&lt;/p&gt;
    &lt;p&gt;Now, with everyone bought into the vision, we are setting our sights towards making Instant retirement a widespread reality.&lt;/p&gt;
    &lt;head rend="h2"&gt;What‚Äôs Next&lt;/head&gt;
    &lt;p&gt;Over the next few months the technical work will only get more sophisticated as we aim to create the first truly automated retirement process end-to-end. Imagine ‚ÄúFull Self-Driving‚Äù with no manual interventions or redundant checks, delivering rapid retirements and paychecks for our retiring civil servants.&lt;/p&gt;
    &lt;p&gt;We‚Äôll expand the ‚ÄúInstant‚Äù program government-wide by partnering with HR and payroll offices to simplify some of their processes as well. It‚Äôs not just the OPM portion that will experience faster processing and reduced backlogs, every participant in the process will see improvements.&lt;/p&gt;
    &lt;p&gt;Along the way, we‚Äôll also keep building the tools our users need. From simple wins like bulk case management and real-time dashboards, to sophisticated AI that flags potential issues early, these tools will further help to reduce processing time, even for cases where manual work is still necessary.&lt;/p&gt;
    &lt;p&gt;Our initial data warehouse discovery unlocked the first Instant cases, but dozens of other systems ‚Äî payroll, insurance, personnel records ‚Äî hold valuable data. New integrations are coming which will result in more pre-filled fields, fewer errors, and faster, more accurate outcomes.&lt;/p&gt;
    &lt;p&gt;The pattern is consistent - the data to streamline federal services often already exists, it's just sitting in disconnected systems that don't talk to each other. Connect them, and suddenly month-long processes can become instant.&lt;/p&gt;
    &lt;p&gt;Outdated systems are everywhere in government, and initiatives like ours are exactly what the President‚Äôs Executive Order earlier this year called for. We hope this project serves as a blueprint for similar efforts, demonstrating how to successfully drive the technological and operational changes needed to bring government into the modern era.&lt;/p&gt;
    &lt;head rend="h2"&gt;Reflections&lt;/head&gt;
    &lt;p&gt;A year ago, government work wasn't even on our radar. But the reality surprised us.&lt;/p&gt;
    &lt;p&gt;Every federal employee who retires from now on can use what we built ‚Äî for all 2.3 million current employees and everyone who follows. We shipped a government-wide system in six months, built to last. Few places let you create this kind of impact this fast.&lt;/p&gt;
    &lt;p&gt;The problems are genuinely interesting ‚Äî integrating fragmented systems with no single source of truth, encoding decades of retirement law, bridging legacy tech, building trust in automation, and driving the operational shifts to match.&lt;/p&gt;
    &lt;p&gt;We built most of this as a small team of two engineers. We're still building, and there‚Äôs many more opportunities like this throughout the government. If this sounds like the kind of problem you want to work on, we should talk.&lt;/p&gt;
    &lt;p&gt;Thank you to Scott Kupor, Joe Gebbia, the OPM Retirement Services team, and countless others for their partnership in making this project a reality. Additional thanks to Edward Coristine and Zach Terrell for reviewing this blog post.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46402327</guid><pubDate>Sat, 27 Dec 2025 15:02:30 +0000</pubDate></item><item><title>New York to require social media platforms to display mental health warnings</title><link>https://www.reuters.com/legal/litigation/new-york-require-social-media-platforms-display-mental-health-warnings-2025-12-26/</link><description>&lt;doc fingerprint="1d97ce2908809a39"&gt;
  &lt;main&gt;
    &lt;p&gt;Dec 26 (Reuters) - Social media platforms with infinite scrolling, auto-play and algorithmic feeds will be required to display warning labels about their potential harm to young users‚Äô mental health under a new law, New York Governor Kathy Hochul announced on Friday.&lt;/p&gt;
    &lt;p&gt;"Keeping New Yorkers safe has been my top priority since taking office, and that includes protecting our kids from the potential harms of social media features that encourage excessive use," Hochul said in a statement.&lt;/p&gt;
    &lt;p&gt;Sign up here.&lt;/p&gt;
    &lt;p&gt;This month Australia imposed a social media ban for children under 16. New York joins states like California and Minnesota that have similar social media laws.&lt;/p&gt;
    &lt;p&gt;The New York law includes platforms that offer "addictive feeds," auto play or infinite scroll, according to the legislation. The law applies to conduct occurring partly or wholly in New York but not when the platform is accessed by users physically outside the state.&lt;/p&gt;
    &lt;p&gt;It allows the state's attorney general to bring legal action and seek civil penalties of up $5,000 per violation of the law.&lt;/p&gt;
    &lt;p&gt;Hochul compared the social media labels to warnings on other products like tobacco, where they communicate the risk of cancer, or plastic packaging, where they warn of the risk of suffocation for small children.&lt;/p&gt;
    &lt;p&gt;Spokespeople for TikTok, Snap (SNAP.N), Meta (META.O), and Alphabet (GOOGL.O) did not immediately respond to requests for comment.&lt;/p&gt;
    &lt;p&gt;The effect of social media on children's mental health has become a growing global concern, with U.S. school districts suing Meta Platforms and other social media companies.&lt;/p&gt;
    &lt;p&gt;In 2023, the U.S. surgeon general issued an advisory on safeguards for children and later called for social media warning labels like the one now required in New York.&lt;/p&gt;
    &lt;p&gt;Reporting by Jasper Ward in Washington; Additional reporting by Harshita Varghese in Bangalore; Editing by Howard Goller&lt;/p&gt;
    &lt;p&gt;Our Standards: The Thomson Reuters Trust Principles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46402609</guid><pubDate>Sat, 27 Dec 2025 15:41:50 +0000</pubDate></item><item><title>A Century of Noether's Theorem</title><link>https://arxiv.org/abs/1902.01989</link><description>&lt;doc fingerprint="a49c240a54f5908a"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Physics &amp;gt; History and Philosophy of Physics&lt;/head&gt;&lt;p&gt; [Submitted on 6 Feb 2019 (v1), last revised 9 Jul 2019 (this version, v2)]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Colloquium: A Century of Noether's Theorem&lt;/head&gt;View PDF&lt;quote&gt;Abstract:In the summer of 1918, Emmy Noether published the theorem that now bears her name, establishing a profound two-way connection between symmetries and conservation laws. The influence of this insight is pervasive in physics; it underlies all of our theories of the fundamental interactions and gives meaning to conservation laws that elevates them beyond useful empirical rules. Noether's papers, lectures, and personal interactions with students and colleagues drove the development of abstract algebra, establishing her in the pantheon of twentieth-century mathematicians. This essay traces her path from Erlangen through G√∂ttingen to a brief but happy exile at Bryn Mawr College in Pennsylvania, illustrating the importance of "Noether's Theorem" for the way we think today. The text draws on a colloquium presented at Fermilab on 15 August 2018.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Chris Quigg [view email]&lt;p&gt;[v1] Wed, 6 Feb 2019 00:51:17 UTC (183 KB)&lt;/p&gt;&lt;p&gt;[v2] Tue, 9 Jul 2019 18:15:15 UTC (183 KB)&lt;/p&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;physics.hist-ph&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46402611</guid><pubDate>Sat, 27 Dec 2025 15:42:02 +0000</pubDate></item><item><title>Nvidia Just Paid $20B for a Company That Missed Its Revenue Target by 75%</title><link>https://blog.drjoshcsimmons.com/p/nvidia-just-paid-20-billion-for-a</link><description>&lt;doc fingerprint="3350914c4df605bc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Nvidia Just Paid $20 Billion for a Company That Missed Its Revenue Target by 75%&lt;/head&gt;
    &lt;head rend="h3"&gt;Panic buying, plain and simple. If anything indicates that this AI bubble is about to pop, it‚Äôs this.&lt;/head&gt;
    &lt;head rend="h2"&gt;First, Let‚Äôs Clear Up the Groq Confusion&lt;/head&gt;
    &lt;p&gt;If you‚Äôve heard ‚ÄúGrok‚Äù thrown around lately, you‚Äôre probably thinking of Elon‚Äôs chatbot from xAI. We‚Äôre not talking about that one. That model isn‚Äôt particularly good, but its whole value prop is being politically incorrect so you can get it to say edgy things.&lt;/p&gt;
    &lt;p&gt;The company Nvidia bought is Groq (with a Q). Totally different beast.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Groq Actually Does&lt;/head&gt;
    &lt;p&gt;If you‚Äôve used any high quality LLM, you‚Äôve noticed it takes a while to generate a response. Especially for something rapid fire like a conversation, you want high quality AND speed. But speed is often what gets sacrificed. There‚Äôs always that ‚Äúthinking... gathering my notes... taking some time to form the best response‚Äù delay.&lt;/p&gt;
    &lt;p&gt;Groq specialized in hardware and software that makes this way faster. They created a new type of chip called an LPU (Language Processing Unit). It‚Äôs based on an ASIC, an application specific integrated circuit. If that‚Äôs confusing, don‚Äôt worry about it. It‚Äôs just a processor that does a specific type of task really well.&lt;/p&gt;
    &lt;p&gt;So imagine you‚Äôre talking to Gemini and it takes a couple seconds to respond. Now imagine it responded instantly, like 10 or 100 times faster. That‚Äôs the problem Groq was solving.&lt;/p&gt;
    &lt;head rend="h3"&gt;I Explain LPUs vs GPUs So That Anyone Can Understand Them In One Minute&lt;/head&gt;
    &lt;p&gt;To go one level deeper on LPUs versus GPUs (the processors most LLMs run on, typically Nvidia cards): those GPU calculations have to access a lot of things in memory. Nvidia‚Äôs chips depend on HBM, high bandwidth memory. But LPUs use something called SRAM that‚Äôs much faster to reference.&lt;/p&gt;
    &lt;p&gt;Think about it like this. Your wife has a grocery list for you. You go to the store but forget the list. Every time you‚Äôre in an aisle, you have to call her on the phone: ‚ÄúHey, do I need anything from the bread aisle?‚Äù Get the bread. Put the phone down. Go to the next aisle. ‚ÄúHey, do I need anything from canned goods?‚Äù And so on through produce, meat, pick up the beer, check out, get home. Very inefficient.&lt;/p&gt;
    &lt;p&gt;Groq‚Äôs approach is like you just took the list to the store. Get to a new aisle, look at the list. Next aisle, look at the list. Much faster than a phone call.&lt;/p&gt;
    &lt;p&gt;That‚Äôs the key difference. Nvidia GPUs are phoning out every time they hit a new aisle. Groq‚Äôs LPUs mean the shopper has the list in their pocket.&lt;/p&gt;
    &lt;head rend="h3"&gt;Groq‚Äôs Business Model&lt;/head&gt;
    &lt;p&gt;Groq‚Äôs main offering is GroqCloud. An engineer like me isn‚Äôt going to go out and buy an LPU (I don‚Äôt even know if they‚Äôre commercially available). What I‚Äôm going to do is, if I need lightning fast response in an application I‚Äôm building, I‚Äôll use GroqCloud. That inference happens at an extremely fast rate, running on LPUs in a data center somewhere.&lt;/p&gt;
    &lt;p&gt;Their value prop is: fast, cheap, low energy.&lt;/p&gt;
    &lt;p&gt;Where they‚Äôve been falling short is they mostly use open source models. Llama, Mistral, GPT-OSS (OpenAI‚Äôs open source offering). These are decent models, but nowhere near the quality of something like Anthropic‚Äôs Opus 4.5 or Gemini 3 Pro.&lt;/p&gt;
    &lt;p&gt;Groq positioned themselves for hardcore use cases where milliseconds matter. One of their big industry fits is real time data analysis for Formula 1. When your driver‚Äôs out there on the track, you don‚Äôt have time to send a query to Gemini and wait 20 to 30 seconds to figure out if you should pit this guy for new tires this lap. You want something like Groq which does pretty good analysis, really really really fast.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Financials Are Where This Gets Insane&lt;/head&gt;
    &lt;p&gt;This is insider baseball you‚Äôre going to miss from mainstream news headlines. The media is paying attention to Grok (Elon‚Äôs chatbot), not Groq (the chip company). This isn‚Äôt a conspiracy, it‚Äôs just that the only people aware of Groq are software developers and tech nuts like me.&lt;/p&gt;
    &lt;p&gt;This is a canary in the coal mine for worse things to come in 2026.&lt;/p&gt;
    &lt;head rend="h3"&gt;What Valuation?&lt;/head&gt;
    &lt;p&gt;About a year ago, Groq announced a $1.5 billion infrastructure investment deal with Saudi Arabia. They also secured a $750 million Series D funding round. These are crazy multiples even for a software company that‚Äôs somewhat leveraged in hardware. Bubble level projections.&lt;/p&gt;
    &lt;p&gt;To visualize $1.5 billion: if you cashed that check out in $100 bills and stacked them one on top of another, it would reach a five story building. For ordinary plebeians like us, at the average US salary of around $75K, you‚Äôd need to work 20,000 years to earn that.&lt;/p&gt;
    &lt;p&gt;At that time, the company was valued at $2 billion. Hello bubble.&lt;/p&gt;
    &lt;p&gt;Then in maybe one of the best rug pulls of all time, in July they quietly changed their revenue projections to $500 million.1 A 75% cut in four months. I‚Äôve never seen anything like that since the 2008 financial crisis.&lt;/p&gt;
    &lt;p&gt;This was a company valued at $2 billion, enough that the government of Saudi Arabia was investing at that valuation. Then they took a 75% haircut four months later without anything major happening.&lt;/p&gt;
    &lt;p&gt;If it can happen to Groq, who else can it happen to? Nvidia? Intel?&lt;/p&gt;
    &lt;head rend="h3"&gt;Was It an Early Christmas Present?&lt;/head&gt;
    &lt;p&gt;The rumors started flying on Christmas Eve. Confirmed the 26th: Nvidia will be buying Groq, their key product line, and key personnel including the CEO, for $20 billion.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs walk through that again:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;February: $2 billion valuation&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;July: Down to $500 million&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;December: Nvidia buys them for $20 billion after they took a 75% haircut&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What is going on? This is a bubble.&lt;/p&gt;
    &lt;p&gt;The only explanation is this is a fear purchase. Groq was promising faster, cheaper, more efficient, less electricity use for their chips. But they couldn‚Äôt scale fast enough to compete with the vendor lock in and buddy system Nvidia has going.&lt;/p&gt;
    &lt;p&gt;Nvidia‚Äôs buying them with their insanely inflated war chest. They don‚Äôt want a chunk taken out of their market share. They can‚Äôt afford to take that chance. So it‚Äôs like they‚Äôre just saying: ‚ÄúShut up, take the $20 billion, walk away from this project.‚Äù&lt;/p&gt;
    &lt;p&gt;This is a sign that in order to succeed, Nvidia needs a monopoly on the market. Otherwise they would not pay ten times the company‚Äôs valuation that was then decreased by 75%. This is a desperate move to consolidate the market into ‚Äúyou have to go with us.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;Monopoly Is The Name of the Game&lt;/head&gt;
    &lt;p&gt;Saudi Arabia didn‚Äôt keep that $1.5 billion sitting around. They redirected it to Nvidia and AMD instead. Nvidia still gets paid ofc.&lt;/p&gt;
    &lt;p&gt;Smaller competitors like Cerebras and Inflection, doing things in Groq‚Äôs space or exploring different architectures for AI inference, are canceling IPOs, dropping like flies, seeking emergency funding. The chatter I‚Äôm hearing from VCs and friends in that world? Ain‚Äôt nobody buying it right now.&lt;/p&gt;
    &lt;p&gt;Google made their own chip. Microsoft and Amazon are racing to make competition chips that run on less electricity, are more efficient, faster. But no matter what anybody does, the market is consolidating around the Nvidia monopoly for AI hardware. Engineers like me and architects at large enterprises are trying to escape this. Once they consolidate enough of the market, they can set their price for chips and usage. If you don‚Äôt own them, you go through Oracle or some cloud computing service, and they can charge whatever they want because there will be no competitors. Even a competitor having a rough time but getting some traction? They just buy them out for $20 billion because with this monopoly going, that‚Äôs pocket change.&lt;/p&gt;
    &lt;p&gt;$20 billion is a rounding error to Nvidia.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Power Crisis Nobody‚Äôs Talking About&lt;/head&gt;
    &lt;p&gt;The AI infrastructure boom ran on one large errant assumption: that power is cheap and plentiful. That assumption was very, very wrong.&lt;/p&gt;
    &lt;p&gt;We‚Äôve seen parts of the power grid fail, go unmaintained. There‚Äôs a great article on Palladium called ‚ÄúThe Competency Crisis‚Äù that explains some of what‚Äôs going on in the US right now. Electricity is now the bottleneck. It‚Äôs the constraint. Too expensive or you can‚Äôt get enough of it. Who‚Äôs paying these costs? The tech companies aren‚Äôt. Trump is meeting with Jensen Huang, with Sam Altman. He hasn‚Äôt been over my place lately. He hasn‚Äôt invited you to the White House to talk about how you can‚Äôt afford groceries and eggs cost three times what they did a few years ago.&lt;/p&gt;
    &lt;p&gt;No.&lt;/p&gt;
    &lt;p&gt;You and I are going to pay to subsidize the electricity constraints.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Numbers Are Staggering&lt;/head&gt;
    &lt;p&gt;US data centers are using about 4% of all electricity right now. If growth continues at the same rate, in ten years they‚Äôll use 9%. Almost one tenth of all electricity generated in the US.&lt;/p&gt;
    &lt;p&gt;I‚Äôm not much of an environmentalist. But even someone like me, pretty jaded to some amount of waste because of industrialization, something like this actually makes my stomach turn. In places with lots of data centers, AI heavy regions, they‚Äôre experiencing about a 250% increase in energy costs compared to just five years ago. That‚Äôs huge. Even compared to grocery costs, which are out of control. At least with food you have alternatives. Red meat too expensive? Buy chicken. Chicken too expensive? Buy eggs. But electricity? You have to run electricity. It‚Äôs a public utility. You can‚Äôt just ‚Äúuse a lot less‚Äù when your bill goes up 2.5x.&lt;/p&gt;
    &lt;head rend="h3"&gt;How Data Center Deals Actually Work&lt;/head&gt;
    &lt;p&gt;Let me walk you through what happens. Some business development guy from Oracle wants to build a new data center in Rural America. A year before it‚Äôs even built, they meet with city officials, maybe the governor. They grease the right people. Get legislation passed with the utility companies that says they‚Äôll pay a preferential rate for electricity because they‚Äôre going to use a shit ton.&lt;/p&gt;
    &lt;p&gt;They‚Äôre Oracle or Nvidia, they‚Äôre good for it. They pay five years upfront. Then the utility decides what to do with the rest of the electricity. The grid is strained. They want everyone else to use less. They can‚Äôt just tell them to use less, so they keep raising the price until naturally you just can‚Äôt afford to use more.&lt;/p&gt;
    &lt;p&gt;You turn the lights off. Turn the TV off. Get those LED bulbs that disrupt your sleep. Do everything to keep electricity costs down. But you and I are left holding the bag. The data center folks aren‚Äôt paying for that, they paid upfront at a preferential rate.&lt;/p&gt;
    &lt;p&gt;Senate Democrats are allegedly investigating this. I‚Äôll believe it when I see it. These tech companies have their hooks so far into influential politicians. It‚Äôs a vote grab. I‚Äôd be happy to be wrong about that, but I know I‚Äôm not going to be.&lt;/p&gt;
    &lt;head rend="h2"&gt;Infinite Money Glitch&lt;/head&gt;
    &lt;p&gt;I talked about this in my last piece on the AI bubble. This computer communism that‚Äôs going on, pricing you out of personal computing, keeping it all in the family of these tech companies. But with the Groq deal confirmed, it‚Äôs gone one step further. Nvidia is not just selling chips anymore. They are lending money to customers who buy the chips. They are artificially inflating demand.&lt;/p&gt;
    &lt;head rend="h3"&gt;Another Grocery Store Analogy&lt;/head&gt;
    &lt;p&gt;It‚Äôs like if I run a small grocery store and I need to show good signal to investors that I‚Äôm bringing cash in the door. So I go downtown during farmer‚Äôs market and give everybody a $20 voucher to use at my store. I take a wholesale hit when they come in and buy stuff. But what I can show is: ‚ÄúHey, people are coming in and spending money. Look at the revenue. Give me more venture capital money.‚Äù&lt;/p&gt;
    &lt;p&gt;This can‚Äôt work infinitely, for the same reason any perpetual motion machine can‚Äôt work.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Numbers&lt;/head&gt;
    &lt;p&gt;Back in September, Nvidia announced a $100 billion investment in OpenAI. Coming through in $10 billion tranches over time. And it‚Äôs not equity, it‚Äôs lease agreements for Nvidia‚Äôs chips. Literally paying them to pay themselves.There‚Äôs probably some tax shenanigans going on there since they‚Äôre typically offering $xxx in leases of their chips to the company they‚Äôre ‚Äúlending‚Äù to. Assuming they do this in part because the depreciation on the physical asset (the chips) can be written off on their taxes somehow. They‚Äôre essentially incentivizing another person to use them with money. Even OpenAI‚Äôs CFO has admitted, quote: ‚ÄúMost of the money will go back to Nvidia.‚Äù&lt;/p&gt;
    &lt;p&gt;They‚Äôre playing both sides. In the OpenAI case, they‚Äôre financing software that uses their chips. But they‚Äôre also getting their hooks into data centers.&lt;/p&gt;
    &lt;p&gt;CoreWeave: they have something like 7% share in the company. Worth $3 billion. That‚Äôs funded by GPU revenue from CoreWeave.&lt;/p&gt;
    &lt;p&gt;Lambda: another data center operator. That‚Äôs a $1.3 billion spending deal. Renting Nvidia‚Äôs own chips back from them.&lt;/p&gt;
    &lt;p&gt;They‚Äôve pledged to invest ¬£2 billion across British startups, which of course are going to go back to Nvidia chips one way or another.&lt;/p&gt;
    &lt;p&gt;In 2024, they invested about $1 billion across startups and saw a $24 billion return in chip spend. They 24x‚Äôd their billion dollar investment in one year. Nvidia has more power than the Fed right now. More power than the president over the economy. They have their hand on the knob of the economy. They can choose how fast or slow they want it to go. If the Nvidia cash machine stops printing, if they stop funding startups, data centers, hardware companies, software companies, that whole part of the economy slows way down and maybe crashes if investors get spooked.&lt;/p&gt;
    &lt;p&gt;I‚Äôm waiting for somebody to blow the whistle on this. I‚Äôm not a finance guy, so it‚Äôs strange I‚Äôm even talking about it. But their entire success story for the next couple years hinges on their $100 billion investment in OpenAI, which they‚Äôre expecting to bring back about $300 billion in chip purchases.&lt;/p&gt;
    &lt;p&gt;It‚Äôs vendor financing. It‚Äôs sweetening the pot on your own deals. I cannot believe more people are not talking about this.&lt;/p&gt;
    &lt;head rend="h2"&gt;OpenAI‚Äôs Financials Are Existential&lt;/head&gt;
    &lt;p&gt;OpenAI, the leader of this space, the company whose CEO Sam Altman is invited to the White House numerous times, probably has a direct line to Trump, a lot of the economy hinges on this guy‚Äôs strategy, opinions, and public statements.&lt;/p&gt;
    &lt;p&gt;And he runs a company that is not profitable. Actually insane if you think about it. All he‚Äôs done with that company, from an economics point of view, is rack up debt. Spent more than he‚Äôs earned.&lt;/p&gt;
    &lt;p&gt;By that metric, I‚Äôm richer than Sam Altman. Not in net worth. But if I consider myself a business and the fact that I bring in any salary at all, even a dollar a year, that would make me earn more than Sam Altman, who has only lost money. In the next few years, they‚Äôre expected to burn something like $75 billion a year. Just set that money on fire. I have a credit card with no preset spending limit, but I assume if I run up a $75 billion charge it‚Äôs going to get denied. By their projections, they think they‚Äôll become profitable around 2029/2030, and they need $200 billion in annual revenue to offset their debts and losses.&lt;/p&gt;
    &lt;p&gt;To visualize $200 billion: if you cashed that out in $100 bills and stacked them, it would reach halfway to the International Space Station. That‚Äôs how much they‚Äôd have to make every single year to just be profitable. Not be a massively successful company. Just to not spend more than they earn.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Year by Year&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;2024: Spent $5 billion, earned $3.7 billion. Spending $1.35 for every dollar earned.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;2025: Set $8 billion on fire (after profits).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;2028 (projected): Will lose $74 billion that year. Just lose it.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Cumulative losses through 2029: $143 billion.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;They‚Äôd need to make $200 billion in a year to offset that. Are they including interest? I have no idea how these things work, but in simple terms: they‚Äôre spending a lot more money than they make.&lt;/p&gt;
    &lt;head rend="h2"&gt;Bubble Signals for 2026&lt;/head&gt;
    &lt;p&gt;Groq was kind of a one off because Nvidia panic bought the competition. But they also need to figure out how to get prices down or they can‚Äôt keep this money machine moving.&lt;/p&gt;
    &lt;p&gt;Groq is probably one of the last companies that caught a good lifeboat off a sinking ship.&lt;/p&gt;
    &lt;p&gt;What we‚Äôre going to see this year: it‚Äôll start small, but get major. A company first, then multiple larger ones, that had a 2025 valuation, will go to raise. They‚Äôll do a 409A evaluation. A bunch of smart analysts will say what it‚Äôs worth to investors. And you‚Äôre going to see the valuation drop. They won‚Äôt be able to raise money.&lt;/p&gt;
    &lt;p&gt;Then the shit is really going to start to hit the fan.&lt;/p&gt;
    &lt;p&gt;The dominoes will start falling. That‚Äôs probably what kicks off the actual pop, and it‚Äôs imminent. Any day now.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Labor Displacement Shell Game&lt;/head&gt;
    &lt;p&gt;Part of the big gamble they‚Äôve sold investors is: we‚Äôve got to replace you. The worker. That‚Äôs why we need to spend so much money, go into debt. It‚Äôll all be worth it because then we won‚Äôt have to pay people to do these jobs anymore.&lt;/p&gt;
    &lt;p&gt;We‚Äôre going to continue to see massive labor displacement. To a degree this is a shell game, an investor illusion. What these larger enterprise companies are hoping to do: cut a lot of folks, have big layoffs, say it‚Äôs because AI is replacing the jobs.&lt;/p&gt;
    &lt;p&gt;In some cases they‚Äôre right. Data entry, for example. I don‚Äôt mean to be mean if you do data entry for a living, but there are models very good at that now. You need someone to manage the work, spot check it. But it‚Äôs kind of a job AI can do.&lt;/p&gt;
    &lt;p&gt;Like how grocery stores have automatic checkout lines now with one person monitoring six or eight of them. So some of that‚Äôs real. A lot of it isn‚Äôt though.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Pattern&lt;/head&gt;
    &lt;p&gt;They cut a bunch of American workers under the guise that AI‚Äôs replacing workers. A lot of these megacorp execs are actually convinced of it. Americans are expensive, especially tech workers.&lt;/p&gt;
    &lt;p&gt;Then they see: damn, maybe we could have cut some, but not as many. We got greedy. Now our services are failing in production. AWS in Northern Virginia is flaky, going down again. That just happened, by the way, direct result of these layoffs.&lt;/p&gt;
    &lt;p&gt;So instead they think, ‚ÄúWe‚Äôll look globally! Spin up a campus in Hyderabad!‚Äù Pay them way less. The cost of living is less there, they expect less. Bring them over on H-1B when needed. I‚Äôve written about the H-1B program. This is nothing against the individuals on that program. I‚Äôve worked with very talented H-1Bs, and some very inferior ones, just like American citizens.&lt;/p&gt;
    &lt;p&gt;But the corporate sleight of hand is something like this, we can get those H-1B visas, and they‚Äôre not going to ask for pesky stuff like Sunday off for church. We can put them on call 24/7 and they can‚Äôt say no because if they do, we kick them back to their country. Same thing that‚Äôs happened with migrant labor in farming over the past century. Even if it doesn‚Äôt look like it on the surface, corporations know that they can pay H-1B employees less than American citizens. If a US citizen and H-1B recipient both make $120k but the H-1B works double the hours because they have no room to push back and are under threat of being sent home, they are making 50% less than the American per-hour.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Numbers&lt;/head&gt;
    &lt;p&gt;Amazon/AWS: 14,000 laid off.&lt;/p&gt;
    &lt;p&gt;Microsoft: 15,000 total just in 2025.&lt;/p&gt;
    &lt;p&gt;Salesforce: My favorite one. 4,000 customer support roles cut. And the CEO is gloating about it in interviews. So great that he can replace workers!&lt;/p&gt;
    &lt;p&gt;Now Salesforce is admitting that they fucked up. They cut too many people.&lt;/p&gt;
    &lt;head rend="h3"&gt;Smoke Filled Backrooms&lt;/head&gt;
    &lt;p&gt;I‚Äôve been on the other side of this when I was an engineering director at a Fortune 500 company. They were neurotic about tracking AI use. Spending an exorbitant amount of money on shitty AI tools. Like tools from a year ago. GPT-4o in the GPT-5 era, in the Anthropic dominance era. More or less useless.&lt;/p&gt;
    &lt;p&gt;Not only would they monitor all usage across employees, specifically who‚Äôs using it how much, they could see every single message being sent to the AI. So theoretically you could check somebody‚Äôs queries and do a performance evaluation based on where you perceive them to be.&lt;/p&gt;
    &lt;p&gt;Pretty creepy.&lt;/p&gt;
    &lt;p&gt;They‚Äôre using yesterday‚Äôs tools because of regulation and compliance, blowing an absurd amount of money. The CEO just sees a lot going out the door: ‚ÄúI thought these were supposed to save money, what‚Äôs going on here?‚Äù So his lieutenants have to get a grip on it, monitor everything. Even at Amazon this is being included in performance reviews, how much they‚Äôre using AI.&lt;/p&gt;
    &lt;p&gt;That‚Äôs why if you‚Äôre a software developer wondering why your boss is on you about using AI tools. They‚Äôre probably getting pressure from their bosses. I want my engineers to be as productive as possible. I think AI is probably part of that tool belt for everyone at this point. But is tracking it really the best way? I‚Äôm going to gauge performance on metrics, how you interacted with the team, what you shipped. It puts the cart before the horse to say you‚Äôre paid by how much you use these AI tools. If I‚Äôm a developer, I‚Äôm just spinning up a script to send lorem ipsum text 24 hours a day, get maximum ratings because I used GPT-3.5 the most.&lt;/p&gt;
    &lt;head rend="h2"&gt;The MIT Study That Should Scare Everyone&lt;/head&gt;
    &lt;p&gt;MIT did a study in summer 2025. They‚Äôre saying 95% of companies report zero measurable ROI on AI products.&lt;/p&gt;
    &lt;p&gt;Actually not that crazy if you consider that a lot of them did layoffs and subbed in AI. That‚Äôs just going according to plan in my estimation.&lt;/p&gt;
    &lt;p&gt;They estimate about $30 to $40 billion has been spent on enterprise AI. That‚Äôs the money your JPMorgan Chase is spending for their engineers to use Claude Code or whatever dated tool they have access to.&lt;/p&gt;
    &lt;p&gt;The market heard that signal. When that study came out:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Nvidia crashed 3.5%&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Palantir down 10%&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Nasdaq in general down 1.2%&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;That last one isn‚Äôt encouraging for an AI bubble pop because it indicates this is a big part of the economy.&lt;/p&gt;
    &lt;head rend="h2"&gt;What to Look Out For&lt;/head&gt;
    &lt;p&gt;January through February: Maybe down valuations, just a very flat market without much growth.&lt;/p&gt;
    &lt;p&gt;Q1 to Q2: We‚Äôll start to see a couple businesses, or maybe one major one at first like a domino starting to fall, not able to raise capital at their 2025 valuation. We‚Äôll see valuations go down. VCs will be like: ‚ÄúNot touching it, not giving them more money, cutting our losses.‚Äù&lt;/p&gt;
    &lt;p&gt;Then timing a little more indeterminate but these things will happen quickly in succession:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Credit markets start to tighten&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Debt refinancing pressure builds up in the system&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Nvidia revises its revenue guidance to something at least vaguely linked to reality&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And that‚Äôs when the big reckoning begins.&lt;/p&gt;
    &lt;head rend="h2"&gt;AI Isn‚Äôt Going Anywhere&lt;/head&gt;
    &lt;p&gt;I want to be clear. AI is not going anywhere. It‚Äôs going to continue being a mainstream part of the world. I like a lot of these tools, I think they‚Äôre very helpful.&lt;/p&gt;
    &lt;p&gt;But the talking heads have really promised us the world. It‚Äôs clear the technology cannot deliver above and beyond what it‚Äôs doing now.&lt;/p&gt;
    &lt;p&gt;We‚Äôve seen progress of these models slow at an exponential rate of slowing over the past few releases. Each release is better, but the gap between the current release and the last release is much smaller than it used to be.&lt;/p&gt;
    &lt;p&gt;Because of that, a lot of these AI companies are going to survive, but their valuations are going to get giga slashed.&lt;/p&gt;
    &lt;p&gt;Valuations of $500 billion for OpenAI, $42 billion for Anthropic are unsustainable. We‚Äôre going to actually see them become unsustainable in 2026 as they‚Äôre eventually cut. Smaller companies will face those slashes first. But it‚Äôs coming for the major AI labs as well.&lt;/p&gt;
    &lt;p&gt;This is good news, honestly. This AI hype has really turned tech into something different these days, different than it used to be. While I don‚Äôt feel AI is going anywhere, I do feel we‚Äôll get a little more back to normal once this bubble pops and resolves.&lt;/p&gt;
    &lt;p&gt;What do you think? Drop a comment below. Subscribe if you found this interesting.&lt;/p&gt;
    &lt;p&gt;Previously I incorrectly reported this as valuation. https://www.investing.com/news/company-news/groq-slashes-2025-revenue-projections-to-500-million--the-information-93CH-4158309&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46403041</guid><pubDate>Sat, 27 Dec 2025 16:47:13 +0000</pubDate></item><item><title>This PNG shows a different version when loaded in Chrome than in Safari</title><link>https://lr0.org/blog/p/pngchanges/</link><description>&lt;doc fingerprint="6803d4327f5183ae"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Opening this PNG in Chrome shows a different image than in Safari or any desktop app&lt;/head&gt;&lt;p&gt;Check this beautiful painting, Pleading, an artwork by Sir Lawrence Alma-Tadema:&lt;/p&gt;If you are using Firefox or a Chromium browser (for me Google Chrome 143.0.7499.170), it's very likely that you are seeing a very foggy version of the painting, however, if you download the image and open it with your default image viewer (or open it in the Safari browser), you will see the image normally.&lt;p&gt;My website contains some of these artworks, you're probably looking at one now on the right side of the page if you are reading from a desktop browser, I sent one of the pages to my friend and he told me that the image looks foggy, and I spent hours debugging a nasty edge case in how browsers handle PNG color profiles.&lt;/p&gt;&lt;head rend="h2"&gt;What's going on&lt;/head&gt;&lt;p&gt;You open a PNG screenshot in your desktop app, it looks great, you include it in a web page suddenly there's a white, foggy veil over everything. The contrast is wrong, colors look washed out, and you're left wondering if the file got corrupted somehow. The instinct? ‚ÄúSomething must be wrong with the image encoding.‚Äù Maybe it's alpha transparency? Gamma? Some weird metadata? (will tbh this was not really my instinct, I first debugged my web server for 20 minutes.)&lt;/p&gt;&lt;head rend="h3"&gt;Attempt 1: Strip Metadata and Fix Alpha&lt;/head&gt;&lt;p&gt;The first suspect is usually alpha channel issues or embedded metadata:&lt;/p&gt;&lt;code&gt;mogrify -strip -alpha off -alpha on -colorspace sRGB *.png&lt;/code&gt;&lt;p&gt;Result: No change. The images still look foggy in Chrome.&lt;/p&gt;&lt;head rend="h3"&gt;Attempt 2: Fix the Gamma&lt;/head&gt;&lt;p&gt;When you run &lt;code&gt;identify -verbose&lt;/code&gt; on the image, you might see:&lt;/p&gt;&lt;quote&gt;Gamma: 0.454545&lt;/quote&gt;&lt;p&gt;Aha! Surely this is a gamma correction issue. Chrome must be applying gamma math differently than desktop apps.&lt;/p&gt;&lt;code&gt;mogrify -gamma 2.2 -colorspace sRGB -strip *.png&lt;/code&gt;&lt;p&gt;Result: The image gets even more foggy. Now it's worse!&lt;/p&gt;&lt;p&gt;(fun-related fact: ImageMagick's &lt;code&gt;identify&lt;/code&gt; command
reports an assumed gamma for PNG decoding, not necessarily the
presence of an actual &lt;code&gt;gAMA&lt;/code&gt; chunk in the file. You were chasing a
phantom.)&lt;/p&gt;&lt;head rend="h3"&gt;Attempt 3: Nuclear option&lt;/head&gt;&lt;p&gt;Fine, let's just rewrite all the pixels from scratch:&lt;/p&gt;&lt;code&gt;mogrify -alpha remove -background white -flatten -colorspace sRGB *.png&lt;/code&gt;&lt;p&gt;Result: Still foggy. Nothing changed.&lt;/p&gt;&lt;p&gt;Because the problem isn't in the pixel data at all.&lt;/p&gt;&lt;head rend="h3"&gt;Attempt 4: Remove the gAMA Chunk&lt;/head&gt;&lt;p&gt;Maybe it's that pesky gamma chunk after all. Let's use &lt;code&gt;pngcrush&lt;/code&gt; to
remove it without touching the pixels:&lt;/p&gt;&lt;code&gt;pngcrush -ow -rem gAMA -rem cHRM -rem iCCP -rem sRGB *.png&lt;/code&gt;&lt;p&gt;Result: Still no change.&lt;/p&gt;&lt;p&gt;Plot twist; here was never a &lt;code&gt;gAMA&lt;/code&gt; chunk to begin with!&lt;/p&gt;&lt;head rend="h3"&gt;The Smoking Gun&lt;/head&gt;&lt;p&gt;After all these failed attempts, it's time to actually look at what's in the PNG file:&lt;/p&gt;&lt;code&gt;pngcheck -v image.png&lt;/code&gt;&lt;p&gt;The output reveals the truth:&lt;/p&gt;&lt;quote&gt;chunk iCCP at offset 0x00025, length 5147 profile name = ICC Profile, compression method = 0 (deflate) compressed profile = 5134 bytes&lt;/quote&gt;&lt;p&gt;There it is: an embedded ICC color profile, about 5KB in size. No &lt;code&gt;gAMA&lt;/code&gt; chunk. No broken alpha. Just an ICC profile&lt;/p&gt;&lt;head rend="h3"&gt;What's Really Happening&lt;/head&gt;&lt;p&gt;(1) The PNG contains an embedded ICC color profile* (likely Display-P3 or another wide-gamut color space), (2) Chrome fully honors ICC profiles and performs proper color management (3) Desktop image viewers often ignore or approximate ICC profiles to keep things simple.&lt;/p&gt;&lt;p&gt;Result: Chrome shows you what the image actually looks like according to its embedded profile, while desktop apps (and apparently Safari) show you a ‚Äúhelpful lie‚Äù.&lt;/p&gt;&lt;p&gt;The paintings came from the internet, likely screenshots from macOS, iOS, or modern web tools that default to the Display-P3 color space. The pixel values are encoded for Display-P3, but when Chrome renders them, it respects that color space. Desktop apps? They just assume sRGB and move on.&lt;/p&gt;&lt;p&gt;You don't want to strip the ICC profile, that would leave Display-P3 pixel values being interpreted as sRGB, making things worse. You need to convert the pixels to sRGB:&lt;/p&gt;&lt;code&gt;magick mogrify -profile /System/Library/ColorSync/Profiles/sRGB\ Profile.icc *.png&lt;/code&gt;&lt;p&gt;This command does three things: 1. Reads the embedded ICC profile 2. Converts the pixel values from that color space to sRGB 3. Embeds a correct sRGB ICC profile&lt;/p&gt;&lt;p&gt;After running this, Chrome will display the images correctly, matching what you saw in your desktop apps all along.&lt;/p&gt;&lt;p&gt;Unironically we're living in a world where modern devices support Display-P3, DCI-P3, and other wider color spaces but some apps do full color management, others fake it.&lt;/p&gt;&lt;p&gt;The ‚Äúhelpful lies‚Äù that desktop image viewers tell you (ignoring ICC profiles, making assumptions about color space) work great until you need actual color accuracy. Then they break down.&lt;/p&gt;&lt;p&gt;Takeaways:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Chrome was not wrong. it's doing proper color management by respecting the embedded ICC profile&lt;/item&gt;&lt;item&gt;Desktop apps might lie. they ignore color profiles to avoid confusion, but this masks the real issue&lt;/item&gt;&lt;item&gt;Identify might mislead you. the ‚ÄúGamma‚Äù value it reports is often ImageMagick's assumption, not file metadata&lt;/item&gt;&lt;item&gt;Convert, don't strip. When dealing with ICC profiles, you must convert pixel values to the target color space, not just remove the profile&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46403048</guid><pubDate>Sat, 27 Dec 2025 16:48:18 +0000</pubDate></item><item><title>VSCode rebrands as "The open source AI code editor"</title><link>https://code.visualstudio.com</link><description>&lt;doc fingerprint="1e100b58aaa53690"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;The open source AI code editor&lt;/head&gt;&lt;p&gt;Web, Insiders edition, or other platforms&lt;/p&gt;&lt;p&gt;By using VS Code, you agree to its license and privacy statement.&lt;/p&gt;&lt;code&gt;import { For, createSignal, createMemo } from "solid-js";
import { useNavigate, useParams } from "@tanstack/solid-router";
import { getEmailsForMailbox } from "~/data/emails";
import { MailListItem } from "~/components/MailListItem";

export function MailList() {
  const params = useParams({ strict: false }) as {
    mailbox?: string;
    id?: string;
  };
  const navigate = useNavigate();
  const [query, setQuery] = createSignal("");
  const mailbox = () =&amp;gt; params.mailbox || "inbox";
  const list = createMemo(() =&amp;gt; {
    const q = query().toLowerCase();
    return getEmailsForMailbox(mailbox()).filter(
      (e) =&amp;gt;
        !q ||
        e.subject.toLowerCase().includes(q) ||
        e.snippet.toLowerCase().includes(q)
    );
  });
  function open(id: string) {
    navigate({
      to: "/mail/$mailbox/$id",
      params: { mailbox: mailbox(), id },
      search: (prev) =&amp;gt; prev,
    });
  }

  return (
    &amp;lt;For each={list()}&amp;gt;
      {(e) =&amp;gt; (
        &amp;lt;div
          role="listitem"
          tabindex={0}
          onClick={() =&amp;gt; open(e.id)}
          onKeyDown={(ev) =&amp;gt; ev.key === "Enter" &amp;amp;&amp;amp; open(e.id)}
          class="mail-item"
          data-selected={params.id === e.id ? "true" : undefined}
          aria-selected={params.id === e.id ? "true" : undefined}
        &amp;gt;
          &amp;lt;div&amp;gt;
            &amp;lt;div class="mail-item-subject truncate"&amp;gt;{e.subject}&amp;lt;/div&amp;gt;
            &amp;lt;div class="mail-item-snippet truncate"&amp;gt;{e.snippet}&amp;lt;/div&amp;gt;
          &amp;lt;/div&amp;gt;
          &amp;lt;time
            class="text-xs muted"
            datetime={e.date}
            title={new Date(e.date).toLocaleString()}
          &amp;gt;
            {new Date(e.date).toLocaleDateString(undefined, {
              month: "short",
              day: "numeric",
            })}
          &amp;lt;/time&amp;gt;
        &amp;lt;/div&amp;gt;
        &amp;lt;MailListItem
          email={e}
          isSelected={params.id === e.id}
          onOpen={open}
        /&amp;gt;
      )}
    &amp;lt;/For&amp;gt;
  );
}
&lt;/code&gt;&lt;code&gt;import type { Email } from "~/types";

interface MailListItemProps {
  email: Email;
  isSelected: boolean;
  onOpen: (id: string) =&amp;gt; void;
}

export function MailListItem(props: MailListItemProps) {
  return (
    &amp;lt;div
      role="listitem"
      tabindex={0}
      onClick={() =&amp;gt; props.onOpen(props.email.id)}
      onKeyDown={(ev) =&amp;gt; ev.key === "Enter" &amp;amp;&amp;amp; props.onOpen(props.email.id)}
      class="mail-item"
      data-selected={props.isSelected ? "true" : undefined}
      aria-selected={props.isSelected ? "true" : undefined}
    &amp;gt;
      &amp;lt;div&amp;gt;
        &amp;lt;div class="mail-item-subject truncate"&amp;gt;{props.email.subject}&amp;lt;/div&amp;gt;
        &amp;lt;div class="mail-item-snippet truncate"&amp;gt;{props.email.snippet}&amp;lt;/div&amp;gt;
      &amp;lt;/div&amp;gt;
      &amp;lt;time
        class="text-xs muted"
        datetime={props.email.date}
        title={new Date(props.email.date).toLocaleString()}
      &amp;gt;
        {new Date(props.email.date).toLocaleDateString(undefined, {
          month: "short",
          day: "numeric",
        })}
      &amp;lt;/time&amp;gt;
    &amp;lt;/div&amp;gt;
  );
&lt;/code&gt;&lt;list rend="ul"&gt;&lt;item&gt;Create new &lt;chat-response-file&gt;MailListItem&lt;/chat-response-file&gt;component that handles individual mail list item rendering&lt;/item&gt;&lt;item&gt;Extract mail item JSX and logic from &lt;chat-response-file&gt;MailList&lt;/chat-response-file&gt;into the new&lt;chat-response-file&gt;MailListItem&lt;/chat-response-file&gt;component&lt;/item&gt;&lt;item&gt;Update &lt;chat-response-file&gt;MailList&lt;/chat-response-file&gt;to use the new&lt;chat-response-file&gt;MailListItem&lt;/chat-response-file&gt;component&lt;/item&gt;&lt;item&gt;Build the project to verify changes compile correctly&lt;/item&gt;&lt;item&gt;Test the application to ensure functionality remains intact&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;Created a reusable component for rendering individual mail list items&lt;/item&gt;&lt;item&gt;Accepts &lt;chat-response-file&gt;email&lt;/chat-response-file&gt;,&lt;chat-response-file&gt;isSelected&lt;/chat-response-file&gt;, and&lt;chat-response-file&gt;onSelect&lt;/chat-response-file&gt;props&lt;/item&gt;&lt;item&gt;Maintains all accessibility features (ARIA roles, keyboard navigation)&lt;/item&gt;&lt;item&gt;Preserves styling and interaction behavior&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;Simplified by removing inline mail item rendering logic&lt;/item&gt;&lt;item&gt;Now uses the &lt;chat-response-file&gt;MailListItem&lt;/chat-response-file&gt;component with clean prop passing&lt;/item&gt;&lt;item&gt;Reduced component complexity and improved readability&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;‚úÖ Build successful&lt;/item&gt;&lt;item&gt;‚úÖ All functionality working correctly (filtering, selection, navigation)&lt;/item&gt;&lt;item&gt;‚úÖ Keyboard accessibility preserved (Enter key navigation)&lt;/item&gt;&lt;item&gt;‚úÖ Visual selection state working properly&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Any model for any team&lt;/head&gt;&lt;p&gt;Choose from multiple out of the box models, or bring your own key to access models from your preferred model and hosting provider.&lt;/p&gt;&lt;head rend="h2"&gt;An expert on your codebase&lt;/head&gt;&lt;p&gt;Your codebase is indexed locally and remotely to understand what's relevant, enabling fast, context-aware interactions.&lt;/p&gt;&lt;head rend="h2"&gt;AI that works the way your team does&lt;/head&gt;&lt;p&gt;Personalize interactions using custom agents, custom instructions, and reusable prompt files tailored to your workflows and tools.&lt;/p&gt;&lt;code&gt;---
                        description: 'Generate compact responses, focusing on brevity and clarity.'
                        tools: ['search', 'fetch', 'githubRepo', 'usages', 'vscodeAPI', 'problems', 'changes', 'testFailure', 'todos']
                        ---
                        You are a chat mode that provides extremely concise and clear responses. 
                        Your replies should be brief, to the point, and free of unnecessary details. 
                        Focus on delivering the essential information in a straightforward manner.
                        When responding, you must adhere to the following guidelines:
                        - Use short sentences and simple language.
                        - Prioritize clarity over completeness.
                        - Do not provide explanations or justifications unless explicitly asked.
                        - Do not provide any updates as you are working on the task ‚Äì‚Äì only respond when the task is complete.
                        &lt;/code&gt;&lt;head rend="h2"&gt;Agent mode&lt;/head&gt;&lt;p&gt;Tackle complex, multi-step tasks. Agent mode reads your codebase, suggests edits across files, runs terminal commands, and responds to compile or test failures ‚Äî all in a loop until the job is done. Further refine agent mode to fit your team's workflows with VS Code extensions and Model Context Protocol (MCP) servers.&lt;/p&gt;Build with agent mode&lt;code&gt;package http

import (
    "io"
    "log/slog"
    "mime/multipart"
    "net/http"
    "strings"
)

type BatchItemResult struct {
    Name string `json:"name"`
    Metadata *struct {
        Format string `json:"format"`
        Width  int    `json:"width"`
        Height int    `json:"height"`
        Bytes  int    `json:"bytes"`
    } `json:"metadata,omitempty"`
    Error string `json:"error,omitempty"`
}

type BatchResponse struct {
    Results []*BatchItemResult `json:"results"`
    Count   int                `json:"count"`
    Success int                `json:"success"`
    Failed  int                `json:"failed"`
}

// handleProcessBatch processes multiple uploaded images (multipart/form-data) under the field name "files".
// It returns metadata for each image or an error per item without failing the whole batch unless the request is malformed.
func (s *Server) handleProcessBatch(w http.ResponseWriter, r *http.Request) {
    // Enforce max body size overall.
    r.Body = http.MaxBytesReader(w, r.Body, s.cfg.MaxUploadBytes)
    if ct := r.Header.Get("Content-Type"); !strings.HasPrefix(ct, "multipart/form-data") {
        s.writeJSON(w, http.StatusBadRequest, map[string]string{"error": "content type must be multipart/form-data"})
        return
    }
    if err := r.ParseMultipartForm(s.cfg.MaxUploadBytes); err != nil {
        status := http.StatusBadRequest
        if strings.Contains(err.Error(), "request body too large") {
            status = http.StatusRequestEntityTooLarge
        }
        s.writeJSON(w, status, map[string]string{"error": "invalid multipart form: " + err.Error()})
        return
    }

    // Accept files under the key "files". If absent, attempt to fallback to any file parts.
    var fileHeaders []*multipart.FileHeader
    if r.MultipartForm != nil &amp;amp;&amp;amp; len(r.MultipartForm.File["files"]) &amp;gt; 0 {
        fileHeaders = r.MultipartForm.File["files"]
    } else if r.MultipartForm != nil {
        // Fallback: gather all files across keys.
        for _, fhs := range r.MultipartForm.File {
            fileHeaders = append(fileHeaders, fhs...)
        }
    }

    if len(fileHeaders) == 0 {
        s.writeJSON(w, http.StatusBadRequest, map[string]string{"error": "no files provided (expect key 'files')"})
        return
    }

    resp := &amp;amp;BatchResponse{Results: make([]*BatchItemResult, 0, len(fileHeaders))}

    for _, fh := range fileHeaders {
        item := &amp;amp;BatchItemResult{Name: fh.Filename}
        f, err := fh.Open()
        if err != nil {
            item.Error = "open file: " + err.Error()
            resp.Results = append(resp.Results, item)
            resp.Failed++
            continue
        }
        data, err := io.ReadAll(f)
        _ = f.Close()
        if err != nil {
            item.Error = "read file: " + err.Error()
            resp.Results = append(resp.Results, item)
            resp.Failed++
            continue
        }
        meta, err := s.proc.ExtractMetadata(data)
        if err != nil {
            item.Error = err.Error()
            resp.Results = append(resp.Results, item)
            resp.Failed++
            continue
        }
        // Copy into anonymous struct to decouple from internal type if it changes.
        item.Metadata = &amp;amp;struct {
            Format string `json:"format"`
            Width  int    `json:"width"`
            Height int    `json:"height"`
            Bytes  int    `json:"bytes"`
        }{Format: meta.Format, Width: meta.Width, Height: meta.Height, Bytes: meta.Bytes}
        resp.Results = append(resp.Results, item)
        resp.Success++
    }

    resp.Count = len(resp.Results)
    s.log.LogAttrs(r.Context(), slog.LevelInfo, "batch processed", slog.Int("count", resp.Count), slog.Int("success", resp.Success), slog.Int("failed", resp.Failed))
    s.writeJSON(w, http.StatusOK, resp)
}
&lt;/code&gt;
				&lt;head data-status="success"&gt;Creating a todo list&lt;/head&gt;I'm starting with the todo list creation, managing tasks like reading the existing server and processor code, designing the batch endpoint contract, and implementing a new file with a handler. I want to wire the handler into server routes and maybe add a minimal test for the batch endpoint, though that's optional. I'll also plan to run tests and build everything afterward. Let's get this executed!&lt;head data-status="success"&gt;Improving file processing...&lt;/head&gt;I could modify server.go, but they've asked for a new file. So, I need to create a route, let's call it /process/batch. I'll enforce a max body size and ensure the content type is multipart/form-data. Next, I'm going to parse the form and iterate over form.File["files"]. For each FileHeader, I'll open it and read the bytes, then call ExtractMetadata to collect results. Finally, I'll return a structured JSON response with results and handle edge cases for no files and max batch limits. I think it might not be absolutely necessary, but I'm considering a small improvement by using sync.WaitGroup to process each file sequentially while limiting concurrency. This would make the initial commit simpler. I need to add the code file and import the internal/image referencing alias. Next, I'll check out the existing tests in tests/image_processor_test.go to see the style and determine if I should create a new test file for the batch handler. I'll read through that and then update the todo statuses, marking tasks one and two as completed.&lt;head data-status="success"&gt;Preparing for HTTP test&lt;/head&gt;I need to run an HTTP test, but I notice that the current test package is in 'tests' and not within the main modules. To conduct the HTTP test, I'll have to set up a few things like the config, processor, logger, and server, plus send a multipart request. My next step is to check the config in config.go to understand what required fields I need to include. Let's dive into that!&lt;head data-status="success"&gt;Managing updates and patches&lt;/head&gt;I need to use the manage_todo_list to keep everything organized, ensuring I don't lose track of any tasks. Once that's done, I can proceed with applying the patch. It will involve adding a new file and making edits to server.go. I want to make sure everything is clear and accurate during this process to avoid any mistakes along the way. Let's keep moving forward!&lt;head data-status="success"&gt;Implementing updates and tests&lt;/head&gt;I'm marking the design contract as complete, and then I need to implement the updates. I'll proceed with managing the todo list and apply the patch to add a file and update server.go. It seems I might need to add a route for /process/batch in server.go and implement a new file internal/http/batch.go. After writing the code, I'll add a test file, run the tests with go test, and use run_in_terminal commands. Let's get to it!&lt;list rend="ul"&gt;&lt;item&gt;&lt;chat-response-file&gt;server.go&lt;/chat-response-file&gt;: Registered new route POST /process/batch.&lt;/item&gt;&lt;item&gt;&lt;chat-response-file&gt;batch.go&lt;/chat-response-file&gt;: New handler handleProcessBatch that:&lt;/item&gt;&lt;item&gt;&lt;list rend="ul"&gt;&lt;item&gt;Accepts multipart/form-data.&lt;/item&gt;&lt;item&gt;Reads multiple files under the files key (falls back to any file parts if files missing).&lt;/item&gt;&lt;item&gt;Returns per-file success/error without failing the whole batch.&lt;/item&gt;&lt;item&gt;Aggregates counts: count, success, failed.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;&lt;chat-response-file&gt;batch_endpoint_test.go&lt;/chat-response-file&gt;: Tests happy path (1 valid + 1 invalid file) and missing files error case.&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;Add a configurable max files per batch (e.g., via config).&lt;/item&gt;&lt;item&gt;Stream processing with limited memory (process + discard) for very large images.&lt;/item&gt;&lt;item&gt;Optional parallelism with a worker pool and context cancellation.&lt;/item&gt;&lt;item&gt;Add size validation per file before decoding.&lt;/item&gt;&lt;item&gt;Support JSON-based batch (URLs or base64) for non-multipart clients.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Next edit suggestions&lt;/head&gt;&lt;p&gt;VS Code predicts your next move as you code. Use the Tab key to accept AI-powered suggestions right in your editor. It intelligently recommends what to change ‚Äî and where ‚Äî based on the edits you're already making.&lt;/p&gt;Code with AI-powered suggestions&lt;code&gt;import numpy as np
import pandas as pd

iris_data = pd.read_csv("iris_dataset.csv")

def describe(species: str) -&amp;gt; pd.Series:

        7
        
      subset = data[data["species"] == species]¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†
subset = iris_data[iris_data["species"] == species]
if subset.empty:
raise ValueError(f"{species} missing from sample")
return subset[["petal", "sepal"]].agg(["mean", "std"]).loc["mean"]

def summary():

        13
        
      for species in np.sort(data["species"].unique()):¬†¬†¬†¬†¬†
for species in np.sort(iris_data["species"].unique()):
try:
stats = describe(species)
except ValueError:
print(f"{species}: no records")
continue
print(f"{species}: petal={stats['petal']:.2f} sepal={stats['sepal']:.2f}")

if __name__ == "__main__":
summary()
&lt;/code&gt;
				&lt;head rend="h2"&gt;Code with extensions&lt;/head&gt;&lt;p&gt;Customize VS Code with AI-powered functionality from extensions and Model Context Protocol servers to use in Chat. Or, build your own extension to power your team's unique scenarios.&lt;/p&gt;&lt;head rend="h2"&gt;Code in any language&lt;/head&gt;&lt;p&gt;VS Code supports almost every major programming language. Several ship in the box, like JavaScript, TypeScript, CSS, and HTML, but extensions for others can be found in the VS Code Marketplace.&lt;/p&gt;&lt;code&gt;JavaScript&lt;/code&gt;&lt;code&gt;TypeScript&lt;/code&gt;&lt;code&gt;Python&lt;/code&gt;&lt;code&gt;C#&lt;/code&gt;&lt;code&gt;C++&lt;/code&gt;&lt;code&gt;HTML&lt;/code&gt;&lt;code&gt;Java&lt;/code&gt;&lt;code&gt;JSON&lt;/code&gt;&lt;code&gt;PHP&lt;/code&gt;&lt;code&gt;Markdown&lt;/code&gt;&lt;code&gt;Powershell&lt;/code&gt;&lt;code&gt;YAML&lt;/code&gt;&lt;head rend="h2"&gt;Fully customizable&lt;/head&gt;&lt;p&gt;Customize your VS Code UI and layout so that it fits your coding style.&lt;/p&gt;&lt;p&gt;Color themes let you modify the colors in VS Code's user interface to suit your preferences and work environment.&lt;/p&gt;&lt;p&gt;Settings Sync enables you to share your user settings across your VS Code instances with the Settings Sync feature.&lt;/p&gt;&lt;p&gt;Profiles let you create sets of customizations and quickly switch between them or share them with others.&lt;/p&gt;&lt;head rend="h2"&gt;Code anywhere&lt;/head&gt;&lt;p&gt;Code wherever you're most productive, whether you're connected to the cloud, a remote repository, or in the browser with VS Code for the Web (vscode.dev).&lt;/p&gt;&lt;p&gt;Built-in Source Control empowers you with Git support out-of-the-box. Many other source control providers are available through extensions.&lt;/p&gt;&lt;p&gt;GitHub Codespaces provides cloud-powered development environments for any activity - whether it's a long-term project, or a short-term task like reviewing a pull request.&lt;/p&gt;&lt;head rend="h2"&gt;Code with rich features&lt;/head&gt;&lt;p&gt;There's a lot more to an editor. Whether it's using built-in features or rich extensions, there's something for everyone.&lt;/p&gt;&lt;head rend="h3"&gt;Integrated terminal&lt;/head&gt;&lt;p&gt;Use your favorite shell whether it's zsh, pwsh, or git bash, all inside the editor.&lt;/p&gt;&lt;head rend="h3"&gt;Run code&lt;/head&gt;&lt;p&gt;Run and debug your code without leaving your editor.&lt;/p&gt;&lt;head rend="h3"&gt;Version control&lt;/head&gt;&lt;p&gt;Built-in support for git and many other source control providers.&lt;/p&gt;&lt;head rend="h3"&gt;Build tasks&lt;/head&gt;&lt;p&gt;Run tools and analyze their results from within VS Code.&lt;/p&gt;&lt;head rend="h3"&gt;Local history&lt;/head&gt;&lt;p&gt;Never lose your changes with automatically tracked local history.&lt;/p&gt;&lt;head rend="h3"&gt;Themes&lt;/head&gt;&lt;p&gt;Your theme is an extension of your personality. Add some flair to your editor and add your touch.&lt;/p&gt;&lt;head rend="h3"&gt;Accessibility&lt;/head&gt;&lt;p&gt;Optimized experience for screen readers, high contrast themes, and keyboard-only navigation.&lt;/p&gt;&lt;head rend="h3"&gt;Web support&lt;/head&gt;&lt;p&gt;Whether you are on your phone, tablet, or desktop, you can access your code from anywhere.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46403073</guid><pubDate>Sat, 27 Dec 2025 16:51:01 +0000</pubDate></item><item><title>Gpg.fail</title><link>https://gpg.fail</link><description>&lt;doc fingerprint="536587a44e4054d8"&gt;
  &lt;main&gt;
    &lt;p&gt;brb, were on it!!!!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46403200</guid><pubDate>Sat, 27 Dec 2025 17:05:50 +0000</pubDate></item><item><title>Janet Jackson had the power to crash laptop computers (2022)</title><link>https://devblogs.microsoft.com/oldnewthing/20220816-00/?p=106994</link><description>&lt;doc fingerprint="5455cd69a968ea9f"&gt;
  &lt;main&gt;
    &lt;p&gt;A colleague of mine shared a story from Windows XP product support. A major computer manufacturer discovered that playing the music video for Janet Jackson‚Äôs ‚ÄúRhythm Nation‚Äù would crash certain models of laptops. I would not have wanted to be in the laboratory that they must have set up to investigate this problem. Not an artistic judgement.&lt;/p&gt;
    &lt;p&gt;One discovery during the investigation is that playing the music video also crashed some of their competitors‚Äô laptops.&lt;/p&gt;
    &lt;p&gt;And then they discovered something extremely weird: Playing the music video on one laptop caused a laptop sitting nearby to crash, even though that other laptop wasn‚Äôt playing the video!&lt;/p&gt;
    &lt;p&gt;What‚Äôs going on?&lt;/p&gt;
    &lt;p&gt;It turns out that the song contained one of the natural resonant frequencies for the model of 5400 rpm laptop hard drives that they and other manufacturers used.&lt;/p&gt;
    &lt;p&gt;The manufacturer worked around the problem by adding a custom filter in the audio pipeline that detected and removed the offending frequencies during audio playback.&lt;/p&gt;
    &lt;p&gt;And I‚Äôm sure they put a digital version of a ‚ÄúDo not remove‚Äù sticker on that audio filter. (Though I‚Äôm worried that in the many years since the workaround was added, nobody remembers why it‚Äôs there. Hopefully, their laptops are not still carrying this audio filter to protect against damage to a model of hard drive they are no longer using.)&lt;/p&gt;
    &lt;p&gt;And of course, no story about natural resonant frequencies can pass without a reference to the collapse of the Tacoma Narrows Bridge in 1940.¬π&lt;/p&gt;
    &lt;p&gt;Related: Shouting in the Datacenter.&lt;/p&gt;
    &lt;p&gt;Bonus chatter: Video version of this story and a Twitter poll.&lt;/p&gt;
    &lt;p&gt;Also, Larry Osterman had a similar experience with a specific game that crashed a prototype PC.&lt;/p&gt;
    &lt;p&gt;Follow-up: Janet Jackson had the power to crash laptop computers, follow-up.&lt;/p&gt;
    &lt;p&gt;¬π Follow-up 2: Yes, I know that the Tacoma Narrows Bridge collapse was not the result of resonance, but I felt I had to drop the reference to forestall the ‚ÄúYou forgot to mention the Tacoma Narrows Bridge!‚Äù comments.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46403291</guid><pubDate>Sat, 27 Dec 2025 17:16:08 +0000</pubDate></item></channel></rss>