<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 22 Nov 2025 21:33:03 +0000</lastBuildDate><item><title>Show HN: Wealthfolio 2.0- Open source investment tracker. Now Mobile and Docker</title><link>https://wealthfolio.app/?v=2.0</link><description>&lt;doc fingerprint="27ab40bb69b94b92"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Grow Wealth. Keep Control.&lt;/head&gt;
    &lt;head rend="h2"&gt;A beautiful, Private and Open-Source investment tracker that runs locally on all your devices.&lt;/head&gt;
    &lt;head rend="h2"&gt;WHY CHOOSE WEALTHFOLIO?&lt;/head&gt;
    &lt;p&gt;A beautiful portfolio tracker that respects your privacy and your data&lt;/p&gt;
    &lt;head rend="h3"&gt;Privacy-First Approach&lt;/head&gt;
    &lt;p&gt;Your data never leaves your device. As an open-source project, we prioritize security and transparency.&lt;/p&gt;
    &lt;head rend="h3"&gt;Simple and Beautifully Crafted&lt;/head&gt;
    &lt;p&gt;Powerful features wrapped in an elegant, easy-to-use interface. Simplicity meets sophistication.&lt;/p&gt;
    &lt;head rend="h3"&gt;No Hidden Costs&lt;/head&gt;
    &lt;p&gt;Free to use with optional one-time payment. No subscriptions or recurring fees.&lt;/p&gt;
    &lt;head rend="h2"&gt;THE ESSENTIALS YOU NEED TO TRACK YOUR WEALTH&lt;/head&gt;
    &lt;p&gt;No More Messy Spreadsheets or Privacy Concerns - Just You and Your Secure, Personal Wealth Companion Application&lt;/p&gt;
    &lt;head rend="h3"&gt;Accounts Aggregation&lt;/head&gt;
    &lt;p&gt;Gather all your investment and savings accounts in one place. See everything at a glance, from stocks to savings! Import your CSV statements from your broker or bank.&lt;/p&gt;
    &lt;head rend="h4"&gt;Comprehensive View&lt;/head&gt;
    &lt;p&gt;See all your accounts in one place.&lt;/p&gt;
    &lt;head rend="h4"&gt;CSV Import&lt;/head&gt;
    &lt;p&gt;Easily import your CSV statements.&lt;/p&gt;
    &lt;head rend="h3"&gt;Holdings Overview&lt;/head&gt;
    &lt;p&gt;Get a clear picture of what's in your portfolio. Stocks, ETFs, or Cryptocurrencies - know what you have and how it's performing.&lt;/p&gt;
    &lt;head rend="h4"&gt;Portfolio Insights&lt;/head&gt;
    &lt;p&gt;Understand your asset allocation.&lt;/p&gt;
    &lt;head rend="h4"&gt;Performance Tracking&lt;/head&gt;
    &lt;p&gt;Monitor how your investments are doing.&lt;/p&gt;
    &lt;head rend="h3"&gt;Performance Dashboard&lt;/head&gt;
    &lt;p&gt;See how your investments stack up, all in one place. Compare your accounts side by side, check if you are beating the S&amp;amp;P 500, and track your favorite ETFs without the hassle. No fancy jargon - just clear, useful charts that help you understand how your money is really doing.&lt;/p&gt;
    &lt;head rend="h4"&gt;Compare Your Accounts&lt;/head&gt;
    &lt;p&gt;See which accounts are doing best.&lt;/p&gt;
    &lt;head rend="h4"&gt;Beat the Market?&lt;/head&gt;
    &lt;p&gt;Check how you stack up against some popular indexes and ETFs.&lt;/p&gt;
    &lt;head rend="h3"&gt;Income Tracking&lt;/head&gt;
    &lt;p&gt;Monitor dividends and interest income across your entire portfolio. Get a clear view of your passive income streams, helping you make informed decisions about your investments.&lt;/p&gt;
    &lt;head rend="h4"&gt;Dividend Monitoring&lt;/head&gt;
    &lt;p&gt;Track your dividend income.&lt;/p&gt;
    &lt;head rend="h4"&gt;Interest Income&lt;/head&gt;
    &lt;p&gt;Keep an eye on interest earnings.&lt;/p&gt;
    &lt;head rend="h3"&gt;Accounts Performance&lt;/head&gt;
    &lt;p&gt;Track your accounts' holdings and performance over time. See how a particular account is performing, and how it's changing over time.&lt;/p&gt;
    &lt;head rend="h4"&gt;Historical Data&lt;/head&gt;
    &lt;p&gt;View past performance trends.&lt;/p&gt;
    &lt;head rend="h4"&gt;Account Analysis&lt;/head&gt;
    &lt;p&gt;Analyze individual account performance.&lt;/p&gt;
    &lt;head rend="h3"&gt;Goals Tracking&lt;/head&gt;
    &lt;p&gt;Set your savings targets clearly. Distribute your funds across these objectives, assigning a specific percentage to each. Keep an eye on your progress.&lt;/p&gt;
    &lt;head rend="h4"&gt;Target Setting&lt;/head&gt;
    &lt;p&gt;Define your financial goals.&lt;/p&gt;
    &lt;head rend="h4"&gt;Progress Monitoring&lt;/head&gt;
    &lt;p&gt;Track your progress towards goals.&lt;/p&gt;
    &lt;head rend="h3"&gt;Contribution Rooms and Limit Tracking&lt;/head&gt;
    &lt;p&gt;Stay on top of your contribution limits for tax-advantaged accounts like IRAs, 401(k)s, or TFSAs. Track your available contribution room and avoid over-contributing.&lt;/p&gt;
    &lt;head rend="h4"&gt;Limit Awareness&lt;/head&gt;
    &lt;p&gt;Know your contribution limits.&lt;/p&gt;
    &lt;head rend="h4"&gt;Avoid Over-Contribution&lt;/head&gt;
    &lt;p&gt;Prevent excess contributions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Extend Wealthfolio with Powerful Add-ons&lt;/head&gt;
    &lt;head rend="h3"&gt;Investment Fees Tracker&lt;/head&gt;
    &lt;p&gt;Track and analyze investment fees across your portfolio with detailed analytics and insights&lt;/p&gt;
    &lt;head rend="h3"&gt;Goal Progress Tracker&lt;/head&gt;
    &lt;p&gt;Track your investment progress towards target amounts with a visual representation&lt;/p&gt;
    &lt;head rend="h3"&gt;Stock Trading Tracker&lt;/head&gt;
    &lt;p&gt;Simple swing stock trading tracker with performance analytics and calendar views&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46006016</guid><pubDate>Fri, 21 Nov 2025 16:34:52 +0000</pubDate></item><item><title>Helping Valve to power up Steam devices</title><link>https://www.igalia.com/2025/11/helpingvalve.html</link><description>&lt;doc fingerprint="961b0d5348912672"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Helping Valve to Power Up Steam Devices&lt;/head&gt;
    &lt;p&gt;Last week, Valve stunned the computer gaming world by unveiling three new gaming devices at once: the Steam Frame, a wireless VR headset; the Steam Machine, a gaming console in the vein of a PlayStation or Xbox; and the Steam Controller, a handheld game controller. Successors to the highly successful Valve Index and Steam Deck, these devices are set to be released in the coming year.&lt;/p&gt;
    &lt;p&gt;Igalia has long worked with Valve on SteamOS, which will power the Machine and Frame, and is excited to be contributing to these new devices, particularly the Frame. The Frame, unlike the Machine or Deck which have x86 CPUs, runs on an ARM-based CPU.&lt;/p&gt;
    &lt;p&gt;Under normal circumstances, this would mean that only games compiled to run on ARM chips could be played on the Frame. In order to get around this barrier, a translation layer called FEX is used to run applications compiled for x86 chips (which are used in nearly all gaming PCs) on ARM chips by translating the x86 machine code into ARM64 machine code.&lt;/p&gt;
    &lt;p&gt;âIf you love video games, like I do, working on FEX with Valve is a dream come true,â said Paulo Matos, an engineer with Igaliaâs Compilers Team. Even so, the challenges can be daunting, because making sure the translation is working often requires manual QA rather than automated testing. âYou have to start a game, sometimes the error shows up in the colors or sound, or how the game behaves when you break down the door in the second level. Just debugging this can take a while,â said Matos. âFor optimization work I did early last year, I used a game called Psychonauts to test it. I must have played the first 3 to 4 minutes of the game many, many times for debugging. Looking at my history, Steam tells me I played it for 29 hours, but it was always the first few minutes, nothing else.â&lt;/p&gt;
    &lt;p&gt;Beyond the CPU, the Qualcomm Adreno 750 GPU used in the Steam Frame introduced its own set of challenges when it came to running desktop games, and other complex workloads, on these devices. Doing so requires a rock-solid Vulkan driver that can ensure correctness, eliminating major rendering bugs, while maintaining high performance. This is a very difficult combination to achieve, and yet thatâs exactly what weâve done for Valve with Mesa3D Turnip, a FOSS Vulkan driver for Qualcomm Adreno GPUs.&lt;/p&gt;
    &lt;p&gt;Before we started our work, critical optimizations such as LRZ (which you can learn more about from our blog post here) or the autotuner (and its subsequent overhaul) werenât in place. Even worse, there wasnât support for the Adreno 700-series GPUs at all, which we eventually added along with support for tiled rendering.&lt;/p&gt;
    &lt;p&gt;âWe implemented many Vulkan extensions and reviewed numerous others,â said Danylo Piliaiev, an engineer on the Graphics Team. âOver the years, we ensured that D3D11, D3D12, and OpenGL games rendered correctly through DXVK, vkd3d-proton, and Zink, investigating many rendering issues along the way. We achieved higher correctness than the proprietary driver and, in many cases, Mesa3D Turnip is faster as well.â&lt;/p&gt;
    &lt;p&gt;Weâve worked with many wonderful people from Valve, Google, and other companies to iterate on the Vulkan driver over the years in order to introduce new features, bug fixes, performance improvements, as well as debugging workflows. Some of those people decided to join Igalia later on, such as our colleague and Graphics Team developer Emma Anholt. âIâve been working on Mesa for 22 years, and itâs great to have a home now where I can keep doing that work, across hardware projects, where the organization prioritizes the work experience of its developers and empowers them within the organization.â&lt;/p&gt;
    &lt;p&gt;Valveâs support in all this cannot be understated, either. Their choice to build their devices using open software like Mesa3D Turnip and FEX means theyâre committed to working on and supporting improvements and optimizations that become available to anyone who uses the same open-source projects.&lt;/p&gt;
    &lt;p&gt;âWeâve received a lot of positive feedback about significantly improved performance and fewer rendering glitches from hobbyists who use these projects to run PC games on Android phones as a result of our work,â said Dhruv Mark Collins, another Graphics Team engineer working on Turnip. âAnd it goes both ways! Weâve caught a couple of nasty bugs because of that widespread testing, which really emphasizes why the FOSS model is beneficial for everyone involved.â&lt;/p&gt;
    &lt;p&gt;An interesting area of graphics driver development is all the compiler work that is involved. Vulkan drivers such as Mesa3D Turnip need to process shader programs sent by the application to the GPU, and these programs govern how pixels in our screens are shaded or colored with geometry, textures, and lights while playing games. Job Noorman, an engineer from our Compilers Team, made significant contributions to the compiler used by Mesa3D Turnip. He also contributed to the Mesa3D NIR shader compiler, a common part that all Mesa drivers use, including RADV (most popularly used on the Steam Deck) or V3DV (used on Raspberry Pi boards).&lt;/p&gt;
    &lt;p&gt;As is normal for Igalia, while we focused on delivering results for our customer, we also made our work as widely useful as possible. For example: âWhile our target throughout our work has been the Snapdragon 8 Gen 3 thatâs in the Frame, much of our work extends back through years of Snapdragon hardware, and we regression test it to make sure it stays Vulkan conformant,â said Anholt. This means that Igaliaâs work for the Frame has consistently passed Vulkanâs Conformance Test Suite (CTS) of over 2.8 million tests, some of which Igalia is involved in creating.&lt;/p&gt;
    &lt;p&gt;Our very own Vulkan CTS expert Ricardo GarcÃa says:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Igalia and other Valve contractors actively participate in several areas inside the Khronos Group, the organization maintaining and developing graphics API standards like Vulkan. We contribute specification fixes and feedback, and we are regularly involved in the development of many new Vulkan extensions. Some of these end up being critical for game developers, like mesh shading. Others ensure a smooth and efficient translation of other APIs like DirectX to Vulkan, or help take advantage of hardware features to ensure applications perform great across multiple platforms, both mobile like the Steam Frame or desktop like the Steam Machine. Having Vulkan CTS coverage for these new extensions is a critical step in the release process, helping make sure the specification is clear and drivers implement it correctly, and Igalia engineers have contributed millions of source code lines and tests since our collaboration with Valve started.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;A huge challenge we faced in moving forward with development is ensuring that we didnât introduce regressions, small innocent-seeming changes can completely break rendering on games in a way that even CTS might not catch. What automated testing could be done was often quite constrained, but Igalians found ways to push through the barriers. âI made a continuous integration test to automatically run single-frame captures of a wide range of games spanning D3D11, D3D9, D3D8, Vulkan, and OpenGL APIs,â said Piliaiev, about the development covered in his recent XDC 2025 talk, âensuring that we donât have rendering or performance regressions.â&lt;/p&gt;
    &lt;p&gt;Looking ahead, Igaliaâs work for Valve will continue to deliver benefits to the wider Linux Gaming ecosystem. For example, the Steam Frame, as a battery-powered VR headset, needs to deliver high performance within a limited power budget. A way to address this is to create a more efficient task scheduler, which is something Changwoo Min of Igaliaâs Kernel Team has been working on. As he says, âI have been developing a customized CPU scheduler for gaming, named LAVD: Latency-criticality Aware Virtual Deadline scheduler.â&lt;/p&gt;
    &lt;p&gt;In general terms, a scheduler automatically identifies critical tasks and dynamically boosts their deadlines to improve responsiveness. Most task schedulers donât take energy consumption into account, but the Rust-based LAVD is different. âLAVD makes scheduling decisions considering each chipâs performance versus energy trade-offs. It measures and predicts the required computing power on the fly, then selects the best set of CPUs to meet that demand with minimal energy consumption,â said Min.&lt;/p&gt;
    &lt;p&gt;One of our other kernel engineers, Melissa Wen, has been working on AMD kernel display drivers to maintain good color management and HDR support for SteamOS across AMD hardware families, both for the Steam Deck and the Steam Machine. This is especially important with newer display hardware in the Steam Machine, which features some notable differences in color capabilities, aiming for more powerful and efficient color management which necessitated driver work.&lt;/p&gt;
    &lt;p&gt;â¦and thatâs a wrap! We will continue our efforts toward improving future versions of SteamOS, and with a partner as strongly supportive as Valve, we expect to do more work to make Linux gaming even better. If any of that sounded interesting and youâd like to work with us to tackle tricky problems of your own, please get in touch!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46006616</guid><pubDate>Fri, 21 Nov 2025 17:29:59 +0000</pubDate></item><item><title>Personal blogs are back, should niche blogs be next?</title><link>https://disassociated.com/personal-blogs-back-niche-blogs-next/</link><description>&lt;doc fingerprint="3b8090076bc54e9f"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Personal blogs are back, should niche blogs be next?&lt;/head&gt;
    &lt;p&gt;20 November 2025&lt;/p&gt;
    &lt;p&gt;When it comes to blogging there are few rules. Write content that is somehow meaningful might be one of them though. I think it’s down to the individual to determine what constitutes meaningful.&lt;/p&gt;
    &lt;p&gt;In the hey-day, the so-called golden age of blogging, there were plenty of people prepared to offer definitions of meaningful, and how to write accordingly. It was natural. The web was once awash with all sorts of blogs. Likewise people who wanted to show others how to blog “successfully”.&lt;/p&gt;
    &lt;p&gt;Again, the definition of successful resided with the individual, but it was obvious this involved monetary return for some people. And why not. If you’re going to invest time and energy in creating a resource that is useful to other people, why shouldn’t you earn money, make a living even, from it?&lt;/p&gt;
    &lt;p&gt;One of these people blogging about blogging was Melbourne based Australian writer and author Darren Rowse, who launched his blogging resource Problogger in 2004. Without going into detail, because you can look it up for yourself, Rowse, as one of the earlier bloggers about blogging, did, and still does presumably, rather well for himself.&lt;/p&gt;
    &lt;p&gt;Rowse’s writing, and that of his contributors, attracted numerous readers keen to learn what they could about blogging, and the potential to make money from it.&lt;/p&gt;
    &lt;p&gt;Problogger is what’s called a niche blog. As a blog about blogging, it has a reasonably singular focus. Some people considered this niche principle to be a core tenet of blogging. There was this idea, in the earlier days of blogging, which possibly still persists, that blogs would do better if they had a speciality. Not only were search engines said to be in favour the approach, but the author of a speciality, or niche blog, would generally be considered to be an expert, of some sort, in their field.&lt;/p&gt;
    &lt;p&gt;A master of one trade, rather than the proverbial jack of all trades.&lt;/p&gt;
    &lt;p&gt;Regardless, the world was once full of blogs on every topic imaginable. It was a great time to be alive. If you wanted to learn about something in particular, there was a blog for you. Some publications featured quality content, others required a little fact checking, while some were definitely to be taken with a pinch of salt.&lt;/p&gt;
    &lt;p&gt;But niche blogging was never a format that suited everyone. There are people who did, still do, well, writing about a range, sometimes a wide range, of topics. Kottke is one of the better known blogs that does not have a specific speciality. Here, the publication itself is the speciality. To repeat what I wrote in the first sentence of this article: the rules of blogging are few.&lt;/p&gt;
    &lt;p&gt;But the facets of blogging covered at Problogger, and numerous other similar websites, usually only applied to blogs of a commercial nature. That’s not to say one or two personal bloggers might have looked at the tips posted there for increasing their audience, or improving their writing though. But in my view, personal bloggers were not, are not, part of Problogger’s target audience.&lt;/p&gt;
    &lt;p&gt;It’s been a long time since I last wrote about Problogger, let alone visited the website, maybe fifteen plus years, but a recent mention of it by Kev Quick, via ldstephens, caught my eye. But I don’t believe Rowse is being critical, in any way, of personal bloggers because they do not adhere to a niche or speciality publishing format. That’s not what Problogger, or Rowse, is about.&lt;/p&gt;
    &lt;p&gt;But this started me thinking, and writing another of my long posts.&lt;/p&gt;
    &lt;p&gt;In an age where social media, and influencers, have usurped blogs and their A-List authors, in the jostle for supremacy, it has to be wondered what role websites like Problogger still have. Only a handful of blogs generate liveable incomes today. Despite the doom and gloom though, the form has not completely died off. A backlash against social media, and a growing IndieWeb/SmallWeb community, has precipitated a revival in personal websites.&lt;/p&gt;
    &lt;p&gt;This is a largely non-commercial movement. Of course, there’s nothing wrong with personal websites. Many of us started out with them in the early days of the web. But the web was not only intended for personal journals. It was a vehicle for sharing all manner of information. The web could also empower individuals, and partnerships, to not only set up shop online, be that blogs, or quite literally shops, but potentially make a living at the same time.&lt;/p&gt;
    &lt;p&gt;But with the revival of personal blogs well underway, I think it’s time to bring niche blogs back into the fold. I’m talking about well written, quality, topic focused resources. This is material fast vanishing from the web, leaving ever diminishing options to source useful and accurate information. What are the alternatives? The misinformation morass that is social media? Being served AI generated summaries in response to search engine queries? A web choke full of AI slop?&lt;/p&gt;
    &lt;p&gt;At the same time, I’m not advocating for a return of niche blogs plastered with adverts, and popup boxes urging visitors to subscribe to say a newsletter, before they’ve even had a chance to blink at what they came to read.&lt;/p&gt;
    &lt;p&gt;I’m talking about work produced by independent writers, with an interest in their subject matter, who are not backed by large media organisations, or private equity. This is bringing back reliable sources of information, that also recompenses the content writers in some way. Hopefully we’ve learned a few lessons about monetisation since the earlier wave of niche blogging. We know it is possible to generate revenue without compromising the reader experience.&lt;/p&gt;
    &lt;p&gt;A resurgence in personal blogging is the first step in rebuilding a vibrant, thriving, web, or if you like, blogosphere. Now the focus needs to be on restoring the flow of accessible and trusted information.&lt;/p&gt;
    &lt;p&gt;RELATED CONTENT&lt;/p&gt;
    &lt;p&gt;blogs, history, IndieWeb, self publishing, SmallWeb, technology, trends&lt;/p&gt;
    &lt;head rend="h3"&gt;There's 2 comments on this post&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt; On 22 November 2025 at 11:34 AM, Jorge Arango said:&lt;p&gt;Thanks for sharing. I’d like to believe a resurgence of personal blogs is underway. Is there data that substantiates this claim?&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46009894</guid><pubDate>Fri, 21 Nov 2025 22:40:28 +0000</pubDate></item><item><title>How I learned Vulkan and wrote a small game engine with it (2024)</title><link>https://edw.is/learning-vulkan/</link><description>&lt;doc fingerprint="23684b734fb50739"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How I learned Vulkan and wrote a small game engine with it&lt;/head&gt;
    &lt;p&gt;tl;dr: I learned some Vulkan and made a game engine with two small game demos in 3 months.&lt;/p&gt;
    &lt;p&gt;The code for the engine and the games can be found here: https://github.com/eliasdaler/edbr&lt;/p&gt;
    &lt;head rend="h2"&gt;Table Of Contents&lt;/head&gt;
    &lt;p&gt;This article documents my experience of learning Vulkan and writing a small game/engine with it. It took me around 3 months to do it without any previous knowledge of Vulkan (I had previous OpenGL experience and some experience with making game engines, though).&lt;/p&gt;
    &lt;p&gt;The engine wasn’t implemented as a general purpose engine, which is probably why it took me a few months (and not years) to achieve this. I started by making a small 3D game and separated reusable parts into the “engine” afterwards. I can recommend everyone to follow the same process to not get stuck in the weeds (see “Bike-shedding” section below for more advice).&lt;/p&gt;
    &lt;head rend="h2"&gt;Preface&lt;/head&gt;
    &lt;p&gt;I’m a professional programmer, but I’m self-taught in graphics programming. I started studying graphics programming around 1.5 years ago by learning OpenGL and writing a 3D engine in it.&lt;/p&gt;
    &lt;p&gt;The engine I wrote in Vulkan is mostly suited for smaller level-based games. I’ll explain things which worked for me, but they might not be the most efficient. My implementation would probably still be a good starting point for many people.&lt;/p&gt;
    &lt;quote&gt;Hopefully, this article will help make some things about Vulkan clearer to you. But you also need to be patient. It took me months to implement what I have today and I did it by cutting corners in many places. But if a self-taught programmer like me can build something with Vulkan, then so can you!&lt;/quote&gt;
    &lt;head rend="h2"&gt;Learning graphics programming&lt;/head&gt;
    &lt;quote&gt;This is a very high level overview of how I learned some graphics programming myself. If there’s interest, I might write another article with more resources and helpful guidelines.&lt;/quote&gt;
    &lt;p&gt;If you haven’t done any graphics programming before, you should start with OpenGL. It’s much easier to learn it and not get overwhelmed by all the complexity that Vulkan has. A lot of your OpenGL and graphics programming knowledge will be useful when you start doing things with Vulkan later.&lt;/p&gt;
    &lt;p&gt;Ideally, you should at least get a textured model displayed on the screen with some simple Blinn-Phong lighting. I can also recommend doing some basic shadow mapping too, so that you learn how to render your scene from a different viewpoint and to a different render target, how to sample from depth textures and so on.&lt;/p&gt;
    &lt;p&gt;I can recommend using the following resources to learn OpenGL:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;https://learnopengl.com/&lt;/item&gt;
      &lt;item&gt;Anton’s OpenGL 4 Tutorials book&lt;/item&gt;
      &lt;item&gt;Thorsten ThormÃ¤hlen’s lectures lectures (watch the first 6 videos, the rest might be a bit too advanced)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Sadly, most OpenGL resources don’t teach the latest OpenGL 4.6 practices. They make writing OpenGL a lot more enjoyable. If you learn them, transitioning to Vulkan will be much easier (I only learned about OpenGL 3.3 during my previous engine development, though, so it’s not a necessity).&lt;/p&gt;
    &lt;p&gt;Here are some resources which teach you the latest OpenGL practices:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;https://juandiegomontoya.github.io/modern_opengl.html&lt;/item&gt;
      &lt;item&gt;https://github.com/fendevel/Guide-to-Modern-OpenGL-Functions&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;It’s also good to have some math knowledge, especially linear algebra: how to work with vectors, transformation matrices and quaternions. My favorite book about linear algebra/math is 3D Math Primer for Graphics and Game Development by F. Dunn and I. Parbery. You don’t need to read it all in one go - use it as a reference if some math in the OpenGL resources above doesn’t make sense to you.&lt;/quote&gt;
    &lt;head rend="h2"&gt;Bike-shedding and how to avoid it&lt;/head&gt;
    &lt;p&gt;https://en.wikipedia.org/wiki/Law_of_triviality&lt;/p&gt;
    &lt;p&gt;Ah, bike-shedding… Basically, it’s a harmful pattern of overthinking and over-engineering even the simplest things. It’s easy to fall into this trap when doing graphics programming (especially when doing Vulkan since you need to make many choices when implementing an engine with it).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Always ask yourself “Do I really need this?”, “Will this thing ever become a bottleneck?”.&lt;/item&gt;
      &lt;item&gt;Remember that you can always rewrite any part of your game/engine later.&lt;/item&gt;
      &lt;item&gt;Don’t implement something unless you need it right now. Don’t think “Well, a good engine needs X, right…?”.&lt;/item&gt;
      &lt;item&gt;Don’t try to make a general purpose game engine. It’s probably even better to not think about “the engine” at first and write a simple game.&lt;/item&gt;
      &lt;item&gt;Make a small game first - a Breakout clone, for example. Starting your engine development by doing a Minecraft clone with multiplayer support is probably not a good idea.&lt;/item&gt;
      &lt;item&gt;Be wary of people who tend to suggest complicated solutions to simple problems.&lt;/item&gt;
      &lt;item&gt;Don’t look too much at what other people do. I’ve seen many over-engineered engines on GitHub - sometimes they’re that complex for a good reason (and there are years of work behind them). But you probably don’t need most of that complexity, especially for simpler games.&lt;/item&gt;
      &lt;item&gt;Don’t try to make magical wrappers around Vulkan interfaces prematurely, especially while you’re still learning Vulkan.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Get it working first. Leave “TODO”/“FIXME” comments in some places. Then move on to the next thing. Try to fix “TODO”/“FIXME” places only when they really become problematic or bottleneck your performance. You’ll be surprised to see how many things won’t become a problem at all.&lt;/p&gt;
    &lt;quote&gt;Some of this advice only applies when you’re working alone on a hobby project. Of course, it’s much harder to rewrite something from scratch when others start to depend on it and a “temp hack” becomes a fundamental part of the engine which is very hard to change without breaking many things.&lt;/quote&gt;
    &lt;head rend="h2"&gt;Why Vulkan?&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Ask yourself if you need to learn a graphics API at all. If your main goal is to make a game as soon as possible, then you might be better off using something like Godot or Unreal Engine.&lt;/p&gt;
      &lt;p&gt;However, there’s nothing wrong with reinventing the wheel or doing something from scratch. Especially if you do it just for fun, to get into graphics programming or to get an in-depth knowledge about how something works.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The situation with graphic APIs in 2024 is somewhat complicated. It all depends on the use case: DirectX seems like the most solid choice for most AAA games. WebGL or WebGPU are the only two choices for doing 3D graphics on the web. Metal is the go-to graphics API on macOS and iOS (though you can still do Vulkan there via MoltenVK).&lt;/p&gt;
    &lt;p&gt;My use case is simple: I want to make small 3D games for desktop platforms (Windows and Linux mostly). I also love open source technology and open standards. So, it was a choice between OpenGL and Vulkan for me.&lt;/p&gt;
    &lt;p&gt;OpenGL is a good enough choice for many small games. But it’s very unlikely that it’ll get new versions in the future (so you can’t use some newest GPU capabilities like ray tracing), it’s deprecated on macOS and its future is uncertain.&lt;/p&gt;
    &lt;p&gt;WebGPU was also a possible choice. Before learning Vulkan, I learned some of it. It’s a pretty solid API, but I had some problems with it:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It’s still not stable and there’s not a lot of tutorials and examples for it. This tutorial is fantastic, though.&lt;/item&gt;
      &lt;item&gt;WGSL is an okay shading language, but I just find its syntax not as pleasant as GLSL’s (note that you can write in GLSL and then load compiled SPIR-V on WebGPU native).&lt;/item&gt;
      &lt;item&gt;On desktop, it’s essentially a wrapper around other graphic APIs (DirectX, Vulkan, Metal).This introduces additional problems for me: &lt;list rend="ul"&gt;&lt;item&gt;It can’t do things some things that Vulkan or DirectX can do.&lt;/item&gt;&lt;item&gt;It has more limitations than native graphic APIs since it needs to behave similarly between them.&lt;/item&gt;&lt;item&gt;RenderDoc captures become confusing as they differ between the platforms (you can get DirectX capture on Windows and Vulkan capture on Linux) and you don’t have 1-to-1 mapping between WebGPU calls and native API calls.&lt;/item&gt;&lt;item&gt;Using Dawn and WGPU feels like using bgfx or sokol. You don’t get the same degree of control over the GPU and some of the choices/abstractions might not be the most pleasant for you.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;No bindless textures (WIP discussion here).&lt;/item&gt;
      &lt;item&gt;No push constants (WIP discussion here).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Still, I think that WebGPU is a better API than OpenGL/WebGL and can be more useful to you than Vulkan in some use cases:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Validation errors are much better than in OpenGL/WebGL and not having global state helps a lot.&lt;/item&gt;
      &lt;item&gt;It’s also kind of similar to Vulkan in many things, so learning a bit of it before diving into Vulkan also helped me a lot.&lt;/item&gt;
      &lt;item&gt;It requires a lot less boilerplate to get things on the screen (compared to Vulkan).&lt;/item&gt;
      &lt;item&gt;You don’t have to deal with explicit synchronization which makes things much simpler.&lt;/item&gt;
      &lt;item&gt;You can make your games playable inside the browser.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Learning Vulkan&lt;/head&gt;
    &lt;p&gt;Learning Vulkan seemed like an impossible thing for me previously. It felt like you needed to have many years of AAA game graphics programming experience to be able to do things in it. You also hear people saying “you’re basically writing a graphics driver when writing in Vulkan” which also made Vulkan sounds like an incredibly complicated thing.&lt;/p&gt;
    &lt;p&gt;I have also checked out some engines written in Vulkan before and was further demotivated by seeing tons of scary abstractions and files named like &lt;code&gt;GPUDevice.cpp&lt;/code&gt; or &lt;code&gt;GPUAbstraction.cpp&lt;/code&gt; which had thousands of lines of scary C++ code.&lt;/p&gt;
    &lt;p&gt;The situation has changed over the years. Vulkan is not as complicated as it was before. First of all, Khronos realized that some parts of Vulkan were indeed very complex and introduced some newer features which made many things much simpler (for example, dynamic rendering). Secondly, some very useful libraries which reduce boilerplate were implemented. And finally, there are a lot of fantastic resources which make learning Vulkan much easier than it was before.&lt;/p&gt;
    &lt;p&gt;The best Vulkan learning resource which helped me get started was vkguide. If you’re starting from scratch, just go through it all (you might stop at “GPU driver rendering” chapter at first - many simple games probably won’t need this level of complexity)&lt;/p&gt;
    &lt;p&gt;Vulkan Lecture Series by TU Wien also nicely teaches Vulkan basics (you can probably skip “Real-Time Ray Tracing” chapter for now). I especially found a lecture on synchronization very helpful.&lt;/p&gt;
    &lt;p&gt;Here are some more advanced Vulkan books that also helped me:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;3D Graphics Rendering Cookbook by Sergey Kosarevsky and Viktor Latypov. There is the second edition in the writing and it’s promising to be better than the first one. The second edition is not released yet, but the source code for it can be found here: https://github.com/PacktPublishing/3D-Graphics-Rendering-Cookbook-Second-Edition&lt;/item&gt;
      &lt;item&gt;Mastering Graphics Programming with Vulkan by Marco Castorina, Gabriel Sassone. Very advanced book which explains some of the “cutting edge” graphics programming concepts (I mostly read it to understand where to go further, but didn’t have time to implement most of it). The source code for it can be found here: https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here’s the result of my first month of learning Vulkan:&lt;/p&gt;
    &lt;p&gt;By this point I had:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;glTF model loading&lt;/item&gt;
      &lt;item&gt;Compute skinning&lt;/item&gt;
      &lt;item&gt;Frustum culling&lt;/item&gt;
      &lt;item&gt;Shadow mapping and cascaded shadow maps&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Of course, doing it for the 3rd time (I had it implemented it all in OpenGL and WebGPU before) certainly helped. Once you get to this point, Vulkan won’t seem as scary anymore.&lt;/p&gt;
    &lt;p&gt;Let’s see how the engine works and some useful things I learned.&lt;/p&gt;
    &lt;head rend="h2"&gt;Engine overview and frame analysis&lt;/head&gt;
    &lt;p&gt;https://github.com/eliasdaler/edbr&lt;/p&gt;
    &lt;p&gt;My engine is called EDBR (Elias Daler’s Bikeshed Engine) and was initially started as a project for learning Vulkan. It quickly grew into a somewhat usable engine which I’m going to use for my further projects.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;At the time of writing this article, the source code line counts are as follows:&lt;/p&gt;
      &lt;item&gt;Engine itself: 19k lines of code&lt;/item&gt;
      &lt;item&gt;6.7k LoC related to graphics,&lt;/item&gt;
      &lt;item&gt;2k LoC are light abstractions around Vulkan&lt;/item&gt;
      &lt;item&gt;3D cat game: 4.6k LoC&lt;/item&gt;
      &lt;item&gt;2D platformer game: 1.2k LoC&lt;/item&gt;
    &lt;/quote&gt;
    &lt;p&gt;I copy-pasted some non-graphics related stuff from my previous engine (e.g. input handling and audio system) but all of the graphics and many other core systems were rewritten from scratch. I feel like it was a good way to do it instead of trying to cram Vulkan into my old OpenGL abstractions.&lt;/p&gt;
    &lt;quote&gt;You can follow the commit history which shows how I started from clearing the screen, drawing the first triangle, drawing a textured quad and so on. It might be easier to understand the engine when it was simpler and smaller.&lt;/quote&gt;
    &lt;p&gt;Let’s see how this frame in rendered:&lt;/p&gt;
    &lt;quote&gt;Most of the steps will be explained in more detail below.&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Skinning&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;First, models with skeletal animations are skinned in the compute shader. The compute shader takes unskinned mesh and produces a buffer of vertices which are then used instead of the original mesh in later rendering steps. This allows me to treat static and skinned meshes similarly in shaders and not do skinning repeatedly in different rendering steps.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CSM (Cascaded Shadow Mapping)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I use a 4096x4096 depth texture with 3 slices for cascaded shadow mapping. The first slice looks like this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Geometry + shading&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All the models are drawn and shading is calculated using the shadow map and light info. I use a PBR model which is almost identical to the one described in Physically Based Rendering in Filament. The fragment shader is quite big and does calculation for all the lights affecting the drawn mesh in one draw call:&lt;/p&gt;
    &lt;p&gt;Everything is drawn into a multi-sampled texture. Here’s how it looks after resolve:&lt;/p&gt;
    &lt;p&gt;(Open the previous two screenshots in the next tab and flip between the tabs to see the difference more clearly)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Depth resolve&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Depth resolve step is performed manually via a fragment shader. I just go through all the fragments of multi-sample depth texture and write the minimum value into the non-MS depth texture (it’ll be useful in the next step).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Post FX&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Some post FX is applied - right now it’s only depth fog (I use “depth resolve” texture from the previous step here), afterwards tone-mapping and bloom will also be done here.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;UI&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Dialogue UI is drawn. Everything is done in one draw call (more is explained in “Drawing many sprites” section)&lt;/p&gt;
    &lt;p&gt;And that’s it! It’s pretty basic right now and would probably become much more complex in the future (see “Future work” section).&lt;/p&gt;
    &lt;head rend="h2"&gt;General advice&lt;/head&gt;
    &lt;head rend="h3"&gt;Recommended Vulkan libraries&lt;/head&gt;
    &lt;p&gt;There are a couple of libraries which greatly improve the experience of writing Vulkan. Most of them are already used in vkguide, but I still want to highlight how helpful they were to me.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;vk-bootstrap - https://github.com/charles-lunarg/vk-bootstrap&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;vk-bootstrap simplifies a lot of Vulkan boilerplate: physical device selection, swapchain creation and so on.&lt;/p&gt;
    &lt;p&gt;I don’t like big wrappers around graphic APIs because they tend to be very opinionated. Plus, you need to keep a mental map of “wrapper function vs function in the API spec” in your head at all times.&lt;/p&gt;
    &lt;p&gt;Thankfully, vk-bootstrap is not like this. It mostly affects the initialization step of your program and doesn’t attempt to be a wrapper around every Vulkan function.&lt;/p&gt;
    &lt;quote&gt;When I was learning Vulkan, I started doing Vulkan from scratch, without using any 3rd party libraries. Replacing big amounts of the initialization code with vk-bootstrap was a joy. It’s really worth it.&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Vulkan Memory Allocator (VMA) - https://github.com/GPUOpen-LibrariesAndSDKs/VulkanMemoryAllocator&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I’ll be honest, I used VMA without even learning about how to allocate memory in Vulkan manually. I read about it in the Vulkan spec later - I’m glad that I didn’t have to do it on my own.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;volk&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Volk was very useful for me for simplifying extension function loading. For example, if you want to use very useful &lt;code&gt;vkSetDebugUtilsObjectNameEXT&lt;/code&gt; for setting debug names for your objects (useful for RenderDoc captures and validation errors), you’ll need to do this if you don’t use volk:&lt;/p&gt;
    &lt;code&gt;// store this pointer somewhere
PFN_vkSetDebugUtilsObjectNameEXT pfnSetDebugUtilsObjectNameEXT;

// during your game init
pfnSetDebugUtilsObjectNameEXT = (PFN_vkSetDebugUtilsObjectNameEXT)
    vkGetInstanceProcAddr(instance, "vkSetDebugUtilsObjectNameEXT");

// and finally in your game code
pfnSetDebugUtilsObjectNameEXT(device, ...);
&lt;/code&gt;
    &lt;p&gt;With volk, all the extensions are immediately loaded after you call &lt;code&gt;volkInitialize&lt;/code&gt; and you don’t need to store these pointers everywhere. You just include &lt;code&gt;volk.h&lt;/code&gt; and call &lt;code&gt;vkSetDebugUtilsObjectNameEXT&lt;/code&gt; - beautiful!&lt;/p&gt;
    &lt;head rend="h3"&gt;GfxDevice abstraction&lt;/head&gt;
    &lt;p&gt;I have a &lt;code&gt;GfxDevice&lt;/code&gt; class which encapsulates most of the commonly used functionality and stores many objects that you need for calling Vulkan functions (&lt;code&gt;VkDevice&lt;/code&gt;, &lt;code&gt;VkQueue&lt;/code&gt; and so on). A single &lt;code&gt;GfxDevice&lt;/code&gt; instance is created on the startup and then gets passed around.&lt;/p&gt;
    &lt;p&gt;It handles:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Vulkan context initialization.&lt;/item&gt;
      &lt;item&gt;Swapchain creation and management.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;beginFrame&lt;/code&gt;returns a new&lt;code&gt;VkCommandBuffer&lt;/code&gt;which is later used in all the drawing steps.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;endFrame&lt;/code&gt;does drawing to the swapchain and does sync between the frames.&lt;/item&gt;
      &lt;item&gt;Image creation and loading textures from files.&lt;/item&gt;
      &lt;item&gt;Buffer creation.&lt;/item&gt;
      &lt;item&gt;Bindless descriptor set management (see “Bindless descriptors” section below).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;That’s… a lot of things. However, it’s not that big: &lt;code&gt;GfxDevice.cpp&lt;/code&gt; is only 714 lines at the time of writing this article. It’s more convenient to pass one object into the function instead of many (&lt;code&gt;VkDevice&lt;/code&gt;, &lt;code&gt;VkQueue&lt;/code&gt;, &lt;code&gt;VmaAllocator&lt;/code&gt; and so on).&lt;/p&gt;
    &lt;head rend="h3"&gt;Handling shaders&lt;/head&gt;
    &lt;p&gt;In Vulkan, you can use any shading language which compiles to SPIR-V - that means that you can use GLSL, HLSL and others. I chose GLSL because I already knew it from my OpenGL experience.&lt;/p&gt;
    &lt;p&gt;You can pre-compile your shaders during the build step or compile them on the fly. I do it during the build so that my shader loading runtime code is simpler. I also don’t have an additional runtime dependency on the shader compiler. Also, shader errors are detected during the build step and I don’t get compile errors during the runtime.&lt;/p&gt;
    &lt;p&gt;I use glslc (from shaderc project, it’s included in Vulkan SDK) which allows you to specify a &lt;code&gt;DEPFILE&lt;/code&gt; in CMake which is incredibly useful when you use shader includes. If you change a shader file, all files which include it are recompiled automatically. Without the &lt;code&gt;DEPFILE&lt;/code&gt;, CMake won’t be able to see which files shader files need to be recompiled and will only recompile the file which was changed.&lt;/p&gt;
    &lt;p&gt;My CMake script for building shaders looks like this:&lt;/p&gt;
    &lt;code&gt;function (target_shaders target shaders)
    set(SHADERS_BUILD_DIR "${CMAKE_CURRENT_BINARY_DIR}/shaders")
    file(MAKE_DIRECTORY "${SHADERS_BUILD_DIR}")
    foreach (SHADER_PATH ${SHADERS})
        get_filename_component(SHADER_FILENAME "${SHADER_PATH}" NAME)
        set(SHADER_SPIRV_PATH "${SHADERS_BUILD_DIR}/${SHADER_FILENAME}.spv")
        set(DEPFILE "${SHADER_SPIRV_PATH}.d")
        add_custom_command(
          COMMENT "Building ${SHADER_FILENAME}"
          OUTPUT "${SHADER_SPIRV_PATH}"
          COMMAND ${GLSLC} "${SHADER_PATH}" -o "${SHADER_SPIRV_PATH}" -MD -MF ${DEPFILE} -g
          DEPENDS "${SHADER_PATH}"
          DEPFILE "${DEPFILE}"
        )
        list(APPEND SPIRV_BINARY_FILES ${SHADER_SPIRV_PATH})
    endforeach()

    set(shaders_target_name "${target}_build_shaders")
    add_custom_target(${shaders_target_name}
      DEPENDS ${SPIRV_BINARY_FILES}
    )
    add_dependencies(${target} ${shaders_target_name})
endfunction()
&lt;/code&gt;
    &lt;p&gt;and then in the main CMakeLists file:&lt;/p&gt;
    &lt;code&gt;set(SHADERS
    skybox.frag
    skinning.comp
    ... // etc
)

# prepend shaders directory path
get_target_property(EDBR_SOURCE_DIR edbr SOURCE_DIR)
set(EDBR_SHADERS_DIR "${EDBR_SOURCE_DIR}/src/shaders/")
list(TRANSFORM SHADERS PREPEND "${EDBR_SHADERS_DIR}")

target_shaders(game ${SHADERS})
&lt;/code&gt;
    &lt;p&gt;Now, when you build a &lt;code&gt;game&lt;/code&gt; target, shaders get built automatically and the resulting SPIR-V files are put into the binary directory.&lt;/p&gt;
    &lt;head rend="h3"&gt;Push constants, descriptor sets and bindless descriptors&lt;/head&gt;
    &lt;p&gt;Passing data to shaders in OpenGL is much simpler than it is in Vulkan. In OpenGL, you could just do this:&lt;/p&gt;
    &lt;p&gt;In shader:&lt;/p&gt;
    &lt;code&gt;uniform float someFloat;
&lt;/code&gt;
    &lt;p&gt;In C++ code:&lt;/p&gt;
    &lt;code&gt;const auto loc = glGetUniformLocation(shader, "someFloat");
glUseProgram(shader);
glUniform1f(loc, 42.f);
&lt;/code&gt;
    &lt;p&gt;You can also use explicit uniform location like this.&lt;/p&gt;
    &lt;p&gt;In shader:&lt;/p&gt;
    &lt;code&gt;layout(location = 20) uniform float someFloat;
&lt;/code&gt;
    &lt;p&gt;In code:&lt;/p&gt;
    &lt;code&gt;const auto loc = 20;
glUniform1f(loc, 42.f);
&lt;/code&gt;
    &lt;p&gt;In Vulkan, you need to group your uniforms into “descriptor sets”:&lt;/p&gt;
    &lt;code&gt;// set 0
layout (set = 0, binding = 0) uniform float someFloat;
layout (set = 0, binding = 1) uniform mat4 someMatrix;
// set 1
layout (set = 1, binding = 0) uniform float someOtherFloat;
... // etc.
&lt;/code&gt;
    &lt;p&gt;Now, this makes things a lot more complicated, because you need to specify descriptor set layout beforehand, use descriptor set pools and allocate descriptor sets with them, do the whole &lt;code&gt;VkWriteDescriptorSet&lt;/code&gt; + &lt;code&gt;vkUpdateDescriptorSets&lt;/code&gt; thing, call &lt;code&gt;vkCmdBindDescriptorSets&lt;/code&gt; for each descriptor set and so on.&lt;/p&gt;
    &lt;p&gt;I’ll explain later how I avoided using descriptor sets by using bindless descriptors and buffer device access. Basically, I only have one “global” descriptor set for bindless textures and samplers, and that’s it. Everything else is passed via push constants which makes everything much easier to handle.&lt;/p&gt;
    &lt;head rend="h3"&gt;Pipeline pattern&lt;/head&gt;
    &lt;p&gt;I separate drawing steps into “pipeline” classes.&lt;/p&gt;
    &lt;p&gt;Most of them look like this:&lt;/p&gt;
    &lt;code&gt;class PostFXPipeline {
public:
    void init(GfxDevice&amp;amp; gfxDevice, VkFormat drawImageFormat);
    void cleanup(VkDevice device);

    void draw(
        VkCommandBuffer cmd,
        GfxDevice&amp;amp; gfxDevice,
        const GPUImage&amp;amp; drawImage,
        const GPUImage&amp;amp; depthImage,
        const GPUBuffer&amp;amp; sceneDataBuffer);

private:
    VkPipelineLayout pipelineLayout;
    VkPipeline pipeline;

    struct PushConstants {
        VkDeviceAddress sceneDataBuffer;
        std::uint32_t drawImageId;
        std::uint32_t depthImageId;
    };
};
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;init&lt;/code&gt;loads needed shaders and initializes&lt;code&gt;pipeline&lt;/code&gt;and&lt;code&gt;pipelineLayout&lt;/code&gt;:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;void PostFXPipeline::init(GfxDevice&amp;amp; gfxDevice, VkFormat drawImageFormat)
{
    const auto&amp;amp; device = gfxDevice.getDevice();

    const auto pcRange = VkPushConstantRange{
        .stageFlags = VK_SHADER_STAGE_FRAGMENT_BIT,
        .offset = 0,
        .size = sizeof(PushConstants),
    };

    const auto layouts = std::array{gfxDevice.getBindlessDescSetLayout()};
    const auto pushConstantRanges = std::array{pcRange};
    pipelineLayout = vkutil::createPipelineLayout(device, layouts, pushConstantRanges);

    const auto vertexShader =
        vkutil::loadShaderModule("shaders/fullscreen_triangle.vert.spv", device);
    const auto fragShader =
        vkutil::loadShaderModule("shaders/postfx.frag.spv", device);
    pipeline = PipelineBuilder{pipelineLayout}
                   .setShaders(vertexShader, fragShader)
                   .setInputTopology(VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST)
                   .setPolygonMode(VK_POLYGON_MODE_FILL)
                   .disableCulling()
                   .setMultisamplingNone()
                   .disableBlending()
                   .setColorAttachmentFormat(drawImageFormat)
                   .disableDepthTest()
                   .build(device);
    vkutil::addDebugLabel(device, pipeline, "postFX pipeline");

    vkDestroyShaderModule(device, vertexShader, nullptr);
    vkDestroyShaderModule(device, fragShader, nullptr);
}
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;init&lt;/code&gt; function is usually called once during the engine initialization. &lt;code&gt;PipelineBuilder&lt;/code&gt; abstraction is described in vkguide here. I modified it a bit to use the Builder pattern to be able to chain the calls.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;cleanup&lt;/code&gt;does all the needed cleanup. It usually simply destroys the pipeline and its layout:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;void PostFXPipeline::cleanup(VkDevice device)
{
    vkDestroyPipeline(device, pipeline, nullptr);
    vkDestroyPipelineLayout(device, pipelineLayout, nullptr);
}
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;draw&lt;/code&gt;is called each frame and all the needed inputs are passed as arguments. It’s assumed that the sync is performed outside of the&lt;code&gt;draw&lt;/code&gt;call (see “Synchronization” section below). Some pipelines are only called once per frame - some either take&lt;code&gt;std::vector&lt;/code&gt;of objects to draw or are called like this:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;for (const auto&amp;amp; mesh : meshes) {
    somePipeline.draw(cmd, gfxDevice, mesh, ...);
}
&lt;/code&gt;
    &lt;p&gt;The typical &lt;code&gt;draw&lt;/code&gt; function looks like this:&lt;/p&gt;
    &lt;code&gt;void PostFXPipeline::draw(
    VkCommandBuffer cmd,
    GfxDevice&amp;amp; gfxDevice,
    const GPUImage&amp;amp; drawImage,
    const GPUImage&amp;amp; depthImage,
    const GPUBuffer&amp;amp; sceneDataBuffer)
{
    // Bind the pipeline
    vkCmdBindPipeline(cmd, VK_PIPELINE_BIND_POINT_GRAPHICS, pipeline);

    // Bind the bindless descriptor set
    gfxDevice.bindBindlessDescSet(cmd, pipelineLayout);

    // Handle push constants
    const auto pcs = PushConstants{
        // BDA - explained below
        .sceneDataBuffer = sceneDataBuffer.address,
        // bindless texture ids - no need for desc. sets!
        // explained below
        .drawImageId = drawImage.getBindlessId(),
        .depthImageId = depthImage.getBindlessId(),
    };
    vkCmdPushConstants(
        cmd, pipelineLayout, VK_SHADER_STAGE_FRAGMENT_BIT, 0, sizeof(PushConstants), &amp;amp;pcs);

    // Finally, do some drawing. Here we're drawing a fullscreen triangle
    // to do a full-screen effect.
    vkCmdDraw(cmd, 3, 1, 0, 0);
}
&lt;/code&gt;
    &lt;p&gt;Note another thing: it’s assumed that &lt;code&gt;draw&lt;/code&gt; is called between &lt;code&gt;vkCmdBeginRendering&lt;/code&gt; and &lt;code&gt;vkCmdEndRendering&lt;/code&gt; - the render pass itself doesn’t care what texture it renders to - the caller of &lt;code&gt;draw&lt;/code&gt; is responsible for that. It makes things simpler and allows you to do several draws to the same render target, e.g.:&lt;/p&gt;
    &lt;code&gt;// handy wrapper for creating VkRenderingInfo
const auto renderInfo = vkutil::createRenderingInfo({
    .renderExtent = drawImage.getExtent2D(),
    .colorImageView = drawImage.imageView,
    .colorImageClearValue = glm::vec4{0.f, 0.f, 0.f, 1.f},
    .depthImageView = depthImage.imageView,
    .depthImageClearValue = 0.f,
    // for MSAA
    .resolveImageView = resolveImage.imageView,
});

vkCmdBeginRendering(cmd, &amp;amp;renderInfo.renderingInfo);

// draw meshes
for (const auto&amp;amp; mesh : meshesToDraw) {
    meshPipeline.draw(cmd, gfxDevice, mesh, ...);
}
// draw sky
skyboxPipeline.draw(cmd, gfxDevice, camera);

vkCmdEndRendering(cmd);
&lt;/code&gt;
    &lt;quote&gt;I use&lt;code&gt;VK_KHR_dynamic_rendering&lt;/code&gt;everywhere. I don’t use Vulkan render passes and subpasses at all. I’ve heard that they’re more efficient on tile-based GPUs, but I don’t care about mobile support for now.&lt;code&gt;VK_KHR_dynamic_rendering&lt;/code&gt;just makes everything much easier.&lt;/quote&gt;
    &lt;head rend="h3"&gt;Using programmable vertex pulling (PVP) + buffer device address (BDA)&lt;/head&gt;
    &lt;p&gt;I have one vertex type for all the meshes. It looks like this:&lt;/p&gt;
    &lt;code&gt;struct Vertex {
    vec3 position;
    float uv_x;
    vec3 normal;
    float uv_y;
    vec4 tangent;
};
&lt;/code&gt;
    &lt;quote&gt;Of course, you can greatly optimize it using various methods, but it’s good enough for me for now. The&lt;code&gt;uv_x&lt;/code&gt;/&lt;code&gt;uv_y&lt;/code&gt;separation comes from vkguide - I think it’s a nice idea to get good alignment and not waste any bytes&lt;/quote&gt;
    &lt;p&gt;The vertices are accessed in the shader like this:&lt;/p&gt;
    &lt;code&gt;layout (buffer_reference, std430) readonly buffer VertexBuffer {
    Vertex vertices[];
};

layout (push_constant, scalar) uniform constants
{
    VertexBuffer vertexBuffer;
    ... // other stuff
} pcs;

void main()
{
    Vertex v = pcs.vertexBuffer.vertices[gl_VertexIndex];
    ...
}
&lt;/code&gt;
    &lt;p&gt;PVP frees you from having to define vertex format (no more VAOs like in OpenGL or &lt;code&gt;VkVertexInputBindingDescription&lt;/code&gt; + &lt;code&gt;VkVertexInputAttributeDescription&lt;/code&gt; in Vulkan). BDA also frees you from having to bind a buffer to a descriptor set - you just pass an address to your buffer which contains vertices in push constants and that’s it.&lt;/p&gt;
    &lt;code&gt;
  Also note the  scalar layout for push constants. I use it for all the buffers too. Compared to “std430” layout, it makes alignment a lot more easy to handle - it almost works the same as in C++ and greatly reduces the need for “padding” members in C++ structs.
&lt;/code&gt;
    &lt;head rend="h3"&gt;Bindless descriptors&lt;/head&gt;
    &lt;p&gt;Textures were painful to work with even in OpenGL - you had “texture slots” which were awkward to work with. You couldn’t just sample any texture from the shader if it wasn’t bound to a texture slot beforehand. &lt;code&gt;ARB_bindless_texture&lt;/code&gt; changed that and made many things easier.&lt;/p&gt;
    &lt;p&gt;Vulkan doesn’t have the exact same functionality, but it has something similar. You can create big descriptor sets which look like this:&lt;/p&gt;
    &lt;code&gt;// bindless.glsl
layout (set = 0, binding = 0) uniform texture2D textures[];
...
layout (set = 0, binding = 1) uniform sampler samplers[];
&lt;/code&gt;
    &lt;p&gt;You’ll need to maintain a list of all your textures using some “image manager” and when a new texture is loaded, you need to insert it into the &lt;code&gt;textures&lt;/code&gt; array. The index at which you inserted it becomes a bindless “texture id” which then can be used to sample it in shaders. Now you can pass these ids in your push constants like this:&lt;/p&gt;
    &lt;code&gt;layout (push_constant, scalar) uniform constants
{
  uint textureId;
  ...
} pcs;
&lt;/code&gt;
    &lt;p&gt;and then you can sample your texture in the fragment shader like this:&lt;/p&gt;
    &lt;code&gt;// bindless.glsl
#define NEAREST_SAMPLER_ID 0
...

vec4 sampleTexture2DNearest(uint texID, vec2 uv) {
    return texture(nonuniformEXT(sampler2D(textures[texID], samplers[NEAREST_SAMPLER_ID])), uv);
}

// shader.frag
vec4 color = sampleTexture2DNearest(pcs.textureId, inUV);
&lt;/code&gt;
    &lt;p&gt;Two things to note:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;I chose separate image samplers so that I could sample any texture using different samplers. Common samplers (nearest, linear with anisotropy, depth texture samplers) are created and put into &lt;code&gt;samplers&lt;/code&gt;array on the startup.&lt;/item&gt;
      &lt;item&gt;The wrapper function makes the process of sampling a lot more convenient.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;
  The placement of  nonuniformEXT is somewhat tricky and is explained very well here.
&lt;/code&gt;
    &lt;p&gt;I use bindless ids for the mesh material buffer which looks like this:&lt;/p&gt;
    &lt;code&gt;struct MaterialData {
    vec4 baseColor;
    vec4 metallicRoughnessEmissive;
    uint diffuseTex;
    uint normalTex;
    uint metallicRoughnessTex;
    uint emissiveTex;
};

layout (buffer_reference, std430) readonly buffer MaterialsBuffer {
    MaterialData data[];
} materialsBuffer;
&lt;/code&gt;
    &lt;p&gt;Now I can only pass material ID in my push constants and then sample texture like this in the fragment shader:&lt;/p&gt;
    &lt;code&gt;MaterialData material = materials[pcs.materialID];
vec4 diffuse = sampleTexture2DLinear(material.diffuseTex, inUV);
...
&lt;/code&gt;
    &lt;p&gt;Neat! No more bulky descriptor sets, just one int per material in the push constants.&lt;/p&gt;
    &lt;p&gt;You can also put different texture types into the same set like this (this is needed for being able to access textures of types other than &lt;code&gt;texture2D&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;layout (set = 0, binding = 0) uniform texture2D textures[];
layout (set = 0, binding = 0) uniform texture2DMS texturesMS[];
layout (set = 0, binding = 0) uniform textureCube textureCubes[];
layout (set = 0, binding = 0) uniform texture2DArray textureArrays[];
&lt;/code&gt;
    &lt;p&gt;And here’s how you can sample &lt;code&gt;textureCube&lt;/code&gt; with a linear sampler (note that we use &lt;code&gt;textureCubes&lt;/code&gt; here instead of &lt;code&gt;textures&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;vec4 sampleTextureCubeLinear(uint texID, vec3 p) {
    return texture(nonuniformEXT(samplerCube(textureCubes[texID], samplers[NEAREST_SAMPLER_ID])), p);
}
&lt;/code&gt;
    &lt;p&gt;Here’s a very good article on using bindless textures in Vulkan:&lt;/p&gt;
    &lt;p&gt;https://jorenjoestar.github.io/post/vulkan_bindless_texture/&lt;/p&gt;
    &lt;head rend="h3"&gt;Handling dynamic data which needs to be uploaded every frame&lt;/head&gt;
    &lt;p&gt;I find it useful to pre-allocate big arrays of things and push stuff to them in every frame. Basically, you can pre-allocate an array of N structs (or matrices) and then start at index 0 at each new frame and push things to it from the CPU. Then, you can access all these items in your shaders. For example, I have all joint matrices stored in one big &lt;code&gt;mat4&lt;/code&gt; array and the skinning compute shader accesses joint matrices of a particular mesh using start index passed via push constants (more about it will be explained later).&lt;/p&gt;
    &lt;p&gt;Here are two ways of doing this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;list rend="ol"&gt;
          &lt;item&gt;Have N buffers on GPU and swap between them.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;vkguide explains the concept of “in flight” frames pretty well. To handle this parallelism properly, you need to have one buffer for the “currently drawing” frame and one buffer for “currently recording new drawing commands” frame to not have races. (If you have more frames in flight, you’ll need to allocate more than 2 buffers)&lt;/p&gt;
    &lt;p&gt;This means that you need to preallocate 2 buffers on GPU. You write data from CPU to GPU to the first buffer during the first frame. While you record the second frame, GPU reads from the first buffer while you write new data to the second buffer. On the third frame, GPU reads from the second buffer and you write new info to the first buffer… and so on.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;list rend="ol"&gt;
          &lt;item&gt;One buffer on GPU and N “staging” buffers on CPU&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This might be useful if you need to conserve some memory on the GPU.&lt;/p&gt;
    &lt;p&gt;Let’s see how it works in my engine:&lt;/p&gt;
    &lt;code&gt;class NBuffer {
public:
    void init(
        GfxDevice&amp;amp; gfxDevice,
        VkBufferUsageFlags usage,
        std::size_t dataSize,
        std::size_t numFramesInFlight,
        const char* label);

    void cleanup(GfxDevice&amp;amp; gfxDevice);

    void uploadNewData(
        VkCommandBuffer cmd,
        std::size_t frameIndex,
        void* newData,
        std::size_t dataSize,
        std::size_t offset = 0);

    const GPUBuffer&amp;amp; getBuffer() const { return gpuBuffer; }

private:
    std::size_t framesInFlight{0};
    std::size_t gpuBufferSize{0};
    std::vector&amp;lt;GPUBuffer&amp;gt; stagingBuffers;
    GPUBuffer gpuBuffer;
    bool initialized{false};
};

void NBuffer::init(
    GfxDevice&amp;amp; gfxDevice,
    VkBufferUsageFlags usage,
    std::size_t dataSize,
    std::size_t numFramesInFlight,
    const char* label)
{
    ...

    gpuBuffer = gfxDevice.createBuffer(
        dataSize, usage | VK_IMAGE_USAGE_TRANSFER_DST_BIT, VMA_MEMORY_USAGE_AUTO_PREFER_DEVICE);
    vkutil::addDebugLabel(gfxDevice.getDevice(), gpuBuffer.buffer, label);

    for (std::size_t i = 0; i &amp;lt; numFramesInFlight; ++i) {
        stagingBuffers.push_back(gfxDevice.createBuffer(
            dataSize, usage | VK_BUFFER_USAGE_TRANSFER_SRC_BIT, VMA_MEMORY_USAGE_AUTO_PREFER_HOST));
    }

    ...
}
&lt;/code&gt;
    &lt;p&gt;Note how staging buffers are created using VMA’s &lt;code&gt;PREFER_HOST&lt;/code&gt; flag and the “main” buffer from which we read in the shader is using the &lt;code&gt;PREFER_DEVICE&lt;/code&gt; flag.&lt;/p&gt;
    &lt;p&gt;Here’s how new data is uploaded (full implementation):&lt;/p&gt;
    &lt;code&gt;void NBuffer::uploadNewData(
    VkCommandBuffer cmd,
    std::size_t frameIndex,
    void* newData,
    std::size_t dataSize,
    std::size_t offset) const
{
    assert(initialized);
    assert(frameIndex &amp;lt; framesInFlight);
    assert(offset + dataSize &amp;lt;= gpuBufferSize &amp;amp;&amp;amp; "NBuffer::uploadNewData: out of bounds write");

    if (dataSize == 0) {
        return;
    }

    // sync with previous read
    ... // READ BARRIER CODE HERE

    auto&amp;amp; staging = stagingBuffers[frameIndex];
    auto* mappedData = reinterpret_cast&amp;lt;std::uint8_t*&amp;gt;(staging.info.pMappedData);
    memcpy((void*)&amp;amp;mappedData[offset], newData, dataSize);

    const auto region = VkBufferCopy2{
        .sType = VK_STRUCTURE_TYPE_BUFFER_COPY_2,
        .srcOffset = (VkDeviceSize)offset,
        .dstOffset = (VkDeviceSize)offset,
        .size = dataSize,
    };
    const auto bufCopyInfo = VkCopyBufferInfo2{
        .sType = VK_STRUCTURE_TYPE_COPY_BUFFER_INFO_2,
        .srcBuffer = staging.buffer,
        .dstBuffer = gpuBuffer.buffer,
        .regionCount = 1,
        .pRegions = &amp;amp;region,
    };

    vkCmdCopyBuffer2(cmd, &amp;amp;bufCopyInfo);

    // sync with write
    ... // WRITE BARRIER CODE HERE
}
&lt;/code&gt;
    &lt;p&gt;I’d go with the first approach for most cases (more data on GPU, but no need for manual sync) unless you need to conserve GPU memory for some reason. I’ve found no noticeable difference in performance between two approaches, but it might matter if you are uploading huge amounts of data to GPU on each frame.&lt;/p&gt;
    &lt;head rend="h3"&gt;Destructors, deletion queue and cleanup&lt;/head&gt;
    &lt;p&gt;Now, this might be somewhat controversial… but I didn’t find much use of the deletion queue pattern used in vkguide. I don’t really need to allocated/destroy new objects on every frame.&lt;/p&gt;
    &lt;p&gt;Using C++ destructors for Vulkan object cleanup is not very convenient either. You need to wrap everything in custom classes, add move constructors and move &lt;code&gt;operator=&lt;/code&gt;… It adds an additional layer of complexity.&lt;/p&gt;
    &lt;p&gt;In most cases, the cleanup of Vulkan objects happens in one place - and you don’t want to accidentally destroy some in-use object mid-frame by accidentally destroying some wrapper object.&lt;/p&gt;
    &lt;p&gt;It’s also harder to manage lifetimes when you have cleanup in happening in the destructor. For example, suppose you have a case like this:&lt;/p&gt;
    &lt;code&gt;struct SomeClass {
    SomeOtherClass b;

    void init() {
        ...
    }

    void cleanup() {
        ...
    }
}
&lt;/code&gt;
    &lt;p&gt;If you want to cleanup &lt;code&gt;SomeOtherClass&lt;/code&gt; resources (e.g. the instance of &lt;code&gt;SomeOtherClass&lt;/code&gt; has a &lt;code&gt;VkPipeline&lt;/code&gt; object) during &lt;code&gt;SomeClass::cleanup&lt;/code&gt;, you can’t do that if the cleanup of &lt;code&gt;SomeOtherClass&lt;/code&gt; is performed in its destructor.&lt;/p&gt;
    &lt;p&gt;Of course, you can do this:&lt;/p&gt;
    &lt;code&gt;struct SomeClass {
    std::unique_ptr&amp;lt;SomeOtherClass&amp;gt; b;

    void init() {
        b = std::make_unique&amp;lt;SomeOtherClass&amp;gt;();
        ...
    }

    void cleanup() {
        b.reset();
        ...
    }
}
&lt;/code&gt;
    &lt;p&gt;… but I don’t like how it introduces a dynamic allocation and requires you to do write more code (and it’s not that much different from calling a &lt;code&gt;cleanup&lt;/code&gt; function manually).&lt;/p&gt;
    &lt;p&gt;Right now, I prefer to clean up stuff directly, e.g.&lt;/p&gt;
    &lt;code&gt;class SkyboxPipeline {
public:
    void cleanup(VkDevice device) {
        vkDestroyPipeline(device, pipeline, nullptr);
        vkDestroyPipelineLayout(device, pipelineLayout, nullptr);
    }

private:
    VkPipelineLayout pipelineLayout;
    VkPipeline pipeline;
    ...
}

// in GameRenderer.cpp:
void GameRenderer::cleanup(VkDevice device) {
    ...
    skyboxPipeline.cleanup(device);
    ...
}
&lt;/code&gt;
    &lt;p&gt;This approach is not perfect - first of all, it’s easy to forget to call &lt;code&gt;cleanup&lt;/code&gt; function, This is not a huge problem since you get a validation error in case you forget to cleanup some Vulkan resources on shutdown:&lt;/p&gt;
    &lt;code&gt;Validation Error: [ VUID-vkDestroyDevice-device-05137 ] Object 0: handle = 0x4256c1000000005d, type = VK_OBJECT_TYPE_PIPELINE_LAYOUT; | MessageID = 0x4872eaa0 | vkCreateDevice():  OBJ ERROR : For VkDevice 0x27bd530[], VkPipelineLayout 0x4256c1000000005d[] has not been destroyed. The Vulkan spec states: All child objects created on device must have been destroyed prior to destroying device (https://vulkan.lunarg.com/doc/view/1.3.280.1/linux/1.3-extensions/vkspec.html#VUID-vkDestroyDevice-device-05137)
&lt;/code&gt;
    &lt;p&gt;VMA also triggers asserts if you forget to free some buffer/image allocated with it.&lt;/p&gt;
    &lt;p&gt;I find it convenient to have all the Vulkan cleanup happening explicitly in one place. It makes it easy to track when the objects get destroyed.&lt;/p&gt;
    &lt;head rend="h3"&gt;Synchronization&lt;/head&gt;
    &lt;p&gt;Synchronization in Vulkan is difficult. OpenGL and WebGPU do it for you - if you read from some texture/buffer, you know that it will have the correct data and you won’t get problems with data races. With Vulkan, you need to be explicit and this is usually where things tend to get complicated.&lt;/p&gt;
    &lt;p&gt;Right now I manage most of the complexities of sync manually in one place. I separate my drawing into “passes”/pipelines (as described above) and then insert barriers between them. For example, the skinning pass writes new vertex data into GPU memory. Shadow mapping pass reads this data to render skinned meshes into the shadow map. Sync in my code looks like this:&lt;/p&gt;
    &lt;code&gt;// do skinning in compute shader
for (const auto&amp;amp; mesh : skinnedMeshes) {
    skinningPass.doSkinning(gfxDevice, mesh);
}

{
    // Sync skinning with CSM
    // This is a "fat" barrier and you can potentially optimize it
    // by specifying all the buffers that the next pass will read from
    const auto memoryBarrier = VkMemoryBarrier2{
        .sType = VK_STRUCTURE_TYPE_MEMORY_BARRIER_2,
        .srcStageMask = VK_PIPELINE_STAGE_2_COMPUTE_SHADER_BIT,
        .srcAccessMask = VK_ACCESS_2_SHADER_WRITE_BIT,
        .dstStageMask = VK_PIPELINE_STAGE_2_VERTEX_SHADER_BIT,
        .dstAccessMask = VK_ACCESS_2_MEMORY_READ_BIT,
    };
    const auto dependencyInfo = VkDependencyInfo{
        .sType = VK_STRUCTURE_TYPE_DEPENDENCY_INFO,
        .memoryBarrierCount = 1,
        .pMemoryBarriers = &amp;amp;memoryBarrier,
    };
    vkCmdPipelineBarrier2(cmd, &amp;amp;dependencyInfo);
}

// do shadow mapping
shadowMappingPass.draw(gfxDevice, ...);
&lt;/code&gt;
    &lt;p&gt;Of course, this can be automated/simplified using render graphs. This is something that I might implement in the future. Right now I’m okay with doing manual sync. vkconfig’s “synchronization” validation layer also helps greatly in finding sync errors.&lt;/p&gt;
    &lt;p&gt;The following resources were useful for understanding synchronization:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;https://themaister.net/blog/2019/08/14/yet-another-blog-explaining-vulkan-synchronization/&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;https://github.com/KhronosGroup/Vulkan-Docs/wiki/Synchronization-Examples&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;More implementation notes&lt;/head&gt;
    &lt;head rend="h3"&gt;Drawing many sprites&lt;/head&gt;
    &lt;p&gt;With bindless textures, it’s easy to draw many sprites using one draw call without having to allocate vertex buffers at all.&lt;/p&gt;
    &lt;p&gt;First of all, you can emit vertex coordinates and UVs using &lt;code&gt;gl_VertexIndex&lt;/code&gt; in your vertex shader like this:&lt;/p&gt;
    &lt;code&gt;void main()
{
    uint b = 1 &amp;lt;&amp;lt; (gl_VertexIndex % 6);
    vec2 baseCoord = vec2((0x1C &amp;amp; b) != 0, (0xE &amp;amp; b) != 0);
    ...
}
&lt;/code&gt;
    &lt;p&gt;This snippet produces this set of values:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;gl_VertexIndex&lt;/cell&gt;
        &lt;cell role="head"&gt;baseCoord&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;(0,0)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;(0,1)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;(1,1)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;(1,1)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;(1,0)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;(0,0)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;All the sprite draw calls are combined into &lt;code&gt;SpriteDrawBuffer&lt;/code&gt; which looks like this in GLSL:&lt;/p&gt;
    &lt;code&gt;struct SpriteDrawCommand {
    mat4 transform; // could potentially be mat2x2...
    vec2 uv0; // top-left uv coord
    vec2 uv1; // bottom-right uv coord
    vec4 color; // color by which texture is multiplied
    uint textureID; // sprite texture
    uint shaderID; // explained below
    vec2 padding; // padding to satisfy "scalar" requirements
};

layout (buffer_reference, scalar) readonly buffer SpriteDrawBuffer {
    SpriteDrawCommand commands[];
};
&lt;/code&gt;
    &lt;p&gt;On CPU/C++ side, it looks almost the same:&lt;/p&gt;
    &lt;code&gt;struct SpriteDrawCommand {
    glm::mat4 transform;
    glm::vec2 uv0; // top-left uv coordinate
    glm::vec2 uv1; // bottom-right uv coodinate
    LinearColor color; // color by which texture is multiplied by
    std::uint32_t textureId; // sprite texture
    std::uint32_t shaderId; // explained below
    glm::vec2 padding; // padding
};

std::vector&amp;lt;SpriteDrawCommand&amp;gt; spriteDrawCommands;
&lt;/code&gt;
    &lt;p&gt;I create two fixed size buffers on the GPU and then upload the contents of &lt;code&gt;spriteDrawCommands&lt;/code&gt; (using techniques described above in the “Handling dynamic data” section).&lt;/p&gt;
    &lt;p&gt;The sprite renderer is used like this:&lt;/p&gt;
    &lt;code&gt;// record commands
renderer.beginDrawing();
{
    renderer.drawSprite(sprite, pos);
    renderer.drawText(font, "Hello");
    renderer.drawRect(...);
}
renderer.endDrawing();

// do actual drawing later:
renderer.draw(cmd, gfxDevice, ...);
&lt;/code&gt;
    &lt;code&gt;
  The same renderer also draws text, rectangles and lines in my engine. For example, the text is just N “draw sprite” commands for a string composed of N glyphs. Solid color rectangles and lines are achieved by using a 1x1 pixel white texture and multiplying it by  SpriteCommand::color in the fragment shader.
&lt;/code&gt;
    &lt;p&gt;And finally, here’s how the command to do the drawing looks like inside &lt;code&gt;SpriteRenderer::draw&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;vkCmdDraw(cmd, 6, spriteDrawCommands.size(), 0, 0);
// 6 vertices per instance, spriteDrawCommands.size() instances in total
&lt;/code&gt;
    &lt;p&gt;The complete sprite.vert looks like this:&lt;/p&gt;
    &lt;code&gt;#version 460

#extension GL_GOOGLE_include_directive : require
#extension GL_EXT_buffer_reference : require

#include "sprite_commands.glsl"

layout (push_constant) uniform constants
{
    mat4 viewProj; // 2D camera matrix
    SpriteDrawBuffer drawBuffer; // where sprite draw commands are stored
} pcs;

layout (location = 0) out vec2 outUV;
layout (location = 1) out vec4 outColor;
layout (location = 2) flat out uint textureID;
layout (location = 3) flat out uint shaderID;

void main()
{
    uint b = 1 &amp;lt;&amp;lt; (gl_VertexIndex % 6);
    vec2 baseCoord = vec2((0x1C &amp;amp; b) != 0, (0xE &amp;amp; b) != 0);

    SpriteDrawCommand command = pcs.drawBuffer.commands[gl_InstanceIndex];

    gl_Position = pcs.viewProj * command.transform * vec4(baseCoord, 0.f, 1.f);
    outUV = (1.f - baseCoord) * command.uv0 + baseCoord * command.uv1;
    outColor = command.color;
    textureID = command.textureID;
    shaderID = command.shaderID;
}
&lt;/code&gt;
    &lt;p&gt;All the parameters of the sprite draw command are self-explanatory, but &lt;code&gt;shaderID&lt;/code&gt; needs a bit of clarification. Currently, I use it to branch inside the fragment shader:&lt;/p&gt;
    &lt;code&gt;...

#define SPRITE_SHADER_ID 0
#define TEXT_SHADER_ID   1

void main()
{
    vec4 texColor = sampleTexture2DNearest(textureID, inUV);

    // text drawing is performed differently...
    if (shaderID == TEXT_SHADER_ID) {
        // glyph atlas uses single-channel texture
        texColor = vec4(1.0, 1.0, 1.0, texColor.r);
    }

    if (texColor.a &amp;lt; 0.1) {
        discard;
    }

    outColor = inColor * texColor;
}
&lt;/code&gt;
    &lt;p&gt;This allows me to draw sprites differently depending on this ID without having to change pipelines. Of course, it can be potentially bad for the performance. This can be improved by drawing sprites with the same shader ID in batches. You’ll only need to switch pipelines when you encounter a draw command with a different shader ID.&lt;/p&gt;
    &lt;p&gt;The sprite renderer is very efficient: it can draw 10 thousand sprites in just 315 microseconds.&lt;/p&gt;
    &lt;head rend="h3"&gt;Compute skinning&lt;/head&gt;
    &lt;p&gt;I do skinning for skeletal animation in a compute shader. This allows me to have the same vertex format for all the meshes.&lt;/p&gt;
    &lt;p&gt;Basically, I just take the mesh’s vertices (not skinned) and joint matrices and produce a new buffer of vertices which are used in later rendering stages.&lt;/p&gt;
    &lt;p&gt;Suppose you spawn three cats with identical meshes:&lt;/p&gt;
    &lt;p&gt;All three of them can have different animations. They all have an identical “input” mesh. But the “output” vertex buffer will differ between them, which means that you need to pre-allocate a vertex buffer for each instance of the mesh.&lt;/p&gt;
    &lt;p&gt;Here’s how the skinning compute shader looks like:&lt;/p&gt;
    &lt;code&gt;#version 460

#extension GL_GOOGLE_include_directive : require
#extension GL_EXT_buffer_reference : require

#include "vertex.glsl"

struct SkinningDataType {
    ivec4 jointIds;
    vec4 weights;
};

layout (buffer_reference, std430) readonly buffer SkinningData {
    SkinningDataType data[];
};

layout (buffer_reference, std430) readonly buffer JointMatrices {
    mat4 matrices[];
};

layout (push_constant) uniform constants
{
    JointMatrices jointMatrices;
    uint jointMatricesStartIndex;
    uint numVertices;
    VertexBuffer inputBuffer;
    SkinningData skinningData;
    VertexBuffer outputBuffer;
} pcs;

layout (local_size_x = 256, local_size_y = 1, local_size_z = 1) in;

mat4 getJointMatrix(int jointId) {
    return pcs.jointMatrices.matrices[pcs.jointMatricesStartIndex + jointId];
}

void main()
{
    uint index = gl_GlobalInvocationID.x;
    if (index &amp;gt;= pcs.numVertices) {
        return;
    }

    SkinningDataType sd = pcs.skinningData.data[index];
    mat4 skinMatrix =
        sd.weights.x * getJointMatrix(sd.jointIds.x) +
        sd.weights.y * getJointMatrix(sd.jointIds.y) +
        sd.weights.z * getJointMatrix(sd.jointIds.z) +
        sd.weights.w * getJointMatrix(sd.jointIds.w);

    Vertex v = pcs.inputBuffer.vertices[index];
    v.position = vec3(skinMatrix * vec4(v.position, 1.0));

    pcs.outputBuffer.vertices[index] = v;
}
&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;I store all joint matrices in a big array and populate it every frame (and also pass the starting index in the array for each skinned mesh, &lt;code&gt;jointMatricesStartIndex&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Skinning data is not stored inside each mesh vertex, a separate buffer of &lt;code&gt;num_vertices&lt;/code&gt;elements is used.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;After the skinning is performed, all the later rendering stages use this set of vertices Thee rendering process for static and skinned meshes becomes identical, thanks to that.&lt;/p&gt;
    &lt;quote&gt;Anton’s OpenGL 4 Tutorials book has the best skinning implementation guide I’ve ever read. Game Engine Architecture by Jason Gregory has nice explanations about skinning/skeletal animation math as well.&lt;/quote&gt;
    &lt;head rend="h3"&gt;Game / renderer separation&lt;/head&gt;
    &lt;p&gt;I have a game/renderer separation which uses a simple concept of “draw commands”. In the game logic, I use entt, but the renderer doesn’t know anything about entities or “game objects”. It only knows about the lights, some scene parameters (like fog, which skybox texture to use etc) and meshes it needs to draw.&lt;/p&gt;
    &lt;p&gt;The renderer’s API looks like this in action:&lt;/p&gt;
    &lt;code&gt;void Game::generateDrawList()
{
    renderer.beginDrawing();

    // Add lights
    const auto lights = ...; // get list of all active lights
    for (const auto&amp;amp;&amp;amp; [e, tc, lc] : lights.each()) {
        renderer.addLight(lc.light, tc.transform);
    }

    // Render static meshes
    const auto staticMeshes = ...; // list of entities with static meshes
    for (const auto&amp;amp;&amp;amp; [e, tc, mc] : staticMeshes.each()) {
        // Each "mesh" can have multiple submeshes similar to how
        // glTF separates each "mesh" into "primitives".
        for (std::size_t i = 0; i &amp;lt; mc.meshes.size(); ++i) {
            renderer.drawMesh(mc.meshes[i], tc.worldTransform, mc.castShadow);
        }
    }

    // Render meshes with skeletal animation
    const auto skinnedMeshes = ...; // list of entities with skeletal animations
    for (const auto&amp;amp;&amp;amp; [e, tc, mc, sc] : skinnedMeshes.each()) {
        renderer.drawSkinnedMesh(
            mc.meshes, sc.skinnedMeshes, tc.worldTransform,
            sc.skeletonAnimator.getJointMatrices());
    }

    renderer.endDrawing();
}
&lt;/code&gt;
    &lt;p&gt;When you call &lt;code&gt;drawMesh&lt;/code&gt; or &lt;code&gt;drawSkinnedMesh&lt;/code&gt;, the renderer creates a mesh draw command and puts it in &lt;code&gt;std::vector&amp;lt;MeshDrawCommand&amp;gt;&lt;/code&gt; which are then iterated through during the drawing process. The &lt;code&gt;MeshDrawCommand&lt;/code&gt; looks like this:&lt;/p&gt;
    &lt;code&gt;
struct SkinnedMesh {
    GPUBuffer skinnedVertexBuffer;
};

struct MeshDrawCommand {
    MeshId meshId;
    glm::mat4 transformMatrix;
    math::Sphere worldBoundingSphere;

    const SkinnedMesh* skinnedMesh{nullptr};
    std::uint32_t jointMatricesStartIndex;
    bool castShadow{true};
};
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;meshId&lt;/code&gt;is used for looking up static meshes in&lt;code&gt;MeshCache&lt;/code&gt;- it’s a simple&lt;code&gt;std::vector&lt;/code&gt;of references to vertex buffers on GPU.&lt;/item&gt;
      &lt;item&gt;If the mesh has a skeleton, &lt;code&gt;jointMatricesStartIndex&lt;/code&gt;is used during compute skinning and&lt;code&gt;skinnedMesh-&amp;gt;skinnedVertexBuffer&lt;/code&gt;is used for all the rendering afterwards (instead of&lt;code&gt;meshId&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;worldBoundingSphere&lt;/code&gt;is used for frustum culling.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This separation is nice because the renderer is clearly separated from the game logic. You can also do something more clever as described here if sorting draw commands becomes a bottleneck.&lt;/p&gt;
    &lt;head rend="h3"&gt;Scene loading and entity prefabs&lt;/head&gt;
    &lt;p&gt;I use Blender as a level editor and export it as glTF. It’s easy to place objects, colliders and lights there. Here’s how it looks like:&lt;/p&gt;
    &lt;p&gt;Writing your own level editor would probably take months (years!), so using Blender instead saved me quite a lot of time.&lt;/p&gt;
    &lt;p&gt;It’s important to mention how I use node names for spawning some objects. For example, you can see an object named &lt;code&gt;Interact.Sphere.Diary&lt;/code&gt; selected in the screenshot above. The part before the first dot is the prefab name (in this case “Interact”). The “Sphere” part is used by the physics system to create a sphere physics body for the object (“Capsule” and “Box” can also be used, otherwise the physics shape is created using mesh vertices).&lt;/p&gt;
    &lt;p&gt;Some models are pretty complex and I don’t want to place them directly into the level glTF file as it’ll greatly increase each level’s size. I just place an “Empty-&amp;gt;Arrows” object and name it something like “Cat.NearStore”. This will spawn “Cat” prefab and attach “NearStore” tag to it for runtime identification.&lt;/p&gt;
    &lt;p&gt;Prefabs are written in JSON and look like this:&lt;/p&gt;
    &lt;code&gt;{
  "scene": {
    "scene": "assets/models/cato.gltf"
  },
  "movement": {
    "maxSpeed": [4, 4, 4]
  },
  "physics": {
    "type": "dynamic",
    "bodyType": "virtual_character",
    "bodyParams": {
        ...
    }
  }
}
&lt;/code&gt;
    &lt;p&gt;During the level loading process, if the node doesn’t have a corresponding prefab, it’s loaded as-is and its mesh data is taken from the glTF file itself (this is mostly used for static geometry). If the node has a corresponding prefab loaded, it’s created instead. Its mesh data is loaded from the external glTF file - only transform is copied from the original glTF node (the one in the level glTF file).&lt;/p&gt;
    &lt;quote&gt;Once glTFX is released and the support for it is added to Blender, things might be even easier to handle as you’ll be able to reference external glTF files with it.&lt;/quote&gt;
    &lt;head rend="h3"&gt;MSAA&lt;/head&gt;
    &lt;p&gt;Using forward rendering allowed me to easily implement MSAA. Here’s a comparison of how the game looks without AA and with MSAA on:&lt;/p&gt;
    &lt;p&gt;MSAA is explained well here: https://vulkan-tutorial.com/Multisampling&lt;/p&gt;
    &lt;p&gt;Here’s another good article about MSAA: https://therealmjp.github.io/posts/msaa-overview/ and potential problems you can have with it (especially with HDR and tone-mapping).&lt;/p&gt;
    &lt;head rend="h3"&gt;UI&lt;/head&gt;
    &lt;p&gt;My UI system was inspired by Roblox’s UI API: https://create.roblox.com/docs/ui&lt;/p&gt;
    &lt;p&gt;Basically, the UI can calculate its own layout without me having to hard code each individual element’s size and position. Basically it relies on the following concepts:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Origin is an anchor around which the UI element is positioned. If origin is &lt;code&gt;(0, 0)&lt;/code&gt;, setting UI element’s position to be&lt;code&gt;(x,y)&lt;/code&gt;will make its upper-left pixel have (x,y) pixel coordinate. If the origin is&lt;code&gt;(1, 1)&lt;/code&gt;, then the element’s bottom-right corner will be positioned at&lt;code&gt;(x, y)&lt;/code&gt;. If the origin is (0.5, 1) then it will be positioned using bottom-center point as the reference.&lt;/item&gt;
      &lt;item&gt;Relative size makes the children’s be proportional to parent’s size. If (1,1) then the child element will have the same size as the parent element. If it’s (0.5, 0.5) then it’ll have half the size of the parent. If the parent uses children’s size as a guide, then if a child has (0.5, 0.25) relative size, the parent’s width will be 2x larger and the height will be 4x larger.&lt;/item&gt;
      &lt;item&gt;Relative position uses parent’s size as a guide for positioning. It’s useful for centering elements, for example if you have an element with (0.5, 0.5) origin and (0.5, 0.5) relative position, it’ll be centered inside its parent element.&lt;/item&gt;
      &lt;item&gt;You can also set pixel offsets for both position and size separately (they’re called &lt;code&gt;offsetPosition&lt;/code&gt;and&lt;code&gt;offsetSize&lt;/code&gt;in my codebase).&lt;/item&gt;
      &lt;item&gt;You can also set a fixed size for the elements if you don’t want them to ever be resized.&lt;/item&gt;
      &lt;item&gt;The label/image element size is determined using its content.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here are some examples of how it can be used to position child elements:&lt;/p&gt;
    &lt;p&gt;a) The child (yellow) has relative size (0.5, 1), relative position of (0.5, 0.5) and origin (0.5, 0.5) (alternatively, the relative position can be (0.5, 0.0) and origin at (0.5, 0.0) in this case). Its parent (green) will be two times wider, but will have the same height. The child element will be centered inside the parent.&lt;/p&gt;
    &lt;p&gt;b) The child (yellow) has origin (1, 1), fixed size (w,h) and absolute offset of (x,y) - this way, the item can be positioned relative to the bottom-right corner of its parent (green)&lt;/p&gt;
    &lt;p&gt;Let’s see how sizes and positions of UI elements are calculated (implementation in EDBR).&lt;/p&gt;
    &lt;p&gt;First, sizes of all elements are calculated recursively. Then positions are computed based on the previously computed sizes and specified offset positions. Afterwards all elements are drawn recursively - parent element first, then its children etc.&lt;/p&gt;
    &lt;p&gt;When calculating the size, most elements either have a “fixed” size (which you can set manually, e.g. you can set some button to always be 60x60 pixels) or their size is computed based on their content. For example, for label elements, their size is computed using the text’s bounding box. For image elements, their size equals the image size and so on.&lt;/p&gt;
    &lt;p&gt;If an element has an “Auto-size” property, it needs to specify which child will be used to calculate its size. For example, the menu nine-slice can have several text labels inside the “vertical layout” element - the bounding boxes will be calculated first, then their sizes will be summed up - then, the parent’s size is calculated.&lt;/p&gt;
    &lt;p&gt;Let’s take a look at a simple menu with bounding boxes displayed:&lt;/p&gt;
    &lt;p&gt;Here, root &lt;code&gt;NineSliceElement&lt;/code&gt; is marked as “Auto-size”. To compute its size, it first computes the size of its child (&lt;code&gt;ListLayoutElement&lt;/code&gt;). This recursively computes the sizes of each button, sums them up and adds some padding (&lt;code&gt;ListLayoutElement&lt;/code&gt; also makes the width of each button the same based on the maximum width in the list).&lt;/p&gt;
    &lt;head rend="h3"&gt;Dear ImGui and sRGB issues&lt;/head&gt;
    &lt;p&gt;I love Dear ImGui. I used it to implement many useful dev and debug tools (open the image in a new tab to see them better):&lt;/p&gt;
    &lt;p&gt;It has some problems with sRGB, though. I won’t explain it in detail, but basically if you use sRGB framebuffer, Dear ImGui will look wrong in many ways, see the comparison:&lt;/p&gt;
    &lt;p&gt;Sometimes you can see people doing hacks by doing &lt;code&gt;pow(col, vec4(2.2))&lt;/code&gt; with Dear ImGui’s colors but it still doesn’t work properly with alpha and produces incorrect color pickers.&lt;/p&gt;
    &lt;p&gt;I ended up writing my own Dear ImGui backend and implementing DilligentEngine’s workaround which is explained in detail here and here.&lt;/p&gt;
    &lt;quote&gt;Writing it wasn’t as hard as I expected. I only need to write the rendering part, while “logic/OS interaction” part (input event processing, clipboard etc.) is still handled by default Dear ImGui SDL backend in my case.&lt;/quote&gt;
    &lt;p&gt;There are some additional benefits of having my own backend:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;It supports bindless texture ids, so I can draw images by simply calling &lt;code&gt;ImGui::Image(bindlessTextureId, ...)&lt;/code&gt;. Dear ImGui’s Vulkan backend requires you to “register” textures by calling&lt;code&gt;ImGui_ImplVulkan_AddTexture&lt;/code&gt;for each texture before you can call&lt;code&gt;ImGui::Image&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;It can properly draw linear and non-linear images by passing their format into backend (so that sRGB images are not gamma corrected twice when they’re displayed)&lt;/item&gt;
      &lt;item&gt;Initializing and dealing with it is easier as it does Vulkan things in the same way as the rest of my engine.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Other stuff&lt;/head&gt;
    &lt;p&gt;There are many parts of the engine not covered there because they’re not related to Vulkan. I still feel like it’s good to mention them briefly for the sake of completion.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I use Jolt Physics for physics.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Integrating it into the engine was pretty easy. Right now I mostly use it for collision resolution and basic character movement.&lt;/p&gt;
    &lt;p&gt;The samples are fantastic. The docs are very good too.&lt;/p&gt;
    &lt;p&gt;I especially want to point out how incredible &lt;code&gt;JPH::CharacterVirtual&lt;/code&gt; is. It handles basic character movement so well. I remember spending days trying to get proper slope movement in Bullet to work. With Jolt, it just worked “out of the box”.&lt;/p&gt;
    &lt;p&gt;Here’s how it basically works (explaining how it works properly would probably require me to write quite a big article):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You add your shapes to Jolt’s world.&lt;/item&gt;
      &lt;item&gt;You run the simulation.&lt;/item&gt;
      &lt;item&gt;You get new positions of your physics objects and use these positions to render objects in their current positions.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I use entt for the entity-component-system part.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It has worked great for me so far. Previously I had my own ECS implementation, but decided to experiment with a 3rd party ECS library to have less code to maintain.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I use openal-soft, libogg and libvorbis for audio.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The audio system is mostly based on these articles: https://indiegamedev.net/2020/02/15/the-complete-guide-to-openal-with-c-part-1-playing-a-sound/&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I use Tracy for profiling.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Integrating it was very easy (read the PDF doc, it’s fantastic!) and it helped me avoid tons of bike-shedding by seeing how little time something, which I thought was “inefficient”, really took.&lt;/p&gt;
    &lt;head rend="h2"&gt;What I gained from switching to Vulkan&lt;/head&gt;
    &lt;p&gt;There are many nice things I got after switching to Vulkan:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;No more global state&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This makes abstractions a lot easier. With OpenGL abstractions/engines, you frequently see “shader.bind()” calls, state trackers, magic RAII, which automatically binds/unbinds objects and so on. There’s no need for that in Vulkan - it’s easy to write functions which take some objects as an input and produce some output - stateless, more explicit and easier to reason about.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;API is more pleasant to work with overall - I didn’t like “binding” things and the whole “global state machine” of OpenGL.&lt;/item&gt;
      &lt;item&gt;You need to write less abstractions overall.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With OpenGL, you need to write a lot of abstractions to make it all less error-prone… Vulkan’s API requires a lot less of this, in my experience. And usually the abstractions that you write map closer to Vulkan’s “raw” functions, compared to OpenGL abstractions which hide manipulation of global state and usually call several functions (and might do some stateful things for optimization).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Better validation errors&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Validation errors are very good in Vulkan. While OpenGL has &lt;code&gt;glDebugMessageCallback&lt;/code&gt;, it doesn’t catch that many issues and you’re left wondering why your texture looks weird, why your lighting is broken and so on. Vulkan has more extensive validation which makes the debugging process much better.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Debugging in RenderDoc&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I can now debug shaders in RenderDoc. It looks like this:&lt;/p&gt;
    &lt;p&gt;With OpenGL I had to output the values to some texture and color-pick them… which took a lot of time. But now I can debug vertex and fragment shaders easily.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;More consistent experience across different GPUs and OSes.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With OpenGL, drivers on different GPUs and OSes worked differently from each other which made some bugs pop up only on certain hardware configurations. It made the process of debugging them hard. I still experienced some slight differences between different GPUs in Vulkan, but it’s much less prevalent compared to OpenGL.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Ability to use better shading languages in the future&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;GLSL is a fine shading language, but there are some new shading languages which promise to be more feature-complete, convenient and readable, for example:&lt;/p&gt;
    &lt;p&gt;I might explore them in the future and see if they offer me something that GLSL lacks.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;More control over every aspect of the graphics pipeline.&lt;/item&gt;
      &lt;item&gt;Second system effect, but good&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;My first OpenGL engine was written during the process of learning graphics programming from scratch. Many abstractions were not that good and rewriting them with some graphics programming knowledge (and some help from vkguide) helped me implement a much cleaner system.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Street cred&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And finally, it makes me proud to be able to say “I have a custom engine written in Vulkan and it works”. Sometimes people start thinking about you as a coding wizard and it makes me happy and proud of my work. :)&lt;/p&gt;
    &lt;head rend="h2"&gt;Future work&lt;/head&gt;
    &lt;p&gt;There are many things that I plan to do in the future, here’s a list of some of them:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Sign-distance field font support (good article about implementing them)&lt;/item&gt;
      &lt;item&gt;Loading many images and generating mipmaps in parallel (or use image formats which already have mipmaps stored inside of them)&lt;/item&gt;
      &lt;item&gt;Bloom.&lt;/item&gt;
      &lt;item&gt;Volumetric fog.&lt;/item&gt;
      &lt;item&gt;Animation blending.&lt;/item&gt;
      &lt;item&gt;Render graphs.&lt;/item&gt;
      &lt;item&gt;Ambient occlusion.&lt;/item&gt;
      &lt;item&gt;Finishing the game? (hopefully…)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Overall, I’m quite satisfied with what I managed to accomplish. Learning Vulkan was quite difficult, but it wasn’t as hard as I imagined. It taught me a lot about graphics programming and modern APIs and now I have a strong foundation to build my games with.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46010329</guid><pubDate>Fri, 21 Nov 2025 23:28:40 +0000</pubDate></item><item><title>Sharper MRI scans may be on horizon thanks to new physics-based model</title><link>https://news.rice.edu/news/2025/sharper-mri-scans-may-be-horizon-thanks-new-physics-based-model</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46010806</guid><pubDate>Sat, 22 Nov 2025 00:30:26 +0000</pubDate></item><item><title>Moss Survives 9 Months in Space Vacuum</title><link>https://scienceclock.com/moss-survives-9-months-in-space-vacuum/</link><description>&lt;doc fingerprint="3f88d37b68b59460"&gt;
  &lt;main&gt;
    &lt;p&gt;Mosses are already known for coping with harsh radiation, dehydration, and long freezes. Now scientists have pushed them even further by exposing their spore capsules to open space for nine months, and most of them survived.&lt;/p&gt;
    &lt;p&gt;The team worked with spreading earthmoss (Physcomitrium patens), a small moss species used widely as a plant model by researchers. Its spore-containing capsules were mounted on the outside of the International Space Station (ISS), where they experienced direct solar radiation, vacuum conditions, and sharp temperature swings during each orbit.&lt;/p&gt;
    &lt;p&gt;Under those conditions, cells usually break down quickly. So the researchers were surprised by what came back. “We expected almost zero survival, but the result was the opposite,” says Hokkaido University biologist Tomomichi Fujita. More than 80 percent of the spores still germinated once they returned to Earth.&lt;/p&gt;
    &lt;p&gt;Also Read: Microbe That Could Turn Martian Dust into Oxygen&lt;/p&gt;
    &lt;p&gt;The team detected a small drop in chlorophyll a, but the other pigments remained stable. The spores grew normally in follow-up tests, showing no signs of major stress from their time in orbit.&lt;/p&gt;
    &lt;p&gt;This kind of toughness fits with the evolutionary history of mosses. Bryophytes — the group that includes mosses, liverworts, and hornworts — were among the first plants to move from water onto land about 500 million years ago. Their spores had to withstand drying and direct sunlight long before soils existed, which may explain why their protective structures still hold up so well today.&lt;/p&gt;
    &lt;p&gt;The results place moss spores alongside the few organisms known to tolerate direct space exposure, including tardigrades and certain microbes. Their survival also adds to ongoing discussions about what types of life might endure extreme environments beyond Earth.&lt;/p&gt;
    &lt;p&gt;According to the researchers, this durability could matter for future experiments on the Moon or Mars. Mosses need very little soil and can pull nutrients directly from rock, making them candidates for early ecosystem tests in extraterrestrial settings.&lt;/p&gt;
    &lt;p&gt;“Ultimately, we hope this work opens a new frontier toward constructing ecosystems in extraterrestrial environments such as the Moon and Mars,” says Fujita.&lt;/p&gt;
    &lt;p&gt;The research was published in iScience. Read the study here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46011978</guid><pubDate>Sat, 22 Nov 2025 03:57:29 +0000</pubDate></item><item><title>Original Superman comic becomes the highest-priced comic book ever sold</title><link>https://www.bbc.com/news/articles/c8e9rp0knj6o</link><description>&lt;doc fingerprint="b72b5181609a05bd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Superman copy found in mum's attic is most valuable comic ever at $9.12m&lt;/head&gt;
    &lt;p&gt;While cleaning out their late mother's California loft last Christmas, three brothers made a life-changing discovery under a pile of faded newspapers: one of the first Superman comics ever made.&lt;/p&gt;
    &lt;p&gt;An original copy of the June 1939 first edition on the Man of Steel's adventures, it was in a remarkably pristine condition.&lt;/p&gt;
    &lt;p&gt;Now it has become the highest-priced comic book ever sold, fetching $9.12m (£7m) at auction.&lt;/p&gt;
    &lt;p&gt;Texas-based Heritage Auctions, which hosted Thursday's sale, called it the "pinnacle of comic collecting".&lt;/p&gt;
    &lt;p&gt;The brothers found six comic books, including Superman #1, in the loft underneath a stack of newspapers inside a cardboard box and surrounded by cobwebs in 2024, Heritage said.&lt;/p&gt;
    &lt;p&gt;They waited a few months before contacting the auction house, but once they did, Heritage Auctions vice-president Lon Allen visited them in San Francisco within days, according to the auction house.&lt;/p&gt;
    &lt;p&gt;The brothers, who have chosen to withhold their names, are "in their 50s and 60s, and their mom had always told them she had an expensive comics collection but never showed them", Mr Allen said.&lt;/p&gt;
    &lt;p&gt;"It's a twist on the old 'Mom threw away my comics' story."&lt;/p&gt;
    &lt;p&gt;Their mother had held onto the comic books since she and her brother bought them between the Great Depression and the beginning of World War Two, Heritage said.&lt;/p&gt;
    &lt;p&gt;Mr Allen added that the cool northern California climate was perfect for preserving old paper.&lt;/p&gt;
    &lt;p&gt;"If it had been in an attic here in Texas, it would have been ruined," he said.&lt;/p&gt;
    &lt;p&gt;That helped CGC, a large third-party comics grading service, give this copy of Superman #1 a 9.0 rating on a 10-point scale, topping the previous record of 8.5.&lt;/p&gt;
    &lt;p&gt;And at its sale price of over $9m, including buyer's premium, Superman #1 easily beat the previous highest-priced comic book ever sold by $3m.&lt;/p&gt;
    &lt;p&gt;Action Comics No. 1, the 1938 work that first introduced Superman, sold for $6m last year.&lt;/p&gt;
    &lt;p&gt;The youngest brother said in a press release by the auction house that the box had remained forgotten in the back of attic.&lt;/p&gt;
    &lt;p&gt;"As the years unfolded, life brought about a series of losses and changes," he said. "The demands of everyday survival took centre stage, and the box of comics, once set aside with care and intention, was forgotten. Until last Christmas."&lt;/p&gt;
    &lt;p&gt;He added: "This isn't simply a story about old paper and ink. This was never just about a collectible.&lt;/p&gt;
    &lt;p&gt;"This is a testament to memory, family and the unexpected ways the past finds its way back to us."&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46012328</guid><pubDate>Sat, 22 Nov 2025 05:21:53 +0000</pubDate></item><item><title>Agent design is still hard</title><link>https://lucumr.pocoo.org/2025/11/21/agents-are-hard/</link><description>&lt;doc fingerprint="67169c5569238917"&gt;
  &lt;main&gt;
    &lt;p&gt;written on November 21, 2025&lt;/p&gt;
    &lt;p&gt;I felt like it might be a good time to write about some new things I’ve learned. Most of this is going to be about building agents, with a little bit about using agentic coding tools.&lt;/p&gt;
    &lt;p&gt;TL;DR: Building agents is still messy. SDK abstractions break once you hit real tool use. Caching works better when you manage it yourself, but differs between models. Reinforcement ends up doing more heavy lifting than expected, and failures need strict isolation to avoid derailing the loop. Shared state via a file-system-like layer is an important building block. Output tooling is surprisingly tricky, and model choice still depends on the task.&lt;/p&gt;
    &lt;p&gt;When you build your own agent, you have the choice of targeting an underlying SDK like the OpenAI SDK or the Anthropic SDK, or you can go with a higher level abstraction such as the Vercel AI SDK or Pydantic. The choice we made a while back was to adopt the Vercel AI SDK but only the provider abstractions, and to basically drive the agent loop ourselves. At this point we would not make that choice again. There is absolutely nothing wrong with the Vercel AI SDK, but when you are trying to build an agent, two things happen that we originally didn’t anticipate:&lt;/p&gt;
    &lt;p&gt;The first is that the differences between models are significant enough that you will need to build your own agent abstraction. We have not found any of the solutions from these SDKs that build the right abstraction for an agent. I think this is partly because, despite the basic agent design being just a loop, there are subtle differences based on the tools you provide. These differences affect how easy or hard it is to find the right abstraction (cache control, different requirements for reinforcement, tool prompts, provider-side tools, etc.). Because the right abstraction is not yet clear, using the original SDKs from the dedicated platforms keeps you fully in control. With some of these higher-level SDKs you have to build on top of their existing abstractions, which might not be the ones you actually want in the end.&lt;/p&gt;
    &lt;p&gt;We also found it incredibly challenging to work with the Vercel SDK when it comes to dealing with provider-side tools. The attempted unification of messaging formats doesn’t quite work. For instance, the web search tool from Anthropic routinely destroys the message history with the Vercel SDK, and we haven’t yet fully figured out the cause. Also, in Anthropic’s case, cache management is much easier when targeting their SDK directly instead of the Vercel one. The error messages when you get things wrong are much clearer.&lt;/p&gt;
    &lt;p&gt;This might change, but right now we would probably not use an abstraction when building an agent, at least until things have settled down a bit. The benefits do not yet outweigh the costs for us.&lt;/p&gt;
    &lt;p&gt;Someone else might have figured it out. If you’re reading this and think I’m wrong, please drop me a mail. I want to learn.&lt;/p&gt;
    &lt;p&gt;The different platforms have very different approaches to caching. A lot has been said about this already, but Anthropic makes you pay for caching. It makes you manage cache points explicitly, and this really changes the way you interact with it from an agent engineering level. I initially found the manual management pretty dumb. Why doesn’t the platform do this for me? But I’ve fully come around and now vastly prefer explicit cache management. It makes costs and cache utilization much more predictable.&lt;/p&gt;
    &lt;p&gt;Explicit caching allows you to do certain things that are much harder otherwise. For instance, you can split off a conversation and have it run in two different directions simultaneously. You also have the opportunity to do context editing. The optimal strategy here is unclear, but you clearly have a lot more control, and I really like having that control. It also makes it much easier to understand the cost of the underlying agent. You can assume much more about how well your cache will be utilized, whereas with other platforms we found it to be hit and miss.&lt;/p&gt;
    &lt;p&gt;The way we do caching in the agent with Anthropic is pretty straightforward. One cache point is after the system prompt. Two cache points are placed at the beginning of the conversation, where the last one moves up with the tail of the conversation. And then there is some optimization along the way that you can do.&lt;/p&gt;
    &lt;p&gt;Because the system prompt and the tool selection now have to be mostly static, we feed a dynamic message later to provide information such as the current time. Otherwise, this would trash the cache. We also leverage reinforcement during the loop much more.&lt;/p&gt;
    &lt;p&gt;Every time the agent runs a tool you have the opportunity to not just return data that the tool produces, but also to feed more information back into the loop. For instance, you can remind the agent about the overall objective and the status of individual tasks. You can also provide hints about how the tool call might succeed when a tool fails. Another use of reinforcement is to inform the system about state changes that happened in the background. If you have an agent that uses parallel processing, you can inject information after every tool call when that state changed and when it is relevant for completing the task.&lt;/p&gt;
    &lt;p&gt;Sometimes it’s enough for the agent to self-reinforce. In Claude Code, for instance, the todo write tool is a self-reinforcement tool. All it does is take from the agent a list of tasks that it thinks it should do and echo out what came in. It’s basically just an echo tool; it really doesn’t do anything else. But that is enough to drive the agent forward better than if the only task and subtask were given at the beginning of the context and too much has happened in the meantime.&lt;/p&gt;
    &lt;p&gt;We also use reinforcements to inform the system if the environment changed during execution in a way that’s problematic for the agent. For instance, if our agent fails and retries from a certain step forward but the recovery operates off broken data, we inject a message informing it that it might want to back off a couple of steps and redo an earlier step.&lt;/p&gt;
    &lt;p&gt;If you expect a lot of failures during code execution, there is an opportunity to hide those failures from the context. This can happen in two ways. One is to run tasks that might require iteration individually. You would run them in a subagent until they succeed and only report back the success, plus maybe a brief summary of approaches that did not work. It is helpful for an agent to learn about what did not work in a subtask because it can then feed that information into the next task to hopefully steer away from those failures.&lt;/p&gt;
    &lt;p&gt;The second option doesn’t exist in all agents or foundation models, but with Anthropic you can do context editing. So far we haven’t had a lot of success with context editing, but we believe it’s an interesting thing we would love to explore more. We would also love to learn if people have success with it. What is interesting about context editing is that you should be able to preserve tokens for further down the iteration loop. You can take out of the context certain failures that didn’t drive towards successful completion of the loop, but only negatively affected certain attempts during execution. But as with the point I made earlier: it is also useful for the agent to understand what didn’t work, but maybe it doesn’t require the full state and full output of all the failures.&lt;/p&gt;
    &lt;p&gt;Unfortunately, context editing will automatically invalidate caches. There is really no way around it. So it can be unclear when the trade-off of doing that compensates for the extra cost of trashing the cache.&lt;/p&gt;
    &lt;p&gt;As I mentioned a couple of times on this blog already, most of our agents are based on code execution and code generation. That really requires a common place for the agent to store data. Our choice is a file system—in our case a virtual file system—but that requires different tools to access it. This is particularly important if you have something like a subagent or subinference.&lt;/p&gt;
    &lt;p&gt;You should try to build an agent that doesn’t have dead ends. A dead end is where a task can only continue executing within the sub-tool that you built. For instance, you might build a tool that generates an image, but is only able to feed that image back into one more tool. That’s a problem because you might then want to put those images into a zip archive using the code execution tool. So there needs to be a system that allows the image generation tool to write the image to the same place where the code execution tool can read it. In essence, that’s a file system.&lt;/p&gt;
    &lt;p&gt;Obviously it has to go the other way around too. You might want to use the code execution tool to unpack a zip archive and then go back to inference to describe all the images so that the next step can go back to code execution and so forth. The file system is the mechanism that we use for that. But it does require tools to be built in a way that they can take file paths to the virtual file system to work with.&lt;/p&gt;
    &lt;p&gt;So basically an &lt;code&gt;ExecuteCode&lt;/code&gt; tool would have access to the same file system as
the &lt;code&gt;RunInference&lt;/code&gt; tool which could take a &lt;code&gt;path&lt;/code&gt; to a file on that same
virtual file system.&lt;/p&gt;
    &lt;p&gt;One interesting thing about how we structured our agent is that it does not represent a chat session. It will eventually communicate something to the user or the outside world, but all the messages that it sends in between are usually not revealed. The question is: how does it create that message? We have one tool which is the output tool. The agent uses it explicitly to communicate to the human. We then use a prompt to instruct it when to use that tool. In our case the output tool sends an email.&lt;/p&gt;
    &lt;p&gt;But that turns out to pose a few other challenges. One is that it’s surprisingly hard to steer the wording and tone of that output tool compared to just using the main agent loop’s text output as the mechanism to talk to the user. I cannot say why this is, but I think it’s probably related to how these models are trained.&lt;/p&gt;
    &lt;p&gt;One attempt that didn’t work well was to have the output tool run another quick LLM like Gemini 2.5 Flash to adjust the tone to our preference. But this increases latency and actually reduces the quality of the output. In part, I think the model just doesn’t word things correctly and the subtool doesn’t have sufficient context. Providing more slices of the main agentic context into the subtool makes it expensive and also didn’t fully solve the problem. It also sometimes reveals information in the final output that we didn’t want to be there, like the steps that led to the end result.&lt;/p&gt;
    &lt;p&gt;Another problem with an output tool is that sometimes it just doesn’t call the tool. One of the ways in which we’re forcing this is we remember if the output tool was called. If the loop ends without the output tool, we inject a reinforcement message to encourage it to use the output tool.&lt;/p&gt;
    &lt;p&gt;Overall our choices for models haven’t dramatically changed so far. I think Haiku and Sonnet are still the best tool callers available, so they make for excellent choices in the agent loop. They are also somewhat transparent with regards to what the RL looks like. The other obvious choices are the Gemini models. We so far haven’t found a ton of success with the GPT family of models for the main loop.&lt;/p&gt;
    &lt;p&gt;For the individual sub-tools, which in part might also require inference, our current choice is Gemini 2.5 if you need to summarize large documents or work with PDFs and things like that. That is also a pretty good model for extracting information from images, in particular because the Sonnet family of models likes to run into a safety filter which can be annoying.&lt;/p&gt;
    &lt;p&gt;There’s also probably the very obvious realization that token cost alone doesn’t really define how expensive an agent. A better tool caller will do the job in fewer tokens. There are some cheaper models available than sonnet today, but they are not necessarily cheaper in a loop.&lt;/p&gt;
    &lt;p&gt;But all things considered, not that much has changed in the last couple of weeks.&lt;/p&gt;
    &lt;p&gt;We find testing and evals to be the hardest problem here. This is not entirely surprising, but the agentic nature makes it even harder. Unlike prompts, you cannot just do the evals in some external system because there’s too much you need to feed into it. This means you want to do evals based on observability data or instrumenting your actual test runs. So far none of the solutions we have tried have convinced us that they found the right approach here. Unfortunately, I have to report that at the moment we haven’t found something that really makes us happy. I hope we’re going to find a solution for this because it is becoming an increasingly frustrating aspect of building an agent.&lt;/p&gt;
    &lt;p&gt;As for my experience with coding agents, not really all that much has changed. The main new development is that I’m trialing Amp more. In case you’re curious why: it’s not that it’s objectively a better agent than what I’m using, but I really quite like the way they’re thinking about agents from what they’re posting. The interactions of the different sub agents like the Oracle with the main loop is beautifully done, and not many other harnesses do this today. It’s also a good way for me to validate how different agent designs work. Amp, similar to Claude Code, really feels like a product built by people who also use their own tool. I do not feel every other agent in the industry does this.&lt;/p&gt;
    &lt;p&gt;That’s just a random assortment of things that I feel might also be worth sharing:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46013935</guid><pubDate>Sat, 22 Nov 2025 11:27:24 +0000</pubDate></item><item><title>'The French people want to save us': help pours in for glassmaker Duralex</title><link>https://www.theguardian.com/world/2025/nov/22/french-people-want-to-save-us-help-pours-glassmaker-duralex</link><description>&lt;doc fingerprint="6bebd9019b121e62"&gt;
  &lt;main&gt;
    &lt;p&gt;Drop a Duralex glass and it will most likely bounce, not break. The French company itself has tumbled several times in the past two decades and always bounced back, but never quite as spectacularly as when, earlier this month, it asked the public for money.&lt;/p&gt;
    &lt;p&gt;An appeal for €5m (£4.4m) of emergency funding to secure the immediate future of the glassworks took just five hours and 40 minutes to reach its target. Within 48 hours, the total amount pledged had topped €19m.&lt;/p&gt;
    &lt;p&gt;François Marciano, 59, the director general of Duralex, said the response had astonished everyone at the company. “We thought it would take five or six weeks to raise the €5m. When it reached nearly €20m we had to say stop. Enough,” he said.&lt;/p&gt;
    &lt;p&gt;As a staff cooperative, €5m is the maximum Duralex can accept in public investment under financial rules.&lt;/p&gt;
    &lt;head rend="h2"&gt;Beloved French brand&lt;/head&gt;
    &lt;p&gt;Mention Duralex to any French person and they will be transported back to childhood and a school canteen. The brand evokes a mix of nostalgia and pride and is a symbol of French patriotism and industrial savoir faire.&lt;/p&gt;
    &lt;p&gt;“We’re like Proust’s madeleines,” Marciano said. “The French people want to save us. They are fed up with factories closing and the country’s industries declining.”&lt;/p&gt;
    &lt;p&gt;At the Duralex factory on an industrial estate in La Chapelle-Saint-Mesmin on the banks of the Loire just outside Orléans, Marciano says he and his colleagues are “floating on a cloud” after the appeal.&lt;/p&gt;
    &lt;p&gt;Eighteen months ago, Marciano oversaw a staff buyout of the company, which had been placed in receivership for the fourth time in 20 years. Today, 180 of the 243 employees are “associates” in the company.&lt;/p&gt;
    &lt;p&gt;Suliman El Moussaoui, 44, a union representative at the factory where he has worked for 18 years, said the appeal had prompted “a tsunami of orders, so many that we’re struggling to keep up. Every time the company is mentioned on the television or radio we have more orders. It’s been amazing.”&lt;/p&gt;
    &lt;p&gt;Inside the factory, a simple but magical alchemy takes place. A mix of sand, soda ash and limestone, the exact proportions of which are a closely guarded secret, is heated in a vast overhead oven to 1,400C. Glowing globs of molten glass drop into iron casts that are blasted with a flame of gas. The red-hot glass is instantly pounded into shape, sprung from the mould, snatched by metal pincers and placed on a conveyor belt.&lt;/p&gt;
    &lt;p&gt;The process has changed little since Duralex – which is said to take its name from the Latin expression Dura lex, sed lex, meaning “the law is harsh, but it is the law” – opened in 1945. When the Guardian visited, the production line was turning out small clear glasses in the Provence range.&lt;/p&gt;
    &lt;p&gt;A worker brandishing tongs lifted a glass to the light to inspect it for faults. During a production run, more than a dozen samples of whatever is being made – glasses, plates, bowls – will be randomly removed and subjected to stress tests. In the quality control room, they will be heated to 150C then plunged into cold water to see if they resist a thermic shock, and dropped from the height of a kitchen counter on to a metal sheet to see if they shatter. They will be tested for stackability and then weighed and the glass thickness measured. If they pass, they are thrown in a bin and the production line is given a thumbs up. If they fail, everything stops and the machines are recalibrated.&lt;/p&gt;
    &lt;head rend="h2"&gt;‘The ultimate drinking vessel’&lt;/head&gt;
    &lt;p&gt;It is not known who invented the company’s trademark Picardie glass, the tumbler used in school canteens with a thick curved rim and semi-fluted shape that first appeared in 1954. The British design guru Patrick Taylor has ranked the Picardie alongside Levi’s jeans and the Swiss Army knife as an icon of modern design. Taylor describes it as: “An object whose form gives the impression it was discovered rather than designed. It is the ultimate drinking vessel created by man, and of its type cannot be improved.”&lt;/p&gt;
    &lt;p&gt;Duralex says its glass is microwave, freezer and dishwasher-safe and will not turn cloudy or lose its colour, which is in the glass rather than on it. When they do break, Duralex glasses shatter into small pieces rather than shards, reducing the injury risk.&lt;/p&gt;
    &lt;p&gt;Joël Cardon, 59, who has worked at the factory for 35 years, said the soaring cost of gas and electricity were the firm’s largest and most worrying expense.&lt;/p&gt;
    &lt;p&gt;On his screen, the oven containing the liquid glass showed a temperature of 1,440C. It can never be allowed to cool or the glass will solidify. Another screen showed the factory was using 360 cubic metres of gas an hour. According to the regulator Ofgem, the average UK house uses 97.3 cubic metres of gas a year.&lt;/p&gt;
    &lt;p&gt;Last weekend, potential investors were asked to come good on their promises on a first come, first served basis. They will be issued with securities that pay 8% interest over seven years but give no company voting rights. The maximum investment was set at €1,000.&lt;/p&gt;
    &lt;p&gt;“We want to involve as many people as possible but with almost €20m in pledges obviously some people will be disappointed,” Marciano said.&lt;/p&gt;
    &lt;p&gt;Since the company became a staff cooperative, turnover has increased by 22% and Marciano said he hoped Duralex would be breaking even by 2027.&lt;/p&gt;
    &lt;p&gt;The €5m raised will be used to modernise the factory and develop new products. These include a partnership with the Élysée presidential palace shop to sell a set of three of its Gigogne glasses in red, white and blue, marked RF for République Française.&lt;/p&gt;
    &lt;p&gt;Duralex plans to commission moulds to make “pint” glasses with a measure line for British pubs and bars and the US, both regions identified by the company as untapped markets.&lt;/p&gt;
    &lt;p&gt;“Selling abroad is more difficult because there isn’t the same nostalgia for Duralex as there is in France,” said Vincent Vallin, the head of strategy and development. “Interest in the company is high and this is positive, but now we have to focus on increasing sales.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46015379</guid><pubDate>Sat, 22 Nov 2025 15:14:45 +0000</pubDate></item><item><title>New Apple Study Shows LLMs Can Tell What You're Doing from Audio and Motion Data</title><link>https://9to5mac.com/2025/11/21/apple-research-llm-study-audio-motion-activity/</link><description>&lt;doc fingerprint="3404c5bfb12cd2c7"&gt;
  &lt;main&gt;
    &lt;p&gt;Apple researchers have published a study that looks into how LLMs can analyze audio and motion data to get a better overview of the user’s activities. Here are the details.&lt;/p&gt;
    &lt;head rend="h2"&gt;They’re good at it, but not in a creepy way&lt;/head&gt;
    &lt;p&gt;A new paper titled “Using LLMs for Late Multimodal Sensor Fusion for Activity Recognition” offers insight into how Apple may be considering incorporating LLM analysis alongside traditional sensor data to gain a more precise understanding of user activity.&lt;/p&gt;
    &lt;p&gt;This, they argue, has great potential to make activity analysis more precise, even in situations where there isn’t enough sensor data.&lt;/p&gt;
    &lt;p&gt;From the researchers:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Sensor data streams provide valuable information around activities and context for downstream applications, though integrating complementary information can be challenging. We show that large language models (LLMs) can be used for late fusion for activity classification from audio and motion time series data. We curated a subset of data for diverse activity recognition across contexts (e.g., household activities, sports) from the Ego4D dataset. Evaluated LLMs achieved 12-class zero- and one-shot classification F1-scores significantly above chance, with no task-specific training. Zero-shot classification via LLM-based fusion from modality-specific models can enable multimodal temporal applications where there is limited aligned training data for learning a shared embedding space. Additionally, LLM-based fusion can enable model deploying without requiring additional memory and computation for targeted application-specific multimodal models.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In other words, LLMs are actually pretty good at inferring what a user is doing from basic audio and motion signals, even when they’re not specifically trained for that. Moreover, when given just a single example, their accuracy improves even further.&lt;/p&gt;
    &lt;p&gt;One important distinction is that in this study, the LLM wasn’t fed the actual audio recording, but rather, short text descriptions generated by audio models and an IMU-based motion model (which tracks movement through accelerometer and gyroscope data), as shown below:&lt;/p&gt;
    &lt;head rend="h2"&gt;Diving a bit deeper&lt;/head&gt;
    &lt;p&gt;In the paper, the researchers explain that they used Ego4D, a massive dataset of media shot in first-person perspective. The data contains thousands of hours of real-world environments and situations, from household tasks to outdoor activities.&lt;/p&gt;
    &lt;p&gt;From the study:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“We curated a dataset of day-to-day activities from the Ego4D dataset by searching for activities of daily living within the provided narrative descriptions. The curated dataset includes 20 second samples from twelve high-level activities: vacuum cleaning, cooking, doing laundry, eating, playing basketball, playing soccer, playing with pets, reading a book, using a computer, washing dishes, watching TV, workout/weightlifting. These activities were selected to span a range of household and fitness tasks, and based on their prevalence in the larger dataset.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The researchers ran the audio and motion data through smaller models that generated text captions and class predictions, then fed those outputs into different LLMs (Gemini-2.5-pro and Qwen-32B) to see how well they could identify the activity.&lt;/p&gt;
    &lt;p&gt;Then, Apple compared the performance of these models in two different situations: one in which they were given the list of the 12 possible activities to choose from (closed-set), and another where they weren’t given any options (open-ended).&lt;/p&gt;
    &lt;p&gt;For each test, they were given different combinations of audio captions, audio labels, IMU activity prediction data, and extra context, and this is how they did:&lt;/p&gt;
    &lt;p&gt;In the end, the researchers note that the results of this study offer interesting insights into how combining multiple models can benefit activity and health data, especially in cases where raw sensor data alone is insufficient to provide a clear picture of the user’s activity.&lt;/p&gt;
    &lt;p&gt;Perhaps more importantly, Apple published supplemental materials alongside the study, including the Ego4D segment IDs, timestamps, prompts, and one-shot examples used in the experiments, to assist researchers interested in reproducing the results.&lt;/p&gt;
    &lt;head rend="h4"&gt;Accessory deals on Amazon&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Wireless CarPlay adapter&lt;/item&gt;
      &lt;item&gt;Logitech MX Master 4&lt;/item&gt;
      &lt;item&gt;Apple AirTag 4 Pack&lt;/item&gt;
      &lt;item&gt;AirPods Pro 3&lt;/item&gt;
      &lt;item&gt;Beats USB-C to USB-C Woven Short Cable&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;FTC: We use income earning auto affiliate links. More.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46015578</guid><pubDate>Sat, 22 Nov 2025 15:45:26 +0000</pubDate></item><item><title>The Uncertain Origins of Aspirin</title><link>https://press.asimov.com/articles/aspirin</link><description>&lt;doc fingerprint="be8150d52a335197"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Uncertain Origins of Aspirin&lt;/head&gt;
    &lt;p&gt;â&lt;/p&gt;
    &lt;quote&gt;On a cool starlit night in ancient Egypt, a wife brews willow-bark tea for her husband, hot with fever;&lt;lb/&gt;While Athens and Sparta wage war, Hippocrates hurries to the river to shave some more willow bark, intending to cool down another sick child brought to his door;&lt;lb/&gt;While George III marries Princess Charlotte, a son dashes off into the woods in search of willow bark to treat his motherâs worsening fever.&lt;/quote&gt;
    &lt;p&gt;While these anecdotes are familiar from cinema and literature, the history of aspirin and the willow bark from which it is (supposedly) derived is far from clear.&lt;/p&gt;
    &lt;p&gt;For instance, it is often said that Hippocrates prescribed willow bark tea to treat inflammatory pain. In a perfect world, we would know this because a verified scroll from around 400 BC would exist, stating: âFor inflammation, I recommend willow bark tea, and so does everyone I know. So sayeth Hippocrates of Kos, future father of medicine and writer of the eponymous oath.â&lt;/p&gt;
    &lt;p&gt;Of course, such primary material does not always come to light. And many who recount medical and scientific histories (or, indeed, any history at all) do so despite incomplete information. In these cases, however, itâs still important to cite what evidence there is: what, for example, has led so many people to believe Hippocrates prescribed willow bark tea for inflammatory pain? If the answer is âsomeone said so,â who was that someone, and why did they think it was true?&lt;/p&gt;
    &lt;p&gt;This history of one of the worldâs most widely consumed classes of drugs demonstrates the difficulties that surround the fact-finding of its origins. Some of these difficulties are historic, such as bad record keeping or obscure translations, and some are of continued relevance, such as political upheaval or the prejudice that often interferes with science.&lt;/p&gt;
    &lt;p&gt;My goal is not only to tell the story of a pharmaceutical staple but to share what my decades-long work in evidence synthesis in epidemiology has taught me about researching scientific history. In doing so, Iâll differentiate claims that are known from original evidence â such as the writings of Hippocrates and Pliny the Elder or original journal articles â from those made without primary support. I have sourced as much of the latter as possible, but both conflicting and unsupported claims remain, which Iâll note.&lt;/p&gt;
    &lt;p&gt;The origins of aspirin make a good subject for exposing the challenges of scientific research for a couple of reasons. Firstly, the stories stretch back millennia, and secondly, aspirin is such a successful drug that there is ample material to work with. Aspirin and other non-steroidal anti-inflammatory drugs (NSAIDs)1 are among the most widely prescribed drugs worldwide,2 are safe enough that many are available without a prescription, and are some of the cheapest available drugs of any class. Itâs often claimed that 30 million people take NSAIDs worldwide every day, although this assertion originally dates back to 1987 and wasnât referenced. Nonetheless, if it were true, we would expect that number to be substantially higher now, given the increase in global population.&lt;/p&gt;
    &lt;p&gt;But before we can contend with the popularity of NSAIDs, we must first look at their origins.&lt;/p&gt;
    &lt;p&gt;{{signup}}&lt;/p&gt;
    &lt;head rend="h2"&gt;Ancient History: Antiquity to 1763 AD&lt;/head&gt;
    &lt;p&gt;When I was in medical school in 2007, I learned that willow bark tea has been used for thousands of years to treat pain and fever. Iâve read at least a handful of books â historical and fantasy alike â that make the same claim. The fifth Bridgerton book, To Sir Philip, With Love, includes a scene with an urgent search for willow bark to bring down a characterâs fever. Diarmuid Jeffreys wrote an entire book on aspirin, The Remarkable Story of a Wonder Drug, which detailed how willow was used from Ancient Egypt, through Ancient Greece and Rome, to the Middle Ages in Europe, and beyond. This is repeated by journal articles, though their claims are rarely referenced.&lt;/p&gt;
    &lt;p&gt;Even if their sources are sketchy, these accounts seem plausible. Willow trees are relatively common, grow worldwide (though mostly in colder and wetter parts of the Northern Hemisphere), and have had various uses since antiquity. For example, a willow fishing net was found in Finland dating from 8,300 BC, and willow has also been used for wattle fences, wattle and daub houses, coracles, cricket bats, and even World War II parachute baskets.&lt;/p&gt;
    &lt;p&gt;However, the most plausible reason that willow bark could be the antecedent of aspirin is that it contains salicin (named for the genus of willow trees, Salix). Salicin is converted into salicylic acid in the body when an enzyme bisects salicin, one half of which is then oxidized to become salicylic acid. Acetylsalicylic acid, known today as aspirin, is also converted into salicylic acid in the body: an enzyme simply cuts off the acetyl group to give salicylic acid. Salicylic acid is likely the active compound that blocks the enzyme cyclooxygenase, giving aspirin its efficacy, and was used as a treatment for fever and gout before aspirin was developed.&lt;/p&gt;
    &lt;p&gt;It seems reasonable, therefore, to believe that willow bark tea could act like aspirin, reducing fever, inflammation, and pain. Willow grew in abundance across the world, and people have been using it for thousands of years. Additionally, myrtle and poplar trees, as well as meadowsweet, likewise contain salicin and could have been used for the same purpose.&lt;/p&gt;
    &lt;p&gt;However, there is a problem with the claim that willow bark and similar plants are the ancient equivalent of aspirin when brewed as tea or simply chewed. And it is this: most of the extant evidence referenced by histories of aspirin fail entirely to mention using willow bark or similar plants to reduce fever, pain, or inflammation.Â&lt;/p&gt;
    &lt;p&gt;When people talk about evidence of the ancients brewing or chewing willow and similar plants, they often invoke the Ebers papyrus, Hippocrates, Celsus, Pliny the Elder, and Pedanius Dioscorides.3&lt;/p&gt;
    &lt;p&gt;The Ebers papyrus is an ancient Egyptian medical scroll from about 1550 BC, though it may have been copied from earlier texts. Translated by German Egyptologist Georg Ebers in 1875, the papyrus has 110 pages, is 20 meters long, and includes 700 remedies for various afflictions. As a piece of history, itâs fantastic. And some of the remedies are still practiced today: the treatment for Guinea-worm disease was, and still is, to wrap the emerging end of the worm around a stick and slowly pull it out.4&lt;/p&gt;
    &lt;p&gt;When I searched through a translation of the papyrus, however, I saw no evidence of willow bark used similarly to aspirin. I did find a treatment for an âear-that-discharges-foul-smelling-matterâ that used âberry-of-the-willowâ and a remedy to âput the Heart into proper working order and make it take up nourishmentâ that used âWillow-tree, one-eighth part, added as a stiffening.â&lt;/p&gt;
    &lt;p&gt;There was also a remedy to make the âmetâ supple (nerves or possibly blood vessels, Egyptologists appear uncertain) that used âsplinters-of-the-willow-tree,â although this particular remedy also required âhogâs dungâ and âmyrrhâ among 34 other ingredients. Still, there was nothing about using willow bark specifically concerning pain, inflammation, or fever.&lt;/p&gt;
    &lt;p&gt;In his 1992 book Murder, Magic, and Medicine, author John Mann wrote that the Ebers papyrus contains the following remedy: âWhen you examine a man with an irregular wound â¦ and that wound is inflamed â¦ [there is] a concentration of heat; the lips of that wound are reddened and that man is hot in consequence â¦ then you must make cooling substances for him to draw the heat out â¦ [from the] leaves of the willow,â but Iâve been unable to find this in any translation of the papyrus, and Mann doesnât reference the translation he claims to be using.&lt;/p&gt;
    &lt;p&gt;Uncertainty about the role of willow bark in treating inflammation remains as we move to Hippocrates, the ancient Greek physician and philosopher often regarded as the father of (clinical) medicine.5 Pharmacology lecturer Philippa Martyr suggests the works ascribed to Hippocrates only reference willow once, specifically in the context of burning willow leaves to make smoke for fumigating the uterus to get rid of a miscarried pregnancy. Indeed, a French translation of Hippocratesâs complete works confirms this. I was, however, unable to find any reference to willow in other translations. It is also said that Hippocrates recommended chewing willow bark to relieve fever and pain, but this, too, lacked evidence.&lt;/p&gt;
    &lt;p&gt;Other ancient sources are similarly unclear. The Roman encyclopedist Celsus, who wrote De Medicina in the first century, suggested willow leaves boiled in vinegar could be used to treat ulcerations of the anus and prolapse of the anus and uterus (Iâm not sure whether that would work, and it certainly isnât a common use of aspirin today).&lt;/p&gt;
    &lt;p&gt;Pliny the Elder, a first-century Roman author and natural philosopher, expounds the uses of poplar and willow trees in his encyclopedia Natural History. For poplar trees, he suggests, âA potion prepared from the bark is good for sciatica,â and âThe leaves, boiled in vinegar, are applied topically for gout.â And for willow: âThe leaves, too, boiled and beaten up with wax, are employed as a liniment for â¦Â gout.â This treatment is echoed by Pedanius Dioscorides, a Greek physician in the Roman army, also writing in the first century, who describes a similar treatment in his pharmacopeia, De materia medica. This is the earliest reference I have found to using salicin-containing plants as weâd potentially use aspirin today.&lt;/p&gt;
    &lt;p&gt;So ultimately, while we have a smattering of evidence that some version of a poplar bark potion may have been used for sciatica and that poplar and willow leaves may have been used for gout, we arrive at our second problem with the claim that willow bark and similar plants are the ancient equivalent of aspirin â that of effectiveness.&lt;/p&gt;
    &lt;p&gt;The amount of salicin in plants, even willow bark, is negligible compared to the aspirin dosages that we deem effective today. When researchers gave people willow bark extract corresponding to 240 mg of salicin, then looked at how much salicylic acid was present in their blood over time, it was the equivalent of taking 87 mg of aspirin (300 mg to 600 mg is recommended per dose, with up to 3600 mg allowed per day). Notably, 240 mg of salicin is the recommended daily dose specified by the European Scientific Cooperative on Phytotherapy.&lt;/p&gt;
    &lt;p&gt;But 240 mg of salicin today comes from concentrated and standardized willow bark extracts, not raw bark or leaves. The actual salicin concentration in willow bark is wildly variable, ranging between 0.04 percent and 12.06 percent across different species, according to one study. Salicin concentrations also vary across plants seasonally and based on a treeâs age. Only a fraction of the salicin would remain in tea or chewed bark.&lt;/p&gt;
    &lt;p&gt;If, for example, each cup of tea provided 240 mg salicin (possible with a good steeping and a high salicin content in the bark), then one would need to drink 41 cups of tea to get a full, therapeutic aspirin dose of 3600 mg. This is about 10 liters or two-and-a-half gallons.&lt;/p&gt;
    &lt;p&gt;Willow bark tea is also notoriously bitter, likely due to the high concentration of tannins, which can cause an upset stomach and nausea. Even if you could push through the bitterness, itâs unlikely youâd be able to stomach the bucketfuls of tea required to get enough salicin from willow bark (or similar plants) to ease your discomfort.&lt;/p&gt;
    &lt;p&gt;Thatâs not to say willow bark and similar plants couldnât be effective in reducing pain, inflammation, and fever when steeped or chewed, however. Unlike aspirin, willow bark contains other compounds â flavonoids and polyphenols â that may contribute to alleviating such symptoms. However, few (if any) human studies have been conducted looking specifically at simply brewing or chewing these plants. While some research has been done on the efficacy of willow bark extract in the treatment of pain and inflammation, the extract is much more concentrated than in chewed bark, and results have varied.&lt;/p&gt;
    &lt;p&gt;Philippa Martyr adds an additional caveat when she notes:&lt;/p&gt;
    &lt;quote&gt;If willow bark and leaves were handy and potent painkillers, we would have used them almost to extinction by now.&lt;/quote&gt;
    &lt;p&gt;Overall, given patchy evidence and dubious efficacy, I am skeptical that the history of aspirin began in antiquity. The mythology of aspirinâs ancient history is, most likely, a coincidence: itâs easy to believe that because willow bark contains salicin, and it was possibly used for some of the same things as aspirin, and it was possibly effective, it must work, and therefore willow bark tea was ancient aspirin. It makes for a plausible story with historical continuity, but I believe it remains just that â a story.&lt;/p&gt;
    &lt;p&gt;For what I believe to be the most credible origins of aspirin and other NSAIDs, we must advance to 18th-century England.&lt;/p&gt;
    &lt;head rend="h2"&gt;Discovery of Aspirin: 1763 to 1877&lt;/head&gt;
    &lt;p&gt;The Reverend Edward Stone appears to have given the first published account of using willow bark extract to treat patients in Chipping Norton, England, in 1763. The patients were suffering from malarial fever (ague),Â which was still endemic to England at the time. He writes:&lt;/p&gt;
    &lt;quote&gt;There is a bark of an Englifh tree, which I have found by experience to be a powerful aftringent, and very efficacious in curing aguifh [agues] and intermitting diforders.&lt;/quote&gt;
    &lt;p&gt;Like many of his predecessors, Reverend Stone believed that the remedy to a malady could be found close to the cause. That is, if people were becoming sick in a certain place, there should be a plant or other remedy nearby.6 As willow trees grew in abundance in âmoist and wet soil where agues chiefly abound,â and because it was as bitter as âPeruvian barkâ (Chichona tree bark, which contains quinine, a traditional remedy for malaria), Reverend Stone thought he could use the dried, powdered bark to treat fevers.7&lt;/p&gt;
    &lt;p&gt;Drying the bark increases its potency, which gets around the issues of having to drink bucketfuls of tea â similar to using willow bark extract today. For three months, Stone dried a pound of bark next to a bakerâs oven before pulverizing it into a powder. He started small, giving his first patient âtwenty grains of powderâ in âwater, tea, small beer and such like,â but quickly increased the dose after noticing no side effects. He treated fifty people over five years, all of whom he said were either cured or helped by the treatment.&lt;/p&gt;
    &lt;p&gt;Notably, Stone had investigated whether his treatment had precedent, but came up empty-handed:&lt;/p&gt;
    &lt;quote&gt;My curiofity prompted me to look into the difpenfatories and books of botany, and examine what they faid concerning it; but there it exifted only by name. I could not find, that it hath, or ever had, any place in pharmacy, or any fuch qualities, as I fufpected afcribed to it by the botanifts.&lt;/quote&gt;
    &lt;p&gt;Stoneâs observation of the novelty of his treatment is corroborated by the medicinal herbalist Anne Stobart, who looked through 6,500 17th-century medicinal recipes for 40 plants with longstanding use in the UK, determining that willow had six or fewer mentions.8 It seems fair to conclude that, at least in the UK in the 17th and 18th centuries, willow was not a well-known treatment for pain, fever, or inflammation. Stone documented his use of it, but it was by no means a widespread curative.&lt;/p&gt;
    &lt;p&gt;Around 1824, about 50 years after Stoneâs investigation of willow bark powder, Italian pharmacist Bartolomeo Rigatelli extracted a âvery bitter antipyreticâ called âsalineâ from a plant native to Europe. The âsalineâ was subsequently renamed âsalicinâ by Francesco Fontana, who also extracted it from white willow and used it as a substitute for quinine sulfate. Fontana reported it was effective against fevers of all types, even âquartan feversâ (one of the four types of malaria). And while Fontana did not reference Rigatelli, he did reference someone named âStone.â While thereâs no way to be certain, it seems likely this was Reverend Stone.&lt;/p&gt;
    &lt;p&gt;The progression from salicin to aspirin would take over 70 years. In 1829, French chemist Henri Leroux refined the process used by Rigatelli, Fontana, and others and managed to extract pure salicin. His method was further refined in 1838 when Raffaele PirÃ¬a, an Italian chemist, produced salicylic acid from salicin, after determining its molecular formula. By 1859, the German chemist Hermann Kolbe used the discovery of salicinâs molecular structure to synthesize salicylic acid directly. Kolbeâs process was refined by his assistant, Rudolf Wilhelm Schmitt, with the resulting process known as the Kolbe-Schmitt Reaction.9&lt;/p&gt;
    &lt;p&gt;In the 1870s, salicylic acid took off as a treatment, and in 1874, Friedrich von Heyden, another student of Kolbe, opened a factory in Radebeul (near Dresden) to produce it, reportedly selling it ten times more cheaply than its naturally derived counterpart. This spurred research into its clinical applications. In 1876, a Scottish physician, Thomas MacLagan, and a German physician, Franz Stricker, both published studies showing that salicin and salicylic acid were effective in treating rheumatic fever, particularly in reducing fever and pain. A year later, in 1877, a French physician, Germain SÃ©e, showed that chronic rheumatism and gout could also be treated with salicylic acid.&lt;/p&gt;
    &lt;p&gt;Salicylic acid had proven effective in reducing pain, fever, and inflammation, and it could be manufactured cheaply and in large quantities. However, it had several serious side effects, such as nausea, gastric irritation, and tinnitus. If a drug manufacturer were able to create a better alternative, patients and doctors would be grateful, and it would likely be extremely successful.&lt;/p&gt;
    &lt;p&gt;With their synthesis of aspirin, chemists at Bayer did exactly that.&lt;/p&gt;
    &lt;head rend="h2"&gt;Aspirin Synthesis Controversy: 1897 to 1949&lt;/head&gt;
    &lt;p&gt;While the events of the 18th and 19th centuries relate to a verifiable history of aspirin, the next period becomes muddied once again. However, here it does not relate to lost or convoluted records, but prejudice.&lt;/p&gt;
    &lt;p&gt;We know the following to be absolutely true: Felix Hoffman, a chemist working for Bayer, synthesized pure acetylsalicylic acid (later known as aspirin) from salicylic acid in 1897. His name is on the U.S. patent for aspirin, and his lab notebook details his synthesis of acetylsalicylic acid. Hoffmanâs method was relatively simple, reliable, and efficient. Hoffman heated a combination of salicylic acid and acetic anhydride (an acetylating agent) for two hours, which resulted in a clear liquid. Upon cooling, this liquid yielded a mass of acetylsalicylic acid crystals, which he separated out and recrystallized, using dry chloroform to remove any remaining impurities.&lt;/p&gt;
    &lt;p&gt;The controversy, then, refers both to why Hoffman synthesized aspirin and what happened afterward.&lt;/p&gt;
    &lt;p&gt;On the one hand, we have the official story from Bayer, which claims that Hoffman created aspirin to help his father, who was suffering from severe rheumatism. Hoffman had treated his father with salicylic acid, but his father had severe side effects, including nausea, gastric irritation, and tinnitus. Hoffman, therefore, set out to produce a purer derivative of salicylic acid that would be as effective. This version of events was first reported in a footnote in a 1934 book on the history of chemical engineering.10&lt;/p&gt;
    &lt;p&gt;On the other hand, we have a story from Arthur EichengrÃ¼n. EichengrÃ¼n was a Jewish chemist who also worked at Bayer. In 1949, he wrote a journal article describing why aspirin was synthesized, and what happened after.11&lt;/p&gt;
    &lt;p&gt;In this article, EichengrÃ¼n stated that he was appointed, in 1895, to establish and manage a pharmaceutical laboratory at Bayer. He also claimed that it was he who instructed Hoffman to synthesize acetylsalicylic acid in 1898 and that Hoffman had done so without knowing why. Notably, EichengrÃ¼n also claimed that several Bayer chemists made various derivatives of salicylic acid, each of which was tested further.&lt;/p&gt;
    &lt;p&gt;Drugs developed in EichengrÃ¼nâs laboratory were tested at Bayerâs pharmacological laboratory, led by Heinrich Dreser.12 When the salicylic acid derivatives were tested, it was clear that acetylsalicylic acid was the most favorable, producing only minor deleterious effects on a frog heart. However, in a Bayer management meeting to discuss whether acetylsalicylic acid should go forward to clinical trials, Dreser asserted that it was a direct cardiac poison and opposed it progressing to trials. Dreser had the right to veto any drug going to clinical trials, so this is where the story of aspirin could have ended.&lt;/p&gt;
    &lt;p&gt;However, in this article, EichengrÃ¼n stated he couldnât accept the decision to stop work on acetylsalicylic acid, and, against his contract, continued to conduct tests privately. He tested the drug on himself, then enlisted the help of doctors to test 100 grams of homemade acetylsalicylic acid.13 None of the doctors reported side effects in their patients, and they asked for larger quantities for more detailed testing. From these tests, it was clear that acetylsalicylic acid retained the beneficial clinical effects of salicylic acid, including potent pain relief, but produced fewer side effects.&lt;/p&gt;
    &lt;p&gt;A report was sent to Bayer detailing the results of these tests, upon which Dreser commented: âthe product has no value.â Nonetheless, Bayer decided to conduct more tests, the results of which confirmed that acetylsalicylic acid worked. EichengrÃ¼n stated he suggested the name âaspirin.â14&lt;/p&gt;
    &lt;p&gt;Despite his condemnation of aspirin, Dreser was commissioned to write the paper on Bayerâs synthesis and testing of aspirin, which was published in 1899. His article focused on the pharmacology and animal studies, omitted details of tests in humans, and contains no mention of either Hoffman or EichengrÃ¼n. EichengrÃ¼n acknowledged this was standard practice at the time: only the company that made the drug was reported, not the inventors.15&lt;/p&gt;
    &lt;p&gt;While EichengrÃ¼nâs article makes it very clear that he and Hoffman should be credited with the invention of aspirin and not Dreser, he waited until 1949 to publish his account. The account with Hoffman as the sole inventor, however, was published in 1934. So why did EichengrÃ¼n wait?&lt;/p&gt;
    &lt;p&gt;In 1999, Walter Sneader published a reappraisal of the discovery of aspirin, in which he looked at EichengrÃ¼nâs 1949 article and other relevant documents. In it, Sneader argued that EichengrÃ¼nâs ethnicity forced him to remain quiet. EichengrÃ¼n was a Jew living in 1930s and 1940s Germany. The Nazis were making life successively more difficult for Jews, even for successful factory owners like EichengrÃ¼n. While EichengrÃ¼n had hired a gentile associate to avoid the loss of state contracts, his company was forcibly transferred to a non-Jew in 1938. And although 76 and married to an âaryan,â he was interned at Theresienstadt in 1944 for 14 months.Â&lt;/p&gt;
    &lt;p&gt;In his 1949 article, EichengrÃ¼n recalled that he saw a display for aspirin in the Hall of Honor of the chemical department of the German Museum in Munich in 1941, with the inscription: "Aspirin; Inventors Dreser and Hoffman." Also at the entrance to the museum was a sign prohibiting Non-Aryans from entering. To this, EichengrÃ¼n simply stated: âSapienti sat!â (translated as: âEnough for the wise!â)Â&lt;/p&gt;
    &lt;p&gt;Given this context, itâs not difficult to imagine why EichengrÃ¼n may have been reluctant to claim credit, even if he were aware of the 1934 book. Aspirin was successful and important: if a Jew were to have claimed credit for its invention, when at every level Jews were being forced out of public life and their accomplishments erased, such a person would have undoubtedly provoked a hostile response.&lt;/p&gt;
    &lt;p&gt;Additionally, EichengrÃ¼nâs article is only the account of one man, written at the very end of his life (he died the same month his article was published), and could be biased, deceptive, or otherwise incorrect. In a press release responding to Sneaderâs article, Bayer stated that EichengrÃ¼nâs claims cannot be proven. Bayer also claimed that Hoffman was EichengrÃ¼nâs equal hierarchically, so EichengrÃ¼n couldnât have ordered Hoffman to create acetylsalicylic acid. The press release also questioned why EichengrÃ¼n didnât object at the time of the patent being awarded solely to Hoffman, and seemed troubled that EichengrÃ¼n waited 50 years to claim his role in the development of aspirin.&lt;/p&gt;
    &lt;p&gt;Against this, we have the knowledge that Nazi censorship, anti-Jewish legislation and sentiment, and propaganda (including in textbooks) could have removed EichengrÃ¼n from the history of aspirin. Even this year, we have examples of erasure of accomplishments due to peopleâs ethnicity, gender, or both.&lt;/p&gt;
    &lt;p&gt;Ultimately, this controversy remains unresolved. While it is entirely possible that evidence for EichengrÃ¼nâs contributions at Bayer were purged due to antisemitism, we cannot be certain.&lt;/p&gt;
    &lt;head rend="h2"&gt;NSAID Expansion: 1949 to present&lt;/head&gt;
    &lt;p&gt;While it is seemingly impossible to find figures for aspirin consumption or production over time, it is clear that it took off after Bayer began marketing the drug in 1899. EichengrÃ¼n noted that it wasnât just that aspirin was effective with limited side effects, but also that it came packaged as tablets rather than as a powder in a paper bag. Tablets were a novelty at the end of the 19th century. Additionally, while the trade name âaspirinâ was protected from imitation, the process for making it was not. This meant the availability of generic acetylsalicylic acid sold under different names16 soon drove down prices.&lt;/p&gt;
    &lt;p&gt;Aspirinâs popularity diminished once paracetamol and ibuprofen became available in the late 1950s and early 1960s, as the latter drugs had even fewer gastrointestinal side effects. However, its use rose again after the ISIS-2 trial, published in 1988. This trial tested whether low-dose aspirin and streptokinase, separately or together, were effective at preventing mortality after suspected acute myocardial infarction (heart attack). The results were so unambiguously positive for aspirin (and streptokinase, although aspirin was far cheaper) that aspirin use sharply increased worldwide in acute coronary care. The use of aspirin amongst people in hospitals with acute myocardial infarction, for example, increased in the UK from 10 percent in 1987 to over 90 percent in 1989.&lt;/p&gt;
    &lt;p&gt;Further studies looked at whether aspirin was effective at preventing cardiovascular disease (including heart attacks and strokes), and led to recommendations promoting low-dose aspirin use. A study using 2017 interview data suggested that 23.4 percent of adults 40 years or older in the U.S. (estimated to be about 29 million people) took daily aspirin to prevent cardiovascular disease. Although there are disputes around who should take aspirin for cardiovascular disease prevention, it nonetheless remains extremely popular.&lt;/p&gt;
    &lt;p&gt;The origins of other NSAIDs are not nearly as dramatic as aspirin. Starting in the 1960s, multiple NSAIDs were developed and patented: indomethacin (1961), ibuprofen (1962),17 mefenamic acid (1964), naproxen (1967), diclofenac (1978), celecoxib (1993), etoricoxib (1996), among others.18&lt;/p&gt;
    &lt;p&gt;Despite the numerous brands of NSAIDs, their mechanism of action remained unknown until 1971, when John Vane discovered the mechanism of action of aspirin, and, by extension, other NSAIDs. These molecules, he found, work by blocking cyclooxygenase (COX) enzymes. COX enzymes produce compounds19 that cause pain, inflammation, and fever: if you block them, fewer of those compounds are produced.20 This discovery led to a rapid expansion in the number of available NSAIDs and a Nobel Prize for Vane in 1982.&lt;/p&gt;
    &lt;p&gt;While future NSAID development is likely to focus on maintaining or improving clinical effectiveness while reducing side effects, there may be novel roles for NSAIDs to fulfil, such as occurred in the 1980s when aspirin was promoted as a treatment and preventative for cardiovascular disease. NSAIDs may likewise play some as yet undetermined role in neurodegenerative diseases, diabetes, and cancer disease therapy.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Search in the Cabinet&lt;/head&gt;
    &lt;p&gt;When setting out to write the history of NSAIDs, I thought the project would be reasonably straightforward; people used to drink willow bark tea, and someone clever turned that into aspirin. What I found instead was a labyrinth of oft-repeated myths, partial histories, and conjecture. While piecing the story together, I couldnât help but feel that scientists could do a better job of preserving their work and methods for posterity.Â&lt;/p&gt;
    &lt;p&gt;At its heart, the issue is one of knowing when information is fact, conjecture, or mythology. This is as relevant today as it has ever been, for while the internet has allowed unprecedented access to information, it is as unclear as ever whether that information represents truth. With the rise of artificial intelligence, as well as malicious agents intent on creating and propagating misinformation, determining what is factual will become increasingly more difficult.Â&lt;/p&gt;
    &lt;p&gt;Knowing who synthesized aspirin for the first time and why may seem relatively trivial when compared with questions of more immediate relevance and consequence, such as whether facemasks help prevent the spread of COVID-19. But as someone who has attempted to answer both questions, the difficulties in establishing the facts are similar. We need to know who did what, how, and why.&lt;/p&gt;
    &lt;p&gt;Newton said that scientists stand on the shoulders of giants. However, scientists can only stand above the clouds when there is an unbroken chain of giants beneath them. As soon as one giant is missing, as soon as one link in the unbroken chain of scientific evidence breaks, the whole thing comes tumbling down.&lt;/p&gt;
    &lt;p&gt;I have one piece of advice for scientists and science communicators: your references matter. They are the evidence that we even have giants supporting us. All scientific claims should be referenced. It isnât sufficient for you to state that Hippocrates prescribed willow bark tea to treat inflammatory pain. You need to show why you think that is true.&lt;/p&gt;
    &lt;p&gt;The risk of not providing reputable sources is not just that myths get propagated, itâs that lies get propagated. After all, it likely doesnât really matter in 2025 whether Hippocrates made people drink 41 cups of willow bark tea a day, or if people write historical fiction where characters rush off to find willow bark to quell a fever. But it does matter whether people believe, for instance, that vaccination is the best way to prevent measles.&lt;/p&gt;
    &lt;p&gt;I also have one request for people who read scientific literature (of any description): demand better. People may claim to be standing on the shoulders of giants, but are actually shouting from two feet off the ground on a rusty, broken bicycle. Do authors present quality evidence to support their claims, or does it fall apart when you dig a little deeper?Â&lt;/p&gt;
    &lt;p&gt;Before researching its origins, I believed that willow bark tea was ancient aspirin. Now, I believe itâs simply willow bark tea. It may behave similarly to aspirin, but not because it is aspirin.&lt;/p&gt;
    &lt;p&gt;However, by using direct evidence to piece together the rest of the story, Iâve come to trust the following:Â Reverend Stone found a successful application of powdered willow bark sometime before 1763. He didnât do this because of any historical precedent, but simply because he thought it might work. Fontana then extracted and named salicin, likely referencing Stone in his report. This led to the use and manufacture of salicylic acid, and then to Arthur EichengrÃ¼n, who likely asked Felix Hoffman to synthesize acetylsalicylic acid in 1897.&lt;/p&gt;
    &lt;p&gt;Ultimately, while I donât think willow bark tea is ancient aspirin, I do think aspirin can still trace its origins back to the willow bark infusions that Reverend Stone used to treat the people of Chipping Norton over 250 years ago. So fancy that: aspirin was ultimately derived from willow bark after all, maybe just not as long ago as the histories would have us believe.&lt;/p&gt;
    &lt;p&gt;{{divider}}&lt;/p&gt;
    &lt;p&gt;Watch our behind-the-scenes interview with the author. Available now on YouTube.&lt;/p&gt;
    &lt;p&gt;Sean Harrison is an expert in epidemiology and evidence synthesis. He has spent the last decade answering research questions by finding, analysing, and synthesizing all available evidence to answer those questions. During the COVID-19 pandemic, he worked at the UK Health Security Agency, providing evidence reviews to inform COVID-19 policy. He is currently a research fellow at the University of Exeter and blogs at seanharrison.blog. Find him on BlueSky at @sean-h.bsky.social.&lt;/p&gt;
    &lt;p&gt;Cite: Harrison, S. âThe Uncertain Origins of Aspirin.â Asimov Press (2025). https://doi.org/10.62211/58qw-41hg&lt;/p&gt;
    &lt;p&gt;Header image by Ella Watkins-Dulaney.&lt;/p&gt;
    &lt;p&gt;This article was published on 14 July 2025.&lt;/p&gt;
    &lt;p&gt;{{divider}}&lt;/p&gt;
    &lt;head rend="h2"&gt;Footnotes&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;If you have a headache, a sprained ankle, a temperature, or some other minor complaint, thereâs a good chance that if you reach for any drug, itâll either be an NSAID, such as aspirin or ibuprofen, or paracetamol (a different class of drug).&lt;/item&gt;
      &lt;item&gt;Accurate global statistics are difficult (possibly impossible) to find for the total number of prescribed NSAIDs, but in 2022 in the U.S., ibuprofen was the 33rd most prescribed medication (17.5 million prescriptions), followed by aspirin at 36th (17.0 million), diclofenac at 51st (12.5 million), naproxen at 89th (7.4 million), celecoxib at 93rd (7.0 million), and indomethacin at 256th (1.1 million). Mefenamic acid and indomethacin werenât in the top 300 most prescribed medications.&lt;/item&gt;
      &lt;item&gt;There are other, more infrequent references to ancient people using willow to reduce pain, inflammation, or fever found among the Chinese and the indigenous peoples of America and South Africa. Additionally, although it is claimed that an Ancient Assyrian clay tablet (3,500 to 2,000 BC) described the use of willow leaves for pain and inflammation, I havenât found original evidence for this, nor the current location of the tablet, nor its translation.&lt;/item&gt;
      &lt;item&gt;The symbol of medicine as a staff with a serpent coiled around it â the staff of Asclepius â may have been derived from this treatment for guinea worm. However, like the rest of the historical details in this article, we canât be sure. We do know, however, that the âcaduceus,â a rod with two snakes coiled around it, often with wings at the top, originally had nothing to do with healing or healthcare. Various healthcare-aligned groups, as well as the U.S. Public Health Service, have adopted it nevertheless, possibly confusing the two symbols. In fairness, the two symbols look similar, and a winged rod with two snakes does look better than a wingless rod with only a single snake.&lt;/item&gt;
      &lt;item&gt;The Hippocratic oath was named for Hippocrates, although it was unlikely to have been written by Hippocrates, and doesnât start with âfirst, do no harm,â as many (including myself, until recently) believe. Whether any of the surviving works attributed to Hippocrates were actually written by him is debatable, given they are anonymous, written at different times by different hands, and have different ideas about the body and healing. Franz Zacharias Ermerins, a Dutch physician and editor, apparently identified at least 19 different authors of works attributed to Hippocrates.&lt;/item&gt;
      &lt;item&gt;This is, evidently, part of the Doctrine of Signatures. This is the belief that there must be some (divine) sign telling us which plants to use to cure which diseases. Often, it was the appearance of a plant that was the clue: eyebright flowers resemble eyes, so must be able to treat eye issues; liverwort resembles the shape and colour of the liver, so must be able to treat liver issues; lungwort resembles disease lungs, so must be able to treat lung issues. In this case, it was the location of willow trees: âthe general maxim, that many natural maladies carry their cures along with them, or that their remedies lie not far from their caufes, was fo very appofite to this particular cafe, that I could not help applying it; and that this might be the intention of Providence here, I muft own had fome little weight with me.â&lt;/item&gt;
      &lt;item&gt;Cinchona is almost certainly named for the Countess of ChinchÃ³n, a Spanish noblewoman married to the Viceroy of Peru, who developed fever and chills (likely malaria) in 1631. Jesuit priests made a remedy that included the bark of the Cinchona tree, which, presumably, previously had a different name. The remedy worked, and the tree was named Cinchona in her honor.&lt;/item&gt;
      &lt;item&gt;Other plants with six or fewer mentions were buttercup, foxglove, lesser celandine, and pennywort. Notably, foxgloves were the initial source of digoxin, used to treat various heart conditions, including heart failure. The origins of digoxin also involves medical history mythology: William Withering was an 18th century botanist and physician who, in 1785, first wrote about using foxgloves to treat dropsy (edema caused by heart failure, among other things). However, in 1928, the pharmaceutical company manufacturing digoxin invented âMother Huttonâ as part of a marketing campaign. âMother Huttonâ was an old herbalist from Shropshire, who originally discovered that foxglove tea helped dropsy, and who was paid by Withering for that information. Many people now believe the myth that âMother Huttonâ first used foxglove tea for dropsy, despite her being entirely fictional.&lt;/item&gt;
      &lt;item&gt;Charles Gerhardt was credited with the first synthesis of aspirin in 1852.Â He reportedly reacted sodium salicylate with acetyl chloride, creating acetylsalicylic acid. However, the final compound was unstable and impure, and the process to make it inconsistent and cumbersome, so Gerhardt reportedly did not investigate further. I was unable to verify this when translating the original evidence: it is both technical and in German, so Iâm leaving this as âreportedly.â Itâs one of the challenges of working with 19th century foreign-language technical journal articles â¦&lt;/item&gt;
      &lt;item&gt;Iâve been unable to access a copy.&lt;/item&gt;
      &lt;item&gt;I went to some length to find a copy of this article. It didnât exist online, but I found a physical copy for sale on eBay in Poland. Unfortunately, the seller wouldnât initially ship to me in the UK, so I used Google Translate to ask them (in German) to allow shipping to the UK, which they very kindly did. Subsequently, DHL managed to lose the parcel, which is a shame as it was one of the few extant copies of this article in existence. However, the British Library is, thankfully, magnificent: they had a copy, and someone very generously managed to dig it out of the archives and photograph it for me. I transcribed the German text, translated it with Google translate, and put both the original German transcription and the English translation on the Internet Archive for posterity. Weeks later, DHL found the article and delivered it, so I scanned the original and uploaded it to the Internet Archive.&lt;/item&gt;
      &lt;item&gt;EichengrÃ¼n did not go into specifics of these tests in his article. Dreserâs introductory paper on aspirin mentions a number of different tests, but it is unclear when they were conducted, and by whom. Nonetheless, Dreser mentions tests using acids and alkalis, taking aspirin himself and then testing his urine (concluding the aspirin had turned into salicylic acid), and tests in rabbits (including body temperature), frogs (including blood vessel constriction, isolated heart function, and lethal dosage), and fish (including lethal dosage). Other tests may have been conducted that were not reported in this paper.&lt;/item&gt;
      &lt;item&gt;This, quite obviously, could have gone horrendously wrong: thankfully, clinical testing of new drugs has far stronger safeguards these days.&lt;/item&gt;
      &lt;item&gt;âAspirinâ is derived from âa-â for acetyl, â-spir-â from âSpirsaÃ¼reâ (spiric acid, an older name for salicylic acid, derived from the Latin for meadowsweet: Spiraea ulmaria), and â-inâ, a common chemical suffix.&lt;/item&gt;
      &lt;item&gt;EichengrÃ¼n also stated that they couldnât patent aspirin in Germany as only the preparation process, not the end result, could be patented. The process for making aspirin, however, also couldnât be patented because an earlier publication described how acetyl chloride had been mixed with salicylic acid under pressure in a gun barrel. Although the end result was not described, this was evidently sufficient grounds to not award a patent for the process of making aspirin. As a result, and because Bayer would only financially compensate EichengrÃ¼n and Hoffman if a patent were granted for a new drug, neither benefited financially from creating aspirin.&lt;/item&gt;
      &lt;item&gt;For example, salicyl acetate and acidum acetylo-salicylicum: the latter I imagine being a challenge for anyone to pronounce quickly and easily upon first reading it.&lt;/item&gt;
      &lt;item&gt;The development of ibuprofen shares striking similarities to the development of aspirin. Ibuprofen was developed while searching for a derivative of aspirin that would be suitable for long-term use for rheumatoid arthritis with fewer side effects, much as aspirin was developed as an alternative to salicylic acid. The lead scientist, Dr Stewart Adams, was also happy to test the compounds on himself first (after toxicity tests), and was reportedly âexcited to be the first person to take a dose of ibuprofenâ, much as EichengrÃ¼n first tested aspirin on himself.&lt;/item&gt;
      &lt;item&gt;Iâd be lying if I said I knew all those drug names before writing this article.&lt;/item&gt;
      &lt;item&gt;Thromboxanes, which play a role in platelet adhesion; prostaglandins, which cause vasodilation (expansion of blood vessels), increase body temperature by interacting with the hypothalamus, and reduce pain; and prostacyclins, which inhibit platelet activation and cause vasodilation.&lt;/item&gt;
      &lt;item&gt;There are two cyclooxygenase (COX) enzymes, which are both affected to a greater or lesser extent by NSAIDs. The first of which (COX-1) is found all over the body (in particular the gastrointestinal lining and kidneys), and the second (COX-2) is only around during an inflammatory response. As they affect these two enzymes differently, NSAIDs have different levels of effectiveness and side effect profiles.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Always free. No ads. Richly storied.&lt;/p&gt;
    &lt;p&gt;Always free. No ads. Richly storied.&lt;/p&gt;
    &lt;p&gt;Always free. No ads. Richly storied.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46015860</guid><pubDate>Sat, 22 Nov 2025 16:23:06 +0000</pubDate></item><item><title>The privacy nightmare of browser fingerprinting</title><link>https://kevinboone.me/fingerprinting.html</link><description>&lt;doc fingerprint="d73014573db7254d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The privacy nightmare of browser fingerprinting&lt;/head&gt;
    &lt;p&gt;I imagine that most people who take an interest in de-Googling are concerned about privacy. Privacy on the Internet is a somewhat nebulous concept, but one aspect of privacy is surely the prevention of your web browsing behaviour being propagated from one organization to another. I don’t want my medical insurers to know, for example, that I’ve been researching coronary artery disease. And even though my personal safety and liberty probably aren’t at stake, I don’t want to give any support to the global advertising behemoth, by allowing advertisers access to better information about me.&lt;/p&gt;
    &lt;p&gt;Unfortunately, while distancing yourself from Google and its services might be a necessary first step in protecting your privacy, it’s far from the last. There’s more to do, and it’s getting harder to do it, because of browser fingerprinting.&lt;/p&gt;
    &lt;head rend="h2"&gt;How we got here&lt;/head&gt;
    &lt;p&gt;Until about five years ago, our main concern surrounding browser privacy was probably the use of third-party tracking cookies. The original intent behind cookies was that they would allow a web browser and a web server to engage in a conversation over a period of time. The HTTP protocol that web servers use is stateless; that is, each interaction between browser and server is expected to be complete in itself. Having the browser and the server exchange a cookie (which could just be a random number) in each interaction allowed the server to associate each browser with an ongoing conversation. This was, and is, a legitimate use of cookies, one that is necessary for almost all interactive web-based services. If the cookie is short-lived, and only applies to a single conversation with a single web server, it’s not a privacy concern.&lt;/p&gt;
    &lt;p&gt;Unfortunately, web browsers for a long time lacked the ability to distinguish between privacy-sparing and privacy-breaking uses of cookies. If many different websites issue pages that contain links to the same server – usually some kind of advertising service – then the browser would send cookies to that server, thinking it was being helpful. This behaviour effectively linked web-based services together, allowing them to share information about their users. The process is a bit more complicated than I’m making it out to be, but these third-party cookies were of such concern that, in Europe at least, legislation was enacted to force websites to disclose that they were using them.&lt;/p&gt;
    &lt;p&gt;Browsers eventually got better at figuring out which cookies were helpful and which harmful and, for the most part, we don’t need to be too concerned about ‘tracking cookies’ these days. Not only can browsers mitigate their risks, there’s a far more sinister one: browser fingerprinting.&lt;/p&gt;
    &lt;head rend="h2"&gt;Browser fingerprinting&lt;/head&gt;
    &lt;p&gt;Browser fingerprinting does not depend on cookies. It’s resistant, to some extent, to privacy measures like VPNs. Worst of all, steps that we might take to mitigate the risk of fingerprinting can actually worsen the risk. It’s a privacy nightmare, and it’s getting worse.&lt;/p&gt;
    &lt;p&gt;Fingerprinting works by having the web server extract certain discrete elements of information from the browser, and combining those elements into a numerical identifier. Some of the information supplied by the browser is fundamental and necessary and, although a browser could fake it, such a measure is likely to break the website.&lt;/p&gt;
    &lt;p&gt;For example, a fingerprinting system knows, just from information that my browser always supplies (and probably has to), that I’m using version 144 of the Firefox browser, on Linux; my preferred language is English, and my time-zone is GMT. That, by itself, isn’t enough information to identify me uniquely, but it’s a step towards doing so.&lt;/p&gt;
    &lt;p&gt;To get more information, the fingerprinter needs to use more sophisticated methods which the browser could, in theory, block. For example, if the browser supports JavaScript – and they nearly all do – then the fingerprinter can figure out what fonts I have installed, what browser extensions I use, perhaps even what my hardware is. Worst of all, perhaps, it can extract a canvas fingerprint. Canvas fingerprinting works by having the browser run code that draws text (perhaps invisibly), and then retrieving the individual pixel data that it drew. This pixel data will differ subtly from one system to another, even drawing the same text, because of subtle differences in the graphics hardware and the operating system.&lt;/p&gt;
    &lt;p&gt;It appears that only about one browser in every thousand share the same canvas fingerprint. Again, this alone isn’t enough to identify me, but it’s another significant data point.&lt;/p&gt;
    &lt;p&gt;Fingerprinting can make use of even what appears to be trivial information. If, for example, I resize my browser window, the browser will probably make the next window the same size. It will probably remember my preference from one day to the next. If the fingerprinter knows my preferred browser window size is, say, 1287x892 pixels, that probably narrows down the search for my identify by a factor of a thousand or more.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why crude methods to defeat fingerprinting don’t work&lt;/head&gt;
    &lt;p&gt;You might think that a simple way to prevent, or at least hamper, fingerprinting would be simply to disable JavaScript support in the browser. While this does defeat measures like canvas fingerprinting, it generates a significant data point of its own: the fact that JavaScript is disabled. Since almost every web browser in the world now supports JavaScript, turning it off as a measure to protect privacy is like going to the shopping mall wearing a ski mask. Sure, it hides your identify; but nobody’s going to want to serve you in stores. And disabling JavaScript will break many websites, including some pages on this one, because I use it to render math equations.&lt;/p&gt;
    &lt;p&gt;Less dramatic approaches to fingerprinting resistance have their own problems. For example, a debate has long raged about whether a browser should actually identify itself at all. The fact that I’m running Firefox on Linux probably puts me in a small, easily identified group. Perhaps my browser should instead tell the server I’m running Chrome on Windows? That’s a much larger group, after all.&lt;/p&gt;
    &lt;p&gt;The problem is that the fingerprinters can guess the browser and platform with pretty good accuracy using other methods, whether the browser reports this information or not. If the browser says something different to what the fingerprinter infers, we’re back in ski-mask territory.&lt;/p&gt;
    &lt;p&gt;What about more subtle methods to spoof the client’s behaviour? Browsers (or plug-ins) can modify the canvas drawing procedures, for example, to spoof the results of canvas fingerprinting. Unfortunately, these methods leave traces of their own, if they aren’t applied subtly. What’s more, if they’re applied rigorously enough to be effective, they can break websites that rely on them for normal operation.&lt;/p&gt;
    &lt;p&gt;All in all, browser fingerprinting is very hard to defeat, and organizations that want to track us have gotten disturbingly good at it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Is there any good news?&lt;/head&gt;
    &lt;p&gt;Not much, frankly.&lt;/p&gt;
    &lt;p&gt;Before sinking into despondency, it’s worth bearing in mind that websites that attempt to demonstrate the efficacy of fingerprinting, like amiunique and fingerprint.com do not reflect how fingerprinting works in the real world. They’re operating on comparatively small sets of data and, for the most part, they’re not tracking users over days. Real-world tracking is much harder than these sites make it out to be. That’s not to say it’s too hard but it is, at best, a statistical approach, rather than an exact one.&lt;/p&gt;
    &lt;p&gt;In addition ‘uniqueness’, in itself, is not a strong measure of traceability. That my browser fingerprint is unique at some point in time is irrelevant if my fingerprint will be different tomorrow, whether it remains unique within the fingerprinter’s database or not.&lt;/p&gt;
    &lt;p&gt;Of course, these facts also mean that it’s difficult to assess the effectiveness of our countermeasures: our assessment can only be approximate, because we don’t actually know what real fingerprinters are doing.&lt;/p&gt;
    &lt;p&gt;Another small piece of good news is that browser developers are starting to realize how much of a hazard fingerprinting is, and to integrate more robust countermeasures. We don’t necessarily need to resort to plug-ins and extensions, which are themselves detectable and become part of the fingerprint. At present, Brave and Mullvad seems to be doing the most to resist fingerprinting, albeit in different ways. Librewolf has the same fingerprint resistance as Firefox, but it is turned on by default. Probably anti-fingerprinting methods will improve over time but, of course, the fingerprinters will get better at what they do, too.&lt;/p&gt;
    &lt;head rend="h2"&gt;So what can we do?&lt;/head&gt;
    &lt;p&gt;First, and most obviously, if you care about avoiding tracking, you must prevent long-lived cookies hanging around in the browser, and you must use a VPN. Ideally the VPN should rotate its endpoint regularly.&lt;/p&gt;
    &lt;p&gt;The fact that you’re using a VPN, of course, is something that the fingerprinters will know, and it is does make you stand out. Sophisticated fingerprinters won’t be defeated by a VPN alone. But if you don’t use a VPN, the trackers don’t even need to fingerprint you: your IP number, combined with a few other bits of routine information, will identify you immediately, and with near-certainty.&lt;/p&gt;
    &lt;p&gt;Many browsers can be configured to remove cookies when they seem not to be in use; Librewolf does this by default, and Firefox and Chrome do it in ‘incognito’ mode. The downside, of course, is that long-lived cookies are often used to store authentication status so, if you delete them, you’ll find yourself having to log in every time you look at a site that requires authentication. To mitigate this annoyance, browsers generally allow particular sites to be excluded from their cookie-burning policies.&lt;/p&gt;
    &lt;p&gt;Next, you need to be as unremarkable as possible. Fingerprinting is about uniqueness, so you should use the most popular browser on the most popular operating system on the kind of hardware you can buy from PC World. If you’re running the latest Chrome on the latest Windows 11 on a two-year-old, bog-standard laptop, you’re going to be one of a very large group. Of course Chrome, being a Google product, has its own privacy concerns, so you might be better off using a Chromium-based browser with reduced Google influence, like Brave.&lt;/p&gt;
    &lt;p&gt;You should endeavour to keep your computer in as near its stock configuration as possible. Don’t install anything (like fonts) that are reportable by the browser. Don’t install any extensions, and don’t change any settings. Use the same ‘light’ theme as everybody else, and use the browser with a maximized window, and always the same size. And so on.&lt;/p&gt;
    &lt;p&gt;If possible, use a browser that has built-in fingerprint resistance, like Mullvad or Librewolf (or Firefox with these features turned on).&lt;/p&gt;
    &lt;p&gt;If you take all these precautions, you can probably reduce the probability that you can be tracked by you browser fingerprint, over days or weeks, from about 99% to about 50%.&lt;/p&gt;
    &lt;p&gt;50% is still too high, of course.&lt;/p&gt;
    &lt;head rend="h2"&gt;The downsides of resisting fingerprinting&lt;/head&gt;
    &lt;p&gt;If you enable fingerprinting resistance in Firefox, or use Librewolf, you’ll immediately encounter oddities. Most obviously, every time you open a new browser window, it will be the same size. Resizing the window may have odd results, as the browser will try to constrain certain screen elements to common size multiples. In addition, you won’t be able to change the theme.&lt;/p&gt;
    &lt;p&gt;You’ll probably find yourself facing more ‘CAPTCHA’ and similar identity challenges, because your browser will be unknown to the server. Websites don’t do this out of spite: hacking and fraud are rife on the Internet, and the operators of web-based services are rightly paranoid about client behaviour.&lt;/p&gt;
    &lt;p&gt;You’ll likely find that some websites just don’t work properly, in many small ways: wrong colours, misplaced text, that kind of thing. I’ve found these issues to be irritations rather than show-stoppers, but you might discover otherwise.&lt;/p&gt;
    &lt;head rend="h2"&gt;Is browser fingerprinting legal?&lt;/head&gt;
    &lt;p&gt;The short answer, I think, is that nobody knows, even within a specific jurisdiction. In the UK, the Information Commissioner’s Office takes a dim view of it, and it probably violates the spirit of the GDPR, if not the letter.&lt;/p&gt;
    &lt;p&gt;The GDPR is, for the most part, technologically neutral, although it has specific provisions for cookies, which were a significant concern at the time it was drafted. So far as I know, nobody has yet challenged browser fingerprinting under the GDPR, even though it seems to violate the provisions regarding consent. Since there are legitimate reasons for fingerprinting, such as hacking detection, organizations that do it could perhaps defend against a legal challenge on the basis that fingerprinting is necessary to operate their services safely. In the end, we really need specific, new legislation to address this privacy threat.&lt;/p&gt;
    &lt;head rend="h2"&gt;Closing remarks&lt;/head&gt;
    &lt;p&gt;I suspect that many people who take an interest in Internet privacy don’t appreciate how hard it is to resist browser fingerprinting. Taking steps to reduce it leads to inconvenience and, with the present state of technology, even the most intrusive approaches are only partially effective. The data collected by fingerprinting is invisible to the user, and stored somewhere beyond the user’s reach.&lt;/p&gt;
    &lt;p&gt;On the other hand, browser fingerprinting produces only statistical results, and usually can’t be used to track or identify a user with certainty. The data it collects has a relatively short lifespan – days to weeks, not months or years. While it probably can be used for sinister purposes, my main concern is that it supports the intrusive, out-of-control online advertising industry, which has made a wasteland of the Internet.&lt;/p&gt;
    &lt;p&gt;In the end, it’s probably only going to be controlled by legislation and, even when that happens, the advertisers will seek new ways to make the Internet even more of a hellscape – they always do.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46016249</guid><pubDate>Sat, 22 Nov 2025 17:08:36 +0000</pubDate></item><item><title>Gwern's "Stem Humor" Directory</title><link>https://gwern.net/doc/math/humor/index</link><description>&lt;doc fingerprint="ad63379805be0bff"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;‘STEM humor’ directory&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;See Also&lt;/item&gt;
      &lt;item&gt;Gwern &lt;list rend="ul"&gt;&lt;item&gt;“Conference Fermi Problems ”, Gwern 2025&lt;/item&gt;&lt;item&gt;“Human Cannibalism Alignment Chart ”, Gwern et al 2025&lt;/item&gt;&lt;item&gt;“The Meta-LW Doomsday Argument ”, Gwern 2025&lt;/item&gt;&lt;item&gt;“Estimated Cost of DMT Machine Elf Prime Factorization Experiment ”, Gwern 2015&lt;/item&gt;&lt;item&gt;“A Christmas Protestation ”, o1-pro et al 2024&lt;/item&gt;&lt;item&gt;“Second Life Sentences ”, Gwern 2024&lt;/item&gt;&lt;item&gt;“The Carcinisation of Satan ”, Gwern 2024&lt;/item&gt;&lt;item&gt;“On the Impossibility of Superintelligent Rubik’s Cube Solvers ”, Gwern et al 2023&lt;/item&gt;&lt;item&gt;“Paperclip Alignment Chart ”, Gwern 2023&lt;/item&gt;&lt;item&gt;“Rare Greek Variables ”, Gwern 2021&lt;/item&gt;&lt;item&gt;“Gilles Goullet, Author of the Blindsight ”, Gwern 2010&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Links &lt;list rend="ul"&gt;&lt;item&gt;“Placebo Emporium: 2025 Annual Shareholder Letter ”, Troesh 2025&lt;/item&gt;&lt;item&gt;“The Fine Art of Being Too Dumb to Regulate; Or: How I Learned to Stop Worrying and Love Betting on Earnings Buzzwords ”, Vagabonds 2025&lt;/item&gt;&lt;item&gt;“My Antichrist Lecture: Forecasting Transformative AI Using the Book of Revelation [Anthropic gematria] ”, Alexander 2025&lt;/item&gt;&lt;item&gt;“Gwern Visits BAIR ”, Liu 2025&lt;/item&gt;&lt;item&gt;The Way of Code: The Timeless Art of Vibe Coding, Rubin 2025&lt;/item&gt;&lt;item&gt;“[Social Acceptability of Eating Human Meat Alignment Chart] ”, Hero 2025&lt;/item&gt;&lt;item&gt;“You Can Never Reproduce The Same Bug Twice [Demotivational Poster] ”, Gwern 2025&lt;/item&gt;&lt;item&gt;“NeuRaLaTeX: A Machine Learning Library Written in Pure LaTeX ”, Gardner et al 2025&lt;/item&gt;&lt;item&gt;“Regex Chess: A 2-Ply Minimax Chess Engine in 84,688 Regular Expressions ”, Carlini 2025&lt;/item&gt;&lt;item&gt;“Trajectoid ”, Weinersmith 2024&lt;/item&gt;&lt;item&gt;“Age against the Machine—Susceptibility of Large Language Models to Cognitive Impairment: Cross Sectional Analysis ”&lt;/item&gt;&lt;item&gt;“A Numerical Evaluation of the Finite Monkeys Theorem ”, Woodcock &amp;amp; Falletta 2024&lt;/item&gt;&lt;item&gt;“How a Silly Science Prize Changed My Career: A Levitating Frog, a Necrophiliac Duck, Taxi Drivers’ Brains—The Ig Nobel Prizes Have Shined a Spotlight on Offbeat Work. Here’s an inside Look at How Winners Feel about This Sometimes Unwanted ‘Honor’ ”, Clarke 2024&lt;/item&gt;&lt;item&gt;“On the Impossibility of Superintelligent Rubik’s Cube Solvers [Claude-3.5-Sonnet] ”, Claude-3 2024&lt;/item&gt;&lt;item&gt;“Towel Day: The Aerodynamics of Freefalling Sperm Whales [Terminal Velocity: 178.3 M/s] ”, Ferguson 2024&lt;/item&gt;&lt;item&gt;“A Programming Language Embedded in Magic: The Gathering ”, Yin &amp;amp; Churchill 2024&lt;/item&gt;&lt;item&gt;“An Abundance of Katherines: The Game Theory of Baby Naming ”, Blumer et al 2024&lt;/item&gt;&lt;item&gt;“Are We Safe from Lightning Inside Buildings? A Study of Lightning Fatalities Inside Buildings Using Smartphones ”, Souza et al 2024&lt;/item&gt;&lt;item&gt;“Polyamorous Scheduling ”, Gąsieniec et al 2024&lt;/item&gt;&lt;item&gt;“An Incomplete Primer of Caselaw Appertaining To Bigfoot, AKA Sasquatch, LNU ”, White 2024&lt;/item&gt;&lt;item&gt;“IOCCC 2024: Stedolan—Best One Liner ”&lt;/item&gt;&lt;item&gt;“Paperclip Alignment Chart (Alternate) ”, saturn2 2023&lt;/item&gt;&lt;item&gt;“A LLM Assisted Exploitation of AI-Guardian ”, Carlini 2023&lt;/item&gt;&lt;item&gt;“Can a Good Philosophical Contribution Be Made Just by Asking a Question? ”, Habgood-Coote et al 2022&lt;/item&gt;&lt;item&gt;“Immaterials and Methods: Reagents for the Total Laboratory Synthesis of the Chocolate Chip Cookie ”, Schlonk 2022&lt;/item&gt;&lt;item&gt;“A Modest Spelling Reform to Increase Autologicity, Symmetry, and Readability ”&lt;/item&gt;&lt;item&gt;“Rare Greek Variables ”, Bayer 2021&lt;/item&gt;&lt;item&gt;“Flinch ”, Munroe 2021&lt;/item&gt;&lt;item&gt;“Proposed Detection of Ghosts by Mass Spectrometry-Spectral Presence Origin-Omics Kinetic Yield (MS-SPOOKY) ”, Schlonk 2021&lt;/item&gt;&lt;item&gt;“Are Cats Good? An Important Study ”, Owen &amp;amp; Lamon 2021b&lt;/item&gt;&lt;item&gt;“My Cat Chester’s Dynamical Systems Analysyyyyy7777777777777777y7is of the Laser Pointer and the Red Dot on the Wall: Correlation, Causation, or SARS-Cov-2 Hallucination? ”, Armstrong &amp;amp; Chester 2021&lt;/item&gt;&lt;item&gt;“How Fast Can Evangelion Run? Application Of Aerodynamics And Scaling Laws To The Super Robot ”, Ryu et al 2020&lt;/item&gt;&lt;item&gt;“The Treachery of Image Files ”, Earnest 2020&lt;/item&gt;&lt;item&gt;“My Immortal As Alchemical Allegory ”, Alexander 2020&lt;/item&gt;&lt;item&gt;“Single Headed Attention RNN: Stop Thinking With Your Head ”, Merity 2019&lt;/item&gt;&lt;item&gt;“A Mulching Proposal ”, Keyes et al 2019&lt;/item&gt;&lt;item&gt;“30 Weird Chess Algorithms: Elo World ”, Tom7 2019&lt;/item&gt;&lt;item&gt;“Real Numbers, Data Science and Chaos: How to Fit Any Dataset With a Single Parameter ”, Boué 2019&lt;/item&gt;&lt;item&gt;“Spooky Fizz Buzz § Pg42 ”, Menghrajani 2019 (page 42)&lt;/item&gt;&lt;item&gt;“Blueberry Earth ”, Sandberg 2018&lt;/item&gt;&lt;item&gt;“The Random Walk of Cars and Their Collision Probabilities With Planets ”, Rein et al 2018&lt;/item&gt;&lt;item&gt;“Super-Earths in Need for Extremely Big Rockets ”, Hippke 2018&lt;/item&gt;&lt;item&gt;“It’s a Man Eat Man World ”, Graham et al 2017&lt;/item&gt;&lt;item&gt;“How Sheep With Cameras Got Some Tiny Islands onto Google Street View ”, Brulliard 2017&lt;/item&gt;&lt;item&gt;“Factoring in the Chicken McNugget Monoid ”, Chapman &amp;amp; O’Neill 2017&lt;/item&gt;&lt;item&gt;“F—K Nuance ”, Healy 2017&lt;/item&gt;&lt;item&gt;“On the Impossibility of Supersized Machines ”, Garfinkel et al 2017&lt;/item&gt;&lt;item&gt;“Seasonality of Auricular Amputations in Rabbits ”, Yaremchuk et al 2017&lt;/item&gt;&lt;item&gt;“Sheep View: Where There’s a Wool, There’s a Way ”, Vega 2016&lt;/item&gt;&lt;item&gt;“Identifying the Source of Perytons at the Parkes Radio Telescope ”, Petroff et al 2015&lt;/item&gt;&lt;item&gt;“Optimal Tip-To-Tip Efficiency: a Model for Male Audience Stimulation ”, Chugtai &amp;amp; Gilfoyle 2014&lt;/item&gt;&lt;item&gt;“Heaven Is Hotter Than Hell &amp;amp; A Refutation ”, Simanek 2014&lt;/item&gt;&lt;item&gt;“A Few Goodmen: Surname-Sharing Economist Coauthors ”, Goodman et al 2014&lt;/item&gt;&lt;item&gt;“Two Curious Integrals and a Graphic Proof ”, Schmid 2014&lt;/item&gt;&lt;item&gt;“Searching the Internet for Evidence of Time Travelers ”, Nemiroff &amp;amp; Wilson 2013&lt;/item&gt;&lt;item&gt;“XKCD Plots Have Landed in Matplotlib! ”&lt;/item&gt;&lt;item&gt;“[What Deals Should the Devil Optimally Betray in Any given Social Graph?] ”, Schou 2013&lt;/item&gt;&lt;item&gt;“Robert Bunsen’s Sweet Tooth ”, Jensen 2013&lt;/item&gt;&lt;item&gt;“Your Right Arm For A Publication In AER? ”, Attema et al 2013&lt;/item&gt;&lt;item&gt;“Vigil, the Eternal Morally Vigilant Programming Language ”, munificent 2013&lt;/item&gt;&lt;item&gt;“The Survival Time of Chocolates on Hospital Wards: Covert Observational Study ”, Gajendragadkar et al 2013&lt;/item&gt;&lt;item&gt;“Possible Bubbles of Spacetime Curvature in the South Pacific ”, Tippett 2012&lt;/item&gt;&lt;item&gt;“On the Tumbling Toast Problem ”, Borghi 2012&lt;/item&gt;&lt;item&gt;“Robust Soldier Crab Ball Gate ”, Gunji et al 2012&lt;/item&gt;&lt;item&gt;“Non-Detection of the Tooth Fairy at Optical Wavelengths ”, Armstrong 2012&lt;/item&gt;&lt;item&gt;“Gods As Topological Invariants ”, Schoch 2012&lt;/item&gt;&lt;item&gt;“Tiramisu [Lexical Gaps in English Borrowing from Latin] ”, Pullum 2011&lt;/item&gt;&lt;item&gt;“A Parasite from Outer Space: How Sergei Kurekhin Proved That Lenin Was a Mushroom ”, Yurchak 2011&lt;/item&gt;&lt;item&gt;“Quantum Computation With Devices Whose Contents Are Never Read ”, Yakaryilmaz et al 2010&lt;/item&gt;&lt;item&gt;“The Optimal Taxation of Height: A Case Study of Utilitarian Income Redistribution ”, Mankiw &amp;amp; Weinzierl 2010&lt;/item&gt;&lt;item&gt;“Are Birds Smarter Than Mathematicians? Pigeons (Columba Livia) Perform Optimally on a Version of the Monty Hall Dilemma ”, Herbranson &amp;amp; Schroeder 2010&lt;/item&gt;&lt;item&gt;“The Name Is Shrdlu… Etaoin Shrdlu ”, D. 2009&lt;/item&gt;&lt;item&gt;“Woosh: A Wonderful Object-Oriented Shell Environment [Unix Directories As Objects] ”, mhinsch 2009&lt;/item&gt;&lt;item&gt;“Time Variation of a Fundamental Dimensionless Constant ”, Scherrer 2009&lt;/item&gt;&lt;item&gt;“Japan’s Phillips Curve Looks Like Japan ”, Smith 2008&lt;/item&gt;&lt;item&gt;“BREATHTAKING Design Strategy ”, Group 2008&lt;/item&gt;&lt;item&gt;“Possible Girls ”, Sinhababu 2008&lt;/item&gt;&lt;item&gt;“Down-Sizing Forever ”, Scott &amp;amp; Frolop 2008&lt;/item&gt;&lt;item&gt;The SICP Saga, Anonymous 2008&lt;/item&gt;&lt;item&gt;“Rugby (The Religion of Wales) and Its Influence on the Catholic Church: Should Pope Benedict XVI Be Worried? ”, Payne 2008&lt;/item&gt;&lt;item&gt;“Of Cinema, Food, and Desire: Franz Kafka’s ‘Investigations of a Dog’ ”, Williams 2007&lt;/item&gt;&lt;item&gt;“Sex, Aggression, and Humour: Responses to Unicycling ”, Shuster 2007&lt;/item&gt;&lt;item&gt;“The Wisdom of Hendrik W. Lenstra Junior ”, Magidin 2006&lt;/item&gt;&lt;item&gt;“Serge Lang, 1927–2005 § Part 1: Paul Vojta, University of California, Berkeley ”, Jorgenson &amp;amp; Krantz 2006 (page 12)&lt;/item&gt;&lt;item&gt;“We Are Sorry to Inform You... ”, Santini 2005&lt;/item&gt;&lt;item&gt;“A Box, Darkly: Obfuscation, Weird Languages, and Code Esthetics ”, Mateas &amp;amp; Montfort 2005&lt;/item&gt;&lt;item&gt;“Patent Office Annual Performance Review: Albert Einstein ”, Norvig 2005&lt;/item&gt;&lt;item&gt;“The Case of the Disappearing Teaspoons: Longitudinal Cohort Study of the Displacement of Teaspoons in an Australian Research Institute ”, Lim et al 2005&lt;/item&gt;&lt;item&gt;“Lewis Carroll’s Humpty Dumpty: an Early Report of Prosopagnosia? ”, Larner 2004&lt;/item&gt;&lt;item&gt;“Some AI Koans § Http://www.catb.org/esr/jargon/html/koans.html#id3141241 ”, Raymond 2003&lt;/item&gt;&lt;item&gt;“Some AI Koans ”, Raymond 2003&lt;/item&gt;&lt;item&gt;“Electron Band Structure In Germanium, My Ass ”, Kovar 2002&lt;/item&gt;&lt;item&gt;“A Tour of Accounting: Random Number Generator [Dilbert] ”, Adams 2001&lt;/item&gt;&lt;item&gt;“The Temperature of Heaven and Hell [Retrospective] ”, Pérez 2001&lt;/item&gt;&lt;item&gt;“Storks Deliver Babies (p = 0.008) ”, Matthews 2001&lt;/item&gt;&lt;item&gt;“Some Remarkable Properties of Sinc and Related Integrals ”, Borwein &amp;amp; Borwein 2001&lt;/item&gt;&lt;item&gt;“A Closer Look at Tumbling Toast ”, Bacon et al 2001&lt;/item&gt;&lt;item&gt;“The Evolution of a Haskell Programmer ”, Ruehr 2001&lt;/item&gt;&lt;item&gt;“Is Hell Endothermic or Exothermic? Old Collegiate Legend Involves a Student’s Coming up With a Clever Proof about the Physical Properties of Hell ”, Mikkelson 2000&lt;/item&gt;&lt;item&gt;“Area Man Consults Internet Whenever Possible ”, Onion 2000&lt;/item&gt;&lt;item&gt;“A Letter from the Frustrated Author of a Journal Paper ”, Glass 2000&lt;/item&gt;&lt;item&gt;“What Do Animals Do All Day? The Division of Labor, Class Bodies, and Totemic Thinking in the Popular Imagination ”, Martin 2000&lt;/item&gt;&lt;item&gt;“Klingon Programmers ”, Baker 1999&lt;/item&gt;&lt;item&gt;“I M A G I N E ”, Krishnamurthi 1996&lt;/item&gt;&lt;item&gt;“Tumbling Toast, Murphy’s Law and the Fundamental Constants ”, Matthews 1995&lt;/item&gt;&lt;item&gt;“Knockdown Arguments ”, Wreen 1995&lt;/item&gt;&lt;item&gt;“The Love Song of J. Random Hacker ”, Duntemann 1995&lt;/item&gt;&lt;item&gt;“(Para)bosons, (Para)fermions, Quons and Other Beasts in the Menagerie of Particle Statistics ”, Greenberg et al 1993&lt;/item&gt;&lt;item&gt;“Szeged in 1934 ”, Lorch &amp;amp; Hersh 1993&lt;/item&gt;&lt;item&gt;Geoffrey Sonnabend: Obliscence, Theories of Forgetting and the Problem of Matter—An Encapsulation (Fourth Edition, Abridged), Worth 1991&lt;/item&gt;&lt;item&gt;“Mustard Watches: An Integrated Approach To Time and Food ”, Ringard et al 1990&lt;/item&gt;&lt;item&gt;“What’s Wrong With This Lagrangean? ”, Mermin 1988&lt;/item&gt;&lt;item&gt;“Presentation Announcement / Automatic Weapons, Parts I–III ”, Shivers 1987&lt;/item&gt;&lt;item&gt;“Humour: The Interdisciplinary Denominator in Science ”, Kohn 1982&lt;/item&gt;&lt;item&gt;“An Epistemological Nightmare ”, Smullyan 1982&lt;/item&gt;&lt;item&gt;“Child’s Play: A Distorting Factor in Archaeological Distribution ”, Hammond &amp;amp; Hammond 1981&lt;/item&gt;&lt;item&gt;“A Rebuke of A. B. Smith‘s Paper, 'A Note on Piffles’ ”, Farlow 1980&lt;/item&gt;&lt;item&gt;“Paul Darwin Foote (1888–1971) § The Temperature of Heaven &amp;amp; Hell ”, Astin 1979 (page 12)&lt;/item&gt;&lt;item&gt;“The First Sally (A), Or, Trurl’s Electronic Bard § Love And Tensor Algebra ”, Lem &amp;amp; Kandel 1974 (page 7)&lt;/item&gt;&lt;item&gt;“Principia Discordia (1970) ”&lt;/item&gt;&lt;item&gt;“On the Enfeeblement of Mathematical Skills by ‘Modern Mathematics’ and by Similar Soft Intellectual Trash in Schools and Universities ”, Hammersley 1968&lt;/item&gt;&lt;item&gt;“A Note On Piffles, By A. B. Smith ”, Austin 1967&lt;/item&gt;&lt;item&gt;A Stress Analysis of a Strapless Evening Gown: Essays for a Scientific Age, Baker 1963&lt;/item&gt;&lt;item&gt;“On The Nature Of Mathematical Proof ”, Cohen 1961&lt;/item&gt;&lt;item&gt;“Hiawatha’s Lipid ”, Sinclair 1960&lt;/item&gt;&lt;item&gt;“Mathmanship ”, Vanserg 1958&lt;/item&gt;&lt;item&gt;“How to Write Geologese ”, Vansberg 1952&lt;/item&gt;&lt;item&gt;“How Newton Discovered the Law of Gravitation ”, Miller 1951&lt;/item&gt;&lt;item&gt;“A Royal Practical Joke ”, Oesper 1948&lt;/item&gt;&lt;item&gt;“Investigations of a Dog ”, Kafka et al 1922&lt;/item&gt;&lt;item&gt;“The Chaos ”, Trenité 1922&lt;/item&gt;&lt;item&gt;“Some Unattractive Meta-Ethical Positions, Free to a Good Home ”&lt;/item&gt;&lt;item&gt;“Theological Engineering Exam ”, Anonymous 2025&lt;/item&gt;&lt;item&gt;“Center for the Alignment of AI Alignment Centers ”&lt;/item&gt;&lt;item&gt;“Bahfest ”&lt;/item&gt;&lt;item&gt;“Determining Cat Chirality ”&lt;/item&gt;&lt;item&gt;The Space Child’s Mother Goose, Regehr 2025&lt;/item&gt;&lt;item&gt;“How to Install Linux on a Dead Badger ”&lt;/item&gt;&lt;item&gt;“&lt;code&gt;roguetype&lt;/code&gt;: The First Ever Rogue-Like Written in the OCaml Type System ”, Octachron 2025&lt;/item&gt;&lt;item&gt;“Extremely Linear Git History ”, zegl 2025&lt;/item&gt;&lt;item&gt;“The Hardest Chess Problem in the World? ”&lt;/item&gt;&lt;item&gt;“HTTP Cats ”&lt;/item&gt;&lt;item&gt;“Is the Great Attractor a Tengen Toppa Gurren Lagann? ”&lt;/item&gt;&lt;item&gt;“King James Programming ”&lt;/item&gt;&lt;item&gt;“Occupy Babel! ”&lt;/item&gt;&lt;item&gt;“The New Economics of Chess ”&lt;/item&gt;&lt;item&gt;“How Can I Draw a Homer Simpson With Epicycloids? ”&lt;/item&gt;&lt;item&gt;“A Congress of Robert Reichs ”&lt;/item&gt;&lt;item&gt;“Does Garlic Protect against Vampires? An Experimental Study ”&lt;/item&gt;&lt;item&gt;“Blogging versus Blog Setups ”&lt;/item&gt;&lt;item&gt;“The Association for Computational Heresy ”&lt;/item&gt;&lt;item&gt;“SIGBOVIK 2019 ”&lt;/item&gt;&lt;item&gt;“Turing-Complete Chess Computation ”&lt;/item&gt;&lt;item&gt;“How to Burn a Magnesium NeXT Cube ”&lt;/item&gt;&lt;item&gt;“Opinions of Doron Zeilberger ”, Zeilberger 2025&lt;/item&gt;&lt;item&gt;“Akin’s Laws of Spacecraft Design ”&lt;/item&gt;&lt;item&gt;“Futurama Theorem ”&lt;/item&gt;&lt;item&gt;“Sheepview360 ”&lt;/item&gt;&lt;item&gt;“Scunthorpe Sans: a Profanity-Blocking Font ”&lt;/item&gt;&lt;item&gt;“Computer Error Haikus ”, WikiWikiWeb 2025&lt;/item&gt;&lt;item&gt;“Population Dynamics in Madoka ”&lt;/item&gt;&lt;item&gt;“BMJ Christmas Issue ”&lt;/item&gt;&lt;item&gt;“The Roentgen Standard ”, Niven 2025&lt;/item&gt;&lt;item&gt;“VDT: a Solution to Decision Theory ”&lt;/item&gt;&lt;item&gt;“Voo Doo: the MIT Journal of Rational Disco and Campus Intercourse ”&lt;/item&gt;&lt;item&gt;“The Most Popular Chess Streamer on Twitch ”&lt;/item&gt;&lt;item&gt;“What Are You Paying For in a $300 Chess Set? Mostly the Knights ”&lt;/item&gt;&lt;item&gt;“How Magnus Carlsen Turned Chess Skill Into a Business Empire ”&lt;/item&gt;&lt;item&gt;“[A Magic: The Gathering Combo That Deals Infinite Damage If the Twin Prime Conjecture Is True] ”&lt;/item&gt;&lt;item&gt;“Frayn’s Spoof of Wittgenstein ”&lt;/item&gt;&lt;item&gt;“Seraphim: An Angelic Conlang for Agma Schwa’s Cursed Conlang Contest ”&lt;/item&gt;&lt;item&gt;“Harder Drive: Hard Drives We Didn’t Want or Need ”, tom7 2025&lt;/item&gt;&lt;item&gt;“Ptolemy and Homer (Simpson) ”&lt;/item&gt;&lt;item&gt;erowidrecruiter&lt;/item&gt;&lt;item&gt;kimkierkegaard&lt;/item&gt;&lt;item&gt;“Random Number ”, Munroe 2025&lt;/item&gt;&lt;item&gt;“Bracket Symbols ”, Munroe 2025&lt;/item&gt;&lt;item&gt;“Correlation ”, Munroe 2025&lt;/item&gt;&lt;item&gt;Sort By Magic&lt;/item&gt;&lt;item&gt;Wikipedia (19)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Miscellaneous&lt;/item&gt;
      &lt;item&gt;Bibliography&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;See Also&lt;/head&gt;
    &lt;head rend="h1"&gt;Gwern&lt;/head&gt;
    &lt;head rend="h2"&gt;“Conference Fermi Problems ”, Gwern 2025&lt;/head&gt;
    &lt;head rend="h2"&gt;“Human Cannibalism Alignment Chart ”, Gwern et al 2025&lt;/head&gt;
    &lt;head rend="h2"&gt;“The Meta-LW Doomsday Argument ”, Gwern 2025&lt;/head&gt;
    &lt;head rend="h2"&gt;“Estimated Cost of DMT Machine Elf Prime Factorization Experiment ”, Gwern 2015&lt;/head&gt;
    &lt;p&gt;Estimated Cost of DMT Machine Elf Prime Factorization Experiment&lt;/p&gt;
    &lt;head rend="h2"&gt;“A Christmas Protestation ”, o1-pro et al 2024&lt;/head&gt;
    &lt;head rend="h2"&gt;“Second Life Sentences ”, Gwern 2024&lt;/head&gt;
    &lt;head rend="h2"&gt;“The Carcinisation of Satan ”, Gwern 2024&lt;/head&gt;
    &lt;head rend="h2"&gt;“On the Impossibility of Superintelligent Rubik’s Cube Solvers ”, Gwern et al 2023&lt;/head&gt;
    &lt;p&gt;On the Impossibility of Superintelligent Rubik’s Cube Solvers&lt;/p&gt;
    &lt;head rend="h2"&gt;“Paperclip Alignment Chart ”, Gwern 2023&lt;/head&gt;
    &lt;head rend="h2"&gt;“Rare Greek Variables ”, Gwern 2021&lt;/head&gt;
    &lt;head rend="h2"&gt;“Gilles Goullet, Author of the Blindsight ”, Gwern 2010&lt;/head&gt;
    &lt;head rend="h1"&gt;Links&lt;/head&gt;
    &lt;head rend="h2"&gt;“Placebo Emporium: 2025 Annual Shareholder Letter ”, Troesh 2025&lt;/head&gt;
    &lt;head rend="h2"&gt;“The Fine Art of Being Too Dumb to Regulate; Or: How I Learned to Stop Worrying and Love Betting on Earnings Buzzwords ”, Vagabonds 2025&lt;/head&gt;
    &lt;head rend="h2"&gt;“My Antichrist Lecture: Forecasting Transformative AI Using the Book of Revelation [Anthropic gematria] ”, Alexander 2025&lt;/head&gt;
    &lt;head rend="h2"&gt;“Gwern Visits BAIR ”, Liu 2025&lt;/head&gt;
    &lt;head rend="h2"&gt;The Way of Code: The Timeless Art of Vibe Coding, Rubin 2025&lt;/head&gt;
    &lt;head rend="h2"&gt;“[Social Acceptability of Eating Human Meat Alignment Chart] ”, Hero 2025&lt;/head&gt;
    &lt;p&gt;[Social acceptability of eating human meat alignment chart] :&lt;/p&gt;
    &lt;head rend="h2"&gt;“You Can Never Reproduce The Same Bug Twice [Demotivational Poster] ”, Gwern 2025&lt;/head&gt;
    &lt;p&gt;You Can Never Reproduce The Same Bug Twice [demotivational poster]&lt;/p&gt;
    &lt;head rend="h2"&gt;“NeuRaLaTeX: A Machine Learning Library Written in Pure LaTeX ”, Gardner et al 2025&lt;/head&gt;
    &lt;p&gt;NeuRaLaTeX: A machine learning library written in pure LaTeX&lt;/p&gt;
    &lt;head rend="h2"&gt;“Regex Chess: A 2-Ply Minimax Chess Engine in 84,688 Regular Expressions ”, Carlini 2025&lt;/head&gt;
    &lt;p&gt;Regex Chess: A 2-ply minimax chess engine in 84,688 regular expressions&lt;/p&gt;
    &lt;head rend="h2"&gt;“Trajectoid ”, Weinersmith 2024&lt;/head&gt;
    &lt;head rend="h2"&gt;“Age against the Machine—Susceptibility of Large Language Models to Cognitive Impairment: Cross Sectional Analysis ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“A Numerical Evaluation of the Finite Monkeys Theorem ”, Woodcock &amp;amp; Falletta 2024&lt;/head&gt;
    &lt;head rend="h2"&gt;“How a Silly Science Prize Changed My Career: A Levitating Frog, a Necrophiliac Duck, Taxi Drivers’ Brains—The Ig Nobel Prizes Have Shined a Spotlight on Offbeat Work. Here’s an inside Look at How Winners Feel about This Sometimes Unwanted ‘Honor’ ”, Clarke 2024&lt;/head&gt;
    &lt;head rend="h2"&gt;“On the Impossibility of Superintelligent Rubik’s Cube Solvers [Claude-3.5-Sonnet] ”, Claude-3 2024&lt;/head&gt;
    &lt;p&gt;On the Impossibility of Superintelligent Rubik’s Cube Solvers [Claude-3.5-sonnet]&lt;/p&gt;
    &lt;head rend="h2"&gt;“Towel Day: The Aerodynamics of Freefalling Sperm Whales [Terminal Velocity: 178.3 M/s] ”, Ferguson 2024&lt;/head&gt;
    &lt;p&gt;Towel Day: The Aerodynamics of Freefalling Sperm Whales [terminal velocity: 178.3 m/s] :&lt;/p&gt;
    &lt;head rend="h2"&gt;“A Programming Language Embedded in Magic: The Gathering ”, Yin &amp;amp; Churchill 2024&lt;/head&gt;
    &lt;head rend="h2"&gt;“An Abundance of Katherines: The Game Theory of Baby Naming ”, Blumer et al 2024&lt;/head&gt;
    &lt;head rend="h2"&gt;“Are We Safe from Lightning Inside Buildings? A Study of Lightning Fatalities Inside Buildings Using Smartphones ”, Souza et al 2024&lt;/head&gt;
    &lt;head rend="h2"&gt;“Polyamorous Scheduling ”, Gąsieniec et al 2024&lt;/head&gt;
    &lt;head rend="h2"&gt;“An Incomplete Primer of Caselaw Appertaining To Bigfoot, AKA Sasquatch, LNU ”, White 2024&lt;/head&gt;
    &lt;p&gt;An Incomplete Primer of Caselaw Appertaining To Bigfoot, AKA Sasquatch, LNU&lt;/p&gt;
    &lt;head rend="h2"&gt;“IOCCC 2024: Stedolan—Best One Liner ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“Paperclip Alignment Chart (Alternate) ”, saturn2 2023&lt;/head&gt;
    &lt;head rend="h2"&gt;“A LLM Assisted Exploitation of AI-Guardian ”, Carlini 2023&lt;/head&gt;
    &lt;head rend="h2"&gt;“Can a Good Philosophical Contribution Be Made Just by Asking a Question? ”, Habgood-Coote et al 2022&lt;/head&gt;
    &lt;p&gt;Can a good philosophical contribution be made just by asking a question?&lt;/p&gt;
    &lt;head rend="h2"&gt;“Immaterials and Methods: Reagents for the Total Laboratory Synthesis of the Chocolate Chip Cookie ”, Schlonk 2022&lt;/head&gt;
    &lt;p&gt;Immaterials and Methods: Reagents for the Total Laboratory Synthesis of the Chocolate Chip Cookie :&lt;/p&gt;
    &lt;p&gt;View PDF:&lt;/p&gt;
    &lt;head rend="h2"&gt;“A Modest Spelling Reform to Increase Autologicity, Symmetry, and Readability ”&lt;/head&gt;
    &lt;p&gt;A modest spelling reform to increase autologicity, symmetry, and readability&lt;/p&gt;
    &lt;head rend="h2"&gt;“Rare Greek Variables ”, Bayer 2021&lt;/head&gt;
    &lt;head rend="h2"&gt;“Flinch ”, Munroe 2021&lt;/head&gt;
    &lt;head rend="h2"&gt;“Proposed Detection of Ghosts by Mass Spectrometry-Spectral Presence Origin-Omics Kinetic Yield (MS-SPOOKY) ”, Schlonk 2021&lt;/head&gt;
    &lt;head rend="h2"&gt;“Are Cats Good? An Important Study ”, Owen &amp;amp; Lamon 2021b&lt;/head&gt;
    &lt;head rend="h2"&gt;“My Cat Chester’s Dynamical Systems Analysyyyyy7777777777777777y7is of the Laser Pointer and the Red Dot on the Wall: Correlation, Causation, or SARS-Cov-2 Hallucination? ”, Armstrong &amp;amp; Chester 2021&lt;/head&gt;
    &lt;head rend="h2"&gt;“How Fast Can Evangelion Run? Application Of Aerodynamics And Scaling Laws To The Super Robot ”, Ryu et al 2020&lt;/head&gt;
    &lt;p&gt;How Fast Can Evangelion Run? Application Of Aerodynamics And Scaling Laws To The Super Robot&lt;/p&gt;
    &lt;head rend="h2"&gt;“The Treachery of Image Files ”, Earnest 2020&lt;/head&gt;
    &lt;head rend="h2"&gt;“My Immortal As Alchemical Allegory ”, Alexander 2020&lt;/head&gt;
    &lt;head rend="h2"&gt;“Single Headed Attention RNN: Stop Thinking With Your Head ”, Merity 2019&lt;/head&gt;
    &lt;head rend="h2"&gt;“A Mulching Proposal ”, Keyes et al 2019&lt;/head&gt;
    &lt;head rend="h2"&gt;“30 Weird Chess Algorithms: Elo World ”, Tom7 2019&lt;/head&gt;
    &lt;head rend="h2"&gt;“Real Numbers, Data Science and Chaos: How to Fit Any Dataset With a Single Parameter ”, Boué 2019&lt;/head&gt;
    &lt;p&gt;Real numbers, data science and chaos: How to fit any dataset with a single parameter&lt;/p&gt;
    &lt;head rend="h2"&gt;“Spooky Fizz Buzz § Pg42 ”, Menghrajani 2019 (page 42)&lt;/head&gt;
    &lt;head rend="h2"&gt;“Blueberry Earth ”, Sandberg 2018&lt;/head&gt;
    &lt;head rend="h2"&gt;“The Random Walk of Cars and Their Collision Probabilities With Planets ”, Rein et al 2018&lt;/head&gt;
    &lt;p&gt;The Random Walk of Cars and Their Collision Probabilities with Planets&lt;/p&gt;
    &lt;head rend="h2"&gt;“Super-Earths in Need for Extremely Big Rockets ”, Hippke 2018&lt;/head&gt;
    &lt;head rend="h2"&gt;“It’s a Man Eat Man World ”, Graham et al 2017&lt;/head&gt;
    &lt;head rend="h2"&gt;“How Sheep With Cameras Got Some Tiny Islands onto Google Street View ”, Brulliard 2017&lt;/head&gt;
    &lt;p&gt;How sheep with cameras got some tiny islands onto Google Street View&lt;/p&gt;
    &lt;head rend="h2"&gt;“Factoring in the Chicken McNugget Monoid ”, Chapman &amp;amp; O’Neill 2017&lt;/head&gt;
    &lt;head rend="h2"&gt;“F—K Nuance ”, Healy 2017&lt;/head&gt;
    &lt;head rend="h2"&gt;“On the Impossibility of Supersized Machines ”, Garfinkel et al 2017&lt;/head&gt;
    &lt;head rend="h2"&gt;“Seasonality of Auricular Amputations in Rabbits ”, Yaremchuk et al 2017&lt;/head&gt;
    &lt;head rend="h2"&gt;“Sheep View: Where There’s a Wool, There’s a Way ”, Vega 2016&lt;/head&gt;
    &lt;head rend="h2"&gt;“Identifying the Source of Perytons at the Parkes Radio Telescope ”, Petroff et al 2015&lt;/head&gt;
    &lt;p&gt;Identifying the source of perytons at the Parkes radio telescope&lt;/p&gt;
    &lt;head rend="h2"&gt;“Optimal Tip-To-Tip Efficiency: a Model for Male Audience Stimulation ”, Chugtai &amp;amp; Gilfoyle 2014&lt;/head&gt;
    &lt;p&gt;Optimal Tip-to-Tip Efficiency: a model for male audience stimulation&lt;/p&gt;
    &lt;head rend="h2"&gt;“Heaven Is Hotter Than Hell &amp;amp; A Refutation ”, Simanek 2014&lt;/head&gt;
    &lt;head rend="h2"&gt;“A Few Goodmen: Surname-Sharing Economist Coauthors ”, Goodman et al 2014&lt;/head&gt;
    &lt;head rend="h2"&gt;“Two Curious Integrals and a Graphic Proof ”, Schmid 2014&lt;/head&gt;
    &lt;p&gt;Two curious integrals and a graphic proof :&lt;/p&gt;
    &lt;p&gt;View PDF:&lt;/p&gt;
    &lt;head rend="h2"&gt;“Searching the Internet for Evidence of Time Travelers ”, Nemiroff &amp;amp; Wilson 2013&lt;/head&gt;
    &lt;head rend="h2"&gt;“XKCD Plots Have Landed in Matplotlib! ”&lt;/head&gt;
    &lt;p&gt;XKCD Plots have Landed in Matplotlib! :&lt;/p&gt;
    &lt;p&gt;View External Link:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;https://jakevdp.github.io/blog/2013/07/10/XKCD-plots-in-matplotlib/&lt;/code&gt;
    &lt;/p&gt;
    &lt;head rend="h2"&gt;“[What Deals Should the Devil Optimally Betray in Any given Social Graph?] ”, Schou 2013&lt;/head&gt;
    &lt;p&gt;[What deals should the Devil optimally betray in any given social graph?] :&lt;/p&gt;
    &lt;head rend="h2"&gt;“Robert Bunsen’s Sweet Tooth ”, Jensen 2013&lt;/head&gt;
    &lt;head rend="h2"&gt;“Your Right Arm For A Publication In AER? ”, Attema et al 2013&lt;/head&gt;
    &lt;head rend="h2"&gt;“Vigil, the Eternal Morally Vigilant Programming Language ”, munificent 2013&lt;/head&gt;
    &lt;head rend="h2"&gt;“The Survival Time of Chocolates on Hospital Wards: Covert Observational Study ”, Gajendragadkar et al 2013&lt;/head&gt;
    &lt;p&gt;The survival time of chocolates on hospital wards: covert observational study&lt;/p&gt;
    &lt;head rend="h2"&gt;“Possible Bubbles of Spacetime Curvature in the South Pacific ”, Tippett 2012&lt;/head&gt;
    &lt;p&gt;Possible Bubbles of Spacetime Curvature in the South Pacific&lt;/p&gt;
    &lt;head rend="h2"&gt;“On the Tumbling Toast Problem ”, Borghi 2012&lt;/head&gt;
    &lt;head rend="h2"&gt;“Robust Soldier Crab Ball Gate ”, Gunji et al 2012&lt;/head&gt;
    &lt;head rend="h2"&gt;“Non-Detection of the Tooth Fairy at Optical Wavelengths ”, Armstrong 2012&lt;/head&gt;
    &lt;head rend="h2"&gt;“Gods As Topological Invariants ”, Schoch 2012&lt;/head&gt;
    &lt;head rend="h2"&gt;“Tiramisu [Lexical Gaps in English Borrowing from Latin] ”, Pullum 2011&lt;/head&gt;
    &lt;head rend="h2"&gt;“A Parasite from Outer Space: How Sergei Kurekhin Proved That Lenin Was a Mushroom ”, Yurchak 2011&lt;/head&gt;
    &lt;p&gt;A Parasite from Outer Space: How Sergei Kurekhin Proved That Lenin Was a Mushroom&lt;/p&gt;
    &lt;head rend="h2"&gt;“Quantum Computation With Devices Whose Contents Are Never Read ”, Yakaryilmaz et al 2010&lt;/head&gt;
    &lt;p&gt;Quantum computation with devices whose contents are never read&lt;/p&gt;
    &lt;head rend="h2"&gt;“The Optimal Taxation of Height: A Case Study of Utilitarian Income Redistribution ”, Mankiw &amp;amp; Weinzierl 2010&lt;/head&gt;
    &lt;p&gt;The Optimal Taxation of Height: A Case Study of Utilitarian Income Redistribution&lt;/p&gt;
    &lt;head rend="h2"&gt;“Are Birds Smarter Than Mathematicians? Pigeons (Columba Livia) Perform Optimally on a Version of the Monty Hall Dilemma ”, Herbranson &amp;amp; Schroeder 2010&lt;/head&gt;
    &lt;head rend="h2"&gt;“The Name Is Shrdlu… Etaoin Shrdlu ”, D. 2009&lt;/head&gt;
    &lt;head rend="h2"&gt;“Woosh: A Wonderful Object-Oriented Shell Environment [Unix Directories As Objects] ”, mhinsch 2009&lt;/head&gt;
    &lt;p&gt;Woosh: A wonderful object-oriented shell environment [Unix directories as objects]&lt;/p&gt;
    &lt;head rend="h2"&gt;“Time Variation of a Fundamental Dimensionless Constant ”, Scherrer 2009&lt;/head&gt;
    &lt;head rend="h2"&gt;“Japan’s Phillips Curve Looks Like Japan ”, Smith 2008&lt;/head&gt;
    &lt;head rend="h2"&gt;“BREATHTAKING Design Strategy ”, Group 2008&lt;/head&gt;
    &lt;head rend="h2"&gt;“Possible Girls ”, Sinhababu 2008&lt;/head&gt;
    &lt;head rend="h2"&gt;“Down-Sizing Forever ”, Scott &amp;amp; Frolop 2008&lt;/head&gt;
    &lt;head rend="h2"&gt;The SICP Saga, Anonymous 2008&lt;/head&gt;
    &lt;head rend="h2"&gt;“Rugby (The Religion of Wales) and Its Influence on the Catholic Church: Should Pope Benedict XVI Be Worried? ”, Payne 2008&lt;/head&gt;
    &lt;head rend="h2"&gt;“Of Cinema, Food, and Desire: Franz Kafka’s ‘Investigations of a Dog’ ”, Williams 2007&lt;/head&gt;
    &lt;p&gt;Of Cinema, Food, and Desire: Franz Kafka’s ‘Investigations of a Dog’&lt;/p&gt;
    &lt;head rend="h2"&gt;“Sex, Aggression, and Humour: Responses to Unicycling ”, Shuster 2007&lt;/head&gt;
    &lt;head rend="h2"&gt;“The Wisdom of Hendrik W. Lenstra Junior ”, Magidin 2006&lt;/head&gt;
    &lt;head rend="h2"&gt;“Serge Lang, 1927–2005 § Part 1: Paul Vojta, University of California, Berkeley ”, Jorgenson &amp;amp; Krantz 2006 (page 12)&lt;/head&gt;
    &lt;p&gt;Serge Lang, 1927–2005 § Part 1: Paul Vojta, University of California, Berkeley&lt;/p&gt;
    &lt;head rend="h2"&gt;“We Are Sorry to Inform You... ”, Santini 2005&lt;/head&gt;
    &lt;head rend="h2"&gt;“A Box, Darkly: Obfuscation, Weird Languages, and Code Esthetics ”, Mateas &amp;amp; Montfort 2005&lt;/head&gt;
    &lt;p&gt;A Box, Darkly: Obfuscation, Weird Languages, and Code esthetics&lt;/p&gt;
    &lt;head rend="h2"&gt;“Patent Office Annual Performance Review: Albert Einstein ”, Norvig 2005&lt;/head&gt;
    &lt;head rend="h2"&gt;“The Case of the Disappearing Teaspoons: Longitudinal Cohort Study of the Displacement of Teaspoons in an Australian Research Institute ”, Lim et al 2005&lt;/head&gt;
    &lt;head rend="h2"&gt;“Lewis Carroll’s Humpty Dumpty: an Early Report of Prosopagnosia? ”, Larner 2004&lt;/head&gt;
    &lt;p&gt;Lewis Carroll’s Humpty Dumpty: an early report of prosopagnosia? :&lt;/p&gt;
    &lt;p&gt;View PDF:&lt;/p&gt;
    &lt;head rend="h2"&gt;“Some AI Koans § Http://www.catb.org/esr/jargon/html/koans.html#id3141241 ”, Raymond 2003&lt;/head&gt;
    &lt;p&gt;Some AI Koans § http://www.catb.org/esr/jargon/html/koans.html#id3141241 :&lt;/p&gt;
    &lt;head rend="h2"&gt;“Some AI Koans ”, Raymond 2003&lt;/head&gt;
    &lt;head rend="h2"&gt;“Electron Band Structure In Germanium, My Ass ”, Kovar 2002&lt;/head&gt;
    &lt;head rend="h2"&gt;“A Tour of Accounting: Random Number Generator [Dilbert] ”, Adams 2001&lt;/head&gt;
    &lt;head rend="h2"&gt;“The Temperature of Heaven and Hell [Retrospective] ”, Pérez 2001&lt;/head&gt;
    &lt;p&gt;The temperature of heaven and hell [retrospective] :&lt;/p&gt;
    &lt;p&gt;View PDF:&lt;/p&gt;
    &lt;head rend="h2"&gt;“Storks Deliver Babies (p = 0.008) ”, Matthews 2001&lt;/head&gt;
    &lt;head rend="h2"&gt;“Some Remarkable Properties of Sinc and Related Integrals ”, Borwein &amp;amp; Borwein 2001&lt;/head&gt;
    &lt;head rend="h2"&gt;“A Closer Look at Tumbling Toast ”, Bacon et al 2001&lt;/head&gt;
    &lt;head rend="h2"&gt;“The Evolution of a Haskell Programmer ”, Ruehr 2001&lt;/head&gt;
    &lt;head rend="h2"&gt;“Is Hell Endothermic or Exothermic? Old Collegiate Legend Involves a Student’s Coming up With a Clever Proof about the Physical Properties of Hell ”, Mikkelson 2000&lt;/head&gt;
    &lt;head rend="h2"&gt;“Area Man Consults Internet Whenever Possible ”, Onion 2000&lt;/head&gt;
    &lt;head rend="h2"&gt;“A Letter from the Frustrated Author of a Journal Paper ”, Glass 2000&lt;/head&gt;
    &lt;p&gt;A letter from the frustrated author of a journal paper :&lt;/p&gt;
    &lt;p&gt;View PDF:&lt;/p&gt;
    &lt;head rend="h2"&gt;“What Do Animals Do All Day? The Division of Labor, Class Bodies, and Totemic Thinking in the Popular Imagination ”, Martin 2000&lt;/head&gt;
    &lt;p&gt;View PDF:&lt;/p&gt;
    &lt;head rend="h2"&gt;“Klingon Programmers ”, Baker 1999&lt;/head&gt;
    &lt;head rend="h2"&gt;“I M A G I N E ”, Krishnamurthi 1996&lt;/head&gt;
    &lt;head rend="h2"&gt;“Tumbling Toast, Murphy’s Law and the Fundamental Constants ”, Matthews 1995&lt;/head&gt;
    &lt;head rend="h2"&gt;“Knockdown Arguments ”, Wreen 1995&lt;/head&gt;
    &lt;head rend="h2"&gt;“The Love Song of J. Random Hacker ”, Duntemann 1995&lt;/head&gt;
    &lt;head rend="h2"&gt;“(Para)bosons, (Para)fermions, Quons and Other Beasts in the Menagerie of Particle Statistics ”, Greenberg et al 1993&lt;/head&gt;
    &lt;p&gt;(Para)bosons, (para)fermions, quons and other beasts in the menagerie of particle statistics&lt;/p&gt;
    &lt;head rend="h2"&gt;“Szeged in 1934 ”, Lorch &amp;amp; Hersh 1993&lt;/head&gt;
    &lt;p&gt;View PDF:&lt;/p&gt;
    &lt;head rend="h2"&gt;Geoffrey Sonnabend: Obliscence, Theories of Forgetting and the Problem of Matter—An Encapsulation (Fourth Edition, Abridged), Worth 1991&lt;/head&gt;
    &lt;head rend="h2"&gt;“Mustard Watches: An Integrated Approach To Time and Food ”, Ringard et al 1990&lt;/head&gt;
    &lt;head rend="h2"&gt;“What’s Wrong With This Lagrangean? ”, Mermin 1988&lt;/head&gt;
    &lt;head rend="h2"&gt;“Presentation Announcement / Automatic Weapons, Parts I–III ”, Shivers 1987&lt;/head&gt;
    &lt;p&gt;Presentation announcement / Automatic weapons, parts I–III :&lt;/p&gt;
    &lt;head rend="h2"&gt;“Humour: The Interdisciplinary Denominator in Science ”, Kohn 1982&lt;/head&gt;
    &lt;head rend="h2"&gt;“An Epistemological Nightmare ”, Smullyan 1982&lt;/head&gt;
    &lt;head rend="h2"&gt;“Child’s Play: A Distorting Factor in Archaeological Distribution ”, Hammond &amp;amp; Hammond 1981&lt;/head&gt;
    &lt;p&gt;Child’s Play: A Distorting Factor in Archaeological Distribution&lt;/p&gt;
    &lt;head rend="h2"&gt;“A Rebuke of A. B. Smith‘s Paper, 'A Note on Piffles’ ”, Farlow 1980&lt;/head&gt;
    &lt;p&gt;A rebuke of A. B. Smith‘s paper, 'A Note on Piffles’ :&lt;/p&gt;
    &lt;p&gt;View PDF:&lt;/p&gt;
    &lt;head rend="h2"&gt;“Paul Darwin Foote (1888–1971) § The Temperature of Heaven &amp;amp; Hell ”, Astin 1979 (page 12)&lt;/head&gt;
    &lt;p&gt;Paul Darwin Foote (1888–1971) § The Temperature of Heaven &amp;amp; Hell&lt;/p&gt;
    &lt;head rend="h2"&gt;“The First Sally (A), Or, Trurl’s Electronic Bard § Love And Tensor Algebra ”, Lem &amp;amp; Kandel 1974 (page 7)&lt;/head&gt;
    &lt;p&gt;The First Sally (A), or, Trurl’s Electronic Bard § Love And Tensor Algebra :&lt;/p&gt;
    &lt;head rend="h2"&gt;“Principia Discordia (1970) ”&lt;/head&gt;
    &lt;p&gt;View External Link:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;https://en.wikisource.org/wiki/Page:Principia_Discordia_(1970).djvu/19&lt;/code&gt;
    &lt;/p&gt;
    &lt;head rend="h2"&gt;“On the Enfeeblement of Mathematical Skills by ‘Modern Mathematics’ and by Similar Soft Intellectual Trash in Schools and Universities ”, Hammersley 1968&lt;/head&gt;
    &lt;p&gt;View PDF:&lt;/p&gt;
    &lt;head rend="h2"&gt;“A Note On Piffles, By A. B. Smith ”, Austin 1967&lt;/head&gt;
    &lt;p&gt;A Note On Piffles, By A. B. Smith :&lt;/p&gt;
    &lt;p&gt;View PDF:&lt;/p&gt;
    &lt;head rend="h2"&gt;A Stress Analysis of a Strapless Evening Gown: Essays for a Scientific Age, Baker 1963&lt;/head&gt;
    &lt;p&gt;A Stress Analysis of a Strapless Evening Gown: Essays for a Scientific Age :&lt;/p&gt;
    &lt;head rend="h2"&gt;“On The Nature Of Mathematical Proof ”, Cohen 1961&lt;/head&gt;
    &lt;p&gt;On The Nature Of Mathematical Proof :&lt;/p&gt;
    &lt;p&gt;View PDF:&lt;/p&gt;
    &lt;head rend="h2"&gt;“Hiawatha’s Lipid ”, Sinclair 1960&lt;/head&gt;
    &lt;head rend="h2"&gt;“Mathmanship ”, Vanserg 1958&lt;/head&gt;
    &lt;p&gt;View PDF:&lt;/p&gt;
    &lt;head rend="h2"&gt;“How to Write Geologese ”, Vansberg 1952&lt;/head&gt;
    &lt;p&gt;View PDF:&lt;/p&gt;
    &lt;head rend="h2"&gt;“How Newton Discovered the Law of Gravitation ”, Miller 1951&lt;/head&gt;
    &lt;p&gt;How Newton Discovered the Law of Gravitation :&lt;/p&gt;
    &lt;p&gt;View PDF:&lt;/p&gt;
    &lt;head rend="h2"&gt;“A Royal Practical Joke ”, Oesper 1948&lt;/head&gt;
    &lt;head rend="h2"&gt;“Investigations of a Dog ”, Kafka et al 1922&lt;/head&gt;
    &lt;head rend="h2"&gt;“The Chaos ”, Trenité 1922&lt;/head&gt;
    &lt;head rend="h2"&gt;“Some Unattractive Meta-Ethical Positions, Free to a Good Home ”&lt;/head&gt;
    &lt;p&gt;Some Unattractive Meta-Ethical Positions, Free to a Good Home :&lt;/p&gt;
    &lt;head rend="h2"&gt;“Theological Engineering Exam ”, Anonymous 2025&lt;/head&gt;
    &lt;head rend="h2"&gt;“Center for the Alignment of AI Alignment Centers ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“Bahfest ”&lt;/head&gt;
    &lt;p&gt;Bahfest :&lt;/p&gt;
    &lt;head rend="h2"&gt;“Determining Cat Chirality ”&lt;/head&gt;
    &lt;head rend="h2"&gt;The Space Child’s Mother Goose, Regehr 2025&lt;/head&gt;
    &lt;head rend="h2"&gt;“How to Install Linux on a Dead Badger ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“&lt;code&gt;roguetype&lt;/code&gt;: The First Ever Rogue-Like Written in the OCaml Type System ”, Octachron 2025&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;roguetype&lt;/code&gt;: The first ever rogue-like written in the OCaml type system&lt;/p&gt;
    &lt;head rend="h2"&gt;“Extremely Linear Git History ”, zegl 2025&lt;/head&gt;
    &lt;head rend="h2"&gt;“The Hardest Chess Problem in the World? ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“HTTP Cats ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“Is the Great Attractor a Tengen Toppa Gurren Lagann? ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“King James Programming ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“Occupy Babel! ”&lt;/head&gt;
    &lt;p&gt;View External Link:&lt;/p&gt;
    &lt;head rend="h2"&gt;“The New Economics of Chess ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“How Can I Draw a Homer Simpson With Epicycloids? ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“A Congress of Robert Reichs ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“Does Garlic Protect against Vampires? An Experimental Study ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“Blogging versus Blog Setups ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“The Association for Computational Heresy ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“SIGBOVIK 2019 ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“Turing-Complete Chess Computation ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“How to Burn a Magnesium NeXT Cube ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“Opinions of Doron Zeilberger ”, Zeilberger 2025&lt;/head&gt;
    &lt;head rend="h2"&gt;“Akin’s Laws of Spacecraft Design ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“Futurama Theorem ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“Sheepview360 ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“Scunthorpe Sans: a Profanity-Blocking Font ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“Computer Error Haikus ”, WikiWikiWeb 2025&lt;/head&gt;
    &lt;head rend="h2"&gt;“Population Dynamics in Madoka ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“BMJ Christmas Issue ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“The Roentgen Standard ”, Niven 2025&lt;/head&gt;
    &lt;head rend="h2"&gt;“VDT: a Solution to Decision Theory ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“Voo Doo: the MIT Journal of Rational Disco and Campus Intercourse ”&lt;/head&gt;
    &lt;p&gt;Voo Doo: the MIT Journal of Rational Disco and Campus Intercourse&lt;/p&gt;
    &lt;head rend="h2"&gt;“The Most Popular Chess Streamer on Twitch ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“What Are You Paying For in a $300 Chess Set? Mostly the Knights ”&lt;/head&gt;
    &lt;p&gt;What Are You Paying For in a $300 Chess Set? Mostly the Knights&lt;/p&gt;
    &lt;head rend="h2"&gt;“How Magnus Carlsen Turned Chess Skill Into a Business Empire ”&lt;/head&gt;
    &lt;p&gt;How Magnus Carlsen Turned Chess Skill Into a Business Empire&lt;/p&gt;
    &lt;head rend="h2"&gt;“[A Magic: The Gathering Combo That Deals Infinite Damage If the Twin Prime Conjecture Is True] ”&lt;/head&gt;
    &lt;p&gt;[A Magic: The Gathering combo that deals infinite damage if the Twin Prime Conjecture is true] :&lt;/p&gt;
    &lt;head rend="h2"&gt;“Frayn’s Spoof of Wittgenstein ”&lt;/head&gt;
    &lt;head rend="h2"&gt;“Seraphim: An Angelic Conlang for Agma Schwa’s Cursed Conlang Contest ”&lt;/head&gt;
    &lt;p&gt;Seraphim: An Angelic Conlang for Agma Schwa’s Cursed Conlang Contest :&lt;/p&gt;
    &lt;head rend="h2"&gt;“Harder Drive: Hard Drives We Didn’t Want or Need ”, tom7 2025&lt;/head&gt;
    &lt;head rend="h2"&gt;“Ptolemy and Homer (Simpson) ”&lt;/head&gt;
    &lt;head rend="h2"&gt;erowidrecruiter&lt;/head&gt;
    &lt;head rend="h2"&gt;kimkierkegaard&lt;/head&gt;
    &lt;head rend="h2"&gt;“Random Number ”, Munroe 2025&lt;/head&gt;
    &lt;head rend="h2"&gt;“Bracket Symbols ”, Munroe 2025&lt;/head&gt;
    &lt;p&gt;View External Link:&lt;/p&gt;
    &lt;head rend="h2"&gt;“Correlation ”, Munroe 2025&lt;/head&gt;
    &lt;p&gt;View External Link:&lt;/p&gt;
    &lt;head rend="h2"&gt;Sort By Magic&lt;/head&gt;
    &lt;p&gt;Annotations sorted by machine learning into inferred 'tags'. This provides an alternative way to browse: instead of by date order, one can browse in topic order. The 'sorted' list has been automatically clustered into multiple sections &amp;amp; auto-labeled for easier browsing.&lt;/p&gt;
    &lt;p&gt;Beginning with the newest annotation, it uses the embedding of each annotation to attempt to create a list of nearest-neighbor annotations, creating a progression of topics. For more details, see the link.&lt;/p&gt;
    &lt;head rend="h3"&gt;
      &lt;code&gt;playful-absurdity&lt;/code&gt;
    &lt;/head&gt;
    &lt;head rend="h3"&gt;
      &lt;code&gt;demotivational-comedy&lt;/code&gt;
    &lt;/head&gt;
    &lt;head rend="h3"&gt;
      &lt;code&gt;absurd-intelligence&lt;/code&gt;
    &lt;/head&gt;
    &lt;head rend="h3"&gt;
      &lt;code&gt;weird-algorithms&lt;/code&gt;
    &lt;/head&gt;
    &lt;head rend="h2"&gt;Wikipedia (19)&lt;/head&gt;
    &lt;head rend="h1"&gt;Miscellaneous&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;/doc/math/humor/2024-06-30-michelangelo-thecreationofadam-editedwithrubikscube.jpg&lt;/code&gt;:&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/doc/cs/security/2001-12-02-treginaldgibbons-isyoursonacomputerhacker.html&lt;/code&gt;:&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;https://andreas-zeller.blogspot.com/2017/01/twelve-latex-packages-to-get-your-paper.html&lt;/code&gt;:&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;https://andreasjhkarlsson.github.io/jekyll/update/2023/12/27/4-billion-if-statements.html&lt;/code&gt;:&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;https://ctan.org/pkg/coffeestains&lt;/code&gt;:&lt;p&gt;View External Link:&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;https://james-iry.blogspot.com/2009/05/brief-incomplete-and-mostly-wrong.html&lt;/code&gt;:&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;https://kieranhealy.org/blog/archives/2023/06/19/the-naming-of-stats/&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;https://mathwithbaddrawings.com/2023/11/07/mathematicians-play-set/&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;https://merrillmarkoe.substack.com/p/dylans-christmas-lights-a-scholarly&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;https://pages.cpsc.ucalgary.ca/~robin/class/449/Evolution.htm&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;code&gt;https://scholar.harvard.edu/files/mickens/files/thisworldofours.pdf&lt;/code&gt;:&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;https://www.cs.purdue.edu/homes/comer/essay.criticize.html&lt;/code&gt;:&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;https://www.eveonline.com/news/view/information-is-power-excel-release&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;https://www.lesswrong.com/posts/YKfNZAmiLdepDngwi/gpt-175bee&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;https://www.lesswrong.com/posts/YMo5PuXnZDwRjhHhE/i-have-been-a-good-bing&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;code&gt;https://www.lesswrong.com/posts/tBy4RvCzhYyrrMFj3/introducing-open-asteroid-impact&lt;/code&gt;:&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;https://www.protocol.com/chess-streaming-twitch-hikaru-botez&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;https://www.quantamagazine.org/why-mathematicians-re-prove-what-they-already-know-20230426/&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;https://www.stavros.io/posts/compressing-images-with-stable-diffusion/&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;https://www.theonion.com/u-s-economy-grinds-to-halt-as-nation-realizes-money-ju-1819571322&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;View External Link:&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Bibliography&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;https://arxiv.org/abs/2503.24187&lt;/code&gt;: “NeuRaLaTeX: A Machine Learning Library Written in Pure LaTeX ”,&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;https://arxiv.org/abs/2404.00732&lt;/code&gt;: “An Abundance of Katherines: The Game Theory of Baby Naming ”,&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;https://arxiv.org/abs/2403.00465&lt;/code&gt;: “Polyamorous Scheduling ”,&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;https://journals.open.tudelft.nl/superhero/article/download/5332/4801&lt;/code&gt;: “How Fast Can Evangelion Run? Application Of Aerodynamics And Scaling Laws To The Super Robot ”,&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;https://arxiv.org/abs/1911.11423&lt;/code&gt;: “Single Headed Attention RNN: Stop Thinking With Your Head ”,&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;1979-astin.pdf#page=12&lt;/code&gt;: “Paul Darwin Foote (1888–1971) § The Temperature of Heaven &amp;amp; Hell ”,&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46016630</guid><pubDate>Sat, 22 Nov 2025 17:49:05 +0000</pubDate></item><item><title>China reaches energy milestone by "breeding" uranium from thorium</title><link>https://www.scmp.com/news/china/science/article/3331312/china-reaches-energy-independence-milestone-breeding-uranium-thorium</link><description>&lt;doc fingerprint="35c25b54af5ed989"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;China reaches energy independence milestone by ‘breeding’ uranium from thorium&lt;/head&gt;
    &lt;p&gt;Chinese research institute confirms success of fission-based innovation that is poised to reshape clean, sustainable nuclear power&lt;/p&gt;
    &lt;p&gt;The achievement makes the 2 megawatt liquid-fuelled thorium-based molten salt reactor (TMSR) the only operating example of the technology in the world to have successfully loaded and used thorium fuel.&lt;/p&gt;
    &lt;p&gt;According to the academy, the experiment has provided initial proof of the technical feasibility of using thorium resources in molten salt reactor systems and represents a major leap forward for the technology.&lt;/p&gt;
    &lt;p&gt;It is the first time in the world that scientists have been able to acquire experimental data on thorium operations from inside a molten salt reactor, according to a report by Science and Technology Daily.&lt;/p&gt;
    &lt;p&gt;The article, published on Saturday, was China’s first official confirmation of its success in the development of TMSR technology, an innovation that is poised to reshape the future of clean sustainable nuclear energy.&lt;/p&gt;
    &lt;p&gt;Li Qingnuan, Communist Party secretary and deputy director at the Shanghai Institute of Applied Physics, told the newspaper that “since achieving first criticality on October 11, 2023, the thorium molten salt reactor has been steadily generating heat through nuclear fission”.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46016639</guid><pubDate>Sat, 22 Nov 2025 17:49:27 +0000</pubDate></item><item><title>Depot (YC W23) Is Hiring a Staff Infrastructure Engineer</title><link>https://www.ycombinator.com/companies/depot/jobs/O2iB56E-staff-infrastructure-engineer</link><description>&lt;doc fingerprint="2cccf64b3f052532"&gt;
  &lt;main&gt;
    &lt;p&gt;Build faster. Waste less time.&lt;/p&gt;
    &lt;p&gt;At Depot, we are on a mission to redefine software collaboration and accelerate developers everywhere. We are creating a build performance and developer platform unlike any other, combining performance, empathy, and centralized collaboration to enable companies to iterate exponentially faster.&lt;/p&gt;
    &lt;p&gt;We launch millions of EC2 instances per month and orchestrate half a petabyte of cache data to accelerate CI jobs and local builds. We are looking to hire a Staff Infrastructure Engineer who can build for the next level of scale.&lt;/p&gt;
    &lt;p&gt;For this role, you should be a seasoned expert with robust systems engineering skills and the ability to engage deeply in technical discussions. As part of a small team, you will work side-by-side with other engineers to test ideas, build proofs of concept, and ultimately ship quality solutions to customers. You will be a key contributor with the ownership and autonomy to see projects through from beginning to end.&lt;/p&gt;
    &lt;p&gt;Please note: We are an equal opportunity employer and remote-only company. At this time, we can only support hiring within North America and Europe for this role.&lt;/p&gt;
    &lt;p&gt;Depot is a fully remote and globally distributed team across the US, Europe, and Canada. As a remote startup, there are several key values and expectations:&lt;/p&gt;
    &lt;p&gt;Depot is a build acceleration and developer productivity platform that saves companies like PostHog, Wistia, Semgrep, and Secoda thousands of hours in build time every week.&lt;/p&gt;
    &lt;p&gt;We are developers. We started Depot because we were frustrated with the constant pain of slow build performance. We were fed up waiting for builds and annoyed by the lack of tooling and providers that actually made builds performant. So, we went and built the solution we had always wanted.&lt;/p&gt;
    &lt;p&gt;Slow builds are the dam standing in the way between mediocrity and innovation. They’re wasteful, expensive, and a drain on developer happiness &amp;amp; productivity. They slow down innovation.&lt;/p&gt;
    &lt;p&gt;Taking a 40-minute build down to a minute, changes everything. We help folks save literal years in build time every single week.&lt;/p&gt;
    &lt;p&gt;And we’re just getting started. For us, it’s all about iteration speed and keeping developers in their flow state. Our mission is to be relentless in accelerating software development.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46016799</guid><pubDate>Sat, 22 Nov 2025 18:05:47 +0000</pubDate></item><item><title>Show HN: Forty.News – Daily news, but on a 40-year delay</title><link>https://forty.news</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46017175</guid><pubDate>Sat, 22 Nov 2025 18:47:08 +0000</pubDate></item><item><title>The Censorship Network: Regulation and Repression in Germany Today</title><link>https://liber-net.org/germany/</link><description>&lt;doc fingerprint="c08f99ab4bbfbf45"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;The Censorship Network: Regulation and Repression in Germany Today&lt;/head&gt;
    &lt;head rend="h3"&gt;At vero eos et accusamus&lt;/head&gt;
    &lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.&lt;/p&gt;
    &lt;p&gt;Over the past several years, investigative reporting has uncovered a range of coordinated efforts to suppress online speech in Western countries. Often described as the Censorship-Industrial Complex, these networks of information suppression (mostly operating under the guise of countering “disinformation” or “hate speech”) have been particularly widespread in the United States, United Kingdom and the European Union. In the EU, Germany plays a central role in this system, with numerous governmental and private actors monitoring online speech and urging ever-greater levels of content suppression.&lt;/p&gt;
    &lt;p&gt;Germany’s reputation as a hub of censorship has grown significantly in recent years. In early 2025, a US 60 Minutes investigation drew international attention for clips of dawn apartment raids by armed police on people who had posted offensive memes. In other clips, state prosecutors chuckled at the seizure of citizens’ devices and emphasized the seriousness of the offense of “insulting” a politician.&lt;/p&gt;
    &lt;p&gt;We applied the methodology liber-net had used previously in our collaboration with journalist MattTaibbi on the Twitter Files, in mapping the US-focused Censorship-Industrial Complex. With German specialists, researchers and advisers, we documented this system at a scale far beyond what we anticipated. It includes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;a map of the leading content controls organizations in Germany, inspired by the original Censorship-Industrial Complex map (see above, or download the full-resolution image)&lt;/item&gt;
      &lt;item&gt;a report exploring the origins, politics and scope of German content controls&lt;/item&gt;
      &lt;item&gt;an organizations database including profiles of more than 330 government agencies, NGOs, academic centers, think tanks, foundations, and networks involved&lt;/item&gt;
      &lt;item&gt;a grants database of more than 420 content controls awards and grants&lt;/item&gt;
      &lt;item&gt;a series of infographics that visualize the above data&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This reflects more than half a year of research and mapping. For more details of how we approached this research, read our methodology.&lt;/p&gt;
    &lt;p&gt;It is tempting to describe the more than 330 organizations as censorship advocates or even censors, but the reality is more complex. Some clearly are overtly censorious, such as the government-appointed “trusted flagger” organization HateAid. Similarly, the unironic Machine Against the Rage initiative provokes a “you can’t be serious?” response, but serious they are indeed. At the same time, our database includes more moderate initiatives, such as local governments offering small grants for counter-hate speech education as a way to combat increasing social fragmentation.&lt;/p&gt;
    &lt;p&gt;We’ve included them all in the database and ranked them from one to five flags – with five flags indicating the worst offenders – to provide a full picture of this massive, tangled sector that maintains unusually close relationships with the government whilst presenting themselves as independent.&lt;/p&gt;
    &lt;p&gt;There is a real problem in online discourse but we argue that heavy-handed approaches are liable to political weaponization and threaten free expression. We hope this material helps journalists, policymakers and advocates see the scale of current speech suppression, defend free expression and develop methods for dealing with beyond-the-pale content that resist political weaponization.&lt;/p&gt;
    &lt;head rend="h1"&gt;Das Zensurnetzwerk: Regulierung und Repression im heutigen Deutschland&lt;/head&gt;
    &lt;p&gt;In den letzten Jahren haben investigative Berichte eine Reihe koordinierter Bemühungen zur Unterdrückung von Online-Meinungsäußerungen in westlichen Ländern aufgedeckt. Diese Netzwerke zur Unterdrückung von Informationen, die oft als „Zensur-Industriekomplex” bezeichnet werden und meist unter dem Deckmantel der Bekämpfung von „Desinformation” oder „Hassrede” operieren, sind insbesondere in den Vereinigten Staaten, im Vereinigten Königreich und in der Europäischen Union weit verbreitet. In der EU spielt Deutschland eine zentrale Rolle in diesem System: Zahlreiche staatliche und private Akteure überwachen Online-Äußerungen und fordern immer strengere Maßnahmen zur Unterdrückung von Inhalten. Deutschlands Ruf als Zentrum der Zensur hat in den letzten Jahren erheblich zugenommen. Anfang 2025 erregte eine Reportage der US-Sendung „60 Minutes” mit Clips von Razzien bewaffneter Polizisten in den Wohnungen von Personen, die beleidigende Memes gepostet hatten, internationale Aufmerksamkeit. In anderen Clips lachten Staatsanwälte über die Beschlagnahmung der Geräte von Bürgerinnen und Bürgern und betonten die Schwere des Vergehens, einen Politiker „beleidigt” zu haben.&lt;/p&gt;
    &lt;p&gt;Wir haben die von liber-net in der Zusammenarbeit mit dem Journalisten Matt Taibbi bei den „Twitter Files” verwendete Methodik angewendet, um den auf die USA fokussierten Zensur-Industriekomplex abzubilden. Zusammen mit deutschen Spezialisten, Forschern und Beratern haben wir dieses System dokumentiert, dessen Umfang unsere Erwartungen bei Weitem übertrifft. Die Dokumentation umfasst:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;eine Karte der führenden Organisationen für Inhaltskontrolle in Deutschland, die von der ursprünglichen Karte des Zensur-Industriekomplex inspiriert wurde (siehe oben oder lade das Bild in voller Auflösung herunter) .&lt;/item&gt;
      &lt;item&gt;einen Bericht, der die Ursprünge, den politischen HIntergrund und den Umfang der deutschen Kontrolle von Online-Inhalten untersucht.&lt;/item&gt;
      &lt;item&gt;eine Datenbank mit Profilen von mehr als 330 beteiligten Regierungsbehörden, NGOs, akademischen Zentren, Thinktanks, Stiftungen und Netzwerken.&lt;/item&gt;
      &lt;item&gt;eine Datenbank mit Fördermitteln, die mehr als 420 Zuschüsse und Fördermittel für Inhaltskontrolle umfasst,&lt;/item&gt;
      &lt;item&gt;eine Reihe von Infografiken, die die oben genannten Daten visualisieren.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Dies ist das Ergebnis von mehr als einem halben Jahr Recherche und Kartierung. Weitere Einzelheiten zu unserer Vorgehensweise bei dieser Recherche finden Sie in unserer Methodik.&lt;/p&gt;
    &lt;p&gt;Es ist verlockend, die mehr als 330 Organisationen als Befürworter von Zensur oder sogar als Zensoren zu bezeichnen, aber die Realität ist komplexer. Einige sind eindeutig offen zensierend, wie beispielsweise die von der Regierung ernannte Organisation „HateAid”, die als Trusted Flagger fungiert. Ähnlich reagiert man auf die unironische Initiative „Machine Against the Rage” mit „Das kann doch nicht Ihr Ernst sein?”, aber ernst ist es ihnen tatsächlich. Gleichzeitig umfasst unsere Datenbank auch moderatere Initiativen, wie beispielsweise lokale Behörden, die kleine Zuschüsse für Aufklärungsmaßnahmen gegen Hassreden anbieten, um der zunehmenden gesellschaftlichen Fragmentierung entgegenzuwirken.&lt;/p&gt;
    &lt;p&gt;Wir haben sie alle in die Datenbank aufgenommen und mit einer bis fünf Flaggen bewertet – wobei fünf Flaggen die schlimmsten Verstöße anzeigen –, um ein vollständiges Bild dieses riesigen, verworrenen Sektors zu vermitteln, der ungewöhnlich enge Beziehungen zur Regierung unterhält und sich gleichzeitig als unabhängig präsentiert.&lt;/p&gt;
    &lt;p&gt;Es gibt ein echtes Problem im Online-Diskurs, aber wir sind der Meinung, dass hart durchgreifende Maßnahmen leicht zu politischen Zwecken missbraucht werden können und die freie Meinungsäußerung gefährden. Wir hoffen, dass dieses Material Journalisten, politischen Entscheidungsträgern und Aktivisten hilft, das Ausmaß der derzeitigen Unterdrückung der Meinungsfreiheit zu erkennen, die freie Meinungsäußerung zu verteidigen und Methoden zu entwickeln, um mit unzumutbaren Inhalten umzugehen, die sich nicht für politische Zwecke missbrauchen lassen.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46017833</guid><pubDate>Sat, 22 Nov 2025 20:11:47 +0000</pubDate></item><item><title>The Mozilla Cycle, Part III: Mozilla Dies in Ignominy</title><link>https://taggart-tech.com/mozilla-cycle-pt3/</link><description>&lt;doc fingerprint="3f2a935d1a8f875c"&gt;
  &lt;main&gt;
    &lt;p&gt;I owe Mozilla a thank-you. Really, I do. Maybe an Edible Arrangement? People like those. Some lil pineapples cut into stars on sticks and chocolate strawberries might brighten their day. For the note, I'm thinking something like:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Thank you for proving me exactly right.&lt;/p&gt;
      &lt;p&gt;XOXO MT&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Eight months ago, in the fallout of Mozilla's fumbling of a Privacy Policy update, I wrote:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Mozilla is pursuing its primary objective, which is the survival of Mozilla. Its mission statement is more than broad enough to accommodate that, and Firefox is not a real priority. The community should accept that and stop waiting for Mozilla to be the hero they deserve.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Regrettably, I was unable to take my own advice on the last part. So here we are yet again, marveling at Mozilla's dedication toward eroding decades of good will in the community they purportedly serve. To quote one of my sacred texts, it's a focus and intensity normally seen only in successes.&lt;/p&gt;
    &lt;p&gt;Back in the present, we have Mozilla &lt;del&gt;doubling&lt;/del&gt;&lt;del&gt;tripling&lt;/del&gt; nthing down on this direction. First, with their announcement of "AI Window," a new feature (used very loosely) coming to Firefox which seems to emulate the user experience offered by AI browsers like Perplexity's Comet or OpenAI's Atlas. In other words, instead of performing search from the address bar and interacting with websites like browsers have done since they were invented, your first interaction will be with a language model prompt, which then mediates your experience of the web.&lt;/p&gt;
    &lt;p&gt;Not to gloat, but I told you so.&lt;/p&gt;
    &lt;p&gt;The response from the Firefox community has not just been overwhelmingly negative, it is universally negative as far as I can tell. At least among users willing to post on Mozilla's forums about the issue, which is absolutely a biased sample set. I have received some comments separately in support of Firefox, but they are countable and the vast, vast minority. Mozilla's core audience hates this move. At the very least, they would want all the AI components of Firefox to be opt-in, a choice that Firefox has been unwilling to make so far, instead enabling these new features by default.&lt;/p&gt;
    &lt;p&gt;What does Mozilla do? Temper the plan? Ease up on the forced features?&lt;/p&gt;
    &lt;p&gt;Nah, they do what any good corporate PR person would tell you to do when facing public backlash: post through it.&lt;/p&gt;
    &lt;p&gt;This post is a summary of Mozilla's new Strategic Plan, which is viewable in full here. I read it through a few times, and my brain nearly ripped in half from the cognitive dissonance involved. But I think it's worth examining Mozilla's claims carefully. They are:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;AI (by which they mean generative AI) is a transformative technology that will fundamentally alter how we interact with machines and the web.&lt;/item&gt;
      &lt;item&gt;The current landscape is dangerous and controlled by big tech and "closed source" models.&lt;/item&gt;
      &lt;item&gt;Mozilla should therefore pivot to develop and support "open source" AI implementations the same way they advocated for open web standards.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The strategy details the "what" and "how" of Mozilla's transformation in this direction. We're going to touch on some of those points, but let's begin with these big claims, affording Mozilla maximum benefit of the doubt.&lt;/p&gt;
    &lt;p&gt;Is generative AI a transformative technology? The Corpos sure seem to want it to be, although its actual usage seems mostly to be chatbot-related. All other attempts to use this trick in other realms have failed rather miserably. Microsoft, for example, wants you to talk to your computer instead of using a mouse and keyboard like a dinosaur. The results, unfortunately, are much worse than the Jurassic version of computer interaction. The pattern holds true across the board. Google's AI Overview continues to be an inferior provider of information than solid web search results. Also, as it turns out, people learn less from LLM output.&lt;/p&gt;
    &lt;p&gt;Even the AI browsers Mozilla wants to emulate have significant issues, vulnerable to old web vulnerabilities and new attacks against the models themselves.&lt;/p&gt;
    &lt;p&gt;Generative AI is transforming something, but I don't think it's the web, and I don't think it's for the better.&lt;/p&gt;
    &lt;p&gt;Which means their second claim is definitely true! The current landscape is dangerous, as I've been decrying for years.&lt;/p&gt;
    &lt;p&gt;But because Mozilla is convinced that generative AI is a force for good (with no evidence to back that claim up), they conclude that their mission must be to create "open source" alternatives to commercial ("big tech") offerings.&lt;/p&gt;
    &lt;p&gt;If you truly believe generative AI is a net good but with potential for significant harm, there are arguments to be made for ethical implementations. This same instinct is what propelled researchers from OpenAI to split and found Anthropic.&lt;/p&gt;
    &lt;p&gt;This, however, is an article of faith. It cannot be argued rationally because no empirical evidence exists to support it. The entirety of the belief is predicated on future potential—and it always will be, right up until the harms are so inescapably clear that even the most ardent of believers suffer because of them. Even then, not all of the Flock will lose faith. And as we now see, Mozilla leadership are not just the Flock, but Disciples.&lt;/p&gt;
    &lt;p&gt;Mozilla has had a conversion experience, while its core audience has not. This results in a schism of purpose.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Actual Strategy&lt;/head&gt;
    &lt;p&gt;Digging into the plan itself, Mozilla's ambitions are remarkable. Mozilla has, as the plan notes, always measured itself against a "double bottom line" of mission and market success. However, it seems these two criteria are now separately defined by: "a. AI that advances the Manifesto; and b. diversifying revenue away from search."&lt;/p&gt;
    &lt;p&gt;Their specific goals include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;All Mozilla orgs have a flagship AI product by 2028&lt;/item&gt;
      &lt;item&gt;10% year-over-year community growth&lt;/item&gt;
      &lt;item&gt;20% year-over-year growth in non-search revenue&lt;/item&gt;
      &lt;item&gt;3 Mozilla orgs have more than $25M in revenue (currently: 1)&lt;/item&gt;
      &lt;item&gt;10% year-over-year investment portfolio returns&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I am dumbfounded by these goals. I can't even be snarky about them. They seem so disconnected from reality that I can't imagine how a Board arrived at them.&lt;/p&gt;
    &lt;p&gt;Let's go through them one at a time.&lt;/p&gt;
    &lt;head rend="h3"&gt;"Flagship" AI Products&lt;/head&gt;
    &lt;p&gt;What "orgs" are we talking about here? Historically there have been two Mozilla organizations: the Mozilla Foundation, which is the not-for-profit to which you donate to preserve the open web); and the Mozilla Corporation, which develops Firefox, makes deals with search engines, and creates other revenue-generating projects like, uh, Pocket.&lt;/p&gt;
    &lt;p&gt;There now exist three other for-profit subsidiaries of the Foundation, although these are not mentioned in the official listings. The first is MZLA Technologies Corporation, which is responsible for Thunderbird. I can't tell what else they do, if anything.&lt;/p&gt;
    &lt;p&gt;Another is Mozilla.ai, which has a much clearer purpose. This company produces AI products and services. So of these organizations, 3 of them need to have flagship AI products by 2028. What could that possibly look like?&lt;/p&gt;
    &lt;p&gt;There is also Mozilla Ventures, which is literally just a venture capital firm throwing money at AI projects that align with Mozilla's Manifesto.&lt;/p&gt;
    &lt;p&gt;Mozilla.ai has the easiest and clearest road, as their Agent Platformis already in early access and is absolutely a commercial product. MZLA has...Thunderbird? So AI-powered Thunderbird? That's what I can figure, although Thunderbird is not exactly known as an AI platform. Their new paid Thunderbird Pro service currently makes no mention of AI integration. That's a headscratcher. Mozilla VenturesAnd finally, we have the Corporation and Firefox.&lt;/p&gt;
    &lt;p&gt;Let's be as clear as we can possibly be. Mozilla is an AI company, and Firefox will be a flagship AI product according to this strategic plan. This is the focus for Mozilla, which means users of Firefox will only get more and more AI shoved down their throat, and likely fewer ways to avoid it.&lt;/p&gt;
    &lt;head rend="h3"&gt;Community Growth&lt;/head&gt;
    &lt;p&gt;I don't have access to Mozilla's "community" numbers, however they choose to define them. But if the reaction to recent changes is any indication, expecting growth of any kind isn't just optimistic, it's delusional. They are betraying the principles of their core use base in favor of their new god. That behavior is usually not rewarded by users or customers.&lt;/p&gt;
    &lt;head rend="h3"&gt;Financials&lt;/head&gt;
    &lt;p&gt;While I don't have access to community numbers, the Mozilla Foundation must disclose its financials, so that I can review—and you can too, if you're broken like me. I don't want to think about how much time I've spent reading Mozilla's 990s.&lt;/p&gt;
    &lt;p&gt;Looking at their revenue change from 2022 to 2023, we see a drop of 3% in royalties (search deals) and almost 15% in subscriptions and advertising. Let's also note that by these counts, royalties account for about 76% of Mozilla's annual revenue. That's by my own calculation on these disclosure, but Mozilla themselves cite 85% as share of revenue from search alone.&lt;/p&gt;
    &lt;p&gt;2022's numbers show a similar drop (down 3% from 2021) in royalties, but a 25% (!!) jump in subscriptions and ad revenue. My guess is ads, since I don't think the VPN service is raking it in, nor do I think a bunch of people suddenly signed up for Pocket before it died. This would certainly explain why last year, Mozilla went hard on their "privacy-honoring" advertising acquisition.&lt;/p&gt;
    &lt;p&gt;Zooming back out: the current business model is not delivering growth. So the pivot to AI is a bet that investment is out there for alternative sources of AI technology. It's also, tacitly, a bet that the AI bubble will last long enough to get competing products off the ground and attract investment before it's too late.&lt;/p&gt;
    &lt;p&gt;I...wouldn't be so sure.&lt;/p&gt;
    &lt;p&gt;As far as their investment portfolio's performance, Mozilla has changed their strategy significantly in the last 3 years, resulting in significant increases in dividend and realized gains in investments. What's the change in strategy?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;At the end of 2022, Mozilla changed our strategy for managing our financial reserves. In prior years we took a purely defensive approach, investing solely in highly liquid fixed-income securities. Our revised approach is focused on delivering a total return to Mozilla after inflation, while maintaining sufficient liquid reserves to weather economic pressures and seize growth opportunities.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Translation: we invested more in stocks and less in bonds, T-notes, and CDs. What specifically they've invested in is unclear, but you can probably guess it rhymes with Blavidia. I'm sure they have a diversified portfolio, but if you believe (as I do) that the market is heading for a massive correction, this goal is unattainable and a dangerous target for a strategic plan.&lt;/p&gt;
    &lt;p&gt;Lastly, on revenue. Mozilla plainly has to diversify away from search, because search is dying. Google itself is trying to kill it, in favor of AI. If this succeeds, Firefox's primary revenue stream is drying up, and they know it. More than anything else, this is the reason for the pivot. As I've said before, the will to survive takes precedence over principle when choosing a path forward for any organization, even a not-for-profit with a stated mission.&lt;/p&gt;
    &lt;p&gt;These goals are not so much reasonable expectations as existential mandates. Either Mozilla approaches these targets in 3 years, or they may be staring death in the face.&lt;/p&gt;
    &lt;head rend="h2"&gt;Flawed Hypotheses&lt;/head&gt;
    &lt;p&gt;This strategy hinges on three stated hypotheses from Mozilla:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;A generational shift in human computer interaction is widening the gap between Mozilla’s products and trustworthy, user-centered experiences.&lt;/item&gt;
      &lt;item&gt;A vibrant, successful and decentralized open source AI ecosystem is essential if we want independent tech players to thrive — and for innovation to come from everywhere.&lt;/item&gt;
      &lt;item&gt;The growing need for sovereign, public interest AI which will only be met by governments and public interest tech players pooling resources and banding together.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;That's...okay. We'll take it from the top.&lt;/p&gt;
    &lt;p&gt;Would you say generative AI is a "generational shift in human computer interaction?" The Corpos want it to be, but so far this hasn't taken place. Declaring it thus is the wish becoming the father of the thought. Maybe someday a functional language model will govern our interaction with computing machines, but that is nowhere near the case now, and the fundamental flaws in the technology preclude it from being so in the foreseeable future.&lt;/p&gt;
    &lt;p&gt;Would you say generative AI is "trustworthy" or "user-centered?" The people who implicitly trust generative AI are suffering from psychosis. It's a pathology. The model creators themselves tell you not to trust them! What are we doing here?&lt;/p&gt;
    &lt;p&gt;Y'know what is trustworthy? A goddamned URL bar that takes me to the website I want to go to. A search engine that shows me sources, ideally curated for quality.&lt;/p&gt;
    &lt;p&gt;Okay so hypothesis 1 doesn't pass the sniff test. On to number 2.&lt;/p&gt;
    &lt;p&gt;Can someone please explain to me what the hell "open source AI" is? Mozilla's helpful Strategy Wiki lists Mozilla's own products and investments under this category. Remember that for LLMs, you have two major "source" components: the dataset on which a model was trained, and the resulting vectors/weights file that comprises the model. Among them is HuggingFace, which is probably best understood as GitHub for AI. HuggingFace hosts both models and datasets used in ML/AI applications. It's about as close to open source AI as I can imagine.&lt;/p&gt;
    &lt;p&gt;Some of those HuggingFace datasets are really useful. Like, for example, the OCRed version of the Epstein Files. That's rad as hell, and I'm glad there's a place to share those things. It's even a goldmine for researchers like me, since datasets containing model jailbreaking prompts are available.&lt;/p&gt;
    &lt;p&gt;But let's be clear about Mozilla's value proposition of the "transformative" generative AI. These are not small models we're talking about; these are large language models that were trained on massive corpora of text. Those corpora are the "source." We know that the training data for frontier models comes from copyrighted material and material scraped without consent. We also know that code generated from scraped sources may well violate the licenses of that source code in reproduction.&lt;/p&gt;
    &lt;p&gt;In other words, there can never be an open source large language model when the sources are themselves violate of content usage agreements. For all the talk about "ethical" AI, Mozilla fails to address this original sin of the technology.&lt;/p&gt;
    &lt;p&gt;I'm sorry, I should say "nearly fails." In the "Threats" section of their SWOT analysis of their own strategy, they identify "Open models disappear" as a threat:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Big tech / China stop releasing open models. No public open source frontier models emerge. Mozilla’s strategy is obsolete / outflanked.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Okay so by "open source AI" you actually mean Qwen/Deepseek/Llama. Cool. Cool cool cool. These are open weight only, so the premise of open data goes out the window. And this threat gives away the fact that Mozilla can only succeed on the backs of frontier models. There is no real plan to "democratize" LLMs, nor can there be for the scale required.&lt;/p&gt;
    &lt;p&gt;This entire exercise is a farce. Yet again, Mozilla pursues a parasitical relationship with the corpos. It worked last time, right??&lt;/p&gt;
    &lt;p&gt;Hypothesis 3: the growing need for "sovereign" AI. We've already established that there is no large language model possible without corpo scale and investment, except perhaps with government support. So is that what Mozilla wants? State-sponsored LLMs? This hypothesis points in that direction, with Mozilla as the "public interest tech player" catching a percentage somewhere in the middle. Being a government intermediary is also probably not a safe position for anyone at this juncture, much less a tech company.&lt;/p&gt;
    &lt;p&gt;But also, what "need" are we talking about here? Why is there a need for any of this at all?&lt;/p&gt;
    &lt;p&gt;Again we encounter the fundamental schism of purpose between Mozilla trying to survive, and the mission its core audience believes in. You could imagine a Mozilla that decided, "Actually, the web was better without this dreck in it, and the experience of the web is not improved by moving users closer to it." You could imagine an organization that doubled down on true privacy, and a human-centered web. We'll never know what kind of funding streams such an organization could build, because Mozilla has chosen the machines over people. They have chosen quick revenue over long-term sustainability.&lt;/p&gt;
    &lt;p&gt;It's finally time you and I take the advice I offered before: let Mozilla die. It no longer serves its stated purpose.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46017910</guid><pubDate>Sat, 22 Nov 2025 20:21:56 +0000</pubDate></item><item><title>The Go-Between</title><link>https://theamericanscholar.org/the-go-between/</link><description>&lt;doc fingerprint="7e5099718aa091f3"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Go-Between&lt;/head&gt;
    &lt;p&gt;One of America’s most celebrated women war correspondents walked a fine line between journalism and espionage&lt;/p&gt;
    &lt;p&gt;Late in August 1939, just before Germany invaded Poland, the Chicago Daily News broke an ironclad policy to make the American reporter Helen Paull Kirkpatrick its first and only woman correspondent abroad. She was nearly 30 and had been living in London since 1937 after two years in Geneva, circulating with patrician ease among the native and expat upper classes. With two English colleagues, she had cofounded The Whitehall Letter, a successful weekly digest of world affairs with a strong antifascist bent, and on her own wrote two books: one about Prime Minister Neville Chamberlain and the prewar Munich Agreement, the other about the British after the war began. She also started an American edition of the newsletter run by her younger brother, Lyman Bickford Kirkpatrick Jr., whose eventual experiences in the American intelligence apparatus would figure heavily in her own working life.&lt;/p&gt;
    &lt;p&gt;Helen Kirkpatrick’s start date in the Daily News London bureau could not have been better timed. The Duke and Duchess of Windsor had just returned to England after a period of semi-exile in France. By way of Helen’s frequent weekends with Waldorf and Nancy Astor at Cliveden and with Ronald and Nancy Tree at Ditchley Park, she happened to know something most others did not: that the Windsors were staying at South Hartfield House, the grand home of Edward Dudley Metcalfe, the duke’s former equerry, whom she also happened to know. Bill Stoneman, the Daily News London bureau chief, thought her foolish to trek the 40 miles south to Sussex in what was sure to be a failed attempt to interview the Duke of Windsor—the man who had been the nation’s king until abdicating the throne in 1936. But off she went. She arrived at twilight, buoyed with anticipation until it emerged that the duke had already declared that he would not give interviews during his stay. And yet, struck by the dismay on the face of this visitor, the duke devised a gallant way to both keep his word and salvage Helen’s hopes for a triumphant debut in the Daily News—and the many other papers that subscribed to its well-regarded foreign news service. “He seemed to have decided that even though I was not to be allowed to interview him, he would interview me,” she wrote. Her story appeared on page two, September 18, 1939, under the headline, “Duchess of Windsor to Run Hospital, Duke May Join Army.”&lt;/p&gt;
    &lt;p&gt;This flashy little royal scoop became the first of scores of exclusives during Helen’s seven years with the paper, most of them far more substantive in news value. For her first anniversary on staff, the editors featured her in a five-column promotional house ad titled “War and a Woman,” which called her articles “clear as crystal, accurate as a radio beam, prompt as the crashing impact of the happenings they record”; her dispatches arrived in Chicago by cablegram at “machine-gun tempo”—three, four, sometimes five times a day. Her beat was all of England and Ireland and General Charles de Gaulle and his London-based Free French Movement. Later, there would be lengthy forays to Algeria, Italy, France, Germany, and elsewhere in Europe—wherever war news flowed.&lt;/p&gt;
    &lt;p&gt;Least known to the public among her journalistic virtues, the ad disclosed, was how often her stories had to be “splashed across eight-columns, front page headlines, without a hint of credit to the razor-edged intelligence that rifled them home.” For example, eight days before the German blitzkrieg of May 10, 1940, Helen was alone among correspondents to report that King Leopold III of Belgium had privately informed the U.S. government that the Germans were sure to invade his country next. Clearly to avoid linking the news to Helen or revealing how or where she had obtained the information, the story ran buried in a column of items under someone else’s byline, attributed only to “private sources in Chicago.” The point was, the impeccable confidential sources cultivated by “Our Helen,” as Daily News headlines would sometimes dub her in the years to come, were either newsmakers themselves or those just as likely to know of what they spoke. “Not even now,” the ad went on, “—not until war and war’s tongue-stilling offspring, strict censorship, have lifted—can the complete story of Helen Kirkpatrick’s incredible war coverage be told.”&lt;/p&gt;
    &lt;p&gt;It is fair to say that as a class, American women correspondents during World War II were not held in particularly high regard, so Helen Kirkpatrick’s outsize ability to garner not only respect but also major governmental and military awards does conjure up questions. Of the more than 1,600 U.S.-accredited World War II correspondents, only 19 received the coveted U.S. Medal of Freedom—and of those 19, Helen was the only woman. This despite similar barrier-breaking reportage by Margaret Bourke-White, Ann Stringer, Lee Carson, Lee Miller, Iris Carpenter, Marguerite Higgins, and others, none of whose names even appear in archived military lists of suggested nominees. How did she manage to have so much swift, direct access to so many top-line political, diplomatic, military, and intelligence sources? Was it just her keen reporting, or did the close social relationships she developed with important men set her apart?&lt;/p&gt;
    &lt;p&gt;Lyman Kirkpatrick’s time in Europe during the war either ran parallel to hers or was intertwined. And yet in her lengthiest latter-day interviews, references to her brother are few and casual. In his books, Lyman’s mentions of his sister were similarly spare. Both of their names appear in the wartime memoirs of friends and colleagues, but never in the same account. Only a careful rereading of the Washington Press Club Foundation’s oral history of Helen revealed an offhand mention of a brother in the CIA. Did Lyman’s rapid rise through the U.S. intelligence ranks figure in her successes, and if so, how? Had Helen broken with journalism’s established codes of conduct and crossed the line into espionage? In a more general way, the siblings’ connectedness during the war years casts a hazy light on how the realms of intelligence-gathering and major media reportage, meant to be strictly separate, have sometimes intersected in times of war and tyranny.&lt;/p&gt;
    &lt;p&gt;In interviews, Helen’s answers to questions about how she achieved such high recognition were veiled, self-deprecating. Sometimes she’d deflect. Did she do anything heroic? No, she’d reply, adding that she could not remember why she was honored by the French and with a U.S. Medal of Freedom or if she ever even knew the reasons. Check her papers at Smith College, she would suggest. They offer little. The questions lingered. For even her nearest living relations, they linger still.&lt;/p&gt;
    &lt;p&gt;The Kirkpatricks of Rochester, New York, were a prominent family, albeit no&lt;lb/&gt; longer monied by the time Helen and Lyman’s parents married. (They later divorced, then married each other again.) On their father’s side, the siblings were mindful and proud of a Scottish lineage that pre-dated Robert the Bruce; I Mak Siccar (“I’ll make sure”) was the family motto. Their maternal heritage came via the Paulls of Wheeling, West Virginia; they often spent holidays at the family home in Hawthorne Court in Woodsdale, on Wheeling’s outskirts. Their ancestors included Virginia unionists like Colonel James Paull, a soldier in the Revolutionary War, and Colonel Joshua Fry, who, alongside the father of Thomas Jefferson, created the original map of Virginia. A long list of judges, lawyers, military men, and other public servants followed.&lt;/p&gt;
    &lt;p&gt;With tuition help from grandparents and scholarships, and after a couple of time-outs for Helen for financial hiccups, both siblings completed their education with prestigious degrees. Helen attended The Masters School in Dobbs Ferry, New York, and then studied history at Smith, graduating Phi Beta Kappa in 1931; Lyman went to Deerfield and Princeton, where he majored in politics and graduated in 1938. Helen looked after Lyman like an ambitious other mother. In letters home, she lovingly mocked her parents’ adoration of him, which she shared, referring to him as “Little Man” or “Son.”&lt;/p&gt;
    &lt;p&gt;To intimates, Lyman went by Kirk; Helen, they called Pat. Seven years apart in age, they were as tall as they were driven, smart, and talented. Lyman was a handsome six-foot-five; Helen, a stately five-foot-10. Both were appealing in style and manner, always commanding notice. Her friend and colleague Ben Robertson found her “extraordinary” and “beautiful” with “a first-class mind” that she put to use, he later wrote, in “taking up matters with people at the top, with cabinet ministers and the like.” Her only known detractor in print was General Raymond E. Lee, a U.S. military attaché in London whom she met in December 1940. He found her “rather clever,” his journals record, but “far from being as attractive and alluring as she thinks she is.”&lt;/p&gt;
    &lt;p&gt;It was during her student days that Helen first spent time in Geneva, which fed her fascination with the comings and goings of the crowd that convened around the still-promising League of Nations. “There were all kinds of operators around,” she once said, “people whose jobs were a little obscure as to what they were. They were oil merchants or they were spies for one side or another. It was a very exciting place to be.” In the summer of 1935, she returned to the city as a tour leader for a group of high-school girls, but really to flee an unhappy marriage. “Not returning,” read the two-word transatlantic cable she sent to Victor Polachek Jr., the husband of two years she’d left behind in New York City. She found work writing policy papers for the Geneva Research Center, an affiliate of the Foreign Policy Association, and as a newspaper stringer who covered the League of Nations for the New York Herald-Tribune and a few other American and British papers. That she spoke French was an enormous advantage, she said, but not monetarily. She lived on Brussels sprouts and cottage cheese.&lt;/p&gt;
    &lt;p&gt;By 1937, Helen was 28. Most journalists of her era and caliber would have advanced to staff positions with journeymen status by that age, but she had not yet hit her stride. Her working life had zigzagged a few times before she settled in Europe: There was the year she spent with her mother in a management training program at Macy’s; her nondegree graduate study on a fellowship in Geneva; the marriage to Polachek, during which they lived in a charming but oh-so-narrow three-story townhouse in Greenwich Village, once rented for a couple of years by Edna St. Vincent Millay and her husband. Through the Polacheks’ next-door neighbors, Osgood and Alice Field, Helen had taken a job helping to organize an exhibition on Soviet education at the Museum of Natural History. This was under the auspices of the Soviet All-Union Society for Cultural Relations with Foreign Countries, also called VOKS. However, the Communist Party affiliation of many of its members left her dubious and made her steer clear of any further involvement with the organization.&lt;/p&gt;
    &lt;p&gt;In Geneva, her stringer status meant that her copy appeared unsigned. Newspaper archives yield her name only once from those days: She is quoted in other reporters’ stories about the July 4, 1936, suicide of Štefan Lux, a Czech journalist who shot himself in the assembly room of the League of Nations to protest the League’s inaction on Germany’s treatment of Jews. Of the League’s reporters, only Helen—“an American girl attached to the Geneva Research Center,” The New York Times called her—was within sight of Lux and within earshot of his last words: “C’est le dernier coup.” To have no outlet that would publish her firsthand report, she later said, was especially frustrating.&lt;/p&gt;
    &lt;p&gt;Victor Gordon-Lennox, a well-born diplomatic correspondent for The Daily Telegraph, often reported from Geneva. It was he who persuaded Helen to join him and Graham Hutton of The Economist in the Whitehall Letter venture in London. For Helen, this was a fresh and appealing opportunity. In part, she owed her swift entrée into London’s sought-after social circles to “V.G.L.,” as letters home so often refer to him in reports of her weekends and glittering evenings out.&lt;/p&gt;
    &lt;p&gt;Meanwhile, the timing of Helen’s move to London coincided with intensified familial concern over young Lyman’s professional prospects. Helen was in the best position to help. The summer after his graduation from Princeton, he went biking in England with a college mate. This was when the siblings’ adult lives began to converge. Helen introduced Lyman to Kermit “Kim” Roosevelt, son of Theodore by his second marriage, who was seeking a summer tutor to prepare his son, Dirck, for admission to Groton. Helen would later say Lyman’s fine manners got him the position over several Rhodes scholars. Living with the Roosevelts meant that Lyman needed the right clothing—a tux, for example, which would have taken too long to arrive from home. Helen arranged to borrow one from someone at the U.S. Embassy. “The name escapes me,” Lyman wrote years later, “but my foggy recollection is that it might have been a tuxedo of the ambassador himself.” And yet, Ambassador Joseph P. Kennedy stood five inches shorter than Lyman, so perhaps not. Helen also sent her brother new white flannels and tennis shirts. “He’s coming to town one day soon [to] be fitted for a suit and have some tweed he got in Scotland made into another jacket,” she wrote home. Once Lyman was back in the United States that September, a Princeton connection recommended him to David Lawrence, who hired him for his company, United States News, the eventual publisher of U.S. News &amp;amp; World Report. Lyman edited the U.S. edition of The Whitehall Letter on the side, with typing and administrative help from his wife, the former Jeanne Barclay Courtney, whom he married in February 1939.&lt;/p&gt;
    &lt;p&gt;In London, Helen knew both William “Wild Bill” Donovan and David K. E. Bruce well. Donovan headed up the Office of the Coordinator of Information, known as the COI, which evolved into the Office of Strategic Services, the OSS. He once tried to recruit her to the agency, but as she later told an interviewer, her response was, “To do what?” Donovan said he didn’t know, but he would find a spot for her. She declined, telling him she thought she was as useful to the war effort doing what she was doing as she would be in the OSS. Bruce, whom she met when he first arrived in England as chief representative of the American Red Cross, served both the COI and OSS as London branch chief and deputy executive director. Published entries from his diaries mention Helen innocuously only a couple of times, but his biographer described her as Bruce’s old friend, who often joined him at the home of Nancy and Ronald Tree.&lt;/p&gt;
    &lt;p&gt;In August 1940, Bruce, then still with the Red Cross, would go with Helen and other correspondents to Shakespeare Cliff, facing the Dover Strait, to watch the RAF fighters confront the invading Luftwaffe overhead. The memoirists among them later name-dropped their colleagues in passages about these deeply affecting days. “We lived in expectation of a full German attack any night,” Vincent “Jimmy” Sheean wrote, “and the nerves of some of our friends grew so exacerbated by suspense that they actually said they would welcome it.” Not Helen; she was steely, and was in fact first to suggest the Dover vigils. Ben Robertson said that by then she had already become one of the best American journalists, woman or man, “and in the weeks that were to follow she was to add to her already established reputation.”&lt;/p&gt;
    &lt;p&gt;Another crucial contact of Helen’s was David Gray, the “openly pro-British” U.S. minister plenipotentiary to Ireland. She stayed with the Grays whenever she was in Dublin, which was often. It was Gray who told her, as she reported on June 12, 1940, how much evidence there was of German infiltration in Ireland. She mentioned the tide of fifth columnists who secretly wanted a British defeat, although she does not attribute her source. To avoid Irish censorship, she filed the story with a Dublin dateline once she got back to England. Ireland’s minister in Washington, Robert Brennan, wrote to the editor, conveying his country’s ire and calling out what he said were misstatements in the story. The Daily News published his missive promptly, adding this note: “Miss Kirkpatrick’s article was based on careful investigation in England and in Eire, and, The Daily News has no reason to doubt the accuracy of her reports. It is obvious that a diplomat in Washington cannot be better informed on London opinion than a resident correspondent in London.”&lt;/p&gt;
    &lt;p&gt;For Helen, breaking stories for the Daily News enlarged her already formidable social standing and long list of contacts and sources who cultivated her as eagerly as she cultivated them. What she gleaned during a Christmastime weekend at Ditchley Park in 1940 about secret negotiations between Britain and Vichy France almost got her thrown out of England. Another guest told her that Vichy had said it would not aid the Nazis in attacking Britain; Helen reported it, enraging Winston Churchill. “Miss Helen Kirkpatrick should be shipped out of the country at the earliest moment,” the prime minister’s minutes record. “It is very undesirable to have a person of this kind scouting about private houses for copy regardless of British interests.” Duff Cooper, the British minister of information, whom Helen considered “a great close personal friend,” vouched for her; the prime minister reconsidered.&lt;/p&gt;
    &lt;p&gt;In Dublin late in the summer of 1941, David Gray tapped Helen to take a secret message to London and hand it to Britain’s cabinet minister for the colonies. It concerned a scheme devised by Gray and Sir John Maffey, Britain’s chief diplomatic representative to Ireland, to force the Irish into the war or at least to give up some rights. Helen obliged, despite the line-crossing this involved. By Gray’s mistake, however, a copy of the memo ended up in an envelope sent to Joe Walshe, the secretary of the Irish Free State’s Department of External Affairs—Gray had meant to send him only a copy of one of Helen’s articles from Dublin. “Well, the fat was in the fire,” she recalled. Even in wartime, for a correspondent to be seen as engaging in the trading of unpublished information or in espionage of any sort was and is a clear violation of every established journalistic code of ethics. Especially in conflict situations, any insinuation of such a sideline, even a comment tossed off in jest, could be as destructive to a reporter’s reputation inside the press corps as it was potentially lethal outside it.&lt;/p&gt;
    &lt;p&gt;Gray, knowing his telephones were bugged, traveled to Belfast to call Helen about what had happened and then wrote to her to apologize for putting her in such a terrible position. He offered to resign or do whatever she suggested because, he wrote, “I never can square myself for this stupidity.” She told him she was the expendable one, not he. In the end, nothing came of the episode beyond the doubt it sowed in the minds of Dubliners that Helen “was at least an intelligence officer or a spy. And,” she recalled, “I was treated that way.” The British, she said, were especially dubious of Americans who traveled often between England and Ireland, and the IRA went so far as to accuse her of being the harbinger of an American invasion of their country. “But I continued to go regularly,” she said, “and I became quite good friends with the man in the Foreign Office.”&lt;/p&gt;
    &lt;p&gt;It remained Helen’s style, at every opportunity, to share with officials among the Allies whatever she had learned that they might be able to make good use of, sometimes preparing lengthy unrequested written memos about hard-won information, reports that just as often went nowhere. The Americans were invariably unreceptive—“We have our own sources” was the official attitude, Helen would later say—but the British and French were keen to learn whatever they could. Years later, she would reflect on the “strong feeling” she and Lyman shared about “the importance of intelligence, of knowing what’s going on, and finding out from people, asking what they’ve seen, what they’ve heard. Then you evaluate it as to whether it’s of real interest or not.”&lt;/p&gt;
    &lt;p&gt;Given these predilections, it is not surprising that Helen would see intelligence as a career route for Lyman, if not for herself. Once again, she flung a handful of sisterly pixie dust onto her brother’s job prospects. “I’ve cast a few flies in [the COI’s Bill] Donovan’s direction with no results so far,” she wrote to her brother in Washington early in January 1942, just weeks after Pearl Harbor was attacked and after the Naval Reserve Air Force rejected his enlistment because he was red-green colorblind. “Everyone in the service branches of the [U.S.] embassy has suddenly blossomed into uniform, etc., and our English friends have ceased to be polite. … Most of us here wanted to get home—or into some job other than our present ones.” However, she went on, the U.S. Ambassador, John G. Winant, “asked us all to sit still and keep on with what we’re doing for the time being.” Helen felt out David Gray to see whether he could make use of her in Dublin, but he demurred, affirming her own growing sense that she was better off where she was. From Colonel Frank Knox, her publisher, came cajoling affirmation. “I can think of no war work in which a courageous and intelligent woman could be engaged that would be more valuable to the country in the present circumstances than that you are doing for us,” he wrote. “Us” in this case seems to have meant more than the foreign news service of the Chicago Daily News: In 1941, Knox had also become the secretary of the U.S. Navy.&lt;/p&gt;
    &lt;p&gt;Two months later, Lyman, still at his publishing job in Washington, got a call from Helen’s friend David Bruce, whom Lyman had met back in 1940. Bruce offered Lyman a post with the COI. Lyman later wrote of some “flattering and undeserved attention” that had come his way, at about the same time, from Colonel Knox himself, the Navy secretary–cum–Daily News publisher. This happened via Bill Stoneman, Helen’s London bureau chief, who mentioned to Knox the Navy’s rejection of Lyman. Knox then called Lyman into his office and offered to rescind the decision, but by that point, Lyman had accepted the job with the COI. Knox cautioned Lyman against “that crazy outfit” but did not convince him otherwise. Knox further offered to help if Lyman changed his mind.&lt;/p&gt;
    &lt;p&gt;That, in essence, is how their world worked.&lt;/p&gt;
    &lt;p&gt;Lyman was soon deployed to London and later to the continent as the COI became the OSS. He was considered a master at postmortem assessments, a specialty that years later would include a seminal report on the failed Bay of Pigs invasion of 1961. Among his wartime assignments was the task of traveling with the 12th Army as General Omar Bradley’s briefer. He also worked in close liaison with the French and Belgian resistance, serving as a conduit for intelligence reports on the resistance and from OSS agents to the 12th Army Group.&lt;/p&gt;
    &lt;p&gt;His duties included giving the enemy order of battle at morning briefings each day. According to Helen, General Bradley marveled at Lyman’s ability to reel off—from memory, without notes—the entire litany of intelligence gathered about German operations across and up and down the continent from one day to the next. One of Lyman’s favorite memories, meanwhile, involved General George S. Patton, who was often at Army group headquarters. Shortly before Christmas 1944, Patton asked for a briefing on when the Russian forces would be able to resume their offenses in the East, thus taking some pressure off the western front. The Russians shared little, despite repeated requests from SHAEF, the Supreme Headquarters Allied Expeditionary Force. As Lyman explained in his memoir, most information came from listening to German and Russian communiqués about the battles in the East “and then plotting the map based upon what seemed most plausible from what they were both saying and then balancing this with what was known from our own intelligence sources.” The intelligence team prepared an answer, which they provided close to New Year’s Day, when the generals had time to hear it. As the briefing concluded, Patton asked one question: “When do you think the Russians are going to launch their next offensive?” Lyman gave the reply. The second week in January, he said, based on the case study the team had prepared of the time lags between Soviet offensives, coupled with knowledge that in Poland, the Russians were along the bank of the Vistula and that they would want the river frozen to a sufficient depth to allow tanks to cross.&lt;/p&gt;
    &lt;p&gt;The Russians indeed launched on January 11. “The next time General Patton came to a briefing,” Lyman recalled, “he marched into the room, pointed directly at me, and said, ‘Brad, you’d better watch that fellow—he must be a Communist. He knew when the Russians were going to attack!’ ” Sometime later, Lyman learned of a pair of high compliments: that Patton asked Bradley to transfer Lyman to Patton’s staff and that Bradley declined.&lt;/p&gt;
    &lt;p&gt;For the D-Day invasion, 1944, Lyman and most of the OSS did not get to Normandy until “D-Day plus 17,” or June 23. That day, the Daily News carried a story from Helen datelined “Normandy Beachhead, June 21.” It appeared on the front page with an editor’s note above it, saying that she was among the first 10 women correspondents permitted to make an in-and-out visit to Normandy. Throughout the war, women reporters were forbidden to go closer to any front than the nurses were allowed to venture, although unauthorized breaches did occur. (Martha Gellhorn, for example, stowed away on a hospital ship to report the beginning of the D-Day invasion and lost her military privileges as a result.) In this case, the women arrived on an unarmed Douglas transport to pick up the American wounded. Throughout most of the days leading up to and after the invasion, Helen’s datelines were either London or some version of “Supreme Allied Expeditionary Force Headquarters in England.” Gossips passed word, and the Daily News reported that Helen “plays bridge with Eisenhower and Churchill calls her ‘The Kirk.’ ”&lt;/p&gt;
    &lt;p&gt;Not until July 11 was she more permanently in France. Above her first Cherbourg dateline, July 19, her editors trumpeted in italics that she was the “first war correspondent”— woman or otherwise—to be assigned to the headquarters of General Marie-Pierre Koenig, commander of the French forces of the interior. All that coverage of de Gaulle and the Free French had paid off. That day, she wrote home to say she “went up” to see Pete Quesada, the commanding officer of the Tactical Air Command, and that they called Lyman to join them for dinner. Lyman had grown a mustache that she mistook for dirt on his face but otherwise looked tanned and well. “We had fun,” she wrote, “just the three of us, and the mess wasn’t hard to take …”&lt;/p&gt;
    &lt;p&gt;Helen told in interviews of how, when on the continent, she would often attach herself to OSS teams “because even in Normandy and Brittany, they would go into Gestapo headquarters and pick up stuff.” In 1945, when the military authorized a group of reporters to cross the Rhine on a glider, Helen was on the list to go. That is, until Lyman, “of all the interfering characters, somehow got wind of it and saw that my name was taken off. Now you could say that was brotherly-sisterly or male-female, but I must say later I was awfully glad because they all got shot down.”&lt;/p&gt;
    &lt;p&gt;On the night of August 24, Helen rode behind General Jacques-Philippe Leclerc’s tanks as they entered Paris to liberate the city. The following day, she left the luncheon table of Ernest Hemingway, holding court at the newly liberated Ritz, to cover the parade, which culminated at Notre Dame with a memorial service reserved for the families of those who had died in the Resistance. There, inside the cathedral, she was alone among reporters who witnessed the failed assassination attempt on Generals de Gaulle, Koenig, and Leclerc. Years later, for an oral historian, Helen recalled how she had positioned herself standing up and hanging off a grille fence for a better view, when somehow the teeming crowd shoved her into the cathedral, just as the lights went out and the organ music stopped. “Suddenly there was some shooting and a man near me was hit,” she said. “They were shooting from the clerestory balcony. A Dominican monk appeared at the altar. Well, I am not a Catholic, but I knew that monks are not cathedral priests, and he led them in the Magnificat. Then they turned around and marched out.” The day after that, she reopened the Paris office of the Daily News as its new chef de bureau.&lt;/p&gt;
    &lt;p&gt;Lyman, for his war service, received the U.S. Legion of Merit, the Bronze Star medal, the European Theater Ribbon and five battle stars, and both the French and Belgian Croix de Guerre. For Helen, her U.S. Medal of Freedom covered the period from June 6, 1944, to May 8, 1945: D-Day to V-E Day. She also earned a European Theater Ribbon. From France, she won the Médaille de la Reconnaissance in 1945 and the country’s highest award, the Légion d’Honneur, in 1947—along with three men and Janet Flanner, the Paris-based New Yorker writer known in print as Genêt.&lt;/p&gt;
    &lt;p&gt;Why, of all the women who distinguished themselves as World War II correspondents, was Helen the only one singled out for the U.S. military’s highest recognition? It could be that her consistent access to solid, privileged information and her “I-was-there” reporting are the only explanations. All of the Medal of Freedom honorees were cited “for exceptionally meritorious achievement, which aided the United States in the prosecution of the war against the enemy in continental Europe.” Helen’s citation went on to describe her courage, how she “never hesitated to face danger in the pursuance of her profession,” and how her “objective interpretation of military operations and particularly of the renaissance of occupied France not only contributed to understanding of the problem in the mind of the American public but also went far to promote good Allied relations, thereby meriting the praise and recognition of the United States.” How so exactly? Is there more to what Helen did than her citation describes?&lt;/p&gt;
    &lt;p&gt;Once asked by an oral historian about the awarding of the French Légion d’Honneur, Helen remembered the luncheon at the Quai d’Orsay, hosted by Suzanne Borel Bidault, the wife of Foreign Minister Georges Bidault, a figure in the Resistance, and the first French woman to become a diplomat. But Helen said she did not know why she had received it. “I suppose because I had been reporting on the Free French and de Gaulle was president at that point,” she said. “I was known as a strong advocate of France during the war and was in France then, had been there as a correspondent; they gave a number of them to correspondents,” she said. “It was sort of handed out, you know. An awful lot of French have them.” She said she suspected that her friend the baron Louis de Cabrol might have initiated the Médaille de la Reconnaissance because she “plucked him out of a British hospital” and got him into an American one, where a surgeon “saved his knees so that he was able to walk and ride horseback thereafter. I don’t know. I never knew, and, as a matter of fact, I don’t recall it being presented. Maybe it was.”&lt;/p&gt;
    &lt;p&gt;Lyman, after the war, returned briefly to his postcollege job in magazine publishing but then joined the CIA at its formation in 1947. In time, he would become the agency’s inspector general and after that, executive director, its number-three position, despite the polio that left him paralyzed from the waist down in 1952. When he left the agency at age 48 in 1964, he received the President’s Award for Distinguished Federal Civilian Service and the CIA’s Distinguished Intelligence Medal, an honor that had been conferred at that point no more than a dozen times. The letters of nomination, although considerably more restrained in style than the praise lavished on his sister in the Chicago Daily News, are comparable as indications of the respect and admiration he commanded. “Of all the recipients of this medal known to me,” one nominator wrote, “none has given to the CIA and the intelligence community the dedicated, selfless devotion to duty over such a long period of time as Kirk.”&lt;/p&gt;
    &lt;p&gt;The Daily News foreign service started to decline in the period after Colonel Knox’s death on April 28, 1944, so Helen and others from their Europe-based team went to the New York Post, starting late in 1946. During the transition, Helen traveled to Moscow with her good friend and the new U.S. ambassador to the Soviet Union, Walter Bedell Smith, and his wife. A long memo followed but nothing publishable, since any reporting could be tied too closely to the new ambassador. Two years later, in 1950, Smith became Lyman’s boss as director of the CIA, succeeded by Allen Dulles.&lt;/p&gt;
    &lt;p&gt;For Helen, the New York Post of 1947 could not have been a worse fit; the lighter assignments favored by editors annoyed her, as did the way they handled and displayed what she wrote. And yet, despite her stunning résumé, repeated efforts to land another newspaper job failed. No one seemed to have a place for Helen Kirkpatrick. She went to work for the U.S. State Department, first at Voice of America, then as communications director in France for the Economic Cooperation Administration, which administered the Marshall Plan. In Paris again, she worked first for her old friend David Bruce, and then for Barry Bingham when Bruce became the U.S. ambassador to France.&lt;/p&gt;
    &lt;p&gt;Back in Washington, as a since-declassified document of April 17, 1951, records, then–CIA director Allen Dulles had lunch with “Miss Helen Kirkpatrick, State Department DD/P and Mr. Lyman Kirkpatrick.” Days later, she had a new post in Washington as public affairs adviser to the U.S. assistant secretary of state for European Affairs, a job that involved frequent travel abroad.&lt;/p&gt;
    &lt;p&gt;Helen left the State Department in 1953—her appointments were always temporary, although she tried several times for civil service status—to become assistant to the president of Smith College and soon the second wife of Robbins Milbank, a widower and Smith College trustee. She continued to lecture and appear on panels about the war, staying in touch with her legions of contacts, just as she had been doing since her first of many U.S. speaking tours in 1937.&lt;/p&gt;
    &lt;p&gt;Lyman, after leaving Washington, accepted an academic appointment at Brown and wrote two books about the CIA, examining his own experiences and the agency’s structure, strengths, and weaknesses. He died at 78 in 1995, two years before Helen, who lived to 88.&lt;/p&gt;
    &lt;p&gt;A genealogical search has led me to several living Kirkpatrick descendants. Among them, John Pitner, Helen’s great-nephew and one of Lyman’s grandsons, has the greatest sense of the family’s history and lore. He remembers well his grandfather’s study with its many photographs of Lyman posed with the famous, especially the one with General Patton. Although Lyman never shared his career experiences with Pitner directly, the grandson sensed his grandfather’s august personal history all the same. Lyman’s demeanor, Pitner said, was “stern,” almost the opposite of “Aunt Pat.” He recalled a trip to Jackson Hole she organized with him and another grandnephew, both preteens, when she was about 77. Both boys were in the back seat as she careened into the passing lane of the main two-lane road into town and whizzed past an interminable line of stalled traffic as the oncoming cars came perilously close. “You’re not going to make it,” the fly-fishing guide in the front passenger seat said. “Yes, I am,” she replied.&lt;/p&gt;
    &lt;p&gt;From his grandfather’s books, Pitner knew well the paramount importance Lyman placed on “keeping secrets secret. I’m certain [Helen] would have been of the same mind,” he said. “Also, her character was such that she didn’t brag or otherwise bring up her numerous exploits and connections unless specifically asked.” His mother, one of Lyman’s four children, had the same sense. Was his Aunt Pat a spy? She never spoke of the matter, and neither Pitner nor his mother has any knowledge about the question one way or the other. However, he said, neither of them would be surprised to learn that she was.&lt;/p&gt;
    &lt;p&gt;“I do see the potential for an interesting Hollywood story,” Pitner mused. “Given the lack of factual proof (thus far), it might include ‘based on a true story’ in the opening credits. At any rate, maybe you can send me an extra ticket to the premiere!”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46017934</guid><pubDate>Sat, 22 Nov 2025 20:24:17 +0000</pubDate></item><item><title>WorldGen – Text to Immersive 3D Worlds</title><link>https://www.meta.com/en-gb/blog/worldgen-3d-world-generation-reality-labs-generative-ai-research/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46018380</guid><pubDate>Sat, 22 Nov 2025 21:20:24 +0000</pubDate></item></channel></rss>