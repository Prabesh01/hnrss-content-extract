<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 06 Jan 2026 18:16:56 +0000</lastBuildDate><item><title>SCiZE's Classic Warez Collection</title><link>https://scenelist.org/</link><description>&lt;doc fingerprint="b603dfc87132d888"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;SCiZE's CLASSIC WAREZ COLLECTION&lt;/head&gt;
    &lt;p&gt; From 1990 onwards I used to roam BBS's, trading and collecting warez.&lt;lb/&gt; Fast forward over 20 years and I still have very fond memories of the 90's BBS scene.&lt;/p&gt;
    &lt;p&gt; I've put the filelists from those days online here.&lt;lb/&gt; Or browse them on my BBS.&lt;lb/&gt; Search for and view the release nfo's here.&lt;/p&gt;
    &lt;p&gt; The lists are displayed as they originally were on BBS's with all their FILE_ID.DIZ ascii magic.&lt;lb/&gt; Anyone who shares the same nostalgic feelings as me can browse to this website and look through the lists of days gone by.&lt;lb/&gt; These were the golden years of the warez scene as far as I was concerned.&lt;/p&gt;
    &lt;p&gt;I'm very interested in getting in touch with other sceners from the past so if you stumble upon this page please send me an email .&lt;/p&gt;
    &lt;head rend="h2"&gt;NFO SEARCH&lt;/head&gt;
    &lt;p&gt;Find releases based on keywords an/or filenames and view their NFO. Filtering on year also supported (e.g. 'pwa 1993').&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46510625</guid><pubDate>Tue, 06 Jan 2026 10:13:43 +0000</pubDate></item><item><title>AWS raises GPU prices 15% on a Saturday, hopes you weren't paying attention</title><link>https://www.theregister.com/2026/01/05/aws_price_increase/</link><description>&lt;doc fingerprint="4c00405dad86879c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;AWS raises GPU prices 15% on a Saturday, hopes you weren't paying attention&lt;/head&gt;
    &lt;head rend="h2"&gt;An anomaly or the beginning of a new trend? My bet's on the latter&lt;/head&gt;
    &lt;p&gt;I've been tracking AWS for a long time, with a specific emphasis on pricing. "What happens if AWS hikes prices" has always been something of a boogeyman, trotted out as a hypothetical to urge folks to avoid taking dependencies on a given provider.&lt;/p&gt;
    &lt;p&gt;Over the weekend - on a Saturday, no less - that hypothetical became real.&lt;/p&gt;
    &lt;p&gt;AWS has quietly raised prices on its EC2 Capacity Blocks for ML by approximately 15 percent. The p5e.48xlarge instance ‚Äì eight NVIDIA H200 accelerators in a trenchcoat ‚Äì jumped from $34.61 to $39.80 per hour across most regions, while the p5en.48xlarge climbed from $36.18 to $41.61. Customers in US West (N. California) face steeper hikes, with p5e rates rising from $43.26 to $49.75. The change had been telegraphed: AWS's pricing page noted (and bizarrely, still does) that "current prices are scheduled to be updated in January, 2026," though the company neglected to mention which direction.&lt;/p&gt;
    &lt;p&gt;This comes about seven months after AWS trumpeted "up to 45% price reductions" for GPU instances - though that announcement covered On-Demand and Savings Plans rather than Capacity Blocks. Funny how that works.&lt;/p&gt;
    &lt;p&gt;For the uninitiated, Capacity Blocks are AWS's answer to "I need guaranteed GPU capacity for my ML training job next Tuesday." You reserve specific GPU instances for a defined time window ‚Äì anywhere from a day to a few weeks out ‚Äì and pay up front at a locked-in rate. It's popular with companies doing serious ML work who can't afford to have a training run interrupted because spot capacity evaporated. The pricing should make it abundantly clear that the people using this aren't hobbyists; these are teams with budgets measured in millions.&lt;/p&gt;
    &lt;p&gt;An Amazon spox told us via email, "EC2 Capacity Blocks for ML pricing vary based on supply and demand patterns, as described on the product detail page. This price adjustment reflects the supply/demand patterns we expect this quarter."&lt;/p&gt;
    &lt;p&gt;To be clear, AWS has raised prices before, but rarely as a straight increase to a line item. The company prefers to change pricing dimensions entirely, often spinning this as a price reduction for most customers ‚Äì a claim I'd characterize as "creative." Historical straight-up price increases have been tied to regulatory actions: per-SMS charges in certain markets and the like. This is different.&lt;/p&gt;
    &lt;p&gt;The timing is curious for another reason: it hands Azure and GCP a talking point on a silver platter. Both have been aggressively courting ML workloads, and "AWS just raised GPU prices 15%" is exactly the kind of ammunition enterprise sales teams dream about. Whether the competitors can actually absorb the demand is another question ‚Äì GPU constraints are hardly unique to AWS ‚Äì but perception matters in enterprise deals.&lt;/p&gt;
    &lt;p&gt;For companies with Enterprise Discount Programs or other negotiated agreements, this raises uncomfortable questions. EDPs typically guarantee discounts off public pricing ‚Äì so if public pricing goes up 15 percent, your "discounted" rate just got more expensive in absolute terms, even if the percentage held steady. I expect some pointed conversations between AWS account teams and their larger customers in the coming weeks.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why are they doing this?&lt;/head&gt;
    &lt;p&gt;It's hard not to see this as a bellwether. GPUs are increasingly constrained globally as the world pivots to generating slop-as-a-service in every conceivable domain. The question is what this means for other resource types down the road. Does the global RAM crunch mean RAM-centric services are next? You can ignore ML Capacity Block pricing if you're not running machine learning workloads ‚Äì which describes north of 95 percent of most companies' cloud spend ‚Äì but RAM touches every service AWS offers. Well, possibly excepting their support function, though that's rapidly becoming "AI-Powered" too, so give it time.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Deploying to Amazon's cloud is a pain in the AWS younger devs won't tolerate&lt;/item&gt;
      &lt;item&gt;AWS adds hybrid cloud storage support for Nutanix's AHV hypervisor&lt;/item&gt;
      &lt;item&gt;Jassy taps 27-year Amazon veteran to run AGI org, which is now definitely a thing that exists&lt;/item&gt;
      &lt;item&gt;Smartphones face a memory cost crunch ‚Äì and buyers aren't in the mood&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The canary-in-the-coal-mine concern here isn't GPUs specifically, but rather the precedent it establishes. AWS has spent two decades conditioning customers to expect prices only ever go down. That expectation is now broken. Once you've raised prices on one service and the world doesn't end, the second increase becomes easier. And the third. The playbook has changed.&lt;/p&gt;
    &lt;p&gt;Keep an eye on services where AWS faces genuine supply constraints or where their costs have materially increased. Graviton instances have been priced aggressively to drive adoption ‚Äì what happens when ARM chip supply tightens? Data transfer costs have been a cash cow for years, but they've also been stable; are those next? I don't have inside information, but I do have pattern recognition, and the pattern just shifted.&lt;/p&gt;
    &lt;p&gt;AWS has long benefited from the assumption that cloud pricing only trends in one direction. That assumption died on a Saturday in January, with all the fanfare of a Terms of Service update. The question isn't whether this matters ‚Äì it does. The question is whether it's an anomaly or the new normal. My money's on the latter. ¬Æ&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46511153</guid><pubDate>Tue, 06 Jan 2026 11:42:35 +0000</pubDate></item><item><title>System: Control your Mac from anywhere using natural language</title><link>https://system.surf/</link><description>&lt;doc fingerprint="a51fdf48312faeb2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;SYSTEM&lt;/head&gt;
    &lt;p&gt;remote mac automation&lt;/p&gt;
    &lt;p&gt;Control your Mac from anywhere using natural language. Built with Cloudflare Agents SDK for intelligent scheduling, memory, and tool orchestration.&lt;/p&gt;
    &lt;head rend="h2"&gt;quick start&lt;/head&gt;
    &lt;head rend="h3"&gt;1. clone and install&lt;/head&gt;
    &lt;code&gt;git clone https://github.com/ygwyg/system
cd system &amp;amp;&amp;amp; npm install&lt;/code&gt;
    &lt;head rend="h3"&gt;2. run setup wizard&lt;/head&gt;
    &lt;code&gt;npm run setup&lt;/code&gt;
    &lt;p&gt;Interactive setup: Anthropic API key, Raycast extensions, remote access.&lt;/p&gt;
    &lt;head rend="h3"&gt;3. start system&lt;/head&gt;
    &lt;code&gt;npm start&lt;/code&gt;
    &lt;p&gt;Starts bridge, tunnel, and opens the agent UI.&lt;/p&gt;
    &lt;head rend="h2"&gt;architecture&lt;/head&gt;
    &lt;p&gt;SYSTEM uses a split architecture for security: the Agent (brain) runs on Cloudflare Workers, while the Bridge (body) runs locally on your Mac.&lt;/p&gt;
    &lt;quote&gt;√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢ USER √¢ √¢ (phone/browser) √¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢¬¨√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢ HTTPS √¢¬º √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢ AGENT (Brain) √¢ √¢ Cloudflare Workers √¢ √¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢ √¢ √¢ Claude √¢ √¢ State √¢ √¢ Schedules √¢ √¢ √¢ √¢ AI √¢ √¢ (D.O.) √¢ √¢ (D.O.) √¢ √¢ √¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢¬¨√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢ Tunnel √¢¬º √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢ BRIDGE (Body) √¢ √¢ Your Mac (local) √¢ √¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢ √¢ √¢ AppleScript √¢ √¢ Shell √¢ √¢ Raycast √¢ √¢ √¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢&lt;/quote&gt;
    &lt;p&gt;√¢¬¢ Claude for NLP&lt;/p&gt;
    &lt;p&gt;√¢¬¢ State, memory, scheduling&lt;/p&gt;
    &lt;p&gt;√¢¬¢ WebSocket real-time&lt;/p&gt;
    &lt;p&gt;√¢¬¢ AppleScript, shell exec&lt;/p&gt;
    &lt;p&gt;√¢¬¢ Raycast extensions&lt;/p&gt;
    &lt;p&gt;√¢¬¢ Cloudflare Tunnel&lt;/p&gt;
    &lt;head rend="h2"&gt;authentication&lt;/head&gt;
    &lt;p&gt;All requests require an API secret via Bearer token or query parameter.&lt;/p&gt;
    &lt;code&gt;// Header
Authorization: Bearer &amp;lt;api_secret&amp;gt;

// Or query parameter
?token=&amp;lt;api_secret&amp;gt;&lt;/code&gt;
    &lt;p&gt;The API secret is generated during &lt;code&gt;npm run setup&lt;/code&gt; and stored in &lt;code&gt;bridge.config.json&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;chat&lt;/head&gt;
    &lt;p&gt;Send natural language commands to control your Mac.&lt;/p&gt;
    &lt;p&gt;Send a message to the agent.&lt;/p&gt;
    &lt;head rend="h3"&gt;request&lt;/head&gt;
    &lt;code&gt;{
  "message": "Play some jazz music"
}&lt;/code&gt;
    &lt;head rend="h3"&gt;response&lt;/head&gt;
    &lt;code&gt;{
  "message": "Playing jazz on Apple Music",
  "actions": [{
    "tool": "music_play",
    "args": { "query": "jazz" },
    "success": true,
    "result": "Now playing: Jazz Vibes"
  }]
}&lt;/code&gt;
    &lt;p&gt;Clear conversation history and state.&lt;/p&gt;
    &lt;head rend="h2"&gt;schedules&lt;/head&gt;
    &lt;p&gt;Schedule one-time or recurring tasks using natural language or cron syntax.&lt;/p&gt;
    &lt;p&gt;List all scheduled tasks.&lt;/p&gt;
    &lt;code&gt;{
  "schedules": [{
    "id": "abc123",
    "description": "Play closing time",
    "scheduledAt": "2026-01-05T17:00:00Z",
    "cron": "0 17 * * *"
  }]
}&lt;/code&gt;
    &lt;p&gt;Cancel a scheduled task by ID.&lt;/p&gt;
    &lt;p&gt; √¢¬¢ "Remind me to call mom in 30 minutes"&lt;lb/&gt; √¢¬¢ "Every day at 5pm, play Closing Time"&lt;lb/&gt; √¢¬¢ "At 9am tomorrow, open Linear" &lt;/p&gt;
    &lt;head rend="h2"&gt;state&lt;/head&gt;
    &lt;p&gt;The agent maintains persistent state including preferences and conversation history.&lt;/p&gt;
    &lt;p&gt;Get current agent state for debugging.&lt;/p&gt;
    &lt;code&gt;{
  "preferences": { "wife": "Jane" },
  "historyLength": 12,
  "scheduleCount": 2
}&lt;/code&gt;
    &lt;head rend="h2"&gt;core tools&lt;/head&gt;
    &lt;p&gt;Foundational tools for Mac automation.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;tool&lt;/cell&gt;
        &lt;cell role="head"&gt;description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;open_app&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Open any application&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;open_url&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Open URL in browser&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;shell&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Run safe shell commands&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;shell_list&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;List available shell commands&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;applescript&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Execute AppleScript&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;notify&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Show macOS notification&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;say&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Text-to-speech&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;clipboard_get&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Get clipboard contents&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;clipboard_set&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Set clipboard contents&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;screenshot&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Take screenshot&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;music&lt;/head&gt;
    &lt;p&gt;Control Apple Music playback.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;tool&lt;/cell&gt;
        &lt;cell role="head"&gt;description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;music_play&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Play/search music&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;music_pause&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Pause playback&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;music_next&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Skip to next track&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;music_previous&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Previous track&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;music_current&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Get current track info&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;volume_get&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Get volume level&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;volume_set&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Set volume (0-100)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;volume_up&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Increase volume 10%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;volume_down&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Decrease volume 10%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;volume_mute&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Toggle mute&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;messaging&lt;/head&gt;
    &lt;p&gt;Send iMessages with human-in-the-loop confirmation.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;tool&lt;/cell&gt;
        &lt;cell role="head"&gt;description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;search_contacts&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Find contact by name&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;send_imessage&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Send iMessage&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;When you say "text my wife hello", SYSTEM will: 1) resolve "wife" from preferences, 2) search contacts, 3) ask for confirmation before sending.&lt;/p&gt;
    &lt;head rend="h2"&gt;system&lt;/head&gt;
    &lt;p&gt;Control system settings, get status, manage files and apps.&lt;/p&gt;
    &lt;head rend="h3"&gt;calendar &amp;amp; reminders&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;tool&lt;/cell&gt;
        &lt;cell role="head"&gt;description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;calendar_today&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Today's events&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;calendar_upcoming&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Upcoming events&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;calendar_next&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Next event&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;calendar_create&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Create event&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;reminders_list&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;List reminders&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;reminders_create&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Create reminder&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;reminders_complete&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Complete reminder&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;display &amp;amp; focus&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;tool&lt;/cell&gt;
        &lt;cell role="head"&gt;description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;brightness_set&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Set brightness&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;dark_mode_toggle&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Toggle dark mode&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;dark_mode_status&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Get dark mode status&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;dnd_toggle&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Toggle Do Not Disturb&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;lock_screen&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Lock Mac&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;sleep_display&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Sleep display&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;sleep_mac&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Sleep Mac&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;system status&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;tool&lt;/cell&gt;
        &lt;cell role="head"&gt;description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;battery_status&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Battery level &amp;amp; charging&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;wifi_status&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;WiFi network info&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;storage_status&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Disk space&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;running_apps&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;List running apps&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;front_app&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Get frontmost app&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;notes&lt;/head&gt;
    &lt;p&gt;Read and write Apple Notes.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;tool&lt;/cell&gt;
        &lt;cell role="head"&gt;description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;notes_list&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;List recent notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;notes_search&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Search notes by keyword&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;notes_create&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Create a new note&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;notes_read&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Read note content&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;notes_append&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Append to existing note&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;files&lt;/head&gt;
    &lt;p&gt;Search and manage files via Finder.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;tool&lt;/cell&gt;
        &lt;cell role="head"&gt;description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;finder_search&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Search files by name&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;finder_downloads&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;List recent downloads&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;finder_desktop&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;List desktop files&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;finder_reveal&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Reveal file in Finder&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;finder_trash&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Move file to trash&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;shortcuts&lt;/head&gt;
    &lt;p&gt;Run Apple Shortcuts.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;tool&lt;/cell&gt;
        &lt;cell role="head"&gt;description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;shortcut_run&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Run a shortcut by name&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;shortcut_list&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;List available shortcuts&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Create powerful automations in Shortcuts.app, then trigger them via SYSTEM. Example: "Run my Morning Routine shortcut"&lt;/p&gt;
    &lt;head rend="h2"&gt;browser&lt;/head&gt;
    &lt;p&gt;Get info from Safari, Chrome, Arc, or other browsers.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;tool&lt;/cell&gt;
        &lt;cell role="head"&gt;description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_url&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Get current tab URL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_tabs&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;List open tabs&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;raycast extensions&lt;/head&gt;
    &lt;p&gt;Execute Raycast extensions for powerful integrations. SYSTEM scans your installed extensions and makes them available as tools.&lt;/p&gt;
    &lt;head rend="h3"&gt;how it works&lt;/head&gt;
    &lt;p&gt;During &lt;code&gt;npm run setup&lt;/code&gt;, SYSTEM scans your Raycast extensions folder and presents compatible commands for you to enable. Each enabled command becomes a dedicated tool.&lt;/p&gt;
    &lt;quote&gt;Raycast Extension SYSTEM Tool √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢ spotify-player/play √¢ spotify_play linear/create-issue √¢ linear_create_issue slack/send-message √¢ slack_send_message&lt;/quote&gt;
    &lt;head rend="h3"&gt;extension discovery&lt;/head&gt;
    &lt;p&gt;SYSTEM looks in &lt;code&gt;~/.config/raycast/extensions/&lt;/code&gt; and reads each extension's &lt;code&gt;package.json&lt;/code&gt; to find commands. Only commands with &lt;code&gt;mode: "no-view"&lt;/code&gt; or &lt;code&gt;mode: "view"&lt;/code&gt; are compatible.&lt;/p&gt;
    &lt;head rend="h3"&gt;compatible extension types&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;type&lt;/cell&gt;
        &lt;cell role="head"&gt;works?&lt;/cell&gt;
        &lt;cell role="head"&gt;notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;No-view commands&lt;/cell&gt;
        &lt;cell&gt;√¢ Best&lt;/cell&gt;
        &lt;cell&gt;Execute silently, return result&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;View commands&lt;/cell&gt;
        &lt;cell&gt;√¢ √Ø¬∏ Partial&lt;/cell&gt;
        &lt;cell&gt;Opens Raycast UI briefly&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Form commands&lt;/cell&gt;
        &lt;cell&gt;√¢ No&lt;/cell&gt;
        &lt;cell&gt;Requires user input in Raycast&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Menu bar commands&lt;/cell&gt;
        &lt;cell&gt;√¢ No&lt;/cell&gt;
        &lt;cell&gt;Background only&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;popular extensions that work well&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;extension&lt;/cell&gt;
        &lt;cell role="head"&gt;commands&lt;/cell&gt;
        &lt;cell role="head"&gt;use case&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;spotify-player&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;play, pause, next, like&lt;/cell&gt;
        &lt;cell&gt;Music control&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;linear&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;create-issue, search&lt;/cell&gt;
        &lt;cell&gt;Issue tracking&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;slack&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;send-message, set-status&lt;/cell&gt;
        &lt;cell&gt;Team communication&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;todoist&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;create-task, today&lt;/cell&gt;
        &lt;cell&gt;Task management&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;github&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;create-issue, search&lt;/cell&gt;
        &lt;cell&gt;Code management&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;notion&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;create-page, search&lt;/cell&gt;
        &lt;cell&gt;Notes &amp;amp; docs&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;tool naming&lt;/head&gt;
    &lt;p&gt;Tools are named as &lt;code&gt;{extension}_{command}&lt;/code&gt; with hyphens replaced by underscores:&lt;/p&gt;
    &lt;code&gt;// Extension: linear, Command: create-issue-for-myself
Tool name: linear_create_issue_for_myself

// Extension: spotify-player, Command: play
Tool name: spotify_player_play&lt;/code&gt;
    &lt;head rend="h3"&gt;using raycast tools&lt;/head&gt;
    &lt;p&gt;Once enabled, just ask naturally:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"Create a Linear issue for fixing the login bug"&lt;/item&gt;
      &lt;item&gt;"Send a Slack message to #general saying hello"&lt;/item&gt;
      &lt;item&gt;"Play Daft Punk on Spotify"&lt;/item&gt;
      &lt;item&gt;"Add 'buy groceries' to my Todoist"&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;generic raycast tool&lt;/head&gt;
    &lt;p&gt;For extensions not in your enabled list, use the generic &lt;code&gt;raycast&lt;/code&gt; tool:&lt;/p&gt;
    &lt;code&gt;{
  "extension": "spotify-player",
  "command": "play",
  "arguments": { "query": "jazz" }
}&lt;/code&gt;
    &lt;head rend="h3"&gt;deep link format&lt;/head&gt;
    &lt;p&gt;Under the hood, SYSTEM uses Raycast deep links:&lt;/p&gt;
    &lt;code&gt;raycast://extensions/{author}/{extension}/{command}?arguments={json}&lt;/code&gt;
    &lt;head rend="h3"&gt;troubleshooting&lt;/head&gt;
    &lt;p&gt;If an extension isn't showing in setup, make sure it's installed via Raycast Store, not manually. Check &lt;code&gt;~/.config/raycast/extensions/&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;This usually means the command requires UI interaction (forms, selections). These commands aren't fully compatible. Try a different command from the same extension.&lt;/p&gt;
    &lt;p&gt;Many extensions require you to authenticate in Raycast first. Open Raycast and run the command manually once to complete OAuth/login flows.&lt;/p&gt;
    &lt;head rend="h3"&gt;re-scanning extensions&lt;/head&gt;
    &lt;p&gt;If you install new Raycast extensions, run setup again to add them:&lt;/p&gt;
    &lt;code&gt;npm run setup&lt;/code&gt;
    &lt;p&gt;Your existing configuration will be preserved√¢you'll just see new extensions to enable.&lt;/p&gt;
    &lt;head rend="h2"&gt;bridge api&lt;/head&gt;
    &lt;p&gt;Direct API to the local bridge. Used by the agent, but also available for custom integrations.&lt;/p&gt;
    &lt;p&gt;List all available tools on the bridge.&lt;/p&gt;
    &lt;p&gt;Execute a specific tool.&lt;/p&gt;
    &lt;code&gt;{
  "tool": "open_app",
  "args": { "app": "Safari" }
}&lt;/code&gt;
    &lt;p&gt;Check bridge status.&lt;/p&gt;
    &lt;head rend="h2"&gt;websocket&lt;/head&gt;
    &lt;p&gt;Real-time updates for scheduled tasks and notifications.&lt;/p&gt;
    &lt;code&gt;// Connect to WebSocket
const ws = new WebSocket('wss://your-agent.workers.dev/ws?token=...');

ws.onmessage = (event) =&amp;gt; {
  const data = JSON.parse(event.data);
  // Types: scheduled_result, notification, bridge_status
  console.log(data.type, data.payload);
};&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;event type&lt;/cell&gt;
        &lt;cell role="head"&gt;description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;scheduled_result&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Result of a scheduled task&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;notification&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;System notification&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;bridge_status&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Bridge online/offline&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;security&lt;/head&gt;
    &lt;p&gt;SYSTEM is designed with security as a priority.&lt;/p&gt;
    &lt;head rend="h4"&gt;√∞ authentication&lt;/head&gt;
    &lt;p&gt;Bearer token required for all requests. Tokens are generated during setup and stored locally.&lt;/p&gt;
    &lt;head rend="h4"&gt;√∞¬°√Ø¬∏ shell safety&lt;/head&gt;
    &lt;p&gt;Only allowlisted commands can run. Dangerous patterns (rm -rf, sudo, etc.) are blocked.&lt;/p&gt;
    &lt;head rend="h4"&gt;√∞ tunnel security&lt;/head&gt;
    &lt;p&gt;Quick Tunnels are ephemeral √¢ new URL each session. Bridge binds to 0.0.0.0 only when tunnel is active.&lt;/p&gt;
    &lt;head rend="h4"&gt;√∞¬§ human-in-the-loop&lt;/head&gt;
    &lt;p&gt;Sensitive actions like sending messages require explicit user confirmation.&lt;/p&gt;
    &lt;head rend="h3"&gt;cloudflare access (recommended)&lt;/head&gt;
    &lt;p&gt;If you deploy to Cloudflare Workers, add Cloudflare Access for Zero Trust authentication at the edge √¢ before requests even reach your agent.&lt;/p&gt;
    &lt;p&gt;While the API secret provides application-level auth, Cloudflare Access adds network-level protection. Only authenticated users can reach your agent at all.&lt;/p&gt;
    &lt;head rend="h3"&gt;setup via dashboard&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Go to Cloudflare Zero Trust Dashboard&lt;/item&gt;
      &lt;item&gt;Navigate to Access √¢ Applications √¢ Add an application&lt;/item&gt;
      &lt;item&gt;Select Self-hosted and enter your worker URL&lt;/item&gt;
      &lt;item&gt;Create an access policy (e.g., email = &lt;code&gt;you@example.com&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Save √¢ users must now authenticate before accessing SYSTEM&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;automation (terraform)&lt;/head&gt;
    &lt;code&gt;# Note: wrangler doesn't support Access config directly
# Use Terraform for infrastructure-as-code

resource "cloudflare_access_application" "system" {
  zone_id          = var.zone_id
  name             = "SYSTEM"
  domain           = "your-agent.workers.dev"
  session_duration = "24h"
}

resource "cloudflare_access_policy" "allow_me" {
  application_id = cloudflare_access_application.system.id
  zone_id        = var.zone_id
  name           = "Allow specific emails"
  precedence     = 1
  decision       = "allow"

  include {
    email = ["you@example.com"]
  }
}&lt;/code&gt;
    &lt;p&gt;Cloudflare Access is configured separately from Workers deployment. The &lt;code&gt;wrangler&lt;/code&gt; CLI doesn't manage Access policies √¢ use the dashboard or Terraform.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46511298</guid><pubDate>Tue, 06 Jan 2026 12:04:57 +0000</pubDate></item><item><title>Show HN: Prism.Tools ‚Äì Free and privacy-focused developer utilities</title><link>https://blgardner.github.io/prism.tools/</link><description>&lt;doc fingerprint="4aabc530823215a8"&gt;
  &lt;main&gt;
    &lt;p&gt;PRISM.TOOLS üîç ‚òï Donate Every Dev Tool You Need Fast. Private. Free forever. üîí Data never leaves your browser All Tools Formatters &amp;amp; Parsers Security &amp;amp; Dev Visual &amp;amp; CSS Generators &amp;amp; Content Encoders &amp;amp; Transformers üõ†Ô∏è All Tools Recent Tools 0 Tools Used 38 Available&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46511469</guid><pubDate>Tue, 06 Jan 2026 12:33:49 +0000</pubDate></item><item><title>C Is Best (2025)</title><link>https://sqlite.org/whyc.html</link><description>&lt;doc fingerprint="c34a58f9ca2a1b78"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;td&gt;Note: Sections 2.0 and 3.0 of this article were added in response to comments on Hacker News and Reddit.&lt;/td&gt;
    &lt;/quote&gt;
    &lt;p&gt;Since its inception on 2000-05-29, SQLite has been implemented in generic C. C was and continues to be the best language for implementing a software library like SQLite. There are no plans to recode SQLite in any other programming language at this time.&lt;/p&gt;
    &lt;p&gt;The reasons why C is the best language to implement SQLite include:&lt;/p&gt;
    &lt;p&gt;An intensively used low-level library like SQLite needs to be fast. (And SQLite is fast, see Internal Versus External BLOBs and 35% Faster Than The Filesystem for examples.)&lt;/p&gt;
    &lt;p&gt;C is a great language for writing fast code. C is sometimes described as "portable assembly language". It enables developers to code as close to the underlying hardware as possible while still remaining portable across platforms.&lt;/p&gt;
    &lt;p&gt;Other programming languages sometimes claim to be "as fast as C". But no other language claims to be faster than C for general-purpose programming, because none are.&lt;/p&gt;
    &lt;p&gt;Nearly all systems have the ability to call libraries written in C. This is not true of other implementation languages.&lt;/p&gt;
    &lt;p&gt;So, for example, Android applications written in Java are able to invoke SQLite (through an adaptor). Maybe it would have been more convenient for Android if SQLite had been coded in Java as that would make the interface simpler. However, on iPhone applications are coded in Objective-C or Swift, neither of which have the ability to call libraries written in Java. Thus, SQLite would be unusable on iPhones had it been written in Java.&lt;/p&gt;
    &lt;p&gt;Libraries written in C do not have a huge run-time dependency. In its minimum configuration, SQLite requires only the following routines from the standard C library:&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;In a more complete build, SQLite also uses library routines like malloc() and free() and operating system interfaces for opening, reading, writing, and closing files. But even then, the number of dependencies is very small. Other "modern" languages, in contrast, often require multi-megabyte runtimes loaded with thousands and thousands of interfaces.&lt;/p&gt;
    &lt;p&gt;The C language is old and boring. It is a well-known and well-understood language. This is exactly what one wants when developing a module like SQLite. Writing a small, fast, and reliable database engine is hard enough as it is without the implementation language changing out from under you with each update to the implementation language specification.&lt;/p&gt;
    &lt;p&gt;Some programmers cannot imagine developing a complex system like SQLite in a language that is not "object oriented". So why is SQLite not coded in C++ or Java?&lt;/p&gt;
    &lt;p&gt;Libraries written in C++ or Java can generally only be used by applications written in the same language. It is difficult to get an application written in Haskell or Java to invoke a library written in C++. On the other hand, libraries written in C are callable from any programming language.&lt;/p&gt;
    &lt;p&gt;Object-Oriented is a design pattern, not a programming language. You can do object-oriented programming in any language you want, including assembly language. Some languages (ex: C++ or Java) make object-oriented easier. But you can still do object-oriented programming in languages like C.&lt;/p&gt;
    &lt;p&gt;Object-oriented is not the only valid design pattern. Many programmers have been taught to think purely in terms of objects. And, to be fair, objects are often a good way to decompose a problem. But objects are not the only way, and are not always the best way to decompose a problem. Sometimes good old procedural code is easier to write, easier to maintain and understand, and faster than object-oriented code.&lt;/p&gt;
    &lt;p&gt;When SQLite was first being developed, Java was a young and immature language. C++ was older, but was undergoing such growing pains that it was difficult to find any two C++ compilers that worked the same way. So C was definitely a better choice back when SQLite was first being developed. The situation is less stark now, but there is little to no benefit in recoding SQLite at this point.&lt;/p&gt;
    &lt;p&gt;There has lately been a lot of interest in "safe" programming languages like Rust or Go in which it is impossible, or is at least difficult, to make common programming errors like memory leaks or array overruns. So the question often arises as to why SQLite is not coded in a "safe" language.&lt;/p&gt;
    &lt;p&gt;None of the safe programming languages existed for the first 10 years of SQLite's existence. SQLite could be recoded in Go or Rust, but doing so would probably introduce far more bugs than would be fixed, and it may also result in slower code.&lt;/p&gt;
    &lt;p&gt;Safe languages insert additional machine branches to do things like verify that array accesses are in-bounds. In correct code, those branches are never taken. That means that the machine code cannot be 100% branch tested, which is an important component of SQLite's quality strategy.&lt;/p&gt;
    &lt;p&gt;Safe languages usually want to abort if they encounter an out-of-memory (OOM) situation. SQLite is designed to recover gracefully from an OOM. It is unclear how this could be accomplished in the current crop of safe languages.&lt;/p&gt;
    &lt;p&gt;All of the existing safe languages are new. The developers of SQLite applaud the efforts of computer language researchers in trying to develop languages that are easier to program safely. We encourage these efforts to continue. But we ourselves are more interested in old and boring languages when it comes to implementing SQLite.&lt;/p&gt;
    &lt;p&gt;All that said, it is possible that SQLite might one day be recoded in Rust. Recoding SQLite in Go is unlikely since Go hates assert(). But Rust is a possibility. Some preconditions that must occur before SQLite is recoded in Rust include:&lt;/p&gt;
    &lt;p&gt;If you are a "rustacean" and feel that Rust already meets the preconditions listed above, and that SQLite should be recoded in Rust, then you are welcomed and encouraged to contact the SQLite developers privately and argue your case.&lt;/p&gt;
    &lt;p&gt;This page was last updated on 2025-05-09 15:56:17Z&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46511470</guid><pubDate>Tue, 06 Jan 2026 12:33:54 +0000</pubDate></item><item><title>Show HN: DDL to Data ‚Äì Generate realistic test data from SQL schemas</title><link>https://news.ycombinator.com/item?id=46511578</link><description>&lt;doc fingerprint="2deaaa31c784bee8"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;I built DDL to Data after repeatedly pushing back on "just use production data and mask it" requests. Teams needed populated databases for testing, but pulling prod meant security reviews, PII scrubbing, and DevOps tickets. Hand-written seed scripts were the alternative slow, fragile, and out of sync the moment schemas changed.&lt;/p&gt;
      &lt;p&gt;Paste your CREATE TABLE statements, get realistic test data back. It parses your schema, preserves foreign key relationships, and generates data that looks real, emails look like emails, timestamps are reasonable, uniqueness constraints are honored.&lt;/p&gt;
      &lt;p&gt;No setup, no config. Works with PostgreSQL and MySQL.&lt;/p&gt;
      &lt;p&gt;https://ddltodata.com&lt;/p&gt;
      &lt;p&gt;Would love feedback from anyone who deals with test data or staging environments. What's missing?&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46511578</guid><pubDate>Tue, 06 Jan 2026 12:47:23 +0000</pubDate></item><item><title>Gemini Protocol Deployment Statistics</title><link>https://www.obsessivefacts.com/gemini-proxy?uri=gemini%3A%2F%2Fgemini.bortzmeyer.org%2Fsoftware%2Flupa%2Fstats.gmi</link><description>&lt;doc fingerprint="7309191894b681c1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Statistics on the Gemini space&lt;/head&gt;
    &lt;p&gt;This page presents some statistics on the current state of the Gemini space. It has been updated on 2026-01-06 04:04:01Z.&lt;/p&gt;
    &lt;p&gt;It cannot claim to represent the entire space. The real number of URIs is certainly higher. There are several reasons why many URIs are not in the database:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;the capsule may forbid retrieval, through robots.txt,&lt;/item&gt;
      &lt;item&gt;we do not know all the URIs and some cannot be found from the ones we know,&lt;/item&gt;
      &lt;item&gt;Lupa has a maximum number of URIs per capsule, to save resources (currently 10000).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;On this page, "working" means there was a successful connection recently. "recently" means "less than 31 days". "Dead" URLs and capsules are removed after 46 days and no longer appear in any statistics.&lt;/p&gt;
    &lt;p&gt;Currently, our database includes 646,369 URIs, 560,646 of them having been checked successfully (status code 20) and recently. Among the recently accessed, 431,340 URIs serve a Gemini content.&lt;/p&gt;
    &lt;head rend="h2"&gt;Resources&lt;/head&gt;
    &lt;p&gt;The average size of the resources is 46,339 bytes.&lt;/p&gt;
    &lt;head rend="h3"&gt;Quantiles&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;10% of the resources are 306 bytes or less,&lt;/item&gt;
      &lt;item&gt;20% of the resources are 674 bytes or less,&lt;/item&gt;
      &lt;item&gt;30% of the resources are 1,098 bytes or less,&lt;/item&gt;
      &lt;item&gt;40% of the resources are 1,466 bytes or less,&lt;/item&gt;
      &lt;item&gt;50% of the resources are 2,318 bytes or less, MEDIAN&lt;/item&gt;
      &lt;item&gt;60% of the resources are 3,902 bytes or less,&lt;/item&gt;
      &lt;item&gt;70% of the resources are 6,768 bytes or less,&lt;/item&gt;
      &lt;item&gt;80% of the resources are 14,821 bytes or less,&lt;/item&gt;
      &lt;item&gt;90% of the resources are 63,909 bytes or less,&lt;/item&gt;
      &lt;item&gt;100% of the resources are 4,156,230 bytes or less.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;# Quantiles only for Gemini pages&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;10% of the resources are 273 bytes or less,&lt;/item&gt;
      &lt;item&gt;20% of the resources are 524 bytes or less,&lt;/item&gt;
      &lt;item&gt;30% of the resources are 851 bytes or less,&lt;/item&gt;
      &lt;item&gt;40% of the resources are 1,136 bytes or less,&lt;/item&gt;
      &lt;item&gt;50% of the resources are 1,466 bytes or less, MEDIAN&lt;/item&gt;
      &lt;item&gt;60% of the resources are 2,279 bytes or less,&lt;/item&gt;
      &lt;item&gt;70% of the resources are 3,537 bytes or less,&lt;/item&gt;
      &lt;item&gt;80% of the resources are 5,781 bytes or less,&lt;/item&gt;
      &lt;item&gt;90% of the resources are 10,011 bytes or less,&lt;/item&gt;
      &lt;item&gt;100% of the resources are 4,156,230 bytes or less.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Ranges&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Less than 10 bytes: 1380 URLs (0.25 %)&lt;/item&gt;
      &lt;item&gt;10 to 100 bytes: 12513 URLs (2.2 %)&lt;/item&gt;
      &lt;item&gt;100 to 1000 bytes: 141180 URLs (25.2 %)&lt;/item&gt;
      &lt;item&gt;1 to 10 kbytes: 271587 URLs (48.4 %)&lt;/item&gt;
      &lt;item&gt;10 to 100 kbytes: 89482 URLs (16.0 %)&lt;/item&gt;
      &lt;item&gt;100 to 1000 kbytes: 33186 URLs (5.9 %)&lt;/item&gt;
      &lt;item&gt;More than 1000 kbytes: 11318 URLs (2.02 %)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Most common media (MIME) types&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;text/gemini: 431,340 URLs&lt;/item&gt;
      &lt;item&gt;image/jpeg: 35,445 URLs&lt;/item&gt;
      &lt;item&gt;text/plain: 25,736 URLs&lt;/item&gt;
      &lt;item&gt;image/png: 23,934 URLs&lt;/item&gt;
      &lt;item&gt;application/octet-stream: 10,889 URLs&lt;/item&gt;
      &lt;item&gt;image/webp: 7,788 URLs&lt;/item&gt;
      &lt;item&gt;application/pdf: 5,370 URLs&lt;/item&gt;
      &lt;item&gt;image/gif: 2,696 URLs&lt;/item&gt;
      &lt;item&gt;application/zip: 2,563 URLs&lt;/item&gt;
      &lt;item&gt;octet/stream: 1,954 URLs&lt;/item&gt;
      &lt;item&gt;application/x-mscardfile: 1,928 URLs&lt;/item&gt;
      &lt;item&gt;text/html: 1,512 URLs&lt;/item&gt;
      &lt;item&gt;audio/mpeg: 1,041 URLs&lt;/item&gt;
      &lt;item&gt;text/x-diff: 864 URLs&lt;/item&gt;
      &lt;item&gt;text/markdown: 815 URLs&lt;/item&gt;
      &lt;item&gt;audio/ogg: 739 URLs&lt;/item&gt;
      &lt;item&gt;application/atom+xml: 639 URLs&lt;/item&gt;
      &lt;item&gt;application/json: 588 URLs&lt;/item&gt;
      &lt;item&gt;text/xml: 549 URLs&lt;/item&gt;
      &lt;item&gt;image/svg+xml: 343 URLs&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Most common languages&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Unspecified: 383,664 URLs&lt;/item&gt;
      &lt;item&gt;en: 121,355 URLs&lt;/item&gt;
      &lt;item&gt;de: 20,574 URLs&lt;/item&gt;
      &lt;item&gt;fr: 13,024 URLs&lt;/item&gt;
      &lt;item&gt;es: 9,242 URLs&lt;/item&gt;
      &lt;item&gt;it: 7,635 URLs&lt;/item&gt;
      &lt;item&gt;es_ar: 1,273 URLs&lt;/item&gt;
      &lt;item&gt;ru: 684 URLs&lt;/item&gt;
      &lt;item&gt;fa: 572 URLs&lt;/item&gt;
      &lt;item&gt;ja: 560 URLs&lt;/item&gt;
      &lt;item&gt;grc: 420 URLs&lt;/item&gt;
      &lt;item&gt;en_au: 252 URLs&lt;/item&gt;
      &lt;item&gt;arb: 202 URLs&lt;/item&gt;
      &lt;item&gt;en_us: 154 URLs&lt;/item&gt;
      &lt;item&gt;pl: 131 URLs&lt;/item&gt;
      &lt;item&gt;sv: 129 URLs&lt;/item&gt;
      &lt;item&gt;he: 93 URLs&lt;/item&gt;
      &lt;item&gt;gl: 62 URLs&lt;/item&gt;
      &lt;item&gt;ko: 56 URLs&lt;/item&gt;
      &lt;item&gt;fr,it: 47 URLs&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Most common language tags&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Unspecified: 383,613 URLs&lt;/item&gt;
      &lt;item&gt;en: 58,319 URLs&lt;/item&gt;
      &lt;item&gt;en-gb: 42,784 URLs&lt;/item&gt;
      &lt;item&gt;de: 20,526 URLs&lt;/item&gt;
      &lt;item&gt;en-us: 19,274 URLs&lt;/item&gt;
      &lt;item&gt;fr: 11,147 URLs&lt;/item&gt;
      &lt;item&gt;it: 7,635 URLs&lt;/item&gt;
      &lt;item&gt;es: 7,072 URLs&lt;/item&gt;
      &lt;item&gt;es-es: 2,069 URLs&lt;/item&gt;
      &lt;item&gt;fr-fr: 1,877 URLs&lt;/item&gt;
      &lt;item&gt;es_ar: 1,273 URLs&lt;/item&gt;
      &lt;item&gt;fa: 572 URLs&lt;/item&gt;
      &lt;item&gt;ja: 560 URLs&lt;/item&gt;
      &lt;item&gt;en-ie: 478 URLs&lt;/item&gt;
      &lt;item&gt;grc: 420 URLs&lt;/item&gt;
      &lt;item&gt;en-ca: 409 URLs&lt;/item&gt;
      &lt;item&gt;ru-ru: 356 URLs&lt;/item&gt;
      &lt;item&gt;ru: 328 URLs&lt;/item&gt;
      &lt;item&gt;en_au: 252 URLs&lt;/item&gt;
      &lt;item&gt;arb: 202 URLs&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Most common encodings ("charsets") for all files&lt;/head&gt;
    &lt;p&gt;(Remember there exists testing capsules, with very exotic encodings, so don't be surprised by some strange ones.)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Unspecified: 488,732 URLs&lt;/item&gt;
      &lt;item&gt;utf-8: 71,650 URLs&lt;/item&gt;
      &lt;item&gt;binary: 161 URLs&lt;/item&gt;
      &lt;item&gt;us-ascii: 75 URLs&lt;/item&gt;
      &lt;item&gt;gzip: 21 URLs&lt;/item&gt;
      &lt;item&gt;iso-8859-1: 6 URLs&lt;/item&gt;
      &lt;item&gt;xz: 1 URLs&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Most common encodings for gemtext files only&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Unspecified: 370,176 URLs&lt;/item&gt;
      &lt;item&gt;utf-8: 61,157 URLs&lt;/item&gt;
      &lt;item&gt;iso-8859-1: 6 URLs&lt;/item&gt;
      &lt;item&gt;us-ascii: 1 URLs&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By the way, 457 of recently tested URLs (0.075 %) have a wrong encoding (it does not match the actual content).&lt;/p&gt;
    &lt;head rend="h3"&gt;Status codes&lt;/head&gt;
    &lt;p&gt;(Remember there are test capsules with funny status codes, to exercice Gemini clients.)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;20 (Success): 560,646 occurrences (94.98 %)&lt;/item&gt;
      &lt;item&gt;51 (Not found): 17,919 occurrences (3.04 %)&lt;/item&gt;
      &lt;item&gt;10 (Input request): 3,356 occurrences (0.57 %)&lt;/item&gt;
      &lt;item&gt;30 (Temporary redirect): 3,146 occurrences (0.53 %)&lt;/item&gt;
      &lt;item&gt;60 (Client certificate request): 2,894 occurrences (0.49 %)&lt;/item&gt;
      &lt;item&gt;40 (Temporary failure): 772 occurrences (0.13 %)&lt;/item&gt;
      &lt;item&gt;53 (Proxy request refused): 547 occurrences (0.09 %)&lt;/item&gt;
      &lt;item&gt;42 (CGI error): 266 occurrences (0.05 %)&lt;/item&gt;
      &lt;item&gt;50 (Permanent failure): 239 occurrences (0.04 %)&lt;/item&gt;
      &lt;item&gt;31 (Permanent redirect): 171 occurrences (0.03 %)&lt;/item&gt;
      &lt;item&gt;52 (Gone with the wind): 138 occurrences (0.02 %)&lt;/item&gt;
      &lt;item&gt;59 (Bad request): 88 occurrences (0.01 %)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Links&lt;/head&gt;
    &lt;p&gt;(We count only backlinks from external capsules, and at most one link per capsule. Also, we exclude links from capsules like search engines or directories.)&lt;/p&gt;
    &lt;p&gt;Maximum number of incoming links: 381&lt;/p&gt;
    &lt;p&gt;Average number of incoming links: 0.28&lt;/p&gt;
    &lt;head rend="h2"&gt;Capsules&lt;/head&gt;
    &lt;p&gt;There are 4825 capsules. We successfully connected recently to 3251 of them.&lt;/p&gt;
    &lt;head rend="h3"&gt;Most common capsules by number of working URLs&lt;/head&gt;
    &lt;p&gt;We have a limit of 10000 URLs per capsule.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;gemini.kpopify.me: 10000 URLs&lt;/item&gt;
      &lt;item&gt;x5dragonfire.flounder.online: 10000 URLs&lt;/item&gt;
      &lt;item&gt;blitter.com: 10000 URLs&lt;/item&gt;
      &lt;item&gt;dvd.flounder.online: 10000 URLs&lt;/item&gt;
      &lt;item&gt;gemini.conman.org: 10000 URLs&lt;/item&gt;
      &lt;item&gt;gemini.oxydable.fr: 10000 URLs&lt;/item&gt;
      &lt;item&gt;gemini.techrights.org: 10000 URLs&lt;/item&gt;
      &lt;item&gt;gemini.tuxmachines.org: 9999 URLs&lt;/item&gt;
      &lt;item&gt;federal.cx: 9998 URLs&lt;/item&gt;
      &lt;item&gt;fumble-around.mediocregopher.com: 9994 URLs&lt;/item&gt;
      &lt;item&gt;musicbrainz.uploadedlobster.com: 9994 URLs&lt;/item&gt;
      &lt;item&gt;gmi.noulin.net: 9990 URLs&lt;/item&gt;
      &lt;item&gt;gemini.omarpolo.com: 9990 URLs&lt;/item&gt;
      &lt;item&gt;caiofior.pollux.casa: 9990 URLs&lt;/item&gt;
      &lt;item&gt;station.martinrue.com: 9970 URLs&lt;/item&gt;
      &lt;item&gt;taz.de: 9967 URLs&lt;/item&gt;
      &lt;item&gt;techrights.org: 9965 URLs&lt;/item&gt;
      &lt;item&gt;library.inu.red: 9952 URLs&lt;/item&gt;
      &lt;item&gt;bbs.geminispace.org: 9932 URLs&lt;/item&gt;
      &lt;item&gt;gemlog.stargrave.org: 9914 URLs&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Most common capsules by number of bytes in working URLs&lt;/head&gt;
    &lt;p&gt;We have a limit of bytes per URL.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;mirrors.apple2.org.za: 2453.8 megabytes&lt;/item&gt;
      &lt;item&gt;nytpu.com: 2079.5 megabytes&lt;/item&gt;
      &lt;item&gt;higeki.jp: 1503.7 megabytes&lt;/item&gt;
      &lt;item&gt;gem.librehacker.com: 1040.6 megabytes&lt;/item&gt;
      &lt;item&gt;librehacker.com: 954.6 megabytes&lt;/item&gt;
      &lt;item&gt;uscoffings.net: 927.2 megabytes&lt;/item&gt;
      &lt;item&gt;gael.mooo.com: 754.6 megabytes&lt;/item&gt;
      &lt;item&gt;blitter.com: 687.1 megabytes&lt;/item&gt;
      &lt;item&gt;dfdn.info: 596.0 megabytes&lt;/item&gt;
      &lt;item&gt;going-flying.com: 448.6 megabytes&lt;/item&gt;
      &lt;item&gt;gemini.tcrouzet.com: 415.5 megabytes&lt;/item&gt;
      &lt;item&gt;tweek.zyxxyz.eu: 379.0 megabytes&lt;/item&gt;
      &lt;item&gt;norayr.am: 377.8 megabytes&lt;/item&gt;
      &lt;item&gt;villastraylight.online: 371.6 megabytes&lt;/item&gt;
      &lt;item&gt;techrights.org: 339.9 megabytes&lt;/item&gt;
      &lt;item&gt;ecs.d2evs.net: 320.9 megabytes&lt;/item&gt;
      &lt;item&gt;gemini.kpopify.me: 310.6 megabytes&lt;/item&gt;
      &lt;item&gt;library.inu.red: 281.2 megabytes&lt;/item&gt;
      &lt;item&gt;8by3.net: 260.2 megabytes&lt;/item&gt;
      &lt;item&gt;gemi.dev: 250.5 megabytes&lt;/item&gt;
      &lt;item&gt;gem.ortie.org: 228.9 megabytes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All working capsules:&lt;/p&gt;
    &lt;head rend="h3"&gt;Certificates&lt;/head&gt;
    &lt;p&gt;3006 (92.5 %) capsules are self-signed, 5 (0.2 %) use the Certificate Authority Let's Encrypt, 240 (7.4 %) are signed by another CA (may be not a trusted one).&lt;/p&gt;
    &lt;p&gt;93 capsules (2.87 %) have an expired certificate.&lt;/p&gt;
    &lt;p&gt;Algorithms:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ecdsa-with-SHA256: 2046 capsules&lt;/item&gt;
      &lt;item&gt;sha256WithRSAEncryption: 1096 capsules&lt;/item&gt;
      &lt;item&gt;ecdsa-with-SHA384: 79 capsules&lt;/item&gt;
      &lt;item&gt;ED25519: 25 capsules&lt;/item&gt;
      &lt;item&gt;ecdsa-with-SHA512: 3 capsules&lt;/item&gt;
      &lt;item&gt;sha512WithRSAEncryption: 2 capsules&lt;/item&gt;
      &lt;item&gt;sha384WithRSAEncryption: 1 capsules&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Key types:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ECDSA: 2128 capsules&lt;/item&gt;
      &lt;item&gt;RSA: 1099 capsules&lt;/item&gt;
      &lt;item&gt;ED25519: 25 capsules&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Key sizes for RSA:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2048: 815 capsules&lt;/item&gt;
      &lt;item&gt;4096: 279 capsules&lt;/item&gt;
      &lt;item&gt;3072: 3 capsules&lt;/item&gt;
      &lt;item&gt;1024: 2 capsules&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Key sizes for ECDSA:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;256: 2068 capsules&lt;/item&gt;
      &lt;item&gt;384: 59 capsules&lt;/item&gt;
      &lt;item&gt;521: 1 capsules&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;TLS&lt;/head&gt;
    &lt;p&gt;99 % of the capsules use TLS 1.3, 1 % use TLS 1.2.&lt;/p&gt;
    &lt;head rend="h3"&gt;robots.txt&lt;/head&gt;
    &lt;p&gt;317 (10 %) the capsules have a robots.txt exclusion file.&lt;/p&gt;
    &lt;head rend="h3"&gt;Ports&lt;/head&gt;
    &lt;p&gt;23 working capsules (0.7 %) use an alternative port&lt;/p&gt;
    &lt;head rend="h3"&gt;Addresses&lt;/head&gt;
    &lt;p&gt;1263 IP addresses used. 27 % are IPv6.&lt;/p&gt;
    &lt;head rend="h3"&gt;# Addresses with most virtual hosts&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;173.230.145.243: 1079 vhosts&lt;/item&gt;
      &lt;item&gt;72.65.51.74: 549 vhosts&lt;/item&gt;
      &lt;item&gt;213.219.38.200: 328 vhosts&lt;/item&gt;
      &lt;item&gt;46.23.81.157: 143 vhosts&lt;/item&gt;
      &lt;item&gt;2a03:6000:1813:1337::157: 123 vhosts&lt;/item&gt;
      &lt;item&gt;86.194.163.71: 46 vhosts&lt;/item&gt;
      &lt;item&gt;109.237.26.252: 34 vhosts&lt;/item&gt;
      &lt;item&gt;45.56.93.217: 21 vhosts&lt;/item&gt;
      &lt;item&gt;172.236.4.52: 18 vhosts&lt;/item&gt;
      &lt;item&gt;128.140.115.191: 16 vhosts&lt;/item&gt;
      &lt;item&gt;143.244.176.58: 10 vhosts&lt;/item&gt;
      &lt;item&gt;2604:a880:4:1d0::4e1:3000: 10 vhosts&lt;/item&gt;
      &lt;item&gt;2a01:4f8:c17:20f1::42: 9 vhosts&lt;/item&gt;
      &lt;item&gt;23.88.35.144: 9 vhosts&lt;/item&gt;
      &lt;item&gt;46.23.94.99: 9 vhosts&lt;/item&gt;
      &lt;item&gt;129.151.254.123: 9 vhosts&lt;/item&gt;
      &lt;item&gt;143.244.212.63: 8 vhosts&lt;/item&gt;
      &lt;item&gt;2001:8b0:1d97:eeca:3da5:94ce:b61e:ee69: 8 vhosts&lt;/item&gt;
      &lt;item&gt;81.187.234.86: 8 vhosts&lt;/item&gt;
      &lt;item&gt;2a03:6000:6f67:624::99: 8 vhosts&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;TLDs&lt;/head&gt;
    &lt;p&gt;There are 277 TLDs in the capsule's names, and 2248 registered domains.&lt;/p&gt;
    &lt;head rend="h3"&gt;Most common TLDs&lt;/head&gt;
    &lt;head rend="h3"&gt;# By number of registered domains&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;com: 361 domains&lt;/item&gt;
      &lt;item&gt;net: 212 domains&lt;/item&gt;
      &lt;item&gt;org: 179 domains&lt;/item&gt;
      &lt;item&gt;xyz: 154 domains&lt;/item&gt;
      &lt;item&gt;space: 99 domains&lt;/item&gt;
      &lt;item&gt;site: 75 domains&lt;/item&gt;
      &lt;item&gt;de: 64 domains&lt;/item&gt;
      &lt;item&gt;dev: 63 domains&lt;/item&gt;
      &lt;item&gt;me: 56 domains&lt;/item&gt;
      &lt;item&gt;eu: 41 domains&lt;/item&gt;
      &lt;item&gt;uk: 37 domains&lt;/item&gt;
      &lt;item&gt;fr: 37 domains&lt;/item&gt;
      &lt;item&gt;info: 30 domains&lt;/item&gt;
      &lt;item&gt;io: 28 domains&lt;/item&gt;
      &lt;item&gt;club: 24 domains&lt;/item&gt;
      &lt;item&gt;onion: 20 domains&lt;/item&gt;
      &lt;item&gt;ru: 19 domains&lt;/item&gt;
      &lt;item&gt;online: 18 domains&lt;/item&gt;
      &lt;item&gt;ca: 18 domains&lt;/item&gt;
      &lt;item&gt;se: 18 domains&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;# By number of capsules&lt;/head&gt;
    &lt;p&gt;(There's a strong bias towards TLDs which have hosting services such as flounder.online, which has many capsules in subdomains. See before the TLDs per registered domains, which are probably more useful.)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;online: 1093 capsules&lt;/item&gt;
      &lt;item&gt;org: 788 capsules&lt;/item&gt;
      &lt;item&gt;com: 452 capsules&lt;/item&gt;
      &lt;item&gt;pub: 344 capsules&lt;/item&gt;
      &lt;item&gt;net: 255 capsules&lt;/item&gt;
      &lt;item&gt;xyz: 178 capsules&lt;/item&gt;
      &lt;item&gt;space: 123 capsules&lt;/item&gt;
      &lt;item&gt;site: 78 capsules&lt;/item&gt;
      &lt;item&gt;de: 73 capsules&lt;/item&gt;
      &lt;item&gt;dev: 72 capsules&lt;/item&gt;
      &lt;item&gt;me: 58 capsules&lt;/item&gt;
      &lt;item&gt;eu: 58 capsules&lt;/item&gt;
      &lt;item&gt;cc: 57 capsules&lt;/item&gt;
      &lt;item&gt;casa: 54 capsules&lt;/item&gt;
      &lt;item&gt;club: 53 capsules&lt;/item&gt;
      &lt;item&gt;fr: 41 capsules&lt;/item&gt;
      &lt;item&gt;uk: 41 capsules&lt;/item&gt;
      &lt;item&gt;info: 37 capsules&lt;/item&gt;
      &lt;item&gt;io: 33 capsules&lt;/item&gt;
      &lt;item&gt;town: 27 capsules&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Other statistics on the geminispace&lt;/head&gt;
    &lt;p&gt;At the search engine geminispace.info&lt;/p&gt;
    &lt;p&gt;By Nervuri (specially for certificates)&lt;/p&gt;
    &lt;head rend="h2"&gt;Contact&lt;/head&gt;
    &lt;p&gt;Maintained by St√©phane Bortzmeyer (email &amp;lt;stephane+gemini@bortzmeyer.org&amp;gt;). Comments and criticisms are welcome.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46512707</guid><pubDate>Tue, 06 Jan 2026 14:30:53 +0000</pubDate></item><item><title>High-performance header-only container library for C++23 on x86-64</title><link>https://github.com/kressler/fast-containers</link><description>&lt;doc fingerprint="6f8fe048c40538a9"&gt;
  &lt;main&gt;
    &lt;p&gt;High-performance header-only container library for C++23 on x86-64.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;B+Tree (&lt;code&gt;kressler::fast_containers::btree&lt;/code&gt;) - Cache-friendly B+tree with SIMD search and hugepage support&lt;/item&gt;
      &lt;item&gt;Dense Map (&lt;code&gt;kressler::fast_containers::dense_map&lt;/code&gt;) - Fixed-size sorted array used internally by btree nodes&lt;/item&gt;
      &lt;item&gt;Hugepage Allocators - Pooling allocators that reduce TLB misses and allocation overhead &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;HugePageAllocator&lt;/code&gt;- Single-size allocator for uniform allocations&lt;/item&gt;&lt;item&gt;&lt;code&gt;MultiSizeHugePageAllocator&lt;/code&gt;- Multi-size pooling for variable-sized allocations (e.g., Abseil btree)&lt;/item&gt;&lt;item&gt;&lt;code&gt;PolicyBasedHugePageAllocator&lt;/code&gt;- Advanced control with shared pools&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The B+tree implementation provides significant performance improvements over industry standards for large trees. For some workloads with large trees, we've observed:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;vs Abseil B+tree: 2-5√ó faster across insert/find/erase operations&lt;/item&gt;
      &lt;item&gt;vs std::map: 2-5√ó faster across insert/find/erase operations&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See benchmark results for detailed performance analysis.&lt;/p&gt;
    &lt;p&gt;Important qualifications:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Performance advantages are most significant for large tree sizes where TLB misses and allocation costs dominate&lt;/item&gt;
      &lt;item&gt;Benchmarks currently focus on 10M element trees; smaller tree sizes have not been comprehensively tested&lt;/item&gt;
      &lt;item&gt;Results are specific to the tested configurations (8-byte keys, 32-byte and 256-byte values)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Key advantages over Abseil's btree:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Hugepage allocator integration: 3-5√ó speedup from reduced TLB misses and pooled allocations&lt;/item&gt;
      &lt;item&gt;SIMD-accelerated search: 3-10% faster node searches using AVX2 instructions&lt;/item&gt;
      &lt;item&gt;Tunable node sizes: Optimize cache behavior for your specific key/value sizes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Work in progress This is a work in progress. I don't have plans for major changes to the B+tree currently, but am actively cleaning up the implementation.&lt;/p&gt;
    &lt;p&gt;Platforms This library is really only built and tested on Linux, on x86-64 CPUs with AVX2 support. In theory, it could be built for Windows, though that hasn't been tested. The SIMD implementations are x86-64 specific. Timing in the custom benchmarks is also x86-64 specific (via use of &lt;code&gt;rdtscp&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;History/Motivations This project started as an exploration of using AI agents for software development. Based on experience tuning systems using Abseil's B+tree, I was curious if performance could be improved through SIMD instructions, a customized allocator, and tunable node sizes. Claude proved surprisingly adept at helping implement this quickly, and the resulting B+tree showed compelling performance improvements, so I'm making it available here.&lt;/p&gt;
    &lt;p&gt;Prerequisites:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;C++23 compiler (GCC 14+, Clang 19+)&lt;/item&gt;
      &lt;item&gt;CMake 3.30+&lt;/item&gt;
      &lt;item&gt;AVX2-capable CPU (Intel Haswell 2013+, AMD Excavator 2015+)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Include in your project:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Add as a git submodule:&lt;/p&gt;
        &lt;quote&gt;git submodule add https://github.com/kressler/fast-containers.git third_party/fast-containers&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Link in CMakeLists.txt:&lt;/p&gt;
        &lt;quote&gt;add_subdirectory(third_party/fast-containers) target_link_libraries(your_target PRIVATE fast_containers::fast_containers)&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Include headers:&lt;/p&gt;
        &lt;quote&gt;#include &amp;lt;fast_containers/btree.hpp&amp;gt; #include &amp;lt;fast_containers/hugepage_allocator.hpp&amp;gt;&lt;/quote&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;#include &amp;lt;fast_containers/btree.hpp&amp;gt;
#include &amp;lt;cstdint&amp;gt;
#include &amp;lt;iostream&amp;gt;

int main() {
  // Create a btree mapping int64_t keys to int32_t values
  // Using defaults: auto-computed node sizes, Linear search
  using Tree = kressler::fast_containers::btree&amp;lt;int64_t, int32_t&amp;gt;;

  Tree tree;

  // Insert key-value pairs
  tree.insert(42, 100);
  tree.insert(17, 200);
  tree.insert(99, 300);

  // Find a value
  auto it = tree.find(42);
  if (it != tree.end()) {
    std::cout &amp;lt;&amp;lt; "Found: " &amp;lt;&amp;lt; it-&amp;gt;second &amp;lt;&amp;lt; std::endl;  // Prints: 100
  }

  // Iterate over all elements (sorted by key)
  for (const auto&amp;amp; [key, value] : tree) {
    std::cout &amp;lt;&amp;lt; key &amp;lt;&amp;lt; " -&amp;gt; " &amp;lt;&amp;lt; value &amp;lt;&amp;lt; std::endl;
  }

  // Erase an element
  tree.erase(17);

  // Check size
  std::cout &amp;lt;&amp;lt; "Size: " &amp;lt;&amp;lt; tree.size() &amp;lt;&amp;lt; std::endl;  // Prints: 2
}&lt;/code&gt;
    &lt;code&gt;#include &amp;lt;fast_containers/btree.hpp&amp;gt;
#include &amp;lt;fast_containers/hugepage_allocator.hpp&amp;gt;
#include &amp;lt;cstdint&amp;gt;
#include &amp;lt;cassert&amp;gt;

int main() {
  // Use the hugepage allocator for 3-5√ó performance improvement
  // Allocator type must match the btree's value_type (std::pair&amp;lt;Key, Value&amp;gt;)
  using Allocator = kressler::fast_containers::HugePageAllocator&amp;lt;
      std::pair&amp;lt;int64_t, int32_t&amp;gt;&amp;gt;;

  using Tree = kressler::fast_containers::btree&amp;lt;
    int64_t,                                 // Key type
    int32_t,                                 // Value type
    96,                                      // Leaf node size
    128,                                     // Internal node size
    std::less&amp;lt;int64_t&amp;gt;,                      // Comparator
    kressler::fast_containers::SearchMode::SIMD,  // SIMD search
    Allocator                                // Hugepage allocator
  &amp;gt;;

  // Tree will default-construct the allocator (256MB initial pool, 64MB growth)
  // The btree automatically creates separate pools for leaf and internal nodes
  Tree tree;

  // Insert 10 million elements - hugepages reduce TLB misses
  for (int64_t i = 0; i &amp;lt; 10'000'000; ++i) {
    tree.insert(i, i * 2);
  }

  // Find operations are much faster with hugepages
  auto it = tree.find(5'000'000);
  assert(it != tree.end() &amp;amp;&amp;amp; it-&amp;gt;second == 10'000'000);
}&lt;/code&gt;
    &lt;p&gt;For multiple trees or fine-grained control over pool sizes, use &lt;code&gt;PolicyBasedHugePageAllocator&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;#include &amp;lt;fast_containers/btree.hpp&amp;gt;
#include &amp;lt;fast_containers/policy_based_hugepage_allocator.hpp&amp;gt;
#include &amp;lt;cstdint&amp;gt;

int main() {
  // Create separate pools for leaf and internal nodes with custom sizes
  auto leaf_pool = std::make_shared&amp;lt;kressler::fast_containers::HugePagePool&amp;gt;(
      512 * 1024 * 1024, true);  // 512MB for leaves
  auto internal_pool = std::make_shared&amp;lt;kressler::fast_containers::HugePagePool&amp;gt;(
      256 * 1024 * 1024, true);  // 256MB for internals

  // Create policy that routes types to appropriate pools
  kressler::fast_containers::TwoPoolPolicy policy{leaf_pool, internal_pool};

  // Create allocator with the policy
  using Allocator = kressler::fast_containers::PolicyBasedHugePageAllocator&amp;lt;
      std::pair&amp;lt;int64_t, int32_t&amp;gt;,
      kressler::fast_containers::TwoPoolPolicy&amp;gt;;

  Allocator alloc(policy);

  using Tree = kressler::fast_containers::btree&amp;lt;
    int64_t, int32_t, 96, 128, std::less&amp;lt;int64_t&amp;gt;,
    kressler::fast_containers::SearchMode::SIMD, Allocator&amp;gt;;

  // Multiple trees can share the same pools
  Tree tree1(alloc);
  Tree tree2(alloc);

  // Both trees share leaf_pool for leaves and internal_pool for internals
  tree1.insert(1, 100);
  tree2.insert(2, 200);
}&lt;/code&gt;
    &lt;p&gt;For containers that allocate variable-sized objects (like &lt;code&gt;absl::btree_map&lt;/code&gt;), use &lt;code&gt;MultiSizeHugePageAllocator&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;#include &amp;lt;fast_containers/multi_size_hugepage_allocator.hpp&amp;gt;
#include &amp;lt;absl/container/btree_map.h&amp;gt;
#include &amp;lt;array&amp;gt;
#include &amp;lt;cstdint&amp;gt;

int main() {
  // absl::btree_map allocates different-sized nodes (leaf vs internal)
  // MultiSizeHugePageAllocator routes allocations to size-class-specific pools

  using ValueType = std::array&amp;lt;std::byte, 32&amp;gt;;
  using Allocator = kressler::fast_containers::MultiSizeHugePageAllocator&amp;lt;
      std::pair&amp;lt;const int64_t, ValueType&amp;gt;&amp;gt;;

  // Helper function creates allocator with default settings
  // - 64MB initial size per size class
  // - Hugepages enabled
  // - 64MB growth size per size class
  auto alloc = kressler::fast_containers::make_multi_size_hugepage_allocator&amp;lt;
      std::pair&amp;lt;const int64_t, ValueType&amp;gt;&amp;gt;();

  // Create absl::btree_map with hugepage allocator
  absl::btree_map&amp;lt;int64_t, ValueType, std::less&amp;lt;int64_t&amp;gt;, Allocator&amp;gt; tree(alloc);

  // Insert 1 million elements - multiple size classes created automatically
  for (int64_t i = 0; i &amp;lt; 1'000'000; ++i) {
    tree[i] = ValueType{};
  }

  // Find operations benefit from reduced TLB misses
  auto it = tree.find(500'000);
}&lt;/code&gt;
    &lt;p&gt;How it works:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Allocations are routed to size classes based on requested size&lt;/item&gt;
      &lt;item&gt;Size classes: 0-512B (64B alignment), 513-2048B (256B alignment), 2049+B (power-of-2)&lt;/item&gt;
      &lt;item&gt;Each size class maintains its own &lt;code&gt;HugePagePool&lt;/code&gt;with uniform-sized blocks&lt;/item&gt;
      &lt;item&gt;Pools created on-demand as different sizes are requested&lt;/item&gt;
      &lt;item&gt;Provides 2-3√ó performance improvement for &lt;code&gt;absl::btree_map&lt;/code&gt;over standard allocator&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When to use each allocator:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;HugePageAllocator&lt;/code&gt;: Simple, automatic separate pools per type (recommended for our btree)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;MultiSizeHugePageAllocator&lt;/code&gt;: Variable-sized allocations (e.g.,&lt;code&gt;absl::btree_map&lt;/code&gt;, other STL containers with allocator support)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;PolicyBasedHugePageAllocator&lt;/code&gt;: Fine-grained control, shared pools across trees, custom pool sizes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The &lt;code&gt;btree&lt;/code&gt; class provides an API similar to &lt;code&gt;std::map&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;Insertion:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;std::pair&amp;lt;iterator, bool&amp;gt; insert(const Key&amp;amp; key, const Value&amp;amp; value)&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;std::pair&amp;lt;iterator, bool&amp;gt; emplace(Args&amp;amp;&amp;amp;... args)&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;Value&amp;amp; operator[](const Key&amp;amp; key)&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Lookup:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;iterator find(const Key&amp;amp; key)&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;const_iterator find(const Key&amp;amp; key) const&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;iterator lower_bound(const Key&amp;amp; key)&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;iterator upper_bound(const Key&amp;amp; key)&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;std::pair&amp;lt;iterator, iterator&amp;gt; equal_range(const Key&amp;amp; key)&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Removal:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;size_type erase(const Key&amp;amp; key)&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;iterator erase(iterator pos)&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Iteration:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;iterator begin()&lt;/code&gt;/&lt;code&gt;const_iterator begin() const&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;iterator end()&lt;/code&gt;/&lt;code&gt;const_iterator end() const&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Range-based for loops supported&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Capacity:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;size_type size() const&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;bool empty() const&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;void clear()&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Other:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;void swap(btree&amp;amp; other) noexcept&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;key_compare key_comp() const&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;value_compare value_comp() const&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;template &amp;lt;
  typename Key,
  typename Value,
  std::size_t LeafNodeSize = default_leaf_node_size&amp;lt;Key, Value&amp;gt;(),
  std::size_t InternalNodeSize = default_internal_node_size&amp;lt;Key&amp;gt;(),
  typename Compare = std::less&amp;lt;Key&amp;gt;,
  SearchMode SearchModeT = SearchMode::Linear,
  typename Allocator = std::allocator&amp;lt;std::pair&amp;lt;Key, Value&amp;gt;&amp;gt;
&amp;gt;
class btree;&lt;/code&gt;
    &lt;p&gt;Parameters:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;Key&lt;/code&gt;,&lt;code&gt;Value&lt;/code&gt;: The key and value types&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;LeafNodeSize&lt;/code&gt;: Number of key-value pairs per leaf node&lt;list rend="ul"&gt;&lt;item&gt;Default: Auto-computed heuristic targeting ~2KB (32 cache lines)&lt;/item&gt;&lt;item&gt;Formula: &lt;code&gt;2048 / (sizeof(Key) + sizeof(Value))&lt;/code&gt;, rounded to multiple of 8, clamped to [8, 64]&lt;/item&gt;&lt;item&gt;Manual tuning: Larger values (64-96) for small values, smaller values (8-16) for large values&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;InternalNodeSize&lt;/code&gt;: Number of child pointers per internal node&lt;list rend="ul"&gt;&lt;item&gt;Default: Auto-computed heuristic targeting ~1KB (16 cache lines)&lt;/item&gt;&lt;item&gt;Formula: &lt;code&gt;1024 / (sizeof(Key) + sizeof(void*))&lt;/code&gt;, rounded to multiple of 8, clamped to [16, 64]&lt;/item&gt;&lt;item&gt;Generally leave at default (stores only 8-byte pointers)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Compare&lt;/code&gt;: Comparison function (must satisfy&lt;code&gt;ComparatorCompatible&amp;lt;Key, Compare&amp;gt;&lt;/code&gt;)&lt;list rend="ul"&gt;&lt;item&gt;Default: &lt;code&gt;std::less&amp;lt;Key&amp;gt;&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Also supports &lt;code&gt;std::greater&amp;lt;Key&amp;gt;&lt;/code&gt;for descending order&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Default: &lt;/item&gt;
      &lt;item&gt;&lt;code&gt;SearchMode&lt;/code&gt;: How to search within a node&lt;list rend="ul"&gt;&lt;item&gt;Default: &lt;code&gt;SearchMode::Linear&lt;/code&gt;(scalar linear search)&lt;/item&gt;&lt;item&gt;&lt;code&gt;SearchMode::SIMD&lt;/code&gt;: AVX2-accelerated search (3-10% faster, requires AVX2 CPU and SIMD-compatible keys: int32_t, uint32_t, int64_t, uint64_t, float, double)&lt;/item&gt;&lt;item&gt;&lt;code&gt;SearchMode::Binary&lt;/code&gt;: Binary search&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Default: &lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Allocator&lt;/code&gt;: Memory allocation strategy&lt;list rend="ul"&gt;&lt;item&gt;Default: &lt;code&gt;std::allocator&amp;lt;std::pair&amp;lt;Key, Value&amp;gt;&amp;gt;&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Recommended for performance: &lt;code&gt;HugePageAllocator&amp;lt;std::pair&amp;lt;Key, Value&amp;gt;&amp;gt;&lt;/code&gt;for working sets &amp;gt;1GB (3-5√ó faster)&lt;list rend="ul"&gt;&lt;item&gt;Automatically creates separate pools for leaf and internal nodes via rebind&lt;/item&gt;&lt;item&gt;Default: 256MB initial pool, 64MB growth per pool&lt;/item&gt;&lt;item&gt;Requires hugepages configured: &lt;code&gt;sudo sysctl -w vm.nr_hugepages=&amp;lt;num_pages&amp;gt;&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Falls back to regular pages if unavailable&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;For variable-sized allocations: &lt;code&gt;MultiSizeHugePageAllocator&amp;lt;std::pair&amp;lt;Key, Value&amp;gt;&amp;gt;&lt;/code&gt;&lt;list rend="ul"&gt;&lt;item&gt;Routes allocations to size-class-specific pools&lt;/item&gt;&lt;item&gt;Use with &lt;code&gt;absl::btree_map&lt;/code&gt;or other containers that allocate different-sized objects&lt;/item&gt;&lt;item&gt;Provides 2-3√ó speedup for Abseil btree over standard allocator&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Advanced control: &lt;code&gt;PolicyBasedHugePageAllocator&amp;lt;std::pair&amp;lt;Key, Value&amp;gt;, TwoPoolPolicy&amp;gt;&lt;/code&gt;&lt;list rend="ul"&gt;&lt;item&gt;Fine-grained control over pool sizes&lt;/item&gt;&lt;item&gt;Share pools across multiple trees&lt;/item&gt;&lt;item&gt;Separate pools for leaf and internal nodes with custom sizes&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Default: &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Benchmarks comparing against Abseil's &lt;code&gt;btree_map&lt;/code&gt; and &lt;code&gt;std::map&lt;/code&gt; are available in results/btree_benchmark_results.md.&lt;/p&gt;
    &lt;p&gt;Our btree with hugepages (&lt;code&gt;btree_8_32_96_128_simd_hp&lt;/code&gt;):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;INSERT P99.9: 1,023 ns&lt;/item&gt;
      &lt;item&gt;FIND P99.9: 864 ns&lt;/item&gt;
      &lt;item&gt;ERASE P99.9: 1,086 ns&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Our btree with standard allocator (&lt;code&gt;btree_8_32_96_128_simd&lt;/code&gt;):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;INSERT P99.9: 3,155 ns (3.1√ó slower than with hugepages)&lt;/item&gt;
      &lt;item&gt;FIND P99.9: 950 ns (1.1√ó slower than with hugepages)&lt;/item&gt;
      &lt;item&gt;ERASE P99.9: 1,323 ns (1.2√ó slower than with hugepages)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;vs. Abseil btree with hugepages (&lt;code&gt;absl_8_32_hp&lt;/code&gt; using &lt;code&gt;MultiSizeHugePageAllocator&lt;/code&gt;):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;INSERT P99.9: 1,401 ns (27% slower)&lt;/item&gt;
      &lt;item&gt;FIND P99.9: 1,190 ns (38% slower)&lt;/item&gt;
      &lt;item&gt;ERASE P99.9: 1,299 ns (20% slower)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;vs. Abseil btree with standard allocator (&lt;code&gt;absl_8_32&lt;/code&gt;):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;INSERT P99.9: 3,287 ns (3.2√ó slower)&lt;/item&gt;
      &lt;item&gt;FIND P99.9: 1,342 ns (55% slower)&lt;/item&gt;
      &lt;item&gt;ERASE P99.9: 1,679 ns (55% slower)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;vs. std::map (&lt;code&gt;map_8_32&lt;/code&gt;):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;INSERT P99.9: 3,587 ns (3.5√ó slower)&lt;/item&gt;
      &lt;item&gt;FIND P99.9: 2,312 ns (2.7√ó slower)&lt;/item&gt;
      &lt;item&gt;ERASE P99.9: 2,253 ns (2.1√ó slower)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Hugepage allocators provide massive performance improvements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Our btree: 2-3√ó faster with hugepages vs. standard allocator&lt;/item&gt;
      &lt;item&gt;Abseil btree: 2√ó faster with &lt;code&gt;MultiSizeHugePageAllocator&lt;/code&gt;vs. standard allocator&lt;/item&gt;
      &lt;item&gt;Critical for large working sets (&amp;gt;1M elements)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Our implementation maintains significant advantages even with fair comparison:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;20-67% faster than Abseil btree even when both use hugepage allocators&lt;/item&gt;
      &lt;item&gt;Advantages from SIMD search, tunable node sizes, and optimized bulk transfers&lt;/item&gt;
      &lt;item&gt;Performance gap widens with larger values (256 bytes: 21-135% faster)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Performance varies by tree size:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Large trees (10M elements): Our btree dominates all metrics&lt;/item&gt;
      &lt;item&gt;Small trees (10K elements): Competition intensifies, std::map becomes viable for some workloads&lt;/item&gt;
      &lt;item&gt;See benchmark results for detailed analysis&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The hugepage allocator is the single most important optimization, providing benefits by reducing TLB misses (helps find operations) and making allocations extremely cheap through pooling (helps insert/erase operations).&lt;/p&gt;
    &lt;code&gt;# List available presets
cmake --list-presets

# Configure, build, and test in one workflow
cmake --preset release
cmake --build --preset release
ctest --preset release

# Common presets:
cmake --preset debug          # Debug build
cmake --preset release        # Release with AVX2 (default)
cmake --preset asan           # AddressSanitizer build
cmake --preset release-no-avx2  # Release without AVX2&lt;/code&gt;
    &lt;code&gt;# Clone with submodules
git clone --recursive https://github.com/kressler/fast-containers.git
cd fast-containers

# Configure
cmake -S . -B build -DCMAKE_BUILD_TYPE=Release

# Build
cmake --build build

# Run tests
ctest --test-dir build --output-on-failure&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Option&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;ENABLE_AVX2&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;ON&lt;/code&gt; (Release), &lt;code&gt;OFF&lt;/code&gt; (Debug)&lt;/cell&gt;
        &lt;cell&gt;Enable AVX2 SIMD optimizations&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;ENABLE_ASAN&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;OFF&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Enable AddressSanitizer&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;ENABLE_ALLOCATOR_STATS&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;OFF&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Enable allocator statistics&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;ENABLE_LTO&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;ON&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Enable Link-Time Optimization&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;ENABLE_NUMA&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Auto-detected&lt;/cell&gt;
        &lt;cell&gt;Enable NUMA support (requires libnuma)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Clone with submodules:&lt;/p&gt;
        &lt;code&gt;git clone --recursive https://github.com/kressler/fast-containers.git cd fast-containers&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;One-time development setup:&lt;/p&gt;
        &lt;quote&gt;./setup-dev.sh&lt;/quote&gt;
        &lt;p&gt;This installs pre-commit hooks and configures clang-tidy.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Automatic formatting and checks (via pre-commit hook):&lt;/p&gt;
    &lt;code&gt;git commit  # Automatically formats code and runs clang-tidy&lt;/code&gt;
    &lt;p&gt;The pre-commit hook will:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Format all staged C++ files with clang-format&lt;/item&gt;
      &lt;item&gt;Check production headers with clang-tidy&lt;/item&gt;
      &lt;item&gt;Fail the commit if warnings are found&lt;/item&gt;
      &lt;item&gt;Auto-create build directories if missing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Manual formatting:&lt;/p&gt;
    &lt;code&gt;cmake --build build --target format&lt;/code&gt;
    &lt;p&gt;Manual static analysis:&lt;/p&gt;
    &lt;code&gt;cmake --build build --target clang-tidy
# Or manually:
clang-tidy-19 -p cmake-build-clang-tidy include/fast_containers/*.hpp&lt;/code&gt;
    &lt;p&gt;Requirements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;clang-format (for code formatting)&lt;/item&gt;
      &lt;item&gt;clang-tidy-19 (for static analysis)&lt;/item&gt;
      &lt;item&gt;cmake (to auto-create build directories)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Bypass hook (when needed):&lt;/p&gt;
    &lt;code&gt;git commit --no-verify&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Make your changes&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Build and test:&lt;/p&gt;
        &lt;code&gt;cmake --build build &amp;amp;&amp;amp; ctest --test-dir build&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Commit (auto-formatted and checked):&lt;/p&gt;
        &lt;quote&gt;git add . git commit -m "Your changes" # Pre-commit hook runs automatically&lt;/quote&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Follow Google C++ Style Guide (enforced by clang-format)&lt;/item&gt;
      &lt;item&gt;Use C++23 features&lt;/item&gt;
      &lt;item&gt;Write tests for new functionality using Catch2&lt;/item&gt;
      &lt;item&gt;Production code must be clang-tidy clean (enforced in CI and pre-commit)&lt;/item&gt;
      &lt;item&gt;Run &lt;code&gt;cmake --build build --target format&lt;/code&gt;before submitting PRs&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;.
‚îú‚îÄ‚îÄ include/
‚îÇ   ‚îî‚îÄ‚îÄ fast_containers/         # Public header files
‚îÇ       ‚îú‚îÄ‚îÄ btree.hpp, btree.ipp
‚îÇ       ‚îú‚îÄ‚îÄ dense_map.hpp, dense_map.ipp
‚îÇ       ‚îú‚îÄ‚îÄ hugepage_allocator.hpp
‚îÇ       ‚îú‚îÄ‚îÄ multi_size_hugepage_allocator.hpp
‚îÇ       ‚îú‚îÄ‚îÄ multi_size_hugepage_pool.hpp
‚îÇ       ‚îú‚îÄ‚îÄ policy_based_hugepage_allocator.hpp
‚îÇ       ‚îî‚îÄ‚îÄ hugepage_pool.hpp
‚îú‚îÄ‚îÄ tests/                       # Unit tests (Catch2)
‚îÇ   ‚îú‚îÄ‚îÄ test_btree.cpp
‚îÇ   ‚îú‚îÄ‚îÄ test_dense_map.cpp
‚îÇ   ‚îú‚îÄ‚îÄ test_hugepage_allocator.cpp
‚îÇ   ‚îî‚îÄ‚îÄ test_policy_based_allocator.cpp
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ benchmarks/              # Google Benchmark performance tests
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dense_map_search_benchmark.cpp
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ hugepage_allocator_benchmark.cpp
‚îÇ   ‚îî‚îÄ‚îÄ binary/                  # Standalone benchmark executables
‚îÇ       ‚îú‚îÄ‚îÄ btree_benchmark.cpp
‚îÇ       ‚îî‚îÄ‚îÄ btree_stress.cpp
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ interleaved_btree_benchmark.py  # A/B testing harness
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îî‚îÄ‚îÄ btree_benchmark_results.md      # Performance analysis
‚îú‚îÄ‚îÄ third_party/                 # Git submodules
‚îÇ   ‚îú‚îÄ‚îÄ catch2/                  # Unit testing framework
‚îÇ   ‚îú‚îÄ‚îÄ benchmark/               # Google Benchmark
‚îÇ   ‚îú‚îÄ‚îÄ histograms/              # Latency histogram library
‚îÇ   ‚îú‚îÄ‚îÄ abseil-cpp/              # Comparison baseline
‚îÇ   ‚îú‚îÄ‚îÄ lyra/                    # Command-line parsing
‚îÇ   ‚îî‚îÄ‚îÄ unordered_dense/         # Dense hash map
‚îú‚îÄ‚îÄ hooks/                       # Git hooks (install with setup-dev.sh)
‚îÇ   ‚îî‚îÄ‚îÄ pre-commit               # Auto-format and clang-tidy
‚îî‚îÄ‚îÄ CMakeLists.txt               # Build configuration
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Language: C++23&lt;/item&gt;
      &lt;item&gt;Build System: CMake 3.30+&lt;/item&gt;
      &lt;item&gt;Testing: Catch2 v3.11.0&lt;/item&gt;
      &lt;item&gt;Code Formatting: clang-format (Google C++ Style)&lt;/item&gt;
      &lt;item&gt;Static Analysis: clang-tidy-19&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46512842</guid><pubDate>Tue, 06 Jan 2026 14:41:55 +0000</pubDate></item><item><title>65% of Hacker News posts have negative sentiment, and they outperform</title><link>https://philippdubach.com/standalone/hn-sentiment/</link><description>&lt;doc fingerprint="350c80263eb05556"&gt;
  &lt;main&gt;
    &lt;p&gt;Posts with negative sentiment average 35.6 points on Hacker News. The overall average is 28 points. That‚Äôs a 27% performance premium for negativity. This finding comes from an empirical study I‚Äôve been running on HN attention dynamics, covering decay curves, preferential attachment, survival probability, and early-engagement prediction. The preprint is available on SSRN. I already had a gut feeling. Across 32,000 posts and 340,000 comments, nearly 65% register as negative. This might be a feature of my classifier being miscalibrated toward negativity; yet the pattern holds across six different models. I tested three transformer-based classifiers (DistilBERT, BERT Multi, RoBERTa) and three LLMs (Llama 3.1 8B, Mistral 3.1 24B, Gemma 3 12B). The distributions vary, but the negative skew persists across all of them (inverted scale for 2-6). The results I use in my dashboard are from DistilBERT because it runs efficiently in my Cloudflare-based pipeline.&lt;/p&gt;
    &lt;p&gt;What counts as ‚Äúnegative‚Äù here? Criticism of technology, skepticism toward announcements, complaints about industry practices, frustration with APIs. The usual. It‚Äôs worth noting that technical critique reads differently than personal attacks; most HN negativity is substantive rather than toxic. But, does negativity cause engagement, or does controversial content attract both negative framing and attention? Probably some of both.&lt;/p&gt;
    &lt;p&gt;I‚Äôll publish the full code, dataset, and a dashboard for the HN archiver soon and I‚Äôm happy to send you an update:&lt;/p&gt;
    &lt;p&gt;Alternatively, you can also subscribe to the RSS feed or get updates on Bluesky.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46512881</guid><pubDate>Tue, 06 Jan 2026 14:45:47 +0000</pubDate></item><item><title>The skill of the future is not 'AI', but 'Focus' (2025)</title><link>https://carette.xyz/posts/focus_will_be_the_skill_of_the_future/</link><description>&lt;doc fingerprint="d94de1802fb14c0d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The skill of the future is not 'AI', but 'Focus'&lt;/head&gt;
    &lt;p&gt;¬∑ 3 min read&lt;/p&gt;
    &lt;p&gt;If you frequent Hacker News regurlarly, you have likely noticed the buzz around engineers using AI (specifically Large Language Models, or LLMs) to tackle Computer Science problems.&lt;/p&gt;
    &lt;p&gt;I want to be clear: I‚Äôm not against LLMs.&lt;lb/&gt; LLMs are incredibly powerful tools, and can be a huge boon to engineers. They can automate repetitive tasks, generate code snippets, help with brainstorming, assist in debugging, ‚Ä¶ and this can frees up engineers‚Äô time and mental energy, which could be channeled into more complex, creative problem-solving.&lt;lb/&gt; But, like any tool, LLMs should be used wisely.&lt;lb/&gt; LLMs can hallucinate, exhibit inconsistencies (especially with self-reflection models), and harbor biases. These limitations mean that LLM outputs require careful review before they can be trusted.&lt;/p&gt;
    &lt;p&gt;A key concern with LLMs lies in their training data.&lt;lb/&gt; The data can be biased, contradictory sometimes, but those data contain solutions to known problems.&lt;lb/&gt; If an engineer wants to ‚Äúreinvent the wheel,‚Äù an LLM might offer a solution (good or bad, depending on the prompt). But when faced with truly novel problems, LLMs often provide unreliable responses, placing the burden of error detection squarely on the engineer.&lt;/p&gt;
    &lt;p&gt;This reliance on readily available solutions, particularly for familiar problems, creates a real risk: engineers may inadvertently atrophy their own problem-solving skills, hindering their ability to tackle truly novel challenges.&lt;lb/&gt; The solution lies is balance, and a focus on the ‚Äúwhy‚Äù, not just the ‚Äúwhat‚Äù.&lt;lb/&gt; Engineers should strive to understand the reasoning behind LLM-generated solutions, not simply accept them blindly. Blind acceptance shifts the focus from solving problems to merely obtaining a solution. Crucially, solving complex problems often depends on mastering simpler and foundational skills, which the engineer might lose quickly.&lt;/p&gt;
    &lt;p&gt;This idea summarizes why I disagree with those who equate the LLM revolution to the rise of search engines, like Google in the 90s. Search enginers offer a good choice between Exploration (crawl through the list and pages of results) and Exploitation (click on the top result).&lt;lb/&gt; LLMs, however, do not give this choice, and tend to encourage immediate exploitation instead. Users may explore if the first solution does not work, but the first choice is always to exploit.&lt;lb/&gt; Exploitation and exploration are complementary. Remove the exploration and you will introduce more and more instability into the exploitation process.&lt;/p&gt;
    &lt;p&gt;Computer Science emerged because Humans needed tools to solve problems faster and wanted to focus on the real problems, not repetitive tasks. Humans built machines to accelerate problem-solving, but engineers remained the masters of the algorithms.&lt;lb/&gt; I fear we‚Äôre losing our grip on this mastery. Not because engineers are becoming less and less intelligent, but because the pressure to deliver solutions quickly is paramount.&lt;lb/&gt; In embracing these ‚Äúfast-paced solutions‚Äù, we risk losing a fundamental skill: focus. Because focus, like any skill, requires practice.&lt;/p&gt;
    &lt;p&gt;This is a worrying trend. If engineers become less adept at solving complex problems, what does the future hold? Will our ability to tackle complex challenges rest solely on self-reflecting AIs, rather than human ingenuity?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46513728</guid><pubDate>Tue, 06 Jan 2026 15:44:44 +0000</pubDate></item><item><title>State of the Fin 2026-01-06 ‚Äì Jellyfin</title><link>https://jellyfin.org/posts/state-of-the-fin-2026-01-06/</link><description>&lt;doc fingerprint="fe7c95df8880a4da"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;State of the Fin 2026-01-06&lt;/head&gt;
    &lt;p&gt;Happy New Year and welcome to the State of the Fin! This new blog series will regularly basis highlight the ongoing development of Jellyfin and our official clients. We aim to keep our community informed and engaged, so feel free to share your feedback or thoughts on our progress!&lt;/p&gt;
    &lt;head rend="h2"&gt;Project Updates&lt;/head&gt;
    &lt;head rend="h3"&gt;Jellyfin Turns 7&lt;/head&gt;
    &lt;p&gt;December marked Jellyfin's 7th anniversary! A lot has changed in 7 years, but we remain steadfast in our commitment to Open Source and to being the best personal media server out there. Special thanks to our developers, testers, moderators, and supporters for your invaluable contributions! Here's to many more years of collaboration and streaming!&lt;/p&gt;
    &lt;head rend="h3"&gt;Versioning&lt;/head&gt;
    &lt;p&gt;We received a substantial amount of feedback regarding our versioning scheme following the 10.11 release, particularly concerning the stability of what are perceived as 'minor' version updates. This has prompted internal discussions about potentially revising our versioning scheme in the next major release. While nothing has been finalized yet, we are considering 'dropping' the major version 10, which would make the next release 12.0. Stay tuned for further updates as we navigate this feedback!&lt;/p&gt;
    &lt;head rend="h2"&gt;Development Updates&lt;/head&gt;
    &lt;head rend="h3"&gt;10.11 Release Status&lt;/head&gt;
    &lt;p&gt;Jellyfin 10.11 introduced a major EF Core refactor, consolidating the legacy &lt;code&gt;library.db&lt;/code&gt; into a single unified &lt;code&gt;jellyfin.db&lt;/code&gt;.
Following more than six months of development and an additional six months of release candidate testing, version 10.11.0 was released last year.
This extended testing period allowed us to mitigate most refactoring and RC-related issues prior to release.&lt;/p&gt;
    &lt;p&gt;Even with this level of testing, issues were expected given the scale of the database change and the limited number of users reporting bugs. These issues are currently being tracked on GitHub across three categories:&lt;/p&gt;
    &lt;p&gt;We have been moving quickly to address these issues, delivering four additional point releases with over 100 changes since the initial 10.11.0 release. To date, most point releases have focused on resolving general and migration-related issues. The remaining migration issues are largely isolated, one-off cases and are unlikely to be resolved. Most general issues have already been fixed, and the next bug-fix release is expected to include additional fixes for music metadata display issues and for watched status not being preserved when media is replaced or renamed.&lt;/p&gt;
    &lt;p&gt;We are continuing to investigate ways to mitigate performance issues caused by client-side enumeration and filtering of large datasets.&lt;/p&gt;
    &lt;head rend="h3"&gt;Jellyfin Web vNext (aka 10.12 / 12.0)&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Default 'Experimental' Layout: The 'Experimental' layout is now enabled by default for all non-TV devices, introducing a new navigation layout and updated UI components.&lt;/item&gt;
      &lt;item&gt;Theming Support Overhaul: We are improving theming support by enabling easier runtime customization of default themes through CSS variables and simplifying the process for creating new bundled themes.&lt;/item&gt;
      &lt;item&gt;Community Acknowledgment: Huge thanks to those reviewing, testing, and providing feedback on web pull requests. Your contributions are immensely helpful, as the review burden largely falls on me alone!&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Client Corner&lt;/head&gt;
    &lt;head rend="h3"&gt;Jellyfin Desktop&lt;/head&gt;
    &lt;p&gt;We're rebranding the desktop application from Jellyfin Media Player to Jellyfin Desktop. The most noteworthy change is the migration from Qt 5 to Qt 6. This seems to have improved overall performance, though we're still working out issues regarding memory leaks due to the migration.&lt;/p&gt;
    &lt;p&gt;Apart from the Qt migration, other noteworthy updates.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Saved servers and settings will not be migrated from Jellyfin Media Player.&lt;/item&gt;
      &lt;item&gt;We've laid the foundation for switching servers with the addition of profiles CLI options. The long-term goal is to have a UI for this as well, but the timeline is TBD.&lt;/item&gt;
      &lt;item&gt;A slew of bug fixes are included.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The release is currently available on Flathub and in the Arch Linux AUR. Stable builds for Windows and macOS builds are not currently available. Other Linux distributions will likely be added, though we recommend using Flathub for the time being. We are not currently supporting Ubuntu 24.04 LTS due to it being stuck on the older Qt 6.4 series, while our new dependency, mpvqt, requires at least Qt 6.5.&lt;/p&gt;
    &lt;head rend="h3"&gt;Jellyfin for Android TV&lt;/head&gt;
    &lt;p&gt;Two versions of the Android TV app have been released: v0.19.5 and v0.19.6! These updates contain various improvements to music transcoding. The app now properly displays durations again and allows for seeking when music is transcoding. These changes also solve the issue of lyrics not scrolling in certain cases.&lt;/p&gt;
    &lt;p&gt;For video playback, we have improved the stability of Live TV and now support direct play for the VC-1 and AV1 codecs (if your device supports them). The AV1 support was already available on Android 10 and newer but now works on older Fire TV devices as well.&lt;/p&gt;
    &lt;head rend="h3"&gt;Jellyfin for Xbox&lt;/head&gt;
    &lt;p&gt;The last two updates brought the long awaited full gamepad support and fixes for 4K and HDR.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Gamepad support: Gamepad navigation is now the default navigation type for the Jellyfin for Xbox app and requires a server version of 10.11 or higher to work. However as we cannot switch the input mode type while the app is running, the Jellyfin for Xbox app can no longer connect to older versions than 10.11. As this is a fundamental change in how the app works, there are still a few hiccups like the app not loading correctly and users reporting that the gamepad does not work at all. In those instances we recommend uninstalling and reinstalling the app.&lt;/item&gt;
      &lt;item&gt;Web UI TV mode: For versions of Jellyfin earlier than 10.11.5 the web UI still runs in the desktop mode, which might look a bit odd. However, with Jellyfin 10.11.5, we have fixed a bug that now correctly sets the web UI to TV mode, so the UI should work a lot better.&lt;/item&gt;
      &lt;item&gt;4K and HDR: For the last few versions, we have been working on enabling 4K and HDR for the app. This is done by integrating with the web UI and switching the HDMI modes. Sadly, this also comes at the cost of not being allowed to run in the background. To enable 4K support, we had to use a feature flag that allocates more video memory to the Jellyfin for Xbox app, making it incompatible with running in the background.&lt;/item&gt;
      &lt;item&gt;General Improvements: Alongside the shiny new headline features, we have also been working on the code in general, adding small improvements and cleaning up a lot of code. The latest versions added log files and their upload to the Jellyfin server, tighter integrations with the web UI, a settings view that can be expanded for future features, version compatibility checking, a better server connection experience, and more.&lt;/item&gt;
      &lt;item&gt;Future: When I took over the for the previous maintainer almost a year ago, I made a rough plan for the general development of the app. I always planned on keeping the app as a web wrapper because while the app is certainly more popular than most think, it does not have enough support in development to be a full UWP app. Nevertheless, there are a few features left on my to-do list: &lt;list rend="ul"&gt;&lt;item&gt;Localization to other languages&lt;/item&gt;&lt;item&gt;Server discovery&lt;/item&gt;&lt;item&gt;Desktop support&lt;/item&gt;&lt;item&gt;Better decoder support&lt;/item&gt;&lt;item&gt;Subtitle storage on-device&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;- JPVenson&lt;/p&gt;
    &lt;head rend="h3"&gt;Jellyfin for Roku&lt;/head&gt;
    &lt;p&gt;3.0.15 was released on 2025-12-18 and is our last release before Roku's year-end publishing blackout. It fixes a bug with HDHomeRun Tuners.&lt;/p&gt;
    &lt;p&gt;- 1hitsong&lt;/p&gt;
    &lt;head rend="h3"&gt;Swiftfin&lt;/head&gt;
    &lt;head rend="h4"&gt;Swiftfin 1.4 is out now!&lt;/head&gt;
    &lt;p&gt;This is a large release with a lot of changes under the hood. Our three highlight changes are:&lt;/p&gt;
    &lt;head rend="h4"&gt;Swiftfin Roadmap&lt;/head&gt;
    &lt;p&gt;A roadmap / project board for Swiftfin is now available!&lt;/p&gt;
    &lt;p&gt;Follow this discussion for information about the next tvOS release.&lt;/p&gt;
    &lt;p&gt;To help organize Issues &amp;amp; PRs, Swiftfin now has milestones to help users identify which changes will be included in each release:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Version 1.5 &lt;list rend="ul"&gt;&lt;item&gt;Contains issues that should be resolved in version 1.5 of Swiftfin iOS.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;tvOS Resync &lt;list rend="ul"&gt;&lt;item&gt;Contains tvOS-specific issues that will be resolved as part of our next tvOS Release.&lt;/item&gt;&lt;item&gt;Issues that impact tvOS but are part of 1.4 or 1.5 will end up in the version milestone instead of this one. Once tvOS is released, it should mirror our existing 1.X structure and iOS.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A more detailed post about these changes can be found on GitHub!&lt;/p&gt;
    &lt;p&gt;- JPKribs&lt;/p&gt;
    &lt;head rend="h3"&gt;Other TV Platforms&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Tizen app was submitted for review, but unfortunately failed testing. Additional work is needed to replicate the reported issues and correct them.&lt;/item&gt;
      &lt;item&gt;Support for multiple new platforms is currently underway, and we will provide updates as progress is made.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Wishing you all happy streaming in 2026 and beyond! We look forward to another year filled with exciting updates and features for Jellyfin.&lt;/p&gt;
    &lt;p&gt;- thornbill and the Jellyfin Team&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46514282</guid><pubDate>Tue, 06 Jan 2026 16:17:24 +0000</pubDate></item><item><title>Vienam bans unskippable ads</title><link>https://saigoneer.com/vietnam-news/28652-vienam-bans-unskippable-ads,-requires-skip-button-to-appear-after-5-seconds</link><description>&lt;doc fingerprint="6f8928bd4270847c"&gt;
  &lt;main&gt;
    &lt;p&gt;If things go our way, YouTube‚Äôs notorious unskippable ads might be a thing of the past come this February.&lt;/p&gt;
    &lt;p&gt;As Ph·ª• N·ªØ reports, Vietnam recently announced Decree No. 342, which details a number of provisions to the national Advertising Law, due to take effect from February 15, 2026. The adjustments are expected to place stricter control on Vietnam‚Äôs online advertising activities to protect consumers and curb illegal ads.&lt;/p&gt;
    &lt;p&gt;Amongst the decree articles, some standout stipulations include a hard cap on the waiting time before viewers can skip video and animated ads to no more than 5 seconds. Static ads must be immediately cancellable.&lt;/p&gt;
    &lt;p&gt;Additionally, the decree requires platforms to implement clear and straightforward ways for users to close ads with just one interaction. False or vague symbols designed to confuse viewers are forbidden.&lt;/p&gt;
    &lt;p&gt;Online platforms must add visible symbols and guidelines to help users report ads that violate the law and allow them to turn off, deny, or stop seeing inappropriate ads.&lt;/p&gt;
    &lt;p&gt;Beside rules about the user experience, the decree also seeks to tightly regulate ads for 11 groups of goods and services that directly impact the environment and human health, including: cosmetics; food and beverages; milk and formula for children; insecticidal chemicals and substances; medical supplies; healthcare services; plant pesticides and veterinary drugs; fertilizers; plant seeds and saplings; pharmaceuticals; and alcoholic drinks.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46514677</guid><pubDate>Tue, 06 Jan 2026 16:45:42 +0000</pubDate></item><item><title>Why is the Gmail app 700 MB?</title><link>https://akr.am/blog/posts/why-is-the-gmail-app-700-mb</link><description>&lt;doc fingerprint="bda994732ecfabe0"&gt;
  &lt;main&gt;
    &lt;p&gt;The Gmail app, on the App Store, is currently 760.7 MB in size. It is in the top three most bloated apps out of the top 100 free apps. I don‚Äôt use it on my phone, but I was prompted to compare it with the seemingly hefty one I (have to) use, Outlook, while clearing up some storage space. Its measly 428 MB size pales in comparison.&lt;/p&gt;
    &lt;p&gt;This isn‚Äôt new. In 2017, Axios reported that the top iPhone apps had been taking up an increasing amount of space over the period from 2013 to 2017. For most of that period, the size of the Gmail app hovered around 12 MB, with a sudden jump to more than 200 MB near the start of 2017. Other popular apps also saw a 10x or more increase in size over the same period.&lt;/p&gt;
    &lt;p&gt;Gmail isn‚Äôt even the worst offender, it‚Äôs just a more popular one. The Tesla and Crypto.com apps are around 1 GB each. So is Samsung‚Äôs SmartThings app. What about Google‚Äôs other popular apps? Google Home is another hefty one, at 630 MB, that I used for its remote feature, which I replaced with Google TV at almost a tenth the size. Their other popular apps average around 250 MB in size. This seems tame in comparison to Microsoft, with an average app size of around 330MB. For reference, the average size of an app in the top 100 free apps is 280 MB or, in a more expanded set (including games), 200MB.&lt;/p&gt;
    &lt;p&gt;Just to put this into perspective, on my device, apps (excluding their data) use up 35 GB, and the data is another 35 GB. iOS takes up another 25 GB. Let‚Äôs say, 100 GB for apps, data and the OS. That leaves me with 20 GB (leaving a margin of free space for updates) meant to be used for capturing 4K video and high-quality photos (why else get an iPhone), and storing music (don‚Äôt even think about lossless). The reality is that running out of space also slows things down, since most of my photos need to be fetched from the cloud before viewing them, and I need to re-download these hefty offloaded apps when I need them again. And good luck if you have a limited data bundle.&lt;/p&gt;
    &lt;p&gt;Maybe this doesn‚Äôt matter. The latest iPhones start at 256 GB, and surely I‚Äôll have plenty of space when I get a new one (although I remember saying this when I upgraded to 64 GB from 32 GB). It‚Äôs not really about the space though. These apps don‚Äôt have 50x or even 10x the functionality. But now they‚Äôre 100x larger, and probably slower. Why?&lt;/p&gt;
    &lt;p&gt;Also, can someone explain why Microsoft Authenticator is 150 MB to show 6-digit codes?&lt;/p&gt;
    &lt;p&gt;It‚Äôs not clear if this is specifically an iOS problem. I don‚Äôt have an Android device and I could not find a way to get that information from the Play Store without a device. That said, I checked the size of Gmail on someone‚Äôs Android phone, and it‚Äôs around 185 MB, which certainly seems much better.&lt;/p&gt;
    &lt;p&gt;And if you‚Äôre considering switching from the default apps, this is what the installed size (which differs slightly from the App Store size) is of the alternatives on my iPhone running iOS 26.2:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;App&lt;/cell&gt;
        &lt;cell role="head"&gt;Apple&lt;/cell&gt;
        &lt;cell role="head"&gt;Microsoft&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Files - Drive - OneDrive&lt;/cell&gt;
        &lt;cell&gt;2.6 MB&lt;/cell&gt;
        &lt;cell&gt;370 MB&lt;/cell&gt;
        &lt;cell&gt;283 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Passwords - Authenticator&lt;/cell&gt;
        &lt;cell&gt;3.2 MB&lt;/cell&gt;
        &lt;cell&gt;35 MB&lt;/cell&gt;
        &lt;cell&gt;138 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;FaceTime - Meet - Teams&lt;/cell&gt;
        &lt;cell&gt;3.4 MB&lt;/cell&gt;
        &lt;cell&gt;263 MB&lt;/cell&gt;
        &lt;cell&gt;423 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Photos&lt;/cell&gt;
        &lt;cell&gt;4.2 MB&lt;/cell&gt;
        &lt;cell&gt;372 MB&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Safari - Chrome - Edge&lt;/cell&gt;
        &lt;cell&gt;5.1 MB&lt;/cell&gt;
        &lt;cell&gt;313 MB&lt;/cell&gt;
        &lt;cell&gt;397 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Reminders - Tasks - To Do&lt;/cell&gt;
        &lt;cell&gt;7.7 MB&lt;/cell&gt;
        &lt;cell&gt;89 MB&lt;/cell&gt;
        &lt;cell&gt;132 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Mail - Gmail - Outlook&lt;/cell&gt;
        &lt;cell&gt;8.7 MB&lt;/cell&gt;
        &lt;cell&gt;673 MB&lt;/cell&gt;
        &lt;cell&gt;376 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Home&lt;/cell&gt;
        &lt;cell&gt;14.1 MB&lt;/cell&gt;
        &lt;cell&gt;584 MB&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Notes - Keep - OneNote&lt;/cell&gt;
        &lt;cell&gt;17.3 MB&lt;/cell&gt;
        &lt;cell&gt;171 MB&lt;/cell&gt;
        &lt;cell&gt;315 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Maps&lt;/cell&gt;
        &lt;cell&gt;68 MB&lt;/cell&gt;
        &lt;cell&gt;385 MB&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Pages - Docs - Word&lt;/cell&gt;
        &lt;cell&gt;456 MB&lt;/cell&gt;
        &lt;cell&gt;311 MB&lt;/cell&gt;
        &lt;cell&gt;434 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Numbers - Sheets - Excel&lt;/cell&gt;
        &lt;cell&gt;500 MB&lt;/cell&gt;
        &lt;cell&gt;337 MB&lt;/cell&gt;
        &lt;cell&gt;370 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Keynote - Slides - PowerPoint&lt;/cell&gt;
        &lt;cell&gt;516 MB&lt;/cell&gt;
        &lt;cell&gt;270 MB&lt;/cell&gt;
        &lt;cell&gt;376 MB&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;So, why is the Gmail app almost 80x the size of the native Mail app? My guess is as good as yours.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46514692</guid><pubDate>Tue, 06 Jan 2026 16:46:13 +0000</pubDate></item><item><title>Raspberry Pi and mini PC home lab prices hit parity as DRAM costs skyrocket</title><link>https://www.tomshardware.com/raspberry-pi/raspberry-pi-and-mini-pc-home-lab-prices-hit-parity-as-dram-costs-skyrocket-price-hikes-force-hobbyists-to-weigh-up-performance-versus-power-consumption</link><description>&lt;doc fingerprint="9353208944bfd02e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Raspberry Pi and mini PC home lab prices hit parity as DRAM costs skyrocket ‚Äî price hikes force hobbyists to weigh up performance versus power consumption&lt;/head&gt;
    &lt;p&gt;Building your own homelab has just become more expensive&lt;/p&gt;
    &lt;p&gt;The humble Raspberry Pi, the perennial leader of the low-power, single-board computing (SBC) world, has hit a price parity with its rival, the Intel N100-based mini PCs. An investigation by Jeff Geerling, which we‚Äôve independently confirmed, shows that pricing for Pi‚Äôs is now within just a few cents with a similarly configured board from brands like GMKTec. Why does this matter? Hobbyists and homelab builders had a great 2024 / 2025 which saw low prices for their DIY setups.&lt;/p&gt;
    &lt;p&gt;If you‚Äôve been keeping a close eye on the PC hardware market of late, you‚Äôll have noticed prices only going one way: upward. Flash memory costs, along with tariff uncertainties last year, have forced mini PC manufacturers and retailers to raise prices across the board. As Geerling explains, an explosion in homelab builds using $100-150 mini PCs made those same PCs a better, or certainly cheaper, alternative to current-gen Raspberry Pi 5s which when bundled up with NVMe HATs, NVMe drives, cases etc, retailed for over $200 last year.&lt;/p&gt;
    &lt;p&gt;Now, the tables have turned. Geerling, who compared the prices of a GMKTec mini PC versus a Raspberry Pi 5 kit in March 2025, found in his updated investigation that the GMKTec machine he considered in his first investigation is now more expensive (albeit by only a few cents). Both systems feature 16GB RAM and a 512GB NVMe SSD, but given current market conditions, systems like these aren't be sold as cheaply as they were last year.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Model&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;2025 price&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;2026 price&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Raspberry Pi 5 16GB (with 512GB SSD, 27W PSU, Bumper Case, and RTC Battery)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$208.75 (Jeff Geerling - Jan 2025)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$246.95 (Jeff Geerling - Jan 2026)&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;$156.87 (Aug 2025)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$246.99 (Jan 2026)&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;$159 (Aug 2025)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$259 (Jan 2026)&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;$158 (Aug 2025)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$217.54 (Jan 2026)&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;$199&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$199&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Our own comparison of rival mini PCs, based on Amazon‚Äôs current pricing whilst compared with Camelcamelcamel‚Äôs historical data, shows that this isn‚Äôt just a brand-specific issue. For instance, the Beelink S13 with the refreshed Intel N150 CPU, 16GB RAM, and a 512GB SSD is on sale for $269, from as low as $168.99 in August 2025.&lt;/p&gt;
    &lt;p&gt;Meanwhile the Acemagic V1, with similar specs, is available for $217.54, up from $158 in August 2025, or $180 in January 2025. Geekom does offer an N100 mini PC costing $199.99 that hasn't seen a price change on Amazon in the last year, but with only 8GB RAM and a 256GB SSD. &lt;lb/&gt;The Raspberry Pi is also not immune to the upward pricing trend. The cost of a Raspberry Pi has changed in recent months, and Raspberry Pi introduced a 1GB Pi 5 in order to keep a low $45 price point. A Raspberry Pi 5 with 16GB of RAM is now $145, $25 more expensive than in early 2025.&lt;lb/&gt;The cost of additional components, such as the SSD, have all added to the cost of creating your own DIY homelab.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;Product&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;RAM&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;Old Price&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;New Price&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;p&gt;Raspberry Pi 4&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;4GB&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$55&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$60&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;p&gt;Raspberry Pi 4&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;8GB&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$75&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$85&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;p&gt;Raspberry Pi 5&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;1GB&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;New product&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$45&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;p&gt;Raspberry Pi 5&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;2GB&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$50&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$55&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;p&gt;Raspberry Pi 5&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;4GB&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$60&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$70&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;p&gt;Raspberry Pi 5&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;8GB&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$80&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$95&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Raspberry Pi 5&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;16GB&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$120&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;$145&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Source: Raspberry Pi blog.&lt;/p&gt;
    &lt;p&gt;This now leaves prospective homelab builders with three variables to consider: overall cost, power usage, and performance. Intel mini PCs are more powerful than the Raspberry Pi, even if the Pi 5 did offer a significant speed boost over the Pi 4, as our Pi 5 review explains. However, the Raspberry Pi continues to be the superior option if you're looking for the lowest power draw, even compared to the otherwise power-efficient Intel N100 and refreshed N150 mini PCs on sale.&lt;/p&gt;
    &lt;p&gt;Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.&lt;/p&gt;
    &lt;p&gt;Geerling believes that, as a result of these price rises, repurposing old hardware will be the ‚Äútheme‚Äù for this new year, and one that will save you far more money, given the alternatives. This might be the status quo for some time, too. There‚Äôs no end in sight for the price shocks affecting the market, with memory manufacturers warning that the crisis has only just started, and could roll on for years to come.&lt;/p&gt;
    &lt;p&gt;Follow Tom's Hardware on Google News, or add us as a preferred source, to get our latest news, analysis, &amp;amp; reviews in your feeds.&lt;/p&gt;
    &lt;p&gt;Ben Stockton is a deals writer at Tom‚Äôs Hardware. He's been writing about technology since 2018, with bylines at PCGamesN, How-To Geek, and Tom‚Äôs Guide, among others. When he‚Äôs not hunting down the best bargains, he‚Äôs busy tinkering with his homelab or watching old Star Trek episodes.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;header&gt;bit_user&lt;/header&gt;I know it depends a lot on what you do with it, but I think 16 GB is overkill for a Pi 5. Sure, if you do heavy web-browsing, then ads and videos will quickly fill up even that much. But, a Pi 5 isn't going to provide a very good web browsing experience, no matter how much RAM it has. I definitely wouldn't use one as a primary desktop, if I could avoid it. For most other things, 8 GB on a 4-core/4-thread CPU is probably quite adequate.Reply&lt;lb/&gt;By contrast, a Alder Lake-N system is a much more viable desktop option. It does deliver a usable web experience, both by having significantly faster CPU cores and having proper driver support for video decode. As a desktop, it'd definitely benefit from having 16 GB - as well as DDR5, if you can manage. And here, regular DDR5 is best, since it's significantly lower-latency than LPDDR5. I think a lot of the Alder Lake-N boards with soldered-down DRAM probably use LPDDR4 or LPDDR5.&lt;lb/&gt;Heat and power consumption are where you can get burned by going the Alder Lake-N route. The Pi 5 hits a ceiling on power consumption, at a point where Alder Lake-N is just stretching its legs. I'm basing this on wall-power data I've seen from a quad-core N97, even with restricted package power limits. The specified TDP on those N97 or N100 chips is, by no means, the full story on how much power those systems actually use!&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46514794</guid><pubDate>Tue, 06 Jan 2026 16:52:08 +0000</pubDate></item><item><title>Loongarch Improvements with Box64</title><link>https://box86.org/2026/01/new-box64-v0-4-0-released/</link><description>&lt;doc fingerprint="b7c6381d6a23a46b"&gt;
  &lt;main&gt;
    &lt;p&gt;Happy new year, and happy new release of Box64!&lt;/p&gt;
    &lt;p&gt;The new version brings a ton of new enhancements and fixes to all 3 supported platforms, with Steam running not only on Arm64, but also on RiSC-V and on Loongarch! And this is the Linux version of Steam, not the Windows one (but the Windows one works too if you really prefer that one). While Box32 (used to run Steam) is still experimental and unstable, stability did improve. Still, expect some crashes when downloading things with steam. And it‚Äôs not all, Battle.net is also getting stable, and some games are working too. Not all unfortunately, and your success might depend on your geographical region, as program versions might differ. At least, you can try it on ARM64 &amp;amp; Loongarch. It‚Äôs still to be tested on RiSC-V.&lt;/p&gt;
    &lt;head rend="h2"&gt;Highlights&lt;/head&gt;
    &lt;p&gt;So, what‚Äôs new in this release? Apart from the traditionals fixes, speedups, opcodes implementation and new wrapper functions, there has been a number of refactors. Some are more groundwork for later use, like the &lt;code&gt;libdl&lt;/code&gt; one. But some have immediate benefits. The prefix opcode decoder, now implemented on the interpreter and the 3 dynarec backend is one of those. This allows to more generically handle exotic opcode prefixes without doing hacks or adding duplicated code. This one lead to the removal of many source files, now useless, making the maintenance of box64 a bit easier. Also, this automatically added support for many rare (or less rare) occurrences of many opcodes in the Dynarec, with 0 extra coding.&lt;/p&gt;
    &lt;p&gt;There has been some work on the memory footprint of box64 too. Some applications use a lot of memory once launched with box64 (Steam for example, or other things that use &lt;code&gt;libcef&lt;/code&gt; or a variant of it). So some work was started to develop mechanisms to try to identify blocks of code that have been converted to native, but that seem to not be used anymore, so they can be deleted and the memory recycled for some fresh code. The work is still in progress on this subject, and more work will come in next release.&lt;/p&gt;
    &lt;head rend="h2"&gt;Capture card&lt;/head&gt;
    &lt;p&gt;I have (finally?) invested in a capture card (an Elgato HD60X) for all my video capture. I did all the Loongarch &amp;amp; RiSC-V game captures using OBS on my Ampere ARM64 machine (plug‚Äôn play), and I did the Ampere game footage captures using a Lenovo T14s (XElite/ARM64) running Ubuntu also with OBS. While the capture done on the Ampere (using the NVidia card and encoder) were fine, the ones done on the T14s (using software encoder) were a little too compressed for many captures. I have adjusted the settings, but not redone most of them, so you will see some compression artefacts in the ARM64 gameplay video. But at least the performances are not hurt by the capture anymore‚Ä¶&lt;/p&gt;
    &lt;p&gt;Side note: the editing was also done on the Ampere ARM64 machine (with OpenShot), so no x86 machine was involved in those videos at all!&lt;/p&gt;
    &lt;head rend="h2"&gt;Architectures&lt;/head&gt;
    &lt;p&gt;While there is not much news on the ARM64 side (there is added support for the GB10 cpu as a build profile for Box64), there was still some refactoring to improve performances of the Dynarec there. There is still ongoing work to detect and optimize more code loops; for instance, pre-loading used XMM/YMM register just before entering the loop, to avoid loading and saving these registers when it‚Äôs not needed. That can give some big speedup in some case. More speedup will be expected when more loop cases are getting detected and handled.&lt;/p&gt;
    &lt;p&gt;On the RiSC-V, the last months have brought the Dynarec to a very decent level of completion and performances, thanks to contribution of PLCT Labs and many things are working now. Steam, Proton and Wine are all running (even with the 39bits address space limitation of many hardware). But DRM protected stuff that need Windows Syscall emulation will not work for now unless the hardware support SV48 (48bits address space) or using a hacked Wine/Proton. The current hardware used for the video is a Pioneer Milk-V mini-server and its 64 cores CPU. But each core is still quite slow, at 1.5GHz, and the equipped graphic card, an old AMD RX550, is also showing it‚Äôs limitation in some of those videos‚Ä¶&lt;/p&gt;
    &lt;p&gt;The Loongarch backend is the one that saw the most progress in this cycle, and this CPU is starting to shine already, even if the Dynarec doesn‚Äôt yet have all the bells and whistles from the ARM64 version. Steam works now, but also Wine and Proton. But you need to use the 4K page size kernel. The default for this system is usually 16K, but most OS have a 4K option. I use AOSC on my side, but there is now a Debian option too. The modest 3A6000 is a 4 physical cores (8 logicals cores) CPU at 2.5 GHz. Sounds modest on paper, but equipped with a good AMD RX7600, the results are already quite surprising. And it seems to be even better on more powerful variants of the CPU, like the 3B6000 (12 cores) or 3C6000 (16 cores).&lt;/p&gt;
    &lt;head rend="h2"&gt;ESync / FSync / NTSync&lt;/head&gt;
    &lt;p&gt;Wine and Proton need some complex synchronisation mechanisms between processes. By default, Wine uses a basic system on the wineserver side. It works but can be quite slow depending on the number of processes / threads / CPU cores‚Ä¶ So various mechanisms have been developed in the last few years. The first two are ESync and FSync. While they can be faster, they can also be not 100% accurate. Box64 supports both of them (and they get used automatically by Proton in Steam), but some games are not synchronising correctly when using them. Games that use the Rockstar launcher or Microsoft XBox services might not start correctly when using ESync and FSync on ARM64. So on steam, you might need to use&lt;/p&gt;
    &lt;code&gt;PROTON_NO_ESYNC=1 PROTON_NO_FSYNC=1 %command%&lt;/code&gt;
    &lt;p&gt;on the program launch option in steam. Or disable them using the UI if you are using Heroic.&lt;/p&gt;
    &lt;p&gt;NTSync on the other hand seems to work fine, but is very new. You need to have a kernel where NTSync is enabled to use it. Debian on ARM64 still hasn‚Äôt that, even on the Forky branch. Ubuntu on ARM64 seems the same. Both OS on X64 ship kernels with NTSync enabled it seems. Armbian, on the other hand, have kernel with NTSync enabled. On Loongarch, AOSC also has NTSync enabled. Note that you need a bleeding edge Wine or Proton-GE to actually use NTSync. The default Proton from Steam will not use it for now, so it‚Äôs very early, but some result on 3C6000 processor shows some impressive result with about 80% more FPS in heavy games.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Box64 is ready to be used, so go grab the source, build your own version and enjoy!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46514807</guid><pubDate>Tue, 06 Jan 2026 16:52:56 +0000</pubDate></item><item><title>Show HN: Stash ‚Äì Sync Markdown Files with Apple Notes via CLI</title><link>https://github.com/shakedlokits/stash</link><description>&lt;doc fingerprint="20c6dcb573341fc0"&gt;
  &lt;main&gt;
    &lt;code&gt;                                     
                                     
  ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñÑ ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà  ‚ñà‚ñà 
  ‚ñÄ‚ñÄ‚ñÄ‚ñÑ‚ñÑ‚ñÑ   ‚ñà‚ñà   ‚ñà‚ñà‚ñÑ‚ñÑ‚ñà‚ñà ‚ñÄ‚ñÄ‚ñÄ‚ñÑ‚ñÑ‚ñÑ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 
  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÄ   ‚ñà‚ñà   ‚ñà‚ñà  ‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÄ ‚ñà‚ñà  ‚ñà‚ñà 
                                     
                                     
&lt;/code&gt;
    &lt;p&gt;Bidirectionally sync Markdown files with Apple Notes!&lt;/p&gt;
    &lt;code&gt;brew tap shakedlokits/stash https://github.com/shakedlokits/stash
brew install shakedlokits/stash/stash&lt;/code&gt;
    &lt;p&gt;Push a markdown file to Apple Notes:&lt;/p&gt;
    &lt;code&gt;stash push my-note.md&lt;/code&gt;
    &lt;p&gt;Pull changes back from Apple Notes:&lt;/p&gt;
    &lt;code&gt;stash pull my-note.md&lt;/code&gt;
    &lt;p&gt;That's it! The tool uses front-matter to track which Apple Note corresponds to your file.&lt;/p&gt;
    &lt;p&gt;Apple Notes has been my daily driver for years. I love its simplicity‚Äîit syncs fast, stays out of the way, and just lets me write.&lt;/p&gt;
    &lt;p&gt;I've explored the full spectrum of note-taking apps: &lt;code&gt;Workflowy&lt;/code&gt;, &lt;code&gt;Obsidian&lt;/code&gt;, &lt;code&gt;Bear&lt;/code&gt;, &lt;code&gt;Evernote&lt;/code&gt;, &lt;code&gt;Notion&lt;/code&gt;, &lt;code&gt;Google Keep&lt;/code&gt;, &lt;code&gt;GoodNotes&lt;/code&gt;, and others I've since forgotten. Each promised to revolutionize how I capture thoughts. But eventually, I realized something simple: note-taking is about writing things down, not managing a complex system. I came back to Apple Notes and haven't looked back.&lt;/p&gt;
    &lt;p&gt;There's just one friction point. When I'm building things‚Äîwhich is most days‚ÄîI live in Markdown. At work, I sync those files to Notion or Confluence with CLI tools. For personal projects, everything goes into Git. But increasingly, I find myself writing quick notes that don't belong to any project‚Äîjust ideas, experiments, small discoveries‚Äîand I want them on Apple Notes where I can read them anywhere. Right now, there's no clean path from my Markdown workflow to my notes.&lt;/p&gt;
    &lt;p&gt;I went searching for CLI tools to bridge this gap. What I found was disappointing: tools either pack in too many features, making them brittle and hard to maintain, or they offer so little functionality (read-only sync) that they're effectively useless.&lt;/p&gt;
    &lt;p&gt;So I built my own.&lt;/p&gt;
    &lt;p&gt;The requirements are straightforward:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Run from the shell without configuration files&lt;/item&gt;
      &lt;item&gt;Use AppleScript for maximum compatibility and stability&lt;/item&gt;
      &lt;item&gt;Bidirectionally sync Markdown and Apple Notes, using front-matter to track state&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Congratulations! You've written a new Markdown note, it's nice and tidy, and you've even run &lt;code&gt;vale&lt;/code&gt; on it. Now all that remains is getting it into Apple Notes. Here's what you need to do:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Run &lt;code&gt;push my-cool-note.md&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;A new note will be created: &lt;code&gt;My Cool Note ...&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Front-matter with a unique identifier will be added to your markdown file: &lt;quote&gt;--- apple_notes_id: my-new-cool-note-identifier --- # My Cool Note ...&lt;/quote&gt;&lt;p&gt;NOTE: If you already have front-matter, it will be added to the existing front-matter.&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Made changes to the Markdown file and now it's out of sync? Simply:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Rerun &lt;code&gt;push my-cool-note.md&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;The tool searches for the note matching your identifier (&lt;code&gt;id_my-new-cool-note-identifier&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;It rewrites the note's content with your updated Markdown. &lt;p&gt;NOTE: If no note was found (due to unexpected ID changes) you will be asked if you'd like to create a new note, which will overwrite your previous ID.&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You've gone off for your coffee/potty/meeting break, and while skimming through your note on your phone, you realized you made a terrible mistake‚Äîwhich inevitably led you to rewrite half of it.&lt;/p&gt;
    &lt;p&gt;Now the panic has settled, you're back at your computer, and you're wondering: "What the hell have I done, and how can I possibly get all those changes back into my Markdown?"&lt;/p&gt;
    &lt;p&gt;Don't fret. Simply:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Run &lt;code&gt;pull my-cool-note.md&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;The tool searches for the note matching your identifier (&lt;code&gt;id_my-new-cool-note-identifier&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;It rewrites your local Markdown file with the content from Apple Notes. &lt;p&gt;NOTE: The front-matter is unchanged during pull operations.&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;macOS with Apple Notes&lt;/item&gt;
      &lt;item&gt;Pandoc for Markdown ‚Üî HTML conversion&lt;/item&gt;
      &lt;item&gt;pcregrep for frontmatter parsing (usually pre-installed on macOS, or install via &lt;code&gt;brew install pcre&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The tool is built in three layers:&lt;/p&gt;
    &lt;p&gt;AppleScript forms the core, handling all communication with Apple Notes‚Äîfinding existing notes, updating content, and creating or deleting notes (the latter mostly for testing).&lt;/p&gt;
    &lt;p&gt;Shell scripts contain the business logic that orchestrates these AppleScript operations, managing the sync workflow and front-matter processing.&lt;/p&gt;
    &lt;p&gt;Pandoc handles the conversion between Markdown and HTML, ensuring content is properly formatted for Apple Notes.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Bashly&lt;/code&gt; ties it all together, providing a clean CLI interface, shell completions, and command scaffolding.&lt;/p&gt;
    &lt;p&gt;Clone the repository and build:&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/shakedlokits/stash.git
cd stash
make build&lt;/code&gt;
    &lt;code&gt;# Run all tests (requires Apple Notes access)
make test

# Run unit tests only (no Apple Notes required)
make test-unit&lt;/code&gt;
    &lt;code&gt;src/
  lib/           # Utility functions (pure and integration)
  bashly.yml     # CLI configuration
  *_command.sh   # Command implementations
test/
  cases/         # Test specs (unit, integration, e2e)
  fixtures/      # Test fixture files
  approvals/     # Approval test snapshots
dist/
  stash          # Generated CLI (via bashly)
Formula/
  stash.rb       # Homebrew formula
&lt;/code&gt;
    &lt;code&gt;make release VERSION=x.y.z&lt;/code&gt;
    &lt;p&gt;This will:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Update the version in &lt;code&gt;src/bashly.yml&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Commit the change&lt;/item&gt;
      &lt;item&gt;Create and push a git tag&lt;/item&gt;
      &lt;item&gt;Trigger the release workflow (build, publish, update Homebrew formula)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This backlog contains both current and future development items, feel free to take some or add to it:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Basic Functionality &lt;list rend="ul"&gt;&lt;item&gt; AppleScript notes access functions &lt;list rend="ul"&gt;&lt;item&gt;Find note&lt;/item&gt;&lt;item&gt;Create note&lt;/item&gt;&lt;item&gt;Delete note&lt;/item&gt;&lt;item&gt;Update note&lt;/item&gt;&lt;item&gt;Read note&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Markdown front-matter parser (get-id, extract, strip, update)&lt;/item&gt;&lt;item&gt;Push command shell script&lt;/item&gt;&lt;item&gt;Push command tests&lt;/item&gt;&lt;item&gt;Pull command shell script&lt;/item&gt;&lt;item&gt;Pull command tests&lt;/item&gt;&lt;item&gt;&lt;code&gt;Pandoc&lt;/code&gt;integration&lt;/item&gt;&lt;item&gt;&lt;code&gt;Bashly&lt;/code&gt;setup&lt;list rend="ul"&gt;&lt;item&gt;CLI interface&lt;/item&gt;&lt;item&gt;Shell completion&lt;/item&gt;&lt;item&gt;Documentation&lt;/item&gt;&lt;item&gt;Approval testing&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt; AppleScript notes access functions &lt;/item&gt;
      &lt;item&gt; Nice to have &lt;list rend="ul"&gt;&lt;item&gt;Diff changes (requires design)&lt;/item&gt;&lt;item&gt;Attachments support&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46514874</guid><pubDate>Tue, 06 Jan 2026 16:57:15 +0000</pubDate></item><item><title>Volkswagen Brings Back Physical Buttons</title><link>https://www.caranddriver.com/news/a69916699/volkswagen-interior-physical-buttons-return/</link><description>&lt;doc fingerprint="bdad3ddd2a3489a9"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Volkswagen revealed a new generation of cockpit design with the refreshed ID. Polo.&lt;/item&gt;
      &lt;item&gt;The new design marks a big departure for VW and features a plethora of physical controls rather than the capacitive buttons on current models.&lt;/item&gt;
      &lt;item&gt;While the switchgear is currently only found on the new ID. Polo, which isn't sold in the United States, it could debut on the soon-to-be-refreshed ID.4.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Volkswagen is making a drastic change to its interiors, or at least the interiors of its electric vehicles. The automaker recently unveiled a new cockpit generation with the refreshed ID. Polo‚Äîthe diminutive electric hatchback that the brand sells in Europe‚Äîthat now comes with physical buttons.&lt;/p&gt;
    &lt;p&gt;While VW certainly isn't the only automaker that pushed the envelope with haptic controls and digital buttons, it was a particularly egregious offender. Now, the company is doing a complete 180-degree shift, adding a full suite of physical buttons and switchgear to the Polo's interior.&lt;/p&gt;
    &lt;head rend="h2"&gt;For Sale Near You&lt;/head&gt;
    &lt;p&gt;See all results for Volkswagen for sale near 07076&lt;/p&gt;
    &lt;p&gt;The steering wheel gets new clusters of buttons for cruise control and interacting with music playback, while switches for the temperature and fan speed now live in a row along the dashboard. The move back to buttons doesn't come out of nowhere. Volkswagen already started the shift with the new versions of the Golf and Tiguan models in the United States. Unfortunately, some climate controls, such as those for the rear defrost and the heated seats, are still accessed through the touchscreen. Thankfully, they look to retain their dedicated spot at the bottom of the display.&lt;/p&gt;
    &lt;p&gt;Volkswagen hasn't announced which models will receive the new cockpit design. The redesigned interior also may be limited to the brand's electric vehicles, which would limit it to the upcoming refresh for the ID.4 SUV (and potentially the ID.Buzz), as the only VW EV models currently sold in America.&lt;/p&gt;
    &lt;p&gt;‚û°Ô∏è Skip the lot. Let Car and Driver help you find your next car.&lt;/p&gt;
    &lt;p&gt;Jack Fitzgerald‚Äôs love for cars stems from his as yet unshakable addiction to Formula 1. &lt;lb/&gt; After a brief stint as a detailer for a local dealership group in college, he knew he needed a more permanent way to drive all the new cars he couldn‚Äôt afford and decided to pursue a career in auto writing. By hounding his college professors at the University of Wisconsin-Milwaukee, he was able to travel Wisconsin seeking out stories in the auto world before landing his dream job at Car and Driver. His new goal is to delay the inevitable demise of his 2010 Volkswagen Golf.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46514913</guid><pubDate>Tue, 06 Jan 2026 16:59:44 +0000</pubDate></item><item><title>Opus 4.5 is not the normal AI agent experience that I have had thus far</title><link>https://burkeholland.github.io/posts/opus-4-5-change-everything/</link><description>&lt;doc fingerprint="26499875abe73fe9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Opus 4.5 is going to change everything&lt;/head&gt;
    &lt;p&gt;If you had asked me three months ago about these statements, I would have said only someone who‚Äôs never built anything non-trivial would believe they‚Äôre true. Great for augmenting a developer‚Äôs existing workflow, and completions are powerful, but agents replacing developers entirely? No. Absolutely not.&lt;/p&gt;
    &lt;p&gt;Today, I think that AI coding agents can absolutely replace developers. And the reason that I believe this is Claude Opus 4.5.&lt;/p&gt;
    &lt;head rend="h2"&gt;Opus 4.5 is not normal&lt;/head&gt;
    &lt;p&gt;And by ‚Äúnormal‚Äù, I mean that it is not the normal AI agent experience that I have had thus far. So far, AI Agents seem to be pretty good at writing spaghetti code and after 9 rounds of copy / paste errors into the terminal and ‚Äúfix it‚Äù have probably destroyed my codebase to the extent that I‚Äôll be throwing this whole chat session out and there goes 30 minutes I‚Äôm never getting back.&lt;/p&gt;
    &lt;p&gt;Opus 4.5 feels to me like the model that we were promised - or rather the promise of AI for coding actually delivered.&lt;/p&gt;
    &lt;p&gt;One of the toughest things about writing that last sentence is that the immediate response from you should be, ‚Äúprove it‚Äù. So let me show you what I‚Äôve been able to build.&lt;/p&gt;
    &lt;head rend="h3"&gt;Project 1 - Windows Image Conversion Utility&lt;/head&gt;
    &lt;p&gt;I first noticed that Opus 4.5 was drastically different when I used it to build a Windows utility to right-click an image and convert it to different file types. This was basically a one shot build after asking Opus the best way to add a right-click menu to the file explorer.&lt;/p&gt;
    &lt;p&gt;What amazed me through the process of building this was Opus 4.5 ability to get most things right on the first try. And if it ran into errors, it would try and build using the dotnet CLI, read the errors and iterate until fixed. The only issue I had was Opus inability to see XAML errors, which I used Visual Studio to see and copy / paste back into the agent.&lt;/p&gt;
    &lt;p&gt;Opus built a site for me to distribute it and handled the bundling of the executable so as to use a powershell script for the install, uninstall. It also built the GitHub Actions which do the release and update the landing page so that all I have to do is push source.&lt;/p&gt;
    &lt;p&gt;The only place I had to use other tools was for the logo - where I used Figma‚Äôs AI to generate a bunch of different variations - but then Opus wrote the scripts to convert that SVG to the right formats for icons, even store distribution if I chose to do so.&lt;/p&gt;
    &lt;p&gt;Now this is admittedly not a complex application. This is a small Windows utility that is doing basically one thing. It‚Äôs not like I asked Opus 4.5 to build Photoshop.&lt;/p&gt;
    &lt;p&gt;Except I kind of did.&lt;/p&gt;
    &lt;head rend="h3"&gt;Project 2 - Screen recording / editing&lt;/head&gt;
    &lt;p&gt;I was so impressed by Opus 4.5 work on this utility that I decided to make a simple GIF recording utility similar to LICEcap for Mac. Great app, questionable name.&lt;/p&gt;
    &lt;p&gt;But that proved to be so easy, that I went ahead and continued adding features, including capturing and editing video, static images, adding shapes, cropping, blurs and more. I‚Äôm still working on this application as it turns out building a full on image/video editor is kind of a big undertaking. But I got REALLY far in a matter of hours. HOURS, PEOPLE.&lt;/p&gt;
    &lt;p&gt;I don‚Äôt have a fancy landing page for this one yet, but you can view all of the source code here.&lt;/p&gt;
    &lt;p&gt;I realized that if I could build a video recording app, I could probably build anything at all - at least UI-wise. But the achilles heel of all AI agents is when they have to glue together backend systems - which any real world application is going to have - auth, database, API, storage.&lt;/p&gt;
    &lt;p&gt;Except Opus 4.5 can do that too.&lt;/p&gt;
    &lt;head rend="h3"&gt;Project 3 - AI Posting Utility&lt;/head&gt;
    &lt;p&gt;Armed with my confidence in Opus 4.5, I took on a project that I had built in React Native last year and finished for Android, but gave up in the final stretches (as one does).&lt;/p&gt;
    &lt;p&gt;The application is for my wife who owns a small yard sign franchise. The problem is that she has a Facebook page for the business, but never posts there because it‚Äôs time consuming. But any good small business has a vibrant page where people can see photos of your business doing‚Ä¶whatever the heck it does. So people know that it exsits and is alive and well.&lt;/p&gt;
    &lt;p&gt;The idea is simple - each time she sets up a yard sign, she takes a picture to send to the person who ordered it so they can see it was setup. So why not have a mobile app where she can upload 10 images at a time, and the app will use AI to generate captions and then schedule them and post them over the coming week.&lt;/p&gt;
    &lt;p&gt;It‚Äôs a simple premise, but it has a lot of moving parts - there is the Facebook authentication which is a caper in and of itself - not for the faint of heart. There is authentication with a backend, there is file storage for photos that are scheduled to go out, there is the backend process which needs to post the photo. It‚Äôs a full on backend setup.&lt;/p&gt;
    &lt;p&gt;As it turns out, I needed to install some blinds in the house so I thought - why don‚Äôt I see if Opus 4.5 can build this while I install the blinds.&lt;/p&gt;
    &lt;p&gt;So I fired up a chat session and just started by telling Opus 4.5 what I wanted to build and how it would recommend handling the backend. It recommended several options but settled on Firebase. I‚Äôm not now nor have I ever been a Firebase user, but at this point I trust Opus 4.5 a lot. Probably too much.&lt;/p&gt;
    &lt;p&gt;So I created a Firebase account, upgraded to the Blaze plan with alerts for billing and Opus 4.5 got to work.&lt;/p&gt;
    &lt;p&gt;By the time I was done installing blinds, I had a functional iOS application for using AI to caption photos and posting them on a schedule to Facebook.&lt;/p&gt;
    &lt;p&gt;When I say that Opus 4.5 built this almost entirely, I mean it. It used the &lt;code&gt;firebase&lt;/code&gt; CLI to stand up any resources it needed and would tag me in for certain things like upgrading a project to the Blaze plan for features like storage, etc. The best part was that when the Firebase cloud functions would throw errors, it would automatically grep those logs, find the error and resolve it. And all it needed was a CLI. No MCP Server. No fancy prompt file telling it how to use Firebase.&lt;/p&gt;
    &lt;p&gt;And of course, since it‚Äôs solved, I had Opus 4.5 create a backend admin dashboard so I could see what she‚Äôs got pending and make any adjustments.&lt;/p&gt;
    &lt;p&gt;And since it did in a few hours what had taken me two months of work in the evenings instead of being a decent husband, I decided to make up for my dereliction of duties by building her another app for her sign business that would make her life just a bit more delightful - and eliminate two other apps she is currently paying for.&lt;/p&gt;
    &lt;head rend="h3"&gt;Project 4 - Order tracking and routing&lt;/head&gt;
    &lt;p&gt;This app parses orders from her business Gmail account to show her what sign setups / pickups she has for the day, calculates how long its going to take to go to each stop, calculates the optimal route when there is more than one stop and tracks drive time for tax purposes. She was previously using two paid apps for the last two features there.&lt;/p&gt;
    &lt;p&gt;This app also uses Firebase. Again, Opus one-shotted the Google auth email integration. This is the kind of thing that is painstakingly miserable by hand. And again, Firebase is so well suited here because Opus knows how to use the Firebase CLI so well. It needs zero instruction.&lt;/p&gt;
    &lt;head rend="h3"&gt;BUT YOU DON‚ÄôT KNOW HOW THE CODE WORKS&lt;/head&gt;
    &lt;p&gt;No I don‚Äôt. I have a vague idea, but you are right - I do not know how the applications are actually assembled. Especially since I don‚Äôt know Swift at all.&lt;/p&gt;
    &lt;p&gt;This used to be a major hangup for me. I couldn‚Äôt diagnose problems when things went sideways. With Opus 4.5, I haven‚Äôt hit that wall yet‚ÄîOpus always figures out what the issue is and fixes its own bugs.&lt;/p&gt;
    &lt;p&gt;The real question is code quality. Without understanding how it‚Äôs built, how do I know if there‚Äôs duplication, dead code, or poor patterns? I used to obsess over this. Now I‚Äôm less worried that a human needs to read the code, because I‚Äôm genuinely not sure that they do.&lt;/p&gt;
    &lt;p&gt;Why does a human need to read this code at all? I use a custom agent in VS Code that tells Opus to write code for LLMs, not humans. Think about it‚Äîwhy optimize for human readability when the AI is doing all the work and will explain things to you when you ask?&lt;/p&gt;
    &lt;p&gt;What you don‚Äôt need: variable names, formatting, comments meant for humans, or patterns designed to spare your brain.&lt;/p&gt;
    &lt;p&gt;What you do need: simple entry points, explicit code with fewer abstractions, minimal coupling, and linear control flow.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs my custom agent prompt:&lt;/p&gt;
    &lt;code&gt;You are an AI-first software engineer. Assume all code will be written and maintained by LLMs, not humans. Optimize for model reasoning, regeneration, and debugging ‚Äî not human aesthetics.

These coding principles are mandatory:

1. Structure
- Use a consistent, predictable project layout.
- Group code by feature/screen; keep shared utilities minimal.
- Create simple, obvious entry points.
- Before scaffolding multiple files, identify shared structure first. Use framework-native composition patterns (layouts, base templates, providers, shared components) for elements that appear across pages. Duplication that requires the same fix in multiple places is a code smell, not a pattern to preserve.

2. Architecture
- Prefer flat, explicit code over abstractions or deep hierarchies.
- Avoid clever patterns, metaprogramming, and unnecessary indirection.
- Minimize coupling so files can be safely regenerated.

3. Functions and Modules
- Keep control flow linear and simple.
- Use small-to-medium functions; avoid deeply nested logic.
- Pass state explicitly; avoid globals.

4. Naming and Comments
- Use descriptive-but-simple names.
- Comment only to note invariants, assumptions, or external requirements.

5. Logging and Errors
- Emit detailed, structured logs at key boundaries.
- Make errors explicit and informative.

6. Regenerability
- Write code so any file/module can be rewritten from scratch without breaking the system.
- Prefer clear, declarative configuration (JSON/YAML/etc.).

7. Platform Use
- Use platform conventions directly and simply (e.g., WinUI/WPF) without over-abstracting.

8. Modifications
- When extending/refactoring, follow existing patterns.
- Prefer full-file rewrites over micro-edits unless told otherwise.

9. Quality
- Favor deterministic, testable behavior.
- Keep tests simple and focused on verifying observable behavior.

Your goal: produce code that is predictable, debuggable, and easy for future LLMs to rewrite or extend.
&lt;/code&gt;
    &lt;p&gt;All of that said, I don‚Äôt have any proof that this prompt makes a difference. I find that Opus 4.5 writes pretty solid code no matter what you prompt it with. However, because models like to write code WAY more than they like to delete it, I will at points run a prompt that looks something like this‚Ä¶&lt;/p&gt;
    &lt;code&gt;Check your LLM, AI coding principles and then do a comprehensive search of this application and suggest what we can do to refactor this to better align to those principles. Also point out any code that can be deleted, any files that can be deleted, things that should read should be renamed, things that should be restructured. Then do a write up of what that looks like. Kind of keep it high level so that it's easy for me to read and not too complex. Add sections for high, medium and lower priority And if something doesn't need to be changed, then don't change it. You don't need to change things just for the sake of changing them. You only need to change them if it helps better align to your LLM AI coding principles. Save to a markdown file.
&lt;/code&gt;
    &lt;p&gt;And you get a document that has high, medium and low priority items. The high ones you can deal with and the AI will stop finding them. You can refactor your project a million times and it will keep finding medium/low priority refactors that you can do. An AI is never ever going to pass on the opportunity to generate some text.&lt;/p&gt;
    &lt;p&gt;I use a similar prompt to find security issues. These you have to be very careful about. Where are the API keys? Is login handled correctly? Are you storing sensitive values in the database? This is probably the most manual part of the project and frankly, something that makes me the most nervous about all of these apps at the moment. I‚Äôm not 100% confident that they are bullet proof. Maybe like 80%. And that, as they say, is too damn low.&lt;/p&gt;
    &lt;head rend="h3"&gt;Times they are A-changin&lt;/head&gt;
    &lt;p&gt;I don‚Äôt know if I feel exhilarated by what I can now build in a matter of hours, or depressed because the thing I‚Äôve spent my life learning to do is now trivial for a computer. Both are true.&lt;/p&gt;
    &lt;p&gt;I understand if this post made you angry. I get it - I didn‚Äôt like it either when people said ‚ÄúAI is going to replace developers.‚Äù But I can‚Äôt dismiss it anymore. I can wish it weren‚Äôt true, but wishing doesn‚Äôt change reality.&lt;/p&gt;
    &lt;p&gt;But for everything else? Build. Stop waiting to have all the answers. Stop trying to figure out your place in an AI-first world. The answer is the same as it always was: make things. And now you can make them faster than you ever thought possible.&lt;/p&gt;
    &lt;p&gt;Just make sure you know where your API keys are.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Disclaimer: This post was written by a human and edited for spelling, grammer by Haiku 4.5&lt;/p&gt;
    &lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46515696</guid><pubDate>Tue, 06 Jan 2026 17:45:37 +0000</pubDate></item><item><title>Launch HN: Tamarind Bio (YC W24) ‚Äì AI Inference Provider for Drug Discovery</title><link>https://news.ycombinator.com/item?id=46515777</link><description>&lt;doc fingerprint="6f51ad5b7d3645cb"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hi HN, we're Deniz and Sherry from Tamarind Bio (&lt;/p&gt;https://www.tamarind.bio&lt;p&gt;). Tamarind is an inference provider for AI drug discovery, serving models like AlphaFold. Biopharma companies use our library of leading open-source models to design new medicines computationally.&lt;/p&gt;&lt;p&gt;Here‚Äôs a demo: https://youtu.be/luoMApPeglo&lt;/p&gt;&lt;p&gt;Two years ago, I was hired at a Stanford lab to run models for my labmates. Some post-doc would ask me to run a set of 1-5 models in sequence with tens of thousands inputs and I would email them back the result after setting up the workflow in the university cluster.&lt;/p&gt;&lt;p&gt;At some point, it became unreasonable that all of an organization's computational biology work would go through an undergrad, so we built Tamarind as a single place for all molecular AI tools, usable at massive scale with no technical background needed. Today, we are used by much of the top 20 pharma, dozens of biotechs and tens of thousands of scientists.&lt;/p&gt;&lt;p&gt;When we started getting adoption in the big pharma companies, we found that this problem also persisted. I know directors of data science, where half their job could be described as running scripts for other people.&lt;/p&gt;&lt;p&gt;Lots of companies have also deprecated their internally built solution to switch over, dealing with GPU infra and onboarding docker containers not being a very exciting problem when the company you work for is trying to cure cancer.&lt;/p&gt;&lt;p&gt;Unlike non-specialized inference providers, we build both a programmatic interface for developers along with a scientist-friendly web app, since most of our users are non-technical. Some of them used to extract proteins from animal blood before replacing that process with using AI to generate proteins on Tamarind.&lt;/p&gt;&lt;p&gt;Besides grinding out images for each of the models we serve, we‚Äôve designed a standardized schema to be able to share each model‚Äôs data format. We‚Äôve built a custom scheduler and queue optimized for horizontal scaling (each inference call takes minutes to hours, and runs on one GPU at a time), while splitting jobs across CPUs and GPUs for optimal timing.&lt;/p&gt;&lt;p&gt;As we've grown to handle a substantial portion of the biopharma R&amp;amp;D AI demand on behalf of our customers, we've expanded beyond just offering a library of open source protocols.&lt;/p&gt;&lt;p&gt;A common use case we saw from early on was the need to connect multiple models together into pipelines, and having reproducible, consistent protocols to replace physical experiments. Once we became the place to build internal tools for computational science, our users started asking if they could onboard their own models to the platform.&lt;/p&gt;&lt;p&gt;From there, we now support fine-tuning, building UIs for arbitrary docker containers, connecting to wet lab data sources and more!&lt;/p&gt;&lt;p&gt;Reach out to me at deniz[at]tamarind.bio if you‚Äôre interested in our work, we are hiring! Check out our product at https://app.tamarind.bio and let us know if you have any feedback to support how the biotech industry uses AI today.&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46515777</guid><pubDate>Tue, 06 Jan 2026 17:49:56 +0000</pubDate></item><item><title>Locating a Photo of a Vehicle in 30 Seconds with GeoSpy</title><link>https://geospy.ai/blog/locating-a-photo-of-a-vehicle-in-30-seconds-with-geospy</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46515948</guid><pubDate>Tue, 06 Jan 2026 18:00:27 +0000</pubDate></item></channel></rss>